From Pradip.Muhuri at samhsa.hhs.gov  Mon Dec  1 02:45:10 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 1 Dec 2014 01:45:10 +0000
Subject: [R] R dplyr solution vs. Base R solution for the slect column
 total
In-Reply-To: <8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
	<8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>

Hi Boris,

Sorry for not being explicit when replying to your first email.   I wanted to say it does not work when row-binding.  I want the following output.  Thanks,  Pradip


1            1      3
2            2      4
Total              7

################### Below is the console ##########
> test <- data.frame(first=c(1,2), second=c(3,4)) 
> test
  first second
1     1      3
2     2      4
> 
> sum(test$second)
[1] 7
> 
> rbind(test, sum(test$second))
  first second
1     1      3
2     2      4
3     7      7

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

-----Original Message-----
From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
Sent: Sunday, November 30, 2014 5:51 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total

No it doesn't ...
consider:

test <- data.frame(first=c(1,2), second=c(3,4)) test
  first second
1     1      3
2     2      4

sum(test$second)
[1] 7




On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hi Boris,
> 
> That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.
> 
> Thanks,
> 
> Pradip Muhuri
> 
> 
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
> Sent: Sunday, November 30, 2014 12:50 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
> column total
> 
> try:
> 
> sum(test$count)
> 
> 
> B.
> 
> 
> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
> 
>> Hello,
>> 
>> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
>> rbind(test, colSums(test))
>> 
>> I only want the total for the very last column.  I am struggling with 
>> this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
>> 
>> Any hints will be appreciated.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> 
>> ####### The following is from the console - the R script with reproducible example is also appended.
>> 
>> 
>> mrjflag cocflag inhflag halflag oidflag count
>> 1        0       0       0       0       0   256
>> 2        0       0       0       1       1   256
>> 3        0       0       1       0       1   256
>> 4        0       0       1       1       1   256
>> 5        0       1       0       0       1   256
>> 6        0       1       0       1       1   256
>> 7        0       1       1       0       1   256
>> 8        0       1       1       1       1   256
>> 9        1       0       0       0       1   256
>> 10       1       0       0       1       1   256
>> 11       1       0       1       0       1   256
>> 12       1       0       1       1       1   256
>> 13       1       1       0       0       1   256
>> 14       1       1       0       1       1   256
>> 15       1       1       1       0       1   256
>> 16       1       1       1       1       1   256
>> 17       8       8       8       8      15  4096
>> 
>> 
>> 
>> #######################  below is the reproducible example 
>> ########################
>> library(dplyr)
>> # generate data
>> dlist <- rep( list( 0:1 ), 4 )
>> data <- do.call(expand.grid, drbind)
>> data$id <- 1:nrow(data)
>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>> 
>> 
>> # mutate a column and then sumamrize
>> test <- data %>%
>>      mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>>      group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>      summarise(count=n()) %>%
>>      arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>> 
>> 
>> #  This works, giving me the total for each column - This is not what I exactly want.
>>   rbind(test, colSums(test))
>> 
>> # I only want the total for the very last column rbind(test, 
>> c("Total", colSums(test, ...)))
>> 
>> Pradip K. Muhuri, PhD
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.CA.us  Mon Dec  1 02:52:11 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 30 Nov 2014 17:52:11 -0800
Subject: [R] R dplyr solution vs. Base R solution for the slect column
	total
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
	<8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
Message-ID: <8725D84B-49DE-48A6-A61F-4BDB9C59EC20@dcn.davis.CA.us>

Seems like you have what you want, unless you meant to show something different than you did show.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On November 30, 2014 5:45:10 PM PST, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hi Boris,
>
>Sorry for not being explicit when replying to your first email.   I
>wanted to say it does not work when row-binding.  I want the following
>output.  Thanks,  Pradip
>
>
>1            1      3
>2            2      4
>Total              7
>
>################### Below is the console ##########
>> test <- data.frame(first=c(1,2), second=c(3,4)) 
>> test
>  first second
>1     1      3
>2     2      4
>> 
>> sum(test$second)
>[1] 7
>> 
>> rbind(test, sum(test$second))
>  first second
>1     1      3
>2     2      4
>3     7      7
>
>Pradip K. Muhuri, PhD
>SAMHSA/CBHSQ
>1 Choke Cherry Road, Room 2-1071
>Rockville, MD 20857
>Tel: 240-276-1070
>Fax: 240-276-1260
>
>-----Original Message-----
>From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
>Sent: Sunday, November 30, 2014 5:51 PM
>To: Muhuri, Pradip (SAMHSA/CBHSQ)
>Cc: r-help at r-project.org
>Subject: Re: [R] R dplyr solution vs. Base R solution for the slect
>column total
>
>No it doesn't ...
>consider:
>
>test <- data.frame(first=c(1,2), second=c(3,4)) test
>  first second
>1     1      3
>2     2      4
>
>sum(test$second)
>[1] 7
>
>
>
>
>On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ)
><Pradip.Muhuri at samhsa.hhs.gov> wrote:
>
>> Hi Boris,
>> 
>> That gives me the total for each of the 6 columns of the data frame.
>I want the column sum just for the last column.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> 
>> 
>> -----Original Message-----
>> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
>> Sent: Sunday, November 30, 2014 12:50 PM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
>> column total
>> 
>> try:
>> 
>> sum(test$count)
>> 
>> 
>> B.
>> 
>> 
>> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ)
><Pradip.Muhuri at samhsa.hhs.gov> wrote:
>> 
>>> Hello,
>>> 
>>> I am looking for a dplyr or base R solution for the column total -
>JUST FOR THE LAST COLUMN in the example below. The following code
>works, giving me the total for each column - This is not exactly what I
>want.
>>> rbind(test, colSums(test))
>>> 
>>> I only want the total for the very last column.  I am struggling
>with 
>>> this part of the code: rbind(test, c("Total", colSums(test, ...))) I
>have searched for a solution on Stack Oveflow.  I found  some mutate()
>code for the cumsum but no luck for the select column total.  Is there
>a dplyr solution for the select column total?
>>> 
>>> Any hints will be appreciated.
>>> 
>>> Thanks,
>>> 
>>> Pradip Muhuri
>>> 
>>> 
>>> ####### The following is from the console - the R script with
>reproducible example is also appended.
>>> 
>>> 
>>> mrjflag cocflag inhflag halflag oidflag count
>>> 1        0       0       0       0       0   256
>>> 2        0       0       0       1       1   256
>>> 3        0       0       1       0       1   256
>>> 4        0       0       1       1       1   256
>>> 5        0       1       0       0       1   256
>>> 6        0       1       0       1       1   256
>>> 7        0       1       1       0       1   256
>>> 8        0       1       1       1       1   256
>>> 9        1       0       0       0       1   256
>>> 10       1       0       0       1       1   256
>>> 11       1       0       1       0       1   256
>>> 12       1       0       1       1       1   256
>>> 13       1       1       0       0       1   256
>>> 14       1       1       0       1       1   256
>>> 15       1       1       1       0       1   256
>>> 16       1       1       1       1       1   256
>>> 17       8       8       8       8      15  4096
>>> 
>>> 
>>> 
>>> #######################  below is the reproducible example 
>>> ########################
>>> library(dplyr)
>>> # generate data
>>> dlist <- rep( list( 0:1 ), 4 )
>>> data <- do.call(expand.grid, drbind)
>>> data$id <- 1:nrow(data)
>>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>>> 
>>> 
>>> # mutate a column and then sumamrize
>>> test <- data %>%
>>>      mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 |
>halflag==1, 1, 0)) %>%
>>>      group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>>      summarise(count=n()) %>%
>>>      arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>>> 
>>> 
>>> #  This works, giving me the total for each column - This is not
>what I exactly want.
>>>   rbind(test, colSums(test))
>>> 
>>> # I only want the total for the very last column rbind(test, 
>>> c("Total", colSums(test, ...)))
>>> 
>>> Pradip K. Muhuri, PhD
>>> SAMHSA/CBHSQ
>>> 1 Choke Cherry Road, Room 2-1071
>>> Rockville, MD 20857
>>> Tel: 240-276-1070
>>> Fax: 240-276-1260
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Dec  1 03:15:41 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Nov 2014 21:15:41 -0500
Subject: [R] R dplyr solution vs. Base R solution for the slect column
 total
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>	<8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
Message-ID: <547BCF4D.6060108@gmail.com>

On 30/11/2014, 8:45 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hi Boris,
> 
> Sorry for not being explicit when replying to your first email.   I wanted to say it does not work when row-binding.  I want the following output.  Thanks,  Pradip
> 
> 
> 1            1      3
> 2            2      4
> Total              7

You are mixing up the computation of results with the presentation of
them.  That's the spreadsheet way of thinking, and it's okay for simple
things like this, but gets really bogged down when the computations get
hard.

In R you can do it, and it's not too hard:

test <- data.frame(first=c(1,2), second=c(3,4))
total <- c("", sum(test$second))
rbind(test, Total=total)

but this isn't a really sensible thing to do:  you can't work with that
final result at all.  It makes more sense to leave it in the original
form, and then think about how you want to present it, and write a
function that displays the result, with nice formatting, etc.  That
probably won't happen in the R console, you should be using Sweave or
knitr or some other package for presentation of the results.

Duncan Murdoch


> 
> ################### Below is the console ##########
>> test <- data.frame(first=c(1,2), second=c(3,4)) 
>> test
>   first second
> 1     1      3
> 2     2      4
>>
>> sum(test$second)
> [1] 7
>>
>> rbind(test, sum(test$second))
>   first second
> 1     1      3
> 2     2      4
> 3     7      7
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
> Sent: Sunday, November 30, 2014 5:51 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total
> 
> No it doesn't ...
> consider:
> 
> test <- data.frame(first=c(1,2), second=c(3,4)) test
>   first second
> 1     1      3
> 2     2      4
> 
> sum(test$second)
> [1] 7
> 
> 
> 
> 
> On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
> 
>> Hi Boris,
>>
>> That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.
>>
>> Thanks,
>>
>> Pradip Muhuri
>>
>>
>>
>> -----Original Message-----
>> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
>> Sent: Sunday, November 30, 2014 12:50 PM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
>> column total
>>
>> try:
>>
>> sum(test$count)
>>
>>
>> B.
>>
>>
>> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>>
>>> Hello,
>>>
>>> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
>>> rbind(test, colSums(test))
>>>
>>> I only want the total for the very last column.  I am struggling with 
>>> this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
>>>
>>> Any hints will be appreciated.
>>>
>>> Thanks,
>>>
>>> Pradip Muhuri
>>>
>>>
>>> ####### The following is from the console - the R script with reproducible example is also appended.
>>>
>>>
>>> mrjflag cocflag inhflag halflag oidflag count
>>> 1        0       0       0       0       0   256
>>> 2        0       0       0       1       1   256
>>> 3        0       0       1       0       1   256
>>> 4        0       0       1       1       1   256
>>> 5        0       1       0       0       1   256
>>> 6        0       1       0       1       1   256
>>> 7        0       1       1       0       1   256
>>> 8        0       1       1       1       1   256
>>> 9        1       0       0       0       1   256
>>> 10       1       0       0       1       1   256
>>> 11       1       0       1       0       1   256
>>> 12       1       0       1       1       1   256
>>> 13       1       1       0       0       1   256
>>> 14       1       1       0       1       1   256
>>> 15       1       1       1       0       1   256
>>> 16       1       1       1       1       1   256
>>> 17       8       8       8       8      15  4096
>>>
>>>
>>>
>>> #######################  below is the reproducible example 
>>> ########################
>>> library(dplyr)
>>> # generate data
>>> dlist <- rep( list( 0:1 ), 4 )
>>> data <- do.call(expand.grid, drbind)
>>> data$id <- 1:nrow(data)
>>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>>>
>>>
>>> # mutate a column and then sumamrize
>>> test <- data %>%
>>>      mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>>>      group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>>      summarise(count=n()) %>%
>>>      arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>>>
>>>
>>> #  This works, giving me the total for each column - This is not what I exactly want.
>>>   rbind(test, colSums(test))
>>>
>>> # I only want the total for the very last column rbind(test, 
>>> c("Total", colSums(test, ...)))
>>>
>>> Pradip K. Muhuri, PhD
>>> SAMHSA/CBHSQ
>>> 1 Choke Cherry Road, Room 2-1071
>>> Rockville, MD 20857
>>> Tel: 240-276-1070
>>> Fax: 240-276-1260
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Pradip.Muhuri at samhsa.hhs.gov  Mon Dec  1 03:29:54 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 1 Dec 2014 02:29:54 +0000
Subject: [R] R dplyr solution vs. Base R solution for the slect column
 total
In-Reply-To: <547BCF4D.6060108@gmail.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
	<8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
	<547BCF4D.6060108@gmail.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C3892F3DC@PL-EMSMB20.ees.hhs.gov>

Hi Duncan,

Thank you for sending your solution.  Below is another way.  

Pradip

> test <- data.frame(first=c(1,2),  second=c(3,4)) 
> total <- c("", sum(test$second))
> rbind(test, Total=total)
      first second
1         1      3
2         2      4
Total            7

> rbind(test, c("Total", colSums(test[,2, drop=FALSE])))
  first second
1     1      3
2     2      4
3 Total      7

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Sunday, November 30, 2014 9:16 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ); 'Boris Steipe'
Cc: r-help at r-project.org
Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total

On 30/11/2014, 8:45 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hi Boris,
> 
> Sorry for not being explicit when replying to your first email.   I wanted to say it does not work when row-binding.  I want the following output.  Thanks,  Pradip
> 
> 
> 1            1      3
> 2            2      4
> Total              7

You are mixing up the computation of results with the presentation of them.  That's the spreadsheet way of thinking, and it's okay for simple things like this, but gets really bogged down when the computations get hard.

In R you can do it, and it's not too hard:

test <- data.frame(first=c(1,2), second=c(3,4)) total <- c("", sum(test$second)) rbind(test, Total=total)

but this isn't a really sensible thing to do:  you can't work with that final result at all.  It makes more sense to leave it in the original form, and then think about how you want to present it, and write a function that displays the result, with nice formatting, etc.  That probably won't happen in the R console, you should be using Sweave or knitr or some other package for presentation of the results.

Duncan Murdoch


> 
> ################### Below is the console ##########
>> test <- data.frame(first=c(1,2), second=c(3,4)) test
>   first second
> 1     1      3
> 2     2      4
>>
>> sum(test$second)
> [1] 7
>>
>> rbind(test, sum(test$second))
>   first second
> 1     1      3
> 2     2      4
> 3     7      7
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
> Sent: Sunday, November 30, 2014 5:51 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
> column total
> 
> No it doesn't ...
> consider:
> 
> test <- data.frame(first=c(1,2), second=c(3,4)) test
>   first second
> 1     1      3
> 2     2      4
> 
> sum(test$second)
> [1] 7
> 
> 
> 
> 
> On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
> 
>> Hi Boris,
>>
>> That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.
>>
>> Thanks,
>>
>> Pradip Muhuri
>>
>>
>>
>> -----Original Message-----
>> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
>> Sent: Sunday, November 30, 2014 12:50 PM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
>> column total
>>
>> try:
>>
>> sum(test$count)
>>
>>
>> B.
>>
>>
>> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>>
>>> Hello,
>>>
>>> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
>>> rbind(test, colSums(test))
>>>
>>> I only want the total for the very last column.  I am struggling 
>>> with this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
>>>
>>> Any hints will be appreciated.
>>>
>>> Thanks,
>>>
>>> Pradip Muhuri
>>>
>>>
>>> ####### The following is from the console - the R script with reproducible example is also appended.
>>>
>>>
>>> mrjflag cocflag inhflag halflag oidflag count
>>> 1        0       0       0       0       0   256
>>> 2        0       0       0       1       1   256
>>> 3        0       0       1       0       1   256
>>> 4        0       0       1       1       1   256
>>> 5        0       1       0       0       1   256
>>> 6        0       1       0       1       1   256
>>> 7        0       1       1       0       1   256
>>> 8        0       1       1       1       1   256
>>> 9        1       0       0       0       1   256
>>> 10       1       0       0       1       1   256
>>> 11       1       0       1       0       1   256
>>> 12       1       0       1       1       1   256
>>> 13       1       1       0       0       1   256
>>> 14       1       1       0       1       1   256
>>> 15       1       1       1       0       1   256
>>> 16       1       1       1       1       1   256
>>> 17       8       8       8       8      15  4096
>>>
>>>
>>>
>>> #######################  below is the reproducible example 
>>> ########################
>>> library(dplyr)
>>> # generate data
>>> dlist <- rep( list( 0:1 ), 4 )
>>> data <- do.call(expand.grid, drbind) data$id <- 1:nrow(data)
>>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>>>
>>>
>>> # mutate a column and then sumamrize
>>> test <- data %>%
>>>      mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>>>      group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>>      summarise(count=n()) %>%
>>>      arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>>>
>>>
>>> #  This works, giving me the total for each column - This is not what I exactly want.
>>>   rbind(test, colSums(test))
>>>
>>> # I only want the total for the very last column rbind(test, 
>>> c("Total", colSums(test, ...)))
>>>
>>> Pradip K. Muhuri, PhD
>>> SAMHSA/CBHSQ
>>> 1 Choke Cherry Road, Room 2-1071
>>> Rockville, MD 20857
>>> Tel: 240-276-1070
>>> Fax: 240-276-1260
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From maitra.mbox.ignored at inbox.com  Mon Dec  1 03:37:22 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sun, 30 Nov 2014 20:37:22 -0600
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <alpine.LNX.2.11.1411301224370.28168@localhost>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
Message-ID: <20141130203722.1993f561c970a83d1ab8b384@inbox.com>

Following on Rich and Peter, is it practical for the list to put it at the top then, before the R-message?

Something like:

TO UNSUBSCRIBE from the list: see https://stat.ethz.ch/mailman/listinfo/r-help

And then continue on for each R message. Because top-posting has pretty much taken over, the best efforts of puritans notwithstanding, putting stuff at the bottom is unlikely to evoke much attention, and especially so in our 140-character-3-second attention-span world.

As an aside, if I were the OP, and wanted to unsubscribe, the volume of the e-mail messages on this topic alone would have been punishment enough for the original post:-)

Best wishes,
Ranjan

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From boris.steipe at utoronto.ca  Mon Dec  1 03:42:13 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 30 Nov 2014 21:42:13 -0500
Subject: [R] R dplyr solution vs. Base R solution for the slect column
	total
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
	<8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
Message-ID: <00D353B0-0B42-47E7-A909-53BCBBA21714@utoronto.ca>

What do you think should be in the empty cells? Zero? NA? Empty strings? There can't just be nothing...
Here's an example with empty strings "" as the filler element - but do consider carefully what Duncan wrote.


test <- data.frame(first=c(1,2), second=c(3,4))
typeof(test[1,1])  # double

# rbind() a vector that repeats the "empty" element one-less-then-ncols() times, 
# and has the column sum as its last element.
test <- rbind(test, c(rep("", ncol(test)-1), sum(test$second)))
test

  first second
1     1      3
2     2      4
3            7

# but...!

typeof(test[1,1]) # character!
typeof(test[2,2]) # also character! 

By adding characters to your columns, you cast all of your data into character type!
If you want to *do* anything with the number, you'll need to cast it back to numeric.
Or use 0 or NA as the filler element.

test <- rbind(test, c(rep(NA, ncol(test)-1), sum(test$second)))

But anyway ... as others have said, you may want to reconsider the logic of your approach.


B.



On Nov 30, 2014, at 8:45 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hi Boris,
> 
> Sorry for not being explicit when replying to your first email.   I wanted to say it does not work when row-binding.  I want the following output.  Thanks,  Pradip
> 
> 
> 1            1      3
> 2            2      4
> Total              7
> 
> ################### Below is the console ##########
>> test <- data.frame(first=c(1,2), second=c(3,4)) 
>> test
>  first second
> 1     1      3
> 2     2      4
>> 
>> sum(test$second)
> [1] 7
>> 
>> rbind(test, sum(test$second))
>  first second
> 1     1      3
> 2     2      4
> 3     7      7
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
> Sent: Sunday, November 30, 2014 5:51 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total
> 
> No it doesn't ...
> consider:
> 
> test <- data.frame(first=c(1,2), second=c(3,4)) test
>  first second
> 1     1      3
> 2     2      4
> 
> sum(test$second)
> [1] 7
> 
> 
> 
> 
> On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
> 
>> Hi Boris,
>> 
>> That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> 
>> 
>> -----Original Message-----
>> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
>> Sent: Sunday, November 30, 2014 12:50 PM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
>> column total
>> 
>> try:
>> 
>> sum(test$count)
>> 
>> 
>> B.
>> 
>> 
>> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>> 
>>> Hello,
>>> 
>>> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
>>> rbind(test, colSums(test))
>>> 
>>> I only want the total for the very last column.  I am struggling with 
>>> this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
>>> 
>>> Any hints will be appreciated.
>>> 
>>> Thanks,
>>> 
>>> Pradip Muhuri
>>> 
>>> 
>>> ####### The following is from the console - the R script with reproducible example is also appended.
>>> 
>>> 
>>> mrjflag cocflag inhflag halflag oidflag count
>>> 1        0       0       0       0       0   256
>>> 2        0       0       0       1       1   256
>>> 3        0       0       1       0       1   256
>>> 4        0       0       1       1       1   256
>>> 5        0       1       0       0       1   256
>>> 6        0       1       0       1       1   256
>>> 7        0       1       1       0       1   256
>>> 8        0       1       1       1       1   256
>>> 9        1       0       0       0       1   256
>>> 10       1       0       0       1       1   256
>>> 11       1       0       1       0       1   256
>>> 12       1       0       1       1       1   256
>>> 13       1       1       0       0       1   256
>>> 14       1       1       0       1       1   256
>>> 15       1       1       1       0       1   256
>>> 16       1       1       1       1       1   256
>>> 17       8       8       8       8      15  4096
>>> 
>>> 
>>> 
>>> #######################  below is the reproducible example 
>>> ########################
>>> library(dplyr)
>>> # generate data
>>> dlist <- rep( list( 0:1 ), 4 )
>>> data <- do.call(expand.grid, drbind)
>>> data$id <- 1:nrow(data)
>>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>>> 
>>> 
>>> # mutate a column and then sumamrize
>>> test <- data %>%
>>>     mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>>>     group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>>     summarise(count=n()) %>%
>>>     arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>>> 
>>> 
>>> #  This works, giving me the total for each column - This is not what I exactly want.
>>>  rbind(test, colSums(test))
>>> 
>>> # I only want the total for the very last column rbind(test, 
>>> c("Total", colSums(test, ...)))
>>> 
>>> Pradip K. Muhuri, PhD
>>> SAMHSA/CBHSQ
>>> 1 Choke Cherry Road, Room 2-1071
>>> Rockville, MD 20857
>>> Tel: 240-276-1070
>>> Fax: 240-276-1260
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 


From Pradip.Muhuri at samhsa.hhs.gov  Mon Dec  1 04:08:03 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Mon, 1 Dec 2014 03:08:03 +0000
Subject: [R] R dplyr solution vs. Base R solution for the slect column
 total
In-Reply-To: <00D353B0-0B42-47E7-A909-53BCBBA21714@utoronto.ca>
References: <E18C153EBB81024CB60FCE9B4C34D57C3892F367@PL-EMSMB20.ees.hhs.gov>
	<4D34899B-274C-430C-9D4F-21D1246DCA93@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F395@PL-EMSMB20.ees.hhs.gov>
	<8C1EDBE9-35B8-47F3-912F-3E3C723243E5@utoronto.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C3892F3BA@PL-EMSMB20.ees.hhs.gov>
	<00D353B0-0B42-47E7-A909-53BCBBA21714@utoronto.ca>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C3892F3F0@PL-EMSMB20.ees.hhs.gov>

Hi Boris,

Excellent point.  Yes, I want to convert it into to the numeric type.  Your code has worked out well on the real data set.  The issue is resolved.

Thanks so much for your help!

Pradip



-----Original Message-----
From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
Sent: Sunday, November 30, 2014 9:42 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] R dplyr solution vs. Base R solution for the slect column total

What do you think should be in the empty cells? Zero? NA? Empty strings? There can't just be nothing...
Here's an example with empty strings "" as the filler element - but do consider carefully what Duncan wrote.


test <- data.frame(first=c(1,2), second=c(3,4))
typeof(test[1,1])  # double

# rbind() a vector that repeats the "empty" element one-less-then-ncols() times, # and has the column sum as its last element.
test <- rbind(test, c(rep("", ncol(test)-1), sum(test$second))) test

  first second
1     1      3
2     2      4
3            7

# but...!

typeof(test[1,1]) # character!
typeof(test[2,2]) # also character! 

By adding characters to your columns, you cast all of your data into character type!
If you want to *do* anything with the number, you'll need to cast it back to numeric.
Or use 0 or NA as the filler element.

test <- rbind(test, c(rep(NA, ncol(test)-1), sum(test$second)))

But anyway ... as others have said, you may want to reconsider the logic of your approach.


B.



On Nov 30, 2014, at 8:45 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hi Boris,
> 
> Sorry for not being explicit when replying to your first email.   I wanted to say it does not work when row-binding.  I want the following output.  Thanks,  Pradip
> 
> 
> 1            1      3
> 2            2      4
> Total              7
> 
> ################### Below is the console ##########
>> test <- data.frame(first=c(1,2), second=c(3,4)) test
>  first second
> 1     1      3
> 2     2      4
>> 
>> sum(test$second)
> [1] 7
>> 
>> rbind(test, sum(test$second))
>  first second
> 1     1      3
> 2     2      4
> 3     7      7
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
> Sent: Sunday, November 30, 2014 5:51 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
> column total
> 
> No it doesn't ...
> consider:
> 
> test <- data.frame(first=c(1,2), second=c(3,4)) test  first second
> 1     1      3
> 2     2      4
> 
> sum(test$second)
> [1] 7
> 
> 
> 
> 
> On Nov 30, 2014, at 3:48 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
> 
>> Hi Boris,
>> 
>> That gives me the total for each of the 6 columns of the data frame. I want the column sum just for the last column.
>> 
>> Thanks,
>> 
>> Pradip Muhuri
>> 
>> 
>> 
>> -----Original Message-----
>> From: Boris Steipe [mailto:boris.steipe at utoronto.ca]
>> Sent: Sunday, November 30, 2014 12:50 PM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] R dplyr solution vs. Base R solution for the slect 
>> column total
>> 
>> try:
>> 
>> sum(test$count)
>> 
>> 
>> B.
>> 
>> 
>> On Nov 30, 2014, at 12:01 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>> 
>>> Hello,
>>> 
>>> I am looking for a dplyr or base R solution for the column total - JUST FOR THE LAST COLUMN in the example below. The following code works, giving me the total for each column - This is not exactly what I want.
>>> rbind(test, colSums(test))
>>> 
>>> I only want the total for the very last column.  I am struggling 
>>> with this part of the code: rbind(test, c("Total", colSums(test, ...))) I have searched for a solution on Stack Oveflow.  I found  some mutate() code for the cumsum but no luck for the select column total.  Is there a dplyr solution for the select column total?
>>> 
>>> Any hints will be appreciated.
>>> 
>>> Thanks,
>>> 
>>> Pradip Muhuri
>>> 
>>> 
>>> ####### The following is from the console - the R script with reproducible example is also appended.
>>> 
>>> 
>>> mrjflag cocflag inhflag halflag oidflag count
>>> 1        0       0       0       0       0   256
>>> 2        0       0       0       1       1   256
>>> 3        0       0       1       0       1   256
>>> 4        0       0       1       1       1   256
>>> 5        0       1       0       0       1   256
>>> 6        0       1       0       1       1   256
>>> 7        0       1       1       0       1   256
>>> 8        0       1       1       1       1   256
>>> 9        1       0       0       0       1   256
>>> 10       1       0       0       1       1   256
>>> 11       1       0       1       0       1   256
>>> 12       1       0       1       1       1   256
>>> 13       1       1       0       0       1   256
>>> 14       1       1       0       1       1   256
>>> 15       1       1       1       0       1   256
>>> 16       1       1       1       1       1   256
>>> 17       8       8       8       8      15  4096
>>> 
>>> 
>>> 
>>> #######################  below is the reproducible example 
>>> ########################
>>> library(dplyr)
>>> # generate data
>>> dlist <- rep( list( 0:1 ), 4 )
>>> data <- do.call(expand.grid, drbind) data$id <- 1:nrow(data)
>>> names(data) <- c('mrjflag', 'cocflag', 'inhflag', 'halflag')
>>> 
>>> 
>>> # mutate a column and then sumamrize test <- data %>%
>>>     mutate(oidflag= ifelse(mrjflag==1 | cocflag==1 | inhflag==1 | halflag==1, 1, 0)) %>%
>>>     group_by(mrjflag,cocflag, inhflag, halflag, oidflag) %>%
>>>     summarise(count=n()) %>%
>>>     arrange(mrjflag,cocflag, inhflag, halflag, oidflag)
>>> 
>>> 
>>> #  This works, giving me the total for each column - This is not what I exactly want.
>>>  rbind(test, colSums(test))
>>> 
>>> # I only want the total for the very last column rbind(test, 
>>> c("Total", colSums(test, ...)))
>>> 
>>> Pradip K. Muhuri, PhD
>>> SAMHSA/CBHSQ
>>> 1 Choke Cherry Road, Room 2-1071
>>> Rockville, MD 20857
>>> Tel: 240-276-1070
>>> Fax: 240-276-1260
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 


From petr.pikal at precheza.cz  Mon Dec  1 09:32:00 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 1 Dec 2014 08:32:00 +0000
Subject: [R] HELP
In-Reply-To: <CAHFo0Ls6EDZLR0HyB5AMEOYb4PV9j+QGv2eMm4v0RGLNHphxQQ@mail.gmail.com>
References: <CAHFo0LvPsW6hAnOuzKF80u3Wizbc7VL3WSB7Ne0Um=J-he0ibg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA5DB@SRVEXCHMBX.precheza.cz>
	<CAHFo0Ls6EDZLR0HyB5AMEOYb4PV9j+QGv2eMm4v0RGLNHphxQQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0587@SRVEXCHMBX.precheza.cz>

Hi

Your code is not reproducible.

I found this
http://rstudio-pubs-static.s3.amazonaws.com/1963_60f8740918d5416e8d54f07f48ce04fd.html

which does ggplot with 2 axes. I did not went further as I do not see the point for two y axes in ggplot. Working directly with grid graphics objects is beyond my abilities.

If I want several graphs sharing one axis I use facet_grid.

You can also check twoord.plot from plotrix, which is easier.

Cheers
Petr

From: JAVAD LESSAN [mailto:jlessan13 at ku.edu.tr]
Sent: Friday, November 28, 2014 4:30 PM
To: PIKAL Petr
Subject: Re: [R] HELP

Hi Sir!
Hope you are doing well!
Sine my last email and your kind reply, I have been doing every thing easily in R so far, but I got a problem and after a long search I could not find any solution for I am writing to have your help, please.
The problem is that I use ggplot function to draw a plot with two Y axises, but it does not show the second Y axis label as far as I tried.
I attached my code and a shot from the plot I can create, to help you understand my problem better. And I would be grateful if you help me about.
Thanks in advance.

Best,
Javad


On Thu, Oct 16, 2014 at 8:35 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

It will be even worse with age, try to contact optician :-)

If you want to get better answer you need to provide more info about your file, what you did and how it failed.

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-<mailto:r-help-bounces at r->
> project.org<http://project.org>] On Behalf Of JAVAD LESSAN
> Sent: Wednesday, October 15, 2014 2:53 PM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] HELP
>
> Hello There!
>
> I have an issue reading a large text file and parsing it. I would be
> grateful if you let me you can help me about? Thanks.
>
> Javad
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From lterlemez at anadolu.edu.tr  Mon Dec  1 10:00:25 2014
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Mon, 1 Dec 2014 09:00:25 +0000
Subject: [R] Cycling and different xerror values in cp of rpart,
 which result should I trust?...
Message-ID: <D0A1FACE.11DB3%lterlemez@anadolu.edu.tr>

Dear Users,
Is it possible to get cycling and different xerror scores in cp of rpart while getting the same tree on every run (or am I missing something or understood wrong)? I build it with an old version of R in a Windows VM installed on a Intel based macbook and reuse the same codes with a newer version of R and required packages on an AMD pc installed with standalone Windows. Both Windows are 64bit, which result should I trust, the old one or new one, macbook or pc?

Thanks in advanced,
Levent TERLEMEZ.


	[[alternative HTML version deleted]]


From Rainer at krugs.de  Mon Dec  1 10:09:52 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 1 Dec 2014 10:09:52 +0100
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <20141130203722.1993f561c970a83d1ab8b384@inbox.com> (Ranjan
	Maitra's message of "Sun, 30 Nov 2014 20:37:22 -0600")
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
Message-ID: <m2vblvu467.fsf@krugs.de>

Top post as new thought:

I just searched the archives, and there are less then 1000 emails about
unsubscribing since 2003. There are more then 70% (guess) which have nothing to do
with unsubscription, and about 19 (plus this one) mails in this
thread... Counting the poccurrance of "unsubscribe" in the headers, I
get about 30, which means 30 threads having "unsubscribe" or
"Unsubscribe" in the header.

Assuming that I missed all the "remove me ..." questions, I just triple
the number of threads.

So: this thread has one mail for three unsubscribe questions...

Cheers,

Rainer

Ranjan Maitra <maitra.mbox.ignored at inbox.com> writes:

> Following on Rich and Peter, is it practical for the list to put it at the top then, before the R-message?
>
> Something like:
>
> TO UNSUBSCRIBE from the list: see https://stat.ethz.ch/mailman/listinfo/r-help
>
> And then continue on for each R message. Because top-posting has
> pretty much taken over, the best efforts of puritans notwithstanding,
> putting stuff at the bottom is unlikely to evoke much attention, and
> especially so in our 140-character-3-second attention-span world.
>
> As an aside, if I were the OP, and wanted to unsubscribe, the volume
> of the e-mail messages on this topic alone would have been punishment
> enough for the original post:-)
>
> Best wishes,
> Ranjan
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141201/37761a00/attachment.bin>

From rhelpmaillist at 163.com  Mon Dec  1 03:09:17 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 1 Dec 2014 10:09:17 +0800 (CST)
Subject: [R] using win task to run Rscript somepackages can't work in script
 mode
Message-ID: <768f0f57.20e4.14a039be90a.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? ? ?These days i want to run a .R file contained a package called gmailr to do something about processing gmail , it works well in?
interactive
?GUI ?,that is ,Rstudio. But i want to run it by a windows task, so i need to run the .R file in Rscript mode, sadly, there seems different between the two ways, the gmailr package fails work in the script mode.
? ? So, what the difference? why Rscript can't run some codes which works well in Rstudio? How can i do something to make it suceess if there is some options to set ?
? ??




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From rhelp at numberland.de  Mon Dec  1 10:26:01 2014
From: rhelp at numberland.de (rhelp at numberland.de)
Date: Mon, 01 Dec 2014 10:26:01 +0100
Subject: [R] rgl WebGL export
Message-ID: <547C3429.10802@numberland.de>

Dear List members,

I would be glad to get some tips on the following topic.

I use rgl package to generate a 3D-cube with labeled dots at certain 
coordinates. After that I try to export the scene as a WebGL 
application. For this I use the syntax from rgl documentation 
"writeWebGL" mentioned in the example - page 94.

In principle this works, but:

- using Firefox to view the result, the dots have become quadratic dots, 
and the labels don?t show (i. e. there are only unlabeled dots)
- using Chrome to view the result, the dots have become quadratic dots 
too, and the labels show up as black beams - nothing can be reads

Is there a way to get the point labels exported to WebGL?

Many thanks in advance for any hint.

Wolfgang

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Dec  1 15:15:47 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 1 Dec 2014 15:15:47 +0100
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <20141130203722.1993f561c970a83d1ab8b384@inbox.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
Message-ID: <21628.30739.730844.340918@stat.math.ethz.ch>

Thank you for all the thoughts about alleviating these problems,
both to us and the "newbies" (or otherwise e-mail clueless subscribers).

>>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
>>>>>     on Sun, 30 Nov 2014 20:37:22 -0600 writes:

    > Following on Rich and Peter, is it practical for the list to put it at the top then, before the R-message?
    > Something like:

    > TO UNSUBSCRIBE from the list: see https://stat.ethz.ch/mailman/listinfo/r-help

Indeed, that is possible for mailman lists as I see.
It looks ugly to me but I have been brought up in the age where
civilized letters started (in English) with 'Dear ..' and
e-mails were electronic letters..  and that age has gone...

Shall we do that in spite of esthetic reasons? 
and keep the current footer?

Martin

    > And then continue on for each R message. Because top-posting has pretty much taken over, the best efforts of puritans notwithstanding, putting stuff at the bottom is unlikely to evoke much attention, and especially so in our 140-character-3-second attention-span world.

    > As an aside, if I were the OP, and wanted to unsubscribe, the volume of the e-mail messages on this topic alone would have been punishment enough for the original post:-)

    > Best wishes,
    > Ranjan


From jdnewmil at dcn.davis.CA.us  Mon Dec  1 15:31:14 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 1 Dec 2014 06:31:14 -0800
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <21628.30739.730844.340918@stat.math.ethz.ch>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
	<21628.30739.730844.340918@stat.math.ethz.ch>
Message-ID: <9A21E12A-E9E1-4583-B559-2970C8688A8A@dcn.davis.CA.us>

I disagree that this message belongs at the top... That is rare in bulk mail I receive, and seems unnecessarily intrusive. Addition of the word "Unsubscribe" to clarify the function of the link seems in line with current use.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 1, 2014 6:15:47 AM PST, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>Thank you for all the thoughts about alleviating these problems,
>both to us and the "newbies" (or otherwise e-mail clueless
>subscribers).
>
>>>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
>>>>>>     on Sun, 30 Nov 2014 20:37:22 -0600 writes:
>
>> Following on Rich and Peter, is it practical for the list to put it
>at the top then, before the R-message?
>    > Something like:
>
>> TO UNSUBSCRIBE from the list: see
>https://stat.ethz.ch/mailman/listinfo/r-help
>
>Indeed, that is possible for mailman lists as I see.
>It looks ugly to me but I have been brought up in the age where
>civilized letters started (in English) with 'Dear ..' and
>e-mails were electronic letters..  and that age has gone...
>
>Shall we do that in spite of esthetic reasons? 
>and keep the current footer?
>
>Martin
>
>> And then continue on for each R message. Because top-posting has
>pretty much taken over, the best efforts of puritans notwithstanding,
>putting stuff at the bottom is unlikely to evoke much attention, and
>especially so in our 140-character-3-second attention-span world.
>
>> As an aside, if I were the OP, and wanted to unsubscribe, the volume
>of the e-mail messages on this topic alone would have been punishment
>enough for the original post:-)
>
>    > Best wishes,
>    > Ranjan
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Dec  1 15:31:19 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 01 Dec 2014 09:31:19 -0500
Subject: [R] rgl WebGL export
In-Reply-To: <547C3429.10802@numberland.de>
References: <547C3429.10802@numberland.de>
Message-ID: <547C7BB7.40007@gmail.com>

On 01/12/2014 4:26 AM, rhelp at numberland.de wrote:
> Dear List members,
>
> I would be glad to get some tips on the following topic.
>
> I use rgl package to generate a 3D-cube with labeled dots at certain
> coordinates. After that I try to export the scene as a WebGL
> application. For this I use the syntax from rgl documentation
> "writeWebGL" mentioned in the example - page 94.
>
> In principle this works, but:
>
> - using Firefox to view the result, the dots have become quadratic dots,
> and the labels don?t show (i. e. there are only unlabeled dots)
> - using Chrome to view the result, the dots have become quadratic dots
> too, and the labels show up as black beams - nothing can be reads
>
> Is there a way to get the point labels exported to WebGL?
>
> Many thanks in advance for any hint.

I don't know what "quadratic dots" are, but I'd suggest that you try the 
version from R-forge.  It has some bug fixes, but it will still be a few 
days or weeks before it makes it to CRAN.  If you still don't get what 
you want, then please put together a simple example and send it to me, 
explaining what you want, and what you see, and I'll try to fix it if 
it's an rgl problem.

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Dec  1 15:34:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 1 Dec 2014 09:34:51 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <21628.30739.730844.340918@stat.math.ethz.ch>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>	<547A7D73.3030107@auckland.ac.nz>
	<547A87CF.2060305@gmail.com>	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>	<547B35CE.808@gmail.com>	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>	<alpine.LNX.2.11.1411301224370.28168@localhost>	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
	<21628.30739.730844.340918@stat.math.ethz.ch>
Message-ID: <547C7C8B.8080403@gmail.com>

On 01/12/2014 9:15 AM, Martin Maechler wrote:
> Thank you for all the thoughts about alleviating these problems,
> both to us and the "newbies" (or otherwise e-mail clueless subscribers).
>
> >>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
> >>>>>     on Sun, 30 Nov 2014 20:37:22 -0600 writes:
>
>      > Following on Rich and Peter, is it practical for the list to put it at the top then, before the R-message?
>      > Something like:
>
>      > TO UNSUBSCRIBE from the list: see https://stat.ethz.ch/mailman/listinfo/r-help
>
> Indeed, that is possible for mailman lists as I see.
> It looks ugly to me but I have been brought up in the age where
> civilized letters started (in English) with 'Dear ..' and
> e-mails were electronic letters..  and that age has gone...
>
> Shall we do that in spite of esthetic reasons?
> and keep the current footer?

Please don't put something at the top of the message.   I don't care if 
you add an extra line at the bottom (even if you YELL), but I often 
browse in a fairly small window, and I'd like to see what's at the top.

Duncan Murdoch
>
> Martin
>
>      > And then continue on for each R message. Because top-posting has pretty much taken over, the best efforts of puritans notwithstanding, putting stuff at the bottom is unlikely to evoke much attention, and especially so in our 140-character-3-second attention-span world.
>
>      > As an aside, if I were the OP, and wanted to unsubscribe, the volume of the e-mail messages on this topic alone would have been punishment enough for the original post:-)
>
>      > Best wishes,
>      > Ranjan
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From JSorkin at grecc.umaryland.edu  Mon Dec  1 15:39:55 2014
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 1 Dec 2014 09:39:55 -0500
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <9A21E12A-E9E1-4583-B559-2970C8688A8A@dcn.davis.CA.us>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
	<21628.30739.730844.340918@stat.math.ethz.ch>
	<9A21E12A-E9E1-4583-B559-2970C8688A8A@dcn.davis.CA.us>
Message-ID: <547C376B020000CB0011BF0C@smtp.medicine.umaryland.edu>

Can the Gods of the mailing list please end this long email thread? All that needs to be done is to add an unsubscribe link to messages sent by the server. If this is technically feasible, please do it. If it is not let us know so we can get on to other issues!
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Jeff Newmiller <jdnewmil at dcn.davis.ca.us> 12/01/14 9:31 AM >>>
I disagree that this message belongs at the top... That is rare in bulk mail I receive, and seems unnecessarily intrusive. Addition of the word "Unsubscribe" to clarify the function of the link seems in line with current use.
---------------------------------------------------------------------------
Jeff Newmiller The ..... ..... Go Live...
DCN:<jdnewmil at dcn.davis.ca.us> Basics: ##.#. ##.#. Live Go...
 Live: OO#.. Dead: OO#.. Playing
Research Engineer (Solar/Batteries O.O#. #.O#. with
/Software/Embedded Controllers) .OO#. .OO#. rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On December 1, 2014 6:15:47 AM PST, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>Thank you for all the thoughts about alleviating these problems,
>both to us and the "newbies" (or otherwise e-mail clueless
>subscribers).
>
>>>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
>>>>>> on Sun, 30 Nov 2014 20:37:22 -0600 writes:
>
>> Following on Rich and Peter, is it practical for the list to put it
>at the top then, before the R-message?
> > Something like:
>
>> TO UNSUBSCRIBE from the list: see
>https://stat.ethz.ch/mailman/listinfo/r-help
>
>Indeed, that is possible for mailman lists as I see.
>It looks ugly to me but I have been brought up in the age where
>civilized letters started (in English) with 'Dear ..' and
>e-mails were electronic letters.. and that age has gone...
>
>Shall we do that in spite of esthetic reasons? 
>and keep the current footer?
>
>Martin
>
>> And then continue on for each R message. Because top-posting has
>pretty much taken over, the best efforts of puritans notwithstanding,
>putting stuff at the bottom is unlikely to evoke much attention, and
>especially so in our 140-character-3-second attention-span world.
>
>> As an aside, if I were the OP, and wanted to unsubscribe, the volume
>of the e-mail messages on this topic alone would have been punishment
>enough for the original post:-)
>
> > Best wishes,
> > Ranjan
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From maitra.mbox.ignored at inbox.com  Mon Dec  1 15:47:02 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Mon, 1 Dec 2014 08:47:02 -0600
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <9A21E12A-E9E1-4583-B559-2970C8688A8A@dcn.davis.CA.us>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
	<21628.30739.730844.340918@stat.math.ethz.ch>
	<9A21E12A-E9E1-4583-B559-2970C8688A8A@dcn.davis.CA.us>
Message-ID: <20141201084702.28116a9679e0e3de04da0c43@inbox.com>

Well, we can start with the footer and then see how many "unsubscribe" messages continue to come R-help's way. Then, if it is not making an appreciable difference, we can look into putting it in the top.

Btw, I have seen mailing list e-mails elsewhere with an unsubscribe line at the top. I don't see it as a big deal.

Best wishes,
Ranjan

On Mon, 1 Dec 2014 06:31:14 -0800 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I disagree that this message belongs at the top... That is rare in bulk mail I receive, and seems unnecessarily intrusive. Addition of the word "Unsubscribe" to clarify the function of the link seems in line with current use.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> On December 1, 2014 6:15:47 AM PST, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> >Thank you for all the thoughts about alleviating these problems,
> >both to us and the "newbies" (or otherwise e-mail clueless
> >subscribers).
> >
> >>>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
> >>>>>>     on Sun, 30 Nov 2014 20:37:22 -0600 writes:
> >
> >> Following on Rich and Peter, is it practical for the list to put it
> >at the top then, before the R-message?
> >    > Something like:
> >
> >> TO UNSUBSCRIBE from the list: see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >
> >Indeed, that is possible for mailman lists as I see.
> >It looks ugly to me but I have been brought up in the age where
> >civilized letters started (in English) with 'Dear ..' and
> >e-mails were electronic letters..  and that age has gone...
> >
> >Shall we do that in spite of esthetic reasons? 
> >and keep the current footer?
> >
> >Martin
> >
> >> And then continue on for each R message. Because top-posting has
> >pretty much taken over, the best efforts of puritans notwithstanding,
> >putting stuff at the bottom is unlikely to evoke much attention, and
> >especially so in our 140-character-3-second attention-span world.
> >
> >> As an aside, if I were the OP, and wanted to unsubscribe, the volume
> >of the e-mail messages on this topic alone would have been punishment
> >enough for the original post:-)
> >
> >    > Best wishes,
> >    > Ranjan
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From eautocorrelation at gmail.com  Mon Dec  1 14:34:20 2014
From: eautocorrelation at gmail.com (Daniel James)
Date: Mon, 1 Dec 2014 14:34:20 +0100
Subject: [R] Fwd: PLEASE HELP ON R-LANGUAGE
In-Reply-To: <CA+Uy=imqAzCah9347SjWnSWiedMXCK+mPb7qbbMuJxvZUWZV4w@mail.gmail.com>
References: <CA+Uy=imqAzCah9347SjWnSWiedMXCK+mPb7qbbMuJxvZUWZV4w@mail.gmail.com>
Message-ID: <CA+Uy=ikDWX2U=NcTJcrpRDPdhNA86Zd33+vDu2sXjcKvfHpc5w@mail.gmail.com>

Subject: PLEASE HELP ON R-LANGUAGE


I am writing my project on "The effect of Bootstrapping on Time Series
Data". My problem is how I will write r programme to run a non stationary
time series data. I am familia to r language already.
Please help me.

	[[alternative HTML version deleted]]


From roberta.boni01 at universitadipavia.it  Mon Dec  1 15:24:18 2014
From: roberta.boni01 at universitadipavia.it (=?UTF-8?Q?ROBERTA_BON=C3=8C?=)
Date: Mon, 1 Dec 2014 15:24:18 +0100
Subject: [R] mixtools
Message-ID: <CAADCDxkGcNC8EBV4fNQqoiNVroRGJyYR-uSFgrTCFmnZb=5fOQ@mail.gmail.com>

Dear all,

I am fitting data by the use of the normalizedEM algoritm in the mixtools
package, but I don't know if it is possible to obtain as output the
component (first or second) for each object.

Regards
Roberta Bon?

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Dec  1 16:58:49 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Mon, 1 Dec 2014 10:58:49 -0500
Subject: [R] Fwd: PLEASE HELP ON R-LANGUAGE
In-Reply-To: <CA+Uy=ikDWX2U=NcTJcrpRDPdhNA86Zd33+vDu2sXjcKvfHpc5w@mail.gmail.com>
References: <CA+Uy=imqAzCah9347SjWnSWiedMXCK+mPb7qbbMuJxvZUWZV4w@mail.gmail.com>
	<CA+Uy=ikDWX2U=NcTJcrpRDPdhNA86Zd33+vDu2sXjcKvfHpc5w@mail.gmail.com>
Message-ID: <41E963A4-1C8B-4C9D-9723-0D039156AE37@utoronto.ca>

Daniel -

a simple Google search for "r programme to run a non stationary time series data" turns up a large number of relevant hits, including a task view. What have you tried that did not work for you?

B.


On Dec 1, 2014, at 8:34 AM, Daniel James <eautocorrelation at gmail.com> wrote:

> Subject: PLEASE HELP ON R-LANGUAGE
> 
> 
> I am writing my project on "The effect of Bootstrapping on Time Series
> Data". My problem is how I will write r programme to run a non stationary
> time series data. I am familia to r language already.
> Please help me.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Dec  1 17:02:37 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 1 Dec 2014 16:02:37 +0000
Subject: [R] Fwd: PLEASE HELP ON R-LANGUAGE
In-Reply-To: <CA+Uy=ikDWX2U=NcTJcrpRDPdhNA86Zd33+vDu2sXjcKvfHpc5w@mail.gmail.com>
References: <CA+Uy=imqAzCah9347SjWnSWiedMXCK+mPb7qbbMuJxvZUWZV4w@mail.gmail.com>
	<CA+Uy=ikDWX2U=NcTJcrpRDPdhNA86Zd33+vDu2sXjcKvfHpc5w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF07A0@SRVEXCHMBX.precheza.cz>

Hm. What do you meen by

"to run a non stationary time series data"

http://cran.r-project.org/web/views/TimeSeries.html

lead you to some packages for testing stationarity.

Did you check them?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Daniel
> James
> Sent: Monday, December 01, 2014 2:34 PM
> To: R-help at r-project.org
> Subject: [R] Fwd: PLEASE HELP ON R-LANGUAGE
>
> Subject: PLEASE HELP ON R-LANGUAGE
>
>
> I am writing my project on "The effect of Bootstrapping on Time Series
> Data". My problem is how I will write r programme to run a non
> stationary time series data. I am familia to r language already.
> Please help me.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From maechler at stat.math.ethz.ch  Mon Dec  1 17:35:30 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 1 Dec 2014 17:35:30 +0100
Subject: [R] please please unsubscribe!!!!!!!!!!!!!!!!
In-Reply-To: <20141201084702.28116a9679e0e3de04da0c43@inbox.com>
References: <CAFh18f22H7bqTdC_xu6aw83ekGEdpw-V5+AgZuWY4fASNt=Rfw@mail.gmail.com>
	<547A19EE020000CB0011BDF0@smtp.medicine.umaryland.edu>
	<84FBE77F-A67D-496B-8325-A6B974057145@dcn.davis.CA.us>
	<547A2994020000CB0011BDF6@smtp.medicine.umaryland.edu>
	<547A7D73.3030107@auckland.ac.nz> <547A87CF.2060305@gmail.com>
	<20141130083055.91e407890b5ba2f95c2e8155@inbox.com>
	<CAAu8QF7iZQXTExzU8Prm7eAGmMLxcSeYSJiS3mK9sszcz_y-4A@mail.gmail.com>
	<547B35CE.808@gmail.com>
	<CAAu8QF4ARZpcSp1MOiTehronuZhw83jwApLYqqPhYUbY=wOtdg@mail.gmail.com>
	<3846A2D0-2FB4-42E2-B97C-562A0A53EF08@gmail.com>
	<alpine.LNX.2.11.1411301224370.28168@localhost>
	<20141130203722.1993f561c970a83d1ab8b384@inbox.com>
	<21628.30739.730844.340918@stat.math.ethz.ch>
	<9A21E12A-E9E1-4583-B559-2970C8688A8A@dcn.davis.CA.us>
	<20141201084702.28116a9679e0e3de04da0c43@inbox.com>
Message-ID: <21628.39122.500841.812063@stat.math.ethz.ch>

>>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
>>>>>     on Mon, 1 Dec 2014 08:47:02 -0600 writes:

    > Well, we can start with the footer and then see how many "unsubscribe" messages continue to come R-help's way. Then, if it is not making an appreciable difference, we can look into putting it in the top.
    > Btw, I have seen mailing list e-mails elsewhere with an unsubscribe line at the top. I don't see it as a big deal.

    > Best wishes,
    > Ranjan

Ok,... I think I --- and 99.9% of all other readers have had
enough input about this:

Decision:  
 - No header
 - We replace in the footer the first of the 4 text lines

from
   R-help at r-project.org mailing list

to
   R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

Martin Maechler, ETH Zurich  (and R core team).


    > On Mon, 1 Dec 2014 06:31:14 -0800 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

    >> I disagree that this message belongs at the top... That is rare in bulk mail I receive, and seems unnecessarily intrusive. Addition of the word "Unsubscribe" to clarify the function of the link seems in line with current use.
    >> ---------------------------------------------------------------------------
    >> Jeff Newmiller                        The     .....       .....  Go Live...
    >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
    >> Live:   OO#.. Dead: OO#..  Playing
    >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
    >> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
    >> ---------------------------------------------------------------------------
    >> Sent from my phone. Please excuse my brevity.
    >> 
    >> On December 1, 2014 6:15:47 AM PST, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
    >> >Thank you for all the thoughts about alleviating these problems,
    >> >both to us and the "newbies" (or otherwise e-mail clueless
    >> >subscribers).
    >> >
    >> >>>>>> Ranjan Maitra <maitra.mbox.ignored at inbox.com>
    >> >>>>>>     on Sun, 30 Nov 2014 20:37:22 -0600 writes:
    >> >
    >> >> Following on Rich and Peter, is it practical for the list to put it
    >> >at the top then, before the R-message?
    >> >    > Something like:
    >> >
    >> >> TO UNSUBSCRIBE from the list: see
    >> >https://stat.ethz.ch/mailman/listinfo/r-help
    >> >
    >> >Indeed, that is possible for mailman lists as I see.
    >> >It looks ugly to me but I have been brought up in the age where
    >> >civilized letters started (in English) with 'Dear ..' and
    >> >e-mails were electronic letters..  and that age has gone...
    >> >
    >> >Shall we do that in spite of esthetic reasons? 
    >> >and keep the current footer?
    >> >
    >> >Martin
    >> >
    >> >> And then continue on for each R message. Because top-posting has
    >> >pretty much taken over, the best efforts of puritans notwithstanding,
    >> >putting stuff at the bottom is unlikely to evoke much attention, and
    >> >especially so in our 140-character-3-second attention-span world.
    >> >
    >> >> As an aside, if I were the OP, and wanted to unsubscribe, the volume
    >> >of the e-mail messages on this topic alone would have been punishment
    >> >enough for the original post:-)
    >> >
    >> >    > Best wishes,
    >> >    > Ranjan
    >> >
    >> >______________________________________________
    >> >R-help at r-project.org mailing list
    >> >https://stat.ethz.ch/mailman/listinfo/r-help
    >> >PLEASE do read the posting guide
    >> >http://www.R-project.org/posting-guide.html
    >> >and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 


    > -- 
    > Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

    > ____________________________________________________________
    > Receive Notifications of Incoming Messages
    > Easily monitor multiple email accounts & access them with a click.
    > Visit http://www.inbox.com/notifier and check it out!

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From trichter at uni-bremen.de  Mon Dec  1 17:47:39 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Mon, 01 Dec 2014 17:47:39 +0100
Subject: [R] Creating submatrices from a dataframe,
 depending on factors in sample names
Message-ID: <547C9BAB.5080408@uni-bremen.de>

Hello there,

this is a cross-post of a stack-overflow question, which wasnt answered, 
but is very important for my work. Apologies for breaking any rules, but 
i do hope for some help from the list instead:

I have a huge matrix of pairwise similarity percentages between 
different samples. The samples are belonging to groups. The groups are 
determined by the suffix "_n" in the row.names/header names.
In the first step, i wanted to create submatrices consisting of all 
pairs within single groups (i.e. for all samples from "_1").
However, I realized that i need to know all pairwise submatrices, 
between all combination of groups. So, i want to create (a list of) 
vectors that are named "_n1 vs _n2" (or similar) for all combinations of 
n, as illustrated by the colored rectangulars:

http://i.stack.imgur.com/XMkxj.png

Reproducible code, as provided by helpful Stack Overflow members, 
dealing with identical "_n"s.


         df <- structure(list(HQ673618_1 = c(NA, 90.8, 89.8, 89.6, 89.8, 
88.9,
         87.8, 88.2, 88.3), HQ674317_1 = c(90.8, NA, 98.6, 97.7, 98.4,
         97.4, 94.9, 96.2, 95.1), EU686630_1 = c(89.8, 98.6, NA, 98.4,
         98.9, 97.7, 95.4, 96.4, 95.8), EU686593_2 = c(89.6, 97.7, 98.4,
         NA, 98.1, 96.8, 94.4, 95.6, 94.8), JN166322_2 = c(89.8, 98.4,
         98.9, 98.1, NA, 97.5, 95.3, 96.5, 95.9), EU491340_2 = c(88.9,
         97.4, 97.7, 96.8, 97.5, NA, 96.5, 97.7, 96), AB694259_3 = c(87.8,
         94.9, 95.4, 94.4, 95.3, 96.5, NA, 98.3, 95.9), AB694258_3 = 
c(88.2,
         96.2, 96.4, 95.6, 96.5, 97.7, 98.3, NA, 95.8), AB694462_3 = 
c(88.3,
         95.1, 95.8, 94.8, 95.9, 96, 95.9, 95.8, NA)), .Names = 
c("HQ673618_1",
         "HQ674317_1", "EU686630_1", "EU686593_2", "JN166322_2", 
"EU491340_2",
         "AB694259_3", "AB694258_3", "AB694462_3"), class = 
"data.frame", row.names = c("HQ673618_1",
         "HQ674317_1", "EU686630_1", "EU686593_2", "JN166322_2", 
"EU491340_2",
         "AB694259_3", "AB694258_3", "AB694462_3"))


         indx <- gsub(".*_", "", names(df))
         sub.matrices <- lapply(unique(indx), function(x) {
           temp <- which(indx %in% x)
           df[temp, temp]
         })
         unique_values <- lapply(sub.matrices, function(x) x[upper.tri(x)])
         names(unique_values) <- unique(indx)

This code needs to be expanded to form sub.matrices for any combination 
of unique indices in temp.


Thank you so much!




-- 
Tim Richter-Heitmann (M.Sc.)
PhD Candidate



International Max-Planck Research School for Marine Microbiology
University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


From denizagirdan at gmail.com  Mon Dec  1 17:37:34 2014
From: denizagirdan at gmail.com (=?UTF-8?B?RGVuaXogQcSfxLFyZGFu?=)
Date: Mon, 1 Dec 2014 18:37:34 +0200
Subject: [R] R source scripts
Message-ID: <CAMP2mC=XEfq5=qdohJB-M4SjjCaBOZcEk6yg=abBCqFQdZ07HA@mail.gmail.com>

Dear R Team,

I have problem about finding R source scripts. I need script of
kmeans(stats) function. I would be grateful, if you helped me.

I am looking forward to hearing from you.

Yours sincerely,

Deniz Agirdan

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Dec  1 18:28:31 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 1 Dec 2014 12:28:31 -0500
Subject: [R] R source scripts
In-Reply-To: <CAMP2mC=XEfq5=qdohJB-M4SjjCaBOZcEk6yg=abBCqFQdZ07HA@mail.gmail.com>
References: <CAMP2mC=XEfq5=qdohJB-M4SjjCaBOZcEk6yg=abBCqFQdZ07HA@mail.gmail.com>
Message-ID: <CAM_vju=DmjpnJ57DJPd=7yDrix+O7P51i+RUx6VPFZpvwF5iSw@mail.gmail.com>

Hi,

On Mon, Dec 1, 2014 at 11:37 AM, Deniz A??rdan <denizagirdan at gmail.com> wrote:
> Dear R Team,
>
> I have problem about finding R source scripts. I need script of
> kmeans(stats) function. I would be grateful, if you helped me.

I assume you mean the source code rather than a script using that
function. Google is your friend, for instance:

http://stackoverflow.com/questions/19226816/how-can-i-view-the-source-code-for-a-function


Briefly, typing the name of the function at the R prompt will often
get you the code:

kmeans.

Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From pdalgd at gmail.com  Mon Dec  1 18:33:05 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Dec 2014 18:33:05 +0100
Subject: [R] R source scripts
In-Reply-To: <CAMP2mC=XEfq5=qdohJB-M4SjjCaBOZcEk6yg=abBCqFQdZ07HA@mail.gmail.com>
References: <CAMP2mC=XEfq5=qdohJB-M4SjjCaBOZcEk6yg=abBCqFQdZ07HA@mail.gmail.com>
Message-ID: <B5E2602A-E6AC-4D21-909A-A2ACE7796E0D@gmail.com>


> On 01 Dec 2014, at 17:37 , Deniz A??rdan <denizagirdan at gmail.com> wrote:
> 
> Dear R Team,
> 
> I have problem about finding R source scripts. I need script of
> kmeans(stats) function. I would be grateful, if you helped me.
> 
> I am looking forward to hearing from you.
> 

@article{Rnews:Ligges:2006
,
  author = {Uwe Ligges},
  title = {{R} {H}elp {D}esk: {Accessing} the Sources},
  journal = {R News},
  year = 2006,
  volume = 6,
  number = 4,
  pages = {43--45},
  month = {October},
  url = {
http://CRAN.R-project.org/doc/Rnews/
},
  pdf = {
http://CRAN.R-project.org/doc/Rnews/Rnews_2006-4.pdf
}
}




> Yours sincerely,
> 
> Deniz Agirdan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Mon Dec  1 18:46:03 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 1 Dec 2014 09:46:03 -0800
Subject: [R] Creating submatrices from a dataframe,
 depending on factors in sample names
In-Reply-To: <547C9BAB.5080408@uni-bremen.de>
References: <547C9BAB.5080408@uni-bremen.de>
Message-ID: <CACk-te0yLT=wxHpG-_r-OTx+OYYPV9iPf1LNovmFxhJRL=_8OA@mail.gmail.com>

I do not have the patience to study your request carefully, but does
the following help?

> a <- 1:3
> x <- outer(a,a,paste,sep=".")
> x
     [,1]  [,2]  [,3]
[1,] "1.1" "1.2" "1.3"
[2,] "2.1" "2.2" "2.3"
[3,] "3.1" "3.2" "3.3"
> x[upper.tri(x)]
[1] "1.2" "1.3" "2.3"

> x[upper.tri(x,diag=TRUE)]
[1] "1.1" "1.2" "2.2" "1.3" "2.3" "3.3"

This gives you a vector all possible pairs (including identical pairs
or not) of values of a, which you could then loop over as an index to
do what you want, I think.

If this is not what you want, just ignore without replying.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Dec 1, 2014 at 8:47 AM, Tim Richter-Heitmann
<trichter at uni-bremen.de> wrote:
> Hello there,
>
> this is a cross-post of a stack-overflow question, which wasnt answered, but
> is very important for my work. Apologies for breaking any rules, but i do
> hope for some help from the list instead:
>
> I have a huge matrix of pairwise similarity percentages between different
> samples. The samples are belonging to groups. The groups are determined by
> the suffix "_n" in the row.names/header names.
> In the first step, i wanted to create submatrices consisting of all pairs
> within single groups (i.e. for all samples from "_1").
> However, I realized that i need to know all pairwise submatrices, between
> all combination of groups. So, i want to create (a list of) vectors that are
> named "_n1 vs _n2" (or similar) for all combinations of n, as illustrated by
> the colored rectangulars:
>
> http://i.stack.imgur.com/XMkxj.png
>
> Reproducible code, as provided by helpful Stack Overflow members, dealing
> with identical "_n"s.
>
>
>         df <- structure(list(HQ673618_1 = c(NA, 90.8, 89.8, 89.6, 89.8,
> 88.9,
>         87.8, 88.2, 88.3), HQ674317_1 = c(90.8, NA, 98.6, 97.7, 98.4,
>         97.4, 94.9, 96.2, 95.1), EU686630_1 = c(89.8, 98.6, NA, 98.4,
>         98.9, 97.7, 95.4, 96.4, 95.8), EU686593_2 = c(89.6, 97.7, 98.4,
>         NA, 98.1, 96.8, 94.4, 95.6, 94.8), JN166322_2 = c(89.8, 98.4,
>         98.9, 98.1, NA, 97.5, 95.3, 96.5, 95.9), EU491340_2 = c(88.9,
>         97.4, 97.7, 96.8, 97.5, NA, 96.5, 97.7, 96), AB694259_3 = c(87.8,
>         94.9, 95.4, 94.4, 95.3, 96.5, NA, 98.3, 95.9), AB694258_3 = c(88.2,
>         96.2, 96.4, 95.6, 96.5, 97.7, 98.3, NA, 95.8), AB694462_3 = c(88.3,
>         95.1, 95.8, 94.8, 95.9, 96, 95.9, 95.8, NA)), .Names =
> c("HQ673618_1",
>         "HQ674317_1", "EU686630_1", "EU686593_2", "JN166322_2",
> "EU491340_2",
>         "AB694259_3", "AB694258_3", "AB694462_3"), class = "data.frame",
> row.names = c("HQ673618_1",
>         "HQ674317_1", "EU686630_1", "EU686593_2", "JN166322_2",
> "EU491340_2",
>         "AB694259_3", "AB694258_3", "AB694462_3"))
>
>
>         indx <- gsub(".*_", "", names(df))
>         sub.matrices <- lapply(unique(indx), function(x) {
>           temp <- which(indx %in% x)
>           df[temp, temp]
>         })
>         unique_values <- lapply(sub.matrices, function(x) x[upper.tri(x)])
>         names(unique_values) <- unique(indx)
>
> This code needs to be expanded to form sub.matrices for any combination of
> unique indices in temp.
>
>
> Thank you so much!
>
>
>
>
> --
> Tim Richter-Heitmann (M.Sc.)
> PhD Candidate
>
>
>
> International Max-Planck Research School for Marine Microbiology
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Mon Dec  1 18:49:20 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 01 Dec 2014 17:49:20 +0000
Subject: [R] Cycling and different xerror values in cp of rpart,
 which result should I trust?...
In-Reply-To: <D0A1FACE.11DB3%lterlemez@anadolu.edu.tr>
References: <D0A1FACE.11DB3%lterlemez@anadolu.edu.tr>
Message-ID: <547CAA20.6030706@stats.ox.ac.uk>

Do see the posting guide, and do not re-post 
(https://stat.ethz.ch/pipermail/r-help/2014-November/423727.html).

I suspect I am not alone in not knowing what you are talking about (even 
though I am the rpart maintainer).  Please do try to explain clearly 
what you mean with the reproducible example asked for in the posting 
guide, and show us the output you get and want to understand.

And a hint: rpart cross-validation is random, so set a seed and include 
that in your 'reproducible example'.


On 01/12/2014 09:00, Levent TERLEMEZ wrote:
> Dear Users,
> Is it possible to get cycling and different xerror scores in cp of rpart while getting the same tree on every run (or am I missing something or understood wrong)? I build it with an old version of R in a Windows VM installed on a Intel based macbook and reuse the same codes with a newer version of R and required packages on an AMD pc installed with standalone Windows. Both Windows are 64bit, which result should I trust, the old one or new one, macbook or pc?
>
> Thanks in advanced,
> Levent TERLEMEZ.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do (and no HTML).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From bpro at post.cz  Mon Dec  1 19:05:07 2014
From: bpro at post.cz (bpro at post.cz)
Date: Mon, 01 Dec 2014 19:05:07 +0100 (CET)
Subject: [R] New book using R
Message-ID: <k3C.gDDW.7ZAYgWfwPjm.1KVAtJ@seznam.cz>


Dear Colleagues,
I have prepared a book to be published in Czech, ?Biostatistika pro l?ka?e, 
principy z?kladn?ch metod a jejich interpretace s vyu?it?m statistick?ho 
syst?mu R? ?(in English ?Biostatistics for physicians ? principles of basic 
methods and interpretation of results using the R statistical system?). 
Let me ask you two questions:

Can I use the logo of the R program?
Could you make reference to this book on your web pages?

Many thanks for answer, 

Bohumir Prochazka


============================================================================
===============================

Bohum?r Proch?zka: Biostatistika pro l?ka?e, principy z?kladn?ch metod a 
jejich
interpretace s vyu?it?m statistick?ho syst?mu R. ?(in Czech) Karolinum 
Press, publisher of Charles University, Prague 2015, ISBN
978-80-246-2782-3.

Annotation (in Czech):
Autor p?edstavuje matematickou statistiku a jej? mo?nosti jako n?stroje 
medic?ny zalo?en? na d?kazu. Text je soust?ed?n p?edev??m na popis princip? 
statistick?ho uva?ov?n? a interpretaci v?sledk?. V?nuje se i uk?zk?m 
proveden? anal?z a chybn? interpretace v?sledk?. D?le seznamuje i s 
mo?nostmi vyu?it? statistick?ho programu R, kter? je voln? dostupn? a nab?z?
pou?it? libovoln?ch statistick?ch n?stroj?. Kniha p?ekon?v? vzd?lenost mezi 
medic?nou a matematikou a hled? spole?n? jazyk, kter? poskytne medic?n? 
objektivn? n?stroje k hodnocen? biologick?ch dat. 


Bohum?r Proch?zka:Biostatistics for physicians ? principles of basic methods
and interpretation of results using the R statistical system? (in Czech) 
Karolinum Press, publisher of Charles University, Prague 2015, ISBN
978-80-246-2782-3.


Annotation (in English):
The author presents mathematical statistics and its potential as a tool in 
evidence-based medicine. He focuses primarily on the statistical principles 
and considerations as well as interpretation of results. Some illustrative 
examples are given of the errors in analyses and of results. Furthermore, 
the reader is familiarized with the usability of the R statistical program, 
free and available for anyone to use, offers multiple statistical tools. ?
This book overcomes the distance between medicine and mathematics in an 
attempt to find a common language that will provide the medical community 
with objective tools for the assessment of biological data.??




?


?
=
	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Dec  1 22:57:25 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 1 Dec 2014 21:57:25 +0000
Subject: [R] Creating submatrices from a dataframe,
 depending on factors in sample names
In-Reply-To: <CACk-te0yLT=wxHpG-_r-OTx+OYYPV9iPf1LNovmFxhJRL=_8OA@mail.gmail.com>
References: <547C9BAB.5080408@uni-bremen.de>
	<CACk-te0yLT=wxHpG-_r-OTx+OYYPV9iPf1LNovmFxhJRL=_8OA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FBC25E@mb02.ads.tamu.edu>

I may have misunderstood, but does this do what you want?

> df.mat <- as.matrix(df)
> same <- lapply(1:3, function(x) df.mat[grep(paste0("_", x), 
+ rownames(df.mat)), grep(paste0("_", x), colnames(df.mat))])
> same
[[1]]
           HQ673618_1 HQ674317_1 EU686630_1
HQ673618_1         NA       90.8       89.8
HQ674317_1       90.8         NA       98.6
EU686630_1       89.8       98.6         NA

[[2]]
           EU686593_2 JN166322_2 EU491340_2
EU686593_2         NA       98.1       96.8
JN166322_2       98.1         NA       97.5
EU491340_2       96.8       97.5         NA

[[3]]
           AB694259_3 AB694258_3 AB694462_3
AB694259_3         NA       98.3       95.9
AB694258_3       98.3         NA       95.8
AB694462_3       95.9       95.8         NA

> Diff <- as.matrix(expand.grid(1:3, 1:3))
> Diff <- Diff[Diff[,1]<Diff[,2],]
> different <- lapply(seq_len(nrow(Diff)), function(x) 
+ df.mat[grep(paste0("_", Diff[x,1]), rownames(df.mat)),
+ grep(paste0("_", Diff[x,2]), colnames(df.mat))])
> different
[[1]]
           EU686593_2 JN166322_2 EU491340_2
HQ673618_1       89.6       89.8       88.9
HQ674317_1       97.7       98.4       97.4
EU686630_1       98.4       98.9       97.7

[[2]]
           AB694259_3 AB694258_3 AB694462_3
HQ673618_1       87.8       88.2       88.3
HQ674317_1       94.9       96.2       95.1
EU686630_1       95.4       96.4       95.8

[[3]]
           AB694259_3 AB694258_3 AB694462_3
EU686593_2       94.4       95.6       94.8
JN166322_2       95.3       96.5       95.9
EU491340_2       96.5       97.7       96.0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Monday, December 1, 2014 11:46 AM
To: Tim Richter-Heitmann
Cc: r-help at r-project.org
Subject: Re: [R] Creating submatrices from a dataframe, depending on factors in sample names

I do not have the patience to study your request carefully, but does
the following help?

> a <- 1:3
> x <- outer(a,a,paste,sep=".")
> x
     [,1]  [,2]  [,3]
[1,] "1.1" "1.2" "1.3"
[2,] "2.1" "2.2" "2.3"
[3,] "3.1" "3.2" "3.3"
> x[upper.tri(x)]
[1] "1.2" "1.3" "2.3"

> x[upper.tri(x,diag=TRUE)]
[1] "1.1" "1.2" "2.2" "1.3" "2.3" "3.3"

This gives you a vector all possible pairs (including identical pairs
or not) of values of a, which you could then loop over as an index to
do what you want, I think.

If this is not what you want, just ignore without replying.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Dec 1, 2014 at 8:47 AM, Tim Richter-Heitmann
<trichter at uni-bremen.de> wrote:
> Hello there,
>
> this is a cross-post of a stack-overflow question, which wasnt answered, but
> is very important for my work. Apologies for breaking any rules, but i do
> hope for some help from the list instead:
>
> I have a huge matrix of pairwise similarity percentages between different
> samples. The samples are belonging to groups. The groups are determined by
> the suffix "_n" in the row.names/header names.
> In the first step, i wanted to create submatrices consisting of all pairs
> within single groups (i.e. for all samples from "_1").
> However, I realized that i need to know all pairwise submatrices, between
> all combination of groups. So, i want to create (a list of) vectors that are
> named "_n1 vs _n2" (or similar) for all combinations of n, as illustrated by
> the colored rectangulars:
>
> http://i.stack.imgur.com/XMkxj.png
>
> Reproducible code, as provided by helpful Stack Overflow members, dealing
> with identical "_n"s.
>
>
>         df <- structure(list(HQ673618_1 = c(NA, 90.8, 89.8, 89.6, 89.8,
> 88.9,
>         87.8, 88.2, 88.3), HQ674317_1 = c(90.8, NA, 98.6, 97.7, 98.4,
>         97.4, 94.9, 96.2, 95.1), EU686630_1 = c(89.8, 98.6, NA, 98.4,
>         98.9, 97.7, 95.4, 96.4, 95.8), EU686593_2 = c(89.6, 97.7, 98.4,
>         NA, 98.1, 96.8, 94.4, 95.6, 94.8), JN166322_2 = c(89.8, 98.4,
>         98.9, 98.1, NA, 97.5, 95.3, 96.5, 95.9), EU491340_2 = c(88.9,
>         97.4, 97.7, 96.8, 97.5, NA, 96.5, 97.7, 96), AB694259_3 = c(87.8,
>         94.9, 95.4, 94.4, 95.3, 96.5, NA, 98.3, 95.9), AB694258_3 = c(88.2,
>         96.2, 96.4, 95.6, 96.5, 97.7, 98.3, NA, 95.8), AB694462_3 = c(88.3,
>         95.1, 95.8, 94.8, 95.9, 96, 95.9, 95.8, NA)), .Names =
> c("HQ673618_1",
>         "HQ674317_1", "EU686630_1", "EU686593_2", "JN166322_2",
> "EU491340_2",
>         "AB694259_3", "AB694258_3", "AB694462_3"), class = "data.frame",
> row.names = c("HQ673618_1",
>         "HQ674317_1", "EU686630_1", "EU686593_2", "JN166322_2",
> "EU491340_2",
>         "AB694259_3", "AB694258_3", "AB694462_3"))
>
>
>         indx <- gsub(".*_", "", names(df))
>         sub.matrices <- lapply(unique(indx), function(x) {
>           temp <- which(indx %in% x)
>           df[temp, temp]
>         })
>         unique_values <- lapply(sub.matrices, function(x) x[upper.tri(x)])
>         names(unique_values) <- unique(indx)
>
> This code needs to be expanded to form sub.matrices for any combination of
> unique indices in temp.
>
>
> Thank you so much!
>
>
>
>
> --
> Tim Richter-Heitmann (M.Sc.)
> PhD Candidate
>
>
>
> International Max-Planck Research School for Marine Microbiology
> University of Bremen
> Microbial Ecophysiology Group (AG Friedrich)
> FB02 - Biologie/Chemie
> Leobener Stra?e (NW2 A2130)
> D-28359 Bremen
> Tel.: 0049(0)421 218-63062
> Fax: 0049(0)421 218-63069
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From dulcalma at bigpond.com  Tue Dec  2 00:44:50 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 2 Dec 2014 09:44:50 +1000
Subject: [R] Remove the border/frame in a dotplot()
In-Reply-To: <CAGx1TMDKjNEdqPz=U7cOK3oRGLi2kb1fpOaUSt1ZUVYi=zKj_A@mail.gmail.com>
References: <1915414038.2620031.1417298354946.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
	<CAGx1TMDKjNEdqPz=U7cOK3oRGLi2kb1fpOaUSt1ZUVYi=zKj_A@mail.gmail.com>
Message-ID: <000601d00dc0$cd771600$68654200$@bigpond.com>

Hi 

See also 
https://stat.ethz.ch/pipermail/r-help/2007-September/140098.html

This may do

library(grid)

dotplot(~ 1:10, scales = list(col = "black", tck = c(1, 0)),
       par.settings = list(axis.line = list(col = "transparent")),
       axis = function(side, ...) {
           if (side == "left")
                grid.lines(x = c(0, 0), y = c(0, 1),  default.units = "npc")
           else if (side == "bottom")
                grid.lines(x = c(0, 1), y = c(0, 0),   default.units = "npc")
           axis.default(side = side, ...)
       })

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Richard M. Heiberger
Sent: Monday, 1 December 2014 03:01
To: st?phanie braun
Cc: r-help at r-project.org
Subject: Re: [R] Remove the border/frame in a dotplot()

st?phanie,

I believe you need all of this.  Look at it with a good editor and in
a monowidth font such
as courier to see the structure.

Rich

library(lattice)
library(latticeExtra)
dotplot(~ 1:10,
        par.settings=list(
          axis.line=list(col="transparent"),
          clip=list(panel=FALSE))) +
            layer({panel.axis(side="bottom", line.col="black", outside=TRUE);
                   panel.abline(h=current.panel.limits()$ylim[1],
                                v=current.panel.limits()$xlim[1])})

On Sat, Nov 29, 2014 at 4:59 PM, st?phanie braun <r-help at r-project.org> wrote:
> Dear listmembersI wouldlike to remove in a dotplot() the border/frame from the figure and only keepthe x- and y-axis. I can?t find a way to do this. bty="n" does notwork. Can somebody help? I include the r coding for my figure below. dotplot(plant_species ~ mean, data =botany,            aspect= 1.5,            scales=list(x=list(tck=c(-1,0)),y = list(tck=c(-1,0))),            ylab= "Plant species",            xlim= c(-1.1, 1.1),            xlab= "Electivity index",prepanel = NULL,            panel= function (x, y) {            panel.abline(v=0)            panel.xyplot(x,y, pch = 16, col = "black")            panel.segments(botany$lower,as.numeric(y),            botany$upper,as.numeric(y), lty = 1, col = "black")}
>
> Thank you!St?phanie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rafa_moral2004 at yahoo.com.br  Tue Dec  2 02:51:59 2014
From: rafa_moral2004 at yahoo.com.br (Rafael Moral)
Date: Tue, 2 Dec 2014 01:51:59 +0000 (UTC)
Subject: [R] hierarchical model with heteroscedastic variances
Message-ID: <1583138195.836808.1417485119900.JavaMail.yahoo@jws10707.mail.gq1.yahoo.com>

Dear useRs,I have been wondering whether it would be possible to fit a linear mixed model including heteroscedastic variances for a 2-level hierarchical study with subsampling.Suppose that I had three levels for the first hierarchical level and 4 for the second, with 2 subsamples, e.g.
set.seed(2014)y <- rnorm(24, 20, 2)level1 <- gl(3, 8)level2 <- gl(4, 2)my.data <- data.frame(y, level1, level2)
Then, I can easily fit a model with nested random effects, i.e.
y_{ijk} = \mu + \alpha_i + \beta_{ij} + \epsilon_{ijk}
with \alpha_i ~ N(0, \sigma^2_1) the random effect for level 1, \beta_{ij} ~ N(0, \sigma^2_2) the random effect for level 2 and \epsilon_{ijk} ~ N(0, sigma^2) the error,
using the following code
require(nlme)fit1 <- lme(y ~ 1, random=~1|level1/level2, my.data)
# which is equivalent tofit1 <- lme(y ~ 1, random=list(level1=pdDiag(~1), level2=pdDiag(~1)), my.data)
However, I would like to have different variances per each "level1" level (model i) and then a different model considering different variances per each "level1" and per each "level2" level within "level1" (model ii).So we would have
Model (i):\alpha_i ~ N(0, \sigma^2_1_i), \beta_{ij} ~ N(0, \sigma^2_2) and \epsilon_{ijk} ~ N(0, sigma^2),
that is, different sigma^2_1 per "level1" level
Model (ii):\alpha_i ~ N(0, \sigma^2_1_i), \beta_{ij} ~ N(0, \sigma^2_2_{ij}) and \epsilon_{ijk} ~ N(0, sigma^2),
that is, different sigma^2_1 per "level1" level and different sigma^2_2 per "level1:level2" level combination
I tried the following for model (i):
fit2 <- lme(y ~ 1, random=list(level1=pdDiag(~level1)), my.data)
and this for model (ii):
fit3 <- lme(y ~ 1, random=list(level1=pdDiag(~level1), level2=pdDiag(~level1:level2)), my.data)
This second fit also gives a warning, and I don't believe that these are doing what I intend to.I also tried using the weights argument, i.e., for model (i)
fit2.2 <- lme(y ~ 1, random=~1|level1/level2, weights=varIdent(form=~1|level1), my.data)
Perhaps this is closer to what I'm trying to do, but when it comes to model (ii) I can't properly work the syntax, as the "/" creates an error, so I tried
fit2.3 <- lme(y ~ 1, random=~1|level1/level2, weights=varIdent(form=~1|level1*level2), my.data)

but I'm still doubtful.
Any suggestions on how I might be able to fit these models?
Best wishes,Rafael.
	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue Dec  2 08:42:25 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 2 Dec 2014 01:42:25 -0600
Subject: [R] hierarchical model with heteroscedastic variances
In-Reply-To: <1583138195.836808.1417485119900.JavaMail.yahoo@jws10707.mail.gq1.yahoo.com>
References: <1583138195.836808.1417485119900.JavaMail.yahoo@jws10707.mail.gq1.yahoo.com>
Message-ID: <CAAJSdjjcfSh2Lzycm9AD-YK3fsSOt6bLy74jUFZM0gj1XZCoqA@mail.gmail.com>

Please repost your message in plain text. On my gmail account, it was
totally unreadable due to the fact that the forum software strips out all
the HTML "stuff".

On Mon, Dec 1, 2014 at 7:51 PM, Rafael Moral <rafa_moral2004 at yahoo.com.br>
wrote:

> Dear useRs,I have been wondering whether it would be possible to fit a
> linear mixed model including heteroscedastic variances for a 2-level
> hierarchical study with subsampling.Suppose that I had three levels for the
> first hierarchical level and 4 for the second, with 2 subsamples, e.g.
> set.seed(2014)y <- rnorm(24, 20, 2)level1 <- gl(3, 8)level2 <- gl(4,
> 2)my.data <- data.frame(y, level1, level2)
> Then, I can easily fit a model with nested random effects, i.e.
> y_{ijk} = \mu + \alpha_i + \beta_{ij} + \epsilon_{ijk}
> with \alpha_i ~ N(0, \sigma^2_1) the random effect for level 1, \beta_{ij}
> ~ N(0, \sigma^2_2) the random effect for level 2 and \epsilon_{ijk} ~ N(0,
> sigma^2) the error,
> using the following code
> require(nlme)fit1 <- lme(y ~ 1, random=~1|level1/level2, my.data)
> # which is equivalent tofit1 <- lme(y ~ 1, random=list(level1=pdDiag(~1),
> level2=pdDiag(~1)), my.data)
> However, I would like to have different variances per each "level1" level
> (model i) and then a different model considering different variances per
> each "level1" and per each "level2" level within "level1" (model ii).So we
> would have
> Model (i):\alpha_i ~ N(0, \sigma^2_1_i), \beta_{ij} ~ N(0, \sigma^2_2) and
> \epsilon_{ijk} ~ N(0, sigma^2),
> that is, different sigma^2_1 per "level1" level
> Model (ii):\alpha_i ~ N(0, \sigma^2_1_i), \beta_{ij} ~ N(0,
> \sigma^2_2_{ij}) and \epsilon_{ijk} ~ N(0, sigma^2),
> that is, different sigma^2_1 per "level1" level and different sigma^2_2
> per "level1:level2" level combination
> I tried the following for model (i):
> fit2 <- lme(y ~ 1, random=list(level1=pdDiag(~level1)), my.data)
> and this for model (ii):
> fit3 <- lme(y ~ 1, random=list(level1=pdDiag(~level1),
> level2=pdDiag(~level1:level2)), my.data)
> This second fit also gives a warning, and I don't believe that these are
> doing what I intend to.I also tried using the weights argument, i.e., for
> model (i)
> fit2.2 <- lme(y ~ 1, random=~1|level1/level2,
> weights=varIdent(form=~1|level1), my.data)
> Perhaps this is closer to what I'm trying to do, but when it comes to
> model (ii) I can't properly work the syntax, as the "/" creates an error,
> so I tried
> fit2.3 <- lme(y ~ 1, random=~1|level1/level2,
> weights=varIdent(form=~1|level1*level2), my.data)
>
> but I'm still doubtful.
> Any suggestions on how I might be able to fit these models?
> Best wishes,Rafael.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Tue Dec  2 09:28:08 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 2 Dec 2014 09:28:08 +0100
Subject: [R] function to avoid <<-
Message-ID: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>

Dear All,

I am writing a GUIpackage that needs global variables.
I had many warning message when I checked the code as for example:
geteSet: no visible binding for global variable ?curselectCases?
I would like to write a function that creates a global place for Objects to
be loaded as:


Fun <- function(){

Object <- 5

Var2Global <- function(Object){
.myDataEnv <- new.env(parent=emptyenv()) # not exported
isLoaded <- function(Object) {
    exists(Object, .myDataEnv)
}
getData <- function(Object) {
    if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
    .myDataEnv[[Object]]
}
}

}

To avoid the use of:  Object <<- 5

but it seems not working yet. Object == 5 is not a global variable after
running Fun().

Any Idea?
Thanks
  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/

	[[alternative HTML version deleted]]


From johnwasige at gmail.com  Tue Dec  2 00:01:57 2014
From: johnwasige at gmail.com (John Wasige)
Date: Tue, 2 Dec 2014 00:01:57 +0100
Subject: [R] SPI script
Message-ID: <CAJgdCD42FL8kK2DY3HPMPU-s_kyLo6zpLHh203tK1VwxxkBb8A@mail.gmail.com>

Hello R community,

Could somebody kindly help with SPI script for dailly or monthly
raster time-series data of rainfall?

Thanks for your help

Best Rgds John

	[[alternative HTML version deleted]]


From elham_h763 at yahoo.com  Tue Dec  2 07:55:40 2014
From: elham_h763 at yahoo.com (Patty Haaem)
Date: Tue, 2 Dec 2014 06:55:40 +0000 (UTC)
Subject: [R] multivariate normal distribution
Message-ID: <1025542914.3663988.1417503340093.JavaMail.yahoo@jws10615.mail.bf1.yahoo.com>

Dear every one
I want to generate 10 vector of multivariate normal distribution(means are zero and the size of the vectors is 40). correlation among these variables is ? ? |0.5| ^(i-j) ? , i,j=1,...,10.?How can I generate these vectors?Thanks in advanceElham
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Dec  2 09:59:14 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 02 Dec 2014 21:59:14 +1300
Subject: [R] multivariate normal distribution
In-Reply-To: <1025542914.3663988.1417503340093.JavaMail.yahoo@jws10615.mail.bf1.yahoo.com>
References: <1025542914.3663988.1417503340093.JavaMail.yahoo@jws10615.mail.bf1.yahoo.com>
Message-ID: <547D7F62.8090205@auckland.ac.nz>

On 02/12/14 19:55, Patty Haaem wrote:
> Dear every one I want to generate 10 vector of multivariate normal
> distribution(means  are zero and the size of the vectors is 40).
> correlation among these variables is |0.5| ^(i-j) , i,j=1,...,10.
> How can I generate these vectors?

Sure sounds like homework to me.  This list has a ***no homework*** policy.

cheers,

Rolf Turner

P. S. Even if it's not homework as such, the list expects you to put a 
modicum of effort into searching for the relevant facilities.  In this 
case a search is not difficult to carry out.

Don't expect others to do your work for you.

R. T.



-- 
Rolf Turner
Technical Editor ANZJS


From chirleu at gmail.com  Tue Dec  2 11:33:36 2014
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Tue, 2 Dec 2014 11:33:36 +0100
Subject: [R] specifying a structural equation model with sem
Message-ID: <CALC46t-P60BrbPKqRuTdL1j7D-8CiVQAe4drEkx3S57VfwU03A@mail.gmail.com>

Hi all,
I'm new to sem package and sem analyses, so this is probably very basic,
although I was not able to solve it myself reading some other similar
posts. I was trying to specify a structural equation model using a
correlation matrix of three variables. The correlation matrix comes from a
mixed model in which repeated measures of each variable were analysed as a
function of some fixed and random effects. All the correlations are really
high:

                   mirror          novel       shelter
mirror  1.0000000 0.8360787  0.9107897
novel   0.8360787 1.0000000  0.8745305
shelter 0.9107897 0.8745305  1.0000000

I want to test two models using sem:

1. Independence model: the three variables are independent
2. Syndrome model: all the variables linked through a common latent variable

So my code is:

*# independence model*

model.0=specifyModel()
mirror<->mirror, e1, NA
novel<->novel, e2, NA
shelter<->shelter, e3, NA

*# syndrome model; L represents the latent variable*

model.1=specifyModel()
L->mirror,a1,NA
L->novel,a2,NA
L->shelter,a3,NA
L<->L,NA,1
mirror<->mirror,e1,NA
novel<->novel,e2,NA
shelter<->shelter,e3,NA

*Sem function:*

output0.b=sem(model.0,b,N=235)
output1.b=sem(model.1,b,N=235)

*And my outputs are:*

> summary(output0.b)

 Model Chisquare =  761.9988   Df =  3 Pr(>Chisq) = 7.543238e-165
 AIC =  767.9988
 BIC =  745.62

 Normalized Residuals
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
  0.000   0.000  12.790   8.911  13.380  13.930

 Parameter Estimates
   Estimate Std Error  z value  Pr(>|z|)
e1 1        0.09245003 10.81665 2.870676e-27 mirror <--> mirror
e2 1        0.09245003 10.81665 2.870676e-27 novel <--> novel
e3 1        0.09245003 10.81665 2.870676e-27 shelter <--> shelter

 Iterations =  0


> summary(output1.b)

 Model Chisquare =  3.117506e-13   Df =  0 Pr(>Chisq) = NA
 AIC =  12
 BIC =  3.117506e-13

 Normalized Residuals
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
1.107e-07 1.627e-07 1.701e-07 1.696e-07 1.753e-07 2.457e-07

 R-square for Endogenous Variables
 mirror   novel shelter
 0.8707  0.8028  0.9527

 Parameter Estimates
   Estimate   Std Error  z value   Pr(>|z|)
a1 0.93313643 0.04964952 18.794470 8.381262e-79 mirror <--- L
a2 0.89598763 0.05105094 17.550855 5.859107e-69 novel <--- L
a3 0.97605200 0.04790520 20.374657 2.806748e-92 shelter <--- L
e1 0.12925637 0.01801049  7.176726 7.140033e-13 mirror <--> mirror
e2 0.19720615 0.02206224  8.938628 3.940334e-19 novel <--> novel
e3 0.04732249 0.01537861  3.077164 2.089805e-03 shelter <--> shelter

 Iterations =  23

*My questions are:*

1) Are the models properly specyfied? I followed some examples in the
literature, specifically Broomer et al., 2014 Behav
Ecol, doi:10.1093/beheco/aru057

2) The outputs look pretty strange to me...first, all the paths seems
(highly!) significant. But looking at the model fit, and which model fits
the data better, I guess that the AIC value of the syndrome model is not
correct, and that the Df=0...so I guess that particular model is not
properly specified (unidentified model?). Also, in the independence model,
all the Z values are the same (?)

3) I specifyied N=235 since the original data consist of 235 rows for one
of the variables (5 repeated measures of 47 individuals). But for the two
other variables, I only have 94 rows (2 repeated measures of the same 47
individuals). So I'm not sure which N I should specify in the sem model.
Maybe something like N=c(94,94,235)? Or N=47 because in the end everything
is based on 47 individuals?

Any advise at this point would be greatly appreciated, I'm a bit at loss.

David

	[[alternative HTML version deleted]]


From pbruneau at gmail.com  Tue Dec  2 12:33:21 2014
From: pbruneau at gmail.com (Pierrick Bruneau)
Date: Tue, 2 Dec 2014 12:33:21 +0100
Subject: [R] Sorting method used by order()
Message-ID: <CAF_q7hVW41AFA5uyum9hq30xjjJYV5N+cVraMPjmkpcXgtXocQ@mail.gmail.com>

Hi all,

In ?order, the sorting method used appears as the "method" argument to
sort.list(), but I cannot make out which is used by default when calling
order(), and how to parametrize it.

Does someone have a clue there?

Thanks by advance,
Pierrick

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Dec  2 13:17:37 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 2 Dec 2014 12:17:37 +0000
Subject: [R] Sorting method used by order()
In-Reply-To: <CAF_q7hVW41AFA5uyum9hq30xjjJYV5N+cVraMPjmkpcXgtXocQ@mail.gmail.com>
References: <CAF_q7hVW41AFA5uyum9hq30xjjJYV5N+cVraMPjmkpcXgtXocQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0958@SRVEXCHMBX.precheza.cz>

Hi

Can you be more specific? How do you want parametrize order?

There is no sort.list argument in order.

For sort list, the default method is "radix", AFAIK.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Pierrick Bruneau
> Sent: Tuesday, December 02, 2014 12:33 PM
> To: r-help at stat.math.ethz.ch
> Subject: [R] Sorting method used by order()
>
> Hi all,
>
> In ?order, the sorting method used appears as the "method" argument to
> sort.list(), but I cannot make out which is used by default when
> calling order(), and how to parametrize it.
>
> Does someone have a clue there?
>
> Thanks by advance,
> Pierrick
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From pbruneau at gmail.com  Tue Dec  2 13:28:42 2014
From: pbruneau at gmail.com (Pierrick Bruneau)
Date: Tue, 2 Dec 2014 13:28:42 +0100
Subject: [R] Sorting method used by order()
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0958@SRVEXCHMBX.precheza.cz>
References: <CAF_q7hVW41AFA5uyum9hq30xjjJYV5N+cVraMPjmkpcXgtXocQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0958@SRVEXCHMBX.precheza.cz>
Message-ID: <CAF_q7hX7Rb9QQhWvz0D=3KEuYMQ6e-8mz2p-UmMkUcVtAs820g@mail.gmail.com>

I'll try to be more specific:
- ?order points to a common man page for both order() and sort.list()
- sort.list() has a "method" argument, i.e. a sorting algorithm. As far as
I can read, I'll rather say the default is "shell"
- order() seems not to support this argument. My questions were thus 1)
what is the algorithm it uses ("shell" or other), and 2) is there a way to
parametrize it.

On Tue, Dec 2, 2014 at 1:17 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> Can you be more specific? How do you want parametrize order?
>
> There is no sort.list argument in order.
>
> For sort list, the default method is "radix", AFAIK.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Pierrick Bruneau
> > Sent: Tuesday, December 02, 2014 12:33 PM
> > To: r-help at stat.math.ethz.ch
> > Subject: [R] Sorting method used by order()
> >
> > Hi all,
> >
> > In ?order, the sorting method used appears as the "method" argument to
> > sort.list(), but I cannot make out which is used by default when
> > calling order(), and how to parametrize it.
> >
> > Does someone have a clue there?
> >
> > Thanks by advance,
> > Pierrick
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Dec  2 13:40:37 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 2 Dec 2014 07:40:37 -0500
Subject: [R] Sorting method used by order()
In-Reply-To: <CAF_q7hX7Rb9QQhWvz0D=3KEuYMQ6e-8mz2p-UmMkUcVtAs820g@mail.gmail.com>
References: <CAF_q7hVW41AFA5uyum9hq30xjjJYV5N+cVraMPjmkpcXgtXocQ@mail.gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0958@SRVEXCHMBX.precheza.cz>
	<CAF_q7hX7Rb9QQhWvz0D=3KEuYMQ6e-8mz2p-UmMkUcVtAs820g@mail.gmail.com>
Message-ID: <547DB345.9070004@gmail.com>

On 02/12/2014, 7:28 AM, Pierrick Bruneau wrote:
> I'll try to be more specific:
> - ?order points to a common man page for both order() and sort.list()
> - sort.list() has a "method" argument, i.e. a sorting algorithm. As far as
> I can read, I'll rather say the default is "shell"
> - order() seems not to support this argument. My questions were thus 1)
> what is the algorithm it uses ("shell" or other), and 2) is there a way to
> parametrize it.

For sort.list(), "shell" is the default for most objects, but "radix" is
sometimes used:  see the Details section in the help page.

For order(), the method is undocumented and not under your control.  Use
sort.list() if you need the control.  Read the source if you want to
know the current implementation (but being undocumented, it might change
without notice in a future release).

Duncan Murdoch

> 
> On Tue, Dec 2, 2014 at 1:17 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
>> Hi
>>
>> Can you be more specific? How do you want parametrize order?
>>
>> There is no sort.list argument in order.
>>
>> For sort list, the default method is "radix", AFAIK.
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Pierrick Bruneau
>>> Sent: Tuesday, December 02, 2014 12:33 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] Sorting method used by order()
>>>
>>> Hi all,
>>>
>>> In ?order, the sorting method used appears as the "method" argument to
>>> sort.list(), but I cannot make out which is used by default when
>>> calling order(), and how to parametrize it.
>>>
>>> Does someone have a clue there?
>>>
>>> Thanks by advance,
>>> Pierrick
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Tue Dec  2 13:47:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 2 Dec 2014 12:47:51 +0000
Subject: [R] Sorting method used by order()
In-Reply-To: <CAF_q7hX7Rb9QQhWvz0D=3KEuYMQ6e-8mz2p-UmMkUcVtAs820g@mail.gmail.com>
References: <CAF_q7hVW41AFA5uyum9hq30xjjJYV5N+cVraMPjmkpcXgtXocQ@mail.gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF0958@SRVEXCHMBX.precheza.cz>
	<CAF_q7hX7Rb9QQhWvz0D=3KEuYMQ6e-8mz2p-UmMkUcVtAs820g@mail.gmail.com>
Message-ID: <547DB4F7.2030603@stats.ox.ac.uk>

On 02/12/2014 12:28, Pierrick Bruneau wrote:
> I'll try to be more specific:
> - ?order points to a common man page for both order() and sort.list()
> - sort.list() has a "method" argument, i.e. a sorting algorithm. As far as
> I can read, I'll rather say the default is "shell"

Not quite: the page says

   method: the method to be used: partial matches are allowed.  The
           default is ?"shell"? except for some special cases: see
           ?Details?.

> - order() seems not to support this argument. My questions were thus 1)
> what is the algorithm it uses ("shell" or other), and 2) is there a way to
> parametrize it.

You are expected to read the source code to answer questions like that. 
  As order() is much more general than sort.list(), it needs much more 
general sorting code.

But the overall message is

- when order() is doing the same job as sort.list it uses the same 
defaults (which means it sometimes uses radix sorting).
- otherwise it uses a method from the Shell sort family.

>
> On Tue, Dec 2, 2014 at 1:17 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
>> Hi
>>
>> Can you be more specific? How do you want parametrize order?
>>
>> There is no sort.list argument in order.
>>
>> For sort list, the default method is "radix", AFAIK.
>>
>> Cheers
>> Petr
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Pierrick Bruneau
>>> Sent: Tuesday, December 02, 2014 12:33 PM
>>> To: r-help at stat.math.ethz.ch
>>> Subject: [R] Sorting method used by order()
>>>
>>> Hi all,
>>>
>>> In ?order, the sorting method used appears as the "method" argument to
>>> sort.list(), but I cannot make out which is used by default when
>>> calling order(), and how to parametrize it.
>>>
>>> Does someone have a clue there?
>>>
>>> Thanks by advance,
>>> Pierrick
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From johannesradinger at gmail.com  Tue Dec  2 13:57:52 2014
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 2 Dec 2014 13:57:52 +0100
Subject: [R] Two wireframe plots (lattice) aside (grid.arrange) without
	outer box
Message-ID: <CABsGe_z=srto8yZcuJBnEckRdWO_rhwQ6RgQzvmSTK9URPeN6w@mail.gmail.com>

Hi,

I'd like to arrange two wireframe plots (library "lattice") next to each
other using the grid.arrange function of the library "gridExtra". However
the two wireframe plots should be closer to each other and the outer 2D box
should be removed (to save space).
To remove the outer box for a single plot I am using
trellis.par.set("axis.line",list(col=NA,lty=1,lwd=1))
However this approach does not work in combination with grid.arrange().

Here a small working example:

trellis.par.set("axis.line",list(col=NA,lty=1,lwd=1))
p1 <- wireframe(volcano, shade = TRUE,
          aspect = c(61/87, 0.4),
          light.source = c(10,0,10))
grid.arrange(p1,p1,nrow=1)

Does anybody have any suggestions?

/johannes

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue Dec  2 16:17:09 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 2 Dec 2014 09:17:09 -0600
Subject: [R] function to avoid <<-
In-Reply-To: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
Message-ID: <CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>

At the top level do:

myenv <- new.env(parent = emptyenv())

Then in your functions do

myenv$x <- 50
myenv$x

etc

You also should not be using data() in that way. Perhaps you want
R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more details.

Hadley

On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> Dear All,
>
> I am writing a GUIpackage that needs global variables.
> I had many warning message when I checked the code as for example:
> geteSet: no visible binding for global variable ?curselectCases?
> I would like to write a function that creates a global place for Objects to
> be loaded as:
>
>
> Fun <- function(){
>
> Object <- 5
>
> Var2Global <- function(Object){
> .myDataEnv <- new.env(parent=emptyenv()) # not exported
> isLoaded <- function(Object) {
>     exists(Object, .myDataEnv)
> }
> getData <- function(Object) {
>     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
>     .myDataEnv[[Object]]
> }
> }
>
> }
>
> To avoid the use of:  Object <<- 5
>
> but it seems not working yet. Object == 5 is not a global variable after
> running Fun().
>
> Any Idea?
> Thanks
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From paul.johnston at manchester.ac.uk  Tue Dec  2 10:16:40 2014
From: paul.johnston at manchester.ac.uk (Paul Johnston)
Date: Tue, 2 Dec 2014 09:16:40 +0000
Subject: [R] Passing data to t.test in loop
Message-ID: <EE85AFC56BE9E84EB86F7739169F1BD64D594E5A@MBXP15.ds.man.ac.uk>

Dear All

First post so sorry for any breaches of etiquette.
I have a csv containing the results for a series of experiments which record the time taken for various sizes of iterations.

"run_id","size","time"
1,100,1.00
2,200,2.100
3,100,1.100
4,200,2.100
5,200,1.900
6,300,4.00
7,200,2.5
...

I read the data set, extract the results for each "size" and return various statistics.
The only problem is I would like to iterate over the distinct sizes to do a t.test
My code has a section commented #manual t.test but I have no luck with the attempt labelled #attempt to automate t.test
I'm assuming it's my attempt to pass the data as an argument to t.test()

Any pointers gratefully accepted but as I'm a learner hints rather than a solution are preferred.

Cheers Paul

getwd()
setwd("c:/work/R/experiment1")
# read raw experimental data from results file
data <- read.csv("data1.csv", header = TRUE)
data
#create a new dataframe which has space for a record for each unique size of experiment
# this is to collect collated statistics for each experiment

var_list <- c("num_obs", "size_run", "sample_mean","sample_var","std_dev","se")
var_list_length <- length(var_list)
num_experiments <- length(unique(data$size))
# create the dataframe
df = data.frame(matrix(vector(), num_experiments , var_list_length, dimnames=list(c(),var_list)), stringsAsFactors=F)
# it should be empty
df
# insert the experiment size
df$size_run <- unique(data$size)
# now it should have a single column filled
# using
df$size_run
df
# create a vector with the experiment sizes

for (i in df$size_run)
{
# calculate the sample_variance of observations on a particular size
df$sample_var[df$size == i] <- var(subset(data$time, data$size == i))

# calculate the mean of the returned values for all experiments of the same size
df$sample_mean[df$size == i] <- mean(subset(data$time, data$size ==i))

# calculate the number of observations on a particular size
df$num_obs[df$size == i] <- length(subset(data$time, data$size == i))

# calculate the sd of the data
df$std_dev[df$size == i] <- sd(subset(data$time, data$size == i))

# calculate the standard error
df$se[df$size == i] <- sd(subset(data$time, data$size ==i))/sqrt(length(subset(data$time, data$size ==i)))
}

df

#manual t.test
print("t.test for size  = 100")
t.test(subset(data$time, data$size == 100))

print("t.test for size  = 200")
t.test(subset(data$time, data$size == 200))

print("t.test for size  = 300")
t.test(subset(data$time, data$size == 300))

#attempt to automate t.test
for (i in df$size_run)
{
print(i)
a <- subset(data$time, data$size == i)
print(a)
t.test(a)
}

	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Tue Dec  2 16:29:26 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Tue, 2 Dec 2014 16:29:26 +0100
Subject: [R] move date-values from one line to several lines
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF3EB@mail.ell.fnt.de>

Hello together,

i have a data.frame with date-values. What I want is a data.frame with a several lines for each date.

My current data.frame looks like this one:

ID     FROM         TO                REASON
1      2015-02-27   2015-02-28    Holiday
1      2015-03-15   2015-03-20    Illness
2      2015-05-20   2015-02-23    Holiday
2      2015-06-01   2015-06-03    Holiday
2      2015-07-01   2015-07-01    Illness

The result looks like this one:

ID   DATE           REASON
1    2015-02-27    Holiday
1    2015-02-28    Holiday
1    2015-03-15    Illness
1    2015-03-16    Illness
1    2015-03-17    Illness
1    2015-03-18    Illness
1    2015-03-19    Illness
1    2015-03-20    Illness
2    2015-05-20   Holiday
2    2015-05-21   Holiday
2    2015-05-22   Holiday
2    2015-05-23   Holiday
2    2015-06-01   Holiday
2    2015-06-02   Holiday
2    2015-06-02   Holiday
2    2015-07-01   Illness

Maybe anyone can help me, how I can do this.

Thank you.

Best regards.

Mat

________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Dec  2 17:14:42 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 02 Dec 2014 10:14:42 -0600
Subject: [R] move date-values from one line to several lines
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF3EB@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF3EB@mail.ell.fnt.de>
Message-ID: <B9EB3880-32F9-4D26-B75E-8FE7D80A6E4A@me.com>


> On Dec 2, 2014, at 9:29 AM, Matthias Weber <Matthias.Weber at fntsoftware.com> wrote:
> 
> Hello together,
> 
> i have a data.frame with date-values. What I want is a data.frame with a several lines for each date.
> 
> My current data.frame looks like this one:
> 
> ID     FROM         TO                REASON
> 1      2015-02-27   2015-02-28    Holiday
> 1      2015-03-15   2015-03-20    Illness
> 2      2015-05-20   2015-02-23    Holiday
> 2      2015-06-01   2015-06-03    Holiday
> 2      2015-07-01   2015-07-01    Illness
> 
> The result looks like this one:
> 
> ID   DATE           REASON
> 1    2015-02-27    Holiday
> 1    2015-02-28    Holiday
> 1    2015-03-15    Illness
> 1    2015-03-16    Illness
> 1    2015-03-17    Illness
> 1    2015-03-18    Illness
> 1    2015-03-19    Illness
> 1    2015-03-20    Illness
> 2    2015-05-20   Holiday
> 2    2015-05-21   Holiday
> 2    2015-05-22   Holiday
> 2    2015-05-23   Holiday
> 2    2015-06-01   Holiday
> 2    2015-06-02   Holiday
> 2    2015-06-02   Holiday
> 2    2015-07-01   Illness
> 
> Maybe anyone can help me, how I can do this.
> 
> Thank you.
> 
> Best regards.
> 
> Mat


A quick and dirty approach.

First, note that in your source data frame, the TO value in the third row is incorrect. I changed it here:

> DF
  ID       FROM         TO  REASON
1  1 2015-02-27 2015-02-28 Holiday
2  1 2015-03-15 2015-03-20 Illness
3  2 2015-05-20 2015-05-23 Holiday
4  2 2015-06-01 2015-06-03 Holiday
5  2 2015-07-01 2015-07-01 Illness

With that in place, you can use R's recycling of values to create multiple data frame rows from the date sequences and the single ID and REASON entries:

i <- 1

> data.frame(ID = DF$ID[i], DATE = seq(DF$FROM[i], DF$TO[i], by = "day"), REASON = DF$REASON[i])
  ID       DATE  REASON
1  1 2015-02-27 Holiday
2  1 2015-02-28 Holiday


So just put that into an lapply() based loop, which returns a list:

> DF.TMP <- lapply(seq(nrow(DF)), 
                   function(i) data.frame(ID = DF$ID[i], 
                                          DATE = seq(DF$FROM[i], DF$TO[i], by = "day"), 
                                          REASON = DF$REASON[i]))

> DF.TMP
[[1]]
  ID       DATE  REASON
1  1 2015-02-27 Holiday
2  1 2015-02-28 Holiday

[[2]]
  ID       DATE  REASON
1  1 2015-03-15 Illness
2  1 2015-03-16 Illness
3  1 2015-03-17 Illness
4  1 2015-03-18 Illness
5  1 2015-03-19 Illness
6  1 2015-03-20 Illness

[[3]]
  ID       DATE  REASON
1  2 2015-05-20 Holiday
2  2 2015-05-21 Holiday
3  2 2015-05-22 Holiday
4  2 2015-05-23 Holiday

[[4]]
  ID       DATE  REASON
1  2 2015-06-01 Holiday
2  2 2015-06-02 Holiday
3  2 2015-06-03 Holiday

[[5]]
  ID       DATE  REASON
1  2 2015-07-01 Illness


Then use do.call() on the result:

> do.call(rbind, DF.TMP)
   ID       DATE  REASON
1   1 2015-02-27 Holiday
2   1 2015-02-28 Holiday
3   1 2015-03-15 Illness
4   1 2015-03-16 Illness
5   1 2015-03-17 Illness
6   1 2015-03-18 Illness
7   1 2015-03-19 Illness
8   1 2015-03-20 Illness
9   2 2015-05-20 Holiday
10  2 2015-05-21 Holiday
11  2 2015-05-22 Holiday
12  2 2015-05-23 Holiday
13  2 2015-06-01 Holiday
14  2 2015-06-02 Holiday
15  2 2015-06-03 Holiday
16  2 2015-07-01 Illness


See ?seq.Date for the critical step.

Regards,

Marc Schwartz


From kmezhoud at gmail.com  Tue Dec  2 17:32:22 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 2 Dec 2014 17:32:22 +0100
Subject: [R] function to avoid <<-
In-Reply-To: <CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
	<CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
Message-ID: <CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>

Thanks Dr Hadley,

but when I use a function the myenv remains temporary and I am to face the
same problem.


fun <- function(){

myenv <- new.env(parent = emptyenv())

fun1 <- function(){
myenv$X <- 5
}

}

ls(myEnv)
#character(0)

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Tue, Dec 2, 2014 at 4:17 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

> At the top level do:
>
> myenv <- new.env(parent = emptyenv())
>
> Then in your functions do
>
> myenv$x <- 50
> myenv$x
>
> etc
>
> You also should not be using data() in that way. Perhaps you want
> R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more details.
>
> Hadley
>
> On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> > Dear All,
> >
> > I am writing a GUIpackage that needs global variables.
> > I had many warning message when I checked the code as for example:
> > geteSet: no visible binding for global variable ?curselectCases?
> > I would like to write a function that creates a global place for Objects
> to
> > be loaded as:
> >
> >
> > Fun <- function(){
> >
> > Object <- 5
> >
> > Var2Global <- function(Object){
> > .myDataEnv <- new.env(parent=emptyenv()) # not exported
> > isLoaded <- function(Object) {
> >     exists(Object, .myDataEnv)
> > }
> > getData <- function(Object) {
> >     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
> >     .myDataEnv[[Object]]
> > }
> > }
> >
> > }
> >
> > To avoid the use of:  Object <<- 5
> >
> > but it seems not working yet. Object == 5 is not a global variable after
> > running Fun().
> >
> > Any Idea?
> > Thanks
> >   ?__
> >  c/ /'_;~~~~kmezhoud
> > (*) \(*)   ?????  ??????
> > http://bioinformatics.tn/
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> http://had.co.nz/
>

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Tue Dec  2 17:47:19 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 2 Dec 2014 09:47:19 -0700
Subject: [R] function to avoid <<-
In-Reply-To: <CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
	<CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
	<CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>
Message-ID: <CAFEqCdy9vWXA0zXYiaVn5pg5-tT_gmx+R=bs=vBy4ywBA6bnKw@mail.gmail.com>

By "At the top level" Hadley meant to put that code outside of the function
definition.  In you source file that line should be very near the top,
before any function definitions.  Then "myenv" will not be temporary (well
it will go away when you end the R session).  Further, when this code is
compiled into a package then "myenv" becomes package local, meaning that
functions within the package can access it and the objects inside of it,
but it will not interfere with any other packages or the global environment.

On Tue, Dec 2, 2014 at 9:32 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Thanks Dr Hadley,
>
> but when I use a function the myenv remains temporary and I am to face the
> same problem.
>
>
> fun <- function(){
>
> myenv <- new.env(parent = emptyenv())
>
> fun1 <- function(){
> myenv$X <- 5
> }
>
> }
>
> ls(myEnv)
> #character(0)
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Tue, Dec 2, 2014 at 4:17 PM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
>
> > At the top level do:
> >
> > myenv <- new.env(parent = emptyenv())
> >
> > Then in your functions do
> >
> > myenv$x <- 50
> > myenv$x
> >
> > etc
> >
> > You also should not be using data() in that way. Perhaps you want
> > R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more details.
> >
> > Hadley
> >
> > On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com>
> wrote:
> > > Dear All,
> > >
> > > I am writing a GUIpackage that needs global variables.
> > > I had many warning message when I checked the code as for example:
> > > geteSet: no visible binding for global variable ?curselectCases?
> > > I would like to write a function that creates a global place for
> Objects
> > to
> > > be loaded as:
> > >
> > >
> > > Fun <- function(){
> > >
> > > Object <- 5
> > >
> > > Var2Global <- function(Object){
> > > .myDataEnv <- new.env(parent=emptyenv()) # not exported
> > > isLoaded <- function(Object) {
> > >     exists(Object, .myDataEnv)
> > > }
> > > getData <- function(Object) {
> > >     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
> > >     .myDataEnv[[Object]]
> > > }
> > > }
> > >
> > > }
> > >
> > > To avoid the use of:  Object <<- 5
> > >
> > > but it seems not working yet. Object == 5 is not a global variable
> after
> > > running Fun().
> > >
> > > Any Idea?
> > > Thanks
> > >   ?__
> > >  c/ /'_;~~~~kmezhoud
> > > (*) \(*)   ?????  ??????
> > > http://bioinformatics.tn/
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > http://had.co.nz/
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Tue Dec  2 17:59:50 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 2 Dec 2014 17:59:50 +0100
Subject: [R] function to avoid <<-
In-Reply-To: <CAFEqCdy9vWXA0zXYiaVn5pg5-tT_gmx+R=bs=vBy4ywBA6bnKw@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
	<CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
	<CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>
	<CAFEqCdy9vWXA0zXYiaVn5pg5-tT_gmx+R=bs=vBy4ywBA6bnKw@mail.gmail.com>
Message-ID: <CALJKBv-He=6BDEKqqG=0GWH8Pu5wgwxwHiOm-Nwp2amsrar02w@mail.gmail.com>

OK thanks as:

myenv <- new.env(parent = emptyenv())
fun <- function(){
fun1 <- function(){
myenv$X <- 5
}

}
fun()
ls(myenv)
#X
X
#5

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Tue, Dec 2, 2014 at 5:47 PM, Greg Snow <538280 at gmail.com> wrote:

> By "At the top level" Hadley meant to put that code outside of the
> function definition.  In you source file that line should be very near the
> top, before any function definitions.  Then "myenv" will not be temporary
> (well it will go away when you end the R session).  Further, when this code
> is compiled into a package then "myenv" becomes package local, meaning that
> functions within the package can access it and the objects inside of it,
> but it will not interfere with any other packages or the global environment.
>
> On Tue, Dec 2, 2014 at 9:32 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Thanks Dr Hadley,
>>
>> but when I use a function the myenv remains temporary and I am to face the
>> same problem.
>>
>>
>> fun <- function(){
>>
>> myenv <- new.env(parent = emptyenv())
>>
>> fun1 <- function(){
>> myenv$X <- 5
>> }
>>
>> }
>>
>> ls(myEnv)
>> #character(0)
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Tue, Dec 2, 2014 at 4:17 PM, Hadley Wickham <h.wickham at gmail.com>
>> wrote:
>>
>> > At the top level do:
>> >
>> > myenv <- new.env(parent = emptyenv())
>> >
>> > Then in your functions do
>> >
>> > myenv$x <- 50
>> > myenv$x
>> >
>> > etc
>> >
>> > You also should not be using data() in that way. Perhaps you want
>> > R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more details.
>> >
>> > Hadley
>> >
>> > On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com>
>> wrote:
>> > > Dear All,
>> > >
>> > > I am writing a GUIpackage that needs global variables.
>> > > I had many warning message when I checked the code as for example:
>> > > geteSet: no visible binding for global variable ?curselectCases?
>> > > I would like to write a function that creates a global place for
>> Objects
>> > to
>> > > be loaded as:
>> > >
>> > >
>> > > Fun <- function(){
>> > >
>> > > Object <- 5
>> > >
>> > > Var2Global <- function(Object){
>> > > .myDataEnv <- new.env(parent=emptyenv()) # not exported
>> > > isLoaded <- function(Object) {
>> > >     exists(Object, .myDataEnv)
>> > > }
>> > > getData <- function(Object) {
>> > >     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
>> > >     .myDataEnv[[Object]]
>> > > }
>> > > }
>> > >
>> > > }
>> > >
>> > > To avoid the use of:  Object <<- 5
>> > >
>> > > but it seems not working yet. Object == 5 is not a global variable
>> after
>> > > running Fun().
>> > >
>> > > Any Idea?
>> > > Thanks
>> > >   ?__
>> > >  c/ /'_;~~~~kmezhoud
>> > > (*) \(*)   ?????  ??????
>> > > http://bioinformatics.tn/
>> > >
>> > >         [[alternative HTML version deleted]]
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> > --
>> > http://had.co.nz/
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>

	[[alternative HTML version deleted]]


From alejandra.chovar at gmail.com  Tue Dec  2 16:38:03 2014
From: alejandra.chovar at gmail.com (Alejandra Chovar Vera)
Date: Tue, 2 Dec 2014 12:38:03 -0300
Subject: [R] help
Message-ID: <CAGW2UaDZYafdcnVYZ82qkb127FxRa0RVuv9z3MdVU1bp7mUAYg@mail.gmail.com>

Dear R

I have a big problem in my estimation process,  I try to estimate my
likelihood function with the option "optim", but R give me this message
"Error en optim(par = valores$par, nlogL, method = "BFGS", hessian = T,  :

  valor inicial en 'vmmin' no es finito " I know this is because my initial
values are out the interval, but i try with different initial values and
the problem persist.

I don't know what can i do.


I have this code, to obtain my initial values:


 valores<-
optim(c(-1,-1,1,1,1),nlogL,method="SANN",control=list(maxit=1000))

DCp <-
optim(par=valores$par,nlogL,method="BFGS",hessian=T,control=list(maxit=1000))



I found in this link "http://es.listoso.com/r-help/2012-02/msg02395.html"
something similar, but in this case there isn't answer.


If you need more information about my code, please tell me.


Sincerely


Alejandra

	[[alternative HTML version deleted]]


From gupta567varun at gmail.com  Tue Dec  2 18:10:11 2014
From: gupta567varun at gmail.com (VG)
Date: Tue, 2 Dec 2014 12:10:11 -0500
Subject: [R] R installation
Message-ID: <CAN7A_QznVVXtszQ2n0M9Cm+oNRbjRpL2h=dmX4pBjcYaCh2Jeg@mail.gmail.com>

Hi everyone,

I was having trouble with R i installed some time ago on my local ubuntu
machine. So i removed R completely from my system in order to re install
it. I used these commands to install R

sudo apt-get install r-base r-base-dev

Then on the terminal I typed which R:
it returns
/usr/bin/R

When i launch R on the terminal by typing R it gives me this:

*/usr/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or directory*

R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i486-pc-linux-gnu (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.


*Warning: namespace ?DESeq? is not available and has been replacedby
.GlobalEnv when processing object ?data2*

To fix "*/usr/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or
directory*"

I went to
*/usr/lib/R/etc/ and did *

*file ldpaths and it gave me*

ldpaths: broken symbolic link to `/etc/R/ldpaths'

How to fix this??
Also I need to fix warning

Regards
Varun

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Dec  2 18:15:55 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 02 Dec 2014 12:15:55 -0500
Subject: [R] specifying a structural equation model with sem
In-Reply-To: <CALC46t-P60BrbPKqRuTdL1j7D-8CiVQAe4drEkx3S57VfwU03A@mail.gmail.com>
References: <CALC46t-P60BrbPKqRuTdL1j7D-8CiVQAe4drEkx3S57VfwU03A@mail.gmail.com>
Message-ID: <web-538684085@cgpsrv2.cis.mcmaster.ca>

Dear David,

There's nothing wrong with what you did: You've fit the independence model and a one-factor CFA model as I believe you intended. It's unnecessary to fit the first model because sem() computes the chisquare for the independence model in any event, and (as the message printed by specifyModel() indicates) it's much easier to use cfa() for the second model.

In the input and output below, I've cleaned up your code a bit:

------------------ snip --------------

> R <- scan()
1:  1.0000000 0.8360787 0.9107897
4:  0.8360787 1.0000000 0.8745305
7:  0.9107897 0.8745305 1.0000000
10: 
Read 9 items

> R <- matrix(R, 3, 3)
> names <- scan(what="")
1: mirror novel shelter
4: 
Read 3 items

> rownames(R) <- colnames(R) <- names
> R
           mirror     novel   shelter
mirror  1.0000000 0.8360787 0.9107897
novel   0.8360787 1.0000000 0.8745305
shelter 0.9107897 0.8745305 1.0000000

> model.0 <- specifyModel()
1: mirror <-> mirror, e1 
2: novel <-> novel, e2 
3: shelter <-> shelter, e3
4: 
Read 3 records
NOTE: it is generally simpler to use specifyEquations() or cfa()
      see ?specifyEquations

> (s0 <- summary(sem(model.0, R, N=235)))

 Model Chisquare =  761.9987   Df =  3 Pr(>Chisq) = 7.543436e-165
 AIC =  767.9987
 BIC =  745.62

 Normalized Residuals
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  0.000   0.000  12.790   8.911  13.380  13.930 

 Parameter Estimates
   Estimate Std Error  z value  Pr(>|z|)                         
e1 1        0.09245003 10.81665 2.870676e-27 mirror <--> mirror  
e2 1        0.09245003 10.81665 2.870676e-27 novel <--> novel    
e3 1        0.09245003 10.81665 2.870676e-27 shelter <--> shelter

 Iterations =  0 

> s0$chisqNull
[1] 761.9987

> s0$chisq
[1] 761.9987

> model.1 <- specifyModel()
1: L -> mirror, a1
2: L -> novel, a2
3: L -> shelter, a3
4: L <->L , NA, 1
5: mirror <-> mirror, e1 
6: novel <-> novel, e2 
7: shelter <-> shelter, e3
8: 
Read 7 records
NOTE: it is generally simpler to use specifyEquations() or cfa()
      see ?specifyEquations

> summary(sem(model.1, R, N=235))

 Model Chisquare =  4.918292e-13   Df =  0 Pr(>Chisq) = NA
 AIC =  12
 BIC =  4.918292e-13

 Normalized Residuals
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
1.107e-07 1.627e-07 1.701e-07 1.696e-07 1.753e-07 2.457e-07 

 R-square for Endogenous Variables
 mirror   novel shelter 
 0.8707  0.8028  0.9527 

 Parameter Estimates
   Estimate  Std Error  z value   Pr(>|z|)                         
a1 0.9331364 0.04964952 18.794471 8.381222e-79 mirror <--- L       
a2 0.8959876 0.05105094 17.550854 5.859212e-69 novel <--- L        
a3 0.9760520 0.04790520 20.374657 2.806766e-92 shelter <--- L      
e1 0.1292564 0.01801049  7.176725 7.140093e-13 mirror <--> mirror  
e2 0.1972062 0.02206224  8.938628 3.940313e-19 novel <--> novel    
e3 0.0473225 0.01537861  3.077164 2.089802e-03 shelter <--> shelter

 Iterations =  23 

> model.cfa <- cfa(reference.indicators=FALSE) # equivalent
1: L: mirror, novel, shelter
2: 
Read 1 item
NOTE: adding 3 variances to the model

> summary(sem(model.1, R, N=235))

 Model Chisquare =  4.918292e-13   Df =  0 Pr(>Chisq) = NA
 AIC =  12
 BIC =  4.918292e-13

 Normalized Residuals
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
1.107e-07 1.627e-07 1.701e-07 1.696e-07 1.753e-07 2.457e-07 

 R-square for Endogenous Variables
 mirror   novel shelter 
 0.8707  0.8028  0.9527 

 Parameter Estimates
   Estimate  Std Error  z value   Pr(>|z|)                         
a1 0.9331364 0.04964952 18.794471 8.381222e-79 mirror <--- L       
a2 0.8959876 0.05105094 17.550854 5.859212e-69 novel <--- L        
a3 0.9760520 0.04790520 20.374657 2.806766e-92 shelter <--- L      
e1 0.1292564 0.01801049  7.176725 7.140093e-13 mirror <--> mirror  
e2 0.1972062 0.02206224  8.938628 3.940313e-19 novel <--> novel    
e3 0.0473225 0.01537861  3.077164 2.089802e-03 shelter <--> shelter

 Iterations =  23 

----------- snip -----------

Your questions really seem to pertain to the the models themselves and not to how to use sem() to fit them. For example, df = 0 in the second model because the model is just-identified (not under-identified). That's why the model chisquare is also 0 (within rounding error). I think that you should probably try to talk to someone about what you're doing.

I hope this helps,
 John

On Tue, 2 Dec 2014 11:33:36 +0100
 David Villegas R?os <chirleu at gmail.com> wrote:
> Hi all,
> I'm new to sem package and sem analyses, so this is probably very basic,
> although I was not able to solve it myself reading some other similar
> posts. I was trying to specify a structural equation model using a
> correlation matrix of three variables. The correlation matrix comes from a
> mixed model in which repeated measures of each variable were analysed as a
> function of some fixed and random effects. All the correlations are really
> high:
> 
>                    mirror          novel       shelter
> mirror  1.0000000 0.8360787  0.9107897
> novel   0.8360787 1.0000000  0.8745305
> shelter 0.9107897 0.8745305  1.0000000
> 
> I want to test two models using sem:
> 
> 1. Independence model: the three variables are independent
> 2. Syndrome model: all the variables linked through a common latent variable
> 
> So my code is:
> 
> *# independence model*
> 
> model.0=specifyModel()
> mirror<->mirror, e1, NA
> novel<->novel, e2, NA
> shelter<->shelter, e3, NA
> 
> *# syndrome model; L represents the latent variable*
> 
> model.1=specifyModel()
> L->mirror,a1,NA
> L->novel,a2,NA
> L->shelter,a3,NA
> L<->L,NA,1
> mirror<->mirror,e1,NA
> novel<->novel,e2,NA
> shelter<->shelter,e3,NA
> 
> *Sem function:*
> 
> output0.b=sem(model.0,b,N=235)
> output1.b=sem(model.1,b,N=235)
> 
> *And my outputs are:*
> 
> > summary(output0.b)
> 
>  Model Chisquare =  761.9988   Df =  3 Pr(>Chisq) = 7.543238e-165
>  AIC =  767.9988
>  BIC =  745.62
> 
>  Normalized Residuals
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>   0.000   0.000  12.790   8.911  13.380  13.930
> 
>  Parameter Estimates
>    Estimate Std Error  z value  Pr(>|z|)
> e1 1        0.09245003 10.81665 2.870676e-27 mirror <--> mirror
> e2 1        0.09245003 10.81665 2.870676e-27 novel <--> novel
> e3 1        0.09245003 10.81665 2.870676e-27 shelter <--> shelter
> 
>  Iterations =  0
> 
> 
> > summary(output1.b)
> 
>  Model Chisquare =  3.117506e-13   Df =  0 Pr(>Chisq) = NA
>  AIC =  12
>  BIC =  3.117506e-13
> 
>  Normalized Residuals
>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> 1.107e-07 1.627e-07 1.701e-07 1.696e-07 1.753e-07 2.457e-07
> 
>  R-square for Endogenous Variables
>  mirror   novel shelter
>  0.8707  0.8028  0.9527
> 
>  Parameter Estimates
>    Estimate   Std Error  z value   Pr(>|z|)
> a1 0.93313643 0.04964952 18.794470 8.381262e-79 mirror <--- L
> a2 0.89598763 0.05105094 17.550855 5.859107e-69 novel <--- L
> a3 0.97605200 0.04790520 20.374657 2.806748e-92 shelter <--- L
> e1 0.12925637 0.01801049  7.176726 7.140033e-13 mirror <--> mirror
> e2 0.19720615 0.02206224  8.938628 3.940334e-19 novel <--> novel
> e3 0.04732249 0.01537861  3.077164 2.089805e-03 shelter <--> shelter
> 
>  Iterations =  23
> 
> *My questions are:*
> 
> 1) Are the models properly specyfied? I followed some examples in the
> literature, specifically Broomer et al., 2014 Behav
> Ecol, doi:10.1093/beheco/aru057
> 
> 2) The outputs look pretty strange to me...first, all the paths seems
> (highly!) significant. But looking at the model fit, and which model fits
> the data better, I guess that the AIC value of the syndrome model is not
> correct, and that the Df=0...so I guess that particular model is not
> properly specified (unidentified model?). Also, in the independence model,
> all the Z values are the same (?)
> 
> 3) I specifyied N=235 since the original data consist of 235 rows for one
> of the variables (5 repeated measures of 47 individuals). But for the two
> other variables, I only have 94 rows (2 repeated measures of the same 47
> individuals). So I'm not sure which N I should specify in the sem model.
> Maybe something like N=c(94,94,235)? Or N=47 because in the end everything
> is based on 47 individuals?
> 
> Any advise at this point would be greatly appreciated, I'm a bit at loss.
> 
> David
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From jecogeo at gmail.com  Tue Dec  2 19:08:07 2014
From: jecogeo at gmail.com (Jefferson Ferreira-Ferreira)
Date: Tue, 02 Dec 2014 18:08:07 +0000
Subject: [R] if else for cumulative sum error
Message-ID: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>

Hello everybody;

I'm writing a code where part of it is as follows:

for (i in nrow(dadosmax)){
  dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1 else 0
}

That is for each row of my data frame, sum an specific column (0 or 1) of
that row plus 44 rows. If It is >=45 than enchday is 1 else 0.

The following error is returned:

Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
  missing value where TRUE/FALSE needed

I've tested the ifelse statement assigning different values to i and it
works. So I'm wondering if this error is due the fact that at the final of
my data frame there aren't 45 rows to sum anymore. I tried to use "try" but
It's simply hide the error.

How can I deal with this? Any ideas?
Thank you very much.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Dec  2 19:19:28 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Dec 2014 10:19:28 -0800
Subject: [R] if else for cumulative sum error
In-Reply-To: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
References: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
Message-ID: <530437AA-CBC3-42B6-86B4-C99FC539DBEF@comcast.net>


On Dec 2, 2014, at 10:08 AM, Jefferson Ferreira-Ferreira wrote:

> Hello everybody;
> 
> I'm writing a code where part of it is as follows:
> 
> for (i in nrow(dadosmax)){
>  dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1 else 0
> }
> 
> That is for each row of my data frame, sum an specific column (0 or 1) of
> that row plus 44 rows. If It is >=45 than enchday is 1 else 0.
> 
> The following error is returned:
> 
> Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
>  missing value where TRUE/FALSE needed
> 
> I've tested the ifelse statement assigning different values to i and it
> works. So I'm wondering if this error is due the fact that at the final of
> my data frame there aren't 45 rows to sum anymore. I tried to use "try" but
> It's simply hide the error.
> 
> How can I deal with this? Any ideas?

You should think about what would happen at the high end of values (for what is now being erroneously coded) for `nrow(dadosmax)` which a assume was meant to be `1:nrow(dadosmax)`. Should have been `seq_along(rownames(dadosmax))`. But even if that error were fixed you would be referencing non-existent rows as soon as you were within 44 rows of the end of the dataframe.

-- 
David.


> Thank you very much.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From john.archie.mckown at gmail.com  Tue Dec  2 19:22:22 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 2 Dec 2014 12:22:22 -0600
Subject: [R] if else for cumulative sum error
In-Reply-To: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
References: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
Message-ID: <CAAJSdji+4FPz2ZWbna6M6UTMkKSShBS33pLv=YQ3sisgjEGVLQ@mail.gmail.com>

On Tue, Dec 2, 2014 at 12:08 PM, Jefferson Ferreira-Ferreira <
jecogeo at gmail.com> wrote:

> Hello everybody;
>
> I'm writing a code where part of it is as follows:
>
> for (i in nrow(dadosmax)){
>   dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1 else 0
> }
>

?Without some test data for any validation, I would try the following
formula

dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(min(i+44,nrow(dadosmax)))]
>= 45) 1 else 0?



>
> That is for each row of my data frame, sum an specific column (0 or 1) of
> that row plus 44 rows. If It is >=45 than enchday is 1 else 0.
>
> The following error is returned:
>
> Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
>   missing value where TRUE/FALSE needed
>
> I've tested the ifelse statement assigning different values to i and it
> works. So I'm wondering if this error is due the fact that at the final of
> my data frame there aren't 45 rows to sum anymore. I tried to use "try" but
> It's simply hide the error.
>
> How can I deal with this? Any ideas?
> Thank you very much.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Tue Dec  2 19:34:07 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 2 Dec 2014 18:34:07 +0000 (UTC)
Subject: [R] How to fill rainbow colors under curves in R
Message-ID: <476789801.3951082.1417545247845.JavaMail.yahoo@jws10605.mail.bf1.yahoo.com>

Hi All,
I have a tricky problem here.
The short code below plots some percentiles from a simulation. The percentiles are indicated in different colors.

Problem: 
- How can I fill the area under the curve using the same colors as for the percentiles-1?
- Also, I would like the rainbow intensity to look like a typical coloramp (used for plotting climate variables) generated using for example:
 
colorRampPalette(c("darkred","red3","orange","yellow","darkblue"))

such that "0%" percentile values go from say "darkred" at min(0%) and fade out before approaching "2.5%" whose color is 
"red3". The same applies for other percentiles except "100%" whose color intensity will increase with increased values.
 

#====================================================================================================================
time<-1971:2000 
matplot(time,t(ACF1SIM), type="l",ylim=c(0.2,2.5), col=c("darkred","red3","orange","yellow","darkblue"), lty=c(2,3,1,4,6), 
lwd=c(2,1.9,2.5,1.9,2),cex.lab=1.4,cex.axis=1.5,ylab="Quantiles")#====================================================================================================================


#REPRODUCIBLE EXAMPLE

structure(c(0.406666666666667, 0.519, 0.935, 1.331, 1.49666666666667, 
0.456666666666667, 0.54, 0.848333333333333, 1.20016666666667, 
1.27, 0.526666666666667, 0.556333333333333, 0.883333333333333, 
1.34783333333333, 1.44, 0.8, 0.923083333333333, 1.38666666666667, 
1.85958333333333, 2.17666666666667, 0.883333333333333, 1.162, 
1.655, 2.34658333333333, 2.65666666666667, 0.46, 0.579666666666667, 
0.908333333333333, 1.53366666666667, 1.58, 0.74, 0.87475, 1.37333333333333, 
1.76875, 1.95, 0.686666666666667, 0.74475, 1.09833333333333, 
1.48508333333333, 1.56666666666667, 0.633333333333333, 0.746666666666667, 
1.04, 1.448, 1.61666666666667, 0.516666666666667, 0.576166666666667, 
0.978333333333333, 1.40191666666667, 1.46666666666667, 0.46, 
0.559833333333333, 0.913333333333333, 1.28858333333333, 1.53333333333333, 
0.71, 0.8095, 1.26, 1.87658333333333, 2.15, 0.656666666666667, 
0.70825, 0.933333333333333, 1.31716666666667, 1.41, 0.67, 0.79075, 
1.11333333333333, 1.59508333333333, 1.69, 0.78, 0.81125, 1.18333333333333, 
1.58875, 1.73666666666667, 0.813333333333333, 0.9095, 1.32666666666667, 
1.87066666666667, 1.93666666666667, 0.763333333333333, 0.80475, 
1.15, 1.57908333333333, 1.83666666666667, 0.596666666666667, 
0.682833333333333, 1.07833333333333, 1.5515, 1.81666666666667, 
0.476666666666667, 0.673166666666667, 1.04, 1.53, 2.11666666666667, 
0.706666666666667, 0.79825, 1.11, 1.66875, 1.79333333333333, 
0.656666666666667, 0.773166666666667, 1.17166666666667, 1.6275, 
1.75, 0.493333333333333, 0.534583333333333, 0.846666666666667, 
1.19416666666667, 1.30666666666667, 0.633333333333333, 0.719916666666667, 
1.12666666666667, 1.52525, 1.93, 0.383333333333333, 0.45025, 
0.843333333333333, 1.18741666666667, 1.26, 0.37, 0.401416666666667, 
0.655, 0.998416666666667, 1.11666666666667, 0.366666666666667, 
0.584916666666667, 0.895, 1.3, 1.42333333333333, 0.43, 0.483, 
0.813333333333333, 1.264, 1.38, 0.45, 0.533, 0.893333333333333, 
1.31858333333333, 1.46, 0.706666666666667, 0.747916666666667, 
1.09333333333333, 1.58575, 1.69666666666667, 0.41, 0.479166666666667, 
0.755, 1.2035, 1.37), .Dim = c(5L, 30L), .Dimnames = list(c("0%", 
"2.5%", "50%", "97.5%", "100%"), NULL))

 Many thanks for your insightful feedbacks.
Asong.


From jdnewmil at dcn.davis.ca.us  Tue Dec  2 19:51:55 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 2 Dec 2014 10:51:55 -0800 (PST)
Subject: [R] move date-values from one line to several lines
In-Reply-To: <B9EB3880-32F9-4D26-B75E-8FE7D80A6E4A@me.com>
References: <7E39CF5278A2C948968C39502CF451020174CEADF3EB@mail.ell.fnt.de>
	<B9EB3880-32F9-4D26-B75E-8FE7D80A6E4A@me.com>
Message-ID: <alpine.BSF.2.00.1412021028210.24825@pedal.dcn.davis.ca.us>

On Tue, 2 Dec 2014, Marc Schwartz wrote:

>
>> On Dec 2, 2014, at 9:29 AM, Matthias Weber <Matthias.Weber at fntsoftware.com> wrote:
>>
>> Hello together,
>>
>> i have a data.frame with date-values. What I want is a data.frame with a several lines for each date.
>>
>> My current data.frame looks like this one:
>>
>> ID     FROM         TO                REASON
>> 1      2015-02-27   2015-02-28    Holiday
>> 1      2015-03-15   2015-03-20    Illness
>> 2      2015-05-20   2015-02-23    Holiday
>> 2      2015-06-01   2015-06-03    Holiday
>> 2      2015-07-01   2015-07-01    Illness
>>
>> The result looks like this one:
>>
>> ID   DATE           REASON
>> 1    2015-02-27    Holiday
>> 1    2015-02-28    Holiday
>> 1    2015-03-15    Illness
>> 1    2015-03-16    Illness
>> 1    2015-03-17    Illness
>> 1    2015-03-18    Illness
>> 1    2015-03-19    Illness
>> 1    2015-03-20    Illness
>> 2    2015-05-20   Holiday
>> 2    2015-05-21   Holiday
>> 2    2015-05-22   Holiday
>> 2    2015-05-23   Holiday
>> 2    2015-06-01   Holiday
>> 2    2015-06-02   Holiday
>> 2    2015-06-02   Holiday
>> 2    2015-07-01   Illness
>>
>> Maybe anyone can help me, how I can do this.
>>
>> Thank you.
>>
>> Best regards.
>>
>> Mat
>
>
> A quick and dirty approach.
>
> First, note that in your source data frame, the TO value in the third row is incorrect. I changed it here:
>
>> DF
>  ID       FROM         TO  REASON
> 1  1 2015-02-27 2015-02-28 Holiday
> 2  1 2015-03-15 2015-03-20 Illness
> 3  2 2015-05-20 2015-05-23 Holiday
> 4  2 2015-06-01 2015-06-03 Holiday
> 5  2 2015-07-01 2015-07-01 Illness
>
> With that in place, you can use R's recycling of values to create multiple data frame rows from the date sequences and the single ID and REASON entries:
>
> i <- 1
>
>> data.frame(ID = DF$ID[i], DATE = seq(DF$FROM[i], DF$TO[i], by = "day"), REASON = DF$REASON[i])
>  ID       DATE  REASON
> 1  1 2015-02-27 Holiday
> 2  1 2015-02-28 Holiday
>
>
> So just put that into an lapply() based loop, which returns a list:
>
>> DF.TMP <- lapply(seq(nrow(DF)),
>                   function(i) data.frame(ID = DF$ID[i],
>                                          DATE = seq(DF$FROM[i], DF$TO[i], by = "day"),
>                                          REASON = DF$REASON[i]))
>
>> DF.TMP
> [[1]]
>  ID       DATE  REASON
> 1  1 2015-02-27 Holiday
> 2  1 2015-02-28 Holiday
>
> [[2]]
>  ID       DATE  REASON
> 1  1 2015-03-15 Illness
> 2  1 2015-03-16 Illness
> 3  1 2015-03-17 Illness
> 4  1 2015-03-18 Illness
> 5  1 2015-03-19 Illness
> 6  1 2015-03-20 Illness
>
> [[3]]
>  ID       DATE  REASON
> 1  2 2015-05-20 Holiday
> 2  2 2015-05-21 Holiday
> 3  2 2015-05-22 Holiday
> 4  2 2015-05-23 Holiday
>
> [[4]]
>  ID       DATE  REASON
> 1  2 2015-06-01 Holiday
> 2  2 2015-06-02 Holiday
> 3  2 2015-06-03 Holiday
>
> [[5]]
>  ID       DATE  REASON
> 1  2 2015-07-01 Illness
>
>
> Then use do.call() on the result:
>
>> do.call(rbind, DF.TMP)
>   ID       DATE  REASON
> 1   1 2015-02-27 Holiday
> 2   1 2015-02-28 Holiday
> 3   1 2015-03-15 Illness
> 4   1 2015-03-16 Illness
> 5   1 2015-03-17 Illness
> 6   1 2015-03-18 Illness
> 7   1 2015-03-19 Illness
> 8   1 2015-03-20 Illness
> 9   2 2015-05-20 Holiday
> 10  2 2015-05-21 Holiday
> 11  2 2015-05-22 Holiday
> 12  2 2015-05-23 Holiday
> 13  2 2015-06-01 Holiday
> 14  2 2015-06-02 Holiday
> 15  2 2015-06-03 Holiday
> 16  2 2015-07-01 Illness
>
>
> See ?seq.Date for the critical step.
>
> Regards,
>
> Marc Schwartz

Same thing, with some optional syntactic sugar:

library(dplyr)
dta <- read.table( text=
"ID     FROM         TO                REASON
1      2015-02-27   2015-02-28    Holiday
1      2015-03-15   2015-03-20    Illness
2      2015-05-20   2015-05-23    Holiday
2      2015-06-01   2015-06-03    Holiday
2      2015-07-01   2015-07-01    Illness
", header=TRUE, as.is=TRUE )

# Wrap function sequence in parentheses so pipes can be at beginning
# of line
(     dta
       # data not provided using dput, so date columns are character
   %>% mutate( FROM = as.Date(FROM)
             , TO = as.Date(TO)
             )
       # process data frame one row at a time
   %>% rowwise
       # form a new data frame using each row, results automatically
       # rbind()ed
   %>% do( data.frame( ID=.$ID
                     , DATE=seq.Date( .$FROM, .$TO, by="day" )
                     , REASON=.$REASON
                     , stringsAsFactors=FALSE
                     )
         )
       # optionally drop "data frame features" provided by dplyr to get
       # comparable result as above
   %>% as.data.frame
)

Read the dplyr and magrittr package help files to learn more about this 
method of handling data. I think Marc's solution is worth understanding 
because that is really what dplyr is doing for you, but it can get tedious 
to do that whole process yourself day-in and day-out.

Dplyr can also be used in conjunction with data.tables package or SQL, 
which can be good if you have a lot of data to work with... again, just 
syntactic sugar, but convenient.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jvadams at usgs.gov  Tue Dec  2 20:40:47 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 2 Dec 2014 13:40:47 -0600
Subject: [R] function to avoid <<-
In-Reply-To: <CALJKBv-He=6BDEKqqG=0GWH8Pu5wgwxwHiOm-Nwp2amsrar02w@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
	<CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
	<CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>
	<CAFEqCdy9vWXA0zXYiaVn5pg5-tT_gmx+R=bs=vBy4ywBA6bnKw@mail.gmail.com>
	<CALJKBv-He=6BDEKqqG=0GWH8Pu5wgwxwHiOm-Nwp2amsrar02w@mail.gmail.com>
Message-ID: <CAN5YmCGPHqxGin-1u_QG610NiL5N4+g5QXeX4f+qz5z6LkH=6w@mail.gmail.com>

Glad to see this query and the responses.  You all just helped me to
eliminate the use of global variables from my R package.  I knew they were
not recommended, but I didn't know how to get around using them.

Thanks!

Jean

On Tue, Dec 2, 2014 at 10:59 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> OK thanks as:
>
> myenv <- new.env(parent = emptyenv())
> fun <- function(){
> fun1 <- function(){
> myenv$X <- 5
> }
>
> }
> fun()
> ls(myenv)
> #X
> X
> #5
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Tue, Dec 2, 2014 at 5:47 PM, Greg Snow <538280 at gmail.com> wrote:
>
> > By "At the top level" Hadley meant to put that code outside of the
> > function definition.  In you source file that line should be very near
> the
> > top, before any function definitions.  Then "myenv" will not be temporary
> > (well it will go away when you end the R session).  Further, when this
> code
> > is compiled into a package then "myenv" becomes package local, meaning
> that
> > functions within the package can access it and the objects inside of it,
> > but it will not interfere with any other packages or the global
> environment.
> >
> > On Tue, Dec 2, 2014 at 9:32 AM, Karim Mezhoud <kmezhoud at gmail.com>
> wrote:
> >
> >> Thanks Dr Hadley,
> >>
> >> but when I use a function the myenv remains temporary and I am to face
> the
> >> same problem.
> >>
> >>
> >> fun <- function(){
> >>
> >> myenv <- new.env(parent = emptyenv())
> >>
> >> fun1 <- function(){
> >> myenv$X <- 5
> >> }
> >>
> >> }
> >>
> >> ls(myEnv)
> >> #character(0)
> >>
> >>   ?__
> >>  c/ /'_;~~~~kmezhoud
> >> (*) \(*)   ?????  ??????
> >> http://bioinformatics.tn/
> >>
> >>
> >>
> >> On Tue, Dec 2, 2014 at 4:17 PM, Hadley Wickham <h.wickham at gmail.com>
> >> wrote:
> >>
> >> > At the top level do:
> >> >
> >> > myenv <- new.env(parent = emptyenv())
> >> >
> >> > Then in your functions do
> >> >
> >> > myenv$x <- 50
> >> > myenv$x
> >> >
> >> > etc
> >> >
> >> > You also should not be using data() in that way. Perhaps you want
> >> > R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more
> details.
> >> >
> >> > Hadley
> >> >
> >> > On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com>
> >> wrote:
> >> > > Dear All,
> >> > >
> >> > > I am writing a GUIpackage that needs global variables.
> >> > > I had many warning message when I checked the code as for example:
> >> > > geteSet: no visible binding for global variable ?curselectCases?
> >> > > I would like to write a function that creates a global place for
> >> Objects
> >> > to
> >> > > be loaded as:
> >> > >
> >> > >
> >> > > Fun <- function(){
> >> > >
> >> > > Object <- 5
> >> > >
> >> > > Var2Global <- function(Object){
> >> > > .myDataEnv <- new.env(parent=emptyenv()) # not exported
> >> > > isLoaded <- function(Object) {
> >> > >     exists(Object, .myDataEnv)
> >> > > }
> >> > > getData <- function(Object) {
> >> > >     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
> >> > >     .myDataEnv[[Object]]
> >> > > }
> >> > > }
> >> > >
> >> > > }
> >> > >
> >> > > To avoid the use of:  Object <<- 5
> >> > >
> >> > > but it seems not working yet. Object == 5 is not a global variable
> >> after
> >> > > running Fun().
> >> > >
> >> > > Any Idea?
> >> > > Thanks
> >> > >   ?__
> >> > >  c/ /'_;~~~~kmezhoud
> >> > > (*) \(*)   ?????  ??????
> >> > > http://bioinformatics.tn/
> >> > >
> >> > >         [[alternative HTML version deleted]]
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> >
> >> >
> >> > --
> >> > http://had.co.nz/
> >> >
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> >
> > --
> > Gregory (Greg) L. Snow Ph.D.
> > 538280 at gmail.com
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From saxenasonalika12 at gmail.com  Tue Dec  2 20:01:10 2014
From: saxenasonalika12 at gmail.com (Sonika Saxena)
Date: Wed, 3 Dec 2014 00:31:10 +0530
Subject: [R] Regarding new version of R library
Message-ID: <CADGmOf6hg+1yUa8TvvwG7VOfTWqktFjceRHEN4jLzmxy8B2wuA@mail.gmail.com>

Respected Sir,
i am using library(galgo).But it is old version .i want to installed new
version for R 3.0 for windows 7.at the timing of installing this message
show this version not installing foe R 3.0,please re-installed ,so please
guide me how to installed this library.sir my project is paused that's why
please guide me.I  will be waiting your positive response.

-- 
*Sonika Saxena*

	[[alternative HTML version deleted]]


From dries-david at hotmail.com  Tue Dec  2 20:32:48 2014
From: dries-david at hotmail.com (Dries David)
Date: Tue, 2 Dec 2014 20:32:48 +0100
Subject: [R] FW: R Statistics
In-Reply-To: <547DF6C7.4070304@r-tutor.com>
References: <DUB124-W433ED6F408ECBBBC645DB0F57A0@phx.gbl>,
	<547DF6C7.4070304@r-tutor.com>
Message-ID: <DUB124-W52C56A1971F89D9EF44976F57A0@phx.gbl>


> > Hey
> > I have a question about making a new variable in R. I have put my dataset in attachment. I have to make a new variable "spits" where spits=morning when uurenminuut (also a variabel) is between 5.30 and 9.30, when uurenminuut is between 16.30 and 19.0 spits has to be equal to evening. But here is my problem: for all the values not between 5.30- 9.30 and 16.30-19.0 spits must be equal to "between"
> >   
> > achtergrond$minuutdec=achtergrond$minuut/100
> > achtergrond$uurenminuut=achtergrond$uur+achtergrond$minuutdec
> > achtergrond$spits=cut(uurenminuut,c(-1.0,5.30,9.30,16.30,19.0,24.0),labels=c("between","morning","between","evening","between"),right=FALSE)
> >   
> > When I do this i get a warning message, because I use between more than once as label. Between has to be one label that covers all values that are not in morning and evening.
> >   
> > Could you help me with this?
> >   
> > Kind regards
> >   
> > Dries David
> >   		 	   		
> 

 		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: achtergrondlawaai.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141202/847f419d/attachment.txt>

From wdunlap at tibco.com  Tue Dec  2 21:04:35 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Dec 2014 12:04:35 -0800
Subject: [R] FW: R Statistics
In-Reply-To: <DUB124-W52C56A1971F89D9EF44976F57A0@phx.gbl>
References: <DUB124-W433ED6F408ECBBBC645DB0F57A0@phx.gbl>
	<547DF6C7.4070304@r-tutor.com>
	<DUB124-W52C56A1971F89D9EF44976F57A0@phx.gbl>
Message-ID: <CAF8bMcY2n_Btb9vkGSxQjMPrBcACSWceqZcsk3yRdTcx2fKcyQ@mail.gmail.com>

You can do this in 2 steps - have cut() make a factor with a different
level for each time period
then use levels<-() to merge some of the levels.
   > z <- cut(.5:3.5, breaks=c(0,1,2,3,4), labels=c("0-1", "1-2", "2-3",
"3-4"))
   > levels(z)
   [1] "0-1" "1-2" "2-3" "3-4"
   > levels(z) <- c("between", "1-2", "between", "3-4") # or
levels(z)[c(1,3)] <- "between"
   > str(z)
   Factor w/ 3 levels "between","1-2",..: 1 2 1 3




Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Dec 2, 2014 at 11:32 AM, Dries David <dries-david at hotmail.com>
wrote:

>
> > > Hey
> > > I have a question about making a new variable in R. I have put my
> dataset in attachment. I have to make a new variable "spits" where
> spits=morning when uurenminuut (also a variabel) is between 5.30 and 9.30,
> when uurenminuut is between 16.30 and 19.0 spits has to be equal to
> evening. But here is my problem: for all the values not between 5.30- 9.30
> and 16.30-19.0 spits must be equal to "between"
> > >
> > > achtergrond$minuutdec=achtergrond$minuut/100
> > > achtergrond$uurenminuut=achtergrond$uur+achtergrond$minuutdec
> > >
> achtergrond$spits=cut(uurenminuut,c(-1.0,5.30,9.30,16.30,19.0,24.0),labels=c("between","morning","between","evening","between"),right=FALSE)
> > >
> > > When I do this i get a warning message, because I use between more
> than once as label. Between has to be one label that covers all values that
> are not in morning and evening.
> > >
> > > Could you help me with this?
> > >
> > > Kind regards
> > >
> > > Dries David
> > >
> >
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jecogeo at gmail.com  Tue Dec  2 21:26:02 2014
From: jecogeo at gmail.com (Jefferson Ferreira-Ferreira)
Date: Tue, 02 Dec 2014 20:26:02 +0000
Subject: [R] if else for cumulative sum error
References: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
	<CAAJSdji+4FPz2ZWbna6M6UTMkKSShBS33pLv=YQ3sisgjEGVLQ@mail.gmail.com>
Message-ID: <CAFFT+Y7juXZSV6mzoGt83k08ds1+h-kGysFEeS09O5GnjbA8SQ@mail.gmail.com>

Thank you for replies.

David,

I tried your modified form

for (i in 1:seq_along(rownames(dadosmax))){
  dadosmax$enchday[i] <- if ( (sum(dadosmax$above[i:(i+44)])) >= 45) 1 else
0
}

However, I'm receiving this warning:
Warning message:
In 1:seq_along(rownames(dadosmax)) :
  numerical expression has 2720 elements: only the first used

I can't figure out why only the first row was calculated...
Any ideas?



Em Tue Dec 02 2014 at 15:22:25, John McKown <john.archie.mckown at gmail.com>
escreveu:

> On Tue, Dec 2, 2014 at 12:08 PM, Jefferson Ferreira-Ferreira <
> jecogeo at gmail.com> wrote:
>
>> Hello everybody;
>>
>> I'm writing a code where part of it is as follows:
>>
>> for (i in nrow(dadosmax)){
>>   dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1 else 0
>> }
>>
>
> ?Without some test data for any validation, I would try the following
> formula
>
> dadosmax$enchday[i] <- if
> (sum(dadosmax$above[i:(min(i+44,nrow(dadosmax)))] >= 45) 1 else 0?
>
>
>
>>
>> That is for each row of my data frame, sum an specific column (0 or 1) of
>> that row plus 44 rows. If It is >=45 than enchday is 1 else 0.
>>
>> The following error is returned:
>>
>> Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
>>   missing value where TRUE/FALSE needed
>>
>> I've tested the ifelse statement assigning different values to i and it
>> works. So I'm wondering if this error is due the fact that at the final of
>> my data frame there aren't 45 rows to sum anymore. I tried to use "try"
>> but
>> It's simply hide the error.
>>
>> How can I deal with this? Any ideas?
>> Thank you very much.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> The temperature of the aqueous content of an unremittingly ogled
> culinary vessel will not achieve 100 degrees on the Celsius scale.
>
> Maranatha! <><
> John McKown
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Dec  2 21:49:38 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Dec 2014 12:49:38 -0800
Subject: [R] if else for cumulative sum error
In-Reply-To: <CAFFT+Y7juXZSV6mzoGt83k08ds1+h-kGysFEeS09O5GnjbA8SQ@mail.gmail.com>
References: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
	<CAAJSdji+4FPz2ZWbna6M6UTMkKSShBS33pLv=YQ3sisgjEGVLQ@mail.gmail.com>
	<CAFFT+Y7juXZSV6mzoGt83k08ds1+h-kGysFEeS09O5GnjbA8SQ@mail.gmail.com>
Message-ID: <44C52509-F974-4B87-BE71-6C9EDC7AFCF3@comcast.net>


On Dec 2, 2014, at 12:26 PM, Jefferson Ferreira-Ferreira wrote:

> Thank you for replies.
> 
> David,
> 
> I tried your modified form
> 
> for (i in 1:seq_along(rownames(dadosmax))){


No. it is either 1: .... or seq_along(...). in this case perhaps 1:(nrow(dadosmax)-44 would be safer

You do not seem to have understood that you cannot use an index of i+44 when i is going to be the entire set of rows of the dataframe. There is "no there there" to quote Gertrude Stein's slur against Oakland. In fact there is not there there at i+1 when you get to the end. You either need to only go to row

>  dadosmax$enchday[i] <- if ( (sum(dadosmax$above[i:(i+44)])) >= 45) 1 else
> 0
> }
> 
> However, I'm receiving this warning:
> Warning message:
> In 1:seq_along(rownames(dadosmax)) :
>  numerical expression has 2720 elements: only the first used
> 
> I can't figure out why only the first row was calculated...

You should of course read these, but the error is not from your if-statement but rahter you for-loop-indexing.

?'if'
?ifelse


> Any ideas?
> 
> 
> 
> Em Tue Dec 02 2014 at 15:22:25, John McKown <john.archie.mckown at gmail.com>
> escreveu:
> 
>> On Tue, Dec 2, 2014 at 12:08 PM, Jefferson Ferreira-Ferreira <
>> jecogeo at gmail.com> wrote:
>> 
>>> Hello everybody;
>>> 
>>> I'm writing a code where part of it is as follows:
>>> 
>>> for (i in nrow(dadosmax)){
>>>  dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1 else 0
>>> }
>>> 
>> 
>> ?Without some test data for any validation, I would try the following
>> formula
>> 
>> dadosmax$enchday[i] <- if
>> (sum(dadosmax$above[i:(min(i+44,nrow(dadosmax)))] >= 45) 1 else 0?
>> 
>> 
>> 
>>> 
>>> That is for each row of my data frame, sum an specific column (0 or 1) of
>>> that row plus 44 rows. If It is >=45 than enchday is 1 else 0.
>>> 
>>> The following error is returned:
>>> 
>>> Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
>>>  missing value where TRUE/FALSE needed
>>> 
>>> I've tested the ifelse statement assigning different values to i and it
>>> works. So I'm wondering if this error is due the fact that at the final of
>>> my data frame there aren't 45 rows to sum anymore. I tried to use "try"
>>> but
>>> It's simply hide the error.
>>> 
>>> How can I deal with this? Any ideas?
>>> Thank you very much.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> The temperature of the aqueous content of an unremittingly ogled
>> culinary vessel will not achieve 100 degrees on the Celsius scale.
>> 
>> Maranatha! <><
>> John McKown
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ramiro at precisionbioassay.com  Tue Dec  2 21:57:12 2014
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Tue, 2 Dec 2014 20:57:12 +0000
Subject: [R] How to have NLME return when convergence not reached
Message-ID: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>

Hello,

I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.

Thanks in advance,

Ramiro

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Dec  2 22:30:43 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 2 Dec 2014 13:30:43 -0800
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>

?try 
Or
?tryCatch

Bert

Sent from my iPhone -- please excuse typos.

> On Dec 2, 2014, at 12:57 PM, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
> 
> Hello,
> 
> I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.
> 
> Thanks in advance,
> 
> Ramiro
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From charles.santana at gmail.com  Tue Dec  2 22:43:01 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Tue, 2 Dec 2014 22:43:01 +0100
Subject: [R] Profiling a C/C++ library from R
Message-ID: <CAH-FEnhzH-n9Sx+DnF7fX0ehEUu3wPDqxDJgfOCu6f9bs+sSyA@mail.gmail.com>

Dear all,

I am running a c++ library (a .so file) from a R code. I am using the
function dyn.load("lib.so") to load the library. Do you know a way to
profile my C library from R? Or should I compile my C library as an
executable and profile it using the typical C-profilers?

Thanks in advance for any help!

Best,

Charles

-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Dec  2 22:49:20 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 2 Dec 2014 13:49:20 -0800
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <CAF8bMcYzpq3VsZ2ZQJkX0RyGsuP8kA9LJdCVnbz9kTfu2inPog@mail.gmail.com>

You could try using R.utils::withTimeout(expr, timeout=10) to cause an
error when evaluating the expression expr takes longer than 10 seconds.
Wrap that in tryCatch or try to catch the error and examine the outputs of
lapply for ones of class "TimeoutException" to find the ones that took too
long.

E.g.,
  >
  > system.time(z <- lapply(1:10, function(p)tryCatch(withTimeout(timeout=5,
  +     { for(i in seq_len(10^p))log(sqrt(i)) ; p }),
  +     error=function(e)e))
  + )
     user  system elapsed
   13.521   1.516  15.065
  > sapply(z, function(zi)class(zi)[1])
  [1] "integer"          "integer"          "integer"          "integer"
  [5] "integer"          "integer"          "integer"
 "TimeoutException"
  [9] "TimeoutException" "simpleError"
The first 7 iterations finished within 5 seconds, the next 2 timed out,
and the last had a different error (cannot allocate 74.5 Gb vector).

(R.utils's TimeoutException has an exceptionally long printout so I didn't
show the entire result.)



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Dec 2, 2014 at 12:57 PM, Ramiro Barrantes <
ramiro at precisionbioassay.com> wrote:

> Hello,
>
> I am trying to fit many hundreds of simulated datasets using NLME (it's
> all in a big loop in R).  Some don't seem to converge.  I am working on
> addressing the issues by perhaps adjusting my simulation, or tweaking
> iteration steps in nlme, etc.  However, when it doesn't converge, NLME just
> hangs, and my program either stalls for hours/days or takes over the
> computer memory and everything crashes eventually.  Is there a way to tell
> nlme to stop when it doesn't seem to be converging somehow?   I have been
> looking at the parameters in nlmeControl() but see nothing obvious.
>
> Thanks in advance,
>
> Ramiro
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ramiro at precisionbioassay.com  Tue Dec  2 22:59:46 2014
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Tue, 2 Dec 2014 21:59:46 +0000
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>,
	<348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>
Message-ID: <C7338A7EFF31BB4D831BB06C0088778979B45130@MBX023-W1-CA-2.exch023.domain.local>

Thanks so much for your reply.  I am using try but nlme never returns!!  and I think the process is getting killed by the system as it is taking over all the memory.  However, I do like William Dunlap's idea of using R.utils::withTimeout to limit the time.

Thanks again for your help!
________________________________________
From: Bert Gunter [gunter.berton at gene.com]
Sent: Tuesday, December 02, 2014 4:30 PM
To: Ramiro Barrantes
Cc: r-help at r-project.org
Subject: Re: [R] How to have NLME return when convergence not reached

?try
Or
?tryCatch

Bert

Sent from my iPhone -- please excuse typos.

> On Dec 2, 2014, at 12:57 PM, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
>
> Hello,
>
> I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.
>
> Thanks in advance,
>
> Ramiro
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ramiro at precisionbioassay.com  Tue Dec  2 22:59:58 2014
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Tue, 2 Dec 2014 21:59:58 +0000
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <CAF8bMcYzpq3VsZ2ZQJkX0RyGsuP8kA9LJdCVnbz9kTfu2inPog@mail.gmail.com>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>,
	<CAF8bMcYzpq3VsZ2ZQJkX0RyGsuP8kA9LJdCVnbz9kTfu2inPog@mail.gmail.com>
Message-ID: <C7338A7EFF31BB4D831BB06C0088778979B4513C@MBX023-W1-CA-2.exch023.domain.local>

Great suggestion!! Will give that a try.

________________________________
From: William Dunlap [wdunlap at tibco.com]
Sent: Tuesday, December 02, 2014 4:49 PM
To: Ramiro Barrantes
Cc: r-help at r-project.org
Subject: Re: [R] How to have NLME return when convergence not reached

You could try using R.utils::withTimeout(expr, timeout=10) to cause an error when evaluating the expression expr takes longer than 10 seconds.  Wrap that in tryCatch or try to catch the error and examine the outputs of lapply for ones of class "TimeoutException" to find the ones that took too long.

E.g.,
  >
  > system.time(z <- lapply(1:10, function(p)tryCatch(withTimeout(timeout=5,
  +     { for(i in seq_len(10^p))log(sqrt(i)) ; p }),
  +     error=function(e)e))
  + )
     user  system elapsed
   13.521   1.516  15.065
  > sapply(z, function(zi)class(zi)[1])
  [1] "integer"          "integer"          "integer"          "integer"
  [5] "integer"          "integer"          "integer"          "TimeoutException"
  [9] "TimeoutException" "simpleError"
The first 7 iterations finished within 5 seconds, the next 2 timed out,
and the last had a different error (cannot allocate 74.5 Gb vector).

(R.utils's TimeoutException has an exceptionally long printout so I didn't
show the entire result.)



Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Tue, Dec 2, 2014 at 12:57 PM, Ramiro Barrantes <ramiro at precisionbioassay.com<mailto:ramiro at precisionbioassay.com>> wrote:
Hello,

I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.

Thanks in advance,

Ramiro

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Dec  2 23:03:44 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 2 Dec 2014 14:03:44 -0800
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <C7338A7EFF31BB4D831BB06C0088778979B45130@MBX023-W1-CA-2.exch023.domain.local>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
	<348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>
	<C7338A7EFF31BB4D831BB06C0088778979B45130@MBX023-W1-CA-2.exch023.domain.local>
Message-ID: <CACk-te0Y39M0s+aBo0oA5gBDT3Wy95=zDAdL8A6LcPwJ8FWg+g@mail.gmail.com>

Yes, Bill almost always has helpful ideas.

Just a comment: If indeed the process is gobbling up too much memory,
that might indicate a problem with your function or implementation. I
defer to real experts on this, however.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Dec 2, 2014 at 1:59 PM, Ramiro Barrantes
<ramiro at precisionbioassay.com> wrote:
> Thanks so much for your reply.  I am using try but nlme never returns!!  and I think the process is getting killed by the system as it is taking over all the memory.  However, I do like William Dunlap's idea of using R.utils::withTimeout to limit the time.
>
> Thanks again for your help!
> ________________________________________
> From: Bert Gunter [gunter.berton at gene.com]
> Sent: Tuesday, December 02, 2014 4:30 PM
> To: Ramiro Barrantes
> Cc: r-help at r-project.org
> Subject: Re: [R] How to have NLME return when convergence not reached
>
> ?try
> Or
> ?tryCatch
>
> Bert
>
> Sent from my iPhone -- please excuse typos.
>
>> On Dec 2, 2014, at 12:57 PM, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
>>
>> Hello,
>>
>> I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.
>>
>> Thanks in advance,
>>
>> Ramiro
>>
>>    [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Dec  2 23:22:46 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 2 Dec 2014 22:22:46 +0000
Subject: [R] if else for cumulative sum error
In-Reply-To: <44C52509-F974-4B87-BE71-6C9EDC7AFCF3@comcast.net>
References: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
	<CAAJSdji+4FPz2ZWbna6M6UTMkKSShBS33pLv=YQ3sisgjEGVLQ@mail.gmail.com>
	<CAFFT+Y7juXZSV6mzoGt83k08ds1+h-kGysFEeS09O5GnjbA8SQ@mail.gmail.com>
	<44C52509-F974-4B87-BE71-6C9EDC7AFCF3@comcast.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FBC785@mb02.ads.tamu.edu>

Let's try a different approach. You don't need a loop for this. First we need a reproducible example:

> set.seed(42)
> dadosmax <- data.frame(above=runif(150) + .5)

Now compute your sums using cumsum() and diff() and then compute enchday using ifelse(). See the manual pages for each of these functions to understand how they work:

> sums <- diff(c(0, cumsum(dadosmax$above)), 45)
> dadosmax$enchday <- c(ifelse(sums >= 45, 1, 0), rep(NA, 44))

> dadosmax$enchday
  [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
 [26]  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
 [51]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
 [76]  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
[101]  1  1  1  1  1  1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
[126] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA

See the NA's? Those are what David Winsemius is talking about. For the 106th value, 106+44 is 150, but for the 107th value 107+144 is 151 which does not exist. Fortunately diff() understands that and stops at 106, but we have to add 44 NA's because that is the number of rows in your data frame.

You might find this plot informative as well:

> plot(sums, typ="l")
> abline(h=45)

Another way to get there is to use sapply() which will add the NA's for us:

> sums <- sapply(1:150, function(x) sum(dadosmax$above[x:(x+44)]))
> dadosmax$enchday <- ifelse(sums >= 45, 1, 0)

But it won't be as fast if you have a large data set.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
Sent: Tuesday, December 2, 2014 2:50 PM
To: Jefferson Ferreira-Ferreira
Cc: r-help at r-project.org
Subject: Re: [R] if else for cumulative sum error


On Dec 2, 2014, at 12:26 PM, Jefferson Ferreira-Ferreira wrote:

> Thank you for replies.
> 
> David,
> 
> I tried your modified form
> 
> for (i in 1:seq_along(rownames(dadosmax))){


No. it is either 1: .... or seq_along(...). in this case perhaps 1:(nrow(dadosmax)-44 would be safer

You do not seem to have understood that you cannot use an index of i+44 when i is going to be the entire set of rows of the dataframe. There is "no there there" to quote Gertrude Stein's slur against Oakland. In fact there is not there there at i+1 when you get to the end. You either need to only go to row

>  dadosmax$enchday[i] <- if ( (sum(dadosmax$above[i:(i+44)])) >= 45) 1 else
> 0
> }
> 
> However, I'm receiving this warning:
> Warning message:
> In 1:seq_along(rownames(dadosmax)) :
>  numerical expression has 2720 elements: only the first used
> 
> I can't figure out why only the first row was calculated...

You should of course read these, but the error is not from your if-statement but rahter you for-loop-indexing.

?'if'
?ifelse


> Any ideas?
> 
> 
> 
> Em Tue Dec 02 2014 at 15:22:25, John McKown <john.archie.mckown at gmail.com>
> escreveu:
> 
>> On Tue, Dec 2, 2014 at 12:08 PM, Jefferson Ferreira-Ferreira <
>> jecogeo at gmail.com> wrote:
>> 
>>> Hello everybody;
>>> 
>>> I'm writing a code where part of it is as follows:
>>> 
>>> for (i in nrow(dadosmax)){
>>>  dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1 else 0
>>> }
>>> 
>> 
>> ?Without some test data for any validation, I would try the following
>> formula
>> 
>> dadosmax$enchday[i] <- if
>> (sum(dadosmax$above[i:(min(i+44,nrow(dadosmax)))] >= 45) 1 else 0?
>> 
>> 
>> 
>>> 
>>> That is for each row of my data frame, sum an specific column (0 or 1) of
>>> that row plus 44 rows. If It is >=45 than enchday is 1 else 0.
>>> 
>>> The following error is returned:
>>> 
>>> Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
>>>  missing value where TRUE/FALSE needed
>>> 
>>> I've tested the ifelse statement assigning different values to i and it
>>> works. So I'm wondering if this error is due the fact that at the final of
>>> my data frame there aren't 45 rows to sum anymore. I tried to use "try"
>>> but
>>> It's simply hide the error.
>>> 
>>> How can I deal with this? Any ideas?
>>> Thank you very much.
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> The temperature of the aqueous content of an unremittingly ogled
>> culinary vessel will not achieve 100 degrees on the Celsius scale.
>> 
>> Maranatha! <><
>> John McKown
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From mtmorgan at fredhutch.org  Wed Dec  3 00:02:24 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Tue, 02 Dec 2014 15:02:24 -0800
Subject: [R] Profiling a C/C++ library from R
In-Reply-To: <CAH-FEnhzH-n9Sx+DnF7fX0ehEUu3wPDqxDJgfOCu6f9bs+sSyA@mail.gmail.com>
References: <CAH-FEnhzH-n9Sx+DnF7fX0ehEUu3wPDqxDJgfOCu6f9bs+sSyA@mail.gmail.com>
Message-ID: <547E4500.6050300@fredhutch.org>

On 12/02/2014 01:43 PM, Charles Novaes de Santana wrote:
> Dear all,
>
> I am running a c++ library (a .so file) from a R code. I am using the
> function dyn.load("lib.so") to load the library. Do you know a way to
> profile my C library from R? Or should I compile my C library as an
> executable and profile it using the typical C-profilers?
>
> Thanks in advance for any help!

Hi Charles

Section 3.4 of RShowDoc("R-exts") discusses some options; I've had luck with 
operf & friends. Remember to compile without optimizations and with debugging 
information -ggdb -O0.

(I think this is appropriate for the R-devel mailing list 
http://www.r-project.org/posting-guide.html#which_list)

Martin Morgan

>
> Best,
>
> Charles
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From murdoch.duncan at gmail.com  Wed Dec  3 00:03:21 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 02 Dec 2014 18:03:21 -0500
Subject: [R] Profiling a C/C++ library from R
In-Reply-To: <CAH-FEnhzH-n9Sx+DnF7fX0ehEUu3wPDqxDJgfOCu6f9bs+sSyA@mail.gmail.com>
References: <CAH-FEnhzH-n9Sx+DnF7fX0ehEUu3wPDqxDJgfOCu6f9bs+sSyA@mail.gmail.com>
Message-ID: <547E4539.6040303@gmail.com>

On 02/12/2014, 4:43 PM, Charles Novaes de Santana wrote:
> Dear all,
> 
> I am running a c++ library (a .so file) from a R code. I am using the
> function dyn.load("lib.so") to load the library. Do you know a way to
> profile my C library from R? Or should I compile my C library as an
> executable and profile it using the typical C-profilers?
> 
> Thanks in advance for any help!

If you want line-level profiling of your C++ code, you'll certainly need
to use something that's not built in to R.  You can probably do it
without recompiling your C++ code, just by profiling the R process.  But
the details certainly depend on the profiler you choose to use.

If you just want to know how much time is being spent in each C++
function called from R, Rprof() should be able to tell you.  (It might
give misleading information if your C++ code takes too long to execute,
and some timer ticks get lost; I'm not sure if the underlying code takes
account of that.)

Duncan Murdoch


From silong.liao at hotmail.com  Wed Dec  3 00:27:18 2014
From: silong.liao at hotmail.com (Silong Liao)
Date: Tue, 2 Dec 2014 23:27:18 +0000
Subject: [R] Add group name in barchart
In-Reply-To: <44730b$24h64a@mail78-12.dmzglobal.net>
References: <44730b$24h64a@mail78-12.dmzglobal.net>
Message-ID: <DUB122-W4540DD9DD8A3F734EC4699FA7A0@phx.gbl>

Dear ALL,
 
I have a dataset contains 2 variables: mate (mating groups) and ratio (ratio of number of mothers and fathers). And mate is an identifer which consists three components: year, flock (flk), and tag.
 
I am using command "barchart" under package "lattice" to generate plots of ratio against mate divided by each flock (See attachment). I want to put flock names onto the corresponding plots, but don't know how.
 
Cheers, Sid
 
load("ratiodata.Rdata")
attach(ratiodata)
head(ratiodata)
 
        mate    ratio1 2007.102.A 21.285712 2007.102.B 68.200003 2007.102.C 59.500004 2007.102.D 19.333335 2007.102.E 72.333336 2007.102.F 35.50000 
str(ratiodata$mate) #factor
str(ratiodata$ratio) #num
unique(ratiodata$flk)
 
[1]  102    2 2744 2747 2749  391 4357 4880 3001 3003 3004 3855 3658 4588 4591 4631 
library("lattice")
ratiodata$flk=read.table(text=as.character(ratiodata$mate),sep=".")[,2]
barchart(ratiodata$ratio~ratiodata$mate|ratiodata$flk)
 
 
 		 	   		  

From jdnewmil at dcn.davis.CA.us  Wed Dec  3 04:16:46 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 02 Dec 2014 19:16:46 -0800
Subject: [R] Regarding new version of R library
In-Reply-To: <CADGmOf6hg+1yUa8TvvwG7VOfTWqktFjceRHEN4jLzmxy8B2wuA@mail.gmail.com>
References: <CADGmOf6hg+1yUa8TvvwG7VOfTWqktFjceRHEN4jLzmxy8B2wuA@mail.gmail.com>
Message-ID: <095B030D-6FD8-4AC9-9A79-70A578E3E587@dcn.davis.CA.us>

I suggest that you contact the maintainer of that package, who should be identified by using the maintainer function (see ?maintainer) or on the website where you obtained it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 2, 2014 11:01:10 AM PST, Sonika Saxena <saxenasonalika12 at gmail.com> wrote:
>Respected Sir,
>i am using library(galgo).But it is old version .i want to installed
>new
>version for R 3.0 for windows 7.at the timing of installing this
>message
>show this version not installing foe R 3.0,please re-installed ,so
>please
>guide me how to installed this library.sir my project is paused that's
>why
>please guide me.I  will be waiting your positive response.


From maechler at stat.math.ethz.ch  Wed Dec  3 09:26:21 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 3 Dec 2014 09:26:21 +0100
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <CACk-te0Y39M0s+aBo0oA5gBDT3Wy95=zDAdL8A6LcPwJ8FWg+g@mail.gmail.com>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
	<348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>
	<C7338A7EFF31BB4D831BB06C0088778979B45130@MBX023-W1-CA-2.exch023.domain.local>
	<CACk-te0Y39M0s+aBo0oA5gBDT3Wy95=zDAdL8A6LcPwJ8FWg+g@mail.gmail.com>
Message-ID: <21630.51501.637914.723727@stat.math.ethz.ch>

>>>>> Bert Gunter <gunter.berton at gene.com>
>>>>>     on Tue, 2 Dec 2014 14:03:44 -0800 writes:

    > Yes, Bill almost always has helpful ideas.
    > Just a comment: If indeed the process is gobbling up too much memory,
    > that might indicate a problem with your function or implementation. I
    > defer to real experts on this, however.

    > Cheers,
    > Bert

    > Bert Gunter
    > Genentech Nonclinical Biostatistics
    > (650) 467-7374


Yes, thank you Bert, it could be entirely Ramiro's function, but
we don't know as you have not given any indication about what
the non-linear function is in your nlme() formula.

The little you wrote _seems_ to indicate a bug in nlme, and if
that was the case, the bug should be reported and fixed,
and we (R core - the maintainer of the recommended package nlme)
would really like to to get a reproducible example.

If OTOH, it is your nonlinear function that "goes haywire", 
the implicit blame on nlme would not be warranted.

Martin Maechler, 
ETH Zurich and R Core team


    > On Tue, Dec 2, 2014 at 1:59 PM, Ramiro Barrantes
    > <ramiro at precisionbioassay.com> wrote:
    >> Thanks so much for your reply.  I am using try but nlme never returns!!  and I think the process is getting killed by the system as it is taking over all the memory.  However, I do like William Dunlap's idea of using R.utils::withTimeout to limit the time.
    >> 
    >> Thanks again for your help!
    >> ________________________________________
    >> From: Bert Gunter [gunter.berton at gene.com]
    >> Sent: Tuesday, December 02, 2014 4:30 PM
    >> To: Ramiro Barrantes
    >> Cc: r-help at r-project.org
    >> Subject: Re: [R] How to have NLME return when convergence not reached
    >> 
    >> ?try
    >> Or
    >> ?tryCatch
    >> 
    >> Bert
    >> 
    >> Sent from my iPhone -- please excuse typos.
    >> 
    >>> On Dec 2, 2014, at 12:57 PM, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
    >>> 
    >>> Hello,
    >>> 
    >>> I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.
    >>> 
    >>> Thanks in advance,
    >>> 
    >>> Ramiro
    >>> 
    >>> [[alternative HTML version deleted]]
    >>> 
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From katherine_gobin at yahoo.com  Wed Dec  3 10:03:06 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Wed, 3 Dec 2014 09:03:06 +0000 (UTC)
Subject: [R] lmom package
Message-ID: <381778580.2795341.1417597386539.JavaMail.yahoo@jws10972.mail.sg3.yahoo.com>

Dear R Forum
I have a set of data say as given below and as an exercise of trying to fit statistical distribution to this data, I am estimating parameters.?
amounts = ?c(38572.5599129508,11426.6705314315,21974.1571641187,118530.32782443,3735.43055996748,66309.5211176106,72039.2934132668,21934.8841708626,78564.9136114375,1703.65825161293,2116.89180930203,11003.495671332,19486.3296339113,1871.35861218795,6887.53851253407,148900.978055447,7078.56497101651,79348.1239806592,20157.6241066905,1259.99802108593,3934.45912233674,3297.69946631591,56221.1154121067,13322.0705174134,45110.2498756567,31910.3686613912,3196.71168501252,32843.0140437202,14615.1499458453,13013.9915051561,116104.176753387,7229.03056392023,9833.37962177814,2882.63239493673,165457.372543821,41114.066453219,47188.1677766245,25708.5883755617,82703.7378298092,8845.04197017415,844.28834047836,35410.8486123933,19446.3808445684,17662.2398792892,11882.8497070776,4277181.17817307,30239.0371267968,45165.7512343364,22102.8513746687,5988.69296597127,51345.0146170238,1275658.35495898,15260.4892854214,8861.76578480635,37647.1638704867,4979.53544046949,7012.48134772332,3385.20612391205,1911.03114395959,66886.5036605189,2223.47536156462,814.947809578378,234.028589468841,5397.4347625133,13346.3226579065,28809.3901352898,6387.69226236731,5639.42730553242,2011100.92675507,4150.63707173462,34098.7514446498,3437.10672573502,289710.315303182,8664.66947305203,13813.3867161134,208817.521491857,169317.624400274,9966.78447705792,37811.1721605562,2263.19211279927,80434.5581206454,19057.8093104899,24664.5067589624,25136.5042354789,3582.85741610706,6683.13898432794,65423.9991390846,134848.302304064,3018.55371579808,546249.641168158,172926.689143006,3074.15064180208,1521.70624812788,59012.4248281661,21226.928522236,17572.5682970983,226.646947337851,56232.2982652019,14641.0043361533,6997.94414914865)
library(lmom)lmom   ? ? ? ? <- samlmu(amounts)

# ____________________________________________________
# Normal distribution
parameters_of_NOR ?<- pelnor(lmom); parameters_of_NOR

> parameters_of_NOR ?<- pelnor(lmom); parameters_of_NOR? ? ? mu ? ? ? ?sigma?115148.4 ?175945.8?

# Minitab and SPSS parameter values? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Location ? ? ? ? ? ? ? ? ? ?Scale
Minitab ? ? ? ? ? ? ?115148.4 ? ? ? ? ? ? ? ? 485173SPSS ? ? ? ? ? ? ? ? 115148.4 ? ? ? ? ? ? ? ? 485173 ? ? ? ? ??
# __________________________________________________________

# Log normal 3 parameter distribution?parameters_of_LN3 ?<- pelln3(lmom); parameters_of_LN3

> parameters_of_LN3 ?<- pelln3(lmom); parameters_of_LN3
? ? ? ?zeta ? ? ? ? ? ? ?mu ? ? ? ? ? ? ? ?sigma?3225.798890 ? ?9.114879 ? ? 2.240841
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?Location ? ? ? ? ? ? Scale ? ? ? ? ? ? ? ? ?ShapeMinitab ? ? ? ? ? ? ? ? ?9.73361 ? ? ? ? ? ? 1.76298 ? ? ? ? ? ? ? 75.51864SPSS ? ? ? ? ? ? ? ? ? ?9.7336 ? ? ? ? ? ? ? ?1.763 ? ? ? ? ? ? ? ? ? ?75.519 ? ? ? ??

Similarly besides Generalized extreme Value distribution, all the parameter values vary significantly than parameter values obtained using Minitab and SPSS. In case of Normal distribution, the dispersion parameter is simply sample standard deviation and excel also gives the parameter value 485172.8 and varies significantly than what we get from R.
And parameter values do differ even for many other distributions too viz. Gamma distribution etc.
Is there any different algorithm or logic used in R? Can someone please guide.?
Regards
Katherine


	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Dec  3 10:27:59 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 3 Dec 2014 10:27:59 +0100
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <21630.51501.637914.723727@stat.math.ethz.ch>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
	<348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>
	<C7338A7EFF31BB4D831BB06C0088778979B45130@MBX023-W1-CA-2.exch023.domain.local>
	<CACk-te0Y39M0s+aBo0oA5gBDT3Wy95=zDAdL8A6LcPwJ8FWg+g@mail.gmail.com>
	<21630.51501.637914.723727@stat.math.ethz.ch>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730EFCBB02F7@UM-MAIL4112.unimaas.nl>

Here is a reproducible bug in nlme (reported in 2008) that still crashes R today:

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001425.html

Seems to be related to memory corruption (as diagnosed by Martin and William Dunlap at the time):

https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001429.html
https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q3/001431.html

I don't know if that is related to the present case, but it sounds a bit like it.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin
> Maechler
> Sent: Wednesday, December 03, 2014 09:26
> To: Bert Gunter
> Cc: r-help at r-project.org; Ramiro Barrantes
> Subject: Re: [R] How to have NLME return when convergence not reached
> 
> >>>>> Bert Gunter <gunter.berton at gene.com>
> >>>>>     on Tue, 2 Dec 2014 14:03:44 -0800 writes:
> 
>     > Yes, Bill almost always has helpful ideas.
>     > Just a comment: If indeed the process is gobbling up too much
> memory,
>     > that might indicate a problem with your function or implementation.
> I
>     > defer to real experts on this, however.
> 
>     > Cheers,
>     > Bert
> 
>     > Bert Gunter
>     > Genentech Nonclinical Biostatistics
>     > (650) 467-7374
> 
> 
> Yes, thank you Bert, it could be entirely Ramiro's function, but
> we don't know as you have not given any indication about what
> the non-linear function is in your nlme() formula.
> 
> The little you wrote _seems_ to indicate a bug in nlme, and if
> that was the case, the bug should be reported and fixed,
> and we (R core - the maintainer of the recommended package nlme)
> would really like to to get a reproducible example.
> 
> If OTOH, it is your nonlinear function that "goes haywire",
> the implicit blame on nlme would not be warranted.
> 
> Martin Maechler,
> ETH Zurich and R Core team
> 
> 
>     > On Tue, Dec 2, 2014 at 1:59 PM, Ramiro Barrantes
>     > <ramiro at precisionbioassay.com> wrote:
>     >> Thanks so much for your reply.  I am using try but nlme never
> returns!!  and I think the process is getting killed by the system as it
> is taking over all the memory.  However, I do like William Dunlap's idea
> of using R.utils::withTimeout to limit the time.
>     >>
>     >> Thanks again for your help!
>     >> ________________________________________
>     >> From: Bert Gunter [gunter.berton at gene.com]
>     >> Sent: Tuesday, December 02, 2014 4:30 PM
>     >> To: Ramiro Barrantes
>     >> Cc: r-help at r-project.org
>     >> Subject: Re: [R] How to have NLME return when convergence not
> reached
>     >>
>     >> ?try
>     >> Or
>     >> ?tryCatch
>     >>
>     >> Bert
>     >>
>     >> Sent from my iPhone -- please excuse typos.
>     >>
>     >>> On Dec 2, 2014, at 12:57 PM, Ramiro Barrantes
> <ramiro at precisionbioassay.com> wrote:
>     >>>
>     >>> Hello,
>     >>>
>     >>> I am trying to fit many hundreds of simulated datasets using NLME
> (it's all in a big loop in R).  Some don't seem to converge.  I am
> working on addressing the issues by perhaps adjusting my simulation, or
> tweaking iteration steps in nlme, etc.  However, when it doesn't
> converge, NLME just hangs, and my program either stalls for hours/days or
> takes over the computer memory and everything crashes eventually.  Is
> there a way to tell nlme to stop when it doesn't seem to be converging
> somehow?   I have been looking at the parameters in nlmeControl() but see
> nothing obvious.
>     >>>
>     >>> Thanks in advance,
>     >>>
>     >>> Ramiro


From katherine_gobin at yahoo.com  Wed Dec  3 10:45:43 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Wed, 3 Dec 2014 09:45:43 +0000 (UTC)
Subject: [R] lmom package - Resending the email
Message-ID: <969494576.2824738.1417599943152.JavaMail.yahoo@jws10980.mail.sg3.yahoo.com>

Dear R forum
I sincerely apologize as my earlier mail with the captioned subject, since all the values got mixed up and the email is not readable.?I am trying to write it again.?
My problem is I have a set of data and I am trying to fit some distributions to it. As a part of this exercise, I need to find out the parameter values of various distributions e.g. Normal distribution, Log normal distribution etc. I am using lmom package to do the same, however the parameter values obtained using lmom pacakge differ to a large extent from the parameter values obtained using say MINITAB and SPSS as given below -
_____________________________________________

amounts = ?c(38572.5599129508,11426.6705314315,21974.1571641187,118530.32782443,3735.43055996748,66309.5211176106,72039.2934132668,21934.8841708626,78564.9136114375,1703.65825161293,2116.89180930203,11003.495671332,19486.3296339113,1871.35861218795,6887.53851253407,148900.978055447,7078.56497101651,79348.1239806592,20157.6241066905,1259.99802108593,3934.45912233674,3297.69946631591,56221.1154121067,13322.0705174134,45110.2498756567,31910.3686613912,3196.71168501252,32843.0140437202,14615.1499458453,13013.9915051561,116104.176753387,7229.03056392023,9833.37962177814,2882.63239493673,165457.372543821,41114.066453219,47188.1677766245,25708.5883755617,82703.7378298092,8845.04197017415,844.28834047836,35410.8486123933,19446.3808445684,17662.2398792892,11882.8497070776,4277181.17817307,30239.0371267968,45165.7512343364,22102.8513746687,5988.69296597127,51345.0146170238,1275658.35495898,15260.4892854214,8861.76578480635,37647.1638704867,4979.53544046949,7012.48134772332,3385.20612391205,1911.03114395959,66886.5036605189,2223.47536156462,814.947809578378,234.028589468841,5397.4347625133,13346.3226579065,28809.3901352898,6387.69226236731,5639.42730553242,2011100.92675507,4150.63707173462,34098.7514446498,3437.10672573502,289710.315303182,8664.66947305203,13813.3867161134,208817.521491857,169317.624400274,9966.78447705792,37811.1721605562,2263.19211279927,80434.5581206454,19057.8093104899,24664.5067589624,25136.5042354789,3582.85741610706,6683.13898432794,65423.9991390846,134848.302304064,3018.55371579808,546249.641168158,172926.689143006,3074.15064180208,1521.70624812788,59012.4248281661,21226.928522236,17572.5682970983,226.646947337851,56232.2982652019,14641.0043361533,6997.94414914865)

library(lmom)
lmom ?= ?samlmu(amounts)
# __________________________________________________________________
# Normal Distribution parameters
parameters_of_NOR ?<- pelnor(lmom); parameters_of_NOR

? ? ? mu ? ? ? ? ?sigma?115148.4 ? ?175945.8
? ? ? ? ? ? ? ? ? ? ? Location ? ? ? Scale ? ??Minitab ? ? ? ??115148.4 ? ??485173SPSS ? ? ? ? ??115148.4 ? ??485173
# __________________________________________________________________
# Log Normal (3 Parameter) Distribution parameters
? ? ? ?zeta ? ? ? ? ? ? ? ?mu ? ? ? ? ? ? ? sigma?3225.798890 ? ?9.114879 ? ? ?2.240841
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Location ? ? ? ? ? ?Scale ? ? ? ? ? Shape
MINITAB ? ? ? ? ? ? ? 9.73361 ? ? ? ? ? ? 1.76298 ? ? ?75.51864SPSS ? ? ? ? ? ? ? ? ? ?9.7336 ? ? ? ? ? ? ? ?1.763 ? ? ? ? ?75.519? ? ? ? ???# __________________________________________________________________

Besides Genaralized extreme Value distributions, all the other distributions e.g. Gamma, Exponential (2 parameter) distributions etc give different results than MINITAB and SPSS.
Can some one guide me?

Regards
Katherine











































	[[alternative HTML version deleted]]


From szehnder at uni-bonn.de  Wed Dec  3 10:57:13 2014
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Wed, 3 Dec 2014 10:57:13 +0100
Subject: [R] lmom package - Resending the email
In-Reply-To: <969494576.2824738.1417599943152.JavaMail.yahoo@jws10980.mail.sg3.yahoo.com>
References: <969494576.2824738.1417599943152.JavaMail.yahoo@jws10980.mail.sg3.yahoo.com>
Message-ID: <844CA46E-B55F-4E5B-BCFA-C11D1C025C7D@uni-bonn.de>

Katherine,

for a deeper understanding of differing values it makes sense to provide the list at least with an online description of the corresponding functions used in Minitab and SPSS?

Best 
Simon
On 03 Dec 2014, at 10:45, Katherine Gobin via R-help <r-help at r-project.org> wrote:

> Dear R forum
> I sincerely apologize as my earlier mail with the captioned subject, since all the values got mixed up and the email is not readable. I am trying to write it again. 
> My problem is I have a set of data and I am trying to fit some distributions to it. As a part of this exercise, I need to find out the parameter values of various distributions e.g. Normal distribution, Log normal distribution etc. I am using lmom package to do the same, however the parameter values obtained using lmom pacakge differ to a large extent from the parameter values obtained using say MINITAB and SPSS as given below -
> _____________________________________________
> 
> amounts =  c(38572.5599129508,11426.6705314315,21974.1571641187,118530.32782443,3735.43055996748,66309.5211176106,72039.2934132668,21934.8841708626,78564.9136114375,1703.65825161293,2116.89180930203,11003.495671332,19486.3296339113,1871.35861218795,6887.53851253407,148900.978055447,7078.56497101651,79348.1239806592,20157.6241066905,1259.99802108593,3934.45912233674,3297.69946631591,56221.1154121067,13322.0705174134,45110.2498756567,31910.3686613912,3196.71168501252,32843.0140437202,14615.1499458453,13013.9915051561,116104.176753387,7229.03056392023,9833.37962177814,2882.63239493673,165457.372543821,41114.066453219,47188.1677766245,25708.5883755617,82703.7378298092,8845.04197017415,844.28834047836,35410.8486123933,19446.3808445684,17662.2398792892,11882.8497070776,4277181.17817307,30239.0371267968,45165.7512343364,22102.8513746687,5988.69296597127,51345.0146170238,1275658.35495898,15260.4892854214,8861.76578480635,37647.1638704867,4979.53544046949,7012.48134772332,3385.20612391205,1911.03114395959,66886.5036605189,2223.47536156462,814.947809578378,234.028589468841,5397.4347625133,13346.3226579065,28809.3901352898,6387.69226236731,5639.42730553242,2011100.92675507,4150.63707173462,34098.7514446498,3437.10672573502,289710.315303182,8664.66947305203,13813.3867161134,208817.521491857,169317.624400274,9966.78447705792,37811.1721605562,2263.19211279927,80434.5581206454,19057.8093104899,24664.5067589624,25136.5042354789,3582.85741610706,6683.13898432794,65423.9991390846,134848.302304064,3018.55371579808,546249.641168158,172926.689143006,3074.15064180208,1521.70624812788,59012.4248281661,21226.928522236,17572.5682970983,226.646947337851,56232.2982652019,14641.0043361533,6997.94414914865)
> 
> library(lmom)
> lmom  =  samlmu(amounts)
> # __________________________________________________________________
> # Normal Distribution parameters
> parameters_of_NOR  <- pelnor(lmom); parameters_of_NOR
> 
>       mu          sigma 115148.4    175945.8
>                       Location       Scale     Minitab         115148.4     485173SPSS           115148.4     485173
> # __________________________________________________________________
> # Log Normal (3 Parameter) Distribution parameters
>        zeta                mu               sigma 3225.798890    9.114879      2.240841
>                               Location            Scale           Shape
> MINITAB               9.73361             1.76298      75.51864SPSS                    9.7336                1.763          75.519           # __________________________________________________________________
> 
> Besides Genaralized extreme Value distributions, all the other distributions e.g. Gamma, Exponential (2 parameter) distributions etc give different results than MINITAB and SPSS.
> Can some one guide me?
> 
> Regards
> Katherine
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Wed Dec  3 12:57:27 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 03 Dec 2014 11:57:27 +0000
Subject: [R] Add group name in barchart
In-Reply-To: <DUB122-W4540DD9DD8A3F734EC4699FA7A0@phx.gbl>
References: <44730b$24h64a@mail78-12.dmzglobal.net>
	<DUB122-W4540DD9DD8A3F734EC4699FA7A0@phx.gbl>
Message-ID: <547EFAA7.2090805@aghmed.fsnet.co.uk>

Comments in line

On 02/12/2014 23:27, Silong Liao wrote:
> Dear ALL,
>
> I have a dataset contains 2 variables: mate (mating groups) and ratio (ratio of number of mothers and fathers). And mate is an identifer which consists three components: year, flock (flk), and tag.
>
> I am using command "barchart" under package "lattice" to generate plots of ratio against mate divided by each flock (See attachment). I want to put flock names onto the corresponding plots, but don't know how.
>
> Cheers, Sid
>
> load("ratiodata.Rdata")
> attach(ratiodata)

in general it is a bad idea to use attach, use the data= parameter if 
available.

> head(ratiodata)
>
>          mate    ratio1 2007.102.A 21.285712 2007.102.B 68.200003 2007.102.C 59.500004 2007.102.D 19.333335 2007.102.E 72.333336 2007.102.F 35.50000
> str(ratiodata$mate) #factor
> str(ratiodata$ratio) #num
> unique(ratiodata$flk)
>
> [1]  102    2 2744 2747 2749  391 4357 4880 3001 3003 3004 3855 3658 4588 4591 4631
> library("lattice")
> ratiodata$flk=read.table(text=as.character(ratiodata$mate),sep=".")[,2]

So what did this give you for flk?

> barchart(ratiodata$ratio~ratiodata$mate|ratiodata$flk)

This could be

barchart(ratio ~ mate | flk, data = ratiodata)

which is much easier to read.
So what did it label the panels with?

>
>
>   		 	   		
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4235/8673 - Release Date: 12/03/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From bodenhofer at bioinf.jku.at  Wed Dec  3 13:17:33 2014
From: bodenhofer at bioinf.jku.at (Ulrich Bodenhofer)
Date: Wed, 03 Dec 2014 13:17:33 +0100
Subject: [R] Version 1.4.0 of the 'apcluster' package
Message-ID: <547EFF5D.6030500@bioinf.jku.at>

Dear colleagues,

This is to inform you that Version 1.4.0 of the R package 'apcluster' 
has been released on CRAN earlier this week. This is a major release 
that - apart from other important improvements - fulfills a long-term 
user request: the genuine support of sparse similarity matrices. For 
more details, see the package documentation and the following URLs:

http://www.bioinf.jku.at/software/apcluster/
http://cran.r-project.org/web/packages/apcluster/index.html


Best regards,
Ulrich Bodenhofer


------------------------------------------------------------------------
*Dr. Ulrich Bodenhofer*
Associate Professor
Institute of Bioinformatics

*Johannes Kepler University*
Altenberger Str. 69
4040 Linz, Austria

Tel. +43 732 2468 4526
Fax +43 732 2468 4539
bodenhofer at bioinf.jku.at <mailto:bodenhofer at bioinf.jku.at>
http://www.bioinf.jku.at/ <http://www.bioinf.jku.at>


From pmassicotte at hotmail.com  Wed Dec  3 13:37:56 2014
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Wed, 3 Dec 2014 12:37:56 +0000
Subject: [R] Substitute initial guesses of parameters in a function
Message-ID: <COL127-W44971419BCAF7E10D1F586B37B0@phx.gbl>

Hi everyone, I have a formula like this:

f <- as.formula(y ~ p0a * exp(-0.5 * ((x - p1a)/p2a)^2))

I would like to "dynamically" provide starting values for p0a, p1a, p2a. Is there a way to do it?

#Params estimates
p <- c(12, 10, 1)

# This is where I have difficulties
mystart <- substitute(...)

nls(formula = f, start = mystart)

Regards,
Philippe
 		 	   		  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Dec  3 14:02:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 03 Dec 2014 08:02:17 -0500
Subject: [R] Substitute initial guesses of parameters in a function
In-Reply-To: <COL127-W44971419BCAF7E10D1F586B37B0@phx.gbl>
References: <COL127-W44971419BCAF7E10D1F586B37B0@phx.gbl>
Message-ID: <547F09D9.9050707@gmail.com>

On 03/12/2014 7:37 AM, philippe massicotte wrote:
> Hi everyone, I have a formula like this:
>
> f <- as.formula(y ~ p0a * exp(-0.5 * ((x - p1a)/p2a)^2))
>
> I would like to "dynamically" provide starting values for p0a, p1a, p2a. Is there a way to do it?

Just give a named vector of starting values.
>
> #Params estimates
> p <- c(12, 10, 1)

Should be p <- c(p0a = 12, p1a = 10, p2a = 1)
>
> # This is where I have difficulties
> mystart <- substitute(...)
>
> nls(formula = f, start = mystart)

Now start = p will work.  No need to mess with substitute.  (And no need 
to use as.formula on the very first line; that's already a formula.)

Duncan Murdoch
>
> Regards,
> Philippe
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nashjc at uottawa.ca  Wed Dec  3 14:13:07 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 03 Dec 2014 08:13:07 -0500
Subject: [R] non-finite initial optimization function; was "help"
In-Reply-To: <mailman.19.1417604408.26109.r-help@r-project.org>
References: <mailman.19.1417604408.26109.r-help@r-project.org>
Message-ID: <547F0C63.8090501@uottawa.ca>

If you want this resolved, you are going to have to provide the full 
function in a reproducible example. Nearly a half-century with this type 
of problem suggests a probability of nearly 1 that nlogL will be poorly 
set up.

JN

On 14-12-03 06:00 AM, r-help-request at r-project.org wrote:
> Message: 14
> Date: Tue, 2 Dec 2014 12:38:03 -0300
> From: Alejandra Chovar Vera<alejandra.chovar at gmail.com>
> To:r-help at r-project.org
> Subject: [R] help
> Message-ID:
> 	<CAGW2UaDZYafdcnVYZ82qkb127FxRa0RVuv9z3MdVU1bp7mUAYg at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Dear R
>
> I have a big problem in my estimation process,  I try to estimate my
> likelihood function with the option "optim", but R give me this message
> "Error en optim(par = valores$par, nlogL, method = "BFGS", hessian = T,  :
>
>    valor inicial en 'vmmin' no es finito " I know this is because my initial
> values are out the interval, but i try with different initial values and
> the problem persist.
>
> I don't know what can i do.
>
>
> I have this code, to obtain my initial values:
>
>
>   valores<-
> optim(c(-1,-1,1,1,1),nlogL,method="SANN",control=list(maxit=1000))
>
> DCp <-
> optim(par=valores$par,nlogL,method="BFGS",hessian=T,control=list(maxit=1000))
>
>
>
> I found in this link"http://es.listoso.com/r-help/2012-02/msg02395.html"
> something similar, but in this case there isn't answer.
>
>
> If you need more information about my code, please tell me.
>
>
> Sincerely
>
>
> Alejandra


From ramiro at precisionbioassay.com  Wed Dec  3 16:48:10 2014
From: ramiro at precisionbioassay.com (Ramiro Barrantes)
Date: Wed, 3 Dec 2014 15:48:10 +0000
Subject: [R] How to have NLME return when convergence not reached
In-Reply-To: <21630.51501.637914.723727@stat.math.ethz.ch>
References: <C7338A7EFF31BB4D831BB06C0088778979B440FA@MBX023-W1-CA-2.exch023.domain.local>
	<348AFDCF-8D3C-495F-800A-46EE8EB23C58@gene.com>
	<C7338A7EFF31BB4D831BB06C0088778979B45130@MBX023-W1-CA-2.exch023.domain.local>
	<CACk-te0Y39M0s+aBo0oA5gBDT3Wy95=zDAdL8A6LcPwJ8FWg+g@mail.gmail.com>,
	<21630.51501.637914.723727@stat.math.ethz.ch>
Message-ID: <C7338A7EFF31BB4D831BB06C0088778979B451AD@MBX023-W1-CA-2.exch023.domain.local>

Ok.  I am trying to figure out if it's a bug in my code or in nlme, will let you know and send you a reproducible example to you, Martin, if the latter, or apologize profusely for blaming nlme :) if the former.

Thanks again for everyone's input.

________________________________________
From: Martin Maechler [maechler at stat.math.ethz.ch]
Sent: Wednesday, December 03, 2014 3:26 AM
To: Bert Gunter
Cc: Ramiro Barrantes; r-help at r-project.org
Subject: Re: [R] How to have NLME return when convergence not reached

>>>>> Bert Gunter <gunter.berton at gene.com>
>>>>>     on Tue, 2 Dec 2014 14:03:44 -0800 writes:

    > Yes, Bill almost always has helpful ideas.
    > Just a comment: If indeed the process is gobbling up too much memory,
    > that might indicate a problem with your function or implementation. I
    > defer to real experts on this, however.

    > Cheers,
    > Bert

    > Bert Gunter
    > Genentech Nonclinical Biostatistics
    > (650) 467-7374


Yes, thank you Bert, it could be entirely Ramiro's function, but
we don't know as you have not given any indication about what
the non-linear function is in your nlme() formula.

The little you wrote _seems_ to indicate a bug in nlme, and if
that was the case, the bug should be reported and fixed,
and we (R core - the maintainer of the recommended package nlme)
would really like to to get a reproducible example.

If OTOH, it is your nonlinear function that "goes haywire",
the implicit blame on nlme would not be warranted.

Martin Maechler,
ETH Zurich and R Core team


    > On Tue, Dec 2, 2014 at 1:59 PM, Ramiro Barrantes
    > <ramiro at precisionbioassay.com> wrote:
    >> Thanks so much for your reply.  I am using try but nlme never returns!!  and I think the process is getting killed by the system as it is taking over all the memory.  However, I do like William Dunlap's idea of using R.utils::withTimeout to limit the time.
    >>
    >> Thanks again for your help!
    >> ________________________________________
    >> From: Bert Gunter [gunter.berton at gene.com]
    >> Sent: Tuesday, December 02, 2014 4:30 PM
    >> To: Ramiro Barrantes
    >> Cc: r-help at r-project.org
    >> Subject: Re: [R] How to have NLME return when convergence not reached
    >>
    >> ?try
    >> Or
    >> ?tryCatch
    >>
    >> Bert
    >>
    >> Sent from my iPhone -- please excuse typos.
    >>
    >>> On Dec 2, 2014, at 12:57 PM, Ramiro Barrantes <ramiro at precisionbioassay.com> wrote:
    >>>
    >>> Hello,
    >>>
    >>> I am trying to fit many hundreds of simulated datasets using NLME (it's all in a big loop in R).  Some don't seem to converge.  I am working on addressing the issues by perhaps adjusting my simulation, or tweaking iteration steps in nlme, etc.  However, when it doesn't converge, NLME just hangs, and my program either stalls for hours/days or takes over the computer memory and everything crashes eventually.  Is there a way to tell nlme to stop when it doesn't seem to be converging somehow?   I have been looking at the parameters in nlmeControl() but see nothing obvious.
    >>>
    >>> Thanks in advance,
    >>>
    >>> Ramiro
    >>>
    >>> [[alternative HTML version deleted]]
    >>>
    >>> ______________________________________________
    >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >>> https://stat.ethz.ch/mailman/listinfo/r-help
    >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >>> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From pmassicotte at hotmail.com  Wed Dec  3 17:09:21 2014
From: pmassicotte at hotmail.com (philippe massicotte)
Date: Wed, 3 Dec 2014 16:09:21 +0000
Subject: [R] Substitute initial guesses of parameters in a function
In-Reply-To: <547F09D9.9050707@gmail.com>
References: <COL127-W44971419BCAF7E10D1F586B37B0@phx.gbl>,
	<547F09D9.9050707@gmail.com>
Message-ID: <COL127-W404C726470373E5880F20AB37B0@phx.gbl>

Thank you!


> Date: Wed, 3 Dec 2014 08:02:17 -0500
> From: murdoch.duncan at gmail.com
> To: pmassicotte at hotmail.com; r-help at r-project.org
> Subject: Re: [R] Substitute initial guesses of parameters in a function
> 
> On 03/12/2014 7:37 AM, philippe massicotte wrote:
> > Hi everyone, I have a formula like this:
> >
> > f <- as.formula(y ~ p0a * exp(-0.5 * ((x - p1a)/p2a)^2))
> >
> > I would like to "dynamically" provide starting values for p0a, p1a, p2a. Is there a way to do it?
> 
> Just give a named vector of starting values.
> >
> > #Params estimates
> > p <- c(12, 10, 1)
> 
> Should be p <- c(p0a = 12, p1a = 10, p2a = 1)
> >
> > # This is where I have difficulties
> > mystart <- substitute(...)
> >
> > nls(formula = f, start = mystart)
> 
> Now start = p will work.  No need to mess with substitute.  (And no need 
> to use as.formula on the very first line; that's already a formula.)
> 
> Duncan Murdoch
> >
> > Regards,
> > Philippe
> >   		 	   		
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
 		 	   		  
	[[alternative HTML version deleted]]


From fmagalhaes at gmail.com  Wed Dec  3 17:58:32 2014
From: fmagalhaes at gmail.com (=?UTF-8?B?RsOhYmlvIE1hZ2FsaMOjZXM=?=)
Date: Wed, 3 Dec 2014 14:58:32 -0200
Subject: [R] using win task to run Rscript somepackages can't work in
 script mode
In-Reply-To: <768f0f57.20e4.14a039be90a.Coremail.rhelpmaillist@163.com>
References: <768f0f57.20e4.14a039be90a.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAu8QF4kPROaW-xkXzd9AnQkk_Q2+y6bEYh6pBGoWiRQvX0qUQ@mail.gmail.com>

Hi,

You didn't provide enough details (like the error message), but you
could start by calling Rscript with --vanilla option so that it
doesn't read Rprofile, nor environment files and see what happens.

#! F?bio


On Mon, Dec 1, 2014 at 12:09 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Dear expeRts,
>      These days i want to run a .R file contained a package called gmailr to do something about processing gmail , it works well in
> interactive
>  GUI  ,that is ,Rstudio. But i want to run it by a windows task, so i need to run the .R file in Rscript mode, sadly, there seems different between the two ways, the gmailr package fails work in the script mode.
>     So, what the difference? why Rscript can't run some codes which works well in Rstudio? How can i do something to make it suceess if there is some options to set ?
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul.tanger at colostate.edu  Wed Dec  3 19:35:52 2014
From: paul.tanger at colostate.edu (Paul Tanger)
Date: Wed, 3 Dec 2014 11:35:52 -0700
Subject: [R] extract AICc from model in glmulti object
In-Reply-To: <CA+igPh9ahHJWsKS49pHKusLmLTzcqhi0xzSeJDeo32L=HTM0pw@mail.gmail.com>
References: <CA+igPh9ahHJWsKS49pHKusLmLTzcqhi0xzSeJDeo32L=HTM0pw@mail.gmail.com>
Message-ID: <CA+igPh9p-doQz3CiA1hY0MfRGGTKPd0KmR2VQn=9AEM5yFuGfA@mail.gmail.com>

> Hi,
>
> Is there an easy way to extract the AICc from a model within a glmulti
> object?  I see the AIC, but not AICc.  For example:
>
> data(mtcars)
> cardata = mtcars
> library(glmulti)
> # create models
> global = glm(mpg ~ ., data=mtcars)
> models = glmulti(global, level=1, crit="aicc", confsetsize=50, plotty=F)
> # the AICc are here
> tableofdata = weightable(models)
> # but can I get it for a specific model here?
> # Because I also want to get other data in a loop from these objects, such
> as coefficients..
> summary(models at objects[[1]])
>
> Should this post be in a SIG list? I couldn't figure out which one..
>
> Thanks!
>

	[[alternative HTML version deleted]]


From bdemeulder at eisbm.org  Wed Dec  3 11:58:32 2014
From: bdemeulder at eisbm.org (Bertrand)
Date: Wed, 03 Dec 2014 11:58:32 +0100
Subject: [R] Question on LIMMA analysis with covariates and some missing data
Message-ID: <547EECD8.7090000@eisbm.org>

Hello,

I have a dataset of asthma patients for which white blood cells gene 
expression was measured with one-color Affymetrix microarrays (N~500, 
asthma is a factor with 4 levels: control, moderate, severe, severe & 
smokers).

I also have an extensive clinical dataset related, but with many missing 
values (for example, our controls don't have asthma exacerbations counts).

Our goal is to find DEGs between asthma groups, but we suspect that some 
of those clinical variables have an influence on gene expression, so we 
want to treat those as covariates in the model.

Now the question: can LIMMA handle missing data in the covariates and 
produce accurately corrected p-values for the genes ?

The model matrix is constructed like so (example with age and sex as 
covariates):

# Microarray data is in 'data' variable
asthma<-factor("Control", "Moderate", "Severe", "SevereSmokers")
design<-model.matrix(~0 + asthma + age + sex)
contrast.matrix<-makeContrasts(Control-Moderate, Control-Severe, 
Control-SevereSmokers, levels=design)
fit<-lmFit(data, design)
fit2<-contrasts.fit(fit, contrast.matrix)
fit2<-eBayes(fit2)

Many thanks,

Bertrand
-- 
EISBM logo <http://www.eisbm.org> *Bertrand De Meulder
Researcher *
European Institute for Systems Biology and Medicine
Campus Charles M?rieux - Universit? de Lyon
CNRS - UCBL - ENS
*E-mail:*bdemeulder at eisbm.org <mailto:bdemeulder at eisbm.org>

*Office:* +33(0)4 37 28 74 41

*Office*
Universit? Claude Bernard
3^e ?tage plot 2
50 Avenue Tony Garnier
69366 Lyon cedex 07
France 	*Laboratory*
LyonBioP?le - Centre d'Infectiologie
2^e ?tage B?t. Domilyon
321 Avenue Jean Jaur?s
69007 Lyon
France

Follow us : EISBM eisbm.org <http://www.eisbm.org> | Facebook Facebook 
<http://www.facebook.com/EISBM> | Twitter Twitter 
<http://twitter.com/EISBM_EU>


From cddis at att.net  Wed Dec  3 19:29:12 2014
From: cddis at att.net (Charles R Parker)
Date: Wed, 3 Dec 2014 10:29:12 -0800
Subject: [R] coerce data to numeric
Message-ID: <1417631352.22623.YahooMailNeo@web184305.mail.ne1.yahoo.com>

I am trying to create groups of barplots from data that have different number of records in the groups, in such a way that all of the plots will have the same numbers and sizes of bars represented even when some of the groups will have some bars of zero height. The goal then would be to display multiple plots on a single page using split.screen or something similar. lattice does not seem suitable because of the data structure it operates on. A simple data structure that I operate on is given here:

> dput(stplot)
structure(list(GId = structure(1:11, .Label = c("A1", "B1", "B2", 
"B3", "B4", "B5", "C1", "C2", "D1", "D2", "D3"), class = "factor"), 
    Grp = structure(c(1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 4L, 4L, 
    4L), .Label = c("A", "B", "C", "D"), class = "factor"), S = c(12.3, 
    23.8, 0, 7.6, 14.32, 1.9, 5.1, 0, 14.6, 10.1, 8.7), T = c(5L, 
    12L, 2L, 1L, 4L, 1L, 1L, 9L, 5L, 6L, 3L)), .Names = c("GId", 
"Grp", "S", "T"), class = "data.frame", row.names = c(NA, -11L
))


My code, which doesn't quite work is:

> nbars <-
function(x){
  sG = summary(x$Grp)
  mG = max(sG)
  for(n in 1:length(sG)){
    tX = subset(x,x$Grp==names(sG[n]))
    if(nrow(tX) < mG){
      fm = as.numeric(rep(length = mG - nrow(tX), 0))
      tX = rbind(tX, as.data.frame(cbind(GId = " ",Grp = names(sG[n]), 
             S = fm, T = fm)))
    }
#print(tX)
#dput(t(as.matrix(tX[,3:4])))
    barplot(t(as.matrix(tX[,3:4])),beside=TRUE, names.arg=tX$GId, 
              col = c("navy","gray"))
  }
}


The function nbars first gets the list of group values with their counts 'summary(x$Grp)'.
It then determines the maximum number of bar pairs in the largest of the groups 'max(sG)', and uses this to determine how much each smaller group needs to be padded to fill out the proper number of bars in the ultimate barplots, using the for loop. If you uncomment the #print(tX) you can see that this works...sort of. The problem becomes apparent if you uncomment the #dput. This shows that the tX treats the S and T values as characters rather than as numeric values. This prevents the barplots from working. By changing the for loop to begin 'for(n in 2:length(sG)' the second plot will display correctly, but the third plot will fail.

I have tried various options to force the S and T variables to be numeric, but none of those have worked (as.numeric(fm), as.matrix(fm), as.vector(fm)) in the 'if(nrow(tX) < mG)' loop, but these have not worked.

If there is a sure-fire way to solve the problem I would be grateful.

Thanks.

	[[alternative HTML version deleted]]


From dries-david at hotmail.com  Wed Dec  3 12:40:25 2014
From: dries-david at hotmail.com (Dries David)
Date: Wed, 3 Dec 2014 12:40:25 +0100
Subject: [R] Problem with
Message-ID: <DUB124-W28738BC807A785A94A33D9F57B0@phx.gbl>

 Hey
 
In my data set i have two variables: month (march or april) and wind direction (N,NE,E,SE,S,SW,W,NW). I have to know if there is a difference in wind direction between these months. What kind of test statistic should i use?
 
Kind regards
 
Dries David
 		 	   		  
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: achtergrondlawaai.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141203/39ddb6e7/attachment.txt>

From AARTI.MUNJAL at ucdenver.edu  Wed Dec  3 13:38:13 2014
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Wed, 3 Dec 2014 12:38:13 +0000
Subject: [R] ASA John M. Chambers Statistical Software Award - 2015
Message-ID: <D0A4521C.3DB4%aarti.munjal@ucdenver.edu>

################################################################################
John M. Chambers Statistical Software Award - 2015
Statistical Computing Section
American Statistical Association

The Statistical Computing Section of the American Statistical Association announces the competition for the John M. Chambers Statistical Software Award. In 1998 the Association for Computing Machinery presented its Software System Award to John Chambers for the design and development of S. Dr. Chambers generously donated his award to the Statistical Computing Section to endow an annual prize for statistical software written by, or in collaboration with, an undergraduate or graduate student. The prize carries with it a cash award of $1000, plus a substantial allowance for travel to the annual Joint Statistical Meetings (JSM) where the award will be presented.

Teams of up to 3 people can participate in the competition, with the cash award being split among team members. The travel allowance will be given to just one individual in the team, who will be presented the award at JSM. To be eligible, the team must have designed and implemented a piece of statistical software. The individual within the team indicated to receive the travel allowance must have begun the development while a student, and must either currently be a student, or have completed all requirements for her/his last degree after January 1, 2014. To apply for the award, teams must provide the following materials:

Current CV's of all team members.

A letter from a faculty mentor at the academic institution of the individual indicated to receive the travel award. The letter should confirm that the individual had substantial participation in the development of the software, certify her/his student status when the software began to be developed (and either the current student status or the date of degree completion), and briefly discuss the importance of the software to statistical practice.

A brief, one to two page description of the software, summarizing what it does, how it does it, and why it is an important contribution. If the team member competing for the travel allowance has continued developing the software after finishing her/his studies, the description should indicate what was developed when the individual was a student and what has been added since.

An installable software package with its source code for use by the award committee. It should be accompanied by enough information to allow the judges to effectively use and evaluate the software (including its design considerations.) This information can be provided in a variety of ways, including but not limited to a user manual (paper or electronic), a paper, a URL, and online help to the system.

All materials must be in English. We prefer that electronic text be submitted in Postscript or PDF. The entries will be judged on a variety of dimensions, including the importance and relevance for statistical practice of the tasks performed by the software, ease of use, clarity of description, elegance and availability for use by the statistical community. Preference will be given to those entries that are grounded in software design rather than calculation. The decision of the award committee is final.

All application materials must be received by 5:00pm EST, Tuesday, February 17, 2015 at the address below. The winner will be announced in May and the award will be given at the 2015 Joint Statistical Meetings.

Student Paper Competition
c/o Aarti Munjal
Colorado School of Public Health
University of Colorado Denver
aarti.munjal at ucdenver.edu


--
Aarti Munjal, PhD
Assistant Research Professor
Department of Biostatistics and Informatics
Colorado School of Public Health
University of Colorado, Denver
Phone: 303-724-6273
aarti.munjal at ucdenver.edu<mailto:aarti.munjal at ucdenver.edu>

	[[alternative HTML version deleted]]


From jecogeo at gmail.com  Wed Dec  3 20:04:52 2014
From: jecogeo at gmail.com (Jefferson Ferreira-Ferreira)
Date: Wed, 03 Dec 2014 19:04:52 +0000
Subject: [R] if else for cumulative sum error
References: <CAFFT+Y5dagh+sH1+=0h=Vc+RehEVr9skkfB9EBUMgzdnhAfExA@mail.gmail.com>
	<CAAJSdji+4FPz2ZWbna6M6UTMkKSShBS33pLv=YQ3sisgjEGVLQ@mail.gmail.com>
	<CAFFT+Y7juXZSV6mzoGt83k08ds1+h-kGysFEeS09O5GnjbA8SQ@mail.gmail.com>
	<44C52509-F974-4B87-BE71-6C9EDC7AFCF3@comcast.net>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FBC785@mb02.ads.tamu.edu>
Message-ID: <CAFFT+Y7pgkic8pQWz4knOdrhqfkecXg=EJ5mC8R-wdip0rJr-A@mail.gmail.com>

Nice, David!!

Worked like a charm!!
Thank you very much.



Em Tue Dec 02 2014 at 19:22:48, David L Carlson <dcarlson at tamu.edu>
escreveu:

> Let's try a different approach. You don't need a loop for this. First we
> need a reproducible example:
>
> > set.seed(42)
> > dadosmax <- data.frame(above=runif(150) + .5)
>
> Now compute your sums using cumsum() and diff() and then compute enchday
> using ifelse(). See the manual pages for each of these functions to
> understand how they work:
>
> > sums <- diff(c(0, cumsum(dadosmax$above)), 45)
> > dadosmax$enchday <- c(ifelse(sums >= 45, 1, 0), rep(NA, 44))
>
> > dadosmax$enchday
>   [1]  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
> 1  1  1
>  [26]  1  1  1  1  1  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 0  0  0
>  [51]  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
> 0  0  0
>  [76]  0  0  0  0  0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1
> 1  1  1
> [101]  1  1  1  1  1  1 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> NA NA
> [126] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
> NA NA
>
> See the NA's? Those are what David Winsemius is talking about. For the
> 106th value, 106+44 is 150, but for the 107th value 107+144 is 151 which
> does not exist. Fortunately diff() understands that and stops at 106, but
> we have to add 44 NA's because that is the number of rows in your data
> frame.
>
> You might find this plot informative as well:
>
> > plot(sums, typ="l")
> > abline(h=45)
>
> Another way to get there is to use sapply() which will add the NA's for us:
>
> > sums <- sapply(1:150, function(x) sum(dadosmax$above[x:(x+44)]))
> > dadosmax$enchday <- ifelse(sums >= 45, 1, 0)
>
> But it won't be as fast if you have a large data set.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Tuesday, December 2, 2014 2:50 PM
> To: Jefferson Ferreira-Ferreira
> Cc: r-help at r-project.org
> Subject: Re: [R] if else for cumulative sum error
>
>
> On Dec 2, 2014, at 12:26 PM, Jefferson Ferreira-Ferreira wrote:
>
> > Thank you for replies.
> >
> > David,
> >
> > I tried your modified form
> >
> > for (i in 1:seq_along(rownames(dadosmax))){
>
>
> No. it is either 1: .... or seq_along(...). in this case perhaps
> 1:(nrow(dadosmax)-44 would be safer
>
> You do not seem to have understood that you cannot use an index of i+44
> when i is going to be the entire set of rows of the dataframe. There is "no
> there there" to quote Gertrude Stein's slur against Oakland. In fact there
> is not there there at i+1 when you get to the end. You either need to only
> go to row
>
> >  dadosmax$enchday[i] <- if ( (sum(dadosmax$above[i:(i+44)])) >= 45) 1
> else
> > 0
> > }
> >
> > However, I'm receiving this warning:
> > Warning message:
> > In 1:seq_along(rownames(dadosmax)) :
> >  numerical expression has 2720 elements: only the first used
> >
> > I can't figure out why only the first row was calculated...
>
> You should of course read these, but the error is not from your
> if-statement but rahter you for-loop-indexing.
>
> ?'if'
> ?ifelse
>
>
> > Any ideas?
> >
> >
> >
> > Em Tue Dec 02 2014 at 15:22:25, John McKown <
> john.archie.mckown at gmail.com>
> > escreveu:
> >
> >> On Tue, Dec 2, 2014 at 12:08 PM, Jefferson Ferreira-Ferreira <
> >> jecogeo at gmail.com> wrote:
> >>
> >>> Hello everybody;
> >>>
> >>> I'm writing a code where part of it is as follows:
> >>>
> >>> for (i in nrow(dadosmax)){
> >>>  dadosmax$enchday[i] <- if (sum(dadosmax$above[i:(i+44)]) >= 45) 1
> else 0
> >>> }
> >>>
> >>
> >> ?Without some test data for any validation, I would try the following
> >> formula
> >>
> >> dadosmax$enchday[i] <- if
> >> (sum(dadosmax$above[i:(min(i+44,nrow(dadosmax)))] >= 45) 1 else 0?
> >>
> >>
> >>
> >>>
> >>> That is for each row of my data frame, sum an specific column (0 or 1)
> of
> >>> that row plus 44 rows. If It is >=45 than enchday is 1 else 0.
> >>>
> >>> The following error is returned:
> >>>
> >>> Error in if (sum(dadosmax$above[i:(i + 44)]) >= 45) 1 else 0 :
> >>>  missing value where TRUE/FALSE needed
> >>>
> >>> I've tested the ifelse statement assigning different values to i and it
> >>> works. So I'm wondering if this error is due the fact that at the
> final of
> >>> my data frame there aren't 45 rows to sum anymore. I tried to use "try"
> >>> but
> >>> It's simply hide the error.
> >>>
> >>> How can I deal with this? Any ideas?
> >>> Thank you very much.
> >>>
> >>>        [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>
> >> --
> >> The temperature of the aqueous content of an unremittingly ogled
> >> culinary vessel will not achieve 100 degrees on the Celsius scale.
> >>
> >> Maranatha! <><
> >> John McKown
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Wed Dec  3 20:11:16 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 3 Dec 2014 13:11:16 -0600
Subject: [R] Problem with
In-Reply-To: <DUB124-W28738BC807A785A94A33D9F57B0@phx.gbl>
References: <DUB124-W28738BC807A785A94A33D9F57B0@phx.gbl>
Message-ID: <CAN5YmCFOTbrxPw_6fM1NztoFtS=jNOq5VhD0j=hLdQnjtRESrw@mail.gmail.com>

This question is more about statistics than R.  I suggest that you post it
to Cross Validated instead, http://stats.stackexchange.com/.

Jean

On Wed, Dec 3, 2014 at 5:40 AM, Dries David <dries-david at hotmail.com> wrote:

>  Hey
>
> In my data set i have two variables: month (march or april) and wind
> direction (N,NE,E,SE,S,SW,W,NW). I have to know if there is a difference in
> wind direction between these months. What kind of test statistic should i
> use?
>
> Kind regards
>
> Dries David
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Wed Dec  3 20:25:32 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 3 Dec 2014 11:25:32 -0800 (PST)
Subject: [R] Problem with
In-Reply-To: <CAN5YmCFOTbrxPw_6fM1NztoFtS=jNOq5VhD0j=hLdQnjtRESrw@mail.gmail.com>
References: <DUB124-W28738BC807A785A94A33D9F57B0@phx.gbl>
	<CAN5YmCFOTbrxPw_6fM1NztoFtS=jNOq5VhD0j=hLdQnjtRESrw@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1412031120500.13276@aeolus.ecy.wa.gov>

I'd also suggest plotting a wind rose for each month (try openair) to 
understand the statistical test results.

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 3 Dec 2014, Adams, Jean wrote:

> This question is more about statistics than R.  I suggest that you post it
> to Cross Validated instead, http://stats.stackexchange.com/.
>
> Jean
>
> On Wed, Dec 3, 2014 at 5:40 AM, Dries David <dries-david at hotmail.com> wrote:
>
>>  Hey
>>
>> In my data set i have two variables: month (march or april) and wind
>> direction (N,NE,E,SE,S,SW,W,NW). I have to know if there is a difference in
>> wind direction between these months. What kind of test statistic should i
>> use?
>>
>> Kind regards
>>
>> Dries David
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From brockhunts at gmail.com  Wed Dec  3 22:14:16 2014
From: brockhunts at gmail.com (Brock Huntsman)
Date: Wed, 3 Dec 2014 12:14:16 -0900
Subject: [R] combining unequal dataframes based on a common grouping factor
Message-ID: <CAEjgJV7wfsOef7NyeSk7oFwR327S7Ef=-YZLrR=GkzFo2PSvjQ@mail.gmail.com>

I apologize if this is a relatively easy problem, but have been stuck on
this issue for a few days. I am attempting to combine values from 2
separate dataframes. Each dataframe contains a shared identifier (GROUP).
Dataframe 1 (3272 rows x 3 columns) further divides this shared grouping
factor into unique identifiers (ID), as well as contains the proportion of
the GROUP area of which the unique identifier consists (PROP_AREA).
Dataframe 2 (291 x 14976) in addition to consisting of the shared
identifier, also has numerous columns consisting of values (VALUE1,
VALUE2). I would like to multiply the PROP_AREA in dataframe 1 by each
value in dataframe 2 (VALUE1 through VALUE14976) based on the GROUP factor,
constructing a final dataframe of size 3272 x 14976. An example of the data
frames are as follows:


frame1:

ID

GROUP

PROP_AREA

1

A

0.33

2

A

0.33

3

A

0.33

4

B

0.50

5

B

0.50

6

C

1.00

7

D

1.00



frame2:

GROUP

VALUE1

VALUE2

A

10

5

B

20

10

C

30

15

D

40

20



 Desired dataframe

frame3:

ID

VALUE1

VALUE2

1

3.3

1.65

2

3.3

1.65

3

3.3

1.65

4

10

5

5

10

5

6

30

15

7

40

20





I assume I would need to use the %in% function or if statements, but am
unsure how to write the code. I have attempted to construct a for loop with
an if statement, but have not been successful as of yet.


for(i in 1:nrow(frame1)) {

  for(j in 2:ncol(frame2)) {

    if (frame1$GROUP[i] == frame2$GROUP[i]) {

      frame3[i,j+1] <- frame1$PROP_AREA[i]*frame2[i,j+1]

    }

  }

}


Any advice on suggested code or packages to read up on would be much
appreciated.

Brock

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Dec  3 22:40:58 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 03 Dec 2014 13:40:58 -0800
Subject: [R] combining unequal dataframes based on a common grouping
	factor
In-Reply-To: <CAEjgJV7wfsOef7NyeSk7oFwR327S7Ef=-YZLrR=GkzFo2PSvjQ@mail.gmail.com>
References: <CAEjgJV7wfsOef7NyeSk7oFwR327S7Ef=-YZLrR=GkzFo2PSvjQ@mail.gmail.com>
Message-ID: <825F296A-A544-4044-802A-38A23A088D37@dcn.davis.CA.us>

Posting in HTML format doesn't work nearly as well as you think it does... Your email is pretty mixed up. Please use plain text format and use dput to make your data usable in R.

I expect the best answer to your problem is going to be to use the merge function instead of your for loops.. but the actual data can affect how well any solution works so giving us dput output is crucial.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 3, 2014 1:14:16 PM PST, Brock Huntsman <brockhunts at gmail.com> wrote:
>I apologize if this is a relatively easy problem, but have been stuck
>on
>this issue for a few days. I am attempting to combine values from 2
>separate dataframes. Each dataframe contains a shared identifier
>(GROUP).
>Dataframe 1 (3272 rows x 3 columns) further divides this shared
>grouping
>factor into unique identifiers (ID), as well as contains the proportion
>of
>the GROUP area of which the unique identifier consists (PROP_AREA).
>Dataframe 2 (291 x 14976) in addition to consisting of the shared
>identifier, also has numerous columns consisting of values (VALUE1,
>VALUE2). I would like to multiply the PROP_AREA in dataframe 1 by each
>value in dataframe 2 (VALUE1 through VALUE14976) based on the GROUP
>factor,
>constructing a final dataframe of size 3272 x 14976. An example of the
>data
>frames are as follows:
>
>
>frame1:
>
>ID
>
>GROUP
>
>PROP_AREA
>
>1
>
>A
>
>0.33
>
>2
>
>A
>
>0.33
>
>3
>
>A
>
>0.33
>
>4
>
>B
>
>0.50
>
>5
>
>B
>
>0.50
>
>6
>
>C
>
>1.00
>
>7
>
>D
>
>1.00
>
>
>
>frame2:
>
>GROUP
>
>VALUE1
>
>VALUE2
>
>A
>
>10
>
>5
>
>B
>
>20
>
>10
>
>C
>
>30
>
>15
>
>D
>
>40
>
>20
>
>
>
> Desired dataframe
>
>frame3:
>
>ID
>
>VALUE1
>
>VALUE2
>
>1
>
>3.3
>
>1.65
>
>2
>
>3.3
>
>1.65
>
>3
>
>3.3
>
>1.65
>
>4
>
>10
>
>5
>
>5
>
>10
>
>5
>
>6
>
>30
>
>15
>
>7
>
>40
>
>20
>
>
>
>
>
>I assume I would need to use the %in% function or if statements, but am
>unsure how to write the code. I have attempted to construct a for loop
>with
>an if statement, but have not been successful as of yet.
>
>
>for(i in 1:nrow(frame1)) {
>
>  for(j in 2:ncol(frame2)) {
>
>    if (frame1$GROUP[i] == frame2$GROUP[i]) {
>
>      frame3[i,j+1] <- frame1$PROP_AREA[i]*frame2[i,j+1]
>
>    }
>
>  }
>
>}
>
>
>Any advice on suggested code or packages to read up on would be much
>appreciated.
>
>Brock
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Wed Dec  3 23:10:46 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Wed, 3 Dec 2014 22:10:46 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>

Hello,

Two alternative approaches - mutate() vs. sapply() - were used to get the desired results (i.e., creating a new column of the most recent date  from 4 dates ) with help from Arun and Mark on this forum.  I now find that the two data objects (created using two different approaches) are not identical although results are exactly the same.  
 
identical(new1, new2) 
[1] FALSE
 
Please see the reproducible example below.

I don't understand why the code returns FALSE here.  Any hints/comments  will be  appreciated.

Thanks,

Pradip

#############################################  reproducible example ########################################
library(dplyr)
# data object - description 

temp <- "id  mrjdate cocdate inhdate haldate
1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
2             NA         NA         NA         NA     
3     2009-10-24         NA 2011-10-13         NA
4     2007-10-10         NA         NA         NA
5     2006-09-01 2005-08-10         NA         NA
6     2007-09-04 2011-10-05         NA         NA
7     2005-10-25         NA         NA 2011-11-04"

# read the data object

example.data <- read.table(textConnection(temp), 
                    colClasses=c("character", "Date", "Date", "Date", "Date"),  
                    header=TRUE, as.is=TRUE
                    )


# create a new column -dplyr solution (Acknowledgement: Arun)

new1 <- example.data %>% 
     rowwise() %>%
      mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
                                                               na.rm=TRUE), origin='1970-01-01'))

# create a new column - Base R solution (Acknowlegement: Mark Sharp)

new2 <- example.data
new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
  if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

identical(new1, new2) 

# print records

print (new1); print(new2)

Pradip K. Muhuri
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip (SAMHSA/CBHSQ)
Sent: Sunday, November 09, 2014 6:11 AM
To: 'Mark Sharp'
Cc: r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

Hi Mark,

Your code has also given me the results I expected.  Thank you so much for your help.

Regards,

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: Mark Sharp [mailto:msharp at TxBiomed.org] 
Sent: Sunday, November 09, 2014 3:01 AM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

Pradip,

mutate() works on the entire column as a vector so that you find the maximum of the entire data set.

I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.

max() does not want a dataframe thus the use of unlist().

Using your definition of data1:

data3 <- data1
data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
  if (all(is.na(unlist(data1[row, -1])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

data3
  id    mrjdate    cocdate    inhdate    haldate    oidflag
1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
2  2       <NA>       <NA>       <NA>       <NA>       <NA>
3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04



R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center Texas Biomedical Research Institute P.O. Box 760549 San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org





NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ssefick at gmail.com  Wed Dec  3 23:51:31 2014
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 3 Dec 2014 16:51:31 -0600
Subject: [R] RcppArmadillo compilation errors (Scientific Linux 6.5)
Message-ID: <CADKEMqiT=-08FuP9Azmk5FA8n6Pf=LFN5pcqV5WpXpGMKxxgPg@mail.gmail.com>

I would appreciate any help that you may be able to give. Please let me
know if any more information is required.

I get a the following error when I try to install RcppArmadillo in a
session started with R --vanilla using the
install.packages("RcppArmadillo") command.

make: *** [RcppArmadillo.o] Error 1
ERROR: compilation failed for package ?RcppArmadillo?
* removing
?/home/ssefick/R/x86_64-unknown-linux-gnu-library/3.1/RcppArmadillo?

The downloaded source packages are in
?/tmp/RtmpdYI41j/downloaded_packages?
Warning message:
In install.packages("RcppArmadillo") :
  installation of package ?RcppArmadillo? had non-zero exit status


OS: Scientific Linux 6.5

R version 3.1.0 Patched (2014-06-15 r65949)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Dec  4 00:10:28 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Dec 2014 15:10:28 -0800
Subject: [R] Problem with
In-Reply-To: <DUB124-W28738BC807A785A94A33D9F57B0@phx.gbl>
References: <DUB124-W28738BC807A785A94A33D9F57B0@phx.gbl>
Message-ID: <DCADD907-838D-40A9-8844-FAD3661AF03E@comcast.net>

You should at least look at the facilities in the 'circular' package. Also the  Envirometrics Task View: http://cran.r-project.org/web/views/Environmetrics.html which mention another package that up until today I had not heard of: http://cran.r-project.org/web/packages/CircStats/index.html

-- 
David.


On Dec 3, 2014, at 3:40 AM, Dries David wrote:

> Hey
> 
> In my data set i have two variables: month (march or april) and wind direction (N,NE,E,SE,S,SW,W,NW). I have to know if there is a difference in wind direction between these months. What kind of test statistic should i use?
> 
> Kind regards
> 
> Dries David
> 		 	   		  <achtergrondlawaai.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ssefick at gmail.com  Thu Dec  4 00:11:54 2014
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 3 Dec 2014 17:11:54 -0600
Subject: [R] RcppArmadillo compilation errors (Scientific Linux 6.5)
In-Reply-To: <CADKEMqiT=-08FuP9Azmk5FA8n6Pf=LFN5pcqV5WpXpGMKxxgPg@mail.gmail.com>
References: <CADKEMqiT=-08FuP9Azmk5FA8n6Pf=LFN5pcqV5WpXpGMKxxgPg@mail.gmail.com>
Message-ID: <CADKEMqhdmjrj_-H2UPjj+J7Kk4__ew9dL9i7zozd42Za6-tFqA@mail.gmail.com>

solved; sorry for the spam.

library(devtools)
install_github("RcppCore/RcppArmadillo")

On Wed, Dec 3, 2014 at 4:51 PM, stephen sefick <ssefick at gmail.com> wrote:

> I would appreciate any help that you may be able to give. Please let me
> know if any more information is required.
>
> I get a the following error when I try to install RcppArmadillo in a
> session started with R --vanilla using the
> install.packages("RcppArmadillo") command.
>
> make: *** [RcppArmadillo.o] Error 1
> ERROR: compilation failed for package ?RcppArmadillo?
> * removing
> ?/home/ssefick/R/x86_64-unknown-linux-gnu-library/3.1/RcppArmadillo?
>
> The downloaded source packages are in
> ?/tmp/RtmpdYI41j/downloaded_packages?
> Warning message:
> In install.packages("RcppArmadillo") :
>   installation of package ?RcppArmadillo? had non-zero exit status
>
>
> OS: Scientific Linux 6.5
>
> R version 3.1.0 Patched (2014-06-15 r65949)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>  [7] LC_PAPER=en_US.utf8       LC_NAME=C
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>
> --
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>


-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Dec  4 02:14:21 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Dec 2014 17:14:21 -0800
Subject: [R] Getting the most recent dates in a new column from dates in
	four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
	<E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
Message-ID: <A836C020-CA50-4B01-B6AD-B85156A2DDDA@comcast.net>


On Dec 3, 2014, at 2:10 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:

> Hello,
> 
> Two alternative approaches - mutate() vs. sapply() - were used to get the desired results (i.e., creating a new column of the most recent date  from 4 dates ) with help from Arun and Mark on this forum.  I now find that the two data objects (created using two different approaches) are not identical although results are exactly the same.  
> 
> identical(new1, new2) 
> [1] FALSE
> 

You should have examined the output from dput() on both objects. I think you will find that dplyr is adding new attributes.

Notice the the "mutate()-ed" object now has this class:

class = c("rowwise_df", "tbl_df", "tbl", "data.frame")

Moral: Never rely on the the print representation.

-- 
David.


> Please see the reproducible example below.
> 
> I don't understand why the code returns FALSE here.  Any hints/comments  will be  appreciated.
> 
> Thanks,
> 
> Pradip
> 
> #############################################  reproducible example ########################################
> library(dplyr)
> # data object - description 
> 
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA     
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
> 
> # read the data object
> 
> example.data <- read.table(textConnection(temp), 
>                    colClasses=c("character", "Date", "Date", "Date", "Date"),  
>                    header=TRUE, as.is=TRUE
>                    )
> 
> 
> # create a new column -dplyr solution (Acknowledgement: Arun)
> 
> new1 <- example.data %>% 
>     rowwise() %>%
>      mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                               na.rm=TRUE), origin='1970-01-01'))
> 
> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
> 
> new2 <- example.data
> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>  if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
>    max_d <- NA
>  } else {
>    max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
>  }
>  max_d}),
>  origin = "1970-01-01")
> 
> identical(new1, new2) 
> 
> # print records
> 
> print (new1); print(new2)
> 
> Pradip K. Muhuri
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip (SAMHSA/CBHSQ)
> Sent: Sunday, November 09, 2014 6:11 AM
> To: 'Mark Sharp'
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)
> 
> Hi Mark,
> 
> Your code has also given me the results I expected.  Thank you so much for your help.
> 
> Regards,
> 
> Pradip
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> 
> -----Original Message-----
> From: Mark Sharp [mailto:msharp at TxBiomed.org] 
> Sent: Sunday, November 09, 2014 3:01 AM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)
> 
> Pradip,
> 
> mutate() works on the entire column as a vector so that you find the maximum of the entire data set.
> 
> I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.
> 
> max() does not want a dataframe thus the use of unlist().
> 
> Using your definition of data1:
> 
> data3 <- data1
> data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
>  if (all(is.na(unlist(data1[row, -1])))) {
>    max_d <- NA
>  } else {
>    max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>  }
>  max_d}),
>  origin = "1970-01-01")
> 
> data3
>  id    mrjdate    cocdate    inhdate    haldate    oidflag
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
> 
> 
> 
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center Texas Biomedical Research Institute P.O. Box 760549 San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
> 
> 
> 
> 
> 
> NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From chl948 at mail.usask.ca  Thu Dec  4 02:48:00 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 03 Dec 2014 19:48:00 -0600
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
	<E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
Message-ID: <547FBD50.2090407@mail.usask.ca>

The output in the object 'new1' are apparently same the output in the 
object 'new2'.  Are you trying to compare the entries of two outputs 
'new1' and 'new2'?  If so, the function 'all()' would be useful:

 > all(new1 == new2, na.rm=TRUE)
[1] TRUE

If you are interested in the comparison of two objects in terms of 
class, then the function 'identical()' is useful:

 > attributes(new1)
$names
[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oldflag"

$class
[1] "rowwise_df" "tbl_df"     "tbl"        "data.frame"

$row.names
[1] 1 2 3 4 5 6 7

 > attributes(new2)
$names
[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oiddate"

$row.names
[1] 1 2 3 4 5 6 7

$class
[1] "data.frame"

I hope this helps.

Chel Hee Lee

On 12/03/2014 04:10 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hello,
>
> Two alternative approaches - mutate() vs. sapply() - were used to get the desired results (i.e., creating a new column of the most recent date  from 4 dates ) with help from Arun and Mark on this forum.  I now find that the two data objects (created using two different approaches) are not identical although results are exactly the same.
>
> identical(new1, new2)
> [1] FALSE
>
> Please see the reproducible example below.
>
> I don't understand why the code returns FALSE here.  Any hints/comments  will be  appreciated.
>
> Thanks,
>
> Pradip
>
> #############################################  reproducible example ########################################
> library(dplyr)
> # data object - description
>
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
>
> # read the data object
>
> example.data <- read.table(textConnection(temp),
>                      colClasses=c("character", "Date", "Date", "Date", "Date"),
>                      header=TRUE, as.is=TRUE
>                      )
>
>
> # create a new column -dplyr solution (Acknowledgement: Arun)
>
> new1 <- example.data %>%
>       rowwise() %>%
>        mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                                 na.rm=TRUE), origin='1970-01-01'))
>
> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
>
> new2 <- example.data
> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>    if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
>      max_d <- NA
>    } else {
>      max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
>    }
>    max_d}),
>    origin = "1970-01-01")
>
> identical(new1, new2)
>
> # print records
>
> print (new1); print(new2)
>
> Pradip K. Muhuri
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip (SAMHSA/CBHSQ)
> Sent: Sunday, November 09, 2014 6:11 AM
> To: 'Mark Sharp'
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)
>
> Hi Mark,
>
> Your code has also given me the results I expected.  Thank you so much for your help.
>
> Regards,
>
> Pradip
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
> -----Original Message-----
> From: Mark Sharp [mailto:msharp at TxBiomed.org]
> Sent: Sunday, November 09, 2014 3:01 AM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)
>
> Pradip,
>
> mutate() works on the entire column as a vector so that you find the maximum of the entire data set.
>
> I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.
>
> max() does not want a dataframe thus the use of unlist().
>
> Using your definition of data1:
>
> data3 <- data1
> data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
>    if (all(is.na(unlist(data1[row, -1])))) {
>      max_d <- NA
>    } else {
>      max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>    }
>    max_d}),
>    origin = "1970-01-01")
>
> data3
>    id    mrjdate    cocdate    inhdate    haldate    oidflag
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
>
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center Texas Biomedical Research Institute P.O. Box 760549 San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
>
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chl948 at mail.usask.ca  Thu Dec  4 03:17:48 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 03 Dec 2014 20:17:48 -0600
Subject: [R] combining unequal dataframes based on a common grouping
	factor
In-Reply-To: <CAEjgJV7wfsOef7NyeSk7oFwR327S7Ef=-YZLrR=GkzFo2PSvjQ@mail.gmail.com>
References: <CAEjgJV7wfsOef7NyeSk7oFwR327S7Ef=-YZLrR=GkzFo2PSvjQ@mail.gmail.com>
Message-ID: <547FC44C.5090000@mail.usask.ca>

 > frame1
   ID GROUP PROP_AREA
1  1     A      0.33
2  2     A      0.33
3  3     A      0.33
4  4     B      0.50
5  5     B      0.50
6  6     C      1.00
7  7     D      1.00
 > frame2
   GROUP VALUE1 VALUE2
1     A     10      5
2     B     20     10
3     C     30     15
4     D     40     20
 >
 > obj1 <- merge(x=frame1, y=frame2, by="GROUP")
 > obj1$rval1 <- obj1$PROP_AREA * obj1$VALUE1
 > obj1$rval2 <- obj1$PROP_AREA * obj1$VALUE2
 > obj1
   GROUP ID PROP_AREA VALUE1 VALUE2 rval1 rval2
1     A  1      0.33     10      5   3.3  1.65
2     A  2      0.33     10      5   3.3  1.65
3     A  3      0.33     10      5   3.3  1.65
4     B  4      0.50     20     10  10.0  5.00
5     B  5      0.50     20     10  10.0  5.00
6     C  6      1.00     30     15  30.0 15.00
7     D  7      1.00     40     20  40.0 20.00
 >
 > idx <- match(x=frame1$GROUP, table=frame2$GROUP)
 > rval1 <- frame1["PROP_AREA"] * frame2[idx, "VALUE1"]
 > rval2 <- frame1["PROP_AREA"] * frame2[idx, "VALUE2"]
 > cbind("ID"=frame1[idx, "ID"], rval1, rval2)
   ID PROP_AREA PROP_AREA
1  1       3.3      1.65
2  1       3.3      1.65
3  1       3.3      1.65
4  2      10.0      5.00
5  2      10.0      5.00
6  3      30.0     15.00
7  4      40.0     20.00
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 12/03/2014 03:14 PM, Brock Huntsman wrote:
> I apologize if this is a relatively easy problem, but have been stuck on
> this issue for a few days. I am attempting to combine values from 2
> separate dataframes. Each dataframe contains a shared identifier (GROUP).
> Dataframe 1 (3272 rows x 3 columns) further divides this shared grouping
> factor into unique identifiers (ID), as well as contains the proportion of
> the GROUP area of which the unique identifier consists (PROP_AREA).
> Dataframe 2 (291 x 14976) in addition to consisting of the shared
> identifier, also has numerous columns consisting of values (VALUE1,
> VALUE2). I would like to multiply the PROP_AREA in dataframe 1 by each
> value in dataframe 2 (VALUE1 through VALUE14976) based on the GROUP factor,
> constructing a final dataframe of size 3272 x 14976. An example of the data
> frames are as follows:
>
>
> frame1:
>
> ID
>
> GROUP
>
> PROP_AREA
>
> 1
>
> A
>
> 0.33
>
> 2
>
> A
>
> 0.33
>
> 3
>
> A
>
> 0.33
>
> 4
>
> B
>
> 0.50
>
> 5
>
> B
>
> 0.50
>
> 6
>
> C
>
> 1.00
>
> 7
>
> D
>
> 1.00
>
>
>
> frame2:
>
> GROUP
>
> VALUE1
>
> VALUE2
>
> A
>
> 10
>
> 5
>
> B
>
> 20
>
> 10
>
> C
>
> 30
>
> 15
>
> D
>
> 40
>
> 20
>
>
>
>   Desired dataframe
>
> frame3:
>
> ID
>
> VALUE1
>
> VALUE2
>
> 1
>
> 3.3
>
> 1.65
>
> 2
>
> 3.3
>
> 1.65
>
> 3
>
> 3.3
>
> 1.65
>
> 4
>
> 10
>
> 5
>
> 5
>
> 10
>
> 5
>
> 6
>
> 30
>
> 15
>
> 7
>
> 40
>
> 20
>
>
>
>
>
> I assume I would need to use the %in% function or if statements, but am
> unsure how to write the code. I have attempted to construct a for loop with
> an if statement, but have not been successful as of yet.
>
>
> for(i in 1:nrow(frame1)) {
>
>    for(j in 2:ncol(frame2)) {
>
>      if (frame1$GROUP[i] == frame2$GROUP[i]) {
>
>        frame3[i,j+1] <- frame1$PROP_AREA[i]*frame2[i,j+1]
>
>      }
>
>    }
>
> }
>
>
> Any advice on suggested code or packages to read up on would be much
> appreciated.
>
> Brock
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chl948 at mail.usask.ca  Thu Dec  4 04:01:41 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 03 Dec 2014 21:01:41 -0600
Subject: [R] coerce data to numeric
In-Reply-To: <1417631352.22623.YahooMailNeo@web184305.mail.ne1.yahoo.com>
References: <1417631352.22623.YahooMailNeo@web184305.mail.ne1.yahoo.com>
Message-ID: <547FCE95.6020906@mail.usask.ca>

In your function 'nbars()', I see the line:

       tX = rbind(tX, as.data.frame(cbind(GId = " ",Grp = names(sG[n]),
              S = fm, T = fm)))

It seems that you wish to have a data frame that has numeric variables 
'S' and 'T'.  The reason why you have character variables of 'S' and 'T' 
from your code is that you used a character vector when function 
'cbind()' is used.   Please see the following example:

 > cbind(1:3, 4:6)
      [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
 > cbind(1:3, LETTERS[1:3])
      [,1] [,2]
[1,] "1"  "A"
[2,] "2"  "B"
[3,] "3"  "C"
 >

What do you see?  I see that numeric values are changed to characters. 
Hence, I guess that you will have the output that you want if you change 
your code as below:

       tX = rbind(tX, as.data.frame(cbind(GId =0,Grp = 0,
              S = fm, T = fm)))

Of course you have to do little more works with this change in order to 
get final bar plots.  I hope this helps.

Chel Hee Lee

On 12/03/2014 12:29 PM, Charles R Parker wrote:
> I am trying to create groups of barplots from data that have different number of records in the groups, in such a way that all of the plots will have the same numbers and sizes of bars represented even when some of the groups will have some bars of zero height. The goal then would be to display multiple plots on a single page using split.screen or something similar. lattice does not seem suitable because of the data structure it operates on. A simple data structure that I operate on is given here:
>
>> dput(stplot)
> structure(list(GId = structure(1:11, .Label = c("A1", "B1", "B2",
> "B3", "B4", "B5", "C1", "C2", "D1", "D2", "D3"), class = "factor"),
>      Grp = structure(c(1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 4L, 4L,
>      4L), .Label = c("A", "B", "C", "D"), class = "factor"), S = c(12.3,
>      23.8, 0, 7.6, 14.32, 1.9, 5.1, 0, 14.6, 10.1, 8.7), T = c(5L,
>      12L, 2L, 1L, 4L, 1L, 1L, 9L, 5L, 6L, 3L)), .Names = c("GId",
> "Grp", "S", "T"), class = "data.frame", row.names = c(NA, -11L
> ))
>
>
> My code, which doesn't quite work is:
>
>> nbars <-
> function(x){
>    sG = summary(x$Grp)
>    mG = max(sG)
>    for(n in 1:length(sG)){
>      tX = subset(x,x$Grp==names(sG[n]))
>      if(nrow(tX) < mG){
>        fm = as.numeric(rep(length = mG - nrow(tX), 0))
>        tX = rbind(tX, as.data.frame(cbind(GId = " ",Grp = names(sG[n]),
>               S = fm, T = fm)))
>      }
> #print(tX)
> #dput(t(as.matrix(tX[,3:4])))
>      barplot(t(as.matrix(tX[,3:4])),beside=TRUE, names.arg=tX$GId,
>                col = c("navy","gray"))
>    }
> }
>
>
> The function nbars first gets the list of group values with their counts 'summary(x$Grp)'.
> It then determines the maximum number of bar pairs in the largest of the groups 'max(sG)', and uses this to determine how much each smaller group needs to be padded to fill out the proper number of bars in the ultimate barplots, using the for loop. If you uncomment the #print(tX) you can see that this works...sort of. The problem becomes apparent if you uncomment the #dput. This shows that the tX treats the S and T values as characters rather than as numeric values. This prevents the barplots from working. By changing the for loop to begin 'for(n in 2:length(sG)' the second plot will display correctly, but the third plot will fail.
>
> I have tried various options to force the S and T variables to be numeric, but none of those have worked (as.numeric(fm), as.matrix(fm), as.vector(fm)) in the 'if(nrow(tX) < mG)' loop, but these have not worked.
>
> If there is a sure-fire way to solve the problem I would be grateful.
>
> Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Pradip.Muhuri at samhsa.hhs.gov  Thu Dec  4 04:43:37 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Thu, 4 Dec 2014 03:43:37 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <547FBD50.2090407@mail.usask.ca>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
	<E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
	<547FBD50.2090407@mail.usask.ca>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C389302EA@PL-EMSMB20.ees.hhs.gov>

Hello Chel and David,

Thank you very much for providing new insights into this issue.  Here is one more question.  Why  does the mutate () give incorrect results here? 

# The following gives INCORRECT results - mutated()ed object
na.date.cases = ifelse(!is.na(oiddate),1,0)

# The following gives CORRECT results
new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)

###############################  reproducible example - slightly revised/modified  ###############
library(dplyr)
# data object - description 

temp <- "id  mrjdate cocdate inhdate haldate
1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
2             NA         NA         NA         NA     
3     2009-10-24         NA 2011-10-13         NA
4     2007-10-10         NA         NA         NA
5     2006-09-01 2005-08-10         NA         NA
6     2007-09-04 2011-10-05         NA         NA
7     2005-10-25         NA         NA 2011-11-04"

# read the data object

example.data <- read.table(textConnection(temp), 
                    colClasses=c("character", "Date", "Date", "Date", "Date"),  
                    header=TRUE, as.is=TRUE
                    )


# create a new column -dplyr solution (Acknowledgement: Arun)

new1 <- example.data %>% 
     rowwise() %>%
      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate, na.rm=TRUE), origin='1970-01-01'),
             na.date.cases = ifelse(!is.na(oiddate),1,0)
             )

# create a new column - Base R solution (Acknowlegement: Mark Sharp)

new2 <- example.data
new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
  if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
    max_d <- NA
  } else {
    max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
  }
  max_d}),
  origin = "1970-01-01")

new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)


identical(new1, new2) 

table(new1$oiddate)
table(new2$oiddate)

# print records

print (new1); print(new2)

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

-----Original Message-----
From: Chel Hee Lee [mailto:chl948 at mail.usask.ca] 
Sent: Wednesday, December 03, 2014 8:48 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

The output in the object 'new1' are apparently same the output in the object 'new2'.  Are you trying to compare the entries of two outputs 'new1' and 'new2'?  If so, the function 'all()' would be useful:

 > all(new1 == new2, na.rm=TRUE)
[1] TRUE

If you are interested in the comparison of two objects in terms of class, then the function 'identical()' is useful:

 > attributes(new1)
$names
[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oldflag"

$class
[1] "rowwise_df" "tbl_df"     "tbl"        "data.frame"

$row.names
[1] 1 2 3 4 5 6 7

 > attributes(new2)
$names
[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oiddate"

$row.names
[1] 1 2 3 4 5 6 7

$class
[1] "data.frame"

I hope this helps.

Chel Hee Lee

On 12/03/2014 04:10 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
> Hello,
>
> Two alternative approaches - mutate() vs. sapply() - were used to get the desired results (i.e., creating a new column of the most recent date  from 4 dates ) with help from Arun and Mark on this forum.  I now find that the two data objects (created using two different approaches) are not identical although results are exactly the same.
>
> identical(new1, new2)
> [1] FALSE
>
> Please see the reproducible example below.
>
> I don't understand why the code returns FALSE here.  Any hints/comments  will be  appreciated.
>
> Thanks,
>
> Pradip
>
> #############################################  reproducible example 
> ########################################
> library(dplyr)
> # data object - description
>
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
>
> # read the data object
>
> example.data <- read.table(textConnection(temp),
>                      colClasses=c("character", "Date", "Date", "Date", "Date"),
>                      header=TRUE, as.is=TRUE
>                      )
>
>
> # create a new column -dplyr solution (Acknowledgement: Arun)
>
> new1 <- example.data %>%
>       rowwise() %>%
>        mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>                                                                 
> na.rm=TRUE), origin='1970-01-01'))
>
> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
>
> new2 <- example.data
> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>    if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
>      max_d <- NA
>    } else {
>      max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
>    }
>    max_d}),
>    origin = "1970-01-01")
>
> identical(new1, new2)
>
> # print records
>
> print (new1); print(new2)
>
> Pradip K. Muhuri
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip 
> (SAMHSA/CBHSQ)
> Sent: Sunday, November 09, 2014 6:11 AM
> To: 'Mark Sharp'
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from 
> dates in four columns using the dplyr package (mutate verb)
>
> Hi Mark,
>
> Your code has also given me the results I expected.  Thank you so much for your help.
>
> Regards,
>
> Pradip
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
> -----Original Message-----
> From: Mark Sharp [mailto:msharp at TxBiomed.org]
> Sent: Sunday, November 09, 2014 3:01 AM
> To: Muhuri, Pradip (SAMHSA/CBHSQ)
> Cc: r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from 
> dates in four columns using the dplyr package (mutate verb)
>
> Pradip,
>
> mutate() works on the entire column as a vector so that you find the maximum of the entire data set.
>
> I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.
>
> max() does not want a dataframe thus the use of unlist().
>
> Using your definition of data1:
>
> data3 <- data1
> data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
>    if (all(is.na(unlist(data1[row, -1])))) {
>      max_d <- NA
>    } else {
>      max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>    }
>    max_d}),
>    origin = "1970-01-01")
>
> data3
>    id    mrjdate    cocdate    inhdate    haldate    oidflag
> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>
>
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center Texas Biomedical Research 
> Institute P.O. Box 760549 San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
>
>
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From paulbernal07 at gmail.com  Thu Dec  4 05:12:27 2014
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 3 Dec 2014 22:12:27 -0600
Subject: [R] R Arimax Function
Message-ID: <CAMOcQfNvUsg3S+KtT_0yxwNyhM_EWoO28KArQ9w3Wk2i1VXZ2g@mail.gmail.com>

Hello everyone,

I am just trying to understand how the Arimax function works, so my
questions are:

1. If I have a univariate time series of sales and sales are dependent
upon, say inflation rates, then my xreg would be inflation rates right?

2. Now is I have historial data on sales (from january 2000 to december
2010) then my xreg argument would be a historical time series of inflation
rates on the same time frame? (from january 2000 to december 2010?)

3. If I want to predit, say 5 years of monthly data (60 periods) using the
exogenous variable (in this particular case inflation rates) then that
means I would have to have a a 60 period forecast of inflation rates and
that would be my newxreg argument?

Any guidance will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Thu Dec  4 05:30:09 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 03 Dec 2014 22:30:09 -0600
Subject: [R] R installation
In-Reply-To: <CAN7A_QznVVXtszQ2n0M9Cm+oNRbjRpL2h=dmX4pBjcYaCh2Jeg@mail.gmail.com>
References: <CAN7A_QznVVXtszQ2n0M9Cm+oNRbjRpL2h=dmX4pBjcYaCh2Jeg@mail.gmail.com>
Message-ID: <547FE351.60901@mail.usask.ca>

This question seems to be the problem specific to Ubuntu.  What if you 
post the message to <r-sig-debian at r-project.org>??  I hope you get 
answers from that mailing list.

Chel Hee Lee

On 12/02/2014 11:10 AM, VG wrote:
> Hi everyone,
>
> I was having trouble with R i installed some time ago on my local ubuntu
> machine. So i removed R completely from my system in order to re install
> it. I used these commands to install R
>
> sudo apt-get install r-base r-base-dev
>
> Then on the terminal I typed which R:
> it returns
> /usr/bin/R
>
> When i launch R on the terminal by typing R it gives me this:
>
> */usr/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or directory*
>
> R version 3.1.2 (2014-10-31) -- "Pumpkin Helmet"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: i486-pc-linux-gnu (32-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
>
> *Warning: namespace ?DESeq? is not available and has been replacedby
> .GlobalEnv when processing object ?data2*
>
> To fix "*/usr/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or
> directory*"
>
> I went to
> */usr/lib/R/etc/ and did *
>
> *file ldpaths and it gave me*
>
> ldpaths: broken symbolic link to `/etc/R/ldpaths'
>
> How to fix this??
> Also I need to fix warning
>
> Regards
> Varun
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From paulbernal07 at gmail.com  Thu Dec  4 06:12:43 2014
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Wed, 3 Dec 2014 23:12:43 -0600
Subject: [R] R Arimax Function
In-Reply-To: <CAHz+bWZ+MPSyaQ9=GnB-fGCT6sqerykqNE_AG0+p2VyB1mkSeg@mail.gmail.com>
References: <CAMOcQfNvUsg3S+KtT_0yxwNyhM_EWoO28KArQ9w3Wk2i1VXZ2g@mail.gmail.com>
	<CAHz+bWZ+MPSyaQ9=GnB-fGCT6sqerykqNE_AG0+p2VyB1mkSeg@mail.gmail.com>
Message-ID: <CAMOcQfN3AtHdyYuvi8cuHUePQ_GR0_H=tFNX8r0Eu_ZgBro5mw@mail.gmail.com>

Hello Mark,

Thank you for your timely reply. All I want to know is if the xreg argument
must contain the same amount of historical observations as the dependent
variable and if newxreg  has to have a forecast of the exogenous variable
equal to the number of periods to be forecasted.

Best regards and thanks again,

Paul

2014-12-03 22:30 GMT-06:00 Mark Leeds <markleeds2 at gmail.com>:

> hi paul: I don't have time to answer all of your questions but below
> should help.
> there'sa  better one that actually how arima is better for forecasting
> than gls
> but I can't find it right now. if I find it, I'll send it.
>
>
> http://stats.stackexchange.com/questions/6469/simple-linear-model-with-autocorrelated-errors-in-r
>
>
> On Wed, Dec 3, 2014 at 11:12 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Hello everyone,
>>
>> I am just trying to understand how the Arimax function works, so my
>> questions are:
>>
>> 1. If I have a univariate time series of sales and sales are dependent
>> upon, say inflation rates, then my xreg would be inflation rates right?
>>
>> 2. Now is I have historial data on sales (from january 2000 to december
>> 2010) then my xreg argument would be a historical time series of inflation
>> rates on the same time frame? (from january 2000 to december 2010?)
>>
>> 3. If I want to predit, say 5 years of monthly data (60 periods) using the
>> exogenous variable (in this particular case inflation rates) then that
>> means I would have to have a a 60 period forecast of inflation rates and
>> that would be my newxreg argument?
>>
>> Any guidance will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Thu Dec  4 06:27:53 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Wed, 03 Dec 2014 23:27:53 -0600
Subject: [R] FW: R Statistics
In-Reply-To: <CAF8bMcY2n_Btb9vkGSxQjMPrBcACSWceqZcsk3yRdTcx2fKcyQ@mail.gmail.com>
References: <DUB124-W433ED6F408ECBBBC645DB0F57A0@phx.gbl>
	<547DF6C7.4070304@r-tutor.com>
	<DUB124-W52C56A1971F89D9EF44976F57A0@phx.gbl>
	<CAF8bMcY2n_Btb9vkGSxQjMPrBcACSWceqZcsk3yRdTcx2fKcyQ@mail.gmail.com>
Message-ID: <547FF0D9.8040804@mail.usask.ca>

Or, you may use this approach:

 > attach(achtergrond)
 > spits <- ifelse(uurenminuut >= 5.30 & uurenminuut < 9.30, "morning",
+ ifelse(uurenminuut >=16.30 & uurenminuut < 19.0, "evening",
+ "between"))
 > table(spits)
spits
between evening morning
    1636     142     579
 >

I personally like the approach presented by Bill Dunlap (in the previous 
message).  I think his approach is smart and nice.  You will see the 
same results as shown in the above:

 > 
achtergrond$spits=cut(achtergrond$uurenminuut,c(-1.0,5.30,9.30,16.30,19.0,24.0),right=FALSE)
 > levels(achtergrond$spits) <- 
c("between","morning","between","evening","between")
 > table(achtergrond$spits)

between morning evening
    1636     579     142
 >

You can also use function 'findInterval()' instead of using 'cut()'.  I 
hope this helps.

Chel Hee Lee


On 12/02/2014 02:04 PM, William Dunlap wrote:
> You can do this in 2 steps - have cut() make a factor with a different
> level for each time period
> then use levels<-() to merge some of the levels.
>     > z <- cut(.5:3.5, breaks=c(0,1,2,3,4), labels=c("0-1", "1-2", "2-3",
> "3-4"))
>     > levels(z)
>     [1] "0-1" "1-2" "2-3" "3-4"
>     > levels(z) <- c("between", "1-2", "between", "3-4") # or
> levels(z)[c(1,3)] <- "between"
>     > str(z)
>     Factor w/ 3 levels "between","1-2",..: 1 2 1 3
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Dec 2, 2014 at 11:32 AM, Dries David <dries-david at hotmail.com>
> wrote:
>
>>
>>>> Hey
>>>> I have a question about making a new variable in R. I have put my
>> dataset in attachment. I have to make a new variable "spits" where
>> spits=morning when uurenminuut (also a variabel) is between 5.30 and 9.30,
>> when uurenminuut is between 16.30 and 19.0 spits has to be equal to
>> evening. But here is my problem: for all the values not between 5.30- 9.30
>> and 16.30-19.0 spits must be equal to "between"
>>>>
>>>> achtergrond$minuutdec=achtergrond$minuut/100
>>>> achtergrond$uurenminuut=achtergrond$uur+achtergrond$minuutdec
>>>>
>> achtergrond$spits=cut(uurenminuut,c(-1.0,5.30,9.30,16.30,19.0,24.0),labels=c("between","morning","between","evening","between"),right=FALSE)
>>>>
>>>> When I do this i get a warning message, because I use between more
>> than once as label. Between has to be one label that covers all values that
>> are not in morning and evening.
>>>>
>>>> Could you help me with this?
>>>>
>>>> Kind regards
>>>>
>>>> Dries David
>>>>
>>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michel.arnaud at cirad.fr  Thu Dec  4 11:09:12 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 04 Dec 2014 11:09:12 +0100
Subject: [R] outputs of a function
In-Reply-To: <381778580.2795341.1417597386539.JavaMail.yahoo@jws10972.mail.sg3.yahoo.com>
References: <381778580.2795341.1417597386539.JavaMail.yahoo@jws10972.mail.sg3.yahoo.com>
Message-ID: <548032C8.4020808@cirad.fr>

Hello

I have a function named FctModele13 in which
1) I calculate a dataframe named Total and
2) I used ggplot2.
I have the following problem. I cannot produce simultaneously

  * the graphic by ggplot2
  * the dataframe

My simplified code is the following one :


TT <- FctModele13(ListePlusde50ans, PourcentSexeCsp, NbAn=10)
FctModele <- function(ListePlusde50ans, PourcentSexeCsp, NbAn)
{
# calculate Total
.....
.....
Total <- data.frame(....)
###################
# plot by ggplot
library(ggplot2)
ggplot(.....) +
......
axis.title.y = element_text(size = 8)) +
labs(title="Title")

Total
}



Any idea ?

-- 
Michel ARNAUD
CIRAD Montpellier
tel : 04.67.61.75.38
port: 06.47.43.55.31


	[[alternative HTML version deleted]]


From mestre.frederico at gmail.com  Thu Dec  4 12:11:57 2014
From: mestre.frederico at gmail.com (Frederico Mestre)
Date: Thu, 4 Dec 2014 11:11:57 +0000
Subject: [R] Error loading workspace
Message-ID: <CAPfBvqz1KJOcTcECOpD+Dg+Xadek+okkEWrhjCftUs8rh51O-Q@mail.gmail.com>

Hello,

I'm trying to load a workspace and I'm getting this error:

value of 'SET_ATTRIB' must be a pairlist or NULL, not a 'double'

Is there anything I can do to correct this?

Cheers,
Frederico Mestre

	[[alternative HTML version deleted]]


From tal.galili at gmail.com  Thu Dec  4 13:40:55 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Thu, 4 Dec 2014 14:40:55 +0200
Subject: [R] Using "line" (Tukey's robust line) on 3 observations?
Message-ID: <CANdJ3dU7VvSFmeK_S-FDap5erqtsNZaSTyJAo_gxTGzGPCs+FQ@mail.gmail.com>

By accident I came across the following example:

x <- 1:3
y <- 1:3
line(x, y) # returns:

Call:
line(x, x)

Coefficients:
[1]  -2   2


While when using 1:4, it will give the more reasonable 0,1 coefficients.

I imagine this is in the way it calculate the quantiles (i.e.: a "feature").
Can someone help in explaining this?


Thanks,
Tal









----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Dec  4 15:04:25 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Dec 2014 15:04:25 +0100
Subject: [R] lmom package - Resending the email
In-Reply-To: <844CA46E-B55F-4E5B-BCFA-C11D1C025C7D@uni-bonn.de>
References: <969494576.2824738.1417599943152.JavaMail.yahoo@jws10980.mail.sg3.yahoo.com>
	<844CA46E-B55F-4E5B-BCFA-C11D1C025C7D@uni-bonn.de>
Message-ID: <3EFB05A1-BAD3-480A-AD07-B1E05B817444@gmail.com>

lmom is based on L-moments, which are different from ordinary moments, except for the 1st one. It would be truly miraculous if it gave the same result as the ordinary method of moments or maximum likelihood. 

Estimates of any distributional parameter requires that the model actually fits the data, and in your case a qqnorm(amounts) shows that they are certainly not normal. In such cases, the L-moment estimator of the std.dev. is not necessarily an estimate of the std.dev. of the actual distribution.

A lognormal distribution seems to fit the data better. However, the L-moments suggest a value for zeta (the lower bound) of 3226 which is well inside the range of the actual data. In fact there are 16 observations that are less than 3226. Maximum likelihood would never do that, but the same sort of effect is well-known for the ordinary method of moments.

In short, you need to study the theory before you appply its results.

- Peter D.


On 03 Dec 2014, at 10:57 , Simon Zehnder <szehnder at uni-bonn.de> wrote:

> Katherine,
> 
> for a deeper understanding of differing values it makes sense to provide the list at least with an online description of the corresponding functions used in Minitab and SPSS?
> 
> Best 
> Simon
> On 03 Dec 2014, at 10:45, Katherine Gobin via R-help <r-help at r-project.org> wrote:
> 
>> Dear R forum
>> I sincerely apologize as my earlier mail with the captioned subject, since all the values got mixed up and the email is not readable. I am trying to write it again. 
>> My problem is I have a set of data and I am trying to fit some distributions to it. As a part of this exercise, I need to find out the parameter values of various distributions e.g. Normal distribution, Log normal distribution etc. I am using lmom package to do the same, however the parameter values obtained using lmom pacakge differ to a large extent from the parameter values obtained using say MINITAB and SPSS as given below -
>> _____________________________________________
>> 
>> amounts =  c(38572.5599129508,11426.6705314315,21974.1571641187,118530.32782443,3735.43055996748,66309.5211176106,72039.2934132668,21934.8841708626,78564.9136114375,1703.65825161293,2116.89180930203,11003.495671332,19486.3296339113,1871.35861218795,6887.53851253407,148900.978055447,7078.56497101651,79348.1239806592,20157.6241066905,1259.99802108593,3934.45912233674,3297.69946631591,56221.1154121067,13322.0705174134,45110.2498756567,31910.3686613912,3196.71168501252,32843.0140437202,14615.1499458453,13013.9915051561,116104.176753387,7229.03056392023,9833.37962177814,2882.63239493673,165457.372543821,41114.066453219,47188.1677766245,25708.5883755617,82703.7378298092,8845.04197017415,844.28834047836,35410.8486123933,19446.3808445684,17662.2398792892,11882.8497070776,4277181.17817307,30239.0371267968,45165.7512343364,22102.8513746687,5988.69296597127,51345.0146170238,1275658.35495898,15260.4892854214,8861.76578480635,37647.1638704867,4979.53544046949,7012.48134772332,3385.20612391205,1911.03114395959,66886.5036605189,2223.47536156462,814.947809578378,234.028589468841,5397.4347625133,13346.3226579065,28809.3901352898,6387.69226236731,5639.42730553242,2011100.92675507,4150.63707173462,34098.7514446498,3437.10672573502,289710.315303182,8664.66947305203,13813.3867161134,208817.521491857,169317.624400274,9966.78447705792,37811.1721605562,2263.19211279927,80434.5581206454,19057.8093104899,24664.5067589624,25136.5042354789,3582.85741610706,6683.13898432794,65423.9991390846,134848.302304064,3018.55371579808,546249.641168158,172926.689143006,3074.15064180208,1521.70624812788,59012.4248281661,21226.928522236,17572.5682970983,226.646947337851,56232.2982652019,14641.0043361533,6997.94414914865)
>> 
>> library(lmom)
>> lmom  =  samlmu(amounts)
>> # __________________________________________________________________
>> # Normal Distribution parameters
>> parameters_of_NOR  <- pelnor(lmom); parameters_of_NOR
>> 
>>      mu          sigma 115148.4    175945.8
>>                      Location       Scale     Minitab         115148.4     485173SPSS           115148.4     485173
>> # __________________________________________________________________
>> # Log Normal (3 Parameter) Distribution parameters
>>       zeta                mu               sigma 3225.798890    9.114879      2.240841
>>                              Location            Scale           Shape
>> MINITAB               9.73361             1.76298      75.51864SPSS                    9.7336                1.763          75.519           # __________________________________________________________________
>> 
>> Besides Genaralized extreme Value distributions, all the other distributions e.g. Gamma, Exponential (2 parameter) distributions etc give different results than MINITAB and SPSS.
>> Can some one guide me?
>> 
>> Regards
>> Katherine
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Thu Dec  4 15:09:06 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 04 Dec 2014 06:09:06 -0800
Subject: [R] outputs of a function
In-Reply-To: <548032C8.4020808@cirad.fr>
References: <381778580.2795341.1417597386539.JavaMail.yahoo@jws10972.mail.sg3.yahoo.com>
	<548032C8.4020808@cirad.fr>
Message-ID: <AA3F6958-4836-40D8-832D-471233BBB3E4@dcn.davis.CA.us>

This is a poor approach from a usability perspective... I suggest you create two separate functions rather than one.

However, you seem to be missing a crucial point in the use of ggplot, which also applies to lattice graphics. These functions actually don't produce output at all... they produce "grid graphics" objects that produce graphic output when printed. Interactively, this printing step is done automatically for you, but inside functions that does not happen. So, you can wrap your ggplot expression in a print function call to have your function produce the graphic output as a side effect.

print( ggplot(.....) +
......
axis.title.y = element_text(size = 8)) +
labs(title="Title") )

One of the things that is nice about grid graphics is that you can modify the object before you print it. For example, if you make a basic scatterplot function for your data, you can tack on things like labels or extra lines to aid your explanation about what is in the data just as you print it. Then you can also print it later with different notations or none at all. Having a separate graph-generating function that just returns the grid object for you to print or modify as you wish can be quite useful later.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 4, 2014 2:09:12 AM PST, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>Hello
>
>I have a function named FctModele13 in which
>1) I calculate a dataframe named Total and
>2) I used ggplot2.
>I have the following problem. I cannot produce simultaneously
>
>  * the graphic by ggplot2
>  * the dataframe
>
>My simplified code is the following one :
>
>
>TT <- FctModele13(ListePlusde50ans, PourcentSexeCsp, NbAn=10)
>FctModele <- function(ListePlusde50ans, PourcentSexeCsp, NbAn)
>{
># calculate Total
>.....
>.....
>Total <- data.frame(....)
>###################
># plot by ggplot
>library(ggplot2)
>ggplot(.....) +
>......
>axis.title.y = element_text(size = 8)) +
>labs(title="Title")
>
>Total
>}
>
>
>
>Any idea ?


From highstat at highstat.com  Thu Dec  4 15:47:54 2014
From: highstat at highstat.com (Highland Statistics Ltd)
Date: Thu, 04 Dec 2014 14:47:54 +0000
Subject: [R] 8 statistics course; January - June 2015
Message-ID: <5480741A.5020401@highstat.com>

Apologies for cross-posting

We would like to announce the following 8 statistics course covering 
topics such as R, data exploration (using lattice and ggplot2), multiple 
linear regression, GLM, GAM, mixed modelling, GLMM, GAMM, Bayesian 
analysis and MCMC. For further information, registration, prices, course 
flyers, etc., see:

http://www.highstat.com/statscourse.htm



List of open courses in January - June 2015:

Data exploration, regression, GLM & GAM with introduction to R.
2 - 6 February 2015. Coimbra, Portugal

Introduction to Linear mixed effects models,  GLMM and MCMC with R
9-13 February 2015. Lisbon

Data exploration, regression, GLM & GAM with introduction to R.
23-27 March 2015. University of Southampton, Southampton, UK

Introduction to Bayesian statistics and MCMC
8-10 April 2015. University of Southampton, Southampton, UK

Introduction to Linear Mixed Effects Models and GLMM with R
3-17 April 2015. University of Southampton, Southampton, UK

Data exploration, regression, GLM & GAM with introduction to R.
4-8 May 2015. University of Palermo, Italy

Introduction to GAM and GAMM with R
1-15 May 2015. University of Genua, Italy

Data exploration, regression, GLM & GAM with introduction to R
6-10 July 2015. Leamington, Ontario, Canada





-- 
Dr. Alain F. Zuur

First author of:
1. Beginner's Guide to GAMM with R (2014).
2. Beginner's Guide to GLM and GLMM with R (2013).
3. Beginner's Guide to GAM with R (2012).
4. Zero Inflated Models and GLMM with R (2012).
5. A Beginner's Guide to R (2009).
6. Mixed effects models and extensions in ecology with R (2009).
7. Analysing Ecological Data (2007).

Highland Statistics Ltd.
9 St Clair Wynd
UK - AB41 6DZ Newburgh
Tel:   0044 1358 788177
Email: highstat at highstat.com
URL:   www.highstat.com


From michel.arnaud at cirad.fr  Thu Dec  4 16:20:19 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 04 Dec 2014 16:20:19 +0100
Subject: [R] outputs of a function
In-Reply-To: <AA3F6958-4836-40D8-832D-471233BBB3E4@dcn.davis.CA.us>
References: <381778580.2795341.1417597386539.JavaMail.yahoo@jws10972.mail.sg3.yahoo.com>
	<548032C8.4020808@cirad.fr>
	<AA3F6958-4836-40D8-832D-471233BBB3E4@dcn.davis.CA.us>
Message-ID: <54807BB3.7060402@cirad.fr>

Thank you Jeff and Mark for your help
Michel

Le 04/12/2014 15:09, Jeff Newmiller a ?crit :
> This is a poor approach from a usability perspective... I suggest you create two separate functions rather than one.
>
> However, you seem to be missing a crucial point in the use of ggplot, which also applies to lattice graphics. These functions actually don't produce output at all... they produce "grid graphics" objects that produce graphic output when printed. Interactively, this printing step is done automatically for you, but inside functions that does not happen. So, you can wrap your ggplot expression in a print function call to have your function produce the graphic output as a side effect.
>
> print( ggplot(.....) +
> ......
> axis.title.y = element_text(size = 8)) +
> labs(title="Title") )
>
> One of the things that is nice about grid graphics is that you can modify the object before you print it. For example, if you make a basic scatterplot function for your data, you can tack on things like labels or extra lines to aid your explanation about what is in the data just as you print it. Then you can also print it later with different notations or none at all. Having a separate graph-generating function that just returns the grid object for you to print or modify as you wish can be quite useful later.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On December 4, 2014 2:09:12 AM PST, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>> Hello
>>
>> I have a function named FctModele13 in which
>> 1) I calculate a dataframe named Total and
>> 2) I used ggplot2.
>> I have the following problem. I cannot produce simultaneously
>>
>>   * the graphic by ggplot2
>>   * the dataframe
>>
>> My simplified code is the following one :
>>
>>
>> TT <- FctModele13(ListePlusde50ans, PourcentSexeCsp, NbAn=10)
>> FctModele <- function(ListePlusde50ans, PourcentSexeCsp, NbAn)
>> {
>> # calculate Total
>> .....
>> .....
>> Total <- data.frame(....)
>> ###################
>> # plot by ggplot
>> library(ggplot2)
>> ggplot(.....) +
>> ......
>> axis.title.y = element_text(size = 8)) +
>> labs(title="Title")
>>
>> Total
>> }
>>
>>
>>
>> Any idea ?
>
>

-- 
Michel ARNAUD
DGDRD-Drh - TA 174/04
tel : 04.67.61.75.38
port: 06.47.43.55.31


From gosia_jl at hotmail.com  Thu Dec  4 13:16:56 2014
From: gosia_jl at hotmail.com (Malgosia Lubczynska)
Date: Thu, 4 Dec 2014 12:16:56 +0000
Subject: [R] change x-axis labels in dlnm's slices figures
Message-ID: <DUB118-W347FA7ECE84BD05089393BE5780@phx.gbl>






Hello,





I am using the dlnm package and I would like
to change the x-axis labels in the slices figures (the figures showing associations along the
range of the predictor at specific lags and along the range of lags at specific
values of the predictor. I am using the
following script:




plot(crosspred, "slices", var=c(33,31,29,28),
lag=c(0,1,2,3), ci.level = 0.95, col=2, ci.arg=list(density=60, col=grey(0.7)))




When I simply add "xlab ="
statement, nothing changes and the labels remain as default (Var and lag). 



Thank you,Gosia
 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Dec  4 19:14:10 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Dec 2014 10:14:10 -0800
Subject: [R] Getting the most recent dates in a new column from dates in
	four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C389302EA@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
	<E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
	<547FBD50.2090407@mail.usask.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C389302EA@PL-EMSMB20.ees.hhs.gov>
Message-ID: <8073FB11-CA6E-4878-865F-8ABEE0709289@comcast.net>


On Dec 3, 2014, at 7:43 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:

> Hello Chel and David,
> 
> Thank you very much for providing new insights into this issue.  Here is one more question.  Why  does the mutate () give incorrect results here? 
> 
> # The following gives INCORRECT results - mutated()ed object
> na.date.cases = ifelse(!is.na(oiddate),1,0)
> 
> # The following gives CORRECT results
> new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)
> 
> ###############################  reproducible example - slightly revised/modified  ###############
> library(dplyr)
> # data object - description 
> 
> temp <- "id  mrjdate cocdate inhdate haldate
> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
> 2             NA         NA         NA         NA     
> 3     2009-10-24         NA 2011-10-13         NA
> 4     2007-10-10         NA         NA         NA
> 5     2006-09-01 2005-08-10         NA         NA
> 6     2007-09-04 2011-10-05         NA         NA
> 7     2005-10-25         NA         NA 2011-11-04"
> 
> # read the data object
> 
> example.data <- read.table(textConnection(temp), 
>                    colClasses=c("character", "Date", "Date", "Date", "Date"),  
>                    header=TRUE, as.is=TRUE
>                    )
> 
> 
> # create a new column -dplyr solution (Acknowledgement: Arun)
> 
> new1 <- example.data %>% 
>     rowwise() %>%
>      mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate, na.rm=TRUE), origin='1970-01-01'),
>             na.date.cases = ifelse(!is.na(oiddate),1,0)
>             )
> 

It would have been polite to include the warning printed to the console after this line of code. It seems to me that this highlights the fact that you used different logic in the two methods and got, therefore, different answers.

-- 
David.
> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
> 
> new2 <- example.data
> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>  if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
>    max_d <- NA
>  } else {
>    max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
>  }
>  max_d}),
>  origin = "1970-01-01")
> 
> new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)
> 
> 
> identical(new1, new2) 
> 
> table(new1$oiddate)
> table(new2$oiddate)
> 
> # print records
> 
> print (new1); print(new2)
> 
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> 
> -----Original Message-----
> From: Chel Hee Lee [mailto:chl948 at mail.usask.ca] 
> Sent: Wednesday, December 03, 2014 8:48 PM
> To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
> Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)
> 
> The output in the object 'new1' are apparently same the output in the object 'new2'.  Are you trying to compare the entries of two outputs 'new1' and 'new2'?  If so, the function 'all()' would be useful:
> 
>> all(new1 == new2, na.rm=TRUE)
> [1] TRUE
> 
> If you are interested in the comparison of two objects in terms of class, then the function 'identical()' is useful:
> 
>> attributes(new1)
> $names
> [1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oldflag"
> 
> $class
> [1] "rowwise_df" "tbl_df"     "tbl"        "data.frame"
> 
> $row.names
> [1] 1 2 3 4 5 6 7
> 
>> attributes(new2)
> $names
> [1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oiddate"
> 
> $row.names
> [1] 1 2 3 4 5 6 7
> 
> $class
> [1] "data.frame"
> 
> I hope this helps.
> 
> Chel Hee Lee
> 
> On 12/03/2014 04:10 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
>> Hello,
>> 
>> Two alternative approaches - mutate() vs. sapply() - were used to get the desired results (i.e., creating a new column of the most recent date  from 4 dates ) with help from Arun and Mark on this forum.  I now find that the two data objects (created using two different approaches) are not identical although results are exactly the same.
>> 
>> identical(new1, new2)
>> [1] FALSE
>> 
>> Please see the reproducible example below.
>> 
>> I don't understand why the code returns FALSE here.  Any hints/comments  will be  appreciated.
>> 
>> Thanks,
>> 
>> Pradip
>> 
>> #############################################  reproducible example 
>> ########################################
>> library(dplyr)
>> # data object - description
>> 
>> temp <- "id  mrjdate cocdate inhdate haldate
>> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>> 2             NA         NA         NA         NA
>> 3     2009-10-24         NA 2011-10-13         NA
>> 4     2007-10-10         NA         NA         NA
>> 5     2006-09-01 2005-08-10         NA         NA
>> 6     2007-09-04 2011-10-05         NA         NA
>> 7     2005-10-25         NA         NA 2011-11-04"
>> 
>> # read the data object
>> 
>> example.data <- read.table(textConnection(temp),
>>                     colClasses=c("character", "Date", "Date", "Date", "Date"),
>>                     header=TRUE, as.is=TRUE
>>                     )
>> 
>> 
>> # create a new column -dplyr solution (Acknowledgement: Arun)
>> 
>> new1 <- example.data %>%
>>      rowwise() %>%
>>       mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>> 
>> na.rm=TRUE), origin='1970-01-01'))
>> 
>> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
>> 
>> new2 <- example.data
>> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>>   if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')])))) {
>>     max_d <- NA
>>   } else {
>>     max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 'haldate')]), na.rm = TRUE)
>>   }
>>   max_d}),
>>   origin = "1970-01-01")
>> 
>> identical(new1, new2)
>> 
>> # print records
>> 
>> print (new1); print(new2)
>> 
>> Pradip K. Muhuri
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org 
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip 
>> (SAMHSA/CBHSQ)
>> Sent: Sunday, November 09, 2014 6:11 AM
>> To: 'Mark Sharp'
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Getting the most recent dates in a new column from 
>> dates in four columns using the dplyr package (mutate verb)
>> 
>> Hi Mark,
>> 
>> Your code has also given me the results I expected.  Thank you so much for your help.
>> 
>> Regards,
>> 
>> Pradip
>> 
>> Pradip K. Muhuri, PhD
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>> 
>> 
>> -----Original Message-----
>> From: Mark Sharp [mailto:msharp at TxBiomed.org]
>> Sent: Sunday, November 09, 2014 3:01 AM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Getting the most recent dates in a new column from 
>> dates in four columns using the dplyr package (mutate verb)
>> 
>> Pradip,
>> 
>> mutate() works on the entire column as a vector so that you find the maximum of the entire data set.
>> 
>> I am almost certain there is some nice way to handle this, but the sapply() function is a standard approach.
>> 
>> max() does not want a dataframe thus the use of unlist().
>> 
>> Using your definition of data1:
>> 
>> data3 <- data1
>> data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
>>   if (all(is.na(unlist(data1[row, -1])))) {
>>     max_d <- NA
>>   } else {
>>     max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>>   }
>>   max_d}),
>>   origin = "1970-01-01")
>> 
>> data3
>>   id    mrjdate    cocdate    inhdate    haldate    oidflag
>> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
>> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
>> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
>> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
>> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
>> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
>> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>> 
>> 
>> 
>> R. Mark Sharp, Ph.D.
>> Director of Primate Records Database
>> Southwest National Primate Research Center Texas Biomedical Research 
>> Institute P.O. Box 760549 San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org
>> 
>> 
>> 
>> 
>> 
>> NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Thu Dec  4 19:20:23 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 04 Dec 2014 10:20:23 -0800
Subject: [R] Getting the most recent dates in a new column from dates in
	four columns using the dplyr package (mutate verb)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C389302EA@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
	<E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
	<547FBD50.2090407@mail.usask.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C389302EA@PL-EMSMB20.ees.hhs.gov>
Message-ID: <3B9F6520-7FE6-4C2F-BCFA-6B997C0DDDCE@dcn.davis.CA.us>

There is something weird going on with mutate's interaction with the scalar Date objects. It seems to be passing them to max as constants of mode double.

Regardless, use of rowwise should be very rare, and you are definitely abusing it. Learn to work with vectors of values rather than one value at a time.

new3 <- example.data %>%
      mutate( oiddate = pmax( mrjdate, cocdate, inhdate, haldate, na.rm=TRUE)
                   , na.date.cases= as.numeric( !is.na( oiddate ) ) )

You might find it more useful to not convert the result of is.na to numeric... logical indexing can use that more efficiently than testing which rows have na.date.cases==1.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 3, 2014 7:43:37 PM PST, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hello Chel and David,
>
>Thank you very much for providing new insights into this issue.  Here
>is one more question.  Why  does the mutate () give incorrect results
>here? 
>
># The following gives INCORRECT results - mutated()ed object
>na.date.cases = ifelse(!is.na(oiddate),1,0)
>
># The following gives CORRECT results
>new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)
>
>###############################  reproducible example - slightly
>revised/modified  ###############
>library(dplyr)
># data object - description 
>
>temp <- "id  mrjdate cocdate inhdate haldate
>1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>2             NA         NA         NA         NA     
>3     2009-10-24         NA 2011-10-13         NA
>4     2007-10-10         NA         NA         NA
>5     2006-09-01 2005-08-10         NA         NA
>6     2007-09-04 2011-10-05         NA         NA
>7     2005-10-25         NA         NA 2011-11-04"
>
># read the data object
>
>example.data <- read.table(textConnection(temp), 
>           colClasses=c("character", "Date", "Date", "Date", "Date"),  
>                    header=TRUE, as.is=TRUE
>                    )
>
>
># create a new column -dplyr solution (Acknowledgement: Arun)
>
>new1 <- example.data %>% 
>     rowwise() %>%
>mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>na.rm=TRUE), origin='1970-01-01'),
>             na.date.cases = ifelse(!is.na(oiddate),1,0)
>             )
>
># create a new column - Base R solution (Acknowlegement: Mark Sharp)
>
>new2 <- example.data
>new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate',
>'inhdate', 'haldate')])))) {
>    max_d <- NA
>  } else {
>max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate',
>'haldate')]), na.rm = TRUE)
>  }
>  max_d}),
>  origin = "1970-01-01")
>
>new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)
>
>
>identical(new1, new2) 
>
>table(new1$oiddate)
>table(new2$oiddate)
>
># print records
>
>print (new1); print(new2)
>
>Pradip K. Muhuri, PhD
>SAMHSA/CBHSQ
>1 Choke Cherry Road, Room 2-1071
>Rockville, MD 20857
>Tel: 240-276-1070
>Fax: 240-276-1260
>
>-----Original Message-----
>From: Chel Hee Lee [mailto:chl948 at mail.usask.ca] 
>Sent: Wednesday, December 03, 2014 8:48 PM
>To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
>Subject: Re: [R] Getting the most recent dates in a new column from
>dates in four columns using the dplyr package (mutate verb)
>
>The output in the object 'new1' are apparently same the output in the
>object 'new2'.  Are you trying to compare the entries of two outputs
>'new1' and 'new2'?  If so, the function 'all()' would be useful:
>
> > all(new1 == new2, na.rm=TRUE)
>[1] TRUE
>
>If you are interested in the comparison of two objects in terms of
>class, then the function 'identical()' is useful:
>
> > attributes(new1)
>$names
>[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oldflag"
>
>$class
>[1] "rowwise_df" "tbl_df"     "tbl"        "data.frame"
>
>$row.names
>[1] 1 2 3 4 5 6 7
>
> > attributes(new2)
>$names
>[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oiddate"
>
>$row.names
>[1] 1 2 3 4 5 6 7
>
>$class
>[1] "data.frame"
>
>I hope this helps.
>
>Chel Hee Lee
>
>On 12/03/2014 04:10 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
>> Hello,
>>
>> Two alternative approaches - mutate() vs. sapply() - were used to get
>the desired results (i.e., creating a new column of the most recent
>date  from 4 dates ) with help from Arun and Mark on this forum.  I now
>find that the two data objects (created using two different approaches)
>are not identical although results are exactly the same.
>>
>> identical(new1, new2)
>> [1] FALSE
>>
>> Please see the reproducible example below.
>>
>> I don't understand why the code returns FALSE here.  Any
>hints/comments  will be  appreciated.
>>
>> Thanks,
>>
>> Pradip
>>
>> #############################################  reproducible example 
>> ########################################
>> library(dplyr)
>> # data object - description
>>
>> temp <- "id  mrjdate cocdate inhdate haldate
>> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>> 2             NA         NA         NA         NA
>> 3     2009-10-24         NA 2011-10-13         NA
>> 4     2007-10-10         NA         NA         NA
>> 5     2006-09-01 2005-08-10         NA         NA
>> 6     2007-09-04 2011-10-05         NA         NA
>> 7     2005-10-25         NA         NA 2011-11-04"
>>
>> # read the data object
>>
>> example.data <- read.table(textConnection(temp),
>>                      colClasses=c("character", "Date", "Date",
>"Date", "Date"),
>>                      header=TRUE, as.is=TRUE
>>                      )
>>
>>
>> # create a new column -dplyr solution (Acknowledgement: Arun)
>>
>> new1 <- example.data %>%
>>       rowwise() %>%
>>        mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>>                                                                 
>> na.rm=TRUE), origin='1970-01-01'))
>>
>> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
>>
>> new2 <- example.data
>> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>>    if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate',
>'inhdate', 'haldate')])))) {
>>      max_d <- NA
>>    } else {
>>      max_d <- max(unlist(example.data[row, c('mrjdate','cocdate',
>'inhdate', 'haldate')]), na.rm = TRUE)
>>    }
>>    max_d}),
>>    origin = "1970-01-01")
>>
>> identical(new1, new2)
>>
>> # print records
>>
>> print (new1); print(new2)
>>
>> Pradip K. Muhuri
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org 
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip 
>> (SAMHSA/CBHSQ)
>> Sent: Sunday, November 09, 2014 6:11 AM
>> To: 'Mark Sharp'
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Getting the most recent dates in a new column from 
>> dates in four columns using the dplyr package (mutate verb)
>>
>> Hi Mark,
>>
>> Your code has also given me the results I expected.  Thank you so
>much for your help.
>>
>> Regards,
>>
>> Pradip
>>
>> Pradip K. Muhuri, PhD
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>>
>>
>> -----Original Message-----
>> From: Mark Sharp [mailto:msharp at TxBiomed.org]
>> Sent: Sunday, November 09, 2014 3:01 AM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Getting the most recent dates in a new column from 
>> dates in four columns using the dplyr package (mutate verb)
>>
>> Pradip,
>>
>> mutate() works on the entire column as a vector so that you find the
>maximum of the entire data set.
>>
>> I am almost certain there is some nice way to handle this, but the
>sapply() function is a standard approach.
>>
>> max() does not want a dataframe thus the use of unlist().
>>
>> Using your definition of data1:
>>
>> data3 <- data1
>> data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
>>    if (all(is.na(unlist(data1[row, -1])))) {
>>      max_d <- NA
>>    } else {
>>      max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>>    }
>>    max_d}),
>>    origin = "1970-01-01")
>>
>> data3
>>    id    mrjdate    cocdate    inhdate    haldate    oidflag
>> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
>> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
>> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
>> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
>> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
>> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
>> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>>
>>
>> R. Mark Sharp, Ph.D.
>> Director of Primate Records Database
>> Southwest National Primate Research Center Texas Biomedical Research 
>> Institute P.O. Box 760549 San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org
>>
>>
>>
>>
>>
>> NOTICE:  This E-Mail (including attachments) is confidential and may
>be legally privileged.  It is covered by the Electronic Communications
>Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended
>recipient, you are hereby notified that any retention, dissemination,
>distribution or copying of this communication is strictly prohibited. 
>Please reply to the sender that you have received this message in
>error, then delete it.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Pradip.Muhuri at samhsa.hhs.gov  Thu Dec  4 20:32:25 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Thu, 4 Dec 2014 19:32:25 +0000
Subject: [R] Getting the most recent dates in a new column from dates in
 four columns using the dplyr package (mutate verb)
In-Reply-To: <3B9F6520-7FE6-4C2F-BCFA-6B997C0DDDCE@dcn.davis.CA.us>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F5CFF6@pl-emsmb11>
	<9BF3DC65-AF82-448B-B866-3D191283C07A@txbiomed.org>
	<E18C153EBB81024CB60FCE9B4C34D57C37F5D037@pl-emsmb11>
	<E18C153EBB81024CB60FCE9B4C34D57C38930263@PL-EMSMB20.ees.hhs.gov>
	<547FBD50.2090407@mail.usask.ca>
	<E18C153EBB81024CB60FCE9B4C34D57C389302EA@PL-EMSMB20.ees.hhs.gov>
	<3B9F6520-7FE6-4C2F-BCFA-6B997C0DDDCE@dcn.davis.CA.us>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C38930764@PL-EMSMB20.ees.hhs.gov>

Hello Jeff,

Your code has given me desired results, and your advice is well taken.  I agree with you regarding the use of logical indexing for testing conditions.   Thank you so much for your time and advice.

Pradip

Pradip K. Muhuri
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.CA.us] 
Sent: Thursday, December 04, 2014 1:20 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
Subject: Re: [R] Getting the most recent dates in a new column from dates in four columns using the dplyr package (mutate verb)

There is something weird going on with mutate's interaction with the scalar Date objects. It seems to be passing them to max as constants of mode double.

Regardless, use of rowwise should be very rare, and you are definitely abusing it. Learn to work with vectors of values rather than one value at a time.

new3 <- example.data %>%
      mutate( oiddate = pmax( mrjdate, cocdate, inhdate, haldate, na.rm=TRUE)
                   , na.date.cases= as.numeric( !is.na( oiddate ) ) )

You might find it more useful to not convert the result of is.na to numeric... logical indexing can use that more efficiently than testing which rows have na.date.cases==1.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

On December 3, 2014 7:43:37 PM PST, "Muhuri, Pradip (SAMHSA/CBHSQ)" <Pradip.Muhuri at samhsa.hhs.gov> wrote:
>Hello Chel and David,
>
>Thank you very much for providing new insights into this issue.  Here 
>is one more question.  Why  does the mutate () give incorrect results 
>here?
>
># The following gives INCORRECT results - mutated()ed object 
>na.date.cases = ifelse(!is.na(oiddate),1,0)
>
># The following gives CORRECT results
>new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)
>
>###############################  reproducible example - slightly 
>revised/modified  ###############
>library(dplyr)
># data object - description
>
>temp <- "id  mrjdate cocdate inhdate haldate
>1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>2             NA         NA         NA         NA     
>3     2009-10-24         NA 2011-10-13         NA
>4     2007-10-10         NA         NA         NA
>5     2006-09-01 2005-08-10         NA         NA
>6     2007-09-04 2011-10-05         NA         NA
>7     2005-10-25         NA         NA 2011-11-04"
>
># read the data object
>
>example.data <- read.table(textConnection(temp), 
>           colClasses=c("character", "Date", "Date", "Date", "Date"),  
>                    header=TRUE, as.is=TRUE
>                    )
>
>
># create a new column -dplyr solution (Acknowledgement: Arun)
>
>new1 <- example.data %>% 
>     rowwise() %>%
>mutate(oiddate=as.Date(max(mrjdate,cocdate, inhdate, haldate, 
>na.rm=TRUE), origin='1970-01-01'),
>             na.date.cases = ifelse(!is.na(oiddate),1,0)
>             )
>
># create a new column - Base R solution (Acknowlegement: Mark Sharp)
>
>new2 <- example.data
>new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) { if 
>(all(is.na(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 
>'haldate')])))) {
>    max_d <- NA
>  } else {
>max_d <- max(unlist(example.data[row, c('mrjdate','cocdate', 'inhdate', 
>'haldate')]), na.rm = TRUE)
>  }
>  max_d}),
>  origin = "1970-01-01")
>
>new2$na.date.cases = ifelse(!is.na(new2$oiddate),1,0)
>
>
>identical(new1, new2)
>
>table(new1$oiddate)
>table(new2$oiddate)
>
># print records
>
>print (new1); print(new2)
>
>Pradip K. Muhuri, PhD
>SAMHSA/CBHSQ
>1 Choke Cherry Road, Room 2-1071
>Rockville, MD 20857
>Tel: 240-276-1070
>Fax: 240-276-1260
>
>-----Original Message-----
>From: Chel Hee Lee [mailto:chl948 at mail.usask.ca]
>Sent: Wednesday, December 03, 2014 8:48 PM
>To: Muhuri, Pradip (SAMHSA/CBHSQ); r-help at r-project.org
>Subject: Re: [R] Getting the most recent dates in a new column from 
>dates in four columns using the dplyr package (mutate verb)
>
>The output in the object 'new1' are apparently same the output in the 
>object 'new2'.  Are you trying to compare the entries of two outputs 
>'new1' and 'new2'?  If so, the function 'all()' would be useful:
>
> > all(new1 == new2, na.rm=TRUE)
>[1] TRUE
>
>If you are interested in the comparison of two objects in terms of 
>class, then the function 'identical()' is useful:
>
> > attributes(new1)
>$names
>[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oldflag"
>
>$class
>[1] "rowwise_df" "tbl_df"     "tbl"        "data.frame"
>
>$row.names
>[1] 1 2 3 4 5 6 7
>
> > attributes(new2)
>$names
>[1] "id"      "mrjdate" "cocdate" "inhdate" "haldate" "oiddate"
>
>$row.names
>[1] 1 2 3 4 5 6 7
>
>$class
>[1] "data.frame"
>
>I hope this helps.
>
>Chel Hee Lee
>
>On 12/03/2014 04:10 PM, Muhuri, Pradip (SAMHSA/CBHSQ) wrote:
>> Hello,
>>
>> Two alternative approaches - mutate() vs. sapply() - were used to get
>the desired results (i.e., creating a new column of the most recent 
>date  from 4 dates ) with help from Arun and Mark on this forum.  I now 
>find that the two data objects (created using two different approaches) 
>are not identical although results are exactly the same.
>>
>> identical(new1, new2)
>> [1] FALSE
>>
>> Please see the reproducible example below.
>>
>> I don't understand why the code returns FALSE here.  Any
>hints/comments  will be  appreciated.
>>
>> Thanks,
>>
>> Pradip
>>
>> #############################################  reproducible example 
>> ########################################
>> library(dplyr)
>> # data object - description
>>
>> temp <- "id  mrjdate cocdate inhdate haldate
>> 1     2004-11-04 2008-07-18 2005-07-07 2007-11-07
>> 2             NA         NA         NA         NA
>> 3     2009-10-24         NA 2011-10-13         NA
>> 4     2007-10-10         NA         NA         NA
>> 5     2006-09-01 2005-08-10         NA         NA
>> 6     2007-09-04 2011-10-05         NA         NA
>> 7     2005-10-25         NA         NA 2011-11-04"
>>
>> # read the data object
>>
>> example.data <- read.table(textConnection(temp),
>>                      colClasses=c("character", "Date", "Date",
>"Date", "Date"),
>>                      header=TRUE, as.is=TRUE
>>                      )
>>
>>
>> # create a new column -dplyr solution (Acknowledgement: Arun)
>>
>> new1 <- example.data %>%
>>       rowwise() %>%
>>        mutate(oldflag=as.Date(max(mrjdate,cocdate, inhdate, haldate,
>>                                                                 
>> na.rm=TRUE), origin='1970-01-01'))
>>
>> # create a new column - Base R solution (Acknowlegement: Mark Sharp)
>>
>> new2 <- example.data
>> new2$oiddate <- as.Date(sapply(seq_along(new2$id), function(row) {
>>    if (all(is.na(unlist(example.data[row, c('mrjdate','cocdate',
>'inhdate', 'haldate')])))) {
>>      max_d <- NA
>>    } else {
>>      max_d <- max(unlist(example.data[row, c('mrjdate','cocdate',
>'inhdate', 'haldate')]), na.rm = TRUE)
>>    }
>>    max_d}),
>>    origin = "1970-01-01")
>>
>> identical(new1, new2)
>>
>> # print records
>>
>> print (new1); print(new2)
>>
>> Pradip K. Muhuri
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Muhuri, Pradip
>> (SAMHSA/CBHSQ)
>> Sent: Sunday, November 09, 2014 6:11 AM
>> To: 'Mark Sharp'
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Getting the most recent dates in a new column from 
>> dates in four columns using the dplyr package (mutate verb)
>>
>> Hi Mark,
>>
>> Your code has also given me the results I expected.  Thank you so
>much for your help.
>>
>> Regards,
>>
>> Pradip
>>
>> Pradip K. Muhuri, PhD
>> SAMHSA/CBHSQ
>> 1 Choke Cherry Road, Room 2-1071
>> Rockville, MD 20857
>> Tel: 240-276-1070
>> Fax: 240-276-1260
>>
>>
>> -----Original Message-----
>> From: Mark Sharp [mailto:msharp at TxBiomed.org]
>> Sent: Sunday, November 09, 2014 3:01 AM
>> To: Muhuri, Pradip (SAMHSA/CBHSQ)
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Getting the most recent dates in a new column from 
>> dates in four columns using the dplyr package (mutate verb)
>>
>> Pradip,
>>
>> mutate() works on the entire column as a vector so that you find the
>maximum of the entire data set.
>>
>> I am almost certain there is some nice way to handle this, but the
>sapply() function is a standard approach.
>>
>> max() does not want a dataframe thus the use of unlist().
>>
>> Using your definition of data1:
>>
>> data3 <- data1
>> data3$oidflag <- as.Date(sapply(seq_along(data3$id), function(row) {
>>    if (all(is.na(unlist(data1[row, -1])))) {
>>      max_d <- NA
>>    } else {
>>      max_d <- max(unlist(data1[row, -1]), na.rm = TRUE)
>>    }
>>    max_d}),
>>    origin = "1970-01-01")
>>
>> data3
>>    id    mrjdate    cocdate    inhdate    haldate    oidflag
>> 1  1 2004-11-04 2008-07-18 2005-07-07 2007-11-07 2008-07-18
>> 2  2       <NA>       <NA>       <NA>       <NA>       <NA>
>> 3  3 2009-10-24       <NA> 2011-10-13       <NA> 2011-10-13
>> 4  4 2007-10-10       <NA>       <NA>       <NA> 2007-10-10
>> 5  5 2006-09-01 2005-08-10       <NA>       <NA> 2006-09-01
>> 6  6 2007-09-04 2011-10-05       <NA>       <NA> 2011-10-05
>> 7  7 2005-10-25       <NA>       <NA> 2011-11-04 2011-11-04
>>
>>
>>
>> R. Mark Sharp, Ph.D.
>> Director of Primate Records Database
>> Southwest National Primate Research Center Texas Biomedical Research 
>> Institute P.O. Box 760549 San Antonio, TX 78245-0549
>> Telephone: (210)258-9476
>> e-mail: msharp at TxBiomed.org
>>
>>
>>
>>
>>
>> NOTICE:  This E-Mail (including attachments) is confidential and may
>be legally privileged.  It is covered by the Electronic Communications 
>Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended 
>recipient, you are hereby notified that any retention, dissemination, 
>distribution or copying of this communication is strictly prohibited.
>Please reply to the sender that you have received this message in 
>error, then delete it.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Massoud.Ghasemzadeh-Barvarz at pfizer.com  Thu Dec  4 21:19:13 2014
From: Massoud.Ghasemzadeh-Barvarz at pfizer.com (Ghasemzadeh-Barvarz, Massoud)
Date: Thu, 4 Dec 2014 20:19:13 +0000
Subject: [R] Question
Message-ID: <3E0A16EDE7B94D4EA71CB2E75B55AA27EA20B9@NDHAMREXDF05.amer.pfizer.com>

Could you please let me know whether R software has any advantage over MATLAB to analyze very big datasets?
Thanks you so much

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Fri Dec  5 04:44:42 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 5 Dec 2014 03:44:42 +0000 (UTC)
Subject: [R] Rename multiple files in a directory and write renamed files
 back to directory
Message-ID: <30354722.5101811.1417751082308.JavaMail.yahoo@jws10637.mail.bf1.yahoo.com>

Hello,
I would like to rename multiple files in a directory. Filenames are read using:

lfile <- list.files(pattern="rcp45_Daily_") 
files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files 

dput(lfile) 
c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat") 


- How can I rename these files (200 in number) using something like:
  file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.

- I would like to write the new file names to the directory.

The data files contain huge amounts of data and should not be read into R. Only the file names should change.

Many thanks for your helpful answers.
Asong.


From erinm.hodgess at gmail.com  Fri Dec  5 04:53:19 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 4 Dec 2014 22:53:19 -0500
Subject: [R] using inspect with a TermDocumentMatrix to convert to a data
	frame
Message-ID: <CACxE24mrhKjkS=wZPN+e98fbYvDpaqxyvhAuxyTTskA5OfGv3g@mail.gmail.com>

Hello!

I am working through the "Social Media Mining with R" book and I have
something that is a bit problematic.

Here is the code:

 hash2_tdm <- TermDocumentMatrix(hash2_corpus)
       print(hash2_tdm)
       print(findFreqTerms(hash2_tdm,lowfreq=10))
       hash3_tdm <- removeSparseTerms(hash2_tdm,0.92)

       hash3.df <- as.data.frame(inspect(hash3_tdm))

Now when the hash3.df is created, the entire data frame is printed on the
console.  That's ok if the data frame is relatively small, but is not
acceptable for a large data frame.

Has anyone run into this before, please?  I have tried all kinds of other
options for converting to a data frame, but to no avail.


This is on R-3.1.2, on Ubuntu 14.0.4

Thanks!
Sincerely,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Fri Dec  5 05:16:54 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 04 Dec 2014 22:16:54 -0600
Subject: [R] Rename multiple files in a directory and write renamed
 files back to directory
In-Reply-To: <30354722.5101811.1417751082308.JavaMail.yahoo@jws10637.mail.bf1.yahoo.com>
References: <30354722.5101811.1417751082308.JavaMail.yahoo@jws10637.mail.bf1.yahoo.com>
Message-ID: <548131B6.90105@mail.usask.ca>

I put five data files (example1.dat, example2.dat, example3.dat, 
example4.dat, example5.dat, example6.dat) in my working directory.

 >
 > file_names <- list.files(pattern="*.dat")
 > file_names
[1] "example1.dat" "example2.dat" "example3.dat" "example4.dat" 
"example5.dat"
[6] "example6.dat"
 >
 > new_names <- paste("new_example_",
+ formatC(seq(length(file_names)), width=2, flag="0"),
+ ".dat", sep="")
 > new_names
[1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
[4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
 >
 > file.rename(from=file_names, to=new_names)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
 > list.files(pattern="*.dat")
[1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
[4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee


On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
> Hello,
> I would like to rename multiple files in a directory. Filenames are read using:
>
> lfile <- list.files(pattern="rcp45_Daily_")
> files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files
>
> dput(lfile)
> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>
>
> - How can I rename these files (200 in number) using something like:
>    file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.
>
> - I would like to write the new file names to the directory.
>
> The data files contain huge amounts of data and should not be read into R. Only the file names should change.
>
> Many thanks for your helpful answers.
> Asong.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zilefacelvis at yahoo.com  Fri Dec  5 05:54:48 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 5 Dec 2014 04:54:48 +0000 (UTC)
Subject: [R] Rename multiple files in a directory and write renamed
 files back to directory
In-Reply-To: <548131B6.90105@mail.usask.ca>
References: <548131B6.90105@mail.usask.ca>
Message-ID: <1868962194.5404090.1417755288812.JavaMail.yahoo@jws10638.mail.bf1.yahoo.com>

Hi Chel,
Thanks for the timely reply.
It works but a minor problem remains.
Here is the modified version of your code:

file_names<- list.files(pattern="Sim1971-2000_Daily_") 
new_names <- paste("rcp45_Daily_Sim",format(seq(length(file_names)), width=3, flag="00"), ".dat", sep="") 

#files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files/contents 
file.rename(from=file_names, to=new_names) 
list.files(pattern="*.dat")

I changed width =3 and flag=00 because my output has to be 001.dat...200.dat. However, this is what i got:

list.files(pattern="*.dat") 
[1] "rcp45_Daily_Sim  1.dat" "rcp45_Daily_Sim  2.dat" "rcp45_Daily_Sim  3.dat" "rcp45_Daily_Sim  4.dat" 
[5] "rcp45_Daily_Sim  5.dat" "rcp45_Daily_Sim  6.dat" "rcp45_Daily_Sim  7.dat" "rcp45_Daily_Sim  8.dat" 
[9] "rcp45_Daily_Sim  9.dat" "rcp45_Daily_Sim 10.dat"


The zeros disappear but I need them.

Please help.
Asong.


On Thursday, December 4, 2014 10:16 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
I put five data files (example1.dat, example2.dat, example3.dat, 
example4.dat, example5.dat, example6.dat) in my working directory.

>
> file_names <- list.files(pattern="*.dat")
> file_names
[1] "example1.dat" "example2.dat" "example3.dat" "example4.dat" 
"example5.dat"
[6] "example6.dat"
>
> new_names <- paste("new_example_",
+ formatC(seq(length(file_names)), width=2, flag="0"),
+ ".dat", sep="")
> new_names
[1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
[4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>
> file.rename(from=file_names, to=new_names)
[1] TRUE TRUE TRUE TRUE TRUE TRUE
> list.files(pattern="*.dat")
[1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
[4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>

Is this what you are looking for?  I hope this helps.

Chel Hee Lee



On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
> Hello,
> I would like to rename multiple files in a directory. Filenames are read using:
>
> lfile <- list.files(pattern="rcp45_Daily_")
> files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files
>
> dput(lfile)
> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>
>
> - How can I rename these files (200 in number) using something like:
>    file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.
>
> - I would like to write the new file names to the directory.
>
> The data files contain huge amounts of data and should not be read into R. Only the file names should change.
>
> Many thanks for your helpful answers.
> Asong.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>


From chl948 at mail.usask.ca  Fri Dec  5 06:17:39 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 04 Dec 2014 23:17:39 -0600
Subject: [R] Rename multiple files in a directory and write renamed
 files back to directory
In-Reply-To: <1868962194.5404090.1417755288812.JavaMail.yahoo@jws10638.mail.bf1.yahoo.com>
References: <548131B6.90105@mail.usask.ca>
	<1868962194.5404090.1417755288812.JavaMail.yahoo@jws10638.mail.bf1.yahoo.com>
Message-ID: <54813FF3.1010205@mail.usask.ca>

I see that a function 'format()' is used in your code.

 > format(c(1,5,32,100), width=3, flag="0")
[1] "  1" "  5" " 32" "100"

 > formatC(c(1,5,32,100), width=3, flag="0")
[1] "001" "005" "032" "100"

I hope this helps.

Chel Hee Lee


On 12/04/2014 10:54 PM, Zilefac Elvis wrote:
> Hi Chel,
> Thanks for the timely reply.
> It works but a minor problem remains.
> Here is the modified version of your code:
>
> file_names<- list.files(pattern="Sim1971-2000_Daily_")
> new_names <- paste("rcp45_Daily_Sim",format(seq(length(file_names)), width=3, flag="00"), ".dat", sep="")
>
> #files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files/contents
> file.rename(from=file_names, to=new_names)
> list.files(pattern="*.dat")
>
> I changed width =3 and flag=00 because my output has to be 001.dat...200.dat. However, this is what i got:
>
> list.files(pattern="*.dat")
> [1] "rcp45_Daily_Sim  1.dat" "rcp45_Daily_Sim  2.dat" "rcp45_Daily_Sim  3.dat" "rcp45_Daily_Sim  4.dat"
> [5] "rcp45_Daily_Sim  5.dat" "rcp45_Daily_Sim  6.dat" "rcp45_Daily_Sim  7.dat" "rcp45_Daily_Sim  8.dat"
> [9] "rcp45_Daily_Sim  9.dat" "rcp45_Daily_Sim 10.dat"
>
>
> The zeros disappear but I need them.
>
> Please help.
> Asong.
>
>
> On Thursday, December 4, 2014 10:16 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
> I put five data files (example1.dat, example2.dat, example3.dat,
> example4.dat, example5.dat, example6.dat) in my working directory.
>
>>
>> file_names <- list.files(pattern="*.dat")
>> file_names
> [1] "example1.dat" "example2.dat" "example3.dat" "example4.dat"
> "example5.dat"
> [6] "example6.dat"
>>
>> new_names <- paste("new_example_",
> + formatC(seq(length(file_names)), width=2, flag="0"),
> + ".dat", sep="")
>> new_names
> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>
>> file.rename(from=file_names, to=new_names)
> [1] TRUE TRUE TRUE TRUE TRUE TRUE
>> list.files(pattern="*.dat")
> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>
>
> Is this what you are looking for?  I hope this helps.
>
> Chel Hee Lee
>
>
>
> On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
>> Hello,
>> I would like to rename multiple files in a directory. Filenames are read using:
>>
>> lfile <- list.files(pattern="rcp45_Daily_")
>> files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files
>>
>> dput(lfile)
>> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>>
>>
>> - How can I rename these files (200 in number) using something like:
>>     file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.
>>
>> - I would like to write the new file names to the directory.
>>
>> The data files contain huge amounts of data and should not be read into R. Only the file names should change.
>>
>> Many thanks for your helpful answers.
>> Asong.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>>


From wush978 at gmail.com  Fri Dec  5 06:48:54 2014
From: wush978 at gmail.com (Wush Wu)
Date: Fri, 5 Dec 2014 13:48:54 +0800
Subject: [R] using inspect with a TermDocumentMatrix to convert to a
	data frame
In-Reply-To: <CACxE24mrhKjkS=wZPN+e98fbYvDpaqxyvhAuxyTTskA5OfGv3g@mail.gmail.com>
References: <CACxE24mrhKjkS=wZPN+e98fbYvDpaqxyvhAuxyTTskA5OfGv3g@mail.gmail.com>
Message-ID: <CABjzuv56V9kedJxwUJxKpZGcNak=Kd96_r4xAqCUVw6CWr+6tw@mail.gmail.com>

Dear Erin,

For the issue of printing big data.frame, you could define a customized
`print.data.frame` in the user environment

to prevent R prints all the data. For example:

```r
print.data.frame <- function(df) {
  base::print.data.frame(head(df))
  cat("===\n")
  base::print.data.frame(tail(df))
}
```

Hope that helps.

Regards,
Wush


2014-12-05 11:53 GMT+08:00 Erin Hodgess <erinm.hodgess at gmail.com>:

> Hello!
>
> I am working through the "Social Media Mining with R" book and I have
> something that is a bit problematic.
>
> Here is the code:
>
>  hash2_tdm <- TermDocumentMatrix(hash2_corpus)
>        print(hash2_tdm)
>        print(findFreqTerms(hash2_tdm,lowfreq=10))
>        hash3_tdm <- removeSparseTerms(hash2_tdm,0.92)
>
>        hash3.df <- as.data.frame(inspect(hash3_tdm))
>
> Now when the hash3.df is created, the entire data frame is printed on the
> console.  That's ok if the data frame is relatively small, but is not
> acceptable for a large data frame.
>
> Has anyone run into this before, please?  I have tried all kinds of other
> options for converting to a data frame, but to no avail.
>
>
> This is on R-3.1.2, on Ubuntu 14.0.4
>
> Thanks!
> Sincerely,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From katherine_gobin at yahoo.com  Fri Dec  5 06:10:41 2014
From: katherine_gobin at yahoo.com (Katherine Gobin)
Date: Fri, 5 Dec 2014 13:10:41 +0800
Subject: [R] lmom package - Resending the email
In-Reply-To: <3EFB05A1-BAD3-480A-AD07-B1E05B817444@gmail.com>
Message-ID: <1417756241.23623.YahooMailBasic@web193305.mail.sg3.yahoo.com>

Dear Dalgaard sir,


Thanks a lot for detailed clarification. It indeed is very enlightening and will be very useful for me in future.

And your suggestion is well taken.

Thanks again.

Regards

Katherine

--------------------------------------------
On Thu, 4/12/14, peter dalgaard <pdalgd at gmail.com> wrote:

 Subject: Re: [R] lmom package - Resending the email
 To: "Simon Zehnder" <szehnder at uni-bonn.de>

<r-help at r-project.org>
 Date: Thursday, 4 December, 2014, 2:04 PM

 lmom is based on
 L-moments, which are different from ordinary moments, except
 for the 1st one. It would be truly miraculous if it gave the
 same result as the ordinary method of moments or maximum
 likelihood. 

 Estimates of
 any distributional parameter requires that the model
 actually fits the data, and in your case a qqnorm(amounts)
 shows that they are certainly not normal. In such cases, the
 L-moment estimator of the std.dev. is not necessarily an
 estimate of the std.dev. of the actual distribution.

 A lognormal distribution seems
 to fit the data better. However, the L-moments suggest a
 value for zeta (the lower bound) of 3226 which is well
 inside the range of the actual data. In fact there are 16
 observations that are less than 3226. Maximum likelihood
 would never do that, but the same sort of effect is
 well-known for the ordinary method of moments.

 In short, you need to study
 the theory before you appply its results.

 - Peter D.


 On 03 Dec 2014, at 10:57 ,
 Simon Zehnder <szehnder at uni-bonn.de>
 wrote:

 > Katherine,
 > 
 > for a deeper
 understanding of differing values it makes sense to provide
 the list at least with an online description of the
 corresponding functions used in Minitab and SPSS?
 > 
 > Best 
 > Simon
 > On 03 Dec 2014,
 at 10:45, Katherine Gobin via R-help <r-help at r-project.org>
 wrote:
 > 
 >> Dear R
 forum
 >> I sincerely apologize as my
 earlier mail with the captioned subject, since all the
 values got mixed up and the email is not readable. I am
 trying to write it again. 
 >> My
 problem is I have a set of data and I am trying to fit some
 distributions to it. As a part of this exercise, I need to
 find out the parameter values of various distributions e.g.
 Normal distribution, Log normal distribution etc. I am using
 lmom package to do the same, however the parameter values
 obtained using lmom pacakge differ to a large extent from
 the parameter values obtained using say MINITAB and SPSS as
 given below -
 >>
 _____________________________________________
 >> 
 >> amounts =?
 c(38572.5599129508,11426.6705314315,21974.1571641187,118530.32782443,3735.43055996748,66309.5211176106,72039.2934132668,21934.8841708626,78564.9136114375,1703.65825161293,2116.89180930203,11003.495671332,19486.3296339113,1871.35861218795,6887.53851253407,148900.978055447,7078.56497101651,79348.1239806592,20157.6241066905,1259.99802108593,3934.45912233674,3297.69946631591,56221.1154121067,13322.0705174134,45110.2498756567,31910.3686613912,3196.71168501252,32843.0140437202,14615.1499458453,13013.9915051561,116104.176753387,7229.03056392023,9833.37962177814,2882.63239493673,165457.372543821,41114.066453219,47188.1677766245,25708.5883755617,82703.7378298092,8845.04197017415,844.28834047836,35410.8486123933,19446.3808445684,17662.2398792892,11882.8497070776,4277181.17817307,30239.0371267968,45165.7512343364,22102.8513746687,5988.69296597127,51345.0146170238,1275658.35495898,15260.4892854214,8861.76578480635,37647.1638704867,4979.53544046949,7012.48134772332
,3385.20612391205,1911.03114395959,66886.5036605189,2223.47536156462,814.947809578378,234.028589468841,5397.4347625133,13346.3226579065,28809.3901352898,6387.69226236731,5639.42730553242,2011100.92675507,4150.63707173462,34098.7514446498,3437.10672573502,289710.315303182,8664.66947305203,13813.3867161134,208817.521491857,169317.624400274,9966.78447705792,37811.1721605562,2263.19211279927,80434.5581206454,19057.8093104899,24664.5067589624,25136.5042354789,3582.85741610706,6683.13898432794,65423.9991390846,134848.302304064,3018.55371579808,546249.641168158,172926.689143006,3074.15064180208,1521.70624812788,59012.4248281661,21226.928522236,17572.5682970983,226.646947337851,56232.2982652019,14641.0043361533,6997.94414914865)
 >> 
 >>
 library(lmom)
 >> lmom? =?
 samlmu(amounts)
 >> #
 __________________________________________________________________
 >> # Normal Distribution parameters
 >> parameters_of_NOR? <-
 pelnor(lmom); parameters_of_NOR
 >> 
 >>? ? ? mu? ? ? ? ? sigma
 115148.4? ? 175945.8
 >>? ? ? ?
 ? ? ? ? ? ? ? Location? ? ???Scale?
 ???Minitab? ? ? ???115148.4?
 ???485173SPSS? ? ? ? ???115148.4?
 ???485173
 >> #
 __________________________________________________________________
 >> # Log Normal (3 Parameter)
 Distribution parameters
 >>? ?
 ???zeta? ? ? ? ? ? ? ? mu? ? ? ? ?
 ? ???sigma 3225.798890? ? 9.114879? ? ?
 2.240841
 >>? ? ? ? ? ? ? ? ?
 ? ? ? ? ? ? Location? ? ? ? ? ? Scale? ? ? ?
 ???Shape
 >> MINITAB? ? ?
 ? ? ? ???9.73361? ? ? ? ?
 ???1.76298? ? ? 75.51864SPSS? ? ? ? ? ?
 ? ? ? ? 9.7336? ? ? ? ? ? ? ? 1.763? ? ? ?
 ? 75.519? ? ? ? ???#
 __________________________________________________________________
 >> 
 >> Besides
 Genaralized extreme Value distributions, all the other
 distributions e.g. Gamma, Exponential (2 parameter)
 distributions etc give different results than MINITAB and
 SPSS.
 >> Can some one guide me?
 >> 
 >> Regards
 >> Katherine
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> 
 >> ??? [[alternative HTML version
 deleted]]
 >> 
 >>
 ______________________________________________
 >> R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal,
 self-contained, reproducible code.
 > 
 >
 ______________________________________________
 > R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal,
 self-contained, reproducible code.

 -- 
 Peter Dalgaard,
 Professor,
 Center for Statistics, Copenhagen
 Business School
 Solbjerg Plads 3, 2000
 Frederiksberg, Denmark
 Phone:
 (+45)38153501
 Email: pd.mes at cbs.dk? Priv:
 PDalgd at gmail.com


From adrien.bonvin at outlook.fr  Thu Dec  4 23:23:38 2014
From: adrien.bonvin at outlook.fr (Adrien Bonvin)
Date: Thu, 4 Dec 2014 22:23:38 +0000
Subject: [R] =?utf-8?q?2_ablines_dans_1_m=C3=AAme_plot_=22vide=22?=
Message-ID: <SNT404-EAS382C943DBD52BFA691D6ACB80780@phx.gbl>

Bonjour

J?aimerais savoir comment cr?er un ?plot vide?, dans lequel je pourrais ajouter deux valeurs d?abline, trac?es ? partir de deux nuages de points diff?rents (que je souhaiterais ne pas voir dans mon graphique final).


Comme r?sultat final je voudrais donc avoir un plot ne contenant que les deux droites d?abline sans les nuages de points qui vont avec.
J?esp?re que mon probl?me est assez bien expliqu?.

Merci beaucoup pour votre attention, en esp?rant que vous avez la solution ? mon probl?me.
Cordialement

Adrien Bonvin
	[[alternative HTML version deleted]]


From dilaradi21 at gmail.com  Fri Dec  5 03:55:15 2014
From: dilaradi21 at gmail.com (dila radi)
Date: Thu, 4 Dec 2014 18:55:15 -0800
Subject: [R] Plot gamma distribution with relative frequency histogram
Message-ID: <CAMgoKBKen51P8FS4=rT3J5xeMMivt52o6eviGKAFTJEN0ttLZQ@mail.gmail.com>

Dear R users,

I am looking to fit a gamma curve onto a histogram of the data.

Consider dt1 as my data:
c(203.9, 91.5, 24.5, 34.5, 164, 144, 160.5, 195, 191.5, 189,
133, 110.5, 155, 80.5, 250.5, 116, 145, 118.5, 406, 183.5, 142.5,
197, 367, 134, 153.5)

I am using this code in R
x<-dt1
h<-hist(x,breaks=seq(0,500,25),col=rgb(0,0,1), plot=F)
h$counts <- h$counts / sum(h$counts)
plot(h, freq=TRUE, ylab="Relative Frequency", xlab="Rainfall (mm)",
     main = 'Histogram KBU-ML Gamma Disribution')
est <- fitdistr(dt1,"gamma")$estimate
curve(dgamma(x, rate=0.02220921, shape=3.63421746),from=0, to=500,
      main="Gamma distribution", add = T, col = "red")

but the gamma fit is not fitted onto histogram as much as it supposed to
be. How should I overcome this?

Thank you in advanced.

Dila

	[[alternative HTML version deleted]]


From brianna.noland at gmail.com  Fri Dec  5 06:01:36 2014
From: brianna.noland at gmail.com (Brianna Noland)
Date: Thu, 4 Dec 2014 21:01:36 -0800
Subject: [R] building generic regression tool - error invalid type (list)
	for variable
Message-ID: <CAHOCEWs9LzpVieX=g_cj64yxgS1JhPQcw9czsKUQzj-KDi1dmw@mail.gmail.com>

Hello,

First I apologize in advance for for my limited knowledge of R. For an R
course I am writing a generic tool which will execute models based on
inputs. When I attempt to run one of the input models, I get the error:

    invalid type (list) for variable 'MPG'

which has been described here:
http://r.789695.n4.nabble.com/Error-invalid-type-list-for-variable-when-using-lm-td3045462.html
and
http://stats.stackexchange.com/questions/70990/error-with-lm-common-r-mistake

however, these have not helped. Let me describe in detail. I have code
which takes a list of models, input data, performs a regression for each
model.
Since this is generic, I build up a data frame based on which variables the
model
includes and then build a formula regression the independent variable,
constant, over
the independent variables for this particular model.

The following code:

     print(disjointSet(names(data), depVariable))
     print(depVariable)
     formula <- reformulate(termlabels = disjointSet(names(data),
depVariable), response = depVariable)
     print(Reduce(paste, deparse(formula)))

has the following output:

    [1] "VOL" "HP"
    [1] "MPG"
    [1] "MPG ~ VOL + HP"

As you can see, this particular dataset is related to automobiles and MPG
is the dependent variable.
For one model, VOL and HP are independent variables.

The following two lines:

     print(class(data))
     print(data)

result in:

    [1] "data.frame"
       VOL  HP  MPG
    1   89  49 65.4
    2   92  55   56
... (remaining data at http://pastebin.com/3Mnwn1Ve)

Of course the error occurs when I call lm:

    lm(formula, data = data)

Here is the full error:

    Error in model.frame.default(formula = formula, data = data,
drop.unused.levels = TRUE) :
      invalid type (list) for variable 'MPG'
    7: model.frame.default(formula = formula, data = data,
drop.unused.levels = TRUE)
    6: stats::model.frame(formula = formula, data = data,
drop.unused.levels = TRUE)
    5: eval(expr, envir, enclos)
    4: eval(mf, parent.frame())
    3: lm(formula, data = data) at #15
    2: fitness(filteredData, depVariable, regType, criterion) at #42
    1: runModels(parent_pop, depVariable = "MPG", regType = "LM", criterion
= "AIC")

Do you have any ideas of what my mistake might be?

	[[alternative HTML version deleted]]


From theuns at sun.ac.za  Fri Dec  5 08:24:17 2014
From: theuns at sun.ac.za (Dirkse van Schalkwyk, Theuns <theuns@sun.ac.za>)
Date: Fri, 5 Dec 2014 07:24:17 +0000
Subject: [R] I am trying to use assign and paste to assign value to existing
 variable
Message-ID: <338e644aae754ceca0b3a0823245fb44@STBEXMB03.stb.sun.ac.za>

In the code below, the last line of code does what I am trying to do; however, I do not know the name of the variable before the user creates it, by choosing values in Route1. So, how can I assign values to the variables individually, when I created them using the code in lines 9-12 and assigned values in lines 15 and 16?

Lines 18 to 24 are various ways that I tried without success. Line 26 does what I want of course, but since I don't know the name of the variable beforehand I cannot use it. Maybe it will be easier to re-think the problem to use a dataframe; but I would still like to know how to do this as well.


evaluate<-function(..., envir=.GlobalEnv){ eval(parse(text=paste( ... ,sep="")), envir=envir) }  #By Rufo in stackoverflow
envir <- environment()

Route1<<- c("Ao1","B1","C1","D1","Ei1")
Arrive<<- c(15,30,100,1000,5000,12000)   # the time between events > exponential parameter of the arrivals
N <<- 9  # number of simulated arrivals
Route1S<<- length(Route1)    # determines the number of routes in Route1

for (i in 1:(Route1S)){     # create the route variables, maybe can be vectorised, but this works for now...
  assign(paste(Route1[i],"TimeB",sep = ""), rep(0, N))
  assign(paste(Route1[i],"TimeE",sep = ""), rep(0, N))
  assign(paste(Route1[i],"ServiceT",sep = ""), rep(0, N))
}

assign(paste(Route1[1],"TimeB",sep = ""), round(cumsum(rpois(N,Arrive[1])),2))  #time the entity comes into Source1, N values
assign(paste(Route1[1],"ServiceT",sep = ""),  round(rpois(N,Arrive[2]),2)) #just service time

assign(eval(paste(Route1[1],"TimeB[",2,"]",sep = "")), 3)
x[1]<-0
assign(paste(Route1[1],"TimeB",eval("[1]"),sep = ""), 0)
sum(unlist(mget(paste("u",1:n,sep=""),envir=as.environment(-1)))))
evaluate(paste(Route1[1],"TimeB[1]",sep = ""), envir=envir) # will find the value in Ao1TimeB[1], but how to place a new value in Ao1TimeB[1]???
assign(evaluate(paste(Route1[1],"TimeB[1]",sep = "")), 0)   # Creates Ao1Timeb[1] as 0 but does not change the vector Ao1TimeB...
assign(eval(parse(text=paste(Route1[1],"TimeB[1]",sep = ""))), 0)  # does not work either and is frowned upon R-help list 106

Ao1TimeB[1]<- 0   # this is what I am trying to do in the previous two lines
# the reason I want to do it with the paste method is because there could be 100 values in Route1
# and expanding the method to include more such as Route2 with another 100 values etc.
# I am trying to figure out how to address these values Ao1TimeB[1], Ao1TimeB[2] etc without typing the variable name

Theuns
The integrity and confidentiality of this email is governed by these terms / Hierdie terme bepaal die integriteit en vertroulikheid van hierdie epos. http://www.sun.ac.za/emaildisclaimer

The integrity and confidentiality of this email is governed by these terms / Hierdie terme bepaal die integriteit en vertroulikheid van hierdie epos. http://www.sun.ac.za/emaildisclaimer



	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec  5 09:22:59 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Dec 2014 00:22:59 -0800
Subject: [R] I am trying to use assign and paste to assign value to
	existing variable
In-Reply-To: <338e644aae754ceca0b3a0823245fb44@STBEXMB03.stb.sun.ac.za>
References: <338e644aae754ceca0b3a0823245fb44@STBEXMB03.stb.sun.ac.za>
Message-ID: <F13CFC5B-6043-4E44-9FDC-76480F055A3E@comcast.net>


On Dec 4, 2014, at 11:24 PM, Dirkse van Schalkwyk, Theuns <theuns at sun.ac.za> wrote:

> In the code below, the last line of code does what I am trying to do; however, I do not know the name of the variable before the user creates it, by choosing values in Route1. So, how can I assign values to the variables individually, when I created them using the code in lines 9-12 and assigned values in lines 15 and 16?
> 
> Lines 18 to 24 are various ways that I tried without success. Line 26 does what I want of course, but since I don't know the name of the variable beforehand I cannot use it. Maybe it will be easier to re-think the problem to use a dataframe; but I would still like to know how to do this as well.
> 
> 
> evaluate<-function(..., envir=.GlobalEnv){ eval(parse(text=paste( ... ,sep="")), envir=envir) }  #By Rufo in stackoverflow
> envir <- environment()
> 
> Route1<<- c("Ao1","B1","C1","D1","Ei1")
> Arrive<<- c(15,30,100,1000,5000,12000)   # the time between events > exponential parameter of the arrivals
> N <<- 9  # number of simulated arrivals
> Route1S<<- length(Route1)    # determines the number of routes in Route1
> 
> for (i in 1:(Route1S)){     # create the route variables, maybe can be vectorised, but this works for now...
>  assign(paste(Route1[i],"TimeB",sep = ""), rep(0, N))
>  assign(paste(Route1[i],"TimeE",sep = ""), rep(0, N))
>  assign(paste(Route1[i],"ServiceT",sep = ""), rep(0, N))
> }
> 
> assign(paste(Route1[1],"TimeB",sep = ""), round(cumsum(rpois(N,Arrive[1])),2))  #time the entity comes into Source1, N values
> assign(paste(Route1[1],"ServiceT",sep = ""),  round(rpois(N,Arrive[2]),2)) #just service time
> 
> assign(eval(paste(Route1[1],"TimeB[",2,"]",sep = "")), 3)
> x[1]<-0
> assign(paste(Route1[1],"TimeB",eval("[1]"),sep = ""), 0)
> sum(unlist(mget(paste("u",1:n,sep=""),envir=as.environment(-1)))))

The line above throws an error for too many closing parens, and when a paren is removed it then very reasonably complains about a missing value for "n". After a value of 3 is substituted for `n` the error becomes: Error: value for ?u1? not found. ( It's not clear what value the line provides since it is not assigned to any name.)


> evaluate(paste(Route1[1],"TimeB[1]",sep = ""), envir=envir) # will find the value in Ao1TimeB[1], but how to place a new value in Ao1TimeB[1]???

I get 17.

> assign(evaluate(paste(Route1[1],"TimeB[1]",sep = "")), 0)   # Creates Ao1Timeb[1] as 0 but does not change the vector Ao1TimeB...
> assign(eval(parse(text=paste(Route1[1],"TimeB[1]",sep = ""))), 0)  # does not work either and is frowned upon R-help list 106

This would be much less painful if you built one list with named descendants. 
You can give character values that need to be evaluated to either "[[" or "["

routlist <- list( TimeB=numeric(), TimeE=numeric() )
> routlist[['TimeB']] <- lapply(paste0(Route1, "TimeB"), function(x) rep(0,N) )
> routlist[['TimeE']] <- lapply(paste0(Route1, "TimeB"), function(x) rep(0,N) )
> # Let's say the user input is to be placed in the 3rd location in TimeB's first entry"
> inp_a <- "timeB"
> inc_b <- 400
> routlist[[inp_a]][[1]][3] <- inp_b
> routlist
$TimeB
$TimeB[[1]]
[1]   0   0 400   0   0   0   0   0   0

$TimeB[[2]]
[1] 0 0 0 0 0 0 0 0 0

$TimeB[[3]]
[1] 0 0 0 0 0 0 0 0 0

snipped remainder.

-- 
David.



> 
> Ao1TimeB[1]<- 0   # this is what I am trying to do in the previous two lines
> # the reason I want to do it with the paste method is because there could be 100 values in Route1
> # and expanding the method to include more such as Route2 with another 100 values etc.
> # I am trying to figure out how to address these values Ao1TimeB[1], Ao1TimeB[2] etc without typing the variable name
> 
> Theuns
> The integrity and confidentiality of this email is governed by these terms / Hierdie terme bepaal die integriteit en vertroulikheid van hierdie epos. http://www.sun.ac.za/emaildisclaimer
> 
> The integrity and confidentiality of this email is governed by these terms / Hierdie terme bepaal die integriteit en vertroulikheid van hierdie epos. http://www.sun.ac.za/emaildisclaimer
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Dec  5 09:32:24 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Dec 2014 00:32:24 -0800
Subject: [R] Plot gamma distribution with relative frequency histogram
In-Reply-To: <CAMgoKBKen51P8FS4=rT3J5xeMMivt52o6eviGKAFTJEN0ttLZQ@mail.gmail.com>
References: <CAMgoKBKen51P8FS4=rT3J5xeMMivt52o6eviGKAFTJEN0ttLZQ@mail.gmail.com>
Message-ID: <040E5C8C-6052-42B5-9E51-277660C75B49@comcast.net>


On Dec 4, 2014, at 6:55 PM, dila radi wrote:

> Dear R users,
> 
> I am looking to fit a gamma curve onto a histogram of the data.
> 
> Consider dt1 as my data:
> c(203.9, 91.5, 24.5, 34.5, 164, 144, 160.5, 195, 191.5, 189,
> 133, 110.5, 155, 80.5, 250.5, 116, 145, 118.5, 406, 183.5, 142.5,
> 197, 367, 134, 153.5)
> 
> I am using this code in R
> x<-dt1
> h<-hist(x,breaks=seq(0,500,25),col=rgb(0,0,1), plot=F)
> h$counts <- h$counts / sum(h$counts)
> plot(h, freq=TRUE, ylab="Relative Frequency", xlab="Rainfall (mm)",
>     main = 'Histogram KBU-ML Gamma Disribution')
> est <- fitdistr(dt1,"gamma")$estimate
> curve(dgamma(x, rate=0.02220921, shape=3.63421746),from=0, to=500,
>      main="Gamma distribution", add = T, col = "red")
> 
> but the gamma fit is not fitted onto histogram as much as it supposed to
> be. How should I overcome this?
> 
First read ?hist. Then set freq=FALSE. Then you will be comparing "like to like".

Otherwise you cna just hack it by multiplying the dgamma expression by 25.

> sum(h$counts)  #before the standardization
[1] 25


> Thank you in advanced.
> 
> Dila
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From adrien.bonvin at outlook.fr  Fri Dec  5 09:30:01 2014
From: adrien.bonvin at outlook.fr (Adrien Bonvin)
Date: Fri, 5 Dec 2014 08:30:01 +0000
Subject: [R] =?utf-8?q?Put_2_ablines_in_an_=22empty_plot=22?=
Message-ID: <SNT404-EAS4045F54C8CC87B9284432380790@phx.gbl>

Bonjour
Hi everybody,




Firs of all, sorry for my terrible English,

I would like to know if it?s possible to create an ?empty plot? in which i could add two ablines I created on two different plots earlyer in my script.




As a result I would like to have a plot with only the two ablines (in the same plot) but without the graphs I used to create the ablines in the first place.

I hope I explained my problem well enough.

Thanks for helping me out, i hope someone has the answer.

Adrien Bonvin
	[[alternative HTML version deleted]]


From stephane.adamowicz at avignon.inra.fr  Fri Dec  5 09:54:31 2014
From: stephane.adamowicz at avignon.inra.fr (=?iso-8859-1?Q?St=E9phane_Adamowicz?=)
Date: Fri, 5 Dec 2014 09:54:31 +0100
Subject: [R] Using "line" (Tukey's robust line) on 3 observations?
In-Reply-To: <CANdJ3dU7VvSFmeK_S-FDap5erqtsNZaSTyJAo_gxTGzGPCs+FQ@mail.gmail.com>
References: <CANdJ3dU7VvSFmeK_S-FDap5erqtsNZaSTyJAo_gxTGzGPCs+FQ@mail.gmail.com>
Message-ID: <CAC504F2-5403-463B-BFB6-C165AF88FBCE@avignon.inra.fr>


Le 4 d?c. 2014 ? 13:40, Tal Galili a ?crit :

> By accident I came across the following example:
> 
> x <- 1:3
> y <- 1:3
> line(x, y) # returns:
> 
> Call:
> line(x, x)
> 
> Coefficients:
> [1]  -2   2
> 
> 
> While when using 1:4, it will give the more reasonable 0,1 coefficients.
> 
> I imagine this is in the way it calculate the quantiles (i.e.: a "feature").
> Can someone help in explaining this?
> 
> 
> Thanks,
> Tal

Strange, indeed. The problem arises also with other examples :

> line(1:8,1:8)

Call:
line(1:8, 1:8)

Coefficients:
[1]  -1.125   1.250

> line(1:9,1:9)

Call:
line(1:9, 1:9)

Coefficients:
[1]  -1.0   1.2



_________________________________
St?phane Adamowicz
Inra, centre de recherche Paca, unit? PSH
228, route de l'a?rodrome
CS 40509
domaine St Paul, site Agroparc
84914 Avignon, cedex 9
France

stephane.adamowicz at avignon.inra.fr
tel.  +33 (0)4 32 72 24 35
fax. +33 (0)4 32 72 24 32
do not dial 0 when out of France
web PSH  : https://www6.paca.inra.fr/psh
web Inra : http://www.inra.fr/
_________________________________


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec  5 10:06:42 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Dec 2014 01:06:42 -0800
Subject: [R] Put 2 ablines in an "empty plot"
In-Reply-To: <SNT404-EAS4045F54C8CC87B9284432380790@phx.gbl>
References: <SNT404-EAS4045F54C8CC87B9284432380790@phx.gbl>
Message-ID: <5C12CEFC-B70F-4972-8F4C-38FC19FBFD44@comcast.net>


On Dec 5, 2014, at 12:30 AM, Adrien Bonvin wrote:

> Bonjour
> Hi everybody,
> 
> Firs of all, sorry for my terrible English,
> 
> I would like to know if it?s possible to create an ?empty plot? in which i could add two ablines I created on two different plots earlyer in my script.
> 
> 
> 
Read there help page for ?plot.default. There is a type parameter that lets you do what you ask. There's also a worked example on ?plot.window
> 
> As a result I would like to have a plot with only the two ablines (in the same plot) but without the graphs I used to create the ablines in the first place.
> 
> I hope I explained my problem well enough.
> 
> Thanks for helping me out, i hope someone has the answer.
> 
> Adrien Bonvin
> 	[[alternative HTML version deleted]]

Please read what the posting guide says about html posting.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From info at aghmed.fsnet.co.uk  Fri Dec  5 10:26:53 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 05 Dec 2014 09:26:53 +0000
Subject: [R] =?utf-8?q?2_ablines_dans_1_m=C3=AAme_plot_=22vide=22?=
In-Reply-To: <SNT404-EAS382C943DBD52BFA691D6ACB80780@phx.gbl>
References: <SNT404-EAS382C943DBD52BFA691D6ACB80780@phx.gbl>
Message-ID: <54817A5D.1040009@aghmed.fsnet.co.uk>

If I understand correctly
plot(1:10, 1:10, type = "n")
should get you started.

This is an Anglophone list by the way.

On 04/12/2014 22:23, Adrien Bonvin wrote:
> Bonjour
>
> J?aimerais savoir comment cr?er un ?plot vide?, dans lequel je pourrais ajouter deux valeurs d?abline, trac?es ? partir de deux nuages de points diff?rents (que je souhaiterais ne pas voir dans mon graphique final).
>
>
> Comme r?sultat final je voudrais donc avoir un plot ne contenant que les deux droites d?abline sans les nuages de points qui vont avec.
> J?esp?re que mon probl?me est assez bien expliqu?.
>
> Merci beaucoup pour votre attention, en esp?rant que vous avez la solution ? mon probl?me.
> Cordialement
>
> Adrien Bonvin
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4235/8683 - Release Date: 12/05/14
>

-- 
Michael
http://www.dewey.myzen.co.uk


From chl948 at mail.usask.ca  Fri Dec  5 14:18:22 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Fri, 05 Dec 2014 07:18:22 -0600
Subject: [R] Put 2 ablines in an "empty plot"
In-Reply-To: <SNT404-EAS4045F54C8CC87B9284432380790@phx.gbl>
References: <SNT404-EAS4045F54C8CC87B9284432380790@phx.gbl>
Message-ID: <5481B09E.80102@mail.usask.ca>

The following example may give you an idea regarding your question. 
Please see what happens by typing the codes

 > x <- seq(from=-5, to=5, by=1)
 > y1 <- 0 + 0.5*x
 > y2 <- 0 - 0.5*x
 >
 > plot(x,y1, type="n")
 > points(x,y1)
 > points(x,y2)
 > abline(a=0, b=0.5)
 > abline(a=0, b=-0.5)

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 12/05/2014 02:30 AM, Adrien Bonvin wrote:
> Bonjour
> Hi everybody,
>
>
>
>
> Firs of all, sorry for my terrible English,
>
> I would like to know if it?s possible to create an ?empty plot? in which i could add two ablines I created on two different plots earlyer in my script.
>
>
>
>
> As a result I would like to have a plot with only the two ablines (in the same plot) but without the graphs I used to create the ablines in the first place.
>
> I hope I explained my problem well enough.
>
> Thanks for helping me out, i hope someone has the answer.
>
> Adrien Bonvin
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From stbarningham at gmail.com  Fri Dec  5 14:40:53 2014
From: stbarningham at gmail.com (Thomas Barningham)
Date: Fri, 5 Dec 2014 13:40:53 +0000
Subject: [R] Run script automatically on several input files in the
 directory and produce separate outputs?
Message-ID: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>

Hi,

I have written a script that currently reads in a .txt file where I
specify the name e.g

mydata<-read.table("a_date.txt", header=TRUE)

The script eventually produces a plot, e.g:

pdf(file="myfilename.txt")
plot(etc)
dev.off

What I want to do is run this script on several input files in my
directory, without having to manually change the input file name each
time, and produce the output plot pdf with the input file name as the
output file name. It would also be handy if my plot title is also the
input file name.

I'm relatively new to R so i'm not sure how to approach this. I
presume it's some sort of loop function, but i've never implemented
one of these before - any advice would be greatly appreciated!

Thanks in advance!
Thomas
-- 
Thomas Barningham
Centre for Ocean and Atmospheric Sciences
School of Environmental Sciences
University of East Anglia
Norwich Research Park
Norwich
NR4 7TJ


From erinm.hodgess at gmail.com  Fri Dec  5 15:03:13 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 5 Dec 2014 09:03:13 -0500
Subject: [R] using inspect with a TermDocumentMatrix to convert to a
	data frame
In-Reply-To: <CABjzuv56V9kedJxwUJxKpZGcNak=Kd96_r4xAqCUVw6CWr+6tw@mail.gmail.com>
References: <CACxE24mrhKjkS=wZPN+e98fbYvDpaqxyvhAuxyTTskA5OfGv3g@mail.gmail.com>
	<CABjzuv56V9kedJxwUJxKpZGcNak=Kd96_r4xAqCUVw6CWr+6tw@mail.gmail.com>
Message-ID: <CACxE24kebqgBPMMMa45QHLUacP8nuYP0WR5+kfYLH-AFoefnDg@mail.gmail.com>

Great!

Thank you!


On Fri, Dec 5, 2014 at 12:48 AM, Wush Wu <wush978 at gmail.com> wrote:

> Dear Erin,
>
> For the issue of printing big data.frame, you could define a customized
> `print.data.frame` in the user environment
>
> to prevent R prints all the data. For example:
>
> ```r
> print.data.frame <- function(df) {
>   base::print.data.frame(head(df))
>   cat("===\n")
>   base::print.data.frame(tail(df))
> }
> ```
>
> Hope that helps.
>
> Regards,
> Wush
>
>
> 2014-12-05 11:53 GMT+08:00 Erin Hodgess <erinm.hodgess at gmail.com>:
>
>> Hello!
>>
>> I am working through the "Social Media Mining with R" book and I have
>> something that is a bit problematic.
>>
>> Here is the code:
>>
>>  hash2_tdm <- TermDocumentMatrix(hash2_corpus)
>>        print(hash2_tdm)
>>        print(findFreqTerms(hash2_tdm,lowfreq=10))
>>        hash3_tdm <- removeSparseTerms(hash2_tdm,0.92)
>>
>>        hash3.df <- as.data.frame(inspect(hash3_tdm))
>>
>> Now when the hash3.df is created, the entire data frame is printed on the
>> console.  That's ok if the data frame is relatively small, but is not
>> acceptable for a large data frame.
>>
>> Has anyone run into this before, please?  I have tried all kinds of other
>> options for converting to a data frame, but to no avail.
>>
>>
>> This is on R-3.1.2, on Ubuntu 14.0.4
>>
>> Thanks!
>> Sincerely,
>> Erin
>>
>>
>> --
>> Erin Hodgess
>> Associate Professor
>> Department of Mathematical and Statistics
>> University of Houston - Downtown
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Fri Dec  5 15:20:47 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 5 Dec 2014 14:20:47 +0000
Subject: [R] Run script automatically on several input files in the
 directory and produce separate outputs?
In-Reply-To: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>
References: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3C755E3@inbomail.inbo.be>

Dear Thomas,

list.files() will be your new best friend.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-help [mailto:r-help-bounces at r-project.org] Namens Thomas Barningham
Verzonden: vrijdag 5 december 2014 14:41
Aan: r-help at r-project.org
Onderwerp: [R] Run script automatically on several input files in the directory and produce separate outputs?

Hi,

I have written a script that currently reads in a .txt file where I specify the name e.g

mydata<-read.table("a_date.txt", header=TRUE)

The script eventually produces a plot, e.g:

pdf(file="myfilename.txt")
plot(etc)
dev.off

What I want to do is run this script on several input files in my directory, without having to manually change the input file name each time, and produce the output plot pdf with the input file name as the output file name. It would also be handy if my plot title is also the input file name.

I'm relatively new to R so i'm not sure how to approach this. I presume it's some sort of loop function, but i've never implemented one of these before - any advice would be greatly appreciated!

Thanks in advance!
Thomas
--
Thomas Barningham
Centre for Ocean and Atmospheric Sciences School of Environmental Sciences University of East Anglia Norwich Research Park Norwich
NR4 7TJ

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
**** D I S C L A I M E R ****
Bezoek onze website/Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From kmezhoud at gmail.com  Fri Dec  5 15:44:54 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Fri, 5 Dec 2014 15:44:54 +0100
Subject: [R] function to avoid <<-
In-Reply-To: <CAN5YmCGPHqxGin-1u_QG610NiL5N4+g5QXeX4f+qz5z6LkH=6w@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
	<CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
	<CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>
	<CAFEqCdy9vWXA0zXYiaVn5pg5-tT_gmx+R=bs=vBy4ywBA6bnKw@mail.gmail.com>
	<CALJKBv-He=6BDEKqqG=0GWH8Pu5wgwxwHiOm-Nwp2amsrar02w@mail.gmail.com>
	<CAN5YmCGPHqxGin-1u_QG610NiL5N4+g5QXeX4f+qz5z6LkH=6w@mail.gmail.com>
Message-ID: <CALJKBv-J63nPR7azeYEXZL7pWH7jaWN8ajhxR55ksepwGo8vRA@mail.gmail.com>

Hi,
An other alternative using "assign" function

func <- function(){
X <- 5
assign("X", X, envir = .GlobalEnv)
}


  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Tue, Dec 2, 2014 at 8:40 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> Glad to see this query and the responses.  You all just helped me to
> eliminate the use of global variables from my R package.  I knew they were
> not recommended, but I didn't know how to get around using them.
>
> Thanks!
>
> Jean
>
> On Tue, Dec 2, 2014 at 10:59 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> OK thanks as:
>>
>> myenv <- new.env(parent = emptyenv())
>> fun <- function(){
>> fun1 <- function(){
>> myenv$X <- 5
>> }
>>
>> }
>> fun()
>> ls(myenv)
>> #X
>> X
>> #5
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Tue, Dec 2, 2014 at 5:47 PM, Greg Snow <538280 at gmail.com> wrote:
>>
>> > By "At the top level" Hadley meant to put that code outside of the
>> > function definition.  In you source file that line should be very near
>> the
>> > top, before any function definitions.  Then "myenv" will not be
>> temporary
>> > (well it will go away when you end the R session).  Further, when this
>> code
>> > is compiled into a package then "myenv" becomes package local, meaning
>> that
>> > functions within the package can access it and the objects inside of it,
>> > but it will not interfere with any other packages or the global
>> environment.
>> >
>> > On Tue, Dec 2, 2014 at 9:32 AM, Karim Mezhoud <kmezhoud at gmail.com>
>> wrote:
>> >
>> >> Thanks Dr Hadley,
>> >>
>> >> but when I use a function the myenv remains temporary and I am to face
>> the
>> >> same problem.
>> >>
>> >>
>> >> fun <- function(){
>> >>
>> >> myenv <- new.env(parent = emptyenv())
>> >>
>> >> fun1 <- function(){
>> >> myenv$X <- 5
>> >> }
>> >>
>> >> }
>> >>
>> >> ls(myEnv)
>> >> #character(0)
>> >>
>> >>   ?__
>> >>  c/ /'_;~~~~kmezhoud
>> >> (*) \(*)   ?????  ??????
>> >> http://bioinformatics.tn/
>> >>
>> >>
>> >>
>> >> On Tue, Dec 2, 2014 at 4:17 PM, Hadley Wickham <h.wickham at gmail.com>
>> >> wrote:
>> >>
>> >> > At the top level do:
>> >> >
>> >> > myenv <- new.env(parent = emptyenv())
>> >> >
>> >> > Then in your functions do
>> >> >
>> >> > myenv$x <- 50
>> >> > myenv$x
>> >> >
>> >> > etc
>> >> >
>> >> > You also should not be using data() in that way. Perhaps you want
>> >> > R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more
>> details.
>> >> >
>> >> > Hadley
>> >> >
>> >> > On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com>
>> >> wrote:
>> >> > > Dear All,
>> >> > >
>> >> > > I am writing a GUIpackage that needs global variables.
>> >> > > I had many warning message when I checked the code as for example:
>> >> > > geteSet: no visible binding for global variable ?curselectCases?
>> >> > > I would like to write a function that creates a global place for
>> >> Objects
>> >> > to
>> >> > > be loaded as:
>> >> > >
>> >> > >
>> >> > > Fun <- function(){
>> >> > >
>> >> > > Object <- 5
>> >> > >
>> >> > > Var2Global <- function(Object){
>> >> > > .myDataEnv <- new.env(parent=emptyenv()) # not exported
>> >> > > isLoaded <- function(Object) {
>> >> > >     exists(Object, .myDataEnv)
>> >> > > }
>> >> > > getData <- function(Object) {
>> >> > >     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
>> >> > >     .myDataEnv[[Object]]
>> >> > > }
>> >> > > }
>> >> > >
>> >> > > }
>> >> > >
>> >> > > To avoid the use of:  Object <<- 5
>> >> > >
>> >> > > but it seems not working yet. Object == 5 is not a global variable
>> >> after
>> >> > > running Fun().
>> >> > >
>> >> > > Any Idea?
>> >> > > Thanks
>> >> > >   ?__
>> >> > >  c/ /'_;~~~~kmezhoud
>> >> > > (*) \(*)   ?????  ??????
>> >> > > http://bioinformatics.tn/
>> >> > >
>> >> > >         [[alternative HTML version deleted]]
>> >> > >
>> >> > > ______________________________________________
>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > > and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > http://had.co.nz/
>> >> >
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>> >
>> > --
>> > Gregory (Greg) L. Snow Ph.D.
>> > 538280 at gmail.com
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From stbarningham at gmail.com  Fri Dec  5 16:00:38 2014
From: stbarningham at gmail.com (Thomas Barningham)
Date: Fri, 5 Dec 2014 15:00:38 +0000
Subject: [R] Run script automatically on several input files in the
 directory and produce separate outputs?
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3C755E3@inbomail.inbo.be>
References: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C755E3@inbomail.inbo.be>
Message-ID: <CAM5qaWeK4xDWv5Xp=G1R11-60F2CppYx5Vj4LeqFHWYhMSfzNQ@mail.gmail.com>

Dear Thierry,

Thanks for your suggestion...but I don't how I would apply this for my
situation, the R help isn't much help for me either. (Apologies - I am
a rookie!) Do I still need a for loop?

Many thanks
Thomas



On Fri, Dec 5, 2014 at 2:20 PM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear Thomas,
>
> list.files() will be your new best friend.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> -----Oorspronkelijk bericht-----
> Van: R-help [mailto:r-help-bounces at r-project.org] Namens Thomas Barningham
> Verzonden: vrijdag 5 december 2014 14:41
> Aan: r-help at r-project.org
> Onderwerp: [R] Run script automatically on several input files in the directory and produce separate outputs?
>
> Hi,
>
> I have written a script that currently reads in a .txt file where I specify the name e.g
>
> mydata<-read.table("a_date.txt", header=TRUE)
>
> The script eventually produces a plot, e.g:
>
> pdf(file="myfilename.txt")
> plot(etc)
> dev.off
>
> What I want to do is run this script on several input files in my directory, without having to manually change the input file name each time, and produce the output plot pdf with the input file name as the output file name. It would also be handy if my plot title is also the input file name.
>
> I'm relatively new to R so i'm not sure how to approach this. I presume it's some sort of loop function, but i've never implemented one of these before - any advice would be greatly appreciated!
>
> Thanks in advance!
> Thomas
> --
> Thomas Barningham
> Centre for Ocean and Atmospheric Sciences School of Environmental Sciences University of East Anglia Norwich Research Park Norwich
> NR4 7TJ
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> **** D I S C L A I M E R ****
> Bezoek onze website/Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>



-- 
Thomas Barningham
Centre for Ocean and Atmospheric Sciences
School of Environmental Sciences
University of East Anglia
Norwich Research Park
Norwich
NR4 7TJ


From jdnewmil at dcn.davis.CA.us  Fri Dec  5 16:10:05 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 05 Dec 2014 07:10:05 -0800
Subject: [R] Run script automatically on several input files in the
	directory and produce separate outputs?
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3C755E3@inbomail.inbo.be>
References: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3C755E3@inbomail.inbo.be>
Message-ID: <91EA25E1-7000-4B76-8DFB-D5E1D8942523@dcn.davis.CA.us>

Of course, you probably also need to wrap your code into a function first. R script files are not very good units of code to repeat multiple times. Once you have a function that you can give a data file name to and get a plot, then it is easy to use the lapply function to call that function once for each filename you get back from the list.files function.

Reading other emails on this list can be helpful also. In the last day there was a discussion about how to rename files which could give you ideas how to automatically make new filenames to write your plot images into. See the archives mentioned in the link in the footer of this message. E.g.

myplotfilecreator <- function( fname ) {
  pngfname <- paste0( fname, ".png" )
  # code to create png file
  pngfname # return output file name when done
}

inputdir <- "data" # where your input files are
fnames <- list.files( inputdir, full.names=TRUE )
lapply( fnames, myplotfilecreator )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 5, 2014 6:20:47 AM PST, "ONKELINX, Thierry" <Thierry.ONKELINX at inbo.be> wrote:
>Dear Thomas,
>
>list.files() will be your new best friend.
>
>Best regards,
>
>ir. Thierry Onkelinx
>Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>and Forest
>team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>Kliniekstraat 25
>1070 Anderlecht
>Belgium
>+ 32 2 525 02 51
>+ 32 54 43 61 85
>Thierry.Onkelinx at inbo.be
>www.inbo.be
>
>To call in the statistician after the experiment is done may be no more
>than asking him to perform a post-mortem examination: he may be able to
>say what the experiment died of.
>~ Sir Ronald Aylmer Fisher
>
>The plural of anecdote is not data.
>~ Roger Brinner
>
>The combination of some data and an aching desire for an answer does
>not ensure that a reasonable answer can be extracted from a given body
>of data.
>~ John Tukey
>
>-----Oorspronkelijk bericht-----
>Van: R-help [mailto:r-help-bounces at r-project.org] Namens Thomas
>Barningham
>Verzonden: vrijdag 5 december 2014 14:41
>Aan: r-help at r-project.org
>Onderwerp: [R] Run script automatically on several input files in the
>directory and produce separate outputs?
>
>Hi,
>
>I have written a script that currently reads in a .txt file where I
>specify the name e.g
>
>mydata<-read.table("a_date.txt", header=TRUE)
>
>The script eventually produces a plot, e.g:
>
>pdf(file="myfilename.txt")
>plot(etc)
>dev.off
>
>What I want to do is run this script on several input files in my
>directory, without having to manually change the input file name each
>time, and produce the output plot pdf with the input file name as the
>output file name. It would also be handy if my plot title is also the
>input file name.
>
>I'm relatively new to R so i'm not sure how to approach this. I presume
>it's some sort of loop function, but i've never implemented one of
>these before - any advice would be greatly appreciated!
>
>Thanks in advance!
>Thomas
>--
>Thomas Barningham
>Centre for Ocean and Atmospheric Sciences School of Environmental
>Sciences University of East Anglia Norwich Research Park Norwich
>NR4 7TJ
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>**** D I S C L A I M E R ****
>Bezoek onze website/Visit our
>website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Fri Dec  5 16:24:28 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 5 Dec 2014 07:24:28 -0800
Subject: [R] function to avoid <<-
In-Reply-To: <CALJKBv-J63nPR7azeYEXZL7pWH7jaWN8ajhxR55ksepwGo8vRA@mail.gmail.com>
References: <CALJKBv9ENaxcvkWwmLpxfqPwwwyqMqZ72P1ooiOapMX535gsLQ@mail.gmail.com>
	<CABdHhvHyetihkVYxfSnG9WM8ktTxashpkS0S68eqZzNb-84kpQ@mail.gmail.com>
	<CALJKBv_1o7zBD4R5MQ6Qmr7Qyp9_nzdWHPNTidr33bTt+do8hQ@mail.gmail.com>
	<CAFEqCdy9vWXA0zXYiaVn5pg5-tT_gmx+R=bs=vBy4ywBA6bnKw@mail.gmail.com>
	<CALJKBv-He=6BDEKqqG=0GWH8Pu5wgwxwHiOm-Nwp2amsrar02w@mail.gmail.com>
	<CAN5YmCGPHqxGin-1u_QG610NiL5N4+g5QXeX4f+qz5z6LkH=6w@mail.gmail.com>
	<CALJKBv-J63nPR7azeYEXZL7pWH7jaWN8ajhxR55ksepwGo8vRA@mail.gmail.com>
Message-ID: <CAFDcVCT_DwfixKDNjRTKtf=oHbueT6OasZHWdG3X4nQEUP2MEA@mail.gmail.com>

Don't have your package "mess with" (e.g. assign) to the global
environment. Also, CRAN won't accept such packages.

A good rule of thumb is that if you find yourself using assign(), get(),
and <<-, or assigning explicitly to the global environment, it's a good
indicator that you're hiking up the wrong path and that there's probably a
better and more scenic route you should follow.

... Hadley's suggested a nice one.

Henrik
Hi,
An other alternative using "assign" function

func <- function(){
X <- 5
assign("X", X, envir = .GlobalEnv)
}


  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Tue, Dec 2, 2014 at 8:40 PM, Adams, Jean <jvadams at usgs.gov> wrote:

> Glad to see this query and the responses.  You all just helped me to
> eliminate the use of global variables from my R package.  I knew they were
> not recommended, but I didn't know how to get around using them.
>
> Thanks!
>
> Jean
>
> On Tue, Dec 2, 2014 at 10:59 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> OK thanks as:
>>
>> myenv <- new.env(parent = emptyenv())
>> fun <- function(){
>> fun1 <- function(){
>> myenv$X <- 5
>> }
>>
>> }
>> fun()
>> ls(myenv)
>> #X
>> X
>> #5
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Tue, Dec 2, 2014 at 5:47 PM, Greg Snow <538280 at gmail.com> wrote:
>>
>> > By "At the top level" Hadley meant to put that code outside of the
>> > function definition.  In you source file that line should be very near
>> the
>> > top, before any function definitions.  Then "myenv" will not be
>> temporary
>> > (well it will go away when you end the R session).  Further, when this
>> code
>> > is compiled into a package then "myenv" becomes package local, meaning
>> that
>> > functions within the package can access it and the objects inside of
it,
>> > but it will not interfere with any other packages or the global
>> environment.
>> >
>> > On Tue, Dec 2, 2014 at 9:32 AM, Karim Mezhoud <kmezhoud at gmail.com>
>> wrote:
>> >
>> >> Thanks Dr Hadley,
>> >>
>> >> but when I use a function the myenv remains temporary and I am to face
>> the
>> >> same problem.
>> >>
>> >>
>> >> fun <- function(){
>> >>
>> >> myenv <- new.env(parent = emptyenv())
>> >>
>> >> fun1 <- function(){
>> >> myenv$X <- 5
>> >> }
>> >>
>> >> }
>> >>
>> >> ls(myEnv)
>> >> #character(0)
>> >>
>> >>   ?__
>> >>  c/ /'_;~~~~kmezhoud
>> >> (*) \(*)   ?????  ??????
>> >> http://bioinformatics.tn/
>> >>
>> >>
>> >>
>> >> On Tue, Dec 2, 2014 at 4:17 PM, Hadley Wickham <h.wickham at gmail.com>
>> >> wrote:
>> >>
>> >> > At the top level do:
>> >> >
>> >> > myenv <- new.env(parent = emptyenv())
>> >> >
>> >> > Then in your functions do
>> >> >
>> >> > myenv$x <- 50
>> >> > myenv$x
>> >> >
>> >> > etc
>> >> >
>> >> > You also should not be using data() in that way. Perhaps you want
>> >> > R/sysdata.rda. See http://r-pkgs.had.co.nz/data.html for more
>> details.
>> >> >
>> >> > Hadley
>> >> >
>> >> > On Tue, Dec 2, 2014 at 2:28 AM, Karim Mezhoud <kmezhoud at gmail.com>
>> >> wrote:
>> >> > > Dear All,
>> >> > >
>> >> > > I am writing a GUIpackage that needs global variables.
>> >> > > I had many warning message when I checked the code as for example:
>> >> > > geteSet: no visible binding for global variable ?curselectCases?
>> >> > > I would like to write a function that creates a global place for
>> >> Objects
>> >> > to
>> >> > > be loaded as:
>> >> > >
>> >> > >
>> >> > > Fun <- function(){
>> >> > >
>> >> > > Object <- 5
>> >> > >
>> >> > > Var2Global <- function(Object){
>> >> > > .myDataEnv <- new.env(parent=emptyenv()) # not exported
>> >> > > isLoaded <- function(Object) {
>> >> > >     exists(Object, .myDataEnv)
>> >> > > }
>> >> > > getData <- function(Object) {
>> >> > >     if (!isLoaded(Object)) data(Object, envir=.myDataEnv)
>> >> > >     .myDataEnv[[Object]]
>> >> > > }
>> >> > > }
>> >> > >
>> >> > > }
>> >> > >
>> >> > > To avoid the use of:  Object <<- 5
>> >> > >
>> >> > > but it seems not working yet. Object == 5 is not a global variable
>> >> after
>> >> > > running Fun().
>> >> > >
>> >> > > Any Idea?
>> >> > > Thanks
>> >> > >   ?__
>> >> > >  c/ /'_;~~~~kmezhoud
>> >> > > (*) \(*)   ?????  ??????
>> >> > > http://bioinformatics.tn/
>> >> > >
>> >> > >         [[alternative HTML version deleted]]
>> >> > >
>> >> > > ______________________________________________
>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > > and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> >
>> >> >
>> >> > --
>> >> > http://had.co.nz/
>> >> >
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>> >
>> > --
>> > Gregory (Greg) L. Snow Ph.D.
>> > 538280 at gmail.com
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From zilefacelvis at yahoo.com  Fri Dec  5 16:35:59 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 5 Dec 2014 15:35:59 +0000 (UTC)
Subject: [R] Rename multiple files in a directory and write renamed
 files back to directory
In-Reply-To: <54813FF3.1010205@mail.usask.ca>
References: <54813FF3.1010205@mail.usask.ca>
Message-ID: <384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>

Hi Chel,
How can I modify the script such that the numbering starts from 200,... instead of 001?
flag="0" does not accept anything other than 0.
Thanks,
Asong.



On Thursday, December 4, 2014 11:17 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
I see that a function 'format()' is used in your code.

> format(c(1,5,32,100), width=3, flag="0")
[1] "  1" "  5" " 32" "100"

> formatC(c(1,5,32,100), width=3, flag="0")
[1] "001" "005" "032" "100"

I hope this helps.

Chel Hee Lee



On 12/04/2014 10:54 PM, Zilefac Elvis wrote:
> Hi Chel,
> Thanks for the timely reply.
> It works but a minor problem remains.
> Here is the modified version of your code:
>
> file_names<- list.files(pattern="Sim1971-2000_Daily_")
> new_names <- paste("rcp45_Daily_Sim",format(seq(length(file_names)), width=3, flag="00"), ".dat", sep="")
>
> #files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files/contents
> file.rename(from=file_names, to=new_names)
> list.files(pattern="*.dat")
>
> I changed width =3 and flag=00 because my output has to be 001.dat...200.dat. However, this is what i got:
>
> list.files(pattern="*.dat")
> [1] "rcp45_Daily_Sim  1.dat" "rcp45_Daily_Sim  2.dat" "rcp45_Daily_Sim  3.dat" "rcp45_Daily_Sim  4.dat"
> [5] "rcp45_Daily_Sim  5.dat" "rcp45_Daily_Sim  6.dat" "rcp45_Daily_Sim  7.dat" "rcp45_Daily_Sim  8.dat"
> [9] "rcp45_Daily_Sim  9.dat" "rcp45_Daily_Sim 10.dat"
>
>
> The zeros disappear but I need them.
>
> Please help.
> Asong.
>
>
> On Thursday, December 4, 2014 10:16 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
> I put five data files (example1.dat, example2.dat, example3.dat,
> example4.dat, example5.dat, example6.dat) in my working directory.
>
>>
>> file_names <- list.files(pattern="*.dat")
>> file_names
> [1] "example1.dat" "example2.dat" "example3.dat" "example4.dat"
> "example5.dat"
> [6] "example6.dat"
>>
>> new_names <- paste("new_example_",
> + formatC(seq(length(file_names)), width=2, flag="0"),
> + ".dat", sep="")
>> new_names
> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>
>> file.rename(from=file_names, to=new_names)
> [1] TRUE TRUE TRUE TRUE TRUE TRUE
>> list.files(pattern="*.dat")
> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>
>
> Is this what you are looking for?  I hope this helps.
>
> Chel Hee Lee
>
>
>
> On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
>> Hello,
>> I would like to rename multiple files in a directory. Filenames are read using:
>>
>> lfile <- list.files(pattern="rcp45_Daily_")
>> files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files
>>
>> dput(lfile)
>> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>>
>>
>> - How can I rename these files (200 in number) using something like:
>>     file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.
>>
>> - I would like to write the new file names to the directory.
>>
>> The data files contain huge amounts of data and should not be read into R. Only the file names should change.
>>
>> Many thanks for your helpful answers.
>> Asong.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>>


From alexg at ruggedtextile.com  Fri Dec  5 17:12:18 2014
From: alexg at ruggedtextile.com (Alex Gutteridge)
Date: Fri, 05 Dec 2014 16:12:18 +0000
Subject: [R] RCurl much faster than base R
Message-ID: <e8f35113f89a6d0bf5895a0a7c81b377@ruggedtextile.com>

I'm trying to debug a curious network issue, I wonder if anyone can help 
me as I (and my local sysadmin) am stumped:

This base R command takes ~1 minute to complete:

readLines(url("http://bioconductor.org/biocLite.R"))

(biocLite.R is a couple of KB in size)

Using RCurl (and so libcurl under the hood) is instantaneous (<1s):

library(RCurl)
getURL("http://bioconductor.org/biocLite.R")

I've not set it to use any proxies (which was my first thought) unless 
libcurl autodetects them somehow... And the speed is similarly fast 
using wget or curl on the command line. It just seems to be the base R 
commands which are slow (including install.packages etc...).

Does anyone have hints on how to debug this (if not an answer directly)?

AlexG


From zilefacelvis at yahoo.com  Fri Dec  5 17:13:07 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Fri, 5 Dec 2014 16:13:07 +0000 (UTC)
Subject: [R] Rename multiple files in a directory and write renamed
 files back to directory
In-Reply-To: <384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>
References: <54813FF3.1010205@mail.usask.ca>
	<384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>
Message-ID: <1553146666.5530213.1417795987329.JavaMail.yahoo@jws10670.mail.bf1.yahoo.com>

Hi Chel,
I got it right.
Many thanks.

file.rename(file_names, to=paste0("rcp45_Daily_Sim", 200:210))
list.files(pattern="rcp45_Daily_Sim") 
[1] "rcp45_Daily_Sim200" "rcp45_Daily_Sim201" "rcp45_Daily_Sim202"



On Friday, December 5, 2014 9:35 AM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi Chel,
How can I modify the script such that the numbering starts from 200,... instead of 001?
flag="0" does not accept anything other than 0.
Thanks,
Asong.




On Thursday, December 4, 2014 11:17 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
I see that a function 'format()' is used in your code.

> format(c(1,5,32,100), width=3, flag="0")
[1] "  1" "  5" " 32" "100"

> formatC(c(1,5,32,100), width=3, flag="0")
[1] "001" "005" "032" "100"

I hope this helps.

Chel Hee Lee



On 12/04/2014 10:54 PM, Zilefac Elvis wrote:
> Hi Chel,
> Thanks for the timely reply.
> It works but a minor problem remains.
> Here is the modified version of your code:
>
> file_names<- list.files(pattern="Sim1971-2000_Daily_")
> new_names <- paste("rcp45_Daily_Sim",format(seq(length(file_names)), width=3, flag="00"), ".dat", sep="")
>
> #files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files/contents
> file.rename(from=file_names, to=new_names)
> list.files(pattern="*.dat")
>
> I changed width =3 and flag=00 because my output has to be 001.dat...200.dat. However, this is what i got:
>
> list.files(pattern="*.dat")
> [1] "rcp45_Daily_Sim  1.dat" "rcp45_Daily_Sim  2.dat" "rcp45_Daily_Sim  3.dat" "rcp45_Daily_Sim  4.dat"
> [5] "rcp45_Daily_Sim  5.dat" "rcp45_Daily_Sim  6.dat" "rcp45_Daily_Sim  7.dat" "rcp45_Daily_Sim  8.dat"
> [9] "rcp45_Daily_Sim  9.dat" "rcp45_Daily_Sim 10.dat"
>
>
> The zeros disappear but I need them.
>
> Please help.
> Asong.
>
>
> On Thursday, December 4, 2014 10:16 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
> I put five data files (example1.dat, example2.dat, example3.dat,
> example4.dat, example5.dat, example6.dat) in my working directory.
>
>>
>> file_names <- list.files(pattern="*.dat")
>> file_names
> [1] "example1.dat" "example2.dat" "example3.dat" "example4.dat"
> "example5.dat"
> [6] "example6.dat"
>>
>> new_names <- paste("new_example_",
> + formatC(seq(length(file_names)), width=2, flag="0"),
> + ".dat", sep="")
>> new_names
> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>
>> file.rename(from=file_names, to=new_names)
> [1] TRUE TRUE TRUE TRUE TRUE TRUE
>> list.files(pattern="*.dat")
> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>
>
> Is this what you are looking for?  I hope this helps.
>
> Chel Hee Lee
>
>
>
> On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
>> Hello,
>> I would like to rename multiple files in a directory. Filenames are read using:
>>
>> lfile <- list.files(pattern="rcp45_Daily_")
>> files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files
>>
>> dput(lfile)
>> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>>
>>
>> - How can I rename these files (200 in number) using something like:
>>     file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.
>>
>> - I would like to write the new file names to the directory.
>>
>> The data files contain huge amounts of data and should not be read into R. Only the file names should change.
>>
>> Many thanks for your helpful answers.
>> Asong.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>>


From jdnewmil at dcn.davis.CA.us  Fri Dec  5 17:17:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 05 Dec 2014 08:17:51 -0800
Subject: [R] Rename multiple files in a directory and write renamed
	files back to directory
In-Reply-To: <384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>
References: <54813FF3.1010205@mail.usask.ca>
	<384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>
Message-ID: <B49F671E-6471-4A6C-828E-D55A5FE55D48@dcn.davis.CA.us>

You could read the help file:

?formatC

which says that flag modifies how the numbers are formatted... it does not affect what numbers are used..  that is given by the "x" argument (typically the first item in the argument list to formatC). In your case I think that came from a call to the seq function, so perhaps you should read

?seq
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 5, 2014 7:35:59 AM PST, Zilefac Elvis via R-help <r-help at r-project.org> wrote:
>Hi Chel,
>How can I modify the script such that the numbering starts from 200,...
>instead of 001?
>flag="0" does not accept anything other than 0.
>Thanks,
>Asong.
>
>
>
>On Thursday, December 4, 2014 11:17 PM, Chel Hee Lee
><chl948 at mail.usask.ca> wrote:
>I see that a function 'format()' is used in your code.
>
>> format(c(1,5,32,100), width=3, flag="0")
>[1] "  1" "  5" " 32" "100"
>
>> formatC(c(1,5,32,100), width=3, flag="0")
>[1] "001" "005" "032" "100"
>
>I hope this helps.
>
>Chel Hee Lee
>
>
>
>On 12/04/2014 10:54 PM, Zilefac Elvis wrote:
>> Hi Chel,
>> Thanks for the timely reply.
>> It works but a minor problem remains.
>> Here is the modified version of your code:
>>
>> file_names<- list.files(pattern="Sim1971-2000_Daily_")
>> new_names <- paste("rcp45_Daily_Sim",format(seq(length(file_names)),
>width=3, flag="00"), ".dat", sep="")
>>
>> #files <-  paste(paste(getwd(),lfile,sep="/"),
>list.files(lfile),sep="/")# getwd of these files/contents
>> file.rename(from=file_names, to=new_names)
>> list.files(pattern="*.dat")
>>
>> I changed width =3 and flag=00 because my output has to be
>001.dat...200.dat. However, this is what i got:
>>
>> list.files(pattern="*.dat")
>> [1] "rcp45_Daily_Sim  1.dat" "rcp45_Daily_Sim  2.dat"
>"rcp45_Daily_Sim  3.dat" "rcp45_Daily_Sim  4.dat"
>> [5] "rcp45_Daily_Sim  5.dat" "rcp45_Daily_Sim  6.dat"
>"rcp45_Daily_Sim  7.dat" "rcp45_Daily_Sim  8.dat"
>> [9] "rcp45_Daily_Sim  9.dat" "rcp45_Daily_Sim 10.dat"
>>
>>
>> The zeros disappear but I need them.
>>
>> Please help.
>> Asong.
>>
>>
>> On Thursday, December 4, 2014 10:16 PM, Chel Hee Lee
><chl948 at mail.usask.ca> wrote:
>> I put five data files (example1.dat, example2.dat, example3.dat,
>> example4.dat, example5.dat, example6.dat) in my working directory.
>>
>>>
>>> file_names <- list.files(pattern="*.dat")
>>> file_names
>> [1] "example1.dat" "example2.dat" "example3.dat" "example4.dat"
>> "example5.dat"
>> [6] "example6.dat"
>>>
>>> new_names <- paste("new_example_",
>> + formatC(seq(length(file_names)), width=2, flag="0"),
>> + ".dat", sep="")
>>> new_names
>> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
>> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>>
>>> file.rename(from=file_names, to=new_names)
>> [1] TRUE TRUE TRUE TRUE TRUE TRUE
>>> list.files(pattern="*.dat")
>> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
>> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>>
>>
>> Is this what you are looking for?  I hope this helps.
>>
>> Chel Hee Lee
>>
>>
>>
>> On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
>>> Hello,
>>> I would like to rename multiple files in a directory. Filenames are
>read using:
>>>
>>> lfile <- list.files(pattern="rcp45_Daily_")
>>> files <-  paste(paste(getwd(),lfile,sep="/"),
>list.files(lfile),sep="/")# getwd of these files
>>>
>>> dput(lfile)
>>> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>>>
>>>
>>> - How can I rename these files (200 in number) using something like:
>>>     file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new
>filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ...,
>rcp45_Daily_Sim200.
>>>
>>> - I would like to write the new file names to the directory.
>>>
>>> The data files contain huge amounts of data and should not be read
>into R. Only the file names should change.
>>>
>>> Many thanks for your helpful answers.
>>> Asong.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Fri Dec  5 17:13:47 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Fri, 05 Dec 2014 10:13:47 -0600
Subject: [R] Rename multiple files in a directory and write renamed
 files back to directory
In-Reply-To: <384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>
References: <54813FF3.1010205@mail.usask.ca>
	<384073080.5592874.1417793759137.JavaMail.yahoo@jws10622.mail.bf1.yahoo.com>
Message-ID: <5481D9BB.1070606@mail.usask.ca>

Your question is not clear to me.  Do you wish to start numbers from 200 
using 'formatC()'?

 > formatC(seq(from=200, to=1200, by=500), width=5, flag="0")
[1] "00200" "00700" "01200"

You can do the same job using function 'sprintf()' as shown in the below:

 > sprintf("%05d", seq(from=200, to=1200, by=500))
[1] "00200" "00700" "01200"

I like to read the documentation by typing

 > help(formatC)
 > help(sprintf)

You may find answers what you wish to get.  Documentation has been my 
best friend when using R.  I hope this helps.

Chel Hee Lee


On 12/05/2014 09:35 AM, Zilefac Elvis wrote:
> Hi Chel,
> How can I modify the script such that the numbering starts from 200,... instead of 001?
> flag="0" does not accept anything other than 0.
> Thanks,
> Asong.
>
>
>
> On Thursday, December 4, 2014 11:17 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
> I see that a function 'format()' is used in your code.
>
>> format(c(1,5,32,100), width=3, flag="0")
> [1] "  1" "  5" " 32" "100"
>
>> formatC(c(1,5,32,100), width=3, flag="0")
> [1] "001" "005" "032" "100"
>
> I hope this helps.
>
> Chel Hee Lee
>
>
>
> On 12/04/2014 10:54 PM, Zilefac Elvis wrote:
>> Hi Chel,
>> Thanks for the timely reply.
>> It works but a minor problem remains.
>> Here is the modified version of your code:
>>
>> file_names<- list.files(pattern="Sim1971-2000_Daily_")
>> new_names <- paste("rcp45_Daily_Sim",format(seq(length(file_names)), width=3, flag="00"), ".dat", sep="")
>>
>> #files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files/contents
>> file.rename(from=file_names, to=new_names)
>> list.files(pattern="*.dat")
>>
>> I changed width =3 and flag=00 because my output has to be 001.dat...200.dat. However, this is what i got:
>>
>> list.files(pattern="*.dat")
>> [1] "rcp45_Daily_Sim  1.dat" "rcp45_Daily_Sim  2.dat" "rcp45_Daily_Sim  3.dat" "rcp45_Daily_Sim  4.dat"
>> [5] "rcp45_Daily_Sim  5.dat" "rcp45_Daily_Sim  6.dat" "rcp45_Daily_Sim  7.dat" "rcp45_Daily_Sim  8.dat"
>> [9] "rcp45_Daily_Sim  9.dat" "rcp45_Daily_Sim 10.dat"
>>
>>
>> The zeros disappear but I need them.
>>
>> Please help.
>> Asong.
>>
>>
>> On Thursday, December 4, 2014 10:16 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>> I put five data files (example1.dat, example2.dat, example3.dat,
>> example4.dat, example5.dat, example6.dat) in my working directory.
>>
>>>
>>> file_names <- list.files(pattern="*.dat")
>>> file_names
>> [1] "example1.dat" "example2.dat" "example3.dat" "example4.dat"
>> "example5.dat"
>> [6] "example6.dat"
>>>
>>> new_names <- paste("new_example_",
>> + formatC(seq(length(file_names)), width=2, flag="0"),
>> + ".dat", sep="")
>>> new_names
>> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
>> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>>
>>> file.rename(from=file_names, to=new_names)
>> [1] TRUE TRUE TRUE TRUE TRUE TRUE
>>> list.files(pattern="*.dat")
>> [1] "new_example_01.dat" "new_example_02.dat" "new_example_03.dat"
>> [4] "new_example_04.dat" "new_example_05.dat" "new_example_06.dat"
>>>
>>
>> Is this what you are looking for?  I hope this helps.
>>
>> Chel Hee Lee
>>
>>
>>
>> On 12/04/2014 09:44 PM, Zilefac Elvis via R-help wrote:
>>> Hello,
>>> I would like to rename multiple files in a directory. Filenames are read using:
>>>
>>> lfile <- list.files(pattern="rcp45_Daily_")
>>> files <-  paste(paste(getwd(),lfile,sep="/"), list.files(lfile),sep="/")# getwd of these files
>>>
>>> dput(lfile)
>>> c("rcp45_Daily_Sim001.dat", "rcp45_Daily_Sim002.dat")
>>>
>>>
>>> - How can I rename these files (200 in number) using something like:
>>>      file.rename(lfile, paste0("rcp45_Daily_Sim", 1:200))?The new filenames should be rcp45_Daily_Sim001, rcp45_Daily_Sim002, ..., rcp45_Daily_Sim200.
>>>
>>> - I would like to write the new file names to the directory.
>>>
>>> The data files contain huge amounts of data and should not be read into R. Only the file names should change.
>>>
>>> Many thanks for your helpful answers.
>>> Asong.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>>


From maitra.mbox.ignored at inbox.com  Fri Dec  5 18:34:37 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 5 Dec 2014 11:34:37 -0600
Subject: [R] Deducer future?
Message-ID: <20141205113437.ecf071966065322598fae317@inbox.com>

Hi,

I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost. 

I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.

I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.

Many thanks and best wishes,
Ranjan


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From murdoch.duncan at gmail.com  Fri Dec  5 18:54:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 5 Dec 2014 12:54:17 -0500
Subject: [R] Deducer future?
In-Reply-To: <20141205113437.ecf071966065322598fae317@inbox.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
Message-ID: <5481F149.20607@gmail.com>

On 05/12/2014 12:34 PM, Ranjan Maitra wrote:
> Hi,
>
> I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost.
>
> I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.
>
> I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.
>
> Many thanks and best wishes,
> Ranjan
>
>
A question like this could only be answered by the maintainer of the 
package.  Have you tried writing there?  (You might already know the 
answer if you've reported the "issues" to them.)

Duncan Murdoch


From mmurenu at unica.it  Fri Dec  5 10:51:27 2014
From: mmurenu at unica.it (Matteo Murenu)
Date: Fri, 5 Dec 2014 10:51:27 +0100
Subject: [R] Put 2 ablines in an "empty plot"
In-Reply-To: <5C12CEFC-B70F-4972-8F4C-38FC19FBFD44@comcast.net>
References: <SNT404-EAS4045F54C8CC87B9284432380790@phx.gbl>
	<5C12CEFC-B70F-4972-8F4C-38FC19FBFD44@comcast.net>
Message-ID: <005201d01071$09931f50$1cb95df0$@unica.it>

plot.new()
abline(0,1)
abline(1,1)

# or as Michael suggest
plot(1:10, 1:10, type = "n")
# then 
abline(0,1)
abline(1,1)

Best
Matteo Murenu,
Cagliari, IT


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David
Winsemius
Sent: 05 December 2014 10:07
To: Adrien Bonvin
Cc: r-help at r-project.org
Subject: Re: [R] Put 2 ablines in an "empty plot"


On Dec 5, 2014, at 12:30 AM, Adrien Bonvin wrote:

> Bonjour
> Hi everybody,
> 
> Firs of all, sorry for my terrible English,
> 
> I would like to know if it's possible to create an "empty plot" in which i
could add two ablines I created on two different plots earlyer in my script.
> 
> 
> 
Read there help page for ?plot.default. There is a type parameter that lets
you do what you ask. There's also a worked example on ?plot.window
> 
> As a result I would like to have a plot with only the two ablines (in the
same plot) but without the graphs I used to create the ablines in the first
place.
> 
> I hope I explained my problem well enough.
> 
> Thanks for helping me out, i hope someone has the answer.
> 
> Adrien Bonvin
> 	[[alternative HTML version deleted]]

Please read what the posting guide says about html posting.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rena.buesch at gmx.de  Fri Dec  5 13:28:15 2014
From: rena.buesch at gmx.de (=?ISO-8859-1?Q?Rena_B=FCsch?=)
Date: Fri, 05 Dec 2014 13:28:15 +0100
Subject: [R] Difference in cummulative variance depending on print command
Message-ID: <5481A4DF.4060908@gmx.de>

Hello,
I am trying a factor analysis via R.
When running the pricipal axis analysis I do get different tables depending
on the print command.
This is my factor analysis:
fa.pa_cor_3_2<- fa(ItemsCor_4, nfactors=3, fm="pa",rotate="oblimin")

To get the h2 I did the following print command:
print (fa.pa_cor_3_2, digits=2, cut=.3, sort=T)
To just get the loadings I did the following print command:
print (fa.pa_cor_3_2$loadings, digits=2, cutoff=.3, sort=T)

The result of the first print is the following Eigenvalue-cumulative
variance table:
                     PA1   PA2  PA3
SS loadings    20.59 18.16 5.03
Proportion Var  0.28  0.25 0.07
Cumulative Var  0.28  0.52 0.59

With the second print command I get a different table:
                     PA1   PA2  PA3
SS loadings    17.63 15.12 3.14
Proportion Var  0.24  0.20 0.04
Cumulative Var  0.24  0.44 0.49

The loadings are the same for both commands. There is just this slight
difference in the cumulative Var.

Does anyone have an idea of a cause for the difference? What can I report?
Did I post enough information to fully understand my problem?
Thanks in Advance
Rena


From mhdk.dinesh at gmail.com  Fri Dec  5 16:16:56 2014
From: mhdk.dinesh at gmail.com (Dinesh Chowdhary)
Date: Fri, 5 Dec 2014 10:16:56 -0500
Subject: [R] Factors and NaN
Message-ID: <CAH7iKjLuFxv2cKQc9MqYRWsQPJtT4Wco5UEFMSNAM+8hwvBcRA@mail.gmail.com>

R-3.1.2

> x <- factor(c("yes", "yes", "no", NA, "yes", "no", NaN))
> x
[1] yes  yes  no   <NA> yes  no   NaN
Levels: NaN no yes
> is.nan(x)
[1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE

>From the above snippet can you notice that the "NaN" value is not logically
identified in a vector? Can anyone elaborate on this?

Thank you for your effort!

	[[alternative HTML version deleted]]


From mhdk.dinesh at gmail.com  Fri Dec  5 18:12:05 2014
From: mhdk.dinesh at gmail.com (Dinesh Chowdhary)
Date: Fri, 5 Dec 2014 12:12:05 -0500
Subject: [R] Subsetting R 3.1.2
Message-ID: <CAH7iKjLOU7JC-4Ry=6Y+kfXbcfTth3C7mfZOXwEVn8Fw_2OHAA@mail.gmail.com>

> x <- list(seq = 3:7, alpha = c("a", "b", "c"))
> x$alpha
[1] "a" "b" "c"

> x["alpha"]
$alpha
[1] "a" "b" "c"

> x[c(1,2)]
$seq
[1] 3 4 5 6 7

$alpha
[1] "a" "b" "c"

*> x[c(1, alpha[2])]*
*$<NA>*
*NULL*

*$<NA>*
*NULL*

How to access a character subset withing a list?

Thank you for your effort...

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec  5 19:31:05 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Dec 2014 10:31:05 -0800
Subject: [R] Factors and NaN
In-Reply-To: <CAH7iKjLuFxv2cKQc9MqYRWsQPJtT4Wco5UEFMSNAM+8hwvBcRA@mail.gmail.com>
References: <CAH7iKjLuFxv2cKQc9MqYRWsQPJtT4Wco5UEFMSNAM+8hwvBcRA@mail.gmail.com>
Message-ID: <DA500BFA-88BA-4202-95D3-E3189370EDDF@comcast.net>


On Dec 5, 2014, at 7:16 AM, Dinesh Chowdhary wrote:

> R-3.1.2
> 
>> x <- factor(c("yes", "yes", "no", NA, "yes", "no", NaN))
>> x
> [1] yes  yes  no   <NA> yes  no   NaN
> Levels: NaN no yes
>> is.nan(x)
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> 
>> From the above snippet can you notice that the "NaN" value is not logically
> identified in a vector? Can anyone elaborate on this?

It gets converted to a character value. (As always... Read the help page.)

> x <- factor(c("yes", "yes", "no", NA, "yes", "no", NaN), exclude=c(NA,NaN) )
> x
[1] yes  yes  no   <NA> yes  no   <NA>
Levels: no yes

> 
> Thank you for your effort!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From chl948 at mail.usask.ca  Fri Dec  5 19:40:48 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Fri, 05 Dec 2014 12:40:48 -0600
Subject: [R] Factors and NaN
In-Reply-To: <CAH7iKjLuFxv2cKQc9MqYRWsQPJtT4Wco5UEFMSNAM+8hwvBcRA@mail.gmail.com>
References: <CAH7iKjLuFxv2cKQc9MqYRWsQPJtT4Wco5UEFMSNAM+8hwvBcRA@mail.gmail.com>
Message-ID: <5481FC30.3000600@mail.usask.ca>

'NaN' is a reserved keyword that implies 'Not a number'.  I see that you 
use a character vector that includes 'NA' and 'NaN'.  The former 'NA' is 
considered as a missing value; however, the latter 'NaN' is considered 
as a string 'NaN'.  That's why three levels of 'NaN', 'no', 'yes' are 
shown.

Function 'is.nan()' test if a numeric value is 'NaN'. Since you are 
using a character vector, the result of using 'is.nan()' should be all 
FALSE.

If you wish to make R understand 'NaN' as missing value, it would be a 
good choice to use reserved keyword 'NA_character' as shown in the below:

 > x <- factor(c("yes", "yes", "no", NA, "yes", "no", NA_character_))
 > x
[1] yes  yes  no   <NA> yes  no   <NA>
Levels: no yes
 > is.na(x)
[1] FALSE FALSE FALSE  TRUE FALSE FALSE  TRUE

I hope this helps.

Chel Hee Lee

On 12/5/2014 9:16 AM, Dinesh Chowdhary wrote:
> R-3.1.2
>
>> x <- factor(c("yes", "yes", "no", NA, "yes", "no", NaN))
>> x
> [1] yes  yes  no   <NA> yes  no   NaN
> Levels: NaN no yes
>> is.nan(x)
> [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>
>>From the above snippet can you notice that the "NaN" value is not logically
> identified in a vector? Can anyone elaborate on this?
>
> Thank you for your effort!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chl948 at mail.usask.ca  Fri Dec  5 19:44:19 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Fri, 05 Dec 2014 12:44:19 -0600
Subject: [R] Subsetting R 3.1.2
In-Reply-To: <CAH7iKjLOU7JC-4Ry=6Y+kfXbcfTth3C7mfZOXwEVn8Fw_2OHAA@mail.gmail.com>
References: <CAH7iKjLOU7JC-4Ry=6Y+kfXbcfTth3C7mfZOXwEVn8Fw_2OHAA@mail.gmail.com>
Message-ID: <5481FD03.3060604@mail.usask.ca>

Your question is not clear to me.

 > x$alpha[1:2]
[1] "a" "b"
 > x$alpha[2]
[1] "b"
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 12/5/2014 11:12 AM, Dinesh Chowdhary wrote:
>> x <- list(seq = 3:7, alpha = c("a", "b", "c"))
>> x$alpha
> [1] "a" "b" "c"
>
>> x["alpha"]
> $alpha
> [1] "a" "b" "c"
>
>> x[c(1,2)]
> $seq
> [1] 3 4 5 6 7
>
> $alpha
> [1] "a" "b" "c"
>
> *> x[c(1, alpha[2])]*
> *$<NA>*
> *NULL*
>
> *$<NA>*
> *NULL*
>
> How to access a character subset withing a list?
>
> Thank you for your effort...
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Fri Dec  5 20:07:17 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 5 Dec 2014 19:07:17 +0000
Subject: [R] Run script automatically on several input files in the
 directory and produce separate outputs?
In-Reply-To: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>
References: <CAM5qaWfLrPrin1gB1owYg3gVHKu4RPHqXuRDOgCL-oDF07Sp_Q@mail.gmail.com>
Message-ID: <D0A740CE.114ECB%macqueen1@llnl.gov>

The simplest approach, and a good one for someone new to R, would be
something like this:

myfiles <- c('fileA', 'fileB','fileC")

for (nm in myfiles) {
  cat('now reading input file',nm,'\n')
  mydat <- read.table( paste0(nm,'.txt'), header=TRUE)
  pdf( paste0(nm, '.pdf') )
  plot(etc , main=nm)
  dev.off()
}

I stored the file names without the ".txt", so that the base part of the
name could more easily be used to construct the pdf file name. The
paste0() command is used to construct the full input and pdf file names,
i.e., with the .txt and .pdf suffices.

Fancier tools include using functions like list.files() to, for example,
find the names of all the .txt files in your current working directory,
but until you understand what I've shown you, I wouldn't tackle those.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/5/14, 5:40 AM, "Thomas Barningham" <stbarningham at gmail.com> wrote:

>Hi,
>
>I have written a script that currently reads in a .txt file where I
>specify the name e.g
>
>mydata<-read.table("a_date.txt", header=TRUE)
>
>The script eventually produces a plot, e.g:
>
>pdf(file="myfilename.txt")
>plot(etc)
>dev.off
>
>What I want to do is run this script on several input files in my
>directory, without having to manually change the input file name each
>time, and produce the output plot pdf with the input file name as the
>output file name. It would also be handy if my plot title is also the
>input file name.
>
>I'm relatively new to R so i'm not sure how to approach this. I
>presume it's some sort of loop function, but i've never implemented
>one of these before - any advice would be greatly appreciated!
>
>Thanks in advance!
>Thomas
>-- 
>Thomas Barningham
>Centre for Ocean and Atmospheric Sciences
>School of Environmental Sciences
>University of East Anglia
>Norwich Research Park
>Norwich
>NR4 7TJ
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Fri Dec  5 20:24:07 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Fri, 5 Dec 2014 14:24:07 -0500
Subject: [R] recoding genetic information using gsub
Message-ID: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>

I have genetic information for several thousand individuals:

A/T
T/G
C/G  etc

For some individuals there are some genotypes that are like this:  A/,
C/, T/, G/ or even just / which represents missing and I want to
change these to the following:

A/ A/.
C/ C/.
G/ G/.
T/ T/.
/ ./.
/A ./A
/C ./C
/G ./G
/T ./T

I've tried to use gsub with a command like the following:

gsub("A/","[A/.]", GT[,6])

but if genotypes arent like the above, the command will change it to
look something like:

A/.T
T/.G
C/.G

Is there anyway to be more specific in gsub?

Thanks!


From sarah.goslee at gmail.com  Fri Dec  5 20:30:49 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 5 Dec 2014 14:30:49 -0500
Subject: [R] recoding genetic information using gsub
In-Reply-To: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>
References: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>
Message-ID: <CAM_vjumU_ZjoO83EK2Z8ah5j0F9m+g=HOA3GEP5zf1WJ8a5iqA@mail.gmail.com>

Hi,

Briefly, you need to read about regular expressions. It's possible to
be incredibly specific, and even to do what you want with a single
line of code.

It's hard to be certain of exactly what you need, though, without a
reproducible example. See inline for one possibility.

On Fri, Dec 5, 2014 at 2:24 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> I have genetic information for several thousand individuals:
>
> A/T
> T/G
> C/G  etc
>
> For some individuals there are some genotypes that are like this:  A/,
> C/, T/, G/ or even just / which represents missing and I want to
> change these to the following:
>
> A/ A/.
> C/ C/.
> G/ G/.
> T/ T/.
> / ./.
> /A ./A
> /C ./C
> /G ./G
> /T ./T
>
> I've tried to use gsub with a command like the following:
>
> gsub("A/","[A/.]", GT[,6])

I don't understand why you put square brackets in, and you probably
want the end marker to distinguish
A/
from
A/A

gsub("A/$","A/.", GT[,6])


> but if genotypes arent like the above, the command will change it to
> look something like:
>
> A/.T
> T/.G
> C/.G
>
> Is there anyway to be more specific in gsub?


Sarah

-- 
Sarah Goslee
http://www.functionaldiversity.org


From mtmorgan at fredhutch.org  Fri Dec  5 21:02:35 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Fri, 05 Dec 2014 12:02:35 -0800
Subject: [R] recoding genetic information using gsub
In-Reply-To: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>
References: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>
Message-ID: <54820F5B.3010801@fredhutch.org>

On 12/5/2014 11:24 AM, Kate Ignatius wrote:
> I have genetic information for several thousand individuals:
>
> A/T
> T/G
> C/G  etc
>
> For some individuals there are some genotypes that are like this:  A/,
> C/, T/, G/ or even just / which represents missing and I want to
> change these to the following:
>
> A/ A/.
> C/ C/.
> G/ G/.
> T/ T/.
> / ./.
> /A ./A
> /C ./C
> /G ./G
> /T ./T
>
> I've tried to use gsub with a command like the following:
>
> gsub("A/","[A/.]", GT[,6])

Hi Kate -- a different approach is to create a 'map' (named character vector) 
describing what you want in terms of what you have; the number of possible 
genotypes is not large.

http://stackoverflow.com/questions/15912210/replace-a-list-of-values-by-another-in-r/15912309#15912309

Martin

>
> but if genotypes arent like the above, the command will change it to
> look something like:
>
> A/.T
> T/.G
> C/.G
>
> Is there anyway to be more specific in gsub?
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Dr. Martin Morgan, PhD
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109


From wdunlap at tibco.com  Fri Dec  5 21:10:29 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Dec 2014 12:10:29 -0800
Subject: [R] recoding genetic information using gsub
In-Reply-To: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>
References: <CAE6QMsaWJgNTKhr3X5iva6NO3WHLMCzoRqYUimWHCwJun5tuHg@mail.gmail.com>
Message-ID: <CAF8bMcb6n9W9k0AtyPhsejuUgi6LKXPBU2JXgv1VgFaE3SbzbA@mail.gmail.com>

Does the following do what you want?
> raw <- c("A/B", " /B", "A/", "/ ")
> tmp <- sub("^ */", "./", raw)
> cleaned <- sub("/ *$", "/.", tmp)
> cleaned
[1] "A/B" "./B" "A/." "./."

(The " *" is to allow optional spaces before or after the slash.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Dec 5, 2014 at 11:24 AM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> I have genetic information for several thousand individuals:
>
> A/T
> T/G
> C/G  etc
>
> For some individuals there are some genotypes that are like this:  A/,
> C/, T/, G/ or even just / which represents missing and I want to
> change these to the following:
>
> A/ A/.
> C/ C/.
> G/ G/.
> T/ T/.
> / ./.
> /A ./A
> /C ./C
> /G ./G
> /T ./T
>
> I've tried to use gsub with a command like the following:
>
> gsub("A/","[A/.]", GT[,6])
>
> but if genotypes arent like the above, the command will change it to
> look something like:
>
> A/.T
> T/.G
> C/.G
>
> Is there anyway to be more specific in gsub?
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maitra.mbox.ignored at inbox.com  Fri Dec  5 21:11:58 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 5 Dec 2014 14:11:58 -0600
Subject: [R] Deducer future?
In-Reply-To: <5481F149.20607@gmail.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
	<5481F149.20607@gmail.com>
Message-ID: <20141205141158.9153a890bb600d505796c315@inbox.com>

On Fri, 5 Dec 2014 12:54:17 -0500 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 05/12/2014 12:34 PM, Ranjan Maitra wrote:
> > Hi,
> >
> > I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost.
> >
> > I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.
> >
> > I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.
> >
> > Many thanks and best wishes,
> > Ranjan
> >
> >
> A question like this could only be answered by the maintainer of the 
> package.  Have you tried writing there?  (You might already know the 
> answer if you've reported the "issues" to them.)

Thanks very much! I agree. However, I can not tell who the developer/maintainer is, from the www.deducer.org webpage. There are several questions, etc on the associated Google help group (on several topics) but no answers. So I have been "fearing the worst," which is a pity: much as I detest this GUI stuff for everything for my personal use, this was a good (and better) option for these specific classes than JMP. Besides, at least 20% of the students would figure out from the GUI that it was far easier and more efficient to simply write out the commands than to submit using the GUI interface, and the GUI would inform them what they could write (and modify). I came to Deducer after looking at a lot of other related software. 

Well, I guess I was hoping that the developer was lurking here and he or somebody else who knew could answer.

Thanks again for responding!

Best wishes,
Ranjan

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From sarah.goslee at gmail.com  Fri Dec  5 21:23:17 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 5 Dec 2014 15:23:17 -0500
Subject: [R] Deducer future?
In-Reply-To: <20141205141158.9153a890bb600d505796c315@inbox.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
	<5481F149.20607@gmail.com>
	<20141205141158.9153a890bb600d505796c315@inbox.com>
Message-ID: <CAM_vjums+SfTUT5+shZ2-DPnBzGbKKdoPtsCFnz+v-x_0ThkKA@mail.gmail.com>

To find the maintainer, see
?maintainer

The maintainer is also listed on the CRAN page.
http://cran.r-project.org/web/packages/Deducer/index.html


Sarah

On Fri, Dec 5, 2014 at 3:11 PM, Ranjan Maitra
<maitra.mbox.ignored at inbox.com> wrote:
> On Fri, 5 Dec 2014 12:54:17 -0500 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 05/12/2014 12:34 PM, Ranjan Maitra wrote:
>> > Hi,
>> >
>> > I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost.
>> >
>> > I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.
>> >
>> > I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.
>> >
>> > Many thanks and best wishes,
>> > Ranjan
>> >
>> >
>> A question like this could only be answered by the maintainer of the
>> package.  Have you tried writing there?  (You might already know the
>> answer if you've reported the "issues" to them.)
>
> Thanks very much! I agree. However, I can not tell who the developer/maintainer is, from the www.deducer.org webpage. There are several questions, etc on the associated Google help group (on several topics) but no answers. So I have been "fearing the worst," which is a pity: much as I detest this GUI stuff for everything for my personal use, this was a good (and better) option for these specific classes than JMP. Besides, at least 20% of the students would figure out from the GUI that it was far easier and more efficient to simply write out the commands than to submit using the GUI interface, and the GUI would inform them what they could write (and modify). I came to Deducer after looking at a lot of other related software.
>
> Well, I guess I was hoping that the developer was lurking here and he or somebody else who knew could answer.
>
> Thanks again for responding!
>
> Best wishes,
> Ranjan
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Fri Dec  5 21:27:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 5 Dec 2014 15:27:10 -0500
Subject: [R] Deducer future?
In-Reply-To: <20141205141158.9153a890bb600d505796c315@inbox.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>	<5481F149.20607@gmail.com>
	<20141205141158.9153a890bb600d505796c315@inbox.com>
Message-ID: <5482151E.5040302@gmail.com>

On 05/12/2014 3:11 PM, Ranjan Maitra wrote:
> On Fri, 5 Dec 2014 12:54:17 -0500 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> > On 05/12/2014 12:34 PM, Ranjan Maitra wrote:
> > > Hi,
> > >
> > > I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost.
> > >
> > > I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.
> > >
> > > I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.
> > >
> > > Many thanks and best wishes,
> > > Ranjan
> > >
> > >
> > A question like this could only be answered by the maintainer of the
> > package.  Have you tried writing there?  (You might already know the
> > answer if you've reported the "issues" to them.)
>
> Thanks very much! I agree. However, I can not tell who the developer/maintainer is, from the www.deducer.org webpage. There are several questions, etc on the associated Google help group (on several topics) but no answers. So I have been "fearing the worst," which is a pity: much as I detest this GUI stuff for everything for my personal use, this was a good (and better) option for these specific classes than JMP. Besides, at least 20% of the students would figure out from the GUI that it was far easier and more efficient to simply write out the commands than to submit using the GUI interface, and the GUI would inform them what they could write (and modify). I came to Deducer after looking at a lot of other related software.
>
> Well, I guess I was hoping that the developer was lurking here and he or somebody else who knew could answer.

Since there is an associated R package, you can find the maintainer's 
email using

maintainer("Deducer")

in R.  That gives me

"Ian Fellows <ian at fellstat.com>"


Duncan Murdoch


From maitra.mbox.ignored at inbox.com  Fri Dec  5 21:39:44 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 5 Dec 2014 14:39:44 -0600
Subject: [R] Deducer future?
In-Reply-To: <5482151E.5040302@gmail.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
	<5481F149.20607@gmail.com>
	<20141205141158.9153a890bb600d505796c315@inbox.com>
	<5482151E.5040302@gmail.com>
Message-ID: <20141205143944.7efb92f591887058632b4dac@inbox.com>


On Fri, 5 Dec 2014 15:27:10 -0500 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 05/12/2014 3:11 PM, Ranjan Maitra wrote:
> > On Fri, 5 Dec 2014 12:54:17 -0500 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > > On 05/12/2014 12:34 PM, Ranjan Maitra wrote:
> > > > Hi,
> > > >
> > > > I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost.
> > > >
> > > > I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.
> > > >
> > > > I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.
> > > >
> > > > Many thanks and best wishes,
> > > > Ranjan
> > > >
> > > >
> > > A question like this could only be answered by the maintainer of the
> > > package.  Have you tried writing there?  (You might already know the
> > > answer if you've reported the "issues" to them.)
> >
> > Thanks very much! I agree. However, I can not tell who the developer/maintainer is, from the www.deducer.org webpage. There are several questions, etc on the associated Google help group (on several topics) but no answers. So I have been "fearing the worst," which is a pity: much as I detest this GUI stuff for everything for my personal use, this was a good (and better) option for these specific classes than JMP. Besides, at least 20% of the students would figure out from the GUI that it was far easier and more efficient to simply write out the commands than to submit using the GUI interface, and the GUI would inform them what they could write (and modify). I came to Deducer after looking at a lot of other related software.
> >
> > Well, I guess I was hoping that the developer was lurking here and he or somebody else who knew could answer.
> 
> Since there is an associated R package, you can find the maintainer's 
> email using
> 
> maintainer("Deducer")
> 
> in R.  That gives me
> 
> "Ian Fellows <ian at fellstat.com>"
> 

Thanks to both you and Sarah Goslee!! I completely forgot about this aspect of R packages. This was so dumb of me! I was looking all over the web trying to figure this out and forgot about the most basic feature.

Thanks again!

Best wishes,
Ranjan

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From dwinsemius at comcast.net  Fri Dec  5 23:56:20 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Dec 2014 14:56:20 -0800
Subject: [R] Deducer future?
In-Reply-To: <20141205141158.9153a890bb600d505796c315@inbox.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
	<5481F149.20607@gmail.com>
	<20141205141158.9153a890bb600d505796c315@inbox.com>
Message-ID: <5546E379-EBD4-4109-A03C-4FE9D0EEAA4E@comcast.net>


On Dec 5, 2014, at 12:11 PM, Ranjan Maitra wrote:

> On Fri, 5 Dec 2014 12:54:17 -0500 Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 05/12/2014 12:34 PM, Ranjan Maitra wrote:
>>> Hi,
>>> 
>>> I have been using Deducer for the past year for my very basic 100-level introductory statistics classes for students from other disciplines. I really have liked using it for this specific purpose (takes me out of JMP!). However, over the past few months, issues have started cropping up with (some, not all) Windows 7 machines (which I am personally not very familiar with). Most of these problems are cleared when I manually and individually install all the required packages one by one. However, this is tedious to do for me, an instructor, for each and every student, and also means that the main appeal of Deducer: one-click install and GUI is lost.
>>> 
>>> I have also noticed that Deducer's webpage mentions that it works on R 2.10.0 or greater. However, it is not clear if this project is maintained or not, so therefore, before I invest more time in using this for teaching, I was wondering if the software is being maintained and developed.
>>> 
>>> I would like to say that Deducer works as advertised and no hiccups on Fedora 20 Linux for R 3.1.2.
>>> 
>>> Many thanks and best wishes,
>>> Ranjan
>>> 
>>> 
>> A question like this could only be answered by the maintainer of the 
>> package.  Have you tried writing there?  (You might already know the 
>> answer if you've reported the "issues" to them.)
> 
> Thanks very much! I agree. However, I can not tell who the developer/maintainer is, from the www.deducer.org webpage. There are several questions, etc on the associated Google help group (on several topics) but no answers. So I have been "fearing the worst," which is a pity: much as I detest this GUI stuff for everything for my personal use, this was a good (and better) option for these specific classes than JMP. Besides, at least 20% of the students would figure out from the GUI that it was far easier and more efficient to simply write out the commands than to submit using the GUI interface, and the GUI would inform them what they could write (and modify). I came to Deducer after looking at a lot of other related software. 

You appear unfamiliar with the maintainer function:

> maintainer("Deducer")
[1] "Ian Fellows <ian at fellstat.com>"
> 
> 
> Well, I guess I was hoping that the developer was lurking here and he or somebody else who knew could answer.
> 
> Thanks again for responding!
> 
> Best wishes,
> Ranjan
> 
> __ 

David Winsemius
Alameda, CA, USA


From charles.santana at gmail.com  Sat Dec  6 00:20:50 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Sat, 6 Dec 2014 00:20:50 +0100
Subject: [R] Profiling a C/C++ library from R
In-Reply-To: <547E4539.6040303@gmail.com>
References: <CAH-FEnhzH-n9Sx+DnF7fX0ehEUu3wPDqxDJgfOCu6f9bs+sSyA@mail.gmail.com>
	<547E4539.6040303@gmail.com>
Message-ID: <CAH-FEniSHJKK+X_1bSJTdvpmU+nuyfwMrMvQ4UvQU_PJ1T6ZCg@mail.gmail.com>

Thank you very much for the tips, Martin and Duncan! Rprof and operf are
helping me a lot!!

Also, I am now in R-dev maillist and I see there seems to be more
appropriate to this kind of question.

Best,

Charles

On Wed, Dec 3, 2014 at 12:03 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 02/12/2014, 4:43 PM, Charles Novaes de Santana wrote:
> > Dear all,
> >
> > I am running a c++ library (a .so file) from a R code. I am using the
> > function dyn.load("lib.so") to load the library. Do you know a way to
> > profile my C library from R? Or should I compile my C library as an
> > executable and profile it using the typical C-profilers?
> >
> > Thanks in advance for any help!
>
> If you want line-level profiling of your C++ code, you'll certainly need
> to use something that's not built in to R.  You can probably do it
> without recompiling your C++ code, just by profiling the R process.  But
> the details certainly depend on the profiler you choose to use.
>
> If you just want to know how much time is being spent in each C++
> function called from R, Rprof() should be able to tell you.  (It might
> give misleading information if your C++ code takes too long to execute,
> and some timer ticks get lost; I'm not sure if the underlying code takes
> account of that.)
>
> Duncan Murdoch
>



-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From maitra.mbox.ignored at inbox.com  Sat Dec  6 01:15:30 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Fri, 5 Dec 2014 18:15:30 -0600
Subject: [R] Deducer future?
In-Reply-To: <5546E379-EBD4-4109-A03C-4FE9D0EEAA4E@comcast.net>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
	<5481F149.20607@gmail.com>
	<20141205141158.9153a890bb600d505796c315@inbox.com>
	<5546E379-EBD4-4109-A03C-4FE9D0EEAA4E@comcast.net>
Message-ID: <20141205181530.6861cc12d402699d56eea693@inbox.com>

Btw, I did hear back immediately from Ian Fellows and it is being maintained as his time permits, though he himself is not a windows user, and possibly therefore the issues. I thanked him for his e-mail and was relieved to note that this is not going away yet.

Thanks again to Duncan, Sarah and now David for pointing me to the maintainer() function.

Best wishes,
Ranjan

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From rhelpmaillist at 163.com  Fri Dec  5 22:12:36 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 6 Dec 2014 05:12:36 +0800 (CST)
Subject: [R]  How to build a vignette?
Message-ID: <45367f51.fa1d.14a1c4c1945.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? I know we can build a vignette from .Rmd file, but ?i find a lot of r packages have R topic documented words then followed an index, then functions'document which are already?described in .RD files. I mean that , i don't want to write a vignette , but rather using function documents from .Rd files, how can i do?
?TKS.
?




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From dwinsemius at comcast.net  Sat Dec  6 02:35:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Dec 2014 17:35:49 -0800
Subject: [R] Deducer future?
In-Reply-To: <20141205181530.6861cc12d402699d56eea693@inbox.com>
References: <20141205113437.ecf071966065322598fae317@inbox.com>
	<5481F149.20607@gmail.com>
	<20141205141158.9153a890bb600d505796c315@inbox.com>
	<5546E379-EBD4-4109-A03C-4FE9D0EEAA4E@comcast.net>
	<20141205181530.6861cc12d402699d56eea693@inbox.com>
Message-ID: <F94B17E9-E084-459D-BE6E-7C5567A14C47@comcast.net>


On Dec 5, 2014, at 4:15 PM, Ranjan Maitra wrote:

> Btw, I did hear back immediately from Ian Fellows and it is being maintained as his time permits, though he himself is not a windows user, and possibly therefore the issues. I thanked him for his e-mail and was relieved to note that this is not going away yet.
> 
> Thanks again to Duncan, Sarah and now David for pointing me to the maintainer() function.
> 

You might also try: help(package=Deducer) which brings up the help index page and always has a link near the top to the DESCRIPTION file.


> Best wishes,
> Ranjan
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Sat Dec  6 04:12:32 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 05 Dec 2014 19:12:32 -0800
Subject: [R] How to build a vignette?
In-Reply-To: <45367f51.fa1d.14a1c4c1945.Coremail.rhelpmaillist@163.com>
References: <45367f51.fa1d.14a1c4c1945.Coremail.rhelpmaillist@163.com>
Message-ID: <619548B7-25F1-479A-B41F-4A38938A321E@dcn.davis.CA.us>

You are not talking about a vignette. That is the pdf version of the help files, automatically generated from the same Rd files as the HTML versions.

If you are not going to write the Rd file directly, you probably want roxygen. Markdown is weak on links and template structures, and Rd files use a lot of them. RStudio makes using roxygen to generate Rd files easy, though raw Rd files aren't that bad. Keep in mind that you will probably end up learning a bit of Rd syntax even if you preprocess with roxygen, so don't be shy about diving in to section 2 of the "Writing R Extensions" documentation.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 5, 2014 1:12:36 PM PST, PO SU <rhelpmaillist at 163.com> wrote:
>
>Dear expeRts,
>? I know we can build a vignette from .Rmd file, but ?i find a lot of r
>packages have R topic documented words then followed an index, then
>functions'document which are already?described in .RD files. I mean
>that , i don't want to write a vignette , but rather using function
>documents from .Rd files, how can i do?
>?TKS.
>?
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Dec  6 07:12:45 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 05 Dec 2014 22:12:45 -0800
Subject: [R] How to build a vignette?
In-Reply-To: <3aec2c75.c7fe.14a1e2396c7.Coremail.rhelpmaillist@163.com>
References: <45367f51.fa1d.14a1c4c1945.Coremail.rhelpmaillist@163.com>
	<619548B7-25F1-479A-B41F-4A38938A321E@dcn.davis.CA.us>
	<3aec2c75.c7fe.14a1e2396c7.Coremail.rhelpmaillist@163.com>
Message-ID: <0131272A-A7BE-4E81-8596-F0DB98D75ABD@dcn.davis.CA.us>

If you run R CMD check on your package successfully, then that file will be generated as needed automatically. If you install your package for you're own use before sending it to CRAN then you can see the file by following the link on the help index html page for your package.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 5, 2014 9:47:36 PM PST, PO SU <rhelpmaillist at 163.com> wrote:
>
>
>Yeah, i can write some roxygen2 which transformed to .RD files.
>?The pdf of a ?package in the cran is not a vignette? ?That's to say
>some packages have not vignettes?
>?And the pdf version is generated by me or cran ? If by me , how can i
>generate it from my .RD files.
>i am writing ?a package, source R codes are already written but i don't
>very clear about how to subbmmit to cran.
>?
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>
>
>
>At 2014-12-06 11:12:32, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
>wrote:
>>You are not talking about a vignette. That is the pdf version of the
>help files, automatically generated from the same Rd files as the HTML
>versions.
>>
>>If you are not going to write the Rd file directly, you probably want
>roxygen. Markdown is weak on links and template structures, and Rd
>files use a lot of them. RStudio makes using roxygen to generate Rd
>files easy, though raw Rd files aren't that bad. Keep in mind that you
>will probably end up learning a bit of Rd syntax even if you preprocess
>with roxygen, so don't be shy about diving in to section 2 of the
>"Writing R Extensions" documentation.
>>---------------------------------------------------------------------------
>>Jeff Newmiller                        The     .....       .....  Go
>Live...
>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>---------------------------------------------------------------------------
>
>>Sent from my phone. Please excuse my brevity.
>>
>>On December 5, 2014 1:12:36 PM PST, PO SU <rhelpmaillist at 163.com>
>wrote:
>>>
>>>Dear expeRts,
>>>? I know we can build a vignette from .Rmd file, but ?i find a lot of
>r
>>>packages have R topic documented words then followed an index, then
>>>functions'document which are already?described in .RD files. I mean
>>>that , i don't want to write a vignette , but rather using function
>>>documents from .Rd files, how can i do?
>>>?TKS.
>>>?
>>>
>>>
>>>
>>>
>>>--
>>>
>>>PO SU
>>>mail: desolator88 at 163.com 
>>>Majored in Statistics from SJTU
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From rhelpmaillist at 163.com  Sat Dec  6 06:47:36 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 6 Dec 2014 13:47:36 +0800 (CST)
Subject: [R] How to build a vignette?
In-Reply-To: <619548B7-25F1-479A-B41F-4A38938A321E@dcn.davis.CA.us>
References: <45367f51.fa1d.14a1c4c1945.Coremail.rhelpmaillist@163.com>
	<619548B7-25F1-479A-B41F-4A38938A321E@dcn.davis.CA.us>
Message-ID: <3aec2c75.c7fe.14a1e2396c7.Coremail.rhelpmaillist@163.com>



Yeah, i can write some roxygen2 which transformed to .RD files.
?The pdf of a ?package in the cran is not a vignette? ?That's to say some packages have not vignettes?
?And the pdf version is generated by me or cran ? If by me , how can i generate it from my .RD files.
i am writing ?a package, source R codes are already written but i don't very clear about how to subbmmit to cran.
?



--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-12-06 11:12:32, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us> wrote:
>You are not talking about a vignette. That is the pdf version of the help files, automatically generated from the same Rd files as the HTML versions.
>
>If you are not going to write the Rd file directly, you probably want roxygen. Markdown is weak on links and template structures, and Rd files use a lot of them. RStudio makes using roxygen to generate Rd files easy, though raw Rd files aren't that bad. Keep in mind that you will probably end up learning a bit of Rd syntax even if you preprocess with roxygen, so don't be shy about diving in to section 2 of the "Writing R Extensions" documentation.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>--------------------------------------------------------------------------- 
>Sent from my phone. Please excuse my brevity.
>
>On December 5, 2014 1:12:36 PM PST, PO SU <rhelpmaillist at 163.com> wrote:
>>
>>Dear expeRts,
>>? I know we can build a vignette from .Rmd file, but ?i find a lot of r
>>packages have R topic documented words then followed an index, then
>>functions'document which are already?described in .RD files. I mean
>>that , i don't want to write a vignette , but rather using function
>>documents from .Rd files, how can i do?
>>?TKS.
>>?
>>
>>
>>
>>
>>--
>>
>>PO SU
>>mail: desolator88 at 163.com 
>>Majored in Statistics from SJTU
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>

From rhelpmaillist at 163.com  Sat Dec  6 08:25:21 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 6 Dec 2014 15:25:21 +0800 (CST)
Subject: [R] How to build a vignette?
In-Reply-To: <0131272A-A7BE-4E81-8596-F0DB98D75ABD@dcn.davis.CA.us>
References: <45367f51.fa1d.14a1c4c1945.Coremail.rhelpmaillist@163.com>
	<619548B7-25F1-479A-B41F-4A38938A321E@dcn.davis.CA.us>
	<3aec2c75.c7fe.14a1e2396c7.Coremail.rhelpmaillist@163.com>
	<0131272A-A7BE-4E81-8596-F0DB98D75ABD@dcn.davis.CA.us>
Message-ID: <5a3b3c0d.1a2d8.14a1e7d1482.Coremail.rhelpmaillist@163.com>


OK, I got it , you helped me ?a lot , tks very much. :)




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-12-06 14:12:45, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us> wrote:
>If you run R CMD check on your package successfully, then that file will be generated as needed automatically. If you install your package for you're own use before sending it to CRAN then you can see the file by following the link on the help index html page for your package.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>--------------------------------------------------------------------------- 
>Sent from my phone. Please excuse my brevity.
>
>On December 5, 2014 9:47:36 PM PST, PO SU <rhelpmaillist at 163.com> wrote:
>>
>>
>>Yeah, i can write some roxygen2 which transformed to .RD files.
>>?The pdf of a ?package in the cran is not a vignette? ?That's to say
>>some packages have not vignettes?
>>?And the pdf version is generated by me or cran ? If by me , how can i
>>generate it from my .RD files.
>>i am writing ?a package, source R codes are already written but i don't
>>very clear about how to subbmmit to cran.
>>?
>>
>>
>>
>>--
>>
>>PO SU
>>mail: desolator88 at 163.com 
>>Majored in Statistics from SJTU
>>
>>
>>
>>At 2014-12-06 11:12:32, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
>>wrote:
>>>You are not talking about a vignette. That is the pdf version of the
>>help files, automatically generated from the same Rd files as the HTML
>>versions.
>>>
>>>If you are not going to write the Rd file directly, you probably want
>>roxygen. Markdown is weak on links and template structures, and Rd
>>files use a lot of them. RStudio makes using roxygen to generate Rd
>>files easy, though raw Rd files aren't that bad. Keep in mind that you
>>will probably end up learning a bit of Rd syntax even if you preprocess
>>with roxygen, so don't be shy about diving in to section 2 of the
>>"Writing R Extensions" documentation.
>>>---------------------------------------------------------------------------
>>>Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>>                                      Live:   OO#.. Dead: OO#.. 
>>Playing
>>>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>/Software/Embedded Controllers)               .OO#.       .OO#. 
>>rocks...1k
>>>---------------------------------------------------------------------------
>>
>>>Sent from my phone. Please excuse my brevity.
>>>
>>>On December 5, 2014 1:12:36 PM PST, PO SU <rhelpmaillist at 163.com>
>>wrote:
>>>>
>>>>Dear expeRts,
>>>>? I know we can build a vignette from .Rmd file, but ?i find a lot of
>>r
>>>>packages have R topic documented words then followed an index, then
>>>>functions'document which are already?described in .RD files. I mean
>>>>that , i don't want to write a vignette , but rather using function
>>>>documents from .Rd files, how can i do?
>>>>?TKS.
>>>>?
>>>>
>>>>
>>>>
>>>>
>>>>--
>>>>
>>>>PO SU
>>>>mail: desolator88 at 163.com 
>>>>Majored in Statistics from SJTU
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>

From pdalgd at gmail.com  Sat Dec  6 17:48:38 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 6 Dec 2014 17:48:38 +0100
Subject: [R] Difference in cummulative variance depending on print
	command
In-Reply-To: <5481A4DF.4060908@gmx.de>
References: <5481A4DF.4060908@gmx.de>
Message-ID: <17781317-BE9B-4FB4-AB6A-8F65C9B5F542@gmail.com>

Firstly, there is no fa() function in base R. There is one in package psych(), which has a maintainer, etc.

I guess that it is because fa() does a non-orthogonal factor rotation and its print method knows about it, whereas the default print method for loadings assumes that rotations are orthogonal.

- Peter D.

> On 05 Dec 2014, at 13:28 , Rena B?sch <rena.buesch at gmx.de> wrote:
> 
> Hello,
> I am trying a factor analysis via R.
> When running the pricipal axis analysis I do get different tables depending
> on the print command.
> This is my factor analysis:
> fa.pa_cor_3_2<- fa(ItemsCor_4, nfactors=3, fm="pa",rotate="oblimin")
> 
> To get the h2 I did the following print command:
> print (fa.pa_cor_3_2, digits=2, cut=.3, sort=T)
> To just get the loadings I did the following print command:
> print (fa.pa_cor_3_2$loadings, digits=2, cutoff=.3, sort=T)
> 
> The result of the first print is the following Eigenvalue-cumulative
> variance table:
>                    PA1   PA2  PA3
> SS loadings    20.59 18.16 5.03
> Proportion Var  0.28  0.25 0.07
> Cumulative Var  0.28  0.52 0.59
> 
> With the second print command I get a different table:
>                    PA1   PA2  PA3
> SS loadings    17.63 15.12 3.14
> Proportion Var  0.24  0.20 0.04
> Cumulative Var  0.24  0.44 0.49
> 
> The loadings are the same for both commands. There is just this slight
> difference in the cumulative Var.
> 
> Does anyone have an idea of a cause for the difference? What can I report?
> Did I post enough information to fully understand my problem?
> Thanks in Advance
> Rena
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Sat Dec  6 09:24:03 2014
From: smartpink111 at yahoo.com (arun)
Date: Sat, 6 Dec 2014 08:24:03 +0000 (UTC)
Subject: [R] Scatter plot for repeated measures
In-Reply-To: <10667078.5764455.1417819525375.JavaMail.yahoo@jws10606.mail.bf1.yahoo.com>
References: <10667078.5764455.1417819525375.JavaMail.yahoo@jws10606.mail.bf1.yahoo.com>
Message-ID: <1830591256.5902607.1417854243262.JavaMail.yahoo@jws106138.mail.bf1.yahoo.com>



Not sure whether it is a scatterplot or just a plot with 3 lines.  If it is the latter,

library(reshape2)

matplot(acast(my.df, TIME~ID, value.var='X'), type='l', col=1:3, ylab='X', xlab='TIME')
legend('bottomright', inset=.05, legend=LETTERS[1:3], pch=1, col=1:3)
A.K.

On Friday, December 5, 2014 5:45 PM, farnoosh sheikhi <farnoosh_81 at yahoo.com> wrote:



Hi Arun,

I hope you are doing well.
I have a data set as follow:
my.df <- data.frame(ID=rep(c("A","B","C"), 5), TIME=rep(1:5, each=3), X=1:5)

I would like to get a scatterplot where x axis is Time (1,2,3,4,5) and y axis is X, but I want to have three lines separately for each ID.
 I basically want to tack each ID over time. Is this possible?


Thanks a lot and Happy Holidays to you!


From solmaz.taheri.1990 at gmail.com  Sat Dec  6 12:12:33 2014
From: solmaz.taheri.1990 at gmail.com (solmaz taheri)
Date: Sat, 6 Dec 2014 14:42:33 +0330
Subject: [R] (no subject)
Message-ID: <CADtnbkuJR3pw+cU7OK6Fe-qgYFJB1Zctp0JCYfJOkFfazTzSRg@mail.gmail.com>

dear
I am interested about"A semiparametric recurrent events model with
time-varying coefficients*"*

>  I want to analyze my data with related R program but i could not get it
from its correspondence.
the similar program in  frailtypack exict but only used  Gamma or Lognormal
frailty whereas in this article used Gaussian frailty .
if it is possible please guide me.

	[[alternative HTML version deleted]]


From nashjc at uottawa.ca  Sat Dec  6 20:00:46 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 06 Dec 2014 14:00:46 -0500
Subject: [R] backslash quirk in paste
Message-ID: <5483525E.9090404@uottawa.ca>

This is NOT critical. It arose due to a fumble fingers when developing
an R example, but slightly intriguing.

How could one build a string from substrings with a single backslash (\)
as separator. Here's the reproducible example:

fname = "John"; lname = "Smith"
paste(fname, lname)
paste(fname, lname, sep=" / ")
# BUT there's a glitch with backslash
paste(fname, lname, sep=" \ ") # because of escaping character
paste(fname, lname, sep=' \ ')
paste(fname, lname, sep=' \\ ') # because of escaping character
bslash <- "\\"
print(bslash)
paste(fname, lname, sep=bslash)

Possibly the answer is that R never allows a single backslash in its
strings, but I can imagine possible cases where I might want to output
such lines, for example, in documenting this.

Best, JN


From btupper at bigelow.org  Sat Dec  6 20:30:24 2014
From: btupper at bigelow.org (Ben Tupper)
Date: Sat, 6 Dec 2014 14:30:24 -0500
Subject: [R] backslash quirk in paste
In-Reply-To: <5483525E.9090404@uottawa.ca>
References: <5483525E.9090404@uottawa.ca>
Message-ID: <83C5C221-5B07-41E0-9574-5A4B292EAA8A@bigelow.org>

Hi,

When you call paste without assigning the value it returns to anything it runs through the print command.  So, while your string may contain escapes, using print will not present escapes as you are expecting them.  In this case you could wrap cat() around your paste command.  

> cat(paste(fname, '\\', lname), "\n")
John \ Smith 

See FAQ 7.37 

http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-does-backslash-behave-strangely-inside-strings_003f

Cheers,
Ben

> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.1.0


On Dec 6, 2014, at 2:00 PM, Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:

> This is NOT critical. It arose due to a fumble fingers when developing
> an R example, but slightly intriguing.
> 
> How could one build a string from substrings with a single backslash (\)
> as separator. Here's the reproducible example:
> 
> fname = "John"; lname = "Smith"
> paste(fname, lname)
> paste(fname, lname, sep=" / ")
> # BUT there's a glitch with backslash
> paste(fname, lname, sep=" \ ") # because of escaping character
> paste(fname, lname, sep=' \ ')
> paste(fname, lname, sep=' \\ ') # because of escaping character
> bslash <- "\\"
> print(bslash)
> paste(fname, lname, sep=bslash)
> 
> Possibly the answer is that R never allows a single backslash in its
> strings, but I can imagine possible cases where I might want to output
> such lines, for example, in documenting this.
> 
> Best, JN
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From nashjc at uottawa.ca  Sat Dec  6 20:33:30 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 06 Dec 2014 14:33:30 -0500
Subject: [R] backslash quirk in paste
In-Reply-To: <83C5C221-5B07-41E0-9574-5A4B292EAA8A@bigelow.org>
References: <5483525E.9090404@uottawa.ca>
	<83C5C221-5B07-41E0-9574-5A4B292EAA8A@bigelow.org>
Message-ID: <54835A0A.10806@uottawa.ca>

Thanks. Now why didn't I think of that? However, it underlines that
there is an implicit call to print(), which processes the string rather
than simply dumping it to the screen. That's something to remember (and
I should have!).

Best, JN


On 14-12-06 02:30 PM, Ben Tupper wrote:
> Hi,
> 
> When you call paste without assigning the value it returns to anything it runs through the print command.  So, while your string may contain escapes, using print will not present escapes as you are expecting them.  In this case you could wrap cat() around your paste command.  
> 
>> cat(paste(fname, '\\', lname), "\n")
> John \ Smith 
> 
> See FAQ 7.37 
> 
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-does-backslash-behave-strangely-inside-strings_003f
> 
> Cheers,
> Ben
> 
>> sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
> 
> 
> On Dec 6, 2014, at 2:00 PM, Prof J C Nash (U30A) <nashjc at uottawa.ca> wrote:
> 
>> This is NOT critical. It arose due to a fumble fingers when developing
>> an R example, but slightly intriguing.
>>
>> How could one build a string from substrings with a single backslash (\)
>> as separator. Here's the reproducible example:
>>
>> fname = "John"; lname = "Smith"
>> paste(fname, lname)
>> paste(fname, lname, sep=" / ")
>> # BUT there's a glitch with backslash
>> paste(fname, lname, sep=" \ ") # because of escaping character
>> paste(fname, lname, sep=' \ ')
>> paste(fname, lname, sep=' \\ ') # because of escaping character
>> bslash <- "\\"
>> print(bslash)
>> paste(fname, lname, sep=bslash)
>>
>> Possibly the answer is that R never allows a single backslash in its
>> strings, but I can imagine possible cases where I might want to output
>> such lines, for example, in documenting this.
>>
>> Best, JN
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
> 
> 
> 
> 
> 
> 
> 
>


From jdnewmil at dcn.davis.CA.us  Sat Dec  6 20:33:38 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 06 Dec 2014 11:33:38 -0800
Subject: [R] backslash quirk in paste
In-Reply-To: <5483525E.9090404@uottawa.ca>
References: <5483525E.9090404@uottawa.ca>
Message-ID: <F523115E-F083-45A9-B70B-BFF13E58568B@dcn.davis.CA.us>

fname = "John"; lname = "Smith"
ans <- paste( fname, " \\ ", lname )
cat( ans)
print( ans )

Note that ans only has one backslash in it, but print gives you a source-suitable string with the escape character.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 6, 2014 11:00:46 AM PST, "Prof J C Nash (U30A)" <nashjc at uottawa.ca> wrote:
>This is NOT critical. It arose due to a fumble fingers when developing
>an R example, but slightly intriguing.
>
>How could one build a string from substrings with a single backslash
>(\)
>as separator. Here's the reproducible example:
>
>fname = "John"; lname = "Smith"
>paste(fname, lname)
>paste(fname, lname, sep=" / ")
># BUT there's a glitch with backslash
>paste(fname, lname, sep=" \ ") # because of escaping character
>paste(fname, lname, sep=' \ ')
>paste(fname, lname, sep=' \\ ') # because of escaping character
>bslash <- "\\"
>print(bslash)
>paste(fname, lname, sep=bslash)
>
>Possibly the answer is that R never allows a single backslash in its
>strings, but I can imagine possible cases where I might want to output
>such lines, for example, in documenting this.
>
>Best, JN
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Dec  6 20:35:12 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 6 Dec 2014 11:35:12 -0800
Subject: [R] backslash quirk in paste
In-Reply-To: <5483525E.9090404@uottawa.ca>
References: <5483525E.9090404@uottawa.ca>
Message-ID: <CAF8bMcZZZRMYQ5xSMQ8AwA9C-1dcm+-5f3UYTU+cRA-1CjjDmQ@mail.gmail.com>

"\\" is stored as a single backslash, just as "\n" is a single newline
character.  It is printed with an extra backslash.

  > nchar("\\")
  [1] 1
  > cat(paste0("\\", "\n"))
  \



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Dec 6, 2014 at 11:00 AM, Prof J C Nash (U30A) <nashjc at uottawa.ca>
wrote:

> This is NOT critical. It arose due to a fumble fingers when developing
> an R example, but slightly intriguing.
>
> How could one build a string from substrings with a single backslash (\)
> as separator. Here's the reproducible example:
>
> fname = "John"; lname = "Smith"
> paste(fname, lname)
> paste(fname, lname, sep=" / ")
> # BUT there's a glitch with backslash
> paste(fname, lname, sep=" \ ") # because of escaping character
> paste(fname, lname, sep=' \ ')
> paste(fname, lname, sep=' \\ ') # because of escaping character
> bslash <- "\\"
> print(bslash)
> paste(fname, lname, sep=bslash)
>
> Possibly the answer is that R never allows a single backslash in its
> strings, but I can imagine possible cases where I might want to output
> such lines, for example, in documenting this.
>
> Best, JN
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From arnaud.duranel.09 at ucl.ac.uk  Sat Dec  6 22:30:58 2014
From: arnaud.duranel.09 at ucl.ac.uk (A Duranel)
Date: Sat, 6 Dec 2014 13:30:58 -0800 (PST)
Subject: [R] vectorization of rolling function
Message-ID: <1417901458880-4700487.post@n4.nabble.com>

Hello
I use R to run a simple model of rainfall interception by vegetation:
rainfall falls on vegetation, some is retained by the vegetation (part of
which can evaporate), the rest falls on the ground (quite crude but very
similar to those used in SWAT or MikeSHE, for the hydrologists among you).
It uses a loop on zoo time-series of rainfall and potential
evapotranspiration. Unfortunately I did not find a way to vectorize it and
it takes ages to run on long datasets. Could anybody help me to make it run
faster?

library(zoo)
set.seed(1)
# artificial potential evapotranspiration time-series
ETmax<-zoo(runif(10, min=1, max=6), c(1:10))
# artificial rainfall time-series
RR<-zoo(runif(10, min=0, max=6), c(1:10))

## create empty time-series to fill
# effective rainfall (i.e. rainfall minus intercepted rainfall)
RReff<-zoo(NA, c(1:10))
# intercepted rainfall
int<-zoo(NA, c(1:10))
# residual potential evapotranspiration (ie ETmax minus evaporation from
interception)
ETres<-zoo(NA, c(1:10))

# define maximum interception storage capacity (maximum volume of rainfall
that can be intercepted per time step, provided the interception store is
empty at start of time-step)
Smax<-3
# volume of water in interception storage at start of computation
storage<-0

for (i in 1:length(ETmax)) {
  # compute interception capacity for time step i (maximum interception
capacity minus any water intercepted but not evaporated during previous
time-step).
  int[i]<-Smax-storage
  # compute intercepted rainfall: equal to rainfall if smaller than
interception capacity, and to interception capacity if larger.
  if(RR[i]<int[i]) int[i]&lt;-RR[i]
  # compute effective rainfall (rainfall minus intercepted rainfall).
  RReff[i]&lt;-RR[i]-int[i]
  # update interception storage: initial interception storage + intercepted
rainfall.
  storage&lt;-storage+coredata(int[i])
  # compute evaporation from interception storage: equal to potential
evapotranspiration if the latter is smaller than interception storage, and
to interception storage if larger. 
  if(storage>coredata(ETmax[i])) evap<-coredata(ETmax[i]) else evap<-storage
  # compute residual potentiel evapotranspiration: potential
evapotranspiration minus evaporation from interception storage.
  ETres[i]<-ETmax[i]-evap
  # update interception storage, to be carried over to next time-step:
interception storage minus evaporation from interception storage.
  storage<-storage-evap
}

Many thanks for your help!

Arnaud
UCL Department of Geography, UK



--
View this message in context: http://r.789695.n4.nabble.com/vectorization-of-rolling-function-tp4700487.html
Sent from the R help mailing list archive at Nabble.com.


From zadig_1 at excite.com  Sat Dec  6 23:53:27 2014
From: zadig_1 at excite.com (ce)
Date: Sat, 06 Dec 2014 17:53:27 -0500
Subject: [R] need help with withRestarts ?
Message-ID: <20141206175327.2777@web001.roc2.bluetie.com>

Dear all,

Let's say I have this script , below. tryCatch  indeed catches the error but exists, I want function to continue and stay in the loop. I found very  examples of withRestarts on internet to figure it out. Could you help me how to do it ?


myfunc <- function()
{
  while(1)
  {
  x <- runif(1)
  if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
  print(a)
  Sys.sleep(1)
  }
}

tryCatch({ myfunc() },
        warning = function(w) { print("warning") },
        error = function(e) { print("error") },
        finally = {  print("end") }
)


From edoardo.prestianni at gmail.com  Sun Dec  7 00:54:00 2014
From: edoardo.prestianni at gmail.com (Edoardo Prestianni)
Date: Sun, 7 Dec 2014 00:54:00 +0100
Subject: [R] bad STATA dataset import, how to change value labels
Message-ID: <CAB-RVxSTY1i1B5vtMenNCEHY1EkA1Q0jEnwsK=zWeVywOgaL=g@mail.gmail.com>

hello,

I have imported a couple of .dta datasets, but a variable, instead of being
labeled as factor (w/ values ranging from a to b) is labeled as integer.

How can I fix this? I am sorry if it is a rookie question but I don't find
the command googling.

Thanks everyone for their help,

-- 
Edoardo Prestianni

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Sun Dec  7 02:22:18 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sat, 06 Dec 2014 17:22:18 -0800
Subject: [R] need help with withRestarts ?
In-Reply-To: <20141206175327.2777@web001.roc2.bluetie.com>
References: <20141206175327.2777@web001.roc2.bluetie.com>
Message-ID: <5483ABCA.1080803@fredhutch.org>

On 12/06/2014 02:53 PM, ce wrote:
> Dear all,
>
> Let's say I have this script , below. tryCatch  indeed catches the error but exists, I want function to continue and stay in the loop. I found very  examples of withRestarts on internet to figure it out. Could you help me how to do it ?
>
>
> myfunc <- function()
> {
>    while(1)
>    {
>    x <- runif(1)
>    if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
>    print(a)
>    Sys.sleep(1)
>    }
> }

Hi --

Modify your function so that the code that you'd like to restart after is 
surrounded with withRestarts(), and with a handler that performs the action 
you'd like, so

myfunc <- function()
{
     while(TRUE)
     {
         x <- runif(1)
         withRestarts({
             if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
             print(a)
         }, restartLoop = function() {
             message("restarting")
             NULL
         })
         Sys.sleep(1)
     }
}

Instead of using tryCatch(), which returns to the top level context to evaluate 
the handlers, use withCallingHandlers(), which retains the calling context. 
Write a handler that invokes the restart

withCallingHandlers({
     myfunc()
}, error = function(e) {
     message("error")
     invokeRestart("restartLoop")
})

It's interesting that tryCatch is usually used with errors (because errors are 
hard to recover from), and withCallingHandlers are usually used with warnings 
(because warnings can usually be recovered from), but tryCatch() and 
withCallingHandlers() can be used with any condition.

Martin

>
> tryCatch({ myfunc() },
>          warning = function(w) { print("warning") },
>          error = function(e) { print("error") },
>          finally = {  print("end") }
> )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From dwinsemius at comcast.net  Sun Dec  7 03:14:34 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 6 Dec 2014 18:14:34 -0800
Subject: [R] bad STATA dataset import, how to change value labels
In-Reply-To: <CAB-RVxSTY1i1B5vtMenNCEHY1EkA1Q0jEnwsK=zWeVywOgaL=g@mail.gmail.com>
References: <CAB-RVxSTY1i1B5vtMenNCEHY1EkA1Q0jEnwsK=zWeVywOgaL=g@mail.gmail.com>
Message-ID: <6A2ACD54-32A2-4EFE-877F-3C9AA8A186E8@comcast.net>


On Dec 6, 2014, at 3:54 PM, Edoardo Prestianni wrote:

> hello,
> 
> I have imported a couple of .dta datasets, but a variable, instead of being
> labeled as factor (w/ values ranging from a to b) is labeled as integer.
> 
> How can I fix this? I am sorry if it is a rookie question but I don't find
> the command googling.

What "command"?

The word "labeled" is not an R term unless on is talking about the labels of factor variables in which case there is no problem. Factors have mode integer.

Post the results of dput(head( dfrm[ , "varname"]))

-- 
David.


> Thanks everyone for their help,
> 
> -- 
> Edoardo Prestianni
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From edoardo.prestianni at gmail.com  Sun Dec  7 03:37:53 2014
From: edoardo.prestianni at gmail.com (Edoardo Prestianni)
Date: Sun, 7 Dec 2014 03:37:53 +0100
Subject: [R] bad STATA dataset import, how to change value labels
In-Reply-To: <6A2ACD54-32A2-4EFE-877F-3C9AA8A186E8@comcast.net>
References: <CAB-RVxSTY1i1B5vtMenNCEHY1EkA1Q0jEnwsK=zWeVywOgaL=g@mail.gmail.com>
	<6A2ACD54-32A2-4EFE-877F-3C9AA8A186E8@comcast.net>
Message-ID: <CAB-RVxTPO9c94zBBm_sQJvQygeiA7irQGtUqy1ERnHvNUdLP3A@mail.gmail.com>

Excuse the inaccuracy, the warning is "value label missing". the same
variable is considered as factor (w/ values ranging from a to b) in one
dataset, as int in another. I want it to be a factor in both.

I think I am missing a package, the output is.

Error in head(dfrm[, "variable"]) : object 'dfrm' not found


2014-12-07 3:14 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Dec 6, 2014, at 3:54 PM, Edoardo Prestianni wrote:
>
> > hello,
> >
> > I have imported a couple of .dta datasets, but a variable, instead of
> being
> > labeled as factor (w/ values ranging from a to b) is labeled as integer.
> >
> > How can I fix this? I am sorry if it is a rookie question but I don't
> find
> > the command googling.
>
> What "command"?
>
> The word "labeled" is not an R term unless on is talking about the labels
> of factor variables in which case there is no problem. Factors have mode
> integer.
>
> Post the results of dput(head( dfrm[ , "varname"]))
>
> --
> David.
>
>
> > Thanks everyone for their help,
> >
> > --
> > Edoardo Prestianni
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Edoardo Prestianni

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Sun Dec  7 04:29:19 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sat, 06 Dec 2014 21:29:19 -0600
Subject: [R] need help with withRestarts ?
In-Reply-To: <5483ABCA.1080803@fredhutch.org>
References: <20141206175327.2777@web001.roc2.bluetie.com>
	<5483ABCA.1080803@fredhutch.org>
Message-ID: <5483C98F.9060702@mail.usask.ca>

I am very happy to see the message replied by Martin Morgan.  He 
provides an example how to use the function 'withRestarts()'.  I 
personally like his approach; however, the function 'tryCatch()' 
evaluates the first argument 'expression'.  That's, this function can be 
placed on anywhere.  It seems to me that your primary goal is to make 
the function 'myfunc()' continue to work.  I hope that I correctly 
understand your question.  Please see the place where I put the function 
'tryCatch()' in your code.

 >
 > myfunc <- function(){
+   while(1){
+   x <- runif(1)
+   tryCatch( {
+ if ( x > 0.3 ) a <- x/2 else a <- x/"b"
+ print(a)
+ },
+     warning=function(w) print("warning"),
+     error=function(e) print("error"),
+     finally=cat("Error is printed if x < 0.3.  x=", x, "\nAnyway, move 
to next!\n") )
+   Sys.sleep(1)
+   }
+ }
 > myfunc()
[1] 0.2630333
Error is printed if x < 0.3.  x= 0.5260666
Anyway, move to next!
[1] "error"
Error is printed if x < 0.3.  x= 0.2929098
Anyway, move to next!
[1] 0.2123464
Error is printed if x < 0.3.  x= 0.4246928
Anyway, move to next!
[1] 0.2535644
Error is printed if x < 0.3.  x= 0.5071288
Anyway, move to next!
[1] "error"
Error is printed if x < 0.3.  x= 0.1941202
Anyway, move to next!
(continue)

I hope this helps, and thank you so much, Martin Morgan, for your good 
lesson.

Chel Hee Lee


On 12/06/2014 07:22 PM, Martin Morgan wrote:
> On 12/06/2014 02:53 PM, ce wrote:
>> Dear all,
>>
>> Let's say I have this script , below. tryCatch  indeed catches the
>> error but exists, I want function to continue and stay in the loop. I
>> found very  examples of withRestarts on internet to figure it out.
>> Could you help me how to do it ?
>>
>>
>> myfunc <- function()
>> {
>>    while(1)
>>    {
>>    x <- runif(1)
>>    if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
>>    print(a)
>>    Sys.sleep(1)
>>    }
>> }
>
> Hi --
>
> Modify your function so that the code that you'd like to restart after
> is surrounded with withRestarts(), and with a handler that performs the
> action you'd like, so
>
> myfunc <- function()
> {
>      while(TRUE)
>      {
>          x <- runif(1)
>          withRestarts({
>              if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
>              print(a)
>          }, restartLoop = function() {
>              message("restarting")
>              NULL
>          })
>          Sys.sleep(1)
>      }
> }
>
> Instead of using tryCatch(), which returns to the top level context to
> evaluate the handlers, use withCallingHandlers(), which retains the
> calling context. Write a handler that invokes the restart
>
> withCallingHandlers({
>      myfunc()
> }, error = function(e) {
>      message("error")
>      invokeRestart("restartLoop")
> })
>
> It's interesting that tryCatch is usually used with errors (because
> errors are hard to recover from), and withCallingHandlers are usually
> used with warnings (because warnings can usually be recovered from), but
> tryCatch() and withCallingHandlers() can be used with any condition.
>
> Martin
>
>>
>> tryCatch({ myfunc() },
>>          warning = function(w) { print("warning") },
>>          error = function(e) { print("error") },
>>          finally = {  print("end") }
>> )
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From chl948 at mail.usask.ca  Sun Dec  7 04:41:17 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sat, 06 Dec 2014 21:41:17 -0600
Subject: [R] Scatter plot for repeated measures
In-Reply-To: <1830591256.5902607.1417854243262.JavaMail.yahoo@jws106138.mail.bf1.yahoo.com>
References: <10667078.5764455.1417819525375.JavaMail.yahoo@jws10606.mail.bf1.yahoo.com>
	<1830591256.5902607.1417854243262.JavaMail.yahoo@jws106138.mail.bf1.yahoo.com>
Message-ID: <5483CC5D.4080904@mail.usask.ca>

It seems that you would like to make a spaghetti plot (in a longitudinal 
data analysis).   You can use the function 'interaction.plot()'.

 > with(my.df, interaction.plot(TIME, ID, X))

I hope this helps.

Chel Hee Lee

On 12/06/2014 02:24 AM, arun wrote:
>
>
> Not sure whether it is a scatterplot or just a plot with 3 lines.  If it is the latter,
>
> library(reshape2)
>
> matplot(acast(my.df, TIME~ID, value.var='X'), type='l', col=1:3, ylab='X', xlab='TIME')
> legend('bottomright', inset=.05, legend=LETTERS[1:3], pch=1, col=1:3)
> A.K.
>
> On Friday, December 5, 2014 5:45 PM, farnoosh sheikhi <farnoosh_81 at yahoo.com> wrote:
>
>
>
> Hi Arun,
>
> I hope you are doing well.
> I have a data set as follow:
> my.df <- data.frame(ID=rep(c("A","B","C"), 5), TIME=rep(1:5, each=3), X=1:5)
>
> I would like to get a scatterplot where x axis is Time (1,2,3,4,5) and y axis is X, but I want to have three lines separately for each ID.
>   I basically want to tack each ID over time. Is this possible?
>
>
> Thanks a lot and Happy Holidays to you!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zadig_1 at excite.com  Sun Dec  7 04:56:09 2014
From: zadig_1 at excite.com (ce)
Date: Sat, 06 Dec 2014 22:56:09 -0500
Subject: [R] need help with withRestarts ?
Message-ID: <20141206225609.21945@web003.roc2.bluetie.com>


Thank you very much Martin and Chel Hee. Indeed both approach works but Martin's approach covers whole function while Chel Hee's concentrates on problem line.  
 Also another thanks to Martin for lesson on error handling which I desperately need. 
ce

 
-----Original Message-----
From: "Chel Hee Lee" [chl948 at mail.usask.ca]
Date: 12/06/2014 10:29 PM
To: "Martin Morgan" <mtmorgan at fredhutch.org>, "ce" <zadig_1 at excite.com>, r-help at r-project.org
Subject: Re: [R] need help with withRestarts ?

I am very happy to see the message replied by Martin Morgan.  He 
provides an example how to use the function 'withRestarts()'.  I 
personally like his approach; however, the function 'tryCatch()' 
evaluates the first argument 'expression'.  That's, this function can be 
placed on anywhere.  It seems to me that your primary goal is to make 
the function 'myfunc()' continue to work.  I hope that I correctly 
understand your question.  Please see the place where I put the function 
'tryCatch()' in your code.

 >
 > myfunc <- function(){
+   while(1){
+   x <- runif(1)
+   tryCatch( {
+ if ( x > 0.3 ) a <- x/2 else a <- x/"b"
+ print(a)
+ },
+     warning=function(w) print("warning"),
+     error=function(e) print("error"),
+     finally=cat("Error is printed if x < 0.3.  x=", x, "\nAnyway, move 
to next!\n") )
+   Sys.sleep(1)
+   }
+ }
 > myfunc()
[1] 0.2630333
Error is printed if x < 0.3.  x= 0.5260666
Anyway, move to next!
[1] "error"
Error is printed if x < 0.3.  x= 0.2929098
Anyway, move to next!
[1] 0.2123464
Error is printed if x < 0.3.  x= 0.4246928
Anyway, move to next!
[1] 0.2535644
Error is printed if x < 0.3.  x= 0.5071288
Anyway, move to next!
[1] "error"
Error is printed if x < 0.3.  x= 0.1941202
Anyway, move to next!
(continue)

I hope this helps, and thank you so much, Martin Morgan, for your good 
lesson.

Chel Hee Lee


On 12/06/2014 07:22 PM, Martin Morgan wrote:
> On 12/06/2014 02:53 PM, ce wrote:
>> Dear all,
>>
>> Let's say I have this script , below. tryCatch  indeed catches the
>> error but exists, I want function to continue and stay in the loop. I
>> found very  examples of withRestarts on internet to figure it out.
>> Could you help me how to do it ?
>>
>>
>> myfunc <- function()
>> {
>>    while(1)
>>    {
>>    x <- runif(1)
>>    if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
>>    print(a)
>>    Sys.sleep(1)
>>    }
>> }
>
> Hi --
>
> Modify your function so that the code that you'd like to restart after
> is surrounded with withRestarts(), and with a handler that performs the
> action you'd like, so
>
> myfunc <- function()
> {
>      while(TRUE)
>      {
>          x <- runif(1)
>          withRestarts({
>              if ( x > 0.3 ) a <-  x/2 else a <- x/"b"
>              print(a)
>          }, restartLoop = function() {
>              message("restarting")
>              NULL
>          })
>          Sys.sleep(1)
>      }
> }
>
> Instead of using tryCatch(), which returns to the top level context to
> evaluate the handlers, use withCallingHandlers(), which retains the
> calling context. Write a handler that invokes the restart
>
> withCallingHandlers({
>      myfunc()
> }, error = function(e) {
>      message("error")
>      invokeRestart("restartLoop")
> })
>
> It's interesting that tryCatch is usually used with errors (because
> errors are hard to recover from), and withCallingHandlers are usually
> used with warnings (because warnings can usually be recovered from), but
> tryCatch() and withCallingHandlers() can be used with any condition.
>
> Martin
>
>>
>> tryCatch({ myfunc() },
>>          warning = function(w) { print("warning") },
>>          error = function(e) { print("error") },
>>          finally = {  print("end") }
>> )
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From emorway at usgs.gov  Sun Dec  7 15:21:48 2014
From: emorway at usgs.gov (Morway, Eric)
Date: Sun, 7 Dec 2014 06:21:48 -0800
Subject: [R] Condensing data.frame
Message-ID: <CAPoqHzriibZVebOe803VnUFCYH3VnLo_FPi5Y1O=MvS3vntU8A@mail.gmail.com>

Using the dataset "dat" (found below), I'm seeking a way to condense down
the data.frame such that each "site" (i.e., "CID_1"..."CID_13") has a
maximum of 7 rows of post-processed data, where the first 6 have the
highest "countPercentage" and the 7th row is the sum of "countPercentage"
from all other rows within that "site", and it is assigned the name
"Other".  So, for the first two sites in the provided data.frame, CID_1 &
CID_10, they would reduce to:

CID_1 Cyanobacteria     37.48
CID_1 Proteobacteria     29.24
CID_1 Bacteroidetes      15.83
CID_1 Verrucomicrobia  6.38
CID_1 Firmicutes          2.30
CID_1 Acidobacteria      2.08
CID_1 Other                6.68
CID_10 Proteobacteria     35.37
CID_10 Bacteroidetes      25.19
CID_10 Cyanobacteria     23.29
CID_10 Verrucomicrobia  6.97
CID_10 Acidobacteria      1.99
CID_10 Actinobacteria     1.64
CID_10 Other                 5.55


dat <- read.table(header=TRUE, sep=",",
text="site,tax_name,count,countTotal,countPercentage
CID_1,Cyanobacteria,46295,123509,37.483098398
CID_1,Proteobacteria,36120,123509,29.244832360
CID_1,Bacteroidetes,19546,123509,15.825567368
CID_1,Verrucomicrobia,7886,123509,6.384959801
CID_1,Firmicutes,2843,123509,2.301856545
CID_1,Acidobacteria,2563,123509,2.075152418
CID_1,Actinobacteria,2069,123509,1.675181566
CID_1,Planctomycetes,1481,123509,1.199102899
CID_1,Chloroflexi,1181,123509,0.956205621
CID_1,Gemmatimonadetes,956,123509,0.774032662
CID_1,Spirochaetes,688,123509,0.557044426
CID_1,Lentisphaerae,526,123509,0.425879895
CID_1,Ignavibacteriae,324,123509,0.262329061
CID_1,Chlorobi,238,123509,0.192698508
CID_1,Nitrospirae,230,123509,0.186221247
CID_1,Nitrospinae,169,123509,0.136832134
CID_1,Elusimicrobia,131,123509,0.106065145
CID_1,Tenericutes,114,123509,0.092300966
CID_1,Fibrobacteres,72,123509,0.058295347
CID_1,Thermotogae,21,123509,0.017002810
CID_1,Fusobacteria,21,123509,0.017002810
CID_1,Armatimonadetes,15,123509,0.012144864
CID_1,Synergistetes,10,123509,0.008096576
CID_1,Deinococcus-Thermus,6,123509,0.004857946
CID_1,Deferribacteres,2,123509,0.001619315
CID_1,Caldiserica,2,123509,0.001619315
CID_10,Proteobacteria,16043,45362,35.366606411
CID_10,Bacteroidetes,11426,45362,25.188483753
CID_10,Cyanobacteria,10567,45362,23.294828270
CID_10,Verrucomicrobia,3162,45362,6.970592126
CID_10,Acidobacteria,902,45362,1.988448481
CID_10,Actinobacteria,746,45362,1.644548300
CID_10,Firmicutes,718,45362,1.582822627
CID_10,Gemmatimonadetes,358,45362,0.789206825
CID_10,Planctomycetes,357,45362,0.787002337
CID_10,Chloroflexi,265,45362,0.584189410
CID_10,Spirochaetes,235,45362,0.518054759
CID_10,Ignavibacteriae,177,45362,0.390194436
CID_10,Lentisphaerae,108,45362,0.238084741
CID_10,Nitrospinae,75,45362,0.165336625
CID_10,Nitrospirae,58,45362,0.127860324
CID_10,Chlorobi,44,45362,0.096997487
CID_10,Elusimicrobia,28,45362,0.061725673
CID_10,Fibrobacteres,26,45362,0.057316697
CID_10,Armatimonadetes,15,45362,0.033067325
CID_10,Deinococcus-Thermus,13,45362,0.028658348
CID_10,Tenericutes,10,45362,0.022044883
CID_10,Synergistetes,9,45362,0.019840395
CID_10,Fusobacteria,9,45362,0.019840395
CID_10,Deferribacteres,6,45362,0.013226930
CID_10,Thermotogae,3,45362,0.006613465
CID_10,Caldiserica,2,45362,0.004408977
CID_11,Proteobacteria,10019,31387,31.920858954
CID_11,Cyanobacteria,8811,31387,28.072131774
CID_11,Bacteroidetes,7930,31387,25.265237200
CID_11,Verrucomicrobia,1750,31387,5.575556759
CID_11,Firmicutes,806,31387,2.567942142
CID_11,Acidobacteria,548,31387,1.745945774
CID_11,Actinobacteria,434,31387,1.382738076
CID_11,Chloroflexi,203,31387,0.646764584
CID_11,Planctomycetes,197,31387,0.627648389
CID_11,Gemmatimonadetes,192,31387,0.611718227
CID_11,Ignavibacteriae,87,31387,0.277184822
CID_11,Spirochaetes,80,31387,0.254882595
CID_11,Tenericutes,71,31387,0.226208303
CID_11,Fusobacteria,67,31387,0.213464173
CID_11,Lentisphaerae,54,31387,0.172045751
CID_11,Chlorobi,40,31387,0.127441297
CID_11,Nitrospinae,33,31387,0.105139070
CID_11,Armatimonadetes,22,31387,0.070092714
CID_11,Fibrobacteres,15,31387,0.047790487
CID_11,Nitrospirae,13,31387,0.041418422
CID_11,Elusimicrobia,13,31387,0.041418422
CID_11,Deinococcus-Thermus,2,31387,0.006372065
CID_12,Cyanobacteria,241,644,37.422360248
CID_12,Bacteroidetes,210,644,32.608695652
CID_12,Proteobacteria,118,644,18.322981366
CID_12,Verrucomicrobia,38,644,5.900621118
CID_12,Acidobacteria,11,644,1.708074534
CID_12,Ignavibacteriae,6,644,0.931677019
CID_12,Lentisphaerae,5,644,0.776397516
CID_12,Firmicutes,5,644,0.776397516
CID_12,Planctomycetes,3,644,0.465838509
CID_12,Fusobacteria,3,644,0.465838509
CID_12,Tenericutes,2,644,0.310559006
CID_12,Actinobacteria,2,644,0.310559006
CID_13,Cyanobacteria,8581,25530,33.611437524
CID_13,Bacteroidetes,6878,25530,26.940853897
CID_13,Proteobacteria,5341,25530,20.920485703
CID_13,Verrucomicrobia,1244,25530,4.872698786
CID_13,Firmicutes,1148,25530,4.496670584
CID_13,Acidobacteria,548,25530,2.146494320
CID_13,Spirochaetes,477,25530,1.868390129
CID_13,Ignavibacteriae,298,25530,1.167254211
CID_13,Actinobacteria,227,25530,0.889150020
CID_13,Planctomycetes,184,25530,0.720720721
CID_13,Chloroflexi,181,25530,0.708969839
CID_13,Gemmatimonadetes,121,25530,0.473952213
CID_13,Lentisphaerae,93,25530,0.364277321
CID_13,Tenericutes,61,25530,0.238934587
CID_13,Fibrobacteres,47,25530,0.184097141
CID_13,Nitrospinae,28,25530,0.109674892
CID_13,Nitrospirae,26,25530,0.101840971
CID_13,Chlorobi,18,25530,0.070505288
CID_13,Elusimicrobia,13,25530,0.050920486
CID_13,Synergistetes,8,25530,0.031335684
CID_13,Fusobacteria,4,25530,0.015667842
CID_13,Deinococcus-Thermus,2,25530,0.007833921
CID_13,Thermotogae,2,25530,0.007833921
CID_2,Cyanobacteria,43812,94826,46.202518297
CID_2,Proteobacteria,22180,94826,23.390209436
CID_2,Bacteroidetes,16993,94826,17.920190665
CID_2,Verrucomicrobia,4779,94826,5.039757029
CID_2,Acidobacteria,1728,94826,1.822285027
CID_2,Firmicutes,1385,94826,1.460569886
CID_2,Planctomycetes,815,94826,0.859468922
CID_2,Actinobacteria,677,94826,0.713939215
CID_2,Gemmatimonadetes,625,94826,0.659101934
CID_2,Chloroflexi,416,94826,0.438698247
CID_2,Spirochaetes,415,94826,0.437643684
CID_2,Lentisphaerae,221,94826,0.233058444
CID_2,Ignavibacteriae,180,94826,0.189821357
CID_2,Fibrobacteres,155,94826,0.163457280
CID_2,Chlorobi,112,94826,0.118111067
CID_2,Elusimicrobia,111,94826,0.117056503
CID_2,Tenericutes,75,94826,0.079092232
CID_2,Nitrospinae,40,94826,0.042182524
CID_2,Nitrospirae,31,94826,0.032691456
CID_2,Deinococcus-Thermus,17,94826,0.017927573
CID_2,Armatimonadetes,17,94826,0.017927573
CID_2,Synergistetes,16,94826,0.016873010
CID_2,Fusobacteria,15,94826,0.015818446
CID_2,Deferribacteres,7,94826,0.007381942
CID_2,Caldiserica,2,94826,0.002109126
CID_2,Thermotogae,2,94826,0.002109126
CID_3,Cyanobacteria,18888,46181,40.899937204
CID_3,Proteobacteria,12532,46181,27.136701241
CID_3,Bacteroidetes,9070,46181,19.640111734
CID_3,Verrucomicrobia,2291,46181,4.960914662
CID_3,Acidobacteria,689,46181,1.491955566
CID_3,Firmicutes,631,46181,1.366362790
CID_3,Actinobacteria,470,46181,1.017734566
CID_3,Spirochaetes,366,46181,0.792533726
CID_3,Planctomycetes,326,46181,0.705918018
CID_3,Chloroflexi,282,46181,0.610640740
CID_3,Gemmatimonadetes,194,46181,0.420086183
CID_3,Fibrobacteres,116,46181,0.251185552
CID_3,Ignavibacteriae,109,46181,0.236027804
CID_3,Nitrospinae,46,46181,0.099608064
CID_3,Nitrospirae,44,46181,0.095277279
CID_3,Tenericutes,40,46181,0.086615708
CID_3,Lentisphaerae,38,46181,0.082284922
CID_3,Chlorobi,16,46181,0.034646283
CID_3,Elusimicrobia,14,46181,0.030315498
CID_3,Fusobacteria,10,46181,0.021653927
CID_3,Armatimonadetes,7,46181,0.015157749
CID_3,Synergistetes,2,46181,0.004330785
CID_4,Proteobacteria,433,1005,43.084577114
CID_4,Bacteroidetes,301,1005,29.950248756
CID_4,Actinobacteria,111,1005,11.044776119
CID_4,Cyanobacteria,44,1005,4.378109453
CID_4,Acidobacteria,28,1005,2.786069652
CID_4,Chloroflexi,24,1005,2.388059701
CID_4,Nitrospirae,21,1005,2.089552239
CID_4,Verrucomicrobia,12,1005,1.194029851
CID_4,Gemmatimonadetes,12,1005,1.194029851
CID_4,Firmicutes,7,1005,0.696517413
CID_4,Spirochaetes,5,1005,0.497512438
CID_4,Ignavibacteriae,5,1005,0.497512438
CID_4,Elusimicrobia,2,1005,0.199004975
CID_5,Proteobacteria,5002,11914,41.984220245
CID_5,Bacteroidetes,1512,11914,12.690951821
CID_5,Verrucomicrobia,1361,11914,11.423535337
CID_5,Acidobacteria,1207,11914,10.130938392
CID_5,Cyanobacteria,721,11914,6.051703878
CID_5,Planctomycetes,635,11914,5.329864026
CID_5,Actinobacteria,398,11914,3.340607688
CID_5,Nitrospirae,314,11914,2.635554809
CID_5,Chloroflexi,313,11914,2.627161323
CID_5,Firmicutes,195,11914,1.636729898
CID_5,Gemmatimonadetes,129,11914,1.082759778
CID_5,Chlorobi,31,11914,0.260198086
CID_5,Armatimonadetes,22,11914,0.184656706
CID_5,Ignavibacteriae,21,11914,0.176263220
CID_5,Fusobacteria,14,11914,0.117508813
CID_5,Deinococcus-Thermus,10,11914,0.083934867
CID_5,Lentisphaerae,9,11914,0.075541380
CID_5,Elusimicrobia,7,11914,0.058754407
CID_5,Nitrospinae,7,11914,0.058754407
CID_5,Synergistetes,4,11914,0.033573947
CID_5,Spirochaetes,2,11914,0.016786973
CID_6,Cyanobacteria,6462,17852,36.197624916
CID_6,Proteobacteria,5036,17852,28.209724401
CID_6,Bacteroidetes,3906,17852,21.879901412
CID_6,Verrucomicrobia,1016,17852,5.691239077
CID_6,Acidobacteria,317,17852,1.775711405
CID_6,Actinobacteria,286,17852,1.602061394
CID_6,Firmicutes,234,17852,1.310777504
CID_6,Planctomycetes,134,17852,0.750616177
CID_6,Gemmatimonadetes,112,17852,0.627380686
CID_6,Spirochaetes,97,17852,0.543356487
CID_6,Chloroflexi,77,17852,0.431324221
CID_6,Lentisphaerae,56,17852,0.313690343
CID_6,Ignavibacteriae,35,17852,0.196056464
CID_6,Nitrospirae,23,17852,0.128837105
CID_6,Nitrospinae,19,17852,0.106430652
CID_6,Tenericutes,12,17852,0.067219359
CID_6,Chlorobi,8,17852,0.044812906
CID_6,Armatimonadetes,7,17852,0.039211293
CID_6,Fibrobacteres,7,17852,0.039211293
CID_6,Elusimicrobia,4,17852,0.022406453
CID_6,Fusobacteria,2,17852,0.011203227
CID_6,Deferribacteres,2,17852,0.011203227
CID_7,Cyanobacteria,11046,30425,36.305669680
CID_7,Proteobacteria,8418,30425,27.668036154
CID_7,Bacteroidetes,6197,30425,20.368118324
CID_7,Verrucomicrobia,1745,30425,5.735414955
CID_7,Firmicutes,732,30425,2.405916187
CID_7,Acidobacteria,582,30425,1.912900575
CID_7,Actinobacteria,365,30425,1.199671323
CID_7,Fusobacteria,344,30425,1.130649137
CID_7,Planctomycetes,253,30425,0.831552999
CID_7,Chloroflexi,221,30425,0.726376335
CID_7,Gemmatimonadetes,131,30425,0.430566968
CID_7,Spirochaetes,127,30425,0.417419885
CID_7,Lentisphaerae,88,30425,0.289235826
CID_7,Ignavibacteriae,69,30425,0.226787182
CID_7,Nitrospinae,37,30425,0.121610518
CID_7,Nitrospirae,21,30425,0.069022186
CID_7,Chlorobi,17,30425,0.055875103
CID_7,Elusimicrobia,15,30425,0.049301561
CID_7,Fibrobacteres,9,30425,0.029580937
CID_7,Armatimonadetes,4,30425,0.013147083
CID_7,Deferribacteres,4,30425,0.013147083
CID_8,Cyanobacteria,14446,43589,33.141388883
CID_8,Proteobacteria,13270,43589,30.443460506
CID_8,Bacteroidetes,8834,43589,20.266581018
CID_8,Verrucomicrobia,2529,43589,5.801922503
CID_8,Firmicutes,1176,43589,2.697928376
CID_8,Acidobacteria,780,43589,1.789442290
CID_8,Actinobacteria,542,43589,1.243432976
CID_8,Spirochaetes,406,43589,0.931427654
CID_8,Planctomycetes,295,43589,0.676776251
CID_8,Chloroflexi,277,43589,0.635481429
CID_8,Ignavibacteriae,243,43589,0.557480098
CID_8,Lentisphaerae,230,43589,0.527656060
CID_8,Gemmatimonadetes,162,43589,0.371653399
CID_8,Fusobacteria,106,43589,0.243180619
CID_8,Tenericutes,57,43589,0.130766937
CID_8,Nitrospirae,51,43589,0.117001996
CID_8,Chlorobi,50,43589,0.114707839
CID_8,Nitrospinae,36,43589,0.082589644
CID_8,Fibrobacteres,34,43589,0.078001331
CID_8,Elusimicrobia,29,43589,0.066530547
CID_8,Armatimonadetes,19,43589,0.043588979
CID_8,Aquificae,8,43589,0.018353254
CID_8,Deferribacteres,7,43589,0.016059097
CID_8,Dictyoglomi,2,43589,0.004588314
CID_9,Proteobacteria,26463,77120,34.314056017
CID_9,Cyanobacteria,20329,77120,26.360217842
CID_9,Bacteroidetes,15956,77120,20.689834025
CID_9,Verrucomicrobia,3323,77120,4.308869295
CID_9,Firmicutes,2726,77120,3.534751037
CID_9,Spirochaetes,1644,77120,2.131742739
CID_9,Acidobacteria,1634,77120,2.118775934
CID_9,Actinobacteria,1200,77120,1.556016598
CID_9,Chloroflexi,1128,77120,1.462655602
CID_9,Planctomycetes,872,77120,1.130705394
CID_9,Ignavibacteriae,578,77120,0.749481328
CID_9,Lentisphaerae,264,77120,0.342323651
CID_9,Gemmatimonadetes,263,77120,0.341026971
CID_9,Fibrobacteres,170,77120,0.220435685
CID_9,Nitrospirae,148,77120,0.191908714
CID_9,Nitrospinae,136,77120,0.176348548
CID_9,Chlorobi,74,77120,0.095954357
CID_9,Tenericutes,71,77120,0.092064315
CID_9,Elusimicrobia,46,77120,0.059647303
CID_9,Armatimonadetes,27,77120,0.035010373
CID_9,Fusobacteria,25,77120,0.032417012
CID_9,Aquificae,13,77120,0.016856846
CID_9,Synergistetes,12,77120,0.015560166
CID_9,Deferribacteres,8,77120,0.010373444
CID_9,Thermotogae,7,77120,0.009076763
CID_9,Chrysiogenetes,3,77120,0.003890041
")

	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Sun Dec  7 17:42:41 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sun, 07 Dec 2014 10:42:41 -0600
Subject: [R] Condensing data.frame
In-Reply-To: <CAPoqHzriibZVebOe803VnUFCYH3VnLo_FPi5Y1O=MvS3vntU8A@mail.gmail.com>
References: <CAPoqHzriibZVebOe803VnUFCYH3VnLo_FPi5Y1O=MvS3vntU8A@mail.gmail.com>
Message-ID: <54848381.7000300@mail.usask.ca>

 > datBySite <- split(dat, dat$site)
 > output <- lapply(datBySite, function(x){
+ x$idx <- seq_len(nrow(x))
+ x$grp <- ifelse(x$idx < 7, x$idx, 7)
+ rval <- tapply(x$countPercentage, x$grp, sum)
+ x$grp <- x$count <- x$countTotal <- NULL
+ x <- x[seq_len(7), ]
+ x$tax_name <- as.character(x$tax_name)
+ x$tax_name[7] <- "Others"
+ x$new <- rval
+ return(x)
+ })
 >
 > head(do.call(rbind, output), 14)
             site        tax_name countPercentage idx       new
CID_1.1    CID_1   Cyanobacteria       37.483098   1 37.483098
CID_1.2    CID_1  Proteobacteria       29.244832   2 29.244832
CID_1.3    CID_1   Bacteroidetes       15.825567   3 15.825567
CID_1.4    CID_1 Verrucomicrobia        6.384960   4  6.384960
CID_1.5    CID_1      Firmicutes        2.301857   5  2.301857
CID_1.6    CID_1   Acidobacteria        2.075152   6  2.075152
CID_1.7    CID_1          Others        1.675182   7  6.684533
CID_10.27 CID_10  Proteobacteria       35.366606   1 35.366606
CID_10.28 CID_10   Bacteroidetes       25.188484   2 25.188484
CID_10.29 CID_10   Cyanobacteria       23.294828   3 23.294828
CID_10.30 CID_10 Verrucomicrobia        6.970592   4  6.970592
CID_10.31 CID_10   Acidobacteria        1.988448   5  1.988448
CID_10.32 CID_10  Actinobacteria        1.644548   6  1.644548
CID_10.33 CID_10          Others        1.582823   7  5.546493
 >

I hope this helps.

Chel Hee Lee

On 12/07/2014 08:21 AM, Morway, Eric wrote:
> Using the dataset "dat" (found below), I'm seeking a way to condense down
> the data.frame such that each "site" (i.e., "CID_1"..."CID_13") has a
> maximum of 7 rows of post-processed data, where the first 6 have the
> highest "countPercentage" and the 7th row is the sum of "countPercentage"
> from all other rows within that "site", and it is assigned the name
> "Other".  So, for the first two sites in the provided data.frame, CID_1 &
> CID_10, they would reduce to:
>
> CID_1 Cyanobacteria     37.48
> CID_1 Proteobacteria     29.24
> CID_1 Bacteroidetes      15.83
> CID_1 Verrucomicrobia  6.38
> CID_1 Firmicutes          2.30
> CID_1 Acidobacteria      2.08
> CID_1 Other                6.68
> CID_10 Proteobacteria     35.37
> CID_10 Bacteroidetes      25.19
> CID_10 Cyanobacteria     23.29
> CID_10 Verrucomicrobia  6.97
> CID_10 Acidobacteria      1.99
> CID_10 Actinobacteria     1.64
> CID_10 Other                 5.55
>
>
> dat <- read.table(header=TRUE, sep=",",
> text="site,tax_name,count,countTotal,countPercentage
> CID_1,Cyanobacteria,46295,123509,37.483098398
> CID_1,Proteobacteria,36120,123509,29.244832360
> CID_1,Bacteroidetes,19546,123509,15.825567368
> CID_1,Verrucomicrobia,7886,123509,6.384959801
> CID_1,Firmicutes,2843,123509,2.301856545
> CID_1,Acidobacteria,2563,123509,2.075152418
> CID_1,Actinobacteria,2069,123509,1.675181566
> CID_1,Planctomycetes,1481,123509,1.199102899
> CID_1,Chloroflexi,1181,123509,0.956205621
> CID_1,Gemmatimonadetes,956,123509,0.774032662
> CID_1,Spirochaetes,688,123509,0.557044426
> CID_1,Lentisphaerae,526,123509,0.425879895
> CID_1,Ignavibacteriae,324,123509,0.262329061
> CID_1,Chlorobi,238,123509,0.192698508
> CID_1,Nitrospirae,230,123509,0.186221247
> CID_1,Nitrospinae,169,123509,0.136832134
> CID_1,Elusimicrobia,131,123509,0.106065145
> CID_1,Tenericutes,114,123509,0.092300966
> CID_1,Fibrobacteres,72,123509,0.058295347
> CID_1,Thermotogae,21,123509,0.017002810
> CID_1,Fusobacteria,21,123509,0.017002810
> CID_1,Armatimonadetes,15,123509,0.012144864
> CID_1,Synergistetes,10,123509,0.008096576
> CID_1,Deinococcus-Thermus,6,123509,0.004857946
> CID_1,Deferribacteres,2,123509,0.001619315
> CID_1,Caldiserica,2,123509,0.001619315
> CID_10,Proteobacteria,16043,45362,35.366606411
> CID_10,Bacteroidetes,11426,45362,25.188483753
> CID_10,Cyanobacteria,10567,45362,23.294828270
> CID_10,Verrucomicrobia,3162,45362,6.970592126
> CID_10,Acidobacteria,902,45362,1.988448481
> CID_10,Actinobacteria,746,45362,1.644548300
> CID_10,Firmicutes,718,45362,1.582822627
> CID_10,Gemmatimonadetes,358,45362,0.789206825
> CID_10,Planctomycetes,357,45362,0.787002337
> CID_10,Chloroflexi,265,45362,0.584189410
> CID_10,Spirochaetes,235,45362,0.518054759
> CID_10,Ignavibacteriae,177,45362,0.390194436
> CID_10,Lentisphaerae,108,45362,0.238084741
> CID_10,Nitrospinae,75,45362,0.165336625
> CID_10,Nitrospirae,58,45362,0.127860324
> CID_10,Chlorobi,44,45362,0.096997487
> CID_10,Elusimicrobia,28,45362,0.061725673
> CID_10,Fibrobacteres,26,45362,0.057316697
> CID_10,Armatimonadetes,15,45362,0.033067325
> CID_10,Deinococcus-Thermus,13,45362,0.028658348
> CID_10,Tenericutes,10,45362,0.022044883
> CID_10,Synergistetes,9,45362,0.019840395
> CID_10,Fusobacteria,9,45362,0.019840395
> CID_10,Deferribacteres,6,45362,0.013226930
> CID_10,Thermotogae,3,45362,0.006613465
> CID_10,Caldiserica,2,45362,0.004408977
> CID_11,Proteobacteria,10019,31387,31.920858954
> CID_11,Cyanobacteria,8811,31387,28.072131774
> CID_11,Bacteroidetes,7930,31387,25.265237200
> CID_11,Verrucomicrobia,1750,31387,5.575556759
> CID_11,Firmicutes,806,31387,2.567942142
> CID_11,Acidobacteria,548,31387,1.745945774
> CID_11,Actinobacteria,434,31387,1.382738076
> CID_11,Chloroflexi,203,31387,0.646764584
> CID_11,Planctomycetes,197,31387,0.627648389
> CID_11,Gemmatimonadetes,192,31387,0.611718227
> CID_11,Ignavibacteriae,87,31387,0.277184822
> CID_11,Spirochaetes,80,31387,0.254882595
> CID_11,Tenericutes,71,31387,0.226208303
> CID_11,Fusobacteria,67,31387,0.213464173
> CID_11,Lentisphaerae,54,31387,0.172045751
> CID_11,Chlorobi,40,31387,0.127441297
> CID_11,Nitrospinae,33,31387,0.105139070
> CID_11,Armatimonadetes,22,31387,0.070092714
> CID_11,Fibrobacteres,15,31387,0.047790487
> CID_11,Nitrospirae,13,31387,0.041418422
> CID_11,Elusimicrobia,13,31387,0.041418422
> CID_11,Deinococcus-Thermus,2,31387,0.006372065
> CID_12,Cyanobacteria,241,644,37.422360248
> CID_12,Bacteroidetes,210,644,32.608695652
> CID_12,Proteobacteria,118,644,18.322981366
> CID_12,Verrucomicrobia,38,644,5.900621118
> CID_12,Acidobacteria,11,644,1.708074534
> CID_12,Ignavibacteriae,6,644,0.931677019
> CID_12,Lentisphaerae,5,644,0.776397516
> CID_12,Firmicutes,5,644,0.776397516
> CID_12,Planctomycetes,3,644,0.465838509
> CID_12,Fusobacteria,3,644,0.465838509
> CID_12,Tenericutes,2,644,0.310559006
> CID_12,Actinobacteria,2,644,0.310559006
> CID_13,Cyanobacteria,8581,25530,33.611437524
> CID_13,Bacteroidetes,6878,25530,26.940853897
> CID_13,Proteobacteria,5341,25530,20.920485703
> CID_13,Verrucomicrobia,1244,25530,4.872698786
> CID_13,Firmicutes,1148,25530,4.496670584
> CID_13,Acidobacteria,548,25530,2.146494320
> CID_13,Spirochaetes,477,25530,1.868390129
> CID_13,Ignavibacteriae,298,25530,1.167254211
> CID_13,Actinobacteria,227,25530,0.889150020
> CID_13,Planctomycetes,184,25530,0.720720721
> CID_13,Chloroflexi,181,25530,0.708969839
> CID_13,Gemmatimonadetes,121,25530,0.473952213
> CID_13,Lentisphaerae,93,25530,0.364277321
> CID_13,Tenericutes,61,25530,0.238934587
> CID_13,Fibrobacteres,47,25530,0.184097141
> CID_13,Nitrospinae,28,25530,0.109674892
> CID_13,Nitrospirae,26,25530,0.101840971
> CID_13,Chlorobi,18,25530,0.070505288
> CID_13,Elusimicrobia,13,25530,0.050920486
> CID_13,Synergistetes,8,25530,0.031335684
> CID_13,Fusobacteria,4,25530,0.015667842
> CID_13,Deinococcus-Thermus,2,25530,0.007833921
> CID_13,Thermotogae,2,25530,0.007833921
> CID_2,Cyanobacteria,43812,94826,46.202518297
> CID_2,Proteobacteria,22180,94826,23.390209436
> CID_2,Bacteroidetes,16993,94826,17.920190665
> CID_2,Verrucomicrobia,4779,94826,5.039757029
> CID_2,Acidobacteria,1728,94826,1.822285027
> CID_2,Firmicutes,1385,94826,1.460569886
> CID_2,Planctomycetes,815,94826,0.859468922
> CID_2,Actinobacteria,677,94826,0.713939215
> CID_2,Gemmatimonadetes,625,94826,0.659101934
> CID_2,Chloroflexi,416,94826,0.438698247
> CID_2,Spirochaetes,415,94826,0.437643684
> CID_2,Lentisphaerae,221,94826,0.233058444
> CID_2,Ignavibacteriae,180,94826,0.189821357
> CID_2,Fibrobacteres,155,94826,0.163457280
> CID_2,Chlorobi,112,94826,0.118111067
> CID_2,Elusimicrobia,111,94826,0.117056503
> CID_2,Tenericutes,75,94826,0.079092232
> CID_2,Nitrospinae,40,94826,0.042182524
> CID_2,Nitrospirae,31,94826,0.032691456
> CID_2,Deinococcus-Thermus,17,94826,0.017927573
> CID_2,Armatimonadetes,17,94826,0.017927573
> CID_2,Synergistetes,16,94826,0.016873010
> CID_2,Fusobacteria,15,94826,0.015818446
> CID_2,Deferribacteres,7,94826,0.007381942
> CID_2,Caldiserica,2,94826,0.002109126
> CID_2,Thermotogae,2,94826,0.002109126
> CID_3,Cyanobacteria,18888,46181,40.899937204
> CID_3,Proteobacteria,12532,46181,27.136701241
> CID_3,Bacteroidetes,9070,46181,19.640111734
> CID_3,Verrucomicrobia,2291,46181,4.960914662
> CID_3,Acidobacteria,689,46181,1.491955566
> CID_3,Firmicutes,631,46181,1.366362790
> CID_3,Actinobacteria,470,46181,1.017734566
> CID_3,Spirochaetes,366,46181,0.792533726
> CID_3,Planctomycetes,326,46181,0.705918018
> CID_3,Chloroflexi,282,46181,0.610640740
> CID_3,Gemmatimonadetes,194,46181,0.420086183
> CID_3,Fibrobacteres,116,46181,0.251185552
> CID_3,Ignavibacteriae,109,46181,0.236027804
> CID_3,Nitrospinae,46,46181,0.099608064
> CID_3,Nitrospirae,44,46181,0.095277279
> CID_3,Tenericutes,40,46181,0.086615708
> CID_3,Lentisphaerae,38,46181,0.082284922
> CID_3,Chlorobi,16,46181,0.034646283
> CID_3,Elusimicrobia,14,46181,0.030315498
> CID_3,Fusobacteria,10,46181,0.021653927
> CID_3,Armatimonadetes,7,46181,0.015157749
> CID_3,Synergistetes,2,46181,0.004330785
> CID_4,Proteobacteria,433,1005,43.084577114
> CID_4,Bacteroidetes,301,1005,29.950248756
> CID_4,Actinobacteria,111,1005,11.044776119
> CID_4,Cyanobacteria,44,1005,4.378109453
> CID_4,Acidobacteria,28,1005,2.786069652
> CID_4,Chloroflexi,24,1005,2.388059701
> CID_4,Nitrospirae,21,1005,2.089552239
> CID_4,Verrucomicrobia,12,1005,1.194029851
> CID_4,Gemmatimonadetes,12,1005,1.194029851
> CID_4,Firmicutes,7,1005,0.696517413
> CID_4,Spirochaetes,5,1005,0.497512438
> CID_4,Ignavibacteriae,5,1005,0.497512438
> CID_4,Elusimicrobia,2,1005,0.199004975
> CID_5,Proteobacteria,5002,11914,41.984220245
> CID_5,Bacteroidetes,1512,11914,12.690951821
> CID_5,Verrucomicrobia,1361,11914,11.423535337
> CID_5,Acidobacteria,1207,11914,10.130938392
> CID_5,Cyanobacteria,721,11914,6.051703878
> CID_5,Planctomycetes,635,11914,5.329864026
> CID_5,Actinobacteria,398,11914,3.340607688
> CID_5,Nitrospirae,314,11914,2.635554809
> CID_5,Chloroflexi,313,11914,2.627161323
> CID_5,Firmicutes,195,11914,1.636729898
> CID_5,Gemmatimonadetes,129,11914,1.082759778
> CID_5,Chlorobi,31,11914,0.260198086
> CID_5,Armatimonadetes,22,11914,0.184656706
> CID_5,Ignavibacteriae,21,11914,0.176263220
> CID_5,Fusobacteria,14,11914,0.117508813
> CID_5,Deinococcus-Thermus,10,11914,0.083934867
> CID_5,Lentisphaerae,9,11914,0.075541380
> CID_5,Elusimicrobia,7,11914,0.058754407
> CID_5,Nitrospinae,7,11914,0.058754407
> CID_5,Synergistetes,4,11914,0.033573947
> CID_5,Spirochaetes,2,11914,0.016786973
> CID_6,Cyanobacteria,6462,17852,36.197624916
> CID_6,Proteobacteria,5036,17852,28.209724401
> CID_6,Bacteroidetes,3906,17852,21.879901412
> CID_6,Verrucomicrobia,1016,17852,5.691239077
> CID_6,Acidobacteria,317,17852,1.775711405
> CID_6,Actinobacteria,286,17852,1.602061394
> CID_6,Firmicutes,234,17852,1.310777504
> CID_6,Planctomycetes,134,17852,0.750616177
> CID_6,Gemmatimonadetes,112,17852,0.627380686
> CID_6,Spirochaetes,97,17852,0.543356487
> CID_6,Chloroflexi,77,17852,0.431324221
> CID_6,Lentisphaerae,56,17852,0.313690343
> CID_6,Ignavibacteriae,35,17852,0.196056464
> CID_6,Nitrospirae,23,17852,0.128837105
> CID_6,Nitrospinae,19,17852,0.106430652
> CID_6,Tenericutes,12,17852,0.067219359
> CID_6,Chlorobi,8,17852,0.044812906
> CID_6,Armatimonadetes,7,17852,0.039211293
> CID_6,Fibrobacteres,7,17852,0.039211293
> CID_6,Elusimicrobia,4,17852,0.022406453
> CID_6,Fusobacteria,2,17852,0.011203227
> CID_6,Deferribacteres,2,17852,0.011203227
> CID_7,Cyanobacteria,11046,30425,36.305669680
> CID_7,Proteobacteria,8418,30425,27.668036154
> CID_7,Bacteroidetes,6197,30425,20.368118324
> CID_7,Verrucomicrobia,1745,30425,5.735414955
> CID_7,Firmicutes,732,30425,2.405916187
> CID_7,Acidobacteria,582,30425,1.912900575
> CID_7,Actinobacteria,365,30425,1.199671323
> CID_7,Fusobacteria,344,30425,1.130649137
> CID_7,Planctomycetes,253,30425,0.831552999
> CID_7,Chloroflexi,221,30425,0.726376335
> CID_7,Gemmatimonadetes,131,30425,0.430566968
> CID_7,Spirochaetes,127,30425,0.417419885
> CID_7,Lentisphaerae,88,30425,0.289235826
> CID_7,Ignavibacteriae,69,30425,0.226787182
> CID_7,Nitrospinae,37,30425,0.121610518
> CID_7,Nitrospirae,21,30425,0.069022186
> CID_7,Chlorobi,17,30425,0.055875103
> CID_7,Elusimicrobia,15,30425,0.049301561
> CID_7,Fibrobacteres,9,30425,0.029580937
> CID_7,Armatimonadetes,4,30425,0.013147083
> CID_7,Deferribacteres,4,30425,0.013147083
> CID_8,Cyanobacteria,14446,43589,33.141388883
> CID_8,Proteobacteria,13270,43589,30.443460506
> CID_8,Bacteroidetes,8834,43589,20.266581018
> CID_8,Verrucomicrobia,2529,43589,5.801922503
> CID_8,Firmicutes,1176,43589,2.697928376
> CID_8,Acidobacteria,780,43589,1.789442290
> CID_8,Actinobacteria,542,43589,1.243432976
> CID_8,Spirochaetes,406,43589,0.931427654
> CID_8,Planctomycetes,295,43589,0.676776251
> CID_8,Chloroflexi,277,43589,0.635481429
> CID_8,Ignavibacteriae,243,43589,0.557480098
> CID_8,Lentisphaerae,230,43589,0.527656060
> CID_8,Gemmatimonadetes,162,43589,0.371653399
> CID_8,Fusobacteria,106,43589,0.243180619
> CID_8,Tenericutes,57,43589,0.130766937
> CID_8,Nitrospirae,51,43589,0.117001996
> CID_8,Chlorobi,50,43589,0.114707839
> CID_8,Nitrospinae,36,43589,0.082589644
> CID_8,Fibrobacteres,34,43589,0.078001331
> CID_8,Elusimicrobia,29,43589,0.066530547
> CID_8,Armatimonadetes,19,43589,0.043588979
> CID_8,Aquificae,8,43589,0.018353254
> CID_8,Deferribacteres,7,43589,0.016059097
> CID_8,Dictyoglomi,2,43589,0.004588314
> CID_9,Proteobacteria,26463,77120,34.314056017
> CID_9,Cyanobacteria,20329,77120,26.360217842
> CID_9,Bacteroidetes,15956,77120,20.689834025
> CID_9,Verrucomicrobia,3323,77120,4.308869295
> CID_9,Firmicutes,2726,77120,3.534751037
> CID_9,Spirochaetes,1644,77120,2.131742739
> CID_9,Acidobacteria,1634,77120,2.118775934
> CID_9,Actinobacteria,1200,77120,1.556016598
> CID_9,Chloroflexi,1128,77120,1.462655602
> CID_9,Planctomycetes,872,77120,1.130705394
> CID_9,Ignavibacteriae,578,77120,0.749481328
> CID_9,Lentisphaerae,264,77120,0.342323651
> CID_9,Gemmatimonadetes,263,77120,0.341026971
> CID_9,Fibrobacteres,170,77120,0.220435685
> CID_9,Nitrospirae,148,77120,0.191908714
> CID_9,Nitrospinae,136,77120,0.176348548
> CID_9,Chlorobi,74,77120,0.095954357
> CID_9,Tenericutes,71,77120,0.092064315
> CID_9,Elusimicrobia,46,77120,0.059647303
> CID_9,Armatimonadetes,27,77120,0.035010373
> CID_9,Fusobacteria,25,77120,0.032417012
> CID_9,Aquificae,13,77120,0.016856846
> CID_9,Synergistetes,12,77120,0.015560166
> CID_9,Deferribacteres,8,77120,0.010373444
> CID_9,Thermotogae,7,77120,0.009076763
> CID_9,Chrysiogenetes,3,77120,0.003890041
> ")
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.posner at MJBIOSTAT.COM  Sun Dec  7 17:56:28 2014
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Sun, 7 Dec 2014 16:56:28 +0000
Subject: [R] Condensing data.frame
In-Reply-To: <54848381.7000300@mail.usask.ca>
References: <CAPoqHzriibZVebOe803VnUFCYH3VnLo_FPi5Y1O=MvS3vntU8A@mail.gmail.com>
	<54848381.7000300@mail.usask.ca>
Message-ID: <9E73F88F04AA25408DBB58FB730BA65329B150F3@AUSP01DAG0503.collaborationhost.net>

Here's a solution using the plyr library:

####################
library(plyr)

dat <- read.table(header=TRUE, sep=",", as.is=TRUE,   ###### <---- as.is=TRUE
text="site,tax_name,count,countTotal,countPercentage
CID_1,Cyanobacteria,46295,123509,37.483098398
CID_1,Proteobacteria,36120,123509,29.244832360
CID_1,Bacteroidetes,19546,123509,15.825567368
CID_1,Verrucomicrobia,7886,123509,6.384959801
CID_1,Firmicutes,2843,123509,2.301856545
   ... <lines deleted here>
CID_9,Armatimonadetes,27,77120,0.035010373
CID_9,Fusobacteria,25,77120,0.032417012
CID_9,Aquificae,13,77120,0.016856846
CID_9,Synergistetes,12,77120,0.015560166
CID_9,Deferribacteres,8,77120,0.010373444
CID_9,Thermotogae,7,77120,0.009076763
CID_9,Chrysiogenetes,3,77120,0.003890041.
")

summ_cid = function(frm) {
  # grab at most 6 rows from data frame
  toprows = head(frm, 6)  
  # add a 7th row
  toprows[nrow(toprows)+1,] = c(toprows[1,1], "", NA, NA, sum(toprows$countPercentage))
  # all done
  return(toprows)
}

result = ddply(dat, "site", summ_cid)
####################

Notes: 

 1. I needed to add the as.is=TRUE option to read.table()
 2. The invocation of ddply() does *not* use summarize()
 3. Because there is no use of summarize(), I have not figured out how to use the dplyr package in this context.

-John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chel Hee
> Lee
> Sent: Sunday, December 07, 2014 11:43 AM
> To: Morway, Eric; R mailing list
> Subject: Re: [R] Condensing data.frame
> 
>  > datBySite <- split(dat, dat$site)
>  > output <- lapply(datBySite, function(x){
> + x$idx <- seq_len(nrow(x))
> + x$grp <- ifelse(x$idx < 7, x$idx, 7)
> + rval <- tapply(x$countPercentage, x$grp, sum) x$grp <- x$count <-
> + x$countTotal <- NULL x <- x[seq_len(7), ] x$tax_name <-
> + as.character(x$tax_name) x$tax_name[7] <- "Others"
> + x$new <- rval
> + return(x)
> + })
>  >
>  > head(do.call(rbind, output), 14)
>              site        tax_name countPercentage idx       new
> CID_1.1    CID_1   Cyanobacteria       37.483098   1 37.483098
> CID_1.2    CID_1  Proteobacteria       29.244832   2 29.244832
> CID_1.3    CID_1   Bacteroidetes       15.825567   3 15.825567
> CID_1.4    CID_1 Verrucomicrobia        6.384960   4  6.384960
> CID_1.5    CID_1      Firmicutes        2.301857   5  2.301857
> CID_1.6    CID_1   Acidobacteria        2.075152   6  2.075152
> CID_1.7    CID_1          Others        1.675182   7  6.684533
> CID_10.27 CID_10  Proteobacteria       35.366606   1 35.366606
> CID_10.28 CID_10   Bacteroidetes       25.188484   2 25.188484
> CID_10.29 CID_10   Cyanobacteria       23.294828   3 23.294828
> CID_10.30 CID_10 Verrucomicrobia        6.970592   4  6.970592
> CID_10.31 CID_10   Acidobacteria        1.988448   5  1.988448
> CID_10.32 CID_10  Actinobacteria        1.644548   6  1.644548
> CID_10.33 CID_10          Others        1.582823   7  5.546493
>  >
> 
> I hope this helps.
> 
> Chel Hee Lee
> 
> On 12/07/2014 08:21 AM, Morway, Eric wrote:
> > Using the dataset "dat" (found below), I'm seeking a way to condense
> > down the data.frame such that each "site" (i.e., "CID_1"..."CID_13")
> > has a maximum of 7 rows of post-processed data, where the first 6 have
> > the highest "countPercentage" and the 7th row is the sum of
> "countPercentage"
> > from all other rows within that "site", and it is assigned the name
> > "Other".  So, for the first two sites in the provided data.frame,
> > CID_1 & CID_10, they would reduce to:
> >
> > CID_1 Cyanobacteria     37.48
> > CID_1 Proteobacteria     29.24
> > CID_1 Bacteroidetes      15.83
> > CID_1 Verrucomicrobia  6.38
> > CID_1 Firmicutes          2.30
> > CID_1 Acidobacteria      2.08
> > CID_1 Other                6.68
> > CID_10 Proteobacteria     35.37
> > CID_10 Bacteroidetes      25.19
> > CID_10 Cyanobacteria     23.29
> > CID_10 Verrucomicrobia  6.97
> > CID_10 Acidobacteria      1.99
> > CID_10 Actinobacteria     1.64
> > CID_10 Other                 5.55
> >
> >
> > dat <- read.table(header=TRUE, sep=",",
> > text="site,tax_name,count,countTotal,countPercentage
> > CID_1,Cyanobacteria,46295,123509,37.483098398
> > CID_1,Proteobacteria,36120,123509,29.244832360
> > CID_1,Bacteroidetes,19546,123509,15.825567368
> > CID_1,Verrucomicrobia,7886,123509,6.384959801
> > CID_1,Firmicutes,2843,123509,2.301856545
> > CID_1,Acidobacteria,2563,123509,2.075152418
> > CID_1,Actinobacteria,2069,123509,1.675181566
> > CID_1,Planctomycetes,1481,123509,1.199102899
> > CID_1,Chloroflexi,1181,123509,0.956205621
> > CID_1,Gemmatimonadetes,956,123509,0.774032662
> > CID_1,Spirochaetes,688,123509,0.557044426
> > CID_1,Lentisphaerae,526,123509,0.425879895
> > CID_1,Ignavibacteriae,324,123509,0.262329061
> > CID_1,Chlorobi,238,123509,0.192698508
> > CID_1,Nitrospirae,230,123509,0.186221247
> > CID_1,Nitrospinae,169,123509,0.136832134
> > CID_1,Elusimicrobia,131,123509,0.106065145
> > CID_1,Tenericutes,114,123509,0.092300966
> > CID_1,Fibrobacteres,72,123509,0.058295347
> > CID_1,Thermotogae,21,123509,0.017002810
> > CID_1,Fusobacteria,21,123509,0.017002810
> > CID_1,Armatimonadetes,15,123509,0.012144864
> > CID_1,Synergistetes,10,123509,0.008096576
> > CID_1,Deinococcus-Thermus,6,123509,0.004857946
> > CID_1,Deferribacteres,2,123509,0.001619315
> > CID_1,Caldiserica,2,123509,0.001619315
> > CID_10,Proteobacteria,16043,45362,35.366606411
> > CID_10,Bacteroidetes,11426,45362,25.188483753
> > CID_10,Cyanobacteria,10567,45362,23.294828270
> > CID_10,Verrucomicrobia,3162,45362,6.970592126
> > CID_10,Acidobacteria,902,45362,1.988448481
> > CID_10,Actinobacteria,746,45362,1.644548300
> > CID_10,Firmicutes,718,45362,1.582822627
> > CID_10,Gemmatimonadetes,358,45362,0.789206825
> > CID_10,Planctomycetes,357,45362,0.787002337
> > CID_10,Chloroflexi,265,45362,0.584189410
> > CID_10,Spirochaetes,235,45362,0.518054759
> > CID_10,Ignavibacteriae,177,45362,0.390194436
> > CID_10,Lentisphaerae,108,45362,0.238084741
> > CID_10,Nitrospinae,75,45362,0.165336625
> > CID_10,Nitrospirae,58,45362,0.127860324
> > CID_10,Chlorobi,44,45362,0.096997487
> > CID_10,Elusimicrobia,28,45362,0.061725673
> > CID_10,Fibrobacteres,26,45362,0.057316697
> > CID_10,Armatimonadetes,15,45362,0.033067325
> > CID_10,Deinococcus-Thermus,13,45362,0.028658348
> > CID_10,Tenericutes,10,45362,0.022044883
> > CID_10,Synergistetes,9,45362,0.019840395
> > CID_10,Fusobacteria,9,45362,0.019840395
> > CID_10,Deferribacteres,6,45362,0.013226930
> > CID_10,Thermotogae,3,45362,0.006613465
> > CID_10,Caldiserica,2,45362,0.004408977
> > CID_11,Proteobacteria,10019,31387,31.920858954
> > CID_11,Cyanobacteria,8811,31387,28.072131774
> > CID_11,Bacteroidetes,7930,31387,25.265237200
> > CID_11,Verrucomicrobia,1750,31387,5.575556759
> > CID_11,Firmicutes,806,31387,2.567942142
> > CID_11,Acidobacteria,548,31387,1.745945774
> > CID_11,Actinobacteria,434,31387,1.382738076
> > CID_11,Chloroflexi,203,31387,0.646764584
> > CID_11,Planctomycetes,197,31387,0.627648389
> > CID_11,Gemmatimonadetes,192,31387,0.611718227
> > CID_11,Ignavibacteriae,87,31387,0.277184822
> > CID_11,Spirochaetes,80,31387,0.254882595
> > CID_11,Tenericutes,71,31387,0.226208303
> > CID_11,Fusobacteria,67,31387,0.213464173
> > CID_11,Lentisphaerae,54,31387,0.172045751
> > CID_11,Chlorobi,40,31387,0.127441297
> > CID_11,Nitrospinae,33,31387,0.105139070
> > CID_11,Armatimonadetes,22,31387,0.070092714
> > CID_11,Fibrobacteres,15,31387,0.047790487
> > CID_11,Nitrospirae,13,31387,0.041418422
> > CID_11,Elusimicrobia,13,31387,0.041418422
> > CID_11,Deinococcus-Thermus,2,31387,0.006372065
> > CID_12,Cyanobacteria,241,644,37.422360248
> > CID_12,Bacteroidetes,210,644,32.608695652
> > CID_12,Proteobacteria,118,644,18.322981366
> > CID_12,Verrucomicrobia,38,644,5.900621118
> > CID_12,Acidobacteria,11,644,1.708074534
> > CID_12,Ignavibacteriae,6,644,0.931677019
> > CID_12,Lentisphaerae,5,644,0.776397516
> > CID_12,Firmicutes,5,644,0.776397516
> > CID_12,Planctomycetes,3,644,0.465838509
> > CID_12,Fusobacteria,3,644,0.465838509
> > CID_12,Tenericutes,2,644,0.310559006
> > CID_12,Actinobacteria,2,644,0.310559006
> > CID_13,Cyanobacteria,8581,25530,33.611437524
> > CID_13,Bacteroidetes,6878,25530,26.940853897
> > CID_13,Proteobacteria,5341,25530,20.920485703
> > CID_13,Verrucomicrobia,1244,25530,4.872698786
> > CID_13,Firmicutes,1148,25530,4.496670584
> > CID_13,Acidobacteria,548,25530,2.146494320
> > CID_13,Spirochaetes,477,25530,1.868390129
> > CID_13,Ignavibacteriae,298,25530,1.167254211
> > CID_13,Actinobacteria,227,25530,0.889150020
> > CID_13,Planctomycetes,184,25530,0.720720721
> > CID_13,Chloroflexi,181,25530,0.708969839
> > CID_13,Gemmatimonadetes,121,25530,0.473952213
> > CID_13,Lentisphaerae,93,25530,0.364277321
> > CID_13,Tenericutes,61,25530,0.238934587
> > CID_13,Fibrobacteres,47,25530,0.184097141
> > CID_13,Nitrospinae,28,25530,0.109674892
> > CID_13,Nitrospirae,26,25530,0.101840971
> > CID_13,Chlorobi,18,25530,0.070505288
> > CID_13,Elusimicrobia,13,25530,0.050920486
> > CID_13,Synergistetes,8,25530,0.031335684
> > CID_13,Fusobacteria,4,25530,0.015667842
> > CID_13,Deinococcus-Thermus,2,25530,0.007833921
> > CID_13,Thermotogae,2,25530,0.007833921
> > CID_2,Cyanobacteria,43812,94826,46.202518297
> > CID_2,Proteobacteria,22180,94826,23.390209436
> > CID_2,Bacteroidetes,16993,94826,17.920190665
> > CID_2,Verrucomicrobia,4779,94826,5.039757029
> > CID_2,Acidobacteria,1728,94826,1.822285027
> > CID_2,Firmicutes,1385,94826,1.460569886
> > CID_2,Planctomycetes,815,94826,0.859468922
> > CID_2,Actinobacteria,677,94826,0.713939215
> > CID_2,Gemmatimonadetes,625,94826,0.659101934
> > CID_2,Chloroflexi,416,94826,0.438698247
> > CID_2,Spirochaetes,415,94826,0.437643684
> > CID_2,Lentisphaerae,221,94826,0.233058444
> > CID_2,Ignavibacteriae,180,94826,0.189821357
> > CID_2,Fibrobacteres,155,94826,0.163457280
> > CID_2,Chlorobi,112,94826,0.118111067
> > CID_2,Elusimicrobia,111,94826,0.117056503
> > CID_2,Tenericutes,75,94826,0.079092232
> > CID_2,Nitrospinae,40,94826,0.042182524
> > CID_2,Nitrospirae,31,94826,0.032691456
> > CID_2,Deinococcus-Thermus,17,94826,0.017927573
> > CID_2,Armatimonadetes,17,94826,0.017927573
> > CID_2,Synergistetes,16,94826,0.016873010
> > CID_2,Fusobacteria,15,94826,0.015818446
> > CID_2,Deferribacteres,7,94826,0.007381942
> > CID_2,Caldiserica,2,94826,0.002109126
> > CID_2,Thermotogae,2,94826,0.002109126
> > CID_3,Cyanobacteria,18888,46181,40.899937204
> > CID_3,Proteobacteria,12532,46181,27.136701241
> > CID_3,Bacteroidetes,9070,46181,19.640111734
> > CID_3,Verrucomicrobia,2291,46181,4.960914662
> > CID_3,Acidobacteria,689,46181,1.491955566
> > CID_3,Firmicutes,631,46181,1.366362790
> > CID_3,Actinobacteria,470,46181,1.017734566
> > CID_3,Spirochaetes,366,46181,0.792533726
> > CID_3,Planctomycetes,326,46181,0.705918018
> > CID_3,Chloroflexi,282,46181,0.610640740
> > CID_3,Gemmatimonadetes,194,46181,0.420086183
> > CID_3,Fibrobacteres,116,46181,0.251185552
> > CID_3,Ignavibacteriae,109,46181,0.236027804
> > CID_3,Nitrospinae,46,46181,0.099608064
> > CID_3,Nitrospirae,44,46181,0.095277279
> > CID_3,Tenericutes,40,46181,0.086615708
> > CID_3,Lentisphaerae,38,46181,0.082284922
> > CID_3,Chlorobi,16,46181,0.034646283
> > CID_3,Elusimicrobia,14,46181,0.030315498
> > CID_3,Fusobacteria,10,46181,0.021653927
> > CID_3,Armatimonadetes,7,46181,0.015157749
> > CID_3,Synergistetes,2,46181,0.004330785
> > CID_4,Proteobacteria,433,1005,43.084577114
> > CID_4,Bacteroidetes,301,1005,29.950248756
> > CID_4,Actinobacteria,111,1005,11.044776119
> > CID_4,Cyanobacteria,44,1005,4.378109453
> > CID_4,Acidobacteria,28,1005,2.786069652
> > CID_4,Chloroflexi,24,1005,2.388059701
> > CID_4,Nitrospirae,21,1005,2.089552239
> > CID_4,Verrucomicrobia,12,1005,1.194029851
> > CID_4,Gemmatimonadetes,12,1005,1.194029851
> > CID_4,Firmicutes,7,1005,0.696517413
> > CID_4,Spirochaetes,5,1005,0.497512438
> > CID_4,Ignavibacteriae,5,1005,0.497512438
> > CID_4,Elusimicrobia,2,1005,0.199004975
> > CID_5,Proteobacteria,5002,11914,41.984220245
> > CID_5,Bacteroidetes,1512,11914,12.690951821
> > CID_5,Verrucomicrobia,1361,11914,11.423535337
> > CID_5,Acidobacteria,1207,11914,10.130938392
> > CID_5,Cyanobacteria,721,11914,6.051703878
> > CID_5,Planctomycetes,635,11914,5.329864026
> > CID_5,Actinobacteria,398,11914,3.340607688
> > CID_5,Nitrospirae,314,11914,2.635554809
> > CID_5,Chloroflexi,313,11914,2.627161323
> > CID_5,Firmicutes,195,11914,1.636729898
> > CID_5,Gemmatimonadetes,129,11914,1.082759778
> > CID_5,Chlorobi,31,11914,0.260198086
> > CID_5,Armatimonadetes,22,11914,0.184656706
> > CID_5,Ignavibacteriae,21,11914,0.176263220
> > CID_5,Fusobacteria,14,11914,0.117508813
> > CID_5,Deinococcus-Thermus,10,11914,0.083934867
> > CID_5,Lentisphaerae,9,11914,0.075541380
> > CID_5,Elusimicrobia,7,11914,0.058754407
> > CID_5,Nitrospinae,7,11914,0.058754407
> > CID_5,Synergistetes,4,11914,0.033573947
> > CID_5,Spirochaetes,2,11914,0.016786973
> > CID_6,Cyanobacteria,6462,17852,36.197624916
> > CID_6,Proteobacteria,5036,17852,28.209724401
> > CID_6,Bacteroidetes,3906,17852,21.879901412
> > CID_6,Verrucomicrobia,1016,17852,5.691239077
> > CID_6,Acidobacteria,317,17852,1.775711405
> > CID_6,Actinobacteria,286,17852,1.602061394
> > CID_6,Firmicutes,234,17852,1.310777504
> > CID_6,Planctomycetes,134,17852,0.750616177
> > CID_6,Gemmatimonadetes,112,17852,0.627380686
> > CID_6,Spirochaetes,97,17852,0.543356487
> > CID_6,Chloroflexi,77,17852,0.431324221
> > CID_6,Lentisphaerae,56,17852,0.313690343
> > CID_6,Ignavibacteriae,35,17852,0.196056464
> > CID_6,Nitrospirae,23,17852,0.128837105
> > CID_6,Nitrospinae,19,17852,0.106430652
> > CID_6,Tenericutes,12,17852,0.067219359
> > CID_6,Chlorobi,8,17852,0.044812906
> > CID_6,Armatimonadetes,7,17852,0.039211293
> > CID_6,Fibrobacteres,7,17852,0.039211293
> > CID_6,Elusimicrobia,4,17852,0.022406453
> > CID_6,Fusobacteria,2,17852,0.011203227
> > CID_6,Deferribacteres,2,17852,0.011203227
> > CID_7,Cyanobacteria,11046,30425,36.305669680
> > CID_7,Proteobacteria,8418,30425,27.668036154
> > CID_7,Bacteroidetes,6197,30425,20.368118324
> > CID_7,Verrucomicrobia,1745,30425,5.735414955
> > CID_7,Firmicutes,732,30425,2.405916187
> > CID_7,Acidobacteria,582,30425,1.912900575
> > CID_7,Actinobacteria,365,30425,1.199671323
> > CID_7,Fusobacteria,344,30425,1.130649137
> > CID_7,Planctomycetes,253,30425,0.831552999
> > CID_7,Chloroflexi,221,30425,0.726376335
> > CID_7,Gemmatimonadetes,131,30425,0.430566968
> > CID_7,Spirochaetes,127,30425,0.417419885
> > CID_7,Lentisphaerae,88,30425,0.289235826
> > CID_7,Ignavibacteriae,69,30425,0.226787182
> > CID_7,Nitrospinae,37,30425,0.121610518
> > CID_7,Nitrospirae,21,30425,0.069022186
> > CID_7,Chlorobi,17,30425,0.055875103
> > CID_7,Elusimicrobia,15,30425,0.049301561
> > CID_7,Fibrobacteres,9,30425,0.029580937
> > CID_7,Armatimonadetes,4,30425,0.013147083
> > CID_7,Deferribacteres,4,30425,0.013147083
> > CID_8,Cyanobacteria,14446,43589,33.141388883
> > CID_8,Proteobacteria,13270,43589,30.443460506
> > CID_8,Bacteroidetes,8834,43589,20.266581018
> > CID_8,Verrucomicrobia,2529,43589,5.801922503
> > CID_8,Firmicutes,1176,43589,2.697928376
> > CID_8,Acidobacteria,780,43589,1.789442290
> > CID_8,Actinobacteria,542,43589,1.243432976
> > CID_8,Spirochaetes,406,43589,0.931427654
> > CID_8,Planctomycetes,295,43589,0.676776251
> > CID_8,Chloroflexi,277,43589,0.635481429
> > CID_8,Ignavibacteriae,243,43589,0.557480098
> > CID_8,Lentisphaerae,230,43589,0.527656060
> > CID_8,Gemmatimonadetes,162,43589,0.371653399
> > CID_8,Fusobacteria,106,43589,0.243180619
> > CID_8,Tenericutes,57,43589,0.130766937
> > CID_8,Nitrospirae,51,43589,0.117001996
> > CID_8,Chlorobi,50,43589,0.114707839
> > CID_8,Nitrospinae,36,43589,0.082589644
> > CID_8,Fibrobacteres,34,43589,0.078001331
> > CID_8,Elusimicrobia,29,43589,0.066530547
> > CID_8,Armatimonadetes,19,43589,0.043588979
> > CID_8,Aquificae,8,43589,0.018353254
> > CID_8,Deferribacteres,7,43589,0.016059097
> > CID_8,Dictyoglomi,2,43589,0.004588314
> > CID_9,Proteobacteria,26463,77120,34.314056017
> > CID_9,Cyanobacteria,20329,77120,26.360217842
> > CID_9,Bacteroidetes,15956,77120,20.689834025
> > CID_9,Verrucomicrobia,3323,77120,4.308869295
> > CID_9,Firmicutes,2726,77120,3.534751037
> > CID_9,Spirochaetes,1644,77120,2.131742739
> > CID_9,Acidobacteria,1634,77120,2.118775934
> > CID_9,Actinobacteria,1200,77120,1.556016598
> > CID_9,Chloroflexi,1128,77120,1.462655602
> > CID_9,Planctomycetes,872,77120,1.130705394
> > CID_9,Ignavibacteriae,578,77120,0.749481328
> > CID_9,Lentisphaerae,264,77120,0.342323651
> > CID_9,Gemmatimonadetes,263,77120,0.341026971
> > CID_9,Fibrobacteres,170,77120,0.220435685
> > CID_9,Nitrospirae,148,77120,0.191908714
> > CID_9,Nitrospinae,136,77120,0.176348548
> > CID_9,Chlorobi,74,77120,0.095954357
> > CID_9,Tenericutes,71,77120,0.092064315
> > CID_9,Elusimicrobia,46,77120,0.059647303
> > CID_9,Armatimonadetes,27,77120,0.035010373
> > CID_9,Fusobacteria,25,77120,0.032417012
> > CID_9,Aquificae,13,77120,0.016856846
> > CID_9,Synergistetes,12,77120,0.015560166
> > CID_9,Deferribacteres,8,77120,0.010373444
> > CID_9,Thermotogae,7,77120,0.009076763
> > CID_9,Chrysiogenetes,3,77120,0.003890041
> > ")
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Dec  7 19:15:36 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 7 Dec 2014 10:15:36 -0800
Subject: [R] bad STATA dataset import, how to change value labels
In-Reply-To: <CAB-RVxTPO9c94zBBm_sQJvQygeiA7irQGtUqy1ERnHvNUdLP3A@mail.gmail.com>
References: <CAB-RVxSTY1i1B5vtMenNCEHY1EkA1Q0jEnwsK=zWeVywOgaL=g@mail.gmail.com>
	<6A2ACD54-32A2-4EFE-877F-3C9AA8A186E8@comcast.net>
	<CAB-RVxTPO9c94zBBm_sQJvQygeiA7irQGtUqy1ERnHvNUdLP3A@mail.gmail.com>
Message-ID: <794C15EF-1794-481B-8B32-8B24883D2B3F@comcast.net>


On Dec 6, 2014, at 6:37 PM, Edoardo Prestianni wrote:

> Excuse the inaccuracy, the warning is "value label missing". the same variable is considered as factor (w/ values ranging from a to b) in one dataset, as int in another. I want it to be a factor in both.

So, you are importing two different Stata formatted files an in only one of them is the warning being emitted?

> 
> I think I am missing a package, the output is. 
> 
> Error in head(dfrm[, "variable"]) : object 'dfrm' not found

My intent was for you to substitute the name of your dataframe for the token `dfrm`.

head(yourDataObject[, "yourVariableNameInQuotes"])

-- 
David.

> 
> 
> 2014-12-07 3:14 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Dec 6, 2014, at 3:54 PM, Edoardo Prestianni wrote:
> 
> > hello,
> >
> > I have imported a couple of .dta datasets, but a variable, instead of being
> > labeled as factor (w/ values ranging from a to b) is labeled as integer.
> >
> > How can I fix this? I am sorry if it is a rookie question but I don't find
> > the command googling.
> 
> What "command"?
> 
> The word "labeled" is not an R term unless on is talking about the labels of factor variables in which case there is no problem. Factors have mode integer.
> 
> Post the results of dput(head( dfrm[ , "varname"]))
> 
> --
> David.
> 
> 
> > Thanks everyone for their help,
> >
> > --
> > Edoardo Prestianni
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 
> -- 
> Edoardo Prestianni

David Winsemius
Alameda, CA, USA


From k-aravindhan1 at ti.com  Sun Dec  7 15:46:13 2014
From: k-aravindhan1 at ti.com (Aravindhan, K)
Date: Sun, 7 Dec 2014 14:46:13 +0000
Subject: [R] boot strapping poisson getting warnings and negative values
In-Reply-To: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E874509959@DBDE04.ent.ti.com>
References: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>
	<EF1CB4B85C8C3D41B75FB3A4E4EEA4E874509959@DBDE04.ent.ti.com>
Message-ID: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E87453CDBB@DBDE04.ent.ti.com>

Team,
I am giving the exact code that produces the error.  Please see below.  Can anyone please help ?

Thanks
Aravindhan

PROGRAM
-------------------------------------------------------------------------------------------
rm(list = ls())
x<-c(1,14,49,26,4,10,25,36,79,15)
y<-c(1,5,32,8,4,23,399,79,341,2)
db = data.frame(x,y)
library(car)
db = data.frame(x,y)
print("---------------------------------------------------------==")
summary(m1 <- glm(y~0+x, family = poisson()))
mod.db.hub<-glm(y~0+x,family="poisson",data=db)
fit<-fitted(mod.db.hub)
e<-residuals(mod.db.hub)
X<-model.matrix(mod.db.hub)
boot.huber.fixed<-function(data,indices,maxit=20) {
Y<-fit+e[indices]
mod<-glm(Y~X+0,family="poisson",maxit=maxit)
coefficients(mod)
}
library(boot)
db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
db.fix.boot
boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
----------------------------------------------------------------------------------------

The error I get is 
------------------------------------------------------------------------------------------

> db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
Error in eval(expr, envir, enclos) : 
  negative values not allowed for the 'Poisson' family
In addition: Warning messages:
1: In dpois(y, mu, log = TRUE) : non-integer x = 1.002114
2: In dpois(y, mu, log = TRUE) : non-integer x = 4.050746
3: In dpois(y, mu, log = TRUE) : non-integer x = 44.219309
4: In dpois(y, mu, log = TRUE) : non-integer x = 7.786340
5: In dpois(y, mu, log = TRUE) : non-integer x = 3.189963
6: In dpois(y, mu, log = TRUE) : non-integer x = 10.348190
7: In dpois(y, mu, log = TRUE) : non-integer x = 56.408862
8: In dpois(y, mu, log = TRUE) : non-integer x = 27.751783
9: In dpois(y, mu, log = TRUE) : non-integer x = 480.383098
10: In dpois(y, mu, log = TRUE) : non-integer x = 2.497504
> db.fix.boot
Error: object 'db.fix.boot' not found
> boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
Error in boot.ci(db.fix.boot, index = 1, type = c("bca", "perc", "poisson")) : 
  object 'db.fix.boot' not found
------------------------------------------------------------------------------------------


-----Original Message-----
From: Aravindhan, K 
Sent: Saturday, November 15, 2014 7:59 AM
To: r-help at r-project.org
Subject: RE: [R] boot strapping poisson getting warnings and negative values

Team,
Has anyone looked at this question from me ?  it will help me immensely if someone can provide an answer to this.

Thanks
Aravindhan

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of K Aravindhan
Sent: Friday, August 08, 2014 7:42 PM
To: r-help at r-project.org
Subject: [R] boot strapping poisson getting warnings and negative values

Dear Team,
I am getting this error while running the boot-strapping functions. 

==================================================
mod.db.hub<-glm(TOTAL~1+IPD,family="poisson",data=db)
fit<-fitted(mod.db.hub)
e<-residuals(mod.db.hub)
X<-model.matrix(mod.db.hub)
boot.huber.fixed<-function(data,indices,maxit=20) { Y<-fit+e[indices]
mod<-glm(Y~X-1,family="poisson",maxit=maxit)
coefficients(mod)
}
library(boot)
db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
db.fix.boot
boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
boot.ci(db.fix.boot,index=2,type=c("bca","perc","poisson"))
==================================================

Error in eval(expr, envir, enclos) : 
negative values not allowed for the 'Poisson' family In addition: Warning messages:
1: In dpois(y, mu, log = TRUE) : non-integer x = 25.006412
2: In dpois(y, mu, log = TRUE) : non-integer x = 26.969411
3: In dpois(y, mu, log = TRUE) : non-integer x = 66.352323
4: In dpois(y, mu, log = TRUE) : non-integer x = 61.083519
5: In dpois(y, mu, log = TRUE) : non-integer x = 20.596770
6: In dpois(y, mu, log = TRUE) : non-integer x = 43.428258
7: In dpois(y, mu, log = TRUE) : non-integer x = 1108.263554
8: In dpois(y, mu, log = TRUE) : non-integer x = 61.937982
9: In dpois(y, mu, log = TRUE) : non-integer x = 419.991213
10: In dpois(y, mu, log = TRUE) : non-integer x = 47.369133

Can you explain to me how to get rid of these ?

Thanks
Aravindhan

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From samuel.reuther at web.de  Sun Dec  7 11:17:52 2014
From: samuel.reuther at web.de (Samuel Reuther)
Date: Sun, 7 Dec 2014 11:17:52 +0100
Subject: [R] Which is the final model for a Boosted Regression Trees (GBM)?
Message-ID: <002901d01207$0ff65fa0$2fe31ee0$@web.de>

Hi Kristi,

 

One year later I've been with the same question and found a solution with
the help (see plot.gbm: Marginal plots of fitted gbm objects.)

 

If your GBM-model is gbm1 <-   gbm(y ~ x1+x2, .) one can get the
coefficients for each x with:

 

print(plot(gbm1, i.var=1, n.trees=1000, return.grid=TRUE)) print(plot(gbm1,
2, return.grid=TRUE))

print(plot(gbm1, i.var=2, n.trees=1000, return.grid=TRUE)) print(plot(gbm1,
2, return.grid=TRUE))

 

This includes all trees from 1 to 1000. Without "return.grid=TRUE" the
graphic is shown. Additionally one can see the coefficients for up to 3-way
interactions:

 

print(plot(gbm1, i.var=c(1,2), n.trees=1000, return.grid=TRUE))
print(plot(gbm1, 2, return.grid=TRUE))

 

Hope that helps for others searching for the same thing!

Samuel

 


	[[alternative HTML version deleted]]


From lists at revelle.net  Sun Dec  7 19:31:59 2014
From: lists at revelle.net (William Revelle)
Date: Sun, 7 Dec 2014 12:31:59 -0600
Subject: [R] Difference in cummulative variance depending on print
	command
In-Reply-To: <17781317-BE9B-4FB4-AB6A-8F65C9B5F542@gmail.com>
References: <5481A4DF.4060908@gmx.de>
	<17781317-BE9B-4FB4-AB6A-8F65C9B5F542@gmail.com>
Message-ID: <DED12903-53F3-4C1E-816D-7AB7FFB0DD10@revelle.net>

Dear Rena,

As Peter points out, it is better to ask the maintainer of the program for detailed questions.  

  As Peter correctly surmised, print.psych (which is used to print the output from the fa function), knows that you have an oblique solution and is reporting the amount of variance associated with the oblique factors (taking into account that they are correlated).  The default print method assumes orthogonal factors.

If you compare the total amount of variance accounted for (cumulative Var) for all of the factors (.59) , this will match that found using orthogonal rotations, while the default print method of the loadings does not.

Bill

> On Dec 6, 2014, at 10:48 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Firstly, there is no fa() function in base R. There is one in package psych(), which has a maintainer, etc.
> 
> I guess that it is because fa() does a non-orthogonal factor rotation and its print method knows about it, whereas the default print method for loadings assumes that rotations are orthogonal.
> 
> - Peter D.
> 
>> On 05 Dec 2014, at 13:28 , Rena B?sch <rena.buesch at gmx.de> wrote:
>> 
>> Hello,
>> I am trying a factor analysis via R.
>> When running the pricipal axis analysis I do get different tables depending
>> on the print command.
>> This is my factor analysis:
>> fa.pa_cor_3_2<- fa(ItemsCor_4, nfactors=3, fm="pa",rotate="oblimin")
>> 
>> To get the h2 I did the following print command:
>> print (fa.pa_cor_3_2, digits=2, cut=.3, sort=T)
>> To just get the loadings I did the following print command:
>> print (fa.pa_cor_3_2$loadings, digits=2, cutoff=.3, sort=T)
>> 
>> The result of the first print is the following Eigenvalue-cumulative
>> variance table:
>>                   PA1   PA2  PA3
>> SS loadings    20.59 18.16 5.03
>> Proportion Var  0.28  0.25 0.07
>> Cumulative Var  0.28  0.52 0.59
>> 
>> With the second print command I get a different table:
>>                   PA1   PA2  PA3
>> SS loadings    17.63 15.12 3.14
>> Proportion Var  0.24  0.20 0.04
>> Cumulative Var  0.24  0.44 0.49
>> 
>> The loadings are the same for both commands. There is just this slight
>> difference in the cumulative Var.
>> 
>> Does anyone have an idea of a cause for the difference? What can I report?
>> Did I post enough information to fully understand my problem?
>> Thanks in Advance
>> Rena
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 5 minutes to midnight	   http://www.thebulletin.org


From alemu.tadesse at gmail.com  Sun Dec  7 20:25:10 2014
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Sun, 7 Dec 2014 12:25:10 -0700
Subject: [R] date time problem
Message-ID: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>

Dear R users

I am puzzled by the following result from R script. I am trying to convert
local time to UTC time. Time zone is -5, therefore I used the following
approach.

Below is the script.
> Corrected_SA_data$date_time[k-1]
[1] "2007-03-11 01:00:00"
> Corrected_SA_data$TZ[k-1]
[1] -5
> Corrected_SA_data$date_time[k-1]-Corrected_SA_data$TZ[k-1]*3600
[1] "2007-03-11 07:00:00 MDT"

I was expecting this last value to be something like "2007-03-11 06:00:00
UTC"

Please correct me if I ma wrong.

On the other hand I have
> Corrected_SA_data$date_time[k]
[1] "2007-03-11 02:00:00"
> Corrected_SA_data$TZ[k]
[1] -5
> Corrected_SA_data$date_time[k]-Corrected_SA_data$TZ[k]*3600
[1] NA

I am not sure why I am getting NA.

Thank you for your help.

Alemu

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec  7 21:13:59 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 7 Dec 2014 12:13:59 -0800 (PST)
Subject: [R] Condensing data.frame
In-Reply-To: <9E73F88F04AA25408DBB58FB730BA65329B150F3@AUSP01DAG0503.collaborationhost.net>
References: <CAPoqHzriibZVebOe803VnUFCYH3VnLo_FPi5Y1O=MvS3vntU8A@mail.gmail.com>
	<54848381.7000300@mail.usask.ca>
	<9E73F88F04AA25408DBB58FB730BA65329B150F3@AUSP01DAG0503.collaborationhost.net>
Message-ID: <alpine.BSF.2.00.1412071145150.21505@pedal.dcn.davis.ca.us>

dplyr version (good for large datasets):

library(dplyr)

# if original example dat data.frame is used
# using read.csv with as.is=TRUE or stringsAsFactors=FALSE is better
dat$tax_name <- as.character( dat$tax_name )

# dplyr pipe chain
(   dat
%>% arrange( site, desc( countPercentage ))
%>% group_by( site )
%>% do( rbind_list( .[ 1:6, c( "site", "tax_name", "countPercentage" ) ]
                   , data.frame( site=.[ 1, "site" ]
                               , tax_name="Other"
                               , countPercentage=sum( .[ -(1:6)
                                                       , "countPercentage" ] )
                               )
                   )
       )
%>% as.data.frame
)

#note that this will break if there are fewer than 7 rows for any site

On Sun, 7 Dec 2014, John Posner wrote:

> Here's a solution using the plyr library:
>
> ####################
> library(plyr)
>
> dat <- read.table(header=TRUE, sep=",", as.is=TRUE,   ###### <---- as.is=TRUE
> text="site,tax_name,count,countTotal,countPercentage
> CID_1,Cyanobacteria,46295,123509,37.483098398
> CID_1,Proteobacteria,36120,123509,29.244832360
> CID_1,Bacteroidetes,19546,123509,15.825567368
> CID_1,Verrucomicrobia,7886,123509,6.384959801
> CID_1,Firmicutes,2843,123509,2.301856545
>   ... <lines deleted here>
> CID_9,Armatimonadetes,27,77120,0.035010373
> CID_9,Fusobacteria,25,77120,0.032417012
> CID_9,Aquificae,13,77120,0.016856846
> CID_9,Synergistetes,12,77120,0.015560166
> CID_9,Deferribacteres,8,77120,0.010373444
> CID_9,Thermotogae,7,77120,0.009076763
> CID_9,Chrysiogenetes,3,77120,0.003890041.
> ")
>
> summ_cid = function(frm) {
>  # grab at most 6 rows from data frame
>  toprows = head(frm, 6)
>  # add a 7th row
>  toprows[nrow(toprows)+1,] = c(toprows[1,1], "", NA, NA, sum(toprows$countPercentage))
>  # all done
>  return(toprows)
> }
>
> result = ddply(dat, "site", summ_cid)
> ####################
>
> Notes:
>
> 1. I needed to add the as.is=TRUE option to read.table()
> 2. The invocation of ddply() does *not* use summarize()
> 3. Because there is no use of summarize(), I have not figured out how to use the dplyr package in this context.
>
> -John
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chel Hee
>> Lee
>> Sent: Sunday, December 07, 2014 11:43 AM
>> To: Morway, Eric; R mailing list
>> Subject: Re: [R] Condensing data.frame
>>
>> > datBySite <- split(dat, dat$site)
>> > output <- lapply(datBySite, function(x){
>> + x$idx <- seq_len(nrow(x))
>> + x$grp <- ifelse(x$idx < 7, x$idx, 7)
>> + rval <- tapply(x$countPercentage, x$grp, sum) x$grp <- x$count <-
>> + x$countTotal <- NULL x <- x[seq_len(7), ] x$tax_name <-
>> + as.character(x$tax_name) x$tax_name[7] <- "Others"
>> + x$new <- rval
>> + return(x)
>> + })
>> >
>> > head(do.call(rbind, output), 14)
>>              site        tax_name countPercentage idx       new
>> CID_1.1    CID_1   Cyanobacteria       37.483098   1 37.483098
>> CID_1.2    CID_1  Proteobacteria       29.244832   2 29.244832
>> CID_1.3    CID_1   Bacteroidetes       15.825567   3 15.825567
>> CID_1.4    CID_1 Verrucomicrobia        6.384960   4  6.384960
>> CID_1.5    CID_1      Firmicutes        2.301857   5  2.301857
>> CID_1.6    CID_1   Acidobacteria        2.075152   6  2.075152
>> CID_1.7    CID_1          Others        1.675182   7  6.684533
>> CID_10.27 CID_10  Proteobacteria       35.366606   1 35.366606
>> CID_10.28 CID_10   Bacteroidetes       25.188484   2 25.188484
>> CID_10.29 CID_10   Cyanobacteria       23.294828   3 23.294828
>> CID_10.30 CID_10 Verrucomicrobia        6.970592   4  6.970592
>> CID_10.31 CID_10   Acidobacteria        1.988448   5  1.988448
>> CID_10.32 CID_10  Actinobacteria        1.644548   6  1.644548
>> CID_10.33 CID_10          Others        1.582823   7  5.546493
>> >
>>
>> I hope this helps.
>>
>> Chel Hee Lee
>>
>> On 12/07/2014 08:21 AM, Morway, Eric wrote:
>>> Using the dataset "dat" (found below), I'm seeking a way to condense
>>> down the data.frame such that each "site" (i.e., "CID_1"..."CID_13")
>>> has a maximum of 7 rows of post-processed data, where the first 6 have
>>> the highest "countPercentage" and the 7th row is the sum of
>> "countPercentage"
>>> from all other rows within that "site", and it is assigned the name
>>> "Other".  So, for the first two sites in the provided data.frame,
>>> CID_1 & CID_10, they would reduce to:
>>>
>>> CID_1 Cyanobacteria     37.48
>>> CID_1 Proteobacteria     29.24
>>> CID_1 Bacteroidetes      15.83
>>> CID_1 Verrucomicrobia  6.38
>>> CID_1 Firmicutes          2.30
>>> CID_1 Acidobacteria      2.08
>>> CID_1 Other                6.68
>>> CID_10 Proteobacteria     35.37
>>> CID_10 Bacteroidetes      25.19
>>> CID_10 Cyanobacteria     23.29
>>> CID_10 Verrucomicrobia  6.97
>>> CID_10 Acidobacteria      1.99
>>> CID_10 Actinobacteria     1.64
>>> CID_10 Other                 5.55
>>>
>>>
>>> dat <- read.table(header=TRUE, sep=",",
>>> text="site,tax_name,count,countTotal,countPercentage
>>> CID_1,Cyanobacteria,46295,123509,37.483098398
>>> CID_1,Proteobacteria,36120,123509,29.244832360
>>> CID_1,Bacteroidetes,19546,123509,15.825567368
>>> CID_1,Verrucomicrobia,7886,123509,6.384959801
>>> CID_1,Firmicutes,2843,123509,2.301856545
>>> CID_1,Acidobacteria,2563,123509,2.075152418
>>> CID_1,Actinobacteria,2069,123509,1.675181566
>>> CID_1,Planctomycetes,1481,123509,1.199102899
>>> CID_1,Chloroflexi,1181,123509,0.956205621
>>> CID_1,Gemmatimonadetes,956,123509,0.774032662
>>> CID_1,Spirochaetes,688,123509,0.557044426
>>> CID_1,Lentisphaerae,526,123509,0.425879895
>>> CID_1,Ignavibacteriae,324,123509,0.262329061
>>> CID_1,Chlorobi,238,123509,0.192698508
>>> CID_1,Nitrospirae,230,123509,0.186221247
>>> CID_1,Nitrospinae,169,123509,0.136832134
>>> CID_1,Elusimicrobia,131,123509,0.106065145
>>> CID_1,Tenericutes,114,123509,0.092300966
>>> CID_1,Fibrobacteres,72,123509,0.058295347
>>> CID_1,Thermotogae,21,123509,0.017002810
>>> CID_1,Fusobacteria,21,123509,0.017002810
>>> CID_1,Armatimonadetes,15,123509,0.012144864
>>> CID_1,Synergistetes,10,123509,0.008096576
>>> CID_1,Deinococcus-Thermus,6,123509,0.004857946
>>> CID_1,Deferribacteres,2,123509,0.001619315
>>> CID_1,Caldiserica,2,123509,0.001619315
>>> CID_10,Proteobacteria,16043,45362,35.366606411
>>> CID_10,Bacteroidetes,11426,45362,25.188483753
>>> CID_10,Cyanobacteria,10567,45362,23.294828270
>>> CID_10,Verrucomicrobia,3162,45362,6.970592126
>>> CID_10,Acidobacteria,902,45362,1.988448481
>>> CID_10,Actinobacteria,746,45362,1.644548300
>>> CID_10,Firmicutes,718,45362,1.582822627
>>> CID_10,Gemmatimonadetes,358,45362,0.789206825
>>> CID_10,Planctomycetes,357,45362,0.787002337
>>> CID_10,Chloroflexi,265,45362,0.584189410
>>> CID_10,Spirochaetes,235,45362,0.518054759
>>> CID_10,Ignavibacteriae,177,45362,0.390194436
>>> CID_10,Lentisphaerae,108,45362,0.238084741
>>> CID_10,Nitrospinae,75,45362,0.165336625
>>> CID_10,Nitrospirae,58,45362,0.127860324
>>> CID_10,Chlorobi,44,45362,0.096997487
>>> CID_10,Elusimicrobia,28,45362,0.061725673
>>> CID_10,Fibrobacteres,26,45362,0.057316697
>>> CID_10,Armatimonadetes,15,45362,0.033067325
>>> CID_10,Deinococcus-Thermus,13,45362,0.028658348
>>> CID_10,Tenericutes,10,45362,0.022044883
>>> CID_10,Synergistetes,9,45362,0.019840395
>>> CID_10,Fusobacteria,9,45362,0.019840395
>>> CID_10,Deferribacteres,6,45362,0.013226930
>>> CID_10,Thermotogae,3,45362,0.006613465
>>> CID_10,Caldiserica,2,45362,0.004408977
>>> CID_11,Proteobacteria,10019,31387,31.920858954
>>> CID_11,Cyanobacteria,8811,31387,28.072131774
>>> CID_11,Bacteroidetes,7930,31387,25.265237200
>>> CID_11,Verrucomicrobia,1750,31387,5.575556759
>>> CID_11,Firmicutes,806,31387,2.567942142
>>> CID_11,Acidobacteria,548,31387,1.745945774
>>> CID_11,Actinobacteria,434,31387,1.382738076
>>> CID_11,Chloroflexi,203,31387,0.646764584
>>> CID_11,Planctomycetes,197,31387,0.627648389
>>> CID_11,Gemmatimonadetes,192,31387,0.611718227
>>> CID_11,Ignavibacteriae,87,31387,0.277184822
>>> CID_11,Spirochaetes,80,31387,0.254882595
>>> CID_11,Tenericutes,71,31387,0.226208303
>>> CID_11,Fusobacteria,67,31387,0.213464173
>>> CID_11,Lentisphaerae,54,31387,0.172045751
>>> CID_11,Chlorobi,40,31387,0.127441297
>>> CID_11,Nitrospinae,33,31387,0.105139070
>>> CID_11,Armatimonadetes,22,31387,0.070092714
>>> CID_11,Fibrobacteres,15,31387,0.047790487
>>> CID_11,Nitrospirae,13,31387,0.041418422
>>> CID_11,Elusimicrobia,13,31387,0.041418422
>>> CID_11,Deinococcus-Thermus,2,31387,0.006372065
>>> CID_12,Cyanobacteria,241,644,37.422360248
>>> CID_12,Bacteroidetes,210,644,32.608695652
>>> CID_12,Proteobacteria,118,644,18.322981366
>>> CID_12,Verrucomicrobia,38,644,5.900621118
>>> CID_12,Acidobacteria,11,644,1.708074534
>>> CID_12,Ignavibacteriae,6,644,0.931677019
>>> CID_12,Lentisphaerae,5,644,0.776397516
>>> CID_12,Firmicutes,5,644,0.776397516
>>> CID_12,Planctomycetes,3,644,0.465838509
>>> CID_12,Fusobacteria,3,644,0.465838509
>>> CID_12,Tenericutes,2,644,0.310559006
>>> CID_12,Actinobacteria,2,644,0.310559006
>>> CID_13,Cyanobacteria,8581,25530,33.611437524
>>> CID_13,Bacteroidetes,6878,25530,26.940853897
>>> CID_13,Proteobacteria,5341,25530,20.920485703
>>> CID_13,Verrucomicrobia,1244,25530,4.872698786
>>> CID_13,Firmicutes,1148,25530,4.496670584
>>> CID_13,Acidobacteria,548,25530,2.146494320
>>> CID_13,Spirochaetes,477,25530,1.868390129
>>> CID_13,Ignavibacteriae,298,25530,1.167254211
>>> CID_13,Actinobacteria,227,25530,0.889150020
>>> CID_13,Planctomycetes,184,25530,0.720720721
>>> CID_13,Chloroflexi,181,25530,0.708969839
>>> CID_13,Gemmatimonadetes,121,25530,0.473952213
>>> CID_13,Lentisphaerae,93,25530,0.364277321
>>> CID_13,Tenericutes,61,25530,0.238934587
>>> CID_13,Fibrobacteres,47,25530,0.184097141
>>> CID_13,Nitrospinae,28,25530,0.109674892
>>> CID_13,Nitrospirae,26,25530,0.101840971
>>> CID_13,Chlorobi,18,25530,0.070505288
>>> CID_13,Elusimicrobia,13,25530,0.050920486
>>> CID_13,Synergistetes,8,25530,0.031335684
>>> CID_13,Fusobacteria,4,25530,0.015667842
>>> CID_13,Deinococcus-Thermus,2,25530,0.007833921
>>> CID_13,Thermotogae,2,25530,0.007833921
>>> CID_2,Cyanobacteria,43812,94826,46.202518297
>>> CID_2,Proteobacteria,22180,94826,23.390209436
>>> CID_2,Bacteroidetes,16993,94826,17.920190665
>>> CID_2,Verrucomicrobia,4779,94826,5.039757029
>>> CID_2,Acidobacteria,1728,94826,1.822285027
>>> CID_2,Firmicutes,1385,94826,1.460569886
>>> CID_2,Planctomycetes,815,94826,0.859468922
>>> CID_2,Actinobacteria,677,94826,0.713939215
>>> CID_2,Gemmatimonadetes,625,94826,0.659101934
>>> CID_2,Chloroflexi,416,94826,0.438698247
>>> CID_2,Spirochaetes,415,94826,0.437643684
>>> CID_2,Lentisphaerae,221,94826,0.233058444
>>> CID_2,Ignavibacteriae,180,94826,0.189821357
>>> CID_2,Fibrobacteres,155,94826,0.163457280
>>> CID_2,Chlorobi,112,94826,0.118111067
>>> CID_2,Elusimicrobia,111,94826,0.117056503
>>> CID_2,Tenericutes,75,94826,0.079092232
>>> CID_2,Nitrospinae,40,94826,0.042182524
>>> CID_2,Nitrospirae,31,94826,0.032691456
>>> CID_2,Deinococcus-Thermus,17,94826,0.017927573
>>> CID_2,Armatimonadetes,17,94826,0.017927573
>>> CID_2,Synergistetes,16,94826,0.016873010
>>> CID_2,Fusobacteria,15,94826,0.015818446
>>> CID_2,Deferribacteres,7,94826,0.007381942
>>> CID_2,Caldiserica,2,94826,0.002109126
>>> CID_2,Thermotogae,2,94826,0.002109126
>>> CID_3,Cyanobacteria,18888,46181,40.899937204
>>> CID_3,Proteobacteria,12532,46181,27.136701241
>>> CID_3,Bacteroidetes,9070,46181,19.640111734
>>> CID_3,Verrucomicrobia,2291,46181,4.960914662
>>> CID_3,Acidobacteria,689,46181,1.491955566
>>> CID_3,Firmicutes,631,46181,1.366362790
>>> CID_3,Actinobacteria,470,46181,1.017734566
>>> CID_3,Spirochaetes,366,46181,0.792533726
>>> CID_3,Planctomycetes,326,46181,0.705918018
>>> CID_3,Chloroflexi,282,46181,0.610640740
>>> CID_3,Gemmatimonadetes,194,46181,0.420086183
>>> CID_3,Fibrobacteres,116,46181,0.251185552
>>> CID_3,Ignavibacteriae,109,46181,0.236027804
>>> CID_3,Nitrospinae,46,46181,0.099608064
>>> CID_3,Nitrospirae,44,46181,0.095277279
>>> CID_3,Tenericutes,40,46181,0.086615708
>>> CID_3,Lentisphaerae,38,46181,0.082284922
>>> CID_3,Chlorobi,16,46181,0.034646283
>>> CID_3,Elusimicrobia,14,46181,0.030315498
>>> CID_3,Fusobacteria,10,46181,0.021653927
>>> CID_3,Armatimonadetes,7,46181,0.015157749
>>> CID_3,Synergistetes,2,46181,0.004330785
>>> CID_4,Proteobacteria,433,1005,43.084577114
>>> CID_4,Bacteroidetes,301,1005,29.950248756
>>> CID_4,Actinobacteria,111,1005,11.044776119
>>> CID_4,Cyanobacteria,44,1005,4.378109453
>>> CID_4,Acidobacteria,28,1005,2.786069652
>>> CID_4,Chloroflexi,24,1005,2.388059701
>>> CID_4,Nitrospirae,21,1005,2.089552239
>>> CID_4,Verrucomicrobia,12,1005,1.194029851
>>> CID_4,Gemmatimonadetes,12,1005,1.194029851
>>> CID_4,Firmicutes,7,1005,0.696517413
>>> CID_4,Spirochaetes,5,1005,0.497512438
>>> CID_4,Ignavibacteriae,5,1005,0.497512438
>>> CID_4,Elusimicrobia,2,1005,0.199004975
>>> CID_5,Proteobacteria,5002,11914,41.984220245
>>> CID_5,Bacteroidetes,1512,11914,12.690951821
>>> CID_5,Verrucomicrobia,1361,11914,11.423535337
>>> CID_5,Acidobacteria,1207,11914,10.130938392
>>> CID_5,Cyanobacteria,721,11914,6.051703878
>>> CID_5,Planctomycetes,635,11914,5.329864026
>>> CID_5,Actinobacteria,398,11914,3.340607688
>>> CID_5,Nitrospirae,314,11914,2.635554809
>>> CID_5,Chloroflexi,313,11914,2.627161323
>>> CID_5,Firmicutes,195,11914,1.636729898
>>> CID_5,Gemmatimonadetes,129,11914,1.082759778
>>> CID_5,Chlorobi,31,11914,0.260198086
>>> CID_5,Armatimonadetes,22,11914,0.184656706
>>> CID_5,Ignavibacteriae,21,11914,0.176263220
>>> CID_5,Fusobacteria,14,11914,0.117508813
>>> CID_5,Deinococcus-Thermus,10,11914,0.083934867
>>> CID_5,Lentisphaerae,9,11914,0.075541380
>>> CID_5,Elusimicrobia,7,11914,0.058754407
>>> CID_5,Nitrospinae,7,11914,0.058754407
>>> CID_5,Synergistetes,4,11914,0.033573947
>>> CID_5,Spirochaetes,2,11914,0.016786973
>>> CID_6,Cyanobacteria,6462,17852,36.197624916
>>> CID_6,Proteobacteria,5036,17852,28.209724401
>>> CID_6,Bacteroidetes,3906,17852,21.879901412
>>> CID_6,Verrucomicrobia,1016,17852,5.691239077
>>> CID_6,Acidobacteria,317,17852,1.775711405
>>> CID_6,Actinobacteria,286,17852,1.602061394
>>> CID_6,Firmicutes,234,17852,1.310777504
>>> CID_6,Planctomycetes,134,17852,0.750616177
>>> CID_6,Gemmatimonadetes,112,17852,0.627380686
>>> CID_6,Spirochaetes,97,17852,0.543356487
>>> CID_6,Chloroflexi,77,17852,0.431324221
>>> CID_6,Lentisphaerae,56,17852,0.313690343
>>> CID_6,Ignavibacteriae,35,17852,0.196056464
>>> CID_6,Nitrospirae,23,17852,0.128837105
>>> CID_6,Nitrospinae,19,17852,0.106430652
>>> CID_6,Tenericutes,12,17852,0.067219359
>>> CID_6,Chlorobi,8,17852,0.044812906
>>> CID_6,Armatimonadetes,7,17852,0.039211293
>>> CID_6,Fibrobacteres,7,17852,0.039211293
>>> CID_6,Elusimicrobia,4,17852,0.022406453
>>> CID_6,Fusobacteria,2,17852,0.011203227
>>> CID_6,Deferribacteres,2,17852,0.011203227
>>> CID_7,Cyanobacteria,11046,30425,36.305669680
>>> CID_7,Proteobacteria,8418,30425,27.668036154
>>> CID_7,Bacteroidetes,6197,30425,20.368118324
>>> CID_7,Verrucomicrobia,1745,30425,5.735414955
>>> CID_7,Firmicutes,732,30425,2.405916187
>>> CID_7,Acidobacteria,582,30425,1.912900575
>>> CID_7,Actinobacteria,365,30425,1.199671323
>>> CID_7,Fusobacteria,344,30425,1.130649137
>>> CID_7,Planctomycetes,253,30425,0.831552999
>>> CID_7,Chloroflexi,221,30425,0.726376335
>>> CID_7,Gemmatimonadetes,131,30425,0.430566968
>>> CID_7,Spirochaetes,127,30425,0.417419885
>>> CID_7,Lentisphaerae,88,30425,0.289235826
>>> CID_7,Ignavibacteriae,69,30425,0.226787182
>>> CID_7,Nitrospinae,37,30425,0.121610518
>>> CID_7,Nitrospirae,21,30425,0.069022186
>>> CID_7,Chlorobi,17,30425,0.055875103
>>> CID_7,Elusimicrobia,15,30425,0.049301561
>>> CID_7,Fibrobacteres,9,30425,0.029580937
>>> CID_7,Armatimonadetes,4,30425,0.013147083
>>> CID_7,Deferribacteres,4,30425,0.013147083
>>> CID_8,Cyanobacteria,14446,43589,33.141388883
>>> CID_8,Proteobacteria,13270,43589,30.443460506
>>> CID_8,Bacteroidetes,8834,43589,20.266581018
>>> CID_8,Verrucomicrobia,2529,43589,5.801922503
>>> CID_8,Firmicutes,1176,43589,2.697928376
>>> CID_8,Acidobacteria,780,43589,1.789442290
>>> CID_8,Actinobacteria,542,43589,1.243432976
>>> CID_8,Spirochaetes,406,43589,0.931427654
>>> CID_8,Planctomycetes,295,43589,0.676776251
>>> CID_8,Chloroflexi,277,43589,0.635481429
>>> CID_8,Ignavibacteriae,243,43589,0.557480098
>>> CID_8,Lentisphaerae,230,43589,0.527656060
>>> CID_8,Gemmatimonadetes,162,43589,0.371653399
>>> CID_8,Fusobacteria,106,43589,0.243180619
>>> CID_8,Tenericutes,57,43589,0.130766937
>>> CID_8,Nitrospirae,51,43589,0.117001996
>>> CID_8,Chlorobi,50,43589,0.114707839
>>> CID_8,Nitrospinae,36,43589,0.082589644
>>> CID_8,Fibrobacteres,34,43589,0.078001331
>>> CID_8,Elusimicrobia,29,43589,0.066530547
>>> CID_8,Armatimonadetes,19,43589,0.043588979
>>> CID_8,Aquificae,8,43589,0.018353254
>>> CID_8,Deferribacteres,7,43589,0.016059097
>>> CID_8,Dictyoglomi,2,43589,0.004588314
>>> CID_9,Proteobacteria,26463,77120,34.314056017
>>> CID_9,Cyanobacteria,20329,77120,26.360217842
>>> CID_9,Bacteroidetes,15956,77120,20.689834025
>>> CID_9,Verrucomicrobia,3323,77120,4.308869295
>>> CID_9,Firmicutes,2726,77120,3.534751037
>>> CID_9,Spirochaetes,1644,77120,2.131742739
>>> CID_9,Acidobacteria,1634,77120,2.118775934
>>> CID_9,Actinobacteria,1200,77120,1.556016598
>>> CID_9,Chloroflexi,1128,77120,1.462655602
>>> CID_9,Planctomycetes,872,77120,1.130705394
>>> CID_9,Ignavibacteriae,578,77120,0.749481328
>>> CID_9,Lentisphaerae,264,77120,0.342323651
>>> CID_9,Gemmatimonadetes,263,77120,0.341026971
>>> CID_9,Fibrobacteres,170,77120,0.220435685
>>> CID_9,Nitrospirae,148,77120,0.191908714
>>> CID_9,Nitrospinae,136,77120,0.176348548
>>> CID_9,Chlorobi,74,77120,0.095954357
>>> CID_9,Tenericutes,71,77120,0.092064315
>>> CID_9,Elusimicrobia,46,77120,0.059647303
>>> CID_9,Armatimonadetes,27,77120,0.035010373
>>> CID_9,Fusobacteria,25,77120,0.032417012
>>> CID_9,Aquificae,13,77120,0.016856846
>>> CID_9,Synergistetes,12,77120,0.015560166
>>> CID_9,Deferribacteres,8,77120,0.010373444
>>> CID_9,Thermotogae,7,77120,0.009076763
>>> CID_9,Chrysiogenetes,3,77120,0.003890041
>>> ")
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jholtman at gmail.com  Sun Dec  7 21:45:54 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 7 Dec 2014 15:45:54 -0500
Subject: [R] date time problem
In-Reply-To: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>
References: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>
Message-ID: <CAAxdm-45ON4C2kqYMCe=15cwBPuaQ95O5D_razcEmGv26_jifA@mail.gmail.com>

I would use the 'lubridate' package for this:

    > z <- Sys.time()
    > z
    [1] "2014-12-07 15:43:50 EST"
    > require(lubridate)
    > with_tz(z, "UTC")
    [1] "2014-12-07 20:43:50 UTC"




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Dec 7, 2014 at 2:25 PM, Alemu Tadesse <alemu.tadesse at gmail.com>
wrote:

> Dear R users
>
> I am puzzled by the following result from R script. I am trying to convert
> local time to UTC time. Time zone is -5, therefore I used the following
> approach.
>
> Below is the script.
> > Corrected_SA_data$date_time[k-1]
> [1] "2007-03-11 01:00:00"
> > Corrected_SA_data$TZ[k-1]
> [1] -5
> > Corrected_SA_data$date_time[k-1]-Corrected_SA_data$TZ[k-1]*3600
> [1] "2007-03-11 07:00:00 MDT"
>
> I was expecting this last value to be something like "2007-03-11 06:00:00
> UTC"
>
> Please correct me if I ma wrong.
>
> On the other hand I have
> > Corrected_SA_data$date_time[k]
> [1] "2007-03-11 02:00:00"
> > Corrected_SA_data$TZ[k]
> [1] -5
> > Corrected_SA_data$date_time[k]-Corrected_SA_data$TZ[k]*3600
> [1] NA
>
> I am not sure why I am getting NA.
>
> Thank you for your help.
>
> Alemu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec  7 21:59:37 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 7 Dec 2014 12:59:37 -0800 (PST)
Subject: [R] date time problem
In-Reply-To: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>
References: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1412071226430.29350@pedal.dcn.davis.ca.us>

You have not provided a reproducible example, so anything I say could be 
wrong just due to misinterpretation. Please read [1] for suggestions on 
making your examples reproducible, particularly regarding the use of dput 
to provide example data. You have also posted in HTML format, 
which can cause additional scrambling of communications on this list.

>From the notation you are using, I would guess that "Corrected_SA_data" is 
a data frame containing columns "date_time" and "TZ" at a minimum. 
The "date_time" column could be a vector of class POSIXlt or POSIXct... 
except that I cannot reproduce such an object that doesn't print some 
kind of timezone indicator in its output. What version of R are you 
using? Note that such an object contains a tz attribute already, so unless 
you have already made sure that the date_time column knows about that 
timezone, they are probably unrelated to each other.

Note that any POSIXct object is internally represented as a specific 
instant of time. The tz attribute is only used to control how that time 
will be displayed. For example:

testtime3 <- as.POSIXct( rawtime1, tz="America/New_York" )
format( testtime3, tz="Etc/GMT", usetz=TRUE )

If you want the output to omit the timezone information you can omit the 
usetz argument:

format( testtime3, tz="Etc/GMT" )

If you have not yet, you should read [2]. Note that three-letter timezone 
indicators (even though they are given in OUTPUT!) are at best unreliable 
for use in specifying timezones in R... read ?timezones.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
[2] http://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf

On Sun, 7 Dec 2014, Alemu Tadesse wrote:

> Dear R users
>
> I am puzzled by the following result from R script. I am trying to convert
> local time to UTC time. Time zone is -5, therefore I used the following
> approach.
>
> Below is the script.
>> Corrected_SA_data$date_time[k-1]
> [1] "2007-03-11 01:00:00"
>> Corrected_SA_data$TZ[k-1]
> [1] -5
>> Corrected_SA_data$date_time[k-1]-Corrected_SA_data$TZ[k-1]*3600
> [1] "2007-03-11 07:00:00 MDT"
>
> I was expecting this last value to be something like "2007-03-11 06:00:00
> UTC"
>
> Please correct me if I ma wrong.
>
> On the other hand I have
>> Corrected_SA_data$date_time[k]
> [1] "2007-03-11 02:00:00"
>> Corrected_SA_data$TZ[k]
> [1] -5
>> Corrected_SA_data$date_time[k]-Corrected_SA_data$TZ[k]*3600
> [1] NA
>
> I am not sure why I am getting NA.
>
> Thank you for your help.
>
> Alemu
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From catalinroibu at gmail.com  Sun Dec  7 22:52:29 2014
From: catalinroibu at gmail.com (catalin roibu)
Date: Sun, 7 Dec 2014 23:52:29 +0200
Subject: [R] neighborhood competition index in r package
Message-ID: <CAEW+BDLk6nrs4tp_KrvdDspOibttNQ7_LPW0wsdFR_tWj4Bb0Q@mail.gmail.com>

Dear all!

Is there a R package to compute neighborhood competition index (Shutz,
Hegyi, and many index).

Thank you very much!

-- 
---
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro

	[[alternative HTML version deleted]]


From edoardo.prestianni at gmail.com  Mon Dec  8 02:48:10 2014
From: edoardo.prestianni at gmail.com (Edoardo Prestianni)
Date: Mon, 8 Dec 2014 02:48:10 +0100
Subject: [R] bad STATA dataset import, how to change value labels
In-Reply-To: <794C15EF-1794-481B-8B32-8B24883D2B3F@comcast.net>
References: <CAB-RVxSTY1i1B5vtMenNCEHY1EkA1Q0jEnwsK=zWeVywOgaL=g@mail.gmail.com>
	<6A2ACD54-32A2-4EFE-877F-3C9AA8A186E8@comcast.net>
	<CAB-RVxTPO9c94zBBm_sQJvQygeiA7irQGtUqy1ERnHvNUdLP3A@mail.gmail.com>
	<794C15EF-1794-481B-8B32-8B24883D2B3F@comcast.net>
Message-ID: <CAB-RVxRSY-X1sygZWOOtcra3Npk6cyHm-xR4-p4-U5Y+PXaddA@mail.gmail.com>

>> Excuse the inaccuracy, the warning is "value label missing". the same
variable is considered as factor (w/ values ranging from a to b) in one
dataset, as int in another. I want it to be a factor in both.

> So, you are importing two different Stata formatted files an in only one
of them is the warning being emitted?

Yes. But the variable is the very same variable, it's an
administrative/postal code given to each province of the country I'm
studying.
Factor have mode integer, but does that that "int" imply also "nominal" as
well? I thought I needed a "factor" for that.


One dataset emits a warning and shows the variable as "int". The other
seems fine, factor w/ values ranging from a to b,  but when I use the the
str(data$var) function, the value shown are weird, like 1011000, 10120000
... instead of being four-digit numbers.


>> Post the results of dput(head( dfrm[ , "varname"]))
>My intent was for you to substitute the name of your dataframe for the
token `dfrm`.

I apologize. The output is:

__________

[1] 1 1 1 1 1 1

__________


Thanks for your time







2014-12-07 19:15 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Dec 6, 2014, at 6:37 PM, Edoardo Prestianni wrote:
>
> > Excuse the inaccuracy, the warning is "value label missing". the same
> variable is considered as factor (w/ values ranging from a to b) in one
> dataset, as int in another. I want it to be a factor in both.
>
> So, you are importing two different Stata formatted files an in only one
> of them is the warning being emitted?
>
> >
> > I think I am missing a package, the output is.
> >
> > Error in head(dfrm[, "variable"]) : object 'dfrm' not found
>
> My intent was for you to substitute the name of your dataframe for the
> token `dfrm`.
>
> head(yourDataObject[, "yourVariableNameInQuotes"])
>
> --
> David.
>
> >
> >
> > 2014-12-07 3:14 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > On Dec 6, 2014, at 3:54 PM, Edoardo Prestianni wrote:
> >
> > > hello,
> > >
> > > I have imported a couple of .dta datasets, but a variable, instead of
> being
> > > labeled as factor (w/ values ranging from a to b) is labeled as
> integer.
> > >
> > > How can I fix this? I am sorry if it is a rookie question but I don't
> find
> > > the command googling.
> >
> > What "command"?
> >
> > The word "labeled" is not an R term unless on is talking about the
> labels of factor variables in which case there is no problem. Factors have
> mode integer.
> >
> > Post the results of dput(head( dfrm[ , "varname"]))
> >
> > --
> > David.
> >
> >
> > > Thanks everyone for their help,
> > >
> > > --
> > > Edoardo Prestianni
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> >
> >
> > --
> > Edoardo Prestianni
>
> David Winsemius
> Alameda, CA, USA
>
>


-- 
Edoardo Prestianni

	[[alternative HTML version deleted]]


From john.posner at MJBIOSTAT.COM  Mon Dec  8 03:01:43 2014
From: john.posner at MJBIOSTAT.COM (John Posner)
Date: Mon, 8 Dec 2014 02:01:43 +0000
Subject: [R] Condensing data.frame
In-Reply-To: <alpine.BSF.2.00.1412071145150.21505@pedal.dcn.davis.ca.us>
References: <CAPoqHzriibZVebOe803VnUFCYH3VnLo_FPi5Y1O=MvS3vntU8A@mail.gmail.com>
	<54848381.7000300@mail.usask.ca>
	<9E73F88F04AA25408DBB58FB730BA65329B150F3@AUSP01DAG0503.collaborationhost.net>
	<alpine.BSF.2.00.1412071145150.21505@pedal.dcn.davis.ca.us>
Message-ID: <9E73F88F04AA25408DBB58FB730BA65329B18155@AUSP01DAG0503.collaborationhost.net>

Looking over Jeff's "dplyr" solution, I see that I forgot this part of the original spec:

      where the first 6 have the highest "countPercentage"

So here's a corrected sum_cid() function for my "plyr" solution:

summ_cid = function(frm) {
  # sort by countPercentage
  sorted_frm = arrange(frm, desc(countPercentage))
  # grab at most 6 rows
  toprows = head(sorted_frm, 6)
  # add a 7th row
  toprows[nrow(toprows)+1,] = c(toprows[1,1], NA, NA, NA, sum(toprows$countPercentage))
  # all done
  return(toprows)
}

-John

> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Sunday, December 07, 2014 3:14 PM
> To: John Posner
> Cc: 'Chel Hee Lee'; Morway, Eric; R mailing list
> Subject: Re: [R] Condensing data.frame
> 
> dplyr version (good for large datasets):
> 
> library(dplyr)
> 
> # if original example dat data.frame is used # using read.csv with as.is=TRUE
> or stringsAsFactors=FALSE is better dat$tax_name <- as.character(
> dat$tax_name )
> 
> # dplyr pipe chain
> (   dat
> %>% arrange( site, desc( countPercentage )) %>% group_by( site ) %>% do(
> rbind_list( .[ 1:6, c( "site", "tax_name", "countPercentage" ) ]
>                    , data.frame( site=.[ 1, "site" ]
>                                , tax_name="Other"
>                                , countPercentage=sum( .[ -(1:6)
>                                                        , "countPercentage" ] )
>                                )
>                    )
>        )
> %>% as.data.frame
> )
> 
> #note that this will break if there are fewer than 7 rows for any site
> 
> On Sun, 7 Dec 2014, John Posner wrote:
> 
> > Here's a solution using the plyr library:
> >
> > ####################
> > library(plyr)
> >
> > dat <- read.table(header=TRUE, sep=",", as.is=TRUE,   ###### <----
> as.is=TRUE
> > text="site,tax_name,count,countTotal,countPercentage
> > CID_1,Cyanobacteria,46295,123509,37.483098398
> > CID_1,Proteobacteria,36120,123509,29.244832360
> > CID_1,Bacteroidetes,19546,123509,15.825567368
> > CID_1,Verrucomicrobia,7886,123509,6.384959801
> > CID_1,Firmicutes,2843,123509,2.301856545
> >   ... <lines deleted here>
> > CID_9,Armatimonadetes,27,77120,0.035010373
> > CID_9,Fusobacteria,25,77120,0.032417012
> > CID_9,Aquificae,13,77120,0.016856846
> > CID_9,Synergistetes,12,77120,0.015560166
> > CID_9,Deferribacteres,8,77120,0.010373444
> > CID_9,Thermotogae,7,77120,0.009076763
> > CID_9,Chrysiogenetes,3,77120,0.003890041.
> > ")
> >
> > summ_cid = function(frm) {
> >  # grab at most 6 rows from data frame  toprows = head(frm, 6)  # add
> > a 7th row  toprows[nrow(toprows)+1,] = c(toprows[1,1], "", NA, NA,
> > sum(toprows$countPercentage))  # all done
> >  return(toprows)
> > }
> >
> > result = ddply(dat, "site", summ_cid)
> > ####################
> >
> > Notes:
> >
> > 1. I needed to add the as.is=TRUE option to read.table() 2. The
> > invocation of ddply() does *not* use summarize() 3. Because there is
> > no use of summarize(), I have not figured out how to use the dplyr package
> in this context.
> >
> > -John
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chel
> >> Hee Lee
> >> Sent: Sunday, December 07, 2014 11:43 AM
> >> To: Morway, Eric; R mailing list
> >> Subject: Re: [R] Condensing data.frame
> >>
> >> > datBySite <- split(dat, dat$site)
> >> > output <- lapply(datBySite, function(x){
> >> + x$idx <- seq_len(nrow(x))
> >> + x$grp <- ifelse(x$idx < 7, x$idx, 7) rval <-
> >> + tapply(x$countPercentage, x$grp, sum) x$grp <- x$count <-
> >> + x$countTotal <- NULL x <- x[seq_len(7), ] x$tax_name <-
> >> + as.character(x$tax_name) x$tax_name[7] <- "Others"
> >> + x$new <- rval
> >> + return(x)
> >> + })
> >> >
> >> > head(do.call(rbind, output), 14)
> >>              site        tax_name countPercentage idx       new
> >> CID_1.1    CID_1   Cyanobacteria       37.483098   1 37.483098
> >> CID_1.2    CID_1  Proteobacteria       29.244832   2 29.244832
> >> CID_1.3    CID_1   Bacteroidetes       15.825567   3 15.825567
> >> CID_1.4    CID_1 Verrucomicrobia        6.384960   4  6.384960
> >> CID_1.5    CID_1      Firmicutes        2.301857   5  2.301857
> >> CID_1.6    CID_1   Acidobacteria        2.075152   6  2.075152
> >> CID_1.7    CID_1          Others        1.675182   7  6.684533
> >> CID_10.27 CID_10  Proteobacteria       35.366606   1 35.366606
> >> CID_10.28 CID_10   Bacteroidetes       25.188484   2 25.188484
> >> CID_10.29 CID_10   Cyanobacteria       23.294828   3 23.294828
> >> CID_10.30 CID_10 Verrucomicrobia        6.970592   4  6.970592
> >> CID_10.31 CID_10   Acidobacteria        1.988448   5  1.988448
> >> CID_10.32 CID_10  Actinobacteria        1.644548   6  1.644548
> >> CID_10.33 CID_10          Others        1.582823   7  5.546493
> >> >
> >>
> >> I hope this helps.
> >>
> >> Chel Hee Lee
> >>
> >> On 12/07/2014 08:21 AM, Morway, Eric wrote:
> >>> Using the dataset "dat" (found below), I'm seeking a way to condense
> >>> down the data.frame such that each "site" (i.e., "CID_1"..."CID_13")
> >>> has a maximum of 7 rows of post-processed data, where the first 6
> >>> have the highest "countPercentage" and the 7th row is the sum of
> >> "countPercentage"
> >>> from all other rows within that "site", and it is assigned the name
> >>> "Other".  So, for the first two sites in the provided data.frame,
> >>> CID_1 & CID_10, they would reduce to:
> >>>
> >>> CID_1 Cyanobacteria     37.48
> >>> CID_1 Proteobacteria     29.24
> >>> CID_1 Bacteroidetes      15.83
> >>> CID_1 Verrucomicrobia  6.38
> >>> CID_1 Firmicutes          2.30
> >>> CID_1 Acidobacteria      2.08
> >>> CID_1 Other                6.68
> >>> CID_10 Proteobacteria     35.37
> >>> CID_10 Bacteroidetes      25.19
> >>> CID_10 Cyanobacteria     23.29
> >>> CID_10 Verrucomicrobia  6.97
> >>> CID_10 Acidobacteria      1.99
> >>> CID_10 Actinobacteria     1.64
> >>> CID_10 Other                 5.55
> >>>
> >>>
> >>> dat <- read.table(header=TRUE, sep=",",
> >>> text="site,tax_name,count,countTotal,countPercentage
> >>> CID_1,Cyanobacteria,46295,123509,37.483098398
> >>> CID_1,Proteobacteria,36120,123509,29.244832360
> >>> CID_1,Bacteroidetes,19546,123509,15.825567368
> >>> CID_1,Verrucomicrobia,7886,123509,6.384959801
> >>> CID_1,Firmicutes,2843,123509,2.301856545
> >>> CID_1,Acidobacteria,2563,123509,2.075152418
> >>> CID_1,Actinobacteria,2069,123509,1.675181566
> >>> CID_1,Planctomycetes,1481,123509,1.199102899
> >>> CID_1,Chloroflexi,1181,123509,0.956205621
> >>> CID_1,Gemmatimonadetes,956,123509,0.774032662
> >>> CID_1,Spirochaetes,688,123509,0.557044426
> >>> CID_1,Lentisphaerae,526,123509,0.425879895
> >>> CID_1,Ignavibacteriae,324,123509,0.262329061
> >>> CID_1,Chlorobi,238,123509,0.192698508
> >>> CID_1,Nitrospirae,230,123509,0.186221247
> >>> CID_1,Nitrospinae,169,123509,0.136832134
> >>> CID_1,Elusimicrobia,131,123509,0.106065145
> >>> CID_1,Tenericutes,114,123509,0.092300966
> >>> CID_1,Fibrobacteres,72,123509,0.058295347
> >>> CID_1,Thermotogae,21,123509,0.017002810
> >>> CID_1,Fusobacteria,21,123509,0.017002810
> >>> CID_1,Armatimonadetes,15,123509,0.012144864
> >>> CID_1,Synergistetes,10,123509,0.008096576
> >>> CID_1,Deinococcus-Thermus,6,123509,0.004857946
> >>> CID_1,Deferribacteres,2,123509,0.001619315
> >>> CID_1,Caldiserica,2,123509,0.001619315
> >>> CID_10,Proteobacteria,16043,45362,35.366606411
> >>> CID_10,Bacteroidetes,11426,45362,25.188483753
> >>> CID_10,Cyanobacteria,10567,45362,23.294828270
> >>> CID_10,Verrucomicrobia,3162,45362,6.970592126
> >>> CID_10,Acidobacteria,902,45362,1.988448481
> >>> CID_10,Actinobacteria,746,45362,1.644548300
> >>> CID_10,Firmicutes,718,45362,1.582822627
> >>> CID_10,Gemmatimonadetes,358,45362,0.789206825
> >>> CID_10,Planctomycetes,357,45362,0.787002337
> >>> CID_10,Chloroflexi,265,45362,0.584189410
> >>> CID_10,Spirochaetes,235,45362,0.518054759
> >>> CID_10,Ignavibacteriae,177,45362,0.390194436
> >>> CID_10,Lentisphaerae,108,45362,0.238084741
> >>> CID_10,Nitrospinae,75,45362,0.165336625
> >>> CID_10,Nitrospirae,58,45362,0.127860324
> >>> CID_10,Chlorobi,44,45362,0.096997487
> >>> CID_10,Elusimicrobia,28,45362,0.061725673
> >>> CID_10,Fibrobacteres,26,45362,0.057316697
> >>> CID_10,Armatimonadetes,15,45362,0.033067325
> >>> CID_10,Deinococcus-Thermus,13,45362,0.028658348
> >>> CID_10,Tenericutes,10,45362,0.022044883
> >>> CID_10,Synergistetes,9,45362,0.019840395
> >>> CID_10,Fusobacteria,9,45362,0.019840395
> >>> CID_10,Deferribacteres,6,45362,0.013226930
> >>> CID_10,Thermotogae,3,45362,0.006613465
> >>> CID_10,Caldiserica,2,45362,0.004408977
> >>> CID_11,Proteobacteria,10019,31387,31.920858954
> >>> CID_11,Cyanobacteria,8811,31387,28.072131774
> >>> CID_11,Bacteroidetes,7930,31387,25.265237200
> >>> CID_11,Verrucomicrobia,1750,31387,5.575556759
> >>> CID_11,Firmicutes,806,31387,2.567942142
> >>> CID_11,Acidobacteria,548,31387,1.745945774
> >>> CID_11,Actinobacteria,434,31387,1.382738076
> >>> CID_11,Chloroflexi,203,31387,0.646764584
> >>> CID_11,Planctomycetes,197,31387,0.627648389
> >>> CID_11,Gemmatimonadetes,192,31387,0.611718227
> >>> CID_11,Ignavibacteriae,87,31387,0.277184822
> >>> CID_11,Spirochaetes,80,31387,0.254882595
> >>> CID_11,Tenericutes,71,31387,0.226208303
> >>> CID_11,Fusobacteria,67,31387,0.213464173
> >>> CID_11,Lentisphaerae,54,31387,0.172045751
> >>> CID_11,Chlorobi,40,31387,0.127441297
> >>> CID_11,Nitrospinae,33,31387,0.105139070
> >>> CID_11,Armatimonadetes,22,31387,0.070092714
> >>> CID_11,Fibrobacteres,15,31387,0.047790487
> >>> CID_11,Nitrospirae,13,31387,0.041418422
> >>> CID_11,Elusimicrobia,13,31387,0.041418422
> >>> CID_11,Deinococcus-Thermus,2,31387,0.006372065
> >>> CID_12,Cyanobacteria,241,644,37.422360248
> >>> CID_12,Bacteroidetes,210,644,32.608695652
> >>> CID_12,Proteobacteria,118,644,18.322981366
> >>> CID_12,Verrucomicrobia,38,644,5.900621118
> >>> CID_12,Acidobacteria,11,644,1.708074534
> >>> CID_12,Ignavibacteriae,6,644,0.931677019
> >>> CID_12,Lentisphaerae,5,644,0.776397516
> >>> CID_12,Firmicutes,5,644,0.776397516
> >>> CID_12,Planctomycetes,3,644,0.465838509
> >>> CID_12,Fusobacteria,3,644,0.465838509
> >>> CID_12,Tenericutes,2,644,0.310559006
> >>> CID_12,Actinobacteria,2,644,0.310559006
> >>> CID_13,Cyanobacteria,8581,25530,33.611437524
> >>> CID_13,Bacteroidetes,6878,25530,26.940853897
> >>> CID_13,Proteobacteria,5341,25530,20.920485703
> >>> CID_13,Verrucomicrobia,1244,25530,4.872698786
> >>> CID_13,Firmicutes,1148,25530,4.496670584
> >>> CID_13,Acidobacteria,548,25530,2.146494320
> >>> CID_13,Spirochaetes,477,25530,1.868390129
> >>> CID_13,Ignavibacteriae,298,25530,1.167254211
> >>> CID_13,Actinobacteria,227,25530,0.889150020
> >>> CID_13,Planctomycetes,184,25530,0.720720721
> >>> CID_13,Chloroflexi,181,25530,0.708969839
> >>> CID_13,Gemmatimonadetes,121,25530,0.473952213
> >>> CID_13,Lentisphaerae,93,25530,0.364277321
> >>> CID_13,Tenericutes,61,25530,0.238934587
> >>> CID_13,Fibrobacteres,47,25530,0.184097141
> >>> CID_13,Nitrospinae,28,25530,0.109674892
> >>> CID_13,Nitrospirae,26,25530,0.101840971
> >>> CID_13,Chlorobi,18,25530,0.070505288
> >>> CID_13,Elusimicrobia,13,25530,0.050920486
> >>> CID_13,Synergistetes,8,25530,0.031335684
> >>> CID_13,Fusobacteria,4,25530,0.015667842
> >>> CID_13,Deinococcus-Thermus,2,25530,0.007833921
> >>> CID_13,Thermotogae,2,25530,0.007833921
> >>> CID_2,Cyanobacteria,43812,94826,46.202518297
> >>> CID_2,Proteobacteria,22180,94826,23.390209436
> >>> CID_2,Bacteroidetes,16993,94826,17.920190665
> >>> CID_2,Verrucomicrobia,4779,94826,5.039757029
> >>> CID_2,Acidobacteria,1728,94826,1.822285027
> >>> CID_2,Firmicutes,1385,94826,1.460569886
> >>> CID_2,Planctomycetes,815,94826,0.859468922
> >>> CID_2,Actinobacteria,677,94826,0.713939215
> >>> CID_2,Gemmatimonadetes,625,94826,0.659101934
> >>> CID_2,Chloroflexi,416,94826,0.438698247
> >>> CID_2,Spirochaetes,415,94826,0.437643684
> >>> CID_2,Lentisphaerae,221,94826,0.233058444
> >>> CID_2,Ignavibacteriae,180,94826,0.189821357
> >>> CID_2,Fibrobacteres,155,94826,0.163457280
> >>> CID_2,Chlorobi,112,94826,0.118111067
> >>> CID_2,Elusimicrobia,111,94826,0.117056503
> >>> CID_2,Tenericutes,75,94826,0.079092232
> >>> CID_2,Nitrospinae,40,94826,0.042182524
> >>> CID_2,Nitrospirae,31,94826,0.032691456
> >>> CID_2,Deinococcus-Thermus,17,94826,0.017927573
> >>> CID_2,Armatimonadetes,17,94826,0.017927573
> >>> CID_2,Synergistetes,16,94826,0.016873010
> >>> CID_2,Fusobacteria,15,94826,0.015818446
> >>> CID_2,Deferribacteres,7,94826,0.007381942
> >>> CID_2,Caldiserica,2,94826,0.002109126
> >>> CID_2,Thermotogae,2,94826,0.002109126
> >>> CID_3,Cyanobacteria,18888,46181,40.899937204
> >>> CID_3,Proteobacteria,12532,46181,27.136701241
> >>> CID_3,Bacteroidetes,9070,46181,19.640111734
> >>> CID_3,Verrucomicrobia,2291,46181,4.960914662
> >>> CID_3,Acidobacteria,689,46181,1.491955566
> >>> CID_3,Firmicutes,631,46181,1.366362790
> >>> CID_3,Actinobacteria,470,46181,1.017734566
> >>> CID_3,Spirochaetes,366,46181,0.792533726
> >>> CID_3,Planctomycetes,326,46181,0.705918018
> >>> CID_3,Chloroflexi,282,46181,0.610640740
> >>> CID_3,Gemmatimonadetes,194,46181,0.420086183
> >>> CID_3,Fibrobacteres,116,46181,0.251185552
> >>> CID_3,Ignavibacteriae,109,46181,0.236027804
> >>> CID_3,Nitrospinae,46,46181,0.099608064
> >>> CID_3,Nitrospirae,44,46181,0.095277279
> >>> CID_3,Tenericutes,40,46181,0.086615708
> >>> CID_3,Lentisphaerae,38,46181,0.082284922
> >>> CID_3,Chlorobi,16,46181,0.034646283
> >>> CID_3,Elusimicrobia,14,46181,0.030315498
> >>> CID_3,Fusobacteria,10,46181,0.021653927
> >>> CID_3,Armatimonadetes,7,46181,0.015157749
> >>> CID_3,Synergistetes,2,46181,0.004330785
> >>> CID_4,Proteobacteria,433,1005,43.084577114
> >>> CID_4,Bacteroidetes,301,1005,29.950248756
> >>> CID_4,Actinobacteria,111,1005,11.044776119
> >>> CID_4,Cyanobacteria,44,1005,4.378109453
> >>> CID_4,Acidobacteria,28,1005,2.786069652
> >>> CID_4,Chloroflexi,24,1005,2.388059701
> >>> CID_4,Nitrospirae,21,1005,2.089552239
> >>> CID_4,Verrucomicrobia,12,1005,1.194029851
> >>> CID_4,Gemmatimonadetes,12,1005,1.194029851
> >>> CID_4,Firmicutes,7,1005,0.696517413
> >>> CID_4,Spirochaetes,5,1005,0.497512438
> >>> CID_4,Ignavibacteriae,5,1005,0.497512438
> >>> CID_4,Elusimicrobia,2,1005,0.199004975
> >>> CID_5,Proteobacteria,5002,11914,41.984220245
> >>> CID_5,Bacteroidetes,1512,11914,12.690951821
> >>> CID_5,Verrucomicrobia,1361,11914,11.423535337
> >>> CID_5,Acidobacteria,1207,11914,10.130938392
> >>> CID_5,Cyanobacteria,721,11914,6.051703878
> >>> CID_5,Planctomycetes,635,11914,5.329864026
> >>> CID_5,Actinobacteria,398,11914,3.340607688
> >>> CID_5,Nitrospirae,314,11914,2.635554809
> >>> CID_5,Chloroflexi,313,11914,2.627161323
> >>> CID_5,Firmicutes,195,11914,1.636729898
> >>> CID_5,Gemmatimonadetes,129,11914,1.082759778
> >>> CID_5,Chlorobi,31,11914,0.260198086
> >>> CID_5,Armatimonadetes,22,11914,0.184656706
> >>> CID_5,Ignavibacteriae,21,11914,0.176263220
> >>> CID_5,Fusobacteria,14,11914,0.117508813
> >>> CID_5,Deinococcus-Thermus,10,11914,0.083934867
> >>> CID_5,Lentisphaerae,9,11914,0.075541380
> >>> CID_5,Elusimicrobia,7,11914,0.058754407
> >>> CID_5,Nitrospinae,7,11914,0.058754407
> >>> CID_5,Synergistetes,4,11914,0.033573947
> >>> CID_5,Spirochaetes,2,11914,0.016786973
> >>> CID_6,Cyanobacteria,6462,17852,36.197624916
> >>> CID_6,Proteobacteria,5036,17852,28.209724401
> >>> CID_6,Bacteroidetes,3906,17852,21.879901412
> >>> CID_6,Verrucomicrobia,1016,17852,5.691239077
> >>> CID_6,Acidobacteria,317,17852,1.775711405
> >>> CID_6,Actinobacteria,286,17852,1.602061394
> >>> CID_6,Firmicutes,234,17852,1.310777504
> >>> CID_6,Planctomycetes,134,17852,0.750616177
> >>> CID_6,Gemmatimonadetes,112,17852,0.627380686
> >>> CID_6,Spirochaetes,97,17852,0.543356487
> >>> CID_6,Chloroflexi,77,17852,0.431324221
> >>> CID_6,Lentisphaerae,56,17852,0.313690343
> >>> CID_6,Ignavibacteriae,35,17852,0.196056464
> >>> CID_6,Nitrospirae,23,17852,0.128837105
> >>> CID_6,Nitrospinae,19,17852,0.106430652
> >>> CID_6,Tenericutes,12,17852,0.067219359
> >>> CID_6,Chlorobi,8,17852,0.044812906
> >>> CID_6,Armatimonadetes,7,17852,0.039211293
> >>> CID_6,Fibrobacteres,7,17852,0.039211293
> >>> CID_6,Elusimicrobia,4,17852,0.022406453
> >>> CID_6,Fusobacteria,2,17852,0.011203227
> >>> CID_6,Deferribacteres,2,17852,0.011203227
> >>> CID_7,Cyanobacteria,11046,30425,36.305669680
> >>> CID_7,Proteobacteria,8418,30425,27.668036154
> >>> CID_7,Bacteroidetes,6197,30425,20.368118324
> >>> CID_7,Verrucomicrobia,1745,30425,5.735414955
> >>> CID_7,Firmicutes,732,30425,2.405916187
> >>> CID_7,Acidobacteria,582,30425,1.912900575
> >>> CID_7,Actinobacteria,365,30425,1.199671323
> >>> CID_7,Fusobacteria,344,30425,1.130649137
> >>> CID_7,Planctomycetes,253,30425,0.831552999
> >>> CID_7,Chloroflexi,221,30425,0.726376335
> >>> CID_7,Gemmatimonadetes,131,30425,0.430566968
> >>> CID_7,Spirochaetes,127,30425,0.417419885
> >>> CID_7,Lentisphaerae,88,30425,0.289235826
> >>> CID_7,Ignavibacteriae,69,30425,0.226787182
> >>> CID_7,Nitrospinae,37,30425,0.121610518
> >>> CID_7,Nitrospirae,21,30425,0.069022186
> >>> CID_7,Chlorobi,17,30425,0.055875103
> >>> CID_7,Elusimicrobia,15,30425,0.049301561
> >>> CID_7,Fibrobacteres,9,30425,0.029580937
> >>> CID_7,Armatimonadetes,4,30425,0.013147083
> >>> CID_7,Deferribacteres,4,30425,0.013147083
> >>> CID_8,Cyanobacteria,14446,43589,33.141388883
> >>> CID_8,Proteobacteria,13270,43589,30.443460506
> >>> CID_8,Bacteroidetes,8834,43589,20.266581018
> >>> CID_8,Verrucomicrobia,2529,43589,5.801922503
> >>> CID_8,Firmicutes,1176,43589,2.697928376
> >>> CID_8,Acidobacteria,780,43589,1.789442290
> >>> CID_8,Actinobacteria,542,43589,1.243432976
> >>> CID_8,Spirochaetes,406,43589,0.931427654
> >>> CID_8,Planctomycetes,295,43589,0.676776251
> >>> CID_8,Chloroflexi,277,43589,0.635481429
> >>> CID_8,Ignavibacteriae,243,43589,0.557480098
> >>> CID_8,Lentisphaerae,230,43589,0.527656060
> >>> CID_8,Gemmatimonadetes,162,43589,0.371653399
> >>> CID_8,Fusobacteria,106,43589,0.243180619
> >>> CID_8,Tenericutes,57,43589,0.130766937
> >>> CID_8,Nitrospirae,51,43589,0.117001996
> >>> CID_8,Chlorobi,50,43589,0.114707839
> >>> CID_8,Nitrospinae,36,43589,0.082589644
> >>> CID_8,Fibrobacteres,34,43589,0.078001331
> >>> CID_8,Elusimicrobia,29,43589,0.066530547
> >>> CID_8,Armatimonadetes,19,43589,0.043588979
> >>> CID_8,Aquificae,8,43589,0.018353254
> >>> CID_8,Deferribacteres,7,43589,0.016059097
> >>> CID_8,Dictyoglomi,2,43589,0.004588314
> >>> CID_9,Proteobacteria,26463,77120,34.314056017
> >>> CID_9,Cyanobacteria,20329,77120,26.360217842
> >>> CID_9,Bacteroidetes,15956,77120,20.689834025
> >>> CID_9,Verrucomicrobia,3323,77120,4.308869295
> >>> CID_9,Firmicutes,2726,77120,3.534751037
> >>> CID_9,Spirochaetes,1644,77120,2.131742739
> >>> CID_9,Acidobacteria,1634,77120,2.118775934
> >>> CID_9,Actinobacteria,1200,77120,1.556016598
> >>> CID_9,Chloroflexi,1128,77120,1.462655602
> >>> CID_9,Planctomycetes,872,77120,1.130705394
> >>> CID_9,Ignavibacteriae,578,77120,0.749481328
> >>> CID_9,Lentisphaerae,264,77120,0.342323651
> >>> CID_9,Gemmatimonadetes,263,77120,0.341026971
> >>> CID_9,Fibrobacteres,170,77120,0.220435685
> >>> CID_9,Nitrospirae,148,77120,0.191908714
> >>> CID_9,Nitrospinae,136,77120,0.176348548
> >>> CID_9,Chlorobi,74,77120,0.095954357
> >>> CID_9,Tenericutes,71,77120,0.092064315
> >>> CID_9,Elusimicrobia,46,77120,0.059647303
> >>> CID_9,Armatimonadetes,27,77120,0.035010373
> >>> CID_9,Fusobacteria,25,77120,0.032417012
> >>> CID_9,Aquificae,13,77120,0.016856846
> >>> CID_9,Synergistetes,12,77120,0.015560166
> >>> CID_9,Deferribacteres,8,77120,0.010373444
> >>> CID_9,Thermotogae,7,77120,0.009076763
> >>> CID_9,Chrysiogenetes,3,77120,0.003890041
> >>> ")
> >>>
> >>> 	[[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html and provide commented, minimal, self-contained,
> >> reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From bbolker at gmail.com  Mon Dec  8 03:05:39 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 8 Dec 2014 02:05:39 +0000
Subject: [R] neighborhood competition index in r package
References: <CAEW+BDLk6nrs4tp_KrvdDspOibttNQ7_LPW0wsdFR_tWj4Bb0Q@mail.gmail.com>
Message-ID: <loom.20141208T030429-238@post.gmane.org>

catalin roibu <catalinroibu <at> gmail.com> writes:

> 
> Dear all!
> 
> Is there a R package to compute neighborhood competition index (Shutz,
> Hegyi, and many index).
> 
> Thank you very much!
> 

  library("sos")
  findFn("Hegyi")

leads to 

  http://finzi.psych.upenn.edu/R/library/siplab/html/pairwise.html

Does that help?


From gunter.berton at gene.com  Mon Dec  8 03:31:14 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 7 Dec 2014 18:31:14 -0800
Subject: [R] neighborhood competition index in r package
In-Reply-To: <loom.20141208T030429-238@post.gmane.org>
References: <CAEW+BDLk6nrs4tp_KrvdDspOibttNQ7_LPW0wsdFR_tWj4Bb0Q@mail.gmail.com>
	<loom.20141208T030429-238@post.gmane.org>
Message-ID: <CACk-te2L=u3SQWF8HapArXa4wM5thxbWp+UdyzRemYBf9rBS8A@mail.gmail.com>

... and even more directly, googling on "R package Hegyi" brought up
the siplab package as the first hit. As it deals with forestry and
vegetation, it would appear to be what the OP wanted -- and could have
found him/her self with a minimum of effort.

Sigh... I don't understand why people don't make even a minimal search
effort on their own and feel it necessary to ask for help here. It
ain't rocket science!

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Dec 7, 2014 at 6:05 PM, Ben Bolker <bbolker at gmail.com> wrote:
> catalin roibu <catalinroibu <at> gmail.com> writes:
>
>>
>> Dear all!
>>
>> Is there a R package to compute neighborhood competition index (Shutz,
>> Hegyi, and many index).
>>
>> Thank you very much!
>>
>
>   library("sos")
>   findFn("Hegyi")
>
> leads to
>
>   http://finzi.psych.upenn.edu/R/library/siplab/html/pairwise.html
>
> Does that help?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alemu.tadesse at gmail.com  Mon Dec  8 05:28:56 2014
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Sun, 7 Dec 2014 21:28:56 -0700
Subject: [R] date time problem
In-Reply-To: <alpine.BSF.2.00.1412071226430.29350@pedal.dcn.davis.ca.us>
References: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>
	<alpine.BSF.2.00.1412071226430.29350@pedal.dcn.davis.ca.us>
Message-ID: <CACGkHRPxtuKXNAGhOOE22aNE9BK73Kp1ZEak0o9efYVAgsnpRg@mail.gmail.com>

Thank you very much Jeff. Below is the data I used:
> Corrected_data
              SA_LST SA_GHI_mean
61759 3/11/2007 1:00     0.00000
67517 3/11/2007 2:00     0.00000
70017 3/11/2007 3:00     0.00000
70524 3/11/2007 4:00     0.00000
71061 3/11/2007 5:00     0.00000
71638 3/11/2007 6:00     0.00000
72113 3/11/2007 7:00    20.20873
72629 3/11/2007 8:00   123.14231
73274 3/11/2007 9:00   306.97343

>test1<-as.POSIXct(Corrected_data$SA_LST,format="%m/%d/%Y %H:%M",
tz="EST5EDT")
>test1
[1] "2007-03-11 01:00:00 EST" NA                        "2007-03-11
03:00:00 EDT" "2007-03-11 04:00:00 EDT"
[5] "2007-03-11 05:00:00 EDT" "2007-03-11 06:00:00 EDT" "2007-03-11
07:00:00 EDT" "2007-03-11 08:00:00 EDT"
[9] "2007-03-11 09:00:00 EDT"

> format(test1, tz="Etc/GMT", usetz=TRUE )
[1] "2007-03-11 06:00:00 GMT" NA                        "2007-03-11
07:00:00 GMT" "2007-03-11 08:00:00 GMT"
[5] "2007-03-11 09:00:00 GMT" "2007-03-11 10:00:00 GMT" "2007-03-11
11:00:00 GMT" "2007-03-11 12:00:00 GMT"
[9] "2007-03-11 13:00:00 GMT"
>

As you can see the "2007-03-11 02:00:00 EST" is not recognized and returned
as NA. This may be due to DST, which I do not know how to handle in R.

Best,

Alemu


On Sun, Dec 7, 2014 at 1:59 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You have not provided a reproducible example, so anything I say could be
> wrong just due to misinterpretation. Please read [1] for suggestions on
> making your examples reproducible, particularly regarding the use of dput
> to provide example data. You have also posted in HTML format, which can
> cause additional scrambling of communications on this list.
>
> From the notation you are using, I would guess that "Corrected_SA_data" is
> a data frame containing columns "date_time" and "TZ" at a minimum. The
> "date_time" column could be a vector of class POSIXlt or POSIXct... except
> that I cannot reproduce such an object that doesn't print some kind of
> timezone indicator in its output. What version of R are you using? Note
> that such an object contains a tz attribute already, so unless you have
> already made sure that the date_time column knows about that timezone, they
> are probably unrelated to each other.
>
> Note that any POSIXct object is internally represented as a specific
> instant of time. The tz attribute is only used to control how that time
> will be displayed. For example:
>
> testtime3 <- as.POSIXct( rawtime1, tz="America/New_York" )
> format( testtime3, tz="Etc/GMT", usetz=TRUE )
>
> If you want the output to omit the timezone information you can omit the
> usetz argument:
>
> format( testtime3, tz="Etc/GMT" )
>
> If you have not yet, you should read [2]. Note that three-letter timezone
> indicators (even though they are given in OUTPUT!) are at best unreliable
> for use in specifying timezones in R... read ?timezones.
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-
> a-great-r-reproducible-example
> [2] http://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf
>
>
> On Sun, 7 Dec 2014, Alemu Tadesse wrote:
>
>  Dear R users
>>
>> I am puzzled by the following result from R script. I am trying to convert
>> local time to UTC time. Time zone is -5, therefore I used the following
>> approach.
>>
>> Below is the script.
>>
>>> Corrected_SA_data$date_time[k-1]
>>>
>> [1] "2007-03-11 01:00:00"
>>
>>> Corrected_SA_data$TZ[k-1]
>>>
>> [1] -5
>>
>>> Corrected_SA_data$date_time[k-1]-Corrected_SA_data$TZ[k-1]*3600
>>>
>> [1] "2007-03-11 07:00:00 MDT"
>>
>> I was expecting this last value to be something like "2007-03-11 06:00:00
>> UTC"
>>
>> Please correct me if I ma wrong.
>>
>> On the other hand I have
>>
>>> Corrected_SA_data$date_time[k]
>>>
>> [1] "2007-03-11 02:00:00"
>>
>>> Corrected_SA_data$TZ[k]
>>>
>> [1] -5
>>
>>> Corrected_SA_data$date_time[k]-Corrected_SA_data$TZ[k]*3600
>>>
>> [1] NA
>>
>> I am not sure why I am getting NA.
>>
>> Thank you for your help.
>>
>> Alemu
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From eddieatr at gmail.com  Mon Dec  8 05:38:27 2014
From: eddieatr at gmail.com (Eddie Smith)
Date: Mon, 8 Dec 2014 12:38:27 +0800
Subject: [R] How to plot bootstrap distribution in rms package?
Message-ID: <CABaJH79h=cc7uFTU1pbJMckpuir_7Gzjffq0VgFeD=K-5LTsgw@mail.gmail.com>

Hi guys,

I am trying to familiar myself with bootstrapping using rms package and
stuck on how to plot the bootstrap distribution. Would appreciate if
somebody could help.

Thanks in advance.

From
http://stats.stackexchange.com/questions/64788/interpreting-a-logistic-regression-model-with-multiple-predictors

library(rms)
mydata <- read.csv("http://www.ats.ucla.edu/stat/data/binary.csv")
mylogit <- lrm(admit ~ gre, x=TRUE, y=TRUE, data = mydata)
mylogit
my.valid <- validate(mylogit, method="boot", B=1000)
my.valid
my.calib <- calibrate(mylogit, method="boot", B=1000)
my.calib

	[[alternative HTML version deleted]]


From ed.purssell at kcl.ac.uk  Mon Dec  8 07:25:47 2014
From: ed.purssell at kcl.ac.uk (Purssell, Ed)
Date: Mon, 8 Dec 2014 06:25:47 +0000
Subject: [R] metafor - code for analysing geometric means
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730EF7D57BBB@UM-MAIL4112.unimaas.nl>
References: <1415876433556.77087@kcl.ac.uk>
	<5464978A.3060902@aghmed.fsnet.co.uk>,
	<077E31A57DA26E46AB0D493C9966AC730EF7D57BBB@UM-MAIL4112.unimaas.nl>
Message-ID: <1418019946707.93133@kcl.ac.uk>

Dear All

I have tried very hard to work out what to do with putting logged data into metafor; the paper says..
'geometric mean antibody concentrations (GMCs) or opsonophagocytic activity titres (geometric mean titres [GMT]) were calculated with 95% CIs by taking the antilog of the mean of the log concentration or titre transformations.'

Does this look right if I take the reported mean, upper and lower bound of the CI, and the number?

m<-log(mean) 
ub<-log(upper bound)
lb<-log(lower bound)
diff<-ub-lb
SE<-diff/3.92
SD<-SE*(sqrt(n))

Then put m, SD and n for each group into metafor as normal.  Or is there a better way?  I am afraid I didn't understand how to do it on a log scale.

Thank you

Edward
----------------------------
Edward Purssell PhD
Senior Lecturer

Florence Nightingale Faculty of Nursing and Midwifery
King's College London
James Clerk Maxwell Building
57 Waterloo Road
London SE1 8WA
Telephone 020 7848 3021
Mobile 07782 374217
email edward.purssell at kcl.ac.uk
https://www.researchgate.net/profile/Edward_Purssell

________________________________________
From: Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl>
Sent: 14 November 2014 10:40
To: Michael Dewey; Purssell, Ed; r-help at r-project.org
Subject: RE: [R] metafor - code for analysing geometric means

With "geometric mean 1 CI /3.92", I assume you mean "(upper bound - lower bound) / 3.92". Two things:

1) That will give you the SE of the mean, not the SD of the observations (which is what you need as input).

2) Probably the CI for the geometric mean was calculated on the log-scale (as Michael hinted at). Check if log(upper bound) and log(lower bound) is (within rounding error) symmetric around log(geometric mean). Then (log(upper bound) - log(lower bound)) / 3.96 * sqrt(n) will give you the SD of the log of the values used to compute the geometric mean. Then you could use log(geometric mean) and that SD as input. But this would give you the difference of the log-transformed geometric means. Not sure if this is what you want to analyze.

Two more articles that may be helpful here:

Friedrich, J. O., Adhikari, N. K., & Beyene, J. (2012). Ratio of geometric means to analyze continuous outcomes in meta-analysis: Comparison to mean differences and ratio of arithmetic means using empiric data and simulation. Statistics in Medicine, 31(17), 1857-1886.

Souverein, O. W., Dullemeijer, C., van 't Veer, P., & van der Voet, H. (2012). Transformations of summary statistics as input in meta-analysis for linear dose-response models on a logarithmic scale: A methodology developed within EURRECA. BMC Medical Research Methodology, 12(57).

Best,
Wolfgang

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Michael Dewey
> Sent: Thursday, November 13, 2014 12:36
> To: Purssell, Ed; r-help at r-project.org
> Subject: Re: [R] metafor - code for analysing geometric means
>
> On 13/11/2014 11:00, Purssell, Ed wrote:
> > ?Dear All
> >
> > I have some data expressed in geometric means and 95% confidence
> intervals.  Can I code them in metafor as:
> >
> > rma(m1i=geometric mean 1, m2i=geometric mean 2, sd1i=geometric mean 1
> CI /3.92, sd2i=geometric mean 2 CI/3.92.......etc, measure="MD")
>
> Would it not be better to work on the log scale?
>
> > All of the studies use geometric means.
> >
> > Thanks!
> >
> > Edward
>
> --
> Michael
> http://www.dewey.myzen.co.uk


From gunter.berton at gene.com  Mon Dec  8 07:35:32 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 7 Dec 2014 22:35:32 -0800
Subject: [R] metafor - code for analysing geometric means
In-Reply-To: <1418019946707.93133@kcl.ac.uk>
References: <1415876433556.77087@kcl.ac.uk>
	<5464978A.3060902@aghmed.fsnet.co.uk>
	<077E31A57DA26E46AB0D493C9966AC730EF7D57BBB@UM-MAIL4112.unimaas.nl>
	<1418019946707.93133@kcl.ac.uk>
Message-ID: <CACk-te2rO8Vvm=sYpgbCz+8vXVZq=H26-T81gXLeK7ZNCJUYsQ@mail.gmail.com>

While you may get a helpful reply, I think this is really not the
forum for such relatively basic math/stat questions. As you seem to be
more or less at sea here, I really really suggest that you seek help
from a local statistical resource.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Dec 7, 2014 at 10:25 PM, Purssell, Ed <ed.purssell at kcl.ac.uk> wrote:
> Dear All
>
> I have tried very hard to work out what to do with putting logged data into metafor; the paper says..
> 'geometric mean antibody concentrations (GMCs) or opsonophagocytic activity titres (geometric mean titres [GMT]) were calculated with 95% CIs by taking the antilog of the mean of the log concentration or titre transformations.'
>
> Does this look right if I take the reported mean, upper and lower bound of the CI, and the number?
>
> m<-log(mean)
> ub<-log(upper bound)
> lb<-log(lower bound)
> diff<-ub-lb
> SE<-diff/3.92
> SD<-SE*(sqrt(n))
>
> Then put m, SD and n for each group into metafor as normal.  Or is there a better way?  I am afraid I didn't understand how to do it on a log scale.
>
> Thank you
>
> Edward
> ----------------------------
> Edward Purssell PhD
> Senior Lecturer
>
> Florence Nightingale Faculty of Nursing and Midwifery
> King's College London
> James Clerk Maxwell Building
> 57 Waterloo Road
> London SE1 8WA
> Telephone 020 7848 3021
> Mobile 07782 374217
> email edward.purssell at kcl.ac.uk
> https://www.researchgate.net/profile/Edward_Purssell
>
> ________________________________________
> From: Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl>
> Sent: 14 November 2014 10:40
> To: Michael Dewey; Purssell, Ed; r-help at r-project.org
> Subject: RE: [R] metafor - code for analysing geometric means
>
> With "geometric mean 1 CI /3.92", I assume you mean "(upper bound - lower bound) / 3.92". Two things:
>
> 1) That will give you the SE of the mean, not the SD of the observations (which is what you need as input).
>
> 2) Probably the CI for the geometric mean was calculated on the log-scale (as Michael hinted at). Check if log(upper bound) and log(lower bound) is (within rounding error) symmetric around log(geometric mean). Then (log(upper bound) - log(lower bound)) / 3.96 * sqrt(n) will give you the SD of the log of the values used to compute the geometric mean. Then you could use log(geometric mean) and that SD as input. But this would give you the difference of the log-transformed geometric means. Not sure if this is what you want to analyze.
>
> Two more articles that may be helpful here:
>
> Friedrich, J. O., Adhikari, N. K., & Beyene, J. (2012). Ratio of geometric means to analyze continuous outcomes in meta-analysis: Comparison to mean differences and ratio of arithmetic means using empiric data and simulation. Statistics in Medicine, 31(17), 1857-1886.
>
> Souverein, O. W., Dullemeijer, C., van 't Veer, P., & van der Voet, H. (2012). Transformations of summary statistics as input in meta-analysis for linear dose-response models on a logarithmic scale: A methodology developed within EURRECA. BMC Medical Research Methodology, 12(57).
>
> Best,
> Wolfgang
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Michael Dewey
>> Sent: Thursday, November 13, 2014 12:36
>> To: Purssell, Ed; r-help at r-project.org
>> Subject: Re: [R] metafor - code for analysing geometric means
>>
>> On 13/11/2014 11:00, Purssell, Ed wrote:
>> > ?Dear All
>> >
>> > I have some data expressed in geometric means and 95% confidence
>> intervals.  Can I code them in metafor as:
>> >
>> > rma(m1i=geometric mean 1, m2i=geometric mean 2, sd1i=geometric mean 1
>> CI /3.92, sd2i=geometric mean 2 CI/3.92.......etc, measure="MD")
>>
>> Would it not be better to work on the log scale?
>>
>> > All of the studies use geometric means.
>> >
>> > Thanks!
>> >
>> > Edward
>>
>> --
>> Michael
>> http://www.dewey.myzen.co.uk
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rh at knut-krueger.de  Mon Dec  8 12:00:40 2014
From: rh at knut-krueger.de (Knut Krueger)
Date: Mon, 8 Dec 2014 12:00:40 +0100
Subject: [R] RODBC Error
Message-ID: <548584D8.5080103@knut-krueger.de>


There is a system wide installation for the university computer of r and 
Rcmdr (R-Commander)
There a a few computer with the following message the user tries to open 
an excel sheet with R.Commander:

(I assume the german message is from the german operating system win 7)

 > library(RODBC, pos=15)
Warning in odbcDriverConnect(con, tabQuote = c("[", "]"), ...) :
   [RODBC] FEHLER: Status IM002, Code 0, Nachricht [Microsoft][ODBC 
Driver Manager] Der Datenquellenname wurde nicht gefunden, und es wurde 
kein Standardtreiber angegeben
Warning in odbcDriverConnect(con, tabQuote = c("[", "]"), ...) :
   ODBC connection failed
Error in sqlTables(channel) : first argument is not an open RODBC channel


I do not know what the difference of the Computers systems could be.
Any hint for me? I am not able to reproduce this error with my Win 7 
computers...


Regards Knut


From rh at knut-krueger.de  Mon Dec  8 12:00:40 2014
From: rh at knut-krueger.de (Knut Krueger)
Date: Mon, 8 Dec 2014 12:00:40 +0100
Subject: [R] RODBC Error
Message-ID: <548584D8.5080103@knut-krueger.de>


There is a system wide installation for the university computer of r and 
Rcmdr (R-Commander)
There a a few computer with the following message the user tries to open 
an excel sheet with R.Commander:

(I assume the german message is from the german operating system win 7)

 > library(RODBC, pos=15)
Warning in odbcDriverConnect(con, tabQuote = c("[", "]"), ...) :
   [RODBC] FEHLER: Status IM002, Code 0, Nachricht [Microsoft][ODBC 
Driver Manager] Der Datenquellenname wurde nicht gefunden, und es wurde 
kein Standardtreiber angegeben
Warning in odbcDriverConnect(con, tabQuote = c("[", "]"), ...) :
   ODBC connection failed
Error in sqlTables(channel) : first argument is not an open RODBC channel


I do not know what the difference of the Computers systems could be.
Any hint for me? I am not able to reproduce this error with my Win 7 
computers...


Regards Knut


From bernardo_brandaum at yahoo.com.br  Mon Dec  8 21:04:50 2014
From: bernardo_brandaum at yahoo.com.br (Bernardo Santos)
Date: Mon, 8 Dec 2014 20:04:50 +0000 (UTC)
Subject: [R] MLE with parameters restricted to a defined range using bbmle
Message-ID: <1067011741.4187447.1418069090594.JavaMail.yahoo@jws10098.mail.ne1.yahoo.com>

Dear all,
I am fitting models to data with mle2 function of the bbmle package.In specific, I want to fit a power-law distribution model, as defined here (http://arxiv.org/pdf/cond-mat/0412004v3.pdf), to data.
However, one of the parameters - xmin -, must be necessarily greater than zero. What can I do to restrict the possible values of a parameter that are passed to the optimizer?
Here there is a sample of my code:
# Loading library
library(bbmle)

# Creating data
set.seed(1234)
data <- rexp(1000, rate = 0.1) # The fit will not be too good, but it is just to test

# Creating the power-law distribution density function
dpowlaw <- function(x, alfa, xmin, log=FALSE){
? c <- (alfa-1)*xmin^(alfa-1)
? if(log) ifelse(x < xmin, 0, log(c*x^(-alfa)))
? else ifelse(x < xmin, 0, c*x^(-alfa))
}
# Testing the function
integrate(dpowlaw, -Inf, Inf, alfa=2, xmin=1)
curve(dpowlaw(x, alfa=2.5, xmin=10), from=0, to=100, log="")
curve(dpowlaw(x, alfa=2.5, xmin=1), from=1, to=100, log="xy")

# Negative log-likelihood function
LLlevy <- function(mu, xmin){
? -sum(dpowlaw(data, alfa=mu, xmin=xmin, log=T))
}

# Fitting model to data
mlevy <- mle2(LLlevy, start=list(mu=2, xmin=1))
The result of model fitting here is?Coefficients:
       mu      xmin 
-916.4043  890.4248 
but this does not make sense!xmin must be > 0, and mu must be > 1.What should I do?
Thanks in advance!Bernardo Niebuhr





	[[alternative HTML version deleted]]


From david at revolutionanalytics.com  Mon Dec  8 19:12:29 2014
From: david at revolutionanalytics.com (David Smith)
Date: Mon, 8 Dec 2014 12:12:29 -0600
Subject: [R] Revolutions blog: November 2014 Roundup
Message-ID: <CABgvEC8dhTXtFV0UJamNTOnhZC4S_yOhh+EeTiSd_D80RrDq5w@mail.gmail.com>

Revolution Analytics staff and guests write about R every weekday at
the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of November:

Reviews of some of the R-related presentations (by John Chambers,
Trevor Hastie and others) at the H20 World conference:
http://bit.ly/1608yy5

An R/Shiny app for making egg-nog: http://bit.ly/1608yy6

An author's look at how R was used to create many of the beautiful
graphics in the book "London: The Information Capital":
http://bit.ly/1608yy4

PhD student Tim Winke used R to explore the popularity of German cars
around the globe: http://bit.ly/1608yy8

Twitter has released an R package for breakout detection in time
series, that they use to monitor user experience on the site:
http://bit.ly/1608AGu

Ford's Chief Data Scientist describes various applications where R is
used by the auto maker: http://bit.ly/1608yy7

The Bay Area R User Group featured presentations on using R to promote
athletes, using R on Azure, and updates to the data.table package:
http://bit.ly/1608yyf

Analyzing data from the Reddit API with R reveals that not all posts
are treated equally when it comes to promotions to the front page:
http://bit.ly/1608yyg

A new free course on DataCamp provides an introduction to the big-data
features of Revolution R Enterprise: http://bit.ly/1608yye

Learn about Revolution R Open and Deploy R Open, new open-source
projects from Revolution Analytics, in this recorded webinar:
http://bit.ly/1608AWK

R is now #12 in the Tiobe index of programming language popularity,
its highest rank ever: http://bit.ly/1608AWJ

A look at the popular igraph package for drawing networks and
connected graphs with R: http://bit.ly/1608AWI

How to create 3D-graphics that you can interactively rotate on-screen
with plotly and ggplot2: http://bit.ly/1608AWL

Some performance benchmarks of Revolution R Open on Linux, with
comparisons to other multithreaded BLAS libraries:
http://bit.ly/1608AWO

Working with a large and messy data set with R packages and Revolution
R Enterprise: http://bit.ly/1608yyj

Revolution R Enterprise 7.3 is now available, with a new Stochastic
Gradient Boosting algorithm for very large data sets:
http://bit.ly/1608yyi

Stanford PhD candidate Peggy Fan explores the World Values Survey data
with R and Shiny: http://bit.ly/1608AWN

A short video describes how R programs can run in the Azure cloud and
be connected to other applications: http://bit.ly/1608AWM

General interest stories (not related to R) in the past month
included: Too Many Cooks, a bizarre satire video
(http://bit.ly/1608AWP) and how Interstellar advanced the science of
black holes (http://bit.ly/1608AWR).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid

-- 
 

Revolution R Plus <http://revolutionanalytics.com/plus>

Subscribe to Technical Support & Indemnification for R


From ragia11 at hotmail.com  Mon Dec  8 09:18:37 2014
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Mon, 8 Dec 2014 10:18:37 +0200
Subject: [R] data frame cumulative row sum
In-Reply-To: <mailman.8.1417950005.3956.r-help@r-project.org>
References: <mailman.8.1417950005.3956.r-help@r-project.org>
Message-ID: <DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>

Hi,
Kindly I had a data frame looks like this
x y  
1 3  
2 2  
3 1  
4 3  
and I want to add column z that sum cumulativly like this
x y z
1 3 3
2 2 5
3 1 6
4 3 9

how to do this?
Regards
Ragia
 		 	   		  
	[[alternative HTML version deleted]]


From arnaud.duranel.09 at ucl.ac.uk  Mon Dec  8 10:51:19 2014
From: arnaud.duranel.09 at ucl.ac.uk (Arnaud Duranel)
Date: Mon, 8 Dec 2014 09:51:19 +0000
Subject: [R] vectorization of rolling function
In-Reply-To: <alpine.BSF.2.00.1412072329030.69489@pedal.dcn.davis.ca.us>
References: <1417901458880-4700487.post@n4.nabble.com>
	<alpine.BSF.2.00.1412072329030.69489@pedal.dcn.davis.ca.us>
Message-ID: <54857497.50201@ucl.ac.uk>

Great, many thanks for your help Jeff.
Apologies for the HTML format, I'll be more careful next time.
Arnaud

On 08/12/2014 08:25, Jeff Newmiller wrote:
> Please don't post in HTML... you may not recognize it, but the 
> receiving end does not necessarily (and in this case did not) look 
> like the sending end, and the cleanup can impede answers you are 
> hoping to get.
>
> In many cases, loops can be vectorized.  However, near as I can tell 
> this is an example of an algorithm that simply needs a loop [1].
>
> One bit of advice: the coredata function is horribly slow. Just 
> converting your time series objects to numeric vectors for the purpose 
> of this computation sped up the algorithm by 500x on 10000 point 
> series. Converting it to inline C++ as below sped it up by yet another 
> factor of 40x. 20000x is nothing to sneeze at.
>
> #######
> ## optional temporary setup for windows
> ## assumes you have installed Rtools
> gcc <- "C:\\Rtools\\bin"
> rtools <- "C:\\Rtools\\gcc-4.6.3\\bin"
> path <- strsplit(Sys.getenv("PATH"), ";")[[1]]
> new_path <- c(rtools, gcc, path)
> new_path <- new_path[!duplicated(tolower(new_path))]
> Sys.setenv(PATH = paste(new_path, collapse = ";"))
> ## end of optional
>
> library(Rcpp)
>
> cppFunction(
> "DataFrame EvapSimRcpp( NumericVector RR
>                       , NumericVector ETmax
>                       , const double Smax
>                       , const double initialStorage ) {
>   int n = RR.size();
>
>   // create empty time-series to fill
>   // effective rainfall (i.e. rainfall minus intercepted rainfall)
>   NumericVector RReff( n );
>   // intercepted rainfall( n );
>   NumericVector Rint( n );
>   // residual potential evapotranspiration (ie ETmax minus
>   // evaporation from interception)
>   NumericVector ETres( n, NA_REAL );
>   double evap;
>
>   // volume of water in interception storage at start of
>   // computation
>   double storage = initialStorage;
>
>   for ( int i=0; i<n; i++ ) {
>     // compute interception capacity for time step i (maximum
>     // interception capacity minus any water intercepted but not
>     // evaporated during previous time-step).
>     Rint[ i ] = Smax - storage;
>     // compute intercepted rainfall: equal to rainfall if smaller
>     // than interception capacity, and to interception capacity if
>     // larger.
>     if ( RR[ i ] < Rint[ i ] ) Rint[ i ] = RR[ i ];
>     // compute effective rainfall (rainfall minus intercepted
>     // rainfall).
>     RReff[ i ] = RR[ i ] - Rint[ i ];
>     // update interception storage: initial interception storage +
>     // intercepted
>     // rainfall.
>     storage = storage + Rint[ i ];
>     // compute evaporation from interception storage: equal to
>     // potential evapotranspiration if the latter is smaller than
>     // interception storage, and to interception storage if larger.
>     if ( storage > ETmax[ i ] )
>       evap = ETmax[ i ];
>     else
>       evap = storage;
>     // compute residual potentiel evapotranspiration: potential
>     // evapotranspiration minus evaporation from interception
>     // storage.
>     ETres[ i ] = ETmax[ i ] - evap;
>     // update interception storage, to be carried over to next
>     // time-step: interception storage minus evaporation from
>     // interception storage.
>     storage = storage - evap;
>   }
>   DataFrame DF = DataFrame::create( Named( \"int\" ) = Rint
>                                   , Named( \"RReff\" ) = RReff
>                                   , Named( \"ETres\" ) = ETres
>                                   );
>   return DF;
> }
> ")
>
> # Assumes your initial variables are already defined
> EvapSimRcpp( RR, ETmax, Smax, 0 )
>
> #######
>
> [1] 
> http://stackoverflow.com/questions/7153586/can-i-vectorize-a-calculation-which-depends-on-previous-elements
>
> On Sat, 6 Dec 2014, A Duranel wrote:
>
>> Hello
>> I use R to run a simple model of rainfall interception by vegetation:
>> rainfall falls on vegetation, some is retained by the vegetation 
>> (part of
>> which can evaporate), the rest falls on the ground (quite crude but very
>> similar to those used in SWAT or MikeSHE, for the hydrologists among 
>> you).
>> It uses a loop on zoo time-series of rainfall and potential
>> evapotranspiration. Unfortunately I did not find a way to vectorize 
>> it and
>> it takes ages to run on long datasets. Could anybody help me to make 
>> it run
>> faster?
>>
>> library(zoo)
>> set.seed(1)
>> # artificial potential evapotranspiration time-series
>> ETmax<-zoo(runif(10, min=1, max=6), c(1:10))
>> # artificial rainfall time-series
>> RR<-zoo(runif(10, min=0, max=6), c(1:10))
>>
>> ## create empty time-series to fill
>> # effective rainfall (i.e. rainfall minus intercepted rainfall)
>> RReff<-zoo(NA, c(1:10))
>> # intercepted rainfall
>> int<-zoo(NA, c(1:10))
>> # residual potential evapotranspiration (ie ETmax minus evaporation from
>> interception)
>> ETres<-zoo(NA, c(1:10))
>>
>> # define maximum interception storage capacity (maximum volume of 
>> rainfall
>> that can be intercepted per time step, provided the interception 
>> store is
>> empty at start of time-step)
>> Smax<-3
>> # volume of water in interception storage at start of computation
>> storage<-0
>>
>> for (i in 1:length(ETmax)) {
>>  # compute interception capacity for time step i (maximum interception
>> capacity minus any water intercepted but not evaporated during previous
>> time-step).
>>  int[i]<-Smax-storage
>>  # compute intercepted rainfall: equal to rainfall if smaller than
>> interception capacity, and to interception capacity if larger.
>>  if(RR[i]<int[i]) int[i]&lt;-RR[i]
>>  # compute effective rainfall (rainfall minus intercepted rainfall).
>>  RReff[i]&lt;-RR[i]-int[i]
>>  # update interception storage: initial interception storage + 
>> intercepted
>> rainfall.
>>  storage&lt;-storage+coredata(int[i])
>>  # compute evaporation from interception storage: equal to potential
>> evapotranspiration if the latter is smaller than interception 
>> storage, and
>> to interception storage if larger.
>>  if(storage>coredata(ETmax[i])) evap<-coredata(ETmax[i]) else 
>> evap<-storage
>>  # compute residual potentiel evapotranspiration: potential
>> evapotranspiration minus evaporation from interception storage.
>>  ETres[i]<-ETmax[i]-evap
>>  # update interception storage, to be carried over to next time-step:
>> interception storage minus evaporation from interception storage.
>>  storage<-storage-evap
>> }
>>
>> Many thanks for your help!
>>
>> Arnaud
>> UCL Department of Geography, UK
>>
>>
>>
>> -- 
>> View this message in context: 
>> http://r.789695.n4.nabble.com/vectorization-of-rolling-function-tp4700487.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --------------------------------------------------------------------------- 
>
> Jeff Newmiller                        The     .....       ..... Go 
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#. ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#.. Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#. with
> /Software/Embedded Controllers)               .OO#.       .OO#. 
> rocks...1k
> --------------------------------------------------------------------------- 
>
> .
>


From dmck at u.washington.edu  Mon Dec  8 21:26:18 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Mon, 8 Dec 2014 12:26:18 -0800
Subject: [R] data frame cumulative row sum
In-Reply-To: <DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>
References: <mailman.8.1417950005.3956.r-help@r-project.org>
	<DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>
Message-ID: <B1C86F74-F487-4224-BC83-EE4A087008F1@u.washington.edu>

my.data$z <- cumsum(my.data$y)

Yes, the function you need is even in your message subject.

> On Dec 8, 2014, at 12:18 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
> 
> Hi,
> Kindly I had a data frame looks like this
> x y  
> 1 3  
> 2 2  
> 3 1  
> 4 3  
> and I want to add column z that sum cumulativly like this
> x y z
> 1 3 3
> 2 2 5
> 3 1 6
> 4 3 9
> 
> how to do this?
> Regards
> Ragia
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Faculty
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From jdnewmil at dcn.davis.ca.us  Mon Dec  8 09:25:46 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 8 Dec 2014 00:25:46 -0800 (PST)
Subject: [R] vectorization of rolling function
In-Reply-To: <1417901458880-4700487.post@n4.nabble.com>
References: <1417901458880-4700487.post@n4.nabble.com>
Message-ID: <alpine.BSF.2.00.1412072329030.69489@pedal.dcn.davis.ca.us>

Please don't post in HTML... you may not recognize it, but the receiving 
end does not necessarily (and in this case did not) look like the sending 
end, and the cleanup can impede answers you are hoping to get.

In many cases, loops can be vectorized.  However, near as I can tell this 
is an example of an algorithm that simply needs a loop [1].

One bit of advice: the coredata function is horribly slow. Just converting 
your time series objects to numeric vectors for the purpose of this 
computation sped up the algorithm by 500x on 10000 point series. 
Converting it to inline C++ as below sped it up by yet another factor of 
40x. 20000x is nothing to sneeze at.

#######
## optional temporary setup for windows
## assumes you have installed Rtools
gcc <- "C:\\Rtools\\bin"
rtools <- "C:\\Rtools\\gcc-4.6.3\\bin"
path <- strsplit(Sys.getenv("PATH"), ";")[[1]]
new_path <- c(rtools, gcc, path)
new_path <- new_path[!duplicated(tolower(new_path))]
Sys.setenv(PATH = paste(new_path, collapse = ";"))
## end of optional

library(Rcpp)

cppFunction(
"DataFrame EvapSimRcpp( NumericVector RR
                       , NumericVector ETmax
                       , const double Smax
                       , const double initialStorage ) {
   int n = RR.size();

   // create empty time-series to fill
   // effective rainfall (i.e. rainfall minus intercepted rainfall)
   NumericVector RReff( n );
   // intercepted rainfall( n );
   NumericVector Rint( n );
   // residual potential evapotranspiration (ie ETmax minus
   // evaporation from interception)
   NumericVector ETres( n, NA_REAL );
   double evap;

   // volume of water in interception storage at start of
   // computation
   double storage = initialStorage;

   for ( int i=0; i<n; i++ ) {
     // compute interception capacity for time step i (maximum
     // interception capacity minus any water intercepted but not
     // evaporated during previous time-step).
     Rint[ i ] = Smax - storage;
     // compute intercepted rainfall: equal to rainfall if smaller
     // than interception capacity, and to interception capacity if
     // larger.
     if ( RR[ i ] < Rint[ i ] ) Rint[ i ] = RR[ i ];
     // compute effective rainfall (rainfall minus intercepted
     // rainfall).
     RReff[ i ] = RR[ i ] - Rint[ i ];
     // update interception storage: initial interception storage +
     // intercepted
     // rainfall.
     storage = storage + Rint[ i ];
     // compute evaporation from interception storage: equal to
     // potential evapotranspiration if the latter is smaller than
     // interception storage, and to interception storage if larger.
     if ( storage > ETmax[ i ] )
       evap = ETmax[ i ];
     else
       evap = storage;
     // compute residual potentiel evapotranspiration: potential
     // evapotranspiration minus evaporation from interception
     // storage.
     ETres[ i ] = ETmax[ i ] - evap;
     // update interception storage, to be carried over to next
     // time-step: interception storage minus evaporation from
     // interception storage.
     storage = storage - evap;
   }
   DataFrame DF = DataFrame::create( Named( \"int\" ) = Rint
                                   , Named( \"RReff\" ) = RReff
                                   , Named( \"ETres\" ) = ETres
                                   );
   return DF;
}
")

# Assumes your initial variables are already defined
EvapSimRcpp( RR, ETmax, Smax, 0 )

#######

[1] http://stackoverflow.com/questions/7153586/can-i-vectorize-a-calculation-which-depends-on-previous-elements

On Sat, 6 Dec 2014, A Duranel wrote:

> Hello
> I use R to run a simple model of rainfall interception by vegetation:
> rainfall falls on vegetation, some is retained by the vegetation (part of
> which can evaporate), the rest falls on the ground (quite crude but very
> similar to those used in SWAT or MikeSHE, for the hydrologists among you).
> It uses a loop on zoo time-series of rainfall and potential
> evapotranspiration. Unfortunately I did not find a way to vectorize it and
> it takes ages to run on long datasets. Could anybody help me to make it run
> faster?
>
> library(zoo)
> set.seed(1)
> # artificial potential evapotranspiration time-series
> ETmax<-zoo(runif(10, min=1, max=6), c(1:10))
> # artificial rainfall time-series
> RR<-zoo(runif(10, min=0, max=6), c(1:10))
>
> ## create empty time-series to fill
> # effective rainfall (i.e. rainfall minus intercepted rainfall)
> RReff<-zoo(NA, c(1:10))
> # intercepted rainfall
> int<-zoo(NA, c(1:10))
> # residual potential evapotranspiration (ie ETmax minus evaporation from
> interception)
> ETres<-zoo(NA, c(1:10))
>
> # define maximum interception storage capacity (maximum volume of rainfall
> that can be intercepted per time step, provided the interception store is
> empty at start of time-step)
> Smax<-3
> # volume of water in interception storage at start of computation
> storage<-0
>
> for (i in 1:length(ETmax)) {
>  # compute interception capacity for time step i (maximum interception
> capacity minus any water intercepted but not evaporated during previous
> time-step).
>  int[i]<-Smax-storage
>  # compute intercepted rainfall: equal to rainfall if smaller than
> interception capacity, and to interception capacity if larger.
>  if(RR[i]<int[i]) int[i]&lt;-RR[i]
>  # compute effective rainfall (rainfall minus intercepted rainfall).
>  RReff[i]&lt;-RR[i]-int[i]
>  # update interception storage: initial interception storage + intercepted
> rainfall.
>  storage&lt;-storage+coredata(int[i])
>  # compute evaporation from interception storage: equal to potential
> evapotranspiration if the latter is smaller than interception storage, and
> to interception storage if larger.
>  if(storage>coredata(ETmax[i])) evap<-coredata(ETmax[i]) else evap<-storage
>  # compute residual potentiel evapotranspiration: potential
> evapotranspiration minus evaporation from interception storage.
>  ETres[i]<-ETmax[i]-evap
>  # update interception storage, to be carried over to next time-step:
> interception storage minus evaporation from interception storage.
>  storage<-storage-evap
> }
>
> Many thanks for your help!
>
> Arnaud
> UCL Department of Geography, UK
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/vectorization-of-rolling-function-tp4700487.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Mon Dec  8 09:57:13 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 8 Dec 2014 00:57:13 -0800 (PST)
Subject: [R] date time problem
In-Reply-To: <CACGkHRPxtuKXNAGhOOE22aNE9BK73Kp1ZEak0o9efYVAgsnpRg@mail.gmail.com>
References: <CACGkHRM5GZKMS=Rr6M8ESV81uW5PjZiK5qr_oCKpNCFvrhWwsw@mail.gmail.com>
	<alpine.BSF.2.00.1412071226430.29350@pedal.dcn.davis.ca.us>
	<CACGkHRPxtuKXNAGhOOE22aNE9BK73Kp1ZEak0o9efYVAgsnpRg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1412080030290.77922@pedal.dcn.davis.ca.us>

You are still posting in HTML, and it is continuing to impede this 
conversation. Learn how to post in plain text before posting again. Gmail 
does have this option.

You are not using dput, as previously asked, either. Read the web page I 
referenced to learn how to send R data unambiguously.

Your time sequence appears to include 2AM at the spring DST change... no 
such point in time exists if you are working with DST, as the clock goes 
from 01:59:59 to 03:00:00.  I suggest that instead of "EST5EDT" you 
specify timezone "Etc/GMT+5" which does not attempt to infer any DST in 
the data.  "EST" may also work, but there are other timezones in the world 
that are referred to by that label, so it may mislead you or not work at 
all in the future.

> tc <- "3/11/2007 2:00"'
> tct <- as.POSIXct( tc, format="%m/%d/%Y %H:%M", tz="Etc/GMT+5")
> tct
[1] "2007-03-11 02:00:00 GMT+5"
> as.POSIXct( tc, format="%m/%d/%Y %H:%M", tz="EST5EDT")
[1] NA
> format(tct, tz="Etc/GMT", usetz=TRUE )
[1] "2007-03-11 07:00:00 GMT"

On Sun, 7 Dec 2014, Alemu Tadesse wrote:

> Thank you very much Jeff. Below is the data I used:> Corrected_data
> ? ? ? ? ? ? ? SA_LST SA_GHI_mean
> 61759 3/11/2007 1:00 ? ? 0.00000
> 67517 3/11/2007 2:00 ? ? 0.00000
> 70017 3/11/2007 3:00 ? ? 0.00000
> 70524 3/11/2007 4:00 ? ? 0.00000
> 71061 3/11/2007 5:00 ? ? 0.00000
> 71638 3/11/2007 6:00 ? ? 0.00000
> 72113 3/11/2007 7:00 ? ?20.20873
> 72629 3/11/2007 8:00 ? 123.14231
> 73274 3/11/2007 9:00 ? 306.97343
> 
> >test1<-as.POSIXct(Corrected_data$SA_LST,format="%m/%d/%Y %H:%M", tz="EST5EDT")
> >test1
> [1] "2007-03-11 01:00:00 EST" NA ? ? ? ? ? ? ? ? ? ? ? ?"2007-03-11 03:00:00 EDT" "2007-03-11 04:00:00 EDT"
> [5] "2007-03-11 05:00:00 EDT" "2007-03-11 06:00:00 EDT" "2007-03-11 07:00:00 EDT" "2007-03-11 08:00:00 EDT"
> [9] "2007-03-11 09:00:00 EDT"
> 
> > format(test1, tz="Etc/GMT", usetz=TRUE )
> [1] "2007-03-11 06:00:00 GMT" NA ? ? ? ? ? ? ? ? ? ? ? ?"2007-03-11 07:00:00 GMT" "2007-03-11 08:00:00 GMT"
> [5] "2007-03-11 09:00:00 GMT" "2007-03-11 10:00:00 GMT" "2007-03-11 11:00:00 GMT" "2007-03-11 12:00:00 GMT"
> [9] "2007-03-11 13:00:00 GMT"
> >
> 
> As you can see the "2007-03-11 02:00:00 EST" is not recognized and returned as NA. This may be due to DST, which I do not know
> how to handle in R.
> 
> Best,
> 
> Alemu?
> 
> 
> On Sun, Dec 7, 2014 at 1:59 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>       You have not provided a reproducible example, so anything I say could be wrong just due to misinterpretation.
>       Please read [1] for suggestions on making your examples reproducible, particularly regarding the use of dput to
>       provide example data. You have also posted in HTML format, which can cause additional scrambling of communications
>       on this list.
>
>       >From the notation you are using, I would guess that "Corrected_SA_data" is a data frame containing columns
>       "date_time" and "TZ" at a minimum. The "date_time" column could be a vector of class POSIXlt or POSIXct... except
>       that I cannot reproduce such an object that doesn't print some kind of timezone indicator in its output. What
>       version of R are you using? Note that such an object contains a tz attribute already, so unless you have already
>       made sure that the date_time column knows about that timezone, they are probably unrelated to each other.
>
>       Note that any POSIXct object is internally represented as a specific instant of time. The tz attribute is only used
>       to control how that time will be displayed. For example:
>
>       testtime3 <- as.POSIXct( rawtime1, tz="America/New_York" )
>       format( testtime3, tz="Etc/GMT", usetz=TRUE )
>
>       If you want the output to omit the timezone information you can omit the usetz argument:
>
>       format( testtime3, tz="Etc/GMT" )
>
>       If you have not yet, you should read [2]. Note that three-letter timezone indicators (even though they are given in
>       OUTPUT!) are at best unreliable for use in specifying timezones in R... read ?timezones.
>
>       [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>       [2] http://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf
>
>       On Sun, 7 Dec 2014, Alemu Tadesse wrote:
>
>       Dear R users
>
>       I am puzzled by the following result from R script. I am trying to convert
>       local time to UTC time. Time zone is -5, therefore I used the following
>       approach.
>
>       Below is the script.
>             Corrected_SA_data$date_time[k-1]
>
>       [1] "2007-03-11 01:00:00"
>             Corrected_SA_data$TZ[k-1]
>
>       [1] -5
>             Corrected_SA_data$date_time[k-1]-Corrected_SA_data$TZ[k-1]*3600
>
>       [1] "2007-03-11 07:00:00 MDT"
>
>       I was expecting this last value to be something like "2007-03-11 06:00:00
>       UTC"
>
>       Please correct me if I ma wrong.
>
>       On the other hand I have
>             Corrected_SA_data$date_time[k]
>
>       [1] "2007-03-11 02:00:00"
>             Corrected_SA_data$TZ[k]
>
>       [1] -5
>             Corrected_SA_data$date_time[k]-Corrected_SA_data$TZ[k]*3600
>
>       [1] NA
>
>       I am not sure why I am getting NA.
>
>       Thank you for your help.
>
>       Alemu
> 
> ? ? ? ? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? ?.....? ? ? ?.....? Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ?##.#.? Live Go...
> ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? ?OO#.. Dead: OO#..? Playing
> Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? ?#.O#.? with
> /Software/Embedded Controllers)? ? ? ? ? ? ? ?.OO#.? ? ? ?.OO#.? rocks...1k
> ---------------------------------------------------------------------------
> 
> 
> 
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From petr.pikal at precheza.cz  Mon Dec  8 15:39:31 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Dec 2014 14:39:31 +0000
Subject: [R] Passing data to t.test in loop
In-Reply-To: <EE85AFC56BE9E84EB86F7739169F1BD64D594E5A@MBXP15.ds.man.ac.uk>
References: <EE85AFC56BE9E84EB86F7739169F1BD64D594E5A@MBXP15.ds.man.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF11DD@SRVEXCHMBX.precheza.cz>

Hi

Is this what you want?

by(data$time, list(data$size), function(x) t.test(x))

Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Paul
> Johnston
> Sent: Tuesday, December 02, 2014 10:17 AM
> To: R-help at lists.R-project.org
> Subject: [R] Passing data to t.test in loop
>
> Dear All
>
> First post so sorry for any breaches of etiquette.
> I have a csv containing the results for a series of experiments which
> record the time taken for various sizes of iterations.
>
> "run_id","size","time"
> 1,100,1.00
> 2,200,2.100
> 3,100,1.100
> 4,200,2.100
> 5,200,1.900
> 6,300,4.00
> 7,200,2.5
> ...
>
> I read the data set, extract the results for each "size" and return
> various statistics.
> The only problem is I would like to iterate over the distinct sizes to
> do a t.test
> My code has a section commented #manual t.test but I have no luck with
> the attempt labelled #attempt to automate t.test
> I'm assuming it's my attempt to pass the data as an argument to
> t.test()
>
> Any pointers gratefully accepted but as I'm a learner hints rather than
> a solution are preferred.
>
> Cheers Paul
>
> getwd()
> setwd("c:/work/R/experiment1")
> # read raw experimental data from results file
> data <- read.csv("data1.csv", header = TRUE)
> data
> #create a new dataframe which has space for a record for each unique
> size of experiment
> # this is to collect collated statistics for each experiment
>
> var_list <- c("num_obs", "size_run",
> "sample_mean","sample_var","std_dev","se")
> var_list_length <- length(var_list)
> num_experiments <- length(unique(data$size))
> # create the dataframe
> df = data.frame(matrix(vector(), num_experiments , var_list_length,
> dimnames=list(c(),var_list)), stringsAsFactors=F)
> # it should be empty
> df
> # insert the experiment size
> df$size_run <- unique(data$size)
> # now it should have a single column filled
> # using
> df$size_run
> df
> # create a vector with the experiment sizes
>
> for (i in df$size_run)
> {
> # calculate the sample_variance of observations on a particular size
> df$sample_var[df$size == i] <- var(subset(data$time, data$size == i))
>
> # calculate the mean of the returned values for all experiments of the
> same size
> df$sample_mean[df$size == i] <- mean(subset(data$time, data$size ==i))
>
> # calculate the number of observations on a particular size
> df$num_obs[df$size == i] <- length(subset(data$time, data$size == i))
>
> # calculate the sd of the data
> df$std_dev[df$size == i] <- sd(subset(data$time, data$size == i))
>
> # calculate the standard error
> df$se[df$size == i] <- sd(subset(data$time, data$size
> ==i))/sqrt(length(subset(data$time, data$size ==i)))
> }
>
> df
>
> #manual t.test
> print("t.test for size  = 100")
> t.test(subset(data$time, data$size == 100))
>
> print("t.test for size  = 200")
> t.test(subset(data$time, data$size == 200))
>
> print("t.test for size  = 300")
> t.test(subset(data$time, data$size == 300))
>
> #attempt to automate t.test
> for (i in df$size_run)
> {
> print(i)
> a <- subset(data$time, data$size == i)
> print(a)
> t.test(a)
> }
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From alaios at yahoo.com  Mon Dec  8 19:45:29 2014
From: alaios at yahoo.com (Alaios)
Date: Mon, 8 Dec 2014 18:45:29 +0000 (UTC)
Subject: [R] combining two distributions
In-Reply-To: <608563335.4057300.1418039527824.JavaMail.yahoo@jws100179.mail.ne1.yahoo.com>
References: <608563335.4057300.1418039527824.JavaMail.yahoo@jws100179.mail.ne1.yahoo.com>
Message-ID: <2045808461.192274.1418064329203.JavaMail.yahoo@jws10044.mail.ne1.yahoo.com>

(I am sorry if you have received this email twice but it does not look sent on my client)

  

 Hi all,I am having some heavy tailed data and I am trying to think of the more appropriate package for the fitting.The canonical try should be something like exponential and pareto or exponential + gamma (or gamma + gamma with different shape parameters). I am trying to have one distribution that is "classical" thin tailed one and another one which is more like a power law or close (pareto,gamma,weibull, log-normal).
Do you have any recommendation with which packages I can start on and if the functions you have in mind they can also provide information like AIC or BIC so to help me choose the best combinations?
I would like to thank you in advance for your help
RegardsAlex

    
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Dec  8 21:35:59 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 09 Dec 2014 09:35:59 +1300
Subject: [R] MLE with parameters restricted to a defined range using
	bbmle
In-Reply-To: <1067011741.4187447.1418069090594.JavaMail.yahoo@jws10098.mail.ne1.yahoo.com>
References: <1067011741.4187447.1418069090594.JavaMail.yahoo@jws10098.mail.ne1.yahoo.com>
Message-ID: <54860BAF.1040500@auckland.ac.nz>



I know nothing about the bbmle package and its mle2() function, but it 
is a general truth that if you need to constrain a parameter to be 
positive in an optimisation procedure a simple and effective approach is 
to reparameterize using exp().

I.e. represent xmin as exp(lxmin) (say) and use lxmin as the argument
to your objective function.

This strategy rarely if ever fails to work.

cheers,

Rolf Turner

On 09/12/14 09:04, Bernardo Santos wrote:
> Dear all,
> I am fitting models to data with mle2 function of the bbmle package.In specific, I want to fit a power-law distribution model, as defined here (http://arxiv.org/pdf/cond-mat/0412004v3.pdf), to data.
> However, one of the parameters - xmin -, must be necessarily greater than zero. What can I do to restrict the possible values of a parameter that are passed to the optimizer?
> Here there is a sample of my code:
> # Loading library
> library(bbmle)
>
> # Creating data
> set.seed(1234)
> data <- rexp(1000, rate = 0.1) # The fit will not be too good, but it is just to test
>
> # Creating the power-law distribution density function
> dpowlaw <- function(x, alfa, xmin, log=FALSE){
>    c <- (alfa-1)*xmin^(alfa-1)
>    if(log) ifelse(x < xmin, 0, log(c*x^(-alfa)))
>    else ifelse(x < xmin, 0, c*x^(-alfa))
> }
> # Testing the function
> integrate(dpowlaw, -Inf, Inf, alfa=2, xmin=1)
> curve(dpowlaw(x, alfa=2.5, xmin=10), from=0, to=100, log="")
> curve(dpowlaw(x, alfa=2.5, xmin=1), from=1, to=100, log="xy")
>
> # Negative log-likelihood function
> LLlevy <- function(mu, xmin){
>    -sum(dpowlaw(data, alfa=mu, xmin=xmin, log=T))
> }
>
> # Fitting model to data
> mlevy <- mle2(LLlevy, start=list(mu=2, xmin=1))
> The result of model fitting here is Coefficients:
>         mu      xmin
> -916.4043  890.4248
> but this does not make sense!xmin must be > 0, and mu must be > 1.What should I do?
> Thanks in advance!Bernardo Niebuhr

-- 
Rolf Turner
Technical Editor ANZJS


From ruipbarradas at sapo.pt  Mon Dec  8 21:37:52 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 08 Dec 2014 20:37:52 +0000
Subject: [R] data frame cumulative row sum
In-Reply-To: <DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>
References: <mailman.8.1417950005.3956.r-help@r-project.org>
	<DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>
Message-ID: <54860C20.60504@sapo.pt>

Hello,

If your dataset is named 'dat', try

dat$z <- cumsum(dat$y)


Hope this helps,

Rui Barradas

Em 08-12-2014 08:18, Ragia Ibrahim escreveu:
> Hi,
> Kindly I had a data frame looks like this
> x y
> 1 3
> 2 2
> 3 1
> 4 3
> and I want to add column z that sum cumulativly like this
> x y z
> 1 3 3
> 2 2 5
> 3 1 6
> 4 3 9
>
> how to do this?
> Regards
> Ragia
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ch_koch at gmx.de  Mon Dec  8 21:21:36 2014
From: ch_koch at gmx.de (apeshifter)
Date: Mon, 8 Dec 2014 12:21:36 -0800 (PST)
Subject: [R] Finding unique elements faster
Message-ID: <1418070096499-4700539.post@n4.nabble.com>

Dear all, 

for the past two weeks, I've been working on a script to retrieve word pairs
and calculate some of their statistics using R. Everything seemed to work
fine until I switched from a small test dataset to the 'real thing' and
noticed what a runtime monster I had devised! 

I could reduce processing time significantly when I realized that with R, I
did not have to do everything in loops and count things vector element by
vector element, but could just have the program count everything with
tables, e.g. with 
  > freq.w1w2.2<-table(all.word.pairs)[all.word.pairs]

However, now I seem to have run into a performance problem that I cannot
solve. I hope there's a kind soul on this list who has some advice for me.
On to the problem:

The last relic of the afore-mentioned for-loop that goes through all the
word pairs and tries to calculate some statistics on them is the following
line of code:
  > typefreq.after1[i]<-length(unique(word2[which(word1==word1[i])]))
(where word1 and word2 are the first and second word within the two-word
sequence (all.word.pairs, above)
  
Here, I am trying to count the number of 'types', linguistically speaking,
before the second word in the two-word sequence (later, I am doing the same
for the first word within the sequence). The expression works, but given my
~400,000 word pairs/word1's/word2's etc, this takes quite some time. About
10 hours on my machine, in fact, since R cannot use the other three of the
four cores. Since I want to repeat the process for another 20 corpora of
similar size, I would definitely appreciate some help on this subject.

I have been trying 'typefreq.after1<-table(unique(word2[word1]))[2]' and the
subset() function and both seem to work (though I haven't checked whether
all the numbers are in fact correctly calculated), but they take about the
same amount of time. So that's no use for me. 

Does anybody have any tips to speed this up?

Thank you very much!



--
View this message in context: http://r.789695.n4.nabble.com/Finding-unique-elements-faster-tp4700539.html
Sent from the R help mailing list archive at Nabble.com.


From lambertd at ksu.edu  Mon Dec  8 17:42:57 2014
From: lambertd at ksu.edu (David Lambert)
Date: Mon, 8 Dec 2014 16:42:57 +0000
Subject: [R] Merging two data.frames
Message-ID: <1418056976565.67668@ksu.edu>

I have 2 data frames, M1[n,20] and M2[m,30].


If V1 and V2 are the same in both M1 and M2, then append V3-V30 from M2 onto M1.


Otherwise, continue searching for a match.


M1 is complete for all V1 and V2.  M2 is missing observations for V1 or V2, or both.


I can't figure this one out, except with reference to my old fortran-era skills.  Help!

	[[alternative HTML version deleted]]


From vassiliki.marinou at gmail.com  Mon Dec  8 20:09:14 2014
From: vassiliki.marinou at gmail.com (Vassiliki Marinou)
Date: Mon, 8 Dec 2014 21:09:14 +0200
Subject: [R] My code needs improvement
Message-ID: <CAAOXzXWiNMq6Qp6Yw+insoCd8hMy17Z13rq08snNnccFrLwQnw@mail.gmail.com>

Hello!

I am performing a sentiment analysis of 2.000 negative and positive reviews.
I think my code needs improvement because I am getting accuracy 68 % and
the running duration of the code is 20 minutes!! Please find below a part
of the code.

"
# Read data from their directories
pos <- Corpus(DirSource(pos_dir), readerControl=list(language="english",
reader=readPlain))
neg <- Corpus(DirSource(neg_dir), readerControl=list(language="english",
reader=readPlain))
# Create training and testing corpuses
print("Creating training and testing corpuses...")
split.percentage      <- 0.75
split.pos.size        <- length(pos)
split.neg.size        <- length(neg)
split.pos.train.size  <- floor(split.pos.size * split.percentage)
split.neg.train.size  <- floor(split.neg.size * split.percentage)
split.pos.test.size   <- split.pos.size - split.pos.train.size
split.neg.test.size   <- split.neg.size - split.neg.train.size
corpus.train          <- c(pos[1:split.pos.train.size],
neg[1:split.neg.train.size])
corpus.test           <- c(pos[(split.pos.train.size + 1) :
split.pos.size],
                           neg[(split.neg.train.size + 1) : split.neg.size])
# Perform  preprocessing
print("Pre-processing corpuses...")
corpus.train <- preProcess(corpus.train)
corpus.test  <- preProcess(corpus.test)
# Create the Document Term Matrix
print("Creating document term matrices...")
corpus.train.dtm <- DocumentTermMatrix(corpus.train,
control=list(minWordLength = 2))
corpus.test.dtm  <- DocumentTermMatrix(corpus.test,
control=list(minWordLength = 2))
# Create the Data Frame
print("Creating data matrices...")
corpus.train.df <- as.matrix(corpus.train.dtm)
corpus.test.df  <- as.matrix(corpus.test.dtm)
# Generate vector with class values
print("Creating class information...")
class.train <- c(rep("pos", split.pos.train.size), rep("neg",
split.neg.train.size))
class.test  <- c(rep("pos", split.pos.test.size), rep("neg",
split.neg.test.size))
# Train classifier
print("Training classifier...")
classifier <- naiveBayes(corpus.train.df, as.factor(class.train))
# Evaluate Classifier
print("Evaluating... Please be patient. This will take a while...")
corpus.predictions <- predict(classifier, corpus.test.df)
table(corpus.predictions, class.test)
"
I could use some ideas.

Thank you for your time.

V.

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Dec  8 21:40:19 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 09 Dec 2014 09:40:19 +1300
Subject: [R] data frame cumulative row sum
In-Reply-To: <DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>
References: <mailman.8.1417950005.3956.r-help@r-project.org>
	<DUB125-W1342640BDCBE33F1CA5A34B3640@phx.gbl>
Message-ID: <54860CB3.8080709@auckland.ac.nz>

On 08/12/14 21:18, Ragia Ibrahim wrote:
> Hi,
> Kindly I had a data frame looks like this
> x y
> 1 3
> 2 2
> 3 1
> 4 3
> and I want to add column z that sum cumulativly like this
> x y z
> 1 3 3
> 2 2 5
> 3 1 6
> 4 3 9
>
> how to do this?

(1) Learn to use R.  This is very basic; read some introductory 
material.  Start with "An Introduction to R" from the R web site.

This is analogous to the assertion that you shouldn't be driving a car 
if you haven't a clue how to drive.

(2) Try:

X$z <- cumsum(X$y)

where X is the data frame in question.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From ntfredo at gmail.com  Mon Dec  8 12:25:59 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Mon, 8 Dec 2014 14:25:59 +0300
Subject: [R] Making random values which are binary numbers
Message-ID: <CAGh51gQpCzFO3LxgrZi8cA+wEEjto7J6VJw-vRigTXkvUp09BQ@mail.gmail.com>

Hi All,

i would like to write a srcipt which ruturn the random numbers which are
binary numbers.

Example: The first group : 111111111
               second : 0000000000000
               third : 10101000011100

in such away that i can make iterartions.


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From gangchen6 at gmail.com  Mon Dec  8 18:08:27 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Mon, 8 Dec 2014 12:08:27 -0500
Subject: [R] String manipulation
Message-ID: <CAHmzXO572nVzE+Vx_nd1r+LRJCC8PDeFap2jTE1hCsvw9r8hXQ@mail.gmail.com>

I want to do the following: if a string does not contain a colon (:),
no change is needed; if it contains one or more colons, break the
string into multiple strings using the colon as a separator. For
example, "happy:" becomes

"happy" ":"

":sad" turns to

":" "sad"

and "happy:sad" changes to

"happy" ":" "sad"

How to do this?

Thanks,
Gang


From murdoch.duncan at gmail.com  Mon Dec  8 22:01:29 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 08 Dec 2014 16:01:29 -0500
Subject: [R] Making random values which are binary numbers
In-Reply-To: <CAGh51gQpCzFO3LxgrZi8cA+wEEjto7J6VJw-vRigTXkvUp09BQ@mail.gmail.com>
References: <CAGh51gQpCzFO3LxgrZi8cA+wEEjto7J6VJw-vRigTXkvUp09BQ@mail.gmail.com>
Message-ID: <548611A9.601@gmail.com>

On 08/12/2014 6:25 AM, Frederic Ntirenganya wrote:
> Hi All,
>
> i would like to write a srcipt which ruturn the random numbers which are
> binary numbers.
>
> Example: The first group : 111111111
>                 second : 0000000000000
>                 third : 10101000011100
>
> in such away that i can make iterartions.

I'm not sure what you mean by the last part, but you can generate binary 
data using rbinom:

firstgroup <- rbinom(9, size=1, prob=0.999)
second <- rbinom(13, size=1, prob=0.001)
third <- rbinom(14, size=1, prob=0.5)

Duncan Murdoch
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Dec  8 22:13:23 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Dec 2014 13:13:23 -0800
Subject: [R] String manipulation
In-Reply-To: <CAHmzXO572nVzE+Vx_nd1r+LRJCC8PDeFap2jTE1hCsvw9r8hXQ@mail.gmail.com>
References: <CAHmzXO572nVzE+Vx_nd1r+LRJCC8PDeFap2jTE1hCsvw9r8hXQ@mail.gmail.com>
Message-ID: <CAF8bMcaOsaB_O128EOP4sHNSrgDoyWS=3Zic+eMqG=H76pvhgw@mail.gmail.com>

strsplit(split=":") does almost what you want, but it omits the colons from
the output.  You can use perl zero-length look-ahead and look-behind
operators in the split argument to get the colons as well:

> strsplit(c(":sad", "happy:", "happy:sad"), split="(?<=:)|(?=:)",
perl=TRUE)
[[1]]
[1] ":"   "sad"

[[2]]
[1] "happy" ":"

[[3]]
[1] "happy" ":"     "sad"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 8, 2014 at 9:08 AM, Gang Chen <gangchen6 at gmail.com> wrote:

> I want to do the following: if a string does not contain a colon (:),
> no change is needed; if it contains one or more colons, break the
> string into multiple strings using the colon as a separator. For
> example, "happy:" becomes
>
> "happy" ":"
>
> ":sad" turns to
>
> ":" "sad"
>
> and "happy:sad" changes to
>
> "happy" ":" "sad"
>
> How to do this?
>
> Thanks,
> Gang
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Dec  8 22:20:30 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Dec 2014 13:20:30 -0800
Subject: [R] String manipulation
In-Reply-To: <CAF8bMcaOsaB_O128EOP4sHNSrgDoyWS=3Zic+eMqG=H76pvhgw@mail.gmail.com>
References: <CAHmzXO572nVzE+Vx_nd1r+LRJCC8PDeFap2jTE1hCsvw9r8hXQ@mail.gmail.com>
	<CAF8bMcaOsaB_O128EOP4sHNSrgDoyWS=3Zic+eMqG=H76pvhgw@mail.gmail.com>
Message-ID: <CAF8bMcamatDk5EOq-zOCai414psMkL0jo5jtVK99Lik+K=pm0g@mail.gmail.com>

Actually, the zero-length look-ahead expression is enough to get the job
done:

> strsplit(c(":sad", "happy:", "happy:sad", ":happy:sad:subdued:"),
split="(?=:)", perl=TRUE)
[[1]]
[1] ":"   "sad"

[[2]]
[1] "happy" ":"

[[3]]
[1] "happy" ":"     "sad"

[[4]]
[1] ":"       "happy"   ":"       "sad"     ":"       "subdued" ":"



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 8, 2014 at 1:13 PM, William Dunlap <wdunlap at tibco.com> wrote:

> strsplit(split=":") does almost what you want, but it omits the colons
> from the output.  You can use perl zero-length look-ahead and look-behind
> operators in the split argument to get the colons as well:
>
> > strsplit(c(":sad", "happy:", "happy:sad"), split="(?<=:)|(?=:)",
> perl=TRUE)
> [[1]]
> [1] ":"   "sad"
>
> [[2]]
> [1] "happy" ":"
>
> [[3]]
> [1] "happy" ":"     "sad"
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Dec 8, 2014 at 9:08 AM, Gang Chen <gangchen6 at gmail.com> wrote:
>
>> I want to do the following: if a string does not contain a colon (:),
>> no change is needed; if it contains one or more colons, break the
>> string into multiple strings using the colon as a separator. For
>> example, "happy:" becomes
>>
>> "happy" ":"
>>
>> ":sad" turns to
>>
>> ":" "sad"
>>
>> and "happy:sad" changes to
>>
>> "happy" ":" "sad"
>>
>> How to do this?
>>
>> Thanks,
>> Gang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Dec  8 22:38:24 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 8 Dec 2014 13:38:24 -0800 (PST)
Subject: [R] Merging two data.frames
In-Reply-To: <1418056976565.67668@ksu.edu>
References: <1418056976565.67668@ksu.edu>
Message-ID: <alpine.BSF.2.00.1412081330370.41489@pedal.dcn.davis.ca.us>

Below...

On Mon, 8 Dec 2014, David Lambert wrote:

> I have 2 data frames, M1[n,20] and M2[m,30].

What does this mean? It might be intended to convey matrix dimensions, but 
these are not matrices and that is not R syntax.

> If V1 and V2 are the same in both M1 and M2, then append V3-V30 from M2 onto M1.

What does this mean? V3 is a default column label for data frames, but 
to just refer to V3 suggests an entire column, which doesn't make sense. 
If you mean individual values in the matching row, then where do you plan 
to put 27 values into M1?

> Otherwise, continue searching for a match.
>
>
> M1 is complete for all V1 and V2.  M2 is missing observations for V1 or V2, or both.
>
>
> I can't figure this one out, except with reference to my old fortran-era skills.  Help!
>
> 	[[alternative HTML version deleted]]

This desperately needs a reproducible example with a few matches and 
non-matches.  Of course, if you email R code using HTML format it will 
likely get corrupted along the way, which is why the Posting Guide asks 
you to post in PLAIN TEXT format.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Mon Dec  8 22:47:31 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 8 Dec 2014 13:47:31 -0800 (PST)
Subject: [R] Finding unique elements faster
In-Reply-To: <1418070096499-4700539.post@n4.nabble.com>
References: <1418070096499-4700539.post@n4.nabble.com>
Message-ID: <alpine.BSF.2.00.1412081340580.41489@pedal.dcn.davis.ca.us>

The data.table package might be of use to you, but lacking a reproducible 
example [1] I think I will leave figuring out just how to you.

Being on Nabble you may not be able to see the footer appended to every 
message on this MAILING LIST. For your benefit, here it is:

* R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
* https://stat.ethz.ch/mailman/listinfo/r-help
* PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
* and provide commented, minimal, self-contained, reproducible code.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

On Mon, 8 Dec 2014, apeshifter wrote:

> Dear all,
>
> for the past two weeks, I've been working on a script to retrieve word pairs
> and calculate some of their statistics using R. Everything seemed to work
> fine until I switched from a small test dataset to the 'real thing' and
> noticed what a runtime monster I had devised!
>
> I could reduce processing time significantly when I realized that with R, I
> did not have to do everything in loops and count things vector element by
> vector element, but could just have the program count everything with
> tables, e.g. with
>  > freq.w1w2.2<-table(all.word.pairs)[all.word.pairs]
>
> However, now I seem to have run into a performance problem that I cannot
> solve. I hope there's a kind soul on this list who has some advice for me.
> On to the problem:
>
> The last relic of the afore-mentioned for-loop that goes through all the
> word pairs and tries to calculate some statistics on them is the following
> line of code:
>  > typefreq.after1[i]<-length(unique(word2[which(word1==word1[i])]))
> (where word1 and word2 are the first and second word within the two-word
> sequence (all.word.pairs, above)
>
> Here, I am trying to count the number of 'types', linguistically speaking,
> before the second word in the two-word sequence (later, I am doing the same
> for the first word within the sequence). The expression works, but given my
> ~400,000 word pairs/word1's/word2's etc, this takes quite some time. About
> 10 hours on my machine, in fact, since R cannot use the other three of the
> four cores. Since I want to repeat the process for another 20 corpora of
> similar size, I would definitely appreciate some help on this subject.
>
> I have been trying 'typefreq.after1<-table(unique(word2[word1]))[2]' and the
> subset() function and both seem to work (though I haven't checked whether
> all the numbers are in fact correctly calculated), but they take about the
> same amount of time. So that's no use for me.
>
> Does anybody have any tips to speed this up?
>
> Thank you very much!
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Finding-unique-elements-faster-tp4700539.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From wdunlap at tibco.com  Mon Dec  8 22:47:38 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Dec 2014 13:47:38 -0800
Subject: [R] Merging two data.frames
In-Reply-To: <1418056976565.67668@ksu.edu>
References: <1418056976565.67668@ksu.edu>
Message-ID: <CAF8bMcaN5_WbLryWPBxRAnSjbN47Y95yJLP0BJ=ug+V+ZYO68w@mail.gmail.com>

Have you looked at the merge() function?

Here is an example.  I don't know if it resembles your problem.

  > M1 <- data.frame(V1=letters[1:3], V2=LETTERS[26:24], N1=101:103)
  > M2 <- data.frame(V1=letters[c(3,1,2,3,2)],
V2=LETTERS[c(23,26,22,24,24)],   N2=c(1003,1001,1002,1003,1002))
  > merge(M1,M2)
    V1 V2  N1   N2
  1  a  Z 101 1001
  2  c  X 103 1003
  > merge(M1, M2, all.x=TRUE)
    V1 V2  N1   N2
  1  a  Z 101 1001
  2  b  Y 102   NA
  3  c  X 103 1003
  > merge(M1, M2, all.y=TRUE)
    V1 V2  N1   N2
  1  a  Z 101 1001
  2  b  X  NA 1002
  3  b  V  NA 1002
  4  c  X 103 1003
  5  c  W  NA 1003



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 8, 2014 at 8:42 AM, David Lambert <lambertd at ksu.edu> wrote:

> I have 2 data frames, M1[n,20] and M2[m,30].
>
>
> If V1 and V2 are the same in both M1 and M2, then append V3-V30 from M2
> onto M1.
>
>
> Otherwise, continue searching for a match.
>
>
> M1 is complete for all V1 and V2.  M2 is missing observations for V1 or
> V2, or both.
>
>
> I can't figure this one out, except with reference to my old fortran-era
> skills.  Help!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From stefanML at collocations.de  Mon Dec  8 23:16:23 2014
From: stefanML at collocations.de (Stefan Evert)
Date: Mon, 8 Dec 2014 23:16:23 +0100
Subject: [R] Finding unique elements faster
In-Reply-To: <1418070096499-4700539.post@n4.nabble.com>
References: <1418070096499-4700539.post@n4.nabble.com>
Message-ID: <24C4D51F-0523-4CA8-9BC0-30958C6CF1A7@collocations.de>


On 8 Dec 2014, at 21:21, apeshifter <ch_koch at gmx.de> wrote:

> The last relic of the afore-mentioned for-loop that goes through all the
> word pairs and tries to calculate some statistics on them is the following
> line of code:
>> typefreq.after1[i]<-length(unique(word2[which(word1==word1[i])]))
> (where word1 and word2 are the first and second word within the two-word
> sequence (all.word.pairs, above)

It is difficult to tell without a fully reproducible example, but from this code I get the impression that word1 and word2 represent word pair _tokens_ rather than pair _types_ (otherwise you wouldn't need the unique()).  That's a very inefficient way of dealing with co-occurrence data, especially since you've already computed the set of pair types in order to get the co-occurrence counts.

If word1, word2 are type vectors (i.e. every pair occurs just once), then this should give you what you want:

	tapply(BB$word2, BB$word1, length)

If they are token vectors, you need to supply your own type counting function, which will be a bit slower

	tapply(BB$word2, BB$word1, function (x) length(unique(x)))

On my machine, this takes about 0.2s for 770,000 word pairs.


BTW, you might want to take a look at Unit 4 of the SIGIL course

	http://sigil.r-forge.r-project.org/

which has some tips on how you can deal efficiently with co-occurrence data in R.

Best,
Stefan

	 


	

From spencer.graves at prodsyse.com  Mon Dec  8 23:21:36 2014
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Mon, 08 Dec 2014 14:21:36 -0800
Subject: [R] combining two distributions
In-Reply-To: <2045808461.192274.1418064329203.JavaMail.yahoo@jws10044.mail.ne1.yahoo.com>
References: <608563335.4057300.1418039527824.JavaMail.yahoo@jws100179.mail.ne1.yahoo.com>
	<2045808461.192274.1418064329203.JavaMail.yahoo@jws10044.mail.ne1.yahoo.com>
Message-ID: <54862470.80100@prodsyse.com>

       Have you considered "distr" and related packages?


       If this does not solve your problem, have you considered 
searching with "findFn" in the "sos" package?  If that still does not 
produce sufficient enlightenment, please try this list again with 
"commented, minimal, self-contained, reproducible code" describing what 
you want in a bit more detail (as indicated at the end of emails on this 
list).


       Spencer


On 12/8/2014 10:45 AM, Alaios via R-help wrote:
> (I am sorry if you have received this email twice but it does not look sent on my client)
>
>    
>
>   Hi all,I am having some heavy tailed data and I am trying to think of the more appropriate package for the fitting.The canonical try should be something like exponential and pareto or exponential + gamma (or gamma + gamma with different shape parameters). I am trying to have one distribution that is "classical" thin tailed one and another one which is more like a power law or close (pareto,gamma,weibull, log-normal).
> Do you have any recommendation with which packages I can start on and if the functions you have in mind they can also provide information like AIC or BIC so to help me choose the best combinations?
> I would like to thank you in advance for your help
> RegardsAlex
>
>      
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Mon Dec  8 12:52:07 2014
From: alaios at yahoo.com (Alaios)
Date: Mon, 8 Dec 2014 11:52:07 +0000 (UTC)
Subject: [R] combining two distributions
Message-ID: <608563335.4057300.1418039527824.JavaMail.yahoo@jws100179.mail.ne1.yahoo.com>

Hi all,I am having some heavy tailed data and I am trying to think of the more appropriate package for the fitting.The canonical try should be something like exponential and pareto or exponential + gamma (or gamma + gamma with different shape parameters). I am trying to have one distribution that is "classical" thin tailed one and another one which is more like a power law or close (pareto,gamma,weibull, log-normal).
Do you have any recommendation with which packages I can start on and if the functions you have in mind they can also provide information like AIC or BIC so to help me choose the best combinations?
I would like to thank you in advance for your help
RegardsAlex
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Dec  9 02:05:39 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 9 Dec 2014 01:05:39 +0000
Subject: [R]
	=?utf-8?q?MLE_with_parameters_restricted_to_a_defined_range_u?=
	=?utf-8?q?sing=09bbmle?=
References: <1067011741.4187447.1418069090594.JavaMail.yahoo@jws10098.mail.ne1.yahoo.com>
	<54860BAF.1040500@auckland.ac.nz>
Message-ID: <loom.20141209T015626-265@post.gmane.org>

Rolf Turner <r.turner <at> auckland.ac.nz> writes:

> 
> 
> I know nothing about the bbmle package and its mle2() function, but it 
> is a general truth that if you need to constrain a parameter to be 
> positive in an optimisation procedure a simple and effective approach is 
> to reparameterize using exp().

 mle2() is a wrapper for R's built-in optim() function, so
you can use method="L-BFGS-B" and set the minimum values via
the lower= argument.  The only potentially tricky part is that
you may want to set the lower bound slightly above the desired
bound, as L-BFGS-B uses as finite difference approximation to
compute the gradients, and I'm not 100% sure that the finite
difference computation always respects the bounds automatically.
(The finite-difference stepsize is set by the 'ndeps' parameter
and is 0.001 by default.)

> 
> I.e. represent xmin as exp(lxmin) (say) and use lxmin as the argument
> to your objective function.
> 
> This strategy rarely if ever fails to work.
> 
> cheers,
> 
> Rolf Turner
> 
> On 09/12/14 09:04, Bernardo Santos wrote:
> > Dear all,
> > I am fitting models to data with mle2 function of the bbmle package.
> In specific, I want to fit a power-law
> distribution model, as defined here 
> (http://arxiv.org/pdf/cond-mat/0412004v3.pdf), to data.
> > However, one of the parameters - xmin -, must be necessarily greater 
> than zero. What can I do to restrict the
> possible values of a parameter that are passed to the optimizer?
> > Here there is a sample of my code:
# Loading library
library(bbmle)

# Creating data
set.seed(1234)
data <- rexp(1000, rate = 0.1) # 
## The fit will not be too good, but it is just to test

# Creating the power-law distribution density function
dpowlaw <- function(x, alfa, xmin, log=FALSE){
c <- (alfa-1)*xmin^(alfa-1)
if(log) ifelse(x < xmin, 0, log(c*x^(-alfa)))
else ifelse(x < xmin, 0, c*x^(-alfa))
}
# Testing the function
integrate(dpowlaw, -Inf, Inf, alfa=2, xmin=1)
curve(dpowlaw(x, alfa=2.5, xmin=10), from=0, to=100, log="")
curve(dpowlaw(x, alfa=2.5, xmin=1), from=1, to=100, log="xy")

# Negative log-likelihood function
LLlevy <- function(mu, xmin){
-sum(dpowlaw(data, alfa=mu, xmin=xmin, log=T))
}

# Fitting model to data
mlevy <- mle2(LLlevy, start=list(mu=2, xmin=1))
The result of model fitting here is Coefficients:
mu      xmin
-916.4043  890.4248

but this does not make sense!xmin must be > 0, 
and mu must be > 1.What should I do?
Thanks in advance!Bernardo Niebuhr


From kate.ignatius at gmail.com  Tue Dec  9 03:31:44 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Mon, 8 Dec 2014 21:31:44 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
Message-ID: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>

Hi,

I have a simple question.  I know there are plenty of packages out
there that can provide code to generate a table in latex.  But I was
wondering whether there was one out there where I can generate a table
from my data (which ever way I please) then allow me to save it as a
pdf?

Thanks

K.


From farnoosh_81 at yahoo.com  Mon Dec  8 18:39:56 2014
From: farnoosh_81 at yahoo.com (farnoosh sheikhi)
Date: Mon, 8 Dec 2014 17:39:56 +0000 (UTC)
Subject: [R] Scatter plot for repeated measures
In-Reply-To: <5483CC5D.4080904@mail.usask.ca>
References: <5483CC5D.4080904@mail.usask.ca>
Message-ID: <931539840.6726562.1418060396116.JavaMail.yahoo@jws106141.mail.bf1.yahoo.com>

Thank you all. That was very helpful.??Farnoosh

 

     On Saturday, December 6, 2014 7:41 PM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
   

 It seems that you would like to make a spaghetti plot (in a longitudinal 
data analysis).? You can use the function 'interaction.plot()'.

 > with(my.df, interaction.plot(TIME, ID, X))

I hope this helps.

Chel Hee Lee

On 12/06/2014 02:24 AM, arun wrote:
>
>
> Not sure whether it is a scatterplot or just a plot with 3 lines.? If it is the latter,
>
> library(reshape2)
>
> matplot(acast(my.df, TIME~ID, value.var='X'), type='l', col=1:3, ylab='X', xlab='TIME')
> legend('bottomright', inset=.05, legend=LETTERS[1:3], pch=1, col=1:3)
> A.K.
>
> On Friday, December 5, 2014 5:45 PM, farnoosh sheikhi <farnoosh_81 at yahoo.com> wrote:
>
>
>
> Hi Arun,
>
> I hope you are doing well.
> I have a data set as follow:
> my.df <- data.frame(ID=rep(c("A","B","C"), 5), TIME=rep(1:5, each=3), X=1:5)
>
> I would like to get a scatterplot where x axis is Time (1,2,3,4,5) and y axis is X, but I want to have three lines separately for each ID.
>? I basically want to tack each ID over time. Is this possible?
>
>
> Thanks a lot and Happy Holidays to you!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


   
	[[alternative HTML version deleted]]


From paladini at trustindata.de  Mon Dec  8 14:31:19 2014
From: paladini at trustindata.de (paladini at trustindata.de)
Date: Mon, 08 Dec 2014 14:31:19 +0100
Subject: [R] how to label countries in a map created with mapCountryData
Message-ID: <20141208143119.Horde.PByW_oGyqc4bqsGmnlBfag1@webmail.df.eu>

Hello,
I use the following code to draw a map of Europe. The colour of the  
countries depends on a value called "EPI2.0" in a data frame called  
epidata.

epimap=joinCountryData2Map(epidata,joinCode="NAME",nameCountryColumn="Country",nameJoinColumn="Country")
mapCountryData(epimap, nameColumnToPlot="EPI.2.0" ,mapRegion="europe",  
oceanCol="slateblue1",
missingCountryCol="darkgrey", colourPalette=c("palegreen","darkgreen"))


The dataframe contains 27 countries and I want to label only(!) these  
countries with there names.
I have no idea how to do this.


I would be nice if somebody could help me.

Thanking you in anticipation!

Best regards

Claudia


From rosita21 at gmail.com  Mon Dec  8 22:15:57 2014
From: rosita21 at gmail.com (GMAIL)
Date: Mon, 8 Dec 2014 21:15:57 +0000
Subject: [R] Extract random effect variances from lmer (lme4) model
Message-ID: <9C965B1B-0EA7-4D92-ABA1-B72F7C01917F@gmail.com>

I have a mer object that has fixed and random effects (lmer). 

How do I extract the variance or standard deviation estimates for the random and fixed effects? Here is a simplified version of my question:


pcrpred <- lmer(PCR ~ (1|TIME) + (1|ID), data = mydataPCRlong)

pcrpred


This gives a long output - not too long in this case. Anyway, how do I explicitly select the variance? I can I extract part of the output? I want the values themselves.

> pcrpred
Linear mixed model fit by REML ['merModLmerTest']
Formula: PCR ~ (1 | TIME) + (1 | ID)
   Data: mydataPCRlong
REML criterion at convergence: 127761.9
Random effects:
 Groups   Name        Std.Dev.
 ID       (Intercept) 22031   
 TIME     (Intercept) 15182   
 Residual             33635   
Number of obs: 5346, groups:  ID, 891; TIME, 6
Fixed Effects:
(Intercept)  
      26791  

I also tried: 
summary(pcrpred)

Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of
  freedom [merModLmerTest]
Formula: PCR ~ (1 | TIME) + (1 | ID)
   Data: mydataPCRlong

REML criterion at convergence: 127761.9

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-2.6822 -0.5974 -0.2283  0.5681  2.8165 

Random effects:
 Groups   Name        Variance  Std.Dev.
 ID       (Intercept) 4.854e+08 22031   
 TIME     (Intercept) 2.305e+08 15182   
 Residual             1.131e+09 33635   
Number of obs: 5346, groups:  ID, 891; TIME, 6

Fixed effects:
             Estimate Std. Error        df t value Pr(>|t|)   
(Intercept) 26790.662   6258.611     5.142   4.281  0.00738 **
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> print(VarCorr(pcrpred),comp=c("Variance","Std.Dev."))
 Groups   Name        Variance   Std.Dev.
 ID       (Intercept)  485373501 22031   
 TIME     (Intercept)  230483110 15182   
 Residual             1131284840 33635 


When I do:

print(VarCorr(pcrpred),comp=c(?Variance?,?Std.Dev.?))

I get:

 Groups   Name        Variance   Std.Dev.
 ID       (Intercept)  485373501 22031   
 TIME     (Intercept)  230483110 15182   
 Residual             1131284840 33635 

And I searched in forums, but another command I found was: 
summary(pcrpred)@REmat
however I get:

Error: trying to get slot ?REmat" from an object (class "summary.merMod") that is not an S4 object 

Can anyone 


I have taken long looks at

str(study)
and there's nothing there! Also checked any extractor functions in the lme4 package to no avail. Please help!
	[[alternative HTML version deleted]]


From gheorghe.postelnicu at gmail.com  Mon Dec  8 21:57:37 2014
From: gheorghe.postelnicu at gmail.com (Gheorghe Postelnicu)
Date: Mon, 8 Dec 2014 21:57:37 +0100
Subject: [R] Finding unique elements faster
In-Reply-To: <1418070096499-4700539.post@n4.nabble.com>
References: <1418070096499-4700539.post@n4.nabble.com>
Message-ID: <CAMwj8T9oMe0OkAOMTrkh7PDdxa+L=Ebs3_N_LeJsk-=1TnmQcA@mail.gmail.com>

2 ideas (haven't tried them):

1. if your data is in a data frame, did you try using the by function?
Seems it would do the grouping for you.

2. Since you mention the cpu cores, you could use libraries like foreach
and %dopar% or mcapply.

I would try 1. and see if it provides a sufficient speed-up.

On Mon, Dec 8, 2014 at 9:21 PM, apeshifter <ch_koch at gmx.de> wrote:

> Dear all,
>
> for the past two weeks, I've been working on a script to retrieve word
> pairs
> and calculate some of their statistics using R. Everything seemed to work
> fine until I switched from a small test dataset to the 'real thing' and
> noticed what a runtime monster I had devised!
>
> I could reduce processing time significantly when I realized that with R, I
> did not have to do everything in loops and count things vector element by
> vector element, but could just have the program count everything with
> tables, e.g. with
>   > freq.w1w2.2<-table(all.word.pairs)[all.word.pairs]
>
> However, now I seem to have run into a performance problem that I cannot
> solve. I hope there's a kind soul on this list who has some advice for me.
> On to the problem:
>
> The last relic of the afore-mentioned for-loop that goes through all the
> word pairs and tries to calculate some statistics on them is the following
> line of code:
>   > typefreq.after1[i]<-length(unique(word2[which(word1==word1[i])]))
> (where word1 and word2 are the first and second word within the two-word
> sequence (all.word.pairs, above)
>
> Here, I am trying to count the number of 'types', linguistically speaking,
> before the second word in the two-word sequence (later, I am doing the same
> for the first word within the sequence). The expression works, but given my
> ~400,000 word pairs/word1's/word2's etc, this takes quite some time. About
> 10 hours on my machine, in fact, since R cannot use the other three of the
> four cores. Since I want to repeat the process for another 20 corpora of
> similar size, I would definitely appreciate some help on this subject.
>
> I have been trying 'typefreq.after1<-table(unique(word2[word1]))[2]' and
> the
> subset() function and both seem to work (though I haven't checked whether
> all the numbers are in fact correctly calculated), but they take about the
> same amount of time. So that's no use for me.
>
> Does anybody have any tips to speed this up?
>
> Thank you very much!
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Finding-unique-elements-faster-tp4700539.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Dec  9 04:28:32 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 8 Dec 2014 22:28:32 -0500
Subject: [R] Extract random effect variances from lmer (lme4) model
In-Reply-To: <9C965B1B-0EA7-4D92-ABA1-B72F7C01917F@gmail.com>
References: <9C965B1B-0EA7-4D92-ABA1-B72F7C01917F@gmail.com>
Message-ID: <CA+vqiLEWYeHejzr+FDxZFbkimcpEgDR6bHeN-NonXRn_O8CVtA@mail.gmail.com>

Perhaps

as.data.frame(VarCorr(pcrpred))

?

Best,
Ista

On Mon, Dec 8, 2014 at 4:15 PM, GMAIL <rosita21 at gmail.com> wrote:
> I have a mer object that has fixed and random effects (lmer).
>
> How do I extract the variance or standard deviation estimates for the random and fixed effects? Here is a simplified version of my question:
>
>
> pcrpred <- lmer(PCR ~ (1|TIME) + (1|ID), data = mydataPCRlong)
>
> pcrpred
>
>
> This gives a long output - not too long in this case. Anyway, how do I explicitly select the variance? I can I extract part of the output? I want the values themselves.
>
>> pcrpred
> Linear mixed model fit by REML ['merModLmerTest']
> Formula: PCR ~ (1 | TIME) + (1 | ID)
>    Data: mydataPCRlong
> REML criterion at convergence: 127761.9
> Random effects:
>  Groups   Name        Std.Dev.
>  ID       (Intercept) 22031
>  TIME     (Intercept) 15182
>  Residual             33635
> Number of obs: 5346, groups:  ID, 891; TIME, 6
> Fixed Effects:
> (Intercept)
>       26791
>
> I also tried:
> summary(pcrpred)
>
> Linear mixed model fit by REML t-tests use Satterthwaite approximations to degrees of
>   freedom [merModLmerTest]
> Formula: PCR ~ (1 | TIME) + (1 | ID)
>    Data: mydataPCRlong
>
> REML criterion at convergence: 127761.9
>
> Scaled residuals:
>     Min      1Q  Median      3Q     Max
> -2.6822 -0.5974 -0.2283  0.5681  2.8165
>
> Random effects:
>  Groups   Name        Variance  Std.Dev.
>  ID       (Intercept) 4.854e+08 22031
>  TIME     (Intercept) 2.305e+08 15182
>  Residual             1.131e+09 33635
> Number of obs: 5346, groups:  ID, 891; TIME, 6
>
> Fixed effects:
>              Estimate Std. Error        df t value Pr(>|t|)
> (Intercept) 26790.662   6258.611     5.142   4.281  0.00738 **
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> print(VarCorr(pcrpred),comp=c("Variance","Std.Dev."))
>  Groups   Name        Variance   Std.Dev.
>  ID       (Intercept)  485373501 22031
>  TIME     (Intercept)  230483110 15182
>  Residual             1131284840 33635
>
>
> When I do:
>
> print(VarCorr(pcrpred),comp=c(?Variance?,?Std.Dev.?))
>
> I get:
>
>  Groups   Name        Variance   Std.Dev.
>  ID       (Intercept)  485373501 22031
>  TIME     (Intercept)  230483110 15182
>  Residual             1131284840 33635
>
> And I searched in forums, but another command I found was:
> summary(pcrpred)@REmat
> however I get:
>
> Error: trying to get slot ?REmat" from an object (class "summary.merMod") that is not an S4 object
>
> Can anyone
>
>
> I have taken long looks at
>
> str(study)
> and there's nothing there! Also checked any extractor functions in the lme4 package to no avail. Please help!
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Tue Dec  9 05:13:58 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 8 Dec 2014 23:13:58 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
Message-ID: <CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>

yes of course, and the answer is latex() in the Hmisc package.
Why were you excluding it?
Details follow

Rich


The current release of the Hmisc package has this capability on
Macintosh and Linux.
For Windows, you need the next release 3.14-7 which is available now at github.

## windows needs these lines until the new Hmisc version is on CRAN
install.packages("devtools")
devtools::install_github("Hmisc", "harrelfe")

## All operating systems
options(latexcmd='pdflatex')
options(dviExtension='pdf')

## Macintosh
options(xdvicmd='open')

## Windows, one of the following
options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
## 32-bit windows
options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
## 64 bit windows

## Linux
## I don't know the xdvicmd value


## this works on all R systems
library(Hmisc)
tmp <- matrix(1:9,3,3)
tmp.dvi <- dvi(latex(tmp))
print.default(tmp.dvi) ## prints filepath of the pdf file
tmp.dvi  ## displays the pdf file on your screen

On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Hi,
>
> I have a simple question.  I know there are plenty of packages out
> there that can provide code to generate a table in latex.  But I was
> wondering whether there was one out there where I can generate a table
> from my data (which ever way I please) then allow me to save it as a
> pdf?
>
> Thanks
>
> K.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Tue Dec  9 08:24:40 2014
From: alaios at yahoo.com (Alaios)
Date: Tue, 9 Dec 2014 07:24:40 +0000 (UTC)
Subject: [R] combining two distributions
In-Reply-To: <54862470.80100@prodsyse.com>
References: <54862470.80100@prodsyse.com>
Message-ID: <1353752947.933328.1418109880889.JavaMail.yahoo@jws100148.mail.ne1.yahoo.com>

Hi,thanks a lot for the answer. I think that my problem is before packages. I have a large amount of different datasets and I had a random look on their histograms. I know that some of them look like the combination I have explained (exponential+pareto, exponential+gamma) but I am not sure still.I wanted to know if there is a "preliminary" approach where a fitting algorithms tries some of the suggested combinations and give me hints where to focus my future research.I will have a look on the package you suggested.
RegardsAlex
 

     On Monday, December 8, 2014 11:23 PM, Spencer Graves <spencer.graves at prodsyse.com> wrote:
   

 ? ? ? Have you considered "distr" and related packages?


? ? ? If this does not solve your problem, have you considered 
searching with "findFn" in the "sos" package?? If that still does not 
produce sufficient enlightenment, please try this list again with 
"commented, minimal, self-contained, reproducible code" describing what 
you want in a bit more detail (as indicated at the end of emails on this 
list).


? ? ? Spencer


On 12/8/2014 10:45 AM, Alaios via R-help wrote:
> (I am sorry if you have received this email twice but it does not look sent on my client)
>
>? ? 
>
>? Hi all,I am having some heavy tailed data and I am trying to think of the more appropriate package for the fitting.The canonical try should be something like exponential and pareto or exponential + gamma (or gamma + gamma with different shape parameters). I am trying to have one distribution that is "classical" thin tailed one and another one which is more like a power law or close (pareto,gamma,weibull, log-normal).
> Do you have any recommendation with which packages I can start on and if the functions you have in mind they can also provide information like AIC or BIC so to help me choose the best combinations?
> I would like to thank you in advance for your help
> RegardsAlex
>
>? ? ? 
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From dario.beraldi at gmail.com  Tue Dec  9 10:57:19 2014
From: dario.beraldi at gmail.com (Dario Beraldi)
Date: Tue, 9 Dec 2014 09:57:19 +0000
Subject: [R] R argparse: Line breaks in description
In-Reply-To: <CAEa0nG4dTRh2RGGSm1ogv1GB5tyPpxaP-ojWj=GXDuw1-uWpgw@mail.gmail.com>
References: <CAEa0nG4dTRh2RGGSm1ogv1GB5tyPpxaP-ojWj=GXDuw1-uWpgw@mail.gmail.com>
Message-ID: <CAEa0nG7VyeAuWUX=LDYWjJ58cgyRwC89fdVZEPhR9DKTnSTkww@mail.gmail.com>

On 27 November 2014 at 09:07, Dario Beraldi <dario.beraldi at gmail.com> wrote:

> Hello,
>
> I'm using the R package argparse to parse command line arguments.
>
> For readability, I'd like to add line breaks in the "description" of the
> script and in the help of the arguments. However, I can't do it... Let's
> see an example. Given this script:
>
>     #!/usr/bin/env Rscript
>
>     require(argparse)
>
>     docstring<- "Description\nDone"
>
>     parser<- ArgumentParser(description= docstring)
>     args<- parser$parse_args()
>
> When executed with *-h* it should print:
>
>     Description
>     Done
>
> However, I'm getting the error:
>
>     Error in rjson::fromJSON(output) : unexpected character 'F'
>     Calls: <Anonymous> -> <Anonymous> -> <Anonymous>
>     Execution halted
>
> Variation of docstring like *paste("Description", "Done", sep= '\n')* are
> equally unsuccessful.
>
> As well as passing RawTextHelpFormatter like:
> parser<- ArgumentParser(description= docstring, RawTextHelpFormatter= TRUE)
>
> Any idea how to put line breaks in argparse?
>
> Many thanks!
>
> NB: Cross posted on StackOverflow http://stackoverflow.com/posts/27150625/
>
> Dario
>
>     sessionInfo()
>     R version 3.0.1 (2013-05-16)
>     Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
>     locale:
>     [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets  methods
> base
>
>     other attached packages:
>     [1] argparse_1.0.1 proto_0.3-10
>
>     loaded via a namespace (and not attached):
>     [1] findpython_1.0.1 getopt_1.20.0    rjson_0.2.13
>
>
I found the solution to this issue. Long story short: Use formatter_class=
'argparse.RawTextHelpFormatter'

See also my answer on StackOverflow
http://stackoverflow.com/questions/27150625/r-argparse-line-breaks-in-description/27375898#27375898

Dario

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Tue Dec  9 16:06:48 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Tue, 09 Dec 2014 07:06:48 -0800
Subject: [R] RCurl much faster than base R
In-Reply-To: <e8f35113f89a6d0bf5895a0a7c81b377@ruggedtextile.com>
References: <e8f35113f89a6d0bf5895a0a7c81b377@ruggedtextile.com>
Message-ID: <54871008.4080303@fredhutch.org>

On 12/05/2014 08:12 AM, Alex Gutteridge wrote:
> I'm trying to debug a curious network issue, I wonder if anyone can help me as I
> (and my local sysadmin) am stumped:
>
> This base R command takes ~1 minute to complete:
>
> readLines(url("http://bioconductor.org/biocLite.R"))
>
> (biocLite.R is a couple of KB in size)
>
> Using RCurl (and so libcurl under the hood) is instantaneous (<1s):
>
> library(RCurl)
> getURL("http://bioconductor.org/biocLite.R")
>
> I've not set it to use any proxies (which was my first thought) unless libcurl
> autodetects them somehow... And the speed is similarly fast using wget or curl
> on the command line. It just seems to be the base R commands which are slow
> (including install.packages etc...).
>
> Does anyone have hints on how to debug this (if not an answer directly)?
>

Hi Alex -- maybe not surprisingly, both approaches are approximately equally 
speedy for me, at least on average.

For what it's worth

- there is no need to use url(), just readLines("http://...")

It would help to

- provide the output of sessionInfo()

- verify or otherwise that the problem is restricted to particular urls

- work through a simple example where the test say 'works' when accessing a 
local http server (e.g., on the same machine and in a directory "mydir", python 
-m SimpleHTTPServer 10000 in one terminal, the 
readLines("http://localhost:10000/<some file in 'mydir'>") but fails after some 
increasingly remote point, e.g., accessing a url outside your institution 
firewall hence indicating a firewall issue.

Maybe at the end of this exercise the only insight will be that the R and curl 
implementations differ (a known known!).

Also if this is really a problem with installing Bioconductor packages rather 
than a general R question, then https://support.bioconductor.org is a better 
place to post. If the problem is restricted to bioconductor.org, then: (a) for 
your sys.admin, the url is redirected (via DNS, not http:) to Amazon Cloud Front 
and from there to a regional Amazon data center; I'm not sure what the 
significance of this might be, e.g., the admin might have throttled download 
speeds from certain ip address ranges; and (b) if you're in Europe or elsewhere, 
you're trying to install Bioconductor packages, and the regional data center is 
not fast enough (it should be responsive, at least when the url has been seen 
'recently'), then configure R to use a local mirror from 
http://bioconductor.org/about/mirrors/, e.g.,

     chooseBioCmirror()

Martin Morgan
Bioconductor

> AlexG
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From ch_koch at gmx.de  Tue Dec  9 11:02:57 2014
From: ch_koch at gmx.de (apeshifter)
Date: Tue, 9 Dec 2014 02:02:57 -0800 (PST)
Subject: [R] Finding unique elements faster
In-Reply-To: <24C4D51F-0523-4CA8-9BC0-30958C6CF1A7@collocations.de>
References: <1418070096499-4700539.post@n4.nabble.com>
	<24C4D51F-0523-4CA8-9BC0-30958C6CF1A7@collocations.de>
Message-ID: <1418119377113-4700582.post@n4.nabble.com>

Thank you all for your suggestions! I must say I am amazed by the number of
people who consider helping out another! Fells like it was a good idea to
start using R - back when I was still using Perl for such tasks, I'd been
happy to have this kind of support!

@ Gheorghe Postelnicu: Unfortunately, the data is not yet in a data frame
when this part of the program starts. At this point, I am trying to fill in
all the relevant vectors (all.word.pairs, word1, word2, freq.word1,
freq.word2, typefreq.w1, typefreq.w2, ...) and then combine them to a data
frame. I will try to get my head around the doParallel package package for
the foreach loop, since parallel computing would certainly be helpful. 

@ Jeff Newmiller: Sound interesting, but I fear the same problem applies as
for Gheorghe's suggestion. I will need a data frame first,for which I do not
have all the correct values... Will keep the package in mind, though, for
future projects.

@ Stefan Evert-3: I am not sure I understand what you mean in the second
example. Since the counting of types is exactly my problem at the moment, I
do not see how I could provide a function that would work more efficiently
in the context you are describing. The line of code that I was giving is
exactly my attempt at doint this... Sorry, I might just not be getting what
you are aiming at... :-/  However, your assumptions are quite correct. word1
and word2 do indeed contain word tokens, as does all.word.pairs. The reason
for this is that I need the word pairs within the vector to be in the same
order as they appeared in the original corpus files. Also, thank you for the
link. I will check this out when I am analysing collocates. However, I
didn't find notes on my specific problem in the slides. However, please do
not think I was not using reference material for designing my script. I was
in fact using  Gries 2009: "Quantitative Corpus Linguistics with R"
<http://www.amazon.de/Quantitative-Corpus-Linguistics-Practical-Introduction-ebook/dp/B001Y35H5A/ref=sr_1_1?ie=UTF8&qid=1418119630&sr=8-1&keywords=gries+quantitative+corpus+linguistics>  
for this. The trouble is that the methods in the book help as far as simple
n-gram frequency calculations are concerned (since, e.g. table() would just
do the trick), but methods for this size of repeated checks on tables are
not included.

Best,
Christopher



--
View this message in context: http://r.789695.n4.nabble.com/Finding-unique-elements-faster-tp4700539p4700582.html
Sent from the R help mailing list archive at Nabble.com.


From chiara_valleb at yahoo.it  Tue Dec  9 12:33:17 2014
From: chiara_valleb at yahoo.it (Chiara Vallebona)
Date: Tue, 9 Dec 2014 12:33:17 +0100
Subject: [R] Validation data critically small with GSIF
Message-ID: <000001d013a3$ee90fa20$cbb2ee60$@it>

I'm trying to make spatial prediction of rainfall erosivity (data from 23
Rainfall gauges) with GSIF package (RK method).

I got this error message (and no prediction):

"Error in validObject(.Object) :  invalid class "SpatialPredictions"
object: Validation data critically small (<50) for reliable
validation".

Is it possible to modify the threshold of 50 validation data?
Could you please give me a hint, any command to solve this issue?

Thank you and best regards

Chiara


----------------
Chiara Vallebona, PhD candidate
Land Lab - Institute of Life Sciences
Sant'Anna School of Advanced Studies
via S. Cecilia 3, 56127 - Pisa, Italy
tel.: +39 050883181
fax.: +39 050883526
e-mail: c.vallebona at sssup.it
http://www.santannaschool.eu/

*******************************

Le informazioni contenute in questo documento sono ad uso esclusivo del
destinatario. Il contenuto e gli allegati di questo messaggio sono
strettamente confidenziali, e ne sono vietati la diffusione, l'inoltro e
l'uso non autorizzato da parte di utenti diversi dal destinatario. Qualora
il presente messaggio Le fosse pervenuto per errore, Le saremmo grati se lo
distruggesse e ce ne desse comunicazione a mezzo e-mail.

The information transmitted is intended only for the per...{{dropped:8}}


From munevver.rock at gmail.com  Tue Dec  9 09:22:30 2014
From: munevver.rock at gmail.com (munevver kaya)
Date: Tue, 9 Dec 2014 10:22:30 +0200
Subject: [R] DIF
Message-ID: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>

Hello,
I will analyze polytomous differential item functioning for IRT. I have a
Likert type scale. For example, I want to analyze items in term of gender.
Is lordifsufficient for this or are there any other packages in R
programme?
Best Regards,

	[[alternative HTML version deleted]]


From kate.ignatius at gmail.com  Tue Dec  9 17:43:02 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 9 Dec 2014 11:43:02 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
Message-ID: <CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>

Thanks!  I do get several errors though when running on Linux.

Running your code, I get this:

Error in system(cmd, intern = TRUE, wait = TRUE) :
error in running command

Fiddling around with the code and running this:

tmp <- matrix(1:9,3,3)
tmp.tex <- latex(tmp, file='tmp.tex')
print.default(tmp.tex)
tmp.dvi <- dvi(tmp.tex)
tmp.dvi
tmp.tex
dvips(tmp.dvi)
dvips(tmp.tex)
library(tools)
texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)

I get this:

Error in texi2dvi(file="tmp.tex",,  :
  Running 'texi2dvi' on 'tmp.tex' failed.
Messages:
/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.

I've read that it may have something to do with the path of pdflatex.

Sys.which('pdflatex')

           pdflatex

"/usr/bin/pdflatex"


Sys.which('texi2dvi')

           texi2dvi

"/usr/bin/texi2dvi"

> file.exists(Sys.which('texi2dvi'))

[1] TRUE

> file.exists(Sys.which('pdflatex'))

[1] TRUE

Is there a specific path I should be giving with pdflatex and/or
'texi2dvi to make this work?

Thanks!

On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> yes of course, and the answer is latex() in the Hmisc package.
> Why were you excluding it?
> Details follow
>
> Rich
>
>
> The current release of the Hmisc package has this capability on
> Macintosh and Linux.
> For Windows, you need the next release 3.14-7 which is available now at github.
>
> ## windows needs these lines until the new Hmisc version is on CRAN
> install.packages("devtools")
> devtools::install_github("Hmisc", "harrelfe")
>
> ## All operating systems
> options(latexcmd='pdflatex')
> options(dviExtension='pdf')
>
> ## Macintosh
> options(xdvicmd='open')
>
> ## Windows, one of the following
> options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
> ## 32-bit windows
> options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
> ## 64 bit windows
>
> ## Linux
> ## I don't know the xdvicmd value
>
>
> ## this works on all R systems
> library(Hmisc)
> tmp <- matrix(1:9,3,3)
> tmp.dvi <- dvi(latex(tmp))
> print.default(tmp.dvi) ## prints filepath of the pdf file
> tmp.dvi  ## displays the pdf file on your screen
>
> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> Hi,
>>
>> I have a simple question.  I know there are plenty of packages out
>> there that can provide code to generate a table in latex.  But I was
>> wondering whether there was one out there where I can generate a table
>> from my data (which ever way I please) then allow me to save it as a
>> pdf?
>>
>> Thanks
>>
>> K.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From janko.thyson at gmail.com  Tue Dec  9 18:28:53 2014
From: janko.thyson at gmail.com (Janko Thyson)
Date: Tue, 9 Dec 2014 18:28:53 +0100
Subject: [R] Inconsistency of S4 dispatch behavior for R6 classes
Message-ID: <CAGmpueh=m5KHFGCWg81E8E=W-f0bS93H_n+CVcdwr0kVxOPijA@mail.gmail.com>

Dear list,

as a week has passed now after filing an issue for package R6 (
https://github.com/wch/R6/issues/36), I thought it's okay to go ahead and
ask a bigger audience about their opinion/suggestions for a general
solution and/or "good" workarounds:

Actual questions
----

1. Shouldn't the fact that [*R6*](https://github.com/wch/R6) classes
inherit from (informal S3) class `R6` allow the definition of S4 methods
for signature arguments of that very class?

2. As this is - AFAICT - not the case, what would be a workaround that is
in line with current S3/S4 standards or that could somewhat be regarded as
"best practice" in such situations?

Background and example
-----

**Reference Classes**

Consider the following example where you would like to define methods that
dispatch on the superclass that all instances of [*Reference Classes*](
https://stat.ethz.ch/R-manual/R-devel/library/methods/html/refClass.html)
inherit from (`envRefClass`):

    TestRefClass <- setRefClass("TestRefClass", fields= list(.x =
"numeric"))
    setGeneric("foo", signature = "x",
      def = function(x) standardGeneric("foo")
    )
    setMethod("foo", c(x = "envRefClass"),
      definition = function(x) {
        "I'm the method for `envRefClass`"
    })
    > try(foo(x = TestRefClass$new()))
    [1] "I'm the method for `envRefClass`"

This inheritance structure is not directly obvious as `class()` won't
reveal that fact:

    class(TestRefClass$new())
    [1] "TestRefClass"
    attr(,"package")
    [1] ".GlobalEnv"

However, a look at the attributes of the class generator object reveals it:

    > attributes(TestRefClass)
    [... omitted ...]
     Class Methods:
        "callSuper", "copy", "export", "field", "getClass", "getRefClass",
"import", "initFields",
    "show", "trace", "untrace", "usingMethods"


     Reference Superclasses:
        "envRefClass"

    [... omitted ...]

That's why the dispatch works

**R6 Classes**

When you would like to a similar thing for R6 classes, things don't seem to
be straight forward even though they initially appear so (compared to
Reference Classes):

    TestR6 <- R6Class("TestR6", public = list(.x = "numeric"))
    setMethod("foo", c(x = "R6"),
      definition = function(x) {
        "I'm the method for `R6`"
    })
    > try(foo(x = TestR6$new()))
    Error in (function (classes, fdef, mtable)  :
      unable to find an inherited method for function ?foo? for signature
?"TestR6"?

By "appearing straight forward" I mean that `class()` actually suggests
that all R6 classes inherit from class `R6` that could be used as
superclass for method dispatch:

    class(TestR6$new())
    [1] "TestR6" "R6"

The help page of `R6Class()` actually reveals that class `R6` is merely
added as an informal S3 class as long as `class = TRUE`. That's also why
there is a warning when trying to define a S4 method for this class.

So then this basically leaves us with two possible options/workarounds:

1. Turn class `R6` into a formal class via `setOldClass()`
2. Have all instances of R6 classes inherit from some other superclass,
say, `.R6`

*Ad 1)*

    setOldClass("R6")
    > isClass("R6")
    [1] TRUE

This works when hacking away in an S3 style at the class table/graph:

    dummy <- structure("something", class = "R6")
    > foo(dummy)
    [1] "I'm the method for `R6`"

However, it fails for actual R6 class instances:

    > try(foo(x = TestR6$new()))
    Error in (function (classes, fdef, mtable)  :
      unable to find an inherited method for function ?foo? for signature
?"TestR6"?

*Ad 2)*

    .R6 <- R6Class(".R6")
    TestR6_2 <- R6Class("TestR6_2", inherit = .R6, public = list(.x =
"numeric"))
    setMethod("foo", c(x = ".R6"),
      definition = function(x) {
        "I'm the method for `.R6`"
    })
    > try(foo(x = TestR6_2$new()))
    Error in (function (classes, fdef, mtable)  :
      unable to find an inherited method for function ?foo? for signature
?"TestR6_2"?

Conclusion
-----

While approach 1 sort operates in a "grey area" to make S3 and S4 somewhat
compatible, approach 2 seems like a perfectly valid "pure S4" solution that
IMO should work. The fact that it's not brought me to raising the question
if there exists an inconsistency in the implementation of R6 classes with
respect to the interaction of informal/formal classes and method dispatch
in R.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Dec  9 19:15:22 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 09 Dec 2014 10:15:22 -0800
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
Message-ID: <BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>

pdflatex appears to have run, because it exited. You should look at the tex log file, the problem is more likely that the latex you sent out to pdflatex was incomplete.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 9, 2014 8:43:02 AM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>Thanks!  I do get several errors though when running on Linux.
>
>Running your code, I get this:
>
>Error in system(cmd, intern = TRUE, wait = TRUE) :
>error in running command
>
>Fiddling around with the code and running this:
>
>tmp <- matrix(1:9,3,3)
>tmp.tex <- latex(tmp, file='tmp.tex')
>print.default(tmp.tex)
>tmp.dvi <- dvi(tmp.tex)
>tmp.dvi
>tmp.tex
>dvips(tmp.dvi)
>dvips(tmp.tex)
>library(tools)
>texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>
>I get this:
>
>Error in texi2dvi(file="tmp.tex",,  :
>  Running 'texi2dvi' on 'tmp.tex' failed.
>Messages:
>/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>
>I've read that it may have something to do with the path of pdflatex.
>
>Sys.which('pdflatex')
>
>           pdflatex
>
>"/usr/bin/pdflatex"
>
>
>Sys.which('texi2dvi')
>
>           texi2dvi
>
>"/usr/bin/texi2dvi"
>
>> file.exists(Sys.which('texi2dvi'))
>
>[1] TRUE
>
>> file.exists(Sys.which('pdflatex'))
>
>[1] TRUE
>
>Is there a specific path I should be giving with pdflatex and/or
>'texi2dvi to make this work?
>
>Thanks!
>
>On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>wrote:
>> yes of course, and the answer is latex() in the Hmisc package.
>> Why were you excluding it?
>> Details follow
>>
>> Rich
>>
>>
>> The current release of the Hmisc package has this capability on
>> Macintosh and Linux.
>> For Windows, you need the next release 3.14-7 which is available now
>at github.
>>
>> ## windows needs these lines until the new Hmisc version is on CRAN
>> install.packages("devtools")
>> devtools::install_github("Hmisc", "harrelfe")
>>
>> ## All operating systems
>> options(latexcmd='pdflatex')
>> options(dviExtension='pdf')
>>
>> ## Macintosh
>> options(xdvicmd='open')
>>
>> ## Windows, one of the following
>>
>options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>> ## 32-bit windows
>>
>options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>> ## 64 bit windows
>>
>> ## Linux
>> ## I don't know the xdvicmd value
>>
>>
>> ## this works on all R systems
>> library(Hmisc)
>> tmp <- matrix(1:9,3,3)
>> tmp.dvi <- dvi(latex(tmp))
>> print.default(tmp.dvi) ## prints filepath of the pdf file
>> tmp.dvi  ## displays the pdf file on your screen
>>
>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
><kate.ignatius at gmail.com> wrote:
>>> Hi,
>>>
>>> I have a simple question.  I know there are plenty of packages out
>>> there that can provide code to generate a table in latex.  But I was
>>> wondering whether there was one out there where I can generate a
>table
>>> from my data (which ever way I please) then allow me to save it as a
>>> pdf?
>>>
>>> Thanks
>>>
>>> K.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Dec  9 19:33:40 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 09 Dec 2014 10:33:40 -0800
Subject: [R] Validation data critically small with GSIF
In-Reply-To: <000001d013a3$ee90fa20$cbb2ee60$@it>
References: <000001d013a3$ee90fa20$cbb2ee60$@it>
Message-ID: <4D19C2C0-FC96-4728-89BD-C92E5088DABF@dcn.davis.CA.us>

Most packages are independent contributions. Their maintainers may or may not monitor this list. Please read the Posting Guide. See ?maintainer.

The package author felt that this warning was necessary to prevent its misuse. You will likely have to learn first what the limits of the algorithms really are (if they are different than this package asserts... you probably ought to document this new knowledge in a paper), and then learn how to create your own package or collaborate with the author to incorporate this knowledge into their package. If you need to test your theories you may be able to look at the package source code and define your own similar functions for temporary use.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 9, 2014 3:33:17 AM PST, Chiara Vallebona <chiara_valleb at yahoo.it> wrote:
>I'm trying to make spatial prediction of rainfall erosivity (data from
>23
>Rainfall gauges) with GSIF package (RK method).
>
>I got this error message (and no prediction):
>
>"Error in validObject(.Object) :  invalid class "SpatialPredictions"
>object: Validation data critically small (<50) for reliable
>validation".
>
>Is it possible to modify the threshold of 50 validation data?
>Could you please give me a hint, any command to solve this issue?
>
>Thank you and best regards
>
>Chiara
>
>
>----------------
>Chiara Vallebona, PhD candidate
>Land Lab - Institute of Life Sciences
>Sant'Anna School of Advanced Studies
>via S. Cecilia 3, 56127 - Pisa, Italy
>tel.: +39 050883181
>fax.: +39 050883526
>e-mail: c.vallebona at sssup.it
>http://www.santannaschool.eu/
>
>*******************************
>
>Le informazioni contenute in questo documento sono ad uso esclusivo del
>destinatario. Il contenuto e gli allegati di questo messaggio sono
>strettamente confidenziali, e ne sono vietati la diffusione, l'inoltro
>e
>l'uso non autorizzato da parte di utenti diversi dal destinatario.
>Qualora
>il presente messaggio Le fosse pervenuto per errore, Le saremmo grati
>se lo
>distruggesse e ce ne desse comunicazione a mezzo e-mail.
>
>The information transmitted is intended only for the
>per...{{dropped:8}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From zilefacelvis at yahoo.com  Tue Dec  9 20:28:21 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 9 Dec 2014 19:28:21 +0000 (UTC)
Subject: [R] add symbol above letter in R
Message-ID: <1796268414.7364442.1418153301276.JavaMail.yahoo@jws10691.mail.bf1.yahoo.com>

Hi,

I would like to add a dash (?) on a letter in R.
How can I add a dash on letter P in the following:

mtext(text=expression(Winter(DJF)~mean~daily~precipitation~italic(P)), side=3, line=1, cex=1.3, col="black")

?plotmath could not provide an answer to my problem.

many thanks for your solutions.

Asong.


From zilefacelvis at yahoo.com  Tue Dec  9 20:34:03 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Tue, 9 Dec 2014 19:34:03 +0000 (UTC)
Subject: [R] add symbol above letter in R
In-Reply-To: <1796268414.7364442.1418153301276.JavaMail.yahoo@jws10691.mail.bf1.yahoo.com>
References: <1796268414.7364442.1418153301276.JavaMail.yahoo@jws10691.mail.bf1.yahoo.com>
Message-ID: <912776681.7427359.1418153643147.JavaMail.yahoo@jws106102.mail.bf1.yahoo.com>

I got the right answer:
mtext(text=expression(Winter(DJF)~mean~daily~precipitation~bar(italic(P))), side=3, line=1, cex=1.3, col="black") 
 Thanks.


On Tuesday, December 9, 2014 1:28 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
Hi,

I would like to add a dash (?) on a letter in R.
How can I add a dash on letter P in the following:

mtext(text=expression(Winter(DJF)~mean~daily~precipitation~italic(P)), side=3, line=1, cex=1.3, col="black")

?plotmath could not provide an answer to my problem.

many thanks for your solutions.

Asong.


From murdoch.duncan at gmail.com  Tue Dec  9 20:36:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 09 Dec 2014 14:36:44 -0500
Subject: [R] add symbol above letter in R
In-Reply-To: <1796268414.7364442.1418153301276.JavaMail.yahoo@jws10691.mail.bf1.yahoo.com>
References: <1796268414.7364442.1418153301276.JavaMail.yahoo@jws10691.mail.bf1.yahoo.com>
Message-ID: <54874F4C.4030403@gmail.com>

On 09/12/2014 2:28 PM, Zilefac Elvis via R-help wrote:
> Hi,
>
> I would like to add a dash (?) on a letter in R.
> How can I add a dash on letter P in the following:
>
> mtext(text=expression(Winter(DJF)~mean~daily~precipitation~italic(P)), side=3, line=1, cex=1.3, col="black")
>
> ?plotmath could not provide an answer to my problem.

But it refers to demo(plotmath), and that's where you could find the 
answer to your question:  use bar().  For example,

mtext(text=expression(Winter(DJF)~mean~daily~precipitation~bar(italic(P))), side=3, line=1, cex=1.3, col="black")

Duncan Murdoch


From kate.ignatius at gmail.com  Tue Dec  9 21:11:46 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 9 Dec 2014 15:11:46 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
Message-ID: <CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>

Ah yes, you're right.

The log has this error:

! LaTeX Error: Missing \begin{document}.

Though can't really find much online on how to resolve it.

On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> pdflatex appears to have run, because it exited. You should look at the tex log file, the problem is more likely that the latex you sent out to pdflatex was incomplete.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On December 9, 2014 8:43:02 AM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>Thanks!  I do get several errors though when running on Linux.
>>
>>Running your code, I get this:
>>
>>Error in system(cmd, intern = TRUE, wait = TRUE) :
>>error in running command
>>
>>Fiddling around with the code and running this:
>>
>>tmp <- matrix(1:9,3,3)
>>tmp.tex <- latex(tmp, file='tmp.tex')
>>print.default(tmp.tex)
>>tmp.dvi <- dvi(tmp.tex)
>>tmp.dvi
>>tmp.tex
>>dvips(tmp.dvi)
>>dvips(tmp.tex)
>>library(tools)
>>texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>
>>I get this:
>>
>>Error in texi2dvi(file="tmp.tex",,  :
>>  Running 'texi2dvi' on 'tmp.tex' failed.
>>Messages:
>>/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>
>>I've read that it may have something to do with the path of pdflatex.
>>
>>Sys.which('pdflatex')
>>
>>           pdflatex
>>
>>"/usr/bin/pdflatex"
>>
>>
>>Sys.which('texi2dvi')
>>
>>           texi2dvi
>>
>>"/usr/bin/texi2dvi"
>>
>>> file.exists(Sys.which('texi2dvi'))
>>
>>[1] TRUE
>>
>>> file.exists(Sys.which('pdflatex'))
>>
>>[1] TRUE
>>
>>Is there a specific path I should be giving with pdflatex and/or
>>'texi2dvi to make this work?
>>
>>Thanks!
>>
>>On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>>wrote:
>>> yes of course, and the answer is latex() in the Hmisc package.
>>> Why were you excluding it?
>>> Details follow
>>>
>>> Rich
>>>
>>>
>>> The current release of the Hmisc package has this capability on
>>> Macintosh and Linux.
>>> For Windows, you need the next release 3.14-7 which is available now
>>at github.
>>>
>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>> install.packages("devtools")
>>> devtools::install_github("Hmisc", "harrelfe")
>>>
>>> ## All operating systems
>>> options(latexcmd='pdflatex')
>>> options(dviExtension='pdf')
>>>
>>> ## Macintosh
>>> options(xdvicmd='open')
>>>
>>> ## Windows, one of the following
>>>
>>options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>> ## 32-bit windows
>>>
>>options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>> ## 64 bit windows
>>>
>>> ## Linux
>>> ## I don't know the xdvicmd value
>>>
>>>
>>> ## this works on all R systems
>>> library(Hmisc)
>>> tmp <- matrix(1:9,3,3)
>>> tmp.dvi <- dvi(latex(tmp))
>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>> tmp.dvi  ## displays the pdf file on your screen
>>>
>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>><kate.ignatius at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> I have a simple question.  I know there are plenty of packages out
>>>> there that can provide code to generate a table in latex.  But I was
>>>> wondering whether there was one out there where I can generate a
>>table
>>>> from my data (which ever way I please) then allow me to save it as a
>>>> pdf?
>>>>
>>>> Thanks
>>>>
>>>> K.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Tue Dec  9 21:24:00 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 9 Dec 2014 15:24:00 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
Message-ID: <CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>

It looks like you skipped the step of setting the options.
the latex function doesn't do pdflatex (by default it does regular
latex) unless you set the options
as I indicated.

On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Ah yes, you're right.
>
> The log has this error:
>
> ! LaTeX Error: Missing \begin{document}.
>
> Though can't really find much online on how to resolve it.
>
> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> pdflatex appears to have run, because it exited. You should look at the tex log file, the problem is more likely that the latex you sent out to pdflatex was incomplete.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>>Thanks!  I do get several errors though when running on Linux.
>>>
>>>Running your code, I get this:
>>>
>>>Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>error in running command
>>>
>>>Fiddling around with the code and running this:
>>>
>>>tmp <- matrix(1:9,3,3)
>>>tmp.tex <- latex(tmp, file='tmp.tex')
>>>print.default(tmp.tex)
>>>tmp.dvi <- dvi(tmp.tex)
>>>tmp.dvi
>>>tmp.tex
>>>dvips(tmp.dvi)
>>>dvips(tmp.tex)
>>>library(tools)
>>>texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>
>>>I get this:
>>>
>>>Error in texi2dvi(file="tmp.tex",,  :
>>>  Running 'texi2dvi' on 'tmp.tex' failed.
>>>Messages:
>>>/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>
>>>I've read that it may have something to do with the path of pdflatex.
>>>
>>>Sys.which('pdflatex')
>>>
>>>           pdflatex
>>>
>>>"/usr/bin/pdflatex"
>>>
>>>
>>>Sys.which('texi2dvi')
>>>
>>>           texi2dvi
>>>
>>>"/usr/bin/texi2dvi"
>>>
>>>> file.exists(Sys.which('texi2dvi'))
>>>
>>>[1] TRUE
>>>
>>>> file.exists(Sys.which('pdflatex'))
>>>
>>>[1] TRUE
>>>
>>>Is there a specific path I should be giving with pdflatex and/or
>>>'texi2dvi to make this work?
>>>
>>>Thanks!
>>>
>>>On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>>>wrote:
>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>> Why were you excluding it?
>>>> Details follow
>>>>
>>>> Rich
>>>>
>>>>
>>>> The current release of the Hmisc package has this capability on
>>>> Macintosh and Linux.
>>>> For Windows, you need the next release 3.14-7 which is available now
>>>at github.
>>>>
>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>> install.packages("devtools")
>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>
>>>> ## All operating systems
>>>> options(latexcmd='pdflatex')
>>>> options(dviExtension='pdf')
>>>>
>>>> ## Macintosh
>>>> options(xdvicmd='open')
>>>>
>>>> ## Windows, one of the following
>>>>
>>>options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>> ## 32-bit windows
>>>>
>>>options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>> ## 64 bit windows
>>>>
>>>> ## Linux
>>>> ## I don't know the xdvicmd value
>>>>
>>>>
>>>> ## this works on all R systems
>>>> library(Hmisc)
>>>> tmp <- matrix(1:9,3,3)
>>>> tmp.dvi <- dvi(latex(tmp))
>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>
>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>><kate.ignatius at gmail.com> wrote:
>>>>> Hi,
>>>>>
>>>>> I have a simple question.  I know there are plenty of packages out
>>>>> there that can provide code to generate a table in latex.  But I was
>>>>> wondering whether there was one out there where I can generate a
>>>table
>>>>> from my data (which ever way I please) then allow me to save it as a
>>>>> pdf?
>>>>>
>>>>> Thanks
>>>>>
>>>>> K.
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From kate.ignatius at gmail.com  Tue Dec  9 21:36:29 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 9 Dec 2014 15:36:29 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
Message-ID: <CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>

I set these options:

options(latexcmd='pdflatex')
options(dviExtension='pdf')
options(xdvicmd='xdvi')

Maybe one too many?  I'm running in Linux.



On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> It looks like you skipped the step of setting the options.
> the latex function doesn't do pdflatex (by default it does regular
> latex) unless you set the options
> as I indicated.
>
> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> Ah yes, you're right.
>>
>> The log has this error:
>>
>> ! LaTeX Error: Missing \begin{document}.
>>
>> Though can't really find much online on how to resolve it.
>>
>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> pdflatex appears to have run, because it exited. You should look at the tex log file, the problem is more likely that the latex you sent out to pdflatex was incomplete.
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>>>Thanks!  I do get several errors though when running on Linux.
>>>>
>>>>Running your code, I get this:
>>>>
>>>>Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>error in running command
>>>>
>>>>Fiddling around with the code and running this:
>>>>
>>>>tmp <- matrix(1:9,3,3)
>>>>tmp.tex <- latex(tmp, file='tmp.tex')
>>>>print.default(tmp.tex)
>>>>tmp.dvi <- dvi(tmp.tex)
>>>>tmp.dvi
>>>>tmp.tex
>>>>dvips(tmp.dvi)
>>>>dvips(tmp.tex)
>>>>library(tools)
>>>>texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>
>>>>I get this:
>>>>
>>>>Error in texi2dvi(file="tmp.tex",,  :
>>>>  Running 'texi2dvi' on 'tmp.tex' failed.
>>>>Messages:
>>>>/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>
>>>>I've read that it may have something to do with the path of pdflatex.
>>>>
>>>>Sys.which('pdflatex')
>>>>
>>>>           pdflatex
>>>>
>>>>"/usr/bin/pdflatex"
>>>>
>>>>
>>>>Sys.which('texi2dvi')
>>>>
>>>>           texi2dvi
>>>>
>>>>"/usr/bin/texi2dvi"
>>>>
>>>>> file.exists(Sys.which('texi2dvi'))
>>>>
>>>>[1] TRUE
>>>>
>>>>> file.exists(Sys.which('pdflatex'))
>>>>
>>>>[1] TRUE
>>>>
>>>>Is there a specific path I should be giving with pdflatex and/or
>>>>'texi2dvi to make this work?
>>>>
>>>>Thanks!
>>>>
>>>>On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>>>>wrote:
>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>> Why were you excluding it?
>>>>> Details follow
>>>>>
>>>>> Rich
>>>>>
>>>>>
>>>>> The current release of the Hmisc package has this capability on
>>>>> Macintosh and Linux.
>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>at github.
>>>>>
>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>> install.packages("devtools")
>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>
>>>>> ## All operating systems
>>>>> options(latexcmd='pdflatex')
>>>>> options(dviExtension='pdf')
>>>>>
>>>>> ## Macintosh
>>>>> options(xdvicmd='open')
>>>>>
>>>>> ## Windows, one of the following
>>>>>
>>>>options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>> ## 32-bit windows
>>>>>
>>>>options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>> ## 64 bit windows
>>>>>
>>>>> ## Linux
>>>>> ## I don't know the xdvicmd value
>>>>>
>>>>>
>>>>> ## this works on all R systems
>>>>> library(Hmisc)
>>>>> tmp <- matrix(1:9,3,3)
>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>
>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>><kate.ignatius at gmail.com> wrote:
>>>>>> Hi,
>>>>>>
>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>> there that can provide code to generate a table in latex.  But I was
>>>>>> wondering whether there was one out there where I can generate a
>>>>table
>>>>>> from my data (which ever way I please) then allow me to save it as a
>>>>>> pdf?
>>>>>>
>>>>>> Thanks
>>>>>>
>>>>>> K.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>


From filippomarolla at gmail.com  Tue Dec  9 21:07:48 2014
From: filippomarolla at gmail.com (Filippo Marolla)
Date: Tue, 9 Dec 2014 21:07:48 +0100
Subject: [R] waller test
Message-ID: <CADmo4kQvruQA-ScZ48LL919z3Ge07r+_b30V_O=64h8ZgUa_Kw@mail.gmail.com>

I am trying to run a duncan-waller test, but i don't get how to implement
it.

These my scripts based on dataframe "lookout":

attach(lookout)
sqrt.res<-sqrt(res.hr.km)
bartlett.test(sqrt.res~time_slot)#no homoscedasticity
welchtest<-oneway.test(sqrt.res~time_slot)#means are differents

wallertest<-waller.test(welchtest, "time_slot", group=FALSE)

It always gives me the following error:

 cannot coerce class '"htest"' into a data.frame


What to do with this?

thanks

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue Dec  9 21:47:06 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 9 Dec 2014 15:47:06 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
	<CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
Message-ID: <CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>

the last one is wrong.  That is the one for which I don't know the
right answer on linux.

'xdvi' displays dvi files.  you need to display a pdf file.
whatever is the right program on linux to display pdf files is what
belongs there.

On Macintosh we can avoid knowing by using 'open', which means use the
system standard.
I don't know what the linux equivalent is, either the exact program or
the instruction to use the standard.

On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> I set these options:
>
> options(latexcmd='pdflatex')
> options(dviExtension='pdf')
> options(xdvicmd='xdvi')
>
> Maybe one too many?  I'm running in Linux.
>
>
>
> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> It looks like you skipped the step of setting the options.
>> the latex function doesn't do pdflatex (by default it does regular
>> latex) unless you set the options
>> as I indicated.
>>
>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>> Ah yes, you're right.
>>>
>>> The log has this error:
>>>
>>> ! LaTeX Error: Missing \begin{document}.
>>>
>>> Though can't really find much online on how to resolve it.
>>>
>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>> pdflatex appears to have run, because it exited. You should look at the tex log file, the problem is more likely that the latex you sent out to pdflatex was incomplete.
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>>>>Thanks!  I do get several errors though when running on Linux.
>>>>>
>>>>>Running your code, I get this:
>>>>>
>>>>>Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>error in running command
>>>>>
>>>>>Fiddling around with the code and running this:
>>>>>
>>>>>tmp <- matrix(1:9,3,3)
>>>>>tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>print.default(tmp.tex)
>>>>>tmp.dvi <- dvi(tmp.tex)
>>>>>tmp.dvi
>>>>>tmp.tex
>>>>>dvips(tmp.dvi)
>>>>>dvips(tmp.tex)
>>>>>library(tools)
>>>>>texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>
>>>>>I get this:
>>>>>
>>>>>Error in texi2dvi(file="tmp.tex",,  :
>>>>>  Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>Messages:
>>>>>/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>
>>>>>I've read that it may have something to do with the path of pdflatex.
>>>>>
>>>>>Sys.which('pdflatex')
>>>>>
>>>>>           pdflatex
>>>>>
>>>>>"/usr/bin/pdflatex"
>>>>>
>>>>>
>>>>>Sys.which('texi2dvi')
>>>>>
>>>>>           texi2dvi
>>>>>
>>>>>"/usr/bin/texi2dvi"
>>>>>
>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>
>>>>>[1] TRUE
>>>>>
>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>
>>>>>[1] TRUE
>>>>>
>>>>>Is there a specific path I should be giving with pdflatex and/or
>>>>>'texi2dvi to make this work?
>>>>>
>>>>>Thanks!
>>>>>
>>>>>On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>>>>>wrote:
>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>> Why were you excluding it?
>>>>>> Details follow
>>>>>>
>>>>>> Rich
>>>>>>
>>>>>>
>>>>>> The current release of the Hmisc package has this capability on
>>>>>> Macintosh and Linux.
>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>at github.
>>>>>>
>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>> install.packages("devtools")
>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>
>>>>>> ## All operating systems
>>>>>> options(latexcmd='pdflatex')
>>>>>> options(dviExtension='pdf')
>>>>>>
>>>>>> ## Macintosh
>>>>>> options(xdvicmd='open')
>>>>>>
>>>>>> ## Windows, one of the following
>>>>>>
>>>>>options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>> ## 32-bit windows
>>>>>>
>>>>>options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>> ## 64 bit windows
>>>>>>
>>>>>> ## Linux
>>>>>> ## I don't know the xdvicmd value
>>>>>>
>>>>>>
>>>>>> ## this works on all R systems
>>>>>> library(Hmisc)
>>>>>> tmp <- matrix(1:9,3,3)
>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>
>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>><kate.ignatius at gmail.com> wrote:
>>>>>>> Hi,
>>>>>>>
>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>> there that can provide code to generate a table in latex.  But I was
>>>>>>> wondering whether there was one out there where I can generate a
>>>>>table
>>>>>>> from my data (which ever way I please) then allow me to save it as a
>>>>>>> pdf?
>>>>>>>
>>>>>>> Thanks
>>>>>>>
>>>>>>> K.
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>______________________________________________
>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>PLEASE do read the posting guide
>>>>>http://www.R-project.org/posting-guide.html
>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>


From ripley at stats.ox.ac.uk  Tue Dec  9 22:02:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 09 Dec 2014 21:02:51 +0000
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>	<CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
	<CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
Message-ID: <5487637B.0@stats.ox.ac.uk>

On 09/12/2014 20:47, Richard M. Heiberger wrote:
> the last one is wrong.  That is the one for which I don't know the
> right answer on linux.
>
> 'xdvi' displays dvi files.  you need to display a pdf file.
> whatever is the right program on linux to display pdf files is what
> belongs there.
>
> On Macintosh we can avoid knowing by using 'open', which means use the
> system standard.
> I don't know what the linux equivalent is, either the exact program or
> the instruction to use the standard.

xdg-open (but like OS X it depends on having the right associations set).

>
> On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> I set these options:
>>
>> options(latexcmd='pdflatex')
>> options(dviExtension='pdf')
>> options(xdvicmd='xdvi')
>>
>> Maybe one too many?  I'm running in Linux.
>>
>>
>>
>> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>> It looks like you skipped the step of setting the options.
>>> the latex function doesn't do pdflatex (by default it does regular
>>> latex) unless you set the options
>>> as I indicated.
>>>
>>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>>> Ah yes, you're right.
>>>>
>>>> The log has this error:
>>>>
>>>> ! LaTeX Error: Missing \begin{document}.
>>>>
>>>> Though can't really find much online on how to resolve it.
>>>>
>>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>>>> pdflatex appears to have run, because it exited. You should look at the tex log file, the problem is more likely that the latex you sent out to pdflatex was incomplete.
>>>>> ---------------------------------------------------------------------------
>>>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>>>                                        Live:   OO#.. Dead: OO#..  Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>>>> ---------------------------------------------------------------------------
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>>>>> Thanks!  I do get several errors though when running on Linux.
>>>>>>
>>>>>> Running your code, I get this:
>>>>>>
>>>>>> Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>> error in running command
>>>>>>
>>>>>> Fiddling around with the code and running this:
>>>>>>
>>>>>> tmp <- matrix(1:9,3,3)
>>>>>> tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>> print.default(tmp.tex)
>>>>>> tmp.dvi <- dvi(tmp.tex)
>>>>>> tmp.dvi
>>>>>> tmp.tex
>>>>>> dvips(tmp.dvi)
>>>>>> dvips(tmp.tex)
>>>>>> library(tools)
>>>>>> texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>>
>>>>>> I get this:
>>>>>>
>>>>>> Error in texi2dvi(file="tmp.tex",,  :
>>>>>>   Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>> Messages:
>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>
>>>>>> I've read that it may have something to do with the path of pdflatex.
>>>>>>
>>>>>> Sys.which('pdflatex')
>>>>>>
>>>>>>            pdflatex
>>>>>>
>>>>>> "/usr/bin/pdflatex"
>>>>>>
>>>>>>
>>>>>> Sys.which('texi2dvi')
>>>>>>
>>>>>>            texi2dvi
>>>>>>
>>>>>> "/usr/bin/texi2dvi"
>>>>>>
>>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>>
>>>>>> [1] TRUE
>>>>>>
>>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>>
>>>>>> [1] TRUE
>>>>>>
>>>>>> Is there a specific path I should be giving with pdflatex and/or
>>>>>> 'texi2dvi to make this work?
>>>>>>
>>>>>> Thanks!
>>>>>>
>>>>>> On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>>>>>> wrote:
>>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>>> Why were you excluding it?
>>>>>>> Details follow
>>>>>>>
>>>>>>> Rich
>>>>>>>
>>>>>>>
>>>>>>> The current release of the Hmisc package has this capability on
>>>>>>> Macintosh and Linux.
>>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>> at github.
>>>>>>>
>>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>>> install.packages("devtools")
>>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>>
>>>>>>> ## All operating systems
>>>>>>> options(latexcmd='pdflatex')
>>>>>>> options(dviExtension='pdf')
>>>>>>>
>>>>>>> ## Macintosh
>>>>>>> options(xdvicmd='open')
>>>>>>>
>>>>>>> ## Windows, one of the following
>>>>>>>
>>>>>> options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>> ## 32-bit windows
>>>>>>>
>>>>>> options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>> ## 64 bit windows
>>>>>>>
>>>>>>> ## Linux
>>>>>>> ## I don't know the xdvicmd value
>>>>>>>
>>>>>>>
>>>>>>> ## this works on all R systems
>>>>>>> library(Hmisc)
>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>>
>>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>>> there that can provide code to generate a table in latex.  But I was
>>>>>>>> wondering whether there was one out there where I can generate a
>>>>>> table
>>>>>>>> from my data (which ever way I please) then allow me to save it as a
>>>>>>>> pdf?
>>>>>>>>
>>>>>>>> Thanks
>>>>>>>>
>>>>>>>> K.
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From rmh at temple.edu  Tue Dec  9 22:20:57 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 9 Dec 2014 16:20:57 -0500
Subject: [R] DIF
In-Reply-To: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>
References: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>
Message-ID: <CAGx1TMD-KwKjHUfxNssp__FU6o5_oiWHqX=Od=VnWmLXzbo+bQ@mail.gmail.com>

I recommend the likert() function in the HH package.

install.packages("HH")
library(HH)
?likert



On Tue, Dec 9, 2014 at 3:22 AM, munevver kaya <munevver.rock at gmail.com> wrote:
> Hello,
> I will analyze polytomous differential item functioning for IRT. I have a
> Likert type scale. For example, I want to analyze items in term of gender.
> Is lordifsufficient for this or are there any other packages in R
> programme?
> Best Regards,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Achim.Zeileis at uibk.ac.at  Tue Dec  9 22:36:39 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 9 Dec 2014 22:36:39 +0100 (CET)
Subject: [R] DIF
In-Reply-To: <CAGx1TMD-KwKjHUfxNssp__FU6o5_oiWHqX=Od=VnWmLXzbo+bQ@mail.gmail.com>
References: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>
	<CAGx1TMD-KwKjHUfxNssp__FU6o5_oiWHqX=Od=VnWmLXzbo+bQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1412092232200.9272@paninaro.uibk.ac.at>

On Tue, 9 Dec 2014, Richard M. Heiberger wrote:

> I recommend the likert() function in the HH package.
>
> install.packages("HH")
> library(HH)
> ?likert

I think this only visualizes the polytomous items but provides no formal 
inference for IRT modeling and DIF testing.

For fitting polytomous IRT models (PCM, RSM, etc.) there are various R 
packages available, probably most prominently the "eRm" package. This also 
includes several tests for DIF. But many other approaches are also 
available (including the "lordif" package). A good first overview is given 
in the Psychometrics task view on CRAN, see: 
http://CRAN.R-project.org/view=Psychometrics

hth,
Z

>
>
> On Tue, Dec 9, 2014 at 3:22 AM, munevver kaya <munevver.rock at gmail.com> wrote:
>> Hello,
>> I will analyze polytomous differential item functioning for IRT. I have a
>> Likert type scale. For example, I want to analyze items in term of gender.
>> Is lordifsufficient for this or are there any other packages in R
>> programme?
>> Best Regards,
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hb at biostat.ucsf.edu  Wed Dec 10 00:11:41 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 9 Dec 2014 15:11:41 -0800
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <5487637B.0@stats.ox.ac.uk>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
	<CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
	<CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
	<5487637B.0@stats.ox.ac.uk>
Message-ID: <CAFDcVCR3bjjcPGuECmQK9TRtPgKOvWS5avpwZbXsnDHuq0YW2w@mail.gmail.com>

I'm surprised no one mentioned alternatives to LaTeX, which is not
necessarily installed on all systems and it's also quite a
heavy-weight setup (100's-1000's MBs).  An alternative is to output a
table in Markdown or HTML and convert that to PDF.  The poor man's
HTML-to-PDF is to manually open the HTML document in a modern web
browser and simply "save as/print to" PDF.  For automatic conversion,
one can use Pandoc [http://johnmacfarlane.net/pandoc/], which is quick
to install.

There are several options to output a table in Markdown or HTML from a
data.frame, e.g. xtable, knitr, rmarkdown.  Here's how you can do it
using R.rsp + knitr::kable:

Create the following RSP-embedded Markdown file 'table.md.rsp' (- - -
lines excluded):
- - - BEGIN - - -
<%
R.utils::use("knitr")
options(knitr.table.format="markdown")
%>

# A Table
<%
data <- head(datasets::iris)
%>

<%= kable(data) %>

_Table: The first <%=nrow(data)%> entries of the iris dataset._
- - - END - - -

Then just run:

> library("R.rsp")
> html <- rfile("table.md.rsp")
> !html

and print/save as PDF in the browser. (*)


If you've got Pandoc installed you can generate a PDF by making sure
to use options(knitr.table.format="pandoc") and then:

> library("R.rsp")
> md <- rfile('table-pandoc.md.rsp', postprocess=FALSE)
> pdf <- gsub("md$", "pdf", md)
> system2("pandoc", args=c(normalizePath(md), "-o", pdf))
> !pdf

See also this Gist: https://gist.github.com/HenrikBengtsson/f4e8f6fe2af5d6ccbed6

/Henrik

(*) For the lazy, to test the above HTML example "on the fly" run:
source("http://callr.org/rfile#https://gist.githubusercontent.com/HenrikBengtsson/f4e8f6fe2af5d6ccbed6/raw/table.md.rsp")



On Tue, Dec 9, 2014 at 1:02 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 09/12/2014 20:47, Richard M. Heiberger wrote:
>>
>> the last one is wrong.  That is the one for which I don't know the
>> right answer on linux.
>>
>> 'xdvi' displays dvi files.  you need to display a pdf file.
>> whatever is the right program on linux to display pdf files is what
>> belongs there.
>>
>> On Macintosh we can avoid knowing by using 'open', which means use the
>> system standard.
>> I don't know what the linux equivalent is, either the exact program or
>> the instruction to use the standard.
>
>
> xdg-open (but like OS X it depends on having the right associations set).
>
>
>>
>> On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com>
>> wrote:
>>>
>>> I set these options:
>>>
>>> options(latexcmd='pdflatex')
>>> options(dviExtension='pdf')
>>> options(xdvicmd='xdvi')
>>>
>>> Maybe one too many?  I'm running in Linux.
>>>
>>>
>>>
>>> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu>
>>> wrote:
>>>>
>>>> It looks like you skipped the step of setting the options.
>>>> the latex function doesn't do pdflatex (by default it does regular
>>>> latex) unless you set the options
>>>> as I indicated.
>>>>
>>>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>>> wrote:
>>>>>
>>>>> Ah yes, you're right.
>>>>>
>>>>> The log has this error:
>>>>>
>>>>> ! LaTeX Error: Missing \begin{document}.
>>>>>
>>>>> Though can't really find much online on how to resolve it.
>>>>>
>>>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>>
>>>>>> pdflatex appears to have run, because it exited. You should look at
>>>>>> the tex log file, the problem is more likely that the latex you sent out to
>>>>>> pdflatex was incomplete.
>>>>>>
>>>>>> ---------------------------------------------------------------------------
>>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>>> Live...
>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>>> Go...
>>>>>>                                        Live:   OO#.. Dead: OO#..
>>>>>> Playing
>>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>>> rocks...1k
>>>>>>
>>>>>> ---------------------------------------------------------------------------
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>
>>>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius
>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>
>>>>>>> Thanks!  I do get several errors though when running on Linux.
>>>>>>>
>>>>>>> Running your code, I get this:
>>>>>>>
>>>>>>> Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>>> error in running command
>>>>>>>
>>>>>>> Fiddling around with the code and running this:
>>>>>>>
>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>> tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>>> print.default(tmp.tex)
>>>>>>> tmp.dvi <- dvi(tmp.tex)
>>>>>>> tmp.dvi
>>>>>>> tmp.tex
>>>>>>> dvips(tmp.dvi)
>>>>>>> dvips(tmp.tex)
>>>>>>> library(tools)
>>>>>>> texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>>>
>>>>>>> I get this:
>>>>>>>
>>>>>>> Error in texi2dvi(file="tmp.tex",,  :
>>>>>>>   Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>>> Messages:
>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>>
>>>>>>> I've read that it may have something to do with the path of pdflatex.
>>>>>>>
>>>>>>> Sys.which('pdflatex')
>>>>>>>
>>>>>>>            pdflatex
>>>>>>>
>>>>>>> "/usr/bin/pdflatex"
>>>>>>>
>>>>>>>
>>>>>>> Sys.which('texi2dvi')
>>>>>>>
>>>>>>>            texi2dvi
>>>>>>>
>>>>>>> "/usr/bin/texi2dvi"
>>>>>>>
>>>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>>>
>>>>>>>
>>>>>>> [1] TRUE
>>>>>>>
>>>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>>>
>>>>>>>
>>>>>>> [1] TRUE
>>>>>>>
>>>>>>> Is there a specific path I should be giving with pdflatex and/or
>>>>>>> 'texi2dvi to make this work?
>>>>>>>
>>>>>>> Thanks!
>>>>>>>
>>>>>>> On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger
>>>>>>> <rmh at temple.edu>
>>>>>>> wrote:
>>>>>>>>
>>>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>>>> Why were you excluding it?
>>>>>>>> Details follow
>>>>>>>>
>>>>>>>> Rich
>>>>>>>>
>>>>>>>>
>>>>>>>> The current release of the Hmisc package has this capability on
>>>>>>>> Macintosh and Linux.
>>>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>>>
>>>>>>> at github.
>>>>>>>>
>>>>>>>>
>>>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>>>> install.packages("devtools")
>>>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>>>
>>>>>>>> ## All operating systems
>>>>>>>> options(latexcmd='pdflatex')
>>>>>>>> options(dviExtension='pdf')
>>>>>>>>
>>>>>>>> ## Macintosh
>>>>>>>> options(xdvicmd='open')
>>>>>>>>
>>>>>>>> ## Windows, one of the following
>>>>>>>>
>>>>>>>
>>>>>>> options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>
>>>>>>>> ## 32-bit windows
>>>>>>>>
>>>>>>>
>>>>>>> options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>
>>>>>>>> ## 64 bit windows
>>>>>>>>
>>>>>>>> ## Linux
>>>>>>>> ## I don't know the xdvicmd value
>>>>>>>>
>>>>>>>>
>>>>>>>> ## this works on all R systems
>>>>>>>> library(Hmisc)
>>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>>>
>>>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>>>>
>>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>>>
>>>>>>>>> Hi,
>>>>>>>>>
>>>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>>>> there that can provide code to generate a table in latex.  But I
>>>>>>>>> was
>>>>>>>>> wondering whether there was one out there where I can generate a
>>>>>>>
>>>>>>> table
>>>>>>>>>
>>>>>>>>> from my data (which ever way I please) then allow me to save it as
>>>>>>>>> a
>>>>>>>>> pdf?
>>>>>>>>>
>>>>>>>>> Thanks
>>>>>>>>>
>>>>>>>>> K.
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Wed Dec 10 01:14:57 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 9 Dec 2014 19:14:57 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <5487637B.0@stats.ox.ac.uk>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
	<CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
	<CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
	<5487637B.0@stats.ox.ac.uk>
Message-ID: <CAE6QMsYeem=95k31fVKxj38ykoSe8kvBDaL+yd6zOxWEBz=Q6A@mail.gmail.com>

Okay, all.

I have it to work using this:

library(Hmisc)
options(latexcmd='pdflatex')
options(dviExtension='pdf')
options(xdvicmd='gnome-open')

Running your simple code from above... by question is this:  the pdf
is saved in a tmp directory... where do I change the directory path? I
thought it was simply this:

tmp.dvi <- dvi(latex(m2,file='/path/to/file/tmp.pdf', label="Title"))

But maybe not.  In addition is it possible to change page size with this?

K.

On Tue, Dec 9, 2014 at 4:02 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 09/12/2014 20:47, Richard M. Heiberger wrote:
>>
>> the last one is wrong.  That is the one for which I don't know the
>> right answer on linux.
>>
>> 'xdvi' displays dvi files.  you need to display a pdf file.
>> whatever is the right program on linux to display pdf files is what
>> belongs there.
>>
>> On Macintosh we can avoid knowing by using 'open', which means use the
>> system standard.
>> I don't know what the linux equivalent is, either the exact program or
>> the instruction to use the standard.
>
>
> xdg-open (but like OS X it depends on having the right associations set).
>
>
>>
>> On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com>
>> wrote:
>>>
>>> I set these options:
>>>
>>> options(latexcmd='pdflatex')
>>> options(dviExtension='pdf')
>>> options(xdvicmd='xdvi')
>>>
>>> Maybe one too many?  I'm running in Linux.
>>>
>>>
>>>
>>> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu>
>>> wrote:
>>>>
>>>> It looks like you skipped the step of setting the options.
>>>> the latex function doesn't do pdflatex (by default it does regular
>>>> latex) unless you set the options
>>>> as I indicated.
>>>>
>>>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>>> wrote:
>>>>>
>>>>> Ah yes, you're right.
>>>>>
>>>>> The log has this error:
>>>>>
>>>>> ! LaTeX Error: Missing \begin{document}.
>>>>>
>>>>> Though can't really find much online on how to resolve it.
>>>>>
>>>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller
>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>>
>>>>>> pdflatex appears to have run, because it exited. You should look at
>>>>>> the tex log file, the problem is more likely that the latex you sent out to
>>>>>> pdflatex was incomplete.
>>>>>>
>>>>>> ---------------------------------------------------------------------------
>>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>>> Live...
>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>>> Go...
>>>>>>                                        Live:   OO#.. Dead: OO#..
>>>>>> Playing
>>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>>> rocks...1k
>>>>>>
>>>>>> ---------------------------------------------------------------------------
>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>
>>>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius
>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>
>>>>>>> Thanks!  I do get several errors though when running on Linux.
>>>>>>>
>>>>>>> Running your code, I get this:
>>>>>>>
>>>>>>> Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>>> error in running command
>>>>>>>
>>>>>>> Fiddling around with the code and running this:
>>>>>>>
>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>> tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>>> print.default(tmp.tex)
>>>>>>> tmp.dvi <- dvi(tmp.tex)
>>>>>>> tmp.dvi
>>>>>>> tmp.tex
>>>>>>> dvips(tmp.dvi)
>>>>>>> dvips(tmp.tex)
>>>>>>> library(tools)
>>>>>>> texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>>>
>>>>>>> I get this:
>>>>>>>
>>>>>>> Error in texi2dvi(file="tmp.tex",,  :
>>>>>>>   Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>>> Messages:
>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>>
>>>>>>> I've read that it may have something to do with the path of pdflatex.
>>>>>>>
>>>>>>> Sys.which('pdflatex')
>>>>>>>
>>>>>>>            pdflatex
>>>>>>>
>>>>>>> "/usr/bin/pdflatex"
>>>>>>>
>>>>>>>
>>>>>>> Sys.which('texi2dvi')
>>>>>>>
>>>>>>>            texi2dvi
>>>>>>>
>>>>>>> "/usr/bin/texi2dvi"
>>>>>>>
>>>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>>>
>>>>>>>
>>>>>>> [1] TRUE
>>>>>>>
>>>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>>>
>>>>>>>
>>>>>>> [1] TRUE
>>>>>>>
>>>>>>> Is there a specific path I should be giving with pdflatex and/or
>>>>>>> 'texi2dvi to make this work?
>>>>>>>
>>>>>>> Thanks!
>>>>>>>
>>>>>>> On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger
>>>>>>> <rmh at temple.edu>
>>>>>>> wrote:
>>>>>>>>
>>>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>>>> Why were you excluding it?
>>>>>>>> Details follow
>>>>>>>>
>>>>>>>> Rich
>>>>>>>>
>>>>>>>>
>>>>>>>> The current release of the Hmisc package has this capability on
>>>>>>>> Macintosh and Linux.
>>>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>>>
>>>>>>> at github.
>>>>>>>>
>>>>>>>>
>>>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>>>> install.packages("devtools")
>>>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>>>
>>>>>>>> ## All operating systems
>>>>>>>> options(latexcmd='pdflatex')
>>>>>>>> options(dviExtension='pdf')
>>>>>>>>
>>>>>>>> ## Macintosh
>>>>>>>> options(xdvicmd='open')
>>>>>>>>
>>>>>>>> ## Windows, one of the following
>>>>>>>>
>>>>>>>
>>>>>>> options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>
>>>>>>>> ## 32-bit windows
>>>>>>>>
>>>>>>>
>>>>>>> options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>
>>>>>>>> ## 64 bit windows
>>>>>>>>
>>>>>>>> ## Linux
>>>>>>>> ## I don't know the xdvicmd value
>>>>>>>>
>>>>>>>>
>>>>>>>> ## this works on all R systems
>>>>>>>> library(Hmisc)
>>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>>>
>>>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>>>>
>>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>>>
>>>>>>>>> Hi,
>>>>>>>>>
>>>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>>>> there that can provide code to generate a table in latex.  But I
>>>>>>>>> was
>>>>>>>>> wondering whether there was one out there where I can generate a
>>>>>>>
>>>>>>> table
>>>>>>>>>
>>>>>>>>> from my data (which ever way I please) then allow me to save it as
>>>>>>>>> a
>>>>>>>>> pdf?
>>>>>>>>>
>>>>>>>>> Thanks
>>>>>>>>>
>>>>>>>>> K.
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>
>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK


From Ted.Harding at wlandres.net  Wed Dec 10 01:55:24 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Wed, 10 Dec 2014 00:55:24 -0000 (GMT)
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
Message-ID: <XFMail.20141209220726.Ted.Harding@wlandres.net>

The program 'gv' is installed on just about any linux system.
It has many available options (one, which might be useful,
being "-watch", whose effect is that if the file being displayed
is changed, e.g. by being over-written by a new file with the
same name, then 'gv' automatically updates what it is displaying).

And of course many linux users install 'acroread' (Acrobat
Reader), though some object!

Hoping this helps,
Ted.

On 09-Dec-2014 20:47:06 Richard M. Heiberger wrote:
> the last one is wrong.  That is the one for which I don't know the
> right answer on linux.
> 
> 'xdvi' displays dvi files.  you need to display a pdf file.
> whatever is the right program on linux to display pdf files is what
> belongs there.
> 
> On Macintosh we can avoid knowing by using 'open', which means use the
> system standard.
> I don't know what the linux equivalent is, either the exact program or
> the instruction to use the standard.
> 
> On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
>> I set these options:
>>
>> options(latexcmd='pdflatex')
>> options(dviExtension='pdf')
>> options(xdvicmd='xdvi')
>>
>> Maybe one too many?  I'm running in Linux.
>>
>>
>>
>> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
>>> It looks like you skipped the step of setting the options.
>>> the latex function doesn't do pdflatex (by default it does regular
>>> latex) unless you set the options
>>> as I indicated.
>>>
>>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>> wrote:
>>>> Ah yes, you're right.
>>>>
>>>> The log has this error:
>>>>
>>>> ! LaTeX Error: Missing \begin{document}.
>>>>
>>>> Though can't really find much online on how to resolve it.
>>>>
>>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>>> wrote:
>>>>> pdflatex appears to have run, because it exited. You should look at the
>>>>> tex log file, the problem is more likely that the latex you sent out to
>>>>> pdflatex was incomplete.
>>>>> --------------------------------------------------------------------------
>>>>> -
>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>> Live...
>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>> Go...
>>>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>>>> rocks...1k
>>>>> --------------------------------------------------------------------------
>>>>> -
>>>>> Sent from my phone. Please excuse my brevity.
>>>>>
>>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius
>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>Thanks!  I do get several errors though when running on Linux.
>>>>>>
>>>>>>Running your code, I get this:
>>>>>>
>>>>>>Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>>error in running command
>>>>>>
>>>>>>Fiddling around with the code and running this:
>>>>>>
>>>>>>tmp <- matrix(1:9,3,3)
>>>>>>tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>>print.default(tmp.tex)
>>>>>>tmp.dvi <- dvi(tmp.tex)
>>>>>>tmp.dvi
>>>>>>tmp.tex
>>>>>>dvips(tmp.dvi)
>>>>>>dvips(tmp.tex)
>>>>>>library(tools)
>>>>>>texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>>
>>>>>>I get this:
>>>>>>
>>>>>>Error in texi2dvi(file="tmp.tex",,  :
>>>>>>  Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>>Messages:
>>>>>>/usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>
>>>>>>I've read that it may have something to do with the path of pdflatex.
>>>>>>
>>>>>>Sys.which('pdflatex')
>>>>>>
>>>>>>           pdflatex
>>>>>>
>>>>>>"/usr/bin/pdflatex"
>>>>>>
>>>>>>
>>>>>>Sys.which('texi2dvi')
>>>>>>
>>>>>>           texi2dvi
>>>>>>
>>>>>>"/usr/bin/texi2dvi"
>>>>>>
>>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>>
>>>>>>[1] TRUE
>>>>>>
>>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>>
>>>>>>[1] TRUE
>>>>>>
>>>>>>Is there a specific path I should be giving with pdflatex and/or
>>>>>>'texi2dvi to make this work?
>>>>>>
>>>>>>Thanks!
>>>>>>
>>>>>>On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger <rmh at temple.edu>
>>>>>>wrote:
>>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>>> Why were you excluding it?
>>>>>>> Details follow
>>>>>>>
>>>>>>> Rich
>>>>>>>
>>>>>>>
>>>>>>> The current release of the Hmisc package has this capability on
>>>>>>> Macintosh and Linux.
>>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>>at github.
>>>>>>>
>>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>>> install.packages("devtools")
>>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>>
>>>>>>> ## All operating systems
>>>>>>> options(latexcmd='pdflatex')
>>>>>>> options(dviExtension='pdf')
>>>>>>>
>>>>>>> ## Macintosh
>>>>>>> options(xdvicmd='open')
>>>>>>>
>>>>>>> ## Windows, one of the following
>>>>>>>
>>>>>>options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>> ## 32-bit windows
>>>>>>>
>>>>>>options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>> ## 64 bit windows
>>>>>>>
>>>>>>> ## Linux
>>>>>>> ## I don't know the xdvicmd value
>>>>>>>
>>>>>>>
>>>>>>> ## this works on all R systems
>>>>>>> library(Hmisc)
>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>>
>>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>>><kate.ignatius at gmail.com> wrote:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>>> there that can provide code to generate a table in latex.  But I was
>>>>>>>> wondering whether there was one out there where I can generate a
>>>>>>table
>>>>>>>> from my data (which ever way I please) then allow me to save it as a
>>>>>>>> pdf?
>>>>>>>>
>>>>>>>> Thanks
>>>>>>>>
>>>>>>>> K.
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>>______________________________________________
>>>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>PLEASE do read the posting guide
>>>>>>http://www.R-project.org/posting-guide.html
>>>>>>and provide commented, minimal, self-contained, reproducible code.
>>>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 09-Dec-2014  Time: 22:07:23
This message was sent by XFMail


From rmh at temple.edu  Wed Dec 10 02:06:05 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 9 Dec 2014 20:06:05 -0500
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAE6QMsYeem=95k31fVKxj38ykoSe8kvBDaL+yd6zOxWEBz=Q6A@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
	<CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
	<CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
	<5487637B.0@stats.ox.ac.uk>
	<CAE6QMsYeem=95k31fVKxj38ykoSe8kvBDaL+yd6zOxWEBz=Q6A@mail.gmail.com>
Message-ID: <CAGx1TMB0RxjiqOGsZa1gRbp6eURACOFe0EVWSwMqso5exqT2RQ@mail.gmail.com>

?latex
answers a lot of these questions.

The design intent of the latex() function is to construct one table at
a time in its own .tex flle.
The user then collects these and inserts them into a full document,
either manually or with Sweave.

The individual table has no context and no caption.
It is a convenience that the dvi() function wraps the table into a pdf
and displays it immediately.

The ?latex documentation shows that there is a file= argument for the
latex() function, not for the others,
You do get information on where the pdf file was stored, so moving it
is a nuisance but not a difficulty.

Changing size is documented.

dvi(tmp.latex, height=11, width=8.5) ## measured in inches

Rich



On Tue, Dec 9, 2014 at 7:14 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Okay, all.
>
> I have it to work using this:
>
> library(Hmisc)
> options(latexcmd='pdflatex')
> options(dviExtension='pdf')
> options(xdvicmd='gnome-open')
>
> Running your simple code from above... by question is this:  the pdf
> is saved in a tmp directory... where do I change the directory path? I
> thought it was simply this:
>
> tmp.dvi <- dvi(latex(m2,file='/path/to/file/tmp.pdf', label="Title"))
>
> But maybe not.  In addition is it possible to change page size with this?
>
> K.
>
> On Tue, Dec 9, 2014 at 4:02 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On 09/12/2014 20:47, Richard M. Heiberger wrote:
>>>
>>> the last one is wrong.  That is the one for which I don't know the
>>> right answer on linux.
>>>
>>> 'xdvi' displays dvi files.  you need to display a pdf file.
>>> whatever is the right program on linux to display pdf files is what
>>> belongs there.
>>>
>>> On Macintosh we can avoid knowing by using 'open', which means use the
>>> system standard.
>>> I don't know what the linux equivalent is, either the exact program or
>>> the instruction to use the standard.
>>
>>
>> xdg-open (but like OS X it depends on having the right associations set).
>>
>>
>>>
>>> On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>> wrote:
>>>>
>>>> I set these options:
>>>>
>>>> options(latexcmd='pdflatex')
>>>> options(dviExtension='pdf')
>>>> options(xdvicmd='xdvi')
>>>>
>>>> Maybe one too many?  I'm running in Linux.
>>>>
>>>>
>>>>
>>>> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu>
>>>> wrote:
>>>>>
>>>>> It looks like you skipped the step of setting the options.
>>>>> the latex function doesn't do pdflatex (by default it does regular
>>>>> latex) unless you set the options
>>>>> as I indicated.
>>>>>
>>>>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> Ah yes, you're right.
>>>>>>
>>>>>> The log has this error:
>>>>>>
>>>>>> ! LaTeX Error: Missing \begin{document}.
>>>>>>
>>>>>> Though can't really find much online on how to resolve it.
>>>>>>
>>>>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller
>>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>>>
>>>>>>> pdflatex appears to have run, because it exited. You should look at
>>>>>>> the tex log file, the problem is more likely that the latex you sent out to
>>>>>>> pdflatex was incomplete.
>>>>>>>
>>>>>>> ---------------------------------------------------------------------------
>>>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>>>> Live...
>>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>>>> Go...
>>>>>>>                                        Live:   OO#.. Dead: OO#..
>>>>>>> Playing
>>>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>>>> rocks...1k
>>>>>>>
>>>>>>> ---------------------------------------------------------------------------
>>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>>
>>>>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius
>>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>>
>>>>>>>> Thanks!  I do get several errors though when running on Linux.
>>>>>>>>
>>>>>>>> Running your code, I get this:
>>>>>>>>
>>>>>>>> Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>>>> error in running command
>>>>>>>>
>>>>>>>> Fiddling around with the code and running this:
>>>>>>>>
>>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>>> tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>>>> print.default(tmp.tex)
>>>>>>>> tmp.dvi <- dvi(tmp.tex)
>>>>>>>> tmp.dvi
>>>>>>>> tmp.tex
>>>>>>>> dvips(tmp.dvi)
>>>>>>>> dvips(tmp.tex)
>>>>>>>> library(tools)
>>>>>>>> texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>>>>
>>>>>>>> I get this:
>>>>>>>>
>>>>>>>> Error in texi2dvi(file="tmp.tex",,  :
>>>>>>>>   Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>>>> Messages:
>>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>>>
>>>>>>>> I've read that it may have something to do with the path of pdflatex.
>>>>>>>>
>>>>>>>> Sys.which('pdflatex')
>>>>>>>>
>>>>>>>>            pdflatex
>>>>>>>>
>>>>>>>> "/usr/bin/pdflatex"
>>>>>>>>
>>>>>>>>
>>>>>>>> Sys.which('texi2dvi')
>>>>>>>>
>>>>>>>>            texi2dvi
>>>>>>>>
>>>>>>>> "/usr/bin/texi2dvi"
>>>>>>>>
>>>>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>>>>
>>>>>>>>
>>>>>>>> [1] TRUE
>>>>>>>>
>>>>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>>>>
>>>>>>>>
>>>>>>>> [1] TRUE
>>>>>>>>
>>>>>>>> Is there a specific path I should be giving with pdflatex and/or
>>>>>>>> 'texi2dvi to make this work?
>>>>>>>>
>>>>>>>> Thanks!
>>>>>>>>
>>>>>>>> On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger
>>>>>>>> <rmh at temple.edu>
>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>>>>> Why were you excluding it?
>>>>>>>>> Details follow
>>>>>>>>>
>>>>>>>>> Rich
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> The current release of the Hmisc package has this capability on
>>>>>>>>> Macintosh and Linux.
>>>>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>>>>
>>>>>>>> at github.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>>>>> install.packages("devtools")
>>>>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>>>>
>>>>>>>>> ## All operating systems
>>>>>>>>> options(latexcmd='pdflatex')
>>>>>>>>> options(dviExtension='pdf')
>>>>>>>>>
>>>>>>>>> ## Macintosh
>>>>>>>>> options(xdvicmd='open')
>>>>>>>>>
>>>>>>>>> ## Windows, one of the following
>>>>>>>>>
>>>>>>>>
>>>>>>>> options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>>
>>>>>>>>> ## 32-bit windows
>>>>>>>>>
>>>>>>>>
>>>>>>>> options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>>
>>>>>>>>> ## 64 bit windows
>>>>>>>>>
>>>>>>>>> ## Linux
>>>>>>>>> ## I don't know the xdvicmd value
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ## this works on all R systems
>>>>>>>>> library(Hmisc)
>>>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>>>>
>>>>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>>>>>
>>>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>>>>
>>>>>>>>>> Hi,
>>>>>>>>>>
>>>>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>>>>> there that can provide code to generate a table in latex.  But I
>>>>>>>>>> was
>>>>>>>>>> wondering whether there was one out there where I can generate a
>>>>>>>>
>>>>>>>> table
>>>>>>>>>>
>>>>>>>>>> from my data (which ever way I please) then allow me to save it as
>>>>>>>>>> a
>>>>>>>>>> pdf?
>>>>>>>>>>
>>>>>>>>>> Thanks
>>>>>>>>>>
>>>>>>>>>> K.
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK


From zilefacelvis at yahoo.com  Wed Dec 10 04:49:05 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 10 Dec 2014 03:49:05 +0000 (UTC)
Subject: [R] Angle brackets ?plotmath
Message-ID: <992048235.7648089.1418183345288.JavaMail.yahoo@jws10697.mail.bf1.yahoo.com>

Hi All,
Please, I would like to enclose T[min] using angle brackets in R.
I have tried something like:

mtext(text=expression(Winter(DJF)~daily~minimum~temperature~bold((italic(symbol("\341")T[min]symbol("\361"))))), side=3, line=1, cex=1.3, col="black") 

but did not succeed. I learnt that adobe-type symbols can  be used but I need help with this.


Please help.
Amny thanks,
Asong.


From hb at biostat.ucsf.edu  Wed Dec 10 06:10:50 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 9 Dec 2014 21:10:50 -0800
Subject: [R] Vignette from existing .pdf manual
In-Reply-To: <3CDD8EA2-20E6-46D6-BA12-AABC0592A5D4@att.net>
References: <3CDD8EA2-20E6-46D6-BA12-AABC0592A5D4@att.net>
Message-ID: <CAFDcVCS7YFtR5h2cWnR4h2qvfibGwt7VAcBieaRcgST+9AdZzg@mail.gmail.com>

With recent versions of R there is no longer a need to trick R with
dummy Rnw files etc.  Instead, try the following:

1. Put your rSARP.tex file in vignettes/, i.e. vignettes/rSARP.tex.
If you have other files that the LaTeX file depends on (e.g. figures),
these should also be put under vignettes/.  When the LaTeX file is
compiled, it's relative to this directory.

2. Rename it to rSARP.latex.  (rSARP.tex will also work, but then R
CMD check will give a NOTE that there is a *.tex file left behind.)

3. Add the following to the top of the rSARP.latex file:

%\VignetteIndexEntry{User manual}
%\VignetteEngine{R.rsp::tex}

4. Add the following two entries to the package DESCRIPTION file:

Suggests: R.rsp
VignetteBuilder: R.rsp

Now 'R CMD build <pkg>' will automatically compile the LaTeX to PDF,
which will be a proper package vignette that is part of your package
*.tar.gz file.  For there on it is just as any other vignette.


If you can't get it to work, make that the following

> tools::buildVignette("vignettes/rSARP.tex")

correctly generates rSARP.pdf without errors. If that works, then 'R
CMD build <pkg>' should also work.

Hope this helps

Henrik


On Sun, Nov 23, 2014 at 7:50 AM, John Hutcheson <hutchesonjohn at att.net> wrote:
> Greetings!  I am trying to develop a package for R for Search and Rescue planning.  I'd like to  re-use an existing PDF file that was created in emacs (so I have the .tex and source data) for use in inst/docs.  The vignette sections of the 'Writing r extensions' manual starts off implying that this can be done, but after lots of effort, I find no way of getting it done.  I did find a suggestion to use a 'dummy' .Rnw file stored alongside the pdf in the inst/doc folder, but haven't been able to make that work.
>
> Here's the setup data:
>
> Package name:   rSARP
> directory structure :  rSARP/inst/doc
>                                             rSARP/inst/extdata
>                                             rSARP/man
>                                             rSARP/R
>
>
> Existing pdf manual:  rSARP.pdf located in rSARP/inst/doc/  (Its less than 5 meg in size)
> VignetteIndexEntry file:        rSARP.Rnw located in rSARP/inst/doc/    The file contents for the dummy .Rnw are:
>
> %\VignetteIndexEntry{User manual}
> \documentclass{article}
> \begin{document}
> \end{document}
>
> I've tried creating an rSARP/vignette folder and storing the .Rnw file there - no luck.
> I appreciate any assistance I can get to incorporate the existing documentation into the package.
>
>
>       John Hutcheson
>      hutchesonjohn at att.net
>             989 - 430 - 7560
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From timothy.benham at uqconnect.edu.au  Wed Dec 10 06:51:22 2014
From: timothy.benham at uqconnect.edu.au (Tim Benham)
Date: Wed, 10 Dec 2014 15:51:22 +1000
Subject: [R] rtmvnorm {tmvtnorm} seems broken
Message-ID: <CACc=JvFJiGV3Dh1tk-euySmzkKc+JjeTEzG2=Y-nnVoVgqcX_Q@mail.gmail.com>

General linear constraints don't seem to work. I get an error message if I
have more constraint equations than variables. E.g. executing the following
code

print(R.version)
library('tmvtnorm')
cat('tmvtnorm version ')
print(packageVersion('tmvtnorm'))
## Let's constrain our sample to the dwarfed hypercube of dimension p.
p <- 3  # dimension
mean <- rep(0,p)
sigma <- diag(p)
## a <= Dx <= b
a <- c(rep(0,p),-Inf)
b <- c(rep(1,p),2)
D <- rbind(diag(p),rep(1,p))
cat('mean is\n'); print(mean)
cat('a is\n'); print(a)
cat('b is\n'); print(b)
cat('D is\n'); print(D)
X <- rtmvnorm(n=1000, mean, sigma, D=D, lower=a, upper=b, algorithm="gibbsR")

produces the following output

platform       x86_64-w64-mingw32
arch           x86_64
os             mingw32
system         x86_64, mingw32
status
major          3
minor          1.0
year           2014
month          04
day            10
svn rev        65387
language       R
version.string R version 3.1.0 (2014-04-10)
nickname       Spring Dance
tmvtnorm version [1] '1.4.9'
mean is
[1] 0 0 0
a is
[1]    0    0    0 -Inf
b is
[1] 1 1 1 2
D is
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    1    0
[3,]    0    0    1
[4,]    1    1    1
Error in checkTmvArgs(mean, sigma, lower, upper) (from rtmvnorm-test.R#18) :
  mean, lower and upper must have the same length

That error message is not appropriate when a matrix of linear constraints is
passed in. I emailed the package maintainer on the 3rd but received only an
automatic out-of-office reply.


From bernardo_brandaum at yahoo.com.br  Wed Dec 10 14:35:15 2014
From: bernardo_brandaum at yahoo.com.br (Bernardo Santos)
Date: Wed, 10 Dec 2014 13:35:15 +0000 (UTC)
Subject: [R] MLE with parameters restricted to a defined range using
 bbmle
In-Reply-To: <54860BAF.1040500@auckland.ac.nz>
References: <54860BAF.1040500@auckland.ac.nz>
Message-ID: <718409083.4794097.1418218515492.JavaMail.yahoo@jws10090.mail.ne1.yahoo.com>

Thanks, Rolf and Ben,
Both solutions worked, but I finished by contraining parameters values using optim().
Best,Bernardo Niebuhr
 

     Em Segunda-feira, 8 de Dezembro de 2014 18:36, Rolf Turner <r.turner at auckland.ac.nz> escreveu:
   

 

I know nothing about the bbmle package and its mle2() function, but it 
is a general truth that if you need to constrain a parameter to be 
positive in an optimisation procedure a simple and effective approach is 
to reparameterize using exp().

I.e. represent xmin as exp(lxmin) (say) and use lxmin as the argument
to your objective function.

This strategy rarely if ever fails to work.

cheers,

Rolf Turner

On 09/12/14 09:04, Bernardo Santos wrote:
> Dear all,
> I am fitting models to data with mle2 function of the bbmle package.In specific, I want to fit a power-law distribution model, as defined here (http://arxiv.org/pdf/cond-mat/0412004v3.pdf), to data.
> However, one of the parameters - xmin -, must be necessarily greater than zero. What can I do to restrict the possible values of a parameter that are passed to the optimizer?
> Here there is a sample of my code:
> # Loading library
> library(bbmle)
>
> # Creating data
> set.seed(1234)
> data <- rexp(1000, rate = 0.1) # The fit will not be too good, but it is just to test
>
> # Creating the power-law distribution density function
> dpowlaw <- function(x, alfa, xmin, log=FALSE){
>? ? c <- (alfa-1)*xmin^(alfa-1)
>? ? if(log) ifelse(x < xmin, 0, log(c*x^(-alfa)))
>? ? else ifelse(x < xmin, 0, c*x^(-alfa))
> }
> # Testing the function
> integrate(dpowlaw, -Inf, Inf, alfa=2, xmin=1)
> curve(dpowlaw(x, alfa=2.5, xmin=10), from=0, to=100, log="")
> curve(dpowlaw(x, alfa=2.5, xmin=1), from=1, to=100, log="xy")
>
> # Negative log-likelihood function
> LLlevy <- function(mu, xmin){
>? ? -sum(dpowlaw(data, alfa=mu, xmin=xmin, log=T))
> }
>
> # Fitting model to data
> mlevy <- mle2(LLlevy, start=list(mu=2, xmin=1))
> The result of model fitting here is Coefficients:
>? ? ? ? mu? ? ? xmin
> -916.4043? 890.4248
> but this does not make sense!xmin must be > 0, and mu must be > 1.What should I do?
> Thanks in advance!Bernardo Niebuhr

-- 
Rolf Turner
Technical Editor ANZJS


   
	[[alternative HTML version deleted]]


From rh at knut-krueger.de  Wed Dec 10 15:26:39 2014
From: rh at knut-krueger.de (Knut Krueger)
Date: Wed, 10 Dec 2014 15:26:39 +0100
Subject: [R] RODBC Error - solved
In-Reply-To: <548584D8.5080103@knut-krueger.de>
References: <548584D8.5080103@knut-krueger.de>
Message-ID: <5488581F.8030009@knut-krueger.de>

Just an update

This error can be reproduced with:
Windows system without MS Office (especially Excel) and an Excel file 
with graphs inside a sheet. It does not depend whether this sheet is 
used or not for import.

Knut


From celine_jouanin at yahoo.fr  Wed Dec 10 17:43:47 2014
From: celine_jouanin at yahoo.fr (Jouanin Celine)
Date: Wed, 10 Dec 2014 16:43:47 +0000 (UTC)
Subject: [R] x axis position and ggplot2
Message-ID: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>

Hi all,
Is it possible to change the position of the x axis to have it at the top of the plot when we use the ggplot function ?Thanks for your help,C?line

	[[alternative HTML version deleted]]


From munevver.rock at gmail.com  Wed Dec 10 15:37:27 2014
From: munevver.rock at gmail.com (munevver kaya)
Date: Wed, 10 Dec 2014 16:37:27 +0200
Subject: [R] DIF
In-Reply-To: <alpine.DEB.2.11.1412092232200.9272@paninaro.uibk.ac.at>
References: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>
	<CAGx1TMD-KwKjHUfxNssp__FU6o5_oiWHqX=Od=VnWmLXzbo+bQ@mail.gmail.com>
	<alpine.DEB.2.11.1412092232200.9272@paninaro.uibk.ac.at>
Message-ID: <CAKM1wmUAsvtL4CqgRbTwPHvH2t_X8QG0MDxBNFEwekG13MBUTQ@mail.gmail.com>

Thanks, Achim and Richard,
I will take into consideration your solutions.
Best,

On Tue, Dec 9, 2014 at 11:36 PM, Achim Zeileis <Achim.Zeileis at uibk.ac.at>
wrote:

> On Tue, 9 Dec 2014, Richard M. Heiberger wrote:
>
>  I recommend the likert() function in the HH package.
>>
>> install.packages("HH")
>> library(HH)
>> ?likert
>>
>
> I think this only visualizes the polytomous items but provides no formal
> inference for IRT modeling and DIF testing.
>
> For fitting polytomous IRT models (PCM, RSM, etc.) there are various R
> packages available, probably most prominently the "eRm" package. This also
> includes several tests for DIF. But many other approaches are also
> available (including the "lordif" package). A good first overview is given
> in the Psychometrics task view on CRAN, see: http://CRAN.R-project.org/
> view=Psychometrics
>
> hth,
>
> Z
>
>
>>
>> On Tue, Dec 9, 2014 at 3:22 AM, munevver kaya <munevver.rock at gmail.com>
>> wrote:
>>
>>> Hello,
>>> I will analyze polytomous differential item functioning for IRT. I have a
>>> Likert type scale. For example, I want to analyze items in term of
>>> gender.
>>> Is lordifsufficient for this or are there any other packages in R
>>> programme?
>>> Best Regards,
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From mselevan at gmail.com  Wed Dec 10 08:21:57 2014
From: mselevan at gmail.com (Michael Selevan)
Date: Tue, 9 Dec 2014 23:21:57 -0800
Subject: [R] AR(1) with an error term arima.sim parameter question
Message-ID: <CAORQ9WqOLigmmq=Kph7Q9VQc0xnGrctQNiQ6YEY2YacGg+o7Zw@mail.gmail.com>

Hello,

I am attempting to plot an AR(1) model with a standard deviation and I am a
little confused as how to do that. I have been looking through the
interwebs and some documentation and I see that there is potentially a few
different ways to do this.

First, simply using the documentation I came up with the command

arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))

which would give me the standard deviation I want. Or I believe that to be
the case. However, after some more searching and googling, I saw an example
where someone used this as a means of adding the AR error term

error.model=function(n){rnorm(n, sd=0.2)}

y = arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2), rand.gen=
error.model)
Now, I am a little confused by this. Would having the error term in the
innov parameter as well as the rand.gen be redundant? What would be the
expected differences between the two? Should only 1 be used?

Just looking for some clarification. Been searching and havent found too
many examples that explicitly state how to add the error term to an AR(1)
model.

Thanks in advance!


-- 
J. Michael Selevan

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Dec 10 21:26:30 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 10 Dec 2014 12:26:30 -0800
Subject: [R] x axis position and ggplot2
In-Reply-To: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
References: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
Message-ID: <63B0FA04-9BED-4962-B1F0-8703B8F76E9C@dcn.davis.CA.us>

I don't think that is possible with the ggplot2 package. Try lattice or base graphics?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 10, 2014 8:43:47 AM PST, Jouanin Celine <celine_jouanin at yahoo.fr> wrote:
>Hi all,
>Is it possible to change the position of the x axis to have it at the
>top of the plot when we use the ggplot function ?Thanks for your
>help,C?line
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Wed Dec 10 21:25:15 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 10 Dec 2014 12:25:15 -0800
Subject: [R] Printing/Generating/Outputting a Table (Not Latex)
In-Reply-To: <CAFDcVCR3bjjcPGuECmQK9TRtPgKOvWS5avpwZbXsnDHuq0YW2w@mail.gmail.com>
References: <CAE6QMsb+9n+-_XbbK+YS4trwG+82_bpq9iRJOQ0SZVhQtchdqQ@mail.gmail.com>
	<CAGx1TMBbO1k2mwwB8=S2eapbdXA5hbBcP2EQ+YF6w39qbTEvmA@mail.gmail.com>
	<CAE6QMsYy3gSRYfZt7mK4HrOqHcOvnx-ewhWLOEXkW8iZJgV_EA@mail.gmail.com>
	<BC5FD5E7-CC93-4759-B362-E057AED79FD9@dcn.davis.CA.us>
	<CAE6QMsZm09Ge05swbFL0EBSkqxvH4gJhfDF1o_WOv6axfQgw-w@mail.gmail.com>
	<CAGx1TMCx6D-KQL8wmU8G734kifgiuZGoLUVC1q=aoogUCvz20w@mail.gmail.com>
	<CAE6QMsZxGFhPDOARSedRmnokShE0LpOV9P2Rwcvsfvrhx=XVww@mail.gmail.com>
	<CAGx1TMBzrzaW6=-v+fvd3Kh99zg3O618Rjur659bFL0UpJbb=A@mail.gmail.com>
	<5487637B.0@stats.ox.ac.uk>
	<CAFDcVCR3bjjcPGuECmQK9TRtPgKOvWS5avpwZbXsnDHuq0YW2w@mail.gmail.com>
Message-ID: <CAFDcVCRZT6KPZsGXKfjyBqivJ23ZjqNLEMCV6OfEZbz1wSAoog@mail.gmail.com>

On Tue, Dec 9, 2014 at 3:11 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> I'm surprised no one mentioned alternatives to LaTeX, which is not
> necessarily installed on all systems and it's also quite a
> heavy-weight setup (100's-1000's MBs).  An alternative is to output a
> table in Markdown or HTML and convert that to PDF.  The poor man's
> HTML-to-PDF is to manually open the HTML document in a modern web
> browser and simply "save as/print to" PDF.  For automatic conversion,
> one can use Pandoc [http://johnmacfarlane.net/pandoc/], which is quick
> to install.
>
> There are several options to output a table in Markdown or HTML from a
> data.frame, e.g. xtable, knitr, rmarkdown.  Here's how you can do it
> using R.rsp + knitr::kable:
>
> Create the following RSP-embedded Markdown file 'table.md.rsp' (- - -
> lines excluded):
> - - - BEGIN - - -
> <%
> R.utils::use("knitr")
> options(knitr.table.format="markdown")
> %>
>
> # A Table
> <%
> data <- head(datasets::iris)
> %>
>
> <%= kable(data) %>
>
> _Table: The first <%=nrow(data)%> entries of the iris dataset._
> - - - END - - -
>
> Then just run:
>
>> library("R.rsp")
>> html <- rfile("table.md.rsp")
>> !html
>
> and print/save as PDF in the browser. (*)
>
>
> If you've got Pandoc installed you can generate a PDF by making sure
> to use options(knitr.table.format="pandoc") and then:
>
>> library("R.rsp")
>> md <- rfile('table-pandoc.md.rsp', postprocess=FALSE)
>> pdf <- gsub("md$", "pdf", md)
>> system2("pandoc", args=c(normalizePath(md), "-o", pdf))
>> !pdf

I was wrong about going down the Pandoc path; Pandoc in turn relies on
LaTeX for generating PDFs so that didn't solve anything:

  "For PDF output, you?ll also need to install LaTeX"
[http://johnmacfarlane.net/pandoc/installing.html]

I've also confirmed that Pandoc fails if 'pdflatex' is not available.

If conversion to PDF from HTML can be done by other means (e.g.
manually in the browser), LaTeX can still be avoided.

Sorry about the noise.

/Henrik

>
> See also this Gist: https://gist.github.com/HenrikBengtsson/f4e8f6fe2af5d6ccbed6
>
> /Henrik
>
> (*) For the lazy, to test the above HTML example "on the fly" run:
> source("http://callr.org/rfile#https://gist.githubusercontent.com/HenrikBengtsson/f4e8f6fe2af5d6ccbed6/raw/table.md.rsp")
>
>
>
> On Tue, Dec 9, 2014 at 1:02 PM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>> On 09/12/2014 20:47, Richard M. Heiberger wrote:
>>>
>>> the last one is wrong.  That is the one for which I don't know the
>>> right answer on linux.
>>>
>>> 'xdvi' displays dvi files.  you need to display a pdf file.
>>> whatever is the right program on linux to display pdf files is what
>>> belongs there.
>>>
>>> On Macintosh we can avoid knowing by using 'open', which means use the
>>> system standard.
>>> I don't know what the linux equivalent is, either the exact program or
>>> the instruction to use the standard.
>>
>>
>> xdg-open (but like OS X it depends on having the right associations set).
>>
>>
>>>
>>> On Tue, Dec 9, 2014 at 3:36 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>> wrote:
>>>>
>>>> I set these options:
>>>>
>>>> options(latexcmd='pdflatex')
>>>> options(dviExtension='pdf')
>>>> options(xdvicmd='xdvi')
>>>>
>>>> Maybe one too many?  I'm running in Linux.
>>>>
>>>>
>>>>
>>>> On Tue, Dec 9, 2014 at 3:24 PM, Richard M. Heiberger <rmh at temple.edu>
>>>> wrote:
>>>>>
>>>>> It looks like you skipped the step of setting the options.
>>>>> the latex function doesn't do pdflatex (by default it does regular
>>>>> latex) unless you set the options
>>>>> as I indicated.
>>>>>
>>>>> On Tue, Dec 9, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com>
>>>>> wrote:
>>>>>>
>>>>>> Ah yes, you're right.
>>>>>>
>>>>>> The log has this error:
>>>>>>
>>>>>> ! LaTeX Error: Missing \begin{document}.
>>>>>>
>>>>>> Though can't really find much online on how to resolve it.
>>>>>>
>>>>>> On Tue, Dec 9, 2014 at 1:15 PM, Jeff Newmiller
>>>>>> <jdnewmil at dcn.davis.ca.us> wrote:
>>>>>>>
>>>>>>> pdflatex appears to have run, because it exited. You should look at
>>>>>>> the tex log file, the problem is more likely that the latex you sent out to
>>>>>>> pdflatex was incomplete.
>>>>>>>
>>>>>>> ---------------------------------------------------------------------------
>>>>>>> Jeff Newmiller                        The     .....       .....  Go
>>>>>>> Live...
>>>>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>>>>> Go...
>>>>>>>                                        Live:   OO#.. Dead: OO#..
>>>>>>> Playing
>>>>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>>>>> rocks...1k
>>>>>>>
>>>>>>> ---------------------------------------------------------------------------
>>>>>>> Sent from my phone. Please excuse my brevity.
>>>>>>>
>>>>>>> On December 9, 2014 8:43:02 AM PST, Kate Ignatius
>>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>>
>>>>>>>> Thanks!  I do get several errors though when running on Linux.
>>>>>>>>
>>>>>>>> Running your code, I get this:
>>>>>>>>
>>>>>>>> Error in system(cmd, intern = TRUE, wait = TRUE) :
>>>>>>>> error in running command
>>>>>>>>
>>>>>>>> Fiddling around with the code and running this:
>>>>>>>>
>>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>>> tmp.tex <- latex(tmp, file='tmp.tex')
>>>>>>>> print.default(tmp.tex)
>>>>>>>> tmp.dvi <- dvi(tmp.tex)
>>>>>>>> tmp.dvi
>>>>>>>> tmp.tex
>>>>>>>> dvips(tmp.dvi)
>>>>>>>> dvips(tmp.tex)
>>>>>>>> library(tools)
>>>>>>>> texi2dvi(file='tmp.tex', pdf=TRUE, clean=TRUE)
>>>>>>>>
>>>>>>>> I get this:
>>>>>>>>
>>>>>>>> Error in texi2dvi(file="tmp.tex",,  :
>>>>>>>>   Running 'texi2dvi' on 'tmp.tex' failed.
>>>>>>>> Messages:
>>>>>>>> /usr/bin/texi2dvi: pdflatex exited with bad status, quitting.
>>>>>>>>
>>>>>>>> I've read that it may have something to do with the path of pdflatex.
>>>>>>>>
>>>>>>>> Sys.which('pdflatex')
>>>>>>>>
>>>>>>>>            pdflatex
>>>>>>>>
>>>>>>>> "/usr/bin/pdflatex"
>>>>>>>>
>>>>>>>>
>>>>>>>> Sys.which('texi2dvi')
>>>>>>>>
>>>>>>>>            texi2dvi
>>>>>>>>
>>>>>>>> "/usr/bin/texi2dvi"
>>>>>>>>
>>>>>>>>> file.exists(Sys.which('texi2dvi'))
>>>>>>>>
>>>>>>>>
>>>>>>>> [1] TRUE
>>>>>>>>
>>>>>>>>> file.exists(Sys.which('pdflatex'))
>>>>>>>>
>>>>>>>>
>>>>>>>> [1] TRUE
>>>>>>>>
>>>>>>>> Is there a specific path I should be giving with pdflatex and/or
>>>>>>>> 'texi2dvi to make this work?
>>>>>>>>
>>>>>>>> Thanks!
>>>>>>>>
>>>>>>>> On Mon, Dec 8, 2014 at 11:13 PM, Richard M. Heiberger
>>>>>>>> <rmh at temple.edu>
>>>>>>>> wrote:
>>>>>>>>>
>>>>>>>>> yes of course, and the answer is latex() in the Hmisc package.
>>>>>>>>> Why were you excluding it?
>>>>>>>>> Details follow
>>>>>>>>>
>>>>>>>>> Rich
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> The current release of the Hmisc package has this capability on
>>>>>>>>> Macintosh and Linux.
>>>>>>>>> For Windows, you need the next release 3.14-7 which is available now
>>>>>>>>
>>>>>>>> at github.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ## windows needs these lines until the new Hmisc version is on CRAN
>>>>>>>>> install.packages("devtools")
>>>>>>>>> devtools::install_github("Hmisc", "harrelfe")
>>>>>>>>>
>>>>>>>>> ## All operating systems
>>>>>>>>> options(latexcmd='pdflatex')
>>>>>>>>> options(dviExtension='pdf')
>>>>>>>>>
>>>>>>>>> ## Macintosh
>>>>>>>>> options(xdvicmd='open')
>>>>>>>>>
>>>>>>>>> ## Windows, one of the following
>>>>>>>>>
>>>>>>>>
>>>>>>>> options(xdvicmd='c:\\progra~1\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>>
>>>>>>>>> ## 32-bit windows
>>>>>>>>>
>>>>>>>>
>>>>>>>> options(xdvicmd='c:\\progra~2\\Adobe\\Reader~1.0\\Reader\\AcroRd32.exe')
>>>>>>>>>
>>>>>>>>> ## 64 bit windows
>>>>>>>>>
>>>>>>>>> ## Linux
>>>>>>>>> ## I don't know the xdvicmd value
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> ## this works on all R systems
>>>>>>>>> library(Hmisc)
>>>>>>>>> tmp <- matrix(1:9,3,3)
>>>>>>>>> tmp.dvi <- dvi(latex(tmp))
>>>>>>>>> print.default(tmp.dvi) ## prints filepath of the pdf file
>>>>>>>>> tmp.dvi  ## displays the pdf file on your screen
>>>>>>>>>
>>>>>>>>> On Mon, Dec 8, 2014 at 9:31 PM, Kate Ignatius
>>>>>>>>
>>>>>>>> <kate.ignatius at gmail.com> wrote:
>>>>>>>>>>
>>>>>>>>>> Hi,
>>>>>>>>>>
>>>>>>>>>> I have a simple question.  I know there are plenty of packages out
>>>>>>>>>> there that can provide code to generate a table in latex.  But I
>>>>>>>>>> was
>>>>>>>>>> wondering whether there was one out there where I can generate a
>>>>>>>>
>>>>>>>> table
>>>>>>>>>>
>>>>>>>>>> from my data (which ever way I please) then allow me to save it as
>>>>>>>>>> a
>>>>>>>>>> pdf?
>>>>>>>>>>
>>>>>>>>>> Thanks
>>>>>>>>>>
>>>>>>>>>> K.
>>>>>>>>>>
>>>>>>>>>> ______________________________________________
>>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>>> PLEASE do read the posting guide
>>>>>>>>
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>>>
>>>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rphilip.chalmers at gmail.com  Wed Dec 10 20:42:21 2014
From: rphilip.chalmers at gmail.com (Phil Chalmers)
Date: Wed, 10 Dec 2014 11:42:21 -0800 (PST)
Subject: [R] DIF
In-Reply-To: <CAKM1wmUAsvtL4CqgRbTwPHvH2t_X8QG0MDxBNFEwekG13MBUTQ@mail.gmail.com>
References: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>
	<CAGx1TMD-KwKjHUfxNssp__FU6o5_oiWHqX=Od=VnWmLXzbo+bQ@mail.gmail.com>
	<alpine.DEB.2.11.1412092232200.9272@paninaro.uibk.ac.at>
	<CAKM1wmUAsvtL4CqgRbTwPHvH2t_X8QG0MDxBNFEwekG13MBUTQ@mail.gmail.com>
Message-ID: <4f64d4e3-2668-4f31-b08a-e61bf8ffe9a8@googlegroups.com>

As well, the mirt package contains a function for DIF using likelihood 
ratio tests via multiple-group estimation methods (the multiple group 
estimation generally goes beyond simply testing for DIF), as well Wald 
tests if the information matrix was computed. Hope that helps.

Phil

On Wednesday, December 10, 2014 2:20:51 PM UTC-5, munevver kaya wrote:
>
> Thanks, Achim and Richard, 
> I will take into consideration your solutions. 
> Best, 
>
> On Tue, Dec 9, 2014 at 11:36 PM, Achim Zeileis <Achim.... at uibk.ac.at 
> <javascript:>> 
> wrote: 
>
> > On Tue, 9 Dec 2014, Richard M. Heiberger wrote: 
> > 
> >  I recommend the likert() function in the HH package. 
> >> 
> >> install.packages("HH") 
> >> library(HH) 
> >> ?likert 
> >> 
> > 
> > I think this only visualizes the polytomous items but provides no formal 
> > inference for IRT modeling and DIF testing. 
> > 
> > For fitting polytomous IRT models (PCM, RSM, etc.) there are various R 
> > packages available, probably most prominently the "eRm" package. This 
> also 
> > includes several tests for DIF. But many other approaches are also 
> > available (including the "lordif" package). A good first overview is 
> given 
> > in the Psychometrics task view on CRAN, see: http://CRAN.R-project.org/ 
> > view=Psychometrics 
> > 
> > hth, 
> > 
> > Z 
> > 
> > 
> >> 
> >> On Tue, Dec 9, 2014 at 3:22 AM, munevver kaya <munevv... at gmail.com 
> <javascript:>> 
> >> wrote: 
> >> 
> >>> Hello, 
> >>> I will analyze polytomous differential item functioning for IRT. I 
> have a 
> >>> Likert type scale. For example, I want to analyze items in term of 
> >>> gender. 
> >>> Is lordifsufficient for this or are there any other packages in R 
> >>> programme? 
> >>> Best Regards, 
> >>> 
> >>>         [[alternative HTML version deleted]] 
> >>> 
> >>> ______________________________________________ 
> >>> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> >>> https://stat.ethz.ch/mailman/listinfo/r-help 
> >>> PLEASE do read the posting guide http://www.R-project.org/ 
> >>> posting-guide.html 
> >>> and provide commented, minimal, self-contained, reproducible code. 
> >>> 
> >> 
> >> ______________________________________________ 
> >> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> >> https://stat.ethz.ch/mailman/listinfo/r-help 
> >> PLEASE do read the posting guide http://www.R-project.org/ 
> >> posting-guide.html 
> >> and provide commented, minimal, self-contained, reproducible code. 
> >> 
> >> 
>
>         [[alternative HTML version deleted]] 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list -- To UNSUBSCRIBE and 
> more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From nashjc at uottawa.ca  Wed Dec 10 22:03:01 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 10 Dec 2014 16:03:01 -0500
Subject: [R] maximum number of dlls issue
Message-ID: <5488B505.8070402@uottawa.ca>

I'm attempting to run the following script to allow me to
bring a "new" computer to a state where it can run a set of scripts
that is running on another.

# listcheckinstall.R
# get a list of R packages from a file,
# check if installed,
# install those not installed
# then update all packages
# Run as superuser
listname <- readline("file of packages=")
biglist<-readLines(listname)
np <- length(biglist)
# instlist <- installed.packages()  # this is alternative method
for (i in 1:np) {
## if (biglist[i] %in% instlist) {  # this is alternative method
   if (require(biglist[i], character.only=TRUE) ) {
      cat(biglist[i], "is installed\n")
      biglist[i] <- NA
   } else {
      cat("need to install ",biglist[i],"\n")
   }
   tmp <- readline("next")
}
plist <- biglist(which(! is.na(biglist)))
plist
install.packages(plist)
update.packages()

About 2/3 of the way through, I get a msg that the maximum number of
dlls has been loaded and then some consequent errors.

I've been looking at library.dynam.unload and .dynLibs as a way to
possibly unload things require() has got into the workspace. So far no
success. I suggest offline contact and I'll post solution or relevant
discussion when things are worked out.

The installed.packages() list approach works OK, so this is not
critical. I was thinking installed.packages() would be slow, but in fact
the call is only done once, and it runs faster than the "require"
approach. However, I would like to understand what is going on with the
DLLs and how to sort them out if needed.

> sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>

OS = Linux Mint Maya (Ubuntu 12.04 derivative) 64 bit.

JN


From r.turner at auckland.ac.nz  Wed Dec 10 22:04:07 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 11 Dec 2014 10:04:07 +1300
Subject: [R] AR(1) with an error term arima.sim parameter question
In-Reply-To: <CAORQ9WqOLigmmq=Kph7Q9VQc0xnGrctQNiQ6YEY2YacGg+o7Zw@mail.gmail.com>
References: <CAORQ9WqOLigmmq=Kph7Q9VQc0xnGrctQNiQ6YEY2YacGg+o7Zw@mail.gmail.com>
Message-ID: <5488B547.1020109@auckland.ac.nz>


Please see below.

On 10/12/14 20:21, Michael Selevan wrote:
> Hello,
>
> I am attempting to plot an AR(1) model with a standard deviation and I am a
> little confused as how to do that. I have been looking through the
> interwebs and some documentation and I see that there is potentially a few
> different ways to do this.
>
> First, simply using the documentation I came up with the command
>
> arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))
>
> which would give me the standard deviation I want. Or I believe that to be
> the case. However, after some more searching and googling, I saw an example
> where someone used this as a means of adding the AR error term
>
> error.model=function(n){rnorm(n, sd=0.2)}
>
> y = arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2), rand.gen=
> error.model)
> Now, I am a little confused by this. Would having the error term in the
> innov parameter as well as the rand.gen be redundant? What would be the
> expected differences between the two? Should only 1 be used?
>
> Just looking for some clarification. Been searching and havent found too
> many examples that explicitly state how to add the error term to an AR(1)
> model.

It's a little bit subtle, but in a way that's not too important.

There is, in addition to "innov" a starting innovations vector 
"start.innov" that is needed.  If either innov or start.innov is not 
supplied their values get supplied by rand.gen().  So in your second 
call to arima.sim() ***start.innov*** is being supplied by rand.gen()
(but ***innov*** will be taken to be equal to the argument supplied.

In your first call, where rand.gen() is not specified (and start.innov
is not specified), the supplied value of innov will be used and 
start.innov will be produced by the *default* value of rand.gen()
which is rnorm(), you'll get rnorm(n.start,0,1).

Thus in your first call, the starting innovations will be done with a 
different standard deviation than the other innovations.  Which is 
probably not what you want.

Hence the second call is correct --- but it *is* kind of redundant and 
confusing to supply "innov" as well as rand.gen().  The code would be
clearer if "innov" were dispensed with and it was just left to 
rand.gen() to do the work.

The following is not important, but it might be mystifying:  If you 
leave out "innov" you will get a different result --- even if you set a 
seed for the random number generators a priori.  E.g.:

# 1.
set.seed(42)
innov <- rnorm(10,0,0.2)
error.model=function(n){rnorm(n, sd=0.2)}
y1 <- arima.sim(n=10, list(ar=0.8), innov=innov,
                 rand.gen=error.model)

# 2.
set.seed(42)
error.model=function(n){rnorm(n, sd=0.2)}
y2 <- arima.sim(n=10, list(ar=0.8),rand.gen=error.model)

The vectors y1 and y2 are (surprisingly until you think carefully) 
different.

This is because for y1, innov.start is generated *after* innov is
generated, whereas for y2 innov.start is generated *before* innov is
generated.  The first entry of innov for y1 will be the same as the
first entry of innov.start for y2.  So the sequence of innovations is
different.

Bottom line:  I would recommend *not* using the "innov" argument and
just specifying rand.gen() to get the standard deviations that you want.

HTH

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From ligges at statistik.tu-dortmund.de  Wed Dec 10 22:19:44 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 10 Dec 2014 22:19:44 +0100
Subject: [R] Angle brackets ?plotmath
In-Reply-To: <992048235.7648089.1418183345288.JavaMail.yahoo@jws10697.mail.bf1.yahoo.com>
References: <992048235.7648089.1418183345288.JavaMail.yahoo@jws10697.mail.bf1.yahoo.com>
Message-ID: <5488B8F0.7060606@statistik.tu-dortmund.de>



On 10.12.2014 04:49, Zilefac Elvis via R-help wrote:
> Hi All,
> Please, I would like to enclose T[min] using angle brackets in R.
> I have tried something like:
>
> mtext(text=expression(Winter(DJF)~daily~minimum~temperature~bold((italic(symbol("\341")T[min]symbol("\361"))))), side=3, line=1, cex=1.3, col="black")
>
> but did not succeed. I learnt that adobe-type symbols can  be used but I need help with this.


What about
italic("<"*T[min]*">")
or
italic(symbol("\341")*T[min]*symbol("\361"))

Best,
Uwe Ligges


>
> Please help.
> Amny thanks,
> Asong.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r_vardavas at hotmail.com  Wed Dec 10 22:34:47 2014
From: r_vardavas at hotmail.com (Raffaello Vardavas)
Date: Wed, 10 Dec 2014 13:34:47 -0800
Subject: [R] NA problem in rbind of an apply summary
Message-ID: <DUB127-W59B1304583EC917348F528E6620@phx.gbl>

Dear All,

I have a data fame. Each column has numerical values but some columns may have NA values.
I'd like a table showing the summary statistics for each column. This is what I do:

I first do the following:

apply(df[,metrics],2,summary,na.rm=T)

giving:

$degree
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    0.0   261.9   489.3   500.6   698.5  1551.0 

$EV.centrality
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
0.0000000 0.0001067 0.0006391 0.0057460 0.0020410 1.0000000 

$betweenness
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    0.0     0.0   150.5  2955.0  2208.0 60940.0 

$knn
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's 
   2.00   21.50   32.44   36.75   46.15  224.50      26 


Then I rbind them and get:

do.call("rbind",apply(df[,metrics],2,summary,na.rm=T))

                            Min.   1st Qu.    Median      Mean   3rd Qu.    Max. NA's
degree                         0 2.619e+02 4.893e+02 5.006e+02 6.985e+02  1551.0    0
EV.centrality                  0 1.067e-04 6.391e-04 5.746e-03 2.041e-03     1.0    0
betweenness                    0 0.000e+00 1.505e+02 2.955e+03 2.208e+03 60940.0    0
knn                            2 2.150e+01 3.244e+01 3.675e+01 4.615e+01   224.5   26

Since the first 3 rows don't have NA's but the 4th has I get the following warning:

Warning message:
In rbind(degree = c(0, 261.9, 489.3, 500.6, 698.5, 1551), EV.centrality = c(0,  :
  number of columns of result is not a multiple of vector length (arg 1)
Calls: do.call -> rbind


How do I code this in a way to avoid this warning? 

Thanks.

Raff
 		 	   		  
	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Wed Dec 10 22:48:05 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 10 Dec 2014 22:48:05 +0100
Subject: [R] NA problem in rbind of an apply summary
In-Reply-To: <DUB127-W59B1304583EC917348F528E6620@phx.gbl>
References: <DUB127-W59B1304583EC917348F528E6620@phx.gbl>
Message-ID: <CALJKBv92ngBTGbXs05hXHu5VVY0ViXqum8FgCRkd+SxPtLFzEA@mail.gmail.com>

Hi,
Could you try  rbind.na.R function.
karim

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 10, 2014 at 10:34 PM, Raffaello Vardavas <r_vardavas at hotmail.com
> wrote:

> Dear All,
>
> I have a data fame. Each column has numerical values but some columns may
> have NA values.
> I'd like a table showing the summary statistics for each column. This is
> what I do:
>
> I first do the following:
>
> apply(df[,metrics],2,summary,na.rm=T)
>
> giving:
>
> $degree
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>     0.0   261.9   489.3   500.6   698.5  1551.0
>
> $EV.centrality
>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
> 0.0000000 0.0001067 0.0006391 0.0057460 0.0020410 1.0000000
>
> $betweenness
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>     0.0     0.0   150.5  2955.0  2208.0 60940.0
>
> $knn
>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
>    2.00   21.50   32.44   36.75   46.15  224.50      26
>
>
> Then I rbind them and get:
>
> do.call("rbind",apply(df[,metrics],2,summary,na.rm=T))
>
>                             Min.   1st Qu.    Median      Mean   3rd Qu.
>   Max. NA's
> degree                         0 2.619e+02 4.893e+02 5.006e+02 6.985e+02
> 1551.0    0
> EV.centrality                  0 1.067e-04 6.391e-04 5.746e-03 2.041e-03
>    1.0    0
> betweenness                    0 0.000e+00 1.505e+02 2.955e+03 2.208e+03
> 60940.0    0
> knn                            2 2.150e+01 3.244e+01 3.675e+01 4.615e+01
>  224.5   26
>
> Since the first 3 rows don't have NA's but the 4th has I get the following
> warning:
>
> Warning message:
> In rbind(degree = c(0, 261.9, 489.3, 500.6, 698.5, 1551), EV.centrality =
> c(0,  :
>   number of columns of result is not a multiple of vector length (arg 1)
> Calls: do.call -> rbind
>
>
> How do I code this in a way to avoid this warning?
>
> Thanks.
>
> Raff
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

From zilefacelvis at yahoo.com  Thu Dec 11 00:04:14 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 10 Dec 2014 23:04:14 +0000 (UTC)
Subject: [R] Angle brackets ?plotmath
In-Reply-To: <5488B8F0.7060606@statistik.tu-dortmund.de>
References: <5488B8F0.7060606@statistik.tu-dortmund.de>
Message-ID: <1631716673.6299646.1418252655247.JavaMail.yahoo@jws10674.mail.bf1.yahoo.com>

Perfect!  #
italic(symbol("\341")*T[min]*symbol("\361"))
Thanks, Uwe.
Asong.

On 10.12.2014 04:49, Zilefac Elvis via R-help wrote:
> Hi All,
> Please, I would like to enclose T[min] using angle brackets in R.
> I have tried something like:
>
> mtext(text=expression(Winter(DJF)~daily~minimum~temperature~bold((italic(symbol("\341")T[min]symbol("\361"))))), side=3, line=1, cex=1.3, col="black")
>
> but did not succeed. I learnt that adobe-type symbols can  be used but I need help with this.


What about
italic("<"*T[min]*">")
or
italic(symbol("\341")*T[min]*symbol("\361"))

Best,
Uwe Ligges



>
> Please help.
> Amny thanks,
> Asong.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>


From dulcalma at bigpond.com  Thu Dec 11 02:57:31 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 11 Dec 2014 11:57:31 +1000
Subject: [R] x axis position and ggplot2
In-Reply-To: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
References: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
Message-ID: <000601d014e5$d4142260$7c3c6720$@bigpond.com>

Hi 

I do not know ggplot2 well enough to give any advice but as Geff has mention lattice see

http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17666.html

library(grid)
myXlabGrob <-
function(...){ ## ...is lab1, lab2, etc

   # you can add arguments to textGrob for more control  in the next line
   labs <- lapply(list(...), textGrob)
   nlabs <- length(labs)

   lab.heights <-
   lapply(labs, function(lab) unit(1, "grobheight", data = list(lab)))

   lab.layout <-
   grid.layout(ncol = nlabs, nrow = 1,
                   heights = do.call(max, lab.heights),
                   widths = unit(1, "null"),
                   respect = TRUE)

   lab.gf <- frameGrob(layout = lab.layout)

   for (i in seq_len(nlabs)){
     lab.gf <- placeGrob(lab.gf, labs[[i]], row = 1, col = i)
   }
   lab.gf
}

xyplot(1:10 ~ 1:10,
        scales = list(x = list(alternating = 2)), # puts scale on the top rather than the bottom
        xlab = "", # removes label at bottom
        xlab.top = myXlabGrob('B')
        )

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jouanin Celine
Sent: Thursday, 11 December 2014 02:44
To: r-help at r-project.org
Subject: [R] x axis position and ggplot2

Hi all,
Is it possible to change the position of the x axis to have it at the top of the plot when we use the ggplot function ?Thanks for your help,C?line

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mselevan at gmail.com  Thu Dec 11 08:09:19 2014
From: mselevan at gmail.com (Michael Selevan)
Date: Wed, 10 Dec 2014 23:09:19 -0800
Subject: [R] AR(1) with an error term arima.sim parameter question
In-Reply-To: <5488B547.1020109@auckland.ac.nz>
References: <CAORQ9WqOLigmmq=Kph7Q9VQc0xnGrctQNiQ6YEY2YacGg+o7Zw@mail.gmail.com>
	<5488B547.1020109@auckland.ac.nz>
Message-ID: <CAORQ9Wo3baGuD4RfU-nfxx137kYXksfGo7TXNDQu0wE+w6fhmg@mail.gmail.com>

This makes sense, thank you for the thorough response!

One follow up question though. Would your #2 option be the same as, say,
not using the rand.gen at all and providing the following parameters
instead?

y3 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))

or even

y4 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2),
innov.start=rnorm(10, sd=0.2))

Would either of these then be the same result as your option #2?

Thanks again!


On Wed, Dec 10, 2014 at 1:04 PM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

>
> Please see below.
>
>
> On 10/12/14 20:21, Michael Selevan wrote:
>
>> Hello,
>>
>> I am attempting to plot an AR(1) model with a standard deviation and I am
>> a
>> little confused as how to do that. I have been looking through the
>> interwebs and some documentation and I see that there is potentially a few
>> different ways to do this.
>>
>> First, simply using the documentation I came up with the command
>>
>> arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))
>>
>> which would give me the standard deviation I want. Or I believe that to be
>> the case. However, after some more searching and googling, I saw an
>> example
>> where someone used this as a means of adding the AR error term
>>
>> error.model=function(n){rnorm(n, sd=0.2)}
>>
>> y = arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2), rand.gen=
>> error.model)
>> Now, I am a little confused by this. Would having the error term in the
>> innov parameter as well as the rand.gen be redundant? What would be the
>> expected differences between the two? Should only 1 be used?
>>
>> Just looking for some clarification. Been searching and havent found too
>> many examples that explicitly state how to add the error term to an AR(1)
>> model.
>>
>
> It's a little bit subtle, but in a way that's not too important.
>
> There is, in addition to "innov" a starting innovations vector
> "start.innov" that is needed.  If either innov or start.innov is not
> supplied their values get supplied by rand.gen().  So in your second call
> to arima.sim() ***start.innov*** is being supplied by rand.gen()
> (but ***innov*** will be taken to be equal to the argument supplied.
>
> In your first call, where rand.gen() is not specified (and start.innov
> is not specified), the supplied value of innov will be used and
> start.innov will be produced by the *default* value of rand.gen()
> which is rnorm(), you'll get rnorm(n.start,0,1).
>
> Thus in your first call, the starting innovations will be done with a
> different standard deviation than the other innovations.  Which is probably
> not what you want.
>
> Hence the second call is correct --- but it *is* kind of redundant and
> confusing to supply "innov" as well as rand.gen().  The code would be
> clearer if "innov" were dispensed with and it was just left to rand.gen()
> to do the work.
>
> The following is not important, but it might be mystifying:  If you leave
> out "innov" you will get a different result --- even if you set a seed for
> the random number generators a priori.  E.g.:
>
> # 1.
> set.seed(42)
> innov <- rnorm(10,0,0.2)
> error.model=function(n){rnorm(n, sd=0.2)}
> y1 <- arima.sim(n=10, list(ar=0.8), innov=innov,
>                 rand.gen=error.model)
>
> # 2.
> set.seed(42)
> error.model=function(n){rnorm(n, sd=0.2)}
> y2 <- arima.sim(n=10, list(ar=0.8),rand.gen=error.model)
>
> The vectors y1 and y2 are (surprisingly until you think carefully)
> different.
>
> This is because for y1, innov.start is generated *after* innov is
> generated, whereas for y2 innov.start is generated *before* innov is
> generated.  The first entry of innov for y1 will be the same as the
> first entry of innov.start for y2.  So the sequence of innovations is
> different.
>
> Bottom line:  I would recommend *not* using the "innov" argument and
> just specifying rand.gen() to get the standard deviations that you want.
>
> HTH
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
>



-- 
J. Michael Selevan

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Dec 11 09:29:14 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 11 Dec 2014 21:29:14 +1300
Subject: [R] AR(1) with an error term arima.sim parameter question
In-Reply-To: <CAORQ9Wo3baGuD4RfU-nfxx137kYXksfGo7TXNDQu0wE+w6fhmg@mail.gmail.com>
References: <CAORQ9WqOLigmmq=Kph7Q9VQc0xnGrctQNiQ6YEY2YacGg+o7Zw@mail.gmail.com>
	<5488B547.1020109@auckland.ac.nz>
	<CAORQ9Wo3baGuD4RfU-nfxx137kYXksfGo7TXNDQu0wE+w6fhmg@mail.gmail.com>
Message-ID: <548955DA.4040007@auckland.ac.nz>

On 11/12/14 20:09, Michael Selevan wrote:
> This makes sense, thank you for the thorough response!
>
> One follow up question though. Would your #2 option be the same as, say,
> not using the rand.gen at all and providing the following parameters
> instead?
>
> y3 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))

No.  This will call rand.gen=rnorm() to generate innov.start, so
start.innov will be generated with a standard deviation of 1 rather
than 0.2.

>
> or even
>
> y4 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2),
> innov.start=rnorm(10, sd=0.2))

Why didn't you try it?  It gives an error, saying start.innov is too 
short.  It needs to be of length *28* according to the error message. 
Note that "innov.start" should read "start.innov".  My bad;
I got the argument name wrong (on the second attempt!) in my previous
posting.

y4 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2),
                 start.innov=rnorm(28, sd=0.2))

should I think be the same as y2.  ***You*** try it and see!

(Set a seed prior to each calculation; that's what seeds are for!)

cheers,

Rolf Turner

<SNIP>

> On Wed, Dec 10, 2014 at 1:04 PM, Rolf Turner <r.turner at auckland.ac.nz
> <mailto:r.turner at auckland.ac.nz>> wrote:
>
>
>     Please see below.
>
>
>     On 10/12/14 20:21, Michael Selevan wrote:
>
>         Hello,
>
>         I am attempting to plot an AR(1) model with a standard deviation
>         and I am a
>         little confused as how to do that. I have been looking through the
>         interwebs and some documentation and I see that there is
>         potentially a few
>         different ways to do this.
>
>         First, simply using the documentation I came up with the command
>
>         arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))
>
>         which would give me the standard deviation I want. Or I believe
>         that to be
>         the case. However, after some more searching and googling, I saw
>         an example
>         where someone used this as a means of adding the AR error term
>
>         error.model=function(n){rnorm(__n, sd=0.2)}
>
>         y = arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2), rand.gen=
>         error.model)
>         Now, I am a little confused by this. Would having the error term
>         in the
>         innov parameter as well as the rand.gen be redundant? What would
>         be the
>         expected differences between the two? Should only 1 be used?
>
>         Just looking for some clarification. Been searching and havent
>         found too
>         many examples that explicitly state how to add the error term to
>         an AR(1)
>         model.
>
>
>     It's a little bit subtle, but in a way that's not too important.
>
>     There is, in addition to "innov" a starting innovations vector
>     "start.innov" that is needed.  If either innov or start.innov is not
>     supplied their values get supplied by rand.gen().  So in your second
>     call to arima.sim() ***start.innov*** is being supplied by rand.gen()
>     (but ***innov*** will be taken to be equal to the argument supplied.
>
>     In your first call, where rand.gen() is not specified (and start.innov
>     is not specified), the supplied value of innov will be used and
>     start.innov will be produced by the *default* value of rand.gen()
>     which is rnorm(), you'll get rnorm(n.start,0,1).
>
>     Thus in your first call, the starting innovations will be done with
>     a different standard deviation than the other innovations.  Which is
>     probably not what you want.
>
>     Hence the second call is correct --- but it *is* kind of redundant
>     and confusing to supply "innov" as well as rand.gen().  The code
>     would be
>     clearer if "innov" were dispensed with and it was just left to
>     rand.gen() to do the work.
>
>     The following is not important, but it might be mystifying:  If you
>     leave out "innov" you will get a different result --- even if you
>     set a seed for the random number generators a priori.  E.g.:
>
>     # 1.
>     set.seed(42)
>     innov <- rnorm(10,0,0.2)
>     error.model=function(n){rnorm(__n, sd=0.2)}
>     y1 <- arima.sim(n=10, list(ar=0.8), innov=innov,
>                      rand.gen=error.model)
>
>     # 2.
>     set.seed(42)
>     error.model=function(n){rnorm(__n, sd=0.2)}
>     y2 <- arima.sim(n=10, list(ar=0.8),rand.gen=error.__model)
>
>     The vectors y1 and y2 are (surprisingly until you think carefully)
>     different.
>
>     This is because for y1, innov.start is generated *after* innov is
>     generated, whereas for y2 innov.start is generated *before* innov is
>     generated.  The first entry of innov for y1 will be the same as the
>     first entry of innov.start for y2.  So the sequence of innovations is
>     different.
>
>     Bottom line:  I would recommend *not* using the "innov" argument and
>     just specifying rand.gen() to get the standard deviations that you want.
>
>     HTH
>
>     cheers,
>
>     Rolf Turner
>
>     --
>     Rolf Turner
>     Technical Editor ANZJS
>
>
>
>
> --
> J. Michael Selevan


-- 
Rolf Turner
Technical Editor ANZJS


From mselevan at gmail.com  Thu Dec 11 09:30:23 2014
From: mselevan at gmail.com (Michael Selevan)
Date: Thu, 11 Dec 2014 00:30:23 -0800
Subject: [R] AR(1) with an error term arima.sim parameter question
In-Reply-To: <548955DA.4040007@auckland.ac.nz>
References: <CAORQ9WqOLigmmq=Kph7Q9VQc0xnGrctQNiQ6YEY2YacGg+o7Zw@mail.gmail.com>
	<5488B547.1020109@auckland.ac.nz>
	<CAORQ9Wo3baGuD4RfU-nfxx137kYXksfGo7TXNDQu0wE+w6fhmg@mail.gmail.com>
	<548955DA.4040007@auckland.ac.nz>
Message-ID: <CAORQ9WqUS_u9VJYhPjVLkahoLhDvMmHX4VMat_gWtcCHZkRS5Q@mail.gmail.com>

Thanks for all the help! Ill give them a shot and compare the results.

On Thu, Dec 11, 2014 at 12:29 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 11/12/14 20:09, Michael Selevan wrote:
>
>> This makes sense, thank you for the thorough response!
>>
>> One follow up question though. Would your #2 option be the same as, say,
>> not using the rand.gen at all and providing the following parameters
>> instead?
>>
>> y3 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))
>>
>
> No.  This will call rand.gen=rnorm() to generate innov.start, so
> start.innov will be generated with a standard deviation of 1 rather
> than 0.2.
>
>
>> or even
>>
>> y4 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2),
>> innov.start=rnorm(10, sd=0.2))
>>
>
> Why didn't you try it?  It gives an error, saying start.innov is too
> short.  It needs to be of length *28* according to the error message. Note
> that "innov.start" should read "start.innov".  My bad;
> I got the argument name wrong (on the second attempt!) in my previous
> posting.
>
> y4 <- arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2),
>                 start.innov=rnorm(28, sd=0.2))
>
> should I think be the same as y2.  ***You*** try it and see!
>
> (Set a seed prior to each calculation; that's what seeds are for!)
>
> cheers,
>
> Rolf Turner
>
> <SNIP>
>
>  On Wed, Dec 10, 2014 at 1:04 PM, Rolf Turner <r.turner at auckland.ac.nz
>> <mailto:r.turner at auckland.ac.nz>> wrote:
>>
>>
>>     Please see below.
>>
>>
>>     On 10/12/14 20:21, Michael Selevan wrote:
>>
>>         Hello,
>>
>>         I am attempting to plot an AR(1) model with a standard deviation
>>         and I am a
>>         little confused as how to do that. I have been looking through the
>>         interwebs and some documentation and I see that there is
>>         potentially a few
>>         different ways to do this.
>>
>>         First, simply using the documentation I came up with the command
>>
>>         arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2))
>>
>>         which would give me the standard deviation I want. Or I believe
>>         that to be
>>         the case. However, after some more searching and googling, I saw
>>         an example
>>         where someone used this as a means of adding the AR error term
>>
>>         error.model=function(n){rnorm(__n, sd=0.2)}
>>
>>
>>         y = arima.sim(n=10, list(ar=0.8), innov=rnorm(10, sd=0.2),
>> rand.gen=
>>         error.model)
>>         Now, I am a little confused by this. Would having the error term
>>         in the
>>         innov parameter as well as the rand.gen be redundant? What would
>>         be the
>>         expected differences between the two? Should only 1 be used?
>>
>>         Just looking for some clarification. Been searching and havent
>>         found too
>>         many examples that explicitly state how to add the error term to
>>         an AR(1)
>>         model.
>>
>>
>>     It's a little bit subtle, but in a way that's not too important.
>>
>>     There is, in addition to "innov" a starting innovations vector
>>     "start.innov" that is needed.  If either innov or start.innov is not
>>     supplied their values get supplied by rand.gen().  So in your second
>>     call to arima.sim() ***start.innov*** is being supplied by rand.gen()
>>     (but ***innov*** will be taken to be equal to the argument supplied.
>>
>>     In your first call, where rand.gen() is not specified (and start.innov
>>     is not specified), the supplied value of innov will be used and
>>     start.innov will be produced by the *default* value of rand.gen()
>>     which is rnorm(), you'll get rnorm(n.start,0,1).
>>
>>     Thus in your first call, the starting innovations will be done with
>>     a different standard deviation than the other innovations.  Which is
>>     probably not what you want.
>>
>>     Hence the second call is correct --- but it *is* kind of redundant
>>     and confusing to supply "innov" as well as rand.gen().  The code
>>     would be
>>     clearer if "innov" were dispensed with and it was just left to
>>     rand.gen() to do the work.
>>
>>     The following is not important, but it might be mystifying:  If you
>>     leave out "innov" you will get a different result --- even if you
>>     set a seed for the random number generators a priori.  E.g.:
>>
>>     # 1.
>>     set.seed(42)
>>     innov <- rnorm(10,0,0.2)
>>     error.model=function(n){rnorm(__n, sd=0.2)}
>>     y1 <- arima.sim(n=10, list(ar=0.8), innov=innov,
>>                      rand.gen=error.model)
>>
>>     # 2.
>>     set.seed(42)
>>     error.model=function(n){rnorm(__n, sd=0.2)}
>>     y2 <- arima.sim(n=10, list(ar=0.8),rand.gen=error.__model)
>>
>>     The vectors y1 and y2 are (surprisingly until you think carefully)
>>     different.
>>
>>     This is because for y1, innov.start is generated *after* innov is
>>     generated, whereas for y2 innov.start is generated *before* innov is
>>     generated.  The first entry of innov for y1 will be the same as the
>>     first entry of innov.start for y2.  So the sequence of innovations is
>>     different.
>>
>>     Bottom line:  I would recommend *not* using the "innov" argument and
>>     just specifying rand.gen() to get the standard deviations that you
>> want.
>>
>>     HTH
>>
>>     cheers,
>>
>>     Rolf Turner
>>
>>     --
>>     Rolf Turner
>>     Technical Editor ANZJS
>>
>>
>>
>>
>> --
>> J. Michael Selevan
>>
>
>
> --
> Rolf Turner
> Technical Editor ANZJS
>



-- 
J. Michael Selevan

	[[alternative HTML version deleted]]


From michel.arnaud at cirad.fr  Thu Dec 11 11:12:14 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 11 Dec 2014 11:12:14 +0100
Subject: [R] to calculate c(rep("1", 43), rep("2",43),...., rep("10",43))
In-Reply-To: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
References: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
Message-ID: <54896DFE.1060101@cirad.fr>

Hello
I would like to find an elegant way of calculating
c(rep("1", 43), rep("2",43),...., rep("10",43))

Any idea ?
Thank you

-- 
Michel ARNAUD
DGDRD-Drh - TA 174/04
tel : 04.67.61.75.38
port: 06.47.43.55.31


From ruipbarradas at sapo.pt  Thu Dec 11 11:34:12 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 11 Dec 2014 10:34:12 +0000
Subject: [R] to calculate c(rep("1", 43), rep("2", 43), ...., rep("10",
	43))
In-Reply-To: <54896DFE.1060101@cirad.fr>
References: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
	<54896DFE.1060101@cirad.fr>
Message-ID: <54897324.1070702@sapo.pt>

Hello,

Try the following.

unlist(lapply(1:10, function(n) rep(as.character(n), 43)))

Hope this helps,

Rui Barradas

Em 11-12-2014 10:12, Arnaud Michel escreveu:
> Hello
> I would like to find an elegant way of calculating
> c(rep("1", 43), rep("2",43),...., rep("10",43))
>
> Any idea ?
> Thank you
>


From ivan.calandra at univ-reims.fr  Thu Dec 11 11:38:05 2014
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 11 Dec 2014 11:38:05 +0100
Subject: [R] to calculate c(rep("1", 43), rep("2", 43), ...., rep("10",
	43))
In-Reply-To: <54896DFE.1060101@cirad.fr>
References: <1903059662.8421027.1418229827228.JavaMail.yahoo@jws11150.mail.ir2.yahoo.com>
	<54896DFE.1060101@cirad.fr>
Message-ID: <5489740D.2000100@univ-reims.fr>

Hi Michel,

What about
rep(1:10, each=43)

If you need to have characters, you could do something like: 
as.character(1:10)

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENA? - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 11/12/14 11:12, Arnaud Michel a ?crit :
> Hello
> I would like to find an elegant way of calculating
> c(rep("1", 43), rep("2",43),...., rep("10",43))
>
> Any idea ?
> Thank you
>


From phaedrusv at gmail.com  Thu Dec 11 14:00:04 2014
From: phaedrusv at gmail.com (Sun Shine)
Date: Thu, 11 Dec 2014 13:00:04 +0000
Subject: [R] Working with data frames
Message-ID: <54899554.10705@gmail.com>

Hello

I am struggling with data frames and would appreciate some help please.

I have a data set of 13 observations and 80 variables. The first column 
is the names of different political area boundaries (e.g. MHad, LBNW, 
etc), the first row is a vector of variable names concerning various 
census data (e.g. age.T, hse.Unk, etc.). The first cell [1,1] is blank.

I have loaded this via read.csv('path.to/data.set.csv'), and now want to 
run some analyses on this data frame. If I want to get a list of the 
names of the political areas (i.e. the first column), the result is a 
vector of numbers which appear to correlate with the factors, but I 
don't get the text names, just the corresponding number. So, if I want 
to plot something basic, like the area that uses the most gas for 
central heating, for example:

 > plot(data.set$ch.Gas)

The result is the y-axis gives the gas usage for the areas, but the 
x-axis gives only the numbers of the areas, not the names of the areas 
(which is preferred).

So, two questions:

(1) have I set up my csv file correctly to be read as a data frame as 
the first row of all of the remaining columns with the values for that 
political area in the corresponding row in the column with the specific 
variable name? So far, looking through tutorials and books seems to 
suggest yes, but at this point I'm no longer sure.

(2) How can I access the names of the political areas when plotting so 
that these are given on the x-axis instead of the numbers?

Thanks for any help.

Cheers
Sun


From ivan.calandra at univ-reims.fr  Thu Dec 11 14:08:38 2014
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 11 Dec 2014 14:08:38 +0100
Subject: [R] Working with data frames
In-Reply-To: <54899554.10705@gmail.com>
References: <54899554.10705@gmail.com>
Message-ID: <54899756.9010301@univ-reims.fr>

Hi Sun,

If I understood correctly (a reproducible example would be of great 
help), it seems you're struggling with factors. Read on this topic to 
better understand how it works.

For your plots, you would need to set the labels with the argument 
'xlab' for plot(). To access the names of the factors, use levels()

HTH,
Ivan

--
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENA? - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 11/12/14 14:00, Sun Shine a ?crit :
> Hello
>
> I am struggling with data frames and would appreciate some help please.
>
> I have a data set of 13 observations and 80 variables. The first 
> column is the names of different political area boundaries (e.g. MHad, 
> LBNW, etc), the first row is a vector of variable names concerning 
> various census data (e.g. age.T, hse.Unk, etc.). The first cell [1,1] 
> is blank.
>
> I have loaded this via read.csv('path.to/data.set.csv'), and now want 
> to run some analyses on this data frame. If I want to get a list of 
> the names of the political areas (i.e. the first column), the result 
> is a vector of numbers which appear to correlate with the factors, but 
> I don't get the text names, just the corresponding number. So, if I 
> want to plot something basic, like the area that uses the most gas for 
> central heating, for example:
>
> > plot(data.set$ch.Gas)
>
> The result is the y-axis gives the gas usage for the areas, but the 
> x-axis gives only the numbers of the areas, not the names of the areas 
> (which is preferred).
>
> So, two questions:
>
> (1) have I set up my csv file correctly to be read as a data frame as 
> the first row of all of the remaining columns with the values for that 
> political area in the corresponding row in the column with the 
> specific variable name? So far, looking through tutorials and books 
> seems to suggest yes, but at this point I'm no longer sure.
>
> (2) How can I access the names of the political areas when plotting so 
> that these are given on the x-axis instead of the numbers?
>
> Thanks for any help.
>
> Cheers
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chirleu at gmail.com  Thu Dec 11 14:28:24 2014
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Thu, 11 Dec 2014 14:28:24 +0100
Subject: [R] How to pass a nested random effect with frailty in coxph() -
	survival package?
Message-ID: <CALC46t-WB5xZvLTPZgJ7N-aKRfaNyFOELL+AUGhG=eGskuEwGg@mail.gmail.com>

Hi,
I have a very simple Cox regression model in which I need to include a
nested random effect: individual nested in treatment. I know how to pass a
single random effect - e.g. frailty(id)- but how can I specify the nested
random (id nested in treatment) effect using frailty?
The equivalent in lme4 would be (treatment|id)

Thanks!

David

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Thu Dec 11 16:10:47 2014
From: jholtman at gmail.com (jim holtman)
Date: Thu, 11 Dec 2014 10:10:47 -0500
Subject: [R] Working with data frames
In-Reply-To: <54899554.10705@gmail.com>
References: <54899554.10705@gmail.com>
Message-ID: <CAAxdm-4ix+A4gXgX0SSKXP6JLfyG7TQUfMqOXafvpcBa3LiV4g@mail.gmail.com>

If you are using 'read.csv' (or 'read.table') to input, then use the 'as.is
= TRUE' parameter to prevent the conversion to factors of the data.

You can also do "as.character(df$col_with_factors)" to get the character
values back.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Dec 11, 2014 at 8:00 AM, Sun Shine <phaedrusv at gmail.com> wrote:

> Hello
>
> I am struggling with data frames and would appreciate some help please.
>
> I have a data set of 13 observations and 80 variables. The first column is
> the names of different political area boundaries (e.g. MHad, LBNW, etc),
> the first row is a vector of variable names concerning various census data
> (e.g. age.T, hse.Unk, etc.). The first cell [1,1] is blank.
>
> I have loaded this via read.csv('path.to/data.set.csv'), and now want to
> run some analyses on this data frame. If I want to get a list of the names
> of the political areas (i.e. the first column), the result is a vector of
> numbers which appear to correlate with the factors, but I don't get the
> text names, just the corresponding number. So, if I want to plot something
> basic, like the area that uses the most gas for central heating, for
> example:
>
> > plot(data.set$ch.Gas)
>
> The result is the y-axis gives the gas usage for the areas, but the x-axis
> gives only the numbers of the areas, not the names of the areas (which is
> preferred).
>
> So, two questions:
>
> (1) have I set up my csv file correctly to be read as a data frame as the
> first row of all of the remaining columns with the values for that
> political area in the corresponding row in the column with the specific
> variable name? So far, looking through tutorials and books seems to suggest
> yes, but at this point I'm no longer sure.
>
> (2) How can I access the names of the political areas when plotting so
> that these are given on the x-axis instead of the numbers?
>
> Thanks for any help.
>
> Cheers
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pollaroid at gmail.com  Thu Dec 11 16:54:27 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Thu, 11 Dec 2014 16:54:27 +0100
Subject: [R] Create previous dates from date with consideration of leap year
Message-ID: <CAAC1QdBueBm2zz_8V-_ZK8ukRo8_kAhGPibF+uq8D-Ham+93Xw@mail.gmail.com>

Dear R Community,

I wish to create 5 preceding dates from the date variable by ID. How
could I create such dates? The code should consider leap year.

Thanks

Sample data follows:


structure(list(id = 1:12, date = structure(c(9L, 6L, 11L, 8L,
7L, 5L, 4L, 3L, 12L, 1L, 10L, 2L), .Label = c("01feb2003", "03mar2008",
"04feb2008", "07jul1991", "07jun2010", "13feb2005", "18dec1991",
"22sep2005", "27apr1993", "29jan2009", "29may2002", "31jan2005"
), class = "factor"), case = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L)), .Names = c("id", "date", "case"), class =
"data.frame", row.names = c(NA,
-12L))


From wdunlap at tibco.com  Thu Dec 11 17:06:44 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 11 Dec 2014 08:06:44 -0800
Subject: [R] Working with data frames
In-Reply-To: <54899554.10705@gmail.com>
References: <54899554.10705@gmail.com>
Message-ID: <CAF8bMcbcr3hzPOCPDEebz-M+7VpuREFwN6DCBxyJed_15qgRJg@mail.gmail.com>

Here is a reproducible example
  > d <- read.csv(text="Name,Age\nBob,2\nXavier,25\nAdam,1")
  > str(d)
  'data.frame':   3 obs. of  2 variables:
   $ Name: Factor w/ 3 levels "Adam","Bob","Xavier": 2 3 1
   $ Age : int  2 25 1

Do you get something similar?  If not, show us what you have (you
could trim it down to a few columns).

Let's try some plots.
    > plot(d$Age)
This shows a plot of d$Age (on y axis) vs "Index", where Index is
1:length(d$Age).  The points are at (1,2), (2,25), and (3,1). You gave
plot() no information about what should be on the x axis so it gave
you the index numbers.

Now asking for d$Name on the x axis and d$Age on the y.
    > plot(d$Name, d$Age)
This put the names, in alphabetical order on the x axis.  The y axis
ranges from about 0 to 25 and neither axis is labelled.  There are
thick horizontal line segments where you expect the the points to
be.  These are degenerate boxplots - when you ask to plot a
'factor' variable on the x axis and numbers on the y you get such
a plot.

Some folks suggested you avoid factors by adding stringsAsFactors=FALSE
(or as.is=TRUE) to your call to read.csv.  Let's try that
  > d2 <- read.csv(stringsAsFactors=FALSE,
        text="Name,Age\nBob,2\nXavier,25\nAdam,1")
  > plot(d2$Name, d2$Age)
  Error in plot.window(...) : need finite 'xlim' values
  In addition: Warning messages:
  1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
  2: In min(x) : no non-missing arguments to min; returning Inf
  3: In max(x) : no non-missing arguments to max; returning -Inf
You get no plot at all.

You can get closer to what I think you want with
  with(d, {
    plot(as.integer(Name), Age, axes=FALSE, xlab="Name")
    axis(side=2) # draw the usual y axis
    axis(side=1, at=seq_along(levels(Name)), lab=levels(Name))
  })
If you want the names in a different order on the x axis, then reconstruct
the factor object d$Name with a different order of levels.  E.g.,
  d$Name <- factor(d$Name, levels=c("Xavier", "Bob", "Adam"))
and replot.

There are various plotting packages, e.g., ggplot2, that can make this
sort of thing easier, but I think the recommendation not to use factors
is wrong.  You do need to learn how to use them to your advantage.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Dec 11, 2014 at 5:00 AM, Sun Shine <phaedrusv at gmail.com> wrote:

> Hello
>
> I am struggling with data frames and would appreciate some help please.
>
> I have a data set of 13 observations and 80 variables. The first column is
> the names of different political area boundaries (e.g. MHad, LBNW, etc),
> the first row is a vector of variable names concerning various census data
> (e.g. age.T, hse.Unk, etc.). The first cell [1,1] is blank.
>
> I have loaded this via read.csv('path.to/data.set.csv'), and now want to
> run some analyses on this data frame. If I want to get a list of the names
> of the political areas (i.e. the first column), the result is a vector of
> numbers which appear to correlate with the factors, but I don't get the
> text names, just the corresponding number. So, if I want to plot something
> basic, like the area that uses the most gas for central heating, for
> example:
>
> > plot(data.set$ch.Gas)
>
> The result is the y-axis gives the gas usage for the areas, but the x-axis
> gives only the numbers of the areas, not the names of the areas (which is
> preferred).
>
> So, two questions:
>
> (1) have I set up my csv file correctly to be read as a data frame as the
> first row of all of the remaining columns with the values for that
> political area in the corresponding row in the column with the specific
> variable name? So far, looking through tutorials and books seems to suggest
> yes, but at this point I'm no longer sure.
>
> (2) How can I access the names of the political areas when plotting so
> that these are given on the x-axis instead of the numbers?
>
> Thanks for any help.
>
> Cheers
> Sun
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From adel.daoud at socav.gu.se  Thu Dec 11 16:40:30 2014
From: adel.daoud at socav.gu.se (Adel)
Date: Thu, 11 Dec 2014 07:40:30 -0800 (PST)
Subject: [R] Using gregexpr and regmatches but getting Iconv error
Message-ID: <1418312430083-4700677.post@n4.nabble.com>

Hi 

I have stumbled upon a problem when using gregexpr and regmatches, with the
following error-message: 

Error in iconv(x, "latin1", "ASCII") : 
  'x' must be a list of NULL or raw vectors 

The data: 

(1) 
I have two journal articles and after some regex manipulation I am at the
following situation: 

# manipluat only two full text articles 
author.test <- articles1[1:2]   
# extract author informaiton 
r <- gregexpr("(\"authors\":(.*?)\"(.*?)\")|(\"authors\": \\[(.*?)\\],)",
author.test) 
authors.raw <- regmatches(author.test, r) 

authors.raw 
[[1]] 
[1] "\"authors\": [\"Allan G. KING\", \"B. Lindsay LOWELL\", \"Frank D.
BEAN\"]," 

[[2]] 
[1] "\"authors\": \"Chris Baldry\", \"" 

(2) 
Now, if I want to conduct additional regex manipulation I get the Error
stated above. 

r <-  gregexpr("([^(\"authors\":)])(.*?)(\"(.*?)\")", authors.raw) 
authors.raw <- regmatches(authors.raw, r) 

Error in iconv(x, "latin1", "ASCII") : 
  'x' must be a list of NULL or raw vectors 

(3) 
One of the ways to avoid this is to unlist(authors.raw)  - see below - but
the problem with this is that I lose some information which was contained in
the list. The first element contains three character elements and which are
the authors of the first paper. I want to keep them in that list format. 

> authors.raw <- unlist(regmatches(authors.raw, r)) 
> authors.raw 
[1] " [\"Allan G. KING\""     ", \"B. Lindsay LOWELL\"" ", \"Frank D.
BEAN\""     " \"Chris Baldry\"" 

(4) 
So what I want to do is to avoid unlis() and apply the gregex() multiple
times in a row. Any ideas? 

Thanks in advance 
Adel 



--
View this message in context: http://r.789695.n4.nabble.com/Using-gregexpr-and-regmatches-but-getting-Iconv-error-tp4700677.html
Sent from the R help mailing list archive at Nabble.com.


From chl948 at mail.usask.ca  Thu Dec 11 17:34:44 2014
From: chl948 at mail.usask.ca (Lee, Chel Hee)
Date: Thu, 11 Dec 2014 10:34:44 -0600
Subject: [R] Create previous dates from date with consideration of leap
	year
In-Reply-To: <CAAC1QdBueBm2zz_8V-_ZK8ukRo8_kAhGPibF+uq8D-Ham+93Xw@mail.gmail.com>
References: <CAAC1QdBueBm2zz_8V-_ZK8ukRo8_kAhGPibF+uq8D-Ham+93Xw@mail.gmail.com>
Message-ID: <5489C7A4.9010205@mail.usask.ca>

The sample data you provided has the variable 'date'.  Since the type of 
this variable is 'factor', you may try to convert type of variable from 
'factor' to 'date' as shown in the below:

 > x$rval <- as.Date(x$date, format="%d%b%Y")-5
 > x
    id      date case       rval
1   1 27apr1993    1 1993-04-22
2   2 13feb2005    1 2005-02-08
3   3 29may2002    1 2002-05-24
4   4 22sep2005    1 2005-09-17
5   5 18dec1991    1 1991-12-13
6   6 07jun2010    1 2010-06-02
7   7 07jul1991    1 1991-07-02
8   8 04feb2008    1 2008-01-30
9   9 31jan2005    1 2005-01-26
10 10 01feb2003    1 2003-01-27
11 11 29jan2009    1 2009-01-24
12 12 03mar2008    1 2008-02-27
 >

Leap year is also considered (See the last case 'id=12').  Is this what 
you are looking for?   I hope this helps.

Chel Hee Lee

On 12/11/2014 9:54 AM, Kuma Raj wrote:
> Dear R Community,
>
> I wish to create 5 preceding dates from the date variable by ID. How
> could I create such dates? The code should consider leap year.
>
> Thanks
>
> Sample data follows:
>
>
> structure(list(id = 1:12, date = structure(c(9L, 6L, 11L, 8L,
> 7L, 5L, 4L, 3L, 12L, 1L, 10L, 2L), .Label = c("01feb2003", "03mar2008",
> "04feb2008", "07jul1991", "07jun2010", "13feb2005", "18dec1991",
> "22sep2005", "27apr1993", "29jan2009", "29may2002", "31jan2005"
> ), class = "factor"), case = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L)), .Names = c("id", "date", "case"), class =
> "data.frame", row.names = c(NA,
> -12L))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Thu Dec 11 17:40:33 2014
From: jholtman at gmail.com (jim holtman)
Date: Thu, 11 Dec 2014 11:40:33 -0500
Subject: [R] Create previous dates from date with consideration of leap
	year
In-Reply-To: <CAAC1QdBueBm2zz_8V-_ZK8ukRo8_kAhGPibF+uq8D-Ham+93Xw@mail.gmail.com>
References: <CAAC1QdBueBm2zz_8V-_ZK8ukRo8_kAhGPibF+uq8D-Ham+93Xw@mail.gmail.com>
Message-ID: <CAAxdm-65CbhDsb64okoTe94AqYGP7iZWyaiXCJuTgCXYfrqSFA@mail.gmail.com>

Here is an example of converting the 'date' your dataframe to 'time'
(POSIXct) and then taking the first 'time' and creating the 5 previous days
from that date:

   id      date case
1   1 27apr1993    1
2   2 13feb2005    1
3   3 29may2002    1
4   4 22sep2005    1
5   5 18dec1991    1
6   6 07jun2010    1
7   7 07jul1991    1
8   8 04feb2008    1
9   9 31jan2005    1
10 10 01feb2003    1
11 11 29jan2009    1
12 12 03mar2008    1
> ?strptime
> x$time <- as.POSIXct(x$date, format = "%d%b%Y")
> x
   id      date case       time
1   1 27apr1993    1 1993-04-27
2   2 13feb2005    1 2005-02-13
3   3 29may2002    1 2002-05-29
4   4 22sep2005    1 2005-09-22
5   5 18dec1991    1 1991-12-18
6   6 07jun2010    1 2010-06-07
7   7 07jul1991    1 1991-07-07
8   8 04feb2008    1 2008-02-04
9   9 31jan2005    1 2005-01-31
10 10 01feb2003    1 2003-02-01
11 11 29jan2009    1 2009-01-29
12 12 03mar2008    1 2008-03-03
> seq(x$time[1], by = '-1 day', length = 5)
[1] "1993-04-27 EDT" "1993-04-26 EDT" "1993-04-25 EDT" "1993-04-24 EDT"
"1993-04-23 EDT"
>

You can do the same thing for the dataframe:

> lapply(x$time, function(a) seq(a, by = '-1 day', length = 5))
[[1]]
[1] "1993-04-27 EDT" "1993-04-26 EDT" "1993-04-25 EDT" "1993-04-24 EDT"
"1993-04-23 EDT"

[[2]]
[1] "2005-02-13 EST" "2005-02-12 EST" "2005-02-11 EST" "2005-02-10 EST"
"2005-02-09 EST"

[[3]]
[1] "2002-05-29 EDT" "2002-05-28 EDT" "2002-05-27 EDT" "2002-05-26 EDT"
"2002-05-25 EDT"

[[4]]
[1] "2005-09-22 EDT" "2005-09-21 EDT" "2005-09-20 EDT" "2005-09-19 EDT"
"2005-09-18 EDT"
.......



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Dec 11, 2014 at 10:54 AM, Kuma Raj <pollaroid at gmail.com> wrote:

> Dear R Community,
>
> I wish to create 5 preceding dates from the date variable by ID. How
> could I create such dates? The code should consider leap year.
>
> Thanks
>
> Sample data follows:
>
>
> structure(list(id = 1:12, date = structure(c(9L, 6L, 11L, 8L,
> 7L, 5L, 4L, 3L, 12L, 1L, 10L, 2L), .Label = c("01feb2003", "03mar2008",
> "04feb2008", "07jul1991", "07jun2010", "13feb2005", "18dec1991",
> "22sep2005", "27apr1993", "29jan2009", "29may2002", "31jan2005"
> ), class = "factor"), case = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L)), .Names = c("id", "date", "case"), class =
> "data.frame", row.names = c(NA,
> -12L))
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From phaedrusv at gmail.com  Thu Dec 11 18:05:32 2014
From: phaedrusv at gmail.com (Sun Shine)
Date: Thu, 11 Dec 2014 17:05:32 +0000
Subject: [R] Working with data frames
In-Reply-To: <CAF8bMcbcr3hzPOCPDEebz-M+7VpuREFwN6DCBxyJed_15qgRJg@mail.gmail.com>
References: <54899554.10705@gmail.com>
	<CAF8bMcbcr3hzPOCPDEebz-M+7VpuREFwN6DCBxyJed_15qgRJg@mail.gmail.com>
Message-ID: <5489CEDC.3000505@gmail.com>

Hello William, Ivan and Jim

I appreciate your replies.

I did suppress the factors using stringsAsFactors=FALSE and in that way 
was able to progress some more on getting a sense of the data set, so 
thanks for that suggestion. I had previously overlooked it.

Also thanks William, I never understood what those thick line segs were 
- now I do. That had been about the best I could get by that point and 
still not with the names on the x axis.

Unfortunately using William's suggestion of 'with' gave me errors:

 > with(MHP.def, {plot(as.integer(MHP.def$Names),cH.E, axes=FALSE, 
xlab='Area') axis(side=2) axis(side=1, 
at=seq_along(levels(MHP.def$Names)), lab=levels(MHP.def$Names))})

Error: unexpected symbol in "with(MHP.def, 
{plot(as.integer(MHP.def$Names), MHP.def$cH.E, axes=FALSE, xlab='Area') 
axis"

This may have something to do with the period between cH and E or 
perhaps from the $ to access data from a column?

I have now installed ggplot2 and with the help of the graphics cookbook 
will see if I can make some headway like this, at least for now. I think 
William's suggestion about learning to work with factors is 
fundamentally sound and something I will need to get my head around. For 
now though, I think I'll stick to exploring ggplot2 so that I can 
visualise this data set more easily.

Thanks again.

Best

Sun

On 11/12/14 16:06, William Dunlap wrote:
> Here is a reproducible example
>   > d <- read.csv(text="Name,Age\nBob,2\nXavier,25\nAdam,1")
>   > str(d)
>   'data.frame':   3 obs. of  2 variables:
>    $ Name: Factor w/ 3 levels "Adam","Bob","Xavier": 2 3 1
>    $ Age : int  2 25 1
>
> Do you get something similar?  If not, show us what you have (you
> could trim it down to a few columns).
>
> Let's try some plots.
>     > plot(d$Age)
> This shows a plot of d$Age (on y axis) vs "Index", where Index is
> 1:length(d$Age).  The points are at (1,2), (2,25), and (3,1). You gave
> plot() no information about what should be on the x axis so it gave
> you the index numbers.
>
> Now asking for d$Name on the x axis and d$Age on the y.
>     > plot(d$Name, d$Age)
> This put the names, in alphabetical order on the x axis. The y axis
> ranges from about 0 to 25 and neither axis is labelled. There are
> thick horizontal line segments where you expect the the points to
> be.  These are degenerate boxplots - when you ask to plot a
> 'factor' variable on the x axis and numbers on the y you get such
> a plot.
>
> Some folks suggested you avoid factors by adding stringsAsFactors=FALSE
> (or as.is <http://as.is>=TRUE) to your call to read.csv.  Let's try that
>   > d2 <- read.csv(stringsAsFactors=FALSE,
>         text="Name,Age\nBob,2\nXavier,25\nAdam,1")
>   > plot(d2$Name, d2$Age)
>   Error in plot.window(...) : need finite 'xlim' values
>   In addition: Warning messages:
>   1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
>   2: In min(x) : no non-missing arguments to min; returning Inf
>   3: In max(x) : no non-missing arguments to max; returning -Inf
> You get no plot at all.
>
> You can get closer to what I think you want with
>   with(d, {
>     plot(as.integer(Name), Age, axes=FALSE, xlab="Name")
>     axis(side=2) # draw the usual y axis
>     axis(side=1, at=seq_along(levels(Name)), lab=levels(Name))
>   })
> If you want the names in a different order on the x axis, then reconstruct
> the factor object d$Name with a different order of levels.  E.g.,
>   d$Name <- factor(d$Name, levels=c("Xavier", "Bob", "Adam"))
> and replot.
>
> There are various plotting packages, e.g., ggplot2, that can make this
> sort of thing easier, but I think the recommendation not to use factors
> is wrong.  You do need to learn how to use them to your advantage.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Thu, Dec 11, 2014 at 5:00 AM, Sun Shine <phaedrusv at gmail.com 
> <mailto:phaedrusv at gmail.com>> wrote:
>
>     Hello
>
>     I am struggling with data frames and would appreciate some help
>     please.
>
>     I have a data set of 13 observations and 80 variables. The first
>     column is the names of different political area boundaries (e.g.
>     MHad, LBNW, etc), the first row is a vector of variable names
>     concerning various census data (e.g. age.T, hse.Unk, etc.). The
>     first cell [1,1] is blank.
>
>     I have loaded this via read.csv('path.to/data.set.csv'
>     <http://path.to/data.set.csv%27>), and now want to run some
>     analyses on this data frame. If I want to get a list of the names
>     of the political areas (i.e. the first column), the result is a
>     vector of numbers which appear to correlate with the factors, but
>     I don't get the text names, just the corresponding number. So, if
>     I want to plot something basic, like the area that uses the most
>     gas for central heating, for example:
>
>     > plot(data.set$ch.Gas)
>
>     The result is the y-axis gives the gas usage for the areas, but
>     the x-axis gives only the numbers of the areas, not the names of
>     the areas (which is preferred).
>
>     So, two questions:
>
>     (1) have I set up my csv file correctly to be read as a data frame
>     as the first row of all of the remaining columns with the values
>     for that political area in the corresponding row in the column
>     with the specific variable name? So far, looking through tutorials
>     and books seems to suggest yes, but at this point I'm no longer sure.
>
>     (2) How can I access the names of the political areas when
>     plotting so that these are given on the x-axis instead of the numbers?
>
>     Thanks for any help.
>
>     Cheers
>     Sun
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Dec 11 18:55:36 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 11 Dec 2014 09:55:36 -0800
Subject: [R] Working with data frames
In-Reply-To: <5489CEDC.3000505@gmail.com>
References: <54899554.10705@gmail.com>
	<CAF8bMcbcr3hzPOCPDEebz-M+7VpuREFwN6DCBxyJed_15qgRJg@mail.gmail.com>
	<5489CEDC.3000505@gmail.com>
Message-ID: <1A110256-0BBA-46F2-91D0-57889F2C51D3@dcn.davis.CA.us>

Ggplot2 also depends on factors, so learn about them asap. It does have some support for automatically converting strings to factors in some cases, but it doesn't always work the way you want it to.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 11, 2014 9:05:32 AM PST, Sun Shine <phaedrusv at gmail.com> wrote:
>Hello William, Ivan and Jim
>
>I appreciate your replies.
>
>I did suppress the factors using stringsAsFactors=FALSE and in that way
>
>was able to progress some more on getting a sense of the data set, so 
>thanks for that suggestion. I had previously overlooked it.
>
>Also thanks William, I never understood what those thick line segs were
>
>- now I do. That had been about the best I could get by that point and 
>still not with the names on the x axis.
>
>Unfortunately using William's suggestion of 'with' gave me errors:
>
> > with(MHP.def, {plot(as.integer(MHP.def$Names),cH.E, axes=FALSE, 
>xlab='Area') axis(side=2) axis(side=1, 
>at=seq_along(levels(MHP.def$Names)), lab=levels(MHP.def$Names))})
>
>Error: unexpected symbol in "with(MHP.def, 
>{plot(as.integer(MHP.def$Names), MHP.def$cH.E, axes=FALSE, xlab='Area')
>
>axis"
>
>This may have something to do with the period between cH and E or 
>perhaps from the $ to access data from a column?
>
>I have now installed ggplot2 and with the help of the graphics cookbook
>
>will see if I can make some headway like this, at least for now. I
>think 
>William's suggestion about learning to work with factors is 
>fundamentally sound and something I will need to get my head around.
>For 
>now though, I think I'll stick to exploring ggplot2 so that I can 
>visualise this data set more easily.
>
>Thanks again.
>
>Best
>
>Sun
>
>On 11/12/14 16:06, William Dunlap wrote:
>> Here is a reproducible example
>>   > d <- read.csv(text="Name,Age\nBob,2\nXavier,25\nAdam,1")
>>   > str(d)
>>   'data.frame':   3 obs. of  2 variables:
>>    $ Name: Factor w/ 3 levels "Adam","Bob","Xavier": 2 3 1
>>    $ Age : int  2 25 1
>>
>> Do you get something similar?  If not, show us what you have (you
>> could trim it down to a few columns).
>>
>> Let's try some plots.
>>     > plot(d$Age)
>> This shows a plot of d$Age (on y axis) vs "Index", where Index is
>> 1:length(d$Age).  The points are at (1,2), (2,25), and (3,1). You
>gave
>> plot() no information about what should be on the x axis so it gave
>> you the index numbers.
>>
>> Now asking for d$Name on the x axis and d$Age on the y.
>>     > plot(d$Name, d$Age)
>> This put the names, in alphabetical order on the x axis. The y axis
>> ranges from about 0 to 25 and neither axis is labelled. There are
>> thick horizontal line segments where you expect the the points to
>> be.  These are degenerate boxplots - when you ask to plot a
>> 'factor' variable on the x axis and numbers on the y you get such
>> a plot.
>>
>> Some folks suggested you avoid factors by adding
>stringsAsFactors=FALSE
>> (or as.is <http://as.is>=TRUE) to your call to read.csv.  Let's try
>that
>>   > d2 <- read.csv(stringsAsFactors=FALSE,
>>         text="Name,Age\nBob,2\nXavier,25\nAdam,1")
>>   > plot(d2$Name, d2$Age)
>>   Error in plot.window(...) : need finite 'xlim' values
>>   In addition: Warning messages:
>>   1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by
>coercion
>>   2: In min(x) : no non-missing arguments to min; returning Inf
>>   3: In max(x) : no non-missing arguments to max; returning -Inf
>> You get no plot at all.
>>
>> You can get closer to what I think you want with
>>   with(d, {
>>     plot(as.integer(Name), Age, axes=FALSE, xlab="Name")
>>     axis(side=2) # draw the usual y axis
>>     axis(side=1, at=seq_along(levels(Name)), lab=levels(Name))
>>   })
>> If you want the names in a different order on the x axis, then
>reconstruct
>> the factor object d$Name with a different order of levels.  E.g.,
>>   d$Name <- factor(d$Name, levels=c("Xavier", "Bob", "Adam"))
>> and replot.
>>
>> There are various plotting packages, e.g., ggplot2, that can make
>this
>> sort of thing easier, but I think the recommendation not to use
>factors
>> is wrong.  You do need to learn how to use them to your advantage.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>>
>> On Thu, Dec 11, 2014 at 5:00 AM, Sun Shine <phaedrusv at gmail.com 
>> <mailto:phaedrusv at gmail.com>> wrote:
>>
>>     Hello
>>
>>     I am struggling with data frames and would appreciate some help
>>     please.
>>
>>     I have a data set of 13 observations and 80 variables. The first
>>     column is the names of different political area boundaries (e.g.
>>     MHad, LBNW, etc), the first row is a vector of variable names
>>     concerning various census data (e.g. age.T, hse.Unk, etc.). The
>>     first cell [1,1] is blank.
>>
>>     I have loaded this via read.csv('path.to/data.set.csv'
>>     <http://path.to/data.set.csv%27>), and now want to run some
>>     analyses on this data frame. If I want to get a list of the names
>>     of the political areas (i.e. the first column), the result is a
>>     vector of numbers which appear to correlate with the factors, but
>>     I don't get the text names, just the corresponding number. So, if
>>     I want to plot something basic, like the area that uses the most
>>     gas for central heating, for example:
>>
>>     > plot(data.set$ch.Gas)
>>
>>     The result is the y-axis gives the gas usage for the areas, but
>>     the x-axis gives only the numbers of the areas, not the names of
>>     the areas (which is preferred).
>>
>>     So, two questions:
>>
>>     (1) have I set up my csv file correctly to be read as a data
>frame
>>     as the first row of all of the remaining columns with the values
>>     for that political area in the corresponding row in the column
>>     with the specific variable name? So far, looking through
>tutorials
>>     and books seems to suggest yes, but at this point I'm no longer
>sure.
>>
>>     (2) How can I access the names of the political areas when
>>     plotting so that these are given on the x-axis instead of the
>numbers?
>>
>>     Thanks for any help.
>>
>>     Cheers
>>     Sun
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>--
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible
>code.
>>
>>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Dec 11 18:58:04 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 11 Dec 2014 09:58:04 -0800
Subject: [R] Working with data frames
In-Reply-To: <5489CEDC.3000505@gmail.com>
References: <54899554.10705@gmail.com>
	<CAF8bMcbcr3hzPOCPDEebz-M+7VpuREFwN6DCBxyJed_15qgRJg@mail.gmail.com>
	<5489CEDC.3000505@gmail.com>
Message-ID: <CAF8bMcY_VfjuYahH2V6oONffSQTB0vsVCph+HFcByvszD1Uowg@mail.gmail.com>

Sun Shine wrote
> with(MHP.def, {plot(as.integer(MHP.def$Names),cH.E, axes=FALSE,
xlab='Area') axis(side=2) axis(side=1, at=seq_along(levels(MHP.def$Names)),
lab=levels(MHP.def$Names))})

Error: unexpected symbol in "with(MHP.def, {plot(as.integer(MHP.def$Names),
MHP.def$cH.E, axes=FALSE, xlab='Area') axis"

This may have something to do with the period between cH and E or perhaps
from the $ to access data from a column?

--> When you see a syntax error message the error is usually towards the
end of the quoted text.  In your case, you are missing a newline or
semicolon between "'Area')" and the subsequent "axis".



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Dec 11, 2014 at 9:05 AM, Sun Shine <phaedrusv at gmail.com> wrote:

>  Hello William, Ivan and Jim
>
> I appreciate your replies.
>
> I did suppress the factors using stringsAsFactors=FALSE and in that way
> was able to progress some more on getting a sense of the data set, so
> thanks for that suggestion. I had previously overlooked it.
>
> Also thanks William, I never understood what those thick line segs were -
> now I do. That had been about the best I could get by that point and still
> not with the names on the x axis.
>
> Unfortunately using William's suggestion of 'with' gave me errors:
>
> > with(MHP.def, {plot(as.integer(MHP.def$Names),cH.E, axes=FALSE,
> xlab='Area') axis(side=2) axis(side=1, at=seq_along(levels(MHP.def$Names)),
> lab=levels(MHP.def$Names))})
>
> Error: unexpected symbol in "with(MHP.def,
> {plot(as.integer(MHP.def$Names), MHP.def$cH.E, axes=FALSE, xlab='Area')
> axis"
>
> This may have something to do with the period between cH and E or perhaps
> from the $ to access data from a column?
>
> I have now installed ggplot2 and with the help of the graphics cookbook
> will see if I can make some headway like this, at least for now. I think
> William's suggestion about learning to work with factors is fundamentally
> sound and something I will need to get my head around. For now though, I
> think I'll stick to exploring ggplot2 so that I can visualise this data set
> more easily.
>
> Thanks again.
>
> Best
>
> Sun
>
>
> On 11/12/14 16:06, William Dunlap wrote:
>
> Here is a reproducible example
>   > d <- read.csv(text="Name,Age\nBob,2\nXavier,25\nAdam,1")
>   > str(d)
>   'data.frame':   3 obs. of  2 variables:
>    $ Name: Factor w/ 3 levels "Adam","Bob","Xavier": 2 3 1
>    $ Age : int  2 25 1
>
>  Do you get something similar?  If not, show us what you have (you
> could trim it down to a few columns).
>
>  Let's try some plots.
>     > plot(d$Age)
> This shows a plot of d$Age (on y axis) vs "Index", where Index is
> 1:length(d$Age).  The points are at (1,2), (2,25), and (3,1). You gave
> plot() no information about what should be on the x axis so it gave
> you the index numbers.
>
>  Now asking for d$Name on the x axis and d$Age on the y.
>     > plot(d$Name, d$Age)
> This put the names, in alphabetical order on the x axis.  The y axis
> ranges from about 0 to 25 and neither axis is labelled.  There are
> thick horizontal line segments where you expect the the points to
> be.  These are degenerate boxplots - when you ask to plot a
> 'factor' variable on the x axis and numbers on the y you get such
> a plot.
>
>  Some folks suggested you avoid factors by adding stringsAsFactors=FALSE
> (or as.is=TRUE) to your call to read.csv.  Let's try that
>   > d2 <- read.csv(stringsAsFactors=FALSE,
>         text="Name,Age\nBob,2\nXavier,25\nAdam,1")
>    > plot(d2$Name, d2$Age)
>   Error in plot.window(...) : need finite 'xlim' values
>   In addition: Warning messages:
>   1: In xy.coords(x, y, xlabel, ylabel, log) : NAs introduced by coercion
>   2: In min(x) : no non-missing arguments to min; returning Inf
>   3: In max(x) : no non-missing arguments to max; returning -Inf
> You get no plot at all.
>
>  You can get closer to what I think you want with
>   with(d, {
>     plot(as.integer(Name), Age, axes=FALSE, xlab="Name")
>     axis(side=2) # draw the usual y axis
>     axis(side=1, at=seq_along(levels(Name)), lab=levels(Name))
>   })
> If you want the names in a different order on the x axis, then reconstruct
> the factor object d$Name with a different order of levels.  E.g.,
>   d$Name <- factor(d$Name, levels=c("Xavier", "Bob", "Adam"))
> and replot.
>
>  There are various plotting packages, e.g., ggplot2, that can make this
> sort of thing easier, but I think the recommendation not to use factors
> is wrong.  You do need to learn how to use them to your advantage.
>
>  Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Dec 11, 2014 at 5:00 AM, Sun Shine <phaedrusv at gmail.com> wrote:
>
>> Hello
>>
>> I am struggling with data frames and would appreciate some help please.
>>
>> I have a data set of 13 observations and 80 variables. The first column
>> is the names of different political area boundaries (e.g. MHad, LBNW, etc),
>> the first row is a vector of variable names concerning various census data
>> (e.g. age.T, hse.Unk, etc.). The first cell [1,1] is blank.
>>
>> I have loaded this via read.csv('path.to/data.set.csv'
>> <http://path.to/data.set.csv%27>), and now want to run some analyses on
>> this data frame. If I want to get a list of the names of the political
>> areas (i.e. the first column), the result is a vector of numbers which
>> appear to correlate with the factors, but I don't get the text names, just
>> the corresponding number. So, if I want to plot something basic, like the
>> area that uses the most gas for central heating, for example:
>>
>> > plot(data.set$ch.Gas)
>>
>> The result is the y-axis gives the gas usage for the areas, but the
>> x-axis gives only the numbers of the areas, not the names of the areas
>> (which is preferred).
>>
>> So, two questions:
>>
>> (1) have I set up my csv file correctly to be read as a data frame as the
>> first row of all of the remaining columns with the values for that
>> political area in the corresponding row in the column with the specific
>> variable name? So far, looking through tutorials and books seems to suggest
>> yes, but at this point I'm no longer sure.
>>
>> (2) How can I access the names of the political areas when plotting so
>> that these are given on the x-axis instead of the numbers?
>>
>> Thanks for any help.
>>
>> Cheers
>> Sun
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

	[[alternative HTML version deleted]]


From r_vardavas at hotmail.com  Thu Dec 11 21:22:08 2014
From: r_vardavas at hotmail.com (Raffaello Vardavas)
Date: Thu, 11 Dec 2014 12:22:08 -0800
Subject: [R] NA problem in rbind of an apply summary
In-Reply-To: <CALJKBv92ngBTGbXs05hXHu5VVY0ViXqum8FgCRkd+SxPtLFzEA@mail.gmail.com>
References: <DUB127-W59B1304583EC917348F528E6620@phx.gbl>
	<CALJKBv92ngBTGbXs05hXHu5VVY0ViXqum8FgCRkd+SxPtLFzEA@mail.gmail.com>
Message-ID: <DUB407-EAS206AD60939AD26983CD9A47E6630@phx.gbl>

Thank you Karim,
I'll try that.
Thanks!
Raff 

Sent from my iPhone

> On Dec 10, 2014, at 1:48 PM, "Karim Mezhoud" <kmezhoud at gmail.com> wrote:
> 
> Hi,
> Could you try  rbind.na.R function.
> karim
> 
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
> 
> 
> 
>> On Wed, Dec 10, 2014 at 10:34 PM, Raffaello Vardavas <r_vardavas at hotmail.com> wrote:
>> Dear All,
>> 
>> I have a data fame. Each column has numerical values but some columns may have NA values.
>> I'd like a table showing the summary statistics for each column. This is what I do:
>> 
>> I first do the following:
>> 
>> apply(df[,metrics],2,summary,na.rm=T)
>> 
>> giving:
>> 
>> $degree
>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>     0.0   261.9   489.3   500.6   698.5  1551.0
>> 
>> $EV.centrality
>>      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
>> 0.0000000 0.0001067 0.0006391 0.0057460 0.0020410 1.0000000
>> 
>> $betweenness
>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>     0.0     0.0   150.5  2955.0  2208.0 60940.0
>> 
>> $knn
>>    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's
>>    2.00   21.50   32.44   36.75   46.15  224.50      26
>> 
>> 
>> Then I rbind them and get:
>> 
>> do.call("rbind",apply(df[,metrics],2,summary,na.rm=T))
>> 
>>                             Min.   1st Qu.    Median      Mean   3rd Qu.    Max. NA's
>> degree                         0 2.619e+02 4.893e+02 5.006e+02 6.985e+02  1551.0    0
>> EV.centrality                  0 1.067e-04 6.391e-04 5.746e-03 2.041e-03     1.0    0
>> betweenness                    0 0.000e+00 1.505e+02 2.955e+03 2.208e+03 60940.0    0
>> knn                            2 2.150e+01 3.244e+01 3.675e+01 4.615e+01   224.5   26
>> 
>> Since the first 3 rows don't have NA's but the 4th has I get the following warning:
>> 
>> Warning message:
>> In rbind(degree = c(0, 261.9, 489.3, 500.6, 698.5, 1551), EV.centrality = c(0,  :
>>   number of columns of result is not a multiple of vector length (arg 1)
>> Calls: do.call -> rbind
>> 
>> 
>> How do I code this in a way to avoid this warning?
>> 
>> Thanks.
>> 
>> Raff
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> <rbind.na.R>

	[[alternative HTML version deleted]]


From bortman at atwell-group.com  Thu Dec 11 20:16:44 2014
From: bortman at atwell-group.com (Brian Ortman)
Date: Thu, 11 Dec 2014 14:16:44 -0500
Subject: [R] Unmarked
Message-ID: <49F43DE1487B8B47919BBD08100AF0820B76AE1F@aaexch975.atwell-hicks.com>

I am trying to write a script to run occupancy analysis for very large
sets of data for multiple species. I have in the past used PRESENCE but
would like to use R. I am having trouble getting the ObsCov into the
data frame. I get the following error message:

 

data1=unmarkedFrameOccu(y=y,siteCovs=siC,obsCov=suC)

 

Error in validObject(.Object) : 

invalid class "unmarkedFrame" object: obsCovData does not have M*obsNum
rows

 

Lastly, I have multiple species in each data set (some as many as 128).
Can i put all species in one unmarkedFrameOccu then call out a species
as I need it or do i need a separate unmarkedFrameOccu for each species?

 

Thanks

-Brian

 

Brian Ortman
Quantitative Ecologist/Avian Specialist
ATWELL, LLC
440.349.2000 Tel
334.524.7334 Mobile
440.349.2028 Fax
7100 E. Pleasant Valley Rd. | Suite 220 | Independence, OH 44131
www.atwell-group.com <http://www.atwell-group.com/> 
Local Solutions | National Presence 
  




Confidential Notice: This is a confidential communication. If you received in error, please notify the sender of the delivery error by replying to this message and then delete it from your system.
Electronic Data: Since data stored on electronic media can deteriorate, be translated or modified, Atwell, LLC will not be liable for the completeness, correctness or readability of the electronic data. The electronic data should be checked against the hard copy (paper, mylar, etc.). Hard copies are on file with Atwell and can be provided upon request.

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Thu Dec 11 21:33:00 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 11 Dec 2014 12:33:00 -0800
Subject: [R] Unmarked
In-Reply-To: <49F43DE1487B8B47919BBD08100AF0820B76AE1F@aaexch975.atwell-hicks.com>
References: <49F43DE1487B8B47919BBD08100AF0820B76AE1F@aaexch975.atwell-hicks.com>
Message-ID: <CACk-te2YDJfmZahzj_=DhUK7DJ7UJPoAEDPg4qKz8DJpNPEbnQ@mail.gmail.com>

Your query is incoherent,  at least to me. If others are similarly
flummoxed and you receive no useful reply, read and follow the posting
guide (link below) to provide code, data, etc. for a minimal example
to explain what you wish to do. In PLAIN TEXT -- no HTML.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Dec 11, 2014 at 11:16 AM, Brian Ortman <bortman at atwell-group.com> wrote:
> I am trying to write a script to run occupancy analysis for very large
> sets of data for multiple species. I have in the past used PRESENCE but
> would like to use R. I am having trouble getting the ObsCov into the
> data frame. I get the following error message:
>
>
>
> data1=unmarkedFrameOccu(y=y,siteCovs=siC,obsCov=suC)
>
>
>
> Error in validObject(.Object) :
>
> invalid class "unmarkedFrame" object: obsCovData does not have M*obsNum
> rows
>
>
>
> Lastly, I have multiple species in each data set (some as many as 128).
> Can i put all species in one unmarkedFrameOccu then call out a species
> as I need it or do i need a separate unmarkedFrameOccu for each species?
>
>
>
> Thanks
>
> -Brian
>
>
>
> Brian Ortman
> Quantitative Ecologist/Avian Specialist
> ATWELL, LLC
> 440.349.2000 Tel
> 334.524.7334 Mobile
> 440.349.2028 Fax
> 7100 E. Pleasant Valley Rd. | Suite 220 | Independence, OH 44131
> www.atwell-group.com <http://www.atwell-group.com/>
> Local Solutions | National Presence
>
>
>
>
>
> Confidential Notice: This is a confidential communication. If you received in error, please notify the sender of the delivery error by replying to this message and then delete it from your system.
> Electronic Data: Since data stored on electronic media can deteriorate, be translated or modified, Atwell, LLC will not be liable for the completeness, correctness or readability of the electronic data. The electronic data should be checked against the hard copy (paper, mylar, etc.). Hard copies are on file with Atwell and can be provided upon request.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From munevver.rock at gmail.com  Thu Dec 11 21:47:17 2014
From: munevver.rock at gmail.com (munevver kaya)
Date: Thu, 11 Dec 2014 22:47:17 +0200
Subject: [R] DIF
In-Reply-To: <4f64d4e3-2668-4f31-b08a-e61bf8ffe9a8@googlegroups.com>
References: <CAKM1wmX=HJ0PxkWgxzz3x3AfFMkRqauCoCOnCMa3M+-jgeg7Ng@mail.gmail.com>
	<CAGx1TMD-KwKjHUfxNssp__FU6o5_oiWHqX=Od=VnWmLXzbo+bQ@mail.gmail.com>
	<alpine.DEB.2.11.1412092232200.9272@paninaro.uibk.ac.at>
	<CAKM1wmUAsvtL4CqgRbTwPHvH2t_X8QG0MDxBNFEwekG13MBUTQ@mail.gmail.com>
	<4f64d4e3-2668-4f31-b08a-e61bf8ffe9a8@googlegroups.com>
Message-ID: <CAKM1wmW-V5A29JXpOtN5mFuv+QZ7Hy7tY4_7Rfu9c=EP0asDmA@mail.gmail.com>

Thank you so much Phil,
I will try that.
Best

On Wed, Dec 10, 2014 at 9:42 PM, Phil Chalmers <rphilip.chalmers at gmail.com>
wrote:

> As well, the mirt package contains a function for DIF using likelihood
> ratio tests via multiple-group estimation methods (the multiple group
> estimation generally goes beyond simply testing for DIF), as well Wald
> tests if the information matrix was computed. Hope that helps.
>
> Phil
>
> On Wednesday, December 10, 2014 2:20:51 PM UTC-5, munevver kaya wrote:
>>
>> Thanks, Achim and Richard,
>> I will take into consideration your solutions.
>> Best,
>>
>> On Tue, Dec 9, 2014 at 11:36 PM, Achim Zeileis <Achim.... at uibk.ac.at>
>> wrote:
>>
>> > On Tue, 9 Dec 2014, Richard M. Heiberger wrote:
>> >
>> >  I recommend the likert() function in the HH package.
>> >>
>> >> install.packages("HH")
>> >> library(HH)
>> >> ?likert
>> >>
>> >
>> > I think this only visualizes the polytomous items but provides no
>> formal
>> > inference for IRT modeling and DIF testing.
>> >
>> > For fitting polytomous IRT models (PCM, RSM, etc.) there are various R
>> > packages available, probably most prominently the "eRm" package. This
>> also
>> > includes several tests for DIF. But many other approaches are also
>> > available (including the "lordif" package). A good first overview is
>> given
>> > in the Psychometrics task view on CRAN, see: http://CRAN.R-project.org/
>> > view=Psychometrics
>> >
>> > hth,
>> >
>> > Z
>> >
>> >
>> >>
>> >> On Tue, Dec 9, 2014 at 3:22 AM, munevver kaya <munevv... at gmail.com>
>> >> wrote:
>> >>
>> >>> Hello,
>> >>> I will analyze polytomous differential item functioning for IRT. I
>> have a
>> >>> Likert type scale. For example, I want to analyze items in term of
>> >>> gender.
>> >>> Is lordifsufficient for this or are there any other packages in R
>> >>> programme?
>> >>> Best Regards,
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> >>> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>
>> >> ______________________________________________
>> >> R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-h... at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From kathryn.lord2000 at gmail.com  Fri Dec 12 01:38:20 2014
From: kathryn.lord2000 at gmail.com (Kathryn Lord)
Date: Fri, 12 Dec 2014 09:38:20 +0900
Subject: [R] make matrices as many as possible with a constraint
Message-ID: <CAMFx86wGO1tgckg1hSrmNTYL9B4D-JcNo5o98eYfDbYxcVBuVg@mail.gmail.com>

Dear R users,

I'd like to make 4 by 7 matrices as many as possible with natural numbers 1
through 28 such that each matrix have different elements of each column.

For example,

simply here is one

> a1 <- matrix(1:28, 4,7)
> a1
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]    1    5    9   13   17   21   25
[2,]    2    6   10   14   18   22   26
[3,]    3    7   11   15   19   23   27
[4,]    4    8   12   16   20   24   28

another one

> a2 <- matrix(1:28, 4,7, byrow=T)
> a2
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]    1    2    3    4    5    6    7
[2,]    8    9   10   11   12   13   14
[3,]   15   16   17   18   19   20   21
[4,]   22   23   24   25   26   27   28

Matrices a1 and a2 have different columns, and I guess there are such many
matrices.

Any suggestion will be greatly appreciated.

Best,

Kathryn Lord

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec 12 02:13:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Dec 2014 17:13:56 -0800
Subject: [R] make matrices as many as possible with a constraint
In-Reply-To: <CAMFx86wGO1tgckg1hSrmNTYL9B4D-JcNo5o98eYfDbYxcVBuVg@mail.gmail.com>
References: <CAMFx86wGO1tgckg1hSrmNTYL9B4D-JcNo5o98eYfDbYxcVBuVg@mail.gmail.com>
Message-ID: <A99677DA-B78A-4CA8-BF7A-0D8D1B0982AE@comcast.net>


On Dec 11, 2014, at 4:38 PM, Kathryn Lord wrote:

> Dear R users,
> 
> I'd like to make 4 by 7 matrices as many as possible with natural numbers 1
> through 28 such that each matrix have different elements of each column.

I was tempted to respond:

We're very sorry. The Soduko Challenge Contest was closed several years ago.

> 
> For example,
> 
> simply here is one
> 
>> a1 <- matrix(1:28, 4,7)
>> a1
>     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    5    9   13   17   21   25
> [2,]    2    6   10   14   18   22   26
> [3,]    3    7   11   15   19   23   27
> [4,]    4    8   12   16   20   24   28
> 
> another one
> 
>> a2 <- matrix(1:28, 4,7, byrow=T)
>> a2
>     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    2    3    4    5    6    7
> [2,]    8    9   10   11   12   13   14
> [3,]   15   16   17   18   19   20   21
> [4,]   22   23   24   25   26   27   28

What about: 

replicate(1000, list(matrix(sample(28), 4,7) ) )

Somebody ( but not me) will probably know the probability that "each matrix has different elements of each column" once you explain exactly what that phrase means to you. At the moment its not clear if a permutation of columns makes a matrix "different".

> 
> Matrices a1 and a2 have different columns, and I guess there are such many
> matrices.
> 
> Any suggestion will be greatly appreciated.
> 
> Best,
> 
> Kathryn Lord
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marius.hofert at uwaterloo.ca  Fri Dec 12 04:38:20 2014
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Thu, 11 Dec 2014 22:38:20 -0500
Subject: [R] Is there a plotmath symbol \mapsto?
Message-ID: <CAM3-KjY=NimMOM24Y77usbwyxEWBr=ocXNhX5hiQGhWeXf2EpA@mail.gmail.com>

Hi,

Is there a plotmath symbol like LaTeX's \mapsto?
I need this comparably often, for example if you want to plot a
two-place function in one variable (and thus would like to have
ylab="t \mapsto f(t,s)", for example). If there is such a symbol, I'd
be great to have it as an example on ?plotmath.

Thanks & cheers,

Marius


From celine_jouanin at yahoo.fr  Fri Dec 12 10:15:39 2014
From: celine_jouanin at yahoo.fr (Jouanin Celine)
Date: Fri, 12 Dec 2014 09:15:39 +0000 (UTC)
Subject: [R] x axis position and ggplot2
In-Reply-To: <000601d014e5$d4142260$7c3c6720$@bigpond.com>
References: <000601d014e5$d4142260$7c3c6720$@bigpond.com>
Message-ID: <1283050411.3983845.1418375739985.JavaMail.yahoo@jws11148.mail.ir2.yahoo.com>

Hi,
Thank you for your answer, I thought we could used something like the "axis" function ( axis(side=3,...)) in ggplot2. 
I didn't find something like this in ggplot and I'm a bite surprised this doesn't exist. 
Sometimes we need to use lattice, grid -thank you Duncan for your help, or ggplot or other package, depending on what we want to show and the type of plot. Anyway, as I really need to use the ggplot package, I suppose that I'll plot my data without the axis on the top.Have a nice day,

C?line
     De?: Duncan Mackay <dulcalma at bigpond.com>
 ??: R <r-help at r-project.org>; 'Jouanin Celine' <celine_jouanin at yahoo.fr> 
 Envoy? le : Jeudi 11 d?cembre 2014 2h57
 Objet?: RE: [R] x axis position and ggplot2
   
Hi 

I do not know ggplot2 well enough to give any advice but as Geff has mention lattice see

http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17666.html

library(grid)
myXlabGrob <-
function(...){ ## ...is lab1, lab2, etc

? # you can add arguments to textGrob for more control? in the next line
? labs <- lapply(list(...), textGrob)
? nlabs <- length(labs)

? lab.heights <-
? lapply(labs, function(lab) unit(1, "grobheight", data = list(lab)))

? lab.layout <-
? grid.layout(ncol = nlabs, nrow = 1,
? ? ? ? ? ? ? ? ? heights = do.call(max, lab.heights),
? ? ? ? ? ? ? ? ? widths = unit(1, "null"),
? ? ? ? ? ? ? ? ? respect = TRUE)

? lab.gf <- frameGrob(layout = lab.layout)

? for (i in seq_len(nlabs)){
? ? lab.gf <- placeGrob(lab.gf, labs[[i]], row = 1, col = i)
? }
? lab.gf
}

xyplot(1:10 ~ 1:10,
? ? ? ? scales = list(x = list(alternating = 2)), # puts scale on the top rather than the bottom
? ? ? ? xlab = "", # removes label at bottom
? ? ? ? xlab.top = myXlabGrob('B')
? ? ? ? )

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jouanin Celine
Sent: Thursday, 11 December 2014 02:44
To: r-help at r-project.org
Subject: [R] x axis position and ggplot2

Hi all,
Is it possible to change the position of the x axis to have it at the top of the plot when we use the ggplot function ?Thanks for your help,C?line

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From therneau at mayo.edu  Fri Dec 12 14:05:45 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 12 Dec 2014 07:05:45 -0600
Subject: [R] How to pass a nested random effect with frailty in coxph()
In-Reply-To: <mailman.1.1418382001.9918.r-help@r-project.org>
References: <mailman.1.1418382001.9918.r-help@r-project.org>
Message-ID: <31062c$9f7tj0@ironport10.mayo.edu>

Use the coxme funtion (package coxme), which has the same syntax as lme4.
The frailty() function in coxph only handles the simple case of a random intercept.

Terry Therneau


On 12/12/2014 05:00 AM, r-help-request at r-project.org wrote:
> Hi,
> I have a very simple Cox regression model in which I need to include a
> nested random effect: individual nested in treatment. I know how to pass a
> single random effect - e.g. frailty(id)- but how can I specify the nested
> random (id nested in treatment) effect using frailty?
> The equivalent in lme4 would be (treatment|id)
>
> Thanks!
>
> David


From ripley at stats.ox.ac.uk  Fri Dec 12 14:32:01 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Dec 2014 13:32:01 +0000
Subject: [R] Is there a plotmath symbol \mapsto?
In-Reply-To: <CAM3-KjY=NimMOM24Y77usbwyxEWBr=ocXNhX5hiQGhWeXf2EpA@mail.gmail.com>
References: <CAM3-KjY=NimMOM24Y77usbwyxEWBr=ocXNhX5hiQGhWeXf2EpA@mail.gmail.com>
Message-ID: <548AEE51.3030703@stats.ox.ac.uk>

The only symbols plotmath has access to are those in the Adobe Symbol 
encoding.  You can display all of those using the example at the bottom 
of ?points, as ?plotmath did tell you.  (So it was a rather rich asking 
for an example.)

It also tells you that on some devices/platforms you can use Unicode 
escapes.

Now TeX (not LaTeX) does not define exactly which glyph \mapsto should 
output, but Unicode \u21A6 is often called 'mapsto' (how Unicode glyphs 
are rendered is font-specific, of course).  That works for me with 
cairo-based devices on Linux; however on my Mac that glyph is not in the 
standard fonts for Quartz-based devices.


On 12/12/2014 03:38, Marius Hofert wrote:
> Hi,
>
> Is there a plotmath symbol like LaTeX's \mapsto?
> I need this comparably often, for example if you want to plot a
> two-place function in one variable (and thus would like to have
> ylab="t \mapsto f(t,s)", for example). If there is such a symbol, I'd
> be great to have it as an example on ?plotmath.
>
> Thanks & cheers,
>
> Marius


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From celine_jouanin at yahoo.fr  Fri Dec 12 11:02:27 2014
From: celine_jouanin at yahoo.fr (Jouanin Celine)
Date: Fri, 12 Dec 2014 10:02:27 +0000 (UTC)
Subject: [R] R and tcltk, problem to get the value entered
Message-ID: <763981550.4796239.1418378547772.JavaMail.yahoo@jws11157.mail.ir2.yahoo.com>

Hi dear R list,
I would like to create a graphical user interface with tcltk.I want to have a window where the user will enter a numeric, this will open a message box with his value. This works, but I don't succeed to get the value x, to use it after in a script in the R console. The x variable doesn't give me the value chosen by the user but returns the initial value "12".How can I do it ? Does exist an another function in tcltk that I need to use ?Thanks for your help
C?line
Here is my code :
library(tcltk2)
tt<-tktoplevel()
tktitle(tt)<-"Select a value"
titre<-tklabel(tt, text="Select a value")
value<-tkentry(tt, width=3, textvariable=tclVar("12"))
ok<-function()
{
??? show<-paste("The value is :", tclvalue(tkget(value)))
??? tkmessageBox(title="End", message=show, icon="info", type="ok")
??? tkdestroy(tt)
}

bouton<-tkbutton(tt, text="OK", command=ok)
tkpack(titre)
tkpack(value,bouton)
x<-tclvalue(tkget(value))
x<-as.numeric(x)
x #this give 12 but I want to have the new value


	[[alternative HTML version deleted]]


From marius.hofert at uwaterloo.ca  Fri Dec 12 15:22:00 2014
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Fri, 12 Dec 2014 09:22:00 -0500
Subject: [R] Is there a plotmath symbol \mapsto?
In-Reply-To: <e77560eab0714d52bcd7b9d411fa1e9b@CONNHUB1.connect.uwaterloo.ca>
References: <CAM3-KjY=NimMOM24Y77usbwyxEWBr=ocXNhX5hiQGhWeXf2EpA@mail.gmail.com>
	<e77560eab0714d52bcd7b9d411fa1e9b@CONNHUB1.connect.uwaterloo.ca>
Message-ID: <CAM3-KjZ17gYQHQJu+5HRH4o5XbkLp_EC1m9wNTJjhEyH6NQ7Uw@mail.gmail.com>

Dear Professor Ripley,

Thank you for your reply.
Do you specify \u21A6 via something like this?

plot(1, main=expression(symbol("\u21A6")))

This gives an the 'registered trademark symbol' (circled R) for me
(also cairo-based Linux).

Thanks and cheers,

Marius


From pdalgd at gmail.com  Fri Dec 12 16:37:18 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Dec 2014 16:37:18 +0100
Subject: [R] R and tcltk, problem to get the value entered
In-Reply-To: <763981550.4796239.1418378547772.JavaMail.yahoo@jws11157.mail.ir2.yahoo.com>
References: <763981550.4796239.1418378547772.JavaMail.yahoo@jws11157.mail.ir2.yahoo.com>
Message-ID: <EA1BD8AD-8F0E-485D-8CCF-9ED2EF4CDA85@gmail.com>


On 12 Dec 2014, at 11:02 , Jouanin Celine <celine_jouanin at yahoo.fr> wrote:

> Hi dear R list,
> I would like to create a graphical user interface with tcltk.I want to have a window where the user will enter a numeric, this will open a message box with his value. This works, but I don't succeed to get the value x, to use it after in a script in the R console. The x variable doesn't give me the value chosen by the user but returns the initial value "12".How can I do it ? Does exist an another function in tcltk that I need to use ?Thanks for your help
> C?line
> Here is my code :
> library(tcltk2)
> tt<-tktoplevel()
> tktitle(tt)<-"Select a value"
> titre<-tklabel(tt, text="Select a value")
> value<-tkentry(tt, width=3, textvariable=tclVar("12"))


I'd prefer this pattern of coding:

var <- tclVar("12")
entry <- tkentry(.... textvariable=var)
....
tkpack(entry)
....
tclvalue(var)


However, tkget() of an entry widget does return its value, so the direct cause of your trouble is different:

> ok<-function()
> {
>     show<-paste("The value is :", tclvalue(tkget(value)))
>     tkmessageBox(title="End", message=show, icon="info", type="ok")
>     tkdestroy(tt)
> }
> 
> bouton<-tkbutton(tt, text="OK", command=ok)
> tkpack(titre)
> tkpack(value,bouton)
> x<-tclvalue(tkget(value))
> x<-as.numeric(x)
> x #this give 12 but I want to have the new value
> 

I think this fetches the value before you get a chance to change it. You need to wait for it, either using tkwait.variable or tkwait.window. I believe that the tkttest demo has this structure.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dulcalma at bigpond.com  Fri Dec 12 16:57:26 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 13 Dec 2014 01:57:26 +1000
Subject: [R] x axis position and ggplot2
In-Reply-To: <1283050411.3983845.1418375739985.JavaMail.yahoo@jws11148.mail.ir2.yahoo.com>
References: <000601d014e5$d4142260$7c3c6720$@bigpond.com>
	<1283050411.3983845.1418375739985.JavaMail.yahoo@jws11148.mail.ir2.yahoo.com>
Message-ID: <000b01d01624$533ec240$f9bc46c0$@bigpond.com>

Hi C?line

 

ggplot2 and lattice have different constructs to the base graphics ? although they may share some common arguments like xlab, lwd col etc the rest may be totally different. 

 

In the latticeExtra package I think there is a function to make the lattice look like ggplot. I have never used it as I stick to lattice.

 

There may be something at Hadley?s web site for ggplot2 that may  do.

 

The other alternative is to add  the axis labels and the x label with using textGrob from library(grid) to put the axis at the top. It would be a bit fiddly but if you have to ?

 

Regards

 

Duncan 

 

 

From: Jouanin Celine [mailto:celine_jouanin at yahoo.fr] 
Sent: Friday, 12 December 2014 19:16
To: Duncan Mackay; R; Jeff Newmiller
Subject: Re: [R] x axis position and ggplot2

 

Hi,

 

Thank you for your answer, I thought we could used something like the "axis" function ( axis(side=3,...)) in ggplot2. 

I didn't find something like this in ggplot and I'm a bite surprised this doesn't exist. 

Sometimes we need to use lattice, grid -thank you Duncan for your help, or ggplot or other package, depending on what we want to show and the type of plot. Anyway, as I really need to use the ggplot package, I suppose that I'll plot my data without the axis on the top.

Have a nice day,

 

C?line

  _____  

De : Duncan Mackay <dulcalma at bigpond.com>
? : R <r-help at r-project.org>; 'Jouanin Celine' <celine_jouanin at yahoo.fr> 
Envoy? le : Jeudi 11 d?cembre 2014 2h57
Objet : RE: [R] x axis position and ggplot2


Hi 

I do not know ggplot2 well enough to give any advice but as Geff has mention lattice see

http://tolstoy.newcastle.edu.au/R/e2/help/07/05/17666.html

library(grid)
myXlabGrob <-
function(...){ ## ...is lab1, lab2, etc

  # you can add arguments to textGrob for more control  in the next line
  labs <- lapply(list(...), textGrob)
  nlabs <- length(labs)

  lab.heights <-
  lapply(labs, function(lab) unit(1, "grobheight", data = list(lab)))

  lab.layout <-
  grid.layout(ncol = nlabs, nrow = 1,
                  heights = do.call(max, lab.heights),
                  widths = unit(1, "null"),
                  respect = TRUE)

  lab.gf <- frameGrob(layout = lab.layout)

  for (i in seq_len(nlabs)){
    lab.gf <- placeGrob(lab.gf, labs[[i]], row = 1, col = i)
  }
  lab.gf
}

xyplot(1:10 ~ 1:10,
        scales = list(x = list(alternating = 2)), # puts scale on the top rather than the bottom
        xlab = "", # removes label at bottom
        xlab.top = myXlabGrob('B')
        )

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

 


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jouanin Celine
Sent: Thursday, 11 December 2014 02:44
To: r-help at r-project.org
Subject: [R] x axis position and ggplot2

Hi all,
Is it possible to change the position of the x axis to have it at the top of the plot when we use the ggplot function ?Thanks for your help,C?line



    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.






	[[alternative HTML version deleted]]


From kathryn.lord2000 at gmail.com  Fri Dec 12 18:00:33 2014
From: kathryn.lord2000 at gmail.com (Kathryn Lord)
Date: Sat, 13 Dec 2014 02:00:33 +0900
Subject: [R] create matrices with constraint
Message-ID: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>

Dear all,

Suppose that I have natural numbers 1 through 28.

Based on these numbers, choose 4 numbers 7 times without replacement and
make a 4 by 7 matrix, for example,

> a1
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]    1    5    9   13   17   21   25
[2,]    2    6   10   14   18   22   26
[3,]    3    7   11   15   19   23   27
[4,]    4    8   12   16   20   24   28

and again create another 4 * 7 matrix, say a2, in the same way; however,
every element of each column in a2 does not exist in any column of a1 like
this, e.g.

> a2
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]    1    2    3    4    5    6    7
[2,]    8    9   10   11   12   13   14
[3,]   15   16   17   18   19   20   21
[4,]   22   23   24   25   26   27   28
>

and again create another 4 * 7 matrix, say a3, in the same way; however,
every element of each column in a3 does not exist in any column of a1 and
a2.

Using same logic, I'd like to make the matrices (a3, a4, a5....) as many as
possible.


Any suggestion will be greatly appreciated.

Best,

Kathryn Lord

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Dec 12 19:17:21 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Dec 2014 19:17:21 +0100
Subject: [R] create matrices with constraint
In-Reply-To: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
Message-ID: <9FDD7BBD-77D0-44E6-9416-03938C5365A7@gmail.com>


> On 12 Dec 2014, at 18:00 , Kathryn Lord <kathryn.lord2000 at gmail.com> wrote:
> 
> Dear all,
> 
> Suppose that I have natural numbers 1 through 28.
> 
> Based on these numbers, choose 4 numbers 7 times without replacement and
> make a 4 by 7 matrix, for example,
> 
>> a1
>     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    5    9   13   17   21   25
> [2,]    2    6   10   14   18   22   26
> [3,]    3    7   11   15   19   23   27
> [4,]    4    8   12   16   20   24   28
> 
> and again create another 4 * 7 matrix, say a2, in the same way; however,
> every element of each column in a2 does not exist in any column of a1 like
> this, e.g.
> 
>> a2
>     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    2    3    4    5    6    7
> [2,]    8    9   10   11   12   13   14
> [3,]   15   16   17   18   19   20   21
> [4,]   22   23   24   25   26   27   28
>> 
> 

No comprendo... In which sense does e.g. "1" in the first column of a2 not exist in any column of a1???? 


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Fri Dec 12 20:40:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Dec 2014 11:40:50 -0800
Subject: [R] Is there a plotmath symbol \mapsto?
In-Reply-To: <548AEE51.3030703@stats.ox.ac.uk>
References: <CAM3-KjY=NimMOM24Y77usbwyxEWBr=ocXNhX5hiQGhWeXf2EpA@mail.gmail.com>
	<548AEE51.3030703@stats.ox.ac.uk>
Message-ID: <F58C8272-AB2A-482B-A7F8-E9E1F384DD5F@comcast.net>


On Dec 12, 2014, at 5:32 AM, Prof Brian Ripley wrote:

> The only symbols plotmath has access to are those in the Adobe Symbol encoding.  You can display all of those using the example at the bottom of ?points, as ?plotmath did tell you.  (So it was a rather rich asking for an example.)
> 
> It also tells you that on some devices/platforms you can use Unicode escapes.
> 
> Now TeX (not LaTeX) does not define exactly which glyph \mapsto should output, but Unicode \u21A6 is often called 'mapsto' (how Unicode glyphs are rendered is font-specific, of course).  That works for me with cairo-based devices on Linux; however on my Mac that glyph is not in the standard fonts for Quartz-based devices.

I did observe that I got failure to get that glyph to appear on a quartz or cairo_pdf device using either points() or text()  but this command did produce an error message that was able to find the glyph in the console font:

> points(1,.8,"\u21A6")
Error in plot.xy(xy.coords(x, y), type = type, ...) : invalid plot type '?'
In addition: Warning message:
In plot.xy(xy.coords(x, y), type = type, ...) :
  plot type '?' will be truncated to first character

-- 
David.
> 
> 
> On 12/12/2014 03:38, Marius Hofert wrote:
>> Hi,
>> 
>> Is there a plotmath symbol like LaTeX's \mapsto?
>> I need this comparably often, for example if you want to plot a
>> two-place function in one variable (and thus would like to have
>> ylab="t \mapsto f(t,s)", for example). If there is such a symbol, I'd
>> be great to have it as an example on ?plotmath.
>> 
>> Thanks & cheers,
>> 
>> Marius
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From john.archie.mckown at gmail.com  Fri Dec 12 20:45:37 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 12 Dec 2014 13:45:37 -0600
Subject: [R] create matrices with constraint
In-Reply-To: <9FDD7BBD-77D0-44E6-9416-03938C5365A7@gmail.com>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
	<9FDD7BBD-77D0-44E6-9416-03938C5365A7@gmail.com>
Message-ID: <CAAJSdjhE4NiXvyOHS+OMAaVABEfEUTqMAFGNKHAeuumMM9GrkA@mail.gmail.com>

On Fri, Dec 12, 2014 at 12:17 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 12 Dec 2014, at 18:00 , Kathryn Lord <kathryn.lord2000 at gmail.com>
> wrote:
> >
> > Dear all,
> >
> > Suppose that I have natural numbers 1 through 28.
> >
> > Based on these numbers, choose 4 numbers 7 times without replacement and
> > make a 4 by 7 matrix, for example,
> >
> >> a1
> >
> ??
>    [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> > [1,]    1    5    9   13   17   21   25
> > [2,]    2    6   10   14   18   22   26
> > [3,]    3    7   11   15   19   23   27
> > [4,]    4    8   12   16   20   24   28
> >
> > and again create another 4 * 7 matrix, say a2, in the same way; however,
> > every element of each column in a2 does not exist in any column of a1
> like
> > this, e.g.
> >
> >> a2
> >     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> > [1,]    1    2    3    4    5    6    7
> > [2,]    8    9   10   11   12   13   14
> > [3,]   15   16   17   18   19   20   21
> > [4,]   22   23   24   25   26   27   28
> >>
> >
>
> No comprendo... In which sense does e.g. "1" in the first column of a2 not
> exist in any column of a1????
>

?I was confused about that too. Perhaps what she means is that each column
in the every "a" matrix has at least one value?

?which does not exist in any column of any other "a" matrix. So that the
set of values in a[,?] for a given version does not exist as a set of
values in any other column (ignoring order) of any other version of "a". So
a1[,1] is c(1,2,3,4) which means that no other a?[,?] contains _all_ of
those. It _may_ contain a proper subset, but at least one value in the set
must differ. But I'm not sure that I was any clearer.

Hum. Consider the set of all possible unique 4 value vectors in which the
values in the vectors are taken, without replacement, from the numbers 1
through 28. This is a mathematical concept called "combination". In this
case, there are 35 such: 7!/(4!*3!).
Combine those vectors in groups of 7
?, each group being a separate column,?
in such a way that each resulting matrix contains no duplicate numbers,
which also ensure
?s?
that each resulting matrix does contain all of the values 1 through 28.
Note that the vector c(1,2,3,4) and c(2,1,4,3) are considered identical
? because, in a combination, order does not matter?
. So a matrix which has a column with c(1,2,3,4) stops any other matrix
from having a column with the values c(2,1,4,3).
?You can also note that two matrices would be consider "identical" if the
only difference is the arrangement of the column. For example:

?

?         ?
[,1] [,2] [,3] [,4] [,5] [,6] [,7]
?   ?
 [1,]    1    5    9   13   17   21   25
?   ?
 [2,]    2    6   10   14   18   22   26
?   ?
 [3,]    3    7   11   15   19   23   27
?   ?
 [4,]    4    8   12   16   20   24   28

?
is really the same as (exchanging [,4] and [,1]):

?
??
??

??

?     ?
[,1] [,2] [,3] [,4] [,5] [,6] [,7]
?   ?
 [1,]
?13
    5    9
? 1?
   17   21   25
?   ?
 [2,]
?14?
    6   10
? 2?
   18   22   26
?   ?
 [3,]
?15?
    7   11
? 3?
   19   23   27
?   ?
 [4,]
?16?
    8   12
? 4?
   20   24   28


as is
? (exchanging [3,7] and [4,7])?

?  ??  ?     ?[,1] [,2] [,3] [,4] [,5] [,6] [,7]
?   ? [1,]   ?13    5    9   ? 1?   17   21   25
?   ? [2,]   ?14?    6   10   ? 2?   18   22   26
?   ? [3,]   ?15?    7   11   ? 3?   19   23   2
?8?
?   ? [4,]   ?16?    8   12   ? 4?   20   24   2
?7?



I think this is what the OP was getting at.

I can't think of a way, off hand, to generate all such "a" matrices. I
might be able to do the first part: creating all unique 4 value vectors.
But then combining the vectors together to make the matrices is not clear
to me.
?

>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
?
While a transcendent vocabulary is laudable, one must be eternally careful
so that the calculated objective of communication does not become ensconced
in obscurity.  In other words, eschew obfuscation.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Fri Dec 12 20:47:57 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Dec 2014 19:47:57 +0000
Subject: [R] Is there a plotmath symbol \mapsto?
In-Reply-To: <F58C8272-AB2A-482B-A7F8-E9E1F384DD5F@comcast.net>
References: <CAM3-KjY=NimMOM24Y77usbwyxEWBr=ocXNhX5hiQGhWeXf2EpA@mail.gmail.com>
	<548AEE51.3030703@stats.ox.ac.uk>
	<F58C8272-AB2A-482B-A7F8-E9E1F384DD5F@comcast.net>
Message-ID: <548B466D.3010501@stats.ox.ac.uk>

On 12/12/2014 19:40, David Winsemius wrote:
>
> On Dec 12, 2014, at 5:32 AM, Prof Brian Ripley wrote:
>
>> The only symbols plotmath has access to are those in the Adobe Symbol encoding.  You can display all of those using the example at the bottom of ?points, as ?plotmath did tell you.  (So it was a rather rich asking for an example.)
>>
>> It also tells you that on some devices/platforms you can use Unicode escapes.
>>
>> Now TeX (not LaTeX) does not define exactly which glyph \mapsto should output, but Unicode \u21A6 is often called 'mapsto' (how Unicode glyphs are rendered is font-specific, of course).  That works for me with cairo-based devices on Linux; however on my Mac that glyph is not in the standard fonts for Quartz-based devices.
>
> I did observe that I got failure to get that glyph to appear on a quartz or cairo_pdf device using either points() or text()  but this command did produce an error message that was able to find the glyph in the console font:
>
>> points(1,.8,"\u21A6")
> Error in plot.xy(xy.coords(x, y), type = type, ...) : invalid plot type '?'
> In addition: Warning message:
> In plot.xy(xy.coords(x, y), type = type, ...) :
>    plot type '?' will be truncated to first character

Hence my careful wording:  'the standard fonts for Quartz-based devices'.

I do not believe 'console font' is a well-defined quantity: perhaps you 
meant 'the default font of the R.app console', which many OS X users 
never use.  For a Terminal and R.app the font can be chosen by the user ....

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From agehsbarg at gmail.com  Fri Dec 12 21:00:20 2014
From: agehsbarg at gmail.com (=?UTF-8?B?0JDQu9C10LrRgdCw0L3QtNGAINCT0LXRhdGB0LHQsNGA0LM=?=)
Date: Fri, 12 Dec 2014 22:00:20 +0200
Subject: [R] R-intro question
Message-ID: <CAG==dkFFfJTsUbrEakX76WHkxQXSNEJEDhcshDuZS_AYvh=yiQ@mail.gmail.com>

Dear Sir/Madam,

While reading R-intro document (found here
http://cran.r-project.org/doc/manuals/R-intro.pdf) on the page 37, I have
found such text

*which does indicate a significant difference, assuming normality*

referenced to t-test for equality of two means (unpaired t-test).

Could, you, please, comment, what type of "normality" is meant in the text?

Thank you in advance,
Aleksandrs Gehsbargs

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec 12 22:03:51 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Dec 2014 13:03:51 -0800
Subject: [R] R-intro question
In-Reply-To: <CAG==dkFFfJTsUbrEakX76WHkxQXSNEJEDhcshDuZS_AYvh=yiQ@mail.gmail.com>
References: <CAG==dkFFfJTsUbrEakX76WHkxQXSNEJEDhcshDuZS_AYvh=yiQ@mail.gmail.com>
Message-ID: <27A7D328-9F47-40AF-A30A-A82D0C5CF31B@comcast.net>


On Dec 12, 2014, at 12:00 PM, ????????? ???????? wrote:

> Dear Sir/Madam,
> 
> While reading R-intro document (found here
> http://cran.r-project.org/doc/manuals/R-intro.pdf) on the page 37, I have
> found such text
> 
> *which does indicate a significant difference, assuming normality*
> 
> referenced to t-test for equality of two means (unpaired t-test).
> 
> Could, you, please, comment, what type of "normality" is meant in the text?

The usual normality that is often spelled with a capital-N:

http://en.wikipedia.org/wiki/Normal_distribution


> 
> Thank you in advance,
> Aleksandrs Gehsbargs
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mhdk.dinesh at gmail.com  Fri Dec 12 22:46:34 2014
From: mhdk.dinesh at gmail.com (Dinesh Chowdhary)
Date: Fri, 12 Dec 2014 16:46:34 -0500
Subject: [R] Invisible Printing
Message-ID: <CAH7iKjKpufSLH4inMgb-HEf5X2ihyAf2r-DALR=EuXcpwfTmAw@mail.gmail.com>

R 3.1.2

Dear good people

I have a very generic question, and please excuse me for the informal
format of presenting it?

Is invisible printing still persistent in the latest version of R. why to
use `invisible(x)` ?


Thanking you in anticipation
Dinesh

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Dec 12 22:54:45 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 12 Dec 2014 13:54:45 -0800
Subject: [R] Invisible Printing
In-Reply-To: <CAH7iKjKpufSLH4inMgb-HEf5X2ihyAf2r-DALR=EuXcpwfTmAw@mail.gmail.com>
References: <CAH7iKjKpufSLH4inMgb-HEf5X2ihyAf2r-DALR=EuXcpwfTmAw@mail.gmail.com>
Message-ID: <35E1939A-BED3-4317-89AC-E1CA1225D1D1@dcn.davis.CA.us>

Yes. The help file for this function explains why it is used.

If you don't want to use it, that is fine.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 12, 2014 1:46:34 PM PST, Dinesh Chowdhary <mhdk.dinesh at gmail.com> wrote:
>R 3.1.2
>
>Dear good people
>
>I have a very generic question, and please excuse me for the informal
>format of presenting it?
>
>Is invisible printing still persistent in the latest version of R. why
>to
>use `invisible(x)` ?
>
>
>Thanking you in anticipation
>Dinesh
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From arjunamusic at gmail.com  Sat Dec 13 01:14:19 2014
From: arjunamusic at gmail.com (N F)
Date: Fri, 12 Dec 2014 19:14:19 -0500
Subject: [R] Missing Data Imputation for Complex Survey Data
Message-ID: <CABHR9jr7btcXi=reY2s+3fNVfTVYRwhfKiYXnfPqrYGh-QrATA@mail.gmail.com>

Dear all,
I've got a bit of a challenge on my hands. I've got survey data produced by
a government agency for which I want to use the person-weights in my
analyses. This is best accomplished by specifying weights in {survey} and
then calculating descriptive statistics/models through functions in that
package.

However, there is also missingness in this data that I'd like to handle
with imputation via {mi}. To properly use imputed datasets in regression,
they need to be pooled using the lm.mi function in {mi}. However, I can't
figure out how to carry out a regression on data that is properly weighted
that has also had its missing values imputed, because both packages use
their own mutually incompatible data objects. Does anyone have any thoughts
on this? I've done a lot of reading and I'm not really seeing anything on
point.

Thanks in advance!

	[[alternative HTML version deleted]]


From sjafri83 at gmail.com  Fri Dec 12 22:43:13 2014
From: sjafri83 at gmail.com (Sajjad Jafri)
Date: Fri, 12 Dec 2014 16:43:13 -0500
Subject: [R] Getting a Error: unexpected symbol in:
Message-ID: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>

I am trying to create a simple function that finds the number of days
between two dates. However, when I run the  function, R gives me an error
message saying:



unexpected '}' in "        }"

Here is my function:

#create a function that finds the number of days between two dates
diffdate<-function(x,y){
        z<-unclass(as.Date(x))
        z1<-unclass(as.Date(y))
        }
        {
                return z1-z
        }

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sat Dec 13 04:11:10 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 12 Dec 2014 19:11:10 -0800
Subject: [R] Getting a Error: unexpected symbol in:
In-Reply-To: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>
References: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>
Message-ID: <CACk-te3qcJip-VfYh8Jim9Kd4HbJqFkJhbaOMVZkJ0N1oUtK5w@mail.gmail.com>

As what is going on is completely obvious, I think you need to consult
a local programmer to explain it to you -- probably a 15 year old kid
will do. Seriously. Doesn't have to know R (other than that a
multiline's function's code/body must be enclosed in "{ }." Perhaps
reading an R tutorial (maybe "An Intro to R", which ships with R --
have you read it? If not, why not??)  might also do.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Dec 12, 2014 at 1:43 PM, Sajjad Jafri <sjafri83 at gmail.com> wrote:
> I am trying to create a simple function that finds the number of days
> between two dates. However, when I run the  function, R gives me an error
> message saying:
>
>
>
> unexpected '}' in "        }"
>
> Here is my function:
>
> #create a function that finds the number of days between two dates
> diffdate<-function(x,y){
>         z<-unclass(as.Date(x))
>         z1<-unclass(as.Date(y))
>         }
>         {
>                 return z1-z
>         }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Dec 13 04:44:16 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Dec 2014 19:44:16 -0800
Subject: [R] Getting a Error: unexpected symbol in:
In-Reply-To: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>
References: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>
Message-ID: <385C816E-502F-4A79-A540-845DBF94BAF9@comcast.net>


On Dec 12, 2014, at 1:43 PM, Sajjad Jafri wrote:

> I am trying to create a simple function that finds the number of days
> between two dates. However, when I run the  function, R gives me an error
> message saying:

What do you mean "when you run the function"? I do not see any calls to the function.

I do see an error message but the functions was defined, nonetheless. All you need to do is type `diffdate` to see it. You will probably be surprised.


> unexpected '}' in "        }"
> 
> Here is my function:
> 
> #create a function that finds the number of days between two dates
> diffdate<-function(x,y){
>        z<-unclass(as.Date(x))
>        z1<-unclass(as.Date(y))
>        }
>        {
>                return z1-z
>        }
> 
> 	[[alternative HTML version deleted]]

Read the Posting Guide regarding teh desired format of posts.

> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Sat Dec 13 05:01:17 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 12 Dec 2014 20:01:17 -0800
Subject: [R] Getting a Error: unexpected symbol in:
In-Reply-To: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>
References: <CAK4U53p1a6+860KnSmXRP5g2pd-u7snveGSAQJmBKZW7aiH5rg@mail.gmail.com>
Message-ID: <8CF2FD50-F031-438B-B0D5-9F59669C0115@dcn.davis.CA.us>

The body of a function needs to be wrapped in one pair of braces.

diffdate<-function(x,y){
        z<-unclass(as.Date(x))
        z1<-unclass(as.Date(y))
        return(z1-z)
 }

It is common in R to make sure that date values are of the appropriate type before you call the function instead of doing it over and over in this and various other functions you might use. If you give the function Date values instead of character strings you can shorten your function because you can do Date arithmetic directly on them. You also don't need the return statement since you are at the end of the code block already.

diffdate2 <- function(x,y){
        as.numeric(y-x)
 }

in1 <- "2014-12-12"
in2 <- "2014-10-12"
in1 <- as.Date(in1)
in2 <- as.Date(in2)
diffdate2(in1,in2)

The expectation that specific types of data will be used is the reason that we are so picky on this mailing list about getting sample data along with sample code... so we know all the pieces of the puzzle that might be giving you trouble.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 12, 2014 1:43:13 PM PST, Sajjad Jafri <sjafri83 at gmail.com> wrote:
>I am trying to create a simple function that finds the number of days
>between two dates. However, when I run the  function, R gives me an
>error
>message saying:
>
>
>
>unexpected '}' in "        }"
>
>Here is my function:
>
>#create a function that finds the number of days between two dates
>diffdate<-function(x,y){
>        z<-unclass(as.Date(x))
>        z1<-unclass(as.Date(y))
>        }
>        {
>                return z1-z
>        }
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Sat Dec 13 06:20:57 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 13 Dec 2014 00:20:57 -0500
Subject: [R] create matrices with constraint
In-Reply-To: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
Message-ID: <CAGx1TMA-ZSsdkE0LmG4ZbDyt1yogJpJ-GvtmfqK8ptLjhdK2Qg@mail.gmail.com>

I think you might be looking for incomplete block designs.  See
Cochran and Cox 1957, page 481
for Plan 11.38
t=28, k=4, r=9, b=63, lambda=1, E=.78. Type I

This design might be the set of 4 x 7 matrices you are looking for.

On Fri, Dec 12, 2014 at 12:00 PM, Kathryn Lord
<kathryn.lord2000 at gmail.com> wrote:
> Dear all,
>
> Suppose that I have natural numbers 1 through 28.
>
> Based on these numbers, choose 4 numbers 7 times without replacement and
> make a 4 by 7 matrix, for example,
>
>> a1
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    5    9   13   17   21   25
> [2,]    2    6   10   14   18   22   26
> [3,]    3    7   11   15   19   23   27
> [4,]    4    8   12   16   20   24   28
>
> and again create another 4 * 7 matrix, say a2, in the same way; however,
> every element of each column in a2 does not exist in any column of a1 like
> this, e.g.
>
>> a2
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    2    3    4    5    6    7
> [2,]    8    9   10   11   12   13   14
> [3,]   15   16   17   18   19   20   21
> [4,]   22   23   24   25   26   27   28
>>
>
> and again create another 4 * 7 matrix, say a3, in the same way; however,
> every element of each column in a3 does not exist in any column of a1 and
> a2.
>
> Using same logic, I'd like to make the matrices (a3, a4, a5....) as many as
> possible.
>
>
> Any suggestion will be greatly appreciated.
>
> Best,
>
> Kathryn Lord
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Sat Dec 13 08:14:17 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 13 Dec 2014 02:14:17 -0500
Subject: [R] Missing Data Imputation for Complex Survey Data
In-Reply-To: <CABHR9jr7btcXi=reY2s+3fNVfTVYRwhfKiYXnfPqrYGh-QrATA@mail.gmail.com>
References: <CABHR9jr7btcXi=reY2s+3fNVfTVYRwhfKiYXnfPqrYGh-QrATA@mail.gmail.com>
Message-ID: <CAOwvMDzegBDtG5Ar0+sB-pyHXeq2zzAzK-AYfUdyZs3NHBR1Qg@mail.gmail.com>

the mitools package is compatible with the survey package..  asdfree.com
has complete step-by-step R code examples to work with govt microdata.
here are the ones with multiply imputed survey data.  :)

national health interview survey
national survey of children's health
consumer expenditure survey
program of international student assessment
survey of consumer finances
survey of business owners
program for the international assessment of adult competencies

once you have the survey design constructed properly, you can just execute
the svyglm like this:

https://github.com/ajdamico/usgsd/blob/d300884bd63dd05c61e8a6fa76ed7293adae55c2/Consumer
Expenditure Survey/2011 fmly intrvw - analysis examples.R#659




On Fri, Dec 12, 2014 at 7:14 PM, N F <arjunamusic at gmail.com> wrote:
>
> Dear all,
> I've got a bit of a challenge on my hands. I've got survey data produced by
> a government agency for which I want to use the person-weights in my
> analyses. This is best accomplished by specifying weights in {survey} and
> then calculating descriptive statistics/models through functions in that
> package.
>
> However, there is also missingness in this data that I'd like to handle
> with imputation via {mi}. To properly use imputed datasets in regression,
> they need to be pooled using the lm.mi function in {mi}. However, I can't
> figure out how to carry out a regression on data that is properly weighted
> that has also had its missing values imputed, because both packages use
> their own mutually incompatible data objects. Does anyone have any thoughts
> on this? I've done a lot of reading and I'm not really seeing anything on
> point.
>
> Thanks in advance!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Sat Dec 13 18:10:43 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 13 Dec 2014 11:10:43 -0600
Subject: [R] create matrices with constraint
In-Reply-To: <CAAJSdjhE4NiXvyOHS+OMAaVABEfEUTqMAFGNKHAeuumMM9GrkA@mail.gmail.com>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
	<9FDD7BBD-77D0-44E6-9416-03938C5365A7@gmail.com>
	<CAAJSdjhE4NiXvyOHS+OMAaVABEfEUTqMAFGNKHAeuumMM9GrkA@mail.gmail.com>
Message-ID: <CAAJSdjhtz1=doNXnHwVFMUdiZhcZQWRqK06+k2q82b=ZKBJr4A@mail.gmail.com>

On Fri, Dec 12, 2014 at 1:45 PM, John McKown <john.archie.mckown at gmail.com>
wrote:

> ?
>
?<snip>?



> Hum. Consider the set of all possible unique 4 value vectors in which the
> values in the vectors are taken, without replacement, from the numbers 1
> through 28. This is a mathematical concept called "combination". In this
> case, there are 35 such: 7!/(4!*3!).
>

?Ack. I'm an idiot. That is 28!/(4!*24!) or 20,475 possible combinations.
The R code to generate a single matrix which contains all of the possible
cominations (which is not what is really wanted) could be:

    result<-c(0,0,0,0); #initialize to something
    for(i1 in 1:25) {
        for (i2 in (i1+1):26) {
            for (i3 in (i2+1):27) {
                for (i4 in (i3+1):28) {
                    x<-c(i1,i2,i3,i4);
                    result<-rbind(result,x);
                }
            }
        }
    }
    result<-result[2:(nrow(result)-1),]; #strip off that first row?

?of c(0,0,0,0)?


?The problem now would be to assign those vectors to the proper matrix. My
first though is to have the result be a data.frame or a three dimensional
"matrix". But actually _doing_ that I haven't figured out yet. Oh, and
obviously from the way that I generated the vectors, the data items within
each vector is sorted in ascending value. An even more difficult problem
would be if the OP needed every possible permutation of each possible
matrix.?


-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From robertzimbardo at gmail.com  Sat Dec 13 20:08:58 2014
From: robertzimbardo at gmail.com (Robert Zimbardo)
Date: Sat, 13 Dec 2014 11:08:58 -0800
Subject: [R] Two-tailed exact binomial test with binom.test and
	sum(dbinom(...))
Message-ID: <CAGJyvhE7BVH3POQvFvOYZtw77CxetfEJuSx2XJJ9=+ZwE+ZEVQ@mail.gmail.com>

Hi R experts,

I have a few related questions that are actually a combination of an R
and a hopefully not too  trivial (?) statistics question, namely
regarding the computation of an exact two-tailed binomial test.

Let's assume the following scenario:
- number of trials = 10
- p of success = 0.6

(a) Let's also assume we have an H1 that there are more than 6
successes and the number of successes we get is 8. In that case, we do
sum(dbinom(8:10, 10, 0.6)) # 0.1672898
binom.test(8, 10, 0.6, alternative="greater") # 0.1673

(b) Now let's assume we have an H1 that there are fewer than 6
successes and the number of successes we get is 2. In that case, we do
sum(dbinom(0:2, 10, 0.6)) # 0.01229455
binom.test(2, 10, 0.6, alternative="less") # 0.01229

So far no problem. My questions are now concerned with a two-tailed test:

(1). My understanding would be that, if we have an H1 that says "the
number of successes won't be 6", then we can add up the two
probabilities from above:
sum(dbinom(8:10, 10, 0.6)) + sum(dbinom(0:2, 10, 0.6)) # 0.1795843, or just
sum(dbinom(c(0:2, 8:10), 10, 0.6)) # 0.1795843

However, that is not what binom.test(..., alternative="two.sided") does:
binom.test(2, 10, 0.6, alternative="two.sided") # 0.01834, which is
the method of small(er) p-values:
sum(dbinom(0:10, 10, 0.6)[dbinom(0:10, 10, 0.6)<=dbinom(2, 10, 0.6)])
# 0.01834117

Thus, question 1) is, is there a reason binom.test is implemented the
way it is rather than the other way?

(2) I am struggling to understand two-tailed scenarios like this one:
- number of trials = 235
- p of success = 1/6
- successes = 51

That is, cases where my logic of taking the successes+1 extreme cases
on each tail don't work: adding the point probabilities of 51:235 is
fine, but it of course makes no sense to add the point probabilities
for 0:185 to that
sum(dbinom(51:235, 235, 1/6)) # 0.02654425
sum(dbinom(0:185, 235, 1/6)) # 1 (!)

So, while binom.test again does its small(er) p-value thing, ...
binom.test(51, 235, 1/6, alternative="two.sided") # 0.04375
sum(dbinom(0:235, 235, 1/6)[dbinom(0:235, 235, 1/6)<=dbinom(51, 235,
1/6)]) # 0.04374797

... I am wondering how my approach with adding the probabilities of
the same number of events from each tail would be done here ...?

(3) What is people's view on computing the two-tailed test like this,
which leads to an ns result unlike binom.test?
2*sum(dbinom(51:235, 235, 1/6)) # 0.05308849

Any input would be much appreciated!

R.Z.


From macqueen1 at llnl.gov  Sat Dec 13 21:36:11 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Sat, 13 Dec 2014 20:36:11 +0000
Subject: [R] Assistance converting to R a python function that extracts from
 an XML file
Message-ID: <D0B1E339.115C03%macqueen1@llnl.gov>

I would appreciate assistance doing in R what a colleague has done in
python. Unfortunately (for me), I have almost no experience with either
python or xml.

Within an xml file there is
    <CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime>
and I need to extract those two values, 20120627 and 07322600


Here is the short python function. Even without knowing python, it's
conceptually clear what it does. I would like to do the same in R.

def readxmldate(xmlfile):
	tree = ET.parse(xmlfile)
	root = tree.getroot()
	for lev1 in root.findall('Esri'):
		xdate = lev1.find('CreaDate').text
		xtime = lev1.find('CreaTime').text
		return xdate, xtime


Thanks in advance
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


From dtemplelang at ucdavis.edu  Sat Dec 13 22:06:02 2014
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Sat, 13 Dec 2014 13:06:02 -0800
Subject: [R] Assistance converting to R a python function that extracts
 from an XML file
In-Reply-To: <D0B1E339.115C03%macqueen1@llnl.gov>
References: <D0B1E339.115C03%macqueen1@llnl.gov>
Message-ID: <548CAA3A.5020102@ucdavis.edu>

Hi Don

library(XML)
readxmldate = 
function(xmlfile) 
{
  doc = xmlParse(xmlfile)
  xpathSApply(doc, '//Esri/CreaDate | //Esri/CreaTime', xmlValue)
}

 D.

On 12/13/14, 12:36 PM, MacQueen, Don wrote:
> I would appreciate assistance doing in R what a colleague has done in
> python. Unfortunately (for me), I have almost no experience with either
> python or xml.
> 
> Within an xml file there is
>     <CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime>
> and I need to extract those two values, 20120627 and 07322600
> 
> 
> Here is the short python function. Even without knowing python, it's
> conceptually clear what it does. I would like to do the same in R.
> 
> def readxmldate(xmlfile):
> 	tree = ET.parse(xmlfile)
> 	root = tree.getroot()
> 	for lev1 in root.findall('Esri'):
> 		xdate = lev1.find('CreaDate').text
> 		xtime = lev1.find('CreaTime').text
> 		return xdate, xtime
> 
> 
> Thanks in advance
> -Don
>


From boris.steipe at utoronto.ca  Sat Dec 13 22:22:14 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 13 Dec 2014 16:22:14 -0500
Subject: [R] Assistance converting to R a python function that extracts
	from an XML file
In-Reply-To: <548CAA3A.5020102@ucdavis.edu>
References: <D0B1E339.115C03%macqueen1@llnl.gov> <548CAA3A.5020102@ucdavis.edu>
Message-ID: <E5F42CED-9159-4F77-807C-366835E5B3E7@utoronto.ca>

Or  ...

txt <- "<doc><CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime></doc>"

if (!require(XML)) {
	install.packages("XML")
	library(XML)
}


result <- xmlParse(txt, asText=TRUE)
# or ... result <- xmlParse(your-file-here.xml)

toString.XMLNode(getNodeSet(result,'//CreaDate/text()')[[1]])
toString.XMLNode(getNodeSet(result,'//CreaTime/text()')[[1]])


B.





On Dec 13, 2014, at 4:06 PM, Duncan Temple Lang <dtemplelang at ucdavis.edu> wrote:

> Hi Don
> 
> library(XML)
> readxmldate = 
> function(xmlfile) 
> {
>  doc = xmlParse(xmlfile)
>  xpathSApply(doc, '//Esri/CreaDate | //Esri/CreaTime', xmlValue)
> }
> 
> D.
> 
> On 12/13/14, 12:36 PM, MacQueen, Don wrote:
>> I would appreciate assistance doing in R what a colleague has done in
>> python. Unfortunately (for me), I have almost no experience with either
>> python or xml.
>> 
>> Within an xml file there is
>>    <CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime>
>> and I need to extract those two values, 20120627 and 07322600
>> 
>> 
>> Here is the short python function. Even without knowing python, it's
>> conceptually clear what it does. I would like to do the same in R.
>> 
>> def readxmldate(xmlfile):
>> 	tree = ET.parse(xmlfile)
>> 	root = tree.getroot()
>> 	for lev1 in root.findall('Esri'):
>> 		xdate = lev1.find('CreaDate').text
>> 		xtime = lev1.find('CreaTime').text
>> 		return xdate, xtime
>> 
>> 
>> Thanks in advance
>> -Don
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rdybowski1 at gmail.com  Sun Dec 14 02:40:35 2014
From: rdybowski1 at gmail.com (Dr.Richard Dybowski)
Date: Sun, 14 Dec 2014 01:40:35 +0000
Subject: [R] How to tell g++ where Rcpp.h is located?
Message-ID: <CAP_TjCe3ht6Qvst0Mo2Qxd4kOoUYQP=-EzBn=KQwD59R=MJmmg@mail.gmail.com>

I am new to Rcpp and want to try the example given in
http://gallery.rcpp.org/articles/r-function-from-c++/
I have installed the Rcpp package via RStudio, but I do not know how to
tell my C++ compiler (g++) where to find the header file Rcpp.h . In case
it is relevant, my C++ IDE is Code::Blocks.

Sorry for the newbie question but I would appreciate help with this.

Thanks.

	[[alternative HTML version deleted]]


From edd at debian.org  Sun Dec 14 03:01:31 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 13 Dec 2014 20:01:31 -0600
Subject: [R] How to tell g++ where Rcpp.h is located?
In-Reply-To: <CAP_TjCe3ht6Qvst0Mo2Qxd4kOoUYQP=-EzBn=KQwD59R=MJmmg@mail.gmail.com>
References: <CAP_TjCe3ht6Qvst0Mo2Qxd4kOoUYQP=-EzBn=KQwD59R=MJmmg@mail.gmail.com>
Message-ID: <21644.61307.836057.614391@max.nulle.part>


On 14 December 2014 at 01:40, Dr.Richard Dybowski wrote:
| I am new to Rcpp and want to try the example given in
| http://gallery.rcpp.org/articles/r-function-from-c++/
| I have installed the Rcpp package via RStudio, but I do not know how to
| tell my C++ compiler (g++) where to find the header file Rcpp.h . In case
| it is relevant, my C++ IDE is Code::Blocks.
| 
| Sorry for the newbie question but I would appreciate help with this.

Did you consider looking at the Rcpp documentation?

Dirk

PS Code::Blocks is irrelevant here, apart from maybe serving as your C++
editor.  You will probably do everything from within RStudio.  Besides
*copious* Rcpp documentation, there is also documentation about Rcpp at the
RStudio site. Oh, and we have a mailing list.

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From nia_gupta at yahoo.com  Sun Dec 14 01:13:28 2014
From: nia_gupta at yahoo.com (Nia Gupta)
Date: Sun, 14 Dec 2014 00:13:28 +0000 (UTC)
Subject: [R] sort by decreasing columns?
Message-ID: <703894820.354764.1418516008739.JavaMail.yahoo@jws106102.mail.bf1.yahoo.com>

Hello, 

I have a data frame that looks like this:
?????????? a????? b??? c
1??????? 2?????? 3??? 8
2??????? 3?????? 5??? 9
I was wondering if it was possible to reorder the columns by decreasing values so the new data frame would look like this:
?????????? c ???? b ?? a
1??????? 8 ???? 3??? 2
2??????? 9 ???? 5?? 3

Thank you


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Dec 14 06:53:09 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 13 Dec 2014 21:53:09 -0800
Subject: [R] sort by decreasing columns?
In-Reply-To: <703894820.354764.1418516008739.JavaMail.yahoo@jws106102.mail.bf1.yahoo.com>
References: <703894820.354764.1418516008739.JavaMail.yahoo@jws106102.mail.bf1.yahoo.com>
Message-ID: <D5829EBA-B145-4036-B56B-D9C7DD6F0CEA@dcn.davis.CA.us>

In general, different rows would sort in different orders. Your example does not illustrate how you would want to address such a problem. Here I assume you are only interested in sorting by the values in the first row.

dta <- data.frame(a=c(2,3), b=c(3,5), c=c(8,9))
dta[,order(unlist(dta[1,]),decreasing=TRUE)]

Note that data frames don't usually contain data that one would want to manipulate this way... this type of thing would normally be associated with matrices, which always have all elements of a single type.

Please follow the instructions in the footer of this email next time... in particular post using plain text because HTML does not always survive the trip to us intact.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 13, 2014 4:13:28 PM PST, Nia Gupta via R-help <r-help at r-project.org> wrote:
>Hello, 
>
>I have a data frame that looks like this:
>?????????? a????? b??? c
>1??????? 2?????? 3??? 8
>2??????? 3?????? 5??? 9
>I was wondering if it was possible to reorder the columns by decreasing
>values so the new data frame would look like this:
>?????????? c ???? b ?? a
>1??????? 8 ???? 3??? 2
>2??????? 9 ???? 5?? 3
>
>Thank you
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Sun Dec 14 08:05:52 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 14 Dec 2014 10:05:52 +0300
Subject: [R] abline function : plot.new has not been called yet
Message-ID: <CAGh51gRHaAa+EYjh-iO7eo10+NFU1fN9oQqFZYTKwTx3L9QCZw@mail.gmail.com>

Hi All,

I would like to have an idea of how I can solve this error.

I am getting the following error in plotting:

> abline(regn,col='red',lwd=1.5 , data=BUTemp)
Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
  plot.new has not been called yet

This is the str of my data set

> str(BUTemp)
'data.frame':    7671 obs. of  6 variables:
 $ Year : int  1971 1971 1971 1971 1971 1971 1971 1971 1971 1971 ...
 $ Month: Factor w/ 12 levels "Aug","Sep","Oct",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ Day  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Rain : num  0 0 0 0 0 0 0 0 0 0 ...
 $ Tmax : num  24.3 25 25.6 26.5 27.8 27.5 25.7 25.1 26.5 25.1 ...
 $ Tmin : num  13.5 13.2 12.7 12.7 12.2 14 13.2 12.3 12.8 11.7 ...

The code I am using is :

require(latticeExtra) # trellis plot for temperature and rain.
require(lattice)

levels(BUTemp$Month) <- c("Aug", "Sep", "Oct", "Nov", "Dec", "Jan",
                          "Feb", "Mar", "Apr", "May", "Jun", "Jul")

xyplot(BUTemp$Tmin + BUTemp$Tmax ~ BUTemp$Year | BUTemp$Month,
       data =BUTemp , type = "b", pch=19)

regn=lm(BUTemp$Tmin + BUTemp$Tmax ~ BUTemp$Year)

abline(regn,col='red',lwd=1.5)
summary(regn)

Thanks  for your help.

Regards,
Frederic.
Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Dec 14 09:13:17 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 14 Dec 2014 00:13:17 -0800
Subject: [R] abline function : plot.new has not been called yet
In-Reply-To: <CAGh51gRHaAa+EYjh-iO7eo10+NFU1fN9oQqFZYTKwTx3L9QCZw@mail.gmail.com>
References: <CAGh51gRHaAa+EYjh-iO7eo10+NFU1fN9oQqFZYTKwTx3L9QCZw@mail.gmail.com>
Message-ID: <50BF6264-B93C-4A55-A5FB-BAAB2C902667@dcn.davis.CA.us>

The abline function is part of base graphics (read the help ?abline... it is part of the "graphics" package).

The xyplot function is part of the lattice package... a clone of the original "trellis" package from the S software. The two approaches to graphics don't play well together.

Once you know to keep this distinction in mind, you can probably find examples on the web, such as [1], or in help files such as ?panel.abline.

[1] http://apcg.uoregon.edu/GeogR/topics/lattice.htm
 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 13, 2014 11:05:52 PM PST, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>Hi All,
>
>I would like to have an idea of how I can solve this error.
>
>I am getting the following error in plotting:
>
>> abline(regn,col='red',lwd=1.5 , data=BUTemp)
>Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
>  plot.new has not been called yet
>
>This is the str of my data set
>
>> str(BUTemp)
>'data.frame':    7671 obs. of  6 variables:
> $ Year : int  1971 1971 1971 1971 1971 1971 1971 1971 1971 1971 ...
>$ Month: Factor w/ 12 levels "Aug","Sep","Oct",..: 2 2 2 2 2 2 2 2 2 2
>...
> $ Day  : int  1 2 3 4 5 6 7 8 9 10 ...
> $ Rain : num  0 0 0 0 0 0 0 0 0 0 ...
> $ Tmax : num  24.3 25 25.6 26.5 27.8 27.5 25.7 25.1 26.5 25.1 ...
> $ Tmin : num  13.5 13.2 12.7 12.7 12.2 14 13.2 12.3 12.8 11.7 ...
>
>The code I am using is :
>
>require(latticeExtra) # trellis plot for temperature and rain.
>require(lattice)
>
>levels(BUTemp$Month) <- c("Aug", "Sep", "Oct", "Nov", "Dec", "Jan",
>                          "Feb", "Mar", "Apr", "May", "Jun", "Jul")
>
>xyplot(BUTemp$Tmin + BUTemp$Tmax ~ BUTemp$Year | BUTemp$Month,
>       data =BUTemp , type = "b", pch=19)
>
>regn=lm(BUTemp$Tmin + BUTemp$Tmax ~ BUTemp$Year)
>
>abline(regn,col='red',lwd=1.5)
>summary(regn)
>
>Thanks  for your help.
>
>Regards,
>Frederic.
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Sun Dec 14 10:11:11 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 14 Dec 2014 12:11:11 +0300
Subject: [R] abline function : plot.new has not been called yet
In-Reply-To: <50BF6264-B93C-4A55-A5FB-BAAB2C902667@dcn.davis.CA.us>
References: <CAGh51gRHaAa+EYjh-iO7eo10+NFU1fN9oQqFZYTKwTx3L9QCZw@mail.gmail.com>
	<50BF6264-B93C-4A55-A5FB-BAAB2C902667@dcn.davis.CA.us>
Message-ID: <CAGh51gQWwKrTfXfNyF2ON8+neeOuseGVUZw=WHo2RepitqKUfA@mail.gmail.com>

Thanks Jeff for the Help. it works correctly.

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Sun, Dec 14, 2014 at 11:13 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:
>
> The abline function is part of base graphics (read the help ?abline... it
> is part of the "graphics" package).
>
> The xyplot function is part of the lattice package... a clone of the
> original "trellis" package from the S software. The two approaches to
> graphics don't play well together.
>
> Once you know to keep this distinction in mind, you can probably find
> examples on the web, such as [1], or in help files such as ?panel.abline.
>
> [1] http://apcg.uoregon.edu/GeogR/topics/lattice.htm
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On December 13, 2014 11:05:52 PM PST, Frederic Ntirenganya <
> ntfredo at gmail.com> wrote:
> >Hi All,
> >
> >I would like to have an idea of how I can solve this error.
> >
> >I am getting the following error in plotting:
> >
> >> abline(regn,col='red',lwd=1.5 , data=BUTemp)
> >Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
> >  plot.new has not been called yet
> >
> >This is the str of my data set
> >
> >> str(BUTemp)
> >'data.frame':    7671 obs. of  6 variables:
> > $ Year : int  1971 1971 1971 1971 1971 1971 1971 1971 1971 1971 ...
> >$ Month: Factor w/ 12 levels "Aug","Sep","Oct",..: 2 2 2 2 2 2 2 2 2 2
> >...
> > $ Day  : int  1 2 3 4 5 6 7 8 9 10 ...
> > $ Rain : num  0 0 0 0 0 0 0 0 0 0 ...
> > $ Tmax : num  24.3 25 25.6 26.5 27.8 27.5 25.7 25.1 26.5 25.1 ...
> > $ Tmin : num  13.5 13.2 12.7 12.7 12.2 14 13.2 12.3 12.8 11.7 ...
> >
> >The code I am using is :
> >
> >require(latticeExtra) # trellis plot for temperature and rain.
> >require(lattice)
> >
> >levels(BUTemp$Month) <- c("Aug", "Sep", "Oct", "Nov", "Dec", "Jan",
> >                          "Feb", "Mar", "Apr", "May", "Jun", "Jul")
> >
> >xyplot(BUTemp$Tmin + BUTemp$Tmax ~ BUTemp$Year | BUTemp$Month,
> >       data =BUTemp , type = "b", pch=19)
> >
> >regn=lm(BUTemp$Tmin + BUTemp$Tmax ~ BUTemp$Year)
> >
> >abline(regn,col='red',lwd=1.5)
> >summary(regn)
> >
> >Thanks  for your help.
> >
> >Regards,
> >Frederic.
> >Frederic Ntirenganya
> >Maseno University,
> >African Maths Initiative,
> >Kenya.
> >Mobile:(+254)718492836
> >Email: fredo at aims.ac.za
> >https://sites.google.com/a/aims.ac.za/fredo/
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From stefanML at collocations.de  Sun Dec 14 13:54:25 2014
From: stefanML at collocations.de (Stefan Evert)
Date: Sun, 14 Dec 2014 13:54:25 +0100
Subject: [R] Two-tailed exact binomial test with binom.test and
	sum(dbinom(...))
In-Reply-To: <CAGJyvhE7BVH3POQvFvOYZtw77CxetfEJuSx2XJJ9=+ZwE+ZEVQ@mail.gmail.com>
References: <CAGJyvhE7BVH3POQvFvOYZtw77CxetfEJuSx2XJJ9=+ZwE+ZEVQ@mail.gmail.com>
Message-ID: <328471DC-410F-467A-B7EB-292A52AD5BB8@collocations.de>

If your null hypothesis is that the probability of a success is 0.6, i.e. H0: p=0.6, then those

> (a) Let's also assume we have an H1 that there are more than 6
> successes
> 
> (b) Now let's assume we have an H1 that there are fewer than 6
> successes 
> 
> (1). My understanding would be that, if we have an H1 that says "the
> number of successes won't be 6"

aren't appropriate alternative hypotheses, because you make a statement about the sample rather than the population.

The correct H1 in the two-tailed case is

	H1: the probability of success is not 0.6, i.e. p != 0.6

With the H1s you gave above, your implicit null hypothesis is

	H0: there will be exactly 6 successes in a sample

which you can refute with 100% certainty if you observe != 6 successes in any sample.


Perhaps Unit 2 of the SIGIL course, which tries to explain the logic behind the binomial test in detail, might help you get a better understanding of the procedure.  Slides are freely available here:

	http://www.stefan-evert.de/SIGIL/sigil_R/

Alternatively, read any good introductory statistics textbook that includes the exact binomial test.


> (3) What is people's view on computing the two-tailed test like this,
> which leads to an ns result unlike binom.test?
> 2*sum(dbinom(51:235, 235, 1/6)) # 0.05308849

This is a popular approximation (which I also use most of the time) because it's much less expensive (in computational terms) than computing an exact (likelihood-based) two-tailed p-value as binom.test() does.  This is particularly relevant if you want to compute confidence intervals for the true probability p based on a large sample, which takes ages with binom.test().


Hope this helps,
Stefan

From syen04 at gmail.com  Sun Dec 14 14:07:38 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 14 Dec 2014 08:07:38 -0500
Subject: [R] Checking if a logical variable exists
In-Reply-To: <544d4402.26dcec0a.7867.fffff267@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
Message-ID: <548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>

My obj does not always come with a logical variable defined. So I do

my.foo <- function(obj,df,digits=5){
if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
...
}

This works when "Fisher" is defined in/passed from obj. When it is 
not, I get error:

Error in (!is.na("obj$spec$Fisher")) & Fisher :
   operations are possible only for numeric, logical or complex types

I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.


From btupper at bigelow.org  Sun Dec 14 14:43:09 2014
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 14 Dec 2014 08:43:09 -0500
Subject: [R] Checking if a logical variable exists
In-Reply-To: <548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
Message-ID: <A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>

Hi,

Does this work for you?  It simply tests if the name Fisher is found among the names of the elements of spec.

obj = list(spec = list)
Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)

Cheers,
Ben

On Dec 14, 2014, at 8:07 AM, Steven Yen <syen04 at gmail.com> wrote:

> My obj does not always come with a logical variable defined. So I do
> 
> my.foo <- function(obj,df,digits=5){
> if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
> ...
> }
> 
> This works when "Fisher" is defined in/passed from obj. When it is not, I get error:
> 
> Error in (!is.na("obj$spec$Fisher")) & Fisher :
>  operations are possible only for numeric, logical or complex types
> 
> I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From murdoch.duncan at gmail.com  Sun Dec 14 14:43:11 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 14 Dec 2014 08:43:11 -0500
Subject: [R] Checking if a logical variable exists
In-Reply-To: <548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>	<544D414F.50303@sapo.pt>
	<544D422E.1050605@sapo.pt>	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
Message-ID: <548D93EF.60902@gmail.com>

On 14/12/2014, 8:07 AM, Steven Yen wrote:
> My obj does not always come with a logical variable defined. So I do
> 
> my.foo <- function(obj,df,digits=5){
> if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
> ...
> }
> 
> This works when "Fisher" is defined in/passed from obj. When it is 
> not, I get error:
> 
> Error in (!is.na("obj$spec$Fisher")) & Fisher :
>    operations are possible only for numeric, logical or complex types
> 
> I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.

The test you want is based on is.null(), and you definitely don't want
quotes there.  For example,

if (!is.null(obj$spec) && !is.null(obj$spec$Fisher))
  Fisher <- obj$spec$Fisher

Duncan Murdoch


From syen04 at gmail.com  Sun Dec 14 15:30:56 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 14 Dec 2014 09:30:56 -0500
Subject: [R] Checking if a logical variable exists
In-Reply-To: <A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
	<A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>
Message-ID: <548d9f24.886eec0a.72bc.ffffafdd@mx.google.com>

Thanks. This worked!! :)
Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)

Steven

At 08:43 AM 12/14/2014, Ben Tupper wrote:
>Hi,
>
>Does this work for you?  It simply tests if the name Fisher is found 
>among the names of the elements of spec.
>
>obj = list(spec = list)
>Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)
>
>Cheers,
>Ben
>
>On Dec 14, 2014, at 8:07 AM, Steven Yen <syen04 at gmail.com> wrote:
>
> > My obj does not always come with a logical variable defined. So I do
> >
> > my.foo <- function(obj,df,digits=5){
> > if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
> > ...
> > }
> >
> > This works when "Fisher" is defined in/passed from obj. When it 
> is not, I get error:
> >
> > Error in (!is.na("obj$spec$Fisher")) & Fisher :
> >  operations are possible only for numeric, logical or complex types
> >
> > I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>Ben Tupper
>Bigelow Laboratory for Ocean Sciences
>60 Bigelow Drive, P.O. Box 380
>East Boothbay, Maine 04544
>http://www.bigelow.org


From pdalgd at gmail.com  Sun Dec 14 16:21:09 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 14 Dec 2014 16:21:09 +0100
Subject: [R] Two-tailed exact binomial test with binom.test and
	sum(dbinom(...))
In-Reply-To: <328471DC-410F-467A-B7EB-292A52AD5BB8@collocations.de>
References: <CAGJyvhE7BVH3POQvFvOYZtw77CxetfEJuSx2XJJ9=+ZwE+ZEVQ@mail.gmail.com>
	<328471DC-410F-467A-B7EB-292A52AD5BB8@collocations.de>
Message-ID: <CED2C361-4D42-4680-B0AA-0A05DC061FEF@gmail.com>


> On 14 Dec 2014, at 13:54 , Stefan Evert <stefanML at collocations.de> wrote:
> 
<snip>
> 
>> (3) What is people's view on computing the two-tailed test like this,
>> which leads to an ns result unlike binom.test?
>> 2*sum(dbinom(51:235, 235, 1/6)) # 0.05308849
> 
> This is a popular approximation (which I also use most of the time) because it's much less expensive (in computational terms) than computing an exact (likelihood-based) two-tailed p-value as binom.test() does.  This is particularly relevant if you want to compute confidence intervals for the true probability p based on a large sample, which takes ages with binom.test().

When I get drilled about this, I usually say that one really shouldn't use "two-tailed" and "exact" in the same sentence, because of the issue with the definition of tails. I don't agree that the version in binom.test is in any sense _the_ correct one and we probably should make alternatives optional at some point. 

One point that is easily overlooked (guilty!) is that defining the p-value as the sum over less probable outcomes is _not_ a likelihood theory technique. The likelihood ratio test should have a denominator equal to the maximum probability of the outcome when the parameter is allowed to vary from the null value. It is not that hard to do the actual LRT:

> LRT <-  -2*log(dbinom(0:235,235,1/6)/dbinom(0:235,235,(0:235)/235))
> dist_null <- dbinom(0:235, 235, 1/6)
> sum(dist_null[LRT >= LRT_obs])
[1] 0.05373588 

I believe there are four reasonable contenders for the two sided p-value:

1) sum of probabilities of less or equally probable outcomes
2) sum of probabilities of outcomes with more extreme LRT
3) double minimum one-tailed p
4) tail-balancing: one-sided p plus the max opposite tail probability less than p

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From john.archie.mckown at gmail.com  Sun Dec 14 17:48:12 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 14 Dec 2014 10:48:12 -0600
Subject: [R] create matrices with constraint
In-Reply-To: <548DAD20.5090802@xs4all.nl>
References: <548DAD20.5090802@xs4all.nl>
Message-ID: <CAAJSdjjBVTXd8xVZJGPkJXwhDjDdpWG1JnijDmKvmdeTyTpMug@mail.gmail.com>

On Sun, Dec 14, 2014 at 9:30 AM, Gerrit Draisma <gdraisma at xs4all.nl> wrote:

> Ha John,
> Sorry I did not follow the discussion but what
> about
>  combn(1:28,4)
> ?
> Gerrit.


?Very nice! Thanks.  The form needed by the OP would be t(combn(1:28,4)) to
swap rows & columns.

I'm cross posting this to the r-help so that the OP can get at it (to give
credit to the right person). This is just "phase 1" of her real quest for a
set of 7x4 (rows x columns) matrices made from rows from that result which
are complete (each matrix contains all the values in 1:28, and disjunct.
 (Assuming I'm remembering the correct words. Which is not so easy at 62,
with college being a fading memory.)

As an aside, I am really curious what the OP wants with this set of
matrices. Another in the thread said something about "incomplete block
designs", but that is something that I've never heard of before. I'm really
poor at statistics.


-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From AARTI.MUNJAL at ucdenver.edu  Sun Dec 14 19:24:05 2014
From: AARTI.MUNJAL at ucdenver.edu (Munjal, Aarti)
Date: Sun, 14 Dec 2014 18:24:05 +0000
Subject: [R] ASA Stat. Computing & Stat. Graphics Student Paper Competition
	2015
Message-ID: <D0B32378.6C09%aarti.munjal@ucdenver.edu>

Statistical Computing and Statistical Graphics Sections
American Statistical Association

Student Paper Competition 2015

The Statistical Computing and Statistical Graphics Sections of the ASA
are co-sponsoring a student paper competition on the topics of
Statistical Computing and Statistical Graphics.  Students are
encouraged to submit a paper in one of these areas, which might be
original methodological research, some novel computing or graphical
application in statistics, or any other suitable contribution (for
example, a software-related project).  The selected winners will
present their papers in a topic-contributed session at the 2015 Joint
Statistical Meetings.  The Sections will pay registration fees for the
winners as well as a substantial allowance for transportation to the
meetings and lodging.

Anyone who is a student (graduate or undergraduate) on or after
September 1, 2014 is eligible to participate.  An entry must include
an abstract, a six page manuscript (including figures, tables and
references), blinded versions of the abstract and manuscript (with no
authors and no references that easily lead to identifying the
authors), a C.V., and a letter from a faculty member familiar with the
student's work.  The applicant must be the first author of the paper.
The faculty letter must include a verification of the applicant's
student status and, in the case of joint authorship, should indicate
what fraction of the contribution is attributable to the applicant.
We prefer that electronic submissions of papers be in Postscript or
PDF.  All materials must be in English.

Students may submit papers to no more than two sections and may accept
only one section's award. Students must inform both sections applied
to when he or she wins and accepts an award, thereby removing the
student from the award competition for the second section.

All application materials MUST BE RECEIVED by 5:00 PM EST, Sunday,
December 14, 2014 at the address below.  They will be reviewed by the
Student Paper Competition Award committee of the Statistical Computing
and Graphics Sections.  The selection criteria used by the committee
will include innovation and significance of the contribution as well
as the professional quality of the manuscript.  Award announcements
will be made by January 15th, 2015.

Additional important information on the competition can be accessed on
ASA's "Student Paper Competition/Travel Award to Attend the Joint
Statistical Meetings" page at
http://www.amstat.org/sections/studentpaperawards.cfm, or at the
website of the Statistical Computing Section,
http://www.statcomputing.org.  Inquiries and application materials
should be emailed or mailed to:

Student Paper Competition
c/o Aarti Munjal
Colorado School of Public Health
University of Colorado Denver
aarti.munjal at ucdenver.edu


	[[alternative HTML version deleted]]


From vokey at uleth.ca  Sun Dec 14 20:51:57 2014
From: vokey at uleth.ca (Vokey, John)
Date: Sun, 14 Dec 2014 19:51:57 +0000
Subject: [R] Using  PBMROC software in R
Message-ID: <37F11F43-FE1C-4BDA-B8A6-9CE999DF85A6@uleth.ca>

Fellow useRs,
  I am trying to install and call the PBMROC software (from the Metz-ROC Software Downloads: http://metz-roc.uchicago.edu) without much success, even though it was designed to be flexible enough to call from R or Matlab.  Has anyone managed to get the PBMROC software to work within R?  If so, I would be thrilled if you could walk me through it.

--
Please avoid sending me Word or PowerPoint attachments.
See <http://www.gnu.org/philosophy/no-word-attachments.html>

-Dr. John R. Vokey


From kp1005 at gmail.com  Sun Dec 14 21:30:45 2014
From: kp1005 at gmail.com (Kruti Pandya)
Date: Sun, 14 Dec 2014 12:30:45 -0800
Subject: [R] extract objects from R output
Message-ID: <CAORW=u4vMN-5xT0hwNu_duRQDpTH3Vd-Ppb1PvyEGRSXjk6FPg@mail.gmail.com>

I am new to R and using this package BoolNet. I wanted to extract the
boolean transition functions resulting from the output of
generateRandomNKNetwork function. I am able to extract individual function
using
net$interactions$Gene1$expression,net$interactions$Gene2$expression.... .
But it gives me the transition function in quotes. How can I remove the
quotes ?

My goal is to  evaluate each transition function at a randomly generated
initial state. What I need to do is to extract each of the individual
functions one by one. Like

extract net$interactions$Gene1$expression
evaluate the function at random initial sate
then extract net$interactions$Gene2$expression
evaluate the function at random initial state

.... do this for all five functions that comes out of the ouput.

I tried something like this but did not work.

for (i in 1:5){
  func[[i]]<-rn$interactions$Gene[i]$expression

#extract net$interactions$Gene1$expression,
net$interactions$Gene2$expression and so on

}


# output of generateRandomNKNetwork
install.packages(BoolNet)
  library(BoolNet)

  net<-generateRandomNKNetwork(5,3,readableFunctions="canonical")

#Output of net
Boolean network with 5 genes

Involved genes:
Gene1 Gene2 Gene3 Gene4 Gene5

Transition functions:
Gene1 = (!Gene5 & Gene1 & !Gene2) | (!Gene5 & Gene1 & Gene2) | (Gene5 &
!Gene1 & !Gene2)
Gene2 = (!Gene1 & !Gene3 & !Gene2) | (!Gene1 & Gene3 & !Gene2) | (!Gene1 &
Gene3 & Gene2) | (Gene1 & Gene3 & Gene2)
Gene3 = (!Gene3 & Gene1 & !Gene2) | (Gene3 & !Gene1 & !Gene2) | (Gene3 &
Gene1 & !Gene2)
Gene4 = (!Gene4 & !Gene2 & !Gene1) | (!Gene4 & !Gene2 & Gene1) | (!Gene4 &
Gene2 & Gene1) | (Gene4 & !Gene2 & !Gene1) | (Gene4 & Gene2 & Gene1)
Gene5 = (!Gene2 & !Gene4 & !Gene5) | (!Gene2 & !Gene4 & Gene5) | (Gene2 &
!Gene4 & Gene5)

net$interactions$Gene1$expression
#[1] "(!Gene5 & Gene1 & !Gene2) | (!Gene5 & Gene1 & Gene2) | (Gene5 &
!Gene1 & !Gene2)"

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Dec 15 02:15:01 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Dec 2014 17:15:01 -0800
Subject: [R] extract objects from R output
In-Reply-To: <CAORW=u4vMN-5xT0hwNu_duRQDpTH3Vd-Ppb1PvyEGRSXjk6FPg@mail.gmail.com>
References: <CAORW=u4vMN-5xT0hwNu_duRQDpTH3Vd-Ppb1PvyEGRSXjk6FPg@mail.gmail.com>
Message-ID: <A9542E5D-7E74-4862-A6F6-C2B748C2F6FC@comcast.net>

PLEASE DO NOT POST IN HTML:


> On Dec 14, 2014, at 12:30 PM, Kruti Pandya <kp1005 at gmail.com> wrote:
> 
> I am new to R and using this package BoolNet. I wanted to extract the
> boolean transition functions resulting from the output of
> generateRandomNKNetwork function. I am able to extract individual function
> using
> net$interactions$Gene1$expression,net$interactions$Gene2$expression.... .
> But it gives me the transition function in quotes. How can I remove the
> quotes ?
> 
> My goal is to  evaluate each transition function at a randomly generated
> initial state. What I need to do is to extract each of the individual
> functions one by one. Like
> 
> extract net$interactions$Gene1$expression
> evaluate the function at random initial sate
> then extract net$interactions$Gene2$expression
> evaluate the function at random initial state
> 
> .... do this for all five functions that comes out of the ouput.
> 
> I tried something like this but did not work.
> 
> for (i in 1:5){
>  func[[i]]<-rn$interactions$Gene[i]$expression
> 
> #extract net$interactions$Gene1$expression,
> net$interactions$Gene2$expression and so on
> 
> }

So look at the object:

> str(net)
List of 3
 $ genes       : chr [1:5] "Gene1" "Gene2" "Gene3" "Gene4" ...
 $ interactions:List of 5
  ..$ Gene1:List of 3
  .. ..$ input     : int [1:3] 5 4 3


> names(net$interactions)
[1] "Gene1" "Gene2" "Gene3" "Gene4" "Gene5"

There are not five items names named ?Gene? with indices 1 to 5. You can get at items with those names by paste0()-ing with ?[[?


#There is nothing named ?fun? yet:


OR FOR THAT  MATTER?. an object name ?rn?. Why on earth did you change the name to 'rn' from ?net'?????


 func=list()
 for (i in 1:5){
  func[[i]]<-net$interactions[[paste0("Gene",i)]]$expression
 }

 str(func)
List of 5
 $ : chr "(!Gene5 & !Gene4 & !Gene3) | (!Gene5 & !Gene4 & Gene3) | (Gene5 & !Gene4 & Gene3) | (Gene5 & Gene4 & Gene3)"
 $ : chr "(!Gene1 & Gene2 & !Gene3) | (!Gene1 & Gene2 & Gene3) | (Gene1 & !Gene2 & !Gene3) | (Gene1 & !Gene2 & Gene3) | (Gene1 & Gene2 & "| __truncated__
 $ : chr "(!Gene4 & !Gene2 & Gene5) | (Gene4 & Gene2 & !Gene5) | (Gene4 & Gene2 & Gene5)"
 $ : chr "(!Gene1 & !Gene2 & Gene5) | (!Gene1 & Gene2 & Gene5) | (Gene1 & !Gene2 & Gene5) | (Gene1 & Gene2 & !Gene5)"
 $ : chr "(!Gene5 & !Gene1 & !Gene4) | (!Gene5 & Gene1 & !Gene4) | (!Gene5 & Gene1 & Gene4) | (Gene5 & !Gene1 & !Gene4) | (Gene5 & !Gene1"| __truncated__


David.

> 
> # output of generateRandomNKNetwork
> install.packages(BoolNet)
>  library(BoolNet)
> 
>  net<-generateRandomNKNetwork(5,3,readableFunctions="canonical")
> 
> #Output of net
> Boolean network with 5 genes
> 
> Involved genes:
> Gene1 Gene2 Gene3 Gene4 Gene5
> 
> Transition functions:
> Gene1 = (!Gene5 & Gene1 & !Gene2) | (!Gene5 & Gene1 & Gene2) | (Gene5 &
> !Gene1 & !Gene2)
> Gene2 = (!Gene1 & !Gene3 & !Gene2) | (!Gene1 & Gene3 & !Gene2) | (!Gene1 &
> Gene3 & Gene2) | (Gene1 & Gene3 & Gene2)
> Gene3 = (!Gene3 & Gene1 & !Gene2) | (Gene3 & !Gene1 & !Gene2) | (Gene3 &
> Gene1 & !Gene2)
> Gene4 = (!Gene4 & !Gene2 & !Gene1) | (!Gene4 & !Gene2 & Gene1) | (!Gene4 &
> Gene2 & Gene1) | (Gene4 & !Gene2 & !Gene1) | (Gene4 & Gene2 & Gene1)
> Gene5 = (!Gene2 & !Gene4 & !Gene5) | (!Gene2 & !Gene4 & Gene5) | (Gene2 &
> !Gene4 & Gene5)
> 
> net$interactions$Gene1$expression
> #[1] "(!Gene5 & Gene1 & !Gene2) | (!Gene5 & Gene1 & Gene2) | (Gene5 &
> !Gene1 & !Gene2)"
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From spencer.graves at prodsyse.com  Mon Dec 15 06:33:44 2014
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 14 Dec 2014 21:33:44 -0800
Subject: [R] Comparing Latin characters with and without accents?
In-Reply-To: <547AF23C.60206@structuremonitoring.com>
References: <547AEDF1.5000305@structuremonitoring.com>
	<1417343132.23112.37.camel@club.fr>
	<547AF23C.60206@structuremonitoring.com>
Message-ID: <E1727D7D-D1AB-440F-9DD6-4048DE5F6988@prodsyse.com>

Hello, All:  


	  What do people do to strip accents from latin characters, returning vanilla ASCII?  


	  For example, I want to convert ?Ra?l? to ?Raul?.  Milan (below) suggested 'iconv(x, ?",  "ASCII//TRANSLIT?)?.  This worked under Windows but failed on Linux and Mac.  It?s part of the ?subNonStandardCharacters? function in the Ecfun package.  The development version on R-Forge uses this and returns ?Raul? under Windows and NA under Mac OS X (and something different from ?Raul?, presumably NA, under Linux).    


	  Thanks, 
	  Spencer 


> On Nov 30, 2014, at 2:32 AM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
> 
> Wonderful.  Thanks very much.  Spencer
> 
> 
> On 11/30/2014 2:25 AM, Milan Bouchet-Valat wrote:
>> Le dimanche 30 novembre 2014 ? 02:14 -0800, Spencer Graves a ?crit :
>>> Hello:
>>> 
>>> 
>>>        How can one convert Latin characters with to the corresponding
>>> characters without?  For example, I want to convert "?" to "u", similar
>>> to how tolower('U') returns "u".
>>> 
>>> 
>>>        This can be done using chartr{base}, e.g., chartr('?', 'u',
>>> 'Ra?l') returns "Raul".  However, I wondered if a simpler version of
>>> this is available.
>> This appears to work:
>>> iconv("?", "", "ASCII//TRANSLIT")
>> [1] "u"
>> 
>> 
>> Regards
>> 
>>>        Thanks,
>>>        Spencer
>>> 
>>> 
>>> p.s.   findFn('convert to ascii') found 117 help pages in 70 packages.
>>> A brief review identified two to "Convert to ASCII": ASCIIfy {gtools}
>>> and stri_enc_toascii {stringi}.  Neither of these did what I expected.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From geoffrey_klein at etu.u-bourgogne.fr  Mon Dec 15 11:33:24 2014
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Mon, 15 Dec 2014 02:33:24 -0800 (PST)
Subject: [R] keep only the first value of a numeric sequence
Message-ID: <1418639604028-4700774.post@n4.nabble.com>

Hello dear R-helpers,

I have a small problem in my algorithm. I have sequences of "0" and "1"
values in a column of a huge data frame, and I just would like to keep the
first value of each sequences of "1" values, such like in this example:

data <-
data.frame(mydata=c(0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,1,1,1,1,1,1),final_wished_data=c(0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0))

Any easy way to do this?

Thanks everybody!




--
View this message in context: http://r.789695.n4.nabble.com/keep-only-the-first-value-of-a-numeric-sequence-tp4700774.html
Sent from the R help mailing list archive at Nabble.com.


From Lalitha.Kristipati at techmahindra.com  Mon Dec 15 12:12:24 2014
From: Lalitha.Kristipati at techmahindra.com (Lalitha Kristipati)
Date: Mon, 15 Dec 2014 11:12:24 +0000
Subject: [R] New to R
Message-ID: <e5a164e0ab50499cbc0df121190a8abb@BLREXCHMBX001.TechMahindra.com>

Hi

I'm learning R language from  past  one month .As R is used highly for data analysis ,mining and modeling ,I want to know few real time examples in R in order to make my learning  fun filled and practical .Any quick suggestions  are appreciated .



Regards,
Lalitha Kristipati
Associate Software Engineer




============================================================================================================================
Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
============================================================================================================================


	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Mon Dec 15 13:18:33 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Mon, 15 Dec 2014 23:18:33 +1100
Subject: [R] keep only the first value of a numeric sequence
In-Reply-To: <1418639604028-4700774.post@n4.nabble.com>
References: <1418639604028-4700774.post@n4.nabble.com>
Message-ID: <CAKL8G3EuewcpVYPc3a6fHNtWnhzGs7DwY-TPn_ecUqHJkHCSzQ@mail.gmail.com>

Dear jeff6868,

Here is one way:

ifelse(with(data, c(0, diff(mydata))) != 1, 0, 1)

You could also take a look at ?rle

HTH,
Jorge.-



On Mon, Dec 15, 2014 at 9:33 PM, jeff6868 <geoffrey_klein at etu.u-bourgogne.fr
> wrote:
>
> Hello dear R-helpers,
>
> I have a small problem in my algorithm. I have sequences of "0" and "1"
> values in a column of a huge data frame, and I just would like to keep the
> first value of each sequences of "1" values, such like in this example:
>
> data <-
>
> data.frame(mydata=c(0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,1,1,1,1,1,1),final_wished_data=c(0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0))
>
> Any easy way to do this?
>
> Thanks everybody!
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/keep-only-the-first-value-of-a-numeric-sequence-tp4700774.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From chrisaa at med.umich.edu  Mon Dec 15 14:09:00 2014
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Mon, 15 Dec 2014 13:09:00 +0000
Subject: [R] Two-tailed exact binomial test with binom.test
	and	sum(dbinom(...))
In-Reply-To: <CAGJyvhE7BVH3POQvFvOYZtw77CxetfEJuSx2XJJ9=+ZwE+ZEVQ@mail.gmail.com>
References: <CAGJyvhE7BVH3POQvFvOYZtw77CxetfEJuSx2XJJ9=+ZwE+ZEVQ@mail.gmail.com>
Message-ID: <30411786F64EEF46856EFBA2CD9177992C35FE45@UHEXMBSPR03.umhs.med.umich.edu>

If you are testing H0: p = 0.6 vs H1: p != 0.6 with a sample of size 10 and you observe X=2, then Pr(X <= 2) + Pr(X >= 8) is not what you want.  You can argue that you want Pr(X <= 2) + Pr(X >= 10).  Both 2 and 10 are 4 away from the null.

binom.test(2, 10, 0.6, alternative="two.sided") # 0.01834
sum(dbinom(c(0:2, 10), 10, 0.6)) #  0.01834117

You don't want the same number of outcomes on each side unless p=0.5 is the null.

Chris


-----Original Message-----
From: Robert Zimbardo [mailto:robertzimbardo at gmail.com] 
Sent: Saturday, December 13, 2014 2:09 PM
To: r-help at r-project.org
Subject: [R] Two-tailed exact binomial test with binom.test and sum(dbinom(...))

Hi R experts,

I have a few related questions that are actually a combination of an R
and a hopefully not too  trivial (?) statistics question, namely
regarding the computation of an exact two-tailed binomial test.

Let's assume the following scenario:
- number of trials = 10
- p of success = 0.6

(a) Let's also assume we have an H1 that there are more than 6
successes and the number of successes we get is 8. In that case, we do
sum(dbinom(8:10, 10, 0.6)) # 0.1672898
binom.test(8, 10, 0.6, alternative="greater") # 0.1673

(b) Now let's assume we have an H1 that there are fewer than 6
successes and the number of successes we get is 2. In that case, we do
sum(dbinom(0:2, 10, 0.6)) # 0.01229455
binom.test(2, 10, 0.6, alternative="less") # 0.01229

So far no problem. My questions are now concerned with a two-tailed test:

(1). My understanding would be that, if we have an H1 that says "the
number of successes won't be 6", then we can add up the two
probabilities from above:
sum(dbinom(8:10, 10, 0.6)) + sum(dbinom(0:2, 10, 0.6)) # 0.1795843, or just
sum(dbinom(c(0:2, 8:10), 10, 0.6)) # 0.1795843

However, that is not what binom.test(..., alternative="two.sided") does:
binom.test(2, 10, 0.6, alternative="two.sided") # 0.01834, which is
the method of small(er) p-values:
sum(dbinom(0:10, 10, 0.6)[dbinom(0:10, 10, 0.6)<=dbinom(2, 10, 0.6)])
# 0.01834117

Thus, question 1) is, is there a reason binom.test is implemented the
way it is rather than the other way?

(2) I am struggling to understand two-tailed scenarios like this one:
- number of trials = 235
- p of success = 1/6
- successes = 51

That is, cases where my logic of taking the successes+1 extreme cases
on each tail don't work: adding the point probabilities of 51:235 is
fine, but it of course makes no sense to add the point probabilities
for 0:185 to that
sum(dbinom(51:235, 235, 1/6)) # 0.02654425
sum(dbinom(0:185, 235, 1/6)) # 1 (!)

So, while binom.test again does its small(er) p-value thing, ...
binom.test(51, 235, 1/6, alternative="two.sided") # 0.04375
sum(dbinom(0:235, 235, 1/6)[dbinom(0:235, 235, 1/6)<=dbinom(51, 235,
1/6)]) # 0.04374797

... I am wondering how my approach with adding the probabilities of
the same number of events from each tail would be done here ...?

(3) What is people's view on computing the two-tailed test like this,
which leads to an ns result unlike binom.test?
2*sum(dbinom(51:235, 235, 1/6)) # 0.05308849

Any input would be much appreciated!

R.Z.


**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

From rmh at temple.edu  Mon Dec 15 14:18:53 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 15 Dec 2014 08:18:53 -0500
Subject: [R] keep only the first value of a numeric sequence
In-Reply-To: <CAKL8G3EuewcpVYPc3a6fHNtWnhzGs7DwY-TPn_ecUqHJkHCSzQ@mail.gmail.com>
References: <1418639604028-4700774.post@n4.nabble.com>
	<CAKL8G3EuewcpVYPc3a6fHNtWnhzGs7DwY-TPn_ecUqHJkHCSzQ@mail.gmail.com>
Message-ID: <CAGx1TMBysdNA06spkw6UtZy=bbT2PHO4B-iuLg0HORCFyKV9Zw@mail.gmail.com>

we can speed this up a lot

> system.time(for (i in 1:2000) ifelse(c(0, diff(data$mydata)) != 1, 0, 1))
   user  system elapsed
  0.122   0.012   0.132
> system.time(for (i in 1:2000) as.numeric( c(0, diff(data$mydata))==1))
   user  system elapsed
  0.073   0.007   0.078
> ifelse(c(0, diff(data$mydata)) != 1, 0, 1)
 [1] 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
> as.numeric( c(0, diff(data$mydata))==1)
 [1] 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0
>

On Mon, Dec 15, 2014 at 7:18 AM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
> Dear jeff6868,
>
> Here is one way:
>
> ifelse(with(data, c(0, diff(mydata))) != 1, 0, 1)
>
> You could also take a look at ?rle
>
> HTH,
> Jorge.-
>
>
>
> On Mon, Dec 15, 2014 at 9:33 PM, jeff6868 <geoffrey_klein at etu.u-bourgogne.fr
>> wrote:
>>
>> Hello dear R-helpers,
>>
>> I have a small problem in my algorithm. I have sequences of "0" and "1"
>> values in a column of a huge data frame, and I just would like to keep the
>> first value of each sequences of "1" values, such like in this example:
>>
>> data <-
>>
>> data.frame(mydata=c(0,0,0,1,1,1,1,1,0,0,0,0,1,1,1,0,0,0,0,1,1,1,1,1,1,1),final_wished_data=c(0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0))
>>
>> Any easy way to do this?
>>
>> Thanks everybody!
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/keep-only-the-first-value-of-a-numeric-sequence-tp4700774.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Mon Dec 15 16:23:11 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 15 Dec 2014 09:23:11 -0600
Subject: [R] create matrices with constraint
In-Reply-To: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
Message-ID: <CAAJSdjhQo4cNpO_pJwhfC5tpeBsrA2Oi+w1Edq8HxZnSErEBLA@mail.gmail.com>

On Fri, Dec 12, 2014 at 11:00 AM, Kathryn Lord <kathryn.lord2000 at gmail.com>
wrote:

> Dear all,
>
> Suppose that I have natural numbers 1 through 28.
>
> Based on these numbers, choose 4 numbers 7 times without replacement and
> make a 4 by 7 matrix, for example,
>
>
?After a relaxing weekend, it came to me that these 4x7 matrices are really
just a subset of all the possible permutations of the vector 1:28, recast
as  4x7 matrices. Of course, there are factorial(28) (about 3*10^29 ) such
4x7 matrices. But given your constraints, I think that these can be
subsetted to only those permutations in which the values in each row are
sorted in ascending (or descending) order. I am fairly certain that this
subset would be exhaustive for your purposes. I not really certain how big
that subset would be. I think it would be 1/168th ( 1 out of 7*factorial(4)
) of the 3*10^29 permutations, or about 1.8*10^27. Which is still way to
big to actually instantiate all at once. You might be able store such a
thing in a huge data base. If you're lucky, you have access to a massive
supercomputer so that you can get the results before the heat death of this
universe. (exaggeration?)

Two R libraries seems to address this. One is combinat. The other is
permute.? The permute library seems, to me, to be the more likely
candidate. It contains a "how()" function which __appears to me__ to
perhaps be a way to subset the permutations as they are being generated.
But all that I get from reading the documentation is a bad headache. I
never studied combinatorics. And I got a milder headache trying to read the
Wikipedia article on it.

?I am curious about what you will do with such a set of matrices, once you
have them. If you are permitted to say.

-- 
?
While a transcendent vocabulary is laudable, one must be eternally careful
so that the calculated objective of communication does not become ensconced
in obscurity.  In other words, eschew obfuscation.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From msharp at txbiomed.org  Mon Dec 15 16:26:32 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Mon, 15 Dec 2014 09:26:32 -0600
Subject: [R] New to R
In-Reply-To: <e5a164e0ab50499cbc0df121190a8abb@BLREXCHMBX001.TechMahindra.com>
References: <e5a164e0ab50499cbc0df121190a8abb@BLREXCHMBX001.TechMahindra.com>
Message-ID: <D4EDE358-AE9A-47C3-9C78-7442E9CD0DF1@txbiomed.org>

I would recommend finding some tutorials on line in areas that you enjoy, read http://r-bloggers.com every day, find introductory texts in the statistical areas of interest, and study some texts on R programming. I really enjoyed The Art of R Programming: A Tour of Statistical Software Design by Norman Matloff. For a bit more depth I like Hadley Wickham's Advanced R book (http://adv-r.had.co.nz).

Mark Sharp

R. Mark Sharp, Ph.D.
Director of Primate Records Database
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org

> On Dec 15, 2014, at 5:12 AM, Lalitha Kristipati <Lalitha.Kristipati at techmahindra.com> wrote:
>
> Hi
>
> I'm learning R language from  past  one month .As R is used highly for data analysis ,mining and modeling ,I want to know few real time examples in R in order to make my learning  fun filled and practical .Any quick suggestions  are appreciated .
>
>
>
> Regards,
> Lalitha Kristipati
> Associate Software Engineer
>
>
>
>
> ============================================================================================================================
> Disclaimer:  This message and the information contained herein is proprietary and confidential and subject to the Tech Mahindra policy statement, you may review the policy at http://www.techmahindra.com/Disclaimer.html externally http://tim.techmahindra.com/tim/disclaimer.html internally within TechMahindra.
> ============================================================================================================================
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From rl at openmailbox.org  Mon Dec 15 17:02:35 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Mon, 15 Dec 2014 16:02:35 +0000
Subject: [R] dotplot axes labelling
Message-ID: <72139ef2c4c932ec42d43066bfae96f6@openmailbox.org>

Subscribers,

What is my mistake with the following example:

library(lattice)
testmatrix<-matrix(c(1,2,3,4,3,6,12,24),nrow=4,ncol=2)
testylabels<-c('w1','x1','y1','z1')
dotplot(testmatrix, scales=list(y=list(testylabels)), xlab=NULL)
#testylabels not shown, instead 'D' 'C' 'B' 'A'

Thanks in advance.

--


From dcarlson at tamu.edu  Mon Dec 15 17:06:34 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 15 Dec 2014 16:06:34 +0000
Subject: [R] create matrices with constraint
In-Reply-To: <CAAJSdjhQo4cNpO_pJwhfC5tpeBsrA2Oi+w1Edq8HxZnSErEBLA@mail.gmail.com>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
	<CAAJSdjhQo4cNpO_pJwhfC5tpeBsrA2Oi+w1Edq8HxZnSErEBLA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FC18B7@mb02.ads.tamu.edu>

Actually there are not so many matrices as you suggest.

> comb <- combn(28, 4)
> dim(comb)
[1]     4 20475
> sum(comb[1,]==1)
[1] 2925
> comb[, 1]
[1] 1 2 3 4

There are 20,475 combinations, but you cannot choose any four to make a 4x7 matrix since each value can be used only once. The combn() function returns the combinations sorted, so we can get the number of combinations that contain 1 with sum(comb[1,]==1) and that is 2,925. The set of 4x7 matrices cannot use the same combination more than once, so 2,925 is the maximum possible number of matrices and there may be fewer. As a first approach to finding them, you could take the first combination comb[, 1] which is 1, 2, 3, 4. Now add a second combination that does not include 1:4 and then a third combination that does not include any in the first two combinations and finally a fourth that does not include any in the first three combinations. Actually this is easy since we will just take 1:4, 5:8, 9:12, 13:16, 17:20, 21:24, 24:18.

> cols <- sapply(c(1, 5, 9, 13, 17, 21, 24), function(x)
+  head(which(comb[1,]==x), 1))
> cols
[1]     1  9850 15631 18656 19981 20406 20471
> comb[,cols]
     [,1] [,2] [,3] [,4] [,5] [,6] [,7]
[1,]    1    5    9   13   17   21   24
[2,]    2    6   10   14   18   22   25
[3,]    3    7   11   15   19   23   26
[4,]    4    8   12   16   20   24   27

But now it gets more complicated. While building the second matrix, we have to make sure that it does not use any combinations that have already been used.  Combinations used on earlier matrices may be necessary to complete later matrices and that is why the number of sets may be less than 2,925. This sequential approach would guarantee to obtain matrices meeting the OP's criteria, but would not necessarily produce the maximum number of matrices possible. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
Sent: Monday, December 15, 2014 9:23 AM
To: Kathryn Lord
Cc: r-help
Subject: Re: [R] create matrices with constraint

On Fri, Dec 12, 2014 at 11:00 AM, Kathryn Lord <kathryn.lord2000 at gmail.com>
wrote:

> Dear all,
>
> Suppose that I have natural numbers 1 through 28.
>
> Based on these numbers, choose 4 numbers 7 times without replacement and
> make a 4 by 7 matrix, for example,
>
>
?After a relaxing weekend, it came to me that these 4x7 matrices are really
just a subset of all the possible permutations of the vector 1:28, recast
as  4x7 matrices. Of course, there are factorial(28) (about 3*10^29 ) such
4x7 matrices. But given your constraints, I think that these can be
subsetted to only those permutations in which the values in each row are
sorted in ascending (or descending) order. I am fairly certain that this
subset would be exhaustive for your purposes. I not really certain how big
that subset would be. I think it would be 1/168th ( 1 out of 7*factorial(4)
) of the 3*10^29 permutations, or about 1.8*10^27. Which is still way to
big to actually instantiate all at once. You might be able store such a
thing in a huge data base. If you're lucky, you have access to a massive
supercomputer so that you can get the results before the heat death of this
universe. (exaggeration?)

Two R libraries seems to address this. One is combinat. The other is
permute.? The permute library seems, to me, to be the more likely
candidate. It contains a "how()" function which __appears to me__ to
perhaps be a way to subset the permutations as they are being generated.
But all that I get from reading the documentation is a bad headache. I
never studied combinatorics. And I got a milder headache trying to read the
Wikipedia article on it.

?I am curious about what you will do with such a set of matrices, once you
have them. If you are permitted to say.

-- 
?
While a transcendent vocabulary is laudable, one must be eternally careful
so that the calculated objective of communication does not become ensconced
in obscurity.  In other words, eschew obfuscation.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From john.archie.mckown at gmail.com  Mon Dec 15 17:10:48 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 15 Dec 2014 10:10:48 -0600
Subject: [R] create matrices with constraint
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FC18B7@mb02.ads.tamu.edu>
References: <CAMFx86xjCRUiqVXrUnEhF7VF0YAW-UEKTsE-Y=eRueMOnMcOwA@mail.gmail.com>
	<CAAJSdjhQo4cNpO_pJwhfC5tpeBsrA2Oi+w1Edq8HxZnSErEBLA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FC18B7@mb02.ads.tamu.edu>
Message-ID: <CAAJSdjjpCPVi=rBUkf1cnTR6nKkT0kKcqay1ATFbrQeXG_HKzw@mail.gmail.com>

On Mon, Dec 15, 2014 at 10:06 AM, David L Carlson <dcarlson at tamu.edu> wrote:

> Actually there are not so many matrices as you suggest.
>
> > comb <- combn(28, 4)
> > dim(comb)
> [1]     4 20475
> > sum(comb[1,]==1)
> [1] 2925
> > comb[, 1]
> [1] 1 2 3 4
>
> There are 20,475 combinations, but you cannot choose any four to make a
> 4x7 matrix since each value can be used only once. The combn() function
> returns the combinations sorted, so we can get the number of combinations
> that contain 1 with sum(comb[1,]==1) and that is 2,925. The set of 4x7
> matrices cannot use the same combination more than once, so 2,925 is the
> maximum possible number of matrices and there may be fewer. As a first
> approach to finding them, you could take the first combination comb[, 1]
> which is 1, 2, 3, 4. Now add a second combination that does not include 1:4
> and then a third combination that does not include any in the first two
> combinations and finally a fourth that does not include any in the first
> three combinations. Actually this is easy since we will just take 1:4, 5:8,
> 9:12, 13:16, 17:20, 21:24, 24:18.
>
> > cols <- sapply(c(1, 5, 9, 13, 17, 21, 24), function(x)
> +  head(which(comb[1,]==x), 1))
> > cols
> [1]     1  9850 15631 18656 19981 20406 20471
> > comb[,cols]
>      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
> [1,]    1    5    9   13   17   21   24
> [2,]    2    6   10   14   18   22   25
> [3,]    3    7   11   15   19   23   26
> [4,]    4    8   12   16   20   24   27
>
> But now it gets more complicated. While building the second matrix, we
> have to make sure that it does not use any combinations that have already
> been used.  Combinations used on earlier matrices may be necessary to
> complete later matrices and that is why the number of sets may be less than
> 2,925. This sequential approach would guarantee to obtain matrices meeting
> the OP's criteria, but would not necessarily produce the maximum number of
> matrices possible.
>

?Thanks. I was thinking that I was not on the right road, but just didn't
see what I was doing wrong. I appreciate the tutoring. And I'm bowing out
now because this is getting far beyond my expertise? both in math and R.


>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
-- 
?
While a transcendent vocabulary is laudable, one must be eternally careful
so that the calculated objective of communication does not become ensconced
in obscurity.  In other words, eschew obfuscation.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Dec 15 17:21:50 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 15 Dec 2014 16:21:50 +0000
Subject: [R] dotplot axes labelling
In-Reply-To: <72139ef2c4c932ec42d43066bfae96f6@openmailbox.org>
References: <72139ef2c4c932ec42d43066bfae96f6@openmailbox.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FC18D2@mb02.ads.tamu.edu>

You are very close. The argument scales(list(y=list())) supports multiple arguments for the y axis so you need to tell lattice how to use testylabels:

dotplot(testmatrix, scales=list(y=list(labels=testylabels), xlab=NULL))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of rl at openmailbox.org
Sent: Monday, December 15, 2014 10:03 AM
To: r-help at r-project.org
Subject: [R] dotplot axes labelling

Subscribers,

What is my mistake with the following example:

library(lattice)
testmatrix<-matrix(c(1,2,3,4,3,6,12,24),nrow=4,ncol=2)
testylabels<-c('w1','x1','y1','z1')
dotplot(testmatrix, scales=list(y=list(testylabels)), xlab=NULL)
#testylabels not shown, instead 'D' 'C' 'B' 'A'

Thanks in advance.

--

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From geoffrey_klein at etu.u-bourgogne.fr  Mon Dec 15 14:41:40 2014
From: geoffrey_klein at etu.u-bourgogne.fr (jeff6868)
Date: Mon, 15 Dec 2014 05:41:40 -0800 (PST)
Subject: [R] keep only the first value of a numeric sequence
In-Reply-To: <CAGx1TMBysdNA06spkw6UtZy=bbT2PHO4B-iuLg0HORCFyKV9Zw@mail.gmail.com>
References: <1418639604028-4700774.post@n4.nabble.com>
	<CAKL8G3EuewcpVYPc3a6fHNtWnhzGs7DwY-TPn_ecUqHJkHCSzQ@mail.gmail.com>
	<CAGx1TMBysdNA06spkw6UtZy=bbT2PHO4B-iuLg0HORCFyKV9Zw@mail.gmail.com>
Message-ID: <1418650900091-4700783.post@n4.nabble.com>

Great! Both ways works well for my whole data!

Thanks guys! 



--
View this message in context: http://r.789695.n4.nabble.com/keep-only-the-first-value-of-a-numeric-sequence-tp4700774p4700783.html
Sent from the R help mailing list archive at Nabble.com.


From acefix at rocketmail.com  Mon Dec 15 17:41:20 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Mon, 15 Dec 2014 16:41:20 +0000 (UTC)
Subject: [R] circlize package: different font size for axis labels
Message-ID: <1422864415.82490.1418661680583.JavaMail.yahoo@jws10727.mail.gq1.yahoo.com>

Hi, Dr. Gu,
I am trying to highlight some axis labels, for example, "72hL3" as bold, using the following command: 

circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f,
ylim=c(-1.3,1.8),track.height=0.5,panel.fun=function(x,y){circos.axis(major.at=c(2:6),minor.ticks=0,labels=c("L3","72hL3","72hL4","8dF","16dF"),labels.cex=0.8,major.tick.percentage=0.02,h="bottom",
direction="inside", labels.font=c(1,2,1,1,1,1))})Is there a way to do this using circlize package?
Thanks!

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Dec 15 18:19:37 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Dec 2014 17:19:37 +0000
Subject: [R] Comparing Latin characters with and without accents?
In-Reply-To: <E1727D7D-D1AB-440F-9DD6-4048DE5F6988@prodsyse.com>
References: <547AEDF1.5000305@structuremonitoring.com>	<1417343132.23112.37.camel@club.fr>	<547AF23C.60206@structuremonitoring.com>
	<E1727D7D-D1AB-440F-9DD6-4048DE5F6988@prodsyse.com>
Message-ID: <548F1829.4000706@stats.ox.ac.uk>

On 15/12/2014 05:33, Spencer Graves wrote:
> Hello, All:
>
>
> 	  What do people do to strip accents from latin characters, returning vanilla ASCII?

I think the devil is the detail here: what is Latin?  Latin-1 has 
characters for which this is unclear, let alone Latin-2 or Latin-7.

What I would do is

1) convert to UTF-8 with iconv()
2) convert to Unicode points with utf8ToInt().
3) remap the Unicode characters with an integer lookup table tab[].
4) convert back to UTF-8, then to the desired encoding (or mark as UTF-8 
with Encoding()).

As I suspect all the characters you do want to convert are in the first 
few planes of Unicode, the lookup table can be small, maybe less than 
512 elements.  So for example ? is Unicode 250 and the value of tab[250] 
should be 117.  iconv() with transliteration might give you a good start 
for preparing that table.

(Note that transliteration to two chars is often more acceptable/widely 
applicable. E.g. ? to aa and ? to ss.)

>
> 	  For example, I want to convert ?Ra?l? to ?Raul?.  Milan (below) suggested 'iconv(x, ?",  "ASCII//TRANSLIT?)?.  This worked under Windows but failed on Linux and Mac.  It?s part of the ?subNonStandardCharacters? function in the Ecfun package.  The development version on R-Forge uses this and returns ?Raul? under Windows and NA under Mac OS X (and something different from ?Raul?, presumably NA, under Linux).
>
>
> 	  Thanks,
> 	  Spencer
>
>
>> On Nov 30, 2014, at 2:32 AM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
>>
>> Wonderful.  Thanks very much.  Spencer
>>
>>
>> On 11/30/2014 2:25 AM, Milan Bouchet-Valat wrote:
>>> Le dimanche 30 novembre 2014 ? 02:14 -0800, Spencer Graves a ?crit :
>>>> Hello:
>>>>
>>>>
>>>>         How can one convert Latin characters with to the corresponding
>>>> characters without?  For example, I want to convert "?" to "u", similar
>>>> to how tolower('U') returns "u".
>>>>
>>>>
>>>>         This can be done using chartr{base}, e.g., chartr('?', 'u',
>>>> 'Ra?l') returns "Raul".  However, I wondered if a simpler version of
>>>> this is available.
>>> This appears to work:
>>>> iconv("?", "", "ASCII//TRANSLIT")
>>> [1] "u"
>>>
>>>
>>> Regards
>>>
>>>>         Thanks,
>>>>         Spencer
>>>>
>>>>
>>>> p.s.   findFn('convert to ascii') found 117 help pages in 70 packages.
>>>> A brief review identified two to "Convert to ASCII": ASCIIfy {gtools}
>>>> and stri_enc_toascii {stringi}.  Neither of these did what I expected.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From scoyoc at gmail.com  Mon Dec 15 18:08:27 2014
From: scoyoc at gmail.com (scoyoc)
Date: Mon, 15 Dec 2014 09:08:27 -0800 (PST)
Subject: [R] How do I interpret linear mixed model contrast estimates from
 multcomp::glht()?
Message-ID: <CALx9ERXSrFn_VitiwFYFKzngCGuhmdDyEdBfnk7BfQh8j9L0Yg@mail.gmail.com>

??
How do the rows in the summary (e.g. "1 == 0") correspond to the model? The
answer is buried *contrast::contrast()*, but I can't figure it out.
Consider this modified example I stole from here
<https://stat.ethz.ch/pipermail/r-sig-mixed-models/2009q4/003061.html>...

> options(contrasts = c(factor = "contr.SAS", ordered = "contr.poly"))
> library("mlmRev")
> library("lme4")
> library("lmerTest")
> library("contrast")
> library("multcomp")
>
> data("egsingle")
> # Linear mixed model
> math.lmm <- lmer(math ~ year * size + female + (1|childid) +
(1|schoolid), egsingle)
> # Linear model
> math.lm <- lm(math ~ year * size + female, data = egsingle)
> # Calculate contrast matrix
> cc<-contrast(math.lm, a = list(year = c(0.5, 1.5, 2.5), size = 380,
female = levels(egsingle$female)), +
                                                b = list(year = c(0.5, 1.5,
2.5), size = 800, female = levels(egsingle$female)))
> # Calculate estimates
> summary(glht(math.lmm, linfct = cc$X))

 Simultaneous Tests for General Linear Hypotheses

Fit: lme4::lmer(formula = math ~ year * size + female + (1 | childid) +
    (1 | schoolid), data = egsingle)

Linear Hypotheses:
              Estimate   Std. Error   z value   Pr(>|z|)
1 == 0  0.12774    0.08020     1.593     0.1272
2 == 0  0.15322    0.08066     1.900    0.0669 .
3 == 0  0.17870    0.08178     2.185    0.0341 *
4 == 0  0.12774    0.08020     1.593    0.1273
5 == 0  0.15322    0.08066     1.900    0.0669 .
6 == 0  0.17870    0.08178     2.185    0.0342 *
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
(Adjusted p values reported -- single-step method)

The row names correspond to the levels of *year* and *female,* and are
probably Female:0.5, Female:1.5, Female:2.5, and so on. But how do I pull
that out of the contrast() object *cc?* It might be simple with 3 fixed
effects, but my current project has 5 fixed effects, four 2-way
interactions, and one 3-way interaction, and the summary table has 24 rows.
Ultimately I would like to create a dataframe so I can plot the contrasts,
something like this...

> x = summary(glht(math.lmm, linfct = cc$X))
> # Contrast data frame
> math.contr = data.frame(Effect.Interaction = reference_something_in_cc,
                                                    Estimate =
x[["test"]]$coefficients, Std.Error = x[["test"]]$sigma)

Thanks for the help!
Cheers,
MVS
=====
Matthew Van Scoyoc

<mvanscoyoc at aggiemail.usu.edu>https://sites.google.com/site/scoyoc/
=====
Think SNOW!




-----
MVS
=====
Matthew Van Scoyoc
Graduate Research Assistant, Ecology
Wildland Resources Department & Ecology Center
Quinney College of Natural Resources
Utah State University
Logan, UT
=====
Think SNOW!


--
View this message in context: http://r.789695.n4.nabble.com/How-do-I-interpret-linear-mixed-model-contrast-estimates-from-multcomp-glht-tp4700797.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From dscheffy at gmail.com  Mon Dec 15 18:44:24 2014
From: dscheffy at gmail.com (Jeff Hansen)
Date: Mon, 15 Dec 2014 11:44:24 -0600
Subject: [R] Why would something work in R but not Rscript?
In-Reply-To: <CAFDcVCSjJw7r1h9wy7dsq8jK3f6rmc6=NnYeHvELHqY7cDgUGg@mail.gmail.com>
References: <CAA77SLsYwWgHH4OFom86mB2cbQKSktbSJ0hBjCPUeSjwO+zBHA@mail.gmail.com>
	<92E225E3-F038-4F18-AF69-AA284019A469@gmail.com>
	<CAFDcVCSjJw7r1h9wy7dsq8jK3f6rmc6=NnYeHvELHqY7cDgUGg@mail.gmail.com>
Message-ID: <CAA77SLscUAy8DWjWwLLK54L=qCVUeJSaZt6uzELZuHc8hUB6Sg@mail.gmail.com>

Thanks Henrik! Adding the line

library("methods")

to the list of required libraries did indeed solve the problem. My next
comment will show my naivety when it comes to R dependency management, but
I noticed that including `library("rJava")` in place of methods also solves
the problem. This confuses me because I would think that RWeka depends on
rJava so I don't understand why transitive dependencies wouldn't
automatically be loaded -- something for me to research more when I have
the chance.

Thanks for the help -- sadly it took me a month to see it as these
responses were automatically diverted to a folder using filter logic I set
up a few years ago and forgot about...

On Wed, Nov 19, 2014 at 2:57 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
wrote:

> When using Rscript, the 'methods' package is not loaded/attached by
> default, which it is when you use R.  See ?Rscript for details.  For
> any scripts intended for batch usage, the safest is to only assume
> that 'base' is attached, but nothing else.
>
> /Henrik
>
> On Wed, Nov 19, 2014 at 10:03 AM, Ben Tupper <ben.bighair at gmail.com>
> wrote:
> > Hi,
> >
> > On Nov 19, 2014, at 11:48 AM, Jeff Hansen <dscheffy at gmail.com> wrote:
> >
> >> I have a script that uses RWeka (and consequently rJava).  When I run
> >> it in Rstudio everything works fine. When I run it with `R CMD BATCH`,
> >> everything also works fine. However, when I run it with Rscript, I get
> >> the following error:
> >>
> >> Error in FUN(X[[1L]], ...) :
> >>  object is not a Java object reference (jobjRef/jarrayRef).
> >> Calls: evaluate_Weka_classifier -> t -> sapply -> lapply -> FUN
> >> Execution halted
> >>
> >> The following is a very simple toy script that you can run to produce
> >> the results:
> >>
> >> library("RWeka")
> >> result <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
> >> observation <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
> >> df <- data.frame(result,observation)
> >> j48 <- J48(result ~ .,data=df)
> >> evaluate_Weka_classifier(j48)
> >>
> >> Save that to a file called help.R and run
> >>
> >> R CMD BATCH help.R
> >>
> >> Check the output file help.Rout and you should see no errors. Now try
> >> running it from:
> >>
> >> Rscript help.R
> >>
> >
> > You might try using the the --vanilla option for each.  At least then
> you can rule out that something is being restored in the session of one but
> not the other.
> >
> > R --vanilla CMD BATCH help.R
> > Rscript --vanilla help.R
> >
> > Cheers,
> > Ben
> >
> >
> >> And you should see the error I've pasted above.
> >>
> >> I have consulted (and will continue to consult) the literature, but
> >> the manuals tend to answer how usage differs between the two commands
> >> rather than going into implementation details. I imagine there's a
> >> difference in how environments get loaded and I just need to adjust
> >> something on the Rscript side.
> >>
> >> I'm working on a Mac (OSX) running R 3.1.0, but I get the same results
> >> when I run everything from a Centos 6.4 virtual machine (headless)
> >> with R 3.1.1 installed.
> >>
> >> Thanks for any help!
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fabien.fivaz at unine.ch  Mon Dec 15 18:28:25 2014
From: fabien.fivaz at unine.ch (Fabien Fivaz)
Date: Mon, 15 Dec 2014 18:28:25 +0100
Subject: [R] No visible bindings and assignement to the global environment
Message-ID: <548F1A39.4010300@unine.ch>

Hi everyone,

I'm sure this question has been asked before, but I'm unable to find a 
definitive answer (if there is any). I've been trying to put back to 
CRAN a package (grasp-r). The package uses many functions that share a 
lot of common variables. For instance, a model call is created by the 
first function and then used through all the modeling process, some 
functions change it with :

/assign("MODELCALL", MODELCALL, envir = .GlobalEnv)/

some just use it without being explicitely called in the function 
arguments. The assignement is explicitely against  the CRAN policies (Do 
not alter the user's workspace). The use of variables raises a warning 
when building the package : "no visible binding for global variable 
?MODELCALL?".

BTW, the old school "double" assignement

/MODELCALL <<- MODELCALL/

works but raises a similar warning "no visible binding for '<<-' 
assignment to ?MODELCALL?" And I understand that it is also against CRAN 
policies to use the double assignement.

Many user groups, examples et al. point to R environments. I could 
create a new.env() in the first function (initializing function), and 
assign all subsequent variables to it. Something like
/
/dummy<-function (a) //
//{//
//    dummy.env <- new.env()//
//    assign("a", a, envir=dummy.env)//

//    return(dummy.env)//
//}/

/ and a call_that_variable_back function :/

/dummy2<-function () //
//{//
//    b<-get("a",envir=dummy.env)//
//    b//
//}//
/
/It works, except that I have to put a enormous sign saying : don't call 
your env anything else than dummy.env...

What do you use ? Is there a best practice for that type of problem ?

Thanks in advance for your help, best wishes
Fabien

-- 
Fabien Fivaz
Centre suisse de cartographie de la faune
Passage Max.-Meuron 6
CH - 2000 Neuch?tel
Switzerland

Tel. +41 32 725 72 57
fabien.fivaz at unine.chv

/", a, envir=dummy.env)//

//    return(dummy.env)//
//}/

and a call_that_variable_back function :

/dummy2<-function () //
//{//
//    b<-get("b",envir=dummy.env)//
//    b//
//}//
/
It works, except that I have to put a enormous sign saying : don't call 
your env anything else than dummy.env...

What do you use ? Is there a best practice for that type of problem ?

Thanks in advance for your help, best wishes
Fabien


-- 
Fabien Fivaz
Centre suisse de cartographie de la faune
Passage Max.-Meuron 6
CH - 2000 Neuch?tel
Switzerland

Tel. +41 32 725 72 57
fabien.fivaz at unine.chv


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Dec 15 19:47:20 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 15 Dec 2014 13:47:20 -0500
Subject: [R] No visible bindings and assignement to the global
	environment
In-Reply-To: <548F1A39.4010300@unine.ch>
References: <548F1A39.4010300@unine.ch>
Message-ID: <548F2CB8.1090805@gmail.com>

On 15/12/2014 12:28 PM, Fabien Fivaz wrote:
> Hi everyone,
>
> I'm sure this question has been asked before, but I'm unable to find a
> definitive answer (if there is any). I've been trying to put back to
> CRAN a package (grasp-r). The package uses many functions that share a
> lot of common variables. For instance, a model call is created by the
> first function and then used through all the modeling process, some
> functions change it with :
>
> /assign("MODELCALL", MODELCALL, envir = .GlobalEnv)/
>
> some just use it without being explicitely called in the function
> arguments. The assignement is explicitely against  the CRAN policies (Do
> not alter the user's workspace). The use of variables raises a warning
> when building the package : "no visible binding for global variable
> ?MODELCALL?".
>
> BTW, the old school "double" assignement
>
> /MODELCALL <<- MODELCALL/
>
> works but raises a similar warning "no visible binding for '<<-'
> assignment to ?MODELCALL?" And I understand that it is also against CRAN
> policies to use the double assignement.
>
> Many user groups, examples et al. point to R environments. I could
> create a new.env() in the first function (initializing function), and
> assign all subsequent variables to it. Something like
> /
> /dummy<-function (a) //
> //{//
> //    dummy.env <- new.env()//
> //    assign("a", a, envir=dummy.env)//
>
> //    return(dummy.env)//
> //}/
>
> / and a call_that_variable_back function :/
>
> /dummy2<-function () //
> //{//
> //    b<-get("a",envir=dummy.env)//
> //    b//
> //}//
> /
> /It works, except that I have to put a enormous sign saying : don't call
> your env anything else than dummy.env...
>
> What do you use ? Is there a best practice for that type of problem ?

It's not clear to me from your description how many of these 
environments you want.  Will a user potentially have more than one of 
them?  If so, then create it in the first call, and pass it explicitly 
to all other functions.  For example,

makeit <- function() new.env(parent=emptyenv())

fn1 <- function(env, ... ) { # get stuff from env using env$a, etc. }
fn2 <- function(env, ...)  { # ditto }

So your user would do something like this:

env1 <- makeit() # create the first one
fn1(env1, ...)      # use it

env2 <- makeit() # create another
fn1(env2, ...)   # use it

fn1(env1, ...) # use the first one again

On the other hand, maybe it only makes sense for one of these to ever 
exist.  Then you should create one for the package,
and just use that.  For example,

env <- new.env(parent = emptyenv())

fn1 <- function(...) { # get stuff from env using env$a, etc. }
fn2 <- function(...) { # ditto }

Users just call fn1 and fn2, and never need to even know about env.

Duncan Murdoch


From istazahn at gmail.com  Mon Dec 15 19:52:53 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 15 Dec 2014 13:52:53 -0500
Subject: [R] Comparing Latin characters with and without accents?
In-Reply-To: <E1727D7D-D1AB-440F-9DD6-4048DE5F6988@prodsyse.com>
References: <547AEDF1.5000305@structuremonitoring.com>
	<1417343132.23112.37.camel@club.fr>
	<547AF23C.60206@structuremonitoring.com>
	<E1727D7D-D1AB-440F-9DD6-4048DE5F6988@prodsyse.com>
Message-ID: <CA+vqiLGH3M_4=tbA1RHrXcAaeBc-Q2KZxj_fjW=rUXr9AXTa6Q@mail.gmail.com>

On Mon, Dec 15, 2014 at 12:33 AM, Spencer Graves
<spencer.graves at prodsyse.com> wrote:
> Hello, All:
>
>
>           What do people do to strip accents from latin characters, returning vanilla ASCII?

I find the stringi package works well for this sort of thing, e.g.,

library(stringi)
x <- c("!", "\"", "#", "$", "%", "&", "'", "(", ")", "*", "+", ",",
+ "-", ".", "/", "0", "1", "2", "3", "4", "5", "6", "7", "8", "9", ":",
+ ";", "<", "=", ">", "?", "@", "A", "B", "C", "D", "E", "F", "G", "H",
+ "I", "J", "K", "L", "M", "N", "O", "P", "Q", "R", "S", "T", "U", "V",
+ "W", "X", "Y", "Z", "[", "\\", "]", "^", "_", "`", "a", "b", "c", "d",
+ "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r",
+ "s", "t", "u", "v", "w", "x", "y", "z", "{", "|", "}", "~", "-", " ",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?",
+ "?", "?", "?", "?", "?", "?", "?", "?", "?", "?", "?")
> cbind(x, stri_trans_general(x, "Latin-ASCII"))

Best,
Ista
>
>
>           For example, I want to convert ?Ra?l? to ?Raul?.  Milan (below) suggested 'iconv(x, ?",  "ASCII//TRANSLIT?)?.  This worked under Windows but failed on Linux and Mac.  It?s part of the ?subNonStandardCharacters? function in the Ecfun package.  The development version on R-Forge uses this and returns ?Raul? under Windows and NA under Mac OS X (and something different from ?Raul?, presumably NA, under Linux).
>
>
>           Thanks,
>           Spencer
>
>
>> On Nov 30, 2014, at 2:32 AM, Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
>>
>> Wonderful.  Thanks very much.  Spencer
>>
>>
>> On 11/30/2014 2:25 AM, Milan Bouchet-Valat wrote:
>>> Le dimanche 30 novembre 2014 ? 02:14 -0800, Spencer Graves a ?crit :
>>>> Hello:
>>>>
>>>>
>>>>        How can one convert Latin characters with to the corresponding
>>>> characters without?  For example, I want to convert "?" to "u", similar
>>>> to how tolower('U') returns "u".
>>>>
>>>>
>>>>        This can be done using chartr{base}, e.g., chartr('?', 'u',
>>>> 'Ra?l') returns "Raul".  However, I wondered if a simpler version of
>>>> this is available.
>>> This appears to work:
>>>> iconv("?", "", "ASCII//TRANSLIT")
>>> [1] "u"
>>>
>>>
>>> Regards
>>>
>>>>        Thanks,
>>>>        Spencer
>>>>
>>>>
>>>> p.s.   findFn('convert to ascii') found 117 help pages in 70 packages.
>>>> A brief review identified two to "Convert to ASCII": ASCIIfy {gtools}
>>>> and stri_enc_toascii {stringi}.  Neither of these did what I expected.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Dec 15 20:08:22 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 15 Dec 2014 11:08:22 -0800
Subject: [R] circlize package: different font size for axis labels
In-Reply-To: <1422864415.82490.1418661680583.JavaMail.yahoo@jws10727.mail.gq1.yahoo.com>
References: <1422864415.82490.1418661680583.JavaMail.yahoo@jws10727.mail.gq1.yahoo.com>
Message-ID: <17E04FE1-4453-400A-BB3E-954EABC6E3B2@comcast.net>


On Dec 15, 2014, at 8:41 AM, Fix Ace wrote:

> Hi, Dr. Gu,
> I am trying to highlight some axis labels, for example, "72hL3" as bold, using the following command: 
> 
> circos.initialize(factors=female.f, xlim=c(1.8,6.2))
> circos.trackPlotRegion(factors=female.f,
> ylim=c(-1.3,1.8),track.height=0.5,panel.fun=function(x,y){circos.axis(major.at=c(2:6),minor.ticks=0,labels=c("L3","72hL3","72hL4","8dF","16dF"),labels.cex=0.8,major.tick.percentage=0.02,h="bottom",
> direction="inside", labels.font=c(1,2,1,1,1,1))})

That appears to be the sort of argument names that would suggest the underlying plot paradigm is base graphics. I would try this as the labels 'argument':

labels=epression("L3", "72hL3", bold(72hL4), "8dF", "16dF")

> Is there a way to do this using circlize package?
> Thanks!
> 
> 	[[alternative HTML version deleted]]

Please read what the Posting Guide says about HTML formatting.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From fabien.fivaz at unine.ch  Mon Dec 15 22:02:05 2014
From: fabien.fivaz at unine.ch (Fabien Fivaz)
Date: Mon, 15 Dec 2014 22:02:05 +0100
Subject: [R] No visible bindings and assignement to the global
	environment
In-Reply-To: <548F2CB8.1090805@gmail.com>
References: <548F1A39.4010300@unine.ch> <548F2CB8.1090805@gmail.com>
Message-ID: <548F4C4D.5090800@unine.ch>

Thanks for the quick answer. Your second guess was right, I only need 
one environment.

I learned one thing: I can create a .R file in my package that is NOT a 
function. Something that contains just

dummyEnv <- new-env(parent=emptyenv())

And it works!
Thanks again

Le 15. 12. 14 19:47, Duncan Murdoch a ?crit :
> On 15/12/2014 12:28 PM, Fabien Fivaz wrote:
>> Hi everyone,
>>
>> I'm sure this question has been asked before, but I'm unable to find a
>> definitive answer (if there is any). I've been trying to put back to
>> CRAN a package (grasp-r). The package uses many functions that share a
>> lot of common variables. For instance, a model call is created by the
>> first function and then used through all the modeling process, some
>> functions change it with :
>>
>> /assign("MODELCALL", MODELCALL, envir = .GlobalEnv)/
>>
>> some just use it without being explicitely called in the function
>> arguments. The assignement is explicitely against  the CRAN policies (Do
>> not alter the user's workspace). The use of variables raises a warning
>> when building the package : "no visible binding for global variable
>> ?MODELCALL?".
>>
>> BTW, the old school "double" assignement
>>
>> /MODELCALL <<- MODELCALL/
>>
>> works but raises a similar warning "no visible binding for '<<-'
>> assignment to ?MODELCALL?" And I understand that it is also against CRAN
>> policies to use the double assignement.
>>
>> Many user groups, examples et al. point to R environments. I could
>> create a new.env() in the first function (initializing function), and
>> assign all subsequent variables to it. Something like
>> /
>> /dummy<-function (a) //
>> //{//
>> //    dummy.env <- new.env()//
>> //    assign("a", a, envir=dummy.env)//
>>
>> //    return(dummy.env)//
>> //}/
>>
>> / and a call_that_variable_back function :/
>>
>> /dummy2<-function () //
>> //{//
>> //    b<-get("a",envir=dummy.env)//
>> //    b//
>> //}//
>> /
>> /It works, except that I have to put a enormous sign saying : don't call
>> your env anything else than dummy.env...
>>
>> What do you use ? Is there a best practice for that type of problem ?
>
> It's not clear to me from your description how many of these 
> environments you want.  Will a user potentially have more than one of 
> them?  If so, then create it in the first call, and pass it explicitly 
> to all other functions.  For example,
>
> makeit <- function() new.env(parent=emptyenv())
>
> fn1 <- function(env, ... ) { # get stuff from env using env$a, etc. }
> fn2 <- function(env, ...)  { # ditto }
>
> So your user would do something like this:
>
> env1 <- makeit() # create the first one
> fn1(env1, ...)      # use it
>
> env2 <- makeit() # create another
> fn1(env2, ...)   # use it
>
> fn1(env1, ...) # use the first one again
>
> On the other hand, maybe it only makes sense for one of these to ever 
> exist.  Then you should create one for the package,
> and just use that.  For example,
>
> env <- new.env(parent = emptyenv())
>
> fn1 <- function(...) { # get stuff from env using env$a, etc. }
> fn2 <- function(...) { # ditto }
>
> Users just call fn1 and fn2, and never need to even know about env.
>
> Duncan Murdoch

-- 
Fabien Fivaz
Centre suisse de cartographie de la faune
Passage Max.-Meuron 6
CH - 2000 Neuch?tel
Switzerland

Tel. +41 32 725 72 57
fabien.fivaz at unine.ch


From z.gu at dkfz-heidelberg.de  Mon Dec 15 20:38:27 2014
From: z.gu at dkfz-heidelberg.de (Gu, Zuguang)
Date: Mon, 15 Dec 2014 20:38:27 +0100
Subject: [R] circlize package: different font size for axis labels
In-Reply-To: <1422864415.82490.1418661680583.JavaMail.yahoo@jws10727.mail.gq1.yahoo.com>
References: <1422864415.82490.1418661680583.JavaMail.yahoo@jws10727.mail.gq1.yahoo.com>
Message-ID: <7E5BC755C53CF44499FF915DCCFF268801CB69782045@DKFZEX01.ad.dkfz-heidelberg.de>

Hi,

In current version, `labels.font` in `circos.axis` can only be a scalar ( a vector with length one).
But you can first add axes with no labels and then add labels by `circos.text`:

female.f = c("a", "b")
circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f, ylim=c(-1.3,1.8),track.height=0.5, panel.fun=function(x,y) {
        circos.axis(h = "top", major.at=c(2:6),minor.ticks=0,labels= rep("", 5),labels.cex=0.8,major.tick.percentage=0.02,
                direction="inside")
        circos.text(2:6, rep(1.5, 5), c("L3","72hL3","72hL4","8dF","16dF"), font = c(1, 2, 1, 1, 1), facing = "inside", niceFacing = TRUE)
})

best,
Zuguang
________________________________________
From: Fix Ace [acefix at rocketmail.com]
Sent: 15 December 2014 17:41
To: r-help at r-project.org; Gu, Zuguang
Subject: circlize package: different font size for axis labels

Hi, Dr. Gu,

I am trying to highlight some axis labels, for example, "72hL3" as bold, using the following command:


circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f,
ylim=c(-1.3,1.8),track.height=0.5,panel.fun=function(x,y){circos.axis(major.at=c(2:6),minor.ticks=0,labels=c("L3","72hL3","72hL4","8dF","16dF"),labels.cex=0.8,major.tick.percentage=0.02,h="bottom",
direction="inside", labels.font=c(1,2,1,1,1,1))})

Is there a way to do this using circlize package?

Thanks!

From macqueen1 at llnl.gov  Mon Dec 15 23:21:18 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 15 Dec 2014 22:21:18 +0000
Subject: [R] Assistance converting to R a python function that extracts
 from an XML file
In-Reply-To: <548CAA3A.5020102@ucdavis.edu>
References: <D0B1E339.115C03%macqueen1@llnl.gov> <548CAA3A.5020102@ucdavis.edu>
Message-ID: <D0B49B1F.115DBE%macqueen1@llnl.gov>

Duncan,

Thank you very much.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/13/14, 1:06 PM, "Duncan Temple Lang" <dtemplelang at ucdavis.edu> wrote:

>Hi Don
>
>library(XML)
>readxmldate = 
>function(xmlfile) 
>{
>  doc = xmlParse(xmlfile)
>  xpathSApply(doc, '//Esri/CreaDate | //Esri/CreaTime', xmlValue)
>}
>
> D.
>
>On 12/13/14, 12:36 PM, MacQueen, Don wrote:
>> I would appreciate assistance doing in R what a colleague has done in
>> python. Unfortunately (for me), I have almost no experience with either
>> python or xml.
>> 
>> Within an xml file there is
>>     <CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime>
>> and I need to extract those two values, 20120627 and 07322600
>> 
>> 
>> Here is the short python function. Even without knowing python, it's
>> conceptually clear what it does. I would like to do the same in R.
>> 
>> def readxmldate(xmlfile):
>> 	tree = ET.parse(xmlfile)
>> 	root = tree.getroot()
>> 	for lev1 in root.findall('Esri'):
>> 		xdate = lev1.find('CreaDate').text
>> 		xtime = lev1.find('CreaTime').text
>> 		return xdate, xtime
>> 
>> 
>> Thanks in advance
>> -Don
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Mon Dec 15 23:25:34 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 15 Dec 2014 22:25:34 +0000
Subject: [R] Assistance converting to R a python function that extracts
 from an XML file
In-Reply-To: <E5F42CED-9159-4F77-807C-366835E5B3E7@utoronto.ca>
References: <D0B1E339.115C03%macqueen1@llnl.gov> <548CAA3A.5020102@ucdavis.edu>
	<E5F42CED-9159-4F77-807C-366835E5B3E7@utoronto.ca>
Message-ID: <D0B49FD8.115E0F%macqueen1@llnl.gov>

Thanks!

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/13/14, 1:22 PM, "Boris Steipe" <boris.steipe at utoronto.ca> wrote:

>Or  ...
>
>txt <- 
>"<doc><CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime></doc>"
>
>if (!require(XML)) {
>	install.packages("XML")
>	library(XML)
>}
>
>
>result <- xmlParse(txt, asText=TRUE)
># or ... result <- xmlParse(your-file-here.xml)
>
>toString.XMLNode(getNodeSet(result,'//CreaDate/text()')[[1]])
>toString.XMLNode(getNodeSet(result,'//CreaTime/text()')[[1]])
>
>
>B.
>
>
>
>
>
>On Dec 13, 2014, at 4:06 PM, Duncan Temple Lang <dtemplelang at ucdavis.edu>
>wrote:
>
>> Hi Don
>> 
>> library(XML)
>> readxmldate = 
>> function(xmlfile)
>> {
>>  doc = xmlParse(xmlfile)
>>  xpathSApply(doc, '//Esri/CreaDate | //Esri/CreaTime', xmlValue)
>> }
>> 
>> D.
>> 
>> On 12/13/14, 12:36 PM, MacQueen, Don wrote:
>>> I would appreciate assistance doing in R what a colleague has done in
>>> python. Unfortunately (for me), I have almost no experience with either
>>> python or xml.
>>> 
>>> Within an xml file there is
>>>    <CreaDate>20120627</CreaDate><CreaTime>07322600</CreaTime>
>>> and I need to extract those two values, 20120627 and 07322600
>>> 
>>> 
>>> Here is the short python function. Even without knowing python, it's
>>> conceptually clear what it does. I would like to do the same in R.
>>> 
>>> def readxmldate(xmlfile):
>>> 	tree = ET.parse(xmlfile)
>>> 	root = tree.getroot()
>>> 	for lev1 in root.findall('Esri'):
>>> 		xdate = lev1.find('CreaDate').text
>>> 		xtime = lev1.find('CreaTime').text
>>> 		return xdate, xtime
>>> 
>>> 
>>> Thanks in advance
>>> -Don
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Tue Dec 16 00:51:21 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 15 Dec 2014 15:51:21 -0800
Subject: [R] Why would something work in R but not Rscript?
In-Reply-To: <CAA77SLscUAy8DWjWwLLK54L=qCVUeJSaZt6uzELZuHc8hUB6Sg@mail.gmail.com>
References: <CAA77SLsYwWgHH4OFom86mB2cbQKSktbSJ0hBjCPUeSjwO+zBHA@mail.gmail.com>
	<92E225E3-F038-4F18-AF69-AA284019A469@gmail.com>
	<CAFDcVCSjJw7r1h9wy7dsq8jK3f6rmc6=NnYeHvELHqY7cDgUGg@mail.gmail.com>
	<CAA77SLscUAy8DWjWwLLK54L=qCVUeJSaZt6uzELZuHc8hUB6Sg@mail.gmail.com>
Message-ID: <CAFDcVCSFRAome2Hq+bLe_MAXQQiPFbERUpqXyaVzCXZOGzE=UQ@mail.gmail.com>

On Mon, Dec 15, 2014 at 9:44 AM, Jeff Hansen <dscheffy at gmail.com> wrote:
> Thanks Henrik! Adding the line
>
> library("methods")
>
> to the list of required libraries did indeed solve the problem. My next
> comment will show my naivety when it comes to R dependency management, but I
> noticed that including `library("rJava")` in place of methods also solves
> the problem. This confuses me because I would think that RWeka depends on
> rJava so I don't understand why transitive dependencies wouldn't
> automatically be loaded -- something for me to research more when I have the
> chance.

The naming of field "Depends" in DESCRIPTION is a bit unfortunate and
misleading, since the package depends all all packages under "Depends"
and "Imports" on order for it to be loaded.  The reason for the name
is historical - it predates namespaces and was coined at a time when
"Imports" didn't exists.

If you look at http://cran.r-project.org/web/packages/RWeka/index.html,
 or packageDescription("RWeka"), you'll find that RWeka *imports*
rJava, but it does not *attach* it.  A package listed under "Depends"
will be *loaded* and *attached* whereas a package under "Imports" will
only be *loaded*.  An attached package makes its API available via
search() and therefore also to the user at the R prompt, whereas a
package that is only loaded, will not be available this way.

Next, since RWeka only lists rJava under Imports, rJava is only
*loaded*.  In turn, whatever package rJava depends on ("Depends" or
"Imports" etc) will only be *loaded*.  In other words, it does not
matter that rJava has "methods" under "Depends" - the latter will
still only be *loaded*.


EXAMPLE:

$ Rscript -e "library('RWeka'); sessionInfo()"
R Under development (unstable) (2014-12-10 r67152)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  base

other attached packages:
[1] RWeka_0.4-23

loaded via a namespace (and not attached):
[1] grid_3.2.0         methods_3.2.0      rJava_0.9-6        RWekajars_3.7.11-1
[5] tools_3.2.0

You can explicitly load (the namespace of a) package (emulating what
happens with Imports) by:

$: Rscript -e "loadNamespace('rJava'); sessionInfo()"
<environment: namespace:rJava>
R Under development (unstable) (2014-12-10 r67152)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  base

loaded via a namespace (and not attached):
[1] methods_3.2.0 rJava_0.9-6   tools_3.2.0

and compare it to when you attach a package:

Rscript -e "library('rJava'); sessionInfo()"

[HB-X201]{hb}: Rscript -e "library('rJava'); sessionInfo()"
Loading required package: methods
R Under development (unstable) (2014-12-10 r67152)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] methods   stats     graphics  grDevices utils     datasets  base

other attached packages:
[1] rJava_0.9-6

loaded via a namespace (and not attached):
[1] tools_3.2.0

Look at where 'methods' ends up.

/Henrik

>
> Thanks for the help -- sadly it took me a month to see it as these responses
> were automatically diverted to a folder using filter logic I set up a few
> years ago and forgot about...
>
> On Wed, Nov 19, 2014 at 2:57 PM, Henrik Bengtsson <hb at biostat.ucsf.edu>
> wrote:
>>
>> When using Rscript, the 'methods' package is not loaded/attached by
>> default, which it is when you use R.  See ?Rscript for details.  For
>> any scripts intended for batch usage, the safest is to only assume
>> that 'base' is attached, but nothing else.
>>
>> /Henrik
>>
>> On Wed, Nov 19, 2014 at 10:03 AM, Ben Tupper <ben.bighair at gmail.com>
>> wrote:
>> > Hi,
>> >
>> > On Nov 19, 2014, at 11:48 AM, Jeff Hansen <dscheffy at gmail.com> wrote:
>> >
>> >> I have a script that uses RWeka (and consequently rJava).  When I run
>> >> it in Rstudio everything works fine. When I run it with `R CMD BATCH`,
>> >> everything also works fine. However, when I run it with Rscript, I get
>> >> the following error:
>> >>
>> >> Error in FUN(X[[1L]], ...) :
>> >>  object is not a Java object reference (jobjRef/jarrayRef).
>> >> Calls: evaluate_Weka_classifier -> t -> sapply -> lapply -> FUN
>> >> Execution halted
>> >>
>> >> The following is a very simple toy script that you can run to produce
>> >> the results:
>> >>
>> >> library("RWeka")
>> >> result <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
>> >> observation <- c(TRUE,FALSE,TRUE,FALSE,TRUE)
>> >> df <- data.frame(result,observation)
>> >> j48 <- J48(result ~ .,data=df)
>> >> evaluate_Weka_classifier(j48)
>> >>
>> >> Save that to a file called help.R and run
>> >>
>> >> R CMD BATCH help.R
>> >>
>> >> Check the output file help.Rout and you should see no errors. Now try
>> >> running it from:
>> >>
>> >> Rscript help.R
>> >>
>> >
>> > You might try using the the --vanilla option for each.  At least then
>> > you can rule out that something is being restored in the session of one but
>> > not the other.
>> >
>> > R --vanilla CMD BATCH help.R
>> > Rscript --vanilla help.R
>> >
>> > Cheers,
>> > Ben
>> >
>> >
>> >> And you should see the error I've pasted above.
>> >>
>> >> I have consulted (and will continue to consult) the literature, but
>> >> the manuals tend to answer how usage differs between the two commands
>> >> rather than going into implementation details. I imagine there's a
>> >> difference in how environments get loaded and I just need to adjust
>> >> something on the Rscript side.
>> >>
>> >> I'm working on a Mac (OSX) running R 3.1.0, but I get the same results
>> >> when I run everything from a Centos 6.4 virtual machine (headless)
>> >> with R 3.1.1 installed.
>> >>
>> >> Thanks for any help!
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From wickedpuppy at gmail.com  Tue Dec 16 02:52:17 2014
From: wickedpuppy at gmail.com (billy am)
Date: Tue, 16 Dec 2014 09:52:17 +0800
Subject: [R] New to R
In-Reply-To: <D4EDE358-AE9A-47C3-9C78-7442E9CD0DF1@txbiomed.org>
References: <e5a164e0ab50499cbc0df121190a8abb@BLREXCHMBX001.TechMahindra.com>
	<D4EDE358-AE9A-47C3-9C78-7442E9CD0DF1@txbiomed.org>
Message-ID: <CAJ_FNV6Ej4vL5te+P07-_a6nxRCBqYh-7HUoo+oaSGsE8PtejA@mail.gmail.com>

Hi ,

As the OP was asking for examples , I would also recommend "Modeling
Techniques in Predictive Analytics" by Thomas Miller.

That book is full of examples + R scripts. Its on Amazon.

Regards
Billy


----------------------------------------------------------------------------------
|


http://billyam.com  || http://use-r.com  || http://shinyserver.com (BETA)

SAS Certified Base Programmer for SAS 9
Oracle SQL Expert(11g)




On Mon, Dec 15, 2014 at 11:26 PM, Mark Sharp <msharp at txbiomed.org> wrote:
>
> I would recommend finding some tutorials on line in areas that you enjoy,
> read http://r-bloggers.com every day, find introductory texts in the
> statistical areas of interest, and study some texts on R programming. I
> really enjoyed The Art of R Programming: A Tour of Statistical Software
> Design by Norman Matloff. For a bit more depth I like Hadley Wickham's
> Advanced R book (http://adv-r.had.co.nz).
>
> Mark Sharp
>
> R. Mark Sharp, Ph.D.
> Director of Primate Records Database
> Southwest National Primate Research Center
> Texas Biomedical Research Institute
> P.O. Box 760549
> San Antonio, TX 78245-0549
> Telephone: (210)258-9476
> e-mail: msharp at TxBiomed.org
>
> > On Dec 15, 2014, at 5:12 AM, Lalitha Kristipati <
> Lalitha.Kristipati at techmahindra.com> wrote:
> >
> > Hi
> >
> > I'm learning R language from  past  one month .As R is used highly for
> data analysis ,mining and modeling ,I want to know few real time examples
> in R in order to make my learning  fun filled and practical .Any quick
> suggestions  are appreciated .
> >
> >
> >
> > Regards,
> > Lalitha Kristipati
> > Associate Software Engineer
> >
> >
> >
> >
> >
> ============================================================================================================================
> > Disclaimer:  This message and the information contained herein is
> proprietary and confidential and subject to the Tech Mahindra policy
> statement, you may review the policy at
> http://www.techmahindra.com/Disclaimer.html externally
> http://tim.techmahindra.com/tim/disclaimer.html internally within
> TechMahindra.
> >
> ============================================================================================================================
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be
> legally privileged.  It is covered by the Electronic Communications Privacy
> Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are
> hereby notified that any retention, dissemination, distribution or copying
> of this communication is strictly prohibited.  Please reply to the sender
> that you have received this message in error, then delete it.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aps6dl at yahoo.com  Tue Dec 16 12:25:19 2014
From: aps6dl at yahoo.com (Aditya Singh)
Date: Tue, 16 Dec 2014 11:25:19 +0000 (UTC)
Subject: [R] Help sought with 1. converting factor to numeric;
 2. creating new dataframe
Message-ID: <475517902.776187.1418729119080.JavaMail.yahoo@jws10619.mail.bf1.yahoo.com>

Dear R-experts,

I am relatively new to R. Please help me in converting a dataframe into a numeric and then creating a new dataframe.

R-code attached:

my_xtrain=read.table("./train/X_train.txt") 
my_xtest=read.table("./test/X_test.txt") 
my_merge_data=merge(my_xtrain,my_xtest,all=TRUE) 


### my_merge_datad is a new dataframe in which I want my_merge_data to be numeric
my_merge_datad=as.numeric(as.character(my_merge_data),na.rm=TRUE) 


### my_m: I want to initialize a dataframe here
my_m=dat() 


for (i in 1: 561) {

## here in my_m[1,i] I want to store the mean of all the columns, 1 to 561  
      my_m[1,i]= mean(my_merge_data[,i]) 

## here in my_m[2,i] that is the second row of the new dataframe my_m I want to store the standard deviation of columns 1 to ##561
      my_m[2,i]=std(my_merge_data[,i]) 
}

Thanking you,
Aditya


From info at aghmed.fsnet.co.uk  Tue Dec 16 13:06:33 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 16 Dec 2014 12:06:33 +0000
Subject: [R] Help sought with 1. converting factor to numeric;
 2. creating new dataframe
In-Reply-To: <475517902.776187.1418729119080.JavaMail.yahoo@jws10619.mail.bf1.yahoo.com>
References: <475517902.776187.1418729119080.JavaMail.yahoo@jws10619.mail.bf1.yahoo.com>
Message-ID: <54902049.9020606@aghmed.fsnet.co.uk>

Comments in line

On 16/12/2014 11:25, Aditya Singh via R-help wrote:
> Dear R-experts,
>
> I am relatively new to R. Please help me in converting a dataframe into a numeric and then creating a new dataframe.
>
> R-code attached:
>
> my_xtrain=read.table("./train/X_train.txt")
> my_xtest=read.table("./test/X_test.txt")
> my_merge_data=merge(my_xtrain,my_xtest,all=TRUE)

Without knowing what is in x_train.txt and x_test.txt it is hard to be 
sure but you might be able to avoid the conversion to factors (assuming 
that is what happened by using stringsAsFactors = FALSE or as.is or 
setting colClasses.

?read.table may help here.

>
>
> ### my_merge_datad is a new dataframe in which I want my_merge_data to be numeric
> my_merge_datad=as.numeric(as.character(my_merge_data),na.rm=TRUE)
>
>
Probably unnecessary to intialise here.

> ### my_m: I want to initialize a dataframe here
> my_m=dat()
>
>

The loop is probably avoidable. Why not use apply on the columns?

mymean <- apply(my_merg_data, 2, mean)
and simlarly for the standard deviation
and then
my_m <- cbind(mymean, mysd)

Of course without the data I have not tested any of this and I may have 
misunderstood the problem but there may be enough hints here to get you 
started.

> for (i in 1: 561) {
>
> ## here in my_m[1,i] I want to store the mean of all the columns, 1 to 561
>        my_m[1,i]= mean(my_merge_data[,i])
>
> ## here in my_m[2,i] that is the second row of the new dataframe my_m I want to store the standard deviation of columns 1 to ##561
>        my_m[2,i]=std(my_merge_data[,i])
> }
>
> Thanking you,
> Aditya
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4253/8746 - Release Date: 12/16/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From dewolf.tim at hotmail.com  Tue Dec 16 08:47:07 2014
From: dewolf.tim at hotmail.com (Tim de Wolf)
Date: Tue, 16 Dec 2014 08:47:07 +0100
Subject: [R] =?windows-1256?q?Network_graph_google_maps=FE?=
Message-ID: <COL131-W564A3C0B3F02FF87D9E880826C0@phx.gbl>

Hello everybody. I am not sure if I am in the right forum for my question. If so, please let me know so I can go somewhere else! Thanks. Currently I am trying to familiarize myself with R. I am trying to plot some sort of Network graph (think of migration maps). Basically, I'd like to have an interactive map (via the google maps packages for R f.e.) of The Netherlands which has nodes and edges. However, I stumble upon some problems. I figured out how to create edges and nodes in R using the map function (this was quite the victory for me). R automatically creates a world map on which I can plot the data. But the world map is nowhere near as detailed as an interactive google map (via, f.e., gvisMap package). So I was looking for a way to get a google map, and plot data onto that, but I just can't seem to find a tutorial. I found this document, which shows several graphs, but none is a "network graph". The goal is to eventually connect it to shiny and be able to plot different kinds of network graphs based on input. I really need a tutorial as I am still a big noob in R :) So is there someone who is willing to help me find some sort of tutorial? Any help is much appreciated!

Tim 		 	   		  
	[[alternative HTML version deleted]]


From wolfgang.obermeier at geo.uni-marburg.de  Tue Dec 16 11:18:26 2014
From: wolfgang.obermeier at geo.uni-marburg.de (Wolfgang Obermeier)
Date: Tue, 16 Dec 2014 11:18:26 +0100
Subject: [R]  - PLS-Package - PLSR loadings
In-Reply-To: <72139ef2c4c932ec42d43066bfae96f6@openmailbox.org>
References: <72139ef2c4c932ec42d43066bfae96f6@openmailbox.org>
Message-ID: <549006F2.6000203@geo.uni-marburg.de>

Dear Subscribers,

how is it possible that the loadings of the second or even third 
component of a PLS-Analysis show higher values than the first component? 
Somebody got an idea??

Thanks in advance,

Wolfgang

-- 
Dipl. Geogr. Wolfgang Obermeier
Faculty of Geography
Philipps-University of Marburg
Deutschhausstr. 12
D-35032 Marburg

+49 (0)6421 28 24204


From christian.brandstaetter at tuwien.ac.at  Tue Dec 16 14:29:50 2014
From: christian.brandstaetter at tuwien.ac.at (=?iso-8859-1?Q?Brandst=E4tter_Christian?=)
Date: Tue, 16 Dec 2014 13:29:50 +0000
Subject: [R] issues with corner.label() from plotrix
Message-ID: <5488039E9207F6408AE2D36F469A6CD45A8CF960@mbx2.intern.tuwien.ac.at>

Dear Mr. Jim Lemon,

I tried to contact you via e-mail, but apparently it didn't work.
I enjoy using the function corner.label() a lot, since I tend to use multiplots.
However, recently I discovered two issues:
firstly, the parameter cex doesn't work; for this I was able to produce a simple workaround for myself;
I put in the function header of corner.label() "cex=1", and in the text-function below "cex=cex".
The second issue I couldn't fix; I produced a few log-scaled barplots (or plots)  and apparently the y-coordinates didn't turn out properly.

Example (R version 3.1.0, plotrix version 3.5-7)
barplot(sample(100),log="y")
corner.label(x=-1,y=1,"test",cex=15)

With best regards
Christian Brandst?tter


	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Dec 16 15:26:30 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 16 Dec 2014 15:26:30 +0100
Subject: [R] The R Foundation - New board
Message-ID: <21648.16662.859007.156817@stat.math.ethz.ch>

Dear R lovers and other useRs,
notably benefactors, donors, supporting members and institutions
of the R foundation 
       http://www.r-project.org/foundation/

About 11.7 years ago, in April 2003, the R Foundation was
announced by Fritz Leisch, 
  https://stat.ethz.ch/pipermail/r-announce/2003/000385.html
shortly after its foundation, and since then, its board has
lead the foundation during years of phenomenal growth and success.

Our thanks go to the *past* board members

   Presidents:	      	 Robert Gentleman, Ross Ihaka 
   Secretary General:    Friedrich Leisch 
   Treasurer:	      	 Kurt Hornik 
   Member at Large:      John Chambers 

In addition, Peter Dalgaard and Martin M?chler had acted as auditors.

After Summer meetings of the R Core and the R Foundation,
we, i.e., Robert Gentleman, on Sep. 15 announced
the new ("ordinary") memberships and the fact that the
membership of the foundation has grown to 29 persons:
    https://stat.ethz.ch/pipermail/r-announce/2014/000577.html

Subsequently (after a careful nomination and voting process),
the election of a new *board* finalized on December 1, and the
new board has started acting since.
It consists of

Presidents:        Duncan Murdoch, Martyn Plummer 
Secretary General: Martin M?chler 
Treasurer:         Kurt Hornik 
Members at Large:  John Chambers 
                   Brian Ripley
                   Dirk Eddelbuettel 

and the two auditors Peter Dalgaard and Roger Bivand.
This is very soon to be reflected on
    http://www.r-project.org/foundation/board.html


The foundation and its board aim to become considerably more
active in the future.  Details about this will be announced here
in due time. 

Thank you all for supporting the R project, a Free Software
(hence Open source) endeavor only made possible by the dedicated
work of many thousands of volunteers and their contributions in several ways, 
including to become supporting (or ++) members of the R foundation!

Martin Maechler

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From Bastien.Ferland-Raymond at mffp.gouv.qc.ca  Tue Dec 16 15:52:17 2014
From: Bastien.Ferland-Raymond at mffp.gouv.qc.ca (Bastien.Ferland-Raymond at mffp.gouv.qc.ca)
Date: Tue, 16 Dec 2014 09:52:17 -0500
Subject: [R] bad label change in step() from lmerTest package
Message-ID: <161DC602615F6943A19BAEA3DBF2E4B901BBDA9E3520@HARFANG.intranet.mrn.gouv>

Hello list,

I recently started working with the step() function in the lmerTest package and I notice a weird behavior that may be a bug.  The package perform stepwise selection of fixed and random effects, however when it discard the random variable because not significant, it changes the label of the dependant variable in the best model formula. 

Here is a reproducible example?:

### load de library?:
library(lmerTest)

###  data preparation
set.seed(1234)

## the Xs
x1 = rnorm(100,23,2)
x2 = rnorm(100,15,3)
x3 = rnorm(100,5,2)
x4 = rnorm(100,10,5)

## the dependant variable
dep = (2 * x1 +  rnorm(100,0,5)) + (-4 * x2 +  rnorm(100,0,1)) + (0.1 * x3 +  rnorm(100,0,3)) + (1 * x4 +  rnorm(100,0,8))

## the random variable, one good (significant) and one bad (not-significant)
good.random = as.character(cut(dep+rnorm(100,0,2),3, c("group1","group2","group3")))
bad.random = sample(c("group1","group2","group3"), 100, replace=T)

###  we make the starting models, one with the good and one with the bad random variable
mod.good <- lmer(dep ~ x1+x2+x3+x4+(1|good.random))
mod.bad  <-   lmer(dep ~ x1+x2+x3+x4+(1|bad.random))

### we do the stepwise selection
select.good <- step(mod.good) 		# should keep the random variable
select.bad <- step(mod.bad)			# should remove the random variable

###  The label of the dependant variable change between model where the random effect was removed and the one where it was kept.
formula(select.good$model)
# output?: dep ~ x1 + x2 + x4 + (1 | good.random)
# it's what it's suppose to be?: dep ~

formula(select.bad$model)
#output?: y ~ x1 + x2 + x3 + x4
# here, it's change by?: y ~
### end code

This is problematic when you're doing automatic model selection.  Is it an option that I missed or a bug?
Also, it's interesting to notice that the stepwise selection of the model with the bad random variable didn't remove the variable x3 which is clearly not significant.  So I wonder if the function is doing selection of fixed effects after having removed the random effects.

Thanks,



Bastien Ferland-Raymond, M.Sc. Stat., M.Sc.?Biol.
Division des orientations et projets sp?ciaux
Direction des inventaires forestiers
Minist?re des For?ts, de la Faune et des Parcs?


From chandratr at gmail.com  Tue Dec 16 15:26:30 2014
From: chandratr at gmail.com (Chandrasekhar Rudrappa)
Date: Tue, 16 Dec 2014 19:56:30 +0530
Subject: [R] Help specifying a non-linear model in nlsLM()
Message-ID: <CAMSabZShR-R1FYNn+bCHzjESO+fMHQajPF8tNx_Z0Pp9__HE3w@mail.gmail.com>

Dear All,

I am trying to fit the following model in nlsLM():

fn5 <- function(x, T, t1, w_inf, Lt0){
S<-function(x, T, t1){
x+(1-T)/(2*pi)*sin(2*pi*(x-t1)/(1-T))
}
F <- function(x, T, t1){
t2 <- t1 + (1-T)/2
t3 <- t1 + (1+T)/2
t.factorial <- x%%1
floor(x)*(1-T) + S(t.factorial, T, t1)*(0<=t.factorial & t.factorial<t2) +
S(t2, T, t1)*(t2<=t.factorial & t.factorial<t3) +
S(t.factorial-T, T, t1)*(t3<=t.factorial & t.factorial<1)
}
return(w_inf - (w_inf - Lt0)*exp(-(2/30)*(F(x,T,t1)-F(7,T,t1))))
}
fn6<- y~fn5(x, T, t1, w_inf, Lt0)
startval<-c(x=x, T=0.035, t1=0.359, w_inf=135, Lt0=47)
(nlsktm1 <- nlsLM(fn6, start=startval, lower=c(x=x, T=0.0135, t1=0.259,
w_inf=131, Lt0=41), jac=NULL, trace=T, data=ktm,
control=nls.control(maxiter=10)))

When I run the above script, the following error is displayed:

Error in nlsModel(formula, mf, start, wts) :
  singular gradient matrix at initial parameter estimates
In addition: Warning message:
In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower =
lower,  :
  lmdif: info = 0. Improper input parameters.

Suitable help is requested.
-- 
Dr. TR Chandrasekhar, M.Sc., M. Tech., Ph. D.,
Sr. Scientist
Rubber Research Institute of India
Hevea Breeding Sub Station
Kadaba - 574 221
DK Dt., Karnataka
Phone-Land: 08251-214336
Mobile: 9448780118

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Dec 16 17:24:45 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 16 Dec 2014 08:24:45 -0800
Subject: [R] Help specifying a non-linear model in nlsLM()
In-Reply-To: <CAMSabZShR-R1FYNn+bCHzjESO+fMHQajPF8tNx_Z0Pp9__HE3w@mail.gmail.com>
References: <CAMSabZShR-R1FYNn+bCHzjESO+fMHQajPF8tNx_Z0Pp9__HE3w@mail.gmail.com>
Message-ID: <CACk-te30269-jbC4rOh24WhyCV2MrsoRQceKUrn+VzhVuRm9fA@mail.gmail.com>

Suitable help may not be possible. I suspect that either your
function/code is funky (is the function smooth, non-infinite near your
starting value?) or you are overparameterized. If the latter, the
remedy may depend on the nature of your data, which you have not
shared.

While you may receive some help here (there are some pretty smart
optimizers who monitor the list), I suggest you try a statistical site
like stats.stackexchange.com for help, as this appears to be primarily
a statistics issue, not an R programming one.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Dec 16, 2014 at 6:26 AM, Chandrasekhar Rudrappa
<chandratr at gmail.com> wrote:
> Dear All,
>
> I am trying to fit the following model in nlsLM():
>
> fn5 <- function(x, T, t1, w_inf, Lt0){
> S<-function(x, T, t1){
> x+(1-T)/(2*pi)*sin(2*pi*(x-t1)/(1-T))
> }
> F <- function(x, T, t1){
> t2 <- t1 + (1-T)/2
> t3 <- t1 + (1+T)/2
> t.factorial <- x%%1
> floor(x)*(1-T) + S(t.factorial, T, t1)*(0<=t.factorial & t.factorial<t2) +
> S(t2, T, t1)*(t2<=t.factorial & t.factorial<t3) +
> S(t.factorial-T, T, t1)*(t3<=t.factorial & t.factorial<1)
> }
> return(w_inf - (w_inf - Lt0)*exp(-(2/30)*(F(x,T,t1)-F(7,T,t1))))
> }
> fn6<- y~fn5(x, T, t1, w_inf, Lt0)
> startval<-c(x=x, T=0.035, t1=0.359, w_inf=135, Lt0=47)
> (nlsktm1 <- nlsLM(fn6, start=startval, lower=c(x=x, T=0.0135, t1=0.259,
> w_inf=131, Lt0=41), jac=NULL, trace=T, data=ktm,
> control=nls.control(maxiter=10)))
>
> When I run the above script, the following error is displayed:
>
> Error in nlsModel(formula, mf, start, wts) :
>   singular gradient matrix at initial parameter estimates
> In addition: Warning message:
> In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower =
> lower,  :
>   lmdif: info = 0. Improper input parameters.
>
> Suitable help is requested.
> --
> Dr. TR Chandrasekhar, M.Sc., M. Tech., Ph. D.,
> Sr. Scientist
> Rubber Research Institute of India
> Hevea Breeding Sub Station
> Kadaba - 574 221
> DK Dt., Karnataka
> Phone-Land: 08251-214336
> Mobile: 9448780118
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Tue Dec 16 17:16:23 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 16 Dec 2014 16:16:23 +0000 (UTC)
Subject: [R] circlize package: different font size for axis labels
In-Reply-To: <7E5BC755C53CF44499FF915DCCFF268801CB69782045@DKFZEX01.ad.dkfz-heidelberg.de>
References: <7E5BC755C53CF44499FF915DCCFF268801CB69782045@DKFZEX01.ad.dkfz-heidelberg.de>
Message-ID: <1516140701.213876.1418746583685.JavaMail.yahoo@jws10730.mail.gq1.yahoo.com>

Hi, Dr. Gu,
Thank you very much for the answer. This trick works.?
Another question, is there a way to change the color or the axis?
Thanks!
 

     On Monday, December 15, 2014 1:39 PM, "Gu, Zuguang" <z.gu at dkfz-heidelberg.de> wrote:
   

 Hi,

In current version, `labels.font` in `circos.axis` can only be a scalar ( a vector with length one).
But you can first add axes with no labels and then add labels by `circos.text`:

female.f = c("a", "b")
circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f, ylim=c(-1.3,1.8),track.height=0.5, panel.fun=function(x,y) {
? ? ? ? circos.axis(h = "top", major.at=c(2:6),minor.ticks=0,labels= rep("", 5),labels.cex=0.8,major.tick.percentage=0.02,
? ? ? ? ? ? ? ? direction="inside")
? ? ? ? circos.text(2:6, rep(1.5, 5), c("L3","72hL3","72hL4","8dF","16dF"), font = c(1, 2, 1, 1, 1), facing = "inside", niceFacing = TRUE)
})

best,
Zuguang
________________________________________

Sent: 15 December 2014 17:41
To: r-help at r-project.org; Gu, Zuguang
Subject: circlize package: different font size for axis labels

Hi, Dr. Gu,

I am trying to highlight some axis labels, for example, "72hL3" as bold, using the following command:


circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f,
ylim=c(-1.3,1.8),track.height=0.5,panel.fun=function(x,y){circos.axis(major.at=c(2:6),minor.ticks=0,labels=c("L3","72hL3","72hL4","8dF","16dF"),labels.cex=0.8,major.tick.percentage=0.02,h="bottom",
direction="inside", labels.font=c(1,2,1,1,1,1))})

Is there a way to do this using circlize package?

Thanks!

   
	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Tue Dec 16 17:17:02 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 16 Dec 2014 16:17:02 +0000 (UTC)
Subject: [R] circlize package: different font size for axis labels
In-Reply-To: <7E5BC755C53CF44499FF915DCCFF268801CB69782045@DKFZEX01.ad.dkfz-heidelberg.de>
References: <7E5BC755C53CF44499FF915DCCFF268801CB69782045@DKFZEX01.ad.dkfz-heidelberg.de>
Message-ID: <612891328.212972.1418746622947.JavaMail.yahoo@jws10741.mail.gq1.yahoo.com>

I was trying to ask if there is way to change the color of the axis...
Thanks! 

     On Monday, December 15, 2014 1:39 PM, "Gu, Zuguang" <z.gu at dkfz-heidelberg.de> wrote:
   

 Hi,

In current version, `labels.font` in `circos.axis` can only be a scalar ( a vector with length one).
But you can first add axes with no labels and then add labels by `circos.text`:

female.f = c("a", "b")
circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f, ylim=c(-1.3,1.8),track.height=0.5, panel.fun=function(x,y) {
? ? ? ? circos.axis(h = "top", major.at=c(2:6),minor.ticks=0,labels= rep("", 5),labels.cex=0.8,major.tick.percentage=0.02,
? ? ? ? ? ? ? ? direction="inside")
? ? ? ? circos.text(2:6, rep(1.5, 5), c("L3","72hL3","72hL4","8dF","16dF"), font = c(1, 2, 1, 1, 1), facing = "inside", niceFacing = TRUE)
})

best,
Zuguang
________________________________________

Sent: 15 December 2014 17:41
To: r-help at r-project.org; Gu, Zuguang
Subject: circlize package: different font size for axis labels

Hi, Dr. Gu,

I am trying to highlight some axis labels, for example, "72hL3" as bold, using the following command:


circos.initialize(factors=female.f, xlim=c(1.8,6.2))
circos.trackPlotRegion(factors=female.f,
ylim=c(-1.3,1.8),track.height=0.5,panel.fun=function(x,y){circos.axis(major.at=c(2:6),minor.ticks=0,labels=c("L3","72hL3","72hL4","8dF","16dF"),labels.cex=0.8,major.tick.percentage=0.02,h="bottom",
direction="inside", labels.font=c(1,2,1,1,1,1))})

Is there a way to do this using circlize package?

Thanks!

   
	[[alternative HTML version deleted]]


From robert.wood at adelphigroup.com  Tue Dec 16 17:04:45 2014
From: robert.wood at adelphigroup.com (Rob Wood)
Date: Tue, 16 Dec 2014 08:04:45 -0800 (PST)
Subject: [R] GenMatch providing different results
Message-ID: <1418745885175-4700836.post@n4.nabble.com>

Hi there,

I'm performing some propensity score matching in R, where I am using
GenMatch() to generate a weight matrix for the covariates, before plugging
that into Match(). However, I keep on getting different results each time I
run the code. I'm using int.seed and unif.seed in GenMatch, but to no avail.
I've also noticed that when I just use Match() without previously using
GenMatch(), the results are consistent each time, which is why I believe
GenMatch() is causing the problem:

A slight extract of my code looks like this:

######Genetic Matching
gmatch <- GenMatch(Tr=treatment, X=X, estimand="ATT", M=1, pop.size=50,
max.generations=15, wait.generations=5, caliper=0.05, ties=FALSE,
int.seed=240690, unif.seed=021189)
  
###Actual matching
 match <- Match(Y=outcome, Tr=treatment, X=X, estimand="ATT",
Weight.matrix=gmatch)

summary(match)

Can anyone point me in the right direction to diagnose my problem?

Thanks,

Rob.
  



--
View this message in context: http://r.789695.n4.nabble.com/GenMatch-providing-different-results-tp4700836.html
Sent from the R help mailing list archive at Nabble.com.


From emptican at gmail.com  Tue Dec 16 18:06:05 2014
From: emptican at gmail.com (SH)
Date: Tue, 16 Dec 2014 12:06:05 -0500
Subject: [R] Extract values from multiple lists
Message-ID: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>

Dear List,

I hope this posting is not redundant.  I have several list outputs with the
same components.  I ran a function with three different scenarios below
(e.g., scen1, scen2, and scen3,...,scenN).  I would like to extract the
same components and group them as a data frame.  For example,
pop.inf.r1 <- scen1[['pop.inf.r']]
pop.inf.r2 <- scen2[['pop.inf.r']]
pop.inf.r3 <- scen3[['pop.inf.r']]
...
pop.inf.rN<-scenN[['pop.inf.r']]
new.df <- data.frame(pop.inf.r1, pop.inf.r2, pop.inf.r3,...,pop.inf.rN)

My final output would be 'new.df'.  Could you help me how I can do that
efficiently?

Thanks in advance,

Steve

P.S.:  Below are some examples of summary outputs.


> summary(scen1)
                Length Class  Mode
aql                1   -none- numeric
rql                1   -none- numeric
alpha              1   -none- numeric
beta               1   -none- numeric
n.sim              1   -none- numeric
N                  1   -none- numeric
n.sample           1   -none- numeric
n.acc              1   -none- numeric
lot.inf.r          1   -none- numeric
pop.inf.n       2000   -none- list
pop.inf.r       2000   -none- list
pop.decision.t1 2000   -none- list
pop.decision.t2 2000   -none- list
sp.inf.n        2000   -none- list
sp.inf.r        2000   -none- list
sp.decision     2000   -none- list
> summary(scen2)
                Length Class  Mode
aql                1   -none- numeric
rql                1   -none- numeric
alpha              1   -none- numeric
beta               1   -none- numeric
n.sim              1   -none- numeric
N                  1   -none- numeric
n.sample           1   -none- numeric
n.acc              1   -none- numeric
lot.inf.r          1   -none- numeric
pop.inf.n       2000   -none- list
pop.inf.r       2000   -none- list
pop.decision.t1 2000   -none- list
pop.decision.t2 2000   -none- list
sp.inf.n        2000   -none- list
sp.inf.r        2000   -none- list
sp.decision     2000   -none- list
> summary(scen3)
                Length Class  Mode
aql                1   -none- numeric
rql                1   -none- numeric
alpha              1   -none- numeric
beta               1   -none- numeric
n.sim              1   -none- numeric
N                  1   -none- numeric
n.sample           1   -none- numeric
n.acc              1   -none- numeric
lot.inf.r          1   -none- numeric
pop.inf.n       2000   -none- list
pop.inf.r       2000   -none- list
pop.decision.t1 2000   -none- list
pop.decision.t2 2000   -none- list
sp.inf.n        2000   -none- list
sp.inf.r        2000   -none- list
sp.decision     2000   -none- list

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Dec 16 19:33:29 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 16 Dec 2014 18:33:29 +0000
Subject: [R] Extract values from multiple lists
In-Reply-To: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
References: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FC1DBB@mb02.ads.tamu.edu>

Something like

scens <- paste0("scen", 1:N)
new.df <- data.frame(sapply(scens, function(x) get(x)[["pop.inf.r"]]))

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of SH
Sent: Tuesday, December 16, 2014 11:06 AM
To: r-help
Subject: [R] Extract values from multiple lists

Dear List,

I hope this posting is not redundant.  I have several list outputs with the
same components.  I ran a function with three different scenarios below
(e.g., scen1, scen2, and scen3,...,scenN).  I would like to extract the
same components and group them as a data frame.  For example,
pop.inf.r1 <- scen1[['pop.inf.r']]
pop.inf.r2 <- scen2[['pop.inf.r']]
pop.inf.r3 <- scen3[['pop.inf.r']]
...
pop.inf.rN<-scenN[['pop.inf.r']]
new.df <- data.frame(pop.inf.r1, pop.inf.r2, pop.inf.r3,...,pop.inf.rN)

My final output would be 'new.df'.  Could you help me how I can do that
efficiently?

Thanks in advance,

Steve

P.S.:  Below are some examples of summary outputs.


> summary(scen1)
                Length Class  Mode
aql                1   -none- numeric
rql                1   -none- numeric
alpha              1   -none- numeric
beta               1   -none- numeric
n.sim              1   -none- numeric
N                  1   -none- numeric
n.sample           1   -none- numeric
n.acc              1   -none- numeric
lot.inf.r          1   -none- numeric
pop.inf.n       2000   -none- list
pop.inf.r       2000   -none- list
pop.decision.t1 2000   -none- list
pop.decision.t2 2000   -none- list
sp.inf.n        2000   -none- list
sp.inf.r        2000   -none- list
sp.decision     2000   -none- list
> summary(scen2)
                Length Class  Mode
aql                1   -none- numeric
rql                1   -none- numeric
alpha              1   -none- numeric
beta               1   -none- numeric
n.sim              1   -none- numeric
N                  1   -none- numeric
n.sample           1   -none- numeric
n.acc              1   -none- numeric
lot.inf.r          1   -none- numeric
pop.inf.n       2000   -none- list
pop.inf.r       2000   -none- list
pop.decision.t1 2000   -none- list
pop.decision.t2 2000   -none- list
sp.inf.n        2000   -none- list
sp.inf.r        2000   -none- list
sp.decision     2000   -none- list
> summary(scen3)
                Length Class  Mode
aql                1   -none- numeric
rql                1   -none- numeric
alpha              1   -none- numeric
beta               1   -none- numeric
n.sim              1   -none- numeric
N                  1   -none- numeric
n.sample           1   -none- numeric
n.acc              1   -none- numeric
lot.inf.r          1   -none- numeric
pop.inf.n       2000   -none- list
pop.inf.r       2000   -none- list
pop.decision.t1 2000   -none- list
pop.decision.t2 2000   -none- list
sp.inf.n        2000   -none- list
sp.inf.r        2000   -none- list
sp.decision     2000   -none- list

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From toth.denes at ttk.mta.hu  Tue Dec 16 21:42:47 2014
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Tue, 16 Dec 2014 21:42:47 +0100
Subject: [R] Extract values from multiple lists
In-Reply-To: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
References: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
Message-ID: <54909947.6030304@ttk.mta.hu>



On 12/16/2014 06:06 PM, SH wrote:
> Dear List,
>
> I hope this posting is not redundant.  I have several list outputs with the
> same components.  I ran a function with three different scenarios below
> (e.g., scen1, scen2, and scen3,...,scenN).  I would like to extract the
> same components and group them as a data frame.  For example,
> pop.inf.r1 <- scen1[['pop.inf.r']]
> pop.inf.r2 <- scen2[['pop.inf.r']]
> pop.inf.r3 <- scen3[['pop.inf.r']]
> ...
> pop.inf.rN<-scenN[['pop.inf.r']]
> new.df <- data.frame(pop.inf.r1, pop.inf.r2, pop.inf.r3,...,pop.inf.rN)
>
> My final output would be 'new.df'.  Could you help me how I can do that
> efficiently?

If efficiency is of concern, do not use data.frame() but create a list 
and add the required attributes with data.table::setattr (the setattr 
function of the data.table package). (You can also consider creating a 
data.table instead of a data.frame.)

# some largish lists
a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
a3 <- list(x = rnorm(1e6), y = rnorm(1e6))

# amount of memory allocated
gc(reset=TRUE)

# get names of the objects
out_names <- ls(pattern="a[[:digit:]]$")

# create a list
out <- lapply(lapply(out_names, get), "[[", "x")

# note that no copying occured
gc()

# decorate the list
data.table::setattr(out, "names", out_names)
data.table::setattr(out, "row.names", seq_along(out[[1]]))
class(out) <- "data.frame"

# still no copy
gc()

# output
head(out)


HTH,
   Denes


>
> Thanks in advance,
>
> Steve
>
> P.S.:  Below are some examples of summary outputs.
>
>
>> summary(scen1)
>                  Length Class  Mode
> aql                1   -none- numeric
> rql                1   -none- numeric
> alpha              1   -none- numeric
> beta               1   -none- numeric
> n.sim              1   -none- numeric
> N                  1   -none- numeric
> n.sample           1   -none- numeric
> n.acc              1   -none- numeric
> lot.inf.r          1   -none- numeric
> pop.inf.n       2000   -none- list
> pop.inf.r       2000   -none- list
> pop.decision.t1 2000   -none- list
> pop.decision.t2 2000   -none- list
> sp.inf.n        2000   -none- list
> sp.inf.r        2000   -none- list
> sp.decision     2000   -none- list
>> summary(scen2)
>                  Length Class  Mode
> aql                1   -none- numeric
> rql                1   -none- numeric
> alpha              1   -none- numeric
> beta               1   -none- numeric
> n.sim              1   -none- numeric
> N                  1   -none- numeric
> n.sample           1   -none- numeric
> n.acc              1   -none- numeric
> lot.inf.r          1   -none- numeric
> pop.inf.n       2000   -none- list
> pop.inf.r       2000   -none- list
> pop.decision.t1 2000   -none- list
> pop.decision.t2 2000   -none- list
> sp.inf.n        2000   -none- list
> sp.inf.r        2000   -none- list
> sp.decision     2000   -none- list
>> summary(scen3)
>                  Length Class  Mode
> aql                1   -none- numeric
> rql                1   -none- numeric
> alpha              1   -none- numeric
> beta               1   -none- numeric
> n.sim              1   -none- numeric
> N                  1   -none- numeric
> n.sample           1   -none- numeric
> n.acc              1   -none- numeric
> lot.inf.r          1   -none- numeric
> pop.inf.n       2000   -none- list
> pop.inf.r       2000   -none- list
> pop.decision.t1 2000   -none- list
> pop.decision.t2 2000   -none- list
> sp.inf.n        2000   -none- list
> sp.inf.r        2000   -none- list
> sp.decision     2000   -none- list
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Wed Dec 17 01:46:16 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 16 Dec 2014 16:46:16 -0800 (PST)
Subject: [R] Extract values from multiple lists
In-Reply-To: <54909947.6030304@ttk.mta.hu>
References: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
	<54909947.6030304@ttk.mta.hu>
Message-ID: <alpine.BSF.2.00.1412161636060.44925@pedal.dcn.davis.ca.us>

You are chasing ghosts of performance past, Denes. The data.frame 
function causes no problems, and if it is used then the OP would not need 
to presume they know the internal structure of the data frame.
See below. (I am using R3.1.2.)

a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
a3 <- list(x = rnorm(1e6), y = rnorm(1e6))

# get names of the objects
out_names <- ls(pattern="a[[:digit:]]$")

# amount of memory allocated
gc(reset=TRUE)

# Explicitly call data frame
out2 <- data.frame( a1=a1[["x"]], a2=a2[["x"]], a3=a3[["x"]] )

# No copying.
gc()

# Your suggested retreival method
out3a <- lapply( lapply( out_names, get ), "[[", "x" )
names( out3a ) <- out_names
# The "obvious" way to finish the job works fine.
out3 <- do.call( data.frame, out3a )

# No copying... well, you do end up with a new list in out3, but the data 
itself doesn't get copied.
gc()


On Tue, 16 Dec 2014, D?nes T?th wrote:

> On 12/16/2014 06:06 PM, SH wrote:
>> Dear List,
>> 
>> I hope this posting is not redundant.  I have several list outputs with the
>> same components.  I ran a function with three different scenarios below
>> (e.g., scen1, scen2, and scen3,...,scenN).  I would like to extract the
>> same components and group them as a data frame.  For example,
>> pop.inf.r1 <- scen1[['pop.inf.r']]
>> pop.inf.r2 <- scen2[['pop.inf.r']]
>> pop.inf.r3 <- scen3[['pop.inf.r']]
>> ...
>> pop.inf.rN<-scenN[['pop.inf.r']]
>> new.df <- data.frame(pop.inf.r1, pop.inf.r2, pop.inf.r3,...,pop.inf.rN)
>> 
>> My final output would be 'new.df'.  Could you help me how I can do that
>> efficiently?
>
> If efficiency is of concern, do not use data.frame() but create a list and 
> add the required attributes with data.table::setattr (the setattr function of 
> the data.table package). (You can also consider creating a data.table instead 
> of a data.frame.)
>
> # some largish lists
> a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
> a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
> a3 <- list(x = rnorm(1e6), y = rnorm(1e6))
>
> # amount of memory allocated
> gc(reset=TRUE)
>
> # get names of the objects
> out_names <- ls(pattern="a[[:digit:]]$")
>
> # create a list
> out <- lapply(lapply(out_names, get), "[[", "x")
>
> # note that no copying occured
> gc()
>
> # decorate the list
> data.table::setattr(out, "names", out_names)
> data.table::setattr(out, "row.names", seq_along(out[[1]]))
> class(out) <- "data.frame"
>
> # still no copy
> gc()
>
> # output
> head(out)
>
>
> HTH,
>  Denes
>
>
>> 
>> Thanks in advance,
>> 
>> Steve
>> 
>> P.S.:  Below are some examples of summary outputs.
>> 
>> 
>>> summary(scen1)
>>                  Length Class  Mode
>> aql                1   -none- numeric
>> rql                1   -none- numeric
>> alpha              1   -none- numeric
>> beta               1   -none- numeric
>> n.sim              1   -none- numeric
>> N                  1   -none- numeric
>> n.sample           1   -none- numeric
>> n.acc              1   -none- numeric
>> lot.inf.r          1   -none- numeric
>> pop.inf.n       2000   -none- list
>> pop.inf.r       2000   -none- list
>> pop.decision.t1 2000   -none- list
>> pop.decision.t2 2000   -none- list
>> sp.inf.n        2000   -none- list
>> sp.inf.r        2000   -none- list
>> sp.decision     2000   -none- list
>>> summary(scen2)
>>                  Length Class  Mode
>> aql                1   -none- numeric
>> rql                1   -none- numeric
>> alpha              1   -none- numeric
>> beta               1   -none- numeric
>> n.sim              1   -none- numeric
>> N                  1   -none- numeric
>> n.sample           1   -none- numeric
>> n.acc              1   -none- numeric
>> lot.inf.r          1   -none- numeric
>> pop.inf.n       2000   -none- list
>> pop.inf.r       2000   -none- list
>> pop.decision.t1 2000   -none- list
>> pop.decision.t2 2000   -none- list
>> sp.inf.n        2000   -none- list
>> sp.inf.r        2000   -none- list
>> sp.decision     2000   -none- list
>>> summary(scen3)
>>                  Length Class  Mode
>> aql                1   -none- numeric
>> rql                1   -none- numeric
>> alpha              1   -none- numeric
>> beta               1   -none- numeric
>> n.sim              1   -none- numeric
>> N                  1   -none- numeric
>> n.sample           1   -none- numeric
>> n.acc              1   -none- numeric
>> lot.inf.r          1   -none- numeric
>> pop.inf.n       2000   -none- list
>> pop.inf.r       2000   -none- list
>> pop.decision.t1 2000   -none- list
>> pop.decision.t2 2000   -none- list
>> sp.inf.n        2000   -none- list
>> sp.inf.r        2000   -none- list
>> sp.decision     2000   -none- list
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From darwinpadilla84 at gmail.com  Wed Dec 17 02:59:00 2014
From: darwinpadilla84 at gmail.com (Darwin Padilla)
Date: Tue, 16 Dec 2014 20:59:00 -0500
Subject: [R] Forecast with data Georeferenced
Message-ID: <CAF4G_J9_eyVxuqtPQfhmta3-25ivhLScJw2nftE5PUY4-0BRjQ@mail.gmail.com>

Dear R.

My name is Darwin, I'm currently doing my thesis and I want to develop a
package to help me predict georeferenced data, ie whether there is any
pattern or behavior to know if it will happen again the same event again, I
might say statistical technique helps to accomplish what I need or whether
there is already a package to help me get what I need.

Advance my thanks for the help.


Darwin Padilla
Ecuador

	[[alternative HTML version deleted]]


From sachin.abeywardana at gmail.com  Wed Dec 17 07:55:27 2014
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Wed, 17 Dec 2014 17:55:27 +1100
Subject: [R] Stop R from changing matrix to numeric
Message-ID: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>

I have the following cost function:
cost<-function(x){
    x[,1]*sin(4*x[,1])+1.1*x[,2]*sin(2*x[,2])
}

If I send in a matrix which has MORE than one row and 2 columns, this
works fine. However, if I try to do cost(t(as.matrix(c(1,1)))) it
gives me an index error. When I tried debugging it, I found that the
type of matrix 'x' was converted to numeric.

How do I prevent this conversion from matrix to numeric if its a
matrix with just one row? The only way it would work is if I have:
x[1]*sin(4*x[1])+1.1*x[2]*sin(2*x[2]), which in turn wont work with a
matrix input.

Thanks,
Sachin


From petr.pikal at precheza.cz  Wed Dec 17 08:07:14 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Dec 2014 07:07:14 +0000
Subject: [R] Stop R from changing matrix to numeric
In-Reply-To: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>
References: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BF2278@SRVEXCHMBX.precheza.cz>

Hi

I can not reproduce your error

> cost<-function(x){
+     x[,1]*sin(4*x[,1])+1.1*x[,2]*sin(2*x[,2])
+ }
> cost(t(as.matrix(c(1,1))))
[1] 0.2434247
>

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Sachinthaka Abeywardana
> Sent: Wednesday, December 17, 2014 7:55 AM
> To: r-help at r-project.org
> Subject: [R] Stop R from changing matrix to numeric
>
> I have the following cost function:
> cost<-function(x){
>     x[,1]*sin(4*x[,1])+1.1*x[,2]*sin(2*x[,2])
> }
>
> If I send in a matrix which has MORE than one row and 2 columns, this
> works fine. However, if I try to do cost(t(as.matrix(c(1,1)))) it gives
> me an index error. When I tried debugging it, I found that the type of
> matrix 'x' was converted to numeric.
>
> How do I prevent this conversion from matrix to numeric if its a matrix
> with just one row? The only way it would work is if I have:
> x[1]*sin(4*x[1])+1.1*x[2]*sin(2*x[2]), which in turn wont work with a
> matrix input.
>
> Thanks,
> Sachin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From b.h.mevik at usit.uio.no  Wed Dec 17 10:05:54 2014
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Wed, 17 Dec 2014 10:05:54 +0100
Subject: [R] - PLS-Package - PLSR loadings
In-Reply-To: <549006F2.6000203@geo.uni-marburg.de> (Wolfgang Obermeier's
	message of "Tue, 16 Dec 2014 11:18:26 +0100")
References: <72139ef2c4c932ec42d43066bfae96f6@openmailbox.org>
	<549006F2.6000203@geo.uni-marburg.de>
Message-ID: <s3siohay7bh.fsf@slagelg.uio.no>

Wolfgang Obermeier <wolfgang.obermeier at geo.uni-marburg.de> writes:

> how is it possible that the loadings of the second or even third component of
> a PLS-Analysis show higher values than the first component? Somebody got an
> idea??

The loadings of a PLS regression are simply the coefficients that are
multiplied with the X variables to transform X to the "latent vectors"
used in the regression (this is slightly over-simplified).  There is no
reason why the coefficients of the first component should be larger than
the coefficients of other components.  (In fact, it is often the case
that when one fits too many components (i.e., one starts to model
"noise"), the coefficients of the last components get higher and
higher.)

-- 
Regards,
Bj?rn-Helge Mevik


From toth.denes at ttk.mta.hu  Wed Dec 17 11:46:17 2014
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Wed, 17 Dec 2014 11:46:17 +0100
Subject: [R] Extract values from multiple lists
In-Reply-To: <alpine.BSF.2.00.1412161636060.44925@pedal.dcn.davis.ca.us>
References: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
	<54909947.6030304@ttk.mta.hu>
	<alpine.BSF.2.00.1412161636060.44925@pedal.dcn.davis.ca.us>
Message-ID: <54915EF9.10203@ttk.mta.hu>

Dear Jeff,

On 12/17/2014 01:46 AM, Jeff Newmiller wrote:
> You are chasing ghosts of performance past, Denes.

In terms of memory efficiency, yes. In terms of CPU time, there can be 
significant difference, see below.


The data.frame
> function causes no problems, and if it is used then the OP would not
> need to presume they know the internal structure of the data frame.
> See below. (I am using R3.1.2.)
>
> a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
> a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
> a3 <- list(x = rnorm(1e6), y = rnorm(1e6))
>
> # get names of the objects
> out_names <- ls(pattern="a[[:digit:]]$")
>
> # amount of memory allocated
> gc(reset=TRUE)
>
> # Explicitly call data frame
> out2 <- data.frame( a1=a1[["x"]], a2=a2[["x"]], a3=a3[["x"]] )
>
> # No copying.
> gc()
>
> # Your suggested retreival method
> out3a <- lapply( lapply( out_names, get ), "[[", "x" )
> names( out3a ) <- out_names
> # The "obvious" way to finish the job works fine.
> out3 <- do.call( data.frame, out3a )

BTW, the even more "obvious" as.data.frame() produces the same with an 
even more intuitive interface.

However, for lists with a larger number of elements the transformation 
to a data.frame can be pretty slow. In the toy example, we created only 
a three-element list. Let's increase it a little bit.

---

# this is not even that large
datlen <- 1e2
listlen <- 1e5

# create a toy list
mylist <- matrix(seq_len(datlen * listlen),
                  nrow = datlen, ncol = listlen)
mylist <- lapply(1:ncol(mylist), function(i) mylist[, i])
names(mylist) <- paste0("V", seq_len(listlen))


# define the more efficient function ---
# note that I put class(x) first so that setattr does not
# modify the attributes of the original input (see ?setattr,
# you have to be careful)
setAttrib <- function(x) {
     class(x) <- "data.frame"
     data.table::setattr(x, "row.names", seq_along(x[[1]]))
     x
}

# benchmarking
# (we do not need microbenchmark here, the differences are
# extremely large) - on my machine, 9.4 sec, 8.1 sec vs 0.15 sec
gc(reset=TRUE)
system.time(df1 <- do.call(data.frame, mylist))
gc()
system.time(df2 <- as.data.frame(mylist))
gc()
system.time(df3 <- setAttrib(mylist))
gc()

# check results
identical(df1, df2)
identical(df1, df3)

----

Of course for small datasets, one should use the built-in and safe 
functions (either do.call or as.data.frame). BTW, for the original 
three-element list, these are even faster than the workaround.

All the best,
   Denes




>
> # No copying... well, you do end up with a new list in out3, but the
> data itself doesn't get copied.
> gc()
>
>
> On Tue, 16 Dec 2014, D?nes T?th wrote:
>
>> On 12/16/2014 06:06 PM, SH wrote:
>>> Dear List,
>>>
>>> I hope this posting is not redundant.  I have several list outputs
>>> with the
>>> same components.  I ran a function with three different scenarios below
>>> (e.g., scen1, scen2, and scen3,...,scenN).  I would like to extract the
>>> same components and group them as a data frame.  For example,
>>> pop.inf.r1 <- scen1[['pop.inf.r']]
>>> pop.inf.r2 <- scen2[['pop.inf.r']]
>>> pop.inf.r3 <- scen3[['pop.inf.r']]
>>> ...
>>> pop.inf.rN<-scenN[['pop.inf.r']]
>>> new.df <- data.frame(pop.inf.r1, pop.inf.r2, pop.inf.r3,...,pop.inf.rN)
>>>
>>> My final output would be 'new.df'.  Could you help me how I can do that
>>> efficiently?
>>
>> If efficiency is of concern, do not use data.frame() but create a list
>> and add the required attributes with data.table::setattr (the setattr
>> function of the data.table package). (You can also consider creating a
>> data.table instead of a data.frame.)
>>
>> # some largish lists
>> a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
>> a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
>> a3 <- list(x = rnorm(1e6), y = rnorm(1e6))
>>
>> # amount of memory allocated
>> gc(reset=TRUE)
>>
>> # get names of the objects
>> out_names <- ls(pattern="a[[:digit:]]$")
>>
>> # create a list
>> out <- lapply(lapply(out_names, get), "[[", "x")
>>
>> # note that no copying occured
>> gc()
>>
>> # decorate the list
>> data.table::setattr(out, "names", out_names)
>> data.table::setattr(out, "row.names", seq_along(out[[1]]))
>> class(out) <- "data.frame"
>>
>> # still no copy
>> gc()
>>
>> # output
>> head(out)
>>
>>
>> HTH,
>>  Denes
>>
>>
>>>
>>> Thanks in advance,
>>>
>>> Steve
>>>
>>> P.S.:  Below are some examples of summary outputs.
>>>
>>>
>>>> summary(scen1)
>>>                  Length Class  Mode
>>> aql                1   -none- numeric
>>> rql                1   -none- numeric
>>> alpha              1   -none- numeric
>>> beta               1   -none- numeric
>>> n.sim              1   -none- numeric
>>> N                  1   -none- numeric
>>> n.sample           1   -none- numeric
>>> n.acc              1   -none- numeric
>>> lot.inf.r          1   -none- numeric
>>> pop.inf.n       2000   -none- list
>>> pop.inf.r       2000   -none- list
>>> pop.decision.t1 2000   -none- list
>>> pop.decision.t2 2000   -none- list
>>> sp.inf.n        2000   -none- list
>>> sp.inf.r        2000   -none- list
>>> sp.decision     2000   -none- list
>>>> summary(scen2)
>>>                  Length Class  Mode
>>> aql                1   -none- numeric
>>> rql                1   -none- numeric
>>> alpha              1   -none- numeric
>>> beta               1   -none- numeric
>>> n.sim              1   -none- numeric
>>> N                  1   -none- numeric
>>> n.sample           1   -none- numeric
>>> n.acc              1   -none- numeric
>>> lot.inf.r          1   -none- numeric
>>> pop.inf.n       2000   -none- list
>>> pop.inf.r       2000   -none- list
>>> pop.decision.t1 2000   -none- list
>>> pop.decision.t2 2000   -none- list
>>> sp.inf.n        2000   -none- list
>>> sp.inf.r        2000   -none- list
>>> sp.decision     2000   -none- list
>>>> summary(scen3)
>>>                  Length Class  Mode
>>> aql                1   -none- numeric
>>> rql                1   -none- numeric
>>> alpha              1   -none- numeric
>>> beta               1   -none- numeric
>>> n.sim              1   -none- numeric
>>> N                  1   -none- numeric
>>> n.sample           1   -none- numeric
>>> n.acc              1   -none- numeric
>>> lot.inf.r          1   -none- numeric
>>> pop.inf.n       2000   -none- list
>>> pop.inf.r       2000   -none- list
>>> pop.decision.t1 2000   -none- list
>>> pop.decision.t2 2000   -none- list
>>> sp.inf.n        2000   -none- list
>>> sp.inf.r        2000   -none- list
>>> sp.decision     2000   -none- list
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From nashjc at uottawa.ca  Wed Dec 17 12:46:24 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 17 Dec 2014 06:46:24 -0500
Subject: [R] Help specifying a non-linear model in nlsLM()
In-Reply-To: <mailman.1.1418814002.8005.r-help@r-project.org>
References: <mailman.1.1418814002.8005.r-help@r-project.org>
Message-ID: <54916D10.4050305@uottawa.ca>

nlsLM and nls share a numerical gradient approximation and pop up the 
"singular gradient" quite often at the start. Package nlmrt and a very 
alpha nls14 (not on CRAN) try to use analytic derivatives for the 
Jacobian (most optimization folk will say singular Jacobian rather than 
singular gradient), so you might be better off with nlxb  from nlmrt. 
BUT ... it works on expressions, not functions.

Or you could provide your own Jacobian and make sure it is not singular 
at the start.

Both nlsLM and nlxb/nlfb will generally be OK once they get started due 
to the Marquardt adjustment to the Jacobian to avoid singularity.

JN


On 14-12-17 06:00 AM, r-help-request at r-project.org wrote:
> Message: 9 Date: Tue, 16 Dec 2014 08:24:45 -0800 From: Bert Gunter
> <gunter.berton at gene.com> To: Chandrasekhar Rudrappa
> <chandratr at gmail.com> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Subject: Re: [R] Help specifying a non-linear model in nlsLM()
> Message-ID:
> <CACk-te30269-jbC4rOh24WhyCV2MrsoRQceKUrn+VzhVuRm9fA at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8 Suitable help may not be
> possible. I suspect that either your function/code is funky (is the
> function smooth, non-infinite near your starting value?) or you are
> overparameterized. If the latter, the remedy may depend on the nature of
> your data, which you have not shared. While you may receive some help
> here (there are some pretty smart optimizers who monitor the list), I
> suggest you try a statistical site like stats.stackexchange.com for
> help, as this appears to be primarily a statistics issue, not an R
> programming one. Cheers, Bert Bert Gunter Genentech Nonclinical
> Biostatistics (650) 467-7374 "Data is not information. Information is
> not knowledge. And knowledge is certainly not wisdom." Clifford Stoll On
> Tue, Dec 16, 2014 at 6:26 AM, Chandrasekhar Rudrappa
> <chandratr at gmail.com> wrote:
>> >Dear All,
>> >
>> >I am trying to fit the following model in nlsLM():
>> >
>> >fn5 <- function(x, T, t1, w_inf, Lt0){
>> >S<-function(x, T, t1){
>> >x+(1-T)/(2*pi)*sin(2*pi*(x-t1)/(1-T))
>> >}
>> >F <- function(x, T, t1){
>> >t2 <- t1 + (1-T)/2
>> >t3 <- t1 + (1+T)/2
>> >t.factorial <- x%%1
>> >floor(x)*(1-T) + S(t.factorial, T, t1)*(0<=t.factorial & t.factorial<t2) +
>> >S(t2, T, t1)*(t2<=t.factorial & t.factorial<t3) +
>> >S(t.factorial-T, T, t1)*(t3<=t.factorial & t.factorial<1)
>> >}
>> >return(w_inf - (w_inf - Lt0)*exp(-(2/30)*(F(x,T,t1)-F(7,T,t1))))
>> >}
>> >fn6<- y~fn5(x, T, t1, w_inf, Lt0)
>> >startval<-c(x=x, T=0.035, t1=0.359, w_inf=135, Lt0=47)
>> >(nlsktm1 <- nlsLM(fn6, start=startval, lower=c(x=x, T=0.0135, t1=0.259,
>> >w_inf=131, Lt0=41), jac=NULL, trace=T, data=ktm,
>> >control=nls.control(maxiter=10)))
>> >
>> >When I run the above script, the following error is displayed:
>> >
>> >Error in nlsModel(formula, mf, start, wts) :
>> >   singular gradient matrix at initial parameter estimates
>> >In addition: Warning message:
>> >In nls.lm(par = start, fn = FCT, jac = jac, control = control, lower =
>> >lower,  :
>> >   lmdif: info = 0. Improper input parameters.
>> >
>> >Suitable help is requested.
>> >--
>> >Dr. TR Chandrasekhar, M.Sc., M. Tech., Ph. D.,
>> >Sr. Scientist
>> >Rubber Research Institute of India
>> >Hevea Breeding Sub Station
>> >Kadaba - 574 221
>> >DK Dt., Karnataka
>> >Phone-Land: 08251-214336
>> >Mobile: 9448780118
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org  mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>


From rl at openmailbox.org  Wed Dec 17 13:24:53 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Wed, 17 Dec 2014 12:24:53 +0000
Subject: [R] dotplot legend
Message-ID: <407213f4fd128065062155980aef58fb@openmailbox.org>

Subscribers,

For this example:

library(lattice)
testmatrix<-matrix(c(1,2,3,4,3,6,12,24),nrow=4,ncol=2)
testylabels<-c('w1','x1','y1','z1')
dotplot(testmatrix, scales=list(y=list(labels=testylabels), xlab=NULL))
legend('bottomright', 'legend', col=c('blue', 'pink'))
Error in strwidth(legend, units = "user", cex = cex) :
   plot.new has not been called yet

The help for 'plot.new' is not understood; the graph has been called in 
the previous commands?


From info at aghmed.fsnet.co.uk  Wed Dec 17 14:36:35 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 17 Dec 2014 13:36:35 +0000
Subject: [R] dotplot legend
In-Reply-To: <407213f4fd128065062155980aef58fb@openmailbox.org>
References: <407213f4fd128065062155980aef58fb@openmailbox.org>
Message-ID: <549186E3.8010404@aghmed.fsnet.co.uk>



On 17/12/2014 12:24, rl at openmailbox.org wrote:
> Subscribers,
>
> For this example:
>
> library(lattice)
> testmatrix<-matrix(c(1,2,3,4,3,6,12,24),nrow=4,ncol=2)
> testylabels<-c('w1','x1','y1','z1')
> dotplot(testmatrix, scales=list(y=list(labels=testylabels), xlab=NULL))
> legend('bottomright', 'legend', col=c('blue', 'pink'))
> Error in strwidth(legend, units = "user", cex = cex) :
>    plot.new has not been called yet

lattice uses grid graphics, not base graphics. I suspect you have to 
come to grips with the key parameter in dotplot.

>
> The help for 'plot.new' is not understood; the graph has been called in
> the previous commands?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4253/8751 - Release Date: 12/17/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From jdnewmil at dcn.davis.CA.us  Wed Dec 17 15:05:08 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 17 Dec 2014 06:05:08 -0800
Subject: [R] Stop R from changing matrix to numeric
In-Reply-To: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>
References: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>
Message-ID: <E2D69B80-EE7B-4B76-B1EB-D20CC5A38AEB@dcn.davis.CA.us>

as.matrix(c(1,1)) gives a matrix with only one column, but your function assumes you have at least two columns (you refer to x[,2]). Please make your examples reproducible (run it yourself in a fresh instance of R) to obtain best results with questions on this list. 

However, you might just be needing to read about the drop parameter for indexing:

?"["

which is also mentioned in the Introduction to R document that accompanies the software in the section on indexing.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 16, 2014 10:55:27 PM PST, Sachinthaka Abeywardana <sachin.abeywardana at gmail.com> wrote:
>I have the following cost function:
>cost<-function(x){
>    x[,1]*sin(4*x[,1])+1.1*x[,2]*sin(2*x[,2])
>}
>
>If I send in a matrix which has MORE than one row and 2 columns, this
>works fine. However, if I try to do cost(t(as.matrix(c(1,1)))) it
>gives me an index error. When I tried debugging it, I found that the
>type of matrix 'x' was converted to numeric.
>
>How do I prevent this conversion from matrix to numeric if its a
>matrix with just one row? The only way it would work is if I have:
>x[1]*sin(4*x[1])+1.1*x[2]*sin(2*x[2]), which in turn wont work with a
>matrix input.
>
>Thanks,
>Sachin
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Peter.Alspach at plantandfood.co.nz  Wed Dec 17 19:59:34 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 18 Dec 2014 07:59:34 +1300
Subject: [R] Stop R from changing matrix to numeric
In-Reply-To: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>
References: <CAGuusR-4EPfcA2d2_x_7LG=UhrQhKbT2KCE-+qkSD+s0Y62hEw@mail.gmail.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B754501A1436661@AKLEXM01.PFR.CO.NZ>

Tena koe Sachin

The following might help you understand what is going on and how to rectify it.

cost <- function(x) {x[,1]*x[,2]}
ttMat <- matrix(1:4, ncol=2)
ttMat
cost(ttMat)
cost(ttMat[1,])
cost(as.matrix(ttMat[1,]))
cost(t(as.matrix(ttMat[1,])))
cost(matrix(ttMat[1,], ncol=2))

str(ttMat)
str(ttMat[1,])
str(as.matrix(ttMat[1,]))
str(t(as.matrix(ttMat[1,])))
str(matrix(ttMat[1,], ncol=2))

HTH .....

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sachinthaka Abeywardana
Sent: Wednesday, 17 December 2014 7:55 p.m.
To: r-help at r-project.org
Subject: [R] Stop R from changing matrix to numeric

I have the following cost function:
cost<-function(x){
    x[,1]*sin(4*x[,1])+1.1*x[,2]*sin(2*x[,2])
}

If I send in a matrix which has MORE than one row and 2 columns, this works fine. However, if I try to do cost(t(as.matrix(c(1,1)))) it gives me an index error. When I tried debugging it, I found that the type of matrix 'x' was converted to numeric.

How do I prevent this conversion from matrix to numeric if its a matrix with just one row? The only way it would work is if I have:
x[1]*sin(4*x[1])+1.1*x[2]*sin(2*x[2]), which in turn wont work with a matrix input.

Thanks,
Sachin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From emptican at gmail.com  Wed Dec 17 22:41:06 2014
From: emptican at gmail.com (SH)
Date: Wed, 17 Dec 2014 16:41:06 -0500
Subject: [R] Extract values from multiple lists
In-Reply-To: <54915EF9.10203@ttk.mta.hu>
References: <CALSKosCE=4F3Uck3tEd7=r0k5Ziv+RfyOHgYJpBzrBS81+MWEA@mail.gmail.com>
	<54909947.6030304@ttk.mta.hu>
	<alpine.BSF.2.00.1412161636060.44925@pedal.dcn.davis.ca.us>
	<54915EF9.10203@ttk.mta.hu>
Message-ID: <CALSKosCfTjiO2ZC9RUZN9=5ig0cqZADCih4_U0B6q7f887zGuQ@mail.gmail.com>

Dear Dennis, David, Jeff, and Denes,

Thanks for your helps and comments.  The simple one seems good enough for
my works.

Best,

Steve

On Wed, Dec 17, 2014 at 5:46 AM, D?nes T?th <toth.denes at ttk.mta.hu> wrote:
>
> Dear Jeff,
>
> On 12/17/2014 01:46 AM, Jeff Newmiller wrote:
>
>> You are chasing ghosts of performance past, Denes.
>>
>
> In terms of memory efficiency, yes. In terms of CPU time, there can be
> significant difference, see below.
>
>
> The data.frame
>
>> function causes no problems, and if it is used then the OP would not
>> need to presume they know the internal structure of the data frame.
>> See below. (I am using R3.1.2.)
>>
>> a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
>> a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
>> a3 <- list(x = rnorm(1e6), y = rnorm(1e6))
>>
>> # get names of the objects
>> out_names <- ls(pattern="a[[:digit:]]$")
>>
>> # amount of memory allocated
>> gc(reset=TRUE)
>>
>> # Explicitly call data frame
>> out2 <- data.frame( a1=a1[["x"]], a2=a2[["x"]], a3=a3[["x"]] )
>>
>> # No copying.
>> gc()
>>
>> # Your suggested retreival method
>> out3a <- lapply( lapply( out_names, get ), "[[", "x" )
>> names( out3a ) <- out_names
>> # The "obvious" way to finish the job works fine.
>> out3 <- do.call( data.frame, out3a )
>>
>
> BTW, the even more "obvious" as.data.frame() produces the same with an
> even more intuitive interface.
>
> However, for lists with a larger number of elements the transformation to
> a data.frame can be pretty slow. In the toy example, we created only a
> three-element list. Let's increase it a little bit.
>
> ---
>
> # this is not even that large
> datlen <- 1e2
> listlen <- 1e5
>
> # create a toy list
> mylist <- matrix(seq_len(datlen * listlen),
>                  nrow = datlen, ncol = listlen)
> mylist <- lapply(1:ncol(mylist), function(i) mylist[, i])
> names(mylist) <- paste0("V", seq_len(listlen))
>
>
> # define the more efficient function ---
> # note that I put class(x) first so that setattr does not
> # modify the attributes of the original input (see ?setattr,
> # you have to be careful)
> setAttrib <- function(x) {
>     class(x) <- "data.frame"
>     data.table::setattr(x, "row.names", seq_along(x[[1]]))
>     x
> }
>
> # benchmarking
> # (we do not need microbenchmark here, the differences are
> # extremely large) - on my machine, 9.4 sec, 8.1 sec vs 0.15 sec
> gc(reset=TRUE)
> system.time(df1 <- do.call(data.frame, mylist))
> gc()
> system.time(df2 <- as.data.frame(mylist))
> gc()
> system.time(df3 <- setAttrib(mylist))
> gc()
>
> # check results
> identical(df1, df2)
> identical(df1, df3)
>
> ----
>
> Of course for small datasets, one should use the built-in and safe
> functions (either do.call or as.data.frame). BTW, for the original
> three-element list, these are even faster than the workaround.
>
> All the best,
>   Denes
>
>
>
>
>
>
>> # No copying... well, you do end up with a new list in out3, but the
>> data itself doesn't get copied.
>> gc()
>>
>>
>> On Tue, 16 Dec 2014, D?nes T?th wrote:
>>
>>  On 12/16/2014 06:06 PM, SH wrote:
>>>
>>>> Dear List,
>>>>
>>>> I hope this posting is not redundant.  I have several list outputs
>>>> with the
>>>> same components.  I ran a function with three different scenarios below
>>>> (e.g., scen1, scen2, and scen3,...,scenN).  I would like to extract the
>>>> same components and group them as a data frame.  For example,
>>>> pop.inf.r1 <- scen1[['pop.inf.r']]
>>>> pop.inf.r2 <- scen2[['pop.inf.r']]
>>>> pop.inf.r3 <- scen3[['pop.inf.r']]
>>>> ...
>>>> pop.inf.rN<-scenN[['pop.inf.r']]
>>>> new.df <- data.frame(pop.inf.r1, pop.inf.r2, pop.inf.r3,...,pop.inf.rN)
>>>>
>>>> My final output would be 'new.df'.  Could you help me how I can do that
>>>> efficiently?
>>>>
>>>
>>> If efficiency is of concern, do not use data.frame() but create a list
>>> and add the required attributes with data.table::setattr (the setattr
>>> function of the data.table package). (You can also consider creating a
>>> data.table instead of a data.frame.)
>>>
>>> # some largish lists
>>> a1 <- list(x = rnorm(1e6), y = rnorm(1e6))
>>> a2 <- list(x = rnorm(1e6), y = rnorm(1e6))
>>> a3 <- list(x = rnorm(1e6), y = rnorm(1e6))
>>>
>>> # amount of memory allocated
>>> gc(reset=TRUE)
>>>
>>> # get names of the objects
>>> out_names <- ls(pattern="a[[:digit:]]$")
>>>
>>> # create a list
>>> out <- lapply(lapply(out_names, get), "[[", "x")
>>>
>>> # note that no copying occured
>>> gc()
>>>
>>> # decorate the list
>>> data.table::setattr(out, "names", out_names)
>>> data.table::setattr(out, "row.names", seq_along(out[[1]]))
>>> class(out) <- "data.frame"
>>>
>>> # still no copy
>>> gc()
>>>
>>> # output
>>> head(out)
>>>
>>>
>>> HTH,
>>>  Denes
>>>
>>>
>>>
>>>> Thanks in advance,
>>>>
>>>> Steve
>>>>
>>>> P.S.:  Below are some examples of summary outputs.
>>>>
>>>>
>>>>  summary(scen1)
>>>>>
>>>>                  Length Class  Mode
>>>> aql                1   -none- numeric
>>>> rql                1   -none- numeric
>>>> alpha              1   -none- numeric
>>>> beta               1   -none- numeric
>>>> n.sim              1   -none- numeric
>>>> N                  1   -none- numeric
>>>> n.sample           1   -none- numeric
>>>> n.acc              1   -none- numeric
>>>> lot.inf.r          1   -none- numeric
>>>> pop.inf.n       2000   -none- list
>>>> pop.inf.r       2000   -none- list
>>>> pop.decision.t1 2000   -none- list
>>>> pop.decision.t2 2000   -none- list
>>>> sp.inf.n        2000   -none- list
>>>> sp.inf.r        2000   -none- list
>>>> sp.decision     2000   -none- list
>>>>
>>>>> summary(scen2)
>>>>>
>>>>                  Length Class  Mode
>>>> aql                1   -none- numeric
>>>> rql                1   -none- numeric
>>>> alpha              1   -none- numeric
>>>> beta               1   -none- numeric
>>>> n.sim              1   -none- numeric
>>>> N                  1   -none- numeric
>>>> n.sample           1   -none- numeric
>>>> n.acc              1   -none- numeric
>>>> lot.inf.r          1   -none- numeric
>>>> pop.inf.n       2000   -none- list
>>>> pop.inf.r       2000   -none- list
>>>> pop.decision.t1 2000   -none- list
>>>> pop.decision.t2 2000   -none- list
>>>> sp.inf.n        2000   -none- list
>>>> sp.inf.r        2000   -none- list
>>>> sp.decision     2000   -none- list
>>>>
>>>>> summary(scen3)
>>>>>
>>>>                  Length Class  Mode
>>>> aql                1   -none- numeric
>>>> rql                1   -none- numeric
>>>> alpha              1   -none- numeric
>>>> beta               1   -none- numeric
>>>> n.sim              1   -none- numeric
>>>> N                  1   -none- numeric
>>>> n.sample           1   -none- numeric
>>>> n.acc              1   -none- numeric
>>>> lot.inf.r          1   -none- numeric
>>>> pop.inf.n       2000   -none- list
>>>> pop.inf.r       2000   -none- list
>>>> pop.decision.t1 2000   -none- list
>>>> pop.decision.t2 2000   -none- list
>>>> sp.inf.n        2000   -none- list
>>>> sp.inf.r        2000   -none- list
>>>> sp.decision     2000   -none- list
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ------------------------------------------------------------
>> ---------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ------------------------------------------------------------
>> ---------------
>>
>

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Wed Dec 17 23:55:21 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 18 Dec 2014 08:55:21 +1000
Subject: [R] dotplot legend
In-Reply-To: <407213f4fd128065062155980aef58fb@openmailbox.org>
References: <407213f4fd128065062155980aef58fb@openmailbox.org>
Message-ID: <000301d01a4c$8a0f4e80$9e2deb80$@bigpond.com>

If you want to use lattice then the following should give you some tips
Read ?lattice::xyplot

testmatrix<-matrix(c(1,2,3,4,3,6,12,24),nrow=4,ncol=2)
testylabels<-c('w1','x1','y1','z1')
dtf <- data.frame(testmatrix)
dtf
testmatrix
dotplot(X2 ~ X1, dtf)
dtf[,1] = factor(dtf[,1])
dotplot(X2 ~ X1, dtf)
dotplot(X2 ~ X1, dtf, scales=list(x=list(at = paste(1:4),
labels=testylabels)))

see key in xyplot help for the legend

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
rl at openmailbox.org
Sent: Wednesday, 17 December 2014 22:25
To: r-help at r-project.org
Subject: [R] dotplot legend

Subscribers,

For this example:

library(lattice)
testmatrix<-matrix(c(1,2,3,4,3,6,12,24),nrow=4,ncol=2)
testylabels<-c('w1','x1','y1','z1')
dotplot(testmatrix, scales=list(y=list(labels=testylabels), xlab=NULL))
legend('bottomright', 'legend', col=c('blue', 'pink'))
Error in strwidth(legend, units = "user", cex = cex) :
   plot.new has not been called yet

The help for 'plot.new' is not understood; the graph has been called in 
the previous commands?

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rstrothe at gmail.com  Wed Dec 17 21:14:22 2014
From: rstrothe at gmail.com (Robert Strother)
Date: Thu, 18 Dec 2014 09:14:22 +1300
Subject: [R] pairing columns based on a value
Message-ID: <CAGgz0QqLDN0ix1yqA4LY5YMn5jc41ORYRER5edwTDGXGRrvveg@mail.gmail.com>

I have a large dataset (~50,000 rows, 96 columns), of hospital
administrative data.
many of the columns are clinical coding of inpatient event (using ICD-10).
A simplified example of the data is below

> dput(dat_unmatched)
structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
"BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 = structure(c(2L,
3L, 1L, 1L), .Label = c("B83.2", "C23.2", "F56.23"), class = "factor"),
    X.2 = structure(c(2L, 1L, 2L, 2L), .Label = c("M20.64", "T43.2"
    ), class = "factor"), X.3 = structure(c(2L, 3L, 3L, 1L), .Label =
c("F56.23",
    "R23.1", "Y32.1"), class = "factor"), X.4 = structure(c(1L,
    2L, 2L, 3L), .Label = c("M23.5", "T44.2", "Y32.1"), class = "factor"),
    X.5 = structure(c(1L, 2L, 1L, 2L), .Label = c("", "Q23.6"
    ), class = "factor")), .Names = c("ID", "X.1", "X.2", "X.3",
"X.4", "X.5"), class = "data.frame", row.names = c(NA, -4L))

I am interested in a set of codes that start with a "T" or a "Y", and link
them to the preceding column that does not begin with a "T" or "Y".   I
suspect I will need to use regular expressions, and likely a loop, but I am
really out of my depth at this point.

I would like the final dataset to look like:

> dput(dat_matched)
structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
"BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 = structure(c(2L,
3L, 1L, 1L), .Label = c("B83.2", "C23.2", "M20.64"), class = "factor"),
    X.2 = structure(c(1L, 2L, 1L, 1L), .Label = c("T43.2", "Y32.1"
    ), class = "factor"), X.3 = structure(c(1L, 4L, 2L, 3L), .Label = c("",
    "B83.2", "F56.23", "M20.64"), class = "factor"), X.4 = structure(c(1L,
    2L, 3L, 3L), .Label = c("", "T44.2", "Y32.1"), class = "factor"),
    X.5 = structure(c(1L, 1L, 2L, 1L), .Label = c("", "B83.2"
    ), class = "factor"), X = structure(c(1L, 1L, 2L, 1L), .Label = c("",
    "T44.2"), class = "factor")), .Names = c("ID", "X.1", "X.2",
"X.3", "X.4", "X.5", "X"), class = "data.frame", row.names = c(NA,
-4L))

Any help appreciated.

Matthew

	[[alternative HTML version deleted]]


From fmdarocha at yahoo.de  Wed Dec 17 22:08:54 2014
From: fmdarocha at yahoo.de (Francisco M. da Rocha)
Date: Wed, 17 Dec 2014 22:08:54 +0100
Subject: [R] Question about CHAID
Message-ID: <5491F0E6.30706@yahoo.de>

Hallo there,

I would like to work with CHAID, but the newest version of R does have it.
So I thought I could use an older version of R which accepts or has the 
library CHAID.
Could you tell me which version it is and where to download it?

Thanks a lot in advance.
Francisco


From ievans272 at gmail.com  Wed Dec 17 23:27:39 2014
From: ievans272 at gmail.com (Ian Evans)
Date: Wed, 17 Dec 2014 16:27:39 -0600
Subject: [R] Help: The Difference Between Workspace, Script, and History
Message-ID: <CAB8x9dX-EQ0trA4YBhBmWM3sTXqJqbsuE3SZsU=TyV9ABjCfRg@mail.gmail.com>

I apologize that I am very new to R and programming in general. I do not
understand the difference between the script, the workspace, and the
history, and what saving each one means.

I seem to be doing fine writing commands and going through lessons and
examples (I'm using Learn R in a Day) but when I try to save what I wrote
and load it later, it tells me that it is loaded, but none of my code is
one the screen.

	[[alternative HTML version deleted]]


From jjw3952 at rit.edu  Wed Dec 17 22:03:27 2014
From: jjw3952 at rit.edu (Jacob Warren (RIT Student))
Date: Wed, 17 Dec 2014 16:03:27 -0500
Subject: [R] lme4 2 factor factorial model with random factors
Message-ID: <CADqzGTvp4X6GoF2f2zNR1wDnBEaHM+45H6WSpaPWmdcczGZQJQ@mail.gmail.com>

Using lme4 how does one define a 2 factor factorial model with both factors
being random?

Specifically I am just trying to recreate the results from Montgomery's
Design of Experiments book (7th edition), example 13.2. In this example
there are 2 random factors and I want to include the interaction in the
model as Montgomery tests for significance in the full model first. I've
tried several things but cannot recreate the results in R. I would think
something like what's given below would work, but it does not.

lmer(y ~ (1 | Parts) + (1 | Operators) + (1 | Parts:Operators) )

	[[alternative HTML version deleted]]


From robin at lindinglab.org  Wed Dec 17 21:46:16 2014
From: robin at lindinglab.org (Xavier Robin)
Date: Wed, 17 Dec 2014 21:46:16 +0100
Subject: [R] Maximum likelihood with analytical Hessian and
Message-ID: <5491EB98.6090606@lindinglab.org>

Dear list,

I have an optimization problem that I would like to solve by Maximum
Likelihood.
I have analytical functions for the first and second derivatives of my
parameters.
In addition, some parameters are constrained between 0 and 1, while some
others can vary freely between -Inf and +Inf.

I am looking for an optimization function to solve this problem.

I understand that the base optim function doesn't take a Hessian
function, it only computes it numerically.
I found the maxLik package that takes the function as a "hess" parameter
but the maxNR method (the only one that uses the Hessian function) can't
be bounded.
Surprisingly I couldn't find a function doing both.

Any suggestions for a function doing bounded optimization with an
analytical Hessian function?

Thanks,
Xavier


From gunter.berton at gene.com  Thu Dec 18 00:58:06 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 17 Dec 2014 15:58:06 -0800
Subject: [R] pairing columns based on a value
In-Reply-To: <CAGgz0QqLDN0ix1yqA4LY5YMn5jc41ORYRER5edwTDGXGRrvveg@mail.gmail.com>
References: <CAGgz0QqLDN0ix1yqA4LY5YMn5jc41ORYRER5edwTDGXGRrvveg@mail.gmail.com>
Message-ID: <CACk-te0jHjVSZ_dd+v82QScx6njpzjn=+aRrbe_HeN5pAkp3ng@mail.gmail.com>

"out of your depth" does not serve as a legitimate excuse --  for me
anyway. There are many good tutorials on regular expressions out
there. Go through one. Ditto with R data handling. "An Introduction to
R" (ships with R) is one that's right at hand.

Although others may be more inclined than I am to help, you would
certainly increase the likelihood by first doing some homework and
showing us code that you tried. Although, by that time, you probably
will have figured it out for yourself.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Dec 17, 2014 at 12:14 PM, Robert Strother <rstrothe at gmail.com> wrote:
> I have a large dataset (~50,000 rows, 96 columns), of hospital
> administrative data.
> many of the columns are clinical coding of inpatient event (using ICD-10).
> A simplified example of the data is below
>
>> dput(dat_unmatched)
> structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
> "BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 = structure(c(2L,
> 3L, 1L, 1L), .Label = c("B83.2", "C23.2", "F56.23"), class = "factor"),
>     X.2 = structure(c(2L, 1L, 2L, 2L), .Label = c("M20.64", "T43.2"
>     ), class = "factor"), X.3 = structure(c(2L, 3L, 3L, 1L), .Label =
> c("F56.23",
>     "R23.1", "Y32.1"), class = "factor"), X.4 = structure(c(1L,
>     2L, 2L, 3L), .Label = c("M23.5", "T44.2", "Y32.1"), class = "factor"),
>     X.5 = structure(c(1L, 2L, 1L, 2L), .Label = c("", "Q23.6"
>     ), class = "factor")), .Names = c("ID", "X.1", "X.2", "X.3",
> "X.4", "X.5"), class = "data.frame", row.names = c(NA, -4L))
>
> I am interested in a set of codes that start with a "T" or a "Y", and link
> them to the preceding column that does not begin with a "T" or "Y".   I
> suspect I will need to use regular expressions, and likely a loop, but I am
> really out of my depth at this point.
>
> I would like the final dataset to look like:
>
>> dput(dat_matched)
> structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
> "BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 = structure(c(2L,
> 3L, 1L, 1L), .Label = c("B83.2", "C23.2", "M20.64"), class = "factor"),
>     X.2 = structure(c(1L, 2L, 1L, 1L), .Label = c("T43.2", "Y32.1"
>     ), class = "factor"), X.3 = structure(c(1L, 4L, 2L, 3L), .Label = c("",
>     "B83.2", "F56.23", "M20.64"), class = "factor"), X.4 = structure(c(1L,
>     2L, 3L, 3L), .Label = c("", "T44.2", "Y32.1"), class = "factor"),
>     X.5 = structure(c(1L, 1L, 2L, 1L), .Label = c("", "B83.2"
>     ), class = "factor"), X = structure(c(1L, 1L, 2L, 1L), .Label = c("",
>     "T44.2"), class = "factor")), .Names = c("ID", "X.1", "X.2",
> "X.3", "X.4", "X.5", "X"), class = "data.frame", row.names = c(NA,
> -4L))
>
> Any help appreciated.
>
> Matthew
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From clint at ecy.wa.gov  Thu Dec 18 01:00:05 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 17 Dec 2014 16:00:05 -0800 (PST)
Subject: [R] Help: The Difference Between Workspace, Script, and History
In-Reply-To: <CAB8x9dX-EQ0trA4YBhBmWM3sTXqJqbsuE3SZsU=TyV9ABjCfRg@mail.gmail.com>
References: <CAB8x9dX-EQ0trA4YBhBmWM3sTXqJqbsuE3SZsU=TyV9ABjCfRg@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1412171558270.16187@aeolus.ecy.wa.gov>

Ian,

ls() is your friend. To learn more about ls(), type ?ls

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 17 Dec 2014, Ian Evans wrote:

> I apologize that I am very new to R and programming in general. I do not
> understand the difference between the script, the workspace, and the
> history, and what saving each one means.
>
> I seem to be doing fine writing commands and going through lessons and
> examples (I'm using Learn R in a Day) but when I try to save what I wrote
> and load it later, it tells me that it is loaded, but none of my code is
> one the screen.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Thu Dec 18 01:06:02 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 17 Dec 2014 16:06:02 -0800
Subject: [R] Help: The Difference Between Workspace, Script, and History
In-Reply-To: <CAB8x9dX-EQ0trA4YBhBmWM3sTXqJqbsuE3SZsU=TyV9ABjCfRg@mail.gmail.com>
References: <CAB8x9dX-EQ0trA4YBhBmWM3sTXqJqbsuE3SZsU=TyV9ABjCfRg@mail.gmail.com>
Message-ID: <CACk-te07jEW-Dg=-Z13M6sU3qRfyhF6C68gxd9N4us7EfLg3bQ@mail.gmail.com>

I can answer, but I think you'll get a better one if you tell us the
environment in which you're working -- RStudio, R's GUI, Rterm,... and
the platform (Windows, MAC, _nix).

Very briefly, but perhaps inadequately, the script is what you write
and send to R to execute or perhaps store in its workspace to be run
later (e.g. functions, data); the workspace is the "container" where R
stores its objects -- functions, variables, data, etc. -- that your
script puts there and that R loads by default; and history is simply a
record of the command that you sent to R to run.

I suggest that you have a look at "An Introduction to R" for a better
description of how things work than your current tutorial apparently
gives.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Dec 17, 2014 at 2:27 PM, Ian Evans <ievans272 at gmail.com> wrote:
> I apologize that I am very new to R and programming in general. I do not
> understand the difference between the script, the workspace, and the
> history, and what saving each one means.
>
> I seem to be doing fine writing commands and going through lessons and
> examples (I'm using Learn R in a Day) but when I try to save what I wrote
> and load it later, it tells me that it is loaded, but none of my code is
> one the screen.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From xiaoheyiyh at yahoo.com  Thu Dec 18 03:25:45 2014
From: xiaoheyiyh at yahoo.com (heyi xiao)
Date: Wed, 17 Dec 2014 18:25:45 -0800
Subject: [R] Add encoded special characters (greek characters) as text to
	plot
Message-ID: <1418869545.890.YahooMailBasic@web162606.mail.bf1.yahoo.com>

Dear all,
I read my a character matrix from a text file. Some of them have greek characters. To reserve the special characters, I used stringsAsFactors=F using read.table. I notice that I can?t print these character string using print(), but I can use cat():
> print("LC\246\302")
[1] "LC\246\302"
> cat("LC\246\302\n")
LC?

The problem is when I add text to my output plot like:
text(x,y, labels="LC\246\302")

I got "LC.. " on my plot. Obviously text function doesn?t know what?s "\246\302". I google that encoding, and can?t find exact what that is. It doesn?t look like ascii or Unicode. Anybody knows what that is?
Note that I can?t use expression() method to pass these special characters because these are read from a text file, I just can?t include greek characters manually that way. Is there a way that I can output these strings with special characters automatically?
Thank you!
Heyi


From zadig_1 at excite.com  Thu Dec 18 04:24:56 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 17 Dec 2014 22:24:56 -0500
Subject: [R] how to make this get command work?
Message-ID: <20141217222456.21224@web009.roc2.bluetie.com>

Dear all,

If I have a list like this how I can get an object of it  with a variable :

foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
var <- "A"

get(paste("foo$",'A',sep=''))
Error in get(paste("foo$", "A", sep = "")) : object 'foo$A' not found


From gunter.berton at gene.com  Thu Dec 18 04:35:00 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 17 Dec 2014 19:35:00 -0800
Subject: [R] how to make this get command work?
In-Reply-To: <20141217222456.21224@web009.roc2.bluetie.com>
References: <20141217222456.21224@web009.roc2.bluetie.com>
Message-ID: <CACk-te3+PhomgeCWXSgvuEJzcDa7jgVmVA5fnFKSAPOhL0JKUg@mail.gmail.com>

?"["

Read the docs! Go thru an R tutorial.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Dec 17, 2014 at 7:24 PM, ce <zadig_1 at excite.com> wrote:
> Dear all,
>
> If I have a list like this how I can get an object of it  with a variable :
>
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
> var <- "A"
>
> get(paste("foo$",'A',sep=''))
> Error in get(paste("foo$", "A", sep = "")) : object 'foo$A' not found
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Thu Dec 18 05:22:03 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 17 Dec 2014 23:22:03 -0500
Subject: [R] how to make this get command work?
Message-ID: <20141217232203.10221@web003.roc2.bluetie.com>

Thank you. I was flummoxed by late night tiredness. 
getElement via ?"[" helped me. I am flubbergusted with your speedy answer.
ce

-----Original Message-----
From: "Bert Gunter" [gunter.berton at gene.com]
Date: 12/17/2014 10:35 PM
To: "ce" <zadig_1 at excite.com>
CC: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] how to make this get command work?

?"["

Read the docs! Go thru an R tutorial.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Dec 17, 2014 at 7:24 PM, ce <zadig_1 at excite.com> wrote:
> Dear all,
>
> If I have a list like this how I can get an object of it  with a variable :
>
> foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
> var <- "A"
>
> get(paste("foo$",'A',sep=''))
> Error in get(paste("foo$", "A", sep = "")) : object 'foo$A' not found
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Dec 18 06:14:30 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 17 Dec 2014 21:14:30 -0800
Subject: [R] how to make this get command work?
In-Reply-To: <20141217222456.21224@web009.roc2.bluetie.com>
References: <20141217222456.21224@web009.roc2.bluetie.com>
Message-ID: <87549D5F-6579-4FA2-96B9-75B717E9B58B@dcn.davis.CA.us>

One of the reasons lists are useful is that you can put various things in them and then you have an object name that you can hard code into your program, yet still use variables to find objects in that list. That is you do not need to directly use the get function at all.

foo[[var]]

If you ever think this is not true, just make a new list and put your old list into it, and you can start using variables to look up your old list.

lname <- "foo"
bar <- list( foo= list(A = c(1,3), B =c(1, 2), C = c(3, 1)) )
bar[[lname]][[var]]
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 17, 2014 7:24:56 PM PST, ce <zadig_1 at excite.com> wrote:
>Dear all,
>
>If I have a list like this how I can get an object of it  with a
>variable :
>
>foo<-list(A = c(1,3), B =c(1, 2), C = c(3, 1))
>var <- "A"
>
>get(paste("foo$",'A',sep=''))
>Error in get(paste("foo$", "A", sep = "")) : object 'foo$A' not found
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From andre_mikulec at hotmail.com  Thu Dec 18 03:35:39 2014
From: andre_mikulec at hotmail.com (Andre Mikulec)
Date: Wed, 17 Dec 2014 21:35:39 -0500
Subject: [R] setBreakpoint No source refs found
Message-ID: <BLU174-W49F8DB1ACE7CBBA090DB3C9C6A0@phx.gbl>



Hi,

when I am trying to deug a package, I am getting the error.

> library(quantstrat)
> setBreakpoint("strategy.R#3",envir=environment(strategy))
No source refs found.

In R studio, I get a strange message, "Breakpoints will be activated when an updated version of the quantstrat package is loaded."

However, when I do Hmisc, everything works fine.

> library(Hmisc)
> setBreakpoint("F:\\ProgramFiles\\R\\R-3.1.1\\library\\HmiscSRC\\R\\Misc.s#1221", env=environment(hdquantile)) 

F:\ProgramFiles\R\R-3.1.1\library\HmiscSRC\R\Misc.s#1221:
 hdquantile step  2 in <environment: namespace:Hmisc>
 hdquantile step  2 in <environment: package:Hmisc>

?Tracing function "hdquantile" in package "namespace:Hmisc"
Tracing function "hdquantile" in package "Hmisc"
Also, I can set "RStudio breakpoints" in R Studio on many lines in Misc.s
What is this error, "No source refs found."

Please help.
Thanks.

 Andre Mikulec 
 Andre_Mikulec at Hotmail.com 		 	   		  

From bcrombie at utk.edu  Thu Dec 18 04:15:14 2014
From: bcrombie at utk.edu (bcrombie)
Date: Wed, 17 Dec 2014 19:15:14 -0800 (PST)
Subject: [R] Make 2nd col of 2-col df into header row of same df then adjust
 col1 data display
Message-ID: <1418872514464-4700878.post@n4.nabble.com>

# I have a dataframe that contains 2 columns:
CaseID  <- c('1015285',
'1005317',
'1012281',
'1015285',
'1015285',
'1007183',
'1008833',
'1015315',
'1015322',
'1015285')

Primary.Viol.Type <- c('AS.Age',
'HS.Hours',
'HS.Hours',
'HS.Hours',
'RK.Records_CL',
'OT.Overtime',
'OT.Overtime',
'OT.Overtime',
'V.Poster_Other',
'V.Poster_Other')

PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)

# CaseID?s can be repeated because there can be up to 14 Primary.Viol.Type?s
per CaseID.

# I want to transform this dataframe into one that has 15 columns, where the
first column is CaseID, and the rest are the 14 primary viol. types.  The
CaseID column will contain a list of the unique CaseID?s (no replicates) and
for each of their rows, there will be a ?1? under  a column corresponding to
a primary violation type recorded for that CaseID.  So, technically, there
could be zero to 14 ?1?s? in a CaseID?s row.

# For example, the row for CaseID '1015285' above would have a ?1? under
?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?, but have "NA"
under the rest of the columns.

PViol.Type <- c("CaseID",
                "BW.BackWages",
           "LD.Liquid_Damages",
           "MW.Minimum_Wage",
           "OT.Overtime",
           "RK.Records_FLSA",
           "V.Poster_Other",
           "AS.Age",
           "BW.WHMIS_BackWages",
           "HS.Hours",
           "OA.HazOccupationAg",
           "ON.HazOccupationNonAg",
           "R3.Reg3AgeOccupation",
           "RK.Records_CL",
           "V.Other")

PViol.Type.Columns <- t(data.frame(PViol.Type)

# What is the best way to do this in R?




--
View this message in context: http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row-of-same-df-then-adjust-col1-data-display-tp4700878.html
Sent from the R help mailing list archive at Nabble.com.


From Achim.Zeileis at uibk.ac.at  Thu Dec 18 07:54:15 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 18 Dec 2014 07:54:15 +0100 (CET)
Subject: [R] Question about CHAID
In-Reply-To: <5491F0E6.30706@yahoo.de>
References: <5491F0E6.30706@yahoo.de>
Message-ID: <alpine.DEB.2.11.1412180751001.28547@paninaro.uibk.ac.at>

On Wed, 17 Dec 2014, Francisco M. da Rocha wrote:

> Hallo there,
>
> I would like to work with CHAID, but the newest version of R does have 
> it. So I thought I could use an older version of R which accepts or has 
> the library CHAID. Could you tell me which version it is and where to 
> download it?

A development version of the "CHAID" package is available from R-Forge:
http://R-Forge.R-project.org/R/?group_id=343

Additionally, there is a wide range of other recursive partitioning 
packages for R that are more recent and more actively developed, e.g., 
rpart() from the package of the same name or ctree() from partykit (or the 
older party package). See also:
http://CRAN.R-project.org/view=MachineLearning

> Thanks a lot in advance.
> Francisco
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Thu Dec 18 10:41:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 18 Dec 2014 04:41:51 -0500
Subject: [R] setBreakpoint No source refs found
In-Reply-To: <BLU174-W49F8DB1ACE7CBBA090DB3C9C6A0@phx.gbl>
References: <BLU174-W49F8DB1ACE7CBBA090DB3C9C6A0@phx.gbl>
Message-ID: <5492A15F.1090109@gmail.com>

On 17/12/2014, 9:35 PM, Andre Mikulec wrote:
> 
> 
> Hi,
> 
> when I am trying to deug a package, I am getting the error.
> 
>> library(quantstrat)
>> setBreakpoint("strategy.R#3",envir=environment(strategy))
> No source refs found.
> 
> In R studio, I get a strange message, "Breakpoints will be activated when an updated version of the quantstrat package is loaded."
> 
> However, when I do Hmisc, everything works fine.
> 
>> library(Hmisc)
>> setBreakpoint("F:\\ProgramFiles\\R\\R-3.1.1\\library\\HmiscSRC\\R\\Misc.s#1221", env=environment(hdquantile)) 
> 
> F:\ProgramFiles\R\R-3.1.1\library\HmiscSRC\R\Misc.s#1221:
>  hdquantile step  2 in <environment: namespace:Hmisc>
>  hdquantile step  2 in <environment: package:Hmisc>
> 
>  Tracing function "hdquantile" in package "namespace:Hmisc"
> Tracing function "hdquantile" in package "Hmisc"
> Also, I can set "RStudio breakpoints" in R Studio on many lines in Misc.s
> What is this error, "No source refs found."
> 
> Please help.

The "source refs" are debugging information that by default is added to
functions you load via source(), but not to functions in a package,
because it makes the image noticeably bigger.  You can add it to package
code by setting an environment variable during the INSTALL:  the
variable is "R_KEEP_PKG_SOURCE=yes".  Presumably RStudio is telling you
it needs to re-install the package to get this information.

Duncan Murdoch


From boris.steipe at utoronto.ca  Thu Dec 18 11:28:46 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 18 Dec 2014 05:28:46 -0500
Subject: [R] Make 2nd col of 2-col df into header row of same df then
	adjust col1 data display
In-Reply-To: <1418872514464-4700878.post@n4.nabble.com>
References: <1418872514464-4700878.post@n4.nabble.com>
Message-ID: <DA47BE11-8B6F-4862-A9F3-CBFDFDD23A11@utoronto.ca>

What you are describing sounds like a very spreadsheet-y thing. 

- The information is already IN your dataframe, and easy to get out by subsetting. Depending on your usecase, that may actually be the "best". 

- If the number of CaseIDs is large, I would use a hash of lists (if the data is sparse), or hash of named vectors if it's not sparse. Lookup is O(1) so that may be the best. (Cf package hash, and explanations there). 

- If it must be the spreadsheet-y thing, you could make a matrix with rownames and colnames taken from unique() of your respective dataframe. Instead of 1 and NA I probably would use TRUE/FALSE. 

- If it takes less time to wait for the results than to look up how apply() works, you can write a simple loop to populate your matrix. Otherwise apply() is much faster. 

- You could even use a loop to build the datastructure, checking for every cbind() whether the value in column 1 already exists in the table - but that's terrible and would make a kitten die somewhere on every iteration.

All of these are possible, and you haven't told us enough about what you want to achieve to figure out what the "best" is. If you choose one of the options and need help with the code, let us know.

Cheers,
B.





On Dec 17, 2014, at 10:15 PM, bcrombie <bcrombie at utk.edu> wrote:

> # I have a dataframe that contains 2 columns:
> CaseID  <- c('1015285',
> '1005317',
> '1012281',
> '1015285',
> '1015285',
> '1007183',
> '1008833',
> '1015315',
> '1015322',
> '1015285')
> 
> Primary.Viol.Type <- c('AS.Age',
> 'HS.Hours',
> 'HS.Hours',
> 'HS.Hours',
> 'RK.Records_CL',
> 'OT.Overtime',
> 'OT.Overtime',
> 'OT.Overtime',
> 'V.Poster_Other',
> 'V.Poster_Other')
> 
> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
> 
> # CaseID?s can be repeated because there can be up to 14 Primary.Viol.Type?s
> per CaseID.
> 
> # I want to transform this dataframe into one that has 15 columns, where the
> first column is CaseID, and the rest are the 14 primary viol. types.  The
> CaseID column will contain a list of the unique CaseID?s (no replicates) and
> for each of their rows, there will be a ?1? under  a column corresponding to
> a primary violation type recorded for that CaseID.  So, technically, there
> could be zero to 14 ?1?s? in a CaseID?s row.
> 
> # For example, the row for CaseID '1015285' above would have a ?1? under
> ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?, but have "NA"
> under the rest of the columns.
> 
> PViol.Type <- c("CaseID",
>                "BW.BackWages",
>           "LD.Liquid_Damages",
>           "MW.Minimum_Wage",
>           "OT.Overtime",
>           "RK.Records_FLSA",
>           "V.Poster_Other",
>           "AS.Age",
>           "BW.WHMIS_BackWages",
>           "HS.Hours",
>           "OA.HazOccupationAg",
>           "ON.HazOccupationNonAg",
>           "R3.Reg3AgeOccupation",
>           "RK.Records_CL",
>           "V.Other")
> 
> PViol.Type.Columns <- t(data.frame(PViol.Type)
> 
> # What is the best way to do this in R?
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row-of-same-df-then-adjust-col1-data-display-tp4700878.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Thu Dec 18 14:41:19 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 18 Dec 2014 13:41:19 +0000
Subject: [R] pairing columns based on a value
In-Reply-To: <CAGgz0QqLDN0ix1yqA4LY5YMn5jc41ORYRER5edwTDGXGRrvveg@mail.gmail.com>
References: <CAGgz0QqLDN0ix1yqA4LY5YMn5jc41ORYRER5edwTDGXGRrvveg@mail.gmail.com>
Message-ID: <5492D97F.1080208@aghmed.fsnet.co.uk>

Not sure how much help it will be but there is a package on CRAN called 
icd9. Although clearly the codes are different in ICD 10 it may give you 
some hints. I suppose you could even email the maintainer to see whether 
there is an icd10 in the pipeline.

On 17/12/2014 20:14, Robert Strother wrote:
> I have a large dataset (~50,000 rows, 96 columns), of hospital
> administrative data.
> many of the columns are clinical coding of inpatient event (using ICD-10).
> A simplified example of the data is below
>
>> dput(dat_unmatched)
> structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
> "BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 = structure(c(2L,
> 3L, 1L, 1L), .Label = c("B83.2", "C23.2", "F56.23"), class = "factor"),
>      X.2 = structure(c(2L, 1L, 2L, 2L), .Label = c("M20.64", "T43.2"
>      ), class = "factor"), X.3 = structure(c(2L, 3L, 3L, 1L), .Label =
> c("F56.23",
>      "R23.1", "Y32.1"), class = "factor"), X.4 = structure(c(1L,
>      2L, 2L, 3L), .Label = c("M23.5", "T44.2", "Y32.1"), class = "factor"),
>      X.5 = structure(c(1L, 2L, 1L, 2L), .Label = c("", "Q23.6"
>      ), class = "factor")), .Names = c("ID", "X.1", "X.2", "X.3",
> "X.4", "X.5"), class = "data.frame", row.names = c(NA, -4L))
>
> I am interested in a set of codes that start with a "T" or a "Y", and link
> them to the preceding column that does not begin with a "T" or "Y".   I
> suspect I will need to use regular expressions, and likely a loop, but I am
> really out of my depth at this point.
>
> I would like the final dataset to look like:
>
>> dput(dat_matched)
> structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
> "BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 = structure(c(2L,
> 3L, 1L, 1L), .Label = c("B83.2", "C23.2", "M20.64"), class = "factor"),
>      X.2 = structure(c(1L, 2L, 1L, 1L), .Label = c("T43.2", "Y32.1"
>      ), class = "factor"), X.3 = structure(c(1L, 4L, 2L, 3L), .Label = c("",
>      "B83.2", "F56.23", "M20.64"), class = "factor"), X.4 = structure(c(1L,
>      2L, 3L, 3L), .Label = c("", "T44.2", "Y32.1"), class = "factor"),
>      X.5 = structure(c(1L, 1L, 2L, 1L), .Label = c("", "B83.2"
>      ), class = "factor"), X = structure(c(1L, 1L, 2L, 1L), .Label = c("",
>      "T44.2"), class = "factor")), .Names = c("ID", "X.1", "X.2",
> "X.3", "X.4", "X.5", "X"), class = "data.frame", row.names = c(NA,
> -4L))
>
> Any help appreciated.
>
> Matthew
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4253/8759 - Release Date: 12/18/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From nashjc at uottawa.ca  Thu Dec 18 15:10:50 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 18 Dec 2014 09:10:50 -0500
Subject: [R] Maximum likelihood with analytical Hessian and
In-Reply-To: <mailman.1.1418900401.5963.r-help@r-project.org>
References: <mailman.1.1418900401.5963.r-help@r-project.org>
Message-ID: <5492E06A.1010806@uottawa.ca>

Of the tools I know (and things change every day!), only package trust
uses the Hessian explicitly.

It would not be too difficult to include explicit Hessian by modifying
Rvmmin which is all in R -- I'm currently doing some cleanup on that, so
ask offline if you choose that route.

Given that some parameters are between 0 and 1, you could use the
hyperbolic transformation (section 11.2 of my book Nonlinear parameter
optimization using R tools) with trust, and I think I'd try that as a
first attempt. You probably need to adjust the Hessian for the
transformation carefully.

Generally the work in computing the Hessian ( # obs * (# parameters)^2
in size) is not worth the effort, but there are problems for which it
does make a lot of sense.

JN

On 14-12-18 06:00 AM, r-help-request at r-project.org wrote:
> Message: 12
> Date: Wed, 17 Dec 2014 21:46:16 +0100
> From: Xavier Robin <robin at lindinglab.org>
> To: r-help at r-project.org
> Subject: [R] Maximum likelihood with analytical Hessian and
> Message-ID: <5491EB98.6090606 at lindinglab.org>
> Content-Type: text/plain; charset=utf-8
> 
> Dear list,
> 
> I have an optimization problem that I would like to solve by Maximum
> Likelihood.
> I have analytical functions for the first and second derivatives of my
> parameters.
> In addition, some parameters are constrained between 0 and 1, while some
> others can vary freely between -Inf and +Inf.
> 
> I am looking for an optimization function to solve this problem.
> 
> I understand that the base optim function doesn't take a Hessian
> function, it only computes it numerically.
> I found the maxLik package that takes the function as a "hess" parameter
> but the maxNR method (the only one that uses the Hessian function) can't
> be bounded.
> Surprisingly I couldn't find a function doing both.
> 
> Any suggestions for a function doing bounded optimization with an
> analytical Hessian function?
> 
> Thanks,
> Xavier
> 
>


From alaios at yahoo.com  Thu Dec 18 15:56:42 2014
From: alaios at yahoo.com (Alaios)
Date: Thu, 18 Dec 2014 14:56:42 +0000 (UTC)
Subject: [R] combinations between two vectors
Message-ID: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>

Hi all,I am looking for a function that would give me all the combinations between two vectors.Lets take as example the?

test<-seq(1,30000,by=5000)
Browse[2]> test
[1]???? 1? 5001 10001 15001 20001 25001
I want all the combinations between two times the test... I think this is? called permutation so a function that could do permutation(test,test)and produce the following
1,11,50011,100011,15001....
3,13,5001...25001,20001,25001,25001
is there such a function ?
RegardsAlex


	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Thu Dec 18 16:05:20 2014
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 18 Dec 2014 07:05:20 -0800
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <1418872514464-4700878.post@n4.nabble.com>
Message-ID: <8A81EA5FDE9.00000B39jrkrideau@inbox.com>

Of course, but why? As Brian S says you have not given us enough information to know exactly what you are after. 

Have a look at https://github.com/hadley/devtools/wiki/Reproducibility or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for some information on how to form a question for the list.

It is good that you provided some data but it is better to use dput() (see links above or ?dput) to supply the data as different R users have different settings on their systems and may not read that data in the same way. 

Note that I have simplified your incredibly verbose names and put everything into lower case (see ?tolower) just to make life easier. Because R is case-sensitive, it is usually easier to keep to lower case as much as possible particularly when posting to the list and to use simple variable names where the actual variables are likely to meaningless to the reader and long upper case names just makes for more typing.

In any case here is a quick and dirty semi-solution using the reshape2 package which I imagine you will have to install using ?install.packages("reshape2"). 

Depending on exactly what you need to know there may be, as Brian S says many different and better approaches. While we really don't need the actual variable names we need an overall idea of what you are going in substantive terms and what the final results are. 

Anyway welcome to the R-help list

#========start code=====
library(reshape2)
dat1  <-  structure(list(id = structure(c(5L, 1L, 4L, 5L, 5L, 2L, 3L, 6L, 
7L, 5L), .Label = c("1005317", "1007183", "1008833", "1012281", 
"1015285", "1015315", "1015322"), class = "factor"), type = structure(c(1L, 
2L, 2L, 2L, 4L, 3L, 3L, 3L, 5L, 5L), .Label = c("as.age", "hs.hours", 
"ot.overtime", "rk.records_cl", "v.poster_other"), class = "factor")), .Names = c("id", 
"type"), row.names = c(NA, -10L), class = "data.frame")
  

dcast(dat1, id ~ type)

#=======end code =======

John Kane
Kingston ON Canada


> -----Original Message-----
> From: bcrombie at utk.edu
> Sent: Wed, 17 Dec 2014 19:15:14 -0800 (PST)
> To: r-help at r-project.org
> Subject: [R] Make 2nd col of 2-col df into header row of same df then
> adjust col1 data display
> 
> # I have a dataframe that contains 2 columns:
> CaseID  <- c('1015285',
> '1005317',
> '1012281',
> '1015285',
> '1015285',
> '1007183',
> '1008833',
> '1015315',
> '1015322',
> '1015285')
> 
> Primary.Viol.Type <- c('AS.Age',
> 'HS.Hours',
> 'HS.Hours',
> 'HS.Hours',
> 'RK.Records_CL',
> 'OT.Overtime',
> 'OT.Overtime',
> 'OT.Overtime',
> 'V.Poster_Other',
> 'V.Poster_Other')
> 
> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
> 
> # CaseID?s can be repeated because there can be up to 14
> Primary.Viol.Type?s
> per CaseID.
> 
> # I want to transform this dataframe into one that has 15 columns, where
> the
> first column is CaseID, and the rest are the 14 primary viol. types.  The
> CaseID column will contain a list of the unique CaseID?s (no replicates)
> and
> for each of their rows, there will be a ?1? under  a column corresponding
> to
> a primary violation type recorded for that CaseID.  So, technically,
> there
> could be zero to 14 ?1?s? in a CaseID?s row.
> 
> # For example, the row for CaseID '1015285' above would have a ?1? under
> ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?, but have
> "NA"
> under the rest of the columns.
> 
> PViol.Type <- c("CaseID",
>                 "BW.BackWages",
>            "LD.Liquid_Damages",
>            "MW.Minimum_Wage",
>            "OT.Overtime",
>            "RK.Records_FLSA",
>            "V.Poster_Other",
>            "AS.Age",
>            "BW.WHMIS_BackWages",
>            "HS.Hours",
>            "OA.HazOccupationAg",
>            "ON.HazOccupationNonAg",
>            "R3.Reg3AgeOccupation",
>            "RK.Records_CL",
>            "V.Other")
> 
> PViol.Type.Columns <- t(data.frame(PViol.Type)
> 
> # What is the best way to do this in R?
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row-of-same-df-then-adjust-col1-data-display-tp4700878.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From sarah.goslee at gmail.com  Thu Dec 18 16:06:09 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 18 Dec 2014 10:06:09 -0500
Subject: [R] combinations between two vectors
In-Reply-To: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>
References: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>
Message-ID: <CAM_vju==Y9OVKeJMzeR+KmKK-7qMwzKU018DpxPOVsPSrdk0AA@mail.gmail.com>

I can't quite tell what you want: your example output is either
unclear to me or mangled by posting in HTML (please don't).

Is
expand.grid(test, test)
what you want, or partway to what you want?


Sarah

On Thu, Dec 18, 2014 at 9:56 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Hi all,I am looking for a function that would give me all the combinations between two vectors.Lets take as example the
>
> test<-seq(1,30000,by=5000)
> Browse[2]> test
> [1]     1  5001 10001 15001 20001 25001
> I want all the combinations between two times the test... I think this is  called permutation so a function that could do permutation(test,test)and produce the following
> 1,11,50011,100011,15001....
> 3,13,5001...25001,20001,25001,25001
> is there such a function ?
> RegardsAlex
>
>
>         [[alternative HTML version deleted]]
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Thu Dec 18 16:16:57 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 18 Dec 2014 15:16:57 +0000
Subject: [R] combinations between two vectors
In-Reply-To: <CAM_vju==Y9OVKeJMzeR+KmKK-7qMwzKU018DpxPOVsPSrdk0AA@mail.gmail.com>
References: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>
	<CAM_vju==Y9OVKeJMzeR+KmKK-7qMwzKU018DpxPOVsPSrdk0AA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FC2384@mb02.ads.tamu.edu>

Depending on what you want, you probably want to start with expand.grid():

# All combinations of test with test
> pairs1 <- expand.grid(test, test)
> nrow(pairs1)
[1] 36
# Exclude cases that differ only in the order of the values
# E.g. (1, 5001), but not (5001, 1), also (1, 1), etc are included
> pairs2 <- pairs1[pairs1[,1] <= pairs1[,2],]
> nrow(pairs2)
[1] 21
# Same as pairs2 but (1, 1), etc are not included
> pairs3 <- pairs1[pairs1[,1] < pairs1[,2],]
> nrow(pairs3)
[1] 15

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
Sent: Thursday, December 18, 2014 9:06 AM
To: Alaios
Cc: R-help at r-project.org
Subject: Re: [R] combinations between two vectors

I can't quite tell what you want: your example output is either
unclear to me or mangled by posting in HTML (please don't).

Is
expand.grid(test, test)
what you want, or partway to what you want?


Sarah

On Thu, Dec 18, 2014 at 9:56 AM, Alaios via R-help <r-help at r-project.org> wrote:
> Hi all,I am looking for a function that would give me all the combinations between two vectors.Lets take as example the
>
> test<-seq(1,30000,by=5000)
> Browse[2]> test
> [1]     1  5001 10001 15001 20001 25001
> I want all the combinations between two times the test... I think this is  called permutation so a function that could do permutation(test,test)and produce the following
> 1,11,50011,100011,15001....
> 3,13,5001...25001,20001,25001,25001
> is there such a function ?
> RegardsAlex
>
>
>         [[alternative HTML version deleted]]
>

-- 
Sarah Goslee
http://www.functionaldiversity.org

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From alagador at uevora.pt  Thu Dec 18 16:30:03 2014
From: alagador at uevora.pt (=?iso-8859-1?Q?Diogo_Andr=E9_Alagador?=)
Date: Thu, 18 Dec 2014 15:30:03 -0000
Subject: [R] number of fuctions in a R-package
Message-ID: <011a01d01ad7$7ea88ad0$7bf9a070$@pt>

I would like to know if it is allowable to build an R-package made of one
function only, to launch a GUI to take input data and users to select the
models they intend to use, and to start running the processes?

 

Thanks a lot,

Diogo Alagador

 <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador

CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University
of ?vora, Portugal

 


	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Thu Dec 18 16:38:01 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 18 Dec 2014 15:38:01 +0000
Subject: [R] combinations between two vectors
In-Reply-To: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>
References: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>
Message-ID: <5492F4D9.7010304@aghmed.fsnet.co.uk>



On 18/12/2014 14:56, Alaios via R-help wrote:
> Hi all,I am looking for a function that would give me all the combinations between two vectors.Lets take as example the
>
> test<-seq(1,30000,by=5000)
> Browse[2]> test
> [1]     1  5001 10001 15001 20001 25001
> I want all the combinations between two times the test... I think this is  called permutation

I think is more likely it is a combination problem.
??combination
would have directed you to the solution others have offered 
(expand.grid) and other things too.

  so a function that could do permutation(test,test)and produce the 
following
> 1,11,50011,100011,15001....
> 3,13,5001...25001,20001,25001,25001
> is there such a function ?
> RegardsAlex
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4253/8759 - Release Date: 12/18/14
>

-- 
Michael
http://www.dewey.myzen.co.uk


From boris.steipe at utoronto.ca  Thu Dec 18 16:59:57 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 18 Dec 2014 10:59:57 -0500
Subject: [R] Make 2nd col of 2-col df into header row of same df then
	adjust col1 data display
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CEE5117C18@kmbx4.utk.tennessee.edu>
References: <1418872514464-4700878.post@n4.nabble.com>
	<DA47BE11-8B6F-4862-A9F3-CBFDFDD23A11@utoronto.ca>
	<559C998F7039D84C9793AE43D9BBE9CEE5117C18@kmbx4.utk.tennessee.edu>
Message-ID: <84A8057F-229D-4C71-8A3B-78A736AA83A3@utoronto.ca>

"Make a table that looks like..." sounds like a use case that would benefit from some reflection.
Anyway, at least don't put your IDs  *in* the "table".

# Your data
CaseID  <- c('1015285',
'1005317',
'1012281',
'1015285',
'1015285',
'1007183',
'1008833',
'1015315',
'1015322',
'1015285')

Primary.Viol.Type <- c('AS.Age',
'HS.Hours',
'HS.Hours',
'HS.Hours',
'RK.Records_CL',
'OT.Overtime',
'OT.Overtime',
'OT.Overtime',
'V.Poster_Other',
'V.Poster_Other')

# the code
uID <- unique(CaseID)
uVT <- unique(Primary.Viol.Type)

m <- matrix(NA, nrow=length(uID), ncol=length(uVT), dimnames=list(uID, uVT))

for (i in 1:length(CaseID)) {
    m[CaseID[i], Primary.Viol.Type[i]] <- 1
}


# the result
        AS.Age HS.Hours RK.Records_CL OT.Overtime V.Poster_Other
1015285      1        1             1          NA              1
1005317     NA        1            NA          NA             NA
1012281     NA        1            NA          NA             NA
1007183     NA       NA            NA           1             NA
1008833     NA       NA            NA           1             NA
1015315     NA       NA            NA           1             NA
1015322     NA       NA            NA          NA              1



B.



On Dec 18, 2014, at 8:09 AM, Crombie, Burnette N <bcrombie at utk.edu> wrote:

> I want to achieve a table that looks like a grid of 1's for all cases in a survey.  I'm an R beginner and don't have a clue how to do all the things you just suggested.  I really appreciate the time you took to explain all of those options, though.  -- BNC
> 
> -----Original Message-----
> From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
> Sent: Thursday, December 18, 2014 5:29 AM
> To: Crombie, Burnette N
> Cc: r-help at r-project.org
> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df then adjust col1 data display
> 
> What you are describing sounds like a very spreadsheet-y thing. 
> 
> - The information is already IN your dataframe, and easy to get out by subsetting. Depending on your usecase, that may actually be the "best". 
> 
> - If the number of CaseIDs is large, I would use a hash of lists (if the data is sparse), or hash of named vectors if it's not sparse. Lookup is O(1) so that may be the best. (Cf package hash, and explanations there). 
> 
> - If it must be the spreadsheet-y thing, you could make a matrix with rownames and colnames taken from unique() of your respective dataframe. Instead of 1 and NA I probably would use TRUE/FALSE. 
> 
> - If it takes less time to wait for the results than to look up how apply() works, you can write a simple loop to populate your matrix. Otherwise apply() is much faster. 
> 
> - You could even use a loop to build the datastructure, checking for every cbind() whether the value in column 1 already exists in the table - but that's terrible and would make a kitten die somewhere on every iteration.
> 
> All of these are possible, and you haven't told us enough about what you want to achieve to figure out what the "best" is. If you choose one of the options and need help with the code, let us know.
> 
> Cheers,
> B.
> 
> 
> 
> 
> 
> On Dec 17, 2014, at 10:15 PM, bcrombie <bcrombie at utk.edu> wrote:
> 
>> # I have a dataframe that contains 2 columns:
>> CaseID  <- c('1015285',
>> '1005317',
>> '1012281',
>> '1015285',
>> '1015285',
>> '1007183',
>> '1008833',
>> '1015315',
>> '1015322',
>> '1015285')
>> 
>> Primary.Viol.Type <- c('AS.Age',
>> 'HS.Hours',
>> 'HS.Hours',
>> 'HS.Hours',
>> 'RK.Records_CL',
>> 'OT.Overtime',
>> 'OT.Overtime',
>> 'OT.Overtime',
>> 'V.Poster_Other',
>> 'V.Poster_Other')
>> 
>> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>> 
>> # CaseID's can be repeated because there can be up to 14 
>> Primary.Viol.Type's per CaseID.
>> 
>> # I want to transform this dataframe into one that has 15 columns, 
>> where the first column is CaseID, and the rest are the 14 primary 
>> viol. types.  The CaseID column will contain a list of the unique 
>> CaseID's (no replicates) and for each of their rows, there will be a 
>> "1" under  a column corresponding to a primary violation type recorded 
>> for that CaseID.  So, technically, there could be zero to 14 "1's" in a CaseID's row.
>> 
>> # For example, the row for CaseID '1015285' above would have a "1" 
>> under "AS.Age", "HS.Hours", "RK.Records_CL", and "V.Poster_Other", but have "NA"
>> under the rest of the columns.
>> 
>> PViol.Type <- c("CaseID",
>>               "BW.BackWages",
>>          "LD.Liquid_Damages",
>>          "MW.Minimum_Wage",
>>          "OT.Overtime",
>>          "RK.Records_FLSA",
>>          "V.Poster_Other",
>>          "AS.Age",
>>          "BW.WHMIS_BackWages",
>>          "HS.Hours",
>>          "OA.HazOccupationAg",
>>          "ON.HazOccupationNonAg",
>>          "R3.Reg3AgeOccupation",
>>          "RK.Records_CL",
>>          "V.Other")
>> 
>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>> 
>> # What is the best way to do this in R?
>> 
>> 
>> 
>> 
>> --
>> View this message in context: 
>> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row
>> -of-same-df-then-adjust-col1-data-display-tp4700878.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.ca.us  Thu Dec 18 17:02:29 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Dec 2014 08:02:29 -0800 (PST)
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <1418872514464-4700878.post@n4.nabble.com>
References: <1418872514464-4700878.post@n4.nabble.com>
Message-ID: <alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>

No guarantees on "best"... but one way using base R could be:

# Note that "CaseID" is actually not a valid PViol.Type as you had it
PViol.Type <- c( "BW.BackWages"
                , "LD.Liquid_Damages"
                , "MW.Minimum_Wage"
                , "OT.Overtime"
                , "RK.Records_FLSA"
                , "V.Poster_Other"
                , "AS.Age"
                , "BW.WHMIS_BackWages"
                , "HS.Hours"
                , "OA.HazOccupationAg"
                , "ON.HazOccupationNonAg"
                , "R3.Reg3AgeOccupation"
                , "RK.Records_CL"
                , "V.Other" )

# explicitly specifying all levels to the factor insures a complete
# set of column outputs regardless of what is in the input
PViol.Type.Per.Case.Original <-
     data.frame( CaseID
               , Primary.Viol.Type=factor( Primary.Viol.Type
                                         , levels=PViol.Type ) )

tmp <- table( PViol.Type.Per.Case.Original )
ans <- data.frame( CaseID=rownames( tmp )
                  , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
                  )


On Wed, 17 Dec 2014, bcrombie wrote:

> # I have a dataframe that contains 2 columns:
> CaseID  <- c('1015285',
> '1005317',
> '1012281',
> '1015285',
> '1015285',
> '1007183',
> '1008833',
> '1015315',
> '1015322',
> '1015285')
>
> Primary.Viol.Type <- c('AS.Age',
> 'HS.Hours',
> 'HS.Hours',
> 'HS.Hours',
> 'RK.Records_CL',
> 'OT.Overtime',
> 'OT.Overtime',
> 'OT.Overtime',
> 'V.Poster_Other',
> 'V.Poster_Other')
>
> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>
> # CaseID?s can be repeated because there can be up to 14 Primary.Viol.Type?s
> per CaseID.
>
> # I want to transform this dataframe into one that has 15 columns, where the
> first column is CaseID, and the rest are the 14 primary viol. types.  The
> CaseID column will contain a list of the unique CaseID?s (no replicates) and
> for each of their rows, there will be a ?1? under  a column corresponding to
> a primary violation type recorded for that CaseID.  So, technically, there
> could be zero to 14 ?1?s? in a CaseID?s row.
>
> # For example, the row for CaseID '1015285' above would have a ?1? under
> ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?, but have "NA"
> under the rest of the columns.
>
> PViol.Type <- c("CaseID",
>                "BW.BackWages",
>           "LD.Liquid_Damages",
>           "MW.Minimum_Wage",
>           "OT.Overtime",
>           "RK.Records_FLSA",
>           "V.Poster_Other",
>           "AS.Age",
>           "BW.WHMIS_BackWages",
>           "HS.Hours",
>           "OA.HazOccupationAg",
>           "ON.HazOccupationNonAg",
>           "R3.Reg3AgeOccupation",
>           "RK.Records_CL",
>           "V.Other")
>
> PViol.Type.Columns <- t(data.frame(PViol.Type)
>
> # What is the best way to do this in R?
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row-of-same-df-then-adjust-col1-data-display-tp4700878.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Thu Dec 18 17:12:23 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 18 Dec 2014 08:12:23 -0800 (PST)
Subject: [R] number of fuctions in a R-package
In-Reply-To: <011a01d01ad7$7ea88ad0$7bf9a070$@pt>
References: <011a01d01ad7$7ea88ad0$7bf9a070$@pt>
Message-ID: <alpine.BSF.2.00.1412180804300.44990@pedal.dcn.davis.ca.us>

IANAL and this is not a legal advice forum, but to the best of my 
knowledge... Yes it is allowable. Read the license. Your responsibilities 
and limitations have more to do with what to do if you decide to 
distribute your code. Also, there is no guarantee that CRAN will accept 
your contribution... you may have to distribute it yourself.

I hope you have reviewed existing contributions that take similar 
approaches (such as those discussed at [1]).

[1] http://stats.stackexchange.com/questions/5292/good-gui-for-r-suitable-for-a-beginner-wanting-to-learn-programming-in-r

On Thu, 18 Dec 2014, Diogo Andr? Alagador wrote:

> I would like to know if it is allowable to build an R-package made of one
> function only, to launch a GUI to take input data and users to select the
> models they intend to use, and to start running the processes?
>
>
>
> Thanks a lot,
>
> Diogo Alagador
>
> <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
> http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador
>
> CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University
> of ??ora, Portugal
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From chl948 at mail.usask.ca  Thu Dec 18 17:21:29 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 18 Dec 2014 10:21:29 -0600
Subject: [R] combinations between two vectors
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FC2384@mb02.ads.tamu.edu>
References: <1432216987.471665.1418914602848.JavaMail.yahoo@jws10053.mail.ne1.yahoo.com>
	<CAM_vju==Y9OVKeJMzeR+KmKK-7qMwzKU018DpxPOVsPSrdk0AA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FC2384@mb02.ads.tamu.edu>
Message-ID: <5492FF09.1080109@mail.usask.ca>

I like the example provided by David L. Carlson using the function 
'expand.grid()' as shown in the previous email.

You may try 'outer()' and 'upper.tri()' instead 'expand.grid()'.  Please 
see the below:

 > x <- outer(test, test, paste, sep=",")
 > x
      [,1]      [,2]         [,3]          [,4]          [,5]
[1,] "1,1"     "1,5001"     "1,10001"     "1,15001"     "1,20001"
[2,] "5001,1"  "5001,5001"  "5001,10001"  "5001,15001"  "5001,20001"
[3,] "10001,1" "10001,5001" "10001,10001" "10001,15001" "10001,20001"
[4,] "15001,1" "15001,5001" "15001,10001" "15001,15001" "15001,20001"
[5,] "20001,1" "20001,5001" "20001,10001" "20001,15001" "20001,20001"
[6,] "25001,1" "25001,5001" "25001,10001" "25001,15001" "25001,20001"
      [,6]
[1,] "1,25001"
[2,] "5001,25001"
[3,] "10001,25001"
[4,] "15001,25001"
[5,] "20001,25001"
[6,] "25001,25001"


 > x.idx <- upper.tri(x, diag=FALSE)
 > x[x.idx]
  [1] "1,5001"      "1,10001"     "5001,10001"  "1,15001"     "5001,15001"
  [6] "10001,15001" "1,20001"     "5001,20001"  "10001,20001" "15001,20001"
[11] "1,25001"     "5001,25001"  "10001,25001" "15001,25001" "20001,25001"

 > x.idx2 <- upper.tri(x, diag=TRUE)
 > x[x.idx2]
  [1] "1,1"         "1,5001"      "5001,5001"   "1,10001"     "5001,10001"
  [6] "10001,10001" "1,15001"     "5001,15001"  "10001,15001" "15001,15001"
[11] "1,20001"     "5001,20001"  "10001,20001" "15001,20001" "20001,20001"
[16] "1,25001"     "5001,25001"  "10001,25001" "15001,25001" "20001,25001"
[21] "25001,25001"
 >

I hope this helps.  Thank you, David, for your good lesson.

Chel Hee Lee, PhD.
Biostatistian and Manager
Clinical Research Support Unit
College of Medicine
University of Saskatchewan

On 12/18/2014 9:16 AM, David L Carlson wrote:
> Depending on what you want, you probably want to start with expand.grid():
>
> # All combinations of test with test
>> pairs1 <- expand.grid(test, test)
>> nrow(pairs1)
> [1] 36
> # Exclude cases that differ only in the order of the values
> # E.g. (1, 5001), but not (5001, 1), also (1, 1), etc are included
>> pairs2 <- pairs1[pairs1[,1] <= pairs1[,2],]
>> nrow(pairs2)
> [1] 21
> # Same as pairs2 but (1, 1), etc are not included
>> pairs3 <- pairs1[pairs1[,1] < pairs1[,2],]
>> nrow(pairs3)
> [1] 15
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah Goslee
> Sent: Thursday, December 18, 2014 9:06 AM
> To: Alaios
> Cc: R-help at r-project.org
> Subject: Re: [R] combinations between two vectors
>
> I can't quite tell what you want: your example output is either
> unclear to me or mangled by posting in HTML (please don't).
>
> Is
> expand.grid(test, test)
> what you want, or partway to what you want?
>
>
> Sarah
>
> On Thu, Dec 18, 2014 at 9:56 AM, Alaios via R-help <r-help at r-project.org> wrote:
>> Hi all,I am looking for a function that would give me all the combinations between two vectors.Lets take as example the
>>
>> test<-seq(1,30000,by=5000)
>> Browse[2]> test
>> [1]     1  5001 10001 15001 20001 25001
>> I want all the combinations between two times the test... I think this is  called permutation so a function that could do permutation(test,test)and produce the following
>> 1,11,50011,100011,15001....
>> 3,13,5001...25001,20001,25001,25001
>> is there such a function ?
>> RegardsAlex
>>
>>
>>          [[alternative HTML version deleted]]
>>
>


From xiaoheyiyh at yahoo.com  Thu Dec 18 17:59:47 2014
From: xiaoheyiyh at yahoo.com (heyi xiao)
Date: Thu, 18 Dec 2014 08:59:47 -0800
Subject: [R] Add encoded special characters (greek characters) as text
	to plot
In-Reply-To: <1418869545.890.YahooMailBasic@web162606.mail.bf1.yahoo.com>
Message-ID: <1418921987.7745.YahooMailBasic@web162602.mail.bf1.yahoo.com>

anybody has any hint on this? 

--------------------------------------------


 Subject: Add encoded special characters (greek characters) as text to plot
 To: r-help at r-project.org
 Date: Wednesday, December 17, 2014, 9:25 PM

 Dear all,
 I read my a character matrix from a text file. Some of them
 have greek characters. To reserve the special characters, I
 used stringsAsFactors=F using read.table. I notice that I
 can?t print these character string using print(), but I
 can use cat():
 > print("LC\246\302")
 [1] "LC\246\302"
 > cat("LC\246\302\n")
 LC?

 The problem is when I add text to my output plot like:
 text(x,y, labels="LC\246\302")

 I got "LC.. " on my plot. Obviously text function doesn?t
 know what?s "\246\302". I google that encoding, and
 can?t find exact what that is. It doesn?t look like
 ascii or Unicode. Anybody knows what that is?
 Note that I can?t use expression() method to pass these
 special characters because these are read from a text file,
 I just can?t include greek characters manually that way.
 Is there a way that I can output these strings with special
 characters automatically?
 Thank you!
 Heyi


From ripley at stats.ox.ac.uk  Thu Dec 18 18:31:42 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Dec 2014 17:31:42 +0000
Subject: [R] Add encoded special characters (greek characters) as text
 to plot
In-Reply-To: <1418921987.7745.YahooMailBasic@web162602.mail.bf1.yahoo.com>
References: <1418921987.7745.YahooMailBasic@web162602.mail.bf1.yahoo.com>
Message-ID: <54930F7E.3080705@stats.ox.ac.uk>

On 18/12/2014 16:59, heyi xiao via R-help wrote:
> anybody has any hint on this?

Yes, ?plotmath does. But you will need to know what encoding this is 
(and hence what Unicode points are meant by \246 and \302).

If this really were Greek, common encodings are UTF-8, CP1253 and ISO 
8859-7; however \246 and \302 are not Greek glyphs in any of those.  E.g.

 > iconv("LC\246\302\n", "cp1253")
[1] "LC??\n"

(which may not come out in your mail client).

BTW, "\246" is explained in ?Quotes.

>
> --------------------------------------------
>
>
>   Subject: Add encoded special characters (greek characters) as text to plot
>   To: r-help at r-project.org
>   Date: Wednesday, December 17, 2014, 9:25 PM
>
>   Dear all,
>   I read my a character matrix from a text file. Some of them
>   have greek characters. To reserve the special characters, I
>   used stringsAsFactors=F using read.table. I notice that I
>   can?t print these character string using print(), but I
>   can use cat():
>   > print("LC\246\302")
>   [1] "LC\246\302"
>   > cat("LC\246\302\n")
>   LC?
>
>   The problem is when I add text to my output plot like:
>   text(x,y, labels="LC\246\302")
>
>   I got "LC.. " on my plot. Obviously text function doesn?t
>   know what?s "\246\302". I google that encoding, and
>   can?t find exact what that is. It doesn?t look like
>   ascii or Unicode. Anybody knows what that is?
>   Note that I can?t use expression() method to pass these
>   special characters because these are read from a text file,
>   I just can?t include greek characters manually that way.
>   Is there a way that I can output these strings with special
>   characters automatically?
>   Thank you!
>   Heyi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jdnewmil at dcn.davis.CA.us  Thu Dec 18 18:48:13 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 18 Dec 2014 09:48:13 -0800
Subject: [R] Add encoded special characters (greek characters) as
	text	to plot
In-Reply-To: <1418921987.7745.YahooMailBasic@web162602.mail.bf1.yahoo.com>
References: <1418921987.7745.YahooMailBasic@web162602.mail.bf1.yahoo.com>
Message-ID: <254764A3-3954-416D-BD67-7D12D465BC5E@dcn.davis.CA.us>

Read the posting guide. The solution is likely to depend on your operating system and graphics devices.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 18, 2014 8:59:47 AM PST, heyi xiao via R-help <r-help at r-project.org> wrote:
>anybody has any hint on this? 
>
>--------------------------------------------
>
>
>Subject: Add encoded special characters (greek characters) as text to
>plot
> To: r-help at r-project.org
> Date: Wednesday, December 17, 2014, 9:25 PM
>
> Dear all,
> I read my a character matrix from a text file. Some of them
> have greek characters. To reserve the special characters, I
> used stringsAsFactors=F using read.table. I notice that I
> can?t print these character string using print(), but I
> can use cat():
> > print("LC\246\302")
> [1] "LC\246\302"
> > cat("LC\246\302\n")
> LC?
>
> The problem is when I add text to my output plot like:
> text(x,y, labels="LC\246\302")
>
> I got "LC.. " on my plot. Obviously text function doesn?t
> know what?s "\246\302". I google that encoding, and
> can?t find exact what that is. It doesn?t look like
> ascii or Unicode. Anybody knows what that is?
> Note that I can?t use expression() method to pass these
> special characters because these are read from a text file,
> I just can?t include greek characters manually that way.
> Is there a way that I can output these strings with special
> characters automatically?
> Thank you!
> Heyi
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Thu Dec 18 19:36:08 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 18 Dec 2014 12:36:08 -0600
Subject: [R] Your pardon: An article possibly of interest to statisticians
Message-ID: <CAAJSdjicgTd2=AB9=+pkN1tkXL0U1EC7JV7CFghOG-SHNmH08w@mail.gmail.com>

I do hope this doesn't upset anyone. But it appears rather interesting to
me, despite the fact that I'm not a statistician. So I thought that it
might be of interest to some others here.

https://medium.com/the-physics-arxiv-blog/cause-and-effect-the-revolutionary-new-statistical-test-that-can-tease-them-apart-ed84a988e

http://arxiv.org/abs/1412.3773

Title: Distinguishing cause from effect using observational data: methods
and benchmarks
<quote>
The discovery of causal relationships from purely observational data is a
fundamental problem in science. The most elementary form of such a causal
discovery problem is to decide whether X causes Y or, alternatively, Y
causes X, given joint observations of two variables X, Y . This was often
considered to be impossible. Nevertheless, several approaches for
addressing this bivariate causal discovery problem were proposed recently.
In this paper, we present the benchmark data set CauseEffectPairs that
consists of 88 different "cause-effect pairs" selected from 31 datasets
from various domains. We evaluated the performance of several bivariate
causal discovery methods on these real-world benchmark data and on
artificially simulated data. Our empirical results provide evidence that
additive-noise methods are indeed able to distinguish cause from effect
using only purely observational data. In addition, we prove consistency of
the additive-noise method proposed by Hoyer et al. (2009).
</quote>

Returning to lurkerdom.

-- 
?
While a transcendent vocabulary is laudable, one must be eternally careful
so that the calculated objective of communication does not become ensconced
in obscurity.  In other words, eschew obfuscation.

111,111,111 x 111,111,111 = 12,345,678,987,654,321

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From aoife.marie.doherty at gmail.com  Thu Dec 18 15:38:33 2014
From: aoife.marie.doherty at gmail.com (aoife doherty)
Date: Thu, 18 Dec 2014 14:38:33 +0000
Subject: [R] exclude missing co-variable data in cox model
In-Reply-To: <mailman.172.1418836756.3278.r-help@r-project.org>
References: <mailman.172.1418836756.3278.r-help@r-project.org>
Message-ID: <CAP3fhYeNm47RXTXZtCWYBC9u0eTO06EbxxCxU_4jQxX57V85jg@mail.gmail.com>

Hi all,

I have a data set like this:

Test.cox file:

V1        V2         V3                Survival       Event
ann      13          WTHomo          4                1
ben      20          *                        5                1
tom      40         Variant               6                1

where "*" indicates that I don't know what the value is for V3 for Ben.

I've set up a Cox model to run like this:

#!/usr/bin/Rscript
library(bdsmatrix)
library(kinship2)
library(survival)
library(coxme)
death.dat <- read.table("Test.cox",header=T)
deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
sink("Test.cox.R.Output")
Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
strata(factor(V2)) + factor(V3)) +
(1|ID),data=death.dat,varlist=deathdat.kmat)
Model
sink()


As you can see from the Test.cox file, I have a missing value "*". How do I
alter the R script to include "treat * as a missing variable". If I can't
incorporate missing values into the model, I assume the alternative is to
remove all of the rows with missing data, which will greatly reduce my data
set, as most rows have at least one missing variable.

Thanks

On Wed, Dec 17, 2014 at 5:19 PM, <r-help-owner at r-project.org> wrote:
>
> Message rejected by filter rule match
>
>
>
> ---------- Forwarded message ----------
> From: Eva Marie <aoife.marie.doherty at gmail.com>
> To: r-help at r-project.org
> Cc:
> Date: Wed, 17 Dec 2014 09:09:52 -0800 (PST)
> Subject: exclude missing co-variable data in cox model
> Hi all,
>
> I have a data set like this:
>
> Test.cox file:
>
>
>
> where "*" indicates that I don't know what the value is for V3 for Ben.
>
> I've set up a Cox model to run like this:
>
>
>
>
> As you can see from the Test.cox file, I have a missing value "*". How and
> where do I tell the R script "treat * as a missing variable". If I can't
> incorporate missing values into the model, I assume the alternative is to
> remove all of the rows with missing data, which will greatly reduce my data
> set, as most rows have at least one missing variable.
>
> Thanks
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/exclude-missing-co-variable-data-in-cox-model-tp4700864.html
> Sent from the R help mailing list archive at Nabble.com.
>
>
>

	[[alternative HTML version deleted]]


From bcrombie at utk.edu  Thu Dec 18 14:09:26 2014
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Thu, 18 Dec 2014 13:09:26 +0000
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <DA47BE11-8B6F-4862-A9F3-CBFDFDD23A11@utoronto.ca>
References: <1418872514464-4700878.post@n4.nabble.com>
	<DA47BE11-8B6F-4862-A9F3-CBFDFDD23A11@utoronto.ca>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CEE5117C18@kmbx4.utk.tennessee.edu>

I want to achieve a table that looks like a grid of 1's for all cases in a survey.  I'm an R beginner and don't have a clue how to do all the things you just suggested.  I really appreciate the time you took to explain all of those options, though.  -- BNC

-----Original Message-----
From: Boris Steipe [mailto:boris.steipe at utoronto.ca] 
Sent: Thursday, December 18, 2014 5:29 AM
To: Crombie, Burnette N
Cc: r-help at r-project.org
Subject: Re: [R] Make 2nd col of 2-col df into header row of same df then adjust col1 data display

What you are describing sounds like a very spreadsheet-y thing. 

- The information is already IN your dataframe, and easy to get out by subsetting. Depending on your usecase, that may actually be the "best". 

- If the number of CaseIDs is large, I would use a hash of lists (if the data is sparse), or hash of named vectors if it's not sparse. Lookup is O(1) so that may be the best. (Cf package hash, and explanations there). 

- If it must be the spreadsheet-y thing, you could make a matrix with rownames and colnames taken from unique() of your respective dataframe. Instead of 1 and NA I probably would use TRUE/FALSE. 

- If it takes less time to wait for the results than to look up how apply() works, you can write a simple loop to populate your matrix. Otherwise apply() is much faster. 

- You could even use a loop to build the datastructure, checking for every cbind() whether the value in column 1 already exists in the table - but that's terrible and would make a kitten die somewhere on every iteration.

All of these are possible, and you haven't told us enough about what you want to achieve to figure out what the "best" is. If you choose one of the options and need help with the code, let us know.

Cheers,
B.





On Dec 17, 2014, at 10:15 PM, bcrombie <bcrombie at utk.edu> wrote:

> # I have a dataframe that contains 2 columns:
> CaseID  <- c('1015285',
> '1005317',
> '1012281',
> '1015285',
> '1015285',
> '1007183',
> '1008833',
> '1015315',
> '1015322',
> '1015285')
> 
> Primary.Viol.Type <- c('AS.Age',
> 'HS.Hours',
> 'HS.Hours',
> 'HS.Hours',
> 'RK.Records_CL',
> 'OT.Overtime',
> 'OT.Overtime',
> 'OT.Overtime',
> 'V.Poster_Other',
> 'V.Poster_Other')
> 
> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
> 
> # CaseID's can be repeated because there can be up to 14 
> Primary.Viol.Type's per CaseID.
> 
> # I want to transform this dataframe into one that has 15 columns, 
> where the first column is CaseID, and the rest are the 14 primary 
> viol. types.  The CaseID column will contain a list of the unique 
> CaseID's (no replicates) and for each of their rows, there will be a 
> "1" under  a column corresponding to a primary violation type recorded 
> for that CaseID.  So, technically, there could be zero to 14 "1's" in a CaseID's row.
> 
> # For example, the row for CaseID '1015285' above would have a "1" 
> under "AS.Age", "HS.Hours", "RK.Records_CL", and "V.Poster_Other", but have "NA"
> under the rest of the columns.
> 
> PViol.Type <- c("CaseID",
>                "BW.BackWages",
>           "LD.Liquid_Damages",
>           "MW.Minimum_Wage",
>           "OT.Overtime",
>           "RK.Records_FLSA",
>           "V.Poster_Other",
>           "AS.Age",
>           "BW.WHMIS_BackWages",
>           "HS.Hours",
>           "OA.HazOccupationAg",
>           "ON.HazOccupationNonAg",
>           "R3.Reg3AgeOccupation",
>           "RK.Records_CL",
>           "V.Other")
> 
> PViol.Type.Columns <- t(data.frame(PViol.Type)
> 
> # What is the best way to do this in R?
> 
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row
> -of-same-df-then-adjust-col1-data-display-tp4700878.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From christiano.brodii at gmail.com  Thu Dec 18 10:23:09 2014
From: christiano.brodii at gmail.com (Christian Brodbeck)
Date: Thu, 18 Dec 2014 10:23:09 +0100
Subject: [R] Problems with spatial data for Masterthesis
Message-ID: <98E2EA55-7005-4B61-BA38-A3932FAE213A@gmail.com>

Hi

I write my masterthesis and don't know how I can count points in a spatial net.

In practical I have a data set for carsharing usage in Berlin. It includes the Idletime of the cars with Long/lat coordinates for the certain places. So if I plot those points I have something like a cloud of points over the area of Berlin. SoMy task is, to find out, in which area of Berlin is the idletime of the carsharing the logest. Therefor I wanted to cluster the innercity of Berlin. I loaded a kml file about the districts of berlin and put the "net" together with the cloud of points. So graphically it works and looks nice. By now I have to find out at wihich district shows the most idletimes. 
Do you know a package/program-codeexample which can handle this problem. In other words which can count the points located in the several districts?
I would be very thankful for your help

Regards

Chris

From guillaume.souchay at gmail.com  Thu Dec 18 14:49:56 2014
From: guillaume.souchay at gmail.com (Guillaume Souchay)
Date: Thu, 18 Dec 2014 14:49:56 +0100
Subject: [R] Fitting Structural Equation Model with sem package and Summary
	issues
Message-ID: <CAEE5xg9ttm7c24g4JOmO6cHDr3WNVYNgkfi5p3wPM3dEbkvFJw@mail.gmail.com>

Hi all,

I am trying to analyse bird data to investigate carry-over effect
using structural equation model.
I failed to run properly a big model with several latent variables
with both L -> M block and M -> L block.
Rather than trying again and again with the huge model, I am now
looking to a subset of the model.

Due to previous error message (singularity in the matrix), I scaled
all the variables.
Here is a subset of the data:
> dataE[1:15,]
   Fledgling_date_t Total_Output_t Breed_nb.clutch_t.1 Breed_Egg_t.1
Breed_Total_Output_t.1
1        1.09397971     1.19657515           0.4696909   -0.69784742
           1.2558119
2        0.62564592     0.37786584           0.4696909    0.02046473
          -0.1762543
3        1.51548013     1.19657515          -1.0568046    0.89840181
          -1.8947338
4        0.15731212     1.60592981          -1.0568046   -1.49597204
          -1.3219073
5        0.48514578    -0.44084348           0.4696909   -0.69784742
           0.6829854
6        1.93698054    -0.03148882           0.4696909    0.02046473
           0.9693987
7       -1.66918968    -0.85019813          -1.0568046    0.97821428
          -0.4626676
8        0.01681198     0.78722049           0.4696909   -0.53822250
           1.2558119
9        0.34464564     1.60592981          -1.0568046   -0.13916019
          -1.8947338
10       1.23447985     1.19657515          -1.0568046    1.93596382
          -0.7490808
11      -0.12368816    -0.85019813           0.4696909    1.93596382
           0.1101589
12      -0.17052154     0.78722049          -1.0568046   -0.45841004
          -0.1762543
13      -1.52868954    -0.44084348          -1.0568046    1.37727658
          -0.4626676
14       0.15731212    -1.25955279          -1.0568046    1.61671397
          -0.4626676
15      -0.17052154    -0.85019813          -1.0568046    0.97821428
          -1.6083205

Library(sem)
# the covariance matrix for scaled data
S.covE <- readMoments(diag=T,names=c("Fledgling_date_t","Total_Output_t","Breed_nb.clutch_t.1","Breed_Egg_t.1","Breed_Total_Output_t.1"))
1.0000000
0.350170246 1.0000000
-0.075832501 -0.099929893 1.0000000
-0.15439341 -0.091334987 -0.131698418 1.0000000
-0.191457491 -0.227843749 0.510666663 -0.386711653 1.0000000

# specification of the model - I also provided a diagram of the model
in the attached PDF.
modelE <- specifyModel()
EndBreed -> Fledgling_date_t,                       lambda1,   NA
EndBreed -> Total_Output_t,                         lambda1,   NA
Fledgling_date_t <-> Fledgling_date_t,              delta1,    NA
Total_Output_t <-> Total_Output_t,                  delta2,    NA
Fledgling_date_t <-> Total_Output_t,                theta1,    NA
EndBreed -> BreedSucc,                              gamma1,    NA
EndBreed <-> EndBreed,                              phi1,      NA
BreedSucc -> Breed_Egg_t.1,                         lamdae,    NA
BreedSucc -> Breed_Total_Output_t.1,                lamdae,    NA
BreedSucc -> Breed_nb.clutch_t.1,                   lamdae,    NA
Breed_nb.clutch_t.1 <-> Breed_nb.clutch_t.1,        eps1,      NA
Breed_Egg_t.1 <-> Breed_Egg_t.1,                    eps2,      NA
Breed_Total_Output_t.1 <-> Breed_Total_Output_t.1,  eps3,      NA
Breed_nb.clutch_t.1 <-> Breed_Egg_t.1,              psie12,    NA
Breed_Egg_t.1 <-> Breed_Total_Output_t.1,           psie23,    NA
Breed_nb.clutch_t.1 <-> Breed_Total_Output_t.1,     psie13,    NA
BreedSucc <-> BreedSucc,                            zetae,     NA

# estimation of the model
semE <- sem(modelE,S.covE,N=39,debug=T)

To this point, everything seemed fine, the parameter were estimated
after 129 iterations with all data.
However, the problem arised when I asked for a summary of the model:

> summary(semE)
Error in summary.objectiveML(semE) :
  coefficient covariances cannot be computed

But the model seemed to work well :

> semE

 Model Chisquare =  0.9876903   Df =  1

   lambda1     delta1     delta2     theta1     gamma1       phi1
lamdae       eps1       eps2
 0.8251654  0.3302009  0.3418300 -0.3138143  0.4122545  0.9752364
-0.4671335  0.8020365  0.7857964
      eps3     psie12     psie23     psie13      zetae
 0.7461566 -0.3377820 -0.6207350  0.2847632  0.8828395

 Iterations =  75
> semE$convergence
[1] TRUE

I also tried with using SpecifyEquations() instead of SpecifyModel() :
# specification of the model using specifyEquations
modelEe <- specifyEquations()
Fledgling_date_t = lambda1*EndBreed
Total_Output_t = lambda1*EndBreed
c(Fledgling_date_t,Total_Output_t) = theta1
Breed_nb.clutch_t.1 = lamdae*BreedSucc
Breed_Egg_t.1 = lamdae*BreedSucc
Breed_Total_Output_t.1 = lamdae*BreedSucc
c(Breed_nb.clutch_t.1,Breed_Egg_t.1) = psi12
c(Breed_nb.clutch_t.1,Breed_Total_Output_t.1) = psi13
c(Breed_Egg_t.1,Breed_Total_Output_t.1) = psi23
BreedSucc = gamma1*EndBreed
v(EndBreed) = phi1
v(BreedSucc) = zeta1
v(Fledgling_date_t) = delta1
v(Total_Output_t) = delta2
v(Breed_nb.clutch_t.1) = eps1
v(Breed_Egg_t.1) = eps2
v(Breed_Total_Output_t.1) = eps3

# estimation of the model
semEe <- sem(modelEe,covE,N=39,debug=T)

> semEe

 Model Chisquare =  0.9876903   Df =  1

   lambda1     theta1     lamdae      psi12      psi13      psi23
gamma1       phi1      zeta1
 0.8220182 -0.3346606  0.5034442 -0.3550646  0.2674806 -0.6380177
-0.3694630  1.0135693  0.8326144
    delta1     delta2       eps1       eps2       eps3
 0.3093554  0.3209828  0.7847537  0.7685137  0.7288741

 Iterations =  79
> summary(semEe)
Error in summary.objectiveML(semEe) :
  coefficient covariances cannot be computed

I also tried to set one loading to 1 instead of setting equality among
loadings, but the results were the same.

Could it be possible that the low number of data (N=39 but no NA
inside) may be the cause of the error?
In the model, the df is 1, thus all the parameters should be identifiable.

Hoping you will have enough information to help a bit.

Thanks in advance.

Cheers,

Guillaume

-- 

Guillaume SOUCHAY, Ph.D

Post-doctoral fellow in population dynamics

---

"There is no true model" Anderson & Burhnam 1999

---

?


From shouro at gmail.com  Thu Dec 18 16:12:34 2014
From: shouro at gmail.com (Shouro Dasgupta)
Date: Thu, 18 Dec 2014 16:12:34 +0100
Subject: [R] R - Aggregate 3-Hourly Block Data into Weekly (Melt)
Message-ID: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>

I am trying to compute max, min, and mean from Global Circulation Models
(GCM) for the US. The data is in 3-hour blocks for 2026-2045 and 2081-2100.
Sample Data:

tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 =
c(285.5533142,
  285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
  285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
  ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
      X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
      X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071)),
.Names = c("FIPS",
  "X2026.01.01.1", "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
  "X2026.01.01.5", "X2026.01.01.6"), class = "data.frame", row.names = c(NA,
  -3L))

I have extracted the data by FIPS code and reshaped the yearly data files
using melt();

for (i in filelist) {
  tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
  tmp2 <- melt(tmp1, id="FIPS")
  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))}

I have added datestring and weekdays using the following code:
Inserting Date Variable

tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month, day)))

Inserting Day Variable

tmp2$day <- weekdays(as.Date(tmp2$date))

sample.tmp2 <- "FIPS         xdate     temp year month      day
date      dates weekdays
+ 5599311  1003 X2045.08.14.2 304.5995 2045     8   Monday 2045-08-14
2036-01-29        2
+ 468406  39093 X2045.01.19.7 267.8483 2045     1 Thursday 2045-01-19
2028-06-04        0
+ 5022078 21167 X2045.07.21.8 314.6772 2045     7   Friday 2045-07-21
2035-09-13        4
+ 186822   9005 X2045.01.08.5 269.0803 2045     1   Sunday 2045-01-08
2037-06-28        0
+ 3998678 13295 X2045.06.10.7 307.2408 2045     6 Saturday 2045-06-10
2033-10-13        4"

Data <- read.table(text=sample.tmp2, header = TRUE)

My goal is to aggregate these 3-hourly blocks into weekly data, however,
GCM data is not consistent and the blocks vary between 7 and 8. I want to
clip the data to start on the first Monday of 2026 and end on the last
Sunday of 2045 and then use rep() to assign week numbers for the whole
epoch.

I know I can count the number of each day using something like this;

length(which(weekdays == '0'))

Where 0, 1, 2..., 6 represent Sunday, Monday,...

My question is am I doing anything wrong in trying to aggregate the data to
begin with? But importantly, I would be grateful for any help to clip the
dataset to begin on the first Monday and end on the last Sunday. Thank you
very much!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Dec 18 20:32:08 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 18 Dec 2014 11:32:08 -0800
Subject: [R] Problems with spatial data for Masterthesis
In-Reply-To: <98E2EA55-7005-4B61-BA38-A3932FAE213A@gmail.com>
References: <98E2EA55-7005-4B61-BA38-A3932FAE213A@gmail.com>
Message-ID: <110C559F-A972-431F-AC25-9D18FC37C6BA@dcn.davis.CA.us>

Depending how your data are stored, this could be solved with a very basic use of R, such as the ifelse and aggregate functions. Try reading [1] for suggestions on clarifying your problem statement and follow up. 

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 18, 2014 1:23:09 AM PST, Christian Brodbeck <christiano.brodii at gmail.com> wrote:
>Hi
>
>I write my masterthesis and don't know how I can count points in a
>spatial net.
>
>In practical I have a data set for carsharing usage in Berlin. It
>includes the Idletime of the cars with Long/lat coordinates for the
>certain places. So if I plot those points I have something like a cloud
>of points over the area of Berlin. SoMy task is, to find out, in which
>area of Berlin is the idletime of the carsharing the logest. Therefor I
>wanted to cluster the innercity of Berlin. I loaded a kml file about
>the districts of berlin and put the "net" together with the cloud of
>points. So graphically it works and looks nice. By now I have to find
>out at wihich district shows the most idletimes. 
>Do you know a package/program-codeexample which can handle this
>problem. In other words which can count the points located in the
>several districts?
>I would be very thankful for your help
>
>Regards
>
>Chris
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Thu Dec 18 20:43:07 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 18 Dec 2014 13:43:07 -0600
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
References: <1418872514464-4700878.post@n4.nabble.com>
	<alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
Message-ID: <54932E4B.8030009@mail.usask.ca>

I like the approach presented by Jeff Newmiller as shown in the previous 
post (I really like his way).  As he suggested, it would be good to 
start with 'factor' since you have all values of 'Primary.Viol.Type'. 
You may try to use 'split()' function for creating table that you wish 
to build.  Please see the below (I hope this helps):

 > PViol.Type.Per.Case.Original$Primary.Viol.Type <- 
factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)
 >
 > tmp <- split(PViol.Type.Per.Case.Original, 
PViol.Type.Per.Case.Original$CaseID)
 > ans <- ifelse(do.call(rbind, lapply(tmp, function(x) 
table(x$Primary.Viol.Type))), 1, NA)
 > ans
         CaseID BW.BackWages LD.Liquid_Damages MW.Minimum_Wage OT.Overtime
1005317     NA           NA                NA              NA          NA
1007183     NA           NA                NA              NA           1
1008833     NA           NA                NA              NA           1
1012281     NA           NA                NA              NA          NA
1015285     NA           NA                NA              NA          NA
1015315     NA           NA                NA              NA           1
1015322     NA           NA                NA              NA          NA
         RK.Records_FLSA V.Poster_Other AS.Age BW.WHMIS_BackWages HS.Hours
1005317              NA             NA     NA                 NA        1
1007183              NA             NA     NA                 NA       NA
1008833              NA             NA     NA                 NA       NA
1012281              NA             NA     NA                 NA        1
1015285              NA              1      1                 NA        1
1015315              NA             NA     NA                 NA       NA
1015322              NA              1     NA                 NA       NA
         OA.HazOccupationAg ON.HazOccupationNonAg R3.Reg3AgeOccupation
1005317                 NA                    NA                   NA
1007183                 NA                    NA                   NA
1008833                 NA                    NA                   NA
1012281                 NA                    NA                   NA
1015285                 NA                    NA                   NA
1015315                 NA                    NA                   NA
1015322                 NA                    NA                   NA
         RK.Records_CL V.Other
1005317            NA      NA
1007183            NA      NA
1008833            NA      NA
1012281            NA      NA
1015285             1      NA
1015315            NA      NA
1015322            NA      NA
 >

Chel Hee Lee

On 12/18/2014 10:02 AM, Jeff Newmiller wrote:
> No guarantees on "best"... but one way using base R could be:
>
> # Note that "CaseID" is actually not a valid PViol.Type as you had it
> PViol.Type <- c( "BW.BackWages"
>                 , "LD.Liquid_Damages"
>                 , "MW.Minimum_Wage"
>                 , "OT.Overtime"
>                 , "RK.Records_FLSA"
>                 , "V.Poster_Other"
>                 , "AS.Age"
>                 , "BW.WHMIS_BackWages"
>                 , "HS.Hours"
>                 , "OA.HazOccupationAg"
>                 , "ON.HazOccupationNonAg"
>                 , "R3.Reg3AgeOccupation"
>                 , "RK.Records_CL"
>                 , "V.Other" )
>
> # explicitly specifying all levels to the factor insures a complete
> # set of column outputs regardless of what is in the input
> PViol.Type.Per.Case.Original <-
>      data.frame( CaseID
>                , Primary.Viol.Type=factor( Primary.Viol.Type
>                                          , levels=PViol.Type ) )
>
> tmp <- table( PViol.Type.Per.Case.Original )
> ans <- data.frame( CaseID=rownames( tmp )
>                   , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
>                   )
>
>
> On Wed, 17 Dec 2014, bcrombie wrote:
>
>> # I have a dataframe that contains 2 columns:
>> CaseID  <- c('1015285',
>> '1005317',
>> '1012281',
>> '1015285',
>> '1015285',
>> '1007183',
>> '1008833',
>> '1015315',
>> '1015322',
>> '1015285')
>>
>> Primary.Viol.Type <- c('AS.Age',
>> 'HS.Hours',
>> 'HS.Hours',
>> 'HS.Hours',
>> 'RK.Records_CL',
>> 'OT.Overtime',
>> 'OT.Overtime',
>> 'OT.Overtime',
>> 'V.Poster_Other',
>> 'V.Poster_Other')
>>
>> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>>
>> # CaseID?s can be repeated because there can be up to 14
>> Primary.Viol.Type?s
>> per CaseID.
>>
>> # I want to transform this dataframe into one that has 15 columns,
>> where the
>> first column is CaseID, and the rest are the 14 primary viol. types.  The
>> CaseID column will contain a list of the unique CaseID?s (no
>> replicates) and
>> for each of their rows, there will be a ?1? under  a column
>> corresponding to
>> a primary violation type recorded for that CaseID.  So, technically,
>> there
>> could be zero to 14 ?1?s? in a CaseID?s row.
>>
>> # For example, the row for CaseID '1015285' above would have a ?1? under
>> ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?, but have
>> "NA"
>> under the rest of the columns.
>>
>> PViol.Type <- c("CaseID",
>>                "BW.BackWages",
>>           "LD.Liquid_Damages",
>>           "MW.Minimum_Wage",
>>           "OT.Overtime",
>>           "RK.Records_FLSA",
>>           "V.Poster_Other",
>>           "AS.Age",
>>           "BW.WHMIS_BackWages",
>>           "HS.Hours",
>>           "OA.HazOccupationAg",
>>           "ON.HazOccupationNonAg",
>>           "R3.Reg3AgeOccupation",
>>           "RK.Records_CL",
>>           "V.Other")
>>
>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>>
>> # What is the best way to do this in R?
>>
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row-of-same-df-then-adjust-col1-data-display-tp4700878.html
>>
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Thu Dec 18 21:43:53 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 18 Dec 2014 14:43:53 -0600
Subject: [R] Add encoded special characters (greek characters) as text
 to plot
In-Reply-To: <254764A3-3954-416D-BD67-7D12D465BC5E@dcn.davis.CA.us>
References: <1418921987.7745.YahooMailBasic@web162602.mail.bf1.yahoo.com>
	<254764A3-3954-416D-BD67-7D12D465BC5E@dcn.davis.CA.us>
Message-ID: <54933C89.6060808@mail.usask.ca>

Why don't you try this approach if you cannot use 'expression()'?

 > x <- c("alpha", "beta", "gamma", "delta")
 > plot(0, type="n")
 > for(i in 1:length(x)) text(x=1, y=i/10, labels=parse(text=x[i]))

Please see the output in R.  Is this what you are looking for?  I hope 
this helps.  I would also appreciate it if you would provide 
reproducible examples next time.

Chel Hee Lee

On 12/18/2014 11:48 AM, Jeff Newmiller wrote:
> Read the posting guide. The solution is likely to depend on your operating system and graphics devices.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On December 18, 2014 8:59:47 AM PST, heyi xiao via R-help <r-help at r-project.org> wrote:
>> anybody has any hint on this?
>>
>> --------------------------------------------
>>
>>
>> Subject: Add encoded special characters (greek characters) as text to
>> plot
>> To: r-help at r-project.org
>> Date: Wednesday, December 17, 2014, 9:25 PM
>>
>> Dear all,
>> I read my a character matrix from a text file. Some of them
>> have greek characters. To reserve the special characters, I
>> used stringsAsFactors=F using read.table. I notice that I
>> can?t print these character string using print(), but I
>> can use cat():
>>> print("LC\246\302")
>> [1] "LC\246\302"
>>> cat("LC\246\302\n")
>> LC?
>>
>> The problem is when I add text to my output plot like:
>> text(x,y, labels="LC\246\302")
>>
>> I got "LC.. " on my plot. Obviously text function doesn?t
>> know what?s "\246\302". I google that encoding, and
>> can?t find exact what that is. It doesn?t look like
>> ascii or Unicode. Anybody knows what that is?
>> Note that I can?t use expression() method to pass these
>> special characters because these are read from a text file,
>> I just can?t include greek characters manually that way.
>> Is there a way that I can output these strings with special
>> characters automatically?
>> Thank you!
>> Heyi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From robin at lindinglab.org  Thu Dec 18 23:03:30 2014
From: robin at lindinglab.org (Xavier Robin)
Date: Thu, 18 Dec 2014 23:03:30 +0100
Subject: [R] Maximum likelihood with analytical Hessian and
In-Reply-To: <5492E06A.1010806@uottawa.ca>
References: <mailman.1.1418900401.5963.r-help@r-project.org>
	<5492E06A.1010806@uottawa.ca>
Message-ID: <54934F32.2000708@lindinglab.org>

Dear John,

Thank you for your suggestions.
I'll have a look at the trust package - the trust zone may be doing what
I need.
The tanh transformation could be a good alternative too.

Best wishes
Xavier


On 18. 12. 14 15:10, Prof J C Nash (U30A) wrote:
> Of the tools I know (and things change every day!), only package trust
> uses the Hessian explicitly.
>
> It would not be too difficult to include explicit Hessian by modifying
> Rvmmin which is all in R -- I'm currently doing some cleanup on that, so
> ask offline if you choose that route.
>
> Given that some parameters are between 0 and 1, you could use the
> hyperbolic transformation (section 11.2 of my book Nonlinear parameter
> optimization using R tools) with trust, and I think I'd try that as a
> first attempt. You probably need to adjust the Hessian for the
> transformation carefully.
>
> Generally the work in computing the Hessian ( # obs * (# parameters)^2
> in size) is not worth the effort, but there are problems for which it
> does make a lot of sense.
>
> JN
>
> On 14-12-18 06:00 AM, r-help-request at r-project.org wrote:
>> Message: 12
>> Date: Wed, 17 Dec 2014 21:46:16 +0100
>> From: Xavier Robin <robin at lindinglab.org>
>> To: r-help at r-project.org
>> Subject: [R] Maximum likelihood with analytical Hessian and
>> Message-ID: <5491EB98.6090606 at lindinglab.org>
>> Content-Type: text/plain; charset=utf-8
>>
>> Dear list,
>>
>> I have an optimization problem that I would like to solve by Maximum
>> Likelihood.
>> I have analytical functions for the first and second derivatives of my
>> parameters.
>> In addition, some parameters are constrained between 0 and 1, while some
>> others can vary freely between -Inf and +Inf.
>>
>> I am looking for an optimization function to solve this problem.
>>
>> I understand that the base optim function doesn't take a Hessian
>> function, it only computes it numerically.
>> I found the maxLik package that takes the function as a "hess" parameter
>> but the maxNR method (the only one that uses the Hessian function) can't
>> be bounded.
>> Surprisingly I couldn't find a function doing both.
>>
>> Any suggestions for a function doing bounded optimization with an
>> analytical Hessian function?
>>
>> Thanks,
>> Xavier
>>
>>


-- 
Xavier Robin, PhD
Cellular Signal Integration Group (C-SIG)  - Linding Lab
Biotech Research and Innovation Center (BRIC) - University of Copenhagen
Anker Engelundsvej, DTU Campus, Building 301, DK-2800 Lyngby, DENMARK
Mobile: +45 42 799 833
www.lindinglab.org - www.bric.ku.dk


From jdnewmil at dcn.davis.CA.us  Fri Dec 19 05:21:30 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 18 Dec 2014 20:21:30 -0800
Subject: [R] Make 2nd col of 2-col df into header row of same df then
	adjust col1 data display
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CEE5117DEB@kmbx4.utk.tennessee.edu>
References: <1418872514464-4700878.post@n4.nabble.com>
	<alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
	<559C998F7039D84C9793AE43D9BBE9CEE5117DEB@kmbx4.utk.tennessee.edu>
Message-ID: <0541E0A3-3A7F-4935-828B-F78F164B5353@dcn.davis.CA.us>

Please keep the list in the loop.

Take a look at my code again... the factor function can accept a vector of all levels you want it to include.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 18, 2014 7:35:28 PM PST, "Crombie, Burnette N" <bcrombie at utk.edu> wrote:
>Jeff, your code works fabulously on the dataset I submitted with my
>question, but I can't get it to retain all 14 of the PViol.Type's  with
>my real dataset which is imported as a csv.  Do you have any ideas how
>to fix this?
>
>##########
>MERGE_PViol.Detail.Per.Case <-
>read.csv("~/FOIA_FLSA/MERGE_PViol.Detail.Per.Case_for_rtf10.csv",
>stringsAsFactors=TRUE)
>
>###select only certain columns from dataset
>PViol.Type.Per.Case <- MERGE_PViol.Detail.Per.Case[,c("CaseID",
>"Primary.Viol.Type")]
>PViol.Type.Per.Case$CaseID <- factor(PViol.Type.Per.Case$CaseID)
>str(PViol.Type.Per.Case)
>### 'data.frame':	13 obs. of  2 variables:
>###  $ CaseID           : Factor w/ 8 levels "1005317","1007183",..: 5
>1 4 5 5 2 3 6 7 8 ...
>### $ Primary.Viol.Type: Factor w/ 5 levels "AS.Age","HS.Hours",..: 1 2
>2 2 4 3 3 3 3 3 ...
>
>
>PViol.Type <- c("BW.BackWages",
>                "LD.Liquid_Damages",
>                "MW.Minimum_Wage",
>                "OT.Overtime",
>                "RK.Records_FLSA",
>                "V.Poster_Other",
>                "AS.Age",
>                "BW.WHMIS_BackWages",
>                "HS.Hours",
>                "OA.HazOccupationAg",
>                "ON.HazOccupationNonAg",
>                "R3.Reg3AgeOccupation",
>                "RK.Records_CL",
>                "V.Other")
>
>###### Jeff Newmiller (RHelp)
>#PViol.Type.Per.Case <- data.frame( CaseID, Primary.Viol.Type=factor(
>Primary.Viol.Type, levels=PViol.Type ) )
>
>tmp <- table( PViol.Type.Per.Case )
>ans <- data.frame( CaseID=rownames( tmp ), as.data.frame( ifelse(
>0==tmp, NA, 1 ) ))
>##########
>
>
>
>-----Original Message-----
>From: Crombie, Burnette N 
>Sent: Thursday, December 18, 2014 11:17 AM
>To: 'Jeff Newmiller'
>Subject: RE: [R] Make 2nd col of 2-col df into header row of same df
>then adjust col1 data display
>
>Thanks so much for your time.  I will reply as soon as possible.  I've
>been pulled away from my desk -- BNC
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Thursday, December 18, 2014 11:02 AM
>To: Crombie, Burnette N
>Cc: r-help at r-project.org
>Subject: Re: [R] Make 2nd col of 2-col df into header row of same df
>then adjust col1 data display
>
>No guarantees on "best"... but one way using base R could be:
>
># Note that "CaseID" is actually not a valid PViol.Type as you had it
>PViol.Type <- c( "BW.BackWages"
>                , "LD.Liquid_Damages"
>                , "MW.Minimum_Wage"
>                , "OT.Overtime"
>                , "RK.Records_FLSA"
>                , "V.Poster_Other"
>                , "AS.Age"
>                , "BW.WHMIS_BackWages"
>                , "HS.Hours"
>                , "OA.HazOccupationAg"
>                , "ON.HazOccupationNonAg"
>                , "R3.Reg3AgeOccupation"
>                , "RK.Records_CL"
>                , "V.Other" )
>
># explicitly specifying all levels to the factor insures a complete #
>set of column outputs regardless of what is in the input
>PViol.Type.Per.Case.Original <-
>     data.frame( CaseID
>               , Primary.Viol.Type=factor( Primary.Viol.Type
>                                         , levels=PViol.Type ) )
>
>tmp <- table( PViol.Type.Per.Case.Original ) ans <- data.frame(
>CaseID=rownames( tmp )
>                  , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
>                  )
>
>
>On Wed, 17 Dec 2014, bcrombie wrote:
>
>> # I have a dataframe that contains 2 columns:
>> CaseID  <- c('1015285',
>> '1005317',
>> '1012281',
>> '1015285',
>> '1015285',
>> '1007183',
>> '1008833',
>> '1015315',
>> '1015322',
>> '1015285')
>>
>> Primary.Viol.Type <- c('AS.Age',
>> 'HS.Hours',
>> 'HS.Hours',
>> 'HS.Hours',
>> 'RK.Records_CL',
>> 'OT.Overtime',
>> 'OT.Overtime',
>> 'OT.Overtime',
>> 'V.Poster_Other',
>> 'V.Poster_Other')
>>
>> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>>
>> # CaseID?s can be repeated because there can be up to 14 
>> Primary.Viol.Type?s per CaseID.
>>
>> # I want to transform this dataframe into one that has 15 columns, 
>> where the first column is CaseID, and the rest are the 14 primary 
>> viol. types.  The CaseID column will contain a list of the unique 
>> CaseID?s (no replicates) and for each of their rows, there will be a 
>> ?1? under  a column corresponding to a primary violation type
>recorded 
>> for that CaseID.  So, technically, there could be zero to 14 ?1?s? in
>a CaseID?s row.
>>
>> # For example, the row for CaseID '1015285' above would have a ?1? 
>> under ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?,
>but have "NA"
>> under the rest of the columns.
>>
>> PViol.Type <- c("CaseID",
>>                "BW.BackWages",
>>           "LD.Liquid_Damages",
>>           "MW.Minimum_Wage",
>>           "OT.Overtime",
>>           "RK.Records_FLSA",
>>           "V.Poster_Other",
>>           "AS.Age",
>>           "BW.WHMIS_BackWages",
>>           "HS.Hours",
>>           "OA.HazOccupationAg",
>>           "ON.HazOccupationNonAg",
>>           "R3.Reg3AgeOccupation",
>>           "RK.Records_CL",
>>           "V.Other")
>>
>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>>
>> # What is the best way to do this in R?
>>
>>
>>
>>
>> --
>> View this message in context: 
>>
>http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row
>> -of-same-df-then-adjust-col1-data-display-tp4700878.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------


From chl948 at mail.usask.ca  Fri Dec 19 06:35:16 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Thu, 18 Dec 2014 23:35:16 -0600
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CEE5117DCA@kmbx4.utk.tennessee.edu>
References: <1418872514464-4700878.post@n4.nabble.com>
	<alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
	<54932E4B.8030009@mail.usask.ca>
	<559C998F7039D84C9793AE43D9BBE9CEE5117DCA@kmbx4.utk.tennessee.edu>
Message-ID: <5493B914.4030903@mail.usask.ca>

Please take a look at my code again.  The error message says that object 
'Primary.Viol.Type' not found.  Have you ever created the object 
'Primary.Viol.Type'?   It will be working if you replace 
'Primary.Viol.Type' by 'PViol.Type.Per.Case.Original$Primary.Viol.Type' 
where 'factor()' is used.  I hope this helps.

Chel Hee Lee

On 12/18/2014 08:57 PM, Crombie, Burnette N wrote:
> Chel, your solution is fantastic on the dataset I submitted in my question but it is not working when I import my real dataset into R.  Do I need to vectorize the columns in my real dataset after importing?  I tried a few things (###) but not making progress:
>
> MERGE_PViol.Detail.Per.Case <- read.csv("~/FOIA_FLSA/MERGE_PViol.Detail.Per.Case_for_rtf10.csv", stringsAsFactors=TRUE)
>
> ### select only certain columns
> PViol.Type.Per.Case.Original <- MERGE_PViol.Detail.Per.Case[,c("CaseID", "Primary.Viol.Type")]
>
> ### write.csv(PViol.Type.Per.Case,file="PViol.Type.Per.Case.Select.csv")
> ### PViol.Type.Per.Case.Original <- read.csv("~/FOIA_FLSA/PViol.Type.Per.Case.Select.csv")
> ### PViol.Type.Per.Case.Original$X <- NULL
> ###PViol.Type.Per.Case.Original[] <- lapply(PViol.Type.Per.Case.Original, as.character)
>
> PViol.Type <- c("CaseID",
>                  "BW.BackWages",
>                  "LD.Liquid_Damages",
>                  "MW.Minimum_Wage",
>                  "OT.Overtime",
>                  "RK.Records_FLSA",
>                  "V.Poster_Other",
>                  "AS.Age",
>                  "BW.WHMIS_BackWages",
>                  "HS.Hours",
>                  "OA.HazOccupationAg",
>                  "ON.HazOccupationNonAg",
>                  "R3.Reg3AgeOccupation",
>                  "RK.Records_CL",
>                  "V.Other")
>
> PViol.Type.Per.Case.Original$Primary.Viol.Type <- factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)
>
> ### Error in factor(Primary.Viol.Type, levels = PViol.Type, labels = PViol.Type) :  object 'Primary.Viol.Type' not found
>
> tmp <- split(PViol.Type.Per.Case.Original,PViol.Type.Per.Case.Original$CaseID)
> ans <- ifelse(do.call(rbind, lapply(tmp, function(x)table(x$Primary.Viol.Type))), 1, NA)
>
>
>
> -----Original Message-----
> From: Crombie, Burnette N
> Sent: Thursday, December 18, 2014 3:01 PM
> To: 'Chel Hee Lee'
> Subject: RE: [R] Make 2nd col of 2-col df into header row of same df then adjust col1 data display
>
> Thanks for taking the time to review this, Chel.  I've got to step away from my desk, but will reply more substantially as soon as possible. -- BNC
>
> -----Original Message-----
> From: Chel Hee Lee [mailto:chl948 at mail.usask.ca]
> Sent: Thursday, December 18, 2014 2:43 PM
> To: Jeff Newmiller; Crombie, Burnette N
> Cc: r-help at r-project.org
> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df then adjust col1 data display
>
> I like the approach presented by Jeff Newmiller as shown in the previous post (I really like his way).  As he suggested, it would be good to start with 'factor' since you have all values of 'Primary.Viol.Type'.
> You may try to use 'split()' function for creating table that you wish to build.  Please see the below (I hope this helps):
>
>   > PViol.Type.Per.Case.Original$Primary.Viol.Type <- factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)  >  > tmp <- split(PViol.Type.Per.Case.Original,
> PViol.Type.Per.Case.Original$CaseID)
>   > ans <- ifelse(do.call(rbind, lapply(tmp, function(x) table(x$Primary.Viol.Type))), 1, NA)  > ans
>           CaseID BW.BackWages LD.Liquid_Damages MW.Minimum_Wage OT.Overtime
> 1005317     NA           NA                NA              NA          NA
> 1007183     NA           NA                NA              NA           1
> 1008833     NA           NA                NA              NA           1
> 1012281     NA           NA                NA              NA          NA
> 1015285     NA           NA                NA              NA          NA
> 1015315     NA           NA                NA              NA           1
> 1015322     NA           NA                NA              NA          NA
>           RK.Records_FLSA V.Poster_Other AS.Age BW.WHMIS_BackWages HS.Hours
> 1005317              NA             NA     NA                 NA        1
> 1007183              NA             NA     NA                 NA       NA
> 1008833              NA             NA     NA                 NA       NA
> 1012281              NA             NA     NA                 NA        1
> 1015285              NA              1      1                 NA        1
> 1015315              NA             NA     NA                 NA       NA
> 1015322              NA              1     NA                 NA       NA
>           OA.HazOccupationAg ON.HazOccupationNonAg R3.Reg3AgeOccupation
> 1005317                 NA                    NA                   NA
> 1007183                 NA                    NA                   NA
> 1008833                 NA                    NA                   NA
> 1012281                 NA                    NA                   NA
> 1015285                 NA                    NA                   NA
> 1015315                 NA                    NA                   NA
> 1015322                 NA                    NA                   NA
>           RK.Records_CL V.Other
> 1005317            NA      NA
> 1007183            NA      NA
> 1008833            NA      NA
> 1012281            NA      NA
> 1015285             1      NA
> 1015315            NA      NA
> 1015322            NA      NA
>   >
>
> Chel Hee Lee
>
> On 12/18/2014 10:02 AM, Jeff Newmiller wrote:
>> No guarantees on "best"... but one way using base R could be:
>>
>> # Note that "CaseID" is actually not a valid PViol.Type as you had it
>> PViol.Type <- c( "BW.BackWages"
>>                  , "LD.Liquid_Damages"
>>                  , "MW.Minimum_Wage"
>>                  , "OT.Overtime"
>>                  , "RK.Records_FLSA"
>>                  , "V.Poster_Other"
>>                  , "AS.Age"
>>                  , "BW.WHMIS_BackWages"
>>                  , "HS.Hours"
>>                  , "OA.HazOccupationAg"
>>                  , "ON.HazOccupationNonAg"
>>                  , "R3.Reg3AgeOccupation"
>>                  , "RK.Records_CL"
>>                  , "V.Other" )
>>
>> # explicitly specifying all levels to the factor insures a complete #
>> set of column outputs regardless of what is in the input
>> PViol.Type.Per.Case.Original <-
>>       data.frame( CaseID
>>                 , Primary.Viol.Type=factor( Primary.Viol.Type
>>                                           , levels=PViol.Type ) )
>>
>> tmp <- table( PViol.Type.Per.Case.Original ) ans <- data.frame(
>> CaseID=rownames( tmp )
>>                    , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
>>                    )
>>
>>
>> On Wed, 17 Dec 2014, bcrombie wrote:
>>
>>> # I have a dataframe that contains 2 columns:
>>> CaseID  <- c('1015285',
>>> '1005317',
>>> '1012281',
>>> '1015285',
>>> '1015285',
>>> '1007183',
>>> '1008833',
>>> '1015315',
>>> '1015322',
>>> '1015285')
>>>
>>> Primary.Viol.Type <- c('AS.Age',
>>> 'HS.Hours',
>>> 'HS.Hours',
>>> 'HS.Hours',
>>> 'RK.Records_CL',
>>> 'OT.Overtime',
>>> 'OT.Overtime',
>>> 'OT.Overtime',
>>> 'V.Poster_Other',
>>> 'V.Poster_Other')
>>>
>>> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>>>
>>> # CaseID?s can be repeated because there can be up to 14
>>> Primary.Viol.Type?s per CaseID.
>>>
>>> # I want to transform this dataframe into one that has 15 columns,
>>> where the first column is CaseID, and the rest are the 14 primary
>>> viol. types.  The CaseID column will contain a list of the unique
>>> CaseID?s (no
>>> replicates) and
>>> for each of their rows, there will be a ?1? under  a column
>>> corresponding to a primary violation type recorded for that CaseID.
>>> So, technically, there could be zero to 14 ?1?s? in a CaseID?s row.
>>>
>>> # For example, the row for CaseID '1015285' above would have a ?1?
>>> under ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?,
>>> but have "NA"
>>> under the rest of the columns.
>>>
>>> PViol.Type <- c("CaseID",
>>>                 "BW.BackWages",
>>>            "LD.Liquid_Damages",
>>>            "MW.Minimum_Wage",
>>>            "OT.Overtime",
>>>            "RK.Records_FLSA",
>>>            "V.Poster_Other",
>>>            "AS.Age",
>>>            "BW.WHMIS_BackWages",
>>>            "HS.Hours",
>>>            "OA.HazOccupationAg",
>>>            "ON.HazOccupationNonAg",
>>>            "R3.Reg3AgeOccupation",
>>>            "RK.Records_CL",
>>>            "V.Other")
>>>
>>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>>>
>>> # What is the best way to do this in R?
>>>
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-ro
>>> w-of-same-df-then-adjust-col1-data-display-tp4700878.html
>>>
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                         Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From mrjefftoyou at gmail.com  Thu Dec 18 21:09:41 2014
From: mrjefftoyou at gmail.com (Jeff Johnson)
Date: Thu, 18 Dec 2014 12:09:41 -0800
Subject: [R] How to pass variable column name into R function
Message-ID: <3F1979B0-8680-47DC-B2F1-7A610D448894@gmail.com>


I know this has been explained a few times here in different scenarios, but I am having a hard time digesting this. 

The following code works fine as long as it's not inside a function (see below).

df$season <- as.character(df$season) temp <- model.matrix( ~ season - 1, data=df) df <- cbind(df,temp)
BEFORE:

head(df[c(1,2)]) datetime season 1 2011-01-01 1 2 2011-01-01 1 3 2011-01-01 1 4 2011-01-01 1 5 2011-01-01 1 6 2011-01-01 1
AFTER:

> head(df[c(1,2,13:16)]) datetime season season1 season2 season3 season4 1 2011-01-01 1 1 0 0 0 2 2011-01-01 1 1 0 0 0 3 2011-01-01      1 1 0 0 0 4 2011-01-01 1 1 0 0 0 5 2011-01-01 1 1 0 0 0 6 2011-01-01      1 1 0 0 0
However, when I try to wrap it in a multi-use function:

binarize <- function(data, myvar) { data$myvar <- as.character(data$myvar) temp <- model.matrix( ~ myvar - 1, data=data) data <- cbind(data,temp) }
it throws an error, undoubtedly because it cannot evaluate myvar or data (or both?): Error in $<-.data.frame(*tmp*, "myvar", value = character(0)) : replacement has 0 rows, data has 10886

I've tried experimenting with eval(substitute()) but still it's not working. My ideal end-state is that you start with a dataframe and a variable, have the function map all of the values for the selected variable into separate binary columns and append that to the original dataframe. Again, when it's not in a function it works perfectly.

Here's the dput data if it helps to reproduce.

> dput(head(df,50)) structure(list(datetime = structure(c(14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14977, 14977, 14977), class = "Date"), season = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), holiday = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), workingday = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), weather = c(1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), temp = c(9.84, 9.02, 9.02, 9.84, 9.84, 9.84, 9.02, 8.2, 9.84, 13.12, 15.58, 14.76, 17.22, 18.86, 18.86, 18.04, 17.22, 18.04, 17.22, 17.22, 16.4, 16.4, 16.4, 18.86, 18.86, 18.04, 17.22, 18.86, 18.86, 17.22, 16.4, 16.4, 15.58, 14.76, 14.76, 14.76, 14.76, 14.76, 13.94, 13.94, 13.94, 14.76, 13.12, 12.3, 10.66, 9.84, 9.02, 9.02, 8.2, 6.56), atemp = c(14.395, 13.635, 13.635, 14.395, 14.395, 12.88, 13.635, 12.88, 14.395, 17.425, 19.695, 16.665, 21.21, 22.725, 22.725, 21.97, 21.21, 21.97, 21.21, 21.21, 20.455, 20.455, 20.455, 22.725, 22.725, 21.97, 21.21, 22.725, 22.725, 21.21, 20.455, 20.455, 19.695, 17.425, 16.665, 16.665, 17.425, 17.425, 16.665, 16.665, 16.665, 16.665, 14.395, 13.635, 11.365, 10.605, 11.365, 9.85, 8.335, 6.82), humidity = c(81L, 80L, 80L, 75L, 75L, 75L, 80L, 86L, 75L, 76L, 76L, 81L, 77L, 72L, 72L, 77L, 82L, 82L, 88L, 88L, 87L, 87L, 94L, 88L, 88L, 94L, 100L, 94L, 94L, 77L, 76L, 71L, 76L, 81L, 71L, 66L, 66L, 76L, 81L, 71L, 57L, 46L, 42L, 39L, 44L, 44L, 47L, 44L, 44L, 47L), windspeed = c(0, 0, 0, 0, 0, 6.0032,  0, 0, 0, 0, 16.9979, 19.0012, 19.0012, 19.9995, 19.0012, 19.9995, 19.9995, 19.0012, 16.9979, 16.9979, 16.9979, 12.998, 15.0013, 19.9995, 19.9995, 16.9979, 19.0012, 12.998, 12.998, 19.9995, 12.998, 15.0013, 15.0013, 15.0013, 16.9979, 19.9995, 8.9981, 12.998, 11.0014, 11.0014, 12.998, 22.0028, 30.0026, 23.9994, 22.0028, 19.9995, 11.0014, 23.9994, 27.9993, 26.0027), casual = c(3L, 8L, 5L, 3L, 0L, 0L, 2L, 1L, 1L, 8L, 12L, 26L, 29L, 47L, 35L, 40L, 41L, 15L, 9L, 6L, 11L, 3L, 11L, 15L, 4L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 1L, 7L, 16L, 20L, 11L, 4L, 19L, 9L, 7L, 10L, 1L, 5L, 11L, 0L, 0L, 0L, 0L, 0L), registered = c(13L, 32L, 27L, 10L, 1L, 1L, 0L, 2L, 7L, 6L, 24L, 30L, 55L, 47L, 71L, 70L, 52L, 52L, 26L, 31L, 25L, 31L, 17L, 24L, 13L, 16L, 8L, 4L, 1L, 2L, 1L, 8L, 19L, 46L, 54L, 73L, 64L, 55L, 55L, 67L, 58L, 43L, 29L, 17L, 20L, 9L, 8L, 5L, 2L, 1L), count = c(16L, 40L, 32L, 13L, 1L, 1L, 2L, 3L, 8L, 14L, 36L, 56L, 84L, 94L, 106L, 110L, 93L, 67L, 35L, 37L, 36L, 34L, 28L, 39L, 17L, 17L, 9L, 6L, 3L, 2L, 1L, 8L, 20L, 53L, 70L, 93L, 75L, 59L, 74L, 76L, 65L, 53L, 30L, 22L, 31L, 9L, 8L, 5L, 2L, 1L)), .Names = c("datetime", "season", "holiday", "workingday", "weather", "temp", "atemp", "humidity", "windspeed", "casual",  "registered", "count"), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50"), class = "data.frame")
Thanks for the help in advance!




	[[alternative HTML version deleted]]


From mtrang at buffalo.edu  Thu Dec 18 21:35:06 2014
From: mtrang at buffalo.edu (mtrang)
Date: Thu, 18 Dec 2014 12:35:06 -0800 (PST)
Subject: [R] Calculating mean, median, minimum, and maximum
In-Reply-To: <1418831065531-4700862.post@n4.nabble.com>
References: <1418831065531-4700862.post@n4.nabble.com>
Message-ID: <1418934906993-4700919.post@n4.nabble.com>

Can you show what the first few rows of your table look like so that we
understand the structure?



--
View this message in context: http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-tp4700862p4700919.html
Sent from the R help mailing list archive at Nabble.com.


From email8889 at gmail.com  Fri Dec 19 01:09:27 2014
From: email8889 at gmail.com (email)
Date: Fri, 19 Dec 2014 02:09:27 +0200
Subject: [R] Hash, variable names restriction
Message-ID: <CAJMZ3cfi2X0wScF6c-tqSeX-Kh_wBu8=MtJB_UbCvjKsrhEqkA@mail.gmail.com>

Hi:

I have one million names of city and their population and want to make
a hash so that by giving key = city, the hash function will return its
population.

I use the hash package in R as follows:
h <- hash(c(as.vector(df$city)), c(as.vector(df$population)))

But getting the following error:
Error in assign(keys[[i]], values[[i]], envir = hash at .Data) :
  variable names are limited to 10000 bytes

How can it be solved?

Thanks:

John


From chl948 at mail.usask.ca  Fri Dec 19 07:34:27 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Fri, 19 Dec 2014 00:34:27 -0600
Subject: [R] pairing columns based on a value
In-Reply-To: <5492D97F.1080208@aghmed.fsnet.co.uk>
References: <CAGgz0QqLDN0ix1yqA4LY5YMn5jc41ORYRER5edwTDGXGRrvveg@mail.gmail.com>
	<5492D97F.1080208@aghmed.fsnet.co.uk>
Message-ID: <5493C6F3.80009@mail.usask.ca>

I do not think that you need regular expressions for your problem. 
Please see the below:

 > d0 <- dat_unmatched
 > tmp <- apply(d0, 1, function(x){
+ first <- substr(x,1,1)
+ idx <- which(c("T", "Y") == first)
+ comb <- paste(x[idx[1]-1], x[idx], collapse=" ")
+ unlist(strsplit(comb, " "))
+ })
 > names(tmp) <- d0$ID
 > tmp
$MCZ4325
[1] "C23.2" "T43.2"

$GDR2343
[1] "M20.64" "Y32.1"  "M20.64" "T44.2"

$BZD2643
[1] "B83.2" "T43.2" "B83.2" "Y32.1" "B83.2" "T44.2"

$BCM3455
[1] "B83.2" "T43.2"

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 12/18/2014 07:41 AM, Michael Dewey wrote:
> Not sure how much help it will be but there is a package on CRAN called
> icd9. Although clearly the codes are different in ICD 10 it may give you
> some hints. I suppose you could even email the maintainer to see whether
> there is an icd10 in the pipeline.
>
> On 17/12/2014 20:14, Robert Strother wrote:
>> I have a large dataset (~50,000 rows, 96 columns), of hospital
>> administrative data.
>> many of the columns are clinical coding of inpatient event (using
>> ICD-10).
>> A simplified example of the data is below
>>
>>> dput(dat_unmatched)
>> structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
>> "BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 =
>> structure(c(2L,
>> 3L, 1L, 1L), .Label = c("B83.2", "C23.2", "F56.23"), class = "factor"),
>>      X.2 = structure(c(2L, 1L, 2L, 2L), .Label = c("M20.64", "T43.2"
>>      ), class = "factor"), X.3 = structure(c(2L, 3L, 3L, 1L), .Label =
>> c("F56.23",
>>      "R23.1", "Y32.1"), class = "factor"), X.4 = structure(c(1L,
>>      2L, 2L, 3L), .Label = c("M23.5", "T44.2", "Y32.1"), class =
>> "factor"),
>>      X.5 = structure(c(1L, 2L, 1L, 2L), .Label = c("", "Q23.6"
>>      ), class = "factor")), .Names = c("ID", "X.1", "X.2", "X.3",
>> "X.4", "X.5"), class = "data.frame", row.names = c(NA, -4L))
>>
>> I am interested in a set of codes that start with a "T" or a "Y", and
>> link
>> them to the preceding column that does not begin with a "T" or "Y".   I
>> suspect I will need to use regular expressions, and likely a loop, but
>> I am
>> really out of my depth at this point.
>>
>> I would like the final dataset to look like:
>>
>>> dput(dat_matched)
>> structure(list(ID = structure(c(4L, 3L, 2L, 1L), .Label = c("BCM3455",
>> "BZD2643", "GDR2343", "MCZ4325"), class = "factor"), X.1 =
>> structure(c(2L,
>> 3L, 1L, 1L), .Label = c("B83.2", "C23.2", "M20.64"), class = "factor"),
>>      X.2 = structure(c(1L, 2L, 1L, 1L), .Label = c("T43.2", "Y32.1"
>>      ), class = "factor"), X.3 = structure(c(1L, 4L, 2L, 3L), .Label =
>> c("",
>>      "B83.2", "F56.23", "M20.64"), class = "factor"), X.4 =
>> structure(c(1L,
>>      2L, 3L, 3L), .Label = c("", "T44.2", "Y32.1"), class = "factor"),
>>      X.5 = structure(c(1L, 1L, 2L, 1L), .Label = c("", "B83.2"
>>      ), class = "factor"), X = structure(c(1L, 1L, 2L, 1L), .Label =
>> c("",
>>      "T44.2"), class = "factor")), .Names = c("ID", "X.1", "X.2",
>> "X.3", "X.4", "X.5", "X"), class = "data.frame", row.names = c(NA,
>> -4L))
>>
>> Any help appreciated.
>>
>> Matthew
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> -----
>> No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2015.0.5577 / Virus Database: 4253/8759 - Release Date: 12/18/14
>>
>>
>


From jdnewmil at dcn.davis.ca.us  Fri Dec 19 09:01:21 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 19 Dec 2014 00:01:21 -0800 (PST)
Subject: [R] How to pass variable column name into R function
In-Reply-To: <3F1979B0-8680-47DC-B2F1-7A610D448894@gmail.com>
References: <3F1979B0-8680-47DC-B2F1-7A610D448894@gmail.com>
Message-ID: <alpine.BSF.2.00.1412182339010.1107@pedal.dcn.davis.ca.us>

HTML mutilated your email. Please post in plain text.

Although you are playing with some tricky stuff, you seem to have 
difficulty understanding the difference between a symbol and the value the 
symbol represents. Re-reading section 6.1 of the Introduction to R that 
comes with the software seems called for.

data$myvar is (almost) equivalent to data[[ "myvar" ]], but the first form 
looks at the characters in the symbol myvar directly, while the other form 
can use either a string literal or a variable to accomplish the same task:

myvar <- "season"
# dta defined below
str( dta[[ "season" ]] )
str( dta[[ myvar ]] )

The "almost" above alludes to the "abbreviated" form that is mentioned in 
Section 6.1. (go... read... it....)

Oh, and "df" is the name of a function in base R... so using it as a 
variable name is poor form (confusing).

dta <- structure(list(datetime = structure(c(14975, 14975, 14975, 14975, 
14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 
14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 
14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 
14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 
14976, 14976, 14976, 14977, 14977, 14977), class = "Date"), season = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), holiday = c(0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), workingday = c(0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), weather = c(1L, 1L, 1L, 
1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), temp = c(9.84, 9.02, 9.02, 
9.84, 9.84, 9.84, 9.02, 8.2, 9.84, 13.12, 15.58, 14.76, 17.22, 18.86, 
18.86, 18.04, 17.22, 18.04, 17.22, 17.22, 16.4, 16.4, 16.4, 18.86, 18.86, 
18.04, 17.22, 18.86, 18.86, 17.22, 16.4, 16.4, 15.58, 14.76, 14.76, 14.76, 
14.76, 14.76, 13.94, 13.94, 13.94, 14.76, 13.12, 12.3, 10.66, 9.84, 9.02, 
9.02, 8.2, 6.56), atemp = c(14.395, 13.635, 13.635, 14.395, 14.395, 12.88, 
13.635, 12.88, 14.395, 17.425, 19.695, 16.665, 21.21, 22.725, 22.725, 
21.97, 21.21, 21.97, 21.21, 21.21, 20.455, 20.455, 20.455, 22.725, 22.725, 
21.97, 21.21, 22.725, 22.725, 21.21, 20.455, 20.455, 19.695, 17.425, 
16.665, 16.665, 17.425, 17.425, 16.665, 16.665, 16.665, 16.665, 14.395, 
13.635, 11.365, 10.605, 11.365, 9.85, 8.335, 6.82), humidity = c(81L, 80L, 
80L, 75L, 75L, 75L, 80L, 86L, 75L, 76L, 76L, 81L, 77L, 72L, 72L, 77L, 82L, 
82L, 88L, 88L, 87L, 87L, 94L, 88L, 88L, 94L, 100L, 94L, 94L, 77L, 76L, 
71L, 76L, 81L, 71L, 66L, 66L, 76L, 81L, 71L, 57L, 46L, 42L, 39L, 44L, 44L, 
47L, 44L, 44L, 47L), windspeed = c(0, 0, 0, 0, 0, 6.0032,  0, 0, 0, 0, 
16.9979, 19.0012, 19.0012, 19.9995, 19.0012, 19.9995, 19.9995, 19.0012, 
16.9979, 16.9979, 16.9979, 12.998, 15.0013, 19.9995, 19.9995, 16.9979, 
19.0012, 12.998, 12.998, 19.9995, 12.998, 15.0013, 15.0013, 15.0013, 
16.9979, 19.9995, 8.9981, 12.998, 11.0014, 11.0014, 12.998, 22.0028, 
30.0026, 23.9994, 22.0028, 19.9995, 11.0014, 23.9994, 27.9993, 26.0027), 
casual = c(3L, 8L, 5L, 3L, 0L, 0L, 2L, 1L, 1L, 8L, 12L, 26L, 29L, 47L, 
35L, 40L, 41L, 15L, 9L, 6L, 11L, 3L, 11L, 15L, 4L, 1L, 1L, 2L, 2L, 0L, 0L, 
0L, 1L, 7L, 16L, 20L, 11L, 4L, 19L, 9L, 7L, 10L, 1L, 5L, 11L, 0L, 0L, 0L, 
0L, 0L), registered = c(13L, 32L, 27L, 10L, 1L, 1L, 0L, 2L, 7L, 6L, 24L, 
30L, 55L, 47L, 71L, 70L, 52L, 52L, 26L, 31L, 25L, 31L, 17L, 24L, 13L, 16L, 
8L, 4L, 1L, 2L, 1L, 8L, 19L, 46L, 54L, 73L, 64L, 55L, 55L, 67L, 58L, 43L, 
29L, 17L, 20L, 9L, 8L, 5L, 2L, 1L), count = c(16L, 40L, 32L, 13L, 1L, 1L, 
2L, 3L, 8L, 14L, 36L, 56L, 84L, 94L, 106L, 110L, 93L, 67L, 35L, 37L, 36L, 
34L, 28L, 39L, 17L, 17L, 9L, 6L, 3L, 2L, 1L, 8L, 20L, 53L, 70L, 93L, 75L, 
59L, 74L, 76L, 65L, 53L, 30L, 22L, 31L, 9L, 8L, 5L, 2L, 1L)), .Names = 
c("datetime", "season", "holiday", "workingday", "weather", "temp", 
"atemp", "humidity", "windspeed", "casual",  "registered", "count"), 
row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", 
"12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", 
"24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", 
"36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", 
"48", "49", "50"), class = "data.frame")

binarize <- function( data, myvar ) {
   # here I avoid modifying the "myvar" column in data
   mydf <- data.frame( as.character( data[[ myvar ]] )
                     , stringsAsFactors=FALSE )
   names( mydf ) <- myvar
   temp <- model.matrix( as.formula( paste( "~", myvar, " - 1" ) )
                       , data=mydf )
   data <- data.frame( data, temp )
   data
}
# your subset only had one value in the season column, which breaks your 
# "trick" with model.matrix
newdta <- binarize( dta, "workingday" )
newdta
# I think your idea of pasting these columns into the same data frame may
# lead to column name collisions down the road... but that is your
# minefield.

On Thu, 18 Dec 2014, Jeff Johnson wrote:

>
> I know this has been explained a few times here in different scenarios, but I am having a hard time digesting this.
>
> The following code works fine as long as it's not inside a function (see below).
>
> df$season <- as.character(df$season) temp <- model.matrix( ~ season - 1, data=df) df <- cbind(df,temp)
> BEFORE:
>
> head(df[c(1,2)]) datetime season 1 2011-01-01 1 2 2011-01-01 1 3 2011-01-01 1 4 2011-01-01 1 5 2011-01-01 1 6 2011-01-01 1
> AFTER:
>
>> head(df[c(1,2,13:16)]) datetime season season1 season2 season3 season4 1 2011-01-01 1 1 0 0 0 2 2011-01-01 1 1 0 0 0 3 2011-01-01      1 1 0 0 0 4 2011-01-01 1 1 0 0 0 5 2011-01-01 1 1 0 0 0 6 2011-01-01      1 1 0 0 0
> However, when I try to wrap it in a multi-use function:
>
> binarize <- function(data, myvar) { data$myvar <- as.character(data$myvar) temp <- model.matrix( ~ myvar - 1, data=data) data <- cbind(data,temp) }
> it throws an error, undoubtedly because it cannot evaluate myvar or data (or both?): Error in $<-.data.frame(*tmp*, "myvar", value = character(0)) : replacement has 0 rows, data has 10886
>
> I've tried experimenting with eval(substitute()) but still it's not working. My ideal end-state is that you start with a dataframe and a variable, have the function map all of the values for the selected variable into separate binary columns and append that to the original dataframe. Again, when it's not in a function it works perfectly.
>
> Here's the dput data if it helps to reproduce.
>
>> dput(head(df,50)) structure(list(datetime = structure(c(14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14975, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14976, 14977, 14977, 14977), class = "Date"), season = c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), holiday = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), workingday = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,!
>
>  0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L), weather = c(1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 2L, 3L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), temp = c(9.84, 9.02, 9.02, 9.84, 9.84, 9.84, 9.02, 8.2, 9.84, 13.12, 15.58, 14.76, 17.22, 18.86, 18.86, 18.04, 17.22, 18.04, 17.22, 17.22, 16.4, 16.4, 16.4, 18.86, 18.86, 18.04, 17.22, 18.86, 18.86, 17.22, 16.4, 16.4, 15.58, 14.76, 14.76, 14.76, 14.76, 14.76, 13.94, 13.94, 13.94, 14.76, 13.12, 12.3, 10.66, 9.84, 9.02, 9.02, 8.2, 6.56), atemp = c(14.395, 13.635, 13.635, 14.395, 14.395, 12.88, 13.635, 12.88, 14.395, 17.425, 19.695, 16.665, 21.21, 22.725, 22.725, 21.97, 21.21, 21.97, 21.21, 21.21, 20.455, 20.455, 20.455, 22.725, 22.725, 21.97, 21.21, 22.725, 22.725, 21.21, 20.455, 20.455, 19.695, 17.425, 16.665, 16.665, 17.425, 17.425, 16.665, 16.665, 16.665, 16.665, 14.395, 13.635, 11.365, !
>
> 10.605, 11.365, 9.85, 8.335, 6.82), humidity = c(81L, 80L, 80L, 75L, 7
> 5L, 75L, 80L, 86L, 75L, 76L, 76L, 81L, 77L, 72L, 72L, 77L, 82L, 82L, 88L, 88L, 87L, 87L, 94L, 88L, 88L, 94L, 100L, 94L, 94L, 77L, 76L, 71L, 76L, 81L, 71L, 66L, 66L, 76L, 81L, 71L, 57L, 46L, 42L, 39L, 44L, 44L, 47L, 44L, 44L, 47L), windspeed = c(0, 0, 0, 0, 0, 6.0032,  0, 0, 0, 0, 16.9979, 19.0012, 19.0012, 19.9995, 19.0012, 19.9995, 19.9995, 19.0012, 16.9979, 16.9979, 16.9979, 12.998, 15.0013, 19.9995, 19.9995, 16.9979, 19.0012, 12.998, 12.998, 19.9995, 12.998, 15.0013, 15.0013, 15.0013, 16.9979, 19.9995, 8.9981, 12.998, 11.0014, 11.0014, 12.998, 22.0028, 30.0026, 23.9994, 22.0028, 19.9995, 11.0014, 23.9994, 27.9993, 26.0027), casual = c(3L, 8L, 5L, 3L, 0L, 0L, 2L, 1L, 1L, 8L, 12L, 26L, 29L, 47L, 35L, 40L, 41L, 15L, 9L, 6L, 11L, 3L, 11L, 15L, 4L, 1L, 1L, 2L, 2L, 0L, 0L, 0L, 1L, 7L, 16L, 20L, 11L, 4L, 19L, 9L, 7L, 10L, 1L, 5L, 11L, 0L, 0L, 0L, 0L, 0L), registered = c(13L, 32L, 27L, 10L, 1L, 1L, 0L, 2L, 7L, 6L, 24L, 30L, 55L, 47L, 71L, 70L, 52L, 52L, 26L, 31L, 25L, 31L, 17L, 2!
>
> 4L, 13L, 16L, 8L, 4L, 1L, 2L, 1L, 8L, 19L, 46L, 54L, 73L, 64L, 55L, 55L, 67L, 58L, 43L, 29L, 17L, 20L, 9L, 8L, 5L, 2L, 1L), count = c(16L, 40L, 32L, 13L, 1L, 1L, 2L, 3L, 8L, 14L, 36L, 56L, 84L, 94L, 106L, 110L, 93L, 67L, 35L, 37L, 36L, 34L, 28L, 39L, 17L, 17L, 9L, 6L, 3L, 2L, 1L, 8L, 20L, 53L, 70L, 93L, 75L, 59L, 74L, 76L, 65L, 53L, 30L, 22L, 31L, 9L, 8L, 5L, 2L, 1L)), .Names = c("datetime", "season", "holiday", "workingday", "weather", "temp", "atemp", "humidity", "windspeed", "casual",  "registered", "count"), row.names = c("1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24", "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42", "43", "44", "45", "46", "47", "48", "49", "50"), class = "data.frame")
> Thanks for the help in advance!
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Fri Dec 19 09:37:37 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 19 Dec 2014 00:37:37 -0800 (PST)
Subject: [R] R - Aggregate 3-Hourly Block Data into Weekly (Melt)
In-Reply-To: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>
References: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1412190019140.1107@pedal.dcn.davis.ca.us>

Thank you for attempting to convey your problem clearly using example 
code... but your use of HTML email has very nearly undone all your 
efforts.  Also, use of "dput" to make an R-readable block of data is more 
reliable than read.table to get the data into our R sessions quickly.

First question: you say these are three-hour results, but there are only 
six per day in your example.

Second question: you say the "number of blocks vary between 7 and 8", but 
your example data does not illustrate that problem. (If there were 8 
blocks per day the three-hour statement would make more sense.)

Comment: You have not mentioned timezone information... this information 
looks ripe for GMT, but if that is a bad assumption then daylight savings 
might account for some variations in blocks per day.

Comment: I think your plan of using rep to identify the week numbers is 
risky. I would recommend using a Date or POSIXt type to make the 
timestamps computable, and then find the date corresponding to the 
beginning of the week that the timestamp falls into. Then aggregate 
grouping on those time values. Unfortunately, the specific way you go 
about identifying the beginning of week may depend on the timezone 
information.

On Thu, 18 Dec 2014, Shouro Dasgupta wrote:

> I am trying to compute max, min, and mean from Global Circulation Models
> (GCM) for the US. The data is in 3-hour blocks for 2026-2045 and 2081-2100.
> Sample Data:
>
> tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 =
> c(285.5533142,
>  285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
>  285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
>  ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
>      X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
>      X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071)),
> .Names = c("FIPS",
>  "X2026.01.01.1", "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
>  "X2026.01.01.5", "X2026.01.01.6"), class = "data.frame", row.names = c(NA,
>  -3L))
>
> I have extracted the data by FIPS code and reshaped the yearly data files
> using melt();
>
> for (i in filelist) {
>  tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
>  tmp2 <- melt(tmp1, id="FIPS")
>  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
>  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
>  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))}
>
> I have added datestring and weekdays using the following code:
> Inserting Date Variable
>
> tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month, day)))
>
> Inserting Day Variable
>
> tmp2$day <- weekdays(as.Date(tmp2$date))
>
> sample.tmp2 <- "FIPS         xdate     temp year month      day
> date      dates weekdays
> + 5599311  1003 X2045.08.14.2 304.5995 2045     8   Monday 2045-08-14
> 2036-01-29        2
> + 468406  39093 X2045.01.19.7 267.8483 2045     1 Thursday 2045-01-19
> 2028-06-04        0
> + 5022078 21167 X2045.07.21.8 314.6772 2045     7   Friday 2045-07-21
> 2035-09-13        4
> + 186822   9005 X2045.01.08.5 269.0803 2045     1   Sunday 2045-01-08
> 2037-06-28        0
> + 3998678 13295 X2045.06.10.7 307.2408 2045     6 Saturday 2045-06-10
> 2033-10-13        4"
>
> Data <- read.table(text=sample.tmp2, header = TRUE)
>
> My goal is to aggregate these 3-hourly blocks into weekly data, however,
> GCM data is not consistent and the blocks vary between 7 and 8. I want to
> clip the data to start on the first Monday of 2026 and end on the last
> Sunday of 2045 and then use rep() to assign week numbers for the whole
> epoch.
>
> I know I can count the number of each day using something like this;
>
> length(which(weekdays == '0'))
>
> Where 0, 1, 2..., 6 represent Sunday, Monday,...
>
> My question is am I doing anything wrong in trying to aggregate the data to
> begin with? But importantly, I would be grateful for any help to clip the
> dataset to begin on the first Monday and end on the last Sunday. Thank you
> very much!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Fri Dec 19 09:49:22 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 19 Dec 2014 00:49:22 -0800 (PST)
Subject: [R] Hash, variable names restriction
In-Reply-To: <CAJMZ3cfi2X0wScF6c-tqSeX-Kh_wBu8=MtJB_UbCvjKsrhEqkA@mail.gmail.com>
References: <CAJMZ3cfi2X0wScF6c-tqSeX-Kh_wBu8=MtJB_UbCvjKsrhEqkA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1412190039150.1107@pedal.dcn.davis.ca.us>

df is the name of a function in base R. You have not provided a definition 
of sample data resembling your real data. In this case I suspect that the 
source of your problems is that df may not be what you think it is. 
Learning to use the "str" function may help you.

If df is a data frame containing a column called "city", then df$city is a 
vector. You don't need to convert it to a vector. Nor do you need to 
concatenate it with anything.

Note that hash tables may not be the best or only way to accomplish this. 
The data.table package offers data frames with binary search indexing that 
can be quite fast, particularly if you plan to do these lookups on large 
amounts of data.

Try reading 
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
for ideas on how to communicate your problems with R more clearly.

On Fri, 19 Dec 2014, email wrote:

> Hi:
>
> I have one million names of city and their population and want to make
> a hash so that by giving key = city, the hash function will return its
> population.
>
> I use the hash package in R as follows:
> h <- hash(c(as.vector(df$city)), c(as.vector(df$population)))
>
> But getting the following error:
> Error in assign(keys[[i]], values[[i]], envir = hash at .Data) :
>  variable names are limited to 10000 bytes
>
> How can it be solved?
>
> Thanks:
>
> John
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From sven.templer at gmail.com  Fri Dec 19 10:13:55 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Fri, 19 Dec 2014 10:13:55 +0100
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <5493B914.4030903@mail.usask.ca>
References: <1418872514464-4700878.post@n4.nabble.com>
	<alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
	<54932E4B.8030009@mail.usask.ca>
	<559C998F7039D84C9793AE43D9BBE9CEE5117DCA@kmbx4.utk.tennessee.edu>
	<5493B914.4030903@mail.usask.ca>
Message-ID: <CAHuTOvr=W5USurZ1p-F+eYLkUcjTo7q8nXHAj9wg-ZTGzdf6+g@mail.gmail.com>

Another solution:

CaseID <- c("1015285", "1005317", "1012281", "1015285", "1015285", "1007183",
"1008833", "1015315", "1015322", "1015285")
Primary.Viol.Type <- c("AS.Age", "HS.Hours", "HS.Hours", "HS.Hours",
"RK.Records_CL",
"OT.Overtime", "OT.Overtime", "OT.Overtime", "V.Poster_Other",
"V.Poster_Other")

library(reshape2)
dcast(data.frame(CaseID, Primary.Viol.Type), CaseID~Primary.Viol.Type, length)

# result:

Using Primary.Viol.Type as value column: use value.var to override.
   CaseID AS.Age HS.Hours OT.Overtime RK.Records_CL V.Poster_Other
1 1005317      0        1           0             0              0
2 1007183      0        0           1             0              0
3 1008833      0        0           1             0              0
4 1012281      0        1           0             0              0
5 1015285      1        1           0             1              1
6 1015315      0        0           1             0              0
7 1015322      0        0           0             0              1


best, s.

On 19 December 2014 at 06:35, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
> Please take a look at my code again.  The error message says that object
> 'Primary.Viol.Type' not found.  Have you ever created the object
> 'Primary.Viol.Type'?   It will be working if you replace 'Primary.Viol.Type'
> by 'PViol.Type.Per.Case.Original$Primary.Viol.Type' where 'factor()' is
> used.  I hope this helps.
>
> Chel Hee Lee
>
> On 12/18/2014 08:57 PM, Crombie, Burnette N wrote:
>>
>> Chel, your solution is fantastic on the dataset I submitted in my question
>> but it is not working when I import my real dataset into R.  Do I need to
>> vectorize the columns in my real dataset after importing?  I tried a few
>> things (###) but not making progress:
>>
>> MERGE_PViol.Detail.Per.Case <-
>> read.csv("~/FOIA_FLSA/MERGE_PViol.Detail.Per.Case_for_rtf10.csv",
>> stringsAsFactors=TRUE)
>>
>> ### select only certain columns
>> PViol.Type.Per.Case.Original <- MERGE_PViol.Detail.Per.Case[,c("CaseID",
>> "Primary.Viol.Type")]
>>
>> ### write.csv(PViol.Type.Per.Case,file="PViol.Type.Per.Case.Select.csv")
>> ### PViol.Type.Per.Case.Original <-
>> read.csv("~/FOIA_FLSA/PViol.Type.Per.Case.Select.csv")
>> ### PViol.Type.Per.Case.Original$X <- NULL
>> ###PViol.Type.Per.Case.Original[] <- lapply(PViol.Type.Per.Case.Original,
>> as.character)
>>
>> PViol.Type <- c("CaseID",
>>                  "BW.BackWages",
>>                  "LD.Liquid_Damages",
>>                  "MW.Minimum_Wage",
>>                  "OT.Overtime",
>>                  "RK.Records_FLSA",
>>                  "V.Poster_Other",
>>                  "AS.Age",
>>                  "BW.WHMIS_BackWages",
>>                  "HS.Hours",
>>                  "OA.HazOccupationAg",
>>                  "ON.HazOccupationNonAg",
>>                  "R3.Reg3AgeOccupation",
>>                  "RK.Records_CL",
>>                  "V.Other")
>>
>> PViol.Type.Per.Case.Original$Primary.Viol.Type <-
>> factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)
>>
>> ### Error in factor(Primary.Viol.Type, levels = PViol.Type, labels =
>> PViol.Type) :  object 'Primary.Viol.Type' not found
>>
>> tmp <-
>> split(PViol.Type.Per.Case.Original,PViol.Type.Per.Case.Original$CaseID)
>> ans <- ifelse(do.call(rbind, lapply(tmp,
>> function(x)table(x$Primary.Viol.Type))), 1, NA)
>>
>>
>>
>> -----Original Message-----
>> From: Crombie, Burnette N
>> Sent: Thursday, December 18, 2014 3:01 PM
>> To: 'Chel Hee Lee'
>> Subject: RE: [R] Make 2nd col of 2-col df into header row of same df then
>> adjust col1 data display
>>
>> Thanks for taking the time to review this, Chel.  I've got to step away
>> from my desk, but will reply more substantially as soon as possible. -- BNC
>>
>> -----Original Message-----
>> From: Chel Hee Lee [mailto:chl948 at mail.usask.ca]
>> Sent: Thursday, December 18, 2014 2:43 PM
>> To: Jeff Newmiller; Crombie, Burnette N
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df then
>> adjust col1 data display
>>
>> I like the approach presented by Jeff Newmiller as shown in the previous
>> post (I really like his way).  As he suggested, it would be good to start
>> with 'factor' since you have all values of 'Primary.Viol.Type'.
>> You may try to use 'split()' function for creating table that you wish to
>> build.  Please see the below (I hope this helps):
>>
>>   > PViol.Type.Per.Case.Original$Primary.Viol.Type <-
>> factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)  >  > tmp <-
>> split(PViol.Type.Per.Case.Original,
>> PViol.Type.Per.Case.Original$CaseID)
>>   > ans <- ifelse(do.call(rbind, lapply(tmp, function(x)
>> table(x$Primary.Viol.Type))), 1, NA)  > ans
>>           CaseID BW.BackWages LD.Liquid_Damages MW.Minimum_Wage
>> OT.Overtime
>> 1005317     NA           NA                NA              NA          NA
>> 1007183     NA           NA                NA              NA           1
>> 1008833     NA           NA                NA              NA           1
>> 1012281     NA           NA                NA              NA          NA
>> 1015285     NA           NA                NA              NA          NA
>> 1015315     NA           NA                NA              NA           1
>> 1015322     NA           NA                NA              NA          NA
>>           RK.Records_FLSA V.Poster_Other AS.Age BW.WHMIS_BackWages
>> HS.Hours
>> 1005317              NA             NA     NA                 NA        1
>> 1007183              NA             NA     NA                 NA       NA
>> 1008833              NA             NA     NA                 NA       NA
>> 1012281              NA             NA     NA                 NA        1
>> 1015285              NA              1      1                 NA        1
>> 1015315              NA             NA     NA                 NA       NA
>> 1015322              NA              1     NA                 NA       NA
>>           OA.HazOccupationAg ON.HazOccupationNonAg R3.Reg3AgeOccupation
>> 1005317                 NA                    NA                   NA
>> 1007183                 NA                    NA                   NA
>> 1008833                 NA                    NA                   NA
>> 1012281                 NA                    NA                   NA
>> 1015285                 NA                    NA                   NA
>> 1015315                 NA                    NA                   NA
>> 1015322                 NA                    NA                   NA
>>           RK.Records_CL V.Other
>> 1005317            NA      NA
>> 1007183            NA      NA
>> 1008833            NA      NA
>> 1012281            NA      NA
>> 1015285             1      NA
>> 1015315            NA      NA
>> 1015322            NA      NA
>>   >
>>
>> Chel Hee Lee
>>
>> On 12/18/2014 10:02 AM, Jeff Newmiller wrote:
>>>
>>> No guarantees on "best"... but one way using base R could be:
>>>
>>> # Note that "CaseID" is actually not a valid PViol.Type as you had it
>>> PViol.Type <- c( "BW.BackWages"
>>>                  , "LD.Liquid_Damages"
>>>                  , "MW.Minimum_Wage"
>>>                  , "OT.Overtime"
>>>                  , "RK.Records_FLSA"
>>>                  , "V.Poster_Other"
>>>                  , "AS.Age"
>>>                  , "BW.WHMIS_BackWages"
>>>                  , "HS.Hours"
>>>                  , "OA.HazOccupationAg"
>>>                  , "ON.HazOccupationNonAg"
>>>                  , "R3.Reg3AgeOccupation"
>>>                  , "RK.Records_CL"
>>>                  , "V.Other" )
>>>
>>> # explicitly specifying all levels to the factor insures a complete #
>>> set of column outputs regardless of what is in the input
>>> PViol.Type.Per.Case.Original <-
>>>       data.frame( CaseID
>>>                 , Primary.Viol.Type=factor( Primary.Viol.Type
>>>                                           , levels=PViol.Type ) )
>>>
>>> tmp <- table( PViol.Type.Per.Case.Original ) ans <- data.frame(
>>> CaseID=rownames( tmp )
>>>                    , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
>>>                    )
>>>
>>>
>>> On Wed, 17 Dec 2014, bcrombie wrote:
>>>
>>>> # I have a dataframe that contains 2 columns:
>>>> CaseID  <- c('1015285',
>>>> '1005317',
>>>> '1012281',
>>>> '1015285',
>>>> '1015285',
>>>> '1007183',
>>>> '1008833',
>>>> '1015315',
>>>> '1015322',
>>>> '1015285')
>>>>
>>>> Primary.Viol.Type <- c('AS.Age',
>>>> 'HS.Hours',
>>>> 'HS.Hours',
>>>> 'HS.Hours',
>>>> 'RK.Records_CL',
>>>> 'OT.Overtime',
>>>> 'OT.Overtime',
>>>> 'OT.Overtime',
>>>> 'V.Poster_Other',
>>>> 'V.Poster_Other')
>>>>
>>>> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>>>>
>>>> # CaseID?s can be repeated because there can be up to 14
>>>> Primary.Viol.Type?s per CaseID.
>>>>
>>>> # I want to transform this dataframe into one that has 15 columns,
>>>> where the first column is CaseID, and the rest are the 14 primary
>>>> viol. types.  The CaseID column will contain a list of the unique
>>>> CaseID?s (no
>>>> replicates) and
>>>> for each of their rows, there will be a ?1? under  a column
>>>> corresponding to a primary violation type recorded for that CaseID.
>>>> So, technically, there could be zero to 14 ?1?s? in a CaseID?s row.
>>>>
>>>> # For example, the row for CaseID '1015285' above would have a ?1?
>>>> under ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?,
>>>> but have "NA"
>>>> under the rest of the columns.
>>>>
>>>> PViol.Type <- c("CaseID",
>>>>                 "BW.BackWages",
>>>>            "LD.Liquid_Damages",
>>>>            "MW.Minimum_Wage",
>>>>            "OT.Overtime",
>>>>            "RK.Records_FLSA",
>>>>            "V.Poster_Other",
>>>>            "AS.Age",
>>>>            "BW.WHMIS_BackWages",
>>>>            "HS.Hours",
>>>>            "OA.HazOccupationAg",
>>>>            "ON.HazOccupationNonAg",
>>>>            "R3.Reg3AgeOccupation",
>>>>            "RK.Records_CL",
>>>>            "V.Other")
>>>>
>>>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>>>>
>>>> # What is the best way to do this in R?
>>>>
>>>>
>>>>
>>>>
>>>> --
>>>> View this message in context:
>>>> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-ro
>>>> w-of-same-df-then-adjust-col1-data-display-tp4700878.html
>>>>
>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                         Live:   OO#.. Dead: OO#..
>>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Thierry.ONKELINX at inbo.be  Fri Dec 19 10:31:21 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 19 Dec 2014 09:31:21 +0000
Subject: [R] R - Aggregate 3-Hourly Block Data into Weekly (Melt)
In-Reply-To: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>
References: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427FD62202A@inbomail.inbo.be>

You are looking for the round_date(), floor_date() or ceiling_date() functions from the lubridate package. Those functions can round timestamps to weeks.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-help [mailto:r-help-bounces at r-project.org] Namens Shouro Dasgupta
Verzonden: donderdag 18 december 2014 16:13
Aan: r-help at r-project.org
Onderwerp: [R] R - Aggregate 3-Hourly Block Data into Weekly (Melt)

I am trying to compute max, min, and mean from Global Circulation Models
(GCM) for the US. The data is in 3-hour blocks for 2026-2045 and 2081-2100.
Sample Data:

tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 = c(285.5533142,
  285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
  285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
  ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
      X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
      X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071)), .Names = c("FIPS",
  "X2026.01.01.1", "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
  "X2026.01.01.5", "X2026.01.01.6"), class = "data.frame", row.names = c(NA,
  -3L))

I have extracted the data by FIPS code and reshaped the yearly data files using melt();

for (i in filelist) {
  tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
  tmp2 <- melt(tmp1, id="FIPS")
  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))}

I have added datestring and weekdays using the following code:
Inserting Date Variable

tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month, day)))

Inserting Day Variable

tmp2$day <- weekdays(as.Date(tmp2$date))

sample.tmp2 <- "FIPS         xdate     temp year month      day
date      dates weekdays
+ 5599311  1003 X2045.08.14.2 304.5995 2045     8   Monday 2045-08-14
2036-01-29        2
+ 468406  39093 X2045.01.19.7 267.8483 2045     1 Thursday 2045-01-19
2028-06-04        0
+ 5022078 21167 X2045.07.21.8 314.6772 2045     7   Friday 2045-07-21
2035-09-13        4
+ 186822   9005 X2045.01.08.5 269.0803 2045     1   Sunday 2045-01-08
2037-06-28        0
+ 3998678 13295 X2045.06.10.7 307.2408 2045     6 Saturday 2045-06-10
2033-10-13        4"

Data <- read.table(text=sample.tmp2, header = TRUE)

My goal is to aggregate these 3-hourly blocks into weekly data, however, GCM data is not consistent and the blocks vary between 7 and 8. I want to clip the data to start on the first Monday of 2026 and end on the last Sunday of 2045 and then use rep() to assign week numbers for the whole epoch.

I know I can count the number of each day using something like this;

length(which(weekdays == '0'))

Where 0, 1, 2..., 6 represent Sunday, Monday,...

My question is am I doing anything wrong in trying to aggregate the data to begin with? But importantly, I would be grateful for any help to clip the dataset to begin on the first Monday and end on the last Sunday. Thank you very much!

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>


From shouro at gmail.com  Fri Dec 19 11:01:52 2014
From: shouro at gmail.com (Shouro Dasgupta)
Date: Fri, 19 Dec 2014 11:01:52 +0100
Subject: [R] R - Aggregate 3-Hourly Block Data into Weekly (Melt)
In-Reply-To: <alpine.BSF.2.00.1412190019140.1107@pedal.dcn.davis.ca.us>
References: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>
	<alpine.BSF.2.00.1412190019140.1107@pedal.dcn.davis.ca.us>
Message-ID: <CAMx+UYeUAyxJLow=+x5pPi5dvpjdPKV9ugxZSr+xeoX0gn5qXA@mail.gmail.com>

Thank you very much for your reply. I really appreciate it. I apologize for
the HTML version, I have made modifications and replied to your
questions/comments below. Thanks again



tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 = c(
285.5533142,

  285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,

  285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767

  ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),

      X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),

      X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071),
X2026.01.01.7 = c(282.3938, 282.3938, 283.1096), X2026.01.01.8 = c(285.9133,
285.9133, 286.1951) .Names = c("FIPS", "X2026.01.01.1", "X2026.01.01.2",
"X2026.01.01.3", "X2026.01.01.4",

  "X2026.01.01.5", "X2026.01.01.6", "X2026.01.01.7", "X2026.01.01.8" ),
class = "data.frame", row.names = c(NA, -3L))



*Looks like this*

FIPS

X2026.01.01.1

X2026.01.01.2

X2026.01.01.3

X2026.01.01.4

X2026.01.01.5

X2026.01.01.6

X2026.01.01.7

X2026.01.01.8

1001

285.5533

283.4977

281.9734

280.0235

278.7126

278.5205

282.3938

285.9133

1003

285.5533

283.4977

281.9734

280.0235

278.7126

278.5205

282.3938

285.9133

1005

286.2481

285.086

284.1549

282.6076

281.2554

280.6148

283.1096

286.1951



For X2026.01.01.1 represents Year=2026, Month=01, Day=01, Hour block=1.

I have extracted the data by FIPS code and reshaped the yearly data files
using melt();



for (i in filelist) {

  tmp1 <- as.data.table(read.csv(i,header=T, sep=","))

  tmp2 <- melt(tmp1, id="FIPS")

  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))

  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))

  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))

}


I have added date string and weekdays using the following codes:

*Date Variable*

        tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month,
day)))



*Day Variable*

        tmp2$day <- weekdays(as.Date(tmp2$date))



*Question 1: *Apologies for clipping the data and not showing all the hour
blocks. I have included a full 8-hour block now. For each year, I have
3-hour blocks for every day.



*Question 2: *I have two time periods for each GCM; 2026-2045 and
2081-2100. There are occasions when days would have 7 hour blocks instead
of 8, it could be a data reporting issue from the models.

*Reply to Comment 1: *The data has been downscaled to the US from gridded
data; Resolution: T42 in atm. 1/3~1?lat. x 1?lon. tripolar grids in ocn. So
Daylight Savings Time could well be an issue. I will look into it.



*Reply to Comment 2: * Thank you for the suggestion. I realize that using
rep() is risky, however, I have assign week numbers to each FIPS code (ID)
for each year. I was thinking of something similar to this:



weeks<-rep(seq(1,52,1),each=(unique(tmp2$FIPS)**8*)



Any alternative code will be highly appreciated. My first goal is to
subset/clip the data to begin on the first Monday and end on the last
Sunday of each year.

On Fri, Dec 19, 2014 at 9:37 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:
>
> Thank you for attempting to convey your problem clearly using example
> code... but your use of HTML email has very nearly undone all your
> efforts.  Also, use of "dput" to make an R-readable block of data is more
> reliable than read.table to get the data into our R sessions quickly.
>
> First question: you say these are three-hour results, but there are only
> six per day in your example.
>
> Second question: you say the "number of blocks vary between 7 and 8", but
> your example data does not illustrate that problem. (If there were 8 blocks
> per day the three-hour statement would make more sense.)
>
> Comment: You have not mentioned timezone information... this information
> looks ripe for GMT, but if that is a bad assumption then daylight savings
> might account for some variations in blocks per day.
>
> Comment: I think your plan of using rep to identify the week numbers is
> risky. I would recommend using a Date or POSIXt type to make the timestamps
> computable, and then find the date corresponding to the beginning of the
> week that the timestamp falls into. Then aggregate grouping on those time
> values. Unfortunately, the specific way you go about identifying the
> beginning of week may depend on the timezone information.
>
>
> On Thu, 18 Dec 2014, Shouro Dasgupta wrote:
>
>  I am trying to compute max, min, and mean from Global Circulation Models
>> (GCM) for the US. The data is in 3-hour blocks for 2026-2045 and
>> 2081-2100.
>> Sample Data:
>>
>> tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 =
>> c(285.5533142,
>>  285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
>>  285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
>>  ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
>>      X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
>>      X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071)),
>> .Names = c("FIPS",
>>  "X2026.01.01.1", "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
>>  "X2026.01.01.5", "X2026.01.01.6"), class = "data.frame", row.names =
>> c(NA,
>>  -3L))
>>
>> I have extracted the data by FIPS code and reshaped the yearly data files
>> using melt();
>>
>> for (i in filelist) {
>>  tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
>>  tmp2 <- melt(tmp1, id="FIPS")
>>  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
>>  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
>>  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))}
>>
>> I have added datestring and weekdays using the following code:
>> Inserting Date Variable
>>
>> tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month, day)))
>>
>> Inserting Day Variable
>>
>> tmp2$day <- weekdays(as.Date(tmp2$date))
>>
>> sample.tmp2 <- "FIPS         xdate     temp year month      day
>> date      dates weekdays
>> + 5599311  1003 X2045.08.14.2 304.5995 2045     8   Monday 2045-08-14
>> 2036-01-29        2
>> + 468406 39093 X2045.01.19.7 267.8483 2045     1 Thursday 2045-01-19
>> 2028-06-04        0
>> + 5022078 21167 X2045.07.21.8 314.6772 2045     7   Friday 2045-07-21
>> 2035-09-13        4
>> + 186822   9005 X2045.01.08.5 269.0803 2045     1   Sunday 2045-01-08
>> 2037-06-28        0
>> + 3998678 13295 X2045.06.10.7 307.2408 2045     6 Saturday 2045-06-10
>> 2033-10-13        4"
>>
>> Data <- read.table(text=sample.tmp2, header = TRUE)
>>
>> My goal is to aggregate these 3-hourly blocks into weekly data, however,
>> GCM data is not consistent and the blocks vary between 7 and 8. I want to
>> clip the data to start on the first Monday of 2026 and end on the last
>> Sunday of 2045 and then use rep() to assign week numbers for the whole
>> epoch.
>>
>> I know I can count the number of each day using something like this;
>>
>> length(which(weekdays == '0'))
>>
>> Where 0, 1, 2..., 6 represent Sunday, Monday,...
>>
>> My question is am I doing anything wrong in trying to aggregate the data
>> to
>> begin with? But importantly, I would be grateful for any help to clip the
>> dataset to begin on the first Monday and end on the last Sunday. Thank you
>> very much!
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ------------------------------------------------------------
> ---------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ------------------------------------------------------------
> ---------------
>

	[[alternative HTML version deleted]]


From aoife.m.doherty at gmail.com  Fri Dec 19 11:12:00 2014
From: aoife.m.doherty at gmail.com (aoife doherty)
Date: Fri, 19 Dec 2014 10:12:00 +0000
Subject: [R] Cox model -missing data.
Message-ID: <CAAsJanYcYjzoWSo_wx3ZvrHzMgZiMQRzav=muc_C0_x5biEU5w@mail.gmail.com>

Hi all,

I have a data set like this:

Test.cox file:

V1        V2         V3               Survival       Event
ann      13          WTHomo           4                1
ben      20          *                5                1
tom      40          Variant          6                1


where "*" indicates that I don't know what the value is for V3 for Ben.

I've set up a Cox model to run like this:

#!/usr/bin/Rscript
library(bdsmatrix)
library(kinship2)
library(survival)
library(coxme)
death.dat <- read.table("Test.cox",header=T)
deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
sink("Test.cox.R.Output")
Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
strata(factor(V2)) + factor(V3)) +
(1|ID),data=death.dat,varlist=deathdat.kmat)
Model
sink()



As you can see from the Test.cox file, I have a missing value "*". How and
where do I tell the R script "treat * as a missing variable". If I can't
incorporate missing values into the model, I assume the alternative is to
remove all of the rows with missing data, which will greatly reduce my data
set, as most rows have at least one missing variable.

Thanks

	[[alternative HTML version deleted]]


From shouro at gmail.com  Fri Dec 19 11:18:40 2014
From: shouro at gmail.com (Shouro Dasgupta)
Date: Fri, 19 Dec 2014 11:18:40 +0100
Subject: [R] Cox model -missing data.
In-Reply-To: <CAAsJanYcYjzoWSo_wx3ZvrHzMgZiMQRzav=muc_C0_x5biEU5w@mail.gmail.com>
References: <CAAsJanYcYjzoWSo_wx3ZvrHzMgZiMQRzav=muc_C0_x5biEU5w@mail.gmail.com>
Message-ID: <CAMx+UYfvKxDOZPuW3WmLgzsyEGg9fFuNTVqeWF3KmdAajbfFZA@mail.gmail.com>

First recode the *  in NA: death.dat$v3[death.dat$v1==*] <- NA

Include this in your model: na.rm=TRUE

Or you could create a new dataset: newdata <- na.omit(death.dat)

Shouro




On Fri, Dec 19, 2014 at 11:12 AM, aoife doherty <aoife.m.doherty at gmail.com>
wrote:
>
> Hi all,
>
> I have a data set like this:
>
> Test.cox file:
>
> V1        V2         V3               Survival       Event
> ann      13          WTHomo           4                1
> ben      20          *                5                1
> tom      40          Variant          6                1
>
>
> where "*" indicates that I don't know what the value is for V3 for Ben.
>
> I've set up a Cox model to run like this:
>
> #!/usr/bin/Rscript
> library(bdsmatrix)
> library(kinship2)
> library(survival)
> library(coxme)
> death.dat <- read.table("Test.cox",header=T)
> deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
> sink("Test.cox.R.Output")
> Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
> strata(factor(V2)) + factor(V3)) +
> (1|ID),data=death.dat,varlist=deathdat.kmat)
> Model
> sink()
>
>
>
> As you can see from the Test.cox file, I have a missing value "*". How and
> where do I tell the R script "treat * as a missing variable". If I can't
> incorporate missing values into the model, I assume the alternative is to
> remove all of the rows with missing data, which will greatly reduce my data
> set, as most rows have at least one missing variable.
>
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Ted.Harding at wlandres.net  Fri Dec 19 11:21:26 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Fri, 19 Dec 2014 10:21:26 -0000 (GMT)
Subject: [R] Cox model -missing data.
In-Reply-To: <CAAsJanYcYjzoWSo_wx3ZvrHzMgZiMQRzav=muc_C0_x5biEU5w@mail.gmail.com>
Message-ID: <XFMail.20141219102126.Ted.Harding@wlandres.net>

Hi Aoife,
I think that if you simply replace each "*" in the data file
with "NA", then it should work ("NA" is usually interpreted
as "missing" for those functions for which missingness is
relevant). How you subsequently deal with records which have
missing values is another question (or many questions ... ).

So your data should look like:

V1       V2          V3               Survival       Event
ann      13          WTHomo           4                1
ben      20          NA               5                1
tom      40          Variant          6                1

Hoping this helps,
Ted.

On 19-Dec-2014 10:12:00 aoife doherty wrote:
> Hi all,
> 
> I have a data set like this:
> 
> Test.cox file:
> 
> V1        V2         V3               Survival       Event
> ann      13          WTHomo           4                1
> ben      20          *                5                1
> tom      40          Variant          6                1
> 
> 
> where "*" indicates that I don't know what the value is for V3 for Ben.
> 
> I've set up a Cox model to run like this:
> 
>#!/usr/bin/Rscript
> library(bdsmatrix)
> library(kinship2)
> library(survival)
> library(coxme)
> death.dat <- read.table("Test.cox",header=T)
> deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
> sink("Test.cox.R.Output")
> Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
> strata(factor(V2)) + factor(V3)) +
> (1|ID),data=death.dat,varlist=deathdat.kmat)
> Model
> sink()
> 
> 
> 
> As you can see from the Test.cox file, I have a missing value "*". How and
> where do I tell the R script "treat * as a missing variable". If I can't
> incorporate missing values into the model, I assume the alternative is to
> remove all of the rows with missing data, which will greatly reduce my data
> set, as most rows have at least one missing variable.
> 
> Thanks
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 19-Dec-2014  Time: 10:21:23
This message was sent by XFMail


From aoife.m.doherty at gmail.com  Fri Dec 19 12:17:27 2014
From: aoife.m.doherty at gmail.com (aoife doherty)
Date: Fri, 19 Dec 2014 11:17:27 +0000
Subject: [R] Cox model -missing data.
In-Reply-To: <XFMail.20141219102126.Ted.Harding@wlandres.net>
References: <CAAsJanYcYjzoWSo_wx3ZvrHzMgZiMQRzav=muc_C0_x5biEU5w@mail.gmail.com>
	<XFMail.20141219102126.Ted.Harding@wlandres.net>
Message-ID: <CAAsJanYo4XZ5Of8_jJO0FzWx_4nYLiLv11BpC6sVE2945V9abg@mail.gmail.com>

Many thanks, I appreciate the response.

When I convert the missing values to NA and run the cox model as described
in previous post,  the cox model seems to remove all of the rows with a
missing value (as the number of rows "n" in the cox output after I
completely remove any row with missing data is the same as the number of
rows "n" in the cox output after I change the missing values to NA).

What I had been hoping to do is not completely remove a row with missing
data for a co-variable, but rather somehow censor or estimate a value for
the missing value?

In reality, I have ~600 people with survival data and say 6 variables
attached to them. After I incorporate a 7th variable (for which the
information isn't available for every individual), I have 400 people left.
Since I still have survival data and almost all of the information for the
other 200 people (the only thing missing is information about that 7th
variable), it seems a waste to remove all of the survival data for 200
people over one co-variate. So I was hoping instead of completely removing
the rows, to just somehow acknowledge that the data for this particular
co-variate is missing in the model but not completely remove the row? This
is more what I was hoping someone would know if it's possible to
incorporate into the model I described above?

Thanks



On Fri, Dec 19, 2014 at 10:21 AM, Ted Harding <Ted.Harding at wlandres.net>
wrote:
>
> Hi Aoife,
> I think that if you simply replace each "*" in the data file
> with "NA", then it should work ("NA" is usually interpreted
> as "missing" for those functions for which missingness is
> relevant). How you subsequently deal with records which have
> missing values is another question (or many questions ... ).
>
> So your data should look like:
>
> V1       V2          V3               Survival       Event
> ann      13          WTHomo           4                1
> ben      20          NA               5                1
> tom      40          Variant          6                1
>
> Hoping this helps,
> Ted.
>
> On 19-Dec-2014 10:12:00 aoife doherty wrote:
> > Hi all,
> >
> > I have a data set like this:
> >
> > Test.cox file:
> >
> > V1        V2         V3               Survival       Event
> > ann      13          WTHomo           4                1
> > ben      20          *                5                1
> > tom      40          Variant          6                1
> >
> >
> > where "*" indicates that I don't know what the value is for V3 for Ben.
> >
> > I've set up a Cox model to run like this:
> >
> >#!/usr/bin/Rscript
> > library(bdsmatrix)
> > library(kinship2)
> > library(survival)
> > library(coxme)
> > death.dat <- read.table("Test.cox",header=T)
> > deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
> > sink("Test.cox.R.Output")
> > Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
> > strata(factor(V2)) + factor(V3)) +
> > (1|ID),data=death.dat,varlist=deathdat.kmat)
> > Model
> > sink()
> >
> >
> >
> > As you can see from the Test.cox file, I have a missing value "*". How
> and
> > where do I tell the R script "treat * as a missing variable". If I can't
> > incorporate missing values into the model, I assume the alternative is to
> > remove all of the rows with missing data, which will greatly reduce my
> data
> > set, as most rows have at least one missing variable.
> >
> > Thanks
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 19-Dec-2014  Time: 10:21:23
> This message was sent by XFMail
> -------------------------------------------------
>

	[[alternative HTML version deleted]]


From Ted.Harding at wlandres.net  Fri Dec 19 13:06:17 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Fri, 19 Dec 2014 12:06:17 -0000 (GMT)
Subject: [R] Cox model -missing data.
In-Reply-To: <CAAsJanYo4XZ5Of8_jJO0FzWx_4nYLiLv11BpC6sVE2945V9abg@mail.gmail.com>
Message-ID: <XFMail.20141219120617.Ted.Harding@wlandres.net>

Yes, your basic reasoning is correct. In general, the observed variables
carry information about the variables with missing values, so (in some
way) the missing values can be replaced with estimates ("imputations")
and the standard regression method will then work as though the
replacements were there is the first place. To incorporate the inevitable
uncertainty about what the missing values really were, one approach
("multiple imputation") is to do the replacement many times over,
sampling the replacement values from a posterior distribution estimated
from the non-missing data. There are other approaches.

This is where the "many questions" kick in! I don't have time at the
moment, to go into further detail (there's a lot of it, and several
R packages which deal with missing data in different ways), but I hope
that someone can meanwhile point you in the right direction.

With best wishes,
Ted.

On 19-Dec-2014 11:17:27 aoife doherty wrote:
> Many thanks, I appreciate the response.
> 
> When I convert the missing values to NA and run the cox model as described
> in previous post,  the cox model seems to remove all of the rows with a
> missing value (as the number of rows "n" in the cox output after I
> completely remove any row with missing data is the same as the number of
> rows "n" in the cox output after I change the missing values to NA).
> 
> What I had been hoping to do is not completely remove a row with missing
> data for a co-variable, but rather somehow censor or estimate a value for
> the missing value?
> 
> In reality, I have ~600 people with survival data and say 6 variables
> attached to them. After I incorporate a 7th variable (for which the
> information isn't available for every individual), I have 400 people left.
> Since I still have survival data and almost all of the information for the
> other 200 people (the only thing missing is information about that 7th
> variable), it seems a waste to remove all of the survival data for 200
> people over one co-variate. So I was hoping instead of completely removing
> the rows, to just somehow acknowledge that the data for this particular
> co-variate is missing in the model but not completely remove the row? This
> is more what I was hoping someone would know if it's possible to
> incorporate into the model I described above?
> 
> Thanks
> 
> 
> 
> On Fri, Dec 19, 2014 at 10:21 AM, Ted Harding <Ted.Harding at wlandres.net>
> wrote:
>>
>> Hi Aoife,
>> I think that if you simply replace each "*" in the data file
>> with "NA", then it should work ("NA" is usually interpreted
>> as "missing" for those functions for which missingness is
>> relevant). How you subsequently deal with records which have
>> missing values is another question (or many questions ... ).
>>
>> So your data should look like:
>>
>> V1       V2          V3               Survival       Event
>> ann      13          WTHomo           4                1
>> ben      20          NA               5                1
>> tom      40          Variant          6                1
>>
>> Hoping this helps,
>> Ted.
>>
>> On 19-Dec-2014 10:12:00 aoife doherty wrote:
>> > Hi all,
>> >
>> > I have a data set like this:
>> >
>> > Test.cox file:
>> >
>> > V1        V2         V3               Survival       Event
>> > ann      13          WTHomo           4                1
>> > ben      20          *                5                1
>> > tom      40          Variant          6                1
>> >
>> >
>> > where "*" indicates that I don't know what the value is for V3 for Ben.
>> >
>> > I've set up a Cox model to run like this:
>> >
>> >#!/usr/bin/Rscript
>> > library(bdsmatrix)
>> > library(kinship2)
>> > library(survival)
>> > library(coxme)
>> > death.dat <- read.table("Test.cox",header=T)
>> > deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
>> > sink("Test.cox.R.Output")
>> > Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
>> > strata(factor(V2)) + factor(V3)) +
>> > (1|ID),data=death.dat,varlist=deathdat.kmat)
>> > Model
>> > sink()
>> >
>> >
>> >
>> > As you can see from the Test.cox file, I have a missing value "*". How
>> and
>> > where do I tell the R script "treat * as a missing variable". If I can't
>> > incorporate missing values into the model, I assume the alternative is to
>> > remove all of the rows with missing data, which will greatly reduce my
>> data
>> > set, as most rows have at least one missing variable.
>> >
>> > Thanks
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 19-Dec-2014  Time: 10:21:23
>> This message was sent by XFMail
>> -------------------------------------------------
>>
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 19-Dec-2014  Time: 12:06:14
This message was sent by XFMail


From info at aghmed.fsnet.co.uk  Fri Dec 19 12:37:39 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 19 Dec 2014 11:37:39 +0000
Subject: [R] Cox model -missing data.
In-Reply-To: <CAAsJanYo4XZ5Of8_jJO0FzWx_4nYLiLv11BpC6sVE2945V9abg@mail.gmail.com>
References: <CAAsJanYcYjzoWSo_wx3ZvrHzMgZiMQRzav=muc_C0_x5biEU5w@mail.gmail.com>	<XFMail.20141219102126.Ted.Harding@wlandres.net>
	<CAAsJanYo4XZ5Of8_jJO0FzWx_4nYLiLv11BpC6sVE2945V9abg@mail.gmail.com>
Message-ID: <54940E03.3020509@aghmed.fsnet.co.uk>

Comment inline

On 19/12/2014 11:17, aoife doherty wrote:
> Many thanks, I appreciate the response.
>
> When I convert the missing values to NA and run the cox model as described
> in previous post,  the cox model seems to remove all of the rows with a
> missing value (as the number of rows "n" in the cox output after I
> completely remove any row with missing data is the same as the number of
> rows "n" in the cox output after I change the missing values to NA).
>
> What I had been hoping to do is not completely remove a row with missing
> data for a co-variable, but rather somehow censor or estimate a value for
> the missing value?

I think you are searching for some form of imputation here. A full 
answer would be way beyond the scope of this list as it depends on so 
many things including the mechanism driving the missingness.

Have a look at
http://missingdata.lshtm.ac.uk/
and see whether that helps.

>
> In reality, I have ~600 people with survival data and say 6 variables
> attached to them. After I incorporate a 7th variable (for which the
> information isn't available for every individual), I have 400 people left.
> Since I still have survival data and almost all of the information for the
> other 200 people (the only thing missing is information about that 7th
> variable), it seems a waste to remove all of the survival data for 200
> people over one co-variate. So I was hoping instead of completely removing
> the rows, to just somehow acknowledge that the data for this particular
> co-variate is missing in the model but not completely remove the row? This
> is more what I was hoping someone would know if it's possible to
> incorporate into the model I described above?
>
> Thanks
>
>
>
> On Fri, Dec 19, 2014 at 10:21 AM, Ted Harding <Ted.Harding at wlandres.net>
> wrote:
>>
>> Hi Aoife,
>> I think that if you simply replace each "*" in the data file
>> with "NA", then it should work ("NA" is usually interpreted
>> as "missing" for those functions for which missingness is
>> relevant). How you subsequently deal with records which have
>> missing values is another question (or many questions ... ).
>>
>> So your data should look like:
>>
>> V1       V2          V3               Survival       Event
>> ann      13          WTHomo           4                1
>> ben      20          NA               5                1
>> tom      40          Variant          6                1
>>
>> Hoping this helps,
>> Ted.
>>
>> On 19-Dec-2014 10:12:00 aoife doherty wrote:
>>> Hi all,
>>>
>>> I have a data set like this:
>>>
>>> Test.cox file:
>>>
>>> V1        V2         V3               Survival       Event
>>> ann      13          WTHomo           4                1
>>> ben      20          *                5                1
>>> tom      40          Variant          6                1
>>>
>>>
>>> where "*" indicates that I don't know what the value is for V3 for Ben.
>>>
>>> I've set up a Cox model to run like this:
>>>
>>> #!/usr/bin/Rscript
>>> library(bdsmatrix)
>>> library(kinship2)
>>> library(survival)
>>> library(coxme)
>>> death.dat <- read.table("Test.cox",header=T)
>>> deathdat.kmat <-2*with(death.dat,makekinship(famid,ID,faid,moid))
>>> sink("Test.cox.R.Output")
>>> Model <- coxme(Surv(Survival,Event)~ strata(factor(V1)) +
>>> strata(factor(V2)) + factor(V3)) +
>>> (1|ID),data=death.dat,varlist=deathdat.kmat)
>>> Model
>>> sink()
>>>
>>>
>>>
>>> As you can see from the Test.cox file, I have a missing value "*". How
>> and
>>> where do I tell the R script "treat * as a missing variable". If I can't
>>> incorporate missing values into the model, I assume the alternative is to
>>> remove all of the rows with missing data, which will greatly reduce my
>> data
>>> set, as most rows have at least one missing variable.
>>>
>>> Thanks
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> -------------------------------------------------
>> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
>> Date: 19-Dec-2014  Time: 10:21:23
>> This message was sent by XFMail
>> -------------------------------------------------
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4253/8764 - Release Date: 12/19/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From therneau at mayo.edu  Fri Dec 19 13:58:29 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 19 Dec 2014 06:58:29 -0600
Subject: [R] exclude missing co-variable data in cox model
In-Reply-To: <mailman.1.1418986801.25142.r-help@r-project.org>
References: <mailman.1.1418986801.25142.r-help@r-project.org>
Message-ID: <31062c$9gbahp@ironport10.mayo.edu>

Three responses to your question
   1. Missing values in R are denoted by "NA".  When reading in your data you want to use 
the "na.strings" option so that the internal form of the data has missing values properly 
denoted.

   2. If this is done, then coxme will notice the missings and remove them, you do not 
need to do anything.  Your second question of "how to use the missing data" is a much 
deeper statistical one.  Multiple imputation would be the obvious way to proceed, but it 
is complex and I have no experience with respect to how it would work with a mixed effects 
Cox model.

   3. Your note implies that output was attached.  Note that r-help strips away all 
attachments, so none of us saw it.

Terry Therneau


On 12/19/2014 05:00 AM, r-help-request at r-project.org wrote:
> Hi all,
>
> I have a data set like this:
>
> Test.cox file:
>
> V1        V2         V3                Survival       Event
> ann      13          WTHomo          4                1
> ben      20          *                        5                1
> tom      40         Variant               6                1
>
> where "*" indicates that I don't know what the value is for V3 for Ben.
>
>  Remainder of message excluded


From alagador at uevora.pt  Fri Dec 19 14:02:55 2014
From: alagador at uevora.pt (=?iso-8859-1?Q?Diogo_Andr=E9_Alagador?=)
Date: Fri, 19 Dec 2014 13:02:55 -0000
Subject: [R] where is XMLRPC for R>3.0 for Windows machines
Message-ID: <006a01d01b8c$1b54ad50$51fe07f0$@pt>

 

I am need to install rneos for R 3.1 under Windows 64bit. 

However it depends on the package XMLRPC that is not available in
conventional repositories.

In the CRAN R 3.1 online readme
(http://cran.r-project.org/bin/windows/contrib/3.1/ReadMe) there is an
information regarding the installation of package XMLRP for Windows that
direct users to the Prof Ripley?s link
(http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1/). However the
zip file is not there neither for the 3.0 r version.

Anyone can inform me on how can obtain it?

 

Best regards,

Diogo Alagador

 <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador

CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University
of ?vora, Portugal

 

 

 


	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Fri Dec 19 14:44:12 2014
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 19 Dec 2014 05:44:12 -0800
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <CAHuTOvr=W5USurZ1p-F+eYLkUcjTo7q8nXHAj9wg-ZTGzdf6+g@mail.gmail.com>
References: <54932e4b.8030009@mail.usask.ca>
	<alpine.bsf.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
	<559c998f7039d84c9793ae43d9bbe9cee5117dca@kmbx4.utk.tennessee.edu>
	<5493b914.4030903@mail.usask.ca>
	<1418872514464-4700878.post@n4.nabble.com>
Message-ID: <965F3F18EFD.00000738jrkrideau@inbox.com>

Very pretty. 
I could have saved myself about 1/2 hour of mucking about if I had thought ot "length".

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sven.templer at gmail.com
> Sent: Fri, 19 Dec 2014 10:13:55 +0100
> To: chl948 at mail.usask.ca
> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df then
> adjust col1 data display
> 
> Another solution:
> 
> CaseID <- c("1015285", "1005317", "1012281", "1015285", "1015285",
> "1007183",
> "1008833", "1015315", "1015322", "1015285")
> Primary.Viol.Type <- c("AS.Age", "HS.Hours", "HS.Hours", "HS.Hours",
> "RK.Records_CL",
> "OT.Overtime", "OT.Overtime", "OT.Overtime", "V.Poster_Other",
> "V.Poster_Other")
> 
> library(reshape2)
> dcast(data.frame(CaseID, Primary.Viol.Type), CaseID~Primary.Viol.Type,
> length)
> 
> # result:
> 
> Using Primary.Viol.Type as value column: use value.var to override.
>    CaseID AS.Age HS.Hours OT.Overtime RK.Records_CL V.Poster_Other
> 1 1005317      0        1           0             0              0
> 2 1007183      0        0           1             0              0
> 3 1008833      0        0           1             0              0
> 4 1012281      0        1           0             0              0
> 5 1015285      1        1           0             1              1
> 6 1015315      0        0           1             0              0
> 7 1015322      0        0           0             0              1
> 
> 
> best, s.
> 
> On 19 December 2014 at 06:35, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>> Please take a look at my code again.  The error message says that object
>> 'Primary.Viol.Type' not found.  Have you ever created the object
>> 'Primary.Viol.Type'?   It will be working if you replace
>> 'Primary.Viol.Type'
>> by 'PViol.Type.Per.Case.Original$Primary.Viol.Type' where 'factor()' is
>> used.  I hope this helps.
>> 
>> Chel Hee Lee
>> 
>> On 12/18/2014 08:57 PM, Crombie, Burnette N wrote:
>>> 
>>> Chel, your solution is fantastic on the dataset I submitted in my
>>> question
>>> but it is not working when I import my real dataset into R.  Do I need
>>> to
>>> vectorize the columns in my real dataset after importing?  I tried a
>>> few
>>> things (###) but not making progress:
>>> 
>>> MERGE_PViol.Detail.Per.Case <-
>>> read.csv("~/FOIA_FLSA/MERGE_PViol.Detail.Per.Case_for_rtf10.csv",
>>> stringsAsFactors=TRUE)
>>> 
>>> ### select only certain columns
>>> PViol.Type.Per.Case.Original <-
>>> MERGE_PViol.Detail.Per.Case[,c("CaseID",
>>> "Primary.Viol.Type")]
>>> 
>>> ###
>>> write.csv(PViol.Type.Per.Case,file="PViol.Type.Per.Case.Select.csv")
>>> ### PViol.Type.Per.Case.Original <-
>>> read.csv("~/FOIA_FLSA/PViol.Type.Per.Case.Select.csv")
>>> ### PViol.Type.Per.Case.Original$X <- NULL
>>> ###PViol.Type.Per.Case.Original[] <-
>>> lapply(PViol.Type.Per.Case.Original,
>>> as.character)
>>> 
>>> PViol.Type <- c("CaseID",
>>>                  "BW.BackWages",
>>>                  "LD.Liquid_Damages",
>>>                  "MW.Minimum_Wage",
>>>                  "OT.Overtime",
>>>                  "RK.Records_FLSA",
>>>                  "V.Poster_Other",
>>>                  "AS.Age",
>>>                  "BW.WHMIS_BackWages",
>>>                  "HS.Hours",
>>>                  "OA.HazOccupationAg",
>>>                  "ON.HazOccupationNonAg",
>>>                  "R3.Reg3AgeOccupation",
>>>                  "RK.Records_CL",
>>>                  "V.Other")
>>> 
>>> PViol.Type.Per.Case.Original$Primary.Viol.Type <-
>>> factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)
>>> 
>>> ### Error in factor(Primary.Viol.Type, levels = PViol.Type, labels =
>>> PViol.Type) :  object 'Primary.Viol.Type' not found
>>> 
>>> tmp <-
>>> split(PViol.Type.Per.Case.Original,PViol.Type.Per.Case.Original$CaseID)
>>> ans <- ifelse(do.call(rbind, lapply(tmp,
>>> function(x)table(x$Primary.Viol.Type))), 1, NA)
>>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: Crombie, Burnette N
>>> Sent: Thursday, December 18, 2014 3:01 PM
>>> To: 'Chel Hee Lee'
>>> Subject: RE: [R] Make 2nd col of 2-col df into header row of same df
>>> then
>>> adjust col1 data display
>>> 
>>> Thanks for taking the time to review this, Chel.  I've got to step away
>>> from my desk, but will reply more substantially as soon as possible. --
>>> BNC
>>> 
>>> -----Original Message-----
>>> From: Chel Hee Lee [mailto:chl948 at mail.usask.ca]
>>> Sent: Thursday, December 18, 2014 2:43 PM
>>> To: Jeff Newmiller; Crombie, Burnette N
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df
>>> then
>>> adjust col1 data display
>>> 
>>> I like the approach presented by Jeff Newmiller as shown in the
>>> previous
>>> post (I really like his way).  As he suggested, it would be good to
>>> start
>>> with 'factor' since you have all values of 'Primary.Viol.Type'.
>>> You may try to use 'split()' function for creating table that you wish
>>> to
>>> build.  Please see the below (I hope this helps):
>>> 
>>>   > PViol.Type.Per.Case.Original$Primary.Viol.Type <-
>>> factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)  >  >
>>> tmp <-
>>> split(PViol.Type.Per.Case.Original,
>>> PViol.Type.Per.Case.Original$CaseID)
>>>   > ans <- ifelse(do.call(rbind, lapply(tmp, function(x)
>>> table(x$Primary.Viol.Type))), 1, NA)  > ans
>>>           CaseID BW.BackWages LD.Liquid_Damages MW.Minimum_Wage
>>> OT.Overtime
>>> 1005317     NA           NA                NA              NA
>>> NA
>>> 1007183     NA           NA                NA              NA
>>> 1
>>> 1008833     NA           NA                NA              NA
>>> 1
>>> 1012281     NA           NA                NA              NA
>>> NA
>>> 1015285     NA           NA                NA              NA
>>> NA
>>> 1015315     NA           NA                NA              NA
>>> 1
>>> 1015322     NA           NA                NA              NA
>>> NA
>>>           RK.Records_FLSA V.Poster_Other AS.Age BW.WHMIS_BackWages
>>> HS.Hours
>>> 1005317              NA             NA     NA                 NA
>>> 1
>>> 1007183              NA             NA     NA                 NA
>>> NA
>>> 1008833              NA             NA     NA                 NA
>>> NA
>>> 1012281              NA             NA     NA                 NA
>>> 1
>>> 1015285              NA              1      1                 NA
>>> 1
>>> 1015315              NA             NA     NA                 NA
>>> NA
>>> 1015322              NA              1     NA                 NA
>>> NA
>>>           OA.HazOccupationAg ON.HazOccupationNonAg R3.Reg3AgeOccupation
>>> 1005317                 NA                    NA                   NA
>>> 1007183                 NA                    NA                   NA
>>> 1008833                 NA                    NA                   NA
>>> 1012281                 NA                    NA                   NA
>>> 1015285                 NA                    NA                   NA
>>> 1015315                 NA                    NA                   NA
>>> 1015322                 NA                    NA                   NA
>>>           RK.Records_CL V.Other
>>> 1005317            NA      NA
>>> 1007183            NA      NA
>>> 1008833            NA      NA
>>> 1012281            NA      NA
>>> 1015285             1      NA
>>> 1015315            NA      NA
>>> 1015322            NA      NA
>>>   >
>>> 
>>> Chel Hee Lee
>>> 
>>> On 12/18/2014 10:02 AM, Jeff Newmiller wrote:
>>>> 
>>>> No guarantees on "best"... but one way using base R could be:
>>>> 
>>>> # Note that "CaseID" is actually not a valid PViol.Type as you had it
>>>> PViol.Type <- c( "BW.BackWages"
>>>>                  , "LD.Liquid_Damages"
>>>>                  , "MW.Minimum_Wage"
>>>>                  , "OT.Overtime"
>>>>                  , "RK.Records_FLSA"
>>>>                  , "V.Poster_Other"
>>>>                  , "AS.Age"
>>>>                  , "BW.WHMIS_BackWages"
>>>>                  , "HS.Hours"
>>>>                  , "OA.HazOccupationAg"
>>>>                  , "ON.HazOccupationNonAg"
>>>>                  , "R3.Reg3AgeOccupation"
>>>>                  , "RK.Records_CL"
>>>>                  , "V.Other" )
>>>> 
>>>> # explicitly specifying all levels to the factor insures a complete #
>>>> set of column outputs regardless of what is in the input
>>>> PViol.Type.Per.Case.Original <-
>>>>       data.frame( CaseID
>>>>                 , Primary.Viol.Type=factor( Primary.Viol.Type
>>>>                                           , levels=PViol.Type ) )
>>>> 
>>>> tmp <- table( PViol.Type.Per.Case.Original ) ans <- data.frame(
>>>> CaseID=rownames( tmp )
>>>>                    , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
>>>>                    )
>>>> 
>>>> 
>>>> On Wed, 17 Dec 2014, bcrombie wrote:
>>>> 
>>>>> # I have a dataframe that contains 2 columns:
>>>>> CaseID  <- c('1015285',
>>>>> '1005317',
>>>>> '1012281',
>>>>> '1015285',
>>>>> '1015285',
>>>>> '1007183',
>>>>> '1008833',
>>>>> '1015315',
>>>>> '1015322',
>>>>> '1015285')
>>>>> 
>>>>> Primary.Viol.Type <- c('AS.Age',
>>>>> 'HS.Hours',
>>>>> 'HS.Hours',
>>>>> 'HS.Hours',
>>>>> 'RK.Records_CL',
>>>>> 'OT.Overtime',
>>>>> 'OT.Overtime',
>>>>> 'OT.Overtime',
>>>>> 'V.Poster_Other',
>>>>> 'V.Poster_Other')
>>>>> 
>>>>> PViol.Type.Per.Case.Original <- data.frame(CaseID,Primary.Viol.Type)
>>>>> 
>>>>> # CaseID?s can be repeated because there can be up to 14
>>>>> Primary.Viol.Type?s per CaseID.
>>>>> 
>>>>> # I want to transform this dataframe into one that has 15 columns,
>>>>> where the first column is CaseID, and the rest are the 14 primary
>>>>> viol. types.  The CaseID column will contain a list of the unique
>>>>> CaseID?s (no
>>>>> replicates) and
>>>>> for each of their rows, there will be a ?1? under  a column
>>>>> corresponding to a primary violation type recorded for that CaseID.
>>>>> So, technically, there could be zero to 14 ?1?s? in a CaseID?s row.
>>>>> 
>>>>> # For example, the row for CaseID '1015285' above would have a ?1?
>>>>> under ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?,
>>>>> but have "NA"
>>>>> under the rest of the columns.
>>>>> 
>>>>> PViol.Type <- c("CaseID",
>>>>>                 "BW.BackWages",
>>>>>            "LD.Liquid_Damages",
>>>>>            "MW.Minimum_Wage",
>>>>>            "OT.Overtime",
>>>>>            "RK.Records_FLSA",
>>>>>            "V.Poster_Other",
>>>>>            "AS.Age",
>>>>>            "BW.WHMIS_BackWages",
>>>>>            "HS.Hours",
>>>>>            "OA.HazOccupationAg",
>>>>>            "ON.HazOccupationNonAg",
>>>>>            "R3.Reg3AgeOccupation",
>>>>>            "RK.Records_CL",
>>>>>            "V.Other")
>>>>> 
>>>>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>>>>> 
>>>>> # What is the best way to do this in R?
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> View this message in context:
>>>>> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-ro
>>>>> w-of-same-df-then-adjust-col1-data-display-tp4700878.html
>>>>> 
>>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                         Live:   OO#.. Dead: OO#..
>>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>> rocks...1k
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From bbolker at gmail.com  Fri Dec 19 15:56:02 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 19 Dec 2014 14:56:02 +0000
Subject: [R] lme4 2 factor factorial model with random factors
References: <CADqzGTvp4X6GoF2f2zNR1wDnBEaHM+45H6WSpaPWmdcczGZQJQ@mail.gmail.com>
Message-ID: <loom.20141219T155309-189@post.gmane.org>

Jacob Warren (RIT Student <jjw3952 <at> rit.edu> writes:

> 
> Using lme4 how does one define a 2 factor factorial model with both factors
> being random?
> 
> Specifically I am just trying to recreate the results from Montgomery's
> Design of Experiments book (7th edition), example 13.2. In this example
> there are 2 random factors and I want to include the interaction in the
> model as Montgomery tests for significance in the full model first. I've
> tried several things but cannot recreate the results in R. I would think
> something like what's given below would work, but it does not.
> 
> lmer(y ~ (1 | Parts) + (1 | Operators) + (1 | Parts:Operators) )
> 


 You also posted this on StackOverflow (broken URL to make Gmane
happy, sorry): <http://stats.stackexchange.com/questions/129592/
2-factor-factorial-model-with-random-factors>. While cross-posting
between SO and R mailing lists isn't explicitly forbidden, I think
it's polite to indicate you've done so/cross-link. On SO, I
asked for more information -- not all of us have immediate access to
Montgomery's book (maybe you can provide a Google books link if the
text is accessible that way?).

  SO or r-sig-mixed-models at r-project.org are probably more appropriate
follow-up venues.

  Ben Bolker


From Bernhard_Pfaff at fra.invesco.com  Fri Dec 19 16:10:55 2014
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Fri, 19 Dec 2014 15:10:55 +0000
Subject: [R] where is XMLRPC for R>3.0 for Windows machines
In-Reply-To: <006a01d01b8c$1b54ad50$51fe07f0$@pt>
References: <006a01d01b8c$1b54ad50$51fe07f0$@pt>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C710DFC9F4B@GBLONXMB11.corp.amvescap.net>

Hello Diogo,

the package is hosted on Omegahat:

	http://www.omegahat.org/XMLRPC/

Best wishes,
Bernhard

-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Diogo Andr? Alagador
Gesendet: Freitag, 19. Dezember 2014 14:03
An: r-help at r-project.org
Betreff: [R] where is XMLRPC for R>3.0 for Windows machines

 

I am need to install rneos for R 3.1 under Windows 64bit. 

However it depends on the package XMLRPC that is not available in conventional repositories.

In the CRAN R 3.1 online readme
(http://cran.r-project.org/bin/windows/contrib/3.1/ReadMe) there is an information regarding the installation of package XMLRP for Windows that direct users to the Prof Ripley s link (http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1/). However the zip file is not there neither for the 3.0 r version.

Anyone can inform me on how can obtain it?

 

Best regards,

Diogo Alagador

 <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador

CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University of  vora, Portugal

 

 

 


	[[alternative HTML version deleted]]

*****************************************************************
Confidentiality Note: The information contained in this message,
and any attachments, may contain confidential and/or privileged
material. It is intended solely for the person(s) or entity to
which it is addressed. Any review, retransmission, dissemination,
or taking of any action in reliance upon this information by
persons or entities other than the intended recipient(s) is
prohibited. If you received this in error, please contact the
sender and delete the material from any computer.
*****************************************************************

From zadig_1 at excite.com  Fri Dec 19 17:22:46 2014
From: zadig_1 at excite.com (ce)
Date: Fri, 19 Dec 2014 11:22:46 -0500
Subject: [R] Your pardon: An article possibly of interest to
	statisticians
Message-ID: <20141219112246.8002@web009.roc2.bluetie.com>


Nice but as this is R forum, is there an R package related to it ?

-----Original Message-----
From: "John McKown" [john.archie.mckown at gmail.com]
Date: 12/18/2014 01:38 PM
To: "r-help" <r-help at r-project.org>
Subject: [R] Your pardon: An article possibly of interest to statisticians

I do hope this doesn't upset anyone. But it appears rather interesting to
me, despite the fact that I'm not a statistician. So I thought that it
might be of interest to some others here.

https://medium.com/the-physics-arxiv-blog/cause-and-effect-the-revolutionary-new-statistical-test-that-can-tease-them-apart-ed84a988e

http://arxiv.org/abs/1412.3773

Title: Distinguishing cause from effect using observational data: methods
and benchmarks
<quote>
The discovery of causal relationships from purely observational data is a
fundamental problem in science. The most elementary form of such a causal
discovery problem is to decide whether X causes Y or, alternatively, Y
causes X, given joint observations of two variables X, Y . This was often
considered to be impossible. Nevertheless, several approaches for
addressing this bivariate causal discovery problem were proposed recently.
In this paper, we present the benchmark data set CauseEffectPairs that
consists of 88 different "cause-effect pairs" selected from 31 datasets
from various domains. We evaluated the performance of several bivariate
causal discovery methods on these real-world benchmark data and on
artificially simulated data. Our empirical results provide evidence that
additive-noise methods are indeed able to distinguish cause from effect
using only purely observational data. In addition, we prove consistency of
the additive-noise method proposed by Hoyer et al. (2009).
</quote>

Returning to lurkerdom.

-- 
?
While a transcendent vocabulary is laudable, one must be eternally careful
so that the calculated objective of communication does not become ensconced
in obscurity.  In other words, eschew obfuscation.

111,111,111 x 111,111,111 = 12,345,678,987,654,321

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code


From murdoch.duncan at gmail.com  Fri Dec 19 17:24:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Dec 2014 11:24:51 -0500
Subject: [R] We won an award, and didn't even notice...
Message-ID: <54945153.8030608@gmail.com>

This morning I was reading Jeff Leek's list of awesome things other 
people did in 2014 at http://simplystatistics.org/?p=3696 (thanks to the 
Revolution Analytics blog for the pointer).  One of the items in his 
list had a link to a list of awards for open source software in 2014:

http://www.infoworld.com/article/2688074/big-data/big-data-164727-bossie-awards-2014-the-best-open-source-big-data-tools.html


Turns out R won an award (on September 29!), and we didn't even notice.  
The RCloud project also won one.

Duncan Murdoch


From jfox at mcmaster.ca  Fri Dec 19 17:27:40 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 19 Dec 2014 11:27:40 -0500
Subject: [R] Fitting Structural Equation Model with sem package and
	Summary	issues
In-Reply-To: <CAEE5xg9ttm7c24g4JOmO6cHDr3WNVYNgkfi5p3wPM3dEbkvFJw@mail.gmail.com>
References: <CAEE5xg9ttm7c24g4JOmO6cHDr3WNVYNgkfi5p3wPM3dEbkvFJw@mail.gmail.com>
Message-ID: <001901d01ba8$b58f7dc0$20ae7940$@mcmaster.ca>

Dear Guillaume,

Please see comments interspersed below:

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Guillaume Souchay
> Sent: Thursday, December 18, 2014 8:50 AM
> To: r-help at r-project.org
> Subject: [R] Fitting Structural Equation Model with sem package and
> Summary issues
> 
> Hi all,
> 
> I am trying to analyse bird data to investigate carry-over effect
> using structural equation model.
> I failed to run properly a big model with several latent variables
> with both L -> M block and M -> L block.
> Rather than trying again and again with the huge model, I am now
> looking to a subset of the model.
> 
> Due to previous error message (singularity in the matrix), I scaled
> all the variables.
> Here is a subset of the data:
> > dataE[1:15,]
>    Fledgling_date_t Total_Output_t Breed_nb.clutch_t.1 Breed_Egg_t.1
> Breed_Total_Output_t.1
> 1        1.09397971     1.19657515           0.4696909   -0.69784742
>            1.2558119
> 2        0.62564592     0.37786584           0.4696909    0.02046473
>           -0.1762543
> 3        1.51548013     1.19657515          -1.0568046    0.89840181
>           -1.8947338
> 4        0.15731212     1.60592981          -1.0568046   -1.49597204
>           -1.3219073
> 5        0.48514578    -0.44084348           0.4696909   -0.69784742
>            0.6829854
> 6        1.93698054    -0.03148882           0.4696909    0.02046473
>            0.9693987
> 7       -1.66918968    -0.85019813          -1.0568046    0.97821428
>           -0.4626676
> 8        0.01681198     0.78722049           0.4696909   -0.53822250
>            1.2558119
> 9        0.34464564     1.60592981          -1.0568046   -0.13916019
>           -1.8947338
> 10       1.23447985     1.19657515          -1.0568046    1.93596382
>           -0.7490808
> 11      -0.12368816    -0.85019813           0.4696909    1.93596382
>            0.1101589
> 12      -0.17052154     0.78722049          -1.0568046   -0.45841004
>           -0.1762543
> 13      -1.52868954    -0.44084348          -1.0568046    1.37727658
>           -0.4626676
> 14       0.15731212    -1.25955279          -1.0568046    1.61671397
>           -0.4626676
> 15      -0.17052154    -0.85019813          -1.0568046    0.97821428
>           -1.6083205
> 
> Library(sem)
> # the covariance matrix for scaled data
> S.covE <-
> readMoments(diag=T,names=c("Fledgling_date_t","Total_Output_t","Breed_nb
> .clutch_t.1","Breed_Egg_t.1","Breed_Total_Output_t.1"))
> 1.0000000
> 0.350170246 1.0000000
> -0.075832501 -0.099929893 1.0000000
> -0.15439341 -0.091334987 -0.131698418 1.0000000
> -0.191457491 -0.227843749 0.510666663 -0.386711653 1.0000000
> 
> # specification of the model - I also provided a diagram of the model
> in the attached PDF.
> modelE <- specifyModel()
> EndBreed -> Fledgling_date_t,                       lambda1,   NA
> EndBreed -> Total_Output_t,                         lambda1,   NA
> Fledgling_date_t <-> Fledgling_date_t,              delta1,    NA
> Total_Output_t <-> Total_Output_t,                  delta2,    NA
> Fledgling_date_t <-> Total_Output_t,                theta1,    NA
> EndBreed -> BreedSucc,                              gamma1,    NA
> EndBreed <-> EndBreed,                              phi1,      NA
> BreedSucc -> Breed_Egg_t.1,                         lamdae,    NA
> BreedSucc -> Breed_Total_Output_t.1,                lamdae,    NA
> BreedSucc -> Breed_nb.clutch_t.1,                   lamdae,    NA
> Breed_nb.clutch_t.1 <-> Breed_nb.clutch_t.1,        eps1,      NA
> Breed_Egg_t.1 <-> Breed_Egg_t.1,                    eps2,      NA
> Breed_Total_Output_t.1 <-> Breed_Total_Output_t.1,  eps3,      NA
> Breed_nb.clutch_t.1 <-> Breed_Egg_t.1,              psie12,    NA
> Breed_Egg_t.1 <-> Breed_Total_Output_t.1,           psie23,    NA
> Breed_nb.clutch_t.1 <-> Breed_Total_Output_t.1,     psie13,    NA
> BreedSucc <-> BreedSucc,                            zetae,     NA
> 
> # estimation of the model
> semE <- sem(modelE,S.covE,N=39,debug=T)
> 
> To this point, everything seemed fine, the parameter were estimated
> after 129 iterations with all data.
> However, the problem arised when I asked for a summary of the model:
> 
> > summary(semE)
> Error in summary.objectiveML(semE) :
>   coefficient covariances cannot be computed
> 
> But the model seemed to work well :
> 
> > semE
> 
>  Model Chisquare =  0.9876903   Df =  1
> 
>    lambda1     delta1     delta2     theta1     gamma1       phi1
> lamdae       eps1       eps2
>  0.8251654  0.3302009  0.3418300 -0.3138143  0.4122545  0.9752364
> -0.4671335  0.8020365  0.7857964
>       eps3     psie12     psie23     psie13      zetae
>  0.7461566 -0.3377820 -0.6207350  0.2847632  0.8828395
> 
>  Iterations =  75
> > semE$convergence
> [1] TRUE

What's remarkable is that you got estimates at all. The model is underidentified because even with the equality constraints on the parameters there are no normalizing constraints setting scales for the latent variables. As well, allowing all measurement error variables to be correlated between (among) the indicators of each latent variable underidentifies the model.

> 
> I also tried with using SpecifyEquations() instead of SpecifyModel() :
> # specification of the model using specifyEquations
> modelEe <- specifyEquations()
> Fledgling_date_t = lambda1*EndBreed
> Total_Output_t = lambda1*EndBreed
> c(Fledgling_date_t,Total_Output_t) = theta1
> Breed_nb.clutch_t.1 = lamdae*BreedSucc
> Breed_Egg_t.1 = lamdae*BreedSucc
> Breed_Total_Output_t.1 = lamdae*BreedSucc
> c(Breed_nb.clutch_t.1,Breed_Egg_t.1) = psi12
> c(Breed_nb.clutch_t.1,Breed_Total_Output_t.1) = psi13
> c(Breed_Egg_t.1,Breed_Total_Output_t.1) = psi23
> BreedSucc = gamma1*EndBreed
> v(EndBreed) = phi1
> v(BreedSucc) = zeta1
> v(Fledgling_date_t) = delta1
> v(Total_Output_t) = delta2
> v(Breed_nb.clutch_t.1) = eps1
> v(Breed_Egg_t.1) = eps2
> v(Breed_Total_Output_t.1) = eps3
> 
> # estimation of the model
> semEe <- sem(modelEe,covE,N=39,debug=T)
> 
> > semEe
> 
>  Model Chisquare =  0.9876903   Df =  1
> 
>    lambda1     theta1     lamdae      psi12      psi13      psi23
> gamma1       phi1      zeta1
>  0.8220182 -0.3346606  0.5034442 -0.3550646  0.2674806 -0.6380177
> -0.3694630  1.0135693  0.8326144
>     delta1     delta2       eps1       eps2       eps3
>  0.3093554  0.3209828  0.7847537  0.7685137  0.7288741
> 
>  Iterations =  79
> > summary(semEe)
> Error in summary.objectiveML(semEe) :
>   coefficient covariances cannot be computed
> 

This is the same model. That you got identical chisquares but different parameter estimates points to underidentification. Again, I'm surprised that there was an apparent solution not that the information matrix isn't positive-definite.

> I also tried to set one loading to 1 instead of setting equality among
> loadings, but the results were the same.

That addresses one of the sources of underidentification but not the other. Actually, to be consistent with your prior specification you should have set *all* of the factor loadings to 1, which would both constrain them equal and set a metric for the latent variables -- but the resulting model would still (I believe) be underidentified by virtue of the correlations among the measurement errors.

> 
> Could it be possible that the low number of data (N=39 but no NA
> inside) may be the cause of the error?
> In the model, the df is 1, thus all the parameters should be
> identifiable.

No, the small N probably makes it inadvisable to fit a SEM to these data but the input covariance matrix isn't poorly conditioned. Also, positive df doesn't guarantee an identified model -- it's a necessary but not sufficient condition for identification -- and it's very easy to specify a model with positive df that's still underidentified. Indeed, you easily succeeded in doing that.

> 
> Hoping you will have enough information to help a bit.

I fiddled with your model a bit and produced the following (allowing different factor loadings for different indicators and using as a normalizing constraint that the variances of the latent variables are 1):

-------------- snip -------------

> modelEe.modified <- specifyEquations()
1: Fledgling_date_t = lambda1*EndBreed
2: Total_Output_t = lambda2*EndBreed
3: Breed_nb.clutch_t.1 = lamdae1*BreedSucc
4: Breed_Egg_t.1 = lamdae2*BreedSucc
5: Breed_Total_Output_t.1 = lamdae3*BreedSucc
6: BreedSucc = gamma1*EndBreed
7: V(EndBreed) = 1
8: V(BreedSucc) = 1
9: 
Read 8 items
NOTE: adding 5 variances to the model

> semEe.modified <- sem(modelEe.modified, S.covE, N=39)
> summary(semEe.modified)

 Model Chisquare =  1.998071   Df =  4 Pr(>Chisq) = 0.7361137
 AIC =  23.99807
 BIC =  -12.65618

 Normalized Residuals
    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-1.14900 -0.36600  0.00000 -0.18790  0.08115  0.23380 

 R-square for Endogenous Variables
      Fledgling_date_t         Total_Output_t              BreedSucc    Breed_nb.clutch_t.1          Breed_Egg_t.1 Breed_Total_Output_t.1 
                0.3331                 0.3681                 0.0554                 0.0805                 0.0559                 2.8772 

 Parameter Estimates
                          Estimate   Std Error z value    Pr(>|z|)                                                       
lambda1                    0.5771328 0.2495813  2.3124037 2.075545e-02 Fledgling_date_t <--- EndBreed                    
lambda2                    0.6067412 0.2570540  2.3603648 1.825697e-02 Total_Output_t <--- EndBreed                      
lamdae1                    0.2757486 0.2421902  1.1385623 2.548858e-01 Breed_nb.clutch_t.1 <--- BreedSucc                
lamdae2                   -0.2297048 0.2136600 -1.0750952 2.823321e-01 Breed_Egg_t.1 <--- BreedSucc                      
lamdae3                    1.6485964 1.3517870  1.2195682 2.226286e-01 Breed_Total_Output_t.1 <--- BreedSucc             
gamma1                    -0.2421404 0.2698327 -0.8973722 3.695203e-01 BreedSucc <--- EndBreed                           
V[Fledgling_date_t]        0.6669177 0.2778114  2.4006126 1.636765e-02 Fledgling_date_t <--> Fledgling_date_t            
V[Total_Output_t]          0.6318651 0.2944414  2.1459791 3.187465e-02 Total_Output_t <--> Total_Output_t                
V[Breed_nb.clutch_t.1]     0.9195045 0.2423910  3.7934763 1.485528e-04 Breed_nb.clutch_t.1 <--> Breed_nb.clutch_t.1      
V[Breed_Egg_t.1]           0.9441415 0.2306422  4.0935328 4.248499e-05 Breed_Egg_t.1 <--> Breed_Egg_t.1                  
V[Breed_Total_Output_t.1] -1.8772242 4.4379049 -0.4229979 6.722968e-01 Breed_Total_Output_t.1 <--> Breed_Total_Output_t.1

 Iterations =  34 

-------------- snip -------------

Of course, if you really *believe* that the various measurement errors are correlated then these estimates are biased.

Some more comments:

(1) You don't have to supply error-variances for variables; specifyEquations() and specifyModel() will do that automatically by default (as you can see in my input/output above).

(2) If you have the original data set, as you do, it's better to use that rather than a moment matrix as input to sem().

Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/


> 
> Thanks in advance.
> 
> Cheers,
> 
> Guillaume
> 
> --
> 
> Guillaume SOUCHAY, Ph.D
> 
> Post-doctoral fellow in population dynamics
> 
> ---
> 
> "There is no true model" Anderson & Burhnam 1999
> 
> ---
> 
> ?
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bcrombie at utk.edu  Fri Dec 19 14:52:03 2014
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Fri, 19 Dec 2014 13:52:03 +0000
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <965F3F18EFD.00000738jrkrideau@inbox.com>
References: <54932e4b.8030009@mail.usask.ca>
	<alpine.bsf.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
	<559c998f7039d84c9793ae43d9bbe9cee5117dca@kmbx4.utk.tennessee.edu>
	<5493b914.4030903@mail.usask.ca>
	<1418872514464-4700878.post@n4.nabble.com>
	<965F3F18EFD.00000738jrkrideau@inbox.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CEE5117EC5@kmbx4.utk.tennessee.edu>

That is the solution I had tried first (yes, it's nice!), but it doesn't provide the other PViol.Type's that aren't necessarily in my dataset.  That's where my problem is.  I'm closer to the cure, though, and think I've thought of a solution as soon as I have time.  I'll update everyone then. -- BNC

-----Original Message-----
From: John Kane [mailto:jrkrideau at inbox.com] 
Sent: Friday, December 19, 2014 8:44 AM
To: Sven E. Templer; Chel Hee Lee
Cc: R Help List; Crombie, Burnette N
Subject: Re: [R] Make 2nd col of 2-col df into header row of same df then adjust col1 data display

Very pretty. 
I could have saved myself about 1/2 hour of mucking about if I had thought ot "length".

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sven.templer at gmail.com
> Sent: Fri, 19 Dec 2014 10:13:55 +0100
> To: chl948 at mail.usask.ca
> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df 
> then adjust col1 data display
> 
> Another solution:
> 
> CaseID <- c("1015285", "1005317", "1012281", "1015285", "1015285", 
> "1007183", "1008833", "1015315", "1015322", "1015285") 
> Primary.Viol.Type <- c("AS.Age", "HS.Hours", "HS.Hours", "HS.Hours", 
> "RK.Records_CL", "OT.Overtime", "OT.Overtime", "OT.Overtime", 
> "V.Poster_Other",
> "V.Poster_Other")
> 
> library(reshape2)
> dcast(data.frame(CaseID, Primary.Viol.Type), CaseID~Primary.Viol.Type,
> length)
> 
> # result:
> 
> Using Primary.Viol.Type as value column: use value.var to override.
>    CaseID AS.Age HS.Hours OT.Overtime RK.Records_CL V.Poster_Other
> 1 1005317      0        1           0             0              0
> 2 1007183      0        0           1             0              0
> 3 1008833      0        0           1             0              0
> 4 1012281      0        1           0             0              0
> 5 1015285      1        1           0             1              1
> 6 1015315      0        0           1             0              0
> 7 1015322      0        0           0             0              1
> 
> 
> best, s.
> 
> On 19 December 2014 at 06:35, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>> Please take a look at my code again.  The error message says that 
>> object 'Primary.Viol.Type' not found.  Have you ever created the object
>> 'Primary.Viol.Type'?   It will be working if you replace
>> 'Primary.Viol.Type'
>> by 'PViol.Type.Per.Case.Original$Primary.Viol.Type' where 'factor()' 
>> is used.  I hope this helps.
>> 
>> Chel Hee Lee
>> 
>> On 12/18/2014 08:57 PM, Crombie, Burnette N wrote:
>>> 
>>> Chel, your solution is fantastic on the dataset I submitted in my 
>>> question but it is not working when I import my real dataset into R.  
>>> Do I need to vectorize the columns in my real dataset after 
>>> importing?  I tried a few things (###) but not making progress:
>>> 
>>> MERGE_PViol.Detail.Per.Case <-
>>> read.csv("~/FOIA_FLSA/MERGE_PViol.Detail.Per.Case_for_rtf10.csv",
>>> stringsAsFactors=TRUE)
>>> 
>>> ### select only certain columns
>>> PViol.Type.Per.Case.Original <-
>>> MERGE_PViol.Detail.Per.Case[,c("CaseID",
>>> "Primary.Viol.Type")]
>>> 
>>> ###
>>> write.csv(PViol.Type.Per.Case,file="PViol.Type.Per.Case.Select.csv")
>>> ### PViol.Type.Per.Case.Original <-
>>> read.csv("~/FOIA_FLSA/PViol.Type.Per.Case.Select.csv")
>>> ### PViol.Type.Per.Case.Original$X <- NULL 
>>> ###PViol.Type.Per.Case.Original[] <- 
>>> lapply(PViol.Type.Per.Case.Original,
>>> as.character)
>>> 
>>> PViol.Type <- c("CaseID",
>>>                  "BW.BackWages",
>>>                  "LD.Liquid_Damages",
>>>                  "MW.Minimum_Wage",
>>>                  "OT.Overtime",
>>>                  "RK.Records_FLSA",
>>>                  "V.Poster_Other",
>>>                  "AS.Age",
>>>                  "BW.WHMIS_BackWages",
>>>                  "HS.Hours",
>>>                  "OA.HazOccupationAg",
>>>                  "ON.HazOccupationNonAg",
>>>                  "R3.Reg3AgeOccupation",
>>>                  "RK.Records_CL",
>>>                  "V.Other")
>>> 
>>> PViol.Type.Per.Case.Original$Primary.Viol.Type <- 
>>> factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)
>>> 
>>> ### Error in factor(Primary.Viol.Type, levels = PViol.Type, labels =
>>> PViol.Type) :  object 'Primary.Viol.Type' not found
>>> 
>>> tmp <-
>>> split(PViol.Type.Per.Case.Original,PViol.Type.Per.Case.Original$Case
>>> ID) ans <- ifelse(do.call(rbind, lapply(tmp, 
>>> function(x)table(x$Primary.Viol.Type))), 1, NA)
>>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: Crombie, Burnette N
>>> Sent: Thursday, December 18, 2014 3:01 PM
>>> To: 'Chel Hee Lee'
>>> Subject: RE: [R] Make 2nd col of 2-col df into header row of same df 
>>> then adjust col1 data display
>>> 
>>> Thanks for taking the time to review this, Chel.  I've got to step 
>>> away from my desk, but will reply more substantially as soon as 
>>> possible. -- BNC
>>> 
>>> -----Original Message-----
>>> From: Chel Hee Lee [mailto:chl948 at mail.usask.ca]
>>> Sent: Thursday, December 18, 2014 2:43 PM
>>> To: Jeff Newmiller; Crombie, Burnette N
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Make 2nd col of 2-col df into header row of same df 
>>> then adjust col1 data display
>>> 
>>> I like the approach presented by Jeff Newmiller as shown in the 
>>> previous post (I really like his way).  As he suggested, it would be 
>>> good to start with 'factor' since you have all values of 
>>> 'Primary.Viol.Type'.
>>> You may try to use 'split()' function for creating table that you 
>>> wish to build.  Please see the below (I hope this helps):
>>> 
>>>   > PViol.Type.Per.Case.Original$Primary.Viol.Type <- 
>>> factor(Primary.Viol.Type, levels=PViol.Type, labels=PViol.Type)  >  
>>> > tmp <- split(PViol.Type.Per.Case.Original,
>>> PViol.Type.Per.Case.Original$CaseID)
>>>   > ans <- ifelse(do.call(rbind, lapply(tmp, function(x) 
>>> table(x$Primary.Viol.Type))), 1, NA)  > ans
>>>           CaseID BW.BackWages LD.Liquid_Damages MW.Minimum_Wage 
>>> OT.Overtime
>>> 1005317     NA           NA                NA              NA
>>> NA
>>> 1007183     NA           NA                NA              NA
>>> 1
>>> 1008833     NA           NA                NA              NA
>>> 1
>>> 1012281     NA           NA                NA              NA
>>> NA
>>> 1015285     NA           NA                NA              NA
>>> NA
>>> 1015315     NA           NA                NA              NA
>>> 1
>>> 1015322     NA           NA                NA              NA
>>> NA
>>>           RK.Records_FLSA V.Poster_Other AS.Age BW.WHMIS_BackWages 
>>> HS.Hours
>>> 1005317              NA             NA     NA                 NA
>>> 1
>>> 1007183              NA             NA     NA                 NA
>>> NA
>>> 1008833              NA             NA     NA                 NA
>>> NA
>>> 1012281              NA             NA     NA                 NA
>>> 1
>>> 1015285              NA              1      1                 NA
>>> 1
>>> 1015315              NA             NA     NA                 NA
>>> NA
>>> 1015322              NA              1     NA                 NA
>>> NA
>>>           OA.HazOccupationAg ON.HazOccupationNonAg R3.Reg3AgeOccupation
>>> 1005317                 NA                    NA                   NA
>>> 1007183                 NA                    NA                   NA
>>> 1008833                 NA                    NA                   NA
>>> 1012281                 NA                    NA                   NA
>>> 1015285                 NA                    NA                   NA
>>> 1015315                 NA                    NA                   NA
>>> 1015322                 NA                    NA                   NA
>>>           RK.Records_CL V.Other
>>> 1005317            NA      NA
>>> 1007183            NA      NA
>>> 1008833            NA      NA
>>> 1012281            NA      NA
>>> 1015285             1      NA
>>> 1015315            NA      NA
>>> 1015322            NA      NA
>>>   >
>>> 
>>> Chel Hee Lee
>>> 
>>> On 12/18/2014 10:02 AM, Jeff Newmiller wrote:
>>>> 
>>>> No guarantees on "best"... but one way using base R could be:
>>>> 
>>>> # Note that "CaseID" is actually not a valid PViol.Type as you had 
>>>> it PViol.Type <- c( "BW.BackWages"
>>>>                  , "LD.Liquid_Damages"
>>>>                  , "MW.Minimum_Wage"
>>>>                  , "OT.Overtime"
>>>>                  , "RK.Records_FLSA"
>>>>                  , "V.Poster_Other"
>>>>                  , "AS.Age"
>>>>                  , "BW.WHMIS_BackWages"
>>>>                  , "HS.Hours"
>>>>                  , "OA.HazOccupationAg"
>>>>                  , "ON.HazOccupationNonAg"
>>>>                  , "R3.Reg3AgeOccupation"
>>>>                  , "RK.Records_CL"
>>>>                  , "V.Other" )
>>>> 
>>>> # explicitly specifying all levels to the factor insures a complete 
>>>> # set of column outputs regardless of what is in the input 
>>>> PViol.Type.Per.Case.Original <-
>>>>       data.frame( CaseID
>>>>                 , Primary.Viol.Type=factor( Primary.Viol.Type
>>>>                                           , levels=PViol.Type ) )
>>>> 
>>>> tmp <- table( PViol.Type.Per.Case.Original ) ans <- data.frame( 
>>>> CaseID=rownames( tmp )
>>>>                    , as.data.frame( ifelse( 0==tmp, NA, 1 ) )
>>>>                    )
>>>> 
>>>> 
>>>> On Wed, 17 Dec 2014, bcrombie wrote:
>>>> 
>>>>> # I have a dataframe that contains 2 columns:
>>>>> CaseID  <- c('1015285',
>>>>> '1005317',
>>>>> '1012281',
>>>>> '1015285',
>>>>> '1015285',
>>>>> '1007183',
>>>>> '1008833',
>>>>> '1015315',
>>>>> '1015322',
>>>>> '1015285')
>>>>> 
>>>>> Primary.Viol.Type <- c('AS.Age',
>>>>> 'HS.Hours',
>>>>> 'HS.Hours',
>>>>> 'HS.Hours',
>>>>> 'RK.Records_CL',
>>>>> 'OT.Overtime',
>>>>> 'OT.Overtime',
>>>>> 'OT.Overtime',
>>>>> 'V.Poster_Other',
>>>>> 'V.Poster_Other')
>>>>> 
>>>>> PViol.Type.Per.Case.Original <- 
>>>>> data.frame(CaseID,Primary.Viol.Type)
>>>>> 
>>>>> # CaseID?s can be repeated because there can be up to 14 
>>>>> Primary.Viol.Type?s per CaseID.
>>>>> 
>>>>> # I want to transform this dataframe into one that has 15 columns, 
>>>>> where the first column is CaseID, and the rest are the 14 primary 
>>>>> viol. types.  The CaseID column will contain a list of the unique 
>>>>> CaseID?s (no
>>>>> replicates) and
>>>>> for each of their rows, there will be a ?1? under  a column 
>>>>> corresponding to a primary violation type recorded for that CaseID.
>>>>> So, technically, there could be zero to 14 ?1?s? in a CaseID?s row.
>>>>> 
>>>>> # For example, the row for CaseID '1015285' above would have a ?1?
>>>>> under ?AS.Age?, ?HS.Hours?, ?RK.Records_CL?, and ?V.Poster_Other?, 
>>>>> but have "NA"
>>>>> under the rest of the columns.
>>>>> 
>>>>> PViol.Type <- c("CaseID",
>>>>>                 "BW.BackWages",
>>>>>            "LD.Liquid_Damages",
>>>>>            "MW.Minimum_Wage",
>>>>>            "OT.Overtime",
>>>>>            "RK.Records_FLSA",
>>>>>            "V.Poster_Other",
>>>>>            "AS.Age",
>>>>>            "BW.WHMIS_BackWages",
>>>>>            "HS.Hours",
>>>>>            "OA.HazOccupationAg",
>>>>>            "ON.HazOccupationNonAg",
>>>>>            "R3.Reg3AgeOccupation",
>>>>>            "RK.Records_CL",
>>>>>            "V.Other")
>>>>> 
>>>>> PViol.Type.Columns <- t(data.frame(PViol.Type)
>>>>> 
>>>>> # What is the best way to do this in R?
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> --
>>>>> View this message in context:
>>>>> http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header
>>>>> -ro w-of-same-df-then-adjust-col1-data-display-tp4700878.html
>>>>> 
>>>>> Sent from the R help mailing list archive at Nabble.com.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                         Live:   OO#.. Dead: OO#..
>>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>> rocks...1k
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From mtrang at buffalo.edu  Fri Dec 19 17:08:29 2014
From: mtrang at buffalo.edu (mtrang)
Date: Fri, 19 Dec 2014 08:08:29 -0800 (PST)
Subject: [R] Calculating mean, median, minimum, and maximum
In-Reply-To: <1418999039877-4700943.post@n4.nabble.com>
References: <1418831065531-4700862.post@n4.nabble.com>
	<1418934906993-4700919.post@n4.nabble.com>
	<1418999039877-4700943.post@n4.nabble.com>
Message-ID: <1419005309483-4700946.post@n4.nabble.com>

You can use the apply function which "applies" a function of your choice, and
MARGIN = 2 means you want to do it columnwise:

> apply(X = df, MARGIN=2, FUN = mean, na.rm = TRUE)
 Latitude Longitude   January  February     March     April       May     
June 
  26.9380 -109.8125  159.8454  156.4489  153.6911  150.1719  148.0885 
149.2365 
> apply(X = df, MARGIN=2, FUN = min, na.rm = TRUE)
 Latitude Longitude   January  February     March     April       May     
June 
   26.938  -110.688   121.204   118.713   117.293   114.398   112.357  
113.910 
> apply(X = df, MARGIN=2, FUN = max, na.rm = TRUE)
 Latitude Longitude   January  February     March     April       May     
June 
   26.938  -108.938   252.890   248.991   244.870   241.194   239.615  
239.888 
> apply(X = df, MARGIN=2, FUN = median, na.rm = TRUE)
 Latitude Longitude   January  February     March     April       May     
June 
  26.9380 -109.8120  134.5990  130.7960  127.4495  123.2100  120.8375 
122.3835 



--
View this message in context: http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-tp4700862p4700946.html
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at inbox.com  Fri Dec 19 17:48:44 2014
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 19 Dec 2014 08:48:44 -0800
Subject: [R] Calculating mean, median, minimum, and maximum
In-Reply-To: <1419005309483-4700946.post@n4.nabble.com>
References: <1418934906993-4700919.post@n4.nabble.com>
	<1418999039877-4700943.post@n4.nabble.com>
	<1418831065531-4700862.post@n4.nabble.com>
Message-ID: <97FBAD29EDE.000009B7jrkrideau@inbox.com>

Hi,
It looks like you are replying to some phantom. Is your correspondent actully on R-help?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mtrang at buffalo.edu
> Sent: Fri, 19 Dec 2014 08:08:29 -0800 (PST)
> To: r-help at r-project.org
> Subject: Re: [R] Calculating mean, median, minimum, and maximum
> 
> You can use the apply function which "applies" a function of your choice,
> and
> MARGIN = 2 means you want to do it columnwise:
> 
>> apply(X = df, MARGIN=2, FUN = mean, na.rm = TRUE)
>  Latitude Longitude   January  February     March     April       May
> June
>   26.9380 -109.8125  159.8454  156.4489  153.6911  150.1719  148.0885
> 149.2365
>> apply(X = df, MARGIN=2, FUN = min, na.rm = TRUE)
>  Latitude Longitude   January  February     March     April       May
> June
>    26.938  -110.688   121.204   118.713   117.293   114.398   112.357
> 113.910
>> apply(X = df, MARGIN=2, FUN = max, na.rm = TRUE)
>  Latitude Longitude   January  February     March     April       May
> June
>    26.938  -108.938   252.890   248.991   244.870   241.194   239.615
> 239.888
>> apply(X = df, MARGIN=2, FUN = median, na.rm = TRUE)
>  Latitude Longitude   January  February     March     April       May
> June
>   26.9380 -109.8120  134.5990  130.7960  127.4495  123.2100  120.8375
> 122.3835
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-tp4700862p4700946.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From tea3rd at gmail.com  Fri Dec 19 17:49:25 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Fri, 19 Dec 2014 09:49:25 -0700
Subject: [R] We won an award, and didn't even notice...
In-Reply-To: <54945153.8030608@gmail.com>
References: <54945153.8030608@gmail.com>
Message-ID: <CAGxgkWgYt6CihfR6v=_xLBRH2V87gR-3g0WRSvaZ-McJZfufOA@mail.gmail.com>

Duncan,

Congratulations to you and all the founders and contributors ? very much
deserved; thank you!!

Tom

On Fri, Dec 19, 2014 at 9:24 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
>
> This morning I was reading Jeff Leek's list of awesome things other people
> did in 2014 at http://simplystatistics.org/?p=3696 (thanks to the
> Revolution Analytics blog for the pointer).  One of the items in his list
> had a link to a list of awards for open source software in 2014:
>
> http://www.infoworld.com/article/2688074/big-data/big-
> data-164727-bossie-awards-2014-the-best-open-source-big-data-tools.html
>
>
> Turns out R won an award (on September 29!), and we didn't even notice.
> The RCloud project also won one.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Fri Dec 19 18:35:23 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 19 Dec 2014 09:35:23 -0800
Subject: [R] Calculating mean, median, minimum, and maximum
In-Reply-To: <97FBAD29EDE.000009B7jrkrideau@inbox.com>
References: <1418934906993-4700919.post@n4.nabble.com>
	<1418999039877-4700943.post@n4.nabble.com>
	<1418831065531-4700862.post@n4.nabble.com>
	<1419005309483-4700946.post@n4.nabble.com>
	<97FBAD29EDE.000009B7jrkrideau@inbox.com>
Message-ID: <CAFDcVCQxbmw30ZBLirvti+6N8--37QwDSaZ9U6Dt7-9y2ah7_g@mail.gmail.com>

On Fri, Dec 19, 2014 at 8:48 AM, John Kane <jrkrideau at inbox.com> wrote:
> Hi,
> It looks like you are replying to some phantom. Is your correspondent actully on R-help?

This most likely happens because OP posted the message via Nabble
[http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-td4700862.html]
via "New Topic", which in turn post the message to r-help after asking
the user to confirm:

"Mailing List Subscription Reminder
This forum is an archive/gateway which will forward your post to the
r-help at r-project.org mailing list.

The mailing list may require your subscription before accepting your
post. Please note that being registered with Nabble does NOT
automatically subscribe you to this mailing list. If you haven't
subscribed yet, please do it now. If you aren't sure or don't
remember, just subscribe again because there is no harm."

Since OP is not a registered user on the r-help mailing list, his/her
post is help by r-help for moderation.  However, mtrang probably saw
it on Nabble and replied there and since mtrang is also a registered
user on the r-help, his/her messages reach us here on r-help, before
OP's messages help for moderation are approved.

I'd say, this is quite annoying "feature" to everyone but Nabble
users, particularly since the Nabble message does not include the
previous messages (unlike email).

/Henrik

>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: mtrang at buffalo.edu
>> Sent: Fri, 19 Dec 2014 08:08:29 -0800 (PST)
>> To: r-help at r-project.org
>> Subject: Re: [R] Calculating mean, median, minimum, and maximum
>>
>> You can use the apply function which "applies" a function of your choice,
>> and
>> MARGIN = 2 means you want to do it columnwise:
>>
>>> apply(X = df, MARGIN=2, FUN = mean, na.rm = TRUE)
>>  Latitude Longitude   January  February     March     April       May
>> June
>>   26.9380 -109.8125  159.8454  156.4489  153.6911  150.1719  148.0885
>> 149.2365
>>> apply(X = df, MARGIN=2, FUN = min, na.rm = TRUE)
>>  Latitude Longitude   January  February     March     April       May
>> June
>>    26.938  -110.688   121.204   118.713   117.293   114.398   112.357
>> 113.910
>>> apply(X = df, MARGIN=2, FUN = max, na.rm = TRUE)
>>  Latitude Longitude   January  February     March     April       May
>> June
>>    26.938  -108.938   252.890   248.991   244.870   241.194   239.615
>> 239.888
>>> apply(X = df, MARGIN=2, FUN = median, na.rm = TRUE)
>>  Latitude Longitude   January  February     March     April       May
>> June
>>   26.9380 -109.8120  134.5990  130.7960  127.4495  123.2100  120.8375
>> 122.3835
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-tp4700862p4700946.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Fri Dec 19 18:57:30 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Dec 2014 17:57:30 +0000
Subject: [R] where is XMLRPC for R>3.0 for Windows machines
In-Reply-To: <FCD9A33C859ACC469587CB09DD5C6C710DFC9F4B@GBLONXMB11.corp.amvescap.net>
References: <006a01d01b8c$1b54ad50$51fe07f0$@pt>
	<FCD9A33C859ACC469587CB09DD5C6C710DFC9F4B@GBLONXMB11.corp.amvescap.net>
Message-ID: <5494670A.3030304@stats.ox.ac.uk>

On 19/12/2014 15:10, Pfaff, Bernhard Dr. wrote:
> Hello Diogo,
>
> the package is hosted on Omegahat:
>
> 	http://www.omegahat.org/XMLRPC/

And it installs from the sources on Windows as it has no compiled code. 
Something like

options(pkgType = 'source')
setRepositories() # choose omegahat
install.packages('XMLRPC')

>
> Best wishes,
> Bernhard
>
> -----Urspr?ngliche Nachricht-----
> Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Diogo Andr? Alagador
> Gesendet: Freitag, 19. Dezember 2014 14:03
> An: r-help at r-project.org
> Betreff: [R] where is XMLRPC for R>3.0 for Windows machines
>
>
>
> I am need to install rneos for R 3.1 under Windows 64bit.
>
> However it depends on the package XMLRPC that is not available in conventional repositories.
>
> In the CRAN R 3.1 online readme
> (http://cran.r-project.org/bin/windows/contrib/3.1/ReadMe) there is an information regarding the installation of package XMLRP for Windows that direct users to the Prof Ripley s link (http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1/). However the zip file is not there neither for the 3.0 r version.
>
> Anyone can inform me on how can obtain it?
>
>
>
> Best regards,
>
> Diogo Alagador
>
>   <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
> http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador
>
> CIBIO/UE - Research Center in Biodiversity and Genetic Resources, University of  vora, Portugal
>
>
>
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> *****************************************************************
> Confidentiality Note: The information contained in this message,
> and any attachments, may contain confidential and/or privileged
> material. It is intended solely for the person(s) or entity to
> which it is addressed. Any review, retransmission, dissemination,
> or taking of any action in reliance upon this information by
> persons or entities other than the intended recipient(s) is
> prohibited. If you received this in error, please contact the
> sender and delete the material from any computer.
> *****************************************************************
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From macqueen1 at llnl.gov  Fri Dec 19 19:17:34 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 19 Dec 2014 18:17:34 +0000
Subject: [R] Problems with spatial data for Masterthesis
In-Reply-To: <98E2EA55-7005-4B61-BA38-A3932FAE213A@gmail.com>
References: <98E2EA55-7005-4B61-BA38-A3932FAE213A@gmail.com>
Message-ID: <D0B9A7E5.1163A4%macqueen1@llnl.gov>

The "over" function in the sp package should be able to do this for you.
One of the examples found in ?over says:

 # return the number of points in each polygon:
     sapply(over(sr, geometry(meuse), returnList = TRUE), length)

In that example, meuse contains the points and sr contains polygons,
analogous to your districts. Hopefully, when you loaded the kml file the
resulting object defines polygons.

-Don


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/18/14, 1:23 AM, "Christian Brodbeck" <christiano.brodii at gmail.com>
wrote:

>Hi
>
>I write my masterthesis and don't know how I can count points in a
>spatial net.
>
>In practical I have a data set for carsharing usage in Berlin. It
>includes the Idletime of the cars with Long/lat coordinates for the
>certain places. So if I plot those points I have something like a cloud
>of points over the area of Berlin. SoMy task is, to find out, in which
>area of Berlin is the idletime of the carsharing the logest. Therefor I
>wanted to cluster the innercity of Berlin. I loaded a kml file about the
>districts of berlin and put the "net" together with the cloud of points.
>So graphically it works and looks nice. By now I have to find out at
>wihich district shows the most idletimes.
>Do you know a package/program-codeexample which can handle this problem.
>In other words which can count the points located in the several
>districts?
>I would be very thankful for your help
>
>Regards
>
>Chris
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Fri Dec 19 20:16:55 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 19 Dec 2014 19:16:55 +0000
Subject: [R] where is XMLRPC for R>3.0 for Windows machines
In-Reply-To: <5494670A.3030304@stats.ox.ac.uk>
References: <006a01d01b8c$1b54ad50$51fe07f0$@pt>	<FCD9A33C859ACC469587CB09DD5C6C710DFC9F4B@GBLONXMB11.corp.amvescap.net>
	<5494670A.3030304@stats.ox.ac.uk>
Message-ID: <549479A7.5030601@stats.ox.ac.uk>

On 19/12/2014 17:57, Prof Brian Ripley wrote:
> On 19/12/2014 15:10, Pfaff, Bernhard Dr. wrote:
>> Hello Diogo,
>>
>> the package is hosted on Omegahat:
>>
>>     http://www.omegahat.org/XMLRPC/
>
> And it installs from the sources on Windows as it has no compiled code.
> Something like
>
> options(pkgType = 'source')
> setRepositories() # choose omegahat
> install.packages('XMLRPC')

Or even

setRepositories() # choose omegahat
install.packages('XMLRPC', type='both')


>
>>
>> Best wishes,
>> Bernhard
>>
>> -----Urspr?ngliche Nachricht-----
>> Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Diogo
>> Andr? Alagador
>> Gesendet: Freitag, 19. Dezember 2014 14:03
>> An: r-help at r-project.org
>> Betreff: [R] where is XMLRPC for R>3.0 for Windows machines
>>
>>
>>
>> I am need to install rneos for R 3.1 under Windows 64bit.
>>
>> However it depends on the package XMLRPC that is not available in
>> conventional repositories.
>>
>> In the CRAN R 3.1 online readme
>> (http://cran.r-project.org/bin/windows/contrib/3.1/ReadMe) there is an
>> information regarding the installation of package XMLRP for Windows
>> that direct users to the Prof Ripley s link
>> (http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1/). However
>> the zip file is not there neither for the 3.0 r version.
>>
>> Anyone can inform me on how can obtain it?
>>
>>
>>
>> Best regards,
>>
>> Diogo Alagador
>>
>>   <http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador>
>> http://www.cibioue.uevora.pt/9-uncategorised/185-dr-diogo-alagador
>>
>> CIBIO/UE - Research Center in Biodiversity and Genetic Resources,
>> University of  vora, Portugal
>>
>>
>>
>>
>>
>>
>>
>>
>>     [[alternative HTML version deleted]]
>>
>> *****************************************************************
>> Confidentiality Note: The information contained in this message,
>> and any attachments, may contain confidential and/or privileged
>> material. It is intended solely for the person(s) or entity to
>> which it is addressed. Any review, retransmission, dissemination,
>> or taking of any action in reliance upon this information by
>> persons or entities other than the intended recipient(s) is
>> prohibited. If you received this in error, please contact the
>> sender and delete the material from any computer.
>> *****************************************************************
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kristi.glover at hotmail.com  Sat Dec 20 05:45:12 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Sat, 20 Dec 2014 00:45:12 -0400
Subject: [R] How to make Pivot table with two variables in R?
Message-ID: <COL130-W1624603BB61C49BE6BA5B7FA680@phx.gbl>

Hi R User, Would you suggest me on how I can build a pivot table using two variables? I want to put "text" in the table instead of value.  I have attached an example data and the type of table (FinalTable) I was looking for. I am looking for your suggestions. ThanksKG=====dat<-structure(list(tag = structure(c(1L, 1L, 1L, 2L, 3L, 4L, 5L, 6L, 6L, 7L, 7L, 8L), .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), time = structure(c(1L, 2L, 3L, 1L, 4L, 5L, 5L, 5L, 8L, 4L, 7L, 6L), .Label = c("2010-May 27", "2011-June 27", "2011-June 28", "2012-June 25", "2013-June 21", "2014-Jan 05", "2014-July 27", "2015-April 07"), class = "factor"),     states = structure(c(1L, 2L, 2L, 1L, 4L, 3L, 2L, 5L, 1L,     3L, 5L, 2L), .Label = c("A", "B", "C", "D", "Out"), class = "factor")), .Names = c("tag", "time", "states"), class = "data.frame", row.names = c(NA, -12L))
dat###table(dat$tag,dat$time)# it gives value but I want the name of the states in the table instead of value.#For examplefinalTable<-structure(list(tag = structure(1:8, .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), X2010.May.27 = structure(c(2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "A"), class = "factor"),     X2011.June.27 = structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L    ), .Label = c("0", "B"), class = "factor"), X2011.June.28 = structure(c(2L,     1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "B"), class = "factor"),     X2012.June.25 = structure(c(1L, 1L, 3L, 1L, 1L, 1L, 2L, 1L    ), .Label = c("0", "C", "D"), class = "factor"), X2013.June.21 = structure(c(1L,     1L, 1L, 3L, 2L, 4L, 1L, 1L), .Label = c("0", "B", "C", "Out"    ), class = "factor"), X2014.Jan.05 = structure(c(1L, 1L,     1L, 1L, 1L, 1L, 1L, 2L), .Label = c("0", "B"), class = "factor"),     X2014.July.27 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L    ), .Label = c("0", "Out"), class = "factor"), X2015.April.07 = c(0L,     0L, 0L, 0L, 0L, 1L, 0L, 0L)), .Names = c("tag", "X2010.May.27", "X2011.June.27", "X2011.June.28", "X2012.June.25", "X2013.June.21", "X2014.Jan.05", "X2014.July.27", "X2015.April.07"), class = "data.frame", row.names = c(NA,-8L))
finalTable
#How is it possible to get the finalTable as shown above?Any suggestions? 		 	   		  
	[[alternative HTML version deleted]]


From chl948 at mail.usask.ca  Sat Dec 20 07:09:21 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sat, 20 Dec 2014 00:09:21 -0600
Subject: [R] How to make Pivot table with two variables in R?
In-Reply-To: <COL130-W1624603BB61C49BE6BA5B7FA680@phx.gbl>
References: <COL130-W1624603BB61C49BE6BA5B7FA680@phx.gbl>
Message-ID: <54951291.8050603@mail.usask.ca>

 > x <- dat
 > x$time <- as.factor(as.Date(x$time, format="%Y-%B%d"))
 > tmp <- split(x, x$tag)
 > tmp1 <- do.call(rbind, lapply(tmp, function(x){
+ tb <- table(x$time)
+  idx <- which(tb>0)
+  tb1 <- replace(tb, idx, as.character(x$states))
+ }))
 > print(tmp1, quote=FALSE)
    2010-05-27 2011-06-27 2011-06-28 2012-06-25 2013-06-21 2014-01-05 
2014-07-27
x1 A          B          B          0          0          0          0 

x2 A          0          0          0          0          0          0 

x3 0          0          0          D          0          0          0 

x4 0          0          0          0          C          0          0 

x5 0          0          0          0          B          0          0 

x6 0          0          0          0          Out        0          0 

x7 0          0          0          C          0          0          Out 

x8 0          0          0          0          0          B          0 

    2015-04-07
x1 0
x2 0
x3 0
x4 0
x5 0
x6 A
x7 0
x8 0
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee


On 12/19/2014 10:45 PM, Kristi Glover wrote:
> Hi R User, Would you suggest me on how I can build a pivot table using two variables? I want to put "text" in the table instead of value.  I have attached an example data and the type of table (FinalTable) I was looking for. I am looking for your suggestions. ThanksKG=====dat<-structure(list(tag = structure(c(1L, 1L, 1L, 2L, 3L, 4L, 5L, 6L, 6L, 7L, 7L, 8L), .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), time = structure(c(1L, 2L, 3L, 1L, 4L, 5L, 5L, 5L, 8L, 4L, 7L, 6L), .Label = c("2010-May 27", "2011-June 27", "2011-June 28", "2012-June 25", "2013-June 21", "2014-Jan 05", "2014-July 27", "2015-April 07"), class = "factor"),     states = structure(c(1L, 2L, 2L, 1L, 4L, 3L, 2L, 5L, 1L,     3L, 5L, 2L), .Label = c("A", "B", "C", "D", "Out"), class = "factor")), .Names = c("tag", "time", "states"), class = "data.frame", row.names = c(NA, -12L))
> dat###table(dat$tag,dat$time)# it gives value but I want the name of the states in the table instead of value.#For examplefinalTable<-structure(list(tag = structure(1:8, .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), X2010.May.27 = structure(c(2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "A"), class = "factor"),     X2011.June.27 = structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L    ), .Label = c("0", "B"), class = "factor"), X2011.June.28 = structure(c(2L,     1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "B"), class = "factor"),     X2012.June.25 = structure(c(1L, 1L, 3L, 1L, 1L, 1L, 2L, 1L    ), .Label = c("0", "C", "D"), class = "factor"), X2013.June.21 = structure(c(1L,     1L, 1L, 3L, 2L, 4L, 1L, 1L), .Label = c("0", "B", "C", "Out"    ), class = "factor"), X2014.Jan.05 = structure(c(1L, 1L,     1L, 1L, 1L, 1L, 1L, 2L), .Label = c("0", "B"), class = "factor"),     X2014.July.27 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L    ), .Label = c("!
>   0", "Out"), class = "factor"), X2015.April.07 = c(0L,     0L, 0L, 0L, 0L, 1L, 0L, 0L)), .Names = c("tag", "X2010.May.27", "X2011.June.27", "X2011.June.28", "X2012.June.25", "X2013.June.21", "X2014.Jan.05", "X2014.July.27", "X2015.April.07"), class = "data.frame", row.names = c(NA,-8L))
> finalTable
> #How is it possible to get the finalTable as shown above?Any suggestions? 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Sat Dec 20 07:45:10 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 20 Dec 2014 07:45:10 +0100
Subject: [R] How to make Pivot table with two variables in R?
In-Reply-To: <COL130-W1624603BB61C49BE6BA5B7FA680@phx.gbl>
References: <COL130-W1624603BB61C49BE6BA5B7FA680@phx.gbl>
Message-ID: <FC4F4046-DFAD-47BF-894C-DD27BF989EBB@xs4all.nl>


> On 20-12-2014, at 05:45, Kristi Glover <kristi.glover at hotmail.com> wrote:
> 
> Hi R User, Would you suggest me on how I can build a pivot table using two variables? I want to put "text" in the table instead of value.  I have attached an example data and the type of table (FinalTable) I was looking for. I am looking for your suggestions. ThanksKG=====dat<-structure(list(tag = structure(c(1L, 1L, 1L, 2L, 3L, 4L, 5L, 6L, 6L, 7L, 7L, 8L), .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), time = structure(c(1L, 2L, 3L, 1L, 4L, 5L, 5L, 5L, 8L, 4L, 7L, 6L), .Label = c("2010-May 27", "2011-June 27", "2011-June 28", "2012-June 25", "2013-June 21", "2014-Jan 05", "2014-July 27", "2015-April 07"), class = "factor"),     states = structure(c(1L, 2L, 2L, 1L, 4L, 3L, 2L, 5L, 1L,     3L, 5L, 2L), .Label = c("A", "B", "C", "D", "Out"), class = "factor")), .Names = c("tag", "time", "states"), class = "data.frame", row.names = c(NA, -12L))
> dat###table(dat$tag,dat$time)# it gives value but I want the name of the states in the table instead of value.#For examplefinalTable<-structure(list(tag = structure(1:8, .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), X2010.May.27 = structure(c(2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "A"), class = "factor"),     X2011.June.27 = structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L    ), .Label = c("0", "B"), class = "factor"), X2011.June.28 = structure(c(2L,     1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "B"), class = "factor"),     X2012.June.25 = structure(c(1L, 1L, 3L, 1L, 1L, 1L, 2L, 1L    ), .Label = c("0", "C", "D"), class = "factor"), X2013.June.21 = structure(c(1L,     1L, 1L, 3L, 2L, 4L, 1L, 1L), .Label = c("0", "B", "C", "Out"    ), class = "factor"), X2014.Jan.05 = structure(c(1L, 1L,     1L, 1L, 1L, 1L, 1L, 2L), .Label = c("0", "B"), class = "factor"),     X2014.July.27 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L    ), .Label = c("!
> 0", "Out"), class = "factor"), X2015.April.07 = c(0L,     0L, 0L, 0L, 0L, 1L, 0L, 0L)), .Names = c("tag", "X2010.May.27", "X2011.June.27", "X2011.June.28", "X2012.June.25", "X2013.June.21", "X2014.Jan.05", "X2014.July.27", "X2015.April.07"), class = "data.frame", row.names = c(NA,-8L))
> finalTable
> #How is it possible to get the finalTable as shown above?Any suggestions? 		 	   		  

Since you used html for your mail, it is a complete mess and not usable.
You are requested to not post in HTML. See the posting guide.

Berend

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Sat Dec 20 15:41:39 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sat, 20 Dec 2014 08:41:39 -0600
Subject: [R] How to make Pivot table with two variables in R?
In-Reply-To: <COL130-W3442C98AA7639430B65BF5FA680@phx.gbl>
References: <COL130-W1624603BB61C49BE6BA5B7FA680@phx.gbl>
	<54951291.8050603@mail.usask.ca>
	<COL130-W3442C98AA7639430B65BF5FA680@phx.gbl>
Message-ID: <54958AA3.6010907@mail.usask.ca>

You are welcome, I am glad that I was able to help.

Chel Hee Lee, PhD
Biostatistician and Manager
Clinical Research Support Unit
College of Medicine
University of Saskatchewan


On 12/20/2014 03:53 AM, Kristi Glover wrote:
> Thank you Prof. Lee for your code. I am sorry that I noticed that I sent the email in Httml format and realized that it was almost impossible to read it. However, you gave an effort to help me. Now I changed the format.
> I really appreciated for your help. It seems the code you wrote works for me.
> Sincerely,
> KG
>
>
> ----------------------------------------
>> Date: Sat, 20 Dec 2014 00:09:21 -0600
>> From: chl948 at mail.usask.ca
>> Subject: Re: [R] How to make Pivot table with two variables in R?
>> To: kristi.glover at hotmail.com; r-help at r-project.org
>>
>>
>>> x <- dat
>>> x$time <- as.factor(as.Date(x$time, format="%Y-%B%d"))
>>> tmp <- split(x, x$tag)
>>> tmp1 <- do.call(rbind, lapply(tmp, function(x){
>> + tb <- table(x$time)
>> + idx <- which(tb>0)
>> + tb1 <- replace(tb, idx, as.character(x$states))
>> + }))
>>> print(tmp1, quote=FALSE)
>> 2010-05-27 2011-06-27 2011-06-28 2012-06-25 2013-06-21 2014-01-05
>> 2014-07-27
>> x1 A B B 0 0 0 0
>>
>> x2 A 0 0 0 0 0 0
>>
>> x3 0 0 0 D 0 0 0
>>
>> x4 0 0 0 0 C 0 0
>>
>> x5 0 0 0 0 B 0 0
>>
>> x6 0 0 0 0 Out 0 0
>>
>> x7 0 0 0 C 0 0 Out
>>
>> x8 0 0 0 0 0 B 0
>>
>> 2015-04-07
>> x1 0
>> x2 0
>> x3 0
>> x4 0
>> x5 0
>> x6 A
>> x7 0
>> x8 0
>>>
>>
>> Is this what you are looking for? I hope this helps.
>>
>> Chel Hee Lee
>>
>>
>> On 12/19/2014 10:45 PM, Kristi Glover wrote:
>>> Hi R User, Would you suggest me on how I can build a pivot table using two variables? I want to put "text" in the table instead of value. I have attached an example data and the type of table (FinalTable) I was looking for. I am looking for your suggestions. ThanksKG=====dat<-structure(list(tag = structure(c(1L, 1L, 1L, 2L, 3L, 4L, 5L, 6L, 6L, 7L, 7L, 8L), .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), time = structure(c(1L, 2L, 3L, 1L, 4L, 5L, 5L, 5L, 8L, 4L, 7L, 6L), .Label = c("2010-May 27", "2011-June 27", "2011-June 28", "2012-June 25", "2013-June 21", "2014-Jan 05", "2014-July 27", "2015-April 07"), class = "factor"), states = structure(c(1L, 2L, 2L, 1L, 4L, 3L, 2L, 5L, 1L, 3L, 5L, 2L), .Label = c("A", "B", "C", "D", "Out"), class = "factor")), .Names = c("tag", "time", "states"), class = "data.frame", row.names = c(NA, -12L))
>>> dat###table(dat$tag,dat$time)# it gives value but I want the name of the states in the table instead of value.#For examplefinalTable<-structure(list(tag = structure(1:8, .Label = c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8"), class = "factor"), X2010.May.27 = structure(c(2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "A"), class = "factor"), X2011.June.27 = structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L ), .Label = c("0", "B"), class = "factor"), X2011.June.28 = structure(c(2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("0", "B"), class = "factor"), X2012.June.25 = structure(c(1L, 1L, 3L, 1L, 1L, 1L, 2L, 1L ), .Label = c("0", "C", "D"), class = "factor"), X2013.June.21 = structure(c(1L, 1L, 1L, 3L, 2L, 4L, 1L, 1L), .Label = c("0", "B", "C", "Out" ), class = "factor"), X2014.Jan.05 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L), .Label = c("0", "B"), class = "factor"), X2014.July.27 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L ), .Label = c("!
>>> 0", "Out"), class = "factor"), X2015.April.07 = c(0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L)), .Names = c("tag", "X2010.May.27", "X2011.June.27", "X2011.June.28", "X2012.June.25", "X2013.June.21", "X2014.Jan.05", "X2014.July.27", "X2015.April.07"), class = "data.frame", row.names = c(NA,-8L))
>>> finalTable
>>> #How is it possible to get the finalTable as shown above?Any suggestions?
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>   		 	   		
>


From ragia11 at hotmail.com  Sat Dec 20 16:58:19 2014
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Sat, 20 Dec 2014 17:58:19 +0200
Subject: [R] list of lists, is this element empty
In-Reply-To: <mailman.0.1418986801.25142.r-help@r-project.org>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
Message-ID: <DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>

Hello,
Kindly I have a list of lists as follow
x
[[1]]
[1] 7

[[2]]
[1] 3 4 5

as showen x[[3]] does not have a value and it has NULL, how can I check on this 
how to test if x[[3]] is empty.

thanks in advance
Ragia
 		 	   		  
	[[alternative HTML version deleted]]


From btupper at bigelow.org  Sat Dec 20 17:18:29 2014
From: btupper at bigelow.org (Ben Tupper)
Date: Sat, 20 Dec 2014 11:18:29 -0500
Subject: [R] list of lists, is this element empty
In-Reply-To: <DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
Message-ID: <B9883E11-F364-40B0-B0D4-08FACA018E1F@bigelow.org>

Hi,


On Dec 20, 2014, at 10:58 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:

> Hello,
> Kindly I have a list of lists as follow
> x
> [[1]]
> [1] 7
> 
> [[2]]
> [1] 3 4 5
> 
> as showen x[[3]] does not have a value and it has NULL, how can I check on this 
> how to test if x[[3]] is empty.
> 

In general you can us is.null()

x <- list(7, 3:5, NULL, "A")

> is.null(x[[3]])
[1] TRUE

but be aware that trying access an element by index that is greater than the length of the list will cause you issues.

> is.null(x[[10]])
Error in x[[10]] : subscript out of bounds

You can make your own function to test for the existence of an element and if it is NULL.  Note that the function isn't complete in the sense that it doesn't test if you provide an negative index, that x is not a list, etc.  You can add all of those tests in.

is_null <- function(x, index){
	( index[1] > length(x) ) || is.null(x[[index[1]]])
}

> is_null(x, 1)
[1] FALSE
> is_null(x, 3)
[1] TRUE
> is_null(x, 10)
[1] TRUE


There a lot of info on index at 

> ?`[`

Does that answer your question?

Cheers,
Ben

> thanks in advance
> Ragia
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From ruipbarradas at sapo.pt  Sat Dec 20 17:20:26 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 20 Dec 2014 16:20:26 +0000
Subject: [R] list of lists, is this element empty
In-Reply-To: <DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
Message-ID: <5495A1CA.3030703@sapo.pt>

Hello,

Your list seems to have only 2 elements. You can check this with

length(x)

Or you can try

lapply(x, is.null)

Hope this helps,

Rui Barradas

Em 20-12-2014 15:58, Ragia Ibrahim escreveu:
> Hello,
> Kindly I have a list of lists as follow
> x
> [[1]]
> [1] 7
>
> [[2]]
> [1] 3 4 5
>
> as showen x[[3]] does not have a value and it has NULL, how can I check on this
> how to test if x[[3]] is empty.
>
> thanks in advance
> Ragia
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Sat Dec 20 19:57:53 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 20 Dec 2014 13:57:53 -0500
Subject: [R] list of lists, is this element empty
In-Reply-To: <5495A1CA.3030703@sapo.pt>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<5495A1CA.3030703@sapo.pt>
Message-ID: <8DBAC4FF-7A3E-4E2E-A347-C820C516CAFB@utoronto.ca>

This can be tricky, because depending on what the missing object is, you can get either NULL, NA, or an error. Moreover is.na() behaves differently when evaluated on its own, or as the condition of an if() statement. Here is a function that may make life easier. The goal is NOT to have to pass extra arguments. 

- I use try() and return FALSE if the evaluation returns an error. 
  This applies to objects that are not found, incorrect syntax etc.
- List elements that don't exist are NULL and return FALSE.
- If any elements are NA, return FALSE. This handles out-of-bounds
  elements AND out-of-bounds slices on vectors. But it would also
  trip on valid vectors that contain an NA. I can't think of a good
  way to distinguish these two cases right now. The "best" way for
  this depends on the context.

I think I am handling the most obvious special cases - though I do expect this can be improved.


is.valid <- function(x, 
                     na.ignore = FALSE, 
                     null.ignore=FALSE) {

    # errors are always FALSE
    if (class(try(x, silent=TRUE)) == "try-error") return(FALSE)		

    # NULL is FALSE except if ignored
    if (is.null(x)) {
        if (!null.ignore) return(FALSE)
        return(TRUE)
    }
	
    # If all elments are NA, return FALSE except if ignored; 
    if (any(is.na(x))) {
        if (!na.ignore) return(FALSE)
        return(TRUE)
    }

    # Everything else is TRUE
    return(TRUE)
}



# Test cases
is.valid(1)             # TRUE: valid numeric constant
is.valid(FALSE)         # TRUE: valid boolean constant 
is.valid(nonSuch)       # FALSE: object doesn't exist

x <- 1:5; 
is.valid(x)             # TRUE: existing variable
is.valid(x[4])          # TRUE: vector element
is.valid(x[8])          # FALSE: out of bounds: NA
is.valid(x[5:6])        # FALSE: partially out of bounds: (5, NA)

is.valid(x[8], na.ignore=TRUE)  # TRUE

x[3] <- NA
is.valid(x)             # FALSE: no element can be NA
is.valid(x, na.ignore=TRUE)  # TRUE


m <- matrix(1:9,nrow=3, ncol=3)
is.valid(m[2,2])        # TRUE
is.valid(m[2,4])        # FALSE: subscript out of bounds
is.valid(m[2,2,2])      # FALSE: incorrect n of dimensions

l <- list(first=7, letters, NULL)
is.valid(l[["first"]])  # TRUE: existing list elements
is.valid(l[[4]])        # FALSE: list element does not exist
is.valid(l[[2]][27])    # FALSE: out of bounds on existing element      
is.valid(l$first)       # TRUE: 
is.valid(l$second)      # FALSE: non-existent element: NULL
is.valid(l$second, null.ignore=TRUE)  # TRUE


Cheers,
B.



On Dec 20, 2014, at 11:20 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> Your list seems to have only 2 elements. You can check this with
> 
> length(x)
> 
> Or you can try
> 
> lapply(x, is.null)
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 20-12-2014 15:58, Ragia Ibrahim escreveu:
>> Hello,
>> Kindly I have a list of lists as follow
>> x
>> [[1]]
>> [1] 7
>> 
>> [[2]]
>> [1] 3 4 5
>> 
>> as showen x[[3]] does not have a value and it has NULL, how can I check on this
>> how to test if x[[3]] is empty.
>> 
>> thanks in advance
>> Ragia
>>  		 	   		
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Dec 20 20:45:26 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 20 Dec 2014 11:45:26 -0800
Subject: [R] list of lists, is this element empty
In-Reply-To: <8DBAC4FF-7A3E-4E2E-A347-C820C516CAFB@utoronto.ca>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
	<5495A1CA.3030703@sapo.pt>
	<8DBAC4FF-7A3E-4E2E-A347-C820C516CAFB@utoronto.ca>
Message-ID: <CACk-te1vbFKcygCzkA1Fiyq=50PYmKZ4m13BUhOEKE+Zx3t4Tw@mail.gmail.com>

Boris et. al:

Indeed, corner cases are a bear, which is why it is incumbent on any
OP to precisely define what they mean by, say, "missing",
"null","empty", etc.

Here is an evil example to illustrate the sorts of nastiness that can occur:

> z <- list(a=NULL, b=list(), c=NA)

> with(z,{
+ c(identical(a,b),
+ identical(a,c),
+ identical(b,c)
+ )
+ })
[1] FALSE FALSE FALSE

## OK, none of these three are "the same" in the sense of identical().
But ...

> outer(z,z,identical)
Error in outer(z, z, identical) :
  dims [product 9] do not match the length of object [1]

## outer gets completely flummoxed, as it should!

> expand.grid(z,z)
  Var1 Var2
1 NULL NULL
2 NULL NULL
3   NA NULL
4 NULL NULL
5 NULL NULL
6   NA NULL
7 NULL   NA
8 NULL   NA
9   NA   NA

## and expand.grid gets confused, as it probably should.

:-)

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Dec 20, 2014 at 10:57 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> This can be tricky, because depending on what the missing object is, you can get either NULL, NA, or an error. Moreover is.na() behaves differently when evaluated on its own, or as the condition of an if() statement. Here is a function that may make life easier. The goal is NOT to have to pass extra arguments.
>
> - I use try() and return FALSE if the evaluation returns an error.
>   This applies to objects that are not found, incorrect syntax etc.
> - List elements that don't exist are NULL and return FALSE.
> - If any elements are NA, return FALSE. This handles out-of-bounds
>   elements AND out-of-bounds slices on vectors. But it would also
>   trip on valid vectors that contain an NA. I can't think of a good
>   way to distinguish these two cases right now. The "best" way for
>   this depends on the context.
>
> I think I am handling the most obvious special cases - though I do expect this can be improved.
>
>
> is.valid <- function(x,
>                      na.ignore = FALSE,
>                      null.ignore=FALSE) {
>
>     # errors are always FALSE
>     if (class(try(x, silent=TRUE)) == "try-error") return(FALSE)
>
>     # NULL is FALSE except if ignored
>     if (is.null(x)) {
>         if (!null.ignore) return(FALSE)
>         return(TRUE)
>     }
>
>     # If all elments are NA, return FALSE except if ignored;
>     if (any(is.na(x))) {
>         if (!na.ignore) return(FALSE)
>         return(TRUE)
>     }
>
>     # Everything else is TRUE
>     return(TRUE)
> }
>
>
>
> # Test cases
> is.valid(1)             # TRUE: valid numeric constant
> is.valid(FALSE)         # TRUE: valid boolean constant
> is.valid(nonSuch)       # FALSE: object doesn't exist
>
> x <- 1:5;
> is.valid(x)             # TRUE: existing variable
> is.valid(x[4])          # TRUE: vector element
> is.valid(x[8])          # FALSE: out of bounds: NA
> is.valid(x[5:6])        # FALSE: partially out of bounds: (5, NA)
>
> is.valid(x[8], na.ignore=TRUE)  # TRUE
>
> x[3] <- NA
> is.valid(x)             # FALSE: no element can be NA
> is.valid(x, na.ignore=TRUE)  # TRUE
>
>
> m <- matrix(1:9,nrow=3, ncol=3)
> is.valid(m[2,2])        # TRUE
> is.valid(m[2,4])        # FALSE: subscript out of bounds
> is.valid(m[2,2,2])      # FALSE: incorrect n of dimensions
>
> l <- list(first=7, letters, NULL)
> is.valid(l[["first"]])  # TRUE: existing list elements
> is.valid(l[[4]])        # FALSE: list element does not exist
> is.valid(l[[2]][27])    # FALSE: out of bounds on existing element
> is.valid(l$first)       # TRUE:
> is.valid(l$second)      # FALSE: non-existent element: NULL
> is.valid(l$second, null.ignore=TRUE)  # TRUE
>
>
> Cheers,
> B.
>
>
>
> On Dec 20, 2014, at 11:20 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Your list seems to have only 2 elements. You can check this with
>>
>> length(x)
>>
>> Or you can try
>>
>> lapply(x, is.null)
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 20-12-2014 15:58, Ragia Ibrahim escreveu:
>>> Hello,
>>> Kindly I have a list of lists as follow
>>> x
>>> [[1]]
>>> [1] 7
>>>
>>> [[2]]
>>> [1] 3 4 5
>>>
>>> as showen x[[3]] does not have a value and it has NULL, how can I check on this
>>> how to test if x[[3]] is empty.
>>>
>>> thanks in advance
>>> Ragia
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Dec 20 21:29:38 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 20 Dec 2014 15:29:38 -0500
Subject: [R] list of lists, is this element empty
In-Reply-To: <8DBAC4FF-7A3E-4E2E-A347-C820C516CAFB@utoronto.ca>
References: <mailman.0.1418986801.25142.r-help@r-project.org>	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>	<5495A1CA.3030703@sapo.pt>
	<8DBAC4FF-7A3E-4E2E-A347-C820C516CAFB@utoronto.ca>
Message-ID: <5495DC32.90806@gmail.com>

This may be out of context, but on the face of it, this claim is wrong:

On 20/12/2014, 1:57 PM, Boris Steipe wrote:
"Moreover is.na() behaves differently when evaluated on its own, or as
the condition of an if() statement."

The conditions in an if() statement are not evaluated in special
conditions at all.  The only way you'll get a different value is if the
argument to is.na() does tricky stuff like looking at the evaluation stack.

Duncan Murdoch


From boris.steipe at utoronto.ca  Sat Dec 20 21:41:14 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 20 Dec 2014 15:41:14 -0500
Subject: [R] list of lists, is this element empty
In-Reply-To: <5495DC32.90806@gmail.com>
References: <mailman.0.1418986801.25142.r-help@r-project.org>	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>	<5495A1CA.3030703@sapo.pt>
	<8DBAC4FF-7A3E-4E2E-A347-C820C516CAFB@utoronto.ca>
	<5495DC32.90806@gmail.com>
Message-ID: <FB1C51C3-7122-45B9-B38E-6EA637988ED7@utoronto.ca>

Thanks. This is what I was referring to:

x <- rep(NA, 3)
is.na(x)
[1] TRUE TRUE TRUE

if (is.na(x)) {print("True")}
[1] "True"
Warning message:
In if (is.na(x)) { :
  the condition has length > 1 and only the first element will be used

You are of course right - the warning is generated by if(), not by is.na() and the reason for the warning is that is.na() returns a vector if applied to a vector. I should have been more clear.

Cheers,
B.



On Dec 20, 2014, at 3:29 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> This may be out of context, but on the face of it, this claim is wrong:
> 
> On 20/12/2014, 1:57 PM, Boris Steipe wrote:
> "Moreover is.na() behaves differently when evaluated on its own, or as
> the condition of an if() statement."
> 
> The conditions in an if() statement are not evaluated in special
> conditions at all.  The only way you'll get a different value is if the
> argument to is.na() does tricky stuff like looking at the evaluation stack.
> 
> Duncan Murdoch


From jane.synnergren at his.se  Fri Dec 19 22:56:48 2014
From: jane.synnergren at his.se (Jane Synnergren)
Date: Fri, 19 Dec 2014 21:56:48 +0000
Subject: [R] how update to latest version of R on mac
Message-ID: <D0BA5DA8.57B1F%jane.synnergren@his.se>

Hi,
I get following error when trying to update the affy package to latest
version.

Error: cannot remove prior installation of package ?affy?

I think it is because affy requires R 3.1.1 and I have 3.0.2

I try to find a guide how I do to upgrade from 3.0.2 to latest version on
mac, but cannot find any good description. Can anyone guide me?

Do I just download R for mac (R-3.1.2-snowleopard.pkg) from
<http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg> and
dubbelclick?

What will happen with all installed packages?
I have OS X Lion 10.7.5
Which version number is stable and reliable?

I also need a guide of how to update to latest version of  bioconductor on
mac. 

Descriptions for windows is available everywhere.

/Jane


---------------------------------------------------------------------------
----
Jane Synnergren, PhD
Systems Biology Research Center
School of Bioscience
University of Sk?vde
Sweden

Contact:
email: jane.synnergren at his.se
mobile: +46 (0)708 806495
webpage: his.se/synj

Postal Address: 			Visiting address:

Box 408 				Kanikegr?nd 3A
541 28 Sk?vde			Sk?vde


From bmarwick at uw.edu  Fri Dec 19 23:48:32 2014
From: bmarwick at uw.edu (Ben Marwick)
Date: Fri, 19 Dec 2014 14:48:32 -0800
Subject: [R] where are the NEWS for R <3.0.0?
Message-ID: <5494AB40.6080708@uw.edu>

I'm looking for the NEWS files for versions of R before 3.0.0, does 
anyone know where they are? I'm interested in getting the names of 
people who have been acknowledged when changes are made to R.

At the bottom of http://cran.r-project.org/src/base/NEWS.html it says

"Older news can be found in text format in files NEWS.0, NEWS.1 and 
NEWS.2 in the ?doc? directory. News in HTML format for R versions from 
2.10.0 to 2.15.3 is in NEWS.2.html."

The text includes these URLs:

http://cran.r-project.org/src/NEWS.0
http://cran.r-project.org/src/NEWS.1
http://cran.r-project.org/src/NEWS.2
http://cran.r-project.org/src/base/NEWS.2.html

All of these go to 404s, and when src is replaced by doc, as suggested 
by the text, they also go to 404s. There are no NEWS files in here 
either: http://cran.r-project.org/doc/html/ So there are a bunch of 
broken links here.

I found a bunch of PDFs listed here http://cran.r-project.org/doc/Rnews/ 
dating from 2008-2001. Are these only source of the earlier NEWS files?

They're less convenient because the NEWS section is not a single plain 
text file, but a section of the PDF document. I'd be most grateful to 
know where I can find html or txt files of the earlier NEWS files. If 
the PDFs are all there are, it would be good to know that for sure.

The other method I was considering was scraping bugzilla for names of 
people who submitted bugs that resulted in a fix 
(https://bugs.r-project.org/bugzilla3/buglist.cgi?product=R&query_format=advanced&resolution=FIXED). 
But text mining the NEWS files would be quicker for a first approximation.

thanks,

Ben

-- 
Ben Marwick, Assistant Professor, Department of Anthropology
Denny Hall M32, Box 353100, University of Washington
Seattle, WA 98195-3100 USA

t. (+1) 206.552.9450   e. bmarwick at uw.edu
f. (+1) 206.543.3285   w. http://faculty.washington.edu/bmarwick/


From esra_ulasan at icloud.com  Sat Dec 20 04:21:15 2014
From: esra_ulasan at icloud.com (Esra Ulasan)
Date: Fri, 19 Dec 2014 22:21:15 -0500
Subject: [R] short-sale constraint with nonpositive-definite matrix in
 portfolio optimization
Message-ID: <3691F2F5-3FD3-477E-AD31-B5586EA5A578@icloud.com>

Hello,

I want to ask about portfolio optimization in R. I have a nonpositive-definite matrix. I have handled with the singularity. Unfortunately, quadprog etc. optimization packages fail to solve the optimization problem under the constraints. Because these packages takes the covariance matrix as an input. But I have inverted matrix and I want to use it as an input under the non-negativity constraint (short sale prohibited). It is hard to solve with lagrange because of non-negativity constraint. Which method should I use? If you help me, I would be very happy..

Thank you.

From esra_ulasan at icloud.com  Sat Dec 20 05:26:55 2014
From: esra_ulasan at icloud.com (Esra Ulasan)
Date: Fri, 19 Dec 2014 23:26:55 -0500
Subject: [R] non negativity constraints if else function
Message-ID: <8C5670DE-7B0C-415B-A03F-E50F4BA28A63@icloud.com>

Hello,

I have tried the solve the non-negativity constraint "if else function" in R. But I have done something wrong because it still gives the same solution. I want that, if weight element is negative set it to zero, else recalculate the weights again. These are the codes:

 for(i in 1:M){ w[,i] = f+r[i]*g              #portfolio weights 
    for(i in 1:M){
      if (w <0){w=0}else{w=w}
    }                     
  } 
If you help me I would be happy
Thank you
	[[alternative HTML version deleted]]


From rlderickson at gmail.com  Sat Dec 20 16:29:00 2014
From: rlderickson at gmail.com (Ryan Derickson)
Date: Sat, 20 Dec 2014 10:29:00 -0500
Subject: [R] Specifying plot area in dotchart2
Message-ID: <CALSCBYr6agy+27J5kaDFVZRw0+3CrwHSFMwKrVrutRB-3S0MOQ@mail.gmail.com>

Hello,

I'm producing multiple dotcharts and I want each plotting area (the area
containing the dots only- not the labels) to be the same width. Currently,
the width of the area depends on the length of the labels. I've tried
different margin arguments but they change the parameter of the whole plot
(dots + labels) rather than just the dot area.

A reproducible example is below; I want the dot area to be the same
physical width across charts regardless of the label width. Any suggestions
would be greatly appreciated!

Ryan Derickson


library(Hmisc)
pdf("dotchart2 demo.pdf")

# This plot width is wider

par(omi=c(0, 2, 0, 0), mar=c(2,4,1,1))

num<-rnorm(40, 0, 1)
lab<-paste(rep(letters[1:20],2),rep(letters[1:20],2),rep(letters[1:20],2),rep(letters[1:20],2)

 ,rep(letters[1:20],2),rep(letters[1:20],2),rep(letters[1:20],2),rep(letters[1:20],2),
sep="")

dat<-data.frame(num, lab)
dat<-dat[order(num),]

dotchart2(dat$num, label=dat$lab, xlim=c(-3,3))


# This plot width is narrower

par(omi=c(0, 2, 0, 0), mar=c(2,4,1,1))

num<-rnorm(40, 0, 1)
lab<-paste(rep(letters[1:20],2),rep(letters[1:20],2),rep(letters[1:20],2),rep(letters[1:20],2),
sep="")

dat<-data.frame(num, lab)
dat<-dat[order(num),]

dotchart2(dat$num, label=dat$lab, xlim=c(-3,3))

dev.off()

	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Sat Dec 20 21:36:57 2014
From: varinsacha at yahoo.fr (varin sacha)
Date: Sat, 20 Dec 2014 20:36:57 +0000 (UTC)
Subject: [R] Bca confidence intervals for Pearson coefficient, thanks.
Message-ID: <612077657.1191799.1419107817784.JavaMail.yahoo@jws11119.mail.ir2.yahoo.com>

Hi to everyone,
I am trying to calculate the Bca bootstrap confidence intervals for the Pearson coefficient.
x=Dataset$math.testy=Dataset$geo.testcor(x,y,method="pearson")[1] 0.6983799
boot.ci(cor, conf=0.95, type=bca)Erreur dans boot.out$t0 : objet de type 'closure' non indi?able

I have tried as well to calculate the Pearson coefficient using bootstrap and then to calculate the Bca bootstrap CIs of the Pearson. It doesn't work either.?
boot(data = cbind(x, y), statistic = cor, R = 200)

ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = cbind(x, y), statistic = cor, R = 200)


Bootstrap Statistics :
      original    bias    std. error
t1* -0.6243713 0.6295142   0.2506267
t2* -0.1366533 0.1565392   0.2579134
> boot.ci(cor, conf=0.95, type=bca)
Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
Many thanks to tell me how to correct my R script to get the Bca CIs for my Pearson coefficient. Best regards, looking forward to reading you,
SV

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Sun Dec 21 02:06:26 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Sat, 20 Dec 2014 18:06:26 -0700
Subject: [R] how update to latest version of R on mac
In-Reply-To: <D0BA5DA8.57B1F%jane.synnergren@his.se>
References: <D0BA5DA8.57B1F%jane.synnergren@his.se>
Message-ID: <CAGxgkWidB0=+odRRfgqV4aDjYMF_kgSds2DggwuhdqF=ge=P=w@mail.gmail.com>

Jane,

It's possible, since you are using Mac OS X Lion (10.7.5), you need the R
version for that, which can be found here:
http://cran.r-project.org/bin/macosx/old/R-3.1.1-mavericks.pkg

Cheers!
Tom

On Fri, Dec 19, 2014 at 2:56 PM, Jane Synnergren <jane.synnergren at his.se>
wrote:
>
> Hi,
> I get following error when trying to update the affy package to latest
> version.
>
> Error: cannot remove prior installation of package ?affy?
>
> I think it is because affy requires R 3.1.1 and I have 3.0.2
>
> I try to find a guide how I do to upgrade from 3.0.2 to latest version on
> mac, but cannot find any good description. Can anyone guide me?
>
> Do I just download R for mac (R-3.1.2-snowleopard.pkg) from
> <http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg> and
> dubbelclick?
>
> What will happen with all installed packages?
> I have OS X Lion 10.7.5
> Which version number is stable and reliable?
>
> I also need a guide of how to update to latest version of  bioconductor on
> mac.
>
> Descriptions for windows is available everywhere.
>
> /Jane
>
>
> ---------------------------------------------------------------------------
> ----
> Jane Synnergren, PhD
> Systems Biology Research Center
> School of Bioscience
> University of Sk?vde
> Sweden
>
> Contact:
> email: jane.synnergren at his.se
> mobile: +46 (0)708 806495
> webpage: his.se/synj
>
> Postal Address:                         Visiting address:
>
> Box 408                                 Kanikegr?nd 3A
> 541 28 Sk?vde                   Sk?vde
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Sun Dec 21 02:08:54 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sun, 21 Dec 2014 12:08:54 +1100
Subject: [R] non negativity constraints if else function
In-Reply-To: <8C5670DE-7B0C-415B-A03F-E50F4BA28A63@icloud.com>
References: <8C5670DE-7B0C-415B-A03F-E50F4BA28A63@icloud.com>
Message-ID: <CAKL8G3H0=Wvo9jwn=kdtnjoYK38jjrvnwN7zpzfnFsHJEXhDVw@mail.gmail.com>

What about

ifelse(w < 0, 0, w)

See ?ifelse for more information.

Best,
Jorge.-


On Sat, Dec 20, 2014 at 3:26 PM, Esra Ulasan <esra_ulasan at icloud.com> wrote:

> Hello,
>
> I have tried the solve the non-negativity constraint "if else function" in
> R. But I have done something wrong because it still gives the same
> solution. I want that, if weight element is negative set it to zero, else
> recalculate the weights again. These are the codes:
>
>  for(i in 1:M){ w[,i] = f+r[i]*g              #portfolio weights
>     for(i in 1:M){
>       if (w <0){w=0}else{w=w}
>     }
>   }
> If you help me I would be happy
> Thank you
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From xiaoheyiyh at yahoo.com  Sun Dec 21 02:14:25 2014
From: xiaoheyiyh at yahoo.com (heyi xiao)
Date: Sat, 20 Dec 2014 17:14:25 -0800
Subject: [R] Add encoded special characters (greek characters) as text
	to plot
In-Reply-To: <54933C89.6060808@mail.usask.ca>
Message-ID: <1419124465.58346.YahooMailBasic@web162602.mail.bf1.yahoo.com>

Thank you all for the input. That helps, although I haven?t get the exact solution..

--------------------------------------------
On Thu, 12/18/14, Chel Hee Lee <chl948 at mail.usask.ca> wrote:

 Subject: Re: [R] Add encoded special characters (greek characters) as text to plot
 To: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>, "heyi xiao" <xiaoheyiyh at yahoo.com>, "heyi xiao via R-help" <r-help at r-project.org>
 Date: Thursday, December 18, 2014, 3:43 PM

 Why don't you try
 this approach if you cannot use 'expression()'?

  > x <-
 c("alpha", "beta", "gamma",
 "delta")
  > plot(0,
 type="n")
  > for(i in
 1:length(x)) text(x=1, y=i/10, labels=parse(text=x[i]))

 Please see the output in R.?
 Is this what you are looking for?? I hope 
 this helps.? I would also appreciate it if you
 would provide 
 reproducible examples next
 time.

 Chel Hee Lee

 On 12/18/2014 11:48 AM, Jeff
 Newmiller wrote:
 > Read the posting
 guide. The solution is likely to depend on your operating
 system and graphics devices.
 >
 ---------------------------------------------------------------------------
 > Jeff Newmiller? ? ? ? ? ? ? ? ?
 ? ? ? The? ???.....? ?
 ???.....? Go Live...
 >
 DCN:<jdnewmil at dcn.davis.ca.us>?
 ? ? ? Basics: ##.#.? ? ???##.#.? Live
 Go...
 >? ? ? ? ? ? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? Live:???OO#.. Dead:
 OO#..? Playing
 > Research Engineer
 (Solar/Batteries? ? ? ? ? ? O.O#.? ?
 ???#.O#.? with
 >
 /Software/Embedded Controllers)? ? ? ? ? ?
 ???.OO#.? ? ???.OO#.? rocks...1k
 >
 ---------------------------------------------------------------------------
 > Sent from my phone. Please excuse my
 brevity.
 >
 > On
 December 18, 2014 8:59:47 AM PST, heyi xiao via R-help
 <r-help at r-project.org>
 wrote:
 >> anybody has any hint on
 this?
 >>
 >>
 --------------------------------------------
 >>
 >>
 >> Subject: Add encoded special
 characters (greek characters) as text to
 >> plot
 >> To: r-help at r-project.org
 >> Date: Wednesday, December 17, 2014,
 9:25 PM
 >>
 >>
 Dear all,
 >> I read my a character
 matrix from a text file. Some of them
 >> have greek characters. To reserve the
 special characters, I
 >> used
 stringsAsFactors=F using read.table. I notice that I
 >> can?t print these character string
 using print(), but I
 >> can use
 cat():
 >>>
 print("LC\246\302")
 >> [1]
 "LC\246\302"
 >>>
 cat("LC\246\302\n")
 >>
 LC?
 >>
 >> The
 problem is when I add text to my output plot like:
 >> text(x,y,
 labels="LC\246\302")
 >>
 >> I got "LC.. " on my plot.
 Obviously text function doesn?t
 >>
 know what?s "\246\302". I google that encoding,
 and
 >> can?t find exact what that
 is. It doesn?t look like
 >> ascii or
 Unicode. Anybody knows what that is?
 >> Note that I can?t use expression()
 method to pass these
 >> special
 characters because these are read from a text file,
 >> I just can?t include greek
 characters manually that way.
 >> Is
 there a way that I can output these strings with special
 >> characters automatically?
 >> Thank you!
 >>
 Heyi
 >>
 >>
 ______________________________________________
 >> R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide
 >> http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal,
 self-contained, reproducible code.
 >
 >
 ______________________________________________
 > R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal,
 self-contained, reproducible code.
 >


From jdnewmil at dcn.davis.CA.us  Sun Dec 21 02:41:59 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 20 Dec 2014 17:41:59 -0800
Subject: [R] non negativity constraints if else function
In-Reply-To: <8C5670DE-7B0C-415B-A03F-E50F4BA28A63@icloud.com>
References: <8C5670DE-7B0C-415B-A03F-E50F4BA28A63@icloud.com>
Message-ID: <FF7439AF-452C-4CE6-A4D2-CB27F4F53EC2@dcn.davis.CA.us>

"if weight element is negative set it to zero, else recalculate the weights again"... this seems like the only way out of this loop is to calculate negative weights... and since you set them to zero at that point they will all be zero when you are done. Somehow I doubt that is what you intended to say.

On the other hand, if you had provided us with example input data and result data then we would not have to guess what you want.

I suspect that loops are not really what you want at all... but I could be wrong.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 19, 2014 8:26:55 PM PST, Esra Ulasan <esra_ulasan at icloud.com> wrote:
>Hello,
>
>I have tried the solve the non-negativity constraint "if else function"
>in R. But I have done something wrong because it still gives the same
>solution. I want that, if weight element is negative set it to zero,
>else recalculate the weights again. These are the codes:
>
> for(i in 1:M){ w[,i] = f+r[i]*g              #portfolio weights 
>    for(i in 1:M){
>      if (w <0){w=0}else{w=w}
>    }                     
>  } 
>If you help me I would be happy
>Thank you
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Dec 21 02:53:34 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 20 Dec 2014 17:53:34 -0800
Subject: [R] how update to latest version of R on mac
In-Reply-To: <D0BA5DA8.57B1F%jane.synnergren@his.se>
References: <D0BA5DA8.57B1F%jane.synnergren@his.se>
Message-ID: <1BD33CC1-8E54-48E5-BF96-EAA5A01E8FA5@dcn.davis.CA.us>

You might find help more tuned to your environment by also participating on the R-sig-mac mailing list. As always start by reading the archives and posting guide, as well as using a search engine.

Note that bioconductor has its own website and support forums.

This list is still a good place for general questions about R (yes, read the Posting Guide).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 19, 2014 1:56:48 PM PST, Jane Synnergren <jane.synnergren at his.se> wrote:
>Hi,
>I get following error when trying to update the affy package to latest
>version.
>
>Error: cannot remove prior installation of package ?affy?
>
>I think it is because affy requires R 3.1.1 and I have 3.0.2
>
>I try to find a guide how I do to upgrade from 3.0.2 to latest version
>on
>mac, but cannot find any good description. Can anyone guide me?
>
>Do I just download R for mac (R-3.1.2-snowleopard.pkg) from
><http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg>
>and
>dubbelclick?
>
>What will happen with all installed packages?
>I have OS X Lion 10.7.5
>Which version number is stable and reliable?
>
>I also need a guide of how to update to latest version of  bioconductor
>on
>mac. 
>
>Descriptions for windows is available everywhere.
>
>/Jane
>
>
>---------------------------------------------------------------------------
>----
>Jane Synnergren, PhD
>Systems Biology Research Center
>School of Bioscience
>University of Sk?vde
>Sweden
>
>Contact:
>email: jane.synnergren at his.se
>mobile: +46 (0)708 806495
>webpage: his.se/synj
>
>Postal Address: 			Visiting address:
>
>Box 408 				Kanikegr?nd 3A
>541 28 Sk?vde			Sk?vde
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Dec 21 02:58:19 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 20 Dec 2014 17:58:19 -0800
Subject: [R] Add encoded special characters (greek characters) as text
	to plot
In-Reply-To: <1419124465.58346.YahooMailBasic@web162602.mail.bf1.yahoo.com>
References: <1419124465.58346.YahooMailBasic@web162602.mail.bf1.yahoo.com>
Message-ID: <2F64E8E9-98EA-401D-B85C-65860CA99251@dcn.davis.CA.us>

You are welcome, but you have not yet followed the Posting Guide instructions, so you may not have prompted someone familiar with your situation to respond yet.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 20, 2014 5:14:25 PM PST, heyi xiao <xiaoheyiyh at yahoo.com> wrote:
>Thank you all for the input. That helps, although I haven?t get the
>exact solution..
>
>--------------------------------------------
>On Thu, 12/18/14, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>
>Subject: Re: [R] Add encoded special characters (greek characters) as
>text to plot
>To: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>, "heyi xiao"
><xiaoheyiyh at yahoo.com>, "heyi xiao via R-help" <r-help at r-project.org>
> Date: Thursday, December 18, 2014, 3:43 PM
> 
> Why don't you try
> this approach if you cannot use 'expression()'?
> 
>  > x <-
> c("alpha", "beta", "gamma",
> "delta")
>  > plot(0,
> type="n")
>  > for(i in
> 1:length(x)) text(x=1, y=i/10, labels=parse(text=x[i]))
> 
> Please see the output in R.?
> Is this what you are looking for?? I hope 
> this helps.? I would also appreciate it if you
> would provide 
> reproducible examples next
> time.
> 
> Chel Hee Lee
> 
> On 12/18/2014 11:48 AM, Jeff
> Newmiller wrote:
> > Read the posting
> guide. The solution is likely to depend on your operating
> system and graphics devices.
> >
>---------------------------------------------------------------------------
> > Jeff Newmiller? ? ? ? ? ? ? ? ?
> ? ? ? The? ???.....? ?
> ???.....? Go Live...
> >
> DCN:<jdnewmil at dcn.davis.ca.us>?
> ? ? ? Basics: ##.#.? ? ???##.#.? Live
> Go...
> >? ? ? ? ? ? ? ? ? ? ?
> ? ? ? ? ? ? ? ? ? Live:???OO#.. Dead:
> OO#..? Playing
> > Research Engineer
> (Solar/Batteries? ? ? ? ? ? O.O#.? ?
> ???#.O#.? with
> >
> /Software/Embedded Controllers)? ? ? ? ? ?
> ???.OO#.? ? ???.OO#.? rocks...1k
> >
>---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my
> brevity.
> >
> > On
> December 18, 2014 8:59:47 AM PST, heyi xiao via R-help
> <r-help at r-project.org>
> wrote:
> >> anybody has any hint on
> this?
> >>
> >>
> --------------------------------------------
> >>
> >>
> >> Subject: Add encoded special
> characters (greek characters) as text to
> >> plot
> >> To: r-help at r-project.org
> >> Date: Wednesday, December 17, 2014,
> 9:25 PM
> >>
> >>
> Dear all,
> >> I read my a character
> matrix from a text file. Some of them
> >> have greek characters. To reserve the
> special characters, I
> >> used
> stringsAsFactors=F using read.table. I notice that I
> >> can?t print these character string
> using print(), but I
> >> can use
> cat():
> >>>
> print("LC\246\302")
> >> [1]
> "LC\246\302"
> >>>
> cat("LC\246\302\n")
> >>
> LC?
> >>
> >> The
> problem is when I add text to my output plot like:
> >> text(x,y,
> labels="LC\246\302")
> >>
> >> I got "LC.. " on my plot.
> Obviously text function doesn?t
> >>
> know what?s "\246\302". I google that encoding,
> and
> >> can?t find exact what that
> is. It doesn?t look like
> >> ascii or
> Unicode. Anybody knows what that is?
> >> Note that I can?t use expression()
> method to pass these
> >> special
> characters because these are read from a text file,
> >> I just can?t include greek
> characters manually that way.
> >> Is
> there a way that I can output these strings with special
> >> characters automatically?
> >> Thank you!
> >>
> Heyi
> >>
> >>
> ______________________________________________
> >> R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal,
> self-contained, reproducible code.
> >
> >
> ______________________________________________
> > R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
> > and provide commented, minimal,
> self-contained, reproducible code.
> >


From murdoch.duncan at gmail.com  Sun Dec 21 03:22:23 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 20 Dec 2014 21:22:23 -0500
Subject: [R] where are the NEWS for R <3.0.0?
In-Reply-To: <5494AB40.6080708@uw.edu>
References: <5494AB40.6080708@uw.edu>
Message-ID: <54962EDF.5070100@gmail.com>

On 19/12/2014, 5:48 PM, Ben Marwick wrote:
> I'm looking for the NEWS files for versions of R before 3.0.0, does 
> anyone know where they are? I'm interested in getting the names of 
> people who have been acknowledged when changes are made to R.
> 
> At the bottom of http://cran.r-project.org/src/base/NEWS.html it says
> 
> "Older news can be found in text format in files NEWS.0, NEWS.1 and 
> NEWS.2 in the ?doc? directory. News in HTML format for R versions from 
> 2.10.0 to 2.15.3 is in NEWS.2.html."
> 
> The text includes these URLs:
> 
> http://cran.r-project.org/src/NEWS.0
> http://cran.r-project.org/src/NEWS.1
> http://cran.r-project.org/src/NEWS.2
> http://cran.r-project.org/src/base/NEWS.2.html
> 
> All of these go to 404s, and when src is replaced by doc, as suggested 
> by the text, they also go to 404s. There are no NEWS files in here 
> either: http://cran.r-project.org/doc/html/ So there are a bunch of 
> broken links here.

If you read these from within the HTML help system in R, the links
aren't broken.  CRAN copied some of the files from there, but not all.

You can also find the files in the RHOME/doc directory (and subdirectories).

Duncan Murdoch

> 
> I found a bunch of PDFs listed here http://cran.r-project.org/doc/Rnews/ 
> dating from 2008-2001. Are these only source of the earlier NEWS files?
> 
> They're less convenient because the NEWS section is not a single plain 
> text file, but a section of the PDF document. I'd be most grateful to 
> know where I can find html or txt files of the earlier NEWS files. If 
> the PDFs are all there are, it would be good to know that for sure.
> 
> The other method I was considering was scraping bugzilla for names of 
> people who submitted bugs that resulted in a fix 
> (https://bugs.r-project.org/bugzilla3/buglist.cgi?product=R&query_format=advanced&resolution=FIXED). 
> But text mining the NEWS files would be quicker for a first approximation.
> 
> thanks,
> 
> Ben
>


From jfox at mcmaster.ca  Sun Dec 21 05:33:13 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 20 Dec 2014 23:33:13 -0500
Subject: [R] Bca confidence intervals for Pearson coefficient, thanks.
In-Reply-To: <612077657.1191799.1419107817784.JavaMail.yahoo@jws11119.mail.ir2.yahoo.com>
References: <612077657.1191799.1419107817784.JavaMail.yahoo@jws11119.mail.ir2.yahoo.com>
Message-ID: <web-541279167@cgpsrv2.cis.mcmaster.ca>

Dear varin sacha,

I think that you misunderstand how boot() and boot.ci() work. The boot() function in the simplest case takes two arguments, for the data and indices into the data, while boot.ci() takes as its principal argument the object returned by boot(). All of this seems reasonably clear in ?boot and ?boot.ci.

Here's an example with different data (since as far as I can see you didn't supply yours):

------------- snip --------

> library(boot)
> 
> x <- longley$Year
> y <- longley$Population
> 
> cor(cbind(x, y))
          x         y
x 1.0000000 0.9939528
y 0.9939528 1.0000000
> 
> myCor <- function(data, index){
+   cor(data[index, ])[1, 2]
+ }
> 
> set.seed(12345)
> (b <- boot(data=cbind(x, y), statistic=myCor, R=200))

ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = cbind(x, y), statistic = myCor, R = 200)


Bootstrap Statistics :
     original       bias    std. error
t1* 0.9939528 0.0008263766 0.001850004

> boot.ci(b, type="bca")
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 200 bootstrap replicates

CALL : 
boot.ci(boot.out = b, type = "bca")

Intervals : 
Level       BCa          
95%   ( 0.9895,  0.9969 )  
Calculations and Intervals on Original Scale
Warning : BCa Intervals used Extreme Quantiles
Some BCa intervals may be unstable
Warning message:
In norm.inter(t, adj.alpha) : extreme order statistics used as endpoints

--------------- snip ---------------

Note that 200 bootstrap replications are generally sufficient for bootstrap standard errors (a normal-theory CI would be a poor choice here, unless you transform the correlation coefficient), but really aren't enough for a BCa interval.

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
On Sat, 20 Dec 2014 20:36:57 +0000 (UTC)
 varin sacha <varinsacha at yahoo.fr> wrote:
> Hi to everyone,
> I am trying to calculate the Bca bootstrap confidence intervals for the Pearson coefficient.
> x=Dataset$math.testy=Dataset$geo.testcor(x,y,method="pearson")[1] 0.6983799
> boot.ci(cor, conf=0.95, type=bca)Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
> 
> I have tried as well to calculate the Pearson coefficient using bootstrap and then to calculate the Bca bootstrap CIs of the Pearson. It doesn't work either.?
> boot(data = cbind(x, y), statistic = cor, R = 200)
> 
> ORDINARY NONPARAMETRIC BOOTSTRAP
> 
> 
> Call:
> boot(data = cbind(x, y), statistic = cor, R = 200)
> 
> 
> Bootstrap Statistics :
>       original    bias    std. error
> t1* -0.6243713 0.6295142   0.2506267
> t2* -0.1366533 0.1565392   0.2579134
> > boot.ci(cor, conf=0.95, type=bca)
> Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
> Many thanks to tell me how to correct my R script to get the Bca CIs for my Pearson coefficient. Best regards, looking forward to reading you,
> SV
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Sun Dec 21 06:09:36 2014
From: zadig_1 at excite.com (ce)
Date: Sun, 21 Dec 2014 00:09:36 -0500
Subject: [R] How to create a time series object with time only (no date)
Message-ID: <20141221000936.9034@web010.roc2.bluetie.com>


Dear all,

I want to create a time series object from 00:00:00 to 23:59:00 without dates ?
I can't figure it out with xts ?

ce


From josh.m.ulrich at gmail.com  Sun Dec 21 06:53:15 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 20 Dec 2014 23:53:15 -0600
Subject: [R] How to create a time series object with time only (no date)
In-Reply-To: <20141221000936.9034@web010.roc2.bluetie.com>
References: <20141221000936.9034@web010.roc2.bluetie.com>
Message-ID: <CAPPM_gT1SE-uC6uPaxA=-GozGCjd5pX2VfbtrqKYkZF_z+Bp5Q@mail.gmail.com>

On Dec 20, 2014 11:11 PM, "ce" <zadig_1 at excite.com> wrote:
>
>
> Dear all,
>
> I want to create a time series object from 00:00:00 to 23:59:00 without
dates ?
> I can't figure it out with xts ?
>
You can't create an xts object without a date in the index. If the date
doesn't matter, you can just set it to 1970-01-01 (or any other day).

> ce
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec 21 09:26:07 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 21 Dec 2014 00:26:07 -0800 (PST)
Subject: [R] non negativity constraints if else function
In-Reply-To: <57B55AE9-388C-4DB9-9A25-4AEDCC20F9DD@icloud.com>
References: <8C5670DE-7B0C-415B-A03F-E50F4BA28A63@icloud.com>
	<FF7439AF-452C-4CE6-A4D2-CB27F4F53EC2@dcn.davis.CA.us>
	<57B55AE9-388C-4DB9-9A25-4AEDCC20F9DD@icloud.com>
Message-ID: <alpine.BSF.2.00.1412202358210.81018@pedal.dcn.davis.ca.us>

Please keep the conversation on the list, Esra... I don't do personal 
tutoring online, and others may answer your questions sooner and better 
than I can.

Some comments below:

On Sat, 20 Dec 2014, Esra Ulasan wrote:

> Hello,
> Thank you very much for your concern. I have these codes for portfolio optimization solved by Lagrange function.
> I want to put a non-negativity constraint on weights. If the element of weight vector is negative remove it from the vector and recalculate the other elements of weight vector again after removing negative ones. It is going to be a non-negativity constraint on weights. I am trying to do it but I could not solve it.
> Thank you very much.
> Esra
>
> optimization<-function(returns) {

# what is "x"? From context, perhaps a matrix?
# also, you are abusing positional parameters by not putting x first.. 
# read ?colMeans
# also, "mean" is the name of a VERY common R function... using it as a 
# variable name is very confusing at best

>  mean <- colMeans(na.rm=FALSE,x)

# what is "asset.names"?

>  names(mean) <-assets.names

# 100L is a simpler way to write an integer, though it does not look 
# to me like M really needs to be an integer so much

>  M <- as.integer(100)    #nuber of ports on the eff.front.
>  S <- cov(x)
>  Rmax<- 0.01282409    #max monthly return value
>  Thetah <- solve(S)

# what is p?

>  u <- rep(1,p)
>  a<- matrix(rep(0,4), nrow=2)
>  a[1,1] <- t(u)%*%Thetah%*%u
>  a[1,2] <- t(mean)%*%Thetah%*%u
>  a[2,1] <- a[1,2]
>  a[2,2] <- t(mean)%*%Thetah%*%mean

# you might be interested in the ?det function

>  d <- a[1,1]*a[2,2]-a[1,2]*a[1,2]
>  f <- (Thetah%*%(a[2,2]*u-a[1,2]*mean))/d
>  g <- (Thetah%*%(-a[1,2]*u+a[1,1]*mean))/d
>  r <- seq(0, Rmax, length=M)
>  w <- matrix((rep(0, p*M)), nrow=p)
>
>  for(i in 1:M) { w[,i] = f+r[i]*g                    #portfolio weights
>      if (w[,i] <0) {w[,i]=0} else {w[,i]=w[,i]}
>    }
>  rownames(w)=assets.names

# I think the following two lines can entirely replace the for loop 
#above

w <- f + r * g
>  w=ifelse(w<0, 0, w)
>

# I am not familiar with this type of modification of matrices

>  #removing zero rows from weight matrix
>  row_sub = apply(w, 1, function(row) all(row !=0 ))
>  w2=w[row_sub,]
>
>  s <- sqrt( a[1,1]*((r - a[1,2]/a[1,1])^2)/d + 1/a[1,1] ) # variance of the frontier
>  ss <- sqrt(diag(S))
>  names(ss) <- assets.names
>  minp <- c(sqrt(1/a[1,1]), a[1,2]/a[1,1])            # risk-return values of MVP
>  wminp <- f + (a[1,2]/a[1,1])*g                      #weights(allocation of assets) of MVP
>  names(wminp) <- assets.names
>  sharpe <- c((sqrt(1/a[1,1])) / a[1,2]/a[1,1])      #maximum sharpe ratio
>  tanp <- c(sqrt(a[2,2])/a[1,2], a[2,2]/a[1,2])      #risk-return values of tangency portfolio
>  wtanp <- f+(a[2,2]/a[1,2])*g                       #weight (allocation of assets) of tangency portfolio
>

# Not sure what you are hoping to achieve by concatenating some scalars 
# and vectors together for return from the function.

> return(c(s, r, ss, mean, minp, tanp, wminp, wtanp, w))
>

# seem to be missing a brace "}"

Have you read the help file for the "optim" function? It includes some 
options for constrained optimization that might help you.

(no more comments)

>
> 20 Ara 2014 tarihinde 20:41 saatinde, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> ?unlar? yazd?:
>
>> "if weight element is negative set it to zero, else recalculate the weights again"... this seems like the only way out of this loop is to calculate negative weights... and since you set them to zero at that point they will all be zero when you are done. Somehow I doubt that is what you intended to say.
>>
>> On the other hand, if you had provided us with example input data and result data then we would not have to guess what you want.
>>
>> I suspect that loops are not really what you want at all... but I could be wrong.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On December 19, 2014 8:26:55 PM PST, Esra Ulasan <esra_ulasan at icloud.com> wrote:
>>> Hello,
>>>
>>> I have tried the solve the non-negativity constraint "if else function"
>>> in R. But I have done something wrong because it still gives the same
>>> solution. I want that, if weight element is negative set it to zero,
>>> else recalculate the weights again. These are the codes:
>>>
>>> for(i in 1:M){ w[,i] = f+r[i]*g              #portfolio weights
>>>   for(i in 1:M){
>>>     if (w <0){w=0}else{w=w}
>>>   }
>>> }
>>> If you help me I would be happy
>>> Thank you
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From zadig_1 at excite.com  Sun Dec 21 14:59:55 2014
From: zadig_1 at excite.com (ce)
Date: Sun, 21 Dec 2014 08:59:55 -0500
Subject: [R] How to create a time series object with time only (no date)
Message-ID: <20141221085955.1035@web010.roc2.bluetie.com>


Thanks Joshua,

Would you kindly explain if I have an xts array with different dates how I change all dates to 1970-01-01 without touching the time ? I tried with indexFormat without success. indexFormat(s) <- "1970-01-01 %H:%M:%S" . when I plot a graph it still shows original dates. 
ce


-----Original Message-----
From: "Joshua Ulrich" [josh.m.ulrich at gmail.com]
Date: 12/21/2014 12:53 AM
To: "ce" <zadig_1 at excite.com>
CC: "R-Help" <r-help at r-project.org>
Subject: Re: [R] How to create a time series object with time only (no date)

On Dec 20, 2014 11:11 PM, "ce" <zadig_1 at excite.com> wrote:
>
>
> Dear all,
>
> I want to create a time series object from 00:00:00 to 23:59:00 without dates ?
> I cant figure it out with xts ?
>
You cant create an xts object without a date in the index. If the date doesnt matter, you can just set it to 1970-01-01 (or any other day).
> ce
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From josh.m.ulrich at gmail.com  Sun Dec 21 16:20:25 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sun, 21 Dec 2014 09:20:25 -0600
Subject: [R] How to create a time series object with time only (no date)
In-Reply-To: <20141221085955.1035@web010.roc2.bluetie.com>
References: <20141221085955.1035@web010.roc2.bluetie.com>
Message-ID: <CAPPM_gTMSypnqfD8nkfSeROhEsAubBvTL_ivUm-TRCQJutgKBg@mail.gmail.com>

On Sun, Dec 21, 2014 at 7:59 AM, ce <zadig_1 at excite.com> wrote:
>
> Thanks Joshua,
>
> Would you kindly explain if I have an xts array with different dates how I change all dates to 1970-01-01 without touching the time ? I tried with indexFormat without success. indexFormat(s) <- "1970-01-01 %H:%M:%S" . when I plot a graph it still shows original dates.

You can't just change how the data are printed.  You have to actually
change the underlying data.  Here's one example of how you could do
that:

x <- xts(1:5, .POSIXct(1:5+86400*1:5, tz="UTC"))
index(x) <- as.POSIXct(paste("1970-01-01",
  format(index(x), "%H:%M:%S")), tz="UTC")

Note that you should ensure your timezone is UTC, GMT, or any timezone
that doesn't have daylight saving time.  Otherwise you might have
instances in your data where certain hours either do not exist or
exist twice.

> ce
>
>
> -----Original Message-----
> From: "Joshua Ulrich" [josh.m.ulrich at gmail.com]
> Date: 12/21/2014 12:53 AM
> To: "ce" <zadig_1 at excite.com>
> CC: "R-Help" <r-help at r-project.org>
> Subject: Re: [R] How to create a time series object with time only (no date)
>
> On Dec 20, 2014 11:11 PM, "ce" <zadig_1 at excite.com> wrote:
>>
>>
>> Dear all,
>>
>> I want to create a time series object from 00:00:00 to 23:59:00 without dates ?
>> I cant figure it out with xts ?
>>
> You cant create an xts object without a date in the index. If the date doesnt matter, you can just set it to 1970-01-01 (or any other day).
>> ce
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From shouro at gmail.com  Sun Dec 21 16:26:19 2014
From: shouro at gmail.com (Shouro Dasgupta)
Date: Sun, 21 Dec 2014 16:26:19 +0100
Subject: [R] R - Aggregate 3-Hourly Block Data into Weekly (Melt)
In-Reply-To: <CAMx+UYeUAyxJLow=+x5pPi5dvpjdPKV9ugxZSr+xeoX0gn5qXA@mail.gmail.com>
References: <CAMx+UYdz1z2JKvo9v+J2imC3Yf29weNMONWBXKWx8WR9dY7KhQ@mail.gmail.com>
	<alpine.BSF.2.00.1412190019140.1107@pedal.dcn.davis.ca.us>
	<CAMx+UYeUAyxJLow=+x5pPi5dvpjdPKV9ugxZSr+xeoX0gn5qXA@mail.gmail.com>
Message-ID: <CAMx+UYcVUJK6X3FpWdxPLeiMRUNS7Atk6Dgpc6LDPVKKo4DxfA@mail.gmail.com>

Apologies for re-posting. Any suggestions for clipping/subsetting panel
data (ID=US counties, Time=Week)? I would like start the data to start on
the first Monday and end on the last Sunday for the time period 2026-2045.
Thanks and apologies again.

Sincerely,

Shouro

On Fri, Dec 19, 2014 at 11:01 AM, Shouro Dasgupta <shouro at gmail.com> wrote:

> Thank you very much for your reply. I really appreciate it. I apologize
> for the HTML version, I have made modifications and replied to your
> questions/comments below. Thanks again
>
>
>
> tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 = c(
> 285.5533142,
>
>   285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
>
>   285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
>
>   ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
>
>       X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
>
>       X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071),
> X2026.01.01.7 = c(282.3938, 282.3938, 283.1096), X2026.01.01.8 = c(
> 285.9133, 285.9133, 286.1951) .Names = c("FIPS", "X2026.01.01.1",
> "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
>
>   "X2026.01.01.5", "X2026.01.01.6", "X2026.01.01.7", "X2026.01.01.8" ),
> class = "data.frame", row.names = c(NA, -3L))
>
>
>
> *Looks like this*
>
> FIPS
>
> X2026.01.01.1
>
> X2026.01.01.2
>
> X2026.01.01.3
>
> X2026.01.01.4
>
> X2026.01.01.5
>
> X2026.01.01.6
>
> X2026.01.01.7
>
> X2026.01.01.8
>
> 1001
>
> 285.5533
>
> 283.4977
>
> 281.9734
>
> 280.0235
>
> 278.7126
>
> 278.5205
>
> 282.3938
>
> 285.9133
>
> 1003
>
> 285.5533
>
> 283.4977
>
> 281.9734
>
> 280.0235
>
> 278.7126
>
> 278.5205
>
> 282.3938
>
> 285.9133
>
> 1005
>
> 286.2481
>
> 285.086
>
> 284.1549
>
> 282.6076
>
> 281.2554
>
> 280.6148
>
> 283.1096
>
> 286.1951
>
>
>
> For X2026.01.01.1 represents Year=2026, Month=01, Day=01, Hour block=1.
>
> I have extracted the data by FIPS code and reshaped the yearly data files
> using melt();
>
>
>
> for (i in filelist) {
>
>   tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
>
>   tmp2 <- melt(tmp1, id="FIPS")
>
>   tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
>
>   tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
>
>   tmp2$day <- as.numeric(substr(tmp2$variable,10,11))
>
> }
>
>
> I have added date string and weekdays using the following codes:
>
> *Date Variable*
>
>         tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month,
> day)))
>
>
>
> *Day Variable*
>
>         tmp2$day <- weekdays(as.Date(tmp2$date))
>
>
>
> *Question 1: *Apologies for clipping the data and not showing all the
> hour blocks. I have included a full 8-hour block now. For each year, I have
> 3-hour blocks for every day.
>
>
>
> *Question 2: *I have two time periods for each GCM; 2026-2045 and
> 2081-2100. There are occasions when days would have 7 hour blocks instead
> of 8, it could be a data reporting issue from the models.
>
> *Reply to Comment 1: *The data has been downscaled to the US from gridded
> data; Resolution: T42 in atm. 1/3~1?lat. x 1?lon. tripolar grids in ocn. So
> Daylight Savings Time could well be an issue. I will look into it.
>
>
>
> *Reply to Comment 2: * Thank you for the suggestion. I realize that using
> rep() is risky, however, I have assign week numbers to each FIPS code (ID)
> for each year. I was thinking of something similar to this:
>
>
>
> weeks<-rep(seq(1,52,1),each=(unique(tmp2$FIPS)**8*)
>
>
>
> Any alternative code will be highly appreciated. My first goal is to
> subset/clip the data to begin on the first Monday and end on the last
> Sunday of each year.
>
> On Fri, Dec 19, 2014 at 9:37 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>>
>> Thank you for attempting to convey your problem clearly using example
>> code... but your use of HTML email has very nearly undone all your
>> efforts.  Also, use of "dput" to make an R-readable block of data is more
>> reliable than read.table to get the data into our R sessions quickly.
>>
>> First question: you say these are three-hour results, but there are only
>> six per day in your example.
>>
>> Second question: you say the "number of blocks vary between 7 and 8", but
>> your example data does not illustrate that problem. (If there were 8 blocks
>> per day the three-hour statement would make more sense.)
>>
>> Comment: You have not mentioned timezone information... this information
>> looks ripe for GMT, but if that is a bad assumption then daylight savings
>> might account for some variations in blocks per day.
>>
>> Comment: I think your plan of using rep to identify the week numbers is
>> risky. I would recommend using a Date or POSIXt type to make the timestamps
>> computable, and then find the date corresponding to the beginning of the
>> week that the timestamp falls into. Then aggregate grouping on those time
>> values. Unfortunately, the specific way you go about identifying the
>> beginning of week may depend on the timezone information.
>>
>>
>> On Thu, 18 Dec 2014, Shouro Dasgupta wrote:
>>
>>  I am trying to compute max, min, and mean from Global Circulation Models
>>> (GCM) for the US. The data is in 3-hour blocks for 2026-2045 and
>>> 2081-2100.
>>> Sample Data:
>>>
>>> tmp1 <- structure(list(FIPS = c(1001L, 1003L, 1005L), X2026.01.01.1 =
>>> c(285.5533142,
>>>  285.5533142, 286.2481079), X2026.01.01.2 = c(283.4977112, 283.4977112,
>>>  285.0860291), X2026.01.01.3 = c(281.9733887, 281.9733887, 284.1548767
>>>  ), X2026.01.01.4 = c(280.0234985, 280.0234985, 282.6075745),
>>>      X2026.01.01.5 = c(278.7125854, 278.7125854, 281.2553711),
>>>      X2026.01.01.6 = c(278.5204773, 278.5204773, 280.6148071)),
>>> .Names = c("FIPS",
>>>  "X2026.01.01.1", "X2026.01.01.2", "X2026.01.01.3", "X2026.01.01.4",
>>>  "X2026.01.01.5", "X2026.01.01.6"), class = "data.frame", row.names =
>>> c(NA,
>>>  -3L))
>>>
>>> I have extracted the data by FIPS code and reshaped the yearly data files
>>> using melt();
>>>
>>> for (i in filelist) {
>>>  tmp1 <- as.data.table(read.csv(i,header=T, sep=","))
>>>  tmp2 <- melt(tmp1, id="FIPS")
>>>  tmp2$year <- as.numeric(substr(tmp2$variable,2,5))
>>>  tmp2$month <- as.numeric(substr(tmp2$variable,7,8))
>>>  tmp2$day <- as.numeric(substr(tmp2$variable,10,11))}
>>>
>>> I have added datestring and weekdays using the following code:
>>> Inserting Date Variable
>>>
>>> tmp2$date <- with(tmp2, ymd(sprintf('%04d%02d%02d', year, month, day)))
>>>
>>> Inserting Day Variable
>>>
>>> tmp2$day <- weekdays(as.Date(tmp2$date))
>>>
>>> sample.tmp2 <- "FIPS         xdate     temp year month      day
>>> date      dates weekdays
>>> + 5599311  1003 X2045.08.14.2 304.5995 2045     8   Monday 2045-08-14
>>> 2036-01-29        2
>>> + 468406 39093 X2045.01.19.7 267.8483 2045     1 Thursday 2045-01-19
>>> 2028-06-04        0
>>> + 5022078 21167 X2045.07.21.8 314.6772 2045     7   Friday 2045-07-21
>>> 2035-09-13        4
>>> + 186822   9005 X2045.01.08.5 269.0803 2045     1   Sunday 2045-01-08
>>> 2037-06-28        0
>>> + 3998678 13295 X2045.06.10.7 307.2408 2045     6 Saturday 2045-06-10
>>> 2033-10-13        4"
>>>
>>> Data <- read.table(text=sample.tmp2, header = TRUE)
>>>
>>> My goal is to aggregate these 3-hourly blocks into weekly data, however,
>>> GCM data is not consistent and the blocks vary between 7 and 8. I want to
>>> clip the data to start on the first Monday of 2026 and end on the last
>>> Sunday of 2045 and then use rep() to assign week numbers for the whole
>>> epoch.
>>>
>>> I know I can count the number of each day using something like this;
>>>
>>> length(which(weekdays == '0'))
>>>
>>> Where 0, 1, 2..., 6 represent Sunday, Monday,...
>>>
>>> My question is am I doing anything wrong in trying to aggregate the data
>>> to
>>> begin with? But importantly, I would be grateful for any help to clip the
>>> dataset to begin on the first Monday and end on the last Sunday. Thank
>>> you
>>> very much!
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ------------------------------------------------------------
>> ---------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ------------------------------------------------------------
>> ---------------
>>
>

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Sun Dec 21 16:35:19 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Sun, 21 Dec 2014 08:35:19 -0700
Subject: [R] how update to latest version of R on mac
In-Reply-To: <D0BC4E58.57BDA%jane.synnergren@his.se>
References: <D0BA5DA8.57B1F%jane.synnergren@his.se>
	<CAGxgkWidB0=+odRRfgqV4aDjYMF_kgSds2DggwuhdqF=ge=P=w@mail.gmail.com>
	<D0BC4E58.57BDA%jane.synnergren@his.se>
Message-ID: <CAGxgkWhkpafi2BoBZTDuvrpZ=9Js4T4tWLgAFtjdSyFHhoJiWA@mail.gmail.com>

Jane,

My sincere apologies; I don't know what I was seeing/thinking -- your
original post was correct. Namely, you should download and install:
http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg
(although, I am use to using the main mirror
http://cran.r-project.org/bin/macosx/R-3.1.2-snowleopard.pkg) -- but that
should not make a difference. The documentation does state...

*R 3.1.2* binary for Mac OS X 10.6 (Snow Leopard) *and higher*, signed
package. Contains R 3.1.2 framework, R.app GUI 1.65 in 64-bit for Intel
Macs. The above file is an Installer package which can be installed by
double-clicking. Depending on your browser, you may need to press the
control key and click on this link to download the file.

So, this should be the way to go. I'm glad you double checked!!

Tom

On Sun, Dec 21, 2014 at 2:21 AM, Jane Synnergren <jane.synnergren at his.se>
wrote:

>   Thanks Tom!
> One more quick question, regarding choosing mavericks.pkg or
> snowleopard.pkg.
> Will mavericks work for me though I have OS X Lion 10.7.5? I thought I had
> to choose snowleopard but are still an unexperienced mac user and have
> really no idea.
>
>  Just want to dubble check before I run the installation.
>
>  /Jane
>
> -------------------------------------------------------------------------------
> Jane Synnergren, PhD
> Systems Biology Research Center
> School of Bioscience
> University of Sk?vde
> Sweden
>
>  Contact:
> email: jane.synnergren at his.se
> mobile: +46 (0)708 806495
> webpage: his.se/synj
>
>  Postal Address:  Visiting address:
>  Box 408 Kanikegr?nd 3A
> 541 28 Sk?vde Sk?vde
>
>   From: Thomas Adams <tea3rd at gmail.com>
> Date: Sunday, December 21, 2014 2:06 AM
> To: Jane Synnergren <jane.synnergren at his.se>
> Cc: R-help <r-help at r-project.org>
> Subject: Re: [R] how update to latest version of R on mac
>
>    Jane,
>
>  It's possible, since you are using Mac OS X Lion (10.7.5), you need the R
> version for that, which can be found here:
> http://cran.r-project.org/bin/macosx/old/R-3.1.1-mavericks.pkg
>
>  Cheers!
>  Tom
>
> On Fri, Dec 19, 2014 at 2:56 PM, Jane Synnergren <jane.synnergren at his.se>
> wrote:
>>
>> Hi,
>> I get following error when trying to update the affy package to latest
>> version.
>>
>> Error: cannot remove prior installation of package ?affy?
>>
>> I think it is because affy requires R 3.1.1 and I have 3.0.2
>>
>> I try to find a guide how I do to upgrade from 3.0.2 to latest version on
>> mac, but cannot find any good description. Can anyone guide me?
>>
>> Do I just download R for mac (R-3.1.2-snowleopard.pkg) from
>> <http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg>
>> and
>> dubbelclick?
>>
>> What will happen with all installed packages?
>> I have OS X Lion 10.7.5
>> Which version number is stable and reliable?
>>
>> I also need a guide of how to update to latest version of  bioconductor on
>> mac.
>>
>> Descriptions for windows is available everywhere.
>>
>> /Jane
>>
>>
>>
>> ---------------------------------------------------------------------------
>> ----
>> Jane Synnergren, PhD
>> Systems Biology Research Center
>> School of Bioscience
>> University of Sk?vde
>> Sweden
>>
>> Contact:
>> email: jane.synnergren at his.se
>> mobile: +46 (0)708 806495
>> webpage: his.se/synj
>>
>> Postal Address:                         Visiting address:
>>
>> Box 408                                 Kanikegr?nd 3A
>> 541 28 Sk?vde                   Sk?vde
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>

	[[alternative HTML version deleted]]


From statistics84 at hotmail.com  Sun Dec 21 06:59:14 2014
From: statistics84 at hotmail.com (pari hesabi)
Date: Sun, 21 Dec 2014 05:59:14 +0000
Subject: [R] MLE
Message-ID: <DUB125-W54A7A52D6478A6A419FEBFC6690@phx.gbl>

Dear Sir/Madam
I am trying to get the Maximum Likelihood Estimation of a parameter in a probability mass function. The problem is my pmf which includes a summation and one integral. it is not similar to other known pdfs or pmfs such as normal, exponential, poisson, .....
Does anybody know whether I can use the current packages(like Maxlik) in R for getting the MLE of the parameter?
Can anybody explains me with an example?
I would appreciate any help.
Best Regards,
Pari 		 	   		  

From ruzudumyan at gmail.com  Sun Dec 21 09:03:04 2014
From: ruzudumyan at gmail.com (Ruzan Udumyan)
Date: Sun, 21 Dec 2014 09:03:04 +0100
Subject: [R] mediation analysis in R using the method described by Lange T.,
 et al. in the paper "A simple unified approach for estimating
 natural direct and direct effects
Message-ID: <CAJbUeXZPFFsa1PFTGfX1n32jKCsMOmX8SZb8Ke=YrhyHsmThmA@mail.gmail.com>

Dear All,

I need to do  a mediation analysis with survival data (using Cox model).

   - The independent variable is categorical (with 3 levels, coded as 1, 2,
   3).
   - Mediator variable is a 1-10 score variable (derived from a continuous
   variable).

I must confess, I am a Stata user. However, could not find an appropriate
command in Stata for mediation analysis with Cox model, and was very happy
to find a way of doing it in R.
I am running into problems though, which I do not know how to solve. More
specifically, I get an error message from RStudio after running the syntax
mentioned below.

I am kindly asking you to help me fix the problem.

With many thanks and my best regards,

Ruzan


Error in model.frame.default(formula = Surv(time, event) ~ factor(stress) +  :
  variable lengths differ (found for 'factor(stress)')
 In addition: Warning messages:1: In checkwz(wz, M = M, trace = trace,
wzepsilon = control$wzepsilon) :
  31 elements replaced by 1.819e-122: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  187 elements replaced by 1.819e-123: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  1492 elements replaced by 1.819e-124: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  2081 elements replaced by 1.819e-125: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  2081 elements replaced by 1.819e-126: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  4783 elements replaced by 1.819e-127: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  8309 elements replaced by 1.819e-128: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  8642 elements replaced by 1.819e-129: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  8642 elements replaced by 1.819e-1210: In checkwz(wz, M = M, trace =
trace, wzepsilon = control$wzepsilon) :
  8642 elements replaced by 1.819e-12

    >
Here is the syntax:

doEffectDecomp = function(myData)
 {
   #step 1
   myData$stresstemp <- myData$stress
   library(VGAM)
   fitM <-vglm(phys1 ~ factor(stresstemp)+ C, data = myData, family =
multinomial())  # C stands for confounders
   #summary(fitM)
     #Step 2. Next we construct new variables id and star
     N <- nrow(myData)
     myData$id <- 1:N # construct id variable
     levelsOfstress <- unique(myData$stress)
     myData1 <- myData
     myData2 <- myData
     myData3 <- myData
     myData1$star <- levelsOfstress[1]
    myData2$star <- levelsOfstress[2]
   myData3$star <- levelsOfstress[3]
   newMyData <- rbind(myData1, myData2, myData3)

#Step 3. compute weights
     newMyData$stresstemp <- newMyData$stress
    tempDir <- as.matrix(predict(fitM,type = "response",
newdata=newMyData))[cbind(1:(3*N),newMyData$phys1)]
   newMyData$stresstemp <- newMyData$star
   tempIndir <- as.matrix(predict(fitM,type = "response",
newdata=newMyData))[cbind(1:(3*N),newMyData$phys1)]
   newMyData$weightM <- tempIndir/tempDir
   #hist(newMyData$weightM)
   #Step 4. Finally the MSM model for direct and indirect effects can be
estimated.
    # weighted Cox model
    library(survival)
   cox <- coxph(Surv(time,event) ~factor(stress) + factor(star) +  C,
method="efron", data=newMyData, weights=newMyData$weightM)

  summary(cox)

  # return value: TE; DE; IE
   # Return value: Estimates for total, direct, indirect effect
   TE = exp(sum(coef(cox)[c('stressTRUE', 'starTRUE')]))     # I am not
sure this is correct for the categorical exposure with 3 levels
   DE = exp(unname(coef(cox)['stressTRUE']))
   IE = exp(sum(coef(cox)['starTRUE']))
   PM = log(IE) / log(TE)
    return(c(exp(coef(cox)), TE=TE, DE=DE, IE=IE, PM=PM))
 }



doEffectDecomp(myData)

	[[alternative HTML version deleted]]


From jane.synnergren at his.se  Sun Dec 21 10:21:43 2014
From: jane.synnergren at his.se (Jane Synnergren)
Date: Sun, 21 Dec 2014 09:21:43 +0000
Subject: [R] how update to latest version of R on mac
In-Reply-To: <CAGxgkWidB0=+odRRfgqV4aDjYMF_kgSds2DggwuhdqF=ge=P=w@mail.gmail.com>
References: <D0BA5DA8.57B1F%jane.synnergren@his.se>
	<CAGxgkWidB0=+odRRfgqV4aDjYMF_kgSds2DggwuhdqF=ge=P=w@mail.gmail.com>
Message-ID: <D0BC4E58.57BDA%jane.synnergren@his.se>

Thanks Tom!
One more quick question, regarding choosing mavericks.pkg or snowleopard.pkg.
Will mavericks work for me though I have OS X Lion 10.7.5? I thought I had to choose snowleopard but are still an unexperienced mac user and have really no idea.

Just want to dubble check before I run the installation.

/Jane
-------------------------------------------------------------------------------
Jane Synnergren, PhD
Systems Biology Research Center
School of Bioscience
University of Sk?vde
Sweden

Contact:
email: jane.synnergren at his.se
mobile: +46 (0)708 806495
webpage: his.se/synj

Postal Address:  Visiting address:
Box 408 Kanikegr?nd 3A
541 28 Sk?vde Sk?vde

From: Thomas Adams <tea3rd at gmail.com<mailto:tea3rd at gmail.com>>
Date: Sunday, December 21, 2014 2:06 AM
To: Jane Synnergren <jane.synnergren at his.se<mailto:jane.synnergren at his.se>>
Cc: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] how update to latest version of R on mac

Jane,

It's possible, since you are using Mac OS X Lion (10.7.5), you need the R version for that, which can be found here: http://cran.r-project.org/bin/macosx/old/R-3.1.1-mavericks.pkg

Cheers!
Tom

On Fri, Dec 19, 2014 at 2:56 PM, Jane Synnergren <jane.synnergren at his.se<mailto:jane.synnergren at his.se>> wrote:
Hi,
I get following error when trying to update the affy package to latest
version.

Error: cannot remove prior installation of package ?affy?

I think it is because affy requires R 3.1.1 and I have 3.0.2

I try to find a guide how I do to upgrade from 3.0.2 to latest version on
mac, but cannot find any good description. Can anyone guide me?

Do I just download R for mac (R-3.1.2-snowleopard.pkg) from
<http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg> and
dubbelclick?

What will happen with all installed packages?
I have OS X Lion 10.7.5
Which version number is stable and reliable?

I also need a guide of how to update to latest version of  bioconductor on
mac.

Descriptions for windows is available everywhere.

/Jane


---------------------------------------------------------------------------
----
Jane Synnergren, PhD
Systems Biology Research Center
School of Bioscience
University of Sk?vde
Sweden

Contact:
email: jane.synnergren at his.se<mailto:jane.synnergren at his.se>
mobile: +46 (0)708 806495<tel:%2B46%20%280%29708%20806495>
webpage: his.se/synj<http://his.se/synj>

Postal Address:                         Visiting address:

Box 408                                 Kanikegr?nd 3A
541 28 Sk?vde                   Sk?vde

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Sun Dec 21 18:32:47 2014
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Sun, 21 Dec 2014 17:32:47 +0000
Subject: [R] Subject: short-sale constraint with nonpositive-definite matrix
 in portfolio optimization
Message-ID: <1419183169717.35616@jhu.edu>

Hi,

You can try a projected gradient approach, which is implemented in the spg() function in the "BB" package. You have to provide a projection function which will take an infeasible matrix as input and will give a feasible (i.e. positive-definite) matrix as output. This kind of matrix projection is quite easy to do, and in fact, there are functions in R to do this (e.g., see posdefify() function in "sfsmisc" package).


There is a recent review article on spectral projected gradient algorithm in J Statistical Software.

http://www.jstatsoft.org/v60/i03


Hope this is helpful,

Ravi

	[[alternative HTML version deleted]]


From bmarwick at uw.edu  Sun Dec 21 12:21:49 2014
From: bmarwick at uw.edu (Ben Marwick)
Date: Sun, 21 Dec 2014 03:21:49 -0800
Subject: [R] where are the NEWS for R <3.0.0?
In-Reply-To: <54962EDF.5070100@gmail.com>
References: <5494AB40.6080708@uw.edu> <54962EDF.5070100@gmail.com>
Message-ID: <5496AD4D.3060902@uw.edu>

Thanks, yes I found them in my local installation, just as you said. In 
case anyone else wants to get them programatically, here's what I did 
(on windows 7, R version 3.1.1):

# navigate to local R installation dir
setwd(system.file())
setwd('../../doc')

# get all news files
news_files <- list.files( pattern = "NEWS", full.names = TRUE, recursive 
= TRUE)

Thanks again,

Ben

On 20/12/2014 6:22 PM, Duncan Murdoch wrote:
> On 19/12/2014, 5:48 PM, Ben Marwick wrote:
>> I'm looking for the NEWS files for versions of R before 3.0.0, does
>> anyone know where they are? I'm interested in getting the names of
>> people who have been acknowledged when changes are made to R.
>>
>> At the bottom of http://cran.r-project.org/src/base/NEWS.html it says
>>
>> "Older news can be found in text format in files NEWS.0, NEWS.1 and
>> NEWS.2 in the ?doc? directory. News in HTML format for R versions from
>> 2.10.0 to 2.15.3 is in NEWS.2.html."
>>
>> The text includes these URLs:
>>
>> http://cran.r-project.org/src/NEWS.0
>> http://cran.r-project.org/src/NEWS.1
>> http://cran.r-project.org/src/NEWS.2
>> http://cran.r-project.org/src/base/NEWS.2.html
>>
>> All of these go to 404s, and when src is replaced by doc, as suggested
>> by the text, they also go to 404s. There are no NEWS files in here
>> either: http://cran.r-project.org/doc/html/ So there are a bunch of
>> broken links here.
>
> If you read these from within the HTML help system in R, the links
> aren't broken.  CRAN copied some of the files from there, but not all.
>
> You can also find the files in the RHOME/doc directory (and subdirectories).
>
> Duncan Murdoch
>
>>
>> I found a bunch of PDFs listed here http://cran.r-project.org/doc/Rnews/
>> dating from 2008-2001. Are these only source of the earlier NEWS files?
>>
>> They're less convenient because the NEWS section is not a single plain
>> text file, but a section of the PDF document. I'd be most grateful to
>> know where I can find html or txt files of the earlier NEWS files. If
>> the PDFs are all there are, it would be good to know that for sure.
>>
>> The other method I was considering was scraping bugzilla for names of
>> people who submitted bugs that resulted in a fix
>> (https://bugs.r-project.org/bugzilla3/buglist.cgi?product=R&query_format=advanced&resolution=FIXED).
>> But text mining the NEWS files would be quicker for a first approximation.
>>
>> thanks,
>>
>> Ben
>>
>


From wdunlap at tibco.com  Sun Dec 21 21:39:19 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 21 Dec 2014 12:39:19 -0800
Subject: [R] list of lists, is this element empty
In-Reply-To: <DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
References: <mailman.0.1418986801.25142.r-help@r-project.org>
	<DUB125-W30FC1464FDF72FC398C908B3680@phx.gbl>
Message-ID: <CAF8bMcYVTTHxfQ_M4nbfk6iRdDLBiq70QaphaTkNcc0i9k7cPA@mail.gmail.com>

Your 'x' has length 2, so x[[3]] cannot be calculated ('subscript out of
bounds' is what I get).  You can check for this with length(x)<3.

In general, you want to be more precise: 'does not have a value', 'is
NULL', and 'is empty' are not synonymous.  I'm not sure what 'does not have
a value' means to you.  NULL is a value with a certain type, 'NULL', and
length, 0.  seq_len(0) is empty, but not NULL, since it has type 'integer'.
 c(1,NA) contains a 'missing value'.  Can you explain what what you are
trying to check for, giving some context?



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sat, Dec 20, 2014 at 7:58 AM, Ragia Ibrahim <ragia11 at hotmail.com> wrote:
>
> Hello,
> Kindly I have a list of lists as follow
> x
> [[1]]
> [1] 7
>
> [[2]]
> [1] 3 4 5
>
> as showen x[[3]] does not have a value and it has NULL, how can I check on
> this
> how to test if x[[3]] is empty.
>
> thanks in advance
> Ragia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Sun Dec 21 21:50:43 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 21 Dec 2014 15:50:43 -0500
Subject: [R] How to create a time series object with time only (no date)
In-Reply-To: <20141221000936.9034@web010.roc2.bluetie.com>
References: <20141221000936.9034@web010.roc2.bluetie.com>
Message-ID: <CAP01uRkUnFJfDnozYg9C-1N0rvEcO-ENuK9qzGkCSbo+FDh3=g@mail.gmail.com>

On Sun, Dec 21, 2014 at 12:09 AM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I want to create a time series object from 00:00:00 to 23:59:00 without dates ?
> I can't figure it out with xts ?
>

This uses zoo, rather than xts:

library(zoo)
library(chron)

tt <- seq(times("00:00:00"), times("23:59:00"), by = times("00:01:00"))
dat <- 1:1440
z <- zoo(dat, tt)


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jfox at mcmaster.ca  Sun Dec 21 22:22:14 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sun, 21 Dec 2014 16:22:14 -0500
Subject: [R] Bca confidence intervals for Pearson coefficient, thanks.
In-Reply-To: <387456912.130147.1419192178750.JavaMail.yahoo@jws11134.mail.ir2.yahoo.com>
References: <web-541279167@cgpsrv2.cis.mcmaster.ca>
	<387456912.130147.1419192178750.JavaMail.yahoo@jws11134.mail.ir2.yahoo.com>
Message-ID: <001d01d01d64$30d169f0$92743dd0$@mcmaster.ca>

Dear Sacha,

Simply write a function that takes a data set and index vector as arguments, say statistic(data, index), and have it compute and return either eta^2 or V depending upon the application. Use the function myCor() in the previous example as a model.

Best,
 John 

> -----Original Message-----
> From: varin sacha [mailto:varinsacha at yahoo.fr]
> Sent: Sunday, December 21, 2014 3:03 PM
> To: John Fox
> Cc: r-help help
> Subject: Re: [R] Bca confidence intervals for Pearson coefficient,
> thanks.
> 
> Dear Professor FOX,
> 
> 
> I really thank you lots for all your precisions.
> One last precision, now if I want tot calculate the BCa bootstrap CIs
> for the Cramer's V and the Eta-squared.
> 
> 
> ## Read in the data file, using headers and Tab separator
> > test = read.table(file.choose(), header = TRUE, sep = "\t")
> 
> 
> ## Check the variable names
> > names(test)
> [1] "gender"    "option"    "math.test" "geo.test"  "shopping"  "sports"
> 
> 
> ## Cramer's V
> 
> > library(questionr)
> > tab = table(test$gender, test$option)
> > cramer.v(tab)
> [1] 0.1490712
> 
> ## Eta.square
> 
> > library(lsr)
> > test.aov = aov(math.test ~ gender, data = test)
> 
> > etaSquared(test.aov)
>           eta.sq eta.sq.part
> gender 0.1207154   0.1207154
> 
> 
> 
> Best Regards, looking forward to reading you once more,
> 
> Sacha
> 
> ________________________________
> 
> De : John Fox <jfox at mcmaster.ca>
> ? : varin sacha <varinsacha at yahoo.fr>
> Cc : r-help help <r-help at r-project.org>
> Envoy? le : Dimanche 21 d?cembre 2014 5h33
> Objet : Re: [R] Bca confidence intervals for Pearson coefficient,
> thanks.
> 
> 
> Dear varin sacha,
> 
> I think that you misunderstand how boot() and boot.ci() work. The boot()
> function in the simplest case takes two arguments, for the data and
> indices into the data, while boot.ci() takes as its principal argument
> the object returned by boot(). All of this seems reasonably clear in
> ?boot and ?boot.ci.
> 
> Here's an example with different data (since as far as I can see you
> didn't supply yours):
> 
> ------------- snip --------
> 
> > library(boot)
> >
> > x <- longley$Year
> > y <- longley$Population
> >
> > cor(cbind(x, y))
>           x        y
> x 1.0000000 0.9939528
> y 0.9939528 1.0000000
> >
> > myCor <- function(data, index){
> +  cor(data[index, ])[1, 2]
> + }
> >
> > set.seed(12345)
> > (b <- boot(data=cbind(x, y), statistic=myCor, R=200))
> 
> ORDINARY NONPARAMETRIC BOOTSTRAP
> 
> 
> Call:
> boot(data = cbind(x, y), statistic = myCor, R = 200)
> 
> 
> Bootstrap Statistics :
>     original      bias    std. error
> t1* 0.9939528 0.0008263766 0.001850004
> 
> > boot.ci(b, type="bca")
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 200 bootstrap replicates
> 
> CALL :
> boot.ci(boot.out = b, type = "bca")
> 
> Intervals :
> Level      BCa
> 95%  ( 0.9895,  0.9969 )
> Calculations and Intervals on Original Scale
> Warning : BCa Intervals used Extreme Quantiles
> Some BCa intervals may be unstable
> Warning message:
> In norm.inter(t, adj.alpha) : extreme order statistics used as endpoints
> 
> --------------- snip ---------------
> 
> Note that 200 bootstrap replications are generally sufficient for
> bootstrap standard errors (a normal-theory CI would be a poor choice
> here, unless you transform the correlation coefficient), but really
> aren't enough for a BCa interval.
> 
> I hope this helps,
> John
> 
> 
> 
> 
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 
> On Sat, 20 Dec 2014 20:36:57 +0000 (UTC)
> varin sacha <varinsacha at yahoo.fr> wrote:
> > Hi to everyone,
> > I am trying to calculate the Bca bootstrap confidence intervals for
> the Pearson coefficient.
> > x=Dataset$math.testy=Dataset$geo.testcor(x,y,method="pearson")[1]
> 0.6983799
> > boot.ci(cor, conf=0.95, type=bca)Erreur dans boot.out$t0 : objet de
> type 'closure' non indi?able
> >
> > I have tried as well to calculate the Pearson coefficient using
> bootstrap and then to calculate the Bca bootstrap CIs of the Pearson. It
> doesn't work either.
> > boot(data = cbind(x, y), statistic = cor, R = 200)
> >
> > ORDINARY NONPARAMETRIC BOOTSTRAP
> >
> >
> > Call:
> > boot(data = cbind(x, y), statistic = cor, R = 200)
> >
> >
> > Bootstrap Statistics :
> >      original    bias    std. error
> > t1* -0.6243713 0.6295142  0.2506267
> > t2* -0.1366533 0.1565392  0.2579134
> > > boot.ci(cor, conf=0.95, type=bca)
> > Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
> > Many thanks to tell me how to correct my R script to get the Bca CIs
> for my Pearson coefficient. Best regards, looking forward to reading
> you,
> > SV
> 
> >
> >     [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> 


From arne.henningsen at gmail.com  Sun Dec 21 23:02:43 2014
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sun, 21 Dec 2014 23:02:43 +0100
Subject: [R] MLE
In-Reply-To: <DUB125-W54A7A52D6478A6A419FEBFC6690@phx.gbl>
References: <DUB125-W54A7A52D6478A6A419FEBFC6690@phx.gbl>
Message-ID: <CAMTWbJhqL5e1B3+x9C-XzFPdfpuvxGSsvwhU1PU8PXWogiDr0g@mail.gmail.com>

Dear Pari

On 21 December 2014 at 06:59, pari hesabi <statistics84 at hotmail.com> wrote:
> I am trying to get the Maximum Likelihood Estimation of a parameter
> in a probability mass function. The problem is my pmf which includes
> a summation and one integral. it is not similar to other known pdfs or
> pmfs such as normal, exponential, poisson, .....
> Does anybody know whether I can use the current packages(like
> Maxlik) in R for getting the MLE of the parameter?

maxLik (not Maxlik) will probably work.

> Can anybody explains me with an example?

R> library( "maxLik" )
R> ?maxLik

http://dx.doi.org/10.1007/s00180-010-0217-1

https://absalon.itslearning.com/data/ku/103018/publications/maxLik.pdf

> I would appreciate any help.

http://www.R-project.org/posting-guide.html

http://maxlik.org/

https://r-forge.r-project.org/projects/maxlik/

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From dwinsemius at comcast.net  Sun Dec 21 23:04:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 21 Dec 2014 14:04:50 -0800
Subject: [R] Calculating mean, median, minimum, and maximum
In-Reply-To: <CAFDcVCQxbmw30ZBLirvti+6N8--37QwDSaZ9U6Dt7-9y2ah7_g@mail.gmail.com>
References: <1418934906993-4700919.post@n4.nabble.com>
	<1418999039877-4700943.post@n4.nabble.com>
	<1418831065531-4700862.post@n4.nabble.com>
	<1419005309483-4700946.post@n4.nabble.com>
	<97FBAD29EDE.000009B7jrkrideau@inbox.com>
	<CAFDcVCQxbmw30ZBLirvti+6N8--37QwDSaZ9U6Dt7-9y2ah7_g@mail.gmail.com>
Message-ID: <8917A84C-4A32-45D7-BE3A-59ADCE1C4D35@comcast.net>


On Dec 19, 2014, at 9:35 AM, Henrik Bengtsson wrote:

> On Fri, Dec 19, 2014 at 8:48 AM, John Kane <jrkrideau at inbox.com> wrote:
>> Hi,
>> It looks like you are replying to some phantom. Is your correspondent actully on R-help?
> 
> This most likely happens because OP posted the message via Nabble
> [http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-td4700862.html]
> via "New Topic", which in turn post the message to r-help after asking
> the user to confirm:
> 
> "Mailing List Subscription Reminder
> This forum is an archive/gateway which will forward your post to the
> r-help at r-project.org mailing list.
> 
> The mailing list may require your subscription before accepting your
> post. Please note that being registered with Nabble does NOT
> automatically subscribe you to this mailing list. If you haven't
> subscribed yet, please do it now. If you aren't sure or don't
> remember, just subscribe again because there is no harm."

Some of that statement is incorrect. You will be unable to establish a new subscription if your email address has not changed, since it is the email address that acts as your  useR_name. Furthermore, if your email address changes, you can change the address without re-subscribing as long as you log in with the old email address and your password. The address at which you gain access to the web interface is posted in the standard footer in each message (unless you are using Nabble).

> 
> Since OP is not a registered user on the r-help mailing list, his/her
> post is help by r-help for moderation.  However, mtrang probably saw
> it on Nabble and replied there and since mtrang is also a registered
> user on the r-help, his/her messages reach us here on r-help, before
> OP's messages help for moderation are approved.
> 
> I'd say, this is quite annoying "feature" to everyone but Nabble
> users, particularly since the Nabble message does not include the
> previous messages (unlike email).
> 

Writing as a moderator (but not an owner);

Sometime ago (guessing Jan 2013) the automatic filters were "strengthened" in the ETHZ mail-server that automatically discards some Nabble postings. This was done because someone set up a spam bot that was posting exact duplicates of prior postings altered only by attaching a spam footer that had links to gawd knows where. These were coming in too fast to filter by the moderations staff so it was decided to summarily chuck them in null_dev.  The exact rules were never published, but I have observed that hotmail, gmail, and yahoo addresses will increase the probability of automatic rejection. I think that replies to these are sometimes held up in the moderation queue as well. I do believe that subscription status is also part of that algorithm.

Nabble not only makes it modestly difficult to attach prior message content but it also filters out the footer at the bottom of every posting so the subscription address and the Posting Guide address are not included. It also falsely claims that it is the Rhelp mailing list archive. We, of course, know that there is only One True Archive: https://stat.ethz.ch/pipermail/r-help/

It is possible to use Nabble (or gmail or yahoo)  as a web-front-end successfully and respectfully in accord with mailing list traditions of in-context editing and adherence to group norms. It requires an understanding of mailing list realities and attention to details that most Nabble users seem unwilling or unable to learn. They have over the years imposed considerable effort and time on the moderation volunteers. As a group I hope it is fair to say we moderators have little sympathy for too typical Nabble user who fails to read the Posting Guide (to which there does appear a link when users log in), although we do realize that a few longtime and valued contributors may use its facility when traveling.

-- 
David



> /Henrik
> 
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: mtrang at buffalo.edu
>>> Sent: Fri, 19 Dec 2014 08:08:29 -0800 (PST)
>>> To: r-help at r-project.org
>>> Subject: Re: [R] Calculating mean, median, minimum, and maximum
>>> 
>>> You can use the apply function which "applies" a function of your choice,
>>> and
>>> MARGIN = 2 means you want to do it columnwise:
>>> 
>>>> apply(X = df, MARGIN=2, FUN = mean, na.rm = TRUE)
>>> Latitude Longitude   January  February     March     April       May
>>> June
>>>  26.9380 -109.8125  159.8454  156.4489  153.6911  150.1719  148.0885
>>> 149.2365
>>>> apply(X = df, MARGIN=2, FUN = min, na.rm = TRUE)
>>> Latitude Longitude   January  February     March     April       May
>>> June
>>>   26.938  -110.688   121.204   118.713   117.293   114.398   112.357
>>> 113.910
>>>> apply(X = df, MARGIN=2, FUN = max, na.rm = TRUE)
>>> Latitude Longitude   January  February     March     April       May
>>> June
>>>   26.938  -108.938   252.890   248.991   244.870   241.194   239.615
>>> 239.888
>>>> apply(X = df, MARGIN=2, FUN = median, na.rm = TRUE)
>>> Latitude Longitude   January  February     March     April       May
>>> June
>>>  26.9380 -109.8120  134.5990  130.7960  127.4495  123.2100  120.8375
>>> 122.3835
>>> 
>>> 
>>> 
>>> --
>>> View this message in context:
>>> http://r.789695.n4.nabble.com/Calculating-mean-median-minimum-and-maximum-tp4700862p4700946.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From varinsacha at yahoo.fr  Sun Dec 21 21:02:58 2014
From: varinsacha at yahoo.fr (varin sacha)
Date: Sun, 21 Dec 2014 20:02:58 +0000 (UTC)
Subject: [R] Bca confidence intervals for Pearson coefficient, thanks.
In-Reply-To: <web-541279167@cgpsrv2.cis.mcmaster.ca>
References: <web-541279167@cgpsrv2.cis.mcmaster.ca>
Message-ID: <387456912.130147.1419192178750.JavaMail.yahoo@jws11134.mail.ir2.yahoo.com>

Dear Professor FOX,
I really thank you lots for all your precisions.?One last precision, now if I want tot calculate the BCa bootstrap CIs for the Cramer's V and the Eta-squared.
## Read in the data file, using headers and Tab separator> test = read.table(file.choose(), header = TRUE, sep = "\t")
## Check the variable names> names(test)[1] "gender"? ? "option"? ? "math.test" "geo.test"? "shopping"? "sports"? ?
## Cramer's V
> library(questionr)> tab = table(test$gender, test$option)> cramer.v(tab) ? ? ? ? ? ? ? ? ? ? ? ??[1] 0.1490712 ? ? ? ? ? ? ? ? ? ? ? ? ??
## Eta.square
> library(lsr)> test.aov = aov(math.test ~ gender, data = test)
> etaSquared(test.aov)? ? ? ? ? eta.sq eta.sq.partgender 0.1207154 ? 0.1207154

Best Regards, looking forward to reading you once more,
Sacha
      De?: John Fox <jfox at mcmaster.ca>
 ??: varin sacha <varinsacha at yahoo.fr> 
Cc?: r-help help <r-help at r-project.org> 
 Envoy? le : Dimanche 21 d?cembre 2014 5h33
 Objet?: Re: [R] Bca confidence intervals for Pearson coefficient, thanks.
   
Dear varin sacha,

I think that you misunderstand how boot() and boot.ci() work. The boot() function in the simplest case takes two arguments, for the data and indices into the data, while boot.ci() takes as its principal argument the object returned by boot(). All of this seems reasonably clear in ?boot and ?boot.ci.

Here's an example with different data (since as far as I can see you didn't supply yours):

------------- snip --------

> library(boot)
> 
> x <- longley$Year
> y <- longley$Population
> 
> cor(cbind(x, y))
? ? ? ? ? x? ? ? ? y
x 1.0000000 0.9939528
y 0.9939528 1.0000000
> 
> myCor <- function(data, index){
+? cor(data[index, ])[1, 2]
+ }
> 
> set.seed(12345)
> (b <- boot(data=cbind(x, y), statistic=myCor, R=200))

ORDINARY NONPARAMETRIC BOOTSTRAP


Call:
boot(data = cbind(x, y), statistic = myCor, R = 200)


Bootstrap Statistics :
? ? original? ? ? bias? ? std. error
t1* 0.9939528 0.0008263766 0.001850004

> boot.ci(b, type="bca")
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 200 bootstrap replicates

CALL : 
boot.ci(boot.out = b, type = "bca")

Intervals : 
Level? ? ? BCa? ? ? ? ? 
95%? ( 0.9895,? 0.9969 )? 
Calculations and Intervals on Original Scale
Warning : BCa Intervals used Extreme Quantiles
Some BCa intervals may be unstable
Warning message:
In norm.inter(t, adj.alpha) : extreme order statistics used as endpoints

--------------- snip ---------------

Note that 200 bootstrap replications are generally sufficient for bootstrap standard errors (a normal-theory CI would be a poor choice here, unless you transform the correlation coefficient), but really aren't enough for a BCa interval.

I hope this helps,
 John



------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
??? 
On Sat, 20 Dec 2014 20:36:57 +0000 (UTC)

> Hi to everyone,
> I am trying to calculate the Bca bootstrap confidence intervals for the Pearson coefficient.
> x=Dataset$math.testy=Dataset$geo.testcor(x,y,method="pearson")[1] 0.6983799
> boot.ci(cor, conf=0.95, type=bca)Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
> 
> I have tried as well to calculate the Pearson coefficient using bootstrap and then to calculate the Bca bootstrap CIs of the Pearson. It doesn't work either.?
> boot(data = cbind(x, y), statistic = cor, R = 200)
> 
> ORDINARY NONPARAMETRIC BOOTSTRAP
> 
> 
> Call:
> boot(data = cbind(x, y), statistic = cor, R = 200)
> 
> 
> Bootstrap Statistics :
>? ? ? original? ? bias? ? std. error
> t1* -0.6243713 0.6295142? 0.2506267
> t2* -0.1366533 0.1565392? 0.2579134
> > boot.ci(cor, conf=0.95, type=bca)
> Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
> Many thanks to tell me how to correct my R script to get the Bca CIs for my Pearson coefficient. Best regards, looking forward to reading you,
> SV
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

??? 
??? 


  
	[[alternative HTML version deleted]]


From jane.synnergren at his.se  Sun Dec 21 22:54:39 2014
From: jane.synnergren at his.se (Jane Synnergren)
Date: Sun, 21 Dec 2014 21:54:39 +0000
Subject: [R] how update to latest version of R on mac
In-Reply-To: <CAGxgkWhkpafi2BoBZTDuvrpZ=9Js4T4tWLgAFtjdSyFHhoJiWA@mail.gmail.com>
References: <D0BA5DA8.57B1F%jane.synnergren@his.se>
	<CAGxgkWidB0=+odRRfgqV4aDjYMF_kgSds2DggwuhdqF=ge=P=w@mail.gmail.com>
	<D0BC4E58.57BDA%jane.synnergren@his.se>
	<CAGxgkWhkpafi2BoBZTDuvrpZ=9Js4T4tWLgAFtjdSyFHhoJiWA@mail.gmail.com>
Message-ID: <D0BCFF7F.57C81%jane.synnergren@his.se>

Thanks for your response Tom, now I have successfully upgraded and my affy package problem seems to be is solved with this latest version of R and latest version of Bioconductor.

Thanks!
/Jane

-------------------------------------------------------------------------------
Jane Synnergren, PhD
Systems Biology Research Center
School of Bioscience
University of Sk?vde
Sweden

Contact:
email: jane.synnergren at his.se
mobile: +46 (0)708 806495
webpage: his.se/synj

Postal Address:  Visiting address:
Box 408 Kanikegr?nd 3A
541 28 Sk?vde Sk?vde

From: Thomas Adams <tea3rd at gmail.com<mailto:tea3rd at gmail.com>>
Date: Sunday, December 21, 2014 4:35 PM
To: Jane Synnergren <jane.synnergren at his.se<mailto:jane.synnergren at his.se>>
Cc: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] how update to latest version of R on mac

Jane,

My sincere apologies; I don't know what I was seeing/thinking -- your original post was correct. Namely, you should download and install: http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg (although, I am use to using the main mirror http://cran.r-project.org/bin/macosx/R-3.1.2-snowleopard.pkg) -- but that should not make a difference. The documentation does state...

R 3.1.2 binary for Mac OS X 10.6 (Snow Leopard) and higher, signed package. Contains R 3.1.2 framework, R.app GUI 1.65 in 64-bit for Intel Macs. The above file is an Installer package which can be installed by double-clicking. Depending on your browser, you may need to press the control key and click on this link to download the file.

So, this should be the way to go. I'm glad you double checked!!

Tom

On Sun, Dec 21, 2014 at 2:21 AM, Jane Synnergren <jane.synnergren at his.se<mailto:jane.synnergren at his.se>> wrote:
Thanks Tom!
One more quick question, regarding choosing mavericks.pkg or snowleopard.pkg.
Will mavericks work for me though I have OS X Lion 10.7.5? I thought I had to choose snowleopard but are still an unexperienced mac user and have really no idea.

Just want to dubble check before I run the installation.

/Jane
-------------------------------------------------------------------------------
Jane Synnergren, PhD
Systems Biology Research Center
School of Bioscience
University of Sk?vde
Sweden

Contact:
email: jane.synnergren at his.se<mailto:jane.synnergren at his.se>
mobile: +46 (0)708 806495
webpage: his.se/synj<http://his.se/synj>

Postal Address:  Visiting address:
Box 408 Kanikegr?nd 3A
541 28 Sk?vde Sk?vde

From: Thomas Adams <tea3rd at gmail.com<mailto:tea3rd at gmail.com>>
Date: Sunday, December 21, 2014 2:06 AM
To: Jane Synnergren <jane.synnergren at his.se<mailto:jane.synnergren at his.se>>
Cc: R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] how update to latest version of R on mac

Jane,

It's possible, since you are using Mac OS X Lion (10.7.5), you need the R version for that, which can be found here: http://cran.r-project.org/bin/macosx/old/R-3.1.1-mavericks.pkg

Cheers!
Tom

On Fri, Dec 19, 2014 at 2:56 PM, Jane Synnergren <jane.synnergren at his.se<mailto:jane.synnergren at his.se>> wrote:
Hi,
I get following error when trying to update the affy package to latest
version.

Error: cannot remove prior installation of package ?affy?

I think it is because affy requires R 3.1.1 and I have 3.0.2

I try to find a guide how I do to upgrade from 3.0.2 to latest version on
mac, but cannot find any good description. Can anyone guide me?

Do I just download R for mac (R-3.1.2-snowleopard.pkg) from
<http://ftp.sunet.se/pub/lang/CRAN/bin/macosx/R-3.1.2-snowleopard.pkg> and
dubbelclick?

What will happen with all installed packages?
I have OS X Lion 10.7.5
Which version number is stable and reliable?

I also need a guide of how to update to latest version of  bioconductor on
mac.

Descriptions for windows is available everywhere.

/Jane


---------------------------------------------------------------------------
----
Jane Synnergren, PhD
Systems Biology Research Center
School of Bioscience
University of Sk?vde
Sweden

Contact:
email: jane.synnergren at his.se<mailto:jane.synnergren at his.se>
mobile: +46 (0)708 806495<tel:%2B46%20%280%29708%20806495>
webpage: his.se/synj<http://his.se/synj>

Postal Address:                         Visiting address:

Box 408                                 Kanikegr?nd 3A
541 28 Sk?vde                   Sk?vde

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.






	[[alternative HTML version deleted]]


From eliza_botto at hotmail.com  Sun Dec 21 20:25:41 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Sun, 21 Dec 2014 19:25:41 +0000
Subject: [R] 6 regions around a point
Message-ID: <BLU170-W73DF98AA6BCC87553AB14389690@phx.gbl>

Dear UseRs,
A point was plotted by the following command
 plot(2,4,ylim=c(0,10),xlim=c(0,5))
how to divide the space around the plotted point into six regions each of 60 degree as shown in the Figure 2a) in the following link http://infolab.usc.edu/csci599/Fall2007/papers/b-2.pdf.
Thankyou very much in advance,
Eliza.



 		 	   		  
	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Mon Dec 22 03:15:47 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 21 Dec 2014 21:15:47 -0500
Subject: [R] 6 regions around a point
In-Reply-To: <BLU170-W73DF98AA6BCC87553AB14389690@phx.gbl>
References: <BLU170-W73DF98AA6BCC87553AB14389690@phx.gbl>
Message-ID: <DE9B06A9-ABB0-44C3-AFBF-282D1CD9ADEE@utoronto.ca>

# A general approach to "lines" on a plot is provided by segments().
# However in this special case you can use abline(). 
# You have to take care though that your aspect ratio for the
# plot is exactly 1. Therefore you have to set the asp parameter.

p <- c(2,4)
plot(p[1], p[2], xlim=c(0,5), ylim=c(0,10), xlab="", ylab="", asp=1.0)
abline(h=p[2], lty=2)
abline(p[2] - (p[1]*tan(pi/3)),  tan(pi/3), lty=2)
abline(p[2] + (p[1]*tan(pi/3)), -tan(pi/3), lty=2)

# If you need to reproduce Fig. 2a more exactly:
#  - plot your frame a bit larger, don't draw axes
#  - draw the ablines
#  - draw two arrows to symbolize the coordinate axes

p <- c(2,4)
plot(p[1], p[2], xlim=c(-0.5,10.5), ylim=c(-0.5,10.5), , xlab="", ylab="", axes=n, asp=1.0)
abline(h=p[2], lty=2)
abline(p[2] - (p[1]*tan(pi/3)),  tan(pi/3), lty=2)
abline(p[2] + (p[1]*tan(pi/3)), -tan(pi/3), lty=2)
arrows(0, 0, 10, 0, length=0.1)
arrows(0, 0, 0, 10, length=0.1)


Cheers,
B.

On Dec 21, 2014, at 2:25 PM, eliza botto <eliza_botto at hotmail.com> wrote:

> Dear UseRs,
> A point was plotted by the following command
> plot(2,4,ylim=c(0,10),xlim=c(0,5))
> how to divide the space around the plotted point into six regions each of 60 degree as shown in the Figure 2a) in the following link http://infolab.usc.edu/csci599/Fall2007/papers/b-2.pdf.
> Thankyou very much in advance,
> Eliza.
> 
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Mon Dec 22 05:46:21 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Sun, 21 Dec 2014 22:46:21 -0600
Subject: [R] 6 regions around a point
In-Reply-To: <BLU170-W73DF98AA6BCC87553AB14389690@phx.gbl>
References: <BLU170-W73DF98AA6BCC87553AB14389690@phx.gbl>
Message-ID: <5497A21D.8080608@mail.usask.ca>

You may try this:

 > get.coords.circle <- function(x0, y0, r, len, rot){
+ by <- seq(from=-pi, to=pi, length.out=len)
+ x <- r*cos(by+rot) + x0
+ y <- r*sin(by+rot) + y0
+ coords <- cbind(x,y)
+ coords[!duplicated(coords),]
+ }
 > xtms <- get.coords.circle(x0=2, y0=4, r=2, len=7, rot=0)
 > xtms1 <- get.coords.circle(x0=2, y0=4, r=1, len=7, rot=10)
 >
 > plot(xtms, type="n")
 > segments(x0=xtms[1:3,1], y0=xtms[1:3,2],
+ x=xtms[4:6,1], y=xtms[4:6,2])
 > text(xtms[c(4,5,6),], labels=paste("line1", 1:3, sep="_"))
 > text(xtms1, labels=paste("S", 1:6, sep="_"))
 > points(x=2, y=4, cex=3)
 >

Please see the output.  Is this what you are looking for?  I hope this 
helps.

Chel Hee Lee

On 12/21/2014 01:25 PM, eliza botto wrote:
> Dear UseRs,
> A point was plotted by the following command
>   plot(2,4,ylim=c(0,10),xlim=c(0,5))
> how to divide the space around the plotted point into six regions each of 60 degree as shown in the Figure 2a) in the following link http://infolab.usc.edu/csci599/Fall2007/papers/b-2.pdf.
> Thankyou very much in advance,
> Eliza.
>
>
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bcrombie at utk.edu  Mon Dec 22 05:32:12 2014
From: bcrombie at utk.edu (bcrombie)
Date: Sun, 21 Dec 2014 20:32:12 -0800 (PST)
Subject: [R] Make 2nd col of 2-col df into header row of same df then
 adjust col1 data display
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CEE5117EC5@kmbx4.utk.tennessee.edu>
References: <1418872514464-4700878.post@n4.nabble.com>
	<alpine.BSF.2.00.1412180750570.44990@pedal.dcn.davis.ca.us>
	<54932E4B.8030009@mail.usask.ca> <5493B914.4030903@mail.usask.ca>
	<CAHuTOvr=W5USurZ1p-F+eYLkUcjTo7q8nXHAj9wg-ZTGzdf6+g@mail.gmail.com>
	<965F3F18EFD.00000738jrkrideau@inbox.com>
	<559C998F7039D84C9793AE43D9BBE9CEE5117EC5@kmbx4.utk.tennessee.edu>
Message-ID: <1419222732923-4701020.post@n4.nabble.com>

Here's the answer to my question that I came up with after working with all
of your suggestions.  It's not elegant by any means but gets the job done:

MERGE_PViol.Detail.Per.Case <-
read.csv("~/FOIA_FLSA/MERGE_PViol.Detail.Per.Case_for_rtf10.csv",
stringsAsFactors=TRUE)
# select only certain columns from original dataset
PViol.Type.Per.Case <- MERGE_PViol.Detail.Per.Case[,c("CaseID",
"Primary.Viol.Type")]

# create a dataframe with all the primary violation types possible
Primary.Viol.Type <- c("BW.BackWages",
                "LD.Liquid_Damages",
                "MW.Minimum_Wage",
                "OT.Overtime",
                "RK.Records_FLSA",
                "V.Poster_Other",
                "AS.Age",
                "BW.WHMIS_BackWages",
                "HS.Hours",
                "OA.HazOccupationAg",
                "ON.HazOccupationNonAg",
                "R3.Reg3AgeOccupation",
                "RK.Records_CL",
                "V.Other")

CaseID  <- c('1','2','3','4','5','6','7','8','9','10','11','12','13','14')
PViol.Type.df <- data.frame(CaseID, Primary.Viol.Type)

# merge original data with primary viol type template dataframe
df<- merge(PViol.Type.Per.Case, PViol.Type.df, all=TRUE)
library(reshape2)
df1<-dcast(df, df[,1] ~ df[,2])

# delete rows with template CaseID's;
# replace strings with "1"
colnames(df1)[1] <- "CaseID"
remove <- c('1','2','3','4','5','6','7','8','9','10','11','12','13','14')
rownames(df1) <- df1$CaseID
df2 <- df1[!df1$CaseID %in% remove, ]
df2[!is.na(df2)] <- 1
df2$CaseID <- rownames(df2)




--
View this message in context: http://r.789695.n4.nabble.com/Make-2nd-col-of-2-col-df-into-header-row-of-same-df-then-adjust-col1-data-display-tp4700878p4701020.html
Sent from the R help mailing list archive at Nabble.com.


From podaesmeralda at gmail.com  Mon Dec 22 14:17:52 2014
From: podaesmeralda at gmail.com (ESMERALDA PODA)
Date: Mon, 22 Dec 2014 14:17:52 +0100
Subject: [R] VaR and ES through MonteCarlo method
Message-ID: <CAANpeHLAKgNM_S+B3_JG2-wKxL1saSeFSLx0gDto1aBvAa=cPA@mail.gmail.com>

Hi everybody,

This is the homework I am trying to solve.

Ex. Assume that you have a position of 144530 shares of Bill inc.. The
object Y2 contains an iid sample of the returns for these shares. Assume
that data follow a Student distribution.

   1.

   Compute the maximum likelihood estimate for the model.
    2.

   Compute the estimation of V aR? and of ES? for ? = 0.99 based on the
   obtained estimates, using a parametric formula or with the pure Monte Carlo
   method
    3. Obtain a bootstrap confidence interval for V aR? and of ES? for ? = 0
   .99 at a confidence level 0.90, using B = 1000 replications.

I solved point 1. (you can see the screenshot attached).
However in point 2, where I have to compute VaR and ES, based on the
estimates obtained in point 1. I typed this:

#POINT 2

q<-114530

n.val <- 10000

x <- rt(n=n.val, obj=mle.t)

loss.mc <- -Q*x

but, I obtain error. I am working with a student distribution. I need
particularly
the obj=mle.t since I need to work on the estimate I have obtained.

Can somebody, who is familiar with VaR and ES give me some hint through
this?

I would really appreciate this.

Best

Esmeralda
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Schermata 2014-12-22 alle 12.04.16.png
Type: image/png
Size: 27610 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141222/ebbf7952/attachment.png>

From mjoey at gmx.de  Mon Dec 22 14:45:17 2014
From: mjoey at gmx.de (najuzz)
Date: Mon, 22 Dec 2014 05:45:17 -0800 (PST)
Subject: [R] number of individuals where X=0 during all periods
 (longitudinal data)
Message-ID: <1419255917491-4701023.post@n4.nabble.com>

#Hi guys, 

#I would like to count the number of individuals that receive X=0 troughout
their observational period.
#example dataset:

ID<-c(1,1,1,1,2,2,3,3,3)
X<-c(0,1,2,1,0,0,0,0,0)
Time<-c(1,2,3,4,1,2,1,2,3)
Test<-data.frame(ID,X,Time)

# Individuals 2 and 3 have x=0 during all their periods. The count should
hence equal to two. I simply have 
# no clue how R could solve this for me. As an addon, I would also like to
know the number of individuals  #that report X=0 during all periods plus
have at least 3 weeks of observations. The answer would be one in #this
sample datset.

#Thank you



--
View this message in context: http://r.789695.n4.nabble.com/number-of-individuals-where-X-0-during-all-periods-longitudinal-data-tp4701023.html
Sent from the R help mailing list archive at Nabble.com.


From dcarlson at tamu.edu  Mon Dec 22 17:46:32 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 22 Dec 2014 16:46:32 +0000
Subject: [R] number of individuals where X=0 during all periods
 (longitudinal data)
In-Reply-To: <1419255917491-4701023.post@n4.nabble.com>
References: <1419255917491-4701023.post@n4.nabble.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FC2F39@mb02.ads.tamu.edu>

Spend a little time with aggregate()

?aggregate

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of najuzz
Sent: Monday, December 22, 2014 7:45 AM
To: r-help at r-project.org
Subject: [R] number of individuals where X=0 during all periods (longitudinal data)

#Hi guys, 

#I would like to count the number of individuals that receive X=0 troughout
their observational period.
#example dataset:

ID<-c(1,1,1,1,2,2,3,3,3)
X<-c(0,1,2,1,0,0,0,0,0)
Time<-c(1,2,3,4,1,2,1,2,3)
Test<-data.frame(ID,X,Time)

# Individuals 2 and 3 have x=0 during all their periods. The count should
hence equal to two. I simply have 
# no clue how R could solve this for me. As an addon, I would also like to
know the number of individuals  #that report X=0 during all periods plus
have at least 3 weeks of observations. The answer would be one in #this
sample datset.

#Thank you



--
View this message in context: http://r.789695.n4.nabble.com/number-of-individuals-where-X-0-during-all-periods-longitudinal-data-tp4701023.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From chl948 at mail.usask.ca  Mon Dec 22 19:54:01 2014
From: chl948 at mail.usask.ca (Chel Hee Lee)
Date: Mon, 22 Dec 2014 12:54:01 -0600
Subject: [R] number of individuals where X=0 during all periods
 (longitudinal data)
In-Reply-To: <1419255917491-4701023.post@n4.nabble.com>
References: <1419255917491-4701023.post@n4.nabble.com>
Message-ID: <549868C9.70403@mail.usask.ca>

 > tmp <- split(Test, Test$ID)
 >
 > # number of subjects with X=0 (all periods)
 > x <- lapply(tmp, function(x) all(x$X ==0))
 > length(x[unlist(x)])
[1] 2
 >
 > # number of subjects with X=0 (at least three weeks)
 > x <- lapply(tmp, function(x) sum(x$X==0)>=3)
 > length(x[unlist(x)])
[1] 1
 >

Is this what you are looking for?  I hope this helps.

Chel Hee Lee

On 12/22/2014 7:45 AM, najuzz wrote:
> #Hi guys,
>
> #I would like to count the number of individuals that receive X=0 troughout
> their observational period.
> #example dataset:
>
> ID<-c(1,1,1,1,2,2,3,3,3)
> X<-c(0,1,2,1,0,0,0,0,0)
> Time<-c(1,2,3,4,1,2,1,2,3)
> Test<-data.frame(ID,X,Time)
>
> # Individuals 2 and 3 have x=0 during all their periods. The count should
> hence equal to two. I simply have
> # no clue how R could solve this for me. As an addon, I would also like to
> know the number of individuals  #that report X=0 during all periods plus
> have at least 3 weeks of observations. The answer would be one in #this
> sample datset.
>
> #Thank you
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/number-of-individuals-where-X-0-during-all-periods-longitudinal-data-tp4701023.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nunesmaria at campus.ul.pt  Mon Dec 22 19:26:35 2014
From: nunesmaria at campus.ul.pt (Maria Helena Mourino Silva Nunes)
Date: Mon, 22 Dec 2014 18:26:35 +0000
Subject: [R] Cox model with multiple events - Proportional Hazards Assumption
Message-ID: <CAAG=r6AkqUfpoXPUaU2mDfLrPUmAAo13+bxuUVUEugqp4feNhw@mail.gmail.com>

Dear all,

I'm using the package "survival" for adjusting the Cox model with multiple
events (Prentice, Williams and Peterson Model). I have several covariates,
some of them are time-dependent.

I'm using the function"cox.zph" to check the proportional hazards. Due to
the nature of the time-dependent covariates, I don't need to analyse the
assumptions of the proportional hazards associated with the
time-dependent covariates. Is it right?

?Thanks for your attention.

Best regards,
Helena.

	[[alternative HTML version deleted]]


From podaesmeralda at gmail.com  Mon Dec 22 21:52:40 2014
From: podaesmeralda at gmail.com (podaesmeralda)
Date: Mon, 22 Dec 2014 21:52:40 +0100
Subject: [R] R: VaR and ES in R
Message-ID: <kr9ixhpbtn10ukp2g0k4236r.1419281560227@email.android.com>




From my Android phone on T-Mobile. The first nationwide 4G network.

-------- Messaggio originale --------
Da: ESMERALDA PODA <podaesmeralda at gmail.com> 
Data:12/22/2014  02:44 PM  (GMT+01:00) 
A: r-help at r-project.org 
Oggetto: VaR and ES in R 

Hi everybody,

This is the homework I am trying to solve.

Ex. Assume that you have a position of 144530 shares of?Bill inc.. The object?Y2?contains an iid sample of the returns for these shares. Assume that data follow a Student distribution.

Compute the maximum likelihood estimate for the model.

Compute the estimation of V?aR??and of?ES??for???= 0.99 based on the obtained estimates, using a parametric formula or with the pure Monte Carlo method

Obtain a bootstrap confidence interval for?V aR??and of?ES??for???= 0.99 at a confidence level 0.90, using?B?= 1000 replications.?
I solved point 1. (you can see the screenshot attached).
However in point 2,?where I have to compute VaR and ES, based on the estimates obtained in point 1. I typed this:?
#POINT 2

q<-114530

n.val <- 10000

x <- rt(n=n.val, obj=mle.t)

loss.mc?<- -Q*x

but, I obtain error. I am working with a student distribution. I need?particularly the obj=mle.t since I need to?work on the estimate I have obtained.

Can somebody, who is familiar with VaR and ES give me some hint through this?

I would really appreciate this.

Best


Attachments area
Preview attachment Schermata 2014-12-22 alle 12.04.16.png


Schermata 2014-12-22 alle 12.04.16.png

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Dec 22 22:42:53 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 22 Dec 2014 13:42:53 -0800
Subject: [R] VaR and ES through MonteCarlo method
In-Reply-To: <CAANpeHLAKgNM_S+B3_JG2-wKxL1saSeFSLx0gDto1aBvAa=cPA@mail.gmail.com>
References: <CAANpeHLAKgNM_S+B3_JG2-wKxL1saSeFSLx0gDto1aBvAa=cPA@mail.gmail.com>
Message-ID: <CCE70D6B-A1CC-44F9-97C1-BB42E4EEF5C7@dcn.davis.CA.us>

Unfortunately for you, there is a no-homework policy on this list. Please read the Posting Guide.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 22, 2014 5:17:52 AM PST, ESMERALDA PODA <podaesmeralda at gmail.com> wrote:
>Hi everybody,
>
>This is the homework I am trying to solve.
>
>Ex. Assume that you have a position of 144530 shares of Bill inc.. The
>object Y2 contains an iid sample of the returns for these shares.
>Assume
>that data follow a Student distribution.
>
>   1.
>
>   Compute the maximum likelihood estimate for the model.
>    2.
>
>   Compute the estimation of V aR? and of ES? for ? = 0.99 based on the
>obtained estimates, using a parametric formula or with the pure Monte
>Carlo
>   method
>3. Obtain a bootstrap confidence interval for V aR? and of ES? for ? =
>0
>   .99 at a confidence level 0.90, using B = 1000 replications.
>
>I solved point 1. (you can see the screenshot attached).
>However in point 2, where I have to compute VaR and ES, based on the
>estimates obtained in point 1. I typed this:
>
>#POINT 2
>
>q<-114530
>
>n.val <- 10000
>
>x <- rt(n=n.val, obj=mle.t)
>
>loss.mc <- -Q*x
>
>but, I obtain error. I am working with a student distribution. I need
>particularly
>the obj=mle.t since I need to work on the estimate I have obtained.
>
>Can somebody, who is familiar with VaR and ES give me some hint through
>this?
>
>I would really appreciate this.
>
>Best
>
>Esmeralda
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Mon Dec 22 23:53:54 2014
From: syen04 at gmail.com (Steven Yen)
Date: Mon, 22 Dec 2014 17:53:54 -0500
Subject: [R] Automating regression
In-Reply-To: <7.1.0.9.2.20141214080323.052c49c8@gmail.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<7.1.0.9.2.20141214080323.052c49c8@gmail.com>
Message-ID: <5498a102.6942ec0a.4ed4.ffffdaaa@mx.google.com>

How do I specify the type of regression in calling a procedure/
In the following I call the procedure to do a probit regression. Of 
course, I can change "probit" into "lm" in procedure "myreg" to do a 
linear regression.

My question is, how do I automate this (choice of lm or probit) in 
calling "myreg", with a proper input (e.g., model=lm)? Thank you.

---
eq1<-d~sex+age+children
b<-myreg(eq1,data=mydata); summary(b)

myreg<-function(formula,data){
data<-model.frame(formula,data)
reg<-probit(formula,data=data)
return(reg)
}


From gunter.berton at gene.com  Tue Dec 23 00:08:28 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 22 Dec 2014 15:08:28 -0800
Subject: [R] Automating regression
In-Reply-To: <5498a102.6942ec0a.4ed4.ffffdaaa@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<7.1.0.9.2.20141214080323.052c49c8@gmail.com>
	<5498a102.6942ec0a.4ed4.ffffdaaa@mx.google.com>
Message-ID: <CACk-te1KcNZ5EFgtfJygQ7G3K1E0Y6oNGe5yG8XN84iNRo5g4A@mail.gmail.com>

"Automate" is vague and ill-defined. But perhaps ?do.call is what
you're looking for; e.g.

myProc <- function(FUN, ...) do.call(FUN,...)

This is one of the cool things about functional type programming --
you can pass functions as arguments.

If this is not it, maybe someone else will groc what you mean -- or
you could define yourself more clearly.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Dec 22, 2014 at 2:53 PM, Steven Yen <syen04 at gmail.com> wrote:
> How do I specify the type of regression in calling a procedure/
> In the following I call the procedure to do a probit regression. Of course,
> I can change "probit" into "lm" in procedure "myreg" to do a linear
> regression.
>
> My question is, how do I automate this (choice of lm or probit) in calling
> "myreg", with a proper input (e.g., model=lm)? Thank you.
>
> ---
> eq1<-d~sex+age+children
> b<-myreg(eq1,data=mydata); summary(b)
>
> myreg<-function(formula,data){
> data<-model.frame(formula,data)
> reg<-probit(formula,data=data)
> return(reg)
> }
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Dec 23 00:12:19 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 22 Dec 2014 15:12:19 -0800
Subject: [R] Automating regression
In-Reply-To: <CACk-te1KcNZ5EFgtfJygQ7G3K1E0Y6oNGe5yG8XN84iNRo5g4A@mail.gmail.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<7.1.0.9.2.20141214080323.052c49c8@gmail.com>
	<5498a102.6942ec0a.4ed4.ffffdaaa@mx.google.com>
	<CACk-te1KcNZ5EFgtfJygQ7G3K1E0Y6oNGe5yG8XN84iNRo5g4A@mail.gmail.com>
Message-ID: <CACk-te1Mjr84qSPHNqgkKczrA=Q8NPP1VNccKOw0izVsHCuKEw@mail.gmail.com>

.. that should have been either

myProc <- function(FUN, ...) do.call(FUN,list(...))

or

myProc <- function(FUN, ...) FUN(...)

My other comments still apply.



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Dec 22, 2014 at 3:08 PM, Bert Gunter <bgunter at gene.com> wrote:
> "Automate" is vague and ill-defined. But perhaps ?do.call is what
> you're looking for; e.g.
>
> myProc <- function(FUN, ...) do.call(FUN,...)
>
> This is one of the cool things about functional type programming --
> you can pass functions as arguments.
>
> If this is not it, maybe someone else will groc what you mean -- or
> you could define yourself more clearly.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Mon, Dec 22, 2014 at 2:53 PM, Steven Yen <syen04 at gmail.com> wrote:
>> How do I specify the type of regression in calling a procedure/
>> In the following I call the procedure to do a probit regression. Of course,
>> I can change "probit" into "lm" in procedure "myreg" to do a linear
>> regression.
>>
>> My question is, how do I automate this (choice of lm or probit) in calling
>> "myreg", with a proper input (e.g., model=lm)? Thank you.
>>
>> ---
>> eq1<-d~sex+age+children
>> b<-myreg(eq1,data=mydata); summary(b)
>>
>> myreg<-function(formula,data){
>> data<-model.frame(formula,data)
>> reg<-probit(formula,data=data)
>> return(reg)
>> }
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Dec 22 20:52:21 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 22 Dec 2014 11:52:21 -0800
Subject: [R] number of individuals where X=0 during all periods
 (longitudinal data)
In-Reply-To: <549868C9.70403@mail.usask.ca>
References: <1419255917491-4701023.post@n4.nabble.com>
	<549868C9.70403@mail.usask.ca>
Message-ID: <CAF8bMcb_QbCSwKA=4dRA3gYEvOSfgUg4iwZRr29J68jVfSJqgA@mail.gmail.com>

Another approach to to make a table and extract your summaries from the
table:

  > tbl <- with(Test, table(ID, IsZero=X==0))
  > tbl
     IsZero
  ID  FALSE TRUE
    1     3    1
    2     0    2
    3     0    3
  > sum(tbl[,"FALSE"] == 0)
  [1] 2
  > sum(tbl[,"FALSE"] == 0 & rowSums(tbl)>=3)
  [1] 1

Remove the calls to sum() from those expressions and you will see which
ID's satisfy the conditions.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 22, 2014 at 10:54 AM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>
> > tmp <- split(Test, Test$ID)
> >
> > # number of subjects with X=0 (all periods)
> > x <- lapply(tmp, function(x) all(x$X ==0))
> > length(x[unlist(x)])
> [1] 2
> >
> > # number of subjects with X=0 (at least three weeks)
> > x <- lapply(tmp, function(x) sum(x$X==0)>=3)
> > length(x[unlist(x)])
> [1] 1
> >
>
> Is this what you are looking for?  I hope this helps.
>
> Chel Hee Lee
>
> On 12/22/2014 7:45 AM, najuzz wrote:
>
>> #Hi guys,
>>
>> #I would like to count the number of individuals that receive X=0
>> troughout
>> their observational period.
>> #example dataset:
>>
>> ID<-c(1,1,1,1,2,2,3,3,3)
>> X<-c(0,1,2,1,0,0,0,0,0)
>> Time<-c(1,2,3,4,1,2,1,2,3)
>> Test<-data.frame(ID,X,Time)
>>
>> # Individuals 2 and 3 have x=0 during all their periods. The count should
>> hence equal to two. I simply have
>> # no clue how R could solve this for me. As an addon, I would also like to
>> know the number of individuals  #that report X=0 during all periods plus
>> have at least 3 weeks of observations. The answer would be one in #this
>> sample datset.
>>
>> #Thank you
>>
>>
>>
>> --
>> View this message in context: http://r.789695.n4.nabble.com/
>> number-of-individuals-where-X-0-during-all-periods-
>> longitudinal-data-tp4701023.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ciaranroberts at hotmail.com  Mon Dec 22 21:14:07 2014
From: ciaranroberts at hotmail.com (Ciaran Roberts)
Date: Mon, 22 Dec 2014 20:14:07 +0000
Subject: [R] Help re. Fitting non-linear dynamic model to time series data
Message-ID: <DUB118-W273B97949DFDCA1779DA7DB6560@phx.gbl>

Hey I'm trying to fit the non-linear dynamical model as shown in the 
image to some time series data. The idea is also to utilize k-fold cross
 validation to estimate the prediction error. The term Po will be 
assumed to be constant over a certain timer period and will have to be 
estimated for each time period.


I have extensive experience coding but limited experience in R. I
 understand what I'm trying to do but am unfamiliar with the packages or
 how to fit the model and utilize k-fold cross validation, especially 
for time series data. 


Any help/guidance would be really appreciated.

	
	
	
	 		 	   		  
-------------- next part --------------
A non-text attachment was scrubbed...
Name: model.png
Type: image/png
Size: 9631 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141222/32e7a243/attachment.png>

From gunter.berton at gene.com  Tue Dec 23 06:12:03 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 22 Dec 2014 21:12:03 -0800
Subject: [R] Help re. Fitting non-linear dynamic model to time series
	data
In-Reply-To: <DUB118-W273B97949DFDCA1779DA7DB6560@phx.gbl>
References: <DUB118-W273B97949DFDCA1779DA7DB6560@phx.gbl>
Message-ID: <CACk-te0ygMDXUQbNLV3De2hsFpsJ5FVWmmBNZhvb=oJai2rCHQ@mail.gmail.com>

Hey, read and follow the posting guide -- go through a tutorial or
two, post some code and data, perhaps. Also check out CRAN's time
series task view here:
http://cran.r-project.org/web/views/TimeSeries.html.

You might also try stats.stackexchange.com , as this seems to have
more to do with statistics than R coding.

Cheers,
Bert

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Dec 22, 2014 at 12:14 PM, Ciaran Roberts
<ciaranroberts at hotmail.com> wrote:
> Hey I'm trying to fit the non-linear dynamical model as shown in the
> image to some time series data. The idea is also to utilize k-fold cross
>  validation to estimate the prediction error. The term Po will be
> assumed to be constant over a certain timer period and will have to be
> estimated for each time period.
>
>
> I have extensive experience coding but limited experience in R. I
>  understand what I'm trying to do but am unfamiliar with the packages or
>  how to fit the model and utilize k-fold cross validation, especially
> for time series data.
>
>
> Any help/guidance would be really appreciated.
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From thanoon.younis80 at gmail.com  Tue Dec 23 08:46:22 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Tue, 23 Dec 2014 10:46:22 +0300
Subject: [R] R2WinBUGS
Message-ID: <CABLo8nEWH=fpqVNE8Bc60PJO8S1kd3io7YawCwZ8bwozZe9w1g@mail.gmail.com>

Dear all R-members
I have a problem with R when i wanted to call WinBUGS from R as following:

#Call WinBUGS
    model<-bugs(data,inits,parameters,model.file="D:/Run/model.txt",
    n.chains=2,n.iter=5000,n.burnin=1000,n.thin=1,'DIC=True',
    bugs.directory="c:/Program Files/WinBUGS14/",
    working.directory="D:/Run/")


and the error is

Error in bugs.run(n.burnin, bugs.directory, WINE = WINE, useWINE = useWINE,
 :
  Look at the log file and
try again with 'debug=TRUE' to figure out what went wrong within Bugs.


how can i solve this problem please?

Any guidance would be highly appreciated.










-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Tue Dec 23 09:24:13 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Tue, 23 Dec 2014 08:24:13 +0000
Subject: [R] number of individuals where X=0 during all periods
 (longitudinal data)
In-Reply-To: <4444a7d0094b482d9618bd5ef5738093@EX-0-HT0.lancs.local>
References: <1419255917491-4701023.post@n4.nabble.com>
	<549868C9.70403@mail.usask.ca>
	<4444a7d0094b482d9618bd5ef5738093@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPGmgBUzeuw9iEUMrPAsoWQYFUFG_dbjO==oxBjsxNs8Q@mail.gmail.com>

obligatory dplyr solution:

library(dplyr)
 zeroes = Test %>% group_by(ID) %>% summarise(Zs=all(X==0))

 - that gives you a data frame of unique ID and Zs==TRUE if that ID
has all zeroes. With that you just sum(zeroes$Zs) to get the total
number with all zeroes. Or add "%>% filter(Zs) %>% nrow()" to the
pipeline to get it directly.

Its well worth learning a bit about the dplyr and tidyr package,
especially if you have a lot of things you might want to do by ID in a
data frame.

Barry




On Mon, Dec 22, 2014 at 7:52 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Another approach to to make a table and extract your summaries from the
> table:
>
>   > tbl <- with(Test, table(ID, IsZero=X==0))
>   > tbl
>      IsZero
>   ID  FALSE TRUE
>     1     3    1
>     2     0    2
>     3     0    3
>   > sum(tbl[,"FALSE"] == 0)
>   [1] 2
>   > sum(tbl[,"FALSE"] == 0 & rowSums(tbl)>=3)
>   [1] 1
>
> Remove the calls to sum() from those expressions and you will see which
> ID's satisfy the conditions.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Dec 22, 2014 at 10:54 AM, Chel Hee Lee <chl948 at mail.usask.ca> wrote:
>>
>> > tmp <- split(Test, Test$ID)
>> >
>> > # number of subjects with X=0 (all periods)
>> > x <- lapply(tmp, function(x) all(x$X ==0))
>> > length(x[unlist(x)])
>> [1] 2
>> >
>> > # number of subjects with X=0 (at least three weeks)
>> > x <- lapply(tmp, function(x) sum(x$X==0)>=3)
>> > length(x[unlist(x)])
>> [1] 1
>> >
>>
>> Is this what you are looking for?  I hope this helps.
>>
>> Chel Hee Lee
>>
>> On 12/22/2014 7:45 AM, najuzz wrote:
>>
>>> #Hi guys,
>>>
>>> #I would like to count the number of individuals that receive X=0
>>> troughout
>>> their observational period.
>>> #example dataset:
>>>
>>> ID<-c(1,1,1,1,2,2,3,3,3)
>>> X<-c(0,1,2,1,0,0,0,0,0)
>>> Time<-c(1,2,3,4,1,2,1,2,3)
>>> Test<-data.frame(ID,X,Time)
>>>
>>> # Individuals 2 and 3 have x=0 during all their periods. The count should
>>> hence equal to two. I simply have
>>> # no clue how R could solve this for me. As an addon, I would also like to
>>> know the number of individuals  #that report X=0 during all periods plus
>>> have at least 3 weeks of observations. The answer would be one in #this
>>> sample datset.
>>>
>>> #Thank you
>>>
>>>
>>>
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/
>>> number-of-individuals-where-X-0-during-all-periods-
>>> longitudinal-data-tp4701023.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Tue Dec 23 10:05:47 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 23 Dec 2014 10:05:47 +0100
Subject: [R] Do NOT use ifelse() if you can use if(.) else . [was "Checking
	.."]
In-Reply-To: <548d9f24.886eec0a.72bc.ffffafdd@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
	<A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>
	<548d9f24.886eec0a.72bc.ffffafdd@mx.google.com>
Message-ID: <21657.12395.795068.799342@stat.math.ethz.ch>

>>>>> Steven Yen <syen04 at gmail.com>
>>>>>     on Sun, 14 Dec 2014 09:30:56 -0500 writes:
>>>>> Steven Yen <syen04 at gmail.com>
>>>>>     on Sun, 14 Dec 2014 09:30:56 -0500 writes:

    > Thanks. This worked!! :)
    > Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)

"worked",  yes.

But please --- for the mailing list archives ---
do use better code.

Unfortunately, ifelse() is used and has been advertized much too
often in cases where it is very sub-optimal efficiency wise. 
ifelse(Cond, A, B)  should only be used  when the condition
'Cond', a logical vector can be (and typically is) of length > 1
{and even then, it maybe a nice short cut, but often still suboptimal
 efficiency wise ... but let's not get there}

In cases like this one when the condition 'Cond' is a
simple TRUE or FALSE (i.e. of length 1), using

	if(Cond) A else B

instead of

	ifelse(Cond, A, B)

is

  1. much more R - like  [[ "everything you do is a function call" ]]
     hence much more elegant

  2. considerably more efficient.

  3. :-) less typing: uses two "," less ;-)

  > require(microbenchmark)
  Loading required package: microbenchmark
  > x <- setNames(,LETTERS)
  > y <- setNames(letters, runif(letters))
  > z <- pi
  > microbenchmark(r1 <- ifelse(z > 3, x, y), r2 <- if(z > 3) x else y, times=1000)
  Unit: nanoseconds
			expr  min     lq     mean median     uq   max neval cld
   r1 <- ifelse(z > 3, x, y) 4466 4971.5 5498.928   5244 5673.5 31705  1000   b
   r2 <- if (z > 3) x else y  171  212.0  265.241    264  291.0  3130  1000  a 
  > 

i.e., roughly a factor of 20 times more efficient


Martin Maechler,
ETH Zurich and R Core Team.


    > At 08:43 AM 12/14/2014, Ben Tupper wrote:
    >> Hi,
    >> 
    >> Does this work for you?  It simply tests if the name Fisher is found 
    >> among the names of the elements of spec.
    >> 
    >> obj = list(spec = list)
    >> Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)
    >> 
    >> Cheers,
    >> Ben
    >> 
    >> On Dec 14, 2014, at 8:07 AM, Steven Yen <syen04 at gmail.com> wrote:
    >> 
    >> > My obj does not always come with a logical variable defined. So I do
    >> >
    >> > my.foo <- function(obj,df,digits=5){
    >> > if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
    >> > ...
    >> > }
    >> >
    >> > This works when "Fisher" is defined in/passed from obj. When it 
    >> is not, I get error:
    >> >
    >> > Error in (!is.na("obj$spec$Fisher")) & Fisher :
    >> >  operations are possible only for numeric, logical or complex types
    >> >
    >> > I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.


From pdalgd at gmail.com  Tue Dec 23 12:57:20 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 23 Dec 2014 12:57:20 +0100
Subject: [R] Do NOT use ifelse() if you can use if(.) else . [was
	"Checking .."]
In-Reply-To: <21657.12395.795068.799342@stat.math.ethz.ch>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
	<A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>
	<548d9f24.886eec0a.72bc.ffffafdd@mx.google.com>
	<21657.12395.795068.799342@stat.math.ethz.ch>
Message-ID: <1655417D-B8FB-498D-9825-91709FB2026B@gmail.com>


> On 23 Dec 2014, at 10:05 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> 
> 
> In cases like this one when the condition 'Cond' is a
> simple TRUE or FALSE (i.e. of length 1), using
> 
> 	if(Cond) A else B
> 
> instead of
> 
> 	ifelse(Cond, A, B)
> 
> is
> 
>  1. much more R - like  [[ "everything you do is a function call" ]]
>     hence much more elegant
> 
>  2. considerably more efficient.
> 
>  3. :-) less typing: uses two "," less ;-)
> 

4. Considerably less confusing in terms of the class of the result.

> ifelse (TRUE, Sys.Date(), as.Date("2014-1-1") )
[1] 16427
> ifelse (FALSE, Sys.Date(), as.Date("2014-1-1") )
[1] 16071
> if (TRUE) Sys.Date() else as.Date("2014-1-1") 
[1] "2014-12-23"
> if (FALSE) Sys.Date() else as.Date("2014-1-1") 
[1] "2014-01-01"

(S/R made the Solomonic decision to take the class of the result of ifelse() from the _condition_ part, which is the only possibility common to both cases, but most likely also something that noone would ever actually want.)

 
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Tue Dec 23 15:10:44 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 23 Dec 2014 09:10:44 -0500
Subject: [R] Do NOT use ifelse() if you can use if(.) else . [was
	"Checking	.."]
In-Reply-To: <21657.12395.795068.799342@stat.math.ethz.ch>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
	<A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>
	<548d9f24.886eec0a.72bc.ffffafdd@mx.google.com>
	<21657.12395.795068.799342@stat.math.ethz.ch>
Message-ID: <web-541498052@cgpsrv2.cis.mcmaster.ca>

Hi,

Sorry to chime in late, but here's an alternative solution, without conditionals:

> obj <- list(spec=list("Fisher"=TRUE, "Tukey"=FALSE))

> obj$spec$Fisher
[1] TRUE
 
> !is.null(obj$spec$Fisher) && obj$spec$Fisher
[1] TRUE
 
> obj$spec$Pearson
NULL
 
> !is.null(obj$spec$Pearson) && obj$spec$Pearson
[1] FALSE

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
On Tue, 23 Dec 2014 10:05:47 +0100
 Martin Maechler <maechler at stat.math.ethz.ch> wrote:
> >>>>> Steven Yen <syen04 at gmail.com>
> >>>>>     on Sun, 14 Dec 2014 09:30:56 -0500 writes:
> >>>>> Steven Yen <syen04 at gmail.com>
> >>>>>     on Sun, 14 Dec 2014 09:30:56 -0500 writes:
> 
>     > Thanks. This worked!! :)
>     > Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)
> 
> "worked",  yes.
> 
> But please --- for the mailing list archives ---
> do use better code.
> 
> Unfortunately, ifelse() is used and has been advertized much too
> often in cases where it is very sub-optimal efficiency wise. 
> ifelse(Cond, A, B)  should only be used  when the condition
> 'Cond', a logical vector can be (and typically is) of length > 1
> {and even then, it maybe a nice short cut, but often still suboptimal
>  efficiency wise ... but let's not get there}
> 
> In cases like this one when the condition 'Cond' is a
> simple TRUE or FALSE (i.e. of length 1), using
> 
> 	if(Cond) A else B
> 
> instead of
> 
> 	ifelse(Cond, A, B)
> 
> is
> 
>   1. much more R - like  [[ "everything you do is a function call" ]]
>      hence much more elegant
> 
>   2. considerably more efficient.
> 
>   3. :-) less typing: uses two "," less ;-)
> 
>   > require(microbenchmark)
>   Loading required package: microbenchmark
>   > x <- setNames(,LETTERS)
>   > y <- setNames(letters, runif(letters))
>   > z <- pi
>   > microbenchmark(r1 <- ifelse(z > 3, x, y), r2 <- if(z > 3) x else y, times=1000)
>   Unit: nanoseconds
> 			expr  min     lq     mean median     uq   max neval cld
>    r1 <- ifelse(z > 3, x, y) 4466 4971.5 5498.928   5244 5673.5 31705  1000   b
>    r2 <- if (z > 3) x else y  171  212.0  265.241    264  291.0  3130  1000  a 
>   > 
> 
> i.e., roughly a factor of 20 times more efficient
> 
> 
> Martin Maechler,
> ETH Zurich and R Core Team.
> 
> 
>     > At 08:43 AM 12/14/2014, Ben Tupper wrote:
>     >> Hi,
>     >> 
>     >> Does this work for you?  It simply tests if the name Fisher is found 
>     >> among the names of the elements of spec.
>     >> 
>     >> obj = list(spec = list)
>     >> Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)
>     >> 
>     >> Cheers,
>     >> Ben
>     >> 
>     >> On Dec 14, 2014, at 8:07 AM, Steven Yen <syen04 at gmail.com> wrote:
>     >> 
>     >> > My obj does not always come with a logical variable defined. So I do
>     >> >
>     >> > my.foo <- function(obj,df,digits=5){
>     >> > if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
>     >> > ...
>     >> > }
>     >> >
>     >> > This works when "Fisher" is defined in/passed from obj. When it 
>     >> is not, I get error:
>     >> >
>     >> > Error in (!is.na("obj$spec$Fisher")) & Fisher :
>     >> >  operations are possible only for numeric, logical or complex types
>     >> >
>     >> > I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Tue Dec 23 15:25:25 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Tue, 23 Dec 2014 08:25:25 -0600
Subject: [R] Cox model with multiple events - PH assumption
In-Reply-To: <mailman.1.1419332402.24123.r-help@r-project.org>
References: <mailman.1.1419332402.24123.r-help@r-project.org>
Message-ID: <31062c$9gu47c@ironport10.mayo.edu>



On 12/23/2014 05:00 AM, r-help-request at r-project.org wrote:
> Dear all,
>
> I'm using the package "survival" for adjusting the Cox model with multiple
> events (Prentice, Williams and Peterson Model). I have several covariates,
> some of them are time-dependent.
>
> I'm using the function"cox.zph" to check the proportional hazards. Due to
> the nature of the time-dependent covariates, I don't need to analyse the
> assumptions of the proportional hazards associated with the
> time-dependent covariates. Is it right?
>
> ?Thanks for your attention.
>
> Best regards,
> Helena.

Wrong.
The PH assumption is that the same coefficient b for a covariate applies over all 
follow-up time.  The fact that the covariate itself changes value, or does not change 
value, over time has no bearing on whether the assumption is true.

Now it may often be the case that risk is related to current covariate values, and a Cox 
model using baseline values fails just because the covariates are out of date.  So PH 
might hold for the updated (time-dependent) covariates and fail when using baseline 
values.  This is a very study specific situation, however.

Terry T.


From ruzudumyan at gmail.com  Tue Dec 23 10:42:04 2014
From: ruzudumyan at gmail.com (Ruzan Udumyan)
Date: Tue, 23 Dec 2014 10:42:04 +0100
Subject: [R] Getting HR from Cox model in R
Message-ID: <CAJbUeXbZWbxa0AJ0KGLsAcyqhMqg70v=KLvGhLKSQX8wR6qrPQ@mail.gmail.com>

Dear All,

I am not familiar with R language well. Could you please help me interpret
these commands?:


 TE = exp(sum(coef(cox)[c('aTRUE', 'bTRUE')]))   - does it mean exp(coef(a
variable) + coef(b variable)) ?
 DE = exp(unname(coef(cox)['aTRUE']))  - what is unname for ?

Thank you very much beforehand for your help.

Wishing you happy holidays,
Ruzan

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Tue Dec 23 18:21:54 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 23 Dec 2014 17:21:54 +0000
Subject: [R] Getting HR from Cox model in R
In-Reply-To: <CAJbUeXbZWbxa0AJ0KGLsAcyqhMqg70v=KLvGhLKSQX8wR6qrPQ@mail.gmail.com>
References: <CAJbUeXbZWbxa0AJ0KGLsAcyqhMqg70v=KLvGhLKSQX8wR6qrPQ@mail.gmail.com>
Message-ID: <5499A4B2.6060809@aghmed.fsnet.co.uk>

Inline comments

On 23/12/2014 09:42, Ruzan Udumyan wrote:
> Dear All,
>
> I am not familiar with R language well. Could you please help me interpret
> these commands?:
>
>
>   TE = exp(sum(coef(cox)[c('aTRUE', 'bTRUE')]))   - does it mean exp(coef(a
> variable) + coef(b variable)) ?

You have not given us much to go on here.
I assume if you go
coef(cox)
you will find elements labelled aTRUE and bTRUE which implies the 
existence of a logical covariate with values TRUE and FALSE. The author 
of the code is trying to do what you suggest.

>   DE = exp(unname(coef(cox)['aTRUE']))  - what is unname for ?
>

?unname

> Thank you very much beforehand for your help.
>
> Wishing you happy holidays,
> Ruzan
>
> 	[[alternative HTML version deleted]]
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

If you post again please do read the message above.


>
> -----
> No virus found in this message.
> Checked by AVG - www.avg.com
> Version: 2015.0.5577 / Virus Database: 4257/8792 - Release Date: 12/23/14
>
>

-- 
Michael
http://www.dewey.myzen.co.uk


From btupper at bigelow.org  Tue Dec 23 19:27:52 2014
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 23 Dec 2014 13:27:52 -0500
Subject: [R] Do NOT use ifelse() if you can use if(.) else . [was
	"Checking .."]
In-Reply-To: <21657.12395.795068.799342@stat.math.ethz.ch>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<548d8b9f.e1ddec0a.70a2.ffffae54@mx.google.com>
	<A6CE932E-DED8-4714-B0E3-472907CA8C33@bigelow.org>
	<548d9f24.886eec0a.72bc.ffffafdd@mx.google.com>
	<21657.12395.795068.799342@stat.math.ethz.ch>
Message-ID: <D762664C-DA19-49C3-933F-1AE3FA67EE3B@bigelow.org>


On Dec 23, 2014, at 4:05 AM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

>>>>>> Steven Yen <syen04 at gmail.com>
>>>>>>    on Sun, 14 Dec 2014 09:30:56 -0500 writes:
>>>>>> Steven Yen <syen04 at gmail.com>
>>>>>>    on Sun, 14 Dec 2014 09:30:56 -0500 writes:
> 
>> Thanks. This worked!! :)
>> Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)
> 
> "worked",  yes.
> 
> But please --- for the mailing list archives ---
> do use better code.
> 
> Unfortunately, ifelse() is used and has been advertized much too
> often in cases where it is very sub-optimal efficiency wise. 
> ifelse(Cond, A, B)  should only be used  when the condition
> 'Cond', a logical vector can be (and typically is) of length > 1
> {and even then, it maybe a nice short cut, but often still suboptimal
> efficiency wise ... but let's not get there}
> 
> In cases like this one when the condition 'Cond' is a
> simple TRUE or FALSE (i.e. of length 1), using
> 
> 	if(Cond) A else B
> 
> instead of
> 
> 	ifelse(Cond, A, B)
> 
> is
> 
>  1. much more R - like  [[ "everything you do is a function call" ]]
>     hence much more elegant
> 
>  2. considerably more efficient.
> 
>  3. :-) less typing: uses two "," less ;-)
> 
>> require(microbenchmark)
>  Loading required package: microbenchmark
>> x <- setNames(,LETTERS)
>> y <- setNames(letters, runif(letters))
>> z <- pi
>> microbenchmark(r1 <- ifelse(z > 3, x, y), r2 <- if(z > 3) x else y, times=1000)
>  Unit: nanoseconds
> 			expr  min     lq     mean median     uq   max neval cld
>   r1 <- ifelse(z > 3, x, y) 4466 4971.5 5498.928   5244 5673.5 31705  1000   b
>   r2 <- if (z > 3) x else y  171  212.0  265.241    264  291.0  3130  1000  a 
>> 
> 
> i.e., roughly a factor of 20 times more efficient
> 

Wow! This is great, and I had no idea I was misusing ifelse. 

Thanks!
Ben



> 
> Martin Maechler,
> ETH Zurich and R Core Team.
> 
> 
>> At 08:43 AM 12/14/2014, Ben Tupper wrote:
>>> Hi,
>>> 
>>> Does this work for you?  It simply tests if the name Fisher is found 
>>> among the names of the elements of spec.
>>> 
>>> obj = list(spec = list)
>>> Fisher <- ifelse(!("Fisher" %in% names(obj$spec)), FALSE, obj$spec$Fisher)
>>> 
>>> Cheers,
>>> Ben
>>> 
>>> On Dec 14, 2014, at 8:07 AM, Steven Yen <syen04 at gmail.com> wrote:
>>> 
>>>> My obj does not always come with a logical variable defined. So I do
>>>> 
>>>> my.foo <- function(obj,df,digits=5){
>>>> if (!is.na("obj$spec$Fisher")) Fisher<-obj$spec$Fisher
>>>> ...
>>>> }
>>>> 
>>>> This works when "Fisher" is defined in/passed from obj. When it 
>>> is not, I get error:
>>>> 
>>>> Error in (!is.na("obj$spec$Fisher")) & Fisher :
>>>> operations are possible only for numeric, logical or complex types
>>>> 
>>>> I tried exist(Fisher), missing(Fisher)... to no vail. Any idea? Thanks.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From ligges at statistik.tu-dortmund.de  Tue Dec 23 20:33:38 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 23 Dec 2014 20:33:38 +0100
Subject: [R] R2WinBUGS
In-Reply-To: <CABLo8nEWH=fpqVNE8Bc60PJO8S1kd3io7YawCwZ8bwozZe9w1g@mail.gmail.com>
References: <CABLo8nEWH=fpqVNE8Bc60PJO8S1kd3io7YawCwZ8bwozZe9w1g@mail.gmail.com>
Message-ID: <5499C392.8010504@statistik.tu-dortmund.de>



On 23.12.2014 08:46, thanoon younis wrote:
> Dear all R-members
> I have a problem with R when i wanted to call WinBUGS from R as following:
>
> #Call WinBUGS
>      model<-bugs(data,inits,parameters,model.file="D:/Run/model.txt",
>      n.chains=2,n.iter=5000,n.burnin=1000,n.thin=1,'DIC=True',

???
You need DIC=TRUE rather than 'DIC=True' so without quotes and correct 
capitalization.


>      bugs.directory="c:/Program Files/WinBUGS14/",
>      working.directory="D:/Run/")
>
>
> and the error is
>
> Error in bugs.run(n.burnin, bugs.directory, WINE = WINE, useWINE = useWINE,
>   :
>    Look at the log file and
> try again with 'debug=TRUE' to figure out what went wrong within Bugs.

And what happens if your do that? I mean "try again with 'debug=TRUE' to 
figure out what went wrong within Bugs."

Best,
Uwe Ligges


>
> how can i solve this problem please?
>
> Any guidance would be highly appreciated.
>
>
>
>
>
>
>
>
>
>


From wyllys at ischool.utexas.edu  Tue Dec 23 21:20:00 2014
From: wyllys at ischool.utexas.edu (rewyllys)
Date: Tue, 23 Dec 2014 12:20:00 -0800 (PST)
Subject: [R] Unable to install ggplot2;
 using R 3.1.2 and RStudio 0.98.1091 in Linux Mint 17.1
Message-ID: <1419366000095-4701054.post@n4.nabble.com>

My attempts to install and then load ggplot2 have repeatedly failed.  

Here is the pertinent set of commands and responses: 

-----------------------------------------------------------------------------------------
install.packages("ggplot2")
Installing package into ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1?
(as ?lib? is unspecified)
also installing the dependencies ?Rcpp?, ?plyr?, ?reshape2?, ?scales?

trying URL 'http://cran.stat.ucla.edu/src/contrib/Rcpp_0.11.3.tar.gz'
Content type 'application/x-tar' length 2169583 bytes (2.1 Mb)
opened URL
==================================================
downloaded 2.1 Mb

trying URL 'http://cran.stat.ucla.edu/src/contrib/plyr_1.8.1.tar.gz'
Content type 'application/x-tar' length 393233 bytes (384 Kb)
opened URL
==================================================
downloaded 384 Kb

trying URL 'http://cran.stat.ucla.edu/src/contrib/reshape2_1.4.1.tar.gz'
Content type 'application/x-tar' length 34693 bytes (33 Kb)
opened URL
==================================================
downloaded 33 Kb

trying URL 'http://cran.stat.ucla.edu/src/contrib/scales_0.2.4.tar.gz'
Content type 'application/x-tar' length 40093 bytes (39 Kb)
opened URL
==================================================
downloaded 39 Kb

trying URL 'http://cran.stat.ucla.edu/src/contrib/ggplot2_1.0.0.tar.gz'
Content type 'application/x-tar' length 2351447 bytes (2.2 Mb)
opened URL
==================================================
downloaded 2.2 Mb

* installing *source* package ?Rcpp? ...
** package ?Rcpp? successfully unpacked and MD5 sums checked
** libs
g++ -I/usr/share/R/include -DNDEBUG -I../inst/include/     -fpic  -g -O2
-fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security
-D_FORTIFY_SOURCE=2 -g  -c Date.cpp -o Date.o
/bin/bash: g++: command not found
make: *** [Date.o] Error 127
ERROR: compilation failed for package ?Rcpp?
* removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/Rcpp?
Warning in install.packages :
  installation of package ?Rcpp? had non-zero exit status
ERROR: dependency ?Rcpp? is not available for package ?plyr?
* removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/plyr?
Warning in install.packages :
  installation of package ?plyr? had non-zero exit status
ERROR: dependencies ?plyr?, ?Rcpp? are not available for package ?reshape2?
* removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/reshape2?
Warning in install.packages :
  installation of package ?reshape2? had non-zero exit status
ERROR: dependency ?plyr? is not available for package ?scales?
* removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/scales?
Warning in install.packages :
  installation of package ?scales? had non-zero exit status
ERROR: dependencies ?plyr?, ?reshape2?, ?scales? are not available for
package ?ggplot2?
* removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/ggplot2?
Warning in install.packages :
  installation of package ?ggplot2? had non-zero exit status

The downloaded source packages are in
	?/tmp/Rtmp3phwN2/downloaded_packages?

----------------------------------------------------------------------------------------------------
I am relatively new to using R, but have had no prior problems in installing
packages.

Any and all suggestions and comments will be much appreciated.




--
View this message in context: http://r.789695.n4.nabble.com/Unable-to-install-ggplot2-using-R-3-1-2-and-RStudio-0-98-1091-in-Linux-Mint-17-1-tp4701054.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Tue Dec 23 22:13:19 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 23 Dec 2014 16:13:19 -0500
Subject: [R] Unable to install ggplot2;
 using R 3.1.2 and RStudio 0.98.1091 in Linux Mint 17.1
In-Reply-To: <1419366000095-4701054.post@n4.nabble.com>
References: <1419366000095-4701054.post@n4.nabble.com>
Message-ID: <CAM_vju=NxfefbP67BOURm8OXXBW3sinpdpxw75fi6FHXPNYW-A@mail.gmail.com>

Hi,

It's not an R problem: you don't have the necessary tools installed in linux,
specifically g++

You'll need to install the development tools for your version of
linux, as it states in the Rcpp FAQ.

Google should help you figure out what you need, if you don't already
know how to find and install packages for Mint linux.

Sarah

On Tue, Dec 23, 2014 at 3:20 PM, rewyllys <wyllys at ischool.utexas.edu> wrote:
> My attempts to install and then load ggplot2 have repeatedly failed.
>
> Here is the pertinent set of commands and responses:
>
> -----------------------------------------------------------------------------------------
> install.packages("ggplot2")
> Installing package into ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1?
> (as ?lib? is unspecified)
> also installing the dependencies ?Rcpp?, ?plyr?, ?reshape2?, ?scales?
>
> trying URL 'http://cran.stat.ucla.edu/src/contrib/Rcpp_0.11.3.tar.gz'
> Content type 'application/x-tar' length 2169583 bytes (2.1 Mb)
> opened URL
> ==================================================
> downloaded 2.1 Mb
>
> trying URL 'http://cran.stat.ucla.edu/src/contrib/plyr_1.8.1.tar.gz'
> Content type 'application/x-tar' length 393233 bytes (384 Kb)
> opened URL
> ==================================================
> downloaded 384 Kb
>
> trying URL 'http://cran.stat.ucla.edu/src/contrib/reshape2_1.4.1.tar.gz'
> Content type 'application/x-tar' length 34693 bytes (33 Kb)
> opened URL
> ==================================================
> downloaded 33 Kb
>
> trying URL 'http://cran.stat.ucla.edu/src/contrib/scales_0.2.4.tar.gz'
> Content type 'application/x-tar' length 40093 bytes (39 Kb)
> opened URL
> ==================================================
> downloaded 39 Kb
>
> trying URL 'http://cran.stat.ucla.edu/src/contrib/ggplot2_1.0.0.tar.gz'
> Content type 'application/x-tar' length 2351447 bytes (2.2 Mb)
> opened URL
> ==================================================
> downloaded 2.2 Mb
>
> * installing *source* package ?Rcpp? ...
> ** package ?Rcpp? successfully unpacked and MD5 sums checked
> ** libs
> g++ -I/usr/share/R/include -DNDEBUG -I../inst/include/     -fpic  -g -O2
> -fstack-protector --param=ssp-buffer-size=4 -Wformat -Werror=format-security
> -D_FORTIFY_SOURCE=2 -g  -c Date.cpp -o Date.o
> /bin/bash: g++: command not found
> make: *** [Date.o] Error 127
> ERROR: compilation failed for package ?Rcpp?
> * removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/Rcpp?
> Warning in install.packages :
>   installation of package ?Rcpp? had non-zero exit status
> ERROR: dependency ?Rcpp? is not available for package ?plyr?
> * removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/plyr?
> Warning in install.packages :
>   installation of package ?plyr? had non-zero exit status
> ERROR: dependencies ?plyr?, ?Rcpp? are not available for package ?reshape2?
> * removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/reshape2?
> Warning in install.packages :
>   installation of package ?reshape2? had non-zero exit status
> ERROR: dependency ?plyr? is not available for package ?scales?
> * removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/scales?
> Warning in install.packages :
>   installation of package ?scales? had non-zero exit status
> ERROR: dependencies ?plyr?, ?reshape2?, ?scales? are not available for
> package ?ggplot2?
> * removing ?/home/ron/R/x86_64-pc-linux-gnu-library/3.1/ggplot2?
> Warning in install.packages :
>   installation of package ?ggplot2? had non-zero exit status
>
> The downloaded source packages are in
>         ?/tmp/Rtmp3phwN2/downloaded_packages?
>
> ----------------------------------------------------------------------------------------------------
> I am relatively new to using R, but have had no prior problems in installing
> packages.
>
> Any and all suggestions and comments will be much appreciated.
>
>
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From mbressan at arpa.veneto.it  Tue Dec 23 22:38:34 2014
From: mbressan at arpa.veneto.it (maxbre)
Date: Tue, 23 Dec 2014 13:38:34 -0800 (PST)
Subject: [R] issue on installation of RCurl on Debian Wheezy
Message-ID: <1419370714386-4701058.post@n4.nabble.com>

I must say I'm pretty new to Linux Debian and R so I might miss here
reporting some relevant information (just in case, sorry for that!); I've
been looking around the web and also onto this mailing list - and indeed
this topic has been already covered-, but still I can't find any useful
solution to my problem (so I just hope someone can help me somehow)

by trying to install RCurl I got the following error message:

#########################
install.packages('RCurl')
Installing package into ?/home/max/R/x86_64-pc-linux-gnu-library/3.1?
(as ?lib? is unspecified)
provo con l'URL 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.5.tar.gz'
Content type 'application/x-gzip' length 878651 bytes (858 Kb)
URL aperto
==================================================
downloaded 858 Kb

* installing *source* package ?RCurl? ...
** package ?RCurl? successfully unpacked and MD5 sums checked
checking for curl-config... no
Cannot find curl-config
ERROR: configuration failed for package ?RCurl?
* removing ?/home/max/R/x86_64-pc-linux-gnu-library/3.1/RCurl?
Warning in install.packages :
  installation of package ?RCurl? had non-zero exit status

The downloaded source packages are in
	?/tmp/RtmpYJSYzn/downloaded_packages?

###############################

and this is the content of my config.log

###############################

This file contains any messages produced by compilers while
running configure, to aid debugging if configure makes a mistake.

It was created by configure, which was
generated by GNU Autoconf 2.69.  Invocation command line was

  $ ./configure 

## --------- ##
## Platform. ##
## --------- ##

hostname = max-debian
uname -m = x86_64
uname -r = 3.2.0-4-amd64
uname -s = Linux
uname -v = #1 SMP Debian 3.2.63-2+deb7u2

/usr/bin/uname -p = unknown
/bin/uname -X     = unknown

/bin/arch              = unknown
/usr/bin/arch -k       = unknown
/usr/convex/getsysinfo = unknown
/usr/bin/hostinfo      = unknown
/bin/machine           = unknown
/usr/bin/oslevel       = unknown
/bin/universe          = unknown

PATH: /usr/local/bin
PATH: /usr/bin
PATH: /bin
PATH: /usr/local/games
PATH: /usr/games


## ----------- ##
## Core tests. ##
## ----------- ##

configure:1786: checking for curl-config
configure:1819: result: no

## ---------------- ##
## Cache variables. ##
## ---------------- ##

ac_cv_env_CC_set=
ac_cv_env_CC_value=
ac_cv_env_CFLAGS_set=
ac_cv_env_CFLAGS_value=
ac_cv_env_CPPFLAGS_set=
ac_cv_env_CPPFLAGS_value=
ac_cv_env_CPP_set=
ac_cv_env_CPP_value=
ac_cv_env_LDFLAGS_set=
ac_cv_env_LDFLAGS_value=
ac_cv_env_LIBS_set=
ac_cv_env_LIBS_value=
ac_cv_env_build_alias_set=
ac_cv_env_build_alias_value=
ac_cv_env_host_alias_set=
ac_cv_env_host_alias_value=
ac_cv_env_target_alias_set=
ac_cv_env_target_alias_value=

## ----------------- ##
## Output variables. ##
## ----------------- ##


CC=''
CFLAGS=''
CPP=''
CPPFLAGS=''
CURL_CFLAGS=''
CURL_CONFIG=''
CURL_LIBS=''
DEFINES=''
DEFS=''
ECHO_C=''
ECHO_N='-n'
ECHO_T=''
EXEEXT=''
LDFLAGS=''
LIBOBJS=''
LIBS=''
LTLIBOBJS=''
OBJEXT=''
PACKAGE_BUGREPORT=''
PACKAGE_NAME=''
PACKAGE_STRING=''
PACKAGE_TARNAME=''
PACKAGE_URL=''
PACKAGE_VERSION=''
PATH_SEPARATOR=':'
SHELL='/bin/bash'
ac_ct_CC=''
bindir='${exec_prefix}/bin'
build_alias=''
datadir='${datarootdir}'
datarootdir='${prefix}/share'
docdir='${datarootdir}/doc/${PACKAGE}'
dvidir='${docdir}'
exec_prefix='NONE'
host_alias=''
htmldir='${docdir}'
includedir='${prefix}/include'
infodir='${datarootdir}/info'
libdir='${exec_prefix}/lib'
libexecdir='${exec_prefix}/libexec'
localedir='${datarootdir}/locale'
localstatedir='${prefix}/var'
mandir='${datarootdir}/man'
oldincludedir='/usr/include'
pdfdir='${docdir}'
prefix='NONE'
program_transform_name='s,x,x,'
psdir='${docdir}'
sbindir='${exec_prefix}/sbin'
sharedstatedir='${prefix}/com'
sysconfdir='${prefix}/etc'
target_alias=''

## ----------- ##
## confdefs.h. ##
## ----------- ##

/* confdefs.h */
#define PACKAGE_NAME ""
#define PACKAGE_TARNAME ""
#define PACKAGE_VERSION ""
#define PACKAGE_STRING ""
#define PACKAGE_BUGREPORT ""
#define PACKAGE_URL ""

configure: exit 1

##########################

and finally this is my sessionInfo()

############################

R version 3.1.2 (2014-10-31)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C              
LC_TIME=it_IT.UTF-8       
 [4] LC_COLLATE=it_IT.UTF-8     LC_MONETARY=it_IT.UTF-8   
LC_MESSAGES=it_IT.UTF-8   
 [7] LC_PAPER=it_IT.UTF-8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=it_IT.UTF-8
LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.1.2


#####################


can anyone possibly give me some indications on how to proceed in order to
sort out this problem?
any help much appreciated

bye



--
View this message in context: http://r.789695.n4.nabble.com/issue-on-installation-of-RCurl-on-Debian-Wheezy-tp4701058.html
Sent from the R help mailing list archive at Nabble.com.


From john.kornak at ucsf.edu  Tue Dec 23 22:28:35 2014
From: john.kornak at ucsf.edu (Kornak, John)
Date: Tue, 23 Dec 2014 21:28:35 +0000
Subject: [R] nlme package: changing reference for varIdent parameter
 estimates in summary.gls
Message-ID: <428E87A3-54D5-4D33-B9B3-B0ECA41EE877@ucsf.edu>


Dear R experts,

I am running gls models with heterogeneous group variances using the glm function in the nlme package with varIdent weights. I am interested in controlling the baseline level for the group variance function standard deviation estimates by applying the relevel function to the group variable. When I use relevel, the baseline level in the coefficient table changes as expected, but the baseline level does not change for the variance function table; for example, see the fitted models gls1 vs. gls2 in the contrived example below. Does anyone have a suggestion as to how I can change the baseline level for the variance function output please? In addition to the example below, I have tried specifying the value argument as per the varIdent help page, e.g. variIdent(c(no=0.5), form = ~1|group) and have google searched / checked help pages for solutions without success.

I am running R version 3.1.0 on an iMac OSX v. 10.9.5

Thank you in advance

John Kornak

> library(nlme)
> group <- factor(c(rep("no",20),rep("yes",20)))
> set.seed(2)
> outcome <- c(rnorm(20,0,2),rnorm(20,5,4))
> dataTest <- data.frame(outcome,group)

# Original model fit before releveling
> gls1 <- gls(outcome ~ group, weights=varIdent(form = ~1|group), data=dataTest)
> summary(gls1)

? snip ?

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034

Coefficients:
               Value Std.Error  t-value p-value
(Intercept) 0.390922 0.4734001 0.825775  0.4141
groupyes    4.607951 1.1571140 3.982279  0.0003

 ?snip ?

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual


# relevel the group so that ?yes? is the reference
> dataTest$group <- relevel(dataTest$group,"yes")
> gls2 <- gls(outcome ~ group, weights=varIdent(form = ~1|group), data=dataTest)
> summary(gls2)

? snip ?

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034                 ### ?no" is still the reference group here for the variance function

Coefficients:
                Value Std.Error   t-value p-value
(Intercept)  4.998873  1.055843  4.734484   0e+00
groupno     -4.607951  1.157114 -3.982279   3e-04  # ?yes? has become the reference for the coefficients

 ? snip ?

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual
>

---------------------------------------------------
John Kornak, PhD
Associate Professor in Residence
Department of Epidemiology and Biostatistics
University of California, San Francisco
Mission Hall: Global Health & Clinical Sciences Building
550 16th St, 2nd floor, Box #0560
San Francisco, CA 94158-2549
Tel: 415-514-8028
Fax: 415-514-8150
Email: john.kornak at ucsf.edu<mailto:john.kornak at ucsf.edu>




	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Dec 23 23:19:31 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 24 Dec 2014 11:19:31 +1300
Subject: [R] issue on installation of RCurl on Debian Wheezy
In-Reply-To: <1419370714386-4701058.post@n4.nabble.com>
References: <1419370714386-4701058.post@n4.nabble.com>
Message-ID: <5499EA73.9000002@auckland.ac.nz>


The error message is quite clear:  It says that you are missing
"curl-config" on your system:

 > checking for curl-config... no
 > Cannot find curl-config

On my Fedora system I would do:

yum whatprovides curl-config

and I would get:

libcurl-devel-7.24.0-2.fc17.x86_64 : Files needed for building 
applications with libcurl

So I would then do:

sudo yum install libcurl-devel

I don't know what the appropriate syntax on Debian would be; on Ubuntu I 
believe you say "aptget" rather than "yum".  Whatever; something similar 
should be available to you.

cheers,

Rolf Turner


On 24/12/14 10:38, maxbre wrote:
> I must say I'm pretty new to Linux Debian and R so I might miss here
> reporting some relevant information (just in case, sorry for that!); I've
> been looking around the web and also onto this mailing list - and indeed
> this topic has been already covered-, but still I can't find any useful
> solution to my problem (so I just hope someone can help me somehow)
>
> by trying to install RCurl I got the following error message:
>
> #########################
> install.packages('RCurl')
> Installing package into ?/home/max/R/x86_64-pc-linux-gnu-library/3.1?
> (as ?lib? is unspecified)
> provo con l'URL 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.5.tar.gz'
> Content type 'application/x-gzip' length 878651 bytes (858 Kb)
> URL aperto
> ==================================================
> downloaded 858 Kb
>
> * installing *source* package ?RCurl? ...
> ** package ?RCurl? successfully unpacked and MD5 sums checked
> checking for curl-config... no
> Cannot find curl-config
> ERROR: configuration failed for package ?RCurl?
> * removing ?/home/max/R/x86_64-pc-linux-gnu-library/3.1/RCurl?

<SNIP>


-- 
Rolf Turner
Technical Editor ANZJS


From plalehzari at platinumlp.com  Tue Dec 23 23:57:58 2014
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Tue, 23 Dec 2014 22:57:58 +0000
Subject: [R] Carrying a value down a data.frame conditionally
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB4FC78097@EX03DR.platinum.com>

Hello,
I have a data.frame (below) containing the two fields of "Value" and "Signal" and I would need to create the third field of "To_Be_Produced". The condition for producing the third field is to carry the 1 in the "Signal" field down until "Value" is below 40.
Do I have to create a for-loop to do this or will I be able to do anything else more efficient?


df <- data.frame( Value=c(0,0,100,85,39,1,30,40,20,20,0,0),
                  Signal=c(0,1,0,0,0,0,0,0,0,1,0,0),
                  To_Be_Produced= c(0,1,1,1,0,0,0,0,0,1,0,0)
                )

Thank you,
Pooya.




***
We are pleased to announce that, as of October 20th, 2014, we've moved to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]


From varinsacha at yahoo.fr  Tue Dec 23 23:59:34 2014
From: varinsacha at yahoo.fr (varin sacha)
Date: Tue, 23 Dec 2014 22:59:34 +0000 (UTC)
Subject: [R] Bca confidence intervals for Pearson coefficient, thanks.
In-Reply-To: <001d01d01d64$30d169f0$92743dd0$@mcmaster.ca>
References: <001d01d01d64$30d169f0$92743dd0$@mcmaster.ca>
Message-ID: <1889950765.892986.1419375574210.JavaMail.yahoo@jws11106.mail.ir2.yahoo.com>

Dear Professor Fox,
Once more I really thank you lots for your response. I will try it.
Best regards, and Merry Christmas to you.
SV
      De?: John Fox <jfox at mcmaster.ca>
 ??: 'varin sacha' <varinsacha at yahoo.fr> 
Cc?: 'r-help help' <r-help at r-project.org> 
 Envoy? le : Dimanche 21 d?cembre 2014 22h22
 Objet?: RE: [R] Bca confidence intervals for Pearson coefficient, thanks.
   
Dear Sacha,

Simply write a function that takes a data set and index vector as arguments, say statistic(data, index), and have it compute and return either eta^2 or V depending upon the application. Use the function myCor() in the previous example as a model.

Best,
 John 

> -----Original Message-----
> From: varin sacha [mailto:varinsacha at yahoo.fr]
> Sent: Sunday, December 21, 2014 3:03 PM
> To: John Fox
> Cc: r-help help
> Subject: Re: [R] Bca confidence intervals for Pearson coefficient,
> thanks.
> 
> Dear Professor FOX,
> 
> 
> I really thank you lots for all your precisions.
> One last precision, now if I want tot calculate the BCa bootstrap CIs
> for the Cramer's V and the Eta-squared.
> 
> 
> ## Read in the data file, using headers and Tab separator
> > test = read.table(file.choose(), header = TRUE, sep = "\t")
> 
> 
> ## Check the variable names
> > names(test)
> [1] "gender"? ? "option"? ? "math.test" "geo.test"? "shopping"? "sports"
> 
> 
> ## Cramer's V
> 
> > library(questionr)
> > tab = table(test$gender, test$option)
> > cramer.v(tab)
> [1] 0.1490712
> 
> ## Eta.square
> 
> > library(lsr)
> > test.aov = aov(math.test ~ gender, data = test)
> 
> > etaSquared(test.aov)
>? ? ? ? ? eta.sq eta.sq.part
> gender 0.1207154? 0.1207154
> 
> 
> 
> Best Regards, looking forward to reading you once more,
> 
> Sacha
> 
> ________________________________
> 
> De : John Fox <jfox at mcmaster.ca>
> ? : varin sacha <varinsacha at yahoo.fr>
> Cc : r-help help <r-help at r-project.org>
> Envoy? le : Dimanche 21 d?cembre 2014 5h33
> Objet : Re: [R] Bca confidence intervals for Pearson coefficient,
> thanks.
> 
> 
> Dear varin sacha,
> 
> I think that you misunderstand how boot() and boot.ci() work. The boot()
> function in the simplest case takes two arguments, for the data and
> indices into the data, while boot.ci() takes as its principal argument
> the object returned by boot(). All of this seems reasonably clear in
> ?boot and ?boot.ci.
> 
> Here's an example with different data (since as far as I can see you
> didn't supply yours):
> 
> ------------- snip --------
> 
> > library(boot)
> >
> > x <- longley$Year
> > y <- longley$Population
> >
> > cor(cbind(x, y))
>? ? ? ? ? x? ? ? ? y
> x 1.0000000 0.9939528
> y 0.9939528 1.0000000
> >
> > myCor <- function(data, index){
> +? cor(data[index, ])[1, 2]
> + }
> >
> > set.seed(12345)
> > (b <- boot(data=cbind(x, y), statistic=myCor, R=200))
> 
> ORDINARY NONPARAMETRIC BOOTSTRAP
> 
> 
> Call:
> boot(data = cbind(x, y), statistic = myCor, R = 200)
> 
> 
> Bootstrap Statistics :
>? ? original? ? ? bias? ? std. error
> t1* 0.9939528 0.0008263766 0.001850004
> 
> > boot.ci(b, type="bca")
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 200 bootstrap replicates
> 
> CALL :
> boot.ci(boot.out = b, type = "bca")
> 
> Intervals :
> Level? ? ? BCa
> 95%? ( 0.9895,? 0.9969 )
> Calculations and Intervals on Original Scale
> Warning : BCa Intervals used Extreme Quantiles
> Some BCa intervals may be unstable
> Warning message:
> In norm.inter(t, adj.alpha) : extreme order statistics used as endpoints
> 
> --------------- snip ---------------
> 
> Note that 200 bootstrap replications are generally sufficient for
> bootstrap standard errors (a normal-theory CI would be a poor choice
> here, unless you transform the correlation coefficient), but really
> aren't enough for a BCa interval.
> 
> I hope this helps,
> John
> 
> 
> 
> 
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 
> On Sat, 20 Dec 2014 20:36:57 +0000 (UTC)
> varin sacha <varinsacha at yahoo.fr> wrote:


> > Hi to everyone,
> > I am trying to calculate the Bca bootstrap confidence intervals for
> the Pearson coefficient.
> > x=Dataset$math.testy=Dataset$geo.testcor(x,y,method="pearson")[1]
> 0.6983799
> > boot.ci(cor, conf=0.95, type=bca)Erreur dans boot.out$t0 : objet de
> type 'closure' non indi?able
> >
> > I have tried as well to calculate the Pearson coefficient using
> bootstrap and then to calculate the Bca bootstrap CIs of the Pearson. It
> doesn't work either.
> > boot(data = cbind(x, y), statistic = cor, R = 200)
> >
> > ORDINARY NONPARAMETRIC BOOTSTRAP
> >
> >
> > Call:
> > boot(data = cbind(x, y), statistic = cor, R = 200)
> >
> >
> > Bootstrap Statistics :
> >? ? ? original? ? bias? ? std. error
> > t1* -0.6243713 0.6295142? 0.2506267
> > t2* -0.1366533 0.1565392? 0.2579134
> > > boot.ci(cor, conf=0.95, type=bca)
> > Erreur dans boot.out$t0 : objet de type 'closure' non indi?able
> > Many thanks to tell me how to correct my R script to get the Bca CIs
> for my Pearson coefficient. Best regards, looking forward to reading
> you,
> > SV
> 
> >
> >? ? [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> 
> 



  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Dec 24 00:16:52 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 23 Dec 2014 15:16:52 -0800
Subject: [R] issue on installation of RCurl on Debian Wheezy
In-Reply-To: <1419370714386-4701058.post@n4.nabble.com>
References: <1419370714386-4701058.post@n4.nabble.com>
Message-ID: <C9542E6A-4EAF-4E83-9EA2-8335D333CFF4@dcn.davis.CA.us>

Do you have curl installed? RCurl just uses your external-to-R system installation of the curl software to do its real work.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 23, 2014 1:38:34 PM PST, maxbre <mbressan at arpa.veneto.it> wrote:
>I must say I'm pretty new to Linux Debian and R so I might miss here
>reporting some relevant information (just in case, sorry for that!);
>I've
>been looking around the web and also onto this mailing list - and
>indeed
>this topic has been already covered-, but still I can't find any useful
>solution to my problem (so I just hope someone can help me somehow)
>
>by trying to install RCurl I got the following error message:
>
>#########################
>install.packages('RCurl')
>Installing package into ?/home/max/R/x86_64-pc-linux-gnu-library/3.1?
>(as ?lib? is unspecified)
>provo con l'URL
>'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.5.tar.gz'
>Content type 'application/x-gzip' length 878651 bytes (858 Kb)
>URL aperto
>==================================================
>downloaded 858 Kb
>
>* installing *source* package ?RCurl? ...
>** package ?RCurl? successfully unpacked and MD5 sums checked
>checking for curl-config... no
>Cannot find curl-config
>ERROR: configuration failed for package ?RCurl?
>* removing ?/home/max/R/x86_64-pc-linux-gnu-library/3.1/RCurl?
>Warning in install.packages :
>  installation of package ?RCurl? had non-zero exit status
>
>The downloaded source packages are in
>	?/tmp/RtmpYJSYzn/downloaded_packages?
>
>###############################
>
>and this is the content of my config.log
>
>###############################
>
>This file contains any messages produced by compilers while
>running configure, to aid debugging if configure makes a mistake.
>
>It was created by configure, which was
>generated by GNU Autoconf 2.69.  Invocation command line was
>
>  $ ./configure 
>
>## --------- ##
>## Platform. ##
>## --------- ##
>
>hostname = max-debian
>uname -m = x86_64
>uname -r = 3.2.0-4-amd64
>uname -s = Linux
>uname -v = #1 SMP Debian 3.2.63-2+deb7u2
>
>/usr/bin/uname -p = unknown
>/bin/uname -X     = unknown
>
>/bin/arch              = unknown
>/usr/bin/arch -k       = unknown
>/usr/convex/getsysinfo = unknown
>/usr/bin/hostinfo      = unknown
>/bin/machine           = unknown
>/usr/bin/oslevel       = unknown
>/bin/universe          = unknown
>
>PATH: /usr/local/bin
>PATH: /usr/bin
>PATH: /bin
>PATH: /usr/local/games
>PATH: /usr/games
>
>
>## ----------- ##
>## Core tests. ##
>## ----------- ##
>
>configure:1786: checking for curl-config
>configure:1819: result: no
>
>## ---------------- ##
>## Cache variables. ##
>## ---------------- ##
>
>ac_cv_env_CC_set=
>ac_cv_env_CC_value=
>ac_cv_env_CFLAGS_set=
>ac_cv_env_CFLAGS_value=
>ac_cv_env_CPPFLAGS_set=
>ac_cv_env_CPPFLAGS_value=
>ac_cv_env_CPP_set=
>ac_cv_env_CPP_value=
>ac_cv_env_LDFLAGS_set=
>ac_cv_env_LDFLAGS_value=
>ac_cv_env_LIBS_set=
>ac_cv_env_LIBS_value=
>ac_cv_env_build_alias_set=
>ac_cv_env_build_alias_value=
>ac_cv_env_host_alias_set=
>ac_cv_env_host_alias_value=
>ac_cv_env_target_alias_set=
>ac_cv_env_target_alias_value=
>
>## ----------------- ##
>## Output variables. ##
>## ----------------- ##
>
>
>CC=''
>CFLAGS=''
>CPP=''
>CPPFLAGS=''
>CURL_CFLAGS=''
>CURL_CONFIG=''
>CURL_LIBS=''
>DEFINES=''
>DEFS=''
>ECHO_C=''
>ECHO_N='-n'
>ECHO_T=''
>EXEEXT=''
>LDFLAGS=''
>LIBOBJS=''
>LIBS=''
>LTLIBOBJS=''
>OBJEXT=''
>PACKAGE_BUGREPORT=''
>PACKAGE_NAME=''
>PACKAGE_STRING=''
>PACKAGE_TARNAME=''
>PACKAGE_URL=''
>PACKAGE_VERSION=''
>PATH_SEPARATOR=':'
>SHELL='/bin/bash'
>ac_ct_CC=''
>bindir='${exec_prefix}/bin'
>build_alias=''
>datadir='${datarootdir}'
>datarootdir='${prefix}/share'
>docdir='${datarootdir}/doc/${PACKAGE}'
>dvidir='${docdir}'
>exec_prefix='NONE'
>host_alias=''
>htmldir='${docdir}'
>includedir='${prefix}/include'
>infodir='${datarootdir}/info'
>libdir='${exec_prefix}/lib'
>libexecdir='${exec_prefix}/libexec'
>localedir='${datarootdir}/locale'
>localstatedir='${prefix}/var'
>mandir='${datarootdir}/man'
>oldincludedir='/usr/include'
>pdfdir='${docdir}'
>prefix='NONE'
>program_transform_name='s,x,x,'
>psdir='${docdir}'
>sbindir='${exec_prefix}/sbin'
>sharedstatedir='${prefix}/com'
>sysconfdir='${prefix}/etc'
>target_alias=''
>
>## ----------- ##
>## confdefs.h. ##
>## ----------- ##
>
>/* confdefs.h */
>#define PACKAGE_NAME ""
>#define PACKAGE_TARNAME ""
>#define PACKAGE_VERSION ""
>#define PACKAGE_STRING ""
>#define PACKAGE_BUGREPORT ""
>#define PACKAGE_URL ""
>
>configure: exit 1
>
>##########################
>
>and finally this is my sessionInfo()
>
>############################
>
>R version 3.1.2 (2014-10-31)
>Platform: x86_64-pc-linux-gnu (64-bit)
>
>locale:
> [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C              
>LC_TIME=it_IT.UTF-8       
> [4] LC_COLLATE=it_IT.UTF-8     LC_MONETARY=it_IT.UTF-8   
>LC_MESSAGES=it_IT.UTF-8   
>[7] LC_PAPER=it_IT.UTF-8       LC_NAME=C                  LC_ADDRESS=C 
>            
>[10] LC_TELEPHONE=C             LC_MEASUREMENT=it_IT.UTF-8
>LC_IDENTIFICATION=C       
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>loaded via a namespace (and not attached):
>[1] tools_3.1.2
>
>
>#####################
>
>
>can anyone possibly give me some indications on how to proceed in order
>to
>sort out this problem?
>any help much appreciated
>
>bye
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/issue-on-installation-of-RCurl-on-Debian-Wheezy-tp4701058.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Wed Dec 24 01:31:39 2014
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Tue, 23 Dec 2014 16:31:39 -0800
Subject: [R] issue on installation of RCurl on Debian Wheezy
In-Reply-To: <1419370714386-4701058.post@n4.nabble.com>
References: <1419370714386-4701058.post@n4.nabble.com>
Message-ID: <CACdH2ZbaAbyu6Dc5dEQXuRZxswEQHYshL7LsX3nqYGCBSkVyWg@mail.gmail.com>

I think you need to have curl-config installed.  I had a similar
problem on Ubuntu and found the program in various packages:.

    $ apt-file search curl-config | grep bin
    libcurl4-gnutls-dev: /usr/bin/curl-config
    libcurl4-nss-dev: /usr/bin/curl-config
    libcurl4-openssl-dev: /usr/bin/curl-config

I think that installing any one of them would probably fix the
problem.  I think I used the "openssl" one.

-- Mike


On Tue, Dec 23, 2014 at 1:38 PM, maxbre <mbressan at arpa.veneto.it> wrote:
> I must say I'm pretty new to Linux Debian and R so I might miss here
> reporting some relevant information (just in case, sorry for that!); I've
> been looking around the web and also onto this mailing list - and indeed
> this topic has been already covered-, but still I can't find any useful
> solution to my problem (so I just hope someone can help me somehow)
>
> by trying to install RCurl I got the following error message:
>
> #########################
> install.packages('RCurl')
> Installing package into ?/home/max/R/x86_64-pc-linux-gnu-library/3.1?
> (as ?lib? is unspecified)
> provo con l'URL 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.5.tar.gz'
> Content type 'application/x-gzip' length 878651 bytes (858 Kb)
> URL aperto
> ==================================================
> downloaded 858 Kb
>
> * installing *source* package ?RCurl? ...
> ** package ?RCurl? successfully unpacked and MD5 sums checked
> checking for curl-config... no
> Cannot find curl-config
> ERROR: configuration failed for package ?RCurl?
> * removing ?/home/max/R/x86_64-pc-linux-gnu-library/3.1/RCurl?
> Warning in install.packages :
>   installation of package ?RCurl? had non-zero exit status
>
> The downloaded source packages are in
>         ?/tmp/RtmpYJSYzn/downloaded_packages?
>
> ###############################
>
> and this is the content of my config.log
>
> ###############################
>
> This file contains any messages produced by compilers while
> running configure, to aid debugging if configure makes a mistake.
>
> It was created by configure, which was
> generated by GNU Autoconf 2.69.  Invocation command line was
>
>   $ ./configure
>
> ## --------- ##
> ## Platform. ##
> ## --------- ##
>
> hostname = max-debian
> uname -m = x86_64
> uname -r = 3.2.0-4-amd64
> uname -s = Linux
> uname -v = #1 SMP Debian 3.2.63-2+deb7u2
>
> /usr/bin/uname -p = unknown
> /bin/uname -X     = unknown
>
> /bin/arch              = unknown
> /usr/bin/arch -k       = unknown
> /usr/convex/getsysinfo = unknown
> /usr/bin/hostinfo      = unknown
> /bin/machine           = unknown
> /usr/bin/oslevel       = unknown
> /bin/universe          = unknown
>
> PATH: /usr/local/bin
> PATH: /usr/bin
> PATH: /bin
> PATH: /usr/local/games
> PATH: /usr/games
>
>
> ## ----------- ##
> ## Core tests. ##
> ## ----------- ##
>
> configure:1786: checking for curl-config
> configure:1819: result: no
>
> ## ---------------- ##
> ## Cache variables. ##
> ## ---------------- ##
>
> ac_cv_env_CC_set=
> ac_cv_env_CC_value=
> ac_cv_env_CFLAGS_set=
> ac_cv_env_CFLAGS_value=
> ac_cv_env_CPPFLAGS_set=
> ac_cv_env_CPPFLAGS_value=
> ac_cv_env_CPP_set=
> ac_cv_env_CPP_value=
> ac_cv_env_LDFLAGS_set=
> ac_cv_env_LDFLAGS_value=
> ac_cv_env_LIBS_set=
> ac_cv_env_LIBS_value=
> ac_cv_env_build_alias_set=
> ac_cv_env_build_alias_value=
> ac_cv_env_host_alias_set=
> ac_cv_env_host_alias_value=
> ac_cv_env_target_alias_set=
> ac_cv_env_target_alias_value=
>
> ## ----------------- ##
> ## Output variables. ##
> ## ----------------- ##
>
>
> CC=''
> CFLAGS=''
> CPP=''
> CPPFLAGS=''
> CURL_CFLAGS=''
> CURL_CONFIG=''
> CURL_LIBS=''
> DEFINES=''
> DEFS=''
> ECHO_C=''
> ECHO_N='-n'
> ECHO_T=''
> EXEEXT=''
> LDFLAGS=''
> LIBOBJS=''
> LIBS=''
> LTLIBOBJS=''
> OBJEXT=''
> PACKAGE_BUGREPORT=''
> PACKAGE_NAME=''
> PACKAGE_STRING=''
> PACKAGE_TARNAME=''
> PACKAGE_URL=''
> PACKAGE_VERSION=''
> PATH_SEPARATOR=':'
> SHELL='/bin/bash'
> ac_ct_CC=''
> bindir='${exec_prefix}/bin'
> build_alias=''
> datadir='${datarootdir}'
> datarootdir='${prefix}/share'
> docdir='${datarootdir}/doc/${PACKAGE}'
> dvidir='${docdir}'
> exec_prefix='NONE'
> host_alias=''
> htmldir='${docdir}'
> includedir='${prefix}/include'
> infodir='${datarootdir}/info'
> libdir='${exec_prefix}/lib'
> libexecdir='${exec_prefix}/libexec'
> localedir='${datarootdir}/locale'
> localstatedir='${prefix}/var'
> mandir='${datarootdir}/man'
> oldincludedir='/usr/include'
> pdfdir='${docdir}'
> prefix='NONE'
> program_transform_name='s,x,x,'
> psdir='${docdir}'
> sbindir='${exec_prefix}/sbin'
> sharedstatedir='${prefix}/com'
> sysconfdir='${prefix}/etc'
> target_alias=''
>
> ## ----------- ##
> ## confdefs.h. ##
> ## ----------- ##
>
> /* confdefs.h */
> #define PACKAGE_NAME ""
> #define PACKAGE_TARNAME ""
> #define PACKAGE_VERSION ""
> #define PACKAGE_STRING ""
> #define PACKAGE_BUGREPORT ""
> #define PACKAGE_URL ""
>
> configure: exit 1
>
> ##########################
>
> and finally this is my sessionInfo()
>
> ############################
>
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
> LC_TIME=it_IT.UTF-8
>  [4] LC_COLLATE=it_IT.UTF-8     LC_MONETARY=it_IT.UTF-8
> LC_MESSAGES=it_IT.UTF-8
>  [7] LC_PAPER=it_IT.UTF-8       LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=it_IT.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.2
>
>
> #####################
>
>
> can anyone possibly give me some indications on how to proceed in order to
> sort out this problem?
> any help much appreciated
>
> bye
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/issue-on-installation-of-RCurl-on-Debian-Wheezy-tp4701058.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Thierry.ONKELINX at inbo.be  Wed Dec 24 08:26:31 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 24 Dec 2014 07:26:31 +0000
Subject: [R] nlme package: changing reference for varIdent parameter
 estimates in summary.gls
In-Reply-To: <428E87A3-54D5-4D33-B9B3-B0ECA41EE877@ucsf.edu>
References: <428E87A3-54D5-4D33-B9B3-B0ECA41EE877@ucsf.edu>
Message-ID: <AA818EAD2576BC488B4F623941DA7427FD63D655@inbomail.inbo.be>

Dear John,

R-sig-mixed-models is more suited for this kind of questions. All follow-up mail should be posted only to that mailing list.

It seems like varIdent() by default relevels the grouping factor and that the user cannot control this.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: R-help [mailto:r-help-bounces at r-project.org] Namens Kornak, John
Verzonden: dinsdag 23 december 2014 22:29
Aan: r-help at R-project.org
Onderwerp: [R] nlme package: changing reference for varIdent parameter estimates in summary.gls


Dear R experts,

I am running gls models with heterogeneous group variances using the glm function in the nlme package with varIdent weights. I am interested in controlling the baseline level for the group variance function standard deviation estimates by applying the relevel function to the group variable. When I use relevel, the baseline level in the coefficient table changes as expected, but the baseline level does not change for the variance function table; for example, see the fitted models gls1 vs. gls2 in the contrived example below. Does anyone have a suggestion as to how I can change the baseline level for the variance function output please? In addition to the example below, I have tried specifying the value argument as per the varIdent help page, e.g. variIdent(c(no=0.5), form = ~1|group) and have google searched / checked help pages for solutions without success.

I am running R version 3.1.0 on an iMac OSX v. 10.9.5

Thank you in advance

John Kornak

> library(nlme)
> group <- factor(c(rep("no",20),rep("yes",20)))
> set.seed(2)
> outcome <- c(rnorm(20,0,2),rnorm(20,5,4)) dataTest <-
> data.frame(outcome,group)

# Original model fit before releveling
> gls1 <- gls(outcome ~ group, weights=varIdent(form = ~1|group),
> data=dataTest)
> summary(gls1)

  snip

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034

Coefficients:
               Value Std.Error  t-value p-value
(Intercept) 0.390922 0.4734001 0.825775  0.4141
groupyes    4.607951 1.1571140 3.982279  0.0003

  snip

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual


# relevel the group so that  yes  is the reference
> dataTest$group <- relevel(dataTest$group,"yes")
> gls2 <- gls(outcome ~ group, weights=varIdent(form = ~1|group),
> data=dataTest)
> summary(gls2)

  snip

Variance function:
 Structure: Different standard deviations per stratum
 Formula: ~1 | group
 Parameter estimates:
     no     yes
1.00000 2.23034                 ###  no" is still the reference group here for the variance function

Coefficients:
                Value Std.Error   t-value p-value
(Intercept)  4.998873  1.055843  4.734484   0e+00
groupno     -4.607951  1.157114 -3.982279   3e-04  #  yes  has become the reference for the coefficients

   snip

Residual standard error: 2.11711
Degrees of freedom: 40 total; 38 residual
>

---------------------------------------------------
John Kornak, PhD
Associate Professor in Residence
Department of Epidemiology and Biostatistics University of California, San Francisco Mission Hall: Global Health & Clinical Sciences Building
550 16th St, 2nd floor, Box #0560
San Francisco, CA 94158-2549
Tel: 415-514-8028
Fax: 415-514-8150
Email: john.kornak at ucsf.edu<mailto:john.kornak at ucsf.edu>




        [[alternative HTML version deleted]]

Disclaimer Bezoek onze website / Visit our website<https://drupal.inbo.be/nl/disclaimer-mailberichten-van-het-inbo>

From pdalgd at gmail.com  Wed Dec 24 10:35:13 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 24 Dec 2014 10:35:13 +0100
Subject: [R] Carrying a value down a data.frame conditionally
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB4FC78097@EX03DR.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB4FC78097@EX03DR.platinum.com>
Message-ID: <B41EC0E8-EFB9-41E3-A57F-D297EEF09FA9@gmail.com>


> On 23 Dec 2014, at 23:57 , Pooya Lalehzari <plalehzari at platinumlp.com> wrote:
> 
> Hello,
> I have a data.frame (below) containing the two fields of "Value" and "Signal" and I would need to create the third field of "To_Be_Produced". The condition for producing the third field is to carry the 1 in the "Signal" field down until "Value" is below 40.
> Do I have to create a for-loop to do this or will I be able to do anything else more efficient?
> 
> 
> df <- data.frame( Value=c(0,0,100,85,39,1,30,40,20,20,0,0),
>                  Signal=c(0,1,0,0,0,0,0,0,0,1,0,0),
>                  To_Be_Produced= c(0,1,1,1,0,0,0,0,0,1,0,0)
>                )

I'd go with the for loop, unless you _really_ need the efficiency. And if you do need efficiency that badly, it is probably better to code up the for loop in C/C++. (An Rcpp evangelist is likely to chime in any moment now.)

If you want a vectorized solution just for the academic exercise, I think you can do something with ave(), grouping by cumsum(Signal) and within groups doing cumprod(Value >= 40), except that you need to skip the first element of each group. And be careful that the first group is different.

This seems to do it:

> with(df, ave(Value, cumsum(Signal), FUN=function(x) c(0,cumprod(x[-1]>=40))
              ) + Signal)
 [1] 0 1 1 1 0 0 0 0 0 1 0 0


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mbressan at arpa.veneto.it  Wed Dec 24 15:57:31 2014
From: mbressan at arpa.veneto.it (mbressan at arpa.veneto.it)
Date: Wed, 24 Dec 2014 15:57:31 +0100
Subject: [R] issue on installation of RCurl on Debian Wheezy
In-Reply-To: <CACdH2ZbaAbyu6Dc5dEQXuRZxswEQHYshL7LsX3nqYGCBSkVyWg@mail.gmail.com>
References: <1419370714386-4701058.post@n4.nabble.com>
	<CACdH2ZbaAbyu6Dc5dEQXuRZxswEQHYshL7LsX3nqYGCBSkVyWg@mail.gmail.com>
Message-ID: <4812ee8e48b3c87ee8d33716bd26883f.squirrel@89.96.234.216>

yes, exactly!

all these dependencies were missing plus some other were corrupted (but
frankly I do not know why and how)

now everything seems working fine...

thanks a lot

my best season's greetings

m

> I think you need to have curl-config installed.  I had a similar
> problem on Ubuntu and found the program in various packages:.
>
>     $ apt-file search curl-config | grep bin
>     libcurl4-gnutls-dev: /usr/bin/curl-config
>     libcurl4-nss-dev: /usr/bin/curl-config
>     libcurl4-openssl-dev: /usr/bin/curl-config
>
> I think that installing any one of them would probably fix the
> problem.  I think I used the "openssl" one.
>
> -- Mike
>
>
> On Tue, Dec 23, 2014 at 1:38 PM, maxbre <mbressan at arpa.veneto.it> wrote:
>> I must say I'm pretty new to Linux Debian and R so I might miss here
>> reporting some relevant information (just in case, sorry for that!);
>> I've
>> been looking around the web and also onto this mailing list - and indeed
>> this topic has been already covered-, but still I can't find any useful
>> solution to my problem (so I just hope someone can help me somehow)
>>
>> by trying to install RCurl I got the following error message:
>>
>> #########################
>> install.packages('RCurl')
>> Installing package into ?/home/max/R/x86_64-pc-linux-gnu-library/3.1?
>> (as ?lib? is unspecified)
>> provo con l'URL
>> 'http://cran.rstudio.com/src/contrib/RCurl_1.95-4.5.tar.gz'
>> Content type 'application/x-gzip' length 878651 bytes (858 Kb)
>> URL aperto
>> ==================================================
>> downloaded 858 Kb
>>
>> * installing *source* package ?RCurl? ...
>> ** package ?RCurl? successfully unpacked and MD5 sums checked
>> checking for curl-config... no
>> Cannot find curl-config
>> ERROR: configuration failed for package ?RCurl?
>> * removing ?/home/max/R/x86_64-pc-linux-gnu-library/3.1/RCurl?
>> Warning in install.packages :
>>   installation of package ?RCurl? had non-zero exit status
>>
>> The downloaded source packages are in
>>         ?/tmp/RtmpYJSYzn/downloaded_packages?
>>
>> ###############################
>>
>> and this is the content of my config.log
>>
>> ###############################
>>
>> This file contains any messages produced by compilers while
>> running configure, to aid debugging if configure makes a mistake.
>>
>> It was created by configure, which was
>> generated by GNU Autoconf 2.69.  Invocation command line was
>>
>>   $ ./configure
>>
>> ## --------- ##
>> ## Platform. ##
>> ## --------- ##
>>
>> hostname = max-debian
>> uname -m = x86_64
>> uname -r = 3.2.0-4-amd64
>> uname -s = Linux
>> uname -v = #1 SMP Debian 3.2.63-2+deb7u2
>>
>> /usr/bin/uname -p = unknown
>> /bin/uname -X     = unknown
>>
>> /bin/arch              = unknown
>> /usr/bin/arch -k       = unknown
>> /usr/convex/getsysinfo = unknown
>> /usr/bin/hostinfo      = unknown
>> /bin/machine           = unknown
>> /usr/bin/oslevel       = unknown
>> /bin/universe          = unknown
>>
>> PATH: /usr/local/bin
>> PATH: /usr/bin
>> PATH: /bin
>> PATH: /usr/local/games
>> PATH: /usr/games
>>
>>
>> ## ----------- ##
>> ## Core tests. ##
>> ## ----------- ##
>>
>> configure:1786: checking for curl-config
>> configure:1819: result: no
>>
>> ## ---------------- ##
>> ## Cache variables. ##
>> ## ---------------- ##
>>
>> ac_cv_env_CC_set=
>> ac_cv_env_CC_value=
>> ac_cv_env_CFLAGS_set=
>> ac_cv_env_CFLAGS_value=
>> ac_cv_env_CPPFLAGS_set=
>> ac_cv_env_CPPFLAGS_value=
>> ac_cv_env_CPP_set=
>> ac_cv_env_CPP_value=
>> ac_cv_env_LDFLAGS_set=
>> ac_cv_env_LDFLAGS_value=
>> ac_cv_env_LIBS_set=
>> ac_cv_env_LIBS_value=
>> ac_cv_env_build_alias_set=
>> ac_cv_env_build_alias_value=
>> ac_cv_env_host_alias_set=
>> ac_cv_env_host_alias_value=
>> ac_cv_env_target_alias_set=
>> ac_cv_env_target_alias_value=
>>
>> ## ----------------- ##
>> ## Output variables. ##
>> ## ----------------- ##
>>
>>
>> CC=''
>> CFLAGS=''
>> CPP=''
>> CPPFLAGS=''
>> CURL_CFLAGS=''
>> CURL_CONFIG=''
>> CURL_LIBS=''
>> DEFINES=''
>> DEFS=''
>> ECHO_C=''
>> ECHO_N='-n'
>> ECHO_T=''
>> EXEEXT=''
>> LDFLAGS=''
>> LIBOBJS=''
>> LIBS=''
>> LTLIBOBJS=''
>> OBJEXT=''
>> PACKAGE_BUGREPORT=''
>> PACKAGE_NAME=''
>> PACKAGE_STRING=''
>> PACKAGE_TARNAME=''
>> PACKAGE_URL=''
>> PACKAGE_VERSION=''
>> PATH_SEPARATOR=':'
>> SHELL='/bin/bash'
>> ac_ct_CC=''
>> bindir='${exec_prefix}/bin'
>> build_alias=''
>> datadir='${datarootdir}'
>> datarootdir='${prefix}/share'
>> docdir='${datarootdir}/doc/${PACKAGE}'
>> dvidir='${docdir}'
>> exec_prefix='NONE'
>> host_alias=''
>> htmldir='${docdir}'
>> includedir='${prefix}/include'
>> infodir='${datarootdir}/info'
>> libdir='${exec_prefix}/lib'
>> libexecdir='${exec_prefix}/libexec'
>> localedir='${datarootdir}/locale'
>> localstatedir='${prefix}/var'
>> mandir='${datarootdir}/man'
>> oldincludedir='/usr/include'
>> pdfdir='${docdir}'
>> prefix='NONE'
>> program_transform_name='s,x,x,'
>> psdir='${docdir}'
>> sbindir='${exec_prefix}/sbin'
>> sharedstatedir='${prefix}/com'
>> sysconfdir='${prefix}/etc'
>> target_alias=''
>>
>> ## ----------- ##
>> ## confdefs.h. ##
>> ## ----------- ##
>>
>> /* confdefs.h */
>> #define PACKAGE_NAME ""
>> #define PACKAGE_TARNAME ""
>> #define PACKAGE_VERSION ""
>> #define PACKAGE_STRING ""
>> #define PACKAGE_BUGREPORT ""
>> #define PACKAGE_URL ""
>>
>> configure: exit 1
>>
>> ##########################
>>
>> and finally this is my sessionInfo()
>>
>> ############################
>>
>> R version 3.1.2 (2014-10-31)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>  [1] LC_CTYPE=it_IT.UTF-8       LC_NUMERIC=C
>> LC_TIME=it_IT.UTF-8
>>  [4] LC_COLLATE=it_IT.UTF-8     LC_MONETARY=it_IT.UTF-8
>> LC_MESSAGES=it_IT.UTF-8
>>  [7] LC_PAPER=it_IT.UTF-8       LC_NAME=C                  LC_ADDRESS=C
>> [10] LC_TELEPHONE=C             LC_MEASUREMENT=it_IT.UTF-8
>> LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] tools_3.1.2
>>
>>
>> #####################
>>
>>
>> can anyone possibly give me some indications on how to proceed in order
>> to
>> sort out this problem?
>> any help much appreciated
>>
>> bye
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/issue-on-installation-of-RCurl-on-Debian-Wheezy-tp4701058.html
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From zhanglun1525 at gmail.com  Wed Dec 24 03:14:52 2014
From: zhanglun1525 at gmail.com (=?GB2312?B?1cXC1w==?=)
Date: Wed, 24 Dec 2014 10:14:52 +0800
Subject: [R] Calculating shortest path length among multiple graphs
Message-ID: <CAD06_6NA=ejccE0BNm4u4_KDELHgbpf8bQkN_TWckv3PNU2Fzw@mail.gmail.com>

Hi,
I have an edgelist network data (undirected) with multiple graphs like
this. For each graph (i.e., denoted by doc.id), I want to calculate the
shortest path length (SPL) between the nodes. By using the code attached
below, I can only calculate the SPL for only 1 graph at a time. How can I
handle the multiple networks in R?
Thanks for the help.
Lun
graph = data.frame(V1=c("A","A","B","B","C","D"),
V2=c("C","D","F","A","A","Z"),
doc.id=c("1","2","2","3","3","3"))
el=as.matrix(graph)
el[,1]=as.character(el[,1])
el[,2]=as.character(el[,2])
graph=graph.edgelist(el[,1:2],directed=FALSE)
sp <- shortest.paths(graph, v=V(graph), to=V(graph),
  mode = c("all"),
  weights = NULL, algorithm = c("dijkstra"))
sp <-graph.adjacency(sp, mode=c( "undirected"), weighted=T)
sp <- cbind( get.edgelist(sp) , round( E(sp)$weight, 3 ))

	[[alternative HTML version deleted]]


From rhs206 at exeter.ac.uk  Wed Dec 24 12:23:23 2014
From: rhs206 at exeter.ac.uk (Somers-Yeates, Robin)
Date: Wed, 24 Dec 2014 11:23:23 +0000
Subject: [R] gam mgcv family=scat
Message-ID: <1419420191854.14943@exeter.ac.uk>

?

Dear R users,


I'm currently analysing some data with the gam function from the mgcv package. I'm looking at the relationship between spatially referenced budburst dates (recorded as number of days from January 1st) and two continuous variables, and their interaction, where they are found. I'm particularly interested in testing the significance of the interaction, whilst accounting for spatial trends in the data.

I've set up my model as such, with year as a random factor (10 years of data):


M1<-gam(budburstday~ti(v1)+ti(v2)+ti(v1,v2)+s(Easting,Northing,k=1000)+s(year,bs="re"),family=scat,data=phen)


I initially set up the model with the default Gaussian family, but the qqplot looked a bit heavy tailed with the points on the left of the plot particularly, curving down below the straight line. I have just found the (family=scat - scaled t for heavy tailed data) option in a newer version of mgcv, which it states are:

 "for regression type models dependent on a single linear predictor, and with a log likelihood which is a sum of independent terms, each coprresponding to a single response observation. Usable only with gam, with smoothing parameter estimation by "REML" or "ML" (the latter does not integrate the unpenalized and parameteric effects out of the marginal likelihood optimized for the smoothing parameters)."


Question: I can find very few examples using this scat family, and was hoping someone could tell me whether the model specified above is theoretically sound (i.e. is it okay to include these different smooth types (ti, s & bs="re") with this family)?


Any advice would be greatly appreciated. Thanks in advance.

Robin

	[[alternative HTML version deleted]]


From jinyancool at 163.com  Wed Dec 24 13:20:31 2014
From: jinyancool at 163.com (Jinyan)
Date: Wed, 24 Dec 2014 20:20:31 +0800 (CST)
Subject: [R] plot=FALSE in heatmap.2
Message-ID: <6fbc2f4f.1ebf3.14a7c3dc7de.Coremail.jinyancool@163.com>

Dear expert,

I want to get the calucation from heatmap.2. But I do not want to do the plot. Is there any trick do this, e.g, plot=FALSE in heatmap.2?

hm <- heatmap.2(dat.mat,
                    col=greenred(75),
                    dendrogram="none",
                    scale="row",
                    key=FALSE,
                    Rowv=FALSE,
                    Colv=FALSE,
                    symkey=FALSE,
                    density.info="none",
                    trace="none", cexRow=0.5)
	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Dec 24 17:29:14 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 24 Dec 2014 08:29:14 -0800
Subject: [R] Carrying a value down a data.frame conditionally
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB4FC78097@EX03DR.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB4FC78097@EX03DR.platinum.com>
Message-ID: <CAF8bMcYSPJHsjMakKP5pQ3fmsarM8ruhREAcg1k4inADFqvf3w@mail.gmail.com>

A while ago I wrote for a questioner on this list a function, 'f1', below,
that would give the start and stop times of runs of data that started when
then the data went above a threshold and stopped when it first dropped
below a different (lower) threshold).  It used no loops and was pretty
quick.

With your data you could use it as
  > ss <- with(df, f1( (Value>=40)+Signal*2, start=2, stop=1))
  > ss
    start stop
  1     2    4
  2    10   10
You can convert those start and stop times to a vector with 1's in the runs
and 0's outside of the runs with something like
  > v <- integer(length(df$Value))
  > v[ss$start] <- 1
  > v[pmain(ss$stop+1, length(v))] <- -1
  > cumsum(v)
   [1] 0 1 1 1 0 0 0 0 0 1 0 0

f1 would be trivial to write in C/C++.  It needs a better name.


f1 <-
function(x, startThreshold, stopThreshold, plot=FALSE) {
    # find intervals that
    #  start when x goes above startThreshold and
    #  end when x goes below stopThreshold.
    stopifnot(startThreshold > stopThreshold)
    isFirstInRun <- function(x)c(TRUE, x[-1] != x[-length(x)])
    isLastInRun <- function(x)c(x[-1] != x[-length(x)], TRUE)
    isOverStart <- x >= startThreshold
    isOverStop <- x >= stopThreshold
    possibleStartPt <- which(isFirstInRun(isOverStart) & isOverStart)
    possibleStopPt <- which(isLastInRun(isOverStop) & isOverStop)
    pts <- c(possibleStartPt, possibleStopPt)
    names(pts) <- rep(c("start","stop"),
      c(length(possibleStartPt), length(possibleStopPt)))
    pts <- pts[order(pts)]
    tmp <- isFirstInRun(names(pts))
    start <- pts[tmp & names(pts)=="start"]
    stop <- pts[tmp & names(pts)=="stop"]
    # Remove case where first downcrossing happens
    # before first upcrossing.
    if (length(stop) > length(start)) stop <- stop[-1]

    if (plot) {
        plot(x, cex=.5)
        abline(h=c(startThreshold, stopThreshold))
        abline(v=start, col="green")
        abline(v=stop, col="red")
    }
    data.frame(start=start, stop=stop)
}


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Dec 23, 2014 at 2:57 PM, Pooya Lalehzari <plalehzari at platinumlp.com>
wrote:
>
> Hello,
> I have a data.frame (below) containing the two fields of "Value" and
> "Signal" and I would need to create the third field of "To_Be_Produced".
> The condition for producing the third field is to carry the 1 in the
> "Signal" field down until "Value" is below 40.
> Do I have to create a for-loop to do this or will I be able to do anything
> else more efficient?
>
>
> df <- data.frame( Value=c(0,0,100,85,39,1,30,40,20,20,0,0),
>                   Signal=c(0,1,0,0,0,0,0,0,0,1,0,0),
>                   To_Be_Produced= c(0,1,1,1,0,0,0,0,0,1,0,0)
>                 )
>
> Thank you,
> Pooya.
>
>
>
>
> ***
> We are pleased to announce that, as of October 20th, 2014, we've moved to
> our new office at:
> Platinum Partners
> 250 West 55th Street, 14th Floor, New York, NY 10019
> T: 212.582.2222 | F: 212.582.2424
> ***
> THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY
> CONTAIN
> CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE,
> DISCLOSURE
> OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT,
> PLEASE
> CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL
> E-MAIL.
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mbmiller+l at gmail.com  Wed Dec 24 20:30:41 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Wed, 24 Dec 2014 13:30:41 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
Message-ID: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>

R 3.0.1 on Linux 64...

I was working with someone else's code.  They were using ave() in a way 
that I guess is nonstandard:  Isn't FUN always supposed to be a variant of 
mean()?  The idea was to count for every element of a factor vector how 
many times the level of that element occurs in the factor vector.


gl() makes a factor:

> gl(2,2,5)
[1] 1 1 2 2 1
Levels: 1 2


ave() applies FUN to produce the desired count, and it works:

> ave( 1:5, gl(2,2,5), FUN=length )
[1] 3 3 2 2 3


The elements of the first vector are irrelevant because they are only 
counted, so we should get the same result if it were a character vector, 
but we don't:

> ave( as.character(1:5), gl(2,2,5), FUN=length )
[1] "3" "3" "2" "2" "3"

The output has character type, but it is supposed to be a collection of 
vector lengths.


Two questions:

(1) Is that a bug in ave()?  It certainly is unexpected.

(2) What is the best way to do this sort of thing?

The truth is that we start with a character vector and we want to create 
an integer vector that tells us for every element of the character vector 
how many times that string occurs.  Here are two vectors of length 6 that 
should give the same result:

> intvec <- c(4,5,6,5,6,6)
> charvec <- c("A","B","C","B","C","C")

The code was used like this with integer vectors and it seemed to work:

> ave( intvec, intvec, FUN=length )
[1] 1 2 3 2 3 3

When a character vector came along, it would fail by producing a character 
vector as output:

> ave( charvec, charvec, FUN=length )
[1] "1" "2" "3" "2" "3" "3"

This seems more appropriate, and it might always work, but is it OK?:

> ave( rep(1, length(charvec)), as.factor(charvec), FUN=sum )
[1] 1 2 3 2 3 3

I suspect that ave() isn't the best choice, but what is the best way to do 
this?


Thanks in advance.

Mike


From gunter.berton at gene.com  Wed Dec 24 20:49:13 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 24 Dec 2014 11:49:13 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
Message-ID: <CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>

You said:
"The elements of the first vector are irrelevant because they are only
counted, so we should get the same result if it were a character
vector, but we don't: "

You don't get to invent your own rules! ?ave -- always nice to read
the Help docs **before posting** -- clearly states that the x argument
must be __numeric__. So if you choose to ignore what you are told, you
do so at your own risk. Who knows what you'll get? --  it's a user
error, not a bug.

And if (my understanding of) what you say is the case, this whole post
is silly. See ?table to do exactly what you claim is wanted without
trying to invent square wheels.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Dec 24, 2014 at 11:30 AM, Mike Miller <mbmiller+l at gmail.com> wrote:
> R 3.0.1 on Linux 64...
>
> I was working with someone else's code.  They were using ave() in a way that
> I guess is nonstandard:  Isn't FUN always supposed to be a variant of
> mean()?  The idea was to count for every element of a factor vector how many
> times the level of that element occurs in the factor vector.
>
>
> gl() makes a factor:
>
>> gl(2,2,5)
>
> [1] 1 1 2 2 1
> Levels: 1 2
>
>
> ave() applies FUN to produce the desired count, and it works:
>
>> ave( 1:5, gl(2,2,5), FUN=length )
>
> [1] 3 3 2 2 3
>
>
> The elements of the first vector are irrelevant because they are only
> counted, so we should get the same result if it were a character vector, but
> we don't:
>
>> ave( as.character(1:5), gl(2,2,5), FUN=length )
>
> [1] "3" "3" "2" "2" "3"
>
> The output has character type, but it is supposed to be a collection of
> vector lengths.
>
>
> Two questions:
>
> (1) Is that a bug in ave()?  It certainly is unexpected.
>
> (2) What is the best way to do this sort of thing?
>
> The truth is that we start with a character vector and we want to create an
> integer vector that tells us for every element of the character vector how
> many times that string occurs.  Here are two vectors of length 6 that should
> give the same result:
>
>> intvec <- c(4,5,6,5,6,6)
>> charvec <- c("A","B","C","B","C","C")
>
>
> The code was used like this with integer vectors and it seemed to work:
>
>> ave( intvec, intvec, FUN=length )
>
> [1] 1 2 3 2 3 3
>
> When a character vector came along, it would fail by producing a character
> vector as output:
>
>> ave( charvec, charvec, FUN=length )
>
> [1] "1" "2" "3" "2" "3" "3"
>
> This seems more appropriate, and it might always work, but is it OK?:
>
>> ave( rep(1, length(charvec)), as.factor(charvec), FUN=sum )
>
> [1] 1 2 3 2 3 3
>
> I suspect that ave() isn't the best choice, but what is the best way to do
> this?
>
>
> Thanks in advance.
>
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From NordlDJ at dshs.wa.gov  Wed Dec 24 21:06:15 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 24 Dec 2014 20:06:15 +0000
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623AEC039@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Mike
> Miller
> Sent: Wednesday, December 24, 2014 11:31 AM
> To: R-Help List
> Subject: [R] ave(x, y, FUN=length) produces character output when x is
> character
> 
> R 3.0.1 on Linux 64...
> 
> I was working with someone else's code.  They were using ave() in a way
> that I guess is nonstandard:  Isn't FUN always supposed to be a variant
> of
> mean()?  The idea was to count for every element of a factor vector how
> many times the level of that element occurs in the factor vector.
> 
> 
> gl() makes a factor:
> 
> > gl(2,2,5)
> [1] 1 1 2 2 1
> Levels: 1 2
> 
> 
> ave() applies FUN to produce the desired count, and it works:
> 
> > ave( 1:5, gl(2,2,5), FUN=length )
> [1] 3 3 2 2 3
> 
> 
> The elements of the first vector are irrelevant because they are only
> counted, so we should get the same result if it were a character
> vector,
> but we don't:
> 
> > ave( as.character(1:5), gl(2,2,5), FUN=length )
> [1] "3" "3" "2" "2" "3"
> 
> The output has character type, but it is supposed to be a collection of
> vector lengths.
> 
> 
> Two questions:
> 
> (1) Is that a bug in ave()?  It certainly is unexpected.
> 
> (2) What is the best way to do this sort of thing?
> 
> The truth is that we start with a character vector and we want to
> create
> an integer vector that tells us for every element of the character
> vector
> how many times that string occurs.  Here are two vectors of length 6
> that
> should give the same result:
> 
> > intvec <- c(4,5,6,5,6,6)
> > charvec <- c("A","B","C","B","C","C")
> 
> The code was used like this with integer vectors and it seemed to work:
> 
> > ave( intvec, intvec, FUN=length )
> [1] 1 2 3 2 3 3
> 
> When a character vector came along, it would fail by producing a
> character
> vector as output:
> 
> > ave( charvec, charvec, FUN=length )
> [1] "1" "2" "3" "2" "3" "3"
> 
> This seems more appropriate, and it might always work, but is it OK?:
> 
> > ave( rep(1, length(charvec)), as.factor(charvec), FUN=sum )
> [1] 1 2 3 2 3 3
> 
> I suspect that ave() isn't the best choice, but what is the best way to
> do
> this?
> 
> 
> Thanks in advance.
> 
> Mike

For your character vector example, this will get you the counts.

table(charvec)[charvec]


Hope this is helpful,

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From mbmiller+l at gmail.com  Wed Dec 24 21:39:59 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Wed, 24 Dec 2014 14:39:59 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>

On Wed, 24 Dec 2014, Bert Gunter wrote:

> You said:
> "The elements of the first vector are irrelevant because they are only
> counted, so we should get the same result if it were a character
> vector, but we don't: "
>
> You don't get to invent your own rules! ?ave -- always nice to read the 
> Help docs **before posting** -- clearly states that the x argument must 
> be __numeric__. So if you choose to ignore what you are told, you do so 
> at your own risk. Who knows what you'll get? -- it's a user error, not a 
> bug.

I guess the goal is to humiliate the person who posted the question. 
I've had trouble convincing doctoral students in biostat to post questions 
here because they are afraid of being treated like dirt.  It doesn't 
bother me personally, but I see it as counterproductive.  The code I was 
working with was written by such a student and it has been in CRAN for a 
couple of years.  I'm just trying to fix it.  Your comment is helpful, but 
it would have been even better without the hostile tone.

Regarding the way ave() works -- why doesn't it check that the input 
vector is numeric?  Apparently, integer input is acceptable.  Does numeric 
sometimes mean "numeric" and sometimes "either 'integer' or 'numeric'"? 
Either way, if character is unacceptable, it could throw an error instead 
of pumping out an almost-correct answer.  That made it much harder to 
track down the bug in the code base I was working on.

Also, regarding the sacred text, "x A numeric." is a bit terse.  The same 
text later refers to length(x), so I suspect that "A numeric" is short for 
"A numeric vector", but that might not mean "a vector of 'numeric' type."

https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ave.html


> And if (my understanding of) what you say is the case, this whole post 
> is silly. See ?table to do exactly what you claim is wanted without 
> trying to invent square wheels.

table() counts elements but it has to repeat them in the proper pattern.

For every element of a vector we want to know how many times it occurs in 
that vector.  So if the vector is c("A","A","B","C","C","C") the output 
should be c(2,2,1,3,3,3).  I'm sure we all know that table() will count 
the elements, but it doesn't place them in a vector as desired.  I can do 
this with a character vector:

> charvec <- c("A","A","B","C","C","C")
> as.vector(( table( charvec )[charvec] ))
[1] 2 2 1 3 3 3

It's slightly trickier with an integer vector:

> intvec <- c(4,4,5,6,6,6)
> table( intvec )[intvec]
intvec
<NA> <NA> <NA> <NA> <NA> <NA>
   NA   NA   NA   NA   NA   NA
> as.vector(table( intvec )[as.character(intvec)])
[1] 2 2 1 3 3 3

So I think this will always work for vectors of either type:

as.vector(table( as.character(vec) )[as.character(vec)])

To me that looks like the right way to do it.  Think so?

Best,
Mike


> On Wed, Dec 24, 2014 at 11:30 AM, Mike Miller <mbmiller+l at gmail.com> wrote:
>> R 3.0.1 on Linux 64...
>>
>> I was working with someone else's code.  They were using ave() in a way that
>> I guess is nonstandard:  Isn't FUN always supposed to be a variant of
>> mean()?  The idea was to count for every element of a factor vector how many
>> times the level of that element occurs in the factor vector.
>>
>>
>> gl() makes a factor:
>>
>>> gl(2,2,5)
>>
>> [1] 1 1 2 2 1
>> Levels: 1 2
>>
>>
>> ave() applies FUN to produce the desired count, and it works:
>>
>>> ave( 1:5, gl(2,2,5), FUN=length )
>>
>> [1] 3 3 2 2 3
>>
>>
>> The elements of the first vector are irrelevant because they are only
>> counted, so we should get the same result if it were a character vector, but
>> we don't:
>>
>>> ave( as.character(1:5), gl(2,2,5), FUN=length )
>>
>> [1] "3" "3" "2" "2" "3"
>>
>> The output has character type, but it is supposed to be a collection of
>> vector lengths.
>>
>>
>> Two questions:
>>
>> (1) Is that a bug in ave()?  It certainly is unexpected.
>>
>> (2) What is the best way to do this sort of thing?
>>
>> The truth is that we start with a character vector and we want to create an
>> integer vector that tells us for every element of the character vector how
>> many times that string occurs.  Here are two vectors of length 6 that should
>> give the same result:
>>
>>> intvec <- c(4,5,6,5,6,6)
>>> charvec <- c("A","B","C","B","C","C")
>>
>>
>> The code was used like this with integer vectors and it seemed to work:
>>
>>> ave( intvec, intvec, FUN=length )
>>
>> [1] 1 2 3 2 3 3
>>
>> When a character vector came along, it would fail by producing a character
>> vector as output:
>>
>>> ave( charvec, charvec, FUN=length )
>>
>> [1] "1" "2" "3" "2" "3" "3"
>>
>> This seems more appropriate, and it might always work, but is it OK?:
>>
>>> ave( rep(1, length(charvec)), as.factor(charvec), FUN=sum )
>>
>> [1] 1 2 3 2 3 3
>>
>> I suspect that ave() isn't the best choice, but what is the best way to do
>> this?
>>
>>
>> Thanks in advance.
>>
>> Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From mbmiller+l at gmail.com  Wed Dec 24 21:44:21 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Wed, 24 Dec 2014 14:44:21 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276623AEC039@WAXMXOLYMB025.WAX.wa.lcl>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<F7E6D18CC2877149AB5296CE54EA276623AEC039@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <alpine.DEB.2.00.1412241440190.14665@taxa.psych.umn.edu>

On Wed, 24 Dec 2014, Nordlund, Dan (DSHS/RDA) wrote:

> For your character vector example, this will get you the counts.
>
> table(charvec)[charvec]
>
> Hope this is helpful,


It does help, Dan!  I came up with the same idea and expanded on it a bit 
to work properly with other kinds of vectors:

as.vector(table( as.character(vec) )[as.character(vec)])

If there are, say, 10,000 different elements in vec, each repeated an 
average of 5-10 times, will this still work correctly?  In other words, 
the length of the table output array is unlimited, right?

Mike


From NordlDJ at dshs.wa.gov  Wed Dec 24 22:04:19 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 24 Dec 2014 21:04:19 +0000
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412241440190.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<F7E6D18CC2877149AB5296CE54EA276623AEC039@WAXMXOLYMB025.WAX.wa.lcl>
	<alpine.DEB.2.00.1412241440190.14665@taxa.psych.umn.edu>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623AEC055@WAXMXOLYMB025.WAX.wa.lcl>

Mike,

The output is only limited by available RAM and the maximum permissible length for vectors.  And you can test it fairly easily.

vec <- sample(1:2000,10000,replace=TRUE)

Dan

Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services


> -----Original Message-----
> From: Mike Miller [mailto:mbmiller at gmail.com] On Behalf Of Mike Miller
> Sent: Wednesday, December 24, 2014 12:44 PM
> To: Nordlund, Dan (DSHS/RDA)
> Cc: R-Help List
> Subject: Re: [R] ave(x, y, FUN=length) produces character output when x
> is character
> 
> On Wed, 24 Dec 2014, Nordlund, Dan (DSHS/RDA) wrote:
> 
> > For your character vector example, this will get you the counts.
> >
> > table(charvec)[charvec]
> >
> > Hope this is helpful,
> 
> 
> It does help, Dan!  I came up with the same idea and expanded on it a
> bit
> to work properly with other kinds of vectors:
> 
> as.vector(table( as.character(vec) )[as.character(vec)])
> 
> If there are, say, 10,000 different elements in vec, each repeated an
> average of 5-10 times, will this still work correctly?  In other words,
> the length of the table output array is unlimited, right?
> 
> Mike

From wdunlap at tibco.com  Wed Dec 24 22:34:02 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 24 Dec 2014 13:34:02 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
Message-ID: <CAF8bMcb0FLJoKyvMjZpzxmDmh7h3vq-gdmhYB6oL_H2_q6sDJw@mail.gmail.com>

   > ave( as.character(1:5), gl(2,2,5), FUN=length )
   [1] "3" "3" "2" "2" "3"The output has character type, but it is supposed
to be a collection of vector lengths.

ave() uses its first argument, 'x', to set the length of its output and to
make
an initial guess at the type of its output.  The return value of FUN can
alter
the type, but only in an 'upward' direction where
logical<integer<numeric<complex
<character<list.  (This is the same rule that x[i]<-newvalue uses.)

As currently written, ave also lets FUN(xi) return a vector the length of
xi,
not just a single value.  E.g.,
  > ave(105:101, c("A","A","B","A","B"), FUN=sort)
  [1] 102 104 101 105 103
  > ave(105:101, c("A","A","B","A","B"), FUN=function(xi)xi-mean(xi))
  [1]  1.3333333  0.3333333  1.0000000 -1.6666667 -1.0000000

I don't know what the docs say about that, but I often find that more
useful than
having it repeat the output of mean(xi).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Dec 24, 2014 at 11:30 AM, Mike Miller <mbmiller+l at gmail.com> wrote:
>
> R 3.0.1 on Linux 64...
>
> I was working with someone else's code.  They were using ave() in a way
> that I guess is nonstandard:  Isn't FUN always supposed to be a variant of
> mean()?  The idea was to count for every element of a factor vector how
> many times the level of that element occurs in the factor vector.
>
>
> gl() makes a factor:
>
>  gl(2,2,5)
>>
> [1] 1 1 2 2 1
> Levels: 1 2
>
>
> ave() applies FUN to produce the desired count, and it works:
>
>  ave( 1:5, gl(2,2,5), FUN=length )
>>
> [1] 3 3 2 2 3
>
>
> The elements of the first vector are irrelevant because they are only
> counted, so we should get the same result if it were a character vector,
> but we don't:
>
>  ave( as.character(1:5), gl(2,2,5), FUN=length )
>>
> [1] "3" "3" "2" "2" "3"
>
> The output has character type, but it is supposed to be a collection of
> vector lengths.
>
>
> Two questions:
>
> (1) Is that a bug in ave()?  It certainly is unexpected.
>
> (2) What is the best way to do this sort of thing?
>
> The truth is that we start with a character vector and we want to create
> an integer vector that tells us for every element of the character vector
> how many times that string occurs.  Here are two vectors of length 6 that
> should give the same result:
>
>  intvec <- c(4,5,6,5,6,6)
>> charvec <- c("A","B","C","B","C","C")
>>
>
> The code was used like this with integer vectors and it seemed to work:
>
>  ave( intvec, intvec, FUN=length )
>>
> [1] 1 2 3 2 3 3
>
> When a character vector came along, it would fail by producing a character
> vector as output:
>
>  ave( charvec, charvec, FUN=length )
>>
> [1] "1" "2" "3" "2" "3" "3"
>
> This seems more appropriate, and it might always work, but is it OK?:
>
>  ave( rep(1, length(charvec)), as.factor(charvec), FUN=sum )
>>
> [1] 1 2 3 2 3 3
>
> I suspect that ave() isn't the best choice, but what is the best way to do
> this?
>
>
> Thanks in advance.
>
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruzudumyan at gmail.com  Wed Dec 24 23:09:58 2014
From: ruzudumyan at gmail.com (Ruzan Udumyan)
Date: Wed, 24 Dec 2014 23:09:58 +0100
Subject: [R] Getting HR from Cox model in R
In-Reply-To: <5499A4B2.6060809@aghmed.fsnet.co.uk>
References: <CAJbUeXbZWbxa0AJ0KGLsAcyqhMqg70v=KLvGhLKSQX8wR6qrPQ@mail.gmail.com>
	<5499A4B2.6060809@aghmed.fsnet.co.uk>
Message-ID: <CAJbUeXaJ0o4S-wvoswvUD9vsSJ6wttySYc3rXHjXhxEMmrzpUg@mail.gmail.com>

Dear Michael,

Thank you very much for your reply. The more complete information is as
follows:

I want to do a mediation analysis following the below-mentioned syntax
from:
http://www.biomedcentral.com/content/supplementary/1471-2288-14-9-s1.pdf

I did not define categorical variables as logical variables. I modelled
them as *factor.X, factor.Xstar*, etc. the X variable has 3 levels.

It is all sorted but I am not sure about the last bit: to return the
values. For example, I could not figure out what unname stands for, and
whether it is correct to use when variables are modelled as factor.X.

I wrote the syntax as:

 TE2 = exp(sum(coef(cox)[c('factor(X)2', 'factor(Xstar)2')]))   # level 2
vs level 1(ref)
 TE3 = exp(sum(coef(cox)[c('factor(X)3', 'factor(Xstar)3')]))   # level 3
vs level 1(ref)


  DE2 = exp(unname(coef(cox)['factor(X)2']))
  DE3 = exp(unname(coef(cox)['factor(X)3']))


  IE2 = exp(sum(coef(cox)['factor(Xstar)2']))
  IE3 = exp(sum(coef(cox)['factor(Xstar)3']))

  PM2 = log(IE2) / log(TE2)
  PM3 = log(IE3) / log(TE3)


Thank you very much for your help.

Wishing you happy holidays,
Ruzan


*The script from the link:*
doEffectDecomp = function(d)
{
 # Step 1: Replicate exposure variable, predict mediator
 d$TrialTemp = d$Trial
 MOpti = glm(Opti ~ TrialTemp + Age5 + ECOG + Ascit + Comorb + Histo +
 Grade, family=binomial(), data=d)

# Step 2: Replicate data with different exposures for the mediator
 d1 = d2 = d
 d1$Med = d1$Trial
 d2$Med = !d2$Trial
 newd = rbind(d1, d2)

# Step 3: Compute weights for the mediator
 newd$TrialTemp = newd$Trial
 w = predict(MOpti, newdata=newd, type='response')
 direct = ifelse(newd$Opti, w, 1-w)
 newd$TrialTemp = newd$Med
 w = predict(MOpti, newdata=newd, type='response')
 indirect = ifelse(newd$Opti, w, 1-w)
 newd$W = indirect/direct

# Step 4: Weighted Cox Model
 cox = coxph(Surv(OS, Status) ~ Trial + Med + Age5 + ECOG + Ascit +
 Comorb + Histo + Grade, weight=W, data=newd)

# Return value: Estimates for total, direct, indirect effect
 TE = exp(sum(coef(cox)[c('TrialTRUE', 'MedTRUE')]))
 DE = exp(unname(coef(cox)['TrialTRUE']))
 IE = exp(sum(coef(cox)['MedTRUE']))
 PM = log(IE) / log(TE)
 return(c(exp(coef(cox)), TE=TE, DE=DE, IE=IE, PM=PM))
}

On Tue, Dec 23, 2014 at 6:21 PM, Michael Dewey <info at aghmed.fsnet.co.uk>
wrote:

> Inline comments
>
> On 23/12/2014 09:42, Ruzan Udumyan wrote:
>
>> Dear All,
>>
>> I am not familiar with R language well. Could you please help me interpret
>> these commands?:
>>
>>
>>   TE = exp(sum(coef(cox)[c('aTRUE', 'bTRUE')]))   - does it mean
>> exp(coef(a
>> variable) + coef(b variable)) ?
>>
>
> You have not given us much to go on here.
> I assume if you go
> coef(cox)
> you will find elements labelled aTRUE and bTRUE which implies the
> existence of a logical covariate with values TRUE and FALSE. The author of
> the code is trying to do what you suggest.
>
>    DE = exp(unname(coef(cox)['aTRUE']))  - what is unname for ?
>>
>>
> ?unname
>
>  Thank you very much beforehand for your help.
>>
>> Wishing you happy holidays,
>> Ruzan
>>
>>         [[alternative HTML version deleted]]
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> If you post again please do read the message above.
>
>
>
>> -----
>> No virus found in this message.
>> Checked by AVG - www.avg.com
>> Version: 2015.0.5577 / Virus Database: 4257/8792 - Release Date: 12/23/14
>>
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk
>

	[[alternative HTML version deleted]]


From thomas.f.hahn2 at gmail.com  Wed Dec 24 22:59:31 2014
From: thomas.f.hahn2 at gmail.com (thomas hahn)
Date: Wed, 24 Dec 2014 15:59:31 -0600
Subject: [R] Help with finding R tutors for microarray analysis,
 next generation sequencing and constructing gene interaction
 networks needed
Message-ID: <CAKJ67ZUquT-=gggK9-k4d_rpEqpH3qUehMCyPwuUif4x13JyNw@mail.gmail.com>

Help with finding R tutors for microarray analysis, next generation
sequencing and constructing gene interaction networks needed

Hi

I am a visually impaired bioinformatics graduate student using microarray
data for my master?s thesis aimed at deciphering the mechanism by which the
yeast wild type can suppress the rise of free reactive oxygen species (ROS)
induced by caloric restriction (CR) but the Atg15 and Erg6 knockout mutant
cannot.



Since my remaining vision is very limited I need very high magnification.
But that makes my visual field very small.  Therefore I need somebody to
guide me remotely through the R environment and teach me how to best use
the R packages for bioinformatics, especially for microarray analysis, next
generation sequencing and constructing gene and pathway interaction
networks.  This is very difficult for me to figure out without assistance
because Zoomtext, my magnification and text to speech software, on which I
am depending because I am almost blind, has problems reading out aloud many
R related websites to me.  And even those websites it can read, it can only
read sequentially from left to right and then from top to bottom.
Unfortunately, this way of acquiring, finding, selecting and processing new
information and answering my questions is too tiresome, exhausting,
ineffective and especially way too time consuming for graduating with a PhD
in bioinformatics before my funding runs out despite being severely limited
by my visual disability.



Since I am legally blind the rehab agency is giving me money to pay tutors
for this purpose.  Could you please help me getting in touch regarding this
with anybody, who could potentially be interested in teaching me R thus
saving me time for acquiring new information and skills, which I need to
finish my thesis on time, so that I can remain eligible for funding to
continue in my bioinformatics PhD program despite being almost blind?  The
tutoring can be done remotely via TeamViewer 5 and Skype.  Hence, it does
not matter where my tutors are physically located.  Currently I have tutors
in Croatia and UK.  But since they both work full time jobs while working
on their PhD dissertation they only have very limited time to teach me
online.  Could you therefore please forward this request for help to
anybody, who could potentially be interested or, who could connect me to
somebody, who might be, because my graduation and career depend on it?  Who
else would you recommend me to contact regarding this?

Could you please contact me directly via Email (Thomas.F.Hahn2 at gmail.com)
or Skype (tfh002) because my text to speech software cannot read this forum
website?


I thank you very much in advance for your thoughts, ideas, suggestions,
recommendations, time, help, efforts and support.

With very warm regards,



*Thomas Hahn*



Cell phone: (318) 243 3940

Skype ID: tfh002

Preferred email: Thomas.F.Hahn2 at gmail.com

	[[alternative HTML version deleted]]


From mbmiller+l at gmail.com  Thu Dec 25 03:49:47 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Wed, 24 Dec 2014 20:49:47 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
Message-ID: <alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>

On Wed, 24 Dec 2014, Mike Miller wrote:

> Also, regarding the sacred text, "x A numeric." is a bit terse.  The 
> same text later refers to length(x), so I suspect that "A numeric" is 
> short for "A numeric vector", but that might not mean "a vector of 
> 'numeric' type."


I just realized that numeric type includes integer so that anything of 
type integer also is type numeric.  I'm working on another message.

Mike


From jdnewmil at dcn.davis.CA.us  Thu Dec 25 05:19:57 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 24 Dec 2014 20:19:57 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
Message-ID: <9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>

But all numeric types in R are vectors. So although it might be a good idea to be redundant to aid beginners, the phrase "a numeric" is accurate.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 24, 2014 6:49:47 PM PST, Mike Miller <mbmiller+l at gmail.com> wrote:
>On Wed, 24 Dec 2014, Mike Miller wrote:
>
>> Also, regarding the sacred text, "x A numeric." is a bit terse.  The 
>> same text later refers to length(x), so I suspect that "A numeric" is
>
>> short for "A numeric vector", but that might not mean "a vector of 
>> 'numeric' type."
>
>
>I just realized that numeric type includes integer so that anything of 
>type integer also is type numeric.  I'm working on another message.
>
>Mike
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mbmiller+l at gmail.com  Thu Dec 25 05:45:51 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Wed, 24 Dec 2014 22:45:51 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
Message-ID: <alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>

On Wed, 24 Dec 2014, Jeff Newmiller wrote:

> On December 24, 2014 6:49:47 PM PST, Mike Miller <mbmiller+l at gmail.com> wrote:
>
>> On Wed, 24 Dec 2014, Mike Miller wrote:
>>
>>> Also, regarding the sacred text, "x A numeric." is a bit terse.  The 
>>> same text later refers to length(x), so I suspect that "A numeric" is
>>
>>> short for "A numeric vector", but that might not mean "a vector of 
>>> 'numeric' type."
>>
>>
>> I just realized that numeric type includes integer so that anything of 
>> type integer also is type numeric.  I'm working on another message.
>
>
> But all numeric types in R are vectors. So although it might be a good 
> idea to be redundant to aid beginners, the phrase "a numeric" is 
> accurate.


Interesting, but the data seem to contradict your theory.  Here are two 
examples, one with a numeric matrix, the other with a numeric array, and 
both of them run in ave().

> x <- matrix(1:4, 2,2)

> is.numeric(x)
[1] TRUE

> is.vector(x)
[1] FALSE

> ave(x, gl(2,2))
      [,1] [,2]
[1,]  1.5  3.5
[2,]  1.5  3.5


> x <- as.array(1:4)

> is.numeric(x)
[1] TRUE

> is.vector(x)
[1] FALSE

> ave(x, gl(2,2))
[1] 1.5 1.5 3.5 3.5


So maybe slightly more documentation for ave() would be helpful even for 
non-beginners like yourself.

Thanks.

Mike

-- 
Michael B. Miller, Ph.D.
University of Minnesota
http://scholar.google.com/citations?user=EV_phq4AAAAJ


From gunter.berton at gene.com  Thu Dec 25 06:27:01 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 24 Dec 2014 21:27:01 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
Message-ID: <CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>

You are again misinterpreting because you have not read the docs,
although this time I will grant that they are to some extent
misleading.

First of all, a matrix _IS_ a vector:

> a <- matrix(1:4, 2,2)
> a[3] ## vector indexing works because it is a vector
[1] 3

In fact, a matrix (or array) is a vector with a "dim" attribute. This
is documented in ?matrix:

"is.matrix returns TRUE if x is a vector and has a "dim" attribute of
length 2) and FALSE otherwise."

Your confusion arises because, despite its name, is.vector() does not
actually test whether something "is" a vector (after all these are all
abstractions; what it "is" is contents of memory, implemented as a
linked list or some such).  ?is.vector tells you:

"is.vector returns TRUE if x is a vector of the specified mode having
no attributes other than names. It returns FALSE otherwise."

An array has a "dim" attribute, so is.vector() returns FALSE on it.
But it actually _is_ ("behaves like") a vector (in column major
order,actually).

Now you may complain that this is confusing and I would agree. Why is
it this way? I dunno -- probably due to historical quirks -- evolution
is not necessarily orderly. But that's the way it is; that's the way
it's documented; and tutorials will tell you about this (that's how I
learned). So please stop guessing and intuiting and read the docs to
understand how things work.

Cheers,
Bert


Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Dec 24, 2014 at 8:45 PM, Mike Miller <mbmiller+l at gmail.com> wrote:
> On Wed, 24 Dec 2014, Jeff Newmiller wrote:
>
>> On December 24, 2014 6:49:47 PM PST, Mike Miller <mbmiller+l at gmail.com>
>> wrote:
>>
>>> On Wed, 24 Dec 2014, Mike Miller wrote:
>>>
>>>> Also, regarding the sacred text, "x A numeric." is a bit terse.  The
>>>> same text later refers to length(x), so I suspect that "A numeric" is
>>>
>>>
>>>> short for "A numeric vector", but that might not mean "a vector of
>>>> 'numeric' type."
>>>
>>>
>>>
>>> I just realized that numeric type includes integer so that anything of
>>> type integer also is type numeric.  I'm working on another message.
>>
>>
>>
>> But all numeric types in R are vectors. So although it might be a good
>> idea to be redundant to aid beginners, the phrase "a numeric" is accurate.
>
>
>
> Interesting, but the data seem to contradict your theory.  Here are two
> examples, one with a numeric matrix, the other with a numeric array, and
> both of them run in ave().
>
>> x <- matrix(1:4, 2,2)
>
>
>> is.numeric(x)
>
> [1] TRUE
>
>> is.vector(x)
>
> [1] FALSE
>
>> ave(x, gl(2,2))
>
>      [,1] [,2]
> [1,]  1.5  3.5
> [2,]  1.5  3.5
>
>
>> x <- as.array(1:4)
>
>
>> is.numeric(x)
>
> [1] TRUE
>
>> is.vector(x)
>
> [1] FALSE
>
>> ave(x, gl(2,2))
>
> [1] 1.5 1.5 3.5 3.5
>
>
> So maybe slightly more documentation for ave() would be helpful even for
> non-beginners like yourself.
>
> Thanks.
>
> Mike
>
> --
> Michael B. Miller, Ph.D.
> University of Minnesota
> http://scholar.google.com/citations?user=EV_phq4AAAAJ


From mbmiller+l at gmail.com  Thu Dec 25 08:15:28 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 01:15:28 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>

On Wed, 24 Dec 2014, Bert Gunter wrote:

> You are again misinterpreting because you have not read the docs, 
> although this time I will grant that they are to some extent misleading.
>
> First of all, a matrix _IS_ a vector:
>
>> a <- matrix(1:4, 2,2)
>> a[3] ## vector indexing works because it is a vector
> [1] 3
>
> In fact, a matrix (or array) is a vector with a "dim" attribute. This
> is documented in ?matrix:
>
> "is.matrix returns TRUE if x is a vector and has a "dim" attribute of
> length 2) and FALSE otherwise."

But a vector has no such attribute, so a matrix is not a vector which is 
why you see this:

> a <- matrix(1:4, 2,2)
> is.vector(a)
[1] FALSE

Of course the matrix can be coerced back into a vector just as the vector 
was coerced into a matrix:

> b <- as.vector(a)
> is.vector(b)
[1] TRUE


> Your confusion arises because, despite its name, is.vector() does not 
> actually test whether something "is" a vector (after all these are all 
> abstractions; what it "is" is contents of memory, implemented as a 
> linked list or some such).  ?is.vector tells you:
>
> "is.vector returns TRUE if x is a vector of the specified mode having
> no attributes other than names. It returns FALSE otherwise."

So that means that a vector in R has no attributes other than names.


> An array has a "dim" attribute, so is.vector() returns FALSE on it. But 
> it actually _is_ ("behaves like") a vector (in column major 
> order,actually).

An array is a vector with additional attributes which cause it to be an 
array rather than a vector.  This is why R says FALSE when we query it 
about an array using is.vector().


> Now you may complain that this is confusing and I would agree. Why is it 
> this way? I dunno -- probably due to historical quirks -- evolution is 
> not necessarily orderly. But that's the way it is; that's the way it's 
> documented; and tutorials will tell you about this (that's how I 
> learned). So please stop guessing and intuiting and read the docs to 
> understand how things work.

I don't think it is confusing.  This is the kind of behavior I'm used to 
from other programs like Octave/MATLAB.  A vector is just an ordered list 
of numbers.  Those numbers can be put into matrices or higher-dimensional 
arrays, but they then become something more than just a vector.  A vector 
like 1:4 becomes a 2x2 matrix when we do matrix(1:4, 2,2) such that the 
number 3 which was just the third element before (and still is) is now 
also the [1,2] element of a matrix.  It didn't have that before, back when 
it was a vector, but now that it has become something more than a vector, 
it has that new property.  We can take that away using as.vector().

In many situations the behavior of the R vector and the same values in a 
matrix format will be very different:

> a <- 1:4
> b <- matrix(a, 2,2)
> a %*% a
      [,1]
[1,]   30
> b %*% b
      [,1] [,2]
[1,]    7   15
[2,]   10   22
> b %*% t(b)
      [,1] [,2]
[1,]   10   14
[2,]   14   20
> a %*% t(a)
      [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    2    4    6    8
[3,]    3    6    9   12
[4,]    4    8   12   16

That is not true in ave(), as I showed earlier, because it uses the vector 
ordering of elements in the x matrix or array (what one would get from 
as.vector()) to form the correspondence with the factor.

I get your idea, but I don't think it is correct to say "a matrix is a 
vector."  Rather, I would say that there is a standard way in which one 
can create a one-to-one correspondence between the elements of a matrix of 
given dimensions and the elements of a vector.  I believe this is usually 
called "fortran indexing," or at least that is what it is called in 
Octave.  The same thing is done with vectorization and the vec() operator 
in mathematics:

http://en.wikipedia.org/wiki/Vectorization_(mathematics)

But in math as in computing, we wouldn't say that a matrix *is* a vector. 
If vec(A) = v, that does not mean that A = v.  In R, it looks like 
as.vector() can do what vec() does, and more.

Mike

-- 
Michael B. Miller, Ph.D.
University of Minnesota
http://scholar.google.com/citations?user=EV_phq4AAAAJ


From jdnewmil at dcn.davis.CA.us  Thu Dec 25 09:59:14 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 25 Dec 2014 00:59:14 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
Message-ID: <8AEFF624-B120-4DD5-98CA-310EC272CCD9@dcn.davis.CA.us>

You have written a lot, Mike, as though we did not know it.  You are not the only one with math and multiple computing languages under your belt. The point Bert made is that the concept that a matrix IS-A vector is not just an implementation detail in R... it helps the practitioner keep straight why things like a[3] is perfectly valid when a is a matrix, and why

a*a
     [,1] [,2]
[1,]    1    9
[2,]    4   16

is true. I understand why you are uncomfortable with it, as I was once, but this is how R works so you are only impeding your own effectiveness by clinging to theory on this point.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 24, 2014 11:15:28 PM PST, Mike Miller <mbmiller+l at gmail.com> wrote:
>On Wed, 24 Dec 2014, Bert Gunter wrote:
>
>> You are again misinterpreting because you have not read the docs, 
>> although this time I will grant that they are to some extent
>misleading.
>>
>> First of all, a matrix _IS_ a vector:
>>
>>> a <- matrix(1:4, 2,2)
>>> a[3] ## vector indexing works because it is a vector
>> [1] 3
>>
>> In fact, a matrix (or array) is a vector with a "dim" attribute. This
>> is documented in ?matrix:
>>
>> "is.matrix returns TRUE if x is a vector and has a "dim" attribute of
>> length 2) and FALSE otherwise."
>
>But a vector has no such attribute, so a matrix is not a vector which
>is 
>why you see this:
>
>> a <- matrix(1:4, 2,2)
>> is.vector(a)
>[1] FALSE
>
>Of course the matrix can be coerced back into a vector just as the
>vector 
>was coerced into a matrix:
>
>> b <- as.vector(a)
>> is.vector(b)
>[1] TRUE
>
>
>> Your confusion arises because, despite its name, is.vector() does not
>
>> actually test whether something "is" a vector (after all these are
>all 
>> abstractions; what it "is" is contents of memory, implemented as a 
>> linked list or some such).  ?is.vector tells you:
>>
>> "is.vector returns TRUE if x is a vector of the specified mode having
>> no attributes other than names. It returns FALSE otherwise."
>
>So that means that a vector in R has no attributes other than names.
>
>
>> An array has a "dim" attribute, so is.vector() returns FALSE on it.
>But 
>> it actually _is_ ("behaves like") a vector (in column major 
>> order,actually).
>
>An array is a vector with additional attributes which cause it to be an
>
>array rather than a vector.  This is why R says FALSE when we query it 
>about an array using is.vector().
>
>
>> Now you may complain that this is confusing and I would agree. Why is
>it 
>> this way? I dunno -- probably due to historical quirks -- evolution
>is 
>> not necessarily orderly. But that's the way it is; that's the way
>it's 
>> documented; and tutorials will tell you about this (that's how I 
>> learned). So please stop guessing and intuiting and read the docs to 
>> understand how things work.
>
>I don't think it is confusing.  This is the kind of behavior I'm used
>to 
>from other programs like Octave/MATLAB.  A vector is just an ordered
>list 
>of numbers.  Those numbers can be put into matrices or
>higher-dimensional 
>arrays, but they then become something more than just a vector.  A
>vector 
>like 1:4 becomes a 2x2 matrix when we do matrix(1:4, 2,2) such that the
>
>number 3 which was just the third element before (and still is) is now 
>also the [1,2] element of a matrix.  It didn't have that before, back
>when 
>it was a vector, but now that it has become something more than a
>vector, 
>it has that new property.  We can take that away using as.vector().
>
>In many situations the behavior of the R vector and the same values in
>a 
>matrix format will be very different:
>
>> a <- 1:4
>> b <- matrix(a, 2,2)
>> a %*% a
>      [,1]
>[1,]   30
>> b %*% b
>      [,1] [,2]
>[1,]    7   15
>[2,]   10   22
>> b %*% t(b)
>      [,1] [,2]
>[1,]   10   14
>[2,]   14   20
>> a %*% t(a)
>      [,1] [,2] [,3] [,4]
>[1,]    1    2    3    4
>[2,]    2    4    6    8
>[3,]    3    6    9   12
>[4,]    4    8   12   16
>
>That is not true in ave(), as I showed earlier, because it uses the
>vector 
>ordering of elements in the x matrix or array (what one would get from 
>as.vector()) to form the correspondence with the factor.
>
>I get your idea, but I don't think it is correct to say "a matrix is a 
>vector."  Rather, I would say that there is a standard way in which one
>
>can create a one-to-one correspondence between the elements of a matrix
>of 
>given dimensions and the elements of a vector.  I believe this is
>usually 
>called "fortran indexing," or at least that is what it is called in 
>Octave.  The same thing is done with vectorization and the vec()
>operator 
>in mathematics:
>
>http://en.wikipedia.org/wiki/Vectorization_(mathematics)
>
>But in math as in computing, we wouldn't say that a matrix *is* a
>vector. 
>If vec(A) = v, that does not mean that A = v.  In R, it looks like 
>as.vector() can do what vec() does, and more.
>
>Mike


From mbmiller+l at gmail.com  Thu Dec 25 10:04:09 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 03:04:09 -0600
Subject: [R] debugging R code and dealing with dependencies
Message-ID: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>

I just wanted to put this out there.  It's just some of my observations 
about things that happen with R, or happened in this particular 
investigation.  There were definitely some lessons for me in this, and 
maybe that will be true of someone else.  The main thing I picked up is 
that it is good to put plenty of checks into our code -- if we expect 
input of a certain type or class, then I should either coerce input into 
that structure or test the input and throw an error.  If the function 
works very differently for different kinds of input, this should be 
documented.  The more people are doing this, the better things will go for 
everyone.


I was working with a CRAN package called RFGLS...

http://cran.r-project.org/web/packages/RFGLS/index.html

...and I was getting an error.  After a few rounds of testing I realized 
that the error was caused by a FAMID variable that was of character type.

The problem seemed to be that gls.batch() expected FAMID to be integers, 
but the default ought to be character type because family and individual 
IDs in nearly all genetic-analysis software are character strings (they 
might even be people's names).

This was the error:

Error in sum(blocksize) : invalid 'type' (character) of argument
Calls: gls.batch -> bdsmatrix

To figure out more about it, I spent a bunch of time to go from CMD BATCH 
mode to an interactive session so that I could look at traceback().  That 
got me this additional info:

> traceback()
2: bdsmatrix(sizelist, lme.out$sigma at blocks, dimnames = list(id, id))

bdsmatrix() is from a package on which RFGLS depends:

http://cran.r-project.org/web/packages/bdsmatrix/index.html

The problem is that RFGLS's gls.batch() function is sending something to 
bdsmatrix's bdsmatrix() that it can't handle.  So I look at the code for 
bdsmatrix() and I see this:

      if (any(blocksize <= 0))
          stop("Block sizes must be >0")
      if (any(as.integer(blocksize) != blocksize))
          stop("Block sizes must be integers")
      n1 <- as.integer(sum(blocksize))

The condition any(as.integer(blocksize) != blocksize)) fails (is TRUE) 
only if blocksize contains one or more noninteger numeric values.  It 
doesn't fail if blocksize is character or logical if the character strings 
are integers.  Example:

> 4=="4"
[1] TRUE

That's an interesting feature of R, but I guess that's how it works. 
Also this:

> 1=="1"
[1] TRUE
> 1==TRUE
[1] TRUE
> "1"==TRUE
[1] FALSE

bdsmatrix() has no test that blocksize is numeric, so it fails when 
sum(blocksize) cannot sum character strings.

Next I had to figure out where RFGLS's gls.batch() is going wrong in 
producing sizelist.  It is created in a number of steps, but I identified 
this line as especially suspicious:

test.dat$famsize[test.dat$FTYPE!=6]=ave(test.dat$FAMID[test.dat$FTYPE!=6],test.dat$FAMID[test.dat$FTYPE!=6],FUN=length)

famsize was later converted to sizelist, and this line also includes 
FAMID, so this is likely where the problem originates.  Of course this is 
the big problem with debugging -- it's hard to find the source of an error 
that occurs far downstream in another function from a different package. 
I see that ave() is used, so I have to understand ave().

William Dunlap provided some guidance:

"ave() uses its first argument, 'x', to set the length of its output and 
to make an initial guess at the type of its output.  The return value of 
FUN can alter the type, but only in an 'upward' direction where 
logical<integer<numeric<complex<character<list.  (This is the same rule 
that x[i]<-newvalue uses.)"

In other words, if x is of character type, the output cannot be of integer 
or numeric type even if the output of FUN is always of integer or numeric 
type.  Looking at the ave() code, I can understand that choice:

function (x, ..., FUN = mean)
{
     if (missing(...))
         x[] <- FUN(x)
     else {
         g <- interaction(...)
         split(x, g) <- lapply(split(x, g), FUN)
     }
     x
}

If the factor is missing an element, then the corresponding element of X 
is not changed in the output:

> fact <- gl(2,2)
> fact[3] <- NA
> fact
[1] 1    1    <NA> 2
Levels: 1 2
> ave(1:4, fact)
[1] 1.5 1.5 3.0 4.0

That's a reasonable plan, but it isn't the documented functioning of 
ave().  From the document...

https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ave.html

...you get next to nothing about what the function actually does.  It does 
say that x is "a numeric," but the function does not throw an error when x 
is not numeric.  So if someone writes code expecting numeric x, but a user 
provides a non-numeric x, there may be trouble.

I suspect that the programmer saw that the code worked in her examples and 
she went on to other things.  I can't blame the documentation for that, 
but it is possible that if it said something about the relation between 
the type of the input and the type of the output she might have written it 
differently.  In addition, I probably would have caught it sooner and I 
would have understood the problem.

This is how I'll recommend they fix the bug in the code (thanks to those 
of you who helped with this):

temp.vec <- as.character( test.dat$FAMID[ test.dat$FTYPE != 6 ] )
test.dat$famsize[ test.dat$FTYPE != 6 ] <- as.vector( table( temp.vec )[ temp.vec ] )
rm(temp.vec)

I think we should force FAMID to be character from the beginning, though.

Best,
Mike

FYI -- RFGLS code that fails in RFGLS version 1.1:

library(RFGLS)

data(pheno)
data(geno)
data(map)
data(pedigree)
data(rescovmtx)
  #comment out the following two lines and it will run correctly
pedigree$FAMID <- as.character(pedigree$FAMID)
pheno$FAMID <- as.character(pheno$FAMID)
minigwas <- gls.batch(phenfile=pheno,genfile=data.frame(t(geno)),
   pedifile=pedigree,
   snp.names=map[,2],input.mode=c(1,2,3),pediheader=FALSE,
   pedicolname=c("FAMID","ID","PID","MID","SEX"),
   phen="Zscore",covars="IsFemale",
   outfile=NULL,col.names=TRUE,return.value=TRUE)
str(minigwas)

Mike


From mbmiller+l at gmail.com  Thu Dec 25 10:23:34 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 03:23:34 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <8AEFF624-B120-4DD5-98CA-310EC272CCD9@dcn.davis.CA.us>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<8AEFF624-B120-4DD5-98CA-310EC272CCD9@dcn.davis.CA.us>
Message-ID: <alpine.DEB.2.00.1412250308410.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, Jeff Newmiller wrote:

> You have written a lot, Mike, as though we did not know it.  You are not 
> the only one with math and multiple computing languages under your belt.

I'm not assuming that you and Bert don't know things, but I do expect to 
have a wider audience -- when I search for things, sometimes I find my 
postings from 10 years ago.  I'm probably not the only one.


> The point Bert made is that the concept that a matrix IS-A vector is not 
> just an implementation detail in R... it helps the practitioner keep 
> straight why things like a[3] is perfectly valid when a is a matrix, and 
> why
>
> a*a
>     [,1] [,2]
> [1,]    1    9
> [2,]    4   16
>
> is true. I understand why you are uncomfortable with it, as I was once, 
> but this is how R works so you are only impeding your own effectiveness 
> by clinging to theory on this point.

Sorry, your concepts aren't helping me and I'm not uncomfortable with what 
R is doing.  In fact, what I wrote earlier is that R seems to be much like 
Octave/MATLAB, which I have used even more than I've used R.  The use of 
what Octave calls "fortran indexing" is an example.  We can refer to 
matrix element a[3] in R or element a(3) in Octave and we're referring to 
the same element.  It's also the third element of vec(a).  That doesn't 
mean that 'a' is a vector.  R says that it is not a vector.  That doesn't 
confuse me.  I can refer to the third element of a matrix even if the 
matrix is not a vector.

I don't understand how your concept helps in understanding a*a.  It's an 
element-by-element product (also called Hadamard product).  In Octave it 
would be a.*a.  The matrix product in R is a%*%a and in Octave it is a*a. 
I find nothing confusing about any of this and I don't see how conceiving 
of 'a' as a vector helps at all.

The difference between our concepts is that this makes no sense within 
your framework where you think of a matrix as being a vector:

> a <- matrix(1:4, 2,2)
> is.vector(a)
[1] FALSE

But to me it makes perfect sense because 'a' is a matrix and a matrix is 
not a vector.  We might say that it contains a vector, or that the 
elements of the matrix are constructed from the elements of a vector, but 
not that the matrix is a vector.  It is a different class of object:

> class(a)
[1] "matrix"

Mike


From mbmiller+l at gmail.com  Thu Dec 25 10:28:58 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 03:28:58 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412250308410.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<8AEFF624-B120-4DD5-98CA-310EC272CCD9@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412250308410.14665@taxa.psych.umn.edu>
Message-ID: <alpine.DEB.2.00.1412250327150.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, Mike Miller wrote:

> On Thu, 25 Dec 2014, Jeff Newmiller wrote:
>
>> You have written a lot, Mike, as though we did not know it.  You are 
>> not the only one with math and multiple computing languages under your 
>> belt.
>
> I'm not assuming that you and Bert don't know things, but I do expect to 
> have a wider audience -- when I search for things, sometimes I find my 
> postings from 10 years ago.  I'm probably not the only one.


To clarify one point:  I write some things to organize my own ideas.  I 
also think I'm not the only one who will want to see it.

I don't believe that I know more about R or programming than you guys do. 
I consider that an extremely remote possibility, at best.  That doesn't 
mean you are right about everything, or about any particular thing.

Mike


From pdalgd at gmail.com  Thu Dec 25 12:02:19 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 25 Dec 2014 12:02:19 +0100
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
Message-ID: <36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>


> On 25 Dec 2014, at 08:15 , Mike Miller <mbmiller+l at gmail.com> wrote:
> 
>> 
>> "is.vector returns TRUE if x is a vector of the specified mode having
>> no attributes other than names. It returns FALSE otherwise."
> 
> So that means that a vector in R has no attributes other than names.

Wrong. Read carefully. There are 

- vectors
- vectors having no attributes other than names

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ivan.calandra at univ-reims.fr  Thu Dec 25 15:26:54 2014
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Thu, 25 Dec 2014 15:26:54 +0100
Subject: [R] tcltk
Message-ID: <549C1EAE.8080908@univ-reims.fr>

Dear useRs,

I have just upgraded to R 3.1.2 for MacOS 10.6.8 (with the binary for 
Snow Leopard).

Everything is fine except that I get an error when loading TclTk:
 >library(tcltk)
Error : .onLoad a ?chou? dans loadNamespace() pour 'tcltk', d?tails :
   appel : system2("otool", c("-L", shQuote(DLL)), stdout = TRUE)
   erreur : erreur lors de l'ex?cution d'une commande
Erreur : le chargement du package ou de l'espace de noms a ?chou? pour 
?tcltk?
sh: otool: command not found

What could be wrong? If needed I can translate the error. I had no 
problem with R 3.1.1.

Thanks in advance and Merry Christmas!
Ivan




Here is my session info:
 > sessionInfo()
R version 3.1.2 (2014-10-31)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base



-- 
Ivan Calandra, ATER
University of Reims Champagne-Ardenne
GEGENA? - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra


From ripley at stats.ox.ac.uk  Thu Dec 25 17:08:00 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Dec 2014 16:08:00 +0000
Subject: [R] tcltk
In-Reply-To: <549C1EAE.8080908@univ-reims.fr>
References: <549C1EAE.8080908@univ-reims.fr>
Message-ID: <549C3660.9030706@stats.ox.ac.uk>

On 25/12/2014 14:26, Ivan Calandra wrote:
> Dear useRs,
>
> I have just upgraded to R 3.1.2 for MacOS 10.6.8 (with the binary for
> Snow Leopard).

Rather belatedly ....

> Everything is fine except that I get an error when loading TclTk:
>  >library(tcltk)
> Error : .onLoad a ?chou? dans loadNamespace() pour 'tcltk', d?tails :
>    appel : system2("otool", c("-L", shQuote(DLL)), stdout = TRUE)
>    erreur : erreur lors de l'ex?cution d'une commande
> Erreur : le chargement du package ou de l'espace de noms a ?chou? pour
> ?tcltk?
> sh: otool: command not found
>
> What could be wrong? If needed I can translate the error. I had no
> problem with R 3.1.1.

As the posting guide asks, post Mac-specific questions on R-sig-mac.
otool should be part of OS X.

>
> Thanks in advance and Merry Christmas!
> Ivan
>
>
>
>
> Here is my session info:
>  > sessionInfo()
> R version 3.1.2 (2014-10-31)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)

That is the OS this was compiled under.  You will need to tell people 
the OS you are running under, e.g. via (in R) system('uname -a')

>
> locale:
> [1] fr_FR.UTF-8/fr_FR.UTF-8/fr_FR.UTF-8/C/fr_FR.UTF-8/fr_FR.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From mbmiller+l at gmail.com  Thu Dec 25 19:57:05 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 12:57:05 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
Message-ID: <alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, peter dalgaard wrote:

>
>> On 25 Dec 2014, at 08:15 , Mike Miller <mbmiller+l at gmail.com> wrote:
>>
>>>
>>> "is.vector returns TRUE if x is a vector of the specified mode having
>>> no attributes other than names. It returns FALSE otherwise."
>>
>> So that means that a vector in R has no attributes other than names.
>
> Wrong. Read carefully. There are
>
> - vectors
> - vectors having no attributes other than names

You are right.  I was being difficult about the meaning of "is.vector()".

But would you also say that a matrix is a vector?

I was going to ask a question about it how to test that an object is a 
vector, but then I found this:

"is.vector() does not test if an object is a vector. Instead it returns 
TRUE only if the object is a vector with no attributes apart from names. 
Use is.atomic(x) || is.list(x) to test if an object is actually a vector."

>From here:

http://adv-r.had.co.nz/Data-structures.html#vectors

> a <- c(1,2,3,4)

> names(a) <- LETTERS[1:4]

> attr(a, "vecinfo") <- "yes, I'm a vector"

> a
A B C D
1 2 3 4
attr(,"vecinfo")
[1] "yes, I'm a vector"

> attributes(a)
$names
[1] "A" "B" "C" "D"

$vecinfo
[1] "yes, I'm a vector"

> is.vector(a)
[1] FALSE

> is.atomic(a) || is.list(a)
[1] TRUE

But then we also see this:

> b <- matrix(1:4, 2,2)

> is.atomic(b) || is.list(b)
[1] TRUE


"It is common to call the atomic types ?atomic vectors?, but note that 
is.vector imposes further restrictions: an object can be atomic but not a 
vector (in that sense)."

https://stat.ethz.ch/R-manual/R-devel/library/base/html/is.recursive.html

I think a matrix is always atomic.  So a matrix is "not a vector (in that 
sense)," but "is.matrix returns TRUE if x is a vector and has a 'dim' 
attribute of length 2."

I do think I get what is going on with this, but why should I buy into 
this conceptualization?  Why is it better to say that a matrix *is* a 
vector than to say that a matrix *contains* a vector?  The latter seems to 
be the more common way of thinking but such things.  Even in R you've had 
to construct two different definitions of "vector" to deal with the 
inconsistency created by the "matrix is a vector" way of thinking.  So 
there must be something really good about it that I am not understanding 
(and I'm not being facetious or ironic!)

Mike

From ligges at statistik.tu-dortmund.de  Thu Dec 25 21:31:21 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 25 Dec 2014 21:31:21 +0100
Subject: [R] debugging R code and dealing with dependencies
In-Reply-To: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>
Message-ID: <549C7419.1090808@statistik.tu-dortmund.de>

This is a rather detailed analysis, thanks, but I think it should be 
send to the maintainer of the "RFGLS" package (CCing).

Best,
Uwe Ligges


On 25.12.2014 10:04, Mike Miller wrote:
> I just wanted to put this out there.  It's just some of my observations
> about things that happen with R, or happened in this particular
> investigation.  There were definitely some lessons for me in this, and
> maybe that will be true of someone else.  The main thing I picked up is
> that it is good to put plenty of checks into our code -- if we expect
> input of a certain type or class, then I should either coerce input into
> that structure or test the input and throw an error.  If the function
> works very differently for different kinds of input, this should be
> documented.  The more people are doing this, the better things will go
> for everyone.
>
>
> I was working with a CRAN package called RFGLS...
>
> http://cran.r-project.org/web/packages/RFGLS/index.html
>
> ...and I was getting an error.  After a few rounds of testing I realized
> that the error was caused by a FAMID variable that was of character type.
>
> The problem seemed to be that gls.batch() expected FAMID to be integers,
> but the default ought to be character type because family and individual
> IDs in nearly all genetic-analysis software are character strings (they
> might even be people's names).
>
> This was the error:
>
> Error in sum(blocksize) : invalid 'type' (character) of argument
> Calls: gls.batch -> bdsmatrix
>
> To figure out more about it, I spent a bunch of time to go from CMD
> BATCH mode to an interactive session so that I could look at
> traceback().  That got me this additional info:
>
>> traceback()
> 2: bdsmatrix(sizelist, lme.out$sigma at blocks, dimnames = list(id, id))
>
> bdsmatrix() is from a package on which RFGLS depends:
>
> http://cran.r-project.org/web/packages/bdsmatrix/index.html
>
> The problem is that RFGLS's gls.batch() function is sending something to
> bdsmatrix's bdsmatrix() that it can't handle.  So I look at the code for
> bdsmatrix() and I see this:
>
>       if (any(blocksize <= 0))
>           stop("Block sizes must be >0")
>       if (any(as.integer(blocksize) != blocksize))
>           stop("Block sizes must be integers")
>       n1 <- as.integer(sum(blocksize))
>
> The condition any(as.integer(blocksize) != blocksize)) fails (is TRUE)
> only if blocksize contains one or more noninteger numeric values.  It
> doesn't fail if blocksize is character or logical if the character
> strings are integers.  Example:
>
>> 4=="4"
> [1] TRUE
>
> That's an interesting feature of R, but I guess that's how it works.
> Also this:
>
>> 1=="1"
> [1] TRUE
>> 1==TRUE
> [1] TRUE
>> "1"==TRUE
> [1] FALSE
>
> bdsmatrix() has no test that blocksize is numeric, so it fails when
> sum(blocksize) cannot sum character strings.
>
> Next I had to figure out where RFGLS's gls.batch() is going wrong in
> producing sizelist.  It is created in a number of steps, but I
> identified this line as especially suspicious:
>
> test.dat$famsize[test.dat$FTYPE!=6]=ave(test.dat$FAMID[test.dat$FTYPE!=6],test.dat$FAMID[test.dat$FTYPE!=6],FUN=length)
>
>
> famsize was later converted to sizelist, and this line also includes
> FAMID, so this is likely where the problem originates.  Of course this
> is the big problem with debugging -- it's hard to find the source of an
> error that occurs far downstream in another function from a different
> package. I see that ave() is used, so I have to understand ave().
>
> William Dunlap provided some guidance:
>
> "ave() uses its first argument, 'x', to set the length of its output and
> to make an initial guess at the type of its output.  The return value of
> FUN can alter the type, but only in an 'upward' direction where
> logical<integer<numeric<complex<character<list.  (This is the same rule
> that x[i]<-newvalue uses.)"
>
> In other words, if x is of character type, the output cannot be of
> integer or numeric type even if the output of FUN is always of integer
> or numeric type.  Looking at the ave() code, I can understand that choice:
>
> function (x, ..., FUN = mean)
> {
>      if (missing(...))
>          x[] <- FUN(x)
>      else {
>          g <- interaction(...)
>          split(x, g) <- lapply(split(x, g), FUN)
>      }
>      x
> }
>
> If the factor is missing an element, then the corresponding element of X
> is not changed in the output:
>
>> fact <- gl(2,2)
>> fact[3] <- NA
>> fact
> [1] 1    1    <NA> 2
> Levels: 1 2
>> ave(1:4, fact)
> [1] 1.5 1.5 3.0 4.0
>
> That's a reasonable plan, but it isn't the documented functioning of
> ave().  From the document...
>
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ave.html
>
> ...you get next to nothing about what the function actually does.  It
> does say that x is "a numeric," but the function does not throw an error
> when x is not numeric.  So if someone writes code expecting numeric x,
> but a user provides a non-numeric x, there may be trouble.
>
> I suspect that the programmer saw that the code worked in her examples
> and she went on to other things.  I can't blame the documentation for
> that, but it is possible that if it said something about the relation
> between the type of the input and the type of the output she might have
> written it differently.  In addition, I probably would have caught it
> sooner and I would have understood the problem.
>
> This is how I'll recommend they fix the bug in the code (thanks to those
> of you who helped with this):
>
> temp.vec <- as.character( test.dat$FAMID[ test.dat$FTYPE != 6 ] )
> test.dat$famsize[ test.dat$FTYPE != 6 ] <- as.vector( table( temp.vec )[
> temp.vec ] )
> rm(temp.vec)
>
> I think we should force FAMID to be character from the beginning, though.
>
> Best,
> Mike
>
> FYI -- RFGLS code that fails in RFGLS version 1.1:
>
> library(RFGLS)
>
> data(pheno)
> data(geno)
> data(map)
> data(pedigree)
> data(rescovmtx)
>   #comment out the following two lines and it will run correctly
> pedigree$FAMID <- as.character(pedigree$FAMID)
> pheno$FAMID <- as.character(pheno$FAMID)
> minigwas <- gls.batch(phenfile=pheno,genfile=data.frame(t(geno)),
>    pedifile=pedigree,
>    snp.names=map[,2],input.mode=c(1,2,3),pediheader=FALSE,
>    pedicolname=c("FAMID","ID","PID","MID","SEX"),
>    phen="Zscore",covars="IsFemale",
>    outfile=NULL,col.names=TRUE,return.value=TRUE)
> str(minigwas)
>
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Dec 25 21:41:32 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 25 Dec 2014 15:41:32 -0500
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
Message-ID: <549C767C.3000901@gmail.com>

On 25/12/2014 1:57 PM, Mike Miller wrote:
> On Thu, 25 Dec 2014, peter dalgaard wrote:
> 
>>
>>> On 25 Dec 2014, at 08:15 , Mike Miller <mbmiller+l at gmail.com> wrote:
>>>
>>>>
>>>> "is.vector returns TRUE if x is a vector of the specified mode having
>>>> no attributes other than names. It returns FALSE otherwise."
>>>
>>> So that means that a vector in R has no attributes other than names.
>>
>> Wrong. Read carefully. There are
>>
>> - vectors
>> - vectors having no attributes other than names
> 
> You are right.  I was being difficult about the meaning of "is.vector()".
> 
> But would you also say that a matrix is a vector?
> 
> I was going to ask a question about it how to test that an object is a 
> vector, but then I found this:
> 
> "is.vector() does not test if an object is a vector. Instead it returns 
> TRUE only if the object is a vector with no attributes apart from names. 
> Use is.atomic(x) || is.list(x) to test if an object is actually a vector."
> 
> From here:
> 
> http://adv-r.had.co.nz/Data-structures.html#vectors
> 
>> a <- c(1,2,3,4)
> 
>> names(a) <- LETTERS[1:4]
> 
>> attr(a, "vecinfo") <- "yes, I'm a vector"
> 
>> a
> A B C D
> 1 2 3 4
> attr(,"vecinfo")
> [1] "yes, I'm a vector"
> 
>> attributes(a)
> $names
> [1] "A" "B" "C" "D"
> 
> $vecinfo
> [1] "yes, I'm a vector"
> 
>> is.vector(a)
> [1] FALSE
> 
>> is.atomic(a) || is.list(a)
> [1] TRUE
> 
> But then we also see this:
> 
>> b <- matrix(1:4, 2,2)
> 
>> is.atomic(b) || is.list(b)
> [1] TRUE
> 
> 
> "It is common to call the atomic types ?atomic vectors?, but note that 
> is.vector imposes further restrictions: an object can be atomic but not a 
> vector (in that sense)."
> 
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/is.recursive.html
> 
> I think a matrix is always atomic.  So a matrix is "not a vector (in that 
> sense)," but "is.matrix returns TRUE if x is a vector and has a 'dim' 
> attribute of length 2."
> 
> I do think I get what is going on with this, but why should I buy into 
> this conceptualization?  Why is it better to say that a matrix *is* a 
> vector than to say that a matrix *contains* a vector?  The latter seems to 
> be the more common way of thinking but such things. 

"More common"?  The better way to think of this is as a class hierarchy.
 A matrix is a particular kind of vector (the kind that has a dimension
attribute).  A matrix has all the properties that a vector has, plus
some more.

Would you say a cube contains a polygon, or a cube is a polygon?

Duncan Murdoch

 Even in R you've had
> to construct two different definitions of "vector" to deal with the 
> inconsistency created by the "matrix is a vector" way of thinking.  So 
> there must be something really good about it that I am not understanding 
> (and I'm not being facetious or ironic!)
> 
> Mike
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mbmiller+l at gmail.com  Thu Dec 25 21:45:04 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 14:45:04 -0600
Subject: [R] debugging R code and dealing with dependencies
In-Reply-To: <549C7419.1090808@statistik.tu-dortmund.de>
References: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>
	<549C7419.1090808@statistik.tu-dortmund.de>
Message-ID: <alpine.DEB.2.00.1412251443200.14665@taxa.psych.umn.edu>

Thanks, but I was already in touch with Rob Kirkpatrick about it.  We all 
work together at U Minnesota, or did until Rob went to VCU.

Mike


On Thu, 25 Dec 2014, Uwe Ligges wrote:

> This is a rather detailed analysis, thanks, but I think it should be 
> send to the maintainer of the "RFGLS" package (CCing).
>
> Best,
> Uwe Ligges
>
>
> On 25.12.2014 10:04, Mike Miller wrote:
>> I just wanted to put this out there.  It's just some of my observations
>> about things that happen with R, or happened in this particular
>> investigation.  There were definitely some lessons for me in this, and
>> maybe that will be true of someone else.  The main thing I picked up is
>> that it is good to put plenty of checks into our code -- if we expect
>> input of a certain type or class, then I should either coerce input into
>> that structure or test the input and throw an error.  If the function
>> works very differently for different kinds of input, this should be
>> documented.  The more people are doing this, the better things will go
>> for everyone.
>> 
>> 
>> I was working with a CRAN package called RFGLS...
>> 
>> http://cran.r-project.org/web/packages/RFGLS/index.html
>> 
>> ...and I was getting an error.  After a few rounds of testing I realized
>> that the error was caused by a FAMID variable that was of character type.
>> 
>> The problem seemed to be that gls.batch() expected FAMID to be integers,
>> but the default ought to be character type because family and individual
>> IDs in nearly all genetic-analysis software are character strings (they
>> might even be people's names).
>> 
>> This was the error:
>> 
>> Error in sum(blocksize) : invalid 'type' (character) of argument
>> Calls: gls.batch -> bdsmatrix
>> 
>> To figure out more about it, I spent a bunch of time to go from CMD
>> BATCH mode to an interactive session so that I could look at
>> traceback().  That got me this additional info:
>> 
>>> traceback()
>> 2: bdsmatrix(sizelist, lme.out$sigma at blocks, dimnames = list(id, id))
>> 
>> bdsmatrix() is from a package on which RFGLS depends:
>> 
>> http://cran.r-project.org/web/packages/bdsmatrix/index.html
>> 
>> The problem is that RFGLS's gls.batch() function is sending something to
>> bdsmatrix's bdsmatrix() that it can't handle.  So I look at the code for
>> bdsmatrix() and I see this:
>>
>>       if (any(blocksize <= 0))
>>           stop("Block sizes must be >0")
>>       if (any(as.integer(blocksize) != blocksize))
>>           stop("Block sizes must be integers")
>>       n1 <- as.integer(sum(blocksize))
>> 
>> The condition any(as.integer(blocksize) != blocksize)) fails (is TRUE)
>> only if blocksize contains one or more noninteger numeric values.  It
>> doesn't fail if blocksize is character or logical if the character
>> strings are integers.  Example:
>> 
>>> 4=="4"
>> [1] TRUE
>> 
>> That's an interesting feature of R, but I guess that's how it works.
>> Also this:
>> 
>>> 1=="1"
>> [1] TRUE
>>> 1==TRUE
>> [1] TRUE
>>> "1"==TRUE
>> [1] FALSE
>> 
>> bdsmatrix() has no test that blocksize is numeric, so it fails when
>> sum(blocksize) cannot sum character strings.
>> 
>> Next I had to figure out where RFGLS's gls.batch() is going wrong in
>> producing sizelist.  It is created in a number of steps, but I
>> identified this line as especially suspicious:
>> 
>> test.dat$famsize[test.dat$FTYPE!=6]=ave(test.dat$FAMID[test.dat$FTYPE!=6],test.dat$FAMID[test.dat$FTYPE!=6],FUN=length)
>> 
>> 
>> famsize was later converted to sizelist, and this line also includes
>> FAMID, so this is likely where the problem originates.  Of course this
>> is the big problem with debugging -- it's hard to find the source of an
>> error that occurs far downstream in another function from a different
>> package. I see that ave() is used, so I have to understand ave().
>> 
>> William Dunlap provided some guidance:
>> 
>> "ave() uses its first argument, 'x', to set the length of its output and
>> to make an initial guess at the type of its output.  The return value of
>> FUN can alter the type, but only in an 'upward' direction where
>> logical<integer<numeric<complex<character<list.  (This is the same rule
>> that x[i]<-newvalue uses.)"
>> 
>> In other words, if x is of character type, the output cannot be of
>> integer or numeric type even if the output of FUN is always of integer
>> or numeric type.  Looking at the ave() code, I can understand that choice:
>> 
>> function (x, ..., FUN = mean)
>> {
>>      if (missing(...))
>>          x[] <- FUN(x)
>>      else {
>>          g <- interaction(...)
>>          split(x, g) <- lapply(split(x, g), FUN)
>>      }
>>      x
>> }
>> 
>> If the factor is missing an element, then the corresponding element of X
>> is not changed in the output:
>> 
>>> fact <- gl(2,2)
>>> fact[3] <- NA
>>> fact
>> [1] 1    1    <NA> 2
>> Levels: 1 2
>>> ave(1:4, fact)
>> [1] 1.5 1.5 3.0 4.0
>> 
>> That's a reasonable plan, but it isn't the documented functioning of
>> ave().  From the document...
>> 
>> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ave.html
>> 
>> ...you get next to nothing about what the function actually does.  It
>> does say that x is "a numeric," but the function does not throw an error
>> when x is not numeric.  So if someone writes code expecting numeric x,
>> but a user provides a non-numeric x, there may be trouble.
>> 
>> I suspect that the programmer saw that the code worked in her examples
>> and she went on to other things.  I can't blame the documentation for
>> that, but it is possible that if it said something about the relation
>> between the type of the input and the type of the output she might have
>> written it differently.  In addition, I probably would have caught it
>> sooner and I would have understood the problem.
>> 
>> This is how I'll recommend they fix the bug in the code (thanks to those
>> of you who helped with this):
>> 
>> temp.vec <- as.character( test.dat$FAMID[ test.dat$FTYPE != 6 ] )
>> test.dat$famsize[ test.dat$FTYPE != 6 ] <- as.vector( table( temp.vec )[
>> temp.vec ] )
>> rm(temp.vec)
>> 
>> I think we should force FAMID to be character from the beginning, though.
>> 
>> Best,
>> Mike
>> 
>> FYI -- RFGLS code that fails in RFGLS version 1.1:
>> 
>> library(RFGLS)
>> 
>> data(pheno)
>> data(geno)
>> data(map)
>> data(pedigree)
>> data(rescovmtx)
>>   #comment out the following two lines and it will run correctly
>> pedigree$FAMID <- as.character(pedigree$FAMID)
>> pheno$FAMID <- as.character(pheno$FAMID)
>> minigwas <- gls.batch(phenfile=pheno,genfile=data.frame(t(geno)),
>>    pedifile=pedigree,
>>    snp.names=map[,2],input.mode=c(1,2,3),pediheader=FALSE,
>>    pedicolname=c("FAMID","ID","PID","MID","SEX"),
>>    phen="Zscore",covars="IsFemale",
>>    outfile=NULL,col.names=TRUE,return.value=TRUE)
>> str(minigwas)
>> 
>> Mike
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Thu Dec 25 21:59:37 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 25 Dec 2014 12:59:37 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <549C767C.3000901@gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
	<549C767C.3000901@gmail.com>
Message-ID: <CACk-te0GTb7KDYUtq-G5x8H7hp0Qrf+2Ly+sAsor7jh5yZ-XFg@mail.gmail.com>

On Thu, Dec 25, 2014 at 12:41 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> Would you say a cube contains a polygon, or a cube is a polygon?

Neither, actually. I'd say a cube is a polyhedron or a square is a polygon.

:-)

But point taken, of course.

Cheers,
Bert






Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll


From mbmiller+l at gmail.com  Thu Dec 25 22:19:27 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 15:19:27 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <549C767C.3000901@gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
	<549C767C.3000901@gmail.com>
Message-ID: <alpine.DEB.2.00.1412251447590.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, Duncan Murdoch wrote:

> On 25/12/2014 1:57 PM, Mike Miller wrote:
>
>> I do think I get what is going on with this, but why should I buy into 
>> this conceptualization?  Why is it better to say that a matrix *is* a 
>> vector than to say that a matrix *contains* a vector?  The latter seems 
>> to be the more common way of thinking but such things.
>
> "More common"?  The better way to think of this is as a class hierarchy. 
> A matrix is a particular kind of vector (the kind that has a dimension 
> attribute).  A matrix has all the properties that a vector has, plus 
> some more.
>
> Would you say a cube contains a polygon, or a cube is a polygon?

I would say that the sides of the cube are polygons, so I guess a cube 
"contains" six polygons, but "is" would be wrong because a cube is a 
polyhedron, not a polygon.  A cube is not a polygon.

I get your point about hierarchy.

Someone else showed me that setting the dim attribute to NULL changes the 
matrix into a vector so that is.vector() is TRUE.

Mike


From murdoch.duncan at gmail.com  Thu Dec 25 22:25:42 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 25 Dec 2014 16:25:42 -0500
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <CACk-te0GTb7KDYUtq-G5x8H7hp0Qrf+2Ly+sAsor7jh5yZ-XFg@mail.gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>	<549C767C.3000901@gmail.com>
	<CACk-te0GTb7KDYUtq-G5x8H7hp0Qrf+2Ly+sAsor7jh5yZ-XFg@mail.gmail.com>
Message-ID: <549C80D6.7040200@gmail.com>

On 25/12/2014 3:59 PM, Bert Gunter wrote:
> On Thu, Dec 25, 2014 at 12:41 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> Would you say a cube contains a polygon, or a cube is a polygon?
> 
> Neither, actually. I'd say a cube is a polyhedron or a square is a polygon.
> 
> :-)
> 
> But point taken, of course.

I have trouble remembering how many dimensions I live in.

Duncan


From ggrothendieck at gmail.com  Thu Dec 25 22:26:04 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 25 Dec 2014 16:26:04 -0500
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
Message-ID: <CAP01uRmODk3i5RXtxkAqWCfpRcymkWBUyfHnuisLX5ZntEZgaQ@mail.gmail.com>

On Thu, Dec 25, 2014 at 1:57 PM, Mike Miller <mbmiller+l at gmail.com> wrote:
> I do think I get what is going on with this, but why should I buy into this
> conceptualization?  Why is it better to say that a matrix *is* a vector than
> to say that a matrix *contains* a vector?  The latter seems to be the more
> common way of thinking but such things.  Even in R you've had to construct
> two different definitions of "vector" to deal with the inconsistency created
> by the "matrix is a vector" way of thinking.  So there must be something
> really good about it that I am not understanding (and I'm not being
> facetious or ironic!)

I think its the idea that in R all data objects are vectors (for some
notion of vector) in the sense that all Lisp objects are lists, all
APL objects are arrays and all tcl objects are character strings.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From mbmiller+l at gmail.com  Thu Dec 25 23:45:16 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 16:45:16 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
Message-ID: <alpine.DEB.2.00.1412251543190.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, Mike Miller wrote:

> I was going to ask a question about it how to test that an object is a 
> vector, but then I found this:
>
> "is.vector() does not test if an object is a vector. Instead it returns 
> TRUE only if the object is a vector with no attributes apart from names. 
> Use is.atomic(x) || is.list(x) to test if an object is actually a 
> vector."
>
> From here:
>
> http://adv-r.had.co.nz/Data-structures.html#vectors


But here...

https://stat.ethz.ch/R-manual/R-devel/library/base/html/vector.html

...I read, "Note that factors are *not* vectors" (emphasis theirs), yet...


> d <- gl(2,2)

> is.factor(d)
[1] TRUE

> is.atomic(d) || is.list(d)
[1] TRUE

> is.list(d)
[1] FALSE

> is.atomic(d)
[1] TRUE

> is.vector(d)
[1] FALSE

So the factor is not a vector according to R documentation, but it is a 
vector according to the Wickham test, and it is not a vector according to 
is.vector().  Admittedly, the latter seems not to mean much to the R 
experts.  Maybe a factor is just a vector with additional attributes.

Mike


From gunter.berton at gene.com  Fri Dec 26 00:19:31 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 25 Dec 2014 15:19:31 -0800
Subject: [R] ave(x, y,
	FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412251543190.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412251543190.14665@taxa.psych.umn.edu>
Message-ID: <CACk-te3zFVub4a1VntLWak5FNFuowOu+AsVeHtCemhbCQapMWg@mail.gmail.com>

You persist in failing to read the docs! Moreover, neither Hadley
Wickham, nor anyone else, is the authoritative source for R usage
(other than for the (many!) packages he, himself has authored). R's
Help pages and manuals -- and ultimately the source code -- are the
only such source.

?factor says in its very first line:

"The function factor is used to encode a **vector** as a factor (the
terms ?category? and ?enumerated type? are also used for factors)...."
(emphasis added)

and:

> f <- factor (letters[1:3])
> f
[1] a b c
Levels: a b c

> attributes(f)
$levels
[1] "a" "b" "c"

$class
[1] "factor"

> is.vector(f)
[1] FALSE

> attributes(f) <- NULL

> f
[1] 1 2 3
> is.vector(f)
[1] TRUE

Don't you think it's time to call a halt to this?


Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Dec 25, 2014 at 2:45 PM, Mike Miller <mbmiller+l at gmail.com> wrote:
> On Thu, 25 Dec 2014, Mike Miller wrote:
>
>> I was going to ask a question about it how to test that an object is a
>> vector, but then I found this:
>>
>> "is.vector() does not test if an object is a vector. Instead it returns
>> TRUE only if the object is a vector with no attributes apart from names. Use
>> is.atomic(x) || is.list(x) to test if an object is actually a vector."
>>
>> From here:
>>
>> http://adv-r.had.co.nz/Data-structures.html#vectors
>
>
>
> But here...
>
> https://stat.ethz.ch/R-manual/R-devel/library/base/html/vector.html
>
> ...I read, "Note that factors are *not* vectors" (emphasis theirs), yet...
>
>
>> d <- gl(2,2)
>
>
>> is.factor(d)
>
> [1] TRUE
>
>> is.atomic(d) || is.list(d)
>
> [1] TRUE
>
>> is.list(d)
>
> [1] FALSE
>
>> is.atomic(d)
>
> [1] TRUE
>
>> is.vector(d)
>
> [1] FALSE
>
> So the factor is not a vector according to R documentation, but it is a
> vector according to the Wickham test, and it is not a vector according to
> is.vector().  Admittedly, the latter seems not to mean much to the R
> experts.  Maybe a factor is just a vector with additional attributes.
>
> Mike


From dwinsemius at comcast.net  Fri Dec 26 02:34:06 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Dec 2014 17:34:06 -0800
Subject: [R] debugging R code and dealing with dependencies
In-Reply-To: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>
Message-ID: <FB4995F8-36E0-4AD4-A06F-7D85C94BA3A8@comcast.net>


> On Dec 25, 2014, at 1:04 AM, Mike Miller <mbmiller+l at gmail.com> wrote:
> 
> I just wanted to put this out there.  It's just some of my observations about things that happen with R, or happened in this particular investigation.  There were definitely some lessons for me in this, and maybe that will be true of someone else.  The main thing I picked up is that it is good to put plenty of checks into our code -- if we expect input of a certain type or class, then I should either coerce input into that structure or test the input and throw an error.  If the function works very differently for different kinds of input, this should be documented.  The more people are doing this, the better things will go for everyone.
> 
> 
> I was working with a CRAN package called RFGLS...
> 
> http://cran.r-project.org/web/packages/RFGLS/index.html
> 
> ...and I was getting an error.  After a few rounds of testing I realized that the error was caused by a FAMID variable that was of character type.

But The Details section of the help page does say that the accepted FTYPES are all integers between 1 and 6 and the INDIV variables are integers in range 1:4.

> The problem seemed to be that gls.batch() expected FAMID to be integers, but the default ought to be character type because family and individual IDs in nearly all genetic-analysis software are character strings (they might even be people's names).

You are making up rules that were not in accord with the documentation.

> This was the error:
> 
> Error in sum(blocksize) : invalid 'type' (character) of argument
> Calls: gls.batch -> bdsmatrix
> 
> To figure out more about it, I spent a bunch of time to go from CMD BATCH mode to an interactive session so that I could look at traceback().  

Generally the first thing to check is the help page. And if there is a worked example to look at its data:

> data(pedigree, package="RFGLS")
> str(pedigree)
'data.frame':	4050 obs. of  5 variables:
 $ FAMID: int  10 10 10 10 20 20 20 20 30 30 ...
 $ ID   : int  11 12 13 14 21 22 23 24 31 32 ...
 $ PID  : int  14 14 0 0 24 24 0 0 34 34 ...
 $ MID  : int  13 13 0 0 23 23 0 0 33 33 ...
 $ SEX  : num  1 1 2 1 2 2 2 1 2 2 ?

? 
David.

> That got me this additional info:
> 
>> traceback()
> 2: bdsmatrix(sizelist, lme.out$sigma at blocks, dimnames = list(id, id))
> 
> bdsmatrix() is from a package on which RFGLS depends:
> 
> http://cran.r-project.org/web/packages/bdsmatrix/index.html
> 
> The problem is that RFGLS's gls.batch() function is sending something to bdsmatrix's bdsmatrix() that it can't handle.  So I look at the code for bdsmatrix() and I see this:
> 
>     if (any(blocksize <= 0))
>         stop("Block sizes must be >0")
>     if (any(as.integer(blocksize) != blocksize))
>         stop("Block sizes must be integers")
>     n1 <- as.integer(sum(blocksize))
> 
> The condition any(as.integer(blocksize) != blocksize)) fails (is TRUE) only if blocksize contains one or more noninteger numeric values.  It doesn't fail if blocksize is character or logical if the character strings are integers.  Example:
> 
>> 4=="4"
> [1] TRUE
> 
> That's an interesting feature of R, but I guess that's how it works. Also this:
> 
>> 1=="1"
> [1] TRUE
>> 1==TRUE
> [1] TRUE
>> "1"==TRUE
> [1] FALSE
> 
> bdsmatrix() has no test that blocksize is numeric, so it fails when sum(blocksize) cannot sum character strings.
> 
> Next I had to figure out where RFGLS's gls.batch() is going wrong in producing sizelist.  It is created in a number of steps, but I identified this line as especially suspicious:
> 
> test.dat$famsize[test.dat$FTYPE!=6]=ave(test.dat$FAMID[test.dat$FTYPE!=6],test.dat$FAMID[test.dat$FTYPE!=6],FUN=length)
> 
> famsize was later converted to sizelist, and this line also includes FAMID, so this is likely where the problem originates.  Of course this is the big problem with debugging -- it's hard to find the source of an error that occurs far downstream in another function from a different package. I see that ave() is used, so I have to understand ave().
> 
> William Dunlap provided some guidance:
> 
> "ave() uses its first argument, 'x', to set the length of its output and to make an initial guess at the type of its output.  The return value of FUN can alter the type, but only in an 'upward' direction where logical<integer<numeric<complex<character<list.  (This is the same rule that x[i]<-newvalue uses.)"
> 
> In other words, if x is of character type, the output cannot be of integer or numeric type even if the output of FUN is always of integer or numeric type.  Looking at the ave() code, I can understand that choice:
> 
> function (x, ..., FUN = mean)
> {
>    if (missing(...))
>        x[] <- FUN(x)
>    else {
>        g <- interaction(...)
>        split(x, g) <- lapply(split(x, g), FUN)
>    }
>    x
> }
> 
> If the factor is missing an element, then the corresponding element of X is not changed in the output:
> 
>> fact <- gl(2,2)
>> fact[3] <- NA
>> fact
> [1] 1    1    <NA> 2
> Levels: 1 2
>> ave(1:4, fact)
> [1] 1.5 1.5 3.0 4.0
> 
> That's a reasonable plan, but it isn't the documented functioning of ave().  From the document...
> 
> https://stat.ethz.ch/R-manual/R-devel/library/stats/html/ave.html
> 
> ...you get next to nothing about what the function actually does.  It does say that x is "a numeric," but the function does not throw an error when x is not numeric.  So if someone writes code expecting numeric x, but a user provides a non-numeric x, there may be trouble.
> 
> I suspect that the programmer saw that the code worked in her examples and she went on to other things.  I can't blame the documentation for that, but it is possible that if it said something about the relation between the type of the input and the type of the output she might have written it differently.  In addition, I probably would have caught it sooner and I would have understood the problem.
> 
> This is how I'll recommend they fix the bug in the code (thanks to those of you who helped with this):
> 
> temp.vec <- as.character( test.dat$FAMID[ test.dat$FTYPE != 6 ] )
> test.dat$famsize[ test.dat$FTYPE != 6 ] <- as.vector( table( temp.vec )[ temp.vec ] )
> rm(temp.vec)
> 
> I think we should force FAMID to be character from the beginning, though.
> 
> Best,
> Mike
> 
> FYI -- RFGLS code that fails in RFGLS version 1.1:
> 
> library(RFGLS)
> 
> data(pheno)
> data(geno)
> data(map)
> data(pedigree)
> data(rescovmtx)
> #comment out the following two lines and it will run correctly
> pedigree$FAMID <- as.character(pedigree$FAMID)
> pheno$FAMID <- as.character(pheno$FAMID)
> minigwas <- gls.batch(phenfile=pheno,genfile=data.frame(t(geno)),
>  pedifile=pedigree,
>  snp.names=map[,2],input.mode=c(1,2,3),pediheader=FALSE,
>  pedicolname=c("FAMID","ID","PID","MID","SEX"),
>  phen="Zscore",covars="IsFemale",
>  outfile=NULL,col.names=TRUE,return.value=TRUE)
> str(minigwas)
> 
> Mike
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mbmiller+l at gmail.com  Fri Dec 26 04:16:17 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 21:16:17 -0600
Subject: [R] debugging R code and dealing with dependencies
In-Reply-To: <FB4995F8-36E0-4AD4-A06F-7D85C94BA3A8@comcast.net>
References: <alpine.DEB.2.00.1412241725400.14665@taxa.psych.umn.edu>
	<FB4995F8-36E0-4AD4-A06F-7D85C94BA3A8@comcast.net>
Message-ID: <alpine.DEB.2.00.1412252111200.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, David Winsemius wrote:

>> On Dec 25, 2014, at 1:04 AM, Mike Miller <mbmiller+l at gmail.com> wrote:
>>
>> I just wanted to put this out there.  It's just some of my observations 
>> about things that happen with R, or happened in this particular 
>> investigation.  There were definitely some lessons for me in this, and 
>> maybe that will be true of someone else.  The main thing I picked up is 
>> that it is good to put plenty of checks into our code -- if we expect 
>> input of a certain type or class, then I should either coerce input 
>> into that structure or test the input and throw an error.  If the 
>> function works very differently for different kinds of input, this 
>> should be documented.  The more people are doing this, the better 
>> things will go for everyone.
>>
>>
>> I was working with a CRAN package called RFGLS...
>>
>> http://cran.r-project.org/web/packages/RFGLS/index.html
>>
>> ...and I was getting an error.  After a few rounds of testing I 
>> realized that the error was caused by a FAMID variable that was of 
>> character type.
>
> But The Details section of the help page does say that the accepted 
> FTYPES are all integers between 1 and 6 and the INDIV variables are 
> integers in range 1:4.

But FAMID and FTYPE are different variables, both required.


>> The problem seemed to be that gls.batch() expected FAMID to be 
>> integers, but the default ought to be character type because family and 
>> individual IDs in nearly all genetic-analysis software are character 
>> strings (they might even be people's names).
>
> You are making up rules that were not in accord with the documentation.

I think you are confusing FTYPE with FAMID.


>> This was the error:
>>
>> Error in sum(blocksize) : invalid 'type' (character) of argument
>> Calls: gls.batch -> bdsmatrix
>>
>> To figure out more about it, I spent a bunch of time to go from CMD 
>> BATCH mode to an interactive session so that I could look at 
>> traceback().
>
> Generally the first thing to check is the help page. And if there is a 
> worked example to look at its data:
>
>> data(pedigree, package="RFGLS")
>> str(pedigree)
> 'data.frame':	4050 obs. of  5 variables:
> $ FAMID: int  10 10 10 10 20 20 20 20 30 30 ...
> $ ID   : int  11 12 13 14 21 22 23 24 31 32 ...
> $ PID  : int  14 14 0 0 24 24 0 0 34 34 ...
> $ MID  : int  13 13 0 0 23 23 0 0 33 33 ...
> $ SEX  : num  1 1 2 1 2 2 2 1 2 2 ?

Thanks for your efforts, but you are mistaken.  Before I wrote anything 
here I had already worked through this with Rob Kirkpatrick, we had run 
the data() examples, confirmed the error there, and more.

I was a coauthor of the Human Heredity paper that introduced this software 
and it was based on other work I had done.  I'm pretty sure I'm the #1 
user of this package.

FTYPE != FAMID

Everything I said was correct.

Mike

From mbmiller+l at gmail.com  Fri Dec 26 05:30:13 2014
From: mbmiller+l at gmail.com (Mike Miller)
Date: Thu, 25 Dec 2014 22:30:13 -0600
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <CACk-te3zFVub4a1VntLWak5FNFuowOu+AsVeHtCemhbCQapMWg@mail.gmail.com>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>
	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>
	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>
	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>
	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>
	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>
	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>
	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>
	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>
	<alpine.DEB.2.00.1412251543190.14665@taxa.psych.umn.edu>
	<CACk-te3zFVub4a1VntLWak5FNFuowOu+AsVeHtCemhbCQapMWg@mail.gmail.com>
Message-ID: <alpine.DEB.2.00.1412252116440.14665@taxa.psych.umn.edu>

On Thu, 25 Dec 2014, Bert Gunter wrote:

> You persist in failing to read the docs!

"the docs" -- do those exclude those I have been quoting and linking to?

> Moreover, neither Hadley Wickham, nor anyone else, is the authoritative 
> source for R usage (other than for the (many!) packages he, himself has 
> authored). R's Help pages and manuals -- and ultimately the source code 
> -- are the only such source.

Very pendantic.  Are you saying that Hadley Wickham's claim was incorrect? 
To repeat, he said that this would return TRUE if x were a vector:

is.atomic(x) || is.list(x)

If you think that is wrong, I'd be interested to know more about that.


> ?factor says in its very first line:
>
> "The function factor is used to encode a **vector** as a factor (the 
> terms ?category? and ?enumerated type? are also used for factors)...." 
> (emphasis added)

So what?  Are you saying that a factor *is* a vector?  I quoted this 
before, but I'll repeat it here -- from the third paragaraph of the 
Details section of ?vector:

    Note that factors are _not_ vectors; ?is.vector? returns ?FALSE?
    and ?as.vector? converts a factor to a character vector for ?mode
    = "any"?.

I guess that is an "authoritative source" by your criteria even though it 
isn't in the first line of the page.


>> f <- factor (letters[1:3])
>> f
> [1] a b c
> Levels: a b c
>
>> attributes(f)
> $levels
> [1] "a" "b" "c"
>
> $class
> [1] "factor"
>
>> is.vector(f)
> [1] FALSE
>
>> attributes(f) <- NULL
>
>> f
> [1] 1 2 3
>> is.vector(f)
> [1] TRUE

And your point is what?  Yes, we can convert between different kinds of 
objects.  Are you saying that a factor *is* a vector because you can 
coerce it into a vector by removing its attributes?

I do think it is very central to this discussion that attributes(x) <- 
NULL makes x into a vector, and that is not true just for factors, but 
also matrices, as you showed me earlier.  Following your lead, this is 
another example:

> b <- 1:4

> attr(b, "dim") <- c(2,2)

> is.matrix(b)
[1] TRUE

Does that mean that "a matrix is a vector"?  Not for me, but it does make 
it easy to see how that concept helps people to understand the internal 
workings of R.  Gabor Grothendieck wrote, "I think its the idea that in R 
all data objects are vectors (for some notion of vector) in the sense that 
all Lisp objects are lists, all APL objects are arrays and all tcl objects 
are character strings."  That's how I've been thinking about it, too, but 
I'm not sure that *all* data objects are vectors in this sense.  If that 
were the case, the Wickham test would always return TRUE.


> Don't you think it's time to call a halt to this?

You go first.

Mike

-- 
Michael B. Miller, Ph.D.
University of Minnesota
http://scholar.google.com/citations?user=EV_phq4AAAAJ

From raju.mailinglists at gmail.com  Thu Dec 25 07:38:34 2014
From: raju.mailinglists at gmail.com (kamaraju kusumanchi)
Date: Thu, 25 Dec 2014 01:38:34 -0500
Subject: [R] wiki link on main page is down?
Message-ID: <CABpbYadZxphj22NyAvw9z4-3sYH4rxGX++hBrASz0UAmvHrpQw@mail.gmail.com>

On the left panel of http://www.r-project.org/ , there is a link
titled "Wiki" which points to http://rwiki.sciviews.org/ . However,
this link is broken and gives a 404 Not Found error. Could you please
fix it?

thanks
raju


From phillip.awodutire at gmail.com  Thu Dec 25 11:51:05 2014
From: phillip.awodutire at gmail.com (Phillip Awodutire)
Date: Fri, 26 Dec 2014 06:25:05 +1934
Subject: [R] help
Message-ID: <CANochgffMVcebnR-rTSQdvQOMsOcnaTBH+3n+9QAntoDPUNBQg@mail.gmail.com>

i want to analyse survival data using typeI HALF LOGISTIC
DISTRIBUTION.how can i go about it?it installed one on R in the
survival package didn't include the distribution...or i need a code to
use maximum likelihood to estimate the parameter in survival
analysis.a typical example of distribution other than that installed
in R will help.thanks


From ankita17shukla at gmail.com  Fri Dec 26 07:56:39 2014
From: ankita17shukla at gmail.com (Ankita Shukla)
Date: Thu, 25 Dec 2014 22:56:39 -0800
Subject: [R] Question
Message-ID: <CAL=QHq+vHFRF+YNT7jZ4Sm33fEj4NWiymRYjZfhboLrT4e_kRA@mail.gmail.com>

Hi I was fitting this model with two matrices. But this bifit function
didnt run in my R studio and i got error message. Could anyone guide me how
to install this command. I am giving that command below to have better
understanding.

x.f <- cbind(log(Q5.all.pf), log(Q5.all.pf)^2)
y.f <- t(log(mx5x5.all.pf))
bifit.f <- bifit(x.f, y.f, c=6)


Ankita Shukla
Research Scholar
International Institute for Population sciences
Mumbai, India

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Dec 26 13:00:59 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Dec 2014 07:00:59 -0500
Subject: [R] ave(x, y,
 FUN=length) produces character output when x is character
In-Reply-To: <alpine.DEB.2.00.1412252116440.14665@taxa.psych.umn.edu>
References: <alpine.DEB.2.00.1412241142350.14665@taxa.psych.umn.edu>	<CACk-te3XFk00uu3o86TXjOhjBjWCX0d7RLsOD1a6GXdzrz20cQ@mail.gmail.com>	<alpine.DEB.2.00.1412241356260.14665@taxa.psych.umn.edu>	<alpine.DEB.2.00.1412242047270.14665@taxa.psych.umn.edu>	<9CEDFACF-6CE1-4244-BF28-72D6FB7019EE@dcn.davis.CA.us>	<alpine.DEB.2.00.1412242230000.14665@taxa.psych.umn.edu>	<CACk-te1eSBA1Su925DaOXF9ScK9jaDF6ono8yDBcnhynkPJNVw@mail.gmail.com>	<alpine.DEB.2.00.1412250033290.14665@taxa.psych.umn.edu>	<36A3DB46-C8EA-4178-B164-8A3B37894C56@gmail.com>	<alpine.DEB.2.00.1412250922450.14665@taxa.psych.umn.edu>	<alpine.DEB.2.00.1412251543190.14665@taxa.psych.umn.edu>	<CACk-te3zFVub4a1VntLWak5FNFuowOu+AsVeHtCemhbCQapMWg@mail.gmail.com>
	<alpine.DEB.2.00.1412252116440.14665@taxa.psych.umn.edu>
Message-ID: <549D4DFB.5090806@gmail.com>

On 25/12/2014 11:30 PM, Mike Miller wrote:
> On Thu, 25 Dec 2014, Bert Gunter wrote:
> 
>> You persist in failing to read the docs!
> 
> "the docs" -- do those exclude those I have been quoting and linking to?
> 
>> Moreover, neither Hadley Wickham, nor anyone else, is the authoritative 
>> source for R usage (other than for the (many!) packages he, himself has 
>> authored). R's Help pages and manuals -- and ultimately the source code 
>> -- are the only such source.
> 
> Very pendantic.  Are you saying that Hadley Wickham's claim was incorrect? 
> To repeat, he said that this would return TRUE if x were a vector:
> 
> is.atomic(x) || is.list(x)
> 
> If you think that is wrong, I'd be interested to know more about that.
> 
> 
>> ?factor says in its very first line:
>>
>> "The function factor is used to encode a **vector** as a factor (the 
>> terms ?category? and ?enumerated type? are also used for factors)...." 
>> (emphasis added)
> 
> So what?  Are you saying that a factor *is* a vector?  I quoted this 
> before, but I'll repeat it here -- from the third paragaraph of the 
> Details section of ?vector:
> 
>     Note that factors are _not_ vectors; ?is.vector? returns ?FALSE?
>     and ?as.vector? converts a factor to a character vector for ?mode
>     = "any"?.
> 
> I guess that is an "authoritative source" by your criteria even though it 
> isn't in the first line of the page.

That page documents a function that is named poorly.  "is.vector"
doesn't test for vectors in the sense used in most other places, it
tests for a "vector of the specified mode having no attributes other
than names".  The page also points out a third meaning for the word,
i.e. "the formal class "vector" in the methods package".

So all your confusion is somewhat understandable, but it's still tiresome.

Duncan Murdoch

> 
> 
>>> f <- factor (letters[1:3])
>>> f
>> [1] a b c
>> Levels: a b c
>>
>>> attributes(f)
>> $levels
>> [1] "a" "b" "c"
>>
>> $class
>> [1] "factor"
>>
>>> is.vector(f)
>> [1] FALSE
>>
>>> attributes(f) <- NULL
>>
>>> f
>> [1] 1 2 3
>>> is.vector(f)
>> [1] TRUE
> 
> And your point is what?  Yes, we can convert between different kinds of 
> objects.  Are you saying that a factor *is* a vector because you can 
> coerce it into a vector by removing its attributes?
> 
> I do think it is very central to this discussion that attributes(x) <- 
> NULL makes x into a vector, and that is not true just for factors, but 
> also matrices, as you showed me earlier.  Following your lead, this is 
> another example:
> 
>> b <- 1:4
> 
>> attr(b, "dim") <- c(2,2)
> 
>> is.matrix(b)
> [1] TRUE
> 
> Does that mean that "a matrix is a vector"?  Not for me, but it does make 
> it easy to see how that concept helps people to understand the internal 
> workings of R.  Gabor Grothendieck wrote, "I think its the idea that in R 
> all data objects are vectors (for some notion of vector) in the sense that 
> all Lisp objects are lists, all APL objects are arrays and all tcl objects 
> are character strings."  That's how I've been thinking about it, too, but 
> I'm not sure that *all* data objects are vectors in this sense.  If that 
> were the case, the Wickham test would always return TRUE.
> 
> 
>> Don't you think it's time to call a halt to this?
> 
> You go first.
> 
> Mike
>


From kristi.glover at hotmail.com  Fri Dec 26 15:38:13 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Fri, 26 Dec 2014 07:38:13 -0700
Subject: [R] ANOVA test
Message-ID: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>

Hi R user,
I am wondering whether I can perform a simple ANOVA analysis in the data in which I ?have mean + SE (+- Standard Error) for several groups.?
For this one, ?I calculated upper and lower confidence interval and made three classes for each group (mean, upper and lower values). After that, I did ANOVA (simple Anova). I am wondering whether this is a wrong approach? ?I have given an example


library(reshape)
B<-structure(list(mean = c(0.0241262, 0.0433538, 0.2204764, 0.7830054
), SE = c(0.0209097, 0.0329281, 0.1003248, 0.3019256), site = structure(1:4, .Label = c("A",?
"B", "C", "D"), class = "factor")), .Names = c("mean", "SE",?
"site"), class = "data.frame", row.names = c(NA, -4L))
attach(B)
B1<-data.frame(B, Upper=mean+1.96*SE, Lower=mean-1.96*SE)
B2<-subset(B1, select=c(-2))
B2
B3<-melt(B2, id=c("site"))
B3
Anova<-aov(B3$value~B3$site)
summary(Anova)

Thanks?

 		 	   		  

From gunter.berton at gene.com  Fri Dec 26 16:23:59 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 26 Dec 2014 07:23:59 -0800
Subject: [R] ANOVA test
In-Reply-To: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>
References: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>
Message-ID: <CACk-te3h4P=3VFATb24Cn+1m-LAHy4Q7QJEdD9Wmdy9cKACVSA@mail.gmail.com>

This is a statistical question primarily and, as such, is off topic
here. Either consult a local statistical expert or post to a
statistical site like stats.stackexchange.com  .

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Dec 26, 2014 at 6:38 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R user,
> I am wondering whether I can perform a simple ANOVA analysis in the data in which I  have mean + SE (+- Standard Error) for several groups.
> For this one,  I calculated upper and lower confidence interval and made three classes for each group (mean, upper and lower values). After that, I did ANOVA (simple Anova). I am wondering whether this is a wrong approach?  I have given an example
>
>
> library(reshape)
> B<-structure(list(mean = c(0.0241262, 0.0433538, 0.2204764, 0.7830054
> ), SE = c(0.0209097, 0.0329281, 0.1003248, 0.3019256), site = structure(1:4, .Label = c("A",
> "B", "C", "D"), class = "factor")), .Names = c("mean", "SE",
> "site"), class = "data.frame", row.names = c(NA, -4L))
> attach(B)
> B1<-data.frame(B, Upper=mean+1.96*SE, Lower=mean-1.96*SE)
> B2<-subset(B1, select=c(-2))
> B2
> B3<-melt(B2, id=c("site"))
> B3
> Anova<-aov(B3$value~B3$site)
> summary(Anova)
>
> Thanks
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Dec 26 16:55:31 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 26 Dec 2014 16:55:31 +0100
Subject: [R] ANOVA test
In-Reply-To: <CACk-te3h4P=3VFATb24Cn+1m-LAHy4Q7QJEdD9Wmdy9cKACVSA@mail.gmail.com>
References: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>
	<CACk-te3h4P=3VFATb24Cn+1m-LAHy4Q7QJEdD9Wmdy9cKACVSA@mail.gmail.com>
Message-ID: <5822D376-B1B5-4A56-8018-72DF669A1A40@gmail.com>

You could at least say that no, that is patently wrong! There are ways to reconstruct an ANOVA from means, sd, and group sizes, but this isn't it. In fact, the group sizes are not even used in the code.

I agree about the need for a statistical expert. Fundamental misunderstandings seem to be present. 

-pd

> On 26 Dec 2014, at 16:23 , Bert Gunter <gunter.berton at gene.com> wrote:
> 
> This is a statistical question primarily and, as such, is off topic
> here. Either consult a local statistical expert or post to a
> statistical site like stats.stackexchange.com  .
> 
> Cheers,
> Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Fri, Dec 26, 2014 at 6:38 AM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
>> Hi R user,
>> I am wondering whether I can perform a simple ANOVA analysis in the data in which I  have mean + SE (+- Standard Error) for several groups.
>> For this one,  I calculated upper and lower confidence interval and made three classes for each group (mean, upper and lower values). After that, I did ANOVA (simple Anova). I am wondering whether this is a wrong approach?  I have given an example
>> 
>> 
>> library(reshape)
>> B<-structure(list(mean = c(0.0241262, 0.0433538, 0.2204764, 0.7830054
>> ), SE = c(0.0209097, 0.0329281, 0.1003248, 0.3019256), site = structure(1:4, .Label = c("A",
>> "B", "C", "D"), class = "factor")), .Names = c("mean", "SE",
>> "site"), class = "data.frame", row.names = c(NA, -4L))
>> attach(B)
>> B1<-data.frame(B, Upper=mean+1.96*SE, Lower=mean-1.96*SE)
>> B2<-subset(B1, select=c(-2))
>> B2
>> B3<-melt(B2, id=c("site"))
>> B3
>> Anova<-aov(B3$value~B3$site)
>> summary(Anova)
>> 
>> Thanks
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wyllys at ischool.utexas.edu  Fri Dec 26 18:48:24 2014
From: wyllys at ischool.utexas.edu (rewyllys)
Date: Fri, 26 Dec 2014 09:48:24 -0800 (PST)
Subject: [R] Unable to install ggplot2;
 using R 3.1.2 and RStudio 0.98.1091 in Linux Mint 17.1
In-Reply-To: <CAM_vju=NxfefbP67BOURm8OXXBW3sinpdpxw75fi6FHXPNYW-A@mail.gmail.com>
References: <1419366000095-4701054.post@n4.nabble.com>
	<CAM_vju=NxfefbP67BOURm8OXXBW3sinpdpxw75fi6FHXPNYW-A@mail.gmail.com>
Message-ID: <1419616104699-4701129.post@n4.nabble.com>

@Sarah Goslee,

Many thanks for your excellent help.

It's a measure of my inexperience with R (and with compiling in Linux) that
I failed to recognize the significance of the g++ error message, and that I
was previously unaware that g++ is a (the?) GNU compiler for C++.

After adding g++ to my desktop, I had no trouble in installing ggplot2,
which is running just fine for me now.

Thanks again.

Ron Wyllys



--
View this message in context: http://r.789695.n4.nabble.com/Unable-to-install-ggplot2-using-R-3-1-2-and-RStudio-0-98-1091-in-Linux-Mint-17-1-tp4701054p4701129.html
Sent from the R help mailing list archive at Nabble.com.


From emorway at usgs.gov  Fri Dec 26 22:16:32 2014
From: emorway at usgs.gov (Morway, Eric)
Date: Fri, 26 Dec 2014 13:16:32 -0800
Subject: [R] Selecting values based on two criteria
Message-ID: <CAPoqHzrserybzE8XCKHegQoW0xLmD6awS4prHJhW3qYyE0VCsQ@mail.gmail.com>

I'm in need of help selecting from d2 those values that come after a value
in d1.  For example, d2[1] is both greater than d1[1] and is the value that
is closest to d2[1].  Similarly, d2[2] is both greater than d1[2] and is
the next "highest" number in d2.  Every value in d1 has a corresponding
value in d2 based on this criteria, however, many of the values in d2 will
be discarded.  The final result I'm looking for is a subset of d2 as given
in d3.  Notice for example that 140569 is discarded and not contained in
d3.  This small example is of course a much smaller example of a much
larger problem.  Example R script of how to whittle down d2 to look like d3
based on the criteria above

d1 <- c(135631,136950,137952,138787,139623,142231,143067,144762,
        145601,146441)

d2 <- c(135882,136954,137956,138792,139630,140569,141398,142237,
        143078,143907,144771,145611,146446,147285,148128)

d3 <- c(135882,136954,137956,138792,139630,142237,143078,144771,
        145611,146446)

	[[alternative HTML version deleted]]


From prabhatdalmia at gmail.com  Fri Dec 26 21:38:38 2014
From: prabhatdalmia at gmail.com (Prabhat Dalmia)
Date: Fri, 26 Dec 2014 12:38:38 -0800
Subject: [R] Saving only few columns to database - RODBC doesnt work
Message-ID: <013801d0214b$ee2ced90$ca86c8b0$@com>

Hi,

 

I want to save only few columns to a table in database from the data.frame
in R. My table has more columns than there are columns in my data.frame
object, so I want that all the columns which are not specified should insert
as nulls. I already have data in this table, and I would like to append more
data from this data frame.

 

If I use sqlSave() function in RODBC, this throws an error saying that data
is missing. There is no way for me to specify specific columns that I want
to save to database. There is a colnames parameter to this function, but
that is used only if I want to save the column names from the dataframe as
the first row in my table. 

 

This seems like a very simple functionality which I am not sure why sqlSave
doesnt provide. Is there any other way I could save these specific columns
to an existing table in my database ?

 

Thanks

pkd

 


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Fri Dec 26 23:22:38 2014
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 26 Dec 2014 17:22:38 -0500
Subject: [R] Selecting values based on two criteria
In-Reply-To: <CAPoqHzrserybzE8XCKHegQoW0xLmD6awS4prHJhW3qYyE0VCsQ@mail.gmail.com>
References: <CAPoqHzrserybzE8XCKHegQoW0xLmD6awS4prHJhW3qYyE0VCsQ@mail.gmail.com>
Message-ID: <5A4FF962-D9F1-434E-8925-EBFA15620259@utoronto.ca>

Try this:

d1 <- c(135631,136950,137952,138787,139623,142231,143067,144762,
       145601,146441)

d2 <- c(135882,136954,137956,138792,139630,140569,141398,142237,
       143078,143907,144771,145611,146446,147285,148128)

len <- length(d1)

# concatenate the two vectors
mrg <- c(d1,d2)

# order the concatenated vector
ord <- order(mrg)


# Look at the result: the indices > len (10) are numbers from d2.
ord   # [1]  1 11  2 12  3 13  4 14  5 15 16 17  6 18  7 19 20  8 21  9 22 10 23 24 25

# Thus you are looking for values in ord that are > len,
# and immediately follow a value that is <= len.

# Initialize a result vector (you could also overwrite d1).
d4 <- rep(NULL, len)

# A counting index ...
ind <- 0

# Slowly, element by element. If your vectors are very large you might
# use apply.

for (i in 1:length(ord)) {
    if (ord[i] > len && ord[i-1] <= len) {
        ind <- ind + 1
        d4[ind] <- mrg[ord[i]]
    }
}

# your d3:
d3 <- c(135882,136954,137956,138792,139630,142237,143078,144771,
       145611,146446)

identical(d3, d4)
# TRUE

# special cases you may need to consider:
# - what if there are values in d1 that are equal to values in d2
# - negative values?
# - what if min(d2) is smaller than than min(d1)?




Cheers,
B.





On Dec 26, 2014, at 4:16 PM, Morway, Eric <emorway at usgs.gov> wrote:

> I'm in need of help selecting from d2 those values that come after a value
> in d1.  For example, d2[1] is both greater than d1[1] and is the value that
> is closest to d2[1].  Similarly, d2[2] is both greater than d1[2] and is
> the next "highest" number in d2.  Every value in d1 has a corresponding
> value in d2 based on this criteria, however, many of the values in d2 will
> be discarded.  The final result I'm looking for is a subset of d2 as given
> in d3.  Notice for example that 140569 is discarded and not contained in
> d3.  This small example is of course a much smaller example of a much
> larger problem.  Example R script of how to whittle down d2 to look like d3
> based on the criteria above
> 
> d1 <- c(135631,136950,137952,138787,139623,142231,143067,144762,
>        145601,146441)
> 
> d2 <- c(135882,136954,137956,138792,139630,140569,141398,142237,
>        143078,143907,144771,145611,146446,147285,148128)
> 
> d3 <- c(135882,136954,137956,138792,139630,142237,143078,144771,
>        145611,146446)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roy.mendelssohn at noaa.gov  Sat Dec 27 00:26:16 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 26 Dec 2014 15:26:16 -0800
Subject: [R] ggmap  (or ggplot2 with mapping question)
Message-ID: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>

HI All:

Okay I am feeling particular brain dead today.  i have the following map created so far using ggmap:

> library(ggmap)
> myLocation <- c(-178, -28, -72, 48)
> myMap <- get_map(location=myLocation, source="google", maptype="satellite", crop=FALSE)
> 

I want to color in some lat-lon 5 degree boxes based on some criterion,  and it look like this could be done use geom_polygon if I can figure out how to get the data in the format required for geom_polygon.  To simplify the problem, suppose i have a bounding box:

subbox<-c(-130, 20, -125, 25)

and I want to color that box red on myMap defined above.    To put this in context, I actually have 360 squares which have been clustered by some criteria, and I want to color them all based on the cluster number of the box. but if I can figure out how to do the simple problem above I can  extend it to the more general problem.

Basically the question is how can I get that simple box information into the format required for geom_polygon.

Thanks for any help.

-Roy


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dwinsemius at comcast.net  Sat Dec 27 01:16:57 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Dec 2014 16:16:57 -0800
Subject: [R] ggmap  (or ggplot2 with mapping question)
In-Reply-To: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>
References: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>
Message-ID: <D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>


> On Dec 26, 2014, at 3:26 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> HI All:
> 
> Okay I am feeling particular brain dead today.  i have the following map created so far using ggmap:
> 
>> library(ggmap)
>> myLocation <- c(-178, -28, -72, 48)
>> myMap <- get_map(location=myLocation, source="google", maptype="satellite", crop=FALSE)
>> 

All if get is a matrix. No map.


> 
> I want to color in some lat-lon 5 degree boxes based on some criterion,  and it look like this could be done use geom_polygon if I can figure out how to get the data in the format required for geom_polygon.  To simplify the problem, suppose i have a bounding box:
> 
> subbox<-c(-130, 20, -125, 25)
> 

That looks more like a specification for geom.rect than for geom_polygon.

 
> and I want to color that box red on myMap defined above.    To put this in context, I actually have 360 squares which have been clustered by some criteria, and I want to color them all based on the cluster number of the box. but if I can figure out how to do the simple problem above I can  extend it to the more general problem.
> 
> Basically the question is how can I get that simple box information into the format required for eom_polygon.

If it were used for eom_polygon I would imagine you need to put it in the form pairs (x,y)

subbox<-list(x=c(-130,-125,-125,-130,-130),y=c( 20,20,25, 25,20))

Just a guess mind, you.

? 
David.
> 
> Thanks for any help.
> 
> -Roy
> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS


From roy.mendelssohn at noaa.gov  Sat Dec 27 01:51:05 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 26 Dec 2014 16:51:05 -0800
Subject: [R] ggmap  (or ggplot2 with mapping question)
In-Reply-To: <D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>
References: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>
	<D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>
Message-ID: <F06F8852-BAB5-425E-AEB9-F84876BB1DA4@noaa.gov>

Thanks.  The map specs are  stored in myMap, it can be displayed just by typing at the prompt:

myMap

 Thanks for the geom.rect suggestion.  I will look at that.

-Roy
On Dec 26, 2014, at 4:16 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
>> On Dec 26, 2014, at 3:26 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>> 
>> HI All:
>> 
>> Okay I am feeling particular brain dead today.  i have the following map created so far using ggmap:
>> 
>>> library(ggmap)
>>> myLocation <- c(-178, -28, -72, 48)
>>> myMap <- get_map(location=myLocation, source="google", maptype="satellite", crop=FALSE)
>>> 
> 
> All if get is a matrix. No map.
> 
> 
>> 
>> I want to color in some lat-lon 5 degree boxes based on some criterion,  and it look like this could be done use geom_polygon if I can figure out how to get the data in the format required for geom_polygon.  To simplify the problem, suppose i have a bounding box:
>> 
>> subbox<-c(-130, 20, -125, 25)
>> 
> 
> That looks more like a specification for geom.rect than for geom_polygon.
> 
> 
>> and I want to color that box red on myMap defined above.    To put this in context, I actually have 360 squares which have been clustered by some criteria, and I want to color them all based on the cluster number of the box. but if I can figure out how to do the simple problem above I can  extend it to the more general problem.
>> 
>> Basically the question is how can I get that simple box information into the format required for eom_polygon.
> 
> If it were used for eom_polygon I would imagine you need to put it in the form pairs (x,y)
> 
> subbox<-list(x=c(-130,-125,-125,-130,-130),y=c( 20,20,25, 25,20))
> 
> Just a guess mind, you.
> 
> ? 
> David.
>> 
>> Thanks for any help.
>> 
>> -Roy
>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
> 
> 
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From roy.mendelssohn at noaa.gov  Sat Dec 27 02:35:33 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn - NOAA Federal)
Date: Fri, 26 Dec 2014 17:35:33 -0800
Subject: [R] ggmap  (or ggplot2 with mapping question)
In-Reply-To: <D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>
References: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>
	<D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>
Message-ID: <09B8550A-F8A4-4DBE-9BEC-7392B69378F4@noaa.gov>

Just as a followup, for the archives:

geom_rect does work. The aes for geom_rect requires xmax, xmin, ymax, ymin, - which are the  limits of the bounding box.  So:

> ggmap(myMap) +  geom_rect(aes(xmin=-130,xmax=-125,ymin=30,ymax=35),colour="white",fill="red?)

should work.  geom_polygon will work also (which could be convenient for doing the groupings), if a data frame of the following sort is created:

> test<-data.frame(
>   lon=c(-130,-130,-125,-125,-125,-125,-120,-120),
>   lat=c(20,25,25,20,30,35,35,30),
>   group=c(1,1,1,1,2,2,2,2),
>   order=c(1,2,3,4,5,6,7,8)
> )
> 

then:

> ggmap(myMap) + geom_polygon(data=test,aes(x = lon, y = lat, group=group),color="white",fill="red?)

should also work.  The more I look at various maps the more I like just using ggplot2, Eric Anderson gave me this example:

> library(mapdata)
> library(maptools)
> 
> w <- map_data("worldHires", ylim = c(-25,50), xlim = c(-180,-70))
> z=ggplot() + geom_polygon(data = w, aes(x=long, y = lat, group = group), fill = "grey80") +coord_fixed(1.3, xlim = c(-180,-70), ylim = c(-25,50)) + theme_bw()
> 
 
then either of the two geoms can be added to ?z? to make the desired plot.

-Roy

On Dec 26, 2014, at 4:16 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
>> On Dec 26, 2014, at 3:26 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>> 
>> HI All:
>> 
>> Okay I am feeling particular brain dead today.  i have the following map created so far using ggmap:
>> 
>>> library(ggmap)
>>> myLocation <- c(-178, -28, -72, 48)
>>> myMap <- get_map(location=myLocation, source="google", maptype="satellite", crop=FALSE)
>>> 
> 
> All if get is a matrix. No map.
> 
> 
>> 
>> I want to color in some lat-lon 5 degree boxes based on some criterion,  and it look like this could be done use geom_polygon if I can figure out how to get the data in the format required for geom_polygon.  To simplify the problem, suppose i have a bounding box:
>> 
>> subbox<-c(-130, 20, -125, 25)
>> 
> 
> That looks more like a specification for geom.rect than for geom_polygon.
> 
> 
>> and I want to color that box red on myMap defined above.    To put this in context, I actually have 360 squares which have been clustered by some criteria, and I want to color them all based on the cluster number of the box. but if I can figure out how to do the simple problem above I can  extend it to the more general problem.
>> 
>> Basically the question is how can I get that simple box information into the format required for eom_polygon.
> 
> If it were used for eom_polygon I would imagine you need to put it in the form pairs (x,y)
> 
> subbox<-list(x=c(-130,-125,-125,-130,-130),y=c( 20,20,25, 25,20))
> 
> Just a guess mind, you.
> 
> ? 
> David.
>> 
>> Thanks for any help.
>> 
>> -Roy
>> 
>> 
>> **********************
>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>> **********************
>> Roy Mendelssohn
>> Supervisory Operations Research Analyst
>> NOAA/NMFS
> 
> 
> 

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From rmh at temple.edu  Sat Dec 27 02:50:29 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 26 Dec 2014 20:50:29 -0500
Subject: [R] ANOVA test
In-Reply-To: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>
References: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>
Message-ID: <CAGx1TMBS96gZ20xHBJi0DJizapZSrbCPXY5zHgJYSodk8117FQ@mail.gmail.com>

Kristi,

The easiest way to do what you are looking for is the aovSufficient function
in the HH package.

## install.packages("HH") ## if you don't have it yet
library(HH)
B.aov <- aovSufficient(mean ~ site, data=B, sd=B$SE, weights=c(3,3,3,3))
summary(B.aov)

You must have the sample size for each of the groups.  Your example did
not include sample sizes, so there is no justification for the degrees
of freedom in the residual.

I invented sizes of 3 observations per group.

See the pulmonary example in ?aovSufficient for a complete example.

There are several style issues that need to be commented on.
It is usually a bad idea to attach a data.frame.  In this example, you attached
B and then never used it, and also never detached it.  That has the potential
to mask objects farther down the search() list.

When you use aov(), or any other function that takes a data= argument,
it is best to use the data= argument.

Rich

On Fri, Dec 26, 2014 at 9:38 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R user,
> I am wondering whether I can perform a simple ANOVA analysis in the data in which I  have mean + SE (+- Standard Error) for several groups.
> For this one,  I calculated upper and lower confidence interval and made three classes for each group (mean, upper and lower values). After that, I did ANOVA (simple Anova). I am wondering whether this is a wrong approach?  I have given an example
>
>
> library(reshape)
> B<-structure(list(mean = c(0.0241262, 0.0433538, 0.2204764, 0.7830054
> ), SE = c(0.0209097, 0.0329281, 0.1003248, 0.3019256), site = structure(1:4, .Label = c("A",
> "B", "C", "D"), class = "factor")), .Names = c("mean", "SE",
> "site"), class = "data.frame", row.names = c(NA, -4L))
> attach(B)
> B1<-data.frame(B, Upper=mean+1.96*SE, Lower=mean-1.96*SE)
> B2<-subset(B1, select=c(-2))
> B2
> B3<-melt(B2, id=c("site"))
> B3
> Anova<-aov(B3$value~B3$site)
> summary(Anova)
>
> Thanks
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Dec 27 03:12:03 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Dec 2014 18:12:03 -0800
Subject: [R] ggmap  (or ggplot2 with mapping question)
In-Reply-To: <F06F8852-BAB5-425E-AEB9-F84876BB1DA4@noaa.gov>
References: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>
	<D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>
	<F06F8852-BAB5-425E-AEB9-F84876BB1DA4@noaa.gov>
Message-ID: <B6E9CED3-EA12-442D-BF17-EF41BB35FD47@comcast.net>


> On Dec 26, 2014, at 4:51 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
> 
> Thanks.  The map specs are  stored in myMap, it can be displayed just by typing at the prompt:
> 
> myMap
> 

No. As I said before, all I see when I enter myMap at the console prompt is a set of RGB values displayed, not as a graphic item but rather as a character matrix with [1:78,1:1280]-entries. 

?. omitted a thousand lines of output

 [76,] "#384435" "#3B4A38" "#485242" "#384435" "#243223" "#243223"
  [77,] "#424C3D" "#3B4A38" "#424C3D" "#3B4A38" "#2E3C2E" "#243223"
  [78,] "#424C3D" "#3B4A38" "#3B4A38" "#384435" "#324432" "#2E3C2E"
 [ reached getOption("max.print") -- omitted 1202 rows ]

Kind of a PITA.

? 
David.


> Thanks for the geom.rect suggestion.  I will look at that.
> 
> -Roy
> On Dec 26, 2014, at 4:16 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>>> On Dec 26, 2014, at 3:26 PM, Roy Mendelssohn - NOAA Federal <roy.mendelssohn at noaa.gov> wrote:
>>> 
>>> HI All:
>>> 
>>> Okay I am feeling particular brain dead today.  i have the following map created so far using ggmap:
>>> 
>>>> library(ggmap)
>>>> myLocation <- c(-178, -28, -72, 48)
>>>> myMap <- get_map(location=myLocation, source="google", maptype="satellite", crop=FALSE)
>>>> 
>> 
>> All if get is a matrix. No map.
>> 
>> 
>>> 
>>> I want to color in some lat-lon 5 degree boxes based on some criterion,  and it look like this could be done use geom_polygon if I can figure out how to get the data in the format required for geom_polygon.  To simplify the problem, suppose i have a bounding box:
>>> 
>>> subbox<-c(-130, 20, -125, 25)
>>> 
>> 
>> That looks more like a specification for geom.rect than for geom_polygon.
>> 
>> 
>>> and I want to color that box red on myMap defined above.    To put this in context, I actually have 360 squares which have been clustered by some criteria, and I want to color them all based on the cluster number of the box. but if I can figure out how to do the simple problem above I can  extend it to the more general problem.
>>> 
>>> Basically the question is how can I get that simple box information into the format required for eom_polygon.
>> 
>> If it were used for eom_polygon I would imagine you need to put it in the form pairs (x,y)
>> 
>> subbox<-list(x=c(-130,-125,-125,-130,-130),y=c( 20,20,25, 25,20))
>> 
>> Just a guess mind, you.
>> 
>> ? 
>> David.
>>> 
>>> Thanks for any help.
>>> 
>>> -Roy
>>> 
>>> 
>>> **********************
>>> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
>>> **********************
>>> Roy Mendelssohn
>>> Supervisory Operations Research Analyst
>>> NOAA/NMFS
>> 
>> 
>> 
> 
> **********************
> "The contents of this message do not reflect any position of the U.S. Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
> 
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected" 
> "the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pdalgd at gmail.com  Sat Dec 27 14:41:11 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 27 Dec 2014 14:41:11 +0100
Subject: [R] ANOVA test
In-Reply-To: <CAGx1TMBS96gZ20xHBJi0DJizapZSrbCPXY5zHgJYSodk8117FQ@mail.gmail.com>
References: <COL130-W627D140F09C18CE4516DCEFA520@phx.gbl>
	<CAGx1TMBS96gZ20xHBJi0DJizapZSrbCPXY5zHgJYSodk8117FQ@mail.gmail.com>
Message-ID: <DE308609-E53F-4B0E-B611-391690E8A5FB@gmail.com>


> On 27 Dec 2014, at 02:50 , Richard M. Heiberger <rmh at temple.edu> wrote:
> 
> Kristi,
> 
> The easiest way to do what you are looking for is the aovSufficient function
> in the HH package.
> 
> ## install.packages("HH") ## if you don't have it yet
> library(HH)
> B.aov <- aovSufficient(mean ~ site, data=B, sd=B$SE, weights=c(3,3,3,3))
> summary(B.aov)
> 

Ummm, you want SD, not SE, in there, don't you?

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From n.l.pace at utah.edu  Sat Dec 27 15:30:22 2014
From: n.l.pace at utah.edu (Nathan Pace)
Date: Sat, 27 Dec 2014 14:30:22 +0000
Subject: [R] predict.lqm
Message-ID: <D0C41EAA.1BDB8%n.l.pace@utah.edu>

Hi,

I can estimate quantile regression models, but can?t get the proper syntax
for the newdata argument in the predict.lqm function.

Specifically:

The model call

Des.Iso.ATE.lqm <- lqm(Wakeup.0.30 ~ Anesthetic,
data = Des.Iso.dt,weights = get.weights(Des.Iso.ATE.ps, stop.method =
'es.mean'),
tau = seq(0.1, 0.9, 0.1), control = list(loop_max_iter = 10000))

The explanatory factor Anesthetic is a two level.

Attempts to use predict


> predict(Des.Iso.ATE.lqm, newdata = data.table(Anesthetic = 'Iso'))
Error in predict.lqm(Des.Iso.ATE.lqm, newdata = data.table(Anesthetic =
"Iso")) : 
  object 'yhat' not found
> predict(Des.Iso.ATE.lqm, newdata = data.frame(Anesthetic = factor('Iso',
>levels=levels(Des.Iso.dt$Anesthetic))))
Error in predict.lqm(Des.Iso.ATE.lqm, newdata = data.frame(Anesthetic =
factor("Iso",  : 
  object 'yhat' not found



???

Nathan


From pdalgd at gmail.com  Sat Dec 27 15:45:00 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 27 Dec 2014 15:45:00 +0100
Subject: [R] ggmap  (or ggplot2 with mapping question)
In-Reply-To: <B6E9CED3-EA12-442D-BF17-EF41BB35FD47@comcast.net>
References: <D8ACC79A-754F-4C0C-AF0D-24A1F6EF4CD6@noaa.gov>
	<D875BA76-925E-47AC-B3B1-FA075E50C10F@comcast.net>
	<F06F8852-BAB5-425E-AEB9-F84876BB1DA4@noaa.gov>
	<B6E9CED3-EA12-442D-BF17-EF41BB35FD47@comcast.net>
Message-ID: <C82897D0-6870-445F-B891-A0E399009AEB@gmail.com>


> On 27 Dec 2014, at 03:12 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
> No. As I said before, all I see when I enter myMap at the console prompt is a set of RGB values displayed, not as a graphic item but rather as a character matrix with [1:78,1:1280]-entries. 

ggmap(myMap) looks like a better idea, or str(myMap) to see the rest of the internals. (Not that I actually know what I'm talking about...)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pdalgd at gmail.com  Sat Dec 27 16:01:10 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 27 Dec 2014 16:01:10 +0100
Subject: [R] predict.lqm
In-Reply-To: <D0C41EAA.1BDB8%n.l.pace@utah.edu>
References: <D0C41EAA.1BDB8%n.l.pace@utah.edu>
Message-ID: <8F508792-121E-4EF9-91B2-4C9F832FFB1E@gmail.com>

Looks like a bug in predict.lqm. If nq != 1 and !missing(newdata), it ends up using yhat without having computed it. You need to contact the maintainer:

> maintainer("lqmm")


> On 27 Dec 2014, at 15:30 , Nathan Pace <n.l.pace at utah.edu> wrote:
> 
> Hi,
> 
> I can estimate quantile regression models, but can?t get the proper syntax
> for the newdata argument in the predict.lqm function.
> 
> Specifically:
> 
> The model call
> 
> Des.Iso.ATE.lqm <- lqm(Wakeup.0.30 ~ Anesthetic,
> data = Des.Iso.dt,weights = get.weights(Des.Iso.ATE.ps, stop.method =
> 'es.mean'),
> tau = seq(0.1, 0.9, 0.1), control = list(loop_max_iter = 10000))
> 
> The explanatory factor Anesthetic is a two level.
> 
> Attempts to use predict
> 
> 
>> predict(Des.Iso.ATE.lqm, newdata = data.table(Anesthetic = 'Iso'))
> Error in predict.lqm(Des.Iso.ATE.lqm, newdata = data.table(Anesthetic =
> "Iso")) : 
>  object 'yhat' not found
>> predict(Des.Iso.ATE.lqm, newdata = data.frame(Anesthetic = factor('Iso',
>> levels=levels(Des.Iso.dt$Anesthetic))))
> Error in predict.lqm(Des.Iso.ATE.lqm, newdata = data.frame(Anesthetic =
> factor("Iso",  : 
>  object 'yhat' not found
> 
> 
> 
> ???
> 
> Nathan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wizardchef at gmail.com  Sat Dec 27 21:07:27 2014
From: wizardchef at gmail.com (Ernie Stokely)
Date: Sat, 27 Dec 2014 14:07:27 -0600
Subject: [R] Function bug when sourcing
Message-ID: <549F117F.40406@gmail.com>

I am unable to figure out why I get this error in the code below:

Error in as.Date(data.dates.x, format = "%m/%d/%Y") :
   object 'data.dates.x' not found

Here is the code with comments deleted:
-----------------------------------------------------

ConvertExcelDateData <- function(ticker.prices, data.dates)

      data.dates.x <- as.vector(unlist(data.dates))

      data.dates.x <- as.Date(data.dates.x, format = "%m/%d/%y")

  return(match(data.dates.x,time(ticker.prices)))

--------------------------------------------------------

I'm sure it is something obvious, but I am blind to it. Help appreciated.


From pdalgd at gmail.com  Sat Dec 27 21:28:34 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 27 Dec 2014 21:28:34 +0100
Subject: [R] Function bug when sourcing
In-Reply-To: <549F117F.40406@gmail.com>
References: <549F117F.40406@gmail.com>
Message-ID: <6E7047CC-6772-4D17-9A6C-065333E8B8BE@gmail.com>

A pair of braces: {} would seem required.
-pd

> On 27 Dec 2014, at 21:07 , Ernie Stokely <wizardchef at gmail.com> wrote:
> 
> I am unable to figure out why I get this error in the code below:
> 
> Error in as.Date(data.dates.x, format = "%m/%d/%Y") :
>  object 'data.dates.x' not found
> 
> Here is the code with comments deleted:
> -----------------------------------------------------
> 
> ConvertExcelDateData <- function(ticker.prices, data.dates)
> 
>     data.dates.x <- as.vector(unlist(data.dates))
> 
>     data.dates.x <- as.Date(data.dates.x, format = "%m/%d/%y")
> 
> return(match(data.dates.x,time(ticker.prices)))
> 
> --------------------------------------------------------
> 
> I'm sure it is something obvious, but I am blind to it. Help appreciated.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rolfe at algonet.se  Sun Dec 28 15:56:14 2014
From: rolfe at algonet.se (Rolf Edberg)
Date: Sun, 28 Dec 2014 15:56:14 +0100
Subject: [R] Moving average
Message-ID: <003f01d022ae$6dc008e0$49401aa0$@se>

 

How do I add a new column with 2-days moving average (from
r-adamant(https://github.com/TotallyBullshit/radamant)) on IBM prices in a
csv-file (ibm.csv) and then save all in a new csv file(ibm2.csv)?

 


Prices

 



Date

Open

High

Low

Close

Volume

Adj Close*


Dec 26, 2014

162.27

163.09

162.01

162.34

1,912,200

162.34


Dec 24, 2014

162.88

162.99

161.61

161.82

1,868,100

161.82


Dec 23, 2014

162.23

162.90

161.61

162.24

4,043,300

162.24


Dec 22, 2014

158.33

161.91

158.33

161.44

4,682,500

161.44


Dec 19, 2014

157.49

160.41

157.49

158.51

8,864,900

158.51

 


	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Dec 28 16:45:00 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 28 Dec 2014 07:45:00 -0800
Subject: [R] Moving average
In-Reply-To: <003f01d022ae$6dc008e0$49401aa0$@se>
References: <003f01d022ae$6dc008e0$49401aa0$@se>
Message-ID: <CAAxdm-5M8o8dYcWr7Gow2za3rbMYMDN2A9pcJM+ZEcwwYVLw1A@mail.gmail.com>

could not read the data you posted; try 'dput' next time.

If it is just a 2 day moving average, try the 'filter' function:

> x <- 1:20
> x
 [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
> filter(x, c(.5,.5))
Time Series:
Start = 1
End = 20
Frequency = 1
 [1]  1.5  2.5  3.5  4.5  5.5  6.5  7.5  8.5  9.5 10.5 11.5 12.5 13.5 14.5
15.5 16.5 17.5 18.5 19.5   NA
>



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Dec 28, 2014 at 6:56 AM, Rolf Edberg <rolfe at algonet.se> wrote:

>
>
> How do I add a new column with 2-days moving average (from
> r-adamant(https://github.com/TotallyBullshit/radamant)) on IBM prices in a
> csv-file (ibm.csv) and then save all in a new csv file(ibm2.csv)?
>
>
>
>
> Prices
>
>
>
>
>
> Date
>
> Open
>
> High
>
> Low
>
> Close
>
> Volume
>
> Adj Close*
>
>
> Dec 26, 2014
>
> 162.27
>
> 163.09
>
> 162.01
>
> 162.34
>
> 1,912,200
>
> 162.34
>
>
> Dec 24, 2014
>
> 162.88
>
> 162.99
>
> 161.61
>
> 161.82
>
> 1,868,100
>
> 161.82
>
>
> Dec 23, 2014
>
> 162.23
>
> 162.90
>
> 161.61
>
> 162.24
>
> 4,043,300
>
> 162.24
>
>
> Dec 22, 2014
>
> 158.33
>
> 161.91
>
> 158.33
>
> 161.44
>
> 4,682,500
>
> 161.44
>
>
> Dec 19, 2014
>
> 157.49
>
> 160.41
>
> 157.49
>
> 158.51
>
> 8,864,900
>
> 158.51
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From huseyiniskenderkaragul at gmail.com  Sun Dec 28 17:12:37 2014
From: huseyiniskenderkaragul at gmail.com (Iskender Karagul)
Date: Sun, 28 Dec 2014 18:12:37 +0200
Subject: [R] Question
Message-ID: <00cd01d022b9$1ba867e0$52f937a0$@gmail.com>

Dear All,



I am a very fresh user of R platform. I completed the download of R for
Windows, from the http://cran.r-project.org/ Web address.



After opening the program I wanted to Go to Packages Tab and firstly Set
CRAN mirror and then Install Package(s). However, I saw a statement in the
console like below:



Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
=type) :  'lib = "C:/Program Files/R/R-3.1.2/library"' is not writable.



Am I skipping a stage in this very early stage of R or am I just doing
something wrong?



Would you please help me to successfully complete download process so that I
can start improing my R skills?



What shall I do after just downloading R before I can make it work?



I would like to thank all the R contributors and R society for all of their
efforts.



Kind Regards,



Dr. Iskender KARAG?L





---
This email has been checked for viruses by Avast antivirus software.


	[[alternative HTML version deleted]]


From faranak.golestaneh at gmail.com  Sun Dec 28 15:17:56 2014
From: faranak.golestaneh at gmail.com (Faranak Golestaneh)
Date: Sun, 28 Dec 2014 22:17:56 +0800
Subject: [R] Changing UTC time to a time zone different from system time zone
Message-ID: <CACYQf7gDgUBNUGzBdNtMAcb=vHQVBYef1e6=r5iBp50Qym6=1Q@mail.gmail.com>

Dear Friends, I?ve just started using R. I am working on a database
containing date-time as well as numeric values. Firstly I have changed the
class of the data/time column from factor to POSIXlt. Time and date are
based on UTC time but I need to change them to a local time ( not my local
time, my zone is Singapore but the data are from Australia) so I need to
change the time and date to Australia time say e.g AEST. I tried one way or
another but all failed. The following is example of the command I used.
Also one of my .CSV files is attached.

Data_Power <- read.table("train15.csv",header = TRUE, sep = ",", row.names
= NULL);

Date_clm=Data_Power$TIMESTAMP;

Date_original <- strptime(Date_clm, "%Y %m %d %H:%M", tz="GMT")

Date_local =format(Date_original, format="%c", tz="America/New_York")

Date_local <- strptime(Date_original, "%Y %m %d %H:%M +0800")

Date_local=as.POSIXlt(Date_original, "Australia/Darwin")

Date_local=as.POSIXlt(Date_original, " AEST ")

I would be so thankful if you help me out. Thanks



Cheers,

Faranak

From murdoch.duncan at gmail.com  Sun Dec 28 19:05:57 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 28 Dec 2014 13:05:57 -0500
Subject: [R] Question
In-Reply-To: <00cd01d022b9$1ba867e0$52f937a0$@gmail.com>
References: <00cd01d022b9$1ba867e0$52f937a0$@gmail.com>
Message-ID: <54A04685.8080003@gmail.com>

On 28/12/2014 11:12 AM, Iskender Karagul wrote:
> Dear All,
> 
> 
> 
> I am a very fresh user of R platform. I completed the download of R for
> Windows, from the http://cran.r-project.org/ Web address.
> 
> 
> 
> After opening the program I wanted to Go to Packages Tab and firstly Set
> CRAN mirror and then Install Package(s). However, I saw a statement in the
> console like below:
> 
> 
> 
> Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA, type
> =type) :  'lib = "C:/Program Files/R/R-3.1.2/library"' is not writable.
> 
> 
> 
> Am I skipping a stage in this very early stage of R or am I just doing
> something wrong?

You need to be very precise in describing what you did before seeing
this message.  Did you run the installer?  How did you run it?  Did you
run R after running the installer?  How?

If this message appeared when running the installer, it suggests that
you are trying to install R but you don't have administrator privileges
on your machine.  If that's the case, you can't install it to Program
Files, as the message says, because that directory is not writable by
you.  There are two solutions:  use "Run as administrator" when you run
the installer, or install it somewhere else.

Duncan Murdoch

> 
> 
> 
> Would you please help me to successfully complete download process so that I
> can start improing my R skills?
> 
> 
> 
> What shall I do after just downloading R before I can make it work?
> 
> 
> 
> I would like to thank all the R contributors and R society for all of their
> efforts.
> 
> 
> 
> Kind Regards,
> 
> 
> 
> Dr. Iskender KARAG?L
> 
> 
> 
> 
> 
> ---
> This email has been checked for viruses by Avast antivirus software.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Sun Dec 28 21:12:58 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 28 Dec 2014 12:12:58 -0800
Subject: [R] Question
In-Reply-To: <00cd01d022b9$1ba867e0$52f937a0$@gmail.com>
References: <00cd01d022b9$1ba867e0$52f937a0$@gmail.com>
Message-ID: <0042882D-BABE-4906-909E-F86A561C9658@dcn.davis.CA.us>

This is (mostly) normal. The R software comes with an initial set of packages that are kept in the Program Files directory, which is only modifiable using administrator privileges. If you are running your machine just for you (as most people do) then I highly advise accepting the option during installation to create a local R packages library in your Documents directory. Then you can manage packages without using Administrative privileges that are complicated to keep straight. Your local packages will by default override the ones that originally came with the software so you can upgrade packages frequently without messing with admin privileges. (I recommend avoiding starting any program with administrator privileges unless you have been trained how to use that privilege. Windows can prompt you for those cases where you really need it. Failing to heed this advice will lead to you needing to use Administrator privileges for many things that should not require it, and eventually the
only thing that can fix it is reinstalling your operating system.)

Before you post again, please read the Posting Guide mentioned at the bottom of this email. Note that this guide mentions giving complete, reproducible examples (not snippets of output without any idea what you did to cause them to appear), and it also mentions that this mailing list is text only... HTML email usually mangles the raw text that R produces and that we need to see. Posting in plain text is an option in practically every email program... if yours really does not support it then you need to use another program.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 28, 2014 8:12:37 AM PST, Iskender Karagul <huseyiniskenderkaragul at gmail.com> wrote:
>Dear All,
>
>
>
>I am a very fresh user of R platform. I completed the download of R for
>Windows, from the http://cran.r-project.org/ Web address.
>
>
>
>After opening the program I wanted to Go to Packages Tab and firstly
>Set
>CRAN mirror and then Install Package(s). However, I saw a statement in
>the
>console like below:
>
>
>
>Warning in install.packages(NULL, .libPaths()[1L], dependencies = NA,
>type
>=type) :  'lib = "C:/Program Files/R/R-3.1.2/library"' is not writable.
>
>
>
>Am I skipping a stage in this very early stage of R or am I just doing
>something wrong?
>
>
>
>Would you please help me to successfully complete download process so
>that I
>can start improing my R skills?
>
>
>
>What shall I do after just downloading R before I can make it work?
>
>
>
>I would like to thank all the R contributors and R society for all of
>their
>efforts.
>
>
>
>Kind Regards,
>
>
>
>Dr. Iskender KARAG?L
>
>
>
>
>
>---
>This email has been checked for viruses by Avast antivirus software.
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Dec 28 22:52:56 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 28 Dec 2014 13:52:56 -0800 (PST)
Subject: [R] Changing UTC time to a time zone different from system time
 zone
In-Reply-To: <CACYQf7gDgUBNUGzBdNtMAcb=vHQVBYef1e6=r5iBp50Qym6=1Q@mail.gmail.com>
References: <CACYQf7gDgUBNUGzBdNtMAcb=vHQVBYef1e6=r5iBp50Qym6=1Q@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1412281337580.34923@pedal.dcn.davis.ca.us>

Very few attachment file types are allowed through the mailing list, and 
yours did not make it.

I noticed that your format strings did not appear consistent... see the 
format string I use below, and make sure the characters between the 
numeric parts of your format are correct for your case. Did you read 
the help file ?strptime ?

Note that there are two steps... importing the character data to a POSIXct 
type, and then choosing how you want to display those instants of time in 
whatever time zones you wish. That is, regardless of time zone, the 
POSIXct value represents the same instant of time regardless of time zone 
you want to display it in, while POSIXlt will in general have different 
internal representations that match the external representations.

Note that you really do need to read ?timezone, because the below code 
only works if your system understands the "GMT" and "Australia/Darwin" 
timezones, and that is operating-system-specific behavior.  This was 
successfully run on Ubuntu... you did not mention your operating system.

> tst <- "2014-12-25 00:00" # GMT
> tstct <- as.POSIXct( tst, format="%Y-%m-%d %H:%M", tz="GMT" )
> tstct
[1] "2014-12-25 GMT"
> unclass(tstct)
[1] 1419465600
attr(,"tzone")
[1] "GMT"
> tstlt <- as.POSIXlt( tstct, tz="Australia/Darwin" )
> tstlt
[1] "2014-12-25 09:30:00 ACST"
> unclass(tstlt)
$sec
[1] 0

$min
[1] 30

$hour
[1] 9

$mday
[1] 25

$mon
[1] 11

$year
[1] 114

$wday
[1] 4

$yday
[1] 358

$isdst
[1] 0

$zone
[1] "ACST"

$gmtoff
[1] 34200

attr(,"tzone")
[1] "Australia/Darwin" "ACST"             "ACDT"
> tstct2 <- as.POSIXct( tstlt )
> tstct2
[1] "2014-12-25 09:30:00 ACST"
> unclass(tstct2)
[1] 1419465600
attr(,"tzone")
[1] "Australia/Darwin"


On Sun, 28 Dec 2014, Faranak Golestaneh wrote:

> Dear Friends, I?ve just started using R. I am working on a database
> containing date-time as well as numeric values. Firstly I have changed the
> class of the data/time column from factor to POSIXlt. Time and date are
> based on UTC time but I need to change them to a local time ( not my local
> time, my zone is Singapore but the data are from Australia) so I need to
> change the time and date to Australia time say e.g AEST. I tried one way or
> another but all failed. The following is example of the command I used.
> Also one of my .CSV files is attached.
>
> Data_Power <- read.table("train15.csv",header = TRUE, sep = ",", row.names
> = NULL);
>
> Date_clm=Data_Power$TIMESTAMP;
>
> Date_original <- strptime(Date_clm, "%Y %m %d %H:%M", tz="GMT")
>
> Date_local =format(Date_original, format="%c", tz="America/New_York")
>
> Date_local <- strptime(Date_original, "%Y %m %d %H:%M +0800")
>
> Date_local=as.POSIXlt(Date_original, "Australia/Darwin")
>
> Date_local=as.POSIXlt(Date_original, " AEST ")
>
> I would be so thankful if you help me out. Thanks
>
>
>
> Cheers,
>
> Faranak
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From marongiu.luigi at gmail.com  Mon Dec 29 00:09:23 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Sun, 28 Dec 2014 23:09:23 +0000
Subject: [R] RAxML using R
Message-ID: <54A08DA3.6010209@gmail.com>

Dear all,
I would like to run RAxML for phylogenetic analysis as indicated on 
Paradis' "Analysis of phylogenetic and evolution with R" (p. 158) thus I 
tried to use the package phyloch and its function raxml(). I am using 
Linux Ubuntu 14 and I was able to successfully install RAxML on my machine.
However phyloch is not supported by CRAN and the package as provided by 
the author on http://www.christophheibl.de/Rpackages.html cannot be 
installed -- or at least I could not using the Software centre.
I found a function on http://www.christophheibl.de/raxml.R that should 
be the actual script of the function raxml(). However I do not know how 
to implement such function. Shall I just copy it into my script? But 
then I will have hundreds of lines of code that will mess with my 
script. Can I create a kind of package that I can call from my code? Or 
is there another way to send the data to the linux shell and call the 
raxml function?
Could anybody help?
Thank you
Luigi


From ripley at stats.ox.ac.uk  Mon Dec 29 12:12:54 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Dec 2014 11:12:54 +0000
Subject: [R] Changing UTC time to a time zone different from system time
 zone
In-Reply-To: <alpine.BSF.2.00.1412281337580.34923@pedal.dcn.davis.ca.us>
References: <CACYQf7gDgUBNUGzBdNtMAcb=vHQVBYef1e6=r5iBp50Qym6=1Q@mail.gmail.com>
	<alpine.BSF.2.00.1412281337580.34923@pedal.dcn.davis.ca.us>
Message-ID: <54A13736.2080206@stats.ox.ac.uk>

On 28/12/2014 21:52, Jeff Newmiller wrote:
> Very few attachment file types are allowed through the mailing list, and
> yours did not make it.
>
> I noticed that your format strings did not appear consistent... see the
> format string I use below, and make sure the characters between the
> numeric parts of your format are correct for your case. Did you read the
> help file ?strptime ?
>
> Note that there are two steps... importing the character data to a
> POSIXct type, and then choosing how you want to display those instants
> of time in whatever time zones you wish. That is, regardless of time
> zone, the POSIXct value represents the same instant of time regardless
> of time zone you want to display it in, while POSIXlt will in general
> have different internal representations that match the external
> representations.
>
> Note that you really do need to read ?timezone, because the below code
> only works if your system understands the "GMT" and "Australia/Darwin"
> timezones, and that is operating-system-specific behavior.  This was
> successfully run on Ubuntu... you did not mention your operating system.

Correct, but for R >= 3.1.0 that help page says

'    Almost all R platforms make use of a time-zone database originally
      compiled by Arthur David Olson and now managed by IANA, in which
      the preferred way to refer to a time zone is by a location ...'

and "GMT" is always supported although "UTC" is preferred.

All the platforms documented in 'R Installation and Administration' do 
make such use; however occasionally we hear of new ports, hence the 
cautious use of 'Almost'.

However, we were also not told the R version ....

>
>> tst <- "2014-12-25 00:00" # GMT
>> tstct <- as.POSIXct( tst, format="%Y-%m-%d %H:%M", tz="GMT" )
>> tstct
> [1] "2014-12-25 GMT"
>> unclass(tstct)
> [1] 1419465600
> attr(,"tzone")
> [1] "GMT"
>> tstlt <- as.POSIXlt( tstct, tz="Australia/Darwin" )
>> tstlt
> [1] "2014-12-25 09:30:00 ACST"
>> unclass(tstlt)
> $sec
> [1] 0
>
> $min
> [1] 30
>
> $hour
> [1] 9
>
> $mday
> [1] 25
>
> $mon
> [1] 11
>
> $year
> [1] 114
>
> $wday
> [1] 4
>
> $yday
> [1] 358
>
> $isdst
> [1] 0
>
> $zone
> [1] "ACST"
>
> $gmtoff
> [1] 34200
>
> attr(,"tzone")
> [1] "Australia/Darwin" "ACST"             "ACDT"
>> tstct2 <- as.POSIXct( tstlt )
>> tstct2
> [1] "2014-12-25 09:30:00 ACST"
>> unclass(tstct2)
> [1] 1419465600
> attr(,"tzone")
> [1] "Australia/Darwin"
>
>
> On Sun, 28 Dec 2014, Faranak Golestaneh wrote:
>
>> Dear Friends, I?ve just started using R. I am working on a database
>> containing date-time as well as numeric values. Firstly I have changed
>> the
>> class of the data/time column from factor to POSIXlt. Time and date are
>> based on UTC time but I need to change them to a local time ( not my
>> local
>> time, my zone is Singapore but the data are from Australia) so I need to
>> change the time and date to Australia time say e.g AEST. I tried one
>> way or
>> another but all failed. The following is example of the command I used.
>> Also one of my .CSV files is attached.
>>
>> Data_Power <- read.table("train15.csv",header = TRUE, sep = ",",
>> row.names
>> = NULL);
>>
>> Date_clm=Data_Power$TIMESTAMP;
>>
>> Date_original <- strptime(Date_clm, "%Y %m %d %H:%M", tz="GMT")
>>
>> Date_local =format(Date_original, format="%c", tz="America/New_York")
>>
>> Date_local <- strptime(Date_original, "%Y %m %d %H:%M +0800")
>>
>> Date_local=as.POSIXlt(Date_original, "Australia/Darwin")
>>
>> Date_local=as.POSIXlt(Date_original, " AEST ")
>>
>> I would be so thankful if you help me out. Thanks
>>
>>
>>
>> Cheers,
>>
>> Faranak


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From ruipbarradas at sapo.pt  Mon Dec 29 12:18:51 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 29 Dec 2014 11:18:51 +0000
Subject: [R] RAxML using R
In-Reply-To: <54A08DA3.6010209@gmail.com>
References: <54A08DA3.6010209@gmail.com>
Message-ID: <54A1389B.9030000@sapo.pt>

Hello,

You can put the code of that function in a separate file, say "raxml.R" 
and then use source("raxml.R"). See the help page ?source.

Hope this helps,

Rui Barradas

Em 28-12-2014 23:09, Luigi Marongiu escreveu:
> Dear all,
> I would like to run RAxML for phylogenetic analysis as indicated on
> Paradis' "Analysis of phylogenetic and evolution with R" (p. 158) thus I
> tried to use the package phyloch and its function raxml(). I am using
> Linux Ubuntu 14 and I was able to successfully install RAxML on my machine.
> However phyloch is not supported by CRAN and the package as provided by
> the author on http://www.christophheibl.de/Rpackages.html cannot be
> installed -- or at least I could not using the Software centre.
> I found a function on http://www.christophheibl.de/raxml.R that should
> be the actual script of the function raxml(). However I do not know how
> to implement such function. Shall I just copy it into my script? But
> then I will have hundreds of lines of code that will mess with my
> script. Can I create a kind of package that I can call from my code? Or
> is there another way to send the data to the linux shell and call the
> raxml function?
> Could anybody help?
> Thank you
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Mon Dec 29 14:09:25 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 29 Dec 2014 07:09:25 -0600
Subject: [R] half-logistic distribution
In-Reply-To: <mailman.3.1419591602.11103.r-help@r-project.org>
References: <mailman.3.1419591602.11103.r-help@r-project.org>
Message-ID: <31062c$9hik8m@ironport10.mayo.edu>



On 12/26/2014 05:00 AM, r-help-request at r-project.org wrote:
> i want to analyse survival data using typeI HALF LOGISTIC
> DISTRIBUTION.how can i go about it?it installed one on R in the
> survival package didn't include the distribution...or i need a code to
> use maximum likelihood to estimate the parameter in survival
> analysis.a typical example of distribution other than that installed
> in R will help.thanks
>

I am the author of the survival package, and had never heard of the "type I half-logistic" 
before.
New distributions can be added to survreg() if they can be represented as location-scale 
families; I don't think that your distribution can be written in that way.

Look at "survival" under the "Task Views" tab (upper left corner) of the cran.org web page 
-- someone else may have already done it.

Terry T.


From istazahn at gmail.com  Mon Dec 29 15:07:35 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 29 Dec 2014 09:07:35 -0500
Subject: [R] Legend (guides) for point and two line graph
In-Reply-To: <AEFD3722-0DBA-46AB-9290-26294877C2C9@boomer.org>
References: <AEFD3722-0DBA-46AB-9290-26294877C2C9@boomer.org>
Message-ID: <CA+vqiLGta=K5OUXG2V+SSLrWJOEgMYtaKoV3tWXJyE3tfCCH6g@mail.gmail.com>

Hi David,

1) set size to a fixed value instead of mapping it to a constant,
i.e., geom_line(size = 2) instead of geom_line(aes(size = 2))

2) perhaps

ggplot(rtest, aes(x=Time, y=Calculated,color=Model, group=Model)) +
  geom_line(size = 2) +
  geom_point(aes(y=Observed, shape=""),
             size=6, colour="black") +
               scale_colour_manual(values=c("green","red")) +
  guides(shape = guide_legend("Observed",
                              override.aes=list(shape = 16)))

though this is a bit of a hack.

3) legends are automatically created when you map something to an
aesthetic. see ?guide and guide_legend etc. for customization.

Best,
Ista


On Mon, Oct 13, 2014 at 4:43 PM, David Bourne <david at boomer.org> wrote:
> I?m trying to generate a plot with a series of data points and best fit lines from two stat models. I?m generating the best-fits with another program. I have the data in a csv file as:
>
> Time,Observed,Calculated,Model
> 0.000,0.00000,13.0810,1C
> 0.2500,15.0000,12.5298,1C
> 0.5000,12.0000,12.0018,1C
> 1.000,9.00000,11.0117,1C
> 2.000,8.00000,9.26969,1C
> 4.000,6.50000,6.56882,1C
> 6.000,4.80000,4.65489,1C
> 9.000,3.20000,2.77680,1C
> 12.00,2.10000,1.65641,1C
> 18.00,1.80000,0.589422,1C
> 24.00,0.900000,0.209736,1C
> 0.000,0.00000,21.7130,2C
> 0.2500,15.0000,15.0512,2C
> 0.5000,12.0000,11.8203,2C
> 1.000,9.00000,9.29374,2C
> 2.000,8.00000,7.82242,2C
> 4.000,6.50000,6.20213,2C
> 6.000,4.80000,4.93346,2C
> 9.000,3.20000,3.50010,2C
> 12.00,2.10000,2.48310,2C
> 18.00,1.80000,1.24979,2C
> 24.00,0.900000,0.629039,2C
>
> I read in the data with (R 3.1.1 GUI 1.65 Mavericks build (6784)):
>
>>rtest <- read.csv("rtest.csv",header=TRUE)
>
> Checked with
>
>>rtest
>     Time Observed Calculated Model
> 1   0.00      0.0  13.081000    1C
> 2   0.25     15.0  12.529800    1C
> 3   0.50     12.0  12.001800    1C
> 4   1.00      9.0  11.011700    1C
> 5   2.00      8.0   9.269690    1C
> 6   4.00      6.5   6.568820    1C
> 7   6.00      4.8   4.654890    1C
> 8   9.00      3.2   2.776800    1C
> 9  12.00      2.1   1.656410    1C
> 10 18.00      1.8   0.589422    1C
> 11 24.00      0.9   0.209736    1C
> 12  0.00      0.0  21.713000    2C
> 13  0.25     15.0  15.051200    2C
> 14  0.50     12.0  11.820300    2C
> 15  1.00      9.0   9.293740    2C
> 16  2.00      8.0   7.822420    2C
> 17  4.00      6.5   6.202130    2C
> 18  6.00      4.8   4.933460    2C
> 19  9.00      3.2   3.500100    2C
> 20 12.00      2.1   2.483100    2C
> 21 18.00      1.8   1.249790    2C
> 22 24.00      0.9   0.629039    2C
>
> Generated the graph with:
>
> ggplot(rtest, aes(x=Time, y=Calculated,color=Model, group=Model)) + geom_line(aes(size=2)) + geom_point(aes(y=Observed, size=Observed), size=6, colour="black") + scale_colour_manual(values=c("green","red")) + labs(size="Observed?)
>
> Which resulted in the plot:
>
> http://www.boomer.org/rtest/rtest.pdf
>
> I?d like to:
>
> 1) get rid of the Observed / 2 legend(guide)
> 2) maybe keep the Observed and have a circle, i.e., loose the ?2?
> 3) understand how to create, format the legend
>
> This seems like a common enough problem but the online documentation, R for Dummies nor the R Graphic Cookbook seems to have an answer (from my reading).
>
> Thanks for any clues/suggestion.
>
> David
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Mon Dec 29 15:23:16 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Mon, 29 Dec 2014 14:23:16 +0000
Subject: [R] RAxML using R
In-Reply-To: <54A1389B.9030000@sapo.pt>
References: <54A08DA3.6010209@gmail.com> <54A1389B.9030000@sapo.pt>
Message-ID: <54A163D4.6010704@gmail.com>

Dear Rui,
thanks for the reply. I tried it but there were serious problems with 
the function itself: I can't use it as is because there were different 
error messages according to the parameters passed to it.
Such function has to be re-written on purpose or I should call the RAxML 
function from Linux Shell with some kind of interface.
Best regards
Luigi


On 29/12/14 11:18, Rui Barradas wrote:
> Hello,
>
> You can put the code of that function in a separate file, say 
> "raxml.R" and then use source("raxml.R"). See the help page ?source.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 28-12-2014 23:09, Luigi Marongiu escreveu:
>> Dear all,
>> I would like to run RAxML for phylogenetic analysis as indicated on
>> Paradis' "Analysis of phylogenetic and evolution with R" (p. 158) thus I
>> tried to use the package phyloch and its function raxml(). I am using
>> Linux Ubuntu 14 and I was able to successfully install RAxML on my 
>> machine.
>> However phyloch is not supported by CRAN and the package as provided by
>> the author on http://www.christophheibl.de/Rpackages.html cannot be
>> installed -- or at least I could not using the Software centre.
>> I found a function on http://www.christophheibl.de/raxml.R that should
>> be the actual script of the function raxml(). However I do not know how
>> to implement such function. Shall I just copy it into my script? But
>> then I will have hundreds of lines of code that will mess with my
>> script. Can I create a kind of package that I can call from my code? Or
>> is there another way to send the data to the linux shell and call the
>> raxml function?
>> Could anybody help?
>> Thank you
>> Luigi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From istazahn at gmail.com  Mon Dec 29 16:07:43 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 29 Dec 2014 10:07:43 -0500
Subject: [R] RAxML using R
In-Reply-To: <54A163D4.6010704@gmail.com>
References: <54A08DA3.6010209@gmail.com> <54A1389B.9030000@sapo.pt>
	<54A163D4.6010704@gmail.com>
Message-ID: <CA+vqiLHbF8jjDmKQ1rkFTG9m4TM6e+sXm6ZHJ1gxwbar=LLq1Q@mail.gmail.com>

Let's step back for a moment and look at the larger picture. There are
real advantages to using packages on CRAN, including convenient
installation, updates, etc., so let's see if we can find a package on
cran that does what we want:

install.packages("sos")
library(sos)
findFn("raxml")

This suggests that the ips package does what we want, so let's install
it and test it out:

install.packages("ips")
library(ips)
example(raxml)

If for some reason this does not do what you want, and you really need
to install packages outside the standard R package repositories, the
devtools package will make this easier:

library(devtools)
nstall_url("http://www.christophheibl.de/phyloch_1.5-5.tar.gz")
library(phyloch)
example(raxml)

HTH,
Ista

On Mon, Dec 29, 2014 at 9:23 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear Rui,
> thanks for the reply. I tried it but there were serious problems with the
> function itself: I can't use it as is because there were different error
> messages according to the parameters passed to it.
> Such function has to be re-written on purpose or I should call the RAxML
> function from Linux Shell with some kind of interface.
> Best regards
> Luigi
>
>
>
> On 29/12/14 11:18, Rui Barradas wrote:
>>
>> Hello,
>>
>> You can put the code of that function in a separate file, say "raxml.R"
>> and then use source("raxml.R"). See the help page ?source.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 28-12-2014 23:09, Luigi Marongiu escreveu:
>>>
>>> Dear all,
>>> I would like to run RAxML for phylogenetic analysis as indicated on
>>> Paradis' "Analysis of phylogenetic and evolution with R" (p. 158) thus I
>>> tried to use the package phyloch and its function raxml(). I am using
>>> Linux Ubuntu 14 and I was able to successfully install RAxML on my
>>> machine.
>>> However phyloch is not supported by CRAN and the package as provided by
>>> the author on http://www.christophheibl.de/Rpackages.html cannot be
>>> installed -- or at least I could not using the Software centre.
>>> I found a function on http://www.christophheibl.de/raxml.R that should
>>> be the actual script of the function raxml(). However I do not know how
>>> to implement such function. Shall I just copy it into my script? But
>>> then I will have hundreds of lines of code that will mess with my
>>> script. Can I create a kind of package that I can call from my code? Or
>>> is there another way to send the data to the linux shell and call the
>>> raxml function?
>>> Could anybody help?
>>> Thank you
>>> Luigi
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From info at aghmed.fsnet.co.uk  Mon Dec 29 16:31:15 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Mon, 29 Dec 2014 15:31:15 +0000
Subject: [R] Getting HR from Cox model in R
In-Reply-To: <CAJbUeXaJ0o4S-wvoswvUD9vsSJ6wttySYc3rXHjXhxEMmrzpUg@mail.gmail.com>
References: <CAJbUeXbZWbxa0AJ0KGLsAcyqhMqg70v=KLvGhLKSQX8wR6qrPQ@mail.gmail.com>	<5499A4B2.6060809@aghmed.fsnet.co.uk>
	<CAJbUeXaJ0o4S-wvoswvUD9vsSJ6wttySYc3rXHjXhxEMmrzpUg@mail.gmail.com>
Message-ID: <54A173C3.70007@aghmed.fsnet.co.uk>

Comments in line

On 24/12/2014 22:09, Ruzan Udumyan wrote:
> Dear Michael,
>
> Thank you very much for your reply. The more complete information is as
> follows:
>
> I want to do a mediation analysis following the below-mentioned syntax
> from:
> http://www.biomedcentral.com/content/supplementary/1471-2288-14-9-s1.pdf
>
> I did not define categorical variables as logical variables. I modelled
> them as /*factor.X, factor.Xstar*/, etc. the X variable has 3 levels.
>
> It is all sorted but I am not sure about the last bit: to return the
> values. For example, I could not figure out what unname stands for, and
> whether it is correct to use when variables are modelled as factor.X.
>
> I wrote the syntax as:
>
>   TE2 = exp(sum(coef(cox)[c('factor(X)2', 'factor(Xstar)2')]))   # level
> 2 vs level 1(ref)
>   TE3 = exp(sum(coef(cox)[c('factor(X)3', 'factor(Xstar)3')]))   # level
> 3 vs level 1(ref)
>
>    DE2 = exp(unname(coef(cox)['factor(X)2']))
>    DE3 = exp(unname(coef(cox)['factor(X)3']))
>
>    IE2 = exp(sum(coef(cox)['factor(Xstar)2']))
>    IE3 = exp(sum(coef(cox)['factor(Xstar)3']))
>    PM2 = log(IE2) / log(TE2)
>    PM3 = log(IE3) / log(TE3)
>
>
> Thank you very much for your help.
>
> Wishing you happy holidays,
> Ruzan
>
>
> *The script from the link:*
> doEffectDecomp = function(d)
> {
>   # Step 1: Replicate exposure variable, predict mediator
>   d$TrialTemp = d$Trial
>   MOpti = glm(Opti ~ TrialTemp + Age5 + ECOG + Ascit + Comorb + Histo +
>   Grade, family=binomial(), data=d)
> # Step 2: Replicate data with different exposures for the mediator
>   d1 = d2 = d
>   d1$Med = d1$Trial
>   d2$Med = !d2$Trial
>   newd = rbind(d1, d2)
> # Step 3: Compute weights for the mediator
>   newd$TrialTemp = newd$Trial
>   w = predict(MOpti, newdata=newd, type='response')
>   direct = ifelse(newd$Opti, w, 1-w)
>   newd$TrialTemp = newd$Med
>   w = predict(MOpti, newdata=newd, type='response')
>   indirect = ifelse(newd$Opti, w, 1-w)
>   newd$W = indirect/direct
> # Step 4: Weighted Cox Model
>   cox = coxph(Surv(OS, Status) ~ Trial + Med + Age5 + ECOG + Ascit +
>   Comorb + Histo + Grade, weight=W, data=newd)
> # Return value: Estimates for total, direct, indirect effect
>   TE = exp(sum(coef(cox)[c('TrialTRUE', 'MedTRUE')]))
>   DE = exp(unname(coef(cox)['TrialTRUE']))
>   IE = exp(sum(coef(cox)['MedTRUE']))
>   PM = log(IE) / log(TE)
>   return(c(exp(coef(cox)), TE=TE, DE=DE, IE=IE, PM=PM))
> }
>
> On Tue, Dec 23, 2014 at 6:21 PM, Michael Dewey <info at aghmed.fsnet.co.uk
> <mailto:info at aghmed.fsnet.co.uk>> wrote:
>
>     Inline comments
>
>     On 23/12/2014 09:42, Ruzan Udumyan wrote:
>
>         Dear All,
>
>         I am not familiar with R language well. Could you please help me
>         interpret
>         these commands?:
>
>
>            TE = exp(sum(coef(cox)[c('aTRUE', 'bTRUE')]))   - does it
>         mean exp(coef(a
>         variable) + coef(b variable)) ?
>
>
>     You have not given us much to go on here.
>     I assume if you go
>     coef(cox)
>     you will find elements labelled aTRUE and bTRUE which implies the
>     existence of a logical covariate with values TRUE and FALSE.

You now tell me my assumption was wrong. Presumably you know what you 
are trying to do but we do not and you are not really helping us by 
giving us a load of code to read through with any details of the dataset.

  The
>     author of the code is trying to do what you suggest.
>
>            DE = exp(unname(coef(cox)['aTRUE'])__)  - what is unname for ?
>
>
>     ?unname
>
>         Thank you very much beforehand for your help.
>
>         Wishing you happy holidays,
>         Ruzan
>
>                  [[alternative HTML version deleted]]
>          > PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>     If you post again please do read the message above.
>

Commented, minimal, self-contained, reproducible code was asked for.

>
>
>         -----
>         No virus found in this message.
>         Checked by AVG - www.avg.com <http://www.avg.com>
>         Version: 2015.0.5577 / Virus Database: 4257/8792 - Release Date:
>         12/23/14
>
>
>
>     --
>     Michael
>     http://www.dewey.myzen.co.uk
>
>
> No virus found in this message.
> Checked by AVG - www.avg.com <http://www.avg.com>
> Version: 2015.0.5577 / Virus Database: 4257/8833 - Release Date: 12/29/14
>

-- 
Michael
http://www.dewey.myzen.co.uk


From gdraisma at xs4all.nl  Mon Dec 29 16:32:39 2014
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Mon, 29 Dec 2014 16:32:39 +0100
Subject: [R] attribute and main value
Message-ID: <54A17417.5060007@xs4all.nl>

Just a curiosity question:

In the documentation for the nlm procedure
a find this example of defining a function
with a gradient attribute:
-----------
      f <- function(x, a)
      {
          res <- sum((x-a)^2)
          attr(res, "gradient") <- 2*(x-a)
          res
      }
-----------
I get the gradient with
      attr(f(3,2),"gradient")
but how do I get the function value it self?

Gerrit


From bbolker at gmail.com  Mon Dec 29 16:42:23 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 29 Dec 2014 15:42:23 +0000
Subject: [R] half-logistic distribution
References: <mailman.3.1419591602.11103.r-help@r-project.org>
	<31062c$9hik8m@ironport10.mayo.edu>
Message-ID: <loom.20141229T163027-353@post.gmane.org>

Therneau, Terry M., Ph.D. <therneau <at> mayo.edu> writes:

> 
> 
> On 12/26/2014 05:00 AM, r-help-request <at> r-project.org wrote:
> > i want to analyse survival data using typeI HALF LOGISTIC
> > DISTRIBUTION.how can i go about it?it installed one on R in the
> > survival package didn't include the distribution...or i need a code to
> > use maximum likelihood to estimate the parameter in survival
> > analysis.a typical example of distribution other than that installed
> > in R will help.thanks
> >
 
> I am the author of the survival package, and had never heard of the
> "type I half-logistic" before.  New distributions can be added to
> survreg() if they can be represented as location-scale families; I
> don't think that your distribution can be written in that way.  Look
> at "survival" under the "Task Views" tab (upper left corner) of the
> cran.org web page

  I don't know about 'type I' but based on

http://en.wikipedia.org/wiki/Half-logistic_distribution

   you could try

dhalflogist <- function(x,s,log=FALSE) {
    r <- log(2)-log(s)-x/s-2*log(1+exp(-x/s))
    if (log) r else exp(r)
}
phalflogist <- function(q,s) { (1-exp(-q/s))/(1+exp(-(q/s))) }
rhalflogist <- function(n,s) { abs(rlogis(n,scale=s)) }
set.seed(101)
rr <- rhalflogist(10000,2)
hist(rr,freq=FALSE,breaks=80,col="gray")
curve(dhalflogist(x,2),add=TRUE,col=2,lwd=2)

d <- data.frame(rr)
library("bbmle")
m1 <- mle2(rr~dhalflogist(s=exp(logs)),start=list(logs=0),data=d)

  If you want to fit multiple groups etc., see the 'parameters'
argument of ?mle2


From murdoch.duncan at gmail.com  Mon Dec 29 17:05:09 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Dec 2014 11:05:09 -0500
Subject: [R] attribute and main value
In-Reply-To: <54A17417.5060007@xs4all.nl>
References: <54A17417.5060007@xs4all.nl>
Message-ID: <54A17BB5.5090709@gmail.com>

On 29/12/2014 10:32 AM, Gerrit Draisma wrote:
> Just a curiosity question:
> 
> In the documentation for the nlm procedure
> a find this example of defining a function
> with a gradient attribute:
> -----------
>       f <- function(x, a)
>       {
>           res <- sum((x-a)^2)
>           attr(res, "gradient") <- 2*(x-a)
>           res
>       }
> -----------
> I get the gradient with
>       attr(f(3,2),"gradient")
> but how do I get the function value it self?

value <- f(3,2)
gradient <- attr(value, "gradient")

Duncan Murdoch


From gdraisma at xs4all.nl  Mon Dec 29 17:17:33 2014
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Mon, 29 Dec 2014 17:17:33 +0100
Subject: [R] attribute and main value
In-Reply-To: <54A17BB5.5090709@gmail.com>
References: <54A17417.5060007@xs4all.nl> <54A17BB5.5090709@gmail.com>
Message-ID: <54A17E9D.2020209@xs4all.nl>

Thanks Duncan.

But my question was how to extract
simply the function value from value,
without the gradient attribute?

I see that things like value<2 give the right answer.
I was curiosity. I found now that value[1]
gives strips the attributes from value:
------
 > value
[1] 1
attr(,"gradient")
[1] 2
 > value[1]
[1] 1
------
Is that the way?

Gerrit


On 12/29/2014 05:05 PM, Duncan Murdoch wrote:
> On 29/12/2014 10:32 AM, Gerrit Draisma wrote:
>> Just a curiosity question:
>>
>> In the documentation for the nlm procedure
>> a find this example of defining a function
>> with a gradient attribute:
>> -----------
>>        f <- function(x, a)
>>        {
>>            res <- sum((x-a)^2)
>>            attr(res, "gradient") <- 2*(x-a)
>>            res
>>        }
>> -----------
>> I get the gradient with
>>        attr(f(3,2),"gradient")
>> but how do I get the function value it self?
>
> value <- f(3,2)
> gradient <- attr(value, "gradient")
>
> Duncan Murdoch
>


From wdunlap at tibco.com  Mon Dec 29 17:53:50 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 29 Dec 2014 08:53:50 -0800
Subject: [R] attribute and main value
In-Reply-To: <54A17E9D.2020209@xs4all.nl>
References: <54A17417.5060007@xs4all.nl> <54A17BB5.5090709@gmail.com>
	<54A17E9D.2020209@xs4all.nl>
Message-ID: <CAF8bMcaBJy26iL3rZqCL_j60qd4LcjaAkvC-qFcamA3+-Mu4qA@mail.gmail.com>

as.vector(x) will return x without any attributes and
structure(x, attrA=NULL, attrB=NULL) will return x
without the named attributes.
   > z <- f(1:3, 4)
   > z
   [1] 14
   attr(,"gradient")
   [1] -6 -4 -2
   > as.vector(z)
   [1] 14
   > structure(z, gradient=NULL)
   [1] 14

as.vector is a generic function, so for certain classes
(e.g., factor) it may do more than just strip attributes.
Matrix dimensions are attributes and will be removed by
as.vector.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 29, 2014 at 8:17 AM, Gerrit Draisma <gdraisma at xs4all.nl> wrote:
>
> Thanks Duncan.
>
> But my question was how to extract
> simply the function value from value,
> without the gradient attribute?
>
> I see that things like value<2 give the right answer.
> I was curiosity. I found now that value[1]
> gives strips the attributes from value:
> ------
> > value
> [1] 1
> attr(,"gradient")
> [1] 2
> > value[1]
> [1] 1
> ------
> Is that the way?
>
> Gerrit
>
>
>
> On 12/29/2014 05:05 PM, Duncan Murdoch wrote:
>
>> On 29/12/2014 10:32 AM, Gerrit Draisma wrote:
>>
>>> Just a curiosity question:
>>>
>>> In the documentation for the nlm procedure
>>> a find this example of defining a function
>>> with a gradient attribute:
>>> -----------
>>>        f <- function(x, a)
>>>        {
>>>            res <- sum((x-a)^2)
>>>            attr(res, "gradient") <- 2*(x-a)
>>>            res
>>>        }
>>> -----------
>>> I get the gradient with
>>>        attr(f(3,2),"gradient")
>>> but how do I get the function value it self?
>>>
>>
>> value <- f(3,2)
>> gradient <- attr(value, "gradient")
>>
>> Duncan Murdoch
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gdraisma at xs4all.nl  Mon Dec 29 17:57:40 2014
From: gdraisma at xs4all.nl (Gerrit Draisma)
Date: Mon, 29 Dec 2014 17:57:40 +0100
Subject: [R] attribute and main value
In-Reply-To: <CAF8bMcaBJy26iL3rZqCL_j60qd4LcjaAkvC-qFcamA3+-Mu4qA@mail.gmail.com>
References: <54A17417.5060007@xs4all.nl> <54A17BB5.5090709@gmail.com>
	<54A17E9D.2020209@xs4all.nl>
	<CAF8bMcaBJy26iL3rZqCL_j60qd4LcjaAkvC-qFcamA3+-Mu4qA@mail.gmail.com>
Message-ID: <54A18804.1090905@xs4all.nl>

Thanks Bill,
That is what I was looking for.
Gerrit

On 12/29/2014 05:53 PM, William Dunlap wrote:
> as.vector(x) will return x without any attributes and
> structure(x, attrA=NULL, attrB=NULL) will return x
> without the named attributes.
>     > z <- f(1:3, 4)
>     > z
>     [1] 14
>     attr(,"gradient")
>     [1] -6 -4 -2
>     > as.vector(z)
>     [1] 14
>     > structure(z, gradient=NULL)
>     [1] 14
>
> as.vector is a generic function, so for certain classes
> (e.g., factor) it may do more than just strip attributes.
> Matrix dimensions are attributes and will be removed by
> as.vector.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Mon, Dec 29, 2014 at 8:17 AM, Gerrit Draisma <gdraisma at xs4all.nl
> <mailto:gdraisma at xs4all.nl>> wrote:
>
>     Thanks Duncan.
>
>     But my question was how to extract
>     simply the function value from value,
>     without the gradient attribute?
>
>     I see that things like value<2 give the right answer.
>     I was curiosity. I found now that value[1]
>     gives strips the attributes from value:
>     ------
>      > value
>     [1] 1
>     attr(,"gradient")
>     [1] 2
>      > value[1]
>     [1] 1
>     ------
>     Is that the way?
>
>     Gerrit
>
>
>
>     On 12/29/2014 05:05 PM, Duncan Murdoch wrote:
>
>         On 29/12/2014 10:32 AM, Gerrit Draisma wrote:
>
>             Just a curiosity question:
>
>             In the documentation for the nlm procedure
>             a find this example of defining a function
>             with a gradient attribute:
>             -----------
>                     f <- function(x, a)
>                     {
>                         res <- sum((x-a)^2)
>                         attr(res, "gradient") <- 2*(x-a)
>                         res
>                     }
>             -----------
>             I get the gradient with
>                     attr(f(3,2),"gradient")
>             but how do I get the function value it self?
>
>
>         value <- f(3,2)
>         gradient <- attr(value, "gradient")
>
>         Duncan Murdoch
>
>
>     ________________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/__listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/__posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>


From lterlemez at anadolu.edu.tr  Mon Dec 29 18:04:55 2014
From: lterlemez at anadolu.edu.tr (Levent TERLEMEZ)
Date: Mon, 29 Dec 2014 17:04:55 +0000
Subject: [R] Add labels to my geom_hlines...
Message-ID: <37273DBD29A7A2408A7736A073A9FA3B8CBB9C8F@mb06.porsuk.anadolu.edu.tr>

Dear Users,

Would you pls help me to write a proper geom_text addition to geom_hline of my ggplot2.

This is d.oran

       Tarih  EUROUSD   USDJPY  EUROJPY
1 2005-01-01 1.378200 1.034654 1.425960
2 2005-01-02 1.373217 1.027268 1.410662
3 2005-01-03 1.364489 1.024884 1.398443
4 2005-01-04 1.352766 1.026722 1.388914
5 2005-01-05 1.338793 1.033870 1.384138

this is d.oran.ist

  x_bar    std_sap
EUROUSD 1.3405613 0.08739358
USDJPY  0.9909699 0.13757461
EUROJPY 1.3265161 0.18982005

and both of them are (in function) data frames. Here is my ggplot and i'd like to add texts to left edge of hlines like -3sigma, -2sigma,..., 3sigma.

Here is my ggplot line:

ggplot(data=d.oran)+geom_line(aes(x=Tarih,y=EUROUSD))+geom_hline(data=d.oran.ist,yintercept=x_bar[1]+c(-3:3)*std_sap[1],color=c("red","green","blue","black","blue","green","red"),linetype="dashed",lwd=1)


Thanks in advance.
Levent TERLEMEZ.

	[[alternative HTML version deleted]]


From pushpa.methekar at ge.com  Mon Dec 29 13:37:21 2014
From: pushpa.methekar at ge.com (Methekar, Pushpa (GE Transportation, Non-GE))
Date: Mon, 29 Dec 2014 12:37:21 +0000
Subject: [R] fuction to find outlier
Message-ID: <9C74639432B50946BF93B5350483316103068D@BUDURBPA06.e2k.ad.ge.com>

Hi all, I am stuck on outlier, while doing regression analysis. I done up to modelling ,I got lm model for each y and x.
Now I want to find out outlier in that models. How do I find out outlier and remove them.


for(i in 1:10){
t1=print(outlierTest(fitted.modely1.temp.l ,cutoff=0.05, n.max=1, order=TRUE))
print(outlierTest(fitted.modely2.avg.pcp,cutoff=0.05, n.max=1, order=TRUE))
outlierTest(fitted.modely3.bshc,cutoff=0.05, n.max=1, order=TRUE )

outlierTest(fitted.modely4.bsco ,cutoff=0.05, n.max=1, order=TRUE)

outlierTest(fitted.modely5.gets ,cutoff=0.05, n.max=1, order=TRUE)

outlierTest(fitted.modely6.gimep,cutoff=0.05, n.max=1, order=TRUE )

outlierTest(fitted.modely7.ts ,cutoff=0.05, n.max=1, order=TRUE)

outlierTest(fitted.modely8.imp ,cutoff=0.05, n.max=1, order=TRUE)
outlierTest(fitted.modely9.maf ,cutoff=0.05, n.max=1, order=TRUE)
i<-i+1
}
fix(xsys)

	[[alternative HTML version deleted]]


From kentasuzuki325 at gmail.com  Mon Dec 29 14:30:40 2014
From: kentasuzuki325 at gmail.com (Suzuki Kenta)
Date: Mon, 29 Dec 2014 22:30:40 +0900
Subject: [R] Some questions on R
Message-ID: <CAHn-WnmfKRDsCLp7wSUEOm3dqh24O8JMJrL90eH=HVEHeLqy6A@mail.gmail.com>

To whom it may concern

My name is Kenta Suzuki. Today I subscribed the R-help. I do not know about
this R-help in detail but I send this e-mail since I have some trouble on
programming R. When I type help() in general id dose not work properly. For
instance, when I type,  help("plot")  in R, it shows; Error in file(out,
"wt") : cannot open the connection on the Internet. Beside the problem,
when I try to install packages like rgl, it always shows; Warning in
install.packages("rgl") : 'lib = "C:/Program Files/R/R-3.1.2/library"' is
not writable Error in install.packages("rgl") : unable to create
?C:\Users\<U+5065><U+592A>\Documents/R/win-library/3.1? In addition:
Warning message: In dir.create(userdir, recursive = TRUE) : cannot create
dir 'C:\Users\<U+5065><U+592A>', reason 'Invalid argument'

How can I fix these problems? I would be great if you give me the
solutions.

Yours Sincerely,
Kenta Suzuki

	[[alternative HTML version deleted]]


From pbruneau at gmail.com  Mon Dec 29 19:02:57 2014
From: pbruneau at gmail.com (Pierrick Bruneau)
Date: Mon, 29 Dec 2014 19:02:57 +0100
Subject: [R] Difference between eigs() and eigen()
Message-ID: <CAF_q7hW52M=Vpk527vesJYkW-ekopErzn9x00EzZ5VhLSYP4BA@mail.gmail.com>

Dear R users and contributors,

I recently observed a difference between the outputs of the classic
eigen() function, and the Arnoldi variant eigs() that extracts only
the few first eigenpairs. Here is some sample code illustrating the
problem:

library(rARPACK)
library(speccalt)
set.seed(1)

# compute kernel matrix from rows of synth5
# then its Laplacian
kern <- local.rbfdot(synth5)
diag(kern) <- 0
deg <- sapply(1:(dim(synth5)[1]), function(i) {
return(sum(kern[i,]))
})
L <- diag(1/sqrt(deg)) %*% kern %*% diag(1/sqrt(deg))

eig1 <- eigs(L, 6)
eig2 <- eigen(L, symmetric=TRUE)

eig1$values then reads:
1.0000000 1.0000000 0.9993805 0.9992561 0.9985084 0.9975311

whereas eig2$values reads:
1.0000000 1.0000000 1.0000000 1.0000000 0.9993805 0.9992561
which is the correct result (eigenvalue 1 has multiplicity 4 in that example).

I guess there is an issue between Arnoldi methods and eigenvalues with
multiplicities greater than 1 (indeed at the end of the series the
unique eigenvals look identical), but as the problem is not documented
in the package PDF, I'm quite unclear if this is
implementation-specific or Arnoldi-general... The issue is quite
important in my case, as the associated eigenvectors then differ quite
significantly, and this impacts negatively my further operations.

I guess the next step is to dig into the mathematical literature, but
before this I wondered if someone already encountered this issue?

Any help would be appreciated,
Pierrick


From albmont at centroin.com.br  Mon Dec 29 19:52:05 2014
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Mon, 29 Dec 2014 16:52:05 -0200
Subject: [R] Memory hungry routines
Message-ID: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>

Is there any way to detect which calls are consuming memory?

I run a program whose global variables take up about 50 Megabytes of
memory, but when I monitor the progress of the program it seems to
allocating 150 Megabytes of memory, with peaks of up to 2 Gigabytes.

I know that the global variables aren't "copied" many times by the
routines, but I suspect something weird must be happening.

Alberto Monteiro

PS: the lines, below, count the memory allocated to all global
variables, probably it could be adapted to track the local variables:

y <- ls(pat="")   # get all names of the variables
z <- rep(0, length(y))  # create array of sizes
for (i in 1:length(y)) z[i] <- object.size(get(y[i]))  # loop: get all
sizes (in bytes) of the variables
# BTW, is there any way to vectorialize the above loop?
xix <- sort.int(z, index.return = TRUE)  # sort the sizes
y <- y[xix$ix]  # apply the sort to the variables
z <- z[xix$ix]  # apply the sort to the sizes
y <- c(y, "total")  # add a totalizator
z <- c(z, sum(z))  # sum them all
cbind(y, z)  # ugly way to list them


From ligges at statistik.tu-dortmund.de  Mon Dec 29 19:59:15 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 29 Dec 2014 19:59:15 +0100
Subject: [R] Difference between eigs() and eigen()
In-Reply-To: <CAF_q7hW52M=Vpk527vesJYkW-ekopErzn9x00EzZ5VhLSYP4BA@mail.gmail.com>
References: <CAF_q7hW52M=Vpk527vesJYkW-ekopErzn9x00EzZ5VhLSYP4BA@mail.gmail.com>
Message-ID: <54A1A483.7010005@statistik.tu-dortmund.de>

eigs() is from a contributed package. No idea what it is about, but my 
guess is these are actually numerical differences coming from different 
algorithms used to calculate the eigenvalues.
For details, please ask the author of the corresponding contributed package.

Best,
Uwe Ligges


On 29.12.2014 19:02, Pierrick Bruneau wrote:
> Dear R users and contributors,
>
> I recently observed a difference between the outputs of the classic
> eigen() function, and the Arnoldi variant eigs() that extracts only
> the few first eigenpairs. Here is some sample code illustrating the
> problem:
>
> library(rARPACK)
> library(speccalt)
> set.seed(1)
>
> # compute kernel matrix from rows of synth5
> # then its Laplacian
> kern <- local.rbfdot(synth5)
> diag(kern) <- 0
> deg <- sapply(1:(dim(synth5)[1]), function(i) {
> return(sum(kern[i,]))
> })
> L <- diag(1/sqrt(deg)) %*% kern %*% diag(1/sqrt(deg))
>
> eig1 <- eigs(L, 6)
> eig2 <- eigen(L, symmetric=TRUE)
>
> eig1$values then reads:
> 1.0000000 1.0000000 0.9993805 0.9992561 0.9985084 0.9975311
>
> whereas eig2$values reads:
> 1.0000000 1.0000000 1.0000000 1.0000000 0.9993805 0.9992561
> which is the correct result (eigenvalue 1 has multiplicity 4 in that example).
>
> I guess there is an issue between Arnoldi methods and eigenvalues with
> multiplicities greater than 1 (indeed at the end of the series the
> unique eigenvals look identical), but as the problem is not documented
> in the package PDF, I'm quite unclear if this is
> implementation-specific or Arnoldi-general... The issue is quite
> important in my case, as the associated eigenvectors then differ quite
> significantly, and this impacts negatively my further operations.
>
> I guess the next step is to dig into the mathematical literature, but
> before this I wondered if someone already encountered this issue?
>
> Any help would be appreciated,
> Pierrick
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Dec 29 20:32:50 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 29 Dec 2014 14:32:50 -0500
Subject: [R] Memory hungry routines
In-Reply-To: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
References: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
Message-ID: <54A1AC62.7080801@gmail.com>

On 29/12/2014 1:52 PM, ALBERTO VIEIRA FERREIRA MONTEIRO wrote:
> Is there any way to detect which calls are consuming memory?

The Rprofmem() function can do this, but you need to build R to enable
it.    Rprof() does a more limited version of the same thing if run with
memory.profiling = TRUE.

Duncan Murdoch

> 
> I run a program whose global variables take up about 50 Megabytes of
> memory, but when I monitor the progress of the program it seems to
> allocating 150 Megabytes of memory, with peaks of up to 2 Gigabytes.
> 
> I know that the global variables aren't "copied" many times by the
> routines, but I suspect something weird must be happening.
> 
> Alberto Monteiro
> 
> PS: the lines, below, count the memory allocated to all global
> variables, probably it could be adapted to track the local variables:
> 
> y <- ls(pat="")   # get all names of the variables
> z <- rep(0, length(y))  # create array of sizes
> for (i in 1:length(y)) z[i] <- object.size(get(y[i]))  # loop: get all
> sizes (in bytes) of the variables
> # BTW, is there any way to vectorialize the above loop?
> xix <- sort.int(z, index.return = TRUE)  # sort the sizes
> y <- y[xix$ix]  # apply the sort to the variables
> z <- z[xix$ix]  # apply the sort to the sizes
> y <- c(y, "total")  # add a totalizator
> z <- c(z, sum(z))  # sum them all
> cbind(y, z)  # ugly way to list them
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jfox at mcmaster.ca  Mon Dec 29 20:39:52 2014
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 29 Dec 2014 14:39:52 -0500
Subject: [R] fuction to find outlier
In-Reply-To: <9C74639432B50946BF93B5350483316103068D@BUDURBPA06.e2k.ad.ge.com>
References: <9C74639432B50946BF93B5350483316103068D@BUDURBPA06.e2k.ad.ge.com>
Message-ID: <000701d0239f$375d54a0$a617fde0$@mcmaster.ca>

Dear Pushpa Methekar,

This apparently uses the outlierTest() function in the car package. I'm
afraid that I find your code incomprehensible and there's not enough
information here to reproduce what you've done. You're looping over the
index i in 1:10, explicitly incrementing the loop index at the end of the
loop (which, thankfully, will have no effect), and doing the same things in
each iteration -- i.e., repeatedly executing several commands without
modification. All this seems terribly confused and not clearly related to
locating and dealing with outliers. 

Furthermore, it's not clear to me that what you propose is sensible -- to
delete outliers after performing statistical tests, in each case for a
single outlier, apparently mechanically and without investigating what's
going on in each case. It would probably be a good idea to consult a
competent statistician to help you decide how to proceed.

All that said, to answer your question directly, probably the easiest way to
remove an observation from a fitted model is to use update() with the subset
argument. For example model.1 <- update(model, subset = -6) would remove
case 6 from model and assign the result to model.1.

Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Methekar, Pushpa (GE Transportation, Non-GE)
> Sent: Monday, December 29, 2014 7:37 AM
> To: r-help at r-project.org
> Subject: [R] fuction to find outlier
> 
> Hi all, I am stuck on outlier, while doing regression analysis. I done
> up to modelling ,I got lm model for each y and x.
> Now I want to find out outlier in that models. How do I find out outlier
> and remove them.
> 
> 
> for(i in 1:10){
> t1=print(outlierTest(fitted.modely1.temp.l ,cutoff=0.05, n.max=1,
> order=TRUE))
> print(outlierTest(fitted.modely2.avg.pcp,cutoff=0.05, n.max=1,
> order=TRUE))
> outlierTest(fitted.modely3.bshc,cutoff=0.05, n.max=1, order=TRUE )
> 
> outlierTest(fitted.modely4.bsco ,cutoff=0.05, n.max=1, order=TRUE)
> 
> outlierTest(fitted.modely5.gets ,cutoff=0.05, n.max=1, order=TRUE)
> 
> outlierTest(fitted.modely6.gimep,cutoff=0.05, n.max=1, order=TRUE )
> 
> outlierTest(fitted.modely7.ts ,cutoff=0.05, n.max=1, order=TRUE)
> 
> outlierTest(fitted.modely8.imp ,cutoff=0.05, n.max=1, order=TRUE)
> outlierTest(fitted.modely9.maf ,cutoff=0.05, n.max=1, order=TRUE)
> i<-i+1
> }
> fix(xsys)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From huseyin.karagul at gmail.com  Mon Dec 29 20:46:35 2014
From: huseyin.karagul at gmail.com (Bros)
Date: Mon, 29 Dec 2014 11:46:35 -0800 (PST)
Subject: [R] Installation Help
In-Reply-To: <1419804761301-4701164.post@n4.nabble.com>
References: <1419687028093-4701143.post@n4.nabble.com>
	<1419804761301-4701164.post@n4.nabble.com>
Message-ID: <000c01d023a0$3c09d040$b41d70c0$@gmail.com>

I guess I skipped an option during installation. I removed the program now.

 

Do u think I should choose something else than administrator?

 

From: emorway [via R] [mailto:ml-node+s789695n4701164h40 at n4.nabble.com] 
Sent: Monday, December 29, 2014 12:13 AM
To: Bros
Subject: Re: Installation Help

 

do you have write permissions to your c: drive?  If you're on a machine that
requires administrative privileges, it might only allow you to write to
c:/users.   

  _____  

If you reply to this email, your message will be added to the discussion
below:

http://r.789695.n4.nabble.com/Installation-Help-tp4701143p4701164.html 

To unsubscribe from Installation Help, click here
<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by
_code&node=4701143&code=aHVzZXlpbi5rYXJhZ3VsQGdtYWlsLmNvbXw0NzAxMTQzfDEyNDE4
NzE1MjE=> .
 
<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&i
d=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamesp
ace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNa
mespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%
21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml> NAML 



---
This email has been checked for viruses by Avast antivirus software.





--
View this message in context: http://r.789695.n4.nabble.com/Installation-Help-tp4701143p4701190.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Dec 29 21:16:22 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Dec 2014 12:16:22 -0800
Subject: [R] Installation Help
In-Reply-To: <000c01d023a0$3c09d040$b41d70c0$@gmail.com>
References: <1419687028093-4701143.post@n4.nabble.com>
	<1419804761301-4701164.post@n4.nabble.com>
	<000c01d023a0$3c09d040$b41d70c0$@gmail.com>
Message-ID: <C48A46DE-746A-49C6-A705-D90B3819C81B@dcn.davis.CA.us>

Let windows prompt you for your password when it is needed... don't run anything as  Administrator directly unless you are prepared to fix the problems that occur.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 29, 2014 11:46:35 AM PST, Bros <huseyin.karagul at gmail.com> wrote:
>I guess I skipped an option during installation. I removed the program
>now.
>
> 
>
>Do u think I should choose something else than administrator?
>
> 
>
>From: emorway [via R] [mailto:ml-node+s789695n4701164h40 at n4.nabble.com]
>
>Sent: Monday, December 29, 2014 12:13 AM
>To: Bros
>Subject: Re: Installation Help
>
> 
>
>do you have write permissions to your c: drive?  If you're on a machine
>that
>requires administrative privileges, it might only allow you to write to
>c:/users.   
>
>  _____  
>
>If you reply to this email, your message will be added to the
>discussion
>below:
>
>http://r.789695.n4.nabble.com/Installation-Help-tp4701143p4701164.html 
>
>To unsubscribe from Installation Help, click here
><http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by
>_code&node=4701143&code=aHVzZXlpbi5rYXJhZ3VsQGdtYWlsLmNvbXw0NzAxMTQzfDEyNDE4
>NzE1MjE=> .
> 
><http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&i
>d=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamesp
>ace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNa
>mespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%
>21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml> NAML 
>
>
>
>---
>This email has been checked for viruses by Avast antivirus software.
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Installation-Help-tp4701143p4701190.html
>Sent from the R help mailing list archive at Nabble.com.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Dec 29 23:46:47 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 29 Dec 2014 15:46:47 -0700
Subject: [R] fuction to find outlier
In-Reply-To: <000701d0239f$375d54a0$a617fde0$@mcmaster.ca>
References: <9C74639432B50946BF93B5350483316103068D@BUDURBPA06.e2k.ad.ge.com>
	<000701d0239f$375d54a0$a617fde0$@mcmaster.ca>
Message-ID: <CAFEqCdywfOCuqrcOHFCyVyXR5d65A5HcWO3m7ppVss4g7H7OdA@mail.gmail.com>

Pushpa,

To extend John Fox's answer a little.

Look at the "outliers" dataset in the TeachingDemos package, see
"?outliers" and run the examples on that help page.  Then ask yourself if
you are comfortable with the automatic outlier removal shown in the example.

On Mon, Dec 29, 2014 at 12:39 PM, John Fox <jfox at mcmaster.ca> wrote:

> Dear Pushpa Methekar,
>
> This apparently uses the outlierTest() function in the car package. I'm
> afraid that I find your code incomprehensible and there's not enough
> information here to reproduce what you've done. You're looping over the
> index i in 1:10, explicitly incrementing the loop index at the end of the
> loop (which, thankfully, will have no effect), and doing the same things in
> each iteration -- i.e., repeatedly executing several commands without
> modification. All this seems terribly confused and not clearly related to
> locating and dealing with outliers.
>
> Furthermore, it's not clear to me that what you propose is sensible -- to
> delete outliers after performing statistical tests, in each case for a
> single outlier, apparently mechanically and without investigating what's
> going on in each case. It would probably be a good idea to consult a
> competent statistician to help you decide how to proceed.
>
> All that said, to answer your question directly, probably the easiest way
> to
> remove an observation from a fitted model is to use update() with the
> subset
> argument. For example model.1 <- update(model, subset = -6) would remove
> case 6 from model and assign the result to model.1.
>
> Best,
>  John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > Methekar, Pushpa (GE Transportation, Non-GE)
> > Sent: Monday, December 29, 2014 7:37 AM
> > To: r-help at r-project.org
> > Subject: [R] fuction to find outlier
> >
> > Hi all, I am stuck on outlier, while doing regression analysis. I done
> > up to modelling ,I got lm model for each y and x.
> > Now I want to find out outlier in that models. How do I find out outlier
> > and remove them.
> >
> >
> > for(i in 1:10){
> > t1=print(outlierTest(fitted.modely1.temp.l ,cutoff=0.05, n.max=1,
> > order=TRUE))
> > print(outlierTest(fitted.modely2.avg.pcp,cutoff=0.05, n.max=1,
> > order=TRUE))
> > outlierTest(fitted.modely3.bshc,cutoff=0.05, n.max=1, order=TRUE )
> >
> > outlierTest(fitted.modely4.bsco ,cutoff=0.05, n.max=1, order=TRUE)
> >
> > outlierTest(fitted.modely5.gets ,cutoff=0.05, n.max=1, order=TRUE)
> >
> > outlierTest(fitted.modely6.gimep,cutoff=0.05, n.max=1, order=TRUE )
> >
> > outlierTest(fitted.modely7.ts ,cutoff=0.05, n.max=1, order=TRUE)
> >
> > outlierTest(fitted.modely8.imp ,cutoff=0.05, n.max=1, order=TRUE)
> > outlierTest(fitted.modely9.maf ,cutoff=0.05, n.max=1, order=TRUE)
> > i<-i+1
> > }
> > fix(xsys)
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue Dec 30 01:22:33 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 30 Dec 2014 13:22:33 +1300
Subject: [R] Memory hungry routines
In-Reply-To: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
References: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
Message-ID: <CABdHhvEY9XQNMakeSLcd=W_-bkzx+RjbhF3Aj0m7FbosnUrosw@mail.gmail.com>

You might find the advice at http://adv-r.had.co.nz/memory.html helpful.
Hadley

On Tue, Dec 30, 2014 at 7:52 AM, ALBERTO VIEIRA FERREIRA MONTEIRO
<albmont at centroin.com.br> wrote:
> Is there any way to detect which calls are consuming memory?
>
> I run a program whose global variables take up about 50 Megabytes of
> memory, but when I monitor the progress of the program it seems to
> allocating 150 Megabytes of memory, with peaks of up to 2 Gigabytes.
>
> I know that the global variables aren't "copied" many times by the
> routines, but I suspect something weird must be happening.
>
> Alberto Monteiro
>
> PS: the lines, below, count the memory allocated to all global
> variables, probably it could be adapted to track the local variables:
>
> y <- ls(pat="")   # get all names of the variables
> z <- rep(0, length(y))  # create array of sizes
> for (i in 1:length(y)) z[i] <- object.size(get(y[i]))  # loop: get all
> sizes (in bytes) of the variables
> # BTW, is there any way to vectorialize the above loop?
> xix <- sort.int(z, index.return = TRUE)  # sort the sizes
> y <- y[xix$ix]  # apply the sort to the variables
> z <- z[xix$ix]  # apply the sort to the sizes
> y <- c(y, "total")  # add a totalizator
> z <- c(z, sum(z))  # sum them all
> cbind(y, z)  # ugly way to list them
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From hb at biostat.ucsf.edu  Tue Dec 30 01:29:12 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 29 Dec 2014 16:29:12 -0800
Subject: [R] Memory hungry routines
In-Reply-To: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
References: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
Message-ID: <CAFDcVCRjFL4ghTy1nU_E2DAhRuEBWziBjaQQC5=LqNe7rBjw=w@mail.gmail.com>

On Mon, Dec 29, 2014 at 10:52 AM, ALBERTO VIEIRA FERREIRA MONTEIRO
<albmont at centroin.com.br> wrote:
> Is there any way to detect which calls are consuming memory?
>
> I run a program whose global variables take up about 50 Megabytes of
> memory, but when I monitor the progress of the program it seems to
> allocating 150 Megabytes of memory, with peaks of up to 2 Gigabytes.
>
> I know that the global variables aren't "copied" many times by the
> routines, but I suspect something weird must be happening.
>
> Alberto Monteiro
>
> PS: the lines, below, count the memory allocated to all global
> variables, probably it could be adapted to track the local variables:
>
> y <- ls(pat="")   # get all names of the variables
> z <- rep(0, length(y))  # create array of sizes
> for (i in 1:length(y)) z[i] <- object.size(get(y[i]))  # loop: get all
> sizes (in bytes) of the variables
> # BTW, is there any way to vectorialize the above loop?
> xix <- sort.int(z, index.return = TRUE)  # sort the sizes
> y <- y[xix$ix]  # apply the sort to the variables
> z <- z[xix$ix]  # apply the sort to the sizes
> y <- c(y, "total")  # add a totalizator
> z <- c(z, sum(z))  # sum them all
> cbind(y, z)  # ugly way to list them

Duncan already suggested Rprofmem().  For a neat interface to that,
see also lineprof package.

Common memory hogs are cbind(), rbind() and other ways of
incrementally building up objects.  These can often be avoided by
pre-allocating the final object up front and populating it as you go.
Another source of unnecessary memory duplication is coercion of data
types, e.g. allocating an integer matrix but populating it with
doubles.  A related mistake is to use matrix(nrow, ncol) for allocate
matrices that will hold numeric values.  That is actually doing
matrix(NA, nrow, ncol), which becomes a *logical* matrix, which will
be coerced (involving copying and large memory allocation) the first
thing as soon as it get's populated with a numeric value. One should
have used matrix(NA_real_, nrow, ncol) here.

For listing objects, their sizes and more, you can use ll() in the
R.oo package which returns a data.frame, e.g.

> example(iris)
> a <- 1:1e6
> R.oo::ll()
  member data.class dimension objectSize
1      a    numeric   1000000    4000040
2   dni3       list         3        600
3     ii data.frame  c(150,5)       7088
4   iris data.frame  c(150,5)       7088

> R.oo::ll(sortBy="objectSize")
  member data.class dimension objectSize
2   dni3       list         3        600
3     ii data.frame  c(150,5)       7088
4   iris data.frame  c(150,5)       7088
1      a    numeric   1000000    4000040

> tbl <- R.oo::ll()
> tbl <- tbl[order(tbl$objectSize, decreasing=TRUE),]
> tbl
  member data.class dimension objectSize
1      a    numeric   1000000    4000040
3     ii data.frame  c(150,5)       7088
4   iris data.frame  c(150,5)       7088
5   objs data.frame    c(4,4)       2760
2   dni3       list         3        600
> sum(tbl$objectSize)
[1] 4017576


/Henrik

>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marongiu.luigi at gmail.com  Tue Dec 30 09:38:04 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Tue, 30 Dec 2014 08:38:04 +0000
Subject: [R] RAxML using R
In-Reply-To: <CA+vqiLHbF8jjDmKQ1rkFTG9m4TM6e+sXm6ZHJ1gxwbar=LLq1Q@mail.gmail.com>
References: <54A08DA3.6010209@gmail.com> <54A1389B.9030000@sapo.pt>
	<54A163D4.6010704@gmail.com>
	<CA+vqiLHbF8jjDmKQ1rkFTG9m4TM6e+sXm6ZHJ1gxwbar=LLq1Q@mail.gmail.com>
Message-ID: <54A2646C.3070300@gmail.com>

Dear Ista,
that sos package is certainly something, didn't know there was one!
It turned out that ips is written by the same person who wrote phyloch, 
so the latter must have been an alpha version of the former. The raxml 
function worked from ips worked fine -- just a matter of defining the 
parameters now -- and the installation was smooth, although I had to 
pre-install the ubuntu package |libxml2-dev|.
Thank you for your help,
Luigi


On 29/12/14 15:07, Ista Zahn wrote:
> Let's step back for a moment and look at the larger picture. There are
> real advantages to using packages on CRAN, including convenient
> installation, updates, etc., so let's see if we can find a package on
> cran that does what we want:
>
> install.packages("sos")
> library(sos)
> findFn("raxml")
>
> This suggests that the ips package does what we want, so let's install
> it and test it out:
>
> install.packages("ips")
> library(ips)
> example(raxml)
>
> If for some reason this does not do what you want, and you really need
> to install packages outside the standard R package repositories, the
> devtools package will make this easier:
>
> library(devtools)
> nstall_url("http://www.christophheibl.de/phyloch_1.5-5.tar.gz")
> library(phyloch)
> example(raxml)
>
> HTH,
> Ista
>
> On Mon, Dec 29, 2014 at 9:23 AM, Luigi Marongiu
> <marongiu.luigi at gmail.com> wrote:
>> Dear Rui,
>> thanks for the reply. I tried it but there were serious problems with the
>> function itself: I can't use it as is because there were different error
>> messages according to the parameters passed to it.
>> Such function has to be re-written on purpose or I should call the RAxML
>> function from Linux Shell with some kind of interface.
>> Best regards
>> Luigi
>>
>>
>>
>> On 29/12/14 11:18, Rui Barradas wrote:
>>> Hello,
>>>
>>> You can put the code of that function in a separate file, say "raxml.R"
>>> and then use source("raxml.R"). See the help page ?source.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 28-12-2014 23:09, Luigi Marongiu escreveu:
>>>> Dear all,
>>>> I would like to run RAxML for phylogenetic analysis as indicated on
>>>> Paradis' "Analysis of phylogenetic and evolution with R" (p. 158) thus I
>>>> tried to use the package phyloch and its function raxml(). I am using
>>>> Linux Ubuntu 14 and I was able to successfully install RAxML on my
>>>> machine.
>>>> However phyloch is not supported by CRAN and the package as provided by
>>>> the author on http://www.christophheibl.de/Rpackages.html cannot be
>>>> installed -- or at least I could not using the Software centre.
>>>> I found a function on http://www.christophheibl.de/raxml.R that should
>>>> be the actual script of the function raxml(). However I do not know how
>>>> to implement such function. Shall I just copy it into my script? But
>>>> then I will have hundreds of lines of code that will mess with my
>>>> script. Can I create a kind of package that I can call from my code? Or
>>>> is there another way to send the data to the linux shell and call the
>>>> raxml function?
>>>> Could anybody help?
>>>> Thank you
>>>> Luigi
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From kvirt at tanucoo.com  Mon Dec 29 22:05:54 2014
From: kvirt at tanucoo.com (Subba Rao)
Date: Mon, 29 Dec 2014 22:05:54 +0100
Subject: [R] online classes/certifications?
Message-ID: <54A1C232.6080208@tanucoo.com>

Hi,

Are there any good online classes/certifications for R programming and
Data Analytics?

Thank you in advance for any information.

Subba Rao


From daniel.gabrieli at gmail.com  Mon Dec 29 22:41:59 2014
From: daniel.gabrieli at gmail.com (Daniel Gabrieli)
Date: Mon, 29 Dec 2014 16:41:59 -0500
Subject: [R] Chaining multiple replacement functions in R
Message-ID: <CAPpYv=YkS2NoOrcYUeFbzQKkct++gs6m2H=AU=hWBtoesHHyXw@mail.gmail.com>

I cross posted this on Stack Overflow:
http://stackoverflow.com/questions/27694466/chaining-multiple-replacement-functions-in-r


I am using R to work with a large JS object (using the library rjsonio). As
such, I have a lot of nested lists, which are getting somewhat cumbersome
to work with. I have a simplified example below. I am trying to work with
this object by creating some form of ?getter? and ?setter? functions. After
looking around, I have found a pretty nice ?getter? function that recurses
through the object and returns the value for the first matching label. This
is especially great because it lends itself to chaining functions together.
However, I can not figure out a way to get the same effect for a ?setter?
function. Any thoughts on how to create a ?setter? function that can be
chained together in a similar fashion?

#example, simplified, object
app = list(
  1,
  2,
  d=list(a=123,
         b=456,
         list(
           FirstKey=list(attr1='good stuff', attr2=12345),
           SecondKey=list(attr1='also good stuff', attr2=4321)
           )
         )
  )


#Return a function that returns the value
#associated with first label that matches 'name'
getByName <- function(name){
  rmatch <- function(x) {
    pos <- match(name, names(x))
    if (!is.na(pos))
      return(x[[pos]])
    for (el in x) {
      if (class(el) == "list") {
        out <- Recall(el)
        if (!is.null(out)) return(out)
      }
    }
  }
  rmatch
}

getFirstKey <- getByName("FirstKey")
getAttr1 <- getByName("attr1")
getAttr2 <- getByName("attr2")

#I like that I can chain these functions together
getAttr1(getFirstKey(app))
getAttr2(getFirstKey(app))

# I would like to be able to do something like this
# But this won't work
###    getAttr1(getFirstKey(app)) <- 9876

# This does work,,, but I loose the ability to chain functions together
# Closure around a replacement function
setterKeyAttr <- function(keyName, attr){
  function(x, value){
    x$d[[3]][[keyName]][[attr]] <- value
    x
  }
}

`setFirstKeyAttr2<-` <- setterKeyAttr("FirstKey", "attr2")
setFirstKeyAttr2(app) <- 22222
#check the answer is correct
getAttr2(getFirstKey(app))



references:

http://stackoverflow.com/questions/23124096/r-decorator-to-change-both-input-and-output

http://r.789695.n4.nabble.com/How-to-get-a-specific-named-element-in-a-nested-list-td3037430.html

http://adv-r.had.co.nz/Functions.html

	[[alternative HTML version deleted]]


From pushpa.methekar at ge.com  Tue Dec 30 09:43:59 2014
From: pushpa.methekar at ge.com (Methekar, Pushpa (GE Transportation, Non-GE))
Date: Tue, 30 Dec 2014 08:43:59 +0000
Subject: [R] to create a fuction for removing outlier
Message-ID: <9C74639432B50946BF93B535048331610306BF@BUDURBPA06.e2k.ad.ge.com>

Hi all,
Thanks for your support. sorry for inconvenience cause due to lack of information. here is my all  r- program .


#### read in data
raw=read.csv(file.choose(),header = T, stringsAsFactors=FALSE)

str(raw)

####conversion from factor to numeric of xs
raw$Engine.Speed <- as.numeric(raw$Engine.Speed)
raw$Engine.Power<- as.numeric(raw$Engine.Power)
raw$Diesel.LHV <- as.numeric(raw$Diesel.LHV)
raw$NG.LHV <- as.numeric(raw$NG.LHV)
raw$Compressor.Inlet.Temperature <- as.numeric(raw$Compressor.Inlet.Temperature)
raw$Int.Mfld.Temp<- as.numeric(raw$Int.Mfld.Temp)
raw$Cmd.Advance.Angle<- as.numeric(raw$Cmd.Advance.Angle)
raw$Cmd.Fuel.Rail.Press.Manual<- as.numeric(raw$Cmd.Fuel.Rail.Press.Manual)
raw$X..NG.by.Energy<- as.numeric(sub("%","",raw$X..NG.by.Energy))/100


####conversion from factor to numeric of Ys
raw$Pre.Turb.Temp.L <- as.numeric(raw$Pre.Turb.Temp.L)
raw$Avg.PCP <- as.numeric(raw$Avg.PCP)
raw$BSHC <- as.numeric(raw$BSHC)
raw$BSCO <- as.numeric(raw$BSCO)
raw$GETS.cBSNOx <- as.numeric(raw$GETS.cBSNOx)
raw$Avg.COV.GIMEP <- as.numeric(raw$Avg.COV.GIMEP)
raw$Intake.Manifold.Pressure <- as.numeric(raw$Intake.Manifold.Pressure)
raw$Emiss..1..EPA.MAF..Dry. <- as.numeric(sub(",","",raw$Emiss..1..EPA.MAF..Dry.))
raw$Turbo.Speed <- as.numeric(raw$Turbo.Speed)


#### create a matrix plot of scatter plot
xs=raw[c("Engine.Speed","X..NG.by.Energy","Int.Mfld.Temp","Cmd.Advance.Angle","Engine.Power","Cmd.Fuel.Rail.Press.Manual","Compressor.Inlet.Temperature","Diesel.LHV","NG.LHV")]

ys=raw[c("Pre.Turb.Temp.L","Avg.PCP","BSHC","BSCO","GETS.cBSNOx","Avg.COV.GIMEP","Turbo.Speed","Intake.Manifold.Pressure","Emiss..1..EPA.MAF..Dry.")]
pairs(xs,main="x's")
pairs(ys,main="y's")

### calculate correlation coefficient
xs[is.na(xs)] <- 0 #replace all NA with 0
cor(xs)
ys[is.na(ys)] <- 0 #replace all NA with 0
cor(ys)
cor(xs,ys,method = "spearman")
pairs(xs,ys)
save.image(file="plotting.RData")


## make data frame of x's and y's
xsys=data.frame(xs,ys)

library(MASS)
#### first order multiple linear regression
fitted.modely1.temp.l <- rlm( Pre.Turb.Temp.L~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely2.avg.pcp <- rlm( Avg.PCP~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely3.bshc <- rlm( BSHC~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely4.bsco <- rlm(BSCO~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely5.gets <- rlm(GETS.cBSNOx~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely6.gimep <- rlm(Avg.COV.GIMEP~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely7.ts <- rlm( Turbo.Speed ~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely8.imp <- rlm(Intake.Manifold.Pressure ~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)

fitted.modely9.maf <- rlm( Emiss..1..EPA.MAF..Dry. ~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=xsys)



#### comlete second order multiple linear regression
secfitted.modely1.temp.l<-lm(Pre.Turb.Temp.L ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                             +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                             +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                             +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                             +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)

secfitted.modely2.avg.pcp<-lm(Avg.PCP ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                              +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                              +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                              +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                              +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                              +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                              +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                              +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                              +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                              +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                              +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)

secfitted.modely3.bshc<-lm( BSHC ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                           +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                            +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                            +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                            +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)


secfitted.modely4.bsco<-lm( BSCO ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                            +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                            +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                            +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                            +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)



secfitted.modely5.gets<-lm( GETS.cBSNOx ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                            +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                            +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                            +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                            +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                            +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)



secfitted.modely6.gimep<-lm( Avg.COV.GIMEP ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                             +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                             +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                             +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                             +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                             +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)

secfitted.modely7.ts<-lm( Turbo.Speed ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                          +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                          +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                          +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                          +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)



secfitted.modely8.imp<-lm( Intake.Manifold.Pressure ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                           +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                           +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                           +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                           +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                           +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                           +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                           +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                           +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                           +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                           +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)


secfitted.modely9.maf<-lm(Emiss..1..EPA.MAF..Dry.~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Manual,2)
                          +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
                          +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Speed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV)
                          +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV+NG.LHV)
                          +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed+NG.LHV)
                          +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engine.Speed),data=xsys)


####stepwise forward regression for first order

step(fitted.modely1.temp.l,direction="forward")
step(fitted.modely2.avg.pcp,direction="forward")
step(fitted.modely3.bshc,direction="forward")
step(fitted.modely4.bsco,direction="forward")
step(fitted.modely5.gets,direction="forward")
step(fitted.modely6.gimep,direction="forward")
step(fitted.modely7.ts,direction="forward")
step(fitted.modely8.imp,direction="forward")
step(fitted.modely9.maf,direction="forward")


step(fitted.modely1.temp.l,direction="backward")
step(fitted.modely2.avg.pcp,direction="backward")
step(fitted.modely3.bshc,direction="backward")
step(fitted.modely4.bsco,direction="backward")
step(fitted.modely5.gets,direction="backward")
step(fitted.modely6.gimep,direction="backward")
step(fitted.modely7.ts,direction="backward")
step(fitted.modely8.imp,direction="backward")
step(fitted.modely9.maf,direction="backward")


now after this step I want to find out outliers in each fitted model and remove them from xsys data set and update it .
Ii want a function which will find one by one outlier and remove it .
The condition is that outlier would be consider as outlier if its r student I greater than +3 and -3.
I want all in loop and repeat loop  till no outlier is remained.

From petr.pikal at precheza.cz  Tue Dec 30 11:55:20 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 30 Dec 2014 10:55:20 +0000
Subject: [R] to create a fuction for removing outlier
In-Reply-To: <9C74639432B50946BF93B535048331610306BF@BUDURBPA06.e2k.ad.ge.com>
References: <9C74639432B50946BF93B535048331610306BF@BUDURBPA06.e2k.ad.ge.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C0F38C@SRVEXCHMBX.precheza.cz>

Hi

Without going to deeply to your code; your data seems to be numeric, but for some reason you read them as character. You shall consult read.csv help and your original data. They probably have some feature which prevent them to be read correctly.

To your question, what you want can be achieved by while loop.

something like this

while (abs(studres(object))>3) {
ms <-max(abs(studres(object)))
del <- which(ms== abs(studres(object)))
#do fitting with del removed from data
#save the fit
}

you can also use rstudent(object)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Methekar, Pushpa (GE Transportation, Non-GE)
> Sent: Tuesday, December 30, 2014 9:44 AM
> To: r-help at r-project.org
> Subject: [R] to create a fuction for removing outlier
>
> Hi all,
> Thanks for your support. sorry for inconvenience cause due to lack of
> information. here is my all  r- program .
>
>
> #### read in data
> raw=read.csv(file.choose(),header = T, stringsAsFactors=FALSE)
>
> str(raw)
>
> ####conversion from factor to numeric of xs raw$Engine.Speed <-
> as.numeric(raw$Engine.Speed)
> raw$Engine.Power<- as.numeric(raw$Engine.Power) raw$Diesel.LHV <-
> as.numeric(raw$Diesel.LHV) raw$NG.LHV <- as.numeric(raw$NG.LHV)
> raw$Compressor.Inlet.Temperature <-
> as.numeric(raw$Compressor.Inlet.Temperature)
> raw$Int.Mfld.Temp<- as.numeric(raw$Int.Mfld.Temp)
> raw$Cmd.Advance.Angle<- as.numeric(raw$Cmd.Advance.Angle)
> raw$Cmd.Fuel.Rail.Press.Manual<-
> as.numeric(raw$Cmd.Fuel.Rail.Press.Manual)
> raw$X..NG.by.Energy<- as.numeric(sub("%","",raw$X..NG.by.Energy))/100
>
>
> ####conversion from factor to numeric of Ys raw$Pre.Turb.Temp.L <-
> as.numeric(raw$Pre.Turb.Temp.L) raw$Avg.PCP <- as.numeric(raw$Avg.PCP)
> raw$BSHC <- as.numeric(raw$BSHC) raw$BSCO <- as.numeric(raw$BSCO)
> raw$GETS.cBSNOx <- as.numeric(raw$GETS.cBSNOx) raw$Avg.COV.GIMEP <-
> as.numeric(raw$Avg.COV.GIMEP) raw$Intake.Manifold.Pressure <-
> as.numeric(raw$Intake.Manifold.Pressure)
> raw$Emiss..1..EPA.MAF..Dry. <-
> as.numeric(sub(",","",raw$Emiss..1..EPA.MAF..Dry.))
> raw$Turbo.Speed <- as.numeric(raw$Turbo.Speed)
>
>
> #### create a matrix plot of scatter plot
> xs=raw[c("Engine.Speed","X..NG.by.Energy","Int.Mfld.Temp","Cmd.Advance.
> Angle","Engine.Power","Cmd.Fuel.Rail.Press.Manual","Compressor.Inlet.Te
> mperature","Diesel.LHV","NG.LHV")]
>
> ys=raw[c("Pre.Turb.Temp.L","Avg.PCP","BSHC","BSCO","GETS.cBSNOx","Avg.C
> OV.GIMEP","Turbo.Speed","Intake.Manifold.Pressure","Emiss..1..EPA.MAF..
> Dry.")]
> pairs(xs,main="x's")
> pairs(ys,main="y's")
>
> ### calculate correlation coefficient
> xs[is.na(xs)] <- 0 #replace all NA with 0
> cor(xs)
> ys[is.na(ys)] <- 0 #replace all NA with 0
> cor(ys)
> cor(xs,ys,method = "spearman")
> pairs(xs,ys)
> save.image(file="plotting.RData")
>
>
> ## make data frame of x's and y's
> xsys=data.frame(xs,ys)
>
> library(MASS)
> #### first order multiple linear regression fitted.modely1.temp.l <-
> rlm(
> Pre.Turb.Temp.L~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.
> Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LH
> V+NG.LHV,data=xsys)
>
> fitted.modely2.avg.pcp <- rlm(
> Avg.PCP~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cm
> d.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV
> ,data=xsys)
>
> fitted.modely3.bshc <- rlm(
> BSHC~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.F
> uel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,da
> ta=xsys)
>
> fitted.modely4.bsco <-
> rlm(BSCO~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LH
> V,data=xsys)
>
> fitted.modely5.gets <-
> rlm(GETS.cBSNOx~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.
> Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LH
> V+NG.LHV,data=xsys)
>
> fitted.modely6.gimep <-
> rlm(Avg.COV.GIMEP~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engin
> e.Power+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.
> LHV+NG.LHV,data=xsys)
>
> fitted.modely7.ts <- rlm( Turbo.Speed
> ~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.
> Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=x
> sys)
>
> fitted.modely8.imp <- rlm(Intake.Manifold.Pressure
> ~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.
> Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=x
> sys)
>
> fitted.modely9.maf <- rlm( Emiss..1..EPA.MAF..Dry.
> ~X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+Cmd.Fuel.
> Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+NG.LHV,data=x
> sys)
>
>
>
> #### comlete second order multiple linear regression
> secfitted.modely1.temp.l<-lm(Pre.Turb.Temp.L
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
> secfitted.modely2.avg.pcp<-lm(Avg.PCP
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
> secfitted.modely3.bshc<-lm( BSHC
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
>
> secfitted.modely4.bsco<-lm( BSCO
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
>
>
> secfitted.modely5.gets<-lm( GETS.cBSNOx
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
>
>
> secfitted.modely6.gimep<-lm( Avg.COV.GIMEP
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
> secfitted.modely7.ts<-lm( Turbo.Speed
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
>
>
> secfitted.modely8.imp<-lm( Intake.Manifold.Pressure
> ~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)+poly(Int.Mfld.Temp,2)+pol
> y(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+poly(Cmd.Fuel.Rail.Press.Ma
> nual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
>
> secfitted.modely9.maf<-
> lm(Emiss..1..EPA.MAF..Dry.~poly(Engine.Speed,2)+poly(X..NG.by.Energy,2)
> +poly(Int.Mfld.Temp,2)+poly(Cmd.Advance.Angle,2)+poly(Engine.Power,2)+p
> oly(Cmd.Fuel.Rail.Press.Manual,2)
>
> +poly(Compressor.Inlet.Temperature,2)+poly(Diesel.LHV,2)+poly(NG.LHV,2)
>
> +Engine.Speed*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +X..NG.by.Energy*(Engine.Speed+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Int.Mfld.Temp*(X..NG.by.Energy+Engine.Speed+Cmd.Advance.Angle+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Advance.Angle*(X..NG.by.Energy+Int.Mfld.Temp+Engine.Speed+Engine.P
> ower+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Engine.Power*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.S
> peed+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Cmd.Fuel.Rail.Press.Manual*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.
> Angle+Engine.Power+Engine.Speed+Compressor.Inlet.Temperature+Diesel.LHV
> +NG.LHV)
>
> +Compressor.Inlet.Temperature*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advanc
> e.Angle+Engine.Power+Cmd.Fuel.Rail.Press.Manual+Engine.Speed+Diesel.LHV
> +NG.LHV)
>
> +Diesel.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Pow
> er+Cmd.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Engine.Speed
> +NG.LHV)
>
> +NG.LHV*(X..NG.by.Energy+Int.Mfld.Temp+Cmd.Advance.Angle+Engine.Power+C
> md.Fuel.Rail.Press.Manual+Compressor.Inlet.Temperature+Diesel.LHV+Engin
> e.Speed),data=xsys)
>
>
> ####stepwise forward regression for first order
>
> step(fitted.modely1.temp.l,direction="forward")
> step(fitted.modely2.avg.pcp,direction="forward")
> step(fitted.modely3.bshc,direction="forward")
> step(fitted.modely4.bsco,direction="forward")
> step(fitted.modely5.gets,direction="forward")
> step(fitted.modely6.gimep,direction="forward")
> step(fitted.modely7.ts,direction="forward")
> step(fitted.modely8.imp,direction="forward")
> step(fitted.modely9.maf,direction="forward")
>
>
> step(fitted.modely1.temp.l,direction="backward")
> step(fitted.modely2.avg.pcp,direction="backward")
> step(fitted.modely3.bshc,direction="backward")
> step(fitted.modely4.bsco,direction="backward")
> step(fitted.modely5.gets,direction="backward")
> step(fitted.modely6.gimep,direction="backward")
> step(fitted.modely7.ts,direction="backward")
> step(fitted.modely8.imp,direction="backward")
> step(fitted.modely9.maf,direction="backward")
>
>
> now after this step I want to find out outliers in each fitted model
> and remove them from xsys data set and update it .
> Ii want a function which will find one by one outlier and remove it .
> The condition is that outlier would be consider as outlier if its r
> student I greater than +3 and -3.
> I want all in loop and repeat loop  till no outlier is remained.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Tue Dec 30 12:12:01 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 30 Dec 2014 11:12:01 +0000
Subject: [R] Add labels to my geom_hlines...
In-Reply-To: <37273DBD29A7A2408A7736A073A9FA3B8CBB9C8F@mb06.porsuk.anadolu.edu.tr>
References: <37273DBD29A7A2408A7736A073A9FA3B8CBB9C8F@mb06.porsuk.anadolu.edu.tr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C0F3D7@SRVEXCHMBX.precheza.cz>

Hi

I get error

> ggplot(data=d.oran)+geom_line(aes(x=Tarih,y=EUROUSD))+geom_hline(data=d.oran.ist,yintercept=x_bar[1]+c(-3:3)*std_sap[1],color=c("red","green","blue","black","blue","green","red"),linetype="dashed",lwd=1)
Error in get(x, envir = this, inherits = inh)(this, ...) :
  object 'x_bar' not found

with your data. Maybe it has different structure from yours but this cannot be resolved until you provide them with dput or show us their structure.

> dput(d.oran)
structure(list(Tarih = structure(1:5, .Label = c("2005-01-01",
"2005-01-02", "2005-01-03", "2005-01-04", "2005-01-05"), class = "factor"),
    EUROUSD = c(1.3782, 1.373217, 1.364489, 1.352766, 1.338793
    ), USDJPY = c(1.034654, 1.027268, 1.024884, 1.026722, 1.03387
    ), EUROJPY = c(1.42596, 1.410662, 1.398443, 1.388914, 1.384138
    )), .Names = c("Tarih", "EUROUSD", "USDJPY", "EUROJPY"), class = "data.frame", row.names = c("1",
"2", "3", "4", "5"))
> dput(d.oran.ist)
structure(list(x_bar = c(1.3405613, 0.9909699, 1.3265161), std_sap = c(0.08739358,
0.13757461, 0.18982005)), .Names = c("x_bar", "std_sap"), class = "data.frame", row.names = c("EUROUSD",
"USDJPY", "EUROJPY"))
>

To put text in ggplot see
?geom_text

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Levent
> TERLEMEZ
> Sent: Monday, December 29, 2014 6:05 PM
> To: r-help at r-project.org >> R
> Subject: [R] Add labels to my geom_hlines...
>
> Dear Users,
>
> Would you pls help me to write a proper geom_text addition to
> geom_hline of my ggplot2.
>
> This is d.oran
>
>        Tarih  EUROUSD   USDJPY  EUROJPY
> 1 2005-01-01 1.378200 1.034654 1.425960
> 2 2005-01-02 1.373217 1.027268 1.410662
> 3 2005-01-03 1.364489 1.024884 1.398443
> 4 2005-01-04 1.352766 1.026722 1.388914
> 5 2005-01-05 1.338793 1.033870 1.384138
>
> this is d.oran.ist
>
>   x_bar    std_sap
> EUROUSD 1.3405613 0.08739358
> USDJPY  0.9909699 0.13757461
> EUROJPY 1.3265161 0.18982005
>
> and both of them are (in function) data frames. Here is my ggplot and
> i'd like to add texts to left edge of hlines like -3sigma, -2sigma,...,
> 3sigma.
>
> Here is my ggplot line:
>
> ggplot(data=d.oran)+geom_line(aes(x=Tarih,y=EUROUSD))+geom_hline(data=d
> .oran.ist,yintercept=x_bar[1]+c(-
> 3:3)*std_sap[1],color=c("red","green","blue","black","blue","green","re
> d"),linetype="dashed",lwd=1)
>
>
> Thanks in advance.
> Levent TERLEMEZ.
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From albmont at centroin.com.br  Tue Dec 30 12:20:36 2014
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Tue, 30 Dec 2014 09:20:36 -0200
Subject: [R] Memory hungry routines
In-Reply-To: <CAFDcVCRjFL4ghTy1nU_E2DAhRuEBWziBjaQQC5=LqNe7rBjw=w@mail.gmail.com>
References: <CAEyj4=9E++Bc+EYmwjKzD2KZnkoMWD99ffryec10mGTY5bYKOw@mail.gmail.com>
	<CAFDcVCRjFL4ghTy1nU_E2DAhRuEBWziBjaQQC5=LqNe7rBjw=w@mail.gmail.com>
Message-ID: <CAEyj4=8entKahEDKaHyhNnxdubt3ikQLb8aYGwxZz1sQ8HbTNA@mail.gmail.com>

Thanks to Duncan, Hadley and Henrik.

Duncan, I used Rprof and could pinpoint the critical routine that was
doing the memory crash.

Henrik, you got it right: the culprit was a big matrix of integers,
but where some of its fields are filled with -Inf and Inf. This matrix
is global, it's used only once, it does not consume too much memory,
and it should be harmless, but...

Hadley, your link to memory allocation and management helped to
identify the problem. I did a very stupid think, I added some debug in
the critical routine that duplicated it at each iteration of a loop...
So that big matrix with integers and Infs and -Infs was being copied
several times, killing memory needlessly.

Thanks for all the help.

"I got 99 problems but you won't be one"

Alberto Monteiro


From murdoch.duncan at gmail.com  Tue Dec 30 12:43:18 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 30 Dec 2014 06:43:18 -0500
Subject: [R] Chaining multiple replacement functions in R
In-Reply-To: <CAPpYv=YkS2NoOrcYUeFbzQKkct++gs6m2H=AU=hWBtoesHHyXw@mail.gmail.com>
References: <CAPpYv=YkS2NoOrcYUeFbzQKkct++gs6m2H=AU=hWBtoesHHyXw@mail.gmail.com>
Message-ID: <54A28FD6.1010307@gmail.com>

On 29/12/2014 4:41 PM, Daniel Gabrieli wrote:
> I cross posted this on Stack Overflow:
> http://stackoverflow.com/questions/27694466/chaining-multiple-replacement-functions-in-r
> 
> 
> I am using R to work with a large JS object (using the library rjsonio). As
> such, I have a lot of nested lists, which are getting somewhat cumbersome
> to work with. I have a simplified example below. I am trying to work with
> this object by creating some form of ?getter? and ?setter? functions. After
> looking around, I have found a pretty nice ?getter? function that recurses
> through the object and returns the value for the first matching label. This
> is especially great because it lends itself to chaining functions together.
> However, I can not figure out a way to get the same effect for a ?setter?
> function. Any thoughts on how to create a ?setter? function that can be
> chained together in a similar fashion?

I haven't worked through the details here so this might not work, but
the assignment function could add extra information saying which part of
the object was modified.  In the example below, "Firstkey" is
app[[c(3,3,1)]], so a function that modified it could attach c(3,3,1) as
an attribute, and later functions that wanted to do more things to it
could start looking there.

I guess the tricky part would be getting rid of that attribute if you
didn't want to pass it along the chain, e.g. the final call shouldn't
return it.

Duncan Murdoch

> 
> #example, simplified, object
> app = list(
>   1,
>   2,
>   d=list(a=123,
>          b=456,
>          list(
>            FirstKey=list(attr1='good stuff', attr2=12345),
>            SecondKey=list(attr1='also good stuff', attr2=4321)
>            )
>          )
>   )
> 
> 
> #Return a function that returns the value
> #associated with first label that matches 'name'
> getByName <- function(name){
>   rmatch <- function(x) {
>     pos <- match(name, names(x))
>     if (!is.na(pos))
>       return(x[[pos]])
>     for (el in x) {
>       if (class(el) == "list") {
>         out <- Recall(el)
>         if (!is.null(out)) return(out)
>       }
>     }
>   }
>   rmatch
> }
> 
> getFirstKey <- getByName("FirstKey")
> getAttr1 <- getByName("attr1")
> getAttr2 <- getByName("attr2")
> 
> #I like that I can chain these functions together
> getAttr1(getFirstKey(app))
> getAttr2(getFirstKey(app))
> 
> # I would like to be able to do something like this
> # But this won't work
> ###    getAttr1(getFirstKey(app)) <- 9876
> 
> # This does work,,, but I loose the ability to chain functions together
> # Closure around a replacement function
> setterKeyAttr <- function(keyName, attr){
>   function(x, value){
>     x$d[[3]][[keyName]][[attr]] <- value
>     x
>   }
> }
> 
> `setFirstKeyAttr2<-` <- setterKeyAttr("FirstKey", "attr2")
> setFirstKeyAttr2(app) <- 22222
> #check the answer is correct
> getAttr2(getFirstKey(app))
> 
> 
> 
> references:
> 
> http://stackoverflow.com/questions/23124096/r-decorator-to-change-both-input-and-output
> 
> http://r.789695.n4.nabble.com/How-to-get-a-specific-named-element-in-a-nested-list-td3037430.html
> 
> http://adv-r.had.co.nz/Functions.html
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istazahn at gmail.com  Tue Dec 30 14:39:47 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 30 Dec 2014 08:39:47 -0500
Subject: [R] online classes/certifications?
In-Reply-To: <54A1C232.6080208@tanucoo.com>
References: <54A1C232.6080208@tanucoo.com>
Message-ID: <CA+vqiLFm9S0-NkVOP1GY5nAxph-zXqs0dOA_P87kveL1MCOUbg@mail.gmail.com>

I'm certain a google search will be sufficient to answer this question.

Best,
Ista

On Mon, Dec 29, 2014 at 4:05 PM, Subba Rao <kvirt at tanucoo.com> wrote:
> Hi,
>
> Are there any good online classes/certifications for R programming and
> Data Analytics?
>
> Thank you in advance for any information.
>
> Subba Rao
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Tue Dec 30 15:27:37 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 30 Dec 2014 09:27:37 -0500
Subject: [R] rle with data.table - is it possible?
Message-ID: <CAE6QMsb2bvS_xKEu41Qa1GSQ2x6xPMiwK0=s1zSMcWNWq2MJKQ@mail.gmail.com>

I'm trying to use both these packages and wondering whether they are possible...

To make this simple, my ultimate goal is determine long stretches of
1s, but I want to do this within groups (hence using the data.table as
I use the "set key" option.  However, I'm I'm not having much luck
making this possible.

For example, for simplistic sake, I have the following data:

Dad Mum Child Group
AA RR RA A
AA RR RR A
AA AA AA B
AA AA AA B
RA AA RR B
RR AA RR B
AA AA AA B
AA AA RA C
AA AA RA C
AA RR RA  C

And the following code which I know works

hetdad <- as.numeric(x[c(1)]=="AA" | x[c(1)]=="RR")
sumdad <- rle(hetdad)$lengths[rle(hetdad)$values==1]

hetmum <- as.numeric(x[c(2)]=="AA" | x[c(2)]=="RR")
summum <- rle(hetmum)$lengths[rle(hetmum)$values==1]

hetchild <- as.numeric(x[c(3)]=="AA" | x[c(3)]=="RR")
sumchild <- rle(hetchild)$lengths[rle(hetchild)$values==1]

However, I wish to do the above code by Group (though this file is
millions of rows long and groups will be larger but just wanted to
simply the example).

I did something like this but of course I got an error:

LOH[,hetdad:=as.numeric(x[c(1)]=="AA" | x[c(1)]=="RR")]
LOH[,sumdad:=rle(hetdad)$lengths[rle(hetdad)$values==1],by=Group]
LOH[,hetmum:=as.numeric(x[c(2)]=="AA" | x[c(2)]=="RR")]
LOH[,summum:=rle(hetmum)$lengths[rle(hetmum)$values==1],by=Group]
LOH[,hetchild:=as.numeric(x[c(3)]=="AA" | x[c(3)]=="RR")]
LOH[,sumchild:=rle(hetchild)$lengths[rle(hetchild)$values==1],by=Group]

The reason being as I want to eventually have something like this:

Dad Mum Child Group sumdad summum sumchild
AA RR RA A 2 2 0
AA RR RR A 2 2 1
AA AA AA B 4 5 5
AA AA AA B 4 5 5
RA AA RR B 0 5 5
RR AA RR B 4 5 5
AA AA AA B 4 5 5
AA AA RA C 3 3 0
AA AA RA C 3 3 0
AA RR RA  C 3 3 0

That is, I would like to have the specific counts next to what I'm
consecutively counting per group.  So for Group A for dad there are 2
AAs,  there are two RRs for mum but only 1 AA or RR for the child and
that is RR (so the 1 is next to the RR and not the RA).

Can this be done?

K.


From diegopujoni at gmail.com  Tue Dec 30 18:49:21 2014
From: diegopujoni at gmail.com (Diego Pujoni)
Date: Tue, 30 Dec 2014 15:49:21 -0200
Subject: [R] Include zero density on unsampled species
Message-ID: <CANmSXjR2bkNxdXn031gbGxfhvvomOpZ_dy_eeyD8ZqS0T3-Aeg@mail.gmail.com>

Dear R experts, how are you?

I have a data bank in long format as below:

species month        year       plot        density

sp1         1              2001       1              39

sp2         1              2001       1              6

sp3         1              2001       1              17

sp2         1              2001       2              35

sp3         1              2001       2              15

sp4         1              2001       2              27

sp1         2              2001       1              29

sp3         2              2001       1              49

sp4         2              2001       1              1

sp1         2              2001       2              8

sp4         2              2001       2              20

sp5         2              2001       2              41

...            ...            ...            ...            ...

I want to estimate the mean density of species in each month/year. So I
want to take the mean density of the plots for each month/year (there are
more than two plots). I used the function aggregate to make that

aggregate (density~species*month*year, mean, data=df)

  species month year density

1     sp1     1      2001    39.0

2     sp2     1      2001    20.5

3     sp3     1      2001    16.0

4     sp4     1      2001    27.0

5     sp1     2      2001    18.5

6     sp3     2      2001    49.0

7     sp4     2      2001    10.5

8     sp5     2      2001    41.0


Not all species were sampled in all plots, and for those unsampled species
the estimated density should be zero for that plot. But the function
aggregate won?t make that. It will just look for densities of sampled
species and if it finds records of that species in two or more plots, then
it will take the average, but if it find only one value it will use that
unique value and the mean density will be biased.

So I think I should first transform this data to wide format, including all
combinations of species, month, year and plots, include zero where is NA?s,
retransform back to long format and continue with the analysis. But I don?t
know how to make it.

Thank you very much for any help and all the best for 2015!!

-- 
                                               Diego PJ

	[[alternative HTML version deleted]]


From daniel.gabrieli at gmail.com  Tue Dec 30 19:08:23 2014
From: daniel.gabrieli at gmail.com (Daniel Gabrieli)
Date: Tue, 30 Dec 2014 13:08:23 -0500
Subject: [R] Chaining multiple replacement functions in R
In-Reply-To: <54A28FD6.1010307@gmail.com>
References: <CAPpYv=YkS2NoOrcYUeFbzQKkct++gs6m2H=AU=hWBtoesHHyXw@mail.gmail.com>
	<54A28FD6.1010307@gmail.com>
Message-ID: <CAPpYv=Y9PspQr9xYR1LBZTOCuPN8d8L6Z26yvsJb++1nKVSrLg@mail.gmail.com>

That is really helpful.  I am trying to get the rmatch function to return
the position of the 'name' instead of the value.  So rmatch(app, "FirsKey")
would return c(3,3,1).  Then app[[c(3,3,1)]] <- 'new value' would be
perfect.



On Tue, Dec 30, 2014 at 6:43 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 29/12/2014 4:41 PM, Daniel Gabrieli wrote:
> > I cross posted this on Stack Overflow:
> >
> http://stackoverflow.com/questions/27694466/chaining-multiple-replacement-functions-in-r
> >
> >
> > I am using R to work with a large JS object (using the library rjsonio).
> As
> > such, I have a lot of nested lists, which are getting somewhat cumbersome
> > to work with. I have a simplified example below. I am trying to work with
> > this object by creating some form of ?getter? and ?setter? functions.
> After
> > looking around, I have found a pretty nice ?getter? function that
> recurses
> > through the object and returns the value for the first matching label.
> This
> > is especially great because it lends itself to chaining functions
> together.
> > However, I can not figure out a way to get the same effect for a ?setter?
> > function. Any thoughts on how to create a ?setter? function that can be
> > chained together in a similar fashion?
>
> I haven't worked through the details here so this might not work, but
> the assignment function could add extra information saying which part of
> the object was modified.  In the example below, "Firstkey" is
> app[[c(3,3,1)]], so a function that modified it could attach c(3,3,1) as
> an attribute, and later functions that wanted to do more things to it
> could start looking there.
>
> I guess the tricky part would be getting rid of that attribute if you
> didn't want to pass it along the chain, e.g. the final call shouldn't
> return it.
>
> Duncan Murdoch
>
> >
> > #example, simplified, object
> > app = list(
> >   1,
> >   2,
> >   d=list(a=123,
> >          b=456,
> >          list(
> >            FirstKey=list(attr1='good stuff', attr2=12345),
> >            SecondKey=list(attr1='also good stuff', attr2=4321)
> >            )
> >          )
> >   )
> >
> >
> > #Return a function that returns the value
> > #associated with first label that matches 'name'
> > getByName <- function(name){
> >   rmatch <- function(x) {
> >     pos <- match(name, names(x))
> >     if (!is.na(pos))
> >       return(x[[pos]])
> >     for (el in x) {
> >       if (class(el) == "list") {
> >         out <- Recall(el)
> >         if (!is.null(out)) return(out)
> >       }
> >     }
> >   }
> >   rmatch
> > }
> >
> > getFirstKey <- getByName("FirstKey")
> > getAttr1 <- getByName("attr1")
> > getAttr2 <- getByName("attr2")
> >
> > #I like that I can chain these functions together
> > getAttr1(getFirstKey(app))
> > getAttr2(getFirstKey(app))
> >
> > # I would like to be able to do something like this
> > # But this won't work
> > ###    getAttr1(getFirstKey(app)) <- 9876
> >
> > # This does work,,, but I loose the ability to chain functions together
> > # Closure around a replacement function
> > setterKeyAttr <- function(keyName, attr){
> >   function(x, value){
> >     x$d[[3]][[keyName]][[attr]] <- value
> >     x
> >   }
> > }
> >
> > `setFirstKeyAttr2<-` <- setterKeyAttr("FirstKey", "attr2")
> > setFirstKeyAttr2(app) <- 22222
> > #check the answer is correct
> > getAttr2(getFirstKey(app))
> >
> >
> >
> > references:
> >
> >
> http://stackoverflow.com/questions/23124096/r-decorator-to-change-both-input-and-output
> >
> >
> http://r.789695.n4.nabble.com/How-to-get-a-specific-named-element-in-a-nested-list-td3037430.html
> >
> > http://adv-r.had.co.nz/Functions.html
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From Joseph.Racine at mdaus.com  Tue Dec 30 15:45:14 2014
From: Joseph.Racine at mdaus.com (Joseph Racine)
Date: Tue, 30 Dec 2014 14:45:14 +0000
Subject: [R] FW: R demos or tutorials
In-Reply-To: <F8B1D8887A9AB347882A4C5A4A04067003282B@MDINFEX01.mdaus.corp>
References: <F8B1D8887A9AB347882A4C5A4A04067003282B@MDINFEX01.mdaus.corp>
Message-ID: <F8B1D8887A9AB347882A4C5A4A04067003284E@MDINFEX01.mdaus.corp>

To whom is may concern,

I am interested in working with R, and just downloaded the windows installation. Unfortunately when I tried to run some demos, I received an error (Error: could not find function "demo").

Any suggestions?

Also, if you have some tutorial packages to help gain some familiarity, please pass those on as well.

Best regards and happy new year.

Joe Racine

Joseph K. Racine
Data Scientist
MDA Information Systems LLC
Client Site: (434) 995-4454
Cell: (571) 213-4236
www.mdaus.com<http://www.mdaus.com/>
joseph.racine at mdaus.com

<mailto:joseph.racine at mdaus.com>

The information contained in this communication is confi...{{dropped:11}}


From jdnewmil at dcn.davis.CA.us  Tue Dec 30 19:52:15 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 30 Dec 2014 10:52:15 -0800
Subject: [R] FW: R demos or tutorials
In-Reply-To: <F8B1D8887A9AB347882A4C5A4A04067003284E@MDINFEX01.mdaus.corp>
References: <F8B1D8887A9AB347882A4C5A4A04067003282B@MDINFEX01.mdaus.corp>
	<F8B1D8887A9AB347882A4C5A4A04067003284E@MDINFEX01.mdaus.corp>
Message-ID: <5E2FA45A-D10B-448A-9DFB-3C0C4BD05F6C@dcn.davis.CA.us>

If you entered

demo()

at the R prompt and got the stated error then I would venture that your installation is faulty. 

Another function that should work is

sessionInfo()

and the output of that function can be helpful to us in  troubleshooting.  However, I would strongly consider looking into re-installing R from r--project.org.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On December 30, 2014 6:45:14 AM PST, Joseph Racine <Joseph.Racine at mdaus.com> wrote:
>To whom is may concern,
>
>I am interested in working with R, and just downloaded the windows
>installation. Unfortunately when I tried to run some demos, I received
>an error (Error: could not find function "demo").
>
>Any suggestions?
>
>Also, if you have some tutorial packages to help gain some familiarity,
>please pass those on as well.
>
>Best regards and happy new year.
>
>Joe Racine
>
>Joseph K. Racine
>Data Scientist
>MDA Information Systems LLC
>Client Site: (434) 995-4454
>Cell: (571) 213-4236
>www.mdaus.com<http://www.mdaus.com/>
>joseph.racine at mdaus.com
>
><mailto:joseph.racine at mdaus.com>
>
>The information contained in this communication is
>confi...{{dropped:11}}
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Brent.D.Mast at hud.gov  Tue Dec 30 20:24:54 2014
From: Brent.D.Mast at hud.gov (Mast, Brent D)
Date: Tue, 30 Dec 2014 14:24:54 -0500
Subject: [R] Three-way mosaic residual plot with survey data
Message-ID: <598B1AFF65DDEB4083C14C81FF2CC0C30ACB6FAB86@ELANNEPV115.exh.prod.hud.gov>

Hi.

I want to produce a three-way mosaic residual plot with survey data. I'm using the mosaic function from the vcd package for the plot, and the svytable function from the survey package to produce the contingency table.
Here is my code for a two-way table (that works) and a three-way table that plots but I think is wrong.

library(vcat)
library(survey)
data(api)
summary(apiclus1)
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
summary(dclus1)

# two-way plot
st2 <- svytable(~sch.wide+comp.imp,design=dclus1,round=TRUE)
summary(st2)
mosaic(st2,main = "Two-Way Mosaic Plot", shade = TRUE, legend = TRUE)

# three-way plot
st3 <- svytable(~sch.wide+comp.imp+stype,design=dclus1,round=TRUE)
summary(st3)
windows()
mosaic(st3,main = "Three-Way Mosaic Plot", shade = TRUE, legend = TRUE)

When I try to summarize the three-way svytable object "st3", I get the following error:
> summary(st3)
Error in svychisq.survey.design(~sch.wide + comp.imp + stype, design = dclus1,  :
  Only 2-way tables at the moment

It still produces the three-way mosaic plot. But I don't think it's plotting the residuals correctly because the error message indicates only two-way chi-square tests are allowed.

The vcd package will create a mosaic residual plot from a log-linear model estimated by the loglm function from the MASS package. But it won't accept a log-linear model created with the svyloglin function from the survey package.
I'm wondering if I could run a log-linear model with svyloglin and transform the output into a table format that the mosaic function will plot.

Any help would be appreciated.

Thanks, and happy New Year.

Brent Mast
Social Science Analyst
HUD Office of Policy Development & Research
Program Monitoring & Research Div.


	[[alternative HTML version deleted]]


From Pradip.Muhuri at samhsa.hhs.gov  Tue Dec 30 20:55:28 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Tue, 30 Dec 2014 19:55:28 +0000
Subject: [R] R example codes for direct standardization of rates (Reference:
 Thoma's Lumley's survey package)
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C389472C7@PL-EMSMB20.ees.hhs.gov>

Hello,

I am looking for R  example codes to compute age-standardized death rates by smoking and psychological distress status using person-years of observation created from the National Health Interview Survey Linked Mortality Files.  Any help with the example codes or references will be appreciated.

Thanks,

Pradip

Pradip K. Muhuri
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260


	[[alternative HTML version deleted]]


From btupper at bigelow.org  Tue Dec 30 20:59:55 2014
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 30 Dec 2014 14:59:55 -0500
Subject: [R] Interesting article on R
Message-ID: <1D0F4F80-4059-4E9C-A350-08CDFDEF674E@bigelow.org>

Hi,

In case you missed it...

http://www.nature.com/news/programming-tools-adventures-with-r-1.16609

Cheers,
Ben

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From ajdamico at gmail.com  Tue Dec 30 21:01:18 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 30 Dec 2014 15:01:18 -0500
Subject: [R] R example codes for direct standardization of rates
 (Reference: Thoma's Lumley's survey package)
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C389472C7@PL-EMSMB20.ees.hhs.gov>
References: <E18C153EBB81024CB60FCE9B4C34D57C389472C7@PL-EMSMB20.ees.hhs.gov>
Message-ID: <CAOwvMDzNCwe87WtKeWxd3bOtfJh-bZ4nqQ=kxNF5s16VeWV-5A@mail.gmail.com>

hi pradip hope you're doing well!  these two scripts have age adjustment
calculations, but neither are specific to nhis.  the nhanes example is
probably closer to what you're trying to do :)


https://github.com/ajdamico/usgsd/blob/master/National%20Health%20and%20Nutrition%20Examination%20Survey/2009-2010%20interview%20plus%20laboratory%20-%20download%20and%20analyze.R

https://github.com/ajdamico/usgsd/blob/master/National%20Vital%20Statistics%20System/replicate%20age-adjusted%20death%20rate.R



On Tue, Dec 30, 2014 at 2:55 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <
Pradip.Muhuri at samhsa.hhs.gov> wrote:

> Hello,
>
> I am looking for R  example codes to compute age-standardized death rates
> by smoking and psychological distress status using person-years of
> observation created from the National Health Interview Survey Linked
> Mortality Files.  Any help with the example codes or references will be
> appreciated.
>
> Thanks,
>
> Pradip
>
> Pradip K. Muhuri
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Pradip.Muhuri at samhsa.hhs.gov  Tue Dec 30 21:37:12 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Tue, 30 Dec 2014 20:37:12 +0000
Subject: [R] R example codes for direct standardization of rates
 (Reference: Thoma's Lumley's survey package)
In-Reply-To: <CAOwvMDzNCwe87WtKeWxd3bOtfJh-bZ4nqQ=kxNF5s16VeWV-5A@mail.gmail.com>
References: <E18C153EBB81024CB60FCE9B4C34D57C389472C7@PL-EMSMB20.ees.hhs.gov>
	<CAOwvMDzNCwe87WtKeWxd3bOtfJh-bZ4nqQ=kxNF5s16VeWV-5A@mail.gmail.com>
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C389472EA@PL-EMSMB20.ees.hhs.gov>

Hi Anthony,

Thank you for sending me your well-documented R scripts that are meant for age-adjusted rate calculations.  I will keep you posted on the implementation of these scripts in the context of my analyses.

Pradip

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260

From: Anthony Damico [mailto:ajdamico at gmail.com]
Sent: Tuesday, December 30, 2014 3:01 PM
To: Muhuri, Pradip (SAMHSA/CBHSQ)
Cc: r-help at r-project.org
Subject: Re: [R] R example codes for direct standardization of rates (Reference: Thoma's Lumley's survey package)

hi pradip hope you're doing well!  these two scripts have age adjustment calculations, but neither are specific to nhis.  the nhanes example is probably closer to what you're trying to do :)


https://github.com/ajdamico/usgsd/blob/master/National%20Health%20and%20Nutrition%20Examination%20Survey/2009-2010%20interview%20plus%20laboratory%20-%20download%20and%20analyze.R

https://github.com/ajdamico/usgsd/blob/master/National%20Vital%20Statistics%20System/replicate%20age-adjusted%20death%20rate.R


On Tue, Dec 30, 2014 at 2:55 PM, Muhuri, Pradip (SAMHSA/CBHSQ) <Pradip.Muhuri at samhsa.hhs.gov<mailto:Pradip.Muhuri at samhsa.hhs.gov>> wrote:
Hello,

I am looking for R  example codes to compute age-standardized death rates by smoking and psychological distress status using person-years of observation created from the National Health Interview Survey Linked Mortality Files.  Any help with the example codes or references will be appreciated.

Thanks,

Pradip

Pradip K. Muhuri
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070<tel:240-276-1070>
Fax: 240-276-1260<tel:240-276-1260>


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Tue Dec 30 22:29:52 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 30 Dec 2014 22:29:52 +0100 (CET)
Subject: [R] Three-way mosaic residual plot with survey data
In-Reply-To: <598B1AFF65DDEB4083C14C81FF2CC0C30ACB6FAB86@ELANNEPV115.exh.prod.hud.gov>
References: <598B1AFF65DDEB4083C14C81FF2CC0C30ACB6FAB86@ELANNEPV115.exh.prod.hud.gov>
Message-ID: <alpine.DEB.2.11.1412302214140.6231@paninaro.uibk.ac.at>

On Tue, 30 Dec 2014, Mast, Brent D wrote:

> Hi.
>
> I want to produce a three-way mosaic residual plot with survey data. I'm 
> using the mosaic function from the vcd package for the plot, and the 
> svytable function from the survey package to produce the contingency 
> table. Here is my code for a two-way table (that works) and a three-way 
> table that plots but I think is wrong.
>
> library(vcat)

vcd...in case anybody else wondered.

> library(survey)
> data(api)
> summary(apiclus1)
> dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
> summary(dclus1)
>
> # two-way plot
> st2 <- svytable(~sch.wide+comp.imp,design=dclus1,round=TRUE)
> summary(st2)
> mosaic(st2,main = "Two-Way Mosaic Plot", shade = TRUE, legend = TRUE)

Note that the test statistic and p-value from the summary.svytable 
(calling svychisq) and from mosaic (calling loglin/loglm) are not the 
same.

> # three-way plot
> st3 <- svytable(~sch.wide+comp.imp+stype,design=dclus1,round=TRUE)
> summary(st3)
> windows()
> mosaic(st3,main = "Three-Way Mosaic Plot", shade = TRUE, legend = TRUE)
>
> When I try to summarize the three-way svytable object "st3", I get the 
> following error:
>> summary(st3)
> Error in svychisq.survey.design(~sch.wide + comp.imp + stype, design = dclus1,  :
>  Only 2-way tables at the moment
>
> It still produces the three-way mosaic plot. But I don't think it's 
> plotting the residuals correctly because the error message indicates 
> only two-way chi-square tests are allowed.

mosaic() does not know anything about survey tables etc. Hence, it just 
ignores the design associated with the contingency tables st2 and st3 and 
just visualizes them as if they were cross-section data.

> The vcd package will create a mosaic residual plot from a log-linear 
> model estimated by the loglm function from the MASS package. But it 
> won't accept a log-linear model created with the svyloglin function from 
> the survey package. I'm wondering if I could run a log-linear model with 
> svyloglin and transform the output into a table format that the mosaic 
> function will plot.

If you use strucplot() directly (rather than the mosaic() interface) you 
can supply your own 'residuals' and/or 'expected' arguments. These can be 
tables of the same dimension as the table visualized and will be used for 
shading.

As I'm not really familiar with these chi-squared tests for survey tables, 
I cannot recommend how to adapt exactly. I guess it would be good to use 
the signed square-root of the contributions to the svy chi-squared 
statistic as "residuals" in the strucplot(). Possibly the default cut-offs 
(+/- 2 and 4) could also be modified.

hth,
Z

> Any help would be appreciated.
>
> Thanks, and happy New Year.
>
> Brent Mast
> Social Science Analyst
> HUD Office of Policy Development & Research
> Program Monitoring & Research Div.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From daniel.gabrieli at gmail.com  Tue Dec 30 22:51:10 2014
From: daniel.gabrieli at gmail.com (Daniel Gabrieli)
Date: Tue, 30 Dec 2014 16:51:10 -0500
Subject: [R] Chaining multiple replacement functions in R
In-Reply-To: <CAPpYv=Y9PspQr9xYR1LBZTOCuPN8d8L6Z26yvsJb++1nKVSrLg@mail.gmail.com>
References: <CAPpYv=YkS2NoOrcYUeFbzQKkct++gs6m2H=AU=hWBtoesHHyXw@mail.gmail.com>
	<54A28FD6.1010307@gmail.com>
	<CAPpYv=Y9PspQr9xYR1LBZTOCuPN8d8L6Z26yvsJb++1nKVSrLg@mail.gmail.com>
Message-ID: <CAPpYv=Y57jaxbyqCV_ozCniReO2R3O6TqocfV_11Haf5wgpz1g@mail.gmail.com>

This is what I came up with (to make the recursive function return the
position of the 'name' and still be able to chain the calls together).  I
am not sure if this is a great way to do it... but it seems to be
working...

rmatch.pos <- function(object, name, seq=NA, level=NULL){
  ##return the vector of integers corresponding to the first match
  ##of 'name' to a label in object or NULL if no match is found
    ###object: a list, likely deeply nested
    ##name: the name of the label to look for
    ##seq: starting point to search for 'name' in 'object' i.e. c(2,3,3)
    ##level: don't touch this; it keeps track of how deep the recursive
execution is
  ##can be chained together to reduce ambiguity or result:
    ##obj <- list(a=1, b=list(c=2, d=list(e=1, attr1="really?",
f=list(attr1 = "found me!"))))
    ##obj[[rmatch.pos(obj, "attr1", rmatch.pos(obj, "f"))]]

  if(is.null(seq)){
    #short circuit if NULL gets passed
    #when chaining, this forces the whole 'chain'
    #to NULL when any 'link' is NULL
    return(NULL)
  }
  if(is.null(level)){
    level <- length(na.omit(seq))
  }
  if(any(is.na(seq))){
    temp <- object
  }else{
    temp <- object[[seq]]
  }
  level <- level + 1
  pos <- match(name, names(temp))
  if(!is.na(pos)){
    seq[level] <- pos
    return(seq)
  }
  for(el in seq_along(temp)){
    if(class(temp[[el]]) == "list"){
      seq[level] <- el
      out <- Recall(object, name, seq, level)
      if(!is.null(out)){
        return(out)
      }
    }
  }
}


rmatch.pos(app, "ThirdKey")
rmatch.pos(app, "attr2")
#chaining example
rmatch.pos(app, "attr2", rmatch.pos(app, "FirstKey"))
rmatch.pos(app, "attr2", rmatch.pos(app, "SecondKey"))
rmatch.pos(app, "attr1", rmatch.pos(app, "ERROR"))
rmatch.pos(app, "ERROR", rmatch.pos(app, "attr1"))




On Tue, Dec 30, 2014 at 1:08 PM, Daniel Gabrieli <daniel.gabrieli at gmail.com>
wrote:

> That is really helpful.  I am trying to get the rmatch function to return
> the position of the 'name' instead of the value.  So rmatch(app, "FirsKey")
> would return c(3,3,1).  Then app[[c(3,3,1)]] <- 'new value' would be
> perfect.
>
>
>
> On Tue, Dec 30, 2014 at 6:43 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 29/12/2014 4:41 PM, Daniel Gabrieli wrote:
>> > I cross posted this on Stack Overflow:
>> >
>> http://stackoverflow.com/questions/27694466/chaining-multiple-replacement-functions-in-r
>> >
>> >
>> > I am using R to work with a large JS object (using the library
>> rjsonio). As
>> > such, I have a lot of nested lists, which are getting somewhat
>> cumbersome
>> > to work with. I have a simplified example below. I am trying to work
>> with
>> > this object by creating some form of ?getter? and ?setter? functions.
>> After
>> > looking around, I have found a pretty nice ?getter? function that
>> recurses
>> > through the object and returns the value for the first matching label.
>> This
>> > is especially great because it lends itself to chaining functions
>> together.
>> > However, I can not figure out a way to get the same effect for a
>> ?setter?
>> > function. Any thoughts on how to create a ?setter? function that can be
>> > chained together in a similar fashion?
>>
>> I haven't worked through the details here so this might not work, but
>> the assignment function could add extra information saying which part of
>> the object was modified.  In the example below, "Firstkey" is
>> app[[c(3,3,1)]], so a function that modified it could attach c(3,3,1) as
>> an attribute, and later functions that wanted to do more things to it
>> could start looking there.
>>
>> I guess the tricky part would be getting rid of that attribute if you
>> didn't want to pass it along the chain, e.g. the final call shouldn't
>> return it.
>>
>> Duncan Murdoch
>>
>> >
>> > #example, simplified, object
>> > app = list(
>> >   1,
>> >   2,
>> >   d=list(a=123,
>> >          b=456,
>> >          list(
>> >            FirstKey=list(attr1='good stuff', attr2=12345),
>> >            SecondKey=list(attr1='also good stuff', attr2=4321)
>> >            )
>> >          )
>> >   )
>> >
>> >
>> > #Return a function that returns the value
>> > #associated with first label that matches 'name'
>> > getByName <- function(name){
>> >   rmatch <- function(x) {
>> >     pos <- match(name, names(x))
>> >     if (!is.na(pos))
>> >       return(x[[pos]])
>> >     for (el in x) {
>> >       if (class(el) == "list") {
>> >         out <- Recall(el)
>> >         if (!is.null(out)) return(out)
>> >       }
>> >     }
>> >   }
>> >   rmatch
>> > }
>> >
>> > getFirstKey <- getByName("FirstKey")
>> > getAttr1 <- getByName("attr1")
>> > getAttr2 <- getByName("attr2")
>> >
>> > #I like that I can chain these functions together
>> > getAttr1(getFirstKey(app))
>> > getAttr2(getFirstKey(app))
>> >
>> > # I would like to be able to do something like this
>> > # But this won't work
>> > ###    getAttr1(getFirstKey(app)) <- 9876
>> >
>> > # This does work,,, but I loose the ability to chain functions together
>> > # Closure around a replacement function
>> > setterKeyAttr <- function(keyName, attr){
>> >   function(x, value){
>> >     x$d[[3]][[keyName]][[attr]] <- value
>> >     x
>> >   }
>> > }
>> >
>> > `setFirstKeyAttr2<-` <- setterKeyAttr("FirstKey", "attr2")
>> > setFirstKeyAttr2(app) <- 22222
>> > #check the answer is correct
>> > getAttr2(getFirstKey(app))
>> >
>> >
>> >
>> > references:
>> >
>> >
>> http://stackoverflow.com/questions/23124096/r-decorator-to-change-both-input-and-output
>> >
>> >
>> http://r.789695.n4.nabble.com/How-to-get-a-specific-named-element-in-a-nested-list-td3037430.html
>> >
>> > http://adv-r.had.co.nz/Functions.html
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>

	[[alternative HTML version deleted]]


From friendly at yorku.ca  Wed Dec 31 00:05:04 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 30 Dec 2014 18:05:04 -0500
Subject: [R] simplify code for dummy coding of factors
Message-ID: <54A32FA0.5010004@yorku.ca>

In a manuscript, I have the following code to illustrate dummy coding of 
two factors in a contingency table.

It works, but is surely obscured by the method I used, involving outer() 
to find equalities and 0+outer()
to convert to numeric.  Can someone help simplify this code to be more 
comprehensible and give the
*same* result? I'd prefer a solution that uses base R.

haireye <- margin.table(HairEyeColor, 1:2)

haireye.df <- as.data.frame(haireye)
dummy.hair <-  0+outer(haireye.df$Hair, levels(haireye.df$Hair), `==`)
colnames(dummy.hair)  <- paste0('h', 1:4)
dummy.eye <-  0+outer(haireye.df$Eye, levels(haireye.df$Eye), `==`)
colnames(dummy.eye)  <- paste0('e', 1:4)

haireye.df <- data.frame(haireye.df, dummy.hair, dummy.eye)
haireye.df

 > haireye.df
     Hair   Eye Freq h1 h2 h3 h4 e1 e2 e3 e4
1  Black Brown   68  1  0  0  0  1  0  0  0
2  Brown Brown  119  0  1  0  0  1  0  0  0
3    Red Brown   26  0  0  1  0  1  0  0  0
4  Blond Brown    7  0  0  0  1  1  0  0  0
5  Black  Blue   20  1  0  0  0  0  1  0  0
6  Brown  Blue   84  0  1  0  0  0  1  0  0
7    Red  Blue   17  0  0  1  0  0  1  0  0
8  Blond  Blue   94  0  0  0  1  0  1  0  0
9  Black Hazel   15  1  0  0  0  0  0  1  0
10 Brown Hazel   54  0  1  0  0  0  0  1  0
11   Red Hazel   14  0  0  1  0  0  0  1  0
12 Blond Hazel   10  0  0  0  1  0  0  1  0
13 Black Green    5  1  0  0  0  0  0  0  1
14 Brown Green   29  0  1  0  0  0  0  0  1
15   Red Green   14  0  0  1  0  0  0  0  1
16 Blond Green   16  0  0  0  1  0  0  0  1
 >

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jfox at mcmaster.ca  Wed Dec 31 00:56:13 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 30 Dec 2014 18:56:13 -0500
Subject: [R] simplify code for dummy coding of factors
In-Reply-To: <54A32FA0.5010004@yorku.ca>
References: <54A32FA0.5010004@yorku.ca>
Message-ID: <001c01d0248c$314aee40$93e0cac0$@mcmaster.ca>

Hi Michael,

At first I thought that as.numeric() would do it, but that loses the matrix
structure. Here are two solutions; I think that I prefer the second.

----------- snip --------------------

> (dummy.hair <-  outer(haireye.df$Hair, 
+     levels(haireye.df$Hair), function(x, y) as.numeric(x == y)))
      [,1] [,2] [,3] [,4]
 [1,]    1    0    0    0
 [2,]    0    1    0    0
 [3,]    0    0    1    0
 [4,]    0    0    0    1
 [5,]    1    0    0    0
 [6,]    0    1    0    0
 [7,]    0    0    1    0
 [8,]    0    0    0    1
 [9,]    1    0    0    0
[10,]    0    1    0    0
[11,]    0    0    1    0
[12,]    0    0    0    1
[13,]    1    0    0    0
[14,]    0    1    0    0
[15,]    0    0    1    0
[16,]    0    0    0    1
 
> (dummy.hair <- model.matrix(~ -1 + Hair, data=haireye.df))
   HairBlack HairBrown HairRed HairBlond
1          1         0       0         0
2          0         1       0         0
3          0         0       1         0
4          0         0       0         1
5          1         0       0         0
6          0         1       0         0
7          0         0       1         0
8          0         0       0         1
9          1         0       0         0
10         0         1       0         0
11         0         0       1         0
12         0         0       0         1
13         1         0       0         0
14         0         1       0         0
15         0         0       1         0
16         0         0       0         1
attr(,"assign")
[1] 1 1 1 1
attr(,"contrasts")
attr(,"contrasts")$Hair
[1] "contr.treatment"

----------- snip --------------------

I hope this helps,
 John

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael
> Friendly
> Sent: Tuesday, December 30, 2014 6:05 PM
> To: R-help
> Subject: [R] simplify code for dummy coding of factors
> 
> In a manuscript, I have the following code to illustrate dummy coding of
> two factors in a contingency table.
> 
> It works, but is surely obscured by the method I used, involving outer()
> to find equalities and 0+outer()
> to convert to numeric.  Can someone help simplify this code to be more
> comprehensible and give the
> *same* result? I'd prefer a solution that uses base R.
> 
> haireye <- margin.table(HairEyeColor, 1:2)
> 
> haireye.df <- as.data.frame(haireye)
> dummy.hair <-  0+outer(haireye.df$Hair, levels(haireye.df$Hair), `==`)
> colnames(dummy.hair)  <- paste0('h', 1:4)
> dummy.eye <-  0+outer(haireye.df$Eye, levels(haireye.df$Eye), `==`)
> colnames(dummy.eye)  <- paste0('e', 1:4)
> 
> haireye.df <- data.frame(haireye.df, dummy.hair, dummy.eye)
> haireye.df
> 
>  > haireye.df
>      Hair   Eye Freq h1 h2 h3 h4 e1 e2 e3 e4
> 1  Black Brown   68  1  0  0  0  1  0  0  0
> 2  Brown Brown  119  0  1  0  0  1  0  0  0
> 3    Red Brown   26  0  0  1  0  1  0  0  0
> 4  Blond Brown    7  0  0  0  1  1  0  0  0
> 5  Black  Blue   20  1  0  0  0  0  1  0  0
> 6  Brown  Blue   84  0  1  0  0  0  1  0  0
> 7    Red  Blue   17  0  0  1  0  0  1  0  0
> 8  Blond  Blue   94  0  0  0  1  0  1  0  0
> 9  Black Hazel   15  1  0  0  0  0  0  1  0
> 10 Brown Hazel   54  0  1  0  0  0  0  1  0
> 11   Red Hazel   14  0  0  1  0  0  0  1  0
> 12 Blond Hazel   10  0  0  0  1  0  0  1  0
> 13 Black Green    5  1  0  0  0  0  0  0  1
> 14 Brown Green   29  0  1  0  0  0  0  0  1
> 15   Red Green   14  0  0  1  0  0  0  0  1
> 16 Blond Green   16  0  0  0  1  0  0  0  1
>  >
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Dec 31 01:01:31 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 30 Dec 2014 16:01:31 -0800
Subject: [R] simplify code for dummy coding of factors
In-Reply-To: <54A32FA0.5010004@yorku.ca>
References: <54A32FA0.5010004@yorku.ca>
Message-ID: <61A9867B-6929-4175-BF42-476D71A745A7@comcast.net>


On Dec 30, 2014, at 3:05 PM, Michael Friendly wrote:

> In a manuscript, I have the following code to illustrate dummy coding of two factors in a contingency table.
> 
> It works, but is surely obscured by the method I used, involving outer() to find equalities and 0+outer()
> to convert to numeric.  Can someone help simplify this code to be more comprehensible and give the
> *same* result? I'd prefer a solution that uses base R.
> 
> haireye <- margin.table(HairEyeColor, 1:2)
> 
> haireye.df <- as.data.frame(haireye)
> dummy.hair <-  0+outer(haireye.df$Hair, levels(haireye.df$Hair), `==`)
> colnames(dummy.hair)  <- paste0('h', 1:4)
> dummy.eye <-  0+outer(haireye.df$Eye, levels(haireye.df$Eye), `==`)
> colnames(dummy.eye)  <- paste0('e', 1:4)
> 
> haireye.df <- data.frame(haireye.df, dummy.hair, dummy.eye)
> haireye.df
> 
> > haireye.df
>    Hair   Eye Freq h1 h2 h3 h4 e1 e2 e3 e4
> 1  Black Brown   68  1  0  0  0  1  0  0  0
> 2  Brown Brown  119  0  1  0  0  1  0  0  0
> 3    Red Brown   26  0  0  1  0  1  0  0  0
> 4  Blond Brown    7  0  0  0  1  1  0  0  0
> 5  Black  Blue   20  1  0  0  0  0  1  0  0
> 6  Brown  Blue   84  0  1  0  0  0  1  0  0
> 7    Red  Blue   17  0  0  1  0  0  1  0  0
> 8  Blond  Blue   94  0  0  0  1  0  1  0  0
> 9  Black Hazel   15  1  0  0  0  0  0  1  0
> 10 Brown Hazel   54  0  1  0  0  0  0  1  0
> 11   Red Hazel   14  0  0  1  0  0  0  1  0
> 12 Blond Hazel   10  0  0  0  1  0  0  1  0
> 13 Black Green    5  1  0  0  0  0  0  0  1
> 14 Brown Green   29  0  1  0  0  0  0  0  1
> 15   Red Green   14  0  0  1  0  0  0  0  1
> 16 Blond Green   16  0  0  0  1  0  0  0  1

I think the world would be a better place if you illustrated model.matrix:

 haireye.mtx <- cbind( model.matrix(~0+Hair, as.data.frame(haireye) ),
 model.matrix(~0+Eye, as.data.frame(haireye) ) )
 colnames(haireye.mtx) <- gsub("[a-z]+", "", colnames(haireye.mtx)  )

> haireye.df2
   HB HB HR HB EB EB EH EG
1   1  0  0  0  1  0  0  0
2   0  1  0  0  1  0  0  0
3   0  0  1  0  1  0  0  0
4   0  0  0  1  1  0  0  0
5   1  0  0  0  0  1  0  0
6   0  1  0  0  0  1  0  0
7   0  0  1  0  0  1  0  0
8   0  0  0  1  0  1  0  0
9   1  0  0  0  0  0  1  0
10  0  1  0  0  0  0  1  0
11  0  0  1  0  0  0  1  0
12  0  0  0  1  0  0  1  0
13  1  0  0  0  0  0  0  1
14  0  1  0  0  0  0  0  1
15  0  0  1  0  0  0  0  1
16  0  0  0  1  0  0  0  1

-- 
David.

> >
> 
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Wed Dec 31 01:16:02 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 30 Dec 2014 19:16:02 -0500
Subject: [R] simplify code for dummy coding of factors
In-Reply-To: <54A32FA0.5010004@yorku.ca>
References: <54A32FA0.5010004@yorku.ca>
Message-ID: <CAGx1TMBbTi3c+o2VVEqOaFVVmSSZpW0SeyoWPCqZ3u9H9Hvk1g@mail.gmail.com>

I like this very simple version.  Note that you don't need as.data.frame().

model.matrix(Freq ~ Hair + Eye, data=haireye,
contrasts.arg=list(Hair=diag(4), Eye=diag(4)))

On Tue, Dec 30, 2014 at 6:05 PM, Michael Friendly <friendly at yorku.ca> wrote:
> In a manuscript, I have the following code to illustrate dummy coding of two
> factors in a contingency table.
>
> It works, but is surely obscured by the method I used, involving outer() to
> find equalities and 0+outer()
> to convert to numeric.  Can someone help simplify this code to be more
> comprehensible and give the
> *same* result? I'd prefer a solution that uses base R.
>
> haireye <- margin.table(HairEyeColor, 1:2)
>
> haireye.df <- as.data.frame(haireye)
> dummy.hair <-  0+outer(haireye.df$Hair, levels(haireye.df$Hair), `==`)
> colnames(dummy.hair)  <- paste0('h', 1:4)
> dummy.eye <-  0+outer(haireye.df$Eye, levels(haireye.df$Eye), `==`)
> colnames(dummy.eye)  <- paste0('e', 1:4)
>
> haireye.df <- data.frame(haireye.df, dummy.hair, dummy.eye)
> haireye.df
>
>> haireye.df
>     Hair   Eye Freq h1 h2 h3 h4 e1 e2 e3 e4
> 1  Black Brown   68  1  0  0  0  1  0  0  0
> 2  Brown Brown  119  0  1  0  0  1  0  0  0
> 3    Red Brown   26  0  0  1  0  1  0  0  0
> 4  Blond Brown    7  0  0  0  1  1  0  0  0
> 5  Black  Blue   20  1  0  0  0  0  1  0  0
> 6  Brown  Blue   84  0  1  0  0  0  1  0  0
> 7    Red  Blue   17  0  0  1  0  0  1  0  0
> 8  Blond  Blue   94  0  0  0  1  0  1  0  0
> 9  Black Hazel   15  1  0  0  0  0  0  1  0
> 10 Brown Hazel   54  0  1  0  0  0  0  1  0
> 11   Red Hazel   14  0  0  1  0  0  0  1  0
> 12 Blond Hazel   10  0  0  0  1  0  0  1  0
> 13 Black Green    5  1  0  0  0  0  0  0  1
> 14 Brown Green   29  0  1  0  0  0  0  0  1
> 15   Red Green   14  0  0  1  0  0  0  0  1
> 16 Blond Green   16  0  0  0  1  0  0  0  1
>>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Dec 31 01:18:10 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 30 Dec 2014 16:18:10 -0800 (PST)
Subject: [R] simplify code for dummy coding of factors
In-Reply-To: <54A32FA0.5010004@yorku.ca>
References: <54A32FA0.5010004@yorku.ca>
Message-ID: <alpine.BSF.2.00.1412301607570.36455@pedal.dcn.davis.ca.us>

"More comprehensible" depends on context, which we don't have. You could 
be simply trying to illustrate the logic of the transformation (solution 1 
below) or providing a recipe which by its brevity is (perhaps?) memorable 
(solution 2 below).

Solution 1:

appendDummys <- function( DF, keycol, d.base ) {
   # get levels of key column
   lvls <- levels( DF[[ keycol ]] )
   # for each level in the key column
   keyno <- 1L
   for ( keylvl in lvls ) {
     # name for new column
     dname <- paste0( d.base, keyno )
     # make the new column, filled with default value
     DF[[ dname ]] <- 0L
     # change those values in the new column where the value matches the
     # current level
     DF[ keylvl == DF[[ keycol ]], dname ] <- 1L
     # prepare for next loop
     keyno <- keyno + 1L
   }
   # return modified data frame
   DF
}

haireye <- margin.table(HairEyeColor, 1:2)
haireye.df <- as.data.frame(haireye)
haireye.df <- appendDummys( haireye.df, "Hair", "h" )
haireye.df <- appendDummys( haireye.df, "Eye", "e" )

###
Solution 2

haireye <- margin.table(HairEyeColor, 1:2)
haireye.df <- as.data.frame(haireye)
dummykeys <- data.frame( h = factor( as.integer( haireye.df$Hair ) )
                        , e = factor( as.integer( haireye.df$Eye ) ) )
dummy.hair <- as.data.frame( model.matrix( ~ h - 1 ), data=dummykeys )
dummy.eye <- as.data.frame( model.matrix( ~ e - 1 ), data=dummykeys )
haireye.df <- data.frame( haireye.df, dummy.hair, dummy.eye )

###

FWIW I am not a fan of mixing the model matrix columns in with the 
original data... the column names can (in general) clash.

On Tue, 30 Dec 2014, Michael Friendly wrote:

> In a manuscript, I have the following code to illustrate dummy coding of two 
> factors in a contingency table.
>
> It works, but is surely obscured by the method I used, involving outer() to 
> find equalities and 0+outer()
> to convert to numeric.  Can someone help simplify this code to be more 
> comprehensible and give the
> *same* result? I'd prefer a solution that uses base R.
>
> haireye <- margin.table(HairEyeColor, 1:2)
>
> haireye.df <- as.data.frame(haireye)
> dummy.hair <-  0+outer(haireye.df$Hair, levels(haireye.df$Hair), `==`)
> colnames(dummy.hair)  <- paste0('h', 1:4)
> dummy.eye <-  0+outer(haireye.df$Eye, levels(haireye.df$Eye), `==`)
> colnames(dummy.eye)  <- paste0('e', 1:4)
>
> haireye.df <- data.frame(haireye.df, dummy.hair, dummy.eye)
> haireye.df
>
>> haireye.df
>    Hair   Eye Freq h1 h2 h3 h4 e1 e2 e3 e4
> 1  Black Brown   68  1  0  0  0  1  0  0  0
> 2  Brown Brown  119  0  1  0  0  1  0  0  0
> 3    Red Brown   26  0  0  1  0  1  0  0  0
> 4  Blond Brown    7  0  0  0  1  1  0  0  0
> 5  Black  Blue   20  1  0  0  0  0  1  0  0
> 6  Brown  Blue   84  0  1  0  0  0  1  0  0
> 7    Red  Blue   17  0  0  1  0  0  1  0  0
> 8  Blond  Blue   94  0  0  0  1  0  1  0  0
> 9  Black Hazel   15  1  0  0  0  0  0  1  0
> 10 Brown Hazel   54  0  1  0  0  0  0  1  0
> 11   Red Hazel   14  0  0  1  0  0  0  1  0
> 12 Blond Hazel   10  0  0  0  1  0  0  1  0
> 13 Black Green    5  1  0  0  0  0  0  0  1
> 14 Brown Green   29  0  1  0  0  0  0  0  1
> 15   Red Green   14  0  0  1  0  0  0  0  1
> 16 Blond Green   16  0  0  0  1  0  0  0  1
>>
>
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From friendly at yorku.ca  Wed Dec 31 03:15:06 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 30 Dec 2014 21:15:06 -0500
Subject: [R] simplify code for dummy coding of factors
In-Reply-To: <CAGx1TMBbTi3c+o2VVEqOaFVVmSSZpW0SeyoWPCqZ3u9H9Hvk1g@mail.gmail.com>
References: <54A32FA0.5010004@yorku.ca>
	<CAGx1TMBbTi3c+o2VVEqOaFVVmSSZpW0SeyoWPCqZ3u9H9Hvk1g@mail.gmail.com>
Message-ID: <54A35C2A.1080005@yorku.ca>

On 12/30/14 7:16 PM, Richard M. Heiberger wrote:
> I like this very simple version.  Note that you don't need as.data.frame().
>
> model.matrix(Freq ~ Hair + Eye, data=haireye,
> contrasts.arg=list(Hair=diag(4), Eye=diag(4)))
Thanks to all who replied to this question.  model.matrix() was what I 
had missed, but to
get the result in the form I wanted, required a bit  more work. These 
solutions give me
what I asked for.

haireye <- margin.table(HairEyeColor, 1:2)

# Jeff Newmiller, solution 2, corrected

haireye.df <- as.data.frame(haireye)
dummykeys <- data.frame( h = factor( as.integer( haireye.df$Hair ) )
                        , e = factor( as.integer( haireye.df$Eye ) ) )
dummy.hair <- as.data.frame( model.matrix( ~ h - 1, data=dummykeys ))
dummy.eye <- as.data.frame( model.matrix( ~ e - 1, data=dummykeys ))
haireye.df <- data.frame( haireye.df, dummy.hair, dummy.eye )


# Rich Heiberger, removing intercept, including haireye data
haireye.df <- as.data.frame(haireye)
haireye.df <- cbind(
     haireye.df,
     model.matrix(Freq ~ Hair + Eye, data=haireye,
         contrasts.arg=list(Hair=diag(4), Eye=diag(4)))[,-1]
     )
haireye.df



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From rmh at temple.edu  Wed Dec 31 04:16:27 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 30 Dec 2014 22:16:27 -0500
Subject: [R] simplify code for dummy coding of factors
In-Reply-To: <54A35C2A.1080005@yorku.ca>
References: <54A32FA0.5010004@yorku.ca>
	<CAGx1TMBbTi3c+o2VVEqOaFVVmSSZpW0SeyoWPCqZ3u9H9Hvk1g@mail.gmail.com>
	<54A35C2A.1080005@yorku.ca>
Message-ID: <CAGx1TMB8+b2GJ7amHuV7mGvGA26KXs1Q0mdj0CPt+KMSMXRLrQ@mail.gmail.com>

It can handle one more simplification step

# Rich Heiberger, removing intercept, including haireye data
haireye.df <- cbind(
    as.data.frame(haireye),
    model.matrix(Freq ~ Hair + Eye, data=haireye,
        contrasts.arg=list(Hair=diag(4), Eye=diag(4)))[,-1]
    )
haireye.df

On Tue, Dec 30, 2014 at 9:15 PM, Michael Friendly <friendly at yorku.ca> wrote:
> On 12/30/14 7:16 PM, Richard M. Heiberger wrote:
>>
>> I like this very simple version.  Note that you don't need
>> as.data.frame().
>>
>> model.matrix(Freq ~ Hair + Eye, data=haireye,
>> contrasts.arg=list(Hair=diag(4), Eye=diag(4)))
>
> Thanks to all who replied to this question.  model.matrix() was what I had
> missed, but to
> get the result in the form I wanted, required a bit  more work. These
> solutions give me
> what I asked for.
>
> haireye <- margin.table(HairEyeColor, 1:2)
>
> # Jeff Newmiller, solution 2, corrected
>
> haireye.df <- as.data.frame(haireye)
> dummykeys <- data.frame( h = factor( as.integer( haireye.df$Hair ) )
>                        , e = factor( as.integer( haireye.df$Eye ) ) )
> dummy.hair <- as.data.frame( model.matrix( ~ h - 1, data=dummykeys ))
> dummy.eye <- as.data.frame( model.matrix( ~ e - 1, data=dummykeys ))
> haireye.df <- data.frame( haireye.df, dummy.hair, dummy.eye )
>
>
> # Rich Heiberger, removing intercept, including haireye data
> haireye.df <- as.data.frame(haireye)
> haireye.df <- cbind(
>     haireye.df,
>     model.matrix(Freq ~ Hair + Eye, data=haireye,
>         contrasts.arg=list(Hair=diag(4), Eye=diag(4)))[,-1]
>     )
> haireye.df
>
>
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>


From jholtman at gmail.com  Wed Dec 31 07:08:31 2014
From: jholtman at gmail.com (jim holtman)
Date: Tue, 30 Dec 2014 22:08:31 -0800
Subject: [R] Moving average
In-Reply-To: <005601d022bb$c071da20$41558e60$@se>
References: <003f01d022ae$6dc008e0$49401aa0$@se>
	<CAAxdm-5M8o8dYcWr7Gow2za3rbMYMDN2A9pcJM+ZEcwwYVLw1A@mail.gmail.com>
	<005601d022bb$c071da20$41558e60$@se>
Message-ID: <CAAxdm-7XJUVY8buwUwcCErVH-ghVQau_TErTANhyTYLnBi=pXw@mail.gmail.com>

Try this:

> x <- read.csv(text = "Date,Open,High,Low,Close,Volume,Adj Close
+ 2014-12-26,162.27,163.09,162.01,162.34,1912200,162.34
+ 2014-12-24,162.88,162.99,161.61,161.82,1868100,161.82
+ 2014-12-23,162.23,162.90,161.61,162.24,4043300,162.24
+ 2014-12-22,158.33,161.91,158.33,161.44,4682500,161.44", as.is = TRUE)
> require(lubridate)
> x$Date <- ymd(x$Date)  # convert to a date field
> x <- x[order(x$Date), ]  # sort by date
> x$two_day <- filter(x$Close, c(0.5, 0.5))  # compute moving average
> x
        Date   Open   High    Low  Close  Volume Adj.Close two_day
4 2014-12-22 158.33 161.91 158.33 161.44 4682500    161.44  161.84
3 2014-12-23 162.23 162.90 161.61 162.24 4043300    162.24  162.03
2 2014-12-24 162.88 162.99 161.61 161.82 1868100    161.82  162.08
1 2014-12-26 162.27 163.09 162.01 162.34 1912200    162.34      NA




Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Dec 28, 2014 at 8:31 AM, Rolf Edberg <rolfe at algonet.se> wrote:

> Thank you for trying to help!!
>
>
>
> I am very new to the R code. So need help with every step.
>
>
>
> The goal is to use technical analysis on stock prices. Not only MA but if
> I understand the principle with that I hope I can use the other techniques
> as well.
>
>
>
> I found R-adamant but do not know how to use it.
>
>
>
> I downloaded 4 days of IBM prices from yahoo in a csv-file..
>
> I don?t know what ?dput? is.
>
>
>
> Here is the IBM prices in a text string:
>
> Date,Open,High,Low,Close,Volume,Adj Close
>
> 2014-12-26,162.27,163.09,162.01,162.34,1912200,162.34
>
> 2014-12-24,162.88,162.99,161.61,161.82,1868100,161.82
>
> 2014-12-23,162.23,162.90,161.61,162.24,4043300,162.24
>
> 2014-12-22,158.33,161.91,158.33,161.44,4682500,161.44
>
>
>
> I would like the date in sorted with the oldest at the top.
>
>
>
> I would like to add a column with the technical indicator, in this case
> 2-days MA of Close.
>
>
>
> And I would like to have the result in a csv file. I will use the file in
> another program.
>
>
>
> Thank you !!
>
>
>
> Rolf
>
>
>
> *From:* jim holtman [mailto:jholtman at gmail.com]
> *Sent:* Sunday, December 28, 2014 4:45 PM
> *To:* Rolf Edberg
> *Cc:* R mailing list
> *Subject:* Re: [R] Moving average
>
>
>
> could not read the data you posted; try 'dput' next time.
>
>
>
> If it is just a 2 day moving average, try the 'filter' function:
>
>
>
> > x <- 1:20
>
> > x
>
>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
>
> > filter(x, c(.5,.5))
>
> Time Series:
>
> Start = 1
>
> End = 20
>
> Frequency = 1
>
>  [1]  1.5  2.5  3.5  4.5  5.5  6.5  7.5  8.5  9.5 10.5 11.5 12.5 13.5 14.5
> 15.5 16.5 17.5 18.5 19.5   NA
>
> >
>
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
>
> On Sun, Dec 28, 2014 at 6:56 AM, Rolf Edberg <rolfe at algonet.se> wrote:
>
>
>
> How do I add a new column with 2-days moving average (from
> r-adamant(https://github.com/TotallyBullshit/radamant)) on IBM prices in a
> csv-file (ibm.csv) and then save all in a new csv file(ibm2.csv)?
>
>
>
>
> Prices
>
>
>
>
>
> Date
>
> Open
>
> High
>
> Low
>
> Close
>
> Volume
>
> Adj Close*
>
>
> Dec 26, 2014
>
> 162.27
>
> 163.09
>
> 162.01
>
> 162.34
>
> 1,912,200
>
> 162.34
>
>
> Dec 24, 2014
>
> 162.88
>
> 162.99
>
> 161.61
>
> 161.82
>
> 1,868,100
>
> 161.82
>
>
> Dec 23, 2014
>
> 162.23
>
> 162.90
>
> 161.61
>
> 162.24
>
> 4,043,300
>
> 162.24
>
>
> Dec 22, 2014
>
> 158.33
>
> 161.91
>
> 158.33
>
> 161.44
>
> 4,682,500
>
> 161.44
>
>
> Dec 19, 2014
>
> 157.49
>
> 160.41
>
> 157.49
>
> 158.51
>
> 8,864,900
>
> 158.51
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Wed Dec 31 08:27:30 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Wed, 31 Dec 2014 10:27:30 +0300
Subject: [R] Problem in R2WinBUGS
Message-ID: <CABLo8nExsrfFZ_tDr67fyWtX5ya3msAaLvM4W_xtCq9+s7FBqA@mail.gmail.com>

Dear all members
I have a problem with the code below when i wanted to change the continuous
random variables to mixed ordered categorical and dichotomous as follow

 #transform theta to ordinal variables
       yo <- array(0, dim=c(i,5,100))
       for(j in 1:5){
       if(v[j] < 0.25){
       yo[i,j,t] = 1
       }else if(v[j] >=0.25 & v[j] < 0.5){
       yo[i,j,t] = 2
       }else if(v[j] >=0.5 & v[j] < 0.75){
       yo[i,j,t] = 3
       }else{
       yo[i,j,t] = 4
       }
       }}

    #transform theta1 to dichotomousvariables
    for (j in 6:9) { if (v[j]>0) yo[i,j,t]<-1 else yo[i,j,t]<-0 }

i found this error


*Error in yo[i, j, t] <- 1 : subscript out of bounds*



any Guidance would highly appreciated.

Regards
-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Wed Dec 31 08:40:01 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 08:40:01 +0100
Subject: [R] which is faster "for" or "apply"
Message-ID: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>

Hi All,
I would like to choice between these two data frame convert. which is
faster?

   for(i in 1:ncol(DataFrame)){

                    DataFrame[,i] <- as.numeric(DataFrame[,i])
                }


OR

DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x) as.numeric(x)))


Thanks
Karim
  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Wed Dec 31 08:54:10 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 31 Dec 2014 08:54:10 +0100
Subject: [R] Problem in R2WinBUGS
In-Reply-To: <CABLo8nExsrfFZ_tDr67fyWtX5ya3msAaLvM4W_xtCq9+s7FBqA@mail.gmail.com>
References: <CABLo8nExsrfFZ_tDr67fyWtX5ya3msAaLvM4W_xtCq9+s7FBqA@mail.gmail.com>
Message-ID: <20AFE765-ACB1-4124-9973-3485089CE8DC@xs4all.nl>


> On 31-12-2014, at 08:27, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
> Dear all members
> I have a problem with the code below when i wanted to change the continuous
> random variables to mixed ordered categorical and dichotomous as follow
> 
> #transform theta to ordinal variables
>       yo <- array(0, dim=c(i,5,100))
>       for(j in 1:5){
>       if(v[j] < 0.25){
>       yo[i,j,t] = 1
>       }else if(v[j] >=0.25 & v[j] < 0.5){
>       yo[i,j,t] = 2
>       }else if(v[j] >=0.5 & v[j] < 0.75){
>       yo[i,j,t] = 3
>       }else{
>       yo[i,j,t] = 4
>       }
>       }}
> 
>    #transform theta1 to dichotomousvariables
>    for (j in 6:9) { if (v[j]>0) yo[i,j,t]<-1 else yo[i,j,t]<-0 }
> 
> i found this error
> 
> 
> *Error in yo[i, j, t] <- 1 : subscript out of bounds*
> 
> 
> 
> any Guidance would highly appreciated.
> 

How can we? You have not provided sufficient information.
Where are i and t given values? What are the values?

Why don?t you just try print(i) and print(t) before the  for (j in 6:9) ?

Also have a look at the expression creating y0.
You specify 5 columns.
In the final loop you assign to column j with values starting at 6 and ending at 9; larger than 5.

Berend

> Regards
> -- 
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Wed Dec 31 08:54:58 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 31 Dec 2014 08:54:58 +0100
Subject: [R] which is faster "for" or "apply"
In-Reply-To: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
Message-ID: <857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>


> On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> 
> Hi All,
> I would like to choice between these two data frame convert. which is
> faster?
> 
>   for(i in 1:ncol(DataFrame)){
> 
>                    DataFrame[,i] <- as.numeric(DataFrame[,i])
>                }
> 
> 
> OR
> 
> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x) as.numeric(x)))
> 
> 

Try it and use system.time.

Berend

> Thanks
> Karim
>  ?__
> c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Wed Dec 31 09:22:58 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 09:22:58 +0100
Subject: [R] Fwd:  which is faster "for" or "apply"
In-Reply-To: <CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
Message-ID: <CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>

Thanks,
It seems for loop spends less time ;)

with
dim(DataFrame)
[1] 338  70

For loop has
   user  system elapsed
  0.012   0.000   0.012

and apply has
  user  system elapsed
  0.020   0.000   0.021

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> >
> > Hi All,
> > I would like to choice between these two data frame convert. which is
> > faster?
> >
> >   for(i in 1:ncol(DataFrame)){
> >
> >                    DataFrame[,i] <- as.numeric(DataFrame[,i])
> >                }
> >
> >
> > OR
> >
> > DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x) as.numeric(x)))
> >
> >
>
> Try it and use system.time.
>
> Berend
>
> > Thanks
> > Karim
> >  ?__
> > c/ /'_;~~~~kmezhoud
> > (*) \(*)   ?????  ??????
> > http://bioinformatics.tn/
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Dec 31 09:45:03 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 31 Dec 2014 00:45:03 -0800 (PST)
Subject: [R] rle with data.table - is it possible?
In-Reply-To: <CAE6QMsb2bvS_xKEu41Qa1GSQ2x6xPMiwK0=s1zSMcWNWq2MJKQ@mail.gmail.com>
References: <CAE6QMsb2bvS_xKEu41Qa1GSQ2x6xPMiwK0=s1zSMcWNWq2MJKQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1412301726280.36455@pedal.dcn.davis.ca.us>

I do not understand the value of using the rle function in your 
description, but the code below appears to produce the table you want.

Note that better support for the data.table package might be found at 
stackexchange as the documentation specifies.

x <- read.table( text=
"Dad Mum Child Group
AA RR RA A
AA RR RR A
AA AA AA B
AA AA AA B
RA AA RR B
RR AA RR B
AA AA AA B
AA AA RA C
AA AA RA C
AA RR RA C
", header=TRUE, stringsAsFactors=FALSE )

library(data.table)
DT <- data.table( x )
DT[ , cdad := as.integer( Dad %in% c( "AA", "RR" ) ) ]
DT[ , sumdad := 0L ]
DT[ 1==DT$cdad, sumdad := sum( cdad ), by=Group ]
DT[ , cdad := NULL ]
DT[ , cmum := as.integer( Mum %in% c( "AA", "RR" ) ) ]
DT[ , summum := 0L ]
DT[ 1==DT$cmum, summum := sum( cmum ), by=Group ]
DT[ , cmum := NULL ]
DT[ , cchild := as.integer( Child %in% c( "AA", "RR" ) ) ]
DT[ , sumchild := 0L ]
DT[ 1==DT$cchild, sumchild := sum( cchild ), by=Group ]
DT[ , cchild := NULL ]

>DT
     Dad Mum Child Group sumdad summum sumchild
  1:  AA  RR    RA     A      2      2        0
  2:  AA  RR    RR     A      2      2        1
  3:  AA  AA    AA     B      4      5        5
  4:  AA  AA    AA     B      4      5        5
  5:  RA  AA    RR     B      0      5        5
  6:  RR  AA    RR     B      4      5        5
  7:  AA  AA    AA     B      4      5        5
  8:  AA  AA    RA     C      3      3        0
  9:  AA  AA    RA     C      3      3        0
10:  AA  RR    RA     C      3      3        0

On Tue, 30 Dec 2014, Kate Ignatius wrote:

> I'm trying to use both these packages and wondering whether they are possible...
>
> To make this simple, my ultimate goal is determine long stretches of
> 1s, but I want to do this within groups (hence using the data.table as
> I use the "set key" option.  However, I'm I'm not having much luck
> making this possible.
>
> For example, for simplistic sake, I have the following data:
>
> Dad Mum Child Group
> AA RR RA A
> AA RR RR A
> AA AA AA B
> AA AA AA B
> RA AA RR B
> RR AA RR B
> AA AA AA B
> AA AA RA C
> AA AA RA C
> AA RR RA  C
>
> And the following code which I know works
>
> hetdad <- as.numeric(x[c(1)]=="AA" | x[c(1)]=="RR")
> sumdad <- rle(hetdad)$lengths[rle(hetdad)$values==1]
>
> hetmum <- as.numeric(x[c(2)]=="AA" | x[c(2)]=="RR")
> summum <- rle(hetmum)$lengths[rle(hetmum)$values==1]
>
> hetchild <- as.numeric(x[c(3)]=="AA" | x[c(3)]=="RR")
> sumchild <- rle(hetchild)$lengths[rle(hetchild)$values==1]
>
> However, I wish to do the above code by Group (though this file is
> millions of rows long and groups will be larger but just wanted to
> simply the example).
>
> I did something like this but of course I got an error:
>
> LOH[,hetdad:=as.numeric(x[c(1)]=="AA" | x[c(1)]=="RR")]
> LOH[,sumdad:=rle(hetdad)$lengths[rle(hetdad)$values==1],by=Group]
> LOH[,hetmum:=as.numeric(x[c(2)]=="AA" | x[c(2)]=="RR")]
> LOH[,summum:=rle(hetmum)$lengths[rle(hetmum)$values==1],by=Group]
> LOH[,hetchild:=as.numeric(x[c(3)]=="AA" | x[c(3)]=="RR")]
> LOH[,sumchild:=rle(hetchild)$lengths[rle(hetchild)$values==1],by=Group]
>
> The reason being as I want to eventually have something like this:
>
> Dad Mum Child Group sumdad summum sumchild
> AA RR RA A 2 2 0
> AA RR RR A 2 2 1
> AA AA AA B 4 5 5
> AA AA AA B 4 5 5
> RA AA RR B 0 5 5
> RR AA RR B 4 5 5
> AA AA AA B 4 5 5
> AA AA RA C 3 3 0
> AA AA RA C 3 3 0
> AA RR RA  C 3 3 0
>
> That is, I would like to have the specific counts next to what I'm
> consecutively counting per group.  So for Group A for dad there are 2
> AAs,  there are two RRs for mum but only 1 AA or RR for the child and
> that is RR (so the 1 is next to the RR and not the RA).
>
> Can this be done?
>
> K.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From bhh at xs4all.nl  Wed Dec 31 10:57:12 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 31 Dec 2014 10:57:12 +0100
Subject: [R] Problem in R2WinBUGS
In-Reply-To: <CABLo8nE1Xc7UCunMSs-OhFO3mcW9wHkuDWUBwFZWXPgufe=zLQ@mail.gmail.com>
References: <CABLo8nExsrfFZ_tDr67fyWtX5ya3msAaLvM4W_xtCq9+s7FBqA@mail.gmail.com>
	<20AFE765-ACB1-4124-9973-3485089CE8DC@xs4all.nl>
	<CABLo8nE1Xc7UCunMSs-OhFO3mcW9wHkuDWUBwFZWXPgufe=zLQ@mail.gmail.com>
Message-ID: <37A86821-1D40-47EB-A3D6-49F5AC051A41@xs4all.nl>



You should reply to the R-help list and not only to me .
yo in your answer to me does not correspond with the original mail.

It?s not possible to make sense of your code.

Berend

> On 31-12-2014, at 10:14, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> 
> thank you for your response
> N<-2000; P<-9
> 
> yo<-matrix(data=NA,nrow=N,ncol=P); p<-numeric(P); v<-numeric(P)
> 
> I want to change the continuous variables to mixed ordered categorical and dichotomous 
> 
> from 1:5 ordered categorical 
> from 6:9 dichotomous
> 
> 
> Regards
> 
> On 31 December 2014 at 10:54, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> > On 31-12-2014, at 08:27, thanoon younis <thanoon.younis80 at gmail.com> wrote:
> >
> > Dear all members
> > I have a problem with the code below when i wanted to change the continuous
> > random variables to mixed ordered categorical and dichotomous as follow
> >
> > #transform theta to ordinal variables
> >       yo <- array(0, dim=c(i,5,100))
> >       for(j in 1:5){
> >       if(v[j] < 0.25){
> >       yo[i,j,t] = 1
> >       }else if(v[j] >=0.25 & v[j] < 0.5){
> >       yo[i,j,t] = 2
> >       }else if(v[j] >=0.5 & v[j] < 0.75){
> >       yo[i,j,t] = 3
> >       }else{
> >       yo[i,j,t] = 4
> >       }
> >       }}
> >
> >    #transform theta1 to dichotomousvariables
> >    for (j in 6:9) { if (v[j]>0) yo[i,j,t]<-1 else yo[i,j,t]<-0 }
> >
> > i found this error
> >
> >
> > *Error in yo[i, j, t] <- 1 : subscript out of bounds*
> >
> >
> >
> > any Guidance would highly appreciated.
> >
> 
> How can we? You have not provided sufficient information.
> Where are i and t given values? What are the values?
> 
> Why don?t you just try print(i) and print(t) before the  for (j in 6:9) ?
> 
> Also have a look at the expression creating y0.
> You specify 5 columns.
> In the final loop you assign to column j with values starting at 6 and ending at 9; larger than 5.
> 
> Berend
> 
> > Regards
> > --
> > Thanoon Y. Thanoon
> > PhD Candidate
> > Department of Mathematical Sciences
> > Faculty of Science
> > University Technology Malaysia, UTM
> > E.Mail: Thanoon.younis80 at gmail.com
> > E.Mail: dawn_prayer80 at yahoo.com
> > Facebook:Thanoon Younis AL-Shakerchy
> > Twitter: Thanoon Alshakerchy
> > H.P:00601127550205
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> 
> -- 
> Thanoon Y. Thanoon
> PhD Candidate 
> Department of Mathematical Sciences 
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205


From mtmorgan at fredhutch.org  Wed Dec 31 14:38:35 2014
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Wed, 31 Dec 2014 05:38:35 -0800
Subject: [R] Fwd:  which is faster "for" or "apply"
In-Reply-To: <CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
Message-ID: <54A3FC5B.9050809@fredhutch.org>

On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
> Thanks,
> It seems for loop spends less time ;)
>
> with
> dim(DataFrame)
> [1] 338  70
>
> For loop has
>     user  system elapsed
>    0.012   0.000   0.012
>
> and apply has
>    user  system elapsed
>    0.020   0.000   0.021

The timings are so short that the answer in terms of speed is 'it does not matter'.

Here is a selection of approaches

f0 <- function(df) {
     for (i in seq_along(df))
         df[,i] <- as.numeric(df[,i])
     df
}

f0a <- function(df) {
     ## data.frame is a list-of-equal-length vectors; access each
     ## column with "[["
     for (i in seq_along(df))
         df[[i]] <- as.numeric(df[[i]])
     df
}

f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from compilation

f1 <- function(df)
     as.data.frame(apply(df, 2, as.numeric))

f2 <- function(df) {
     ## replace all columns of df with list-of-vectors
     df[] <- lapply(df, as.numeric)
     df
}

f3 <- function(df) {
     ## coerce to matrix to avoid the explicit loop, use mode<- to
     ## change storage of elements
     m <- as.matrix(df)
     mode(m) <- "numeric"
     as.data.frame(m)
}

f4 <- function(df) {
     ## if it's a matrix, why are we returning a data.frame?
     m <- as.matrix(df)
     mode(m) <- "numeric"
     m
}

f4a <- function(df)
     ## unlist to single vector, coerce, then format as matrix
     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
            dimnames=dimnames(df))

It's important to test that different methods return the same result (perhaps 
allowing for differences in attributes such as row or column names). The 
microbenchmark package repeats timings across multiple trials (default 100 times).

library(microbenchmark)
test <- function(df) {
     stopifnot(
         identical(f0(df), f0a(df)),
         identical(f0(df), f0c(df)),
         identical(f0(df), f1(df)),
         identical(f0(df), f2(df)),
         identical(f0(df), f3(df)),
         identical(as.matrix(f0(df)), f4(df)),
         all.equal(f4(df), f4a(df), check.attributes=FALSE))
     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df), f4a(df))
}

Here are some data sets

m <- matrix(rnorm(338 * 70), 338)
df <- as.data.frame(m)
dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
dff <- as.data.frame(lapply(df, as.character))

and results

 > test(df)
Unit: microseconds
     expr      min        lq      mean    median        uq      max neval
   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281   100
  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618   100
  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116   100
   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229   100
   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732   100
   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584   100
   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977   100
  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443   100
 > test(dfc)
Unit: milliseconds
     expr       min        lq      mean    median        uq       max neval
   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622   100
  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026   100
  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766   100
   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499   100
   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758   100
   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274   100
   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601   100
  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081   100
 > test(dff)
Error: identical(f0(df), f1(df)) is not TRUE

Except when dealing with factors, the use of explicit loops is the slowest. With 
factors, matrix-based methods coerce the level labels to numeric, whereas 
vector-based methods coerce the underlying codes (level values) of the factor; 
obviously great care needs to be taken.

 > f0(dff)[1:5, 1:5]
    V1  V2  V3  V4  V5
1 150 232 294  88  56
2 159   8  89  59  10
3 132 171  40 205 119
4 214 273  26 262 216
5 281  49 255  31 233
 > f1(dff)[1:5, 1:5]
           V1          V2         V3         V4          V5
1 -1.7092463  0.50234009  0.8492982 -0.5636901 -0.38545566
2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
3 -1.2915110 -2.46181533 -0.2470108  0.3301129 -1.06810225
4  0.3065989  0.89263099 -0.1717432  0.7721411  0.35856334
5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149

In terms of 'best practice', I would represent my data in the appropriate data 
structure in the first place (as a matrix of appropriate type, rather than 
data.frame, so the entire coercion is irrelevant). If faced with a data.frame 
with specific columns to coerce I would use the approach

     cidx <- sapply(df, is.character)      # index of columns to coerce
     df[cidx] <- lapply(df[cidx], as.numeric)

which seems to be reasonably correct, expressive, compact, and speedy.

Martin Morgan

>
>    ?__
>   c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
>>
>>> On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>>
>>> Hi All,
>>> I would like to choice between these two data frame convert. which is
>>> faster?
>>>
>>>    for(i in 1:ncol(DataFrame)){
>>>
>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
>>>                 }
>>>
>>>
>>> OR
>>>
>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x) as.numeric(x)))
>>>
>>>
>>
>> Try it and use system.time.
>>
>> Berend
>>
>>> Thanks
>>> Karim
>>>   ?__
>>> c/ /'_;~~~~kmezhoud
>>> (*) \(*)   ?????  ??????
>>> http://bioinformatics.tn/
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From Achim.Zeileis at uibk.ac.at  Wed Dec 31 14:58:06 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 31 Dec 2014 14:58:06 +0100
Subject: [R] Moving average
In-Reply-To: <CAAxdm-7XJUVY8buwUwcCErVH-ghVQau_TErTANhyTYLnBi=pXw@mail.gmail.com>
References: <003f01d022ae$6dc008e0$49401aa0$@se>
	<CAAxdm-5M8o8dYcWr7Gow2za3rbMYMDN2A9pcJM+ZEcwwYVLw1A@mail.gmail.com>
	<005601d022bb$c071da20$41558e60$@se>
	<CAAxdm-7XJUVY8buwUwcCErVH-ghVQau_TErTANhyTYLnBi=pXw@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1412311454510.11117@paninaro.uibk.ac.at>

On Tue, 30 Dec 2014, jim holtman wrote:

> Try this:
>
>> x <- read.csv(text = "Date,Open,High,Low,Close,Volume,Adj Close
> + 2014-12-26,162.27,163.09,162.01,162.34,1912200,162.34
> + 2014-12-24,162.88,162.99,161.61,161.82,1868100,161.82
> + 2014-12-23,162.23,162.90,161.61,162.24,4043300,162.24
> + 2014-12-22,158.33,161.91,158.33,161.44,4682500,161.44", as.is = TRUE)
>> require(lubridate)
>> x$Date <- ymd(x$Date)  # convert to a date field
>> x <- x[order(x$Date), ]  # sort by date
>> x$two_day <- filter(x$Close, c(0.5, 0.5))  # compute moving average
>> x
>        Date   Open   High    Low  Close  Volume Adj.Close two_day
> 4 2014-12-22 158.33 161.91 158.33 161.44 4682500    161.44  161.84
> 3 2014-12-23 162.23 162.90 161.61 162.24 4043300    162.24  162.03
> 2 2014-12-24 162.88 162.99 161.61 161.82 1868100    161.82  162.08
> 1 2014-12-26 162.27 163.09 162.01 162.34 1912200    162.34      NA

A canned approach for reading and filtering the data is also available in 
the "zoo" package. The read.zoo() function can directly create a "zoo" 
time series object with "Date" time index:

R> z <- read.zoo(text = "Date,Open,High,Low,Close,Volume,Adj Close
+  2014-12-26,162.27,163.09,162.01,162.34,1912200,162.34
+  2014-12-24,162.88,162.99,161.61,161.82,1868100,161.82
+  2014-12-23,162.23,162.90,161.61,162.24,4043300,162.24
+  2014-12-22,158.33,161.91,158.33,161.44,4682500,161.44",
+  header = TRUE, sep = ",", format = "%Y-%m-%d")

And then rollmean() can compute rolling means for all variables/columns:

R> rollmean(z, 2)
               Open    High    Low  Close  Volume Adj.Close
2014-12-22 160.280 162.405 159.97 161.84 4362900    161.84
2014-12-23 162.555 162.945 161.61 162.03 2955700    162.03
2014-12-24 162.575 163.040 161.81 162.08 1890150    162.08

You can additionally supply the fill = NA argument if you want trailing 
NAs for 2014-12-26.

>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Sun, Dec 28, 2014 at 8:31 AM, Rolf Edberg <rolfe at algonet.se> wrote:
>
>> Thank you for trying to help!!
>>
>>
>>
>> I am very new to the R code. So need help with every step.
>>
>>
>>
>> The goal is to use technical analysis on stock prices. Not only MA but if
>> I understand the principle with that I hope I can use the other techniques
>> as well.
>>
>>
>>
>> I found R-adamant but do not know how to use it.
>>
>>
>>
>> I downloaded 4 days of IBM prices from yahoo in a csv-file..
>>
>> I don?t know what ?dput? is.
>>
>>
>>
>> Here is the IBM prices in a text string:
>>
>> Date,Open,High,Low,Close,Volume,Adj Close
>>
>> 2014-12-26,162.27,163.09,162.01,162.34,1912200,162.34
>>
>> 2014-12-24,162.88,162.99,161.61,161.82,1868100,161.82
>>
>> 2014-12-23,162.23,162.90,161.61,162.24,4043300,162.24
>>
>> 2014-12-22,158.33,161.91,158.33,161.44,4682500,161.44
>>
>>
>>
>> I would like the date in sorted with the oldest at the top.
>>
>>
>>
>> I would like to add a column with the technical indicator, in this case
>> 2-days MA of Close.
>>
>>
>>
>> And I would like to have the result in a csv file. I will use the file in
>> another program.
>>
>>
>>
>> Thank you !!
>>
>>
>>
>> Rolf
>>
>>
>>
>> *From:* jim holtman [mailto:jholtman at gmail.com]
>> *Sent:* Sunday, December 28, 2014 4:45 PM
>> *To:* Rolf Edberg
>> *Cc:* R mailing list
>> *Subject:* Re: [R] Moving average
>>
>>
>>
>> could not read the data you posted; try 'dput' next time.
>>
>>
>>
>> If it is just a 2 day moving average, try the 'filter' function:
>>
>>
>>
>> > x <- 1:20
>>
>> > x
>>
>>  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20
>>
>> > filter(x, c(.5,.5))
>>
>> Time Series:
>>
>> Start = 1
>>
>> End = 20
>>
>> Frequency = 1
>>
>>  [1]  1.5  2.5  3.5  4.5  5.5  6.5  7.5  8.5  9.5 10.5 11.5 12.5 13.5 14.5
>> 15.5 16.5 17.5 18.5 19.5   NA
>>
>> >
>>
>>
>>
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>>
>> On Sun, Dec 28, 2014 at 6:56 AM, Rolf Edberg <rolfe at algonet.se> wrote:
>>
>>
>>
>> How do I add a new column with 2-days moving average (from
>> r-adamant(https://github.com/TotallyBullshit/radamant)) on IBM prices in a
>> csv-file (ibm.csv) and then save all in a new csv file(ibm2.csv)?
>>
>>
>>
>>
>> Prices
>>
>>
>>
>>
>>
>> Date
>>
>> Open
>>
>> High
>>
>> Low
>>
>> Close
>>
>> Volume
>>
>> Adj Close*
>>
>>
>> Dec 26, 2014
>>
>> 162.27
>>
>> 163.09
>>
>> 162.01
>>
>> 162.34
>>
>> 1,912,200
>>
>> 162.34
>>
>>
>> Dec 24, 2014
>>
>> 162.88
>>
>> 162.99
>>
>> 161.61
>>
>> 161.82
>>
>> 1,868,100
>>
>> 161.82
>>
>>
>> Dec 23, 2014
>>
>> 162.23
>>
>> 162.90
>>
>> 161.61
>>
>> 162.24
>>
>> 4,043,300
>>
>> 162.24
>>
>>
>> Dec 22, 2014
>>
>> 158.33
>>
>> 161.91
>>
>> 158.33
>>
>> 161.44
>>
>> 4,682,500
>>
>> 161.44
>>
>>
>> Dec 19, 2014
>>
>> 157.49
>>
>> 160.41
>>
>> 157.49
>>
>> 158.51
>>
>> 8,864,900
>>
>> 158.51
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Wed Dec 31 16:37:57 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 16:37:57 +0100
Subject: [R] Fwd: which is faster "for" or "apply"
In-Reply-To: <54A3FC5B.9050809@fredhutch.org>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
	<54A3FC5B.9050809@fredhutch.org>
Message-ID: <CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>

Many Many Many thanks!
it is a demonstrative lesson. I need time to  test all examples :)
Thank you for your time and support.
Happy and Healthy New Year

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 31, 2014 at 2:38 PM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
>
>> Thanks,
>> It seems for loop spends less time ;)
>>
>> with
>> dim(DataFrame)
>> [1] 338  70
>>
>> For loop has
>>     user  system elapsed
>>    0.012   0.000   0.012
>>
>> and apply has
>>    user  system elapsed
>>    0.020   0.000   0.021
>>
>
> The timings are so short that the answer in terms of speed is 'it does not
> matter'.
>
> Here is a selection of approaches
>
> f0 <- function(df) {
>     for (i in seq_along(df))
>         df[,i] <- as.numeric(df[,i])
>     df
> }
>
> f0a <- function(df) {
>     ## data.frame is a list-of-equal-length vectors; access each
>     ## column with "[["
>     for (i in seq_along(df))
>         df[[i]] <- as.numeric(df[[i]])
>     df
> }
>
> f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from compilation
>
> f1 <- function(df)
>     as.data.frame(apply(df, 2, as.numeric))
>
> f2 <- function(df) {
>     ## replace all columns of df with list-of-vectors
>     df[] <- lapply(df, as.numeric)
>     df
> }
>
> f3 <- function(df) {
>     ## coerce to matrix to avoid the explicit loop, use mode<- to
>     ## change storage of elements
>     m <- as.matrix(df)
>     mode(m) <- "numeric"
>     as.data.frame(m)
> }
>
> f4 <- function(df) {
>     ## if it's a matrix, why are we returning a data.frame?
>     m <- as.matrix(df)
>     mode(m) <- "numeric"
>     m
> }
>
> f4a <- function(df)
>     ## unlist to single vector, coerce, then format as matrix
>     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
>            dimnames=dimnames(df))
>
> It's important to test that different methods return the same result
> (perhaps allowing for differences in attributes such as row or column
> names). The microbenchmark package repeats timings across multiple trials
> (default 100 times).
>
> library(microbenchmark)
> test <- function(df) {
>     stopifnot(
>         identical(f0(df), f0a(df)),
>         identical(f0(df), f0c(df)),
>         identical(f0(df), f1(df)),
>         identical(f0(df), f2(df)),
>         identical(f0(df), f3(df)),
>         identical(as.matrix(f0(df)), f4(df)),
>         all.equal(f4(df), f4a(df), check.attributes=FALSE))
>     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df),
> f4a(df))
> }
>
> Here are some data sets
>
> m <- matrix(rnorm(338 * 70), 338)
> df <- as.data.frame(m)
> dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
> dff <- as.data.frame(lapply(df, as.character))
>
> and results
>
> > test(df)
> Unit: microseconds
>     expr      min        lq      mean    median        uq      max neval
>   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281   100
>  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618   100
>  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116   100
>   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229   100
>   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732   100
>   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584   100
>   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977   100
>  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443   100
> > test(dfc)
> Unit: milliseconds
>     expr       min        lq      mean    median        uq       max neval
>   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622   100
>  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026   100
>  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766   100
>   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499   100
>   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758   100
>   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274   100
>   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601   100
>  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081   100
> > test(dff)
> Error: identical(f0(df), f1(df)) is not TRUE
>
> Except when dealing with factors, the use of explicit loops is the
> slowest. With factors, matrix-based methods coerce the level labels to
> numeric, whereas vector-based methods coerce the underlying codes (level
> values) of the factor; obviously great care needs to be taken.
>
> > f0(dff)[1:5, 1:5]
>    V1  V2  V3  V4  V5
> 1 150 232 294  88  56
> 2 159   8  89  59  10
> 3 132 171  40 205 119
> 4 214 273  26 262 216
> 5 281  49 255  31 233
> > f1(dff)[1:5, 1:5]
>           V1          V2         V3         V4          V5
> 1 -1.7092463 0.50234009  0.8492982 -0.5636901 -0.38545566
> 2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
> 3 -1.2915110 -2.46181533 -0.2470108 0.3301129 -1.06810225
> 4  0.3065989 0.89263099 -0.1717432  0.7721411 0.35856334
> 5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149
>
> In terms of 'best practice', I would represent my data in the appropriate
> data structure in the first place (as a matrix of appropriate type, rather
> than data.frame, so the entire coercion is irrelevant). If faced with a
> data.frame with specific columns to coerce I would use the approach
>
>     cidx <- sapply(df, is.character)      # index of columns to coerce
>     df[cidx] <- lapply(df[cidx], as.numeric)
>
> which seems to be reasonably correct, expressive, compact, and speedy.
>
> Martin Morgan
>
>
>
>>    ?__
>>   c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>
>>
>>>  On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>>>
>>>> Hi All,
>>>> I would like to choice between these two data frame convert. which is
>>>> faster?
>>>>
>>>>    for(i in 1:ncol(DataFrame)){
>>>>
>>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
>>>>                 }
>>>>
>>>>
>>>> OR
>>>>
>>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x)
>>>> as.numeric(x)))
>>>>
>>>>
>>>>
>>> Try it and use system.time.
>>>
>>> Berend
>>>
>>>  Thanks
>>>> Karim
>>>>   ?__
>>>> c/ /'_;~~~~kmezhoud
>>>> (*) \(*)   ?????  ??????
>>>> http://bioinformatics.tn/
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>>
>>> http://www.R-project.org/posting-guide.html
>>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>

	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Wed Dec 31 17:24:19 2014
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Wed, 31 Dec 2014 11:24:19 -0500
Subject: [R] Saving an edited R function - RStudio and R
In-Reply-To: <alpine.DEB.2.11.1412311454510.11117@paninaro.uibk.ac.at>
References: <003f01d022ae$6dc008e0$49401aa0$@se>
	<CAAxdm-5M8o8dYcWr7Gow2za3rbMYMDN2A9pcJM+ZEcwwYVLw1A@mail.gmail.com>
	<005601d022bb$c071da20$41558e60$@se>
	<CAAxdm-7XJUVY8buwUwcCErVH-ghVQau_TErTANhyTYLnBi=pXw@mail.gmail.com>
	<alpine.DEB.2.11.1412311454510.11117@paninaro.uibk.ac.at>
Message-ID: <54A3DCE3020000CB0011E864@smtp.medicine.umaryland.edu>

Windows 7
 
Colleagues,
I used the fix() function to edit an existing function when using RStudio. After editing the function, I am given the option to SAVE the modified function. I would like to know (1) where the modified function is stored (the save button does not have an option to specify where the modified function will be saved), and (2) how I can access the modified function in other RStudio or R sessions, and (3) how I can make the function accessible to R and RStudio sessions run on other computers.
Thank you,
John 
 
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From kmezhoud at gmail.com  Wed Dec 31 17:24:42 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 17:24:42 +0100
Subject: [R] Fwd: which is faster "for" or "apply"
In-Reply-To: <CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
	<54A3FC5B.9050809@fredhutch.org>
	<CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>
Message-ID: <CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>

Concretely I request cbioportal through cgsdr package.
Depending of Cases and Genetic profiles I receive in general data.frame
with heterogeneous structure. The bad one if the returned data.frame is
composed by numeric and character columns. in this case numeric columns are
considered as  factor. It is the case when I explore/extract information
from Clinical Data (Age, gender., tumor stage..). In this case I need to
convert only numeric column and not character ones. I am using
grep("[0-9]*.[0-9]*",df[,i])!=0 {fun to convert}.

 But this heterogeneity  comes even with only supposed numeric data.frame
(gene expression). here an example


library(cgdsr)
GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
,"ATR", "MDC1" ,"PARP1")
cgds<-CGDS("http://www.cbioportal.org/public-portal/")

str(getProfileData(cgds,GeneList,
"stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))

str(getProfileData(cgds,GeneList,
"stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))


With my computer I did not find the same structure (numeric vs factor).

Also I need to preserve row and column names ;)
So I am working to resolve these details depending on data of cbioportal...

Thank you


  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 31, 2014 at 4:37 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Many Many Many thanks!
> it is a demonstrative lesson. I need time to  test all examples :)
> Thank you for your time and support.
> Happy and Healthy New Year
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Wed, Dec 31, 2014 at 2:38 PM, Martin Morgan <mtmorgan at fredhutch.org>
> wrote:
>
>> On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
>>
>>> Thanks,
>>> It seems for loop spends less time ;)
>>>
>>> with
>>> dim(DataFrame)
>>> [1] 338  70
>>>
>>> For loop has
>>>     user  system elapsed
>>>    0.012   0.000   0.012
>>>
>>> and apply has
>>>    user  system elapsed
>>>    0.020   0.000   0.021
>>>
>>
>> The timings are so short that the answer in terms of speed is 'it does
>> not matter'.
>>
>> Here is a selection of approaches
>>
>> f0 <- function(df) {
>>     for (i in seq_along(df))
>>         df[,i] <- as.numeric(df[,i])
>>     df
>> }
>>
>> f0a <- function(df) {
>>     ## data.frame is a list-of-equal-length vectors; access each
>>     ## column with "[["
>>     for (i in seq_along(df))
>>         df[[i]] <- as.numeric(df[[i]])
>>     df
>> }
>>
>> f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from compilation
>>
>> f1 <- function(df)
>>     as.data.frame(apply(df, 2, as.numeric))
>>
>> f2 <- function(df) {
>>     ## replace all columns of df with list-of-vectors
>>     df[] <- lapply(df, as.numeric)
>>     df
>> }
>>
>> f3 <- function(df) {
>>     ## coerce to matrix to avoid the explicit loop, use mode<- to
>>     ## change storage of elements
>>     m <- as.matrix(df)
>>     mode(m) <- "numeric"
>>     as.data.frame(m)
>> }
>>
>> f4 <- function(df) {
>>     ## if it's a matrix, why are we returning a data.frame?
>>     m <- as.matrix(df)
>>     mode(m) <- "numeric"
>>     m
>> }
>>
>> f4a <- function(df)
>>     ## unlist to single vector, coerce, then format as matrix
>>     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
>>            dimnames=dimnames(df))
>>
>> It's important to test that different methods return the same result
>> (perhaps allowing for differences in attributes such as row or column
>> names). The microbenchmark package repeats timings across multiple trials
>> (default 100 times).
>>
>> library(microbenchmark)
>> test <- function(df) {
>>     stopifnot(
>>         identical(f0(df), f0a(df)),
>>         identical(f0(df), f0c(df)),
>>         identical(f0(df), f1(df)),
>>         identical(f0(df), f2(df)),
>>         identical(f0(df), f3(df)),
>>         identical(as.matrix(f0(df)), f4(df)),
>>         all.equal(f4(df), f4a(df), check.attributes=FALSE))
>>     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df),
>> f4a(df))
>> }
>>
>> Here are some data sets
>>
>> m <- matrix(rnorm(338 * 70), 338)
>> df <- as.data.frame(m)
>> dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
>> dff <- as.data.frame(lapply(df, as.character))
>>
>> and results
>>
>> > test(df)
>> Unit: microseconds
>>     expr      min        lq      mean    median        uq      max neval
>>   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281   100
>>  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618   100
>>  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116   100
>>   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229   100
>>   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732   100
>>   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584   100
>>   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977   100
>>  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443   100
>> > test(dfc)
>> Unit: milliseconds
>>     expr       min        lq      mean    median        uq       max neval
>>   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622
>>  100
>>  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026   100
>>  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766
>>  100
>>   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499   100
>>   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758   100
>>   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274   100
>>   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601   100
>>  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081   100
>> > test(dff)
>> Error: identical(f0(df), f1(df)) is not TRUE
>>
>> Except when dealing with factors, the use of explicit loops is the
>> slowest. With factors, matrix-based methods coerce the level labels to
>> numeric, whereas vector-based methods coerce the underlying codes (level
>> values) of the factor; obviously great care needs to be taken.
>>
>> > f0(dff)[1:5, 1:5]
>>    V1  V2  V3  V4  V5
>> 1 150 232 294  88  56
>> 2 159   8  89  59  10
>> 3 132 171  40 205 119
>> 4 214 273  26 262 216
>> 5 281  49 255  31 233
>> > f1(dff)[1:5, 1:5]
>>           V1          V2         V3         V4          V5
>> 1 -1.7092463 0.50234009  0.8492982 -0.5636901 -0.38545566
>> 2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
>> 3 -1.2915110 -2.46181533 -0.2470108 0.3301129 -1.06810225
>> 4  0.3065989 0.89263099 -0.1717432  0.7721411 0.35856334
>> 5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149
>>
>> In terms of 'best practice', I would represent my data in the appropriate
>> data structure in the first place (as a matrix of appropriate type, rather
>> than data.frame, so the entire coercion is irrelevant). If faced with a
>> data.frame with specific columns to coerce I would use the approach
>>
>>     cidx <- sapply(df, is.character)      # index of columns to coerce
>>     df[cidx] <- lapply(df[cidx], as.numeric)
>>
>> which seems to be reasonably correct, expressive, compact, and speedy.
>>
>> Martin Morgan
>>
>>
>>
>>>    ?__
>>>   c/ /'_;~~~~kmezhoud
>>> (*) \(*)   ?????  ??????
>>> http://bioinformatics.tn/
>>>
>>>
>>>
>>> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>
>>>
>>>>  On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>>>>
>>>>> Hi All,
>>>>> I would like to choice between these two data frame convert. which is
>>>>> faster?
>>>>>
>>>>>    for(i in 1:ncol(DataFrame)){
>>>>>
>>>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
>>>>>                 }
>>>>>
>>>>>
>>>>> OR
>>>>>
>>>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x)
>>>>> as.numeric(x)))
>>>>>
>>>>>
>>>>>
>>>> Try it and use system.time.
>>>>
>>>> Berend
>>>>
>>>>  Thanks
>>>>> Karim
>>>>>   ?__
>>>>> c/ /'_;~~~~kmezhoud
>>>>> (*) \(*)   ?????  ??????
>>>>> http://bioinformatics.tn/
>>>>>
>>>>>        [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>>
>>>> http://www.R-project.org/posting-guide.html
>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>>
>>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> --
>> Computational Biology / Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N.
>> PO Box 19024 Seattle, WA 98109
>>
>> Location: Arnold Building M1 B861
>> Phone: (206) 667-2793
>>
>
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Wed Dec 31 17:49:56 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 31 Dec 2014 11:49:56 -0500
Subject: [R] Saving an edited R function - RStudio and R
In-Reply-To: <54A3DCE3020000CB0011E864@smtp.medicine.umaryland.edu>
References: <003f01d022ae$6dc008e0$49401aa0$@se>
	<CAAxdm-5M8o8dYcWr7Gow2za3rbMYMDN2A9pcJM+ZEcwwYVLw1A@mail.gmail.com>
	<005601d022bb$c071da20$41558e60$@se>
	<CAAxdm-7XJUVY8buwUwcCErVH-ghVQau_TErTANhyTYLnBi=pXw@mail.gmail.com>
	<alpine.DEB.2.11.1412311454510.11117@paninaro.uibk.ac.at>
	<54A3DCE3020000CB0011E864@smtp.medicine.umaryland.edu>
Message-ID: <CAM_vjukz+P++GMaysz1p4eHu=UE3YFTaRJgAC78Ly-eWy_hR=w@mail.gmail.com>

Hi,

On Wed, Dec 31, 2014 at 11:24 AM, John Sorkin
<jsorkin at grecc.umaryland.edu> wrote:
> Windows 7
>
> Colleagues,
> I used the fix() function to edit an existing function when using RStudio. After editing the function, I am given the option to SAVE the modified function. I would like to know (1) where the modified function is stored (the save button does not have an option to specify where the modified function will be saved), and (2) how I can access the modified function in other RStudio or R sessions, and (3) how I can make the function accessible to R and RStudio sessions run on other computers.

I don't use RStudio, so I have no idea if it overwrites the base fix()
function. But if it does, this is the wrong place to ask about it, so
here's the base R answer.

fix() saves the edited function to your workspace. That is, if you
type ls() at an R prompt after running fix(), it will show your new
edited function. The usual methods for exporting something from R to
your hard disk will work, such as save() and load(). You could also
put your function into a text file myfun.R and use source() to read it
into R.

Once you've used one of these options to save your file to disk, it is
portable between R sessions and computers.

I find it much more convenient to use a text editor and source(),
personally, rather than fix(). That eases the transition into making
packages too.

Sarah


-- 
Sarah Goslee
http://www.functionaldiversity.org


From kmezhoud at gmail.com  Wed Dec 31 17:51:32 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 17:51:32 +0100
Subject: [R] Fwd: which is faster "for" or "apply"
In-Reply-To: <CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
	<54A3FC5B.9050809@fredhutch.org>
	<CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>
	<CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>
Message-ID: <CALJKBv-4rhubnWbQacjtxnUiuJ=V=nZz6uYL57hyR2QcWjEuFQ@mail.gmail.com>

Yes the last one this the best. But I need to test if returned data.frame
is with factor or character:
  cidx <- sapply(df, is.factor) or cidx <- sapply(df, is.character)
Thanks

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 31, 2014 at 5:24 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Concretely I request cbioportal through cgsdr package.
> Depending of Cases and Genetic profiles I receive in general data.frame
> with heterogeneous structure. The bad one if the returned data.frame is
> composed by numeric and character columns. in this case numeric columns are
> considered as  factor. It is the case when I explore/extract information
> from Clinical Data (Age, gender., tumor stage..). In this case I need to
> convert only numeric column and not character ones. I am using
> grep("[0-9]*.[0-9]*",df[,i])!=0 {fun to convert}.
>
>  But this heterogeneity  comes even with only supposed numeric data.frame
> (gene expression). here an example
>
>
> library(cgdsr)
> GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
> ,"ATR", "MDC1" ,"PARP1")
> cgds<-CGDS("http://www.cbioportal.org/public-portal/")
>
> str(getProfileData(cgds,GeneList,
> "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
>
> str(getProfileData(cgds,GeneList,
> "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
>
>
> With my computer I did not find the same structure (numeric vs factor).
>
> Also I need to preserve row and column names ;)
> So I am working to resolve these details depending on data of cbioportal...
>
> Thank you
>
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Wed, Dec 31, 2014 at 4:37 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Many Many Many thanks!
>> it is a demonstrative lesson. I need time to  test all examples :)
>> Thank you for your time and support.
>> Happy and Healthy New Year
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Wed, Dec 31, 2014 at 2:38 PM, Martin Morgan <mtmorgan at fredhutch.org>
>> wrote:
>>
>>> On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
>>>
>>>> Thanks,
>>>> It seems for loop spends less time ;)
>>>>
>>>> with
>>>> dim(DataFrame)
>>>> [1] 338  70
>>>>
>>>> For loop has
>>>>     user  system elapsed
>>>>    0.012   0.000   0.012
>>>>
>>>> and apply has
>>>>    user  system elapsed
>>>>    0.020   0.000   0.021
>>>>
>>>
>>> The timings are so short that the answer in terms of speed is 'it does
>>> not matter'.
>>>
>>> Here is a selection of approaches
>>>
>>> f0 <- function(df) {
>>>     for (i in seq_along(df))
>>>         df[,i] <- as.numeric(df[,i])
>>>     df
>>> }
>>>
>>> f0a <- function(df) {
>>>     ## data.frame is a list-of-equal-length vectors; access each
>>>     ## column with "[["
>>>     for (i in seq_along(df))
>>>         df[[i]] <- as.numeric(df[[i]])
>>>     df
>>> }
>>>
>>> f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from compilation
>>>
>>> f1 <- function(df)
>>>     as.data.frame(apply(df, 2, as.numeric))
>>>
>>> f2 <- function(df) {
>>>     ## replace all columns of df with list-of-vectors
>>>     df[] <- lapply(df, as.numeric)
>>>     df
>>> }
>>>
>>> f3 <- function(df) {
>>>     ## coerce to matrix to avoid the explicit loop, use mode<- to
>>>     ## change storage of elements
>>>     m <- as.matrix(df)
>>>     mode(m) <- "numeric"
>>>     as.data.frame(m)
>>> }
>>>
>>> f4 <- function(df) {
>>>     ## if it's a matrix, why are we returning a data.frame?
>>>     m <- as.matrix(df)
>>>     mode(m) <- "numeric"
>>>     m
>>> }
>>>
>>> f4a <- function(df)
>>>     ## unlist to single vector, coerce, then format as matrix
>>>     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
>>>            dimnames=dimnames(df))
>>>
>>> It's important to test that different methods return the same result
>>> (perhaps allowing for differences in attributes such as row or column
>>> names). The microbenchmark package repeats timings across multiple trials
>>> (default 100 times).
>>>
>>> library(microbenchmark)
>>> test <- function(df) {
>>>     stopifnot(
>>>         identical(f0(df), f0a(df)),
>>>         identical(f0(df), f0c(df)),
>>>         identical(f0(df), f1(df)),
>>>         identical(f0(df), f2(df)),
>>>         identical(f0(df), f3(df)),
>>>         identical(as.matrix(f0(df)), f4(df)),
>>>         all.equal(f4(df), f4a(df), check.attributes=FALSE))
>>>     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df),
>>> f4a(df))
>>> }
>>>
>>> Here are some data sets
>>>
>>> m <- matrix(rnorm(338 * 70), 338)
>>> df <- as.data.frame(m)
>>> dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
>>> dff <- as.data.frame(lapply(df, as.character))
>>>
>>> and results
>>>
>>> > test(df)
>>> Unit: microseconds
>>>     expr      min        lq      mean    median        uq      max neval
>>>   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281   100
>>>  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618   100
>>>  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116   100
>>>   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229   100
>>>   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732   100
>>>   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584   100
>>>   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977   100
>>>  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443   100
>>> > test(dfc)
>>> Unit: milliseconds
>>>     expr       min        lq      mean    median        uq       max
>>> neval
>>>   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622
>>>  100
>>>  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026
>>>  100
>>>  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766
>>>  100
>>>   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499
>>>  100
>>>   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758
>>>  100
>>>   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274
>>>  100
>>>   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601
>>>  100
>>>  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081
>>>  100
>>> > test(dff)
>>> Error: identical(f0(df), f1(df)) is not TRUE
>>>
>>> Except when dealing with factors, the use of explicit loops is the
>>> slowest. With factors, matrix-based methods coerce the level labels to
>>> numeric, whereas vector-based methods coerce the underlying codes (level
>>> values) of the factor; obviously great care needs to be taken.
>>>
>>> > f0(dff)[1:5, 1:5]
>>>    V1  V2  V3  V4  V5
>>> 1 150 232 294  88  56
>>> 2 159   8  89  59  10
>>> 3 132 171  40 205 119
>>> 4 214 273  26 262 216
>>> 5 281  49 255  31 233
>>> > f1(dff)[1:5, 1:5]
>>>           V1          V2         V3         V4          V5
>>> 1 -1.7092463 0.50234009  0.8492982 -0.5636901 -0.38545566
>>> 2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
>>> 3 -1.2915110 -2.46181533 -0.2470108 0.3301129 -1.06810225
>>> 4  0.3065989 0.89263099 -0.1717432  0.7721411 0.35856334
>>> 5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149
>>>
>>> In terms of 'best practice', I would represent my data in the
>>> appropriate data structure in the first place (as a matrix of appropriate
>>> type, rather than data.frame, so the entire coercion is irrelevant). If
>>> faced with a data.frame with specific columns to coerce I would use the
>>> approach
>>>
>>>     cidx <- sapply(df, is.character)      # index of columns to coerce
>>>     df[cidx] <- lapply(df[cidx], as.numeric)
>>>
>>> which seems to be reasonably correct, expressive, compact, and speedy.
>>>
>>> Martin Morgan
>>>
>>>
>>>
>>>>    ?__
>>>>   c/ /'_;~~~~kmezhoud
>>>> (*) \(*)   ?????  ??????
>>>> http://bioinformatics.tn/
>>>>
>>>>
>>>>
>>>> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl>
>>>> wrote:
>>>>
>>>>
>>>>>  On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>>>>>
>>>>>> Hi All,
>>>>>> I would like to choice between these two data frame convert. which is
>>>>>> faster?
>>>>>>
>>>>>>    for(i in 1:ncol(DataFrame)){
>>>>>>
>>>>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
>>>>>>                 }
>>>>>>
>>>>>>
>>>>>> OR
>>>>>>
>>>>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x)
>>>>>> as.numeric(x)))
>>>>>>
>>>>>>
>>>>>>
>>>>> Try it and use system.time.
>>>>>
>>>>> Berend
>>>>>
>>>>>  Thanks
>>>>>> Karim
>>>>>>   ?__
>>>>>> c/ /'_;~~~~kmezhoud
>>>>>> (*) \(*)   ?????  ??????
>>>>>> http://bioinformatics.tn/
>>>>>>
>>>>>>        [[alternative HTML version deleted]]
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>>
>>>>> http://www.R-project.org/posting-guide.html
>>>>>
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>>
>>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>
>>> --
>>> Computational Biology / Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N.
>>> PO Box 19024 Seattle, WA 98109
>>>
>>> Location: Arnold Building M1 B861
>>> Phone: (206) 667-2793
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Wed Dec 31 17:55:15 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 17:55:15 +0100
Subject: [R] Fwd: which is faster "for" or "apply"
In-Reply-To: <CALJKBv-4rhubnWbQacjtxnUiuJ=V=nZz6uYL57hyR2QcWjEuFQ@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
	<54A3FC5B.9050809@fredhutch.org>
	<CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>
	<CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>
	<CALJKBv-4rhubnWbQacjtxnUiuJ=V=nZz6uYL57hyR2QcWjEuFQ@mail.gmail.com>
Message-ID: <CALJKBv8gT0oAEYorXsd-VQjEH1F-k-a2jy2PbYfPxWdhZs7jsQ@mail.gmail.com>

for both
cidx <- !(sapply(df, is.numeric))
df[cidx] <- lapply(df[cidx], as.numeric)


  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 31, 2014 at 5:51 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Yes the last one this the best. But I need to test if returned data.frame
> is with factor or character:
>   cidx <- sapply(df, is.factor) or cidx <- sapply(df, is.character)
> Thanks
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Wed, Dec 31, 2014 at 5:24 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Concretely I request cbioportal through cgsdr package.
>> Depending of Cases and Genetic profiles I receive in general data.frame
>> with heterogeneous structure. The bad one if the returned data.frame is
>> composed by numeric and character columns. in this case numeric columns are
>> considered as  factor. It is the case when I explore/extract information
>> from Clinical Data (Age, gender., tumor stage..). In this case I need to
>> convert only numeric column and not character ones. I am using
>> grep("[0-9]*.[0-9]*",df[,i])!=0 {fun to convert}.
>>
>>  But this heterogeneity  comes even with only supposed numeric data.frame
>> (gene expression). here an example
>>
>>
>> library(cgdsr)
>> GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
>> ,"ATR", "MDC1" ,"PARP1")
>> cgds<-CGDS("http://www.cbioportal.org/public-portal/")
>>
>> str(getProfileData(cgds,GeneList,
>> "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
>>
>> str(getProfileData(cgds,GeneList,
>> "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
>>
>>
>> With my computer I did not find the same structure (numeric vs factor).
>>
>> Also I need to preserve row and column names ;)
>> So I am working to resolve these details depending on data of
>> cbioportal...
>>
>> Thank you
>>
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Wed, Dec 31, 2014 at 4:37 PM, Karim Mezhoud <kmezhoud at gmail.com>
>> wrote:
>>
>>> Many Many Many thanks!
>>> it is a demonstrative lesson. I need time to  test all examples :)
>>> Thank you for your time and support.
>>> Happy and Healthy New Year
>>>
>>>   ?__
>>>  c/ /'_;~~~~kmezhoud
>>> (*) \(*)   ?????  ??????
>>> http://bioinformatics.tn/
>>>
>>>
>>>
>>> On Wed, Dec 31, 2014 at 2:38 PM, Martin Morgan <mtmorgan at fredhutch.org>
>>> wrote:
>>>
>>>> On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
>>>>
>>>>> Thanks,
>>>>> It seems for loop spends less time ;)
>>>>>
>>>>> with
>>>>> dim(DataFrame)
>>>>> [1] 338  70
>>>>>
>>>>> For loop has
>>>>>     user  system elapsed
>>>>>    0.012   0.000   0.012
>>>>>
>>>>> and apply has
>>>>>    user  system elapsed
>>>>>    0.020   0.000   0.021
>>>>>
>>>>
>>>> The timings are so short that the answer in terms of speed is 'it does
>>>> not matter'.
>>>>
>>>> Here is a selection of approaches
>>>>
>>>> f0 <- function(df) {
>>>>     for (i in seq_along(df))
>>>>         df[,i] <- as.numeric(df[,i])
>>>>     df
>>>> }
>>>>
>>>> f0a <- function(df) {
>>>>     ## data.frame is a list-of-equal-length vectors; access each
>>>>     ## column with "[["
>>>>     for (i in seq_along(df))
>>>>         df[[i]] <- as.numeric(df[[i]])
>>>>     df
>>>> }
>>>>
>>>> f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from compilation
>>>>
>>>> f1 <- function(df)
>>>>     as.data.frame(apply(df, 2, as.numeric))
>>>>
>>>> f2 <- function(df) {
>>>>     ## replace all columns of df with list-of-vectors
>>>>     df[] <- lapply(df, as.numeric)
>>>>     df
>>>> }
>>>>
>>>> f3 <- function(df) {
>>>>     ## coerce to matrix to avoid the explicit loop, use mode<- to
>>>>     ## change storage of elements
>>>>     m <- as.matrix(df)
>>>>     mode(m) <- "numeric"
>>>>     as.data.frame(m)
>>>> }
>>>>
>>>> f4 <- function(df) {
>>>>     ## if it's a matrix, why are we returning a data.frame?
>>>>     m <- as.matrix(df)
>>>>     mode(m) <- "numeric"
>>>>     m
>>>> }
>>>>
>>>> f4a <- function(df)
>>>>     ## unlist to single vector, coerce, then format as matrix
>>>>     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
>>>>            dimnames=dimnames(df))
>>>>
>>>> It's important to test that different methods return the same result
>>>> (perhaps allowing for differences in attributes such as row or column
>>>> names). The microbenchmark package repeats timings across multiple trials
>>>> (default 100 times).
>>>>
>>>> library(microbenchmark)
>>>> test <- function(df) {
>>>>     stopifnot(
>>>>         identical(f0(df), f0a(df)),
>>>>         identical(f0(df), f0c(df)),
>>>>         identical(f0(df), f1(df)),
>>>>         identical(f0(df), f2(df)),
>>>>         identical(f0(df), f3(df)),
>>>>         identical(as.matrix(f0(df)), f4(df)),
>>>>         all.equal(f4(df), f4a(df), check.attributes=FALSE))
>>>>     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df),
>>>> f4a(df))
>>>> }
>>>>
>>>> Here are some data sets
>>>>
>>>> m <- matrix(rnorm(338 * 70), 338)
>>>> df <- as.data.frame(m)
>>>> dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
>>>> dff <- as.data.frame(lapply(df, as.character))
>>>>
>>>> and results
>>>>
>>>> > test(df)
>>>> Unit: microseconds
>>>>     expr      min        lq      mean    median        uq      max neval
>>>>   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281
>>>>  100
>>>>  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618
>>>>  100
>>>>  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116
>>>>  100
>>>>   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229
>>>>  100
>>>>   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732
>>>>  100
>>>>   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584
>>>>  100
>>>>   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977   100
>>>>  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443   100
>>>> > test(dfc)
>>>> Unit: milliseconds
>>>>     expr       min        lq      mean    median        uq       max
>>>> neval
>>>>   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622
>>>>  100
>>>>  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026
>>>>  100
>>>>  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766
>>>>  100
>>>>   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499
>>>>  100
>>>>   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758
>>>>  100
>>>>   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274
>>>>  100
>>>>   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601
>>>>  100
>>>>  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081
>>>>  100
>>>> > test(dff)
>>>> Error: identical(f0(df), f1(df)) is not TRUE
>>>>
>>>> Except when dealing with factors, the use of explicit loops is the
>>>> slowest. With factors, matrix-based methods coerce the level labels to
>>>> numeric, whereas vector-based methods coerce the underlying codes (level
>>>> values) of the factor; obviously great care needs to be taken.
>>>>
>>>> > f0(dff)[1:5, 1:5]
>>>>    V1  V2  V3  V4  V5
>>>> 1 150 232 294  88  56
>>>> 2 159   8  89  59  10
>>>> 3 132 171  40 205 119
>>>> 4 214 273  26 262 216
>>>> 5 281  49 255  31 233
>>>> > f1(dff)[1:5, 1:5]
>>>>           V1          V2         V3         V4          V5
>>>> 1 -1.7092463 0.50234009  0.8492982 -0.5636901 -0.38545566
>>>> 2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
>>>> 3 -1.2915110 -2.46181533 -0.2470108 0.3301129 -1.06810225
>>>> 4  0.3065989 0.89263099 -0.1717432  0.7721411 0.35856334
>>>> 5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149
>>>>
>>>> In terms of 'best practice', I would represent my data in the
>>>> appropriate data structure in the first place (as a matrix of appropriate
>>>> type, rather than data.frame, so the entire coercion is irrelevant). If
>>>> faced with a data.frame with specific columns to coerce I would use the
>>>> approach
>>>>
>>>>     cidx <- sapply(df, is.character)      # index of columns to coerce
>>>>     df[cidx] <- lapply(df[cidx], as.numeric)
>>>>
>>>> which seems to be reasonably correct, expressive, compact, and speedy.
>>>>
>>>> Martin Morgan
>>>>
>>>>
>>>>
>>>>>    ?__
>>>>>   c/ /'_;~~~~kmezhoud
>>>>> (*) \(*)   ?????  ??????
>>>>> http://bioinformatics.tn/
>>>>>
>>>>>
>>>>>
>>>>> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl>
>>>>> wrote:
>>>>>
>>>>>
>>>>>>  On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>>>>>>>
>>>>>>> Hi All,
>>>>>>> I would like to choice between these two data frame convert. which is
>>>>>>> faster?
>>>>>>>
>>>>>>>    for(i in 1:ncol(DataFrame)){
>>>>>>>
>>>>>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
>>>>>>>                 }
>>>>>>>
>>>>>>>
>>>>>>> OR
>>>>>>>
>>>>>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x)
>>>>>>> as.numeric(x)))
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>> Try it and use system.time.
>>>>>>
>>>>>> Berend
>>>>>>
>>>>>>  Thanks
>>>>>>> Karim
>>>>>>>   ?__
>>>>>>> c/ /'_;~~~~kmezhoud
>>>>>>> (*) \(*)   ?????  ??????
>>>>>>> http://bioinformatics.tn/
>>>>>>>
>>>>>>>        [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>>
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>         [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>>> posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>>
>>>> --
>>>> Computational Biology / Fred Hutchinson Cancer Research Center
>>>> 1100 Fairview Ave. N.
>>>> PO Box 19024 Seattle, WA 98109
>>>>
>>>> Location: Arnold Building M1 B861
>>>> Phone: (206) 667-2793
>>>>
>>>
>>>
>>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Dec 31 18:39:11 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 31 Dec 2014 09:39:11 -0800
Subject: [R] Fwd: which is faster "for" or "apply"
In-Reply-To: <CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
	<54A3FC5B.9050809@fredhutch.org>
	<CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>
	<CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>
Message-ID: <CAF8bMcYEinfxt5XAgF8oOLib6VAMWt=1FpvsRiOzEYxigbKdfw@mail.gmail.com>

> But this heterogeneity  comes even with only supposed numeric data.frame
> (gene expression). here an example
>
> ibrary(cgdsr)
> GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
> ,"ATR", "MDC1" ,"PARP1")
> cgds<-CGDS("http://www.cbioportal.org/public-portal/")
>
> str(getProfileData(cgds,GeneList,
> "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
>
> str(getProfileData(cgds,GeneList,
> "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
>
> With my computer I did not find the same structure (numeric vs factor).

Can you show us what you got.  I am a bit surprised that you got any factors
because putting a trace on read.table shows that getProfileData calls it
with as.is=TRUE (meaning to not convert character columns to factors).  I
got
all numeric columns:
  > trace(read.table)
  > str(getProfileData(cgds,GeneList,
  + "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
  trace: read.table(url, skip = 0, header = TRUE, as.is = TRUE, sep = "\t",
      quote = "")
  'data.frame':   48 obs. of  10 variables:
   $ ATM  : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
   $ ATR  : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
   $ DDR2 : num  0.714 0.857 0.549 0.669 0.587 ...
   $ HPGDS: num  0.505 0.722 0.528 0.411 0.497 ...
   $ MDC1 : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
   $ MLH1 : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
   $ MS4A2: num  0.83 0.853 0.835 0.716 0.481 ...
   $ MSH2 : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
   $ PARP1: num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
   $ SSUH2: num  0.73 0.842 0.794 0.854 0.803 ...

  > str(getProfileData(cgds,GeneList,
  + "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
  trace: read.table(url, skip = 0, header = TRUE, as.is = TRUE, sep = "\t",
      quote = "")
  'data.frame':   338 obs. of  10 variables:
   $ ATM  : num  0.019 0.017 0.0168 0.015 0.014 ...
   $ ATR  : num  0.0356 0.0346 0.0231 0.0275 0.0285 ...
   $ DDR2 : num  0.81 0.786 0.596 0.861 0.646 ...
   $ HPGDS: num  0.576 0.528 0.703 0.781 0.622 ...
   $ MDC1 : num  0.189 0.265 0.201 0.199 0.249 ...
   $ MLH1 : num  0.404 0.0192 0.017 0.0124 0.0197 ...
   $ MS4A2: num  0.913 0.898 0.937 0.861 0.768 ...
   $ MSH2 : num  0.018 0.0184 0.016 0.0145 0.0168 ...
   $ PARP1: num  0.0191 0.0195 0.0146 0.0174 0.0181 ...
   $ SSUH2: num  0.848 0.874 0.644 0.621 0.652 ...

Perhaps some option or locale setting is causing input strings to be
interpretted as non-numbers.  (If you know all these columns should
be numeric, you could add colClasses=rep("numeric", length(GeneList))
to the call to read.table.  See which entries show up as NA and reread
with colClasses=rep("character",length(GeneList)) to see where they
came from).

It is almost always better to get the data input correctly rather than
trying
to fix it up latter.  If you must convert later, using apply(), which
converts
the data.frame to a matrix with a single class for all columns, often causes
problems.  sapply() may or may not convert its output to a matrix, depending
on what FUN returns.   Use lapply instead, with a function that uses the
class of its input
to decide what to do.  DataFrame[] <- lapply(DataFrame,
FUN=function(col)...)
will retain the class, row names, and column names of the data.frame.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Dec 31, 2014 at 8:24 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:

> Concretely I request cbioportal through cgsdr package.
> Depending of Cases and Genetic profiles I receive in general data.frame
> with heterogeneous structure. The bad one if the returned data.frame is
> composed by numeric and character columns. in this case numeric columns are
> considered as  factor. It is the case when I explore/extract information
> from Clinical Data (Age, gender., tumor stage..). In this case I need to
> convert only numeric column and not character ones. I am using
> grep("[0-9]*.[0-9]*",df[,i])!=0 {fun to convert}.
>
>  But this heterogeneity  comes even with only supposed numeric data.frame
> (gene expression). here an example
>
>
> library(cgdsr)
> GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
> ,"ATR", "MDC1" ,"PARP1")
> cgds<-CGDS("http://www.cbioportal.org/public-portal/")
>
> str(getProfileData(cgds,GeneList,
> "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
>
> str(getProfileData(cgds,GeneList,
> "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
>
>
> With my computer I did not find the same structure (numeric vs factor).
>
> Also I need to preserve row and column names ;)
> So I am working to resolve these details depending on data of cbioportal...
>
> Thank you
>
>
>   ?__
>  c/ /'_;~~~~kmezhoud
> (*) \(*)   ?????  ??????
> http://bioinformatics.tn/
>
>
>
> On Wed, Dec 31, 2014 at 4:37 PM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
> > Many Many Many thanks!
> > it is a demonstrative lesson. I need time to  test all examples :)
> > Thank you for your time and support.
> > Happy and Healthy New Year
> >
> >   ?__
> >  c/ /'_;~~~~kmezhoud
> > (*) \(*)   ?????  ??????
> > http://bioinformatics.tn/
> >
> >
> >
> > On Wed, Dec 31, 2014 at 2:38 PM, Martin Morgan <mtmorgan at fredhutch.org>
> > wrote:
> >
> >> On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
> >>
> >>> Thanks,
> >>> It seems for loop spends less time ;)
> >>>
> >>> with
> >>> dim(DataFrame)
> >>> [1] 338  70
> >>>
> >>> For loop has
> >>>     user  system elapsed
> >>>    0.012   0.000   0.012
> >>>
> >>> and apply has
> >>>    user  system elapsed
> >>>    0.020   0.000   0.021
> >>>
> >>
> >> The timings are so short that the answer in terms of speed is 'it does
> >> not matter'.
> >>
> >> Here is a selection of approaches
> >>
> >> f0 <- function(df) {
> >>     for (i in seq_along(df))
> >>         df[,i] <- as.numeric(df[,i])
> >>     df
> >> }
> >>
> >> f0a <- function(df) {
> >>     ## data.frame is a list-of-equal-length vectors; access each
> >>     ## column with "[["
> >>     for (i in seq_along(df))
> >>         df[[i]] <- as.numeric(df[[i]])
> >>     df
> >> }
> >>
> >> f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from compilation
> >>
> >> f1 <- function(df)
> >>     as.data.frame(apply(df, 2, as.numeric))
> >>
> >> f2 <- function(df) {
> >>     ## replace all columns of df with list-of-vectors
> >>     df[] <- lapply(df, as.numeric)
> >>     df
> >> }
> >>
> >> f3 <- function(df) {
> >>     ## coerce to matrix to avoid the explicit loop, use mode<- to
> >>     ## change storage of elements
> >>     m <- as.matrix(df)
> >>     mode(m) <- "numeric"
> >>     as.data.frame(m)
> >> }
> >>
> >> f4 <- function(df) {
> >>     ## if it's a matrix, why are we returning a data.frame?
> >>     m <- as.matrix(df)
> >>     mode(m) <- "numeric"
> >>     m
> >> }
> >>
> >> f4a <- function(df)
> >>     ## unlist to single vector, coerce, then format as matrix
> >>     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
> >>            dimnames=dimnames(df))
> >>
> >> It's important to test that different methods return the same result
> >> (perhaps allowing for differences in attributes such as row or column
> >> names). The microbenchmark package repeats timings across multiple
> trials
> >> (default 100 times).
> >>
> >> library(microbenchmark)
> >> test <- function(df) {
> >>     stopifnot(
> >>         identical(f0(df), f0a(df)),
> >>         identical(f0(df), f0c(df)),
> >>         identical(f0(df), f1(df)),
> >>         identical(f0(df), f2(df)),
> >>         identical(f0(df), f3(df)),
> >>         identical(as.matrix(f0(df)), f4(df)),
> >>         all.equal(f4(df), f4a(df), check.attributes=FALSE))
> >>     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df),
> >> f4a(df))
> >> }
> >>
> >> Here are some data sets
> >>
> >> m <- matrix(rnorm(338 * 70), 338)
> >> df <- as.data.frame(m)
> >> dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
> >> dff <- as.data.frame(lapply(df, as.character))
> >>
> >> and results
> >>
> >> > test(df)
> >> Unit: microseconds
> >>     expr      min        lq      mean    median        uq      max neval
> >>   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281   100
> >>  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618   100
> >>  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116   100
> >>   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229   100
> >>   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732   100
> >>   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584   100
> >>   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977   100
> >>  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443   100
> >> > test(dfc)
> >> Unit: milliseconds
> >>     expr       min        lq      mean    median        uq       max
> neval
> >>   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622
> >>  100
> >>  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026
>  100
> >>  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766
> >>  100
> >>   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499
>  100
> >>   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758
>  100
> >>   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274
>  100
> >>   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601
>  100
> >>  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081
>  100
> >> > test(dff)
> >> Error: identical(f0(df), f1(df)) is not TRUE
> >>
> >> Except when dealing with factors, the use of explicit loops is the
> >> slowest. With factors, matrix-based methods coerce the level labels to
> >> numeric, whereas vector-based methods coerce the underlying codes (level
> >> values) of the factor; obviously great care needs to be taken.
> >>
> >> > f0(dff)[1:5, 1:5]
> >>    V1  V2  V3  V4  V5
> >> 1 150 232 294  88  56
> >> 2 159   8  89  59  10
> >> 3 132 171  40 205 119
> >> 4 214 273  26 262 216
> >> 5 281  49 255  31 233
> >> > f1(dff)[1:5, 1:5]
> >>           V1          V2         V3         V4          V5
> >> 1 -1.7092463 0.50234009  0.8492982 -0.5636901 -0.38545566
> >> 2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
> >> 3 -1.2915110 -2.46181533 -0.2470108 0.3301129 -1.06810225
> >> 4  0.3065989 0.89263099 -0.1717432  0.7721411 0.35856334
> >> 5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149
> >>
> >> In terms of 'best practice', I would represent my data in the
> appropriate
> >> data structure in the first place (as a matrix of appropriate type,
> rather
> >> than data.frame, so the entire coercion is irrelevant). If faced with a
> >> data.frame with specific columns to coerce I would use the approach
> >>
> >>     cidx <- sapply(df, is.character)      # index of columns to coerce
> >>     df[cidx] <- lapply(df[cidx], as.numeric)
> >>
> >> which seems to be reasonably correct, expressive, compact, and speedy.
> >>
> >> Martin Morgan
> >>
> >>
> >>
> >>>    ?__
> >>>   c/ /'_;~~~~kmezhoud
> >>> (*) \(*)   ?????  ??????
> >>> http://bioinformatics.tn/
> >>>
> >>>
> >>>
> >>> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl>
> wrote:
> >>>
> >>>
> >>>>  On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
> >>>>>
> >>>>> Hi All,
> >>>>> I would like to choice between these two data frame convert. which is
> >>>>> faster?
> >>>>>
> >>>>>    for(i in 1:ncol(DataFrame)){
> >>>>>
> >>>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
> >>>>>                 }
> >>>>>
> >>>>>
> >>>>> OR
> >>>>>
> >>>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x)
> >>>>> as.numeric(x)))
> >>>>>
> >>>>>
> >>>>>
> >>>> Try it and use system.time.
> >>>>
> >>>> Berend
> >>>>
> >>>>  Thanks
> >>>>> Karim
> >>>>>   ?__
> >>>>> c/ /'_;~~~~kmezhoud
> >>>>> (*) \(*)   ?????  ??????
> >>>>> http://bioinformatics.tn/
> >>>>>
> >>>>>        [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>>
> >>>> http://www.R-project.org/posting-guide.html
> >>>>
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>
> >>>>
> >>>>
> >>>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/
> >>> posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>
> >> --
> >> Computational Biology / Fred Hutchinson Cancer Research Center
> >> 1100 Fairview Ave. N.
> >> PO Box 19024 Seattle, WA 98109
> >>
> >> Location: Arnold Building M1 B861
> >> Phone: (206) 667-2793
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Wed Dec 31 18:55:21 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 31 Dec 2014 18:55:21 +0100
Subject: [R] Fwd: which is faster "for" or "apply"
In-Reply-To: <CAF8bMcYEinfxt5XAgF8oOLib6VAMWt=1FpvsRiOzEYxigbKdfw@mail.gmail.com>
References: <CALJKBv-12jw5ACDcMZyTYo1BxXknvbECtazwQbrn=PVvnOYaSA@mail.gmail.com>
	<857F6469-BF9F-4276-943C-3A3CCCD58330@xs4all.nl>
	<CALJKBv__=VsMUWm3b2DL3JSMBP9NET5kWpFJ8vUxJ8jC3zfPRg@mail.gmail.com>
	<CALJKBv_fuLqj=DDQ2CN=WxCwAdQ-_nzonH8DYKXvvaS7F19cVA@mail.gmail.com>
	<54A3FC5B.9050809@fredhutch.org>
	<CALJKBv8xMaE=xJ4cE9M34Gg6PhZsLKaheJk_6ZRHn2nYZzn6Kg@mail.gmail.com>
	<CALJKBv-D3e+PtOxks4Vq2j1Rh57Jcv4mKHgT=2paOnkXWS55=Q@mail.gmail.com>
	<CAF8bMcYEinfxt5XAgF8oOLib6VAMWt=1FpvsRiOzEYxigbKdfw@mail.gmail.com>
Message-ID: <CALJKBv88VYaKpSc251CvEoPe8ey_CW4POAkk3x+RQCf0sNT-OQ@mail.gmail.com>

Thanks, please find what I got:

> str(getProfileData(cgds,GeneList,
"stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
'data.frame':    48 obs. of  10 variables:
 $ ATM  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ ATR  : num  NA NA NA NA NA NA NA NA NA NA ...
 $ DDR2 : num  0.714 0.857 0.549 0.669 0.587 ...
 $ HPGDS: num  0.505 0.722 0.528 0.411 0.497 ...
 $ MDC1 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ MLH1 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ MS4A2: num  0.83 0.853 0.835 0.716 0.481 ...
 $ MSH2 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ PARP1: num  NA NA NA NA NA NA NA NA NA NA ...
 $ SSUH2: num  0.73 0.842 0.794 0.854 0.803 ...
> str(getProfileData(cgds,GeneList,
"stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
'data.frame':    338 obs. of  10 variables:
 $ ATM  : Factor w/ 338 levels "0.01060883","0.01065690",..: 256 182 170
101 53 302 183 236 298 334 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ ATR  : Factor w/ 338 levels "0.009422188",..: 271 265 165 215 222 304
176 170 228 277 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ DDR2 : Factor w/ 338 levels "0.38369598","0.42008010",..: 197 161 25 291
40 38 155 85 177 180 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ HPGDS: Factor w/ 338 levels "0.16077929","0.18867898",..: 85 56 208 281
116 67 132 119 152 49 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ MDC1 : Factor w/ 338 levels "0.06105770","0.06532153",..: 162 267 185
180 253 220 108 230 239 271 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ MLH1 : Factor w/ 338 levels "0.009031445",..: 299 194 160 45 198 224 115
167 287 165 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ MS4A2: Factor w/ 338 levels "0.31286204","0.438797860",..: 266 210 329
111 40 49 21 68 134 331 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ MSH2 : Factor w/ 338 levels "0.009568869",..: 260 270 179 114 215 137
263 78 300 283 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ PARP1: Factor w/ 338 levels "0.01110587","0.01208177",..: 249 260 65 191
219 204 32 132 130 225 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
 $ SSUH2: Factor w/ 338 levels "0.17618607","0.184911562",..: 243 276 93 82
99 236 51 88 163 138 ...
  ..- attr(*, "names")= chr  "TCGA.BR.6452.01" "TCGA.BR.6453.01"
"TCGA.BR.6454.01" "TCGA.BR.6455.01" ...
>

  ?__
 c/ /'_;~~~~kmezhoud
(*) \(*)   ?????  ??????
http://bioinformatics.tn/



On Wed, Dec 31, 2014 at 6:39 PM, William Dunlap <wdunlap at tibco.com> wrote:

> > But this heterogeneity  comes even with only supposed numeric data.frame
> > (gene expression). here an example
> >
> > ibrary(cgdsr)
> > GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
> > ,"ATR", "MDC1" ,"PARP1")
> > cgds<-CGDS("http://www.cbioportal.org/public-portal/")
> >
> > str(getProfileData(cgds,GeneList,
> > "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
> >
> > str(getProfileData(cgds,GeneList,
> > "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
> >
> > With my computer I did not find the same structure (numeric vs factor).
>
> Can you show us what you got.  I am a bit surprised that you got any
> factors
> because putting a trace on read.table shows that getProfileData calls it
> with as.is=TRUE (meaning to not convert character columns to factors).  I
> got
> all numeric columns:
>   > trace(read.table)
>   > str(getProfileData(cgds,GeneList,
>   + "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
>   trace: read.table(url, skip = 0, header = TRUE, as.is = TRUE, sep =
> "\t",
>       quote = "")
>   'data.frame':   48 obs. of  10 variables:
>    $ ATM  : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
>    $ ATR  : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
>    $ DDR2 : num  0.714 0.857 0.549 0.669 0.587 ...
>    $ HPGDS: num  0.505 0.722 0.528 0.411 0.497 ...
>    $ MDC1 : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
>    $ MLH1 : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
>    $ MS4A2: num  0.83 0.853 0.835 0.716 0.481 ...
>    $ MSH2 : num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
>    $ PARP1: num  NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
>    $ SSUH2: num  0.73 0.842 0.794 0.854 0.803 ...
>
>   > str(getProfileData(cgds,GeneList,
>   + "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
>   trace: read.table(url, skip = 0, header = TRUE, as.is = TRUE, sep =
> "\t",
>       quote = "")
>   'data.frame':   338 obs. of  10 variables:
>    $ ATM  : num  0.019 0.017 0.0168 0.015 0.014 ...
>    $ ATR  : num  0.0356 0.0346 0.0231 0.0275 0.0285 ...
>    $ DDR2 : num  0.81 0.786 0.596 0.861 0.646 ...
>    $ HPGDS: num  0.576 0.528 0.703 0.781 0.622 ...
>    $ MDC1 : num  0.189 0.265 0.201 0.199 0.249 ...
>    $ MLH1 : num  0.404 0.0192 0.017 0.0124 0.0197 ...
>    $ MS4A2: num  0.913 0.898 0.937 0.861 0.768 ...
>    $ MSH2 : num  0.018 0.0184 0.016 0.0145 0.0168 ...
>    $ PARP1: num  0.0191 0.0195 0.0146 0.0174 0.0181 ...
>    $ SSUH2: num  0.848 0.874 0.644 0.621 0.652 ...
>
> Perhaps some option or locale setting is causing input strings to be
> interpretted as non-numbers.  (If you know all these columns should
> be numeric, you could add colClasses=rep("numeric", length(GeneList))
> to the call to read.table.  See which entries show up as NA and reread
> with colClasses=rep("character",length(GeneList)) to see where they
> came from).
>
> It is almost always better to get the data input correctly rather than
> trying
> to fix it up latter.  If you must convert later, using apply(), which
> converts
> the data.frame to a matrix with a single class for all columns, often
> causes
> problems.  sapply() may or may not convert its output to a matrix,
> depending
> on what FUN returns.   Use lapply instead, with a function that uses the
> class of its input
> to decide what to do.  DataFrame[] <- lapply(DataFrame,
> FUN=function(col)...)
> will retain the class, row names, and column names of the data.frame.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, Dec 31, 2014 at 8:24 AM, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>
>> Concretely I request cbioportal through cgsdr package.
>> Depending of Cases and Genetic profiles I receive in general data.frame
>> with heterogeneous structure. The bad one if the returned data.frame is
>> composed by numeric and character columns. in this case numeric columns
>> are
>> considered as  factor. It is the case when I explore/extract information
>> from Clinical Data (Age, gender., tumor stage..). In this case I need to
>> convert only numeric column and not character ones. I am using
>> grep("[0-9]*.[0-9]*",df[,i])!=0 {fun to convert}.
>>
>>  But this heterogeneity  comes even with only supposed numeric data.frame
>> (gene expression). here an example
>>
>>
>> library(cgdsr)
>> GeneList <- c("DDR2", "HPGDS", "MS4A2","SSUH2","MLH1" ,"MSH2", "ATM"
>> ,"ATR", "MDC1" ,"PARP1")
>> cgds<-CGDS("http://www.cbioportal.org/public-portal/")
>>
>> str(getProfileData(cgds,GeneList,
>> "stad_tcga_methylation_hm27","stad_tcga_methylation_hm27"))
>>
>> str(getProfileData(cgds,GeneList,
>> "stad_tcga_methylation_hm450","stad_tcga_methylation_hm450"))
>>
>>
>> With my computer I did not find the same structure (numeric vs factor).
>>
>> Also I need to preserve row and column names ;)
>> So I am working to resolve these details depending on data of
>> cbioportal...
>>
>> Thank you
>>
>>
>>   ?__
>>  c/ /'_;~~~~kmezhoud
>> (*) \(*)   ?????  ??????
>> http://bioinformatics.tn/
>>
>>
>>
>> On Wed, Dec 31, 2014 at 4:37 PM, Karim Mezhoud <kmezhoud at gmail.com>
>> wrote:
>>
>> > Many Many Many thanks!
>> > it is a demonstrative lesson. I need time to  test all examples :)
>> > Thank you for your time and support.
>> > Happy and Healthy New Year
>> >
>> >   ?__
>> >  c/ /'_;~~~~kmezhoud
>> > (*) \(*)   ?????  ??????
>> > http://bioinformatics.tn/
>> >
>> >
>> >
>> > On Wed, Dec 31, 2014 at 2:38 PM, Martin Morgan <mtmorgan at fredhutch.org>
>> > wrote:
>> >
>> >> On 12/31/2014 12:22 AM, Karim Mezhoud wrote:
>> >>
>> >>> Thanks,
>> >>> It seems for loop spends less time ;)
>> >>>
>> >>> with
>> >>> dim(DataFrame)
>> >>> [1] 338  70
>> >>>
>> >>> For loop has
>> >>>     user  system elapsed
>> >>>    0.012   0.000   0.012
>> >>>
>> >>> and apply has
>> >>>    user  system elapsed
>> >>>    0.020   0.000   0.021
>> >>>
>> >>
>> >> The timings are so short that the answer in terms of speed is 'it does
>> >> not matter'.
>> >>
>> >> Here is a selection of approaches
>> >>
>> >> f0 <- function(df) {
>> >>     for (i in seq_along(df))
>> >>         df[,i] <- as.numeric(df[,i])
>> >>     df
>> >> }
>> >>
>> >> f0a <- function(df) {
>> >>     ## data.frame is a list-of-equal-length vectors; access each
>> >>     ## column with "[["
>> >>     for (i in seq_along(df))
>> >>         df[[i]] <- as.numeric(df[[i]])
>> >>     df
>> >> }
>> >>
>> >> f0c <- compiler::cmpfun(f0)  ## loops sometimes benefit from
>> compilation
>> >>
>> >> f1 <- function(df)
>> >>     as.data.frame(apply(df, 2, as.numeric))
>> >>
>> >> f2 <- function(df) {
>> >>     ## replace all columns of df with list-of-vectors
>> >>     df[] <- lapply(df, as.numeric)
>> >>     df
>> >> }
>> >>
>> >> f3 <- function(df) {
>> >>     ## coerce to matrix to avoid the explicit loop, use mode<- to
>> >>     ## change storage of elements
>> >>     m <- as.matrix(df)
>> >>     mode(m) <- "numeric"
>> >>     as.data.frame(m)
>> >> }
>> >>
>> >> f4 <- function(df) {
>> >>     ## if it's a matrix, why are we returning a data.frame?
>> >>     m <- as.matrix(df)
>> >>     mode(m) <- "numeric"
>> >>     m
>> >> }
>> >>
>> >> f4a <- function(df)
>> >>     ## unlist to single vector, coerce, then format as matrix
>> >>     matrix(as.numeric(unlist(df, use.names=FALSE)), nrow(df),
>> >>            dimnames=dimnames(df))
>> >>
>> >> It's important to test that different methods return the same result
>> >> (perhaps allowing for differences in attributes such as row or column
>> >> names). The microbenchmark package repeats timings across multiple
>> trials
>> >> (default 100 times).
>> >>
>> >> library(microbenchmark)
>> >> test <- function(df) {
>> >>     stopifnot(
>> >>         identical(f0(df), f0a(df)),
>> >>         identical(f0(df), f0c(df)),
>> >>         identical(f0(df), f1(df)),
>> >>         identical(f0(df), f2(df)),
>> >>         identical(f0(df), f3(df)),
>> >>         identical(as.matrix(f0(df)), f4(df)),
>> >>         all.equal(f4(df), f4a(df), check.attributes=FALSE))
>> >>     microbenchmark(f0(df), f0a(df), f1(df), f2(df), f3(df), f4(df),
>> >> f4a(df))
>> >> }
>> >>
>> >> Here are some data sets
>> >>
>> >> m <- matrix(rnorm(338 * 70), 338)
>> >> df <- as.data.frame(m)
>> >> dfc <- as.data.frame(lapply(df, as.character), stringsAsFactors=FALSE)
>> >> dff <- as.data.frame(lapply(df, as.character))
>> >>
>> >> and results
>> >>
>> >> > test(df)
>> >> Unit: microseconds
>> >>     expr      min        lq      mean    median        uq      max
>> neval
>> >>   f0(df) 6208.956 6270.5500 6367.4138 6306.7110 6362.2225 7731.281
>>  100
>> >>  f0a(df) 2917.973 2975.2090 3024.8623 3002.3805 3036.5365 3951.618
>>  100
>> >>  f0c(df) 6078.399 6150.1085 6264.0998 6188.3690 6244.5725 7684.116
>>  100
>> >>   f1(df) 2698.074 2743.2905 2821.8453 2769.3655 2805.5345 4033.229
>>  100
>> >>   f2(df) 1989.057 2041.0685 2066.1830 2055.0020 2083.8545 2267.732
>>  100
>> >>   f3(df) 1532.435 1572.9810 1609.7378 1597.6245 1624.2305 2003.584
>>  100
>> >>   f4(df)  808.593  828.5445  852.2626  847.5355  864.6665 1180.977
>>  100
>> >>  f4a(df)  422.657  437.2705  458.9845  455.2470  465.5815  695.443
>>  100
>> >> > test(dfc)
>> >> Unit: milliseconds
>> >>     expr       min        lq      mean    median        uq       max
>> neval
>> >>   f0(df) 11.416532 11.647858 11.915287 11.767647 12.016276 14.239622
>> >>  100
>> >>  f0a(df)  8.095709  8.211116  8.380638  8.289895  8.454948  9.529026
>>  100
>> >>  f0c(df) 11.339293 11.577811 11.772087 11.702341 11.896729 12.674766
>> >>  100
>> >>   f1(df)  8.227371  8.277147  8.422412  8.331403  8.490411  9.145499
>>  100
>> >>   f2(df)  6.907888  7.010828  7.162529  7.147198  7.239048  7.763758
>>  100
>> >>   f3(df)  6.608107  6.688232  6.845936  6.792066  6.892635  8.359274
>>  100
>> >>   f4(df)  5.859482  5.939680  6.046976  5.993804  6.105388  6.968601
>>  100
>> >>  f4a(df)  5.372214  5.460987  5.556687  5.521542  5.614482  6.107081
>>  100
>> >> > test(dff)
>> >> Error: identical(f0(df), f1(df)) is not TRUE
>> >>
>> >> Except when dealing with factors, the use of explicit loops is the
>> >> slowest. With factors, matrix-based methods coerce the level labels to
>> >> numeric, whereas vector-based methods coerce the underlying codes
>> (level
>> >> values) of the factor; obviously great care needs to be taken.
>> >>
>> >> > f0(dff)[1:5, 1:5]
>> >>    V1  V2  V3  V4  V5
>> >> 1 150 232 294  88  56
>> >> 2 159   8  89  59  10
>> >> 3 132 171  40 205 119
>> >> 4 214 273  26 262 216
>> >> 5 281  49 255  31 233
>> >> > f1(dff)[1:5, 1:5]
>> >>           V1          V2         V3         V4          V5
>> >> 1 -1.7092463 0.50234009  0.8492982 -0.5636901 -0.38545566
>> >> 2 -2.3020854 -0.05580931 -0.5963673 -0.3671748 -0.09408031
>> >> 3 -1.2915110 -2.46181533 -0.2470108 0.3301129 -1.06810225
>> >> 4  0.3065989 0.89263099 -0.1717432  0.7721411 0.35856334
>> >> 5  0.8795616 -0.43049898  0.4560515 -0.1722099  0.46125149
>> >>
>> >> In terms of 'best practice', I would represent my data in the
>> appropriate
>> >> data structure in the first place (as a matrix of appropriate type,
>> rather
>> >> than data.frame, so the entire coercion is irrelevant). If faced with a
>> >> data.frame with specific columns to coerce I would use the approach
>> >>
>> >>     cidx <- sapply(df, is.character)      # index of columns to coerce
>> >>     df[cidx] <- lapply(df[cidx], as.numeric)
>> >>
>> >> which seems to be reasonably correct, expressive, compact, and speedy.
>> >>
>> >> Martin Morgan
>> >>
>> >>
>> >>
>> >>>    ?__
>> >>>   c/ /'_;~~~~kmezhoud
>> >>> (*) \(*)   ?????  ??????
>> >>> http://bioinformatics.tn/
>> >>>
>> >>>
>> >>>
>> >>> On Wed, Dec 31, 2014 at 8:54 AM, Berend Hasselman <bhh at xs4all.nl>
>> wrote:
>> >>>
>> >>>
>> >>>>  On 31-12-2014, at 08:40, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>> >>>>>
>> >>>>> Hi All,
>> >>>>> I would like to choice between these two data frame convert. which
>> is
>> >>>>> faster?
>> >>>>>
>> >>>>>    for(i in 1:ncol(DataFrame)){
>> >>>>>
>> >>>>>                     DataFrame[,i] <- as.numeric(DataFrame[,i])
>> >>>>>                 }
>> >>>>>
>> >>>>>
>> >>>>> OR
>> >>>>>
>> >>>>> DataFrame <- as.data.frame(apply(DataFrame,2 ,function(x)
>> >>>>> as.numeric(x)))
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>> Try it and use system.time.
>> >>>>
>> >>>> Berend
>> >>>>
>> >>>>  Thanks
>> >>>>> Karim
>> >>>>>   ?__
>> >>>>> c/ /'_;~~~~kmezhoud
>> >>>>> (*) \(*)   ?????  ??????
>> >>>>> http://bioinformatics.tn/
>> >>>>>
>> >>>>>        [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>>>
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>>
>> >>>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>>
>> >>>>
>> >>>>
>> >>>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide http://www.R-project.org/
>> >>> posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>>
>> >>>
>> >>
>> >> --
>> >> Computational Biology / Fred Hutchinson Cancer Research Center
>> >> 1100 Fairview Ave. N.
>> >> PO Box 19024 Seattle, WA 98109
>> >>
>> >> Location: Arnold Building M1 B861
>> >> Phone: (206) 667-2793
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From zaid.bhatti at aku.edu  Wed Dec 31 11:30:25 2014
From: zaid.bhatti at aku.edu (zaid bhatti)
Date: Wed, 31 Dec 2014 02:30:25 -0800 (PST)
Subject: [R] R-Hierarchical binomial proportion modelling
Message-ID: <1420021825931-4701239.post@n4.nabble.com>

Hi, 
i am running a model without covariates, along with shape file and
neighbourhood matrix,
i am facing difficulty to edit this code for 34 provinces, can any help me
to edit this below given code.



FinalModels_WINScriptToRunModel_AllMetrics v2 final_20141205

          inits1<-list(precu = 10,precv = 10,alpha =-1,
          v=rep(1,Ndistricts), Bprov=c(NA,/0.1,0.2,0.3,0.4,0.5,0.6,0.7/),
u=rep(1,Ndistricts))                   
          
          inits2<-list(precu = 20,  precv = 20, alpha =-0.9,
          v=rep(-1,
Ndistricts),Bprov=c(NA,/0.01,0.02,0.03,0.04,0.05,0.06,0.07/),
u=rep(-1,Ndistricts))
          inits<-list(inits1,inits2)



Model district dbin_3

Bprov[1] <- 0
  for(j in 2:34){
        Bprov[j] ~ dnorm(0, 0/.0000001/)   ### how should we edit this ?
  }





--
View this message in context: http://r.789695.n4.nabble.com/R-Hierarchical-binomial-proportion-modelling-tp4701239.html
Sent from the R help mailing list archive at Nabble.com.


From kushal.shah at arisglobal.com  Wed Dec 31 12:58:40 2014
From: kushal.shah at arisglobal.com (Kushal)
Date: Wed, 31 Dec 2014 03:58:40 -0800 (PST)
Subject: [R] Memory usage problem while using nlm function
Message-ID: <1420027120635-4701241.post@n4.nabble.com>

Hi,
     I am trying to do nonlinear minimization using nlm() function, but for
large amount of data it is going out of memory.

Code which i am using:

f<-function(p,n11,E){
      sum(-log((p[5] * dnbinom(n11, size=p[1], prob=p[2]/(p[2]+E)) +
(1-p[5]) * dnbinom(n11, size=p[3], prob=p[4]/(p[4]+E)))))
    }
p_out <-nlm(f, p=c(alpha1= 0.2, beta1= 0.06, alpha2=1.4, beta2=1.8, w=0.1),
n11=n11_c, E=E_c)

When the size of n11_c or E_c vector is to large, it is going out of memory.
please give me some solution for this.



--
View this message in context: http://r.789695.n4.nabble.com/Memory-usage-problem-while-using-nlm-function-tp4701241.html
Sent from the R help mailing list archive at Nabble.com.


From thomas.f.hahn2 at gmail.com  Wed Dec 31 18:21:24 2014
From: thomas.f.hahn2 at gmail.com (thomas hahn)
Date: Wed, 31 Dec 2014 11:21:24 -0600
Subject: [R] Help with finding tutors for Linux, R, Perl,
 Python MATLAB and/or Cytoscape for yeast microarray analysis,
 next generation sequencing and constructing gene interaction networks
Message-ID: <CAKJ67ZWecjb31mLDjcK4N_MiHjvAzOomqb+WqNHJG0EfaAOCGA@mail.gmail.com>

?

Help with finding tutors for Linux, R, Perl, Python MATLAB and/or Cytoscape
for yeast microarray analysis, next generation sequencing and constructing
gene interaction networks



Hi



I am a visually impaired bioinformatics graduate student using microarray
data for my master?s thesis aimed at deciphering the mechanism by which the
yeast wild type can suppress the rise of free reactive oxygen species (ROS)
induced by caloric restriction (CR) but the Atg15 and Erg6 knockout mutant
cannot.



Since my remaining vision is very limited I need very high magnification.
But that makes my visual field very small.  Therefore I need somebody to
teach me how to use these programming environments, especially for
microarray analysis, next generation sequencing and constructing gene and
pathway interaction networks.  This is very difficult for me to figure out
without assistance because Zoomtext, my magnification and text to speech
software, on which I am depending because I am almost blind, has problems
reading out aloud many programming related websites to me.  And even those
websites it can read, it can only read sequentially from left to right and
then from top to bottom.  Unfortunately, this way of acquiring, finding,
selecting and processing new information and answering questions is too
tiresome, exhausting, ineffective and especially way too time consuming for
graduating with a PhD in bioinformatics before my funding runs out despite
being severely limited by my visual disability.  I would also need help
with writing a good literature review and applying the described techniques
to my own yeast Affimetrix microarray dataset because I cannot see well
enough to find all relevant publications on my own.



Since I am legally blind the rehab agency is giving me money to pay tutors
for this purpose.  Could you please help me getting in touch regarding this
with anybody, who could potentially be interested in teaching me one on one
thus saving me time for acquiring new information and skills, which I need
to finish my thesis on time, so that I can remain eligible for funding to
continue in my bioinformatics PhD program despite being almost blind?  The
tutoring can be done remotely via TeamViewer 5 and Skype.  Hence, it does
not matter where my tutors are physically located.  Currently I have tutors
in Croatia and UK.  But since they both work full time jobs while working
on their PhD dissertation they only have very limited time to teach me
online.  Could you therefore please forward this request for help to
anybody, who could potentially be interested or, who could connect me to
somebody, who might be, because my graduation and career depend on it?  Who
else would you recommend me to contact regarding this?  Where else could I
post this because I am in urgent need for help?



Could you please contact me directly via email at Thomas.F.Hahn2 at gmail.com
and/or Skype at tfh002 because my text to speech software has problems to
read out this website aloud to me?

I thank you very much in advance for your thoughts, ideas, suggestions,
recommendations, time, help, efforts and support.

With very warm regards,



*Thomas Hahn*

1)    *Graduate student in the Joint Bioinformatics Program at the
University of Arkansas at Little Rock (UALR) and the University of Arkansas
Medical Sciences (UAMS) &*

2)    *Research & Industry Advocate, Founder and Board Member of RADISH
MEDICAL SOLUTIONS, INC. (**http://www.radishmedical.com/thomas-hahn/*
<http://www.radishmedical.com/thomas-hahn/>*) *



*Primary email: **Thomas.F.Hahn2 at gmail.com* <Thomas.F.Hahn2 at gmail.com>

*Cell phone: 318 243 3940*

*Office phone: 501 682 1440*

*Office location: EIT 535*

*Skype ID: tfh002*

*Virtual Google Voice phone to reach me while logged into my email (i.e. *
*Thomas.F.Hahn2 at gmail.com* <Thomas.F.Hahn2 at gmail.com>*), even when having
no cell phone reception, e.g. in big massive buildings:  *(501) 301-4890
<%28501%29%20301-4890>



*Web links: *



1)      https://ualr.academia.edu/ThomasHahn

2)      https://www.linkedin.com/pub/thomas-hahn/42/b29/42

3)      http://facebook.com/Thomas.F.Hahn
<https://www.facebook.com/Thomas.F.Hahn>

4)      https://twitter.com/Thomas_F_Hahn


?

	[[alternative HTML version deleted]]


