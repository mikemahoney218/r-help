From jwd at surewest.net  Thu Dec  1 00:01:58 2016
From: jwd at surewest.net (John Dougherty)
Date: Wed, 30 Nov 2016 15:01:58 -0800
Subject: [R] transpose rows and columns for large data
In-Reply-To: <1367996161.3261271.1480440167187@mail.yahoo.com>
References: <1367996161.3261271.1480440167187.ref@mail.yahoo.com>
	<1367996161.3261271.1480440167187@mail.yahoo.com>
Message-ID: <20161130150158.27913feb@draco.site>

On Tue, 29 Nov 2016 17:22:47 +0000 (UTC)
Elham - via R-help <r-help at r-project.org> wrote:

> Is there another way (I prefer a way with Excel)?

Search on "friends don't let friends use excel for statistics."
Spreadsheets are an inherently perilous way to do statistics and Excel
specifically is notoriously poor. In fact the reason I originally began
using dedicated statistical packages (STATA first and now R) is that
spreadsheets (Excel in my case) can throw subtle errors that can create
problems. immediately, or even worse - later.  I had Excel return a
negative variance. Since variance is a squared value, unless you are
dealing with some very exotic numbers including imaginary values, a
negative variance is an absurd result.  Further investigation revealed
that other stat routines provided with Excel at the time were also
throwing errors that could look reasonable and thus be missed.  It was
also simply using erroneously constructed methods and providing
outright wrong results to things like Chi-square calculations.  

-- 

John


From carlganz at ucla.edu  Thu Dec  1 00:14:01 2016
From: carlganz at ucla.edu (Ganz, Carl)
Date: Wed, 30 Nov 2016 23:14:01 +0000
Subject: [R] Complex Survey MSE for prediction with ML
Message-ID: <A5A30F1D451F924B902DDE8063410E67117B65@EM1A.ad.ucla.edu>

Hello,

I have been toying with the survey package's withReplicates function, which lets users easily extend the survey package to support any weighted statistic. There are a number of ML algorithms in various packages that accept weights, and it is fairly easy to use them with withReplicates. Below is a na?ve example:

library(survey)
library(rpart)
library(gbm)

data(api)

# create survey object
dstrat<-svydesign(id=~1,strata=~stype, weights=~pw, data=apistrat, fpc=~fpc)

rstrat<-as.svrepdesign(dstrat)

# try rpart
predr <- as.data.frame(withReplicates(rstrat, function(w, data) {
  predict(rpart(api00~ell+meals+mobility,data=data,weights=w))
}))

# try gbm
predg <- as.data.frame(withReplicates(rstrat, function(w, data) {
  predict(gbm(api00~ell+meals+mobility,data=data,weights=w,
              n.trees=100))
}))

# try regular svyglm
preds <- as.data.frame(predict(svyglm(api00~ell+meals+mobility,rstrat)))

head(data.frame(predr,predg,preds))

With rpart, the standard errors are absurdly large, and clearly incorrect. With gbm, the results seem reasonable. 

I see in this extremely old post that you can't use quantile regression with withReplicates for some survey designs and expect to get reasonable results: https://stat.ethz.ch/pipermail/r-help/2008-August/171620.html

Quantiles and survey stats are messy business so that issue may be unique to quantile regressions, but based on that post it would seem that the function, and survey design need to have certain properties for withReplicates to generate valid SEs. This is not documented with withReplicates though. 

So my question is, what properties does an ML algorithm/survey design need for withReplicates to generate valid SEs?

Kind Regards,
Carl Ganz


From ashimkapoor at gmail.com  Thu Dec  1 04:55:23 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 1 Dec 2016 09:25:23 +0530
Subject: [R] Command for simple effects following 2 way anova with
	interaction
Message-ID: <CAC8=1epCOeZcwC1ZYXDeMv_tx+rh7LZo91X__LqNm=NXVqJQhA@mail.gmail.com>

Dear All,

Suppose I do :-

head(warpbreaks)
model1<- aov(breaks ~ wool*tension,data = warpbreaks)
summary(model1)

There is significant interaction. So I need to test for simple effects of
wool at each level of  tension and vice versa. I can do a subset and then
do a one way anova for each level of tension and wool. My query is that is
there any command programmed which can do this automatically?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Thu Dec  1 05:06:47 2016
From: chocold12 at gmail.com (lily li)
Date: Wed, 30 Nov 2016 21:06:47 -0700
Subject: [R] about data manipulation
Message-ID: <CAN5afy9=90=Fv_x=_pUO5=QS=7q4tYFdYO+gnj7Wh3C5nHkFdA@mail.gmail.com>

Hi R users,

I'm trying to manipulate dataset, but met some difficulties.

df
year   month   flow
2006     3        3.5
2006     4        3.8
2006     5        21
2006     6        32
2007     3        4.1
2007     4        4.4
...

I want to calculate total flow for each year, and use the code below:
aggregate(flow~year, data=df, sum)
But it gave the error message:
Error in get(as.character(FUN), mode = "function", envir = envir) :
  object 'FUN' of mode 'function' was not found

What is the problem and how to solve it? Thanks for your help.

	[[alternative HTML version deleted]]


From rmh at temple.edu  Thu Dec  1 06:08:11 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 1 Dec 2016 00:08:11 -0500
Subject: [R] Command for simple effects following 2 way anova with
	interaction
In-Reply-To: <CAC8=1epCOeZcwC1ZYXDeMv_tx+rh7LZo91X__LqNm=NXVqJQhA@mail.gmail.com>
References: <CAC8=1epCOeZcwC1ZYXDeMv_tx+rh7LZo91X__LqNm=NXVqJQhA@mail.gmail.com>
Message-ID: <CAGx1TMDEbjn4gNkNKXKCBWLLiC=7D4woNQ-AXsFEooKKJkoLgg@mail.gmail.com>

## Use the split argument to summary.aov

## This tests the levels of tension within each level of wool using a common
## Residuals sum of squares.

sapply(warpbreaks, levels)

model2 <- aov(breaks ~ wool/tension, data = warpbreaks)
colnames(model.matrix(model2))
## [1] "(Intercept)"    "woolB"          "woolA:tensionM" "woolB:tensionM"
## [5] "woolA:tensionH" "woolB:tensionH"
sapply(warpbreaks[2:3], levels)
summary(model2,
        split=list("wool:tension"=list("woolA/tension"=c(1,3),
                                       "woolB/tension"=c(2,4))))


## The less good choice has the same numerator sums of squares but
## different Residuals sums of squares, with fewer df for each,
## and comes to different conclusions.
model3A <- aov(breaks ~ tension,
               data = warpbreaks[warpbreaks$wool=="A",])
summary(model3A)

model3B <- aov(breaks ~ tension,
               data = warpbreaks[warpbreaks$wool=="B",])
summary(model3B)



## The boxplots show that model2 better describes the data.
## There is a significant difference for woolA and not for woolB.
library(lattice)
bwplot(breaks ~ tension | wool, data=warpbreaks)

On Wed, Nov 30, 2016 at 10:55 PM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> Dear All,
>
> Suppose I do :-
>
> head(warpbreaks)
> model1<- aov(breaks ~ wool*tension,data = warpbreaks)
> summary(model1)
>
> There is significant interaction. So I need to test for simple effects of
> wool at each level of  tension and vice versa. I can do a subset and then
> do a one way anova for each level of tension and wool. My query is that is
> there any command programmed which can do this automatically?
>
> Best Regards,
> Ashim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Thu Dec  1 07:21:47 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 1 Dec 2016 07:21:47 +0100
Subject: [R] about data manipulation
In-Reply-To: <CAN5afy9=90=Fv_x=_pUO5=QS=7q4tYFdYO+gnj7Wh3C5nHkFdA@mail.gmail.com>
References: <CAN5afy9=90=Fv_x=_pUO5=QS=7q4tYFdYO+gnj7Wh3C5nHkFdA@mail.gmail.com>
Message-ID: <B6582A6B-D36C-42BC-AC86-160B144C7243@xs4all.nl>


> On 1 Dec 2016, at 05:06, lily li <chocold12 at gmail.com> wrote:
> 
> Hi R users,
> 
> I'm trying to manipulate dataset, but met some difficulties.
> 
> df
> year   month   flow
> 2006     3        3.5
> 2006     4        3.8
> 2006     5        21
> 2006     6        32
> 2007     3        4.1
> 2007     4        4.4
> ...
> 
> I want to calculate total flow for each year, and use the code below:
> aggregate(flow~year, data=df, sum)
> But it gave the error message:
> Error in get(as.character(FUN), mode = "function", envir = envir) :
>  object 'FUN' of mode 'function' was not found
> 
> What is the problem and how to solve it? Thanks for your help.
> 

Not enough information.
If I try this

df <- read.table(text="year   month   flow
2006     3        3.5
2006     4        3.8
2006     5        21
2006     6        32
2007     3        4.1
2007     4        4.4
", header=TRUE)

df

aggregate(flow~year, data=df, sum)

I get a correct answer. So you are likely doing something weird and not showing us all.


> 	[[alternative HTML version deleted]]
> 

Plan text mail. Has been asked many, many times before.


Berend Hasselman


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Dec  1 07:41:12 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 1 Dec 2016 17:41:12 +1100
Subject: [R] about data manipulation
In-Reply-To: <CAN5afy9=90=Fv_x=_pUO5=QS=7q4tYFdYO+gnj7Wh3C5nHkFdA@mail.gmail.com>
References: <CAN5afy9=90=Fv_x=_pUO5=QS=7q4tYFdYO+gnj7Wh3C5nHkFdA@mail.gmail.com>
Message-ID: <CA+8X3fWrys3uH8kqsCJVtgEn3x=Defu-S-fFd-nYBORywGH1oA@mail.gmail.com>

Hi lily,
If you want to use aggregate, supply the name of the function:

aggregate(flow~year, data=df, "sum")

You can also use "by" like this

by(df$flow,df$year,FUN=sum)

I assume that you don't have to worry about missing months in a year.

Jim
:


On Thu, Dec 1, 2016 at 3:06 PM, lily li <chocold12 at gmail.com> wrote:
> Hi R users,
>
> I'm trying to manipulate dataset, but met some difficulties.
>
> df
> year   month   flow
> 2006     3        3.5
> 2006     4        3.8
> 2006     5        21
> 2006     6        32
> 2007     3        4.1
> 2007     4        4.4
> ...
>
> I want to calculate total flow for each year, and use the code below:
> aggregate(flow~year, data=df, sum)
> But it gave the error message:
> Error in get(as.character(FUN), mode = "function", envir = envir) :
>   object 'FUN' of mode 'function' was not found
>
> What is the problem and how to solve it? Thanks for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From qwertyui_period at yahoo.co.jp  Thu Dec  1 04:37:34 2016
From: qwertyui_period at yahoo.co.jp (qwertyui_period at yahoo.co.jp)
Date: Thu, 1 Dec 2016 12:37:34 +0900 (JST)
Subject: [R] Question about proxy setting of R
Message-ID: <669742.77077.qm@web102318.mail.kks.yahoo.co.jp>

Hello,

I use R 3.0.2 on Win 7 through proxy server using ".Rprofile" in home
directory that includes "Sys.setenv(http_proxy=proxy_server:port)".
There has been no problem to access the internet for some years.
In this situation, I installed R 3.3.1 and then entered "update.packages
()", however, "Proxy Authentification" window didn't show up and
failed to access the internet. Error messages are as below.

-------------------------------------------------------------------
> update.packages(ask='graphics',checkBuilt=TRUE)
--- Please select a CRAN mirror for use in this session ---
Warning: failed to download mirrors file (cannot open URL
'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
'C:/PROGRA~1/R/R-33~1.2/doc/CRAN_mirrors.csv'
Warning: unable to access index for repository
https://cran.ism.ac.jp/src/contrib: 
? cannot open URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES' 
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/src/contrib: 
? cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES' 
Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
? cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv': HTTP
status was '407 Proxy Authentication Required'

-------------------------------------------------------------------

Strange to say, R 3.0.2 is able to access to the internet, and R 3.3.1
shows collect proxy setting in ".Rprofile"? by "Sys.getenv("http_proxy")"
From internet information, I added "http_proxy_user=ask" to ".Rprofile", or
" --internet2" to the desktop icon of R 3.3.1, ending up in the same
result.

Please show me the way of proxy setting of R 3.3.1.


From fernando.mozas at trackglobe.com  Thu Dec  1 09:07:00 2016
From: fernando.mozas at trackglobe.com (Fernando Mozas Enguita)
Date: Thu, 1 Dec 2016 08:07:00 +0000
Subject: [R] R & MongoDB
Message-ID: <DB5PR07MB1621E4CE3471F4BA2032B82EE68F0@DB5PR07MB1621.eurprd07.prod.outlook.com>

Hi Everyone!

I?m new in R-world and I need help.
I need to make an R-script for PowerBI to connect with a MongoDB data source and I don?t have so much idea

I have a dataset in a Mongo DB like this:

/* 1 */
{
    "_id" : ObjectId("5819ad77d8828e871ce09297"),
    "Date" : 1478077741,
    "Receptor" : "CORMAD",
    "Position" : "02112016",
    "clients" : [
        {
            "mac" : "A2:C2:CA:18:F0:5E",
            "vendor" : "",
            "lastSeen" : 1478077746,
            "power" : -80,
            "R" : "",
            "bssid" : "(not associated) ",
            "essid" : [],
            "probedESSID" : [
                "any"
            ]
        },
        {
            "mac" : "D6:B0:C2:0E:2B:A0",
            "vendor" : "",
            "lastSeen" : 1478077755,
            "power" : -78,
            "R" : "",
            "bssid" : "(not associated) ",
            "essid" : [],
            "probedESSID" : [
                "any"
            ]
        }
/* 2 */
{
    "_id" : ObjectId("5819b009d8828e871ce092dc"),
    "Date" : 1478078401,
    "Receptor" : "CORMAD",
    "Position" : "02112016",
    "clients" : [
        {
            "mac" : "C0:38:96:86:1E:91",
            "vendor" : "HonHaiPr",
            "lastSeen" : 1478078443,
            "power" : -80,
            "R" : "",
            "bssid" : "0A:18:D6:2B:7F:EB",
            "essid" : [],
            "probedESSID" : [
                "any"
            ]
        },
        {
            "mac" : "F4:F1:E1:60:73:D2",
            "vendor" : "Motorola",
            "lastSeen" : 1478078410,
            "power" : -78,
            "R" : "",
            "bssid" : "(not associated) ",
            "essid" : [],
            "probedESSID" : [
                "JAZZTEL_HY7S"
            ]
        }

How can I iterate throw all the clients to extract the information?
I need to have a classic table with the information.
One row with the fields :
_id | Date | Receptor | Position | clients | mac | vendor | lastSeen | power | R | bssid | essid | probedESSID


Thanks!
Fernando.





	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Thu Dec  1 14:48:06 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 1 Dec 2016 19:18:06 +0530
Subject: [R] Interpreting summary.lm for a 2 factor anova
Message-ID: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>

Dear all,

Here is a small example : -

> model <- aov(breaks ~ wool * tension, data = warpbreaks)
> summary.lm(model)

Call:
aov(formula = breaks ~ wool * tension, data = warpbreaks)

Residuals:
     Min       1Q   Median       3Q      Max
-19.5556  -6.8889  -0.6667   7.1944  25.4444

Coefficients:
               Estimate Std. Error t value Pr(>|t|)
(Intercept)      44.556      3.647  12.218 2.43e-16 ***
woolB           -16.333      5.157  -3.167 0.002677 **
tensionM        -20.556      5.157  -3.986 0.000228 ***
tensionH        -20.000      5.157  -3.878 0.000320 ***
woolB:tensionM   21.111      7.294   2.895 0.005698 **
woolB:tensionH   10.556      7.294   1.447 0.154327
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 10.94 on 48 degrees of freedom
Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772

> model.tables(model,"e")
Tables of effects

 wool
wool
      A       B
 2.8889 -2.8889

 tension
tension
     L      M      H
 8.241 -1.759 -6.481

 wool:tension
    tension
wool L      M      H
   A  5.278 -5.278  0.000
   B -5.278  5.278  0.000


> model.tables(model,"m")
Tables of means
Grand mean

28.14815

 wool
wool
     A      B
31.037 25.259

 tension
tension
    L     M     H
36.39 26.39 21.67

 wool:tension
    tension
wool L     M     H
   A 44.56 24.00 24.56
   B 28.22 28.78 18.78
>

I don't follow the output of summary.lm. I understand the output of
model.tables for effects and means. For instance what does 44.556 represent
? Is it the grand average ? The grand mean is 28.14815. Can someone help me
understand the output of summary.lm ?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From gpetris at uark.edu  Thu Dec  1 17:01:20 2016
From: gpetris at uark.edu (Giovanni Petris)
Date: Thu, 1 Dec 2016 16:01:20 +0000
Subject: [R] Ajdustment of data symbols
Message-ID: <1480608080171.60714@uark.edu>


Hello,

Is there a way to specify a non-default adjustment for data symbols, similar to what "adj" does for text? 

For example, the following lines of code produce a red triangle on the bottom border of the plot:

plot(0, 0, type = 'n', xlab = "", ylab = "")
points(0.25, par("usr")[3], pch = 17, col = "red", cex = 2, xpd = TRUE)

I would like to draw the triangle completely outside the plotting area, with the upper vertex touching the x-axis...

Thank you in advance!

Best,
Giovanni



--
Giovanni Petris, PhD
Professor
Director of Statistics
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/



From dcarlson at tamu.edu  Thu Dec  1 17:18:49 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Dec 2016 16:18:49 +0000
Subject: [R] Ajdustment of data symbols
In-Reply-To: <1480608080171.60714@uark.edu>
References: <1480608080171.60714@uark.edu>
Message-ID: <1250a65182204665abaf61027b09c398@exch-2p-mbx-w2.ads.tamu.edu>

Try this. The par("cxy") gets a vector of character width and height in user coordinates.

points(0.25, par("usr")[3]-par("cxy")[2]/2, pch = 17, col = "red", cex = 2, xpd = TRUE)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Giovanni Petris
Sent: Thursday, December 1, 2016 10:01 AM
To: r-help at r-project.org
Cc: Giovanni Petris
Subject: [R] Ajdustment of data symbols


Hello,

Is there a way to specify a non-default adjustment for data symbols, similar to what "adj" does for text? 

For example, the following lines of code produce a red triangle on the bottom border of the plot:

plot(0, 0, type = 'n', xlab = "", ylab = "")
points(0.25, par("usr")[3], pch = 17, col = "red", cex = 2, xpd = TRUE)

I would like to draw the triangle completely outside the plotting area, with the upper vertex touching the x-axis...

Thank you in advance!

Best,
Giovanni



--
Giovanni Petris, PhD
Professor
Director of Statistics
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From peljasz at yahoo.co.uk  Thu Dec  1 17:20:52 2016
From: peljasz at yahoo.co.uk (lejeczek)
Date: Thu, 1 Dec 2016 16:20:52 +0000
Subject: [R] R re-base/compile problem
Message-ID: <f591fb46-fe14-a7ae-35de-58dc5f4e2b9f@yahoo.co.uk>

hi everyone.

this will be a bit rpm packaging related, not sure if more 
than R itself but before going to rpm gang I hoped someone 
here knows:
why this:

byte-compiling package 'compiler'
Warning in file(datafile, "wb") :
   cannot open file 
'/usr/lib64/R-MY/lib64/R/library/compiler/R/compiler.rdb': 
Permission denied
Error in file(datafile, "wb") : cannot open the connection
Calls: <Anonymous> -> code2LazyLoadDB -> makeLazyLoadDB -> 
close -> file
Execution halted

happens when I rpmbuild R?
I do a bit of mangling there, but nothing in the sources of 
R, just rpm spec files & paths.

Why build process would call this file? (which is not there 
anyway)

Weirder is that if rpm packages (of that my custom build) 
are already installed that problem occurs, build fails only 
then. Suffice to yum/rpm uninstall those R-MY* packages and 
rpm build process is successful.

To me it's strangest thing, but an expert hopefully knows 
what is going on there.
many thanks,
L.


From gpetris at uark.edu  Thu Dec  1 17:31:50 2016
From: gpetris at uark.edu (Giovanni Petris)
Date: Thu, 1 Dec 2016 16:31:50 +0000
Subject: [R] Ajdustment of data symbols
In-Reply-To: <1250a65182204665abaf61027b09c398@exch-2p-mbx-w2.ads.tamu.edu>
References: <1480608080171.60714@uark.edu>,
	<1250a65182204665abaf61027b09c398@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <1480609910424.2858@uark.edu>


That's exactly what I was looking for! 

Thank you,
Giovanni

________________________________________
From: David L Carlson <dcarlson at tamu.edu>
Sent: Thursday, December 1, 2016 10:18
To: Giovanni Petris; r-help at r-project.org
Subject: RE: Ajdustment of data symbols

Try this. The par("cxy") gets a vector of character width and height in user coordinates.

points(0.25, par("usr")[3]-par("cxy")[2]/2, pch = 17, col = "red", cex = 2, xpd = TRUE)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Giovanni Petris
Sent: Thursday, December 1, 2016 10:01 AM
To: r-help at r-project.org
Cc: Giovanni Petris
Subject: [R] Ajdustment of data symbols


Hello,

Is there a way to specify a non-default adjustment for data symbols, similar to what "adj" does for text?

For example, the following lines of code produce a red triangle on the bottom border of the plot:

plot(0, 0, type = 'n', xlab = "", ylab = "")
points(0.25, par("usr")[3], pch = 17, col = "red", cex = 2, xpd = TRUE)

I would like to draw the triangle completely outside the plotting area, with the upper vertex touching the x-axis...

Thank you in advance!

Best,
Giovanni



--
Giovanni Petris, PhD
Professor
Director of Statistics
Department of Mathematical Sciences
University of Arkansas - Fayetteville, AR 72701
Ph: (479) 575-6324, 575-8630 (fax)
http://definetti.uark.edu/


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DgIFAg&c=7ypwAowFJ8v-mw8AB-SdSueVQgSDL4HiiSaLK01W8HA&r=C3DNvy_azplKSvJKgvsgjA&m=eJAlQ1Qalin1IVzkWmqtiDeAOsMhi2ionhGq4KT4u7g&s=SkVbrPUxN4YKUKSG8tTpDTqYcf8VixPuh9HHA38yCuo&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DgIFAg&c=7ypwAowFJ8v-mw8AB-SdSueVQgSDL4HiiSaLK01W8HA&r=C3DNvy_azplKSvJKgvsgjA&m=eJAlQ1Qalin1IVzkWmqtiDeAOsMhi2ionhGq4KT4u7g&s=jW3W6tyyH73FqGxaGgFKnmreBfxV0cwwV9dw0o0gdPc&e=
and provide commented, minimal, self-contained, reproducible code.


From ash369ster at gmail.com  Thu Dec  1 16:45:41 2016
From: ash369ster at gmail.com (Ashwini Patil)
Date: Thu, 1 Dec 2016 10:45:41 -0500
Subject: [R]  Bootstrap using ARIMA model
Message-ID: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>

Hi,

I want to implement a bootstrap method for time series.
I am taking the adj close values from yahoo for NFLX and now I need to
bootstrap these values using ARIMA model.

here is my code so far:
rm(list = ls())
library(boot)
library(tseries)
library(TTR)
library(quantmod)
library(scales)
library(forecast)
library(zoo)
library(TSA)
security<-"NFLX"
startDate<-"2012-06-01"
endDate<-"2016-10-31"
qte_list<-c("AdjClose")

data=get.hist.quote(instrument = security, startDate, endDate, quote =
qte_list,   provider = "yahoo" )
logret<-diff(log(data[,1]))
fit11<-auto.arima(logret, max.order=10)

When i use auto.arima, I get an order of (0,0,0) with non-zero mean. After
this, I tried to use tsboot function but it is not yielding any answers.

Any and all help is appreciated.

Thank you!

	[[alternative HTML version deleted]]


From lokomiauw at gmail.com  Thu Dec  1 16:22:37 2016
From: lokomiauw at gmail.com (lolo koko)
Date: Thu, 1 Dec 2016 16:22:37 +0100
Subject: [R] How to setup a multiplicative dummy function in R
Message-ID: <CAL+9viOmtRb0ZAPkZ27qG52L-T8r0M8Yh9MCzuNLJrbOt0nXJg@mail.gmail.com>

Hello?

Does anyone know how I can implement the below equation in R? I would
like to estimate the following equation:

  y=beta_ij * (1+gamma_j * dummy) * x_ij

where y is continuous, and all the x variables (j of them) are i=3
level categorical variables. The intuition is that instead of
estimating the additive value for a dummy variable, I would like to
estimate the multiplicative value for the dummy variable. Thus the
presence of the dummy would scale the beta. Note that for each x
variable there is only one gamma.

For concreteness, you can imagine that y is a continious test score, x
are categorical variables indicating different types of education
achievements, each type of education achievement is categorised in 3
levels (none, some, a lot), and the dummy indicates race. In this
model I believe that race affects test scores proportionally to
estimated beta of each education level. This avoids having to estimate
a gamma for each education achievement level.

Is the solution to simply use nls {stats} and type out the equation?

Hope the explanation makes sense, happy to explain further.

Best wishes,

Peter


From sandeepmarla at gmail.com  Thu Dec  1 16:00:45 2016
From: sandeepmarla at gmail.com (Sandeep Reddy Marla)
Date: Thu, 1 Dec 2016 09:00:45 -0600
Subject: [R] (no subject)
Message-ID: <CAO6KqEyQ2XK=3qjZjgMEC=5fgoEA17tGpp4d-3sOE-6MYNwHzw@mail.gmail.com>

Hello,

I'm trying to generate heat map for differential expression data. I ranked
each data row and used that for heat map visualization (included an example
data set with script). When difference between numbers within each row is
small, still heat map is not representing correctly as it is ranking that
was used for heat map. Therefore, I tried using scale='row', but the heat
map is not looking as good as ranked data heat map.

In scale = row argument, I want the highest value and lowest values color
to be colors that I have provided and the intermediate values (example:
values of 0,1,500,700 - 0 with royalblue3, 700 with yellow, and 1 and 500
adjusted as per the scale) be colored according to their value. Are there
any arguments to fix this problem in R heatmap.2, your help will be greatly
appreciated.

#creating a sample data set
Bo <- c(0,32,200,1500)
No <- c(5,100, 250, 70)
Bc <- c(700,523,80,3000)
Nc <- c(1,0, 300, 30)
GeneID <- c("G1", "G2","G3","G4")

DEG <- data.frame(GeneID, Bo,No,Bc,Nc)
DEG_data <- DEG[ -(1)]
DEG_data <- as.matrix(DEG_data)
class(DEG_data) <- 'numeric'

ranked_DEG_data <- t(apply(DEG_data, 1, rank))


#generating a heat map using ranked values for each row
#rank 1 is royalblue3 and rank4 is yellow
heatmap.2(ranked_DEG_data, cellnote=DEG_data, notecex=0.7,
          notecol="black",cexRow =0.6,cexCol =1.5, srtCol=360,
          trace="none", dendrogram ='none', Rowv=F, Colv=F, keysize=1,
scale="row",
          ,adjCol=c(0.5,0.25),
          col=colorpanel(100, low="royalblue3", high="yellow"))

#generating a heat map using real values
#rank 1 is royalblue3 and rank4 is yellow in the above heat map but scaling
is not providing similar map for high and low values
heatmap.2(DEG_data, cellnote=DEG_data, notecex=0.7,
          notecol="black",cexRow =0.6,cexCol =1.5, srtCol=360,
          trace="none", dendrogram ='none', Rowv=F, Colv=F, keysize=1,
scale="row",
        ,adjCol=c(0.5,0.25),
          col=colorpanel(100, low="royalblue3", high="yellow"))

Thanks

	[[alternative HTML version deleted]]


From HDoran at air.org  Thu Dec  1 18:27:43 2016
From: HDoran at air.org (Doran, Harold)
Date: Thu, 1 Dec 2016 17:27:43 +0000
Subject: [R] Splitting or Subsetting Using foreach
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601358E85D7@DC1VEX10MB01.air.org>

I am having tremendous fortune using the foreach function in the foreach package sending work out to multiple cores in order to reduce computational time.

I am experimenting with which types of tasks benefit from running in parallel and which do not and so this is a bit of a learning experience by trial and error.

One particular task I cannot seem to realize a benefit from (in terms of reduced time) is splitting or subsetting a large data frame. I realize there are other "fast" options like using data.table, but current goal is to see if this can benefit from multiple cores or not. 

So, a very small toy example of how I am approaching the "traditional" and "parallel" way is as follows. My actual data is much, much larger and it turns out the parallel version of doing it this way vis-?-vis the traditional way is unbelievably slow. Hence Im not sure if there is a good theoretical reason why such a task cannot run faster when sent out to multiple cores if there is a user error that I need to better understand and correct

library(foreach)
library(doParallel)
registerDoParallel(cores=4)

tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))

ff1 <- split(tmp, tmp$id)

myList <- unique(tmp$id)
N <- length(myList)
ff2 <- foreach(i = 1:N) %dopar% { tmp[which(tmp$id == myList[i]),]}

Thanks,
Harold


From jdnewmil at dcn.davis.ca.us  Thu Dec  1 18:36:31 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Dec 2016 09:36:31 -0800
Subject: [R] R re-base/compile problem
In-Reply-To: <f591fb46-fe14-a7ae-35de-58dc5f4e2b9f@yahoo.co.uk>
References: <f591fb46-fe14-a7ae-35de-58dc5f4e2b9f@yahoo.co.uk>
Message-ID: <034D0445-1767-4E87-804D-D862F7CDA7BC@dcn.davis.ca.us>

You MIGHT get an answer here,  but this type of question is more likely to belong on the R-devel mailing list than here. See the Posting Guide. 
-- 
Sent from my phone. Please excuse my brevity.

On December 1, 2016 8:20:52 AM PST, lejeczek via R-help <r-help at r-project.org> wrote:
>hi everyone.
>
>this will be a bit rpm packaging related, not sure if more 
>than R itself but before going to rpm gang I hoped someone 
>here knows:
>why this:
>
>byte-compiling package 'compiler'
>Warning in file(datafile, "wb") :
>   cannot open file 
>'/usr/lib64/R-MY/lib64/R/library/compiler/R/compiler.rdb': 
>Permission denied
>Error in file(datafile, "wb") : cannot open the connection
>Calls: <Anonymous> -> code2LazyLoadDB -> makeLazyLoadDB -> 
>close -> file
>Execution halted
>
>happens when I rpmbuild R?
>I do a bit of mangling there, but nothing in the sources of 
>R, just rpm spec files & paths.
>
>Why build process would call this file? (which is not there 
>anyway)
>
>Weirder is that if rpm packages (of that my custom build) 
>are already installed that problem occurs, build fails only 
>then. Suffice to yum/rpm uninstall those R-MY* packages and 
>rpm build process is successful.
>
>To me it's strangest thing, but an expert hopefully knows 
>what is going on there.
>many thanks,
>L.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Dec  1 19:19:32 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Dec 2016 10:19:32 -0800
Subject: [R] Bootstrap using ARIMA model
In-Reply-To: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>
References: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>
Message-ID: <0B3D77C5-5B29-4709-B157-B0ED2253AC84@comcast.net>


> On Dec 1, 2016, at 7:45 AM, Ashwini Patil <ash369ster at gmail.com> wrote:
> 
> Hi,
> 
> I want to implement a bootstrap method for time series.
> I am taking the adj close values from yahoo for NFLX and now I need to
> bootstrap these values using ARIMA model.
> 
> here is my code so far:
> rm(list = ls())
> library(boot)
> library(tseries)
> library(TTR)
> library(quantmod)
> library(scales)
> library(forecast)
> library(zoo)
> library(TSA)
> security<-"NFLX"
> startDate<-"2012-06-01"
> endDate<-"2016-10-31"
> qte_list<-c("AdjClose")
> 
> data=get.hist.quote(instrument = security, startDate, endDate, quote =
> qte_list,   provider = "yahoo" )
> logret<-diff(log(data[,1]))
> fit11<-auto.arima(logret, max.order=10)
> 
> When i use auto.arima, I get an order of (0,0,0) with non-zero mean. After
> this, I tried to use tsboot function but it is not yielding any answers.

_How_ did you use tsboot?


> 
> Any and all help is appreciated.
> 
> Thank you!
> 
> 	[[alternative HTML version deleted]]

Plain text. Please. Per the Posting Guide.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Thu Dec  1 19:50:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 1 Dec 2016 10:50:14 -0800
Subject: [R] Bootstrap using ARIMA model
In-Reply-To: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>
References: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>
Message-ID: <CAGxFJbTiPn1nuRUTPniLmBs4tHp0yHQAJpOGhR0V40CKBUuRrA@mail.gmail.com>

Just briefly to follow up David's comment, though this is mainly about
statistics and therefore off topic here...

Bootstrapping time series is a subtle issue that requires familiarity
with the technical details-- and maybe even current research. The
tsboot() function gives you several options from which you must choose
*appropriately* -- or maybe choose something else entirely. The Help
doc gives you a sense of the difficulties:

***************
Model based resampling is very similar to the parametric bootstrap and
all simulation must be in one of the user specified functions. This
avoids the complicated problem of choosing the block length but relies
on an accurate model choice being made.

Phase scrambling is described in Section 8.2.4 of Davison and Hinkley
(1997). The types of statistic for which this method produces
reasonable results is very limited and the other methods seem to do
better in most situations. Other types of resampling in the frequency
domain can be accomplished using the function boot with the argument
sim = "parametric".
****

Moral: If you don't know what you're doing, seek local expertise to
help -- remote sites offering suggestions from those who aren't
familiar with the details of your data and analysis goals (maybe you
don't need to do this at all!) may lead you to irreproducible
nonsense.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 1, 2016 at 7:45 AM, Ashwini Patil <ash369ster at gmail.com> wrote:
> Hi,
>
> I want to implement a bootstrap method for time series.
> I am taking the adj close values from yahoo for NFLX and now I need to
> bootstrap these values using ARIMA model.
>
> here is my code so far:
> rm(list = ls())
> library(boot)
> library(tseries)
> library(TTR)
> library(quantmod)
> library(scales)
> library(forecast)
> library(zoo)
> library(TSA)
> security<-"NFLX"
> startDate<-"2012-06-01"
> endDate<-"2016-10-31"
> qte_list<-c("AdjClose")
>
> data=get.hist.quote(instrument = security, startDate, endDate, quote =
> qte_list,   provider = "yahoo" )
> logret<-diff(log(data[,1]))
> fit11<-auto.arima(logret, max.order=10)
>
> When i use auto.arima, I get an order of (0,0,0) with non-zero mean. After
> this, I tried to use tsboot function but it is not yielding any answers.
>
> Any and all help is appreciated.
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nell.redu at hotmail.fr  Thu Dec  1 20:10:57 2016
From: nell.redu at hotmail.fr (Nelly Reduan)
Date: Thu, 1 Dec 2016 19:10:57 +0000
Subject: [R] Run a Python code from R
In-Reply-To: <9d9685bf-b075-94be-356b-923f7de82ca0@atsu.edu>
References: <CY1PR05MB273092A72F36BAEB24AA5C9199BE0@CY1PR05MB2730.namprd05.prod.outlook.com>
	<CAKyN3iBNQDUuzNRVvJMvw+HVzcsuqrBTj545ZfM=D8B0+nG9SQ@mail.gmail.com>
	<SN2PR05MB2734537C1D81907B21E8063999B10@SN2PR05MB2734.namprd05.prod.outlook.com>
	<3F13A4EB-7546-4DF8-8515-BE2A2ADDA8D6@comcast.net>,
	<9d9685bf-b075-94be-356b-923f7de82ca0@atsu.edu>
Message-ID: <CY1PR05MB2730DAB68295D536F3533176998F0@CY1PR05MB2730.namprd05.prod.outlook.com>


Hello,



Thanks a lot for your answers. Finally, I'm using the function system2() to run the python script. However, I don't know how to define a list of numeric values in the character vector of arguments for the function system2 (i.e., in ?args? of the function system2() ) ?



In the Python script, the list of numeric values is defined as follows:

import sys

import nlmpy



weights = sys.argv[1] ## where weights = [0.5, 0.5]



outputNLM = nlmpy.classifyArray(?, weights)



print outputNLM



In the script R, how can I specify the argument weights = [0.5, 0.5] to run the Python script ?



Thanks a lot for your time.

Have a nice day

Nell


________________________________
De : Robert Baer <rbaer at atsu.edu>
Envoy? : samedi 19 novembre 2016 16:05:13
? : David Winsemius; Nelly Reduan
Cc : r-help at r-project.org
Objet : Re: [R] Run a Python code from R


>From https://www.r-bloggers.com/rpithon-vs-rpython/

<https://www.r-bloggers.com/rpithon-vs-rpython/>"Similar to rPython, the rPithon package (http://rpithon.r-forge.r-project.org) allows users to execute Python code from R and exchange the data between Python and R. However, the underlying mechanisms between these two packages are fundamentally different. Wihle rPithon communicates with Python from R through pipes, rPython accomplishes the same task with json. A major advantage of rPithon over rPython is that multiple Python processes can be started within a R session. However, rPithon is not very robust while exchanging large data objects between R and Python."

On 11/16/2016 7:10 PM, David Winsemius wrote:




On Nov 16, 2016, at 4:53 PM, Nelly Reduan <nell.redu at hotmail.fr><mailto:nell.redu at hotmail.fr> wrote:

[[elided Hotmail spam]]


I 'm trying to use the package "rPithon" but I obtain this error message:



Are you sure you are not just misspelling rPython? If that's not the issue than you need to say where you got rPithon,


>From https://www.r-bloggers.com/rpithon-vs-rpython/

"Similar to rPython, the rPithon package (http://rpithon.r-forge.r-project.org) allows users to execute Python code from R and exchange the data between Python and R. However, the underlying mechanisms between these two packages are fundamentally different. While rPithon communicates with Python from R through pipes, rPython accomplishes the same task with json. A major advantage of rPithon over rPython is that multiple Python processes can be started within a R session. However, rPithon is not very robust while exchanging large data objects between R and Python."


On Wed, Nov 16, 2016 at 4:53 PM, Nelly Reduan <nell.redu at hotmail.fr><mailto:nell.redu at hotmail.fr> wrote:


Hello,


How can I run this Python code from R ?




import nlmpy
nlm = nlmpy.mpd(nRow=50, nCol=50, h=0.75)
nlmpy.exportASCIIGrid("raster.asc", nlm)




Nlmpy is a Python package to build neutral landscape models

https://pypi.python.org/pypi/nlmpy . The example comes from this website. I tried to use the function system2 but I don't know how to use it.


path_script_python <- "C:/Users/Anaconda2/Lib/site-packages/nlmpy/nlmpy.py"

test <- system2("python", args = c(path_script_python, as.character(nRow), as.character(nCol), as.character(h)))

Thanks a lot for your help.
Nell


nlmpy 0.1.3 : Python Package Index<https://pypi.python.org/pypi/nlmpy><https://pypi.python.org/pypi/nlmpy>
pypi.python.org
NLMpy. NLMpy is a Python package for the creation of neutral landscape models that are widely used in the modelling of ecological patterns and processes across ...



       [[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From sabasehrish at yahoo.com  Thu Dec  1 20:40:26 2016
From: sabasehrish at yahoo.com (Saba Sehrish)
Date: Thu, 1 Dec 2016 19:40:26 +0000 (UTC)
Subject: [R] Identifying Gender
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
Message-ID: <824423988.5512390.1480621226455@mail.yahoo.com>

Hi
I have a csv file of Names based on male and female managers. Is there some code in R to identify the gender by names?
ThanksSaba

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Dec  1 21:00:12 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 01 Dec 2016 20:00:12 +0000
Subject: [R] Identifying Gender
In-Reply-To: <824423988.5512390.1480621226455@mail.yahoo.com>
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
	<824423988.5512390.1480621226455@mail.yahoo.com>
Message-ID: <5840814C.6040808@sapo.pt>

Hello,

I doubt there is, at least a search with package sos didn't show 
anything usefull.
But a google search found
https://github.com/KartikTalwar/LeGenderary

Maybe you can get inspiration from there and adapt to R code.

Rui Barradas

Em 01-12-2016 19:40, Saba Sehrish via R-help escreveu:
> identify the gender by name


From sezenismail at gmail.com  Thu Dec  1 21:05:47 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 1 Dec 2016 23:05:47 +0300
Subject: [R] Identifying Gender
In-Reply-To: <824423988.5512390.1480621226455@mail.yahoo.com>
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
	<824423988.5512390.1480621226455@mail.yahoo.com>
Message-ID: <E386281D-58EF-4434-9AB7-8FB1FAC2A674@gmail.com>


> On 1 Dec 2016, at 22:40, Saba Sehrish via R-help <r-help at r-project.org> wrote:
> 
> Hi
> I have a csv file of Names based on male and female managers. Is there some code in R to identify the gender by names?
> ThanksSaba
> 

A simple google search gives the what you are after [1]. But I think it works only for English names. Consider this before use.

1- https://cran.r-project.org/web/packages/gender/index.html


From murdoch.duncan at gmail.com  Thu Dec  1 21:10:06 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 1 Dec 2016 15:10:06 -0500
Subject: [R] Identifying Gender
In-Reply-To: <824423988.5512390.1480621226455@mail.yahoo.com>
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
	<824423988.5512390.1480621226455@mail.yahoo.com>
Message-ID: <70da42ce-95d3-ab61-b882-4a6af05014e4@gmail.com>

On 01/12/2016 2:40 PM, Saba Sehrish via R-help wrote:
> Hi
> I have a csv file of Names based on male and female managers. Is there some code in R to identify the gender by names?

There was a package called genderNames on CRAN for a couple of months, 
but the maintainer abandoned it.  You could recover it from the CRAN 
archive and see if you can get it to build.

Look for it in <https://cran.r-project.org/src/contrib/Archive>.

Duncan Murdoch


From rshepard at appl-ecosys.com  Thu Dec  1 21:42:20 2016
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 1 Dec 2016 12:42:20 -0800 (PST)
Subject: [R] Identifying Gender
In-Reply-To: <824423988.5512390.1480621226455@mail.yahoo.com>
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
	<824423988.5512390.1480621226455@mail.yahoo.com>
Message-ID: <alpine.LNX.2.11.1612011238020.14276@localhost>

On Thu, 1 Dec 2016, Saba Sehrish via R-help wrote:

> I have a csv file of Names based on male and female managers. Is there
> some code in R to identify the gender by names?

Saba,

   Despite the availability of some tools you'll never find a satisfactory
answer. Consider Lynn, Alex, Ari, Blaine, Blake, Bobby, etc. Then you'll get
others that don't fall into any discrete category.

   Perhaps a separate column in your CSV file for gender?

Rich


From sezenismail at gmail.com  Thu Dec  1 21:58:24 2016
From: sezenismail at gmail.com (Ismail SEZEN)
Date: Thu, 1 Dec 2016 23:58:24 +0300
Subject: [R] Identifying Gender
In-Reply-To: <alpine.LNX.2.11.1612011238020.14276@localhost>
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
	<824423988.5512390.1480621226455@mail.yahoo.com>
	<alpine.LNX.2.11.1612011238020.14276@localhost>
Message-ID: <9683FAB6-F51C-4C88-B07A-41A6D657C646@gmail.com>


> On 1 Dec 2016, at 23:42, Rich Shepard <rshepard at appl-ecosys.com> wrote:
> 
> On Thu, 1 Dec 2016, Saba Sehrish via R-help wrote:
> 
>> I have a csv file of Names based on male and female managers. Is there
>> some code in R to identify the gender by names?
> 
> Saba,
> 
>  Despite the availability of some tools you'll never find a satisfactory
> answer. Consider Lynn, Alex, Ari, Blaine, Blake, Bobby, etc. Then you'll get
> others that don't fall into any discrete category.
> 
>  Perhaps a separate column in your CSV file for gender?
> 

Rich is right and I don?t think that you have thousands of "managers". Perhaps maximum 100? So, it?s more reasonable to identify the gender manually.


From dwinsemius at comcast.net  Thu Dec  1 22:11:39 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Dec 2016 13:11:39 -0800
Subject: [R] Splitting or Subsetting Using foreach
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68601358E85D7@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68601358E85D7@DC1VEX10MB01.air.org>
Message-ID: <97B68F00-918B-45DB-B370-4D70799B4BDF@comcast.net>


> On Dec 1, 2016, at 9:27 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I am having tremendous fortune using the foreach function in the foreach package sending work out to multiple cores in order to reduce computational time.
> 
> I am experimenting with which types of tasks benefit from running in parallel and which do not and so this is a bit of a learning experience by trial and error.
> 
> One particular task I cannot seem to realize a benefit from (in terms of reduced time) is splitting or subsetting a large data frame. I realize there are other "fast" options like using data.table, but current goal is to see if this can benefit from multiple cores or not. 
> 
> So, a very small toy example of how I am approaching the "traditional" and "parallel" way is as follows. My actual data is much, much larger and it turns out the parallel version of doing it this way vis-?-vis the traditional way is unbelievably slow. Hence Im not sure if there is a good theoretical reason why such a task cannot run faster when sent out to multiple cores if there is a user error that I need to better understand and correct
> 
> library(foreach)
> library(doParallel)
> registerDoParallel(cores=4)
> 
> tmp <- data.frame(id = rep(1:200, each = 10), foo = rnorm(2000))
> 
> ff1 <- split(tmp, tmp$id)
> 
> myList <- unique(tmp$id)
> N <- length(myList)
> ff2 <- foreach(i = 1:N) %dopar% { tmp[which(tmp$id == myList[i]),]}

I would have imagined that using split to deliver separate instance of separate data.frame parcels to the `i` -argument would be more sensible. Otherwise you are sending full copies to each worker and then doing the extraction N times rather than once.There's a lot of checking using data.frame methods. I also think you would want to avoid making reference to objects "outside" the parallel function application.

ff2 <- foreach( z = iter( ff1) ) %dopar% { max(z$id) }


> 
> Thanks,
> Harold
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From elysa.mitova at gmail.com  Thu Dec  1 21:10:18 2016
From: elysa.mitova at gmail.com (Elysa Mitova)
Date: Thu, 1 Dec 2016 21:10:18 +0100
Subject: [R] Plotting Confidence Intervals into a density plot
Message-ID: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>

Hi,

I am desperately looking for a way to plot confidence intervals into a
density plot of only one variable (not a scatter plot etc.)

Have you any advice how to do this?

I've only found manual ways to do with "abline", but this is a rather
bothersome method and only works with ggplot (and not ggplot2).

Thank you!

	[[alternative HTML version deleted]]


From patrcasi at nova.edu  Thu Dec  1 21:48:26 2016
From: patrcasi at nova.edu (Patrick Casimir)
Date: Thu, 1 Dec 2016 20:48:26 +0000
Subject: [R] DocumentTermMatrix
Message-ID: <BN6PR06MB30255629439E52AD3F90BA02B98F0@BN6PR06MB3025.namprd06.prod.outlook.com>

My dtm is showing the 4 files in the corpus correctly, but the number of terms is incorrect at 0. What can cause that?

dtm <- DocumentTermMatrix(docs)
dtm
## <<DocumentTermMatrix (documents: 4, terms: 0)>>


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jfhenson1 at gmail.com  Thu Dec  1 22:17:19 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Thu, 1 Dec 2016 15:17:19 -0600
Subject: [R] confidence intervals for orthogonal contrasts
Message-ID: <CABPq8JOr9ae+7vms8RMN85BJfkE4bcgzc+VbVfoUJTD_uhTtOw@mail.gmail.com>

Hi R users,
Is there a way to calculate a confidence interval for each contrast in
a set of orthogonal contrasts?  The ?multcomp? package will calculate
a CIs at the 95% family-wise confidence level.  But, these confidence
intervals are extremely wide.
Thanks for your help.
Best regards,
James


From ash369ster at gmail.com  Thu Dec  1 22:58:53 2016
From: ash369ster at gmail.com (Ashwini Patil)
Date: Thu, 1 Dec 2016 16:58:53 -0500
Subject: [R] Bootstrap using ARIMA model
In-Reply-To: <CAGxFJbTiPn1nuRUTPniLmBs4tHp0yHQAJpOGhR0V40CKBUuRrA@mail.gmail.com>
References: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>
	<CAGxFJbTiPn1nuRUTPniLmBs4tHp0yHQAJpOGhR0V40CKBUuRrA@mail.gmail.com>
Message-ID: <CAEK8ckCH_uyy8nUaOX4wtp24fF_0_1517y0UGdeaQoojpHZVyQ@mail.gmail.com>

Hi David,

here is my code including what i did for the tsboot:
rm(list = ls())
library(boot)
library(tseries)
library(TTR)
library(quantmod)
library(scales)
library(forecast)
library(zoo)
library(TSA)
security<-"NFLX"
startDate<-"2012-06-01"
endDate<-"2016-10-31"
qte_list<-c("AdjClose")

data=get.hist.quote(instrument = security, startDate, endDate, quote =
qte_list,   provider = "yahoo" )

func.ar<- ar(logret)
func.model<-list(order = c(func.ar$order,0,0),ar=func.ar$ar)
func.res<- func.ar$resid[!is.na(func.ar$resid)]
func.res<-func.res - mean()
func<- function(logret,formula){
  d = logret
  return(RSI(exp(logret)))
}
func.sim<-function(res,n.sim,ran.args){
  rg1<- function(n, res) sample(res, n, replace=TRUE)
  ts.orig<-ran.args$ts
  ts.mod<-ran.args$model
  mean(ts.orig)+ts(arima.sim(model=ts.mod,n=n.sim, ran.gen=rg1,
res=as.vestor(res)))
}
myboot<-tsboot(exp(logret),func,R=500,sim="model", ran.gen=func.sim,
ran.args = List(ts=log(data[,1],model=func.sim))


Best,
Ash


On Thu, Dec 1, 2016 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Just briefly to follow up David's comment, though this is mainly about
> statistics and therefore off topic here...
>
> Bootstrapping time series is a subtle issue that requires familiarity
> with the technical details-- and maybe even current research. The
> tsboot() function gives you several options from which you must choose
> *appropriately* -- or maybe choose something else entirely. The Help
> doc gives you a sense of the difficulties:
>
> ***************
> Model based resampling is very similar to the parametric bootstrap and
> all simulation must be in one of the user specified functions. This
> avoids the complicated problem of choosing the block length but relies
> on an accurate model choice being made.
>
> Phase scrambling is described in Section 8.2.4 of Davison and Hinkley
> (1997). The types of statistic for which this method produces
> reasonable results is very limited and the other methods seem to do
> better in most situations. Other types of resampling in the frequency
> domain can be accomplished using the function boot with the argument
> sim = "parametric".
> ****
>
> Moral: If you don't know what you're doing, seek local expertise to
> help -- remote sites offering suggestions from those who aren't
> familiar with the details of your data and analysis goals (maybe you
> don't need to do this at all!) may lead you to irreproducible
> nonsense.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Dec 1, 2016 at 7:45 AM, Ashwini Patil <ash369ster at gmail.com>
> wrote:
> > Hi,
> >
> > I want to implement a bootstrap method for time series.
> > I am taking the adj close values from yahoo for NFLX and now I need to
> > bootstrap these values using ARIMA model.
> >
> > here is my code so far:
> > rm(list = ls())
> > library(boot)
> > library(tseries)
> > library(TTR)
> > library(quantmod)
> > library(scales)
> > library(forecast)
> > library(zoo)
> > library(TSA)
> > security<-"NFLX"
> > startDate<-"2012-06-01"
> > endDate<-"2016-10-31"
> > qte_list<-c("AdjClose")
> >
> > data=get.hist.quote(instrument = security, startDate, endDate, quote =
> > qte_list,   provider = "yahoo" )
> > logret<-diff(log(data[,1]))
> > fit11<-auto.arima(logret, max.order=10)
> >
> > When i use auto.arima, I get an order of (0,0,0) with non-zero mean.
> After
> > this, I tried to use tsboot function but it is not yielding any answers.
> >
> > Any and all help is appreciated.
> >
> > Thank you!
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec  2 01:24:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Dec 2016 16:24:26 -0800
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
Message-ID: <6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>


> On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com> wrote:
> 
> Hi,
> 
> I am desperately looking for a way to plot confidence intervals into a
> density plot of only one variable (not a scatter plot etc.)
> 
> Have you any advice how to do this?
> 
> I've only found manual ways to do with "abline", but this is a rather
> bothersome method and only works with ggplot (and not ggplot2).

This makes it appear that you expect this to be done in ggplot2 automagically. I suspect you must instead first find the right approach to construction of those upper and lower bounds before plotting. It's not clear what methods you expect to be needed. Your desperation is not a guide. Perhaps trying a bit of searching?

install.packages("sos")
library(sos)
findFn("confidence intervals density estimates")


Delivers quite a few results. Then searching on the text within that webpage you find 


208	2	27	54	nprobust	kdrobust	2016-11-14 16:41:50	27	Kernel Density Estimation with Robust Confidence Intervals
209	2	27	54	nprobust	lprobust	2016-11-14 16:41:50	27	Local-Polynomial Estimation with Robust Confidence Intervals

Is that what you seek?

> 
> Thank you!
> 
> 	[[alternative HTML version deleted]]
I know you just subscribed, so now is the time to read the Posing Guide.

== 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Fri Dec  2 01:33:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Dec 2016 11:33:31 +1100
Subject: [R] Identifying Gender
In-Reply-To: <9683FAB6-F51C-4C88-B07A-41A6D657C646@gmail.com>
References: <824423988.5512390.1480621226455.ref@mail.yahoo.com>
	<824423988.5512390.1480621226455@mail.yahoo.com>
	<alpine.LNX.2.11.1612011238020.14276@localhost>
	<9683FAB6-F51C-4C88-B07A-41A6D657C646@gmail.com>
Message-ID: <CA+8X3fWDxwk_MdC1Df=8FSXWKZJuQJfjY5bg-kh5df+GWAiisA@mail.gmail.com>

On Fri, Dec 2, 2016 at 7:58 AM, Ismail SEZEN <sezenismail at gmail.com> wrote:
>
> So, it?s more reasonable to identify the gender manually.
>
Both Paul ("Crocodile Dundee") Hogan and Donald Trump agree on that.

Jim


From NordlDJ at dshs.wa.gov  Fri Dec  2 01:43:43 2016
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Fri, 2 Dec 2016 00:43:43 +0000
Subject: [R] R & MongoDB
In-Reply-To: <DB5PR07MB1621E4CE3471F4BA2032B82EE68F0@DB5PR07MB1621.eurprd07.prod.outlook.com>
References: <DB5PR07MB1621E4CE3471F4BA2032B82EE68F0@DB5PR07MB1621.eurprd07.prod.outlook.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276643E661F9@WAXMXOLYMB025.WAX.wa.lcl>

Here are some links that may get you started.

https://www.r-bloggers.com/r-and-mongodb/
https://cran.r-project.org/web/packages/mongolite/vignettes/intro.html
https://www.opencpu.org/posts/mongolite-release-0-3/


You may also want to ask your question on the R-sig-DB Mailing list.

https://stat.ethz.ch/mailman/listinfo/r-sig-db


Good luck!

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Fernando
> Mozas Enguita
> Sent: Thursday, December 01, 2016 12:07 AM
> To: r-help at R-project.org
> Subject: [R] R & MongoDB
> 
> Hi Everyone!
> 
> I?m new in R-world and I need help.
> I need to make an R-script for PowerBI to connect with a MongoDB data
> source and I don?t have so much idea
> 
> I have a dataset in a Mongo DB like this:
> 
> /* 1 */
> {
>     "_id" : ObjectId("5819ad77d8828e871ce09297"),
>     "Date" : 1478077741,
>     "Receptor" : "CORMAD",
>     "Position" : "02112016",
>     "clients" : [
>         {
>             "mac" : "A2:C2:CA:18:F0:5E",
>             "vendor" : "",
>             "lastSeen" : 1478077746,
>             "power" : -80,
>             "R" : "",
>             "bssid" : "(not associated) ",
>             "essid" : [],
>             "probedESSID" : [
>                 "any"
>             ]
>         },
>         {
>             "mac" : "D6:B0:C2:0E:2B:A0",
>             "vendor" : "",
>             "lastSeen" : 1478077755,
>             "power" : -78,
>             "R" : "",
>             "bssid" : "(not associated) ",
>             "essid" : [],
>             "probedESSID" : [
>                 "any"
>             ]
>         }
> /* 2 */
> {
>     "_id" : ObjectId("5819b009d8828e871ce092dc"),
>     "Date" : 1478078401,
>     "Receptor" : "CORMAD",
>     "Position" : "02112016",
>     "clients" : [
>         {
>             "mac" : "C0:38:96:86:1E:91",
>             "vendor" : "HonHaiPr",
>             "lastSeen" : 1478078443,
>             "power" : -80,
>             "R" : "",
>             "bssid" : "0A:18:D6:2B:7F:EB",
>             "essid" : [],
>             "probedESSID" : [
>                 "any"
>             ]
>         },
>         {
>             "mac" : "F4:F1:E1:60:73:D2",
>             "vendor" : "Motorola",
>             "lastSeen" : 1478078410,
>             "power" : -78,
>             "R" : "",
>             "bssid" : "(not associated) ",
>             "essid" : [],
>             "probedESSID" : [
>                 "JAZZTEL_HY7S"
>             ]
>         }
> 
> How can I iterate throw all the clients to extract the information?
> I need to have a classic table with the information.
> One row with the fields :
> _id | Date | Receptor | Position | clients | mac | vendor | lastSeen | power |
> R | bssid | essid | probedESSID
> 
> 
> Thanks!
> Fernando.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]


From rmh at temple.edu  Fri Dec  2 05:18:43 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 1 Dec 2016 23:18:43 -0500
Subject: [R] confidence intervals for orthogonal contrasts
In-Reply-To: <CABPq8JOr9ae+7vms8RMN85BJfkE4bcgzc+VbVfoUJTD_uhTtOw@mail.gmail.com>
References: <CABPq8JOr9ae+7vms8RMN85BJfkE4bcgzc+VbVfoUJTD_uhTtOw@mail.gmail.com>
Message-ID: <CAGx1TMA_-wk1ruf3BT9A5Znd1wVvUs-AdU2oxiAk7NQph=nXWQ@mail.gmail.com>

James,

Please look at the maiz example, the last example in ?MMC
help("MMC", package="HH")
where I show how to construct and calculate a set of orthogonal contrasts
for a factor in an analysis of variance setting.  mmc and mmcplot use glht
in the multcomp package for the underlying calculations.

If yo don't have HH, you can get it with
install.packages("HH")

See the references in ?MMC to my book and paper.  The second edition
of the book is now available.

Rich

On Thu, Dec 1, 2016 at 4:17 PM, James Henson <jfhenson1 at gmail.com> wrote:
> Hi R users,
> Is there a way to calculate a confidence interval for each contrast in
> a set of orthogonal contrasts?  The ?multcomp? package will calculate
> a CIs at the 95% family-wise confidence level.  But, these confidence
> intervals are extremely wide.
> Thanks for your help.
> Best regards,
> James
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hotprojects at nyc.rr.com  Thu Dec  1 22:33:10 2016
From: hotprojects at nyc.rr.com (hotprojects at nyc.rr.com)
Date: Thu, 1 Dec 2016 16:33:10 -0500
Subject: [R] i am trying to teach myself R
Message-ID: <04E0DEB265C843718E984E3CB1314245@OwnerPC>

having been reasonably fluent a decade ago in spss and sas
can I do everything in R I did in these two formats?
eg multiple and logistic regression
time series ; anova ancova etc
?
	[[alternative HTML version deleted]]


From elysa.mitova at gmail.com  Fri Dec  2 09:18:44 2016
From: elysa.mitova at gmail.com (Elysa Mitova)
Date: Fri, 2 Dec 2016 09:18:44 +0100
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
	<6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
Message-ID: <CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>

Hi, thank you!

I've constructed the upper and lower bounds with

 a <- 2.505766
 s <- 0.7789832
 n <- 607
 error <- qnorm(0.975)*s/sqrt(n)
 left <- a-error
 right <- a+error
 left
right

Now, I have the numbers I need, but I have no idea how to plot them. I was
thinking of using a polygon, but somehow it doesn't work out, because my
y-axis shows only density and is in itself not a variable?

xx <- data

fit1 <- density(data,na.rm=TRUE)

fit2 <- replicate(10000, { x <- sample(xx, replace=TRUE);
	density(x, na.rm=TRUE, from=min(fit1$x), to=max(fit1$x))$y } )

fit3 <- apply(fit2, 1, quantile, c(0.025,0.975) )  - Probably herein
lies the problem?

plot(fit1, ylim=range(fit3))
polygon( c(fit1$x, rev(fit1$x)), c(fit3[1,], rev(fit3[2,])),
col='grey', border=F)
lines(fit1)

I tried working with this solution I found on the internet, but
somehow now the lines the shaded areas sporadically everywhere around
my density plot? I just want a polygon spreading from  2.44 to 2.57
along the x-axis.


Any tipps?




On Fri, Dec 2, 2016 at 1:24 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I am desperately looking for a way to plot confidence intervals into a
> > density plot of only one variable (not a scatter plot etc.)
> >
> > Have you any advice how to do this?
> >
> > I've only found manual ways to do with "abline", but this is a rather
> > bothersome method and only works with ggplot (and not ggplot2).
>
> This makes it appear that you expect this to be done in ggplot2
> automagically. I suspect you must instead first find the right approach to
> construction of those upper and lower bounds before plotting. It's not
> clear what methods you expect to be needed. Your desperation is not a
> guide. Perhaps trying a bit of searching?
>
> install.packages("sos")
> library(sos)
> findFn("confidence intervals density estimates")
>
>
> Delivers quite a few results. Then searching on the text within that
> webpage you find
>
>
> 208     2       27      54      nprobust        kdrobust        2016-11-14
> 16:41:50     27      Kernel Density Estimation with Robust Confidence
> Intervals
> 209     2       27      54      nprobust        lprobust        2016-11-14
> 16:41:50     27      Local-Polynomial Estimation with Robust Confidence
> Intervals
>
> Is that what you seek?
>
> >
> > Thank you!
> >
> >       [[alternative HTML version deleted]]
> I know you just subscribed, so now is the time to read the Posing Guide.
>
> ==
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Dec  2 10:01:28 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Dec 2016 20:01:28 +1100
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
	<6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
	<CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>
Message-ID: <CA+8X3fVESUv_KUkygtGjjq__qGUUCgvQQ_dQwWm++RMAoX=y4Q@mail.gmail.com>

Hi Elysa,
I think you are going a bit off course in your example. Try this and
see if it is close to what you want:

data<-rnorm(100)+runif(100,0,15)
smu_data<-supsmu(1:100,data)
rollfun<-function(x,window=10,FUN=sd) {
 xlen<-length(x)
 xout<-NA
 forward<-window%/%2
 backward<-window-forward
 for(i in 1:xlen) {
  xstart<-i-backward
  if(xstart < 1) xstart<-1
  xend<-i+forward-1
  if(xend > xlen) xend<-xlen
  xout[i]<-do.call(FUN,list(x[xstart:xend],na.rm=TRUE))
 }
 return(xout)
}
mad_data<-rollfun(data,10,mad)
plot(data,ylim=c(0,17))
library(plotrix)
dispersion(smu_data$x,smu_data$y,mad_data,type="l",interval=TRUE,
 fill="lightgray")
lines(smu_data,lwd=2)
points(1:100,data)

Jim


On Fri, Dec 2, 2016 at 7:18 PM, Elysa Mitova <elysa.mitova at gmail.com> wrote:
> Hi, thank you!
>
> I've constructed the upper and lower bounds with
>
>  a <- 2.505766
>  s <- 0.7789832
>  n <- 607
>  error <- qnorm(0.975)*s/sqrt(n)
>  left <- a-error
>  right <- a+error
>  left
> right
>
> Now, I have the numbers I need, but I have no idea how to plot them. I was
> thinking of using a polygon, but somehow it doesn't work out, because my
> y-axis shows only density and is in itself not a variable?
>
> xx <- data
>
> fit1 <- density(data,na.rm=TRUE)
>
> fit2 <- replicate(10000, { x <- sample(xx, replace=TRUE);
>         density(x, na.rm=TRUE, from=min(fit1$x), to=max(fit1$x))$y } )
>
> fit3 <- apply(fit2, 1, quantile, c(0.025,0.975) )  - Probably herein
> lies the problem?
>
> plot(fit1, ylim=range(fit3))
> polygon( c(fit1$x, rev(fit1$x)), c(fit3[1,], rev(fit3[2,])),
> col='grey', border=F)
> lines(fit1)
>
> I tried working with this solution I found on the internet, but
> somehow now the lines the shaded areas sporadically everywhere around
> my density plot? I just want a polygon spreading from  2.44 to 2.57
> along the x-axis.
>
>
> Any tipps?
>
>
>
>
> On Fri, Dec 2, 2016 at 1:24 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> > On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com>
>> wrote:
>> >
>> > Hi,
>> >
>> > I am desperately looking for a way to plot confidence intervals into a
>> > density plot of only one variable (not a scatter plot etc.)
>> >
>> > Have you any advice how to do this?
>> >
>> > I've only found manual ways to do with "abline", but this is a rather
>> > bothersome method and only works with ggplot (and not ggplot2).
>>
>> This makes it appear that you expect this to be done in ggplot2
>> automagically. I suspect you must instead first find the right approach to
>> construction of those upper and lower bounds before plotting. It's not
>> clear what methods you expect to be needed. Your desperation is not a
>> guide. Perhaps trying a bit of searching?
>>
>> install.packages("sos")
>> library(sos)
>> findFn("confidence intervals density estimates")
>>
>>
>> Delivers quite a few results. Then searching on the text within that
>> webpage you find
>>
>>
>> 208     2       27      54      nprobust        kdrobust        2016-11-14
>> 16:41:50     27      Kernel Density Estimation with Robust Confidence
>> Intervals
>> 209     2       27      54      nprobust        lprobust        2016-11-14
>> 16:41:50     27      Local-Polynomial Estimation with Robust Confidence
>> Intervals
>>
>> Is that what you seek?
>>
>> >
>> > Thank you!
>> >
>> >       [[alternative HTML version deleted]]
>> I know you just subscribed, so now is the time to read the Posing Guide.
>>
>> ==
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From elysa.mitova at gmail.com  Fri Dec  2 10:59:22 2016
From: elysa.mitova at gmail.com (Elysa Mitova)
Date: Fri, 2 Dec 2016 10:59:22 +0100
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <CA+8X3fVESUv_KUkygtGjjq__qGUUCgvQQ_dQwWm++RMAoX=y4Q@mail.gmail.com>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
	<6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
	<CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>
	<CA+8X3fVESUv_KUkygtGjjq__qGUUCgvQQ_dQwWm++RMAoX=y4Q@mail.gmail.com>
Message-ID: <CAMfjniEEnihn7enbz56CokP3sBvxwLo1gQM6Zgp5QfforN=gMw@mail.gmail.com>

Thank you,

this seems to work, but it is not exactly what I need (it indeed looks
great, but a bit beyond my understanding)

I just need a shaded area between  2.44 to 2.57 along the x-axis - a
polygon inserted into my density plot (and not a confidence line along a
scatter plot like your suggested solution)

My x-axis is an index (a data frame), my y-axis is the automatically
constructed density

On Fri, Dec 2, 2016 at 10:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Elysa,
> I think you are going a bit off course in your example. Try this and
> see if it is close to what you want:
>
> data<-rnorm(100)+runif(100,0,15)
> smu_data<-supsmu(1:100,data)
> rollfun<-function(x,window=10,FUN=sd) {
>  xlen<-length(x)
>  xout<-NA
>  forward<-window%/%2
>  backward<-window-forward
>  for(i in 1:xlen) {
>   xstart<-i-backward
>   if(xstart < 1) xstart<-1
>   xend<-i+forward-1
>   if(xend > xlen) xend<-xlen
>   xout[i]<-do.call(FUN,list(x[xstart:xend],na.rm=TRUE))
>  }
>  return(xout)
> }
> mad_data<-rollfun(data,10,mad)
> plot(data,ylim=c(0,17))
> library(plotrix)
> dispersion(smu_data$x,smu_data$y,mad_data,type="l",interval=TRUE,
>  fill="lightgray")
> lines(smu_data,lwd=2)
> points(1:100,data)
>
> Jim
>
>
> On Fri, Dec 2, 2016 at 7:18 PM, Elysa Mitova <elysa.mitova at gmail.com>
> wrote:
> > Hi, thank you!
> >
> > I've constructed the upper and lower bounds with
> >
> >  a <- 2.505766
> >  s <- 0.7789832
> >  n <- 607
> >  error <- qnorm(0.975)*s/sqrt(n)
> >  left <- a-error
> >  right <- a+error
> >  left
> > right
> >
> > Now, I have the numbers I need, but I have no idea how to plot them. I
> was
> > thinking of using a polygon, but somehow it doesn't work out, because my
> > y-axis shows only density and is in itself not a variable?
> >
> > xx <- data
> >
> > fit1 <- density(data,na.rm=TRUE)
> >
> > fit2 <- replicate(10000, { x <- sample(xx, replace=TRUE);
> >         density(x, na.rm=TRUE, from=min(fit1$x), to=max(fit1$x))$y } )
> >
> > fit3 <- apply(fit2, 1, quantile, c(0.025,0.975) )  - Probably herein
> > lies the problem?
> >
> > plot(fit1, ylim=range(fit3))
> > polygon( c(fit1$x, rev(fit1$x)), c(fit3[1,], rev(fit3[2,])),
> > col='grey', border=F)
> > lines(fit1)
> >
> > I tried working with this solution I found on the internet, but
> > somehow now the lines the shaded areas sporadically everywhere around
> > my density plot? I just want a polygon spreading from  2.44 to 2.57
> > along the x-axis.
> >
> >
> > Any tipps?
> >
> >
> >
> >
> > On Fri, Dec 2, 2016 at 1:24 AM, David Winsemius <dwinsemius at comcast.net>
> > wrote:
> >
> >>
> >> > On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com>
> >> wrote:
> >> >
> >> > Hi,
> >> >
> >> > I am desperately looking for a way to plot confidence intervals into a
> >> > density plot of only one variable (not a scatter plot etc.)
> >> >
> >> > Have you any advice how to do this?
> >> >
> >> > I've only found manual ways to do with "abline", but this is a rather
> >> > bothersome method and only works with ggplot (and not ggplot2).
> >>
> >> This makes it appear that you expect this to be done in ggplot2
> >> automagically. I suspect you must instead first find the right approach
> to
> >> construction of those upper and lower bounds before plotting. It's not
> >> clear what methods you expect to be needed. Your desperation is not a
> >> guide. Perhaps trying a bit of searching?
> >>
> >> install.packages("sos")
> >> library(sos)
> >> findFn("confidence intervals density estimates")
> >>
> >>
> >> Delivers quite a few results. Then searching on the text within that
> >> webpage you find
> >>
> >>
> >> 208     2       27      54      nprobust        kdrobust
> 2016-11-14
> >> 16:41:50     27      Kernel Density Estimation with Robust Confidence
> >> Intervals
> >> 209     2       27      54      nprobust        lprobust
> 2016-11-14
> >> 16:41:50     27      Local-Polynomial Estimation with Robust Confidence
> >> Intervals
> >>
> >> Is that what you seek?
> >>
> >> >
> >> > Thank you!
> >> >
> >> >       [[alternative HTML version deleted]]
> >> I know you just subscribed, so now is the time to read the Posing Guide.
> >>
> >> ==
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Dec  2 11:36:11 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Dec 2016 21:36:11 +1100
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <CAMfjniEEnihn7enbz56CokP3sBvxwLo1gQM6Zgp5QfforN=gMw@mail.gmail.com>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
	<6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
	<CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>
	<CA+8X3fVESUv_KUkygtGjjq__qGUUCgvQQ_dQwWm++RMAoX=y4Q@mail.gmail.com>
	<CAMfjniEEnihn7enbz56CokP3sBvxwLo1gQM6Zgp5QfforN=gMw@mail.gmail.com>
Message-ID: <CA+8X3fXtSZE_3PUNU3AYXLW7LRu80FUCyq_Tj+MXdLrTcG4Szw@mail.gmail.com>

In order to display a polygon, you need x/y pairs for each point. If
you just want a rectangle, you only need four x/y pairs, e.g.:

plot(0,xlim=x(2.44,2.57),ylim=c(0,1),type="n")
polygon(c(2.44,2.57,2.57,2.44),c(0,0,1,1),col="lightgray")

Now if you have a series of x values and want to display a band of
constant width around it:

y_values<-runif(14)
plot(seq(2.44,2.57,by=0.01),y_values,ylim=c(-2,3))
dispersion(seq(2.44,2.57,by=0.01),y_values,ulim=rep(0.5,14),
 type="l",interval=TRUE,col="lightgray")
lines(seq(2.44,2.57,by=0.01),y_values)

Jim

On Fri, Dec 2, 2016 at 8:59 PM, Elysa Mitova <elysa.mitova at gmail.com> wrote:
> Thank you,
>
> this seems to work, but it is not exactly what I need (it indeed looks
> great, but a bit beyond my understanding)
>
> I just need a shaded area between  2.44 to 2.57 along the x-axis - a polygon
> inserted into my density plot (and not a confidence line along a scatter
> plot like your suggested solution)
>
> My x-axis is an index (a data frame), my y-axis is the automatically
> constructed density
>
> On Fri, Dec 2, 2016 at 10:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Elysa,
>> I think you are going a bit off course in your example. Try this and
>> see if it is close to what you want:
>>
>> data<-rnorm(100)+runif(100,0,15)
>> smu_data<-supsmu(1:100,data)
>> rollfun<-function(x,window=10,FUN=sd) {
>>  xlen<-length(x)
>>  xout<-NA
>>  forward<-window%/%2
>>  backward<-window-forward
>>  for(i in 1:xlen) {
>>   xstart<-i-backward
>>   if(xstart < 1) xstart<-1
>>   xend<-i+forward-1
>>   if(xend > xlen) xend<-xlen
>>   xout[i]<-do.call(FUN,list(x[xstart:xend],na.rm=TRUE))
>>  }
>>  return(xout)
>> }
>> mad_data<-rollfun(data,10,mad)
>> plot(data,ylim=c(0,17))
>> library(plotrix)
>> dispersion(smu_data$x,smu_data$y,mad_data,type="l",interval=TRUE,
>>  fill="lightgray")
>> lines(smu_data,lwd=2)
>> points(1:100,data)
>>
>> Jim
>>
>>
>> On Fri, Dec 2, 2016 at 7:18 PM, Elysa Mitova <elysa.mitova at gmail.com>
>> wrote:
>> > Hi, thank you!
>> >
>> > I've constructed the upper and lower bounds with
>> >
>> >  a <- 2.505766
>> >  s <- 0.7789832
>> >  n <- 607
>> >  error <- qnorm(0.975)*s/sqrt(n)
>> >  left <- a-error
>> >  right <- a+error
>> >  left
>> > right
>> >
>> > Now, I have the numbers I need, but I have no idea how to plot them. I
>> > was
>> > thinking of using a polygon, but somehow it doesn't work out, because my
>> > y-axis shows only density and is in itself not a variable?
>> >
>> > xx <- data
>> >
>> > fit1 <- density(data,na.rm=TRUE)
>> >
>> > fit2 <- replicate(10000, { x <- sample(xx, replace=TRUE);
>> >         density(x, na.rm=TRUE, from=min(fit1$x), to=max(fit1$x))$y } )
>> >
>> > fit3 <- apply(fit2, 1, quantile, c(0.025,0.975) )  - Probably herein
>> > lies the problem?
>> >
>> > plot(fit1, ylim=range(fit3))
>> > polygon( c(fit1$x, rev(fit1$x)), c(fit3[1,], rev(fit3[2,])),
>> > col='grey', border=F)
>> > lines(fit1)
>> >
>> > I tried working with this solution I found on the internet, but
>> > somehow now the lines the shaded areas sporadically everywhere around
>> > my density plot? I just want a polygon spreading from  2.44 to 2.57
>> > along the x-axis.
>> >
>> >
>> > Any tipps?
>> >
>> >
>> >
>> >
>> > On Fri, Dec 2, 2016 at 1:24 AM, David Winsemius <dwinsemius at comcast.net>
>> > wrote:
>> >
>> >>
>> >> > On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com>
>> >> wrote:
>> >> >
>> >> > Hi,
>> >> >
>> >> > I am desperately looking for a way to plot confidence intervals into
>> >> > a
>> >> > density plot of only one variable (not a scatter plot etc.)
>> >> >
>> >> > Have you any advice how to do this?
>> >> >
>> >> > I've only found manual ways to do with "abline", but this is a rather
>> >> > bothersome method and only works with ggplot (and not ggplot2).
>> >>
>> >> This makes it appear that you expect this to be done in ggplot2
>> >> automagically. I suspect you must instead first find the right approach
>> >> to
>> >> construction of those upper and lower bounds before plotting. It's not
>> >> clear what methods you expect to be needed. Your desperation is not a
>> >> guide. Perhaps trying a bit of searching?
>> >>
>> >> install.packages("sos")
>> >> library(sos)
>> >> findFn("confidence intervals density estimates")
>> >>
>> >>
>> >> Delivers quite a few results. Then searching on the text within that
>> >> webpage you find
>> >>
>> >>
>> >> 208     2       27      54      nprobust        kdrobust
>> >> 2016-11-14
>> >> 16:41:50     27      Kernel Density Estimation with Robust Confidence
>> >> Intervals
>> >> 209     2       27      54      nprobust        lprobust
>> >> 2016-11-14
>> >> 16:41:50     27      Local-Polynomial Estimation with Robust Confidence
>> >> Intervals
>> >>
>> >> Is that what you seek?
>> >>
>> >> >
>> >> > Thank you!
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> I know you just subscribed, so now is the time to read the Posing
>> >> Guide.
>> >>
>> >> ==
>> >>
>> >> David Winsemius
>> >> Alameda, CA, USA
>> >>
>> >>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Fri Dec  2 11:45:24 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 2 Dec 2016 21:45:24 +1100
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <CA+8X3fXtSZE_3PUNU3AYXLW7LRu80FUCyq_Tj+MXdLrTcG4Szw@mail.gmail.com>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
	<6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
	<CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>
	<CA+8X3fVESUv_KUkygtGjjq__qGUUCgvQQ_dQwWm++RMAoX=y4Q@mail.gmail.com>
	<CAMfjniEEnihn7enbz56CokP3sBvxwLo1gQM6Zgp5QfforN=gMw@mail.gmail.com>
	<CA+8X3fXtSZE_3PUNU3AYXLW7LRu80FUCyq_Tj+MXdLrTcG4Szw@mail.gmail.com>
Message-ID: <CA+8X3fXNjkBdLemwiMkCH6BhusdDUXBkvCxGDTAJ8YvAbMk9BA@mail.gmail.com>

Hang on, maybe you mean something like this:

erupt_dens<-density(faithful$eruptions)
plot(erupt_dens,ylim=c(0,0.65))
dispersion(erupt_dens$x,erupt_dens$y,ulim=erupt_dens$y/5,
 type="l",fill="lightgray",interval=TRUE)
lines(erupt_dens)

Jim


On Fri, Dec 2, 2016 at 9:36 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> In order to display a polygon, you need x/y pairs for each point. If
> you just want a rectangle, you only need four x/y pairs, e.g.:
>
> plot(0,xlim=x(2.44,2.57),ylim=c(0,1),type="n")
> polygon(c(2.44,2.57,2.57,2.44),c(0,0,1,1),col="lightgray")
>
> Now if you have a series of x values and want to display a band of
> constant width around it:
>
> y_values<-runif(14)
> plot(seq(2.44,2.57,by=0.01),y_values,ylim=c(-2,3))
> dispersion(seq(2.44,2.57,by=0.01),y_values,ulim=rep(0.5,14),
>  type="l",interval=TRUE,col="lightgray")
> lines(seq(2.44,2.57,by=0.01),y_values)
>
> Jim
>
> On Fri, Dec 2, 2016 at 8:59 PM, Elysa Mitova <elysa.mitova at gmail.com> wrote:
>> Thank you,
>>
>> this seems to work, but it is not exactly what I need (it indeed looks
>> great, but a bit beyond my understanding)
>>
>> I just need a shaded area between  2.44 to 2.57 along the x-axis - a polygon
>> inserted into my density plot (and not a confidence line along a scatter
>> plot like your suggested solution)
>>
>> My x-axis is an index (a data frame), my y-axis is the automatically
>> constructed density
>>
>> On Fri, Dec 2, 2016 at 10:01 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Elysa,
>>> I think you are going a bit off course in your example. Try this and
>>> see if it is close to what you want:
>>>
>>> data<-rnorm(100)+runif(100,0,15)
>>> smu_data<-supsmu(1:100,data)
>>> rollfun<-function(x,window=10,FUN=sd) {
>>>  xlen<-length(x)
>>>  xout<-NA
>>>  forward<-window%/%2
>>>  backward<-window-forward
>>>  for(i in 1:xlen) {
>>>   xstart<-i-backward
>>>   if(xstart < 1) xstart<-1
>>>   xend<-i+forward-1
>>>   if(xend > xlen) xend<-xlen
>>>   xout[i]<-do.call(FUN,list(x[xstart:xend],na.rm=TRUE))
>>>  }
>>>  return(xout)
>>> }
>>> mad_data<-rollfun(data,10,mad)
>>> plot(data,ylim=c(0,17))
>>> library(plotrix)
>>> dispersion(smu_data$x,smu_data$y,mad_data,type="l",interval=TRUE,
>>>  fill="lightgray")
>>> lines(smu_data,lwd=2)
>>> points(1:100,data)
>>>
>>> Jim
>>>
>>>
>>> On Fri, Dec 2, 2016 at 7:18 PM, Elysa Mitova <elysa.mitova at gmail.com>
>>> wrote:
>>> > Hi, thank you!
>>> >
>>> > I've constructed the upper and lower bounds with
>>> >
>>> >  a <- 2.505766
>>> >  s <- 0.7789832
>>> >  n <- 607
>>> >  error <- qnorm(0.975)*s/sqrt(n)
>>> >  left <- a-error
>>> >  right <- a+error
>>> >  left
>>> > right
>>> >
>>> > Now, I have the numbers I need, but I have no idea how to plot them. I
>>> > was
>>> > thinking of using a polygon, but somehow it doesn't work out, because my
>>> > y-axis shows only density and is in itself not a variable?
>>> >
>>> > xx <- data
>>> >
>>> > fit1 <- density(data,na.rm=TRUE)
>>> >
>>> > fit2 <- replicate(10000, { x <- sample(xx, replace=TRUE);
>>> >         density(x, na.rm=TRUE, from=min(fit1$x), to=max(fit1$x))$y } )
>>> >
>>> > fit3 <- apply(fit2, 1, quantile, c(0.025,0.975) )  - Probably herein
>>> > lies the problem?
>>> >
>>> > plot(fit1, ylim=range(fit3))
>>> > polygon( c(fit1$x, rev(fit1$x)), c(fit3[1,], rev(fit3[2,])),
>>> > col='grey', border=F)
>>> > lines(fit1)
>>> >
>>> > I tried working with this solution I found on the internet, but
>>> > somehow now the lines the shaded areas sporadically everywhere around
>>> > my density plot? I just want a polygon spreading from  2.44 to 2.57
>>> > along the x-axis.
>>> >
>>> >
>>> > Any tipps?
>>> >
>>> >
>>> >
>>> >
>>> > On Fri, Dec 2, 2016 at 1:24 AM, David Winsemius <dwinsemius at comcast.net>
>>> > wrote:
>>> >
>>> >>
>>> >> > On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com>
>>> >> wrote:
>>> >> >
>>> >> > Hi,
>>> >> >
>>> >> > I am desperately looking for a way to plot confidence intervals into
>>> >> > a
>>> >> > density plot of only one variable (not a scatter plot etc.)
>>> >> >
>>> >> > Have you any advice how to do this?
>>> >> >
>>> >> > I've only found manual ways to do with "abline", but this is a rather
>>> >> > bothersome method and only works with ggplot (and not ggplot2).
>>> >>
>>> >> This makes it appear that you expect this to be done in ggplot2
>>> >> automagically. I suspect you must instead first find the right approach
>>> >> to
>>> >> construction of those upper and lower bounds before plotting. It's not
>>> >> clear what methods you expect to be needed. Your desperation is not a
>>> >> guide. Perhaps trying a bit of searching?
>>> >>
>>> >> install.packages("sos")
>>> >> library(sos)
>>> >> findFn("confidence intervals density estimates")
>>> >>
>>> >>
>>> >> Delivers quite a few results. Then searching on the text within that
>>> >> webpage you find
>>> >>
>>> >>
>>> >> 208     2       27      54      nprobust        kdrobust
>>> >> 2016-11-14
>>> >> 16:41:50     27      Kernel Density Estimation with Robust Confidence
>>> >> Intervals
>>> >> 209     2       27      54      nprobust        lprobust
>>> >> 2016-11-14
>>> >> 16:41:50     27      Local-Polynomial Estimation with Robust Confidence
>>> >> Intervals
>>> >>
>>> >> Is that what you seek?
>>> >>
>>> >> >
>>> >> > Thank you!
>>> >> >
>>> >> >       [[alternative HTML version deleted]]
>>> >> I know you just subscribed, so now is the time to read the Posing
>>> >> Guide.
>>> >>
>>> >> ==
>>> >>
>>> >> David Winsemius
>>> >> Alameda, CA, USA
>>> >>
>>> >>
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> > http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>


From S.Ellison at LGCGroup.com  Fri Dec  2 12:23:28 2016
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 2 Dec 2016 11:23:28 +0000
Subject: [R] rstan error:  C:/Rtools/mingw_64/bin/g++: not found
Message-ID: <1A8C1289955EF649A09086A153E26724040410919D@GBTEDVPEXCMB04.corp.lgc-group.com>

Apologies for posting a possibly package-specific question, but I'm not sure whether this is an R or rstan ussue.

Running rstan under R 3.1.1 in windows 10 I get the well-known error
"Compilation ERROR, function(s)/method(s) not created! C:/Rtools/mingw_64/bin/g++: not found"

The cause on my system is simple; g++ is not on my C:\ drive; it's on D: 
My system path correctly points to D:, running 

> system('g++ -v') 

works fine. But the error message shows that either rstan or R is insisting on a specific call on C:. 

I suspect that something is causing either a package, or R, to use the wrong drive. It _may_ be related to the fact that R itself is in its usual place in 'C:\Program files'.

Any pointers, either to an answer or to a better place to ask, would be welcome.

Steve Ellison

PS: I can see that there is a _fairly_ simple work-round, but I prefer Rtools where it is for system management reasons and this is (so far) the only place that the path variable is not correctly picked up. 



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From petr.pikal at precheza.cz  Fri Dec  2 12:38:25 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 2 Dec 2016 11:38:25 +0000
Subject: [R] i am trying to teach myself R
In-Reply-To: <04E0DEB265C843718E984E3CB1314245@OwnerPC>
References: <04E0DEB265C843718E984E3CB1314245@OwnerPC>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048704@SRVEXCHMBX.precheza.cz>

Hi

You can find overview of R capabilities here.

https://cran.r-project.org/web/views/

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> hotprojects at nyc.rr.com
> Sent: Thursday, December 1, 2016 10:33 PM
> To: r-help at r-project.org
> Subject: [R] i am trying to teach myself R
>
> having been reasonably fluent a decade ago in spss and sas can I do
> everything in R I did in these two formats?
> eg multiple and logistic regression
> time series ; anova ancova etc
> ?
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Dec  2 12:41:13 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 2 Dec 2016 11:41:13 +0000
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>

Hi

You probably could get better answer from experts but it has something to do with contrasts.

?contrasts

Number 44.556 is mean for wool A and tension L and this is the level to which every other level is compared.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> Kapoor
> Sent: Thursday, December 1, 2016 2:48 PM
> To: r-help at r-project.org
> Subject: [R] Interpreting summary.lm for a 2 factor anova
>
> Dear all,
>
> Here is a small example : -
>
> > model <- aov(breaks ~ wool * tension, data = warpbreaks)
> > summary.lm(model)
>
> Call:
> aov(formula = breaks ~ wool * tension, data = warpbreaks)
>
> Residuals:
>      Min       1Q   Median       3Q      Max
> -19.5556  -6.8889  -0.6667   7.1944  25.4444
>
> Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> woolB           -16.333      5.157  -3.167 0.002677 **
> tensionM        -20.556      5.157  -3.986 0.000228 ***
> tensionH        -20.000      5.157  -3.878 0.000320 ***
> woolB:tensionM   21.111      7.294   2.895 0.005698 **
> woolB:tensionH   10.556      7.294   1.447 0.154327
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> Residual standard error: 10.94 on 48 degrees of freedom
> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>
> > model.tables(model,"e")
> Tables of effects
>
>  wool
> wool
>       A       B
>  2.8889 -2.8889
>
>  tension
> tension
>      L      M      H
>  8.241 -1.759 -6.481
>
>  wool:tension
>     tension
> wool L      M      H
>    A  5.278 -5.278  0.000
>    B -5.278  5.278  0.000
>
>
> > model.tables(model,"m")
> Tables of means
> Grand mean
>
> 28.14815
>
>  wool
> wool
>      A      B
> 31.037 25.259
>
>  tension
> tension
>     L     M     H
> 36.39 26.39 21.67
>
>  wool:tension
>     tension
> wool L     M     H
>    A 44.56 24.00 24.56
>    B 28.22 28.78 18.78
> >
>
> I don't follow the output of summary.lm. I understand the output of
> model.tables for effects and means. For instance what does 44.556
> represent ? Is it the grand average ? The grand mean is 28.14815. Can
> someone help me understand the output of summary.lm ?
>
> Best Regards,
> Ashim
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From elysa.mitova at gmail.com  Fri Dec  2 14:15:25 2016
From: elysa.mitova at gmail.com (Elysa Mitova)
Date: Fri, 2 Dec 2016 14:15:25 +0100
Subject: [R] Plotting Confidence Intervals into a density plot
In-Reply-To: <CA+8X3fXNjkBdLemwiMkCH6BhusdDUXBkvCxGDTAJ8YvAbMk9BA@mail.gmail.com>
References: <CAMfjniF=_MOO4FObCJ3UW82uADYZc5wgSkWcQt+tPRQ5a+jB4w@mail.gmail.com>
	<6F01FBC0-0714-476E-90F8-6CF955D6FB91@comcast.net>
	<CAMfjniHkH+xr9G=KXygsa2Zmn_24=ge0EgAdrH2d9eqzau64eQ@mail.gmail.com>
	<CA+8X3fVESUv_KUkygtGjjq__qGUUCgvQQ_dQwWm++RMAoX=y4Q@mail.gmail.com>
	<CAMfjniEEnihn7enbz56CokP3sBvxwLo1gQM6Zgp5QfforN=gMw@mail.gmail.com>
	<CA+8X3fXtSZE_3PUNU3AYXLW7LRu80FUCyq_Tj+MXdLrTcG4Szw@mail.gmail.com>
	<CA+8X3fXNjkBdLemwiMkCH6BhusdDUXBkvCxGDTAJ8YvAbMk9BA@mail.gmail.com>
Message-ID: <CAMfjniGfpM7NQA-dUn1mTYc1wBsPOhE8juo15mwpEQgdZfth8Q@mail.gmail.com>

Hi,

sadly it does not work either, because my index (x axis) is an atomic
vector.
Error Message: $ operator is invalid for atomic vectors
I think I have to stick to displaying the confidence intervals with
straight lines (ablines) , instead of a shaded area (polygon)

Thank you so much for your help!

On Fri, Dec 2, 2016 at 11:45 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hang on, maybe you mean something like this:
>
> erupt_dens<-density(faithful$eruptions)
> plot(erupt_dens,ylim=c(0,0.65))
> dispersion(erupt_dens$x,erupt_dens$y,ulim=erupt_dens$y/5,
>  type="l",fill="lightgray",interval=TRUE)
> lines(erupt_dens)
>
> Jim
>
>
> On Fri, Dec 2, 2016 at 9:36 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > In order to display a polygon, you need x/y pairs for each point. If
> > you just want a rectangle, you only need four x/y pairs, e.g.:
> >
> > plot(0,xlim=x(2.44,2.57),ylim=c(0,1),type="n")
> > polygon(c(2.44,2.57,2.57,2.44),c(0,0,1,1),col="lightgray")
> >
> > Now if you have a series of x values and want to display a band of
> > constant width around it:
> >
> > y_values<-runif(14)
> > plot(seq(2.44,2.57,by=0.01),y_values,ylim=c(-2,3))
> > dispersion(seq(2.44,2.57,by=0.01),y_values,ulim=rep(0.5,14),
> >  type="l",interval=TRUE,col="lightgray")
> > lines(seq(2.44,2.57,by=0.01),y_values)
> >
> > Jim
> >
> > On Fri, Dec 2, 2016 at 8:59 PM, Elysa Mitova <elysa.mitova at gmail.com>
> wrote:
> >> Thank you,
> >>
> >> this seems to work, but it is not exactly what I need (it indeed looks
> >> great, but a bit beyond my understanding)
> >>
> >> I just need a shaded area between  2.44 to 2.57 along the x-axis - a
> polygon
> >> inserted into my density plot (and not a confidence line along a scatter
> >> plot like your suggested solution)
> >>
> >> My x-axis is an index (a data frame), my y-axis is the automatically
> >> constructed density
> >>
> >> On Fri, Dec 2, 2016 at 10:01 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>>
> >>> Hi Elysa,
> >>> I think you are going a bit off course in your example. Try this and
> >>> see if it is close to what you want:
> >>>
> >>> data<-rnorm(100)+runif(100,0,15)
> >>> smu_data<-supsmu(1:100,data)
> >>> rollfun<-function(x,window=10,FUN=sd) {
> >>>  xlen<-length(x)
> >>>  xout<-NA
> >>>  forward<-window%/%2
> >>>  backward<-window-forward
> >>>  for(i in 1:xlen) {
> >>>   xstart<-i-backward
> >>>   if(xstart < 1) xstart<-1
> >>>   xend<-i+forward-1
> >>>   if(xend > xlen) xend<-xlen
> >>>   xout[i]<-do.call(FUN,list(x[xstart:xend],na.rm=TRUE))
> >>>  }
> >>>  return(xout)
> >>> }
> >>> mad_data<-rollfun(data,10,mad)
> >>> plot(data,ylim=c(0,17))
> >>> library(plotrix)
> >>> dispersion(smu_data$x,smu_data$y,mad_data,type="l",interval=TRUE,
> >>>  fill="lightgray")
> >>> lines(smu_data,lwd=2)
> >>> points(1:100,data)
> >>>
> >>> Jim
> >>>
> >>>
> >>> On Fri, Dec 2, 2016 at 7:18 PM, Elysa Mitova <elysa.mitova at gmail.com>
> >>> wrote:
> >>> > Hi, thank you!
> >>> >
> >>> > I've constructed the upper and lower bounds with
> >>> >
> >>> >  a <- 2.505766
> >>> >  s <- 0.7789832
> >>> >  n <- 607
> >>> >  error <- qnorm(0.975)*s/sqrt(n)
> >>> >  left <- a-error
> >>> >  right <- a+error
> >>> >  left
> >>> > right
> >>> >
> >>> > Now, I have the numbers I need, but I have no idea how to plot them.
> I
> >>> > was
> >>> > thinking of using a polygon, but somehow it doesn't work out,
> because my
> >>> > y-axis shows only density and is in itself not a variable?
> >>> >
> >>> > xx <- data
> >>> >
> >>> > fit1 <- density(data,na.rm=TRUE)
> >>> >
> >>> > fit2 <- replicate(10000, { x <- sample(xx, replace=TRUE);
> >>> >         density(x, na.rm=TRUE, from=min(fit1$x), to=max(fit1$x))$y }
> )
> >>> >
> >>> > fit3 <- apply(fit2, 1, quantile, c(0.025,0.975) )  - Probably herein
> >>> > lies the problem?
> >>> >
> >>> > plot(fit1, ylim=range(fit3))
> >>> > polygon( c(fit1$x, rev(fit1$x)), c(fit3[1,], rev(fit3[2,])),
> >>> > col='grey', border=F)
> >>> > lines(fit1)
> >>> >
> >>> > I tried working with this solution I found on the internet, but
> >>> > somehow now the lines the shaded areas sporadically everywhere around
> >>> > my density plot? I just want a polygon spreading from  2.44 to 2.57
> >>> > along the x-axis.
> >>> >
> >>> >
> >>> > Any tipps?
> >>> >
> >>> >
> >>> >
> >>> >
> >>> > On Fri, Dec 2, 2016 at 1:24 AM, David Winsemius <
> dwinsemius at comcast.net>
> >>> > wrote:
> >>> >
> >>> >>
> >>> >> > On Dec 1, 2016, at 12:10 PM, Elysa Mitova <elysa.mitova at gmail.com
> >
> >>> >> wrote:
> >>> >> >
> >>> >> > Hi,
> >>> >> >
> >>> >> > I am desperately looking for a way to plot confidence intervals
> into
> >>> >> > a
> >>> >> > density plot of only one variable (not a scatter plot etc.)
> >>> >> >
> >>> >> > Have you any advice how to do this?
> >>> >> >
> >>> >> > I've only found manual ways to do with "abline", but this is a
> rather
> >>> >> > bothersome method and only works with ggplot (and not ggplot2).
> >>> >>
> >>> >> This makes it appear that you expect this to be done in ggplot2
> >>> >> automagically. I suspect you must instead first find the right
> approach
> >>> >> to
> >>> >> construction of those upper and lower bounds before plotting. It's
> not
> >>> >> clear what methods you expect to be needed. Your desperation is not
> a
> >>> >> guide. Perhaps trying a bit of searching?
> >>> >>
> >>> >> install.packages("sos")
> >>> >> library(sos)
> >>> >> findFn("confidence intervals density estimates")
> >>> >>
> >>> >>
> >>> >> Delivers quite a few results. Then searching on the text within that
> >>> >> webpage you find
> >>> >>
> >>> >>
> >>> >> 208     2       27      54      nprobust        kdrobust
> >>> >> 2016-11-14
> >>> >> 16:41:50     27      Kernel Density Estimation with Robust
> Confidence
> >>> >> Intervals
> >>> >> 209     2       27      54      nprobust        lprobust
> >>> >> 2016-11-14
> >>> >> 16:41:50     27      Local-Polynomial Estimation with Robust
> Confidence
> >>> >> Intervals
> >>> >>
> >>> >> Is that what you seek?
> >>> >>
> >>> >> >
> >>> >> > Thank you!
> >>> >> >
> >>> >> >       [[alternative HTML version deleted]]
> >>> >> I know you just subscribed, so now is the time to read the Posing
> >>> >> Guide.
> >>> >>
> >>> >> ==
> >>> >>
> >>> >> David Winsemius
> >>> >> Alameda, CA, USA
> >>> >>
> >>> >>
> >>> >
> >>> >         [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide
> >>> > http://www.R-project.org/posting-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Fri Dec  2 15:16:51 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Fri, 2 Dec 2016 19:46:51 +0530
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
Message-ID: <CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>

Dear Pikal,

All levels except the interactions are compared to the Intercept. I'm a
little confused as to what's going on in interaction terms eg. the cell
wool B : tension M. It's mean is :
28.78 and 28.78 - 44.56 = -15.78 != 21.111.

It's something like 44.56 (intercept) -16.333 (wool B) -.20.556 (tension
M)  + 21.111 (woolB:tensionM) = 28.782.

I don't know how to sum up the above line in terms of differences
succinctly.

Best Regards,
Ashim

On Fri, Dec 2, 2016 at 5:11 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> You probably could get better answer from experts but it has something to
> do with contrasts.
>
> ?contrasts
>
> Number 44.556 is mean for wool A and tension L and this is the level to
> which every other level is compared.
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> > Kapoor
> > Sent: Thursday, December 1, 2016 2:48 PM
> > To: r-help at r-project.org
> > Subject: [R] Interpreting summary.lm for a 2 factor anova
> >
> > Dear all,
> >
> > Here is a small example : -
> >
> > > model <- aov(breaks ~ wool * tension, data = warpbreaks)
> > > summary.lm(model)
> >
> > Call:
> > aov(formula = breaks ~ wool * tension, data = warpbreaks)
> >
> > Residuals:
> >      Min       1Q   Median       3Q      Max
> > -19.5556  -6.8889  -0.6667   7.1944  25.4444
> >
> > Coefficients:
> >                Estimate Std. Error t value Pr(>|t|)
> > (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> > woolB           -16.333      5.157  -3.167 0.002677 **
> > tensionM        -20.556      5.157  -3.986 0.000228 ***
> > tensionH        -20.000      5.157  -3.878 0.000320 ***
> > woolB:tensionM   21.111      7.294   2.895 0.005698 **
> > woolB:tensionH   10.556      7.294   1.447 0.154327
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 10.94 on 48 degrees of freedom
> > Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> > F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> >
> > > model.tables(model,"e")
> > Tables of effects
> >
> >  wool
> > wool
> >       A       B
> >  2.8889 -2.8889
> >
> >  tension
> > tension
> >      L      M      H
> >  8.241 -1.759 -6.481
> >
> >  wool:tension
> >     tension
> > wool L      M      H
> >    A  5.278 -5.278  0.000
> >    B -5.278  5.278  0.000
> >
> >
> > > model.tables(model,"m")
> > Tables of means
> > Grand mean
> >
> > 28.14815
> >
> >  wool
> > wool
> >      A      B
> > 31.037 25.259
> >
> >  tension
> > tension
> >     L     M     H
> > 36.39 26.39 21.67
> >
> >  wool:tension
> >     tension
> > wool L     M     H
> >    A 44.56 24.00 24.56
> >    B 28.22 28.78 18.78
> > >
> >
> > I don't follow the output of summary.lm. I understand the output of
> > model.tables for effects and means. For instance what does 44.556
> > represent ? Is it the grand average ? The grand mean is 28.14815. Can
> > someone help me understand the output of summary.lm ?
> >
> > Best Regards,
> > Ashim
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Fri Dec  2 16:37:55 2016
From: jfhenson1 at gmail.com (James Henson)
Date: Fri, 2 Dec 2016 09:37:55 -0600
Subject: [R] confidence intervals for orthogonal contrasts
In-Reply-To: <CAGx1TMA_-wk1ruf3BT9A5Znd1wVvUs-AdU2oxiAk7NQph=nXWQ@mail.gmail.com>
References: <CABPq8JOr9ae+7vms8RMN85BJfkE4bcgzc+VbVfoUJTD_uhTtOw@mail.gmail.com>
	<CAGx1TMA_-wk1ruf3BT9A5Znd1wVvUs-AdU2oxiAk7NQph=nXWQ@mail.gmail.com>
Message-ID: <CABPq8JO2=83zYDs-oPxjXtHZefWGgvFpPSXKE8L08VNTizt95A@mail.gmail.com>

Richard,

Thanks, Have not previously used the HH package, but looks as if it
contains many useful tools.  Will check out your book also.

Best regards,
James

On Thu, Dec 1, 2016 at 10:18 PM, Richard M. Heiberger <rmh at temple.edu> wrote:
> James,
>
> Please look at the maiz example, the last example in ?MMC
> help("MMC", package="HH")
> where I show how to construct and calculate a set of orthogonal contrasts
> for a factor in an analysis of variance setting.  mmc and mmcplot use glht
> in the multcomp package for the underlying calculations.
>
> If yo don't have HH, you can get it with
> install.packages("HH")
>
> See the references in ?MMC to my book and paper.  The second edition
> of the book is now available.
>
> Rich
>
> On Thu, Dec 1, 2016 at 4:17 PM, James Henson <jfhenson1 at gmail.com> wrote:
>> Hi R users,
>> Is there a way to calculate a confidence interval for each contrast in
>> a set of orthogonal contrasts?  The ?multcomp? package will calculate
>> a CIs at the 95% family-wise confidence level.  But, these confidence
>> intervals are extremely wide.
>> Thanks for your help.
>> Best regards,
>> James
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Fri Dec  2 16:44:32 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Dec 2016 07:44:32 -0800
Subject: [R] i am trying to teach myself R
In-Reply-To: <04E0DEB265C843718E984E3CB1314245@OwnerPC>
References: <04E0DEB265C843718E984E3CB1314245@OwnerPC>
Message-ID: <CAGxFJbSE6Jambk9b3HtEzZnDQvby+S7+Za-=uguELDrUo7--yA@mail.gmail.com>

Yes -- and probably much more.

https://cran.r-project.org/web/views/

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 1, 2016 at 1:33 PM,  <hotprojects at nyc.rr.com> wrote:
> having been reasonably fluent a decade ago in spss and sas
> can I do everything in R I did in these two formats?
> eg multiple and logistic regression
> time series ; anova ancova etc
> ?
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Dec  2 17:07:43 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 2 Dec 2016 17:07:43 +0100
Subject: [R] i am trying to teach myself R
In-Reply-To: <CAGxFJbSE6Jambk9b3HtEzZnDQvby+S7+Za-=uguELDrUo7--yA@mail.gmail.com>
References: <04E0DEB265C843718E984E3CB1314245@OwnerPC>
	<CAGxFJbSE6Jambk9b3HtEzZnDQvby+S7+Za-=uguELDrUo7--yA@mail.gmail.com>
Message-ID: <BB2A10E9-8F06-462B-A780-DBE224DFF3E8@gmail.com>

Also notice that there are relatively inexpensive books. Mine and Bob Muenchen's for instance, which tackle your situation from somewhat different perpectives. Bob's is very specifically translating from SAS/SPSS to R, mine is more like "here's how to do X using R". There are also other players on the market, but they can blow their own trumpets...

-pd


On 02 Dec 2016, at 16:44 , Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Yes -- and probably much more.
> 
> https://cran.r-project.org/web/views/
> 
> Cheers,
> Bert
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Dec 1, 2016 at 1:33 PM,  <hotprojects at nyc.rr.com> wrote:
>> having been reasonably fluent a decade ago in spss and sas
>> can I do everything in R I did in these two formats?
>> eg multiple and logistic regression
>> time series ; anova ancova etc
>> ?
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From paulbernal07 at gmail.com  Fri Dec  2 17:37:28 2016
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Fri, 2 Dec 2016 11:37:28 -0500
Subject: [R] R Integration with SPSS Modeler
Message-ID: <CAMOcQfMyhMHJb7epHQ0icQn9vOi6SoOsC0N2QWHsp3RAMfpviw@mail.gmail.com>

Hello everyone,

I have installed R version 3.3.2 (64 bit) but SPSS Modeler (version 16.0)
requires R version 2.15.2 (which is obviously pretty old).

Would it cause any problem if I have two different R versions installed in
my computer? Can I have both versions 3.3.2 and 2.15.2? Any considerations
I should be aware of?


Best regards,

Paul

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Dec  2 17:57:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Dec 2016 08:57:43 -0800
Subject: [R] R Integration with SPSS Modeler
In-Reply-To: <CAMOcQfMyhMHJb7epHQ0icQn9vOi6SoOsC0N2QWHsp3RAMfpviw@mail.gmail.com>
References: <CAMOcQfMyhMHJb7epHQ0icQn9vOi6SoOsC0N2QWHsp3RAMfpviw@mail.gmail.com>
Message-ID: <CAGxFJbSVQ2H_U7tHwk2iEjGkrPQ_xc-pEA2ZiRHa2_JTk8_2zg@mail.gmail.com>

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 2, 2016 at 8:37 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Hello everyone,
>
> I have installed R version 3.3.2 (64 bit) but SPSS Modeler (version 16.0)
> requires R version 2.15.2 (which is obviously pretty old).
>
> Would it cause any problem if I have two different R versions installed in
> my computer? Can I have both versions 3.3.2 and 2.15.2?

yes.

Any considerations
> I should be aware of?

Don't know if .rdata files of the 2 versions are compatible -- check
with docs and/or experts.

So long as you keep library trees for 2 versions separate -- addon
packages for 2 versions are likely to be incompatible -- you should be
fine, I think.

-- Bert


>
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Dec  2 18:09:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 2 Dec 2016 09:09:28 -0800
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
Message-ID: <7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>


> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> 
> Dear Pikal,
> 
> All levels except the interactions are compared to the Intercept. I'm a
> little confused as to what's going on in interaction terms eg. the cell
> wool B : tension M. It's mean is :
> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
> 
> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556 (tension
> M)  + 21.111 (woolB:tensionM) = 28.782.
> 
> I don't know how to sum up the above line in terms of differences
> succinctly.

The aov estimate will not exactly equal the observed mean (this is _statistics_ after all). You should be comparing the mean of that cell to the estimate:

 44.556 + (-16.33) +(-20.556) + (21.11)

The difference between the observed mean and the estimated mean is known as a 'residual' and the squared sum of the all residuals is what this being minimized ... over all the cells including the one implicitly associated with the Intercept.

This isn't really on-topic for Rhelp since you are not having difficulty in getting the R program to perform its duties, but are rather in need of statistical education. That not what this mailing list is set up for.

-- 
David.

> 
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
>>> Kapoor
>>> Sent: Thursday, December 1, 2016 2:48 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
>>> 
>>> Dear all,
>>> 
>>> Here is a small example : -
>>> 
>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
>>>> summary.lm(model)
>>> 
>>> Call:
>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
>>> 
>>> Residuals:
>>>     Min       1Q   Median       3Q      Max
>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
>>> 
>>> Coefficients:
>>>               Estimate Std. Error t value Pr(>|t|)
>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
>>> woolB           -16.333      5.157  -3.167 0.002677 **
>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
>>> woolB:tensionH   10.556      7.294   1.447 0.154327
>>> ---
>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> Residual standard error: 10.94 on 48 degrees of freedom
>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>>> 
>>>> model.tables(model,"e")
>>> Tables of effects
>>> 
>>> wool
>>> wool
>>>      A       B
>>> 2.8889 -2.8889
>>> 
>>> tension
>>> tension
>>>     L      M      H
>>> 8.241 -1.759 -6.481
>>> 
>>> wool:tension
>>>    tension
>>> wool L      M      H
>>>   A  5.278 -5.278  0.000
>>>   B -5.278  5.278  0.000
>>> 
>>> 
>>>> model.tables(model,"m")
>>> Tables of means
>>> Grand mean
>>> 
>>> 28.14815
>>> 
>>> wool
>>> wool
>>>     A      B
>>> 31.037 25.259
>>> 
>>> tension
>>> tension
>>>    L     M     H
>>> 36.39 26.39 21.67
>>> 
>>> wool:tension
>>>    tension
>>> wool L     M     H
>>>   A 44.56 24.00 24.56
>>>   B 28.22 28.78 18.78
>>>> 
>>> 
>>> I don't follow the output of summary.lm. I understand the output of
>>> model.tables for effects and means. For instance what does 44.556
>>> represent ? Is it the grand average ? The grand mean is 28.14815. Can
>>> someone help me understand the output of summary.lm ?
>>> 
>>> Best Regards,
>>> Ashim
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>> ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>> vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>> ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>> p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are
>> intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its
>> sender. Delete the contents of this e-mail with all attachments and its
>> copies from your system.
>> If you are not the intended recipient of this e-mail, you are not
>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage
>> caused by modifications of the e-mail or by delay with transfer of the
>> email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a
>> contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to
>> immediately accept such offer; The sender of this e-mail (offer) excludes
>> any acceptance of the offer on the part of the recipient containing any
>> amendment or variation.
>> - the sender insists on that the respective contract is concluded only
>> upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter
>> into any contracts on behalf of the company except for cases in which
>> he/she is expressly authorized to do so in writing, and such authorization
>> or power of attorney is submitted to the recipient or the person
>> represented by the recipient, or the existence of such authorization is
>> known to the recipient of the person represented by the recipient.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From fernando.mozas at trackglobe.com  Fri Dec  2 09:13:22 2016
From: fernando.mozas at trackglobe.com (Fernando Mozas Enguita)
Date: Fri, 2 Dec 2016 08:13:22 +0000
Subject: [R] R & MongoDB
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276643E661F9@WAXMXOLYMB025.WAX.wa.lcl>
References: <DB5PR07MB1621E4CE3471F4BA2032B82EE68F0@DB5PR07MB1621.eurprd07.prod.outlook.com>
	<F7E6D18CC2877149AB5296CE54EA276643E661F9@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <DB5PR07MB1621C1CC671ABE9BB280390DE68E0@DB5PR07MB1621.eurprd07.prod.outlook.com>

Thanks Daniel for the info,

My principal problem is that I have the script on R and Works fine.
But When I copy on Power BI, it Didn?t work.

I would like to know if someone have worked with the combination of Mongo + R + PowerBI and had the same probllem.

Thanks!
 


-----Mensaje original-----
De: Nordlund, Dan (DSHS/RDA) [mailto:NordlDJ at dshs.wa.gov] 
Enviado el: viernes, 2 de diciembre de 2016 1:44
Para: Fernando Mozas Enguita <fernando.mozas at trackglobe.com>; r-help at R-project.org
Asunto: RE: R & MongoDB

Here are some links that may get you started.

https://www.r-bloggers.com/r-and-mongodb/
https://cran.r-project.org/web/packages/mongolite/vignettes/intro.html
https://www.opencpu.org/posts/mongolite-release-0-3/


You may also want to ask your question on the R-sig-DB Mailing list.

https://stat.ethz.ch/mailman/listinfo/r-sig-db


Good luck!

Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration Washington State Department of Social and Health Services

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of 
> Fernando Mozas Enguita
> Sent: Thursday, December 01, 2016 12:07 AM
> To: r-help at R-project.org
> Subject: [R] R & MongoDB
> 
> Hi Everyone!
> 
> I m new in R-world and I need help.
> I need to make an R-script for PowerBI to connect with a MongoDB data 
> source and I don t have so much idea
> 
> I have a dataset in a Mongo DB like this:
> 
> /* 1 */
> {
>     "_id" : ObjectId("5819ad77d8828e871ce09297"),
>     "Date" : 1478077741,
>     "Receptor" : "CORMAD",
>     "Position" : "02112016",
>     "clients" : [
>         {
>             "mac" : "A2:C2:CA:18:F0:5E",
>             "vendor" : "",
>             "lastSeen" : 1478077746,
>             "power" : -80,
>             "R" : "",
>             "bssid" : "(not associated) ",
>             "essid" : [],
>             "probedESSID" : [
>                 "any"
>             ]
>         },
>         {
>             "mac" : "D6:B0:C2:0E:2B:A0",
>             "vendor" : "",
>             "lastSeen" : 1478077755,
>             "power" : -78,
>             "R" : "",
>             "bssid" : "(not associated) ",
>             "essid" : [],
>             "probedESSID" : [
>                 "any"
>             ]
>         }
> /* 2 */
> {
>     "_id" : ObjectId("5819b009d8828e871ce092dc"),
>     "Date" : 1478078401,
>     "Receptor" : "CORMAD",
>     "Position" : "02112016",
>     "clients" : [
>         {
>             "mac" : "C0:38:96:86:1E:91",
>             "vendor" : "HonHaiPr",
>             "lastSeen" : 1478078443,
>             "power" : -80,
>             "R" : "",
>             "bssid" : "0A:18:D6:2B:7F:EB",
>             "essid" : [],
>             "probedESSID" : [
>                 "any"
>             ]
>         },
>         {
>             "mac" : "F4:F1:E1:60:73:D2",
>             "vendor" : "Motorola",
>             "lastSeen" : 1478078410,
>             "power" : -78,
>             "R" : "",
>             "bssid" : "(not associated) ",
>             "essid" : [],
>             "probedESSID" : [
>                 "JAZZTEL_HY7S"
>             ]
>         }
> 
> How can I iterate throw all the clients to extract the information?
> I need to have a classic table with the information.
> One row with the fields :
> _id | Date | Receptor | Position | clients | mac | vendor | lastSeen | 
> power | R | bssid | essid | probedESSID
> 
> 
> Thanks!
> Fernando.
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]


From mathewanalytics at gmail.com  Fri Dec  2 14:38:43 2016
From: mathewanalytics at gmail.com (Abraham Mathew)
Date: Fri, 2 Dec 2016 05:38:43 -0800
Subject: [R] Oddd results when computing confidence intervals
Message-ID: <CABbYstdCEgdPZUMHiAVxii6_S0zSD5c5JNQ8mYpSHuFAxv6AxQ@mail.gmail.com>

I have a vector of values, and have written a function that takes each
value in that vector, generates a normal distribution with that value as
the mean, and then finds the interval at different levels. However, these
intervals don't seem to be right (too narrow).

### CREATE PREDICTION INTERVALS

ensemble_forecast = c(200,600,400,500,200,100,200,600,400,500,200,100)
forecast_for=12

lo_intervals = c()
hi_intervals = c()

create_prediction_intervals <- function(use_forecast = ensemble_forecast,
                                        conf_level = 0.90,
                                        do_jitter = FALSE){

   conf.levels1 = paste(round(rep(conf_level, forecast_for/2), 2), "0",
sep="")
   conf.levels2 = seq((conf_level+0.02), 0.95, length=forecast_for/2)
   all.conf.levels = c(conf.levels1, conf.levels2)
   all.conf.levels = as.numeric(as.character(all.conf.levels))
   all.conf.levels

   # forc_num=1
   for(forc_num in 1:length(use_forecast)){
         message("Executing forecast number: ", forc_num, " at confidence
level: ", all.conf.levels[forc_num])

         value = rnorm(5000, mean=use_forecast[forc_num],
sd=sd(use_forecast))

         #t.test(value)$conf.int
         #Rmisc::CI(value, ci=0.99)

         low = Rmisc::CI(value, ci=all.conf.levels[forc_num])[[3]]
         high = Rmisc::CI(value, ci=all.conf.levels[forc_num])[[1]]

         #low = t.test(value, conf.level=all.conf.levels[forc_num])$conf.int
[[1]]
         #high = t.test(value, conf.level=all.conf.levels[forc_num])$
conf.int[[2]]

         lo_intervals.tmp <- c(low)
         hi_intervals.tmp <- c(high)

         if(do_jitter){
            if(length(unique(lo_intervals)) <= 3) lo_intervals.tmp <-
round(jitter(lo_intervals.tmp), 0)
            if(length(unique(hi_intervals)) <= 3) hi_intervals.tmp <-
round(jitter(hi_intervals.tmp), 0)
            lo_intervals <<- c(lo_intervals, lo_intervals.tmp)
            hi_intervals <<- c(hi_intervals, hi_intervals.tmp)
         } else {
            lo_intervals <<- c(lo_intervals, lo_intervals.tmp)
            hi_intervals <<- c(hi_intervals, hi_intervals.tmp)
         }
   }
}

summary(value)
hist(value)
create_prediction_intervals(ensemble_forecast)


Any ideas on what I'm doing wrong?


-- 


*Abraham MathewData Ninja and Statistical Modeler*



*Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
<https://mathewanalytics.wordpress.com/>*

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec  2 21:03:25 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 2 Dec 2016 12:03:25 -0800
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
Message-ID: <F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>


> On Dec 2, 2016, at 9:09 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>> 
>> Dear Pikal,
>> 
>> All levels except the interactions are compared to the Intercept. I'm a
>> little confused as to what's going on in interaction terms eg. the cell
>> wool B : tension M. It's mean is :
>> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
>> 
>> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556 (tension
>> M)  + 21.111 (woolB:tensionM) = 28.782.
>> 
>> I don't know how to sum up the above line in terms of differences
>> succinctly.
> 
> The aov estimate will not exactly equal the observed mean (this is _statistics_ after all). You should be comparing the mean of that cell to the estimate:
> 
> 44.556 + (-16.33) +(-20.556) + (21.11)

A respected participant advised me to look at this more closely. In this case (and I think in most such cases)  where there are the same number of parameters as there are means, the model is "saturated" and there is no difference:

 with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
     A.L      B.L      A.M      B.M      A.H      B.H 
44.55556 28.22222 24.00000 28.77778 24.55556 18.77778 

So the B:M estimate is identical up to rounding with the observed mean:

 44.556 + (-16.33) +(-20.556) + (21.11)
[1] 28.78



> 
> The difference between the observed mean and the estimated mean is known as a 'residual'

I've also been privately but gently chided for this misstatement. Residuals are the difference between data and estimates.

> and the squared sum of the all residuals is what this being minimized ... over all the cells including the one implicitly associated with the Intercept.
> 
> This isn't really on-topic for Rhelp since you are not having difficulty in getting the R program to perform its duties, but are rather in need of statistical education. That not what this mailing list is set up for.
> 
> -- 
> David.
> 
>> 
>>> 
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
>>>> Kapoor
>>>> Sent: Thursday, December 1, 2016 2:48 PM
>>>> To: r-help at r-project.org
>>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
>>>> 
>>>> Dear all,
>>>> 
>>>> Here is a small example : -
>>>> 
>>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
>>>>> summary.lm(model)
>>>> 
>>>> Call:
>>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
>>>> 
>>>> Residuals:
>>>>    Min       1Q   Median       3Q      Max
>>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
>>>> 
>>>> Coefficients:
>>>>              Estimate Std. Error t value Pr(>|t|)
>>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
>>>> woolB           -16.333      5.157  -3.167 0.002677 **
>>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
>>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
>>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
>>>> woolB:tensionH   10.556      7.294   1.447 0.154327
>>>> ---
>>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>>> 
>>>> Residual standard error: 10.94 on 48 degrees of freedom
>>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
>>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>>>> 
>>>>> model.tables(model,"e")
>>>> Tables of effects
>>>> 
>>>> wool
>>>> wool
>>>>     A       B
>>>> 2.8889 -2.8889
>>>> 
>>>> tension
>>>> tension
>>>>    L      M      H
>>>> 8.241 -1.759 -6.481
>>>> 
>>>> wool:tension
>>>>   tension
>>>> wool L      M      H
>>>>  A  5.278 -5.278  0.000
>>>>  B -5.278  5.278  0.000
>>>> 
>>>> 
>>>>> model.tables(model,"m")
>>>> Tables of means
>>>> Grand mean
>>>> 
>>>> 28.14815
>>>> 
>>>> wool
>>>> wool
>>>>    A      B
>>>> 31.037 25.259
>>>> 
>>>> tension
>>>> tension
>>>>   L     M     H
>>>> 36.39 26.39 21.67
>>>> 
>>>> wool:tension
>>>>   tension
>>>> wool L     M     H
>>>>  A 44.56 24.00 24.56
>>>>  B 28.22 28.78 18.78
>>>>> 
>>>> 
>>>> I don't follow the output of summary.lm. I understand the output of
>>>> model.tables for effects and means. For instance what does 44.556
>>>> represent ? Is it the grand average ? The grand mean is 28.14815. Can
>>>> someone help me understand the output of summary.lm ?
>>>> 
>>>> Best Regards,
>>>> Ashim
>>>> 
>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>>> guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ________________________________
>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>>> ur?eny pouze jeho adres?t?m.
>>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
>>> vyma?te ze sv?ho syst?mu.
>>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
>>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>>> ?i zpo?d?n?m p?enosu e-mailu.
>>> 
>>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
>>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
>>> p??jemce s dodatkem ?i odchylkou.
>>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
>>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
>>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
>>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>> 
>>> This e-mail and any documents attached to it may be confidential and are
>>> intended only for its intended recipients.
>>> If you received this e-mail by mistake, please immediately inform its
>>> sender. Delete the contents of this e-mail with all attachments and its
>>> copies from your system.
>>> If you are not the intended recipient of this e-mail, you are not
>>> authorized to use, disseminate, copy or disclose this e-mail in any manner.
>>> The sender of this e-mail shall not be liable for any possible damage
>>> caused by modifications of the e-mail or by delay with transfer of the
>>> email.
>>> 
>>> In case that this e-mail forms part of business dealings:
>>> - the sender reserves the right to end negotiations about entering into a
>>> contract in any time, for any reason, and without stating any reasoning.
>>> - if the e-mail contains an offer, the recipient is entitled to
>>> immediately accept such offer; The sender of this e-mail (offer) excludes
>>> any acceptance of the offer on the part of the recipient containing any
>>> amendment or variation.
>>> - the sender insists on that the respective contract is concluded only
>>> upon an express mutual agreement on all its aspects.
>>> - the sender of this e-mail informs that he/she is not authorized to enter
>>> into any contracts on behalf of the company except for cases in which
>>> he/she is expressly authorized to do so in writing, and such authorization
>>> or power of attorney is submitted to the recipient or the person
>>> represented by the recipient, or the existence of such authorization is
>>> known to the recipient of the person represented by the recipient.
>>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Fri Dec  2 23:05:25 2016
From: rmh at temple.edu (RICHARD M. HEIBERGER)
Date: Fri, 2 Dec 2016 17:05:25 -0500
Subject: [R] i am trying to teach myself R
In-Reply-To: <BB2A10E9-8F06-462B-A780-DBE224DFF3E8@gmail.com>
References: <04E0DEB265C843718E984E3CB1314245@OwnerPC>
	<CAGxFJbSE6Jambk9b3HtEzZnDQvby+S7+Za-=uguELDrUo7--yA@mail.gmail.com>
	<BB2A10E9-8F06-462B-A780-DBE224DFF3E8@gmail.com>
Message-ID: <B0CCF91F-CE23-4CFE-881B-B1EFCABEDB30@temple.edu>

I will recommend my book.

http://www.springer.com/us/book/9781493921218

Sent from my iPhone

> On Dec 2, 2016, at 11:07, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> Also notice that there are relatively inexpensive books. Mine and Bob Muenchen's for instance, which tackle your situation from somewhat different perpectives. Bob's is very specifically translating from SAS/SPSS to R, mine is more like "here's how to do X using R". There are also other players on the market, but they can blow their own trumpets...
> 
> -pd
> 
> 
>> On 02 Dec 2016, at 16:44 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 
>> Yes -- and probably much more.
>> 
>> https://cran.r-project.org/web/views/
>> 
>> Cheers,
>> Bert
>> 
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>>> On Thu, Dec 1, 2016 at 1:33 PM,  <hotprojects at nyc.rr.com> wrote:
>>> having been reasonably fluent a decade ago in spss and sas
>>> can I do everything in R I did in these two formats?
>>> eg multiple and logistic regression
>>> time series ; anova ancova etc
>>> ?
>>>       [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sat Dec  3 06:18:39 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sat, 3 Dec 2016 10:48:39 +0530
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
Message-ID: <CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>

Please allow me to rephrase myquery.

> model.tables(model,"m")
Tables of means
Grand mean

28.14815

 wool
wool
     A      B
31.037 25.259

 tension
tension
    L     M     H
36.39 26.39 21.67

 wool:tension
    tension
wool L     M     H
   A 44.56 24.00 24.56
   B 28.22 28.78 18.78
>


The above is the same as :

with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
     A.L      B.L      A.M      B.M      A.H      B.H
44.55556 28.22222 24.00000 28.77778 24.55556 18.77778

For reference:

> model <- aov(breaks ~ wool * tension, data = warpbreaks)
> summary.lm(model)

Call:
aov(formula = breaks ~ wool * tension, data = warpbreaks)

Residuals:
     Min       1Q   Median       3Q      Max
-19.5556  -6.8889  -0.6667   7.1944  25.4444

Coefficients:
               Estimate Std. Error t value Pr(>|t|)
(Intercept)      44.556      3.647  12.218 2.43e-16 ***
woolB           -16.333      5.157  -3.167 0.002677 **
tensionM        -20.556      5.157  -3.986 0.000228 ***
tensionH        -20.000      5.157  -3.878 0.000320 ***
woolB:tensionM   21.111      7.294   2.895 0.005698 **
woolB:tensionH   10.556      7.294   1.447 0.154327
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 10.94 on 48 degrees of freedom
Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772


Now I'll explain what is confusing me in the output of summary.lm.

Coeff of Intercept = 44.556  = cell mean for A.L. This is the base.

Coeff of woolB:L = -16.333 = 28.22222 - 44.556. This is the difference of
this cell mean(B:L) from the base.

Coeff of woolA:tensionM = -20.556  = 24.000- 44.556. This is the difference
of this cell mean (A:M)  from the base.

Coeff of woolA:tensionH = -20.000  = 24.55556 - 44.556. This is the
difference of this cell mean(A:H) from the base.

This is where it stops being the difference from the base.

Coeff of woolB:tensionM = 21.111 should turn out to be 28.77778 - 44.556
but this is -15.77822

Coeff of woolB:tensionH = 10.556 should turn out to be  18.77778 - 44.556
but this is -25.77822

In the above 2 cases, we can't say that the coefficient = cell mean - base
case. Can you tell me what should be the statement to be made ?


Best Regards,
Ashim

PS : My apologies for emailing my query to this list. Can you tell me the
names of a few (active) statistics help list ?

On Sat, Dec 3, 2016 at 1:33 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Dec 2, 2016, at 9:09 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >>
> >> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> >>
> >> Dear Pikal,
> >>
> >> All levels except the interactions are compared to the Intercept. I'm a
> >> little confused as to what's going on in interaction terms eg. the cell
> >> wool B : tension M. It's mean is :
> >> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
> >>
> >> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556 (tension
> >> M)  + 21.111 (woolB:tensionM) = 28.782.
> >>
> >> I don't know how to sum up the above line in terms of differences
> >> succinctly.
> >
> > The aov estimate will not exactly equal the observed mean (this is
> _statistics_ after all). You should be comparing the mean of that cell to
> the estimate:
> >
> > 44.556 + (-16.33) +(-20.556) + (21.11)
>
> A respected participant advised me to look at this more closely. In this
> case (and I think in most such cases)  where there are the same number of
> parameters as there are means, the model is "saturated" and there is no
> difference:
>
>  with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
>      A.L      B.L      A.M      B.M      A.H      B.H
> 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
>
> So the B:M estimate is identical up to rounding with the observed mean:
>
>  44.556 + (-16.33) +(-20.556) + (21.11)
> [1] 28.78
>
>
>
> >
> > The difference between the observed mean and the estimated mean is known
> as a 'residual'
>
> I've also been privately but gently chided for this misstatement.
> Residuals are the difference between data and estimates.
>
> > and the squared sum of the all residuals is what this being minimized
> ... over all the cells including the one implicitly associated with the
> Intercept.
> >
> > This isn't really on-topic for Rhelp since you are not having difficulty
> in getting the R program to perform its duties, but are rather in need of
> statistical education. That not what this mailing list is set up for.
> >
> > --
> > David.
> >
> >>
> >>>
> >>>> -----Original Message-----
> >>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> >>>> Kapoor
> >>>> Sent: Thursday, December 1, 2016 2:48 PM
> >>>> To: r-help at r-project.org
> >>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
> >>>>
> >>>> Dear all,
> >>>>
> >>>> Here is a small example : -
> >>>>
> >>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
> >>>>> summary.lm(model)
> >>>>
> >>>> Call:
> >>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
> >>>>
> >>>> Residuals:
> >>>>    Min       1Q   Median       3Q      Max
> >>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
> >>>>
> >>>> Coefficients:
> >>>>              Estimate Std. Error t value Pr(>|t|)
> >>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> >>>> woolB           -16.333      5.157  -3.167 0.002677 **
> >>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
> >>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
> >>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
> >>>> woolB:tensionH   10.556      7.294   1.447 0.154327
> >>>> ---
> >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>>>
> >>>> Residual standard error: 10.94 on 48 degrees of freedom
> >>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> >>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> >>>>
> >>>>> model.tables(model,"e")
> >>>> Tables of effects
> >>>>
> >>>> wool
> >>>> wool
> >>>>     A       B
> >>>> 2.8889 -2.8889
> >>>>
> >>>> tension
> >>>> tension
> >>>>    L      M      H
> >>>> 8.241 -1.759 -6.481
> >>>>
> >>>> wool:tension
> >>>>   tension
> >>>> wool L      M      H
> >>>>  A  5.278 -5.278  0.000
> >>>>  B -5.278  5.278  0.000
> >>>>
> >>>>
> >>>>> model.tables(model,"m")
> >>>> Tables of means
> >>>> Grand mean
> >>>>
> >>>> 28.14815
> >>>>
> >>>> wool
> >>>> wool
> >>>>    A      B
> >>>> 31.037 25.259
> >>>>
> >>>> tension
> >>>> tension
> >>>>   L     M     H
> >>>> 36.39 26.39 21.67
> >>>>
> >>>> wool:tension
> >>>>   tension
> >>>> wool L     M     H
> >>>>  A 44.56 24.00 24.56
> >>>>  B 28.22 28.78 18.78
> >>>>>
> >>>>
> >>>> I don't follow the output of summary.lm. I understand the output of
> >>>> model.tables for effects and means. For instance what does 44.556
> >>>> represent ? Is it the grand average ? The grand mean is 28.14815. Can
> >>>> someone help me understand the output of summary.lm ?
> >>>>
> >>>> Best Regards,
> >>>> Ashim
> >>>>
> >>>>     [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>>> guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ________________________________
> >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> >>> ur?eny pouze jeho adres?t?m.
> >>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie
> >>> vyma?te ze sv?ho syst?mu.
> >>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email
> >>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi
> >>> ?i zpo?d?n?m p?enosu e-mailu.
> >>>
> >>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout;
> >>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> >>> p??jemce s dodatkem ?i odchylkou.
> >>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n
> >>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> tohoto
> >>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> >>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >>>
> >>> This e-mail and any documents attached to it may be confidential and
> are
> >>> intended only for its intended recipients.
> >>> If you received this e-mail by mistake, please immediately inform its
> >>> sender. Delete the contents of this e-mail with all attachments and its
> >>> copies from your system.
> >>> If you are not the intended recipient of this e-mail, you are not
> >>> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> >>> The sender of this e-mail shall not be liable for any possible damage
> >>> caused by modifications of the e-mail or by delay with transfer of the
> >>> email.
> >>>
> >>> In case that this e-mail forms part of business dealings:
> >>> - the sender reserves the right to end negotiations about entering
> into a
> >>> contract in any time, for any reason, and without stating any
> reasoning.
> >>> - if the e-mail contains an offer, the recipient is entitled to
> >>> immediately accept such offer; The sender of this e-mail (offer)
> excludes
> >>> any acceptance of the offer on the part of the recipient containing any
> >>> amendment or variation.
> >>> - the sender insists on that the respective contract is concluded only
> >>> upon an express mutual agreement on all its aspects.
> >>> - the sender of this e-mail informs that he/she is not authorized to
> enter
> >>> into any contracts on behalf of the company except for cases in which
> >>> he/she is expressly authorized to do so in writing, and such
> authorization
> >>> or power of attorney is submitted to the recipient or the person
> >>> represented by the recipient, or the existence of such authorization is
> >>> known to the recipient of the person represented by the recipient.
> >>>
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Dec  3 07:12:11 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Dec 2016 22:12:11 -0800
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
	<CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
Message-ID: <CAGxFJbSEOgziUzYS9rEPeFHx7ANzasW3PS=gfso85CtuZOhvNA@mail.gmail.com>

> Best Regards,
> Ashim
>
> PS : My apologies for emailing my query to this list. Can you tell me the
> names of a few (active) statistics help list ?

stats.stackexchange.com

-- Bert


From jfox at mcmaster.ca  Sat Dec  3 14:45:55 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 3 Dec 2016 13:45:55 +0000
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
	<CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365A4468@FHSDB2D11-2.csu.mcmaster.ca>

Dear Ashim,

Sorry to chime in late, and my apologies if someone has already pointed this out, but here's the relationship between the cell means and the model coefficients, using the row-basis of the model matrix:

-------------------------- snip ------------------------	

> means <- with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
> x.A <- rep(c(0, 1), 3)
> x.B1 <- rep(c(0, 1, 0), each=2)
> x.B2 <- rep(c(0, 0, 1), each=2)
> x.AB1 <- x.A*x.B1
> x.AB2 <- x.A*x.B2
> X.basis <- cbind(1, x.A, x.B1, x.B2, x.AB1, x.AB2)
> X.basis
       x.A x.B1 x.B2 x.AB1 x.AB2
[1,] 1   0    0    0     0     0
[2,] 1   1    0    0     0     0
[3,] 1   0    1    0     0     0
[4,] 1   1    1    0     1     0
[5,] 1   0    0    1     0     0
[6,] 1   1    0    1     0     1
> solve(X.basis, means)
                x.A      x.B1      x.B2     x.AB1     x.AB2 
 44.55556 -16.33333 -20.55556 -20.00000  21.11111  10.55556 
> coef(aov(breaks ~ wool * tension, data = warpbreaks))
   (Intercept)          woolB       tensionM       tensionH woolB:tensionM 
      44.55556      -16.33333      -20.55556      -20.00000       21.11111 
woolB:tensionH 
      10.55556

-------------------------- snip ------------------------	

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim Kapoor
> Sent: December 3, 2016 12:19 AM
> To: David Winsemius <dwinsemius at comcast.net>
> Cc: r-help at r-project.org
> Subject: Re: [R] Interpreting summary.lm for a 2 factor anova
> 
> Please allow me to rephrase myquery.
> 
> > model.tables(model,"m")
> Tables of means
> Grand mean
> 
> 28.14815
> 
>  wool
> wool
>      A      B
> 31.037 25.259
> 
>  tension
> tension
>     L     M     H
> 36.39 26.39 21.67
> 
>  wool:tension
>     tension
> wool L     M     H
>    A 44.56 24.00 24.56
>    B 28.22 28.78 18.78
> >
> 
> 
> The above is the same as :
> 
> with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
>      A.L      B.L      A.M      B.M      A.H      B.H
> 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
> 
> For reference:
> 
> > model <- aov(breaks ~ wool * tension, data = warpbreaks)
> > summary.lm(model)
> 
> Call:
> aov(formula = breaks ~ wool * tension, data = warpbreaks)
> 
> Residuals:
>      Min       1Q   Median       3Q      Max
> -19.5556  -6.8889  -0.6667   7.1944  25.4444
> 
> Coefficients:
>                Estimate Std. Error t value Pr(>|t|)
> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> woolB           -16.333      5.157  -3.167 0.002677 **
> tensionM        -20.556      5.157  -3.986 0.000228 ***
> tensionH        -20.000      5.157  -3.878 0.000320 ***
> woolB:tensionM   21.111      7.294   2.895 0.005698 **
> woolB:tensionH   10.556      7.294   1.447 0.154327
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 10.94 on 48 degrees of freedom
> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> 
> 
> Now I'll explain what is confusing me in the output of summary.lm.
> 
> Coeff of Intercept = 44.556  = cell mean for A.L. This is the base.
> 
> Coeff of woolB:L = -16.333 = 28.22222 - 44.556. This is the difference of this
> cell mean(B:L) from the base.
> 
> Coeff of woolA:tensionM = -20.556  = 24.000- 44.556. This is the difference of
> this cell mean (A:M)  from the base.
> 
> Coeff of woolA:tensionH = -20.000  = 24.55556 - 44.556. This is the difference
> of this cell mean(A:H) from the base.
> 
> This is where it stops being the difference from the base.
> 
> Coeff of woolB:tensionM = 21.111 should turn out to be 28.77778 - 44.556 but
> this is -15.77822
> 
> Coeff of woolB:tensionH = 10.556 should turn out to be  18.77778 - 44.556 but
> this is -25.77822
> 
> In the above 2 cases, we can't say that the coefficient = cell mean - base case.
> Can you tell me what should be the statement to be made ?
> 
> 
> Best Regards,
> Ashim
> 
> PS : My apologies for emailing my query to this list. Can you tell me the names
> of a few (active) statistics help list ?
> 
> On Sat, Dec 3, 2016 at 1:33 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
> >
> > > On Dec 2, 2016, at 9:09 AM, David Winsemius <dwinsemius at comcast.net>
> > wrote:
> > >
> > >>
> > >> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> > >>
> > >> Dear Pikal,
> > >>
> > >> All levels except the interactions are compared to the Intercept.
> > >> I'm a little confused as to what's going on in interaction terms
> > >> eg. the cell wool B : tension M. It's mean is :
> > >> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
> > >>
> > >> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556
> > >> (tension
> > >> M)  + 21.111 (woolB:tensionM) = 28.782.
> > >>
> > >> I don't know how to sum up the above line in terms of differences
> > >> succinctly.
> > >
> > > The aov estimate will not exactly equal the observed mean (this is
> > _statistics_ after all). You should be comparing the mean of that cell
> > to the estimate:
> > >
> > > 44.556 + (-16.33) +(-20.556) + (21.11)
> >
> > A respected participant advised me to look at this more closely. In
> > this case (and I think in most such cases)  where there are the same
> > number of parameters as there are means, the model is "saturated" and
> > there is no
> > difference:
> >
> >  with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
> >      A.L      B.L      A.M      B.M      A.H      B.H
> > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
> >
> > So the B:M estimate is identical up to rounding with the observed mean:
> >
> >  44.556 + (-16.33) +(-20.556) + (21.11) [1] 28.78
> >
> >
> >
> > >
> > > The difference between the observed mean and the estimated mean is
> known
> > as a 'residual'
> >
> > I've also been privately but gently chided for this misstatement.
> > Residuals are the difference between data and estimates.
> >
> > > and the squared sum of the all residuals is what this being minimized
> > ... over all the cells including the one implicitly associated with the
> > Intercept.
> > >
> > > This isn't really on-topic for Rhelp since you are not having difficulty
> > in getting the R program to perform its duties, but are rather in need of
> > statistical education. That not what this mailing list is set up for.
> > >
> > > --
> > > David.
> > >
> > >>
> > >>>
> > >>>> -----Original Message-----
> > >>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> > >>>> Kapoor
> > >>>> Sent: Thursday, December 1, 2016 2:48 PM
> > >>>> To: r-help at r-project.org
> > >>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
> > >>>>
> > >>>> Dear all,
> > >>>>
> > >>>> Here is a small example : -
> > >>>>
> > >>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
> > >>>>> summary.lm(model)
> > >>>>
> > >>>> Call:
> > >>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
> > >>>>
> > >>>> Residuals:
> > >>>>    Min       1Q   Median       3Q      Max
> > >>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
> > >>>>
> > >>>> Coefficients:
> > >>>>              Estimate Std. Error t value Pr(>|t|)
> > >>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> > >>>> woolB           -16.333      5.157  -3.167 0.002677 **
> > >>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
> > >>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
> > >>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
> > >>>> woolB:tensionH   10.556      7.294   1.447 0.154327
> > >>>> ---
> > >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > >>>>
> > >>>> Residual standard error: 10.94 on 48 degrees of freedom
> > >>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> > >>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> > >>>>
> > >>>>> model.tables(model,"e")
> > >>>> Tables of effects
> > >>>>
> > >>>> wool
> > >>>> wool
> > >>>>     A       B
> > >>>> 2.8889 -2.8889
> > >>>>
> > >>>> tension
> > >>>> tension
> > >>>>    L      M      H
> > >>>> 8.241 -1.759 -6.481
> > >>>>
> > >>>> wool:tension
> > >>>>   tension
> > >>>> wool L      M      H
> > >>>>  A  5.278 -5.278  0.000
> > >>>>  B -5.278  5.278  0.000
> > >>>>
> > >>>>
> > >>>>> model.tables(model,"m")
> > >>>> Tables of means
> > >>>> Grand mean
> > >>>>
> > >>>> 28.14815
> > >>>>
> > >>>> wool
> > >>>> wool
> > >>>>    A      B
> > >>>> 31.037 25.259
> > >>>>
> > >>>> tension
> > >>>> tension
> > >>>>   L     M     H
> > >>>> 36.39 26.39 21.67
> > >>>>
> > >>>> wool:tension
> > >>>>   tension
> > >>>> wool L     M     H
> > >>>>  A 44.56 24.00 24.56
> > >>>>  B 28.22 28.78 18.78
> > >>>>>
> > >>>>
> > >>>> I don't follow the output of summary.lm. I understand the output of
> > >>>> model.tables for effects and means. For instance what does 44.556
> > >>>> represent ? Is it the grand average ? The grand mean is 28.14815. Can
> > >>>> someone help me understand the output of summary.lm ?
> > >>>>
> > >>>> Best Regards,
> > >>>> Ashim
> > >>>>
> > >>>>     [[alternative HTML version deleted]]
> > >>>>
> > >>>> ______________________________________________
> > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>> PLEASE do read the posting guide http://www.R-project.org/posting-
> > >>>> guide.html
> > >>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>
> > >>> ________________________________
> > >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> > >>> ur?eny pouze jeho adres?t?m.
> > >>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > >>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> > kopie
> > >>> vyma?te ze sv?ho syst?mu.
> > >>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> > email
> > >>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > >>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> > modifikacemi
> > >>> ?i zpo?d?n?m p?enosu e-mailu.
> > >>>
> > >>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > >>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > >>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > >>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> > p?ijmout;
> > >>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> > >>> p??jemce s dodatkem ?i odchylkou.
> > >>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > >>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > >>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > >>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> > zmocn?n
> > >>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi
> > tohoto
> > >>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> > >>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> > >>>
> > >>> This e-mail and any documents attached to it may be confidential and
> > are
> > >>> intended only for its intended recipients.
> > >>> If you received this e-mail by mistake, please immediately inform its
> > >>> sender. Delete the contents of this e-mail with all attachments and its
> > >>> copies from your system.
> > >>> If you are not the intended recipient of this e-mail, you are not
> > >>> authorized to use, disseminate, copy or disclose this e-mail in any
> > manner.
> > >>> The sender of this e-mail shall not be liable for any possible damage
> > >>> caused by modifications of the e-mail or by delay with transfer of the
> > >>> email.
> > >>>
> > >>> In case that this e-mail forms part of business dealings:
> > >>> - the sender reserves the right to end negotiations about entering
> > into a
> > >>> contract in any time, for any reason, and without stating any
> > reasoning.
> > >>> - if the e-mail contains an offer, the recipient is entitled to
> > >>> immediately accept such offer; The sender of this e-mail (offer)
> > excludes
> > >>> any acceptance of the offer on the part of the recipient containing any
> > >>> amendment or variation.
> > >>> - the sender insists on that the respective contract is concluded only
> > >>> upon an express mutual agreement on all its aspects.
> > >>> - the sender of this e-mail informs that he/she is not authorized to
> > enter
> > >>> into any contracts on behalf of the company except for cases in which
> > >>> he/she is expressly authorized to do so in writing, and such
> > authorization
> > >>> or power of attorney is submitted to the recipient or the person
> > >>> represented by the recipient, or the existence of such authorization is
> > >>> known to the recipient of the person represented by the recipient.
> > >>>
> > >>
> > >>      [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From valkremk at gmail.com  Sat Dec  3 16:40:48 2016
From: valkremk at gmail.com (Val)
Date: Sat, 3 Dec 2016 09:40:48 -0600
Subject: [R] data
Message-ID: <CAJOiR6b=0A8+OBTxwb=B-WOoKJOajQoYC_ARNv=-R5jnbMseMg@mail.gmail.com>

Hi all,

I am trying to read and summarize  a big data frame( >10M records)

Here is the sample of my data
state,city,x
1,12,100
1,12,100
1,12,200
1,13,200
1,13,100
1,13,100
1,14,200
2,21,200
2,21,200
2,21,100
2,23,100
2,23,200
2,34,200
2,34,100
2,35,100

I want  get  the total count by state, and the  the number of cities
by state. The x variable is either 100 or 200 and count each

The result should look like as follows.

state,city,count,100's,200's
1,3,7,4,3
2,4,8,4,4

At the present I am doing it  in several steps and taking too long

Is there an efficient way of doing this?


From jholtman at gmail.com  Sat Dec  3 17:06:09 2016
From: jholtman at gmail.com (jim holtman)
Date: Sat, 3 Dec 2016 11:06:09 -0500
Subject: [R] data
In-Reply-To: <CAJOiR6b=0A8+OBTxwb=B-WOoKJOajQoYC_ARNv=-R5jnbMseMg@mail.gmail.com>
References: <CAJOiR6b=0A8+OBTxwb=B-WOoKJOajQoYC_ARNv=-R5jnbMseMg@mail.gmail.com>
Message-ID: <CAAxdm-6h9+wP=1jBDY9nxUjtd6hWTDZbPPb+H05nv6iUGbDm-w@mail.gmail.com>

This should be reasonably efficient with 'dplyr':

> library(dplyr)
> input <- read.csv(text = "state,city,x
+ 1,12,100
+ 1,12,100
+ 1,12,200
+ 1,13,200
+ 1,13,100
+ 1,13,100
+ 1,14,200
+ 2,21,200
+ 2,21,200
+ 2,21,100
+ 2,23,100
+ 2,23,200
+ 2,34,200
+ 2,34,100
+ 2,35,100")
>
> result <- input %>%
+             group_by(state) %>%
+             summarise(nCities = length(unique(city)),
+                 count = n(),
+                 `100's` = sum(x == 100),
+                 `200's` = sum(x == 200)
+                 )
> result
# A tibble: 2 ? 5
  state nCities count `100's` `200's`
  <int>   <int> <int>   <int>   <int>
1     1       3     7       4       3
2     2       4     8       4       4


Or you can also use data.table:

> library(data.table)
> input <- fread("state,city,x
+ 1,12,100
+ 1,12,100
+ 1,12,200
+ 1,13,200
+ 1,13,100
+ 1,13,100
+ 1,14,200
+ 2,21,200
+ 2,21,200
+ 2,21,100
+ 2,23,100
+ 2,23,200
+ 2,34,200
+ 2,34,100
+ 2,35,100")
>
> input[, .(nCities = length(unique(city)),
+           count = .N,
+           `100's` = sum(x == 100),
+           `200's` = sum(x == 200)
+           )
+         , keyby = state
+         ]
   state nCities count 100's 200's
1:     1       3     7     4     3
2:     2       4     8     4     4



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sat, Dec 3, 2016 at 10:40 AM, Val <valkremk at gmail.com> wrote:

> Hi all,
>
> I am trying to read and summarize  a big data frame( >10M records)
>
> Here is the sample of my data
> state,city,x
> 1,12,100
> 1,12,100
> 1,12,200
> 1,13,200
> 1,13,100
> 1,13,100
> 1,14,200
> 2,21,200
> 2,21,200
> 2,21,100
> 2,23,100
> 2,23,200
> 2,34,200
> 2,34,100
> 2,35,100
>
> I want  get  the total count by state, and the  the number of cities
> by state. The x variable is either 100 or 200 and count each
>
> The result should look like as follows.
>
> state,city,count,100's,200's
> 1,3,7,4,3
> 2,4,8,4,4
>
> At the present I am doing it  in several steps and taking too long
>
> Is there an efficient way of doing this?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Dec  3 17:42:23 2016
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 3 Dec 2016 17:42:23 +0100
Subject: [R] rstan error: C:/Rtools/mingw_64/bin/g++: not found
In-Reply-To: <1A8C1289955EF649A09086A153E26724040410919D@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <1A8C1289955EF649A09086A153E26724040410919D@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <8ab53717-52db-bb88-ddfb-239e48d33dfc@statistik.tu-dortmund.de>



On 02.12.2016 12:23, S Ellison wrote:
> Apologies for posting a possibly package-specific question, but I'm not sure whether this is an R or rstan ussue.
>
> Running rstan under R 3.1.1 in windows 10 I get the well-known error
> "Compilation ERROR, function(s)/method(s) not created! C:/Rtools/mingw_64/bin/g++: not found"

Are you sure this is R-3.1.1?

I'd expect such a message for R >= 3.3.0 if you do not update some 
files, but for 3.1.1 the correct PATH should be sufficient.

Nevertheless, there is some code in rstan that seems to deal with Rtools 
for some reason, so perhaps better ask its package maintainer.

Best,
Uwe Ligges


>
> The cause on my system is simple; g++ is not on my C:\ drive; it's on D:
> My system path correctly points to D:, running
>
>> system('g++ -v')
>
> works fine. But the error message shows that either rstan or R is insisting on a specific call on C:.
>
> I suspect that something is causing either a package, or R, to use the wrong drive. It _may_ be related to the fact that R itself is in its usual place in 'C:\Program files'.
>
> Any pointers, either to an answer or to a better place to ask, would be welcome.
>
> Steve Ellison
>
> PS: I can see that there is a _fairly_ simple work-round, but I prefer Rtools where it is for system management reasons and this is (so far) the only place that the path variable is not correctly picked up.
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Sat Dec  3 21:03:59 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 03 Dec 2016 12:03:59 -0800
Subject: [R] How to setup a multiplicative dummy function in R
In-Reply-To: <CAL+9viOmtRb0ZAPkZ27qG52L-T8r0M8Yh9MCzuNLJrbOt0nXJg@mail.gmail.com>
References: <CAL+9viOmtRb0ZAPkZ27qG52L-T8r0M8Yh9MCzuNLJrbOt0nXJg@mail.gmail.com>
Message-ID: <1FBBA785-88DB-42F1-BFBE-42313A76D51E@dcn.davis.ca.us>

I think you need an offset term, or maybe I just don't understand your question.  A sample data set, particularly if you can show us how your equation could be used to generate the sample data, would be helpful. 

-- 
Sent from my phone. Please excuse my brevity.

On December 1, 2016 7:22:37 AM PST, lolo koko <lokomiauw at gmail.com> wrote:
>Hello?
>
>Does anyone know how I can implement the below equation in R? I would
>like to estimate the following equation:
>
>  y=beta_ij * (1+gamma_j * dummy) * x_ij
>
>where y is continuous, and all the x variables (j of them) are i=3
>level categorical variables. The intuition is that instead of
>estimating the additive value for a dummy variable, I would like to
>estimate the multiplicative value for the dummy variable. Thus the
>presence of the dummy would scale the beta. Note that for each x
>variable there is only one gamma.
>
>For concreteness, you can imagine that y is a continious test score, x
>are categorical variables indicating different types of education
>achievements, each type of education achievement is categorised in 3
>levels (none, some, a lot), and the dummy indicates race. In this
>model I believe that race affects test scores proportionally to
>estimated beta of each education level. This avoids having to estimate
>a gamma for each education achievement level.
>
>Is the solution to simply use nls {stats} and type out the equation?
>
>Hope the explanation makes sense, happy to explain further.
>
>Best wishes,
>
>Peter
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Sat Dec  3 22:25:44 2016
From: HDoran at air.org (Doran, Harold)
Date: Sat, 3 Dec 2016 21:25:44 +0000
Subject: [R] error serialize (foreach)
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601358EB902@DC1VEX10MB01.air.org>

I have a portion of a foreach loop that I cannot run as parallel but works fine when serialized. Below is a representation of the problem as in this instance I cannot provide reproducible data to generate the same error, the actual data I am working with are confidential.

Within each foreach loop are a series of custom functions acting on my data. When using %do% I get expected result but replacing it with %dopar% generates the error.

I have searched archives and also stackexchange and see this is an issue that arises and I have tried a couple of the recommendations, like trying to use an outfile in makeCluster. But I am not having success.

Oddly, (or perhaps not oddly), others portions of my program run in parallel and do not generate this same error

library(foreach)
library(doParallel)
registerDoParallel(cores=3)

# This portion runs and produces expected result
result <- foreach(i = 1:N) %do% {
tmp1 <- function1(...)
tmp2 <- function2(...)
tmp2
}

# This portion generates error in serialize
result <- foreach(i = 1:N) %dopar% {
tmp1 <- function1(...)
tmp2 <- function2(...)
tmp2
}

error in serialize(data, node$con) : error writing to connection


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Dec  4 02:55:46 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 3 Dec 2016 17:55:46 -0800
Subject: [R] Bootstrap using ARIMA model
In-Reply-To: <CAEK8ckCH_uyy8nUaOX4wtp24fF_0_1517y0UGdeaQoojpHZVyQ@mail.gmail.com>
References: <CAEK8ckA9_Mddv+cuRMUZAcivHVrXHWEhJamROcHTV1fnYLojsQ@mail.gmail.com>
	<CAGxFJbTiPn1nuRUTPniLmBs4tHp0yHQAJpOGhR0V40CKBUuRrA@mail.gmail.com>
	<CAEK8ckCH_uyy8nUaOX4wtp24fF_0_1517y0UGdeaQoojpHZVyQ@mail.gmail.com>
Message-ID: <94297C1E-4859-40CB-9992-7BDA2BFBED95@comcast.net>


> On Dec 1, 2016, at 1:58 PM, Ashwini Patil <ash369ster at gmail.com> wrote:
> 
> Hi David,
> 
> here is my code including what i did for the tsboot:
> rm(list = ls())
> library(boot)
> library(tseries)
> library(TTR)
> library(quantmod)
> library(scales)
> library(forecast)
> library(zoo)
> library(TSA)
> security<-"NFLX"
> startDate<-"2012-06-01"
> endDate<-"2016-10-31"
> qte_list<-c("AdjClose")
> 
> data=get.hist.quote(instrument = security, startDate, endDate, quote =
> qte_list,   provider = "yahoo" )
> 
> func.ar<- ar(logret)

> func.ar<- ar(logret)
Error in ar.yw(x, aic = aic, order.max = order.max, na.action = na.action,  : 
  object 'logret' not found


> func.model<-list(order = c(func.ar$order,0,0),ar=func.ar$ar)
> func.res<- func.ar$resid[!is.na(func.ar$resid)]
> func.res<-func.res - mean()
> func<- function(logret,formula){
>  d = logret
>  return(RSI(exp(logret)))
> }
> func.sim<-function(res,n.sim,ran.args){
>  rg1<- function(n, res) sample(res, n, replace=TRUE)
>  ts.orig<-ran.args$ts
>  ts.mod<-ran.args$model
>  mean(ts.orig)+ts(arima.sim(model=ts.mod,n=n.sim, ran.gen=rg1,
> res=as.vestor(res)))
> }
> myboot<-tsboot(exp(logret),func,R=500,sim="model", ran.gen=func.sim,
> ran.args = List(ts=log(data[,1],model=func.sim))
> 
> 
> Best,
> Ash
> 
> 
> On Thu, Dec 1, 2016 at 1:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
>> Just briefly to follow up David's comment, though this is mainly about
>> statistics and therefore off topic here...
>> 
>> Bootstrapping time series is a subtle issue that requires familiarity
>> with the technical details-- and maybe even current research. The
>> tsboot() function gives you several options from which you must choose
>> *appropriately* -- or maybe choose something else entirely. The Help
>> doc gives you a sense of the difficulties:
>> 
>> ***************
>> Model based resampling is very similar to the parametric bootstrap and
>> all simulation must be in one of the user specified functions. This
>> avoids the complicated problem of choosing the block length but relies
>> on an accurate model choice being made.
>> 
>> Phase scrambling is described in Section 8.2.4 of Davison and Hinkley
>> (1997). The types of statistic for which this method produces
>> reasonable results is very limited and the other methods seem to do
>> better in most situations. Other types of resampling in the frequency
>> domain can be accomplished using the function boot with the argument
>> sim = "parametric".
>> ****
>> 
>> Moral: If you don't know what you're doing, seek local expertise to
>> help -- remote sites offering suggestions from those who aren't
>> familiar with the details of your data and analysis goals (maybe you
>> don't need to do this at all!) may lead you to irreproducible
>> nonsense.
>> 
>> Cheers,
>> Bert
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Thu, Dec 1, 2016 at 7:45 AM, Ashwini Patil <ash369ster at gmail.com>
>> wrote:
>>> Hi,
>>> 
>>> I want to implement a bootstrap method for time series.
>>> I am taking the adj close values from yahoo for NFLX and now I need to
>>> bootstrap these values using ARIMA model.
>>> 
>>> here is my code so far:
>>> rm(list = ls())
>>> library(boot)
>>> library(tseries)
>>> library(TTR)
>>> library(quantmod)
>>> library(scales)
>>> library(forecast)
>>> library(zoo)
>>> library(TSA)
>>> security<-"NFLX"
>>> startDate<-"2012-06-01"
>>> endDate<-"2016-10-31"
>>> qte_list<-c("AdjClose")
>>> 
>>> data=get.hist.quote(instrument = security, startDate, endDate, quote =
>>> qte_list,   provider = "yahoo" )
>>> logret<-diff(log(data[,1]))
>>> fit11<-auto.arima(logret, max.order=10)
>>> 
>>> When i use auto.arima, I get an order of (0,0,0) with non-zero mean.
>> After
>>> this, I tried to use tsboot function but it is not yielding any answers.
>>> 
>>> Any and all help is appreciated.
>>> 
>>> Thank you!
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From klebyn at yahoo.com.br  Sat Dec  3 17:43:59 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sat, 3 Dec 2016 14:43:59 -0200
Subject: [R] tcltk: use of .Tcl.callback
Message-ID: <be31e722-5906-ba5b-fd66-f19b0977d61f@yahoo.com.br>

Dear,
How to properly use the function: .Tcl.callback( ) to trigger a single R
function with different values?
Below is my stupid solution ... The expected behavior is this but I
would like to know how to do it right.

Thanks in advanced

cleber

##############################################

library( tcltk )
top <- tktoplevel()

dummyCopyCutR <- function( optionXXX ){
     if( optionXXX=="copy" ) print("Option Copy")
     if( optionXXX=="cut"  ) print("Option Cut" )
     }

strcmd <- strsplit( .Tcl.callback( dummyCopyCutR ), " %" )[[1]][1]

tkbind( top, '<Control-c>', paste( strcmd, 'copy' ) )
tkbind( top, '<Control-x>', paste( strcmd, 'cut'  ) )

##############################################


---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From klebyn at yahoo.com.br  Sun Dec  4 01:12:26 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sat, 3 Dec 2016 22:12:26 -0200
Subject: [R] tcltk: use of .Tcl.callback
Message-ID: <e5f11678-2448-58cf-1399-b6f3feeea39c@yahoo.com.br>

Dear,
How to properly use the function: .Tcl.callback( ) to trigger a single R
function with different values?
Below is my stupid solution ... The expected behavior is this but I
would like to know how to do it right.

Thanks in advanced

cleber

##############################################

library( tcltk )
top <- tktoplevel()

dummyCopyCutR <- function( optionXXX ){
     if( optionXXX=="copy" ) print("Option Copy")
     if( optionXXX=="cut"  ) print("Option Cut" )
     }

strcmd <- strsplit( .Tcl.callback( dummyCopyCutR ), " %" )[[1]][1]

tkbind( top, '<Control-c>', paste( strcmd, 'copy' ) )
tkbind( top, '<Control-x>', paste( strcmd, 'cut'  ) )

##############################################


---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From HDoran at air.org  Sun Dec  4 03:11:01 2016
From: HDoran at air.org (Doran, Harold)
Date: Sun, 4 Dec 2016 02:11:01 +0000
Subject: [R] error serialize (foreach)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68601358EB902@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68601358EB902@DC1VEX10MB01.air.org>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601358EBAE7@DC1VEX10MB01.air.org>

As a follow up to this, I have been able to generate a toy example of reproducible code that generates the same problem. Below is just a sample to represent the issue, but my data and subsequent functions acting on the data are much more involved. 

I no longer have the error, but, the loop running in parallel is extremely slow relative to its serialized counterpart.

I have narrowed down the problem to the fact that I am searching through a very large list, grabbing the data from that list by indexing to subset and then doing stuff to it. Both "work", but the parallel version is very, very slow. I believe I am sending data files to each core and the number of searches happening is prohibitive.

I am very much stuck in the design-based way of how I would do this particular problem on a single core and am not sure if there is a better designed based approach for solving this problem in the parallel version. 

Any advice on better ways to work with the %dopar% version here?

N <- 200000
myList <- vector('list', N)
names(myList) <- 1:N
for(i in 1:N){
	myList[[i]] <- rnorm(100)
}
nms <- 1:N
library(foreach)
library(doParallel)
registerDoParallel(cores=7)

result <- foreach(i = 1:3) %do% {
	dat <- myList[[which(names(myList) == nms[i])]]
	mean(dat)
}

result <- foreach(i = 1:3) %dopar% {
	dat <- myList[[which(names(myList) == nms[i])]]
	mean(dat)
}
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Saturday, December 03, 2016 4:26 PM
To: r-help at r-project.org
Subject: [R] error serialize (foreach)

I have a portion of a foreach loop that I cannot run as parallel but works fine when serialized. Below is a representation of the problem as in this instance I cannot provide reproducible data to generate the same error, the actual data I am working with are confidential.

Within each foreach loop are a series of custom functions acting on my data. When using %do% I get expected result but replacing it with %dopar% generates the error.

I have searched archives and also stackexchange and see this is an issue that arises and I have tried a couple of the recommendations, like trying to use an outfile in makeCluster. But I am not having success.

Oddly, (or perhaps not oddly), others portions of my program run in parallel and do not generate this same error

library(foreach)
library(doParallel)
registerDoParallel(cores=3)

# This portion runs and produces expected result result <- foreach(i = 1:N) %do% {
tmp1 <- function1(...)
tmp2 <- function2(...)
tmp2
}

# This portion generates error in serialize result <- foreach(i = 1:N) %dopar% {
tmp1 <- function1(...)
tmp2 <- function2(...)
tmp2
}

error in serialize(data, node$con) : error writing to connection


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ashimkapoor at gmail.com  Sun Dec  4 05:33:07 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 4 Dec 2016 10:03:07 +0530
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365A4468@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
	<CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A4468@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAC8=1erwrTRyePhd3Jr1NrfTtucryaLKp-T_ADGhtecYC=iU8g@mail.gmail.com>

Dear Sir,

Many thanks for the explanation. Prior to your email (with some help from a
friend of mine) I was able to figure this one out. If we look at the model
: -

y = intercept + B1.woolB + B2. tensionM + B3.tensionH + B4. woolB.TensionM
+ B5.woolB.TensionH + error

Here woolB, tensionM, tensionH are the dummy indicator variables similar to
how you have defined them.

Now suppose we consider y1,..,yn, all in group A.L (say).

Then y1 + ... + yn = intercept => average(y1,...,yn) = intercept + 0 + 0 +
0 + 0 + 0.

What was confusing me was how to compute the cell mean in woolB,tensionH
cell.

If we have y_1,...,y_n all in group B.H then :-

y_1+ ... + y_n = intercept + B1 + 0 + B3 + 0 +  B5

Therefore average of group B.H = intercept + B1 + B3 + B5

Many thanks and Best Regards,
Ashim



On Sat, Dec 3, 2016 at 7:15 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Ashim,
>
> Sorry to chime in late, and my apologies if someone has already pointed
> this out, but here's the relationship between the cell means and the model
> coefficients, using the row-basis of the model matrix:
>
> -------------------------- snip ------------------------
>
> > means <- with( warpbreaks, tapply( breaks, interaction(wool, tension),
> mean ) )
> > x.A <- rep(c(0, 1), 3)
> > x.B1 <- rep(c(0, 1, 0), each=2)
> > x.B2 <- rep(c(0, 0, 1), each=2)
> > x.AB1 <- x.A*x.B1
> > x.AB2 <- x.A*x.B2
> > X.basis <- cbind(1, x.A, x.B1, x.B2, x.AB1, x.AB2)
> > X.basis
>        x.A x.B1 x.B2 x.AB1 x.AB2
> [1,] 1   0    0    0     0     0
> [2,] 1   1    0    0     0     0
> [3,] 1   0    1    0     0     0
> [4,] 1   1    1    0     1     0
> [5,] 1   0    0    1     0     0
> [6,] 1   1    0    1     0     1
> > solve(X.basis, means)
>                 x.A      x.B1      x.B2     x.AB1     x.AB2
>  44.55556 -16.33333 -20.55556 -20.00000  21.11111  10.55556
> > coef(aov(breaks ~ wool * tension, data = warpbreaks))
>    (Intercept)          woolB       tensionM       tensionH woolB:tensionM
>       44.55556      -16.33333      -20.55556      -20.00000       21.11111
> woolB:tensionH
>       10.55556
>
> -------------------------- snip ------------------------
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
> Kapoor
> > Sent: December 3, 2016 12:19 AM
> > To: David Winsemius <dwinsemius at comcast.net>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Interpreting summary.lm for a 2 factor anova
> >
> > Please allow me to rephrase myquery.
> >
> > > model.tables(model,"m")
> > Tables of means
> > Grand mean
> >
> > 28.14815
> >
> >  wool
> > wool
> >      A      B
> > 31.037 25.259
> >
> >  tension
> > tension
> >     L     M     H
> > 36.39 26.39 21.67
> >
> >  wool:tension
> >     tension
> > wool L     M     H
> >    A 44.56 24.00 24.56
> >    B 28.22 28.78 18.78
> > >
> >
> >
> > The above is the same as :
> >
> > with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
> >      A.L      B.L      A.M      B.M      A.H      B.H
> > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
> >
> > For reference:
> >
> > > model <- aov(breaks ~ wool * tension, data = warpbreaks)
> > > summary.lm(model)
> >
> > Call:
> > aov(formula = breaks ~ wool * tension, data = warpbreaks)
> >
> > Residuals:
> >      Min       1Q   Median       3Q      Max
> > -19.5556  -6.8889  -0.6667   7.1944  25.4444
> >
> > Coefficients:
> >                Estimate Std. Error t value Pr(>|t|)
> > (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> > woolB           -16.333      5.157  -3.167 0.002677 **
> > tensionM        -20.556      5.157  -3.986 0.000228 ***
> > tensionH        -20.000      5.157  -3.878 0.000320 ***
> > woolB:tensionM   21.111      7.294   2.895 0.005698 **
> > woolB:tensionH   10.556      7.294   1.447 0.154327
> > ---
> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >
> > Residual standard error: 10.94 on 48 degrees of freedom
> > Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> > F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> >
> >
> > Now I'll explain what is confusing me in the output of summary.lm.
> >
> > Coeff of Intercept = 44.556  = cell mean for A.L. This is the base.
> >
> > Coeff of woolB:L = -16.333 = 28.22222 - 44.556. This is the difference
> of this
> > cell mean(B:L) from the base.
> >
> > Coeff of woolA:tensionM = -20.556  = 24.000- 44.556. This is the
> difference of
> > this cell mean (A:M)  from the base.
> >
> > Coeff of woolA:tensionH = -20.000  = 24.55556 - 44.556. This is the
> difference
> > of this cell mean(A:H) from the base.
> >
> > This is where it stops being the difference from the base.
> >
> > Coeff of woolB:tensionM = 21.111 should turn out to be 28.77778 - 44.556
> but
> > this is -15.77822
> >
> > Coeff of woolB:tensionH = 10.556 should turn out to be  18.77778 -
> 44.556 but
> > this is -25.77822
> >
> > In the above 2 cases, we can't say that the coefficient = cell mean -
> base case.
> > Can you tell me what should be the statement to be made ?
> >
> >
> > Best Regards,
> > Ashim
> >
> > PS : My apologies for emailing my query to this list. Can you tell me
> the names
> > of a few (active) statistics help list ?
> >
> > On Sat, Dec 3, 2016 at 1:33 AM, David Winsemius <dwinsemius at comcast.net>
> > wrote:
> >
> > >
> > > > On Dec 2, 2016, at 9:09 AM, David Winsemius <dwinsemius at comcast.net>
> > > wrote:
> > > >
> > > >>
> > > >> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> > wrote:
> > > >>
> > > >> Dear Pikal,
> > > >>
> > > >> All levels except the interactions are compared to the Intercept.
> > > >> I'm a little confused as to what's going on in interaction terms
> > > >> eg. the cell wool B : tension M. It's mean is :
> > > >> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
> > > >>
> > > >> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556
> > > >> (tension
> > > >> M)  + 21.111 (woolB:tensionM) = 28.782.
> > > >>
> > > >> I don't know how to sum up the above line in terms of differences
> > > >> succinctly.
> > > >
> > > > The aov estimate will not exactly equal the observed mean (this is
> > > _statistics_ after all). You should be comparing the mean of that cell
> > > to the estimate:
> > > >
> > > > 44.556 + (-16.33) +(-20.556) + (21.11)
> > >
> > > A respected participant advised me to look at this more closely. In
> > > this case (and I think in most such cases)  where there are the same
> > > number of parameters as there are means, the model is "saturated" and
> > > there is no
> > > difference:
> > >
> > >  with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
> > >      A.L      B.L      A.M      B.M      A.H      B.H
> > > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
> > >
> > > So the B:M estimate is identical up to rounding with the observed mean:
> > >
> > >  44.556 + (-16.33) +(-20.556) + (21.11) [1] 28.78
> > >
> > >
> > >
> > > >
> > > > The difference between the observed mean and the estimated mean is
> > known
> > > as a 'residual'
> > >
> > > I've also been privately but gently chided for this misstatement.
> > > Residuals are the difference between data and estimates.
> > >
> > > > and the squared sum of the all residuals is what this being minimized
> > > ... over all the cells including the one implicitly associated with the
> > > Intercept.
> > > >
> > > > This isn't really on-topic for Rhelp since you are not having
> difficulty
> > > in getting the R program to perform its duties, but are rather in need
> of
> > > statistical education. That not what this mailing list is set up for.
> > > >
> > > > --
> > > > David.
> > > >
> > > >>
> > > >>>
> > > >>>> -----Original Message-----
> > > >>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Ashim
> > > >>>> Kapoor
> > > >>>> Sent: Thursday, December 1, 2016 2:48 PM
> > > >>>> To: r-help at r-project.org
> > > >>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
> > > >>>>
> > > >>>> Dear all,
> > > >>>>
> > > >>>> Here is a small example : -
> > > >>>>
> > > >>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
> > > >>>>> summary.lm(model)
> > > >>>>
> > > >>>> Call:
> > > >>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
> > > >>>>
> > > >>>> Residuals:
> > > >>>>    Min       1Q   Median       3Q      Max
> > > >>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
> > > >>>>
> > > >>>> Coefficients:
> > > >>>>              Estimate Std. Error t value Pr(>|t|)
> > > >>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> > > >>>> woolB           -16.333      5.157  -3.167 0.002677 **
> > > >>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
> > > >>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
> > > >>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
> > > >>>> woolB:tensionH   10.556      7.294   1.447 0.154327
> > > >>>> ---
> > > >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> > > >>>>
> > > >>>> Residual standard error: 10.94 on 48 degrees of freedom
> > > >>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> > > >>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> > > >>>>
> > > >>>>> model.tables(model,"e")
> > > >>>> Tables of effects
> > > >>>>
> > > >>>> wool
> > > >>>> wool
> > > >>>>     A       B
> > > >>>> 2.8889 -2.8889
> > > >>>>
> > > >>>> tension
> > > >>>> tension
> > > >>>>    L      M      H
> > > >>>> 8.241 -1.759 -6.481
> > > >>>>
> > > >>>> wool:tension
> > > >>>>   tension
> > > >>>> wool L      M      H
> > > >>>>  A  5.278 -5.278  0.000
> > > >>>>  B -5.278  5.278  0.000
> > > >>>>
> > > >>>>
> > > >>>>> model.tables(model,"m")
> > > >>>> Tables of means
> > > >>>> Grand mean
> > > >>>>
> > > >>>> 28.14815
> > > >>>>
> > > >>>> wool
> > > >>>> wool
> > > >>>>    A      B
> > > >>>> 31.037 25.259
> > > >>>>
> > > >>>> tension
> > > >>>> tension
> > > >>>>   L     M     H
> > > >>>> 36.39 26.39 21.67
> > > >>>>
> > > >>>> wool:tension
> > > >>>>   tension
> > > >>>> wool L     M     H
> > > >>>>  A 44.56 24.00 24.56
> > > >>>>  B 28.22 28.78 18.78
> > > >>>>>
> > > >>>>
> > > >>>> I don't follow the output of summary.lm. I understand the output
> of
> > > >>>> model.tables for effects and means. For instance what does 44.556
> > > >>>> represent ? Is it the grand average ? The grand mean is 28.14815.
> Can
> > > >>>> someone help me understand the output of summary.lm ?
> > > >>>>
> > > >>>> Best Regards,
> > > >>>> Ashim
> > > >>>>
> > > >>>>     [[alternative HTML version deleted]]
> > > >>>>
> > > >>>> ______________________________________________
> > > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >>>> PLEASE do read the posting guide http://www.R-project.org/
> posting-
> > > >>>> guide.html
> > > >>>> and provide commented, minimal, self-contained, reproducible code.
> > > >>>
> > > >>> ________________________________
> > > >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou
> > > >>> ur?eny pouze jeho adres?t?m.
> > > >>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> > > >>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
> jeho
> > > kopie
> > > >>> vyma?te ze sv?ho syst?mu.
> > > >>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
> tento
> > > email
> > > >>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > > >>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> > > modifikacemi
> > > >>> ?i zpo?d?n?m p?enosu e-mailu.
> > > >>>
> > > >>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > > >>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> > > >>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > > >>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> > > p?ijmout;
> > > >>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> strany
> > > >>> p??jemce s dodatkem ?i odchylkou.
> > > >>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> > > >>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > > >>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> > > >>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> > > zmocn?n
> > > >>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi
> > > tohoto
> > > >>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
> jejich
> > > >>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> > > >>>
> > > >>> This e-mail and any documents attached to it may be confidential
> and
> > > are
> > > >>> intended only for its intended recipients.
> > > >>> If you received this e-mail by mistake, please immediately inform
> its
> > > >>> sender. Delete the contents of this e-mail with all attachments
> and its
> > > >>> copies from your system.
> > > >>> If you are not the intended recipient of this e-mail, you are not
> > > >>> authorized to use, disseminate, copy or disclose this e-mail in any
> > > manner.
> > > >>> The sender of this e-mail shall not be liable for any possible
> damage
> > > >>> caused by modifications of the e-mail or by delay with transfer of
> the
> > > >>> email.
> > > >>>
> > > >>> In case that this e-mail forms part of business dealings:
> > > >>> - the sender reserves the right to end negotiations about entering
> > > into a
> > > >>> contract in any time, for any reason, and without stating any
> > > reasoning.
> > > >>> - if the e-mail contains an offer, the recipient is entitled to
> > > >>> immediately accept such offer; The sender of this e-mail (offer)
> > > excludes
> > > >>> any acceptance of the offer on the part of the recipient
> containing any
> > > >>> amendment or variation.
> > > >>> - the sender insists on that the respective contract is concluded
> only
> > > >>> upon an express mutual agreement on all its aspects.
> > > >>> - the sender of this e-mail informs that he/she is not authorized
> to
> > > enter
> > > >>> into any contracts on behalf of the company except for cases in
> which
> > > >>> he/she is expressly authorized to do so in writing, and such
> > > authorization
> > > >>> or power of attorney is submitted to the recipient or the person
> > > >>> represented by the recipient, or the existence of such
> authorization is
> > > >>> known to the recipient of the person represented by the recipient.
> > > >>>
> > > >>
> > > >>      [[alternative HTML version deleted]]
> > > >>
> > > >> ______________________________________________
> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > > >> PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > >> and provide commented, minimal, self-contained, reproducible code.
> > > >
> > > > David Winsemius
> > > > Alameda, CA, USA
> > > >
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > > David Winsemius
> > > Alameda, CA, USA
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Dec  4 05:46:25 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 4 Dec 2016 10:16:25 +0530
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAC8=1erwrTRyePhd3Jr1NrfTtucryaLKp-T_ADGhtecYC=iU8g@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
	<CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A4468@FHSDB2D11-2.csu.mcmaster.ca>
	<CAC8=1erwrTRyePhd3Jr1NrfTtucryaLKp-T_ADGhtecYC=iU8g@mail.gmail.com>
Message-ID: <CAC8=1eo_Vyyq7VyTCeKHJ_5V0tHkMpjiNj1PXcQT0FTTZgpP2g@mail.gmail.com>

On Sun, Dec 4, 2016 at 10:03 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:

> Dear Sir,
>
> Many thanks for the explanation. Prior to your email (with some help from
> a friend of mine) I was able to figure this one out. If we look at the
> model : -
>
> y = intercept + B1.woolB + B2. tensionM + B3.tensionH + B4. woolB.TensionM
> + B5.woolB.TensionH + error
>
> Here woolB, tensionM, tensionH are the dummy indicator variables similar
> to how you have defined them.
>
> Now suppose we consider y1,..,yn, all in group A.L (say).
>
> Then y1 + ... + yn = intercept => average(y1,...,yn) = intercept + 0 + 0 +
> 0 + 0 + 0.
>
> This should be : y1 + ... yn = n . intercept

What was confusing me was how to compute the cell mean in woolB,tensionH
> cell.
>
> If we have y_1,...,y_n all in group B.H then :-
>
> y_1+ ... + y_n = intercept + B1 + 0 + B3 + 0 +  B5
>
> This should be : y_1 + ... +y_n = n( intercept + B1 + 0 + B3 + 0 +  B5 )


> Therefore average of group B.H = intercept + B1 + B3 + B5
>
> Many thanks and Best Regards,
> Ashim
>
>
>
> On Sat, Dec 3, 2016 at 7:15 PM, Fox, John <jfox at mcmaster.ca> wrote:
>
>> Dear Ashim,
>>
>> Sorry to chime in late, and my apologies if someone has already pointed
>> this out, but here's the relationship between the cell means and the model
>> coefficients, using the row-basis of the model matrix:
>>
>> -------------------------- snip ------------------------
>>
>> > means <- with( warpbreaks, tapply( breaks, interaction(wool, tension),
>> mean ) )
>> > x.A <- rep(c(0, 1), 3)
>> > x.B1 <- rep(c(0, 1, 0), each=2)
>> > x.B2 <- rep(c(0, 0, 1), each=2)
>> > x.AB1 <- x.A*x.B1
>> > x.AB2 <- x.A*x.B2
>> > X.basis <- cbind(1, x.A, x.B1, x.B2, x.AB1, x.AB2)
>> > X.basis
>>        x.A x.B1 x.B2 x.AB1 x.AB2
>> [1,] 1   0    0    0     0     0
>> [2,] 1   1    0    0     0     0
>> [3,] 1   0    1    0     0     0
>> [4,] 1   1    1    0     1     0
>> [5,] 1   0    0    1     0     0
>> [6,] 1   1    0    1     0     1
>> > solve(X.basis, means)
>>                 x.A      x.B1      x.B2     x.AB1     x.AB2
>>  44.55556 -16.33333 -20.55556 -20.00000  21.11111  10.55556
>> > coef(aov(breaks ~ wool * tension, data = warpbreaks))
>>    (Intercept)          woolB       tensionM       tensionH woolB:tensionM
>>       44.55556      -16.33333      -20.55556      -20.00000       21.11111
>> woolB:tensionH
>>       10.55556
>>
>> -------------------------- snip ------------------------
>>
>> I hope this helps,
>>  John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
>> Kapoor
>> > Sent: December 3, 2016 12:19 AM
>> > To: David Winsemius <dwinsemius at comcast.net>
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] Interpreting summary.lm for a 2 factor anova
>> >
>> > Please allow me to rephrase myquery.
>> >
>> > > model.tables(model,"m")
>> > Tables of means
>> > Grand mean
>> >
>> > 28.14815
>> >
>> >  wool
>> > wool
>> >      A      B
>> > 31.037 25.259
>> >
>> >  tension
>> > tension
>> >     L     M     H
>> > 36.39 26.39 21.67
>> >
>> >  wool:tension
>> >     tension
>> > wool L     M     H
>> >    A 44.56 24.00 24.56
>> >    B 28.22 28.78 18.78
>> > >
>> >
>> >
>> > The above is the same as :
>> >
>> > with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
>> >      A.L      B.L      A.M      B.M      A.H      B.H
>> > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
>> >
>> > For reference:
>> >
>> > > model <- aov(breaks ~ wool * tension, data = warpbreaks)
>> > > summary.lm(model)
>> >
>> > Call:
>> > aov(formula = breaks ~ wool * tension, data = warpbreaks)
>> >
>> > Residuals:
>> >      Min       1Q   Median       3Q      Max
>> > -19.5556  -6.8889  -0.6667   7.1944  25.4444
>> >
>> > Coefficients:
>> >                Estimate Std. Error t value Pr(>|t|)
>> > (Intercept)      44.556      3.647  12.218 2.43e-16 ***
>> > woolB           -16.333      5.157  -3.167 0.002677 **
>> > tensionM        -20.556      5.157  -3.986 0.000228 ***
>> > tensionH        -20.000      5.157  -3.878 0.000320 ***
>> > woolB:tensionM   21.111      7.294   2.895 0.005698 **
>> > woolB:tensionH   10.556      7.294   1.447 0.154327
>> > ---
>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> >
>> > Residual standard error: 10.94 on 48 degrees of freedom
>> > Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
>> > F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>> >
>> >
>> > Now I'll explain what is confusing me in the output of summary.lm.
>> >
>> > Coeff of Intercept = 44.556  = cell mean for A.L. This is the base.
>> >
>> > Coeff of woolB:L = -16.333 = 28.22222 - 44.556. This is the difference
>> of this
>> > cell mean(B:L) from the base.
>> >
>> > Coeff of woolA:tensionM = -20.556  = 24.000- 44.556. This is the
>> difference of
>> > this cell mean (A:M)  from the base.
>> >
>> > Coeff of woolA:tensionH = -20.000  = 24.55556 - 44.556. This is the
>> difference
>> > of this cell mean(A:H) from the base.
>> >
>> > This is where it stops being the difference from the base.
>> >
>> > Coeff of woolB:tensionM = 21.111 should turn out to be 28.77778 -
>> 44.556 but
>> > this is -15.77822
>> >
>> > Coeff of woolB:tensionH = 10.556 should turn out to be  18.77778 -
>> 44.556 but
>> > this is -25.77822
>> >
>> > In the above 2 cases, we can't say that the coefficient = cell mean -
>> base case.
>> > Can you tell me what should be the statement to be made ?
>> >
>> >
>> > Best Regards,
>> > Ashim
>> >
>> > PS : My apologies for emailing my query to this list. Can you tell me
>> the names
>> > of a few (active) statistics help list ?
>> >
>> > On Sat, Dec 3, 2016 at 1:33 AM, David Winsemius <dwinsemius at comcast.net
>> >
>> > wrote:
>> >
>> > >
>> > > > On Dec 2, 2016, at 9:09 AM, David Winsemius <dwinsemius at comcast.net
>> >
>> > > wrote:
>> > > >
>> > > >>
>> > > >> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com>
>> > wrote:
>> > > >>
>> > > >> Dear Pikal,
>> > > >>
>> > > >> All levels except the interactions are compared to the Intercept.
>> > > >> I'm a little confused as to what's going on in interaction terms
>> > > >> eg. the cell wool B : tension M. It's mean is :
>> > > >> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
>> > > >>
>> > > >> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556
>> > > >> (tension
>> > > >> M)  + 21.111 (woolB:tensionM) = 28.782.
>> > > >>
>> > > >> I don't know how to sum up the above line in terms of differences
>> > > >> succinctly.
>> > > >
>> > > > The aov estimate will not exactly equal the observed mean (this is
>> > > _statistics_ after all). You should be comparing the mean of that cell
>> > > to the estimate:
>> > > >
>> > > > 44.556 + (-16.33) +(-20.556) + (21.11)
>> > >
>> > > A respected participant advised me to look at this more closely. In
>> > > this case (and I think in most such cases)  where there are the same
>> > > number of parameters as there are means, the model is "saturated" and
>> > > there is no
>> > > difference:
>> > >
>> > >  with( warpbreaks, tapply( breaks, interaction(wool, tension), mean )
>> )
>> > >      A.L      B.L      A.M      B.M      A.H      B.H
>> > > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
>> > >
>> > > So the B:M estimate is identical up to rounding with the observed
>> mean:
>> > >
>> > >  44.556 + (-16.33) +(-20.556) + (21.11) [1] 28.78
>> > >
>> > >
>> > >
>> > > >
>> > > > The difference between the observed mean and the estimated mean is
>> > known
>> > > as a 'residual'
>> > >
>> > > I've also been privately but gently chided for this misstatement.
>> > > Residuals are the difference between data and estimates.
>> > >
>> > > > and the squared sum of the all residuals is what this being
>> minimized
>> > > ... over all the cells including the one implicitly associated with
>> the
>> > > Intercept.
>> > > >
>> > > > This isn't really on-topic for Rhelp since you are not having
>> difficulty
>> > > in getting the R program to perform its duties, but are rather in
>> need of
>> > > statistical education. That not what this mailing list is set up for.
>> > > >
>> > > > --
>> > > > David.
>> > > >
>> > > >>
>> > > >>>
>> > > >>>> -----Original Message-----
>> > > >>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> Ashim
>> > > >>>> Kapoor
>> > > >>>> Sent: Thursday, December 1, 2016 2:48 PM
>> > > >>>> To: r-help at r-project.org
>> > > >>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
>> > > >>>>
>> > > >>>> Dear all,
>> > > >>>>
>> > > >>>> Here is a small example : -
>> > > >>>>
>> > > >>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
>> > > >>>>> summary.lm(model)
>> > > >>>>
>> > > >>>> Call:
>> > > >>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
>> > > >>>>
>> > > >>>> Residuals:
>> > > >>>>    Min       1Q   Median       3Q      Max
>> > > >>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
>> > > >>>>
>> > > >>>> Coefficients:
>> > > >>>>              Estimate Std. Error t value Pr(>|t|)
>> > > >>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
>> > > >>>> woolB           -16.333      5.157  -3.167 0.002677 **
>> > > >>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
>> > > >>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
>> > > >>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
>> > > >>>> woolB:tensionH   10.556      7.294   1.447 0.154327
>> > > >>>> ---
>> > > >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>> > > >>>>
>> > > >>>> Residual standard error: 10.94 on 48 degrees of freedom
>> > > >>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
>> > > >>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>> > > >>>>
>> > > >>>>> model.tables(model,"e")
>> > > >>>> Tables of effects
>> > > >>>>
>> > > >>>> wool
>> > > >>>> wool
>> > > >>>>     A       B
>> > > >>>> 2.8889 -2.8889
>> > > >>>>
>> > > >>>> tension
>> > > >>>> tension
>> > > >>>>    L      M      H
>> > > >>>> 8.241 -1.759 -6.481
>> > > >>>>
>> > > >>>> wool:tension
>> > > >>>>   tension
>> > > >>>> wool L      M      H
>> > > >>>>  A  5.278 -5.278  0.000
>> > > >>>>  B -5.278  5.278  0.000
>> > > >>>>
>> > > >>>>
>> > > >>>>> model.tables(model,"m")
>> > > >>>> Tables of means
>> > > >>>> Grand mean
>> > > >>>>
>> > > >>>> 28.14815
>> > > >>>>
>> > > >>>> wool
>> > > >>>> wool
>> > > >>>>    A      B
>> > > >>>> 31.037 25.259
>> > > >>>>
>> > > >>>> tension
>> > > >>>> tension
>> > > >>>>   L     M     H
>> > > >>>> 36.39 26.39 21.67
>> > > >>>>
>> > > >>>> wool:tension
>> > > >>>>   tension
>> > > >>>> wool L     M     H
>> > > >>>>  A 44.56 24.00 24.56
>> > > >>>>  B 28.22 28.78 18.78
>> > > >>>>>
>> > > >>>>
>> > > >>>> I don't follow the output of summary.lm. I understand the output
>> of
>> > > >>>> model.tables for effects and means. For instance what does 44.556
>> > > >>>> represent ? Is it the grand average ? The grand mean is
>> 28.14815. Can
>> > > >>>> someone help me understand the output of summary.lm ?
>> > > >>>>
>> > > >>>> Best Regards,
>> > > >>>> Ashim
>> > > >>>>
>> > > >>>>     [[alternative HTML version deleted]]
>> > > >>>>
>> > > >>>> ______________________________________________
>> > > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> see
>> > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >>>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-
>> > > >>>> guide.html
>> > > >>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> > > >>>
>> > > >>> ________________________________
>> > > >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn?
>> a jsou
>> > > >>> ur?eny pouze jeho adres?t?m.
>> > > >>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> > > >>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>> jeho
>> > > kopie
>> > > >>> vyma?te ze sv?ho syst?mu.
>> > > >>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>> tento
>> > > email
>> > > >>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> > > >>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> > > modifikacemi
>> > > >>> ?i zpo?d?n?m p?enosu e-mailu.
>> > > >>>
>> > > >>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> > > >>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o
>> uzav?en?
>> > > >>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> > > >>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> > > p?ijmout;
>> > > >>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>> strany
>> > > >>> p??jemce s dodatkem ?i odchylkou.
>> > > >>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> > > >>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> > > >>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> > > >>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl
>> p?semn?
>> > > zmocn?n
>> > > >>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> adres?tovi
>> > > tohoto
>> > > >>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>> jejich
>> > > >>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> > > >>>
>> > > >>> This e-mail and any documents attached to it may be confidential
>> and
>> > > are
>> > > >>> intended only for its intended recipients.
>> > > >>> If you received this e-mail by mistake, please immediately inform
>> its
>> > > >>> sender. Delete the contents of this e-mail with all attachments
>> and its
>> > > >>> copies from your system.
>> > > >>> If you are not the intended recipient of this e-mail, you are not
>> > > >>> authorized to use, disseminate, copy or disclose this e-mail in
>> any
>> > > manner.
>> > > >>> The sender of this e-mail shall not be liable for any possible
>> damage
>> > > >>> caused by modifications of the e-mail or by delay with transfer
>> of the
>> > > >>> email.
>> > > >>>
>> > > >>> In case that this e-mail forms part of business dealings:
>> > > >>> - the sender reserves the right to end negotiations about entering
>> > > into a
>> > > >>> contract in any time, for any reason, and without stating any
>> > > reasoning.
>> > > >>> - if the e-mail contains an offer, the recipient is entitled to
>> > > >>> immediately accept such offer; The sender of this e-mail (offer)
>> > > excludes
>> > > >>> any acceptance of the offer on the part of the recipient
>> containing any
>> > > >>> amendment or variation.
>> > > >>> - the sender insists on that the respective contract is concluded
>> only
>> > > >>> upon an express mutual agreement on all its aspects.
>> > > >>> - the sender of this e-mail informs that he/she is not authorized
>> to
>> > > enter
>> > > >>> into any contracts on behalf of the company except for cases in
>> which
>> > > >>> he/she is expressly authorized to do so in writing, and such
>> > > authorization
>> > > >>> or power of attorney is submitted to the recipient or the person
>> > > >>> represented by the recipient, or the existence of such
>> authorization is
>> > > >>> known to the recipient of the person represented by the recipient.
>> > > >>>
>> > > >>
>> > > >>      [[alternative HTML version deleted]]
>> > > >>
>> > > >> ______________________________________________
>> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > > >> PLEASE do read the posting guide http://www.R-project.org/
>> > > posting-guide.html
>> > > >> and provide commented, minimal, self-contained, reproducible code.
>> > > >
>> > > > David Winsemius
>> > > > Alameda, CA, USA
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide http://www.R-project.org/
>> > > posting-guide.html
>> > > > and provide commented, minimal, self-contained, reproducible code.
>> > >
>> > > David Winsemius
>> > > Alameda, CA, USA
>> > >
>> > >
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ashimkapoor at gmail.com  Sun Dec  4 06:44:26 2016
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Sun, 4 Dec 2016 11:14:26 +0530
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAGx1TMAAakFz9UhQV-rVC2W8vfh_gGPLget==5b5prjo3aDM5A@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
	<CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A4468@FHSDB2D11-2.csu.mcmaster.ca>
	<CAC8=1erwrTRyePhd3Jr1NrfTtucryaLKp-T_ADGhtecYC=iU8g@mail.gmail.com>
	<CAC8=1eo_Vyyq7VyTCeKHJ_5V0tHkMpjiNj1PXcQT0FTTZgpP2g@mail.gmail.com>
	<CAGx1TMAAakFz9UhQV-rVC2W8vfh_gGPLget==5b5prjo3aDM5A@mail.gmail.com>
Message-ID: <CAC8=1eqr0cVVWyj-7-EJKwM9PzTdFS0m50zx-p9r=9FgMvYCfw@mail.gmail.com>

Dear Sir,

Alright.

Best Regards,
Ashim

On Sun, Dec 4, 2016 at 10:59 AM, Richard M. Heiberger <rmh at temple.edu>
wrote:

> As Petr Pikal mentioned, the difficulty in interpretation is entirely due
> to the set of contrasts you chose.The default treatment contrasts are
> not orthogonal and are therefore the most difficult to interpret.
> The note in ?aov warns of this difficulty.
>
> sum contrasts will give you numbers that are easiest to interpret.
>
>
> options(contrasts = c("contr.sum", "contr.poly"))
> warpbreakssum.aov <- aov(breaks ~ wool * tension, data = warpbreaks)
> coef(warpbreakssum.aov)
> model.tables(warpbreakstreatment.aov, type="effects")
> model.tables(warpbreakstreatment.aov, type="means")
>
>
> John Fox showed the algebra using the default treatment contrasts
>
> For full understanding you will need to read  in a text more about
> sets of linear contrasts and their algebra.
> I recommend Section 10.3 in mine, of course.
>
> Statistical Analysis and Data Display:
> An Intermediate Course with Examples in R
> Heiberger, Richard M., Holland, Burt
>
> http://www.springer.com/us/book/9781493921218
>
> On Sat, Dec 3, 2016 at 11:46 PM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> > On Sun, Dec 4, 2016 at 10:03 AM, Ashim Kapoor <ashimkapoor at gmail.com>
> wrote:
> >
> >> Dear Sir,
> >>
> >> Many thanks for the explanation. Prior to your email (with some help
> from
> >> a friend of mine) I was able to figure this one out. If we look at the
> >> model : -
> >>
> >> y = intercept + B1.woolB + B2. tensionM + B3.tensionH + B4.
> woolB.TensionM
> >> + B5.woolB.TensionH + error
> >>
> >> Here woolB, tensionM, tensionH are the dummy indicator variables similar
> >> to how you have defined them.
> >>
> >> Now suppose we consider y1,..,yn, all in group A.L (say).
> >>
> >> Then y1 + ... + yn = intercept => average(y1,...,yn) = intercept + 0 +
> 0 +
> >> 0 + 0 + 0.
> >>
> >> This should be : y1 + ... yn = n . intercept
> >
> > What was confusing me was how to compute the cell mean in woolB,tensionH
> >> cell.
> >>
> >> If we have y_1,...,y_n all in group B.H then :-
> >>
> >> y_1+ ... + y_n = intercept + B1 + 0 + B3 + 0 +  B5
> >>
> >> This should be : y_1 + ... +y_n = n( intercept + B1 + 0 + B3 + 0 +  B5 )
> >
> >
> >> Therefore average of group B.H = intercept + B1 + B3 + B5
> >>
> >> Many thanks and Best Regards,
> >> Ashim
> >>
> >>
> >>
> >> On Sat, Dec 3, 2016 at 7:15 PM, Fox, John <jfox at mcmaster.ca> wrote:
> >>
> >>> Dear Ashim,
> >>>
> >>> Sorry to chime in late, and my apologies if someone has already pointed
> >>> this out, but here's the relationship between the cell means and the
> model
> >>> coefficients, using the row-basis of the model matrix:
> >>>
> >>> -------------------------- snip ------------------------
> >>>
> >>> > means <- with( warpbreaks, tapply( breaks, interaction(wool,
> tension),
> >>> mean ) )
> >>> > x.A <- rep(c(0, 1), 3)
> >>> > x.B1 <- rep(c(0, 1, 0), each=2)
> >>> > x.B2 <- rep(c(0, 0, 1), each=2)
> >>> > x.AB1 <- x.A*x.B1
> >>> > x.AB2 <- x.A*x.B2
> >>> > X.basis <- cbind(1, x.A, x.B1, x.B2, x.AB1, x.AB2)
> >>> > X.basis
> >>>        x.A x.B1 x.B2 x.AB1 x.AB2
> >>> [1,] 1   0    0    0     0     0
> >>> [2,] 1   1    0    0     0     0
> >>> [3,] 1   0    1    0     0     0
> >>> [4,] 1   1    1    0     1     0
> >>> [5,] 1   0    0    1     0     0
> >>> [6,] 1   1    0    1     0     1
> >>> > solve(X.basis, means)
> >>>                 x.A      x.B1      x.B2     x.AB1     x.AB2
> >>>  44.55556 -16.33333 -20.55556 -20.00000  21.11111  10.55556
> >>> > coef(aov(breaks ~ wool * tension, data = warpbreaks))
> >>>    (Intercept)          woolB       tensionM       tensionH
> woolB:tensionM
> >>>       44.55556      -16.33333      -20.55556      -20.00000
>  21.11111
> >>> woolB:tensionH
> >>>       10.55556
> >>>
> >>> -------------------------- snip ------------------------
> >>>
> >>> I hope this helps,
> >>>  John
> >>>
> >>> -----------------------------
> >>> John Fox, Professor
> >>> McMaster University
> >>> Hamilton, Ontario
> >>> Canada L8S 4M4
> >>> Web: socserv.mcmaster.ca/jfox
> >>>
> >>>
> >>>
> >>> > -----Original Message-----
> >>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> Ashim
> >>> Kapoor
> >>> > Sent: December 3, 2016 12:19 AM
> >>> > To: David Winsemius <dwinsemius at comcast.net>
> >>> > Cc: r-help at r-project.org
> >>> > Subject: Re: [R] Interpreting summary.lm for a 2 factor anova
> >>> >
> >>> > Please allow me to rephrase myquery.
> >>> >
> >>> > > model.tables(model,"m")
> >>> > Tables of means
> >>> > Grand mean
> >>> >
> >>> > 28.14815
> >>> >
> >>> >  wool
> >>> > wool
> >>> >      A      B
> >>> > 31.037 25.259
> >>> >
> >>> >  tension
> >>> > tension
> >>> >     L     M     H
> >>> > 36.39 26.39 21.67
> >>> >
> >>> >  wool:tension
> >>> >     tension
> >>> > wool L     M     H
> >>> >    A 44.56 24.00 24.56
> >>> >    B 28.22 28.78 18.78
> >>> > >
> >>> >
> >>> >
> >>> > The above is the same as :
> >>> >
> >>> > with( warpbreaks, tapply( breaks, interaction(wool, tension), mean )
> )
> >>> >      A.L      B.L      A.M      B.M      A.H      B.H
> >>> > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
> >>> >
> >>> > For reference:
> >>> >
> >>> > > model <- aov(breaks ~ wool * tension, data = warpbreaks)
> >>> > > summary.lm(model)
> >>> >
> >>> > Call:
> >>> > aov(formula = breaks ~ wool * tension, data = warpbreaks)
> >>> >
> >>> > Residuals:
> >>> >      Min       1Q   Median       3Q      Max
> >>> > -19.5556  -6.8889  -0.6667   7.1944  25.4444
> >>> >
> >>> > Coefficients:
> >>> >                Estimate Std. Error t value Pr(>|t|)
> >>> > (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> >>> > woolB           -16.333      5.157  -3.167 0.002677 **
> >>> > tensionM        -20.556      5.157  -3.986 0.000228 ***
> >>> > tensionH        -20.000      5.157  -3.878 0.000320 ***
> >>> > woolB:tensionM   21.111      7.294   2.895 0.005698 **
> >>> > woolB:tensionH   10.556      7.294   1.447 0.154327
> >>> > ---
> >>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>> >
> >>> > Residual standard error: 10.94 on 48 degrees of freedom
> >>> > Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> >>> > F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> >>> >
> >>> >
> >>> > Now I'll explain what is confusing me in the output of summary.lm.
> >>> >
> >>> > Coeff of Intercept = 44.556  = cell mean for A.L. This is the base.
> >>> >
> >>> > Coeff of woolB:L = -16.333 = 28.22222 - 44.556. This is the
> difference
> >>> of this
> >>> > cell mean(B:L) from the base.
> >>> >
> >>> > Coeff of woolA:tensionM = -20.556  = 24.000- 44.556. This is the
> >>> difference of
> >>> > this cell mean (A:M)  from the base.
> >>> >
> >>> > Coeff of woolA:tensionH = -20.000  = 24.55556 - 44.556. This is the
> >>> difference
> >>> > of this cell mean(A:H) from the base.
> >>> >
> >>> > This is where it stops being the difference from the base.
> >>> >
> >>> > Coeff of woolB:tensionM = 21.111 should turn out to be 28.77778 -
> >>> 44.556 but
> >>> > this is -15.77822
> >>> >
> >>> > Coeff of woolB:tensionH = 10.556 should turn out to be  18.77778 -
> >>> 44.556 but
> >>> > this is -25.77822
> >>> >
> >>> > In the above 2 cases, we can't say that the coefficient = cell mean -
> >>> base case.
> >>> > Can you tell me what should be the statement to be made ?
> >>> >
> >>> >
> >>> > Best Regards,
> >>> > Ashim
> >>> >
> >>> > PS : My apologies for emailing my query to this list. Can you tell me
> >>> the names
> >>> > of a few (active) statistics help list ?
> >>> >
> >>> > On Sat, Dec 3, 2016 at 1:33 AM, David Winsemius <
> dwinsemius at comcast.net
> >>> >
> >>> > wrote:
> >>> >
> >>> > >
> >>> > > > On Dec 2, 2016, at 9:09 AM, David Winsemius <
> dwinsemius at comcast.net
> >>> >
> >>> > > wrote:
> >>> > > >
> >>> > > >>
> >>> > > >> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com
> >
> >>> > wrote:
> >>> > > >>
> >>> > > >> Dear Pikal,
> >>> > > >>
> >>> > > >> All levels except the interactions are compared to the
> Intercept.
> >>> > > >> I'm a little confused as to what's going on in interaction terms
> >>> > > >> eg. the cell wool B : tension M. It's mean is :
> >>> > > >> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
> >>> > > >>
> >>> > > >> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556
> >>> > > >> (tension
> >>> > > >> M)  + 21.111 (woolB:tensionM) = 28.782.
> >>> > > >>
> >>> > > >> I don't know how to sum up the above line in terms of
> differences
> >>> > > >> succinctly.
> >>> > > >
> >>> > > > The aov estimate will not exactly equal the observed mean (this
> is
> >>> > > _statistics_ after all). You should be comparing the mean of that
> cell
> >>> > > to the estimate:
> >>> > > >
> >>> > > > 44.556 + (-16.33) +(-20.556) + (21.11)
> >>> > >
> >>> > > A respected participant advised me to look at this more closely. In
> >>> > > this case (and I think in most such cases)  where there are the
> same
> >>> > > number of parameters as there are means, the model is "saturated"
> and
> >>> > > there is no
> >>> > > difference:
> >>> > >
> >>> > >  with( warpbreaks, tapply( breaks, interaction(wool, tension),
> mean )
> >>> )
> >>> > >      A.L      B.L      A.M      B.M      A.H      B.H
> >>> > > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
> >>> > >
> >>> > > So the B:M estimate is identical up to rounding with the observed
> >>> mean:
> >>> > >
> >>> > >  44.556 + (-16.33) +(-20.556) + (21.11) [1] 28.78
> >>> > >
> >>> > >
> >>> > >
> >>> > > >
> >>> > > > The difference between the observed mean and the estimated mean
> is
> >>> > known
> >>> > > as a 'residual'
> >>> > >
> >>> > > I've also been privately but gently chided for this misstatement.
> >>> > > Residuals are the difference between data and estimates.
> >>> > >
> >>> > > > and the squared sum of the all residuals is what this being
> >>> minimized
> >>> > > ... over all the cells including the one implicitly associated with
> >>> the
> >>> > > Intercept.
> >>> > > >
> >>> > > > This isn't really on-topic for Rhelp since you are not having
> >>> difficulty
> >>> > > in getting the R program to perform its duties, but are rather in
> >>> need of
> >>> > > statistical education. That not what this mailing list is set up
> for.
> >>> > > >
> >>> > > > --
> >>> > > > David.
> >>> > > >
> >>> > > >>
> >>> > > >>>
> >>> > > >>>> -----Original Message-----
> >>> > > >>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf
> Of
> >>> Ashim
> >>> > > >>>> Kapoor
> >>> > > >>>> Sent: Thursday, December 1, 2016 2:48 PM
> >>> > > >>>> To: r-help at r-project.org
> >>> > > >>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
> >>> > > >>>>
> >>> > > >>>> Dear all,
> >>> > > >>>>
> >>> > > >>>> Here is a small example : -
> >>> > > >>>>
> >>> > > >>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
> >>> > > >>>>> summary.lm(model)
> >>> > > >>>>
> >>> > > >>>> Call:
> >>> > > >>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
> >>> > > >>>>
> >>> > > >>>> Residuals:
> >>> > > >>>>    Min       1Q   Median       3Q      Max
> >>> > > >>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
> >>> > > >>>>
> >>> > > >>>> Coefficients:
> >>> > > >>>>              Estimate Std. Error t value Pr(>|t|)
> >>> > > >>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
> >>> > > >>>> woolB           -16.333      5.157  -3.167 0.002677 **
> >>> > > >>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
> >>> > > >>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
> >>> > > >>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
> >>> > > >>>> woolB:tensionH   10.556      7.294   1.447 0.154327
> >>> > > >>>> ---
> >>> > > >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> >>> > > >>>>
> >>> > > >>>> Residual standard error: 10.94 on 48 degrees of freedom
> >>> > > >>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
> >>> > > >>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
> >>> > > >>>>
> >>> > > >>>>> model.tables(model,"e")
> >>> > > >>>> Tables of effects
> >>> > > >>>>
> >>> > > >>>> wool
> >>> > > >>>> wool
> >>> > > >>>>     A       B
> >>> > > >>>> 2.8889 -2.8889
> >>> > > >>>>
> >>> > > >>>> tension
> >>> > > >>>> tension
> >>> > > >>>>    L      M      H
> >>> > > >>>> 8.241 -1.759 -6.481
> >>> > > >>>>
> >>> > > >>>> wool:tension
> >>> > > >>>>   tension
> >>> > > >>>> wool L      M      H
> >>> > > >>>>  A  5.278 -5.278  0.000
> >>> > > >>>>  B -5.278  5.278  0.000
> >>> > > >>>>
> >>> > > >>>>
> >>> > > >>>>> model.tables(model,"m")
> >>> > > >>>> Tables of means
> >>> > > >>>> Grand mean
> >>> > > >>>>
> >>> > > >>>> 28.14815
> >>> > > >>>>
> >>> > > >>>> wool
> >>> > > >>>> wool
> >>> > > >>>>    A      B
> >>> > > >>>> 31.037 25.259
> >>> > > >>>>
> >>> > > >>>> tension
> >>> > > >>>> tension
> >>> > > >>>>   L     M     H
> >>> > > >>>> 36.39 26.39 21.67
> >>> > > >>>>
> >>> > > >>>> wool:tension
> >>> > > >>>>   tension
> >>> > > >>>> wool L     M     H
> >>> > > >>>>  A 44.56 24.00 24.56
> >>> > > >>>>  B 28.22 28.78 18.78
> >>> > > >>>>>
> >>> > > >>>>
> >>> > > >>>> I don't follow the output of summary.lm. I understand the
> output
> >>> of
> >>> > > >>>> model.tables for effects and means. For instance what does
> 44.556
> >>> > > >>>> represent ? Is it the grand average ? The grand mean is
> >>> 28.14815. Can
> >>> > > >>>> someone help me understand the output of summary.lm ?
> >>> > > >>>>
> >>> > > >>>> Best Regards,
> >>> > > >>>> Ashim
> >>> > > >>>>
> >>> > > >>>>     [[alternative HTML version deleted]]
> >>> > > >>>>
> >>> > > >>>> ______________________________________________
> >>> > > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>> see
> >>> > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > > >>>> PLEASE do read the posting guide
> http://www.R-project.org/posti
> >>> ng-
> >>> > > >>>> guide.html
> >>> > > >>>> and provide commented, minimal, self-contained, reproducible
> >>> code.
> >>> > > >>>
> >>> > > >>> ________________________________
> >>> > > >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou
> d?v?rn?
> >>> a jsou
> >>> > > >>> ur?eny pouze jeho adres?t?m.
> >>> > > >>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte
> laskav?
> >>> > > >>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami
> a
> >>> jeho
> >>> > > kopie
> >>> > > >>> vyma?te ze sv?ho syst?mu.
> >>> > > >>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
> >>> tento
> >>> > > email
> >>> > > >>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >>> > > >>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> >>> > > modifikacemi
> >>> > > >>> ?i zpo?d?n?m p?enosu e-mailu.
> >>> > > >>>
> >>> > > >>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >>> > > >>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o
> >>> uzav?en?
> >>> > > >>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >>> > > >>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku
> bezodkladn?
> >>> > > p?ijmout;
> >>> > > >>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
> >>> strany
> >>> > > >>> p??jemce s dodatkem ?i odchylkou.
> >>> > > >>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena
> teprve
> >>> > > >>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >>> > > >>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n
> uzav?rat za
> >>> > > >>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl
> >>> p?semn?
> >>> > > zmocn?n
> >>> > > >>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> >>> adres?tovi
> >>> > > tohoto
> >>> > > >>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny
> nebo
> >>> jejich
> >>> > > >>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >>> > > >>>
> >>> > > >>> This e-mail and any documents attached to it may be
> confidential
> >>> and
> >>> > > are
> >>> > > >>> intended only for its intended recipients.
> >>> > > >>> If you received this e-mail by mistake, please immediately
> inform
> >>> its
> >>> > > >>> sender. Delete the contents of this e-mail with all attachments
> >>> and its
> >>> > > >>> copies from your system.
> >>> > > >>> If you are not the intended recipient of this e-mail, you are
> not
> >>> > > >>> authorized to use, disseminate, copy or disclose this e-mail in
> >>> any
> >>> > > manner.
> >>> > > >>> The sender of this e-mail shall not be liable for any possible
> >>> damage
> >>> > > >>> caused by modifications of the e-mail or by delay with transfer
> >>> of the
> >>> > > >>> email.
> >>> > > >>>
> >>> > > >>> In case that this e-mail forms part of business dealings:
> >>> > > >>> - the sender reserves the right to end negotiations about
> entering
> >>> > > into a
> >>> > > >>> contract in any time, for any reason, and without stating any
> >>> > > reasoning.
> >>> > > >>> - if the e-mail contains an offer, the recipient is entitled to
> >>> > > >>> immediately accept such offer; The sender of this e-mail
> (offer)
> >>> > > excludes
> >>> > > >>> any acceptance of the offer on the part of the recipient
> >>> containing any
> >>> > > >>> amendment or variation.
> >>> > > >>> - the sender insists on that the respective contract is
> concluded
> >>> only
> >>> > > >>> upon an express mutual agreement on all its aspects.
> >>> > > >>> - the sender of this e-mail informs that he/she is not
> authorized
> >>> to
> >>> > > enter
> >>> > > >>> into any contracts on behalf of the company except for cases in
> >>> which
> >>> > > >>> he/she is expressly authorized to do so in writing, and such
> >>> > > authorization
> >>> > > >>> or power of attorney is submitted to the recipient or the
> person
> >>> > > >>> represented by the recipient, or the existence of such
> >>> authorization is
> >>> > > >>> known to the recipient of the person represented by the
> recipient.
> >>> > > >>>
> >>> > > >>
> >>> > > >>      [[alternative HTML version deleted]]
> >>> > > >>
> >>> > > >> ______________________________________________
> >>> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > > >> PLEASE do read the posting guide http://www.R-project.org/
> >>> > > posting-guide.html
> >>> > > >> and provide commented, minimal, self-contained, reproducible
> code.
> >>> > > >
> >>> > > > David Winsemius
> >>> > > > Alameda, CA, USA
> >>> > > >
> >>> > > > ______________________________________________
> >>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> >>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > > > PLEASE do read the posting guide http://www.R-project.org/
> >>> > > posting-guide.html
> >>> > > > and provide commented, minimal, self-contained, reproducible
> code.
> >>> > >
> >>> > > David Winsemius
> >>> > > Alameda, CA, USA
> >>> > >
> >>> > >
> >>> >
> >>> >       [[alternative HTML version deleted]]
> >>> >
> >>> > ______________________________________________
> >>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> > PLEASE do read the posting guide http://www.R-project.org/posti
> >>> ng-guide.html
> >>> > and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ash369ster at gmail.com  Sun Dec  4 11:08:27 2016
From: ash369ster at gmail.com (Ashwini Patil)
Date: Sun, 4 Dec 2016 05:08:27 -0500
Subject: [R] R for skip to the next row if condition met and then another
 condition to check
Message-ID: <CAEK8ckAuswjBYUCzpXKwyCR+BJg_z2Uxx721+=6ceObv3PDchQ@mail.gmail.com>

I have a dataset with many rows and columns. Below is a sample:

V7  V8  V90   1   0-1  1   -1-1  1   -1-1  0   -1-1  0   -1-1  0
-1-1  0   -1-1  1   -10   1   -10   1   -1-1  0   00   0   00   0   00
  0   00   0   00   -1  00   -1  -10   0   00   1   00   0   0

This data is saved in a matrix trboot3 What I want to do is create a loop
whereby two conditions are checked and data is altered.

   1. If there is a zero, skip to the next row.
   2. If there is same number one below another in a row, keep the first
   number and change the rest to zero.

Here is my code for the above loop:

trboot4<-trboot3
valboot<-length(trboot3[,1])for (k in 1:length(trboot3[1,])){
  for (i in 2:valboot-1){
    if (trboot3[k,i]==0) {i<-i+1}
    else{
      if(trboot3[k,i] == trboot3[k,i+1]){
        for (j in i+1:valboot){ if(trboot3[k,j] ==
trboot3[k,i]){trboot4[k,j]<-0}else{break}
          if(j==valboot){break}
        }
      }
    }
  }}

I want to save the new matrix in trboot4

basically the above sample should become:

V7  V8  V90   1   0-1  0   -10   0   00   0   00   0   00   0   00   0
  00   1   00   0   00   0   0-1  0   00   0   00   0   00   0   00
0   00   -1  00   0   -10   0   00   1   00   0   0


Thank you!

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Dec  4 12:59:47 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 04 Dec 2016 11:59:47 +0000
Subject: [R] R for skip to the next row if condition met and then
 another condition to check
In-Reply-To: <CAEK8ckAuswjBYUCzpXKwyCR+BJg_z2Uxx721+=6ceObv3PDchQ@mail.gmail.com>
References: <CAEK8ckAuswjBYUCzpXKwyCR+BJg_z2Uxx721+=6ceObv3PDchQ@mail.gmail.com>
Message-ID: <58440533.70500@sapo.pt>

Hello,

Please post in plain text not in HTML, like the posting guide asks you to.
To give a data example use ?dput, like this:

dput(head(trboot3, 20))  # paste the output of this in your mail

If you have a sample of trboot4 please also use dput to post it.

Finally, I don't understand your second condition, what does "same 
number one below another in a row" mean? Is it "below" (different rows) 
or in the same row? And you say to keep the first and change the rest. 
Once again, is it the rest of the row?

Anyway I believe I have already found a problem in your code. In

for (i in 2:valboot-1)

you should try to see what exactly is 2:valboot-1. [Tip: it starts with a 1]
Maybe you meant 2:(valboot-1).

Rui Barradas

Em 04-12-2016 10:08, Ashwini Patil escreveu:
> I have a dataset with many rows and columns. Below is a sample:
>
> V7  V8  V90   1   0-1  1   -1-1  1   -1-1  0   -1-1  0   -1-1  0
> -1-1  0   -1-1  1   -10   1   -10   1   -1-1  0   00   0   00   0   00
>    0   00   0   00   -1  00   -1  -10   0   00   1   00   0   0
>
> This data is saved in a matrix trboot3 What I want to do is create a loop
> whereby two conditions are checked and data is altered.
>
>     1. If there is a zero, skip to the next row.
>     2. If there is same number one below another in a row, keep the first
>     number and change the rest to zero.
>
> Here is my code for the above loop:
>
> trboot4<-trboot3
> valboot<-length(trboot3[,1])for (k in 1:length(trboot3[1,])){
>    for (i in 2:valboot-1){
>      if (trboot3[k,i]==0) {i<-i+1}
>      else{
>        if(trboot3[k,i] == trboot3[k,i+1]){
>          for (j in i+1:valboot){ if(trboot3[k,j] ==
> trboot3[k,i]){trboot4[k,j]<-0}else{break}
>            if(j==valboot){break}
>          }
>        }
>      }
>    }}
>
> I want to save the new matrix in trboot4
>
> basically the above sample should become:
>
> V7  V8  V90   1   0-1  0   -10   0   00   0   00   0   00   0   00   0
>    00   1   00   0   00   0   0-1  0   00   0   00   0   00   0   00
> 0   00   -1  00   0   -10   0   00   1   00   0   0
>
>
> Thank you!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Sun Dec  4 06:29:29 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 4 Dec 2016 00:29:29 -0500
Subject: [R] Interpreting summary.lm for a 2 factor anova
In-Reply-To: <CAC8=1eo_Vyyq7VyTCeKHJ_5V0tHkMpjiNj1PXcQT0FTTZgpP2g@mail.gmail.com>
References: <CAC8=1eo3AGgKj7SqoGUR4oLPFOuBn5jF0rXtkQh3vGe+M-Xq8Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C5048716@SRVEXCHMBX.precheza.cz>
	<CAC8=1eroKSZ+qTtG9FbFGeg2i4FbnFbGvF7=kztj9UaJHVZpdA@mail.gmail.com>
	<7708FF58-7572-4A3A-8931-A062F173E30E@comcast.net>
	<F0C2CCEC-C348-4893-81C0-E1D7DF9540DE@comcast.net>
	<CAC8=1eoaOUNcEFF2mx=sAh40GkTzEH3ZFH1cCK5MHdsMH4hb_w@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A4468@FHSDB2D11-2.csu.mcmaster.ca>
	<CAC8=1erwrTRyePhd3Jr1NrfTtucryaLKp-T_ADGhtecYC=iU8g@mail.gmail.com>
	<CAC8=1eo_Vyyq7VyTCeKHJ_5V0tHkMpjiNj1PXcQT0FTTZgpP2g@mail.gmail.com>
Message-ID: <CAGx1TMAAakFz9UhQV-rVC2W8vfh_gGPLget==5b5prjo3aDM5A@mail.gmail.com>

As Petr Pikal mentioned, the difficulty in interpretation is entirely due
to the set of contrasts you chose.The default treatment contrasts are
not orthogonal and are therefore the most difficult to interpret.
The note in ?aov warns of this difficulty.

sum contrasts will give you numbers that are easiest to interpret.


options(contrasts = c("contr.sum", "contr.poly"))
warpbreakssum.aov <- aov(breaks ~ wool * tension, data = warpbreaks)
coef(warpbreakssum.aov)
model.tables(warpbreakstreatment.aov, type="effects")
model.tables(warpbreakstreatment.aov, type="means")


John Fox showed the algebra using the default treatment contrasts

For full understanding you will need to read  in a text more about
sets of linear contrasts and their algebra.
I recommend Section 10.3 in mine, of course.

Statistical Analysis and Data Display:
An Intermediate Course with Examples in R
Heiberger, Richard M., Holland, Burt

http://www.springer.com/us/book/9781493921218

On Sat, Dec 3, 2016 at 11:46 PM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
> On Sun, Dec 4, 2016 at 10:03 AM, Ashim Kapoor <ashimkapoor at gmail.com> wrote:
>
>> Dear Sir,
>>
>> Many thanks for the explanation. Prior to your email (with some help from
>> a friend of mine) I was able to figure this one out. If we look at the
>> model : -
>>
>> y = intercept + B1.woolB + B2. tensionM + B3.tensionH + B4. woolB.TensionM
>> + B5.woolB.TensionH + error
>>
>> Here woolB, tensionM, tensionH are the dummy indicator variables similar
>> to how you have defined them.
>>
>> Now suppose we consider y1,..,yn, all in group A.L (say).
>>
>> Then y1 + ... + yn = intercept => average(y1,...,yn) = intercept + 0 + 0 +
>> 0 + 0 + 0.
>>
>> This should be : y1 + ... yn = n . intercept
>
> What was confusing me was how to compute the cell mean in woolB,tensionH
>> cell.
>>
>> If we have y_1,...,y_n all in group B.H then :-
>>
>> y_1+ ... + y_n = intercept + B1 + 0 + B3 + 0 +  B5
>>
>> This should be : y_1 + ... +y_n = n( intercept + B1 + 0 + B3 + 0 +  B5 )
>
>
>> Therefore average of group B.H = intercept + B1 + B3 + B5
>>
>> Many thanks and Best Regards,
>> Ashim
>>
>>
>>
>> On Sat, Dec 3, 2016 at 7:15 PM, Fox, John <jfox at mcmaster.ca> wrote:
>>
>>> Dear Ashim,
>>>
>>> Sorry to chime in late, and my apologies if someone has already pointed
>>> this out, but here's the relationship between the cell means and the model
>>> coefficients, using the row-basis of the model matrix:
>>>
>>> -------------------------- snip ------------------------
>>>
>>> > means <- with( warpbreaks, tapply( breaks, interaction(wool, tension),
>>> mean ) )
>>> > x.A <- rep(c(0, 1), 3)
>>> > x.B1 <- rep(c(0, 1, 0), each=2)
>>> > x.B2 <- rep(c(0, 0, 1), each=2)
>>> > x.AB1 <- x.A*x.B1
>>> > x.AB2 <- x.A*x.B2
>>> > X.basis <- cbind(1, x.A, x.B1, x.B2, x.AB1, x.AB2)
>>> > X.basis
>>>        x.A x.B1 x.B2 x.AB1 x.AB2
>>> [1,] 1   0    0    0     0     0
>>> [2,] 1   1    0    0     0     0
>>> [3,] 1   0    1    0     0     0
>>> [4,] 1   1    1    0     1     0
>>> [5,] 1   0    0    1     0     0
>>> [6,] 1   1    0    1     0     1
>>> > solve(X.basis, means)
>>>                 x.A      x.B1      x.B2     x.AB1     x.AB2
>>>  44.55556 -16.33333 -20.55556 -20.00000  21.11111  10.55556
>>> > coef(aov(breaks ~ wool * tension, data = warpbreaks))
>>>    (Intercept)          woolB       tensionM       tensionH woolB:tensionM
>>>       44.55556      -16.33333      -20.55556      -20.00000       21.11111
>>> woolB:tensionH
>>>       10.55556
>>>
>>> -------------------------- snip ------------------------
>>>
>>> I hope this helps,
>>>  John
>>>
>>> -----------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario
>>> Canada L8S 4M4
>>> Web: socserv.mcmaster.ca/jfox
>>>
>>>
>>>
>>> > -----Original Message-----
>>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ashim
>>> Kapoor
>>> > Sent: December 3, 2016 12:19 AM
>>> > To: David Winsemius <dwinsemius at comcast.net>
>>> > Cc: r-help at r-project.org
>>> > Subject: Re: [R] Interpreting summary.lm for a 2 factor anova
>>> >
>>> > Please allow me to rephrase myquery.
>>> >
>>> > > model.tables(model,"m")
>>> > Tables of means
>>> > Grand mean
>>> >
>>> > 28.14815
>>> >
>>> >  wool
>>> > wool
>>> >      A      B
>>> > 31.037 25.259
>>> >
>>> >  tension
>>> > tension
>>> >     L     M     H
>>> > 36.39 26.39 21.67
>>> >
>>> >  wool:tension
>>> >     tension
>>> > wool L     M     H
>>> >    A 44.56 24.00 24.56
>>> >    B 28.22 28.78 18.78
>>> > >
>>> >
>>> >
>>> > The above is the same as :
>>> >
>>> > with( warpbreaks, tapply( breaks, interaction(wool, tension), mean ) )
>>> >      A.L      B.L      A.M      B.M      A.H      B.H
>>> > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
>>> >
>>> > For reference:
>>> >
>>> > > model <- aov(breaks ~ wool * tension, data = warpbreaks)
>>> > > summary.lm(model)
>>> >
>>> > Call:
>>> > aov(formula = breaks ~ wool * tension, data = warpbreaks)
>>> >
>>> > Residuals:
>>> >      Min       1Q   Median       3Q      Max
>>> > -19.5556  -6.8889  -0.6667   7.1944  25.4444
>>> >
>>> > Coefficients:
>>> >                Estimate Std. Error t value Pr(>|t|)
>>> > (Intercept)      44.556      3.647  12.218 2.43e-16 ***
>>> > woolB           -16.333      5.157  -3.167 0.002677 **
>>> > tensionM        -20.556      5.157  -3.986 0.000228 ***
>>> > tensionH        -20.000      5.157  -3.878 0.000320 ***
>>> > woolB:tensionM   21.111      7.294   2.895 0.005698 **
>>> > woolB:tensionH   10.556      7.294   1.447 0.154327
>>> > ---
>>> > Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> >
>>> > Residual standard error: 10.94 on 48 degrees of freedom
>>> > Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
>>> > F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>>> >
>>> >
>>> > Now I'll explain what is confusing me in the output of summary.lm.
>>> >
>>> > Coeff of Intercept = 44.556  = cell mean for A.L. This is the base.
>>> >
>>> > Coeff of woolB:L = -16.333 = 28.22222 - 44.556. This is the difference
>>> of this
>>> > cell mean(B:L) from the base.
>>> >
>>> > Coeff of woolA:tensionM = -20.556  = 24.000- 44.556. This is the
>>> difference of
>>> > this cell mean (A:M)  from the base.
>>> >
>>> > Coeff of woolA:tensionH = -20.000  = 24.55556 - 44.556. This is the
>>> difference
>>> > of this cell mean(A:H) from the base.
>>> >
>>> > This is where it stops being the difference from the base.
>>> >
>>> > Coeff of woolB:tensionM = 21.111 should turn out to be 28.77778 -
>>> 44.556 but
>>> > this is -15.77822
>>> >
>>> > Coeff of woolB:tensionH = 10.556 should turn out to be  18.77778 -
>>> 44.556 but
>>> > this is -25.77822
>>> >
>>> > In the above 2 cases, we can't say that the coefficient = cell mean -
>>> base case.
>>> > Can you tell me what should be the statement to be made ?
>>> >
>>> >
>>> > Best Regards,
>>> > Ashim
>>> >
>>> > PS : My apologies for emailing my query to this list. Can you tell me
>>> the names
>>> > of a few (active) statistics help list ?
>>> >
>>> > On Sat, Dec 3, 2016 at 1:33 AM, David Winsemius <dwinsemius at comcast.net
>>> >
>>> > wrote:
>>> >
>>> > >
>>> > > > On Dec 2, 2016, at 9:09 AM, David Winsemius <dwinsemius at comcast.net
>>> >
>>> > > wrote:
>>> > > >
>>> > > >>
>>> > > >> On Dec 2, 2016, at 6:16 AM, Ashim Kapoor <ashimkapoor at gmail.com>
>>> > wrote:
>>> > > >>
>>> > > >> Dear Pikal,
>>> > > >>
>>> > > >> All levels except the interactions are compared to the Intercept.
>>> > > >> I'm a little confused as to what's going on in interaction terms
>>> > > >> eg. the cell wool B : tension M. It's mean is :
>>> > > >> 28.78 and 28.78 - 44.56 = -15.78 != 21.111.
>>> > > >>
>>> > > >> It's something like 44.56 (intercept) -16.333 (wool B) -.20.556
>>> > > >> (tension
>>> > > >> M)  + 21.111 (woolB:tensionM) = 28.782.
>>> > > >>
>>> > > >> I don't know how to sum up the above line in terms of differences
>>> > > >> succinctly.
>>> > > >
>>> > > > The aov estimate will not exactly equal the observed mean (this is
>>> > > _statistics_ after all). You should be comparing the mean of that cell
>>> > > to the estimate:
>>> > > >
>>> > > > 44.556 + (-16.33) +(-20.556) + (21.11)
>>> > >
>>> > > A respected participant advised me to look at this more closely. In
>>> > > this case (and I think in most such cases)  where there are the same
>>> > > number of parameters as there are means, the model is "saturated" and
>>> > > there is no
>>> > > difference:
>>> > >
>>> > >  with( warpbreaks, tapply( breaks, interaction(wool, tension), mean )
>>> )
>>> > >      A.L      B.L      A.M      B.M      A.H      B.H
>>> > > 44.55556 28.22222 24.00000 28.77778 24.55556 18.77778
>>> > >
>>> > > So the B:M estimate is identical up to rounding with the observed
>>> mean:
>>> > >
>>> > >  44.556 + (-16.33) +(-20.556) + (21.11) [1] 28.78
>>> > >
>>> > >
>>> > >
>>> > > >
>>> > > > The difference between the observed mean and the estimated mean is
>>> > known
>>> > > as a 'residual'
>>> > >
>>> > > I've also been privately but gently chided for this misstatement.
>>> > > Residuals are the difference between data and estimates.
>>> > >
>>> > > > and the squared sum of the all residuals is what this being
>>> minimized
>>> > > ... over all the cells including the one implicitly associated with
>>> the
>>> > > Intercept.
>>> > > >
>>> > > > This isn't really on-topic for Rhelp since you are not having
>>> difficulty
>>> > > in getting the R program to perform its duties, but are rather in
>>> need of
>>> > > statistical education. That not what this mailing list is set up for.
>>> > > >
>>> > > > --
>>> > > > David.
>>> > > >
>>> > > >>
>>> > > >>>
>>> > > >>>> -----Original Message-----
>>> > > >>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>>> Ashim
>>> > > >>>> Kapoor
>>> > > >>>> Sent: Thursday, December 1, 2016 2:48 PM
>>> > > >>>> To: r-help at r-project.org
>>> > > >>>> Subject: [R] Interpreting summary.lm for a 2 factor anova
>>> > > >>>>
>>> > > >>>> Dear all,
>>> > > >>>>
>>> > > >>>> Here is a small example : -
>>> > > >>>>
>>> > > >>>>> model <- aov(breaks ~ wool * tension, data = warpbreaks)
>>> > > >>>>> summary.lm(model)
>>> > > >>>>
>>> > > >>>> Call:
>>> > > >>>> aov(formula = breaks ~ wool * tension, data = warpbreaks)
>>> > > >>>>
>>> > > >>>> Residuals:
>>> > > >>>>    Min       1Q   Median       3Q      Max
>>> > > >>>> -19.5556  -6.8889  -0.6667   7.1944  25.4444
>>> > > >>>>
>>> > > >>>> Coefficients:
>>> > > >>>>              Estimate Std. Error t value Pr(>|t|)
>>> > > >>>> (Intercept)      44.556      3.647  12.218 2.43e-16 ***
>>> > > >>>> woolB           -16.333      5.157  -3.167 0.002677 **
>>> > > >>>> tensionM        -20.556      5.157  -3.986 0.000228 ***
>>> > > >>>> tensionH        -20.000      5.157  -3.878 0.000320 ***
>>> > > >>>> woolB:tensionM   21.111      7.294   2.895 0.005698 **
>>> > > >>>> woolB:tensionH   10.556      7.294   1.447 0.154327
>>> > > >>>> ---
>>> > > >>>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> > > >>>>
>>> > > >>>> Residual standard error: 10.94 on 48 degrees of freedom
>>> > > >>>> Multiple R-squared:  0.3778,    Adjusted R-squared:  0.3129
>>> > > >>>> F-statistic: 5.828 on 5 and 48 DF,  p-value: 0.0002772
>>> > > >>>>
>>> > > >>>>> model.tables(model,"e")
>>> > > >>>> Tables of effects
>>> > > >>>>
>>> > > >>>> wool
>>> > > >>>> wool
>>> > > >>>>     A       B
>>> > > >>>> 2.8889 -2.8889
>>> > > >>>>
>>> > > >>>> tension
>>> > > >>>> tension
>>> > > >>>>    L      M      H
>>> > > >>>> 8.241 -1.759 -6.481
>>> > > >>>>
>>> > > >>>> wool:tension
>>> > > >>>>   tension
>>> > > >>>> wool L      M      H
>>> > > >>>>  A  5.278 -5.278  0.000
>>> > > >>>>  B -5.278  5.278  0.000
>>> > > >>>>
>>> > > >>>>
>>> > > >>>>> model.tables(model,"m")
>>> > > >>>> Tables of means
>>> > > >>>> Grand mean
>>> > > >>>>
>>> > > >>>> 28.14815
>>> > > >>>>
>>> > > >>>> wool
>>> > > >>>> wool
>>> > > >>>>    A      B
>>> > > >>>> 31.037 25.259
>>> > > >>>>
>>> > > >>>> tension
>>> > > >>>> tension
>>> > > >>>>   L     M     H
>>> > > >>>> 36.39 26.39 21.67
>>> > > >>>>
>>> > > >>>> wool:tension
>>> > > >>>>   tension
>>> > > >>>> wool L     M     H
>>> > > >>>>  A 44.56 24.00 24.56
>>> > > >>>>  B 28.22 28.78 18.78
>>> > > >>>>>
>>> > > >>>>
>>> > > >>>> I don't follow the output of summary.lm. I understand the output
>>> of
>>> > > >>>> model.tables for effects and means. For instance what does 44.556
>>> > > >>>> represent ? Is it the grand average ? The grand mean is
>>> 28.14815. Can
>>> > > >>>> someone help me understand the output of summary.lm ?
>>> > > >>>>
>>> > > >>>> Best Regards,
>>> > > >>>> Ashim
>>> > > >>>>
>>> > > >>>>     [[alternative HTML version deleted]]
>>> > > >>>>
>>> > > >>>> ______________________________________________
>>> > > >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>> > > >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > >>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-
>>> > > >>>> guide.html
>>> > > >>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>> > > >>>
>>> > > >>> ________________________________
>>> > > >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn?
>>> a jsou
>>> > > >>> ur?eny pouze jeho adres?t?m.
>>> > > >>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>>> > > >>> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>>> jeho
>>> > > kopie
>>> > > >>> vyma?te ze sv?ho syst?mu.
>>> > > >>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni
>>> tento
>>> > > email
>>> > > >>> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>>> > > >>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>>> > > modifikacemi
>>> > > >>> ?i zpo?d?n?m p?enosu e-mailu.
>>> > > >>>
>>> > > >>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>>> > > >>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o
>>> uzav?en?
>>> > > >>> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>>> > > >>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>>> > > p?ijmout;
>>> > > >>> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>>> strany
>>> > > >>> p??jemce s dodatkem ?i odchylkou.
>>> > > >>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>>> > > >>> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>>> > > >>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>>> > > >>> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl
>>> p?semn?
>>> > > zmocn?n
>>> > > >>> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>>> adres?tovi
>>> > > tohoto
>>> > > >>> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo
>>> jejich
>>> > > >>> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>> > > >>>
>>> > > >>> This e-mail and any documents attached to it may be confidential
>>> and
>>> > > are
>>> > > >>> intended only for its intended recipients.
>>> > > >>> If you received this e-mail by mistake, please immediately inform
>>> its
>>> > > >>> sender. Delete the contents of this e-mail with all attachments
>>> and its
>>> > > >>> copies from your system.
>>> > > >>> If you are not the intended recipient of this e-mail, you are not
>>> > > >>> authorized to use, disseminate, copy or disclose this e-mail in
>>> any
>>> > > manner.
>>> > > >>> The sender of this e-mail shall not be liable for any possible
>>> damage
>>> > > >>> caused by modifications of the e-mail or by delay with transfer
>>> of the
>>> > > >>> email.
>>> > > >>>
>>> > > >>> In case that this e-mail forms part of business dealings:
>>> > > >>> - the sender reserves the right to end negotiations about entering
>>> > > into a
>>> > > >>> contract in any time, for any reason, and without stating any
>>> > > reasoning.
>>> > > >>> - if the e-mail contains an offer, the recipient is entitled to
>>> > > >>> immediately accept such offer; The sender of this e-mail (offer)
>>> > > excludes
>>> > > >>> any acceptance of the offer on the part of the recipient
>>> containing any
>>> > > >>> amendment or variation.
>>> > > >>> - the sender insists on that the respective contract is concluded
>>> only
>>> > > >>> upon an express mutual agreement on all its aspects.
>>> > > >>> - the sender of this e-mail informs that he/she is not authorized
>>> to
>>> > > enter
>>> > > >>> into any contracts on behalf of the company except for cases in
>>> which
>>> > > >>> he/she is expressly authorized to do so in writing, and such
>>> > > authorization
>>> > > >>> or power of attorney is submitted to the recipient or the person
>>> > > >>> represented by the recipient, or the existence of such
>>> authorization is
>>> > > >>> known to the recipient of the person represented by the recipient.
>>> > > >>>
>>> > > >>
>>> > > >>      [[alternative HTML version deleted]]
>>> > > >>
>>> > > >> ______________________________________________
>>> > > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > >> https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > >> PLEASE do read the posting guide http://www.R-project.org/
>>> > > posting-guide.html
>>> > > >> and provide commented, minimal, self-contained, reproducible code.
>>> > > >
>>> > > > David Winsemius
>>> > > > Alameda, CA, USA
>>> > > >
>>> > > > ______________________________________________
>>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > > PLEASE do read the posting guide http://www.R-project.org/
>>> > > posting-guide.html
>>> > > > and provide commented, minimal, self-contained, reproducible code.
>>> > >
>>> > > David Winsemius
>>> > > Alameda, CA, USA
>>> > >
>>> > >
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maximilian.eckert03 at gmail.com  Sun Dec  4 13:43:47 2016
From: maximilian.eckert03 at gmail.com (Maximilian Eckert)
Date: Sun, 4 Dec 2016 13:43:47 +0100
Subject: [R] Fill an empty matrix with a function
Message-ID: <001801d24e2c$11d00a20$35701e60$@gmail.com>

Dear Sir oder Madam,

 

I am currently writing my master thesis and I am struggling with R:

 

I have created an empty matrix (M) which has months as row.names and stocks
as column.names and now I want to fill this matrix with values from another
matrix (T). The matrix T has also months as row.names and stocks as
column.names however here I have several  values for each month. Now I want
to count the values which have values bigger or equal to zero (plus 1) and
add them to my matrix M:

 

If I do it manually it would look like: 

 

M[,1] <- t(array((colSums(T[1:22,] > 0))+1))  #here in Matrix T I have 22
values for the month January 

M[,2] <- t(array((colSums(T[23:53,] > 0))+1)) #here in Matrix T I have 30
values for the monh February 

 

Is there a way to do this without a loop as I have a very large data set? I
tried to merge it however it did not work:

 

merge.default(as.data.frame(M), as.data.frame(T), by = "row.names",
function(x){colSums(T[,]>0)+1})

 

Thank you very much,

 

Max 


	[[alternative HTML version deleted]]


From rudrty at gmail.com  Sat Dec  3 22:59:49 2016
From: rudrty at gmail.com (Rudransh Tyagi)
Date: Sun, 4 Dec 2016 03:29:49 +0530
Subject: [R] Contribute to R-Project
Message-ID: <CACOH3c8Vw=k=TzPp9HwcnGGryMBEb_kXFRkJJjUNcLuA0iJXaQ@mail.gmail.com>

Hey all,
I am currently a Computer Science undergraduate. Getting straight to point,
I am proficient with C/C++ , have worked with python and R for data
analysis and data visualisation and I know fortran in bits.
I want to start contributing towards your project to gain some experience
in open-source development and would love to participate in the GSOC
program later if you like my work.
I am familiar with version control too but i am just new to open-source.
Can someone please tell me how to get started or provide some links?
I have already gone through your site and will continue browsing meanwhile
for more information.
But it'll be really helpful if someone can guide me a bit.

Thanks in advance

	[[alternative HTML version deleted]]


From profjcnash at gmail.com  Sun Dec  4 15:03:12 2016
From: profjcnash at gmail.com (J C Nash)
Date: Sun, 4 Dec 2016 09:03:12 -0500
Subject: [R] Contribute to R-Project
In-Reply-To: <CACOH3c8Vw=k=TzPp9HwcnGGryMBEb_kXFRkJJjUNcLuA0iJXaQ@mail.gmail.com>
References: <CACOH3c8Vw=k=TzPp9HwcnGGryMBEb_kXFRkJJjUNcLuA0iJXaQ@mail.gmail.com>
Message-ID: <ccb576dc-011f-c9e5-324d-acf8e7a8fee6@gmail.com>

Strongly suggest you join the gsoc-r list.

https://groups.google.com/d/forum/gsoc-r

Make sure you include a short indication of your expertise. We don't approve applications that are empty as there was
some evidence of attempts to spam the list for ads etc.

JN

On 16-12-03 04:59 PM, Rudransh Tyagi wrote:
> Hey all,
> I am currently a Computer Science undergraduate. Getting straight to point,
> I am proficient with C/C++ , have worked with python and R for data
> analysis and data visualisation and I know fortran in bits.
> I want to start contributing towards your project to gain some experience
> in open-source development and would love to participate in the GSOC
> program later if you like my work.
> I am familiar with version control too but i am just new to open-source.
> Can someone please tell me how to get started or provide some links?
> I have already gone through your site and will continue browsing meanwhile
> for more information.
> But it'll be really helpful if someone can guide me a bit.
> 
> Thanks in advance
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sun Dec  4 17:06:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 4 Dec 2016 08:06:26 -0800
Subject: [R] Fill an empty matrix with a function
In-Reply-To: <001801d24e2c$11d00a20$35701e60$@gmail.com>
References: <001801d24e2c$11d00a20$35701e60$@gmail.com>
Message-ID: <F89B7F93-B948-429F-8C84-D922C764AD44@comcast.net>


> On Dec 4, 2016, at 4:43 AM, Maximilian Eckert <maximilian.eckert03 at gmail.com> wrote:
> 
> Dear Sir oder Madam,
> 
> 
> 
> I am currently writing my master thesis and I am struggling with R:
> 
> 
> 
> I have created an empty matrix (M) which has months as row.names and stocks
> as column.names and now I want to fill this matrix with values from another
> matrix (T). The matrix T has also months as row.names and stocks as
> column.names however here I have several  values for each month. Now I want
> to count the values which have values bigger or equal to zero (plus 1) and
> add them to my matrix M:
> 
> 
> 
> If I do it manually it would look like: 
> 
> 
> 
> M[,1] <- t(array((colSums(T[1:22,] > 0))+1))  #here in Matrix T I have 22
> values for the month January 

22 rows

> 
> M[,2] <- t(array((colSums(T[23:53,] > 0))+1)) #here in Matrix T I have 30
> values for the monh February 
> 

31 rows were indexed.

How are these rows labelled? What does rownames(M) produce?


> 
> 
> Is there a way to do this without a loop as I have a very large data set? I
> tried to merge it however it did not work:
> 
> 
> 
> merge.default(as.data.frame(M), as.data.frame(T), by = "row.names",
> function(x){colSums(T[,]>0)+1})
> 
> 

If you want code, then you need to provide enough (accurate) information to support such an effort. If this data is n a matrix then duplicate rownames are allow, but if it is a dataframe or if coerced to a data.frame than duplicates are not allowed.

> 
> Thank you very much,
> 
> 
> 
> Max 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From oriolebaltimore at gmail.com  Mon Dec  5 04:52:33 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Sun, 4 Dec 2016 22:52:33 -0500
Subject: [R] Clustering methods for data that has bimodal distribution
Message-ID: <CAL2fYnM8aj_oZqvMOQPCWuR6c-dLZ-hZhxkr8Y4iC9OPJ_rLng@mail.gmail.com>

Dear group,
pardon me for a naive question. I have data matrix (11K rows , 4K columns).
The data range is between -1 to 1. Not strictly integers, but real
numbers with at least place values in millionths.

The data distribution is peculiar (if I do plot(density(myMatrix)),  I
get nice bimodal curve (nice standard distribution between -1 and 0
and another curve between 0 and 1) .

I am interested in clustering the data (using conesnsus clustering
(that uses K-means)).

My question are:

1. If my data is range is between -1  and 1. Is K-means appropriate
method. considering if the data might have ties.

2. Although K-means is non-parametric, would a bimodal distributed
data be okay as input to K-means.

I appreciate any suggestion.
Thanks
Adrian.


From mlathouri at yahoo.gr  Mon Dec  5 13:25:51 2016
From: mlathouri at yahoo.gr (Maria Lathouri)
Date: Mon, 5 Dec 2016 12:25:51 +0000 (UTC)
Subject: [R] scatter plot of numerical variables against different sample ids
References: <1198746852.10979303.1480940751156.ref@mail.yahoo.com>
Message-ID: <1198746852.10979303.1480940751156@mail.yahoo.com>

Dear all
I know that my question is very simple but although I tried to find an answer online, I couldn't and I am stuck.?
I have a dataset of three numerical variables measured in different samples ID. Something like this:
Sample ? ? ? ?Cu ? ? ? ?Zn ? ? ? ?MnM1 ? ? ? ? ? ? ? 1 ? ? ? ? ?5 ? ? ? ? ?10M2 ? ? ? ? ? ? ? 2.5 ? ? ? 11 ? ? ? ? ?8M3 ? ? ? ? ? ? ?1.15 ? ? ?11 ? ? ? ? 12 ?M4 ? ? ? ? ? ? ? ?2 ? ? ? ? 4 ? ? ? ? ?30M5 ? ? ? ? ? ? ? ?8 ? ? ? ?15 ? ? ? ? 35
I would like to plot these variables (Cu, Zn, Mn) (in y-axis) against the Sample ID (in x-axis) in a scatter plot with lines as I want to see how they change in the samples.
I tried using the command>plot(Sample, Cu, type="l", lty=1, col="red")
but I wouldn't get a line. Actually, I would get some small horizontal lines in each point. I tried to use type="p" but I would get the same thing.?
I would very much appreciate if you could help me on that. Apparently, I am missing something.?
Thank you in advance.?
Kind regards,Maria
	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Dec  5 13:27:20 2016
From: jholtman at gmail.com (jim holtman)
Date: Mon, 5 Dec 2016 07:27:20 -0500
Subject: [R] Question about proxy setting of R
In-Reply-To: <590798.91297.qm@web102317.mail.kks.yahoo.co.jp>
References: <669742.77077.qm@web102318.mail.kks.yahoo.co.jp>
	<CAAxdm-7jKMHe+MEr=hQnzyvn3xAq5Y+XAPCiiTMZraJvutvAPQ@mail.gmail.com>
	<590798.91297.qm@web102317.mail.kks.yahoo.co.jp>
Message-ID: <CAAxdm-5C_bfe9bdn0ZK9J34WKJ0kG+9E5Oh6hN_XSstV5FER_A@mail.gmail.com>

You will probably have to check with your network folks to see what is
possible on your system.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Dec 5, 2016 at 6:33 AM, <qwertyui_period at yahoo.co.jp> wrote:

> Dear Jim,
>
> Thanks to your advice, "Proxy Authentification" window showed up, however,
> I couldn't access to the internet. Error messages are as below.
>
> ------------------------------ ------------------------------ -------
> > update.packages(ask='graphics',checkBuilt=TRUE)
> --- Please select a CRAN mirror for use in this session ---
> Warning: failed to download mirrors file (scheme not supported in URL
> 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
> 'C:/PROGRA~1/R/R-33~1.2/doc/CRAN_mirrors.csv'
> Warning: unable to access index for repository
> https://cran.ism.ac.jp/src/contrib:
>   scheme not supported in URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES'
>
> Proxy authentication failed:
>         please re-enter the credentials or hit Cancel
> ------------------------------ ------------------------------ -------
>
> I assume the proxy server is only available for "http", not "https".
> What should I do ?
>
> J J
>
>
> ----- Original Message -----
> *From:* jim holtman <jholtman at gmail.com>
> *To:* qwertyui_period at yahoo.co.jp
> *Date:* 2016/12/2, Fri 09:13
> *Subject:* Re: [R] Question about proxy setting of R
>
> Try this option:
>
>  options(download.file.method = "internal")
>
>
>
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Wed, Nov 30, 2016 at 10:37 PM, <qwertyui_period at yahoo.co.jp> wrote:
>
> Hello,
>
> I use R 3.0.2 on Win 7 through proxy server using ".Rprofile" in home
> directory that includes "Sys.setenv(http_proxy=proxy_ server:port)".
> There has been no problem to access the internet for some years.
> In this situation, I installed R 3.3.1 and then entered "update.packages
> ()", however, "Proxy Authentification" window didn't show up and
> failed to access the internet. Error messages are as below.
>
> ------------------------------ ------------------------------ -------
> > update.packages(ask='graphics' ,checkBuilt=TRUE)
> --- Please select a CRAN mirror for use in this session ---
> Warning: failed to download mirrors file (cannot open URL
> 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
> 'C:/PROGRA~1/R/R-33~1.2/doc/ CRAN_mirrors.csv'
> Warning: unable to access index for repository
> https://cran.ism.ac.jp/src/contrib:
>   cannot open URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES'
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>   cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES
> '
> Warning message:
> In download.file(url, destfile = f, quiet = TRUE) :
>   cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv': HTTP
> status was '407 Proxy Authentication Required'
>
> ------------------------------ ------------------------------ -------
>
> Strange to say, R 3.0.2 is able to access to the internet, and R 3.3.1
> shows collect proxy setting in ".Rprofile"  by "Sys.getenv("http_proxy")"
> From internet information, I added "http_proxy_user=ask" to ".Rprofile", or
> " --internet2" to the desktop icon of R 3.3.1, ending up in the same
> result.
>
> Please show me the way of proxy setting of R 3.3.1.
>
> ______________________________ ________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.r-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From calandra at rgzm.de  Mon Dec  5 13:48:00 2016
From: calandra at rgzm.de (Ivan Calandra)
Date: Mon, 5 Dec 2016 13:48:00 +0100
Subject: [R] scatter plot of numerical variables against different
 sample ids
In-Reply-To: <1198746852.10979303.1480940751156@mail.yahoo.com>
References: <1198746852.10979303.1480940751156.ref@mail.yahoo.com>
	<1198746852.10979303.1480940751156@mail.yahoo.com>
Message-ID: <a6c9cc81-c717-cf36-2733-2267b354fe13@rgzm.de>

Hi Maria,

What happens is that R plots with boxplots (explaining the horizontal 
lines, i.e. boxes with n=1) when the x-variable is a factor.
What you can do is transform your Sample column into numeric and then 
plot it, with some adjustment of axis labels.

For example:
datf <- data.frame(Sample=c("M1","M2","M3","M4","M5"), 
Cu=c(1,2.5,1.15,2,8), Zn=c(5,11,11,4,15), Mn=c(10,8,12,30,35))
datf$Sample2 <- as.numeric(datf$Sample)
with(datf, plot(Sample2, Cu, type="l", lty=1, col="red", xaxt="n"))
axis(1, at=datf$Sample2, labels=datf$Sample)

It might not be the easiest/best approach though... Someone here might 
have a better idea.

HTH,
Ivan

--
Ivan Calandra, PhD
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
calandra at rgzm.de
+49 (0) 2631 9772-287
--
https://www.researchgate.net/profile/Ivan_Calandra
https://publons.com/author/705639/

Le 05/12/2016 ? 13:25, Maria Lathouri via R-help a ?crit :
> Dear all
> I know that my question is very simple but although I tried to find an answer online, I couldn't and I am stuck.
> I have a dataset of three numerical variables measured in different samples ID. Something like this:
> Sample        Cu        Zn        MnM1               1          5          10M2               2.5       11          8M3              1.15      11         12  M4                2         4          30M5                8        15         35
> I would like to plot these variables (Cu, Zn, Mn) (in y-axis) against the Sample ID (in x-axis) in a scatter plot with lines as I want to see how they change in the samples.
> I tried using the command>plot(Sample, Cu, type="l", lty=1, col="red")
> but I wouldn't get a line. Actually, I would get some small horizontal lines in each point. I tried to use type="p" but I would get the same thing.
> I would very much appreciate if you could help me on that. Apparently, I am missing something.
> Thank you in advance.
> Kind regards,Maria
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From G.Maubach at weinwolf.de  Mon Dec  5 13:59:48 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 5 Dec 2016 13:59:48 +0100
Subject: [R] openxlsx: No Formatting of Numbers
Message-ID: <OF24EB35F5.9D262230-ONC1258080.0046859E-C1258080.0047659C@lotus.hawesko.de>

Hi All,
Dear Readers,

I am using openxlsx to export data to Microsoft Excel 2013, 32-Bit, German 
Version:

--- schnipp ---

library("openxlsx")

dataset <- structure(
  list(
    a = c(1126039.81, 45636.44, 14847.41),
    b = c(1194447.5,
          88310.53, 18699.68),
    c = c(1560307.73, 34203.73, 24755.99),
    d = c(1068790.67,
          67581.86, 12378.55)
  ),
  .Names = c("a", "b", "c", "d"),
  row.names = c(NA,
                3L),
  class = "data.frame"
)

xlsx_workbook <- openxlsx::createWorkbook()
openxlsx::addWorksheet(
  wb = xlsx_workbook,
  sheetName = "Numbers")

openxlsx::writeData(
  wb = xlsx_workbook,
  sheet = "Numbers",
  x = dataset,
  rowNames = TRUE,
  colNames = TRUE,
  startRow = 2,
  startCol = 2,
  borders = c("surrounding")
)

myStyle <- openxlsx::createStyle(numFmt = "###.###.##0")

openxlsx::addStyle(wb = xlsx_workbook,
                   sheet = "Numbers",
                   style = myStyle,
                   rows = 1:1,
                   cols = 10:10,
                   gridExpand = TRUE,
                   stack = TRUE)

openxlsx::saveWorkbook(
  wb = xlsx_workbook,
  file = "C:/temp/openxlsx_example.xlsx",
  overwrite = TRUE
)

--- schnipp ---

The problem with this is, that it does not apply the number formats to the 
Excel cell on the sheet. Also, sometimes the boarder of the data on the 
Excel sheet is delete. I could not find out yet what the cause for this 
behaviour is.

My sessionInfo() output is:

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Germany.1252 
[2] LC_CTYPE=German_Germany.1252 
[3] LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C 
[5] LC_TIME=German_Germany.1252 

attached base packages:
[1] tools     stats     graphics  grDevices utils 
[6] datasets  methods   base 

other attached packages:
[1] tidyr_0.5.1    stringr_1.1.0  reshape2_1.4.1
[4] openxlsx_3.0.0 dplyr_0.5.0 

loaded via a namespace (and not attached):
[1] lazyeval_0.2.0 plyr_1.8.4     magrittr_1.5 
[4] R6_2.2.0       assertthat_0.1 DBI_0.4-1 
[7] tibble_1.1     Rcpp_0.12.5    stringi_1.1.1 

I do not want to round the numbers in R, cause my clients would like to 
use them as they are in further calculations.

How can I export a dataframe to Excel, print a border around the complete 
table/dataset (not the single cells) and format the numbers like 
123.456.789 (thousand delimiter dot ".", all numbers without decimals)?

Kind regards

Georg

	[[alternative HTML version deleted]]


From G.Maubach at weinwolf.de  Mon Dec  5 14:00:59 2016
From: G.Maubach at weinwolf.de (G.Maubach at weinwolf.de)
Date: Mon, 5 Dec 2016 14:00:59 +0100
Subject: [R] openxlsx: No Formatting of Numbers (TEXT ONLY)
Message-ID: <OF5FE23DA2.2411A1D4-ONC1258080.00477442-C1258080.0047810F@lotus.hawesko.de>

Hi All,
Dear Readers,

I am using openxlsx to export data to Microsoft Excel 2013, 32-Bit, German 
Version:

--- schnipp ---

library("openxlsx")

dataset <- structure(
  list(
    a = c(1126039.81, 45636.44, 14847.41),
    b = c(1194447.5,
          88310.53, 18699.68),
    c = c(1560307.73, 34203.73, 24755.99),
    d = c(1068790.67,
          67581.86, 12378.55)
  ),
  .Names = c("a", "b", "c", "d"),
  row.names = c(NA,
                3L),
  class = "data.frame"
)

xlsx_workbook <- openxlsx::createWorkbook()
openxlsx::addWorksheet(
  wb = xlsx_workbook,
  sheetName = "Numbers")

openxlsx::writeData(
  wb = xlsx_workbook,
  sheet = "Numbers",
  x = dataset,
  rowNames = TRUE,
  colNames = TRUE,
  startRow = 2,
  startCol = 2,
  borders = c("surrounding")
)

myStyle <- openxlsx::createStyle(numFmt = "###.###.##0")

openxlsx::addStyle(wb = xlsx_workbook,
                   sheet = "Numbers",
                   style = myStyle,
                   rows = 1:1,
                   cols = 10:10,
                   gridExpand = TRUE,
                   stack = TRUE)

openxlsx::saveWorkbook(
  wb = xlsx_workbook,
  file = "C:/temp/openxlsx_example.xlsx",
  overwrite = TRUE
)

--- schnipp ---

The problem with this is, that it does not apply the number formats to the 
Excel cell on the sheet. Also, sometimes the boarder of the data on the 
Excel sheet is delete. I could not find out yet what the cause for this 
behaviour is.

My sessionInfo() output is:

R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=German_Germany.1252 
[2] LC_CTYPE=German_Germany.1252 
[3] LC_MONETARY=German_Germany.1252
[4] LC_NUMERIC=C 
[5] LC_TIME=German_Germany.1252 

attached base packages:
[1] tools     stats     graphics  grDevices utils 
[6] datasets  methods   base 

other attached packages:
[1] tidyr_0.5.1    stringr_1.1.0  reshape2_1.4.1
[4] openxlsx_3.0.0 dplyr_0.5.0 

loaded via a namespace (and not attached):
[1] lazyeval_0.2.0 plyr_1.8.4     magrittr_1.5 
[4] R6_2.2.0       assertthat_0.1 DBI_0.4-1 
[7] tibble_1.1     Rcpp_0.12.5    stringi_1.1.1 

I do not want to round the numbers in R, cause my clients would like to 
use them as they are in further calculations.

How can I export a dataframe to Excel, print a border around the complete 
table/dataset (not the single cells) and format the numbers like 
123.456.789 (thousand delimiter dot ".", all numbers without decimals)?

Kind regards

Georg


From carina.salt at googlemail.com  Mon Dec  5 14:18:00 2016
From: carina.salt at googlemail.com (Carina Salt)
Date: Mon, 5 Dec 2016 13:18:00 +0000
Subject: [R] Question about proxy setting of R
In-Reply-To: <CAAxdm-5C_bfe9bdn0ZK9J34WKJ0kG+9E5Oh6hN_XSstV5FER_A@mail.gmail.com>
References: <669742.77077.qm@web102318.mail.kks.yahoo.co.jp>
	<CAAxdm-7jKMHe+MEr=hQnzyvn3xAq5Y+XAPCiiTMZraJvutvAPQ@mail.gmail.com>
	<590798.91297.qm@web102317.mail.kks.yahoo.co.jp>
	<CAAxdm-5C_bfe9bdn0ZK9J34WKJ0kG+9E5Oh6hN_XSstV5FER_A@mail.gmail.com>
Message-ID: <CAB+PZ6AmuTeu_iU9V8odYNk+GA+2Y6beAuwQ3o8e38+U+gJmfQ@mail.gmail.com>

As far as I can see, the 'internal' method doesn't work for https mirrors
(on my system, anyway).  However, the http mirrors still exist (try "
http://cloud.r-project.org/" for example) so why not just use one of those?

Cheers,
Carina

On 5 December 2016 at 12:27, jim holtman <jholtman at gmail.com> wrote:

> You will probably have to check with your network folks to see what is
> possible on your system.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Mon, Dec 5, 2016 at 6:33 AM, <qwertyui_period at yahoo.co.jp> wrote:
>
> > Dear Jim,
> >
> > Thanks to your advice, "Proxy Authentification" window showed up,
> however,
> > I couldn't access to the internet. Error messages are as below.
> >
> > ------------------------------ ------------------------------ -------
> > > update.packages(ask='graphics',checkBuilt=TRUE)
> > --- Please select a CRAN mirror for use in this session ---
> > Warning: failed to download mirrors file (scheme not supported in URL
> > 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
> > 'C:/PROGRA~1/R/R-33~1.2/doc/CRAN_mirrors.csv'
> > Warning: unable to access index for repository
> > https://cran.ism.ac.jp/src/contrib:
> >   scheme not supported in URL 'https://cran.ism.ac.jp/src/
> contrib/PACKAGES'
> >
> > Proxy authentication failed:
> >         please re-enter the credentials or hit Cancel
> > ------------------------------ ------------------------------ -------
> >
> > I assume the proxy server is only available for "http", not "https".
> > What should I do ?
> >
> > J J
> >
> >
> > ----- Original Message -----
> > *From:* jim holtman <jholtman at gmail.com>
> > *To:* qwertyui_period at yahoo.co.jp
> > *Date:* 2016/12/2, Fri 09:13
> > *Subject:* Re: [R] Question about proxy setting of R
> >
> > Try this option:
> >
> >  options(download.file.method = "internal")
> >
> >
> >
> >
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> > On Wed, Nov 30, 2016 at 10:37 PM, <qwertyui_period at yahoo.co.jp> wrote:
> >
> > Hello,
> >
> > I use R 3.0.2 on Win 7 through proxy server using ".Rprofile" in home
> > directory that includes "Sys.setenv(http_proxy=proxy_ server:port)".
> > There has been no problem to access the internet for some years.
> > In this situation, I installed R 3.3.1 and then entered "update.packages
> > ()", however, "Proxy Authentification" window didn't show up and
> > failed to access the internet. Error messages are as below.
> >
> > ------------------------------ ------------------------------ -------
> > > update.packages(ask='graphics' ,checkBuilt=TRUE)
> > --- Please select a CRAN mirror for use in this session ---
> > Warning: failed to download mirrors file (cannot open URL
> > 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
> > 'C:/PROGRA~1/R/R-33~1.2/doc/ CRAN_mirrors.csv'
> > Warning: unable to access index for repository
> > https://cran.ism.ac.jp/src/contrib:
> >   cannot open URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES'
> > Warning: unable to access index for repository
> > http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
> >   cannot open URL 'http://www.stats.ox.ac.uk/
> pub/RWin/src/contrib/PACKAGES
> > '
> > Warning message:
> > In download.file(url, destfile = f, quiet = TRUE) :
> >   cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv': HTTP
> > status was '407 Proxy Authentication Required'
> >
> > ------------------------------ ------------------------------ -------
> >
> > Strange to say, R 3.0.2 is able to access to the internet, and R 3.3.1
> > shows collect proxy setting in ".Rprofile"  by "Sys.getenv("http_proxy")"
> > From internet information, I added "http_proxy_user=ask" to ".Rprofile",
> or
> > " --internet2" to the desktop icon of R 3.3.1, ending up in the same
> > result.
> >
> > Please show me the way of proxy setting of R 3.3.1.
> >
> > ______________________________ ________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.r-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jon.skoien at jrc.ec.europa.eu  Mon Dec  5 15:29:23 2016
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Mon, 05 Dec 2016 15:29:23 +0100
Subject: [R] error serialize (foreach)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68601358EBAE7@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68601358EB902@DC1VEX10MB01.air.org>
	<B08B6AF0CF8CA44F81B9983EEBDCD68601358EBAE7@DC1VEX10MB01.air.org>
Message-ID: <a73774e7-faed-455d-0803-263b39287f32@jrc.ec.europa.eu>

Parallel processing usually includes quite a lot of overhead, which is 
expensive if the computation itself is quick. This is definitely an 
example where the function is too simple to take advantage of 
parallelization. Another thing is that your example has some errors, 
which makes the effect even stronger, as you are only averaging over the 
first three elements of the list.

I have modified the example below to call a more complicated function 
than the mean function. Then the parallelized example is faster 
(although not by much). To see the difference, replace the lapply lines 
with "lapply(dat, mean)". Under the foreach example, you can also see 
the same computation with clusterApply, which seems to be much more 
efficient for this problem.


N <- 200000
myList <- vector('list', N)
for(i in 1:N){
	myList[[i]] <- rnorm(100)
}
library(foreach)
library(doParallel)

ncores = 7
registerDoParallel(cores=ncores)

names(myList) = make.names(rep(1:ncores, length.out = N))
nms = 1:ncores

system.time(result <- foreach(i = 1:ncores) %do% {
	dat <- myList[which(names(myList) == make.names(nms[i]))]
	lapply(dat, FUN = function(x) log(sd(x)) + sd(x) + var(x))
}            )

system.time(
result2 <- foreach(i = 1:ncores) %dopar% {
	dat <- myList[which(names(myList) == make.names(nms[i]))]
	lapply(dat, FUN = function(x) log(sd(x)) + sd(x) + var(x))
}           )



foreach is not always the best choice for parallel processing. You could 
also have a look at clusterApply:

f1 = function(x) mean(x)
f2 = function(x) log(sd(x)) + sd(x) + var(x)

cl = makeCluster(ncores)
clusterExport(cl, list("f1", "f2"))
dats = split(myList, names(myList))
system.time(res <- clusterApply(cl, dats, fun = function(x) lapply(x, f1)))
system.time(res <- lapply(dats, FUN = function(x) lapply(x, f1)))

system.time(res <- clusterApply(cl, dats, fun = function(x) lapply(x, f2)))
system.time(res <- lapply(dats, FUN = function(x) lapply(x, f2)))

lapply is still faster for the example with mean, but much slower for 
the more complicated function.


Best,
Jon




On 12/4/2016 3:11 AM, Doran, Harold wrote:
> As a follow up to this, I have been able to generate a toy example of reproducible code that generates the same problem. Below is just a sample to represent the issue, but my data and subsequent functions acting on the data are much more involved.
>
> I no longer have the error, but, the loop running in parallel is extremely slow relative to its serialized counterpart.
>
> I have narrowed down the problem to the fact that I am searching through a very large list, grabbing the data from that list by indexing to subset and then doing stuff to it. Both "work", but the parallel version is very, very slow. I believe I am sending data files to each core and the number of searches happening is prohibitive.
>
> I am very much stuck in the design-based way of how I would do this particular problem on a single core and am not sure if there is a better designed based approach for solving this problem in the parallel version.
>
> Any advice on better ways to work with the %dopar% version here?
>
> N <- 200000
> myList <- vector('list', N)
> names(myList) <- 1:N
> for(i in 1:N){
> 	myList[[i]] <- rnorm(100)
> }
> nms <- 1:N
> library(foreach)
> library(doParallel)
> registerDoParallel(cores=7)
>
> result <- foreach(i = 1:3) %do% {
> 	dat <- myList[[which(names(myList) == nms[i])]]
> 	mean(dat)
> }
>
> result <- foreach(i = 1:3) %dopar% {
> 	dat <- myList[[which(names(myList) == nms[i])]]
> 	mean(dat)
> }
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
> Sent: Saturday, December 03, 2016 4:26 PM
> To: r-help at r-project.org
> Subject: [R] error serialize (foreach)
>
> I have a portion of a foreach loop that I cannot run as parallel but works fine when serialized. Below is a representation of the problem as in this instance I cannot provide reproducible data to generate the same error, the actual data I am working with are confidential.
>
> Within each foreach loop are a series of custom functions acting on my data. When using %do% I get expected result but replacing it with %dopar% generates the error.
>
> I have searched archives and also stackexchange and see this is an issue that arises and I have tried a couple of the recommendations, like trying to use an outfile in makeCluster. But I am not having success.
>
> Oddly, (or perhaps not oddly), others portions of my program run in parallel and do not generate this same error
>
> library(foreach)
> library(doParallel)
> registerDoParallel(cores=3)
>
> # This portion runs and produces expected result result <- foreach(i = 1:N) %do% {
> tmp1 <- function1(...)
> tmp2 <- function2(...)
> tmp2
> }
>
> # This portion generates error in serialize result <- foreach(i = 1:N) %dopar% {
> tmp1 <- function1(...)
> tmp2 <- function2(...)
> tmp2
> }
>
> error in serialize(data, node$con) : error writing to connection
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Space, Security & Migration
Disaster Risk Management Unit

Via E. Fermi 2749, TP 122,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual 
and do not necessarily represent official views of the European Commission.


From daniellthin at gmail.com  Mon Dec  5 11:28:12 2016
From: daniellthin at gmail.com (Daniel)
Date: Mon, 5 Dec 2016 18:28:12 +0800
Subject: [R]  ggplot2, qplot, problems
Message-ID: <CAMTHMoy+Ar0Y9fsx-vST5SGngn8nomCjfQ4UdurWWoU6LoW-6w@mail.gmail.com>

Dear the R Community,

I just encountered an error while using ggplot2 and the qplot function
(please see below for the warnings and error), and i have no idea about how
to make changes so that it will work.
Could anyone kindly advise me a bit and help me out here?

------------------------------------------------------------------------------------------------------
> library(ggplot2)
Warning message:
package ?ggplot2? was built under R version 3.2.5

> library(ggplot2)
> dodge <- position_dodge(width = .9)
> plot <- qplot(happening, target.looking_M, data=d.c2.subjects,
stat="identity",
+ geom="bar", position=dodge,
+ ylab="Proportion of looks", xlab="happening",
+ fill=happening, colour=happening,
+ main="Proportion target looking by condition and testing phase for each
single subject")

Warning messages:
1: `stat` is deprecated
2: `position` is deprecated

> plot <- plot + facet_grid(type ~ subjectname)
> plot

Error: stat_count() must not be used with a y aesthetic.
-------------------------------------------------------------------------------------------------------

thank you very much.

Cheers,
Daniel

	[[alternative HTML version deleted]]


From david.w.watson at nasa.gov  Mon Dec  5 14:31:21 2016
From: david.w.watson at nasa.gov (Watson, David W. (MSFC-ES62))
Date: Mon, 5 Dec 2016 13:31:21 +0000
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct RC
	version
Message-ID: <B7F72FAA-A5D5-4D5A-9D17-E54599F47D69@nasa.gov>

I have been trying to download the ?patched? version of 3.3.2 from CRAN, but the version that gets delivered is actually the October Release Candidate version,
(R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?

David Watson
NASA - MSFC
Mail Code ES62
Phone 256-544-1300
FAX   256-544-2964
david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>


	[[alternative HTML version deleted]]


From emm.charpentier at free.fr  Mon Dec  5 13:29:27 2016
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Mon, 5 Dec 2016 13:29:27 +0100
Subject: [R] Can't install or upgrade the "PKI" package on a Debian testing
	system
Message-ID: <4bb7f523-1026-4e98-911d-2c0a0210e1f8@free.fr>

Dear list,

It seems that recent changes in openssl somehow broke the installation 
or update of the PKI package. This is probably specific of my setup(s) 
(Debian testing, updated frequently).

Copy of a mail to Simon Urbanek (PKI maintainer), sent 5 days ago 
without reply nor acknowledgement so far :
========================================================================

It seems that recent changes in openssl rendered the PKI package 
uninstallable :

--------------------------------------------------------------------------

 > install.packages("PKI")
essai de l'URL 'http://cran.univ-paris1.fr/src/contrib/PKI_0.1-3.tar.gz'
Content type 'application/x-gzip' length 31058 bytes (30 KB)
==================================================
downloaded 30 KB

* installing *source* package ?PKI? ...
** package ?PKI? correctement d?compress? et sommes MD5 v?rifi?es
** libs
gcc -I/usr/local/sage-7/local/lib/R//include -DNDEBUG      -fpic  -g -O2 
   -c asn1.c -o asn1.o
gcc -I/usr/local/sage-7/local/lib/R//include -DNDEBUG      -fpic  -g -O2 
   -c init.c -o init.o
gcc -I/usr/local/sage-7/local/lib/R//include -DNDEBUG      -fpic  -g -O2 
   -c pki-x509.c -o pki-x509.o
pki-x509.c: In function ?PKI_extract_key?:
pki-x509.c:136:26: error: dereferencing pointer to incomplete type 
?EVP_PKEY {aka struct evp_pkey_st}?
      if (EVP_PKEY_type(key->type) != EVP_PKEY_RSA)
                           ^~
pki-x509.c: In function ?get_cipher?:
pki-x509.c:244:40: error: dereferencing pointer to incomplete type 
?EVP_CIPHER_CTX {aka struct evp_cipher_ctx_st}?
   ctx = (EVP_CIPHER_CTX*) malloc(sizeof(*ctx));
                                         ^~~~
pki-x509.c: In function ?PKI_RSAkeygen?:
pki-x509.c:550:5: warning: ?RSA_generate_key? is deprecated 
[-Wdeprecated-declarations]
      rsa = RSA_generate_key(bits, 65537, 0, 0);
      ^~~
In file included from /usr/include/openssl/rsa.h:13:0,
                  from pki.h:13,
                  from pki-x509.c:1:
/usr/include/openssl/rsa.h:193:1: note: declared here
  DEPRECATEDIN_0_9_8(RSA *RSA_generate_key(int bits, unsigned long e, void
  ^
/usr/local/sage-7/local/lib/R//etc/Makeconf:132 : la recette pour la 
cible ? pki-x509.o ? a ?chou?e
make: *** [pki-x509.o] Erreur 1
ERROR: compilation failed for package ?PKI?
* removing ?/usr/local/sage-7/local/lib/R/library/PKI?

Les packages source t?l?charg?s sont dans
     ?/tmp/Rtmpnmt97E/downloaded_packages?
Warning message:
In install.packages("PKI") :
   l'installation du package ?PKI? a eu un statut de sortie non nul

--------------------------------------------------------------------------

This problem blocks the installation of rstanarm, brms, rsconnect and 
shinystan among others. Not exactly trivial.

As far as I know, my libssl libraries are all at 1.1.0c, as well as openssl.
========================================================================

New data point : it turns out that this problem also impedes the update 
of PKI : my running R installatin still has PKI 1.3, which seems enough 
for rstanarm, brms, rsconnect and shinystan to run and install/upgrade.

However, on a new installation of R (installed in Sage), PKI can't be 
installed. I tried to install PKI 1.3 fro Rforge, with no success.

- Did someone already had this problem ?
- Has he/she been able to work around it ? If so, How ?
- Is my mail to Simon Urbanek sufficient as a bug report ? If not, what
    should I do ?

Sincerely yours,

					Emanuel Charpentier

PS : If possible, I'd appreciate to be CC'd of your answers : I'm not on 
the list and have had trouble subscribing "reasonably". I'm following it 
through the mail archives.


From maitra at email.com  Mon Dec  5 06:53:55 2016
From: maitra at email.com (Ranjan Maitra)
Date: Sun, 4 Dec 2016 23:53:55 -0600
Subject: [R] Clustering methods for data that has bimodal distribution
In-Reply-To: <CAL2fYnM8aj_oZqvMOQPCWuR6c-dLZ-hZhxkr8Y4iC9OPJ_rLng@mail.gmail.com>
References: <CAL2fYnM8aj_oZqvMOQPCWuR6c-dLZ-hZhxkr8Y4iC9OPJ_rLng@mail.gmail.com>
Message-ID: <20161204235355.c160ed2957b01b36c293b8e1@email.com>

Hello Adrian,

It all depends on what the structure of the dataset is. For instance, you said that all your values are betweenn -1 and 1. Do the data rown sum-squared up to 1? How about the means? Are they zero. I guess all this has to depend on the application and how the data were processed or what is sought to be answered? Even if Euclidean space is most apt, then you need to figure out what sort of structure you would like in your derived groups/clusters. For example again, k-means has an underlying philosophy: homoegenous spherical clusters of roughly equal sizes. Is this what yuo want?

HTH,
Ranjan

On Sun, 4 Dec 2016 22:52:33 -0500 Adrian Johnson <oriolebaltimore at gmail.com> wrote:

> Dear group,
> pardon me for a naive question. I have data matrix (11K rows , 4K columns).
> The data range is between -1 to 1. Not strictly integers, but real
> numbers with at least place values in millionths.
> 
> The data distribution is peculiar (if I do plot(density(myMatrix)),  I
> get nice bimodal curve (nice standard distribution between -1 and 0
> and another curve between 0 and 1) .
> 
> I am interested in clustering the data (using conesnsus clustering
> (that uses K-means)).
> 
> My question are:
> 
> 1. If my data is range is between -1  and 1. Is K-means appropriate
> method. considering if the data might have ties.
> 
> 2. Although K-means is non-parametric, would a bimodal distributed
> data be okay as input to K-means.
> 
> I appreciate any suggestion.
> Thanks
> Adrian.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From nikwyss at gmail.com  Mon Dec  5 14:00:06 2016
From: nikwyss at gmail.com (Dominik Wyss)
Date: Mon, 5 Dec 2016 14:00:06 +0100
Subject: [R] Sensitivity Analysis for Moderated Mediation?
Message-ID: <014c056c-4644-a9a3-b189-52af8eb1460b@gmail.com>

Dear group,
medsens() is a fantastic method for testing sensitivity of mediation 
models estimated by the mediate(). (mediation package by Tingley et al; 
Version 4.4.5).
However, I'm wondering whether medsens() is also appropriate for 
moderated mediation? And if not, is there an alternative procedure that 
allows to test sensitivity of moderated mediation analysis?

In one of my study, I find strong theoretical and empirical support for 
moderated mediation (moderator is a dummy var; otherwise the model specs 
are similar to chapter 3.2 
ftp://cran.r-project.org/pub/R/web/packages/mediation/vignettes/mediation.pdf). 
However, my medsens() analysis finds only very poor Rho and R2 values. 
Before throwing away the model, I wonder whether medsens is appropriate 
for estimating sensitivity of moderated mediation models, normally 
entailing a moderation*mediator interaction term.

And if medsens is not appropriate for moderated mediation: Would it be 
enough enlightening to test sensitivity of two unmoderated mediation 
models ran over two sub-datasets, split along the moderation dummy?

many thanks for any advice.
Dominik


From qwertyui_period at yahoo.co.jp  Mon Dec  5 12:33:34 2016
From: qwertyui_period at yahoo.co.jp (qwertyui_period at yahoo.co.jp)
Date: Mon, 5 Dec 2016 20:33:34 +0900 (JST)
Subject: [R] Question about proxy setting of R
In-Reply-To: <CAAxdm-7jKMHe+MEr=hQnzyvn3xAq5Y+XAPCiiTMZraJvutvAPQ@mail.gmail.com>
References: <669742.77077.qm@web102318.mail.kks.yahoo.co.jp>
	<CAAxdm-7jKMHe+MEr=hQnzyvn3xAq5Y+XAPCiiTMZraJvutvAPQ@mail.gmail.com>
Message-ID: <590798.91297.qm@web102317.mail.kks.yahoo.co.jp>

Dear Jim,


Thanks to your advice, "Proxy Authentification" window?showed up, however, 
I couldn't access to the internet. Error messages are as below.

------------------------------ ------------------------------ -------
> update.packages(ask='graphics',checkBuilt=TRUE)
--- Please select a CRAN mirror for use in this session ---
Warning: failed to download mirrors file (scheme not supported in URL
'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
'C:/PROGRA~1/R/R-33~1.2/doc/CRAN_mirrors.csv'
Warning: unable to access index for repository
https://cran.ism.ac.jp/src/contrib: 
? scheme not supported in URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES' 
Proxy authentication failed:
? ? ? ? please re-enter the credentials or hit Cancel------------------------------ ------------------------------ -------

I assume the proxy server is only available for "http", not "https".
What should I do ?


J J


----- Original Message -----
>From: jim holtman <jholtman at gmail.com>
>To: qwertyui_period at yahoo.co.jp 
>Date: 2016/12/2, Fri 09:13
>Subject: Re: [R] Question about proxy setting of R
>  
>
>Try this option:
>
>
>?options(download.file.method = "internal")
>
>
>
>
>
>
>
>
>
>Jim Holtman
>Data Munger Guru
>?
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it. 
>
>On Wed, Nov 30, 2016 at 10:37 PM, <qwertyui_period at yahoo.co.jp> wrote:
>
>Hello,
>>
>>I use R 3.0.2 on Win 7 through proxy server using ".Rprofile" in home
>>directory that includes "Sys.setenv(http_proxy=proxy_ server:port)".
>>There has been no problem to access the internet for some years.
>>In this situation, I installed R 3.3.1 and then entered "update.packages
>>()", however, "Proxy Authentification" window didn't show up and
>>failed to access the internet. Error messages are as below.
>>
>>------------------------------ ------------------------------ -------
>>> update.packages(ask='graphics' ,checkBuilt=TRUE)
>>--- Please select a CRAN mirror for use in this session ---
>>Warning: failed to download mirrors file (cannot open URL
>>'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
>>'C:/PROGRA~1/R/R-33~1.2/doc/ CRAN_mirrors.csv'
>>Warning: unable to access index for repository
>>https://cran.ism.ac.jp/src/contrib:
>>? cannot open URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES'
>>Warning: unable to access index for repository
>>http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>>? cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES'
>>Warning message:
>>In download.file(url, destfile = f, quiet = TRUE) :
>>? cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv': HTTP
>>status was '407 Proxy Authentication Required'
>>
>>------------------------------ ------------------------------ -------
>>
>>Strange to say, R 3.0.2 is able to access to the internet, and R 3.3.1
>>shows collect proxy setting in ".Rprofile"? by "Sys.getenv("http_proxy")"
>>From internet information, I added "http_proxy_user=ask" to ".Rprofile", or
>>" --internet2" to the desktop icon of R 3.3.1, ending up in the same
>>result.
>>
>>Please show me the way of proxy setting of R 3.3.1.
>>
>>______________________________ ________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
> 
>
>   
	[[alternative HTML version deleted]]


From jsorkin at grecc.umaryland.edu  Mon Dec  5 15:44:45 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 05 Dec 2016 09:44:45 -0500
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
References: 58452E93.medlxdom.medlxpo.200.20000CB.1.1689F1.1
Message-ID: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>

I am trying to write a function which, when passed the name of a dataframe and the name of a column of the dataframe, will allow me to work on the columns of a dataframe. I can not get my code to work. Please see the code below. Any help in getting the function to work would be appreciated.




mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
mydf
class(mydf)


myfun <- function(frame,var){
  call <- match.call()
  print(call)


  indx <- match(c("frame","var"),names(call),nomatch=0)
  print(indx)
  if(indx[1]==0) stop("Function called without sufficient arguments!")


  cat("I can get the name of the dataframe as a text string!\n")
  xx <- deparse(substitute(frame))
  print(xx)


  cat("I can get the name of the column as a text string!\n")
  yy <- deparse(substitute(var))
  print(yy)


  # This does not work.
  col <- xx[,"yy"]


  # Nor does this work.
  col <- xx[,yy]
  print(col)
}


myfun(mydf,age)

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 




John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 





Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From murdoch.duncan at gmail.com  Mon Dec  5 16:06:04 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 5 Dec 2016 10:06:04 -0500
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct
 RC version
In-Reply-To: <B7F72FAA-A5D5-4D5A-9D17-E54599F47D69@nasa.gov>
References: <B7F72FAA-A5D5-4D5A-9D17-E54599F47D69@nasa.gov>
Message-ID: <ca6dab51-97e2-ed1c-599c-8119c3617e78@gmail.com>

On 05/12/2016 8:31 AM, Watson, David W. (MSFC-ES62) wrote:
> I have been trying to download the ?patched? version of 3.3.2 from CRAN, but the version that gets delivered is actually the October Release Candidate version,
> (R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?

What URL are you using?  The Windows binary at 
https://cloud.r-project.org/bin/windows/base/rpatched.html appears to be 
up to date.

Duncan Murdoch
>
> David Watson
> NASA - MSFC
> Mail Code ES62
> Phone 256-544-1300
> FAX   256-544-2964
> david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Dec  5 16:17:26 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 05 Dec 2016 15:17:26 +0000
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
References: 58452E93.medlxdom.medlxpo.200.20000CB.1.1689F1.1
	<5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
Message-ID: <58458506.9010801@sapo.pt>

Hello,

You don't need xx <- deparse(substitute(...)), since you are passing the 
data.frame to your function. Just use


myfun <- function(frame,var){

   [...]

   # Nor does this work.
   col <- frame[,yy]
   print(col)
}

myfun(mydf,age)
myfun(frame = mydf, var = age)
[1] 2 3
I can get the name of the dataframe as a text string!
[1] "mydf"
I can get the name of the column as a text string!
[1] "age"
[1] 20 34 43 32 21


Hope this helps,

Rui Barradas



Em 05-12-2016 14:44, John Sorkin escreveu:
> I am trying to write a function which, when passed the name of a dataframe and the name of a column of the dataframe, will allow me to work on the columns of a dataframe. I can not get my code to work. Please see the code below. Any help in getting the function to work would be appreciated.
>
>
>
>
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
>
>
> myfun <- function(frame,var){
>    call <- match.call()
>    print(call)
>
>
>    indx <- match(c("frame","var"),names(call),nomatch=0)
>    print(indx)
>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>
>
>    cat("I can get the name of the dataframe as a text string!\n")
>    xx <- deparse(substitute(frame))
>    print(xx)
>
>
>    cat("I can get the name of the column as a text string!\n")
>    yy <- deparse(substitute(var))
>    print(yy)
>
>
>    # This does not work.
>    col <- xx[,"yy"]
>
>
>    # Nor does this work.
>    col <- xx[,yy]
>    print(col)
> }
>
>
> myfun(mydf,age)
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:8}}


From ruipbarradas at sapo.pt  Mon Dec  5 16:23:12 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 05 Dec 2016 15:23:12 +0000
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <58458506.9010801@sapo.pt>
References: 58452E93.medlxdom.medlxpo.200.20000CB.1.1689F1.1	<5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
Message-ID: <58458660.2050305@sapo.pt>

I forgot to say that I've commented out the line

# This does not work.
#col <- xx[,"yy"]

Rui Barradas

Em 05-12-2016 15:17, Rui Barradas escreveu:
> Hello,
>
> You don't need xx <- deparse(substitute(...)), since you are passing the
> data.frame to your function. Just use
>
>
> myfun <- function(frame,var){
>
>    [...]
>
>    # Nor does this work.
>    col <- frame[,yy]
>    print(col)
> }
>
> myfun(mydf,age)
> myfun(frame = mydf, var = age)
> [1] 2 3
> I can get the name of the dataframe as a text string!
> [1] "mydf"
> I can get the name of the column as a text string!
> [1] "age"
> [1] 20 34 43 32 21
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 05-12-2016 14:44, John Sorkin escreveu:
>> I am trying to write a function which, when passed the name of a
>> dataframe and the name of a column of the dataframe, will allow me to
>> work on the columns of a dataframe. I can not get my code to work.
>> Please see the code below. Any help in getting the function to work
>> would be appreciated.
>>
>>
>>
>>
>> mydf <-
>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>
>> mydf
>> class(mydf)
>>
>>
>> myfun <- function(frame,var){
>>    call <- match.call()
>>    print(call)
>>
>>
>>    indx <- match(c("frame","var"),names(call),nomatch=0)
>>    print(indx)
>>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>>
>>
>>    cat("I can get the name of the dataframe as a text string!\n")
>>    xx <- deparse(substitute(frame))
>>    print(xx)
>>
>>
>>    cat("I can get the name of the column as a text string!\n")
>>    yy <- deparse(substitute(var))
>>    print(yy)
>>
>>
>>    # This does not work.
>>    col <- xx[,"yy"]
>>
>>
>>    # Nor does this work.
>>    col <- xx[,yy]
>>    print(col)
>> }
>>
>>
>> myfun(mydf,age)
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>
>>
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for ...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jsorkin at grecc.umaryland.edu  Mon Dec  5 16:29:12 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 05 Dec 2016 10:29:12 -0500
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <58458506.9010801@sapo.pt>
References: 58452E93.medlxdom.medlxpo.200.20000CB.1.1689F1.1
	<5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
Message-ID: <58454178020000CB00168A55@smtp.medicine.umaryland.edu>

Rui,
I appreciate your suggestion, but eliminating the deparse statement does not solve my problem. Do you have any other suggestions? See code below.
Thank you,
John


mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
mydf
class(mydf)


myfun <- function(frame,var){
  call <- match.call()
  print(call)


  indx <- match(c("frame","var"),names(call),nomatch=0)
  print(indx)
  if(indx[1]==0) stop("Function called without sufficient arguments!")


  cat("I can get the name of the dataframe as a text string!\n")
  #xx <- deparse(substitute(frame))
  print(xx)


  cat("I can get the name of the column as a text string!\n")
  #yy <- deparse(substitute(var))
  print(yy)


  # This does not work.
  print(frame[,var])


  # This does not work.
  print(frame[,"var"])




  # This does not work.
  col <- xx[,"yy"]


  # Nor does this work.
  col <- xx[,yy]
  print(col)
}


myfun(mydf,age)




myfun()














John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

>>> Rui Barradas <ruipbarradas at sapo.pt> 12/05/16 10:17 AM >>>
Hello,

You don't need xx <- deparse(substitute(...)), since you are passing the 
data.frame to your function. Just use


myfun <- function(frame,var){

   [...]

   # Nor does this work.
   col <- frame[,yy]
   print(col)
}

myfun(mydf,age)
myfun(frame = mydf, var = age)
[1] 2 3
I can get the name of the dataframe as a text string!
[1] "mydf"
I can get the name of the column as a text string!
[1] "age"
[1] 20 34 43 32 21


Hope this helps,

Rui Barradas



Em 05-12-2016 14:44, John Sorkin escreveu:
> I am trying to write a function which, when passed the name of a dataframe and the name of a column of the dataframe, will allow me to work on the columns of a dataframe. I can not get my code to work. Please see the code below. Any help in getting the function to work would be appreciated.
>
>
>
>
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
>
>
> myfun <- function(frame,var){
>    call <- match.call()
>    print(call)
>
>
>    indx <- match(c("frame","var"),names(call),nomatch=0)
>    print(indx)
>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>
>
>    cat("I can get the name of the dataframe as a text string!\n")
>    xx <- deparse(substitute(frame))
>    print(xx)
>
>
>    cat("I can get the name of the column as a text string!\n")
>    yy <- deparse(substitute(var))
>    print(yy)
>
>
>    # This does not work.
>    col <- xx[,"yy"]
>
>
>    # Nor does this work.
>    col <- xx[,yy]
>    print(col)
> }
>
>
> myfun(mydf,age)
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bgunter.4567 at gmail.com  Mon Dec  5 16:36:03 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Dec 2016 07:36:03 -0800
Subject: [R] Write a function that allows access to columns of a passed
	dataframe.
In-Reply-To: <58454178020000CB00168A55@smtp.medicine.umaryland.edu>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
Message-ID: <CAGxFJbRyKOJ=riezhbD1RXO9ApuvcHmT6yHwxkgLoEyL5dd4sg@mail.gmail.com>

John:

I think you need to re-read about how functions pass arguments and
data frame access works in R.

What Rui meant was to get rid of all the xx stuff and access your column by:

col <- frame[, yy]

That *does* work.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 5, 2016 at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> Rui,
> I appreciate your suggestion, but eliminating the deparse statement does not solve my problem. Do you have any other suggestions? See code below.
> Thank you,
> John
>
>
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
>
>
> myfun <- function(frame,var){
>   call <- match.call()
>   print(call)
>
>
>   indx <- match(c("frame","var"),names(call),nomatch=0)
>   print(indx)
>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>
>
>   cat("I can get the name of the dataframe as a text string!\n")
>   #xx <- deparse(substitute(frame))
>   print(xx)
>
>
>   cat("I can get the name of the column as a text string!\n")
>   #yy <- deparse(substitute(var))
>   print(yy)
>
>
>   # This does not work.
>   print(frame[,var])
>
>
>   # This does not work.
>   print(frame[,"var"])
>
>
>
>
>   # This does not work.
>   col <- xx[,"yy"]
>
>
>   # Nor does this work.
>   col <- xx[,yy]
>   print(col)
> }
>
>
> myfun(mydf,age)
>
>
>
>
> myfun()
>
>
>
>
>
>
>
>
>
>
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>>>> Rui Barradas <ruipbarradas at sapo.pt> 12/05/16 10:17 AM >>>
> Hello,
>
> You don't need xx <- deparse(substitute(...)), since you are passing the
> data.frame to your function. Just use
>
>
> myfun <- function(frame,var){
>
>    [...]
>
>    # Nor does this work.
>    col <- frame[,yy]
>    print(col)
> }
>
> myfun(mydf,age)
> myfun(frame = mydf, var = age)
> [1] 2 3
> I can get the name of the dataframe as a text string!
> [1] "mydf"
> I can get the name of the column as a text string!
> [1] "age"
> [1] 20 34 43 32 21
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 05-12-2016 14:44, John Sorkin escreveu:
>> I am trying to write a function which, when passed the name of a dataframe and the name of a column of the dataframe, will allow me to work on the columns of a dataframe. I can not get my code to work. Please see the code below. Any help in getting the function to work would be appreciated.
>>
>>
>>
>>
>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>> mydf
>> class(mydf)
>>
>>
>> myfun <- function(frame,var){
>>    call <- match.call()
>>    print(call)
>>
>>
>>    indx <- match(c("frame","var"),names(call),nomatch=0)
>>    print(indx)
>>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>>
>>
>>    cat("I can get the name of the dataframe as a text string!\n")
>>    xx <- deparse(substitute(frame))
>>    print(xx)
>>
>>
>>    cat("I can get the name of the column as a text string!\n")
>>    yy <- deparse(substitute(var))
>>    print(yy)
>>
>>
>>    # This does not work.
>>    col <- xx[,"yy"]
>>
>>
>>    # Nor does this work.
>>    col <- xx[,yy]
>>    print(col)
>> }
>>
>>
>> myfun(mydf,age)
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>
>>
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:12}}


From bgunter.4567 at gmail.com  Mon Dec  5 16:44:22 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Dec 2016 07:44:22 -0800
Subject: [R] Sensitivity Analysis for Moderated Mediation?
In-Reply-To: <014c056c-4644-a9a3-b189-52af8eb1460b@gmail.com>
References: <014c056c-4644-a9a3-b189-52af8eb1460b@gmail.com>
Message-ID: <CAGxFJbRFVJJ-kPx9MAt_X6oKN-FUDy0G6oE3SxEMe_MdhP4H1A@mail.gmail.com>

This post actually has nothing to do with R programming per se, and
hence is off topic here. Please post elsewhere, e.g. on
stats.stackexchange.com or other list that discusses "mediation
models".

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 5, 2016 at 5:00 AM, Dominik Wyss <nikwyss at gmail.com> wrote:
> Dear group,
> medsens() is a fantastic method for testing sensitivity of mediation models
> estimated by the mediate(). (mediation package by Tingley et al; Version
> 4.4.5).
> However, I'm wondering whether medsens() is also appropriate for moderated
> mediation? And if not, is there an alternative procedure that allows to test
> sensitivity of moderated mediation analysis?
>
> In one of my study, I find strong theoretical and empirical support for
> moderated mediation (moderator is a dummy var; otherwise the model specs are
> similar to chapter 3.2
> ftp://cran.r-project.org/pub/R/web/packages/mediation/vignettes/mediation.pdf).
> However, my medsens() analysis finds only very poor Rho and R2 values.
> Before throwing away the model, I wonder whether medsens is appropriate for
> estimating sensitivity of moderated mediation models, normally entailing a
> moderation*mediator interaction term.
>
> And if medsens is not appropriate for moderated mediation: Would it be
> enough enlightening to test sensitivity of two unmoderated mediation models
> ran over two sub-datasets, split along the moderation dummy?
>
> many thanks for any advice.
> Dominik
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Mon Dec  5 17:05:36 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 5 Dec 2016 16:05:36 +0000
Subject: [R] ggplot2, qplot, problems
In-Reply-To: <CAMTHMoy+Ar0Y9fsx-vST5SGngn8nomCjfQ4UdurWWoU6LoW-6w@mail.gmail.com>
References: <CAMTHMoy+Ar0Y9fsx-vST5SGngn8nomCjfQ4UdurWWoU6LoW-6w@mail.gmail.com>
Message-ID: <a747eaa5-b3e8-aca7-e82b-bdf27b9c8b75@dewey.myzen.co.uk>

I do not use ggplot2 myself but I think my first action would be to 
update you version of ggplot2 and possibly also of R.

On 05/12/2016 10:28, Daniel wrote:
> Dear the R Community,
>
> I just encountered an error while using ggplot2 and the qplot function
> (please see below for the warnings and error), and i have no idea about how
> to make changes so that it will work.
> Could anyone kindly advise me a bit and help me out here?
>
> ------------------------------------------------------------------------------------------------------
>> library(ggplot2)
> Warning message:
> package ?ggplot2? was built under R version 3.2.5
>
>> library(ggplot2)
>> dodge <- position_dodge(width = .9)
>> plot <- qplot(happening, target.looking_M, data=d.c2.subjects,
> stat="identity",
> + geom="bar", position=dodge,
> + ylab="Proportion of looks", xlab="happening",
> + fill=happening, colour=happening,
> + main="Proportion target looking by condition and testing phase for each
> single subject")
>
> Warning messages:
> 1: `stat` is deprecated
> 2: `position` is deprecated
>
>> plot <- plot + facet_grid(type ~ subjectname)
>> plot
>
> Error: stat_count() must not be used with a y aesthetic.
> -------------------------------------------------------------------------------------------------------
>
> thank you very much.
>
> Cheers,
> Daniel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Mon Dec  5 17:18:02 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 05 Dec 2016 08:18:02 -0800
Subject: [R] ggplot2, qplot, problems
In-Reply-To: <a747eaa5-b3e8-aca7-e82b-bdf27b9c8b75@dewey.myzen.co.uk>
References: <CAMTHMoy+Ar0Y9fsx-vST5SGngn8nomCjfQ4UdurWWoU6LoW-6w@mail.gmail.com>
	<a747eaa5-b3e8-aca7-e82b-bdf27b9c8b75@dewey.myzen.co.uk>
Message-ID: <1DD0A0E3-1404-4548-BF94-4945192007E2@dcn.davis.ca.us>

Given the error messages, it looks like the OP may already have updated and needs to update their code to match. Perhaps reading ?qplot or learning how to use the ggplot function instead of qplot should be next steps. 
-- 
Sent from my phone. Please excuse my brevity.

On December 5, 2016 8:05:36 AM PST, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
>I do not use ggplot2 myself but I think my first action would be to 
>update you version of ggplot2 and possibly also of R.
>
>On 05/12/2016 10:28, Daniel wrote:
>> Dear the R Community,
>>
>> I just encountered an error while using ggplot2 and the qplot
>function
>> (please see below for the warnings and error), and i have no idea
>about how
>> to make changes so that it will work.
>> Could anyone kindly advise me a bit and help me out here?
>>
>>
>------------------------------------------------------------------------------------------------------
>>> library(ggplot2)
>> Warning message:
>> package ?ggplot2? was built under R version 3.2.5
>>
>>> library(ggplot2)
>>> dodge <- position_dodge(width = .9)
>>> plot <- qplot(happening, target.looking_M, data=d.c2.subjects,
>> stat="identity",
>> + geom="bar", position=dodge,
>> + ylab="Proportion of looks", xlab="happening",
>> + fill=happening, colour=happening,
>> + main="Proportion target looking by condition and testing phase for
>each
>> single subject")
>>
>> Warning messages:
>> 1: `stat` is deprecated
>> 2: `position` is deprecated
>>
>>> plot <- plot + facet_grid(type ~ subjectname)
>>> plot
>>
>> Error: stat_count() must not be used with a y aesthetic.
>>
>-------------------------------------------------------------------------------------------------------
>>
>> thank you very much.
>>
>> Cheers,
>> Daniel
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>-- 
>Michael
>http://www.dewey.myzen.co.uk/home.html
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Dec  5 18:09:06 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Dec 2016 09:09:06 -0800
Subject: [R] Write a function that allows access to columns of a passed
	dataframe.
In-Reply-To: <58454178020000CB00168A55@smtp.medicine.umaryland.edu>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
Message-ID: <66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>


> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> Rui,
> I appreciate your suggestion, but eliminating the deparse statement does not solve my problem. Do you have any other suggestions? See code below.
> Thank you,
> John
> 
> 
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
> 
> 
> myfun <- function(frame,var){
>  call <- match.call()
>  print(call)
> 
> 
>  indx <- match(c("frame","var"),names(call),nomatch=0)
>  print(indx)
>  if(indx[1]==0) stop("Function called without sufficient arguments!")
> 
> 
>  cat("I can get the name of the dataframe as a text string!\n")
>  #xx <- deparse(substitute(frame))
>  print(xx)
> 
> 
>  cat("I can get the name of the column as a text string!\n")
>  #yy <- deparse(substitute(var))
>  print(yy)
> 
> 
>  # This does not work.
>  print(frame[,var])
> 
> 
>  # This does not work.
>  print(frame[,"var"])
> 
> 
> 
> 
>  # This does not work.
>  col <- xx[,"yy"]
> 
> 
>  # Nor does this work.
>  col <- xx[,yy]
>  print(col)
> }
> 
> 
> myfun(mydf,age)


When you use that calling syntax, the system will supply the values of whatever the `age` variable contains. (And if there is no `age`-named object, you get an error at the time of the call to `myfun`. You need either to call it as:

myfun( mydf , "age")


# Or:

age <- "age"
myfun( mydf, age)

Unless your value of the `age`-named variable was "age" in the calling environment (and you did not give us that value in either of your postings), you would fail.

-- 
David.

> 
> 
> 
> 
> myfun()
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
>>>> Rui Barradas <ruipbarradas at sapo.pt> 12/05/16 10:17 AM >>>
> Hello,
> 
> You don't need xx <- deparse(substitute(...)), since you are passing the 
> data.frame to your function. Just use
> 
> 
> myfun <- function(frame,var){
> 
>   [...]
> 
>   # Nor does this work.
>   col <- frame[,yy]
>   print(col)
> }
> 
> myfun(mydf,age)
> myfun(frame = mydf, var = age)
> [1] 2 3
> I can get the name of the dataframe as a text string!
> [1] "mydf"
> I can get the name of the column as a text string!
> [1] "age"
> [1] 20 34 43 32 21
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> 
> Em 05-12-2016 14:44, John Sorkin escreveu:
>> I am trying to write a function which, when passed the name of a dataframe and the name of a column of the dataframe, will allow me to work on the columns of a dataframe. I can not get my code to work. Please see the code below. Any help in getting the function to work would be appreciated.
>> 
>> 
>> 
>> 
>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>> mydf
>> class(mydf)
>> 
>> 
>> myfun <- function(frame,var){
>>   call <- match.call()
>>   print(call)
>> 
>> 
>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>   print(indx)
>>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>> 
>> 
>>   cat("I can get the name of the dataframe as a text string!\n")
>>   xx <- deparse(substitute(frame))
>>   print(xx)
>> 
>> 
>>   cat("I can get the name of the column as a text string!\n")
>>   yy <- deparse(substitute(var))
>>   print(yy)
>> 
>> 
>>   # This does not work.
>>   col <- xx[,"yy"]
>> 
>> 
>>   # Nor does this work.
>>   col <- xx[,yy]
>>   print(col)
>> }
>> 
>> 
>> myfun(mydf,age)
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> 
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>> 
>> 
>> 
>> 
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:15}}


From emm.charpentier at free.fr  Mon Dec  5 17:57:50 2016
From: emm.charpentier at free.fr (Emmanuel Charpentier)
Date: Mon, 5 Dec 2016 17:57:50 +0100
Subject: [R] Followup [Can't install or upgrade the "PKI" package on a
 Debian testing system]
Message-ID: <2e03acef-342d-316a-aa70-86879e9ac3b7@free.fr>

Dear list;

since I've posted the message below, Simon Urbanek has fixed the problem 
(in less than 5 hours, phewww...). The version available on Rforge *is* 
installable with OpenSSL 1.1

Note that you'll have to install it with 
"install.packages('PKI',,'https://www.rforge.net/')", NOT 
install.packages('PKI',,'http://www.rforge.net/'), which, for some 
inscrutable reason (runaway proxying ?) fails the same way as before.

A big Kudos and Thank You to Simon Urbanek, on behalf of not-so-stable 
distributions users !

					Emmanuel Charpentier

Original message follows :
------------------------------------------------------------------------

Dear list,

It seems that recent changes in openssl somehow broke the installation 
or update of the PKI package. This is probably specific of my setup(s) 
(Debian testing, updated frequently).

Copy of a mail to Simon Urbanek (PKI maintainer), sent 5 days ago 
without reply nor acknowledgement so far :
========================================================================

It seems that recent changes in openssl rendered the PKI package 
uninstallable :

--------------------------------------------------------------------------

> install.packages("PKI")
essai de l'URL 'http://cran.univ-paris1.fr/src/contrib/PKI_0.1-3.tar.gz'
Content type 'application/x-gzip' length 31058 bytes (30 KB)
==================================================
downloaded 30 KB

* installing *source* package ?PKI? ...
** package ?PKI? correctement d?compress? et sommes MD5 v?rifi?es
** libs
gcc -I/usr/local/sage-7/local/lib/R//include -DNDEBUG      -fpic  -g -O2 
   -c asn1.c -o asn1.o
gcc -I/usr/local/sage-7/local/lib/R//include -DNDEBUG      -fpic  -g -O2 
   -c init.c -o init.o
gcc -I/usr/local/sage-7/local/lib/R//include -DNDEBUG      -fpic  -g -O2 
   -c pki-x509.c -o pki-x509.o
pki-x509.c: In function ?PKI_extract_key?:
pki-x509.c:136:26: error: dereferencing pointer to incomplete type 
?EVP_PKEY {aka struct evp_pkey_st}?
      if (EVP_PKEY_type(key->type) != EVP_PKEY_RSA)
                           ^~
pki-x509.c: In function ?get_cipher?:
pki-x509.c:244:40: error: dereferencing pointer to incomplete type 
?EVP_CIPHER_CTX {aka struct evp_cipher_ctx_st}?
   ctx = (EVP_CIPHER_CTX*) malloc(sizeof(*ctx));
                                         ^~~~
pki-x509.c: In function ?PKI_RSAkeygen?:
pki-x509.c:550:5: warning: ?RSA_generate_key? is deprecated 
[-Wdeprecated-declarations]
      rsa = RSA_generate_key(bits, 65537, 0, 0);
      ^~~
In file included from /usr/include/openssl/rsa.h:13:0,
                  from pki.h:13,
                  from pki-x509.c:1:
/usr/include/openssl/rsa.h:193:1: note: declared here
  DEPRECATEDIN_0_9_8(RSA *RSA_generate_key(int bits, unsigned long e, void
  ^
/usr/local/sage-7/local/lib/R//etc/Makeconf:132 : la recette pour la 
cible ? pki-x509.o ? a ?chou?e
make: *** [pki-x509.o] Erreur 1
ERROR: compilation failed for package ?PKI?
* removing ?/usr/local/sage-7/local/lib/R/library/PKI?

Les packages source t?l?charg?s sont dans
     ?/tmp/Rtmpnmt97E/downloaded_packages?
Warning message:
In install.packages("PKI") :
   l'installation du package ?PKI? a eu un statut de sortie non nul

--------------------------------------------------------------------------

This problem blocks the installation of rstanarm, brms, rsconnect and 
shinystan among others. Not exactly trivial.

As far as I know, my libssl libraries are all at 1.1.0c, as well as openssl.
========================================================================

New data point : it turns out that this problem also impedes the update 
of PKI : my running R installatin still has PKI 1.3, which seems enough 
for rstanarm, brms, rsconnect and shinystan to run and install/upgrade.

However, on a new installation of R (installed in Sage), PKI can't be 
installed. I tried to install PKI 1.3 fro Rforge, with no success.

- Did someone already had this problem ?
- Has he/she been able to work around it ? If so, How ?
- Is my mail to Simon Urbanek sufficient as a bug report ? If not, what
    should I do ?

Sincerely yours,

					Emanuel Charpentier

PS : If possible, I'd appreciate to be CC'd of your answers : I'm not on 
the list and have had trouble subscribing "reasonably". I'm following it 
through the mail archives.


From ruipbarradas at sapo.pt  Mon Dec  5 17:15:58 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 05 Dec 2016 16:15:58 +0000
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <CAGxFJbRyKOJ=riezhbD1RXO9ApuvcHmT6yHwxkgLoEyL5dd4sg@mail.gmail.com>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<CAGxFJbRyKOJ=riezhbD1RXO9ApuvcHmT6yHwxkgLoEyL5dd4sg@mail.gmail.com>
Message-ID: <584592BE.2020009@sapo.pt>

Bert is right, that's exactly what I mant.

Rui Barradas

Em 05-12-2016 15:36, Bert Gunter escreveu:
> John:
>
> I think you need to re-read about how functions pass arguments and
> data frame access works in R.
>
> What Rui meant was to get rid of all the xx stuff and access your column by:
>
> col <- frame[, yy]
>
> That *does* work.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Dec 5, 2016 at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>> Rui,
>> I appreciate your suggestion, but eliminating the deparse statement does not solve my problem. Do you have any other suggestions? See code below.
>> Thank you,
>> John
>>
>>
>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>> mydf
>> class(mydf)
>>
>>
>> myfun <- function(frame,var){
>>    call <- match.call()
>>    print(call)
>>
>>
>>    indx <- match(c("frame","var"),names(call),nomatch=0)
>>    print(indx)
>>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>>
>>
>>    cat("I can get the name of the dataframe as a text string!\n")
>>    #xx <- deparse(substitute(frame))
>>    print(xx)
>>
>>
>>    cat("I can get the name of the column as a text string!\n")
>>    #yy <- deparse(substitute(var))
>>    print(yy)
>>
>>
>>    # This does not work.
>>    print(frame[,var])
>>
>>
>>    # This does not work.
>>    print(frame[,"var"])
>>
>>
>>
>>
>>    # This does not work.
>>    col <- xx[,"yy"]
>>
>>
>>    # Nor does this work.
>>    col <- xx[,yy]
>>    print(col)
>> }
>>
>>
>> myfun(mydf,age)
>>
>>
>>
>>
>> myfun()
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>>>> Rui Barradas <ruipbarradas at sapo.pt> 12/05/16 10:17 AM >>>
>> Hello,
>>
>> You don't need xx <- deparse(substitute(...)), since you are passing the
>> data.frame to your function. Just use
>>
>>
>> myfun <- function(frame,var){
>>
>>     [...]
>>
>>     # Nor does this work.
>>     col <- frame[,yy]
>>     print(col)
>> }
>>
>> myfun(mydf,age)
>> myfun(frame = mydf, var = age)
>> [1] 2 3
>> I can get the name of the dataframe as a text string!
>> [1] "mydf"
>> I can get the name of the column as a text string!
>> [1] "age"
>> [1] 20 34 43 32 21
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Em 05-12-2016 14:44, John Sorkin escreveu:
>>> I am trying to write a function which, when passed the name of a dataframe and the name of a column of the dataframe, will allow me to work on the columns of a dataframe. I can not get my code to work. Please see the code below. Any help in getting the function to work would be appreciated.
>>>
>>>
>>>
>>>
>>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>> mydf
>>> class(mydf)
>>>
>>>
>>> myfun <- function(frame,var){
>>>     call <- match.call()
>>>     print(call)
>>>
>>>
>>>     indx <- match(c("frame","var"),names(call),nomatch=0)
>>>     print(indx)
>>>     if(indx[1]==0) stop("Function called without sufficient arguments!")
>>>
>>>
>>>     cat("I can get the name of the dataframe as a text string!\n")
>>>     xx <- deparse(substitute(frame))
>>>     print(xx)
>>>
>>>
>>>     cat("I can get the name of the column as a text string!\n")
>>>     yy <- deparse(substitute(var))
>>>     print(yy)
>>>
>>>
>>>     # This does not work.
>>>     col <- xx[,"yy"]
>>>
>>>
>>>     # Nor does this work.
>>>     col <- xx[,yy]
>>>     print(col)
>>> }
>>>
>>>
>>> myfun(mydf,age)
>>>
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine
>>> Chief, Biostatistics and Informatics
>>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>>> Baltimore VA Medical Center
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> (Phone) 410-605-7119
>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>
>>>
>>>
>>>
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine
>>> Chief, Biostatistics and Informatics
>>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>>> Baltimore VA Medical Center
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> (Phone) 410-605-7119
>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>
>>>
>>>
>>>
>>>
>>> Confidentiality Statement:
>>> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Dec  5 17:20:46 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 05 Dec 2016 16:20:46 +0000
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <58454178020000CB00168A55@smtp.medicine.umaryland.edu>
References: 58452E93.medlxdom.medlxpo.200.20000CB.1.1689F1.1
	<5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
Message-ID: <584593DE.4020907@sapo.pt>

Hello,

For some reason I got moderation in reply to Bert's post so I'll retry.
Get rid of 'xx', keep 'yy':

frame[, yy]  # this works

Hope this helps,

Rui Barradas

Em 05-12-2016 15:29, John Sorkin escreveu:
> Rui,
> I appreciate your suggestion, but eliminating the deparse statement does
> not solve my problem. Do you have any other suggestions? See code below.
> Thank you,
> John
>
> mydf <-
> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
>
> myfun <- function(frame,var){
>    call <- match.call()
>    print(call)
>
>    indx <- match(c("frame","var"),names(call),nomatch=0)
>    print(indx)
>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>
>    cat("I can get the name of the dataframe as a text string!\n")
>    #xx <- deparse(substitute(frame))
>    print(xx)
>
>    cat("I can get the name of the column as a text string!\n")
>    #yy <- deparse(substitute(var))
>    print(yy)
>
>    # This does not work.
>    print(frame[,var])
>
>    # This does not work.
>    print(frame[,"var"])
>
>
>    # This does not work.
>    col <- xx[,"yy"]
>
>    # Nor does this work.
>    col <- xx[,yy]
>    print(col)
> }
>
> myfun(mydf,age)
>
>
> myfun()
>
>
>
>
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>  >>> Rui Barradas <ruipbarradas at sapo.pt> 12/05/16 10:17 AM >>>
> Hello,
>
> You don't need xx <- deparse(substitute(...)), since you are passing the
> data.frame to your function. Just use
>
>
> myfun <- function(frame,var){
>
> [...]
>
> # Nor does this work.
> col <- frame[,yy]
> print(col)
> }
>
> myfun(mydf,age)
> myfun(frame = mydf, var = age)
> [1] 2 3
> I can get the name of the dataframe as a text string!
> [1] "mydf"
> I can get the name of the column as a text string!
> [1] "age"
> [1] 20 34 43 32 21
>
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 05-12-2016 14:44, John Sorkin escreveu:
>  > I am trying to write a function which, when passed the name of a
> dataframe and the name of a column of the dataframe, will allow me to
> work on the columns of a dataframe. I can not get my code to work.
> Please see the code below. Any help in getting the function to work
> would be appreciated.
>  >
>  >
>  >
>  >
>  > mydf <-
> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>  > mydf
>  > class(mydf)
>  >
>  >
>  > myfun <- function(frame,var){
>  > call <- match.call()
>  > print(call)
>  >
>  >
>  > indx <- match(c("frame","var"),names(call),nomatch=0)
>  > print(indx)
>  > if(indx[1]==0) stop("Function called without sufficient arguments!")
>  >
>  >
>  > cat("I can get the name of the dataframe as a text string!\n")
>  > xx <- deparse(substitute(frame))
>  > print(xx)
>  >
>  >
>  > cat("I can get the name of the column as a text string!\n")
>  > yy <- deparse(substitute(var))
>  > print(yy)
>  >
>  >
>  > # This does not work.
>  > col <- xx[,"yy"]
>  >
>  >
>  > # Nor does this work.
>  > col <- xx[,yy]
>  > print(col)
>  > }
>  >
>  >
>  > myfun(mydf,age)
>  >
>  > John David Sorkin M.D., Ph.D.
>  > Professor of Medicine
>  > Chief, Biostatistics and Informatics
>  > University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>  > Baltimore VA Medical Center
>  > 10 North Greene Street
>  > GRECC (BT/18/GR)
>  > Baltimore, MD 21201-1524
>  > (Phone) 410-605-7119
>  > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>  >
>  >
>  >
>  >
>  > John David Sorkin M.D., Ph.D.
>  > Professor of Medicine
>  > Chief, Biostatistics and Informatics
>  > University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
>  > Baltimore VA Medical Center
>  > 10 North Greene Street
>  > GRECC (BT/18/GR)
>  > Baltimore, MD 21201-1524
>  > (Phone) 410-605-7119
>  > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>  >
>  >
>  >
>  >
>  >
>  > Confidentiality Statement:
>  > This email message, including any attachments, is for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply email and destroy all copies of the original message.
>  > ______________________________________________
>  > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal, self-contained, reproducible code.
>  >
>
>
> _*Confidentiality Statement:*_
>
> This email message, including any attachments, is for ...{{dropped:7}}


From SWay at meco.com  Mon Dec  5 20:16:07 2016
From: SWay at meco.com (Shawn Way)
Date: Mon, 5 Dec 2016 19:16:07 +0000
Subject: [R] Using ggplot2 to plot percentages in bar chart.
Message-ID: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>

I have the following data in which I'm trying to summarize in a stacked bar plot showing the percentages as a label in the bar.

The data is as follows:

> head(data)
  MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
1            X            X            X             X             X
2            C            C            C             X             X
3            C            C            C             X             X
4            U            U            X             X             X
5         <NA>            U            X             X             X
6         <NA>         <NA>            X          <NA>          <NA>

It is then transformed using dplyer:

> d2 <- data %>%
    gather(Model,Status) %>%
    group_by(Model,Status) %>%
    summarise(count=n()) %>%
    mutate(perc=count/sum(count))

giving 
> head (d2)
Source: local data frame [6 x 4]
Groups: Model [2]

          Model Status count       perc
          <chr>  <chr> <int>      <dbl>
1 MASTERPAK10LT      C     8 0.21052632
2 MASTERPAK10LT      X    29 0.76315789
3 MASTERPAK10LT   <NA>     1 0.02631579
4 MASTERPAK22LT      C     6 0.15789474
5 MASTERPAK22LT      U     1 0.02631579
6 MASTERPAK22LT      X    30 0.78947368

I then try to plot this using ggplot using 

plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
    geom_bar(stat="identity") +
    labs(y="Percent Complete") +
    stat_bin(geom = "text",
             aes(label=paste(round(perc*100),"%")),
             vjust=5) +
    scale_y_continuous(labels = percent)

but I get the error:

Error: stat_bin() must not be used with a y aesthetic.

When I leave out the stat_bin, I get the correct bar chart, but without the labels.  Can someone please help me understand what is causing the error above?


Thank you kindly,

Shawn Way, PE


From ruipbarradas at sapo.pt  Mon Dec  5 18:53:35 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 05 Dec 2016 17:53:35 +0000
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
Message-ID: <5845A99F.3060105@sapo.pt>

Hello,

Inline.

Em 05-12-2016 17:09, David Winsemius escreveu:
>
>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>>
>> Rui,
>> I appreciate your suggestion, but eliminating the deparse statement does not solve my problem. Do you have any other suggestions? See code below.
>> Thank you,
>> John
>>
>>
>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>> mydf
>> class(mydf)
>>
>>
>> myfun <- function(frame,var){
>>   call <- match.call()
>>   print(call)
>>
>>
>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>   print(indx)
>>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>>
>>
>>   cat("I can get the name of the dataframe as a text string!\n")
>>   #xx <- deparse(substitute(frame))
>>   print(xx)
>>
>>
>>   cat("I can get the name of the column as a text string!\n")
>>   #yy <- deparse(substitute(var))
>>   print(yy)
>>
>>
>>   # This does not work.
>>   print(frame[,var])
>>
>>
>>   # This does not work.
>>   print(frame[,"var"])
>>
>>
>>
>>
>>   # This does not work.
>>   col <- xx[,"yy"]
>>
>>
>>   # Nor does this work.
>>   col <- xx[,yy]
>>   print(col)
>> }
>>
>>
>> myfun(mydf,age)
>
>
> When you use that calling syntax, the system will supply the values of whatever the `age` variable contains. (And if there is no `age`-named object, you get an error at the time of the call to `myfun`.

Actually, no, which was very surprising to me but John's code worked 
(not the function, the call). And with the change I've proposed, it 
worked flawlessly. No errors. Why I don't know.

Rui Barradas

  You need either to call it as:
>
> myfun( mydf , "age")
>
>
> # Or:
>
> age <- "age"
> myfun( mydf, age)
>
> Unless your value of the `age`-named variable was "age" in the calling environment (and you did not give us that value in either of your postings), you would fail.
>


From davidsmi at microsoft.com  Mon Dec  5 21:22:39 2016
From: davidsmi at microsoft.com (David Smith)
Date: Mon, 5 Dec 2016 20:22:39 +0000
Subject: [R] Revolutions blog: November 2016 roundup
Message-ID: <CY1PR0301MB2105DBDC89C922A0CC212223C8830@CY1PR0301MB2105.namprd03.prod.outlook.com>

Since 2008, Microsoft (formerly Revolution Analytics) staff and guests have written about R every weekday at the
Revolutions blog: http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help.

And in case you missed them, here are some articles related to R from the month of November:

Microsoft R Open 3.3.2, based on R 3.3.2, has been released for Windows, Mac and Linux:
http://blog.revolutionanalytics.com/2016/11/mro-332-now-available.html

A new, free course on EdX focuses on the big-data extensions of Microsoft R Server:
http://blog.revolutionanalytics.com/2016/11/edx-microsoft-r.html

Using ggplot2 to create a calendar heat map of city bike usage in Chicago:
http://blog.revolutionanalytics.com/2016/11/divvy-chicago.html

A tutorial on creating an in-database rental prediction service for a ski shop with SQL Server R Services:
http://blog.revolutionanalytics.com/2016/11/r-services-intelligent-app.html

Detailed R code to calculate AUC, the area under a ROC curve:
http://blog.revolutionanalytics.com/2016/11/calculating-auc.html

Rankings of the 5 most popular R packages by downloads (with and without dependencies):
http://blog.revolutionanalytics.com/2016/11/most-popular-r-packages.html

Using computer vision algorithms from R to find images in a photomosaic:
http://blog.revolutionanalytics.com/2016/11/deep-learning-mona-lisa.html

Airbnb has released the knowledge repository they use to share data science reports generated using R:
http://blog.revolutionanalytics.com/2016/11/airbnb-growth.html

Using the sparklyr package to manipulate data on Azure HDInsight:
http://blog.revolutionanalytics.com/2016/11/data-manipulation-with-sparklyr-on-azure-hdinsight.html

The dplyrXdf package has been updated to provide subsetting and column subsetting for out-of-memory XDF files:
http://blog.revolutionanalytics.com/2016/11/update-to-dplyrxdf.html

RStudio v1.0 has been released: http://blog.revolutionanalytics.com/2016/11/rstudio-v10-released.html

Charting historical baseball statistics with the Lahman package:
http://blog.revolutionanalytics.com/2016/11/a-look-back-at-the-cubs-and-indians-performance.html

This Bayesian US election prediction model, implemented with R and Stan, turned out to be not so successful:
http://blog.revolutionanalytics.com/2016/11/a-bayesian-election-forecast.html

Making elastic net regression with glmnet a little easier: the glmnetUtils package:
http://blog.revolutionanalytics.com/2016/11/glmnetutils.html

A list of notable new and updated R packages: http://blog.revolutionanalytics.com/2016/11/spotlights-october-2016.html

A tutorial on calling the Cognitive Services text analytics APIs from R:
http://blog.revolutionanalytics.com/2016/11/how-to-call-cognitive-services-apis-with-r.html

Some lessons and examples on migrating financial data applications from SAS to R:
http://blog.revolutionanalytics.com/2016/11/sas-to-r-migration.html

General interest stories (not related to R) in the past month included: giving thanks
(http://blog.revolutionanalytics.com/2016/11/happy-thanksgiving.html), non-transitive dice
(http://blog.revolutionanalytics.com/2016/11/because-its-friday-non-transitive-dice.html), the most unsatisfying film
(http://blog.revolutionanalytics.com/2016/11/because-its-friday-current-status.html), the US election surprise
(http://blog.revolutionanalytics.com/2016/11/how-did-the-election-forecasts-get-it-so-wrong.html), and the Cubs win
(http://blog.revolutionanalytics.com/2016/11/because-its-friday-we-went-all-the-way.html).

If you're looking for more articles about R, you can find summaries from previous months at
http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like
blogtrottr.com.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter
(I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft? 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From dwinsemius at comcast.net  Mon Dec  5 21:34:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Dec 2016 12:34:26 -0800
Subject: [R] Write a function that allows access to columns of a passed
	dataframe.
In-Reply-To: <5845A99F.3060105@sapo.pt>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
Message-ID: <8A4A8487-5303-4E2A-8D05-F7A44E86ACD7@comcast.net>


> On Dec 5, 2016, at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Inline.
> 
> Em 05-12-2016 17:09, David Winsemius escreveu:
>> 
>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>>> 
>>> Rui,
>>> I appreciate your suggestion, but eliminating the deparse statement does not solve my problem. Do you have any other suggestions? See code below.
>>> Thank you,
>>> John
>>> 
>>> 
>>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>> mydf
>>> class(mydf)
>>> 
>>> 
>>> myfun <- function(frame,var){
>>>  call <- match.call()
>>>  print(call)
>>> 
>>> 
>>>  indx <- match(c("frame","var"),names(call),nomatch=0)
>>>  print(indx)
>>>  if(indx[1]==0) stop("Function called without sufficient arguments!")
>>> 
>>> 
>>>  cat("I can get the name of the dataframe as a text string!\n")
>>>  #xx <- deparse(substitute(frame))
>>>  print(xx)
>>> 
>>> 
>>>  cat("I can get the name of the column as a text string!\n")
>>>  #yy <- deparse(substitute(var))
>>>  print(yy)
>>> 
>>> 
>>>  # This does not work.
>>>  print(frame[,var])
>>> 
>>> 
>>>  # This does not work.
>>>  print(frame[,"var"])
>>> 
>>> 
>>> 
>>> 
>>>  # This does not work.
>>>  col <- xx[,"yy"]
>>> 
>>> 
>>>  # Nor does this work.
>>>  col <- xx[,yy]
>>>  print(col)
>>> }
>>> 
>>> 
>>> myfun(mydf,age)
>> 
>> 
>> When you use that calling syntax, the system will supply the values of whatever the `age` variable contains. (And if there is no `age`-named object, you get an error at the time of the call to `myfun`.
> 
> Actually, no, which was very surprising to me but John's code worked (not the function, the call). And with the change I've proposed, it worked flawlessly. No errors. Why I don't know.

I see. Must be one of those "promise" things. It appears that if you don't actually require the value you can just pass a name with no value?

Thanks for the correction.

-- 
David.


> 
> Rui Barradas
> 
> You need either to call it as:
>> 
>> myfun( mydf , "age")
>> 
>> 
>> # Or:
>> 
>> age <- "age"
>> myfun( mydf, age)
>> 
>> Unless your value of the `age`-named variable was "age" in the calling environment (and you did not give us that value in either of your postings), you would fail.
>> 

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Mon Dec  5 22:01:34 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Dec 2016 08:01:34 +1100
Subject: [R] scatter plot of numerical variables against different
	sample ids
In-Reply-To: <1198746852.10979303.1480940751156@mail.yahoo.com>
References: <1198746852.10979303.1480940751156.ref@mail.yahoo.com>
	<1198746852.10979303.1480940751156@mail.yahoo.com>
Message-ID: <CA+8X3fWDN3_VsrFiec=matg815Aa81okf2u+JSL=FDmke1WnVA@mail.gmail.com>

Hi Maria,
Perhaps something like this:

 mldf<-read.table(text="Sample  Cu  Zn Mn
 M1 1  5  10
 M2  2.5  11   8
 M3 1.15  11  12
 M4  2  4  30
 M5  8  15 35",
 header=TRUE)
 matplot(mldf,type="b",pch=c("C","Z","M"))

Jim


On Mon, Dec 5, 2016 at 11:25 PM, Maria Lathouri via R-help
<r-help at r-project.org> wrote:
> Dear all
> I know that my question is very simple but although I tried to find an answer online, I couldn't and I am stuck.
> I have a dataset of three numerical variables measured in different samples ID. Something like this:
> Sample        Cu        Zn        MnM1               1          5          10M2               2.5       11          8M3              1.15      11         12  M4                2         4          30M5                8        15         35
> I would like to plot these variables (Cu, Zn, Mn) (in y-axis) against the Sample ID (in x-axis) in a scatter plot with lines as I want to see how they change in the samples.
> I tried using the command>plot(Sample, Cu, type="l", lty=1, col="red")
> but I wouldn't get a line. Actually, I would get some small horizontal lines in each point. I tried to use type="p" but I would get the same thing.
> I would very much appreciate if you could help me on that. Apparently, I am missing something.
> Thank you in advance.
> Kind regards,Maria
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Mon Dec  5 22:09:22 2016
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Mon, 5 Dec 2016 16:09:22 -0500
Subject: [R] Forecast Modeling using R model node in SPSS Modeler
Message-ID: <CAMOcQfORcRo2T2tuVBXiJ56N2wuKUrrMPH0z7AnNap-9-jiSQA@mail.gmail.com>

Hello everyone,

I have been trying really hard to use the SPSS Modeler?s R modeling node to
generate forecasts without success. I personally think the R integration in
SPSS Modeler is kind of poor, since you are only allowed to work with R
version 2.15.2.

Is there anyone who has worked time series and forecasting models using the
R nodes from SPSS Modeler? Is there any document or any guide that you guys
could provide me with?

Best regards,

Paul

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon Dec  5 22:31:25 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 5 Dec 2016 16:31:25 -0500
Subject: [R] Forecast Modeling using R model node in SPSS Modeler
In-Reply-To: <CAMOcQfORcRo2T2tuVBXiJ56N2wuKUrrMPH0z7AnNap-9-jiSQA@mail.gmail.com>
References: <CAMOcQfORcRo2T2tuVBXiJ56N2wuKUrrMPH0z7AnNap-9-jiSQA@mail.gmail.com>
Message-ID: <CA+vqiLErvAgnFNRizLTqP_x4uTwfpcwFTQEBW5m6_RkqjobARQ@mail.gmail.com>

Hi Paul,

I suggest forgetting about SPSS and using R directly. Getting started
with R is easier than ever thanks to the growing number of tutorials,
workshops, mailing lists and forums.

Best,
Ista

On Mon, Dec 5, 2016 at 4:09 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> Hello everyone,
>
> I have been trying really hard to use the SPSS Modeler?s R modeling node to
> generate forecasts without success. I personally think the R integration in
> SPSS Modeler is kind of poor, since you are only allowed to work with R
> version 2.15.2.
>
> Is there anyone who has worked time series and forecasting models using the
> R nodes from SPSS Modeler? Is there any document or any guide that you guys
> could provide me with?
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Dec  5 22:34:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Dec 2016 13:34:28 -0800
Subject: [R] Write a function that allows access to columns of a passed
	dataframe.
In-Reply-To: <5845A99F.3060105@sapo.pt>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
Message-ID: <CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>

Inline.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Inline.
>
> Em 05-12-2016 17:09, David Winsemius escreveu:
>>
>>
>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>> wrote:
>>>
>>> Rui,
>>> I appreciate your suggestion, but eliminating the deparse statement does
>>> not solve my problem. Do you have any other suggestions? See code below.
>>> Thank you,
>>> John
>>>
>>>
>>> mydf <-
>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>> mydf
>>> class(mydf)
>>>
>>>
>>> myfun <- function(frame,var){
>>>   call <- match.call()
>>>   print(call)
>>>
>>>
>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>>   print(indx)
>>>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>>>
>>>
>>>   cat("I can get the name of the dataframe as a text string!\n")
>>>   #xx <- deparse(substitute(frame))
>>>   print(xx)
>>>
>>>
>>>   cat("I can get the name of the column as a text string!\n")
>>>   #yy <- deparse(substitute(var))
>>>   print(yy)
>>>
>>>
>>>   # This does not work.
>>>   print(frame[,var])
>>>
>>>
>>>   # This does not work.
>>>   print(frame[,"var"])
>>>
>>>
>>>
>>>
>>>   # This does not work.
>>>   col <- xx[,"yy"]
>>>
>>>
>>>   # Nor does this work.
>>>   col <- xx[,yy]
>>>   print(col)
>>> }
>>>
>>>
>>> myfun(mydf,age)
>>
>>
>>
>> When you use that calling syntax, the system will supply the values of
>> whatever the `age` variable contains. (And if there is no `age`-named
>> object, you get an error at the time of the call to `myfun`.
>
>
> Actually, no, which was very surprising to me but John's code worked (not
> the function, the call). And with the change I've proposed, it worked
> flawlessly. No errors. Why I don't know.
>
> Rui Barradas
>
>  You need either to call it as:
>>
>>
>> myfun( mydf , "age")
>>
>>
>> # Or:
>>
>> age <- "age"
>> myfun( mydf, age)
>>
>> Unless your value of the `age`-named variable was "age" in the calling
>> environment (and you did not give us that value in either of your postings),
>> you would fail.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Dec  5 22:46:12 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Dec 2016 13:46:12 -0800
Subject: [R] Write a function that allows access to columns of a passed
	dataframe.
In-Reply-To: <CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
Message-ID: <CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>

Sorry, hit "Send" by mistake.

Inline.



On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Inline.
>
> -- Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Inline.
>>
>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>>
>>>
>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>>> wrote:
>>>>
>>>> Rui,
>>>> I appreciate your suggestion, but eliminating the deparse statement does
>>>> not solve my problem. Do you have any other suggestions? See code below.
>>>> Thank you,
>>>> John
>>>>
>>>>
>>>> mydf <-
>>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>>> mydf
>>>> class(mydf)
>>>>
>>>>
>>>> myfun <- function(frame,var){
>>>>   call <- match.call()
>>>>   print(call)
>>>>
>>>>
>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>>>   print(indx)
>>>>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>>>>
>>>>
>>>>   cat("I can get the name of the dataframe as a text string!\n")
>>>>   #xx <- deparse(substitute(frame))
>>>>   print(xx)
>>>>
>>>>
>>>>   cat("I can get the name of the column as a text string!\n")
>>>>   #yy <- deparse(substitute(var))
>>>>   print(yy)
>>>>
>>>>
>>>>   # This does not work.
>>>>   print(frame[,var])
>>>>
>>>>
>>>>   # This does not work.
>>>>   print(frame[,"var"])
>>>>
>>>>
>>>>
>>>>
>>>>   # This does not work.
>>>>   col <- xx[,"yy"]
>>>>
>>>>
>>>>   # Nor does this work.
>>>>   col <- xx[,yy]
>>>>   print(col)
>>>> }
>>>>
>>>>
>>>> myfun(mydf,age)
>>>
>>>
>>>
>>> When you use that calling syntax, the system will supply the values of
>>> whatever the `age` variable contains. (And if there is no `age`-named
>>> object, you get an error at the time of the call to `myfun`.
>>
>>
>> Actually, no, which was very surprising to me but John's code worked (not
>> the function, the call). And with the change I've proposed, it worked
>> flawlessly. No errors. Why I don't know.

See ?substitute and in particular the example highlighted there.

The technical details are explained in the R Language Definition
manual. The key here is the use of promises for lay evaluations. In
fact, the expression in the call *is* available within the functions,
as is (a pointer to) the environment in which to evaluate the
expression. That is how substitute() works. Specifically, quoting from
the manual,

*****
It is possible to access the actual (not default) expressions used as
arguments inside the function. The mechanism is implemented via
promises. When a function is being evaluated the actual expression
used as an argument is stored in the promise together with a pointer
to the environment the function was called from. When (if) the
argument is evaluated the stored expression is evaluated in the
environment that the function was called from. Since only a pointer to
the environment is used any changes made to that environment will be
in effect during this evaluation. The resulting value is then also
stored in a separate spot in the promise. Subsequent evaluations
retrieve this stored value (a second evaluation is not carried out).
Access to the unevaluated expression is also available using
substitute.
********

-- Bert




>>
>> Rui Barradas
>>
>>  You need either to call it as:
>>>
>>>
>>> myfun( mydf , "age")
>>>
>>>
>>> # Or:
>>>
>>> age <- "age"
>>> myfun( mydf, age)
>>>
>>> Unless your value of the `age`-named variable was "age" in the calling
>>> environment (and you did not give us that value in either of your postings),
>>> you would fail.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Mon Dec  5 22:49:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Dec 2016 13:49:07 -0800
Subject: [R] Write a function that allows access to columns of a passed
	dataframe.
In-Reply-To: <CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
Message-ID: <CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>

Typo: "lazy evaluation" not "lay evaluation."

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Sorry, hit "Send" by mistake.
>
> Inline.
>
>
>
> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Inline.
>>
>> -- Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>> Hello,
>>>
>>> Inline.
>>>
>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>>>
>>>>
>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>>>> wrote:
>>>>>
>>>>> Rui,
>>>>> I appreciate your suggestion, but eliminating the deparse statement does
>>>>> not solve my problem. Do you have any other suggestions? See code below.
>>>>> Thank you,
>>>>> John
>>>>>
>>>>>
>>>>> mydf <-
>>>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>>>> mydf
>>>>> class(mydf)
>>>>>
>>>>>
>>>>> myfun <- function(frame,var){
>>>>>   call <- match.call()
>>>>>   print(call)
>>>>>
>>>>>
>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>>>>   print(indx)
>>>>>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>>>>>
>>>>>
>>>>>   cat("I can get the name of the dataframe as a text string!\n")
>>>>>   #xx <- deparse(substitute(frame))
>>>>>   print(xx)
>>>>>
>>>>>
>>>>>   cat("I can get the name of the column as a text string!\n")
>>>>>   #yy <- deparse(substitute(var))
>>>>>   print(yy)
>>>>>
>>>>>
>>>>>   # This does not work.
>>>>>   print(frame[,var])
>>>>>
>>>>>
>>>>>   # This does not work.
>>>>>   print(frame[,"var"])
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>   # This does not work.
>>>>>   col <- xx[,"yy"]
>>>>>
>>>>>
>>>>>   # Nor does this work.
>>>>>   col <- xx[,yy]
>>>>>   print(col)
>>>>> }
>>>>>
>>>>>
>>>>> myfun(mydf,age)
>>>>
>>>>
>>>>
>>>> When you use that calling syntax, the system will supply the values of
>>>> whatever the `age` variable contains. (And if there is no `age`-named
>>>> object, you get an error at the time of the call to `myfun`.
>>>
>>>
>>> Actually, no, which was very surprising to me but John's code worked (not
>>> the function, the call). And with the change I've proposed, it worked
>>> flawlessly. No errors. Why I don't know.
>
> See ?substitute and in particular the example highlighted there.
>
> The technical details are explained in the R Language Definition
> manual. The key here is the use of promises for lay evaluations. In
> fact, the expression in the call *is* available within the functions,
> as is (a pointer to) the environment in which to evaluate the
> expression. That is how substitute() works. Specifically, quoting from
> the manual,
>
> *****
> It is possible to access the actual (not default) expressions used as
> arguments inside the function. The mechanism is implemented via
> promises. When a function is being evaluated the actual expression
> used as an argument is stored in the promise together with a pointer
> to the environment the function was called from. When (if) the
> argument is evaluated the stored expression is evaluated in the
> environment that the function was called from. Since only a pointer to
> the environment is used any changes made to that environment will be
> in effect during this evaluation. The resulting value is then also
> stored in a separate spot in the promise. Subsequent evaluations
> retrieve this stored value (a second evaluation is not carried out).
> Access to the unevaluated expression is also available using
> substitute.
> ********
>
> -- Bert
>
>
>
>
>>>
>>> Rui Barradas
>>>
>>>  You need either to call it as:
>>>>
>>>>
>>>> myfun( mydf , "age")
>>>>
>>>>
>>>> # Or:
>>>>
>>>> age <- "age"
>>>> myfun( mydf, age)
>>>>
>>>> Unless your value of the `age`-named variable was "age" in the calling
>>>> environment (and you did not give us that value in either of your postings),
>>>> you would fail.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From SWay at meco.com  Mon Dec  5 23:24:01 2016
From: SWay at meco.com (Shawn Way)
Date: Mon, 5 Dec 2016 22:24:01 +0000
Subject: [R] scatter plot of numerical variables against
 different	sample ids
In-Reply-To: <CA+8X3fWDN3_VsrFiec=matg815Aa81okf2u+JSL=FDmke1WnVA@mail.gmail.com>
References: <1198746852.10979303.1480940751156.ref@mail.yahoo.com>
	<1198746852.10979303.1480940751156@mail.yahoo.com>
	<CA+8X3fWDN3_VsrFiec=matg815Aa81okf2u+JSL=FDmke1WnVA@mail.gmail.com>
Message-ID: <109c936bf6754f94992a8966ee27f25e@CTC-HOU-EXMB-02.ctcloud.local>

You can also try using ggplot2 to generate the plot:

> library(tidyr)
> library(ggplot2)
> data <- gather(mldf,Element,Value,2:4)
> p <- ggplot(data,aes(x=factor(Element),y=Value,group=Sample,color=Sample))
> p+geom_line()

Shawn Way, PE

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Monday, December 05, 2016 3:02 PM
To: Maria Lathouri <mlathouri at yahoo.gr>
Cc: R-help Mailing List <r-help at r-project.org>
Subject: Re: [R] scatter plot of numerical variables against different sample ids

Hi Maria,
Perhaps something like this:

 mldf<-read.table(text="Sample  Cu  Zn Mn
 M1 1  5  10
 M2  2.5  11   8
 M3 1.15  11  12
 M4  2  4  30
 M5  8  15 35",
 header=TRUE)
 matplot(mldf,type="b",pch=c("C","Z","M"))

Jim


On Mon, Dec 5, 2016 at 11:25 PM, Maria Lathouri via R-help <r-help at r-project.org> wrote:
> Dear all
> I know that my question is very simple but although I tried to find an answer online, I couldn't and I am stuck.
> I have a dataset of three numerical variables measured in different samples ID. Something like this:
> Sample        Cu        Zn        MnM1               1          5          10M2               2.5       11          8M3              1.15      11         12  M4                2         4          30M5                8        15         35
> I would like to plot these variables (Cu, Zn, Mn) (in y-axis) against the Sample ID (in x-axis) in a scatter plot with lines as I want to see how they change in the samples.
> I tried using the command>plot(Sample, Cu, type="l", lty=1, col="red") 
> but I wouldn't get a line. Actually, I would get some small horizontal lines in each point. I tried to use type="p" but I would get the same thing.
> I would very much appreciate if you could help me on that. Apparently, I am missing something.
> Thank you in advance.
> Kind regards,Maria
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From SWay at meco.com  Mon Dec  5 23:56:49 2016
From: SWay at meco.com (Shawn Way)
Date: Mon, 5 Dec 2016 22:56:49 +0000
Subject: [R] Using ggplot2 to plot percentages in bar chart.
In-Reply-To: <520051953.59722.1480977991169@mail.yahoo.com>
References: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
	<520051953.59722.1480977991169@mail.yahoo.com>
Message-ID: <52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>

That?s precisely what I?m trying to accomplish.

Shawn Way, PE

From: John Kane [mailto:jrkrideau at yahoo.ca]
Sent: Monday, December 05, 2016 4:47 PM
To: Shawn Way <SWay at meco.com>; r-help at r-project.org
Subject: Re: [R] Using ggplot2 to plot percentages in bar chart.

I've never seen   stat_bin used like that. What exactly is it supposed to do. It looks like you are trying to label the %ages in each piece of the bar.

On Monday, December 5, 2016 2:17 PM, Shawn Way <SWay at meco.com<mailto:SWay at meco.com>> wrote:

I have the following data in which I'm trying to summarize in a stacked bar plot showing the percentages as a label in the bar.

The data is as follows:

> head(data)
  MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
1            X            X            X            X            X
2            C            C            C            X            X
3            C            C            C            X            X
4            U            U            X            X            X
5        <NA>            U            X            X            X
6        <NA>        <NA>            X          <NA>          <NA>

It is then transformed using dplyer:

> d2 <- data %>%
    gather(Model,Status) %>%
    group_by(Model,Status) %>%
    summarise(count=n()) %>%
    mutate(perc=count/sum(count))

giving
> head (d2)
Source: local data frame [6 x 4]
Groups: Model [2]

          Model Status count      perc
          <chr>  <chr> <int>      <dbl>
1 MASTERPAK10LT      C    8 0.21052632
2 MASTERPAK10LT      X    29 0.76315789
3 MASTERPAK10LT  <NA>    1 0.02631579
4 MASTERPAK22LT      C    6 0.15789474
5 MASTERPAK22LT      U    1 0.02631579
6 MASTERPAK22LT      X    30 0.78947368

I then try to plot this using ggplot using

plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
    geom_bar(stat="identity") +
    labs(y="Percent Complete") +
    stat_bin(geom = "text",
            aes(label=paste(round(perc*100),"%")),
            vjust=5) +
    scale_y_continuous(labels = percent)

but I get the error:

Error: stat_bin() must not be used with a y aesthetic.

When I leave out the stat_bin, I get the correct bar chart, but without the labels.  Can someone please help me understand what is causing the error above?


Thank you kindly,

Shawn Way, PE

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Mon Dec  5 23:46:31 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 5 Dec 2016 22:46:31 +0000 (UTC)
Subject: [R] Using ggplot2 to plot percentages in bar chart.
In-Reply-To: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
References: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <520051953.59722.1480977991169@mail.yahoo.com>

I've never seen ? stat_bin used like that. What exactly is it supposed to do. It looks like you are trying to label the %ages in each piece of the bar.
 

    On Monday, December 5, 2016 2:17 PM, Shawn Way <SWay at meco.com> wrote:
 

 I have the following data in which I'm trying to summarize in a stacked bar plot showing the percentages as a label in the bar.

The data is as follows:

> head(data)
? MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
1? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X
2? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? X? ? ? ? ? ? X
3? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? X? ? ? ? ? ? X
4? ? ? ? ? ? U? ? ? ? ? ? U? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X
5? ? ? ? <NA>? ? ? ? ? ? U? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X
6? ? ? ? <NA>? ? ? ? <NA>? ? ? ? ? ? X? ? ? ? ? <NA>? ? ? ? ? <NA>

It is then transformed using dplyer:

> d2 <- data %>%
? ? gather(Model,Status) %>%
? ? group_by(Model,Status) %>%
? ? summarise(count=n()) %>%
? ? mutate(perc=count/sum(count))

giving 
> head (d2)
Source: local data frame [6 x 4]
Groups: Model [2]

? ? ? ? ? Model Status count? ? ? perc
? ? ? ? ? <chr>? <chr> <int>? ? ? <dbl>
1 MASTERPAK10LT? ? ? C? ? 8 0.21052632
2 MASTERPAK10LT? ? ? X? ? 29 0.76315789
3 MASTERPAK10LT? <NA>? ? 1 0.02631579
4 MASTERPAK22LT? ? ? C? ? 6 0.15789474
5 MASTERPAK22LT? ? ? U? ? 1 0.02631579
6 MASTERPAK22LT? ? ? X? ? 30 0.78947368

I then try to plot this using ggplot using 

plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
? ? geom_bar(stat="identity") +
? ? labs(y="Percent Complete") +
? ? stat_bin(geom = "text",
? ? ? ? ? ? aes(label=paste(round(perc*100),"%")),
? ? ? ? ? ? vjust=5) +
? ? scale_y_continuous(labels = percent)

but I get the error:

Error: stat_bin() must not be used with a y aesthetic.

When I leave out the stat_bin, I get the correct bar chart, but without the labels.? Can someone please help me understand what is causing the error above?


Thank you kindly,

Shawn Way, PE

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Tue Dec  6 06:58:21 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Tue, 06 Dec 2016 05:58:21 +0000
Subject: [R] Using ggplot2 to plot percentages in bar chart.
In-Reply-To: <52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
References: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
	<520051953.59722.1480977991169@mail.yahoo.com>
	<52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <CAKVAULMHSceCUfTTJRLS1gru4GE5hSiYC41a7VNhCLaBdgga_g@mail.gmail.com>

I always use geom_text when I want to add text or labels to a plot.

HTH
Ulrik

Shawn Way <SWay at meco.com> schrieb am Mo., 5. Dez. 2016, 23:58:

> That?s precisely what I?m trying to accomplish.
>
> Shawn Way, PE
>
> From: John Kane [mailto:jrkrideau at yahoo.ca]
> Sent: Monday, December 05, 2016 4:47 PM
> To: Shawn Way <SWay at meco.com>; r-help at r-project.org
> Subject: Re: [R] Using ggplot2 to plot percentages in bar chart.
>
> I've never seen   stat_bin used like that. What exactly is it supposed to
> do. It looks like you are trying to label the %ages in each piece of the
> bar.
>
> On Monday, December 5, 2016 2:17 PM, Shawn Way <SWay at meco.com<mailto:
> SWay at meco.com>> wrote:
>
> I have the following data in which I'm trying to summarize in a stacked
> bar plot showing the percentages as a label in the bar.
>
> The data is as follows:
>
> > head(data)
>   MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
> 1            X            X            X            X            X
> 2            C            C            C            X            X
> 3            C            C            C            X            X
> 4            U            U            X            X            X
> 5        <NA>            U            X            X            X
> 6        <NA>        <NA>            X          <NA>          <NA>
>
> It is then transformed using dplyer:
>
> > d2 <- data %>%
>     gather(Model,Status) %>%
>     group_by(Model,Status) %>%
>     summarise(count=n()) %>%
>     mutate(perc=count/sum(count))
>
> giving
> > head (d2)
> Source: local data frame [6 x 4]
> Groups: Model [2]
>
>           Model Status count      perc
>           <chr>  <chr> <int>      <dbl>
> 1 MASTERPAK10LT      C    8 0.21052632
> 2 MASTERPAK10LT      X    29 0.76315789
> 3 MASTERPAK10LT  <NA>    1 0.02631579
> 4 MASTERPAK22LT      C    6 0.15789474
> 5 MASTERPAK22LT      U    1 0.02631579
> 6 MASTERPAK22LT      X    30 0.78947368
>
> I then try to plot this using ggplot using
>
> plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
>     geom_bar(stat="identity") +
>     labs(y="Percent Complete") +
>     stat_bin(geom = "text",
>             aes(label=paste(round(perc*100),"%")),
>             vjust=5) +
>     scale_y_continuous(labels = percent)
>
> but I get the error:
>
> Error: stat_bin() must not be used with a y aesthetic.
>
> When I leave out the stat_bin, I get the correct bar chart, but without
> the labels.  Can someone please help me understand what is causing the
> error above?
>
>
> Thank you kindly,
>
> Shawn Way, PE
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html<
> http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Dec  6 07:12:48 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 5 Dec 2016 22:12:48 -0800 (PST)
Subject: [R] Using ggplot2 to plot percentages in bar chart.
In-Reply-To: <52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
References: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
	<520051953.59722.1480977991169@mail.yahoo.com>
	<52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <alpine.BSF.2.00.1612052143460.48364@pedal.dcn.davis.ca.us>

I don't understand how your labelling technique was supposed to work. 
Below is my reproducible example of how I would approach this problem.
When you post next time, try to follow this method of making something we 
can put into our fresh R environment and see your problem directly.

---
library(dplyr)
library(tidyr)
library(ggplot2)

dta <- read.table( text=
"  MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
1            X            X            X             X             X
2            C            C            C             X             X
3            C            C            C             X             X
4            U            U            X             X             X
5           NA            U            X             X             X
6           NA           NA            X            NA            NA
", header=TRUE, as.is=TRUE )

d2 <- dta %>%
     gather( Model, Status ) %>%
     group_by( Model, Status ) %>%
     summarise( count = n() ) %>%
     group_by( Model ) %>%
     mutate( perc = 100 * count / sum( count )
           , percpos = rev( cumsum( rev( perc ) ) - 0.5 * rev( perc ) )
           ) %>%
     ungroup %>%
     mutate( Modelf = factor( Model )
           , percLbl = sprintf( "%2.0f%%", perc )
           )

plt <- ggplot( d2
              , aes( x = Modelf
                   , y = perc
                   , fill = Status
                   )
              ) +
     geom_bar( stat = "identity" ) +
     labs( x = "Model", y = "Percent Complete" ) +
     geom_text( mapping = aes( x = Modelf
                             , y = percpos
                             , label = percLbl )
              , vjust = 0.5 )
plt
---

On Mon, 5 Dec 2016, Shawn Way wrote:

> That?s precisely what I?m trying to accomplish.
>
> Shawn Way, PE
>
> From: John Kane [mailto:jrkrideau at yahoo.ca]
> Sent: Monday, December 05, 2016 4:47 PM
> To: Shawn Way <SWay at meco.com>; r-help at r-project.org
> Subject: Re: [R] Using ggplot2 to plot percentages in bar chart.
>
> I've never seen   stat_bin used like that. What exactly is it supposed to do. It looks like you are trying to label the %ages in each piece of the bar.
>
> On Monday, December 5, 2016 2:17 PM, Shawn Way <SWay at meco.com<mailto:SWay at meco.com>> wrote:
>
> I have the following data in which I'm trying to summarize in a stacked bar plot showing the percentages as a label in the bar.
>
> The data is as follows:
>
>> head(data)
>  MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
> 1            X            X            X            X            X
> 2            C            C            C            X            X
> 3            C            C            C            X            X
> 4            U            U            X            X            X
> 5        <NA>            U            X            X            X
> 6        <NA>        <NA>            X          <NA>          <NA>
>
> It is then transformed using dplyer:
>
>> d2 <- data %>%
>    gather(Model,Status) %>%
>    group_by(Model,Status) %>%
>    summarise(count=n()) %>%
>    mutate(perc=count/sum(count))
>
> giving
>> head (d2)
> Source: local data frame [6 x 4]
> Groups: Model [2]
>
>          Model Status count      perc
>          <chr>  <chr> <int>      <dbl>
> 1 MASTERPAK10LT      C    8 0.21052632
> 2 MASTERPAK10LT      X    29 0.76315789
> 3 MASTERPAK10LT  <NA>    1 0.02631579
> 4 MASTERPAK22LT      C    6 0.15789474
> 5 MASTERPAK22LT      U    1 0.02631579
> 6 MASTERPAK22LT      X    30 0.78947368
>
> I then try to plot this using ggplot using
>
> plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
>    geom_bar(stat="identity") +
>    labs(y="Percent Complete") +
>    stat_bin(geom = "text",
>            aes(label=paste(round(perc*100),"%")),
>            vjust=5) +
>    scale_y_continuous(labels = percent)
>
> but I get the error:
>
> Error: stat_bin() must not be used with a y aesthetic.
>
> When I leave out the stat_bin, I get the correct bar chart, but without the labels.  Can someone please help me understand what is causing the error above?
>
>
> Thank you kindly,
>
> Shawn Way, PE
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ruipbarradas at sapo.pt  Tue Dec  6 09:17:04 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 06 Dec 2016 08:17:04 +0000
Subject: [R] Write a function that allows access to columns of a passed
 dataframe.
In-Reply-To: <CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
Message-ID: <58467400.9090401@sapo.pt>

Hello,

Just to say that I wouldn't write the function as John did. I would get 
rid of all the deparse/substitute stuff and instinctively use a quoted 
argument as a column name. Something like the following.

myfun <- function(frame, var){
	[...]
	col <- frame[, var]  # or frame[[var]]
	[...]
}

myfun(mydf, "age")  # much better, simpler, no promises.

Rui Barradas

Em 05-12-2016 21:49, Bert Gunter escreveu:
> Typo: "lazy evaluation" not "lay evaluation."
>
> -- Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Sorry, hit "Send" by mistake.
>>
>> Inline.
>>
>>
>>
>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> Inline.
>>>
>>> -- Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>> Hello,
>>>>
>>>> Inline.
>>>>
>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>>>>
>>>>>
>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>>>>> wrote:
>>>>>>
>>>>>> Rui,
>>>>>> I appreciate your suggestion, but eliminating the deparse statement does
>>>>>> not solve my problem. Do you have any other suggestions? See code below.
>>>>>> Thank you,
>>>>>> John
>>>>>>
>>>>>>
>>>>>> mydf <-
>>>>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>>>>> mydf
>>>>>> class(mydf)
>>>>>>
>>>>>>
>>>>>> myfun <- function(frame,var){
>>>>>>    call <- match.call()
>>>>>>    print(call)
>>>>>>
>>>>>>
>>>>>>    indx <- match(c("frame","var"),names(call),nomatch=0)
>>>>>>    print(indx)
>>>>>>    if(indx[1]==0) stop("Function called without sufficient arguments!")
>>>>>>
>>>>>>
>>>>>>    cat("I can get the name of the dataframe as a text string!\n")
>>>>>>    #xx <- deparse(substitute(frame))
>>>>>>    print(xx)
>>>>>>
>>>>>>
>>>>>>    cat("I can get the name of the column as a text string!\n")
>>>>>>    #yy <- deparse(substitute(var))
>>>>>>    print(yy)
>>>>>>
>>>>>>
>>>>>>    # This does not work.
>>>>>>    print(frame[,var])
>>>>>>
>>>>>>
>>>>>>    # This does not work.
>>>>>>    print(frame[,"var"])
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>    # This does not work.
>>>>>>    col <- xx[,"yy"]
>>>>>>
>>>>>>
>>>>>>    # Nor does this work.
>>>>>>    col <- xx[,yy]
>>>>>>    print(col)
>>>>>> }
>>>>>>
>>>>>>
>>>>>> myfun(mydf,age)
>>>>>
>>>>>
>>>>>
>>>>> When you use that calling syntax, the system will supply the values of
>>>>> whatever the `age` variable contains. (And if there is no `age`-named
>>>>> object, you get an error at the time of the call to `myfun`.
>>>>
>>>>
>>>> Actually, no, which was very surprising to me but John's code worked (not
>>>> the function, the call). And with the change I've proposed, it worked
>>>> flawlessly. No errors. Why I don't know.
>>
>> See ?substitute and in particular the example highlighted there.
>>
>> The technical details are explained in the R Language Definition
>> manual. The key here is the use of promises for lay evaluations. In
>> fact, the expression in the call *is* available within the functions,
>> as is (a pointer to) the environment in which to evaluate the
>> expression. That is how substitute() works. Specifically, quoting from
>> the manual,
>>
>> *****
>> It is possible to access the actual (not default) expressions used as
>> arguments inside the function. The mechanism is implemented via
>> promises. When a function is being evaluated the actual expression
>> used as an argument is stored in the promise together with a pointer
>> to the environment the function was called from. When (if) the
>> argument is evaluated the stored expression is evaluated in the
>> environment that the function was called from. Since only a pointer to
>> the environment is used any changes made to that environment will be
>> in effect during this evaluation. The resulting value is then also
>> stored in a separate spot in the promise. Subsequent evaluations
>> retrieve this stored value (a second evaluation is not carried out).
>> Access to the unevaluated expression is also available using
>> substitute.
>> ********
>>
>> -- Bert
>>
>>
>>
>>
>>>>
>>>> Rui Barradas
>>>>
>>>>   You need either to call it as:
>>>>>
>>>>>
>>>>> myfun( mydf , "age")
>>>>>
>>>>>
>>>>> # Or:
>>>>>
>>>>> age <- "age"
>>>>> myfun( mydf, age)
>>>>>
>>>>> Unless your value of the `age`-named variable was "age" in the calling
>>>>> environment (and you did not give us that value in either of your postings),
>>>>> you would fail.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From prseye at gmail.com  Tue Dec  6 10:44:03 2016
From: prseye at gmail.com (Paul Sanfilippo)
Date: Tue, 6 Dec 2016 20:44:03 +1100
Subject: [R] create list of vectors in for loop
Message-ID: <etPan.58468863.3471f6d.139@gmail.com>

Hi,

As an exercise, I am trying to create a list of 10 random number vectors in a loop. I can create the vectors but am unsure how to assemble them in the list as part of the loop. Any advice?


# Number of vectors to create
n <- c(1:10)

# Create empty list to store vectors
list_of_vecs <- list()

# Create n vectors of random numbers - length 10. This works ok.
for (i in seq_along(n)){
? assign(paste('vec_', i, sep = ''), rnorm(10,0,1))
}

# But how do I append them in a list. This doesn?t work:
for (i in seq_along(n)){
? list_of_vecs <- list(list_of_vecs,(assign(paste('vec_', i, sep = ''), rnorm(10,0,1))))
}


Thank you,

Paul



	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Dec  6 11:17:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Dec 2016 21:17:21 +1100
Subject: [R] create list of vectors in for loop
In-Reply-To: <etPan.58468863.3471f6d.139@gmail.com>
References: <etPan.58468863.3471f6d.139@gmail.com>
Message-ID: <CA+8X3fVWEvNRuZu5OcuN4JSsjRrVn4Q4m13vo_+gqhTTC=-1aA@mail.gmail.com>

Hi Paul,
The easy to understand way is:

n <- c(1:10)
# Create empty list to store vectors
list_of_vecs <- list()

# Create n vectors of random numbers - length 10. This works ok.
for (i in n){
 list_of_vecs[[i]]<-rnorm(10,0,1)
}

If you really want to use "assign":
for (i in n){
 vecname<-paste('vec_', i, sep = '')
 assign(vecname, rnorm(10,0,1))
 list_of_vecs[[i]]<-get(vecname)
}

Jim



On Tue, Dec 6, 2016 at 8:44 PM, Paul Sanfilippo <prseye at gmail.com> wrote:
> Hi,
>
> As an exercise, I am trying to create a list of 10 random number vectors in a loop. I can create the vectors but am unsure how to assemble them in the list as part of the loop. Any advice?
>
>
> # Number of vectors to create
> n <- c(1:10)
>
> # Create empty list to store vectors
> list_of_vecs <- list()
>
> # Create n vectors of random numbers - length 10. This works ok.
> for (i in seq_along(n)){
>   assign(paste('vec_', i, sep = ''), rnorm(10,0,1))
> }
>
> # But how do I append them in a list. This doesn?t work:
> for (i in seq_along(n)){
>   list_of_vecs <- list(list_of_vecs,(assign(paste('vec_', i, sep = ''), rnorm(10,0,1))))
> }
>
>
> Thank you,
>
> Paul
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From prseye at gmail.com  Tue Dec  6 11:21:52 2016
From: prseye at gmail.com (Paul Sanfilippo)
Date: Tue, 6 Dec 2016 21:21:52 +1100
Subject: [R] create list of vectors in for loop
In-Reply-To: <CA+8X3fVWEvNRuZu5OcuN4JSsjRrVn4Q4m13vo_+gqhTTC=-1aA@mail.gmail.com>
References: <etPan.58468863.3471f6d.139@gmail.com>
	<CA+8X3fVWEvNRuZu5OcuN4JSsjRrVn4Q4m13vo_+gqhTTC=-1aA@mail.gmail.com>
Message-ID: <etPan.58469140.1d3240c4.139@gmail.com>

Thank you Jim.



On 6 December 2016 at 9:17:21 pm, Jim Lemon (drjimlemon at gmail.com) wrote:

Hi Paul,  
The easy to understand way is:  

n <- c(1:10)  
# Create empty list to store vectors  
list_of_vecs <- list()  

# Create n vectors of random numbers - length 10. This works ok.  
for (i in n){  
list_of_vecs[[i]]<-rnorm(10,0,1)  
}  

If you really want to use "assign":  
for (i in n){  
vecname<-paste('vec_', i, sep = '')  
assign(vecname, rnorm(10,0,1))  
list_of_vecs[[i]]<-get(vecname)  
}  

Jim  



On Tue, Dec 6, 2016 at 8:44 PM, Paul Sanfilippo <prseye at gmail.com> wrote:  
> Hi,  
>  
> As an exercise, I am trying to create a list of 10 random number vectors in a loop. I can create the vectors but am unsure how to assemble them in the list as part of the loop. Any advice?  
>  
>  
> # Number of vectors to create  
> n <- c(1:10)  
>  
> # Create empty list to store vectors  
> list_of_vecs <- list()  
>  
> # Create n vectors of random numbers - length 10. This works ok.  
> for (i in seq_along(n)){  
> assign(paste('vec_', i, sep = ''), rnorm(10,0,1))  
> }  
>  
> # But how do I append them in a list. This doesn?t work:  
> for (i in seq_along(n)){  
> list_of_vecs <- list(list_of_vecs,(assign(paste('vec_', i, sep = ''), rnorm(10,0,1))))  
> }  
>  
>  
> Thank you,  
>  
> Paul  
>  
>  
>  
> [[alternative HTML version deleted]]  
>  
> ______________________________________________  
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see  
> https://stat.ethz.ch/mailman/listinfo/r-help  
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html  
> and provide commented, minimal, self-contained, reproducible code.  

	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Tue Dec  6 11:28:32 2016
From: Ramgad82 at gmx.net (Dagmar)
Date: Tue, 6 Dec 2016 11:28:32 +0100
Subject: [R] drawing a ... barplot (?) along time
Message-ID: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>

# Dear all,
# I hope someone can help me with this, I am kind of desperated even 
though it doesn't sound tooooo complicated at all. Let's see:
# I have a data frame like this:
datframe <- data.frame(Name=c("Kati","Kati","Kati","Leon","Leon","Leon"),
                        changepoint =as.POSIXct 
(strptime(as.character("03.01.2011","05.01.2011", "27.01.2011", 
"26.01.2011","28.01.2011", "28.02.2011"), "%d.%m.%Y")),
                        knownstate =c("breeding",NA, 
NA,"breeding","moulting",NA))
datframe
str(datframe)
# Now I want a stacked horizontal bar diagram: One bar-line for animal 
Kati and bellow one for animal Leon.
# Each bar should be "drawn" along the time (on the x-axes) and be 
interupted (by a vertical line) at the changepoints
# then additionally I want colours for the known states (e.g. red for 
the time from 03.01.2011 to 05.01.2011 when animal Kati was breeding)

# help would be much appreciated!


From drjimlemon at gmail.com  Tue Dec  6 12:18:15 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Dec 2016 22:18:15 +1100
Subject: [R] drawing a ... barplot (?) along time
In-Reply-To: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>
References: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>
Message-ID: <CA+8X3fWnJxDBuDEy0dVQy5hNUdN2FAKeknCOi=Nu83eG_r8zsA@mail.gmail.com>

Hi Dagmar,
I think you want something like a gantt.chart. I know this is wrong in
some ways, but it is late and I must retire:

datframe <- data.frame(Name=c("Kati","Kati","Kati","Leon","Leon","Leon"),
 changepoint=as.Date(c("03.01.2011","05.01.2011", "27.01.2011",
  "26.01.2011","28.01.2011", "28.02.2011"), "%d.%m.%Y"),
 knownstate =c("breeding",NA, NA,"breeding","moulting",NA))
library(plotrix)
tm.info<-list(labels=datframe$Name,
 starts=c(as.Date("01.01.2011","%d.%m.%Y"),datframe$changepoint[1:2],
 as.Date("01.01.2011","%d.%m.%Y"),datframe$changepoint[4:5]),
 ends=datframe$changepoint)
gantt.chart(tm.info,xlim=as.Date(c("1.1.2011","1.3.2011"),"%d.%m.%Y"),
taskcolors=c(2,3,3,2,"orange",3))

Jim

On Tue, Dec 6, 2016 at 9:28 PM, Dagmar <Ramgad82 at gmx.net> wrote:
> # Dear all,
> # I hope someone can help me with this, I am kind of desperated even though
> it doesn't sound tooooo complicated at all. Let's see:
> # I have a data frame like this:
> datframe <- data.frame(Name=c("Kati","Kati","Kati","Leon","Leon","Leon"),
>                        changepoint =as.POSIXct
> (strptime(as.character("03.01.2011","05.01.2011", "27.01.2011",
> "26.01.2011","28.01.2011", "28.02.2011"), "%d.%m.%Y")),
>                        knownstate =c("breeding",NA,
> NA,"breeding","moulting",NA))
> datframe
> str(datframe)
> # Now I want a stacked horizontal bar diagram: One bar-line for animal Kati
> and bellow one for animal Leon.
> # Each bar should be "drawn" along the time (on the x-axes) and be
> interupted (by a vertical line) at the changepoints
> # then additionally I want colours for the known states (e.g. red for the
> time from 03.01.2011 to 05.01.2011 when animal Kati was breeding)
>
> # help would be much appreciated!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mtsagris at yahoo.gr  Tue Dec  6 12:47:10 2016
From: mtsagris at yahoo.gr (michael tsagris)
Date: Tue, 6 Dec 2016 11:47:10 +0000 (UTC)
Subject: [R] (no subject)
References: <2122996270.635703.1481024830195.ref@mail.yahoo.com>
Message-ID: <2122996270.635703.1481024830195@mail.yahoo.com>

Hello, I have encountered a problem when running a glm with the inverse gaussian as distribution and the log as a link function. 
Do you think this could be a bug, or something else?Attached is a document to run the example. I have written my own functions and they seem to work fine. 

From jrkrideau at yahoo.ca  Tue Dec  6 13:07:02 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 6 Dec 2016 12:07:02 +0000 (UTC)
Subject: [R] Using ggplot2 to plot percentages in bar chart.
In-Reply-To: <52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
References: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
	<520051953.59722.1480977991169@mail.yahoo.com>
	<52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
Message-ID: <1464040087.465506.1481026022227@mail.yahoo.com>

Well personally I would not have a clue on how to approach the problem but have a look at http://stackoverflow.com/questions/6644997/showing-data-values-on-stacked-bar-chart-in-ggplot2. which seems to do what you want only using geom_text()

Best of luck.
 ? 





 

    On Monday, December 5, 2016 5:56 PM, Shawn Way <SWay at meco.com> wrote:
 

 #yiv4374957155 #yiv4374957155 -- _filtered #yiv4374957155 {font-family:Helvetica;panose-1:2 11 6 4 2 2 2 2 2 4;} _filtered #yiv4374957155 {font-family:SimSun;panose-1:2 1 6 0 3 1 1 1 1 1;} _filtered #yiv4374957155 {panose-1:2 4 5 3 5 4 6 3 2 4;} _filtered #yiv4374957155 {font-family:Calibri;panose-1:2 15 5 2 2 2 4 3 2 4;} _filtered #yiv4374957155 {panose-1:2 1 6 0 3 1 1 1 1 1;}#yiv4374957155 #yiv4374957155 p.yiv4374957155MsoNormal, #yiv4374957155 li.yiv4374957155MsoNormal, #yiv4374957155 div.yiv4374957155MsoNormal {margin:0in;margin-bottom:.0001pt;font-size:12.0pt;}#yiv4374957155 a:link, #yiv4374957155 span.yiv4374957155MsoHyperlink {color:blue;text-decoration:underline;}#yiv4374957155 a:visited, #yiv4374957155 span.yiv4374957155MsoHyperlinkFollowed {color:purple;text-decoration:underline;}#yiv4374957155 span.yiv4374957155EmailStyle17 {color:#1F497D;}#yiv4374957155 .yiv4374957155MsoChpDefault {font-size:10.0pt;} _filtered #yiv4374957155 {margin:1.0in 1.0in 1.0in 1.0in;}#yiv4374957155 div.yiv4374957155WordSection1 {}#yiv4374957155 That?s precisely what I?m trying to accomplish.  ? Shawn Way, PE  ? From: John Kane [mailto:jrkrideau at yahoo.ca]
Sent: Monday, December 05, 2016 4:47 PM
To: Shawn Way <SWay at meco.com>; r-help at r-project.org
Subject: Re: [R] Using ggplot2 to plot percentages in bar chart.  ? I've never seen ? stat_bin used like that. What exactly is it supposed to do. It looks like you are trying to label the %ages in each piece of the bar.  ? On Monday, December 5, 2016 2:17 PM, Shawn Way <SWay at meco.com> wrote:  ? I have the following data in which I'm trying to summarize in a stacked bar plot showing the percentages as a label in the bar.

The data is as follows:

> head(data)
? MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
1? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X
2? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? X? ? ? ? ? ? X
3? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? C? ? ? ? ? ? X? ? ? ? ? ? X
4? ? ? ? ? ? U? ? ? ? ? ? U? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X
5? ? ? ? <NA>? ? ? ? ? ? U? ? ? ? ? ? X? ? ? ? ? ? X? ? ? ? ? ? X
6? ? ? ? <NA>? ? ? ? <NA>? ? ? ? ? ? X? ? ? ? ? <NA>? ? ? ? ? <NA>

It is then transformed using dplyer:

> d2 <- data %>%
? ? gather(Model,Status) %>%
? ? group_by(Model,Status) %>%
? ? summarise(count=n()) %>%
? ? mutate(perc=count/sum(count))

giving 
> head (d2)
Source: local data frame [6 x 4]
Groups: Model [2]

? ? ? ? ? Model Status count? ? ? perc
? ? ? ? ? <chr>? <chr> <int>? ? ? <dbl>
1 MASTERPAK10LT? ? ? C? ? 8 0.21052632
2 MASTERPAK10LT? ? ? X? ? 29 0.76315789
3 MASTERPAK10LT? <NA>? ? 1 0.02631579
4 MASTERPAK22LT? ? ? C? ? 6 0.15789474
5 MASTERPAK22LT? ? ? U? ? 1 0.02631579
6 MASTERPAK22LT? ? ? X? ? 30 0.78947368

I then try to plot this using ggplot using 

plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
? ? geom_bar(stat="identity") +
? ? labs(y="Percent Complete") +
? ? stat_bin(geom = "text",
? ? ? ? ? ? aes(label=paste(round(perc*100),"%")),
? ? ? ? ? ? vjust=5) +
? ? scale_y_continuous(labels = percent)

but I get the error:

Error: stat_bin() must not be used with a y aesthetic.

When I leave out the stat_bin, I get the correct bar chart, but without the labels.? Can someone please help me understand what is causing the error above?


Thank you kindly,

Shawn Way, PE

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



   
	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Tue Dec  6 13:27:02 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Tue, 6 Dec 2016 12:27:02 +0000 (UTC)
Subject: [R] (no subject)
In-Reply-To: <2122996270.635703.1481024830195@mail.yahoo.com>
References: <2122996270.635703.1481024830195.ref@mail.yahoo.com>
	<2122996270.635703.1481024830195@mail.yahoo.com>
Message-ID: <1475686554.62861.1481027222213@mail.yahoo.com>

No attachment.? R-help; is very fussy about the type of file it will accept. Try a text document with .txt extention or just put the code and the sample data in the actual email. Use dput(), see ?dput for details, to provide the data.
 

    On Tuesday, December 6, 2016 6:51 AM, michael tsagris via R-help <r-help at r-project.org> wrote:
 

 Hello, I have encountered a problem when running a glm with the inverse gaussian as distribution and the log as a link function. 
Do you think this could be a bug, or something else?Attached is a document to run the example. I have written my own functions and they seem to work fine. 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Dec  6 13:33:35 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 6 Dec 2016 13:33:35 +0100
Subject: [R] create list of vectors in for loop
In-Reply-To: <CA+8X3fVWEvNRuZu5OcuN4JSsjRrVn4Q4m13vo_+gqhTTC=-1aA@mail.gmail.com>
References: <etPan.58468863.3471f6d.139@gmail.com>
	<CA+8X3fVWEvNRuZu5OcuN4JSsjRrVn4Q4m13vo_+gqhTTC=-1aA@mail.gmail.com>
Message-ID: <06F4FDC1-D96E-4B50-A63E-2CFD43C29E6A@gmail.com>


On 06 Dec 2016, at 11:17 , Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Paul,
> The easy to understand way is:
> 
> n <- c(1:10)
> # Create empty list to store vectors
> list_of_vecs <- list()
> 
> # Create n vectors of random numbers - length 10. This works ok.
> for (i in n){
> list_of_vecs[[i]]<-rnorm(10,0,1)
> }

As a principle, you want 

  list_of_vecs <- vector("list", 10)

to avoid extending the list on each iteration.


However, a simpler way is

replicate(10, rnorm(10), simplify=FALSE)

(where the simplify bit prevents conversion to 10x10 matrix)

or 

lapply(1:10, function(i) rnorm(10))



-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From topijush at gmail.com  Tue Dec  6 07:20:41 2016
From: topijush at gmail.com (Pijush Das)
Date: Tue, 6 Dec 2016 11:50:41 +0530
Subject: [R] LaTeX errors when creating PDF version.
Message-ID: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>

Hello Sir,

I am facing a common problem in R. I have searched a lot but nobody gives a
proper way. The problem is : when I am tying to check my package in R
created by me it shows an error given below

* checking PDF version of manual ... WARNING
> LaTeX errors when creating PDF version.
This typically indicates Rd problems.
LaTeX errors found:
! Package inputenc Error: Unicode char (U+9D)
(inputenc)                not set up for use with LaTeX.

>See the inputenc package documentation for explanation.
Type  H <return>  for immediate help.
! Package inputenc Error: Unicode char (U+9D)
(inputenc)                not set up for use with LaTeX.

>See the inputenc package documentation for explanation.
Type  H <return>  for immediate help.
! Package inputenc Error: Unicode char (U+9D)
(inputenc)                not set up for use with LaTeX.


I found this is a common problem for each novice who are trying create
their won package. But I unable to find any proper solution.

Please help me .

Thank you very much

regards Pijush

	[[alternative HTML version deleted]]


From patrcasi at nova.edu  Tue Dec  6 13:57:51 2016
From: patrcasi at nova.edu (Patrick Casimir)
Date: Tue, 6 Dec 2016 12:57:51 +0000
Subject: [R] Why is DocumentTermMatrix  showing 0 term?
Message-ID: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>

<<DocumentTermMatrix (documents: 4, terms: 0)>>
Non-/sparse entries: 0/0
Sparsity           : 100%
Maximal term length: 0
Weighting          : term frequency (tf)






	[[alternative HTML version deleted]]


From paulbernal07 at gmail.com  Tue Dec  6 14:05:56 2016
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Tue, 6 Dec 2016 08:05:56 -0500
Subject: [R] Forecast Modeling using R model node in SPSS Modeler
In-Reply-To: <CA+vqiLErvAgnFNRizLTqP_x4uTwfpcwFTQEBW5m6_RkqjobARQ@mail.gmail.com>
References: <CAMOcQfORcRo2T2tuVBXiJ56N2wuKUrrMPH0z7AnNap-9-jiSQA@mail.gmail.com>
	<CA+vqiLErvAgnFNRizLTqP_x4uTwfpcwFTQEBW5m6_RkqjobARQ@mail.gmail.com>
Message-ID: <CAMOcQfN=zQa6dyvdechVEitKpiF0ggvpVG-RfCJfUb6UKN2pvg@mail.gmail.com>

Hi Ista,

Your suggestion is great. There is no better way to work with R than
working with R directly, however, I have been asked to generate forecasts
in SPSS Modeler using the R integration that comes with it, so
unfortunately, I need to find a way around. If I find the way to do it, I
will make sure I share it with the rest of the R user community.

Anyway, thank you for your quick and kind reply,

Best of regards,

Paul

2016-12-05 16:31 GMT-05:00 Ista Zahn <istazahn at gmail.com>:

> Hi Paul,
>
> I suggest forgetting about SPSS and using R directly. Getting started
> with R is easier than ever thanks to the growing number of tutorials,
> workshops, mailing lists and forums.
>
> Best,
> Ista
>
> On Mon, Dec 5, 2016 at 4:09 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> > Hello everyone,
> >
> > I have been trying really hard to use the SPSS Modeler?s R modeling node
> to
> > generate forecasts without success. I personally think the R integration
> in
> > SPSS Modeler is kind of poor, since you are only allowed to work with R
> > version 2.15.2.
> >
> > Is there anyone who has worked time series and forecasting models using
> the
> > R nodes from SPSS Modeler? Is there any document or any guide that you
> guys
> > could provide me with?
> >
> > Best regards,
> >
> > Paul
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From SWay at meco.com  Tue Dec  6 14:20:30 2016
From: SWay at meco.com (Shawn Way)
Date: Tue, 6 Dec 2016 13:20:30 +0000
Subject: [R] Using ggplot2 to plot percentages in bar chart.
In-Reply-To: <alpine.BSF.2.00.1612052143460.48364@pedal.dcn.davis.ca.us>
References: <887d0711b404431da1a7aa7169d5ea52@CTC-HOU-EXMB-02.ctcloud.local>
	<520051953.59722.1480977991169@mail.yahoo.com>
	<52c127b98314438a8bba73c28e4b145e@CTC-HOU-EXMB-02.ctcloud.local>
	<alpine.BSF.2.00.1612052143460.48364@pedal.dcn.davis.ca.us>
Message-ID: <20b85da50d5341ce8e47704261c56b5e@CTC-HOU-EXMB-02.ctcloud.local>

This worked well!  Thank you very much.

For the record, the stat_bin was used in a solution I found on stackexchange for something similar, but I was having issues adapting.

Thanks again to all who responded.  I appreciate it greatly.

Shawn Way, PE

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, December 06, 2016 12:13 AM
To: Shawn Way <SWay at meco.com>
Cc: John Kane <jrkrideau at yahoo.ca>; r-help at r-project.org
Subject: Re: [R] Using ggplot2 to plot percentages in bar chart.

I don't understand how your labelling technique was supposed to work. 
Below is my reproducible example of how I would approach this problem.
When you post next time, try to follow this method of making something we can put into our fresh R environment and see your problem directly.

---
library(dplyr)
library(tidyr)
library(ggplot2)

dta <- read.table( text=
"  MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
1            X            X            X             X             X
2            C            C            C             X             X
3            C            C            C             X             X
4            U            U            X             X             X
5           NA            U            X             X             X
6           NA           NA            X            NA            NA
", header=TRUE, as.is=TRUE )

d2 <- dta %>%
     gather( Model, Status ) %>%
     group_by( Model, Status ) %>%
     summarise( count = n() ) %>%
     group_by( Model ) %>%
     mutate( perc = 100 * count / sum( count )
           , percpos = rev( cumsum( rev( perc ) ) - 0.5 * rev( perc ) )
           ) %>%
     ungroup %>%
     mutate( Modelf = factor( Model )
           , percLbl = sprintf( "%2.0f%%", perc )
           )

plt <- ggplot( d2
              , aes( x = Modelf
                   , y = perc
                   , fill = Status
                   )
              ) +
     geom_bar( stat = "identity" ) +
     labs( x = "Model", y = "Percent Complete" ) +
     geom_text( mapping = aes( x = Modelf
                             , y = percpos
                             , label = percLbl )
              , vjust = 0.5 )
plt
---

On Mon, 5 Dec 2016, Shawn Way wrote:

> That?s precisely what I?m trying to accomplish.
>
> Shawn Way, PE
>
> From: John Kane [mailto:jrkrideau at yahoo.ca]
> Sent: Monday, December 05, 2016 4:47 PM
> To: Shawn Way <SWay at meco.com>; r-help at r-project.org
> Subject: Re: [R] Using ggplot2 to plot percentages in bar chart.
>
> I've never seen   stat_bin used like that. What exactly is it supposed to do. It looks like you are trying to label the %ages in each piece of the bar.
>
> On Monday, December 5, 2016 2:17 PM, Shawn Way <SWay at meco.com<mailto:SWay at meco.com>> wrote:
>
> I have the following data in which I'm trying to summarize in a stacked bar plot showing the percentages as a label in the bar.
>
> The data is as follows:
>
>> head(data)
>  MASTERPAK2LT MASTERPAK4LT MASTERPAK7LT MASTERPAK10LT MASTERPAK22LT
> 1            X            X            X            X            X
> 2            C            C            C            X            X
> 3            C            C            C            X            X
> 4            U            U            X            X            X
> 5        <NA>            U            X            X            X
> 6        <NA>        <NA>            X          <NA>          <NA>
>
> It is then transformed using dplyer:
>
>> d2 <- data %>%
>    gather(Model,Status) %>%
>    group_by(Model,Status) %>%
>    summarise(count=n()) %>%
>    mutate(perc=count/sum(count))
>
> giving
>> head (d2)
> Source: local data frame [6 x 4]
> Groups: Model [2]
>
>          Model Status count      perc
>          <chr>  <chr> <int>      <dbl>
> 1 MASTERPAK10LT      C    8 0.21052632
> 2 MASTERPAK10LT      X    29 0.76315789
> 3 MASTERPAK10LT  <NA>    1 0.02631579
> 4 MASTERPAK22LT      C    6 0.15789474
> 5 MASTERPAK22LT      U    1 0.02631579
> 6 MASTERPAK22LT      X    30 0.78947368
>
> I then try to plot this using ggplot using
>
> plt <- ggplot(d2,aes(x=Model,y= perc,fill=Status)) +
>    geom_bar(stat="identity") +
>    labs(y="Percent Complete") +
>    stat_bin(geom = "text",
>            aes(label=paste(round(perc*100),"%")),
>            vjust=5) +
>    scale_y_continuous(labels = percent)
>
> but I get the error:
>
> Error: stat_bin() must not be used with a y aesthetic.
>
> When I leave out the stat_bin, I get the correct bar chart, but without the labels.  Can someone please help me understand what is causing the error above?
>
>
> Thank you kindly,
>
> Shawn Way, PE
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html<http://www.r-project.org/p
> osting-guide.html> and provide commented, minimal, self-contained, 
> reproducible code.
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From istazahn at gmail.com  Tue Dec  6 14:57:59 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 08:57:59 -0500
Subject: [R] Forecast Modeling using R model node in SPSS Modeler
In-Reply-To: <CAMOcQfN=zQa6dyvdechVEitKpiF0ggvpVG-RfCJfUb6UKN2pvg@mail.gmail.com>
References: <CAMOcQfORcRo2T2tuVBXiJ56N2wuKUrrMPH0z7AnNap-9-jiSQA@mail.gmail.com>
	<CA+vqiLErvAgnFNRizLTqP_x4uTwfpcwFTQEBW5m6_RkqjobARQ@mail.gmail.com>
	<CAMOcQfN=zQa6dyvdechVEitKpiF0ggvpVG-RfCJfUb6UKN2pvg@mail.gmail.com>
Message-ID: <CA+vqiLGFFwx6XMAUfxQNa9Hb7RmVdC7zEuUvAR-+YF8=m-PXdA@mail.gmail.com>

Hi Paul,

Not everything people ask for makes sense. If you insist on trying to get R
integration working in SPSS you should reach out to the SPSS company and/or
community for support.

Best,
Ista

On Dec 6, 2016 8:05 AM, "Paul Bernal" <paulbernal07 at gmail.com> wrote:

> Hi Ista,
>
> Your suggestion is great. There is no better way to work with R than
> working with R directly, however, I have been asked to generate forecasts
> in SPSS Modeler using the R integration that comes with it, so
> unfortunately, I need to find a way around. If I find the way to do it, I
> will make sure I share it with the rest of the R user community.
>
> Anyway, thank you for your quick and kind reply,
>
> Best of regards,
>
> Paul
>
> 2016-12-05 16:31 GMT-05:00 Ista Zahn <istazahn at gmail.com>:
>
>> Hi Paul,
>>
>> I suggest forgetting about SPSS and using R directly. Getting started
>> with R is easier than ever thanks to the growing number of tutorials,
>> workshops, mailing lists and forums.
>>
>> Best,
>> Ista
>>
>> On Mon, Dec 5, 2016 at 4:09 PM, Paul Bernal <paulbernal07 at gmail.com>
>> wrote:
>> > Hello everyone,
>> >
>> > I have been trying really hard to use the SPSS Modeler?s R modeling
>> node to
>> > generate forecasts without success. I personally think the R
>> integration in
>> > SPSS Modeler is kind of poor, since you are only allowed to work with R
>> > version 2.15.2.
>> >
>> > Is there anyone who has worked time series and forecasting models using
>> the
>> > R nodes from SPSS Modeler? Is there any document or any guide that you
>> guys
>> > could provide me with?
>> >
>> > Best regards,
>> >
>> > Paul
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Dec  6 15:09:37 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 09:09:37 -0500
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
Message-ID: <CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>

Hi Patrick,

How could anyone possibly answer this question with only the information
you've provided? It's like showing me an empty cup and asking why it's
empty. Maybe you didn't put anything in it. Maybe you did and then you dog
drank it or your cat knocked it over or your girlfriend drank it. How would
I possibly know?

Bottom line, you need to show exactly what you did to produce that result,
preferably in the form of a few lines of code that we can run to reproduce
your problem.

Finally, you may find it helpful take some time to learn how to ask
questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is
a good place to learn this important skill.

Best,
Ista

On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:

<<DocumentTermMatrix (documents: 4, terms: 0)>>
Non-/sparse entries: 0/0
Sparsity           : 100%
Maximal term length: 0
Weighting          : term frequency (tf)






        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Dec  6 15:22:42 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 6 Dec 2016 15:22:42 +0100
Subject: [R] LaTeX errors when creating PDF version.
In-Reply-To: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>
References: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>
Message-ID: <FAF39236-4CC5-4E27-8BAD-58A1C587C512@gmail.com>

This is not really an R problem but a TeX one. Apparently, your input file contains Unicode characters that LaTeX doesn't know what to do with. 

That raises the suspicion is that the file might not be in UTF-8 encoding at all, however tan kind of issue does occasionally happen, even in UTF-8, if you "fat-finger" certain special characters - the per mille symbol on Shift-Alt-5 on a Mac sometimes catches me out when attempting to type "\%" (== Shift-Alt-7 Shift-5 on a Danish keyboard).

However, I don't know how to get U+9D speecifically; it seems to be unallocated in all the major code sets. You need to locate the file with the problem and the offending line inside of it and inspect.

-pd
  

On 06 Dec 2016, at 07:20 , Pijush Das <topijush at gmail.com> wrote:

> Hello Sir,
> 
> I am facing a common problem in R. I have searched a lot but nobody gives a
> proper way. The problem is : when I am tying to check my package in R
> created by me it shows an error given below
> 
> * checking PDF version of manual ... WARNING
>> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
> 
>> See the inputenc package documentation for explanation.
> Type  H <return>  for immediate help.
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
> 
>> See the inputenc package documentation for explanation.
> Type  H <return>  for immediate help.
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
> 
> 
> I found this is a common problem for each novice who are trying create
> their won package. But I unable to find any proper solution.
> 
> Please help me .
> 
> Thank you very much
> 
> regards Pijush
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From rmh at temple.edu  Tue Dec  6 15:21:13 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 6 Dec 2016 09:21:13 -0500
Subject: [R] LaTeX errors when creating PDF version.
In-Reply-To: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>
References: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>
Message-ID: <CAGx1TMDWpooq0PuafFYQU_04GR2_Q4=BFWDq9yr+cKaD5hg1qQ@mail.gmail.com>

The specific error message you are getting says that there are
non-ASCII characters
in one of your .Rd files.  You can locate them with the
tools::showNonASCII function.

library(tools)
?showNonASCII

Replace them with ASCII characters and the packaging should work.

If you really need the non-ASCII characters see the "Writing R
Extensions" manual at
   system.file("../../doc/manual/R-exts.pdf")
and read the sections on Encoding.


On Tue, Dec 6, 2016 at 1:20 AM, Pijush Das <topijush at gmail.com> wrote:
> Hello Sir,
>
> I am facing a common problem in R. I have searched a lot but nobody gives a
> proper way. The problem is : when I am tying to check my package in R
> created by me it shows an error given below
>
> * checking PDF version of manual ... WARNING
>> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
>
>>See the inputenc package documentation for explanation.
> Type  H <return>  for immediate help.
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
>
>>See the inputenc package documentation for explanation.
> Type  H <return>  for immediate help.
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
>
>
> I found this is a common problem for each novice who are trying create
> their won package. But I unable to find any proper solution.
>
> Please help me .
>
> Thank you very much
>
> regards Pijush
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jsorkin at grecc.umaryland.edu  Tue Dec  6 15:28:07 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 06 Dec 2016 09:28:07 -0500
Subject: [R] Write a function that allows access to columns of a
 passeddataframe.
In-Reply-To: <58467400.9090401@sapo.pt>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
Message-ID: <584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>

Over my almost 50 years programming, I have come to believe that if one wants a program to be useful, one should write the program to do as much work as possible and demand as little as possible from the user of the program. In my opinion, one should not ask the person who uses my function to remember to put the name of the data frame column in quotation marks. The function should be written so that all that needs to be passed is the name of the column; the function should take care of the quotation marks.
Jihny

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Hello,
> 
> Just to say that I wouldn't write the function as John did. I would get 
> rid of all the deparse/substitute stuff and instinctively use a quoted 
> argument as a column name. Something like the following.
> 
> myfun <- function(frame, var){
>    [...]
>    col <- frame[, var]  # or frame[[var]]
>    [...]
> }
> 
> myfun(mydf, "age")  # much better, simpler, no promises.
> 
> Rui Barradas
> 
> Em 05-12-2016 21:49, Bert Gunter escreveu:
>> Typo: "lazy evaluation" not "lay evaluation."
>> 
>> -- Bert
>> 
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> Sorry, hit "Send" by mistake.
>>> 
>>> Inline.
>>> 
>>> 
>>> 
>>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> Inline.
>>>> 
>>>> -- Bert
>>>> 
>>>> 
>>>> Bert Gunter
>>>> 
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>> 
>>>> 
>>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>>>> Hello,
>>>>> 
>>>>> Inline.
>>>>> 
>>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>>>>> 
>>>>>> 
>>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>>>>>>> wrote:
>>>>>>> 
>>>>>>> Rui,
>>>>>>> I appreciate your suggestion, but eliminating the deparse statement does
>>>>>>> not solve my problem. Do you have any other suggestions? See code below.
>>>>>>> Thank you,
>>>>>>> John
>>>>>>> 
>>>>>>> 
>>>>>>> mydf <-
>>>>>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>>>>>> mydf
>>>>>>> class(mydf)
>>>>>>> 
>>>>>>> 
>>>>>>> myfun <- function(frame,var){
>>>>>>>   call <- match.call()
>>>>>>>   print(call)
>>>>>>> 
>>>>>>> 
>>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>>>>>>   print(indx)
>>>>>>>   if(indx[1]==0) stop("Function called without sufficient arguments!")
>>>>>>> 
>>>>>>> 
>>>>>>>   cat("I can get the name of the dataframe as a text string!\n")
>>>>>>>   #xx <- deparse(substitute(frame))
>>>>>>>   print(xx)
>>>>>>> 
>>>>>>> 
>>>>>>>   cat("I can get the name of the column as a text string!\n")
>>>>>>>   #yy <- deparse(substitute(var))
>>>>>>>   print(yy)
>>>>>>> 
>>>>>>> 
>>>>>>>   # This does not work.
>>>>>>>   print(frame[,var])
>>>>>>> 
>>>>>>> 
>>>>>>>   # This does not work.
>>>>>>>   print(frame[,"var"])
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>>   # This does not work.
>>>>>>>   col <- xx[,"yy"]
>>>>>>> 
>>>>>>> 
>>>>>>>   # Nor does this work.
>>>>>>>   col <- xx[,yy]
>>>>>>>   print(col)
>>>>>>> }
>>>>>>> 
>>>>>>> 
>>>>>>> myfun(mydf,age)
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> When you use that calling syntax, the system will supply the values of
>>>>>> whatever the `age` variable contains. (And if there is no `age`-named
>>>>>> object, you get an error at the time of the call to `myfun`.
>>>>> 
>>>>> 
>>>>> Actually, no, which was very surprising to me but John's code worked (not
>>>>> the function, the call). And with the change I've proposed, it worked
>>>>> flawlessly. No errors. Why I don't know.
>>> 
>>> See ?substitute and in particular the example highlighted there.
>>> 
>>> The technical details are explained in the R Language Definition
>>> manual. The key here is the use of promises for lay evaluations. In
>>> fact, the expression in the call *is* available within the functions,
>>> as is (a pointer to) the environment in which to evaluate the
>>> expression. That is how substitute() works. Specifically, quoting from
>>> the manual,
>>> 
>>> *****
>>> It is possible to access the actual (not default) expressions used as
>>> arguments inside the function. The mechanism is implemented via
>>> promises. When a function is being evaluated the actual expression
>>> used as an argument is stored in the promise together with a pointer
>>> to the environment the function was called from. When (if) the
>>> argument is evaluated the stored expression is evaluated in the
>>> environment that the function was called from. Since only a pointer to
>>> the environment is used any changes made to that environment will be
>>> in effect during this evaluation. The resulting value is then also
>>> stored in a separate spot in the promise. Subsequent evaluations
>>> retrieve this stored value (a second evaluation is not carried out).
>>> Access to the unevaluated expression is also available using
>>> substitute.
>>> ********
>>> 
>>> -- Bert
>>> 
>>> 
>>> 
>>> 
>>>>> 
>>>>> Rui Barradas
>>>>> 
>>>>>  You need either to call it as:
>>>>>> 
>>>>>> 
>>>>>> myfun( mydf , "age")
>>>>>> 
>>>>>> 
>>>>>> # Or:
>>>>>> 
>>>>>> age <- "age"
>>>>>> myfun( mydf, age)
>>>>>> 
>>>>>> Unless your value of the `age`-named variable was "age" in the calling
>>>>>> environment (and you did not give us that value in either of your postings),
>>>>>> you would fail.
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From profjcnash at gmail.com  Tue Dec  6 15:29:10 2016
From: profjcnash at gmail.com (J C Nash)
Date: Tue, 6 Dec 2016 09:29:10 -0500
Subject: [R] LaTeX errors when creating PDF version.
In-Reply-To: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>
References: <CAGa91zhPeDVtNrokH0SMBNdcQ9+eAYoFDVDtN22-SLR_rG5dQA@mail.gmail.com>
Message-ID: <a3ba9b92-7f9f-3ba2-86fd-6ade52aa8978@gmail.com>

What operating system? It is very unlikely anyone will offer help in the darkness.

JN

On 16-12-06 01:20 AM, Pijush Das wrote:
> Hello Sir,
> 
> I am facing a common problem in R. I have searched a lot but nobody gives a
> proper way. The problem is : when I am tying to check my package in R
> created by me it shows an error given below
> 
> * checking PDF version of manual ... WARNING
>> LaTeX errors when creating PDF version.
> This typically indicates Rd problems.
> LaTeX errors found:
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
> 
>> See the inputenc package documentation for explanation.
> Type  H <return>  for immediate help.
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
> 
>> See the inputenc package documentation for explanation.
> Type  H <return>  for immediate help.
> ! Package inputenc Error: Unicode char (U+9D)
> (inputenc)                not set up for use with LaTeX.
> 
> 
> I found this is a common problem for each novice who are trying create
> their won package. But I unable to find any proper solution.
> 
> Please help me .
> 
> Thank you very much
> 
> regards Pijush
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From patrcasi at nova.edu  Tue Dec  6 15:29:23 2016
From: patrcasi at nova.edu (Patrick Casimir)
Date: Tue, 6 Dec 2016 14:29:23 +0000
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>,
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
Message-ID: <BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>

Thanks Ista. See codes below. I am not sure why the DTM is showing 0 term. I have 4 documents in the corpus. And I was able to make transformations

to the documents inside the corpus.


> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
> dir(cname)
[1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
> library(tm)
> docs <- Corpus(DirSource(cname))
> install.packages("magrittr" ,dependencies=TRUE)
> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>% writeLines()}
> viewDocs(docs, 1)
> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
> docs <- tm_map(docs, toSpace, "/|@|nn|")
> inspect(docs[1])
> docs <- tm_map(docs, removePunctuation)
> docs <- tm_map(docs, removeWords, stopwords("english"))
> inspect(docs[1])
> docs <- tm_map(docs, stripWhitespace)
> docs <- tm_map(docs, stemDocument)
> dtm <- DocumentTermMatrix(docs)
> dtm
<<DocumentTermMatrix (documents: 4, terms: 0)>>
Non-/sparse entries: 0/0
Sparsity           : 100%
Maximal term length: 0
Weighting          : term frequency (tf)
>




________________________________
From: Ista Zahn <istazahn at gmail.com>
Sent: Tuesday, December 6, 2016 9:09:37 AM
To: Patrick Casimir
Cc: r-help at r-project.org
Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?


Hi Patrick,

How could anyone possibly answer this question with only the information you've provided? It's like showing me an empty cup and asking why it's empty. Maybe you didn't put anything in it. Maybe you did and then you dog drank it or your cat knocked it over or your girlfriend drank it. How would I possibly know?

Bottom line, you need to show exactly what you did to produce that result, preferably in the form of a few lines of code that we can run to reproduce your problem.

Finally, you may find it helpful take some time to learn how to ask questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is a good place to learn this important skill.

Best,
Ista

On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu<mailto:patrcasi at nova.edu>> wrote:
<<DocumentTermMatrix (documents: 4, terms: 0)>>
Non-/sparse entries: 0/0
Sparsity           : 100%
Maximal term length: 0
Weighting          : term frequency (tf)






        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Dec  6 16:03:07 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Dec 2016 07:03:07 -0800
Subject: [R] Write a function that allows access to columns of a
	passeddataframe.
In-Reply-To: <584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
	<584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
Message-ID: <CAF8bMcaPfTBvsZZv3KnGx0y5Tr5EGwGxBHnfW9zMTeae3ZNv7g@mail.gmail.com>

I basically agree with Rui - using substitute will cause trouble.  E.g., how
would the user iterate over the columns, calling your function for each?
     for(column in dataFrame) func(column)
would fail because dataFrame$column does not exist.  You need to provide
an extra argument to handle this case. something like the following:
     func <- function(df,
         columnAsName,,
         columnAsString = deparse(substitute(columnAsName))[1])
         ...
     }
The default value of columnAsString should also deal with the case that
the user supplied something like log(Conc.) instead of Conc.

I think that using a formula for the lazily evaluated argument
(columnAsName)
works well.  The user then knows exactly how it gets evaluated.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Dec 6, 2016 at 6:28 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> Over my almost 50 years programming, I have come to believe that if one
> wants a program to be useful, one should write the program to do as much
> work as possible and demand as little as possible from the user of the
> program. In my opinion, one should not ask the person who uses my function
> to remember to put the name of the data frame column in quotation marks.
> The function should be written so that all that needs to be passed is the
> name of the column; the function should take care of the quotation marks.
> Jihny
>
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> > Baltimore VA Medical Center
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
> > On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> >
> > Hello,
> >
> > Just to say that I wouldn't write the function as John did. I would get
> > rid of all the deparse/substitute stuff and instinctively use a quoted
> > argument as a column name. Something like the following.
> >
> > myfun <- function(frame, var){
> >    [...]
> >    col <- frame[, var]  # or frame[[var]]
> >    [...]
> > }
> >
> > myfun(mydf, "age")  # much better, simpler, no promises.
> >
> > Rui Barradas
> >
> > Em 05-12-2016 21:49, Bert Gunter escreveu:
> >> Typo: "lazy evaluation" not "lay evaluation."
> >>
> >> -- Bert
> >>
> >>
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming along
> >> and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>> Sorry, hit "Send" by mistake.
> >>>
> >>> Inline.
> >>>
> >>>
> >>>
> >>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
> >>>> Inline.
> >>>>
> >>>> -- Bert
> >>>>
> >>>>
> >>>> Bert Gunter
> >>>>
> >>>> "The trouble with having an open mind is that people keep coming along
> >>>> and sticking things into it."
> >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>>>
> >>>>
> >>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
> >>>>> Hello,
> >>>>>
> >>>>> Inline.
> >>>>>
> >>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
> >>>>>>
> >>>>>>
> >>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin <
> jsorkin at grecc.umaryland.edu>
> >>>>>>> wrote:
> >>>>>>>
> >>>>>>> Rui,
> >>>>>>> I appreciate your suggestion, but eliminating the deparse
> statement does
> >>>>>>> not solve my problem. Do you have any other suggestions? See code
> below.
> >>>>>>> Thank you,
> >>>>>>> John
> >>>>>>>
> >>>>>>>
> >>>>>>> mydf <-
> >>>>>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),
> age=c(20,34,43,32,21))
> >>>>>>> mydf
> >>>>>>> class(mydf)
> >>>>>>>
> >>>>>>>
> >>>>>>> myfun <- function(frame,var){
> >>>>>>>   call <- match.call()
> >>>>>>>   print(call)
> >>>>>>>
> >>>>>>>
> >>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
> >>>>>>>   print(indx)
> >>>>>>>   if(indx[1]==0) stop("Function called without sufficient
> arguments!")
> >>>>>>>
> >>>>>>>
> >>>>>>>   cat("I can get the name of the dataframe as a text string!\n")
> >>>>>>>   #xx <- deparse(substitute(frame))
> >>>>>>>   print(xx)
> >>>>>>>
> >>>>>>>
> >>>>>>>   cat("I can get the name of the column as a text string!\n")
> >>>>>>>   #yy <- deparse(substitute(var))
> >>>>>>>   print(yy)
> >>>>>>>
> >>>>>>>
> >>>>>>>   # This does not work.
> >>>>>>>   print(frame[,var])
> >>>>>>>
> >>>>>>>
> >>>>>>>   # This does not work.
> >>>>>>>   print(frame[,"var"])
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>
> >>>>>>>   # This does not work.
> >>>>>>>   col <- xx[,"yy"]
> >>>>>>>
> >>>>>>>
> >>>>>>>   # Nor does this work.
> >>>>>>>   col <- xx[,yy]
> >>>>>>>   print(col)
> >>>>>>> }
> >>>>>>>
> >>>>>>>
> >>>>>>> myfun(mydf,age)
> >>>>>>
> >>>>>>
> >>>>>>
> >>>>>> When you use that calling syntax, the system will supply the values
> of
> >>>>>> whatever the `age` variable contains. (And if there is no
> `age`-named
> >>>>>> object, you get an error at the time of the call to `myfun`.
> >>>>>
> >>>>>
> >>>>> Actually, no, which was very surprising to me but John's code worked
> (not
> >>>>> the function, the call). And with the change I've proposed, it worked
> >>>>> flawlessly. No errors. Why I don't know.
> >>>
> >>> See ?substitute and in particular the example highlighted there.
> >>>
> >>> The technical details are explained in the R Language Definition
> >>> manual. The key here is the use of promises for lay evaluations. In
> >>> fact, the expression in the call *is* available within the functions,
> >>> as is (a pointer to) the environment in which to evaluate the
> >>> expression. That is how substitute() works. Specifically, quoting from
> >>> the manual,
> >>>
> >>> *****
> >>> It is possible to access the actual (not default) expressions used as
> >>> arguments inside the function. The mechanism is implemented via
> >>> promises. When a function is being evaluated the actual expression
> >>> used as an argument is stored in the promise together with a pointer
> >>> to the environment the function was called from. When (if) the
> >>> argument is evaluated the stored expression is evaluated in the
> >>> environment that the function was called from. Since only a pointer to
> >>> the environment is used any changes made to that environment will be
> >>> in effect during this evaluation. The resulting value is then also
> >>> stored in a separate spot in the promise. Subsequent evaluations
> >>> retrieve this stored value (a second evaluation is not carried out).
> >>> Access to the unevaluated expression is also available using
> >>> substitute.
> >>> ********
> >>>
> >>> -- Bert
> >>>
> >>>
> >>>
> >>>
> >>>>>
> >>>>> Rui Barradas
> >>>>>
> >>>>>  You need either to call it as:
> >>>>>>
> >>>>>>
> >>>>>> myfun( mydf , "age")
> >>>>>>
> >>>>>>
> >>>>>> # Or:
> >>>>>>
> >>>>>> age <- "age"
> >>>>>> myfun( mydf, age)
> >>>>>>
> >>>>>> Unless your value of the `age`-named variable was "age" in the
> calling
> >>>>>> environment (and you did not give us that value in either of your
> postings),
> >>>>>> you would fail.
> >>>>>>
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From istazahn at gmail.com  Tue Dec  6 16:08:28 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 10:08:28 -0500
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
	<BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
Message-ID: <CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>

What is in docs?

What does

inspect(docs)

say?

--Ista



On Tue, Dec 6, 2016 at 9:29 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
> Thanks Ista. See codes below. I am not sure why the DTM is showing 0 term. I
> have 4 documents in the corpus. And I was able to make transformations
>
> to the documents inside the corpus.
>
>
>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>> dir(cname)
> [1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
>> library(tm)
>> docs <- Corpus(DirSource(cname))
>> install.packages("magrittr" ,dependencies=TRUE)
>> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>%
>> writeLines()}
>> viewDocs(docs, 1)
>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
>> docs <- tm_map(docs, toSpace, "/|@|nn|")
>> inspect(docs[1])
>> docs <- tm_map(docs, removePunctuation)
>> docs <- tm_map(docs, removeWords, stopwords("english"))
>> inspect(docs[1])
>> docs <- tm_map(docs, stripWhitespace)
>> docs <- tm_map(docs, stemDocument)
>> dtm <- DocumentTermMatrix(docs)
>> dtm
> <<DocumentTermMatrix (documents: 4, terms: 0)>>
> Non-/sparse entries: 0/0
> Sparsity           : 100%
> Maximal term length: 0
> Weighting          : term frequency (tf)
>>
>
>
>
>
> ________________________________
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Tuesday, December 6, 2016 9:09:37 AM
> To: Patrick Casimir
> Cc: r-help at r-project.org
> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>
>
> Hi Patrick,
>
> How could anyone possibly answer this question with only the information
> you've provided? It's like showing me an empty cup and asking why it's
> empty. Maybe you didn't put anything in it. Maybe you did and then you dog
> drank it or your cat knocked it over or your girlfriend drank it. How would
> I possibly know?
>
> Bottom line, you need to show exactly what you did to produce that result,
> preferably in the form of a few lines of code that we can run to reproduce
> your problem.
>
> Finally, you may find it helpful take some time to learn how to ask
> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is a
> good place to learn this important skill.
>
> Best,
> Ista
>
>
> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>
> <<DocumentTermMatrix (documents: 4, terms: 0)>>
> Non-/sparse entries: 0/0
> Sparsity           : 100%
> Maximal term length: 0
> Weighting          : term frequency (tf)
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From patrcasi at nova.edu  Tue Dec  6 16:25:33 2016
From: patrcasi at nova.edu (Patrick Casimir)
Date: Tue, 6 Dec 2016 15:25:33 +0000
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
	<BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>,
	<CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>
Message-ID: <BN6PR06MB30252B39B0F6BB337A803512B9820@BN6PR06MB3025.namprd06.prod.outlook.com>


docs has 4 documents and inspect(docs) shows 4 plaintextdocument


> summary(docs)
          Length Class             Mode
case1.txt 2      PlainTextDocument list
case2.txt 2      PlainTextDocument list
case3.txt 2      PlainTextDocument list
case4.txt 2      PlainTextDocument list


> inspect(docs)
<<VCorpus>>
Metadata:  corpus specific: 0, document level (indexed): 0
Content:  documents: 4

[[1]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 4564

[[2]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 9312

[[3]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 1388

[[4]]
<<PlainTextDocument>>
Metadata:  7
Content:  chars: 2366


________________________________
From: Ista Zahn <istazahn at gmail.com>
Sent: Tuesday, December 6, 2016 10:08:28 AM
To: Patrick Casimir
Cc: r-help at r-project.org
Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?

What is in docs?

What does

inspect(docs)

say?

--Ista



On Tue, Dec 6, 2016 at 9:29 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
> Thanks Ista. See codes below. I am not sure why the DTM is showing 0 term. I
> have 4 documents in the corpus. And I was able to make transformations
>
> to the documents inside the corpus.
>
>
>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>> dir(cname)
> [1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
>> library(tm)
>> docs <- Corpus(DirSource(cname))
>> install.packages("magrittr" ,dependencies=TRUE)
>> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>%
>> writeLines()}
>> viewDocs(docs, 1)
>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ", x))
>> docs <- tm_map(docs, toSpace, "/|@|nn|")
>> inspect(docs[1])
>> docs <- tm_map(docs, removePunctuation)
>> docs <- tm_map(docs, removeWords, stopwords("english"))
>> inspect(docs[1])
>> docs <- tm_map(docs, stripWhitespace)
>> docs <- tm_map(docs, stemDocument)
>> dtm <- DocumentTermMatrix(docs)
>> dtm
> <<DocumentTermMatrix (documents: 4, terms: 0)>>
> Non-/sparse entries: 0/0
> Sparsity           : 100%
> Maximal term length: 0
> Weighting          : term frequency (tf)
>>
>
>
>
>
> ________________________________
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Tuesday, December 6, 2016 9:09:37 AM
> To: Patrick Casimir
> Cc: r-help at r-project.org
> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>
>
> Hi Patrick,
>
> How could anyone possibly answer this question with only the information
> you've provided? It's like showing me an empty cup and asking why it's
> empty. Maybe you didn't put anything in it. Maybe you did and then you dog
> drank it or your cat knocked it over or your girlfriend drank it. How would
> I possibly know?
>
> Bottom line, you need to show exactly what you did to produce that result,
> preferably in the form of a few lines of code that we can run to reproduce
> your problem.
>
> Finally, you may find it helpful take some time to learn how to ask
> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is a
> good place to learn this important skill.
>
> Best,
> Ista
>
>
> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>
> <<DocumentTermMatrix (documents: 4, terms: 0)>>
> Non-/sparse entries: 0/0
> Sparsity           : 100%
> Maximal term length: 0
> Weighting          : term frequency (tf)
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Tue Dec  6 16:26:58 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Tue, 6 Dec 2016 15:26:58 +0000 (UTC)
Subject: [R] (no subject)
References: <250726041.746769.1481038018016.ref@mail.yahoo.com>
Message-ID: <250726041.746769.1481038018016@mail.yahoo.com>

hi everyone,I tried to run my code in RStudio,but I received this error message,what should I do?Error: cannot allocate vector of size 12.1 Gb
In addition: Warning messages:
1: In cor(coding.rpkm[grep("23.C", coding.rpkm$name), -1], ncoding.rpkm[grep("23.C",  :
  Reached total allocation of 6027Mb: see help(memory.size)

	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Tue Dec  6 16:40:40 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Tue, 6 Dec 2016 15:40:40 +0000 (UTC)
Subject: [R] memory allocation problem
References: <1234229010.791666.1481038840370.ref@mail.yahoo.com>
Message-ID: <1234229010.791666.1481038840370@mail.yahoo.com>

hi everyone,
I tried to run my code in RStudio,but I received this error message,what should I do?
Error: cannot allocate vector of size 12.1 Gb
In addition: Warning messages:
1: In cor(coding.rpkm[grep("23.C", coding.rpkm$name), -1], ncoding.rpkm[grep("23.C",  :
  Reached total allocation of 6027Mb: see help(memory.size)
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Tue Dec  6 16:49:55 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Dec 2016 07:49:55 -0800
Subject: [R] memory allocation problem
In-Reply-To: <1234229010.791666.1481038840370@mail.yahoo.com>
References: <1234229010.791666.1481038840370.ref@mail.yahoo.com>
	<1234229010.791666.1481038840370@mail.yahoo.com>
Message-ID: <682D89E4-BBC4-4D94-BFE7-B4D3825357C2@dcn.davis.ca.us>

Buy more memory? Do something different than you were doing before the error occurred? Use a search engine to find what other people have done when this message appeared? Follow the recommendations in the Posting Guide mentioned in the footer of this and every post on this mailing list? 
-- 
Sent from my phone. Please excuse my brevity.

On December 6, 2016 7:40:40 AM PST, Elham - via R-help <r-help at r-project.org> wrote:
>hi everyone,
>I tried to run my code in RStudio,but I received this error
>message,what should I do?
>Error: cannot allocate vector of size 12.1 Gb
>In addition: Warning messages:
>1: In cor(coding.rpkm[grep("23.C", coding.rpkm$name), -1],
>ncoding.rpkm[grep("23.C",  :
>  Reached total allocation of 6027Mb: see help(memory.size)
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Dec  6 16:57:46 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Dec 2016 07:57:46 -0800
Subject: [R] Write a function that allows access to columns of a
	passeddataframe.
In-Reply-To: <5846DA54.4010303@sapo.pt>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
	<584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
	<CAF8bMcaPfTBvsZZv3KnGx0y5Tr5EGwGxBHnfW9zMTeae3ZNv7g@mail.gmail.com>
	<5846DA54.4010303@sapo.pt>
Message-ID: <CAF8bMcZs5RFEfHYH43eRXZQd8R72C90i3fMapa+FSjUNgSdA3g@mail.gmail.com>

Note that library has another argument, character.only=TRUE/FALSE,
to control whether the main argument should be regarded as a variable
or a literal.  I think you need two arguments to handle this.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Dec 6, 2016 at 7:33 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Perhaps the best way is the one used by library(), where both
> library(package) and library("package") work. It uses
> as.charecter/substitute, not deparse/substitute, as follows.
>
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(
> 20,34,43,32,21))
> mydf
> class(mydf)
> str(mydf)
>
> myfun <- function(frame,var){
>         yy <- as.character(substitute(var))
>         frame[, yy]
> }
>
> myfun(mydf, age)
> myfun(mydf, "age")
>
> Rui Barradas
>
> Em 06-12-2016 15:03, William Dunlap escreveu:
>
>> I basically agree with Rui - using substitute will cause trouble.  E.g.,
>> how
>> would the user iterate over the columns, calling your function for each?
>>       for(column in dataFrame) func(column)
>> would fail because dataFrame$column does not exist.  You need to provide
>> an extra argument to handle this case. something like the following:
>>       func <- function(df,
>>           columnAsName,,
>>           columnAsString = deparse(substitute(columnAsName))[1])
>>           ...
>>       }
>> The default value of columnAsString should also deal with the case that
>> the user supplied something like log(Conc.) instead of Conc.
>>
>> I think that using a formula for the lazily evaluated argument
>> (columnAsName)
>> works well.  The user then knows exactly how it gets evaluated.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>>
>> On Tue, Dec 6, 2016 at 6:28 AM, John Sorkin <jsorkin at grecc.umaryland.edu
>> <mailto:jsorkin at grecc.umaryland.edu>> wrote:
>>
>>     Over my almost 50 years programming, I have come to believe that if
>>     one wants a program to be useful, one should write the program to do
>>     as much work as possible and demand as little as possible from the
>>     user of the program. In my opinion, one should not ask the person
>>     who uses my function to remember to put the name of the data frame
>>     column in quotation marks. The function should be written so that
>>     all that needs to be passed is the name of the column; the function
>>     should take care of the quotation marks.
>>     Jihny
>>
>>     > John David Sorkin M.D., Ph.D.
>>     > Professor of Medicine
>>     > Chief, Biostatistics and Informatics
>>     > University of Maryland School of Medicine Division of Gerontology
>> and Geriatric Medicine
>>     > Baltimore VA Medical Center
>>     > 10 North Greene Street
>>     > GRECC (BT/18/GR)
>>     > Baltimore, MD 21201-1524
>>     > (Phone)410-605-7119 <tel:410-605-7119>
>>     > (Fax)410-605-7913 <tel:410-605-7913> (Please call phone number
>> above
>>     prior to faxing)
>>
>>
>>      > On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt
>>     <mailto:ruipbarradas at sapo.pt>> wrote:
>>      >
>>      > Hello,
>>      >
>>      > Just to say that I wouldn't write the function as John did. I
>>     would get
>>      > rid of all the deparse/substitute stuff and instinctively use a
>>     quoted
>>      > argument as a column name. Something like the following.
>>      >
>>      > myfun <- function(frame, var){
>>      >    [...]
>>      >    col <- frame[, var]  # or frame[[var]]
>>      >    [...]
>>      > }
>>      >
>>      > myfun(mydf, "age")  # much better, simpler, no promises.
>>      >
>>      > Rui Barradas
>>      >
>>      > Em 05-12-2016 21:49, Bert Gunter escreveu:
>>      >> Typo: "lazy evaluation" not "lay evaluation."
>>      >>
>>      >> -- Bert
>>      >>
>>      >>
>>      >>
>>      >> Bert Gunter
>>      >>
>>      >> "The trouble with having an open mind is that people keep coming
>>     along
>>      >> and sticking things into it."
>>      >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>      >>
>>      >>
>>      >>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter
>>     <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>>      >>> Sorry, hit "Send" by mistake.
>>      >>>
>>      >>> Inline.
>>      >>>
>>      >>>
>>      >>>
>>      >>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter
>>     <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>>      >>>> Inline.
>>      >>>>
>>      >>>> -- Bert
>>      >>>>
>>      >>>>
>>      >>>> Bert Gunter
>>      >>>>
>>      >>>> "The trouble with having an open mind is that people keep
>>     coming along
>>      >>>> and sticking things into it."
>>      >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic
>> strip )
>>      >>>>
>>      >>>>
>>      >>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas
>>     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>>      >>>>> Hello,
>>      >>>>>
>>      >>>>> Inline.
>>      >>>>>
>>      >>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>      >>>>>>
>>      >>>>>>
>>      >>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin
>>     <jsorkin at grecc.umaryland.edu <mailto:jsorkin at grecc.umaryland.edu>>
>>
>>      >>>>>>> wrote:
>>      >>>>>>>
>>      >>>>>>> Rui,
>>      >>>>>>> I appreciate your suggestion, but eliminating the deparse
>>     statement does
>>      >>>>>>> not solve my problem. Do you have any other suggestions?
>>     See code below.
>>      >>>>>>> Thank you,
>>      >>>>>>> John
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>> mydf <-
>>      >>>>>>>
>>     data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(
>> 20,34,43,32,21))
>>      >>>>>>> mydf
>>      >>>>>>> class(mydf)
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>> myfun <- function(frame,var){
>>      >>>>>>>   call <- match.call()
>>      >>>>>>>   print(call)
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>      >>>>>>>   print(indx)
>>      >>>>>>>   if(indx[1]==0) stop("Function called without sufficient
>>     arguments!")
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   cat("I can get the name of the dataframe as a text
>>     string!\n")
>>      >>>>>>>   #xx <- deparse(substitute(frame))
>>      >>>>>>>   print(xx)
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   cat("I can get the name of the column as a text string!\n")
>>      >>>>>>>   #yy <- deparse(substitute(var))
>>      >>>>>>>   print(yy)
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   # This does not work.
>>      >>>>>>>   print(frame[,var])
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   # This does not work.
>>      >>>>>>>   print(frame[,"var"])
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   # This does not work.
>>      >>>>>>>   col <- xx[,"yy"]
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>>   # Nor does this work.
>>      >>>>>>>   col <- xx[,yy]
>>      >>>>>>>   print(col)
>>      >>>>>>> }
>>      >>>>>>>
>>      >>>>>>>
>>      >>>>>>> myfun(mydf,age)
>>      >>>>>>
>>      >>>>>>
>>      >>>>>>
>>      >>>>>> When you use that calling syntax, the system will supply the
>>     values of
>>      >>>>>> whatever the `age` variable contains. (And if there is no
>>     `age`-named
>>      >>>>>> object, you get an error at the time of the call to `myfun`.
>>      >>>>>
>>      >>>>>
>>      >>>>> Actually, no, which was very surprising to me but John's code
>>     worked (not
>>      >>>>> the function, the call). And with the change I've proposed,
>>     it worked
>>      >>>>> flawlessly. No errors. Why I don't know.
>>      >>>
>>      >>> See ?substitute and in particular the example highlighted there.
>>      >>>
>>      >>> The technical details are explained in the R Language Definition
>>      >>> manual. The key here is the use of promises for lay evaluations.
>> In
>>      >>> fact, the expression in the call *is* available within the
>>     functions,
>>      >>> as is (a pointer to) the environment in which to evaluate the
>>      >>> expression. That is how substitute() works. Specifically,
>>     quoting from
>>      >>> the manual,
>>      >>>
>>      >>> *****
>>      >>> It is possible to access the actual (not default) expressions
>>     used as
>>      >>> arguments inside the function. The mechanism is implemented via
>>      >>> promises. When a function is being evaluated the actual
>> expression
>>      >>> used as an argument is stored in the promise together with a
>>     pointer
>>      >>> to the environment the function was called from. When (if) the
>>      >>> argument is evaluated the stored expression is evaluated in the
>>      >>> environment that the function was called from. Since only a
>>     pointer to
>>      >>> the environment is used any changes made to that environment
>>     will be
>>      >>> in effect during this evaluation. The resulting value is then
>> also
>>      >>> stored in a separate spot in the promise. Subsequent evaluations
>>      >>> retrieve this stored value (a second evaluation is not carried
>>     out).
>>      >>> Access to the unevaluated expression is also available using
>>      >>> substitute.
>>      >>> ********
>>      >>>
>>      >>> -- Bert
>>      >>>
>>      >>>
>>      >>>
>>      >>>
>>      >>>>>
>>      >>>>> Rui Barradas
>>      >>>>>
>>      >>>>>  You need either to call it as:
>>      >>>>>>
>>      >>>>>>
>>      >>>>>> myfun( mydf , "age")
>>      >>>>>>
>>      >>>>>>
>>      >>>>>> # Or:
>>      >>>>>>
>>      >>>>>> age <- "age"
>>      >>>>>> myfun( mydf, age)
>>      >>>>>>
>>      >>>>>> Unless your value of the `age`-named variable was "age" in
>>     the calling
>>      >>>>>> environment (and you did not give us that value in either of
>>     your postings),
>>      >>>>>> you would fail.
>>      >>>>>>
>>      >>>>>
>>      >>>>> ______________________________________________
>>      >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>     list -- To UNSUBSCRIBE and more, see
>>      >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>      >>>>> PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>      >>>>> and provide commented, minimal, self-contained, reproducible
>>     code.
>>
>>     Confidentiality Statement:
>>     This email message, including any attachments, is for the sole use
>>     of the intended recipient(s) and may contain confidential and
>>     privileged information. Any unauthorized use, disclosure or
>>     distribution is prohibited. If you are not the intended recipient,
>>     please contact the sender by reply email and destroy all copies of
>>     the original message.
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Dec  6 17:16:18 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Dec 2016 08:16:18 -0800
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
Message-ID: <CAGxFJbSPSuGb4cPZX=H8RxV3mhC1d=dkwbPa3xCyCt3ZD_-bCg@mail.gmail.com>

Fortune Nomination!


Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 6, 2016 at 6:09 AM, Ista Zahn <istazahn at gmail.com> wrote:
> Hi Patrick,
>
> How could anyone possibly answer this question with only the information
> you've provided? It's like showing me an empty cup and asking why it's
> empty. Maybe you didn't put anything in it. Maybe you did and then you dog
> drank it or your cat knocked it over or your girlfriend drank it. How would
> I possibly know?
>
> Bottom line, you need to show exactly what you did to produce that result,
> preferably in the form of a few lines of code that we can run to reproduce
> your problem.
>
> Finally, you may find it helpful take some time to learn how to ask
> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is
> a good place to learn this important skill.
>
> Best,
> Ista
>
> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>
> <<DocumentTermMatrix (documents: 4, terms: 0)>>
> Non-/sparse entries: 0/0
> Sparsity           : 100%
> Maximal term length: 0
> Weighting          : term frequency (tf)
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Dec  6 18:20:57 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 12:20:57 -0500
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <BN6PR06MB30252B39B0F6BB337A803512B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
	<BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>
	<BN6PR06MB30252B39B0F6BB337A803512B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
Message-ID: <CA+vqiLESDMR5R8s97Zvkc1U8ZjfiHLt8O_5RRsPyy0XaxrinNQ@mail.gmail.com>

Does

cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
docs <- Corpus(DirSource(cname))
dtm <- DocumentTermMatrix(docs)
dtm

work?

If so, add start adding back your tm_map until you find the thing that
breaks it.

Best,
Ista

On Tue, Dec 6, 2016 at 10:25 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>
> docs has 4 documents and inspect(docs) shows 4 plaintextdocument
>
>
>> summary(docs)
>           Length Class             Mode
> case1.txt 2      PlainTextDocument list
> case2.txt 2      PlainTextDocument list
> case3.txt 2      PlainTextDocument list
> case4.txt 2      PlainTextDocument list
>
>> inspect(docs)
> <<VCorpus>>
> Metadata:  corpus specific: 0, document level (indexed): 0
> Content:  documents: 4
>
> [[1]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 4564
>
> [[2]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 9312
>
> [[3]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 1388
>
> [[4]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 2366
>
>
>
> ________________________________
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Tuesday, December 6, 2016 10:08:28 AM
>
> To: Patrick Casimir
> Cc: r-help at r-project.org
> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>
> What is in docs?
>
> What does
>
> inspect(docs)
>
> say?
>
> --Ista
>
>
>
> On Tue, Dec 6, 2016 at 9:29 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>> Thanks Ista. See codes below. I am not sure why the DTM is showing 0 term.
>> I
>> have 4 documents in the corpus. And I was able to make transformations
>>
>> to the documents inside the corpus.
>>
>>
>>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>>> dir(cname)
>> [1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
>>> library(tm)
>>> docs <- Corpus(DirSource(cname))
>>> install.packages("magrittr" ,dependencies=TRUE)
>>> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>%
>>> writeLines()}
>>> viewDocs(docs, 1)
>>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ",
>>> x))
>>> docs <- tm_map(docs, toSpace, "/|@|nn|")
>>> inspect(docs[1])
>>> docs <- tm_map(docs, removePunctuation)
>>> docs <- tm_map(docs, removeWords, stopwords("english"))
>>> inspect(docs[1])
>>> docs <- tm_map(docs, stripWhitespace)
>>> docs <- tm_map(docs, stemDocument)
>>> dtm <- DocumentTermMatrix(docs)
>>> dtm
>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>> Non-/sparse entries: 0/0
>> Sparsity           : 100%
>> Maximal term length: 0
>> Weighting          : term frequency (tf)
>>>
>>
>>
>>
>>
>> ________________________________
>> From: Ista Zahn <istazahn at gmail.com>
>> Sent: Tuesday, December 6, 2016 9:09:37 AM
>> To: Patrick Casimir
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>>
>>
>> Hi Patrick,
>>
>> How could anyone possibly answer this question with only the information
>> you've provided? It's like showing me an empty cup and asking why it's
>> empty. Maybe you didn't put anything in it. Maybe you did and then you dog
>> drank it or your cat knocked it over or your girlfriend drank it. How
>> would
>> I possibly know?
>>
>> Bottom line, you need to show exactly what you did to produce that result,
>> preferably in the form of a few lines of code that we can run to reproduce
>> your problem.
>>
>> Finally, you may find it helpful take some time to learn how to ask
>> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is
>> a
>> good place to learn this important skill.
>>
>> Best,
>> Ista
>>
>>
>> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>>
>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>> Non-/sparse entries: 0/0
>> Sparsity           : 100%
>> Maximal term length: 0
>> Weighting          : term frequency (tf)
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


From ruipbarradas at sapo.pt  Tue Dec  6 15:44:16 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 06 Dec 2016 14:44:16 +0000
Subject: [R] Write a function that allows access to columns of a
	passeddataframe.
In-Reply-To: <584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
	<584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
Message-ID: <5846CEC0.20509@sapo.pt>

Ok, that's a way of seeing it.

Rui Barradas

Em 06-12-2016 14:28, John Sorkin escreveu:
> Over my almost 50 years programming, I have come to believe that if one
> wants a program to be useful, one should write the program to do as much
> work as possible and demand as little as possible from the user of the
> program. In my opinion, one should not ask the person who uses my
> function to remember to put the name of the data frame column in
> quotation marks. The function should be written so that all that needs
> to be passed is the name of the column; the function should take care of
> the quotation marks.
> Jihny
>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street <x-apple-data-detectors://12>
>> GRECC <x-apple-data-detectors://12> (BT/18/GR)
>> Baltimore, MD 21201-1524 <x-apple-data-detectors://13/0>
>> (Phone) 410-605-711 <tel:410-605-7119>9
>> (Fax)410-605-7913 <tel:410-605-7913> (Please call phone number above
>> prior to faxing)
>
> On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>> Hello,
>>
>> Just to say that I wouldn't write the function as John did. I would get
>> rid of all the deparse/substitute stuff and instinctively use a quoted
>> argument as a column name. Something like the following.
>>
>> myfun <- function(frame, var){
>>    [...]
>>    col <- frame[, var]  # or frame[[var]]
>>    [...]
>> }
>>
>> myfun(mydf, "age")  # much better, simpler, no promises.
>>
>> Rui Barradas
>>
>> Em 05-12-2016 21:49, Bert Gunter escreveu:
>>> Typo: "lazy evaluation" not "lay evaluation."
>>>
>>> -- Bert
>>>
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter <bgunter.4567 at gmail.com
>>> <mailto:bgunter.4567 at gmail.com>> wrote:
>>>> Sorry, hit "Send" by mistake.
>>>>
>>>> Inline.
>>>>
>>>>
>>>>
>>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter <bgunter.4567 at gmail.com
>>>> <mailto:bgunter.4567 at gmail.com>> wrote:
>>>>> Inline.
>>>>>
>>>>> -- Bert
>>>>>
>>>>>
>>>>> Bert Gunter
>>>>>
>>>>> "The trouble with having an open mind is that people keep coming along
>>>>> and sticking things into it."
>>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>>
>>>>>
>>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas <ruipbarradas at sapo.pt
>>>>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>>>>> Hello,
>>>>>>
>>>>>> Inline.
>>>>>>
>>>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>>>>>>
>>>>>>>
>>>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin
>>>>>>>> <jsorkin at grecc.umaryland.edu <mailto:jsorkin at grecc.umaryland.edu>>
>>>>>>>> wrote:
>>>>>>>>
>>>>>>>> Rui,
>>>>>>>> I appreciate your suggestion, but eliminating the deparse
>>>>>>>> statement does
>>>>>>>> not solve my problem. Do you have any other suggestions? See
>>>>>>>> code below.
>>>>>>>> Thank you,
>>>>>>>> John
>>>>>>>>
>>>>>>>>
>>>>>>>> mydf <-
>>>>>>>> data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>>>>>>> mydf
>>>>>>>> class(mydf)
>>>>>>>>
>>>>>>>>
>>>>>>>> myfun <- function(frame,var){
>>>>>>>>   call <- match.call()
>>>>>>>>   print(call)
>>>>>>>>
>>>>>>>>
>>>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>>>>>>>   print(indx)
>>>>>>>>   if(indx[1]==0) stop("Function called without sufficient
>>>>>>>> arguments!")
>>>>>>>>
>>>>>>>>
>>>>>>>>   cat("I can get the name of the dataframe as a text string!\n")
>>>>>>>>   #xx <- deparse(substitute(frame))
>>>>>>>>   print(xx)
>>>>>>>>
>>>>>>>>
>>>>>>>>   cat("I can get the name of the column as a text string!\n")
>>>>>>>>   #yy <- deparse(substitute(var))
>>>>>>>>   print(yy)
>>>>>>>>
>>>>>>>>
>>>>>>>>   # This does not work.
>>>>>>>>   print(frame[,var])
>>>>>>>>
>>>>>>>>
>>>>>>>>   # This does not work.
>>>>>>>>   print(frame[,"var"])
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>>   # This does not work.
>>>>>>>>   col <- xx[,"yy"]
>>>>>>>>
>>>>>>>>
>>>>>>>>   # Nor does this work.
>>>>>>>>   col <- xx[,yy]
>>>>>>>>   print(col)
>>>>>>>> }
>>>>>>>>
>>>>>>>>
>>>>>>>> myfun(mydf,age)
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> When you use that calling syntax, the system will supply the
>>>>>>> values of
>>>>>>> whatever the `age` variable contains. (And if there is no `age`-named
>>>>>>> object, you get an error at the time of the call to `myfun`.
>>>>>>
>>>>>>
>>>>>> Actually, no, which was very surprising to me but John's code
>>>>>> worked (not
>>>>>> the function, the call). And with the change I've proposed, it worked
>>>>>> flawlessly. No errors. Why I don't know.
>>>>
>>>> See ?substitute and in particular the example highlighted there.
>>>>
>>>> The technical details are explained in the R Language Definition
>>>> manual. The key here is the use of promises for lay evaluations. In
>>>> fact, the expression in the call *is* available within the functions,
>>>> as is (a pointer to) the environment in which to evaluate the
>>>> expression. That is how substitute() works. Specifically, quoting from
>>>> the manual,
>>>>
>>>> *****
>>>> It is possible to access the actual (not default) expressions used as
>>>> arguments inside the function. The mechanism is implemented via
>>>> promises. When a function is being evaluated the actual expression
>>>> used as an argument is stored in the promise together with a pointer
>>>> to the environment the function was called from. When (if) the
>>>> argument is evaluated the stored expression is evaluated in the
>>>> environment that the function was called from. Since only a pointer to
>>>> the environment is used any changes made to that environment will be
>>>> in effect during this evaluation. The resulting value is then also
>>>> stored in a separate spot in the promise. Subsequent evaluations
>>>> retrieve this stored value (a second evaluation is not carried out).
>>>> Access to the unevaluated expression is also available using
>>>> substitute.
>>>> ********
>>>>
>>>> -- Bert
>>>>
>>>>
>>>>
>>>>
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>>  You need either to call it as:
>>>>>>>
>>>>>>>
>>>>>>> myfun( mydf , "age")
>>>>>>>
>>>>>>>
>>>>>>> # Or:
>>>>>>>
>>>>>>> age <- "age"
>>>>>>> myfun( mydf, age)
>>>>>>>
>>>>>>> Unless your value of the `age`-named variable was "age" in the
>>>>>>> calling
>>>>>>> environment (and you did not give us that value in either of your
>>>>>>> postings),
>>>>>>> you would fail.
>>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>>>> To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>
> _*Confidentiality Statement:*_
>
> This email message, including any attachments, is for ...{{dropped:7}}


From ruipbarradas at sapo.pt  Tue Dec  6 16:33:40 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 06 Dec 2016 15:33:40 +0000
Subject: [R] Write a function that allows access to columns of a
	passeddataframe.
In-Reply-To: <CAF8bMcaPfTBvsZZv3KnGx0y5Tr5EGwGxBHnfW9zMTeae3ZNv7g@mail.gmail.com>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
	<584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
	<CAF8bMcaPfTBvsZZv3KnGx0y5Tr5EGwGxBHnfW9zMTeae3ZNv7g@mail.gmail.com>
Message-ID: <5846DA54.4010303@sapo.pt>

Perhaps the best way is the one used by library(), where both 
library(package) and library("package") work. It uses 
as.charecter/substitute, not deparse/substitute, as follows.

mydf <- 
data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
mydf
class(mydf)
str(mydf)

myfun <- function(frame,var){
	yy <- as.character(substitute(var))
	frame[, yy]
}

myfun(mydf, age)
myfun(mydf, "age")

Rui Barradas

Em 06-12-2016 15:03, William Dunlap escreveu:
> I basically agree with Rui - using substitute will cause trouble.  E.g., how
> would the user iterate over the columns, calling your function for each?
>       for(column in dataFrame) func(column)
> would fail because dataFrame$column does not exist.  You need to provide
> an extra argument to handle this case. something like the following:
>       func <- function(df,
>           columnAsName,,
>           columnAsString = deparse(substitute(columnAsName))[1])
>           ...
>       }
> The default value of columnAsString should also deal with the case that
> the user supplied something like log(Conc.) instead of Conc.
>
> I think that using a formula for the lazily evaluated argument
> (columnAsName)
> works well.  The user then knows exactly how it gets evaluated.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
>
> On Tue, Dec 6, 2016 at 6:28 AM, John Sorkin <jsorkin at grecc.umaryland.edu
> <mailto:jsorkin at grecc.umaryland.edu>> wrote:
>
>     Over my almost 50 years programming, I have come to believe that if
>     one wants a program to be useful, one should write the program to do
>     as much work as possible and demand as little as possible from the
>     user of the program. In my opinion, one should not ask the person
>     who uses my function to remember to put the name of the data frame
>     column in quotation marks. The function should be written so that
>     all that needs to be passed is the name of the column; the function
>     should take care of the quotation marks.
>     Jihny
>
>     > John David Sorkin M.D., Ph.D.
>     > Professor of Medicine
>     > Chief, Biostatistics and Informatics
>     > University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>     > Baltimore VA Medical Center
>     > 10 North Greene Street
>     > GRECC (BT/18/GR)
>     > Baltimore, MD 21201-1524
>     > (Phone)410-605-7119 <tel:410-605-7119>
>     > (Fax)410-605-7913 <tel:410-605-7913> (Please call phone number above
>     prior to faxing)
>
>
>      > On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt
>     <mailto:ruipbarradas at sapo.pt>> wrote:
>      >
>      > Hello,
>      >
>      > Just to say that I wouldn't write the function as John did. I
>     would get
>      > rid of all the deparse/substitute stuff and instinctively use a
>     quoted
>      > argument as a column name. Something like the following.
>      >
>      > myfun <- function(frame, var){
>      >    [...]
>      >    col <- frame[, var]  # or frame[[var]]
>      >    [...]
>      > }
>      >
>      > myfun(mydf, "age")  # much better, simpler, no promises.
>      >
>      > Rui Barradas
>      >
>      > Em 05-12-2016 21:49, Bert Gunter escreveu:
>      >> Typo: "lazy evaluation" not "lay evaluation."
>      >>
>      >> -- Bert
>      >>
>      >>
>      >>
>      >> Bert Gunter
>      >>
>      >> "The trouble with having an open mind is that people keep coming
>     along
>      >> and sticking things into it."
>      >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>      >>
>      >>
>      >>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter
>     <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>      >>> Sorry, hit "Send" by mistake.
>      >>>
>      >>> Inline.
>      >>>
>      >>>
>      >>>
>      >>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter
>     <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>      >>>> Inline.
>      >>>>
>      >>>> -- Bert
>      >>>>
>      >>>>
>      >>>> Bert Gunter
>      >>>>
>      >>>> "The trouble with having an open mind is that people keep
>     coming along
>      >>>> and sticking things into it."
>      >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>      >>>>
>      >>>>
>      >>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas
>     <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>      >>>>> Hello,
>      >>>>>
>      >>>>> Inline.
>      >>>>>
>      >>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>      >>>>>>
>      >>>>>>
>      >>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin
>     <jsorkin at grecc.umaryland.edu <mailto:jsorkin at grecc.umaryland.edu>>
>      >>>>>>> wrote:
>      >>>>>>>
>      >>>>>>> Rui,
>      >>>>>>> I appreciate your suggestion, but eliminating the deparse
>     statement does
>      >>>>>>> not solve my problem. Do you have any other suggestions?
>     See code below.
>      >>>>>>> Thank you,
>      >>>>>>> John
>      >>>>>>>
>      >>>>>>>
>      >>>>>>> mydf <-
>      >>>>>>>
>     data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>      >>>>>>> mydf
>      >>>>>>> class(mydf)
>      >>>>>>>
>      >>>>>>>
>      >>>>>>> myfun <- function(frame,var){
>      >>>>>>>   call <- match.call()
>      >>>>>>>   print(call)
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>      >>>>>>>   print(indx)
>      >>>>>>>   if(indx[1]==0) stop("Function called without sufficient
>     arguments!")
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   cat("I can get the name of the dataframe as a text
>     string!\n")
>      >>>>>>>   #xx <- deparse(substitute(frame))
>      >>>>>>>   print(xx)
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   cat("I can get the name of the column as a text string!\n")
>      >>>>>>>   #yy <- deparse(substitute(var))
>      >>>>>>>   print(yy)
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   # This does not work.
>      >>>>>>>   print(frame[,var])
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   # This does not work.
>      >>>>>>>   print(frame[,"var"])
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   # This does not work.
>      >>>>>>>   col <- xx[,"yy"]
>      >>>>>>>
>      >>>>>>>
>      >>>>>>>   # Nor does this work.
>      >>>>>>>   col <- xx[,yy]
>      >>>>>>>   print(col)
>      >>>>>>> }
>      >>>>>>>
>      >>>>>>>
>      >>>>>>> myfun(mydf,age)
>      >>>>>>
>      >>>>>>
>      >>>>>>
>      >>>>>> When you use that calling syntax, the system will supply the
>     values of
>      >>>>>> whatever the `age` variable contains. (And if there is no
>     `age`-named
>      >>>>>> object, you get an error at the time of the call to `myfun`.
>      >>>>>
>      >>>>>
>      >>>>> Actually, no, which was very surprising to me but John's code
>     worked (not
>      >>>>> the function, the call). And with the change I've proposed,
>     it worked
>      >>>>> flawlessly. No errors. Why I don't know.
>      >>>
>      >>> See ?substitute and in particular the example highlighted there.
>      >>>
>      >>> The technical details are explained in the R Language Definition
>      >>> manual. The key here is the use of promises for lay evaluations. In
>      >>> fact, the expression in the call *is* available within the
>     functions,
>      >>> as is (a pointer to) the environment in which to evaluate the
>      >>> expression. That is how substitute() works. Specifically,
>     quoting from
>      >>> the manual,
>      >>>
>      >>> *****
>      >>> It is possible to access the actual (not default) expressions
>     used as
>      >>> arguments inside the function. The mechanism is implemented via
>      >>> promises. When a function is being evaluated the actual expression
>      >>> used as an argument is stored in the promise together with a
>     pointer
>      >>> to the environment the function was called from. When (if) the
>      >>> argument is evaluated the stored expression is evaluated in the
>      >>> environment that the function was called from. Since only a
>     pointer to
>      >>> the environment is used any changes made to that environment
>     will be
>      >>> in effect during this evaluation. The resulting value is then also
>      >>> stored in a separate spot in the promise. Subsequent evaluations
>      >>> retrieve this stored value (a second evaluation is not carried
>     out).
>      >>> Access to the unevaluated expression is also available using
>      >>> substitute.
>      >>> ********
>      >>>
>      >>> -- Bert
>      >>>
>      >>>
>      >>>
>      >>>
>      >>>>>
>      >>>>> Rui Barradas
>      >>>>>
>      >>>>>  You need either to call it as:
>      >>>>>>
>      >>>>>>
>      >>>>>> myfun( mydf , "age")
>      >>>>>>
>      >>>>>>
>      >>>>>> # Or:
>      >>>>>>
>      >>>>>> age <- "age"
>      >>>>>> myfun( mydf, age)
>      >>>>>>
>      >>>>>> Unless your value of the `age`-named variable was "age" in
>     the calling
>      >>>>>> environment (and you did not give us that value in either of
>     your postings),
>      >>>>>> you would fail.
>      >>>>>>
>      >>>>>
>      >>>>> ______________________________________________
>      >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>     list -- To UNSUBSCRIBE and more, see
>      >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>      >>>>> PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>      >>>>> and provide commented, minimal, self-contained, reproducible
>     code.
>
>     Confidentiality Statement:
>     This email message, including any attachments, is for the sole use
>     of the intended recipient(s) and may contain confidential and
>     privileged information. Any unauthorized use, disclosure or
>     distribution is prohibited. If you are not the intended recipient,
>     please contact the sender by reply email and destroy all copies of
>     the original message.
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From mak.hholly at gmail.com  Tue Dec  6 19:18:41 2016
From: mak.hholly at gmail.com (greg holly)
Date: Tue, 6 Dec 2016 13:18:41 -0500
Subject: [R] CONFUSSING WITH select[!miss] <- 1:sum(!miss)
Message-ID: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>

Dear All;

I am very new in R and try to understand the logic for a program has been
run sucessfully. Here select[!miss] <- 1:sum(!miss) par is confussing me. I
need to understandand the logic behind this commend line.

Thanks in advance for your help,

Greg


miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
select <- integer(nrow(ph))
select[!miss] <- 1:sum(!miss)

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Dec  6 19:41:52 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 6 Dec 2016 10:41:52 -0800
Subject: [R] Write a function that allows access to columns of a
	passeddataframe.
In-Reply-To: <5846DA54.4010303@sapo.pt>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
	<584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
	<CAF8bMcaPfTBvsZZv3KnGx0y5Tr5EGwGxBHnfW9zMTeae3ZNv7g@mail.gmail.com>
	<5846DA54.4010303@sapo.pt>
Message-ID: <C6451355-9CF3-4C6C-8F74-920DCA3F919F@comcast.net>


> On Dec 6, 2016, at 7:33 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> 
> Perhaps the best way is the one used by library(), where both library(package) and library("package") work. It uses as.charecter/substitute, not deparse/substitute, as follows.
> 
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
> str(mydf)
> 
> myfun <- function(frame,var){
> 	yy <- as.character(substitute(var))
> 	frame[, yy]
> }
> 
> myfun(mydf, age)
> myfun(mydf, "age")
> 
> Rui Barradas
> 
> Em 06-12-2016 15:03, William Dunlap escreveu:
>> I basically agree with Rui - using substitute will cause trouble.  E.g., how
>> would the user iterate over the columns, calling your function for each?
>>      for(column in dataFrame) func(column)
>> would fail because dataFrame$column does not exist.  You need to provide
>> an extra argument to handle this case. something like the following:
>>      func <- function(df,
>>          columnAsName,,
>>          columnAsString = deparse(substitute(columnAsName))[1])
>>          ...
>>      }
>> The default value of columnAsString should also deal with the case that
>> the user supplied something like log(Conc.) instead of Conc.
>> 
>> I think that using a formula for the lazily evaluated argument
>> (columnAsName)
>> works well.  The user then knows exactly how it gets evaluated.

This would be an implementation that would support a multi-column extraction using a formula object:

mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
mydf
class(mydf)
str(mydf)

myfun <- function(frame, vars){
	yy <- terms(vars)
	frame[, attr(yy, "term.labels")]
}

myfun(mydf, ~age+sex)


>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>> 
>> On Tue, Dec 6, 2016 at 6:28 AM, John Sorkin <jsorkin at grecc.umaryland.edu
>> <mailto:jsorkin at grecc.umaryland.edu>> wrote:
>> 
>>    Over my almost 50 years programming, I have come to believe that if
>>    one wants a program to be useful, one should write the program to do
>>    as much work as possible and demand as little as possible from the
>>    user of the program. In my opinion, one should not ask the person
>>    who uses my function to remember to put the name of the data frame
>>    column in quotation marks. The function should be written so that
>>    all that needs to be passed is the name of the column; the function
>>    should take care of the quotation marks.
>>    Jihny
>> 
>>    > John David Sorkin M.D., Ph.D.
>>    > Professor of Medicine
>>    > Chief, Biostatistics and Informatics
>>    > University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>>    > Baltimore VA Medical Center
>>    > 10 North Greene Street
>>    > GRECC (BT/18/GR)
>>    > Baltimore, MD 21201-1524
>>    > (Phone)410-605-7119 <tel:410-605-7119>
>>    > (Fax)410-605-7913 <tel:410-605-7913> (Please call phone number above
>>    prior to faxing)
>> 
>> 
>>     > On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt
>>    <mailto:ruipbarradas at sapo.pt>> wrote:
>>     >
>>     > Hello,
>>     >
>>     > Just to say that I wouldn't write the function as John did. I
>>    would get
>>     > rid of all the deparse/substitute stuff and instinctively use a
>>    quoted
>>     > argument as a column name. Something like the following.
>>     >
>>     > myfun <- function(frame, var){
>>     >    [...]
>>     >    col <- frame[, var]  # or frame[[var]]
>>     >    [...]
>>     > }
>>     >
>>     > myfun(mydf, "age")  # much better, simpler, no promises.
>>     >
>>     > Rui Barradas
>>     >
>>     > Em 05-12-2016 21:49, Bert Gunter escreveu:
>>     >> Typo: "lazy evaluation" not "lay evaluation."
>>     >>
>>     >> -- Bert
>>     >>
>>     >>
>>     >>
>>     >> Bert Gunter
>>     >>
>>     >> "The trouble with having an open mind is that people keep coming
>>    along
>>     >> and sticking things into it."
>>     >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>     >>
>>     >>
>>     >>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter
>>    <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>>     >>> Sorry, hit "Send" by mistake.
>>     >>>
>>     >>> Inline.
>>     >>>
>>     >>>
>>     >>>
>>     >>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter
>>    <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>>     >>>> Inline.
>>     >>>>
>>     >>>> -- Bert
>>     >>>>
>>     >>>>
>>     >>>> Bert Gunter
>>     >>>>
>>     >>>> "The trouble with having an open mind is that people keep
>>    coming along
>>     >>>> and sticking things into it."
>>     >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>     >>>>
>>     >>>>
>>     >>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas
>>    <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>>     >>>>> Hello,
>>     >>>>>
>>     >>>>> Inline.
>>     >>>>>
>>     >>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>     >>>>>>
>>     >>>>>>
>>     >>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin
>>    <jsorkin at grecc.umaryland.edu <mailto:jsorkin at grecc.umaryland.edu>>
>>     >>>>>>> wrote:
>>     >>>>>>>
>>     >>>>>>> Rui,
>>     >>>>>>> I appreciate your suggestion, but eliminating the deparse
>>    statement does
>>     >>>>>>> not solve my problem. Do you have any other suggestions?
>>    See code below.
>>     >>>>>>> Thank you,
>>     >>>>>>> John
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> mydf <-
>>     >>>>>>>
>>    data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>     >>>>>>> mydf
>>     >>>>>>> class(mydf)
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> myfun <- function(frame,var){
>>     >>>>>>>   call <- match.call()
>>     >>>>>>>   print(call)
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>     >>>>>>>   print(indx)
>>     >>>>>>>   if(indx[1]==0) stop("Function called without sufficient
>>    arguments!")
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   cat("I can get the name of the dataframe as a text
>>    string!\n")
>>     >>>>>>>   #xx <- deparse(substitute(frame))
>>     >>>>>>>   print(xx)
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   cat("I can get the name of the column as a text string!\n")
>>     >>>>>>>   #yy <- deparse(substitute(var))
>>     >>>>>>>   print(yy)
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   # This does not work.
>>     >>>>>>>   print(frame[,var])
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   # This does not work.
>>     >>>>>>>   print(frame[,"var"])
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   # This does not work.
>>     >>>>>>>   col <- xx[,"yy"]
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>>   # Nor does this work.
>>     >>>>>>>   col <- xx[,yy]
>>     >>>>>>>   print(col)
>>     >>>>>>> }
>>     >>>>>>>
>>     >>>>>>>
>>     >>>>>>> myfun(mydf,age)
>>     >>>>>>
>>     >>>>>>
>>     >>>>>>
>>     >>>>>> When you use that calling syntax, the system will supply the
>>    values of
>>     >>>>>> whatever the `age` variable contains. (And if there is no
>>    `age`-named
>>     >>>>>> object, you get an error at the time of the call to `myfun`.
>>     >>>>>
>>     >>>>>
>>     >>>>> Actually, no, which was very surprising to me but John's code
>>    worked (not
>>     >>>>> the function, the call). And with the change I've proposed,
>>    it worked
>>     >>>>> flawlessly. No errors. Why I don't know.
>>     >>>
>>     >>> See ?substitute and in particular the example highlighted there.
>>     >>>
>>     >>> The technical details are explained in the R Language Definition
>>     >>> manual. The key here is the use of promises for lay evaluations. In
>>     >>> fact, the expression in the call *is* available within the
>>    functions,
>>     >>> as is (a pointer to) the environment in which to evaluate the
>>     >>> expression. That is how substitute() works. Specifically,
>>    quoting from
>>     >>> the manual,
>>     >>>
>>     >>> *****
>>     >>> It is possible to access the actual (not default) expressions
>>    used as
>>     >>> arguments inside the function. The mechanism is implemented via
>>     >>> promises. When a function is being evaluated the actual expression
>>     >>> used as an argument is stored in the promise together with a
>>    pointer
>>     >>> to the environment the function was called from. When (if) the
>>     >>> argument is evaluated the stored expression is evaluated in the
>>     >>> environment that the function was called from. Since only a
>>    pointer to
>>     >>> the environment is used any changes made to that environment
>>    will be
>>     >>> in effect during this evaluation. The resulting value is then also
>>     >>> stored in a separate spot in the promise. Subsequent evaluations
>>     >>> retrieve this stored value (a second evaluation is not carried
>>    out).
>>     >>> Access to the unevaluated expression is also available using
>>     >>> substitute.
>>     >>> ********
>>     >>>
>>     >>> -- Bert
>>     >>>
>>     >>>
>>     >>>
>>     >>>
>>     >>>>>
>>     >>>>> Rui Barradas
>>     >>>>>
>>     >>>>>  You need either to call it as:
>>     >>>>>>
>>     >>>>>>
>>     >>>>>> myfun( mydf , "age")
>>     >>>>>>
>>     >>>>>>
>>     >>>>>> # Or:
>>     >>>>>>
>>     >>>>>> age <- "age"
>>     >>>>>> myfun( mydf, age)
>>     >>>>>>
>>     >>>>>> Unless your value of the `age`-named variable was "age" in
>>    the calling
>>     >>>>>> environment (and you did not give us that value in either of
>>    your postings),
>>     >>>>>> you would fail.
>>     >>>>>>
>>     >>>>>
>>     >>>>> ______________________________________________
>>     >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>    list -- To UNSUBSCRIBE and more, see
>>     >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     >>>>> PLEASE do read the posting guide
>>    http://www.R-project.org/posting-guide.html
>>    <http://www.R-project.org/posting-guide.html>
>>     >>>>> and provide commented, minimal, self-contained, reproducible
>>    code.
>> 
>>    Confidentiality Statement:
>>    This email message, including any attachments, is for the sole use
>>    of the intended recipient(s) and may contain confidential and
>>    privileged information. Any unauthorized use, disclosure or
>>    distribution is prohibited. If you are not the intended recipient,
>>    please contact the sender by reply email and destroy all copies of
>>    the original message.
>>    ______________________________________________
>>    R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>    To UNSUBSCRIBE and more, see
>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>    PLEASE do read the posting guide
>>    http://www.R-project.org/posting-guide.html
>>    <http://www.R-project.org/posting-guide.html>
>>    and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Tue Dec  6 20:04:01 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 06 Dec 2016 19:04:01 +0000
Subject: [R] CONFUSSING WITH select[!miss] <- 1:sum(!miss)
In-Reply-To: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
References: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
Message-ID: <58470BA1.5010504@sapo.pt>

Hello,

The first command line produces a logical vector with TRUE if at least 
one row element of ph is NA and FALSE otherwise.
The second creates a vector of zeros with length equal to nrow(ph).
Now the third command line. ! negates miss, so TRUE becomes FALSE and 
vice-versa. sum(!miss) counts how many not misses are there and 
1:sum(!miss) creates a vector 1, 2, ..., sum(!miss). To see this print 
each of these components one by one:

print(miss)
print(!miss)
print(sum(!miss))
etc

And select[!miss] uses a logical index into 'select' to set only the 
values of 'select' where !miss is TRUE equal to 1, 2, 3, ...

I believe you should read R-intro.pdf that comes with your installation 
of R more carefully, specially sections 2.4 and 2.7.

Hope this helps,

Rui Barradas

Em 06-12-2016 18:18, greg holly escreveu:
> Dear All;
>
> I am very new in R and try to understand the logic for a program has been
> run sucessfully. Here select[!miss] <- 1:sum(!miss) par is confussing me. I
> need to understandand the logic behind this commend line.
>
> Thanks in advance for your help,
>
> Greg
>
>
> miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
> select <- integer(nrow(ph))
> select[!miss] <- 1:sum(!miss)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Tue Dec  6 20:04:52 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Dec 2016 11:04:52 -0800
Subject: [R] CONFUSSING WITH select[!miss] <- 1:sum(!miss)
In-Reply-To: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
References: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
Message-ID: <CAF8bMcaRBg1X0iZgoE8Sg3UvEa6bZf7tHqr8VsZYT=Evzo_80A@mail.gmail.com>

R is interactive so you can print the intermediate results:
> ph <- data.frame(M1=c(1,NA,3,4,5), X1=1:5, X2=c(1,2,NA,4,5), X3=1:5,
Y=c(11,12,13,14,NA), row.names=paste0("R",1:5))
> ph
   M1 X1 X2 X3  Y
R1  1  1  1  1 11
R2 NA  2  2  2 12
R3  3  3 NA  3 13
R4  4  4  4  4 14
R5  5  5  5  5 NA
> miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
> miss
   R1    R2    R3    R4    R5
FALSE  TRUE  TRUE FALSE FALSE
> select <- integer(nrow(ph))
> select
[1] 0 0 0 0 0
> sum(!miss)
[1] 3
> select[!miss] <- 1:sum(!miss)
> select
[1] 1 0 0 2 3

Then you can look in the Introduction to R document or ask about the steps
that confuse you.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Dec 6, 2016 at 10:18 AM, greg holly <mak.hholly at gmail.com> wrote:

> Dear All;
>
> I am very new in R and try to understand the logic for a program has been
> run sucessfully. Here select[!miss] <- 1:sum(!miss) par is confussing me. I
> need to understandand the logic behind this commend line.
>
> Thanks in advance for your help,
>
> Greg
>
>
> miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
> select <- integer(nrow(ph))
> select[!miss] <- 1:sum(!miss)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From patrcasi at nova.edu  Tue Dec  6 20:28:05 2016
From: patrcasi at nova.edu (Patrick Casimir)
Date: Tue, 6 Dec 2016 19:28:05 +0000
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <CA+vqiLESDMR5R8s97Zvkc1U8ZjfiHLt8O_5RRsPyy0XaxrinNQ@mail.gmail.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
	<BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>
	<BN6PR06MB30252B39B0F6BB337A803512B9820@BN6PR06MB3025.namprd06.prod.outlook.com>,
	<CA+vqiLESDMR5R8s97Zvkc1U8ZjfiHLt8O_5RRsPyy0XaxrinNQ@mail.gmail.com>
Message-ID: <BN6PR06MB30250F44B6487C1FBE2A415AB9820@BN6PR06MB3025.namprd06.prod.outlook.com>

Actually, the DTM works now. This is amazing.  Million thanks. Why wasn't it working before?

See below:


> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
> docs <- Corpus(DirSource(cname))
> dtm <- DocumentTermMatrix(docs)
> dtm
<<DocumentTermMatrix (documents: 4, terms: 766)>>
Non-/sparse entries: 920/2144
Sparsity           : 70%
Maximal term length: 29
Weighting          : term frequency (tf)



________________________________
From: Ista Zahn <istazahn at gmail.com>
Sent: Tuesday, December 6, 2016 12:20:57 PM
To: Patrick Casimir
Cc: r-help at r-project.org
Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?

Does

cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
docs <- Corpus(DirSource(cname))
dtm <- DocumentTermMatrix(docs)
dtm

work?

If so, add start adding back your tm_map until you find the thing that
breaks it.

Best,
Ista

On Tue, Dec 6, 2016 at 10:25 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>
> docs has 4 documents and inspect(docs) shows 4 plaintextdocument
>
>
>> summary(docs)
>           Length Class             Mode
> case1.txt 2      PlainTextDocument list
> case2.txt 2      PlainTextDocument list
> case3.txt 2      PlainTextDocument list
> case4.txt 2      PlainTextDocument list
>
>> inspect(docs)
> <<VCorpus>>
> Metadata:  corpus specific: 0, document level (indexed): 0
> Content:  documents: 4
>
> [[1]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 4564
>
> [[2]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 9312
>
> [[3]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 1388
>
> [[4]]
> <<PlainTextDocument>>
> Metadata:  7
> Content:  chars: 2366
>
>
>
> ________________________________
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Tuesday, December 6, 2016 10:08:28 AM
>
> To: Patrick Casimir
> Cc: r-help at r-project.org
> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>
> What is in docs?
>
> What does
>
> inspect(docs)
>
> say?
>
> --Ista
>
>
>
> On Tue, Dec 6, 2016 at 9:29 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>> Thanks Ista. See codes below. I am not sure why the DTM is showing 0 term.
>> I
>> have 4 documents in the corpus. And I was able to make transformations
>>
>> to the documents inside the corpus.
>>
>>
>>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>>> dir(cname)
>> [1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
>>> library(tm)
>>> docs <- Corpus(DirSource(cname))
>>> install.packages("magrittr" ,dependencies=TRUE)
>>> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>%
>>> writeLines()}
>>> viewDocs(docs, 1)
>>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ",
>>> x))
>>> docs <- tm_map(docs, toSpace, "/|@|nn|")
>>> inspect(docs[1])
>>> docs <- tm_map(docs, removePunctuation)
>>> docs <- tm_map(docs, removeWords, stopwords("english"))
>>> inspect(docs[1])
>>> docs <- tm_map(docs, stripWhitespace)
>>> docs <- tm_map(docs, stemDocument)
>>> dtm <- DocumentTermMatrix(docs)
>>> dtm
>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>> Non-/sparse entries: 0/0
>> Sparsity           : 100%
>> Maximal term length: 0
>> Weighting          : term frequency (tf)
>>>
>>
>>
>>
>>
>> ________________________________
>> From: Ista Zahn <istazahn at gmail.com>
>> Sent: Tuesday, December 6, 2016 9:09:37 AM
>> To: Patrick Casimir
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>>
>>
>> Hi Patrick,
>>
>> How could anyone possibly answer this question with only the information
>> you've provided? It's like showing me an empty cup and asking why it's
>> empty. Maybe you didn't put anything in it. Maybe you did and then you dog
>> drank it or your cat knocked it over or your girlfriend drank it. How
>> would
>> I possibly know?
>>
>> Bottom line, you need to show exactly what you did to produce that result,
>> preferably in the form of a few lines of code that we can run to reproduce
>> your problem.
>>
>> Finally, you may find it helpful take some time to learn how to ask
>> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html is
>> a
>> good place to learn this important skill.
>>
>> Best,
>> Ista
>>
>>
>> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>>
>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>> Non-/sparse entries: 0/0
>> Sparsity           : 100%
>> Maximal term length: 0
>> Weighting          : term frequency (tf)
>>
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Tue Dec  6 20:49:30 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 14:49:30 -0500
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <BN6PR06MB30250F44B6487C1FBE2A415AB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
	<BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>
	<BN6PR06MB30252B39B0F6BB337A803512B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLESDMR5R8s97Zvkc1U8ZjfiHLt8O_5RRsPyy0XaxrinNQ@mail.gmail.com>
	<BN6PR06MB30250F44B6487C1FBE2A415AB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
Message-ID: <CA+vqiLFwsmVfE-Vej0pBmqefmAfOLV9+Ea4vxGZg=Rmedte3pA@mail.gmail.com>

On Tue, Dec 6, 2016 at 2:28 PM, Patrick Casimir <patrcasi at nova.edu> wrote:
> Actually, the DTM works now. This is amazing.  Million thanks. Why wasn't it
> working before?

Do as I suggested and

start adding back your tm_map's until you find the thing that
breaks it.

--Ista

>
> See below:
>
>
>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>> docs <- Corpus(DirSource(cname))
>> dtm <- DocumentTermMatrix(docs)
>> dtm
> <<DocumentTermMatrix (documents: 4, terms: 766)>>
> Non-/sparse entries: 920/2144
> Sparsity           : 70%
> Maximal term length: 29
> Weighting          : term frequency (tf)
>
>
>
> ________________________________
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Tuesday, December 6, 2016 12:20:57 PM
>
> To: Patrick Casimir
> Cc: r-help at r-project.org
> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>
> Does
>
> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
> docs <- Corpus(DirSource(cname))
> dtm <- DocumentTermMatrix(docs)
> dtm
>
> work?
>
> If so, add start adding back your tm_map until you find the thing that
> breaks it.
>
> Best,
> Ista
>
> On Tue, Dec 6, 2016 at 10:25 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>>
>> docs has 4 documents and inspect(docs) shows 4 plaintextdocument
>>
>>
>>> summary(docs)
>>           Length Class             Mode
>> case1.txt 2      PlainTextDocument list
>> case2.txt 2      PlainTextDocument list
>> case3.txt 2      PlainTextDocument list
>> case4.txt 2      PlainTextDocument list
>>
>>> inspect(docs)
>> <<VCorpus>>
>> Metadata:  corpus specific: 0, document level (indexed): 0
>> Content:  documents: 4
>>
>> [[1]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 4564
>>
>> [[2]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 9312
>>
>> [[3]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 1388
>>
>> [[4]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 2366
>>
>>
>>
>> ________________________________
>> From: Ista Zahn <istazahn at gmail.com>
>> Sent: Tuesday, December 6, 2016 10:08:28 AM
>>
>> To: Patrick Casimir
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>>
>> What is in docs?
>>
>> What does
>>
>> inspect(docs)
>>
>> say?
>>
>> --Ista
>>
>>
>>
>> On Tue, Dec 6, 2016 at 9:29 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>>> Thanks Ista. See codes below. I am not sure why the DTM is showing 0
>>> term.
>>> I
>>> have 4 documents in the corpus. And I was able to make transformations
>>>
>>> to the documents inside the corpus.
>>>
>>>
>>>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>>>> dir(cname)
>>> [1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
>>>> library(tm)
>>>> docs <- Corpus(DirSource(cname))
>>>> install.packages("magrittr" ,dependencies=TRUE)
>>>> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>%
>>>> writeLines()}
>>>> viewDocs(docs, 1)
>>>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ",
>>>> x))
>>>> docs <- tm_map(docs, toSpace, "/|@|nn|")
>>>> inspect(docs[1])
>>>> docs <- tm_map(docs, removePunctuation)
>>>> docs <- tm_map(docs, removeWords, stopwords("english"))
>>>> inspect(docs[1])
>>>> docs <- tm_map(docs, stripWhitespace)
>>>> docs <- tm_map(docs, stemDocument)
>>>> dtm <- DocumentTermMatrix(docs)
>>>> dtm
>>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>>> Non-/sparse entries: 0/0
>>> Sparsity           : 100%
>>> Maximal term length: 0
>>> Weighting          : term frequency (tf)
>>>>
>>>
>>>
>>>
>>>
>>> ________________________________
>>> From: Ista Zahn <istazahn at gmail.com>
>>> Sent: Tuesday, December 6, 2016 9:09:37 AM
>>> To: Patrick Casimir
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>>>
>>>
>>> Hi Patrick,
>>>
>>> How could anyone possibly answer this question with only the information
>>> you've provided? It's like showing me an empty cup and asking why it's
>>> empty. Maybe you didn't put anything in it. Maybe you did and then you
>>> dog
>>> drank it or your cat knocked it over or your girlfriend drank it. How
>>> would
>>> I possibly know?
>>>
>>> Bottom line, you need to show exactly what you did to produce that
>>> result,
>>> preferably in the form of a few lines of code that we can run to
>>> reproduce
>>> your problem.
>>>
>>> Finally, you may find it helpful take some time to learn how to ask
>>> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html
>>> is
>>> a
>>> good place to learn this important skill.
>>>
>>> Best,
>>> Ista
>>>
>>>
>>> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>>>
>>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>>> Non-/sparse entries: 0/0
>>> Sparsity           : 100%
>>> Maximal term length: 0
>>> Weighting          : term frequency (tf)
>>>
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>


From patrcasi at nova.edu  Tue Dec  6 21:00:25 2016
From: patrcasi at nova.edu (Patrick Casimir)
Date: Tue, 6 Dec 2016 20:00:25 +0000
Subject: [R] Why is DocumentTermMatrix showing 0 term?
In-Reply-To: <CA+vqiLFwsmVfE-Vej0pBmqefmAfOLV9+Ea4vxGZg=Rmedte3pA@mail.gmail.com>
References: <BN6PR06MB30255EA9D289691283EFCBBCB9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLFFbzCgUPsRN6T7YjkAs3W_HUK-a8TiYeA0BYfYH5XGYg@mail.gmail.com>
	<CA+vqiLHQ1FgdqupU_oQ8R25-nrzXcNXhvsP5Q3dsLFTTJqfd3A@mail.gmail.com>
	<CA+vqiLGzwUdR8m21_eW05VUq_of3enw1D8D7MGMYkoJ8hNSdAA@mail.gmail.com>
	<BN6PR06MB3025B0DDD8A6B88F88A2B0F2B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLG+sZjyyYS=dxY6syA7U4fN7UFUzcMm984kLoCG=JKSqw@mail.gmail.com>
	<BN6PR06MB30252B39B0F6BB337A803512B9820@BN6PR06MB3025.namprd06.prod.outlook.com>
	<CA+vqiLESDMR5R8s97Zvkc1U8ZjfiHLt8O_5RRsPyy0XaxrinNQ@mail.gmail.com>
	<BN6PR06MB30250F44B6487C1FBE2A415AB9820@BN6PR06MB3025.namprd06.prod.outlook.com>,
	<CA+vqiLFwsmVfE-Vej0pBmqefmAfOLV9+Ea4vxGZg=Rmedte3pA@mail.gmail.com>
Message-ID: <BN6PR06MB3025E6F4D1167C0326DB5729B9820@BN6PR06MB3025.namprd06.prod.outlook.com>



Will do.

________________________________
From: Ista Zahn <istazahn at gmail.com>
Sent: Tuesday, December 6, 2016 2:49:30 PM
To: Patrick Casimir
Cc: r-help at r-project.org
Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?

On Tue, Dec 6, 2016 at 2:28 PM, Patrick Casimir <patrcasi at nova.edu> wrote:
> Actually, the DTM works now. This is amazing.  Million thanks. Why wasn't it
> working before?

Do as I suggested and

start adding back your tm_map's until you find the thing that
breaks it.

--Ista

>
> See below:
>
>
>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>> docs <- Corpus(DirSource(cname))
>> dtm <- DocumentTermMatrix(docs)
>> dtm
> <<DocumentTermMatrix (documents: 4, terms: 766)>>
> Non-/sparse entries: 920/2144
> Sparsity           : 70%
> Maximal term length: 29
> Weighting          : term frequency (tf)
>
>
>
> ________________________________
> From: Ista Zahn <istazahn at gmail.com>
> Sent: Tuesday, December 6, 2016 12:20:57 PM
>
> To: Patrick Casimir
> Cc: r-help at r-project.org
> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>
> Does
>
> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
> docs <- Corpus(DirSource(cname))
> dtm <- DocumentTermMatrix(docs)
> dtm
>
> work?
>
> If so, add start adding back your tm_map until you find the thing that
> breaks it.
>
> Best,
> Ista
>
> On Tue, Dec 6, 2016 at 10:25 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>>
>> docs has 4 documents and inspect(docs) shows 4 plaintextdocument
>>
>>
>>> summary(docs)
>>           Length Class             Mode
>> case1.txt 2      PlainTextDocument list
>> case2.txt 2      PlainTextDocument list
>> case3.txt 2      PlainTextDocument list
>> case4.txt 2      PlainTextDocument list
>>
>>> inspect(docs)
>> <<VCorpus>>
>> Metadata:  corpus specific: 0, document level (indexed): 0
>> Content:  documents: 4
>>
>> [[1]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 4564
>>
>> [[2]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 9312
>>
>> [[3]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 1388
>>
>> [[4]]
>> <<PlainTextDocument>>
>> Metadata:  7
>> Content:  chars: 2366
>>
>>
>>
>> ________________________________
>> From: Ista Zahn <istazahn at gmail.com>
>> Sent: Tuesday, December 6, 2016 10:08:28 AM
>>
>> To: Patrick Casimir
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>>
>> What is in docs?
>>
>> What does
>>
>> inspect(docs)
>>
>> say?
>>
>> --Ista
>>
>>
>>
>> On Tue, Dec 6, 2016 at 9:29 AM, Patrick Casimir <patrcasi at nova.edu> wrote:
>>> Thanks Ista. See codes below. I am not sure why the DTM is showing 0
>>> term.
>>> I
>>> have 4 documents in the corpus. And I was able to make transformations
>>>
>>> to the documents inside the corpus.
>>>
>>>
>>>> cname <- file.path("C:\\Users\\Desktop\\Text Mining\\Cases\\MyCorpus")
>>>> dir(cname)
>>> [1] "case1.txt" "case2.txt" "case3.txt" "case4.txt"
>>>> library(tm)
>>>> docs <- Corpus(DirSource(cname))
>>>> install.packages("magrittr" ,dependencies=TRUE)
>>>> viewDocs <- function(d, n) {d %>% extract2(n) %>% as.character() %>%
>>>> writeLines()}
>>>> viewDocs(docs, 1)
>>>> toSpace <- content_transformer(function(x, pattern) gsub(pattern, " ",
>>>> x))
>>>> docs <- tm_map(docs, toSpace, "/|@|nn|")
>>>> inspect(docs[1])
>>>> docs <- tm_map(docs, removePunctuation)
>>>> docs <- tm_map(docs, removeWords, stopwords("english"))
>>>> inspect(docs[1])
>>>> docs <- tm_map(docs, stripWhitespace)
>>>> docs <- tm_map(docs, stemDocument)
>>>> dtm <- DocumentTermMatrix(docs)
>>>> dtm
>>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>>> Non-/sparse entries: 0/0
>>> Sparsity           : 100%
>>> Maximal term length: 0
>>> Weighting          : term frequency (tf)
>>>>
>>>
>>>
>>>
>>>
>>> ________________________________
>>> From: Ista Zahn <istazahn at gmail.com>
>>> Sent: Tuesday, December 6, 2016 9:09:37 AM
>>> To: Patrick Casimir
>>> Cc: r-help at r-project.org
>>> Subject: Re: [R] Why is DocumentTermMatrix showing 0 term?
>>>
>>>
>>> Hi Patrick,
>>>
>>> How could anyone possibly answer this question with only the information
>>> you've provided? It's like showing me an empty cup and asking why it's
>>> empty. Maybe you didn't put anything in it. Maybe you did and then you
>>> dog
>>> drank it or your cat knocked it over or your girlfriend drank it. How
>>> would
>>> I possibly know?
>>>
>>> Bottom line, you need to show exactly what you did to produce that
>>> result,
>>> preferably in the form of a few lines of code that we can run to
>>> reproduce
>>> your problem.
>>>
>>> Finally, you may find it helpful take some time to learn how to ask
>>> questions the smart way. http://catb.org/~esr/faqs/smart-questions.html
>>> is
>>> a
>>> good place to learn this important skill.
>>>
>>> Best,
>>> Ista
>>>
>>>
>>> On Dec 6, 2016 7:58 AM, "Patrick Casimir" <patrcasi at nova.edu> wrote:
>>>
>>> <<DocumentTermMatrix (documents: 4, terms: 0)>>
>>> Non-/sparse entries: 0/0
>>> Sparsity           : 100%
>>> Maximal term length: 0
>>> Weighting          : term frequency (tf)
>>>
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>

	[[alternative HTML version deleted]]


From Vanessa.Vetter at uni-bayreuth.de  Tue Dec  6 21:00:58 2016
From: Vanessa.Vetter at uni-bayreuth.de (Vetter, Vanessa)
Date: Tue, 6 Dec 2016 20:00:58 +0000
Subject: [R] Polygon to raster with large data set
Message-ID: <2ee159bf557b4bce98ab35d5983eec17@btrxmbx01.myubt.de>

Hi everyone,
I have a very large shapefile with many polygons (17769 polygons, 104.4 Mb), which I want to convert to a raster file. A grid cell can be covered by either none, 1 or several polygons. I want to assign the percentage cover of polygons to the respective grid cell, just like the function rasterize (x, y, getCover=TRUE) does. The big problem ist, that the rasterize function only notes those polygons covering the center of the grid cell and ignores all others. So, I lose more than half of my data set when applying this. The second problem is that my data is very large. I tried this (see below), but it is very slow and at some point crashes down (but works for smaller data sets):

(r = raster, ln = shapefile with polygons)

rp <- rasterToPolygons(r)

covers <- unique(ln at data$PERCENTAGE)

for(cover in covers){
  psub <- subset(ln, PERCENTAGE==cover)
  pu <- gUnaryUnion(psub)
  gi <- gIntersection(rp, pu, byid = T)
  ind <- as.numeric(do.call(rbind, strsplit(names(gi), " "))[,1])
  r[] <- NA
  r[ind] <- sapply(gi at polygons, function(x) slot(x, 'area'))  # a bit faster than gArea(gi, byid = T)
  writeRaster(r, paste0("cover/", cover, "area.tif"))
}

Every polygon contains a cover estimation (percentage cover of an invasive plant species) and the column name of that information is called PERCENTAGE. There are basically 4 cover classes. At the end of this loope I get 4 rasters, which are named correspondingly to the cover class and in whose raster cells the information of the percentage cover of polygons of every grid cell is stored.
Has anybody an idea to either trick the rasterize function to consider all polygons (not just those covering the cell center of the raster) or fasten my code above?
Any help will be appreciated!
Thank you very much!

Best regards,
Vanessa



_________________________________________
PhD student / Doktorandin
Disturbance Ecology / St?rungs?kologie
University of Bayreuth / Universit?t Bayreuth
Phone / Telefon: 0921-552188
Raum: GEO II, Rm 015.2
Universit?tsstra?e 30
D-95447 Bayreuth

	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Tue Dec  6 21:14:56 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 6 Dec 2016 20:14:56 +0000 (UTC)
Subject: [R] help with gradient boxplot
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
Message-ID: <825389587.741141.1481055296512@mail.yahoo.com>

Hello, there,
I will like to fill the boxplot with gradient color, as exampled below:

Can anyone help me figure out what package I should go with?
Thank you very much for any inputs!
Kind regards,
Ace
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 72026 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161206/27d24464/attachment.png>

From drjimlemon at gmail.com  Tue Dec  6 22:06:16 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 7 Dec 2016 08:06:16 +1100
Subject: [R] CONFUSSING WITH select[!miss] <- 1:sum(!miss)
In-Reply-To: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
References: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
Message-ID: <CA+8X3fXZWV_V4MR8=DcgGtQvgjCjuNT9qst6G+uOPwHqHMrcpA@mail.gmail.com>

Hi Greg,
What is happening is easy to see:

 ph<-matrix(sample(1:100,40),ncol=4)
 colnames(ph)<-c("M1","X1","X2","X3")
 ph[sample(1:10,3),1]<-NA
 ph
       M1 X1 X2 X3
 [1,]  34 98  3 35
 [2,]  13 66 74 68
 [3,]  NA 22 99 79
 [4,]  94  6 80 36
 [5,]  18  9 16 65
 [6,]  NA 29 56 90
 [7,]  41 23  7 55
 [8,] 100 93 71 70
 [9,]  NA 61  8 57
[10,]  25  4 47 60
# get a logical vector showing which rows contain NA
 miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
 miss
 [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE
# create a vector of zeros the length of the number of rows
 select <- integer(nrow(ph))
 select
 [1] 0 0 0 0 0 0 0 0 0 0
# get the indices for the rows that do _not_ have NAs
 select[!miss] <- 1:sum(!miss)
 select
 [1] 1 2 0 3 4 0 5 6 0 7

If this is to select the rows without NAs, it may be easier to do:

which(!miss)
[1]  1  2  4  5  7  8 10

Jim



On Wed, Dec 7, 2016 at 5:18 AM, greg holly <mak.hholly at gmail.com> wrote:
> Dear All;
>
> I am very new in R and try to understand the logic for a program has been
> run sucessfully. Here select[!miss] <- 1:sum(!miss) par is confussing me. I
> need to understandand the logic behind this commend line.
>
> Thanks in advance for your help,
>
> Greg
>
>
> miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
> select <- integer(nrow(ph))
> select[!miss] <- 1:sum(!miss)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chrishold at psyctc.org  Tue Dec  6 22:26:29 2016
From: chrishold at psyctc.org (Chris Evans)
Date: Tue, 6 Dec 2016 21:26:29 +0000 (GMT)
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
Message-ID: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>

I hope I am obeying the list rules here. I am using a raw R IDE for this and running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)

Here is a reproducible example.  Code only first

require(tibble)
tmpTibble <- tibble(ID=letters,num=1:26)
min(tmpTibble[,2]) # fine
max(tmpTibble[,2]) # fine
median(tmpTibble[,2])  # not fine
mean(tmpTibble[,2])    # not fine
newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be necessary?!
newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
newMedianFun(tmpTibble[,2]) # ditto
str(tmpTibble[,2])

### then I tried this to make sure it wasn't about having fed in integers

tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
tmpTibble2
mean(tmpTibble2[,3]) # not fine, not about integers!


### before I just created tmpTibble2 I found myself trying to add a column to tmpTibble
tmpTibble$newNum <- tmpTibble[,2]/10  # NO!
tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
### and oddly enough ...
add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!

Now here it is with the output:

> require(tibble)
Loading required package: tibble
> tmpTibble <- tibble(ID=letters,num=1:26)
> min(tmpTibble[,2]) # fine
[1] 1
> max(tmpTibble[,2]) # fine
[1] 26
> median(tmpTibble[,2])  # not fine
Error in median.default(tmpTibble[, 2]) : need numeric data
> mean(tmpTibble[,2])    # not fine
[1] NA
Warning message:
In mean.default(tmpTibble[, 2]) :
  argument is not numeric or logical: returning NA
> newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
> newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be necessary?!
[1] 13.5
> newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
> newMedianFun(tmpTibble[,2]) # ditto
[1] 13.5
> str(tmpTibble[,2])
Classes ?tbl_df?, ?tbl? and 'data.frame':       26 obs. of  1 variable:
 $ num: int  1 2 3 4 5 6 7 8 9 10 ...
> 
> ### then I tried this to make sure it wasn't about having fed in integers
> 
> tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
> tmpTibble2
# A tibble: 26 ? 3
      ID   num  num2
   <chr> <int> <dbl>
1      a     1   0.1
2      b     2   0.2
3      c     3   0.3
4      d     4   0.4
5      e     5   0.5
6      f     6   0.6
7      g     7   0.7
8      h     8   0.8
9      i     9   0.9
10     j    10   1.0
# ... with 16 more rows
> mean(tmpTibble2[,3]) # not fine, not about integers!
[1] NA
Warning message:
In mean.default(tmpTibble2[, 3]) :
  argument is not numeric or logical: returning NA
> 
> 
> ### before I just created tmpTibble2 I found myself trying to add a column to tmpTibble
> tmpTibble$newNum <- tmpTibble[,2]/10  # NO!
> tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
> ### and oddly enough ...
> add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
Error: Each variable must be a 1d atomic vector or list.
Problem variables: 'newNum'
> 
> 

I discovered this when I hit odd behaviour after using read_spss() from the haven package for the first time as it seemed to be offering a step forward over good old read.spss() from the excellent foreign package.  I am reporting it here not directly to Prof. Wickham as the issues seem rather general though I'm guessing that it needs to be fixed with a fix to tibble.   Or perhaps I've completely missed something.

TIA,

Chris


From jvadams at usgs.gov  Tue Dec  6 22:24:44 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 6 Dec 2016 15:24:44 -0600
Subject: [R] R for skip to the next row if condition met and then
 another condition to check
In-Reply-To: <CAEK8ckAuswjBYUCzpXKwyCR+BJg_z2Uxx721+=6ceObv3PDchQ@mail.gmail.com>
References: <CAEK8ckAuswjBYUCzpXKwyCR+BJg_z2Uxx721+=6ceObv3PDchQ@mail.gmail.com>
Message-ID: <CAN5YmCGVUm4fqm4sYw8CD079wq-u1Crx=_fucWidCLdgSmWn6A@mail.gmail.com>

This might help.

# your example data
trboot3 <- structure(c(0L, -1L, -1L, -1L, -1L, -1L, -1L, -1L, 0L, 0L, -1L,
  0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 1L, 1L, 0L, 0L, 0L, 0L,
  1L, 1L, 1L, 0L, 0L, 0L, 0L, 0L, -1L, -1L, 0L, 1L, 0L, 0L, -1L,
  -1L, -1L, -1L, -1L, -1L, -1L, -1L, -1L, 0L, 0L, 0L, 0L, 0L, 0L,
  -1L, 0L, 0L, 0L), .Dim = c(20L, 3L), .Dimnames = list(NULL, c("V7",
  "V8", "V9")))

# function to identify first occurrence of successive values in a vector
first <- function (x) {
    l <- length(x)
    y <- c(1, 1 - (x[-1] == x[-l]))
    y==1
}

# start with a matrix of zeroes, the same size as the original
trboot4 <- array(0, dim=dim(trboot3), dimnames=dimnames(trboot3))

# identify the first occurrence of successive values in each column
indx <- apply(trboot3, 2, first)

# replace these first occurrence cells with their original values
trboot4[indx] <- trboot3[indx]

trboot4

      V7 V8 V9
 [1,]  0  1  0
 [2,] -1  0 -1
 [3,]  0  0  0
 [4,]  0  0  0
 [5,]  0  0  0
 [6,]  0  0  0
 [7,]  0  0  0
 [8,]  0  1  0
 [9,]  0  0  0
[10,]  0  0  0
[11,] -1  0  0
[12,]  0  0  0
[13,]  0  0  0
[14,]  0  0  0
[15,]  0  0  0
[16,]  0 -1  0
[17,]  0  0 -1
[18,]  0  0  0
[19,]  0  1  0
[20,]  0  0  0

Jean

On Sun, Dec 4, 2016 at 4:08 AM, Ashwini Patil <ash369ster at gmail.com> wrote:

> I have a dataset with many rows and columns. Below is a sample:
>
> V7  V8  V90   1   0-1  1   -1-1  1   -1-1  0   -1-1  0   -1-1  0
> -1-1  0   -1-1  1   -10   1   -10   1   -1-1  0   00   0   00   0   00
>   0   00   0   00   -1  00   -1  -10   0   00   1   00   0   0
>
> This data is saved in a matrix trboot3 What I want to do is create a loop
> whereby two conditions are checked and data is altered.
>
>    1. If there is a zero, skip to the next row.
>    2. If there is same number one below another in a row, keep the first
>    number and change the rest to zero.
>
> Here is my code for the above loop:
>
> trboot4<-trboot3
> valboot<-length(trboot3[,1])for (k in 1:length(trboot3[1,])){
>   for (i in 2:valboot-1){
>     if (trboot3[k,i]==0) {i<-i+1}
>     else{
>       if(trboot3[k,i] == trboot3[k,i+1]){
>         for (j in i+1:valboot){ if(trboot3[k,j] ==
> trboot3[k,i]){trboot4[k,j]<-0}else{break}
>           if(j==valboot){break}
>         }
>       }
>     }
>   }}
>
> I want to save the new matrix in trboot4
>
> basically the above sample should become:
>
> V7  V8  V90   1   0-1  0   -10   0   00   0   00   0   00   0   00   0
>   00   1   00   0   00   0   0-1  0   00   0   00   0   00   0   00
> 0   00   -1  00   0   -10   0   00   1   00   0   0
>
>
> Thank you!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Dec  6 22:25:44 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 7 Dec 2016 08:25:44 +1100
Subject: [R] drawing a ... barplot (?) along time
In-Reply-To: <CA+8X3fWnJxDBuDEy0dVQy5hNUdN2FAKeknCOi=Nu83eG_r8zsA@mail.gmail.com>
References: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>
	<CA+8X3fWnJxDBuDEy0dVQy5hNUdN2FAKeknCOi=Nu83eG_r8zsA@mail.gmail.com>
Message-ID: <CA+8X3fV0zBxEcCQtuzn2JP9oO2BJ6NXAgsoUPK2dV=skBBdoMw@mail.gmail.com>

Hi Dagmar,
Having recovered somewhat, I can refine my suggestion a bit:

datframe <- data.frame(Name=c("Kati","Kati","Kati","Leon","Leon","Leon"),
 changepoint=as.POSIXct(strptime(c("03.01.2011","05.01.2011", "27.01.2011",
  "26.01.2011","28.01.2011", "28.02.2011"), "%d.%m.%Y")),
 knownstate =c("breeding",NA, NA,"breeding","moulting",NA))
library(plotrix)
tm.info<-list(labels=datframe$Name,
 starts=c(as.POSIXct(strptime("01.01.2011","%d.%m.%Y")),
 datframe$changepoint[1:2],
 as.POSIXct(strptime("24.01.2011","%d.%m.%Y")),
 datframe$changepoint[4:5]),
 ends=datframe$changepoint)
gantt.chart(tm.info,
 xlim=as.POSIXct(strptime(c("1.1.2011","10.3.2011"),"%d.%m.%Y")),
 taskcolors=c(2,3,3,2,"orange",3))
legend(as.POSIXct(strptime("10.02.2011","%d.%m.%Y")),2,
 c("Breeding","Moulting","Loafing"),fill=c(2,"orange",3))

Jim

On Tue, Dec 6, 2016 at 10:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Dagmar,
> I think you want something like a gantt.chart. I know this is wrong in
> some ways, but it is late and I must retire:
>
> datframe <- data.frame(Name=c("Kati","Kati","Kati","Leon","Leon","Leon"),
>  changepoint=as.Date(c("03.01.2011","05.01.2011", "27.01.2011",
>   "26.01.2011","28.01.2011", "28.02.2011"), "%d.%m.%Y"),
>  knownstate =c("breeding",NA, NA,"breeding","moulting",NA))
> library(plotrix)
> tm.info<-list(labels=datframe$Name,
>  starts=c(as.Date("01.01.2011","%d.%m.%Y"),datframe$changepoint[1:2],
>  as.Date("01.01.2011","%d.%m.%Y"),datframe$changepoint[4:5]),
>  ends=datframe$changepoint)
> gantt.chart(tm.info,xlim=as.Date(c("1.1.2011","1.3.2011"),"%d.%m.%Y"),
> taskcolors=c(2,3,3,2,"orange",3))
>
> Jim
>
> On Tue, Dec 6, 2016 at 9:28 PM, Dagmar <Ramgad82 at gmx.net> wrote:
>> # Dear all,
>> # I hope someone can help me with this, I am kind of desperated even though
>> it doesn't sound tooooo complicated at all. Let's see:
>> # I have a data frame like this:
>> datframe <- data.frame(Name=c("Kati","Kati","Kati","Leon","Leon","Leon"),
>>                        changepoint =as.POSIXct
>> (strptime(as.character("03.01.2011","05.01.2011", "27.01.2011",
>> "26.01.2011","28.01.2011", "28.02.2011"), "%d.%m.%Y")),
>>                        knownstate =c("breeding",NA,
>> NA,"breeding","moulting",NA))
>> datframe
>> str(datframe)
>> # Now I want a stacked horizontal bar diagram: One bar-line for animal Kati
>> and bellow one for animal Leon.
>> # Each bar should be "drawn" along the time (on the x-axes) and be
>> interupted (by a vertical line) at the changepoints
>> # then additionally I want colours for the known states (e.g. red for the
>> time from 03.01.2011 to 05.01.2011 when animal Kati was breeding)
>>
>> # help would be much appreciated!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Tue Dec  6 22:40:41 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 16:40:41 -0500
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
In-Reply-To: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
References: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
Message-ID: <CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>

Not at a computer to check right now, but I believe single bracket indexing
a tibble always returns a tibble. To extract a vector use [[

On Dec 6, 2016 4:28 PM, "Chris Evans" <chrishold at psyctc.org> wrote:
>
> I hope I am obeying the list rules here. I am using a raw R IDE for this
and running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)
>
> Here is a reproducible example.  Code only first
>
> require(tibble)
> tmpTibble <- tibble(ID=letters,num=1:26)
> min(tmpTibble[,2]) # fine
> max(tmpTibble[,2]) # fine
> median(tmpTibble[,2])  # not fine
> mean(tmpTibble[,2])    # not fine

I think you want

mean(tmpTibble[[2]]

> newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
> newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be
necessary?!
> newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
> newMedianFun(tmpTibble[,2]) # ditto
> str(tmpTibble[,2])
>
> ### then I tried this to make sure it wasn't about having fed in integers
>
> tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
> tmpTibble2
> mean(tmpTibble2[,3]) # not fine, not about integers!
>
>
> ### before I just created tmpTibble2 I found myself trying to add a
column to tmpTibble
> tmpTibble$newNum <- tmpTibble[,2]/10  # NO!
> tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
> ### and oddly enough ...
> add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>
> Now here it is with the output:
>
> > require(tibble)
> Loading required package: tibble
> > tmpTibble <- tibble(ID=letters,num=1:26)
> > min(tmpTibble[,2]) # fine
> [1] 1
> > max(tmpTibble[,2]) # fine
> [1] 26
> > median(tmpTibble[,2])  # not fine
> Error in median.default(tmpTibble[, 2]) : need numeric data
> > mean(tmpTibble[,2])    # not fine
> [1] NA
> Warning message:
> In mean.default(tmpTibble[, 2]) :
>   argument is not numeric or logical: returning NA
> > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
> > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be
necessary?!
> [1] 13.5
> > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
> > newMedianFun(tmpTibble[,2]) # ditto
> [1] 13.5
> > str(tmpTibble[,2])
> Classes ?tbl_df?, ?tbl? and 'data.frame':       26 obs. of  1 variable:
>  $ num: int  1 2 3 4 5 6 7 8 9 10 ...
> >
> > ### then I tried this to make sure it wasn't about having fed in
integers
> >
> > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
> > tmpTibble2
> # A tibble: 26 ? 3
>       ID   num  num2
>    <chr> <int> <dbl>
> 1      a     1   0.1
> 2      b     2   0.2
> 3      c     3   0.3
> 4      d     4   0.4
> 5      e     5   0.5
> 6      f     6   0.6
> 7      g     7   0.7
> 8      h     8   0.8
> 9      i     9   0.9
> 10     j    10   1.0
> # ... with 16 more rows
> > mean(tmpTibble2[,3]) # not fine, not about integers!
> [1] NA
> Warning message:
> In mean.default(tmpTibble2[, 3]) :
>   argument is not numeric or logical: returning NA
> >
> >
> > ### before I just created tmpTibble2 I found myself trying to add a
column to tmpTibble
> > tmpTibble$newNum <- tmpTibble[,2]/10  # NO!
> > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
> > ### and oddly enough ...
> > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
> Error: Each variable must be a 1d atomic vector or list.
> Problem variables: 'newNum'
> >
> >
>
> I discovered this when I hit odd behaviour after using read_spss() from
the haven package for the first time as it seemed to be offering a step
forward over good old read.spss() from the excellent foreign package.  I am
reporting it here not directly to Prof. Wickham as the issues seem rather
general though I'm guessing that it needs to be fixed with a fix to
tibble.   Or perhaps I've completely missed something.
>
> TIA,
>
> Chris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Dec  6 23:00:40 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Dec 2016 14:00:40 -0800
Subject: [R] Write a function that allows access to columns of a
	passeddataframe.
In-Reply-To: <C6451355-9CF3-4C6C-8F74-920DCA3F919F@comcast.net>
References: <5845370D020000CB00168A22@smtp.medicine.umaryland.edu>
	<58458506.9010801@sapo.pt>
	<58454178020000CB00168A55@smtp.medicine.umaryland.edu>
	<66D70C67-59FF-4795-9BB1-65827AD95095@comcast.net>
	<5845A99F.3060105@sapo.pt>
	<CAGxFJbRBRz5EHB99sZyMojmQUdJbRapyY=htxee8bacPKo35AA@mail.gmail.com>
	<CAGxFJbRuhQQz8T2-tR12otcD7z9Ni1_YhU48X07x-cmOympe3g@mail.gmail.com>
	<CAGxFJbQbVWMQFKj42bt5fevEoms6_fmsCMWF27nL1LxApHawBw@mail.gmail.com>
	<58467400.9090401@sapo.pt>
	<584684AF020000CB00168C9B@smtp.medicine.umaryland.edu>
	<CAF8bMcaPfTBvsZZv3KnGx0y5Tr5EGwGxBHnfW9zMTeae3ZNv7g@mail.gmail.com>
	<5846DA54.4010303@sapo.pt>
	<C6451355-9CF3-4C6C-8F74-920DCA3F919F@comcast.net>
Message-ID: <CAGxFJbSvUtHry8wasEE5OLYXt7bADRr-Pn7Vx9nxXi=bLhE-MA@mail.gmail.com>

Simpler I think: ?all.vars

> all.vars(~A+B)
[1] "A" "B"

Note also:

> all.vars(~log(A))
[1] "A"

Cheers,
Bert





"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 6, 2016 at 10:41 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Dec 6, 2016, at 7:33 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>> Perhaps the best way is the one used by library(), where both library(package) and library("package") work. It uses as.charecter/substitute, not deparse/substitute, as follows.
>>
>> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>> mydf
>> class(mydf)
>> str(mydf)
>>
>> myfun <- function(frame,var){
>>       yy <- as.character(substitute(var))
>>       frame[, yy]
>> }
>>
>> myfun(mydf, age)
>> myfun(mydf, "age")
>>
>> Rui Barradas
>>
>> Em 06-12-2016 15:03, William Dunlap escreveu:
>>> I basically agree with Rui - using substitute will cause trouble.  E.g., how
>>> would the user iterate over the columns, calling your function for each?
>>>      for(column in dataFrame) func(column)
>>> would fail because dataFrame$column does not exist.  You need to provide
>>> an extra argument to handle this case. something like the following:
>>>      func <- function(df,
>>>          columnAsName,,
>>>          columnAsString = deparse(substitute(columnAsName))[1])
>>>          ...
>>>      }
>>> The default value of columnAsString should also deal with the case that
>>> the user supplied something like log(Conc.) instead of Conc.
>>>
>>> I think that using a formula for the lazily evaluated argument
>>> (columnAsName)
>>> works well.  The user then knows exactly how it gets evaluated.
>
> This would be an implementation that would support a multi-column extraction using a formula object:
>
> mydf <- data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
> mydf
> class(mydf)
> str(mydf)
>
> myfun <- function(frame, vars){
>         yy <- terms(vars)
>         frame[, attr(yy, "term.labels")]
> }
>
> myfun(mydf, ~age+sex)
>
>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com <http://tibco.com>
>>>
>>> On Tue, Dec 6, 2016 at 6:28 AM, John Sorkin <jsorkin at grecc.umaryland.edu
>>> <mailto:jsorkin at grecc.umaryland.edu>> wrote:
>>>
>>>    Over my almost 50 years programming, I have come to believe that if
>>>    one wants a program to be useful, one should write the program to do
>>>    as much work as possible and demand as little as possible from the
>>>    user of the program. In my opinion, one should not ask the person
>>>    who uses my function to remember to put the name of the data frame
>>>    column in quotation marks. The function should be written so that
>>>    all that needs to be passed is the name of the column; the function
>>>    should take care of the quotation marks.
>>>    Jihny
>>>
>>>    > John David Sorkin M.D., Ph.D.
>>>    > Professor of Medicine
>>>    > Chief, Biostatistics and Informatics
>>>    > University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>>>    > Baltimore VA Medical Center
>>>    > 10 North Greene Street
>>>    > GRECC (BT/18/GR)
>>>    > Baltimore, MD 21201-1524
>>>    > (Phone)410-605-7119 <tel:410-605-7119>
>>>    > (Fax)410-605-7913 <tel:410-605-7913> (Please call phone number above
>>>    prior to faxing)
>>>
>>>
>>>     > On Dec 6, 2016, at 3:17 AM, Rui Barradas <ruipbarradas at sapo.pt
>>>    <mailto:ruipbarradas at sapo.pt>> wrote:
>>>     >
>>>     > Hello,
>>>     >
>>>     > Just to say that I wouldn't write the function as John did. I
>>>    would get
>>>     > rid of all the deparse/substitute stuff and instinctively use a
>>>    quoted
>>>     > argument as a column name. Something like the following.
>>>     >
>>>     > myfun <- function(frame, var){
>>>     >    [...]
>>>     >    col <- frame[, var]  # or frame[[var]]
>>>     >    [...]
>>>     > }
>>>     >
>>>     > myfun(mydf, "age")  # much better, simpler, no promises.
>>>     >
>>>     > Rui Barradas
>>>     >
>>>     > Em 05-12-2016 21:49, Bert Gunter escreveu:
>>>     >> Typo: "lazy evaluation" not "lay evaluation."
>>>     >>
>>>     >> -- Bert
>>>     >>
>>>     >>
>>>     >>
>>>     >> Bert Gunter
>>>     >>
>>>     >> "The trouble with having an open mind is that people keep coming
>>>    along
>>>     >> and sticking things into it."
>>>     >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>     >>
>>>     >>
>>>     >>> On Mon, Dec 5, 2016 at 1:46 PM, Bert Gunter
>>>    <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>>>     >>> Sorry, hit "Send" by mistake.
>>>     >>>
>>>     >>> Inline.
>>>     >>>
>>>     >>>
>>>     >>>
>>>     >>>> On Mon, Dec 5, 2016 at 1:34 PM, Bert Gunter
>>>    <bgunter.4567 at gmail.com <mailto:bgunter.4567 at gmail.com>> wrote:
>>>     >>>> Inline.
>>>     >>>>
>>>     >>>> -- Bert
>>>     >>>>
>>>     >>>>
>>>     >>>> Bert Gunter
>>>     >>>>
>>>     >>>> "The trouble with having an open mind is that people keep
>>>    coming along
>>>     >>>> and sticking things into it."
>>>     >>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>     >>>>
>>>     >>>>
>>>     >>>>> On Mon, Dec 5, 2016 at 9:53 AM, Rui Barradas
>>>    <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> wrote:
>>>     >>>>> Hello,
>>>     >>>>>
>>>     >>>>> Inline.
>>>     >>>>>
>>>     >>>>> Em 05-12-2016 17:09, David Winsemius escreveu:
>>>     >>>>>>
>>>     >>>>>>
>>>     >>>>>>> On Dec 5, 2016, at 7:29 AM, John Sorkin
>>>    <jsorkin at grecc.umaryland.edu <mailto:jsorkin at grecc.umaryland.edu>>
>>>     >>>>>>> wrote:
>>>     >>>>>>>
>>>     >>>>>>> Rui,
>>>     >>>>>>> I appreciate your suggestion, but eliminating the deparse
>>>    statement does
>>>     >>>>>>> not solve my problem. Do you have any other suggestions?
>>>    See code below.
>>>     >>>>>>> Thank you,
>>>     >>>>>>> John
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>> mydf <-
>>>     >>>>>>>
>>>    data.frame(id=c(1,2,3,4,5),sex=c("M","M","M","F","F"),age=c(20,34,43,32,21))
>>>     >>>>>>> mydf
>>>     >>>>>>> class(mydf)
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>> myfun <- function(frame,var){
>>>     >>>>>>>   call <- match.call()
>>>     >>>>>>>   print(call)
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   indx <- match(c("frame","var"),names(call),nomatch=0)
>>>     >>>>>>>   print(indx)
>>>     >>>>>>>   if(indx[1]==0) stop("Function called without sufficient
>>>    arguments!")
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   cat("I can get the name of the dataframe as a text
>>>    string!\n")
>>>     >>>>>>>   #xx <- deparse(substitute(frame))
>>>     >>>>>>>   print(xx)
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   cat("I can get the name of the column as a text string!\n")
>>>     >>>>>>>   #yy <- deparse(substitute(var))
>>>     >>>>>>>   print(yy)
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   # This does not work.
>>>     >>>>>>>   print(frame[,var])
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   # This does not work.
>>>     >>>>>>>   print(frame[,"var"])
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   # This does not work.
>>>     >>>>>>>   col <- xx[,"yy"]
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>>   # Nor does this work.
>>>     >>>>>>>   col <- xx[,yy]
>>>     >>>>>>>   print(col)
>>>     >>>>>>> }
>>>     >>>>>>>
>>>     >>>>>>>
>>>     >>>>>>> myfun(mydf,age)
>>>     >>>>>>
>>>     >>>>>>
>>>     >>>>>>
>>>     >>>>>> When you use that calling syntax, the system will supply the
>>>    values of
>>>     >>>>>> whatever the `age` variable contains. (And if there is no
>>>    `age`-named
>>>     >>>>>> object, you get an error at the time of the call to `myfun`.
>>>     >>>>>
>>>     >>>>>
>>>     >>>>> Actually, no, which was very surprising to me but John's code
>>>    worked (not
>>>     >>>>> the function, the call). And with the change I've proposed,
>>>    it worked
>>>     >>>>> flawlessly. No errors. Why I don't know.
>>>     >>>
>>>     >>> See ?substitute and in particular the example highlighted there.
>>>     >>>
>>>     >>> The technical details are explained in the R Language Definition
>>>     >>> manual. The key here is the use of promises for lay evaluations. In
>>>     >>> fact, the expression in the call *is* available within the
>>>    functions,
>>>     >>> as is (a pointer to) the environment in which to evaluate the
>>>     >>> expression. That is how substitute() works. Specifically,
>>>    quoting from
>>>     >>> the manual,
>>>     >>>
>>>     >>> *****
>>>     >>> It is possible to access the actual (not default) expressions
>>>    used as
>>>     >>> arguments inside the function. The mechanism is implemented via
>>>     >>> promises. When a function is being evaluated the actual expression
>>>     >>> used as an argument is stored in the promise together with a
>>>    pointer
>>>     >>> to the environment the function was called from. When (if) the
>>>     >>> argument is evaluated the stored expression is evaluated in the
>>>     >>> environment that the function was called from. Since only a
>>>    pointer to
>>>     >>> the environment is used any changes made to that environment
>>>    will be
>>>     >>> in effect during this evaluation. The resulting value is then also
>>>     >>> stored in a separate spot in the promise. Subsequent evaluations
>>>     >>> retrieve this stored value (a second evaluation is not carried
>>>    out).
>>>     >>> Access to the unevaluated expression is also available using
>>>     >>> substitute.
>>>     >>> ********
>>>     >>>
>>>     >>> -- Bert
>>>     >>>
>>>     >>>
>>>     >>>
>>>     >>>
>>>     >>>>>
>>>     >>>>> Rui Barradas
>>>     >>>>>
>>>     >>>>>  You need either to call it as:
>>>     >>>>>>
>>>     >>>>>>
>>>     >>>>>> myfun( mydf , "age")
>>>     >>>>>>
>>>     >>>>>>
>>>     >>>>>> # Or:
>>>     >>>>>>
>>>     >>>>>> age <- "age"
>>>     >>>>>> myfun( mydf, age)
>>>     >>>>>>
>>>     >>>>>> Unless your value of the `age`-named variable was "age" in
>>>    the calling
>>>     >>>>>> environment (and you did not give us that value in either of
>>>    your postings),
>>>     >>>>>> you would fail.
>>>     >>>>>>
>>>     >>>>>
>>>     >>>>> ______________________________________________
>>>     >>>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>    list -- To UNSUBSCRIBE and more, see
>>>     >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>     >>>>> PLEASE do read the posting guide
>>>    http://www.R-project.org/posting-guide.html
>>>    <http://www.R-project.org/posting-guide.html>
>>>     >>>>> and provide commented, minimal, self-contained, reproducible
>>>    code.
>>>
>>>    Confidentiality Statement:
>>>    This email message, including any attachments, is for the sole use
>>>    of the intended recipient(s) and may contain confidential and
>>>    privileged information. Any unauthorized use, disclosure or
>>>    distribution is prohibited. If you are not the intended recipient,
>>>    please contact the sender by reply email and destroy all copies of
>>>    the original message.
>>>    ______________________________________________
>>>    R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>>    To UNSUBSCRIBE and more, see
>>>    https://stat.ethz.ch/mailman/listinfo/r-help
>>>    <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>    PLEASE do read the posting guide
>>>    http://www.R-project.org/posting-guide.html
>>>    <http://www.R-project.org/posting-guide.html>
>>>    and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chrishold at psyctc.org  Tue Dec  6 23:10:15 2016
From: chrishold at psyctc.org (Chris Evans)
Date: Tue, 6 Dec 2016 22:10:15 +0000 (GMT)
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
In-Reply-To: <CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>
References: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
	<CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>
Message-ID: <571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>

{{SIGH}} 

You are absolutely right. 

I wonder if I am losing some cognitive capacities that are needed to be part of the evolving R community. It seems to me that if a tibble is designed to be an enhanced replacement for a dataframe then it shouldn't quite so radically change things. 

I notice that the documentation on tibble says "[ Never simplifies (drops), so always returns data.frame" 
That is much less explicit than I would have liked and actually doesn't seem to be true. In fact, as you rightly say, it generally, but not quite always, returns a tibble. In fact it can be fooled into a vector of length 1. 

> tmpTibble[[1,]] 
Error in `[[.data.frame`(tmpTibble, 1, ) : 
argument "..2" is missing, with no default 

> tmpTibble[1] 
# A tibble: 26 ? 1 
ID 
<chr> 
1 a 
2 b 
3 c 
4 d 
5 e 
6 f 
7 g 
8 h 
9 i 
10 j 
# ... with 16 more rows 
> tmpTibble[,1] 
# A tibble: 26 ? 1 
ID 
<chr> 
1 a 
2 b 
3 c 
4 d 
5 e 
6 f 
7 g 
8 h 
9 i 
10 j 
# ... with 16 more rows 
> tmpTibble[1,] 
Error in `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", : 
replacement element 3 is a matrix/data frame of 26 rows, need 1 
In addition: Warning messages: 
1: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", : 
replacement element 1 has 26 rows to replace 1 rows 
2: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", : 
replacement element 2 has 26 rows to replace 1 rows 
> tmpTibble[1,1:26] 
Error: Invalid column indexes: 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26 
> tmpTibble[[1,2]] 
[1] 1 
> str(tmpTibble[[1,2]]) 
int 1 
> str(tmpTibble[[1:2,2]]) 
Error in col[[i, exact = exact]] : 
attempt to select more than one element in vectorIndex 
> 
> tmpTibble[[1,1:2]] 
[1] "b" 
> 

So [[a,b]] works if a and b are legal with the dimensions of the tibble and if a is of length 1 but returns NOT a tibble but a vector of length 1 (I think), I can see that's logical but not what it says in the documentation. 

[[a]] and [[,a]] return the same result, that seems excessively tolerant to me. 

[[a,b:c]] actually returns [[a,c]] and again as a single value, NOT a tibble. 

And row subsetting/indexing has gone. 

Why create replacement for a dataframe that has no row indexing and so radically redefines column indexing, in fact redefines the whole of indexing and subsetting? 

OK. I will go to sleep now and hope to feel less dumb(ed) when I wake. Perhaps Prof. Wickham or someone can spell out a bit less tersely, and I think incompletely, than the tibble documentation does, why all this is good. 

Thanks anyway Ista, you certainly hit the issue! 

Very best all, 

Chris 

> From: "Ista Zahn" <istazahn at gmail.com>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: "r-helpr-project.org" <r-help at r-project.org>
> Sent: Tuesday, 6 December, 2016 21:40:41
> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a tibble

> Not at a computer to check right now, but I believe single bracket indexing a
> tibble always returns a tibble. To extract a vector use [[

> On Dec 6, 2016 4:28 PM, "Chris Evans" < chrishold at psyctc.org > wrote:

>> I hope I am obeying the list rules here. I am using a raw R IDE for this and
> > running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)

> > Here is a reproducible example. Code only first

> > require(tibble)
> > tmpTibble <- tibble(ID=letters,num=1:26)
> > min(tmpTibble[,2]) # fine
> > max(tmpTibble[,2]) # fine
> > median(tmpTibble[,2]) # not fine
> > mean(tmpTibble[,2]) # not fine

> I think you want

> mean(tmpTibble[[2]]

> > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
> > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be necessary?!
> > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
> > newMedianFun(tmpTibble[,2]) # ditto
> > str(tmpTibble[,2])

> > ### then I tried this to make sure it wasn't about having fed in integers

> > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
> > tmpTibble2
> > mean(tmpTibble2[,3]) # not fine, not about integers!


>> ### before I just created tmpTibble2 I found myself trying to add a column to
> > tmpTibble
> > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
> > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
> > ### and oddly enough ...
> > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!

> > Now here it is with the output:

> > > require(tibble)
> > Loading required package: tibble
> > > tmpTibble <- tibble(ID=letters,num=1:26)
> > > min(tmpTibble[,2]) # fine
> > [1] 1
> > > max(tmpTibble[,2]) # fine
> > [1] 26
> > > median(tmpTibble[,2]) # not fine
> > Error in median.default(tmpTibble[, 2]) : need numeric data
> > > mean(tmpTibble[,2]) # not fine
> > [1] NA
> > Warning message:
> > In mean.default(tmpTibble[, 2]) :
> > argument is not numeric or logical: returning NA
> > > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
> > > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be necessary?!
> > [1] 13.5
> > > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
> > > newMedianFun(tmpTibble[,2]) # ditto
> > [1] 13.5
> > > str(tmpTibble[,2])
> > Classes ?tbl_df?, ?tbl? and 'data.frame': 26 obs. of 1 variable:
> > $ num: int 1 2 3 4 5 6 7 8 9 10 ...

> > > ### then I tried this to make sure it wasn't about having fed in integers

> > > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
> > > tmpTibble2
> > # A tibble: 26 ? 3
> > ID num num2
> > <chr> <int> <dbl>
> > 1 a 1 0.1
> > 2 b 2 0.2
> > 3 c 3 0.3
> > 4 d 4 0.4
> > 5 e 5 0.5
> > 6 f 6 0.6
> > 7 g 7 0.7
> > 8 h 8 0.8
> > 9 i 9 0.9
> > 10 j 10 1.0
> > # ... with 16 more rows
> > > mean(tmpTibble2[,3]) # not fine, not about integers!
> > [1] NA
> > Warning message:
> > In mean.default(tmpTibble2[, 3]) :
> > argument is not numeric or logical: returning NA


>> > ### before I just created tmpTibble2 I found myself trying to add a column to
> > > tmpTibble
> > > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
> > > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
> > > ### and oddly enough ...
> > > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
> > Error: Each variable must be a 1d atomic vector or list.
> > Problem variables: 'newNum'



>> I discovered this when I hit odd behaviour after using read_spss() from the
>> haven package for the first time as it seemed to be offering a step forward
>> over good old read.spss() from the excellent foreign package. I am reporting it
>> here not directly to Prof. Wickham as the issues seem rather general though I'm
>> guessing that it needs to be fixed with a fix to tibble. Or perhaps I've
> > completely missed something.

> > TIA,

> > Chris

> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Dec  7 00:23:28 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Dec 2016 15:23:28 -0800
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
In-Reply-To: <571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>
References: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
	<CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>
	<571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>
Message-ID: <69822CFB-446F-4C23-A814-4442D59FB65A@dcn.davis.ca.us>

You really need sleep. Then you need to read

?`[[`

and in particular read about the second argument to the `[[` function, since you don't seem to understand what it is for. Maybe reread the Introduction to R document that comes with R.

The simplest solution is to treat `[[` as supporting one index and `[` as supporting either one or two. 

As for expecting any form of row indexing of data frames or tibbles to return a vector, that is hopeless because each column can have a different type.  dta[ 1, ] returns exactly what it has to return to avoid losing fidelity. If you really need row indexing to return a vector you should be using a matrix. 
-- 
Sent from my phone. Please excuse my brevity.

On December 6, 2016 2:10:15 PM PST, Chris Evans <chrishold at psyctc.org> wrote:
>{{SIGH}} 
>
>You are absolutely right. 
>
>I wonder if I am losing some cognitive capacities that are needed to be
>part of the evolving R community. It seems to me that if a tibble is
>designed to be an enhanced replacement for a dataframe then it
>shouldn't quite so radically change things. 
>
>I notice that the documentation on tibble says "[ Never simplifies
>(drops), so always returns data.frame" 
>That is much less explicit than I would have liked and actually doesn't
>seem to be true. In fact, as you rightly say, it generally, but not
>quite always, returns a tibble. In fact it can be fooled into a vector
>of length 1. 
>
>> tmpTibble[[1,]] 
>Error in `[[.data.frame`(tmpTibble, 1, ) : 
>argument "..2" is missing, with no default 
>
>> tmpTibble[1] 
># A tibble: 26 ? 1 
>ID 
><chr> 
>1 a 
>2 b 
>3 c 
>4 d 
>5 e 
>6 f 
>7 g 
>8 h 
>9 i 
>10 j 
># ... with 16 more rows 
>> tmpTibble[,1] 
># A tibble: 26 ? 1 
>ID 
><chr> 
>1 a 
>2 b 
>3 c 
>4 d 
>5 e 
>6 f 
>7 g 
>8 h 
>9 i 
>10 j 
># ... with 16 more rows 
>> tmpTibble[1,] 
>Error in `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a",
>: 
>replacement element 3 is a matrix/data frame of 26 rows, need 1 
>In addition: Warning messages: 
>1: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", : 
>replacement element 1 has 26 rows to replace 1 rows 
>2: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", : 
>replacement element 2 has 26 rows to replace 1 rows 
>> tmpTibble[1,1:26] 
>Error: Invalid column indexes: 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
>15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26 
>> tmpTibble[[1,2]] 
>[1] 1 
>> str(tmpTibble[[1,2]]) 
>int 1 
>> str(tmpTibble[[1:2,2]]) 
>Error in col[[i, exact = exact]] : 
>attempt to select more than one element in vectorIndex 
>> 
>> tmpTibble[[1,1:2]] 
>[1] "b" 
>> 
>
>So [[a,b]] works if a and b are legal with the dimensions of the tibble
>and if a is of length 1 but returns NOT a tibble but a vector of length
>1 (I think), I can see that's logical but not what it says in the
>documentation. 
>
>[[a]] and [[,a]] return the same result, that seems excessively
>tolerant to me. 
>
>[[a,b:c]] actually returns [[a,c]] and again as a single value, NOT a
>tibble. 
>
>And row subsetting/indexing has gone. 
>
>Why create replacement for a dataframe that has no row indexing and so
>radically redefines column indexing, in fact redefines the whole of
>indexing and subsetting? 
>
>OK. I will go to sleep now and hope to feel less dumb(ed) when I wake.
>Perhaps Prof. Wickham or someone can spell out a bit less tersely, and
>I think incompletely, than the tibble documentation does, why all this
>is good. 
>
>Thanks anyway Ista, you certainly hit the issue! 
>
>Very best all, 
>
>Chris 
>
>> From: "Ista Zahn" <istazahn at gmail.com>
>> To: "Chris Evans" <chrishold at psyctc.org>
>> Cc: "r-helpr-project.org" <r-help at r-project.org>
>> Sent: Tuesday, 6 December, 2016 21:40:41
>> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a
>tibble
>
>> Not at a computer to check right now, but I believe single bracket
>indexing a
>> tibble always returns a tibble. To extract a vector use [[
>
>> On Dec 6, 2016 4:28 PM, "Chris Evans" < chrishold at psyctc.org > wrote:
>
>>> I hope I am obeying the list rules here. I am using a raw R IDE for
>this and
>> > running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)
>
>> > Here is a reproducible example. Code only first
>
>> > require(tibble)
>> > tmpTibble <- tibble(ID=letters,num=1:26)
>> > min(tmpTibble[,2]) # fine
>> > max(tmpTibble[,2]) # fine
>> > median(tmpTibble[,2]) # not fine
>> > mean(tmpTibble[,2]) # not fine
>
>> I think you want
>
>> mean(tmpTibble[[2]]
>
>> > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>> > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be
>necessary?!
>> > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>> > newMedianFun(tmpTibble[,2]) # ditto
>> > str(tmpTibble[,2])
>
>> > ### then I tried this to make sure it wasn't about having fed in
>integers
>
>> > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>> > tmpTibble2
>> > mean(tmpTibble2[,3]) # not fine, not about integers!
>
>
>>> ### before I just created tmpTibble2 I found myself trying to add a
>column to
>> > tmpTibble
>> > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>> > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>> > ### and oddly enough ...
>> > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>
>> > Now here it is with the output:
>
>> > > require(tibble)
>> > Loading required package: tibble
>> > > tmpTibble <- tibble(ID=letters,num=1:26)
>> > > min(tmpTibble[,2]) # fine
>> > [1] 1
>> > > max(tmpTibble[,2]) # fine
>> > [1] 26
>> > > median(tmpTibble[,2]) # not fine
>> > Error in median.default(tmpTibble[, 2]) : need numeric data
>> > > mean(tmpTibble[,2]) # not fine
>> > [1] NA
>> > Warning message:
>> > In mean.default(tmpTibble[, 2]) :
>> > argument is not numeric or logical: returning NA
>> > > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>> > > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't
>be necessary?!
>> > [1] 13.5
>> > > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>> > > newMedianFun(tmpTibble[,2]) # ditto
>> > [1] 13.5
>> > > str(tmpTibble[,2])
>> > Classes ?tbl_df?, ?tbl? and 'data.frame': 26 obs. of 1 variable:
>> > $ num: int 1 2 3 4 5 6 7 8 9 10 ...
>
>> > > ### then I tried this to make sure it wasn't about having fed in
>integers
>
>> > > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>> > > tmpTibble2
>> > # A tibble: 26 ? 3
>> > ID num num2
>> > <chr> <int> <dbl>
>> > 1 a 1 0.1
>> > 2 b 2 0.2
>> > 3 c 3 0.3
>> > 4 d 4 0.4
>> > 5 e 5 0.5
>> > 6 f 6 0.6
>> > 7 g 7 0.7
>> > 8 h 8 0.8
>> > 9 i 9 0.9
>> > 10 j 10 1.0
>> > # ... with 16 more rows
>> > > mean(tmpTibble2[,3]) # not fine, not about integers!
>> > [1] NA
>> > Warning message:
>> > In mean.default(tmpTibble2[, 3]) :
>> > argument is not numeric or logical: returning NA
>
>
>>> > ### before I just created tmpTibble2 I found myself trying to add
>a column to
>> > > tmpTibble
>> > > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>> > > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>> > > ### and oddly enough ...
>> > > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>> > Error: Each variable must be a 1d atomic vector or list.
>> > Problem variables: 'newNum'
>
>
>
>>> I discovered this when I hit odd behaviour after using read_spss()
>from the
>>> haven package for the first time as it seemed to be offering a step
>forward
>>> over good old read.spss() from the excellent foreign package. I am
>reporting it
>>> here not directly to Prof. Wickham as the issues seem rather general
>though I'm
>>> guessing that it needs to be fixed with a fix to tibble. Or perhaps
>I've
>> > completely missed something.
>
>> > TIA,
>
>> > Chris
>
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From christian at echoffmann.ch  Tue Dec  6 23:34:59 2016
From: christian at echoffmann.ch (Christian)
Date: Tue, 6 Dec 2016 23:34:59 +0100
Subject: [R] 1: Setting LC_CTYPE failed, using "C"
Message-ID: <4c959aca-47b4-cc6d-8468-bf20f2a4fe18@echoffmann.ch>

At startup or and using R CMD .. I stumble about

1: Setting LC_CTYPE failed, using "C"
2: Setting LC_TIME failed, using "C"
3: Setting LC_MESSAGES failed, using "C"
4: Setting LC_MONETARY failed, using "C"

Iam am working with

R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.1

locale:
[1] C

attached base packages:
  [1] tools     tcltk     stats4    splines   parallel  compiler grid
  [8] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
  [1] survival_2.39-5    spatial_7.3-11     rpart_4.1-10 nnet_7.3-12
  [5] mgcv_1.8-15        nlme_3.1-128       foreign_0.8-67 codetools_0.2-15
  [9] cluster_2.0.5      class_7.3-14       boot_1.3-18 Matrix_1.2-7.1
[13] MASS_7.3-45        KernSmooth_2.23-15 cwhmisc_6.0 lattice_0.20-34

What are these messages telling me other than in version 3.1 where they 
were not present?

Thanks for hints

Christian


-- 
Christian Hoffmann
Rigiblickstrasee 15b
CH-8915 Hausen am Albis
Telefon 0041-(0)44-7640853


From istazahn at gmail.com  Wed Dec  7 01:33:36 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 6 Dec 2016 19:33:36 -0500
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
In-Reply-To: <571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>
References: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
	<CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>
	<571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>
Message-ID: <CA+vqiLHw5k2f8Q4n_D6AA-VemsHiHN44jft8pQfSZPqU1pkyrQ@mail.gmail.com>

On Tue, Dec 6, 2016 at 5:10 PM, Chris Evans <chrishold at psyctc.org> wrote:
> {{SIGH}}
>
> You are absolutely right.
>
> I wonder if I am losing some cognitive capacities that are needed to be part of the evolving R community. It seems to me that if a tibble is designed to be an enhanced replacement for a dataframe then it shouldn't quite so radically change things.

Well, there are some things about data frames that are darn annoying,
and tibbles exist partly as an attempt to eliminate some of the
inconsistencies with data.frames. That necessarily means changing
things.

>
> I notice that the documentation on tibble says "[ Never simplifies (drops), so always returns data.frame"
> That is much less explicit than I would have liked and actually doesn't seem to be true. In fact, as you rightly say, it generally, but not quite always, returns a tibble. In fact it can be fooled into a vector of length 1.

Really? How?

>
>> tmpTibble[[1,]]
> Error in `[[.data.frame`(tmpTibble, 1, ) :
> argument "..2" is missing, with no default

That doesn't have anything to do with tibbles:

as.data.frame(tmpTibble)[[1, ]]

gives the same thing.

>
>> tmpTibble[1]
> # A tibble: 26 ? 1
> ID
> <chr>
> 1 a
> 2 b
> 3 c
> 4 d
> 5 e
> 6 f
> 7 g
> 8 h
> 9 i
> 10 j
> # ... with 16 more rows

Again, just what you expect from a data.frame (except for the print method).

>> tmpTibble[,1]
> # A tibble: 26 ? 1
> ID
> <chr>
> 1 a
> 2 b
> 3 c
> 4 d
> 5 e
> 6 f
> 7 g
> 8 h
> 9 i
> 10 j
> # ... with 16 more rows

That is different, and by design as you noted. It is different from
data.frame indexing, but the data.frame behavior is needlessly
complicated. Sometimes you get a vector, sometimes a data.frame. That
hardly seems worth it given that we already have $ or [[ if you really
wanted a vector.

>> tmpTibble[1,]
> Error in `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
> replacement element 3 is a matrix/data frame of 26 rows, need 1
> In addition: Warning messages:
> 1: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
> replacement element 1 has 26 rows to replace 1 rows
> 2: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
> replacement element 2 has 26 rows to replace 1 rows

That's not what I get.

> tmpTibble[1,]
# A tibble: 1 ? 2
    ID   num
 <chr> <int>
1     a     1

works just as I would expect here.
>> tmpTibble[1,1:26]
> Error: Invalid column indexes: 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26

Other than providing more information about what went wrong this is
the same as data.frame:

> as.data.frame(tmpTibble)[1,1:26]
Error in `[.data.frame`(as.data.frame(tmpTibble), 1, 1:26) :
 undefined columns selected

>> tmpTibble[[1,2]]
> [1] 1

Same as data.frame. (and not at odds with the documentations which
says that [ (not [[ ) always returns a data.frame).

>> str(tmpTibble[[1,2]])
> int 1
>> str(tmpTibble[[1:2,2]])
> Error in col[[i, exact = exact]] :
> attempt to select more than one element in vectorIndex

Same behavior as data.frame.

>>
>> tmpTibble[[1,1:2]]
> [1] "b"
>>

Same behavior as data.frame.
>
> So [[a,b]] works if a and b are legal with the dimensions of the tibble and if a is of length 1 but returns NOT a tibble but a vector of length 1 (I think), I can see that's logical but not what it says in the documentation.

In what documentation? The documentation that says [ always returns a
data.frame? Note that [ and [[ are not the same, and only [ is
documented to always return a data.frame.
>
> [[a]] and [[,a]] return the same result, that seems excessively tolerant to me.

Not for me:

> tmpTibble[[1]]
[1] "a" "b" "c" "d" "e" "f" "g" "h" "i" "j" "k" "l" "m" "n" "o" "p" "q" "r" "s"
[20] "t" "u" "v" "w" "x" "y" "z"
> tmpTibble[[, 1]]
Error in `[[.data.frame`(tmpTibble, , 1) :
 argument "..1" is missing, with no default

(this is the same thing that happens with a data.frame)
>
> [[a,b:c]] actually returns [[a,c]] and again as a single value, NOT a tibble.

That is weird, but not different that data.frame. See above regarding
"NOT a  tibble".

>
> And row subsetting/indexing has gone.

Whatever do you mean?

> tmpTibble[tmpTibble$ID == "d", ]
# A tibble: 1 ? 2
    ID   num
 <chr> <int>
1     d     4

>
> Why create replacement for a dataframe that has no row indexing and so radically redefines column indexing, in fact redefines the whole of indexing and subsetting?

It has row indexing, and besides [, x] not dropping dimension it works
pretty much the same.
>
> OK. I will go to sleep now and hope to feel less dumb(ed) when I wake. Perhaps Prof. Wickham or someone can spell out a bit less tersely, and I think incompletely, than the tibble documentation does, why all this is good.

Most of the things you identify here are issues inherited from
data.frame, and and not due differences between tibbles and
data.frames.

Best,
Ista

>
> Thanks anyway Ista, you certainly hit the issue!
>
> Very best all,
>
> Chris
>
>> From: "Ista Zahn" <istazahn at gmail.com>
>> To: "Chris Evans" <chrishold at psyctc.org>
>> Cc: "r-helpr-project.org" <r-help at r-project.org>
>> Sent: Tuesday, 6 December, 2016 21:40:41
>> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a tibble
>
>> Not at a computer to check right now, but I believe single bracket indexing a
>> tibble always returns a tibble. To extract a vector use [[
>
>> On Dec 6, 2016 4:28 PM, "Chris Evans" < chrishold at psyctc.org > wrote:
>
>>> I hope I am obeying the list rules here. I am using a raw R IDE for this and
>> > running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)
>
>> > Here is a reproducible example. Code only first
>
>> > require(tibble)
>> > tmpTibble <- tibble(ID=letters,num=1:26)
>> > min(tmpTibble[,2]) # fine
>> > max(tmpTibble[,2]) # fine
>> > median(tmpTibble[,2]) # not fine
>> > mean(tmpTibble[,2]) # not fine
>
>> I think you want
>
>> mean(tmpTibble[[2]]
>
>> > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>> > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be necessary?!
>> > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>> > newMedianFun(tmpTibble[,2]) # ditto
>> > str(tmpTibble[,2])
>
>> > ### then I tried this to make sure it wasn't about having fed in integers
>
>> > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>> > tmpTibble2
>> > mean(tmpTibble2[,3]) # not fine, not about integers!
>
>
>>> ### before I just created tmpTibble2 I found myself trying to add a column to
>> > tmpTibble
>> > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>> > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>> > ### and oddly enough ...
>> > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>
>> > Now here it is with the output:
>
>> > > require(tibble)
>> > Loading required package: tibble
>> > > tmpTibble <- tibble(ID=letters,num=1:26)
>> > > min(tmpTibble[,2]) # fine
>> > [1] 1
>> > > max(tmpTibble[,2]) # fine
>> > [1] 26
>> > > median(tmpTibble[,2]) # not fine
>> > Error in median.default(tmpTibble[, 2]) : need numeric data
>> > > mean(tmpTibble[,2]) # not fine
>> > [1] NA
>> > Warning message:
>> > In mean.default(tmpTibble[, 2]) :
>> > argument is not numeric or logical: returning NA
>> > > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>> > > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be necessary?!
>> > [1] 13.5
>> > > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>> > > newMedianFun(tmpTibble[,2]) # ditto
>> > [1] 13.5
>> > > str(tmpTibble[,2])
>> > Classes ?tbl_df?, ?tbl? and 'data.frame': 26 obs. of 1 variable:
>> > $ num: int 1 2 3 4 5 6 7 8 9 10 ...
>
>> > > ### then I tried this to make sure it wasn't about having fed in integers
>
>> > > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>> > > tmpTibble2
>> > # A tibble: 26 ? 3
>> > ID num num2
>> > <chr> <int> <dbl>
>> > 1 a 1 0.1
>> > 2 b 2 0.2
>> > 3 c 3 0.3
>> > 4 d 4 0.4
>> > 5 e 5 0.5
>> > 6 f 6 0.6
>> > 7 g 7 0.7
>> > 8 h 8 0.8
>> > 9 i 9 0.9
>> > 10 j 10 1.0
>> > # ... with 16 more rows
>> > > mean(tmpTibble2[,3]) # not fine, not about integers!
>> > [1] NA
>> > Warning message:
>> > In mean.default(tmpTibble2[, 3]) :
>> > argument is not numeric or logical: returning NA
>
>
>>> > ### before I just created tmpTibble2 I found myself trying to add a column to
>> > > tmpTibble
>> > > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>> > > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>> > > ### and oddly enough ...
>> > > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>> > Error: Each variable must be a 1d atomic vector or list.
>> > Problem variables: 'newNum'
>
>
>
>>> I discovered this when I hit odd behaviour after using read_spss() from the
>>> haven package for the first time as it seemed to be offering a step forward
>>> over good old read.spss() from the excellent foreign package. I am reporting it
>>> here not directly to Prof. Wickham as the issues seem rather general though I'm
>>> guessing that it needs to be fixed with a fix to tibble. Or perhaps I've
>> > completely missed something.
>
>> > TIA,
>
>> > Chris
>
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul at stat.auckland.ac.nz  Wed Dec  7 01:43:26 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 7 Dec 2016 13:43:26 +1300
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <825389587.741141.1481055296512@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
Message-ID: <a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>

Hi

'gridSVG' might be one way to get this.  For example ...

library(lattice)
# Draw boxplot (with a package that sits on top of 'grid')
bwplot(voice.part ~ height, data=singer, xlab="Height (inches)",
        horizontal=FALSE)

library(grid)
grid.ls()
# Looks like boxes are called <blah>bwplot.box.polygon<blah>

library(gridSVG)
# Define linear gradient
fill <- linearGradient(c("blue", "red"),
                        x0=.5, x1=.5,
                        gradientUnits="coords")
# Register gradient now so it applies to the whole page
registerGradientFill("br", fill)
# Fill each box with gradient
grid.gradientFill("bwplot.box.polygon", label=rep("br", 17), grep=TRUE,
                   group=FALSE)
# Generate SVG version "Rplots.svg"
# (where the gradient will actually be visible)
grid.export()

Does that help ?

Paul

On 07/12/16 09:14, Fix Ace wrote:
> Hello, there,
> I will like to fill the boxplot with gradient color, as exampled below:
>
> Can anyone help me figure out what package I should go with?
> Thank you very much for any inputs!
> Kind regards,
> Ace
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ed_isfahani at yahoo.com  Wed Dec  7 12:26:41 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Wed, 7 Dec 2016 11:26:41 +0000 (UTC)
Subject: [R] calculate correlations
References: <1066086341.1704879.1481110001838.ref@mail.yahoo.com>
Message-ID: <1066086341.1704879.1481110001838@mail.yahoo.com>

Hi All,I have 11 human RNA-seq data (control/treatment),The effect of various drugs on various cancers,I want to calculate the genes-lncRna correlations for all tumors considered together for network,I did?differential expression analysis and?prepared?normalized values (rpkm)?of coding and lncoding in two separate file and import them to R, then transpose them and now I want to calculate corr by this function:
control.corr=cor(cod[grep(".C",cod$name),-1],lnc[grep(".C",lnc$name),-1],method = "spearman")

if I understand true,I should write?the numbers of columns whose related to control,then I counted all of control`s column and?wrote 23 .now my question is,how does R understand?what column is control and what is treatment?


	[[alternative HTML version deleted]]


From marna.wagley at gmail.com  Wed Dec  7 12:58:16 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Wed, 7 Dec 2016 03:58:16 -0800
Subject: [R] how to randomly select the samples with different probabilities
 for different classes?
Message-ID: <CAMwU6B0qKL8Ruh+o6-ZUHxzjiBND6NWvxHs8NRgKS7gVoLkvEg@mail.gmail.com>

Hi R user,
I have samples with covariates for different classes, I wanted to choose
the samples of different groups with different probabilities. For example,
I have a 22 samples size with 3 classes,
groupA has 8 samples
groupB has 8 samples
groupC has 6 samples

I want to select a total 14 samples from 22 samples, in which  40% of the
14 samples should be in groups A and B, 60% of the 14 samples should be in
the group C.

Would you mind to help me on how I can select the samples with that
conditions? I have attached a sample data

dat<-structure(list(sampleID = c(17L, 21L, 36L, 45L, 67L, 82L, 90L,
31L, 70L, 45L, 24L, 80L, 82L, 45L, 85L, 14L, 81L, 96L, 61L, 12L,
65L, 88L), group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A",
"B", "C"), class = "factor")), .Names = c("sampleID", "group"
), class = "data.frame", row.names = c(NA, -22L))

thanks,
  MW

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Dec  7 14:23:10 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 07 Dec 2016 13:23:10 +0000
Subject: [R] how to randomly select the samples with different
 probabilities for different classes?
In-Reply-To: <CAMwU6B0qKL8Ruh+o6-ZUHxzjiBND6NWvxHs8NRgKS7gVoLkvEg@mail.gmail.com>
References: <CAMwU6B0qKL8Ruh+o6-ZUHxzjiBND6NWvxHs8NRgKS7gVoLkvEg@mail.gmail.com>
Message-ID: <58480D3E.9020302@sapo.pt>

Hello,

If 60% of the 14 samples come from group C, then 8.4 samples should come 
from a group with 6 elements. Do you want sampling with replacement? If 
so maybe the following will do.


perc <- c(0.4, 0.6)
tmp <- split(seq_len(nrow(dat)), dat$group == "C")
idx <- sapply(seq_along(tmp), function(i) sample(length(tmp[[i]]), 
round(perc[i]*14), replace = TRUE))
idx[[2]] <- idx[[2]] + 16
idx <- unlist(idx)
dat[idx, ]

Hope this helps,

Rui Barradas

Em 07-12-2016 11:58, Marna Wagley escreveu:
> Hi R user,
> I have samples with covariates for different classes, I wanted to choose
> the samples of different groups with different probabilities. For example,
> I have a 22 samples size with 3 classes,
> groupA has 8 samples
> groupB has 8 samples
> groupC has 6 samples
>
> I want to select a total 14 samples from 22 samples, in which  40% of the
> 14 samples should be in groups A and B, 60% of the 14 samples should be in
> the group C.
>
> Would you mind to help me on how I can select the samples with that
> conditions? I have attached a sample data
>
> dat<-structure(list(sampleID = c(17L, 21L, 36L, 45L, 67L, 82L, 90L,
> 31L, 70L, 45L, 24L, 80L, 82L, 45L, 85L, 14L, 81L, 96L, 61L, 12L,
> 65L, 88L), group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A",
> "B", "C"), class = "factor")), .Names = c("sampleID", "group"
> ), class = "data.frame", row.names = c(NA, -22L))
>
> thanks,
>    MW
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From mak.hholly at gmail.com  Wed Dec  7 15:22:21 2016
From: mak.hholly at gmail.com (greg holly)
Date: Wed, 7 Dec 2016 09:22:21 -0500
Subject: [R] CONFUSSING WITH select[!miss] <- 1:sum(!miss)
In-Reply-To: <CA+8X3fXZWV_V4MR8=DcgGtQvgjCjuNT9qst6G+uOPwHqHMrcpA@mail.gmail.com>
References: <CAM9Qe4gqxF+k2qUDOpd-0e79GopDDs=g2S1syEhUa-piwQ2Hpg@mail.gmail.com>
	<CA+8X3fXZWV_V4MR8=DcgGtQvgjCjuNT9qst6G+uOPwHqHMrcpA@mail.gmail.com>
Message-ID: <CAM9Qe4hVmdwOaNpu_4FkqFfM6FAu3B8GeSu626aPe5uYGk6xiA@mail.gmail.com>

Hi Jim, Rui and William;

I do appreciate for your explanations and help. These are very helpful.
Regards,

Hayrettin

On Tue, Dec 6, 2016 at 4:06 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Greg,
> What is happening is easy to see:
>
>  ph<-matrix(sample(1:100,40),ncol=4)
>  colnames(ph)<-c("M1","X1","X2","X3")
>  ph[sample(1:10,3),1]<-NA
>  ph
>        M1 X1 X2 X3
>  [1,]  34 98  3 35
>  [2,]  13 66 74 68
>  [3,]  NA 22 99 79
>  [4,]  94  6 80 36
>  [5,]  18  9 16 65
>  [6,]  NA 29 56 90
>  [7,]  41 23  7 55
>  [8,] 100 93 71 70
>  [9,]  NA 61  8 57
> [10,]  25  4 47 60
> # get a logical vector showing which rows contain NA
>  miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
>  miss
>  [1] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE
> # create a vector of zeros the length of the number of rows
>  select <- integer(nrow(ph))
>  select
>  [1] 0 0 0 0 0 0 0 0 0 0
> # get the indices for the rows that do _not_ have NAs
>  select[!miss] <- 1:sum(!miss)
>  select
>  [1] 1 2 0 3 4 0 5 6 0 7
>
> If this is to select the rows without NAs, it may be easier to do:
>
> which(!miss)
> [1]  1  2  4  5  7  8 10
>
> Jim
>
>
>
> On Wed, Dec 7, 2016 at 5:18 AM, greg holly <mak.hholly at gmail.com> wrote:
> > Dear All;
> >
> > I am very new in R and try to understand the logic for a program has been
> > run sucessfully. Here select[!miss] <- 1:sum(!miss) par is confussing
> me. I
> > need to understandand the logic behind this commend line.
> >
> > Thanks in advance for your help,
> >
> > Greg
> >
> >
> > miss <- apply(is.na(ph[,c("M1","X1","X2","X3")]),1, any)
> > select <- integer(nrow(ph))
> > select[!miss] <- 1:sum(!miss)
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Dec  7 15:26:55 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 7 Dec 2016 15:26:55 +0100
Subject: [R] MC_CORES and mc.cores for parallel package
Message-ID: <c5a9f84b-e152-3f8a-a955-e2b8c821c1e3@yahoo.fr>

Hi,

 From the documentation of ?options

Options set in package parallel
These will be set when package parallel (or its namespace) is loaded if 
not already set.

mc.cores:
a integer giving the maximum allowed number of additional R processes 
allowed to be run in parallel to the current R process. Defaults to the 
setting of the environment variable MC_CORES if set. Most applications 
which use this assume a limit of 2 if it is unset.

Then I try:
 > getOption("mc.cores")
NULL

I suspect that my environment variable MC_CORES is not set. I test and 
that's right:
 > Sys.getenv("MC_CORES")
[1] ""

Then I do:
 > Sys.setenv(MC_CORES=4)
 > Sys.getenv("MC_CORES")
[1] "4"

But when I try again getOption("mc.cores"); it does not change:
 > getOption("mc.cores")
NULL

Probably I do something wrong but I don't see what !

Thanks

Marc


From lists at dewey.myzen.co.uk  Wed Dec  7 15:41:43 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 7 Dec 2016 14:41:43 +0000
Subject: [R] calculate correlations
In-Reply-To: <1066086341.1704879.1481110001838@mail.yahoo.com>
References: <1066086341.1704879.1481110001838.ref@mail.yahoo.com>
	<1066086341.1704879.1481110001838@mail.yahoo.com>
Message-ID: <ed8c0cfa-a67c-4246-6523-f203f6d5a209@dewey.myzen.co.uk>

If I understand this correctly you are choosing all the rows from each 
of cod and lnc which contain .c (ie any character followed by a C) and 
deleting the first column from each of cod and lnc. You then correlate 
them so that you get the correlation between corresponding columns of 
each. Since you do not tell us how you know which column is which it is 
hard to answer the question of how R will know.

On 07/12/2016 11:26, Elham - via R-help wrote:
> Hi All,I have 11 human RNA-seq data (control/treatment),The effect of various drugs on various cancers,I want to calculate the genes-lncRna correlations for all tumors considered together for network,I did differential expression analysis and prepared normalized values (rpkm) of coding and lncoding in two separate file and import them to R, then transpose them and now I want to calculate corr by this function:
> control.corr=cor(cod[grep(".C",cod$name),-1],lnc[grep(".C",lnc$name),-1],method = "spearman")
>
> if I understand true,I should write the numbers of columns whose related to control,then I counted all of control`s column and wrote 23 .now my question is,how does R understand what column is control and what is treatment?
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jdnewmil at dcn.davis.ca.us  Wed Dec  7 16:04:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 07 Dec 2016 07:04:19 -0800
Subject: [R] MC_CORES and mc.cores for parallel package
In-Reply-To: <c5a9f84b-e152-3f8a-a955-e2b8c821c1e3@yahoo.fr>
References: <c5a9f84b-e152-3f8a-a955-e2b8c821c1e3@yahoo.fr>
Message-ID: <6E42CE37-B328-43BE-91F3-DB0457975C4B@dcn.davis.ca.us>

Your error is in thinking that environment variables are the same thing as options. While environment variables might be used to set initial values of certain options, options are completely separate from environment variables.  If you want to change the option on the fly, then change the option.
-- 
Sent from my phone. Please excuse my brevity.

On December 7, 2016 6:26:55 AM PST, Marc Girondot via R-help <r-help at r-project.org> wrote:
>Hi,
>
> From the documentation of ?options
>
>Options set in package parallel
>These will be set when package parallel (or its namespace) is loaded if
>
>not already set.
>
>mc.cores:
>a integer giving the maximum allowed number of additional R processes 
>allowed to be run in parallel to the current R process. Defaults to the
>
>setting of the environment variable MC_CORES if set. Most applications 
>which use this assume a limit of 2 if it is unset.
>
>Then I try:
> > getOption("mc.cores")
>NULL
>
>I suspect that my environment variable MC_CORES is not set. I test and 
>that's right:
> > Sys.getenv("MC_CORES")
>[1] ""
>
>Then I do:
> > Sys.setenv(MC_CORES=4)
> > Sys.getenv("MC_CORES")
>[1] "4"
>
>But when I try again getOption("mc.cores"); it does not change:
> > getOption("mc.cores")
>NULL
>
>Probably I do something wrong but I don't see what !
>
>Thanks
>
>Marc
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Wed Dec  7 16:40:46 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 7 Dec 2016 07:40:46 -0800
Subject: [R] MC_CORES and mc.cores for parallel package
In-Reply-To: <6E42CE37-B328-43BE-91F3-DB0457975C4B@dcn.davis.ca.us>
References: <c5a9f84b-e152-3f8a-a955-e2b8c821c1e3@yahoo.fr>
	<6E42CE37-B328-43BE-91F3-DB0457975C4B@dcn.davis.ca.us>
Message-ID: <CAGxFJbSafnqc7gzz82yEXe33Bk8ZOASNt96_nUffK1pcM=JhAg@mail.gmail.com>

On Wed, Dec 7, 2016 at 7:04 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> Your error is in thinking that environment variables are the same thing as options. While environment variables might be used to set initial values of certain options, options are completely separate from environment variables.  If you want to change the option on the fly, then change the option.


i.e. ?options

-- Bert



> --
> Sent from my phone. Please excuse my brevity.
>
> On December 7, 2016 6:26:55 AM PST, Marc Girondot via R-help <r-help at r-project.org> wrote:
>>Hi,
>>
>> From the documentation of ?options
>>
>>Options set in package parallel
>>These will be set when package parallel (or its namespace) is loaded if
>>
>>not already set.
>>
>>mc.cores:
>>a integer giving the maximum allowed number of additional R processes
>>allowed to be run in parallel to the current R process. Defaults to the
>>
>>setting of the environment variable MC_CORES if set. Most applications
>>which use this assume a limit of 2 if it is unset.
>>
>>Then I try:
>> > getOption("mc.cores")
>>NULL
>>
>>I suspect that my environment variable MC_CORES is not set. I test and
>>that's right:
>> > Sys.getenv("MC_CORES")
>>[1] ""
>>
>>Then I do:
>> > Sys.setenv(MC_CORES=4)
>> > Sys.getenv("MC_CORES")
>>[1] "4"
>>
>>But when I try again getOption("mc.cores"); it does not change:
>> > getOption("mc.cores")
>>NULL
>>
>>Probably I do something wrong but I don't see what !
>>
>>Thanks
>>
>>Marc
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From andrea.ostvik at nmbu.no  Wed Dec  7 12:46:15 2016
From: andrea.ostvik at nmbu.no (=?iso-8859-1?Q?Andrea_Nyg=E5rd_=D8stvik?=)
Date: Wed, 7 Dec 2016 11:46:15 +0000
Subject: [R] Help!
Message-ID: <1481111161425.44511@nmbu.no>

Hi!


I have a problem with R studio running the whole script whenever I run one seperate line at the time. It keeps on running the whole script over and over and does not read the seperate line. I have exam tomorrow, please help!!


?Best Regards!

	[[alternative HTML version deleted]]


From paciorek at stat.berkeley.edu  Mon Dec  5 01:30:31 2016
From: paciorek at stat.berkeley.edu (Chris Paciorek)
Date: Sun, 4 Dec 2016 16:30:31 -0800
Subject: [R] [R-pkgs] NIMBLE package for hierarchical modeling now on CRAN
Message-ID: <CAG=M9Loqy+ph1iAwzi_vP78BCQZLTszSnQGpfw7P95zqOvnF2w@mail.gmail.com>

NIMBLE version 0.6-2 has been released on CRAN and at  r-nimble.org.

NIMBLE is a system that allows you to:

 - Write general hierarchical statistical models in BUGS code and
create a corresponding model object to use in R.
 - Build Markov chain Monte Carlo (MCMC), particle filters, Monte
Carlo Expectation  Maximization (MCEM), or write generic algorithms
that can be applied to any model.
 - Compile models and algorithms via problem-specific generated C++
that NIMBLE interfaces to R for you.

Most people associate BUGS with MCMC, but NIMBLE is about much more
than that.  It implements and extends the BUGS language as a flexible
system for model declaration and lets you do what you want with the
resulting models.  Some of the cool things you can do with NIMBLE
include:

 - Extend BUGS with functions and distributions you write in R as
nimbleFunctions, which will be automatically turned into C++ and
compiled into your model.
 - Program with models written in BUGS code: get and set values of
variables, control model calculations, simulate new values, use
different data sets in the same model, and more.
 - Write your own MCMC samplers as nimbleFunctions and use them in
combination with NIMBLE?s samplers.
 - Write functions that use MCMC as one step of a larger algorithm.
 - Use standard particle filter methods or write your own.
 - Combine particle filters with MCMC as Particle MCMC methods.
 - Write other kinds of model-generic algorithms as nimbleFunctions.
 - Compile a subset of R?s math syntax to C++ automatically, without
writing any C++ yourself.

Compared to earlier versions, the new version of NIMBLE is faster and
more flexible in a lot of ways.  Building and compiling models and
algorithms could sometimes get bogged down for large models, so we
streamlined those steps quite a lot.   We?ve generally increased the
efficiency of C++ generated by the NIMBLE compiler.  We?ve added
functionality to what can be compiled to C++ from nimbleFunctions.
And we?ve added a bunch of better error-trapping and informative
messages, although there is still a good way to go on that.   Give us
a holler on the nimble-users list (see r-nimble.org) if you run into
questions.

- Chris Paciorek, for the NIMBLE development team

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From yann.desjeux at inra.fr  Tue Dec  6 14:32:30 2016
From: yann.desjeux at inra.fr (Yann Desjeux)
Date: Tue, 6 Dec 2016 14:32:30 +0100
Subject: [R] [R-pkgs] New R package on CRAN: productivity (0.1.0)
Message-ID: <02810bae-1a85-a4be-eece-d3a01c9f15c2@inra.fr>

Dear R users,


I am happy to announce that the R package 'productivity: Indices of 
Productivity Using Data Envelopment Analysis' is now available on CRAN 
(https://cran.r-project.org/package=productivity).

Productivity allows computing various transitive measures of 
productivity and profitability, in both levels and changes.
In addition to the classic Malmquist productivity index, 'productivity' 
also contains the multiplicatively complete and transitive F?re-Primont 
and Lowe indices.

All estimations are based on the nonparametric Data Envelopment Analysis 
(DEA) and several assumptions regarding returns to scale are available 
(i.e. CRS, VRS, NIRS, NDRS).

Besides, the package allows parallel computing.

I would certainly appreciate feedback, comments and suggestions from 
more experienced packagers and R users at 
https://r-forge.r-project.org/projects/productivity/


Best regards,

Yann

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From David.DasNeves at vcontractor.co.za  Wed Dec  7 14:00:10 2016
From: David.DasNeves at vcontractor.co.za (Das Neves, David, Vodacom South Africa)
Date: Wed, 7 Dec 2016 13:00:10 +0000
Subject: [R] R XML package on RHEL
Message-ID: <0E9D79AD97FE4B499F3B8DD41D23025F220DEFDD@SOEXMBXFO02.internal.vodafone.com>

Hi

I am trying install the XML package on R 3.3.0 on RHEL. After it complained that the curl library was missing and we installed it, it continues to fail the linking step:

gcc -m64 -std=gnu99 -shared -L/usr/lib64/R/lib -ldl -lpthread -lc -lrt -lcurl -lidn -lssh2 -lssh2 -lssl -lcrypto -lssl -lcrypto -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lldap -lz -lrt -o XML.so DocParse.o EventParse.o ExpatParse.o HTMLParse.o NodeGC.o RSDTD.o RUtils.o Rcatalog.o Utils.o XMLEventParse.o XMLHashTree.o XMLTree.o fixNS.o libxmlFeatures.o schema.o xmlsecurity.o xpath.o -lxml2 -lz -lm -lz -lxml2 -L/usr/lib64/R/lib -lR
/usr/bin/ld: cannot find -lldap

It is not clear which package is meant to provide the ldap library, although I can see I library that may be appropriate it is not referred to as libldap as such. Should I be creating a symbolic link to the library or something like that?

Please help!

Regards

David das Neves

This e-mail is classified C2 - Vodacom Restricted - Information to be used inside Vodacom but it may be shared with authorised partners.
?This e-mail is sent on the Terms and Conditions that can be accessed by Clicking on this link https://webmail.vodacom.co.za/tc/default.html " 


From ulrik.stervbo at gmail.com  Wed Dec  7 17:50:54 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Wed, 07 Dec 2016 16:50:54 +0000
Subject: [R] Help!
In-Reply-To: <1481111161425.44511@nmbu.no>
References: <1481111161425.44511@nmbu.no>
Message-ID: <CAKVAULMvw0dYJnuxghTPvnWuiDZH0BrEEQtYhf3o_Ob6HyagSg@mail.gmail.com>

Hi Andrea,

The R-studio shortcut for running the current line or selection is Ctrl +
Enter. The shortcut for sourcing the whole script is Ctrl+Shift+Enter

If you press the 'source' button it will source the whole script - I
believe there's a Run-button which will make you able to run the current
line or selection, but I don't have R-studio here, so I can check.

HTH
Ulrik

On Wed, 7 Dec 2016 at 17:36 Andrea Nyg?rd ?stvik <andrea.ostvik at nmbu.no>
wrote:

> Hi!
>
>
> I have a problem with R studio running the whole script whenever I run one
> seperate line at the time. It keeps on running the whole script over and
> over and does not read the seperate line. I have exam tomorrow, please
> help!!
>
>
> ?Best Regards!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Wed Dec  7 18:03:10 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 7 Dec 2016 17:03:10 +0000
Subject: [R] Help!
Message-ID: <D46D7EE1.190CC0%macqueen1@llnl.gov>

This sounds like an RStudio interface problem, not an R programming
problem, so a better place for help would be some resource provided by
RStudio.

That said, the phrase "does not read the separate line" suggests that
maybe your script is not a plain text file, so you could check that, and
make sure that it is.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/7/16, 3:46 AM, "R-help on behalf of Andrea Nyg?rd ?stvik"
<r-help-bounces at r-project.org on behalf of andrea.ostvik at nmbu.no> wrote:

>Hi!
>
>
>I have a problem with R studio running the whole script whenever I run
>one seperate line at the time. It keeps on running the whole script over
>and over and does not read the seperate line. I have exam tomorrow,
>please help!!
>
>
>?Best Regards!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Dec  7 18:07:43 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 7 Dec 2016 18:07:43 +0100
Subject: [R] Help!
In-Reply-To: <1481111161425.44511@nmbu.no>
References: <1481111161425.44511@nmbu.no>
Message-ID: <418EBD2E-2EB5-4EB2-B47F-5350C67D77D0@gmail.com>


> On 07 Dec 2016, at 12:46 , Andrea Nyg?rd ?stvik <andrea.ostvik at nmbu.no> wrote:
> 
> Hi!
> 
> 
> I have a problem with R studio running the whole script whenever I run one seperate line at the time. It keeps on running the whole script over and over and does not read the seperate line. I have exam tomorrow, please help!!

- if you select everything, "Run" runs everything. So don't.
- it's Run, not Source

-pd

> 
> 
> ?Best Regards!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From macqueen1 at llnl.gov  Wed Dec  7 18:12:36 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 7 Dec 2016 17:12:36 +0000
Subject: [R] Polygon to raster with large data set
Message-ID: <D46D82C9.190CDB%macqueen1@llnl.gov>

This sounds like a question better suited for R-sig-geo.
-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/6/16, 12:00 PM, "R-help on behalf of Vetter, Vanessa"
<r-help-bounces at r-project.org on behalf of Vanessa.Vetter at uni-bayreuth.de>
wrote:

>Hi everyone,
>I have a very large shapefile with many polygons (17769 polygons, 104.4
>Mb), which I want to convert to a raster file. A grid cell can be covered
>by either none, 1 or several polygons. I want to assign the percentage
>cover of polygons to the respective grid cell, just like the function
>rasterize (x, y, getCover=TRUE) does. The big problem ist, that the
>rasterize function only notes those polygons covering the center of the
>grid cell and ignores all others. So, I lose more than half of my data
>set when applying this. The second problem is that my data is very large.
>I tried this (see below), but it is very slow and at some point crashes
>down (but works for smaller data sets):
>
>(r = raster, ln = shapefile with polygons)
>
>rp <- rasterToPolygons(r)
>
>covers <- unique(ln at data$PERCENTAGE)
>
>for(cover in covers){
>  psub <- subset(ln, PERCENTAGE==cover)
>  pu <- gUnaryUnion(psub)
>  gi <- gIntersection(rp, pu, byid = T)
>  ind <- as.numeric(do.call(rbind, strsplit(names(gi), " "))[,1])
>  r[] <- NA
>  r[ind] <- sapply(gi at polygons, function(x) slot(x, 'area'))  # a bit
>faster than gArea(gi, byid = T)
>  writeRaster(r, paste0("cover/", cover, "area.tif"))
>}
>
>Every polygon contains a cover estimation (percentage cover of an
>invasive plant species) and the column name of that information is called
>PERCENTAGE. There are basically 4 cover classes. At the end of this loope
>I get 4 rasters, which are named correspondingly to the cover class and
>in whose raster cells the information of the percentage cover of polygons
>of every grid cell is stored.
>Has anybody an idea to either trick the rasterize function to consider
>all polygons (not just those covering the cell center of the raster) or
>fasten my code above?
>Any help will be appreciated!
>Thank you very much!
>
>Best regards,
>Vanessa
>
>
>
>_________________________________________
>PhD student / Doktorandin
>Disturbance Ecology / St?rungs?kologie
>University of Bayreuth / Universit?t Bayreuth
>Phone / Telefon: 0921-552188
>Raum: GEO II, Rm 015.2
>Universit?tsstra?e 30
>D-95447 Bayreuth
>
>	[[alternative HTML version deleted]]
>


From jlhooten at eckerd.edu  Wed Dec  7 18:53:56 2016
From: jlhooten at eckerd.edu (Jackson Hooten)
Date: Wed, 7 Dec 2016 12:53:56 -0500
Subject: [R] Help with Error Messages
Message-ID: <CAG23Y3tJvkMK-wavaXjKK5NFtBwJ0fS4G=CnBnkvqYi-J2xD4Q@mail.gmail.com>

Hello everyone,
I am new to R and need help with a project I am currently running. I am
tracking about 24 great white sharks in Mossel Bay South Africa. I wish to
summarize these sharks' movements in and around the bay. In order to do
that I have a shapefile of a map that I wish to import into R and use as a
base layer to show the movements of the sharks. I have been searching
everywhere online, but cannot seem to find anything that can show me how to
import such a shapefile. Any advise?

On top of that, I also wish to do a kernel density estimation of these
sharks' movements on the map. My data consists of "x" and "y" (Latitude and
Longitude) coordinates of where the sharks pinged, the date, and their ID.
So far, I have been able to figure out some codes that will get me what I
need as far as the kernel density estimations go.

Code example:
> kud.href<-kernelUD(shark.sp[,"id"], h="href", hlim=c(0.01,0.5), grid=500,
extent=0.1)
> image(kud.href,col=rev(heat.colors(50)))

However, whenever I run this code:
> kud95<-getverticeshr(kud,percent=95)
I get this error message:
Error in getverticeshr.estUD(x[[i]], percent, ida = names(x)[i], unin,  :
  The grid is too small to allow the estimation of home-range.
You should rerun kernelUD with a larger extent parameter

Could anyone advise me on how to solve this problem? I have already tried
to increase the "grid" as well as the "extent parameter" but continuously
get this same error message. I read online somewhere, that one could use
the "SpatialPixels" function to solve the problem, but they never put an
example up, so I have no idea how to apply it. Thank you so much for your
patience and assistance.

Sincerely,
Jackson

	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Wed Dec  7 19:47:35 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Wed, 7 Dec 2016 18:47:35 +0000 (UTC)
Subject: [R] calculate correlations
In-Reply-To: <ed8c0cfa-a67c-4246-6523-f203f6d5a209@dewey.myzen.co.uk>
References: <1066086341.1704879.1481110001838.ref@mail.yahoo.com>
	<1066086341.1704879.1481110001838@mail.yahoo.com>
	<ed8c0cfa-a67c-4246-6523-f203f6d5a209@dewey.myzen.co.uk>
Message-ID: <1338011811.2170405.1481136455709@mail.yahoo.com>

hello Michael,I specified each column like this screenshot:(A.C1 means experiment A and first control,A.T3 means experiment A and third treatment .... ?) I have two transposed file,one for coding and one for lncoding.




 

    On Wednesday, December 7, 2016 6:11 PM, Michael Dewey <lists at dewey.myzen.co.uk> wrote:
 

 If I understand this correctly you are choosing all the rows from each 
of cod and lnc which contain .c (ie any character followed by a C) and 
deleting the first column from each of cod and lnc. You then correlate 
them so that you get the correlation between corresponding columns of 
each. Since you do not tell us how you know which column is which it is 
hard to answer the question of how R will know.

On 07/12/2016 11:26, Elham - via R-help wrote:
> Hi All,I have 11 human RNA-seq data (control/treatment),The effect of various drugs on various cancers,I want to calculate the genes-lncRna correlations for all tumors considered together for network,I did differential expression analysis and prepared normalized values (rpkm) of coding and lncoding in two separate file and import them to R, then transpose them and now I want to calculate corr by this function:
> control.corr=cor(cod[grep(".C",cod$name),-1],lnc[grep(".C",lnc$name),-1],method = "spearman")
>
> if I understand true,I should write the numbers of columns whose related to control,then I counted all of control`s column and wrote 23 .now my question is,how does R understand what column is control and what is treatment?
>
>
> ??? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


   
-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 25172 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161207/1e55c772/attachment.png>

From istazahn at gmail.com  Wed Dec  7 19:53:21 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Dec 2016 13:53:21 -0500
Subject: [R] R XML package on RHEL
In-Reply-To: <0E9D79AD97FE4B499F3B8DD41D23025F220DEFDD@SOEXMBXFO02.internal.vodafone.com>
References: <0E9D79AD97FE4B499F3B8DD41D23025F220DEFDD@SOEXMBXFO02.internal.vodafone.com>
Message-ID: <CA+vqiLHBMMmu8Y7XwhANSaihzV+-tHhz3kacKgfkZy26FhXkJQ@mail.gmail.com>

As far as I know you only need libxml and libxml2-devel. Do you have
those installed?

--Ista

On Wed, Dec 7, 2016 at 8:00 AM, Das Neves, David, Vodacom South Africa
<David.DasNeves at vcontractor.co.za> wrote:
> Hi
>
> I am trying install the XML package on R 3.3.0 on RHEL. After it complained that the curl library was missing and we installed it, it continues to fail the linking step:
>
> gcc -m64 -std=gnu99 -shared -L/usr/lib64/R/lib -ldl -lpthread -lc -lrt -lcurl -lidn -lssh2 -lssh2 -lssl -lcrypto -lssl -lcrypto -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err -lldap -lz -lrt -o XML.so DocParse.o EventParse.o ExpatParse.o HTMLParse.o NodeGC.o RSDTD.o RUtils.o Rcatalog.o Utils.o XMLEventParse.o XMLHashTree.o XMLTree.o fixNS.o libxmlFeatures.o schema.o xmlsecurity.o xpath.o -lxml2 -lz -lm -lz -lxml2 -L/usr/lib64/R/lib -lR
> /usr/bin/ld: cannot find -lldap
>
> It is not clear which package is meant to provide the ldap library, although I can see I library that may be appropriate it is not referred to as libldap as such. Should I be creating a symbolic link to the library or something like that?
>
> Please help!
>
> Regards
>
> David das Neves
>
> This e-mail is classified C2 - Vodacom Restricted - Information to be used inside Vodacom but it may be shared with authorised partners.
> ?This e-mail is sent on the Terms and Conditions that can be accessed by Clicking on this link https://webmail.vodacom.co.za/tc/default.html "
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Wed Dec  7 20:04:07 2016
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Wed, 7 Dec 2016 11:04:07 -0800
Subject: [R] MC_CORES and mc.cores for parallel package
In-Reply-To: <c5a9f84b-e152-3f8a-a955-e2b8c821c1e3@yahoo.fr>
References: <c5a9f84b-e152-3f8a-a955-e2b8c821c1e3@yahoo.fr>
Message-ID: <alpine.OSX.2.20.1612071059130.846@charles-berrys-macbook.local>

On Wed, 7 Dec 2016, Marc Girondot via R-help wrote:

> Hi,
>
> From the documentation of ?options
>
> Options set in package parallel
> These will be set when package parallel (or its namespace) is loaded if not 
> already set.
>
> mc.cores:
> a integer giving the maximum allowed number of additional R processes allowed 
> to be run in parallel to the current R process. Defaults to the setting of 
> the environment variable MC_CORES if set. Most applications which use this 
> assume a limit of 2 if it is unset.
>

As advertised.

- Start R with no MC_CORES specified:
- check environment var
- set environment var
- check options
- THEN load parallel
- check option again

  Sys.getenv("MC_CORES")
[1] ""
> Sys.setenv("MC_CORES"=3L)
> options("mc.cores")
$mc.cores
NULL

> library(parallel)
> options("mc.cores")
$mc.cores
[1] 3

---

I think you confused things by loading parallel *before* setting the 
environment var.

HTH,

Chuck


From istazahn at gmail.com  Wed Dec  7 21:12:12 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 7 Dec 2016 15:12:12 -0500
Subject: [R] R XML package on RHEL
In-Reply-To: <0E9D79AD97FE4B499F3B8DD41D23025F220DF278@SOEXMBXFO02.internal.vodafone.com>
References: <0E9D79AD97FE4B499F3B8DD41D23025F220DEFDD@SOEXMBXFO02.internal.vodafone.com>
	<CA+vqiLHBMMmu8Y7XwhANSaihzV+-tHhz3kacKgfkZy26FhXkJQ@mail.gmail.com>
	<0E9D79AD97FE4B499F3B8DD41D23025F220DF278@SOEXMBXFO02.internal.vodafone.com>
Message-ID: <CA+vqiLHMau=_oXYYPRjS21dWKn1u0S0p1fXx+8hEd1fxZfwUJA@mail.gmail.com>

I don't know, the only thing with ldap in the name that I have
installed is "openldap".

On Wed, Dec 7, 2016 at 2:21 PM, Das Neves, David, Vodacom South Africa
<David.DasNeves at vcontractor.co.za> wrote:
> Hi
>
> Thanks for your reply. I do have them installed it seems:
>
> [dasneved at drdsv01zatcrh ~]$ yum list installed | grep xml2
> *Note* Red Hat Network repositories are not listed below. You must run this command as root to access RHN repositories.
> libxml2.x86_64       2.7.6-21.el6_8.1  @RHEL6.8-Server-P1-Jul2016-x86_64
> libxml2-devel.x86_64 2.7.6-21.el6_8.1  @RHEL6.8-Server-P1-Oct2016-x86_64
>
> I have a .so for ldap on the server, maybe I should try symlinking to it? I can't find anything called libldap without a version number, so maybe that is the problem?
>
> [dasneved at drdsv01zatcrh ~]$ find / -name '*libldap*' 2>/dev/null
> /lib64/libldap-2.4.so.2
> /lib64/libldap_r-2.4.so.2
> /lib64/libldap_r-2.4.so.2.10.3
> /lib64/libldap-2.4.so.2.10.3
> /opt/apps/oracle/product/11.2.0/client64/lib/libldapjclnt11.so
> /opt/apps/oracle/product/11.2.0/client64/lib/libldapjclnt11.a
> /opt/apps/oracle/product/11.2.0/client64/lib/libldapclnt11.a
> /opt/apps/oracle/product/11.2.0/dbhome/lib/libldapjclnt11.so
> /opt/apps/oracle/product/11.2.0/dbhome/lib/libldapjclnt11.a
> /opt/apps/oracle/product/11.2.0/dbhome/lib/libldapclnt11.a
> /usr/lib64/libreoffice/program/libldapbe2lo.so
> /usr/lib64/libldap-2.3.so.0.2.31
> /usr/lib64/libldap_r-2.3.so.0
> /usr/lib64/libldap_r-2.3.so.0.2.31
> /usr/lib64/sasl2/libldapdb.so
> /usr/lib64/sasl2/libldapdb.so.2.0.23
> /usr/lib64/sasl2/libldapdb.so.2
> /usr/lib64/libldap-2.3.so.0
> /usr/lib64/thunderbird/libldap60.so
>
> Regards
>
> David
>
>
> -----Original Message-----
> From: Ista Zahn [mailto:istazahn at gmail.com]
> Sent: 07 December 2016 08:53 PM
> To: Das Neves, David, Vodacom South Africa
> Cc: r-help at R-project.org
> Subject: Re: [R] R XML package on RHEL
>
> As far as I know you only need libxml and libxml2-devel. Do you have those installed?
>
> --Ista
>
> On Wed, Dec 7, 2016 at 8:00 AM, Das Neves, David, Vodacom South Africa <David.DasNeves at vcontractor.co.za> wrote:
>> Hi
>>
>> I am trying install the XML package on R 3.3.0 on RHEL. After it complained that the curl library was missing and we installed it, it continues to fail the linking step:
>>
>> gcc -m64 -std=gnu99 -shared -L/usr/lib64/R/lib -ldl -lpthread -lc -lrt
>> -lcurl -lidn -lssh2 -lssh2 -lssl -lcrypto -lssl -lcrypto -lgssapi_krb5
>> -lkrb5 -lk5crypto -lcom_err -lldap -lz -lrt -o XML.so DocParse.o
>> EventParse.o ExpatParse.o HTMLParse.o NodeGC.o RSDTD.o RUtils.o
>> Rcatalog.o Utils.o XMLEventParse.o XMLHashTree.o XMLTree.o fixNS.o
>> libxmlFeatures.o schema.o xmlsecurity.o xpath.o -lxml2 -lz -lm -lz
>> -lxml2 -L/usr/lib64/R/lib -lR
>> /usr/bin/ld: cannot find -lldap
>>
>> It is not clear which package is meant to provide the ldap library, although I can see I library that may be appropriate it is not referred to as libldap as such. Should I be creating a symbolic link to the library or something like that?
>>
>> Please help!
>>
>> Regards
>>
>> David das Neves
>>
>> This e-mail is classified C2 - Vodacom Restricted - Information to be used inside Vodacom but it may be shared with authorised partners.
>> ?This e-mail is sent on the Terms and Conditions that can be accessed by Clicking on this link https://webmail.vodacom.co.za/tc/default.html "
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ?This e-mail is sent on the Terms and Conditions that can be accessed by Clicking on this link https://webmail.vodacom.co.za/tc/default.html "


From drjimlemon at gmail.com  Wed Dec  7 22:11:15 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 8 Dec 2016 08:11:15 +1100
Subject: [R] how to randomly select the samples with different
 probabilities for different classes?
In-Reply-To: <CAMwU6B0qKL8Ruh+o6-ZUHxzjiBND6NWvxHs8NRgKS7gVoLkvEg@mail.gmail.com>
References: <CAMwU6B0qKL8Ruh+o6-ZUHxzjiBND6NWvxHs8NRgKS7gVoLkvEg@mail.gmail.com>
Message-ID: <CA+8X3fVusjFstcSNR1hbNOGGQGU4aoGtmisV7bxr4anJU3yJDA@mail.gmail.com>

Hi Marna,
If we assume a sample size of 1, something like this:

dat[sample(which(dat$group!="C"),ceiling(14*0.4),TRUE),]
dat[sample(which(dat$group=="C"),floor(14*0.6),TRUE),]

Then just step through the two subsets to access your samples.

One problem is that you will not get exactly 40 or 60 %, which is why
I had to put the "ceiling " and "floor" functions to work. Also, you
will have to sample with replacement as you will exhaust the "C"
group.

Jim


On Wed, Dec 7, 2016 at 10:58 PM, Marna Wagley <marna.wagley at gmail.com> wrote:
> Hi R user,
> I have samples with covariates for different classes, I wanted to choose
> the samples of different groups with different probabilities. For example,
> I have a 22 samples size with 3 classes,
> groupA has 8 samples
> groupB has 8 samples
> groupC has 6 samples
>
> I want to select a total 14 samples from 22 samples, in which  40% of the
> 14 samples should be in groups A and B, 60% of the 14 samples should be in
> the group C.
>
> Would you mind to help me on how I can select the samples with that
> conditions? I have attached a sample data
>
> dat<-structure(list(sampleID = c(17L, 21L, 36L, 45L, 67L, 82L, 90L,
> 31L, 70L, 45L, 24L, 80L, 82L, 45L, 85L, 14L, 81L, 96L, 61L, 12L,
> 65L, 88L), group = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L), .Label = c("A",
> "B", "C"), class = "factor")), .Names = c("sampleID", "group"
> ), class = "data.frame", row.names = c(NA, -22L))
>
> thanks,
>   MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From iknowchris at gmail.com  Wed Dec  7 23:03:38 2016
From: iknowchris at gmail.com (Chris Webb)
Date: Wed, 7 Dec 2016 16:03:38 -0600
Subject: [R] Can you get the DEFT from svyratio?
Message-ID: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>

To Dr. Lumley or anyone who may know the answer,

I am trying to obtain ratio estimates from Levy and Lemeshow's Sampling of
Populations 4th ed. page 281. The results in the book are from STATA.
According to the STATA output, the DEFT is 0.830749

I can recreate all of the results except for DEFT. For svytotal and svymean
I can use the option deff="replace" to obtain DEFT results (by taking the
square root), but I get an error when using this option with svyratio. The
problem can be my poor understanding of how to calculate DEFT, but perhaps
it's not implemented for svyratio?


R code to that fails:

library(survey)

# Creating the dataset
df_tbl_10_1 <-
  data.frame(
    center = c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
    nurse = c(rep(c(1,2,3),5)),
    seen = c(58,44,18,42,63,10,13,18,37,16,32,10,25,23,23),
    referred = c(5,6,6,3,19,2,12,6,30,5,14,4,17,9,14)
  )
df_tbl_10_2 <- df_tbl_10_1[c(2,3,4,6,10,11),]

# Defining the cluster sampling design
svy_tbl_10_2 <-
  svydesign(id=~center + nurse,
            data=df_tbl_10_2,
            fpc= ~M + Nbar)

# Ratio estimates
svyratio(~referred, ~seen, svy_tbl_10_2)
confint(svyratio(~referred, ~seen, svy_tbl_10_2), df=degf(svy_tbl_10_2))

# DEFF
deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff=TRUE))

# DEFT (fails)
sqrt(deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff="replace")))

Fail message:
Error in if (deff) deffs <- matrix(ncol = nd, nrow = nn) : argument is not
interpretable as logical


For other individuals, I have included code that will calculate DEFF and
DEFT for svytotal on page 280, This code doesn't fail.

svytotal(~referred, svy_tbl_10_2)
confint(svytotal(~referred, svy_tbl_10_2), df=degf(svy_tbl_10_2))
deff(svytotal(~referred, svy_tbl_10_2, deff=TRUE))
sqrt(deff(svytotal(~referred, svy_tbl_10_2, deff="replace")))



To recap: can you get the DEFT from svyratio?

Sincerely,
Chris Webb

	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Wed Dec  7 23:32:17 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 7 Dec 2016 17:32:17 -0500
Subject: [R] Can you get the DEFT from svyratio?
In-Reply-To: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>
References: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>
Message-ID: <CAOwvMDwXReAmhNT52bqi5ibbkO4SDn-7zna4s_tNrMyAZ6Y7jw@mail.gmail.com>

hi, your code isn't runnable at

            fpc= ~M + Nbar)

On Wed, Dec 7, 2016 at 5:03 PM, Chris Webb <iknowchris at gmail.com> wrote:

> To Dr. Lumley or anyone who may know the answer,
>
> I am trying to obtain ratio estimates from Levy and Lemeshow's Sampling of
> Populations 4th ed. page 281. The results in the book are from STATA.
> According to the STATA output, the DEFT is 0.830749
>
> I can recreate all of the results except for DEFT. For svytotal and svymean
> I can use the option deff="replace" to obtain DEFT results (by taking the
> square root), but I get an error when using this option with svyratio. The
> problem can be my poor understanding of how to calculate DEFT, but perhaps
> it's not implemented for svyratio?
>
>
> R code to that fails:
>
> library(survey)
>
> # Creating the dataset
> df_tbl_10_1 <-
>   data.frame(
>     center = c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
>     nurse = c(rep(c(1,2,3),5)),
>     seen = c(58,44,18,42,63,10,13,18,37,16,32,10,25,23,23),
>     referred = c(5,6,6,3,19,2,12,6,30,5,14,4,17,9,14)
>   )
> df_tbl_10_2 <- df_tbl_10_1[c(2,3,4,6,10,11),]
>
> # Defining the cluster sampling design
> svy_tbl_10_2 <-
>   svydesign(id=~center + nurse,
>             data=df_tbl_10_2,
>             fpc= ~M + Nbar)
>
> # Ratio estimates
> svyratio(~referred, ~seen, svy_tbl_10_2)
> confint(svyratio(~referred, ~seen, svy_tbl_10_2), df=degf(svy_tbl_10_2))
>
> # DEFF
> deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff=TRUE))
>
> # DEFT (fails)
> sqrt(deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff="replace")))
>
> Fail message:
> Error in if (deff) deffs <- matrix(ncol = nd, nrow = nn) : argument is not
> interpretable as logical
>
>
> For other individuals, I have included code that will calculate DEFF and
> DEFT for svytotal on page 280, This code doesn't fail.
>
> svytotal(~referred, svy_tbl_10_2)
> confint(svytotal(~referred, svy_tbl_10_2), df=degf(svy_tbl_10_2))
> deff(svytotal(~referred, svy_tbl_10_2, deff=TRUE))
> sqrt(deff(svytotal(~referred, svy_tbl_10_2, deff="replace")))
>
>
>
> To recap: can you get the DEFT from svyratio?
>
> Sincerely,
> Chris Webb
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From iknowchris at gmail.com  Wed Dec  7 23:56:30 2016
From: iknowchris at gmail.com (Chris Webb)
Date: Wed, 7 Dec 2016 16:56:30 -0600
Subject: [R] Can you get the DEFT from svyratio?
In-Reply-To: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>
References: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>
Message-ID: <CABv3HW08ZBTRWfsX-mWYZ59HRRewTcLf4GwvaJVSFyOYeVpu=w@mail.gmail.com>

Whoops. I forgot to add the one line that I included later in the script.
(I extracted the prior code from a longer document). The code should run
now. It uses dplyr although this could have been done with alternative
methods.

How would you extend svyratio to included calculations for DEFT?


library(survey)
library(dplyr)

# Creating the dataset
df_tbl_10_1 <-
  data.frame(
    center = c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
    nurse = c(rep(c(1,2,3),5)),
    seen = c(58,44,18,42,63,10,13,18,37,16,32,10,25,23,23),
    referred = c(5,6,6,3,19,2,12,6,30,5,14,4,17,9,14)
  )
df_tbl_10_2 <- df_tbl_10_1[c(2,3,4,6,10,11),]

library(dplyr)

df_tbl_10_2 <-
  df_tbl_10_2 %>%
  mutate(M=5,
         Nbar=3,
         w=2.5)

# Defining the cluster sampling design
svy_tbl_10_2 <-
  svydesign(id=~center + nurse,
            data=df_tbl_10_2,
            fpc= ~M + Nbar)

# Ratio estimates
svyratio(~referred, ~seen, svy_tbl_10_2)
confint(svyratio(~referred, ~seen, svy_tbl_10_2), df=degf(svy_tbl_10_2))

# DEFF
deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff=TRUE))

# DEFT (fails)
sqrt(deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff="replace")))




On Wed, Dec 7, 2016 at 4:03 PM, Chris Webb <iknowchris at gmail.com> wrote:

> To Dr. Lumley or anyone who may know the answer,
>
> I am trying to obtain ratio estimates from Levy and Lemeshow's Sampling of
> Populations 4th ed. page 281. The results in the book are from STATA.
> According to the STATA output, the DEFT is 0.830749
>
> I can recreate all of the results except for DEFT. For svytotal and
> svymean I can use the option deff="replace" to obtain DEFT results (by
> taking the square root), but I get an error when using this option with
> svyratio. The problem can be my poor understanding of how to calculate
> DEFT, but perhaps it's not implemented for svyratio?
>
>
> R code to that fails:
>
> library(survey)
>
> # Creating the dataset
> df_tbl_10_1 <-
>   data.frame(
>     center = c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
>     nurse = c(rep(c(1,2,3),5)),
>     seen = c(58,44,18,42,63,10,13,18,37,16,32,10,25,23,23),
>     referred = c(5,6,6,3,19,2,12,6,30,5,14,4,17,9,14)
>   )
> df_tbl_10_2 <- df_tbl_10_1[c(2,3,4,6,10,11),]
>
> # Defining the cluster sampling design
> svy_tbl_10_2 <-
>   svydesign(id=~center + nurse,
>             data=df_tbl_10_2,
>             fpc= ~M + Nbar)
>
> # Ratio estimates
> svyratio(~referred, ~seen, svy_tbl_10_2)
> confint(svyratio(~referred, ~seen, svy_tbl_10_2), df=degf(svy_tbl_10_2))
>
> # DEFF
> deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff=TRUE))
>
> # DEFT (fails)
> sqrt(deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff="replace")))
>
> Fail message:
> Error in if (deff) deffs <- matrix(ncol = nd, nrow = nn) : argument is not
> interpretable as logical
>
>
> For other individuals, I have included code that will calculate DEFF and
> DEFT for svytotal on page 280, This code doesn't fail.
>
> svytotal(~referred, svy_tbl_10_2)
> confint(svytotal(~referred, svy_tbl_10_2), df=degf(svy_tbl_10_2))
> deff(svytotal(~referred, svy_tbl_10_2, deff=TRUE))
> sqrt(deff(svytotal(~referred, svy_tbl_10_2, deff="replace")))
>
>
>
> To recap: can you get the DEFT from svyratio?
>
> Sincerely,
> Chris Webb
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Dec  7 23:59:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 7 Dec 2016 14:59:14 -0800
Subject: [R] Help with Error Messages
In-Reply-To: <CAG23Y3tJvkMK-wavaXjKK5NFtBwJ0fS4G=CnBnkvqYi-J2xD4Q@mail.gmail.com>
References: <CAG23Y3tJvkMK-wavaXjKK5NFtBwJ0fS4G=CnBnkvqYi-J2xD4Q@mail.gmail.com>
Message-ID: <CAGxFJbSu53DUGtkJP+7qPBDmRtEi1XFEFewFy=O6bTG4qmq7uQ@mail.gmail.com>

Well, have you looked to see what:

https://cran.r-project.org/web/views/Spatial.html

has to offer? And, if so, why did you not follow their advice to post
on the r-sig-geo list; if not, you should consider posting there
rather than here.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 7, 2016 at 9:53 AM, Jackson Hooten <jlhooten at eckerd.edu> wrote:
> Hello everyone,
> I am new to R and need help with a project I am currently running. I am
> tracking about 24 great white sharks in Mossel Bay South Africa. I wish to
> summarize these sharks' movements in and around the bay. In order to do
> that I have a shapefile of a map that I wish to import into R and use as a
> base layer to show the movements of the sharks. I have been searching
> everywhere online, but cannot seem to find anything that can show me how to
> import such a shapefile. Any advise?
>
> On top of that, I also wish to do a kernel density estimation of these
> sharks' movements on the map. My data consists of "x" and "y" (Latitude and
> Longitude) coordinates of where the sharks pinged, the date, and their ID.
> So far, I have been able to figure out some codes that will get me what I
> need as far as the kernel density estimations go.
>
> Code example:
>> kud.href<-kernelUD(shark.sp[,"id"], h="href", hlim=c(0.01,0.5), grid=500,
> extent=0.1)
>> image(kud.href,col=rev(heat.colors(50)))
>
> However, whenever I run this code:
>> kud95<-getverticeshr(kud,percent=95)
> I get this error message:
> Error in getverticeshr.estUD(x[[i]], percent, ida = names(x)[i], unin,  :
>   The grid is too small to allow the estimation of home-range.
> You should rerun kernelUD with a larger extent parameter
>
> Could anyone advise me on how to solve this problem? I have already tried
> to increase the "grid" as well as the "extent parameter" but continuously
> get this same error message. I read online somewhere, that one could use
> the "SpatialPixels" function to solve the problem, but they never put an
> example up, so I have no idea how to apply it. Thank you so much for your
> patience and assistance.
>
> Sincerely,
> Jackson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From David.DasNeves at vcontractor.co.za  Wed Dec  7 20:21:36 2016
From: David.DasNeves at vcontractor.co.za (Das Neves, David, Vodacom South Africa)
Date: Wed, 7 Dec 2016 19:21:36 +0000
Subject: [R] R XML package on RHEL
In-Reply-To: <CA+vqiLHBMMmu8Y7XwhANSaihzV+-tHhz3kacKgfkZy26FhXkJQ@mail.gmail.com>
References: <0E9D79AD97FE4B499F3B8DD41D23025F220DEFDD@SOEXMBXFO02.internal.vodafone.com>
	<CA+vqiLHBMMmu8Y7XwhANSaihzV+-tHhz3kacKgfkZy26FhXkJQ@mail.gmail.com>
Message-ID: <0E9D79AD97FE4B499F3B8DD41D23025F220DF278@SOEXMBXFO02.internal.vodafone.com>

Hi

Thanks for your reply. I do have them installed it seems:

[dasneved at drdsv01zatcrh ~]$ yum list installed | grep xml2
*Note* Red Hat Network repositories are not listed below. You must run this command as root to access RHN repositories.
libxml2.x86_64       2.7.6-21.el6_8.1  @RHEL6.8-Server-P1-Jul2016-x86_64        
libxml2-devel.x86_64 2.7.6-21.el6_8.1  @RHEL6.8-Server-P1-Oct2016-x86_64

I have a .so for ldap on the server, maybe I should try symlinking to it? I can't find anything called libldap without a version number, so maybe that is the problem?

[dasneved at drdsv01zatcrh ~]$ find / -name '*libldap*' 2>/dev/null
/lib64/libldap-2.4.so.2
/lib64/libldap_r-2.4.so.2
/lib64/libldap_r-2.4.so.2.10.3
/lib64/libldap-2.4.so.2.10.3
/opt/apps/oracle/product/11.2.0/client64/lib/libldapjclnt11.so
/opt/apps/oracle/product/11.2.0/client64/lib/libldapjclnt11.a
/opt/apps/oracle/product/11.2.0/client64/lib/libldapclnt11.a
/opt/apps/oracle/product/11.2.0/dbhome/lib/libldapjclnt11.so
/opt/apps/oracle/product/11.2.0/dbhome/lib/libldapjclnt11.a
/opt/apps/oracle/product/11.2.0/dbhome/lib/libldapclnt11.a
/usr/lib64/libreoffice/program/libldapbe2lo.so
/usr/lib64/libldap-2.3.so.0.2.31
/usr/lib64/libldap_r-2.3.so.0
/usr/lib64/libldap_r-2.3.so.0.2.31
/usr/lib64/sasl2/libldapdb.so
/usr/lib64/sasl2/libldapdb.so.2.0.23
/usr/lib64/sasl2/libldapdb.so.2
/usr/lib64/libldap-2.3.so.0
/usr/lib64/thunderbird/libldap60.so

Regards

David


-----Original Message-----
From: Ista Zahn [mailto:istazahn at gmail.com] 
Sent: 07 December 2016 08:53 PM
To: Das Neves, David, Vodacom South Africa
Cc: r-help at R-project.org
Subject: Re: [R] R XML package on RHEL

As far as I know you only need libxml and libxml2-devel. Do you have those installed?

--Ista

On Wed, Dec 7, 2016 at 8:00 AM, Das Neves, David, Vodacom South Africa <David.DasNeves at vcontractor.co.za> wrote:
> Hi
>
> I am trying install the XML package on R 3.3.0 on RHEL. After it complained that the curl library was missing and we installed it, it continues to fail the linking step:
>
> gcc -m64 -std=gnu99 -shared -L/usr/lib64/R/lib -ldl -lpthread -lc -lrt 
> -lcurl -lidn -lssh2 -lssh2 -lssl -lcrypto -lssl -lcrypto -lgssapi_krb5 
> -lkrb5 -lk5crypto -lcom_err -lldap -lz -lrt -o XML.so DocParse.o 
> EventParse.o ExpatParse.o HTMLParse.o NodeGC.o RSDTD.o RUtils.o 
> Rcatalog.o Utils.o XMLEventParse.o XMLHashTree.o XMLTree.o fixNS.o 
> libxmlFeatures.o schema.o xmlsecurity.o xpath.o -lxml2 -lz -lm -lz 
> -lxml2 -L/usr/lib64/R/lib -lR
> /usr/bin/ld: cannot find -lldap
>
> It is not clear which package is meant to provide the ldap library, although I can see I library that may be appropriate it is not referred to as libldap as such. Should I be creating a symbolic link to the library or something like that?
>
> Please help!
>
> Regards
>
> David das Neves
>
> This e-mail is classified C2 - Vodacom Restricted - Information to be used inside Vodacom but it may be shared with authorised partners.
> ???This e-mail is sent on the Terms and Conditions that can be accessed by Clicking on this link https://webmail.vodacom.co.za/tc/default.html "
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

?This e-mail is sent on the Terms and Conditions that can be accessed by Clicking on this link https://webmail.vodacom.co.za/tc/default.html " 

From t.lumley at auckland.ac.nz  Wed Dec  7 23:37:36 2016
From: t.lumley at auckland.ac.nz (Thomas Lumley)
Date: Wed, 7 Dec 2016 22:37:36 +0000
Subject: [R] Can you get the DEFT from svyratio?
In-Reply-To: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>
References: <CABv3HW1ZHegsqXJV23gmUgH3c0q8kYTXcYGuVTQDv6iR4DSWBw@mail.gmail.com>
Message-ID: <1481150334208.50492@auckland.ac.nz>

No, you can't (at the moment), though it shouldn't be too hard to extend.


I can't run your example, though. I get:

Error in eval(expr, envir, enclos) : object 'M' not found

   -thomas


Thomas Lumley
Professor of Biostatistics
University of Auckland
________________________________
From: Chris Webb <iknowchris at gmail.com>
Sent: Thursday, December 8, 2016 11:03 AM
To: r-help at r-project.org; Thomas Lumley
Subject: Can you get the DEFT from svyratio?

To Dr. Lumley or anyone who may know the answer,

I am trying to obtain ratio estimates from Levy and Lemeshow's Sampling of Populations 4th ed. page 281. The results in the book are from STATA. According to the STATA output, the DEFT is 0.830749

I can recreate all of the results except for DEFT. For svytotal and svymean I can use the option deff="replace" to obtain DEFT results (by taking the square root), but I get an error when using this option with svyratio. The problem can be my poor understanding of how to calculate DEFT, but perhaps it's not implemented for svyratio?


R code to that fails:

library(survey)

# Creating the dataset
df_tbl_10_1 <-
  data.frame(
    center = c(1,1,1,2,2,2,3,3,3,4,4,4,5,5,5),
    nurse = c(rep(c(1,2,3),5)),
    seen = c(58,44,18,42,63,10,13,18,37,16,32,10,25,23,23),
    referred = c(5,6,6,3,19,2,12,6,30,5,14,4,17,9,14)
  )
df_tbl_10_2 <- df_tbl_10_1[c(2,3,4,6,10,11),]

# Defining the cluster sampling design
svy_tbl_10_2 <-
  svydesign(id=~center + nurse,
            data=df_tbl_10_2,
            fpc= ~M + Nbar)

# Ratio estimates
svyratio(~referred, ~seen, svy_tbl_10_2)
confint(svyratio(~referred, ~seen, svy_tbl_10_2), df=degf(svy_tbl_10_2))

# DEFF
deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff=TRUE))

# DEFT (fails)
sqrt(deff(svyratio(~referred, ~seen, svy_tbl_10_2, deff="replace")))

Fail message:
Error in if (deff) deffs <- matrix(ncol = nd, nrow = nn) : argument is not interpretable as logical


For other individuals, I have included code that will calculate DEFF and DEFT for svytotal on page 280, This code doesn't fail.

svytotal(~referred, svy_tbl_10_2)
confint(svytotal(~referred, svy_tbl_10_2), df=degf(svy_tbl_10_2))
deff(svytotal(~referred, svy_tbl_10_2, deff=TRUE))
sqrt(deff(svytotal(~referred, svy_tbl_10_2, deff="replace")))



To recap: can you get the DEFT from svyratio?

Sincerely,
Chris Webb

	[[alternative HTML version deleted]]


From HDoran at air.org  Thu Dec  8 15:20:03 2016
From: HDoran at air.org (Doran, Harold)
Date: Thu, 8 Dec 2016 14:20:03 +0000
Subject: [R] Benefit of Iterators (package iterator)
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F382E@DC1VEX10MB01.air.org>

R-Help (and package author)

I'm trying to understand within the context of R what the benefit of using an iterator is. My only goal in using the foreach package is to improve computational speed with some embarrassingly parallel tasks I have to compute.

I took the example found at the link below to provide a reproducible example and ran it in a "conventional" way to iterate in a loop and the timing suggests here (as well as with my actual project) that using an iterator generates the same object, but at a much slower speed.

If I can get the same thing faster without using an iterator what would be the potential of its use?	

https://msdn.microsoft.com/en-us/microsoft-r/foreach

> library(doParallel)
> cl <- makeCluster(8) 
> registerDoParallel(cl)
> x <- matrix(rnorm(1000000), ncol=1000)
> itx <- iter(x, by='row')
> system.time(r1 <- foreach(i=itx, .combine=c) %dopar% mean(i))
   user  system elapsed 
   0.40    0.08    0.87 
> system.time(r2 <- foreach(i= 1:nrow(x), .combine=c) %dopar% mean(x[i,]))
   user  system elapsed 
   0.41    0.03    0.81 
> all.equal(r1,r2)
[1] TRUE


From thierry.onkelinx at inbo.be  Thu Dec  8 16:45:26 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 8 Dec 2016 16:45:26 +0100
Subject: [R] Benefit of Iterators (package iterator)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F382E@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F382E@DC1VEX10MB01.air.org>
Message-ID: <CAJuCY5z_nHsQ8LeoYZW5PnUbg6+BgppD8oYr7CZw8e796Q_JiA@mail.gmail.com>

Dear Harold,

I get a different story

library(doParallel)
library(microbenchmark)
cl <- makeCluster(4)
registerDoParallel(cl)
x <- matrix(rnorm(1000000), ncol=1000)
itx <- iter(x, by='row')
microbenchmark(
  iterator = foreach(i=itx, .combine=c) %dopar% mean(i),
  base = foreach(i= 1:nrow(x), .combine=c) %dopar% mean(x[i,])
)

Unit: milliseconds
     expr       min         lq       mean     median         uq      max
neval cld
 iterator   2.11206   2.298507   6.254412   2.540116   2.691283  370.623
100  a
     base 390.21825 442.561737 550.169590 452.729684 466.343894 2554.329
100   b

Best regards,


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-12-08 15:20 GMT+01:00 Doran, Harold <HDoran at air.org>:

> R-Help (and package author)
>
> I'm trying to understand within the context of R what the benefit of using
> an iterator is. My only goal in using the foreach package is to improve
> computational speed with some embarrassingly parallel tasks I have to
> compute.
>
> I took the example found at the link below to provide a reproducible
> example and ran it in a "conventional" way to iterate in a loop and the
> timing suggests here (as well as with my actual project) that using an
> iterator generates the same object, but at a much slower speed.
>
> If I can get the same thing faster without using an iterator what would be
> the potential of its use?
>
> https://msdn.microsoft.com/en-us/microsoft-r/foreach
>
> > library(doParallel)
> > cl <- makeCluster(8)
> > registerDoParallel(cl)
> > x <- matrix(rnorm(1000000), ncol=1000)
> > itx <- iter(x, by='row')
> > system.time(r1 <- foreach(i=itx, .combine=c) %dopar% mean(i))
>    user  system elapsed
>    0.40    0.08    0.87
> > system.time(r2 <- foreach(i= 1:nrow(x), .combine=c) %dopar% mean(x[i,]))
>    user  system elapsed
>    0.41    0.03    0.81
> > all.equal(r1,r2)
> [1] TRUE
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pnsinha68 at gmail.com  Thu Dec  8 17:57:57 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Thu, 8 Dec 2016 22:27:57 +0530
Subject: [R] sample train and test data using dplyr
Message-ID: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>

I want to create two files train and test using dplyr (by random sampling
method). How to do the same same using lets say iris data.
Regards
Parth

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Thu Dec  8 18:17:47 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 12:17:47 -0500
Subject: [R] double metaphone for non-English languages
Message-ID: <CAN2xGJarbaqV6kHXhBHv==_UjKQ8i0_hjDXnY4CvHTp7pS5sOA@mail.gmail.com>

Hello!

I am processing some strings using package "PGRdup".
I using function 'DoubleMetaphone' to generate the double metaphone
codes of strings - to match words that sound alike (in case they were
written differently).

However, I got some French and German strings and discovered that
DoubleMetaphone can't process non-ASCII characters (like Umlauts in
German, accents in French).

What would you recommend I use instead?
Use 'phonetic' from stringdist?


Thank you!
-- 
Dimitri Liakhovitski


From bgunter.4567 at gmail.com  Thu Dec  8 18:45:58 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Dec 2016 09:45:58 -0800
Subject: [R] sample train and test data using dplyr
In-Reply-To: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>
References: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>
Message-ID: <CAGxFJbSDyYLYhisfjGawM-WaQJF5=w=E4eRY1+c_MhEXpnFpBQ@mail.gmail.com>

Usually we expect posters to do their homework by reading necessary R
documentation and relevant subject matter resources (e.g. on
clustering) and making a serious attempt to solve the problem by
offering their code to us along as part of  a reproducible example of
how it failed. You have done none of these things, and so you may not
receive a helpful reply -- or maybe some kind soul will offer one.

I am not such a kind soul. However I will tell you that ?sample is
probably relevant and that you should read and follow the posting
guide at the foot of this email to post a coherent query, which, IMO,
yours is not.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 8, 2016 at 8:57 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:
> I want to create two files train and test using dplyr (by random sampling
> method). How to do the same same using lets say iris data.
> Regards
> Parth
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Thu Dec  8 18:47:26 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 12:47:26 -0500
Subject: [R] are R packages safe?
Message-ID: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>

Guys,

suddenly, I am being asked for a proof that R packages that are not
'"base" are safe. I've never been asked this question before.

Is there some documentation on CRAN that discusses how it's ensured
that all "official" R packages have been "vetted" and are safe?

Thanks a lot!

-- 
Dimitri Liakhovitski


From ulrik.stervbo at gmail.com  Thu Dec  8 18:53:08 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 08 Dec 2016 17:53:08 +0000
Subject: [R] sample train and test data using dplyr
In-Reply-To: <CAGxFJbSDyYLYhisfjGawM-WaQJF5=w=E4eRY1+c_MhEXpnFpBQ@mail.gmail.com>
References: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>
	<CAGxFJbSDyYLYhisfjGawM-WaQJF5=w=E4eRY1+c_MhEXpnFpBQ@mail.gmail.com>
Message-ID: <CAKVAULNuvj2o1wDqNsxFRpZRvjsULMKv7ozB-=A5Mh_QY8KsWg@mail.gmail.com>

In addition to 'sample', and if you insist on dplyr, you can use 'sample_n'.

Best,
Ulrik

On Thu, 8 Dec 2016 at 18:47 Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Usually we expect posters to do their homework by reading necessary R
> documentation and relevant subject matter resources (e.g. on
> clustering) and making a serious attempt to solve the problem by
> offering their code to us along as part of  a reproducible example of
> how it failed. You have done none of these things, and so you may not
> receive a helpful reply -- or maybe some kind soul will offer one.
>
> I am not such a kind soul. However I will tell you that ?sample is
> probably relevant and that you should read and follow the posting
> guide at the foot of this email to post a coherent query, which, IMO,
> yours is not.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Dec 8, 2016 at 8:57 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:
> > I want to create two files train and test using dplyr (by random sampling
> > method). How to do the same same using lets say iris data.
> > Regards
> > Parth
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Dec  8 18:55:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Dec 2016 09:55:17 -0800
Subject: [R] are R packages safe?
In-Reply-To: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
Message-ID: <CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>

1. What does "Safe" mean???

2. From the R banner on startup:

"R is free software and comes with ABSOLUTELY NO WARRANTY."

Don't think it could be clearer than that!

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 8, 2016 at 9:47 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Guys,
>
> suddenly, I am being asked for a proof that R packages that are not
> '"base" are safe. I've never been asked this question before.
>
> Is there some documentation on CRAN that discusses how it's ensured
> that all "official" R packages have been "vetted" and are safe?
>
> Thanks a lot!
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Dec  8 19:04:09 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 08 Dec 2016 12:04:09 -0600
Subject: [R] are R packages safe?
In-Reply-To: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
Message-ID: <89873E05-5166-44DB-9680-77D21013A3E3@me.com>


> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
> 
> Guys,
> 
> suddenly, I am being asked for a proof that R packages that are not
> '"base" are safe. I've never been asked this question before.
> 
> Is there some documentation on CRAN that discusses how it's ensured
> that all "official" R packages have been "vetted" and are safe?
> 
> Thanks a lot!
> 
> -- 
> Dimitri Liakhovitski


Dimitri,

You are going to need to define "safe".

Also, note that the notion of "official R packages" is not defined, other than for those that bear the copyright of The R Foundation (Base + Recommended), as per:

  https://www.r-project.org/certification.html <https://www.r-project.org/certification.html>

That packages are available on CRAN does not infer, implicitly or explicitly, that the packages are endorsed/certified/validated by any party.

You can review the CRAN Policy here:

  https://cran.r-project.org/web/packages/policies.html <https://cran.r-project.org/web/packages/policies.html>.

which provides a standardized framework for CRAN submissions.

Does "safe" mean that they are virus/malware free?

Does "safe" mean that they are extensively tested/validated, bug free and yield documented evidence of consistent and correct results, possibly having also been tested for "edge cases"?

Regards,

Marc Schwartz



	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Thu Dec  8 19:05:26 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 13:05:26 -0500
Subject: [R] are R packages safe?
In-Reply-To: <CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
Message-ID: <CAN2xGJax9cNb87bUB=uW0FmnLtM4th7n3JZF3yWjy+uWAy0hzQ@mail.gmail.com>

I just thought maybe there is something - about the process of
submitting packages or anything like that - that shows that at least
some diligence is being done to ensure that a given package is not
just a piece of malware from ISIS or Russia.
But if you, Bert, say it's not the case, then I'll believe you.

I've asked my question after I received the following email from a
partner company (that is a SaS company):
They are starting to work with R and we are delivering some R code to
them that will run in the background. I mentioned that certain R
packages have to be installed in order for the code to run and got
this:

"I?m also going to assume that our team will want to vet any package
you request. We?re big fans of open source and leveraging 3rd party
libraries but are keenly aware of the risks in ?inviting strangers
into your house?."

This is why I asked.
So, I guess, my response should be - yes, please, go ahead and "vet"
them any way you want.
Thank you!

On Thu, Dec 8, 2016 at 12:55 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 1. What does "Safe" mean???
>
> 2. From the R banner on startup:
>
> "R is free software and comes with ABSOLUTELY NO WARRANTY."
>
> Don't think it could be clearer than that!
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Dec 8, 2016 at 9:47 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> Guys,
>>
>> suddenly, I am being asked for a proof that R packages that are not
>> '"base" are safe. I've never been asked this question before.
>>
>> Is there some documentation on CRAN that discusses how it's ensured
>> that all "official" R packages have been "vetted" and are safe?
>>
>> Thanks a lot!
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Thu Dec  8 19:08:51 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 13:08:51 -0500
Subject: [R] are R packages safe?
In-Reply-To: <89873E05-5166-44DB-9680-77D21013A3E3@me.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<89873E05-5166-44DB-9680-77D21013A3E3@me.com>
Message-ID: <CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>

Thank you, Marc.
That's helpful!
I think, in this case it's mostly:

That they are virus/malware free.
And that they don't send out some info that they are not supposed to.

Thank you!
Dimitri


On Thu, Dec 8, 2016 at 1:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>
> Guys,
>
> suddenly, I am being asked for a proof that R packages that are not
> '"base" are safe. I've never been asked this question before.
>
> Is there some documentation on CRAN that discusses how it's ensured
> that all "official" R packages have been "vetted" and are safe?
>
> Thanks a lot!
>
> --
> Dimitri Liakhovitski
>
>
>
> Dimitri,
>
> You are going to need to define "safe".
>
> Also, note that the notion of "official R packages" is not defined, other
> than for those that bear the copyright of The R Foundation (Base +
> Recommended), as per:
>
>   https://www.r-project.org/certification.html
>
> That packages are available on CRAN does not infer, implicitly or
> explicitly, that the packages are endorsed/certified/validated by any party.
>
> You can review the CRAN Policy here:
>
>   https://cran.r-project.org/web/packages/policies.html.
>
> which provides a standardized framework for CRAN submissions.
>
> Does "safe" mean that they are virus/malware free?
>
> Does "safe" mean that they are extensively tested/validated, bug free and
> yield documented evidence of consistent and correct results, possibly having
> also been tested for "edge cases"?
>
> Regards,
>
> Marc Schwartz
>
>



-- 
Dimitri Liakhovitski


From bgunter.4567 at gmail.com  Thu Dec  8 19:13:55 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Dec 2016 10:13:55 -0800
Subject: [R] are R packages safe?
In-Reply-To: <CAN2xGJax9cNb87bUB=uW0FmnLtM4th7n3JZF3yWjy+uWAy0hzQ@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
	<CAN2xGJax9cNb87bUB=uW0FmnLtM4th7n3JZF3yWjy+uWAy0hzQ@mail.gmail.com>
Message-ID: <CAGxFJbRnPxHp_nmfPPCO2nzY-FKFpXc2QwLaiJ66BZJobd1vzQ@mail.gmail.com>

Dimitri:




On Thu, Dec 8, 2016 at 10:05 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> I just thought maybe there is something - about the process of
> submitting packages or anything like that - that shows that at least
> some diligence is being done to ensure that a given package is not
> just a piece of malware from ISIS or Russia.
> But if you, Bert, say it's not the case, then I'll believe you.

** I DID NOT SAY THAT ***

You asked for **guarantees." R has none. But of course U. Wien checks
R packages on submission for malicious code (it is one reason binary
submissions are generally not permitted) and R repository servers of
course have filters in place. BUT THERE ARE NO GUARANTEES, explicit or
implied.

Cheers,
Bert



>
> I've asked my question after I received the following email from a
> partner company (that is a SaS company):
> They are starting to work with R and we are delivering some R code to
> them that will run in the background. I mentioned that certain R
> packages have to be installed in order for the code to run and got
> this:
>
> "I?m also going to assume that our team will want to vet any package
> you request. We?re big fans of open source and leveraging 3rd party
> libraries but are keenly aware of the risks in ?inviting strangers
> into your house?."
>
> This is why I asked.
> So, I guess, my response should be - yes, please, go ahead and "vet"
> them any way you want.
> Thank you!
>
> On Thu, Dec 8, 2016 at 12:55 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> 1. What does "Safe" mean???
>>
>> 2. From the R banner on startup:
>>
>> "R is free software and comes with ABSOLUTELY NO WARRANTY."
>>
>> Don't think it could be clearer than that!
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Dec 8, 2016 at 9:47 AM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>> Guys,
>>>
>>> suddenly, I am being asked for a proof that R packages that are not
>>> '"base" are safe. I've never been asked this question before.
>>>
>>> Is there some documentation on CRAN that discusses how it's ensured
>>> that all "official" R packages have been "vetted" and are safe?
>>>
>>> Thanks a lot!
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Dimitri Liakhovitski


From jdnewmil at dcn.davis.ca.us  Thu Dec  8 19:14:58 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 08 Dec 2016 10:14:58 -0800
Subject: [R] are R packages safe?
In-Reply-To: <CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
Message-ID: <4C906D2D-7318-4E3A-AE1B-C96F799446EE@dcn.davis.ca.us>

On the plus side, all binary packages on CRAN are built from source code automatically by the CRAN team, so it would be a bit audacious to include "unsafe" code when the source code had to reviewable at any time.

There is nothing in R that would prevent a user from downloading a binary package from a non-CRAN source, though.

The only legally defensible answer is No, you use this at your own risk. 
-- 
Sent from my phone. Please excuse my brevity.

On December 8, 2016 9:55:17 AM PST, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>1. What does "Safe" mean???
>
>2. From the R banner on startup:
>
>"R is free software and comes with ABSOLUTELY NO WARRANTY."
>
>Don't think it could be clearer than that!
>
>Cheers,
>Bert
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Thu, Dec 8, 2016 at 9:47 AM, Dimitri Liakhovitski
><dimitri.liakhovitski at gmail.com> wrote:
>> Guys,
>>
>> suddenly, I am being asked for a proof that R packages that are not
>> '"base" are safe. I've never been asked this question before.
>>
>> Is there some documentation on CRAN that discusses how it's ensured
>> that all "official" R packages have been "vetted" and are safe?
>>
>> Thanks a lot!
>>
>> --
>> Dimitri Liakhovitski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Thu Dec  8 19:16:08 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 13:16:08 -0500
Subject: [R] are R packages safe?
In-Reply-To: <CAGxFJbRnPxHp_nmfPPCO2nzY-FKFpXc2QwLaiJ66BZJobd1vzQ@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
	<CAN2xGJax9cNb87bUB=uW0FmnLtM4th7n3JZF3yWjy+uWAy0hzQ@mail.gmail.com>
	<CAGxFJbRnPxHp_nmfPPCO2nzY-FKFpXc2QwLaiJ66BZJobd1vzQ@mail.gmail.com>
Message-ID: <CAN2xGJZvx67Avj7KiXBb_teT9jL+uuOYS5v4XbfnDEk5zzm4Hg@mail.gmail.com>

Great to know thanks, Bert!

Do you happen to have a reference that shows that:
-U. Wien checks R packages on submission for malicious code
-R repository servers have filters in place.

Thanks again!

On Thu, Dec 8, 2016 at 1:13 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> Dimitri:
>
>
>
>
> On Thu, Dec 8, 2016 at 10:05 AM, Dimitri Liakhovitski
> <dimitri.liakhovitski at gmail.com> wrote:
>> I just thought maybe there is something - about the process of
>> submitting packages or anything like that - that shows that at least
>> some diligence is being done to ensure that a given package is not
>> just a piece of malware from ISIS or Russia.
>> But if you, Bert, say it's not the case, then I'll believe you.
>
> ** I DID NOT SAY THAT ***
>
> You asked for **guarantees." R has none. But of course U. Wien checks
> R packages on submission for malicious code (it is one reason binary
> submissions are generally not permitted) and R repository servers of
> course have filters in place. BUT THERE ARE NO GUARANTEES, explicit or
> implied.
>
> Cheers,
> Bert
>
>
>
>>
>> I've asked my question after I received the following email from a
>> partner company (that is a SaS company):
>> They are starting to work with R and we are delivering some R code to
>> them that will run in the background. I mentioned that certain R
>> packages have to be installed in order for the code to run and got
>> this:
>>
>> "I?m also going to assume that our team will want to vet any package
>> you request. We?re big fans of open source and leveraging 3rd party
>> libraries but are keenly aware of the risks in ?inviting strangers
>> into your house?."
>>
>> This is why I asked.
>> So, I guess, my response should be - yes, please, go ahead and "vet"
>> them any way you want.
>> Thank you!
>>
>> On Thu, Dec 8, 2016 at 12:55 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>> 1. What does "Safe" mean???
>>>
>>> 2. From the R banner on startup:
>>>
>>> "R is free software and comes with ABSOLUTELY NO WARRANTY."
>>>
>>> Don't think it could be clearer than that!
>>>
>>> Cheers,
>>> Bert
>>>
>>>
>>> Bert Gunter
>>>
>>> "The trouble with having an open mind is that people keep coming along
>>> and sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>
>>>
>>> On Thu, Dec 8, 2016 at 9:47 AM, Dimitri Liakhovitski
>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>> Guys,
>>>>
>>>> suddenly, I am being asked for a proof that R packages that are not
>>>> '"base" are safe. I've never been asked this question before.
>>>>
>>>> Is there some documentation on CRAN that discusses how it's ensured
>>>> that all "official" R packages have been "vetted" and are safe?
>>>>
>>>> Thanks a lot!
>>>>
>>>> --
>>>> Dimitri Liakhovitski
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From bgunter.4567 at gmail.com  Thu Dec  8 19:17:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Dec 2016 10:17:07 -0800
Subject: [R] are R packages safe?
In-Reply-To: <CAN2xGJZvx67Avj7KiXBb_teT9jL+uuOYS5v4XbfnDEk5zzm4Hg@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<CAGxFJbQ1yJvWVbFebK6=PgRT+y2vR2FOjffe7Zd1vvHO3UnMiA@mail.gmail.com>
	<CAN2xGJax9cNb87bUB=uW0FmnLtM4th7n3JZF3yWjy+uWAy0hzQ@mail.gmail.com>
	<CAGxFJbRnPxHp_nmfPPCO2nzY-FKFpXc2QwLaiJ66BZJobd1vzQ@mail.gmail.com>
	<CAN2xGJZvx67Avj7KiXBb_teT9jL+uuOYS5v4XbfnDEk5zzm4Hg@mail.gmail.com>
Message-ID: <CAGxFJbT4HzRhSbC69ECyYFAjAz5MF-WfCFeB0Re_b_wtTrtjKg@mail.gmail.com>

On Thu, Dec 8, 2016 at 10:16 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Great to know thanks, Bert!
>
> Do you happen to have a reference that shows that:
> -U. Wien checks R packages on submission for malicious code
> -R repository servers have filters in place.

No. Ask them

-- Bert

>
> Thanks again!
>
> On Thu, Dec 8, 2016 at 1:13 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> Dimitri:
>>
>>
>>
>>
>> On Thu, Dec 8, 2016 at 10:05 AM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>> I just thought maybe there is something - about the process of
>>> submitting packages or anything like that - that shows that at least
>>> some diligence is being done to ensure that a given package is not
>>> just a piece of malware from ISIS or Russia.
>>> But if you, Bert, say it's not the case, then I'll believe you.
>>
>> ** I DID NOT SAY THAT ***
>>
>> You asked for **guarantees." R has none. But of course U. Wien checks
>> R packages on submission for malicious code (it is one reason binary
>> submissions are generally not permitted) and R repository servers of
>> course have filters in place. BUT THERE ARE NO GUARANTEES, explicit or
>> implied.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>>
>>> I've asked my question after I received the following email from a
>>> partner company (that is a SaS company):
>>> They are starting to work with R and we are delivering some R code to
>>> them that will run in the background. I mentioned that certain R
>>> packages have to be installed in order for the code to run and got
>>> this:
>>>
>>> "I?m also going to assume that our team will want to vet any package
>>> you request. We?re big fans of open source and leveraging 3rd party
>>> libraries but are keenly aware of the risks in ?inviting strangers
>>> into your house?."
>>>
>>> This is why I asked.
>>> So, I guess, my response should be - yes, please, go ahead and "vet"
>>> them any way you want.
>>> Thank you!
>>>
>>> On Thu, Dec 8, 2016 at 12:55 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>>>> 1. What does "Safe" mean???
>>>>
>>>> 2. From the R banner on startup:
>>>>
>>>> "R is free software and comes with ABSOLUTELY NO WARRANTY."
>>>>
>>>> Don't think it could be clearer than that!
>>>>
>>>> Cheers,
>>>> Bert
>>>>
>>>>
>>>> Bert Gunter
>>>>
>>>> "The trouble with having an open mind is that people keep coming along
>>>> and sticking things into it."
>>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>>>
>>>>
>>>> On Thu, Dec 8, 2016 at 9:47 AM, Dimitri Liakhovitski
>>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>>> Guys,
>>>>>
>>>>> suddenly, I am being asked for a proof that R packages that are not
>>>>> '"base" are safe. I've never been asked this question before.
>>>>>
>>>>> Is there some documentation on CRAN that discusses how it's ensured
>>>>> that all "official" R packages have been "vetted" and are safe?
>>>>>
>>>>> Thanks a lot!
>>>>>
>>>>> --
>>>>> Dimitri Liakhovitski
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Dimitri Liakhovitski
>
>
>
> --
> Dimitri Liakhovitski


From marc_schwartz at me.com  Thu Dec  8 19:24:14 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 08 Dec 2016 12:24:14 -0600
Subject: [R] are R packages safe?
In-Reply-To: <CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<89873E05-5166-44DB-9680-77D21013A3E3@me.com>
	<CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
Message-ID: <54F96535-DAA1-4FFE-90FF-1CA62AC2D397@me.com>

Dimitri,

Even if you narrowly define "safe" as being virus/malware free and even if the CRAN maintainers have extensive screening in place, the burden will still be on the end users to test/scan the downloaded packages (whether in source or binary form), according to some a priori defined standard operating procedures, to achieve a level of confidence, that the packages pass those tests/scans.

As you know, virus and malware are moving targets and there are so-called "zero day" exploits, which means that even actively updated virus and malware scanning software can be defeated.

With respect to the security issue you raised, to the best of my knowledge, no CRAN packages are tested for such exploits (it would be an impossible task to extensively check for overt, much less covert channels of communications) and that again, would be a local issue. CRAN packages are, of course, not the only potential source of such exploits, as we know.

As Bert noted in his reply, even the official R distribution comes with no warranty, and that will be the case with most OSS.

Regards,

Marc


> On Dec 8, 2016, at 12:08 PM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
> 
> Thank you, Marc.
> That's helpful!
> I think, in this case it's mostly:
> 
> That they are virus/malware free.
> And that they don't send out some info that they are not supposed to.
> 
> Thank you!
> Dimitri
> 
> 
> On Thu, Dec 8, 2016 at 1:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> 
>> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>> 
>> Guys,
>> 
>> suddenly, I am being asked for a proof that R packages that are not
>> '"base" are safe. I've never been asked this question before.
>> 
>> Is there some documentation on CRAN that discusses how it's ensured
>> that all "official" R packages have been "vetted" and are safe?
>> 
>> Thanks a lot!
>> 
>> --
>> Dimitri Liakhovitski
>> 
>> 
>> 
>> Dimitri,
>> 
>> You are going to need to define "safe".
>> 
>> Also, note that the notion of "official R packages" is not defined, other
>> than for those that bear the copyright of The R Foundation (Base +
>> Recommended), as per:
>> 
>>  https://www.r-project.org/certification.html
>> 
>> That packages are available on CRAN does not infer, implicitly or
>> explicitly, that the packages are endorsed/certified/validated by any party.
>> 
>> You can review the CRAN Policy here:
>> 
>>  https://cran.r-project.org/web/packages/policies.html.
>> 
>> which provides a standardized framework for CRAN submissions.
>> 
>> Does "safe" mean that they are virus/malware free?
>> 
>> Does "safe" mean that they are extensively tested/validated, bug free and
>> yield documented evidence of consistent and correct results, possibly having
>> also been tested for "edge cases"?
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 
>> 
> 
> 
> 
> -- 
> Dimitri Liakhovitski


From spencer.graves at effectivedefense.org  Thu Dec  8 19:25:20 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 8 Dec 2016 12:25:20 -0600
Subject: [R] are R packages safe?
In-Reply-To: <CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<89873E05-5166-44DB-9680-77D21013A3E3@me.com>
	<CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
Message-ID: <bfdba3a9-3cd8-c2e7-c612-8030521e59c4@effectivedefense.org>



On 12/8/2016 12:08 PM, Dimitri Liakhovitski wrote:
> Thank you, Marc.
> That's helpful!
> I think, in this case it's mostly:
>
> That they are virus/malware free.
> And that they don't send out some info that they are not supposed to.


       Doing those things are absolutely against CRAN policies, but you 
should get one of the CRAN maintainers to tell you the extent to which 
they check these things.


       CRAN will reject a violation of these rules if they catch them, 
and they do scan for many possible problems.  For example, I don't know 
if they'd catch a call to "q()" in a package if that line of code was 
not exercised in any of the standard tests.  Even of they could catch 
that, I don't know if they'd catch "do.call(q, list())"


       Best Wishes,
       Spencer Graves
>
> Thank you!
> Dimitri
>
>
> On Thu, Dec 8, 2016 at 1:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski
>> <dimitri.liakhovitski at gmail.com> wrote:
>>
>> Guys,
>>
>> suddenly, I am being asked for a proof that R packages that are not
>> '"base" are safe. I've never been asked this question before.
>>
>> Is there some documentation on CRAN that discusses how it's ensured
>> that all "official" R packages have been "vetted" and are safe?
>>
>> Thanks a lot!
>>
>> --
>> Dimitri Liakhovitski
>>
>>
>>
>> Dimitri,
>>
>> You are going to need to define "safe".
>>
>> Also, note that the notion of "official R packages" is not defined, other
>> than for those that bear the copyright of The R Foundation (Base +
>> Recommended), as per:
>>
>>    https://www.r-project.org/certification.html
>>
>> That packages are available on CRAN does not infer, implicitly or
>> explicitly, that the packages are endorsed/certified/validated by any party.
>>
>> You can review the CRAN Policy here:
>>
>>    https://cran.r-project.org/web/packages/policies.html.
>>
>> which provides a standardized framework for CRAN submissions.
>>
>> Does "safe" mean that they are virus/malware free?
>>
>> Does "safe" mean that they are extensively tested/validated, bug free and
>> yield documented evidence of consistent and correct results, possibly having
>> also been tested for "edge cases"?
>>
>> Regards,
>>
>> Marc Schwartz
>>
>>
>
>


From dimitri.liakhovitski at gmail.com  Thu Dec  8 19:27:31 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 13:27:31 -0500
Subject: [R] are R packages safe?
In-Reply-To: <54F96535-DAA1-4FFE-90FF-1CA62AC2D397@me.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<89873E05-5166-44DB-9680-77D21013A3E3@me.com>
	<CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
	<54F96535-DAA1-4FFE-90FF-1CA62AC2D397@me.com>
Message-ID: <CAN2xGJbSoSve-QEm7h+LwR7i8GPcXqmb19MK9+srZ1yd02-R0A@mail.gmail.com>

Thanks a lot, guys - it's very helpful!

On Thu, Dec 8, 2016 at 1:24 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> Dimitri,
>
> Even if you narrowly define "safe" as being virus/malware free and even if the CRAN maintainers have extensive screening in place, the burden will still be on the end users to test/scan the downloaded packages (whether in source or binary form), according to some a priori defined standard operating procedures, to achieve a level of confidence, that the packages pass those tests/scans.
>
> As you know, virus and malware are moving targets and there are so-called "zero day" exploits, which means that even actively updated virus and malware scanning software can be defeated.
>
> With respect to the security issue you raised, to the best of my knowledge, no CRAN packages are tested for such exploits (it would be an impossible task to extensively check for overt, much less covert channels of communications) and that again, would be a local issue. CRAN packages are, of course, not the only potential source of such exploits, as we know.
>
> As Bert noted in his reply, even the official R distribution comes with no warranty, and that will be the case with most OSS.
>
> Regards,
>
> Marc
>
>
>> On Dec 8, 2016, at 12:08 PM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>
>> Thank you, Marc.
>> That's helpful!
>> I think, in this case it's mostly:
>>
>> That they are virus/malware free.
>> And that they don't send out some info that they are not supposed to.
>>
>> Thank you!
>> Dimitri
>>
>>
>> On Thu, Dec 8, 2016 at 1:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>>
>>> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski
>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>
>>> Guys,
>>>
>>> suddenly, I am being asked for a proof that R packages that are not
>>> '"base" are safe. I've never been asked this question before.
>>>
>>> Is there some documentation on CRAN that discusses how it's ensured
>>> that all "official" R packages have been "vetted" and are safe?
>>>
>>> Thanks a lot!
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>>
>>>
>>> Dimitri,
>>>
>>> You are going to need to define "safe".
>>>
>>> Also, note that the notion of "official R packages" is not defined, other
>>> than for those that bear the copyright of The R Foundation (Base +
>>> Recommended), as per:
>>>
>>>  https://www.r-project.org/certification.html
>>>
>>> That packages are available on CRAN does not infer, implicitly or
>>> explicitly, that the packages are endorsed/certified/validated by any party.
>>>
>>> You can review the CRAN Policy here:
>>>
>>>  https://cran.r-project.org/web/packages/policies.html.
>>>
>>> which provides a standardized framework for CRAN submissions.
>>>
>>> Does "safe" mean that they are virus/malware free?
>>>
>>> Does "safe" mean that they are extensively tested/validated, bug free and
>>> yield documented evidence of consistent and correct results, possibly having
>>> also been tested for "edge cases"?
>>>
>>> Regards,
>>>
>>> Marc Schwartz
>>>
>>>
>>
>>
>>
>> --
>> Dimitri Liakhovitski
>



-- 
Dimitri Liakhovitski


From spencer.graves at effectivedefense.org  Thu Dec  8 19:27:38 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 8 Dec 2016 12:27:38 -0600
Subject: [R] are R packages safe?
In-Reply-To: <54F96535-DAA1-4FFE-90FF-1CA62AC2D397@me.com>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<89873E05-5166-44DB-9680-77D21013A3E3@me.com>
	<CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
	<54F96535-DAA1-4FFE-90FF-1CA62AC2D397@me.com>
Message-ID: <d22dc775-8bc2-392a-6a0e-cbeebe7f6435@effectivedefense.org>



On 12/8/2016 12:24 PM, Marc Schwartz wrote:
> Dimitri,
>
> Even if you narrowly define "safe" as being virus/malware free and even if the CRAN maintainers have extensive screening in place, the burden will still be on the end users to test/scan the downloaded packages (whether in source or binary form), according to some a priori defined standard operating procedures, to achieve a level of confidence, that the packages pass those tests/scans.
>
> As you know, virus and malware are moving targets and there are so-called "zero day" exploits, which means that even actively updated virus and malware scanning software can be defeated.
>
> With respect to the security issue you raised, to the best of my knowledge, no CRAN packages are tested for such exploits (it would be an impossible task to extensively check for overt, much less covert channels of communications) and that again, would be a local issue. CRAN packages are, of course, not the only potential source of such exploits, as we know.
>
> As Bert noted in his reply, even the official R distribution comes with no warranty, and that will be the case with most OSS.


       Will an organization like RStudio provide some sort of testing 
service -- for a fee of course?


       Spencer
>
> Regards,
>
> Marc
>
>
>> On Dec 8, 2016, at 12:08 PM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>
>> Thank you, Marc.
>> That's helpful!
>> I think, in this case it's mostly:
>>
>> That they are virus/malware free.
>> And that they don't send out some info that they are not supposed to.
>>
>> Thank you!
>> Dimitri
>>
>>
>> On Thu, Dec 8, 2016 at 1:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski
>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>
>>> Guys,
>>>
>>> suddenly, I am being asked for a proof that R packages that are not
>>> '"base" are safe. I've never been asked this question before.
>>>
>>> Is there some documentation on CRAN that discusses how it's ensured
>>> that all "official" R packages have been "vetted" and are safe?
>>>
>>> Thanks a lot!
>>>
>>> --
>>> Dimitri Liakhovitski
>>>
>>>
>>>
>>> Dimitri,
>>>
>>> You are going to need to define "safe".
>>>
>>> Also, note that the notion of "official R packages" is not defined, other
>>> than for those that bear the copyright of The R Foundation (Base +
>>> Recommended), as per:
>>>
>>>   https://www.r-project.org/certification.html
>>>
>>> That packages are available on CRAN does not infer, implicitly or
>>> explicitly, that the packages are endorsed/certified/validated by any party.
>>>
>>> You can review the CRAN Policy here:
>>>
>>>   https://cran.r-project.org/web/packages/policies.html.
>>>
>>> which provides a standardized framework for CRAN submissions.
>>>
>>> Does "safe" mean that they are virus/malware free?
>>>
>>> Does "safe" mean that they are extensively tested/validated, bug free and
>>> yield documented evidence of consistent and correct results, possibly having
>>> also been tested for "edge cases"?
>>>
>>> Regards,
>>>
>>> Marc Schwartz
>>>
>>>
>>
>>
>> -- 
>> Dimitri Liakhovitski
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Thu Dec  8 20:11:58 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 08 Dec 2016 13:11:58 -0600
Subject: [R] are R packages safe?
In-Reply-To: <d22dc775-8bc2-392a-6a0e-cbeebe7f6435@effectivedefense.org>
References: <CAN2xGJaCp8cbyOJ8bYW_uoNPBydBD0F6aSydJ=+2uzM5nBGt6A@mail.gmail.com>
	<89873E05-5166-44DB-9680-77D21013A3E3@me.com>
	<CAN2xGJYHXw-GOVcDwPEoTPBKoiLCNbd9CtYDBsVAjmnBcVD6Vw@mail.gmail.com>
	<54F96535-DAA1-4FFE-90FF-1CA62AC2D397@me.com>
	<d22dc775-8bc2-392a-6a0e-cbeebe7f6435@effectivedefense.org>
Message-ID: <297B2996-EFF1-4113-A03E-5360AB9DA7B8@me.com>

Inline below...

> On Dec 8, 2016, at 12:27 PM, Spencer Graves <spencer.graves at effectivedefense.org> wrote:
> 
> 
> 
> On 12/8/2016 12:24 PM, Marc Schwartz wrote:
>> Dimitri,
>> 
>> Even if you narrowly define "safe" as being virus/malware free and even if the CRAN maintainers have extensive screening in place, the burden will still be on the end users to test/scan the downloaded packages (whether in source or binary form), according to some a priori defined standard operating procedures, to achieve a level of confidence, that the packages pass those tests/scans.
>> 
>> As you know, virus and malware are moving targets and there are so-called "zero day" exploits, which means that even actively updated virus and malware scanning software can be defeated.
>> 
>> With respect to the security issue you raised, to the best of my knowledge, no CRAN packages are tested for such exploits (it would be an impossible task to extensively check for overt, much less covert channels of communications) and that again, would be a local issue. CRAN packages are, of course, not the only potential source of such exploits, as we know.
>> 
>> As Bert noted in his reply, even the official R distribution comes with no warranty, and that will be the case with most OSS.
> 
> 
>      Will an organization like RStudio provide some sort of testing service -- for a fee of course?
> 
> 
>      Spencer


Spencer,

That would be a question for them, Microsoft, Mango, ...

From a business perspective, that might be a "value added" service that some class of useRs might be interested in paying for, much like the difference between CentOS and RHEL as server distributions of Linux.

As with such things, what is the standard that you want them to abide by and be able to support/defend and for what kinds of issues (virus, malware, security, statistical performance, regulatory qualification/validation, ...).

Regards,

Marc


>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>>> On Dec 8, 2016, at 12:08 PM, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>> 
>>> Thank you, Marc.
>>> That's helpful!
>>> I think, in this case it's mostly:
>>> 
>>> That they are virus/malware free.
>>> And that they don't send out some info that they are not supposed to.
>>> 
>>> Thank you!
>>> Dimitri
>>> 
>>> 
>>> On Thu, Dec 8, 2016 at 1:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>>>> On Dec 8, 2016, at 11:47 AM, Dimitri Liakhovitski
>>>> <dimitri.liakhovitski at gmail.com> wrote:
>>>> 
>>>> Guys,
>>>> 
>>>> suddenly, I am being asked for a proof that R packages that are not
>>>> '"base" are safe. I've never been asked this question before.
>>>> 
>>>> Is there some documentation on CRAN that discusses how it's ensured
>>>> that all "official" R packages have been "vetted" and are safe?
>>>> 
>>>> Thanks a lot!
>>>> 
>>>> --
>>>> Dimitri Liakhovitski
>>>> 
>>>> 
>>>> 
>>>> Dimitri,
>>>> 
>>>> You are going to need to define "safe".
>>>> 
>>>> Also, note that the notion of "official R packages" is not defined, other
>>>> than for those that bear the copyright of The R Foundation (Base +
>>>> Recommended), as per:
>>>> 
>>>>  https://www.r-project.org/certification.html
>>>> 
>>>> That packages are available on CRAN does not infer, implicitly or
>>>> explicitly, that the packages are endorsed/certified/validated by any party.
>>>> 
>>>> You can review the CRAN Policy here:
>>>> 
>>>>  https://cran.r-project.org/web/packages/policies.html.
>>>> 
>>>> which provides a standardized framework for CRAN submissions.
>>>> 
>>>> Does "safe" mean that they are virus/malware free?
>>>> 
>>>> Does "safe" mean that they are extensively tested/validated, bug free and
>>>> yield documented evidence of consistent and correct results, possibly having
>>>> also been tested for "edge cases"?
>>>> 
>>>> Regards,
>>>> 
>>>> Marc Schwartz
>>>> 
>>>> 
>>> 
>>> 
>>> -- 
>>> Dimitri Liakhovitski
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gking at ctps.org  Thu Dec  8 19:56:49 2016
From: gking at ctps.org (Grace King)
Date: Thu, 8 Dec 2016 13:56:49 -0500
Subject: [R] R problem
Message-ID: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>

Hi all,



I am trying to run a macro by R in a EMME script. The R macro that we wrote
is called IPFPUMS.R. The whole process has been working until someone
removed R. We tried to re-install R but getting the error message:

??R? is not recognized as an internal or external command, operable program
or batch file.?



Here is how R is called to run the macro in the script:



*R --save < IPFPUMS.R*



R now resides on the same server location as EMME. Our IT person created a
symbolic link for R but still the same error occurred.



Any thoughts will be much appreciated.



Grace

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Dec  8 20:54:57 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 8 Dec 2016 19:54:57 +0000
Subject: [R] R problem
In-Reply-To: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>
References: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>
Message-ID: <D46EF890.190E29%macqueen1@llnl.gov>

Since you didn't say, I'm going to assume this is Linux.

One option would be to put the full path to R in the call in the EMME
script. This might be, for example

/usr/local/bin/R --save < IPFPUMS.R

Without the asterisks before and after, unless they are a requirement of
EMME (which I've never heard of).

But it will depend on where R is installed.

It might be easier in the long run to use Rscript instead of R.


(strictly speaking, this is not an R problem, but a operating
system/installation problem, possibly combined with the methods EMME uses
to interact with software other than itself)

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 12/8/16, 10:56 AM, "R-help on behalf of Grace King"
<r-help-bounces at r-project.org on behalf of gking at ctps.org> wrote:

>Hi all,
>
>
>
>I am trying to run a macro by R in a EMME script. The R macro that we
>wrote
>is called IPFPUMS.R. The whole process has been working until someone
>removed R. We tried to re-install R but getting the error message:
>
>??R? is not recognized as an internal or external command, operable
>program
>or batch file.?
>
>
>
>Here is how R is called to run the macro in the script:
>
>
>
>*R --save < IPFPUMS.R*
>
>
>
>R now resides on the same server location as EMME. Our IT person created a
>symbolic link for R but still the same error occurred.
>
>
>
>Any thoughts will be much appreciated.
>
>
>
>Grace
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Dec  8 21:02:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 8 Dec 2016 12:02:26 -0800
Subject: [R] R problem
In-Reply-To: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>
References: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>
Message-ID: <CAGxFJbQezu606Wptq53nFX-rtSY-QYoeZgA3HfsY_XaReYQj5A@mail.gmail.com>

This looks like it has nothing to do with R per se and therefore is
likely OT here. Please consult your local IT resources for help.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 8, 2016 at 10:56 AM, Grace King <gking at ctps.org> wrote:
> Hi all,
>
>
>
> I am trying to run a macro by R in a EMME script. The R macro that we wrote
> is called IPFPUMS.R. The whole process has been working until someone
> removed R. We tried to re-install R but getting the error message:
>
> ??R? is not recognized as an internal or external command, operable program
> or batch file.?
>
>
>
> Here is how R is called to run the macro in the script:
>
>
>
> *R --save < IPFPUMS.R*
>
>
>
> R now resides on the same server location as EMME. Our IT person created a
> symbolic link for R but still the same error occurred.
>
>
>
> Any thoughts will be much appreciated.
>
>
>
> Grace
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Thu Dec  8 21:39:31 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 9 Dec 2016 07:39:31 +1100
Subject: [R] R problem
In-Reply-To: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>
References: <2e87a82aa81c0e2f5292b7bbf350bb03@mail.gmail.com>
Message-ID: <CA+8X3fXS2xbJ+9NBO5nkYGbk==e6KBM2MQcD5Lz4NYMc+0HtMQ@mail.gmail.com>

Hi Grace,
It is almost certainly a directory problem. The new R installation may
be in a different directory from the old one. Does R run from the
Start menu or a desktop icon? If so, look at "Properties" to discover
where it is located and use the explicit path (e.g. C:\Users\Grace\R
-save < IPFPUMS.R) If that works you can probably add the R home
directory to your PATH when calling the script.

Jim

On Fri, Dec 9, 2016 at 5:56 AM, Grace King <gking at ctps.org> wrote:
> Hi all,
>
>
>
> I am trying to run a macro by R in a EMME script. The R macro that we wrote
> is called IPFPUMS.R. The whole process has been working until someone
> removed R. We tried to re-install R but getting the error message:
>
> ??R? is not recognized as an internal or external command, operable program
> or batch file.?
>
>
>
> Here is how R is called to run the macro in the script:
>
>
>
> *R --save < IPFPUMS.R*
>
>
>
> R now resides on the same server location as EMME. Our IT person created a
> symbolic link for R but still the same error occurred.
>
>
>
> Any thoughts will be much appreciated.
>
>
>
> Grace
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From paul at stat.auckland.ac.nz  Thu Dec  8 23:24:52 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 9 Dec 2016 11:24:52 +1300
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <1492163843.673701.1481235207181@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
	<1492163843.673701.1481235207181@mail.yahoo.com>
Message-ID: <6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>

Hi

You could try ...

grid.export(..., strict=FALSE)

... and/or install the latest gridSVG version from R-Forge ...

https://r-forge.r-project.org/R/?group_id=1025

Paul

On 09/12/16 11:13, Fix Ace wrote:
> Hi, Paul,
>
> Thank you very much for your reply. I tried your sample code, but did
> not get gradient filling (still empty box). And many warnings:
> 1: In checkAttrs(attrs, eltName) :
>   Removing non-SVG attribute name(s): fill, fill-opacity
> 2: In checkAttrs(attrs, eltName) :
>   Removing non-SVG attribute name(s): fill, fill-opacity
> 3: In checkAttrs(attrs, eltName) :
>   Removing non-SVG attribute name(s): fill, fill-opacity
> 4: In checkAttrs(attrs, eltName) :
>   Removing non-SVG attribute name(s): fill, fill-opacity
> 5: In checkAttrs(attrs, eltName) :
> .
> .
> .
>
> I saw the figure in an article, and so I don't have to script. I am
> actually trying to generate the similar figure for my own data.
>
> Any other thoughts?
>
> Thanks.
>
> Ace
>
>
> On Tuesday, December 6, 2016 7:43 PM, Paul Murrell
> <paul at stat.auckland.ac.nz> wrote:
>
>
> Hi
>
> 'gridSVG' might be one way to get this.  For example ...
>
> library(lattice)
> # Draw boxplot (with a package that sits on top of 'grid')
> bwplot(voice.part ~ height, data=singer, xlab="Height (inches)",
>         horizontal=FALSE)
>
> library(grid)
> grid.ls()
> # Looks like boxes are called <blah>bwplot.box.polygon<blah>
>
> library(gridSVG)
> # Define linear gradient
> fill <- linearGradient(c("blue", "red"),
>                         x0=.5, x1=.5,
>                         gradientUnits="coords")
> # Register gradient now so it applies to the whole page
> registerGradientFill("br", fill)
> # Fill each box with gradient
> grid.gradientFill("bwplot.box.polygon", label=rep("br", 17), grep=TRUE,
>                   group=FALSE)
> # Generate SVG version "Rplots.svg"
> # (where the gradient will actually be visible)
> grid.export()
>
> Does that help ?
>
> Paul
>
> On 07/12/16 09:14, Fix Ace wrote:
>> Hello, there,
>> I will like to fill the boxplot with gradient color, as exampled below:
>>
>> Can anyone help me figure out what package I should go with?
>> Thank you very much for any inputs!
>> Kind regards,
>> Ace
>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz <mailto:paul at stat.auckland.ac.nz>
> http://www.stat.auckland.ac.nz/~paul/
>
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From dimitri.liakhovitski at gmail.com  Fri Dec  9 00:02:51 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 18:02:51 -0500
Subject: [R] creating possible cominations of a vector's elements
Message-ID: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>

Hello!

I have a vector of strings 'x' that was based on a longer string
'mystring' (the actual length of x is unknown).

mystring <- "this is my vector"
x <- strsplit(mystr, " ")[[1]]

I am looking for an elegant way of creating an object (e.g., a list)
that contains the following strings:

"this"
"this is"
"this is my"
"this is my vector"
"is"
"is my"
"is my vector"
"my"
"my vector"
"vector"

Thanks a lot!

-- 
Dimitri


From dcarlson at tamu.edu  Fri Dec  9 00:51:03 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 8 Dec 2016 23:51:03 +0000
Subject: [R] creating possible cominations of a vector's elements
In-Reply-To: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
References: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
Message-ID: <2c97510e49584bb1b61cc7e67eedf3eb@exch-2p-mbx-w2.ads.tamu.edu>

You can use expand.grid() and mapply():

mystring <- "this is my vector"
mystring.spl <- strsplit(mystring, " ")[[1]]

makestrings <- function(x) {
     len <- length(mystring.spl)
     idx <- expand.grid(1:len, 1:len)
     idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
     mapply(function(x, y) paste(mystring.spl[x:y], collapse=" "), 
          x=idx[, 1], y=idx[, 2])
}
makestrings(mystring.spl)

 [1] "this"              "this is"           "this is my"       
 [4] "this is my vector" "is"                "is my"            
 [7] "is my vector"      "my"                "my vector"        
[10] "vector"

This makes a vector of strings but if you want a list use as.list(mapply())

David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
Sent: Thursday, December 8, 2016 5:03 PM
To: r-help <r-help at r-project.org>
Subject: [R] creating possible cominations of a vector's elements

Hello!

I have a vector of strings 'x' that was based on a longer string
'mystring' (the actual length of x is unknown).

mystring <- "this is my vector"
x <- strsplit(mystr, " ")[[1]]

I am looking for an elegant way of creating an object (e.g., a list)
that contains the following strings:

"this"
"this is"
"this is my"
"this is my vector"
"is"
"is my"
"is my vector"
"my"
"my vector"
"vector"

Thanks a lot!

-- 
Dimitri

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Fri Dec  9 00:58:25 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Thu, 8 Dec 2016 18:58:25 -0500
Subject: [R] creating possible cominations of a vector's elements
In-Reply-To: <2c97510e49584bb1b61cc7e67eedf3eb@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
	<2c97510e49584bb1b61cc7e67eedf3eb@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAN2xGJYe85Q-UGpNBCVXtAOj0pRO3ewWH=ZDPPXLtrJiNuqjfA@mail.gmail.com>

Thanks a lot, David - this is great!

On Thu, Dec 8, 2016 at 6:51 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> You can use expand.grid() and mapply():
>
> mystring <- "this is my vector"
> mystring.spl <- strsplit(mystring, " ")[[1]]
>
> makestrings <- function(x) {
>      len <- length(mystring.spl)
>      idx <- expand.grid(1:len, 1:len)
>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>      mapply(function(x, y) paste(mystring.spl[x:y], collapse=" "),
>           x=idx[, 1], y=idx[, 2])
> }
> makestrings(mystring.spl)
>
>  [1] "this"              "this is"           "this is my"
>  [4] "this is my vector" "is"                "is my"
>  [7] "is my vector"      "my"                "my vector"
> [10] "vector"
>
> This makes a vector of strings but if you want a list use as.list(mapply())
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
> Sent: Thursday, December 8, 2016 5:03 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] creating possible cominations of a vector's elements
>
> Hello!
>
> I have a vector of strings 'x' that was based on a longer string
> 'mystring' (the actual length of x is unknown).
>
> mystring <- "this is my vector"
> x <- strsplit(mystr, " ")[[1]]
>
> I am looking for an elegant way of creating an object (e.g., a list)
> that contains the following strings:
>
> "this"
> "this is"
> "this is my"
> "this is my vector"
> "is"
> "is my"
> "is my vector"
> "my"
> "my vector"
> "vector"
>
> Thanks a lot!
>
> --
> Dimitri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From wdunlap at tibco.com  Fri Dec  9 01:05:41 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 8 Dec 2016 16:05:41 -0800
Subject: [R] creating possible cominations of a vector's elements
In-Reply-To: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
References: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
Message-ID: <CAF8bMcaA-i9=atbRQjj=tVh+u77adzKfHo+fQFCCmNkG1akTZg@mail.gmail.com>

> ij <- combn(length(x)+1, 2)
> lapply(seq_len(ncol(ij)), function(k) x[ij[1,k]:(ij[2,k]-1)])
[[1]]
[1] "this"

[[2]]
[1] "this" "is"
...
[[9]]
[1] "my"     "vector"

[[10]]
[1] "vector"


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Dec 8, 2016 at 3:02 PM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Hello!
>
> I have a vector of strings 'x' that was based on a longer string
> 'mystring' (the actual length of x is unknown).
>
> mystring <- "this is my vector"
> x <- strsplit(mystr, " ")[[1]]
>
> I am looking for an elegant way of creating an object (e.g., a list)
> that contains the following strings:
>
> "this"
> "this is"
> "this is my"
> "this is my vector"
> "is"
> "is my"
> "is my vector"
> "my"
> "my vector"
> "vector"
>
> Thanks a lot!
>
> --
> Dimitri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Dec  9 02:12:22 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 9 Dec 2016 01:12:22 +0000
Subject: [R] creating possible cominations of a vector's elements
References: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
Message-ID: <05236a0db7b1475f82e6d23851968cf5@exch-2p-mbx-w2.ads.tamu.edu>

This corrects an error in my earlier function definition:

makestrings <- function(vec) {
     len <- length(mystring.spl)
     idx <- expand.grid(1:len, 1:len)
     idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
     mapply(function(x, y) paste(vec[x:y], collapse=" "), 
          x=idx[, 1], y=idx[, 2])
}

David C

-----Original Message-----
From: David L Carlson 
Sent: Thursday, December 8, 2016 5:51 PM
To: 'Dimitri Liakhovitski' <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
Subject: RE: [R] creating possible cominations of a vector's elements

You can use expand.grid() and mapply():

mystring <- "this is my vector"
mystring.spl <- strsplit(mystring, " ")[[1]]

makestrings <- function(x) {
     len <- length(mystring.spl)
     idx <- expand.grid(1:len, 1:len)
     idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
     mapply(function(x, y) paste(mystring.spl[x:y], collapse=" "), 
          x=idx[, 1], y=idx[, 2])
}
makestrings(mystring.spl)

 [1] "this"              "this is"           "this is my"       
 [4] "this is my vector" "is"                "is my"            
 [7] "is my vector"      "my"                "my vector"        
[10] "vector"

This makes a vector of strings but if you want a list use as.list(mapply())

David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
Sent: Thursday, December 8, 2016 5:03 PM
To: r-help <r-help at r-project.org>
Subject: [R] creating possible cominations of a vector's elements

Hello!

I have a vector of strings 'x' that was based on a longer string
'mystring' (the actual length of x is unknown).

mystring <- "this is my vector"
x <- strsplit(mystr, " ")[[1]]

I am looking for an elegant way of creating an object (e.g., a list)
that contains the following strings:

"this"
"this is"
"this is my"
"this is my vector"
"is"
"is my"
"is my vector"
"my"
"my vector"
"vector"

Thanks a lot!

-- 
Dimitri

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Dec  9 02:16:19 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 9 Dec 2016 01:16:19 +0000
Subject: [R] creating possible cominations of a vector's elements
In-Reply-To: <05236a0db7b1475f82e6d23851968cf5@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
	<05236a0db7b1475f82e6d23851968cf5@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <ff42fb78d5044987b3e826fca2693d96@exch-2p-mbx-w2.ads.tamu.edu>

Not my day. Another correction:

makestrings <- function(vec) {
     len <- length(vec)
     idx <- expand.grid(1:len, 1:len)
     idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
     mapply(function(x, y) paste(vec[x:y], collapse=" "), 
          x=idx[, 1], y=idx[, 2])
}

David C

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Thursday, December 8, 2016 7:12 PM
To: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
Subject: Re: [R] creating possible cominations of a vector's elements

This corrects an error in my earlier function definition:

makestrings <- function(vec) {
     len <- length(mystring.spl)
     idx <- expand.grid(1:len, 1:len)
     idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
     mapply(function(x, y) paste(vec[x:y], collapse=" "), 
          x=idx[, 1], y=idx[, 2])
}

David C

-----Original Message-----
From: David L Carlson 
Sent: Thursday, December 8, 2016 5:51 PM
To: 'Dimitri Liakhovitski' <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
Subject: RE: [R] creating possible cominations of a vector's elements

You can use expand.grid() and mapply():

mystring <- "this is my vector"
mystring.spl <- strsplit(mystring, " ")[[1]]

makestrings <- function(x) {
     len <- length(mystring.spl)
     idx <- expand.grid(1:len, 1:len)
     idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
     mapply(function(x, y) paste(mystring.spl[x:y], collapse=" "), 
          x=idx[, 1], y=idx[, 2])
}
makestrings(mystring.spl)

 [1] "this"              "this is"           "this is my"       
 [4] "this is my vector" "is"                "is my"            
 [7] "is my vector"      "my"                "my vector"        
[10] "vector"

This makes a vector of strings but if you want a list use as.list(mapply())

David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
Sent: Thursday, December 8, 2016 5:03 PM
To: r-help <r-help at r-project.org>
Subject: [R] creating possible cominations of a vector's elements

Hello!

I have a vector of strings 'x' that was based on a longer string
'mystring' (the actual length of x is unknown).

mystring <- "this is my vector"
x <- strsplit(mystr, " ")[[1]]

I am looking for an elegant way of creating an object (e.g., a list)
that contains the following strings:

"this"
"this is"
"this is my"
"this is my vector"
"is"
"is my"
"is my vector"
"my"
"my vector"
"vector"

Thanks a lot!

-- 
Dimitri

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Thu Dec  8 23:13:27 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Thu, 8 Dec 2016 22:13:27 +0000 (UTC)
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
Message-ID: <1492163843.673701.1481235207181@mail.yahoo.com>

Hi, Paul,
Thank you very much for your reply. I tried your sample code, but did not get gradient filling (still empty box). And many warnings:1: In checkAttrs(attrs, eltName) :
? Removing non-SVG attribute name(s): fill, fill-opacity
2: In checkAttrs(attrs, eltName) :
? Removing non-SVG attribute name(s): fill, fill-opacity
3: In checkAttrs(attrs, eltName) :
? Removing non-SVG attribute name(s): fill, fill-opacity
4: In checkAttrs(attrs, eltName) :
? Removing non-SVG attribute name(s): fill, fill-opacity
5: In checkAttrs(attrs, eltName) :
...

I saw the figure in an article, and so I don't have to script. I am actually trying to generate the similar figure for my own data. 

Any other thoughts?
Thanks.
Ace
 

    On Tuesday, December 6, 2016 7:43 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
 

 Hi

'gridSVG' might be one way to get this.? For example ...

library(lattice)
# Draw boxplot (with a package that sits on top of 'grid')
bwplot(voice.part ~ height, data=singer, xlab="Height (inches)",
? ? ? ? horizontal=FALSE)

library(grid)
grid.ls()
# Looks like boxes are called <blah>bwplot.box.polygon<blah>

library(gridSVG)
# Define linear gradient
fill <- linearGradient(c("blue", "red"),
? ? ? ? ? ? ? ? ? ? ? ? x0=.5, x1=.5,
? ? ? ? ? ? ? ? ? ? ? ? gradientUnits="coords")
# Register gradient now so it applies to the whole page
registerGradientFill("br", fill)
# Fill each box with gradient
grid.gradientFill("bwplot.box.polygon", label=rep("br", 17), grep=TRUE,
? ? ? ? ? ? ? ? ? group=FALSE)
# Generate SVG version "Rplots.svg"
# (where the gradient will actually be visible)
grid.export()

Does that help ?

Paul

On 07/12/16 09:14, Fix Ace wrote:
> Hello, there,
> I will like to fill the boxplot with gradient color, as exampled below:
>
> Can anyone help me figure out what package I should go with?
> Thank you very much for any inputs!
> Kind regards,
> Ace
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


   
	[[alternative HTML version deleted]]


From christian at echoffmann.ch  Thu Dec  8 23:22:52 2016
From: christian at echoffmann.ch (Christian)
Date: Thu, 8 Dec 2016 23:22:52 +0100
Subject: [R] .External2(C_savehistory, file) : no history available to save
Message-ID: <761c0c28-bd50-3a7e-9bc8-1e588304f6a8@echoffmann.ch>

Hi,
I try to save my history:
 > if (interactive()) try(savehistory(file=paste0(dir,"/.Rhistory")) )
to get:  Error in .External2(C_savehistory, file) : no history vailable 
to save
My system:
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.1

locale:
[1] C

attached base packages:
  [1] tcltk     tools     stats4    splines   parallel  datasets  compiler
  [8] graphics  grDevices stats     grid      utils     methods   base

other attached packages:
  [1] survival_2.39-5    spatial_7.3-11     rpart_4.1-10 
nnet_7.3-12
  [5] mgcv_1.8-15        nlme_3.1-128       foreign_0.8-67 
codetools_0.2-15
  [9] cluster_2.0.5      class_7.3-14       boot_1.3-18 
Matrix_1.2-7.1
[13] MASS_7.3-45        KernSmooth_2.23-15 cwhmisc_6.0 
lattice_0.20-34

Why this?
C.

-- 
Christian Hoffmann
Rigiblickstrasee 15b
CH-8915 Hausen am Albis
Telefon 0041-(0)44-7640853


From pnsinha68 at gmail.com  Fri Dec  9 06:55:37 2016
From: pnsinha68 at gmail.com (Partha Sinha)
Date: Fri, 9 Dec 2016 11:25:37 +0530
Subject: [R] sample train and test data using dplyr
In-Reply-To: <CAKVAULNuvj2o1wDqNsxFRpZRvjsULMKv7ozB-=A5Mh_QY8KsWg@mail.gmail.com>
References: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>
	<CAGxFJbSDyYLYhisfjGawM-WaQJF5=w=E4eRY1+c_MhEXpnFpBQ@mail.gmail.com>
	<CAKVAULNuvj2o1wDqNsxFRpZRvjsULMKv7ozB-=A5Mh_QY8KsWg@mail.gmail.com>
Message-ID: <CADcgpJc9V1g_8Xjt_NQKmfcdnFWKge0Yy=LPTMARyKaH3zVNjA@mail.gmail.com>

How to get two sets of non overlapping data?
Regards
Parth

On 8 December 2016 at 23:23, Ulrik Stervbo <ulrik.stervbo at gmail.com> wrote:

> In addition to 'sample', and if you insist on dplyr, you can use
> 'sample_n'.
>
> Best,
> Ulrik
>
> On Thu, 8 Dec 2016 at 18:47 Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
>> Usually we expect posters to do their homework by reading necessary R
>> documentation and relevant subject matter resources (e.g. on
>> clustering) and making a serious attempt to solve the problem by
>> offering their code to us along as part of  a reproducible example of
>> how it failed. You have done none of these things, and so you may not
>> receive a helpful reply -- or maybe some kind soul will offer one.
>>
>> I am not such a kind soul. However I will tell you that ?sample is
>> probably relevant and that you should read and follow the posting
>> guide at the foot of this email to post a coherent query, which, IMO,
>> yours is not.
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Thu, Dec 8, 2016 at 8:57 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:
>> > I want to create two files train and test using dplyr (by random
>> sampling
>> > method). How to do the same same using lets say iris data.
>> > Regards
>> > Parth
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Fri Dec  9 07:42:56 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 09 Dec 2016 06:42:56 +0000
Subject: [R] sample train and test data using dplyr
In-Reply-To: <CADcgpJc9V1g_8Xjt_NQKmfcdnFWKge0Yy=LPTMARyKaH3zVNjA@mail.gmail.com>
References: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>
	<CAGxFJbSDyYLYhisfjGawM-WaQJF5=w=E4eRY1+c_MhEXpnFpBQ@mail.gmail.com>
	<CAKVAULNuvj2o1wDqNsxFRpZRvjsULMKv7ozB-=A5Mh_QY8KsWg@mail.gmail.com>
	<CADcgpJc9V1g_8Xjt_NQKmfcdnFWKge0Yy=LPTMARyKaH3zVNjA@mail.gmail.com>
Message-ID: <CAKVAULOd1pphr-7B0rQCy+2C9PT6vF=M8eoMpswOJfJD4D+qSw@mail.gmail.com>

df <- data.frame(x = 1:12, y = rnorm(12))

If you use sample:

RowIndex <- sample(1:nrow(df), 5)
TrainSet <- df[RowIndex, ]
TestSet <- df[-RowIndex, ]

Or with dplyr:

TrainSet <- sample_n(df, 5)
TestSet <- anti_join(TestSet, df)

HTH
Ulrik

On Fri, 9 Dec 2016, 06:56 Partha Sinha, <pnsinha68 at gmail.com> wrote:

> How to get two sets of non overlapping data?
> Regards
> Parth
>
> On 8 December 2016 at 23:23, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
> In addition to 'sample', and if you insist on dplyr, you can use
> 'sample_n'.
>
> Best,
> Ulrik
>
> On Thu, 8 Dec 2016 at 18:47 Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> Usually we expect posters to do their homework by reading necessary R
> documentation and relevant subject matter resources (e.g. on
> clustering) and making a serious attempt to solve the problem by
> offering their code to us along as part of  a reproducible example of
> how it failed. You have done none of these things, and so you may not
> receive a helpful reply -- or maybe some kind soul will offer one.
>
> I am not such a kind soul. However I will tell you that ?sample is
> probably relevant and that you should read and follow the posting
> guide at the foot of this email to post a coherent query, which, IMO,
> yours is not.
>
> Cheers,
> Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Dec 8, 2016 at 8:57 AM, Partha Sinha <pnsinha68 at gmail.com> wrote:
> > I want to create two files train and test using dplyr (by random sampling
> > method). How to do the same same using lets say iris data.
> > Regards
> > Parth
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Fri Dec  9 16:52:53 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Fri, 9 Dec 2016 10:52:53 -0500
Subject: [R] creating possible cominations of a vector's elements
In-Reply-To: <ff42fb78d5044987b3e826fca2693d96@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAN2xGJbbtgkXCQr8WGLMAphSzX2JmKWg6xH5QQXH2K5=6M9pUA@mail.gmail.com>
	<05236a0db7b1475f82e6d23851968cf5@exch-2p-mbx-w2.ads.tamu.edu>
	<ff42fb78d5044987b3e826fca2693d96@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAN2xGJagCqQ41YNCXcD3SPdQ670sxwd50rUz9aqntz1do7-paQ@mail.gmail.com>

Thanks a lot, David and Bill!


On Thu, Dec 8, 2016 at 8:16 PM, David L Carlson <dcarlson at tamu.edu> wrote:
> Not my day. Another correction:
>
> makestrings <- function(vec) {
>      len <- length(vec)
>      idx <- expand.grid(1:len, 1:len)
>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>      mapply(function(x, y) paste(vec[x:y], collapse=" "),
>           x=idx[, 1], y=idx[, 2])
> }
>
> David C
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
> Sent: Thursday, December 8, 2016 7:12 PM
> To: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
> Subject: Re: [R] creating possible cominations of a vector's elements
>
> This corrects an error in my earlier function definition:
>
> makestrings <- function(vec) {
>      len <- length(mystring.spl)
>      idx <- expand.grid(1:len, 1:len)
>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>      mapply(function(x, y) paste(vec[x:y], collapse=" "),
>           x=idx[, 1], y=idx[, 2])
> }
>
> David C
>
> -----Original Message-----
> From: David L Carlson
> Sent: Thursday, December 8, 2016 5:51 PM
> To: 'Dimitri Liakhovitski' <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
> Subject: RE: [R] creating possible cominations of a vector's elements
>
> You can use expand.grid() and mapply():
>
> mystring <- "this is my vector"
> mystring.spl <- strsplit(mystring, " ")[[1]]
>
> makestrings <- function(x) {
>      len <- length(mystring.spl)
>      idx <- expand.grid(1:len, 1:len)
>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>      mapply(function(x, y) paste(mystring.spl[x:y], collapse=" "),
>           x=idx[, 1], y=idx[, 2])
> }
> makestrings(mystring.spl)
>
>  [1] "this"              "this is"           "this is my"
>  [4] "this is my vector" "is"                "is my"
>  [7] "is my vector"      "my"                "my vector"
> [10] "vector"
>
> This makes a vector of strings but if you want a list use as.list(mapply())
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
> Sent: Thursday, December 8, 2016 5:03 PM
> To: r-help <r-help at r-project.org>
> Subject: [R] creating possible cominations of a vector's elements
>
> Hello!
>
> I have a vector of strings 'x' that was based on a longer string
> 'mystring' (the actual length of x is unknown).
>
> mystring <- "this is my vector"
> x <- strsplit(mystr, " ")[[1]]
>
> I am looking for an elegant way of creating an object (e.g., a list)
> that contains the following strings:
>
> "this"
> "this is"
> "this is my"
> "this is my vector"
> "is"
> "is my"
> "is my vector"
> "my"
> "my vector"
> "vector"
>
> Thanks a lot!
>
> --
> Dimitri
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From HDoran at air.org  Fri Dec  9 18:15:38 2016
From: HDoran at air.org (Doran, Harold)
Date: Fri, 9 Dec 2016 17:15:38 +0000
Subject: [R] "Safe" use of iterator (package iterators)
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F73D9@DC1VEX10MB01.air.org>

I believe I now see the light vis-?-vis iterators when combined with foreach() calls in R. I have now been able to reduce computational workload to minutes instead of hours. I want to verify that the way I am using them is "safe". By safe I mean does the iterator traverse elements in the same way as I have below in my toy example to illustrate what I mean.

In the first "traditional" example, I have only one index variable for the loop and so I know that the same list in r1 and r2 are always being grabbed. That is, in iteration 1 it is guaranteed to use r1[[1]] + r2[[1]].

In the example that uses the iterators, is this also guaranteed even though I now have two iterator objects? That is, will the index for element i always be the same as the index for element j when using this across many different cores?

It seems to be true and in all my test cases so far I am seeing it to be true. But, that could be just luck, so I wonder if there is a condition under which that would NOT be true.

Thank you
Harold


library(foreach)
library(doParallel)
cl <- makeCluster(2) 
registerDoParallel(cl)

### Create random data
r1 <- vector("list", 20)
for(i in 1:20){
	r1[[i]] <- rnorm(10)
}

### Create random data
r2 <- vector("list", 20)
for(i in 1:20){
	r2[[i]] <- rnorm(10)
}

### Use a for loop traditionally 
result1 <- vector("list", 20)
for(i in 1:20){
	result1[[i]] <- r1[[i]] + r2[[i]]
}
	
### Use iterators
itx1 <- iter(r1)
itx2 <- iter(r2)

result2 <- foreach(i = itx1, j = itx2) %dopar% {
	i + j
	}	

all.equal(result1, result2)


From sibylle.stoeckli at gmx.ch  Fri Dec  9 19:20:25 2016
From: sibylle.stoeckli at gmx.ch (=?iso-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Fri, 9 Dec 2016 19:20:25 +0100
Subject: [R] vegan NMDS labels
Message-ID: <E1A6220A-7392-459A-9F81-A365A05BF845@gmx.ch>

Dear R users

Does anybody know how it may be possible to plot the labels of a ordihull function separately (in R vegan)? We have studied the bee community in 5 different habitat types. As you see from the code, we use different point types (pch) and line types (lty). This is only possible if we change the habitat from character to integer. However, we prefer to show the labels as characters and not as integers 1-5? Furthermore, does anybody now how to plot the labels at the border and not in the centroid of the polygon (due to overlapping polygons it is not easy to assign them to the right polygon)?

Many thanks
Sibylle

### NMDS code ####
example_NMDS=metaMDS(community_matrix, # Our community-by-species matrix
                     distance = "bray", k=2) # The number of reduced dimensions
stressplot(example_NMDS)
ordiplot (example_NMDS, display = 'species', type = 'n', xlim=c(-0.5,0.5), ylim=c(-0.7,0.7))
HabTyp<-as.integer(S1$H_Aggregat1) # 5 different habitats. 
points (example_NMDS, col="black", pch = HabTyp)
for (i in unique (HabTyp)) ordihull (example_NMDS, groups = HabTyp, show.group = i, draw = 'polygon', label=T, cex=1.5, lty=i)


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec  9 19:26:55 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Dec 2016 10:26:55 -0800
Subject: [R] "Safe" use of iterator (package iterators)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F73D9@DC1VEX10MB01.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F73D9@DC1VEX10MB01.air.org>
Message-ID: <F5E6B19C-1C53-427B-8BCF-0739DDC63645@comcast.net>


> On Dec 9, 2016, at 9:15 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I believe I now see the light vis-?-vis iterators when combined with foreach() calls in R. I have now been able to reduce computational workload to minutes instead of hours. I want to verify that the way I am using them is "safe". By safe I mean does the iterator traverse elements in the same way as I have below in my toy example to illustrate what I mean.
> 
> In the first "traditional" example, I have only one index variable for the loop and so I know that the same list in r1 and r2 are always being grabbed. That is, in iteration 1 it is guaranteed to use r1[[1]] + r2[[1]].
> 
> In the example that uses the iterators, is this also guaranteed even though I now have two iterator objects? That is, will the index for element i always be the same as the index for element j when using this across many different cores?
> 
> It seems to be true and in all my test cases so far I am seeing it to be true. But, that could be just luck, so I wonder if there is a condition under which that would NOT be true.
> 
> Thank you
> Harold
> 
> 
> library(foreach)
> library(doParallel)
> cl <- makeCluster(2) 
> registerDoParallel(cl)
> 
> ### Create random data
> r1 <- vector("list", 20)
> for(i in 1:20){
> 	r1[[i]] <- rnorm(10)
> }
> 
> ### Create random data
> r2 <- vector("list", 20)
> for(i in 1:20){
> 	r2[[i]] <- rnorm(10)
> }
> 
> ### Use a for loop traditionally 
> result1 <- vector("list", 20)
> for(i in 1:20){
> 	result1[[i]] <- r1[[i]] + r2[[i]]
> }
> 	
> ### Use iterators
> itx1 <- iter(r1)
> itx2 <- iter(r2)
> 
> result2 <- foreach(i = itx1, j = itx2) %dopar% {
> 	i + j
> 	}	
> 
> all.equal(result1, result2)

I wasn't sure how this would or should behave. I'm not an experienced user, merely a reader of help pages. Neither the help page, not the vignette references on the help page answered my questions in this case. I expected that call would behave analogously to the behavior of mapply when given iterators of unequal length. (The shorter of the objects is recycled to reach the length of the longer object.) That expectation was not realized. It appears that the length of first object of the objects determines computation length, but that missing values will not be recycled for the shorter iterator. An error is not reported, but rather numeric(0) is returned. So in one sense the %dopar% version is "safer" at least to the extent of not failing with an error that would have occurred when using a for-loop.

This was my test case:

r1 <- vector("list", 10)
for(i in 1:20){
	r1[[i]] <-20:29+i*10  
# random numbers are not good for determining sequences of operations
}
r2 <- vector("list", 20)
for(i in 1:10){
	r2[[i]] <- 1:10 +i
}
itx1 <- iter(r1)
itx2 <- iter(r2)

result2 <- foreach(i = itx1, j = itx2) %dopar% {
	i + j
	}	

result2



-- 

David Winsemius
Alameda, CA, USA


From HDoran at air.org  Fri Dec  9 19:42:10 2016
From: HDoran at air.org (Doran, Harold)
Date: Fri, 9 Dec 2016 18:42:10 +0000
Subject: [R] "Safe" use of iterator (package iterators)
In-Reply-To: <F5E6B19C-1C53-427B-8BCF-0739DDC63645@comcast.net>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F73D9@DC1VEX10MB01.air.org>
	<F5E6B19C-1C53-427B-8BCF-0739DDC63645@comcast.net>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601358F75F6@DC1VEX10MB01.air.org>

That is a helpful, and important, caveat. So, perhaps I should amend my original question to ask something like is it safe *when* length(r1) == length(r2)

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Friday, December 09, 2016 1:27 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] "Safe" use of iterator (package iterators)


> On Dec 9, 2016, at 9:15 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I believe I now see the light vis-?-vis iterators when combined with foreach() calls in R. I have now been able to reduce computational workload to minutes instead of hours. I want to verify that the way I am using them is "safe". By safe I mean does the iterator traverse elements in the same way as I have below in my toy example to illustrate what I mean.
> 
> In the first "traditional" example, I have only one index variable for the loop and so I know that the same list in r1 and r2 are always being grabbed. That is, in iteration 1 it is guaranteed to use r1[[1]] + r2[[1]].
> 
> In the example that uses the iterators, is this also guaranteed even though I now have two iterator objects? That is, will the index for element i always be the same as the index for element j when using this across many different cores?
> 
> It seems to be true and in all my test cases so far I am seeing it to be true. But, that could be just luck, so I wonder if there is a condition under which that would NOT be true.
> 
> Thank you
> Harold
> 
> 
> library(foreach)
> library(doParallel)
> cl <- makeCluster(2)
> registerDoParallel(cl)
> 
> ### Create random data
> r1 <- vector("list", 20)
> for(i in 1:20){
> 	r1[[i]] <- rnorm(10)
> }
> 
> ### Create random data
> r2 <- vector("list", 20)
> for(i in 1:20){
> 	r2[[i]] <- rnorm(10)
> }
> 
> ### Use a for loop traditionally
> result1 <- vector("list", 20)
> for(i in 1:20){
> 	result1[[i]] <- r1[[i]] + r2[[i]]
> }
> 	
> ### Use iterators
> itx1 <- iter(r1)
> itx2 <- iter(r2)
> 
> result2 <- foreach(i = itx1, j = itx2) %dopar% {
> 	i + j
> 	}	
> 
> all.equal(result1, result2)

I wasn't sure how this would or should behave. I'm not an experienced user, merely a reader of help pages. Neither the help page, not the vignette references on the help page answered my questions in this case. I expected that call would behave analogously to the behavior of mapply when given iterators of unequal length. (The shorter of the objects is recycled to reach the length of the longer object.) That expectation was not realized. It appears that the length of first object of the objects determines computation length, but that missing values will not be recycled for the shorter iterator. An error is not reported, but rather numeric(0) is returned. So in one sense the %dopar% version is "safer" at least to the extent of not failing with an error that would have occurred when using a for-loop.

This was my test case:

r1 <- vector("list", 10)
for(i in 1:20){
	r1[[i]] <-20:29+i*10
# random numbers are not good for determining sequences of operations }
r2 <- vector("list", 20)
for(i in 1:10){
	r2[[i]] <- 1:10 +i
}
itx1 <- iter(r1)
itx2 <- iter(r2)

result2 <- foreach(i = itx1, j = itx2) %dopar% {
	i + j
	}	

result2



-- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Fri Dec  9 20:29:15 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 9 Dec 2016 19:29:15 +0000
Subject: [R] vegan NMDS labels
In-Reply-To: <E1A6220A-7392-459A-9F81-A365A05BF845@gmx.ch>
References: <E1A6220A-7392-459A-9F81-A365A05BF845@gmx.ch>
Message-ID: <9cc35a13a3d04e3b8995b6c16c5d2d48@exch-2p-mbx-w2.ads.tamu.edu>

You did not provide a reproducible example, but you should be able to get what you want as follows:

library(vegan)
data(dune)
data(dune.env)

lbls <-as.integer(dune.env$Management)
grps <- levels(dune.env$Management)
ngrps <- length(grps)

example_dune <- metaMDS(dune, distance="bray", k=2)
ordiplot(example_dune, display="species", type="n")
points(example_dune, col="black", pch = lbls)
ordihull(example_dune, dune.env$Management, scaling = "symmetric", lty=lbls)
# Optionally add a legend
legend("topright", grps, pch=1:ngrps, lty=1:ngrps)

# However if you want to position the labels, try this
grp.lbls <- locator()
# Click where you want each label to appear.
# The pch symbols are circle, triangle, plus, X
# click where you want the label to appear for each group
# in that order and then click stop (upper left corner)
# of the window.
text(grp.lbls, grps)

Or just eyeball the coordinates. Once you have them where you want them, save them with dput() and include them in your script file (assuming you are planning to plot to a print device later).

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sibylle St?ckli
Sent: Friday, December 9, 2016 12:20 PM
To: r-help at r-project.org
Subject: [R] vegan NMDS labels

Dear R users

Does anybody know how it may be possible to plot the labels of a ordihull function separately (in R vegan)? We have studied the bee community in 5 different habitat types. As you see from the code, we use different point types (pch) and line types (lty). This is only possible if we change the habitat from character to integer. However, we prefer to show the labels as characters and not as integers 1-5? Furthermore, does anybody now how to plot the labels at the border and not in the centroid of the polygon (due to overlapping polygons it is not easy to assign them to the right polygon)?

Many thanks
Sibylle

### NMDS code ####
example_NMDS=metaMDS(community_matrix, # Our community-by-species matrix
                     distance = "bray", k=2) # The number of reduced dimensions
stressplot(example_NMDS)
ordiplot (example_NMDS, display = 'species', type = 'n', xlim=c(-0.5,0.5), ylim=c(-0.7,0.7))
HabTyp<-as.integer(S1$H_Aggregat1) # 5 different habitats. 
points (example_NMDS, col="black", pch = HabTyp)
for (i in unique (HabTyp)) ordihull (example_NMDS, groups = HabTyp, show.group = i, draw = 'polygon', label=T, cex=1.5, lty=i)


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: DuneExample.png
Type: image/png
Size: 8863 bytes
Desc: DuneExample.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161209/b1bb1382/attachment.png>

From huxinghai1989 at gmail.com  Fri Dec  9 23:45:00 2016
From: huxinghai1989 at gmail.com (Hu Xinghai)
Date: Fri, 9 Dec 2016 14:45:00 -0800
Subject: [R] glmnet error: no-comfortable arguments
Message-ID: <CAKaWgJ46yuZHnF2afPL4K1deSwFeBmjh_57CKPmjhO2cPUOqCA@mail.gmail.com>

I come across the following error training Logistic Regression model using
cv.glmnet:

> Error in drop(y %*% rep(1, nc)) : error in evaluating the argument 'x' in
> selecting a method for function 'drop': Error in y %*% rep(1, nc) :
> non-conformable arguments
> error in evaluating the argument 'x' in selecting a method for function
> 'drop': Error in y %*% rep(1, nc) : non-conformable arguments


The error appears occasionally. However, since I need to run over a
parameter grid to optimize a parameter, the logistic regression needs to
run for multiple time; and therefore, almost certainly this error would be
hit.

Below is my code:

>     cellDF = df[(df$cell_id == cellid), ]
>     X = cellDF[, c(5:(ncol(cellDF)-2) )]
>     X$median_age = as.numeric(X$median_age)
>     X = data.matrix(X)
>     Y = cellDF$signup
>     impWeights = as.double(cellDF$trW)
>     has_NA = union(apply(is.na(X), 1, any), sapply(Y, is.na) )
>     has_NA = union(has_NA, sapply(impWeights, is.na))
>     X = X[!has_NA,]
>     Y = Y[!has_NA]
>     impWeights = impWeights[!has_NA]
>     nfolds = 8
>     YPosIdx = which(Y == 1)
>     YNegIdx = which(Y == 0)
>     LYPos = length(YPosIdx)
>     LYNeg = length(YNegIdx)
>     samplePos = sample(c(1:nfolds), LYPos, replace = TRUE)
>     sampleNeg = sample(c(1:nfolds), LYNeg, replace = TRUE)
>     order = match(c(1: length(Y)), c(YPosIdx, YNegIdx))
>     foldid = c(samplePos, sampleNeg)[order]
>     model = cv.glmnet(x = X, y = Y, weights = impWeights,
> family="binomial", type.measure="auc", lambda = lambdaGrid, nfolds =
> nfolds, foldid = foldid)
>     fit = predict(model, censusX, s = "lambda.1se", type = "response")


I read some posts online about the issue, suggesting that there might be
NA, and I should use data.matrix instead of as.matrix, and also I need to
fix foldid to make sure both positive and negative samples exists. I tried
all these tricks, but none helps.

Is there any thought about it?

Thanks

	[[alternative HTML version deleted]]


From jatin.kala.jk at gmail.com  Fri Dec  9 09:02:30 2016
From: jatin.kala.jk at gmail.com (Jatin Kala)
Date: Fri, 9 Dec 2016 16:02:30 +0800
Subject: [R] issue overlaying a contour plot on map
Message-ID: <24a95f4c-570a-65c7-5039-936660b544f3@gmail.com>

Hi R-community,
I am able to do a contour plot, and a map separately, but having some 
issues overlaying them. The script and data is attached.
test_filled_contour_plot.png is the contour plot alone
test_ggmap.png is the map alone.
test_overaly.png is supposed to overaly the two, but as you can see, 
it's not happening for some reason.
Any suggestions?
Cheers,
Jatin

-------------- next part --------------
# Always delete everything first
rm(list = ls())
library(rgdal)
# load processed AERMOD outputs generated by read_AERMOD_save.R
load("ALL_HOURLY_NOX_Processed")
utmcoor<-SpatialPoints(cbind(x,y), proj4string=CRS("+proj=utm +zone=50 +ellps=WGS84 +south"))
longlatcoor<-spTransform(utmcoor,CRS("+proj=longlat"))
lon <-longlatcoor at coords[,1]
lat <-longlatcoor at coords[,2]
png("test_filled_countour_plot.png")
filled.contour(x=lon,y=lat,max_conc)
dev.off()
library(ggmap)
pngMAP_df = get_map(location = c(min(lon), min(lat), max(lon), max(lat)), source = "osm", zoom = 12,filename="test_ggmap")
ggmap(pngMAP_df) + filled.contour(x=lon,y=lat,max_conc)
ggsave("test_overlay.png")
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test_filled_countour_plot.png
Type: image/png
Size: 58183 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161209/a646360a/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test_ggmap.png
Type: image/png
Size: 1636781 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161209/a646360a/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test_overlay.png
Type: image/png
Size: 1865369 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161209/a646360a/attachment-0005.png>

From acefix at rocketmail.com  Fri Dec  9 22:39:48 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Fri, 9 Dec 2016 21:39:48 +0000 (UTC)
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
	<1492163843.673701.1481235207181@mail.yahoo.com>
	<6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>
Message-ID: <1667594422.52330.1481319588031@mail.yahoo.com>

Hi, Paul,
Thank you very much! It works this time with "strict=FALSE" option.
Another relevant question:
how did you figure out? that boxes in boxplot are called "bwplot.box.polygon". If I am trying to make a gradient filling for barplot of other plots, how would I define grobs?
Thanks!!
Ace



 

    On Thursday, December 8, 2016 5:24 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
 

 Hi

You could try ...

grid.export(..., strict=FALSE)

... and/or install the latest gridSVG version from R-Forge ...

https://r-forge.r-project.org/R/?group_id=1025

Paul


   
	[[alternative HTML version deleted]]


From acefix at rocketmail.com  Fri Dec  9 22:39:48 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Fri, 9 Dec 2016 21:39:48 +0000 (UTC)
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
	<1492163843.673701.1481235207181@mail.yahoo.com>
	<6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>
Message-ID: <1667594422.52330.1481319588031@mail.yahoo.com>

Hi, Paul,
Thank you very much! It works this time with "strict=FALSE" option.
Another relevant question:
how did you figure out? that boxes in boxplot are called "bwplot.box.polygon". If I am trying to make a gradient filling for barplot of other plots, how would I define grobs?
Thanks!!
Ace



 

    On Thursday, December 8, 2016 5:24 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
 

 Hi

You could try ...

grid.export(..., strict=FALSE)

... and/or install the latest gridSVG version from R-Forge ...

https://r-forge.r-project.org/R/?group_id=1025

Paul


   
	[[alternative HTML version deleted]]


From psychexpert1992 at gmail.com  Sat Dec 10 00:20:33 2016
From: psychexpert1992 at gmail.com (Julia Edeleva)
Date: Sat, 10 Dec 2016 00:20:33 +0100
Subject: [R] =?utf-8?q?package_=E2=80=98Rccp=E2=80=99_is_not_available_=28?=
	=?utf-8?q?for_R_version_3=2E3=2E2=29?=
Message-ID: <CAOVRatwk8uehvxbYOApF8o1hwTuW_u2zGQ+xKGvz4L62TAAEXw@mail.gmail.com>

Dear R-Community,

I am trying to install the "eyetrackingR"-package to analyse my
eye-tracking data.

When installing the package prompts me to install the Rccp. However, when
trying to do so, I am getting the error message

package ?Rccp? is not available (for R version 3.3.2)

Which version of R should I use to make Rccp work?

Thank you in advance
Julia Edeleva

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Dec 10 02:11:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 09 Dec 2016 17:11:19 -0800
Subject: [R]
	=?utf-8?q?package_=E2=80=98Rccp=E2=80=99_is_not_available_=28?=
	=?utf-8?q?for_R_version_3=2E3=2E2=29?=
In-Reply-To: <CAOVRatwk8uehvxbYOApF8o1hwTuW_u2zGQ+xKGvz4L62TAAEXw@mail.gmail.com>
References: <CAOVRatwk8uehvxbYOApF8o1hwTuW_u2zGQ+xKGvz4L62TAAEXw@mail.gmail.com>
Message-ID: <B4C51F14-7061-4134-B18D-0E4DDC67916C@dcn.davis.ca.us>

A) it is Rcpp, not Rccp

B)  try another CRAN mirror if the automatic dependency handling did not work
-- 
Sent from my phone. Please excuse my brevity.

On December 9, 2016 3:20:33 PM PST, Julia Edeleva <psychexpert1992 at gmail.com> wrote:
>Dear R-Community,
>
>I am trying to install the "eyetrackingR"-package to analyse my
>eye-tracking data.
>
>When installing the package prompts me to install the Rccp. However,
>when
>trying to do so, I am getting the error message
>
>package ?Rccp? is not available (for R version 3.3.2)
>
>Which version of R should I use to make Rccp work?
>
>Thank you in advance
>Julia Edeleva
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From djnordlund at gmail.com  Sat Dec 10 02:40:13 2016
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Fri, 9 Dec 2016 17:40:13 -0800
Subject: [R]
 =?utf-8?q?package_=E2=80=98Rccp=E2=80=99_is_not_available_=28?=
 =?utf-8?q?for_R_version_3=2E3=2E2=29?=
In-Reply-To: <CAOVRatwk8uehvxbYOApF8o1hwTuW_u2zGQ+xKGvz4L62TAAEXw@mail.gmail.com>
References: <CAOVRatwk8uehvxbYOApF8o1hwTuW_u2zGQ+xKGvz4L62TAAEXw@mail.gmail.com>
Message-ID: <ea1e3030-5056-6843-308f-18c91ca4ee94@gmail.com>

On 12/9/2016 3:20 PM, Julia Edeleva wrote:
> Dear R-Community,
>
> I am trying to install the "eyetrackingR"-package to analyse my
> eye-tracking data.
>
> When installing the package prompts me to install the Rccp. However, when
> trying to do so, I am getting the error message
>
> package ?Rccp? is not available (for R version 3.3.2)
>
> Which version of R should I use to make Rccp work?
>
> Thank you in advance
> Julia Edeleva
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Should that be the Rcpp package and not Rccp?

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From dwinsemius at comcast.net  Sat Dec 10 03:57:07 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Dec 2016 18:57:07 -0800
Subject: [R] glmnet error: no-comfortable arguments
In-Reply-To: <CAKaWgJ46yuZHnF2afPL4K1deSwFeBmjh_57CKPmjhO2cPUOqCA@mail.gmail.com>
References: <CAKaWgJ46yuZHnF2afPL4K1deSwFeBmjh_57CKPmjhO2cPUOqCA@mail.gmail.com>
Message-ID: <2C9CE282-A681-41ED-91E9-100BB4DC8EAD@comcast.net>


> On Dec 9, 2016, at 2:45 PM, Hu Xinghai <huxinghai1989 at gmail.com> wrote:
> 
> I come across the following error training Logistic Regression model using
> cv.glmnet:
> 
>> Error in drop(y %*% rep(1, nc)) : error in evaluating the argument 'x' in
>> selecting a method for function 'drop': Error in y %*% rep(1, nc) :
>> non-conformable arguments
>> error in evaluating the argument 'x' in selecting a method for function
>> 'drop': Error in y %*% rep(1, nc) : non-conformable arguments
> 
> 
> The error appears occasionally. However, since I need to run over a
> parameter grid to optimize a parameter, the logistic regression needs to
> run for multiple time; and therefore, almost certainly this error would be
> hit.
> 
> Below is my code:
> 
>>    cellDF = df[(df$cell_id == cellid), ]
>>    X = cellDF[, c(5:(ncol(cellDF)-2) )]
>>    X$median_age = as.numeric(X$median_age)
>>    X = data.matrix(X)
>>    Y = cellDF$signup
>>    impWeights = as.double(cellDF$trW)
>>    has_NA = union(apply(is.na(X), 1, any), sapply(Y, is.na) )
>>    has_NA = union(has_NA, sapply(impWeights, is.na))
>>    X = X[!has_NA,]
>>    Y = Y[!has_NA]
>>    impWeights = impWeights[!has_NA]
>>    nfolds = 8
>>    YPosIdx = which(Y == 1)
>>    YNegIdx = which(Y == 0)
>>    LYPos = length(YPosIdx)
>>    LYNeg = length(YNegIdx)
>>    samplePos = sample(c(1:nfolds), LYPos, replace = TRUE)
>>    sampleNeg = sample(c(1:nfolds), LYNeg, replace = TRUE)
>>    order = match(c(1: length(Y)), c(YPosIdx, YNegIdx))
>>    foldid = c(samplePos, sampleNeg)[order]
>>    model = cv.glmnet(x = X, y = Y, weights = impWeights,
>> family="binomial", type.measure="auc", lambda = lambdaGrid, nfolds =
>> nfolds, foldid = foldid)
>>    fit = predict(model, censusX, s = "lambda.1se", type = "response")
> 
> 
> I read some posts online about the issue, suggesting that there might be
> NA, and I should use data.matrix instead of as.matrix, and also I need to
> fix foldid to make sure both positive and negative samples exists. I tried
> all these tricks, but none helps.
> 
> Is there any thought about it?

This duplicates a posting on StackOverflow. If you read the Posting Guide you will find advice cautioning you against cross-posting. If you do not get a satisfactory answer in a reasonable interval which I would say would be 24 hours at a minimum you can justify cross-posting but it should be accompanied by a reference to the original posting>

http://stackoverflow.com/questions/41070103/glmnet-error-non-conformable-arguments

The posting guide (as well as the StackOverflow help pages) ask the you post sufficient sample data to support demonstration and testing. You already have two close votes on the basis of failing to do that. On StackOverflow you can search on `[MCVE]` and "great reproducible example" or you can read the relevant sections of the Posting Guide. Using dput() to post data objects delivers the most specificity in data structure.

-- 
david.


> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Sat Dec 10 07:29:45 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 10 Dec 2016 17:29:45 +1100
Subject: [R] issue overlaying a contour plot on map
In-Reply-To: <24a95f4c-570a-65c7-5039-936660b544f3@gmail.com>
References: <24a95f4c-570a-65c7-5039-936660b544f3@gmail.com>
Message-ID: <CA+8X3fX4WbLD6dw_p3En9jQ5sVhGfdoSkXhbn6NVt3K0NdqSSg@mail.gmail.com>

Hi Jatin,
It looks as though the third plot has the contour plot beneath the
map, which is opaque.If you just want to show the three "hotspots" on
the map, perhaps you could adjust the colors so that they are
displayed on a transparent field instead of blue and then overlay that
on the map.

Jim


On Fri, Dec 9, 2016 at 7:02 PM, Jatin Kala <jatin.kala.jk at gmail.com> wrote:
> Hi R-community,
> I am able to do a contour plot, and a map separately, but having some issues
> overlaying them. The script and data is attached.
> test_filled_contour_plot.png is the contour plot alone
> test_ggmap.png is the map alone.
> test_overaly.png is supposed to overaly the two, but as you can see, it's
> not happening for some reason.
> Any suggestions?
> Cheers,
> Jatin
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Dec 10 07:33:44 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 10 Dec 2016 17:33:44 +1100
Subject: [R] sample train and test data using dplyr
In-Reply-To: <CADcgpJc9V1g_8Xjt_NQKmfcdnFWKge0Yy=LPTMARyKaH3zVNjA@mail.gmail.com>
References: <CADcgpJcYjyM+3KiEsbtB1pcrN_H+iGiAE7NBGO_kj3uMJXphPA@mail.gmail.com>
	<CAGxFJbSDyYLYhisfjGawM-WaQJF5=w=E4eRY1+c_MhEXpnFpBQ@mail.gmail.com>
	<CAKVAULNuvj2o1wDqNsxFRpZRvjsULMKv7ozB-=A5Mh_QY8KsWg@mail.gmail.com>
	<CADcgpJc9V1g_8Xjt_NQKmfcdnFWKge0Yy=LPTMARyKaH3zVNjA@mail.gmail.com>
Message-ID: <CA+8X3fV2eOK-OS78cvt6tdGWrMfS7+6MDXUE6p869qA5qU_JyQ@mail.gmail.com>

Sample without replacement and then split that sample into train and
test components.

Jim

On Fri, Dec 9, 2016 at 4:55 PM, Partha Sinha <pnsinha68 at gmail.com> wrote:
> How to get two sets of non overlapping data?
> Regards
> Parth


From tandaichuan at yahoo.com  Sat Dec 10 08:04:12 2016
From: tandaichuan at yahoo.com (Tan Dai Chuan)
Date: Sat, 10 Dec 2016 07:04:12 +0000 (UTC)
Subject: [R] Overlapping of arrow in PCA
References: <591052266.212849.1481353453109.ref@mail.yahoo.com>
Message-ID: <591052266.212849.1481353453109@mail.yahoo.com>

Hi, i face the problem as i attached in below. although i enlarge it, i still a straight and any solutions to solve it? Hope can get repsonse?this few days. It is urgent.?

Thank you so much.
Regards,Tan Dai Chuan
-------------- next part --------------
A non-text attachment was scrubbed...
Name: curcuma spme gcms biplot.pdf
Type: application/pdf
Size: 1935 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161210/d83ca448/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot (6).png
Type: image/png
Size: 130926 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161210/d83ca448/attachment.png>

From francesca.pancotto at gmail.com  Sat Dec 10 08:32:48 2016
From: francesca.pancotto at gmail.com (francesca Pancotto)
Date: Sat, 10 Dec 2016 08:32:48 +0100
Subject: [R] Organize regression output
Message-ID: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>

Dear Contributors

I would like to ask some help concerning the automatization process of an analysis, that sounds hard to my knowledge.
I have a list of regression models. 
I call them models=c(ra,rb,rc,rd,re,rf,rg,rh)

I can access the output of each of them using for example, for the first

ra$coefficients

and i obtain

(Intercept)       coeff1          coeff2            age      		gender  
 0.62003033  0.00350807 -0.03817848 -0.01513533 -0.18668972
and I know that ra$coefficients[1] would give me the intercept of this model.

What i need to do is to collect the coefficients of each regression in models, and calculate and place in a table, the following simple summation:


ra						rb	 						rc      ...

intercept					intercept					intercept
intercept+coeff1			intercept+coeff1			intercept+coeff1
intercept+coeff2			intercept+coeff2			intercept+coeff2
intercept+coeff1+coeff2		intercept+coeff1+coeff2		intercept+coeff1+coeff2


The calculations are trivial(I know how to do it in steps) but what is difficult for me is to invent a procedure that organizes the data in an efficient way.

I tried some step , starting with collecting the coefficients but i think I am going the wrong way

calcolati <- list()
for (i in c(ra,rb,rc,rd,re,rf,rg,rh))
{
  calcolati[[i]] <- i$coefficients[1]
}

Thanks for any help you can provide.

f.
----------------------------------
Francesca Pancotto
Web: https://sites.google.com/site/francescapancotto/ <https://sites.google.com/site/francescapancotto/>
Energie: 
http://www.energie.unimore.it/ <http://www.energie.unimore.it/>
----------------------------------


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sat Dec 10 10:49:29 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 10 Dec 2016 09:49:29 +0000
Subject: [R] Organize regression output
In-Reply-To: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>
References: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>
Message-ID: <563b68e4-9e35-cdd2-29f8-56f89e0f0f4e@dewey.myzen.co.uk>

Dear Francesca

i usually do this by collecting the models into a list not a vector

model <- list(ra = ra, rb = rb, and so on

and then I use lapply or sapply to process the model

lapply(mode, function(x) coef(x)[1])

or something like that, not tested

On 10/12/2016 07:32, francesca Pancotto wrote:
> Dear Contributors
>
> I would like to ask some help concerning the automatization process of an analysis, that sounds hard to my knowledge.
> I have a list of regression models.
> I call them models=c(ra,rb,rc,rd,re,rf,rg,rh)
>
> I can access the output of each of them using for example, for the first
>
> ra$coefficients
>
> and i obtain
>
> (Intercept)       coeff1          coeff2            age      		gender
>  0.62003033  0.00350807 -0.03817848 -0.01513533 -0.18668972
> and I know that ra$coefficients[1] would give me the intercept of this model.
>
> What i need to do is to collect the coefficients of each regression in models, and calculate and place in a table, the following simple summation:
>
>
> ra						rb	 						rc      ...
>
> intercept					intercept					intercept
> intercept+coeff1			intercept+coeff1			intercept+coeff1
> intercept+coeff2			intercept+coeff2			intercept+coeff2
> intercept+coeff1+coeff2		intercept+coeff1+coeff2		intercept+coeff1+coeff2
>
>
> The calculations are trivial(I know how to do it in steps) but what is difficult for me is to invent a procedure that organizes the data in an efficient way.
>
> I tried some step , starting with collecting the coefficients but i think I am going the wrong way
>
> calcolati <- list()
> for (i in c(ra,rb,rc,rd,re,rf,rg,rh))
> {
>   calcolati[[i]] <- i$coefficients[1]
> }
>
> Thanks for any help you can provide.
>
> f.
> ----------------------------------
> Francesca Pancotto
> Web: https://sites.google.com/site/francescapancotto/ <https://sites.google.com/site/francescapancotto/>
> Energie:
> http://www.energie.unimore.it/ <http://www.energie.unimore.it/>
> ----------------------------------
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bgunter.4567 at gmail.com  Sat Dec 10 12:57:21 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 10 Dec 2016 03:57:21 -0800
Subject: [R] Organize regression output
In-Reply-To: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>
References: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>
Message-ID: <CAGxFJbQCHCRQMJJWS5vG-1LWkV7-0Ea21GS2NTvoWKyGoLWZrw@mail.gmail.com>

Francesca:

It is hard to know what you might mean by "organize the results in an
efficient way." Some would say that a list of models already does this
for you.

The task you described is fairly simple, so I believe you would
benefit by going through an R tutorial or two to improve your R
programming skills. There are many good ones on the Web. That would
probably be a better long term strategy for you than posting basic
questions here.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 9, 2016 at 11:32 PM, francesca Pancotto
<francesca.pancotto at gmail.com> wrote:
> Dear Contributors
>
> I would like to ask some help concerning the automatization process of an analysis, that sounds hard to my knowledge.
> I have a list of regression models.
> I call them models=c(ra,rb,rc,rd,re,rf,rg,rh)
>
> I can access the output of each of them using for example, for the first
>
> ra$coefficients
>
> and i obtain
>
> (Intercept)       coeff1          coeff2            age                 gender
>  0.62003033  0.00350807 -0.03817848 -0.01513533 -0.18668972
> and I know that ra$coefficients[1] would give me the intercept of this model.
>
> What i need to do is to collect the coefficients of each regression in models, and calculate and place in a table, the following simple summation:
>
>
> ra                                              rb                                                      rc      ...
>
> intercept                                       intercept                                       intercept
> intercept+coeff1                        intercept+coeff1                        intercept+coeff1
> intercept+coeff2                        intercept+coeff2                        intercept+coeff2
> intercept+coeff1+coeff2         intercept+coeff1+coeff2         intercept+coeff1+coeff2
>
>
> The calculations are trivial(I know how to do it in steps) but what is difficult for me is to invent a procedure that organizes the data in an efficient way.
>
> I tried some step , starting with collecting the coefficients but i think I am going the wrong way
>
> calcolati <- list()
> for (i in c(ra,rb,rc,rd,re,rf,rg,rh))
> {
>   calcolati[[i]] <- i$coefficients[1]
> }
>
> Thanks for any help you can provide.
>
> f.
> ----------------------------------
> Francesca Pancotto
> Web: https://sites.google.com/site/francescapancotto/ <https://sites.google.com/site/francescapancotto/>
> Energie:
> http://www.energie.unimore.it/ <http://www.energie.unimore.it/>
> ----------------------------------
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Sat Dec 10 15:47:08 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Sat, 10 Dec 2016 15:47:08 +0100
Subject: [R] Error: XYZ is not an exported object
Message-ID: <CAAjnpdgeQQAW0+WO1B6g9dA2-S_GTGLh-2APFEg8O3MRc3TFBw@mail.gmail.com>

I am wrting a package and would like to be able to export it to access it with:

packagename::dataset

This is how my roxygen doc for the data object looks like:
#' Data frame with amino acid masses
#'
#' @name AminoAcids
#' @docType data
#' @keywords data
#' @export
NULL

It does end up in the namespace file with:
export(AminoAcids)

the data is in the data/ folder of the package.
and I can load it with data(AminoAcid)

Still R CMD build gives me the error:
Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'

because I am trying to access it with bibliospec::AminoAcids

Help highly appreciated.

Thank you

-- 
Witold Eryk Wolski


From wewolski at gmail.com  Sat Dec 10 16:13:01 2016
From: wewolski at gmail.com (Witold E Wolski)
Date: Sat, 10 Dec 2016 16:13:01 +0100
Subject: [R] See section 'Good practice' in '?data'.
Message-ID: <CAAjnpdgjJbNB2xOhPmwGaQYKyyjSG0LwWA0yX7-5WrL57xG5Kg@mail.gmail.com>

To which document
"See section 'Good practice' in '?data'."

refers too?


Found the following calls to data() loading into the global environment:
File 'bibliospec/R/annotateClass.R':
  data("AminoAcids")
See section 'Good practice' in '?data'.

Thanks


-- 
Witold Eryk Wolski


From bgunter.4567 at gmail.com  Sat Dec 10 16:25:14 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 10 Dec 2016 07:25:14 -0800
Subject: [R] Error: XYZ is not an exported object
In-Reply-To: <CAAjnpdgeQQAW0+WO1B6g9dA2-S_GTGLh-2APFEg8O3MRc3TFBw@mail.gmail.com>
References: <CAAjnpdgeQQAW0+WO1B6g9dA2-S_GTGLh-2APFEg8O3MRc3TFBw@mail.gmail.com>
Message-ID: <CAGxFJbSmBu9Ug6tKor4_OembBDVeNVhgwiiyCkis+BDR4C8prw@mail.gmail.com>

Please post this to the R-package-devel list, not here.


-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 10, 2016 at 6:47 AM, Witold E Wolski <wewolski at gmail.com> wrote:
> I am wrting a package and would like to be able to export it to access it with:
>
> packagename::dataset
>
> This is how my roxygen doc for the data object looks like:
> #' Data frame with amino acid masses
> #'
> #' @name AminoAcids
> #' @docType data
> #' @keywords data
> #' @export
> NULL
>
> It does end up in the namespace file with:
> export(AminoAcids)
>
> the data is in the data/ folder of the package.
> and I can load it with data(AminoAcid)
>
> Still R CMD build gives me the error:
> Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'
>
> because I am trying to access it with bibliospec::AminoAcids
>
> Help highly appreciated.
>
> Thank you
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Dec 10 16:34:13 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 10 Dec 2016 07:34:13 -0800
Subject: [R] See section 'Good practice' in '?data'.
In-Reply-To: <CAAjnpdgjJbNB2xOhPmwGaQYKyyjSG0LwWA0yX7-5WrL57xG5Kg@mail.gmail.com>
References: <CAAjnpdgjJbNB2xOhPmwGaQYKyyjSG0LwWA0yX7-5WrL57xG5Kg@mail.gmail.com>
Message-ID: <CB55163A-80EB-48A6-B104-06B4EE137EF1@dcn.davis.ca.us>

Type

?data

at the R console. 
-- 
Sent from my phone. Please excuse my brevity.

On December 10, 2016 7:13:01 AM PST, Witold E Wolski <wewolski at gmail.com> wrote:
>To which document
>"See section 'Good practice' in '?data'."
>
>refers too?
>
>
>Found the following calls to data() loading into the global
>environment:
>File 'bibliospec/R/annotateClass.R':
>  data("AminoAcids")
>See section 'Good practice' in '?data'.
>
>Thanks


From btupper at bigelow.org  Sat Dec 10 18:01:56 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Sat, 10 Dec 2016 12:01:56 -0500
Subject: [R] Error: XYZ is not an exported object
In-Reply-To: <CAGxFJbSmBu9Ug6tKor4_OembBDVeNVhgwiiyCkis+BDR4C8prw@mail.gmail.com>
References: <CAAjnpdgeQQAW0+WO1B6g9dA2-S_GTGLh-2APFEg8O3MRc3TFBw@mail.gmail.com>
	<CAGxFJbSmBu9Ug6tKor4_OembBDVeNVhgwiiyCkis+BDR4C8prw@mail.gmail.com>
Message-ID: <6F5F5982-EC8D-4C88-B5C9-D90DF42746D9@bigelow.org>

In addition to Bert's suggestion, you might want to check here...

http://r-pkgs.had.co.nz/man.html#man-data


> On Dec 10, 2016, at 10:25 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Please post this to the R-package-devel list, not here.
> 
> 
> -- Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sat, Dec 10, 2016 at 6:47 AM, Witold E Wolski <wewolski at gmail.com> wrote:
>> I am wrting a package and would like to be able to export it to access it with:
>> 
>> packagename::dataset
>> 
>> This is how my roxygen doc for the data object looks like:
>> #' Data frame with amino acid masses
>> #'
>> #' @name AminoAcids
>> #' @docType data
>> #' @keywords data
>> #' @export
>> NULL
>> 
>> It does end up in the namespace file with:
>> export(AminoAcids)
>> 
>> the data is in the data/ folder of the package.
>> and I can load it with data(AminoAcid)
>> 
>> Still R CMD build gives me the error:
>> Error : 'AminoAcids' is not an exported object from 'namespace:bibliospec'
>> 
>> because I am trying to access it with bibliospec::AminoAcids
>> 
>> Help highly appreciated.
>> 
>> Thank you
>> 
>> --
>> Witold Eryk Wolski
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From chrishold at psyctc.org  Sat Dec 10 22:57:57 2016
From: chrishold at psyctc.org (Chris Evans)
Date: Sat, 10 Dec 2016 21:57:57 +0000 (GMT)
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
In-Reply-To: <69822CFB-446F-4C23-A814-4442D59FB65A@dcn.davis.ca.us>
References: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
	<CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>
	<571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>
	<69822CFB-446F-4C23-A814-4442D59FB65A@dcn.davis.ca.us>
Message-ID: <615002926.18502448.1481407077488.JavaMail.zimbra@psyctc.org>

Thanks to both Jeff and Ista for your inputs some days back.  I confess I was _indeed_ too tired to be thinking well and laterally, and even to be copying things into Emails successfully.

I have since had more sleep (!) and I have read ?`[[`, gone back to the pertinent parts of "Introduction to R" and generally pondered all this.  I confess I had always avoided [[ and only ever used it for lists that were not data frames.  I can now see just how badly I was misguessing its behaviour: apologies, I should have realised that I needed to go right back to basics.

I _can_ see that there are things in the behaviour of data frames that are not that obvious but I had become very used to them.  I can see values in converting to using tibbles instead of data frames and may try to do that.

However, I think the documentation for tibble would be improved for people like myself if it started with something that made it even clearer that tibbles are lists, just as data frames are, but that whereas a data frame has a single class(df) of "data.frame", class(tibble) is:
c("tbl_df","tbl","data.frame").

I can now see that what I get from ?tibble, i.e. "tibble is a trimmed down version of data.frame" is probably technically true though I'd describe it as a rationalised or even a beefed up version of data.frame.  I can also now see that what I find in https://cran.r-project.org/web/packages/tibble/tibble.pdf:

"[ Never simplifies (drops), so always returns data.frame"

is true, but only to the extent that any tibble is still a data.frame but with "data.frame" moved to the third position in the classes of the tibble where it would be the first and only class were it a pure data.frame.  I can also see now that that is not really inconsistent with what I get in https://github.com/tidyverse/tibble:

"Tibbles also clearly delineate [ and [[: [ always returns another tibble, [[ always returns a vector. No more drop = FALSE!"

However, I think it would be better if the tibble.pdf document said:

"[ Never simplifies (drops), so always returns tibble" even though "[ Never simplifies (drops), so always returns data.frame" is technically true, up to and including passing is.data.frame() as 

Finally, I think I can see that if want various functions I have written that worked fine on data frames, but which depended on indexing or subsetting those data frames using [,i] or sometimes [,i:j]to select vectors or matrices, then I will have to modify them so they test whether the input is a simple data frame or a data frame that is also a tibble.  I guess that I could have trapped things had my functions (where appropriate) had an is.numeric() input check ... and that I have to use an is.tibble() check, not an is.data.frame() check to distinguish the two!

Ah well, even after years of part-time use of R, I guess it's been good for my soul and my deeper and wider understanding of R to go right back to the basics.

Thanks again to you both.  I am posting here to convey thanks and in case this is useful to anyone like myself who benefits from a bit more narrative than is usually offered by R definitions and help entries.

Chris


----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: "Chris Evans" <chrishold at psyctc.org>, "r-helpr-project.org" <r-help at r-project.org>
> Sent: Tuesday, 6 December, 2016 23:23:28
> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a tibble

> You really need sleep. Then you need to read
> 
> ?`[[`
> 
> and in particular read about the second argument to the `[[` function, since you
> don't seem to understand what it is for. Maybe reread the Introduction to R
> document that comes with R.
> 
> The simplest solution is to treat `[[` as supporting one index and `[` as
> supporting either one or two.
> 
> As for expecting any form of row indexing of data frames or tibbles to return a
> vector, that is hopeless because each column can have a different type.  dta[
> 1, ] returns exactly what it has to return to avoid losing fidelity. If you
> really need row indexing to return a vector you should be using a matrix.
> --
> Sent from my phone. Please excuse my brevity.
> 
> On December 6, 2016 2:10:15 PM PST, Chris Evans <chrishold at psyctc.org> wrote:
>>{{SIGH}}
>>
>>You are absolutely right.
>>
>>I wonder if I am losing some cognitive capacities that are needed to be
>>part of the evolving R community. It seems to me that if a tibble is
>>designed to be an enhanced replacement for a dataframe then it
>>shouldn't quite so radically change things.
>>
>>I notice that the documentation on tibble says "[ Never simplifies
>>(drops), so always returns data.frame"
>>That is much less explicit than I would have liked and actually doesn't
>>seem to be true. In fact, as you rightly say, it generally, but not
>>quite always, returns a tibble. In fact it can be fooled into a vector
>>of length 1.
>>
>>> tmpTibble[[1,]]
>>Error in `[[.data.frame`(tmpTibble, 1, ) :
>>argument "..2" is missing, with no default
>>
>>> tmpTibble[1]
>># A tibble: 26 ? 1
>>ID
>><chr>
>>1 a
>>2 b
>>3 c
>>4 d
>>5 e
>>6 f
>>7 g
>>8 h
>>9 i
>>10 j
>># ... with 16 more rows
>>> tmpTibble[,1]
>># A tibble: 26 ? 1
>>ID
>><chr>
>>1 a
>>2 b
>>3 c
>>4 d
>>5 e
>>6 f
>>7 g
>>8 h
>>9 i
>>10 j
>># ... with 16 more rows
>>> tmpTibble[1,]
>>Error in `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a",
>>:
>>replacement element 3 is a matrix/data frame of 26 rows, need 1
>>In addition: Warning messages:
>>1: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
>>replacement element 1 has 26 rows to replace 1 rows
>>2: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
>>replacement element 2 has 26 rows to replace 1 rows
>>> tmpTibble[1,1:26]
>>Error: Invalid column indexes: 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
>>15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26
>>> tmpTibble[[1,2]]
>>[1] 1
>>> str(tmpTibble[[1,2]])
>>int 1
>>> str(tmpTibble[[1:2,2]])
>>Error in col[[i, exact = exact]] :
>>attempt to select more than one element in vectorIndex
>>> 
>>> tmpTibble[[1,1:2]]
>>[1] "b"
>>> 
>>
>>So [[a,b]] works if a and b are legal with the dimensions of the tibble
>>and if a is of length 1 but returns NOT a tibble but a vector of length
>>1 (I think), I can see that's logical but not what it says in the
>>documentation.
>>
>>[[a]] and [[,a]] return the same result, that seems excessively
>>tolerant to me.
>>
>>[[a,b:c]] actually returns [[a,c]] and again as a single value, NOT a
>>tibble.
>>
>>And row subsetting/indexing has gone.
>>
>>Why create replacement for a dataframe that has no row indexing and so
>>radically redefines column indexing, in fact redefines the whole of
>>indexing and subsetting?
>>
>>OK. I will go to sleep now and hope to feel less dumb(ed) when I wake.
>>Perhaps Prof. Wickham or someone can spell out a bit less tersely, and
>>I think incompletely, than the tibble documentation does, why all this
>>is good.
>>
>>Thanks anyway Ista, you certainly hit the issue!
>>
>>Very best all,
>>
>>Chris
>>
>>> From: "Ista Zahn" <istazahn at gmail.com>
>>> To: "Chris Evans" <chrishold at psyctc.org>
>>> Cc: "r-helpr-project.org" <r-help at r-project.org>
>>> Sent: Tuesday, 6 December, 2016 21:40:41
>>> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a
>>tibble
>>
>>> Not at a computer to check right now, but I believe single bracket
>>indexing a
>>> tibble always returns a tibble. To extract a vector use [[
>>
>>> On Dec 6, 2016 4:28 PM, "Chris Evans" < chrishold at psyctc.org > wrote:
>>
>>>> I hope I am obeying the list rules here. I am using a raw R IDE for
>>this and
>>> > running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)
>>
>>> > Here is a reproducible example. Code only first
>>
>>> > require(tibble)
>>> > tmpTibble <- tibble(ID=letters,num=1:26)
>>> > min(tmpTibble[,2]) # fine
>>> > max(tmpTibble[,2]) # fine
>>> > median(tmpTibble[,2]) # not fine
>>> > mean(tmpTibble[,2]) # not fine
>>
>>> I think you want
>>
>>> mean(tmpTibble[[2]]
>>
>>> > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>>> > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be
>>necessary?!
>>> > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>>> > newMedianFun(tmpTibble[,2]) # ditto
>>> > str(tmpTibble[,2])
>>
>>> > ### then I tried this to make sure it wasn't about having fed in
>>integers
>>
>>> > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>>> > tmpTibble2
>>> > mean(tmpTibble2[,3]) # not fine, not about integers!
>>
>>
>>>> ### before I just created tmpTibble2 I found myself trying to add a
>>column to
>>> > tmpTibble
>>> > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>>> > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>>> > ### and oddly enough ...
>>> > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>>
>>> > Now here it is with the output:
>>
>>> > > require(tibble)
>>> > Loading required package: tibble
>>> > > tmpTibble <- tibble(ID=letters,num=1:26)
>>> > > min(tmpTibble[,2]) # fine
>>> > [1] 1
>>> > > max(tmpTibble[,2]) # fine
>>> > [1] 26
>>> > > median(tmpTibble[,2]) # not fine
>>> > Error in median.default(tmpTibble[, 2]) : need numeric data
>>> > > mean(tmpTibble[,2]) # not fine
>>> > [1] NA
>>> > Warning message:
>>> > In mean.default(tmpTibble[, 2]) :
>>> > argument is not numeric or logical: returning NA
>>> > > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>>> > > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't
>>be necessary?!
>>> > [1] 13.5
>>> > > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>>> > > newMedianFun(tmpTibble[,2]) # ditto
>>> > [1] 13.5
>>> > > str(tmpTibble[,2])
>>> > Classes ?tbl_df?, ?tbl? and 'data.frame': 26 obs. of 1 variable:
>>> > $ num: int 1 2 3 4 5 6 7 8 9 10 ...
>>
>>> > > ### then I tried this to make sure it wasn't about having fed in
>>integers
>>
>>> > > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>>> > > tmpTibble2
>>> > # A tibble: 26 ? 3
>>> > ID num num2
>>> > <chr> <int> <dbl>
>>> > 1 a 1 0.1
>>> > 2 b 2 0.2
>>> > 3 c 3 0.3
>>> > 4 d 4 0.4
>>> > 5 e 5 0.5
>>> > 6 f 6 0.6
>>> > 7 g 7 0.7
>>> > 8 h 8 0.8
>>> > 9 i 9 0.9
>>> > 10 j 10 1.0
>>> > # ... with 16 more rows
>>> > > mean(tmpTibble2[,3]) # not fine, not about integers!
>>> > [1] NA
>>> > Warning message:
>>> > In mean.default(tmpTibble2[, 3]) :
>>> > argument is not numeric or logical: returning NA
>>
>>
>>>> > ### before I just created tmpTibble2 I found myself trying to add
>>a column to
>>> > > tmpTibble
>>> > > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>>> > > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>>> > > ### and oddly enough ...
>>> > > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>>> > Error: Each variable must be a 1d atomic vector or list.
>>> > Problem variables: 'newNum'
>>
>>
>>
>>>> I discovered this when I hit odd behaviour after using read_spss()
>>from the
>>>> haven package for the first time as it seemed to be offering a step
>>forward
>>>> over good old read.spss() from the excellent foreign package. I am
>>reporting it
>>>> here not directly to Prof. Wickham as the issues seem rather general
>>though I'm
>>>> guessing that it needs to be fixed with a fix to tibble. Or perhaps
>>I've
>>> > completely missed something.
>>
>>> > TIA,
>>
>>> > Chris
>>
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Dec 10 23:27:34 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 10 Dec 2016 17:27:34 -0500
Subject: [R] See section 'Good practice' in '?data'.
In-Reply-To: <CAAjnpdgjJbNB2xOhPmwGaQYKyyjSG0LwWA0yX7-5WrL57xG5Kg@mail.gmail.com>
References: <CAAjnpdgjJbNB2xOhPmwGaQYKyyjSG0LwWA0yX7-5WrL57xG5Kg@mail.gmail.com>
Message-ID: <1f9dde33-afd6-ab7d-fed4-729c1c0f7595@gmail.com>

On 10/12/2016 10:13 AM, Witold E Wolski wrote:
> To which document
> "See section 'Good practice' in '?data'."
>
> refers too?

It refers to the help page for the data() function, which you see by 
typing ?data in the console.

Duncan Murdoch

>
>
> Found the following calls to data() loading into the global environment:
> File 'bibliospec/R/annotateClass.R':
>   data("AminoAcids")
> See section 'Good practice' in '?data'.
>
> Thanks
>
>


From istazahn at gmail.com  Sun Dec 11 03:02:40 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 10 Dec 2016 21:02:40 -0500
Subject: [R] Odd behaviour of mean() with a numeric column in a tibble
In-Reply-To: <615002926.18502448.1481407077488.JavaMail.zimbra@psyctc.org>
References: <882491819.17289207.1481059589302.JavaMail.zimbra@psyctc.org>
	<CA+vqiLHFean8qjpw97j5DK=fJQHpmZCRhw-whzuL6mCoVZaZ=A@mail.gmail.com>
	<571072458.17297777.1481062215412.JavaMail.zimbra@psyctc.org>
	<69822CFB-446F-4C23-A814-4442D59FB65A@dcn.davis.ca.us>
	<615002926.18502448.1481407077488.JavaMail.zimbra@psyctc.org>
Message-ID: <CA+vqiLFhrR7cremybpjOkmJSuUJYQ=NQuU5A08rTvWSWFs31Hg@mail.gmail.com>

On Dec 10, 2016 4:59 PM, "Chris Evans" <chrishold at psyctc.org> wrote:

Thanks to both Jeff and Ista for your inputs some days back.  I confess I
was _indeed_ too tired to be thinking well and laterally, and even to be
copying things into Emails successfully.

I have since had more sleep (!) and I have read ?`[[`, gone back to the
pertinent parts of "Introduction to R" and generally pondered all this.  I
confess I had always avoided [[ and only ever used it for lists that were
not data frames.  I can now see just how badly I was misguessing its
behaviour: apologies, I should have realised that I needed to go right back
to basics.

I _can_ see that there are things in the behaviour of data frames that are
not that obvious but I had become very used to them.  I can see values in
converting to using tibbles instead of data frames and may try to do that.

However, I think the documentation for tibble would be improved for people
like myself if it started with something that made it even clearer that
tibbles are lists, just as data frames are, but that whereas a data frame
has a single class(df) of "data.frame", class(tibble) is:
c("tbl_df","tbl","data.frame").

I can now see that what I get from ?tibble, i.e. "tibble is a trimmed down
version of data.frame" is probably technically true though I'd describe it
as a rationalised or even a beefed up version of data.frame.  I can also
now see that what I find in https://cran.r-project.org/
web/packages/tibble/tibble.pdf:

"[ Never simplifies (drops), so always returns data.frame"

is true, but only to the extent that any tibble is still a data.frame but
with "data.frame" moved to the third position in the classes of the tibble
where it would be the first and only class were it a pure data.frame.  I
can also see now that that is not really inconsistent with what I get in
https://github.com/tidyverse/tibble:

"Tibbles also clearly delineate [ and [[: [ always returns another tibble,
[[ always returns a vector. No more drop = FALSE!"

However, I think it would be better if the tibble.pdf document said:

"[ Never simplifies (drops), so always returns tibble" even though "[ Never
simplifies (drops), so always returns data.frame" is technically true, up
to and including passing is.data.frame() as

Finally, I think I can see that if want various functions I have written
that worked fine on data frames, but which depended on indexing or
subsetting those data frames using [,i] or sometimes [,i:j]to select
vectors or matrices, then I will have to modify them so they test whether
the input is a simple data frame or a data frame that is also a tibble.


only if you relied on [.data.frame returning a vector for length-one j.
Just use [[ (or always pass a drop argument) for that case and your
indexing code will work the same on pure data.frames and tbl_dfs.

--Ista

  I guess that I could have trapped things had my functions (where
appropriate) had an is.numeric() input check ... and that I have to use an
is.tibble() check, not an is.data.frame() check to distinguish the two!


Ah well, even after years of part-time use of R, I guess it's been good for
my soul and my deeper and wider understanding of R to go right back to the
basics.

Thanks again to you both.  I am posting here to convey thanks and in case
this is useful to anyone like myself who benefits from a bit more narrative
than is usually offered by R definitions and help entries.

Chris


----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: "Chris Evans" <chrishold at psyctc.org>, "r-helpr-project.org" <
r-help at r-project.org>
> Sent: Tuesday, 6 December, 2016 23:23:28
> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a tibble

> You really need sleep. Then you need to read
>
> ?`[[`
>
> and in particular read about the second argument to the `[[` function,
since you
> don't seem to understand what it is for. Maybe reread the Introduction to
R
> document that comes with R.
>
> The simplest solution is to treat `[[` as supporting one index and `[` as
> supporting either one or two.
>
> As for expecting any form of row indexing of data frames or tibbles to
return a
> vector, that is hopeless because each column can have a different type.
dta[
> 1, ] returns exactly what it has to return to avoid losing fidelity. If
you
> really need row indexing to return a vector you should be using a matrix.
> --
> Sent from my phone. Please excuse my brevity.
>
> On December 6, 2016 2:10:15 PM PST, Chris Evans <chrishold at psyctc.org>
wrote:
>>{{SIGH}}
>>
>>You are absolutely right.
>>
>>I wonder if I am losing some cognitive capacities that are needed to be
>>part of the evolving R community. It seems to me that if a tibble is
>>designed to be an enhanced replacement for a dataframe then it
>>shouldn't quite so radically change things.
>>
>>I notice that the documentation on tibble says "[ Never simplifies
>>(drops), so always returns data.frame"
>>That is much less explicit than I would have liked and actually doesn't
>>seem to be true. In fact, as you rightly say, it generally, but not
>>quite always, returns a tibble. In fact it can be fooled into a vector
>>of length 1.
>>
>>> tmpTibble[[1,]]
>>Error in `[[.data.frame`(tmpTibble, 1, ) :
>>argument "..2" is missing, with no default
>>
>>> tmpTibble[1]
>># A tibble: 26 ? 1
>>ID
>><chr>
>>1 a
>>2 b
>>3 c
>>4 d
>>5 e
>>6 f
>>7 g
>>8 h
>>9 i
>>10 j
>># ... with 16 more rows
>>> tmpTibble[,1]
>># A tibble: 26 ? 1
>>ID
>><chr>
>>1 a
>>2 b
>>3 c
>>4 d
>>5 e
>>6 f
>>7 g
>>8 h
>>9 i
>>10 j
>># ... with 16 more rows
>>> tmpTibble[1,]
>>Error in `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a",
>>:
>>replacement element 3 is a matrix/data frame of 26 rows, need 1
>>In addition: Warning messages:
>>1: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
>>replacement element 1 has 26 rows to replace 1 rows
>>2: In `[<-.data.frame`(`*tmp*`, , value = list(ID = c("a", "a", "a", :
>>replacement element 2 has 26 rows to replace 1 rows
>>> tmpTibble[1,1:26]
>>Error: Invalid column indexes: 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,
>>15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26
>>> tmpTibble[[1,2]]
>>[1] 1
>>> str(tmpTibble[[1,2]])
>>int 1
>>> str(tmpTibble[[1:2,2]])
>>Error in col[[i, exact = exact]] :
>>attempt to select more than one element in vectorIndex
>>>
>>> tmpTibble[[1,1:2]]
>>[1] "b"
>>>
>>
>>So [[a,b]] works if a and b are legal with the dimensions of the tibble
>>and if a is of length 1 but returns NOT a tibble but a vector of length
>>1 (I think), I can see that's logical but not what it says in the
>>documentation.
>>
>>[[a]] and [[,a]] return the same result, that seems excessively
>>tolerant to me.
>>
>>[[a,b:c]] actually returns [[a,c]] and again as a single value, NOT a
>>tibble.
>>
>>And row subsetting/indexing has gone.
>>
>>Why create replacement for a dataframe that has no row indexing and so
>>radically redefines column indexing, in fact redefines the whole of
>>indexing and subsetting?
>>
>>OK. I will go to sleep now and hope to feel less dumb(ed) when I wake.
>>Perhaps Prof. Wickham or someone can spell out a bit less tersely, and
>>I think incompletely, than the tibble documentation does, why all this
>>is good.
>>
>>Thanks anyway Ista, you certainly hit the issue!
>>
>>Very best all,
>>
>>Chris
>>
>>> From: "Ista Zahn" <istazahn at gmail.com>
>>> To: "Chris Evans" <chrishold at psyctc.org>
>>> Cc: "r-helpr-project.org" <r-help at r-project.org>
>>> Sent: Tuesday, 6 December, 2016 21:40:41
>>> Subject: Re: [R] Odd behaviour of mean() with a numeric column in a
>>tibble
>>
>>> Not at a computer to check right now, but I believe single bracket
>>indexing a
>>> tibble always returns a tibble. To extract a vector use [[
>>
>>> On Dec 6, 2016 4:28 PM, "Chris Evans" < chrishold at psyctc.org > wrote:
>>
>>>> I hope I am obeying the list rules here. I am using a raw R IDE for
>>this and
>>> > running 3.3.2 (2016-10-31) on x86_64-w64-mingw32/x64 (64-bit)
>>
>>> > Here is a reproducible example. Code only first
>>
>>> > require(tibble)
>>> > tmpTibble <- tibble(ID=letters,num=1:26)
>>> > min(tmpTibble[,2]) # fine
>>> > max(tmpTibble[,2]) # fine
>>> > median(tmpTibble[,2]) # not fine
>>> > mean(tmpTibble[,2]) # not fine
>>
>>> I think you want
>>
>>> mean(tmpTibble[[2]]
>>
>>> > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>>> > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't be
>>necessary?!
>>> > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>>> > newMedianFun(tmpTibble[,2]) # ditto
>>> > str(tmpTibble[,2])
>>
>>> > ### then I tried this to make sure it wasn't about having fed in
>>integers
>>
>>> > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>>> > tmpTibble2
>>> > mean(tmpTibble2[,3]) # not fine, not about integers!
>>
>>
>>>> ### before I just created tmpTibble2 I found myself trying to add a
>>column to
>>> > tmpTibble
>>> > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>>> > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>>> > ### and oddly enough ...
>>> > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>>
>>> > Now here it is with the output:
>>
>>> > > require(tibble)
>>> > Loading required package: tibble
>>> > > tmpTibble <- tibble(ID=letters,num=1:26)
>>> > > min(tmpTibble[,2]) # fine
>>> > [1] 1
>>> > > max(tmpTibble[,2]) # fine
>>> > [1] 26
>>> > > median(tmpTibble[,2]) # not fine
>>> > Error in median.default(tmpTibble[, 2]) : need numeric data
>>> > > mean(tmpTibble[,2]) # not fine
>>> > [1] NA
>>> > Warning message:
>>> > In mean.default(tmpTibble[, 2]) :
>>> > argument is not numeric or logical: returning NA
>>> > > newMeanFun <- function(x) {mean(as.numeric(unlist(x)))}
>>> > > newMeanFun(tmpTibble[,2]) # solved problem but surely shouldn't
>>be necessary?!
>>> > [1] 13.5
>>> > > newMedianFun <- function(x) {median(as.numeric(unlist(x)))}
>>> > > newMedianFun(tmpTibble[,2]) # ditto
>>> > [1] 13.5
>>> > > str(tmpTibble[,2])
>>> > Classes ?tbl_df?, ?tbl? and 'data.frame': 26 obs. of 1 variable:
>>> > $ num: int 1 2 3 4 5 6 7 8 9 10 ...
>>
>>> > > ### then I tried this to make sure it wasn't about having fed in
>>integers
>>
>>> > > tmpTibble2 <- tibble(ID=letters,num=1:26,num2=(1:26)/10)
>>> > > tmpTibble2
>>> > # A tibble: 26 ? 3
>>> > ID num num2
>>> > <chr> <int> <dbl>
>>> > 1 a 1 0.1
>>> > 2 b 2 0.2
>>> > 3 c 3 0.3
>>> > 4 d 4 0.4
>>> > 5 e 5 0.5
>>> > 6 f 6 0.6
>>> > 7 g 7 0.7
>>> > 8 h 8 0.8
>>> > 9 i 9 0.9
>>> > 10 j 10 1.0
>>> > # ... with 16 more rows
>>> > > mean(tmpTibble2[,3]) # not fine, not about integers!
>>> > [1] NA
>>> > Warning message:
>>> > In mean.default(tmpTibble2[, 3]) :
>>> > argument is not numeric or logical: returning NA
>>
>>
>>>> > ### before I just created tmpTibble2 I found myself trying to add
>>a column to
>>> > > tmpTibble
>>> > > tmpTibble$newNum <- tmpTibble[,2]/10 # NO!
>>> > > tmpTibble[["newNum"]] <- tmpTibble[,2]/10 # NO!
>>> > > ### and oddly enough ...
>>> > > add_column(tmpTibble,newNum = tmpTibble[,2]/10) # NO!
>>> > Error: Each variable must be a 1d atomic vector or list.
>>> > Problem variables: 'newNum'
>>
>>
>>
>>>> I discovered this when I hit odd behaviour after using read_spss()
>>from the
>>>> haven package for the first time as it seemed to be offering a step
>>forward
>>>> over good old read.spss() from the excellent foreign package. I am
>>reporting it
>>>> here not directly to Prof. Wickham as the issues seem rather general
>>though I'm
>>>> guessing that it needs to be fixed with a fix to tibble. Or perhaps
>>I've
>>> > completely missed something.
>>
>>> > TIA,
>>
>>> > Chris
>>
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>      [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From qwertyui_period at yahoo.co.jp  Sun Dec 11 05:49:25 2016
From: qwertyui_period at yahoo.co.jp (qwertyui_period at yahoo.co.jp)
Date: Sun, 11 Dec 2016 13:49:25 +0900 (JST)
Subject: [R] Question about proxy setting of R
In-Reply-To: <CAB+PZ6AmuTeu_iU9V8odYNk+GA+2Y6beAuwQ3o8e38+U+gJmfQ@mail.gmail.com>
References: <669742.77077.qm@web102318.mail.kks.yahoo.co.jp>
	<CAAxdm-7jKMHe+MEr=hQnzyvn3xAq5Y+XAPCiiTMZraJvutvAPQ@mail.gmail.com>
	<590798.91297.qm@web102317.mail.kks.yahoo.co.jp>
	<CAAxdm-5C_bfe9bdn0ZK9J34WKJ0kG+9E5Oh6hN_XSstV5FER_A@mail.gmail.com>
	<CAB+PZ6AmuTeu_iU9V8odYNk+GA+2Y6beAuwQ3o8e38+U+gJmfQ@mail.gmail.com>
Message-ID: <807698.66668.qm@web102301.mail.kks.yahoo.co.jp>

Dear, Carina

Thanks for your adivice.

It worked finally as below:

Sys.setenv(http_proxy="http://proxyserver:port")
options(repos="http://cloud.r-project.org/")
options(download.file.method="internal")

J J


----- Original Message -----
>From: Carina Salt <carina.salt at googlemail.com>
>To: jim holtman <jholtman at gmail.com> 
>Cc: qwertyui_period at yahoo.co.jp; "r-help at r-project.org" <r-help at r-project.org>
>Date: 2016/12/5, Mon 22:18
>Subject: Re: [R] Question about proxy setting of R
>  
>
>As far as I can see, the 'internal' method doesn't work for https mirrors (on my system, anyway).? However, the http mirrors still exist (try "http://cloud.r-project.org/" for example) so why not just use one of those?
>
>
>Cheers,
>Carina
>
>
>On 5 December 2016 at 12:27, jim holtman <jholtman at gmail.com> wrote:
>
>You will probably have to check with your network folks to see what is
>>possible on your system.
>>
>>
>>Jim Holtman
>>Data Munger Guru
>>
>>What is the problem that you are trying to solve?
>>Tell me what you want to do, not how you want to do it.
>>
>>On Mon, Dec 5, 2016 at 6:33 AM, <qwertyui_period at yahoo.co.jp> wrote:
>>
>>> Dear Jim,
>>>
>>> Thanks to your advice, "Proxy Authentification" window showed up, however,
>>> I couldn't access to the internet. Error messages are as below.
>>>
>>> ------------------------------ ------------------------------ -------
>>> > update.packages(ask='graphics' ,checkBuilt=TRUE)
>>> --- Please select a CRAN mirror for use in this session ---
>>> Warning: failed to download mirrors file (scheme not supported in URL
>>> 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
>>> 'C:/PROGRA~1/R/R-33~1.2/doc/ CRAN_mirrors.csv'
>>> Warning: unable to access index for repository
>>> https://cran.ism.ac.jp/src/contrib:
>>>? ?scheme not supported in URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES'
>>>
>>> Proxy authentication failed:
>>>? ? ? ? ?please re-enter the credentials or hit Cancel
>>> ------------------------------ ------------------------------ -------
>>>
>>> I assume the proxy server is only available for "http", not "https".
>>> What should I do ?
>>>
>>> J J
>>>
>>>
>>> ----- Original Message -----
>>> *From:* jim holtman <jholtman at gmail.com>
>>> *To:* qwertyui_period at yahoo.co.jp
>>> *Date:* 2016/12/2, Fri 09:13
>>> *Subject:* Re: [R] Question about proxy setting of R
>>>
>>> Try this option:
>>>
>>>? options(download.file.method = "internal")
>>>
>>>
>>>
>>>
>>>
>>> Jim Holtman
>>> Data Munger Guru
>>>
>>> What is the problem that you are trying to solve?
>>> Tell me what you want to do, not how you want to do it.
>>>
>>> On Wed, Nov 30, 2016 at 10:37 PM, <qwertyui_period at yahoo.co.jp> wrote:
>>>
>>> Hello,
>>>
>>> I use R 3.0.2 on Win 7 through proxy server using ".Rprofile" in home
>>> directory that includes "Sys.setenv(http_proxy=proxy_ server:port)".
>>> There has been no problem to access the internet for some years.
>>> In this situation, I installed R 3.3.1 and then entered "update.packages
>>> ()", however, "Proxy Authentification" window didn't show up and
>>> failed to access the internet. Error messages are as below.
>>>
>>> ------------------------------ ------------------------------ -------
>>> > update.packages(ask='graphics' ,checkBuilt=TRUE)
>>> --- Please select a CRAN mirror for use in this session ---
>>> Warning: failed to download mirrors file (cannot open URL
>>> 'https://cran.r-project.org/CRAN_mirrors.csv'); using local file
>>> 'C:/PROGRA~1/R/R-33~1.2/doc/ CRAN_mirrors.csv'
>>> Warning: unable to access index for repository
>>> https://cran.ism.ac.jp/src/contrib:
>>>? ?cannot open URL 'https://cran.ism.ac.jp/src/contrib/PACKAGES'
>>> Warning: unable to access index for repository
>>> http://www.stats.ox.ac.uk/pub/RWin/src/contrib:
>>>? ?cannot open URL 'http://www.stats.ox.ac.uk/pub/RWin/src/contrib/PACKAGES
>>> '
>>> Warning message:
>>> In download.file(url, destfile = f, quiet = TRUE) :
>>>? ?cannot open URL 'https://cran.r-project.org/CRAN_mirrors.csv': HTTP
>>> status was '407 Proxy Authentication Required'
>>>
>>> ------------------------------ ------------------------------ -------
>>>
>>> Strange to say, R 3.0.2 is able to access to the internet, and R 3.3.1
>>> shows collect proxy setting in ".Rprofile"? by "Sys.getenv("http_proxy")"
>>> From internet information, I added "http_proxy_user=ask" to ".Rprofile", or
>>> " --internet2" to the desktop icon of R 3.3.1, ending up in the same
>>> result.
>>>
>>> Please show me the way of proxy setting of R 3.3.1.
>>>
>>> ______________________________ ________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.r-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>>
>>
>>? ? ? ? [[alternative HTML version deleted]]
>>
>>______________________________ ________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.r-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
> 
>
>   
	[[alternative HTML version deleted]]


From marlin- at gmx.cn  Sun Dec 11 04:18:25 2016
From: marlin- at gmx.cn (Marlin JL.M)
Date: Sun, 11 Dec 2016 11:18:25 +0800
Subject: [R] Assign a list to one column of data frame
Message-ID: <1481426305.14714.2.camel@gmx.cn>

Dear all,

I want to assign a list to one column of data.frame where the name of the column
is a variable. I tried the following:

Using R version 3.3.2

> df <- iris[1:3, ]
> df
# Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1          5.1         3.5          1.4         0.2  setosa
# 2          4.9         3.0          1.4         0.2  setosa
# 3          4.7         3.2          1.3         0.2  setosa

> mylist <- list(c(1,2,3),c(1),c())
> mylist
# [[1]]
# [1] 1 2 3
# 
# [[2]]
# [1] 1
# 
# [[3]]
# NULL

> n1 <- 'new1'
> df$n1 <- mylist

> n2 <- 'new2'
> df[,n2] <- mylist
# Warning message:
# In `[<-.data.frame`(`*tmp*`, , "new4", value = list(c(1, 2, 3),  :
# provided 3 variables to replace 1 variables

> n3 <- 'new3'
> df[,n3] <- I(mylist)
# Warning message:
# In `[<-.data.frame`(`*tmp*`, , "new3", value = list(c(1, 2, 3),  :
# provided 3 variables to replace 1 variables

> eval(parse(text = paste0("df$","new4","<- mylist")))

> df
# Sepal.Length Sepal.Width Petal.Length Petal.Width Species      n1 new2 new3    new4
# 1          5.1         3.5          1.4         0.2  setosa 1, 2, 3    1    1 1, 2, 3
# 2          4.9         3.0          1.4         0.2  setosa       1    2    2       1
# 3          4.7         3.2          1.3         0.2  setosa    NULL    3    3    NULL


The "eval" works correctly, however, if I want to avoid using "eval", what
should I do?

Thanks!


From frederik at ofb.net  Sun Dec 11 07:24:49 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sat, 10 Dec 2016 22:24:49 -0800
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
Message-ID: <20161211062449.GA20109@ofb.net>

Dear R-Help,

I asked this question on StackOverflow,

http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex

but thought perhaps R-help would be more appropriate.

I want to write a function in R which grabs the name of a variable
from the context of its caller's caller. I think the problem I have is
best understood by asking how to compose `deparse` and `substitute`.
You can see that a naive composition does not work:

    # a compose operator
    >  `%c%` = function(x,y)function(...)x(y(...))

    # a naive attempt to combine deparse and substitute
    > desub = deparse %c% substitute
    > f=function(foo) { message(desub(foo)) }
    > f(log)
    foo

    # this is how it is supposed to work
    > g=function(foo) { message(deparse(substitute(foo))) }
    > g(log)
    log

Is there a way I can define a function `desub` so that `desub(x)` has
the same value as `deparse(substitute(x))` in every context?

Thank you,

Frederick Eaton


From fsbmat at gmail.com  Sat Dec 10 20:01:12 2016
From: fsbmat at gmail.com (Fernando de Souza Bastos)
Date: Sat, 10 Dec 2016 17:01:12 -0200
Subject: [R] Function implemented in R returns the wrong value
Message-ID: <CAPTmxS1TkQx1F5=ztyp=EWvAPR4XxDtDHcgdyyJmzW7RW=S8Kw@mail.gmail.com>

The Log.lik function below returns the value '-INF' when it should return
the value -5836.219. I can not figure out the error, does anyone have any
suggestions?

    rm(list=ls())
    library(ssmrob)
    data(MEPS2001)
    attach(MEPS2001)
    n<-nrow(MEPS2001)
    Log.lik <- function(par,X,W,y){
      n <- length(y)
      beta <- par[1:(ncol(X)+1)]
      gamma <- par[(ncol(X)+2):(ncol(X)+ncol(W)+2)]
      mu1 <- model.matrix(~X)%*%beta
      mu2 <- model.matrix(~W)%*%gamma
      sigma <- par[(ncol(X)+ncol(W)+3)]
      rho <- par[(ncol(X)+ncol(W)+4)]
      term0 <- (y-mu1)/sigma
      term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
      Phi_mu2 <- pnorm(mu2)
      phi_t0 <- dnorm(term0)
      phi_t1 <- dnorm(term1)
      Phi_t0 <- pnorm(term0)
      Phi_t1 <- pnorm(term1)
      f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
      #Fun??o log de verossimilhan?a

return(sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2))))
    }
    y <- lnambx
    Y2 <- dambexp
    X <- cbind(age,female,educ,blhisp,totchr,ins)
    W <- cbind(age,female,educ,blhisp,totchr,ins,income)

    gamma0=-0.6760544
    gamma1=0.0879359
    gamma2=0.6626647
    gamma3=0.0619485
    gamma4=-0.3639377
    gamma5=0.7969515
    gamma6=0.1701366
    gamma7=0.0027078
    beta0=5.0440623
    beta1=0.2119747
    beta2=0.3481427
    beta3=0.0187158
    beta4=-0.2185706
    beta5=0.5399190
    beta6=-0.0299875
    sigma=1.2710176
    rho=-0.1306012
    beta=c(beta0,beta1,beta2,beta3,beta4,beta5,beta6)
    gamma=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7)

start=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7,beta0,beta1,beta2,beta3,beta4,beta5,beta6,sigma,rho)
    Log.lik(start,X=X,W=W,y)

If you run the codes below that are within the programming of the Log.lik
function they compile correctly!

    mu1 <- model.matrix(~X)%*%beta
    mu2 <- model.matrix(~W)%*%gamma

    term0 <- (y-mu1)/sigma
    term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
    Phi_mu2 <- pnorm(mu2)
    phi_t0 <- dnorm(term0)
    phi_t1 <- dnorm(term1)
    Phi_t0 <- pnorm(term0)
    Phi_t1 <- pnorm(term1)
    f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
    sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2)))




Fernando Bastos

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec 11 09:46:23 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 11 Dec 2016 00:46:23 -0800
Subject: [R] how do I define a function which is equivalent to
	`deparse(substitute(x))`?
In-Reply-To: <20161211062449.GA20109@ofb.net>
References: <20161211062449.GA20109@ofb.net>
Message-ID: <B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>

No. Read Hadley Wickham's "Advanced R" to learn why not. 
-- 
Sent from my phone. Please excuse my brevity.

On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
>Dear R-Help,
>
>I asked this question on StackOverflow,
>
>http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex
>
>but thought perhaps R-help would be more appropriate.
>
>I want to write a function in R which grabs the name of a variable
>from the context of its caller's caller. I think the problem I have is
>best understood by asking how to compose `deparse` and `substitute`.
>You can see that a naive composition does not work:
>
>    # a compose operator
>    >  `%c%` = function(x,y)function(...)x(y(...))
>
>    # a naive attempt to combine deparse and substitute
>    > desub = deparse %c% substitute
>    > f=function(foo) { message(desub(foo)) }
>    > f(log)
>    foo
>
>    # this is how it is supposed to work
>    > g=function(foo) { message(deparse(substitute(foo))) }
>    > g(log)
>    log
>
>Is there a way I can define a function `desub` so that `desub(x)` has
>the same value as `deparse(substitute(x))` in every context?
>
>Thank you,
>
>Frederick Eaton
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sun Dec 11 10:51:35 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sun, 11 Dec 2016 20:51:35 +1100
Subject: [R] Organize regression output
In-Reply-To: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>
References: <51936A85-262B-4417-9066-41C0729FF89F@gmail.com>
Message-ID: <CA+8X3fV9MZZ_77iaNNmYVQYwW1EEP5ZpUnujp-DiUua5QWxkfQ@mail.gmail.com>

Hi Francesca,
I'm not sure what you are doing here, but try this:

regnames<-paste("r",letters[1:8],sep="")
for(i in 1:8) {
 response<-rnorm(20)
 coef1<-rnorm(20)
 coef2<-rnorm(20)
 age<-sample(20:50,20)
 gender<-sample(c("M","F"),20,TRUE)
 assign(regnames[i],lm(response~coef1+coef2+age+gender))
}
reglist<-list(ra,rb,rc,rd,re,rf,rg,rh)
cumsumcoef<-function(x) return(cumsum(x$coef))
coefsumlist<-as.data.frame(lapply(reglist,cumsumcoef))
names(coefsumlist)<-regnames
coefsumlist

Jim

On Sat, Dec 10, 2016 at 6:32 PM, francesca Pancotto
<francesca.pancotto at gmail.com> wrote:
> Dear Contributors
>
> I would like to ask some help concerning the automatization process of an analysis, that sounds hard to my knowledge.
> I have a list of regression models.
> I call them models=c(ra,rb,rc,rd,re,rf,rg,rh)
>
> I can access the output of each of them using for example, for the first
>
> ra$coefficients
>
> and i obtain
>
> (Intercept)       coeff1          coeff2            age                 gender
>  0.62003033  0.00350807 -0.03817848 -0.01513533 -0.18668972
> and I know that ra$coefficients[1] would give me the intercept of this model.
>
> What i need to do is to collect the coefficients of each regression in models, and calculate and place in a table, the following simple summation:
>
>
> ra                                              rb                                                      rc      ...
>
> intercept                                       intercept                                       intercept
> intercept+coeff1                        intercept+coeff1                        intercept+coeff1
> intercept+coeff2                        intercept+coeff2                        intercept+coeff2
> intercept+coeff1+coeff2         intercept+coeff1+coeff2         intercept+coeff1+coeff2
>
>
> The calculations are trivial(I know how to do it in steps) but what is difficult for me is to invent a procedure that organizes the data in an efficient way.
>
> I tried some step , starting with collecting the coefficients but i think I am going the wrong way
>
> calcolati <- list()
> for (i in c(ra,rb,rc,rd,re,rf,rg,rh))
> {
>   calcolati[[i]] <- i$coefficients[1]
> }
>
> Thanks for any help you can provide.
>
> f.
> ----------------------------------
> Francesca Pancotto
> Web: https://sites.google.com/site/francescapancotto/ <https://sites.google.com/site/francescapancotto/>
> Energie:
> http://www.energie.unimore.it/ <http://www.energie.unimore.it/>
> ----------------------------------
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Dec 11 12:03:45 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Dec 2016 03:03:45 -0800
Subject: [R] Assign a list to one column of data frame
In-Reply-To: <1481426305.14714.2.camel@gmx.cn>
References: <1481426305.14714.2.camel@gmx.cn>
Message-ID: <CAGxFJbSHnGHQfLr3_wagH6Cr-MsL5QSAjnqu0gXU+=a7tv5-4g@mail.gmail.com>

?data.frame says:

"If a list or data frame or matrix is passed to data.frame it is as if
each component or column had been passed as a separate argument
(except for matrices of class "model.matrix" and those protected by
I). "

So doing what Help says to do seems to do what you asked:


> df <- data.frame(a=1:3,b=letters[1:3])
> df
  a b
1 1 a
2 2 b
3 3 c

## add a list column, protected by "I()"
> df$new <- I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))

## works as advertised
> df
  a b          new
1 1 a 1, 2, 3,....
2 2 b          foo
3 3 c 0.080349....

> df$new
[[1]]
[1] 1 2 3 4 5

$g
[1] "foo"

$abb
           [,1]       [,2]
[1,] 0.08034915 0.83671591
[2,] 0.43938440 0.06067429
[3,] 0.88196881 0.33461234


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 10, 2016 at 7:18 PM, Marlin JL.M <marlin- at gmx.cn> wrote:
> Dear all,
>
> I want to assign a list to one column of data.frame where the name of the column
> is a variable. I tried the following:
>
> Using R version 3.3.2
>
>> df <- iris[1:3, ]
>> df
> # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> # 1          5.1         3.5          1.4         0.2  setosa
> # 2          4.9         3.0          1.4         0.2  setosa
> # 3          4.7         3.2          1.3         0.2  setosa
>
>> mylist <- list(c(1,2,3),c(1),c())
>> mylist
> # [[1]]
> # [1] 1 2 3
> #
> # [[2]]
> # [1] 1
> #
> # [[3]]
> # NULL
>
>> n1 <- 'new1'
>> df$n1 <- mylist
>
>> n2 <- 'new2'
>> df[,n2] <- mylist
> # Warning message:
> # In `[<-.data.frame`(`*tmp*`, , "new4", value = list(c(1, 2, 3),  :
> # provided 3 variables to replace 1 variables
>
>> n3 <- 'new3'
>> df[,n3] <- I(mylist)
> # Warning message:
> # In `[<-.data.frame`(`*tmp*`, , "new3", value = list(c(1, 2, 3),  :
> # provided 3 variables to replace 1 variables
>
>> eval(parse(text = paste0("df$","new4","<- mylist")))
>
>> df
> # Sepal.Length Sepal.Width Petal.Length Petal.Width Species      n1 new2 new3    new4
> # 1          5.1         3.5          1.4         0.2  setosa 1, 2, 3    1    1 1, 2, 3
> # 2          4.9         3.0          1.4         0.2  setosa       1    2    2       1
> # 3          4.7         3.2          1.3         0.2  setosa    NULL    3    3    NULL
>
>
> The "eval" works correctly, however, if I want to avoid using "eval", what
> should I do?
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sun Dec 11 14:25:10 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 11 Dec 2016 08:25:10 -0500
Subject: [R] Function implemented in R returns the wrong value
In-Reply-To: <CAPTmxS1TkQx1F5=ztyp=EWvAPR4XxDtDHcgdyyJmzW7RW=S8Kw@mail.gmail.com>
References: <CAPTmxS1TkQx1F5=ztyp=EWvAPR4XxDtDHcgdyyJmzW7RW=S8Kw@mail.gmail.com>
Message-ID: <7330aa38-b080-10d3-cdd9-52f4fd5a06fa@gmail.com>

On 10/12/2016 2:01 PM, Fernando de Souza Bastos wrote:
> The Log.lik function below returns the value '-INF' when it should return
> the value -5836.219. I can not figure out the error, does anyone have any
> suggestions?

I haven't read it carefully, but a likely problem is that you are using 
constructs like log(dnorm(x)) (e.g. log(phi_t0)) instead of dnorm(x, log 
= TRUE).  The dnorm(x) value will underflow to zero, and taking the log 
will give you -Inf.  Using the "log = TRUE" argument avoids the underflow.

Duncan Murdoch

>
>     rm(list=ls())
>     library(ssmrob)
>     data(MEPS2001)
>     attach(MEPS2001)
>     n<-nrow(MEPS2001)
>     Log.lik <- function(par,X,W,y){
>       n <- length(y)
>       beta <- par[1:(ncol(X)+1)]
>       gamma <- par[(ncol(X)+2):(ncol(X)+ncol(W)+2)]
>       mu1 <- model.matrix(~X)%*%beta
>       mu2 <- model.matrix(~W)%*%gamma
>       sigma <- par[(ncol(X)+ncol(W)+3)]
>       rho <- par[(ncol(X)+ncol(W)+4)]
>       term0 <- (y-mu1)/sigma
>       term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
>       Phi_mu2 <- pnorm(mu2)
>       phi_t0 <- dnorm(term0)
>       phi_t1 <- dnorm(term1)
>       Phi_t0 <- pnorm(term0)
>       Phi_t1 <- pnorm(term1)
>       f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
>       #Fun??o log de verossimilhan?a
>
> return(sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2))))
>     }
>     y <- lnambx
>     Y2 <- dambexp
>     X <- cbind(age,female,educ,blhisp,totchr,ins)
>     W <- cbind(age,female,educ,blhisp,totchr,ins,income)
>
>     gamma0=-0.6760544
>     gamma1=0.0879359
>     gamma2=0.6626647
>     gamma3=0.0619485
>     gamma4=-0.3639377
>     gamma5=0.7969515
>     gamma6=0.1701366
>     gamma7=0.0027078
>     beta0=5.0440623
>     beta1=0.2119747
>     beta2=0.3481427
>     beta3=0.0187158
>     beta4=-0.2185706
>     beta5=0.5399190
>     beta6=-0.0299875
>     sigma=1.2710176
>     rho=-0.1306012
>     beta=c(beta0,beta1,beta2,beta3,beta4,beta5,beta6)
>     gamma=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7)
>
> start=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7,beta0,beta1,beta2,beta3,beta4,beta5,beta6,sigma,rho)
>     Log.lik(start,X=X,W=W,y)
>
> If you run the codes below that are within the programming of the Log.lik
> function they compile correctly!
>
>     mu1 <- model.matrix(~X)%*%beta
>     mu2 <- model.matrix(~W)%*%gamma
>
>     term0 <- (y-mu1)/sigma
>     term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
>     Phi_mu2 <- pnorm(mu2)
>     phi_t0 <- dnorm(term0)
>     phi_t1 <- dnorm(term1)
>     Phi_t0 <- pnorm(term0)
>     Phi_t1 <- pnorm(term1)
>     f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
>     sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2)))
>
>
>
>
> Fernando Bastos
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Sun Dec 11 15:52:24 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Dec 2016 06:52:24 -0800
Subject: [R] Assign a list to one column of data frame
In-Reply-To: <1481457267.22088.2.camel@gmx.cn>
References: <1481426305.14714.2.camel@gmx.cn>
	<CAGxFJbSHnGHQfLr3_wagH6Cr-MsL5QSAjnqu0gXU+=a7tv5-4g@mail.gmail.com>
	<1481457267.22088.2.camel@gmx.cn>
Message-ID: <CAGxFJbSg-mD-+=Onspob2tq7_Vv-mPBQCdDW1OO30Kx31McTaQ@mail.gmail.com>

Use list indexing, "[[" not "[" .

> df <- data.frame(a=1:3,b=letters[1:3])
> x <- "new"
> df[[x]]<-  I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
> df
  a b          new
1 1 a 1, 2, 3,....
2 2 b          foo
3 3 c 0.248115....
> df$new
[[1]]
[1] 1 2 3 4 5

$g
[1] "foo"

$abb
          [,1]      [,2]
[1,] 0.2481156 0.2138564
[2,] 0.8598658 0.2898058
[3,] 0.5854885 0.4084578


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 11, 2016 at 3:54 AM, Marlin JL.M <marlin- at gmx.cn> wrote:
>
> If you see my previous example, I have tried something like
>> df[,n3] <- I(mylist)
>
> However, in my case, the name of the new column is in a variable (by
> user input) which can not be directly used by the dollar assign. On the
> other hand, "[<-" does not work correctly even if I wrap the list into
> "I()".
>
> Perhaps the title of my email is a little unclear, sorry for the case.
>
> Best,
> Marlin.
>
> On Sun, 2016-12-11 at 03:03 -0800, Bert Gunter wrote:
>> ?data.frame says:
>>
>> "If a list or data frame or matrix is passed to data.frame it is as
>> if
>> each component or column had been passed as a separate argument
>> (except for matrices of class "model.matrix" and those protected by
>> I). "
>>
>> So doing what Help says to do seems to do what you asked:
>>
>>
>> > df <- data.frame(a=1:3,b=letters[1:3])
>> > df
>>
>>   a b
>> 1 1 a
>> 2 2 b
>> 3 3 c
>>
>> ## add a list column, protected by "I()"
>> > df$new <- I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
>>
>> ## works as advertised
>> > df
>>
>>   a b          new
>> 1 1 a 1, 2, 3,....
>> 2 2 b          foo
>> 3 3 c 0.080349....
>>
>> > df$new
>>
>> [[1]]
>> [1] 1 2 3 4 5
>>
>> $g
>> [1] "foo"
>>
>> $abb
>>            [,1]       [,2]
>> [1,] 0.08034915 0.83671591
>> [2,] 0.43938440 0.06067429
>> [3,] 0.88196881 0.33461234
>>
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>> along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Dec 10, 2016 at 7:18 PM, Marlin JL.M <marlin- at gmx.cn> wrote:
>> > Dear all,
>> >
>> > I want to assign a list to one column of data.frame where the name
>> > of the column
>> > is a variable. I tried the following:
>> >
>> > Using R version 3.3.2
>> >
>> > > df <- iris[1:3, ]
>> > > df
>> >
>> > # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> > # 1          5.1         3.5          1.4         0.2  setosa
>> > # 2          4.9         3.0          1.4         0.2  setosa
>> > # 3          4.7         3.2          1.3         0.2  setosa
>> >
>> > > mylist <- list(c(1,2,3),c(1),c())
>> > > mylist
>> >
>> > # [[1]]
>> > # [1] 1 2 3
>> > #
>> > # [[2]]
>> > # [1] 1
>> > #
>> > # [[3]]
>> > # NULL
>> >
>> > > n1 <- 'new1'
>> > > df$n1 <- mylist
>> > > n2 <- 'new2'
>> > > df[,n2] <- mylist
>> >
>> > # Warning message:
>> > # In `[<-.data.frame`(`*tmp*`, , "new4", value = list(c(1, 2,
>> > 3),  :
>> > # provided 3 variables to replace 1 variables
>> >
>> > > n3 <- 'new3'
>> > > df[,n3] <- I(mylist)
>> >
>> > # Warning message:
>> > # In `[<-.data.frame`(`*tmp*`, , "new3", value = list(c(1, 2,
>> > 3),  :
>> > # provided 3 variables to replace 1 variables
>> >
>> > > eval(parse(text = paste0("df$","new4","<- mylist")))
>> > > df
>> >
>> > # Sepal.Length Sepal.Width Petal.Length Petal.Width Species      n1
>> > new2 new3    new4
>> > # 1          5.1         3.5          1.4         0.2  setosa 1, 2,
>> > 3    1    1 1, 2, 3
>> > #
>> > 2          4.9         3.0          1.4         0.2  setosa       1
>> >     2    2       1
>> > #
>> > 3          4.7         3.2          1.3         0.2  setosa    NULL
>> >     3    3    NULL
>> >
>> >
>> > The "eval" works correctly, however, if I want to avoid using
>> > "eval", what
>> > should I do?
>> >
>> > Thanks!
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-g
>> > uide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Dec 11 16:20:16 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Dec 2016 07:20:16 -0800
Subject: [R] Assign a list to one column of data frame
In-Reply-To: <1481468498.29188.1.camel@gmx.cn>
References: <1481426305.14714.2.camel@gmx.cn>
	<CAGxFJbSHnGHQfLr3_wagH6Cr-MsL5QSAjnqu0gXU+=a7tv5-4g@mail.gmail.com>
	<1481457267.22088.2.camel@gmx.cn>
	<CAGxFJbSg-mD-+=Onspob2tq7_Vv-mPBQCdDW1OO30Kx31McTaQ@mail.gmail.com>
	<1481468498.29188.1.camel@gmx.cn>
Message-ID: <CAGxFJbT7bD04Am6AMs1cyQ5KcmV=bZySNMQw6GHqpDC7OzhQFA@mail.gmail.com>

Glad to help.

However, I need to publicly correct my misstatement. Both "[[" and "["
can be used and are useful for list indexing. As ?"[" clearly states,
the former selects only a single column, while the latter can select
several.

Also:

"Both [[ and $ select a single element of the list. The main
difference is that $ does not allow computed indices, whereas [[ does.
x$name is equivalent to x[["name", exact = FALSE]]. "

Also, when used for list selection, "[" returns a list, while "[["
returns whatever was selected.



-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 11, 2016 at 7:01 AM, Marlin JL.M <marlin- at gmx.cn> wrote:
> Dear Bert,
>
> This is awesome, thanks a lot!
>
> Best,
> Marlin
>
>
> On Sun, 2016-12-11 at 06:52 -0800, Bert Gunter wrote:
>> Use list indexing, "[[" not "[" .
>>
>> > df <- data.frame(a=1:3,b=letters[1:3])
>> > x <- "new"
>> > df[[x]]<-  I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
>> > df
>>
>>   a b          new
>> 1 1 a 1, 2, 3,....
>> 2 2 b          foo
>> 3 3 c 0.248115....
>> > df$new
>>
>> [[1]]
>> [1] 1 2 3 4 5
>>
>> $g
>> [1] "foo"
>>
>> $abb
>>           [,1]      [,2]
>> [1,] 0.2481156 0.2138564
>> [2,] 0.8598658 0.2898058
>> [3,] 0.5854885 0.4084578
>>
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>> along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Dec 11, 2016 at 3:54 AM, Marlin JL.M <marlin- at gmx.cn> wrote:
>> >
>> > If you see my previous example, I have tried something like
>> > > df[,n3] <- I(mylist)
>> >
>> > However, in my case, the name of the new column is in a variable
>> > (by
>> > user input) which can not be directly used by the dollar assign. On
>> > the
>> > other hand, "[<-" does not work correctly even if I wrap the list
>> > into
>> > "I()".
>> >
>> > Perhaps the title of my email is a little unclear, sorry for the
>> > case.
>> >
>> > Best,
>> > Marlin.
>> >
>> > On Sun, 2016-12-11 at 03:03 -0800, Bert Gunter wrote:
>> > > ?data.frame says:
>> > >
>> > > "If a list or data frame or matrix is passed to data.frame it is
>> > > as
>> > > if
>> > > each component or column had been passed as a separate argument
>> > > (except for matrices of class "model.matrix" and those protected
>> > > by
>> > > I). "
>> > >
>> > > So doing what Help says to do seems to do what you asked:
>> > >
>> > >
>> > > > df <- data.frame(a=1:3,b=letters[1:3])
>> > > > df
>> > >
>> > >   a b
>> > > 1 1 a
>> > > 2 2 b
>> > > 3 3 c
>> > >
>> > > ## add a list column, protected by "I()"
>> > > > df$new <- I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
>> > >
>> > > ## works as advertised
>> > > > df
>> > >
>> > >   a b          new
>> > > 1 1 a 1, 2, 3,....
>> > > 2 2 b          foo
>> > > 3 3 c 0.080349....
>> > >
>> > > > df$new
>> > >
>> > > [[1]]
>> > > [1] 1 2 3 4 5
>> > >
>> > > $g
>> > > [1] "foo"
>> > >
>> > > $abb
>> > >            [,1]       [,2]
>> > > [1,] 0.08034915 0.83671591
>> > > [2,] 0.43938440 0.06067429
>> > > [3,] 0.88196881 0.33461234
>> > >
>> > >
>> > > Cheers,
>> > > Bert
>> > >
>> > >
>> > > Bert Gunter
>> > >
>> > > "The trouble with having an open mind is that people keep coming
>> > > along
>> > > and sticking things into it."
>> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
>> > > )
>> > >
>> > >
>> > > On Sat, Dec 10, 2016 at 7:18 PM, Marlin JL.M <marlin- at gmx.cn>
>> > > wrote:
>> > > > Dear all,
>> > > >
>> > > > I want to assign a list to one column of data.frame where the
>> > > > name
>> > > > of the column
>> > > > is a variable. I tried the following:
>> > > >
>> > > > Using R version 3.3.2
>> > > >
>> > > > > df <- iris[1:3, ]
>> > > > > df
>> > > >
>> > > > # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> > > > # 1          5.1         3.5          1.4         0.2  setosa
>> > > > # 2          4.9         3.0          1.4         0.2  setosa
>> > > > # 3          4.7         3.2          1.3         0.2  setosa
>> > > >
>> > > > > mylist <- list(c(1,2,3),c(1),c())
>> > > > > mylist
>> > > >
>> > > > # [[1]]
>> > > > # [1] 1 2 3
>> > > > #
>> > > > # [[2]]
>> > > > # [1] 1
>> > > > #
>> > > > # [[3]]
>> > > > # NULL
>> > > >
>> > > > > n1 <- 'new1'
>> > > > > df$n1 <- mylist
>> > > > > n2 <- 'new2'
>> > > > > df[,n2] <- mylist
>> > > >
>> > > > # Warning message:
>> > > > # In `[<-.data.frame`(`*tmp*`, , "new4", value = list(c(1, 2,
>> > > > 3),  :
>> > > > # provided 3 variables to replace 1 variables
>> > > >
>> > > > > n3 <- 'new3'
>> > > > > df[,n3] <- I(mylist)
>> > > >
>> > > > # Warning message:
>> > > > # In `[<-.data.frame`(`*tmp*`, , "new3", value = list(c(1, 2,
>> > > > 3),  :
>> > > > # provided 3 variables to replace 1 variables
>> > > >
>> > > > > eval(parse(text = paste0("df$","new4","<- mylist")))
>> > > > > df
>> > > >
>> > > > # Sepal.Length Sepal.Width Petal.Length Petal.Width
>> > > > Species      n1
>> > > > new2 new3    new4
>> > > > # 1          5.1         3.5          1.4         0.2  setosa
>> > > > 1, 2,
>> > > > 3    1    1 1, 2, 3
>> > > > #
>> > > > 2          4.9         3.0          1.4         0.2  setosa
>> > > >    1
>> > > >     2    2       1
>> > > > #
>> > > > 3          4.7         3.2          1.3         0.2  setosa
>> > > > NULL
>> > > >     3    3    NULL
>> > > >
>> > > >
>> > > > The "eval" works correctly, however, if I want to avoid using
>> > > > "eval", what
>> > > > should I do?
>> > > >
>> > > > Thanks!
>> > > >
>> > > > ______________________________________________
>> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> > > > see
>> > > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > > PLEASE do read the posting guide http://www.R-project.org/posti
>> > > > ng-g
>> > > > uide.html
>> > > > and provide commented, minimal, self-contained, reproducible
>> > > > code.
>


From marlin- at gmx.cn  Sun Dec 11 12:54:27 2016
From: marlin- at gmx.cn (Marlin JL.M)
Date: Sun, 11 Dec 2016 19:54:27 +0800
Subject: [R] Assign a list to one column of data frame
In-Reply-To: <CAGxFJbSHnGHQfLr3_wagH6Cr-MsL5QSAjnqu0gXU+=a7tv5-4g@mail.gmail.com>
References: <1481426305.14714.2.camel@gmx.cn>
	<CAGxFJbSHnGHQfLr3_wagH6Cr-MsL5QSAjnqu0gXU+=a7tv5-4g@mail.gmail.com>
Message-ID: <1481457267.22088.2.camel@gmx.cn>


If you see my previous example, I have tried something like 
> df[,n3] <- I(mylist)

However, in my case, the name of the new column is in a variable (by
user input) which can not be directly used by the dollar assign. On the
other hand, "[<-" does not work correctly even if I wrap the list into
"I()".

Perhaps the title of my email is a little unclear, sorry for the case.

Best,
Marlin.

On Sun, 2016-12-11 at 03:03 -0800, Bert Gunter wrote:
> ?data.frame says:
> 
> "If a list or data frame or matrix is passed to data.frame it is as
> if
> each component or column had been passed as a separate argument
> (except for matrices of class "model.matrix" and those protected by
> I). "
> 
> So doing what Help says to do seems to do what you asked:
> 
> 
> > df <- data.frame(a=1:3,b=letters[1:3])
> > df
> 
> ? a b
> 1 1 a
> 2 2 b
> 3 3 c
> 
> ## add a list column, protected by "I()"
> > df$new <- I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
> 
> ## works as advertised
> > df
> 
> ? a b??????????new
> 1 1 a 1, 2, 3,....
> 2 2 b??????????foo
> 3 3 c 0.080349....
> 
> > df$new
> 
> [[1]]
> [1] 1 2 3 4 5
> 
> $g
> [1] "foo"
> 
> $abb
> ???????????[,1]???????[,2]
> [1,] 0.08034915 0.83671591
> [2,] 0.43938440 0.06067429
> [3,] 0.88196881 0.33461234
> 
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming
> along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sat, Dec 10, 2016 at 7:18 PM, Marlin JL.M <marlin- at gmx.cn> wrote:
> > Dear all,
> > 
> > I want to assign a list to one column of data.frame where the name
> > of the column
> > is a variable. I tried the following:
> > 
> > Using R version 3.3.2
> > 
> > > df <- iris[1:3, ]
> > > df
> > 
> > # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > # 1??????????5.1?????????3.5??????????1.4?????????0.2??setosa
> > # 2??????????4.9?????????3.0??????????1.4?????????0.2??setosa
> > # 3??????????4.7?????????3.2??????????1.3?????????0.2??setosa
> > 
> > > mylist <- list(c(1,2,3),c(1),c())
> > > mylist
> > 
> > # [[1]]
> > # [1] 1 2 3
> > #
> > # [[2]]
> > # [1] 1
> > #
> > # [[3]]
> > # NULL
> > 
> > > n1 <- 'new1'
> > > df$n1 <- mylist
> > > n2 <- 'new2'
> > > df[,n2] <- mylist
> > 
> > # Warning message:
> > # In `[<-.data.frame`(`*tmp*`, , "new4", value = list(c(1, 2,
> > 3),??:
> > # provided 3 variables to replace 1 variables
> > 
> > > n3 <- 'new3'
> > > df[,n3] <- I(mylist)
> > 
> > # Warning message:
> > # In `[<-.data.frame`(`*tmp*`, , "new3", value = list(c(1, 2,
> > 3),??:
> > # provided 3 variables to replace 1 variables
> > 
> > > eval(parse(text = paste0("df$","new4","<- mylist")))
> > > df
> > 
> > # Sepal.Length Sepal.Width Petal.Length Petal.Width Species??????n1
> > new2 new3????new4
> > # 1??????????5.1?????????3.5??????????1.4?????????0.2??setosa 1, 2,
> > 3????1????1 1, 2, 3
> > #
> > 2??????????4.9?????????3.0??????????1.4?????????0.2??setosa???????1
> > ????2????2???????1
> > #
> > 3??????????4.7?????????3.2??????????1.3?????????0.2??setosa????NULL
> > ????3????3????NULL
> > 
> > 
> > The "eval" works correctly, however, if I want to avoid using
> > "eval", what
> > should I do?
> > 
> > Thanks!
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-g
> > uide.html
> > and provide commented, minimal, self-contained, reproducible code.

From fsbmat at gmail.com  Sun Dec 11 15:25:03 2016
From: fsbmat at gmail.com (Fernando de Souza Bastos)
Date: Sun, 11 Dec 2016 12:25:03 -0200
Subject: [R] Function implemented in R returns the wrong value
In-Reply-To: <7330aa38-b080-10d3-cdd9-52f4fd5a06fa@gmail.com>
References: <CAPTmxS1TkQx1F5=ztyp=EWvAPR4XxDtDHcgdyyJmzW7RW=S8Kw@mail.gmail.com>
	<7330aa38-b080-10d3-cdd9-52f4fd5a06fa@gmail.com>
Message-ID: <CAPTmxS2D88XZBXjCDJiSe8mBNyaQxW9a1NcDTzmd278rW5UrGw@mail.gmail.com>

Thank you Duncan, it really was that!

Fernando de Souza Bastos
Professor Assistente

Universidade Federal de Vi?osa (UFV)

Campus UFV - Florestal

Doutorando em Estat?stica
Universidade Federal de Minas Gerais (UFMG)
Cel: (31) 99751-6586



2016-12-11 11:25 GMT-02:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 10/12/2016 2:01 PM, Fernando de Souza Bastos wrote:
>
>> The Log.lik function below returns the value '-INF' when it should return
>> the value -5836.219. I can not figure out the error, does anyone have any
>> suggestions?
>>
>
> I haven't read it carefully, but a likely problem is that you are using
> constructs like log(dnorm(x)) (e.g. log(phi_t0)) instead of dnorm(x, log =
> TRUE).  The dnorm(x) value will underflow to zero, and taking the log will
> give you -Inf.  Using the "log = TRUE" argument avoids the underflow.
>
> Duncan Murdoch
>
>
>>     rm(list=ls())
>>     library(ssmrob)
>>     data(MEPS2001)
>>     attach(MEPS2001)
>>     n<-nrow(MEPS2001)
>>     Log.lik <- function(par,X,W,y){
>>       n <- length(y)
>>       beta <- par[1:(ncol(X)+1)]
>>       gamma <- par[(ncol(X)+2):(ncol(X)+ncol(W)+2)]
>>       mu1 <- model.matrix(~X)%*%beta
>>       mu2 <- model.matrix(~W)%*%gamma
>>       sigma <- par[(ncol(X)+ncol(W)+3)]
>>       rho <- par[(ncol(X)+ncol(W)+4)]
>>       term0 <- (y-mu1)/sigma
>>       term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
>>       Phi_mu2 <- pnorm(mu2)
>>       phi_t0 <- dnorm(term0)
>>       phi_t1 <- dnorm(term1)
>>       Phi_t0 <- pnorm(term0)
>>       Phi_t1 <- pnorm(term1)
>>       f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
>>       #Fun??o log de verossimilhan?a
>>
>> return(sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),
>> log(1-Phi_mu2))))
>>     }
>>     y <- lnambx
>>     Y2 <- dambexp
>>     X <- cbind(age,female,educ,blhisp,totchr,ins)
>>     W <- cbind(age,female,educ,blhisp,totchr,ins,income)
>>
>>     gamma0=-0.6760544
>>     gamma1=0.0879359
>>     gamma2=0.6626647
>>     gamma3=0.0619485
>>     gamma4=-0.3639377
>>     gamma5=0.7969515
>>     gamma6=0.1701366
>>     gamma7=0.0027078
>>     beta0=5.0440623
>>     beta1=0.2119747
>>     beta2=0.3481427
>>     beta3=0.0187158
>>     beta4=-0.2185706
>>     beta5=0.5399190
>>     beta6=-0.0299875
>>     sigma=1.2710176
>>     rho=-0.1306012
>>     beta=c(beta0,beta1,beta2,beta3,beta4,beta5,beta6)
>>     gamma=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7)
>>
>> start=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gam
>> ma7,beta0,beta1,beta2,beta3,beta4,beta5,beta6,sigma,rho)
>>     Log.lik(start,X=X,W=W,y)
>>
>> If you run the codes below that are within the programming of the Log.lik
>> function they compile correctly!
>>
>>     mu1 <- model.matrix(~X)%*%beta
>>     mu2 <- model.matrix(~W)%*%gamma
>>
>>     term0 <- (y-mu1)/sigma
>>     term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
>>     Phi_mu2 <- pnorm(mu2)
>>     phi_t0 <- dnorm(term0)
>>     phi_t1 <- dnorm(term1)
>>     Phi_t0 <- pnorm(term0)
>>     Phi_t1 <- pnorm(term1)
>>     f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
>>     sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2)))
>>
>>
>>
>>
>> Fernando Bastos
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From marlin- at gmx.cn  Sun Dec 11 16:01:38 2016
From: marlin- at gmx.cn (Marlin JL.M)
Date: Sun, 11 Dec 2016 23:01:38 +0800
Subject: [R] Assign a list to one column of data frame
In-Reply-To: <CAGxFJbSg-mD-+=Onspob2tq7_Vv-mPBQCdDW1OO30Kx31McTaQ@mail.gmail.com>
References: <1481426305.14714.2.camel@gmx.cn>
	<CAGxFJbSHnGHQfLr3_wagH6Cr-MsL5QSAjnqu0gXU+=a7tv5-4g@mail.gmail.com>
	<1481457267.22088.2.camel@gmx.cn>
	<CAGxFJbSg-mD-+=Onspob2tq7_Vv-mPBQCdDW1OO30Kx31McTaQ@mail.gmail.com>
Message-ID: <1481468498.29188.1.camel@gmx.cn>

Dear Bert,

This is awesome, thanks a lot!

Best,
Marlin


On Sun, 2016-12-11 at 06:52 -0800, Bert Gunter wrote:
> Use list indexing, "[[" not "[" .
> 
> > df <- data.frame(a=1:3,b=letters[1:3])
> > x <- "new"
> > df[[x]]<-??I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
> > df
> 
> ? a b??????????new
> 1 1 a 1, 2, 3,....
> 2 2 b??????????foo
> 3 3 c 0.248115....
> > df$new
> 
> [[1]]
> [1] 1 2 3 4 5
> 
> $g
> [1] "foo"
> 
> $abb
> ??????????[,1]??????[,2]
> [1,] 0.2481156 0.2138564
> [2,] 0.8598658 0.2898058
> [3,] 0.5854885 0.4084578
> 
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming
> along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Dec 11, 2016 at 3:54 AM, Marlin JL.M <marlin- at gmx.cn> wrote:
> > 
> > If you see my previous example, I have tried something like
> > > df[,n3] <- I(mylist)
> > 
> > However, in my case, the name of the new column is in a variable
> > (by
> > user input) which can not be directly used by the dollar assign. On
> > the
> > other hand, "[<-" does not work correctly even if I wrap the list
> > into
> > "I()".
> > 
> > Perhaps the title of my email is a little unclear, sorry for the
> > case.
> > 
> > Best,
> > Marlin.
> > 
> > On Sun, 2016-12-11 at 03:03 -0800, Bert Gunter wrote:
> > > ?data.frame says:
> > > 
> > > "If a list or data frame or matrix is passed to data.frame it is
> > > as
> > > if
> > > each component or column had been passed as a separate argument
> > > (except for matrices of class "model.matrix" and those protected
> > > by
> > > I). "
> > > 
> > > So doing what Help says to do seems to do what you asked:
> > > 
> > > 
> > > > df <- data.frame(a=1:3,b=letters[1:3])
> > > > df
> > > 
> > > ? a b
> > > 1 1 a
> > > 2 2 b
> > > 3 3 c
> > > 
> > > ## add a list column, protected by "I()"
> > > > df$new <- I(list(1:5,g = "foo", abb = matrix(runif(6),nr=3)))
> > > 
> > > ## works as advertised
> > > > df
> > > 
> > > ? a b??????????new
> > > 1 1 a 1, 2, 3,....
> > > 2 2 b??????????foo
> > > 3 3 c 0.080349....
> > > 
> > > > df$new
> > > 
> > > [[1]]
> > > [1] 1 2 3 4 5
> > > 
> > > $g
> > > [1] "foo"
> > > 
> > > $abb
> > > ???????????[,1]???????[,2]
> > > [1,] 0.08034915 0.83671591
> > > [2,] 0.43938440 0.06067429
> > > [3,] 0.88196881 0.33461234
> > > 
> > > 
> > > Cheers,
> > > Bert
> > > 
> > > 
> > > Bert Gunter
> > > 
> > > "The trouble with having an open mind is that people keep coming
> > > along
> > > and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip
> > > )
> > > 
> > > 
> > > On Sat, Dec 10, 2016 at 7:18 PM, Marlin JL.M <marlin- at gmx.cn>
> > > wrote:
> > > > Dear all,
> > > > 
> > > > I want to assign a list to one column of data.frame where the
> > > > name
> > > > of the column
> > > > is a variable. I tried the following:
> > > > 
> > > > Using R version 3.3.2
> > > > 
> > > > > df <- iris[1:3, ]
> > > > > df
> > > > 
> > > > # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> > > > # 1??????????5.1?????????3.5??????????1.4?????????0.2??setosa
> > > > # 2??????????4.9?????????3.0??????????1.4?????????0.2??setosa
> > > > # 3??????????4.7?????????3.2??????????1.3?????????0.2??setosa
> > > > 
> > > > > mylist <- list(c(1,2,3),c(1),c())
> > > > > mylist
> > > > 
> > > > # [[1]]
> > > > # [1] 1 2 3
> > > > #
> > > > # [[2]]
> > > > # [1] 1
> > > > #
> > > > # [[3]]
> > > > # NULL
> > > > 
> > > > > n1 <- 'new1'
> > > > > df$n1 <- mylist
> > > > > n2 <- 'new2'
> > > > > df[,n2] <- mylist
> > > > 
> > > > # Warning message:
> > > > # In `[<-.data.frame`(`*tmp*`, , "new4", value = list(c(1, 2,
> > > > 3),??:
> > > > # provided 3 variables to replace 1 variables
> > > > 
> > > > > n3 <- 'new3'
> > > > > df[,n3] <- I(mylist)
> > > > 
> > > > # Warning message:
> > > > # In `[<-.data.frame`(`*tmp*`, , "new3", value = list(c(1, 2,
> > > > 3),??:
> > > > # provided 3 variables to replace 1 variables
> > > > 
> > > > > eval(parse(text = paste0("df$","new4","<- mylist")))
> > > > > df
> > > > 
> > > > # Sepal.Length Sepal.Width Petal.Length Petal.Width
> > > > Species??????n1
> > > > new2 new3????new4
> > > > # 1??????????5.1?????????3.5??????????1.4?????????0.2??setosa
> > > > 1, 2,
> > > > 3????1????1 1, 2, 3
> > > > #
> > > > 2??????????4.9?????????3.0??????????1.4?????????0.2??setosa????
> > > > ???1
> > > > ????2????2???????1
> > > > #
> > > > 3??????????4.7?????????3.2??????????1.3?????????0.2??setosa????
> > > > NULL
> > > > ????3????3????NULL
> > > > 
> > > > 
> > > > The "eval" works correctly, however, if I want to avoid using
> > > > "eval", what
> > > > should I do?
> > > > 
> > > > Thanks!
> > > > 
> > > > ______________________________________________
> > > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> > > > see
> > > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > > PLEASE do read the posting guide http://www.R-project.org/posti
> > > > ng-g
> > > > uide.html
> > > > and provide commented, minimal, self-contained, reproducible
> > > > code.


From paul at stat.auckland.ac.nz  Sun Dec 11 20:08:54 2016
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 12 Dec 2016 08:08:54 +1300
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <1667594422.52330.1481319588031@mail.yahoo.com>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
	<1492163843.673701.1481235207181@mail.yahoo.com>
	<6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>
	<1667594422.52330.1481319588031@mail.yahoo.com>
Message-ID: <b83441fc-9b59-f42c-d650-b8247e6e91d2@stat.auckland.ac.nz>

Hi

Great to hear you have it working.

Figuring out the names of grobs takes two things:

1. someone has to name the grobs
2. grid.ls()

The reason why I did my example using 'lattice' is because 'lattice' 
names all of its grobs.  There is a document ...

http://lattice.r-forge.r-project.org/Vignettes/src/naming-scheme/namingScheme.pdf

... that describes the 'lattice' naming scheme.

Paul

On 10/12/16 10:39, Fix Ace wrote:
> Hi, Paul,
>
> Thank you very much! It works this time with "strict=FALSE" option.
>
> Another relevant question:
>
> how did you figure out  that boxes in boxplot are called
> "bwplot.box.polygon". If I am trying to make a gradient filling for
> barplot of other plots, how would I define grobs?
>
> Thanks!!
>
> Ace
>
>
>
>
>
> On Thursday, December 8, 2016 5:24 PM, Paul Murrell
> <paul at stat.auckland.ac.nz> wrote:
>
>
> Hi
>
> You could try ...
>
> grid.export(..., strict=FALSE)
>
> ... and/or install the latest gridSVG version from R-Forge ...
>
> https://r-forge.r-project.org/R/?group_id=1025
>
> Paul
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From pdalgd at gmail.com  Sun Dec 11 21:47:47 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 11 Dec 2016 21:47:47 +0100
Subject: [R] Function implemented in R returns the wrong value
In-Reply-To: <CAPTmxS1TkQx1F5=ztyp=EWvAPR4XxDtDHcgdyyJmzW7RW=S8Kw@mail.gmail.com>
References: <CAPTmxS1TkQx1F5=ztyp=EWvAPR4XxDtDHcgdyyJmzW7RW=S8Kw@mail.gmail.com>
Message-ID: <2317C832-4DE1-441F-B4D1-E72736A2A850@gmail.com>

There are limits to how much people will do your debugging for you, but it looks like you are unpacking beta,gamma from par, but packing gamma,beta into start. Otherwise, print some of the values computed in the function and check.

-pd

> On 10 Dec 2016, at 20:01 , Fernando de Souza Bastos <fsbmat at gmail.com> wrote:
> 
> The Log.lik function below returns the value '-INF' when it should return
> the value -5836.219. I can not figure out the error, does anyone have any
> suggestions?
> 
>    rm(list=ls())
>    library(ssmrob)
>    data(MEPS2001)
>    attach(MEPS2001)
>    n<-nrow(MEPS2001)
>    Log.lik <- function(par,X,W,y){
>      n <- length(y)
>      beta <- par[1:(ncol(X)+1)]
>      gamma <- par[(ncol(X)+2):(ncol(X)+ncol(W)+2)]
>      mu1 <- model.matrix(~X)%*%beta
>      mu2 <- model.matrix(~W)%*%gamma
>      sigma <- par[(ncol(X)+ncol(W)+3)]
>      rho <- par[(ncol(X)+ncol(W)+4)]
>      term0 <- (y-mu1)/sigma
>      term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
>      Phi_mu2 <- pnorm(mu2)
>      phi_t0 <- dnorm(term0)
>      phi_t1 <- dnorm(term1)
>      Phi_t0 <- pnorm(term0)
>      Phi_t1 <- pnorm(term1)
>      f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
>      #Fun??o log de verossimilhan?a
> 
> return(sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2))))
>    }
>    y <- lnambx
>    Y2 <- dambexp
>    X <- cbind(age,female,educ,blhisp,totchr,ins)
>    W <- cbind(age,female,educ,blhisp,totchr,ins,income)
> 
>    gamma0=-0.6760544
>    gamma1=0.0879359
>    gamma2=0.6626647
>    gamma3=0.0619485
>    gamma4=-0.3639377
>    gamma5=0.7969515
>    gamma6=0.1701366
>    gamma7=0.0027078
>    beta0=5.0440623
>    beta1=0.2119747
>    beta2=0.3481427
>    beta3=0.0187158
>    beta4=-0.2185706
>    beta5=0.5399190
>    beta6=-0.0299875
>    sigma=1.2710176
>    rho=-0.1306012
>    beta=c(beta0,beta1,beta2,beta3,beta4,beta5,beta6)
>    gamma=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7)
> 
> start=c(gamma0,gamma1,gamma2,gamma3,gamma4,gamma5,gamma6,gamma7,beta0,beta1,beta2,beta3,beta4,beta5,beta6,sigma,rho)
>    Log.lik(start,X=X,W=W,y)
> 
> If you run the codes below that are within the programming of the Log.lik
> function they compile correctly!
> 
>    mu1 <- model.matrix(~X)%*%beta
>    mu2 <- model.matrix(~W)%*%gamma
> 
>    term0 <- (y-mu1)/sigma
>    term1 <- ((rho*(term0))+mu2)/sqrt(1-rho^2)
>    Phi_mu2 <- pnorm(mu2)
>    phi_t0 <- dnorm(term0)
>    phi_t1 <- dnorm(term1)
>    Phi_t0 <- pnorm(term0)
>    Phi_t1 <- pnorm(term1)
>    f <- (phi_t0*Phi_t1)/(sigma*Phi_mu2)
>    sum(ifelse(Y2>0,log(phi_t0)+log(Phi_t1)+log(1/sigma),log(1-Phi_mu2)))
> 
> 
> 
> 
> Fernando Bastos
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Mon Dec 12 00:18:00 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 12 Dec 2016 10:18:00 +1100
Subject: [R] Overlapping of arrow in PCA
In-Reply-To: <591052266.212849.1481353453109@mail.yahoo.com>
References: <591052266.212849.1481353453109.ref@mail.yahoo.com>
	<591052266.212849.1481353453109@mail.yahoo.com>
Message-ID: <CA+8X3fUaZG9SmxTBxkV7XGwmX12+9DKAhH16e9QpbZYcO8oKFg@mail.gmail.com>

Hi Tan Dai,
It looks like you have little or no variance in your measurements, and
so the result is degenerate. The functions you are using are probably
working properly, but there is nothing to display.

Jim


On Sat, Dec 10, 2016 at 6:04 PM, Tan Dai Chuan via R-help
<r-help at r-project.org> wrote:
> Hi, i face the problem as i attached in below. although i enlarge it, i still a straight and any solutions to solve it? Hope can get repsonse this few days. It is urgent.
>
> Thank you so much.
> Regards,Tan Dai Chuan
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From frederik at ofb.net  Mon Dec 12 02:35:22 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 11 Dec 2016 17:35:22 -0800
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
Message-ID: <20161212013522.GB20649@ofb.net>

Dear R-Help,

I was going to ask Jeff to read the entire works of William
Shakespeare to learn why his reply was not helpful to me...

Then I realized that the answer, as always, lies within...

    desub <- function(y) {
      e1=substitute(y, environment())
      e2=do.call(substitute,list(e1), env=parent.frame())
      deparse(e2)
    }

Sorry to trouble the list; other solutions still welcome.

Cheers,

Frederick

On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> No. Read Hadley Wickham's "Advanced R" to learn why not. 
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> >Dear R-Help,
> >
> >I asked this question on StackOverflow,
> >
> >http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex
> >
> >but thought perhaps R-help would be more appropriate.
> >
> >I want to write a function in R which grabs the name of a variable
> >from the context of its caller's caller. I think the problem I have is
> >best understood by asking how to compose `deparse` and `substitute`.
> >You can see that a naive composition does not work:
> >
> >    # a compose operator
> >    >  `%c%` = function(x,y)function(...)x(y(...))
> >
> >    # a naive attempt to combine deparse and substitute
> >    > desub = deparse %c% substitute
> >    > f=function(foo) { message(desub(foo)) }
> >    > f(log)
> >    foo
> >
> >    # this is how it is supposed to work
> >    > g=function(foo) { message(deparse(substitute(foo))) }
> >    > g(log)
> >    log
> >
> >Is there a way I can define a function `desub` so that `desub(x)` has
> >the same value as `deparse(substitute(x))` in every context?
> >
> >Thank you,
> >
> >Frederick Eaton
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Mon Dec 12 05:53:42 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 11 Dec 2016 20:53:42 -0800
Subject: [R] how do I define a function which is equivalent to
	`deparse(substitute(x))`?
In-Reply-To: <20161212013522.GB20649@ofb.net>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
Message-ID: <E1905089-105B-4BF7-BE88-9384AC54F627@comcast.net>


> On Dec 11, 2016, at 5:35 PM, frederik at ofb.net wrote:
> 
> Dear R-Help,
> 
> I was going to ask Jeff to read the entire works of William
> Shakespeare to learn why his reply was not helpful to me...

From a typical US 10th grade English assignment:

Cassius:
"The fault, dear Brutus, is not in our stars,
But in ourselves, that we are underlings."

-- 
David.
> 
> Then I realized that the answer, as always, lies within...
> 
>    desub <- function(y) {
>      e1=substitute(y, environment())
>      e2=do.call(substitute,list(e1), env=parent.frame())
>      deparse(e2)
>    }
> 
> Sorry to trouble the list; other solutions still welcome.
> 
> Cheers,
> 
> Frederick
> 
> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
>> No. Read Hadley Wickham's "Advanced R" to learn why not. 
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
>>> Dear R-Help,
>>> 
>>> I asked this question on StackOverflow,
>>> 
>>> http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex
>>> 
>>> but thought perhaps R-help would be more appropriate.
>>> 
>>> I want to write a function in R which grabs the name of a variable
>>> from the context of its caller's caller. I think the problem I have is
>>> best understood by asking how to compose `deparse` and `substitute`.
>>> You can see that a naive composition does not work:
>>> 
>>>   # a compose operator
>>>> `%c%` = function(x,y)function(...)x(y(...))
>>> 
>>>   # a naive attempt to combine deparse and substitute
>>>> desub = deparse %c% substitute
>>>> f=function(foo) { message(desub(foo)) }
>>>> f(log)
>>>   foo
>>> 
>>>   # this is how it is supposed to work
>>>> g=function(foo) { message(deparse(substitute(foo))) }
>>>> g(log)
>>>   log
>>> 
>>> Is there a way I can define a function `desub` so that `desub(x)` has
>>> the same value as `deparse(substitute(x))` in every context?
>>> 
>>> Thank you,
>>> 
>>> Frederick Eaton
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From frederik at ofb.net  Mon Dec 12 06:54:41 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 11 Dec 2016 21:54:41 -0800
Subject: [R] why does parent.frame() cycle when called from inside
 capture.output()?
Message-ID: <20161212055441.GA11787@ofb.net>

Hello R devel/help,

I ran into this strange behavior:

    # showstack is supposed to walk through the stack of parent
    # environments when it is called:
    showstack = function() {
      env = environment()
      for(i in 1:12) {
        env = do.call(parent.frame, list(), env=env)
        print(env)
      }
    }

    # a simple chain of functions:
    g3=function(t) showstack()
    g2=function(w) g3(w)
    g1=function(z) g2(z)
    g=function(y) g1(y)

    g()
    # outputs:
    # <environment: 0xb5ef810>
    # <environment: 0xb5ef6f8>
    # <environment: 0xb5ef5e0>
    # <environment: 0xb5ef4c8>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # ...

    cat(capture.output(g()),sep="\n")
    # outputs:
    # <environment: 0x8106a30>
    # <environment: 0x8106918>
    # <environment: 0x8106800>
    # <environment: 0x81066e8>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>

The strange thing of course is that the second call doesn't stay with
R_GlobalEnv, but in fact goes into a loop of period 4. I'm not so
surprised that the parent frame of the global environment is itself,
as in the first call, but it seems weird to have a loop of period 4...
Using `ls()` shows that two of the "loop" environments belong to
capture.output() and eval().

But if capture.output is really evaluating its input in the parent
frame, as it appears to be doing from its source code, then I would
have expected the output to be the same as the output I get by
evaluating the same expression in this frame.

I was trying to debug a function which attempts to be a multi-frame
version of deparse(substitute(...)). I'm attaching this function in
case anyone is curious. Perhaps my attachment can shed more light on
the problem I'm having.

Apologies if this is not a bug - I wasn't sure which mailing list to
send this to, and I took a guess.

Thanks,

Frederick
-------------- next part --------------
desubN <- function(y,n=1) {
  env=environment();
  for(i in 1:n) {
    y = do.call(substitute, list(substitute(y)), env=env)
    env = do.call(parent.frame, list(), env=env)
  }
  deparse(y)
}
g2=function(t) {
  for(i in 1:5) {
    print(desubN(t,i))
    print(capture.output(desubN(t,i)))
  }
}
g1=function(z) g2(z)
g=function(y) g1(y)

g(log)
# output: (why does it stop at "z"?)
## [1] "t"
## [1] "[1] \"t\""
## [1] "z"
## [1] "[1] \"z\""
## [1] "y"
## [1] "[1] \"z\""
## [1] "log"
## [1] "[1] \"z\""
## [1] "log"
## [1] "[1] \"z\""

From frederik at ofb.net  Mon Dec 12 06:55:48 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Sun, 11 Dec 2016 21:55:48 -0800
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <E1905089-105B-4BF7-BE88-9384AC54F627@comcast.net>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<E1905089-105B-4BF7-BE88-9384AC54F627@comcast.net>
Message-ID: <20161212055548.GB11787@ofb.net>

Thank you, that made me laugh :)

On Sun, Dec 11, 2016 at 08:53:42PM -0800, David Winsemius wrote:
> 
> > On Dec 11, 2016, at 5:35 PM, frederik at ofb.net wrote:
> > 
> > Dear R-Help,
> > 
> > I was going to ask Jeff to read the entire works of William
> > Shakespeare to learn why his reply was not helpful to me...
> 
> From a typical US 10th grade English assignment:
> 
> Cassius:
> "The fault, dear Brutus, is not in our stars,
> But in ourselves, that we are underlings."
> 
> -- 
> David.
> > 
> > Then I realized that the answer, as always, lies within...
> > 
> >    desub <- function(y) {
> >      e1=substitute(y, environment())
> >      e2=do.call(substitute,list(e1), env=parent.frame())
> >      deparse(e2)
> >    }
> > 
> > Sorry to trouble the list; other solutions still welcome.
> > 
> > Cheers,
> > 
> > Frederick
> > 
> > On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> >> No. Read Hadley Wickham's "Advanced R" to learn why not. 
> >> -- 
> >> Sent from my phone. Please excuse my brevity.
> >> 
> >> On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> >>> Dear R-Help,
> >>> 
> >>> I asked this question on StackOverflow,
> >>> 
> >>> http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex
> >>> 
> >>> but thought perhaps R-help would be more appropriate.
> >>> 
> >>> I want to write a function in R which grabs the name of a variable
> >>> from the context of its caller's caller. I think the problem I have is
> >>> best understood by asking how to compose `deparse` and `substitute`.
> >>> You can see that a naive composition does not work:
> >>> 
> >>>   # a compose operator
> >>>> `%c%` = function(x,y)function(...)x(y(...))
> >>> 
> >>>   # a naive attempt to combine deparse and substitute
> >>>> desub = deparse %c% substitute
> >>>> f=function(foo) { message(desub(foo)) }
> >>>> f(log)
> >>>   foo
> >>> 
> >>>   # this is how it is supposed to work
> >>>> g=function(foo) { message(deparse(substitute(foo))) }
> >>>> g(log)
> >>>   log
> >>> 
> >>> Is there a way I can define a function `desub` so that `desub(x)` has
> >>> the same value as `deparse(substitute(x))` in every context?
> >>> 
> >>> Thank you,
> >>> 
> >>> Frederick Eaton
> >>> 
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >> 
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
>


From frederik at ofb.net  Mon Dec 12 09:23:32 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 12 Dec 2016 00:23:32 -0800
Subject: [R] [RE: [Rd] why does parent.frame() cycle when called from inside
 capture.output()?]
In-Reply-To: <20161212055441.GA11787@ofb.net>
Message-ID: <20161212082332.GC11787@ofb.net>

Thanks, Mark - I'm taking up your invitation to forward your message
to the list just because it gives us some valuable data on (1) how
long the behavior has been around, and (2) how many other people
(don't) understand the behavior, and (3) how we might fix or work
around it.

I notice some other people also seem to be diffident about posting on
R-devel; perhaps I should conclude that bugs like this are below the
radar for busy statisticians.

FWIW, after playing around a bit with mvbutils::mvb.parent.frame, I
now have a working "desubN" (see the attachment on my original
message, and this one). I don't really have a good understanding of
*why* it now works, and why the original version didn't work...

Thanks again Mark. Also, nice hacking.

Frederick

----- Forwarded message from Mark.Bravington at data61.csiro.au -----

Date: Mon, 12 Dec 2016 06:20:17 +0000
From: Mark.Bravington at data61.csiro.au
To: frederik at ofb.net
Subject: RE: [Rd] why does parent.frame() cycle when called from inside
	capture.output()?
X-Spam-Status: No, score=-2.0 required=5.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,T_SPF_HELO_TEMPERROR,T_SPF_TEMPERROR autolearn=ham
	autolearn_force=no version=3.4.1
X-Spam-Level: 
X-My-Tags: inbox r-devel

Hi Frederik

[ I'm replying off-list in case you, or the rest of R-devel, don't find this reply useful... please fwd to the list if it does help you ]

I'm the author of the 'debug' package. When I wrote it--- many years ago now--- I encountered some fairly strange behaviour with frames in the call stack, which is reminiscent of what you're seeing. The debug package still works fine, so I presume nothing has changed much.

If you load debug and then do ?mvb.sys.parent (and look at the code), you might get *some* idea of what's going on. TBH I can't remember the details now...

HTH
Mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: R-devel [r-devel-bounces at r-project.org] on behalf of frederik at ofb.net [frederik at ofb.net]
Sent: 12 December 2016 16:54
To: r-devel at r-project.org
Cc: r-help at r-project.org
Subject: [Rd] why does parent.frame() cycle when called from inside capture.output()?

Hello R devel/help,

I ran into this strange behavior:

    # showstack is supposed to walk through the stack of parent
    # environments when it is called:
    showstack = function() {
      env = environment()
      for(i in 1:12) {
        env = do.call(parent.frame, list(), env=env)
        print(env)
      }
    }

    # a simple chain of functions:
    g3=function(t) showstack()
    g2=function(w) g3(w)
    g1=function(z) g2(z)
    g=function(y) g1(y)

    g()
    # outputs:
    # <environment: 0xb5ef810>
    # <environment: 0xb5ef6f8>
    # <environment: 0xb5ef5e0>
    # <environment: 0xb5ef4c8>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # ...

    cat(capture.output(g()),sep="\n")
    # outputs:
    # <environment: 0x8106a30>
    # <environment: 0x8106918>
    # <environment: 0x8106800>
    # <environment: 0x81066e8>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>

The strange thing of course is that the second call doesn't stay with
R_GlobalEnv, but in fact goes into a loop of period 4. I'm not so
surprised that the parent frame of the global environment is itself,
as in the first call, but it seems weird to have a loop of period 4...
Using `ls()` shows that two of the "loop" environments belong to
capture.output() and eval().

But if capture.output is really evaluating its input in the parent
frame, as it appears to be doing from its source code, then I would
have expected the output to be the same as the output I get by
evaluating the same expression in this frame.

I was trying to debug a function which attempts to be a multi-frame
version of deparse(substitute(...)). I'm attaching this function in
case anyone is curious. Perhaps my attachment can shed more light on
the problem I'm having.

Apologies if this is not a bug - I wasn't sure which mailing list to
send this to, and I took a guess.

Thanks,

Frederick


----- End forwarded message -----
-------------- next part --------------
# We can't just use `mvb.parent.frame` as a replacement for
# `parent.frame`, because the former throws an error when there is no
# parent frame - while we had relied on the latter gracefully giving
# us the global environment. So here's a wrapper which gives
# mvb.parent.frame the behavior we want:

my_mvb_parent=function() {
  tryCatch(
    mvb.parent.frame(2),
    error=function(e) { globalenv()})
}

desubN <- function(y,n=1) {
  env=environment();
  for(i in 1:n) {
    y = do.call(substitute, list(substitute(y)), env=env)
    env = do.call(my_mvb_parent, list(), env=env)
  }
  deparse(y)
}
g2=function(t) {
  for(i in 1:5) {
    print(desubN(t,i))
    print(capture.output(desubN(t,i)))
  }
}
g1=function(z) g2(z)
g=function(y) g1(y)

g(log)

# now capture.output seems to give the same results as the bare
# expression
## [1] "t"
## [1] "[1] \"t\""
## [1] "z"
## [1] "[1] \"z\""
## [1] "y"
## [1] "[1] \"y\""
## [1] "log"
## [1] "[1] \"log\""
## [1] "log"
## [1] "[1] \"log\""

From johanlarsson at outlook.com  Sun Dec 11 21:22:14 2016
From: johanlarsson at outlook.com (Johan Larsson)
Date: Sun, 11 Dec 2016 20:22:14 +0000
Subject: [R] [R-pkgs] Announcing eulerr 1.0.0
Message-ID: <AM5PR0801MB1732CB6901C67D5373ADBBF6C0990@AM5PR0801MB1732.eurprd08.prod.outlook.com>

Dear R users,



I would like to announce version 1.0.0 of eulerr (https://cran.r-project.org/package=eulerr). eulerr produces venn and euler diagrams for any number of sets. The user inputs a string of set relationships, for instance eulerr(c("A" = 10, "B" = 5, "A&B" = 2)), and out pops a specification for a euler diagram that can be plotted via eulerr.



For some set relationships, there is no perfect solution in the form of a euler diagram; in these cases, eulerr offers an approximation using numerical optimization and provides the user with diagnostics that reveal if the approximation can be trusted.



In this version, most of the optimization routines have been ported to C++ via Rcpp and RcppArmadillo, label placement has been improved, and additional loss functions for the optimization have been introduced. For a complete list of the updates, please see https://cran.r-project.org/package=eulerr/news.html



Finally, please visit the repository at https://github.com/jolars/eulerr if you are interested in contributing.



All the best,

Johan


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From acefix at rocketmail.com  Mon Dec 12 15:50:02 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Mon, 12 Dec 2016 14:50:02 +0000 (UTC)
Subject: [R] [FORGED]  help with gradient boxplot
In-Reply-To: <b83441fc-9b59-f42c-d650-b8247e6e91d2@stat.auckland.ac.nz>
References: <825389587.741141.1481055296512.ref@mail.yahoo.com>
	<825389587.741141.1481055296512@mail.yahoo.com>
	<a04e3d41-3e49-68ab-f14c-cffa38f4d8d9@stat.auckland.ac.nz>
	<1492163843.673701.1481235207181@mail.yahoo.com>
	<6b5f910f-03a8-a967-74b1-fa86b2cc8d8a@stat.auckland.ac.nz>
	<1667594422.52330.1481319588031@mail.yahoo.com>
	<b83441fc-9b59-f42c-d650-b8247e6e91d2@stat.auckland.ac.nz>
Message-ID: <251124452.1108440.1481554202093@mail.yahoo.com>

Hi, Paul,
Thank you so much for this further clarification!
Ace 

    On Sunday, December 11, 2016 2:09 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
 

 Hi

Great to hear you have it working.

Figuring out the names of grobs takes two things:

1. someone has to name the grobs
2. grid.ls()

The reason why I did my example using 'lattice' is because 'lattice' 
names all of its grobs.? There is a document ...

http://lattice.r-forge.r-project.org/Vignettes/src/naming-scheme/namingScheme.pdf

... that describes the 'lattice' naming scheme.

Paul

On 10/12/16 10:39, Fix Ace wrote:
> Hi, Paul,
>
> Thank you very much! It works this time with "strict=FALSE" option.
>
> Another relevant question:
>
> how did you figure out? that boxes in boxplot are called
> "bwplot.box.polygon". If I am trying to make a gradient filling for
> barplot of other plots, how would I define grobs?
>
> Thanks!!
>
> Ace
>
>
>
>
>
> On Thursday, December 8, 2016 5:24 PM, Paul Murrell
> <paul at stat.auckland.ac.nz> wrote:
>
>
> Hi
>
> You could try ...
>
> grid.export(..., strict=FALSE)
>
> ... and/or install the latest gridSVG version from R-Forge ...
>
> https://r-forge.r-project.org/R/?group_id=1025
>
> Paul
>
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


   
	[[alternative HTML version deleted]]


From faradj.g at gmail.com  Mon Dec 12 17:23:20 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Mon, 12 Dec 2016 17:23:20 +0100
Subject: [R] Log plus one transformation in R
Message-ID: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>

Hi all, 

How do I perform log(x+1) in R? 

log1p_trans() from the package ?scales" doesn?t seem to work for me. 

Best, 
Faradj

From jsorkin at grecc.umaryland.edu  Mon Dec 12 17:35:35 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 12 Dec 2016 11:35:35 -0500
Subject: [R] Log plus one transformation in R
In-Reply-To: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
Message-ID: <584E8B87020000CB0016981C@smtp.medicine.umaryland.edu>

Faradj,
 
I all you need to do is
 
newvalue <- log(x+1)


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Faradj Koliev <faradj.g at gmail.com> 12/12/16 11:24 AM >>>
Hi all, 

How do I perform log(x+1) in R? 

log1p_trans() from the package ?scales" doesn?t seem to work for me. 

Best, 
Faradj
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From spencer.graves at effectivedefense.org  Mon Dec 12 17:35:26 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Mon, 12 Dec 2016 10:35:26 -0600
Subject: [R] Log plus one transformation in R
In-Reply-To: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
Message-ID: <972ae3bc-b06d-6948-de68-44e5d71f29e1@effectivedefense.org>

       "?log" includes documentation for "log1p" in the base package


       Will that work?


       Spencer Graves


On 12/12/2016 10:23 AM, Faradj Koliev wrote:
> Hi all,
>
> How do I perform log(x+1) in R?
>
> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>
> Best,
> Faradj
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Dec 12 17:37:29 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Dec 2016 08:37:29 -0800
Subject: [R] Log plus one transformation in R
In-Reply-To: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
Message-ID: <CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>

log1p(x), in the base package computes log(1+x) accurately for small x (and
large).

E.g.,
> options(digits=16)
> base::log1p(1e-14)
[1] 9.99999999999995e-15
> base::log1p(1e-14) - base::log(1+1e-14)
[1] 7.992778373591124e-18
> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
precBits=1000))) - log1p(1e-14)
[1] 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com> wrote:

> Hi all,
>
> How do I perform log(x+1) in R?
>
> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>
> Best,
> Faradj
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Dec 12 17:39:44 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 12 Dec 2016 17:39:44 +0100
Subject: [R] Log plus one transformation in R
In-Reply-To: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
Message-ID: <22606.53968.425644.624715@stat.math.ethz.ch>

>>>>> Faradj Koliev <faradj.g at gmail.com>
>>>>>     on Mon, 12 Dec 2016 17:23:20 +0100 writes:

    > Hi all, How do I perform log(x+1) in R?

    > log1p_trans() from the package ?scales" doesn?t seem to
    > work for me.

amazing that you did not find  log1p()  in base R.


From jsorkin at grecc.umaryland.edu  Mon Dec 12 17:53:36 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 12 Dec 2016 11:53:36 -0500
Subject: [R] Log plus one transformation in R
In-Reply-To: <CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
Message-ID: <584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>

At the risk of being flamed . . .
What is the difference between log1p(x) and log(x+1)?
The two methods appear to give the same results:
> log1p(0.000001)/log(0.000001+1)
[1] 1
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
>>>
log1p(x), in the base package computes log(1+x) accurately for small x
(and
large).

E.g.,
> options(digits=16)
> base::log1p(1e-14)
[1] 9.99999999999995e-15
> base::log1p(1e-14) - base::log(1+1e-14)
[1] 7.992778373591124e-18
> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
precBits=1000))) - log1p(1e-14)
[1] 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
wrote:

> Hi all,
>
> How do I perform log(x+1) in R?
>
> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>
> Best,
> Faradj
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From dwinsemius at comcast.net  Mon Dec 12 18:05:34 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Dec 2016 09:05:34 -0800
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
Message-ID: <86587113-D978-4406-841D-547DB74FEACE@comcast.net>


> On Dec 12, 2016, at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> At the risk of being flamed . . .
> What is the difference between log1p(x) and log(x+1)?
> The two methods appear to give the same results:
>> log1p(0.000001)/log(0.000001+1)
> [1] 1
> John

Read the help page more carefully.

-- 
David.
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
>>>> 
> log1p(x), in the base package computes log(1+x) accurately for small x
> (and
> large).
> 
> E.g.,
>> options(digits=16)
>> base::log1p(1e-14)
> [1] 9.99999999999995e-15
>> base::log1p(1e-14) - base::log(1+1e-14)
> [1] 7.992778373591124e-18
>> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
> precBits=1000))) - log1p(1e-14)
> [1] 0
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
> wrote:
> 
>> Hi all,
>> 
>> How do I perform log(x+1) in R?
>> 
>> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>> 
>> Best,
>> Faradj
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From milujisb at gmail.com  Mon Dec 12 18:10:15 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Mon, 12 Dec 2016 18:10:15 +0100
Subject: [R] Reshape to wide format
Message-ID: <CAMLwc7O7kCZbeMXie8irri7Xn564VsSQ-pN2=Y8eGwqYWdXqBQ@mail.gmail.com>

Dear all,

I have the following monthly data by coordinates:

I would like to reshape this data to wide format so that each column is a
coordinate and each row is a month,

coordinate1 coordinate2 coordinate3...
Month 1
Month 2

Is the best option to concatenate the iso3, lon, and lat variables to
create an ID variable? I realize that this question might be very basic but
I'm slightly baffled. Thank you.

temp <- dput(head(precip_2000,20))
structure(list(iso3 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("AFG",
"AGO", "ALB", "ARE", "ARG", "ARM", "AUS", "AUT", "AZE", "BDI",
"BEL", "BEN", "BFA", "BGD", "BGR", "BHS", "BIH", "BLR", "BLZ",
"BOL", "BRA", "BRN", "BTN", "BWA", "CAF", "CAN", "CHE", "CHL",
"CHN", "CIV", "CMR", "COD", "COG", "COL", "CRI", "CUB", "CYP",
"CZE", "DEU", "DJI", "DNK", "DOM", "DZA", "ECU", "EGY", "ERI",
"ESH", "ESP", "EST", "ETH", "FIN", "FJI", "FLK", "FRA", "GAB",
"GBR", "GEO", "GHA", "GIN", "GNB", "GNQ", "GRC", "GRL", "GTM",
"GUF", "GUY", "HND", "HRV", "HTI", "HUN", "IDN", "IND", "IRL",
"IRN", "IRQ", "ISL", "ISR", "ITA", "JAM", "JOR", "JPN", "KAZ",
"KEN", "KGZ", "KHM", "KIR", "KOR", "KWT", "LAO", "LBN", "LBR",
"LBY", "LCA", "LKA", "LSO", "LTU", "LUX", "LVA", "MAR", "MDA",
"MDG", "MEX", "MKD", "MLI", "MMR", "MNE", "MNG", "MOZ", "MRT",
"MWI", "MYS", "NAM", "NCL", "NER", "NGA", "NIC", "NLD", "NOR",
"NPL", "NZL", "OMN", "PAK", "PAN", "PER", "PHL", "PNG", "POL",
"PRI", "PRK", "PRT", "PRY", "QAT", "ROU", "RUS", "RWA", "SAU",
"SDN", "SEN", "SJM", "SLB", "SLE", "SLV", "SOM", "SRB", "SUR",
"SVK", "SVN", "SWE", "SWZ", "SYR", "TCD", "TGO", "THA", "TJK",
"TKM", "TLS", "TUN", "TUR", "TWN", "TZA", "UGA", "UKR", "URY",
"USA", "UZB", "VEN", "VNM", "VUT", "YEM", "ZAF", "ZMB", "ZWE"
), class = "factor"), lon = c(61L, 61L, 61L, 61L, 61L, 61L, 61L,
61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L
), lat = c(32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L,
32L, 32L, 33L, 33L, 33L, 33L, 33L, 33L, 33L, 33L), dm = structure(c(1L,
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 1L, 5L, 6L, 7L,
8L, 9L, 10L, 11L), .Label = c("2000m1", "2000m10", "2000m11",
"2000m12", "2000m2", "2000m3", "2000m4", "2000m5", "2000m6",
"2000m7", "2000m8", "2000m9"), class = "factor"), month = c(1L,
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
5L, 6L, 7L, 8L), precip = c(0.996665806451613, 0.156711724137931,
0.242477419354839, 0, 0, 0, 0, 0, 0, 0, 0.121536, 0.38866064516129,
1.13312903225806, 0.355208275862069, 0.307277419354839, 0.008316,
0, 0, 0, 0.0008361290322581)), .Names = c("iso3", "lon", "lat",
"dm", "month", "precip"), row.names = c(NA, 20L), class = "data.frame")

Sincerely,

Milu

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Dec 12 18:23:22 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 12 Dec 2016 17:23:22 +0000
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
Message-ID: <bd218feb720c41ab983bdf68c5a2f2a9@exch-2p-mbx-t2.ads.tamu.edu>

The difference increases as the value gets closer to 0:

> dput(log1p(0.000001))
9.99999500000333e-07
> dput(log(1+0.000001))
9.99999499918067e-07

> dput(log1p(0.000001)/log(0.000001+1))
1.00000000008227
> dput(log1p(0.00000001)/log(0.00000001+1))
1.00000000607747
> dput(log1p(0.0000000001)/log(0.0000000001+1))
0.999999917259636
> dput(log1p(0.000000000001)/log(0.000000000001+1))
0.99991110732027
> dput(log1p(0.00000000000001)/log(0.00000000000001+1))
1.00079991719344

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of John Sorkin
Sent: Monday, December 12, 2016 10:54 AM
To: faradj.g at gmail.com; r-help at r-project.org; wdunlap at tibco.com
Subject: Re: [R] Log plus one transformation in R

At the risk of being flamed . . .
What is the difference between log1p(x) and log(x+1)?
The two methods appear to give the same results:
> log1p(0.000001)/log(0.000001+1)
[1] 1
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
>>>
log1p(x), in the base package computes log(1+x) accurately for small x
(and
large).

E.g.,
> options(digits=16)
> base::log1p(1e-14)
[1] 9.99999999999995e-15
> base::log1p(1e-14) - base::log(1+1e-14)
[1] 7.992778373591124e-18
> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
precBits=1000))) - log1p(1e-14)
[1] 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
wrote:

> Hi all,
>
> How do I perform log(x+1) in R?
>
> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>
> Best,
> Faradj
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
Confidentiality Statement:
This email message, including any attachments, is for the sole use of
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jsorkin at grecc.umaryland.edu  Mon Dec 12 18:26:17 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 12 Dec 2016 12:26:17 -0500
Subject: [R] Log plus one transformation in R
In-Reply-To: <86587113-D978-4406-841D-547DB74FEACE@comcast.net>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<86587113-D978-4406-841D-547DB74FEACE@comcast.net>
Message-ID: <584E9769020000CB00169845@smtp.medicine.umaryland.edu>

David,
 
I did read the help page. All it says is
log1p(x) computes log(1+x) accurately also for |x| << 1 (and less
accurately when x is approximately -1). 
This gives me pause. Does it mean that log(x) does not give accurate
results? If log1p gives more accurate values than log, why is the log
function not written to use the more accurate computation performed by
log1p. I don't believe I can look directly at the code for log and
log1p, so I need to rely on the kindness of others to explain the
differences between the computations performed by the functions. I guess
the test I ran, log1p(0.000001)/log(0.000001+1), did not have enough
precision to demonstrate a difference between the two functions.
John



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and
Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> David Winsemius <dwinsemius at comcast.net> 12/12/16 12:05 PM >>>

> On Dec 12, 2016, at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:
> 
> At the risk of being flamed . . .
> What is the difference between log1p(x) and log(x+1)?
> The two methods appear to give the same results:
>> log1p(0.000001)/log(0.000001+1)
> [1] 1
> John

Read the help page more carefully.

-- 
David.
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
>>>> 
> log1p(x), in the base package computes log(1+x) accurately for small x
> (and
> large).
> 
> E.g.,
>> options(digits=16)
>> base::log1p(1e-14)
> [1] 9.99999999999995e-15
>> base::log1p(1e-14) - base::log(1+1e-14)
> [1] 7.992778373591124e-18
>> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
> precBits=1000))) - log1p(1e-14)
> [1] 0
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
> wrote:
> 
>> Hi all,
>> 
>> How do I perform log(x+1) in R?
>> 
>> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>> 
>> Best,
>> Faradj
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> Confidentiality Statement:
> This email message, including any attachments, is for the sole use of
> the intended recipient(s) and may contain confidential and privileged
> information. Any unauthorized use, disclosure or distribution is
> prohibited. If you are not the intended recipient, please contact the
> sender by reply email and destroy all copies of the original message. 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
the intended recipient(s) and may contain confidential and privileged
information. Any unauthorized use, disclosure or distribution is
prohibited. If you are not the intended recipient, please contact the
sender by reply email and destroy all copies of the original message. 

From wdunlap at tibco.com  Mon Dec 12 18:26:53 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Dec 2016 09:26:53 -0800
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
Message-ID: <CAF8bMcahkOo4d+NjFos1naLraTqJ-kcQW4E7eFfbTfYUXWu_pQ@mail.gmail.com>

Print more digits of the quotient or subtract one from it and you will see
the difference:

> log1p(0.000001)/log(0.000001+1) - 1
[1] 8.22666379463044e-11


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 12, 2016 at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> At the risk of being flamed . . .
> What is the difference between log1p(x) and log(x+1)?
> The two methods appear to give the same results:
> > log1p(0.000001)/log(0.000001+1)
> [1] 1
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> >>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM >>>
> log1p(x), in the base package computes log(1+x) accurately for small x (and
> large).
>
> E.g.,
> > options(digits=16)
> > base::log1p(1e-14)
> [1] 9.99999999999995e-15
> > base::log1p(1e-14) - base::log(1+1e-14)
> [1] 7.992778373591124e-18
> > as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
> precBits=1000))) - log1p(1e-14)
> [1] 0
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com> wrote:
>
> > Hi all,
> >
> > How do I perform log(x+1) in R?
> >
> > log1p_trans() from the package ?scales" doesn?t seem to work for me.
> >
> > Best,
> > Faradj
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> *Confidentiality Statement:*
>
> This email message, including any attachments, is for ...{{dropped:10}}


From wdunlap at tibco.com  Mon Dec 12 18:29:13 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Dec 2016 09:29:13 -0800
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E9769020000CB00169845@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<86587113-D978-4406-841D-547DB74FEACE@comcast.net>
	<584E9769020000CB00169845@smtp.medicine.umaryland.edu>
Message-ID: <CAF8bMcanuCGhgjkjLT0LuEF91vLGctretq6nhN+DL=C2iBXHqQ@mail.gmail.com>

The problem is that 1+x does not give accurate results for small x:
    > (1+1e-17) == 1
   [1] TRUE


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Dec 12, 2016 at 9:26 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> David,
>
> I did read the help page. All it says is
>
> log1p(x) computes *log(1+x)* accurately also for *|x| << 1* (and less
> accurately when *x is approximately -1*).
>
> This gives me pause. Does it mean that log(x) does not give accurate
> results? If log1p gives more accurate values than log, why is the log
> function not written to use the more accurate computation performed by
> log1p. I don't believe I can look directly at the code for log and log1p,
> so I need to rely on the kindness of others to explain the differences
> between the computations performed by the functions. I guess the test I
> ran, log1p(0.000001)/log(0.000001+1), did not have enough precision to
> demonstrate a difference between the two functions.
>
> John
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> >>> David Winsemius <dwinsemius at comcast.net> 12/12/16 12:05 PM >>>
>
>
> > On Dec 12, 2016, at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
> wrote:
> >
> > At the risk of being flamed . . .
> > What is the difference between log1p(x) and log(x+1)?
> > The two methods appear to give the same results:
> >> log1p(0.000001)/log(0.000001+1)
> > [1] 1
> > John
>
> Read the help page more carefully.
>
> --
> David.
> >
> >
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and
> > Geriatric Medicine
> > Baltimore VA Medical Center
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
> >>>>
> > log1p(x), in the base package computes log(1+x) accurately for small x
> > (and
> > large).
> >
> > E.g.,
> >> options(digits=16)
> >> base::log1p(1e-14)
> > [1] 9.99999999999995e-15
> >> base::log1p(1e-14) - base::log(1+1e-14)
> > [1] 7.992778373591124e-18
> >> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
> > precBits=1000))) - log1p(1e-14)
> > [1] 0
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
> > wrote:
> >
> >> Hi all,
> >>
> >> How do I perform log(x+1) in R?
> >>
> >> log1p_trans() from the package ?scales" doesn?t seem to work for me.
> >>
> >> Best,
> >> Faradj
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > Confidentiality Statement:
> > This email message, including any attachments, is for the sole use of
> > the intended recipient(s) and may contain confidential and privileged
> > information. Any unauthorized use, disclosure or distribution is
> > prohibited. If you are not the intended recipient, please contact the
> > sender by reply email and destroy all copies of the original message.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>
>
> *Confidentiality Statement:*
>
> This email message, including any attachments, is for ...{{dropped:10}}


From dwinsemius at comcast.net  Mon Dec 12 18:50:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Dec 2016 09:50:44 -0800
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E9769020000CB00169845@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<86587113-D978-4406-841D-547DB74FEACE@comcast.net>
	<584E9769020000CB00169845@smtp.medicine.umaryland.edu>
Message-ID: <F5957B9E-B712-4CA8-BC79-19F59F2BB5EE@comcast.net>


> On Dec 12, 2016, at 9:26 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
> David,
>  
> I did read the help page. All it says is
> log1p(x) computes log(1+x) accurately also for |x| << 1 (and less accurately when x is approximately -1).

Not true. You evidently did not run the examples.

-- 
David.
> 
> This gives me pause. Does it mean that log(x) does not give accurate results? If log1p gives more accurate values than log, why is the log function not written to use the more accurate computation performed by log1p. I don't believe I can look directly at the code for log and log1p, so I need to rely on the kindness of others to explain the differences between the computations performed by the functions. I guess the test I ran, log1p(0.000001)/log(0.000001+1), did not have enough precision to demonstrate a difference between the two functions.
> 
> John
> 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> >>> David Winsemius <dwinsemius at comcast.net> 12/12/16 12:05 PM >>>
> 
> > On Dec 12, 2016, at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> > 
> > At the risk of being flamed . . .
> > What is the difference between log1p(x) and log(x+1)?
> > The two methods appear to give the same results:
> >> log1p(0.000001)/log(0.000001+1)
> > [1] 1
> > John
> 
> Read the help page more carefully.
> 
> -- 
> David.
> > 
> > 
> > John David Sorkin M.D., Ph.D.
> > Professor of Medicine
> > Chief, Biostatistics and Informatics
> > University of Maryland School of Medicine Division of Gerontology and
> > Geriatric Medicine
> > Baltimore VA Medical Center
> > 10 North Greene Street
> > GRECC (BT/18/GR)
> > Baltimore, MD 21201-1524
> > (Phone) 410-605-7119
> > (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> >>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
> >>>> 
> > log1p(x), in the base package computes log(1+x) accurately for small x
> > (and
> > large).
> > 
> > E.g.,
> >> options(digits=16)
> >> base::log1p(1e-14)
> > [1] 9.99999999999995e-15
> >> base::log1p(1e-14) - base::log(1+1e-14)
> > [1] 7.992778373591124e-18
> >> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
> > precBits=1000))) - log1p(1e-14)
> > [1] 0
> > 
> > 
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> > 
> > On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
> > wrote:
> > 
> >> Hi all,
> >> 
> >> How do I perform log(x+1) in R?
> >> 
> >> log1p_trans() from the package ?scales" doesn?t seem to work for me.
> >> 
> >> Best,
> >> Faradj
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> > 
> > [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> > Confidentiality Statement:
> > This email message, including any attachments, is for the sole use of
> > the intended recipient(s) and may contain confidential and privileged
> > information. Any unauthorized use, disclosure or distribution is
> > prohibited. If you are not the intended recipient, please contact the
> > sender by reply email and destroy all copies of the original message. 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 
> 
> Confidentiality Statement:
> 
> This email message, including any attachments, is for ...{{dropped:10}}


From jdnewmil at dcn.davis.ca.us  Mon Dec 12 18:58:08 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 12 Dec 2016 09:58:08 -0800
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E9769020000CB00169845@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<86587113-D978-4406-841D-547DB74FEACE@comcast.net>
	<584E9769020000CB00169845@smtp.medicine.umaryland.edu>
Message-ID: <B9FA9E15-5365-4718-979B-6C5A792436FA@dcn.davis.ca.us>

Numerical accuracy in floating point math is a much broader discussion than R, but [1] seems to summarize it reasonably well. There are whole courses on this topic at university. 

[1] http://www.johndcook.com/blog/2010/06/07/math-library-functions-that-seem-unnecessary/
-- 
Sent from my phone. Please excuse my brevity.

On December 12, 2016 9:26:17 AM PST, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>David,
> 
>I did read the help page. All it says is
>log1p(x) computes log(1+x) accurately also for |x| << 1 (and less
>accurately when x is approximately -1). 
>This gives me pause. Does it mean that log(x) does not give accurate
>results? If log1p gives more accurate values than log, why is the log
>function not written to use the more accurate computation performed by
>log1p. I don't believe I can look directly at the code for log and
>log1p, so I need to rely on the kindness of others to explain the
>differences between the computations performed by the functions. I
>guess
>the test I ran, log1p(0.000001)/log(0.000001+1), did not have enough
>precision to demonstrate a difference between the two functions.
>John
>
>
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>> David Winsemius <dwinsemius at comcast.net> 12/12/16 12:05 PM >>>
>
>> On Dec 12, 2016, at 8:53 AM, John Sorkin
><jsorkin at grecc.umaryland.edu>
>wrote:
>> 
>> At the risk of being flamed . . .
>> What is the difference between log1p(x) and log(x+1)?
>> The two methods appear to give the same results:
>>> log1p(0.000001)/log(0.000001+1)
>> [1] 1
>> John
>
>Read the help page more carefully.
>
>-- 
>David.
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM
>>>>> 
>> log1p(x), in the base package computes log(1+x) accurately for small
>x
>> (and
>> large).
>> 
>> E.g.,
>>> options(digits=16)
>>> base::log1p(1e-14)
>> [1] 9.99999999999995e-15
>>> base::log1p(1e-14) - base::log(1+1e-14)
>> [1] 7.992778373591124e-18
>>> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
>> precBits=1000))) - log1p(1e-14)
>> [1] 0
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com>
>> wrote:
>> 
>>> Hi all,
>>> 
>>> How do I perform log(x+1) in R?
>>> 
>>> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>>> 
>>> Best,
>>> Faradj
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> Confidentiality Statement:
>> This email message, including any attachments, is for the sole use of
>> the intended recipient(s) and may contain confidential and privileged
>> information. Any unauthorized use, disclosure or distribution is
>> prohibited. If you are not the intended recipient, please contact the
>> sender by reply email and destroy all copies of the original message.
>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>the intended recipient(s) and may contain confidential and privileged
>information. Any unauthorized use, disclosure or distribution is
>prohibited. If you are not the intended recipient, please contact the
>sender by reply email and destroy all copies of the original message. 
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Dec 12 22:54:17 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 12 Dec 2016 22:54:17 +0100
Subject: [R] Log plus one transformation in R
In-Reply-To: <CAF8bMcahkOo4d+NjFos1naLraTqJ-kcQW4E7eFfbTfYUXWu_pQ@mail.gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<CAF8bMcahkOo4d+NjFos1naLraTqJ-kcQW4E7eFfbTfYUXWu_pQ@mail.gmail.com>
Message-ID: <24DB7DA6-D8B2-44FE-A57A-77C2825C52B7@gmail.com>

And, for crying out loud... just try it with x = 1.234e-16 or so. One would think that the hint |x| << 1 was obvious enough.

-pd

> On 12 Dec 2016, at 18:26 , William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> Print more digits of the quotient or subtract one from it and you will see
> the difference:
> 
>> log1p(0.000001)/log(0.000001+1) - 1
> [1] 8.22666379463044e-11
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Mon, Dec 12, 2016 at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
> wrote:
> 
>> At the risk of being flamed . . .
>> What is the difference between log1p(x) and log(x+1)?
>> The two methods appear to give the same results:
>>> log1p(0.000001)/log(0.000001+1)
>> [1] 1
>> John
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>> 
>>>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM >>>
>> log1p(x), in the base package computes log(1+x) accurately for small x (and
>> large).
>> 
>> E.g.,
>>> options(digits=16)
>>> base::log1p(1e-14)
>> [1] 9.99999999999995e-15
>>> base::log1p(1e-14) - base::log(1+1e-14)
>> [1] 7.992778373591124e-18
>>> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
>> precBits=1000))) - log1p(1e-14)
>> [1] 0
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com> wrote:
>> 
>>> Hi all,
>>> 
>>> How do I perform log(x+1) in R?
>>> 
>>> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>>> 
>>> Best,
>>> Faradj
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> *Confidentiality Statement:*
>> 
>> This email message, including any attachments, is for ...{{dropped:10}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Mon Dec 12 23:07:06 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 12 Dec 2016 22:07:06 +0000
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <20161212013522.GB20649@ofb.net>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>

Dear Frederick,

I found this a challenging puzzle, and it took me awhile to come up with an alternative, and I think slightly simpler, solution:

> desub <- function(y) {
+     deparse(eval(substitute(substitute(y)), 
+                  env=parent.frame()))
+ }
 
> f <- function(x){
+     message(desub(x))
+ }

> f(log)
log

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox




> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> frederik at ofb.net
> Sent: December 11, 2016 8:35 PM
> To: r-help at r-project.org
> Subject: Re: [R] how do I define a function which is equivalent to
> `deparse(substitute(x))`?
> 
> Dear R-Help,
> 
> I was going to ask Jeff to read the entire works of William Shakespeare to learn
> why his reply was not helpful to me...
> 
> Then I realized that the answer, as always, lies within...
> 
>     desub <- function(y) {
>       e1=substitute(y, environment())
>       e2=do.call(substitute,list(e1), env=parent.frame())
>       deparse(e2)
>     }
> 
> Sorry to trouble the list; other solutions still welcome.
> 
> Cheers,
> 
> Frederick
> 
> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> > No. Read Hadley Wickham's "Advanced R" to learn why not.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> > >Dear R-Help,
> > >
> > >I asked this question on StackOverflow,
> > >
> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-fu
> > >nction-which-is-equivalent-to-deparsesubstitutex
> > >
> > >but thought perhaps R-help would be more appropriate.
> > >
> > >I want to write a function in R which grabs the name of a variable
> > >from the context of its caller's caller. I think the problem I have
> > >is best understood by asking how to compose `deparse` and `substitute`.
> > >You can see that a naive composition does not work:
> > >
> > >    # a compose operator
> > >    >  `%c%` = function(x,y)function(...)x(y(...))
> > >
> > >    # a naive attempt to combine deparse and substitute
> > >    > desub = deparse %c% substitute
> > >    > f=function(foo) { message(desub(foo)) }
> > >    > f(log)
> > >    foo
> > >
> > >    # this is how it is supposed to work
> > >    > g=function(foo) { message(deparse(substitute(foo))) }
> > >    > g(log)
> > >    log
> > >
> > >Is there a way I can define a function `desub` so that `desub(x)` has
> > >the same value as `deparse(substitute(x))` in every context?
> > >
> > >Thank you,
> > >
> > >Frederick Eaton
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From faradj.g at gmail.com  Mon Dec 12 23:17:38 2016
From: faradj.g at gmail.com (Faradj Koliev)
Date: Mon, 12 Dec 2016 23:17:38 +0100
Subject: [R] Log plus one transformation in R
In-Reply-To: <24DB7DA6-D8B2-44FE-A57A-77C2825C52B7@gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<CAF8bMcahkOo4d+NjFos1naLraTqJ-kcQW4E7eFfbTfYUXWu_pQ@mail.gmail.com>
	<24DB7DA6-D8B2-44FE-A57A-77C2825C52B7@gmail.com>
Message-ID: <396C7F91-7F42-41BF-8743-20E399197548@gmail.com>

Many thanks! 

logp1(x) worked just fine.

Best,
Faradj

Skickat fr?n min iPhone

> 12 dec. 2016 kl. 22:54 skrev peter dalgaard <pdalgd at gmail.com>:
> 
> And, for crying out loud... just try it with x = 1.234e-16 or so. One would think that the hint |x| << 1 was obvious enough.
> 
> -pd
> 
>> On 12 Dec 2016, at 18:26 , William Dunlap via R-help <r-help at r-project.org> wrote:
>> 
>> Print more digits of the quotient or subtract one from it and you will see
>> the difference:
>> 
>>> log1p(0.000001)/log(0.000001+1) - 1
>> [1] 8.22666379463044e-11
>> 
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> On Mon, Dec 12, 2016 at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>> wrote:
>> 
>>> At the risk of being flamed . . .
>>> What is the difference between log1p(x) and log(x+1)?
>>> The two methods appear to give the same results:
>>>> log1p(0.000001)/log(0.000001+1)
>>> [1] 1
>>> John
>>> 
>>> 
>>> John David Sorkin M.D., Ph.D.
>>> Professor of Medicine
>>> Chief, Biostatistics and Informatics
>>> University of Maryland School of Medicine Division of Gerontology and
>>> Geriatric Medicine
>>> Baltimore VA Medical Center
>>> 10 North Greene Street
>>> GRECC (BT/18/GR)
>>> Baltimore, MD 21201-1524
>>> (Phone) 410-605-7119
>>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>> 
>>>>>> William Dunlap via R-help <r-help at r-project.org> 12/12/16 11:38 AM >>>
>>> log1p(x), in the base package computes log(1+x) accurately for small x (and
>>> large).
>>> 
>>> E.g.,
>>>> options(digits=16)
>>>> base::log1p(1e-14)
>>> [1] 9.99999999999995e-15
>>>> base::log1p(1e-14) - base::log(1+1e-14)
>>> [1] 7.992778373591124e-18
>>>> as.numeric(log(Rmpfr::mpfr(1,precBits=1000) + Rmpfr::mpfr(1e-14,
>>> precBits=1000))) - log1p(1e-14)
>>> [1] 0
>>> 
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>>> On Mon, Dec 12, 2016 at 8:23 AM, Faradj Koliev <faradj.g at gmail.com> wrote:
>>>> 
>>>> Hi all,
>>>> 
>>>> How do I perform log(x+1) in R?
>>>> 
>>>> log1p_trans() from the package ?scales" doesn?t seem to work for me.
>>>> 
>>>> Best,
>>>> Faradj
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>>   [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> *Confidentiality Statement:*
>>> 
>>> This email message, including any attachments, is for ...{{dropped:10}}
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 


From dwinsemius at comcast.net  Mon Dec 12 23:54:14 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Dec 2016 14:54:14 -0800
Subject: [R] how do I define a function which is equivalent to
	`deparse(substitute(x))`?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <12F7E3A9-AAE3-423F-973D-1E52E7D11A91@comcast.net>


> On Dec 12, 2016, at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
> 
> Dear Frederick,
> 
> I found this a challenging puzzle, and it took me awhile to come up with an alternative, and I think slightly simpler, solution:
> 
>> desub <- function(y) {
> +     deparse(eval(substitute(substitute(y)), 
> +                  env=parent.frame()))
> + }
> 
>> f <- function(x){
> +     message(desub(x))
> + }
> 
>> f(log)
> log

Exactly the same answer as the crossposting elicited:

http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex

-- 
David
> 
> Best,
> John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> frederik at ofb.net
>> Sent: December 11, 2016 8:35 PM
>> To: r-help at r-project.org
>> Subject: Re: [R] how do I define a function which is equivalent to
>> `deparse(substitute(x))`?
>> 
>> Dear R-Help,
>> 
>> I was going to ask Jeff to read the entire works of William Shakespeare to learn
>> why his reply was not helpful to me...
>> 
>> Then I realized that the answer, as always, lies within...
>> 
>>    desub <- function(y) {
>>      e1=substitute(y, environment())
>>      e2=do.call(substitute,list(e1), env=parent.frame())
>>      deparse(e2)
>>    }
>> 
>> Sorry to trouble the list; other solutions still welcome.
>> 
>> Cheers,
>> 
>> Frederick
>> 
>> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
>>> No. Read Hadley Wickham's "Advanced R" to learn why not.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
>>>> Dear R-Help,
>>>> 
>>>> I asked this question on StackOverflow,
>>>> 
>>>> http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-fu
>>>> nction-which-is-equivalent-to-deparsesubstitutex
>>>> 
>>>> but thought perhaps R-help would be more appropriate.
>>>> 
>>>> I want to write a function in R which grabs the name of a variable
>>>> from the context of its caller's caller. I think the problem I have
>>>> is best understood by asking how to compose `deparse` and `substitute`.
>>>> You can see that a naive composition does not work:
>>>> 
>>>>   # a compose operator
>>>>> `%c%` = function(x,y)function(...)x(y(...))
>>>> 
>>>>   # a naive attempt to combine deparse and substitute
>>>>> desub = deparse %c% substitute
>>>>> f=function(foo) { message(desub(foo)) }
>>>>> f(log)
>>>>   foo
>>>> 
>>>>   # this is how it is supposed to work
>>>>> g=function(foo) { message(deparse(substitute(foo))) }
>>>>> g(log)
>>>>   log
>>>> 
>>>> Is there a way I can define a function `desub` so that `desub(x)` has
>>>> the same value as `deparse(substitute(x))` in every context?
>>>> 
>>>> Thank you,
>>>> 
>>>> Frederick Eaton
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Tue Dec 13 00:41:28 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Dec 2016 15:41:28 -0800
Subject: [R] how do I define a function which is equivalent to
	`deparse(substitute(x))`?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>

*If* I understand correctly -- and please let me know if I don't --
this seems somewhat more straightforward and less "hacky" :

> desub <- function(x) as.name(all.vars(sys.call(-1)))

Yielding in the OP's example:

> g <- function(y)desub(y)
> g(log)
log

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 12, 2016 at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
> Dear Frederick,
>
> I found this a challenging puzzle, and it took me awhile to come up with an alternative, and I think slightly simpler, solution:
>
>> desub <- function(y) {
> +     deparse(eval(substitute(substitute(y)),
> +                  env=parent.frame()))
> + }
>
>> f <- function(x){
> +     message(desub(x))
> + }
>
>> f(log)
> log
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> frederik at ofb.net
>> Sent: December 11, 2016 8:35 PM
>> To: r-help at r-project.org
>> Subject: Re: [R] how do I define a function which is equivalent to
>> `deparse(substitute(x))`?
>>
>> Dear R-Help,
>>
>> I was going to ask Jeff to read the entire works of William Shakespeare to learn
>> why his reply was not helpful to me...
>>
>> Then I realized that the answer, as always, lies within...
>>
>>     desub <- function(y) {
>>       e1=substitute(y, environment())
>>       e2=do.call(substitute,list(e1), env=parent.frame())
>>       deparse(e2)
>>     }
>>
>> Sorry to trouble the list; other solutions still welcome.
>>
>> Cheers,
>>
>> Frederick
>>
>> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
>> > No. Read Hadley Wickham's "Advanced R" to learn why not.
>> > --
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
>> > >Dear R-Help,
>> > >
>> > >I asked this question on StackOverflow,
>> > >
>> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-fu
>> > >nction-which-is-equivalent-to-deparsesubstitutex
>> > >
>> > >but thought perhaps R-help would be more appropriate.
>> > >
>> > >I want to write a function in R which grabs the name of a variable
>> > >from the context of its caller's caller. I think the problem I have
>> > >is best understood by asking how to compose `deparse` and `substitute`.
>> > >You can see that a naive composition does not work:
>> > >
>> > >    # a compose operator
>> > >    >  `%c%` = function(x,y)function(...)x(y(...))
>> > >
>> > >    # a naive attempt to combine deparse and substitute
>> > >    > desub = deparse %c% substitute
>> > >    > f=function(foo) { message(desub(foo)) }
>> > >    > f(log)
>> > >    foo
>> > >
>> > >    # this is how it is supposed to work
>> > >    > g=function(foo) { message(deparse(substitute(foo))) }
>> > >    > g(log)
>> > >    log
>> > >
>> > >Is there a way I can define a function `desub` so that `desub(x)` has
>> > >the same value as `deparse(substitute(x))` in every context?
>> > >
>> > >Thank you,
>> > >
>> > >Frederick Eaton
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Tue Dec 13 00:58:00 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 12 Dec 2016 23:58:00 +0000
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365A844B@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bert,

It's nitpicking, I guess, but the call to message() is in the original posting. Your solution produces

> desub <- function(x) as.name(all.vars(sys.call(-1)))

> f <- function(x){
+     message(desub(x))
+ }

> f(log)
x

Best,
 John

> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Monday, December 12, 2016 6:41 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: frederik at ofb.net; r-help at r-project.org
> Subject: Re: [R] how do I define a function which is equivalent to
> `deparse(substitute(x))`?
> 
> *If* I understand correctly -- and please let me know if I don't -- this
> seems somewhat more straightforward and less "hacky" :
> 
> > desub <- function(x) as.name(all.vars(sys.call(-1)))
> 
> Yielding in the OP's example:
> 
> > g <- function(y)desub(y)
> > g(log)
> log
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Dec 12, 2016 at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > Dear Frederick,
> >
> > I found this a challenging puzzle, and it took me awhile to come up
> with an alternative, and I think slightly simpler, solution:
> >
> >> desub <- function(y) {
> > +     deparse(eval(substitute(substitute(y)),
> > +                  env=parent.frame())) }
> >
> >> f <- function(x){
> > +     message(desub(x))
> > + }
> >
> >> f(log)
> > log
> >
> > Best,
> >  John
> >
> > -----------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario
> > Canada L8S 4M4
> > Web: socserv.mcmaster.ca/jfox
> >
> >
> >
> >
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> frederik at ofb.net
> >> Sent: December 11, 2016 8:35 PM
> >> To: r-help at r-project.org
> >> Subject: Re: [R] how do I define a function which is equivalent to
> >> `deparse(substitute(x))`?
> >>
> >> Dear R-Help,
> >>
> >> I was going to ask Jeff to read the entire works of William
> >> Shakespeare to learn why his reply was not helpful to me...
> >>
> >> Then I realized that the answer, as always, lies within...
> >>
> >>     desub <- function(y) {
> >>       e1=substitute(y, environment())
> >>       e2=do.call(substitute,list(e1), env=parent.frame())
> >>       deparse(e2)
> >>     }
> >>
> >> Sorry to trouble the list; other solutions still welcome.
> >>
> >> Cheers,
> >>
> >> Frederick
> >>
> >> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> >> > No. Read Hadley Wickham's "Advanced R" to learn why not.
> >> > --
> >> > Sent from my phone. Please excuse my brevity.
> >> >
> >> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> >> > >Dear R-Help,
> >> > >
> >> > >I asked this question on StackOverflow,
> >> > >
> >> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a
> >> > >-fu nction-which-is-equivalent-to-deparsesubstitutex
> >> > >
> >> > >but thought perhaps R-help would be more appropriate.
> >> > >
> >> > >I want to write a function in R which grabs the name of a variable
> >> > >from the context of its caller's caller. I think the problem I
> >> > >have is best understood by asking how to compose `deparse` and
> `substitute`.
> >> > >You can see that a naive composition does not work:
> >> > >
> >> > >    # a compose operator
> >> > >    >  `%c%` = function(x,y)function(...)x(y(...))
> >> > >
> >> > >    # a naive attempt to combine deparse and substitute
> >> > >    > desub = deparse %c% substitute
> >> > >    > f=function(foo) { message(desub(foo)) }
> >> > >    > f(log)
> >> > >    foo
> >> > >
> >> > >    # this is how it is supposed to work
> >> > >    > g=function(foo) { message(deparse(substitute(foo))) }
> >> > >    > g(log)
> >> > >    log
> >> > >
> >> > >Is there a way I can define a function `desub` so that `desub(x)`
> >> > >has the same value as `deparse(substitute(x))` in every context?
> >> > >
> >> > >Thank you,
> >> > >
> >> > >Frederick Eaton
> >> > >
> >> > >______________________________________________
> >> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > >https://stat.ethz.ch/mailman/listinfo/r-help
> >> > >PLEASE do read the posting guide
> >> > >http://www.R-project.org/posting-guide.html
> >> > >and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From bgunter.4567 at gmail.com  Tue Dec 13 01:25:57 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Dec 2016 16:25:57 -0800
Subject: [R] how do I define a function which is equivalent to
	`deparse(substitute(x))`?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365A844B@FHSDB2D11-2.csu.mcmaster.ca>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A844B@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAGxFJbQmZgwrm1nrU0tCdbdytA=qLiesJHTxLukSDywXv9ioUw@mail.gmail.com>

John. et. al:

I assumed the message call was there to convert a quoted string to an
unquoted name and simply did this with as.name() in desub(). The point
of using sys.call() is that you can go up the call stack as far as you
need, so if you want to leave in the message() call, just go one
farther up the call stack:

> desub <- function(x) (all.vars(sys.call(-2))) ## note the -2 now

> g <- function(y)message((desub(y)))
> g(log)
log


-- Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 12, 2016 at 3:58 PM, Fox, John <jfox at mcmaster.ca> wrote:
> Dear Bert,
>
> It's nitpicking, I guess, but the call to message() is in the original posting. Your solution produces
>
>> desub <- function(x) as.name(all.vars(sys.call(-1)))
>
>> f <- function(x){
> +     message(desub(x))
> + }
>
>> f(log)
> x
>
> Best,
>  John
>
>> -----Original Message-----
>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> Sent: Monday, December 12, 2016 6:41 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: frederik at ofb.net; r-help at r-project.org
>> Subject: Re: [R] how do I define a function which is equivalent to
>> `deparse(substitute(x))`?
>>
>> *If* I understand correctly -- and please let me know if I don't -- this
>> seems somewhat more straightforward and less "hacky" :
>>
>> > desub <- function(x) as.name(all.vars(sys.call(-1)))
>>
>> Yielding in the OP's example:
>>
>> > g <- function(y)desub(y)
>> > g(log)
>> log
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Dec 12, 2016 at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
>> > Dear Frederick,
>> >
>> > I found this a challenging puzzle, and it took me awhile to come up
>> with an alternative, and I think slightly simpler, solution:
>> >
>> >> desub <- function(y) {
>> > +     deparse(eval(substitute(substitute(y)),
>> > +                  env=parent.frame())) }
>> >
>> >> f <- function(x){
>> > +     message(desub(x))
>> > + }
>> >
>> >> f(log)
>> > log
>> >
>> > Best,
>> >  John
>> >
>> > -----------------------------
>> > John Fox, Professor
>> > McMaster University
>> > Hamilton, Ontario
>> > Canada L8S 4M4
>> > Web: socserv.mcmaster.ca/jfox
>> >
>> >
>> >
>> >
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> >> frederik at ofb.net
>> >> Sent: December 11, 2016 8:35 PM
>> >> To: r-help at r-project.org
>> >> Subject: Re: [R] how do I define a function which is equivalent to
>> >> `deparse(substitute(x))`?
>> >>
>> >> Dear R-Help,
>> >>
>> >> I was going to ask Jeff to read the entire works of William
>> >> Shakespeare to learn why his reply was not helpful to me...
>> >>
>> >> Then I realized that the answer, as always, lies within...
>> >>
>> >>     desub <- function(y) {
>> >>       e1=substitute(y, environment())
>> >>       e2=do.call(substitute,list(e1), env=parent.frame())
>> >>       deparse(e2)
>> >>     }
>> >>
>> >> Sorry to trouble the list; other solutions still welcome.
>> >>
>> >> Cheers,
>> >>
>> >> Frederick
>> >>
>> >> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
>> >> > No. Read Hadley Wickham's "Advanced R" to learn why not.
>> >> > --
>> >> > Sent from my phone. Please excuse my brevity.
>> >> >
>> >> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
>> >> > >Dear R-Help,
>> >> > >
>> >> > >I asked this question on StackOverflow,
>> >> > >
>> >> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a
>> >> > >-fu nction-which-is-equivalent-to-deparsesubstitutex
>> >> > >
>> >> > >but thought perhaps R-help would be more appropriate.
>> >> > >
>> >> > >I want to write a function in R which grabs the name of a variable
>> >> > >from the context of its caller's caller. I think the problem I
>> >> > >have is best understood by asking how to compose `deparse` and
>> `substitute`.
>> >> > >You can see that a naive composition does not work:
>> >> > >
>> >> > >    # a compose operator
>> >> > >    >  `%c%` = function(x,y)function(...)x(y(...))
>> >> > >
>> >> > >    # a naive attempt to combine deparse and substitute
>> >> > >    > desub = deparse %c% substitute
>> >> > >    > f=function(foo) { message(desub(foo)) }
>> >> > >    > f(log)
>> >> > >    foo
>> >> > >
>> >> > >    # this is how it is supposed to work
>> >> > >    > g=function(foo) { message(deparse(substitute(foo))) }
>> >> > >    > g(log)
>> >> > >    log
>> >> > >
>> >> > >Is there a way I can define a function `desub` so that `desub(x)`
>> >> > >has the same value as `deparse(substitute(x))` in every context?
>> >> > >
>> >> > >Thank you,
>> >> > >
>> >> > >Frederick Eaton
>> >> > >
>> >> > >______________________________________________
>> >> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > >PLEASE do read the posting guide
>> >> > >http://www.R-project.org/posting-guide.html
>> >> > >and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Tue Dec 13 01:51:24 2016
From: valkremk at gmail.com (Val)
Date: Mon, 12 Dec 2016 18:51:24 -0600
Subject: [R] output
Message-ID: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>

Hi all,

I have a data frame with more than 100,000 rows.

datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
dat <- datx(110000,10,2)

1)
WriteXLS(dat, "test4.xls", row.names=FALSE)
Error in WriteXLS(dat, "test4.xls", row.names = FALSE) :
  One or more of the data frames named in 'x' exceeds 65,535 rows or 256 columns

I noticed that *.xls has  row and column limitations.

How can I take the excess row to the next sheet?

2) I also tried to use xlsx and have a problem

write.xlsx(dat, "test3.xlsx",sheetName="sheet1", row.names=FALSE)
Error in .jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook") :
  java.lang.OutOfMemoryError: Java heap
space.jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook")<S4 object of
class "jobjRef">

Any help ?
Thank you in advance


From jfox at mcmaster.ca  Tue Dec 13 02:45:12 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 13 Dec 2016 01:45:12 +0000
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <CAGxFJbQmZgwrm1nrU0tCdbdytA=qLiesJHTxLukSDywXv9ioUw@mail.gmail.com>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A844B@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbQmZgwrm1nrU0tCdbdytA=qLiesJHTxLukSDywXv9ioUw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365A8503@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bert,

Your current version satisfies the original posting, but, though simpler than mine, is a bit fragile, in the following sense:

> desub <- function(x) (all.vars(sys.call(-2)))

> f <- function(x){
+     message(desub(x))
+ }

> f(log)
log

> g <- function(x){
+     desub(x)
+ }

> g(log)
character(0)


My version:

> desub <- function(y) {
+     deparse(eval(substitute(substitute(y)), 
+                  env=parent.frame()))
+ }

> f(log)
log

> g(log)
[1] "log"

The deparse(substitute()) idiom returns the argument to f() or g() as a character string and so desub() should too, I guess.

Best,
 John

> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: December 12, 2016 7:26 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: frederik at ofb.net; r-help at r-project.org
> Subject: Re: [R] how do I define a function which is equivalent to
> `deparse(substitute(x))`?
> 
> John. et. al:
> 
> I assumed the message call was there to convert a quoted string to an
> unquoted name and simply did this with as.name() in desub(). The point of
> using sys.call() is that you can go up the call stack as far as you need, so if you
> want to leave in the message() call, just go one farther up the call stack:
> 
> > desub <- function(x) (all.vars(sys.call(-2))) ## note the -2 now
> 
> > g <- function(y)message((desub(y)))
> > g(log)
> log
> 
> 
> -- Bert
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Dec 12, 2016 at 3:58 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > Dear Bert,
> >
> > It's nitpicking, I guess, but the call to message() is in the original
> > posting. Your solution produces
> >
> >> desub <- function(x) as.name(all.vars(sys.call(-1)))
> >
> >> f <- function(x){
> > +     message(desub(x))
> > + }
> >
> >> f(log)
> > x
> >
> > Best,
> >  John
> >
> >> -----Original Message-----
> >> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> >> Sent: Monday, December 12, 2016 6:41 PM
> >> To: Fox, John <jfox at mcmaster.ca>
> >> Cc: frederik at ofb.net; r-help at r-project.org
> >> Subject: Re: [R] how do I define a function which is equivalent to
> >> `deparse(substitute(x))`?
> >>
> >> *If* I understand correctly -- and please let me know if I don't --
> >> this seems somewhat more straightforward and less "hacky" :
> >>
> >> > desub <- function(x) as.name(all.vars(sys.call(-1)))
> >>
> >> Yielding in the OP's example:
> >>
> >> > g <- function(y)desub(y)
> >> > g(log)
> >> log
> >>
> >> Cheers,
> >> Bert
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming
> >> along and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, Dec 12, 2016 at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
> >> > Dear Frederick,
> >> >
> >> > I found this a challenging puzzle, and it took me awhile to come up
> >> with an alternative, and I think slightly simpler, solution:
> >> >
> >> >> desub <- function(y) {
> >> > +     deparse(eval(substitute(substitute(y)),
> >> > +                  env=parent.frame())) }
> >> >
> >> >> f <- function(x){
> >> > +     message(desub(x))
> >> > + }
> >> >
> >> >> f(log)
> >> > log
> >> >
> >> > Best,
> >> >  John
> >> >
> >> > -----------------------------
> >> > John Fox, Professor
> >> > McMaster University
> >> > Hamilton, Ontario
> >> > Canada L8S 4M4
> >> > Web: socserv.mcmaster.ca/jfox
> >> >
> >> >
> >> >
> >> >
> >> >> -----Original Message-----
> >> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> >> frederik at ofb.net
> >> >> Sent: December 11, 2016 8:35 PM
> >> >> To: r-help at r-project.org
> >> >> Subject: Re: [R] how do I define a function which is equivalent to
> >> >> `deparse(substitute(x))`?
> >> >>
> >> >> Dear R-Help,
> >> >>
> >> >> I was going to ask Jeff to read the entire works of William
> >> >> Shakespeare to learn why his reply was not helpful to me...
> >> >>
> >> >> Then I realized that the answer, as always, lies within...
> >> >>
> >> >>     desub <- function(y) {
> >> >>       e1=substitute(y, environment())
> >> >>       e2=do.call(substitute,list(e1), env=parent.frame())
> >> >>       deparse(e2)
> >> >>     }
> >> >>
> >> >> Sorry to trouble the list; other solutions still welcome.
> >> >>
> >> >> Cheers,
> >> >>
> >> >> Frederick
> >> >>
> >> >> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> >> >> > No. Read Hadley Wickham's "Advanced R" to learn why not.
> >> >> > --
> >> >> > Sent from my phone. Please excuse my brevity.
> >> >> >
> >> >> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> >> >> > >Dear R-Help,
> >> >> > >
> >> >> > >I asked this question on StackOverflow,
> >> >> > >
> >> >> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-defin
> >> >> > >e-a -fu nction-which-is-equivalent-to-deparsesubstitutex
> >> >> > >
> >> >> > >but thought perhaps R-help would be more appropriate.
> >> >> > >
> >> >> > >I want to write a function in R which grabs the name of a
> >> >> > >variable from the context of its caller's caller. I think the
> >> >> > >problem I have is best understood by asking how to compose
> >> >> > >`deparse` and
> >> `substitute`.
> >> >> > >You can see that a naive composition does not work:
> >> >> > >
> >> >> > >    # a compose operator
> >> >> > >    >  `%c%` = function(x,y)function(...)x(y(...))
> >> >> > >
> >> >> > >    # a naive attempt to combine deparse and substitute
> >> >> > >    > desub = deparse %c% substitute
> >> >> > >    > f=function(foo) { message(desub(foo)) }
> >> >> > >    > f(log)
> >> >> > >    foo
> >> >> > >
> >> >> > >    # this is how it is supposed to work
> >> >> > >    > g=function(foo) { message(deparse(substitute(foo))) }
> >> >> > >    > g(log)
> >> >> > >    log
> >> >> > >
> >> >> > >Is there a way I can define a function `desub` so that
> >> >> > >`desub(x)` has the same value as `deparse(substitute(x))` in every
> context?
> >> >> > >
> >> >> > >Thank you,
> >> >> > >
> >> >> > >Frederick Eaton
> >> >> > >
> >> >> > >______________________________________________
> >> >> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >> > >see https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > >PLEASE do read the posting guide
> >> >> > >http://www.R-project.org/posting-guide.html
> >> >> > >and provide commented, minimal, self-contained, reproducible code.
> >> >> >
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Tue Dec 13 03:32:19 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 12 Dec 2016 18:32:19 -0800
Subject: [R] output
In-Reply-To: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
References: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
Message-ID: <A2C66E1F-55B5-4036-8ED4-F73F8C9B43AA@dcn.davis.ca.us>

1) I recommend against using xls for very large data sets. (Not that xlsx is really that much better.) If you really think this is necessary you will probably need to split the data frame and write each element of the resulting list. See ?split.

2) Google tells me (as it could have told you) that you could choose another package or increase your memory allocation to java. [1] If you encounter bugs in packages, don't forget to use the maintainer() function as mentioned in the Posting Guide. 

[1] http://stackoverflow.com/questions/19147884/importing-a-big-xlsx-file-into-r
-- 
Sent from my phone. Please excuse my brevity.

On December 12, 2016 4:51:24 PM PST, Val <valkremk at gmail.com> wrote:
>Hi all,
>
>I have a data frame with more than 100,000 rows.
>
>datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
>dat <- datx(110000,10,2)
>
>1)
>WriteXLS(dat, "test4.xls", row.names=FALSE)
>Error in WriteXLS(dat, "test4.xls", row.names = FALSE) :
>One or more of the data frames named in 'x' exceeds 65,535 rows or 256
>columns
>
>I noticed that *.xls has  row and column limitations.
>
>How can I take the excess row to the next sheet?
>
>2) I also tried to use xlsx and have a problem
>
>write.xlsx(dat, "test3.xlsx",sheetName="sheet1", row.names=FALSE)
>Error in .jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook") :
>  java.lang.OutOfMemoryError: Java heap
>space.jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook")<S4 object of
>class "jobjRef">
>
>Any help ?
>Thank you in advance
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Mark.Bravington at data61.csiro.au  Mon Dec 12 23:36:00 2016
From: Mark.Bravington at data61.csiro.au (Mark.Bravington at data61.csiro.au)
Date: Mon, 12 Dec 2016 22:36:00 +0000
Subject: [R] [RE: [Rd] why does parent.frame() cycle when called from
 inside capture.output()?]
In-Reply-To: <20161212082332.GC11787@ofb.net>
References: <20161212055441.GA11787@ofb.net>,<20161212082332.GC11787@ofb.net>
Message-ID: <4aea0ecaeaa448c29e6c2b2b99d403fb@exch1-cdc.nexus.csiro.au>

Hi Frederik

Goodo, glad you found mvbutils::mvb.parent.frame useful. I had forgotten that it's in mvbutils rather than debug package. This all dates back about 15 years...

To be fair, I don't think R's behaviour with duplicated-but-aliased frames in the call stack is a "bug"--- everything normal just works--- and it's not something to be "fixed" IMO, since it's clearly built-in by design and who knows what else would break if it got changed? But, working round it is indeed sometimes necessary...

[ BTW I'm not particularly diffident about posting to R-devel--- eg here I am!--- but I'm generally too busy to check out my own answers thoroughly, so rather than risk opening up blind alleys, I tend to suggest things off-list. In the cases where I'm sure that I do have a good answer, someone else has already usually responded... ]

bye
mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: frederik at ofb.net [frederik at ofb.net]
Sent: 12 December 2016 19:23
To: R-devel at r-project.org
Cc: Bravington, Mark (Data61, Hobart); r-help at r-project.org
Subject: [RE: [Rd] why does parent.frame() cycle when called from inside capture.output()?]

Thanks, Mark - I'm taking up your invitation to forward your message
to the list just because it gives us some valuable data on (1) how
long the behavior has been around, and (2) how many other people
(don't) understand the behavior, and (3) how we might fix or work
around it.

I notice some other people also seem to be diffident about posting on
R-devel; perhaps I should conclude that bugs like this are below the
radar for busy statisticians.

FWIW, after playing around a bit with mvbutils::mvb.parent.frame, I
now have a working "desubN" (see the attachment on my original
message, and this one). I don't really have a good understanding of
*why* it now works, and why the original version didn't work...

Thanks again Mark. Also, nice hacking.

Frederick

----- Forwarded message from Mark.Bravington at data61.csiro.au -----

Date: Mon, 12 Dec 2016 06:20:17 +0000
From: Mark.Bravington at data61.csiro.au
To: frederik at ofb.net
Subject: RE: [Rd] why does parent.frame() cycle when called from inside
        capture.output()?
X-Spam-Status: No, score=-2.0 required=5.0 tests=BAYES_00,DKIM_SIGNED,
        DKIM_VALID,DKIM_VALID_AU,T_SPF_HELO_TEMPERROR,T_SPF_TEMPERROR autolearn=ham
        autolearn_force=no version=3.4.1
X-Spam-Level:
X-My-Tags: inbox r-devel

Hi Frederik

[ I'm replying off-list in case you, or the rest of R-devel, don't find this reply useful... please fwd to the list if it does help you ]

I'm the author of the 'debug' package. When I wrote it--- many years ago now--- I encountered some fairly strange behaviour with frames in the call stack, which is reminiscent of what you're seeing. The debug package still works fine, so I presume nothing has changed much.

If you load debug and then do ?mvb.sys.parent (and look at the code), you might get *some* idea of what's going on. TBH I can't remember the details now...

HTH
Mark

Mark Bravington
CSIRO Marine Lab
Hobart
Australia

________________________________________
From: R-devel [r-devel-bounces at r-project.org] on behalf of frederik at ofb.net [frederik at ofb.net]
Sent: 12 December 2016 16:54
To: r-devel at r-project.org
Cc: r-help at r-project.org
Subject: [Rd] why does parent.frame() cycle when called from inside capture.output()?

Hello R devel/help,

I ran into this strange behavior:

    # showstack is supposed to walk through the stack of parent
    # environments when it is called:
    showstack = function() {
      env = environment()
      for(i in 1:12) {
        env = do.call(parent.frame, list(), env=env)
        print(env)
      }
    }

    # a simple chain of functions:
    g3=function(t) showstack()
    g2=function(w) g3(w)
    g1=function(z) g2(z)
    g=function(y) g1(y)

    g()
    # outputs:
    # <environment: 0xb5ef810>
    # <environment: 0xb5ef6f8>
    # <environment: 0xb5ef5e0>
    # <environment: 0xb5ef4c8>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # <environment: R_GlobalEnv>
    # ...

    cat(capture.output(g()),sep="\n")
    # outputs:
    # <environment: 0x8106a30>
    # <environment: 0x8106918>
    # <environment: 0x8106800>
    # <environment: 0x81066e8>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>
    # <environment: R_GlobalEnv>
    # <environment: 0x8107458>
    # <environment: 0x81071b8>
    # <environment: 0x80c6a08>

The strange thing of course is that the second call doesn't stay with
R_GlobalEnv, but in fact goes into a loop of period 4. I'm not so
surprised that the parent frame of the global environment is itself,
as in the first call, but it seems weird to have a loop of period 4...
Using `ls()` shows that two of the "loop" environments belong to
capture.output() and eval().

But if capture.output is really evaluating its input in the parent
frame, as it appears to be doing from its source code, then I would
have expected the output to be the same as the output I get by
evaluating the same expression in this frame.

I was trying to debug a function which attempts to be a multi-frame
version of deparse(substitute(...)). I'm attaching this function in
case anyone is curious. Perhaps my attachment can shed more light on
the problem I'm having.

Apologies if this is not a bug - I wasn't sure which mailing list to
send this to, and I took a guess.

Thanks,

Frederick


----- End forwarded message -----


From bailster at hotmail.com  Tue Dec 13 00:41:01 2016
From: bailster at hotmail.com (Bailey Hewitt)
Date: Mon, 12 Dec 2016 23:41:01 +0000
Subject: [R] Merging two columns of unequal length
Message-ID: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>

Dear R Help,


I am trying to put together two columns of unequal length in a data frame. Unfortunately, so far I have been unsuccessful in the functions I have tried (such as cbind). The code I am currently using is : (I have highlighted the code that is not working)


y<- mydata[,2:75]

year <- mydata$Year

res <- data.frame()

for (i in 1:74){

  y.val <- y[,i]

  lake.lm= lm(y.val ~ year)

  lake.res=residuals(lake.lm)

  new.res <- data.frame(lake.res=lake.res)

  colnames(new.res) <- colnames(y)[i]

#cbind doesn't work because of the unequal lengths of my data columns

  res <- cbind(res, new.res)

  print(res)

}


mydata is a csv file with "Year" from 1950 on as my first column and then each proceeding column has a lake name and a day of year (single number) in each row.


Please let me know if there is any more information I can provide as I am new to emailing in this list. Thank you for your time!


Bailey Hewitt

	[[alternative HTML version deleted]]


From subodh.adhikari1 at gmail.com  Tue Dec 13 01:27:28 2016
From: subodh.adhikari1 at gmail.com (Subodh Adhikari)
Date: Mon, 12 Dec 2016 17:27:28 -0700
Subject: [R] Reshape to wide format
In-Reply-To: <1481563056882.707505557@boxbe>
References: <1481563056882.707505557@boxbe>
Message-ID: <CACStCOkjhYn=YnxHUbzpgioMrWxUsD98ucivwU6C5jv9HQ5SpQ@mail.gmail.com>

For long to wide, try *dcas*t function in reshape2 package. (*melt* is from
wide to long).
Subodh

On Mon, Dec 12, 2016 at 10:10 AM, Miluji Sb <milujisb at gmail.com> wrote:

> [image: Boxbe] <https://www.boxbe.com/overview> Miluji Sb (
> milujisb at gmail.com) is not on your Guest List
> <https://www.boxbe.com/approved-list?tc_serial=27970590433&tc_rand=207238374&utm_source=stf&utm_medium=email&utm_campaign=ANNO_MWTP&utm_content=001&key=Rie9cz5zwnfjZUTkAyjbuHbUZyg4xi9ABP3GXbPk3wE%3D&token=0PSll570AP37QuCLt5N8K4YQYhleAA9pNQcUSXeBvi4ZnzoK6P%2BsykOpLi08Uza2>
> | Approve sender
> <https://www.boxbe.com/anno?tc_serial=27970590433&tc_rand=207238374&utm_source=stf&utm_medium=email&utm_campaign=ANNO_MWTP&utm_content=001&key=Rie9cz5zwnfjZUTkAyjbuHbUZyg4xi9ABP3GXbPk3wE%3D&token=0PSll570AP37QuCLt5N8K4YQYhleAA9pNQcUSXeBvi4ZnzoK6P%2BsykOpLi08Uza2>
> | Approve domain
> <https://www.boxbe.com/anno?tc_serial=27970590433&tc_rand=207238374&utm_source=stf&utm_medium=email&utm_campaign=ANNO_MWTP&utm_content=001&dom&key=Rie9cz5zwnfjZUTkAyjbuHbUZyg4xi9ABP3GXbPk3wE%3D&token=0PSll570AP37QuCLt5N8K4YQYhleAA9pNQcUSXeBvi4ZnzoK6P%2BsykOpLi08Uza2>
>
> Dear all,
>
> I have the following monthly data by coordinates:
>
> I would like to reshape this data to wide format so that each column is a
> coordinate and each row is a month,
>
> coordinate1 coordinate2 coordinate3...
> Month 1
> Month 2
>
> Is the best option to concatenate the iso3, lon, and lat variables to
> create an ID variable? I realize that this question might be very basic but
> I'm slightly baffled. Thank you.
>
> temp <- dput(head(precip_2000,20))
> structure(list(iso3 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("AFG",
> "AGO", "ALB", "ARE", "ARG", "ARM", "AUS", "AUT", "AZE", "BDI",
> "BEL", "BEN", "BFA", "BGD", "BGR", "BHS", "BIH", "BLR", "BLZ",
> "BOL", "BRA", "BRN", "BTN", "BWA", "CAF", "CAN", "CHE", "CHL",
> "CHN", "CIV", "CMR", "COD", "COG", "COL", "CRI", "CUB", "CYP",
> "CZE", "DEU", "DJI", "DNK", "DOM", "DZA", "ECU", "EGY", "ERI",
> "ESH", "ESP", "EST", "ETH", "FIN", "FJI", "FLK", "FRA", "GAB",
> "GBR", "GEO", "GHA", "GIN", "GNB", "GNQ", "GRC", "GRL", "GTM",
> "GUF", "GUY", "HND", "HRV", "HTI", "HUN", "IDN", "IND", "IRL",
> "IRN", "IRQ", "ISL", "ISR", "ITA", "JAM", "JOR", "JPN", "KAZ",
> "KEN", "KGZ", "KHM", "KIR", "KOR", "KWT", "LAO", "LBN", "LBR",
> "LBY", "LCA", "LKA", "LSO", "LTU", "LUX", "LVA", "MAR", "MDA",
> "MDG", "MEX", "MKD", "MLI", "MMR", "MNE", "MNG", "MOZ", "MRT",
> "MWI", "MYS", "NAM", "NCL", "NER", "NGA", "NIC", "NLD", "NOR",
> "NPL", "NZL", "OMN", "PAK", "PAN", "PER", "PHL", "PNG", "POL",
> "PRI", "PRK", "PRT", "PRY", "QAT", "ROU", "RUS", "RWA", "SAU",
> "SDN", "SEN", "SJM", "SLB", "SLE", "SLV", "SOM", "SRB", "SUR",
> "SVK", "SVN", "SWE", "SWZ", "SYR", "TCD", "TGO", "THA", "TJK",
> "TKM", "TLS", "TUN", "TUR", "TWN", "TZA", "UGA", "UKR", "URY",
> "USA", "UZB", "VEN", "VNM", "VUT", "YEM", "ZAF", "ZMB", "ZWE"
> ), class = "factor"), lon = c(61L, 61L, 61L, 61L, 61L, 61L, 61L,
> 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L
> ), lat = c(32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L,
> 32L, 32L, 33L, 33L, 33L, 33L, 33L, 33L, 33L, 33L), dm = structure(c(1L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 1L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L), .Label = c("2000m1", "2000m10", "2000m11",
> "2000m12", "2000m2", "2000m3", "2000m4", "2000m5", "2000m6",
> "2000m7", "2000m8", "2000m9"), class = "factor"), month = c(1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L), precip = c(0.996665806451613, 0.156711724137931,
> 0.242477419354839, 0, 0, 0, 0, 0, 0, 0, 0.121536, 0.38866064516129,
> 1.13312903225806, 0.355208275862069, 0.307277419354839, 0.008316,
> 0, 0, 0, 0.0008361290322581)), .Names = c("iso3", "lon", "lat",
> "dm", "month", "precip"), row.names = c(NA, 20L), class = "data.frame")
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
*Subodh Adhikari*

*????? ??????? *
PhD Candidate
Land Resources and Environmental Sciences,
Montana State University, USA

*"The Weak can Never Forgive. Forgiveness is the Attribute of the Strong" -*
* Gandhi*
*"Injustice Anywhere is a Threat to Justice Everywhere"*
*- Martin Luther King, Jr. *

	[[alternative HTML version deleted]]


From frederik at ofb.net  Tue Dec 13 02:27:49 2016
From: frederik at ofb.net (frederik at ofb.net)
Date: Mon, 12 Dec 2016 17:27:49 -0800
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <12F7E3A9-AAE3-423F-973D-1E52E7D11A91@comcast.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <20161213012749.GF11787@ofb.net>

Thank you, John and David.

Yes someone already came up with that one on Stack Overflow.

Although I don't quite understand how it works - it would be nice to
see a step-by-step explanation of what is getting substituted and
evaluated in which environment. I guess 'eval.parent' must do its own
substituting, just so that it can see the variables you pass to it,
before it actually evaluates its argument. But 'eval' is .Internal...
Maybe if this is less of a mystery to someone else ...

Frederick

On Mon, Dec 12, 2016 at 02:54:14PM -0800, David Winsemius wrote:
> >...
> Exactly the same answer as the crossposting elicited:
> 
> http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-function-which-is-equivalent-to-deparsesubstitutex
> 
> -- 
> David

On Mon, Dec 12, 2016 at 10:07:06PM +0000, Fox, John wrote:
> Dear Frederick,
> 
> I found this a challenging puzzle, and it took me awhile to come up with an alternative, and I think slightly simpler, solution:
> 
> > desub <- function(y) {
> +     deparse(eval(substitute(substitute(y)), 
> +                  env=parent.frame()))
> + }
>  
> > f <- function(x){
> +     message(desub(x))
> + }
> 
> > f(log)
> log
> 
> Best,
>  John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> > frederik at ofb.net
> > Sent: December 11, 2016 8:35 PM
> > To: r-help at r-project.org
> > Subject: Re: [R] how do I define a function which is equivalent to
> > `deparse(substitute(x))`?
> > 
> > Dear R-Help,
> > 
> > I was going to ask Jeff to read the entire works of William Shakespeare to learn
> > why his reply was not helpful to me...
> > 
> > Then I realized that the answer, as always, lies within...
> > 
> >     desub <- function(y) {
> >       e1=substitute(y, environment())
> >       e2=do.call(substitute,list(e1), env=parent.frame())
> >       deparse(e2)
> >     }
> > 
> > Sorry to trouble the list; other solutions still welcome.
> > 
> > Cheers,
> > 
> > Frederick
> > 
> > On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> > > No. Read Hadley Wickham's "Advanced R" to learn why not.
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> > > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> > > >Dear R-Help,
> > > >
> > > >I asked this question on StackOverflow,
> > > >
> > > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-define-a-fu
> > > >nction-which-is-equivalent-to-deparsesubstitutex
> > > >
> > > >but thought perhaps R-help would be more appropriate.
> > > >
> > > >I want to write a function in R which grabs the name of a variable
> > > >from the context of its caller's caller. I think the problem I have
> > > >is best understood by asking how to compose `deparse` and `substitute`.
> > > >You can see that a naive composition does not work:
> > > >
> > > >    # a compose operator
> > > >    >  `%c%` = function(x,y)function(...)x(y(...))
> > > >
> > > >    # a naive attempt to combine deparse and substitute
> > > >    > desub = deparse %c% substitute
> > > >    > f=function(foo) { message(desub(foo)) }
> > > >    > f(log)
> > > >    foo
> > > >
> > > >    # this is how it is supposed to work
> > > >    > g=function(foo) { message(deparse(substitute(foo))) }
> > > >    > g(log)
> > > >    log
> > > >
> > > >Is there a way I can define a function `desub` so that `desub(x)` has
> > > >the same value as `deparse(substitute(x))` in every context?
> > > >
> > > >Thank you,
> > > >
> > > >Frederick Eaton
> > > >
> > > >______________________________________________
> > > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > >https://stat.ethz.ch/mailman/listinfo/r-help
> > > >PLEASE do read the posting guide
> > > >http://www.R-project.org/posting-guide.html
> > > >and provide commented, minimal, self-contained, reproducible code.
> > >
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Tue Dec 13 05:09:29 2016
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 12 Dec 2016 22:09:29 -0600
Subject: [R] output
In-Reply-To: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
References: <CAJOiR6bB0KBMf_1Gas3EUHPgp2N8URtQHqfr=w5SHLd3BMFO1g@mail.gmail.com>
Message-ID: <25E7578F-967F-49AE-B257-4241DDDC4958@me.com>

Hi,

With the WriteXLS() function, from the package of the same name, if you specify '.xlsx' for the file name extension, the function will create an Excel 2007 compatible file, which can handle worksheets of up to 1,048,576 rows by 16,384 columns.

Thus:

  WriteXLS(dat, "test4.xlsx", row.names = FALSE)

That is all described in the help file for the function.

Regards,

Marc Schwartz


> On Dec 12, 2016, at 6:51 PM, Val <valkremk at gmail.com> wrote:
> 
> Hi all,
> 
> I have a data frame with more than 100,000 rows.
> 
> datx <- function(n,mean,sd) { mean+sd*scale(rnorm(n)) }
> dat <- datx(110000,10,2)
> 
> 1)
> WriteXLS(dat, "test4.xls", row.names=FALSE)
> Error in WriteXLS(dat, "test4.xls", row.names = FALSE) :
>  One or more of the data frames named in 'x' exceeds 65,535 rows or 256 columns
> 
> I noticed that *.xls has  row and column limitations.
> 
> How can I take the excess row to the next sheet?
> 
> 2) I also tried to use xlsx and have a problem
> 
> write.xlsx(dat, "test3.xlsx",sheetName="sheet1", row.names=FALSE)
> Error in .jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook") :
>  java.lang.OutOfMemoryError: Java heap
> space.jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook")<S4 object of
> class "jobjRef">
> 
> Any help ?
> Thank you in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Tue Dec 13 05:21:19 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 13 Dec 2016 04:21:19 +0000
Subject: [R] Merging two columns of unequal length
In-Reply-To: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <8106552D-EBFE-4118-982E-9BB62C16F7A5@txbiomed.org>

I did not look at the code, but note the following.

By definition,
1. You cannot highlight code in plan text, which is the format accepted by r-help.
2. You cannot have columns of different lengths in a dataframe.


R. Mark Sharp, Ph.D.
msharp at TxBiomed.org





> On Dec 12, 2016, at 5:41 PM, Bailey Hewitt <bailster at hotmail.com> wrote:
>
> Dear R Help,
>
>
> I am trying to put together two columns of unequal length in a data frame. Unfortunately, so far I have been unsuccessful in the functions I have tried (such as cbind). The code I am currently using is : (I have highlighted the code that is not working)
>
>
> y<- mydata[,2:75]
>
> year <- mydata$Year
>
> res <- data.frame()
>
> for (i in 1:74){
>
>  y.val <- y[,i]
>
>  lake.lm= lm(y.val ~ year)
>
>  lake.res=residuals(lake.lm)
>
>  new.res <- data.frame(lake.res=lake.res)
>
>  colnames(new.res) <- colnames(y)[i]
>
> #cbind doesn't work because of the unequal lengths of my data columns
>
>  res <- cbind(res, new.res)
>
>  print(res)
>
> }
>
>
> mydata is a csv file with "Year" from 1950 on as my first column and then each proceeding column has a lake name and a day of year (single number) in each row.
>
>
> Please let me know if there is any more information I can provide as I am new to emailing in this list. Thank you for your time!
>
>
> Bailey Hewitt
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From jdnewmil at dcn.davis.ca.us  Tue Dec 13 06:39:37 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 12 Dec 2016 21:39:37 -0800
Subject: [R] Merging two columns of unequal length
In-Reply-To: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <F48D94FF-CE8B-4D5E-BDEA-F4C8D2EC5891@dcn.davis.ca.us>

You can't do that. You can either make a different data frame, or you can stack the data in additional rows. If you make your example reproducible, we may be able to give more specific help. 

Also,  post in plain text to avoid HTML code corruption. 

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

http://adv-r.had.co.nz/Reproducibility.html
-- 
Sent from my phone. Please excuse my brevity.

On December 12, 2016 3:41:01 PM PST, Bailey Hewitt <bailster at hotmail.com> wrote:
>Dear R Help,
>
>
>I am trying to put together two columns of unequal length in a data
>frame. Unfortunately, so far I have been unsuccessful in the functions
>I have tried (such as cbind). The code I am currently using is : (I
>have highlighted the code that is not working)
>
>
>y<- mydata[,2:75]
>
>year <- mydata$Year
>
>res <- data.frame()
>
>for (i in 1:74){
>
>  y.val <- y[,i]
>
>  lake.lm= lm(y.val ~ year)
>
>  lake.res=residuals(lake.lm)
>
>  new.res <- data.frame(lake.res=lake.res)
>
>  colnames(new.res) <- colnames(y)[i]
>
>#cbind doesn't work because of the unequal lengths of my data columns
>
>  res <- cbind(res, new.res)
>
>  print(res)
>
>}
>
>
>mydata is a csv file with "Year" from 1950 on as my first column and
>then each proceeding column has a lake name and a day of year (single
>number) in each row.
>
>
>Please let me know if there is any more information I can provide as I
>am new to emailing in this list. Thank you for your time!
>
>
>Bailey Hewitt
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Dec 13 06:52:15 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Dec 2016 21:52:15 -0800
Subject: [R] how do I define a function which is equivalent to
	`deparse(substitute(x))`?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365A8503@FHSDB2D11-2.csu.mcmaster.ca>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A844B@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbQmZgwrm1nrU0tCdbdytA=qLiesJHTxLukSDywXv9ioUw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A8503@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAGxFJbTk2POyVSDoO3Xv4SOEJcBSnhDWi=c4Qvdsu4MbuVRt8g@mail.gmail.com>

John:

If you insist:

> desub <- function(x)
      deparse(sys.call(-length(sys.parents())+1)[[2]])

>
> f <- function(y)desub(y)
> g <- function(y)message(desub(y))
>
> f(log)
[1] "log"

> g(log)
log


However, I would agree that searching backward through the call stack
can be tricky. For example, suppose we have in addition to the above,

h <- function(foo) g(foo)

Then using desub() as I defined it above, one gets as desired:

> h(log)
log

However, using your gsub(),

> desub <- function(y) {
       deparse(eval(substitute(substitute(y)),
         env=parent.frame()))
 }

One then gets:

> h(log)
foo  ## whoops!

I suspect one can find a way to break my approach that doesn't break
yours -- and if/when you find it, please post it. But on general
principles I prefer accessing the call stack directly rather than
indirectly through nested substitute calls. But beauty is in the eye
of the beholder...


Cheers,
Bert





Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 12, 2016 at 5:45 PM, Fox, John <jfox at mcmaster.ca> wrote:
> Dear Bert,
>
> Your current version satisfies the original posting, but, though simpler than mine, is a bit fragile, in the following sense:
>
>> desub <- function(x) (all.vars(sys.call(-2)))
>
>> f <- function(x){
> +     message(desub(x))
> + }
>
>> f(log)
> log
>
>> g <- function(x){
> +     desub(x)
> + }
>
>> g(log)
> character(0)
>
>
> My version:
>
>> desub <- function(y) {
> +     deparse(eval(substitute(substitute(y)),
> +                  env=parent.frame()))
> + }
>
>> f(log)
> log
>
>> g(log)
> [1] "log"
>
> The deparse(substitute()) idiom returns the argument to f() or g() as a character string and so desub() should too, I guess.
>
> Best,
>  John
>
>> -----Original Message-----
>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> Sent: December 12, 2016 7:26 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: frederik at ofb.net; r-help at r-project.org
>> Subject: Re: [R] how do I define a function which is equivalent to
>> `deparse(substitute(x))`?
>>
>> John. et. al:
>>
>> I assumed the message call was there to convert a quoted string to an
>> unquoted name and simply did this with as.name() in desub(). The point of
>> using sys.call() is that you can go up the call stack as far as you need, so if you
>> want to leave in the message() call, just go one farther up the call stack:
>>
>> > desub <- function(x) (all.vars(sys.call(-2))) ## note the -2 now
>>
>> > g <- function(y)message((desub(y)))
>> > g(log)
>> log
>>
>>
>> -- Bert
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Mon, Dec 12, 2016 at 3:58 PM, Fox, John <jfox at mcmaster.ca> wrote:
>> > Dear Bert,
>> >
>> > It's nitpicking, I guess, but the call to message() is in the original
>> > posting. Your solution produces
>> >
>> >> desub <- function(x) as.name(all.vars(sys.call(-1)))
>> >
>> >> f <- function(x){
>> > +     message(desub(x))
>> > + }
>> >
>> >> f(log)
>> > x
>> >
>> > Best,
>> >  John
>> >
>> >> -----Original Message-----
>> >> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> >> Sent: Monday, December 12, 2016 6:41 PM
>> >> To: Fox, John <jfox at mcmaster.ca>
>> >> Cc: frederik at ofb.net; r-help at r-project.org
>> >> Subject: Re: [R] how do I define a function which is equivalent to
>> >> `deparse(substitute(x))`?
>> >>
>> >> *If* I understand correctly -- and please let me know if I don't --
>> >> this seems somewhat more straightforward and less "hacky" :
>> >>
>> >> > desub <- function(x) as.name(all.vars(sys.call(-1)))
>> >>
>> >> Yielding in the OP's example:
>> >>
>> >> > g <- function(y)desub(y)
>> >> > g(log)
>> >> log
>> >>
>> >> Cheers,
>> >> Bert
>> >> Bert Gunter
>> >>
>> >> "The trouble with having an open mind is that people keep coming
>> >> along and sticking things into it."
>> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> >>
>> >>
>> >> On Mon, Dec 12, 2016 at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
>> >> > Dear Frederick,
>> >> >
>> >> > I found this a challenging puzzle, and it took me awhile to come up
>> >> with an alternative, and I think slightly simpler, solution:
>> >> >
>> >> >> desub <- function(y) {
>> >> > +     deparse(eval(substitute(substitute(y)),
>> >> > +                  env=parent.frame())) }
>> >> >
>> >> >> f <- function(x){
>> >> > +     message(desub(x))
>> >> > + }
>> >> >
>> >> >> f(log)
>> >> > log
>> >> >
>> >> > Best,
>> >> >  John
>> >> >
>> >> > -----------------------------
>> >> > John Fox, Professor
>> >> > McMaster University
>> >> > Hamilton, Ontario
>> >> > Canada L8S 4M4
>> >> > Web: socserv.mcmaster.ca/jfox
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >> -----Original Message-----
>> >> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
>> >> >> frederik at ofb.net
>> >> >> Sent: December 11, 2016 8:35 PM
>> >> >> To: r-help at r-project.org
>> >> >> Subject: Re: [R] how do I define a function which is equivalent to
>> >> >> `deparse(substitute(x))`?
>> >> >>
>> >> >> Dear R-Help,
>> >> >>
>> >> >> I was going to ask Jeff to read the entire works of William
>> >> >> Shakespeare to learn why his reply was not helpful to me...
>> >> >>
>> >> >> Then I realized that the answer, as always, lies within...
>> >> >>
>> >> >>     desub <- function(y) {
>> >> >>       e1=substitute(y, environment())
>> >> >>       e2=do.call(substitute,list(e1), env=parent.frame())
>> >> >>       deparse(e2)
>> >> >>     }
>> >> >>
>> >> >> Sorry to trouble the list; other solutions still welcome.
>> >> >>
>> >> >> Cheers,
>> >> >>
>> >> >> Frederick
>> >> >>
>> >> >> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
>> >> >> > No. Read Hadley Wickham's "Advanced R" to learn why not.
>> >> >> > --
>> >> >> > Sent from my phone. Please excuse my brevity.
>> >> >> >
>> >> >> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
>> >> >> > >Dear R-Help,
>> >> >> > >
>> >> >> > >I asked this question on StackOverflow,
>> >> >> > >
>> >> >> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-defin
>> >> >> > >e-a -fu nction-which-is-equivalent-to-deparsesubstitutex
>> >> >> > >
>> >> >> > >but thought perhaps R-help would be more appropriate.
>> >> >> > >
>> >> >> > >I want to write a function in R which grabs the name of a
>> >> >> > >variable from the context of its caller's caller. I think the
>> >> >> > >problem I have is best understood by asking how to compose
>> >> >> > >`deparse` and
>> >> `substitute`.
>> >> >> > >You can see that a naive composition does not work:
>> >> >> > >
>> >> >> > >    # a compose operator
>> >> >> > >    >  `%c%` = function(x,y)function(...)x(y(...))
>> >> >> > >
>> >> >> > >    # a naive attempt to combine deparse and substitute
>> >> >> > >    > desub = deparse %c% substitute
>> >> >> > >    > f=function(foo) { message(desub(foo)) }
>> >> >> > >    > f(log)
>> >> >> > >    foo
>> >> >> > >
>> >> >> > >    # this is how it is supposed to work
>> >> >> > >    > g=function(foo) { message(deparse(substitute(foo))) }
>> >> >> > >    > g(log)
>> >> >> > >    log
>> >> >> > >
>> >> >> > >Is there a way I can define a function `desub` so that
>> >> >> > >`desub(x)` has the same value as `deparse(substitute(x))` in every
>> context?
>> >> >> > >
>> >> >> > >Thank you,
>> >> >> > >
>> >> >> > >Frederick Eaton
>> >> >> > >
>> >> >> > >______________________________________________
>> >> >> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>> >> >> > >see https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> > >PLEASE do read the posting guide
>> >> >> > >http://www.R-project.org/posting-guide.html
>> >> >> > >and provide commented, minimal, self-contained, reproducible code.
>> >> >> >
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Tue Dec 13 06:57:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Dec 2016 21:57:19 -0800
Subject: [R] Regex Help
Message-ID: <CAGxFJbRyWEyvRKBBtbanPhTKMBPNttMgqDAJZAOnAJYt8e4GqA@mail.gmail.com>

1. Once you have the character vector from the regex, see ?strsplit to
get the strings on either side of the "->" .
You may have to fiddle a bit if one or the other side is empty.

You can then format the results as you like.

2. "Graphical representation similar to this" is too vague a
specification to be meaningful.

Cheers,

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


From drjimlemon at gmail.com  Tue Dec 13 09:58:59 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 13 Dec 2016 19:58:59 +1100
Subject: [R] Reshape to wide format
In-Reply-To: <CAMLwc7O7kCZbeMXie8irri7Xn564VsSQ-pN2=Y8eGwqYWdXqBQ@mail.gmail.com>
References: <CAMLwc7O7kCZbeMXie8irri7Xn564VsSQ-pN2=Y8eGwqYWdXqBQ@mail.gmail.com>
Message-ID: <CA+8X3fXtsir220YwpgRZ20wktiYRm=Br887SCU_vY3V89ZGYXA@mail.gmail.com>

Hi Milu,
I may have the wrong idea, but is this what you want?

temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
library(prettyR)
newtemp<-stretch_df(temp,"month","precip")[,c(5,7,8)]
names(newtemp)<-c("month",unique(temp$ID))

Jim


On Tue, Dec 13, 2016 at 4:10 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have the following monthly data by coordinates:
>
> I would like to reshape this data to wide format so that each column is a
> coordinate and each row is a month,
>
> coordinate1 coordinate2 coordinate3...
> Month 1
> Month 2
>
> Is the best option to concatenate the iso3, lon, and lat variables to
> create an ID variable? I realize that this question might be very basic but
> I'm slightly baffled. Thank you.
>
> temp <- dput(head(precip_2000,20))
> structure(list(iso3 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("AFG",
> "AGO", "ALB", "ARE", "ARG", "ARM", "AUS", "AUT", "AZE", "BDI",
> "BEL", "BEN", "BFA", "BGD", "BGR", "BHS", "BIH", "BLR", "BLZ",
> "BOL", "BRA", "BRN", "BTN", "BWA", "CAF", "CAN", "CHE", "CHL",
> "CHN", "CIV", "CMR", "COD", "COG", "COL", "CRI", "CUB", "CYP",
> "CZE", "DEU", "DJI", "DNK", "DOM", "DZA", "ECU", "EGY", "ERI",
> "ESH", "ESP", "EST", "ETH", "FIN", "FJI", "FLK", "FRA", "GAB",
> "GBR", "GEO", "GHA", "GIN", "GNB", "GNQ", "GRC", "GRL", "GTM",
> "GUF", "GUY", "HND", "HRV", "HTI", "HUN", "IDN", "IND", "IRL",
> "IRN", "IRQ", "ISL", "ISR", "ITA", "JAM", "JOR", "JPN", "KAZ",
> "KEN", "KGZ", "KHM", "KIR", "KOR", "KWT", "LAO", "LBN", "LBR",
> "LBY", "LCA", "LKA", "LSO", "LTU", "LUX", "LVA", "MAR", "MDA",
> "MDG", "MEX", "MKD", "MLI", "MMR", "MNE", "MNG", "MOZ", "MRT",
> "MWI", "MYS", "NAM", "NCL", "NER", "NGA", "NIC", "NLD", "NOR",
> "NPL", "NZL", "OMN", "PAK", "PAN", "PER", "PHL", "PNG", "POL",
> "PRI", "PRK", "PRT", "PRY", "QAT", "ROU", "RUS", "RWA", "SAU",
> "SDN", "SEN", "SJM", "SLB", "SLE", "SLV", "SOM", "SRB", "SUR",
> "SVK", "SVN", "SWE", "SWZ", "SYR", "TCD", "TGO", "THA", "TJK",
> "TKM", "TLS", "TUN", "TUR", "TWN", "TZA", "UGA", "UKR", "URY",
> "USA", "UZB", "VEN", "VNM", "VUT", "YEM", "ZAF", "ZMB", "ZWE"
> ), class = "factor"), lon = c(61L, 61L, 61L, 61L, 61L, 61L, 61L,
> 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L
> ), lat = c(32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L,
> 32L, 32L, 33L, 33L, 33L, 33L, 33L, 33L, 33L, 33L), dm = structure(c(1L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 1L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L), .Label = c("2000m1", "2000m10", "2000m11",
> "2000m12", "2000m2", "2000m3", "2000m4", "2000m5", "2000m6",
> "2000m7", "2000m8", "2000m9"), class = "factor"), month = c(1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L), precip = c(0.996665806451613, 0.156711724137931,
> 0.242477419354839, 0, 0, 0, 0, 0, 0, 0, 0.121536, 0.38866064516129,
> 1.13312903225806, 0.355208275862069, 0.307277419354839, 0.008316,
> 0, 0, 0, 0.0008361290322581)), .Names = c("iso3", "lon", "lat",
> "dm", "month", "precip"), row.names = c(NA, 20L), class = "data.frame")
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Tue Dec 13 11:15:15 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Tue, 13 Dec 2016 02:15:15 -0800
Subject: [R] Merging two columns of unequal length
Message-ID: <CAA99HCx8epqZR3QjjGhsC3bkotBMEtL27dM1A+c=qmZzRna8eQ@mail.gmail.com>

You should review "The Recycling Rule in R" before attempting to
perform functions on 2 or more vectors of unequal lengths:

https://cran.r-project.org/doc/manuals/R-intro.html#The-recycling-rule

Most often, the "Recycling Rule" does exactly what the researcher
intends (automatically). And in many cases, performing functions on
data of unequal (or not evenly divisible) lengths is either 1) an
indication of problems with the input data, or 2) an indication that
the researcher is unnecessarily 'forcing' data into a rectangular data
structure, when another approach might be better (e.g. the use of the
tapply function).

However, if you see no other way, the functions "cbind.na" and/or
"rbind.na" available from Andrej-Nikolai Spiess perform binding of
vectors without recycling:

http://www.dr-spiess.de/Rscripts.html

All you have to do is download and source the correct R-script, and
call the function:

> cbind(1:5, 1:2)
     [,1] [,2]
[1,]    1    1
[2,]    2    2
[3,]    3    1
[4,]    4    2
[5,]    5    1

Warning message:
In cbind(1:5, 1:2) :
  number of rows of result is not a multiple of vector length (arg 2)

> source("/Users/myhomedirectory/Downloads/cbind.na.R")
> cbind.na(1:5, 1:2)
     [,1] [,2]
[1,]    1    1
[2,]    2    2
[3,]    3   NA
[4,]    4   NA
[5,]    5   NA
>

This issue arises so often, Dr. Spiess's two scripts "rbind.na" and
"cbind.na" have my vote for inclusion into the base-R distribution.

Best of luck,

W Michels, Ph.D.


On Mon, Dec 12, 2016 at 3:41 PM, Bailey Hewitt <bailster at hotmail.com> wrote:
>
> Dear R Help,
>
>
> I am trying to put together two columns of unequal length in a data frame. Unfortunately, so far I have been unsuccessful in the functions I have tried (such as cbind). The code I am currently using is : (I have highlighted the code that is not working)
>
>
> y<- mydata[,2:75]
>
> year <- mydata$Year
>
> res <- data.frame()
>
> for (i in 1:74){
>
>   y.val <- y[,i]
>
>   lake.lm= lm(y.val ~ year)
>
>   lake.res=residuals(lake.lm)
>
>   new.res <- data.frame(lake.res=lake.res)
>
>   colnames(new.res) <- colnames(y)[i]
>
> #cbind doesn't work because of the unequal lengths of my data columns
>
>   res <- cbind(res, new.res)
>
>   print(res)
>
> }
>
>
> mydata is a csv file with "Year" from 1950 on as my first column and then each proceeding column has a lake name and a day of year (single number) in each row.
>
>
> Please let me know if there is any more information I can provide as I am new to emailing in this list. Thank you for your time!
>
>
> Bailey Hewitt
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From judyoringe at naver.com  Tue Dec 13 12:08:16 2016
From: judyoringe at naver.com (=?UTF-8?B?7J207JWE66aE?=)
Date: Tue, 13 Dec 2016 20:08:16 +0900 (KST)
Subject: [R] =?utf-8?q?K-modes_clustering_=3A_how_to_choose_the_number_of_?=
 =?utf-8?q?clusters=3F?=
Message-ID: <8bffd83f1f7a6b0a1035a78b030de@cweb11.nm.nhnsystem.com>

 
Dear all. 
 
I tried to cluster the data with categorical variables with K-modes using klaR packages. 
 
I tried to find the optimal number of clusters by considering the average silhouette width though..  
 
In k-modes, however, the average silhouette width increases, when the the number of clusters increases in my case.
 
So i tried to derive the elbow plot and I got the attached graph. 
It is quite hard to which point is the location of a bend in this plot.. 
In this case, how can I choose the best number of groups? 
 
Can anyone introduce better method that help choose the optimal number of clusters for K-modes? 
 
Thanks!
 
Kind regards
 
Ann. 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Example_ElbowPlot.png
Type: image/png
Size: 7087 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161213/834676ab/attachment.png>

From jfox at mcmaster.ca  Tue Dec 13 15:09:49 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 13 Dec 2016 14:09:49 +0000
Subject: [R] how do I define a function which is equivalent to
 `deparse(substitute(x))`?
In-Reply-To: <CAGxFJbTk2POyVSDoO3Xv4SOEJcBSnhDWi=c4Qvdsu4MbuVRt8g@mail.gmail.com>
References: <20161211062449.GA20109@ofb.net>
	<B36BD4D7-959B-48FC-9F02-28E3B07C9AF4@dcn.davis.ca.us>
	<20161212013522.GB20649@ofb.net>
	<ACD1644AA6C67E4FBD0C350625508EC8365A83FE@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbTYwgPuR01SrH5Qzq--TwgOZnzZKg1nPRLM0eX8U6Faag@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A844B@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbQmZgwrm1nrU0tCdbdytA=qLiesJHTxLukSDywXv9ioUw@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365A8503@FHSDB2D11-2.csu.mcmaster.ca>
	<CAGxFJbTk2POyVSDoO3Xv4SOEJcBSnhDWi=c4Qvdsu4MbuVRt8g@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365A86DB@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bert,

I'm tempted to let this thread drop, since I like your last solution better than mine: it's clearer and more robust -- in fact, I don't see a way to break it -- and the approach you used to write it generalizes better to other problems. But if the object is to produce a function that behaves like deparse(substitute()), which is the subject of the original posting, then 

> g <- function(x) deparse(substitute(x))
> h <- function(foo) g(foo)
> h(log)
[1] "foo"

Best,
 John

> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: December 13, 2016 12:52 AM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: frederik at ofb.net; r-help at r-project.org
> Subject: Re: [R] how do I define a function which is equivalent to
> `deparse(substitute(x))`?
> 
> John:
> 
> If you insist:
> 
> > desub <- function(x)
>       deparse(sys.call(-length(sys.parents())+1)[[2]])
> 
> >
> > f <- function(y)desub(y)
> > g <- function(y)message(desub(y))
> >
> > f(log)
> [1] "log"
> 
> > g(log)
> log
> 
> 
> However, I would agree that searching backward through the call stack can be
> tricky. For example, suppose we have in addition to the above,
> 
> h <- function(foo) g(foo)
> 
> Then using desub() as I defined it above, one gets as desired:
> 
> > h(log)
> log
> 
> However, using your gsub(),
> 
> > desub <- function(y) {
>        deparse(eval(substitute(substitute(y)),
>          env=parent.frame()))
>  }
> 
> One then gets:
> 
> > h(log)
> foo  ## whoops!
> 
> I suspect one can find a way to break my approach that doesn't break yours --
> and if/when you find it, please post it. But on general principles I prefer
> accessing the call stack directly rather than indirectly through nested substitute
> calls. But beauty is in the eye of the beholder...
> 
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Mon, Dec 12, 2016 at 5:45 PM, Fox, John <jfox at mcmaster.ca> wrote:
> > Dear Bert,
> >
> > Your current version satisfies the original posting, but, though simpler than
> mine, is a bit fragile, in the following sense:
> >
> >> desub <- function(x) (all.vars(sys.call(-2)))
> >
> >> f <- function(x){
> > +     message(desub(x))
> > + }
> >
> >> f(log)
> > log
> >
> >> g <- function(x){
> > +     desub(x)
> > + }
> >
> >> g(log)
> > character(0)
> >
> >
> > My version:
> >
> >> desub <- function(y) {
> > +     deparse(eval(substitute(substitute(y)),
> > +                  env=parent.frame())) }
> >
> >> f(log)
> > log
> >
> >> g(log)
> > [1] "log"
> >
> > The deparse(substitute()) idiom returns the argument to f() or g() as a
> character string and so desub() should too, I guess.
> >
> > Best,
> >  John
> >
> >> -----Original Message-----
> >> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> >> Sent: December 12, 2016 7:26 PM
> >> To: Fox, John <jfox at mcmaster.ca>
> >> Cc: frederik at ofb.net; r-help at r-project.org
> >> Subject: Re: [R] how do I define a function which is equivalent to
> >> `deparse(substitute(x))`?
> >>
> >> John. et. al:
> >>
> >> I assumed the message call was there to convert a quoted string to an
> >> unquoted name and simply did this with as.name() in desub(). The
> >> point of using sys.call() is that you can go up the call stack as far
> >> as you need, so if you want to leave in the message() call, just go one farther
> up the call stack:
> >>
> >> > desub <- function(x) (all.vars(sys.call(-2))) ## note the -2 now
> >>
> >> > g <- function(y)message((desub(y)))
> >> > g(log)
> >> log
> >>
> >>
> >> -- Bert
> >>
> >> Bert Gunter
> >>
> >> "The trouble with having an open mind is that people keep coming
> >> along and sticking things into it."
> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >>
> >>
> >> On Mon, Dec 12, 2016 at 3:58 PM, Fox, John <jfox at mcmaster.ca> wrote:
> >> > Dear Bert,
> >> >
> >> > It's nitpicking, I guess, but the call to message() is in the
> >> > original posting. Your solution produces
> >> >
> >> >> desub <- function(x) as.name(all.vars(sys.call(-1)))
> >> >
> >> >> f <- function(x){
> >> > +     message(desub(x))
> >> > + }
> >> >
> >> >> f(log)
> >> > x
> >> >
> >> > Best,
> >> >  John
> >> >
> >> >> -----Original Message-----
> >> >> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> >> >> Sent: Monday, December 12, 2016 6:41 PM
> >> >> To: Fox, John <jfox at mcmaster.ca>
> >> >> Cc: frederik at ofb.net; r-help at r-project.org
> >> >> Subject: Re: [R] how do I define a function which is equivalent to
> >> >> `deparse(substitute(x))`?
> >> >>
> >> >> *If* I understand correctly -- and please let me know if I don't
> >> >> -- this seems somewhat more straightforward and less "hacky" :
> >> >>
> >> >> > desub <- function(x) as.name(all.vars(sys.call(-1)))
> >> >>
> >> >> Yielding in the OP's example:
> >> >>
> >> >> > g <- function(y)desub(y)
> >> >> > g(log)
> >> >> log
> >> >>
> >> >> Cheers,
> >> >> Bert
> >> >> Bert Gunter
> >> >>
> >> >> "The trouble with having an open mind is that people keep coming
> >> >> along and sticking things into it."
> >> >> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >> >>
> >> >>
> >> >> On Mon, Dec 12, 2016 at 2:07 PM, Fox, John <jfox at mcmaster.ca> wrote:
> >> >> > Dear Frederick,
> >> >> >
> >> >> > I found this a challenging puzzle, and it took me awhile to come
> >> >> > up
> >> >> with an alternative, and I think slightly simpler, solution:
> >> >> >
> >> >> >> desub <- function(y) {
> >> >> > +     deparse(eval(substitute(substitute(y)),
> >> >> > +                  env=parent.frame())) }
> >> >> >
> >> >> >> f <- function(x){
> >> >> > +     message(desub(x))
> >> >> > + }
> >> >> >
> >> >> >> f(log)
> >> >> > log
> >> >> >
> >> >> > Best,
> >> >> >  John
> >> >> >
> >> >> > -----------------------------
> >> >> > John Fox, Professor
> >> >> > McMaster University
> >> >> > Hamilton, Ontario
> >> >> > Canada L8S 4M4
> >> >> > Web: socserv.mcmaster.ca/jfox
> >> >> >
> >> >> >
> >> >> >
> >> >> >
> >> >> >> -----Original Message-----
> >> >> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of
> >> >> >> frederik at ofb.net
> >> >> >> Sent: December 11, 2016 8:35 PM
> >> >> >> To: r-help at r-project.org
> >> >> >> Subject: Re: [R] how do I define a function which is equivalent
> >> >> >> to `deparse(substitute(x))`?
> >> >> >>
> >> >> >> Dear R-Help,
> >> >> >>
> >> >> >> I was going to ask Jeff to read the entire works of William
> >> >> >> Shakespeare to learn why his reply was not helpful to me...
> >> >> >>
> >> >> >> Then I realized that the answer, as always, lies within...
> >> >> >>
> >> >> >>     desub <- function(y) {
> >> >> >>       e1=substitute(y, environment())
> >> >> >>       e2=do.call(substitute,list(e1), env=parent.frame())
> >> >> >>       deparse(e2)
> >> >> >>     }
> >> >> >>
> >> >> >> Sorry to trouble the list; other solutions still welcome.
> >> >> >>
> >> >> >> Cheers,
> >> >> >>
> >> >> >> Frederick
> >> >> >>
> >> >> >> On Sun, Dec 11, 2016 at 12:46:23AM -0800, Jeff Newmiller wrote:
> >> >> >> > No. Read Hadley Wickham's "Advanced R" to learn why not.
> >> >> >> > --
> >> >> >> > Sent from my phone. Please excuse my brevity.
> >> >> >> >
> >> >> >> > On December 10, 2016 10:24:49 PM PST, frederik at ofb.net wrote:
> >> >> >> > >Dear R-Help,
> >> >> >> > >
> >> >> >> > >I asked this question on StackOverflow,
> >> >> >> > >
> >> >> >> > >http://stackoverflow.com/questions/41083293/in-r-how-do-i-de
> >> >> >> > >fin e-a -fu nction-which-is-equivalent-to-deparsesubstitutex
> >> >> >> > >
> >> >> >> > >but thought perhaps R-help would be more appropriate.
> >> >> >> > >
> >> >> >> > >I want to write a function in R which grabs the name of a
> >> >> >> > >variable from the context of its caller's caller. I think
> >> >> >> > >the problem I have is best understood by asking how to
> >> >> >> > >compose `deparse` and
> >> >> `substitute`.
> >> >> >> > >You can see that a naive composition does not work:
> >> >> >> > >
> >> >> >> > >    # a compose operator
> >> >> >> > >    >  `%c%` = function(x,y)function(...)x(y(...))
> >> >> >> > >
> >> >> >> > >    # a naive attempt to combine deparse and substitute
> >> >> >> > >    > desub = deparse %c% substitute
> >> >> >> > >    > f=function(foo) { message(desub(foo)) }
> >> >> >> > >    > f(log)
> >> >> >> > >    foo
> >> >> >> > >
> >> >> >> > >    # this is how it is supposed to work
> >> >> >> > >    > g=function(foo) { message(deparse(substitute(foo))) }
> >> >> >> > >    > g(log)
> >> >> >> > >    log
> >> >> >> > >
> >> >> >> > >Is there a way I can define a function `desub` so that
> >> >> >> > >`desub(x)` has the same value as `deparse(substitute(x))` in
> >> >> >> > >every
> >> context?
> >> >> >> > >
> >> >> >> > >Thank you,
> >> >> >> > >
> >> >> >> > >Frederick Eaton
> >> >> >> > >
> >> >> >> > >______________________________________________
> >> >> >> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and
> >> >> >> > >more, see https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >> > >PLEASE do read the posting guide
> >> >> >> > >http://www.R-project.org/posting-guide.html
> >> >> >> > >and provide commented, minimal, self-contained, reproducible
> code.
> >> >> >> >
> >> >> >>
> >> >> >> ______________________________________________
> >> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >> >> see https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >> PLEASE do read the posting guide
> >> >> >> http://www.R-project.org/posting-guide.html
> >> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >> >> > see https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Tue Dec 13 15:23:23 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Dec 2016 06:23:23 -0800
Subject: [R] Merging two columns of unequal length
In-Reply-To: <CAA99HCx8epqZR3QjjGhsC3bkotBMEtL27dM1A+c=qmZzRna8eQ@mail.gmail.com>
References: <CAA99HCx8epqZR3QjjGhsC3bkotBMEtL27dM1A+c=qmZzRna8eQ@mail.gmail.com>
Message-ID: <FE98604D-D1F2-49C5-A74B-CA42E0C495AF@dcn.davis.ca.us>

I frequently work with mismatched-length data, but I think I would rarely want this behaviour because there is no compelling reason to believe that all of the NA values should wind up at the end of the data as you suggest. Normally there is a second column that controls where things should line up, and the merge function handles that reliably. If merge is not appropriate then I usually regard that as a warning that those data should perhaps be rbinded or stacked rather than cbinded.

I think Hadley Wickham's paper on tidy data [1] describes this philosophy well. 

[1] https://www.jstatsoft.org/article/view/v059i10
-- 
Sent from my phone. Please excuse my brevity.

On December 13, 2016 2:15:15 AM PST, William Michels via R-help <r-help at r-project.org> wrote:
>You should review "The Recycling Rule in R" before attempting to
>perform functions on 2 or more vectors of unequal lengths:
>
>https://cran.r-project.org/doc/manuals/R-intro.html#The-recycling-rule
>
>Most often, the "Recycling Rule" does exactly what the researcher
>intends (automatically). And in many cases, performing functions on
>data of unequal (or not evenly divisible) lengths is either 1) an
>indication of problems with the input data, or 2) an indication that
>the researcher is unnecessarily 'forcing' data into a rectangular data
>structure, when another approach might be better (e.g. the use of the
>tapply function).
>
>However, if you see no other way, the functions "cbind.na" and/or
>"rbind.na" available from Andrej-Nikolai Spiess perform binding of
>vectors without recycling:
>
>http://www.dr-spiess.de/Rscripts.html
>
>All you have to do is download and source the correct R-script, and
>call the function:
>
>> cbind(1:5, 1:2)
>     [,1] [,2]
>[1,]    1    1
>[2,]    2    2
>[3,]    3    1
>[4,]    4    2
>[5,]    5    1
>
>Warning message:
>In cbind(1:5, 1:2) :
>  number of rows of result is not a multiple of vector length (arg 2)
>
>> source("/Users/myhomedirectory/Downloads/cbind.na.R")
>> cbind.na(1:5, 1:2)
>     [,1] [,2]
>[1,]    1    1
>[2,]    2    2
>[3,]    3   NA
>[4,]    4   NA
>[5,]    5   NA
>>
>
>This issue arises so often, Dr. Spiess's two scripts "rbind.na" and
>"cbind.na" have my vote for inclusion into the base-R distribution.
>
>Best of luck,
>
>W Michels, Ph.D.
>
>
>On Mon, Dec 12, 2016 at 3:41 PM, Bailey Hewitt <bailster at hotmail.com>
>wrote:
>>
>> Dear R Help,
>>
>>
>> I am trying to put together two columns of unequal length in a data
>frame. Unfortunately, so far I have been unsuccessful in the functions
>I have tried (such as cbind). The code I am currently using is : (I
>have highlighted the code that is not working)
>>
>>
>> y<- mydata[,2:75]
>>
>> year <- mydata$Year
>>
>> res <- data.frame()
>>
>> for (i in 1:74){
>>
>>   y.val <- y[,i]
>>
>>   lake.lm= lm(y.val ~ year)
>>
>>   lake.res=residuals(lake.lm)
>>
>>   new.res <- data.frame(lake.res=lake.res)
>>
>>   colnames(new.res) <- colnames(y)[i]
>>
>> #cbind doesn't work because of the unequal lengths of my data columns
>>
>>   res <- cbind(res, new.res)
>>
>>   print(res)
>>
>> }
>>
>>
>> mydata is a csv file with "Year" from 1950 on as my first column and
>then each proceeding column has a lake name and a day of year (single
>number) in each row.
>>
>>
>> Please let me know if there is any more information I can provide as
>I am new to emailing in this list. Thank you for your time!
>>
>>
>> Bailey Hewitt
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Dec 13 17:00:32 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 13 Dec 2016 16:00:32 +0000
Subject: [R] K-modes clustering : how to choose the number of clusters?
In-Reply-To: <8bffd83f1f7a6b0a1035a78b030de@cweb11.nm.nhnsystem.com>
References: <8bffd83f1f7a6b0a1035a78b030de@cweb11.nm.nhnsystem.com>
Message-ID: <76002552fdc14a728a643661e5128a24@exch-2p-mbx-w2.ads.tamu.edu>

Function NbClust() in package NbClust computes 30 different indices for determining the number of clusters.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of ???
Sent: Tuesday, December 13, 2016 5:08 AM
To: r-help at R-project.org
Subject: [R] K-modes clustering : how to choose the number of clusters?

 
Dear all. 
 
I tried to cluster the data with categorical variables with K-modes using klaR packages. 
 
I tried to find the optimal number of clusters by considering the average silhouette width though..  
 
In k-modes, however, the average silhouette width increases, when the the number of clusters increases in my case.
 
So i tried to derive the elbow plot and I got the attached graph. 
It is quite hard to which point is the location of a bend in this plot.. 
In this case, how can I choose the best number of groups? 
 
Can anyone introduce better method that help choose the optimal number of clusters for K-modes? 
 
Thanks!
 
Kind regards
 
Ann. 

From gferraz29 at gmail.com  Tue Dec 13 17:02:11 2016
From: gferraz29 at gmail.com (=?utf-8?Q?Gon=C3=A7alo_Ferraz?=)
Date: Tue, 13 Dec 2016 14:02:11 -0200
Subject: [R] R.app not installing
Message-ID: <7F7806EF-3D6E-4E05-8BD6-E19CF81F1A80@gmail.com>

Hi, Has anyone had problems installing R version 3.3.2 on Mac OS X 10.11.6?
I am trying to install from the binary and the R.app is nowhere to be found. It is not in my applications folder and does not appear in the spotlight search.
I can open R with ESS, but then can?t install packages from there. 
Any information about this?
Thank you,
Gon?alo

From gferraz29 at gmail.com  Tue Dec 13 17:15:13 2016
From: gferraz29 at gmail.com (=?utf-8?Q?Gon=C3=A7alo_Ferraz?=)
Date: Tue, 13 Dec 2016 14:15:13 -0200
Subject: [R] Can't install packages from ESS command line after upgrading to
	R 3.3.2 on MacOS
Message-ID: <70B20945-12FC-4747-A9F9-58CB86F4EEFC@gmail.com>

Hi, 

I just upgraded R to version 3.3.2 on a Mac OS X system. I suspect something may have gone wrong with the installation (despite a ?successfully installed? message) because the R.App is nowhere to be found.
Nevertheless, I can open R in ESS. The problem is I can?t install packages from there. Here is an example of the error message:

> install.packages("rjags")
--- Please select a CRAN mirror for use in this session ---
trying URL 'https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3/rjags_4-6.tgz'
Content type 'application/x-gzip' length 249529 bytes (243 KB)
==================================================
downloaded 243 KB

The downloaded binary packages are in
	/var/folders/kf/zkk64rtj5197pzwq94qfls0w0000gn/T//RtmpuSb7P1/downloaded_packages
> library(rjags)
Loading required package: coda
Error : .onLoad failed in loadNamespace() for 'rjags', details:
  call: dyn.load(file, DLLpath = DLLpath, ...)
  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rjags/libs/rjags.so':
  dlopen(/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rjags/libs/rjags.so, 10): Library not loaded: /usr/local/lib/libjags.4.dylib
  Referenced from: /Library/Frameworks/R.framework/Versions/3.3/Resources/library/rjags/libs/rjags.so
  Reason: image not found
Error: package or namespace load failed for ?rjags?

Does anyone know what may be going on?

Thank you,

Gon?alo

 

From murdoch.duncan at gmail.com  Tue Dec 13 18:12:18 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 13 Dec 2016 12:12:18 -0500
Subject: [R] Log plus one transformation in R
In-Reply-To: <584E9769020000CB00169845@smtp.medicine.umaryland.edu>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<86587113-D978-4406-841D-547DB74FEACE@comcast.net>
	<584E9769020000CB00169845@smtp.medicine.umaryland.edu>
Message-ID: <60a2a421-17d2-4c9b-9685-57b5c429b246@gmail.com>

On 12/12/2016 12:26 PM, John Sorkin wrote:
> David,
>   
> I did read the help page. All it says is
> log1p(x) computes log(1+x) accurately also for |x| << 1 (and less
> accurately when x is approximately -1).
> This gives me pause. Does it mean that log(x) does not give accurate
> results? If log1p gives more accurate values than log, why is the log
> function not written to use the more accurate computation performed by
> log1p.

I don't think anyone has directly answered these questions.  The problem 
isn't with log(), it's with the representation of floating point numbers 
in R.  The log of 1 + 10^(-100) is very close to 10^(-100), but since 1 
+ 1e-100 evaluates to 1 (we only keep 15 or 16 digits of precision), 
log(1 + 1e-100) will come out as zero.  On the other hand, log1p(1e-100) 
evaluates correctly to 1e-100.

>   I don't believe I can look directly at the code for log and
> log1p,

R is open source, so you could, but those are likely coming from system 
libraries, so it isn't easy to see how the approximations are being done.

Duncan Murdoch
>   so I need to rely on the kindness of others to explain the
> differences between the computations performed by the functions. I guess
> the test I ran, log1p(0.000001)/log(0.000001+1), did not have enough
> precision to demonstrate a difference between the two functions.
> John
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> >>> David Winsemius <dwinsemius at comcast.net> 12/12/16 12:05 PM >>>
>
> > On Dec 12, 2016, at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
> wrote:
> >
> > At the risk of being flamed . . .
> > What is the difference between log1p(x) and log(x+1)?
> > The two methods appear to give the same results:
> >> log1p(0.000001)/log(0.000001+1)
> > [1] 1
> > John
>
> Read the help page more carefully.
>


From jsorkin at grecc.umaryland.edu  Tue Dec 13 18:18:49 2016
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Tue, 13 Dec 2016 12:18:49 -0500
Subject: [R] Log plus one transformation in R
In-Reply-To: <60a2a421-17d2-4c9b-9685-57b5c429b246@gmail.com>
References: <1A1C81A9-23EF-4F02-805B-E0CD7A34FD35@gmail.com>
	<CAF8bMcYOZAtpVsWGqdDO_7ZyLtT_cRSmH5684syQC31QPLW_BA@mail.gmail.com>
	<584E8FC0020000CB0016982B@smtp.medicine.umaryland.edu>
	<86587113-D978-4406-841D-547DB74FEACE@comcast.net>
	<584E9769020000CB00169845@smtp.medicine.umaryland.edu>
	<60a2a421-17d2-4c9b-9685-57b5c429b246@gmail.com>
Message-ID: <584FE72B020000CB00169A89@smtp.medicine.umaryland.edu>

Duncan,
Thank you. You are correct no one answered my question , despite the fact that several people reply to my email, until you replied. Your exclamation is quite clear and I thank you for your kindness. I did not pursue my question any further as I was concerned that I would be flamed.
John

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Dec 13, 2016, at 12:12 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 12/12/2016 12:26 PM, John Sorkin wrote:
>> David,
>> 
>> I did read the help page. All it says is
>> log1p(x) computes log(1+x) accurately also for |x| << 1 (and less
>> accurately when x is approximately -1).
>> This gives me pause. Does it mean that log(x) does not give accurate
>> results? If log1p gives more accurate values than log, why is the log
>> function not written to use the more accurate computation performed by
>> log1p.
> 
> I don't think anyone has directly answered these questions.  The problem 
> isn't with log(), it's with the representation of floating point numbers 
> in R.  The log of 1 + 10^(-100) is very close to 10^(-100), but since 1 
> + 1e-100 evaluates to 1 (we only keep 15 or 16 digits of precision), 
> log(1 + 1e-100) will come out as zero.  On the other hand, log1p(1e-100) 
> evaluates correctly to 1e-100.
> 
>>  I don't believe I can look directly at the code for log and
>> log1p,
> 
> R is open source, so you could, but those are likely coming from system 
> libraries, so it isn't easy to see how the approximations are being done.
> 
> Duncan Murdoch
>>  so I need to rely on the kindness of others to explain the
>> differences between the computations performed by the functions. I guess
>> the test I ran, log1p(0.000001)/log(0.000001+1), did not have enough
>> precision to demonstrate a difference between the two functions.
>> John
>> 
>> 
>> 
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and
>> Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>>>> David Winsemius <dwinsemius at comcast.net> 12/12/16 12:05 PM >>>
>> 
>>> On Dec 12, 2016, at 8:53 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
>> wrote:
>>> 
>>> At the risk of being flamed . . .
>>> What is the difference between log1p(x) and log(x+1)?
>>> The two methods appear to give the same results:
>>>> log1p(0.000001)/log(0.000001+1)
>>> [1] 1
>>> John
>> 
>> Read the help page more carefully.
>> 
> 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From dcarlson at tamu.edu  Tue Dec 13 18:21:23 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 13 Dec 2016 17:21:23 +0000
Subject: [R] Reshape to wide format
In-Reply-To: <CA+8X3fXtsir220YwpgRZ20wktiYRm=Br887SCU_vY3V89ZGYXA@mail.gmail.com>
References: <CAMLwc7O7kCZbeMXie8irri7Xn564VsSQ-pN2=Y8eGwqYWdXqBQ@mail.gmail.com>
	<CA+8X3fXtsir220YwpgRZ20wktiYRm=Br887SCU_vY3V89ZGYXA@mail.gmail.com>
Message-ID: <69d5c080a2444e9cafdab13513eca36a@exch-2p-mbx-w2.ads.tamu.edu>

You can also use function reshape() in stats:

temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
wide <- reshape(temp, v.names="precip", timevar="ID", idvar="month",
     direction="wide",  drop=c("iso3", "lon", "lat", "dm"))
wide

   month precip.AFG6132 precip.AFG6133
1      1      0.9966658    1.133129032
2      2      0.1567117    0.355208276
3      3      0.2424774    0.307277419
4      4      0.0000000    0.008316000
5      5      0.0000000    0.000000000
6      6      0.0000000    0.000000000
7      7      0.0000000    0.000000000
8      8      0.0000000    0.000836129
9      9      0.0000000             NA
10    10      0.0000000             NA
11    11      0.1215360             NA
12    12      0.3886606             NA

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Tuesday, December 13, 2016 2:59 AM
To: Miluji Sb; r-help mailing list
Subject: Re: [R] Reshape to wide format

Hi Milu,
I may have the wrong idea, but is this what you want?

temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
library(prettyR)
newtemp<-stretch_df(temp,"month","precip")[,c(5,7,8)]
names(newtemp)<-c("month",unique(temp$ID))

Jim


On Tue, Dec 13, 2016 at 4:10 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have the following monthly data by coordinates:
>
> I would like to reshape this data to wide format so that each column is a
> coordinate and each row is a month,
>
> coordinate1 coordinate2 coordinate3...
> Month 1
> Month 2
>
> Is the best option to concatenate the iso3, lon, and lat variables to
> create an ID variable? I realize that this question might be very basic but
> I'm slightly baffled. Thank you.
>
> temp <- dput(head(precip_2000,20))
> structure(list(iso3 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("AFG",
> "AGO", "ALB", "ARE", "ARG", "ARM", "AUS", "AUT", "AZE", "BDI",
> "BEL", "BEN", "BFA", "BGD", "BGR", "BHS", "BIH", "BLR", "BLZ",
> "BOL", "BRA", "BRN", "BTN", "BWA", "CAF", "CAN", "CHE", "CHL",
> "CHN", "CIV", "CMR", "COD", "COG", "COL", "CRI", "CUB", "CYP",
> "CZE", "DEU", "DJI", "DNK", "DOM", "DZA", "ECU", "EGY", "ERI",
> "ESH", "ESP", "EST", "ETH", "FIN", "FJI", "FLK", "FRA", "GAB",
> "GBR", "GEO", "GHA", "GIN", "GNB", "GNQ", "GRC", "GRL", "GTM",
> "GUF", "GUY", "HND", "HRV", "HTI", "HUN", "IDN", "IND", "IRL",
> "IRN", "IRQ", "ISL", "ISR", "ITA", "JAM", "JOR", "JPN", "KAZ",
> "KEN", "KGZ", "KHM", "KIR", "KOR", "KWT", "LAO", "LBN", "LBR",
> "LBY", "LCA", "LKA", "LSO", "LTU", "LUX", "LVA", "MAR", "MDA",
> "MDG", "MEX", "MKD", "MLI", "MMR", "MNE", "MNG", "MOZ", "MRT",
> "MWI", "MYS", "NAM", "NCL", "NER", "NGA", "NIC", "NLD", "NOR",
> "NPL", "NZL", "OMN", "PAK", "PAN", "PER", "PHL", "PNG", "POL",
> "PRI", "PRK", "PRT", "PRY", "QAT", "ROU", "RUS", "RWA", "SAU",
> "SDN", "SEN", "SJM", "SLB", "SLE", "SLV", "SOM", "SRB", "SUR",
> "SVK", "SVN", "SWE", "SWZ", "SYR", "TCD", "TGO", "THA", "TJK",
> "TKM", "TLS", "TUN", "TUR", "TWN", "TZA", "UGA", "UKR", "URY",
> "USA", "UZB", "VEN", "VNM", "VUT", "YEM", "ZAF", "ZMB", "ZWE"
> ), class = "factor"), lon = c(61L, 61L, 61L, 61L, 61L, 61L, 61L,
> 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L
> ), lat = c(32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L,
> 32L, 32L, 33L, 33L, 33L, 33L, 33L, 33L, 33L, 33L), dm = structure(c(1L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 1L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L), .Label = c("2000m1", "2000m10", "2000m11",
> "2000m12", "2000m2", "2000m3", "2000m4", "2000m5", "2000m6",
> "2000m7", "2000m8", "2000m9"), class = "factor"), month = c(1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L), precip = c(0.996665806451613, 0.156711724137931,
> 0.242477419354839, 0, 0, 0, 0, 0, 0, 0, 0.121536, 0.38866064516129,
> 1.13312903225806, 0.355208275862069, 0.307277419354839, 0.008316,
> 0, 0, 0, 0.0008361290322581)), .Names = c("iso3", "lon", "lat",
> "dm", "month", "precip"), row.names = c(NA, 20L), class = "data.frame")
>
> Sincerely,
>
> Milu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From anec at aneconomist.com  Tue Dec 13 18:33:03 2016
From: anec at aneconomist.com (Muhammad Anees)
Date: Tue, 13 Dec 2016 22:33:03 +0500
Subject: [R] WaveletComp with as.POSIXct Showing Error on Date for:
	2000-01-01 Format
Message-ID: <CAEhkw2245_SumuC=1nQXEb4JcP0GNBZY9MeuckBJ00Smq58mWg@mail.gmail.com>

Dear All,

I tried to find an answer everywhere including stackoverflows and manuals
but there is no specific solution that might have helped. Hence, I am sure
you will bear with me for this first query.

I am trying to replicate production of Wavelet Coherency using the
following codes: I dont know why the two errors/warnings appear and my
resultant figures dont show up the time as I use the format of Date as
2000-01-01

Code used is:

> library(WaveletComp)> x<- API> y<- TFS> my.data = data.frame(x = x, y = y)> my.wc = analyze.coherency(my.data, my.pair = c("x","y"),+                           loess.span = 0,+                           dt = 1/24, dj = 1/100,+                           lowerPeriod = 1/2,+                           make.pval = T, n.sim = 10)> wc.image(my.wc, n.levels = 250,+          siglvl.contour = 0.1, siglvl.arrow = 0.05,+          legend.params = list(lab = "cross-wavelet power levels"))> wc.image(my.wc, n.levels = 250, color.key = "interval",+          siglvl.contour = 0.1, siglvl.arrow = 0.05, which.arrow.sig = "wt",+          legend.params = list(lab = "cross-wavelet power levels"))> wc.image(my.wc, which.image = "wc", n.levels = 250,+          siglvl.contour = 0.1, siglvl.arrow = 0.05,+          legend.params = list(lab = "wavelet coherence levels"))> my.date = seq(as.POSIXct("2002-01-01),+               by = "hour", length.out = 24*96)########################################
########################################


Warning messages:1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
  unknown timezone '%F %T'2: In as.POSIXct.POSIXlt(x) : unknown
timezone '%F %T'3: In strptime(x, f, tz = tz) : unknown timezone '%F
%T'4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone '%F %T'

########################################
########################################

I would be happier to see a suggestion for removing this warning and
get the results as the time axis showing Date as in the data on the
figures of my output from above.

Regards



------------------------------
Muhammad Anees
Assistant Professor,
The Econometrician &
Statistical Consultant @
www.aneconomist.com

	[[alternative HTML version deleted]]


From topijush at gmail.com  Tue Dec 13 11:19:13 2016
From: topijush at gmail.com (Pijush Das)
Date: Tue, 13 Dec 2016 15:49:13 +0530
Subject: [R] Unable arrange the functions according to the requirement in
 the help page of my package.
Message-ID: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>

Hello Sir,


I am trying to create my package in R. I have few functions for this
package. After including all the functions in the package, I have seen that
the help page does not contain the functions sequentially as it is demanded
by the package. e.g.

The package requires the function arrangement given below:

a()
d()
c()
b()

After building the package , found that function arrangement given below
a()
b()
c()
d()

Another problem which I am facing is given below:
I have created the vignette file in R markdown file format with the help of
VignetteBuilder: knitr. There is no error but after building and checking
the package I unable to see the  vignette.pdf in the Help file.

I have seen that there is a Index.html page in other package.  I able to
create such index.html file but I unable to connect all the function and
the vignette.pdf in that html file.

I unable to understand the document found in the website describing about
how to create an R package.  There I do not find any clue to solve my
problem.


Please help me.


Thank you very much.

regards
Pijush Das

	[[alternative HTML version deleted]]


From farshad.fathian at gmail.com  Tue Dec 13 10:23:50 2016
From: farshad.fathian at gmail.com (Farshad Fathian)
Date: Tue, 13 Dec 2016 12:53:50 +0330
Subject: [R]  data manipulation
Message-ID: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>

Hi,

 

I couldn't access to data file about PSCoperwait by
http://massey.ac.nz/~pscoperwait/ts/cbe.dat.

 

Looking forward to hearing from you,


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Dec 13 19:43:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Dec 2016 10:43:11 -0800
Subject: [R] Can't install packages from ESS command line after
	upgrading to R 3.3.2 on MacOS
In-Reply-To: <70B20945-12FC-4747-A9F9-58CB86F4EEFC@gmail.com>
References: <70B20945-12FC-4747-A9F9-58CB86F4EEFC@gmail.com>
Message-ID: <DC89EDF1-A478-45B4-BDF6-E7F062259241@comcast.net>


> On Dec 13, 2016, at 8:15 AM, Gon?alo Ferraz <gferraz29 at gmail.com> wrote:
> 
> Hi, 
> 
> I just upgraded R to version 3.3.2 on a Mac OS X system. I suspect something may have gone wrong with the installation (despite a ?successfully installed? message) because the R.App is nowhere to be found.

There are two different installation packages. One has the GUI and one doesn't. Which one did you use?

And this is really coming to the wrong mailing list:

Should have been directed to: R-SIG-Mac at r-project.org


> Nevertheless, I can open R in ESS. The problem is I can?t install packages from there. Here is an example of the error message:
> 
>> install.packages("rjags")
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'https://vps.fmvz.usp.br/CRAN/bin/macosx/mavericks/contrib/3.3/rjags_4-6.tgz'
> Content type 'application/x-gzip' length 249529 bytes (243 KB)
> ==================================================
> downloaded 243 KB
> 
> The downloaded binary packages are in
> 	/var/folders/kf/zkk64rtj5197pzwq94qfls0w0000gn/T//RtmpuSb7P1/downloaded_packages

rjags requires an external package to be installed to be functional

packageDescription('rjags')

# SystemRequirements: JAGS 4.x.y

Is that done?

>> library(rjags)
> Loading required package: coda
> Error : .onLoad failed in loadNamespace() for 'rjags', details:
>  call: dyn.load(file, DLLpath = DLLpath, ...)
>  error: unable to load shared object '/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rjags/libs/rjags.so':
>  dlopen(/Library/Frameworks/R.framework/Versions/3.3/Resources/library/rjags/libs/rjags.so, 10): Library not loaded: /usr/local/lib/libjags.4.dylib
>  Referenced from: /Library/Frameworks/R.framework/Versions/3.3/Resources/library/rjags/libs/rjags.so
>  Reason: image not found
> Error: package or namespace load failed for ?rjags?

So, is there a symlink in that directory?


> 
> Does anyone know what may be going on?
> 
> Thank you,
> 
> Gon?alo
> 
-- 

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Tue Dec 13 19:43:49 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 13 Dec 2016 18:43:49 +0000
Subject: [R] data manipulation
In-Reply-To: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
Message-ID: <58504165.4080106@sapo.pt>

Hello,

And what has your question to do with R?
Please read the posting guide before posting and when you do, post a 
question where at least the link is correct.

Rui Barradas


Em 13-12-2016 09:23, Farshad Fathian escreveu:
> Hi,
>
>
>
> I couldn't access to data file about PSCoperwait by
> http://massey.ac.nz/~pscoperwait/ts/cbe.dat.
>
>
>
> Looking forward to hearing from you,
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Tue Dec 13 19:47:36 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Dec 2016 10:47:36 -0800
Subject: [R] Unable arrange the functions according to the requirement
 in the help page of my package.
In-Reply-To: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>
References: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>
Message-ID: <CAGxFJbTFt+FsCZXwzQd4WZOggNjmiqCVpxp_L05K8g_NjQCLxw@mail.gmail.com>

Please post at r-package-devel, not here. You will probably get a
faster, better response there, too.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 13, 2016 at 2:19 AM, Pijush Das <topijush at gmail.com> wrote:
> Hello Sir,
>
>
> I am trying to create my package in R. I have few functions for this
> package. After including all the functions in the package, I have seen that
> the help page does not contain the functions sequentially as it is demanded
> by the package. e.g.
>
> The package requires the function arrangement given below:
>
> a()
> d()
> c()
> b()
>
> After building the package , found that function arrangement given below
> a()
> b()
> c()
> d()
>
> Another problem which I am facing is given below:
> I have created the vignette file in R markdown file format with the help of
> VignetteBuilder: knitr. There is no error but after building and checking
> the package I unable to see the  vignette.pdf in the Help file.
>
> I have seen that there is a Index.html page in other package.  I able to
> create such index.html file but I unable to connect all the function and
> the vignette.pdf in that html file.
>
> I unable to understand the document found in the website describing about
> how to create an R package.  There I do not find any clue to solve my
> problem.
>
>
> Please help me.
>
>
> Thank you very much.
>
> regards
> Pijush Das
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From oriolebaltimore at gmail.com  Tue Dec 13 20:19:52 2016
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Tue, 13 Dec 2016 14:19:52 -0500
Subject: [R] tests for significance on conditional inference trees from
	party package
Message-ID: <CAL2fYnPoGanDC67ejW78abz3nqCanS03-Q14nLgoiMwaGh9rbw@mail.gmail.com>

Dear group,
Please allow me to ask a naive question and pardon if it is qualified
as stupid question.

I am using party package to classify covariates and predict
distribution of survival times for the classified variables.
Typically I have a matrix of covariates (columns) including outcome
data (overall survival in months, censor status) and other covariates
I want to split in tree (such as treatment dose etc. ) . Rows are
patients (~1000 patients).

Now similarly I have many such matrices (4K)  with completely
different set of covariates but identical outcome data and patients
(in rows). i cannot combine all data into a giant matrix,because these
covariates are totally independent.

Currently I am running this model in a loop and storing the tree and
parsing the tree structure.

My question is, is there some testing method to choose or rank these
4K trees such that I can select each tree from top to bottom. I know
each tree is important in its own way.    If selection based on
significance is required, then is there any other way instead of
conditional inference tree , that partitions data but will also carry
some significance to choose from.

Thanks!
.


From Achim.Zeileis at uibk.ac.at  Tue Dec 13 21:22:43 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 13 Dec 2016 21:22:43 +0100 (CET)
Subject: [R] tests for significance on conditional inference trees from
 party package
In-Reply-To: <CAL2fYnPoGanDC67ejW78abz3nqCanS03-Q14nLgoiMwaGh9rbw@mail.gmail.com>
References: <CAL2fYnPoGanDC67ejW78abz3nqCanS03-Q14nLgoiMwaGh9rbw@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1612132114190.5927@paninaro>

Adrian,

thanks for your interest.

On Tue, 13 Dec 2016, Adrian Johnson wrote:

> Dear group,
> Please allow me to ask a naive question and pardon if it is qualified
> as stupid question.
>
> I am using party package to classify covariates and predict distribution 
> of survival times for the classified variables. Typically I have a 
> matrix of covariates (columns) including outcome data (overall survival 
> in months, censor status) and other covariates I want to split in tree 
> (such as treatment dose etc. ) . Rows are patients (~1000 patients).
>
> Now similarly I have many such matrices (4K)  with completely different 
> set of covariates but identical outcome data and patients (in rows). i 
> cannot combine all data into a giant matrix,because these covariates are 
> totally independent.

If the response variable is the same and the patients are the same, then I 
don't see why - conceptionally - you couldn't combine "totally 
independent" variables in the same tree. Or maybe I misunderstand what 
"totally independent" is.

Practically - however, choosing a tree from 4,000 regressor variables will 
be challenging, especially if you want to adjust in some way for the 
multiple testing. So maybe some additional structure would help here.

> Currently I am running this model in a loop and storing the tree and
> parsing the tree structure.

Parsing the tree structure is quite cumbersome in the old "party" 
implementation. This was one of the main motivations to establish the 
reimplementation in "partykit". This has a much better and more accessible 
tree infrastructure. See the vignettes in the "partykit" package for more 
details - especially vignette("partykit", package = "partykit") gives a 
good overview of the building blocks.

Additionally, over at StackOverflow you can find various additional 
bits and pieces that may be helpful. Look for the "party" tag.

Finally, there is also a partykit support forum on R-Forge.

> My question is, is there some testing method to choose or rank these 4K 
> trees such that I can select each tree from top to bottom. I know each 
> tree is important in its own way.

It is not clear to me what/how you want to rank the results. However, 
looking at the sources of information listed above might take you a few 
steps further.

> If selection based on significance is required, then is there any other 
> way instead of conditional inference tree , that partitions data but 
> will also carry some significance to choose from.

The MOB (model-based recursive partitioning) algorithm is also based on 
significance tests and implemented in the "partykit" package. It uses 
parametric asymptotic inference rather than nonparametric conditional 
inference. Otherwise the two approaches are very similar in many respects.

Hope that helps,
Z


From marna.wagley at gmail.com  Wed Dec 14 00:37:39 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Tue, 13 Dec 2016 15:37:39 -0800
Subject: [R] how to show a plot without overlaying the text on top of the
	another text?
Message-ID: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>

Hi R user,
I have created using metaNMDS (Nonmetirc Multidimensional Scaling, MDS) to
show species composition but some of the species are concentrated at some
of the sites so that the name of the species are overlaid and it was
almost impossible to read the species name in the figure. I was wondering how
we can show the plot without overlaying the text on top of another.
I used the following to create the plot. would you mind to suggest me?

comm.bc.mds <- metaMDS(dat, dist = "bray")
ordiplot(comm.bc.mds, display = "sites", type = "text")
ordipointlabel(comm.bc.mds,font = c(1, 1), cex = c(0.5, 0.3))

Thanks

MW

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Wed Dec 14 03:42:50 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 13 Dec 2016 20:42:50 -0600
Subject: [R] data manipulation
In-Reply-To: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
Message-ID: <CAAJSdjh0s4SVbZTTwSoaLiMMxxpVN5dgkjr7PsqmvdKejHM83w@mail.gmail.com>

On Tue, Dec 13, 2016 at 3:23 AM, Farshad Fathian <farshad.fathian at gmail.com>
wrote:

> Hi,
>
> I couldn't access to data file about PSCoperwait by
> http://massey.ac.nz/~pscoperwait/ts/cbe.dat.
>

?First off, this post is nearly useless. You don't tell us what you tried
to do. And you didn't tell us what error message you got.?


?From a fast test, the reason is that the above URL is invalid.. It gets a
404 error. That is "requested document does not exist." You can't read that
which does not exist. Why doesn't it exist? I don't know - ask Massey
University of New Zealand.


>
> Looking forward to hearing from you,
>
>
>


-- 
Heisenberg may have been here.

http://xkcd.com/1770/

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From shirley.roitberg at gmail.com  Wed Dec 14 00:08:41 2016
From: shirley.roitberg at gmail.com (Shirley R)
Date: Tue, 13 Dec 2016 17:08:41 -0600
Subject: [R] Question regarding package deSolve and R versions
Message-ID: <CAFXpiv4eUguKK0oTwPE+Bm-FnraXw43CMYKbcU=A7nqz_nPSeQ@mail.gmail.com>

To whom it may concern,

I've run into trouble installing the crqa package. R error messages tell me
it is because I don't have the deSolve package. I cannot install the
deSolve package, but according to everything I've found online, my version
of R (3.2.1) should be fine to work with deSolve. Is there an older version
of R that I could use that would work?


Thank you!

Shirley

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Dec 14 06:58:32 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Dec 2016 21:58:32 -0800
Subject: [R] Question regarding package deSolve and R versions
In-Reply-To: <CAFXpiv4eUguKK0oTwPE+Bm-FnraXw43CMYKbcU=A7nqz_nPSeQ@mail.gmail.com>
References: <CAFXpiv4eUguKK0oTwPE+Bm-FnraXw43CMYKbcU=A7nqz_nPSeQ@mail.gmail.com>
Message-ID: <493EAC01-6882-4DB8-820B-59F76FA3D5AB@comcast.net>


> On Dec 13, 2016, at 3:08 PM, Shirley R <shirley.roitberg at gmail.com> wrote:
> 
> To whom it may concern,
> 
> I've run into trouble installing the crqa package. R error messages tell me
> it is because I don't have the deSolve package. I cannot install the
> deSolve package, but according to everything I've found online, my version
> of R (3.2.1) should be fine to work with deSolve. Is there an older version
> of R that I could use that would work?
> 

Read the Posting Guide. It should be obvious then than you have omitted much of the requested detail regarding your problem.


> 
> Thank you!
> 
> Shirley
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Wed Dec 14 07:28:38 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Dec 2016 22:28:38 -0800
Subject: [R] Question regarding package deSolve and R versions
In-Reply-To: <CAFXpiv4eUguKK0oTwPE+Bm-FnraXw43CMYKbcU=A7nqz_nPSeQ@mail.gmail.com>
References: <CAFXpiv4eUguKK0oTwPE+Bm-FnraXw43CMYKbcU=A7nqz_nPSeQ@mail.gmail.com>
Message-ID: <9755E9B4-F370-4702-A751-70F8925BF46C@dcn.davis.ca.us>

You are approaching this the wrong way... you should be upgrading your version of R to be current.  The deSolve package is up to date... it is your R that is behind. 

You should also read the Posting Guide which would have told you this and also that you need to post using plain text and mention your OS among other things.
-- 
Sent from my phone. Please excuse my brevity.

On December 13, 2016 3:08:41 PM PST, Shirley R <shirley.roitberg at gmail.com> wrote:
>To whom it may concern,
>
>I've run into trouble installing the crqa package. R error messages
>tell me
>it is because I don't have the deSolve package. I cannot install the
>deSolve package, but according to everything I've found online, my
>version
>of R (3.2.1) should be fine to work with deSolve. Is there an older
>version
>of R that I could use that would work?
>
>
>Thank you!
>
>Shirley
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Dec 14 09:53:19 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 14 Dec 2016 19:53:19 +1100
Subject: [R] Unable arrange the functions according to the requirement
 in the help page of my package.
In-Reply-To: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>
References: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>
Message-ID: <CA+8X3fU4Zk-x8+-3L+6a=wXiie=ONVTeHu=Szc09pLr3W-g-+g@mail.gmail.com>

Hi Pijush,
Don't worry about the "arrangement" of the functions in the help file.
They are ordered alphabetically and this has nothing to do with the
order in which they are actually used. The more serious problem is
probably your help files. There should be a "man" (help) file for each
function, usually written in the "Rd" format. These files should be in
the "man" subdirectory of your package directory. Getting the right
files in the right directories is a bit tricky, and I am afraid that
you will just have to plow through the "Writing R Extensions" file to
learn how.

Jim

On Tue, Dec 13, 2016 at 9:19 PM, Pijush Das <topijush at gmail.com> wrote:
> Hello Sir,
>
>
> I am trying to create my package in R. I have few functions for this
> package. After including all the functions in the package, I have seen that
> the help page does not contain the functions sequentially as it is demanded
> by the package. e.g.
>
> The package requires the function arrangement given below:
>
> a()
> d()
> c()
> b()
>
> After building the package , found that function arrangement given below
> a()
> b()
> c()
> d()
>
> Another problem which I am facing is given below:
> I have created the vignette file in R markdown file format with the help of
> VignetteBuilder: knitr. There is no error but after building and checking
> the package I unable to see the  vignette.pdf in the Help file.
>
> I have seen that there is a Index.html page in other package.  I able to
> create such index.html file but I unable to connect all the function and
> the vignette.pdf in that html file.
>
> I unable to understand the document found in the website describing about
> how to create an R package.  There I do not find any clue to solve my
> problem.
>
>
> Please help me.
>
>
> Thank you very much.
>
> regards
> Pijush Das
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lists at dewey.myzen.co.uk  Wed Dec 14 10:42:12 2016
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Wed, 14 Dec 2016 09:42:12 +0000
Subject: [R] Unable arrange the functions according to the requirement
 in the help page of my package.
In-Reply-To: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>
References: <CAGa91ziQ30eZUtwVWCOYup2ZGGCNpw5bmtYpA5-b9t9sov394Q@mail.gmail.com>
Message-ID: <880635ab-1761-5db4-c48c-b7e87518e6aa@dewey.myzen.co.uk>

Dear Pijush

When you say your package demands the functions in a particular order 
what exactly do you mean by that?

On 13/12/2016 10:19, Pijush Das wrote:
> Hello Sir,
>
>
> I am trying to create my package in R. I have few functions for this
> package. After including all the functions in the package, I have seen that
> the help page does not contain the functions sequentially as it is demanded
> by the package. e.g.
>
> The package requires the function arrangement given below:
>
> a()
> d()
> c()
> b()
>
> After building the package , found that function arrangement given below
> a()
> b()
> c()
> d()
>
> Another problem which I am facing is given below:
> I have created the vignette file in R markdown file format with the help of
> VignetteBuilder: knitr. There is no error but after building and checking
> the package I unable to see the  vignette.pdf in the Help file.
>
> I have seen that there is a Index.html page in other package.  I able to
> create such index.html file but I unable to connect all the function and
> the vignette.pdf in that html file.
>
> I unable to understand the document found in the website describing about
> how to create an R package.  There I do not find any clue to solve my
> problem.
>
>
> Please help me.
>
>
> Thank you very much.
>
> regards
> Pijush Das
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jrkrideau at yahoo.ca  Wed Dec 14 12:56:35 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Wed, 14 Dec 2016 11:56:35 +0000
Subject: [R] data manipulation
In-Reply-To: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
Message-ID: <1768303695.2867148.1481716595402@mail.yahoo.com>

xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly 

    On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
 

 Hi,

 

I couldn't access to data file about PSCoperwait by
http://massey.ac.nz/~pscoperwait/ts/cbe.dat.

 

Looking forward to hearing from you,


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Dec 14 13:12:09 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 14 Dec 2016 12:12:09 +0000
Subject: [R] data manipulation
In-Reply-To: <1768303695.2867148.1481716595402@mail.yahoo.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
Message-ID: <58513719.5000309@sapo.pt>

Hello,

What do you mean by "gives me something"?

xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
   cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat': HTTP 
status was '404 Not Found'

Rui Barradas


Em 14-12-2016 11:56, John Kane via R-help escreveu:
> xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
> gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly
>
>      On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>
>
>   Hi,
>
>
>
> I couldn't access to data file about PSCoperwait by
> http://massey.ac.nz/~pscoperwait/ts/cbe.dat.
>
>
>
> Looking forward to hearing from you,
>
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bailster at hotmail.com  Wed Dec 14 16:13:49 2016
From: bailster at hotmail.com (Bailey Hewitt)
Date: Wed, 14 Dec 2016 15:13:49 +0000
Subject: [R] Merging two columns of unequal length
In-Reply-To: <FE98604D-D1F2-49C5-A74B-CA42E0C495AF@dcn.davis.ca.us>
References: <CAA99HCx8epqZR3QjjGhsC3bkotBMEtL27dM1A+c=qmZzRna8eQ@mail.gmail.com>,
	<FE98604D-D1F2-49C5-A74B-CA42E0C495AF@dcn.davis.ca.us>
Message-ID: <YQBPR01MB01131EDDACB238F693BE1501D99A0@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>

Sorry for the delay! Thank you very much! I think I am getting a better understanding of my options from what you have said. Thanks again for the quick replies and the information, I really appreciate it!


Bailey


________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Sent: December 13, 2016 9:23 AM
To: William Michels; William Michels via R-help; r-help at R-project.org
Subject: Re: [R] Merging two columns of unequal length

I frequently work with mismatched-length data, but I think I would rarely want this behaviour because there is no compelling reason to believe that all of the NA values should wind up at the end of the data as you suggest. Normally there is a second column that controls where things should line up, and the merge function handles that reliably. If merge is not appropriate then I usually regard that as a warning that those data should perhaps be rbinded or stacked rather than cbinded.

I think Hadley Wickham's paper on tidy data [1] describes this philosophy well.

[1] https://www.jstatsoft.org/article/view/v059i10
Tidy Data | Wickham | Journal of Statistical Software<https://www.jstatsoft.org/article/view/v059i10>
www.jstatsoft.org
Authors: Hadley Wickham: Title: Tidy Data: Abstract: A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research ...



--
Sent from my phone. Please excuse my brevity.

On December 13, 2016 2:15:15 AM PST, William Michels via R-help <r-help at r-project.org> wrote:
>You should review "The Recycling Rule in R" before attempting to
>perform functions on 2 or more vectors of unequal lengths:
>
>https://cran.r-project.org/doc/manuals/R-intro.html#The-recycling-rule
>
>Most often, the "Recycling Rule" does exactly what the researcher
>intends (automatically). And in many cases, performing functions on
>data of unequal (or not evenly divisible) lengths is either 1) an
>indication of problems with the input data, or 2) an indication that
>the researcher is unnecessarily 'forcing' data into a rectangular data
>structure, when another approach might be better (e.g. the use of the
>tapply function).
>
>However, if you see no other way, the functions "cbind.na" and/or
>"rbind.na" available from Andrej-Nikolai Spiess perform binding of
>vectors without recycling:
>
>http://www.dr-spiess.de/Rscripts.html
Supplemental Data<http://www.dr-spiess.de/Rscripts.html>
www.dr-spiess.de
data.frame.na Create a dataframe with variables of unequal length avoiding repetition or errors by filling with NA s. In contrast to classical data.frame, data.frame ...



>
>All you have to do is download and source the correct R-script, and
>call the function:
>
>> cbind(1:5, 1:2)
>     [,1] [,2]
>[1,]    1    1
>[2,]    2    2
>[3,]    3    1
>[4,]    4    2
>[5,]    5    1
>
>Warning message:
>In cbind(1:5, 1:2) :
>  number of rows of result is not a multiple of vector length (arg 2)
>
>> source("/Users/myhomedirectory/Downloads/cbind.na.R")
>> cbind.na(1:5, 1:2)
>     [,1] [,2]
>[1,]    1    1
>[2,]    2    2
>[3,]    3   NA
>[4,]    4   NA
>[5,]    5   NA
>>
>
>This issue arises so often, Dr. Spiess's two scripts "rbind.na" and
>"cbind.na" have my vote for inclusion into the base-R distribution.
>
>Best of luck,
>
>W Michels, Ph.D.
>
>
>On Mon, Dec 12, 2016 at 3:41 PM, Bailey Hewitt <bailster at hotmail.com>
>wrote:
>>
>> Dear R Help,
>>
>>
>> I am trying to put together two columns of unequal length in a data
>frame. Unfortunately, so far I have been unsuccessful in the functions
>I have tried (such as cbind). The code I am currently using is : (I
>have highlighted the code that is not working)
>>
>>
>> y<- mydata[,2:75]
>>
>> year <- mydata$Year
>>
>> res <- data.frame()
>>
>> for (i in 1:74){
>>
>>   y.val <- y[,i]
>>
>>   lake.lm= lm(y.val ~ year)
>>
>>   lake.res=residuals(lake.lm)
>>
>>   new.res <- data.frame(lake.res=lake.res)
>>
>>   colnames(new.res) <- colnames(y)[i]
>>
>> #cbind doesn't work because of the unequal lengths of my data columns
>>
>>   res <- cbind(res, new.res)
>>
>>   print(res)
>>
>> }
>>
>>
>> mydata is a csv file with "Year" from 1950 on as my first column and
>then each proceeding column has a lake name and a day of year (single
>number) in each row.
>>
>>
>> Please let me know if there is any more information I can provide as
[[elided Hotmail spam]]
>>
>>
>> Bailey Hewitt
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help

thz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Dec 14 15:18:33 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 14 Dec 2016 14:18:33 +0000
Subject: [R] data manipulation
In-Reply-To: <CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
Message-ID: <585154B9.8020002@sapo.pt>

Hello,

Please cc your mails to the list.
As for your data, your url is wrong, you need to contact Massey or maybe 
the source of your information and get a valid internet address.
Without one there's not much we can do.

Rui Barradas

Em 14-12-2016 12:16, Farshad Fathian escreveu:
> Hello,
>
> Thanks for your e-mail. I was reading "Introductory Time Series with R"
> by PS. Cowperwait. I am going to run the R codes in this book, but I
> don't access to the input data from
> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>
> Regards,
>
> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     What do you mean by "gives me something"?
>
>     xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>     <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>     Error in file(file, "rt") : cannot open the connection
>     In addition: Warning message:
>     In file(file, "rt") :
>        cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>     <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>     Not Found'
>
>     Rui Barradas
>
>
>     Em 14-12-2016 11:56, John Kane via R-help escreveu:
>
>         xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>         <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>         gives me something. Since we have no idea of what you are doing
>         I don't know if the data has downloaded correctly
>
>               On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>         <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>         wrote:
>
>
>            Hi,
>
>
>
>         I couldn't access to data file about PSCoperwait by
>         http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>         <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>
>
>
>         Looking forward to hearing from you,
>
>
>               [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>                  [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>


From shirley.roitberg at gmail.com  Wed Dec 14 15:39:42 2016
From: shirley.roitberg at gmail.com (Shirley R)
Date: Wed, 14 Dec 2016 08:39:42 -0600
Subject: [R] Question regarding package deSolve and R versions
In-Reply-To: <9755E9B4-F370-4702-A751-70F8925BF46C@dcn.davis.ca.us>
References: <CAFXpiv4eUguKK0oTwPE+Bm-FnraXw43CMYKbcU=A7nqz_nPSeQ@mail.gmail.com>
	<9755E9B4-F370-4702-A751-70F8925BF46C@dcn.davis.ca.us>
Message-ID: <CAFXpiv60+z0v+zC_B3bfuRRnfFafEiqQ7evbvio278sNReRp7g@mail.gmail.com>

My apologies. When I found the r-help email, I entirely missed the posting
guide. I will try just update my version of R to be current. If I need to
ask another qustion, I will be sure to look up the posting guide, first.

Thank you very much!!

Shirley

On Dec 14, 2016 12:28 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

> You are approaching this the wrong way... you should be upgrading your
> version of R to be current.  The deSolve package is up to date... it is
> your R that is behind.
>
> You should also read the Posting Guide which would have told you this and
> also that you need to post using plain text and mention your OS among other
> things.
> --
> Sent from my phone. Please excuse my brevity.
>
> On December 13, 2016 3:08:41 PM PST, Shirley R <shirley.roitberg at gmail.com>
> wrote:
> >To whom it may concern,
> >
> >I've run into trouble installing the crqa package. R error messages
> >tell me
> >it is because I don't have the deSolve package. I cannot install the
> >deSolve package, but according to everything I've found online, my
> >version
> >of R (3.2.1) should be fine to work with deSolve. Is there an older
> >version
> >of R that I could use that would work?
> >
> >
> >Thank you!
> >
> >Shirley
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Dec 14 16:17:30 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 14 Dec 2016 15:17:30 +0000
Subject: [R] data manipulation
In-Reply-To: <58513719.5000309@sapo.pt>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
Message-ID: <684311b74bfd4359b852ca5a1196f3bf@exch-2p-mbx-w2.ads.tamu.edu>

It seems to be a data set for use with Introductory Time Series with R by P S Cowpertwait and A V Metcalfe. It is not just the file that is missing, the whole folder is missing:

The requested URL /~pscoperwait/ was not found on this server.

The Springer website for the book indicates the data sets are located at

http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/

but there is no server at staff.elena.aut.ac.nz. A web search turns up this link:

http://www.maths.adelaide.edu.au/andrew.metcalfe/

But the link to cbe.dat and the other data sets are dead.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Wednesday, December 14, 2016 6:12 AM
To: John Kane; Farshad Fathian; r-help at stat.math.ethz.ch
Subject: Re: [R] data manipulation

Hello,

What do you mean by "gives me something"?

xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :
   cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat': HTTP 
status was '404 Not Found'

Rui Barradas


Em 14-12-2016 11:56, John Kane via R-help escreveu:
> xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
> gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly
>
>      On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>
>
>   Hi,
>
>
>
> I couldn't access to data file about PSCoperwait by
> http://massey.ac.nz/~pscoperwait/ts/cbe.dat.
>
>
>
> Looking forward to hearing from you,
>
>
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Wed Dec 14 20:35:06 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 14 Dec 2016 14:35:06 -0500
Subject: [R] weird behavior of DoubleMetaphone
Message-ID: <CAN2xGJZmLWOv3Fdtw1imx3OVs-x9SVmSM-rbp79Rjd6=UBa5Lg@mail.gmail.com>

I was wondering if anyone can answer this question.

library(PGRdup)

Both lines below return "NTFL".
DoubleMetaphone("netflix")$primary
DoubleMetaphone("net flex")$primary

Now, I modify the function a bit - I first split the string on
"space", then merge back together:

mymetaphone = function(x){
    temp <- strsplit(x, split=" ")[[1]]
    for(word in 1:length(temp)){
     temp[word]<-DoubleMetaphone(temp[word])$primary
    }
    return(paste(temp, collapse = ""))
}
mymetaphone("netflix")    # returns "NTFL"
mymetaphone("net flex")  # returns "NTFLKS"

Why such a difference between DoubleMetaphone("net flex")$primary and
mymetaphone("net flex")?
Why isn't DoubleMetaphone("net flex")$primary returning "NTFLKS"?
Thank you!

-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Wed Dec 14 20:42:14 2016
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 14 Dec 2016 14:42:14 -0500
Subject: [R] weird behavior of DoubleMetaphone
In-Reply-To: <CAN2xGJZmLWOv3Fdtw1imx3OVs-x9SVmSM-rbp79Rjd6=UBa5Lg@mail.gmail.com>
References: <CAN2xGJZmLWOv3Fdtw1imx3OVs-x9SVmSM-rbp79Rjd6=UBa5Lg@mail.gmail.com>
Message-ID: <CAN2xGJa5=vLDA0EGh52JD9bgfj6S_heLHF0rQoO7zNpXyGNcRg@mail.gmail.com>

No real need to answer. I found that function 'metaphone' from package
"phonics" doesn't misbehave this way!

library(phonics)
mymetaphone = function(x){
    temp <- strsplit(x, split=" ")[[1]]
    for(word in 1:length(temp)){
     temp[word]<-metaphone(temp[word])
    }
    return(paste(temp, collapse = ""))
}

The next 4 lines return the same thing:
metaphone("netflix")
metaphone("net flex")
mymetaphone("netflix")
mymetaphone("net flex")

Dimitri

On Wed, Dec 14, 2016 at 2:35 PM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> I was wondering if anyone can answer this question.
>
> library(PGRdup)
>
> Both lines below return "NTFL".
> DoubleMetaphone("netflix")$primary
> DoubleMetaphone("net flex")$primary
>
> Now, I modify the function a bit - I first split the string on
> "space", then merge back together:
>
> mymetaphone = function(x){
>     temp <- strsplit(x, split=" ")[[1]]
>     for(word in 1:length(temp)){
>      temp[word]<-DoubleMetaphone(temp[word])$primary
>     }
>     return(paste(temp, collapse = ""))
> }
> mymetaphone("netflix")    # returns "NTFL"
> mymetaphone("net flex")  # returns "NTFLKS"
>
> Why such a difference between DoubleMetaphone("net flex")$primary and
> mymetaphone("net flex")?
> Why isn't DoubleMetaphone("net flex")$primary returning "NTFLKS"?
> Thank you!
>
> --
> Dimitri Liakhovitski



-- 
Dimitri Liakhovitski


From dwinsemius at comcast.net  Wed Dec 14 21:03:54 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Dec 2016 12:03:54 -0800
Subject: [R] data manipulation
In-Reply-To: <684311b74bfd4359b852ca5a1196f3bf@exch-2p-mbx-w2.ads.tamu.edu>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<684311b74bfd4359b852ca5a1196f3bf@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <898C5871-D88D-48A8-9BBC-603454A659E0@comcast.net>


> On Dec 14, 2016, at 7:17 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> 
> It seems to be a data set for use with Introductory Time Series with R by P S Cowpertwait and A V Metcalfe. It is not just the file that is missing, the whole folder is missing:
> 
> The requested URL /~pscoperwait/ was not found on this server.
> 
> The Springer website for the book indicates the data sets are located at
> 
> http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/
> 
> but there is no server at staff.elena.aut.ac.nz. A web search turns up this link:
> 
> http://www.maths.adelaide.edu.au/andrew.metcalfe/
> 
> But the link to cbe.dat and the other data sets are dead.

There were images of them in the Wayback Machine. This appears to be the one originally sought.

https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/cbe.dat

Many others can be found with this search:

https://web.archive.org/web/*/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/*


> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
> Sent: Wednesday, December 14, 2016 6:12 AM
> To: John Kane; Farshad Fathian; r-help at stat.math.ethz.ch
> Subject: Re: [R] data manipulation
> 
> Hello,
> 
> What do you mean by "gives me something"?
> 
> xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :
>   cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat': HTTP 
> status was '404 Not Found'
> 
> Rui Barradas
> 
> 
> Em 14-12-2016 11:56, John Kane via R-help escreveu:
>> xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
>> gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly
>> 
>>     On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>> 
>> 
>>  Hi,
>> 
>> 
>> 
>> I couldn't access to data file about PSCoperwait by
>> http://massey.ac.nz/~pscoperwait/ts/cbe.dat.
>> 
>> 
>> 
>> Looking forward to hearing from you,
>> 
>> 
>>     [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Wed Dec 14 21:56:44 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 14 Dec 2016 20:56:44 +0000
Subject: [R] data manipulation
In-Reply-To: <898C5871-D88D-48A8-9BBC-603454A659E0@comcast.net>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<684311b74bfd4359b852ca5a1196f3bf@exch-2p-mbx-w2.ads.tamu.edu>
	<898C5871-D88D-48A8-9BBC-603454A659E0@comcast.net>
Message-ID: <5851B20C.9010700@sapo.pt>

OK, to the op: don't use read.csv, use read.table. Like this:

URL <- 
"https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/cbe.dat"
xx <- read.table(URL, header = TRUE)
str(xx)

Hope this helps,

Rui Barradas

Em 14-12-2016 20:03, David Winsemius escreveu:
>
>> On Dec 14, 2016, at 7:17 AM, David L Carlson <dcarlson at tamu.edu> wrote:
>>
>> It seems to be a data set for use with Introductory Time Series with R by P S Cowpertwait and A V Metcalfe. It is not just the file that is missing, the whole folder is missing:
>>
>> The requested URL /~pscoperwait/ was not found on this server.
>>
>> The Springer website for the book indicates the data sets are located at
>>
>> http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/
>>
>> but there is no server at staff.elena.aut.ac.nz. A web search turns up this link:
>>
>> http://www.maths.adelaide.edu.au/andrew.metcalfe/
>>
>> But the link to cbe.dat and the other data sets are dead.
>
> There were images of them in the Wayback Machine. This appears to be the one originally sought.
>
> https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/cbe.dat
>
> Many others can be found with this search:
>
> https://web.archive.org/web/*/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/*
>
>
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>> Sent: Wednesday, December 14, 2016 6:12 AM
>> To: John Kane; Farshad Fathian; r-help at stat.math.ethz.ch
>> Subject: Re: [R] data manipulation
>>
>> Hello,
>>
>> What do you mean by "gives me something"?
>>
>> xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
>> Error in file(file, "rt") : cannot open the connection
>> In addition: Warning message:
>> In file(file, "rt") :
>>    cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat': HTTP
>> status was '404 Not Found'
>>
>> Rui Barradas
>>
>>
>> Em 14-12-2016 11:56, John Kane via R-help escreveu:
>>> xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
>>> gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly
>>>
>>>      On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
>>>
>>>
>>>   Hi,
>>>
>>>
>>>
>>> I couldn't access to data file about PSCoperwait by
>>> http://massey.ac.nz/~pscoperwait/ts/cbe.dat.
>>>
>>>
>>>
>>> Looking forward to hearing from you,
>>>
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From jvadams at usgs.gov  Wed Dec 14 22:32:42 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 14 Dec 2016 15:32:42 -0600
Subject: [R] how to show a plot without overlaying the text on top of
 the another text?
In-Reply-To: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
References: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
Message-ID: <CAN5YmCGdSSGYSrXjKSHeHu-V_LFy16mYuA1cCVgvNFTxpm8yKw@mail.gmail.com>

The ggrepel package might help.

http://blog.revolutionanalytics.com/2016/01/avoid-overlapping-labels-in-ggplot2-charts.html

Jean

On Tue, Dec 13, 2016 at 5:37 PM, Marna Wagley <marna.wagley at gmail.com>
wrote:

> Hi R user,
> I have created using metaNMDS (Nonmetirc Multidimensional Scaling, MDS) to
> show species composition but some of the species are concentrated at some
> of the sites so that the name of the species are overlaid and it was
> almost impossible to read the species name in the figure. I was wondering
> how
> we can show the plot without overlaying the text on top of another.
> I used the following to create the plot. would you mind to suggest me?
>
> comm.bc.mds <- metaMDS(dat, dist = "bray")
> ordiplot(comm.bc.mds, display = "sites", type = "text")
> ordipointlabel(comm.bc.mds,font = c(1, 1), cex = c(0.5, 0.3))
>
> Thanks
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From richcala at microsoft.com  Thu Dec 15 00:02:05 2016
From: richcala at microsoft.com (Rich Calaway)
Date: Wed, 14 Dec 2016 23:02:05 +0000
Subject: [R] "Safe" use of iterator (package iterators)
Message-ID: <MWHPR03MB3056E1B71A04A116EA721E0ADE9A0@MWHPR03MB3056.namprd03.prod.outlook.com>

Hi, Harold--

The short answer is "Yes"--in your example, the nextElem will always be a list with the i component equal to the next element of itx1 and the j component equal to the next element of itx2.

I posted a more detailed explanation in response to a query from David on the Microsoft TechNet forum: https://social.technet.microsoft.com/Forums/en-US/724b1dde-03e3-4fff-b061-363bc8ba1652/how-are-multiple-iterobjects-handled-by-foreach?forum=ropen


Cheers,
Rich

Rich Calaway
Release Manager
Microsoft R Product Team
24/1341
+1 (425) 4219919 X19919


Message: 2
Date: Fri, 9 Dec 2016 17:15:38 +0000
From: "Doran, Harold" <HDoran at air.org>
To: "r-help at r-project.org" <r-help at r-project.org>
Subject: [R] "Safe" use of iterator (package iterators)
Message-ID:
	<B08B6AF0CF8CA44F81B9983EEBDCD68601358F73D9 at DC1VEX10MB01.air.org>
Content-Type: text/plain; charset="iso-8859-1"

I believe I now see the light vis-?-vis iterators when combined with foreach() calls in R. I have now been able to reduce computational workload to minutes instead of hours. I want to verify that the way I am using them is "safe". By safe I mean does the iterator traverse elements in the same way as I have below in my toy example to illustrate what I mean.

In the first "traditional" example, I have only one index variable for the loop and so I know that the same list in r1 and r2 are always being grabbed. That is, in iteration 1 it is guaranteed to use r1[[1]] + r2[[1]].

In the example that uses the iterators, is this also guaranteed even though I now have two iterator objects? That is, will the index for element i always be the same as the index for element j when using this across many different cores?

It seems to be true and in all my test cases so far I am seeing it to be true. But, that could be just luck, so I wonder if there is a condition under which that would NOT be true.

Thank you
Harold


library(foreach)
library(doParallel)
cl <- makeCluster(2) 
registerDoParallel(cl)

### Create random data
r1 <- vector("list", 20)
for(i in 1:20){
	r1[[i]] <- rnorm(10)
}

### Create random data
r2 <- vector("list", 20)
for(i in 1:20){
	r2[[i]] <- rnorm(10)
}

### Use a for loop traditionally 
result1 <- vector("list", 20)
for(i in 1:20){
	result1[[i]] <- r1[[i]] + r2[[i]]
}
	
### Use iterators
itx1 <- iter(r1)
itx2 <- iter(r2)

result2 <- foreach(i = itx1, j = itx2) %dopar% {
	i + j
	}	

all.equal(result1, result2)




Message: 4
Date: Fri, 9 Dec 2016 10:26:55 -0800
From: David Winsemius <dwinsemius at comcast.net>
To: "Doran, Harold" <HDoran at air.org>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] "Safe" use of iterator (package iterators)
Message-ID: <F5E6B19C-1C53-427B-8BCF-0739DDC63645 at comcast.net>
Content-Type: text/plain; charset=iso-8859-1


> On Dec 9, 2016, at 9:15 AM, Doran, Harold <HDoran at air.org> wrote:
> 
> I believe I now see the light vis-?-vis iterators when combined with foreach() calls in R. I have now been able to reduce computational workload to minutes instead of hours. I want to verify that the way I am using them is "safe". By safe I mean does the iterator traverse elements in the same way as I have below in my toy example to illustrate what I mean.
> 
> In the first "traditional" example, I have only one index variable for the loop and so I know that the same list in r1 and r2 are always being grabbed. That is, in iteration 1 it is guaranteed to use r1[[1]] + r2[[1]].
> 
> In the example that uses the iterators, is this also guaranteed even though I now have two iterator objects? That is, will the index for element i always be the same as the index for element j when using this across many different cores?
> 
> It seems to be true and in all my test cases so far I am seeing it to be true. But, that could be just luck, so I wonder if there is a condition under which that would NOT be true.
> 
> Thank you
> Harold
> 
> 
> library(foreach)
> library(doParallel)
> cl <- makeCluster(2) 
> registerDoParallel(cl)
> 
> ### Create random data
> r1 <- vector("list", 20)
> for(i in 1:20){
> 	r1[[i]] <- rnorm(10)
> }
> 
> ### Create random data
> r2 <- vector("list", 20)
> for(i in 1:20){
> 	r2[[i]] <- rnorm(10)
> }
> 
> ### Use a for loop traditionally 
> result1 <- vector("list", 20)
> for(i in 1:20){
> 	result1[[i]] <- r1[[i]] + r2[[i]]
> }
> 	
> ### Use iterators
> itx1 <- iter(r1)
> itx2 <- iter(r2)
> 
> result2 <- foreach(i = itx1, j = itx2) %dopar% {
> 	i + j
> 	}	
> 
> all.equal(result1, result2)

I wasn't sure how this would or should behave. I'm not an experienced user, merely a reader of help pages. Neither the help page, not the vignette references on the help page answered my questions in this case. I expected that call would behave analogously to the behavior of mapply when given iterators of unequal length. (The shorter of the objects is recycled to reach the length of the longer object.) That expectation was not realized. It appears that the length of first object of the objects determines computation length, but that missing values will not be recycled for the shorter iterator. An error is not reported, but rather numeric(0) is returned. So in one sense the %dopar% version is "safer" at least to the extent of not failing with an error that would have occurred when using a for-loop.

This was my test case:

r1 <- vector("list", 10)
for(i in 1:20){
	r1[[i]] <-20:29+i*10  
# random numbers are not good for determining sequences of operations
}
r2 <- vector("list", 20)
for(i in 1:10){
	r2[[i]] <- 1:10 +i
}
itx1 <- iter(r1)
itx2 <- iter(r2)

result2 <- foreach(i = itx1, j = itx2) %dopar% {
	i + j
	}	

result2



-- 

David Winsemius
Alameda, CA, USA



------------------------------

Message: 5
Date: Fri, 9 Dec 2016 18:42:10 +0000
From: "Doran, Harold" <HDoran at air.org>
To: "'David Winsemius'" <dwinsemius at comcast.net>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] "Safe" use of iterator (package iterators)
Message-ID:
	<B08B6AF0CF8CA44F81B9983EEBDCD68601358F75F6 at DC1VEX10MB01.air.org>
Content-Type: text/plain; charset="iso-8859-1"

That is a helpful, and important, caveat. So, perhaps I should amend my original question to ask something like is it safe *when* length(r1) == length(r2)


From drjimlemon at gmail.com  Thu Dec 15 02:25:24 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 15 Dec 2016 12:25:24 +1100
Subject: [R] how to show a plot without overlaying the text on top of
 the another text?
In-Reply-To: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
References: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
Message-ID: <CA+8X3fUfEFrNKsLi3ExLCR4vMb=qKoA=h3s=ePBACc6BNha11w@mail.gmail.com>

Hi Marna,
Your request made me think that a simple manual label placing function
might be useful to some people.

placeLabels<-function(pointer=TRUE,cex=1,labelcol=par("fg"),
 bg="white",border=par("fg"),pointercol=par("fg")) {

 cat("Enter a blank label to finish\n")
 nextlabel<-"XXX"
 while(nchar(nextlabel)) {
  cat("Click on a data point\n")
  datumxy<-locator(1)
  cat("Click on the label position\n")
  labelxy<-locator(1)
  nextlabel<-readline("Enter the label - ")
  if(nchar(nextlabel)) {
   if(pointer) segments(datumxy$x,datumxy$y,labelxy$x,labelxy$y,
    col=pointercol)
   boxed.labels(labelxy$x,labelxy$y,nextlabel,col=labelcol,
    bg=bg,border=border)
  }
 }
}

All I have to do is work out how to get it to automatically switch
back to the console window for the label entry.

Jim


On Wed, Dec 14, 2016 at 10:37 AM, Marna Wagley <marna.wagley at gmail.com> wrote:
> Hi R user,
> I have created using metaNMDS (Nonmetirc Multidimensional Scaling, MDS) to
> show species composition but some of the species are concentrated at some
> of the sites so that the name of the species are overlaid and it was
> almost impossible to read the species name in the figure. I was wondering how
> we can show the plot without overlaying the text on top of another.
> I used the following to create the plot. would you mind to suggest me?
>
> comm.bc.mds <- metaMDS(dat, dist = "bray")
> ordiplot(comm.bc.mds, display = "sites", type = "text")
> ordipointlabel(comm.bc.mds,font = c(1, 1), cex = c(0.5, 0.3))
>
> Thanks
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amelia_marsh08 at yahoo.com  Thu Dec 15 07:18:18 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 15 Dec 2016 06:18:18 +0000 (UTC)
Subject: [R] R studio Problem
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
Message-ID: <1078945316.3309558.1481782698094@mail.yahoo.com>

Hi

I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error

Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 


I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -


> a = 40 

> b = 45 
Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 
> c = 120 
Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 
Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 
Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 
Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 
Error in normalizePath(dir, winslash = "/", mustWork = TRUE) : 
unused argument(s) (winslash = "/", mustWork = TRUE) 


I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.


Can someone guide me.

Regards

Amelais


From maillists at pp.inet.fi  Thu Dec 15 07:34:29 2016
From: maillists at pp.inet.fi (K. Elo)
Date: Thu, 15 Dec 2016 08:34:29 +0200
Subject: [R] R studio Problem
In-Reply-To: <1078945316.3309558.1481782698094@mail.yahoo.com>
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
	<1078945316.3309558.1481782698094@mail.yahoo.com>
Message-ID: <24c65ed8-0b70-c0fe-a12b-0b1bc0207fc7@pp.inet.fi>

Hi!

Maybe this helps:

http://r.789695.n4.nabble.com/Error-in-normalizePath-path-with-McAfee-td2532324.html

Best,
Kimmo

15.12.2016, 08:18, Amelia Marsh via R-help wrote:
> Hi
>
> I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error
>
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -
>
>
>> a = 40
>
>> b = 45
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>> c = 120
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.
>
>
> Can someone guide me.
>
> Regards
>
> Amelais
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Thu Dec 15 08:09:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 14 Dec 2016 23:09:27 -0800
Subject: [R] R studio Problem
In-Reply-To: <1078945316.3309558.1481782698094@mail.yahoo.com>
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
	<1078945316.3309558.1481782698094@mail.yahoo.com>
Message-ID: <CAGxFJbRJetohm5z=F7gqMp6+hcAMvmC8JHZ+o7ms9KPo2czF-A@mail.gmail.com>

You may get a reply here, but this is the wrong place for you to post.
RStudio is a separate commercial entity and product from the
noncommercial R foundation and R software that runs this list. This
list is about R programming; for questions about RStudio, you should
consult the RStudio website and post to their support lists.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 14, 2016 at 10:18 PM, Amelia Marsh via R-help
<r-help at r-project.org> wrote:
> Hi
>
> I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error
>
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -
>
>
>> a = 40
>
>> b = 45
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>> c = 120
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.
>
>
> Can someone guide me.
>
> Regards
>
> Amelais
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From brijeshkmishra at gmail.com  Thu Dec 15 04:40:51 2016
From: brijeshkmishra at gmail.com (Brijesh Mishra)
Date: Thu, 15 Dec 2016 09:10:51 +0530
Subject: [R] Computing growth rate
Message-ID: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>

Hi,

I am trying to calculate growth rate (say, sales, though it is to be
computed for many variables) in a panel data set. Problem is that I
have missing data for many firms for many years. To put it simply, I
have created this short dataframe (original df id much bigger)

df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))

# this gives me
co_code1 fyear1 sales1
1      1100   1990   1000
2      1100   1991   1100
3      1100   1992   1200
4      1100   1993   1300
5      1100   1994   1400
6      1100   1995   1500
7      1100   1996   1600
8      1200   1990   1000
9      1200   1991   1100
10     1200   1992   1200
11     1200   1993   1300
12     1200   1994   1400
13     1200   1995   1500
14     1200   1996   1600
15     1300   1990   1000
16     1300   1991   1100
17     1300   1992   1200
18     1300   1993   1300
19     1300   1994   1400
20     1300   1995   1500
21     1300   1996   1600

# I am now removing a couple of rows
df1<-df1[-c(5, 8), ]
# the result is
   co_code1 fyear1 sales1
1      1100   1990   1000
2      1100   1991   1100
3      1100   1992   1200
4      1100   1993   1300
6      1100   1995   1500
7      1100   1996   1600
9      1200   1991   1100
10     1200   1992   1200
11     1200   1993   1300
12     1200   1994   1400
13     1200   1995   1500
14     1200   1996   1600
15     1300   1990   1000
16     1300   1991   1100
17     1300   1992   1200
18     1300   1993   1300
19     1300   1994   1400
20     1300   1995   1500
21     1300   1996   1600
# so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
removed. If I try,
d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-1)*100)

# this apparently gives wrong results for the year 1995 (as shown
below) as growth rates are computed considering yearly increment.

   co_code1 fyear1 sales1    growth
1      1100   1990   1000        NA
2      1100   1991   1100 10.000000
3      1100   1992   1200  9.090909
4      1100   1993   1300  8.333333
5      1100   1995   1500 15.384615
6      1100   1996   1600  6.666667
7      1200   1991   1100        NA
8      1200   1992   1200  9.090909
9      1200   1993   1300  8.333333
10     1200   1994   1400  7.692308
11     1200   1995   1500  7.142857
12     1200   1996   1600  6.666667
13     1300   1990   1000        NA
14     1300   1991   1100 10.000000
15     1300   1992   1200  9.090909
16     1300   1993   1300  8.333333
17     1300   1994   1400  7.692308
18     1300   1995   1500  7.142857
19     1300   1996   1600  6.666667
# I thought of using the formula only when the increment of fyear1 is
only 1 while in a co_code1, by using this formula

d<-ddply(df1,
         "co_code1",
         transform,
         if(diff(fyear1)==1){
           growth=(exp(diff(log(df1$sales1)))-1)*100
         } else{
           growth=NA
         })

But, this doesn't work. I am getting the following error.

In if (diff(fyear1) == 1) { :
  the condition has length > 1 and only the first element will be used
(repeated a few times).

# I have searched for a solution, but somehow couldn't get one. Hope
that some kind soul will guide me here.

Regards,

Brijesh K Mishra
Indian Institute of Management, Indore
India


From amelia_marsh08 at yahoo.com  Thu Dec 15 09:04:41 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 15 Dec 2016 08:04:41 +0000 (UTC)
Subject: [R] R studio Problem
In-Reply-To: <24c65ed8-0b70-c0fe-a12b-0b1bc0207fc7@pp.inet.fi>
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
	<1078945316.3309558.1481782698094@mail.yahoo.com>
	<24c65ed8-0b70-c0fe-a12b-0b1bc0207fc7@pp.inet.fi>
Message-ID: <1853598532.3423934.1481789081752@mail.yahoo.com>

Thanks a lot Kimmo for your valuable guidance. Hope it works.

Regards

Amelia



On Thursday, 15 December 2016 12:06 PM, K. Elo <maillists at pp.inet.fi> wrote:
Hi!

Maybe this helps:

http://r.789695.n4.nabble.com/Error-in-normalizePath-path-with-McAfee-td2532324.html

Best,
Kimmo

15.12.2016, 08:18, Amelia Marsh via R-help wrote:
> Hi
>
> I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error
>
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -
>
>
>> a = 40
>
>> b = 45
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>> c = 120
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.
>
>
> Can someone guide me.
>
> Regards
>
> Amelais
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From amelia_marsh08 at yahoo.com  Thu Dec 15 09:05:44 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 15 Dec 2016 08:05:44 +0000 (UTC)
Subject: [R] R studio Problem
In-Reply-To: <CAGxFJbRJetohm5z=F7gqMp6+hcAMvmC8JHZ+o7ms9KPo2czF-A@mail.gmail.com>
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
	<1078945316.3309558.1481782698094@mail.yahoo.com>
	<CAGxFJbRJetohm5z=F7gqMp6+hcAMvmC8JHZ+o7ms9KPo2czF-A@mail.gmail.com>
Message-ID: <2096651103.3437887.1481789144205@mail.yahoo.com>

Sorry Mr Gunter. I didn't realize it.

Regards

Amelia



On Thursday, 15 December 2016 12:39 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
You may get a reply here, but this is the wrong place for you to post.
RStudio is a separate commercial entity and product from the
noncommercial R foundation and R software that runs this list. This
list is about R programming; for questions about RStudio, you should
consult the RStudio website and post to their support lists.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



On Wed, Dec 14, 2016 at 10:18 PM, Amelia Marsh via R-help
<r-help at r-project.org> wrote:
> Hi
>
> I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error
>
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -
>
>
>> a = 40
>
>> b = 45
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>> c = 120
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)
>
>
> I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.
>
>
> Can someone guide me.
>
> Regards
>
> Amelais
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jimmaasuk at gmail.com  Thu Dec 15 09:08:40 2016
From: jimmaasuk at gmail.com (Jim Maas)
Date: Thu, 15 Dec 2016 08:08:40 +0000
Subject: [R] problem installing Rmpi
Message-ID: <CAGQ6_y_6ei-a8+sPCaE+NhBRJOW72a=eBMnnGDnT_Y7QoZM-8g@mail.gmail.com>

Can anyone tell me to start looking to fix this, when attempting to install
Rmpi on Ubuntu 16.04, just updated R version to 3.3.2


** building package indices
** testing if installed package can be loaded
Error in system2(file.path(R.home("bin"), "R"), c(if (nzchar(arch))
paste0("--arch=",  :
  error in running command
* removing ?/usr/local/lib/R/site-library/Rmpi?

?Thanks, J?

-- 
Jim Maas

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Thu Dec 15 10:12:58 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 15 Dec 2016 10:12:58 +0100
Subject: [R] R studio Problem
In-Reply-To: <2096651103.3437887.1481789144205@mail.yahoo.com>
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
	<1078945316.3309558.1481782698094@mail.yahoo.com>
	<CAGxFJbRJetohm5z=F7gqMp6+hcAMvmC8JHZ+o7ms9KPo2czF-A@mail.gmail.com>
	<2096651103.3437887.1481789144205@mail.yahoo.com>
Message-ID: <22610.24218.145047.248345@stat.math.ethz.ch>

>>>>> Amelia Marsh via R-help <r-help at r-project.org>
>>>>>     on Thu, 15 Dec 2016 08:05:44 +0000 writes:

    > Sorry Mr Gunter. I didn't realize it.
    > Regards

    > Amelia

In this case, however, it was only the 'Subject' of Amelia's
posting and her own "feeling about" the problem which were
wrong:

As K. Elo's helpful reply suggests, it most probably 
is indeed an *R* problem, not an RStudio one:

Excursion (HW, do listen!):  A very efficient and easy way to _search_
 all the R mailing lists @R-project.org, i.e., including
 R-help (and R-devel, R-packages, R-package-devel, R-SIG-Mac, ...) is
by knowing/noticing that

  a) the website of all these lists are
    at  https://stat.ethz.ch/mailman/listinfo/<lower-case-listname>
    and (consequently) all the list __archives__ are at
      https://stat.ethz.ch/pipermail/<lower-case-listname>

  b) the (somewhat) advanced, but not known well enough,
     Google search feature  'site:<domain>' 

In this case (because it has been on R-help in the past),
consequently a very efficient search to solve this problem is to
enter this into Google
 site:stat.ethz.ch normalizePath McAfee
 ~~~~~
(or click here to "learn it":
 https://lmgtfy.com/?q=site%3Astat.ethz.ch+normalizePath+McAfee)

which finds this as a first hit  
https://stat.ethz.ch/pipermail/r-help/2010-September/252217.html
which used to be the solution of the problem (and K.Elo's URL was to the
infamous Nabble version of R-help).

-------

It is very said to notice that more and more users of R (and
Rtudio) and it seems even *instructors* are thinking they use
RStudio when they are primarily using R via RStudio... and their
credits are going to RStudio only instead of to R, the R
foundation and its not-unimportant subset, the R core team,
plus the 1000s of package authors and bug report / patches
contributing volunteers around the world.

--> Please spread the word: It is __R__ (and RStudio),  not the
    other way around.




    > On Thursday, 15 December 2016 12:39 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    > You may get a reply here, but this is the wrong place for you to post.
    > RStudio is a separate commercial entity and product from the
    > noncommercial R foundation and R software that runs this list. This
    > list is about R programming; for questions about RStudio, you should
    > consult the RStudio website and post to their support lists.

    > Cheers,
    > Bert


    > Bert Gunter

    > "The trouble with having an open mind is that people keep coming along
    > and sticking things into it."
    > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



    > On Wed, Dec 14, 2016 at 10:18 PM, Amelia Marsh via R-help
    > <r-help at r-project.org> wrote:
    >> Hi
    >> 
    >> I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error
    >> 
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> 
    >> 
    >> I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -
    >> 
    >> 
    >>> a = 40
    >> 
    >>> b = 45
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >>> c = 120
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> 
    >> 
    >> I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.
    >> 
    >> 
    >> Can someone guide me.
    >> 
    >> Regards
    >> 
    >> Amelais
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From Ramgad82 at gmx.net  Thu Dec 15 10:22:34 2016
From: Ramgad82 at gmx.net (Dagmar)
Date: Thu, 15 Dec 2016 10:22:34 +0100
Subject: [R] ggplot aestetics: beginner question - I am lost in endless
 possibilites
Message-ID: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>

# Dear all,
# I hope someone can help me with this. I am so lost and can't find a 
solution even though I spent hours on searching for a solution of that 
tiny problem.
# Maybe someone of you could give me hint?
#This is my string:
exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie", 
"Leon","Leon","Leon"),
               recordedTime=c("03.01.2011","04.01.2011","05.01.2011",
"04.01.2011","05.01.2011","06.01.2011"),
                knownstate =c("breeding","moulting","moulting",
                              "breeding","breeding",NA))
exdatframe

exdatframeT <- as.POSIXct 
(strptime(as.character(exdatframe$recordedTime),"%d.%m.%Y"))
exdatframeT
exdatframe2 <- cbind(exdatframe, exdatframeT)
exdatframe2$recordedTime <-NULL
exdatframe2
str(datframe)

library(ggplot2)
ggplot(exdatframe2)+geom_tile(aes(x=exdatframeT,y=Name,fill=knownstate), 
height=0.5)

# Now all I want is:
# 1) a black outline around the bars. Adding colour="black" like I have 
found elsewere on the internet doesn't work
# 2) change the colours: E.g. I want white for NAs. I can't find a 
command to describe my wishes.

#?


From erinm.hodgess at gmail.com  Thu Dec 15 11:34:48 2016
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Thu, 15 Dec 2016 04:34:48 -0600
Subject: [R] problem installing Rmpi
In-Reply-To: <CAGQ6_y_6ei-a8+sPCaE+NhBRJOW72a=eBMnnGDnT_Y7QoZM-8g@mail.gmail.com>
References: <CAGQ6_y_6ei-a8+sPCaE+NhBRJOW72a=eBMnnGDnT_Y7QoZM-8g@mail.gmail.com>
Message-ID: <CACxE24=o+cmqimQv=mq7Va1W8k=854RayGkJkUQiRD8kpJ6dNA@mail.gmail.com>

At the risk of sounding simplistic, do you have MPI installed, please?

On Thu, Dec 15, 2016 at 2:08 AM, Jim Maas <jimmaasuk at gmail.com> wrote:

> Can anyone tell me to start looking to fix this, when attempting to install
> Rmpi on Ubuntu 16.04, just updated R version to 3.3.2
>
>
> ** building package indices
> ** testing if installed package can be loaded
> Error in system2(file.path(R.home("bin"), "R"), c(if (nzchar(arch))
> paste0("--arch=",  :
>   error in running command
> * removing ?/usr/local/lib/R/site-library/Rmpi?
>
> ?Thanks, J?
>
> --
> Jim Maas
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Dec 15 11:48:38 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 15 Dec 2016 11:48:38 +0100
Subject: [R] ggplot aestetics: beginner question - I am lost in endless
	possibilites
In-Reply-To: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>
References: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>
Message-ID: <CAJuCY5z4egfGZfwWuXq56-BZjAyQ3eFTbv+kN7bVuT8LazsRLQ@mail.gmail.com>

Here is a solution

ggplot(exdatframe2) +
  geom_tile(aes(x = exdatframeT, y = Name, fill = knownstate), colour =
"black", height = 0.5) +
  scale_fill_discrete(na.value = "white")

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-12-15 10:22 GMT+01:00 Dagmar <Ramgad82 at gmx.net>:

> # Dear all,
> # I hope someone can help me with this. I am so lost and can't find a
> solution even though I spent hours on searching for a solution of that tiny
> problem.
> # Maybe someone of you could give me hint?
> #This is my string:
> exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie",
> "Leon","Leon","Leon"),
>               recordedTime=c("03.01.2011","04.01.2011","05.01.2011",
> "04.01.2011","05.01.2011","06.01.2011"),
>                knownstate =c("breeding","moulting","moulting",
>                              "breeding","breeding",NA))
> exdatframe
>
> exdatframeT <- as.POSIXct (strptime(as.character(exdatfr
> ame$recordedTime),"%d.%m.%Y"))
> exdatframeT
> exdatframe2 <- cbind(exdatframe, exdatframeT)
> exdatframe2$recordedTime <-NULL
> exdatframe2
> str(datframe)
>
> library(ggplot2)
> ggplot(exdatframe2)+geom_tile(aes(x=exdatframeT,y=Name,fill=knownstate),
> height=0.5)
>
> # Now all I want is:
> # 1) a black outline around the bars. Adding colour="black" like I have
> found elsewere on the internet doesn't work
> # 2) change the colours: E.g. I want white for NAs. I can't find a command
> to describe my wishes.
>
> #?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Dec 15 12:32:53 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 15 Dec 2016 11:32:53 +0000
Subject: [R] Computing growth rate
In-Reply-To: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
Message-ID: <58527F65.1010400@sapo.pt>

Hello,

That is a very common mistake. if() accepts only one TRUE/FALSE, for a 
vectorized version you need ?ifelse. Something like the following 
(untested).

growth <- ifelse(diff(fyear1)==1, (exp(diff(log(df1$sales1)))-1)*100, NA)

Hope this helps,

Rui Barradas

Em 15-12-2016 03:40, Brijesh Mishra escreveu:
> Hi,
>
> I am trying to calculate growth rate (say, sales, though it is to be
> computed for many variables) in a panel data set. Problem is that I
> have missing data for many firms for many years. To put it simply, I
> have created this short dataframe (original df id much bigger)
>
> df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
> fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
>
> # this gives me
> co_code1 fyear1 sales1
> 1      1100   1990   1000
> 2      1100   1991   1100
> 3      1100   1992   1200
> 4      1100   1993   1300
> 5      1100   1994   1400
> 6      1100   1995   1500
> 7      1100   1996   1600
> 8      1200   1990   1000
> 9      1200   1991   1100
> 10     1200   1992   1200
> 11     1200   1993   1300
> 12     1200   1994   1400
> 13     1200   1995   1500
> 14     1200   1996   1600
> 15     1300   1990   1000
> 16     1300   1991   1100
> 17     1300   1992   1200
> 18     1300   1993   1300
> 19     1300   1994   1400
> 20     1300   1995   1500
> 21     1300   1996   1600
>
> # I am now removing a couple of rows
> df1<-df1[-c(5, 8), ]
> # the result is
>     co_code1 fyear1 sales1
> 1      1100   1990   1000
> 2      1100   1991   1100
> 3      1100   1992   1200
> 4      1100   1993   1300
> 6      1100   1995   1500
> 7      1100   1996   1600
> 9      1200   1991   1100
> 10     1200   1992   1200
> 11     1200   1993   1300
> 12     1200   1994   1400
> 13     1200   1995   1500
> 14     1200   1996   1600
> 15     1300   1990   1000
> 16     1300   1991   1100
> 17     1300   1992   1200
> 18     1300   1993   1300
> 19     1300   1994   1400
> 20     1300   1995   1500
> 21     1300   1996   1600
> # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
> removed. If I try,
> d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-1)*100)
>
> # this apparently gives wrong results for the year 1995 (as shown
> below) as growth rates are computed considering yearly increment.
>
>     co_code1 fyear1 sales1    growth
> 1      1100   1990   1000        NA
> 2      1100   1991   1100 10.000000
> 3      1100   1992   1200  9.090909
> 4      1100   1993   1300  8.333333
> 5      1100   1995   1500 15.384615
> 6      1100   1996   1600  6.666667
> 7      1200   1991   1100        NA
> 8      1200   1992   1200  9.090909
> 9      1200   1993   1300  8.333333
> 10     1200   1994   1400  7.692308
> 11     1200   1995   1500  7.142857
> 12     1200   1996   1600  6.666667
> 13     1300   1990   1000        NA
> 14     1300   1991   1100 10.000000
> 15     1300   1992   1200  9.090909
> 16     1300   1993   1300  8.333333
> 17     1300   1994   1400  7.692308
> 18     1300   1995   1500  7.142857
> 19     1300   1996   1600  6.666667
> # I thought of using the formula only when the increment of fyear1 is
> only 1 while in a co_code1, by using this formula
>
> d<-ddply(df1,
>           "co_code1",
>           transform,
>           if(diff(fyear1)==1){
>             growth=(exp(diff(log(df1$sales1)))-1)*100
>           } else{
>             growth=NA
>           })
>
> But, this doesn't work. I am getting the following error.
>
> In if (diff(fyear1) == 1) { :
>    the condition has length > 1 and only the first element will be used
> (repeated a few times).
>
> # I have searched for a solution, but somehow couldn't get one. Hope
> that some kind soul will guide me here.
>
> Regards,
>
> Brijesh K Mishra
> Indian Institute of Management, Indore
> India
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From amelia_marsh08 at yahoo.com  Thu Dec 15 12:33:21 2016
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Thu, 15 Dec 2016 11:33:21 +0000 (UTC)
Subject: [R] R studio Problem
In-Reply-To: <22610.24218.145047.248345@stat.math.ethz.ch>
References: <1078945316.3309558.1481782698094.ref@mail.yahoo.com>
	<1078945316.3309558.1481782698094@mail.yahoo.com>
	<CAGxFJbRJetohm5z=F7gqMp6+hcAMvmC8JHZ+o7ms9KPo2czF-A@mail.gmail.com>
	<2096651103.3437887.1481789144205@mail.yahoo.com>
	<22610.24218.145047.248345@stat.math.ethz.ch>
Message-ID: <623743979.3621265.1481801601341@mail.yahoo.com>

Dear Mr Martin,

Thanks a lot for this much needed insight. Unfortunately even though my system admin has uninstalled McAfee from my laptop, however, the same problem still exists. After uninstalling MCafee, I have reinstalled Rstudio but of no use. As Mr Gunter has suggested, trying to take this issue with RStudio people too.

I have started using R again.

Regards and thanks again

Amelia



On Thursday, 15 December 2016 2:43 PM, Martin Maechler <maechler at stat.math.ethz.ch> wrote:
>>>>> Amelia Marsh via R-help <r-help at r-project.org>
>>>>>     on Thu, 15 Dec 2016 08:05:44 +0000 writes:

    > Sorry Mr Gunter. I didn't realize it.
    > Regards

    > Amelia

In this case, however, it was only the 'Subject' of Amelia's
posting and her own "feeling about" the problem which were
wrong:

As K. Elo's helpful reply suggests, it most probably 
is indeed an *R* problem, not an RStudio one:

Excursion (HW, do listen!):  A very efficient and easy way to _search_
all the R mailing lists @R-project.org, i.e., including
R-help (and R-devel, R-packages, R-package-devel, R-SIG-Mac, ...) is
by knowing/noticing that

  a) the website of all these lists are
    at  https://stat.ethz.ch/mailman/listinfo/<lower-case-listname>
    and (consequently) all the list __archives__ are at
      https://stat.ethz.ch/pipermail/<lower-case-listname>

  b) the (somewhat) advanced, but not known well enough,
     Google search feature  'site:<domain>' 

In this case (because it has been on R-help in the past),
consequently a very efficient search to solve this problem is to
enter this into Google
site:stat.ethz.ch normalizePath McAfee
~~~~~
(or click here to "learn it":
https://lmgtfy.com/?q=site%3Astat.ethz.ch+normalizePath+McAfee)

which finds this as a first hit  
https://stat.ethz.ch/pipermail/r-help/2010-September/252217.html
which used to be the solution of the problem (and K.Elo's URL was to the
infamous Nabble version of R-help).

-------

It is very said to notice that more and more users of R (and
Rtudio) and it seems even *instructors* are thinking they use
RStudio when they are primarily using R via RStudio... and their
credits are going to RStudio only instead of to R, the R
foundation and its not-unimportant subset, the R core team,
plus the 1000s of package authors and bug report / patches
contributing volunteers around the world.

--> Please spread the word: It is __R__ (and RStudio),  not the
    other way around.





    > On Thursday, 15 December 2016 12:39 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
    > You may get a reply here, but this is the wrong place for you to post.
    > RStudio is a separate commercial entity and product from the
    > noncommercial R foundation and R software that runs this list. This
    > list is about R programming; for questions about RStudio, you should
    > consult the RStudio website and post to their support lists.

    > Cheers,
    > Bert


    > Bert Gunter

    > "The trouble with having an open mind is that people keep coming along
    > and sticking things into it."
    > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )



    > On Wed, Dec 14, 2016 at 10:18 PM, Amelia Marsh via R-help
    > <r-help at r-project.org> wrote:
    >> Hi
    >> 
    >> I had installed R studio Desktop 1.0.44. However whenever I wanted to write any command, before I could complete, I was getting following error
    >> 
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> 
    >> 
    >> I had uninstalled RStudio and again downloaded it and reinstalled. But still I am getting error like as mentioned below -
    >> 
    >> 
    >>> a = 40
    >> 
    >>> b = 45
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >>> c = 120
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> Error in normalizePath(dir, winslash = "/", mustWork = TRUE) :
    >> unused argument(s) (winslash = "/", mustWork = TRUE)
    >> 
    >> 
    >> I had assigned value 40 to a, value 45 to b, but when I tried to assign value 120 to c, before I could complete, it started throwing above messages. I tried rnorm etc, however the error keeps on reappearing.
    >> 
    >> 
    >> Can someone guide me.
    >> 
    >> Regards
    >> 
    >> Amelais
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Thu Dec 15 13:18:08 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 15 Dec 2016 13:18:08 +0100
Subject: [R] Computing growth rate
In-Reply-To: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
Message-ID: <96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>


> On 15 Dec 2016, at 04:40, Brijesh Mishra <brijeshkmishra at gmail.com> wrote:
> 
> Hi,
> 
> I am trying to calculate growth rate (say, sales, though it is to be
> computed for many variables) in a panel data set. Problem is that I
> have missing data for many firms for many years. To put it simply, I
> have created this short dataframe (original df id much bigger)
> 
> df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
> fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
> 
> # this gives me
> co_code1 fyear1 sales1
> 1      1100   1990   1000
> 2      1100   1991   1100
> 3      1100   1992   1200
> 4      1100   1993   1300
> 5      1100   1994   1400
> 6      1100   1995   1500
> 7      1100   1996   1600
> 8      1200   1990   1000
> 9      1200   1991   1100
> 10     1200   1992   1200
> 11     1200   1993   1300
> 12     1200   1994   1400
> 13     1200   1995   1500
> 14     1200   1996   1600
> 15     1300   1990   1000
> 16     1300   1991   1100
> 17     1300   1992   1200
> 18     1300   1993   1300
> 19     1300   1994   1400
> 20     1300   1995   1500
> 21     1300   1996   1600
> 
> # I am now removing a couple of rows
> df1<-df1[-c(5, 8), ]
> # the result is
>   co_code1 fyear1 sales1
> 1      1100   1990   1000
> 2      1100   1991   1100
> 3      1100   1992   1200
> 4      1100   1993   1300
> 6      1100   1995   1500
> 7      1100   1996   1600
> 9      1200   1991   1100
> 10     1200   1992   1200
> 11     1200   1993   1300
> 12     1200   1994   1400
> 13     1200   1995   1500
> 14     1200   1996   1600
> 15     1300   1990   1000
> 16     1300   1991   1100
> 17     1300   1992   1200
> 18     1300   1993   1300
> 19     1300   1994   1400
> 20     1300   1995   1500
> 21     1300   1996   1600
> # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
> removed. If I try,
> d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-1)*100)
> 
> # this apparently gives wrong results for the year 1995 (as shown
> below) as growth rates are computed considering yearly increment.
> 
>   co_code1 fyear1 sales1    growth
> 1      1100   1990   1000        NA
> 2      1100   1991   1100 10.000000
> 3      1100   1992   1200  9.090909
> 4      1100   1993   1300  8.333333
> 5      1100   1995   1500 15.384615
> 6      1100   1996   1600  6.666667
> 7      1200   1991   1100        NA
> 8      1200   1992   1200  9.090909
> 9      1200   1993   1300  8.333333
> 10     1200   1994   1400  7.692308
> 11     1200   1995   1500  7.142857
> 12     1200   1996   1600  6.666667
> 13     1300   1990   1000        NA
> 14     1300   1991   1100 10.000000
> 15     1300   1992   1200  9.090909
> 16     1300   1993   1300  8.333333
> 17     1300   1994   1400  7.692308
> 18     1300   1995   1500  7.142857
> 19     1300   1996   1600  6.666667
> # I thought of using the formula only when the increment of fyear1 is
> only 1 while in a co_code1, by using this formula
> 
> d<-ddply(df1,
>         "co_code1",
>         transform,
>         if(diff(fyear1)==1){
>           growth=(exp(diff(log(df1$sales1)))-1)*100
>         } else{
>           growth=NA
>         })
> 
> But, this doesn't work. I am getting the following error.
> 
> In if (diff(fyear1) == 1) { :
>  the condition has length > 1 and only the first element will be used
> (repeated a few times).
> 
> # I have searched for a solution, but somehow couldn't get one. Hope
> that some kind soul will guide me here.
> 

In your case use ifelse() as explained by Rui. 
But it can be done more easily since the fyear1 and co_code1 are synchronized.
Add a new column to df1 like this

df1$growth <- c(NA,
         ifelse(diff(df1$fyear1)==1,
                    (exp(diff(log(df1$sales1)))-1)*100,
                    NA
                    )
        )

and display df1. From your request I cannot determine if this is what you want.

regards,

Berend Hasselman


From petr.pikal at precheza.cz  Thu Dec 15 14:51:16 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 15 Dec 2016 13:51:16 +0000
Subject: [R] Computing growth rate
In-Reply-To: <96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C504A1E1@SRVEXCHMBX.precheza.cz>

Hi

Maybe you does not need if or ifelse but just divide by years difference.

d2<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1))/diff(fyear1))- 1)*100)

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Berend
> Hasselman
> Sent: Thursday, December 15, 2016 1:18 PM
> To: Brijesh Mishra <brijeshkmishra at gmail.com>
> Cc: r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] Computing growth rate
>
>
> > On 15 Dec 2016, at 04:40, Brijesh Mishra <brijeshkmishra at gmail.com>
> wrote:
> >
> > Hi,
> >
> > I am trying to calculate growth rate (say, sales, though it is to be
> > computed for many variables) in a panel data set. Problem is that I
> > have missing data for many firms for many years. To put it simply, I
> > have created this short dataframe (original df id much bigger)
> >
> > df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
> > fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
> >
> > # this gives me
> > co_code1 fyear1 sales1
> > 1      1100   1990   1000
> > 2      1100   1991   1100
> > 3      1100   1992   1200
> > 4      1100   1993   1300
> > 5      1100   1994   1400
> > 6      1100   1995   1500
> > 7      1100   1996   1600
> > 8      1200   1990   1000
> > 9      1200   1991   1100
> > 10     1200   1992   1200
> > 11     1200   1993   1300
> > 12     1200   1994   1400
> > 13     1200   1995   1500
> > 14     1200   1996   1600
> > 15     1300   1990   1000
> > 16     1300   1991   1100
> > 17     1300   1992   1200
> > 18     1300   1993   1300
> > 19     1300   1994   1400
> > 20     1300   1995   1500
> > 21     1300   1996   1600
> >
> > # I am now removing a couple of rows
> > df1<-df1[-c(5, 8), ]
> > # the result is
> >   co_code1 fyear1 sales1
> > 1      1100   1990   1000
> > 2      1100   1991   1100
> > 3      1100   1992   1200
> > 4      1100   1993   1300
> > 6      1100   1995   1500
> > 7      1100   1996   1600
> > 9      1200   1991   1100
> > 10     1200   1992   1200
> > 11     1200   1993   1300
> > 12     1200   1994   1400
> > 13     1200   1995   1500
> > 14     1200   1996   1600
> > 15     1300   1990   1000
> > 16     1300   1991   1100
> > 17     1300   1992   1200
> > 18     1300   1993   1300
> > 19     1300   1994   1400
> > 20     1300   1995   1500
> > 21     1300   1996   1600
> > # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
> > removed. If I try,
> > d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-
> 1)*100)
> >
> > # this apparently gives wrong results for the year 1995 (as shown
> > below) as growth rates are computed considering yearly increment.
> >
> >   co_code1 fyear1 sales1    growth
> > 1      1100   1990   1000        NA
> > 2      1100   1991   1100 10.000000
> > 3      1100   1992   1200  9.090909
> > 4      1100   1993   1300  8.333333
> > 5      1100   1995   1500 15.384615
> > 6      1100   1996   1600  6.666667
> > 7      1200   1991   1100        NA
> > 8      1200   1992   1200  9.090909
> > 9      1200   1993   1300  8.333333
> > 10     1200   1994   1400  7.692308
> > 11     1200   1995   1500  7.142857
> > 12     1200   1996   1600  6.666667
> > 13     1300   1990   1000        NA
> > 14     1300   1991   1100 10.000000
> > 15     1300   1992   1200  9.090909
> > 16     1300   1993   1300  8.333333
> > 17     1300   1994   1400  7.692308
> > 18     1300   1995   1500  7.142857
> > 19     1300   1996   1600  6.666667
> > # I thought of using the formula only when the increment of fyear1 is
> > only 1 while in a co_code1, by using this formula
> >
> > d<-ddply(df1,
> >         "co_code1",
> >         transform,
> >         if(diff(fyear1)==1){
> >           growth=(exp(diff(log(df1$sales1)))-1)*100
> >         } else{
> >           growth=NA
> >         })
> >
> > But, this doesn't work. I am getting the following error.
> >
> > In if (diff(fyear1) == 1) { :
> >  the condition has length > 1 and only the first element will be used
> > (repeated a few times).
> >
> > # I have searched for a solution, but somehow couldn't get one. Hope
> > that some kind soul will guide me here.
> >
>
> In your case use ifelse() as explained by Rui.
> But it can be done more easily since the fyear1 and co_code1 are
> synchronized.
> Add a new column to df1 like this
>
> df1$growth <- c(NA,
>          ifelse(diff(df1$fyear1)==1,
>                     (exp(diff(log(df1$sales1)))-1)*100,
>                     NA
>                     )
>         )
>
> and display df1. From your request I cannot determine if this is what you
> want.
>
> regards,
>
> Berend Hasselman
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bhh at xs4all.nl  Thu Dec 15 15:23:38 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 15 Dec 2016 15:23:38 +0100
Subject: [R] Computing growth rate
In-Reply-To: <CAHUdqRvYv_LdTjvxm8amBj+6-M-n7aLBNSS90XevaofmBcjLrA@mail.gmail.com>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
	<CAHUdqRvYv_LdTjvxm8amBj+6-M-n7aLBNSS90XevaofmBcjLrA@mail.gmail.com>
Message-ID: <35309909-9A98-4D95-9BD1-C1836019334F@xs4all.nl>


> On 15 Dec 2016, at 13:34, Brijesh Mishra <brijeshkmishra at gmail.com> wrote:
> 
> Dear Mr Hasselman,
> 
> I missed you mail, while I was typing my own mail as a reply to Mr.
> Barradas suggestion. In fact, I implemented your suggestion even
> before reading it. But, I have a concern that I have noted (though its
> only hypothetical- such a scenario is very unlikely to occur). Is
> there a way to restrict such calculations co_code1 wise?

Like this?

df2 <- ddply(df1,"co_code1", transform,
    growth=c(NA, ifelse(diff(fyear1)==1, (exp(diff(log(sales1)))-1)*100,NA))
    )


But do also look at Petr Pikal's solution. Which of the two solutions you prefer depends on what you want in your special case.

Berend

From david.stevens at usu.edu  Thu Dec 15 15:32:15 2016
From: david.stevens at usu.edu (David Stevens)
Date: Thu, 15 Dec 2016 09:32:15 -0500
Subject: [R] Computing growth rate
In-Reply-To: <96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
Message-ID: <a9fb5a8d-0666-9c1b-4199-09c16edbee21@usu.edu>

Berend - Unless you need the change in sales year by year, you might 
consider looking at each company's sales over the years and use 
regression or other type of trend analysis to get an overall trend... 
Or, if not, simply divide diff(sales) by diff(fyear1) for each company 
so at least you get the average over the missing years.

David


On 12/15/2016 7:18 AM, Berend Hasselman wrote:
>> On 15 Dec 2016, at 04:40, Brijesh Mishra <brijeshkmishra at gmail.com> wrote:
>>
>> Hi,
>>
>> I am trying to calculate growth rate (say, sales, though it is to be
>> computed for many variables) in a panel data set. Problem is that I
>> have missing data for many firms for many years. To put it simply, I
>> have created this short dataframe (original df id much bigger)
>>
>> df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
>> fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
>>
>> # this gives me
>> co_code1 fyear1 sales1
>> 1      1100   1990   1000
>> 2      1100   1991   1100
>> 3      1100   1992   1200
>> 4      1100   1993   1300
>> 5      1100   1994   1400
>> 6      1100   1995   1500
>> 7      1100   1996   1600
>> 8      1200   1990   1000
>> 9      1200   1991   1100
>> 10     1200   1992   1200
>> 11     1200   1993   1300
>> 12     1200   1994   1400
>> 13     1200   1995   1500
>> 14     1200   1996   1600
>> 15     1300   1990   1000
>> 16     1300   1991   1100
>> 17     1300   1992   1200
>> 18     1300   1993   1300
>> 19     1300   1994   1400
>> 20     1300   1995   1500
>> 21     1300   1996   1600
>>
>> # I am now removing a couple of rows
>> df1<-df1[-c(5, 8), ]
>> # the result is
>>    co_code1 fyear1 sales1
>> 1      1100   1990   1000
>> 2      1100   1991   1100
>> 3      1100   1992   1200
>> 4      1100   1993   1300
>> 6      1100   1995   1500
>> 7      1100   1996   1600
>> 9      1200   1991   1100
>> 10     1200   1992   1200
>> 11     1200   1993   1300
>> 12     1200   1994   1400
>> 13     1200   1995   1500
>> 14     1200   1996   1600
>> 15     1300   1990   1000
>> 16     1300   1991   1100
>> 17     1300   1992   1200
>> 18     1300   1993   1300
>> 19     1300   1994   1400
>> 20     1300   1995   1500
>> 21     1300   1996   1600
>> # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
>> removed. If I try,
>> d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-1)*100)
>>
>> # this apparently gives wrong results for the year 1995 (as shown
>> below) as growth rates are computed considering yearly increment.
>>
>>    co_code1 fyear1 sales1    growth
>> 1      1100   1990   1000        NA
>> 2      1100   1991   1100 10.000000
>> 3      1100   1992   1200  9.090909
>> 4      1100   1993   1300  8.333333
>> 5      1100   1995   1500 15.384615
>> 6      1100   1996   1600  6.666667
>> 7      1200   1991   1100        NA
>> 8      1200   1992   1200  9.090909
>> 9      1200   1993   1300  8.333333
>> 10     1200   1994   1400  7.692308
>> 11     1200   1995   1500  7.142857
>> 12     1200   1996   1600  6.666667
>> 13     1300   1990   1000        NA
>> 14     1300   1991   1100 10.000000
>> 15     1300   1992   1200  9.090909
>> 16     1300   1993   1300  8.333333
>> 17     1300   1994   1400  7.692308
>> 18     1300   1995   1500  7.142857
>> 19     1300   1996   1600  6.666667
>> # I thought of using the formula only when the increment of fyear1 is
>> only 1 while in a co_code1, by using this formula
>>
>> d<-ddply(df1,
>>          "co_code1",
>>          transform,
>>          if(diff(fyear1)==1){
>>            growth=(exp(diff(log(df1$sales1)))-1)*100
>>          } else{
>>            growth=NA
>>          })
>>
>> But, this doesn't work. I am getting the following error.
>>
>> In if (diff(fyear1) == 1) { :
>>   the condition has length > 1 and only the first element will be used
>> (repeated a few times).
>>
>> # I have searched for a solution, but somehow couldn't get one. Hope
>> that some kind soul will guide me here.
>>
> In your case use ifelse() as explained by Rui.
> But it can be done more easily since the fyear1 and co_code1 are synchronized.
> Add a new column to df1 like this
>
> df1$growth <- c(NA,
>           ifelse(diff(df1$fyear1)==1,
>                      (exp(diff(log(df1$sales1)))-1)*100,
>                      NA
>                      )
>          )
>
> and display df1. From your request I cannot determine if this is what you want.
>
> regards,
>
> Berend Hasselman
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From brijeshkmishra at gmail.com  Thu Dec 15 13:35:48 2016
From: brijeshkmishra at gmail.com (Brijesh Mishra)
Date: Thu, 15 Dec 2016 18:05:48 +0530
Subject: [R] Computing growth rate
In-Reply-To: <CAHUdqRvYv_LdTjvxm8amBj+6-M-n7aLBNSS90XevaofmBcjLrA@mail.gmail.com>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
	<CAHUdqRvYv_LdTjvxm8amBj+6-M-n7aLBNSS90XevaofmBcjLrA@mail.gmail.com>
Message-ID: <CAHUdqRt49E1J+ePL-K6Vxduv_-y0=v6Q9p-ONqagMm0j0nHbEQ@mail.gmail.com>

This was ensured while using ddply()...

On Thu, Dec 15, 2016 at 6:04 PM, Brijesh Mishra
<brijeshkmishra at gmail.com> wrote:
> Dear Mr Hasselman,
>
> I missed you mail, while I was typing my own mail as a reply to Mr.
> Barradas suggestion. In fact, I implemented your suggestion even
> before reading it. But, I have a concern that I have noted (though its
> only hypothetical- such a scenario is very unlikely to occur). Is
> there a way to restrict such calculations co_code1 wise?
>
> Many thanks,
>
> Brijesh
>
> On Thu, Dec 15, 2016 at 5:48 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>
>>> On 15 Dec 2016, at 04:40, Brijesh Mishra <brijeshkmishra at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> I am trying to calculate growth rate (say, sales, though it is to be
>>> computed for many variables) in a panel data set. Problem is that I
>>> have missing data for many firms for many years. To put it simply, I
>>> have created this short dataframe (original df id much bigger)
>>>
>>> df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
>>> fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
>>>
>>> # this gives me
>>> co_code1 fyear1 sales1
>>> 1      1100   1990   1000
>>> 2      1100   1991   1100
>>> 3      1100   1992   1200
>>> 4      1100   1993   1300
>>> 5      1100   1994   1400
>>> 6      1100   1995   1500
>>> 7      1100   1996   1600
>>> 8      1200   1990   1000
>>> 9      1200   1991   1100
>>> 10     1200   1992   1200
>>> 11     1200   1993   1300
>>> 12     1200   1994   1400
>>> 13     1200   1995   1500
>>> 14     1200   1996   1600
>>> 15     1300   1990   1000
>>> 16     1300   1991   1100
>>> 17     1300   1992   1200
>>> 18     1300   1993   1300
>>> 19     1300   1994   1400
>>> 20     1300   1995   1500
>>> 21     1300   1996   1600
>>>
>>> # I am now removing a couple of rows
>>> df1<-df1[-c(5, 8), ]
>>> # the result is
>>>   co_code1 fyear1 sales1
>>> 1      1100   1990   1000
>>> 2      1100   1991   1100
>>> 3      1100   1992   1200
>>> 4      1100   1993   1300
>>> 6      1100   1995   1500
>>> 7      1100   1996   1600
>>> 9      1200   1991   1100
>>> 10     1200   1992   1200
>>> 11     1200   1993   1300
>>> 12     1200   1994   1400
>>> 13     1200   1995   1500
>>> 14     1200   1996   1600
>>> 15     1300   1990   1000
>>> 16     1300   1991   1100
>>> 17     1300   1992   1200
>>> 18     1300   1993   1300
>>> 19     1300   1994   1400
>>> 20     1300   1995   1500
>>> 21     1300   1996   1600
>>> # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
>>> removed. If I try,
>>> d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-1)*100)
>>>
>>> # this apparently gives wrong results for the year 1995 (as shown
>>> below) as growth rates are computed considering yearly increment.
>>>
>>>   co_code1 fyear1 sales1    growth
>>> 1      1100   1990   1000        NA
>>> 2      1100   1991   1100 10.000000
>>> 3      1100   1992   1200  9.090909
>>> 4      1100   1993   1300  8.333333
>>> 5      1100   1995   1500 15.384615
>>> 6      1100   1996   1600  6.666667
>>> 7      1200   1991   1100        NA
>>> 8      1200   1992   1200  9.090909
>>> 9      1200   1993   1300  8.333333
>>> 10     1200   1994   1400  7.692308
>>> 11     1200   1995   1500  7.142857
>>> 12     1200   1996   1600  6.666667
>>> 13     1300   1990   1000        NA
>>> 14     1300   1991   1100 10.000000
>>> 15     1300   1992   1200  9.090909
>>> 16     1300   1993   1300  8.333333
>>> 17     1300   1994   1400  7.692308
>>> 18     1300   1995   1500  7.142857
>>> 19     1300   1996   1600  6.666667
>>> # I thought of using the formula only when the increment of fyear1 is
>>> only 1 while in a co_code1, by using this formula
>>>
>>> d<-ddply(df1,
>>>         "co_code1",
>>>         transform,
>>>         if(diff(fyear1)==1){
>>>           growth=(exp(diff(log(df1$sales1)))-1)*100
>>>         } else{
>>>           growth=NA
>>>         })
>>>
>>> But, this doesn't work. I am getting the following error.
>>>
>>> In if (diff(fyear1) == 1) { :
>>>  the condition has length > 1 and only the first element will be used
>>> (repeated a few times).
>>>
>>> # I have searched for a solution, but somehow couldn't get one. Hope
>>> that some kind soul will guide me here.
>>>
>>
>> In your case use ifelse() as explained by Rui.
>> But it can be done more easily since the fyear1 and co_code1 are synchronized.
>> Add a new column to df1 like this
>>
>> df1$growth <- c(NA,
>>          ifelse(diff(df1$fyear1)==1,
>>                     (exp(diff(log(df1$sales1)))-1)*100,
>>                     NA
>>                     )
>>         )
>>
>> and display df1. From your request I cannot determine if this is what you want.
>>
>> regards,
>>
>> Berend Hasselman
>>


From brijeshkmishra at gmail.com  Thu Dec 15 13:34:39 2016
From: brijeshkmishra at gmail.com (Brijesh Mishra)
Date: Thu, 15 Dec 2016 18:04:39 +0530
Subject: [R] Computing growth rate
In-Reply-To: <96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
Message-ID: <CAHUdqRvYv_LdTjvxm8amBj+6-M-n7aLBNSS90XevaofmBcjLrA@mail.gmail.com>

Dear Mr Hasselman,

I missed you mail, while I was typing my own mail as a reply to Mr.
Barradas suggestion. In fact, I implemented your suggestion even
before reading it. But, I have a concern that I have noted (though its
only hypothetical- such a scenario is very unlikely to occur). Is
there a way to restrict such calculations co_code1 wise?

Many thanks,

Brijesh

On Thu, Dec 15, 2016 at 5:48 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
>> On 15 Dec 2016, at 04:40, Brijesh Mishra <brijeshkmishra at gmail.com> wrote:
>>
>> Hi,
>>
>> I am trying to calculate growth rate (say, sales, though it is to be
>> computed for many variables) in a panel data set. Problem is that I
>> have missing data for many firms for many years. To put it simply, I
>> have created this short dataframe (original df id much bigger)
>>
>> df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
>> fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
>>
>> # this gives me
>> co_code1 fyear1 sales1
>> 1      1100   1990   1000
>> 2      1100   1991   1100
>> 3      1100   1992   1200
>> 4      1100   1993   1300
>> 5      1100   1994   1400
>> 6      1100   1995   1500
>> 7      1100   1996   1600
>> 8      1200   1990   1000
>> 9      1200   1991   1100
>> 10     1200   1992   1200
>> 11     1200   1993   1300
>> 12     1200   1994   1400
>> 13     1200   1995   1500
>> 14     1200   1996   1600
>> 15     1300   1990   1000
>> 16     1300   1991   1100
>> 17     1300   1992   1200
>> 18     1300   1993   1300
>> 19     1300   1994   1400
>> 20     1300   1995   1500
>> 21     1300   1996   1600
>>
>> # I am now removing a couple of rows
>> df1<-df1[-c(5, 8), ]
>> # the result is
>>   co_code1 fyear1 sales1
>> 1      1100   1990   1000
>> 2      1100   1991   1100
>> 3      1100   1992   1200
>> 4      1100   1993   1300
>> 6      1100   1995   1500
>> 7      1100   1996   1600
>> 9      1200   1991   1100
>> 10     1200   1992   1200
>> 11     1200   1993   1300
>> 12     1200   1994   1400
>> 13     1200   1995   1500
>> 14     1200   1996   1600
>> 15     1300   1990   1000
>> 16     1300   1991   1100
>> 17     1300   1992   1200
>> 18     1300   1993   1300
>> 19     1300   1994   1400
>> 20     1300   1995   1500
>> 21     1300   1996   1600
>> # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
>> removed. If I try,
>> d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-1)*100)
>>
>> # this apparently gives wrong results for the year 1995 (as shown
>> below) as growth rates are computed considering yearly increment.
>>
>>   co_code1 fyear1 sales1    growth
>> 1      1100   1990   1000        NA
>> 2      1100   1991   1100 10.000000
>> 3      1100   1992   1200  9.090909
>> 4      1100   1993   1300  8.333333
>> 5      1100   1995   1500 15.384615
>> 6      1100   1996   1600  6.666667
>> 7      1200   1991   1100        NA
>> 8      1200   1992   1200  9.090909
>> 9      1200   1993   1300  8.333333
>> 10     1200   1994   1400  7.692308
>> 11     1200   1995   1500  7.142857
>> 12     1200   1996   1600  6.666667
>> 13     1300   1990   1000        NA
>> 14     1300   1991   1100 10.000000
>> 15     1300   1992   1200  9.090909
>> 16     1300   1993   1300  8.333333
>> 17     1300   1994   1400  7.692308
>> 18     1300   1995   1500  7.142857
>> 19     1300   1996   1600  6.666667
>> # I thought of using the formula only when the increment of fyear1 is
>> only 1 while in a co_code1, by using this formula
>>
>> d<-ddply(df1,
>>         "co_code1",
>>         transform,
>>         if(diff(fyear1)==1){
>>           growth=(exp(diff(log(df1$sales1)))-1)*100
>>         } else{
>>           growth=NA
>>         })
>>
>> But, this doesn't work. I am getting the following error.
>>
>> In if (diff(fyear1) == 1) { :
>>  the condition has length > 1 and only the first element will be used
>> (repeated a few times).
>>
>> # I have searched for a solution, but somehow couldn't get one. Hope
>> that some kind soul will guide me here.
>>
>
> In your case use ifelse() as explained by Rui.
> But it can be done more easily since the fyear1 and co_code1 are synchronized.
> Add a new column to df1 like this
>
> df1$growth <- c(NA,
>          ifelse(diff(df1$fyear1)==1,
>                     (exp(diff(log(df1$sales1)))-1)*100,
>                     NA
>                     )
>         )
>
> and display df1. From your request I cannot determine if this is what you want.
>
> regards,
>
> Berend Hasselman
>


From brijeshkmishra at gmail.com  Thu Dec 15 13:28:23 2016
From: brijeshkmishra at gmail.com (Brijesh Mishra)
Date: Thu, 15 Dec 2016 17:58:23 +0530
Subject: [R] Computing growth rate
In-Reply-To: <58527F65.1010400@sapo.pt>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<58527F65.1010400@sapo.pt>
Message-ID: <CAHUdqRsJV089zbK0J6XW456FMRAsj3VQA1vvNaNS1VDQREmwYA@mail.gmail.com>

Dear Mr. Barradas,

Thanks a lot for pointing that. I tried that in a few steps-
1. when I evaluated

d<-ddply(df1,"co_code1",transform, growth <- ifelse(diff(fyear1)==1,
(exp(diff(log(df1$sales1)))-1)*100, NA))

I got the following, i.e., I was not getting the growth column automatically.

co_code1 fyear1 sales1
1      1100   1990   1000
2      1100   1991   1100
3      1100   1992   1200
4      1100   1993   1300
5      1100   1995   1500
6      1100   1996   1600
7      1200   1991   1100
8      1200   1992   1200
9      1200   1993   1300
10     1200   1994   1400
11     1200   1995   1500
12     1200   1996   1600
13     1300   1990   1000
14     1300   1992   1200
15     1300   1993   1300
16     1300   1994   1400
17     1300   1995   1500
18     1300   1996   1600

2. When, just for the heck of it, the assign mark (<-) was changed to
'=' as done previously,

d<-ddply(df1,"co_code1",transform, growth = ifelse(diff(fyear1)==1,
(exp(diff(log(df1$sales1)))-1)*100, NA))

It was no longer evaluated-error was

"Error in data.frame(list(co_code1 = c(1100, 1100, 1100, 1100, 1100, 1100 :
  arguments imply differing number of rows: 6, 5"

3. The following gives the desired result

df1$growth<-c(NA, ifelse(diff(df1$fyear1)==1,
(exp(diff(log(df1$sales1)))-1)*100, NA))

But now I am no longer restricting each iteranation to
'co_code1'-hypothetically if one co_code1 is followed by another with
incremental 'fyear1' difference as 1, growth will be evaluated.

Is there a better and more elegant way of doing it?

Thanks and regards,

Brijesh

On Thu, Dec 15, 2016 at 5:02 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> That is a very common mistake. if() accepts only one TRUE/FALSE, for a
> vectorized version you need ?ifelse. Something like the following
> (untested).
>
> growth <- ifelse(diff(fyear1)==1, (exp(diff(log(df1$sales1)))-1)*100, NA)
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 15-12-2016 03:40, Brijesh Mishra escreveu:
>>
>> Hi,
>>
>> I am trying to calculate growth rate (say, sales, though it is to be
>> computed for many variables) in a panel data set. Problem is that I
>> have missing data for many firms for many years. To put it simply, I
>> have created this short dataframe (original df id much bigger)
>>
>> df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
>> fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
>>
>> # this gives me
>> co_code1 fyear1 sales1
>> 1      1100   1990   1000
>> 2      1100   1991   1100
>> 3      1100   1992   1200
>> 4      1100   1993   1300
>> 5      1100   1994   1400
>> 6      1100   1995   1500
>> 7      1100   1996   1600
>> 8      1200   1990   1000
>> 9      1200   1991   1100
>> 10     1200   1992   1200
>> 11     1200   1993   1300
>> 12     1200   1994   1400
>> 13     1200   1995   1500
>> 14     1200   1996   1600
>> 15     1300   1990   1000
>> 16     1300   1991   1100
>> 17     1300   1992   1200
>> 18     1300   1993   1300
>> 19     1300   1994   1400
>> 20     1300   1995   1500
>> 21     1300   1996   1600
>>
>> # I am now removing a couple of rows
>> df1<-df1[-c(5, 8), ]
>> # the result is
>>     co_code1 fyear1 sales1
>> 1      1100   1990   1000
>> 2      1100   1991   1100
>> 3      1100   1992   1200
>> 4      1100   1993   1300
>> 6      1100   1995   1500
>> 7      1100   1996   1600
>> 9      1200   1991   1100
>> 10     1200   1992   1200
>> 11     1200   1993   1300
>> 12     1200   1994   1400
>> 13     1200   1995   1500
>> 14     1200   1996   1600
>> 15     1300   1990   1000
>> 16     1300   1991   1100
>> 17     1300   1992   1200
>> 18     1300   1993   1300
>> 19     1300   1994   1400
>> 20     1300   1995   1500
>> 21     1300   1996   1600
>> # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
>> removed. If I try,
>> d<-ddply(df1,"co_code1",transform,
>> growth=c(NA,exp(diff(log(sales1)))-1)*100)
>>
>> # this apparently gives wrong results for the year 1995 (as shown
>> below) as growth rates are computed considering yearly increment.
>>
>>     co_code1 fyear1 sales1    growth
>> 1      1100   1990   1000        NA
>> 2      1100   1991   1100 10.000000
>> 3      1100   1992   1200  9.090909
>> 4      1100   1993   1300  8.333333
>> 5      1100   1995   1500 15.384615
>> 6      1100   1996   1600  6.666667
>> 7      1200   1991   1100        NA
>> 8      1200   1992   1200  9.090909
>> 9      1200   1993   1300  8.333333
>> 10     1200   1994   1400  7.692308
>> 11     1200   1995   1500  7.142857
>> 12     1200   1996   1600  6.666667
>> 13     1300   1990   1000        NA
>> 14     1300   1991   1100 10.000000
>> 15     1300   1992   1200  9.090909
>> 16     1300   1993   1300  8.333333
>> 17     1300   1994   1400  7.692308
>> 18     1300   1995   1500  7.142857
>> 19     1300   1996   1600  6.666667
>> # I thought of using the formula only when the increment of fyear1 is
>> only 1 while in a co_code1, by using this formula
>>
>> d<-ddply(df1,
>>           "co_code1",
>>           transform,
>>           if(diff(fyear1)==1){
>>             growth=(exp(diff(log(df1$sales1)))-1)*100
>>           } else{
>>             growth=NA
>>           })
>>
>> But, this doesn't work. I am getting the following error.
>>
>> In if (diff(fyear1) == 1) { :
>>    the condition has length > 1 and only the first element will be used
>> (repeated a few times).
>>
>> # I have searched for a solution, but somehow couldn't get one. Hope
>> that some kind soul will guide me here.
>>
>> Regards,
>>
>> Brijesh K Mishra
>> Indian Institute of Management, Indore
>> India
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From brijeshkmishra at gmail.com  Thu Dec 15 15:43:32 2016
From: brijeshkmishra at gmail.com (Brijesh Mishra)
Date: Thu, 15 Dec 2016 20:13:32 +0530
Subject: [R] Computing growth rate
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C504A1E1@SRVEXCHMBX.precheza.cz>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C504A1E1@SRVEXCHMBX.precheza.cz>
Message-ID: <CAHUdqRtFWpeGRQohZJCW+4mTdCAQWevTWcO-OGnM+EOTeR=m-Q@mail.gmail.com>

Wow, Mr Petr. The placing of diff(fyear1) was very clever indeed. Just
to understand the steps intended by you-

exp(diff(log(sales1))/diff(fyear1))- 1)
= exp(((log(sales1(t)/sales1(t-1)))/(fyear1(t)-fyear(t-1)))-1)
= exp(log(sales(t)/sales(t-1))^(1/(delta(fyear1))))-1
= ((sales(t)/(sales(t-1)))^(1/(delta(fyear1)))-1

This gives the CAGR, which saves some precious data-points (in my
dataset, it may prove a big boon). I spent a significant amount of
time today to figure out something like this, which you did so easily.

Many Thanks,

Brijesh

On Thu, Dec 15, 2016 at 7:21 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> Maybe you does not need if or ifelse but just divide by years difference.
>
> d2<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1))/diff(fyear1))- 1)*100)
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Berend
>> Hasselman
>> Sent: Thursday, December 15, 2016 1:18 PM
>> To: Brijesh Mishra <brijeshkmishra at gmail.com>
>> Cc: r-help mailing list <r-help at r-project.org>
>> Subject: Re: [R] Computing growth rate
>>
>>
>> > On 15 Dec 2016, at 04:40, Brijesh Mishra <brijeshkmishra at gmail.com>
>> wrote:
>> >
>> > Hi,
>> >
>> > I am trying to calculate growth rate (say, sales, though it is to be
>> > computed for many variables) in a panel data set. Problem is that I
>> > have missing data for many firms for many years. To put it simply, I
>> > have created this short dataframe (original df id much bigger)
>> >
>> > df1<-data.frame(co_code1=rep(c(1100, 1200, 1300), each=7),
>> > fyear1=rep(1990:1996, 3), sales1=rep(seq(1000,1600, by=100),3))
>> >
>> > # this gives me
>> > co_code1 fyear1 sales1
>> > 1      1100   1990   1000
>> > 2      1100   1991   1100
>> > 3      1100   1992   1200
>> > 4      1100   1993   1300
>> > 5      1100   1994   1400
>> > 6      1100   1995   1500
>> > 7      1100   1996   1600
>> > 8      1200   1990   1000
>> > 9      1200   1991   1100
>> > 10     1200   1992   1200
>> > 11     1200   1993   1300
>> > 12     1200   1994   1400
>> > 13     1200   1995   1500
>> > 14     1200   1996   1600
>> > 15     1300   1990   1000
>> > 16     1300   1991   1100
>> > 17     1300   1992   1200
>> > 18     1300   1993   1300
>> > 19     1300   1994   1400
>> > 20     1300   1995   1500
>> > 21     1300   1996   1600
>> >
>> > # I am now removing a couple of rows
>> > df1<-df1[-c(5, 8), ]
>> > # the result is
>> >   co_code1 fyear1 sales1
>> > 1      1100   1990   1000
>> > 2      1100   1991   1100
>> > 3      1100   1992   1200
>> > 4      1100   1993   1300
>> > 6      1100   1995   1500
>> > 7      1100   1996   1600
>> > 9      1200   1991   1100
>> > 10     1200   1992   1200
>> > 11     1200   1993   1300
>> > 12     1200   1994   1400
>> > 13     1200   1995   1500
>> > 14     1200   1996   1600
>> > 15     1300   1990   1000
>> > 16     1300   1991   1100
>> > 17     1300   1992   1200
>> > 18     1300   1993   1300
>> > 19     1300   1994   1400
>> > 20     1300   1995   1500
>> > 21     1300   1996   1600
>> > # so 1994 for co_code1 1100 and 1990 for co_code1 1200 have been
>> > removed. If I try,
>> > d<-ddply(df1,"co_code1",transform, growth=c(NA,exp(diff(log(sales1)))-
>> 1)*100)
>> >
>> > # this apparently gives wrong results for the year 1995 (as shown
>> > below) as growth rates are computed considering yearly increment.
>> >
>> >   co_code1 fyear1 sales1    growth
>> > 1      1100   1990   1000        NA
>> > 2      1100   1991   1100 10.000000
>> > 3      1100   1992   1200  9.090909
>> > 4      1100   1993   1300  8.333333
>> > 5      1100   1995   1500 15.384615
>> > 6      1100   1996   1600  6.666667
>> > 7      1200   1991   1100        NA
>> > 8      1200   1992   1200  9.090909
>> > 9      1200   1993   1300  8.333333
>> > 10     1200   1994   1400  7.692308
>> > 11     1200   1995   1500  7.142857
>> > 12     1200   1996   1600  6.666667
>> > 13     1300   1990   1000        NA
>> > 14     1300   1991   1100 10.000000
>> > 15     1300   1992   1200  9.090909
>> > 16     1300   1993   1300  8.333333
>> > 17     1300   1994   1400  7.692308
>> > 18     1300   1995   1500  7.142857
>> > 19     1300   1996   1600  6.666667
>> > # I thought of using the formula only when the increment of fyear1 is
>> > only 1 while in a co_code1, by using this formula
>> >
>> > d<-ddply(df1,
>> >         "co_code1",
>> >         transform,
>> >         if(diff(fyear1)==1){
>> >           growth=(exp(diff(log(df1$sales1)))-1)*100
>> >         } else{
>> >           growth=NA
>> >         })
>> >
>> > But, this doesn't work. I am getting the following error.
>> >
>> > In if (diff(fyear1) == 1) { :
>> >  the condition has length > 1 and only the first element will be used
>> > (repeated a few times).
>> >
>> > # I have searched for a solution, but somehow couldn't get one. Hope
>> > that some kind soul will guide me here.
>> >
>>
>> In your case use ifelse() as explained by Rui.
>> But it can be done more easily since the fyear1 and co_code1 are
>> synchronized.
>> Add a new column to df1 like this
>>
>> df1$growth <- c(NA,
>>          ifelse(diff(df1$fyear1)==1,
>>                     (exp(diff(log(df1$sales1)))-1)*100,
>>                     NA
>>                     )
>>         )
>>
>> and display df1. From your request I cannot determine if this is what you
>> want.
>>
>> regards,
>>
>> Berend Hasselman
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From brijeshkmishra at gmail.com  Thu Dec 15 15:45:36 2016
From: brijeshkmishra at gmail.com (Brijesh Mishra)
Date: Thu, 15 Dec 2016 20:15:36 +0530
Subject: [R] Computing growth rate
In-Reply-To: <35309909-9A98-4D95-9BD1-C1836019334F@xs4all.nl>
References: <CAHUdqRsBY-WRYha7n=q1Tmgm+M9=zSrs8W51VnEpqsV6ryMjbw@mail.gmail.com>
	<96924A16-E018-4187-874B-1D68802D3B3D@xs4all.nl>
	<CAHUdqRvYv_LdTjvxm8amBj+6-M-n7aLBNSS90XevaofmBcjLrA@mail.gmail.com>
	<35309909-9A98-4D95-9BD1-C1836019334F@xs4all.nl>
Message-ID: <CAHUdqRtbgCQKorXYu3ebOLSmaR2V2T9P=QHgAK00eFe4ctcchQ@mail.gmail.com>

Yes, Mr Hasselman. This works like charm now. I also realise where I
was making an error. Now I have two very good options to choose from.
Spoilt for choices...

Many Many Thanks,

Brijesh

On Thu, Dec 15, 2016 at 7:53 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
>> On 15 Dec 2016, at 13:34, Brijesh Mishra <brijeshkmishra at gmail.com> wrote:
>>
>> Dear Mr Hasselman,
>>
>> I missed you mail, while I was typing my own mail as a reply to Mr.
>> Barradas suggestion. In fact, I implemented your suggestion even
>> before reading it. But, I have a concern that I have noted (though its
>> only hypothetical- such a scenario is very unlikely to occur). Is
>> there a way to restrict such calculations co_code1 wise?
>
> Like this?
>
> df2 <- ddply(df1,"co_code1", transform,
>     growth=c(NA, ifelse(diff(fyear1)==1, (exp(diff(log(sales1)))-1)*100,NA))
>     )
>
>
> But do also look at Petr Pikal's solution. Which of the two solutions you prefer depends on what you want in your special case.
>
> Berend


From hfang.shanghai at gmail.com  Tue Dec 13 22:54:27 2016
From: hfang.shanghai at gmail.com (Hai Fang)
Date: Tue, 13 Dec 2016 21:54:27 +0000
Subject: [R] [R-pkgs]  Announcing XGR
Message-ID: <CAF-SqYEyTHNuPZ+LUn7ofRLB===Swbe-Lq054mGWZc7b31mSJg@mail.gmail.com>

Dear R users,

I am happy to announce that the package 'XGR' (Exploring Genomic Relations
available at http://cran.r-project.org/package=XGR) has been on CRAN since
this April. Now it gets published in Genome Medicine (see
http://dx.doi.org/10.1186/s13073-016-0384-y). Together with its web app,
XGR is able to provide a user-friendly tool for exploring genomic relations
at the gene, SNP and genomic region level.

Best regards,

Dr Hai Fang
Wellcome Trust Centre for Human Genetics
University of Oxford
Roosevelt Drive Headington
Oxford OX3 7BN

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From nstefi at gmail.com  Thu Dec 15 17:46:55 2016
From: nstefi at gmail.com (Steven Nagy)
Date: Thu, 15 Dec 2016 11:46:55 -0500
Subject: [R] Need some help with regular expression
In-Reply-To: <013901d254f3$ec3fdc80$c4bf9580$@gmail.com>
References: <00a301d242e3$7d884e20$7898ea60$@gmail.com>	<CAGxFJbRLyPgD0RJG9Y-ZG4qumPjp4UWi7h1iF4gm1kMYhXeh7g@mail.gmail.com>	<001101d243a0$a91e4f90$fb5aeeb0$@gmail.com>
	<CAGxFJbTo9p-ixAKFZqqAqH7t_xPg1qtVHejFVQ_=ocr9rBfAKA@mail.gmail.com>
	<013901d254f3$ec3fdc80$c4bf9580$@gmail.com>
Message-ID: <001f01d256f2$d897ff40$89c7fdc0$@gmail.com>

I tried to send this email, but it didn't go through. I guess pictures are
not allowed to send through HTML formatted emails?
I'm re-sending it again without the picture, just comment there instead as
placeholder.

Thanks,
Steven


From: Steven Nagy [mailto:nstefi at gmail.com] 
Sent: Monday, December 12, 2016 10:50 PM
To: 'Bert Gunter' <bgunter.4567 at gmail.com>
Cc: 'R-help' <r-help at r-project.org>
Subject: RE: [R] Need some help with regular expression

Hi Bert and all,

Sorry I was too busy at work and didn't have much time to continue this
until now.
So I studied "?regexp" and I can understand your regular expression now:
sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","\\1",x)

But I also wanted to split up these results in 2 columns, so your previous
command would give me this result:
[1] "NMA -> STU" "STU -> REG" "-> STU"

and I wanted to further split them up to show this:
From	To
NMA	STU
STU	REG
	STU

I still don?t quite understand the backreferences, and how could I have 2
backreferences, one for the left side of the ?->? sign and one for the right
side?

So it seems like I need to apply the ?sub? function twice, similar how I
used the ?strapply? function twice in my original post:
strapply(strapply(a, "(file://w+ -> STU|STU -> file://w+)", c, backref = -1,
perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl = TRUE)

or maybe there would be a more simple way of using only 1 ?sub? function and
2 backreferences?

Also I?m not sure what do I do after I get the data? How could I represent
the member type changes graphically? We need to analyze the behavior of
switching from STU to another type or from another type to STU.
Google Analytics has a nice chart under Behavior Flow, or Users Flow, and it
looks like this:
<here was my picture from Google Analytics - it's from Behavior Flow or
Users Flow showing flows from one category to another one and further to
another one>



Is there any graphical representation in R that is similar to this?

Thanks a lot,
Steven

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Sunday, November 20, 2016 10:05 PM
To: Aliz Csonka <mailto:lyzae.ro at gmail.com>
Cc: R-help <mailto:r-help at r-project.org>
Subject: Re: [R] Need some help with regular expression

Although others may respond, I think you will do much better studying
?regexp, which will answer all your questions. I believe the effort you will
make figuring it out will pay dividends for your future R/regular expression
usage that you cannot gain from my direct explanation.

Good luck.

Best,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Nov 20, 2016 at 6:40 PM, Steven Nagy <mailto:nstefi at gmail.com>
wrote:
> Thanks a lot Bert. That's amazing. I am very new to both R and regular 
> expressions. I don't really understand the regular expression that you 
> used below.
> And looks like I don't even need any special library, like the 
> "gsubfn" for the strapply function.
> I was trying to use the regexr.com website to analyze your regular 
> expression, but it doesn't seem to match any text there.
> Can you explain me the regular expression that you used?
> ".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*"
> So the dot in the front means any character and the star after that 
> means that it can repeat 0 or more times, right?
> Then followed by a colon character ":" and a space, and what is the 
> next star after that? It means that the sequence before that again can 
> repeat 0 or more times?
> And what are the double square brackets?
> Is ":alnum:" specific to R? I don't think "regexr.com" understands 
> that. Or maybe that site is for regular expressions in Javascript, and 
> the syntax is different in R?
>
> Thank you,
> Steven
>
> -----Original Message-----
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Sunday, November 20, 2016 2:15 PM
> To: Steven Nagy <mailto:nstefi at gmail.com>
> Cc: R-help <mailto:r-help at r-project.org>
> Subject: Re: [R] Need some help with regular expression
>
> If I understand you correctly, I think you are making it more complex 
> than necessary. Using your example (thanks!!), the following should 
> get you
> started:
>
>
>> x<- c("Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:? -> 1 ; CITY:
>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN -> 
>> ; MEMBER_STATUS:? -> N", "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1
>> ->","Name.MEMBER_TYPE: -> STU")
>>
>> x
> [1] "Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:? -> 1 ; CITY:
> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN -> 
> ;
> MEMBER_STATUS:? -> N"
>
> [2] "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1 ->"
> [3] "Name.MEMBER_TYPE: -> STU"
>>
>> sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","file://1",x)
> [1] "NMA -> STU" "STU -> REG" "-> STU"
>
>
> I am sure that you can get things to the form you desire in one go 
> with some fiddling of the above, but it was easier for me to write the 
> regex to pick out the pieces you wanted and leave the rest to you.
> Others may have slicker ways to do it, of course.
>
> HTH
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Nov 19, 2016 at 8:06 PM, Steven Nagy <mailto:nstefi at gmail.com>
wrote:
>> I tried out a regular expression on this website:
>>
>> http://regexr.com/3en1m
>>
>>
>>
>> So the input text is:
>>
>> "Name.MEMBER_TYPE:? -> STU"
>>
>>
>>
>> The regular expression is: ((?:\w+|\s) -> STU|STU -> (?:\w+|\s))
>>
>> And it returns:
>>
>> "? -> STU"
>>
>>
>>
>> but when I use in R, it doesn't return the same result:
>>
>> strapply(c, "((?:\\w+|\\s) -> STU|STU -> (?:\\w+|\\s))", c, backref = 
>> -1, perl = TRUE)
>>
>> returns:
>> "Name.MEMBER_TYPE: -> STU"
>>
>>
>>
>>
>>
>> Here is what I was trying to do:
>>
>>
>>
>> I need to extract some values from a log table, and I created a 
>> regular expression that helps me with that.
>>
>> The log table has cells with values like:
>>
>> a = "Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:? -> 1 ; CITY:
>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN -> 
>> ; MEMBER_STATUS:? -> N"
>>
>> or
>> b = "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1 ->"
>>
>> so I needed to extract the values that a STU member type is changing 
>> from and to, so I needed NMA, STU in the 1st case or STU, REG in the 
>> 2nd
> case.
>>
>> I came up with this expression which worked in both cases:
>>
>> strapply(strapply(a, "(file://w+ -> STU|STU -> file://w+)", c, backref =
-1, 
>> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl = TRUE)
>>
>>
>>
>> But I had a 3rd case when the source member type was blank:
>>
>> c = "Name.MEMBER_TYPE: -> STU"
>>
>> and in that case it returned an error:
>>
>> strapply(strapply(c, "(file://w+ -> STU|STU -> file://w+)", c, backref =
-1, 
>> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl = TRUE)
>>
>> Error: is.character(x) is not TRUE
>>
>>
>>
>> I found that the error is because this returns NULL:
>>
>> strapply(c, "(file://w+ -> STU|STU -> file://w+)", c, backref = -1, perl
= 
>> TRUE)
>>
>>
>>
>>
>>
>> So I tried to modify the regular expression to match any word or 
>> blank
>> space:
>>
>> strapply(c, "((?:\\w+|\\s) -> STU|STU -> (?:\\w+|\\s))", c, backref = 
>> -1, perl = TRUE)
>>
>>
>>
>> but this returned me the whole value of "c":
>>
>> "Name.MEMBER_TYPE:? -> STU"
>>
>> and I only needed "? -> STU" as it shows on the website regxr.com
>>
>>
>>
>> Is the result wrong on the regxr.com website or strapply returns the 
>> wrong result?
>>
>>
>>
>> Thanks,
>>
>> Steven
>>
>>
>>???????? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Dec 15 19:55:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Dec 2016 10:55:11 -0800
Subject: [R] Need some help with regular expression
In-Reply-To: <001f01d256f2$d897ff40$89c7fdc0$@gmail.com>
References: <00a301d242e3$7d884e20$7898ea60$@gmail.com>
	<CAGxFJbRLyPgD0RJG9Y-ZG4qumPjp4UWi7h1iF4gm1kMYhXeh7g@mail.gmail.com>
	<001101d243a0$a91e4f90$fb5aeeb0$@gmail.com>
	<CAGxFJbTo9p-ixAKFZqqAqH7t_xPg1qtVHejFVQ_=ocr9rBfAKA@mail.gmail.com>
	<013901d254f3$ec3fdc80$c4bf9580$@gmail.com>
	<001f01d256f2$d897ff40$89c7fdc0$@gmail.com>
Message-ID: <5016BD04-7A08-4E96-B3FB-CC171EB44D57@dcn.davis.ca.us>

Actually, the issue of mail formatting is discussed in the Posting Guide, but some key points are:

1) Only a very few types of file attachments are allowed.

2) email processed through the mailing list automatically strips HTML, which often leaves us looking at something full of wacko characters and with no formatting. As the PG says... this is a plain text mailing list... don't send HTML email to it. Fortunately R is plain text, so if you focus on short, reproducible examples then your meaning will come through just fine. 
-- 
Sent from my phone. Please excuse my brevity.

On December 15, 2016 8:46:55 AM PST, Steven Nagy <nstefi at gmail.com> wrote:
>I tried to send this email, but it didn't go through. I guess pictures
>are
>not allowed to send through HTML formatted emails?
>I'm re-sending it again without the picture, just comment there instead
>as
>placeholder.
>
>Thanks,
>Steven
>
>
>From: Steven Nagy [mailto:nstefi at gmail.com] 
>Sent: Monday, December 12, 2016 10:50 PM
>To: 'Bert Gunter' <bgunter.4567 at gmail.com>
>Cc: 'R-help' <r-help at r-project.org>
>Subject: RE: [R] Need some help with regular expression
>
>Hi Bert and all,
>
>Sorry I was too busy at work and didn't have much time to continue this
>until now.
>So I studied "?regexp" and I can understand your regular expression
>now:
>sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","\\1",x)
>
>But I also wanted to split up these results in 2 columns, so your
>previous
>command would give me this result:
>[1] "NMA -> STU" "STU -> REG" "-> STU"
>
>and I wanted to further split them up to show this:
>From	To
>NMA	STU
>STU	REG
>	STU
>
>I still don?t quite understand the backreferences, and how could I have
>2
>backreferences, one for the left side of the ?->? sign and one for the
>right
>side?
>
>So it seems like I need to apply the ?sub? function twice, similar how
>I
>used the ?strapply? function twice in my original post:
>strapply(strapply(a, "(file://w+ -> STU|STU -> file://w+)", c, backref
>= -1,
>perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl =
>TRUE)
>
>or maybe there would be a more simple way of using only 1 ?sub?
>function and
>2 backreferences?
>
>Also I?m not sure what do I do after I get the data? How could I
>represent
>the member type changes graphically? We need to analyze the behavior of
>switching from STU to another type or from another type to STU.
>Google Analytics has a nice chart under Behavior Flow, or Users Flow,
>and it
>looks like this:
><here was my picture from Google Analytics - it's from Behavior Flow or
>Users Flow showing flows from one category to another one and further
>to
>another one>
>
>
>
>Is there any graphical representation in R that is similar to this?
>
>Thanks a lot,
>Steven
>
>-----Original Message-----
>From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert
>Gunter
>Sent: Sunday, November 20, 2016 10:05 PM
>To: Aliz Csonka <mailto:lyzae.ro at gmail.com>
>Cc: R-help <mailto:r-help at r-project.org>
>Subject: Re: [R] Need some help with regular expression
>
>Although others may respond, I think you will do much better studying
>?regexp, which will answer all your questions. I believe the effort you
>will
>make figuring it out will pay dividends for your future R/regular
>expression
>usage that you cannot gain from my direct explanation.
>
>Good luck.
>
>Best,
>Bert
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>On Sun, Nov 20, 2016 at 6:40 PM, Steven Nagy <mailto:nstefi at gmail.com>
>wrote:
>> Thanks a lot Bert. That's amazing. I am very new to both R and
>regular 
>> expressions. I don't really understand the regular expression that
>you 
>> used below.
>> And looks like I don't even need any special library, like the 
>> "gsubfn" for the strapply function.
>> I was trying to use the regexr.com website to analyze your regular 
>> expression, but it doesn't seem to match any text there.
>> Can you explain me the regular expression that you used?
>> ".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*"
>> So the dot in the front means any character and the star after that 
>> means that it can repeat 0 or more times, right?
>> Then followed by a colon character ":" and a space, and what is the 
>> next star after that? It means that the sequence before that again
>can 
>> repeat 0 or more times?
>> And what are the double square brackets?
>> Is ":alnum:" specific to R? I don't think "regexr.com" understands 
>> that. Or maybe that site is for regular expressions in Javascript,
>and 
>> the syntax is different in R?
>>
>> Thank you,
>> Steven
>>
>> -----Original Message-----
>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> Sent: Sunday, November 20, 2016 2:15 PM
>> To: Steven Nagy <mailto:nstefi at gmail.com>
>> Cc: R-help <mailto:r-help at r-project.org>
>> Subject: Re: [R] Need some help with regular expression
>>
>> If I understand you correctly, I think you are making it more complex
>
>> than necessary. Using your example (thanks!!), the following should 
>> get you
>> started:
>>
>>
>>> x<- c("Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:? -> 1 ; CITY:
>>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN
>-> 
>>> ; MEMBER_STATUS:? -> N", "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1
>>> ->","Name.MEMBER_TYPE: -> STU")
>>>
>>> x
>> [1] "Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:? -> 1 ; CITY:
>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN ->
>
>> ;
>> MEMBER_STATUS:? -> N"
>>
>> [2] "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1 ->"
>> [3] "Name.MEMBER_TYPE: -> STU"
>>>
>>> sub(".*: *([[:alnum:]]* *-> *STU|STU *->
>*[[:alnum:]]*).*","file://1",x)
>> [1] "NMA -> STU" "STU -> REG" "-> STU"
>>
>>
>> I am sure that you can get things to the form you desire in one go 
>> with some fiddling of the above, but it was easier for me to write
>the 
>> regex to pick out the pieces you wanted and leave the rest to you.
>> Others may have slicker ways to do it, of course.
>>
>> HTH
>>
>> Cheers,
>> Bert
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming
>along 
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sat, Nov 19, 2016 at 8:06 PM, Steven Nagy
><mailto:nstefi at gmail.com>
>wrote:
>>> I tried out a regular expression on this website:
>>>
>>> http://regexr.com/3en1m
>>>
>>>
>>>
>>> So the input text is:
>>>
>>> "Name.MEMBER_TYPE:? -> STU"
>>>
>>>
>>>
>>> The regular expression is: ((?:\w+|\s) -> STU|STU -> (?:\w+|\s))
>>>
>>> And it returns:
>>>
>>> "? -> STU"
>>>
>>>
>>>
>>> but when I use in R, it doesn't return the same result:
>>>
>>> strapply(c, "((?:\\w+|\\s) -> STU|STU -> (?:\\w+|\\s))", c, backref
>= 
>>> -1, perl = TRUE)
>>>
>>> returns:
>>> "Name.MEMBER_TYPE: -> STU"
>>>
>>>
>>>
>>>
>>>
>>> Here is what I was trying to do:
>>>
>>>
>>>
>>> I need to extract some values from a log table, and I created a 
>>> regular expression that helps me with that.
>>>
>>> The log table has cells with values like:
>>>
>>> a = "Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:? -> 1 ; CITY:
>>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN
>-> 
>>> ; MEMBER_STATUS:? -> N"
>>>
>>> or
>>> b = "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1 ->"
>>>
>>> so I needed to extract the values that a STU member type is changing
>
>>> from and to, so I needed NMA, STU in the 1st case or STU, REG in the
>
>>> 2nd
>> case.
>>>
>>> I came up with this expression which worked in both cases:
>>>
>>> strapply(strapply(a, "(file://w+ -> STU|STU -> file://w+)", c,
>backref =
>-1, 
>>> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl =
>TRUE)
>>>
>>>
>>>
>>> But I had a 3rd case when the source member type was blank:
>>>
>>> c = "Name.MEMBER_TYPE: -> STU"
>>>
>>> and in that case it returned an error:
>>>
>>> strapply(strapply(c, "(file://w+ -> STU|STU -> file://w+)", c,
>backref =
>-1, 
>>> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl =
>TRUE)
>>>
>>> Error: is.character(x) is not TRUE
>>>
>>>
>>>
>>> I found that the error is because this returns NULL:
>>>
>>> strapply(c, "(file://w+ -> STU|STU -> file://w+)", c, backref = -1,
>perl
>= 
>>> TRUE)
>>>
>>>
>>>
>>>
>>>
>>> So I tried to modify the regular expression to match any word or 
>>> blank
>>> space:
>>>
>>> strapply(c, "((?:\\w+|\\s) -> STU|STU -> (?:\\w+|\\s))", c, backref
>= 
>>> -1, perl = TRUE)
>>>
>>>
>>>
>>> but this returned me the whole value of "c":
>>>
>>> "Name.MEMBER_TYPE:? -> STU"
>>>
>>> and I only needed "? -> STU" as it shows on the website regxr.com
>>>
>>>
>>>
>>> Is the result wrong on the regxr.com website or strapply returns the
>
>>> wrong result?
>>>
>>>
>>>
>>> Thanks,
>>>
>>> Steven
>>>
>>>
>>>???????? [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From macqueen1 at llnl.gov  Thu Dec 15 20:27:57 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 15 Dec 2016 19:27:57 +0000
Subject: [R] WaveletComp with as.POSIXct Showing Error on Date for:
 2000-01-01 Format
In-Reply-To: <CAEhkw2245_SumuC=1nQXEb4JcP0GNBZY9MeuckBJ00Smq58mWg@mail.gmail.com>
References: <CAEhkw2245_SumuC=1nQXEb4JcP0GNBZY9MeuckBJ00Smq58mWg@mail.gmail.com>
Message-ID: <2F639BFF-28AC-4817-B935-41CF507C4068@llnl.gov>

Your code is nearly unreadable, probably because you posted in HTML instead of plain text. Plain text is the standard expected on R-help.

The only apparent date/time conversion in your code is the use of as.POSIXct(). You are missing a closing quote mark after the date.

If I fix that, then on my system as.POSIXct() succeeds:

> seq(as.POSIXct("2002-01-01"), by = "hour", length.out = 5)
[1] "2002-01-01 00:00:00 PST" "2002-01-01 01:00:00 PST"
[3] "2002-01-01 02:00:00 PST" "2002-01-01 03:00:00 PST"
[5] "2002-01-01 04:00:00 PST"

Your warning (not error) messages refer to an unknown timezone. So check your timezone, for example:

> Sys.getenv('TZ')
[1] "US/Pacific"

I hope this helps.
-Don


On 12/13/16, 9:33 AM, "R-help on behalf of Muhammad Anees" <r-help-bounces at r-project.org on behalf of anec at aneconomist.com> wrote:

    Dear All,
    
    I tried to find an answer everywhere including stackoverflows and manuals
    but there is no specific solution that might have helped. Hence, I am sure
    you will bear with me for this first query.
    
    I am trying to replicate production of Wavelet Coherency using the
    following codes: I dont know why the two errors/warnings appear and my
    resultant figures dont show up the time as I use the format of Date as
    2000-01-01
    
    Code used is:
    
    > library(WaveletComp)> x<- API> y<- TFS> my.data = data.frame(x = x, y = y)> my.wc = analyze.coherency(my.data, my.pair = c("x","y"),+                           loess.span = 0,+                           dt = 1/24, dj = 1/100,+                           lowerPeriod = 1/2,+                           make.pval = T, n.sim = 10)> wc.image(my.wc, n.levels = 250,+          siglvl.contour = 0.1, siglvl.arrow = 0.05,+          legend.params = list(lab = "cross-wavelet power levels"))> wc.image(my.wc, n.levels = 250, color.key = "interval",+          siglvl.contour = 0.1, siglvl.arrow = 0.05, which.arrow.sig = "wt",+          legend.params = list(lab = "cross-wavelet power levels"))> wc.image(my.wc, which.image = "wc", n.levels = 250,+          siglvl.contour = 0.1, siglvl.arrow = 0.05,+          legend.params = list(lab = "wavelet coherence levels"))> my.date = seq(as.POSIXct("2002-01-01),+               by = "hour", length.out = 24*96)########################################
    ########################################
    
    
    Warning messages:1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
      unknown timezone '%F %T'2: In as.POSIXct.POSIXlt(x) : unknown
    timezone '%F %T'3: In strptime(x, f, tz = tz) : unknown timezone '%F
    %T'4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
      unknown timezone '%F %T'
    
    ########################################
    ########################################
    
    I would be happier to see a suggestion for removing this warning and
    get the results as the time axis showing Date as in the data on the
    figures of my output from above.
    
    Regards
    
    
    
    ------------------------------
    Muhammad Anees
    Assistant Professor,
    The Econometrician &
    Statistical Consultant @
    www.aneconomist.com
    
    	[[alternative HTML version deleted]]
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From dwinsemius at comcast.net  Thu Dec 15 21:29:47 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Dec 2016 12:29:47 -0800
Subject: [R] Need some help with regular expression
In-Reply-To: <001f01d256f2$d897ff40$89c7fdc0$@gmail.com>
References: <00a301d242e3$7d884e20$7898ea60$@gmail.com>
	<CAGxFJbRLyPgD0RJG9Y-ZG4qumPjp4UWi7h1iF4gm1kMYhXeh7g@mail.gmail.com>
	<001101d243a0$a91e4f90$fb5aeeb0$@gmail.com>
	<CAGxFJbTo9p-ixAKFZqqAqH7t_xPg1qtVHejFVQ_=ocr9rBfAKA@mail.gmail.com>
	<013901d254f3$ec3fdc80$c4bf9580$@gmail.com>
	<001f01d256f2$d897ff40$89c7fdc0$@gmail.com>
Message-ID: <558C4FA8-9F54-413B-B4DF-32E48168B0B2@comcast.net>


> On Dec 15, 2016, at 8:46 AM, Steven Nagy <nstefi at gmail.com> wrote:
> 
> I tried to send this email, but it didn't go through. I guess pictures are
> not allowed to send through HTML formatted emails?
> I'm re-sending it again without the picture, just comment there instead as
> placeholder.
> 
> Thanks,
> Steven
> 
> 
> From: Steven Nagy [mailto:nstefi at gmail.com] 
> Sent: Monday, December 12, 2016 10:50 PM
> To: 'Bert Gunter' <bgunter.4567 at gmail.com>
> Cc: 'R-help' <r-help at r-project.org>
> Subject: RE: [R] Need some help with regular expression
> 
> Hi Bert and all,
> 
> Sorry I was too busy at work and didn't have much time to continue this
> until now.
> So I studied "?regexp" and I can understand your regular expression now:
> sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","\\1",x)
> 
> But I also wanted to split up these results in 2 columns, so your previous
> command would give me this result:
> [1] "NMA -> STU" "STU -> REG" "-> STU"
> 
> and I wanted to further split them up to show this:
> From	To
> NMA	STU
> STU	REG
> 	STU

So one more step:

> strsplit( sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","\\1",x), split="-> ")

[[1]]
[1] "NMA " "STU" 

[[2]]
[1] "STU " "REG" 

[[3]]
[1] ""    "STU"

> 
Well, maybe 2:

> sapply(  strsplit( sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","\\1",x), split="-> "), "[",1 )
[1] "NMA " "STU " ""    
> sapply(  strsplit( sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","\\1",x), split="-> "), "[",2 )
[1] "STU" "REG" "STU"
> 


> I still don?t quite understand the backreferences, and how could I have 2
> backreferences, one for the left side of the ?->? sign and one for the right
> side?
> 
> So it seems like I need to apply the ?sub? function twice, similar how I
> used the ?strapply? function twice in my original post:
> strapply(strapply(a, "(file://w+ -> STU|STU -> file://w+)", c, backref = -1,
> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl = TRUE)
> 
> or maybe there would be a more simple way of using only 1 ?sub? function and
> 2 backreferences?
> 
> Also I?m not sure what do I do after I get the data? How could I represent
> the member type changes graphically? We need to analyze the behavior of
> switching from STU to another type or from another type to STU.
> Google Analytics has a nice chart under Behavior Flow, or Users Flow, and it
> looks like this:
> <here was my picture from Google Analytics - it's from Behavior Flow or
> Users Flow showing flows from one category to another one and further to
> another one>
> 
> 
> 
> Is there any graphical representation in R that is similar to this?
> 
> Thanks a lot,
> Steven
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
> Sent: Sunday, November 20, 2016 10:05 PM
> To: Aliz Csonka <mailto:lyzae.ro at gmail.com>
> Cc: R-help <mailto:r-help at r-project.org>
> Subject: Re: [R] Need some help with regular expression
> 
> Although others may respond, I think you will do much better studying
> ?regexp, which will answer all your questions. I believe the effort you will
> make figuring it out will pay dividends for your future R/regular expression
> usage that you cannot gain from my direct explanation.
> 
> Good luck.
> 
> Best,
> Bert
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sun, Nov 20, 2016 at 6:40 PM, Steven Nagy <mailto:nstefi at gmail.com>
> wrote:
>> Thanks a lot Bert. That's amazing. I am very new to both R and regular 
>> expressions. I don't really understand the regular expression that you 
>> used below.
>> And looks like I don't even need any special library, like the 
>> "gsubfn" for the strapply function.
>> I was trying to use the regexr.com website to analyze your regular 
>> expression, but it doesn't seem to match any text there.
>> Can you explain me the regular expression that you used?
>> ".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*"
>> So the dot in the front means any character and the star after that 
>> means that it can repeat 0 or more times, right?
>> Then followed by a colon character ":" and a space, and what is the 
>> next star after that? It means that the sequence before that again can 
>> repeat 0 or more times?
>> And what are the double square brackets?
>> Is ":alnum:" specific to R? I don't think "regexr.com" understands 
>> that. Or maybe that site is for regular expressions in Javascript, and 
>> the syntax is different in R?
>> 
>> Thank you,
>> Steven
>> 
>> -----Original Message-----
>> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
>> Sent: Sunday, November 20, 2016 2:15 PM
>> To: Steven Nagy <mailto:nstefi at gmail.com>
>> Cc: R-help <mailto:r-help at r-project.org>
>> Subject: Re: [R] Need some help with regular expression
>> 
>> If I understand you correctly, I think you are making it more complex 
>> than necessary. Using your example (thanks!!), the following should 
>> get you
>> started:
>> 
>> 
>>> x<- c("Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:  -> 1 ; CITY:
>>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN -> 
>>> ; MEMBER_STATUS:  -> N", "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1
>>> ->","Name.MEMBER_TYPE: -> STU")
>>> 
>>> x
>> [1] "Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:  -> 1 ; CITY:
>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN -> 
>> ;
>> MEMBER_STATUS:  -> N"
>> 
>> [2] "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1 ->"
>> [3] "Name.MEMBER_TYPE: -> STU"
>>> 
>>> sub(".*: *([[:alnum:]]* *-> *STU|STU *-> *[[:alnum:]]*).*","file://1",x)
>> [1] "NMA -> STU" "STU -> REG" "-> STU"
>> 
>> 
>> I am sure that you can get things to the form you desire in one go 
>> with some fiddling of the above, but it was easier for me to write the 
>> regex to pick out the pieces you wanted and leave the rest to you.
>> Others may have slicker ways to do it, of course.
>> 
>> HTH
>> 
>> Cheers,
>> Bert
>> 
>> 
>> Bert Gunter
>> 
>> "The trouble with having an open mind is that people keep coming along 
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>> 
>> 
>> On Sat, Nov 19, 2016 at 8:06 PM, Steven Nagy <mailto:nstefi at gmail.com>
> wrote:
>>> I tried out a regular expression on this website:
>>> 
>>> http://regexr.com/3en1m
>>> 
>>> 
>>> 
>>> So the input text is:
>>> 
>>> "Name.MEMBER_TYPE:  -> STU"
>>> 
>>> 
>>> 
>>> The regular expression is: ((?:\w+|\s) -> STU|STU -> (?:\w+|\s))
>>> 
>>> And it returns:
>>> 
>>> "  -> STU"
>>> 
>>> 
>>> 
>>> but when I use in R, it doesn't return the same result:
>>> 
>>> strapply(c, "((?:\\w+|\\s) -> STU|STU -> (?:\\w+|\\s))", c, backref = 
>>> -1, perl = TRUE)
>>> 
>>> returns:
>>> "Name.MEMBER_TYPE: -> STU"
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Here is what I was trying to do:
>>> 
>>> 
>>> 
>>> I need to extract some values from a log table, and I created a 
>>> regular expression that helps me with that.
>>> 
>>> The log table has cells with values like:
>>> 
>>> a = "Name.MEMBER_TYPE: NMA -> STU ; CATEGORY:  -> 1 ; CITY:
>>> MISSISSAUGA -> Mississauga ; ZIP: L5N1H9 -> L5N 1H9 ; COUNTRY: CAN -> 
>>> ; MEMBER_STATUS:  -> N"
>>> 
>>> or
>>> b = "Name.MEMBER_TYPE: STU -> REG ; CATEGORY: 1 ->"
>>> 
>>> so I needed to extract the values that a STU member type is changing 
>>> from and to, so I needed NMA, STU in the 1st case or STU, REG in the 
>>> 2nd
>> case.
>>> 
>>> I came up with this expression which worked in both cases:
>>> 
>>> strapply(strapply(a, "(file://w+ -> STU|STU -> file://w+)", c, backref =
> -1, 
>>> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl = TRUE)
>>> 
>>> 
>>> 
>>> But I had a 3rd case when the source member type was blank:
>>> 
>>> c = "Name.MEMBER_TYPE: -> STU"
>>> 
>>> and in that case it returned an error:
>>> 
>>> strapply(strapply(c, "(file://w+ -> STU|STU -> file://w+)", c, backref =
> -1, 
>>> perl = TRUE), "(file://w+) -> (file://w+)", c, backref = -2, perl = TRUE)
>>> 
>>> Error: is.character(x) is not TRUE
>>> 
>>> 
>>> 
>>> I found that the error is because this returns NULL:
>>> 
>>> strapply(c, "(file://w+ -> STU|STU -> file://w+)", c, backref = -1, perl
> = 
>>> TRUE)
>>> 
>>> 
>>> 
>>> 
>>> 
>>> So I tried to modify the regular expression to match any word or 
>>> blank
>>> space:
>>> 
>>> strapply(c, "((?:\\w+|\\s) -> STU|STU -> (?:\\w+|\\s))", c, backref = 
>>> -1, perl = TRUE)
>>> 
>>> 
>>> 
>>> but this returned me the whole value of "c":
>>> 
>>> "Name.MEMBER_TYPE:  -> STU"
>>> 
>>> and I only needed "  -> STU" as it shows on the website regxr.com
>>> 
>>> 
>>> 
>>> Is the result wrong on the regxr.com website or strapply returns the 
>>> wrong result?
>>> 
>>> 
>>> 
>>> Thanks,
>>> 
>>> Steven
>>> 
>>> 
>>>          [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From drjimlemon at gmail.com  Thu Dec 15 22:59:27 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 16 Dec 2016 08:59:27 +1100
Subject: [R] Merging two columns of unequal length
In-Reply-To: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
References: <YQBPR01MB011360B9FA0E35D548CDA117D9980@YQBPR01MB0113.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <CA+8X3fVOsGX9FwtNsHq8XBQQP1fxazAc9_XgRtCAtM9y-rakgg@mail.gmail.com>

Hi Bailey,
I may be misunderstanding what you are doing as I can't work out how
you get unequal column lengths, but this may help:

myval<-matrix(sample(1:365,740,TRUE),ncol=74)
mydata<-as.data.frame(cbind(1950:1959,myval))
lakenames<-paste(rep(LETTERS[1:26],length.out=74),
 rev(rep(letters[1:25],length.out=74)),
 rep(letters[1:24],length.out=74),sep="")
names(mydata)<-c("Year",lakenames)
res<-vector("list",74)
for (i in 1:74){
 thisval<-mydata[,i+1]
 lake.lm<-lm(thisval ~ Year,mydata)
 res[[i]]<-residuals(lake.lm)
}
# this will cause an error with as.data.frame
res[[20]]<-res[[20]][-1]
# pad the short column with NA
res<-lapply(res,function(x,length.out) x[1:length.out],10)
res.df<-as.data.frame(res)
names(res.df)<-lakenames
print(res.df)

Jim


On Tue, Dec 13, 2016 at 10:41 AM, Bailey Hewitt <bailster at hotmail.com> wrote:
> Dear R Help,
>
>
> I am trying to put together two columns of unequal length in a data frame. Unfortunately, so far I have been unsuccessful in the functions I have tried (such as cbind). The code I am currently using is : (I have highlighted the code that is not working)
>
>
> y<- mydata[,2:75]
>
> year <- mydata$Year
>
> res <- data.frame()
>
> for (i in 1:74){
>
>   y.val <- y[,i]
>
>   lake.lm= lm(y.val ~ year)
>
>   lake.res=residuals(lake.lm)
>
>   new.res <- data.frame(lake.res=lake.res)
>
>   colnames(new.res) <- colnames(y)[i]
>
> #cbind doesn't work because of the unequal lengths of my data columns
>
>   res <- cbind(res, new.res)
>
>   print(res)
>
> }
>
>
> mydata is a csv file with "Year" from 1950 on as my first column and then each proceeding column has a lake name and a day of year (single number) in each row.
>
>
> Please let me know if there is any more information I can provide as I am new to emailing in this list. Thank you for your time!
>
>
> Bailey Hewitt
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Dec 15 23:09:42 2016
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 15 Dec 2016 15:09:42 -0700
Subject: [R] how to show a plot without overlaying the text on top of
 the another text?
In-Reply-To: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
References: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
Message-ID: <CAFEqCdx9h1VP6s=fH7Q=yuNN=OV6mtwA7mO+=JGNNsY+PUf4iw@mail.gmail.com>

Some tools that might help include spread.labels from the plotrix
package, spread.labs from the TeachingDemos package, and
dynIdentify/TkIdentify from the TeachingDemos package.

On Tue, Dec 13, 2016 at 4:37 PM, Marna Wagley <marna.wagley at gmail.com> wrote:
> Hi R user,
> I have created using metaNMDS (Nonmetirc Multidimensional Scaling, MDS) to
> show species composition but some of the species are concentrated at some
> of the sites so that the name of the species are overlaid and it was
> almost impossible to read the species name in the figure. I was wondering how
> we can show the plot without overlaying the text on top of another.
> I used the following to create the plot. would you mind to suggest me?
>
> comm.bc.mds <- metaMDS(dat, dist = "bray")
> ordiplot(comm.bc.mds, display = "sites", type = "text")
> ordipointlabel(comm.bc.mds,font = c(1, 1), cex = c(0.5, 0.3))
>
> Thanks
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From drjimlemon at gmail.com  Thu Dec 15 23:27:08 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 16 Dec 2016 09:27:08 +1100
Subject: [R] how to show a plot without overlaying the text on top of
 the another text?
In-Reply-To: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
References: <CAMwU6B0U2TYmZ5GEMr9BX-VTg6avoxNz=L5xzGKUuUr5rBH_Sg@mail.gmail.com>
Message-ID: <CA+8X3fWKn5+XrRKgB5TkV9P+3Jxz1nrRvXaOvADZENpQv9Y-qA@mail.gmail.com>

Hi Marna,
After a bit of experimenting I came up with the following function
that "flags" each point to be labeled an allows the operator to
manually place the label for that point:

placeLabels<-function(x,y,labels,pointer=TRUE,cex=1,labelcol=par("fg"),
 labelbg="white",border=par("fg"),pointercol=par("fg"),
 pch=1,col=1,bg="white",flagcol="red") {

 nlabels<-length(labels)
 if(length(labelcol) < nlabels) labelcol<-rep(labelcol,length.out=nlabels)
 if(length(labelbg) < nlabels) labelbg<-rep(labelbg,length.out=nlabels)
 if(length(border) < nlabels) border<-rep(border,length.out=nlabels)
 if(length(pointercol) < nlabels) pointercol<-rep(pointercol,length.out=nlabels)
 if(length(pch) < nlabels) pch<-rep(pch,length.out=nlabels)
 if(length(col) < nlabels) col<-rep(col,length.out=nlabels)
 if(length(bg) < nlabels) bg<-rep(bg,length.out=nlabels)
 for(i in 1:nlabels) {
  points(x[i],y[i],pch=19,col=flagcol)
  labelxy<-locator(1)
  if(pointer)
   segments(x[i],y[i],labelxy$x,labelxy$y,col=pointercol[i])
  boxed.labels(labelxy$x,labelxy$y,labels[i],
   col=labelcol[i],bg=labelbg[i],border=border[i])
  points(rep(x[i],2),rep(y[i],2),pch=c(19,pch[i]),
   col=c("white",col[i]),bg=c(NA,bg[i]))
 }
}
x<-rnorm(10)
y<-rnorm(10)
plot(x,y)
library(plotrix)
placeLabels(x,y,LETTERS[1:10],flagcol="purple")

Jim


On Wed, Dec 14, 2016 at 10:37 AM, Marna Wagley <marna.wagley at gmail.com> wrote:
> Hi R user,
> I have created using metaNMDS (Nonmetirc Multidimensional Scaling, MDS) to
> show species composition but some of the species are concentrated at some
> of the sites so that the name of the species are overlaid and it was
> almost impossible to read the species name in the figure. I was wondering how
> we can show the plot without overlaying the text on top of another.
> I used the following to create the plot. would you mind to suggest me?
>
> comm.bc.mds <- metaMDS(dat, dist = "bray")
> ordiplot(comm.bc.mds, display = "sites", type = "text")
> ordipointlabel(comm.bc.mds,font = c(1, 1), cex = c(0.5, 0.3))
>
> Thanks
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Fri Dec 16 00:49:22 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 15 Dec 2016 23:49:22 +0000
Subject: [R] data manipulation
In-Reply-To: <1768303695.2867148.1481716595402@mail.yahoo.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
Message-ID: <919819882.4137998.1481845762609@mail.yahoo.com>

It downloaded a file for me earlier but I am not getting the 404 error and I did not bother to save the download.? Shrug.
 

    On Wednesday, December 14, 2016 6:57 AM, John Kane via R-help <r-help at r-project.org> wrote:
 

 xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly 

? ? On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
 

 Hi,

 

I couldn't access to data file about PSCoperwait by
http://massey.ac.nz/~pscoperwait/ts/cbe.dat.

 

Looking forward to hearing from you,


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Fri Dec 16 00:50:56 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Thu, 15 Dec 2016 23:50:56 +0000
Subject: [R] data manipulation
In-Reply-To: <919819882.4137998.1481845762609@mail.yahoo.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<919819882.4137998.1481845762609@mail.yahoo.com>
Message-ID: <1144757768.4142641.1481845857004@mail.yahoo.com>

That should read "now" instead of "not"
 

    On Thursday, December 15, 2016 6:49 PM, John Kane <jrkrideau at yahoo.ca> wrote:
 

 It downloaded a file for me earlier but I am not getting the 404 error and I did not bother to save the download.? Shrug.
 

    On Wednesday, December 14, 2016 6:57 AM, John Kane via R-help <r-help at r-project.org> wrote:
 

 xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat")
gives me something. Since we have no idea of what you are doing I don't know if the data has downloaded correctly 

? ? On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian <farshad.fathian at gmail.com> wrote:
 

 Hi,

 

I couldn't access to data file about PSCoperwait by
http://massey.ac.nz/~pscoperwait/ts/cbe.dat.

 

Looking forward to hearing from you,


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

   

   
	[[alternative HTML version deleted]]


From jrkrideau at yahoo.ca  Fri Dec 16 01:22:53 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Fri, 16 Dec 2016 00:22:53 +0000 (UTC)
Subject: [R] ggplot aestetics: beginner question - I am lost in endless
 possibilites
In-Reply-To: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>
References: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>
Message-ID: <1184500679.4125003.1481847773788@mail.yahoo.com>

I cannot see how you get that code to run. It certainly does not on my machine and some of the manipulations don't make any sense as far as I can see.
I changed variable and data.frame names so I would not have to type so much and read in the data with the "stringsAsFactors = FALSE" option.
I then parsed the dates (called 'known' in my data.frame) using the package "lubridate"
dat1$mydate <- dmy(dat1$mydate)

My resulting data.frame called dat1 is presented in dput() format below.
Do I understand you correctly in that you want the NA values plotted as "white" and the outline on the tiles in black?
In any case as my first steps here is a revised program to just get the tileswith no effort to get the outline or change the colours of the fill.



 

    On Thursday, December 15, 2016 4:24 AM, Dagmar <Ramgad82 at gmx.net> wrote:
 

 # Dear all,
# I hope someone can help me with this. I am so lost and can't find a 
solution even though I spent hours on searching for a solution of that 
tiny problem.
# Maybe someone of you could give me hint?
#This is my string:
exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie", 
"Leon","Leon","Leon"),
? ? ? ? ? ? ? recordedTime=c("03.01.2011","04.01.2011","05.01.2011",
"04.01.2011","05.01.2011","06.01.2011"),
? ? ? ? ? ? ? ? knownstate =c("breeding","moulting","moulting",
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "breeding","breeding",NA))
exdatframe

exdatframeT <- as.POSIXct 
(strptime(as.character(exdatframe$recordedTime),"%d.%m.%Y"))
exdatframeT
exdatframe2 <- cbind(exdatframe, exdatframeT)
exdatframe2$recordedTime <-NULL
exdatframe2
str(datframe)

library(ggplot2)
ggplot(exdatframe2)+geom_tile(aes(x=exdatframeT,y=Name,fill=knownstate), 
height=0.5)

# Now all I want is:
# 1) a black outline around the bars. Adding colour="black" like I have 
found elsewere on the internet doesn't work
# 2) change the colours: E.g. I want white for NAs. I can't find a 
command to describe my wishes.

#?

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Fri Dec 16 01:37:43 2016
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 16 Dec 2016 11:37:43 +1100
Subject: [R] ggplot aestetics: beginner question - I am lost in endless
	possibilites
In-Reply-To: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>
References: <e012f203-ae4c-8db4-0efb-5e4a743f2b6c@gmx.net>
Message-ID: <CABdHhvFW0NGnhpkxjf4d2HzH4uy-xXYYUj-SwNJTm6+RptgwpQ@mail.gmail.com>

You are going to find your life much easier if you:

* Organise your code so it's easier to read
* Use a consistent naming scheme for your variables
* Learn a bit more about how to modify variables succintly

Here's my rewriting of your script to make it easier to see what's going on.

library(tidyverse)

df <- tibble(
  name = c("Ernie","Ernie","Ernie", "Leon","Leon","Leon"),
  recorded_time = c("03.01.2011","04.01.2011","05.01.2011",
"04.01.2011","05.01.2011","06.01.2011"),
  known_state = c("breeding","moulting","moulting", "breeding","breeding",NA)
)
df$recorded_time <- lubridate::dmy(df$recorded_time)

ggplot(df) +
  geom_tile(
    aes(recorded_time, name, fill = known_state),
    colour = "black",
    height = 0.5
  ) +
  scale_fill_discrete(na.value = "white")

Hadley

On Thu, Dec 15, 2016 at 8:22 PM, Dagmar <Ramgad82 at gmx.net> wrote:
> # Dear all,
> # I hope someone can help me with this. I am so lost and can't find a
> solution even though I spent hours on searching for a solution of that tiny
> problem.
> # Maybe someone of you could give me hint?
> #This is my string:
> exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie",
> "Leon","Leon","Leon"),
>               recordedTime=c("03.01.2011","04.01.2011","05.01.2011",
> "04.01.2011","05.01.2011","06.01.2011"),
>                knownstate =c("breeding","moulting","moulting",
>                              "breeding","breeding",NA))
> exdatframe
>
> exdatframeT <- as.POSIXct
> (strptime(as.character(exdatframe$recordedTime),"%d.%m.%Y"))
> exdatframeT
> exdatframe2 <- cbind(exdatframe, exdatframeT)
> exdatframe2$recordedTime <-NULL
> exdatframe2
> str(datframe)
>
> library(ggplot2)
> ggplot(exdatframe2)+geom_tile(aes(x=exdatframeT,y=Name,fill=knownstate),
> height=0.5)
>
> # Now all I want is:
> # 1) a black outline around the bars. Adding colour="black" like I have
> found elsewere on the internet doesn't work
> # 2) change the colours: E.g. I want white for NAs. I can't find a command
> to describe my wishes.
>
> #?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://hadley.nz


From jatin.kala.jk at gmail.com  Fri Dec 16 07:03:36 2016
From: jatin.kala.jk at gmail.com (Jatin Kala)
Date: Fri, 16 Dec 2016 14:03:36 +0800
Subject: [R] help using ggplot for contour plot
Message-ID: <27c381b0-75e4-6a03-805f-e2e92c4bda5b@gmail.com>

Hi R community,
I am trying to do a contour plot of (longitude, latitude, concentration).
This is easy enough using filled.contour.
However, i am trying to do the same contour plot using ggplot, and 
overlaying the plot on google-map.
The script and data being read is attached.
  test_filled_contour_plot.png is what contour.filled gives me.
GF_test.png is the output from using ggplot. Something is going wrong, 
but i can't figure out what, and it's doing my head-in....
Any help would be greatly appreciated.
Cheers,
Jatin

-------------- next part --------------

rm(list = ls())
library(ggmap)
library(rgdal)

#########################
load("ALL_HOURLY_NOx_Processed")
# need to convert lat, lon, concnetration into a data-frame before plotting
# convert 2D conc array into 1d vector
utmcoor<-SpatialPoints(cbind(x,y), proj4string=CRS("+proj=utm +zone=50 +ellps=WGS84 +south"))
longlatcoor<-spTransform(utmcoor,CRS("+proj=longlat"))
lon <-longlatcoor at coords[,1]
lat <-longlatcoor at coords[,2]

# quick plot using filled.contour so we know what the plot should look like
png("test_filled_countour_plot.png")
filled.contour(x=lon,y=lat,max_conc)
dev.off()

max_conc_vector <- as.vector(max_conc)
# make equivalent 1d lat and lon arrays
dim_array <- dim(max_conc)
lat2d <- matrix(data=NA,nrow=dim_array[1],ncol=dim_array[2])
lon2d <- lat2d
for (i in 1:dim_array[1]) {
  lon2d[,i] <- lon
}
for (i in 1:dim_array[2]) {
  lat2d[i,] <- lat
}

# this does a google map plot only
Freo = get_map(location = c(min(lon), min(lat), max(lon), max(lat)), source = "osm", zoom = 12)

# now make data frame, lat, lon, concentration
lat1d <- as.vector(lat2d)
lon1d <- as.vector(lon2d)
data_plot <- data.frame(lon1d,lat1d,max_conc_vector)

############
# Plotting concs on map
## Data_plot is not the actual data I want, my concs need to be in a data frame in order to use code below
FreoMap <- ggmap(Freo, extent = "panel" , legend = "topright")
#FreoMap + stat_density2d(aes(x = lon1d, y = lat1d, fill = max_conc_vector, alpha = 0.5),size = 2, bins = 6, data = data_plot, geom = "polygon")
FreoMap + stat_density2d(aes(x = lon1d, y = lat1d, fill = max_conc_vector, alpha = 0.5), data = data_plot, geom = "polygon")
ggsave("GF_test.png")
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GF_test.png
Type: image/png
Size: 1428218 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161216/3515d374/attachment-0002.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: test_filled_countour_plot.png
Type: image/png
Size: 58183 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161216/3515d374/attachment-0003.png>

From dan.abner99 at gmail.com  Fri Dec 16 15:45:15 2016
From: dan.abner99 at gmail.com (Dan Abner)
Date: Fri, 16 Dec 2016 09:45:15 -0500
Subject: [R] Generating Heavy and Light Tailed Normal Variates
Message-ID: <CAPRGo-nuKvAGuSAPpNcEoo+c1xTSEejhHVvz0awV37hnXA=3bA@mail.gmail.com>

Hi all,

I need to generate heavy and light-tailed normal variates separately for
demonstration purposes. I figure for the heavy-tailed, I will just generate
variates from a t distribution with low degrees of freedom. How does one
generate light-tailed normal variates?

Thanks,

Dan

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Dec 16 16:15:25 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 16 Dec 2016 07:15:25 -0800
Subject: [R] Generating Heavy and Light Tailed Normal Variates
In-Reply-To: <CAPRGo-nuKvAGuSAPpNcEoo+c1xTSEejhHVvz0awV37hnXA=3bA@mail.gmail.com>
References: <CAPRGo-nuKvAGuSAPpNcEoo+c1xTSEejhHVvz0awV37hnXA=3bA@mail.gmail.com>
Message-ID: <CAGxFJbQAhwWVJJeS1ismgyExJx83H07zTtiQbkZiKN4e7rczmw@mail.gmail.com>

There is no such thing as "heavy and light tailed normal variates."
The normal distribution is normal, period.

Ask this on stats.stackexchange.com. It is about statistics not R, and
a sensible answer heavily depends on the context you have in mind.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 16, 2016 at 6:45 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> I need to generate heavy and light-tailed normal variates separately for
> demonstration purposes. I figure for the heavy-tailed, I will just generate
> variates from a t distribution with low degrees of freedom. How does one
> generate light-tailed normal variates?
>
> Thanks,
>
> Dan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dan.abner99 at gmail.com  Fri Dec 16 17:09:31 2016
From: dan.abner99 at gmail.com (Dan Abner)
Date: Fri, 16 Dec 2016 11:09:31 -0500
Subject: [R] Generating Heavy and Light Tailed Normal Variates
In-Reply-To: <CAGxFJbQAhwWVJJeS1ismgyExJx83H07zTtiQbkZiKN4e7rczmw@mail.gmail.com>
References: <CAPRGo-nuKvAGuSAPpNcEoo+c1xTSEejhHVvz0awV37hnXA=3bA@mail.gmail.com>
	<CAGxFJbQAhwWVJJeS1ismgyExJx83H07zTtiQbkZiKN4e7rczmw@mail.gmail.com>
Message-ID: <CAPRGo-kLUFa3P0NXNXyP6_qdbZnVj8U-1HAdqJCYDp69zGtOLA@mail.gmail.com>

Hi Bert,

Thank you for the response. Let me re-phrase:

What is the most efficient way to generate variates from a unimodal
symmetric distribution that are leptokurtic or platykurtic in R? There does
not appear to be a kurtosis parameter for rnorm().

Thanks all,

Dan

On Fri, Dec 16, 2016 at 10:15 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> There is no such thing as "heavy and light tailed normal variates."
> The normal distribution is normal, period.
>
> Ask this on stats.stackexchange.com. It is about statistics not R, and
> a sensible answer heavily depends on the context you have in mind.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Fri, Dec 16, 2016 at 6:45 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> > Hi all,
> >
> > I need to generate heavy and light-tailed normal variates separately for
> > demonstration purposes. I figure for the heavy-tailed, I will just
> generate
> > variates from a t distribution with low degrees of freedom. How does one
> > generate light-tailed normal variates?
> >
> > Thanks,
> >
> > Dan
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Dec 16 17:20:27 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 16 Dec 2016 08:20:27 -0800
Subject: [R] Generating Heavy and Light Tailed Normal Variates
In-Reply-To: <CAPRGo-kLUFa3P0NXNXyP6_qdbZnVj8U-1HAdqJCYDp69zGtOLA@mail.gmail.com>
References: <CAPRGo-nuKvAGuSAPpNcEoo+c1xTSEejhHVvz0awV37hnXA=3bA@mail.gmail.com>
	<CAGxFJbQAhwWVJJeS1ismgyExJx83H07zTtiQbkZiKN4e7rczmw@mail.gmail.com>
	<CAPRGo-kLUFa3P0NXNXyP6_qdbZnVj8U-1HAdqJCYDp69zGtOLA@mail.gmail.com>
Message-ID: <CAGxFJbQTeenm20vOHr8Hs1P4=4t_rRXxUDpYawPVokOuoZrJxw@mail.gmail.com>

Sorry, but you need to do some studying of statistical theory. The
normal/Gaussian distribution has a fixed kurtosis of 3.0. **There is
no kurtosis parameter.**

Again, this is not the place for such discussions.

-- Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 16, 2016 at 8:09 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi Bert,
>
> Thank you for the response. Let me re-phrase:
>
> What is the most efficient way to generate variates from a unimodal
> symmetric distribution that are leptokurtic or platykurtic in R? There does
> not appear to be a kurtosis parameter for rnorm().
>
> Thanks all,
>
> Dan
>
> On Fri, Dec 16, 2016 at 10:15 AM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> There is no such thing as "heavy and light tailed normal variates."
>> The normal distribution is normal, period.
>>
>> Ask this on stats.stackexchange.com. It is about statistics not R, and
>> a sensible answer heavily depends on the context you have in mind.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Fri, Dec 16, 2016 at 6:45 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
>> > Hi all,
>> >
>> > I need to generate heavy and light-tailed normal variates separately for
>> > demonstration purposes. I figure for the heavy-tailed, I will just
>> > generate
>> > variates from a t distribution with low degrees of freedom. How does one
>> > generate light-tailed normal variates?
>> >
>> > Thanks,
>> >
>> > Dan
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From abouelmakarim1962 at gmail.com  Fri Dec 16 15:33:21 2016
From: abouelmakarim1962 at gmail.com (AbouEl-Makarim Aboueissa)
Date: Fri, 16 Dec 2016 09:33:21 -0500
Subject: [R] =?utf-8?q?install_the_Bioconductor_package_=E2=80=9CyeastExpD?=
	=?utf-8?b?YXRh4oCd?=
Message-ID: <CAE9stmdnPi=2gpS1ET-Nk-aULnXZ_w16YKOWEO_58caTeNSUXQ@mail.gmail.com>

Dear All:

I am trying to install the Bioconductor package ?yeastExpData?. By the end
I got an error message, please see below. I am not sure what is wrong.


> source("http://bioconductor.org/biocLite.R")
Bioconductor version 3.0 (BiocInstaller 1.16.5), ?biocLite for help
A new version of Bioconductor is available after installing the most recent
  version of R; see http://bioconductor.org/install
> biocLite("yeastExpData")
BioC_mirror: http://bioconductor.org
Using Bioconductor version 3.0 (BiocInstaller 1.16.5), R version 3.1.2.
Installing package(s) 'yeastExpData'
also installing the dependency ?graph?

trying URL '
http://bioconductor.org/packages/3.0/bioc/bin/windows/contrib/3.1/graph_1.44.1.zip
'
Content type 'application/zip' length 2746668 bytes (2.6 Mb)
opened URL
downloaded 2.6 Mb

trying URL '
http://bioconductor.org/packages/3.0/data/experiment/bin/windows/contrib/3.1/yeastExpData_0.11.1.zip
'
Content type 'application/zip' length 1936545 bytes (1.8 Mb)
opened URL
downloaded 1.8 Mb

package ?graph? successfully unpacked and MD5 sums checked
package ?yeastExpData? successfully unpacked and MD5 sums checked

The downloaded binary packages are in

C:\Users\aaboueissa\AppData\Local\Temp\RtmpYNOhi3\downloaded_packages
Old packages: 'boot', 'class', 'cluster', 'codetools', 'foreign',
'KernSmooth',
  'lattice', 'MASS', 'Matrix', 'mgcv', 'nlme', 'nnet', 'rpart', 'spatial',
  'survival'
*Update all/some/none? [a/s/n]: a*
*Warning in install.packages(update[instlib == l, "Package"], l, contriburl
= contriburl,  :*
*  'lib = "C:/Program Files/R/R-3.1.2/library"' is not writable*
*Error in install.packages(update[instlib == l, "Package"], l, contriburl =
contriburl,  : *
*  unable to install packages*
> library("yeastExpData")
Loading required package: graph
>



with thanks
abou

-- 
______________________
AbouEl-Makarim Aboueissa, PhD
University of Southern Maine
Department of Mathematics and Statistics

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Dec 16 18:08:31 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 16 Dec 2016 09:08:31 -0800
Subject: [R]
	=?utf-8?q?install_the_Bioconductor_package_=E2=80=9CyeastExpD?=
	=?utf-8?b?YXRh4oCd?=
In-Reply-To: <CAE9stmdnPi=2gpS1ET-Nk-aULnXZ_w16YKOWEO_58caTeNSUXQ@mail.gmail.com>
References: <CAE9stmdnPi=2gpS1ET-Nk-aULnXZ_w16YKOWEO_58caTeNSUXQ@mail.gmail.com>
Message-ID: <CAGxFJbSchxWFH9bwGSgF_+K44dTZaH=vEDtr9gqZws7WaTisBA@mail.gmail.com>

It looks like a permissions problem. You might want to check with your
local IT support.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Fri, Dec 16, 2016 at 6:33 AM, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
> Dear All:
>
> I am trying to install the Bioconductor package ?yeastExpData?. By the end
> I got an error message, please see below. I am not sure what is wrong.
>
>
>> source("http://bioconductor.org/biocLite.R")
> Bioconductor version 3.0 (BiocInstaller 1.16.5), ?biocLite for help
> A new version of Bioconductor is available after installing the most recent
>   version of R; see http://bioconductor.org/install
>> biocLite("yeastExpData")
> BioC_mirror: http://bioconductor.org
> Using Bioconductor version 3.0 (BiocInstaller 1.16.5), R version 3.1.2.
> Installing package(s) 'yeastExpData'
> also installing the dependency ?graph?
>
> trying URL '
> http://bioconductor.org/packages/3.0/bioc/bin/windows/contrib/3.1/graph_1.44.1.zip
> '
> Content type 'application/zip' length 2746668 bytes (2.6 Mb)
> opened URL
> downloaded 2.6 Mb
>
> trying URL '
> http://bioconductor.org/packages/3.0/data/experiment/bin/windows/contrib/3.1/yeastExpData_0.11.1.zip
> '
> Content type 'application/zip' length 1936545 bytes (1.8 Mb)
> opened URL
> downloaded 1.8 Mb
>
> package ?graph? successfully unpacked and MD5 sums checked
> package ?yeastExpData? successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>
> C:\Users\aaboueissa\AppData\Local\Temp\RtmpYNOhi3\downloaded_packages
> Old packages: 'boot', 'class', 'cluster', 'codetools', 'foreign',
> 'KernSmooth',
>   'lattice', 'MASS', 'Matrix', 'mgcv', 'nlme', 'nnet', 'rpart', 'spatial',
>   'survival'
> *Update all/some/none? [a/s/n]: a*
> *Warning in install.packages(update[instlib == l, "Package"], l, contriburl
> = contriburl,  :*
> *  'lib = "C:/Program Files/R/R-3.1.2/library"' is not writable*
> *Error in install.packages(update[instlib == l, "Package"], l, contriburl =
> contriburl,  : *
> *  unable to install packages*
>> library("yeastExpData")
> Loading required package: graph
>>
>
>
>
> with thanks
> abou
>
> --
> ______________________
> AbouEl-Makarim Aboueissa, PhD
> University of Southern Maine
> Department of Mathematics and Statistics
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From yungchihlai at gmail.com  Fri Dec 16 20:19:03 2016
From: yungchihlai at gmail.com (Yung-Chih Lai)
Date: Fri, 16 Dec 2016 11:19:03 -0800
Subject: [R] How to scale circle sizes in VennDiagram using draw.triple.venn
Message-ID: <CAB11ZD6_=jL09SumfgCYEgm-cHD2Zz3DZuDkLhA1TFn17oiC2Q@mail.gmail.com>

Hi,


The below is the command I used to create a Venn diagram with three sets.
However, the three circle sizes are the same. Could you show me how to
adjust the circle size based on the area size? Many thanks.

grid.newpage()

draw.triple.venn(area1 = 9737, area2 = 13329, area3 = 6300, n12 = 8612, n23
= 6176, n13 = 5781, n123 = 5748, category = c("G8_13", "G8_14", "G8_15"),
lty = "blank", fill = c("pink", "light blue", "orange"))


Best,


Gary

	[[alternative HTML version deleted]]


From btyner at gmail.com  Sat Dec 17 00:06:12 2016
From: btyner at gmail.com (Benjamin Tyner)
Date: Fri, 16 Dec 2016 18:06:12 -0500
Subject: [R] modify the imported version of a function
Message-ID: <ba28b839-ea77-e4be-f9f0-4f7b45e387b0@gmail.com>

Hi

I saw on the assignInNamespace help page, that it changes "the copy in 
the namespace, but not any copies already exported from the namespace, 
in particular an object of that name in the package (if already 
attached) and any copies already imported into other namespaces."

So now I'm wondering, whether there is a way to modify such copies 
already imported into other namespaces? For a concrete example, consider 
the lint package (now archived on CRAN) which includes a function 
check_pattern, which calls stringr:::perl, which has been deprecated in 
newer versions:

    > stringr:::perl
    function (pattern)
    {
        message("perl is deprecated. Please use regexp instead")
        regex(pattern)
    }
    <environment: namespace:stringr>

so, what if I wanted to directly replace stringr:::perl with 
stringr:::regex, in such a way that lint::check_pattern sees the 
replacement? Is there a way, preferably without having to attach stringr 
to the search path?

(I'm mostly just interested in learning about how namespace imports 
actually work; of course in this toy example one could use 
suppressMessages to hide that deprecation message).

Regards
Ben


From ulrik.stervbo at gmail.com  Sat Dec 17 01:09:03 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Sat, 17 Dec 2016 00:09:03 +0000
Subject: [R] How to scale circle sizes in VennDiagram using
	draw.triple.venn
In-Reply-To: <CAB11ZD6_=jL09SumfgCYEgm-cHD2Zz3DZuDkLhA1TFn17oiC2Q@mail.gmail.com>
References: <CAB11ZD6_=jL09SumfgCYEgm-cHD2Zz3DZuDkLhA1TFn17oiC2Q@mail.gmail.com>
Message-ID: <CAKVAULMzJgep+QQ5YVwuBwcPX8ky_uWsUsY9D4RafR8mQBk5gg@mail.gmail.com>

I usually use the package Vennerable for all my Venn needs. It also has the
option to draw weighted diagrams.

HTH
Ulrik

Yung-Chih Lai <yungchihlai at gmail.com> schrieb am Fr., 16. Dez. 2016, 21:40:

> Hi,
>
>
> The below is the command I used to create a Venn diagram with three sets.
> However, the three circle sizes are the same. Could you show me how to
> adjust the circle size based on the area size? Many thanks.
>
> grid.newpage()
>
> draw.triple.venn(area1 = 9737, area2 = 13329, area3 = 6300, n12 = 8612, n23
> = 6176, n13 = 5781, n123 = 5748, category = c("G8_13", "G8_14", "G8_15"),
> lty = "blank", fill = c("pink", "light blue", "orange"))
>
>
> Best,
>
>
> Gary
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From venkynov10 at gmail.com  Sat Dec 17 07:27:45 2016
From: venkynov10 at gmail.com (Venky)
Date: Sat, 17 Dec 2016 11:57:45 +0530
Subject: [R] How to do forecast for the history data
Message-ID: <CAAM-fZ7=jv0k3oSeS+48RD1=eKcGyi0eKG1S895QF8rnbAvfeQ@mail.gmail.com>

Hi,

Please any one help me  to do fine forecasting for the history data.

in that data set A,B... is the account name. based on the spend and revenue
i want allocate the spend amount for the next year of january,february to
the A,B... account and etc.


please find the attached png file for the data


Thanks i advance


Thanks and Regards
Venkatesan
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Forecasting.png
Type: image/png
Size: 75245 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161217/5d70ef24/attachment.png>

From dwinsemius at comcast.net  Sat Dec 17 19:49:45 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 17 Dec 2016 10:49:45 -0800
Subject: [R] Infelicity in print output with matrix indexing of
	`[.data.frame`
Message-ID: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>

This puzzle started with an SO posting where the questioner showed output from a dataframe that had been indexed with a matrix. The output appeared to show that numeric values had been coerced to character. Once I got a reproducible example I discovered that the print output was the problem and that the actual values had not been coerced. I've created a much smaller test case and it appears from the testing below that a matrix indexed output from a dataframe with mixed numeric and character types will be printed as character even if none of the values indexed are character:

> dat <- setNames( as.data.frame( matrix(1:12, ncol=4) ), LETTERS[1:4])
> dat
  A B C  D
1 1 4 7 10
2 2 5 8 11
3 3 6 9 12
> dat[2,4]<-NA
> dat[3,3]<-NA
> ng <- which(is.na(dat), arr.ind=TRUE)
> ng
     row col
[1,]   3   3
[2,]   2   4
> dat[ng] <- 20
> dat[ng]
[1] 20 20

That was as expected. Now repeat the process with a dataframe of mixed types.

> dat[2,4]<-NA
> dat[3,3]<-NA
> dat[,1]<- "a"
> dat
  A B  C  D
1 a 4  7 10
2 a 5  8 NA
3 a 6 NA 12
> dat[ng] <- 20
> dat[ng]
[1] "20" "20"

Quoted print output was not what I was expecting.

-- 

David Winsemius
Alameda, CA, USA


From bgunter.4567 at gmail.com  Sat Dec 17 20:34:34 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 17 Dec 2016 11:34:34 -0800
Subject: [R] Infelicity in print output with matrix indexing of
	`[.data.frame`
In-Reply-To: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
References: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
Message-ID: <CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>

It's documented, David:

>From ?"[.data.frame"

"Matrix indexing (x[i] with a logical or a 2-column integer matrix i)
using [ is not recommended. For extraction, x is first coerced to a
matrix..."

ergo characters for a mixed mode frame.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 17, 2016 at 10:49 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
> This puzzle started with an SO posting where the questioner showed output from a dataframe that had been indexed with a matrix. The output appeared to show that numeric values had been coerced to character. Once I got a reproducible example I discovered that the print output was the problem and that the actual values had not been coerced. I've created a much smaller test case and it appears from the testing below that a matrix indexed output from a dataframe with mixed numeric and character types will be printed as character even if none of the values indexed are character:
>
>> dat <- setNames( as.data.frame( matrix(1:12, ncol=4) ), LETTERS[1:4])
>> dat
>   A B C  D
> 1 1 4 7 10
> 2 2 5 8 11
> 3 3 6 9 12
>> dat[2,4]<-NA
>> dat[3,3]<-NA
>> ng <- which(is.na(dat), arr.ind=TRUE)
>> ng
>      row col
> [1,]   3   3
> [2,]   2   4
>> dat[ng] <- 20
>> dat[ng]
> [1] 20 20
>
> That was as expected. Now repeat the process with a dataframe of mixed types.
>
>> dat[2,4]<-NA
>> dat[3,3]<-NA
>> dat[,1]<- "a"
>> dat
>   A B  C  D
> 1 a 4  7 10
> 2 a 5  8 NA
> 3 a 6 NA 12
>> dat[ng] <- 20
>> dat[ng]
> [1] "20" "20"
>
> Quoted print output was not what I was expecting.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Dec 17 23:58:24 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 17 Dec 2016 14:58:24 -0800
Subject: [R] Infelicity in print output with matrix indexing of
	`[.data.frame`
In-Reply-To: <CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>
References: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
	<CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>
Message-ID: <180C855D-797F-4DA7-8D54-14671CFEBCB6@comcast.net>


> On Dec 17, 2016, at 11:34 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> It's documented, David:
> 
> From ?"[.data.frame"
> 
> "Matrix indexing (x[i] with a logical or a 2-column integer matrix i)
> using [ is not recommended. For extraction, x is first coerced to a
> matrix..."
> 
> ergo characters for a mixed mode frame.

Can we agree that it is most ironic that `[<-.data.frame` does not impose coercion on its `x` argument with a 2 column matrix as `i`, but that `[.data.frame` does? I had initially assumed that the coercion had occurred at the time of assignment which would have made more sense (to me, anyway).

-- 
David.


> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Sat, Dec 17, 2016 at 10:49 AM, David Winsemius
> <dwinsemius at comcast.net> wrote:
>> This puzzle started with an SO posting where the questioner showed output from a dataframe that had been indexed with a matrix. The output appeared to show that numeric values had been coerced to character. Once I got a reproducible example I discovered that the print output was the problem and that the actual values had not been coerced. I've created a much smaller test case and it appears from the testing below that a matrix indexed output from a dataframe with mixed numeric and character types will be printed as character even if none of the values indexed are character:
>> 
>>> dat <- setNames( as.data.frame( matrix(1:12, ncol=4) ), LETTERS[1:4])
>>> dat
>>  A B C  D
>> 1 1 4 7 10
>> 2 2 5 8 11
>> 3 3 6 9 12
>>> dat[2,4]<-NA
>>> dat[3,3]<-NA
>>> ng <- which(is.na(dat), arr.ind=TRUE)
>>> ng
>>     row col
>> [1,]   3   3
>> [2,]   2   4
>>> dat[ng] <- 20
>>> dat[ng]
>> [1] 20 20
>> 
>> That was as expected. Now repeat the process with a dataframe of mixed types.
>> 
>>> dat[2,4]<-NA
>>> dat[3,3]<-NA
>>> dat[,1]<- "a"
>>> dat
>>  A B  C  D
>> 1 a 4  7 10
>> 2 a 5  8 NA
>> 3 a 6 NA 12
>>> dat[ng] <- 20
>>> dat[ng]
>> [1] "20" "20"
>> 
>> Quoted print output was not what I was expecting.
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sun Dec 18 00:15:32 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Dec 2016 15:15:32 -0800
Subject: [R] Infelicity in print output with matrix indexing
	of	`[.data.frame`
In-Reply-To: <180C855D-797F-4DA7-8D54-14671CFEBCB6@comcast.net>
References: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
	<CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>
	<180C855D-797F-4DA7-8D54-14671CFEBCB6@comcast.net>
Message-ID: <B23EC1E4-F610-4A85-A24B-DE0FE9F54D00@dcn.davis.ca.us>

No, cannot agree. The result of using an n by 2 matrix to index into a rectangular object is a vector. A vector can only have one storage mode for all elements. Some type coercion is necessary to accommodate this.
-- 
Sent from my phone. Please excuse my brevity.

On December 17, 2016 2:58:24 PM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Dec 17, 2016, at 11:34 AM, Bert Gunter <bgunter.4567 at gmail.com>
>wrote:
>> 
>> It's documented, David:
>> 
>> From ?"[.data.frame"
>> 
>> "Matrix indexing (x[i] with a logical or a 2-column integer matrix i)
>> using [ is not recommended. For extraction, x is first coerced to a
>> matrix..."
>> 
>> ergo characters for a mixed mode frame.
>
>Can we agree that it is most ironic that `[<-.data.frame` does not
>impose coercion on its `x` argument with a 2 column matrix as `i`, but
>that `[.data.frame` does? I had initially assumed that the coercion had
>occurred at the time of assignment which would have made more sense (to
>me, anyway).


From dulcalma at bigpond.com  Sun Dec 18 04:57:07 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sun, 18 Dec 2016 14:57:07 +1100
Subject: [R] data manipulation
In-Reply-To: <585154B9.8020002@sapo.pt>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>	<1768303695.2867148.1481716595402@mail.yahoo.com>	<58513719.5000309@sapo.pt>	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
Message-ID: <001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>

Hi 

Coming late to the discussion  - I deleted the original message
I found that I have a cbe.dat that I downloaded some years ago from
cowpertwaite's site .

And have attached it

If it does not get through will do a dput as the file is only 7K

Regards

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Thursday, 15 December 2016 01:19
To: Farshad Fathian; r-help
Subject: Re: [R] data manipulation

Hello,

Please cc your mails to the list.
As for your data, your url is wrong, you need to contact Massey or maybe 
the source of your information and get a valid internet address.
Without one there's not much we can do.

Rui Barradas

Em 14-12-2016 12:16, Farshad Fathian escreveu:
> Hello,
>
> Thanks for your e-mail. I was reading "Introductory Time Series with R"
> by PS. Cowperwait. I am going to run the R codes in this book, but I
> don't access to the input data from
> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>
> Regards,
>
> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     What do you mean by "gives me something"?
>
>     xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>     <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>     Error in file(file, "rt") : cannot open the connection
>     In addition: Warning message:
>     In file(file, "rt") :
>        cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>     <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>     Not Found'
>
>     Rui Barradas
>
>
>     Em 14-12-2016 11:56, John Kane via R-help escreveu:
>
>         xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>         <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>         gives me something. Since we have no idea of what you are doing
>         I don't know if the data has downloaded correctly
>
>               On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>         <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>         wrote:
>
>
>            Hi,
>
>
>
>         I couldn't access to data file about PSCoperwait by
>         http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>         <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>
>
>
>         Looking forward to hearing from you,
>
>
>               [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>                  [[alternative HTML version deleted]]
>
>         ______________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         -- To UNSUBSCRIBE and more, see
>         https://stat.ethz.ch/mailman/listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From a67355 at gmail.com  Sun Dec 18 02:09:26 2016
From: a67355 at gmail.com (Pedro Montenegro)
Date: Sun, 18 Dec 2016 01:09:26 +0000
Subject: [R] h5r package: cannot find hdf5
Message-ID: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>

I'm new to R and Linux, and I have an issue I didn't see solved on the
internet.

I'm using Ubuntu Mate and installed R version 2.11 since the current
version does not support R-kinetics.
What happens is that I have hdf5 headers and libraries installed

$ whereis hdf5
hdf5: /usr/include/hdf5

But when I'm installing the package inside R (install.packages) or outside
R (R CMD INSTALL) the program reports the following error:

> install.packages('h5r')
Warning in install.packages("h5r") :
  argument 'lib' is missing: using
'/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
Warning message:
In getDependencies(pkgs, dependencies, available, lib) :
  package ?h5r? is not available
> install.packages('/home/pedro/h5r_1.4.7.tar.gz',repos=NULL,type='source')
Warning in install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
  argument 'lib' is missing: using
'/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
* installing *source* package ?h5r? ...
checking for gcc... gcc
checking for C compiler default output file name... a.out
checking whether the C compiler works... yes
checking whether we are cross compiling... no
checking for suffix of executables...
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed


checking for library containing inflate... -lz
checking for library containing H5open... no
configure: error: Can't find HDF5
ERROR: configuration failed for package ?h5r?
* removing ?/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11/h5r?
Warning message:
In install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
  installation of package '/home/pedro/h5r_1.4.7.tar.gz' had non-zero exit
status.

I tried to reinstall HDF5, R and even the whole OS and do it all over
again. Also tried to add the library to the environment table, do it from
the library's directory and nothing works.

Is there someone who had the same error and was able to solve it?
Is there someone who as a clue how to solve?

I'm sorry if there is a similar post around, I've seen some but I don't
find one where the problem is solved.
Best regards!

*Pedro*

	[[alternative HTML version deleted]]


From oikos.nemo at gmail.com  Sat Dec 17 19:41:38 2016
From: oikos.nemo at gmail.com (Rodriguetti)
Date: Sat, 17 Dec 2016 19:41:38 +0100
Subject: [R] LABOR SUPPLY MODELLING WITH R
Message-ID: <0d3b92d3-079d-953f-15fa-b8be550a953b@gmail.com>

Hi,

I am new to R migrating from Stata. I am estimating through Simulated 
Maximum Likelihood Estimation a utility function for hours of work in a 
discrete choice model.

I have my own Stata code but I still can't get into a similar R code. 
Could anyone just recommend me an applied or reproducible exercice 
related to labor supply modelling?

Thank you very much!

Best,

Ernesto


---
El software de antivirus Avast ha analizado este correo electr?nico en busca de virus.
https://www.avast.com/antivirus


From tramni at abv.bg  Sun Dec 18 12:35:37 2016
From: tramni at abv.bg (Martin Ivanov)
Date: Sun, 18 Dec 2016 13:35:37 +0200 (EET)
Subject: [R] setAs: does it overwrite existing coerce methods?
Message-ID: <1412888114.396710.1482060938407.JavaMail.apache@nm33.abv.bg>

Dear R users,

I am working a lot with spatial objects from the package sp. I need to write my own method for converting a SpatialGrid
to a SpatialPoints object, because the default method as("SpatialGrid", "SpatialPoints") returns a SpatialPoints object with
decreasing latitudes. If I write my own method (that creates a SpatialPoints object with both longitudes and latitudes increasing)
using setAs, will it overwrite the default method provided by the sp packages? Will this result in breaking all other methods in sp
that use as()? If the sp methods always call the as() method from sp, this should not be the case. But if they happen to call the method I?
am going to define instead of the one they expect, they might get broken. So, what is your opinion about this is? Is there a way to safely
define a coerce method with setAs that only the code written by me uses, so ?that no other code coming from packages is broken?

Thank you very much!

Best regards,
Martin


From klebyn at yahoo.com.br  Sun Dec 18 18:07:52 2016
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Sun, 18 Dec 2016 15:07:52 -0200
Subject: [R] dataframe columns class
Message-ID: <6fd4b2f5-b6c6-91c7-1645-a5f3bea8b644@yahoo.com.br>

Why columns classes are function dependents?
Like this example:

 > for( i in 1:5 ) print( class( iris[,i] ) )
[1] "numeric"
[1] "numeric"
[1] "numeric"
[1] "numeric"
[1] "factor"
 >
 > apply( iris, 2, class )
Sepal.Length  Sepal.Width Petal.Length  Petal.Width Species
  "character"  "character"  "character"  "character" "character"
 >



 > dat <- data.frame( v1=1:5, v2=letters[1:5] )
 > dat
   v1 v2
1  1  a
2  2  b
3  3  c
4  4  d
5  5  e
 >
 > summary( dat )
        v1    v2
  Min.   :1   a:1
  1st Qu.:2   b:1
  Median :3   c:1
  Mean   :3   d:1
  3rd Qu.:4   e:1
  Max.   :5
 >
 > apply( dat, 2, class )
          v1          v2
"character" "character"
 >


---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus


From istazahn at gmail.com  Sun Dec 18 18:22:41 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 18 Dec 2016 12:22:41 -0500
Subject: [R] dataframe columns class
In-Reply-To: <6fd4b2f5-b6c6-91c7-1645-a5f3bea8b644@yahoo.com.br>
References: <6fd4b2f5-b6c6-91c7-1645-a5f3bea8b644@yahoo.com.br>
Message-ID: <CA+vqiLHRAenDjniTwzU6eB7FZ3Esh7x02PGd_sxWm=eHp0O2LQ@mail.gmail.com>

Read ?apply and you shall be be enlightened.

--Ista

On Dec 18, 2016 12:09 PM, "Cleber N.Borges via R-help" <r-help at r-project.org>
wrote:

> Why columns classes are function dependents?
> Like this example:
>
> > for( i in 1:5 ) print( class( iris[,i] ) )
> [1] "numeric"
> [1] "numeric"
> [1] "numeric"
> [1] "numeric"
> [1] "factor"
> >
> > apply( iris, 2, class )
> Sepal.Length  Sepal.Width Petal.Length  Petal.Width Species
>  "character"  "character"  "character"  "character" "character"
> >
>
>
>
> > dat <- data.frame( v1=1:5, v2=letters[1:5] )
> > dat
>   v1 v2
> 1  1  a
> 2  2  b
> 3  3  c
> 4  4  d
> 5  5  e
> >
> > summary( dat )
>        v1    v2
>  Min.   :1   a:1
>  1st Qu.:2   b:1
>  Median :3   c:1
>  Mean   :3   d:1
>  3rd Qu.:4   e:1
>  Max.   :5
> >
> > apply( dat, 2, class )
>          v1          v2
> "character" "character"
> >
>
>
> ---
> Este email foi escaneado pelo Avast antiv?rus.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec 18 18:38:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 18 Dec 2016 09:38:09 -0800
Subject: [R] dataframe columns class
In-Reply-To: <6fd4b2f5-b6c6-91c7-1645-a5f3bea8b644@yahoo.com.br>
References: <6fd4b2f5-b6c6-91c7-1645-a5f3bea8b644@yahoo.com.br>
Message-ID: <133B16AC-5F76-4FDA-861C-7D52E219265C@dcn.davis.ca.us>

The apply function operates on arrays, so your data frame is being converted to an array (matrix) before doing its thing.  So use lapply or one of its variants. 
-- 
Sent from my phone. Please excuse my brevity.

On December 18, 2016 9:07:52 AM PST, "Cleber N.Borges via R-help" <r-help at r-project.org> wrote:
>Why columns classes are function dependents?
>Like this example:
>
> > for( i in 1:5 ) print( class( iris[,i] ) )
>[1] "numeric"
>[1] "numeric"
>[1] "numeric"
>[1] "numeric"
>[1] "factor"
> >
> > apply( iris, 2, class )
>Sepal.Length  Sepal.Width Petal.Length  Petal.Width Species
>  "character"  "character"  "character"  "character" "character"
> >
>
>
>
> > dat <- data.frame( v1=1:5, v2=letters[1:5] )
> > dat
>   v1 v2
>1  1  a
>2  2  b
>3  3  c
>4  4  d
>5  5  e
> >
> > summary( dat )
>        v1    v2
>  Min.   :1   a:1
>  1st Qu.:2   b:1
>  Median :3   c:1
>  Mean   :3   d:1
>  3rd Qu.:4   e:1
>  Max.   :5
> >
> > apply( dat, 2, class )
>          v1          v2
>"character" "character"
> >
>
>
>---
>Este email foi escaneado pelo Avast antiv?rus.
>https://www.avast.com/antivirus
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Dec 18 19:00:45 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Dec 2016 10:00:45 -0800
Subject: [R] Infelicity in print output with matrix indexing
	of	`[.data.frame`
In-Reply-To: <B23EC1E4-F610-4A85-A24B-DE0FE9F54D00@dcn.davis.ca.us>
References: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
	<CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>
	<180C855D-797F-4DA7-8D54-14671CFEBCB6@comcast.net>
	<B23EC1E4-F610-4A85-A24B-DE0FE9F54D00@dcn.davis.ca.us>
Message-ID: <9AAAF54B-FE60-4C60-9C4E-E40AF9630BD3@comcast.net>


> On Dec 17, 2016, at 3:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> No, cannot agree. The result of using an n by 2 matrix to index into a rectangular object is a vector. A vector can only have one storage mode for all elements. Some type coercion is necessary to accommodate this.

I have no argument with the premise that an atomic vector must be of a single mode.  But the exact same values were established with a numeric vector into those positions indexed by the 2-column matrix. Why does extraction need to coerce the entire dataframe to matrix when none of the extracted values are character? I suppose my request is that the very simple line in `[.data.frame`


    if (is.matrix(i)) 
            return(as.matrix(x)[i])

If it were replaced by code that would only extract from the values needed and then use a shifted version of the selection matrix, you could get values that were not coerced by being innocent bystanders of a dataframe colum that was not relevant.

as.matrix( x[ min( i[ , 1]):max( i[ , 1]), min( i[ ,2 ]):max(i[ , 2]) ])[
                   cbind( i[,1]-min( i[ , 1]) +1, i[,2]- min( i[ ,2 ]) +1) ]

-- 
David.

> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On December 17, 2016 2:58:24 PM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Dec 17, 2016, at 11:34 AM, Bert Gunter <bgunter.4567 at gmail.com>
>> wrote:
>>> 
>>> It's documented, David:
>>> 
>>> From ?"[.data.frame"
>>> 
>>> "Matrix indexing (x[i] with a logical or a 2-column integer matrix i)
>>> using [ is not recommended. For extraction, x is first coerced to a
>>> matrix..."
>>> 
>>> ergo characters for a mixed mode frame.
>> 
>> Can we agree that it is most ironic that `[<-.data.frame` does not
>> impose coercion on its `x` argument with a 2 column matrix as `i`, but
>> that `[.data.frame` does? I had initially assumed that the coercion had
>> occurred at the time of assignment which would have made more sense (to
>> me, anyway).
> 

David Winsemius
Alameda, CA, USA


From pls at mevik.net  Sun Dec 18 18:36:37 2016
From: pls at mevik.net (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Sun, 18 Dec 2016 18:36:37 +0100
Subject: [R] [R-pkgs] pls 2.6-0 released
Message-ID: <8737hlyw9m.fsf@nor.mevik.net>

Version 2.6-0 of the pls package has been released and will be available
at your local CRAN mirror shortly.  The pls package implements Partial
Least Squares Regression, Principal Component Regression and Canonical
Powered PLS.

The major changes in 2.6-0 are:

- It now has a function selectNcomp() for automatically suggesting the
  optimal number of components for the model.  The function implements
  two different algorithms, and will optionally plot the RMSEP values
  and number of components.

- A description of selectNcomp() has been added to the vignette.

-- 
Regards,
Bj?rn-Helge Mevik

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages

From dwinsemius at comcast.net  Sun Dec 18 19:36:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Dec 2016 10:36:15 -0800
Subject: [R] data manipulation
In-Reply-To: <001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
Message-ID: <6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>


> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> Hi 
> 
> Coming late to the discussion  - I deleted the original message
> I found that I have a cbe.dat that I downloaded some years ago from
> cowpertwaite's site .
> 
> And have attached it

Experience has shown that when you attach a file that you hope to be distributed to the list it needs to have a .txt extension. Leaving it with a .csv, .tsv, or .dat extension will cause it to be dropped by the server, even if the contents of the file are ASCII text.

The URL I offered earlier should have made the file available:
https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/cbe.dat

... but if there is interest in having it in the Rhelp Archive, I can attach it.



-- 
David.
> 
> If it does not get through will do a dput as the file is only 7K
> 
> Regards
> 
> Duncan
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
> Sent: Thursday, 15 December 2016 01:19
> To: Farshad Fathian; r-help
> Subject: Re: [R] data manipulation
> 
> Hello,
> 
> Please cc your mails to the list.
> As for your data, your url is wrong, you need to contact Massey or maybe 
> the source of your information and get a valid internet address.
> Without one there's not much we can do.
> 
> Rui Barradas
> 
> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>> Hello,
>> 
>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>> don't access to the input data from
>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>> 
>> Regards,
>> 
>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>> 
>>    Hello,
>> 
>>    What do you mean by "gives me something"?
>> 
>>    xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>    <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>    Error in file(file, "rt") : cannot open the connection
>>    In addition: Warning message:
>>    In file(file, "rt") :
>>       cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>    <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>    Not Found'
>> 
>>    Rui Barradas
>> 
>> 
>>    Em 14-12-2016 11:56, John Kane via R-help escreveu:
>> 
>>        xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>        <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>        gives me something. Since we have no idea of what you are doing
>>        I don't know if the data has downloaded correctly
>> 
>>              On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>        <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>        wrote:
>> 
>> 
>>           Hi,
>> 
>> 
>> 
>>        I couldn't access to data file about PSCoperwait by
>>        http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>        <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>> 
>> 
>> 
>>        Looking forward to hearing from you,
>> 
>> 
>>              [[alternative HTML version deleted]]
>> 
>>        ______________________________________________
>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>        -- To UNSUBSCRIBE and more, see
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>        PLEASE do read the posting guide
>>        http://www.R-project.org/posting-guide.html
>>        <http://www.R-project.org/posting-guide.html>
>>        and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>>                 [[alternative HTML version deleted]]
>> 
>>        ______________________________________________
>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>        -- To UNSUBSCRIBE and more, see
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>        PLEASE do read the posting guide
>>        http://www.R-project.org/posting-guide.html
>>        <http://www.R-project.org/posting-guide.html>
>>        and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sun Dec 18 19:37:02 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Dec 2016 10:37:02 -0800
Subject: [R] data manipulation
In-Reply-To: <001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
Message-ID: <F13979CE-5C21-445E-9A78-0074A5CFCD26@comcast.net>

An embedded and charset-unspecified text was scrubbed...
Name: cbe.dat.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161218/903d49a9/attachment.txt>
-------------- next part --------------



> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> Hi 
> 
> Coming late to the discussion  - I deleted the original message
> I found that I have a cbe.dat that I downloaded some years ago from
> cowpertwaite's site .
> 
> And have attached it
> 
> If it does not get through will do a dput as the file is only 7K
> 
> Regards
> 
> Duncan
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
> Sent: Thursday, 15 December 2016 01:19
> To: Farshad Fathian; r-help
> Subject: Re: [R] data manipulation
> 
> Hello,
> 
> Please cc your mails to the list.
> As for your data, your url is wrong, you need to contact Massey or maybe 
> the source of your information and get a valid internet address.
> Without one there's not much we can do.
> 
> Rui Barradas
> 
> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>> Hello,
>> 
>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>> don't access to the input data from
>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>> 
>> Regards,
>> 
>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>> 
>>    Hello,
>> 
>>    What do you mean by "gives me something"?
>> 
>>    xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>    <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>    Error in file(file, "rt") : cannot open the connection
>>    In addition: Warning message:
>>    In file(file, "rt") :
>>       cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>    <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>    Not Found'
>> 
>>    Rui Barradas
>> 
>> 
>>    Em 14-12-2016 11:56, John Kane via R-help escreveu:
>> 
>>        xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>        <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>        gives me something. Since we have no idea of what you are doing
>>        I don't know if the data has downloaded correctly
>> 
>>              On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>        <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>        wrote:
>> 
>> 
>>           Hi,
>> 
>> 
>> 
>>        I couldn't access to data file about PSCoperwait by
>>        http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>        <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>> 
>> 
>> 
>>        Looking forward to hearing from you,
>> 
>> 
>>              [[alternative HTML version deleted]]
>> 
>>        ______________________________________________
>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>        -- To UNSUBSCRIBE and more, see
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>        PLEASE do read the posting guide
>>        http://www.R-project.org/posting-guide.html
>>        <http://www.R-project.org/posting-guide.html>
>>        and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>>                 [[alternative HTML version deleted]]
>> 
>>        ______________________________________________
>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>        -- To UNSUBSCRIBE and more, see
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>        PLEASE do read the posting guide
>>        http://www.R-project.org/posting-guide.html
>>        <http://www.R-project.org/posting-guide.html>
>>        and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.ca.us  Sun Dec 18 19:51:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 18 Dec 2016 10:51:29 -0800
Subject: [R] Infelicity in print output with matrix indexing
	of	`[.data.frame`
In-Reply-To: <9AAAF54B-FE60-4C60-9C4E-E40AF9630BD3@comcast.net>
References: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
	<CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>
	<180C855D-797F-4DA7-8D54-14671CFEBCB6@comcast.net>
	<B23EC1E4-F610-4A85-A24B-DE0FE9F54D00@dcn.davis.ca.us>
	<9AAAF54B-FE60-4C60-9C4E-E40AF9630BD3@comcast.net>
Message-ID: <CC4ACE02-069A-4BC1-931C-186A8500114A@dcn.davis.ca.us>

Ah, "why"... perhaps because the speed reduction involved in successive indexing operations on data frames was considered unacceptable to the programmer? (Also the code would essentially have to check for type conversion of the result vector as every row of the index matrix was retrieved.) Perhaps for backward compatibility?

You could code your own version that behaved the way you like, but I think the usual expectation is that indexing should be faster than an R for loop, so hiding such behavior behind [.data.frame seems a bit deceptive to me. 

It seems much more straightforward to me to explicitly convert that portion of the data frame that you intend to do matrix indexing with into a matrix of known type for the purposes of this task, rather than expecting [.data.frame to figure out that you don't plan to retrieve values from the non-numeric columns of the data frame. (Sometimes the fact that things are hard is a hint that you should re-think your solution.)
-- 
Sent from my phone. Please excuse my brevity.

On December 18, 2016 10:00:45 AM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Dec 17, 2016, at 3:15 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> No, cannot agree. The result of using an n by 2 matrix to index into
>a rectangular object is a vector. A vector can only have one storage
>mode for all elements. Some type coercion is necessary to accommodate
>this.
>
>I have no argument with the premise that an atomic vector must be of a
>single mode.  But the exact same values were established with a numeric
>vector into those positions indexed by the 2-column matrix. Why does
>extraction need to coerce the entire dataframe to matrix when none of
>the extracted values are character? I suppose my request is that the
>very simple line in `[.data.frame`
>
>
>    if (is.matrix(i)) 
>            return(as.matrix(x)[i])
>
>If it were replaced by code that would only extract from the values
>needed and then use a shifted version of the selection matrix, you
>could get values that were not coerced by being innocent bystanders of
>a dataframe colum that was not relevant.
>
>as.matrix( x[ min( i[ , 1]):max( i[ , 1]), min( i[ ,2 ]):max(i[ , 2])
>])[
>              cbind( i[,1]-min( i[ , 1]) +1, i[,2]- min( i[ ,2 ]) +1) ]


From dosc3612 at colorado.edu  Sun Dec 18 20:06:13 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Sun, 18 Dec 2016 11:06:13 -0800
Subject: [R] h5r package: cannot find hdf5
In-Reply-To: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>
References: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>
Message-ID: <CAF1jk_mUS3ZQgrqv=Zj1-iaPWREQurtcX-gzctUQVHC+rKO+5A@mail.gmail.com>

Pedro,
I've only worked with netcdf4 but I imagine your issue is similar to one's
I've had:
I think you can:
1. add your hdf5 lib directory to the LD_LIBRARY_PATH
http://grokbase.com/t/r/r-help/10at4wcjfq/r-ncdf4-package-installation-in-r
2. you can specify the direct path to lib and include directories for the
hdf5 library:

e.g.

install.packages("/home/user/Downloads/RNetCDF_1.6.1-2.tar.gz",
repos = NULL,
type="source",
dependencies=FALSE,
configure.args="--with-netcdf-include=/usr/local/netcdf-4.2.1-build/include
--with-netcdf-lib=/usr/local/netcdf-4.2.1-build/lib")

http://stackoverflow.com/questions/11319698/how-to-install-r-packages-rnetcdf-and-ncdf-on-ubuntu


On Sat, Dec 17, 2016 at 5:09 PM, Pedro Montenegro <a67355 at gmail.com> wrote:

> I'm new to R and Linux, and I have an issue I didn't see solved on the
> internet.
>
> I'm using Ubuntu Mate and installed R version 2.11 since the current
> version does not support R-kinetics.
> What happens is that I have hdf5 headers and libraries installed
>
> $ whereis hdf5
> hdf5: /usr/include/hdf5
>
> But when I'm installing the package inside R (install.packages) or outside
> R (R CMD INSTALL) the program reports the following error:
>
> > install.packages('h5r')
> Warning in install.packages("h5r") :
>   argument 'lib' is missing: using
> '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>   package ?h5r? is not available
> > install.packages('/home/pedro/h5r_1.4.7.tar.gz',repos=NULL,
> type='source')
> Warning in install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos =
> NULL,  :
>   argument 'lib' is missing: using
> '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
> * installing *source* package ?h5r? ...
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
>
>
> checking for library containing inflate... -lz
> checking for library containing H5open... no
> configure: error: Can't find HDF5
> ERROR: configuration failed for package ?h5r?
> * removing ?/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11/h5r?
> Warning message:
> In install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
>   installation of package '/home/pedro/h5r_1.4.7.tar.gz' had non-zero exit
> status.
>
> I tried to reinstall HDF5, R and even the whole OS and do it all over
> again. Also tried to add the library to the environment table, do it from
> the library's directory and nothing works.
>
> Is there someone who had the same error and was able to solve it?
> Is there someone who as a clue how to solve?
>
> I'm sorry if there is a similar post around, I've seen some but I don't
> find one where the problem is solved.
> Best regards!
>
> *Pedro*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec 18 20:14:13 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 18 Dec 2016 11:14:13 -0800
Subject: [R] setAs: does it overwrite existing coerce methods?
In-Reply-To: <1412888114.396710.1482060938407.JavaMail.apache@nm33.abv.bg>
References: <1412888114.396710.1482060938407.JavaMail.apache@nm33.abv.bg>
Message-ID: <F14E67C2-8B5B-4E73-880F-0307B291C080@dcn.davis.ca.us>

You probably should have asked this on R-sig-geo. Technically, recent versions of R require that packages import dependencies, so your new function should not be called from within any packages. 

I am not an expert with the sp package but I would be concerned that if you passed your modified objects to existing package functions that they might not work if they assume the data are sorted the other way. Are you sure you cannot re-extract the data at the point when you need it sorted the other way? 
-- 
Sent from my phone. Please excuse my brevity.

On December 18, 2016 3:35:37 AM PST, Martin Ivanov <tramni at abv.bg> wrote:
>Dear R users,
>
>I am working a lot with spatial objects from the package sp. I need to
>write my own method for converting a SpatialGrid
>to a SpatialPoints object, because the default method as("SpatialGrid",
>"SpatialPoints") returns a SpatialPoints object with
>decreasing latitudes. If I write my own method (that creates a
>SpatialPoints object with both longitudes and latitudes increasing)
>using setAs, will it overwrite the default method provided by the sp
>packages? Will this result in breaking all other methods in sp
>that use as()? If the sp methods always call the as() method from sp,
>this should not be the case. But if they happen to call the method I?
>am going to define instead of the one they expect, they might get
>broken. So, what is your opinion about this is? Is there a way to
>safely
>define a coerce method with setAs that only the code written by me
>uses, so ?that no other code coming from packages is broken?
>
>Thank you very much!
>
>Best regards,
>Martin
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ragia11 at hotmail.com  Sun Dec 18 20:22:15 2016
From: ragia11 at hotmail.com (Ragia .)
Date: Sun, 18 Dec 2016 19:22:15 +0000
Subject: [R] re attach into the killed R session
Message-ID: <AMSPR03MB5844D00C8427BE137D22838B39E0@AMSPR03MB584.eurprd03.prod.outlook.com>


Dear group
I had a tmux session, on it an R script is running before the program should ends

on the screen written "killed" and the script terminated and returned bake to bash (in the same tmux window)

Q: how can I re attach into the killed R session and check it? can I recover what was the script doing for more than a month now ?
any ideas?
THANS


Ragia A. Ibrahim



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Dec 18 21:19:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 18 Dec 2016 12:19:11 -0800
Subject: [R] re attach into the killed R session
In-Reply-To: <AMSPR03MB5844D00C8427BE137D22838B39E0@AMSPR03MB584.eurprd03.prod.outlook.com>
References: <AMSPR03MB5844D00C8427BE137D22838B39E0@AMSPR03MB584.eurprd03.prod.outlook.com>
Message-ID: <5F8F983B-5830-42FD-B384-9EEB9E94C87C@dcn.davis.ca.us>

Not a question about R (it is about process management in what I am guessing is some kind of unix-alike OS).

I suspect that unless you wrote log files or intermediate data to disk as you went, it is very likely that you are out of luck. Since you are posting here instead of reviewing those files...
-- 
Sent from my phone. Please excuse my brevity.

On December 18, 2016 11:22:15 AM PST, "Ragia ." <ragia11 at hotmail.com> wrote:
>
>Dear group
>I had a tmux session, on it an R script is running before the program
>should ends
>
>on the screen written "killed" and the script terminated and returned
>bake to bash (in the same tmux window)
>
>Q: how can I re attach into the killed R session and check it? can I
>recover what was the script doing for more than a month now ?
>any ideas?
>THANS
>
>
>Ragia A. Ibrahim
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Dec 18 22:50:12 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 18 Dec 2016 22:50:12 +0100
Subject: [R] Infelicity in print output with matrix indexing of
	`[.data.frame`
In-Reply-To: <CC4ACE02-069A-4BC1-931C-186A8500114A@dcn.davis.ca.us>
References: <841D124A-FB41-4715-AA98-D3E04018B69D@comcast.net>
	<CAGxFJbScTYHZbk7vvmarT4CL+stD1Hfpw8Jj6eEZfmVaU-gqxw@mail.gmail.com>
	<180C855D-797F-4DA7-8D54-14671CFEBCB6@comcast.net>
	<B23EC1E4-F610-4A85-A24B-DE0FE9F54D00@dcn.davis.ca.us>
	<9AAAF54B-FE60-4C60-9C4E-E40AF9630BD3@comcast.net>
	<CC4ACE02-069A-4BC1-931C-186A8500114A@dcn.davis.ca.us>
Message-ID: <4F626749-58BD-43DF-8275-8EB637935D98@gmail.com>


> On 18 Dec 2016, at 19:51 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Ah, "why"... perhaps because the speed reduction involved in successive indexing operations on data frames was considered unacceptable to the programmer? (Also the code would essentially have to check for type conversion of the result vector as every row of the index matrix was retrieved.) Perhaps for backward compatibility?

More likely, to avoid having the type of the result depend on the value of the index. Also, sub-index consistency: does one really want D[M][1:2] to be of a different type than D[M[1:2,]].

-pd 

> 
> You could code your own version that behaved the way you like, but I think the usual expectation is that indexing should be faster than an R for loop, so hiding such behavior behind [.data.frame seems a bit deceptive to me. 
> 
> It seems much more straightforward to me to explicitly convert that portion of the data frame that you intend to do matrix indexing with into a matrix of known type for the purposes of this task, rather than expecting [.data.frame to figure out that you don't plan to retrieve values from the non-numeric columns of the data frame. (Sometimes the fact that things are hard is a hint that you should re-think your solution.)
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On December 18, 2016 10:00:45 AM PST, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> On Dec 17, 2016, at 3:15 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> No, cannot agree. The result of using an n by 2 matrix to index into
>> a rectangular object is a vector. A vector can only have one storage
>> mode for all elements. Some type coercion is necessary to accommodate
>> this.
>> 
>> I have no argument with the premise that an atomic vector must be of a
>> single mode.  But the exact same values were established with a numeric
>> vector into those positions indexed by the 2-column matrix. Why does
>> extraction need to coerce the entire dataframe to matrix when none of
>> the extracted values are character? I suppose my request is that the
>> very simple line in `[.data.frame`
>> 
>> 
>>   if (is.matrix(i)) 
>>           return(as.matrix(x)[i])
>> 
>> If it were replaced by code that would only extract from the values
>> needed and then use a shifted version of the selection matrix, you
>> could get values that were not coerced by being innocent bystanders of
>> a dataframe colum that was not relevant.
>> 
>> as.matrix( x[ min( i[ , 1]):max( i[ , 1]), min( i[ ,2 ]):max(i[ , 2])
>> ])[
>>             cbind( i[,1]-min( i[ , 1]) +1, i[,2]- min( i[ ,2 ]) +1) ]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jholtman at gmail.com  Sun Dec 18 23:20:24 2016
From: jholtman at gmail.com (jim holtman)
Date: Sun, 18 Dec 2016 17:20:24 -0500
Subject: [R] re attach into the killed R session
In-Reply-To: <AMSPR03MB5844D00C8427BE137D22838B39E0@AMSPR03MB584.eurprd03.prod.outlook.com>
References: <AMSPR03MB5844D00C8427BE137D22838B39E0@AMSPR03MB584.eurprd03.prod.outlook.com>
Message-ID: <CAAxdm-6SCwXLtNKWomkm=KohbEDoiQw08hCb3aML3XYuuMqOFg@mail.gmail.com>

I would hope that if you have an R script that is running for a month that
you have built in periodic checkpoints so that you can recover what is
happening.  In cases where I want to be able to restart an R script at some
point downstream, I will "save.image", or just the objects that are
important, and then I can reload at that point and carry forward.  Also you
will have the objects that you need to examine if you have too.  If I had
something running that long, I would at least take a checkpoint every hour
to help in the debugging/recovery process.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Dec 18, 2016 at 2:22 PM, Ragia . <ragia11 at hotmail.com> wrote:

>
> Dear group
> I had a tmux session, on it an R script is running before the program
> should ends
>
> on the screen written "killed" and the script terminated and returned bake
> to bash (in the same tmux window)
>
> Q: how can I re attach into the killed R session and check it? can I
> recover what was the script doing for more than a month now ?
> any ideas?
> THANS
>
>
> Ragia A. Ibrahim
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Dec 19 00:31:11 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 19 Dec 2016 00:31:11 +0100
Subject: [R] data manipulation
In-Reply-To: <6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
	<6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
Message-ID: <2BC93929-9F76-493A-BAB7-7D554390F99E@gmail.com>


> On 18 Dec 2016, at 19:36 , David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> 
>> Hi 
>> 
>> Coming late to the discussion  - I deleted the original message
>> I found that I have a cbe.dat that I downloaded some years ago from
>> cowpertwaite's site .
>> 
>> And have attached it
> 
> Experience has shown that when you attach a file that you hope to be distributed to the list it needs to have a .txt extension. Leaving it with a .csv, .tsv, or .dat extension will cause it to be dropped by the server, even if the contents of the file are ASCII text.

That's not the actual mechanism, as far as I understand. If the content-type is text/plain, the server will pass it through just fine. It's the mail program at the sender end that refuses to send .csv files and friends as text/plain, based on the extension. But the net result is essentially the same.

> The URL I offered earlier should have made the file available:
> https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/cbe.dat
> 
> ... but if there is interest in having it in the Rhelp Archive, I can attach it.
> 
> 

Would be good if someone could ask the authors about what is going on. Better if someone could check licencing issues and put the data somewhere permanent. Still better: convert them to an R package.

> 
> -- 
> David.
>> 
>> If it does not get through will do a dput as the file is only 7K
>> 
>> Regards
>> 
>> Duncan
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>> Sent: Thursday, 15 December 2016 01:19
>> To: Farshad Fathian; r-help
>> Subject: Re: [R] data manipulation
>> 
>> Hello,
>> 
>> Please cc your mails to the list.
>> As for your data, your url is wrong, you need to contact Massey or maybe 
>> the source of your information and get a valid internet address.
>> Without one there's not much we can do.
>> 
>> Rui Barradas
>> 
>> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>>> Hello,
>>> 
>>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>>> don't access to the input data from
>>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>>> 
>>> Regards,
>>> 
>>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>> 
>>>   Hello,
>>> 
>>>   What do you mean by "gives me something"?
>>> 
>>>   xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>   <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>   Error in file(file, "rt") : cannot open the connection
>>>   In addition: Warning message:
>>>   In file(file, "rt") :
>>>      cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>   <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>>   Not Found'
>>> 
>>>   Rui Barradas
>>> 
>>> 
>>>   Em 14-12-2016 11:56, John Kane via R-help escreveu:
>>> 
>>>       xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>       <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>       gives me something. Since we have no idea of what you are doing
>>>       I don't know if the data has downloaded correctly
>>> 
>>>             On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>>       <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>>       wrote:
>>> 
>>> 
>>>          Hi,
>>> 
>>> 
>>> 
>>>       I couldn't access to data file about PSCoperwait by
>>>       http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>       <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>>> 
>>> 
>>> 
>>>       Looking forward to hearing from you,
>>> 
>>> 
>>>             [[alternative HTML version deleted]]
>>> 
>>>       ______________________________________________
>>>       R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>       -- To UNSUBSCRIBE and more, see
>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>       PLEASE do read the posting guide
>>>       http://www.R-project.org/posting-guide.html
>>>       <http://www.R-project.org/posting-guide.html>
>>>       and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>>                [[alternative HTML version deleted]]
>>> 
>>>       ______________________________________________
>>>       R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>       -- To UNSUBSCRIBE and more, see
>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>       PLEASE do read the posting guide
>>>       http://www.R-project.org/posting-guide.html
>>>       <http://www.R-project.org/posting-guide.html>
>>>       and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Mon Dec 19 02:20:49 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Dec 2016 17:20:49 -0800
Subject: [R] h5r package: cannot find hdf5
In-Reply-To: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>
References: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>
Message-ID: <3586ED1B-93E4-436F-8802-492E56CE932C@comcast.net>


> On Dec 17, 2016, at 5:09 PM, Pedro Montenegro <a67355 at gmail.com> wrote:
> 
> I'm new to R and Linux, and I have an issue I didn't see solved on the
> internet.
> 
> I'm using Ubuntu Mate and installed R version 2.11 since the current
> version does not support R-kinetics.
> What happens is that I have hdf5 headers and libraries installed
> 
> $ whereis hdf5
> hdf5: /usr/include/hdf5
> 
> But when I'm installing the package inside R (install.packages) or outside
> R (R CMD INSTALL) the program reports the following error:
> 
>> install.packages('h5r')
> Warning in install.packages("h5r") :

There is also a bioconductor package that provides an HDF5 interface:

http://bioconductor.org/packages/release/bioc/html/rhdf5.html

I have no idea whether it's config files might include a more extensive search for installed versions of HDF5. Unlike h5r it is available for all three major forks of R.

-- 
David.
>  argument 'lib' is missing: using
> '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
> Warning message:
> In getDependencies(pkgs, dependencies, available, lib) :
>  package ?h5r? is not available
>> install.packages('/home/pedro/h5r_1.4.7.tar.gz',repos=NULL,type='source')
> Warning in install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
>  argument 'lib' is missing: using
> '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
> * installing *source* package ?h5r? ...
> checking for gcc... gcc
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc accepts -g... yes
> checking for gcc option to accept ISO C89... none needed
> 
> 
> checking for library containing inflate... -lz
> checking for library containing H5open... no
> configure: error: Can't find HDF5
> ERROR: configuration failed for package ?h5r?
> * removing ?/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11/h5r?
> Warning message:
> In install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
>  installation of package '/home/pedro/h5r_1.4.7.tar.gz' had non-zero exit
> status.
> 
> I tried to reinstall HDF5, R and even the whole OS and do it all over
> again. Also tried to add the library to the environment table, do it from
> the library's directory and nothing works.
> 
> Is there someone who had the same error and was able to solve it?
> Is there someone who as a clue how to solve?
> 
> I'm sorry if there is a similar post around, I've seen some but I don't
> find one where the problem is solved.
> Best regards!
> 
> *Pedro*
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Mon Dec 19 02:39:42 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 19 Dec 2016 12:39:42 +1100
Subject: [R] data manipulation
In-Reply-To: <6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
	<6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
Message-ID: <000401d25998$c585d870$50918950$@bigpond.com>


Hi David

Thanks for the info. 
As a test I am attaching it anyway

Regards

Duncan

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Monday, 19 December 2016 05:36
To: Duncan Mackay
Cc: R
Subject: Re: [R] data manipulation


> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> Hi 
> 
> Coming late to the discussion  - I deleted the original message
> I found that I have a cbe.dat that I downloaded some years ago from
> cowpertwaite's site .
> 
> And have attached it

Experience has shown that when you attach a file that you hope to be
distributed to the list it needs to have a .txt extension. Leaving it with a
.csv, .tsv, or .dat extension will cause it to be dropped by the server,
even if the contents of the file are ASCII text.

The URL I offered earlier should have made the file available:
https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul
-Cowpertwait/ts/cbe.dat

... but if there is interest in having it in the Rhelp Archive, I can attach
it.



-- 
David.
> 
> If it does not get through will do a dput as the file is only 7K
> 
> Regards
> 
> Duncan
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui
Barradas
> Sent: Thursday, 15 December 2016 01:19
> To: Farshad Fathian; r-help
> Subject: Re: [R] data manipulation
> 
> Hello,
> 
> Please cc your mails to the list.
> As for your data, your url is wrong, you need to contact Massey or maybe 
> the source of your information and get a valid internet address.
> Without one there's not much we can do.
> 
> Rui Barradas
> 
> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>> Hello,
>> 
>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>> don't access to the input data from
>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>> 
>> Regards,
>> 
>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> wrote:
>> 
>>    Hello,
>> 
>>    What do you mean by "gives me something"?
>> 
>>    xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>    <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>    Error in file(file, "rt") : cannot open the connection
>>    In addition: Warning message:
>>    In file(file, "rt") :
>>       cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>    <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>    Not Found'
>> 
>>    Rui Barradas
>> 
>> 
>>    Em 14-12-2016 11:56, John Kane via R-help escreveu:
>> 
>>        xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>        <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>        gives me something. Since we have no idea of what you are doing
>>        I don't know if the data has downloaded correctly
>> 
>>              On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>        <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>        wrote:
>> 
>> 
>>           Hi,
>> 
>> 
>> 
>>        I couldn't access to data file about PSCoperwait by
>>        http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>        <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>> 
>> 
>> 
>>        Looking forward to hearing from you,
>> 
>> 
>>              [[alternative HTML version deleted]]
>> 
>>        ______________________________________________
>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>        -- To UNSUBSCRIBE and more, see
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>        PLEASE do read the posting guide
>>        http://www.R-project.org/posting-guide.html
>>        <http://www.R-project.org/posting-guide.html>
>>        and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>>                 [[alternative HTML version deleted]]
>> 
>>        ______________________________________________
>>        R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>        -- To UNSUBSCRIBE and more, see
>>        https://stat.ethz.ch/mailman/listinfo/r-help
>>        <https://stat.ethz.ch/mailman/listinfo/r-help>
>>        PLEASE do read the posting guide
>>        http://www.R-project.org/posting-guide.html
>>        <http://www.R-project.org/posting-guide.html>
>>        and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Dec 19 03:47:19 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Dec 2016 18:47:19 -0800
Subject: [R] data manipulation
In-Reply-To: <000401d25998$c585d870$50918950$@bigpond.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
	<6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
	<000401d25998$c585d870$50918950$@bigpond.com>
Message-ID: <612D1ADD-D3B1-4FA9-A4C2-61E8523B6842@comcast.net>


> On Dec 18, 2016, at 5:39 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> 
> Hi David
> 
> Thanks for the info. 
> As a test I am attaching it anyway

Nothing allowed as an attachment by the server.

--
David.
> 
> Regards
> 
> Duncan
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Monday, 19 December 2016 05:36
> To: Duncan Mackay
> Cc: R
> Subject: Re: [R] data manipulation
> 
> 
>> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> 
>> Hi 
>> 
>> Coming late to the discussion  - I deleted the original message
>> I found that I have a cbe.dat that I downloaded some years ago from
>> cowpertwaite's site .
>> 
>> And have attached it
> 
> Experience has shown that when you attach a file that you hope to be
> distributed to the list it needs to have a .txt extension. Leaving it with a
> .csv, .tsv, or .dat extension will cause it to be dropped by the server,
> even if the contents of the file are ASCII text.
> 
> The URL I offered earlier should have made the file available:
> https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul
> -Cowpertwait/ts/cbe.dat
> 
> ... but if there is interest in having it in the Rhelp Archive, I can attach
> it.
> 
> 
> 
> -- 
> David.
>> 
>> If it does not get through will do a dput as the file is only 7K
>> 
>> Regards
>> 
>> Duncan
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui
> Barradas
>> Sent: Thursday, 15 December 2016 01:19
>> To: Farshad Fathian; r-help
>> Subject: Re: [R] data manipulation
>> 
>> Hello,
>> 
>> Please cc your mails to the list.
>> As for your data, your url is wrong, you need to contact Massey or maybe 
>> the source of your information and get a valid internet address.
>> Without one there's not much we can do.
>> 
>> Rui Barradas
>> 
>> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>>> Hello,
>>> 
>>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>>> don't access to the input data from
>>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>>> 
>>> Regards,
>>> 
>>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>> 
>>>   Hello,
>>> 
>>>   What do you mean by "gives me something"?
>>> 
>>>   xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>   <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>   Error in file(file, "rt") : cannot open the connection
>>>   In addition: Warning message:
>>>   In file(file, "rt") :
>>>      cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>   <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>>   Not Found'
>>> 
>>>   Rui Barradas
>>> 
>>> 
>>>   Em 14-12-2016 11:56, John Kane via R-help escreveu:
>>> 
>>>       xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>       <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>       gives me something. Since we have no idea of what you are doing
>>>       I don't know if the data has downloaded correctly
>>> 
>>>             On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>>       <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>>       wrote:
>>> 
>>> 
>>>          Hi,
>>> 
>>> 
>>> 
>>>       I couldn't access to data file about PSCoperwait by
>>>       http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>       <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>>> 
>>> 
>>> 
>>>       Looking forward to hearing from you,
>>> 
>>> 
>>>             [[alternative HTML version deleted]]
>>> 
>>>       ______________________________________________
>>>       R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>       -- To UNSUBSCRIBE and more, see
>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>       PLEASE do read the posting guide
>>>       http://www.R-project.org/posting-guide.html
>>>       <http://www.R-project.org/posting-guide.html>
>>>       and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>>                [[alternative HTML version deleted]]
>>> 
>>>       ______________________________________________
>>>       R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>       -- To UNSUBSCRIBE and more, see
>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>       PLEASE do read the posting guide
>>>       http://www.R-project.org/posting-guide.html
>>>       <http://www.R-project.org/posting-guide.html>
>>>       and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Dec 19 03:49:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 18 Dec 2016 18:49:12 -0800
Subject: [R] data manipulation
In-Reply-To: <2BC93929-9F76-493A-BAB7-7D554390F99E@gmail.com>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
	<6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
	<2BC93929-9F76-493A-BAB7-7D554390F99E@gmail.com>
Message-ID: <DAF72E61-E1B4-4B24-B252-1238E2B661EA@comcast.net>


> On Dec 18, 2016, at 3:31 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 18 Dec 2016, at 19:36 , David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> 
>>> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>>> 
>>> Hi 
>>> 
>>> Coming late to the discussion  - I deleted the original message
>>> I found that I have a cbe.dat that I downloaded some years ago from
>>> cowpertwaite's site .
>>> 
>>> And have attached it
>> 
>> Experience has shown that when you attach a file that you hope to be distributed to the list it needs to have a .txt extension. Leaving it with a .csv, .tsv, or .dat extension will cause it to be dropped by the server, even if the contents of the file are ASCII text.
> 
> That's not the actual mechanism, as far as I understand. If the content-type is text/plain, the server will pass it through just fine. It's the mail program at the sender end that refuses to send .csv files and friends as text/plain, based on the extension. But the net result is essentially the same.

My hypothesis is that all mail clients in common use fail to label the .csv, .dat and .tsv files as text/plain if this explanation is correct. I've been watching the "behavior" of our mail-server for several years now and have not seen _any_ files with an extension other than .txt be successfully passed to subscribers. So clarifying this issue might be possible _if_ we could find a mail client for which we were certain of its labeling characteristics. Does your mail client label such files as text/plain?


>> The URL I offered earlier should have made the file available:
>> https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul-Cowpertwait/ts/cbe.dat
>> 
>> ... but if there is interest in having it in the Rhelp Archive, I can attach it.
>> 
>> 
> 
> Would be good if someone could ask the authors about what is going on. Better if someone could check licencing issues and put the data somewhere permanent. Still better: convert them to an R package.

It appeared to me that the authors lost their entire university-hosted website. I was unable to find another email address for sending a query to Paul Cowpertwait.


-- 
David. 


> 
>> 
>> -- 
>> David.
>>> 
>>> If it does not get through will do a dput as the file is only 7K
>>> 
>>> Regards
>>> 
>>> Duncan
>>> Duncan Mackay
>>> Department of Agronomy and Soil Science
>>> University of New England
>>> Armidale NSW 2351
>>> Email: home: mackay at northnet.com.au
>>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
>>> Sent: Thursday, 15 December 2016 01:19
>>> To: Farshad Fathian; r-help
>>> Subject: Re: [R] data manipulation
>>> 
>>> Hello,
>>> 
>>> Please cc your mails to the list.
>>> As for your data, your url is wrong, you need to contact Massey or maybe 
>>> the source of your information and get a valid internet address.
>>> Without one there's not much we can do.
>>> 
>>> Rui Barradas
>>> 
>>> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>>>> Hello,
>>>> 
>>>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>>>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>>>> don't access to the input data from
>>>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>>>> 
>>>> Regards,
>>>> 
>>>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>>>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>>> 
>>>>  Hello,
>>>> 
>>>>  What do you mean by "gives me something"?
>>>> 
>>>>  xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>>  <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>>  Error in file(file, "rt") : cannot open the connection
>>>>  In addition: Warning message:
>>>>  In file(file, "rt") :
>>>>     cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>>  <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>>>  Not Found'
>>>> 
>>>>  Rui Barradas
>>>> 
>>>> 
>>>>  Em 14-12-2016 11:56, John Kane via R-help escreveu:
>>>> 
>>>>      xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>>      <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>>      gives me something. Since we have no idea of what you are doing
>>>>      I don't know if the data has downloaded correctly
>>>> 
>>>>            On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>>>      <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>>>      wrote:
>>>> 
>>>> 
>>>>         Hi,
>>>> 
>>>> 
>>>> 
>>>>      I couldn't access to data file about PSCoperwait by
>>>>      http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>>      <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>>>> 
>>>> 
>>>> 
>>>>      Looking forward to hearing from you,
>>>> 
>>>> 
>>>>            [[alternative HTML version deleted]]
>>>> 
>>>>      ______________________________________________
>>>>      R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>>      -- To UNSUBSCRIBE and more, see
>>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>>      <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>      PLEASE do read the posting guide
>>>>      http://www.R-project.org/posting-guide.html
>>>>      <http://www.R-project.org/posting-guide.html>
>>>>      and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>>>               [[alternative HTML version deleted]]
>>>> 
>>>>      ______________________________________________
>>>>      R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>>      -- To UNSUBSCRIBE and more, see
>>>>      https://stat.ethz.ch/mailman/listinfo/r-help
>>>>      <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>>      PLEASE do read the posting guide
>>>>      http://www.R-project.org/posting-guide.html
>>>>      <http://www.R-project.org/posting-guide.html>
>>>>      and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA


From a67355 at gmail.com  Mon Dec 19 00:49:25 2016
From: a67355 at gmail.com (Pedro Montenegro)
Date: Sun, 18 Dec 2016 23:49:25 +0000
Subject: [R] h5r package: cannot find hdf5
In-Reply-To: <CAF1jk_mUS3ZQgrqv=Zj1-iaPWREQurtcX-gzctUQVHC+rKO+5A@mail.gmail.com>
References: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>
	<CAF1jk_mUS3ZQgrqv=Zj1-iaPWREQurtcX-gzctUQVHC+rKO+5A@mail.gmail.com>
Message-ID: <CAModdv6nrBKXyehid2+AHAi8oTnVa0aPH21Z7gtzzhqKripS5g@mail.gmail.com>

Hello!

It worked! Thank you!
Now I have another issue, when I try to input a cmp.h5 it reports the
following error:

> cmpH5 <-
PacBioCmpH5("/home/user/Documents/MFG-share/pacbio/GI.usequality.cmp.h5")
HDF5-DIAG: Error detected in HDF5 (1.8.4-patch1) thread 140365256419200:
  #000: ../../../src/H5F.c line 1514 in H5Fopen(): unable to open file
    major: File accessability
    minor: Unable to open file
  #001: ../../../src/H5F.c line 1309 in H5F_open(): unable to read
superblock
    major: File accessability
    minor: Read failed
  #002: ../../../src/H5Fsuper.c line 305 in H5F_super_read(): unable to
find file signature
    major: File accessability
    minor: Not an HDF5 file
  #003: ../../../src/H5Fsuper.c line 153 in H5F_locate_signature(): unable
to find a valid file signature
    major: Low-level I/O
    minor: Unable to initialize object
Error in .local(.Object, ...) :
  Problem opening file:
/home/user/Documents/MFG-share/pacbio/GI.usequality.cmp.h5

Any idea what can be happening? It must be about the libraries since the
file appears to be OK.

Best regards



*Pedro*
2016-12-18 19:06 GMT+00:00 Dominik Schneider <dosc3612 at colorado.edu>:

> Pedro,
> I've only worked with netcdf4 but I imagine your issue is similar to one's
> I've had:
> I think you can:
> 1. add your hdf5 lib directory to the LD_LIBRARY_PATH
> http://grokbase.com/t/r/r-help/10at4wcjfq/r-ncdf4-package-in
> stallation-in-r
> 2. you can specify the direct path to lib and include directories for the
> hdf5 library:
>
> e.g.
>
> install.packages("/home/user/Downloads/RNetCDF_1.6.1-2.tar.gz",
> repos = NULL,
> type="source",
> dependencies=FALSE,
> configure.args="--with-netcdf-include=/usr/local/netcdf-4.2.1-build/include --with-netcdf-lib=/usr/local/netcdf-4.2.1-build/lib")
>
> http://stackoverflow.com/questions/11319698/how-to-install-r-packages-rnetcdf-and-ncdf-on-ubuntu
>
>
> On Sat, Dec 17, 2016 at 5:09 PM, Pedro Montenegro <a67355 at gmail.com>
> wrote:
>
>> I'm new to R and Linux, and I have an issue I didn't see solved on the
>> internet.
>>
>> I'm using Ubuntu Mate and installed R version 2.11 since the current
>> version does not support R-kinetics.
>> What happens is that I have hdf5 headers and libraries installed
>>
>> $ whereis hdf5
>> hdf5: /usr/include/hdf5
>>
>> But when I'm installing the package inside R (install.packages) or outside
>> R (R CMD INSTALL) the program reports the following error:
>>
>> > install.packages('h5r')
>> Warning in install.packages("h5r") :
>>   argument 'lib' is missing: using
>> '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
>> Warning message:
>> In getDependencies(pkgs, dependencies, available, lib) :
>>   package ?h5r? is not available
>> > install.packages('/home/pedro/h5r_1.4.7.tar.gz',repos=NULL,t
>> ype='source')
>> Warning in install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos =
>> NULL,  :
>>   argument 'lib' is missing: using
>> '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
>> * installing *source* package ?h5r? ...
>> checking for gcc... gcc
>> checking for C compiler default output file name... a.out
>> checking whether the C compiler works... yes
>> checking whether we are cross compiling... no
>> checking for suffix of executables...
>> checking for suffix of object files... o
>> checking whether we are using the GNU C compiler... yes
>> checking whether gcc accepts -g... yes
>> checking for gcc option to accept ISO C89... none needed
>>
>>
>> checking for library containing inflate... -lz
>> checking for library containing H5open... no
>> configure: error: Can't find HDF5
>> ERROR: configuration failed for package ?h5r?
>> * removing ?/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11/h5r?
>> Warning message:
>> In install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
>>   installation of package '/home/pedro/h5r_1.4.7.tar.gz' had non-zero exit
>> status.
>>
>> I tried to reinstall HDF5, R and even the whole OS and do it all over
>> again. Also tried to add the library to the environment table, do it from
>> the library's directory and nothing works.
>>
>> Is there someone who had the same error and was able to solve it?
>> Is there someone who as a clue how to solve?
>>
>> I'm sorry if there is a similar post around, I've seen some but I don't
>> find one where the problem is solved.
>> Best regards!
>>
>> *Pedro*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From jatin.kala.jk at gmail.com  Mon Dec 19 02:08:47 2016
From: jatin.kala.jk at gmail.com (Jatin Kala)
Date: Mon, 19 Dec 2016 09:08:47 +0800
Subject: [R] [FORGED]  help using ggplot for contour plot
In-Reply-To: <5fd04fb6-9c40-008d-db5e-239fd93c2476@stat.auckland.ac.nz>
References: <27c381b0-75e4-6a03-805f-e2e92c4bda5b@gmail.com>
	<5fd04fb6-9c40-008d-db5e-239fd93c2476@stat.auckland.ac.nz>
Message-ID: <df1eec43-663e-8d67-ce74-421c59c18301@gmail.com>

Hi,

It seems that the mail system removed my attachments.

Here are Dropbox links to the files:

R-Script:

https://www.dropbox.com/s/hgabbgzfeiddpsk/ggmap_attempt_GF.R?dl=0

Data being read in:

https://www.dropbox.com/s/xdvnztc1s89qvgz/ALL_HOURLY_NOX_Processed?dl=0

test_filled_contour_plot.png:

https://www.dropbox.com/s/jv0k5bfngundqrb/test_filled_countour_plot.png?dl=0

GF_test.png:

https://www.dropbox.com/s/tkoclttnin1l7a9/GF_test.png?dl=0

Cheers,

jatin




On 19/12/16 4:29 am, Paul Murrell wrote:
> Hi
>
> It is difficult to help because the data needed to run your code is 
> not provided.
>
> This blog post looks like it contains some useful information ...
>
> http://www.exegetic.biz/blog/2013/12/contour-and-density-layers-with-ggmap/ 
>
>
> Paul
>
> On 16/12/16 19:03, Jatin Kala wrote:
>> Hi R community,
>> I am trying to do a contour plot of (longitude, latitude, 
>> concentration).
>> This is easy enough using filled.contour.
>> However, i am trying to do the same contour plot using ggplot, and
>> overlaying the plot on google-map.
>> The script and data being read is attached.
>>  test_filled_contour_plot.png is what contour.filled gives me.
>> GF_test.png is the output from using ggplot. Something is going wrong,
>> but i can't figure out what, and it's doing my head-in....
>> Any help would be greatly appreciated.
>> Cheers,
>> Jatin
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From dosc3612 at colorado.edu  Mon Dec 19 03:16:07 2016
From: dosc3612 at colorado.edu (Dominik Schneider)
Date: Mon, 19 Dec 2016 02:16:07 +0000
Subject: [R] h5r package: cannot find hdf5
In-Reply-To: <3586ED1B-93E4-436F-8802-492E56CE932C@comcast.net>
References: <CAModdv7=BLFbCvid6QwL8K_1NFMAQJoxdTUjff0JmXoOKf38fQ@mail.gmail.com>
	<3586ED1B-93E4-436F-8802-492E56CE932C@comcast.net>
Message-ID: <CAF1jk_n85-vzZ2Oa_Fb5p_3BUPK9RdjD_PNwm6Mkv-3BW7C4SQ@mail.gmail.com>

Sorry I'm not sure what that error means.
Dominik

On Sun, Dec 18, 2016 at 17:21 David Winsemius <dwinsemius at comcast.net>
wrote:

>
>
> > On Dec 17, 2016, at 5:09 PM, Pedro Montenegro <a67355 at gmail.com> wrote:
>
> >
>
> > I'm new to R and Linux, and I have an issue I didn't see solved on the
>
> > internet.
>
> >
>
> > I'm using Ubuntu Mate and installed R version 2.11 since the current
>
> > version does not support R-kinetics.
>
> > What happens is that I have hdf5 headers and libraries installed
>
> >
>
> > $ whereis hdf5
>
> > hdf5: /usr/include/hdf5
>
> >
>
> > But when I'm installing the package inside R (install.packages) or
> outside
>
> > R (R CMD INSTALL) the program reports the following error:
>
> >
>
> >> install.packages('h5r')
>
> > Warning in install.packages("h5r") :
>
>
>
> There is also a bioconductor package that provides an HDF5 interface:
>
>
>
> http://bioconductor.org/packages/release/bioc/html/rhdf5.html
>
>
>
> I have no idea whether it's config files might include a more extensive
> search for installed versions of HDF5. Unlike h5r it is available for all
> three major forks of R.
>
>
>
> --
>
> David.
>
> >  argument 'lib' is missing: using
>
> > '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
>
> > Warning message:
>
> > In getDependencies(pkgs, dependencies, available, lib) :
>
> >  package ?h5r? is not available
>
> >>
> install.packages('/home/pedro/h5r_1.4.7.tar.gz',repos=NULL,type='source')
>
> > Warning in install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos =
> NULL,  :
>
> >  argument 'lib' is missing: using
>
> > '/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11'
>
> > * installing *source* package ?h5r? ...
>
> > checking for gcc... gcc
>
> > checking for C compiler default output file name... a.out
>
> > checking whether the C compiler works... yes
>
> > checking whether we are cross compiling... no
>
> > checking for suffix of executables...
>
> > checking for suffix of object files... o
>
> > checking whether we are using the GNU C compiler... yes
>
> > checking whether gcc accepts -g... yes
>
> > checking for gcc option to accept ISO C89... none needed
>
> >
>
> >
>
> > checking for library containing inflate... -lz
>
> > checking for library containing H5open... no
>
> > configure: error: Can't find HDF5
>
> > ERROR: configuration failed for package ?h5r?
>
> > * removing ?/home/pedro/R/x86_64-unknown-linux-gnu-library/2.11/h5r?
>
> > Warning message:
>
> > In install.packages("/home/pedro/h5r_1.4.7.tar.gz", repos = NULL,  :
>
> >  installation of package '/home/pedro/h5r_1.4.7.tar.gz' had non-zero exit
>
> > status.
>
> >
>
> > I tried to reinstall HDF5, R and even the whole OS and do it all over
>
> > again. Also tried to add the library to the environment table, do it from
>
> > the library's directory and nothing works.
>
> >
>
> > Is there someone who had the same error and was able to solve it?
>
> > Is there someone who as a clue how to solve?
>
> >
>
> > I'm sorry if there is a similar post around, I've seen some but I don't
>
> > find one where the problem is solved.
>
> > Best regards!
>
> >
>
> > *Pedro*
>
> >
>
> >       [[alternative HTML version deleted]]
>
> >
>
> > ______________________________________________
>
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> > https://stat.ethz.ch/mailman/listinfo/r-help
>
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> David Winsemius
>
> Alameda, CA, USA
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Mon Dec 19 12:06:36 2016
From: Ramgad82 at gmx.net (Dagmar)
Date: Mon, 19 Dec 2016 12:06:36 +0100
Subject: [R] qqplot: bar outline colour?
In-Reply-To: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>
References: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>
Message-ID: <763d80ad-095b-9087-e110-0681f6288199@gmx.net>

Dear all,

Apearantly noone in this great mailing list could help me with my 
problem a couple of days ago. As I still struggle with part of the 
problem I try to explain my problem differently:

# This is my example data:
     exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie", 
"Leon","Leon","Leon"),
recordedTime=c("03.01.2011","04.01.2011","05.01.2011",
"04.01.2011","05.01.2011","06.01.2011"),
                      knownstate =c("breeding","moulting","moulting",
                              "breeding","breeding",NA))
     exdatframe
     str(exdatframe)
     exdatframeT <- as.POSIXct 
(strptime(as.character(exdatframe$recordedTime),"%d.%m.%Y"))
     exdatframeT
     exdatframe2 <- cbind(exdatframe, exdatframeT)
     exdatframe2$recordedTime <-NULL
     exdatframe2
     str(exdatframe2)

# I made this plot:

n <- ggplot(exdatframe2, aes(exdatframeT,Name)) + 
geom_tile(aes(fill=knownstate), colour="black", height=0.5)
n

# my question: How do I get a bar outline colour around all of breeding 
that is not interupted each day (I only want vertical bars between 
different "knownstates")

# Help would be terribly much appreciated!!!!


From ulrik.stervbo at gmail.com  Mon Dec 19 14:58:25 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Mon, 19 Dec 2016 13:58:25 +0000
Subject: [R] qqplot: bar outline colour?
In-Reply-To: <763d80ad-095b-9087-e110-0681f6288199@gmx.net>
References: <bf11169e-9db7-03e4-f2ee-2d55d65deb8f@gmx.net>
	<763d80ad-095b-9087-e110-0681f6288199@gmx.net>
Message-ID: <CAKVAULNya98AsLWjZ4eHA=_DEhvdsPS9Q_3LDTO397jAbzJUPA@mail.gmail.com>

Hi Dagmar,

I hope this code below does what you want.

I use two data.frames. One is for the tiles and one is for the lines to
show changes in state. The 'reduce_entries' function is the heart of things
and can probably be improved.

Ulrik

library(ggplot2)
library(lubridate)
library(dplyr)
library(purrr)

exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie",
"Leon","Leon","Leon"),

recordedTime=c("03.01.2011","04.01.2011","05.01.2011","04.01.2011","05.01.2011","06.01.2011"),
  knownstate =c("breeding","moulting","moulting","breeding","breeding",NA))

exdatframe <- exdatframe %>%
  # Convert to date
  mutate(recordedTime = dmy(recordedTime))

reduce_entries <- function(.data){
  for(i in seq_along(1:nrow(.data))){
    this_row <- .data[i, ]
    next_row <- .data[i + 1, ]

    if(!is.na(next_row$knownstate)){
      if(this_row$knownstate == next_row$knownstate){
        this_row$recordedTime <- next_row$recordedTime
      }
    }

   .data[i, ] <- this_row
  }
  .data %>% distinct()
}

state_delimiter <- exdatframe %>%
  split(.$Name) %>%
  map_df(reduce_entries) %>%
  # Get the numerical values for the Names
  mutate(name.y = group_indices_(., .dots = "Name")) %>%
  mutate(name.y.start = name.y - 0.4, name.y.end = name.y + 0.4)

exdatframe %>%
  ggplot() +
  aes(x = recordedTime, y = Name, fill = knownstate) +
  geom_tile() +
  geom_segment(aes(x = recordedTime + 0.5, xend = recordedTime + 0.5,
    y = name.y.start, yend = name.y.end), colour = "black", size = 2,
    data = state_delimiter)

On Mon, 19 Dec 2016 at 12:09 Dagmar <Ramgad82 at gmx.net> wrote:

> Dear all,
>
> Apearantly noone in this great mailing list could help me with my
> problem a couple of days ago. As I still struggle with part of the
> problem I try to explain my problem differently:
>
> # This is my example data:
>      exdatframe <- data.frame(Name=c("Ernie","Ernie","Ernie",
> "Leon","Leon","Leon"),
> recordedTime=c("03.01.2011","04.01.2011","05.01.2011",
> "04.01.2011","05.01.2011","06.01.2011"),
>                       knownstate =c("breeding","moulting","moulting",
>                               "breeding","breeding",NA))
>      exdatframe
>      str(exdatframe)
>      exdatframeT <- as.POSIXct
> (strptime(as.character(exdatframe$recordedTime),"%d.%m.%Y"))
>      exdatframeT
>      exdatframe2 <- cbind(exdatframe, exdatframeT)
>      exdatframe2$recordedTime <-NULL
>      exdatframe2
>      str(exdatframe2)
>
> # I made this plot:
>
> n <- ggplot(exdatframe2, aes(exdatframeT,Name)) +
> geom_tile(aes(fill=knownstate), colour="black", height=0.5)
> n
>
> # my question: How do I get a bar outline colour around all of breeding
> that is not interupted each day (I only want vertical bars between
> different "knownstates")
>
> # Help would be terribly much appreciated!!!!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From florent.angly at gmail.com  Mon Dec 19 09:25:58 2016
From: florent.angly at gmail.com (Florent Angly)
Date: Mon, 19 Dec 2016 09:25:58 +0100
Subject: [R] Bugzilla account request
Message-ID: <CAOiMVK0W+Pg=CPvTJgKVdTumeSHarssm-vaJrq_kBJ9pB4yw_A@mail.gmail.com>

Hi,

I have identified a couple of bugs that I would like to file on
https://bugs.r-project.org/ .

Reading the archives, I found that the bugzilla account creation is not
automated anymore and must be mannually requested on this mailing list.

Can an administrator please create an account for me?

Florent

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Mon Dec 19 16:01:44 2016
From: glennmschultz at me.com (Glenn Schultz)
Date: Mon, 19 Dec 2016 15:01:44 +0000 (GMT)
Subject: [R] getting data from a webpage
Message-ID: <0b794e28-6d8a-4d30-a0f0-eda00e1b624d@me.com>

All,

I was getting data swap rate data from the St. Louis Fed FRED database via the FRED API. ?ICE stopped reporting to FRED and now I must get the data from the ICE website. ?I would like to use httr to get the data but I really don't know much about website design. ?I think the form redirects but I am not sure that is the case much less how to identify what website the form redirects to. ?I used the developer and inspect elements to come up with the below which failed miserably. ?In addition, I purchase the book Automated Data Collection with R which has not been to useful helping me to understand how to navigate pages using forms and redirects.

Can anyone provide a good reference to understanding how to get data from websites using forms and redirects. ?Specifically,

How find the actual webpage that on must submit the POST request.
How to the find the redirected page which really has the data.

Best,
Glenn

library(httr)
#get initial cookies
h <- handle("https://www.theice.com/")
GET(handle = h)
POST(url = "https://www.theice.com/marketdata/reports/180",
body = list(reportDate = "15-Dec-2016", 
SeriesNameAnRunCode_chosen = "USD Rates 1100"),
encode = "form",
handle = h)
page <- GET(url= "https://www.theice.com/marketdata/reports/icebenchmarkadmin/ISDAFIXHistoricalRates.shtml", 
handle = h)

From roger.bos at rothschild.com  Mon Dec 19 17:48:53 2016
From: roger.bos at rothschild.com (Bos, Roger)
Date: Mon, 19 Dec 2016 16:48:53 +0000
Subject: [R] getting data from a webpage
In-Reply-To: <0b794e28-6d8a-4d30-a0f0-eda00e1b624d@me.com>
References: <0b794e28-6d8a-4d30-a0f0-eda00e1b624d@me.com>
Message-ID: <0765308CD028654885F30322557308D8667B5F1A@NYCSM0208.rth.ad.rothschild.com>

Glenn,

R Studio did a webinar on Web Scraping using the rvest package that made it look really easy.  I haven't gotten around to using it yet, but the video should be on their website somewhere.  The link below is the PDF of the slides.  It should be education and will probably give you what you need to know to get the data you need:

https://github.com/rstudio/webinars/blob/master/32-Web-Scraping/02-Web-Scraping.pdf



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Glenn Schultz
Sent: Monday, December 19, 2016 10:02 AM
To: R Help R
Subject: [R] getting data from a webpage

All,

I was getting data swap rate data from the St. Louis Fed FRED database via the FRED API.  ICE stopped reporting to FRED and now I must get the data from the ICE website.  I would like to use httr to get the data but I really don't know much about website design.  I think the form redirects but I am not sure that is the case much less how to identify what website the form redirects to.  I used the developer and inspect elements to come up with the below which failed miserably.  In addition, I purchase the book Automated Data Collection with R which has not been to useful helping me to understand how to navigate pages using forms and redirects.

Can anyone provide a good reference to understanding how to get data from websites using forms and redirects.  Specifically,

How find the actual webpage that on must submit the POST request.
How to the find the redirected page which really has the data.

Best,
Glenn

library(httr)
#get initial cookies
h <- handle("https://www.theice.com/")
GET(handle = h)
POST(url = "https://www.theice.com/marketdata/reports/180",
body = list(reportDate = "15-Dec-2016", SeriesNameAnRunCode_chosen = "USD Rates 1100"), encode = "form", handle = h) page <- GET(url= "https://www.theice.com/marketdata/reports/icebenchmarkadmin/ISDAFIXHistoricalRates.shtml",
handle = h)
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



This message and any attachments are for the intended recipient?s use only. This message may contain confidential, proprietary or legally privileged information. No right to confidential or privileged treatment of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately notify the sender by e-mail, delete the message, any attachments and all copies from your system and destroy any hard copies. You must not, directly or indirectly, use, disclose, distribute, print or copy any part of this message or any attachments if you are not the intended recipient.





From dwinsemius at comcast.net  Mon Dec 19 17:41:32 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 19 Dec 2016 08:41:32 -0800
Subject: [R] Bugzilla account request
In-Reply-To: <CAOiMVK0W+Pg=CPvTJgKVdTumeSHarssm-vaJrq_kBJ9pB4yw_A@mail.gmail.com>
References: <CAOiMVK0W+Pg=CPvTJgKVdTumeSHarssm-vaJrq_kBJ9pB4yw_A@mail.gmail.com>
Message-ID: <0701B546-466A-4BA7-B797-34060DB6F440@comcast.net>


> On Dec 19, 2016, at 12:25 AM, Florent Angly <florent.angly at gmail.com> wrote:
> 
> Hi,
> 
> I have identified a couple of bugs that I would like to file on
> https://bugs.r-project.org/ .
> 
> Reading the archives, I found that the bugzilla account creation is not
> automated anymore and must be mannually requested on this mailing list.

I'm not sure what part of what "archive" was the source of this misinformation, but what I read in "the archives" (which I'm defining broadly by my use of Markmail in this instance) is that you are supposed to contact the administrator individually for permission. 

http://markmail.org/search/?q=list%3Aorg.r-project+bugzilla+account

Almost all of the bug discussion is on R-devel rather than r-help. My understanding is that suspected bugs should be posted to that mailing list unless you are a very experienced R-user with tested bug-fix code that you intend to submit.

I've confirmed my sometimes hazy memory by reading the Posting Guide and following embedded link regarding bug reporting to:

https://www.r-project.org/bugs.html

> 
> Can an administrator please create an account for me?
> 
> Florent
> 
> 	[[alternative HTML version deleted]]

The fact that you are posting in HTML is an additional black mark against you. Rhelp is a plain text mailing list. You should definitely read the Posting Guide before proceeding.


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From oma.gonzales at gmail.com  Mon Dec 19 22:25:07 2016
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 19 Dec 2016 16:25:07 -0500
Subject: [R] Regex to stop at first capital letter after sequence
Message-ID: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>

I have the following strings:

[1] "PPA 06 - Promo Vasito"      [2] "PPA 05 - Cuentos"
[3] "PPA 04 - Promo vasito"      [4] "PPA 03 - Promoci?n escolar"
[5] "PPA - Saluda a tu pediatra" [6] "PPL - Dia del Pediatra"

*Desired result*:

[1] "Promo Vasito"                 "Cuentos"                "Promo vasito"

[4] "Promoci?n escolar"      "Saluda a tu pediatra"   "Dia del Pediatra"


*First attemp*:

After this line:

mead_nov$`Nombre del anuncio` <- gsub("(PPA.*)([A-Z].*)", "\\2",
mead_nov$`Nombre del anuncio`)

I get these:

[1] "Vasito"                 [2] "Cuentos"                [3] "Promo
vasito"
[4] "Promoci?n escolar"      [5] "Saluda a tu pediatra"   [6] "PPL - Dia
del Pediatra"


*Second attemp:*

mead_nov$`Nombre del anuncio` <- gsub("(PPA|PPL.*)([A-Z].*)", "\\2",
mead_nov$`Nombre del anuncio`)

I get this:

[1] "PPA 06 - Promo Vasito"     [2] "PPA 05 - Cuentos"
[3] "PPA 04 - Promo vasito"      [3] "PPA 03 - Promoci?n escolar"
[5] "PPA - Saluda a tu pediatra" [6] "Pediatra"


Thank you for your help.

	[[alternative HTML version deleted]]


From mauriciocornejo at yahoo.com  Mon Dec 19 22:47:53 2016
From: mauriciocornejo at yahoo.com (Mauricio Cornejo)
Date: Mon, 19 Dec 2016 21:47:53 +0000 (UTC)
Subject: [R] Power of t test for unequal variances?
In-Reply-To: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
References: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
Message-ID: <1197452454.8682574.1482184073720@mail.yahoo.com>

Is there a function similar to stats::power.t.test that can handle unequal variances from two samples?
I noticed that stats::t.test has an argument for indicating whether or not to treat the two sample variances as equal.? Wondering why stats::power.t.test doesn?t have that option.
Thanks,Mauricio
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Dec 19 23:01:15 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 19 Dec 2016 14:01:15 -0800
Subject: [R] Regex to stop at first capital letter after sequence
In-Reply-To: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>
References: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>
Message-ID: <74055798-AC8E-401B-B9EA-EE4CE834EFF5@comcast.net>


> On Dec 19, 2016, at 1:25 PM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:
> 
> I have the following strings:
> 
> [1] "PPA 06 - Promo Vasito"      [2] "PPA 05 - Cuentos"
> [3] "PPA 04 - Promo vasito"      [4] "PPA 03 - Promoci?n escolar"
> [5] "PPA - Saluda a tu pediatra" [6] "PPL - Dia del Pediatra"
> 
> *Desired result*:
> 
> [1] "Promo Vasito"                 "Cuentos"                "Promo vasito"
> 
> [4] "Promoci?n escolar"      "Saluda a tu pediatra"   "Dia del Pediatra"

All this assumes you are passing a character vector to sub. The combination of your subject line and the example are a bit underspecified. Here's two solution one of which is delivering everything beginning with the last cap after the (last) dash and the other is delivering everything after but not including the last <dash><spc> sequence:

> sub("^.+[-].+(?=[A-Z])", "" , dat, perl=TRUE)  # need perl=TRUE for PCRE look-ahead
[1] "Vasito"               "Cuentos"             
[3] "Promo vasito"         "Promoci?n escolar"   
[5] "Saluda a tu pediatra" "Pediatra"       

Greedy matching above, ungreedy; set by '(?U)' below:

> sub("(?U)^.+[-].+(?=[A-Z])", "" , dat, perl=TRUE)
[1] "Promo Vasito"         "Cuentos"             
[3] "Promo vasito"         "Promoci?n escolar"   
[5] "Saluda a tu pediatra" "Dia del Pediatra"    


> sub("^.+[-][ ]", "" , dat)   # character classes to define sequence.
[1] "Promo Vasito"         "Cuentos"             
[3] "Promo vasito"         "Promoci?n escolar"   
[5] "Saluda a tu pediatra" "Dia del Pediatra" 
> 
> 
> *First attemp*:
> 
> After this line:
> 
> mead_nov$`Nombre del anuncio` <- gsub("(PPA.*)([A-Z].*)", "\\2",
> mead_nov$`Nombre del anuncio`)
> 
> I get these:
> 
> [1] "Vasito"                 [2] "Cuentos"                [3] "Promo
> vasito"
> [4] "Promoci?n escolar"      [5] "Saluda a tu pediatra"   [6] "PPL - Dia
> del Pediatra"
> 
> 
> *Second attemp:*
> 
> mead_nov$`Nombre del anuncio` <- gsub("(PPA|PPL.*)([A-Z].*)", "\\2",
> mead_nov$`Nombre del anuncio`)
> 
> I get this:
> 
> [1] "PPA 06 - Promo Vasito"     [2] "PPA 05 - Cuentos"
> [3] "PPA 04 - Promo vasito"      [3] "PPA 03 - Promoci?n escolar"
> [5] "PPA - Saluda a tu pediatra" [6] "Pediatra"
> 
> 
> Thank you for your help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Mon Dec 19 23:01:46 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 19 Dec 2016 17:01:46 -0500
Subject: [R] Regex to stop at first capital letter after sequence
In-Reply-To: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>
References: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>
Message-ID: <CAM_vjuk_-fhG1mp8-ia9kh4wSYAkenJoVH2ruz5UMWWH=Su1bg@mail.gmail.com>

Hi,

If your actual data are of the same form as your sample data, why not just:
x <- c("PPA 06 - Promo Vasito", "PPA 05 - Cuentos",
"PPA 04 - Promo vasito", "PPA 03 - Promoci?n escolar",
"PPA - Saluda a tu pediatra", "PPL - Dia del Pediatra")

sub("^.* - ", "", x)
[1] "Promo Vasito"         "Cuentos"              "Promo vasito"
[4] "Promoci?n escolar"    "Saluda a tu pediatra" "Dia del Pediatra"



On Mon, Dec 19, 2016 at 4:25 PM, Omar Andr? Gonz?les D?az
<oma.gonzales at gmail.com> wrote:
> I have the following strings:
>
> [1] "PPA 06 - Promo Vasito"      [2] "PPA 05 - Cuentos"
> [3] "PPA 04 - Promo vasito"      [4] "PPA 03 - Promoci?n escolar"
> [5] "PPA - Saluda a tu pediatra" [6] "PPL - Dia del Pediatra"
>
> *Desired result*:
>
> [1] "Promo Vasito"                 "Cuentos"                "Promo vasito"
>
> [4] "Promoci?n escolar"      "Saluda a tu pediatra"   "Dia del Pediatra"
>
>
> *First attemp*:
>
> After this line:
>
> mead_nov$`Nombre del anuncio` <- gsub("(PPA.*)([A-Z].*)", "\\2",
> mead_nov$`Nombre del anuncio`)
>
> I get these:
>
> [1] "Vasito"                 [2] "Cuentos"                [3] "Promo
> vasito"
> [4] "Promoci?n escolar"      [5] "Saluda a tu pediatra"   [6] "PPL - Dia
> del Pediatra"
>
>
> *Second attemp:*
>
> mead_nov$`Nombre del anuncio` <- gsub("(PPA|PPL.*)([A-Z].*)", "\\2",
> mead_nov$`Nombre del anuncio`)
>
> I get this:
>
> [1] "PPA 06 - Promo Vasito"     [2] "PPA 05 - Cuentos"
> [3] "PPA 04 - Promo vasito"      [3] "PPA 03 - Promoci?n escolar"
> [5] "PPA - Saluda a tu pediatra" [6] "Pediatra"
>
>
> Thank you for your help.
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From bgunter.4567 at gmail.com  Mon Dec 19 23:03:19 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Dec 2016 14:03:19 -0800
Subject: [R] Regex to stop at first capital letter after sequence
In-Reply-To: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>
References: <CAM-xyZjHkTfndpF2_uiKOr2iPJOKPM=woTBThcVktz_Qvcf0=g@mail.gmail.com>
Message-ID: <CAGxFJbRqrqyiby0QwPiAiM4_vMmDTNApQ7YKEuFxBDcQ+g1stA@mail.gmail.com>

You don't need a regex.

?strsplit

Something like:

> y <-c("PPA 06 - Promo Vasito", "PPA 05 - Cuentos")

> sapply(strsplit(y, "-"),"[",2)
[1] " Promo Vasito" " Cuentos"

You may have to add spaces around your "-" , as you failed to supply
data so I cannot be sure what you have.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 19, 2016 at 1:25 PM, Omar Andr? Gonz?les D?az
<oma.gonzales at gmail.com> wrote:
> I have the following strings:
>
> [1] "PPA 06 - Promo Vasito"      [2] "PPA 05 - Cuentos"
> [3] "PPA 04 - Promo vasito"      [4] "PPA 03 - Promoci?n escolar"
> [5] "PPA - Saluda a tu pediatra" [6] "PPL - Dia del Pediatra"
>
> *Desired result*:
>
> [1] "Promo Vasito"                 "Cuentos"                "Promo vasito"
>
> [4] "Promoci?n escolar"      "Saluda a tu pediatra"   "Dia del Pediatra"
>
>
> *First attemp*:
>
> After this line:
>
> mead_nov$`Nombre del anuncio` <- gsub("(PPA.*)([A-Z].*)", "\\2",
> mead_nov$`Nombre del anuncio`)
>
> I get these:
>
> [1] "Vasito"                 [2] "Cuentos"                [3] "Promo
> vasito"
> [4] "Promoci?n escolar"      [5] "Saluda a tu pediatra"   [6] "PPL - Dia
> del Pediatra"
>
>
> *Second attemp:*
>
> mead_nov$`Nombre del anuncio` <- gsub("(PPA|PPL.*)([A-Z].*)", "\\2",
> mead_nov$`Nombre del anuncio`)
>
> I get this:
>
> [1] "PPA 06 - Promo Vasito"     [2] "PPA 05 - Cuentos"
> [3] "PPA 04 - Promo vasito"      [3] "PPA 03 - Promoci?n escolar"
> [5] "PPA - Saluda a tu pediatra" [6] "Pediatra"
>
>
> Thank you for your help.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From btyner at gmail.com  Mon Dec 19 23:54:04 2016
From: btyner at gmail.com (Benjamin Tyner)
Date: Mon, 19 Dec 2016 17:54:04 -0500
Subject: [R] modify the imported version of a function
In-Reply-To: <ba28b839-ea77-e4be-f9f0-4f7b45e387b0@gmail.com>
References: <ba28b839-ea77-e4be-f9f0-4f7b45e387b0@gmail.com>
Message-ID: <70350a92-01e5-136c-3369-5153271ff12c@gmail.com>

Figured it out...in case it is useful to others:

    > library(lint)

    > lint.enclos <- parent.env(asNamespace("lint"))

    > stopifnot(all(c("perl", "regex") %in% ls(lint.enclos)))

    > lint.enclos$perl
    function (pattern)
    {
        message("perl is deprecated. Please use regexp instead")
        regex(pattern)
    }
    <environment: namespace:stringr>

    > unlockBinding("perl", lint.enclos)

    > lint.enclos$perl <- lint.enclos$regex

    > lint.enclos$perl
    function (pattern, ignore_case = FALSE, multiline = FALSE, comments 
= FALSE,
        dotall = FALSE, ...)
    {
        options <- stri_opts_regex(case_insensitive = ignore_case,
            multiline = multiline, comments = comments, dotall = dotall,
            ...)
        structure(pattern, options = options, class = c("regex",
            "pattern", "character"))
    }
    <environment: namespace:stringr>



On 12/16/2016 06:06 PM, Benjamin Tyner wrote:
> Hi
>
> I saw on the assignInNamespace help page, that it changes "the copy in 
> the namespace, but not any copies already exported from the namespace, 
> in particular an object of that name in the package (if already 
> attached) and any copies already imported into other namespaces."
>
> So now I'm wondering, whether there is a way to modify such copies 
> already imported into other namespaces? For a concrete example, 
> consider the lint package (now archived on CRAN) which includes a 
> function check_pattern, which calls stringr:::perl, which has been 
> deprecated in newer versions:
>
>    > stringr:::perl
>    function (pattern)
>    {
>        message("perl is deprecated. Please use regexp instead")
>        regex(pattern)
>    }
>    <environment: namespace:stringr>
>
> so, what if I wanted to directly replace stringr:::perl with 
> stringr:::regex, in such a way that lint::check_pattern sees the 
> replacement? Is there a way, preferably without having to attach 
> stringr to the search path?
>
> (I'm mostly just interested in learning about how namespace imports 
> actually work; of course in this toy example one could use 
> suppressMessages to hide that deprecation message).
>
> Regards
> Ben


From dulcalma at bigpond.com  Tue Dec 20 00:03:36 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 20 Dec 2016 10:03:36 +1100
Subject: [R] data manipulation
In-Reply-To: <612D1ADD-D3B1-4FA9-A4C2-61E8523B6842@comcast.net>
References: <584fbe20.ca57c20a.eb3d8.0e34@mx.google.com>
	<1768303695.2867148.1481716595402@mail.yahoo.com>
	<58513719.5000309@sapo.pt>
	<CAPOnVdhk1nzsCNZKK4wGgA9Rr5gy+VR2BfKc12qAPGP91_2NBg@mail.gmail.com>
	<585154B9.8020002@sapo.pt>
	<001101d258e2$cdb9ba40$692d2ec0$@bigpond.com>
	<6D2E6A05-F90C-4D88-A9AD-1F21C41D4721@comcast.net>
	<000401d25998$c585d870$50918950$@bigpond.com>
	<612D1ADD-D3B1-4FA9-A4C2-61E8523B6842@comcast.net>
Message-ID: <000c01d25a4c$21360b50$63a221f0$@bigpond.com>

Hi David

Thank you for the information

I accidentally deleted my reply coming in from Rhelp and I have not  had a
look at at the  list to see what happened.

I thought that I had set everything up correctly when I had to switch to my
new ISP and use MS Outlook for my email. 

Below is a dput of the file 

dput(cbe)
structure(list(choc = c(1451L, 2037L, 2477L, 2785L, 2994L, 2681L, 
3098L, 2708L, 2517L, 2445L, 2087L, 1801L, 1216L, 2173L, 2286L, 
3121L, 3458L, 3511L, 3524L, 2767L, 2744L, 2603L, 2527L, 1846L, 
1066L, 2327L, 3066L, 3048L, 3806L, 4042L, 3583L, 3438L, 2957L, 
2885L, 2744L, 1837L, 1447L, 2504L, 3248L, 3098L, 4318L, 3561L, 
3316L, 3379L, 2717L, 2354L, 2445L, 1542L, 1606L, 2590L, 3588L, 
3202L, 4704L, 4005L, 3810L, 3488L, 2781L, 2944L, 2817L, 1960L, 
1937L, 2903L, 3357L, 3552L, 4581L, 3905L, 4581L, 4037L, 3345L, 
3175L, 2808L, 2050L, 1719L, 3143L, 3756L, 4776L, 4540L, 4309L, 
4563L, 3506L, 3665L, 3361L, 3094L, 2440L, 1633L, 2935L, 4159L, 
4159L, 4894L, 4921L, 4577L, 4155L, 3851L, 3429L, 3370L, 2726L, 
1674L, 3257L, 4731L, 4481L, 5443L, 5566L, 5044L, 4781L, 4014L, 
3561L, 3801L, 2685L, 1805L, 3756L, 4227L, 4595L, 5702L, 4681L, 
4395L, 4459L, 4191L, 3742L, 3279L, 2468L, 1742L, 3366L, 3633L, 
3701L, 4926L, 4522L, 5275L, 4717L, 4114L, 3851L, 3493L, 2654L, 
2168L, 3561L, 4305L, 4413L, 5307L, 5361L, 4948L, 4472L, 3846L, 
3715L, 3343L, 2939L, 1615L, 3497L, 3915L, 4858L, 4962L, 4504L, 
4767L, 4291L, 4091L, 4164L, 3915L, 3130L, 1696L, 3887L, 4749L, 
4781L, 5089L, 5484L, 5072L, 4611L, 4117L, 3910L, 4252L, 3624L, 
1678L, 3851L, 5021L, 4581L, 6195L, 5338L, 4909L, 4640L, 3706L, 
4113L, 3879L, 3411L, 2043L, 3736L, 4490L, 3715L, 5623L, 4671L, 
5591L, 5461L, 4795L, 4846L, 4843L, 3278L, 2411L, 4278L, 4639L, 
4559L, 6404L, 4851L, 6480L, 6394L, 5752L, 4718L, 4659L, 3842L, 
2873L, 5556L, 5389L, 6135L, 6707L, 5220L, 6249L, 5281L, 4192L, 
4867L, 3752L, 3492L, 1979L, 4584L, 5139L, 5044L, 5501L, 5044L, 
5035L, 5167L, 4650L, 5298L, 4373L, 3941L, 2334L, 4381L, 5665L, 
4393L, 5232L, 5876L, 5900L, 5704L, 4718L, 4650L, 4446L, 3061L, 
2155L, 4274L, 4695L, 4362L, 4889L, 5370L, 5072L, 4985L, 3978L, 
4139L, 3995L, 3025L, 1949L, 4357L, 4638L, 3994L, 6174L, 5656L, 
4411L, 5504L, 4463L, 4458L, 4528L, 2830L, 1843L, 5042L, 5348L, 
5257L, 6699L, 5388L, 6001L, 5966L, 4845L, 4507L, 4214L, 3460L, 
1833L, 4978L, 6464L, 5820L, 6447L, 6191L, 6628L, 5452L, 5295L, 
5080L, 5564L, 3965L, 2062L, 5099L, 6162L, 5529L, 6416L, 6382L, 
5624L, 5785L, 4644L, 5331L, 5143L, 4596L, 2180L, 5786L, 5840L, 
5666L, 6360L, 6219L, 6082L, 5653L, 5726L, 5049L, 5859L, 4091L, 
2167L, 6480L, 7375L, 6583L, 7251L, 6730L, 6428L, 5228L, 4716L, 
6101L, 5753L, 4000L, 2691L, 5898L, 6526L, 5840L, 6650L, 5717L, 
7236L, 6523L, 5729L, 6004L, 5950L, 4690L, 3687L, 7791L, 7153L, 
6434L, 7850L, 6809L, 8379L, 6914L, 6919L, 7265L, 6994L, 5503L, 
3782L, 7502L, 8119L, 7292L, 6886L, 7049L, 7977L, 8519L, 6680L, 
7994L, 7047L, 5782L, 3771L, 7906L, 8970L, 6077L, 7919L, 7340L, 
7791L, 7368L, 8255L, 7816L, 7476L, 6696L, 4484L, 8274L, 8866L, 
8572L, 9176L, 8645L, 8265L, 9558L, 7037L, 9101L, 8180L, 7072L, 
3832L, 7253L, 8667L, 7658L, 8859L, 7291L, 7529L, 8715L, 8450L, 
9085L, 8350L, 7080L), beer = c(96.3, 84.4, 91.2, 81.9, 80.5, 
70.4, 74.8, 75.9, 86.3, 98.7, 100.9, 113.8, 89.8, 84.4, 87.2, 
85.6, 72, 69.2, 77.5, 78.1, 94.3, 97.7, 100.2, 116.4, 97.1, 93, 
96, 80.5, 76.1, 69.9, 73.6, 92.6, 94.2, 93.5, 108.5, 109.4, 105.1, 
92.5, 97.1, 81.4, 79.1, 72.1, 78.7, 87.1, 91.4, 109.9, 116.3, 
113, 100, 84.8, 94.3, 87.1, 90.3, 72.4, 84.9, 92.7, 92.2, 114.9, 
112.5, 118.3, 106, 91.2, 96.6, 96.3, 88.2, 70.2, 86.5, 88.2, 
102.8, 119.1, 119.2, 125.1, 106.1, 102.1, 105.2, 101, 84.3, 87.5, 
92.7, 94.4, 113, 113.9, 122.9, 132.7, 106.9, 96.6, 127.3, 98.2, 
100.2, 89.4, 95.3, 104.2, 106.4, 116.2, 135.9, 134, 104.6, 107.1, 
123.5, 98.8, 98.6, 90.6, 89.1, 105.2, 114, 122.1, 138, 142.2, 
116.4, 112.6, 123.8, 103.6, 113.9, 98.6, 95, 116, 113.9, 127.5, 
131.4, 145.9, 131.5, 131, 130.5, 118.9, 114.3, 85.7, 104.6, 105.1, 
117.3, 142.5, 140, 159.8, 131.2, 125.4, 126.5, 119.4, 113.5, 
98.7, 114.5, 113.8, 133.1, 143.4, 137.3, 165.2, 126.9, 124, 135.7, 
130, 109.4, 117.8, 120.3, 121, 132.3, 142.9, 147.4, 175.9, 132.6, 
123.7, 153.3, 134, 119.6, 116.2, 118.6, 130.7, 129.3, 144.4, 
163.2, 179.4, 128.1, 138.4, 152.7, 120, 140.5, 116.2, 121.4, 
127.8, 143.6, 157.6, 166.2, 182.3, 153.1, 147.6, 157.7, 137.2, 
151.5, 98.7, 145.8, 151.7, 129.4, 174.1, 197, 193.9, 164.1, 142.8, 
157.9, 159.2, 162.2, 123.1, 130, 150.1, 169.4, 179.7, 182.1, 
194.3, 161.4, 169.4, 168.8, 158.1, 158.5, 135.3, 149.3, 143.4, 
142.2, 188.4, 166.2, 199.2, 182.7, 145.2, 182.1, 158.7, 141.6, 
132.6, 139.6, 147, 166.6, 157, 180.4, 210.2, 159.8, 157.8, 168.2, 
158.4, 152, 142.2, 137.2, 152.6, 166.8, 165.6, 198.6, 201.5, 
170.7, 164.4, 179.7, 157, 168, 139.3, 138.6, 153.4, 138.9, 172.1, 
198.4, 217.8, 173.7, 153.8, 175.6, 147.1, 160.3, 135.2, 148.8, 
151, 148.2, 182.2, 189.2, 183.1, 170, 158.4, 176.1, 156.2, 153.2, 
117.9, 149.8, 156.6, 166.7, 156.8, 158.6, 210.8, 203.6, 175.2, 
168.7, 155.9, 147.3, 137, 141.1, 167.4, 160.2, 191.9, 174.4, 
208.2, 159.4, 161.1, 172.1, 158.4, 114.6, 159.6, 159.7, 159.4, 
160.7, 165.5, 205, 205.2, 141.6, 148.1, 184.9, 132.5, 137.3, 
135.5, 121.7, 166.1, 146.8, 162.8, 186.8, 185.5, 151.5, 158.1, 
143, 151.2, 147.6, 130.7, 137.5, 146.1, 133.6, 167.9, 181.9, 
202, 166.5, 151.3, 146.2, 148.3, 144.7, 123.6, 151.6, 133.9, 
137.4, 181.6, 182, 190, 161.2, 155.5, 141.9, 164.6, 136.2, 126.8, 
152.5, 126.6, 150.1, 186.3, 147.5, 200.4, 177.2, 127.4, 177.1, 
154.4, 135.2, 126.4, 147.3, 140.6, 152.3, 151.2, 172.2, 215.3, 
154.1, 159.3, 160.4, 151.9, 148.4, 139.6, 148.2, 153.5, 145.1, 
183.7, 210.5, 203.3, 153.3, 144.3, 169.6, 143.7, 160, 135.5, 
141.7, 159.9, 145.6, 183.4, 198.1, 186.7, 171.9, 150.5, 163, 
153.6, 152.8, 135.4, 148.3, 148.3, 133.5, 193.8, 208.4, 197), 
    elec = c(1497L, 1463L, 1648L, 1595L, 1777L, 1824L, 1994L, 
    1835L, 1787L, 1699L, 1633L, 1645L, 1597L, 1577L, 1709L, 1756L, 
    1936L, 2052L, 2105L, 2016L, 1914L, 1925L, 1824L, 1765L, 1721L, 
    1752L, 1914L, 1857L, 2159L, 2195L, 2287L, 2276L, 2096L, 2055L, 
    2004L, 1924L, 1851L, 1839L, 2019L, 1937L, 2270L, 2251L, 2382L, 
    2364L, 2129L, 2110L, 2072L, 1980L, 1995L, 1932L, 2171L, 2162L, 
    2489L, 2424L, 2641L, 2630L, 2324L, 2412L, 2284L, 2186L, 2184L, 
    2144L, 2379L, 2383L, 2717L, 2774L, 3051L, 2891L, 2613L, 2600L, 
    2493L, 2410L, 2390L, 2463L, 2616L, 2734L, 2970L, 3125L, 3342L, 
    3207L, 2964L, 2919L, 2764L, 2732L, 2622L, 2698L, 2950L, 2895L, 
    3200L, 3408L, 3679L, 3473L, 3154L, 3107L, 3052L, 2918L, 2786L, 
    2739L, 3125L, 3033L, 3486L, 3661L, 3927L, 3851L, 3456L, 3390L, 
    3280L, 3166L, 3080L, 3069L, 3340L, 3310L, 3798L, 3883L, 4191L, 
    4213L, 3766L, 3628L, 3520L, 3322L, 3250L, 3287L, 3552L, 3440L, 
    4153L, 4265L, 4655L, 4492L, 4051L, 3967L, 3807L, 3639L, 3647L, 
    3560L, 3929L, 3858L, 4485L, 4697L, 4977L, 4675L, 4596L, 4491L, 
    4127L, 4144L, 4014L, 3994L, 4320L, 4400L, 5002L, 5091L, 5471L, 
    5193L, 4997L, 4737L, 4546L, 4498L, 4350L, 4206L, 4743L, 4582L, 
    5191L, 5457L, 5891L, 5618L, 5158L, 5030L, 4800L, 4654L, 4453L, 
    4440L, 4945L, 4788L, 5425L, 5706L, 6061L, 5846L, 5242L, 5408L, 
    5114L, 5042L, 5008L, 4657L, 5359L, 5193L, 5891L, 5980L, 6390L, 
    6366L, 5756L, 5640L, 5429L, 5398L, 5413L, 5141L, 5695L, 5554L, 
    6369L, 6592L, 7107L, 6917L, 6353L, 6205L, 5830L, 5646L, 5379L, 
    5489L, 5824L, 5907L, 6482L, 6795L, 7028L, 6776L, 6274L, 6362L, 
    5940L, 5958L, 5769L, 5887L, 6367L, 6165L, 6868L, 7201L, 7601L, 
    7581L, 7090L, 6841L, 6408L, 6435L, 6176L, 6138L, 6717L, 6470L, 
    7312L, 7763L, 8171L, 7788L, 7311L, 6679L, 6704L, 6724L, 6552L, 
    6427L, 7105L, 6869L, 7683L, 8082L, 8555L, 8386L, 7553L, 7398L, 
    7112L, 6886L, 7077L, 6820L, 7426L, 7143L, 8261L, 8240L, 8977L, 
    8991L, 8026L, 7911L, 7510L, 7381L, 7366L, 7414L, 7824L, 7524L, 
    8279L, 8707L, 9486L, 8973L, 8231L, 8206L, 7927L, 7999L, 7834L, 
    7521L, 8284L, 7999L, 8940L, 9381L, 10078L, 9796L, 8471L, 
    8572L, 8150L, 8168L, 8166L, 7903L, 8606L, 8071L, 9178L, 9873L, 
    10476L, 9296L, 8818L, 8697L, 8381L, 8293L, 7942L, 8001L, 
    8744L, 8397L, 9115L, 9773L, 10358L, 9849L, 9083L, 9143L, 
    8800L, 8741L, 8492L, 8795L, 9354L, 8796L, 10072L, 10174L, 
    11326L, 10744L, 9806L, 9740L, 9373L, 9244L, 9407L, 8827L, 
    9880L, 9364L, 10580L, 10899L, 11687L, 11280L, 10208L, 10212L, 
    9725L, 9721L, 9846L, 9407L, 10265L, 9970L, 10801L, 11246L, 
    12167L, 11578L, 10645L, 10613L, 10104L, 10348L, 10263L, 9973L, 
    10803L, 10409L, 11458L, 11845L, 12559L, 12070L, 11221L, 11338L, 
    10761L, 11012L, 10923L, 10790L, 11427L, 10788L, 11772L, 12104L, 
    12634L, 12772L, 11764L, 11956L, 11646L, 11750L, 11485L, 11198L, 
    12265L, 11704L, 12419L, 13259L, 13945L, 13839L, 12387L, 12546L, 
    12038L, 11977L, 12336L, 11793L, 12877L, 11923L, 13306L, 13988L, 
    14002L, 14338L, 12867L, 12761L, 12449L, 12658L)), .Names = c("choc", 
"beer", "elec"), class = "data.frame", row.names = c(NA, -396L
))

Regards

Duncan

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Monday, 19 December 2016 13:47
To: Duncan Mackay
Cc: R
Subject: Re: [R] data manipulation


> On Dec 18, 2016, at 5:39 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
> 
> Hi David
> 
> Thanks for the info. 
> As a test I am attaching it anyway

Nothing allowed as an attachment by the server.

--
David.
> 
> Regards
> 
> Duncan
> 
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Monday, 19 December 2016 05:36
> To: Duncan Mackay
> Cc: R
> Subject: Re: [R] data manipulation
> 
> 
>> On Dec 17, 2016, at 7:57 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>> 
>> Hi 
>> 
>> Coming late to the discussion  - I deleted the original message
>> I found that I have a cbe.dat that I downloaded some years ago from
>> cowpertwaite's site .
>> 
>> And have attached it
> 
> Experience has shown that when you attach a file that you hope to be
> distributed to the list it needs to have a .txt extension. Leaving it with
a
> .csv, .tsv, or .dat extension will cause it to be dropped by the server,
> even if the contents of the file are ASCII text.
> 
> The URL I offered earlier should have made the file available:
>
https://web.archive.org/web/20130501161812/http://staff.elena.aut.ac.nz/Paul
> -Cowpertwait/ts/cbe.dat
> 
> ... but if there is interest in having it in the Rhelp Archive, I can
attach
> it.
> 
> 
> 
> -- 
> David.
>> 
>> If it does not get through will do a dput as the file is only 7K
>> 
>> Regards
>> 
>> Duncan
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rui
> Barradas
>> Sent: Thursday, 15 December 2016 01:19
>> To: Farshad Fathian; r-help
>> Subject: Re: [R] data manipulation
>> 
>> Hello,
>> 
>> Please cc your mails to the list.
>> As for your data, your url is wrong, you need to contact Massey or maybe 
>> the source of your information and get a valid internet address.
>> Without one there's not much we can do.
>> 
>> Rui Barradas
>> 
>> Em 14-12-2016 12:16, Farshad Fathian escreveu:
>>> Hello,
>>> 
>>> Thanks for your e-mail. I was reading "Introductory Time Series with R"
>>> by PS. Cowperwait. I am going to run the R codes in this book, but I
>>> don't access to the input data from
>>> ("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>> <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>") website.
>>> 
>>> Regards,
>>> 
>>> On Wed, Dec 14, 2016 at 3:42 PM, Rui Barradas <ruipbarradas at sapo.pt
>>> <mailto:ruipbarradas at sapo.pt>> wrote:
>>> 
>>>   Hello,
>>> 
>>>   What do you mean by "gives me something"?
>>> 
>>>   xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>   <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>   Error in file(file, "rt") : cannot open the connection
>>>   In addition: Warning message:
>>>   In file(file, "rt") :
>>>      cannot open URL 'http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>   <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>': HTTP status was '404
>>>   Not Found'
>>> 
>>>   Rui Barradas
>>> 
>>> 
>>>   Em 14-12-2016 11:56, John Kane via R-help escreveu:
>>> 
>>>       xx <- read.csv("http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>       <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>")
>>>       gives me something. Since we have no idea of what you are doing
>>>       I don't know if the data has downloaded correctly
>>> 
>>>             On Tuesday, December 13, 2016 1:38 PM, Farshad Fathian
>>>       <farshad.fathian at gmail.com <mailto:farshad.fathian at gmail.com>>
>>>       wrote:
>>> 
>>> 
>>>          Hi,
>>> 
>>> 
>>> 
>>>       I couldn't access to data file about PSCoperwait by
>>>       http://massey.ac.nz/~pscoperwait/ts/cbe.dat
>>>       <http://massey.ac.nz/~pscoperwait/ts/cbe.dat>.
>>> 
>>> 
>>> 
>>>       Looking forward to hearing from you,
>>> 
>>> 
>>>             [[alternative HTML version deleted]]
>>> 
>>>       ______________________________________________
>>>       R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>       -- To UNSUBSCRIBE and more, see
>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>       PLEASE do read the posting guide
>>>       http://www.R-project.org/posting-guide.html
>>>       <http://www.R-project.org/posting-guide.html>
>>>       and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>>                [[alternative HTML version deleted]]
>>> 
>>>       ______________________________________________
>>>       R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>>       -- To UNSUBSCRIBE and more, see
>>>       https://stat.ethz.ch/mailman/listinfo/r-help
>>>       <https://stat.ethz.ch/mailman/listinfo/r-help>
>>>       PLEASE do read the posting guide
>>>       http://www.R-project.org/posting-guide.html
>>>       <http://www.R-project.org/posting-guide.html>
>>>       and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Dec 20 00:31:02 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 19 Dec 2016 15:31:02 -0800
Subject: [R] Power of t test for unequal variances?
In-Reply-To: <1197452454.8682574.1482184073720@mail.yahoo.com>
References: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
	<1197452454.8682574.1482184073720@mail.yahoo.com>
Message-ID: <584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>


> On Dec 19, 2016, at 1:47 PM, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
> 
> Is there a function similar to stats::power.t.test that can handle unequal variances from two samples?
> I noticed that stats::t.test has an argument for indicating whether or not to treat the two sample variances as equal.  Wondering why stats::power.t.test doesn?t have that option.
> Thanks,Mauricio
> 	[[alternative HTML version deleted]]

Because R was developed by statisticians for statisticians and they assumed those other statisticians would know how to extend its functions when needed. But R-help is not advertised as the place to ask such questions when you don't have the statistical skills. (You might want to look at the code of `t.test` to see how you might construct appropriate arguments for `power.t.test` in the situation you imagine. Seems to me it should be fairly straightforward. `power.t.test` is built around the non-central t-distribution and solves a uniroot problem for the missing parameter among  n, delta, power, sd, and sig.level, given the other 4 parameters.)


-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Dec 20 04:14:12 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 19 Dec 2016 19:14:12 -0800
Subject: [R] Power of t test for unequal variances?
In-Reply-To: <584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>
References: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
	<1197452454.8682574.1482184073720@mail.yahoo.com>
	<584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>
Message-ID: <01D64C1E-0E4A-483B-8D52-0D70BC7761D9@comcast.net>


> On Dec 19, 2016, at 3:31 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Dec 19, 2016, at 1:47 PM, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
>> 
>> Is there a function similar to stats::power.t.test that can handle unequal variances from two samples?
>> I noticed that stats::t.test has an argument for indicating whether or not to treat the two sample variances as equal.  Wondering why stats::power.t.test doesn?t have that option.
>> Thanks,Mauricio
>> 	[[alternative HTML version deleted]]
> 
> Because R was developed by statisticians for statisticians and they assumed those other statisticians would know how to extend its functions when needed. But R-help is not advertised as the place to ask such questions when you don't have the statistical skills. (You might want to look at the code of `t.test` to see how you might construct appropriate arguments for `power.t.test` in the situation you imagine. Seems to me it should be fairly straightforward. `power.t.test` is built around the non-central t-distribution and solves a uniroot problem for the missing parameter among  n, delta, power, sd, and sig.level, given the other 4 parameters.)
> 

The other R-specific response might have been to teach you to use R's functions to do a bit of searching:

 ?available.packages
 old.opt <- options(available_packages_filters =
                               c("R_version",   "CRAN", "duplicates"))
 # saved options from prior state

 avail <- available.packages()
 names(avail)
NULL   # oops, not a list.
> str( avail)
 chr [1:9731, 1:17] "A3" "abbyyR" "abc" "ABCanalysis" ...
 - attr(*, "dimnames")=List of 2
  ..$ : chr [1:9731] "A3" "abbyyR" "abc" "ABCanalysis" ...
  ..$ : chr [1:17] "Package" "Version" "Priority" "Depends" ...
 colnames(avail)
#--- result---
 [1] "Package"               "Version"              
 [3] "Priority"              "Depends"              
 [5] "Imports"               "LinkingTo"            
 [7] "Suggests"              "Enhances"             
 [9] "License"               "License_is_FOSS"      
[11] "License_restricts_use" "OS_type"              
[13] "Archs"                 "MD5sum"               
[15] "NeedsCompilation"      "File"                 
[17] "Repository"        
#---------   


 avail[ grepl("pow" ,avail[ ,"Package"] , ignore.case=TRUE), "Package"]
                asypow           bivarRIpower           clusterPower 
              "asypow"         "bivarRIpower"         "clusterPower" 
             easypower                   fpow              longpower 
           "easypower"                 "fpow"            "longpower" 
                matpow               mnormpow               PharmPow 
              "matpow"             "mnormpow"             "PharmPow" 
                powell                  PoweR            Power2Stage 
              "powell"                "PoweR"          "Power2Stage" 
         powerAnalysis          powerbydesign   powerGWASinteraction 
       "powerAnalysis"        "powerbydesign" "powerGWASinteraction" 
              poweRlaw         powerMediation               powerpkg 
            "poweRlaw"       "powerMediation"             "powerpkg" 
             powerplus           powerSurvEpi              PowerTOST 
           "powerplus"         "powerSurvEpi"            "PowerTOST" 
              PowerUpR       rPowerSampleSize      twoStageGwasPower 
            "PowerUpR"     "rPowerSampleSize"    "twoStageGwasPower" 

A more usable result:

 names( avail[ grepl("pow" ,avail[ ,"Package"] , ignore.case=TRUE), "Package"] )
 [1] "asypow"               "bivarRIpower"        
 [3] "clusterPower"         "easypower"           
 [5] "fpow"                 "longpower"           
 [7] "matpow"               "mnormpow"            
 [9] "PharmPow"             "powell"              
[11] "PoweR"                "Power2Stage"         
[13] "powerAnalysis"        "powerbydesign"       
[15] "powerGWASinteraction" "poweRlaw"            
[17] "powerMediation"       "powerpkg"            
[19] "powerplus"            "powerSurvEpi"        
[21] "PowerTOST"            "PowerUpR"            
[23] "rPowerSampleSize"     "twoStageGwasPower"   

 options(old.opt)  # reset options to default values

So you may find additional user-contributed power-oriented packages.



> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From abrogard at yahoo.com  Tue Dec 20 02:08:33 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Tue, 20 Dec 2016 01:08:33 +0000 (UTC)
Subject: [R] Why Does R Print out strange record?
References: <722307751.1990840.1482196113858.ref@mail.yahoo.com>
Message-ID: <722307751.1990840.1482196113858@mail.yahoo.com>

I have this bit of code:
rates=read.csv("Rates2.csv")
attach(rates)
mysize <- nrow(rates)
count <- 0
for(i in 1:(mysize - 3)) {
#print(i)
thisday <- Date[i]
thisone <- Int[i+1] - Int[i]
nextone <- Int[i+2] - Int[i]
lastone <- thisone + nextone
lastone <- lastone/6.5
lastone <- lastone * 1000

#print("thisone")
#print(thisone)
#print("nextone")
#print(nextone)

if (lastone >0){
print(thisday)
print("dollars saved per $100,000")
print(lastone)
count = count + 1
}
}
which generally works alright until I put the last bit in about 'thisday'
since then I get a display with such as this in it:
[1] "dollars saved per $100,000"
[1] 9.230769
[1] Feb-2012
689 Levels: Apr-1959 Apr-1960 Apr-1961 Apr-1962 ... Sep-2015
[1] "dollars saved per $100,000"
[1] 18.46154
[1] Jun-2015
689 Levels: Apr-1959 Apr-1960 Apr-1961 Apr-1962 ... Sep-2015
[1] "dollars saved per $100,000"
[1] 21.53846

This word 'Levels'? is not present in the data.? 

Can anyone help, tell me what is happening here?


?================================

Can you handle truth ? 

Barbara Walker: Woman's Encyclopedia of Myths and Secrets

What it is really about:
https://www.youtube.com/watch?v=sYKAgAfYJZE

The bald truth:
https://www.youtube.com/watch?v=kevNDOCbKxE

https://www.youtube.com/watch?v=fbfdsMdbcfA

Sanity:
Those terrible Russians:
https://www.youtube.com/watch?v=VZsjoiFfpXM
	[[alternative HTML version deleted]]


From heather.h.kettrey at vanderbilt.edu  Tue Dec 20 05:01:30 2016
From: heather.h.kettrey at vanderbilt.edu (Heather Kettrey)
Date: Mon, 19 Dec 2016 22:01:30 -0600
Subject: [R] Exploratory Factor Analysis with Multiply Imputed Data
Message-ID: <CAGcnpaTcbW_XC0ZJkPaQu_h32CmetapR8BR-NZpXEuhkbH71Dw@mail.gmail.com>

Hello,

I am trying to conduct exploratory factor analysis (EFA) with multiply
imputed data. I used Amelia II to create 40 imputed datasets and have saved
the imputed data in .csv format (I saved the imputations both as a single
file with all imputations and as 40 separate files - each containing one
set of imputations).

I plan to use the psych package to conduct 40 separate factor analyses
(without rotation) and then need to conduct consensus rotation of the 40
factor loading matrices that these separate EFAs produce.

I read that the promin() function in the PCovR package is capable of
consensus rotation of multiple (unrotated) factor loading matrices, but I
cannot figure out how to input multiple matrices into this function.

Does anyone know how to use the promin() function to conduct consensus
rotation - or have any other suggestions of how to conduct EFA with
multiply imputed data in R? Any help would be greatly appreciated.

Thanks!

Heather

-- 
Heather Hensman Kettrey, PhD
Research Associate, Peabody Research Institute (PRI)
Senior Researcher, Meta-Analysis Center at PRI
Vanderbilt University

	[[alternative HTML version deleted]]


From rmh at temple.edu  Tue Dec 20 05:59:47 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 19 Dec 2016 23:59:47 -0500
Subject: [R] Why Does R Print out strange record?
In-Reply-To: <722307751.1990840.1482196113858@mail.yahoo.com>
References: <722307751.1990840.1482196113858.ref@mail.yahoo.com>
	<722307751.1990840.1482196113858@mail.yahoo.com>
Message-ID: <CAGx1TMCCZg5u-PtK+Ms56cYFbx0Mc6=g8Qk8LBxy7K9yTqSzyQ@mail.gmail.com>

You have read your Date variable in as a character variable, which was
coerced to a factor.
You probably wanted the values to be interpreted as dates.  example of
what to do is below.
Note that the date-factor levels are sorted alphabetically, which is
almost certainly not what you want.

In addition, please do not use HTML mail.  R-help is plain-text list
and R code often gets scrambled beyond recognition.

Attaching a data.frame is very bad style, and will get you into
trouble in the future.  Again, see below for a recommendation.



rates <- read.csv(text="
    Date, Int
Feb-2012, .04
Mar-2012, .045
Apr-2012, .042
May-2012, .038
Jun-2012, .051
",
header=TRUE,
colClasses=c("character","numeric"))

rates
sapply(rates, class)


## dates are one of the most difficult computing concepts to get
## right.  your dates are month and year, not including day-of-month,
## and are therefore even more difficult.  I am putting them all on
## the first of the month, and forcing a common time zone to bypass
## the daylight savings time problems.

rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y", tz="UTC")
## you will need to read
## ?as.POSIXct
## ?strptime

## the rest of your calculations can be done more easily with
vectorized arithmetic.

mysize <- nrow(rates)
rates$thisone <- c(diff(rates$Int), NA)
rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
rates

On Mon, Dec 19, 2016 at 8:08 PM, arthur brogard via R-help
<r-help at r-project.org> wrote:
> I have this bit of code:
> rates=read.csv("Rates2.csv")
> attach(rates)
> mysize <- nrow(rates)
> count <- 0
> for(i in 1:(mysize - 3)) {
> #print(i)
> thisday <- Date[i]
> thisone <- Int[i+1] - Int[i]
> nextone <- Int[i+2] - Int[i]
> lastone <- thisone + nextone
> lastone <- lastone/6.5
> lastone <- lastone * 1000
>
> #print("thisone")
> #print(thisone)
> #print("nextone")
> #print(nextone)
>
> if (lastone >0){
> print(thisday)
> print("dollars saved per $100,000")
> print(lastone)
> count = count + 1
> }
> }
> which generally works alright until I put the last bit in about 'thisday'
> since then I get a display with such as this in it:
> [1] "dollars saved per $100,000"
> [1] 9.230769
> [1] Feb-2012
> 689 Levels: Apr-1959 Apr-1960 Apr-1961 Apr-1962 ... Sep-2015
> [1] "dollars saved per $100,000"
> [1] 18.46154
> [1] Jun-2015
> 689 Levels: Apr-1959 Apr-1960 Apr-1961 Apr-1962 ... Sep-2015
> [1] "dollars saved per $100,000"
> [1] 21.53846
>
> This word 'Levels'  is not present in the data.
>
> Can anyone help, tell me what is happening here?
>
>
>  ================================
>
> Can you handle truth ?
>
> Barbara Walker: Woman's Encyclopedia of Myths and Secrets
>
> What it is really about:
> https://www.youtube.com/watch?v=sYKAgAfYJZE
>
> The bald truth:
> https://www.youtube.com/watch?v=kevNDOCbKxE
>
> https://www.youtube.com/watch?v=fbfdsMdbcfA
>
> Sanity:
> Those terrible Russians:
> https://www.youtube.com/watch?v=VZsjoiFfpXM
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Tue Dec 20 08:54:42 2016
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Tue, 20 Dec 2016 08:54:42 +0100
Subject: [R] Power of t test for unequal variances?
In-Reply-To: <584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>
References: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
	<1197452454.8682574.1482184073720@mail.yahoo.com>
	<584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>
Message-ID: <f83b324b-22a0-36a8-63b1-3ba100c7808e@math.uni-giessen.de>

Hello, Mauricio,

maybe pwr.t2n.test() in package pwr or/and n.ttest() in package
samplesize do what you need/want.

  Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109            http://www.uni-giessen.de/eichner
---------------------------------------------------------------------

Am 20.12.2016 um 00:31 schrieb David Winsemius:
>
>> On Dec 19, 2016, at 1:47 PM, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
>>
>> Is there a function similar to stats::power.t.test that can handle unequal variances from two samples?
>> I noticed that stats::t.test has an argument for indicating whether or not to treat the two sample variances as equal.  Wondering why stats::power.t.test doesn?t have that option.
>> Thanks,Mauricio
>> 	[[alternative HTML version deleted]]
>
> Because R was developed by statisticians for statisticians and they assumed those other statisticians would know how to extend its functions when needed. But R-help is not advertised as the place to ask such questions when you don't have the statistical skills. (You might want to look at the code of `t.test` to see how you might construct appropriate arguments for `power.t.test` in the situation you imagine. Seems to me it should be fairly straightforward. `power.t.test` is built around the non-central t-distribution and solves a uniroot problem for the missing parameter among  n, delta, power, sd, and sig.level, given the other 4 parameters.)
>
>


From florent.angly at gmail.com  Tue Dec 20 11:50:53 2016
From: florent.angly at gmail.com (Florent Angly)
Date: Tue, 20 Dec 2016 11:50:53 +0100
Subject: [R] Bugzilla account request
In-Reply-To: <0701B546-466A-4BA7-B797-34060DB6F440@comcast.net>
References: <CAOiMVK0W+Pg=CPvTJgKVdTumeSHarssm-vaJrq_kBJ9pB4yw_A@mail.gmail.com>
	<0701B546-466A-4BA7-B797-34060DB6F440@comcast.net>
Message-ID: <CAOiMVK3gJNMVuRELdzXsNcxnGixRLHiBNCoE7ynh4qzYHFq8FA@mail.gmail.com>

The gist of my post was that accounts must be requested through a
mailing list. As you correctly clarified, though, the R-devel list
should be used, not R-help.
I am quite sure of the bugs I have identified, but will report them on
R-devel for good form.
Best regards,
Florent

On 19 December 2016 at 17:41, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Dec 19, 2016, at 12:25 AM, Florent Angly <florent.angly at gmail.com> wrote:
>>
>> Hi,
>>
>> I have identified a couple of bugs that I would like to file on
>> https://bugs.r-project.org/ .
>>
>> Reading the archives, I found that the bugzilla account creation is not
>> automated anymore and must be mannually requested on this mailing list.
>
> I'm not sure what part of what "archive" was the source of this misinformation, but what I read in "the archives" (which I'm defining broadly by my use of Markmail in this instance) is that you are supposed to contact the administrator individually for permission.
>
> http://markmail.org/search/?q=list%3Aorg.r-project+bugzilla+account
>
> Almost all of the bug discussion is on R-devel rather than r-help. My understanding is that suspected bugs should be posted to that mailing list unless you are a very experienced R-user with tested bug-fix code that you intend to submit.
>
> I've confirmed my sometimes hazy memory by reading the Posting Guide and following embedded link regarding bug reporting to:
>
> https://www.r-project.org/bugs.html
>
>>
>> Can an administrator please create an account for me?
>>
>> Florent
>>
>>       [[alternative HTML version deleted]]
>
> The fact that you are posting in HTML is an additional black mark against you. Rhelp is a plain text mailing list. You should definitely read the Posting Guide before proceeding.
>
>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From attenka at utu.fi  Tue Dec 20 09:37:56 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Tue, 20 Dec 2016 10:37:56 +0200
Subject: [R] Getting scan() -command to work during the program run
Message-ID: <5858EDE4.6040409@utu.fi>

Hi,

How to get scan(file="") command to ask my input from the keyboard?

If I put the command straight to the console it works

 > X1 <- scan(n=1)
1: 22
Read 1 item

but as a part of a program it just continues without asking my value?

 > X1 <- scan(n=1)
1:
Read 0 items

Yours,

Atte Tenkanen


From bjpmodi2016 at gmail.com  Tue Dec 20 16:04:19 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Tue, 20 Dec 2016 09:04:19 -0600
Subject: [R] Is it possible to create such graph - Which packages can come
	handy?
Message-ID: <CAPq=xQAv17dGYK1XDYcvgjPo3NxWeLN0p0Us0qYc1XJjX1e9Dg@mail.gmail.com>

Hello Gurus,
I intend to build attached reference graph in R(r.png). Could you give
me some ideas on how it can be done, if at all possible?

Basically, I would like to build a Histogram along Y axis for
different  respective X axis ranges.
As shown in the input.png file, there is a value of EUR for every Lw,
a simple X-Y scatter plot.
Now, what if I build ranges of x axis values, i.e 2000-4000,
4000-6000, 6000-8000 etc and analyze the histograms of Y axis values
for those ranges?

Thanks!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Input.PNG
Type: image/png
Size: 60125 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161220/348a3c86/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: R.PNG
Type: image/png
Size: 42855 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161220/348a3c86/attachment-0001.png>

From bgunter.4567 at gmail.com  Tue Dec 20 16:19:42 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Dec 2016 07:19:42 -0800
Subject: [R] Getting scan() -command to work during the program run
In-Reply-To: <5858EDE4.6040409@utu.fi>
References: <5858EDE4.6040409@utu.fi>
Message-ID: <CAGxFJbTwim9rWmZAZ467_K3CByeJCmaRfcOMrtOOUO9BrgspAA@mail.gmail.com>

??

> f <- function() {X <- scan(n =1); X}
> f()
1: 3
Read 1 item



-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 20, 2016 at 12:37 AM, Atte Tenkanen <attenka at utu.fi> wrote:
> Hi,
>
> How to get scan(file="") command to ask my input from the keyboard?
>
> If I put the command straight to the console it works
>
>> X1 <- scan(n=1)
> 1: 22
> Read 1 item
>
> but as a part of a program it just continues without asking my value?
>
>> X1 <- scan(n=1)
> 1:
> Read 0 items
>
> Yours,
>
> Atte Tenkanen
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Tue Dec 20 16:49:41 2016
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 20 Dec 2016 09:49:41 -0600
Subject: [R] Is it possible to create such graph - Which packages can
	come handy?
In-Reply-To: <CAPq=xQAv17dGYK1XDYcvgjPo3NxWeLN0p0Us0qYc1XJjX1e9Dg@mail.gmail.com>
References: <CAPq=xQAv17dGYK1XDYcvgjPo3NxWeLN0p0Us0qYc1XJjX1e9Dg@mail.gmail.com>
Message-ID: <CAN5YmCFn3ufAJ-ZihF8xu_MpiuacNKhYX5tS+4i66vuSBqjVwA@mail.gmail.com>

?You might find the code in this blog post helpful.
http://theanalyticalminds.blogspot.com/2015/03/part-3a-plotting-with-ggplot2.html

Scroll down to "Analysing the temperature by month - violin geom with
jittered points overlaid?".

This shows a series of violin plots, which is another way to display the
shape of a distribution.

Jean

On Tue, Dec 20, 2016 at 9:04 AM, Narendra Modi <bjpmodi2016 at gmail.com>
wrote:

> Hello Gurus,
> I intend to build attached reference graph in R(r.png). Could you give
> me some ideas on how it can be done, if at all possible?
>
> Basically, I would like to build a Histogram along Y axis for
> different  respective X axis ranges.
> As shown in the input.png file, there is a value of EUR for every Lw,
> a simple X-Y scatter plot.
> Now, what if I build ranges of x axis values, i.e 2000-4000,
> 4000-6000, 6000-8000 etc and analyze the histograms of Y axis values
> for those ranges?
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From attenka at utu.fi  Tue Dec 20 17:11:23 2016
From: attenka at utu.fi (Atte Tenkanen)
Date: Tue, 20 Dec 2016 18:11:23 +0200
Subject: [R] Getting scan() -command to work during the program run
In-Reply-To: <CAGxFJbTwim9rWmZAZ467_K3CByeJCmaRfcOMrtOOUO9BrgspAA@mail.gmail.com>
References: <5858EDE4.6040409@utu.fi>
	<CAGxFJbTwim9rWmZAZ467_K3CByeJCmaRfcOMrtOOUO9BrgspAA@mail.gmail.com>
Message-ID: <5859582B.7020704@utu.fi>

Hi Bert,

I tried using the function, but still the same problem. If there is 
something after the scan-line, scan does not let me to enter any input 
but the program just run forward like before.

I have OSX 10.9.5. and R 3.3.2.

Atte

20.12.2016, 17.19, Bert Gunter kirjoitti:
> ??
>
>> f <- function() {X <- scan(n =1); X}
>> f()
> 1: 3
> Read 1 item
>
>
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Tue, Dec 20, 2016 at 12:37 AM, Atte Tenkanen <attenka at utu.fi> wrote:
>> Hi,
>>
>> How to get scan(file="") command to ask my input from the keyboard?
>>
>> If I put the command straight to the console it works
>>
>>> X1 <- scan(n=1)
>> 1: 22
>> Read 1 item
>>
>> but as a part of a program it just continues without asking my value?
>>
>>> X1 <- scan(n=1)
>> 1:
>> Read 0 items
>>
>> Yours,
>>
>> Atte Tenkanen
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Atte Tenkanen, FT MuM
Turun Martinseurakunnan kanttori
p. 040-3417125


From bgunter.4567 at gmail.com  Tue Dec 20 18:44:29 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Dec 2016 09:44:29 -0800
Subject: [R] Getting scan() -command to work during the program run
In-Reply-To: <5859582B.7020704@utu.fi>
References: <5858EDE4.6040409@utu.fi>
	<CAGxFJbTwim9rWmZAZ467_K3CByeJCmaRfcOMrtOOUO9BrgspAA@mail.gmail.com>
	<5859582B.7020704@utu.fi>
Message-ID: <CAGxFJbSt3gwj5HzWRZ29Be=2=MytLqd48_mPLDHT0gs3+fAAQQ@mail.gmail.com>

No clue.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 20, 2016 at 8:11 AM, Atte Tenkanen <attenka at utu.fi> wrote:
> Hi Bert,
>
> I tried using the function, but still the same problem. If there is
> something after the scan-line, scan does not let me to enter any input but
> the program just run forward like before.
>
> I have OSX 10.9.5. and R 3.3.2.
>
> Atte
>
> 20.12.2016, 17.19, Bert Gunter kirjoitti:
>>
>> ??
>>
>>> f <- function() {X <- scan(n =1); X}
>>> f()
>>
>> 1: 3
>> Read 1 item
>>
>>
>>
>> -- Bert
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Tue, Dec 20, 2016 at 12:37 AM, Atte Tenkanen <attenka at utu.fi> wrote:
>>>
>>> Hi,
>>>
>>> How to get scan(file="") command to ask my input from the keyboard?
>>>
>>> If I put the command straight to the console it works
>>>
>>>> X1 <- scan(n=1)
>>>
>>> 1: 22
>>> Read 1 item
>>>
>>> but as a part of a program it just continues without asking my value?
>>>
>>>> X1 <- scan(n=1)
>>>
>>> 1:
>>> Read 0 items
>>>
>>> Yours,
>>>
>>> Atte Tenkanen
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Atte Tenkanen, FT MuM
> Turun Martinseurakunnan kanttori
> p. 040-3417125
>


From dwinsemius at comcast.net  Tue Dec 20 18:55:51 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 20 Dec 2016 09:55:51 -0800
Subject: [R] Getting scan() -command to work during the program run
In-Reply-To: <5858EDE4.6040409@utu.fi>
References: <5858EDE4.6040409@utu.fi>
Message-ID: <D1A40F68-8E0A-4257-BCDD-554E92F5D4E7@comcast.net>


> On Dec 20, 2016, at 12:37 AM, Atte Tenkanen <attenka at utu.fi> wrote:
> 
> Hi,
> 
> How to get scan(file="") command to ask my input from the keyboard?
> 
> If I put the command straight to the console it works
> 
> > X1 <- scan(n=1)
> 1: 22
> Read 1 item
> 
> but as a part of a program it just continues without asking my value?
> 
> > X1 <- scan(n=1)

As "part of a program" there is no console input file when run in non-interactive mode. Efforts to make a non-interactive session into an interactive session are well documented in the rhelp archives. Search:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+user+input+interactive+rscript

If you did that inside a function which you ran inside an interactive session and did not return the value there would of course be no value, but that would not give you response you report. You would be expected to use the 'file'-parameter for specifying the source of input when using scan in a script.

If my only code is a single line in a text file named 'Untitled.R':

 X1 <- scan(n=1)

Running just that with Rscript at the system console does give me:

Read 0 items

Now make a data file named 'myfile.txt' and a source file named "Untitled.R" and use it to create a data file named myfile.txt and then read from it.

------
 cat("5", "\n", file="myfile.txt")
 X1 <- scan(file="myfile.txt")
 X1
-------

The source Untitled.R or run with Rscript.

From a Unix shell console:

$ Rscript Untitled
#omitting the information about my  R version etc, etc

Read 1 item
[1] 5

If I execute that with no 'myfile.txt' file in my working directory it throws an error and I get "Error in file(file, "r") : cannot open the connection"

If I run this script file:

X1 <- scan()
X1

I do not get an error from a missing file argument to `scan` but X1 does not get set to a value but I do get:

Error in scan() : scan() expected 'a real', got 'X1'


-- 
David.

> 1:
> Read 0 items
> 
> Yours,
> 
> Atte Tenkanen
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From abrogard at yahoo.com  Tue Dec 20 21:42:18 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Tue, 20 Dec 2016 20:42:18 +0000 (UTC)
Subject: [R] Why Does R Print out strange record?
In-Reply-To: <CAGx1TMBr42AVCXSPgAxt3sWTyFxueLquTCCbDxKPT_qyjReP-Q@mail.gmail.com>
References: <722307751.1990840.1482196113858.ref@mail.yahoo.com>
	<722307751.1990840.1482196113858@mail.yahoo.com>
	<CAGx1TMCCZg5u-PtK+Ms56cYFbx0Mc6=g8Qk8LBxy7K9yTqSzyQ@mail.gmail.com>
	<1550695386.2445736.1482260680314@mail.yahoo.com>
	<CAGx1TMBr42AVCXSPgAxt3sWTyFxueLquTCCbDxKPT_qyjReP-Q@mail.gmail.com>
Message-ID: <2054278810.2516253.1482266538350@mail.yahoo.com>




Yep. Okay.  This better?  It's gone to the list I think? And I found the plain text option right before my eyes there at the bottom of the page.

thanks for your help.

 




________________________________
From: Richard M. Heiberger <rmh at temple.edu>

Sent: Wednesday, 21 December 2016, 6:57
Subject: Re: [R] Why Does R Print out strange record?


The convention on this email list is to always reply to the list, not
just the person who replied to you.
Many people comment on the same questions with interesting different
perspectives.

Start with two things to read.
1. the posting guide linked at the bottom of each email on the list.
2. The introductory manual at system.file("../../doc/manual/R-intro.pdf")

Specifics: almost everything in R is vectorized, meaning you usually
do not need explicit loops.

I don't use yahoo email so I don't know how to set it to plain text.
I am sure it is possible.
do a web search.



>
>  Thank you for your help.
>
>  I'm sorry about the html. I use yahoo mail and I can find no way to switch
> it off if it is sending html.  I wasn't aware it was doing that.
>
> I'm looking into installing and using perhaps thunderbird or something.
> Their web site doesn't seem to make a pronouncement about that aspect,
> either.  If you have a recommendation please let me know.
>
> I obviously have a tremendous amount to learn with this R.
>
> I've very old fashioned and pedestrian in my thoughts on what to do.  I'm
> thinking I must go down the list and process each value some way but I think
> R has functions that do this for you. Such as your diff().
>
> Your code has produced all the values I see when I list out 'rates'.   Now
> I'm thinking to loop through and extract all the ones I'm interested in. Are
> you saying there's a better way to do such things just as you did it with
> diff() ?
>
> regards,
>
> ab
>
> p.s. if you wish me to stop communicating until i've got this html thing
> sorted out just say so.
>
>
>
>
>
> ________________________________
> From: Richard M. Heiberger <rmh at temple.edu>

> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Tuesday, 20 December 2016, 15:29
> Subject: Re: [R] Why Does R Print out strange record?
>
> You have read your Date variable in as a character variable, which was
> coerced to a factor.
> You probably wanted the values to be interpreted as dates.  example of
> what to do is below.
> Note that the date-factor levels are sorted alphabetically, which is
> almost certainly not what you want.
>
> In addition, please do not use HTML mail.  R-help is plain-text list
> and R code often gets scrambled beyond recognition.
>
> Attaching a data.frame is very bad style, and will get you into
> trouble in the future.  Again, see below for a recommendation.
>
>
>
> rates <- read.csv(text="
>     Date, Int
> Feb-2012, .04
> Mar-2012, .045
> Apr-2012, .042
> May-2012, .038
> Jun-2012, .051
> ",
> header=TRUE,
> colClasses=c("character","numeric"))
>
> rates
> sapply(rates, class)
>
>
> ## dates are one of the most difficult computing concepts to get
> ## right.  your dates are month and year, not including day-of-month,
> ## and are therefore even more difficult.  I am putting them all on
> ## the first of the month, and forcing a common time zone to bypass
> ## the daylight savings time problems.
>
> rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
> tz="UTC")
> ## you will need to read
> ## ?as.POSIXct
> ## ?strptime
>
> ## the rest of your calculations can be done more easily with
> vectorized arithmetic.
>
> mysize <- nrow(rates)
> rates$thisone <- c(diff(rates$Int), NA)
> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
> rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
> rates
>
> On Mon, Dec 19, 2016 at 8:08 PM, arthur brogard via R-help
> <r-help at r-project.org> wrote:
>> I have this bit of code:
>> rates=read.csv("Rates2.csv")
>> attach(rates)
>> mysize <- nrow(rates)
>> count <- 0
>> for(i in 1:(mysize - 3)) {
>> #print(i)
>> thisday <- Date[i]
>> thisone <- Int[i+1] - Int[i]
>> nextone <- Int[i+2] - Int[i]
>> lastone <- thisone + nextone
>> lastone <- lastone/6.5
>> lastone <- lastone * 1000
>>
>> #print("thisone")
>> #print(thisone)
>> #print("nextone")
>> #print(nextone)
>>
>> if (lastone >0){
>> print(thisday)
>> print("dollars saved per $100,000")
>> print(lastone)
>> count = count + 1
>> }
>> }
>> which generally works alright until I put the last bit in about 'thisday'
>> since then I get a display with such as this in it:
>> [1] "dollars saved per $100,000"
>> [1] 9.230769
>> [1] Feb-2012
>> 689 Levels: Apr-1959 Apr-1960 Apr-1961 Apr-1962 ... Sep-2015
>> [1] "dollars saved per $100,000"
>> [1] 18.46154
>> [1] Jun-2015
>> 689 Levels: Apr-1959 Apr-1960 Apr-1961 Apr-1962 ... Sep-2015
>> [1] "dollars saved per $100,000"
>> [1] 21.53846
>>
>> This word 'Levels'  is not present in the data.
>>
>> Can anyone help, tell me what is happening here?
>>
>>
>>  ================================
>>
>> Can you handle truth ?
>>
>> Barbara Walker: Woman's Encyclopedia of Myths and Secrets
>>
>> What it is really about:
>> https://www.youtube.com/watch?v=sYKAgAfYJZE
>>
>> The bald truth:
>> https://www.youtube.com/watch?v=kevNDOCbKxE
>>
>> https://www.youtube.com/watch?v=fbfdsMdbcfA
>>
>> Sanity:
>> Those terrible Russians:
>> https://www.youtube.com/watch?v=VZsjoiFfpXM
>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>


From llfn at uw.edu  Wed Dec 21 01:14:59 2016
From: llfn at uw.edu (Loretta Fisher)
Date: Tue, 20 Dec 2016 16:14:59 -0800
Subject: [R] Would like to practice running ecological data & R code
Message-ID: <CAMqcYZrH=4zuOCr=SYe_r_GRJADW8FXaKG8a8kWV3VSfQFY-KQ@mail.gmail.com>

Dear R help list,

I am a beginner using R for univariate and multivariate analysis of
ecological data.  About the only thing I can do with R script on my own
thus far is run an ANOVA and a Tukey's HSD test, and I'm finding that this
skill level is not getting me very far in new types of ecological data I am
playing with. It really helps me understand R better when I can run through
existing code (preferably well-annotated) and data sets written by others
to just learn how R communicates with itself, and how it navigates data
with different attributes.  Does anyone know of any places I could find
online (or would anyone be willing to share) .csv files containing
ecological data along with simple text files of R code to go with those
.csv files?  I promise to use these data and R scripts only for my own
educational purposes and am happy to sign any sort of agreements that
anyone might need to feel comfortable sharing data and code with me for
this purpose.  I also promise that I am not currently enrolled in any
courses using R, and that I will never try to pass off any code written by
someone else as my own in any courses I take.  This request is simply for
my own learning, based on the method that works best for me.

At the moment, I'm specifically looking for data and R script that involve
categorical explanatory variables with response variables that are bounded
between 0 and 1, though I am also interested in running and learning from
any code written for ecological datasets.  My own research is in grassland
plant communities, but I am interested in ecological data collected on any
sort of ecosystems or organisms.  For multivariate data, I would really
like to understand principal coordinates analysis better.  I would also
like to start learning Beysian methods.

Thank you!

Loretta Fisher

	[[alternative HTML version deleted]]


From the_august at yahoo.com  Tue Dec 20 22:30:25 2016
From: the_august at yahoo.com (Its August)
Date: Tue, 20 Dec 2016 21:30:25 +0000 (UTC)
Subject: [R] Feature selection using R Caret package: Error in seeds[[num_rs
 + 1L]] : subscript out of bounds
References: <1262920665.2531853.1482269425076.ref@mail.yahoo.com>
Message-ID: <1262920665.2531853.1482269425076@mail.yahoo.com>

Hello All,
I've a dataset of six samples and 1530 variables/features and wish to know the the importance of features. I'm trying to use the "Rank Features By Importance" as mentioned in Feature Selection with the Caret R Package (http://machinelearningmastery.com/feature-selection-with-the-caret-r-package/)
I'm using the following code:
? ? rm(list=ls())? ? set.seed(12345)? ? library(mlbench)? ? library(caret)? ? options(error=utils::recover)
? ? #Pastebin link for Data: http://pastebin.com/raw/cg0Kiueq? ? mydata.df <- read.table("data.PasteBin.txt", header=TRUE,sep="\t",stringsAsFactors=TRUE)? ? dim(mydata.df)
? ? lvq.control <- trainControl(method="LOOCV")? ? lvq.model <- train(ID~., data=mydata.df, method="lvq", trControl=lvq.control ) #FAILS
? ? importance <- varImp(lvq.model, scale=FALSE)? ? print(importance)? ? plot(importance)
The data can be downloaded from the following Pastebin link:
http://pastebin.com/raw/cg0Kiueq

The program fails to execute with the following error and debug messages:
? ? Error in seeds[[num_rs + 1L]] : subscript out of bounds? ? 1: train(ID ~ ., data = mydata.df, method = "lvq", trControl = lvq.control)? ? 2: train.formula(ID ~ ., data = mydata.df, method = "lvq", trControl = lvq.con? ? 3: train(x, y, weights = w, ...)? ? 4: train.default(x, y, weights = w, ...)

I've read from multiple sources (http://davidhughjones.blogspot.com/2015/04/r-tip-caret-error.html) that unless the response variable is of class factor Caret issues error like this.
?However, my response variable('ID') is indeed a factor
? ? > str(mydata.df$ID)? ? ?Factor w/ 2 levels "NONRC","RC": 2 2 1 1 2 1
The detail of my version of R and Caret are as follows:
? ? > packageVersion("caret")? ? [1] ?6.0.70?? ? R version 3.3.0 (2016-05-03)? ? Platform: x86_64-w64-mingw32/x64 (64-bit)? ? Running under: Windows 7 x64 (build 7601) Service Pack 1
Can someone please suggest any remedy?
Thanks in advance
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Dec 21 03:17:47 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 20 Dec 2016 18:17:47 -0800
Subject: [R] Would like to practice running ecological data & R code
In-Reply-To: <CAMqcYZrH=4zuOCr=SYe_r_GRJADW8FXaKG8a8kWV3VSfQFY-KQ@mail.gmail.com>
References: <CAMqcYZrH=4zuOCr=SYe_r_GRJADW8FXaKG8a8kWV3VSfQFY-KQ@mail.gmail.com>
Message-ID: <CAGxFJbRyri+pP_VVQACXA2Bb0=T15cT0ecRGetgSj9Asg50YXQ@mail.gmail.com>

You might want to start here:

https://cran.r-project.org/web/views/Environmetrics.html


I am sure there are many interesting data sets in these packages.

Please also search online for R tutorials -- there are many good ones,
some targeted for your field I'm sure. Google is your friend.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 20, 2016 at 4:14 PM, Loretta Fisher <llfn at uw.edu> wrote:
> Dear R help list,
>
> I am a beginner using R for univariate and multivariate analysis of
> ecological data.  About the only thing I can do with R script on my own
> thus far is run an ANOVA and a Tukey's HSD test, and I'm finding that this
> skill level is not getting me very far in new types of ecological data I am
> playing with. It really helps me understand R better when I can run through
> existing code (preferably well-annotated) and data sets written by others
> to just learn how R communicates with itself, and how it navigates data
> with different attributes.  Does anyone know of any places I could find
> online (or would anyone be willing to share) .csv files containing
> ecological data along with simple text files of R code to go with those
> .csv files?  I promise to use these data and R scripts only for my own
> educational purposes and am happy to sign any sort of agreements that
> anyone might need to feel comfortable sharing data and code with me for
> this purpose.  I also promise that I am not currently enrolled in any
> courses using R, and that I will never try to pass off any code written by
> someone else as my own in any courses I take.  This request is simply for
> my own learning, based on the method that works best for me.
>
> At the moment, I'm specifically looking for data and R script that involve
> categorical explanatory variables with response variables that are bounded
> between 0 and 1, though I am also interested in running and learning from
> any code written for ecological datasets.  My own research is in grassland
> plant communities, but I am interested in ecological data collected on any
> sort of ecosystems or organisms.  For multivariate data, I would really
> like to understand principal coordinates analysis better.  I would also
> like to start learning Beysian methods.
>
> Thank you!
>
> Loretta Fisher
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Dec 21 03:40:58 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 20 Dec 2016 18:40:58 -0800
Subject: [R] Feature selection using R Caret package: Error in
	seeds[[num_rs + 1L]] : subscript out of bounds
In-Reply-To: <1262920665.2531853.1482269425076@mail.yahoo.com>
References: <1262920665.2531853.1482269425076.ref@mail.yahoo.com>
	<1262920665.2531853.1482269425076@mail.yahoo.com>
Message-ID: <25B615F4-F686-4313-8D7F-EF38C0770A55@comcast.net>


> On Dec 20, 2016, at 1:30 PM, Its August via R-help <r-help at r-project.org> wrote:
> 
> rm(list=ls())    set.seed(12345)    library(mlbench)    library(caret)    options(error=utils::recover)
>     #Pastebin link for Data: http://pastebin.com/raw/cg0Kiueq    mydata.df <- read.table("data.PasteBin.txt", header=TRUE,sep="\t",stringsAsFactors=TRUE)    dim(mydata.df)
>     lvq.control <- trainControl(method="LOOCV")    lvq.model <- train(ID~., data=mydata.df, method="lvq", trControl=lvq.control ) #FAILS
>     importance <- varImp(lvq.model, scale=FALSE)    print(importance)    plot(importance)

Posting in HTML causes this sort of unparseable code to appear on the distributed version of your posting. (You didn't read the Posting Guide.)

After looking at the link:
http://machinelearningmastery.com/feature-selection-with-the-caret-r-package/

... I'm of the opinion that you are posting in the wrong place. I think the people that run that program should be the ones you ask for assistance. After all, they say:
#---------
STOP Wasting Your Time Piecing Together One-Off Articles and
Parsing Greek Letters in Academic Textbooks

NOW is the time to actually learn?
How To Deliver Results With Machine Learning
#---------


Obviously their product is what you should be using.


-- 

David Winsemius
Alameda, CA, USA


From yokeyong.wong at gmail.com  Wed Dec 21 03:24:10 2016
From: yokeyong.wong at gmail.com (Wong Yoke Yong)
Date: Wed, 21 Dec 2016 10:24:10 +0800
Subject: [R] Error using nlme; Malformed factors
Message-ID: <CACoL8j5yVNrRUbKbcG=cZbWm89Sxj+Oi-DYgFg6MNqxq4ucEKA@mail.gmail.com>

HI all,

I am using the nlme package to learn multilevel models, and following
examples from the textbook "Discovering Statistics Using R" when it
happened.

[Mixed Models Code][1]

The data set is Honeymoon Period.dat, also downloadable under their
companion website.

[Data Set - Multilevel Models][2]

    require(nlme)
    require(reshape2)
    satisfactionData = read.delim("Honeymoon Period.dat",  header = TRUE)

    restructuredData<-melt(satisfactionData, id = c("Person", "Gender"),
measured = c("Satisfaction_Base", "Satisfaction_6_Months",
"Satisfaction_12_Months", "Satisfaction_18_Months"))
    names(restructuredData)<-c("Person", "Gender", "Time",
"Life_Satisfaction")


    #print(restructuredData)
    #restructuredData.sorted<-restructuredData[order(Person),]

    intercept <-gls(Life_Satisfaction~1, data = restructuredData, method =
"ML", na.action = na.exclude)
    randomIntercept <-lme(Life_Satisfaction ~1, data = restructuredData,
random = ~1|Person, method = "ML",  na.action = na.exclude, control =
list(opt="optim"))
    anova(intercept, randomIntercept)

    timeRI<-update(randomIntercept, .~. + Time)
    timeRS<-update(timeRI, random = ~Time|Person)
    ARModel<-update(timeRS, correlation = corAR1(0, form = ~Time|Person))

The error occured at this moment, when I am trying to update "timeRS"
model. The error is as follows:

    Error in as.character.factor(X[[i]], ...) : malformed factor

Help would be appreciated. Thanks!

  [1]:
https://studysites.uk.sagepub.com/dsur/study/DSUR%20R%20Script%20Files/Chapter%2019%20DSUR%20Mixed%20Models.R
  [2]: https://studysites.uk.sagepub.com/dsur/study/articles.htm


Regards,
Yoke Yong

	[[alternative HTML version deleted]]


From abhinav.piplani at zs.com  Wed Dec 21 14:08:37 2016
From: abhinav.piplani at zs.com (Abhinav Piplani)
Date: Wed, 21 Dec 2016 13:08:37 +0000
Subject: [R]  Plot Cubist Tree
Message-ID: <BF5B2943D7E53C47AC7E9B1CFC884EEB011D027B@ZS-EXMBX02.zs.local>

Hi,

I know its been a long time, but any update on this ?

Regards

Abhinav Piplani
Data Science Associate
ZS Associates India Pvt. Ltd.
Tower A4, DLF WORLD TECH PARK Sector-30, NH-8, Gurgaon 122002, Haryana, India
T  |  +91 124 675 3430
www.zs.com<http://www.zs.com/>

ZS  Impact where it matters.





________________________________
Notice: This message, including attachments, may be confidential or privileged. If you are not the addressee, notify the sender immediately and delete this email from your system.


	[[alternative HTML version deleted]]


From david.w.watson at nasa.gov  Wed Dec 21 14:23:57 2016
From: david.w.watson at nasa.gov (Watson, David W. (MSFC-ES62))
Date: Wed, 21 Dec 2016 13:23:57 +0000
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct RC
	version
Message-ID: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>

I have been trying to download the ?patched? version of 3.3.2 for Mac from CRAN, but the version that gets delivered is actually the October Release Candidate version,
(R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?

David Watson
NASA - MSFC
Mail Code ES62
Phone 256-544-1300
FAX   256-544-2964
david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>


	[[alternative HTML version deleted]]


From mauriciocornejo at yahoo.com  Wed Dec 21 16:58:45 2016
From: mauriciocornejo at yahoo.com (Mauricio Cornejo)
Date: Wed, 21 Dec 2016 15:58:45 +0000 (UTC)
Subject: [R] Power of t test for unequal variances?
In-Reply-To: <f83b324b-22a0-36a8-63b1-3ba100c7808e@math.uni-giessen.de>
References: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
	<1197452454.8682574.1482184073720@mail.yahoo.com>
	<584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>
	<f83b324b-22a0-36a8-63b1-3ba100c7808e@math.uni-giessen.de>
Message-ID: <853164161.490244.1482335925749@mail.yahoo.com>

Gerrit, thanks for the suggestion. ?samplesize::n.ttest does seem to handle unequal variances. 

    On Tuesday, December 20, 2016 2:55 AM, Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de> wrote:
 
 Hello, Mauricio,

maybe pwr.t2n.test() in package pwr or/and n.ttest() in package?samplesize do what you need/want.

? Hth? --? Gerrit


> On Dec 19, 2016, at 1:47 PM, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
>
> Is there a function similar to stats::power.t.test that can handle unequal variances from two samples?
> I noticed that stats::t.test has an argument for indicating whether or not to treat the two sample variances as equal.? Wondering why stats::power.t.test doesn?t have that option.
> Thanks, Mauricio
   
	[[alternative HTML version deleted]]


From bjpmodi2016 at gmail.com  Wed Dec 21 17:36:07 2016
From: bjpmodi2016 at gmail.com (Narendra Modi)
Date: Wed, 21 Dec 2016 10:36:07 -0600
Subject: [R] Is it possible to create such graph - Which packages can
	come handy?
In-Reply-To: <CAN5YmCFn3ufAJ-ZihF8xu_MpiuacNKhYX5tS+4i66vuSBqjVwA@mail.gmail.com>
References: <CAPq=xQAv17dGYK1XDYcvgjPo3NxWeLN0p0Us0qYc1XJjX1e9Dg@mail.gmail.com>
	<CAN5YmCFn3ufAJ-ZihF8xu_MpiuacNKhYX5tS+4i66vuSBqjVwA@mail.gmail.com>
Message-ID: <CAPq=xQBQL8prU1ayLAAXk3DZBsnTa3ZmeQXd5NCUt4dg27ePDA@mail.gmail.com>

Thanks Jean,  let me have a look!

On Tue, Dec 20, 2016 at 9:49 AM, Adams, Jean <jvadams at usgs.gov> wrote:
> You might find the code in this blog post helpful.
> http://theanalyticalminds.blogspot.com/2015/03/part-3a-plotting-with-ggplot2.html
>
> Scroll down to "Analysing the temperature by month - violin geom with
> jittered points overlaid".
>
> This shows a series of violin plots, which is another way to display the
> shape of a distribution.
>
> Jean
>
> On Tue, Dec 20, 2016 at 9:04 AM, Narendra Modi <bjpmodi2016 at gmail.com>
> wrote:
>>
>> Hello Gurus,
>> I intend to build attached reference graph in R(r.png). Could you give
>> me some ideas on how it can be done, if at all possible?
>>
>> Basically, I would like to build a Histogram along Y axis for
>> different  respective X axis ranges.
>> As shown in the input.png file, there is a value of EUR for every Lw,
>> a simple X-Y scatter plot.
>> Now, what if I build ranges of x axis values, i.e 2000-4000,
>> 4000-6000, 6000-8000 etc and analyze the histograms of Y axis values
>> for those ranges?
>>
>> Thanks!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From bgunter.4567 at gmail.com  Wed Dec 21 17:37:43 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Dec 2016 08:37:43 -0800
Subject: [R] Error using nlme; Malformed factors
In-Reply-To: <CACoL8j5yVNrRUbKbcG=cZbWm89Sxj+Oi-DYgFg6MNqxq4ucEKA@mail.gmail.com>
References: <CACoL8j5yVNrRUbKbcG=cZbWm89Sxj+Oi-DYgFg6MNqxq4ucEKA@mail.gmail.com>
Message-ID: <CAGxFJbTaauQF-+tmX0h++n+C7RF0pEVC8Sj_ZXP6jwzw8pD1_w@mail.gmail.com>

You may do better (faster, more knowledgeable responses) posting on
the r-sig-mixed-models list.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Tue, Dec 20, 2016 at 6:24 PM, Wong Yoke Yong <yokeyong.wong at gmail.com> wrote:
> HI all,
>
> I am using the nlme package to learn multilevel models, and following
> examples from the textbook "Discovering Statistics Using R" when it
> happened.
>
> [Mixed Models Code][1]
>
> The data set is Honeymoon Period.dat, also downloadable under their
> companion website.
>
> [Data Set - Multilevel Models][2]
>
>     require(nlme)
>     require(reshape2)
>     satisfactionData = read.delim("Honeymoon Period.dat",  header = TRUE)
>
>     restructuredData<-melt(satisfactionData, id = c("Person", "Gender"),
> measured = c("Satisfaction_Base", "Satisfaction_6_Months",
> "Satisfaction_12_Months", "Satisfaction_18_Months"))
>     names(restructuredData)<-c("Person", "Gender", "Time",
> "Life_Satisfaction")
>
>
>     #print(restructuredData)
>     #restructuredData.sorted<-restructuredData[order(Person),]
>
>     intercept <-gls(Life_Satisfaction~1, data = restructuredData, method =
> "ML", na.action = na.exclude)
>     randomIntercept <-lme(Life_Satisfaction ~1, data = restructuredData,
> random = ~1|Person, method = "ML",  na.action = na.exclude, control =
> list(opt="optim"))
>     anova(intercept, randomIntercept)
>
>     timeRI<-update(randomIntercept, .~. + Time)
>     timeRS<-update(timeRI, random = ~Time|Person)
>     ARModel<-update(timeRS, correlation = corAR1(0, form = ~Time|Person))
>
> The error occured at this moment, when I am trying to update "timeRS"
> model. The error is as follows:
>
>     Error in as.character.factor(X[[i]], ...) : malformed factor
>
> Help would be appreciated. Thanks!
>
>   [1]:
> https://studysites.uk.sagepub.com/dsur/study/DSUR%20R%20Script%20Files/Chapter%2019%20DSUR%20Mixed%20Models.R
>   [2]: https://studysites.uk.sagepub.com/dsur/study/articles.htm
>
>
> Regards,
> Yoke Yong
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mauriciocornejo at yahoo.com  Wed Dec 21 17:39:39 2016
From: mauriciocornejo at yahoo.com (Mauricio Cornejo)
Date: Wed, 21 Dec 2016 16:39:39 +0000 (UTC)
Subject: [R] Power of t test for unequal variances?
In-Reply-To: <01D64C1E-0E4A-483B-8D52-0D70BC7761D9@comcast.net>
References: <2c3e399c84a1463eab3be88337eb9ff9@OMZP1LUMXCA09.uswin.ad.vzwcorp.com>
	<1197452454.8682574.1482184073720@mail.yahoo.com>
	<584E1B41-758A-4A00-9D42-78D4251F4D8E@comcast.net>
	<01D64C1E-0E4A-483B-8D52-0D70BC7761D9@comcast.net>
Message-ID: <393449488.557176.1482338379357@mail.yahoo.com>

David,
I was not aware I could search through the list of available packages. ?Thanks very much for the tip.
Regarding your guidance that my question may not have been appropriate for R-help as it may not have been specifically an R question ... since it seemed like an R question to me, are there any particular criteria that would help me determine if my question is sufficiently specific to R to be appropriate for R-help?
Thanks again,
Mauricio 

    On Monday, December 19, 2016 10:14 PM, David Winsemius <dwinsemius at comcast.net> wrote:
 
 
> On Dec 19, 2016, at 3:31 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Dec 19, 2016, at 1:47 PM, Mauricio Cornejo via R-help <r-help at r-project.org> wrote:
>> 
>> Is there a function similar to stats::power.t.test that can handle unequal variances from two samples?
>> I noticed that stats::t.test has an argument for indicating whether or not to treat the two sample variances as equal.? Wondering why stats::power.t.test doesn?t have that option.
>> Thanks,Mauricio
>> ??? [[alternative HTML version deleted]]
> 
> Because R was developed by statisticians for statisticians and they assumed those other statisticians would know how to extend its functions when needed. But R-help is not advertised as the place to ask such questions when you don't have the statistical skills. (You might want to look at the code of `t.test` to see how you might construct appropriate arguments for `power.t.test` in the situation you imagine. Seems to me it should be fairly straightforward. `power.t.test` is built around the non-central t-distribution and solves a uniroot problem for the missing parameter among? n, delta, power, sd, and sig.level, given the other 4 parameters.)
> 

The other R-specific response might have been to teach you to use R's functions to do a bit of searching:

 ?available.packages
 old.opt <- options(available_packages_filters =
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? c("R_version",? "CRAN", "duplicates"))
 # saved options from prior state

 avail <- available.packages()
 names(avail)
NULL? # oops, not a list.
> str( avail)
 chr [1:9731, 1:17] "A3" "abbyyR" "abc" "ABCanalysis" ...
 - attr(*, "dimnames")=List of 2
? ..$ : chr [1:9731] "A3" "abbyyR" "abc" "ABCanalysis" ...
? ..$ : chr [1:17] "Package" "Version" "Priority" "Depends" ...
 colnames(avail)
#--- result---
 [1] "Package"? ? ? ? ? ? ? "Version"? ? ? ? ? ? ? 
 [3] "Priority"? ? ? ? ? ? ? "Depends"? ? ? ? ? ? ? 
 [5] "Imports"? ? ? ? ? ? ? "LinkingTo"? ? ? ? ? ? 
 [7] "Suggests"? ? ? ? ? ? ? "Enhances"? ? ? ? ? ? 
 [9] "License"? ? ? ? ? ? ? "License_is_FOSS"? ? ? 
[11] "License_restricts_use" "OS_type"? ? ? ? ? ? ? 
[13] "Archs"? ? ? ? ? ? ? ? "MD5sum"? ? ? ? ? ? ? 
[15] "NeedsCompilation"? ? ? "File"? ? ? ? ? ? ? ? 
[17] "Repository"? ? ? ? 
#---------? 


 avail[ grepl("pow" ,avail[ ,"Package"] , ignore.case=TRUE), "Package"]
? ? ? ? ? ? ? ? asypow? ? ? ? ? bivarRIpower? ? ? ? ? clusterPower 
? ? ? ? ? ? ? "asypow"? ? ? ? "bivarRIpower"? ? ? ? "clusterPower" 
? ? ? ? ? ? easypower? ? ? ? ? ? ? ? ? fpow? ? ? ? ? ? ? longpower 
? ? ? ? ? "easypower"? ? ? ? ? ? ? ? "fpow"? ? ? ? ? ? "longpower" 
? ? ? ? ? ? ? ? matpow? ? ? ? ? ? ? mnormpow? ? ? ? ? ? ? PharmPow 
? ? ? ? ? ? ? "matpow"? ? ? ? ? ? "mnormpow"? ? ? ? ? ? "PharmPow" 
? ? ? ? ? ? ? ? powell? ? ? ? ? ? ? ? ? PoweR? ? ? ? ? ? Power2Stage 
? ? ? ? ? ? ? "powell"? ? ? ? ? ? ? ? "PoweR"? ? ? ? ? "Power2Stage" 
? ? ? ? powerAnalysis? ? ? ? ? powerbydesign? powerGWASinteraction 
? ? ? "powerAnalysis"? ? ? ? "powerbydesign" "powerGWASinteraction" 
? ? ? ? ? ? ? poweRlaw? ? ? ? powerMediation? ? ? ? ? ? ? powerpkg 
? ? ? ? ? ? "poweRlaw"? ? ? "powerMediation"? ? ? ? ? ? "powerpkg" 
? ? ? ? ? ? powerplus? ? ? ? ? powerSurvEpi? ? ? ? ? ? ? PowerTOST 
? ? ? ? ? "powerplus"? ? ? ? "powerSurvEpi"? ? ? ? ? ? "PowerTOST" 
? ? ? ? ? ? ? PowerUpR? ? ? rPowerSampleSize? ? ? twoStageGwasPower 
? ? ? ? ? ? "PowerUpR"? ? "rPowerSampleSize"? ? "twoStageGwasPower" 

A more usable result:

 names( avail[ grepl("pow" ,avail[ ,"Package"] , ignore.case=TRUE), "Package"] )
 [1] "asypow"? ? ? ? ? ? ? "bivarRIpower"? ? ? ? 
 [3] "clusterPower"? ? ? ? "easypower"? ? ? ? ? 
 [5] "fpow"? ? ? ? ? ? ? ? "longpower"? ? ? ? ? 
 [7] "matpow"? ? ? ? ? ? ? "mnormpow"? ? ? ? ? ? 
 [9] "PharmPow"? ? ? ? ? ? "powell"? ? ? ? ? ? ? 
[11] "PoweR"? ? ? ? ? ? ? ? "Power2Stage"? ? ? ? 
[13] "powerAnalysis"? ? ? ? "powerbydesign"? ? ? 
[15] "powerGWASinteraction" "poweRlaw"? ? ? ? ? ? 
[17] "powerMediation"? ? ? "powerpkg"? ? ? ? ? ? 
[19] "powerplus"? ? ? ? ? ? "powerSurvEpi"? ? ? ? 
[21] "PowerTOST"? ? ? ? ? ? "PowerUpR"? ? ? ? ? ? 
[23] "rPowerSampleSize"? ? "twoStageGwasPower"? 

 options(old.opt)? # reset options to default values

So you may find additional user-contributed power-oriented packages.



> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


   
	[[alternative HTML version deleted]]


From tonightsthenight at gmail.com  Wed Dec 21 19:38:28 2016
From: tonightsthenight at gmail.com (Sam Albers)
Date: Wed, 21 Dec 2016 10:38:28 -0800
Subject: [R] R implementation of the Split and Merge Algorithm
Message-ID: <CADkXsV0jMnOXm1WN9GTmJ-bOdqQK0t0b-cbne4WOO_HwFA6hBA@mail.gmail.com>

Hello there,

I am wondering if anyone on this list has ever encountered an
implementation of the Split and Merge algorithm for R. This algorithm
is reasonably well known and was first developed in this paper:

https://www.computer.org/csdl/trans/tc/1974/08/01672634-abs.html

>From that paper here is the essence of what the Split and Merge
Algorithm accomplishes:

"Given a set of points S = {xi,yi | i = 1,2... N} determine the
minimum number n such that S is divided in n subsets S1, S2...Sn,
where on each of them the data points are approximated by a polynomial
of order at most m - 1 with an error norm less than a prespecified
quantity e."

There has been work on this in MatLab but so far I've not been able to
find the approach in R. The `segmented` package comes close but as far
as I understand, is not what I am looking for. I am happy to do this
myself but wanted to check first to see if someone has already
accomplished this. I know this is a stretch but I thought it wouldn't
hurt to ask.

Thanks in advance.

Sam


From macqueen1 at llnl.gov  Wed Dec 21 19:53:58 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 21 Dec 2016 18:53:58 +0000
Subject: [R] Would like to practice running ecological data & R code
In-Reply-To: <CAGxFJbRyri+pP_VVQACXA2Bb0=T15cT0ecRGetgSj9Asg50YXQ@mail.gmail.com>
References: <CAMqcYZrH=4zuOCr=SYe_r_GRJADW8FXaKG8a8kWV3VSfQFY-KQ@mail.gmail.com>
	<CAGxFJbRyri+pP_VVQACXA2Bb0=T15cT0ecRGetgSj9Asg50YXQ@mail.gmail.com>
Message-ID: <AF3456BD-6811-4800-BB31-2CAB7B4BE81F@llnl.gov>

There is also the R-sig-eco mailing list.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 12/20/16, 6:17 PM, "R-help on behalf of Bert Gunter" <r-help-bounces at r-project.org on behalf of bgunter.4567 at gmail.com> wrote:

    You might want to start here:
    
    https://cran.r-project.org/web/views/Environmetrics.html
    
    
    I am sure there are many interesting data sets in these packages.
    
    Please also search online for R tutorials -- there are many good ones,
    some targeted for your field I'm sure. Google is your friend.
    
    Cheers,
    Bert
    
    
    Bert Gunter
    
    "The trouble with having an open mind is that people keep coming along
    and sticking things into it."
    -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
    
    
    On Tue, Dec 20, 2016 at 4:14 PM, Loretta Fisher <llfn at uw.edu> wrote:
    > Dear R help list,
    >
    > I am a beginner using R for univariate and multivariate analysis of
    > ecological data.  About the only thing I can do with R script on my own
    > thus far is run an ANOVA and a Tukey's HSD test, and I'm finding that this
    > skill level is not getting me very far in new types of ecological data I am
    > playing with. It really helps me understand R better when I can run through
    > existing code (preferably well-annotated) and data sets written by others
    > to just learn how R communicates with itself, and how it navigates data
    > with different attributes.  Does anyone know of any places I could find
    > online (or would anyone be willing to share) .csv files containing
    > ecological data along with simple text files of R code to go with those
    > .csv files?  I promise to use these data and R scripts only for my own
    > educational purposes and am happy to sign any sort of agreements that
    > anyone might need to feel comfortable sharing data and code with me for
    > this purpose.  I also promise that I am not currently enrolled in any
    > courses using R, and that I will never try to pass off any code written by
    > someone else as my own in any courses I take.  This request is simply for
    > my own learning, based on the method that works best for me.
    >
    > At the moment, I'm specifically looking for data and R script that involve
    > categorical explanatory variables with response variables that are bounded
    > between 0 and 1, though I am also interested in running and learning from
    > any code written for ecological datasets.  My own research is in grassland
    > plant communities, but I am interested in ecological data collected on any
    > sort of ecosystems or organisms.  For multivariate data, I would really
    > like to understand principal coordinates analysis better.  I would also
    > like to start learning Beysian methods.
    >
    > Thank you!
    >
    > Loretta Fisher
    >
    >         [[alternative HTML version deleted]]
    >
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From kevin.mckee at contractors.roche.com  Wed Dec 21 19:23:04 2016
From: kevin.mckee at contractors.roche.com (McKee, Kevin)
Date: Wed, 21 Dec 2016 11:23:04 -0700
Subject: [R] R Statistical Application - Windows 10
Message-ID: <CANv5wYm5CwP+TDTGtKUsHLEcRrqL8ohv54fiEXLTJ89VpG1Xfg@mail.gmail.com>

To whom it may concern:

I am trying to verify the oldest version of the R Statistical Application
that is compatible with Windows 10.  Thanks in advance for any information
you can provide.

Best regards,

Kevin McKee
Consultant - TEKsystems

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Dec 21 23:24:14 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 21 Dec 2016 17:24:14 -0500
Subject: [R] R Statistical Application - Windows 10
In-Reply-To: <CANv5wYm5CwP+TDTGtKUsHLEcRrqL8ohv54fiEXLTJ89VpG1Xfg@mail.gmail.com>
References: <CANv5wYm5CwP+TDTGtKUsHLEcRrqL8ohv54fiEXLTJ89VpG1Xfg@mail.gmail.com>
Message-ID: <8a8aaa83-078c-6012-6175-e6a70ea6baef@gmail.com>

On 21/12/2016 1:23 PM, McKee, Kevin wrote:
> To whom it may concern:
>
> I am trying to verify the oldest version of the R Statistical Application
> that is compatible with Windows 10.  Thanks in advance for any information
> you can provide.

They are all available for download from CRAN back to 2004, with some 
versions back to 2000.  It might be hard to install packages that are 
compatible with those old versions, but at least theoretically you can 
download them and test.

You might also want to ask Microsoft; they now distribute R binaries, 
and certainly know more about Windows 10 than we do.

Duncan Murdoch

>
> Best regards,
>
> Kevin McKee
> Consultant - TEKsystems
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Thu Dec 22 01:55:15 2016
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 22 Dec 2016 00:55:15 +0000
Subject: [R] Is it possible to create such graph - Which packages can
 come handy?
In-Reply-To: <CAPq=xQAv17dGYK1XDYcvgjPo3NxWeLN0p0Us0qYc1XJjX1e9Dg@mail.gmail.com>
References: <CAPq=xQAv17dGYK1XDYcvgjPo3NxWeLN0p0Us0qYc1XJjX1e9Dg@mail.gmail.com>
Message-ID: <3BB202AD-4275-4D3A-A0F9-F018B5640E87@llnl.gov>

It's certainly possible, and you don't need any packages to do it; you can do it all in base R.

You can use the findInterval() function to identify which points are in which ranges. Here's an example:

> x <- runif(16, 20, 30)
> xc <- seq(20, 30, by=2)
> xc
[1] 20 22 24 26 28 30
> findInterval(x, xc)
 [1] 4 5 4 5 2 2 2 5 2 1 1 3 4 1 1 5

Then within each interval calculate the mean and standard deviation, use those as input to the dnorm() function to calculate the bell curves. It'll take some tweaking to deal with the fact that you want the bell curves oriented vertically. The smoothing curve can be created with the supsmu() function, among others. There are various details that could make the whole thing tricky to get exactly as you want it. But it's certainly possible.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062


On 12/20/16, 7:04 AM, "R-help on behalf of Narendra Modi" <r-help-bounces at r-project.org on behalf of bjpmodi2016 at gmail.com> wrote:

    Hello Gurus,
    I intend to build attached reference graph in R(r.png). Could you give
    me some ideas on how it can be done, if at all possible?
    
    Basically, I would like to build a Histogram along Y axis for
    different  respective X axis ranges.
    As shown in the input.png file, there is a value of EUR for every Lw,
    a simple X-Y scatter plot.
    Now, what if I build ranges of x axis values, i.e 2000-4000,
    4000-6000, 6000-8000 etc and analyze the histograms of Y axis values
    for those ranges?
    
    Thanks!
    


From bhh at xs4all.nl  Thu Dec 22 07:45:25 2016
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 22 Dec 2016 07:45:25 +0100
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct
	RC version
In-Reply-To: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>
References: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>
Message-ID: <6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>


> On 21 Dec 2016, at 14:23, Watson, David W. (MSFC-ES62) <david.w.watson at nasa.gov> wrote:
> 
> I have been trying to download the ?patched? version of 3.3.2 for Mac from CRAN, but the version that gets delivered is actually the October Release Candidate version,
> (R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?
> 


Send this message to the R-SIG-Mac mailinglist. More likely to get response.

Berend Hasselman

> David Watson
> NASA - MSFC
> Mail Code ES62
> Phone 256-544-1300
> FAX   256-544-2964
> david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Dec 22 08:58:44 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Dec 2016 23:58:44 -0800
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct
	RC version
In-Reply-To: <6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>
References: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>
	<6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>
Message-ID: <119D477F-2354-42F9-85F3-69F509BB4ECB@comcast.net>


> On Dec 21, 2016, at 10:45 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
>> On 21 Dec 2016, at 14:23, Watson, David W. (MSFC-ES62) <david.w.watson at nasa.gov> wrote:
>> 
>> I have been trying to download the ?patched? version of 3.3.2 for Mac from CRAN, but the version that gets delivered is actually the October Release Candidate version,
>> (R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?
>> 
> 

I just downloaded these pkg file from CRAN and get:

R version 3.3.2 (2016-10-31) -- "Sincere Pumpkin Patch"
https://cran.r-project.org/bin/macosx/R-3.3.2.pkg

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X Yosemite 10.10.5

I had earlier today downloaded the version I get from r.att.research.com and got:

R version 3.3.2 RC (2016-10-26 r71594) -- "Sincere Pumpkin Patch"
https://r.research.att.com/mavericks/R-3.3-branch/R-3.3-branch-mavericks.pkg

> sessionInfo()
R version 3.3.2 RC (2016-10-26 r71594)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X Yosemite 10.10.5



The 10-31 date matches the release data for the 3.3.2 source.
-- 
David Winsemius
usually in Alameda, California

> 


> Send this message to the R-SIG-Mac mailinglist. More likely to get response.
> 
> Berend Hasselman
> 
>> 


From cdetermanjr at gmail.com  Wed Dec 21 17:12:40 2016
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 21 Dec 2016 10:12:40 -0600
Subject: [R] [R-pkgs] gpuR 1.2.0 released
Message-ID: <CAKxd1KM93ZCrTvTm5WprS=F=Pcwd274UFGp7e4Kmv+tTy5N3qg@mail.gmail.com>

Dear R users,



I am happy to announce the most recent version of gpuR has been released.
There are several new enhancements to the package including:

1.    Automatically detect available SDK on install if available

2.    Simplified installation to build OpenCL ICD when have OpenCL driver
but no SDK installed (thanks Yixuan Qui)

3.    Control over individual OpenCL contexts to allow user to choose
device to use

4.    Added as.* methods for vclMatrix/Vector and gpuMatrix/Vector objects

5.    Added str method for matrix objects

6.    Added length method for matrix objects

7.    Added solve method for square vclMatrix objects

8.    Added QR-decompsition, SVD, Cholesky for square gpuMatrix/vclMatrix
objects

9.    Added diag and diag<- method for matix objects


There are many more features in the works.  Suggestions and contributions
continue to be welcomed.  Please submit all through my github issues
https://github.com/cdeterman/gpuR.git


Also, thanks to all those as well for testing this package on various GPU
devices and operating systems.  A lot of the stability of this package is
made possible by your efforts.


Kind regards,

Charles

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From wjm1 at caa.columbia.edu  Thu Dec 22 10:14:22 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Thu, 22 Dec 2016 01:14:22 -0800
Subject: [R] creating possible cominations of a vector's elements
Message-ID: <CAA99HCxqFENKZ=TBCxrqvDf2UAKDzrF4C_72taep2cQDv491wA@mail.gmail.com>

Hi Dmitri,

> hoyt <- unlist(strsplit("how are you today", split="\\s"))
> y <- list()
> for(j in seq_along(hoyt))  y[[j]] <- sapply(combn(length(hoyt), j, simplify=F, function(i) hoyt[i]), paste, collapse = " ")

> y

[[1]]
[1] "how"   "are"   "you"   "today"
[[2]]
[1] "how are"   "how you"   "how today" "are you"   "are today" "you today"
[[3]]
[1] "how are you"   "how are today" "how you today" "are you today"
[[4]]
[1] "how are you today"

>

It was unclear if you wanted combinations (per your subject line), or
consecutive-word substrings (per your example). The code above returns
combinations.

If you actually want a third output--permutations--you'll have to look
at the permn() function in the "combinat" package, authored by Scott
Chasalow and maintained by Vince Carey.

Cheers,

Bill
William Michels, Ph.D.


On Fri, Dec 9, 2016 at 7:52 AM, Dimitri Liakhovitski
<dimitri.liakhovitski at gmail.com> wrote:
> Thanks a lot, David and Bill!
>
>
> On Thu, Dec 8, 2016 at 8:16 PM, David L Carlson <dcarlson at tamu.edu> wrote:
>> Not my day. Another correction:
>>
>> makestrings <- function(vec) {
>>      len <- length(vec)
>>      idx <- expand.grid(1:len, 1:len)
>>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>>      mapply(function(x, y) paste(vec[x:y], collapse=" "),
>>           x=idx[, 1], y=idx[, 2])
>> }
>>
>> David C
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
>> Sent: Thursday, December 8, 2016 7:12 PM
>> To: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
>> Subject: Re: [R] creating possible cominations of a vector's elements
>>
>> This corrects an error in my earlier function definition:
>>
>> makestrings <- function(vec) {
>>      len <- length(mystring.spl)
>>      idx <- expand.grid(1:len, 1:len)
>>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>>      mapply(function(x, y) paste(vec[x:y], collapse=" "),
>>           x=idx[, 1], y=idx[, 2])
>> }
>>
>> David C
>>
>> -----Original Message-----
>> From: David L Carlson
>> Sent: Thursday, December 8, 2016 5:51 PM
>> To: 'Dimitri Liakhovitski' <dimitri.liakhovitski at gmail.com>; r-help <r-help at r-project.org>
>> Subject: RE: [R] creating possible cominations of a vector's elements
>>
>> You can use expand.grid() and mapply():
>>
>> mystring <- "this is my vector"
>> mystring.spl <- strsplit(mystring, " ")[[1]]
>>
>> makestrings <- function(x) {
>>      len <- length(mystring.spl)
>>      idx <- expand.grid(1:len, 1:len)
>>      idx <- idx[idx$Var2 <= idx$Var1, c("Var2", "Var1")]
>>      mapply(function(x, y) paste(mystring.spl[x:y], collapse=" "),
>>           x=idx[, 1], y=idx[, 2])
>> }
>> makestrings(mystring.spl)
>>
>>  [1] "this"              "this is"           "this is my"
>>  [4] "this is my vector" "is"                "is my"
>>  [7] "is my vector"      "my"                "my vector"
>> [10] "vector"
>>
>> This makes a vector of strings but if you want a list use as.list(mapply())
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dimitri Liakhovitski
>> Sent: Thursday, December 8, 2016 5:03 PM
>> To: r-help <r-help at r-project.org>
>> Subject: [R] creating possible cominations of a vector's elements
>>
>> Hello!
>>
>> I have a vector of strings 'x' that was based on a longer string
>> 'mystring' (the actual length of x is unknown).
>>
>> mystring <- "this is my vector"
>> x <- strsplit(mystr, " ")[[1]]
>>
>> I am looking for an elegant way of creating an object (e.g., a list)
>> that contains the following strings:
>>
>> "this"
>> "this is"
>> "this is my"
>> "this is my vector"
>> "is"
>> "is my"
>> "is my vector"
>> "my"
>> "my vector"
>> "vector"
>>
>> Thanks a lot!
>>
>> --
>> Dimitri
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Dimitri Liakhovitski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Thu Dec 22 11:11:28 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Dec 2016 11:11:28 +0100
Subject: [R] Tomas Kalibera joins the R core team
Message-ID: <22619.42704.738227.771907@stat.math.ethz.ch>

We are very happy to announce that

Tomas Kalibera (e.g. https://github.com/kalibera )

has joined the R core team (on Dec 17).  He has been a
contributor to the R source with numerous improvements
since mid 2014. 

Note that he's been among the five newly elected
ordinary members of the R Foundation in early November,
https://stat.ethz.ch/pipermail/r-announce/2016/000609.html


For the R core team, 
Martin Maechler, ETH Zurich

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From marna.wagley at gmail.com  Thu Dec 22 14:08:11 2016
From: marna.wagley at gmail.com (Marna Wagley)
Date: Thu, 22 Dec 2016 05:08:11 -0800
Subject: [R] Any help on R code interpretation?
Message-ID: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>

HI R user,
I was looking a r code and saw "%*%t", what does it("%*%t") mean?. The
example is given below.

For example: here is the code where "%*%t" has been used. when I run the
formula but did not run in my data.

prediction=plogis(as.matrix(mod7)%*%t(with(subset(data,site!='AB'),cbind(1,
site=='BC', site =='MM', site =='XY',Temp,Treatment=='Local'))))

Can I get the same result of above using the following code? Do both codes
give same results?

ab<-with(subset(data,site!='AB'),cbind(1,site=='BC', site =='MM', site ==
'XY',Temp,Treatment=='Local'))
prediction =plogis(as.matrix(mod7),(ab))

Thanks,

MW

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Dec 22 14:23:21 2016
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 22 Dec 2016 14:23:21 +0100
Subject: [R] Any help on R code interpretation?
In-Reply-To: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
References: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
Message-ID: <CAJuCY5zLVYJiL6FpsP+eqCHFg=viaxom5vvOoLUA0sGzcVcaYw@mail.gmail.com>

Dear Marna,

It's a combinations of two functions: %*% and t()
help("%*%") and help("t") will open their helpfiles.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2016-12-22 14:08 GMT+01:00 Marna Wagley <marna.wagley at gmail.com>:

> HI R user,
> I was looking a r code and saw "%*%t", what does it("%*%t") mean?. The
> example is given below.
>
> For example: here is the code where "%*%t" has been used. when I run the
> formula but did not run in my data.
>
> prediction=plogis(as.matrix(mod7)%*%t(with(subset(data,
> site!='AB'),cbind(1,
> site=='BC', site =='MM', site =='XY',Temp,Treatment=='Local'))))
>
> Can I get the same result of above using the following code? Do both codes
> give same results?
>
> ab<-with(subset(data,site!='AB'),cbind(1,site=='BC', site =='MM', site ==
> 'XY',Temp,Treatment=='Local'))
> prediction =plogis(as.matrix(mod7),(ab))
>
> Thanks,
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Thu Dec 22 14:29:01 2016
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 22 Dec 2016 08:29:01 -0500
Subject: [R] Any help on R code interpretation?
In-Reply-To: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
References: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
Message-ID: <87752BBA-BE6E-4F48-BAB6-6BFF7B38A5B1@bigelow.org>

Hi,

It's a bit hard to read what you have provided (don't forget that code pasted into emails on this list are best rendered if the email client is configured for plain text not html), but I suspect that it there is no %*%t. Instead, I think it should look like...

x %*% t(y)

where your x is 'mod7' and your y is all that other stuff. You might try ...

prediction = plogis( as.matrix( mod7 %*% t(ab) ) )

but that's just a guess.

Ben


> On Dec 22, 2016, at 8:08 AM, Marna Wagley <marna.wagley at gmail.com> wrote:
> 
> HI R user,
> I was looking a r code and saw "%*%t", what does it("%*%t") mean?. The
> example is given below.
> 
> For example: here is the code where "%*%t" has been used. when I run the
> formula but did not run in my data.
> 
> prediction=plogis(as.matrix(mod7)%*%t(with(subset(data,site!='AB'),cbind(1,
> site=='BC', site =='MM', site =='XY',Temp,Treatment=='Local'))))
> 
> Can I get the same result of above using the following code? Do both codes
> give same results?
> 
> ab<-with(subset(data,site!='AB'),cbind(1,site=='BC', site =='MM', site ==
> 'XY',Temp,Treatment=='Local'))
> prediction =plogis(as.matrix(mod7),(ab))
> 
> Thanks,
> 
> MW
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From milujisb at gmail.com  Thu Dec 22 15:19:10 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Thu, 22 Dec 2016 15:19:10 +0100
Subject: [R] Reshape to wide format
In-Reply-To: <69d5c080a2444e9cafdab13513eca36a@exch-2p-mbx-w2.ads.tamu.edu>
References: <CAMLwc7O7kCZbeMXie8irri7Xn564VsSQ-pN2=Y8eGwqYWdXqBQ@mail.gmail.com>
	<CA+8X3fXtsir220YwpgRZ20wktiYRm=Br887SCU_vY3V89ZGYXA@mail.gmail.com>
	<69d5c080a2444e9cafdab13513eca36a@exch-2p-mbx-w2.ads.tamu.edu>
Message-ID: <CAMLwc7NKrgzz9_7nUDaPtKwbcrtv4Vr3BbjRBspW1a=zWZivtw@mail.gmail.com>

Apologies for the late reply. Thank you very much!

I get the following warnings. If I modify the code to add both month and
year as part of the ID, will it still be correct?

df$ID<-paste(df$iso3,df$lon,df$lat,df$year,df$month,sep="")

wide <- reshape(df, v.names="precip", timevar="ID", idvar="month",
                direction="wide",  drop=c("iso3", "lon", "lat", "year"))

Sincerely,

Milu

warnings()
Warning messages:
1: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
  some constant variables (year) are really varying
2: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
  multiple rows match for ID=AFG6132: first taken
3: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
  multiple rows match for ID=AFG6133: first taken
4: In reshapeWide(data, idvar = idvar, timevar = timevar,  ... :
  multiple rows match for ID=AFG6134: first taken

On Tue, Dec 13, 2016 at 6:21 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> You can also use function reshape() in stats:
>
> temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
> wide <- reshape(temp, v.names="precip", timevar="ID", idvar="month",
>      direction="wide",  drop=c("iso3", "lon", "lat", "dm"))
> wide
>
>    month precip.AFG6132 precip.AFG6133
> 1      1      0.9966658    1.133129032
> 2      2      0.1567117    0.355208276
> 3      3      0.2424774    0.307277419
> 4      4      0.0000000    0.008316000
> 5      5      0.0000000    0.000000000
> 6      6      0.0000000    0.000000000
> 7      7      0.0000000    0.000000000
> 8      8      0.0000000    0.000836129
> 9      9      0.0000000             NA
> 10    10      0.0000000             NA
> 11    11      0.1215360             NA
> 12    12      0.3886606             NA
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
> Sent: Tuesday, December 13, 2016 2:59 AM
> To: Miluji Sb; r-help mailing list
> Subject: Re: [R] Reshape to wide format
>
> Hi Milu,
> I may have the wrong idea, but is this what you want?
>
> temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
> library(prettyR)
> newtemp<-stretch_df(temp,"month","precip")[,c(5,7,8)]
> names(newtemp)<-c("month",unique(temp$ID))
>
> Jim
>
>
> On Tue, Dec 13, 2016 at 4:10 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > Dear all,
> >
> > I have the following monthly data by coordinates:
> >
> > I would like to reshape this data to wide format so that each column is a
> > coordinate and each row is a month,
> >
> > coordinate1 coordinate2 coordinate3...
> > Month 1
> > Month 2
> >
> > Is the best option to concatenate the iso3, lon, and lat variables to
> > create an ID variable? I realize that this question might be very basic
> but
> > I'm slightly baffled. Thank you.
> >
> > temp <- dput(head(precip_2000,20))
> > structure(list(iso3 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("AFG",
> > "AGO", "ALB", "ARE", "ARG", "ARM", "AUS", "AUT", "AZE", "BDI",
> > "BEL", "BEN", "BFA", "BGD", "BGR", "BHS", "BIH", "BLR", "BLZ",
> > "BOL", "BRA", "BRN", "BTN", "BWA", "CAF", "CAN", "CHE", "CHL",
> > "CHN", "CIV", "CMR", "COD", "COG", "COL", "CRI", "CUB", "CYP",
> > "CZE", "DEU", "DJI", "DNK", "DOM", "DZA", "ECU", "EGY", "ERI",
> > "ESH", "ESP", "EST", "ETH", "FIN", "FJI", "FLK", "FRA", "GAB",
> > "GBR", "GEO", "GHA", "GIN", "GNB", "GNQ", "GRC", "GRL", "GTM",
> > "GUF", "GUY", "HND", "HRV", "HTI", "HUN", "IDN", "IND", "IRL",
> > "IRN", "IRQ", "ISL", "ISR", "ITA", "JAM", "JOR", "JPN", "KAZ",
> > "KEN", "KGZ", "KHM", "KIR", "KOR", "KWT", "LAO", "LBN", "LBR",
> > "LBY", "LCA", "LKA", "LSO", "LTU", "LUX", "LVA", "MAR", "MDA",
> > "MDG", "MEX", "MKD", "MLI", "MMR", "MNE", "MNG", "MOZ", "MRT",
> > "MWI", "MYS", "NAM", "NCL", "NER", "NGA", "NIC", "NLD", "NOR",
> > "NPL", "NZL", "OMN", "PAK", "PAN", "PER", "PHL", "PNG", "POL",
> > "PRI", "PRK", "PRT", "PRY", "QAT", "ROU", "RUS", "RWA", "SAU",
> > "SDN", "SEN", "SJM", "SLB", "SLE", "SLV", "SOM", "SRB", "SUR",
> > "SVK", "SVN", "SWE", "SWZ", "SYR", "TCD", "TGO", "THA", "TJK",
> > "TKM", "TLS", "TUN", "TUR", "TWN", "TZA", "UGA", "UKR", "URY",
> > "USA", "UZB", "VEN", "VNM", "VUT", "YEM", "ZAF", "ZMB", "ZWE"
> > ), class = "factor"), lon = c(61L, 61L, 61L, 61L, 61L, 61L, 61L,
> > 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L
> > ), lat = c(32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L,
> > 32L, 32L, 33L, 33L, 33L, 33L, 33L, 33L, 33L, 33L), dm = structure(c(1L,
> > 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 1L, 5L, 6L, 7L,
> > 8L, 9L, 10L, 11L), .Label = c("2000m1", "2000m10", "2000m11",
> > "2000m12", "2000m2", "2000m3", "2000m4", "2000m5", "2000m6",
> > "2000m7", "2000m8", "2000m9"), class = "factor"), month = c(1L,
> > 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
> > 5L, 6L, 7L, 8L), precip = c(0.996665806451613, 0.156711724137931,
> > 0.242477419354839, 0, 0, 0, 0, 0, 0, 0, 0.121536, 0.38866064516129,
> > 1.13312903225806, 0.355208275862069, 0.307277419354839, 0.008316,
> > 0, 0, 0, 0.0008361290322581)), .Names = c("iso3", "lon", "lat",
> > "dm", "month", "precip"), row.names = c(NA, 20L), class = "data.frame")
> >
> > Sincerely,
> >
> > Milu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Dec 22 16:08:07 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Dec 2016 07:08:07 -0800
Subject: [R] Any help on R code interpretation?
In-Reply-To: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
References: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
Message-ID: <CAGxFJbSdLXuOK7Ejmb_gjxUem1BTx772fod5ExEK0bCLCe=Gcg@mail.gmail.com>

?"%*%"
?t

It looks like you need to spend some (more) time with an R tutorial or
two to understand basic R syntax. Please do so before posting further
here. There are many good ones on the web.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 22, 2016 at 5:08 AM, Marna Wagley <marna.wagley at gmail.com> wrote:
> HI R user,
> I was looking a r code and saw "%*%t", what does it("%*%t") mean?. The
> example is given below.
>
> For example: here is the code where "%*%t" has been used. when I run the
> formula but did not run in my data.
>
> prediction=plogis(as.matrix(mod7)%*%t(with(subset(data,site!='AB'),cbind(1,
> site=='BC', site =='MM', site =='XY',Temp,Treatment=='Local'))))
>
> Can I get the same result of above using the following code? Do both codes
> give same results?
>
> ab<-with(subset(data,site!='AB'),cbind(1,site=='BC', site =='MM', site ==
> 'XY',Temp,Treatment=='Local'))
> prediction =plogis(as.matrix(mod7),(ab))
>
> Thanks,
>
> MW
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From david.w.watson at nasa.gov  Thu Dec 22 14:25:58 2016
From: david.w.watson at nasa.gov (Watson, David W. (MSFC-ES62))
Date: Thu, 22 Dec 2016 13:25:58 +0000
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct
 RC version
In-Reply-To: <70404155-C05F-45A4-A0C1-DE80DABF94D9@neuwirth.priv.at>
References: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>
	<6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>
	<70404155-C05F-45A4-A0C1-DE80DABF94D9@neuwirth.priv.at>
Message-ID: <81585C87-941A-4139-9681-E46D4513F101@nasa.gov>

I downloaded the file R-3.3-branch-mavericks-sa-x86_64.tar.gz<http://r.research.att.com/mavericks/R-3.3-branch/R-3.3-branch-mavericks-sa-x86_64.tar.gz> from http://r.research.att.com and unpacked it. What was downloaded was R version 3.3.2 RC (2016-10-26 r71594), not the advertised patched version.



David Watson
NASA - MSFC
Mail Code ES62
Phone 256-544-1300
FAX   256-544-2964
david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>






On Dec 22, 2016, at 2:47 AM, Erich Subscriptions <erich.subs at neuwirth.priv.at<mailto:erich.subs at neuwirth.priv.at>> wrote:

Current builds for R for Macs are available from
http://r.research.att.com

On 22 Dec 2016, at 07:45, Berend Hasselman <bhh at xs4all.nl> wrote:


On 21 Dec 2016, at 14:23, Watson, David W. (MSFC-ES62) <david.w.watson at nasa.gov> wrote:

I have been trying to download the ?patched? version of 3.3.2 for Mac from CRAN, but the version that gets delivered is actually the October Release Candidate version,
(R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?



Send this message to the R-SIG-Mac mailinglist. More likely to get response.

Berend Hasselman

David Watson
NASA - MSFC
Mail Code ES62
Phone 256-544-1300
FAX   256-544-2964
david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From erich.subs at neuwirth.priv.at  Thu Dec 22 09:47:01 2016
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Thu, 22 Dec 2016 09:47:01 +0100
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct
 RC version
In-Reply-To: <6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>
References: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>
	<6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>
Message-ID: <70404155-C05F-45A4-A0C1-DE80DABF94D9@neuwirth.priv.at>

Current builds for R for Macs are available from
http://r.research.att.com

> On 22 Dec 2016, at 07:45, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
>> On 21 Dec 2016, at 14:23, Watson, David W. (MSFC-ES62) <david.w.watson at nasa.gov> wrote:
>> 
>> I have been trying to download the ?patched? version of 3.3.2 for Mac from CRAN, but the version that gets delivered is actually the October Release Candidate version,
>> (R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?
>> 
> 
> 
> Send this message to the R-SIG-Mac mailinglist. More likely to get response.
> 
> Berend Hasselman
> 
>> David Watson
>> NASA - MSFC
>> Mail Code ES62
>> Phone 256-544-1300
>> FAX   256-544-2964
>> david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From itpro1 at yandex.ru  Thu Dec 22 14:17:28 2016
From: itpro1 at yandex.ru (itpro)
Date: Thu, 22 Dec 2016 16:17:28 +0300
Subject: [R] histogram first bar wrong position
Message-ID: <429051482412648@web22g.yandex.ru>

Hi, everyone.


I stumbled upon weird histogram behaviour.

Consider this "dice emulator":
Step 1: Generate uniform random array x of size N.
Step 2: Multiply each item by six and round to next bigger integer to get numbers 1 to 6.
Step 3: Plot histogram.

> x<-runif(N)
> y<-ceiling(x*6)
> hist(y,freq=TRUE, col='orange')


Now what I get with N=100000

> x<-runif(100000)
> y<-ceiling(x*6)
> hist(y,freq=TRUE, col='green')

At first glance looks OK.

Now try N=100

> x<-runif(100)
> y<-ceiling(x*6)
> hist(y,freq=TRUE, col='red')

Now first bar is not where it should be.
Hmm. Look again to 100000 histogram... First bar is not where I want it, it's only less striking due to narrow bars.

So, first bar is always in wrong position. How do I fix it to make perfectly spaced bars?





-------------- next part --------------
A non-text attachment was scrubbed...
Name: r100.png
Type: image/png
Size: 21541 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161222/174d507d/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: r100000.png
Type: image/png
Size: 22247 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161222/174d507d/attachment-0001.png>

From ruipbarradas at sapo.pt  Thu Dec 22 14:27:39 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 22 Dec 2016 13:27:39 +0000
Subject: [R] Any help on R code interpretation?
In-Reply-To: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
References: <CAMwU6B24rYQuWPy1_8kFucQBpXN9U772U3UHBZ3hijm4YXtKoA@mail.gmail.com>
Message-ID: <585BD4CB.8000305@sapo.pt>

Hello,

t() is the transpose function, it computes the transpose of matrix

with(subset(data,site!='AB'),cbind(1,
site=='BC', site =='MM', site =='XY',Temp,Treatment=='Local'))

then %*% is matrix multiplication. If you have doubts on the result, 
compute as.matrix(mod7)%*%t(...) outside the call to plogis.

And no, the two codes do not give the same results. Read the help page 
?plogis to find out the arguments to that function.

Hope this helps,

Rui Barradas

Em 22-12-2016 13:08, Marna Wagley escreveu:
> HI R user,
> I was looking a r code and saw "%*%t", what does it("%*%t") mean?. The
> example is given below.
>
> For example: here is the code where "%*%t" has been used. when I run the
> formula but did not run in my data.
>
> prediction=plogis(as.matrix(mod7)%*%t(with(subset(data,site!='AB'),cbind(1,
> site=='BC', site =='MM', site =='XY',Temp,Treatment=='Local'))))
>
> Can I get the same result of above using the following code? Do both codes
> give same results?
>
> ab<-with(subset(data,site!='AB'),cbind(1,site=='BC', site =='MM', site ==
> 'XY',Temp,Treatment=='Local'))
> prediction =plogis(as.matrix(mod7),(ab))
>
> Thanks,
>
> MW
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Thu Dec 22 17:19:14 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Dec 2016 17:19:14 +0100
Subject: [R] histogram first bar wrong position
In-Reply-To: <429051482412648@web22g.yandex.ru>
References: <429051482412648@web22g.yandex.ru>
Message-ID: <22619.64770.435473.194979@stat.math.ethz.ch>

>>>>> itpro  <itpro1 at yandex.ru>
>>>>>     on Thu, 22 Dec 2016 16:17:28 +0300 writes:

    > Hi, everyone.
    > I stumbled upon weird histogram behaviour.

    > Consider this "dice emulator":
    > Step 1: Generate uniform random array x of size N.
    > Step 2: Multiply each item by six and round to next bigger integer to get numbers 1 to 6.
    > Step 3: Plot histogram.

    >> x<-runif(N)
    >> y<-ceiling(x*6)
    >> hist(y,freq=TRUE, col='orange')


    > Now what I get with N=100000

    >> x<-runif(100000)
    >> y<-ceiling(x*6)
    >> hist(y,freq=TRUE, col='green')

    > At first glance looks OK.

    > Now try N=100

    >> x<-runif(100)
    >> y<-ceiling(x*6)
    >> hist(y,freq=TRUE, col='red')

    > Now first bar is not where it should be.
    > Hmm. Look again to 100000 histogram... First bar is not where I want it, it's only less striking due to narrow bars.

    > So, first bar is always in wrong position. How do I fix it to make perfectly spaced bars?

Don't use histograms *at all* for such discrete integer data.

 N <- rpois(100, 5)
 plot(table(N), lwd = 4)

Histograms should be only be used for continuous data (or discrete data
with "many" possible values).

It's a pain to see them so often "misused" for data like the 'N' above.

Martin Maechler,
ETH Zurich


From dwinsemius at comcast.net  Thu Dec 22 17:19:46 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Dec 2016 08:19:46 -0800
Subject: [R] "Patched " version listed on CRAN mirrors is actually Oct
	RC version
In-Reply-To: <81585C87-941A-4139-9681-E46D4513F101@nasa.gov>
References: <C2246578-290B-4722-92E1-4B86B124D6FC@nasa.gov>
	<6647CF34-350D-406A-8F9B-5C8F3B0E6290@xs4all.nl>
	<70404155-C05F-45A4-A0C1-DE80DABF94D9@neuwirth.priv.at>
	<81585C87-941A-4139-9681-E46D4513F101@nasa.gov>
Message-ID: <9795D97F-25B1-42FC-92EF-1263B32EAC74@comcast.net>


> On Dec 22, 2016, at 5:25 AM, Watson, David W. (MSFC-ES62) <david.w.watson at nasa.gov> wrote:
> 
> I downloaded the file R-3.3-branch-mavericks-sa-x86_64.tar.gz<http://r.research.att.com/mavericks/R-3.3-branch/R-3.3-branch-mavericks-sa-x86_64.tar.gz> from http://r.research.att.com and unpacked it. What was downloaded was R version 3.3.2 RC (2016-10-26 r71594), not the advertised patched version.

Usually it is the case that the versions at CRAN and at the r.research.att.com site are the same. It appears that Simon forgot to update his own site when he pushed the current version to CRAN. As I showed in my earlier posting yesterday, the CRAN site delivers a more recent version. I suspect it does not have a Patched label because it was the final release and has not been modified since then.

> R.version[["svn rev"]]
[1] "71607"


You should be posting any further responses to R-SIG-Mac.


-- 
The other David W.


> 
> 
> 
> David Watson
> NASA - MSFC
> Mail Code ES62
> Phone 256-544-1300
> FAX   256-544-2964
> david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>
> 
> 
> 
> 
> 
> 
> On Dec 22, 2016, at 2:47 AM, Erich Subscriptions <erich.subs at neuwirth.priv.at<mailto:erich.subs at neuwirth.priv.at>> wrote:
> 
> Current builds for R for Macs are available from
> http://r.research.att.com
> 
> On 22 Dec 2016, at 07:45, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
> 
> On 21 Dec 2016, at 14:23, Watson, David W. (MSFC-ES62) <david.w.watson at nasa.gov> wrote:
> 
> I have been trying to download the ?patched? version of 3.3.2 for Mac from CRAN, but the version that gets delivered is actually the October Release Candidate version,
> (R version 3.3.2 RC (2016-10-26 r71594). It has been doing this since 3.3.2 has been released. Is there a real patched version somewhere?
> 
> 
> 
> Send this message to the R-SIG-Mac mailinglist. More likely to get response.
> 
> Berend Hasselman
> 
> David Watson
> NASA - MSFC
> Mail Code ES62
> Phone 256-544-1300
> FAX   256-544-2964
> david.w.watson at nasa.gov<mailto:david.w.watson at nasa.gov>
> 
> 
> [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Dec 22 17:36:34 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 22 Dec 2016 08:36:34 -0800
Subject: [R] histogram first bar wrong position
In-Reply-To: <429051482412648@web22g.yandex.ru>
References: <429051482412648@web22g.yandex.ru>
Message-ID: <CAF8bMcbgxOkSdk7B3viiXEjd3OMAXRHknZXJM9rJSJ6UxiSx1w@mail.gmail.com>

Looking at the return value of hist will show you what is happening:

> x <- rep(1:6,10*(6:1))
> z <- hist(x, freq=TRUE)
> z
$breaks
 [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0

$counts
 [1] 60 50  0 40  0 30  0 20  0 10
...

The the first bin is [1-1.5], including both endpoints, while the other
bins include only the upper endpoint.  I recommend defining your
own breakpoints, ones don't include possible data points, as in

> print(hist(x, breaks=seq(min(x)-0.5, max(x)+0.5, by=1), freq=TRUE))
$breaks
[1] 0.5 1.5 2.5 3.5 4.5 5.5 6.5

$counts
[1] 60 50 40 30 20 10
...

S+ had a 'factor' method for hist() that did this sort of thing, but R does
not.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Dec 22, 2016 at 5:17 AM, itpro <itpro1 at yandex.ru> wrote:

> Hi, everyone.
>
>
> I stumbled upon weird histogram behaviour.
>
> Consider this "dice emulator":
> Step 1: Generate uniform random array x of size N.
> Step 2: Multiply each item by six and round to next bigger integer to get
> numbers 1 to 6.
> Step 3: Plot histogram.
>
> > x<-runif(N)
> > y<-ceiling(x*6)
> > hist(y,freq=TRUE, col='orange')
>
>
> Now what I get with N=100000
>
> > x<-runif(100000)
> > y<-ceiling(x*6)
> > hist(y,freq=TRUE, col='green')
>
> At first glance looks OK.
>
> Now try N=100
>
> > x<-runif(100)
> > y<-ceiling(x*6)
> > hist(y,freq=TRUE, col='red')
>
> Now first bar is not where it should be.
> Hmm. Look again to 100000 histogram... First bar is not where I want it,
> it's only less striking due to narrow bars.
>
> So, first bar is always in wrong position. How do I fix it to make
> perfectly spaced bars?
>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Dec 22 18:08:35 2016
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 22 Dec 2016 09:08:35 -0800
Subject: [R] histogram first bar wrong position
In-Reply-To: <22619.64770.435473.194979@stat.math.ethz.ch>
References: <429051482412648@web22g.yandex.ru>
	<22619.64770.435473.194979@stat.math.ethz.ch>
Message-ID: <CAF8bMcZL7tsyup8LnNxO7dtzw920cLbQCsWXBM_smRv3tXc6Bg@mail.gmail.com>

As a practical matter, 'continuous' data must be discretized, so if you
have long vectors of it you will run into this problem.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Dec 22, 2016 at 8:19 AM, Martin Maechler <maechler at stat.math.ethz.ch
> wrote:

> >>>>> itpro  <itpro1 at yandex.ru>
> >>>>>     on Thu, 22 Dec 2016 16:17:28 +0300 writes:
>
>     > Hi, everyone.
>     > I stumbled upon weird histogram behaviour.
>
>     > Consider this "dice emulator":
>     > Step 1: Generate uniform random array x of size N.
>     > Step 2: Multiply each item by six and round to next bigger integer
> to get numbers 1 to 6.
>     > Step 3: Plot histogram.
>
>     >> x<-runif(N)
>     >> y<-ceiling(x*6)
>     >> hist(y,freq=TRUE, col='orange')
>
>
>     > Now what I get with N=100000
>
>     >> x<-runif(100000)
>     >> y<-ceiling(x*6)
>     >> hist(y,freq=TRUE, col='green')
>
>     > At first glance looks OK.
>
>     > Now try N=100
>
>     >> x<-runif(100)
>     >> y<-ceiling(x*6)
>     >> hist(y,freq=TRUE, col='red')
>
>     > Now first bar is not where it should be.
>     > Hmm. Look again to 100000 histogram... First bar is not where I want
> it, it's only less striking due to narrow bars.
>
>     > So, first bar is always in wrong position. How do I fix it to make
> perfectly spaced bars?
>
> Don't use histograms *at all* for such discrete integer data.
>
>  N <- rpois(100, 5)
>  plot(table(N), lwd = 4)
>
> Histograms should be only be used for continuous data (or discrete data
> with "many" possible values).
>
> It's a pain to see them so often "misused" for data like the 'N' above.
>
> Martin Maechler,
> ETH Zurich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Ted.Harding at wlandres.net  Thu Dec 22 18:23:30 2016
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Thu, 22 Dec 2016 17:23:30 -0000 (GMT)
Subject: [R] histogram first bar wrong position
In-Reply-To: <CAF8bMcbgxOkSdk7B3viiXEjd3OMAXRHknZXJM9rJSJ6UxiSx1w@mail.gmail.com>
Message-ID: <XFMail.20161222172330.Ted.Harding@wlandres.net>

Willam has listed the lid on the essence of the problem, which is
that in R the way that breaks (and therefore counts) in a histogram
are evaluated is an area of long grass with lurking snakes!

To get a glimpse of this, have a look at
  ?hist
and in the seaction "Arguments", look at "breaks", "freq", "right".
Also see under "Details".

and, as suggested under "See also", look at
  ?nclass.Sturges

As William suggests, if you know what claa intervals you want,
create them yourself! For your example (with N=100), look at:

   hist(y,freq=TRUE, col='red', breaks=0.5+(0:6))

or

   hist(y,freq=TRUE, col='red', breaks=0.25+(0:12)/2)

Hoping this helps!
Best wishes,
Ted.


On 22-Dec-2016 16:36:34 William Dunlap via R-help wrote:
> Looking at the return value of hist will show you what is happening:
> 
>> x <- rep(1:6,10*(6:1))
>> z <- hist(x, freq=TRUE)
>> z
> $breaks
>  [1] 1.0 1.5 2.0 2.5 3.0 3.5 4.0 4.5 5.0 5.5 6.0
> 
> $counts
>  [1] 60 50  0 40  0 30  0 20  0 10
> ...
> 
> The the first bin is [1-1.5], including both endpoints, while the other
> bins include only the upper endpoint.  I recommend defining your
> own breakpoints, ones don't include possible data points, as in
> 
>> print(hist(x, breaks=seq(min(x)-0.5, max(x)+0.5, by=1), freq=TRUE))
> $breaks
> [1] 0.5 1.5 2.5 3.5 4.5 5.5 6.5
> 
> $counts
> [1] 60 50 40 30 20 10
> ...
> 
> S+ had a 'factor' method for hist() that did this sort of thing, but R does
> not.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Dec 22, 2016 at 5:17 AM, itpro <itpro1 at yandex.ru> wrote:
> 
>> Hi, everyone.
>>
>>
>> I stumbled upon weird histogram behaviour.
>>
>> Consider this "dice emulator":
>> Step 1: Generate uniform random array x of size N.
>> Step 2: Multiply each item by six and round to next bigger integer to get
>> numbers 1 to 6.
>> Step 3: Plot histogram.
>>
>> > x<-runif(N)
>> > y<-ceiling(x*6)
>> > hist(y,freq=TRUE, col='orange')
>>
>>
>> Now what I get with N=100000
>>
>> > x<-runif(100000)
>> > y<-ceiling(x*6)
>> > hist(y,freq=TRUE, col='green')
>>
>> At first glance looks OK.
>>
>> Now try N=100
>>
>> > x<-runif(100)
>> > y<-ceiling(x*6)
>> > hist(y,freq=TRUE, col='red')
>>
>> Now first bar is not where it should be.
>> Hmm. Look again to 100000 histogram... First bar is not where I want it,
>> it's only less striking due to narrow bars.
>>
>> So, first bar is always in wrong position. How do I fix it to make
>> perfectly spaced bars?
>>
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
>       [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 22-Dec-2016  Time: 17:23:26
This message was sent by XFMail


From george.trojan at noaa.gov  Thu Dec 22 19:24:03 2016
From: george.trojan at noaa.gov (George Trojan - NOAA Federal)
Date: Thu, 22 Dec 2016 18:24:03 +0000
Subject: [R] gamlss question
Message-ID: <CABie7_r78ciifsMVgEL0R0FMHuVqE2iT48ELx49Xf8ys-pSeDQ@mail.gmail.com>

What is the recommended way of accessing distribution parameters (mu,
sigma, ...) from the model fit? The indention is to use those values in
d/p/q/r calls. I came out with a wrapper

gamlss_fit <- function(x, family) {
    fit <- gamlssML(x, family = family)
    mu <- fitted(fit, "mu")[1]
    sigma <- fitted(fit, "sigma")[1]
    nu <- ifelse("nu" %in% fit$parameters, fitted(fit, "nu")[1], NA)
    tau <- ifelse("tau" %in% fit$parameters, fitted(fit, "tau")[1], NA)
    list(mu = mu, sigma = sigma, nu = nu, tau = tau)
}

Alternatively, I could write functions to emulate logspline calls to
density estimation.

I suspect I must be missing something obvious. I am relatively new to R.

George

	[[alternative HTML version deleted]]


From yungchihlai at gmail.com  Thu Dec 22 20:54:47 2016
From: yungchihlai at gmail.com (Yung-Chih Lai)
Date: Thu, 22 Dec 2016 11:54:47 -0800
Subject: [R] How to scale circle sizes in VennDiagram using
	draw.triple.venn
In-Reply-To: <CAKVAULMzJgep+QQ5YVwuBwcPX8ky_uWsUsY9D4RafR8mQBk5gg@mail.gmail.com>
References: <CAB11ZD6_=jL09SumfgCYEgm-cHD2Zz3DZuDkLhA1TFn17oiC2Q@mail.gmail.com>
	<CAKVAULMzJgep+QQ5YVwuBwcPX8ky_uWsUsY9D4RafR8mQBk5gg@mail.gmail.com>
Message-ID: <CAB11ZD7H_tN--xLmApvhgj=JPmYs1_zGhAYBTp7cD2+v-yp6zQ@mail.gmail.com>

Hi Ulrik,

It seems that VennDiagram cannot draw weighted diagrams. Many thanks for
your information.

Best,

Gary

On Fri, Dec 16, 2016 at 4:09 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
wrote:

> I usually use the package Vennerable for all my Venn needs. It also has
> the option to draw weighted diagrams.
>
> HTH
> Ulrik
>
> Yung-Chih Lai <yungchihlai at gmail.com> schrieb am Fr., 16. Dez. 2016,
> 21:40:
>
>> Hi,
>>
>>
>> The below is the command I used to create a Venn diagram with three sets.
>> However, the three circle sizes are the same. Could you show me how to
>> adjust the circle size based on the area size? Many thanks.
>>
>> grid.newpage()
>>
>> draw.triple.venn(area1 = 9737, area2 = 13329, area3 = 6300, n12 = 8612,
>> n23
>> = 6176, n13 = 5781, n123 = 5748, category = c("G8_13", "G8_14", "G8_15"),
>> lty = "blank", fill = c("pink", "light blue", "orange"))
>>
>>
>> Best,
>>
>>
>> Gary
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

	[[alternative HTML version deleted]]


From ulrik.stervbo at gmail.com  Thu Dec 22 23:33:47 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Thu, 22 Dec 2016 22:33:47 +0000
Subject: [R] How to scale circle sizes in VennDiagram using
	draw.triple.venn
In-Reply-To: <CAB11ZD7H_tN--xLmApvhgj=JPmYs1_zGhAYBTp7cD2+v-yp6zQ@mail.gmail.com>
References: <CAB11ZD6_=jL09SumfgCYEgm-cHD2Zz3DZuDkLhA1TFn17oiC2Q@mail.gmail.com>
	<CAKVAULMzJgep+QQ5YVwuBwcPX8ky_uWsUsY9D4RafR8mQBk5gg@mail.gmail.com>
	<CAB11ZD7H_tN--xLmApvhgj=JPmYs1_zGhAYBTp7cD2+v-yp6zQ@mail.gmail.com>
Message-ID: <CAKVAULNpwQuMYisFqgSdp4ML-ERrpPeSFwAKQe6T0Lu89QHYAw@mail.gmail.com>

Hi Yung-Chih,

This works for me:

library(Vennerable)
data("StemCell")

venn_res <- Venn(StemCell[1:3])
plot(venn_res, doWeights = TRUE)

HTH
Ulrik

On Thu, 22 Dec 2016 at 20:54 Yung-Chih Lai <yungchihlai at gmail.com> wrote:

> Hi Ulrik,
>
> It seems that VennDiagram cannot draw weighted diagrams. Many thanks for
> your information.
>
> Best,
>
> Gary
>
> On Fri, Dec 16, 2016 at 4:09 PM, Ulrik Stervbo <ulrik.stervbo at gmail.com>
> wrote:
>
> I usually use the package Vennerable for all my Venn needs. It also has
> the option to draw weighted diagrams.
>
> HTH
> Ulrik
>
> Yung-Chih Lai <yungchihlai at gmail.com> schrieb am Fr., 16. Dez. 2016,
> 21:40:
>
> Hi,
>
>
> The below is the command I used to create a Venn diagram with three sets.
> However, the three circle sizes are the same. Could you show me how to
> adjust the circle size based on the area size? Many thanks.
>
> grid.newpage()
>
> draw.triple.venn(area1 = 9737, area2 = 13329, area3 = 6300, n12 = 8612, n23
> = 6176, n13 = 5781, n123 = 5748, category = c("G8_13", "G8_14", "G8_15"),
> lty = "blank", fill = c("pink", "light blue", "orange"))
>
>
> Best,
>
>
> Gary
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Fri Dec 23 04:24:33 2016
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 23 Dec 2016 11:24:33 +0800
Subject: [R] different between read.table and read.delim
Message-ID: <7871ad69-3aec-1830-86e9-57f422758a90@yeah.net>

Hi there,

I have a data set file, called "ecotox.rep", which is a delimited file 
separated with "|".

When I tried to read the file with the following command,

 > df <- read.table("ecotox.rep", sep = "|", header = TRUE, 
stringsAsFactors=FALSE)

I got the error messages:

Error in scan(file = file, what = what, sep = sep, quote = quote, dec = 
dec,  :
   line 113 did not have 87 elements

However, when I read the file with the following command,

 > df <- read.delim("ecotox.rep", sep = "|", header = TRUE, 
stringsAsFactors=FALSE)

I got a correct output.

If I understand correctly, read.delim() is just wrapped from 
read.table(), why read.delim() works, but read.table() doesn't.

Thanks in advance.

Best,
Jinsong


From sarah.goslee at gmail.com  Fri Dec 23 04:31:09 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 22 Dec 2016 22:31:09 -0500
Subject: [R] different between read.table and read.delim
In-Reply-To: <7871ad69-3aec-1830-86e9-57f422758a90@yeah.net>
References: <7871ad69-3aec-1830-86e9-57f422758a90@yeah.net>
Message-ID: <CAM_vju=vkbr_sJq--ga-nwyV=bw0D3cdWbwh4GvaP+AGjpr+kg@mail.gmail.com>

Look at the default arguments to each, especially the quote argument.

Sarah

On Thu, Dec 22, 2016 at 10:24 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I have a data set file, called "ecotox.rep", which is a delimited file
> separated with "|".
>
> When I tried to read the file with the following command,
>
>> df <- read.table("ecotox.rep", sep = "|", header = TRUE,
>> stringsAsFactors=FALSE)
>
> I got the error messages:
>
> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,
> :
>   line 113 did not have 87 elements
>
> However, when I read the file with the following command,
>
>> df <- read.delim("ecotox.rep", sep = "|", header = TRUE,
>> stringsAsFactors=FALSE)
>
> I got a correct output.
>
> If I understand correctly, read.delim() is just wrapped from read.table(),
> why read.delim() works, but read.table() doesn't.
>
> Thanks in advance.
>
> Best,
> Jinsong
>


From jszhao at yeah.net  Fri Dec 23 06:13:22 2016
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 23 Dec 2016 13:13:22 +0800
Subject: [R] different between read.table and read.delim
In-Reply-To: <CAM_vju=vkbr_sJq--ga-nwyV=bw0D3cdWbwh4GvaP+AGjpr+kg@mail.gmail.com>
References: <7871ad69-3aec-1830-86e9-57f422758a90@yeah.net>
	<CAM_vju=vkbr_sJq--ga-nwyV=bw0D3cdWbwh4GvaP+AGjpr+kg@mail.gmail.com>
Message-ID: <93c81839-098f-42a9-345c-7f353c8a7c58@yeah.net>

On 2016/12/23 11:31, Sarah Goslee wrote:
> Look at the default arguments to each, especially the quote argument.
>
> Sarah
>

Thank you very much!

The quote and fill argument are not same for the two function. only 
change quote or fill can not make read.table() work.

Best,
Jinsong

> On Thu, Dec 22, 2016 at 10:24 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
>> Hi there,
>>
>> I have a data set file, called "ecotox.rep", which is a delimited file
>> separated with "|".
>>
>> When I tried to read the file with the following command,
>>
>>> df <- read.table("ecotox.rep", sep = "|", header = TRUE,
>>> stringsAsFactors=FALSE)
>>
>> I got the error messages:
>>
>> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,
>> :
>>   line 113 did not have 87 elements
>>
>> However, when I read the file with the following command,
>>
>>> df <- read.delim("ecotox.rep", sep = "|", header = TRUE,
>>> stringsAsFactors=FALSE)
>>
>> I got a correct output.
>>
>> If I understand correctly, read.delim() is just wrapped from read.table(),
>> why read.delim() works, but read.table() doesn't.
>>
>> Thanks in advance.
>>
>> Best,
>> Jinsong


From dwinsemius at comcast.net  Fri Dec 23 08:07:28 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 22 Dec 2016 23:07:28 -0800
Subject: [R] different between read.table and read.delim
In-Reply-To: <93c81839-098f-42a9-345c-7f353c8a7c58@yeah.net>
References: <7871ad69-3aec-1830-86e9-57f422758a90@yeah.net>
	<CAM_vju=vkbr_sJq--ga-nwyV=bw0D3cdWbwh4GvaP+AGjpr+kg@mail.gmail.com>
	<93c81839-098f-42a9-345c-7f353c8a7c58@yeah.net>
Message-ID: <F3F8A204-52E0-41F4-949B-CBC68223F249@comcast.net>

In the future you can examine the consequence kid various choices for parameters with something along the lines of 

table( count.fields( file= .. ,  ... <parameters>))

Sent from my iPhone

> On Dec 22, 2016, at 9:13 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> 
>> On 2016/12/23 11:31, Sarah Goslee wrote:
>> Look at the default arguments to each, especially the quote argument.
>> 
>> Sarah
>> 
> 
> Thank you very much!
> 
> The quote and fill argument are not same for the two function. only change quote or fill can not make read.table() work.
> 
> Best,
> Jinsong
> 
>>> On Thu, Dec 22, 2016 at 10:24 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
>>> Hi there,
>>> 
>>> I have a data set file, called "ecotox.rep", which is a delimited file
>>> separated with "|".
>>> 
>>> When I tried to read the file with the following command,
>>> 
>>>> df <- read.table("ecotox.rep", sep = "|", header = TRUE,
>>>> stringsAsFactors=FALSE)
>>> 
>>> I got the error messages:
>>> 
>>> Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,
>>> :
>>>  line 113 did not have 87 elements
>>> 
>>> However, when I read the file with the following command,
>>> 
>>>> df <- read.delim("ecotox.rep", sep = "|", header = TRUE,
>>>> stringsAsFactors=FALSE)
>>> 
>>> I got a correct output.
>>> 
>>> If I understand correctly, read.delim() is just wrapped from read.table(),
>>> why read.delim() works, but read.table() doesn't.
>>> 
>>> Thanks in advance.
>>> 
>>> Best,
>>> Jinsong
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From milujisb at gmail.com  Fri Dec 23 12:05:52 2016
From: milujisb at gmail.com (Miluji Sb)
Date: Fri, 23 Dec 2016 12:05:52 +0100
Subject: [R] Problem with Zelig - gam.poisson
Message-ID: <CAMLwc7Oywaca2g90KBuXoqgCrvWVG1T+c7mFgCGDyzYLbnwd=w@mail.gmail.com>

I am getting the following error when trying to run a gam.possion model
with Zelig.

Error in eval(expr, envir, enclos) : attempt to apply non-function

Even the example won't run.

library(mgcv)
library(Zelig)

n <- 400
sig <- 2
x0 <- runif(n, 0, 1); x1 <- runif(n, 0, 1)
x2 <- runif(n, 0, 1); x3 <- runif(n, 0, 1)
f0 <- function(x) 2 * sin(pi * x)
f1 <- function(x) exp(2 * x)
f2 <- function(x) 0.2 * x^11 * (10 * (1 - x))^6 + 10 * (10 * x)^3 * (1 -
x)^10
f3 <- function(x) 0 * x
f <- f0(x0) + f1(x1) + f2(x2)
g <- exp(f/4)
y <- rpois(rep(1, n), g)
my.data <- as.data.frame(cbind(y, x0, x1, x2, x3))

z.out <- zelig(y ~ s(x0) + s(x1) + s(x2) + s(x3), model = "gam.poisson",
data = my.data)

What am I doing wrong? Session info is below. Thanks a lot!

Sincerely,

Milu

####
sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United
States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] Zelig_5.0-13 mgcv_1.8-15  nlme_3.1-128

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.8        nloptr_1.0.4       plyr_1.8.4
miscTools_0.6-22   tools_3.3.2        lme4_1.1-12
 [7] MatchIt_2.4-21     jsonlite_1.1       tibble_1.2
lattice_0.20-34    Matrix_1.2-7.1     DBI_0.5-1
[13] maxLik_1.3-4       parallel_3.3.2     SparseM_1.74       coda_0.18-1
     AER_1.2-4          dplyr_0.5.0
[19] MatrixModels_0.4-1 nnet_7.3-12        stats4_3.3.2       lmtest_0.9-34
     grid_3.3.2         R6_2.2.0
[25] geepack_1.2-1      survival_2.40-1    VGAM_1.0-2
foreign_0.8-67     minqa_1.2.4        Amelia_1.7.4
[31] Formula_1.2-1      car_2.1-3          magrittr_1.5       mcmc_0.9-4
      MASS_7.3-45        splines_3.3.2
[37] pbkrtest_0.4-6     assertthat_0.1     quantreg_5.29
 sandwich_2.3-4     survey_3.31-5      MCMCpack_1.3-8
[43] lazyeval_0.2.0     zoo_1.7-13

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Dec 23 13:01:16 2016
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 23 Dec 2016 13:01:16 +0100
Subject: [R] histogram first bar wrong position
In-Reply-To: <CAF8bMcZL7tsyup8LnNxO7dtzw920cLbQCsWXBM_smRv3tXc6Bg@mail.gmail.com>
References: <429051482412648@web22g.yandex.ru>
	<22619.64770.435473.194979@stat.math.ethz.ch>
	<CAF8bMcZL7tsyup8LnNxO7dtzw920cLbQCsWXBM_smRv3tXc6Bg@mail.gmail.com>
Message-ID: <22621.4620.633417.277331@stat.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Thu, 22 Dec 2016 09:08:35 -0800 writes:

    > As a practical matter, 'continuous' data must be discretized, so if you
    > have long vectors of it you will run into this problem.

    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com

Yes, it is true that on the computer and in statistics we never have
continuous data in the strict sense.

My point was  and still is that a histogram is a wrong graphical
tool to be used for visualizing a distribution
on a small finite set, as e.g., the dice rolls 'itpro' has used.

And yes, if (s)he used something like

   dice <- ceiling(6 * runif(100))

and really prefers to use  hist() over (something like)

   plot(table(dice), lwd = 6)

then an appropriate graphic would rather be

  hist(dice, freq=TRUE, col="orange", breaks = (31:(6*32))/32)

(and the default breaks from sample size N = 100'000 is indeed
 relatively close to that because as we both know the number of
 default breaks grows (slowly) with N).

For me, histograms are a (poor but easy to understand and
explain) version of density estimates  (where the underlying
density is wrt to the lebesgue measure or simlar).

Now back to large / long vectors of data:
If you need to bin large vectors, you will hopefully be binning
to rather 100's or 1000's of bins (because 1000 is still much
smaller than "large") and then you actually have computed the
data for a histogram yourself already; so I personally would
again prefer not to use hist(), but to write my own "3 line"
function that returns an "histogram" object which I'd call  plot(.) on.

So, maybe providing such a short function maybe useful, notably
on the ?hist  help page ?

Martin Maechler,
ETH Zurich


    > On Thu, Dec 22, 2016 at 8:19 AM, Martin Maechler <maechler at stat.math.ethz.ch
    >> wrote:

    >> >>>>> itpro  <itpro1 at yandex.ru>
    >> >>>>>     on Thu, 22 Dec 2016 16:17:28 +0300 writes:
    >> 
    >> > Hi, everyone.
    >> > I stumbled upon weird histogram behaviour.
    >> 
    >> > Consider this "dice emulator":
    >> > Step 1: Generate uniform random array x of size N.
    >> > Step 2: Multiply each item by six and round to next bigger integer
    >> to get numbers 1 to 6.
    >> > Step 3: Plot histogram.
    >> 
    >> >> x<-runif(N)
    >> >> y<-ceiling(x*6)
    >> >> hist(y,freq=TRUE, col='orange')
    >> 
    >> 
    >> > Now what I get with N=100000
    >> 
    >> >> x<-runif(100000)
    >> >> y<-ceiling(x*6)
    >> >> hist(y,freq=TRUE, col='green')
    >> 
    >> > At first glance looks OK.
    >> 
    >> > Now try N=100
    >> 
    >> >> x<-runif(100)
    >> >> y<-ceiling(x*6)
    >> >> hist(y,freq=TRUE, col='red')
    >> 
    >> > Now first bar is not where it should be.
    >> > Hmm. Look again to 100000 histogram... First bar is not where I want
    >> it, it's only less striking due to narrow bars.
    >> 
    >> > So, first bar is always in wrong position. How do I fix it to make
    >> perfectly spaced bars?
    >> 
    >> Don't use histograms *at all* for such discrete integer data.
    >> 
    >> N <- rpois(100, 5)
    >> plot(table(N), lwd = 4)
    >> 
    >> Histograms should be only be used for continuous data (or discrete data
    >> with "many" possible values).
    >> 
    >> It's a pain to see them so often "misused" for data like the 'N' above.
    >> 
    >> Martin Maechler,
    >> ETH Zurich
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/
    >> posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.
    >> 

    > [[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Dec 23 19:32:08 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 23 Dec 2016 19:32:08 +0100
Subject: [R] histogram first bar wrong position
In-Reply-To: <CAF8bMcZL7tsyup8LnNxO7dtzw920cLbQCsWXBM_smRv3tXc6Bg@mail.gmail.com>
References: <429051482412648@web22g.yandex.ru>
	<22619.64770.435473.194979@stat.math.ethz.ch>
	<CAF8bMcZL7tsyup8LnNxO7dtzw920cLbQCsWXBM_smRv3tXc6Bg@mail.gmail.com>
Message-ID: <BECF727F-3ED4-432D-BF81-84B826A323F7@gmail.com>


> On 22 Dec 2016, at 18:08 , William Dunlap via R-help <r-help at r-project.org> wrote:
> 
> As a practical matter, 'continuous' data must be discretized, so if you
> have long vectors of it you will run into this problem.

Yep, and it is a bit unfortunate that hist() tries to use "pretty" breakpoints, so that you will have data points on the boundaries, causing all the left/right/endpoint business to come into play. The truehist() function in MASS does somewhat better. 

For the case at hand, things are much improved by setting the breaks explicitly:

hist(y,freq=TRUE, col='red', breaks=0.5:6.5)

but as pointed out by others, it is a much better idea to do

plot(factor(y, levels=1:6))

or similar. 

Incidentally, what is the most handy way to get a plot with percentages instead of counts? This works, but seems a bit ham-fisted:

barplot(prop.table(table(factor(y, levels=1:6))))

-pd

> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> On Thu, Dec 22, 2016 at 8:19 AM, Martin Maechler <maechler at stat.math.ethz.ch
>> wrote:
> 
>>>>>>> itpro  <itpro1 at yandex.ru>
>>>>>>>    on Thu, 22 Dec 2016 16:17:28 +0300 writes:
>> 
>>> Hi, everyone.
>>> I stumbled upon weird histogram behaviour.
>> 
>>> Consider this "dice emulator":
>>> Step 1: Generate uniform random array x of size N.
>>> Step 2: Multiply each item by six and round to next bigger integer
>> to get numbers 1 to 6.
>>> Step 3: Plot histogram.
>> 
>>>> x<-runif(N)
>>>> y<-ceiling(x*6)
>>>> hist(y,freq=TRUE, col='orange')
>> 
>> 
>>> Now what I get with N=100000
>> 
>>>> x<-runif(100000)
>>>> y<-ceiling(x*6)
>>>> hist(y,freq=TRUE, col='green')
>> 
>>> At first glance looks OK.
>> 
>>> Now try N=100
>> 
>>>> x<-runif(100)
>>>> y<-ceiling(x*6)
>>>> hist(y,freq=TRUE, col='red')
>> 
>>> Now first bar is not where it should be.
>>> Hmm. Look again to 100000 histogram... First bar is not where I want
>> it, it's only less striking due to narrow bars.
>> 
>>> So, first bar is always in wrong position. How do I fix it to make
>> perfectly spaced bars?
>> 
>> Don't use histograms *at all* for such discrete integer data.
>> 
>> N <- rpois(100, 5)
>> plot(table(N), lwd = 4)
>> 
>> Histograms should be only be used for continuous data (or discrete data
>> with "many" possible values).
>> 
>> It's a pain to see them so often "misused" for data like the 'N' above.
>> 
>> Martin Maechler,
>> ETH Zurich
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From suttoncarl at ymail.com  Fri Dec 23 21:45:50 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 23 Dec 2016 20:45:50 +0000 (UTC)
Subject: [R] dput and dget error
References: <575225600.1043582.1482525950610.ref@mail.yahoo.com>
Message-ID: <575225600.1043582.1482525950610@mail.yahoo.com>

Merry Christmas and Happy Holidays

I am attempting to use dput and or dget to send data along with a help request to another list (package specific).   Read the help pages for both and they appeared to be fairly simple functions.  Found an example on github and it appeared to be an easy task to replicate.   Alas, a copy and paste of the github example worked but my toy data example did not.

#  dput and dget functions
#  Example from github
set.seed(1337)
NN <- 10
theData <- data.frame(Alpha = rnorm(NN),
                      Beta = rnorm(NN))
theData$Gamma <- theData$Alpha * 2 + theData$Beta / 2 + rnorm(NN)
dput(theData, "temporary_file")
theDataReconstitutedAgain <- dget("temporary_file")
print(theDataReconstitutedAgain)


#  try it with my "toy data"library(data.table)
library(tidyr)
#  data table for melt and columns split
dt1 <- data.table(a_1 = 1:10, b_2 = 20:29,folks = c("art","brian","ed",
"rich","dennis","frank", "derrick","paul","fred","numnuts"),
a_2 = 2:11, b_1 = 21:30)
melted <- melt(dt1, id = "folks")[,c("varType","varIndex") :=
                                 tstrsplit(variable,"_")][,variable:=NULL]
#  melted has 40 observations from stacking a and b variables
#  which have lengths of 20 each
#  here cometh the frustrtion
dput(melted,"temp_file.txt")
goGetIt <- dget("temp_file.txt", keep.source = FALSE)
print(goGetIt)


> goGetIt <- dget("temp_file.txt", keep.source = FALSE)
Error in parse(file = file, keep.source = keep.source) : 
temp_file.txt:18:36: unexpected '<'
17: "varIndex"), row.names = c(NA, -40L), class = c("data.table", 
18: "data.frame"), .internal.selfref = <
^
> print(goGetIt)
Error in print(goGetIt) : object 'goGetIt' not found
> 
the help page states dput just writes an ASCII text representation of an R object to a file or connection, or uses one to recreate the object.  Nothing there about not allowing a data frame or data table and the github example was a data frame.   The line numbers referenced do not appear to refer to my code (but maybe they do and I am ignorant of the meaning) and the code works up to the dget line.

Typing dget in the console to see the inner workings of the function was not helpful.

Also, I am unclear as to just how dput and dget work.  If I save a subset of actual data to an object, then do dput on that object, can I rely that whomever I send my code to (which includes the dput statement) be able to retrieve the data?  In other words, dput saves the data in the code file?

Thanks for your help and may the holidays be wonderful for you and your loved one.
Carl Sutton


From kristi.glover at hotmail.com  Fri Dec 23 22:56:36 2016
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Fri, 23 Dec 2016 21:56:36 +0000
Subject: [R] Problem in calculation of subpopulation mean in Survey package
 (Specify survey design with replicate weights)
Message-ID: <DM3PR13MB06525CBB8ED8B14CABACBBB1FA950@DM3PR13MB0652.namprd13.prod.outlook.com>

Hi R users,

I got a problem when I was trying to calculate the population mean for different groups (classes) in using "svrepdesign", It worked when I used entire rows  but when I introduced by classes (groups or strata), it did not work out. I read several documents but I could not figure it out to the fix the problem.

Actually, I do have about 500 data points (rows) in which there are several classes (groups). I developed the design using the svrepdesign, but when I introduced group in calculating mean, it says

""Error in qr.default(weights(design, "analysis"), tol = 1e-05) :
  NA/NaN/Inf in foreign function call (arg 1)"

I think I have to introduce groups in the design and I tried it different ways but it did not work it out. Would you mind to give some hints?I would be very grateful if you could give some hints.

here I have attached a example (format of the data) and the code I used. Thanks for your help.
have a great holidays.

MG
___

library(survey)

dat<-structure(list(ID = 1:6, group = structure(c(8L, 7L, 7L, 8L,
7L, 7L), .Label = c("groupA", "groupB", "groupC", "groupD", "groupE",
"groupF", "groupG", "groupH"), class = "factor"), ProbSelect = c(0.72,
0.62, 0.62, 0.72, 0.72, 0.62), density = c(28, 227, 65, 132,
13, 227), totalSampled = c(96L, 96L, 96L, 96L, 96L, 96L), pop = c(166L,
166L, 166L, 166L, 166L, 166L), wgt = c(2.42, 2.79, 2.79, 2.42,
2.42, 2.79)), .Names = c("ID", "group", "ProbSelect", "density",
"totalSampled", "pop", "wgt"), row.names = c(NA, 6L), class = "data.frame")

dat

design_dat<-svrepdesign(data=dat, type="bootstrap", weights = I(1/dat$ProbSelect), repweights=W[,-1],scale=bootstrap.results$scale,rscale=bootstrap.results$rscales, combined.weights=TRUE)

svymean(~ density,design=subset(design_dat, group=='groupH'),na.rm=T,digits=2)

"Error in qr.default(weights(design, "analysis"), tol = 1e-05) :
  NA/Na


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Dec 23 23:24:23 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 23 Dec 2016 14:24:23 -0800
Subject: [R] dput and dget error
In-Reply-To: <575225600.1043582.1482525950610@mail.yahoo.com>
References: <575225600.1043582.1482525950610.ref@mail.yahoo.com>
	<575225600.1043582.1482525950610@mail.yahoo.com>
Message-ID: <1609394B-852A-4D01-A337-5BDBC4283A14@comcast.net>


> On Dec 23, 2016, at 12:45 PM, Carl Sutton via R-help <r-help at r-project.org> wrote:
> 
> Merry Christmas and Happy Holidays
> 
> I am attempting to use dput and or dget to send data along with a help request to another list (package specific).   Read the help pages for both and they appeared to be fairly simple functions.  Found an example on github and it appeared to be an easy task to replicate.   Alas, a copy and paste of the github example worked but my toy data example did not.
> 
> #  dput and dget functions
> #  Example from github
> set.seed(1337)
> NN <- 10
> theData <- data.frame(Alpha = rnorm(NN),
>                      Beta = rnorm(NN))
> theData$Gamma <- theData$Alpha * 2 + theData$Beta / 2 + rnorm(NN)
> dput(theData, "temporary_file")
> theDataReconstitutedAgain <- dget("temporary_file")
> print(theDataReconstitutedAgain)
> 
> 
> #  try it with my "toy data"library(data.table)

This is a guess based on what I know about data.table-objects and how they are represented with dput. You will see an .internal.selfref = <pointer: 0x7f7fd18f2778>

But if you try to assign the value of the dput output to an R name, it's going to fail. You need to remove the .internal.selfref = <pointer: 0x7f7fd18f2778> and then assign as a data frame and run setDT() on the name.


> library(tidyr)
> #  data table for melt and columns split
> dt1 <- data.table(a_1 = 1:10, b_2 = 20:29,folks = c("art","brian","ed",
> "rich","dennis","frank", "derrick","paul","fred","numnuts"),
> a_2 = 2:11, b_1 = 21:30)
> melted <- melt(dt1, id = "folks")[,c("varType","varIndex") :=
>                                 tstrsplit(variable,"_")][,variable:=NULL]

Run this:

dput(melted)


> #  melted has 40 observations from stacking a and b variables
> #  which have lengths of 20 each
> #  here cometh the frustrtion
> dput(melted,"temp_file.txt")
> goGetIt <- dget("temp_file.txt", keep.source = FALSE)
> print(goGetIt)
> 
> 
>> goGetIt <- dget("temp_file.txt", keep.source = FALSE)
> Error in parse(file = file, keep.source = keep.source) : 
> temp_file.txt:18:36: unexpected '<'

That's because the regular R parser doesn't recognize the pointer as valid R code. It was not designed to recognize data.tables. the tidyr functions are designed to return data.frames, but `dget` is not from a package that is "data.table-aware"


> 17: "varIndex"), row.names = c(NA, -40L), class = c("data.table", 
> 18: "data.frame"), .internal.selfref = <
> ^
>> print(goGetIt)
> Error in print(goGetIt) : object 'goGetIt' not found
>> 

Try this instead:

 dput(as.data.frame(melted),"temp_file.txt")
 goGetIt <- dget("temp_file.txt", keep.source = FALSE)
 setDT(goGetIt)
 print(goGetIt)

-- 
David.
> the help page states dput just writes an ASCII text representation of an R object to a file or connection, or uses one to recreate the object.  Nothing there about not allowing a data frame or data table and the github example was a data frame.   The line numbers referenced do not appear to refer to my code (but maybe they do and I am ignorant of the meaning) and the code works up to the dget line.
> 
> Typing dget in the console to see the inner workings of the function was not helpful.
> 
> Also, I am unclear as to just how dput and dget work.  If I save a subset of actual data to an object, then do dput on that object, can I rely that whomever I send my code to (which includes the dput statement) be able to retrieve the data?  In other words, dput saves the data in the code file?
> 
> Thanks for your help and may the holidays be wonderful for you and your loved one.
> Carl Sutton
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From abrogard at yahoo.com  Sat Dec 24 00:40:18 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Fri, 23 Dec 2016 23:40:18 +0000 (UTC)
Subject: [R] Is there a funct to sum differences?
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
Message-ID: <703412216.1105374.1482536418760@mail.yahoo.com>

I've been looking but I can't find a function to sum difference.

I have this code:

 
rates$thisone <- c(diff(rates$Int), NA)
rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
rates$lastone <- (rates$thisone + rates$nextone)


It is looking down one long column of numbers.

It sums the difference between the first two and then between the first and third and so on.

Can it be made to automatically sum the difference between the first and subsequent to the end of a list?


From suttoncarl at ymail.com  Sat Dec 24 00:40:21 2016
From: suttoncarl at ymail.com (Carl Sutton)
Date: Fri, 23 Dec 2016 23:40:21 +0000 (UTC)
Subject: [R] dput and dget error
In-Reply-To: <1609394B-852A-4D01-A337-5BDBC4283A14@comcast.net>
References: <575225600.1043582.1482525950610.ref@mail.yahoo.com>
	<575225600.1043582.1482525950610@mail.yahoo.com>
	<1609394B-852A-4D01-A337-5BDBC4283A14@comcast.net>
Message-ID: <1460087999.1097311.1482536421223@mail.yahoo.com>

 Hi

Thank you David.  It was the conflict with data table that was causing the error.  Obviously I was clueless (still).


Just to check out the functionality of dput, I did the following:
1.  commented out the data line in the github example.
2.  attached the file to an email to myself.
3.  used RStudio to open the attachment and ran the code(with data creation line commented out).
The data was present.

NICE, VERY NICE INDEED.

Merry Christmas and Happy Holidays to all.  

Carl Sutton 

ps: David Winsemius is now my very best Santa Claus.




> On Friday, December 23, 2016 3:24 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> > 
>>  On Dec 23, 2016, at 12:45 PM, Carl Sutton via R-help 
> <r-help at r-project.org> wrote:
>> 
>>  Merry Christmas and Happy Holidays
>> 
>>  I am attempting to use dput and or dget to send data along with a help 
> request to another list (package specific).   Read the help pages for both and 
> they appeared to be fairly simple functions.  Found an example on github and it 
> appeared to be an easy task to replicate.   Alas, a copy and paste of the github 
> example worked but my toy data example did not.
>> 
>>  #  dput and dget functions
>>  #  Example from github
>>  set.seed(1337)
>>  NN <- 10
>>  theData <- data.frame(Alpha = rnorm(NN),
>>                       Beta = rnorm(NN))
>>  theData$Gamma <- theData$Alpha * 2 + theData$Beta / 2 + rnorm(NN)
>>  dput(theData, "temporary_file")
>>  theDataReconstitutedAgain <- dget("temporary_file")
>>  print(theDataReconstitutedAgain)
>> 
>> 
>>  #  try it with my "toy data"library(data.table)
> 
> This is a guess based on what I know about data.table-objects and how they are 
> represented with dput. You will see an .internal.selfref = <pointer: 
> 0x7f7fd18f2778>
> 
> But if you try to assign the value of the dput output to an R name, it's 
> going to fail. You need to remove the .internal.selfref = <pointer: 
> 0x7f7fd18f2778> and then assign as a data frame and run setDT() on the name.
> 
> 
>>  library(tidyr)
>>  #  data table for melt and columns split
>>  dt1 <- data.table(a_1 = 1:10, b_2 = 20:29,folks = 
> c("art","brian","ed",
>>  "rich","dennis","frank", 
> "derrick","paul","fred","numnuts"),
>>  a_2 = 2:11, b_1 = 21:30)
>>  melted <- melt(dt1, id = 
> "folks")[,c("varType","varIndex") :=
>>                                 
> tstrsplit(variable,"_")][,variable:=NULL]
> 
> Run this:
> 
> dput(melted)
> 
> 
>>  #  melted has 40 observations from stacking a and b variables
>>  #  which have lengths of 20 each
>>  #  here cometh the frustrtion
>>  dput(melted,"temp_file.txt")
>>  goGetIt <- dget("temp_file.txt", keep.source = FALSE)
>>  print(goGetIt)
>> 
>> 
>>>  goGetIt <- dget("temp_file.txt", keep.source = FALSE)
>>  Error in parse(file = file, keep.source = keep.source) : 
>>  temp_file.txt:18:36: unexpected '<'
> 
> That's because the regular R parser doesn't recognize the pointer as 
> valid R code. It was not designed to recognize data.tables. the tidyr functions 
> are designed to return data.frames, but `dget` is not from a package that is 
> "data.table-aware"
> 
> 
>>  17: "varIndex"), row.names = c(NA, -40L), class = 
> c("data.table", 
>>  18: "data.frame"), .internal.selfref = <
>>  ^
>>>  print(goGetIt)
>>  Error in print(goGetIt) : object 'goGetIt' not found
>>> 
> 
> Try this instead:
> 
> dput(as.data.frame(melted),"temp_file.txt")
> goGetIt <- dget("temp_file.txt", keep.source = FALSE)
> setDT(goGetIt)
> print(goGetIt)
> 
> -- 
> David.
> 
>>  the help page states dput just writes an ASCII text representation of an R 
> object to a file or connection, or uses one to recreate the object.  Nothing 
> there about not allowing a data frame or data table and the github example was a 
> data frame.   The line numbers referenced do not appear to refer to my code (but 
> maybe they do and I am ignorant of the meaning) and the code works up to the 
> dget line.
>> 
>>  Typing dget in the console to see the inner workings of the function was 
> not helpful.
>> 
>>  Also, I am unclear as to just how dput and dget work.  If I save a subset 
> of actual data to an object, then do dput on that object, can I rely that 
> whomever I send my code to (which includes the dput statement) be able to 
> retrieve the data?  In other words, dput saves the data in the code file?
>> 
>>  Thanks for your help and may the holidays be wonderful for you and your 
> loved one.
>>  Carl Sutton
>> 
>>  ______________________________________________
>>  R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>  https://stat.ethz.ch/mailman/listinfo/r-help
>>  PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
>>  and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Sat Dec 24 03:55:59 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 23 Dec 2016 18:55:59 -0800
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <703412216.1105374.1482536418760@mail.yahoo.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
Message-ID: <E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>

Could you make your example reproducible? That is, include some sample input and output. You talk about a column of numbers and then you seem to work with named lists and I can't reconcile your words with the code I see. 
-- 
Sent from my phone. Please excuse my brevity.

On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-project.org> wrote:
>I've been looking but I can't find a function to sum difference.
>
>I have this code:
>
> 
>rates$thisone <- c(diff(rates$Int), NA)
>rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
>rates$lastone <- (rates$thisone + rates$nextone)
>
>
>It is looking down one long column of numbers.
>
>It sums the difference between the first two and then between the first
>and third and so on.
>
>Can it be made to automatically sum the difference between the first
>and subsequent to the end of a list?
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Dec 24 06:04:33 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 23 Dec 2016 21:04:33 -0800 (PST)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <973592405.1191541.1482550037102@mail.yahoo.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>

You need to "reply all" so other people can help as well, and others can 
learn from your questions.

I am still puzzled by how you expect to compute "finalone". If you had 
supplied numbers other than all 5's it might have been easier to figure 
out what is going on.

What is your purpose in performing this calculation?

#### reproducible code
rates <- read.table( text =
"Date          Int
Jan-1959        5
Feb-1959        5
Mar-1959        5
Apr-1959        5
May-1959        5
Jun-1959        5
Jul-1959        5
Aug-1959        5
Sep-1959        5
Oct-1959        5
Nov-1959        5
", header = TRUE, colClasses = c( "character", "numeric" ) )

#your code
rates$thisone <- c(diff(rates$Int), NA)
rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
# I doubt there is a ready-built function that knows you want to
# divide by 6.5 or multiply by 1000

# form a vector from positions 2:11 and append NA)
rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA )
# numbers that are not all the same
rates$Int2 <- (1:11)^2
rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )

# dput(rates)
result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", 
"Apr-1959",
"May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-1959",
"Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0,
0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121), experiment1 = 
c(10,
10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5, 13,
25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date",
"Int", "thisone", "nextone", "lastone", "Int2", "experiment1",
"experiment2"), row.names = c(NA, -11L), class = "data.frame")

On Sat, 24 Dec 2016, arthur brogard wrote:

>
>
> Yes, sure, thanks for your interest.  I apologise for not submitting in the correct manner.  I'll learn (I hope).
>
> Here's the source - a spreadsheet with just two columns, date and 'Int'.
>
>
> Date	Int
> Jan-1959	5
> Feb-1959	5
> Mar-1959	5
> Apr-1959	5
> May-1959	5
> Jun-1959	5
> Jul-1959	5
> Aug-1959	5
> Sep-1959	5
> Oct-1959	5
> Nov-1959	5
>
>
> After processing it becomes this:
>
>
>> rates
> Date   Int thisone nextone     lastone finalone
> 1   1959-01-01  5.00    0.00    0.00    0.000000       10
> 2   1959-02-01  5.00    0.00    0.00    0.000000       10
> 3   1959-03-01  5.00    0.00    0.00    0.000000       10
> 4   1959-04-01  5.00    0.00    0.00    0.000000       10
> 5   1959-05-01  5.00    0.00    0.00    0.000000       10
> 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>
> The one long column I'm referring to is the 'Int' column which R has imported.
>
> The actual code is:
>
>
> rates <- read.csv("Rates2.csv",header = TRUE,colClasses=c("character","numeric"))
>
> sapply(rates,class)
>
> rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y", tz="UTC")
>
>
> rates$thisone <- c(diff(rates$Int), NA)
> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
> rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
>
>
> rates
>
>
>
> ab
>
>
>
> ----- Original Message -----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
> Sent: Saturday, 24 December 2016, 13:25
> Subject: Re: [R] Is there a funct to sum differences?
>
> Could you make your example reproducible? That is, include some sample input and output. You talk about a column of numbers and then you seem to work with named lists and I can't reconcile your words with the code I see.
> -- 
> Sent from my phone. Please excuse my brevity.
>
>
> On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-project.org> wrote:
>> I've been looking but I can't find a function to sum difference.
>>
>> I have this code:
>>
>>
>> rates$thisone <- c(diff(rates$Int), NA)
>> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
>> rates$lastone <- (rates$thisone + rates$nextone)
>>
>>
>> It is looking down one long column of numbers.
>>
>> It sums the difference between the first two and then between the first
>> and third and so on.
>>
>> Can it be made to automatically sum the difference between the first
>> and subsequent to the end of a list?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From abrogard at yahoo.com  Sat Dec 24 06:29:21 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Sat, 24 Dec 2016 05:29:21 +0000 (UTC)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
Message-ID: <538050454.1214553.1482557361906@mail.yahoo.com>

Yes, sorry about that.  I keep making mistakes I shouldn't make.

Thanks for the tip about 'reply all', I had no idea.

You can ignore the finalone. I have been doing other work on this and it comes from there. I took the example from the R screen after it had run one of these other things that created the finalone.

I guess I was thinking just seeing the data mentioned in the code was be enough.

I don't want a function to do the division and multiplication.

It's a function that will ".. automatically sum the difference between the first

 and subsequent to the end of a list? "  that I am looking for.

I will try to explain, I know I often don't make myself clear:

I'm using this diff() function.

This 'diff()' function finds the difference between two adjoining entries and it applies itself to the whole list so that in an instant I can have a list of differences between any two adjoining.

Then I can have a list of differences between any two with any specified gap - 'lag' it is called.
Using the same function.

Now I have them and do that.  Then I add them together to find the 'lastone' which is the total difference for the period. 


Now here's the point:  that covers a period of two timespans, months, they are.

 if I want to cover a span of 24 months, say, then I would have to write this diff() function 24 times.

 what I'm doing is finding the difference between the starting point and every other point and then adding them all together.  bit like finding the area beneath the curve maybe.

 And that's what I want to do.

 :)









----- Original Message -----
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
To: arthur brogard <abrogard at yahoo.com>
Cc: r-help at r-project.org
Sent: Saturday, 24 December 2016, 15:34
Subject: Re: [R] Is there a funct to sum differences?

You need to "reply all" so other people can help as well, and others can 
learn from your questions.

I am still puzzled by how you expect to compute "finalone". If you had 
supplied numbers other than all 5's it might have been easier to figure 
out what is going on.

What is your purpose in performing this calculation?

#### reproducible code
rates <- read.table( text =
"Date          Int
Jan-1959        5
Feb-1959        5
Mar-1959        5
Apr-1959        5
May-1959        5
Jun-1959        5
Jul-1959        5
Aug-1959        5
Sep-1959        5
Oct-1959        5
Nov-1959        5
", header = TRUE, colClasses = c( "character", "numeric" ) )

#your code
rates$thisone <- c(diff(rates$Int), NA)
rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
# I doubt there is a ready-built function that knows you want to
# divide by 6.5 or multiply by 1000

# form a vector from positions 2:11 and append NA)
rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA )
# numbers that are not all the same
rates$Int2 <- (1:11)^2
rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )

# dput(rates)
result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", 
"Apr-1959",
"May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-1959",
"Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0,
0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0,
0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121), experiment1 = 
c(10,
10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5, 13,
25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date",
"Int", "thisone", "nextone", "lastone", "Int2", "experiment1",
"experiment2"), row.names = c(NA, -11L), class = "data.frame")

On Sat, 24 Dec 2016, arthur brogard wrote:

>
>
> Yes, sure, thanks for your interest.  I apologise for not submitting in the correct manner.  I'll learn (I hope).
>
> Here's the source - a spreadsheet with just two columns, date and 'Int'.
>
>
> Date    Int
> Jan-1959    5
> Feb-1959    5
> Mar-1959    5
> Apr-1959    5
> May-1959    5
> Jun-1959    5
> Jul-1959    5
> Aug-1959    5
> Sep-1959    5
> Oct-1959    5
> Nov-1959    5
>
>
> After processing it becomes this:
>
>
>> rates
> Date   Int thisone nextone     lastone finalone
> 1   1959-01-01  5.00    0.00    0.00    0.000000       10
> 2   1959-02-01  5.00    0.00    0.00    0.000000       10
> 3   1959-03-01  5.00    0.00    0.00    0.000000       10
> 4   1959-04-01  5.00    0.00    0.00    0.000000       10
> 5   1959-05-01  5.00    0.00    0.00    0.000000       10
> 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>
> The one long column I'm referring to is the 'Int' column which R has imported.
>
> The actual code is:
>
>
> rates <- read.csv("Rates2.csv",header = TRUE,colClasses=c("character","numeric"))
>
> sapply(rates,class)
>
> rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y", tz="UTC")
>
>
> rates$thisone <- c(diff(rates$Int), NA)
> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
> rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
>
>
> rates
>
>
>
> ab
>
>
>
> ----- Original Message -----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
> Sent: Saturday, 24 December 2016, 13:25
> Subject: Re: [R] Is there a funct to sum differences?
>
> Could you make your example reproducible? That is, include some sample input and output. You talk about a column of numbers and then you seem to work with named lists and I can't reconcile your words with the code I see.
> -- 
> Sent from my phone. Please excuse my brevity.
>
>
> On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-project.org> wrote:
>> I've been looking but I can't find a function to sum difference.
>>
>> I have this code:
>>
>>
>> rates$thisone <- c(diff(rates$Int), NA)
>> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
>> rates$lastone <- (rates$thisone + rates$nextone)
>>
>>
>> It is looking down one long column of numbers.
>>
>> It sums the difference between the first two and then between the first
>> and third and so on.
>>
>> Can it be made to automatically sum the difference between the first
>> and subsequent to the end of a list?
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Sat Dec 24 10:34:50 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 24 Dec 2016 01:34:50 -0800
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <538050454.1214553.1482557361906@mail.yahoo.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
Message-ID: <CF1543DD-0474-47A8-9160-1C437EA65F45@dcn.davis.ca.us>

Perhaps

rates$experiment3  <- rates$Int2 - rates$Int2[ 1 ]

?

I still don't know what you think the numeric values this operation should  yield will be.
-- 
Sent from my phone. Please excuse my brevity.

On December 23, 2016 9:29:21 PM PST, arthur brogard <abrogard at yahoo.com> wrote:
>Yes, sorry about that.  I keep making mistakes I shouldn't make.
>
>Thanks for the tip about 'reply all', I had no idea.
>
>You can ignore the finalone. I have been doing other work on this and
>it comes from there. I took the example from the R screen after it had
>run one of these other things that created the finalone.
>
>I guess I was thinking just seeing the data mentioned in the code was
>be enough.
>
>I don't want a function to do the division and multiplication.
>
>It's a function that will ".. automatically sum the difference between
>the first
>
> and subsequent to the end of a list? "  that I am looking for.
>
>I will try to explain, I know I often don't make myself clear:
>
>I'm using this diff() function.
>
>This 'diff()' function finds the difference between two adjoining
>entries and it applies itself to the whole list so that in an instant I
>can have a list of differences between any two adjoining.
>
>Then I can have a list of differences between any two with any
>specified gap - 'lag' it is called.
>Using the same function.
>
>Now I have them and do that.  Then I add them together to find the
>'lastone' which is the total difference for the period. 
>
>
>Now here's the point:  that covers a period of two timespans, months,
>they are.
>
>if I want to cover a span of 24 months, say, then I would have to write
>this diff() function 24 times.
>
>what I'm doing is finding the difference between the starting point and
>every other point and then adding them all together.  bit like finding
>the area beneath the curve maybe.
>
> And that's what I want to do.
>
> :)
>
>
>
>
>
>
>
>
>
>----- Original Message -----
>From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>To: arthur brogard <abrogard at yahoo.com>
>Cc: r-help at r-project.org
>Sent: Saturday, 24 December 2016, 15:34
>Subject: Re: [R] Is there a funct to sum differences?
>
>You need to "reply all" so other people can help as well, and others
>can 
>learn from your questions.
>
>I am still puzzled by how you expect to compute "finalone". If you had 
>supplied numbers other than all 5's it might have been easier to figure
>
>out what is going on.
>
>What is your purpose in performing this calculation?
>
>#### reproducible code
>rates <- read.table( text =
>"Date          Int
>Jan-1959        5
>Feb-1959        5
>Mar-1959        5
>Apr-1959        5
>May-1959        5
>Jun-1959        5
>Jul-1959        5
>Aug-1959        5
>Sep-1959        5
>Oct-1959        5
>Nov-1959        5
>", header = TRUE, colClasses = c( "character", "numeric" ) )
>
>#your code
>rates$thisone <- c(diff(rates$Int), NA)
>rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
>rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
># I doubt there is a ready-built function that knows you want to
># divide by 6.5 or multiply by 1000
>
># form a vector from positions 2:11 and append NA)
>rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA )
># numbers that are not all the same
>rates$Int2 <- (1:11)^2
>rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
>
># dput(rates)
>result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", 
>"Apr-1959",
>"May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-1959",
>"Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0,
>0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0,
>0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
>NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121), experiment1 =
>
>c(10,
>10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5, 13,
>25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date",
>"Int", "thisone", "nextone", "lastone", "Int2", "experiment1",
>"experiment2"), row.names = c(NA, -11L), class = "data.frame")
>
>On Sat, 24 Dec 2016, arthur brogard wrote:
>
>>
>>
>> Yes, sure, thanks for your interest.  I apologise for not submitting
>in the correct manner.  I'll learn (I hope).
>>
>> Here's the source - a spreadsheet with just two columns, date and
>'Int'.
>>
>>
>> Date    Int
>> Jan-1959    5
>> Feb-1959    5
>> Mar-1959    5
>> Apr-1959    5
>> May-1959    5
>> Jun-1959    5
>> Jul-1959    5
>> Aug-1959    5
>> Sep-1959    5
>> Oct-1959    5
>> Nov-1959    5
>>
>>
>> After processing it becomes this:
>>
>>
>>> rates
>> Date   Int thisone nextone     lastone finalone
>> 1   1959-01-01  5.00    0.00    0.00    0.000000       10
>> 2   1959-02-01  5.00    0.00    0.00    0.000000       10
>> 3   1959-03-01  5.00    0.00    0.00    0.000000       10
>> 4   1959-04-01  5.00    0.00    0.00    0.000000       10
>> 5   1959-05-01  5.00    0.00    0.00    0.000000       10
>> 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>>
>> The one long column I'm referring to is the 'Int' column which R has
>imported.
>>
>> The actual code is:
>>
>>
>> rates <- read.csv("Rates2.csv",header =
>TRUE,colClasses=c("character","numeric"))
>>
>> sapply(rates,class)
>>
>> rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
>tz="UTC")
>>
>>
>> rates$thisone <- c(diff(rates$Int), NA)
>> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
>> rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000
>>
>>
>> rates
>>
>>
>>
>> ab
>>
>>
>>
>> ----- Original Message -----
>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
><r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
>> Sent: Saturday, 24 December 2016, 13:25
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>> Could you make your example reproducible? That is, include some
>sample input and output. You talk about a column of numbers and then
>you seem to work with named lists and I can't reconcile your words with
>the code I see.
>> -- 
>> Sent from my phone. Please excuse my brevity.
>>
>>
>> On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help
><r-help at r-project.org> wrote:
>>> I've been looking but I can't find a function to sum difference.
>>>
>>> I have this code:
>>>
>>>
>>> rates$thisone <- c(diff(rates$Int), NA)
>>> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
>>> rates$lastone <- (rates$thisone + rates$nextone)
>>>
>>>
>>> It is looking down one long column of numbers.
>>>
>>> It sums the difference between the first two and then between the
>first
>>> and third and so on.
>>>
>>> Can it be made to automatically sum the difference between the first
>>> and subsequent to the end of a list?
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>
>---------------------------------------------------------------------------


From ajdamico at gmail.com  Sat Dec 24 12:00:47 2016
From: ajdamico at gmail.com (Anthony Damico)
Date: Sat, 24 Dec 2016 06:00:47 -0500
Subject: [R] Problem in calculation of subpopulation mean in Survey
 package (Specify survey design with replicate weights)
In-Reply-To: <DM3PR13MB06525CBB8ED8B14CABACBBB1FA950@DM3PR13MB0652.namprd13.prod.outlook.com>
References: <DM3PR13MB06525CBB8ED8B14CABACBBB1FA950@DM3PR13MB0652.namprd13.prod.outlook.com>
Message-ID: <CAOwvMDzPjDWSjnW6aLZ_xcQXErOX_KqadVZSOJ_P+UvyvyoCkg@mail.gmail.com>

hi, please revise your minimal reproducible example.  the objects `W` and
`bootstrap.results` do not exist.  thanks

On Fri, Dec 23, 2016 at 4:56 PM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Hi R users,
>
> I got a problem when I was trying to calculate the population mean for
> different groups (classes) in using "svrepdesign", It worked when I used
> entire rows  but when I introduced by classes (groups or strata), it did
> not work out. I read several documents but I could not figure it out to the
> fix the problem.
>
> Actually, I do have about 500 data points (rows) in which there are
> several classes (groups). I developed the design using the svrepdesign, but
> when I introduced group in calculating mean, it says
>
> ""Error in qr.default(weights(design, "analysis"), tol = 1e-05) :
>   NA/NaN/Inf in foreign function call (arg 1)"
>
> I think I have to introduce groups in the design and I tried it different
> ways but it did not work it out. Would you mind to give some hints?I would
> be very grateful if you could give some hints.
>
> here I have attached a example (format of the data) and the code I used.
> Thanks for your help.
> have a great holidays.
>
> MG
> ___
>
> library(survey)
>
> dat<-structure(list(ID = 1:6, group = structure(c(8L, 7L, 7L, 8L,
> 7L, 7L), .Label = c("groupA", "groupB", "groupC", "groupD", "groupE",
> "groupF", "groupG", "groupH"), class = "factor"), ProbSelect = c(0.72,
> 0.62, 0.62, 0.72, 0.72, 0.62), density = c(28, 227, 65, 132,
> 13, 227), totalSampled = c(96L, 96L, 96L, 96L, 96L, 96L), pop = c(166L,
> 166L, 166L, 166L, 166L, 166L), wgt = c(2.42, 2.79, 2.79, 2.42,
> 2.42, 2.79)), .Names = c("ID", "group", "ProbSelect", "density",
> "totalSampled", "pop", "wgt"), row.names = c(NA, 6L), class = "data.frame")
>
> dat
>
> design_dat<-svrepdesign(data=dat, type="bootstrap", weights =
> I(1/dat$ProbSelect), repweights=W[,-1],scale=bootstrap.results$scale,
> rscale=bootstrap.results$rscales, combined.weights=TRUE)
>
> svymean(~ density,design=subset(design_dat, group=='groupH'),na.rm=T,
> digits=2)
>
> "Error in qr.default(weights(design, "analysis"), tol = 1e-05) :
>   NA/Na
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Dec 24 15:25:02 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 24 Dec 2016 14:25:02 +0000
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <538050454.1214553.1482557361906@mail.yahoo.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>

Dear Arthur,

Here's a simple script to do what I think you want. I've applied it to a contrived example, a vector of the squares of the integers 1 to 25, and have summed the first 5 differences, but the script is adaptable to any numeric vector and any maximum lag. You'll have to decide what to do with the last maximum-lag (in my case, 5) entries:

-------------- snip ------------
> (x <- (1:25)^2)
 [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289 324 361 400 441 484 529 576
[25] 625
> len <- length(x)
> maxlag <- 5
> diffs <- matrix(0, len, maxlag)
> for (lag in 1:maxlag){
+     diffs[1:(len - lag), lag] <- diff(x, lag=lag)
+ }
> head(diffs)
     [,1] [,2] [,3] [,4] [,5]
[1,]    3    8   15   24   35
[2,]    5   12   21   32   45
[3,]    7   16   27   40   55
[4,]    9   20   33   48   65
[5,]   11   24   39   56   75
[6,]   13   28   45   64   85
> tail(diffs)
      [,1] [,2] [,3] [,4] [,5]
[20,]   41   84  129  176  225
[21,]   43   88  135  184    0
[22,]   45   92  141    0    0
[23,]   47   96    0    0    0
[24,]   49    0    0    0    0
[25,]    0    0    0    0    0
> rowSums(diffs)
 [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565 595 625 655 450 278 143  49
[25]   0
-------------- snip ------------

The script could very simply be converted into a function if this is a repetitive task with variable inputs.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
> brogard via R-help
> Sent: December 24, 2016 12:29 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help at r-project.org
> Subject: Re: [R] Is there a funct to sum differences?
> 
> Yes, sorry about that.  I keep making mistakes I shouldn't make.
> 
> Thanks for the tip about 'reply all', I had no idea.
> 
> You can ignore the finalone. I have been doing other work on this and it comes
> from there. I took the example from the R screen after it had run one of these
> other things that created the finalone.
> 
> I guess I was thinking just seeing the data mentioned in the code was be
> enough.
> 
> I don't want a function to do the division and multiplication.
> 
> It's a function that will ".. automatically sum the difference between the first
> 
>  and subsequent to the end of a list? "  that I am looking for.
> 
> I will try to explain, I know I often don't make myself clear:
> 
> I'm using this diff() function.
> 
> This 'diff()' function finds the difference between two adjoining entries and it
> applies itself to the whole list so that in an instant I can have a list of
> differences between any two adjoining.
> 
> Then I can have a list of differences between any two with any specified gap -
> 'lag' it is called.
> Using the same function.
> 
> Now I have them and do that.  Then I add them together to find the 'lastone'
> which is the total difference for the period.
> 
> 
> Now here's the point:  that covers a period of two timespans, months, they are.
> 
>  if I want to cover a span of 24 months, say, then I would have to write this
> diff() function 24 times.
> 
>  what I'm doing is finding the difference between the starting point and every
> other point and then adding them all together.  bit like finding the area
> beneath the curve maybe.
> 
>  And that's what I want to do.
> 
>  :)
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ----- Original Message -----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> To: arthur brogard <abrogard at yahoo.com>
> Cc: r-help at r-project.org
> Sent: Saturday, 24 December 2016, 15:34
> Subject: Re: [R] Is there a funct to sum differences?
> 
> You need to "reply all" so other people can help as well, and others can learn
> from your questions.
> 
> I am still puzzled by how you expect to compute "finalone". If you had supplied
> numbers other than all 5's it might have been easier to figure out what is going
> on.
> 
> What is your purpose in performing this calculation?
> 
> #### reproducible code
> rates <- read.table( text =
> "Date          Int
> Jan-1959        5
> Feb-1959        5
> Mar-1959        5
> Apr-1959        5
> May-1959        5
> Jun-1959        5
> Jul-1959        5
> Aug-1959        5
> Sep-1959        5
> Oct-1959        5
> Nov-1959        5
> ", header = TRUE, colClasses = c( "character", "numeric" ) )
> 
> #your code
> rates$thisone <- c(diff(rates$Int), NA)
> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA) rates$lastone <-
> (rates$thisone + rates$nextone)/6.5*1000 # I doubt there is a ready-built
> function that knows you want to # divide by 6.5 or multiply by 1000
> 
> # form a vector from positions 2:11 and append NA)
> rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers that are not
> all the same
> rates$Int2 <- (1:11)^2
> rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
> 
> # dput(rates)
> result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", "Apr-
> 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-
> 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0,
> 0, 0, 0, 0, 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
> experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5,
> 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date", "Int",
> "thisone", "nextone", "lastone", "Int2", "experiment1", "experiment2"),
> row.names = c(NA, -11L), class = "data.frame")
> 
> On Sat, 24 Dec 2016, arthur brogard wrote:
> 
> >
> >
> > Yes, sure, thanks for your interest.  I apologise for not submitting in the
> correct manner.  I'll learn (I hope).
> >
> > Here's the source - a spreadsheet with just two columns, date and 'Int'.
> >
> >
> > Date    Int
> > Jan-1959    5
> > Feb-1959    5
> > Mar-1959    5
> > Apr-1959    5
> > May-1959    5
> > Jun-1959    5
> > Jul-1959    5
> > Aug-1959    5
> > Sep-1959    5
> > Oct-1959    5
> > Nov-1959    5
> >
> >
> > After processing it becomes this:
> >
> >
> >> rates
> > Date   Int thisone nextone     lastone finalone
> > 1   1959-01-01  5.00    0.00    0.00    0.000000       10
> > 2   1959-02-01  5.00    0.00    0.00    0.000000       10
> > 3   1959-03-01  5.00    0.00    0.00    0.000000       10
> > 4   1959-04-01  5.00    0.00    0.00    0.000000       10
> > 5   1959-05-01  5.00    0.00    0.00    0.000000       10
> > 6   1959-06-01  5.00    0.00    0.00    0.000000       10
> >
> > The one long column I'm referring to is the 'Int' column which R has imported.
> >
> > The actual code is:
> >
> >
> > rates <- read.csv("Rates2.csv",header =
> > TRUE,colClasses=c("character","numeric"))
> >
> > sapply(rates,class)
> >
> > rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
> > tz="UTC")
> >
> >
> > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > rates$nextone)/6.5*1000
> >
> >
> > rates
> >
> >
> >
> > ab
> >
> >
> >
> > ----- Original Message -----
> > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
> > <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
> > Sent: Saturday, 24 December 2016, 13:25
> > Subject: Re: [R] Is there a funct to sum differences?
> >
> > Could you make your example reproducible? That is, include some sample
> input and output. You talk about a column of numbers and then you seem to
> work with named lists and I can't reconcile your words with the code I see.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> >
> > On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-
> project.org> wrote:
> >> I've been looking but I can't find a function to sum difference.
> >>
> >> I have this code:
> >>
> >>
> >> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> >> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> >> rates$nextone)
> >>
> >>
> >> It is looking down one long column of numbers.
> >>
> >> It sums the difference between the first two and then between the
> >> first and third and so on.
> >>
> >> Can it be made to automatically sum the difference between the first
> >> and subsequent to the end of a list?
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Dec 24 20:36:11 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 24 Dec 2016 11:36:11 -0800 (PST)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <alpine.BSF.2.00.1612241113560.80994@pedal.dcn.davis.ca.us>

Assuming John's understanding is correct, you can also do this without for 
loops. It takes getting used to vector and matrix arithmetic, which you
can read more about in the Introduction to R document that comes with R, 
or on R Exercises website [1].

You indicated having a problem with my last reproducible example... it did 
work, if you went through it one step at a time. If you skipped steps, you 
would have problems like you encountered. For completeness, I will give 
the whole reproducible example again here... don't mix in your own steps 
until you have worked through all the steps in this example... or at least 
if you do, go back and step through these steps one at a time if you 
change something that breaks it.

[1] http://r-exercises.com/2015/11/28/matrix-exercises/

#########------ begin
rates <- read.table( text =
"Date          Int
Jan-1959        5
Feb-1959        5
Mar-1959        5
Apr-1959        5
May-1959        5
Jun-1959        5
Jul-1959        5
Aug-1959        5
Sep-1959        5
Oct-1959        5
Nov-1959        5
", header = TRUE, colClasses = c( "character", "numeric" ) )

rates$thisone <- c(diff(rates$Int), NA)
rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000

rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA )
rates$Int2 <- (1:11)^2
rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )

# lag
N <- 5
# see ?embed, or https://en.wikipedia.org/wiki/Embedding
embed( c( rates$Int2, rep( NA, N ) ), N+1 )
# make a matrix of the same size as the embed result
matrix( rep( rates$Int2, N+1 ), ncol=N+1 )
# subtract the first values
embed( c( rates$Int2, rep( NA, N ) ), N+1 ) - rates$Int2
# or can rely on automatic replication ... depends on the
# fact that the embed result is a matrix which is really just
# a vector displayed in folded up form
embed( c( rates$Int2, rep( NA, N ) ), N+1 ) - rates$Int2
# anyway, the result can be computed in one line (wrapped for readability)
rates$experiment3 <- rowSums(   embed( c( rates$Int2
                                         , rep( NA, N )
                                         )
                                      , N+1
                                      )
                               - rates$Int2
                             , na.rm=TRUE
                             )
> rates
        Date Int thisone nextone lastone experiment1 Int2 experiment2 experiment3
1  Jan-1959   5       0       0       0          10    1           5          85
2  Feb-1959   5       0       0       0          10    4          13         115
3  Mar-1959   5       0       0       0          10    9          25         145
4  Apr-1959   5       0       0       0          10   16          41         175
5  May-1959   5       0       0       0          10   25          61         205
6  Jun-1959   5       0       0       0          10   36          85         235
7  Jul-1959   5       0       0       0          10   49         113         170
8  Aug-1959   5       0       0       0          10   64         145         110
9  Sep-1959   5       0       0       0          10   81         181          59
10 Oct-1959   5       0      NA      NA          10  100         221          21
11 Nov-1959   5      NA      NA      NA          NA  121          NA           0

#dput(rates)
result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", 
"Apr-1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", 
"Oct-1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone 
= c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0,
0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
NA), experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121), experiment2 = 
c(5, 13, 25, 41, 61, 85, 113, 145, 181, 221, NA), experiment3 = c(85,
115, 145, 175, 205, 235, 170, 110, 59, 21, 0)), .Names = c("Date",
"Int", "thisone", "nextone", "lastone", "experiment1", "Int2",
"experiment2", "experiment3"), row.names = c(NA, -11L), class = 
"data.frame")

#########------ end


On Sat, 24 Dec 2016, Fox, John wrote:

> Dear Arthur,
>
> Here's a simple script to do what I think you want. I've applied it to a contrived example, a vector of the squares of the integers 1 to 25, and have summed the first 5 differences, but the script is adaptable to any numeric vector and any maximum lag. You'll have to decide what to do with the last maximum-lag (in my case, 5) entries:
>
> -------------- snip ------------
>> (x <- (1:25)^2)
> [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289 324 361 400 441 484 529 576
> [25] 625
>> len <- length(x)
>> maxlag <- 5
>> diffs <- matrix(0, len, maxlag)
>> for (lag in 1:maxlag){
> +     diffs[1:(len - lag), lag] <- diff(x, lag=lag)
> + }
>> head(diffs)
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    3    8   15   24   35
> [2,]    5   12   21   32   45
> [3,]    7   16   27   40   55
> [4,]    9   20   33   48   65
> [5,]   11   24   39   56   75
> [6,]   13   28   45   64   85
>> tail(diffs)
>      [,1] [,2] [,3] [,4] [,5]
> [20,]   41   84  129  176  225
> [21,]   43   88  135  184    0
> [22,]   45   92  141    0    0
> [23,]   47   96    0    0    0
> [24,]   49    0    0    0    0
> [25,]    0    0    0    0    0
>> rowSums(diffs)
> [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565 595 625 655 450 278 143  49
> [25]   0
> -------------- snip ------------
>
> The script could very simply be converted into a function if this is a repetitive task with variable inputs.
>
> I hope this helps,
> John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
>> brogard via R-help
>> Sent: December 24, 2016 12:29 AM
>> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>> Yes, sorry about that.  I keep making mistakes I shouldn't make.
>>
>> Thanks for the tip about 'reply all', I had no idea.
>>
>> You can ignore the finalone. I have been doing other work on this and it comes
>> from there. I took the example from the R screen after it had run one of these
>> other things that created the finalone.
>>
>> I guess I was thinking just seeing the data mentioned in the code was be
>> enough.
>>
>> I don't want a function to do the division and multiplication.
>>
>> It's a function that will ".. automatically sum the difference between the first
>>
>>  and subsequent to the end of a list? "  that I am looking for.
>>
>> I will try to explain, I know I often don't make myself clear:
>>
>> I'm using this diff() function.
>>
>> This 'diff()' function finds the difference between two adjoining entries and it
>> applies itself to the whole list so that in an instant I can have a list of
>> differences between any two adjoining.
>>
>> Then I can have a list of differences between any two with any specified gap -
>> 'lag' it is called.
>> Using the same function.
>>
>> Now I have them and do that.  Then I add them together to find the 'lastone'
>> which is the total difference for the period.
>>
>>
>> Now here's the point:  that covers a period of two timespans, months, they are.
>>
>>  if I want to cover a span of 24 months, say, then I would have to write this
>> diff() function 24 times.
>>
>>  what I'm doing is finding the difference between the starting point and every
>> other point and then adding them all together.  bit like finding the area
>> beneath the curve maybe.
>>
>>  And that's what I want to do.
>>
>>  :)
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> ----- Original Message -----
>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> To: arthur brogard <abrogard at yahoo.com>
>> Cc: r-help at r-project.org
>> Sent: Saturday, 24 December 2016, 15:34
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>> You need to "reply all" so other people can help as well, and others can learn
>> from your questions.
>>
>> I am still puzzled by how you expect to compute "finalone". If you had supplied
>> numbers other than all 5's it might have been easier to figure out what is going
>> on.
>>
>> What is your purpose in performing this calculation?
>>
>> #### reproducible code
>> rates <- read.table( text =
>> "Date          Int
>> Jan-1959        5
>> Feb-1959        5
>> Mar-1959        5
>> Apr-1959        5
>> May-1959        5
>> Jun-1959        5
>> Jul-1959        5
>> Aug-1959        5
>> Sep-1959        5
>> Oct-1959        5
>> Nov-1959        5
>> ", header = TRUE, colClasses = c( "character", "numeric" ) )
>>
>> #your code
>> rates$thisone <- c(diff(rates$Int), NA)
>> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA) rates$lastone <-
>> (rates$thisone + rates$nextone)/6.5*1000 # I doubt there is a ready-built
>> function that knows you want to # divide by 6.5 or multiply by 1000
>>
>> # form a vector from positions 2:11 and append NA)
>> rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers that are not
>> all the same
>> rates$Int2 <- (1:11)^2
>> rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
>>
>> # dput(rates)
>> result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", "Apr-
>> 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-
>> 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0,
>> 0, 0, 0, 0, 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
>> experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5,
>> 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date", "Int",
>> "thisone", "nextone", "lastone", "Int2", "experiment1", "experiment2"),
>> row.names = c(NA, -11L), class = "data.frame")
>>
>> On Sat, 24 Dec 2016, arthur brogard wrote:
>>
>>>
>>>
>>> Yes, sure, thanks for your interest.  I apologise for not submitting in the
>> correct manner.  I'll learn (I hope).
>>>
>>> Here's the source - a spreadsheet with just two columns, date and 'Int'.
>>>
>>>
>>> Date    Int
>>> Jan-1959    5
>>> Feb-1959    5
>>> Mar-1959    5
>>> Apr-1959    5
>>> May-1959    5
>>> Jun-1959    5
>>> Jul-1959    5
>>> Aug-1959    5
>>> Sep-1959    5
>>> Oct-1959    5
>>> Nov-1959    5
>>>
>>>
>>> After processing it becomes this:
>>>
>>>
>>>> rates
>>> Date   Int thisone nextone     lastone finalone
>>> 1   1959-01-01  5.00    0.00    0.00    0.000000       10
>>> 2   1959-02-01  5.00    0.00    0.00    0.000000       10
>>> 3   1959-03-01  5.00    0.00    0.00    0.000000       10
>>> 4   1959-04-01  5.00    0.00    0.00    0.000000       10
>>> 5   1959-05-01  5.00    0.00    0.00    0.000000       10
>>> 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>>>
>>> The one long column I'm referring to is the 'Int' column which R has imported.
>>>
>>> The actual code is:
>>>
>>>
>>> rates <- read.csv("Rates2.csv",header =
>>> TRUE,colClasses=c("character","numeric"))
>>>
>>> sapply(rates,class)
>>>
>>> rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
>>> tz="UTC")
>>>
>>>
>>> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>>> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>>> rates$nextone)/6.5*1000
>>>
>>>
>>> rates
>>>
>>>
>>>
>>> ab
>>>
>>>
>>>
>>> ----- Original Message -----
>>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
>>> <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
>>> Sent: Saturday, 24 December 2016, 13:25
>>> Subject: Re: [R] Is there a funct to sum differences?
>>>
>>> Could you make your example reproducible? That is, include some sample
>> input and output. You talk about a column of numbers and then you seem to
>> work with named lists and I can't reconcile your words with the code I see.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>>
>>> On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-
>> project.org> wrote:
>>>> I've been looking but I can't find a function to sum difference.
>>>>
>>>> I have this code:
>>>>
>>>>
>>>> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>>>> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>>>> rates$nextone)
>>>>
>>>>
>>>> It is looking down one long column of numbers.
>>>>
>>>> It sums the difference between the first two and then between the
>>>> first and third and so on.
>>>>
>>>> Can it be made to automatically sum the difference between the first
>>>> and subsequent to the end of a list?
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From abrogard at yahoo.com  Sat Dec 24 21:20:25 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Sat, 24 Dec 2016 20:20:25 +0000 (UTC)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <alpine.BSF.2.00.1612241113560.80994@pedal.dcn.davis.ca.us>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
	<alpine.BSF.2.00.1612241113560.80994@pedal.dcn.davis.ca.us>
Message-ID: <1750710796.1381708.1482610825050@mail.yahoo.com>

Thanks a lot everyone for the help.  I will fall silent for quite some time now as I try to understand what you've put before me.

Yes, my first problem is a lack of understanding of vector and matrix arithmetic.  So I have a bit of a learning curve.

Another mistake I made was not giving you sample input with a variety of numbers in it.  I can see quite clearly. Makes it hard to tell if a routine is working properly when everything is zeroes. That was unthinking - my usual habit - I simply took the first items from the list because they included the column headers.  I could easy have cut and pasted something else in there.

And I forgot to 'reply everyone' last time, too. Will I never learn..

Jeff, yes your last didn't work for me. I entirely believe that was my implementation of it. With this 'sophisticated' or 'grownup' code I'm largely blundering around in the dark.

Okay, I'll go looking for illumination..

Have a good Xmas.


:)

ab----- Original Message -----

From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
To: "Fox, John" <jfox at mcmaster.ca>
Cc: arthur brogard <abrogard at yahoo.com>; "r-help at r-project.org" <r-help at r-project.org>
Sent: Sunday, 25 December 2016, 6:06
Subject: RE: [R] Is there a funct to sum differences?

Assuming John's understanding is correct, you can also do this without for 
loops. It takes getting used to vector and matrix arithmetic, which you
can read more about in the Introduction to R document that comes with R, 
or on R Exercises website [1].

You indicated having a problem with my last reproducible example... it did 
work, if you went through it one step at a time. If you skipped steps, you 
would have problems like you encountered. For completeness, I will give 
the whole reproducible example again here... don't mix in your own steps 
until you have worked through all the steps in this example... or at least 
if you do, go back and step through these steps one at a time if you 
change something that breaks it.

[1] http://r-exercises.com/2015/11/28/matrix-exercises/

#########------ begin
rates <- read.table( text =
"Date          Int
Jan-1959        5
Feb-1959        5
Mar-1959        5
Apr-1959        5
May-1959        5
Jun-1959        5
Jul-1959        5
Aug-1959        5
Sep-1959        5
Oct-1959        5
Nov-1959        5
", header = TRUE, colClasses = c( "character", "numeric" ) )

rates$thisone <- c(diff(rates$Int), NA)
rates$nextone <- c(diff(rates$Int, lag=2), NA, NA)
rates$lastone <- (rates$thisone + rates$nextone)/6.5*1000

rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA )
rates$Int2 <- (1:11)^2
rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )

# lag
N <- 5
# see ?embed, or https://en.wikipedia.org/wiki/Embedding
embed( c( rates$Int2, rep( NA, N ) ), N+1 )
# make a matrix of the same size as the embed result
matrix( rep( rates$Int2, N+1 ), ncol=N+1 )
# subtract the first values
embed( c( rates$Int2, rep( NA, N ) ), N+1 ) - rates$Int2
# or can rely on automatic replication ... depends on the
# fact that the embed result is a matrix which is really just
# a vector displayed in folded up form
embed( c( rates$Int2, rep( NA, N ) ), N+1 ) - rates$Int2
# anyway, the result can be computed in one line (wrapped for readability)
rates$experiment3 <- rowSums(   embed( c( rates$Int2
                                         , rep( NA, N )
                                         )
                                      , N+1
                                      )
                               - rates$Int2
                             , na.rm=TRUE
                             )
> rates
        Date Int thisone nextone lastone experiment1 Int2 experiment2 experiment3
1  Jan-1959   5       0       0       0          10    1           5          85
2  Feb-1959   5       0       0       0          10    4          13         115
3  Mar-1959   5       0       0       0          10    9          25         145
4  Apr-1959   5       0       0       0          10   16          41         175
5  May-1959   5       0       0       0          10   25          61         205
6  Jun-1959   5       0       0       0          10   36          85         235
7  Jul-1959   5       0       0       0          10   49         113         170
8  Aug-1959   5       0       0       0          10   64         145         110
9  Sep-1959   5       0       0       0          10   81         181          59
10 Oct-1959   5       0      NA      NA          10  100         221          21
11 Nov-1959   5      NA      NA      NA          NA  121          NA           0

#dput(rates)
result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", 
"Apr-1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", 
"Oct-1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone 
= c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0,
0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
NA), experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10,
NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121), experiment2 = 
c(5, 13, 25, 41, 61, 85, 113, 145, 181, 221, NA), experiment3 = c(85,
115, 145, 175, 205, 235, 170, 110, 59, 21, 0)), .Names = c("Date",
"Int", "thisone", "nextone", "lastone", "experiment1", "Int2",
"experiment2", "experiment3"), row.names = c(NA, -11L), class = 
"data.frame")

#########------ end


On Sat, 24 Dec 2016, Fox, John wrote:

> Dear Arthur,
>
> Here's a simple script to do what I think you want. I've applied it to a contrived example, a vector of the squares of the integers 1 to 25, and have summed the first 5 differences, but the script is adaptable to any numeric vector and any maximum lag. You'll have to decide what to do with the last maximum-lag (in my case, 5) entries:
>
> -------------- snip ------------
>> (x <- (1:25)^2)
> [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289 324 361 400 441 484 529 576
> [25] 625
>> len <- length(x)
>> maxlag <- 5
>> diffs <- matrix(0, len, maxlag)
>> for (lag in 1:maxlag){
> +     diffs[1:(len - lag), lag] <- diff(x, lag=lag)
> + }
>> head(diffs)
>     [,1] [,2] [,3] [,4] [,5]
> [1,]    3    8   15   24   35
> [2,]    5   12   21   32   45
> [3,]    7   16   27   40   55
> [4,]    9   20   33   48   65
> [5,]   11   24   39   56   75
> [6,]   13   28   45   64   85
>> tail(diffs)
>      [,1] [,2] [,3] [,4] [,5]
> [20,]   41   84  129  176  225
> [21,]   43   88  135  184    0
> [22,]   45   92  141    0    0
> [23,]   47   96    0    0    0
> [24,]   49    0    0    0    0
> [25,]    0    0    0    0    0
>> rowSums(diffs)
> [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565 595 625 655 450 278 143  49
> [25]   0
> -------------- snip ------------
>
> The script could very simply be converted into a function if this is a repetitive task with variable inputs.
>
> I hope this helps,
> John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
>> brogard via R-help
>> Sent: December 24, 2016 12:29 AM
>> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>> Yes, sorry about that.  I keep making mistakes I shouldn't make.
>>
>> Thanks for the tip about 'reply all', I had no idea.
>>
>> You can ignore the finalone. I have been doing other work on this and it comes
>> from there. I took the example from the R screen after it had run one of these
>> other things that created the finalone.
>>
>> I guess I was thinking just seeing the data mentioned in the code was be
>> enough.
>>
>> I don't want a function to do the division and multiplication.
>>
>> It's a function that will ".. automatically sum the difference between the first
>>
>>  and subsequent to the end of a list? "  that I am looking for.
>>
>> I will try to explain, I know I often don't make myself clear:
>>
>> I'm using this diff() function.
>>
>> This 'diff()' function finds the difference between two adjoining entries and it
>> applies itself to the whole list so that in an instant I can have a list of
>> differences between any two adjoining.
>>
>> Then I can have a list of differences between any two with any specified gap -
>> 'lag' it is called.
>> Using the same function.
>>
>> Now I have them and do that.  Then I add them together to find the 'lastone'
>> which is the total difference for the period.
>>
>>
>> Now here's the point:  that covers a period of two timespans, months, they are.
>>
>>  if I want to cover a span of 24 months, say, then I would have to write this
>> diff() function 24 times.
>>
>>  what I'm doing is finding the difference between the starting point and every
>> other point and then adding them all together.  bit like finding the area
>> beneath the curve maybe.
>>
>>  And that's what I want to do.
>>
>>  :)
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> ----- Original Message -----
>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> To: arthur brogard <abrogard at yahoo.com>
>> Cc: r-help at r-project.org
>> Sent: Saturday, 24 December 2016, 15:34
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>> You need to "reply all" so other people can help as well, and others can learn
>> from your questions.
>>
>> I am still puzzled by how you expect to compute "finalone". If you had supplied
>> numbers other than all 5's it might have been easier to figure out what is going
>> on.
>>
>> What is your purpose in performing this calculation?
>>
>> #### reproducible code
>> rates <- read.table( text =
>> "Date          Int
>> Jan-1959        5
>> Feb-1959        5
>> Mar-1959        5
>> Apr-1959        5
>> May-1959        5
>> Jun-1959        5
>> Jul-1959        5
>> Aug-1959        5
>> Sep-1959        5
>> Oct-1959        5
>> Nov-1959        5
>> ", header = TRUE, colClasses = c( "character", "numeric" ) )
>>
>> #your code
>> rates$thisone <- c(diff(rates$Int), NA)
>> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA) rates$lastone <-
>> (rates$thisone + rates$nextone)/6.5*1000 # I doubt there is a ready-built
>> function that knows you want to # divide by 6.5 or multiply by 1000
>>
>> # form a vector from positions 2:11 and append NA)
>> rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers that are not
>> all the same
>> rates$Int2 <- (1:11)^2
>> rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
>>
>> # dput(rates)
>> result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", "Apr-
>> 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-
>> 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0, 0, 0, 0, 0,
>> 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0,
>> 0, 0, 0, 0, 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
>> experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5,
>> 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date", "Int",
>> "thisone", "nextone", "lastone", "Int2", "experiment1", "experiment2"),
>> row.names = c(NA, -11L), class = "data.frame")
>>
>> On Sat, 24 Dec 2016, arthur brogard wrote:
>>
>>>
>>>
>>> Yes, sure, thanks for your interest.  I apologise for not submitting in the
>> correct manner.  I'll learn (I hope).
>>>
>>> Here's the source - a spreadsheet with just two columns, date and 'Int'.
>>>
>>>
>>> Date    Int
>>> Jan-1959    5
>>> Feb-1959    5
>>> Mar-1959    5
>>> Apr-1959    5
>>> May-1959    5
>>> Jun-1959    5
>>> Jul-1959    5
>>> Aug-1959    5
>>> Sep-1959    5
>>> Oct-1959    5
>>> Nov-1959    5
>>>
>>>
>>> After processing it becomes this:
>>>
>>>
>>>> rates
>>> Date   Int thisone nextone     lastone finalone
>>> 1   1959-01-01  5.00    0.00    0.00    0.000000       10
>>> 2   1959-02-01  5.00    0.00    0.00    0.000000       10
>>> 3   1959-03-01  5.00    0.00    0.00    0.000000       10
>>> 4   1959-04-01  5.00    0.00    0.00    0.000000       10
>>> 5   1959-05-01  5.00    0.00    0.00    0.000000       10
>>> 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>>>
>>> The one long column I'm referring to is the 'Int' column which R has imported.
>>>
>>> The actual code is:
>>>
>>>
>>> rates <- read.csv("Rates2.csv",header =
>>> TRUE,colClasses=c("character","numeric"))
>>>
>>> sapply(rates,class)
>>>
>>> rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
>>> tz="UTC")
>>>
>>>
>>> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>>> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>>> rates$nextone)/6.5*1000
>>>
>>>
>>> rates
>>>
>>>
>>>
>>> ab
>>>
>>>
>>>
>>> ----- Original Message -----
>>> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>>> To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
>>> <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
>>> Sent: Saturday, 24 December 2016, 13:25
>>> Subject: Re: [R] Is there a funct to sum differences?
>>>
>>> Could you make your example reproducible? That is, include some sample
>> input and output. You talk about a column of numbers and then you seem to
>> work with named lists and I can't reconcile your words with the code I see.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>>
>>> On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-
>> project.org> wrote:
>>>> I've been looking but I can't find a function to sum difference.
>>>>
>>>> I have this code:
>>>>
>>>>
>>>> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>>>> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>>>> rates$nextone)
>>>>
>>>>
>>>> It is looking down one long column of numbers.
>>>>
>>>> It sums the difference between the first two and then between the
>>>> first and third and so on.
>>>>
>>>> Can it be made to automatically sum the difference between the first
>>>> and subsequent to the end of a list?
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k

>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From abrogard at yahoo.com  Sat Dec 24 22:24:11 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Sat, 24 Dec 2016 21:24:11 +0000 (UTC)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <292647045.1377940.1482614651777@mail.yahoo.com>



Hello John,


Here I am back again. Having learned no maths yet but I've looked over the
results here and they are what I am after.

Now I'll try to understand how you did it.

:)




----- Original Message -----
From: "Fox, John" <jfox at mcmaster.ca>
To: arthur brogard <abrogard at yahoo.com>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org" <r-help at r-project.org>
Sent: Sunday, 25 December 2016, 0:55
Subject: RE: [R] Is there a funct to sum differences?

Dear Arthur,

Here's a simple script to do what I think you want. I've applied it to a contrived example, a vector of the squares of the integers 1 to 25, and have summed the first 5 differences, but the script is adaptable to any numeric vector and any maximum lag. You'll have to decide what to do with the last maximum-lag (in my case, 5) entries:

-------------- snip ------------
> (x <- (1:25)^2)
[1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289 324 361 400 441 484 529 576
[25] 625
> len <- length(x)
> maxlag <- 5
> diffs <- matrix(0, len, maxlag)
> for (lag in 1:maxlag){
+     diffs[1:(len - lag), lag] <- diff(x, lag=lag)
+ }
> head(diffs)
     [,1] [,2] [,3] [,4] [,5]
[1,]    3    8   15   24   35
[2,]    5   12   21   32   45
[3,]    7   16   27   40   55
[4,]    9   20   33   48   65
[5,]   11   24   39   56   75
[6,]   13   28   45   64   85
> tail(diffs)
      [,1] [,2] [,3] [,4] [,5]
[20,]   41   84  129  176  225
[21,]   43   88  135  184    0
[22,]   45   92  141    0    0
[23,]   47   96    0    0    0
[24,]   49    0    0    0    0
[25,]    0    0    0    0    0
> rowSums(diffs)
[1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565 595 625 655 450 278 143  49
[25]   0
-------------- snip ------------

The script could very simply be converted into a function if this is a repetitive task with variable inputs.

I hope this helps,
John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
> brogard via R-help
> Sent: December 24, 2016 12:29 AM
> To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help at r-project.org
> Subject: Re: [R] Is there a funct to sum differences?
> 
> Yes, sorry about that.  I keep making mistakes I shouldn't make.
> 
> Thanks for the tip about 'reply all', I had no idea.
> 
> You can ignore the finalone. I have been doing other work on this and it comes
> from there. I took the example from the R screen after it had run one of these
> other things that created the finalone.
> 
> I guess I was thinking just seeing the data mentioned in the code was be
> enough.
> 
> I don't want a function to do the division and multiplication.
> 
> It's a function that will ".. automatically sum the difference between the first
> 
>  and subsequent to the end of a list? "  that I am looking for.
> 
> I will try to explain, I know I often don't make myself clear:
> 
> I'm using this diff() function.
> 
> This 'diff()' function finds the difference between two adjoining entries and it
> applies itself to the whole list so that in an instant I can have a list of
> differences between any two adjoining.
> 
> Then I can have a list of differences between any two with any specified gap -
> 'lag' it is called.
> Using the same function.
> 
> Now I have them and do that.  Then I add them together to find the 'lastone'
> which is the total difference for the period.
> 
> 
> Now here's the point:  that covers a period of two timespans, months, they are.
> 
>  if I want to cover a span of 24 months, say, then I would have to write this
> diff() function 24 times.
> 
>  what I'm doing is finding the difference between the starting point and every
> other point and then adding them all together.  bit like finding the area
> beneath the curve maybe.
> 
>  And that's what I want to do.
> 
>  :)
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ----- Original Message -----
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> To: arthur brogard <abrogard at yahoo.com>
> Cc: r-help at r-project.org
> Sent: Saturday, 24 December 2016, 15:34
> Subject: Re: [R] Is there a funct to sum differences?
> 
> You need to "reply all" so other people can help as well, and others can learn
> from your questions.
> 
> I am still puzzled by how you expect to compute "finalone". If you had supplied
> numbers other than all 5's it might have been easier to figure out what is going
> on.
> 
> What is your purpose in performing this calculation?
> 
> #### reproducible code
> rates <- read.table( text =
> "Date          Int
> Jan-1959        5
> Feb-1959        5
> Mar-1959        5
> Apr-1959        5
> May-1959        5
> Jun-1959        5
> Jul-1959        5
> Aug-1959        5
> Sep-1959        5
> Oct-1959        5
> Nov-1959        5
> ", header = TRUE, colClasses = c( "character", "numeric" ) )
> 
> #your code
> rates$thisone <- c(diff(rates$Int), NA)
> rates$nextone <- c(diff(rates$Int, lag=2), NA, NA) rates$lastone <-
> (rates$thisone + rates$nextone)/6.5*1000 # I doubt there is a ready-built
> function that knows you want to # divide by 6.5 or multiply by 1000
> 
> # form a vector from positions 2:11 and append NA)
> rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers that are not
> all the same
> rates$Int2 <- (1:11)^2
> rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
> 
> # dput(rates)
> result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959", "Apr-
> 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959", "Sep-1959", "Oct-
> 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5), thisone = c(0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, NA), nextone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0,
> 0, 0, 0, 0, 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
> experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA), experiment2 = c(5,
> 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)), .Names = c("Date", "Int",
> "thisone", "nextone", "lastone", "Int2", "experiment1", "experiment2"),
> row.names = c(NA, -11L), class = "data.frame")
> 
> On Sat, 24 Dec 2016, arthur brogard wrote:
> 
> >
> >
> > Yes, sure, thanks for your interest.  I apologise for not submitting in the
> correct manner.  I'll learn (I hope).
> >
> > Here's the source - a spreadsheet with just two columns, date and 'Int'.
> >
> >
> > Date    Int
> > Jan-1959    5
> > Feb-1959    5
> > Mar-1959    5
> > Apr-1959    5
> > May-1959    5
> > Jun-1959    5
> > Jul-1959    5
> > Aug-1959    5
> > Sep-1959    5
> > Oct-1959    5
> > Nov-1959    5
> >
> >
> > After processing it becomes this:
> >
> >
> >> rates
> > Date   Int thisone nextone     lastone finalone
> > 1   1959-01-01  5.00    0.00    0.00    0.000000       10
> > 2   1959-02-01  5.00    0.00    0.00    0.000000       10
> > 3   1959-03-01  5.00    0.00    0.00    0.000000       10
> > 4   1959-04-01  5.00    0.00    0.00    0.000000       10
> > 5   1959-05-01  5.00    0.00    0.00    0.000000       10
> > 6   1959-06-01  5.00    0.00    0.00    0.000000       10
> >
> > The one long column I'm referring to is the 'Int' column which R has imported.
> >
> > The actual code is:
> >
> >
> > rates <- read.csv("Rates2.csv",header =
> > TRUE,colClasses=c("character","numeric"))
> >
> > sapply(rates,class)
> >
> > rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
> > tz="UTC")
> >
> >
> > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > rates$nextone)/6.5*1000
> >
> >
> > rates
> >
> >
> >
> > ab
> >
> >
> >
> > ----- Original Message -----
> > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
> > <r-help at r-project.org>; "r-help at r-project.org" <r-help at r-project.org>
> > Sent: Saturday, 24 December 2016, 13:25
> > Subject: Re: [R] Is there a funct to sum differences?
> >
> > Could you make your example reproducible? That is, include some sample
> input and output. You talk about a column of numbers and then you seem to
> work with named lists and I can't reconcile your words with the code I see.
> > --
> > Sent from my phone. Please excuse my brevity.
> >
> >
> > On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help <r-help at r-
> project.org> wrote:
> >> I've been looking but I can't find a function to sum difference.
> >>
> >> I have this code:
> >>
> >>
> >> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> >> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> >> rates$nextone)
> >>
> >>
> >> It is looking down one long column of numbers.
> >>
> >> It sums the difference between the first two and then between the
> >> first and third and so on.
> >>
> >> Can it be made to automatically sum the difference between the first
> >> and subsequent to the end of a list?
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sun Dec 25 16:53:16 2016
From: jfox at mcmaster.ca (Fox, John)
Date: Sun, 25 Dec 2016 15:53:16 +0000
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <292647045.1377940.1482614651777@mail.yahoo.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
	<292647045.1377940.1482614651777@mail.yahoo.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC8365AB8F5@FHSDB2D11-2.csu.mcmaster.ca>

Dear Arthur,

Neither my nor Jeff Newmiller's solution uses any fancy math, just a little bit of programming. Here are the two solutions on a much larger simulated problem:

> set.seed(12345) # for reproducibility
> x <- rnorm(1e5)
> len <- length(x)
> maxlag <- 100
> 
> # John:
> system.time(
+     {
+         diffs <- matrix(0, len, maxlag)
+         for (lag in 1:maxlag){
+             diffs[1:(len - lag), lag] <- diff(x, lag=lag) 
+         }
+     }
+ )
   user  system elapsed 
   0.22    0.19    0.41 
> head(rowSums(diffs))
[1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559
> 
> # Jeff:
> system.time(
+     diffs.2 <- embed(c(x, rep(NA, maxlag)), maxlag + 1) - x
+ )
   user  system elapsed 
   0.36    0.04    0.39 
> head(rowSums(diffs.2, na.rm=TRUE))
[1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559

My solution uses a loop, Jeff's uses the embed() function -- of which I was unaware -- which hides the loop in the function.

If you want to do this kind of simple data management in R, it helps to learn some R programming.

Best,
 John

> -----Original Message-----
> From: arthur brogard [mailto:abrogard at yahoo.com]
> Sent: Saturday, December 24, 2016 4:24 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
> Subject: Re: [R] Is there a funct to sum differences?
> 
> 
> 
> Hello John,
> 
> 
> Here I am back again. Having learned no maths yet but I've looked over
> the results here and they are what I am after.
> 
> Now I'll try to understand how you did it.
> 
> :)
> 
> 
> 
> 
> ----- Original Message -----
> From: "Fox, John" <jfox at mcmaster.ca>
> To: arthur brogard <abrogard at yahoo.com>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org"
> <r-help at r-project.org>
> Sent: Sunday, 25 December 2016, 0:55
> Subject: RE: [R] Is there a funct to sum differences?
> 
> Dear Arthur,
> 
> Here's a simple script to do what I think you want. I've applied it to a
> contrived example, a vector of the squares of the integers 1 to 25, and
> have summed the first 5 differences, but the script is adaptable to any
> numeric vector and any maximum lag. You'll have to decide what to do
> with the last maximum-lag (in my case, 5) entries:
> 
> -------------- snip ------------
> > (x <- (1:25)^2)
> [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289
> 324 361 400 441 484 529 576
> [25] 625
> > len <- length(x)
> > maxlag <- 5
> > diffs <- matrix(0, len, maxlag)
> > for (lag in 1:maxlag){
> +     diffs[1:(len - lag), lag] <- diff(x, lag=lag) }
> > head(diffs)
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    3    8   15   24   35
> [2,]    5   12   21   32   45
> [3,]    7   16   27   40   55
> [4,]    9   20   33   48   65
> [5,]   11   24   39   56   75
> [6,]   13   28   45   64   85
> > tail(diffs)
>       [,1] [,2] [,3] [,4] [,5]
> [20,]   41   84  129  176  225
> [21,]   43   88  135  184    0
> [22,]   45   92  141    0    0
> [23,]   47   96    0    0    0
> [24,]   49    0    0    0    0
> [25,]    0    0    0    0    0
> > rowSums(diffs)
> [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565
> 595 625 655 450 278 143  49
> [25]   0
> -------------- snip ------------
> 
> The script could very simply be converted into a function if this is a
> repetitive task with variable inputs.
> 
> I hope this helps,
> John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
> > brogard via R-help
> > Sent: December 24, 2016 12:29 AM
> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Is there a funct to sum differences?
> >
> > Yes, sorry about that.  I keep making mistakes I shouldn't make.
> >
> > Thanks for the tip about 'reply all', I had no idea.
> >
> > You can ignore the finalone. I have been doing other work on this and
> > it comes from there. I took the example from the R screen after it had
> > run one of these other things that created the finalone.
> >
> > I guess I was thinking just seeing the data mentioned in the code was
> > be enough.
> >
> > I don't want a function to do the division and multiplication.
> >
> > It's a function that will ".. automatically sum the difference between
> > the first
> >
> >  and subsequent to the end of a list? "  that I am looking for.
> >
> > I will try to explain, I know I often don't make myself clear:
> >
> > I'm using this diff() function.
> >
> > This 'diff()' function finds the difference between two adjoining
> > entries and it applies itself to the whole list so that in an instant
> > I can have a list of differences between any two adjoining.
> >
> > Then I can have a list of differences between any two with any
> > specified gap - 'lag' it is called.
> > Using the same function.
> >
> > Now I have them and do that.  Then I add them together to find the
> 'lastone'
> > which is the total difference for the period.
> >
> >
> > Now here's the point:  that covers a period of two timespans, months,
> they are.
> >
> >  if I want to cover a span of 24 months, say, then I would have to
> > write this
> > diff() function 24 times.
> >
> >  what I'm doing is finding the difference between the starting point
> > and every other point and then adding them all together.  bit like
> > finding the area beneath the curve maybe.
> >
> >  And that's what I want to do.
> >
> >  :)
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ----- Original Message -----
> > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > To: arthur brogard <abrogard at yahoo.com>
> > Cc: r-help at r-project.org
> > Sent: Saturday, 24 December 2016, 15:34
> > Subject: Re: [R] Is there a funct to sum differences?
> >
> > You need to "reply all" so other people can help as well, and others
> > can learn from your questions.
> >
> > I am still puzzled by how you expect to compute "finalone". If you had
> > supplied numbers other than all 5's it might have been easier to
> > figure out what is going on.
> >
> > What is your purpose in performing this calculation?
> >
> > #### reproducible code
> > rates <- read.table( text =
> > "Date          Int
> > Jan-1959        5
> > Feb-1959        5
> > Mar-1959        5
> > Apr-1959        5
> > May-1959        5
> > Jun-1959        5
> > Jul-1959        5
> > Aug-1959        5
> > Sep-1959        5
> > Oct-1959        5
> > Nov-1959        5
> > ", header = TRUE, colClasses = c( "character", "numeric" ) )
> >
> > #your code
> > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > rates$nextone)/6.5*1000 # I doubt there is a ready-built function that
> > knows you want to # divide by 6.5 or multiply by 1000
> >
> > # form a vector from positions 2:11 and append NA)
> > rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers
> > that are not all the same
> > rates$Int2 <- (1:11)^2
> > rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
> >
> > # dput(rates)
> > result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959",
> > "Apr- 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959",
> > "Sep-1959", "Oct- 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5,
> > 5, 5, 5), thisone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone =
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0,
> > 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
> > experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA),
> > experiment2 = c(5, 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)),
> > .Names = c("Date", "Int", "thisone", "nextone", "lastone", "Int2",
> > "experiment1", "experiment2"), row.names = c(NA, -11L), class =
> > "data.frame")
> >
> > On Sat, 24 Dec 2016, arthur brogard wrote:
> >
> > >
> > >
> > > Yes, sure, thanks for your interest.  I apologise for not submitting
> > > in the
> > correct manner.  I'll learn (I hope).
> > >
> > > Here's the source - a spreadsheet with just two columns, date and
> 'Int'.
> > >
> > >
> > > Date    Int
> > > Jan-1959    5
> > > Feb-1959    5
> > > Mar-1959    5
> > > Apr-1959    5
> > > May-1959    5
> > > Jun-1959    5
> > > Jul-1959    5
> > > Aug-1959    5
> > > Sep-1959    5
> > > Oct-1959    5
> > > Nov-1959    5
> > >
> > >
> > > After processing it becomes this:
> > >
> > >
> > >> rates
> > > Date   Int thisone nextone     lastone finalone
> > > 1   1959-01-01  5.00    0.00    0.00    0.000000       10
> > > 2   1959-02-01  5.00    0.00    0.00    0.000000       10
> > > 3   1959-03-01  5.00    0.00    0.00    0.000000       10
> > > 4   1959-04-01  5.00    0.00    0.00    0.000000       10
> > > 5   1959-05-01  5.00    0.00    0.00    0.000000       10
> > > 6   1959-06-01  5.00    0.00    0.00    0.000000       10
> > >
> > > The one long column I'm referring to is the 'Int' column which R has
> imported.
> > >
> > > The actual code is:
> > >
> > >
> > > rates <- read.csv("Rates2.csv",header =
> > > TRUE,colClasses=c("character","numeric"))
> > >
> > > sapply(rates,class)
> > >
> > > rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
> > > tz="UTC")
> > >
> > >
> > > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > > rates$nextone)/6.5*1000
> > >
> > >
> > > rates
> > >
> > >
> > >
> > > ab
> > >
> > >
> > >
> > > ----- Original Message -----
> > > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > > To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
> > > <r-help at r-project.org>; "r-help at r-project.org"
> > > <r-help at r-project.org>
> > > Sent: Saturday, 24 December 2016, 13:25
> > > Subject: Re: [R] Is there a funct to sum differences?
> > >
> > > Could you make your example reproducible? That is, include some
> > > sample
> > input and output. You talk about a column of numbers and then you seem
> > to work with named lists and I can't reconcile your words with the
> code I see.
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> > >
> > > On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help
> > > <r-help at r-
> > project.org> wrote:
> > >> I've been looking but I can't find a function to sum difference.
> > >>
> > >> I have this code:
> > >>
> > >>
> > >> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > >> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > >> rates$nextone)
> > >>
> > >>
> > >> It is looking down one long column of numbers.
> > >>
> > >> It sums the difference between the first two and then between the
> > >> first and third and so on.
> > >>
> > >> Can it be made to automatically sum the difference between the
> > >> first and subsequent to the end of a list?
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ----------------------------------------------------------------------
> -----
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                        Live:   OO#.. Dead: OO#..
> Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

From bogaso.christofer at gmail.com  Sun Dec 25 21:32:16 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 26 Dec 2016 02:02:16 +0530
Subject: [R] Download data from Internet contained in a Zip file
Message-ID: <CA+dpOJn3OzpdGkvjEJkNMacMPj374tSi0UKEFkAxDaAfJ+f3zg@mail.gmail.com>

Hi again,

I was following the instruction available in
"http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data"
to download data from Internet contained in a zip file from the
address :

https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip

However when I tried to follow the instruction I am facing below error :

> temp <- tempfile()
> download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",temp)
Error in download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",
 :
  unsupported URL scheme

Can someone here please tell me what went wrong in above?

Highly appreciate your feedback.

Thanks for your time.


From abrogard at yahoo.com  Sun Dec 25 22:34:06 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Sun, 25 Dec 2016 21:34:06 +0000 (UTC)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC8365AB8F5@FHSDB2D11-2.csu.mcmaster.ca>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
	<292647045.1377940.1482614651777@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB8F5@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <1790771369.1588008.1482701646079@mail.yahoo.com>

Hi,

thanks for this.


quote 
If you want to do this kind of simple data management in R, it helps to learn some R programming.unquote

yep. I'm trying. we learn by doing, I think, that's what this is all about.

I was a programmer years ago.  Now I want to find a language to work in for the present day and my present interests.  


:)

ab






----- Original Message -----
From: "Fox, John" <jfox at mcmaster.ca>
To: arthur brogard <abrogard at yahoo.com>
Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org" <r-help at r-project.org>
Sent: Monday, 26 December 2016, 2:23
Subject: RE: [R] Is there a funct to sum differences?

Dear Arthur,

Neither my nor Jeff Newmiller's solution uses any fancy math, just a little bit of programming. Here are the two solutions on a much larger simulated problem:

> set.seed(12345) # for reproducibility
> x <- rnorm(1e5)
> len <- length(x)
> maxlag <- 100
> 
> # John:
> system.time(
+     {
+         diffs <- matrix(0, len, maxlag)
+         for (lag in 1:maxlag){
+             diffs[1:(len - lag), lag] <- diff(x, lag=lag) 
+         }
+     }
+ )
   user  system elapsed 
   0.22    0.19    0.41 
> head(rowSums(diffs))
[1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559
> 
> # Jeff:
> system.time(
+     diffs.2 <- embed(c(x, rep(NA, maxlag)), maxlag + 1) - x
+ )
   user  system elapsed 
   0.36    0.04    0.39 
> head(rowSums(diffs.2, na.rm=TRUE))
[1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559

My solution uses a loop, Jeff's uses the embed() function -- of which I was unaware -- which hides the loop in the function.

If you want to do this kind of simple data management in R, it helps to learn some R programming.

Best,
John


> -----Original Message-----
> From: arthur brogard [mailto:abrogard at yahoo.com]
> Sent: Saturday, December 24, 2016 4:24 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
> Subject: Re: [R] Is there a funct to sum differences?
> 
> 
> 
> Hello John,
> 
> 
> Here I am back again. Having learned no maths yet but I've looked over
> the results here and they are what I am after.
> 
> Now I'll try to understand how you did it.
> 
> :)
> 
> 
> 
> 
> ----- Original Message -----
> From: "Fox, John" <jfox at mcmaster.ca>
> To: arthur brogard <abrogard at yahoo.com>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org"
> <r-help at r-project.org>
> Sent: Sunday, 25 December 2016, 0:55
> Subject: RE: [R] Is there a funct to sum differences?
> 
> Dear Arthur,
> 
> Here's a simple script to do what I think you want. I've applied it to a
> contrived example, a vector of the squares of the integers 1 to 25, and
> have summed the first 5 differences, but the script is adaptable to any
> numeric vector and any maximum lag. You'll have to decide what to do
> with the last maximum-lag (in my case, 5) entries:
> 
> -------------- snip ------------
> > (x <- (1:25)^2)
> [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289
> 324 361 400 441 484 529 576
> [25] 625
> > len <- length(x)
> > maxlag <- 5
> > diffs <- matrix(0, len, maxlag)
> > for (lag in 1:maxlag){
> +     diffs[1:(len - lag), lag] <- diff(x, lag=lag) }
> > head(diffs)
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    3    8   15   24   35
> [2,]    5   12   21   32   45
> [3,]    7   16   27   40   55
> [4,]    9   20   33   48   65
> [5,]   11   24   39   56   75
> [6,]   13   28   45   64   85
> > tail(diffs)
>       [,1] [,2] [,3] [,4] [,5]
> [20,]   41   84  129  176  225
> [21,]   43   88  135  184    0
> [22,]   45   92  141    0    0
> [23,]   47   96    0    0    0
> [24,]   49    0    0    0    0
> [25,]    0    0    0    0    0
> > rowSums(diffs)
> [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565
> 595 625 655 450 278 143  49
> [25]   0
> -------------- snip ------------
> 
> The script could very simply be converted into a function if this is a
> repetitive task with variable inputs.
> 
> I hope this helps,
> John
> 
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
> 
> 
> 
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
> > brogard via R-help
> > Sent: December 24, 2016 12:29 AM
> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Is there a funct to sum differences?
> >
> > Yes, sorry about that.  I keep making mistakes I shouldn't make.
> >
> > Thanks for the tip about 'reply all', I had no idea.
> >
> > You can ignore the finalone. I have been doing other work on this and
> > it comes from there. I took the example from the R screen after it had
> > run one of these other things that created the finalone.
> >
> > I guess I was thinking just seeing the data mentioned in the code was
> > be enough.
> >
> > I don't want a function to do the division and multiplication.
> >
> > It's a function that will ".. automatically sum the difference between
> > the first
> >
> >  and subsequent to the end of a list? "  that I am looking for.
> >
> > I will try to explain, I know I often don't make myself clear:
> >
> > I'm using this diff() function.
> >
> > This 'diff()' function finds the difference between two adjoining
> > entries and it applies itself to the whole list so that in an instant
> > I can have a list of differences between any two adjoining.
> >
> > Then I can have a list of differences between any two with any
> > specified gap - 'lag' it is called.
> > Using the same function.
> >
> > Now I have them and do that.  Then I add them together to find the
> 'lastone'
> > which is the total difference for the period.
> >
> >
> > Now here's the point:  that covers a period of two timespans, months,
> they are.
> >
> >  if I want to cover a span of 24 months, say, then I would have to
> > write this
> > diff() function 24 times.
> >
> >  what I'm doing is finding the difference between the starting point
> > and every other point and then adding them all together.  bit like
> > finding the area beneath the curve maybe.
> >
> >  And that's what I want to do.
> >
> >  :)
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ----- Original Message -----
> > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > To: arthur brogard <abrogard at yahoo.com>
> > Cc: r-help at r-project.org
> > Sent: Saturday, 24 December 2016, 15:34
> > Subject: Re: [R] Is there a funct to sum differences?
> >
> > You need to "reply all" so other people can help as well, and others
> > can learn from your questions.
> >
> > I am still puzzled by how you expect to compute "finalone". If you had
> > supplied numbers other than all 5's it might have been easier to
> > figure out what is going on.
> >
> > What is your purpose in performing this calculation?
> >
> > #### reproducible code
> > rates <- read.table( text =
> > "Date          Int
> > Jan-1959        5
> > Feb-1959        5
> > Mar-1959        5
> > Apr-1959        5
> > May-1959        5
> > Jun-1959        5
> > Jul-1959        5
> > Aug-1959        5
> > Sep-1959        5
> > Oct-1959        5
> > Nov-1959        5
> > ", header = TRUE, colClasses = c( "character", "numeric" ) )
> >
> > #your code
> > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > rates$nextone)/6.5*1000 # I doubt there is a ready-built function that
> > knows you want to # divide by 6.5 or multiply by 1000
> >
> > # form a vector from positions 2:11 and append NA)
> > rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers
> > that are not all the same
> > rates$Int2 <- (1:11)^2
> > rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
> >
> > # dput(rates)
> > result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959",
> > "Apr- 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959",
> > "Sep-1959", "Oct- 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5,
> > 5, 5, 5), thisone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone =
> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0,
> > 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
> > experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA),
> > experiment2 = c(5, 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)),
> > .Names = c("Date", "Int", "thisone", "nextone", "lastone", "Int2",
> > "experiment1", "experiment2"), row.names = c(NA, -11L), class =
> > "data.frame")
> >
> > On Sat, 24 Dec 2016, arthur brogard wrote:
> >
> > >
> > >
> > > Yes, sure, thanks for your interest.  I apologise for not submitting
> > > in the
> > correct manner.  I'll learn (I hope).
> > >
> > > Here's the source - a spreadsheet with just two columns, date and
> 'Int'.
> > >
> > >
> > > Date    Int
> > > Jan-1959    5
> > > Feb-1959    5
> > > Mar-1959    5
> > > Apr-1959    5
> > > May-1959    5
> > > Jun-1959    5
> > > Jul-1959    5
> > > Aug-1959    5
> > > Sep-1959    5
> > > Oct-1959    5
> > > Nov-1959    5
> > >
> > >
> > > After processing it becomes this:
> > >
> > >
> > >> rates
> > > Date   Int thisone nextone     lastone finalone
> > > 1   1959-01-01  5.00    0.00    0.00    0.000000       10
> > > 2   1959-02-01  5.00    0.00    0.00    0.000000       10
> > > 3   1959-03-01  5.00    0.00    0.00    0.000000       10
> > > 4   1959-04-01  5.00    0.00    0.00    0.000000       10
> > > 5   1959-05-01  5.00    0.00    0.00    0.000000       10
> > > 6   1959-06-01  5.00    0.00    0.00    0.000000       10
> > >
> > > The one long column I'm referring to is the 'Int' column which R has
> imported.
> > >
> > > The actual code is:
> > >
> > >
> > > rates <- read.csv("Rates2.csv",header =
> > > TRUE,colClasses=c("character","numeric"))
> > >
> > > sapply(rates,class)
> > >
> > > rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
> > > tz="UTC")
> > >
> > >
> > > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > > rates$nextone)/6.5*1000
> > >
> > >
> > > rates
> > >
> > >
> > >
> > > ab
> > >
> > >
> > >
> > > ----- Original Message -----
> > > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> > > To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
> > > <r-help at r-project.org>; "r-help at r-project.org"
> > > <r-help at r-project.org>
> > > Sent: Saturday, 24 December 2016, 13:25
> > > Subject: Re: [R] Is there a funct to sum differences?
> > >
> > > Could you make your example reproducible? That is, include some
> > > sample
> > input and output. You talk about a column of numbers and then you seem
> > to work with named lists and I can't reconcile your words with the
> code I see.
> > > --
> > > Sent from my phone. Please excuse my brevity.
> > >
> > >
> > > On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help
> > > <r-help at r-
> > project.org> wrote:
> > >> I've been looking but I can't find a function to sum difference.
> > >>
> > >> I have this code:
> > >>
> > >>
> > >> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
> > >> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
> > >> rates$nextone)
> > >>
> > >>
> > >> It is looking down one long column of numbers.
> > >>
> > >> It sums the difference between the first two and then between the
> > >> first and third and so on.
> > >>
> > >> Can it be made to automatically sum the difference between the
> > >> first and subsequent to the end of a list?
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> > ----------------------------------------------------------------------
> -----
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                        Live:   OO#.. Dead: OO#..
> Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> 
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Dec 25 22:40:15 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Dec 2016 13:40:15 -0800
Subject: [R] Download data from Internet contained in a Zip file
In-Reply-To: <CA+dpOJn3OzpdGkvjEJkNMacMPj374tSi0UKEFkAxDaAfJ+f3zg@mail.gmail.com>
References: <CA+dpOJn3OzpdGkvjEJkNMacMPj374tSi0UKEFkAxDaAfJ+f3zg@mail.gmail.com>
Message-ID: <C273D081-1091-42EC-B3ED-BB961BA2F452@dcn.davis.ca.us>

This has nothing to do with the fact that you are dealing with a zip file and everything to do with the "s" in "https", and all the solutions I have seen involve knowing what operating system you are using. I highly recommend that you study what Google has to say when you include that detail and leave out the zip keyword.
-- 
Sent from my phone. Please excuse my brevity.

On December 25, 2016 12:32:16 PM PST, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi again,
>
>I was following the instruction available in
>"http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data"
>to download data from Internet contained in a zip file from the
>address :
>
>https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip
>
>However when I tried to follow the instruction I am facing below error
>:
>
>> temp <- tempfile()
>>
>download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",temp)
>Error in
>download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",
> :
>  unsupported URL scheme
>
>Can someone here please tell me what went wrong in above?
>
>Highly appreciate your feedback.
>
>Thanks for your time.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Dec 25 22:46:39 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Dec 2016 13:46:39 -0800
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <1790771369.1588008.1482701646079@mail.yahoo.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
	<292647045.1377940.1482614651777@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB8F5@FHSDB2D11-2.csu.mcmaster.ca>
	<1790771369.1588008.1482701646079@mail.yahoo.com>
Message-ID: <CAGxFJbSB_xFqv0PupT+F=2P4Hxm2k1pBHjg8ftMnrffq49VAyQ@mail.gmail.com>

Arthur:

There are many good R tutorials on the web. e.g. see here for some
recommendations:

https://www.rstudio.com/online-learning/#R

I think you would do better to go through some structured tutorials
then continuing to fool around in this way on your own. Just mho of
course.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 25, 2016 at 1:34 PM, arthur brogard via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> thanks for this.
>
>
> quote
> If you want to do this kind of simple data management in R, it helps to learn some R programming.unquote
>
> yep. I'm trying. we learn by doing, I think, that's what this is all about.
>
> I was a programmer years ago.  Now I want to find a language to work in for the present day and my present interests.
>
>
> :)
>
> ab
>
>
>
>
>
>
> ----- Original Message -----
> From: "Fox, John" <jfox at mcmaster.ca>
> To: arthur brogard <abrogard at yahoo.com>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org" <r-help at r-project.org>
> Sent: Monday, 26 December 2016, 2:23
> Subject: RE: [R] Is there a funct to sum differences?
>
> Dear Arthur,
>
> Neither my nor Jeff Newmiller's solution uses any fancy math, just a little bit of programming. Here are the two solutions on a much larger simulated problem:
>
>> set.seed(12345) # for reproducibility
>> x <- rnorm(1e5)
>> len <- length(x)
>> maxlag <- 100
>>
>> # John:
>> system.time(
> +     {
> +         diffs <- matrix(0, len, maxlag)
> +         for (lag in 1:maxlag){
> +             diffs[1:(len - lag), lag] <- diff(x, lag=lag)
> +         }
> +     }
> + )
>    user  system elapsed
>    0.22    0.19    0.41
>> head(rowSums(diffs))
> [1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559
>>
>> # Jeff:
>> system.time(
> +     diffs.2 <- embed(c(x, rep(NA, maxlag)), maxlag + 1) - x
> + )
>    user  system elapsed
>    0.36    0.04    0.39
>> head(rowSums(diffs.2, na.rm=TRUE))
> [1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559
>
> My solution uses a loop, Jeff's uses the embed() function -- of which I was unaware -- which hides the loop in the function.
>
> If you want to do this kind of simple data management in R, it helps to learn some R programming.
>
> Best,
> John
>
>
>> -----Original Message-----
>> From: arthur brogard [mailto:abrogard at yahoo.com]
>> Sent: Saturday, December 24, 2016 4:24 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>>
>>
>> Hello John,
>>
>>
>> Here I am back again. Having learned no maths yet but I've looked over
>> the results here and they are what I am after.
>>
>> Now I'll try to understand how you did it.
>>
>> :)
>>
>>
>>
>>
>> ----- Original Message -----
>> From: "Fox, John" <jfox at mcmaster.ca>
>> To: arthur brogard <abrogard at yahoo.com>
>> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org"
>> <r-help at r-project.org>
>> Sent: Sunday, 25 December 2016, 0:55
>> Subject: RE: [R] Is there a funct to sum differences?
>>
>> Dear Arthur,
>>
>> Here's a simple script to do what I think you want. I've applied it to a
>> contrived example, a vector of the squares of the integers 1 to 25, and
>> have summed the first 5 differences, but the script is adaptable to any
>> numeric vector and any maximum lag. You'll have to decide what to do
>> with the last maximum-lag (in my case, 5) entries:
>>
>> -------------- snip ------------
>> > (x <- (1:25)^2)
>> [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289
>> 324 361 400 441 484 529 576
>> [25] 625
>> > len <- length(x)
>> > maxlag <- 5
>> > diffs <- matrix(0, len, maxlag)
>> > for (lag in 1:maxlag){
>> +     diffs[1:(len - lag), lag] <- diff(x, lag=lag) }
>> > head(diffs)
>>      [,1] [,2] [,3] [,4] [,5]
>> [1,]    3    8   15   24   35
>> [2,]    5   12   21   32   45
>> [3,]    7   16   27   40   55
>> [4,]    9   20   33   48   65
>> [5,]   11   24   39   56   75
>> [6,]   13   28   45   64   85
>> > tail(diffs)
>>       [,1] [,2] [,3] [,4] [,5]
>> [20,]   41   84  129  176  225
>> [21,]   43   88  135  184    0
>> [22,]   45   92  141    0    0
>> [23,]   47   96    0    0    0
>> [24,]   49    0    0    0    0
>> [25,]    0    0    0    0    0
>> > rowSums(diffs)
>> [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565
>> 595 625 655 450 278 143  49
>> [25]   0
>> -------------- snip ------------
>>
>> The script could very simply be converted into a function if this is a
>> repetitive task with variable inputs.
>>
>> I hope this helps,
>> John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
>> > brogard via R-help
>> > Sent: December 24, 2016 12:29 AM
>> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] Is there a funct to sum differences?
>> >
>> > Yes, sorry about that.  I keep making mistakes I shouldn't make.
>> >
>> > Thanks for the tip about 'reply all', I had no idea.
>> >
>> > You can ignore the finalone. I have been doing other work on this and
>> > it comes from there. I took the example from the R screen after it had
>> > run one of these other things that created the finalone.
>> >
>> > I guess I was thinking just seeing the data mentioned in the code was
>> > be enough.
>> >
>> > I don't want a function to do the division and multiplication.
>> >
>> > It's a function that will ".. automatically sum the difference between
>> > the first
>> >
>> >  and subsequent to the end of a list? "  that I am looking for.
>> >
>> > I will try to explain, I know I often don't make myself clear:
>> >
>> > I'm using this diff() function.
>> >
>> > This 'diff()' function finds the difference between two adjoining
>> > entries and it applies itself to the whole list so that in an instant
>> > I can have a list of differences between any two adjoining.
>> >
>> > Then I can have a list of differences between any two with any
>> > specified gap - 'lag' it is called.
>> > Using the same function.
>> >
>> > Now I have them and do that.  Then I add them together to find the
>> 'lastone'
>> > which is the total difference for the period.
>> >
>> >
>> > Now here's the point:  that covers a period of two timespans, months,
>> they are.
>> >
>> >  if I want to cover a span of 24 months, say, then I would have to
>> > write this
>> > diff() function 24 times.
>> >
>> >  what I'm doing is finding the difference between the starting point
>> > and every other point and then adding them all together.  bit like
>> > finding the area beneath the curve maybe.
>> >
>> >  And that's what I want to do.
>> >
>> >  :)
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ----- Original Message -----
>> > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > To: arthur brogard <abrogard at yahoo.com>
>> > Cc: r-help at r-project.org
>> > Sent: Saturday, 24 December 2016, 15:34
>> > Subject: Re: [R] Is there a funct to sum differences?
>> >
>> > You need to "reply all" so other people can help as well, and others
>> > can learn from your questions.
>> >
>> > I am still puzzled by how you expect to compute "finalone". If you had
>> > supplied numbers other than all 5's it might have been easier to
>> > figure out what is going on.
>> >
>> > What is your purpose in performing this calculation?
>> >
>> > #### reproducible code
>> > rates <- read.table( text =
>> > "Date          Int
>> > Jan-1959        5
>> > Feb-1959        5
>> > Mar-1959        5
>> > Apr-1959        5
>> > May-1959        5
>> > Jun-1959        5
>> > Jul-1959        5
>> > Aug-1959        5
>> > Sep-1959        5
>> > Oct-1959        5
>> > Nov-1959        5
>> > ", header = TRUE, colClasses = c( "character", "numeric" ) )
>> >
>> > #your code
>> > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>> > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>> > rates$nextone)/6.5*1000 # I doubt there is a ready-built function that
>> > knows you want to # divide by 6.5 or multiply by 1000
>> >
>> > # form a vector from positions 2:11 and append NA)
>> > rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers
>> > that are not all the same
>> > rates$Int2 <- (1:11)^2
>> > rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
>> >
>> > # dput(rates)
>> > result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959",
>> > "Apr- 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959",
>> > "Sep-1959", "Oct- 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5,
>> > 5, 5, 5), thisone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone =
>> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0,
>> > 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
>> > experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA),
>> > experiment2 = c(5, 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)),
>> > .Names = c("Date", "Int", "thisone", "nextone", "lastone", "Int2",
>> > "experiment1", "experiment2"), row.names = c(NA, -11L), class =
>> > "data.frame")
>> >
>> > On Sat, 24 Dec 2016, arthur brogard wrote:
>> >
>> > >
>> > >
>> > > Yes, sure, thanks for your interest.  I apologise for not submitting
>> > > in the
>> > correct manner.  I'll learn (I hope).
>> > >
>> > > Here's the source - a spreadsheet with just two columns, date and
>> 'Int'.
>> > >
>> > >
>> > > Date    Int
>> > > Jan-1959    5
>> > > Feb-1959    5
>> > > Mar-1959    5
>> > > Apr-1959    5
>> > > May-1959    5
>> > > Jun-1959    5
>> > > Jul-1959    5
>> > > Aug-1959    5
>> > > Sep-1959    5
>> > > Oct-1959    5
>> > > Nov-1959    5
>> > >
>> > >
>> > > After processing it becomes this:
>> > >
>> > >
>> > >> rates
>> > > Date   Int thisone nextone     lastone finalone
>> > > 1   1959-01-01  5.00    0.00    0.00    0.000000       10
>> > > 2   1959-02-01  5.00    0.00    0.00    0.000000       10
>> > > 3   1959-03-01  5.00    0.00    0.00    0.000000       10
>> > > 4   1959-04-01  5.00    0.00    0.00    0.000000       10
>> > > 5   1959-05-01  5.00    0.00    0.00    0.000000       10
>> > > 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>> > >
>> > > The one long column I'm referring to is the 'Int' column which R has
>> imported.
>> > >
>> > > The actual code is:
>> > >
>> > >
>> > > rates <- read.csv("Rates2.csv",header =
>> > > TRUE,colClasses=c("character","numeric"))
>> > >
>> > > sapply(rates,class)
>> > >
>> > > rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
>> > > tz="UTC")
>> > >
>> > >
>> > > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>> > > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>> > > rates$nextone)/6.5*1000
>> > >
>> > >
>> > > rates
>> > >
>> > >
>> > >
>> > > ab
>> > >
>> > >
>> > >
>> > > ----- Original Message -----
>> > > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > > To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
>> > > <r-help at r-project.org>; "r-help at r-project.org"
>> > > <r-help at r-project.org>
>> > > Sent: Saturday, 24 December 2016, 13:25
>> > > Subject: Re: [R] Is there a funct to sum differences?
>> > >
>> > > Could you make your example reproducible? That is, include some
>> > > sample
>> > input and output. You talk about a column of numbers and then you seem
>> > to work with named lists and I can't reconcile your words with the
>> code I see.
>> > > --
>> > > Sent from my phone. Please excuse my brevity.
>> > >
>> > >
>> > > On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help
>> > > <r-help at r-
>> > project.org> wrote:
>> > >> I've been looking but I can't find a function to sum difference.
>> > >>
>> > >> I have this code:
>> > >>
>> > >>
>> > >> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>> > >> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>> > >> rates$nextone)
>> > >>
>> > >>
>> > >> It is looking down one long column of numbers.
>> > >>
>> > >> It sums the difference between the first two and then between the
>> > >> first and third and so on.
>> > >>
>> > >> Can it be made to automatically sum the difference between the
>> > >> first and subsequent to the end of a list?
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >
>> >
>> > ----------------------------------------------------------------------
>> -----
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>> >                                        Live:   OO#.. Dead: OO#..
>> Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Sun Dec 25 22:50:00 2016
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 26 Dec 2016 03:20:00 +0530
Subject: [R] Download data from Internet contained in a Zip file
In-Reply-To: <C273D081-1091-42EC-B3ED-BB961BA2F452@dcn.davis.ca.us>
References: <CA+dpOJn3OzpdGkvjEJkNMacMPj374tSi0UKEFkAxDaAfJ+f3zg@mail.gmail.com>
	<C273D081-1091-42EC-B3ED-BB961BA2F452@dcn.davis.ca.us>
Message-ID: <CA+dpOJkMd9KXsfxyVePziaK25j7r-y_CNb5CsErd0FbECpwvQg@mail.gmail.com>

Hi Jeff, I dont think I understood all that you said. I am using Mac
OS X 10.7.5 as OS

On Mon, Dec 26, 2016 at 3:10 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> This has nothing to do with the fact that you are dealing with a zip file and everything to do with the "s" in "https", and all the solutions I have seen involve knowing what operating system you are using. I highly recommend that you study what Google has to say when you include that detail and leave out the zip keyword.
> --
> Sent from my phone. Please excuse my brevity.
>
> On December 25, 2016 12:32:16 PM PST, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>>Hi again,
>>
>>I was following the instruction available in
>>"http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data"
>>to download data from Internet contained in a zip file from the
>>address :
>>
>>https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip
>>
>>However when I tried to follow the instruction I am facing below error
>>:
>>
>>> temp <- tempfile()
>>>
>>download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",temp)
>>Error in
>>download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",
>> :
>>  unsupported URL scheme
>>
>>Can someone here please tell me what went wrong in above?
>>
>>Highly appreciate your feedback.
>>
>>Thanks for your time.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From abrogard at yahoo.com  Sun Dec 25 22:57:59 2016
From: abrogard at yahoo.com (arthur brogard)
Date: Sun, 25 Dec 2016 21:57:59 +0000 (UTC)
Subject: [R] Is there a funct to sum differences?
In-Reply-To: <CAGxFJbSB_xFqv0PupT+F=2P4Hxm2k1pBHjg8ftMnrffq49VAyQ@mail.gmail.com>
References: <703412216.1105374.1482536418760.ref@mail.yahoo.com>
	<703412216.1105374.1482536418760@mail.yahoo.com>
	<E6F7C522-BDD7-48ED-8B49-1FE10FD7D8F1@dcn.davis.ca.us>
	<973592405.1191541.1482550037102@mail.yahoo.com>
	<alpine.BSF.2.00.1612232032250.47101@pedal.dcn.davis.ca.us>
	<538050454.1214553.1482557361906@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB6F5@FHSDB2D11-2.csu.mcmaster.ca>
	<292647045.1377940.1482614651777@mail.yahoo.com>
	<ACD1644AA6C67E4FBD0C350625508EC8365AB8F5@FHSDB2D11-2.csu.mcmaster.ca>
	<1790771369.1588008.1482701646079@mail.yahoo.com>
	<CAGxFJbSB_xFqv0PupT+F=2P4Hxm2k1pBHjg8ftMnrffq49VAyQ@mail.gmail.com>
Message-ID: <1097790811.1591772.1482703079745@mail.yahoo.com>

Thanks Bert,

no, you're right.

but how about doing both at once?  that's what I do...

and while i'm doing that I have a metalwork project, a computer a-building and a car fixing going on, to name but a few..

can't help it. my lifestyle just comes out like that...

thanks for the link.  all grist for the mill..


:)





----- Original Message -----
From: Bert Gunter <bgunter.4567 at gmail.com>
To: arthur brogard <abrogard at yahoo.com>
Cc: "Fox, John" <jfox at mcmaster.ca>; "r-help at r-project.org" <r-help at r-project.org>
Sent: Monday, 26 December 2016, 8:16
Subject: Re: [R] Is there a funct to sum differences?

Arthur:

There are many good R tutorials on the web. e.g. see here for some
recommendations:

https://www.rstudio.com/online-learning/#R

I think you would do better to go through some structured tutorials
then continuing to fool around in this way on your own. Just mho of
course.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Dec 25, 2016 at 1:34 PM, arthur brogard via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> thanks for this.
>
>
> quote
> If you want to do this kind of simple data management in R, it helps to learn some R programming.unquote
>
> yep. I'm trying. we learn by doing, I think, that's what this is all about.
>
> I was a programmer years ago.  Now I want to find a language to work in for the present day and my present interests.
>
>
> :)
>
> ab
>
>
>
>
>
>
> ----- Original Message -----
> From: "Fox, John" <jfox at mcmaster.ca>
> To: arthur brogard <abrogard at yahoo.com>
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org" <r-help at r-project.org>
> Sent: Monday, 26 December 2016, 2:23
> Subject: RE: [R] Is there a funct to sum differences?
>
> Dear Arthur,
>
> Neither my nor Jeff Newmiller's solution uses any fancy math, just a little bit of programming. Here are the two solutions on a much larger simulated problem:
>
>> set.seed(12345) # for reproducibility
>> x <- rnorm(1e5)
>> len <- length(x)
>> maxlag <- 100
>>
>> # John:
>> system.time(
> +     {
> +         diffs <- matrix(0, len, maxlag)
> +         for (lag in 1:maxlag){
> +             diffs[1:(len - lag), lag] <- diff(x, lag=lag)
> +         }
> +     }
> + )
>    user  system elapsed
>    0.22    0.19    0.41
>> head(rowSums(diffs))
> [1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559
>>
>> # Jeff:
>> system.time(
> +     diffs.2 <- embed(c(x, rep(NA, maxlag)), maxlag + 1) - x
> + )
>    user  system elapsed
>    0.36    0.04    0.39
>> head(rowSums(diffs.2, na.rm=TRUE))
> [1] -34.39477 -48.65417  33.75448  67.30261 -39.10066 204.56559
>
> My solution uses a loop, Jeff's uses the embed() function -- of which I was unaware -- which hides the loop in the function.
>
> If you want to do this kind of simple data management in R, it helps to learn some R programming.
>
> Best,
> John
>
>
>> -----Original Message-----
>> From: arthur brogard [mailto:abrogard at yahoo.com]
>> Sent: Saturday, December 24, 2016 4:24 PM
>> To: Fox, John <jfox at mcmaster.ca>
>> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; r-help at r-project.org
>> Subject: Re: [R] Is there a funct to sum differences?
>>
>>
>>
>> Hello John,
>>
>>
>> Here I am back again. Having learned no maths yet but I've looked over
>> the results here and they are what I am after.
>>
>> Now I'll try to understand how you did it.
>>
>> :)
>>
>>
>>
>>
>> ----- Original Message -----
>> From: "Fox, John" <jfox at mcmaster.ca>
>> To: arthur brogard <abrogard at yahoo.com>
>> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>; "r-help at r-project.org"
>> <r-help at r-project.org>
>> Sent: Sunday, 25 December 2016, 0:55
>> Subject: RE: [R] Is there a funct to sum differences?
>>
>> Dear Arthur,
>>
>> Here's a simple script to do what I think you want. I've applied it to a
>> contrived example, a vector of the squares of the integers 1 to 25, and
>> have summed the first 5 differences, but the script is adaptable to any
>> numeric vector and any maximum lag. You'll have to decide what to do
>> with the last maximum-lag (in my case, 5) entries:
>>
>> -------------- snip ------------
>> > (x <- (1:25)^2)
>> [1]   1   4   9  16  25  36  49  64  81 100 121 144 169 196 225 256 289
>> 324 361 400 441 484 529 576
>> [25] 625
>> > len <- length(x)
>> > maxlag <- 5
>> > diffs <- matrix(0, len, maxlag)
>> > for (lag in 1:maxlag){
>> +     diffs[1:(len - lag), lag] <- diff(x, lag=lag) }
>> > head(diffs)
>>      [,1] [,2] [,3] [,4] [,5]
>> [1,]    3    8   15   24   35
>> [2,]    5   12   21   32   45
>> [3,]    7   16   27   40   55
>> [4,]    9   20   33   48   65
>> [5,]   11   24   39   56   75
>> [6,]   13   28   45   64   85
>> > tail(diffs)
>>       [,1] [,2] [,3] [,4] [,5]
>> [20,]   41   84  129  176  225
>> [21,]   43   88  135  184    0
>> [22,]   45   92  141    0    0
>> [23,]   47   96    0    0    0
>> [24,]   49    0    0    0    0
>> [25,]    0    0    0    0    0
>> > rowSums(diffs)
>> [1]  85 115 145 175 205 235 265 295 325 355 385 415 445 475 505 535 565
>> 595 625 655 450 278 143  49
>> [25]   0
>> -------------- snip ------------
>>
>> The script could very simply be converted into a function if this is a
>> repetitive task with variable inputs.
>>
>> I hope this helps,
>> John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>> > -----Original Message-----
>> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of arthur
>> > brogard via R-help
>> > Sent: December 24, 2016 12:29 AM
>> > To: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > Cc: r-help at r-project.org
>> > Subject: Re: [R] Is there a funct to sum differences?
>> >
>> > Yes, sorry about that.  I keep making mistakes I shouldn't make.
>> >
>> > Thanks for the tip about 'reply all', I had no idea.
>> >
>> > You can ignore the finalone. I have been doing other work on this and
>> > it comes from there. I took the example from the R screen after it had
>> > run one of these other things that created the finalone.
>> >
>> > I guess I was thinking just seeing the data mentioned in the code was
>> > be enough.
>> >
>> > I don't want a function to do the division and multiplication.
>> >
>> > It's a function that will ".. automatically sum the difference between
>> > the first
>> >
>> >  and subsequent to the end of a list? "  that I am looking for.
>> >
>> > I will try to explain, I know I often don't make myself clear:
>> >
>> > I'm using this diff() function.
>> >
>> > This 'diff()' function finds the difference between two adjoining
>> > entries and it applies itself to the whole list so that in an instant
>> > I can have a list of differences between any two adjoining.
>> >
>> > Then I can have a list of differences between any two with any
>> > specified gap - 'lag' it is called.
>> > Using the same function.
>> >
>> > Now I have them and do that.  Then I add them together to find the
>> 'lastone'
>> > which is the total difference for the period.
>> >
>> >
>> > Now here's the point:  that covers a period of two timespans, months,
>> they are.
>> >
>> >  if I want to cover a span of 24 months, say, then I would have to
>> > write this
>> > diff() function 24 times.
>> >
>> >  what I'm doing is finding the difference between the starting point
>> > and every other point and then adding them all together.  bit like
>> > finding the area beneath the curve maybe.
>> >
>> >  And that's what I want to do.
>> >
>> >  :)
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > ----- Original Message -----
>> > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > To: arthur brogard <abrogard at yahoo.com>
>> > Cc: r-help at r-project.org
>> > Sent: Saturday, 24 December 2016, 15:34
>> > Subject: Re: [R] Is there a funct to sum differences?
>> >
>> > You need to "reply all" so other people can help as well, and others
>> > can learn from your questions.
>> >
>> > I am still puzzled by how you expect to compute "finalone". If you had
>> > supplied numbers other than all 5's it might have been easier to
>> > figure out what is going on.
>> >
>> > What is your purpose in performing this calculation?
>> >
>> > #### reproducible code
>> > rates <- read.table( text =
>> > "Date          Int
>> > Jan-1959        5
>> > Feb-1959        5
>> > Mar-1959        5
>> > Apr-1959        5
>> > May-1959        5
>> > Jun-1959        5
>> > Jul-1959        5
>> > Aug-1959        5
>> > Sep-1959        5
>> > Oct-1959        5
>> > Nov-1959        5
>> > ", header = TRUE, colClasses = c( "character", "numeric" ) )
>> >
>> > #your code
>> > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>> > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>> > rates$nextone)/6.5*1000 # I doubt there is a ready-built function that
>> > knows you want to # divide by 6.5 or multiply by 1000
>> >
>> > # form a vector from positions 2:11 and append NA)
>> > rates$experiment1 <- rates$Int + c( rates$Int[ -1 ], NA ) # numbers
>> > that are not all the same
>> > rates$Int2 <- (1:11)^2
>> > rates$experiment2 <- rates$Int2 + c( rates$Int2[ -1 ], NA )
>> >
>> > # dput(rates)
>> > result <- structure(list(Date = c("Jan-1959", "Feb-1959", "Mar-1959",
>> > "Apr- 1959", "May-1959", "Jun-1959", "Jul-1959", "Aug-1959",
>> > "Sep-1959", "Oct- 1959", "Nov-1959"), Int = c(5, 5, 5, 5, 5, 5, 5, 5,
>> > 5, 5, 5), thisone = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA), nextone =
>> > c(0, 0, 0, 0, 0, 0, 0, 0, 0, NA, NA), lastone = c(0, 0, 0, 0, 0, 0, 0,
>> > 0, 0, NA, NA), Int2 = c(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121),
>> > experiment1 = c(10, 10, 10, 10, 10, 10, 10, 10, 10, 10, NA),
>> > experiment2 = c(5, 13, 25, 41, 61, 85, 113, 145, 181, 221, NA)),
>> > .Names = c("Date", "Int", "thisone", "nextone", "lastone", "Int2",
>> > "experiment1", "experiment2"), row.names = c(NA, -11L), class =
>> > "data.frame")
>> >
>> > On Sat, 24 Dec 2016, arthur brogard wrote:
>> >
>> > >
>> > >
>> > > Yes, sure, thanks for your interest.  I apologise for not submitting
>> > > in the
>> > correct manner.  I'll learn (I hope).
>> > >
>> > > Here's the source - a spreadsheet with just two columns, date and
>> 'Int'.
>> > >
>> > >
>> > > Date    Int
>> > > Jan-1959    5
>> > > Feb-1959    5
>> > > Mar-1959    5
>> > > Apr-1959    5
>> > > May-1959    5
>> > > Jun-1959    5
>> > > Jul-1959    5
>> > > Aug-1959    5
>> > > Sep-1959    5
>> > > Oct-1959    5
>> > > Nov-1959    5
>> > >
>> > >
>> > > After processing it becomes this:
>> > >
>> > >
>> > >> rates
>> > > Date   Int thisone nextone     lastone finalone
>> > > 1   1959-01-01  5.00    0.00    0.00    0.000000       10
>> > > 2   1959-02-01  5.00    0.00    0.00    0.000000       10
>> > > 3   1959-03-01  5.00    0.00    0.00    0.000000       10
>> > > 4   1959-04-01  5.00    0.00    0.00    0.000000       10
>> > > 5   1959-05-01  5.00    0.00    0.00    0.000000       10
>> > > 6   1959-06-01  5.00    0.00    0.00    0.000000       10
>> > >
>> > > The one long column I'm referring to is the 'Int' column which R has
>> imported.
>> > >
>> > > The actual code is:
>> > >
>> > >
>> > > rates <- read.csv("Rates2.csv",header =
>> > > TRUE,colClasses=c("character","numeric"))
>> > >
>> > > sapply(rates,class)
>> > >
>> > > rates$Date <- strptime(paste0("1-", rates$Date), format="%d-%b-%Y",
>> > > tz="UTC")
>> > >
>> > >
>> > > rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>> > > c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>> > > rates$nextone)/6.5*1000
>> > >
>> > >
>> > > rates
>> > >
>> > >
>> > >
>> > > ab
>> > >
>> > >
>> > >
>> > > ----- Original Message -----
>> > > From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>> > > To: arthur brogard <abrogard at yahoo.com>; arthur brogard via R-help
>> > > <r-help at r-project.org>; "r-help at r-project.org"
>> > > <r-help at r-project.org>
>> > > Sent: Saturday, 24 December 2016, 13:25
>> > > Subject: Re: [R] Is there a funct to sum differences?
>> > >
>> > > Could you make your example reproducible? That is, include some
>> > > sample
>> > input and output. You talk about a column of numbers and then you seem
>> > to work with named lists and I can't reconcile your words with the
>> code I see.
>> > > --
>> > > Sent from my phone. Please excuse my brevity.
>> > >
>> > >
>> > > On December 23, 2016 3:40:18 PM PST, arthur brogard via R-help
>> > > <r-help at r-
>> > project.org> wrote:
>> > >> I've been looking but I can't find a function to sum difference.
>> > >>
>> > >> I have this code:
>> > >>
>> > >>
>> > >> rates$thisone <- c(diff(rates$Int), NA) rates$nextone <-
>> > >> c(diff(rates$Int, lag=2), NA, NA) rates$lastone <- (rates$thisone +
>> > >> rates$nextone)
>> > >>
>> > >>
>> > >> It is looking down one long column of numbers.
>> > >>
>> > >> It sums the difference between the first two and then between the
>> > >> first and third and so on.
>> > >>
>> > >> Can it be made to automatically sum the difference between the
>> > >> first and subsequent to the end of a list?
>> > >>
>> > >> ______________________________________________
>> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >> https://stat.ethz.ch/mailman/listinfo/r-help
>> > >> PLEASE do read the posting guide
>> > >> http://www.R-project.org/posting-guide.html
>> > >> and provide commented, minimal, self-contained, reproducible code.
>> > >
>> >
>> > ----------------------------------------------------------------------
>> -----
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>> >                                        Live:   OO#.. Dead: OO#..
>> Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k

>>
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Dec 25 23:34:09 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Dec 2016 14:34:09 -0800
Subject: [R] Download data from Internet contained in a Zip file
In-Reply-To: <CA+dpOJkMd9KXsfxyVePziaK25j7r-y_CNb5CsErd0FbECpwvQg@mail.gmail.com>
References: <CA+dpOJn3OzpdGkvjEJkNMacMPj374tSi0UKEFkAxDaAfJ+f3zg@mail.gmail.com>
	<C273D081-1091-42EC-B3ED-BB961BA2F452@dcn.davis.ca.us>
	<CA+dpOJkMd9KXsfxyVePziaK25j7r-y_CNb5CsErd0FbECpwvQg@mail.gmail.com>
Message-ID: <C669329C-A73B-4258-89BA-872A6A0E965E@dcn.davis.ca.us>

The fact that you are downloading a zip is irrelevant. The "s" in "https" means you are trying to download using the secure http protocol. I don't use a Mac, but Google finds https://stat.ethz.ch/pipermail/r-sig-mac/2011-July/008395.html when I search on "r unsupported url scheme mac osx" which says you need to use different options (but that post is old so the options may be different now). In any case, you should be posting this on R-sig-mac because the answer depends on both your OS and version of R.
-- 
Sent from my phone. Please excuse my brevity.

On December 25, 2016 1:50:00 PM PST, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>Hi Jeff, I dont think I understood all that you said. I am using Mac
>OS X 10.7.5 as OS
>
>On Mon, Dec 26, 2016 at 3:10 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>> This has nothing to do with the fact that you are dealing with a zip
>file and everything to do with the "s" in "https", and all the
>solutions I have seen involve knowing what operating system you are
>using. I highly recommend that you study what Google has to say when
>you include that detail and leave out the zip keyword.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On December 25, 2016 12:32:16 PM PST, Christofer Bogaso
><bogaso.christofer at gmail.com> wrote:
>>>Hi again,
>>>
>>>I was following the instruction available in
>>>"http://stackoverflow.com/questions/3053833/using-r-to-download-zipped-data-file-extract-and-import-data"
>>>to download data from Internet contained in a zip file from the
>>>address :
>>>
>>>https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip
>>>
>>>However when I tried to follow the instruction I am facing below
>error
>>>:
>>>
>>>> temp <- tempfile()
>>>>
>>>download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",temp)
>>>Error in
>>>download.file("https://npscra.nsdl.co.in/download.php?path=download/&filename=NAV_File_23122016.zip",
>>> :
>>>  unsupported URL scheme
>>>
>>>Can someone here please tell me what went wrong in above?
>>>
>>>Highly appreciate your feedback.
>>>
>>>Thanks for your time.
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From amit1983_rathee at rediffmail.com  Sat Dec 24 16:53:40 2016
From: amit1983_rathee at rediffmail.com (amit rathee)
Date: 24 Dec 2016 15:53:40 -0000
Subject: [R] =?utf-8?q?Urgent_Help?=
Message-ID: <20161224155340.23043.qmail@f4mail-235-225.rediffmail.com>

I am trying to perform hierarchical clustering and evaluating it using ClusterClit Package, my code is attached.my problem is that in each iteration even if my data is different in extCriteria() function but it is giving same result every time.kindly helpA Great thanks in advance......AMIT RATHEE

From heather.h.kettrey at vanderbilt.edu  Mon Dec 26 05:36:00 2016
From: heather.h.kettrey at vanderbilt.edu (Heather Kettrey)
Date: Sun, 25 Dec 2016 22:36:00 -0600
Subject: [R] Factor Analysis fit statistics from zelig() model =
 "factor.bayes" (executes mcmcfactanal() function)
Message-ID: <CAGcnpaQaTu8tvrDVrEhhmT+0eeNo9Qdp1Nj98175GCvs3WJ+LA@mail.gmail.com>

Hello,

I am running a factor analysis with a multiply imputed dataset in zelig
(specifying model = factor.bayes). I cannot find a way to get fit
statistics for the specified model (a 2-factor model in this particular
analysis).

The summary() function only returns lambda (factor loadings) and psi
(uniqueness). Does anyone know how to return fit statistics with this
function? The zelig() function seems to be executing mcmcfactanal() from
the MCMCpack package - so if anyone has had success in outputting fit
statistics with mcmcfactanal() the same code should work here. I would
greatly appreciate any help.

Thanks and Merry Christmas.

Heather

-- 
Heather Hensman Kettrey, PhD
Research Associate, Peabody Research Institute (PRI)
Senior Researcher, Meta-Analysis Center at PRI
Vanderbilt University

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Dec 26 05:48:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Dec 2016 20:48:53 -0800
Subject: [R] Urgent Help
In-Reply-To: <20161224155340.23043.qmail@f4mail-235-225.rediffmail.com>
References: <20161224155340.23043.qmail@f4mail-235-225.rediffmail.com>
Message-ID: <CAGxFJbTjFd0pyR3KRcQ7MvA26yNqJFS4QyRbUjL6tjBfDmTyAg@mail.gmail.com>

You are unlikely to get any help if you do not read and follow the
posting guide below.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 24, 2016 at 7:53 AM, amit rathee
<amit1983_rathee at rediffmail.com> wrote:
> I am trying to perform hierarchical clustering and evaluating it using ClusterClit Package, my code is attached.my problem is that in each iteration even if my data is different in extCriteria() function but it is giving same result every time.kindly helpA Great thanks in advance......AMIT RATHEE
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at yahoo.ca  Mon Dec 26 11:50:50 2016
From: jrkrideau at yahoo.ca (John Kane)
Date: Mon, 26 Dec 2016 10:50:50 +0000 (UTC)
Subject: [R] Urgent Help
In-Reply-To: <CAGxFJbTjFd0pyR3KRcQ7MvA26yNqJFS4QyRbUjL6tjBfDmTyAg@mail.gmail.com>
References: <20161224155340.23043.qmail@f4mail-235-225.rediffmail.com>
	<CAGxFJbTjFd0pyR3KRcQ7MvA26yNqJFS4QyRbUjL6tjBfDmTyAg@mail.gmail.com>
Message-ID: <2092791588.1925926.1482749450489@mail.yahoo.com>

No data or code.? Your attachments did not arrive.? See http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
for some suggestions on how to submit a question with data and sample code.

?
 

    On Sunday, December 25, 2016 11:50 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
 

 You are unlikely to get any help if you do not read and follow the
posting guide below.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 24, 2016 at 7:53 AM, amit rathee
<amit1983_rathee at rediffmail.com> wrote:
> I am trying to perform hierarchical clustering and evaluating it using ClusterClit Package, my code is attached.my problem is that in each iteration even if my data is different in extCriteria() function but it is giving same result every time.kindly helpA Great thanks in advance......AMIT RATHEE
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From mrguilfoyle at gmail.com  Mon Dec 26 12:16:52 2016
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Mon, 26 Dec 2016 11:16:52 +0000
Subject: [R] gamm problem/error fitting smooth by factor
Message-ID: <A5EFDBF8-5599-4F67-9417-14C0ADDEFA5C@gmail.com>

I have a (unbalanced) dataset of time series collected across several subjects (n~500, ~60000 observations).  I would like to model the overall smooth time trend of a variable and how this trend differs by various categorical factors, with the subject as a random effect.

My baseline model 

m1 = gamm(v1 ~ s(time), random=list(id=~1+time), data=dat)

shows that time is a significant term.

I have then tried to run this model:

m2 = gamm(v1 ~ s(time)+s(time, by=fac1), random=list(id=~1+time), data=dat)

where fac1 is a binary factor.

My intuitive understanding of this is that the first smooth term will capture the overall major trend common to both groups of fac1 and the second smooth will model the deviation from this mean trend for the fac1==1 subgroup.  However, I get the error:

 Error in MEestimate(lmeSt, grps) : 
  Singularity in backsolve at level 0, block 1 

I've tried other models to isolate the problem but get the exact same error

m3 = gamm(v1 ~ s(time)+s(time, by=fac1), random=list(id=~1), data=dat)   #remove the time random effect
m4 = gamm(v1 ~ fac1+s(time)+s(time, by=fac1), random=list(id=~1+time), data=dat)   #have the factor as a main effect also

I'm not sure if the whole notion of what I'm trying to do is wrong-headed or if I need to adjust some parameters to get the model (m2) to fit.

Thanks


From bgunter.4567 at gmail.com  Mon Dec 26 19:24:24 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Dec 2016 10:24:24 -0800
Subject: [R] gamm problem/error fitting smooth by factor
In-Reply-To: <A5EFDBF8-5599-4F67-9417-14C0ADDEFA5C@gmail.com>
References: <A5EFDBF8-5599-4F67-9417-14C0ADDEFA5C@gmail.com>
Message-ID: <CAGxFJbSc8xVTqsYoRvgq_CPL_Y3GrbRxisKRns5260dFd2T0cQ@mail.gmail.com>

You will likely do better posting this on the r-sig-mixed-models
list. This list is for general R programming issues, whereas that one
is specifically concerned with mixed effects modeling in R, which is
the focus of your post.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Dec 26, 2016 at 3:16 AM, Mathew Guilfoyle <mrguilfoyle at gmail.com> wrote:
> I have a (unbalanced) dataset of time series collected across several subjects (n~500, ~60000 observations).  I would like to model the overall smooth time trend of a variable and how this trend differs by various categorical factors, with the subject as a random effect.
>
> My baseline model
>
> m1 = gamm(v1 ~ s(time), random=list(id=~1+time), data=dat)
>
> shows that time is a significant term.
>
> I have then tried to run this model:
>
> m2 = gamm(v1 ~ s(time)+s(time, by=fac1), random=list(id=~1+time), data=dat)
>
> where fac1 is a binary factor.
>
> My intuitive understanding of this is that the first smooth term will capture the overall major trend common to both groups of fac1 and the second smooth will model the deviation from this mean trend for the fac1==1 subgroup.  However, I get the error:
>
>  Error in MEestimate(lmeSt, grps) :
>   Singularity in backsolve at level 0, block 1
>
> I've tried other models to isolate the problem but get the exact same error
>
> m3 = gamm(v1 ~ s(time)+s(time, by=fac1), random=list(id=~1), data=dat)   #remove the time random effect
> m4 = gamm(v1 ~ fac1+s(time)+s(time, by=fac1), random=list(id=~1+time), data=dat)   #have the factor as a main effect also
>
> I'm not sure if the whole notion of what I'm trying to do is wrong-headed or if I need to adjust some parameters to get the model (m2) to fit.
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From janka.vanschoenwinkel at uhasselt.be  Tue Dec 27 11:20:17 2016
From: janka.vanschoenwinkel at uhasselt.be (Janka VANSCHOENWINKEL)
Date: Tue, 27 Dec 2016 11:20:17 +0100
Subject: [R] gamlss to predict dependent variables in [0,
	1] interval (fractional variable)
Message-ID: <CAHymutJvmNbpByj5RQ=wG_Je87y0hjJ4qVSuN+YJ74TtLqYQhA@mail.gmail.com>

Dear R-users,

I want to model a proportional variable bounded by [0,1]  (the % of land
fertilized). A high percentage of the data contains 0s (60%), a smaller
percentage contains 1s (10%), and all the rest falls in between.


I want to compare different models with each other to see their
performance, however the model I am currently looking at is a zero-one
inflated beta model. I am using the R package gamlss for this.


However, I am having some troubles with the quite technical documentation
of the gamlss package and I don?t seem to find an answer to my questions
below:

1)      model

The model below should model 3 submodels: one part that models the
probability of having y=0 versus y>0 (nu.formula), one part that models the
probability of having y=1 versus y<1 (tau.formula) and a final part that
models all the values in between.


gam<-gamlss(proportion~x1+x2,nu.formula=~ x1+x2,tau.formula=~ x1+x2,
family= BEINF, data=Alldata)


This is okay I think.

2)      prediction

I would like to know now what is the predicted probability of an
observation to have y = 0 or y = 1. I predicted the probability of y = 0
with the code below, however I get values that go far beyond the [0-1]
interval. Therefore, they cannot be probabilities since these have to be in
the interval [0,1].


Alldata$fit_proportion_0<-predict(gam, what="nu", type='response')

summary(Alldata$fit_proportion_0)


Could somebody explain me how to obtain the correct probabilities because
the code above does not seem to work. I think the answer to my problem can
be find on section 10.8.2, page 215 of the following link (
http://www.gamlss.org/wp-content/uploads/2013/01/book-2010-Athens1.pdf). I
think it says that the predict function that I use gives another answer,
that I have to use in a certain formula to find the real probabilities. But
I am not sure how to make this work?



3)      interpretation

Also, to be sure, I would like to know how to interpret the different
coefficients of the three models and how to use the coefficients separately
to determine. For the Nu and Tau models these should be interpreted as
log-odd ratios, right? And the model in the middle is just a normal
log-model, right?

4)      validity

Finally, I do not find a lot of information on how to correctly test the
validity of this model? Do you test that for all three subparts separately?
Or is there a test to model the entire model at once?



Thank you very much for your help! I am aware of the fact that some of this
questions ar very basic.


Janka

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Dec 27 15:47:12 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 27 Dec 2016 14:47:12 +0000
Subject: [R] offset in nlme
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB81B@SRVEXCHCM301.precheza.cz>

Dear all

I would like to fit SSasymp model to some data by nlme. I did not find any clue how to set one of parameters to fixed constant value (R0=0).

One suitable way could be to use SSlogis as it has one parameter zero, however it is not correct AFAIK logistics is defined from -Inf to Inf and my x value is time, starting from 0.

The only option I found is to define my own growth function which is constrained by some fixed starting point. Does anybody know other way around? Like persuading nlme not optimize R0 and be happy with the value set in the function call.

something like

nlsList(rutrtg ~ SSasymp(doba, Asym, R0, lrc), data=rutil.g, start=c(Asym=100, R0= 10, lrc=-2), offset=c(R0=10))

which obviously does not work.

I could put some data but it is more a matter of nlme or other R functions then real data.

Looking forward to some answer.
Happy New year 2017

Petr Pikal

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Tue Dec 27 16:21:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 27 Dec 2016 07:21:29 -0800
Subject: [R] offset in nlme
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB81B@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB81B@SRVEXCHCM301.precheza.cz>
Message-ID: <9B5B9B8B-5594-4D4D-808E-DA37436FCAEE@dcn.davis.ca.us>

Not reproducible. Tsk!

I really don't know what you are taking about,  but some ideas are:

mySSasymp <- function( doba, Asym, lrc ) {
  SSasymp(doba, Asym, 0, lrc)
}

Another idea is to use log( time ) rather than time. 
-- 
Sent from my phone. Please excuse my brevity.

On December 27, 2016 6:47:12 AM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Dear all
>
>I would like to fit SSasymp model to some data by nlme. I did not find
>any clue how to set one of parameters to fixed constant value (R0=0).
>
>One suitable way could be to use SSlogis as it has one parameter zero,
>however it is not correct AFAIK logistics is defined from -Inf to Inf
>and my x value is time, starting from 0.
>
>The only option I found is to define my own growth function which is
>constrained by some fixed starting point. Does anybody know other way
>around? Like persuading nlme not optimize R0 and be happy with the
>value set in the function call.
>
>something like
>
>nlsList(rutrtg ~ SSasymp(doba, Asym, R0, lrc), data=rutil.g,
>start=c(Asym=100, R0= 10, lrc=-2), offset=c(R0=10))
>
>which obviously does not work.
>
>I could put some data but it is more a matter of nlme or other R
>functions then real data.
>
>Looking forward to some answer.
>Happy New year 2017
>
>Petr Pikal
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From cryan at binghamton.edu  Tue Dec 27 19:19:12 2016
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Tue, 27 Dec 2016 13:19:12 -0500
Subject: [R] trouble with starting date in sts and disProg objects in the
 surveillance package
Message-ID: <CAM+rpYk6rimrz8VbyjN23QaKky_L3HNHOtvfxtpsOqXN2NQOQw@mail.gmail.com>

I create a data frame, then, using package surveillance version 1.3, I
convert it to a surveillance time series (sts) object and then to a disProg
object.  But in the plot of the disProg object, the dates seem to be
mislabelled?

Grateful for any advice.

--Chris Ryan
Broome County Health Department
Binghamton, NY

Below is MWE to reproduce the behavior

library(surveillance)
ll <- data.frame(onset = sample(1:200, size = 400, replace = TRUE))
## let the dates begin in mid-September 2012
ll$onset.date <- as.Date("2012-09-15") + ll$onset
dd.sts <- linelist2sts(ll, dateCol="onset.date", aggregate.by="1 week")
## the below command produces a plot where the horizontal (time) axis
begins around mid-September 2012, as expected
plot(dd.sts)
## now convert the sts object to a disProg object
dd.dp <- sts2disProg(dd.sts)
## the below commands shows the start date of the disProg object seems as
expected
str(dd.dp)
dd.dp$start
## But when I plot the disProg object, the horizontal axis is labelled
differently.
## It seems to begin back in 2011 or before
plot(dd.dp)

## here is my sessionInfo
R version 3.3.1 (2016-06-21)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252
LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] surveillance_1.13.0 polyCub_0.5-2       xtable_1.8-2
sp_1.2-4

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.8     lattice_0.20-34 deldir_0.1-12   MASS_7.3-45
grid_3.3.1      nlme_3.1-128
 [7] tensor_1.5      spatstat_1.48-0 goftest_1.0-3   rpart_4.1-10
Matrix_1.2-7.1  tools_3.3.1
[13] polyclip_1.5-6  abind_1.4-5     mgcv_1.8-16

	[[alternative HTML version deleted]]


From amit1983_rathee at rediffmail.com  Tue Dec 27 06:09:17 2016
From: amit1983_rathee at rediffmail.com (amit rathee)
Date: 27 Dec 2016 05:09:17 -0000
Subject: [R] =?utf-8?q?Fw=3A_Urgent_help?=
Message-ID: <1482769110.S.12286.24021.f4mail-235-96.rediffmail.com.1482815357.11550@webmail.rediffmail.com>

I am trying to perform hierarchical clustering and evaluating it using &quot;ClusterCrit&quot; Package, specially interested in precision and recall for multi class problem, my code is attached.my problem is that in each iteration even if my data is different in extCriteria() (used to evaluate clustering based on various external criteria&#39;s) function but it is giving same result every time.kindly helpthe program relies on data from ClassCouplingData.txt file and it is read first as .csv file containing 32 by 32 data and it contains only numeric data &amp; not stringA Great thanks in advance......AMIT RATHEE&nbsp;
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ClassCouplingData.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161227/6b0a7e95/attachment.txt>

From lordpreetam at gmail.com  Tue Dec 27 11:22:16 2016
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 27 Dec 2016 15:52:16 +0530
Subject: [R] Restricted Simulation from GPD & Normal Distributions
In-Reply-To: <CAHVFrXHM4u4ZS0=Ld-XpJftuzwf0X6Rdqf8h_ny1Kf8deK=JzA@mail.gmail.com>
References: <CAHVFrXHM4u4ZS0=Ld-XpJftuzwf0X6Rdqf8h_ny1Kf8deK=JzA@mail.gmail.com>
Message-ID: <CAHVFrXEovrb=zU2Ue4DRs0EP8DpOtz1SMRY3daP0_cnrBSAUAA@mail.gmail.com>

Hi R-users,
(fixing some typos in my previous mail)

I have data on one equity-related variable X, denoted by
x1,x2,x3,.......x1000 which has been ordered as x1<x2<....<x1000. I have
identified the upper and lower 5 percentiles, i.e. x50 and x950
respectively. Based on some analysis, I have inferred that three different
density functions fit the three parts of the data decently well,

   - f1 fits the data for all x<x50 ----- 50 observations
   - f2 fits the data well for all x50<x<x950 ------- 900 observations
   - f3 fits the data well for all x>x950------ 50 obsrvations

Idea is to simulate 50 new observations from f1 *restricted to (- infinity,
x50 ]*, 50 new observations from f3 *restricted to  ( x950, infinity )* and
900 new observations from f2 *restricted between (x50, x950 ]*. So total
number of observations in the simulated data = 1000 as before.

For the example I am working with, f1 and f3 are GPD ( Generalized Pareto
Distribution ) while f2 is Normal with some parameters.

I want to write a function which will take as inputs

   - the entire data (of size 1000)
   - the cut-off points x50 and x950
   - the 3 distributions (along with their parameters)
   - the number of data points from each of the 3 segments (50, 900, 50 in
   this example)
   - note that f1, f2 and f3 need to be properly restricted to the
   corresponding intervals (mentioned in Bold in the description above)

and will output the simulated data with original sample size (here, 1000).

I'll really appreciate any help writing this function. If anything else is
required, please let me know.

On Tue, Dec 27, 2016 at 3:46 PM, Preetam Pal <lordpreetam at gmail.com> wrote:

> HI R-users,
>
> I have data on one equity-related variable X, denoted by
> x1,x2,x3,.......x1000 which has been ordered as x1<x2<....<x1000. I have
> identified the upper and lower 5 percentiles, i.e. x50 and x950
> respectively. Based on some analysis, I have inferred that three different
> density functions fit the three parts of the data decently well,
>
>    - fi fits the data for all x<x50 ----- 50 observations
>    - f2 fits the data well for all x50<x<x950 ------- 900 observations
>    - f3 fits the data well for all x>x950------ 50 obsrvations
>
> Idea is to simulate 50 new observations from f1 *restricted to (-
> infinity, x50 ]*, 50 new observations from f3 *restricted to ( x950,
> infinity )* and 900 new observations from f2 *restricted between (x50,
> x950 ]*. So total number of observations in the simulated data = 1000 as
> before.
>
> For the example I am working with, f1 and f2 are GPD ( Generalized Pareto
> Distribution ) while f2 is Normal with some parameters.
>
> I want to write a function which will take as inputs
>
>    - the entire data (of size 1000)
>    - the cut-off points x50 and x950
>    - the 3 distributions (along with their parameters)
>    - the number of data points from each of the 3 segments (50, 900, 50
>    in this example)
>    - note that f1, f2 and f3 need to be properly restricted to the
>    corresponding intervals (mentioned in Bold in the description above)
>
> and will output the simulated data with original sample size (here, 1000).
>
> I'll really appreciate any help writing this function. If anything else is
> required, please let me know.
>
> --
> Preetam Pal
> (+91)-9432212774
> M-Stat 2nd Year,                                             Room No. N-114
> Statistics Division,                                           C.V.Raman
> Hall
> Indian Statistical Institute,                                 B.H.O.S.
> Kolkata.
>



-- 
Preetam Pal
(+91)-9432212774
M-Stat 2nd Year,                                             Room No. N-114
Statistics Division,                                           C.V.Raman
Hall
Indian Statistical Institute,                                 B.H.O.S.
Kolkata.

	[[alternative HTML version deleted]]


From radhikasundar520 at gmail.com  Tue Dec 27 15:52:30 2016
From: radhikasundar520 at gmail.com (radhika sundar)
Date: Tue, 27 Dec 2016 20:22:30 +0530
Subject: [R] Bayesian cox model: spBayesSurv package
Message-ID: <CAMj135NbmJSm+Eyw0vD_GH3E_=O=WgAkhAos+C=m_m2PSWFZwQ@mail.gmail.com>

I am going through R's function indeptCoxph in the spBayesSurv package
which fits a bayesian Cox model. I am confused by some of the input
parameters to this function.

What is the role of the "prediction" input parameter? Should it not only
contain the predictor covariates? In the R code example, the authors have
included a vector "s" which was used to initially simulate the survival
times data in their example as well as the predictors. I'm not sure what
this "s" is.

Given that my data is just a set of survival times between 0 and 100, along
with censored (yes/no) information, how would I use this function and how
should I handle the input "s"?


Thanks for any help!

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Dec 27 21:41:58 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 27 Dec 2016 12:41:58 -0800
Subject: [R] Bayesian cox model: spBayesSurv package
In-Reply-To: <CAMj135NbmJSm+Eyw0vD_GH3E_=O=WgAkhAos+C=m_m2PSWFZwQ@mail.gmail.com>
References: <CAMj135NbmJSm+Eyw0vD_GH3E_=O=WgAkhAos+C=m_m2PSWFZwQ@mail.gmail.com>
Message-ID: <83F4C518-778D-4E57-93E4-F1D139E97FB7@comcast.net>

Cross posting is deprecated on rhelp but if you do so, please at least post a link to the stackoverflow address for the duplicate question.

Sent from my iPhone

> On Dec 27, 2016, at 6:52 AM, radhika sundar <radhikasundar520 at gmail.com> wrote:
> 
> I am going through R's function indeptCoxph in the spBayesSurv package
> which fits a bayesian Cox model. I am confused by some of the input
> parameters to this function.
> 
> What is the role of the "prediction" input parameter? Should it not only
> contain the predictor covariates? In the R code example, the authors have
> included a vector "s" which was used to initially simulate the survival
> times data in their example as well as the predictors. I'm not sure what
> this "s" is.
> 
> Given that my data is just a set of survival times between 0 and 100, along
> with censored (yes/no) information, how would I use this function and how
> should I handle the input "s"?
> 
> 
> Thanks for any help!
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Wed Dec 28 00:31:27 2016
From: msharp at txbiomed.org (Mark Sharp)
Date: Tue, 27 Dec 2016 23:31:27 +0000
Subject: [R] Urgent help
In-Reply-To: <1482769110.S.12286.24021.f4mail-235-96.rediffmail.com.1482815357.11550@webmail.rediffmail.com>
References: <1482769110.S.12286.24021.f4mail-235-96.rediffmail.com.1482815357.11550@webmail.rediffmail.com>
Message-ID: <408287CF-5C06-4C4C-BBB0-9D940195E144@txbiomed.org>

Please note that your message should be plain text and any attachments must be text and have a .txt extension. Your attached code was apparently removed because it did not have an extension of .txt.

It is best to include your code within the body of the message.

Mark
R. Mark Sharp, Ph.D.
Director of Data Science Core
Southwest National Primate Research Center
Texas Biomedical Research Institute
P.O. Box 760549
San Antonio, TX 78245-0549
Telephone: (210)258-9476
e-mail: msharp at TxBiomed.org









> On Dec 26, 2016, at 11:09 PM, amit rathee <amit1983_rathee at rediffmail.com> wrote:
>
> I am trying to perform hierarchical clustering and evaluating it using &quot;ClusterCrit&quot; Package, specially interested in precision and recall for multi class problem, my code is attached.my problem is that in each iteration even if my data is different in extCriteria() (used to evaluate clustering based on various external criteria&#39;s) function but it is giving same result every time.kindly helpthe program relies on data from ClassCouplingData.txt file and it is read first as .csv file containing 32 by 32 data and it contains only numeric data &amp; not stringA Great thanks in advance......AMIT RATHEE&nbsp;<ClassCouplingData.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

CONFIDENTIALITY NOTICE: This e-mail and any files and/or...{{dropped:10}}


From dwinsemius at comcast.net  Wed Dec 28 01:21:00 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 27 Dec 2016 16:21:00 -0800
Subject: [R] Fw: Urgent help
In-Reply-To: <1482769110.S.12286.24021.f4mail-235-96.rediffmail.com.1482815357.11550@webmail.rediffmail.com>
References: <1482769110.S.12286.24021.f4mail-235-96.rediffmail.com.1482815357.11550@webmail.rediffmail.com>
Message-ID: <5F13C0EE-1DA3-458F-8A20-D1CD5E9078A9@comcast.net>


> On Dec 26, 2016, at 9:09 PM, amit rathee <amit1983_rathee at rediffmail.com> wrote:
> 
> <ClassCouplingData.txt>

The text file you attached has no commas. Perhaps the separators are tabs and you really need to use `read.delim` instead of `read.csv`.

David Winsemius
Alameda, CA, USA


From amit1983_rathee at rediffmail.com  Wed Dec 28 04:28:52 2016
From: amit1983_rathee at rediffmail.com (amit rathee)
Date: 28 Dec 2016 03:28:52 -0000
Subject: [R] =?utf-8?q?Need_Help=2C_Unable_to_find_the_problem_in_R_Script?=
Message-ID: <20161228032852.24673.qmail@f6mail-235-207.rediffmail.com>

R/Sir,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i am trying to find precision and recall value for multi class software clustering problem using package &quot;ClusterCrit&quot;i have attached my source code &quot;Clustering.txt&quot; and input files &quot;ClassCoupling.txt&quot; &amp; &quot;JUnitGoldStandard&quot;in my script for different combination of clustering i am getting same value of precision &amp; recall, which i think should not be?Kindly helpThanks in advanceAMIT RATHEEResearch Scholar
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Clustering.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161228/d2a369b9/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ClassCouplingData.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161228/d2a369b9/attachment-0001.txt>

From petr.pikal at precheza.cz  Wed Dec 28 08:39:29 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 28 Dec 2016 07:39:29 +0000
Subject: [R] offset in nlme
In-Reply-To: <9B5B9B8B-5594-4D4D-808E-DA37436FCAEE@dcn.davis.ca.us>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB81B@SRVEXCHCM301.precheza.cz>
	<9B5B9B8B-5594-4D4D-808E-DA37436FCAEE@dcn.davis.ca.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB895@SRVEXCHCM301.precheza.cz>

Hi Jeff.

Yes, if it had been reproducible I would not post it as I had known solution myself. (Uff, I hope I used this conditional clause correctly).

OTOH your suggestion works and seems to arrive to desired result even that you said you do not know what I am talking about. R (and this smart community) sometimes surprise me even after quite a long time experience.

Thanks.
Petr

> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, December 27, 2016 4:21 PM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-
> project.org>
> Subject: Re: [R] offset in nlme
>
> Not reproducible. Tsk!
>
> I really don't know what you are taking about,  but some ideas are:
>
> mySSasymp <- function( doba, Asym, lrc ) {
>   SSasymp(doba, Asym, 0, lrc)
> }
>
> Another idea is to use log( time ) rather than time.
> --
> Sent from my phone. Please excuse my brevity.
>
> On December 27, 2016 6:47:12 AM PST, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >Dear all
> >
> >I would like to fit SSasymp model to some data by nlme. I did not find
> >any clue how to set one of parameters to fixed constant value (R0=0).
> >
> >One suitable way could be to use SSlogis as it has one parameter zero,
> >however it is not correct AFAIK logistics is defined from -Inf to Inf
> >and my x value is time, starting from 0.
> >
> >The only option I found is to define my own growth function which is
> >constrained by some fixed starting point. Does anybody know other way
> >around? Like persuading nlme not optimize R0 and be happy with the
> >value set in the function call.
> >
> >something like
> >
> >nlsList(rutrtg ~ SSasymp(doba, Asym, R0, lrc), data=rutil.g,
> >start=c(Asym=100, R0= 10, lrc=-2), offset=c(R0=10))
> >
> >which obviously does not work.
> >
> >I could put some data but it is more a matter of nlme or other R
> >functions then real data.
> >
> >Looking forward to some answer.
> >Happy New year 2017
> >
> >Petr Pikal
> >
> >________________________________
> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> >ur?eny pouze jeho adres?t?m.
> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> >kopie vyma?te ze sv?ho syst?mu.
> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> >ze strany p??jemce s dodatkem ?i odchylkou.
> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> >zn?m?.
> >
> >This e-mail and any documents attached to it may be confidential and
> >are intended only for its intended recipients.
> >If you received this e-mail by mistake, please immediately inform its
> >sender. Delete the contents of this e-mail with all attachments and its
> >copies from your system.
> >If you are not the intended recipient of this e-mail, you are not
> >authorized to use, disseminate, copy or disclose this e-mail in any
> >manner.
> >The sender of this e-mail shall not be liable for any possible damage
> >caused by modifications of the e-mail or by delay with transfer of the
> >email.
> >
> >In case that this e-mail forms part of business dealings:
> >- the sender reserves the right to end negotiations about entering into
> >a contract in any time, for any reason, and without stating any
> >reasoning.
> >- if the e-mail contains an offer, the recipient is entitled to
> >immediately accept such offer; The sender of this e-mail (offer)
> >excludes any acceptance of the offer on the part of the recipient
> >containing any amendment or variation.
> >- the sender insists on that the respective contract is concluded only
> >upon an express mutual agreement on all its aspects.
> >- the sender of this e-mail informs that he/she is not authorized to
> >enter into any contracts on behalf of the company except for cases in
> >which he/she is expressly authorized to do so in writing, and such
> >authorization or power of attorney is submitted to the recipient or the
> >person represented by the recipient, or the existence of such
> >authorization is known to the recipient of the person represented by
> >the recipient.
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.ca.us  Wed Dec 28 10:12:35 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Dec 2016 01:12:35 -0800
Subject: [R] offset in nlme
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB895@SRVEXCHCM301.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB81B@SRVEXCHCM301.precheza.cz>
	<9B5B9B8B-5594-4D4D-808E-DA37436FCAEE@dcn.davis.ca.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB895@SRVEXCHCM301.precheza.cz>
Message-ID: <6A6E9055-8591-44DE-9843-FBA14DF4D2F8@dcn.davis.ca.us>

You don't need to post WORKING code... just code that leads to the problem you want help with. The ability to create the error and then eliminate the error greatly reduces guessing on both sides of the conversation about the nature of the question. (Things the asker did not know were important become clear to the answerer and can be highlighted.)

I think you can also forgo the little function definition if you simply remove R0 from the start list in your original call to nlme and put a zero in the function call. 
-- 
Sent from my phone. Please excuse my brevity.

On December 27, 2016 11:39:29 PM PST, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi Jeff.
>
>Yes, if it had been reproducible I would not post it as I had known
>solution myself. (Uff, I hope I used this conditional clause
>correctly).
>
>OTOH your suggestion works and seems to arrive to desired result even
>that you said you do not know what I am talking about. R (and this
>smart community) sometimes surprise me even after quite a long time
>experience.
>
>Thanks.
>Petr
>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, December 27, 2016 4:21 PM
>> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list
><r-help at r-
>> project.org>
>> Subject: Re: [R] offset in nlme
>>
>> Not reproducible. Tsk!
>>
>> I really don't know what you are taking about,  but some ideas are:
>>
>> mySSasymp <- function( doba, Asym, lrc ) {
>>   SSasymp(doba, Asym, 0, lrc)
>> }
>>
>> Another idea is to use log( time ) rather than time.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On December 27, 2016 6:47:12 AM PST, PIKAL Petr
><petr.pikal at precheza.cz>
>> wrote:
>> >Dear all
>> >
>> >I would like to fit SSasymp model to some data by nlme. I did not
>find
>> >any clue how to set one of parameters to fixed constant value
>(R0=0).
>> >
>> >One suitable way could be to use SSlogis as it has one parameter
>zero,
>> >however it is not correct AFAIK logistics is defined from -Inf to
>Inf
>> >and my x value is time, starting from 0.
>> >
>> >The only option I found is to define my own growth function which is
>> >constrained by some fixed starting point. Does anybody know other
>way
>> >around? Like persuading nlme not optimize R0 and be happy with the
>> >value set in the function call.
>> >
>> >something like
>> >
>> >nlsList(rutrtg ~ SSasymp(doba, Asym, R0, lrc), data=rutil.g,
>> >start=c(Asym=100, R0= 10, lrc=-2), offset=c(R0=10))
>> >
>> >which obviously does not work.
>> >
>> >I could put some data but it is more a matter of nlme or other R
>> >functions then real data.
>> >
>> >Looking forward to some answer.
>> >Happy New year 2017
>> >
>> >Petr Pikal
>> >
>> >________________________________
>> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>jsou
>> >ur?eny pouze jeho adres?t?m.
>> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a
>jeho
>> >kopie vyma?te ze sv?ho syst?mu.
>> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> >
>> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet?
>nab?dky
>> >ze strany p??jemce s dodatkem ?i odchylkou.
>> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m
>zastoupen?
>> >zn?m?.
>> >
>> >This e-mail and any documents attached to it may be confidential and
>> >are intended only for its intended recipients.
>> >If you received this e-mail by mistake, please immediately inform
>its
>> >sender. Delete the contents of this e-mail with all attachments and
>its
>> >copies from your system.
>> >If you are not the intended recipient of this e-mail, you are not
>> >authorized to use, disseminate, copy or disclose this e-mail in any
>> >manner.
>> >The sender of this e-mail shall not be liable for any possible
>damage
>> >caused by modifications of the e-mail or by delay with transfer of
>the
>> >email.
>> >
>> >In case that this e-mail forms part of business dealings:
>> >- the sender reserves the right to end negotiations about entering
>into
>> >a contract in any time, for any reason, and without stating any
>> >reasoning.
>> >- if the e-mail contains an offer, the recipient is entitled to
>> >immediately accept such offer; The sender of this e-mail (offer)
>> >excludes any acceptance of the offer on the part of the recipient
>> >containing any amendment or variation.
>> >- the sender insists on that the respective contract is concluded
>only
>> >upon an express mutual agreement on all its aspects.
>> >- the sender of this e-mail informs that he/she is not authorized to
>> >enter into any contracts on behalf of the company except for cases
>in
>> >which he/she is expressly authorized to do so in writing, and such
>> >authorization or power of attorney is submitted to the recipient or
>the
>> >person represented by the recipient, or the existence of such
>> >authorization is known to the recipient of the person represented by
>> >the recipient.
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.


From tolga at coubros.com  Wed Dec 28 10:39:56 2016
From: tolga at coubros.com (Tolga Uzuner)
Date: Wed, 28 Dec 2016 12:39:56 +0300
Subject: [R] Rbbg usurped ?
Message-ID: <68a83ee8-f837-d4e9-f24d-f2a82effd467@coubros.com>

Dear R users,

I have some old code that was using Rbbg, which no longer appears to be 
working.

I tried to download Rbbg using the line:
install.packages("Rbbg", repos = "http://r.findata.org")

in R version 3.3.2 on a Windows 10 machine and got the following error:

 > install.packages("Rbbg", repos = "http://r.findata.org")
Installing package into ?C:/Users/Tolga/Documents/R/win-library/3.3?
(as ?lib? is unspecified)
Warning: unable to access index for repository 
http://r.findata.org/src/contrib:
   cannot open URL 'http://r.findata.org/src/contrib/PACKAGES'
Warning: unable to access index for repository 
http://r.findata.org/bin/windows/contrib/3.3:
   cannot open URL 'http://r.findata.org/bin/windows/contrib/3.3/PACKAGES'
Warning message:
package ?Rbbg? is not available (for R version 3.3.2)
 >

Is Rbbg no longer supported ? Has it been usurped by something else ? 
Does this mean I have to rewrite code or is the new package compatible 
with code written for Rbbg ?

Thanks in advance


From petr.pikal at precheza.cz  Wed Dec 28 11:02:50 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 28 Dec 2016 10:02:50 +0000
Subject: [R] offset in nlme
In-Reply-To: <6A6E9055-8591-44DE-9843-FBA14DF4D2F8@dcn.davis.ca.us>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB81B@SRVEXCHCM301.precheza.cz>
	<9B5B9B8B-5594-4D4D-808E-DA37436FCAEE@dcn.davis.ca.us>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB895@SRVEXCHCM301.precheza.cz>
	<6A6E9055-8591-44DE-9843-FBA14DF4D2F8@dcn.davis.ca.us>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB8C0@SRVEXCHCM301.precheza.cz>

Hi

> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Wednesday, December 28, 2016 10:13 AM
> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list <r-help at r-
> project.org>
> Subject: RE: [R] offset in nlme
>
> You don't need to post WORKING code... just code that leads to the problem
> you want help with. The ability to create the error and then eliminate the
> error greatly reduces guessing on both sides of the conversation about the
> nature of the question. (Things the asker did not know were important
> become clear to the answerer and can be highlighted.)
>
> I think you can also forgo the little function definition if you simply remove R0
> from the start list in your original call to nlme and put a zero in the function
> call.


Yes, you are correct. I am not sure if it is intended but I did not find any mention about this feature in help pages nor in Pinheiro, Bates book.

fit<-nlsList(rutrtg ~ SSasymp(doba, Asym, R0=5, lrc), data=rutil.g, start=c(Asym=100, lrc=-3))
fit1<-nlme(fit, random=Asym+lrc~1)
fixef(fit1)
    Asym      lrc
73.77617 -3.31942

Cheers
Petr

For completeness, here are the data.
dput(rutil.g)
structure(list(vzorek = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 16L,
16L, 16L, 16L, 16L, 16L, 16L, 16L, 16L, 5L, 7L, 9L, 11L, 13L,
6L, 8L, 10L, 12L, 14L), .Label = c("01.I", "02.I", "1", "2",
"2/1*A/900C", "2/1*A/950C", "2/1*B/900C", "2/1*B/950C", "2/1*C/900C",
"2/1*C/950C", "2/1*D/900C", "2/1*D/950C", "2/1*E/900C", "2/1*E/950C",
"3", "4"), class = "factor"), promot = c(3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 6L, 6L, 6L, 6L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L), teplota = c(875L, 875L, 875L, 875L, 875L, 925L, 925L, 925L,
925L, 925L, 875L, 875L, 875L, 875L, 875L, 925L, 925L, 925L, 925L,
925L, 875L, 875L, 875L, 875L, 875L, 925L, 925L, 925L, 925L, 925L,
875L, 875L, 875L, 875L, 875L, 925L, 925L, 925L, 925L, 925L, 875L,
875L, 875L, 875L, 875L, 925L, 925L, 925L, 925L, 925L, 875L, 875L,
875L, 875L, 875L, 925L, 925L, 925L, 925L, 925L, 875L, 875L, 875L,
875L, 875L, 925L, 925L, 925L, 925L, 925L), k2oteor = c(0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,
0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.2,
0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.4, 0.4, 0.4,
0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,
0.4, 0.4, 0.4), p2o5teor = c(0.17, 0.17, 0.17, 0.17, 0.17, 0.17,
0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,
0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,
0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,
0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,
0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17,
0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17, 0.17), k2omer = c(0.104,
0.104, 0.104, 0.104, 0.104, 0.104, 0.104, 0.104, 0.104, 0.104,
0.102, 0.102, 0.102, 0.102, 0.102, 0.102, 0.102, 0.102, 0.102,
0.102, 0.384, 0.384, 0.384, 0.384, 0.384, 0.384, 0.384, 0.384,
0.384, 0.384, 0.211, 0.211, 0.211, 0.211, 0.211, 0.211, 0.211,
0.211, 0.211, 0.211, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18, 0.18,
0.18, 0.18, 0.18, 0.266, 0.266, 0.266, 0.266, 0.266, 0.266, 0.266,
0.266, 0.266, 0.266, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26, 0.26,
0.26, 0.26, 0.26), p2o5mer = c(0.167, 0.167, 0.167, 0.167, 0.167,
0.167, 0.167, 0.167, 0.167, 0.167, 0.165, 0.165, 0.165, 0.165,
0.165, 0.165, 0.165, 0.165, 0.165, 0.165, 0.171, 0.171, 0.171,
0.171, 0.171, 0.171, 0.171, 0.171, 0.171, 0.171, 0.16, 0.16,
0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.16, 0.164, 0.164,
0.164, 0.164, 0.164, 0.164, 0.164, 0.164, 0.164, 0.164, 0.162,
0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162, 0.162,
0.165, 0.165, 0.165, 0.165, 0.165, 0.165, 0.165, 0.165, 0.165,
0.165), al2o3 = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.017, 0.017,
0.017, 0.017, 0.017, 0.017, 0.017, 0.017, 0.017, 0.017, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0.006, 0.006, 0.006, 0.006, 0.006, 0.006,
0.006, 0.006, 0.006, 0.006, 0.025, 0.025, 0.025, 0.025, 0.025,
0.025, 0.025, 0.025, 0.025, 0.025, 0.019, 0.019, 0.019, 0.019,
0.019, 0.019, 0.019, 0.019, 0.019, 0.019, 0.016, 0.016, 0.016,
0.016, 0.016, 0.016, 0.016, 0.016, 0.016, 0.016), tskut = c(900L,
900L, 900L, 900L, 900L, 950L, 950L, 950L, 950L, 950L, 900L, 900L,
900L, 900L, 900L, 950L, 950L, 950L, 950L, 950L, 900L, 900L, 900L,
900L, 900L, 950L, 950L, 950L, 950L, 950L, 900L, 900L, 900L, 900L,
900L, 950L, 950L, 950L, 950L, 950L, 900L, 900L, 900L, 900L, 900L,
950L, 950L, 950L, 950L, 950L, 900L, 900L, 900L, 900L, 900L, 950L,
950L, 950L, 950L, 950L, 900L, 900L, 900L, 900L, 900L, 950L, 950L,
950L, 950L, 950L), doba = c(15L, 30L, 60L, 120L, 240L, 15L, 30L,
60L, 120L, 240L, 15L, 30L, 60L, 120L, 240L, 15L, 30L, 60L, 120L,
240L, 15L, 30L, 60L, 120L, 240L, 15L, 30L, 60L, 120L, 240L, 15L,
30L, 60L, 120L, 240L, 15L, 30L, 60L, 120L, 240L, 15L, 30L, 60L,
120L, 240L, 15L, 30L, 60L, 120L, 240L, 15L, 30L, 60L, 120L, 240L,
15L, 30L, 60L, 120L, 240L, 15L, 30L, 60L, 120L, 240L, 15L, 30L,
60L, 120L, 240L), rutrtg = c(16.4, 87.1, 96.6, 95, 96.5, 34.9,
98.5, 98.3, 99.3, 99.8, 25.9, 71.3, 79.8, 84.9, 89.6, 43.3, 83.2,
87.2, 93.4, 93.5, 10.1, 33, 53.8, 30.5, 34.2, 17.7, 50.9, 69.1,
86.6, 92.4, 20.3, 76.1, 87.6, 89.7, 94.7, 17, 44.6, 43.4, 46.7,
54.7, 10, 42.6, 76.9, 54.2, 75.6, 29, 80.8, 96.2, 84.2, 85.7,
8.9, 41.3, 56.9, 43.9, 46.5, 36.6, 71.8, 83.5, 75.5, 80.4, 9.1,
26.6, 40.7, 36, 56.3, 34.5, 69.2, 73.3, 74.7, 79.5), barvivost = c(888,
1611, 1663, 1681, 1706, 1287, 1341, 1519, 1645, 1689, 1176, 1562,
1665, 1669, 1731, 1375, 1694, 1718, 1769, 1783, 954, 1428, 1568,
1476, 1521, 927, 1641, 1717, 1796, 1848, 1158, 1629, 1746, 1743,
1792, 1090, 1508, 1620, 1636, 1689, 932, 1442, 1689, 1538, 1731,
1139, 1760, 1822, 1864, 1868, 894, 1443, 1629, 1594, 1666, 1572,
1705, 1811, 1774, 1806, 796, 1371, 1512, 1515, 1636, 1352, 1690,
1771, 1778, 1849), podton = c(10L, 6L, 5L, 7L, 7L, 9L, -7L, -3L,
3L, 3L, 12L, 10L, 12L, 11L, 10L, 10L, 11L, 8L, 10L, 8L, 15L,
15L, 16L, 16L, 16L, 10L, 14L, 12L, 13L, 9L, 15L, 14L, 15L, 15L,
13L, 12L, 12L, 12L, 12L, 10L, 13L, 12L, 13L, 15L, 12L, 14L, 13L,
8L, 7L, 6L, 14L, 16L, 15L, 15L, 13L, 15L, 13L, 8L, 9L, 7L, 13L,
16L, 16L, 16L, 13L, 14L, 13L, 8L, 8L, 5L), lpas = c(45.21, 52.42,
52.94, 53.12, 53.37, 49.19, 49.73, 51.5, 52.76, 53.2, 48.08,
51.93, 52.96, 53, 53.62, 50.07, 53.25, 53.49, 54, 54.13, 45.87,
50.6, 51.99, 51.07, 51.52, 45.6, 52.72, 53.48, 54.26, 54.78,
47.9, 52.6, 53.77, 53.74, 54.22, 47.23, 51.39, 52.51, 52.67,
53.2, 45.65, 50.74, 53.2, 51.69, 53.62, 47.71, 53.91, 54.52,
54.94, 54.98, 45.27, 50.75, 52.6, 52.25, 52.97, 52.03, 53.36,
54.41, 54.04, 54.36, 44.3, 50.03, 51.43, 51.46, 52.67, 49.84,
53.21, 54.02, 54.08, 54.79), apas = c(1.05, 0.46, 0.48, 0.45,
0.39, 0.6, 0.82, 0.59, 0.4, 0.33, 0.7, 0.47, 0.27, 0.31, 0.18,
0.54, 0.28, 0.22, 0.1, 0.07, 0.89, 0.57, 0.43, 0.47, 0.38, 0.94,
0.3, 0.14, -0.03, -0.01, 0.67, 0.4, 0.12, 0.17, -0.02, 0.82,
0.46, 0.33, 0.31, 0.26, 0.93, 0.5, 0.24, 0.35, 0.15, 0.72, 0.15,
0.17, 0.12, 0.16, 0.96, 0.54, 0.24, 0.28, 0.27, 0.38, 0.18, 0.16,
0.21, 0.22, 1.13, 0.66, 0.41, 0.41, 0.31, 0.54, 0.18, 0.22, 0.23,
0.19), bpas = c(-0.02, 0.87, 0.91, 0.51, 0.59, 0.13, 3.45, 2.53,
1.45, 1.36, -0.31, 0.03, -0.42, -0.13, 0.03, -0.04, -0.28, 0.46,
0.09, 0.47, -0.92, -0.95, -1.11, -1.1, -1.11, 0.02, -0.7, -0.39,
-0.5, 0.18, -1, -0.81, -0.9, -0.95, -0.68, -0.44, -0.44, -0.33,
-0.33, -0.02, -0.63, -0.48, -0.68, -0.92, -0.36, -0.84, -0.53,
0.43, 0.61, 0.83, -0.72, -1.11, -0.97, -1.06, -0.62, -0.9, -0.56,
0.35, 0.14, 0.64, -0.59, -1.24, -1.13, -1.28, -0.52, -0.83, -0.51,
0.47, 0.4, 0.97), vodivost = c(868, 185.3, 95.5, 106.3, 87.8,
514, 86.4, 95.3, 62.2, 56.4, 1192, 570, 497, 484, 448, 930, 571,
503, 453, 832, 1966, 969, 661, 1288, 678, 3054, 597, 477, 431,
347, 1095, 430, 401, 371, 332, 2250, 1392, 1205, 1173, 1142,
1508, 710, 479, 686, 529, 1017, 520, 417, 466, 488, 2240, 908,
692, 808, 784, 724, 698, 557, 773, 698, 1784, 848, 800, 777,
644, 883, 609, 702, 628, 716), zaverage = c(311.7, 348.1, 336,
321, 325.2, 327.6, 518.3, 415, 353.1, 355.4, 258.3, 286.2, 265.1,
288.7, 308.5, 258.5, 271.6, 311.8, 283.7, 298.3, 209.5, 227,
231, 219.9, 228.1, 245.1, 254.9, 270.6, 265.6, 297.6, 231.8,
256.9, 247.5, 246.7, 258.1, 223.3, 246.2, 253.2, 255.6, 275.8,
250.4, 256.6, 248.6, 223.5, 254.2, 254, 293.8, 296.6, 299.6,
310.1, 225.4, 228.6, 237.4, 228.7, 238, 239.5, 250.5, 288.4,
303.7, 301.1, 230.1, 222, 225.8, 222.9, 255.4, 236.8, 261.6,
292.9, 295.7, 318.7), k2o.f = structure(c(1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L), .Label = c("low", "standard", "high", "extreme"), class = "factor"),
    int = structure(c(1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L,
    1L, 1L, 1L, 1L, 1L, 5L, 5L, 5L, 5L, 5L, 4L, 4L, 4L, 4L, 4L,
    8L, 8L, 8L, 8L, 8L, 2L, 2L, 2L, 2L, 2L, 6L, 6L, 6L, 6L, 6L,
    9L, 9L, 9L, 9L, 9L, 11L, 11L, 11L, 11L, 11L, 10L, 10L, 10L,
    10L, 10L, 12L, 12L, 12L, 12L, 12L, 3L, 3L, 3L, 3L, 3L, 7L,
    7L, 7L, 7L, 7L), .Label = c("low/900/3", "standard/900/3",
    "high/900/3", "extreme/900/3", "low/950/3", "standard/950/3",
    "high/950/3", "extreme/950/3", "standard/900/6", "high/900/6",
    "standard/950/6", "high/950/6"), class = c("ordered", "factor"
    ), scores = structure(c(3, 6, 3, 3, 6, 3, 3, 6, 3, 3, 6,
    3), .Dim = 12L, .Dimnames = list(c("low/900/3", "standard/900/6",
    "standard/900/3", "high/900/3", "high/900/6", "extreme/900/3",
    "low/950/3", "standard/950/6", "standard/950/3", "high/950/3",
    "high/950/6", "extreme/950/3"))))), .Names = c("vzorek",
"promot", "teplota", "k2oteor", "p2o5teor", "k2omer", "p2o5mer",
"al2o3", "tskut", "doba", "rutrtg", "barvivost", "podton", "lpas",
"apas", "bpas", "vodivost", "zaverage", "k2o.f", "int"), class = c("nfnGroupedData",
"nfGroupedData", "groupedData", "data.frame"), row.names = c(NA,
70L), formula = rutrtg ~ doba | int, FUN = function (x)
max(x, na.rm = TRUE), order.groups = TRUE)





> --
> Sent from my phone. Please excuse my brevity.
>
> On December 27, 2016 11:39:29 PM PST, PIKAL Petr
> <petr.pikal at precheza.cz> wrote:
> >Hi Jeff.
> >
> >Yes, if it had been reproducible I would not post it as I had known
> >solution myself. (Uff, I hope I used this conditional clause
> >correctly).
> >
> >OTOH your suggestion works and seems to arrive to desired result even
> >that you said you do not know what I am talking about. R (and this
> >smart community) sometimes surprise me even after quite a long time
> >experience.
> >
> >Thanks.
> >Petr
> >
> >> -----Original Message-----
> >> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> >> Sent: Tuesday, December 27, 2016 4:21 PM
> >> To: PIKAL Petr <petr.pikal at precheza.cz>; r-help mailing list
> ><r-help at r-
> >> project.org>
> >> Subject: Re: [R] offset in nlme
> >>
> >> Not reproducible. Tsk!
> >>
> >> I really don't know what you are taking about,  but some ideas are:
> >>
> >> mySSasymp <- function( doba, Asym, lrc ) {
> >>   SSasymp(doba, Asym, 0, lrc)
> >> }
> >>
> >> Another idea is to use log( time ) rather than time.
> >> --
> >> Sent from my phone. Please excuse my brevity.
> >>
> >> On December 27, 2016 6:47:12 AM PST, PIKAL Petr
> ><petr.pikal at precheza.cz>
> >> wrote:
> >> >Dear all
> >> >
> >> >I would like to fit SSasymp model to some data by nlme. I did not
> >find
> >> >any clue how to set one of parameters to fixed constant value
> >(R0=0).
> >> >
> >> >One suitable way could be to use SSlogis as it has one parameter
> >zero,
> >> >however it is not correct AFAIK logistics is defined from -Inf to
> >Inf
> >> >and my x value is time, starting from 0.
> >> >
> >> >The only option I found is to define my own growth function which is
> >> >constrained by some fixed starting point. Does anybody know other
> >way
> >> >around? Like persuading nlme not optimize R0 and be happy with the
> >> >value set in the function call.
> >> >
> >> >something like
> >> >
> >> >nlsList(rutrtg ~ SSasymp(doba, Asym, R0, lrc), data=rutil.g,
> >> >start=c(Asym=100, R0= 10, lrc=-2), offset=c(R0=10))
> >> >
> >> >which obviously does not work.
> >> >
> >> >I could put some data but it is more a matter of nlme or other R
> >> >functions then real data.
> >> >
> >> >Looking forward to some answer.
> >> >Happy New year 2017
> >> >
> >> >Petr Pikal
> >> >


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sarah.goslee at gmail.com  Wed Dec 28 11:36:36 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 28 Dec 2016 10:36:36 +0000
Subject: [R] Rbbg usurped ?
In-Reply-To: <68a83ee8-f837-d4e9-f24d-f2a82effd467@coubros.com>
References: <68a83ee8-f837-d4e9-f24d-f2a82effd467@coubros.com>
Message-ID: <CAM_vju=0XBB-0KSwb6e_LSAdCLVZk3hQqoKOQhSgwyRobOr5tA@mail.gmail.com>

If you actually visit that link, you will see that the directory structure
isn't laid out in the way that install.packages() currently expects for a
repo, but that you can still download the package yourself, and presumably
install it from local file.


On Wed, Dec 28, 2016 at 4:41 AM Tolga Uzuner <tolga at coubros.com> wrote:

> Dear R users,
>
>
>
> I have some old code that was using Rbbg, which no longer appears to be
>
> working.
>
>
>
> I tried to download Rbbg using the line:
>
> install.packages("Rbbg", repos = "http://r.findata.org")
>
>
>
> in R version 3.3.2 on a Windows 10 machine and got the following error:
>
>
>
>  > install.packages("Rbbg", repos = "http://r.findata.org")
>
> Installing package into ?C:/Users/Tolga/Documents/R/win-library/3.3?
>
> (as ?lib? is unspecified)
>
> Warning: unable to access index for repository
>
> http://r.findata.org/src/contrib:
>
>    cannot open URL 'http://r.findata.org/src/contrib/PACKAGES'
>
> Warning: unable to access index for repository
>
> http://r.findata.org/bin/windows/contrib/3.3:
>
>    cannot open URL 'http://r.findata.org/bin/windows/contrib/3.3/PACKAGES'
>
> Warning message:
>
> package ?Rbbg? is not available (for R version 3.3.2)
>
>  >
>
>
>
> Is Rbbg no longer supported ? Has it been usurped by something else ?
>
> Does this mean I have to rewrite code or is the new package compatible
>
> with code written for Rbbg ?
>
>
>
> Thanks in advance
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From radhikasundar520 at gmail.com  Wed Dec 28 13:30:34 2016
From: radhikasundar520 at gmail.com (radhika sundar)
Date: Wed, 28 Dec 2016 18:00:34 +0530
Subject: [R] Bayesian cox model: spBayesSurv package
In-Reply-To: <83F4C518-778D-4E57-93E4-F1D139E97FB7@comcast.net>
References: <CAMj135NbmJSm+Eyw0vD_GH3E_=O=WgAkhAos+C=m_m2PSWFZwQ@mail.gmail.com>
	<83F4C518-778D-4E57-93E4-F1D139E97FB7@comcast.net>
Message-ID: <CAMj135NpVSKmvbWNsWQ808dyuD0iYh4Cep5PU=H9damxJfv11g@mail.gmail.com>

The example code for the indeptCoxph function  in the spBayesSurv package
has been updated(this is not cross-posted anywhere else). See code below.
The author simulates data to illustrate the Cox model -  I am stuck trying
to understand the role of the functions f0oft, S0oft, fioft and Sioft as
also Finv.

Am I right in thinking that he is only using the above mentioned functions
to simulate his data? If I wanted to run the indeptCoxph function with
different data, do I need to define those functions again?
Roughly, in the author's example, I can understand he fits a Cox model with
2 predictors x1 and x2. He simulates survival time data (but this is where
I am confused).
As for the bayesian model itself, the only prior he uses is for M, the
number of cutpoints in the baseline hazard function. (There is no function
listed as a prior for Survival times in the ideptCoxph call).

Sorry --- this is a novice question relating to understanding both the
statistical set-up and the R-code.
Thanks for any help!
Author's(updated)  code:
###############################################################
# A simulated data: Cox PH
###############################################################
rm(list=ls())
library(survival)
library(spBayesSurv)
library(coda)
library(MASS)
## True parameters
betaT = c(1,1);
n=500; npred=30; ntot=n+npred;
## Baseline Survival
f0oft = function(t) 0.5*dlnorm(t, -1, 0.5)+0.5*dlnorm(t,1,0.5);
S0oft = function(t) (0.5*plnorm(t, -1, 0.5, lower.tail=FALSE)+
                       0.5*plnorm(t, 1, 0.5, lower.tail=FALSE))
## The Survival function:
Sioft = function(t,x)  exp( log(S0oft(t))*exp(sum(x*betaT)) ) ;
fioft = function(t,x) exp(sum(x*betaT))*f0oft(t)/S0oft(t)*Sioft(t,x);
Fioft = function(t,x) 1-Sioft(t,x);
## The inverse for Fioft
Finv = function(u, x) uniroot(function (t) Fioft(t,x)-u, lower=1e-100,
                                  upper=1e100, extendInt ="yes",
tol=1e-6)$root

## generate x
x1 = rbinom(ntot, 1, 0.5); x2 = rnorm(ntot, 0, 1); X = cbind(x1, x2);
## generate survival times
u = runif(ntot);
tT = rep(0, ntot);
for (i in 1:ntot){
  tT[i] = Finv(u[i], X[i,]);
}

## right censoring
t_obs=tT
Centime = runif(ntot, 2, 6);
delta = (tT<=Centime) +0 ;
length(which(delta==0))/ntot; # censoring rate
rcen = which(delta==0);
t_obs[rcen] = Centime[rcen]; ## observed time
## make a data frame
dtotal = data.frame(t_obs=t_obs, x1=x1, x2=x2, delta=delta,
                    tT=tT);
## Hold out npred=30 for prediction purpose
predindex = sample(1:ntot, npred);
dpred = dtotal[predindex,];
dtrain = dtotal[-predindex,];

# Prediction settings
xpred = cbind(dpred$x1,dpred$x2);
prediction = list(xpred=xpred);

###############################################################
# Independent Cox PH
###############################################################
# MCMC parameters
nburn=1000; nsave=1000; nskip=0;
# Note larger nburn, nsave and nskip should be used in practice.
mcmc=list(nburn=nburn, nsave=nsave, nskip=nskip, ndisplay=1000);
prior = list(M=10);
state <- NULL;
# Fit the Cox PH model
res1 = indeptCoxph( y = dtrain$t_obs, delta =dtrain$delta,
                    x = cbind(dtrain$x1, dtrain$x2),RandomIntervals=FALSE,
                    prediction=prediction,  prior=prior, mcmc=mcmc,
state=state);
save.beta = res1$beta; row.names(save.beta)=c("x1","x2")
apply(save.beta, 1, mean); # coefficient estimates
apply(save.beta, 1, sd); # standard errors
apply(save.beta, 1, function(x) quantile(x, probs=c(0.025, 0.975))) # 95% CI
## traceplot
par(mfrow = c(2,1))
traceplot(mcmc(save.beta[1,]), main="beta1")
traceplot(mcmc(save.beta[2,]), main="beta2")
res1$ratebeta; # adaptive MH acceptance rate
## LPML
LPML1 = sum(log(res1$cpo)); LPML1;
## MSPE
mean((dpred$tT-apply(res1$Tpred, 1, median))^2);

## plots
par(mfrow = c(2,1))
x1new = c(0, 0);
x2new = c(0, 1)
xpred = cbind(x1new, x2new);
nxpred = nrow(xpred);
tgrid = seq(1e-10, 4, 0.03);
ngrid = length(tgrid);
estimates = GetCurves(res1, xpred, log(tgrid), CI=c(0.05, 0.95));
fhat = estimates$fhat;
Shat = estimates$Shat;
## density in t
plot(tgrid, fioft(tgrid, xpred[1,]), "l", lwd=2,  ylim=c(0,3),
main="density")
for(i in 1:nxpred){
  lines(tgrid, fioft(tgrid, xpred[i,]), lwd=2)
  lines(tgrid, fhat[,i], lty=2, lwd=2, col=4);
}
## survival in t
plot(tgrid, Sioft(tgrid, xpred[1,]), "l", lwd=2, ylim=c(0,1),
main="survival")
for(i in 1:nxpred){
  lines(tgrid, Sioft(tgrid, xpred[i,]), lwd=2)
  lines(tgrid, Shat[,i], lty=2, lwd=2, col=4);
  lines(tgrid, estimates$Shatup[,i], lty=2, lwd=1, col=4);
  lines(tgrid, estimates$Shatlow[,i], lty=2, lwd=1, col=4);
}


On Wed, Dec 28, 2016 at 2:11 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

> Cross posting is deprecated on rhelp but if you do so, please at least
> post a link to the stackoverflow address for the duplicate question.
>
> Sent from my iPhone
>
> > On Dec 27, 2016, at 6:52 AM, radhika sundar <radhikasundar520 at gmail.com>
> wrote:
> >
> > I am going through R's function indeptCoxph in the spBayesSurv package
> > which fits a bayesian Cox model. I am confused by some of the input
> > parameters to this function.
> >
> > What is the role of the "prediction" input parameter? Should it not only
> > contain the predictor covariates? In the R code example, the authors have
> > included a vector "s" which was used to initially simulate the survival
> > times data in their example as well as the predictors. I'm not sure what
> > this "s" is.
> >
> > Given that my data is just a set of survival times between 0 and 100,
> along
> > with censored (yes/no) information, how would I use this function and how
> > should I handle the input "s"?
> >
> >
> > Thanks for any help!
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Dec 28 18:07:32 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 28 Dec 2016 09:07:32 -0800
Subject: [R] Bayesian cox model: spBayesSurv package
In-Reply-To: <CAMj135NpVSKmvbWNsWQ808dyuD0iYh4Cep5PU=H9damxJfv11g@mail.gmail.com>
References: <CAMj135NbmJSm+Eyw0vD_GH3E_=O=WgAkhAos+C=m_m2PSWFZwQ@mail.gmail.com>
	<83F4C518-778D-4E57-93E4-F1D139E97FB7@comcast.net>
	<CAMj135NpVSKmvbWNsWQ808dyuD0iYh4Cep5PU=H9damxJfv11g@mail.gmail.com>
Message-ID: <C9DC410B-4889-470B-ABBA-A8110FB35C4E@comcast.net>


> On Dec 28, 2016, at 4:30 AM, radhika sundar <radhikasundar520 at gmail.com> wrote:
> 
> The example code for the indeptCoxph function  in the spBayesSurv package has been updated(this is not cross-posted anywhere else). See code below. The author simulates data to illustrate the Cox model -  I am stuck trying to understand the role of the functions f0oft, S0oft, fioft and Sioft as also Finv.

Your preamble very much resembles the 2 questions from yesterday of the anonymous questioner: user2450223

http://stackoverflow.com/questions/41344300/bayesian-survival-analysis
http://stackoverflow.com/questions/41342836/stuck-with-package-example-code-in-r-simulating-data-to-fit-a-model

One of those questions was apparently answered by the package's author yesterday, although you (at least I think it must have been you) have not acknowledged it yet. If you are asking question on Rhelp about little-used packages you are advised in the Posting Guide to first contact the package author and if unsuccessful, then post to Rhelp (preferably with visible CC: to the author as well as to the list.)

Learn the `maintainer` function:

> maintainer( 'spBayesSurv')
[1] "Haiming Zhou <zhouh at niu.edu>"


> 
> Am I right in thinking that he is only using the above mentioned functions to simulate his data? If I wanted to run the indeptCoxph function with different data, do I need to define those functions again?
> Roughly, in the author's example, I can understand he fits a Cox model with 2 predictors x1 and x2. He simulates survival time data (but this is where I am confused).
> As for the bayesian model itself, the only prior he uses is for M, the number of cutpoints in the baseline hazard function. (There is no function listed as a prior for Survival times in the ideptCoxph call).

Rhelp is not set up to handle questions that are fundamentally statistical. When the issue is the underlying statistical theory for running R code the best place start would be the package author, and only when unsuccessful post to whatever alternate location he suggests in the packageDescription (although I don't see one) or then post to:

http://stats.stackexchange.com/

Given the package's "spatial" capacities, it might also have been appropriate on:

https://stat.ethz.ch/mailman/listinfo/r-sig-geo


Neither R-help nor StackOverflow are good fits to this question in my opinion.

-- 
David.

> 
> Sorry --- this is a novice question relating to understanding both the statistical set-up and the R-code.
> Thanks for any help!
> Author's(updated)  code:
> ###############################################################
> # A simulated data: Cox PH
> ###############################################################
> rm(list=ls())
> library(survival)
> library(spBayesSurv)
> library(coda)
> library(MASS)
> ## True parameters 
> betaT = c(1,1); 
> n=500; npred=30; ntot=n+npred;
> ## Baseline Survival
> f0oft = function(t) 0.5*dlnorm(t, -1, 0.5)+0.5*dlnorm(t,1,0.5);
> S0oft = function(t) (0.5*plnorm(t, -1, 0.5, lower.tail=FALSE)+
>                        0.5*plnorm(t, 1, 0.5, lower.tail=FALSE))
> ## The Survival function:
> Sioft = function(t,x)  exp( log(S0oft(t))*exp(sum(x*betaT)) ) ;
> fioft = function(t,x) exp(sum(x*betaT))*f0oft(t)/S0oft(t)*Sioft(t,x);
> Fioft = function(t,x) 1-Sioft(t,x);
> ## The inverse for Fioft
> Finv = function(u, x) uniroot(function (t) Fioft(t,x)-u, lower=1e-100, 
>                                   upper=1e100, extendInt ="yes", tol=1e-6)$root
> 
> ## generate x 
> x1 = rbinom(ntot, 1, 0.5); x2 = rnorm(ntot, 0, 1); X = cbind(x1, x2);
> ## generate survival times
> u = runif(ntot);
> tT = rep(0, ntot);
> for (i in 1:ntot){
>   tT[i] = Finv(u[i], X[i,]);
> }
> 
> ## right censoring
> t_obs=tT 
> Centime = runif(ntot, 2, 6);
> delta = (tT<=Centime) +0 ; 
> length(which(delta==0))/ntot; # censoring rate
> rcen = which(delta==0);
> t_obs[rcen] = Centime[rcen]; ## observed time 
> ## make a data frame
> dtotal = data.frame(t_obs=t_obs, x1=x1, x2=x2, delta=delta, 
>                     tT=tT);
> ## Hold out npred=30 for prediction purpose
> predindex = sample(1:ntot, npred);
> dpred = dtotal[predindex,];
> dtrain = dtotal[-predindex,];
> 
> # Prediction settings 
> xpred = cbind(dpred$x1,dpred$x2);
> prediction = list(xpred=xpred);
> 
> ###############################################################
> # Independent Cox PH
> ###############################################################
> # MCMC parameters
> nburn=1000; nsave=1000; nskip=0;
> # Note larger nburn, nsave and nskip should be used in practice.
> mcmc=list(nburn=nburn, nsave=nsave, nskip=nskip, ndisplay=1000);
> prior = list(M=10);
> state <- NULL;
> # Fit the Cox PH model
> res1 = indeptCoxph( y = dtrain$t_obs, delta =dtrain$delta, 
>                     x = cbind(dtrain$x1, dtrain$x2),RandomIntervals=FALSE, 
>                     prediction=prediction,  prior=prior, mcmc=mcmc, state=state);
> save.beta = res1$beta; row.names(save.beta)=c("x1","x2")
> apply(save.beta, 1, mean); # coefficient estimates
> apply(save.beta, 1, sd); # standard errors
> apply(save.beta, 1, function(x) quantile(x, probs=c(0.025, 0.975))) # 95% CI
> ## traceplot
> par(mfrow = c(2,1))
> traceplot(mcmc(save.beta[1,]), main="beta1")
> traceplot(mcmc(save.beta[2,]), main="beta2")
> res1$ratebeta; # adaptive MH acceptance rate
> ## LPML
> LPML1 = sum(log(res1$cpo)); LPML1;
> ## MSPE
> mean((dpred$tT-apply(res1$Tpred, 1, median))^2); 
> 
> ## plots
> par(mfrow = c(2,1))
> x1new = c(0, 0);
> x2new = c(0, 1)
> xpred = cbind(x1new, x2new); 
> nxpred = nrow(xpred);
> tgrid = seq(1e-10, 4, 0.03);
> ngrid = length(tgrid);
> estimates = GetCurves(res1, xpred, log(tgrid), CI=c(0.05, 0.95));
> fhat = estimates$fhat; 
> Shat = estimates$Shat;
> ## density in t
> plot(tgrid, fioft(tgrid, xpred[1,]), "l", lwd=2,  ylim=c(0,3), main="density")
> for(i in 1:nxpred){
>   lines(tgrid, fioft(tgrid, xpred[i,]), lwd=2)
>   lines(tgrid, fhat[,i], lty=2, lwd=2, col=4);
> }
> ## survival in t
> plot(tgrid, Sioft(tgrid, xpred[1,]), "l", lwd=2, ylim=c(0,1), main="survival")
> for(i in 1:nxpred){
>   lines(tgrid, Sioft(tgrid, xpred[i,]), lwd=2)
>   lines(tgrid, Shat[,i], lty=2, lwd=2, col=4);
>   lines(tgrid, estimates$Shatup[,i], lty=2, lwd=1, col=4);
>   lines(tgrid, estimates$Shatlow[,i], lty=2, lwd=1, col=4);
> }
> 
> 
> On Wed, Dec 28, 2016 at 2:11 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> Cross posting is deprecated on rhelp but if you do so, please at least post a link to the stackoverflow address for the duplicate question.
> 
> Sent from my iPhone
> 
> > On Dec 27, 2016, at 6:52 AM, radhika sundar <radhikasundar520 at gmail.com> wrote:
> >
> > I am going through R's function indeptCoxph in the spBayesSurv package
> > which fits a bayesian Cox model. I am confused by some of the input
> > parameters to this function.
> >
> > What is the role of the "prediction" input parameter? Should it not only
> > contain the predictor covariates? In the R code example, the authors have
> > included a vector "s" which was used to initially simulate the survival
> > times data in their example as well as the predictors. I'm not sure what
> > this "s" is.
> >
> > Given that my data is just a set of survival times between 0 and 100, along
> > with censored (yes/no) information, how would I use this function and how
> > should I handle the input "s"?
> >
> >
> > Thanks for any help!
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 

David Winsemius
Alameda, CA, USA


From john.laing at gmail.com  Wed Dec 28 19:46:13 2016
From: john.laing at gmail.com (John Laing)
Date: Wed, 28 Dec 2016 13:46:13 -0500
Subject: [R] Rbbg usurped ?
In-Reply-To: <CAM_vju=0XBB-0KSwb6e_LSAdCLVZk3hQqoKOQhSgwyRobOr5tA@mail.gmail.com>
References: <68a83ee8-f837-d4e9-f24d-f2a82effd467@coubros.com>
	<CAM_vju=0XBB-0KSwb6e_LSAdCLVZk3hQqoKOQhSgwyRobOr5tA@mail.gmail.com>
Message-ID: <CAA3Wa=vdRYxk89fXwewk5KywTMV630KQAW00h_xKDchrPe3KVg@mail.gmail.com>

I've cleaned up the findata repository, you should now be able to install
Rbbg as expected.

But that said, the package is no longer being actively developed. Recent
efforts have been taking place in the Rblpapi package. The interface is
similar, though not strictly compatible. If you're doing much work with
Bloomberg data I recommend you check it out.

JL

On Dec 28, 2016 5:39 AM, "Sarah Goslee" <sarah.goslee at gmail.com> wrote:

> If you actually visit that link, you will see that the directory structure
> isn't laid out in the way that install.packages() currently expects for a
> repo, but that you can still download the package yourself, and presumably
> install it from local file.
>
>
> On Wed, Dec 28, 2016 at 4:41 AM Tolga Uzuner <tolga at coubros.com> wrote:
>
> > Dear R users,
> >
> >
> >
> > I have some old code that was using Rbbg, which no longer appears to be
> >
> > working.
> >
> >
> >
> > I tried to download Rbbg using the line:
> >
> > install.packages("Rbbg", repos = "http://r.findata.org")
> >
> >
> >
> > in R version 3.3.2 on a Windows 10 machine and got the following error:
> >
> >
> >
> >  > install.packages("Rbbg", repos = "http://r.findata.org")
> >
> > Installing package into ?C:/Users/Tolga/Documents/R/win-library/3.3?
> >
> > (as ?lib? is unspecified)
> >
> > Warning: unable to access index for repository
> >
> > http://r.findata.org/src/contrib:
> >
> >    cannot open URL 'http://r.findata.org/src/contrib/PACKAGES'
> >
> > Warning: unable to access index for repository
> >
> > http://r.findata.org/bin/windows/contrib/3.3:
> >
> >    cannot open URL 'http://r.findata.org/bin/
> windows/contrib/3.3/PACKAGES'
> >
> > Warning message:
> >
> > package ?Rbbg? is not available (for R version 3.3.2)
> >
> >  >
> >
> >
> >
> > Is Rbbg no longer supported ? Has it been usurped by something else ?
> >
> > Does this mean I have to rewrite code or is the new package compatible
> >
> > with code written for Rbbg ?
> >
> >
> >
> > Thanks in advance
> >
> >
> >
> > ______________________________________________
> >
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >
> > https://stat.ethz.ch/mailman/listinfo/r-help
> >
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> >
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Winson.Lui at bwinparty.com  Wed Dec 28 11:23:43 2016
From: Winson.Lui at bwinparty.com (Winson Lui)
Date: Wed, 28 Dec 2016 10:23:43 +0000
Subject: [R] Predictive analysis based on past data
Message-ID: <f25699153d1a48b7af2a1e1286f05577@bwinparty.com>

HI,

I have a historical dataset which tells who bought our products. This dataset contains ID, Age, Gender and Salary.
I have another set of data which contains the four fields above.
How should I use R to calculate the probability of purchase of each customer in the second dataset or whether they would buy our products (T/F)?
Should I use glm function? If yes, how should I approach this?
Thanks.

Regards,
Winson Lui
Business Analyst
M: +44 (0) 79 1714 6247
E: winson.lui at bwinparty.com<mailto:winson.lui at bwinparty.com>


	[[alternative HTML version deleted]]


From diego at caseonit.com  Wed Dec 28 17:07:10 2016
From: diego at caseonit.com (Diego Ruiz Moreno)
Date: Wed, 28 Dec 2016 17:07:10 +0100
Subject: [R] recovering PLSDA equations for prediction (outside R)
Message-ID: <CAOMbmCJnCKarQNeYDOJmEjdWqE0=CZUmp+h7BHpM-4kuwQKyZw@mail.gmail.com>

Hi all,
I'm trying to use the result of a PLSDA model outside R, but I'm having a
really hard time finding documentation on how to write the model from the
results in the fit object.
In order to provide a good starting point I believe that this code creates
a good model that is stored in the fit variable. I know that I can use the
predict function to create the predictions but I would like to "write the
predict function outside R".

Can anyone provide me with the equations? Thanks


# load the package
library(caret)
data(iris)
x <- iris[,1:4]
y <- iris[,5]
# fit model
fit <- plsda(x, y, probMethod="Bayes")
# summarize the fit
summary(fit)
# make predictions
predictions <- predict(fit, iris[,1:4])
# summarize accuracy
table(predictions, iris$Species)

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Dec 28 19:53:43 2016
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 28 Dec 2016 18:53:43 +0000
Subject: [R] Reshape to wide format
In-Reply-To: <CAMLwc7NKrgzz9_7nUDaPtKwbcrtv4Vr3BbjRBspW1a=zWZivtw@mail.gmail.com>
References: <CAMLwc7O7kCZbeMXie8irri7Xn564VsSQ-pN2=Y8eGwqYWdXqBQ@mail.gmail.com>
	<CA+8X3fXtsir220YwpgRZ20wktiYRm=Br887SCU_vY3V89ZGYXA@mail.gmail.com>
	<69d5c080a2444e9cafdab13513eca36a@exch-2p-mbx-w2.ads.tamu.edu>
	<CAMLwc7NKrgzz9_7nUDaPtKwbcrtv4Vr3BbjRBspW1a=zWZivtw@mail.gmail.com>
Message-ID: <5cd1e15b15784704b68d39761ffa890f@exch-2p-mbx-w2.ads.tamu.edu>

Your original data does not contain a field called year. This will not give you what you asked for which was a separate row for each month and you have specified month as part of the timevar (columns) and the idvar (rows). Perhaps you want year and month to specify the rows using idvar=c("year", "month")? 

-----------------------------------------------
David L. Carlson
Department of Anthropology
Texas A&M University



From: Miluji Sb [mailto:milujisb at gmail.com] 
Sent: Thursday, December 22, 2016 8:19 AM
To: David L Carlson <dcarlson at tamu.edu>
Cc: Jim Lemon <drjimlemon at gmail.com>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Reshape to wide format

Apologies for the late reply. Thank you very much!

I get the following warnings. If I modify the code to add both month and year as part of the ID, will it still be correct?

df$ID<-paste(df$iso3,df$lon,df$lat,df$year,df$month,sep="")

wide <- reshape(df, v.names="precip", timevar="ID", idvar="month",
? ? ? ? ? ? ? ? direction="wide", ?drop=c("iso3", "lon", "lat", "year"))

Sincerely,

Milu

warnings()
Warning messages:
1: In reshapeWide(data, idvar = idvar, timevar = timevar, ?... :
? some constant variables (year) are really varying
2: In reshapeWide(data, idvar = idvar, timevar = timevar, ?... :
? multiple rows match for ID=AFG6132: first taken
3: In reshapeWide(data, idvar = idvar, timevar = timevar, ?... :
? multiple rows match for ID=AFG6133: first taken
4: In reshapeWide(data, idvar = idvar, timevar = timevar, ?... :
? multiple rows match for ID=AFG6134: first taken

On Tue, Dec 13, 2016 at 6:21 PM, David L Carlson <dcarlson at tamu.edu> wrote:
You can also use function reshape() in stats:

temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
wide <- reshape(temp, v.names="precip", timevar="ID", idvar="month",
? ? ?direction="wide",? drop=c("iso3", "lon", "lat", "dm"))
wide

? ?month precip.AFG6132 precip.AFG6133
1? ? ? 1? ? ? 0.9966658? ? 1.133129032
2? ? ? 2? ? ? 0.1567117? ? 0.355208276
3? ? ? 3? ? ? 0.2424774? ? 0.307277419
4? ? ? 4? ? ? 0.0000000? ? 0.008316000
5? ? ? 5? ? ? 0.0000000? ? 0.000000000
6? ? ? 6? ? ? 0.0000000? ? 0.000000000
7? ? ? 7? ? ? 0.0000000? ? 0.000000000
8? ? ? 8? ? ? 0.0000000? ? 0.000836129
9? ? ? 9? ? ? 0.0000000? ? ? ? ? ? ?NA
10? ? 10? ? ? 0.0000000? ? ? ? ? ? ?NA
11? ? 11? ? ? 0.1215360? ? ? ? ? ? ?NA
12? ? 12? ? ? 0.3886606? ? ? ? ? ? ?NA

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Tuesday, December 13, 2016 2:59 AM
To: Miluji Sb; r-help mailing list
Subject: Re: [R] Reshape to wide format

Hi Milu,
I may have the wrong idea, but is this what you want?

temp$ID<-paste(temp$iso3,temp$lon,temp$lat,sep="")
library(prettyR)
newtemp<-stretch_df(temp,"month","precip")[,c(5,7,8)]
names(newtemp)<-c("month",unique(temp$ID))

Jim


On Tue, Dec 13, 2016 at 4:10 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have the following monthly data by coordinates:
>
> I would like to reshape this data to wide format so that each column is a
> coordinate and each row is a month,
>
> coordinate1 coordinate2 coordinate3...
> Month 1
> Month 2
>
> Is the best option to concatenate the iso3, lon, and lat variables to
> create an ID variable? I realize that this question might be very basic but
> I'm slightly baffled. Thank you.
>
> temp <- dput(head(precip_2000,20))
> structure(list(iso3 = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("AFG",
> "AGO", "ALB", "ARE", "ARG", "ARM", "AUS", "AUT", "AZE", "BDI",
> "BEL", "BEN", "BFA", "BGD", "BGR", "BHS", "BIH", "BLR", "BLZ",
> "BOL", "BRA", "BRN", "BTN", "BWA", "CAF", "CAN", "CHE", "CHL",
> "CHN", "CIV", "CMR", "COD", "COG", "COL", "CRI", "CUB", "CYP",
> "CZE", "DEU", "DJI", "DNK", "DOM", "DZA", "ECU", "EGY", "ERI",
> "ESH", "ESP", "EST", "ETH", "FIN", "FJI", "FLK", "FRA", "GAB",
> "GBR", "GEO", "GHA", "GIN", "GNB", "GNQ", "GRC", "GRL", "GTM",
> "GUF", "GUY", "HND", "HRV", "HTI", "HUN", "IDN", "IND", "IRL",
> "IRN", "IRQ", "ISL", "ISR", "ITA", "JAM", "JOR", "JPN", "KAZ",
> "KEN", "KGZ", "KHM", "KIR", "KOR", "KWT", "LAO", "LBN", "LBR",
> "LBY", "LCA", "LKA", "LSO", "LTU", "LUX", "LVA", "MAR", "MDA",
> "MDG", "MEX", "MKD", "MLI", "MMR", "MNE", "MNG", "MOZ", "MRT",
> "MWI", "MYS", "NAM", "NCL", "NER", "NGA", "NIC", "NLD", "NOR",
> "NPL", "NZL", "OMN", "PAK", "PAN", "PER", "PHL", "PNG", "POL",
> "PRI", "PRK", "PRT", "PRY", "QAT", "ROU", "RUS", "RWA", "SAU",
> "SDN", "SEN", "SJM", "SLB", "SLE", "SLV", "SOM", "SRB", "SUR",
> "SVK", "SVN", "SWE", "SWZ", "SYR", "TCD", "TGO", "THA", "TJK",
> "TKM", "TLS", "TUN", "TUR", "TWN", "TZA", "UGA", "UKR", "URY",
> "USA", "UZB", "VEN", "VNM", "VUT", "YEM", "ZAF", "ZMB", "ZWE"
> ), class = "factor"), lon = c(61L, 61L, 61L, 61L, 61L, 61L, 61L,
> 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L, 61L
> ), lat = c(32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L, 32L,
> 32L, 32L, 33L, 33L, 33L, 33L, 33L, 33L, 33L, 33L), dm = structure(c(1L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 2L, 3L, 4L, 1L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L), .Label = c("2000m1", "2000m10", "2000m11",
> "2000m12", "2000m2", "2000m3", "2000m4", "2000m5", "2000m6",
> "2000m7", "2000m8", "2000m9"), class = "factor"), month = c(1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L), precip = c(0.996665806451613, 0.156711724137931,
> 0.242477419354839, 0, 0, 0, 0, 0, 0, 0, 0.121536, 0.38866064516129,
> 1.13312903225806, 0.355208275862069, 0.307277419354839, 0.008316,
> 0, 0, 0, 0.0008361290322581)), .Names = c("iso3", "lon", "lat",
> "dm", "month", "precip"), row.names = c(NA, 20L), class = "data.frame")
>
> Sincerely,
>
> Milu
>
>? ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Wed Dec 28 19:57:53 2016
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 28 Dec 2016 12:57:53 -0600
Subject: [R] Rbbg usurped ?
In-Reply-To: <CAA3Wa=vdRYxk89fXwewk5KywTMV630KQAW00h_xKDchrPe3KVg@mail.gmail.com>
References: <68a83ee8-f837-d4e9-f24d-f2a82effd467@coubros.com>
	<CAM_vju=0XBB-0KSwb6e_LSAdCLVZk3hQqoKOQhSgwyRobOr5tA@mail.gmail.com>
	<CAA3Wa=vdRYxk89fXwewk5KywTMV630KQAW00h_xKDchrPe3KVg@mail.gmail.com>
Message-ID: <22628.2865.488148.770432@max.nulle.part>


On 28 December 2016 at 13:46, John Laing wrote:
| I've cleaned up the findata repository, you should now be able to install
| Rbbg as expected.
| 
| But that said, the package is no longer being actively developed. Recent
| efforts have been taking place in the Rblpapi package. The interface is
| similar, though not strictly compatible. If you're doing much work with
| Bloomberg data I recommend you check it out.

Also, Rblpapi is on CRAN and installs like other packages via

    install.packages("Rblpapi")

and update.packages() relieving you from the need to go to findata.org.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From bgunter.4567 at gmail.com  Wed Dec 28 22:56:00 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Dec 2016 13:56:00 -0800
Subject: [R] Predictive analysis based on past data
In-Reply-To: <f25699153d1a48b7af2a1e1286f05577@bwinparty.com>
References: <f25699153d1a48b7af2a1e1286f05577@bwinparty.com>
Message-ID: <CAGxFJbSt_3wq5zm5R9e3cuiBPRKCBY7G5pUr+kf7ai8SWKcE=g@mail.gmail.com>

This list is about R programming, not statistical methodology,
although there is sometimes an overlap. You should do better posting
to a statistics list like stats.stackexchange.com for queries about
statistics. Although it looks like you may need to do some studying in
a basic regression methods text or online tutorial.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 28, 2016 at 2:23 AM, Winson Lui <Winson.Lui at bwinparty.com> wrote:
> HI,
>
> I have a historical dataset which tells who bought our products. This dataset contains ID, Age, Gender and Salary.
> I have another set of data which contains the four fields above.
> How should I use R to calculate the probability of purchase of each customer in the second dataset or whether they would buy our products (T/F)?
> Should I use glm function? If yes, how should I approach this?
> Thanks.
>
> Regards,
> Winson Lui
> Business Analyst
> M: +44 (0) 79 1714 6247
> E: winson.lui at bwinparty.com<mailto:winson.lui at bwinparty.com>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sidoti.23 at buckeyemail.osu.edu  Wed Dec 28 21:11:33 2016
From: sidoti.23 at buckeyemail.osu.edu (Sidoti, Salvatore A.)
Date: Wed, 28 Dec 2016 20:11:33 +0000
Subject: [R] Interpolating Splines: Equidistant Points
Message-ID: <BLUPR0101MB1474E58A94CD0FA3E6F564DDAB680@BLUPR0101MB1474.prod.exchangelabs.com>

I am attempting to smooth the jagged paths of animal tracks to determine their distances with greater accuracy. The data is in the form of (x,y) 2D coordinates. My end goal is to produce a set of interpolating points whereby their Cartesian distances are equal to each other. So far, I have been able to produce a path with a specified number of interpolating points via spline(). However, these points are not equidistant.

An example data set and my code thus far:

df <- structure(list(x = c(329L, 329L, 329L, 329L, 330L, 330L, 330L, 
330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 
330L, 330L, 330L, 330L, 331L, 331L, 331L, 332L, 332L, 333L, 333L, 
333L, 333L, 333L, 333L, 333L, 333L, 333L, 333L, 333L, 334L, 334L, 
334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 
334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 
334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 
334L, 334L, 334L, 334L, 334L, 334L, 334L, 333L, 333L, 332L, 332L, 
332L, 332L, 332L, 332L, 333L, 333L, 333L, 332L, 333L, 331L, 331L, 
330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 329L, 329L, 329L, 
329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 
329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 328L, 
327L, 327L, 327L, 327L, 327L, 326L, 326L, 325L, 325L, 325L, 325L, 
325L, 323L, 322L, 321L, 320L, 319L, 319L, 319L, 319L, 319L, 319L
), y = c(255L, 256L, 256L, 256L, 257L, 257L, 257L, 257L, 257L, 
257L, 257L, 257L, 257L, 257L, 258L, 259L, 259L, 259L, 261L, 261L, 
262L, 263L, 263L, 264L, 265L, 266L, 266L, 267L, 268L, 269L, 270L, 
272L, 272L, 273L, 274L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 
275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 
276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 
276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 
276L, 276L, 276L, 276L, 277L, 278L, 278L, 279L, 280L, 281L, 283L, 
284L, 285L, 287L, 288L, 290L, 291L, 291L, 294L, 295L, 297L, 298L, 
299L, 300L, 301L, 302L, 302L, 304L, 305L, 306L, 306L, 308L, 308L, 
308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 
308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 309L, 
310L, 311L, 311L, 312L, 313L, 314L, 315L, 318L, 319L, 320L, 322L, 
323L, 324L, 325L, 325L, 325L, 325L, 326L, 326L, 327L)), .Names = c("x", 
"y"), row.names = c(NA, -150L), class = "data.frame")

require(Momocs)

cumdist <- coo_perimcum(df)
sx <- spline(cumdist, df[, 1], method = "natural", n = 10)
sy <- spline(cumdist, df[, 2], method = "natural", n = 10)
splines <- cbind.data.frame(x = sx$y, y = sy$y)

par(pty = "s")
with(df, plot(x, y, main = "Example Locomotor Path - Cubic Spline Smoothing",
              axes = FALSE, frame.plot = TRUE, type = "l", col = "light gray", lwd = 3))
with(splines, lines(x, y, type = "b", col = "red", lwd = 3))

Thank you!

Salvatore A. Sidoti
PhD Student
Behavioral Ecology


From vikash.kr.117 at gmail.com  Wed Dec 28 22:02:20 2016
From: vikash.kr.117 at gmail.com (Vikash Kumar)
Date: Thu, 29 Dec 2016 02:32:20 +0530
Subject: [R] Predictive analysis based on past data
In-Reply-To: <f25699153d1a48b7af2a1e1286f05577@bwinparty.com>
References: <f25699153d1a48b7af2a1e1286f05577@bwinparty.com>
Message-ID: <CAALD-gi7bs7i_zwaH=31nBm7jn+CoapXp3J3nQZ3nw2=zAu_3Q@mail.gmail.com>

Collaborative filtering will be helpful.

Regards,
Vikash


On Wed, Dec 28, 2016 at 3:53 PM, Winson Lui <Winson.Lui at bwinparty.com>
wrote:

> HI,
>
> I have a historical dataset which tells who bought our products. This
> dataset contains ID, Age, Gender and Salary.
> I have another set of data which contains the four fields above.
> How should I use R to calculate the probability of purchase of each
> customer in the second dataset or whether they would buy our products (T/F)?
> Should I use glm function? If yes, how should I approach this?
> Thanks.
>
> Regards,
> Winson Lui
> Business Analyst
> M: +44 (0) 79 1714 6247
> E: winson.lui at bwinparty.com<mailto:winson.lui at bwinparty.com>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bryanmac.24 at gmail.com  Wed Dec 28 22:45:25 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Wed, 28 Dec 2016 13:45:25 -0800
Subject: [R] Export R output in Excel
Message-ID: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>

Hi,

How do I export results from R to Excel in a format-friendly way? For example, when I copy and paste my results into excel, the formatting is messed up.

Thanks.
 
Bryan Mac
bryanmac.24 at gmail.com


From r.turner at auckland.ac.nz  Thu Dec 29 00:15:42 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 29 Dec 2016 12:15:42 +1300
Subject: [R] [FORGED]  Export R output in Excel
In-Reply-To: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
Message-ID: <40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>

On 29/12/16 10:45, Bryan Mac wrote:
> Hi,
>
> How do I export results from R to Excel in a format-friendly way? For
> example, when I copy and paste my results into excel, the formatting
> is messed up.


Short answer:  *Don't*.  ("Friends don't let friends use excel for 
statistics.")

Longer answer:  Googling on "export R data to excel" yields lots of 
"useful" hits --- "useful" given the (false) assertion that it is useful 
to export things to excel.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Thu Dec 29 00:56:26 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Dec 2016 15:56:26 -0800
Subject: [R] Interpolating Splines: Equidistant Points
In-Reply-To: <BLUPR0101MB1474E58A94CD0FA3E6F564DDAB680@BLUPR0101MB1474.prod.exchangelabs.com>
References: <BLUPR0101MB1474E58A94CD0FA3E6F564DDAB680@BLUPR0101MB1474.prod.exchangelabs.com>
Message-ID: <CAGxFJbSt5w1egaH0Vy0gh8hoxj0bv_=dXL2uxD9_mLqAkcWM+Q@mail.gmail.com>

I think this is really a statistical issue, not a general r
programming issue, which is what r-help is about.

I think a much better target for this post would be the r-sig-geo
list, where you likely would find the expertise you need.
r-sig-ecology might also work, so you should probably check this out
also.

Cheers,
Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Dec 28, 2016 at 12:11 PM, Sidoti, Salvatore A.
<sidoti.23 at buckeyemail.osu.edu> wrote:
> I am attempting to smooth the jagged paths of animal tracks to determine their distances with greater accuracy. The data is in the form of (x,y) 2D coordinates. My end goal is to produce a set of interpolating points whereby their Cartesian distances are equal to each other. So far, I have been able to produce a path with a specified number of interpolating points via spline(). However, these points are not equidistant.
>
> An example data set and my code thus far:
>
> df <- structure(list(x = c(329L, 329L, 329L, 329L, 330L, 330L, 330L,
> 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L,
> 330L, 330L, 330L, 330L, 331L, 331L, 331L, 332L, 332L, 333L, 333L,
> 333L, 333L, 333L, 333L, 333L, 333L, 333L, 333L, 333L, 334L, 334L,
> 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L,
> 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L,
> 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L, 334L,
> 334L, 334L, 334L, 334L, 334L, 334L, 334L, 333L, 333L, 332L, 332L,
> 332L, 332L, 332L, 332L, 333L, 333L, 333L, 332L, 333L, 331L, 331L,
> 330L, 330L, 330L, 330L, 330L, 330L, 330L, 330L, 329L, 329L, 329L,
> 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L,
> 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 329L, 328L,
> 327L, 327L, 327L, 327L, 327L, 326L, 326L, 325L, 325L, 325L, 325L,
> 325L, 323L, 322L, 321L, 320L, 319L, 319L, 319L, 319L, 319L, 319L
> ), y = c(255L, 256L, 256L, 256L, 257L, 257L, 257L, 257L, 257L,
> 257L, 257L, 257L, 257L, 257L, 258L, 259L, 259L, 259L, 261L, 261L,
> 262L, 263L, 263L, 264L, 265L, 266L, 266L, 267L, 268L, 269L, 270L,
> 272L, 272L, 273L, 274L, 275L, 275L, 275L, 275L, 275L, 275L, 275L,
> 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L, 275L,
> 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L,
> 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L, 276L,
> 276L, 276L, 276L, 276L, 277L, 278L, 278L, 279L, 280L, 281L, 283L,
> 284L, 285L, 287L, 288L, 290L, 291L, 291L, 294L, 295L, 297L, 298L,
> 299L, 300L, 301L, 302L, 302L, 304L, 305L, 306L, 306L, 308L, 308L,
> 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L,
> 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 308L, 309L,
> 310L, 311L, 311L, 312L, 313L, 314L, 315L, 318L, 319L, 320L, 322L,
> 323L, 324L, 325L, 325L, 325L, 325L, 326L, 326L, 327L)), .Names = c("x",
> "y"), row.names = c(NA, -150L), class = "data.frame")
>
> require(Momocs)
>
> cumdist <- coo_perimcum(df)
> sx <- spline(cumdist, df[, 1], method = "natural", n = 10)
> sy <- spline(cumdist, df[, 2], method = "natural", n = 10)
> splines <- cbind.data.frame(x = sx$y, y = sy$y)
>
> par(pty = "s")
> with(df, plot(x, y, main = "Example Locomotor Path - Cubic Spline Smoothing",
>               axes = FALSE, frame.plot = TRUE, type = "l", col = "light gray", lwd = 3))
> with(splines, lines(x, y, type = "b", col = "red", lwd = 3))
>
> Thank you!
>
> Salvatore A. Sidoti
> PhD Student
> Behavioral Ecology
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Thu Dec 29 01:05:14 2016
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 29 Dec 2016 13:05:14 +1300
Subject: [R] [FORGED]  Export R output in Excel
In-Reply-To: <B6A7478E-13AE-48DD-B8E7-74F59B79FF23@gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
	<B6A7478E-13AE-48DD-B8E7-74F59B79FF23@gmail.com>
Message-ID: <213ea99c-2e21-5581-7f6e-1dd08b5cab1f@auckland.ac.nz>

On 29/12/16 12:48, Bryan Mac wrote:
> Hi Rolf,
>
> I wanted to export the output/results of R to an Excel file for
> easier comparisons/reporting. When I tried to copy and paste my
> output to an excel file the formatting was off. I want to export my
> descriptive stats and the linear regression.

This makes little to no sense to me.  Spreadsheets are for use in 
storing data, not for displaying the output of analyses.  (I know that 
Excel users do this sort of thing, but then people do all sorts of 
irrational things.)

> I googled ?Export R output to excel? but did not find most of the
> hints ?useful?. if anything, it got me more confused.
>
> Thanks.

(1) The best advice is still "*Don't*."

(2) You do not need Excel to make comparisons and report.  In fact it is 
a handicap.  Re-think your strategy.

(3) If you insist in proceeding in a wrong-headed manner, isn't the item 
about XLConnect (3rd answer, 1st hit) "useful"?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bryanmac.24 at gmail.com  Thu Dec 29 00:48:11 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Wed, 28 Dec 2016 15:48:11 -0800
Subject: [R] [FORGED]  Export R output in Excel
In-Reply-To: <40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
Message-ID: <B6A7478E-13AE-48DD-B8E7-74F59B79FF23@gmail.com>

Hi Rolf,

I wanted to export the output/results of R to an Excel file for easier comparisons/reporting. When I tried to copy and paste my output to an excel file the formatting was off.
I want to export my descriptive stats and the linear regression.

I googled ?Export R output to excel? but did not find most of the hints ?useful?. if anything, it got me more confused. 

Thanks.

Bryan Mac
bryanmac.24 at gmail.com



> On Dec 28, 2016, at 3:15 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 29/12/16 10:45, Bryan Mac wrote:
>> Hi,
>> 
>> How do I export results from R to Excel in a format-friendly way? For
>> example, when I copy and paste my results into excel, the formatting
>> is messed up.
> 
> 
> Short answer:  *Don't*.  ("Friends don't let friends use excel for statistics.")
> 
> Longer answer:  Googling on "export R data to excel" yields lots of "useful" hits --- "useful" given the (false) assertion that it is useful to export things to excel.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From drjimlemon at gmail.com  Thu Dec 29 03:33:21 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 29 Dec 2016 13:33:21 +1100
Subject: [R] Export R output in Excel
In-Reply-To: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
Message-ID: <CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>

Hi Bryan,
When I have to do something like this, I usually go through HTML
output and import it into MS Word. I am not suggesting that this is
the best thing to do, but it might get you out of trouble. I'm not
sure whether importing HTML into Excel will work as well. I assume
that you are running analyses in R and want to export the output that
appears in the console window. If so, try producing HTML output with
the prettyR or R2HTML packages and importing it. There are other ways
to do this, but the learning curve is steep and you might not want to
climb it right now.

Jim


On Thu, Dec 29, 2016 at 8:45 AM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
> Hi,
>
> How do I export results from R to Excel in a format-friendly way? For example, when I copy and paste my results into excel, the formatting is messed up.
>
> Thanks.
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Thu Dec 29 03:50:34 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Wed, 28 Dec 2016 21:50:34 -0500
Subject: [R] How to overlay lines and rectangles in lattice plot key
Message-ID: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>

Hi,

I would like to create a custom key for a lattice xyplot in which line 
elements are displayed on top of rectangle elements. In the example code 
below, the lines and rectangles are shown side by side (the legend 
itself is meaningless, but that is not the point). Is there a way to 
overlay these key elements (but not the text)?

Thanks

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   key = list(
     column=4,
     text=list(lab=letters[1:4]),
     lines=list(col=1:4, pch=1:4, type='b'),
     rectangles=list(col=1:4, alpha=0.25, border=FALSE)
   )
)


From oma.gonzales at gmail.com  Thu Dec 29 05:27:19 2016
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Wed, 28 Dec 2016 23:27:19 -0500
Subject: [R] Export R output in Excel
In-Reply-To: <CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>
Message-ID: <CAM-xyZjgAq_5xLGv6KAhzy_F=k3xDrG3mOMWXwwuHLGk_0FU=g@mail.gmail.com>

use "write.csv("you-df", "name-of-file.csv", row.names = FALSE).

And Google please, as others have suggested.

2016-12-28 21:33 GMT-05:00 Jim Lemon <drjimlemon at gmail.com>:

> Hi Bryan,
> When I have to do something like this, I usually go through HTML
> output and import it into MS Word. I am not suggesting that this is
> the best thing to do, but it might get you out of trouble. I'm not
> sure whether importing HTML into Excel will work as well. I assume
> that you are running analyses in R and want to export the output that
> appears in the console window. If so, try producing HTML output with
> the prettyR or R2HTML packages and importing it. There are other ways
> to do this, but the learning curve is steep and you might not want to
> climb it right now.
>
> Jim
>
>
> On Thu, Dec 29, 2016 at 8:45 AM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
> > Hi,
> >
> > How do I export results from R to Excel in a format-friendly way? For
> example, when I copy and paste my results into excel, the formatting is
> messed up.
> >
> > Thanks.
> >
> > Bryan Mac
> > bryanmac.24 at gmail.com
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Dec 29 06:00:35 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 28 Dec 2016 21:00:35 -0800
Subject: [R] How to overlay lines and rectangles in lattice plot key
In-Reply-To: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
Message-ID: <C05C3FB6-2BD8-48D8-9FCD-91C86704DA9F@comcast.net>


> On Dec 28, 2016, at 6:50 PM, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
> 
> Hi,
> 
> I would like to create a custom key for a lattice xyplot in which line elements are displayed on top of rectangle elements. In the example code below, the lines and rectangles are shown side by side (the legend itself is meaningless, but that is not the point). Is there a way to overlay these key elements (but not the text)?
> 
> Thanks
> 
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
>  iris,
>  type = c("p", "r"),
>  jitter.x = TRUE,
>  jitter.y = TRUE,
>  factor = 5,
>  key = list(
>    column=4,
>    text=list(lab=letters[1:4]),
>    lines=list(col=1:4, pch=1:4, type='b'),
>    rectangles=list(col=1:4, alpha=0.25, border=FALSE)
>  )
> )

I'm not seeing the result that you describe. Attached is the pdf that comes from:

 pdf(); print( xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
 iris,
 type = c("p", "r"),
 jitter.x = TRUE,
 jitter.y = TRUE,
 factor = 5,
 key = list(
   column=4,
   text=list(lab=letters[1:4]),
   lines=list(col=1:4, pch=1:4, type='b'),
   rectangles=list(col=1:4, alpha=0.25, border=FALSE)
 )
) ); dev.off()

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplots.pdf
Type: application/pdf
Size: 10022 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161228/4a4ed380/attachment.pdf>
-------------- next part --------------


-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Dec 29 06:09:55 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 28 Dec 2016 21:09:55 -0800
Subject: [R] Need Help, Unable to find the problem in R Script
In-Reply-To: <20161228032852.24673.qmail@f6mail-235-207.rediffmail.com>
References: <20161228032852.24673.qmail@f6mail-235-207.rediffmail.com>
Message-ID: <8AB06696-1593-421A-BC6E-28DA8585BD77@comcast.net>


> On Dec 27, 2016, at 7:28 PM, amit rathee <amit1983_rathee at rediffmail.com> wrote:
> 
> R/Sir,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i am trying to find precision and recall value for multi class software clustering problem using package &quot;ClusterCrit&quot;i have attached my source code &quot;Clustering.txt&quot; and input files &quot;ClassCoupling.txt&quot; &amp; &quot;JUnitGoldStandard&quot;in my script for different combination of clustering i am getting same value of precision &amp; recall, which i think should not be?Kindly helpThanks in advanceAMIT RATHEEResearch Scholar


> <Clustering.txt>

> <ClassCouplingData.txt>

You posted two files with a difficult to parse message. You should ask _yourself_ whether a person who saved those two files to his working directory could expect that code file to actually process that data file. I seriously doubt that effort would be successful.


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Thu Dec 29 06:13:47 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 29 Dec 2016 00:13:47 -0500
Subject: [R] How to overlay lines and rectangles in lattice plot key
In-Reply-To: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
Message-ID: <CAGx1TMBjaXtrY_jmG-43U2Z_=KqYAJHMpfqz33hTfaeS=QGFtQ@mail.gmail.com>

Yes, but it will probably require work.  I think you will need to
write a grob that does what you want
and then use the grob in a legend statement in the xyplot.

Start with the 'legend' argument to xyplot (about line 940 in ?xyplot).
You will probably need to work directly with grid functions and will
find Paul Murrell's book very helpful.
https://www.crcpress.com/R-Graphics/Murrell/p/book/9781584884866

Rich

On Wed, Dec 28, 2016 at 9:50 PM, sbihorel
<Sebastien.Bihorel at cognigencorp.com> wrote:
> Hi,
>
> I would like to create a custom key for a lattice xyplot in which line
> elements are displayed on top of rectangle elements. In the example code
> below, the lines and rectangles are shown side by side (the legend itself is
> meaningless, but that is not the point). Is there a way to overlay these key
> elements (but not the text)?
>
> Thanks
>
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
>   iris,
>   type = c("p", "r"),
>   jitter.x = TRUE,
>   jitter.y = TRUE,
>   factor = 5,
>   key = list(
>     column=4,
>     text=list(lab=letters[1:4]),
>     lines=list(col=1:4, pch=1:4, type='b'),
>     rectangles=list(col=1:4, alpha=0.25, border=FALSE)
>   )
> )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Dec 29 06:16:43 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 29 Dec 2016 16:16:43 +1100
Subject: [R] How to overlay lines and rectangles in lattice plot key
In-Reply-To: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
Message-ID: <001801d26192$be8ee140$3baca3c0$@bigpond.com>

Hi

Is this something like what you are looking for?
I have put it on the right and heights etc are just a quick guess. (all i
have time for)
It may be a little too complicated for what you want but I thought  of this
first based on your description rather than the plot.

library(grid)
library(lattice)

# legend
XY04.glay <-
grid.layout(nrow = 8,
            ncol = 2,
            heights = unit(rep(1, 2), rep("cm", 2)),
            widths  = unit(c(0.4, 0.8),
                           c("in","in")),
            just = "centre")

XY04.fmG <- frameGrob(layout = XY04.glay)

k <-0
for (j in seq(1,8,2)){
  k = k+1
  
  XY04.fmG <-
  placeGrob(XY04.fmG, textGrob(lab = letters[1:4][k],
                             just = 0,
                             gp = gpar(cex = 0.8)), row = j, col = 1)
  XY04.fmG <-
  placeGrob(XY04.fmG, linesGrob(c(0.2,0.8),  c(0.5, 0.5),
                              gp = gpar(col = c(1:4)[k])), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, pointsGrob(c(0.2,0.8),  c(0.5, 0.5),
                              pch = j,
                              gp = gpar(cex = 0.7, col = c(1:4)[k])), row =
j, col = 2)
}
k = 0
for (j in seq(2,8,2)){
  k = k+1
  XY04.fmG <-
  placeGrob(XY04.fmG, rectGrob(width = 0.6,
                               gp = gpar(col=k,
                                         alpha = 0.25,
                                         fill = k)), row = j, col = 2)

}

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   legend = list(right = list(fun = XY04.fmG))
)


Have a look at https://stat.ethz.ch/pipermail/r-help/2005-April/069459.html
and the following emails on the thread.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sbihorel
Sent: Thursday, 29 December 2016 13:51
To: r-help at r-project.org
Subject: [R] How to overlay lines and rectangles in lattice plot key

Hi,

I would like to create a custom key for a lattice xyplot in which line 
elements are displayed on top of rectangle elements. In the example code 
below, the lines and rectangles are shown side by side (the legend 
itself is meaningless, but that is not the point). Is there a way to 
overlay these key elements (but not the text)?

Thanks

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   key = list(
     column=4,
     text=list(lab=letters[1:4]),
     lines=list(col=1:4, pch=1:4, type='b'),
     rectangles=list(col=1:4, alpha=0.25, border=FALSE)
   )
)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Thu Dec 29 06:53:48 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 29 Dec 2016 00:53:48 -0500
Subject: [R] How to overlay lines and rectangles in lattice plot key
In-Reply-To: <001801d26192$be8ee140$3baca3c0$@bigpond.com>
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
	<001801d26192$be8ee140$3baca3c0$@bigpond.com>
Message-ID: <CAGx1TMANtwuZGBJnRVwHQwhGaJO9Gq-iJMewbv5h+=VgEA-ziw@mail.gmail.com>

I think the intended appearance is closer to this

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
  iris,
  type = c("p", "r"),
  jitter.x = TRUE,
  jitter.y = TRUE,
  factor = 5,
  key = list(between=c(-4.5),
    column=4,
    text=list(lab=paste0("       ", letters[1:4], "           ")),
    lines=list(col=1:4, pch=1:4, type='b'),
    rectangles=list(col=1:4, alpha=0.25, border=FALSE)
  )
)

I have the partial overlap of the rectangles and the line-point objects.
They don't align correctly.  I think even more complex grid usage is needed than
Duncan provided.

Rich


On Thu, Dec 29, 2016 at 12:16 AM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> Hi
>
> Is this something like what you are looking for?
> I have put it on the right and heights etc are just a quick guess. (all i
> have time for)
> It may be a little too complicated for what you want but I thought  of this
> first based on your description rather than the plot.
>
> library(grid)
> library(lattice)
>
> # legend
> XY04.glay <-
> grid.layout(nrow = 8,
>             ncol = 2,
>             heights = unit(rep(1, 2), rep("cm", 2)),
>             widths  = unit(c(0.4, 0.8),
>                            c("in","in")),
>             just = "centre")
>
> XY04.fmG <- frameGrob(layout = XY04.glay)
>
> k <-0
> for (j in seq(1,8,2)){
>   k = k+1
>
>   XY04.fmG <-
>   placeGrob(XY04.fmG, textGrob(lab = letters[1:4][k],
>                              just = 0,
>                              gp = gpar(cex = 0.8)), row = j, col = 1)
>   XY04.fmG <-
>   placeGrob(XY04.fmG, linesGrob(c(0.2,0.8),  c(0.5, 0.5),
>                               gp = gpar(col = c(1:4)[k])), row = j, col = 2)
>   XY04.fmG <-
>   placeGrob(XY04.fmG, pointsGrob(c(0.2,0.8),  c(0.5, 0.5),
>                               pch = j,
>                               gp = gpar(cex = 0.7, col = c(1:4)[k])), row =
> j, col = 2)
> }
> k = 0
> for (j in seq(2,8,2)){
>   k = k+1
>   XY04.fmG <-
>   placeGrob(XY04.fmG, rectGrob(width = 0.6,
>                                gp = gpar(col=k,
>                                          alpha = 0.25,
>                                          fill = k)), row = j, col = 2)
>
> }
>
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
>    iris,
>    type = c("p", "r"),
>    jitter.x = TRUE,
>    jitter.y = TRUE,
>    factor = 5,
>    legend = list(right = list(fun = XY04.fmG))
> )
>
>
> Have a look at https://stat.ethz.ch/pipermail/r-help/2005-April/069459.html
> and the following emails on the thread.
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sbihorel
> Sent: Thursday, 29 December 2016 13:51
> To: r-help at r-project.org
> Subject: [R] How to overlay lines and rectangles in lattice plot key
>
> Hi,
>
> I would like to create a custom key for a lattice xyplot in which line
> elements are displayed on top of rectangle elements. In the example code
> below, the lines and rectangles are shown side by side (the legend
> itself is meaningless, but that is not the point). Is there a way to
> overlay these key elements (but not the text)?
>
> Thanks
>
> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
>    iris,
>    type = c("p", "r"),
>    jitter.x = TRUE,
>    jitter.y = TRUE,
>    factor = 5,
>    key = list(
>      column=4,
>      text=list(lab=letters[1:4]),
>      lines=list(col=1:4, pch=1:4, type='b'),
>      rectangles=list(col=1:4, alpha=0.25, border=FALSE)
>    )
> )
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Dec 29 08:14:24 2016
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 29 Dec 2016 07:14:24 +0000
Subject: [R] Export R output in Excel
In-Reply-To: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB9D4@SRVEXCHCM301.precheza.cz>

Hi

For rectangular data

write.table(tab, "clipboard", sep = "\t", row.names = F)
followed by Ctrl-V in Excel

or
write.table(tab, "somefile.xls", sep = "\t", row.names = F)

For free format output like summary(somefit) I prefer to copy it to Word and use font like  Courier New with monospaced letters

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bryan Mac
> Sent: Wednesday, December 28, 2016 10:45 PM
> To: R-help at r-project.org
> Subject: [R] Export R output in Excel
>
> Hi,
>
> How do I export results from R to Excel in a format-friendly way? For
> example, when I copy and paste my results into excel, the formatting is
> messed up.
>
> Thanks.
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dulcalma at bigpond.com  Thu Dec 29 08:20:47 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 29 Dec 2016 18:20:47 +1100
Subject: [R] How to overlay lines and rectangles in lattice plot key
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com> 
Message-ID: <000001d261a4$13843d10$3a8cb730$@bigpond.com>

Hi 

It makes it easier

library(grid)
library(lattice)

# legend
XY04.glay <-
grid.layout(nrow = 4,
            ncol = 2,
            heights = unit(rep(1, 2), rep("cm", 2)),
            widths  = unit(c(0.4, 0.8),
                           c("in","in")),
            just = "centre")

XY04.fmG <- frameGrob(layout = XY04.glay)

k <-0
for (j in seq_len(4)){

  XY04.fmG <-
  placeGrob(XY04.fmG, textGrob(lab = letters[j],
                             just = 0,
                             gp = gpar(cex = 0.8)), row = j, col = 1)
  XY04.fmG <-
  placeGrob(XY04.fmG, rectGrob(width = 0.6,
                               gp = gpar(col=j,
                                         alpha = 0.25,
                                         fill = j)), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, linesGrob(c(0.2,0.8),  c(0.5, 0.5),
                              gp = gpar(col = j)), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, pointsGrob(x = unit(1, "cm"), y = unit(0.5, "npc"),
                              pch = j,
                              #width = unit(2, "cm"),
                              gp = gpar(cex = 0.7, col = j)), row = j, col =
2)
}

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   legend = list(right = list(fun = XY04.fmG))
)

This gives 1 point instead of 2 or 3.
The OP needs to change the format and fix the heights of the rectangles etc.
I also fixed the colour vectors had j instead of k


Duncan

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Thursday, 29 December 2016 16:17
To: R
Subject: RE: [R] How to overlay lines and rectangles in lattice plot key

Hi

Is this something like what you are looking for?
I have put it on the right and heights etc are just a quick guess. (all i
have time for)
It may be a little too complicated for what you want but I thought  of this
first based on your description rather than the plot.

library(grid)
library(lattice)

# legend
XY04.glay <-
grid.layout(nrow = 8,
            ncol = 2,
            heights = unit(rep(1, 2), rep("cm", 2)),
            widths  = unit(c(0.4, 0.8),
                           c("in","in")),
            just = "centre")

XY04.fmG <- frameGrob(layout = XY04.glay)

k <-0
for (j in seq(1,8,2)){
  k = k+1
  
  XY04.fmG <-
  placeGrob(XY04.fmG, textGrob(lab = letters[1:4][k],
                             just = 0,
                             gp = gpar(cex = 0.8)), row = j, col = 1)
  XY04.fmG <-
  placeGrob(XY04.fmG, linesGrob(c(0.2,0.8),  c(0.5, 0.5),
                              gp = gpar(col = c(1:4)[k])), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, pointsGrob(c(0.2,0.8),  c(0.5, 0.5),
                              pch = j,
                              gp = gpar(cex = 0.7, col = c(1:4)[k])), row =
j, col = 2)
}
k = 0
for (j in seq(2,8,2)){
  k = k+1
  XY04.fmG <-
  placeGrob(XY04.fmG, rectGrob(width = 0.6,
                               gp = gpar(col=k,
                                         alpha = 0.25,
                                         fill = k)), row = j, col = 2)

}

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   legend = list(right = list(fun = XY04.fmG))
)


Have a look at https://stat.ethz.ch/pipermail/r-help/2005-April/069459.html
and the following emails on the thread.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sbihorel
Sent: Thursday, 29 December 2016 13:51
To: r-help at r-project.org
Subject: [R] How to overlay lines and rectangles in lattice plot key

Hi,

I would like to create a custom key for a lattice xyplot in which line 
elements are displayed on top of rectangle elements. In the example code 
below, the lines and rectangles are shown side by side (the legend 
itself is meaningless, but that is not the point). Is there a way to 
overlay these key elements (but not the text)?

Thanks

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   key = list(
     column=4,
     text=list(lab=letters[1:4]),
     lines=list(col=1:4, pch=1:4, type='b'),
     rectangles=list(col=1:4, alpha=0.25, border=FALSE)
   )
)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From tolga at coubros.com  Thu Dec 29 08:22:21 2016
From: tolga at coubros.com (Tolga Uzuner)
Date: Thu, 29 Dec 2016 10:22:21 +0300
Subject: [R] Rbbg usurped ?
In-Reply-To: <22628.2865.488148.770432@max.nulle.part>
References: <68a83ee8-f837-d4e9-f24d-f2a82effd467@coubros.com>
	<CAM_vju=0XBB-0KSwb6e_LSAdCLVZk3hQqoKOQhSgwyRobOr5tA@mail.gmail.com>
	<CAA3Wa=vdRYxk89fXwewk5KywTMV630KQAW00h_xKDchrPe3KVg@mail.gmail.com>
	<22628.2865.488148.770432@max.nulle.part>
Message-ID: <9D1756BA-EABE-4A6E-A76D-36C87CE045D7@coubros.com>

Many thanks John, Bush, Dirk.

Kind regards

> On Dec 28, 2016, at 9:57 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
> 
> 
> On 28 December 2016 at 13:46, John Laing wrote:
> | I've cleaned up the findata repository, you should now be able to install
> | Rbbg as expected.
> | 
> | But that said, the package is no longer being actively developed. Recent
> | efforts have been taking place in the Rblpapi package. The interface is
> | similar, though not strictly compatible. If you're doing much work with
> | Bloomberg data I recommend you check it out.
> 
> Also, Rblpapi is on CRAN and installs like other packages via
> 
>    install.packages("Rblpapi")
> 
> and update.packages() relieving you from the need to go to findata.org.
> 
> Dirk
> 
> -- 
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
>


From dulcalma at bigpond.com  Thu Dec 29 08:26:11 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 29 Dec 2016 18:26:11 +1100
Subject: [R] How to overlay lines and rectangles in lattice plot key
In-Reply-To: <000001d261a4$13843d10$3a8cb730$@bigpond.com>
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
	<000001d261a4$13843d10$3a8cb730$@bigpond.com>
Message-ID: <000201d261a4$d48f2f10$7dad8d30$@bigpond.com>

I forgot to change the xyplot for the colours; if you want the same colours
in the key you need to use the par.settings argument or set the settings for
the device.

the xyplot becomes

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   par.settings = list(superpose.symbol = list(col = 1:4,
                                               cex = 1,
                                               pch = 1:4),
                       superpose.line = list(col = 1:4)
                  ),
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   legend = list(right = list(fun = XY04.fmG))
)
 
Duncan

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
Mackay
Sent: Thursday, 29 December 2016 18:21
To: R
Subject: Re: [R] How to overlay lines and rectangles in lattice plot key

Hi 

It makes it easier

library(grid)
library(lattice)

# legend
XY04.glay <-
grid.layout(nrow = 4,
            ncol = 2,
            heights = unit(rep(1, 2), rep("cm", 2)),
            widths  = unit(c(0.4, 0.8),
                           c("in","in")),
            just = "centre")

XY04.fmG <- frameGrob(layout = XY04.glay)

k <-0
for (j in seq_len(4)){

  XY04.fmG <-
  placeGrob(XY04.fmG, textGrob(lab = letters[j],
                             just = 0,
                             gp = gpar(cex = 0.8)), row = j, col = 1)
  XY04.fmG <-
  placeGrob(XY04.fmG, rectGrob(width = 0.6,
                               gp = gpar(col=j,
                                         alpha = 0.25,
                                         fill = j)), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, linesGrob(c(0.2,0.8),  c(0.5, 0.5),
                              gp = gpar(col = j)), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, pointsGrob(x = unit(1, "cm"), y = unit(0.5, "npc"),
                              pch = j,
                              #width = unit(2, "cm"),
                              gp = gpar(cex = 0.7, col = j)), row = j, col =
2)
}

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   legend = list(right = list(fun = XY04.fmG))
)

This gives 1 point instead of 2 or 3.
The OP needs to change the format and fix the heights of the rectangles etc.
I also fixed the colour vectors had j instead of k


Duncan

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Thursday, 29 December 2016 16:17
To: R
Subject: RE: [R] How to overlay lines and rectangles in lattice plot key

Hi

Is this something like what you are looking for?
I have put it on the right and heights etc are just a quick guess. (all i
have time for)
It may be a little too complicated for what you want but I thought  of this
first based on your description rather than the plot.

library(grid)
library(lattice)

# legend
XY04.glay <-
grid.layout(nrow = 8,
            ncol = 2,
            heights = unit(rep(1, 2), rep("cm", 2)),
            widths  = unit(c(0.4, 0.8),
                           c("in","in")),
            just = "centre")

XY04.fmG <- frameGrob(layout = XY04.glay)

k <-0
for (j in seq(1,8,2)){
  k = k+1
  
  XY04.fmG <-
  placeGrob(XY04.fmG, textGrob(lab = letters[1:4][k],
                             just = 0,
                             gp = gpar(cex = 0.8)), row = j, col = 1)
  XY04.fmG <-
  placeGrob(XY04.fmG, linesGrob(c(0.2,0.8),  c(0.5, 0.5),
                              gp = gpar(col = c(1:4)[k])), row = j, col = 2)
  XY04.fmG <-
  placeGrob(XY04.fmG, pointsGrob(c(0.2,0.8),  c(0.5, 0.5),
                              pch = j,
                              gp = gpar(cex = 0.7, col = c(1:4)[k])), row =
j, col = 2)
}
k = 0
for (j in seq(2,8,2)){
  k = k+1
  XY04.fmG <-
  placeGrob(XY04.fmG, rectGrob(width = 0.6,
                               gp = gpar(col=k,
                                         alpha = 0.25,
                                         fill = k)), row = j, col = 2)

}

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   legend = list(right = list(fun = XY04.fmG))
)


Have a look at https://stat.ethz.ch/pipermail/r-help/2005-April/069459.html
and the following emails on the thread.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of sbihorel
Sent: Thursday, 29 December 2016 13:51
To: r-help at r-project.org
Subject: [R] How to overlay lines and rectangles in lattice plot key

Hi,

I would like to create a custom key for a lattice xyplot in which line 
elements are displayed on top of rectangle elements. In the example code 
below, the lines and rectangles are shown side by side (the legend 
itself is meaningless, but that is not the point). Is there a way to 
overlay these key elements (but not the text)?

Thanks

xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
   iris,
   type = c("p", "r"),
   jitter.x = TRUE,
   jitter.y = TRUE,
   factor = 5,
   key = list(
     column=4,
     text=list(lab=letters[1:4]),
     lines=list(col=1:4, pch=1:4, type='b'),
     rectangles=list(col=1:4, alpha=0.25, border=FALSE)
   )
)

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jwd at surewest.net  Thu Dec 29 09:46:01 2016
From: jwd at surewest.net (John Dougherty)
Date: Thu, 29 Dec 2016 00:46:01 -0800
Subject: [R] Export R output in Excel
In-Reply-To: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
Message-ID: <20161229004601.758269fe@draco.site>

On Wed, 28 Dec 2016 13:45:25 -0800
Bryan Mac <bryanmac.24 at gmail.com> wrote:

> Hi,
> 
> How do I export results from R to Excel in a format-friendly way? For
> example, when I copy and paste my results into excel, the formatting
> is messed up.
> 
> Thanks.
>  
> Bryan Mac
> bryanmac.24 at gmail.com
>
Your purpose is not clear.  If you are planning to do MORE statistical
work with excel using R output, don't do it.  Learn the R equivalents.
There's nothing that you can do in Excel that can't be done in R.  And,
while Microsoft has made great strides in the reliability of it's
numbers and calculating routines, it is still a spreadsheet.

If you want to add tabular data to a word file from R, out
put it to a csv or tab delimited format and then copy into Word or
LibreOffice Writer. From there you can select the text of the table and
transform it into a table using the table menu. If you want formatted
statistical output, you can sink() the output to an asscii or utf
text file, paste it into Word and then convert the font of the pasted
segment to a fixed pitch font.  R output tends to follow the old-time
typewriter approach to formatting (spaces and tabs), meaning that kerned
fonts behave in horrible ways, fonts are rubbery, etc.


-- 

John


From drjimlemon at gmail.com  Thu Dec 29 10:19:51 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 29 Dec 2016 20:19:51 +1100
Subject: [R] Export R output in Excel
In-Reply-To: <A9719520-E8E7-416A-918A-67752B2D3079@gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>
	<A9719520-E8E7-416A-918A-67752B2D3079@gmail.com>
Message-ID: <CA+8X3fX7Dj5pWKMs6=4MJpVDf9ychnQ_P=B5u0og-MWgum4AuA@mail.gmail.com>

Hi Bryan,
What functions like "htmlize" (prettyR) do is format the basic R
output into HTML tables with the option of interspersed graphics.
While I usually stop at the HTML stage, the output files can be
imported into Word for those who cannot work out how to open them with
an HTML browser. I just tried the example for "htmlize" and it imports
into Libre Office Writer fine, but doesn't fit so well into Libre
Office Calc, which does not bode well for an import into Excel. At
best you will get formatted output, but you cannot play with the
numbers as you would in a spreadsheet. Petr's suggestion, which I just
read, is an alternative that may be more useful to you.

Jim


On Thu, Dec 29, 2016 at 2:58 PM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
> Hi Jim,
>
> Your assumption is correct. When running the analyses in R and want to export the output that appears in the console window to Excel(.csv) file.
> I believe it is easier to do if the export it done to an Excel (.CSV) file.
>
> So is there a way to export the analyses in the console window to a .CSV file with the good formatting ?
> I am looking to export the whole output if possible.
>
> I found this code, but it doesn?t cover the whole output of the console.
>
> write.csv(coef(summary(test)), file=?test.csv?)
>
> My whole output consists of descriptives and regressions.
>
> Best,
>
> Bryan Mac
> bryanmac.24 at gmail.com
>
>
>
>> On Dec 28, 2016, at 6:33 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Bryan,
>> When I have to do something like this, I usually go through HTML
>> output and import it into MS Word. I am not suggesting that this is
>> the best thing to do, but it might get you out of trouble. I'm not
>> sure whether importing HTML into Excel will work as well. I assume
>> that you are running analyses in R and want to export the output that
>> appears in the console window. If so, try producing HTML output with
>> the prettyR or R2HTML packages and importing it. There are other ways
>> to do this, but the learning curve is steep and you might not want to
>> climb it right now.
>>
>> Jim
>>
>>
>> On Thu, Dec 29, 2016 at 8:45 AM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
>>> Hi,
>>>
>>> How do I export results from R to Excel in a format-friendly way? For example, when I copy and paste my results into excel, the formatting is messed up.
>>>
>>> Thanks.
>>>
>>> Bryan Mac
>>> bryanmac.24 at gmail.com
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>


From marc_grt at yahoo.fr  Thu Dec 29 10:35:15 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 29 Dec 2016 10:35:15 +0100
Subject: [R] \n and italic() in legend()
Message-ID: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>

Hi everyone,

Could someone help me to get both \n (return) and italic() in a legend. 
Here is a little example showing what I would like (but without the 
italic) and second what I get:

plot(1, 1)
v1 <- "p-value\nbased on t-test"
legend("topright", legend=v1, y.intersp = 3, bty="n")

plot(1, 1)
v1 <- expression(italic("p")*"-value\nbased on "*italic("t")*"-test")
legend("topright", legend=v1, y.intersp = 3, bty="n")

The second one shows :

-value
pbased on t-test

rather than the expected:

p-value
based on t-test

Thanks a lot,

Marc


From dulcalma at bigpond.com  Thu Dec 29 10:54:07 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 29 Dec 2016 20:54:07 +1100
Subject: [R] \n and italic() in legend()
In-Reply-To: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
References: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
Message-ID: <000401d261b9$7f2e23e0$7d8a6ba0$@bigpond.com>

Hi Marc

Try atop

plot(1, 1)
v1 <- expression(atop(italic("p")*"-value","based on "*italic("t")*"-test"))
legend("topright", legend=v1, y.intersp = 3, bty="n")


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au
-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
Girondot via R-help
Sent: Thursday, 29 December 2016 20:35
To: R-help Mailing List
Subject: [R] \n and italic() in legend()

Hi everyone,

Could someone help me to get both \n (return) and italic() in a legend. 
Here is a little example showing what I would like (but without the 
italic) and second what I get:

plot(1, 1)
v1 <- "p-value\nbased on t-test"
legend("topright", legend=v1, y.intersp = 3, bty="n")

plot(1, 1)
v1 <- expression(italic("p")*"-value\nbased on "*italic("t")*"-test")
legend("topright", legend=v1, y.intersp = 3, bty="n")

The second one shows :

-value
pbased on t-test

rather than the expected:

p-value
based on t-test

Thanks a lot,

Marc

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From erich.subs at neuwirth.priv.at  Thu Dec 29 11:16:26 2016
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Thu, 29 Dec 2016 11:16:26 +0100
Subject: [R] [FORGED]  Export R output in Excel
In-Reply-To: <40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
Message-ID: <C2FC0475-D619-40D9-B7AB-D4B08EADCCE9@neuwirth.priv.at>

Well, my few cents again.
the packages
openxslx and xlsx allow to write dataframes as Excel sheets.
(xlsx is Java based, so it has more requirements to run than openxlsx,
which is just C++ based)

On Windows, R tools for Visual Studio allows Excel export.
For Windows, there also is our Excel add-in RExcel allowing
to use R from within Excel, and the R package rcom
which also allows to interact with Excel from R (more than just writing Excel workbooks).
Our products (rcom and RExcel), however, are not unter a FOSS license.

And a more general remark: There are a lot of things where R is a much better choice than Excel,
but there are a few things where it really makes sense  to use spreadsheets.

Spreadsheets offer a totally different paradigm to work with data, or more generally,
numbers and formulas. 
One can interact with the data directly, not hide them behind variable names.
And, the interaction is haptic, gesture based, not expressed as a language.

Rearranging the layout of a pivot table by dragging variable ?blocks?
is very intuitive and something which R itself doe not offer
(in fact, I wrote an add-in for R Commander to implement it).

Of course, Excel is not a good chice for a polished reproducible workflow.
But I think quite a few people (including me), when starting a new project,
are not ready immediately to set up this ?perfect? workflow,
and it is much easier to experiment with the data with a spreadsheet based
interface.

For me, working with spreadsheets is more like improvising some Jazz,
and writing R code is like writing a score for a composition.





> On 29 Dec 2016, at 00:15, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 29/12/16 10:45, Bryan Mac wrote:
>> Hi,
>> 
>> How do I export results from R to Excel in a format-friendly way? For
>> example, when I copy and paste my results into excel, the formatting
>> is messed up.
> 
> 
> Short answer:  *Don't*.  ("Friends don't let friends use excel for statistics.")
> 
> Longer answer:  Googling on "export R data to excel" yields lots of "useful" hits --- "useful" given the (false) assertion that it is useful to export things to excel.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Thu Dec 29 11:20:44 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Thu, 29 Dec 2016 02:20:44 -0800
Subject: [R] \n and italic() in legend()
In-Reply-To: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
References: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
Message-ID: <CAA99HCwwzgJrRnFGXaOUSW9aMWx0YMv0n1R6W47dC-w9XAjcGQ@mail.gmail.com>

Hi Marc,

I can't seem to get "\n" to work,  but simply using c() and "y.intersp
= 1" looks fine:

> plot(1, 1)
> v1 <- c(expression(italic("p")*"-value"), expression("based on "*italic("t")*"-test"))
> legend("topright", legend=v1, y.intersp = 1, bty="n")



Hope this helps,

Bill

William Michels, Ph.D.

On Thu, Dec 29, 2016 at 1:35 AM, Marc Girondot via R-help
<r-help at r-project.org> wrote:
> Hi everyone,
>
> Could someone help me to get both \n (return) and italic() in a legend. Here
> is a little example showing what I would like (but without the italic) and
> second what I get:
>
> plot(1, 1)
> v1 <- "p-value\nbased on t-test"
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
> plot(1, 1)
> v1 <- expression(italic("p")*"-value\nbased on "*italic("t")*"-test")
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
> The second one shows :
>
> -value
> pbased on t-test
>
> rather than the expected:
>
> p-value
> based on t-test
>
> Thanks a lot,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Dec 29 11:38:11 2016
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 29 Dec 2016 11:38:11 +0100
Subject: [R] [FORGED]  Export R output in Excel
In-Reply-To: <213ea99c-2e21-5581-7f6e-1dd08b5cab1f@auckland.ac.nz>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
	<B6A7478E-13AE-48DD-B8E7-74F59B79FF23@gmail.com>
	<213ea99c-2e21-5581-7f6e-1dd08b5cab1f@auckland.ac.nz>
Message-ID: <2B331DAF-2F8D-4271-A912-EECBE8EF8F04@gmail.com>

I don't really disagree with the below, but part of the issue is that analyses do not typically output results in data frame like formats (neither in the textual form or as R objects). Some people have attacked this issue by wrangling output into data frames, check the "broom" package.

(The ideology of sweeping much of the flexibility of R away by turning all data structures into data sets strikes me a bit much like reinventing SAS, but this might be a spot where it comes in useful.)

-pd

> On 29 Dec 2016, at 01:05 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 29/12/16 12:48, Bryan Mac wrote:
>> Hi Rolf,
>> 
>> I wanted to export the output/results of R to an Excel file for
>> easier comparisons/reporting. When I tried to copy and paste my
>> output to an excel file the formatting was off. I want to export my
>> descriptive stats and the linear regression.
> 
> This makes little to no sense to me.  Spreadsheets are for use in storing data, not for displaying the output of analyses.  (I know that Excel users do this sort of thing, but then people do all sorts of irrational things.)
> 
>> I googled ?Export R output to excel? but did not find most of the
>> hints ?useful?. if anything, it got me more confused.
>> 
>> Thanks.
> 
> (1) The best advice is still "*Don't*."
> 
> (2) You do not need Excel to make comparisons and report.  In fact it is a handicap.  Re-think your strategy.
> 
> (3) If you insist in proceeding in a wrong-headed manner, isn't the item about XLConnect (3rd answer, 1st hit) "useful"?
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spencer.graves at effectivedefense.org  Thu Dec 29 14:15:13 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Thu, 29 Dec 2016 07:15:13 -0600
Subject: [R] Export R output in Excel
In-Reply-To: <CA+8X3fX7Dj5pWKMs6=4MJpVDf9ychnQ_P=B5u0og-MWgum4AuA@mail.gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>
	<A9719520-E8E7-416A-918A-67752B2D3079@gmail.com>
	<CA+8X3fX7Dj5pWKMs6=4MJpVDf9ychnQ_P=B5u0og-MWgum4AuA@mail.gmail.com>
Message-ID: <c1e43251-f5aa-dd58-7316-85ce2a376211@effectivedefense.org>

       The "writeFindFn2xls" function in the sos package include 3 
different ways to write an Excel workbook, depending on which packages, 
etc., you have installed.  I wrote that, because I could not find one 
contributed package that as easy to install on every operating system.  
This writes an Excel workbook with 3 sheets. That may not be what you 
want, but it might provide other options.


Spencer Graves

On 2016-12-29 3:19 AM, Jim Lemon wrote:
> Hi Bryan,
> What functions like "htmlize" (prettyR) do is format the basic R
> output into HTML tables with the option of interspersed graphics.
> While I usually stop at the HTML stage, the output files can be
> imported into Word for those who cannot work out how to open them with
> an HTML browser. I just tried the example for "htmlize" and it imports
> into Libre Office Writer fine, but doesn't fit so well into Libre
> Office Calc, which does not bode well for an import into Excel. At
> best you will get formatted output, but you cannot play with the
> numbers as you would in a spreadsheet. Petr's suggestion, which I just
> read, is an alternative that may be more useful to you.
>
> Jim
>
>
> On Thu, Dec 29, 2016 at 2:58 PM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
>> Hi Jim,
>>
>> Your assumption is correct. When running the analyses in R and want to export the output that appears in the console window to Excel(.csv) file.
>> I believe it is easier to do if the export it done to an Excel (.CSV) file.
>>
>> So is there a way to export the analyses in the console window to a .CSV file with the good formatting ?
>> I am looking to export the whole output if possible.
>>
>> I found this code, but it doesn?t cover the whole output of the console.
>>
>> write.csv(coef(summary(test)), file=?test.csv?)
>>
>> My whole output consists of descriptives and regressions.
>>
>> Best,
>>
>> Bryan Mac
>> bryanmac.24 at gmail.com
>>
>>
>>
>>> On Dec 28, 2016, at 6:33 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>>
>>> Hi Bryan,
>>> When I have to do something like this, I usually go through HTML
>>> output and import it into MS Word. I am not suggesting that this is
>>> the best thing to do, but it might get you out of trouble. I'm not
>>> sure whether importing HTML into Excel will work as well. I assume
>>> that you are running analyses in R and want to export the output that
>>> appears in the console window. If so, try producing HTML output with
>>> the prettyR or R2HTML packages and importing it. There are other ways
>>> to do this, but the learning curve is steep and you might not want to
>>> climb it right now.
>>>
>>> Jim
>>>
>>>
>>> On Thu, Dec 29, 2016 at 8:45 AM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> How do I export results from R to Excel in a format-friendly way? For example, when I copy and paste my results into excel, the formatting is messed up.
>>>>
>>>> Thanks.
>>>>
>>>> Bryan Mac
>>>> bryanmac.24 at gmail.com
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Thu Dec 29 12:32:15 2016
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 29 Dec 2016 06:32:15 -0500
Subject: [R] How to overlay lines and rectangles in lattice plot key
In-Reply-To: <CAGx1TMBjaXtrY_jmG-43U2Z_=KqYAJHMpfqz33hTfaeS=QGFtQ@mail.gmail.com>
References: <57705db1-5d56-56ba-55df-7bfd83887cfd@cognigencorp.com>
	<CAGx1TMBjaXtrY_jmG-43U2Z_=KqYAJHMpfqz33hTfaeS=QGFtQ@mail.gmail.com>
Message-ID: <0d05b0e2-a5b3-a343-8c78-baa259f1f8f8@cognigencorp.com>

Thanks to all the persons who replied,

I was hoping for a quick "grid-free" solution but I guess it is not 
Christmas time anymore :D

Grid coding it is.


On 12/29/2016 12:13 AM, Richard M. Heiberger wrote:
> Yes, but it will probably require work.  I think you will need to
> write a grob that does what you want
> and then use the grob in a legend statement in the xyplot.
>
> Start with the 'legend' argument to xyplot (about line 940 in ?xyplot).
> You will probably need to work directly with grid functions and will
> find Paul Murrell's book very helpful.
> https://www.crcpress.com/R-Graphics/Murrell/p/book/9781584884866
>
> Rich
>
> On Wed, Dec 28, 2016 at 9:50 PM, sbihorel
> <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hi,
>>
>> I would like to create a custom key for a lattice xyplot in which line
>> elements are displayed on top of rectangle elements. In the example code
>> below, the lines and rectangles are shown side by side (the legend itself is
>> meaningless, but that is not the point). Is there a way to overlay these key
>> elements (but not the text)?
>>
>> Thanks
>>
>> xyplot(Sepal.Length + Sepal.Width ~ Petal.Length + Petal.Width,
>>    iris,
>>    type = c("p", "r"),
>>    jitter.x = TRUE,
>>    jitter.y = TRUE,
>>    factor = 5,
>>    key = list(
>>      column=4,
>>      text=list(lab=letters[1:4]),
>>      lines=list(col=1:4, pch=1:4, type='b'),
>>      rectangles=list(col=1:4, alpha=0.25, border=FALSE)
>>    )
>> )
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sebastien Bihorel
Associate Director, Pharmacometrics
Buffalo Office: +1-716-633-3463 ext. 323 | Website 
<http://www.cognigencorp.com>
<http://www.simulations-plus.com/Default.aspx>

From bryanmac.24 at gmail.com  Thu Dec 29 04:58:24 2016
From: bryanmac.24 at gmail.com (Bryan Mac)
Date: Wed, 28 Dec 2016 19:58:24 -0800
Subject: [R] Export R output in Excel
In-Reply-To: <CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<CA+8X3fWsOn-TY24bLCqG4b5vmO0f1Nxj-j1aSk7HFSYW-Qm-uA@mail.gmail.com>
Message-ID: <A9719520-E8E7-416A-918A-67752B2D3079@gmail.com>

Hi Jim,

Your assumption is correct. When running the analyses in R and want to export the output that appears in the console window to Excel(.csv) file.
I believe it is easier to do if the export it done to an Excel (.CSV) file.

So is there a way to export the analyses in the console window to a .CSV file with the good formatting ?
I am looking to export the whole output if possible. 

I found this code, but it doesn?t cover the whole output of the console. 

write.csv(coef(summary(test)), file=?test.csv?)

My whole output consists of descriptives and regressions. 

Best,

Bryan Mac
bryanmac.24 at gmail.com



> On Dec 28, 2016, at 6:33 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> Hi Bryan,
> When I have to do something like this, I usually go through HTML
> output and import it into MS Word. I am not suggesting that this is
> the best thing to do, but it might get you out of trouble. I'm not
> sure whether importing HTML into Excel will work as well. I assume
> that you are running analyses in R and want to export the output that
> appears in the console window. If so, try producing HTML output with
> the prettyR or R2HTML packages and importing it. There are other ways
> to do this, but the learning curve is steep and you might not want to
> climb it right now.
> 
> Jim
> 
> 
> On Thu, Dec 29, 2016 at 8:45 AM, Bryan Mac <bryanmac.24 at gmail.com> wrote:
>> Hi,
>> 
>> How do I export results from R to Excel in a format-friendly way? For example, when I copy and paste my results into excel, the formatting is messed up.
>> 
>> Thanks.
>> 
>> Bryan Mac
>> bryanmac.24 at gmail.com
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Dec 29 15:40:53 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 29 Dec 2016 06:40:53 -0800
Subject: [R] [FORGED] Export R output in Excel
In-Reply-To: <C2FC0475-D619-40D9-B7AB-D4B08EADCCE9@neuwirth.priv.at>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
	<C2FC0475-D619-40D9-B7AB-D4B08EADCCE9@neuwirth.priv.at>
Message-ID: <CAGxFJbS=0PUB1RRtbkfe92tcvk6iT09ehNbdvEA6_b-7Wez-Cw@mail.gmail.com>

(Private -- as this is just my personal opinion and not really helpful).

I found your comments informative. Thank you.

My own experience with scientific colleagues -- biologists mostly --
who use Excel in the way that you describe is that the "haptic" (great
word!) ease with which they manipulate the data almost inevitably
results in errors. That is, the *lack* of enforced structure in Excel
allows them to do things that they shouldn't or don't mean to do,
typically without raising any flags, typically causing downstream
errors that can be hard to trace. Irreproducibility follows.

My point is that the structure that you consider burdensome -- at
least initially -- is desirable exactly because it forces them to
think more carefully about what they are doing. Debugging, or worse
yet, failure to realize that debugging is needed, takes far more time
and is far more consequential.

As I said, just my opinion, no reply necessary, and I do appreciate
your thoughtful remarks.

Best,
Bert Gunter

Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 29, 2016 at 2:16 AM, Erich Subscriptions
<erich.subs at neuwirth.priv.at> wrote:
> Well, my few cents again.
> the packages
> openxslx and xlsx allow to write dataframes as Excel sheets.
> (xlsx is Java based, so it has more requirements to run than openxlsx,
> which is just C++ based)
>
> On Windows, R tools for Visual Studio allows Excel export.
> For Windows, there also is our Excel add-in RExcel allowing
> to use R from within Excel, and the R package rcom
> which also allows to interact with Excel from R (more than just writing Excel workbooks).
> Our products (rcom and RExcel), however, are not unter a FOSS license.
>
> And a more general remark: There are a lot of things where R is a much better choice than Excel,
> but there are a few things where it really makes sense  to use spreadsheets.
>
> Spreadsheets offer a totally different paradigm to work with data, or more generally,
> numbers and formulas.
> One can interact with the data directly, not hide them behind variable names.
> And, the interaction is haptic, gesture based, not expressed as a language.
>
> Rearranging the layout of a pivot table by dragging variable ?blocks?
> is very intuitive and something which R itself doe not offer
> (in fact, I wrote an add-in for R Commander to implement it).
>
> Of course, Excel is not a good chice for a polished reproducible workflow.
> But I think quite a few people (including me), when starting a new project,
> are not ready immediately to set up this ?perfect? workflow,
> and it is much easier to experiment with the data with a spreadsheet based
> interface.
>
> For me, working with spreadsheets is more like improvising some Jazz,
> and writing R code is like writing a score for a composition.
>
>
>
>
>
>> On 29 Dec 2016, at 00:15, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>
>> On 29/12/16 10:45, Bryan Mac wrote:
>>> Hi,
>>>
>>> How do I export results from R to Excel in a format-friendly way? For
>>> example, when I copy and paste my results into excel, the formatting
>>> is messed up.
>>
>>
>> Short answer:  *Don't*.  ("Friends don't let friends use excel for statistics.")
>>
>> Longer answer:  Googling on "export R data to excel" yields lots of "useful" hits --- "useful" given the (false) assertion that it is useful to export things to excel.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Dec 29 15:43:17 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 29 Dec 2016 06:43:17 -0800
Subject: [R] [FORGED] Export R output in Excel
In-Reply-To: <CAGxFJbS=0PUB1RRtbkfe92tcvk6iT09ehNbdvEA6_b-7Wez-Cw@mail.gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
	<C2FC0475-D619-40D9-B7AB-D4B08EADCCE9@neuwirth.priv.at>
	<CAGxFJbS=0PUB1RRtbkfe92tcvk6iT09ehNbdvEA6_b-7Wez-Cw@mail.gmail.com>
Message-ID: <CAGxFJbREyNHAy4QrdSYTN46PETpd4saVd13w7uGjBsnRkBSr9g@mail.gmail.com>

Oh nuts! I replied all. I apologize for the noise!

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Dec 29, 2016 at 6:40 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> (Private -- as this is just my personal opinion and not really helpful).
>
> I found your comments informative. Thank you.
>
> My own experience with scientific colleagues -- biologists mostly --
> who use Excel in the way that you describe is that the "haptic" (great
> word!) ease with which they manipulate the data almost inevitably
> results in errors. That is, the *lack* of enforced structure in Excel
> allows them to do things that they shouldn't or don't mean to do,
> typically without raising any flags, typically causing downstream
> errors that can be hard to trace. Irreproducibility follows.
>
> My point is that the structure that you consider burdensome -- at
> least initially -- is desirable exactly because it forces them to
> think more carefully about what they are doing. Debugging, or worse
> yet, failure to realize that debugging is needed, takes far more time
> and is far more consequential.
>
> As I said, just my opinion, no reply necessary, and I do appreciate
> your thoughtful remarks.
>
> Best,
> Bert Gunter
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Dec 29, 2016 at 2:16 AM, Erich Subscriptions
> <erich.subs at neuwirth.priv.at> wrote:
>> Well, my few cents again.
>> the packages
>> openxslx and xlsx allow to write dataframes as Excel sheets.
>> (xlsx is Java based, so it has more requirements to run than openxlsx,
>> which is just C++ based)
>>
>> On Windows, R tools for Visual Studio allows Excel export.
>> For Windows, there also is our Excel add-in RExcel allowing
>> to use R from within Excel, and the R package rcom
>> which also allows to interact with Excel from R (more than just writing Excel workbooks).
>> Our products (rcom and RExcel), however, are not unter a FOSS license.
>>
>> And a more general remark: There are a lot of things where R is a much better choice than Excel,
>> but there are a few things where it really makes sense  to use spreadsheets.
>>
>> Spreadsheets offer a totally different paradigm to work with data, or more generally,
>> numbers and formulas.
>> One can interact with the data directly, not hide them behind variable names.
>> And, the interaction is haptic, gesture based, not expressed as a language.
>>
>> Rearranging the layout of a pivot table by dragging variable ?blocks?
>> is very intuitive and something which R itself doe not offer
>> (in fact, I wrote an add-in for R Commander to implement it).
>>
>> Of course, Excel is not a good chice for a polished reproducible workflow.
>> But I think quite a few people (including me), when starting a new project,
>> are not ready immediately to set up this ?perfect? workflow,
>> and it is much easier to experiment with the data with a spreadsheet based
>> interface.
>>
>> For me, working with spreadsheets is more like improvising some Jazz,
>> and writing R code is like writing a score for a composition.
>>
>>
>>
>>
>>
>>> On 29 Dec 2016, at 00:15, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>>
>>> On 29/12/16 10:45, Bryan Mac wrote:
>>>> Hi,
>>>>
>>>> How do I export results from R to Excel in a format-friendly way? For
>>>> example, when I copy and paste my results into excel, the formatting
>>>> is messed up.
>>>
>>>
>>> Short answer:  *Don't*.  ("Friends don't let friends use excel for statistics.")
>>>
>>> Longer answer:  Googling on "export R data to excel" yields lots of "useful" hits --- "useful" given the (false) assertion that it is useful to export things to excel.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> --
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wjm1 at caa.columbia.edu  Thu Dec 29 16:20:28 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Thu, 29 Dec 2016 07:20:28 -0800
Subject: [R] Export R output in Excel
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB9D4@SRVEXCHCM301.precheza.cz>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C59FB9D4@SRVEXCHCM301.precheza.cz>
Message-ID: <CAA99HCzth5w9wuy9geqp13VYbuwJ-zhzv0G1BQXSYmSzge0zhQ@mail.gmail.com>

Hi Bryan (and Petr),

If you want to write tsv-style data from R to clipboard on a Mac (e.g.
for pasting into Numbers), you should do:

> x1 <- matrix(1:6, nrow =2)

> clip <- pipe("pbcopy", "w")
> write.table(x1, file=clip, sep = "\t", row.names = FALSE, fileEncoding = "UTF-8" )
> close(clip)
> gc()

> ?write.table
> ?connections

Adding an extra call to gc() (garbage collection) after writing to
clipboard will
close all unused connections (useful if a connection has been entered
incorrectly).

HTH,

Bill
William Michels, Ph.D.

http://stackoverflow.com/questions/14547069/how-to-write-from-r-to-the-clipboard-on-a-mac
http://stackoverflow.com/questions/30445875/what-exactly-is-a-connection-in-r


On Wed, Dec 28, 2016 at 11:14 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> For rectangular data
>
> write.table(tab, "clipboard", sep = "\t", row.names = F)
> followed by Ctrl-V in Excel
>
> or
> write.table(tab, "somefile.xls", sep = "\t", row.names = F)
>
> For free format output like summary(somefit) I prefer to copy it to Word and use font like  Courier New with monospaced letters
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bryan Mac
>> Sent: Wednesday, December 28, 2016 10:45 PM
>> To: R-help at r-project.org
>> Subject: [R] Export R output in Excel
>>
>> Hi,
>>
>> How do I export results from R to Excel in a format-friendly way? For
>> example, when I copy and paste my results into excel, the formatting is
>> messed up.
>>
>> Thanks.
>>
>> Bryan Mac
>> bryanmac.24 at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From acefix at rocketmail.com  Thu Dec 29 15:59:18 2016
From: acefix at rocketmail.com (Fix Ace)
Date: Thu, 29 Dec 2016 14:59:18 +0000 (UTC)
Subject: [R] ggplot2 package: argument of expand with scale_x_discrete()
In-Reply-To: <1696757755.2866913.1482950990817@mail.yahoo.com>
References: <mailman.2109.1481554377.3878.r-help@r-project.org>
	<1696757755.2866913.1482950990817@mail.yahoo.com>
Message-ID: <1819010636.3252551.1483023558354@mail.yahoo.com>




 Hello, there,
What exactly does "expand" do for this function?
I followed the examples from the manual to get a plot: 

d <- ggplot(subset(diamonds, carat > 1), aes(cut, clarity)) +geom_jitter()

I would like to have all the dots in a square instead of rectangular range. When I applied d + scale_x_discrete(expand=c(1,1)) and d + scale_x_discrete(expand=c(1,0)), I got the same plot (different from the original one though).
Could anyone help me to figure out how to use this argument?
Thank you very much!
Ace
 



   
	[[alternative HTML version deleted]]


From habtamustat at gmail.com  Thu Dec 29 16:38:04 2016
From: habtamustat at gmail.com (Habtamu Gebreselassie)
Date: Thu, 29 Dec 2016 18:38:04 +0300
Subject: [R] Help
Message-ID: <CAD8amjQpWVtED8sNtu+o9VBnWLT6YHEHnvWyYej9GqvB9iOnHw@mail.gmail.com>

I had installed R studio desktop in my laptop but i could n't use it
properly due an output "Error in normalizePath(dir, winslash = "/",
mustWork = TRUE) :
unused argument(s) (winslash = "/", mustWork = TRUE)" on r console. please
i am in need of your
immediate assistant.

with regards.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Thu Dec 29 17:43:50 2016
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 29 Dec 2016 11:43:50 -0500
Subject: [R] ggplot2 package: argument of expand with scale_x_discrete()
In-Reply-To: <1819010636.3252551.1483023558354@mail.yahoo.com>
References: <mailman.2109.1481554377.3878.r-help@r-project.org>
	<1696757755.2866913.1482950990817@mail.yahoo.com>
	<1819010636.3252551.1483023558354@mail.yahoo.com>
Message-ID: <CA+vqiLG_72uakzdS9RSpv1razuRs7-Xs5SYPTaPv4=zZ39xN8w@mail.gmail.com>

Use coord_fixed()

--Ista

On Thu, Dec 29, 2016 at 9:59 AM, Fix Ace via R-help
<r-help at r-project.org> wrote:
>
>
>
>  Hello, there,
> What exactly does "expand" do for this function?
> I followed the examples from the manual to get a plot:
>
> d <- ggplot(subset(diamonds, carat > 1), aes(cut, clarity)) +geom_jitter()
>
> I would like to have all the dots in a square instead of rectangular range. When I applied d + scale_x_discrete(expand=c(1,1)) and d + scale_x_discrete(expand=c(1,0)), I got the same plot (different from the original one though).
> Could anyone help me to figure out how to use this argument?
> Thank you very much!
> Ace
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Dec 29 18:14:11 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 29 Dec 2016 09:14:11 -0800
Subject: [R] Help
In-Reply-To: <CAD8amjQpWVtED8sNtu+o9VBnWLT6YHEHnvWyYej9GqvB9iOnHw@mail.gmail.com>
References: <CAD8amjQpWVtED8sNtu+o9VBnWLT6YHEHnvWyYej9GqvB9iOnHw@mail.gmail.com>
Message-ID: <A1C6DF2C-13FB-4A45-847E-54F5661247E4@comcast.net>


> On Dec 29, 2016, at 7:38 AM, Habtamu Gebreselassie <habtamustat at gmail.com> wrote:
> 
> I had installed R studio desktop in my laptop but i could n't use it
> properly due an output "Error in normalizePath(dir, winslash = "/",
> mustWork = TRUE) :
> unused argument(s) (winslash = "/", mustWork = TRUE)" on r console. please
> i am in need of your
> immediate assistant.

Rhelp is not set up to provide support for RStudio. You should use the RStudio support pages. When you do so, be sure to provide them more information about your machine and operating system than you did in this message. 

-- 
David.
> 
> with regards.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From paulbernal07 at gmail.com  Thu Dec 29 21:23:26 2016
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 29 Dec 2016 15:23:26 -0500
Subject: [R] Problems when trying to install and load package "rzmq"
Message-ID: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>

After connecting to a mirror, I typed the following command:

install.packages("rzqm")

but I received the following message:

ERROR: compilation failed for package 'rzmq'

removing 'E:/Documents/R/win-library/3.3/rzmq'

package which is only available in source form, and may need compilation of
C/C++/Fortran: 'rzmq'
These will not be installed

The computer environment is Windows 8 64x bits


Any help and/or guidance will be greatly appreciated

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Dec 29 22:00:29 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 29 Dec 2016 13:00:29 -0800
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
Message-ID: <18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>

Read the system requirements [1]. I don't think you can do this on windows. 

[1] https://cran.r-project.org/web/packages/rzmq/index.html
-- 
Sent from my phone. Please excuse my brevity.

On December 29, 2016 12:23:26 PM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>After connecting to a mirror, I typed the following command:
>
>install.packages("rzqm")
>
>but I received the following message:
>
>ERROR: compilation failed for package 'rzmq'
>
>removing 'E:/Documents/R/win-library/3.3/rzmq'
>
>package which is only available in source form, and may need
>compilation of
>C/C++/Fortran: 'rzmq'
>These will not be installed
>
>The computer environment is Windows 8 64x bits
>
>
>Any help and/or guidance will be greatly appreciated
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From paulbernal07 at gmail.com  Thu Dec 29 22:04:53 2016
From: paulbernal07 at gmail.com (Paul Bernal)
Date: Thu, 29 Dec 2016 16:04:53 -0500
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
Message-ID: <CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>

Dear Jeff,

Thank you for your fast and kind reply. When you say that you do not think
this can be done on windows, then I would have to use something like Ubuntu
or Linux?

Best regards

Paul

2016-12-29 16:00 GMT-05:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> Read the system requirements [1]. I don't think you can do this on windows.
>
> [1] https://cran.r-project.org/web/packages/rzmq/index.html
> --
> Sent from my phone. Please excuse my brevity.
>
> On December 29, 2016 12:23:26 PM PST, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >After connecting to a mirror, I typed the following command:
> >
> >install.packages("rzqm")
> >
> >but I received the following message:
> >
> >ERROR: compilation failed for package 'rzmq'
> >
> >removing 'E:/Documents/R/win-library/3.3/rzmq'
> >
> >package which is only available in source form, and may need
> >compilation of
> >C/C++/Fortran: 'rzmq'
> >These will not be installed
> >
> >The computer environment is Windows 8 64x bits
> >
> >
> >Any help and/or guidance will be greatly appreciated
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Thu Dec 29 22:45:48 2016
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 29 Dec 2016 22:45:48 +0100
Subject: [R] \n and italic() in legend()
In-Reply-To: <000401d261b9$7f2e23e0$7d8a6ba0$@bigpond.com>
References: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
	<000401d261b9$7f2e23e0$7d8a6ba0$@bigpond.com>
Message-ID: <1962bf27-980e-cc51-29ba-c20f63173c3f@yahoo.fr>

Hi,
Thanks a lot to Duncan Mackay for the trick using atop() [but the 
legends are centered and not left aligned] and also for the suggestion 
of William Michels to use simply ",". However this last solution 
prevents to use several legends.

Here is a solution to allow both return within a legend and several legends:
plot(1, 1)
v1 <- c(expression(italic("p")*"-value"), expression("based on 
"*italic("t")*"-test"))
v2 <- c(expression(italic("w")*"-value for A"), expression("and B 
identical models"))
legend("topright", legend=c(v1, v2), lty=c(1, 0, 1, 0), y.intersp = 1, 
bty="n", col=c("black", "", "red", ""))

Thanks again

Marc


Le 29/12/2016 ? 10:54, Duncan Mackay a ?crit :
> Hi Marc
>
> Try atop
>
> plot(1, 1)
> v1 <- expression(atop(italic("p")*"-value","based on "*italic("t")*"-test"))
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
> Girondot via R-help
> Sent: Thursday, 29 December 2016 20:35
> To: R-help Mailing List
> Subject: [R] \n and italic() in legend()
>
> Hi everyone,
>
> Could someone help me to get both \n (return) and italic() in a legend.
> Here is a little example showing what I would like (but without the
> italic) and second what I get:
>
> plot(1, 1)
> v1 <- "p-value\nbased on t-test"
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
> plot(1, 1)
> v1 <- expression(italic("p")*"-value\nbased on "*italic("t")*"-test")
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
> The second one shows :
>
> -value
> pbased on t-test
>
> rather than the expected:
>
> p-value
> based on t-test
>
> Thanks a lot,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Thu Dec 29 22:54:36 2016
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 29 Dec 2016 13:54:36 -0800
Subject: [R] Problems when trying to install and load package "rzmq"
In-Reply-To: <CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
References: <CAMOcQfMiv=KBTx=91Jm2ovvsBvx1mDHgeG-kz+9+CNj3ohB19A@mail.gmail.com>
	<18C650A9-489F-453A-A46D-0F0E61D018CF@dcn.davis.ca.us>
	<CAMOcQfNk2pC-FVMVRWKknEz49=0kBof-QSzKqKmZM2W4Ybw61w@mail.gmail.com>
Message-ID: <3705D0CE-2250-48BF-ABF5-7264D0CD7427@dcn.davis.ca.us>

Something like that.  For all I know, MacOSX might work.  Read the system requirements yourself. I don't know all the systems that can meet those requirements.
-- 
Sent from my phone. Please excuse my brevity.

On December 29, 2016 1:04:53 PM PST, Paul Bernal <paulbernal07 at gmail.com> wrote:
>Dear Jeff,
>
>Thank you for your fast and kind reply. When you say that you do not
>think
>this can be done on windows, then I would have to use something like
>Ubuntu
>or Linux?
>
>Best regards
>
>Paul
>
>2016-12-29 16:00 GMT-05:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>
>> Read the system requirements [1]. I don't think you can do this on
>windows.
>>
>> [1] https://cran.r-project.org/web/packages/rzmq/index.html
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On December 29, 2016 12:23:26 PM PST, Paul Bernal
><paulbernal07 at gmail.com>
>> wrote:
>> >After connecting to a mirror, I typed the following command:
>> >
>> >install.packages("rzqm")
>> >
>> >but I received the following message:
>> >
>> >ERROR: compilation failed for package 'rzmq'
>> >
>> >removing 'E:/Documents/R/win-library/3.3/rzmq'
>> >
>> >package which is only available in source form, and may need
>> >compilation of
>> >C/C++/Fortran: 'rzmq'
>> >These will not be installed
>> >
>> >The computer environment is Windows 8 64x bits
>> >
>> >
>> >Any help and/or guidance will be greatly appreciated
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From erich.subs at neuwirth.priv.at  Thu Dec 29 23:32:50 2016
From: erich.subs at neuwirth.priv.at (Erich Subscriptions)
Date: Thu, 29 Dec 2016 23:32:50 +0100
Subject: [R] [FORGED] Export R output in Excel
In-Reply-To: <CAGxFJbS=0PUB1RRtbkfe92tcvk6iT09ehNbdvEA6_b-7Wez-Cw@mail.gmail.com>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
	<C2FC0475-D619-40D9-B7AB-D4B08EADCCE9@neuwirth.priv.at>
	<CAGxFJbS=0PUB1RRtbkfe92tcvk6iT09ehNbdvEA6_b-7Wez-Cw@mail.gmail.com>
Message-ID: <1586A022-BEF1-4094-8778-CEF4DC946F3B@neuwirth.priv.at>

Just a very brief footnote.
I is easy to write badly structured spreadsheets.
But if people dong this would not have spreadsheets 
and be forded to write code, they probably also
would write badly structured code.

There is a lot of bad R code around also!



> On Dec 29, 2016, at 15:40, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> (Private -- as this is just my personal opinion and not really helpful).
> 
> I found your comments informative. Thank you.
> 
> My own experience with scientific colleagues -- biologists mostly --
> who use Excel in the way that you describe is that the "haptic" (great
> word!) ease with which they manipulate the data almost inevitably
> results in errors. That is, the *lack* of enforced structure in Excel
> allows them to do things that they shouldn't or don't mean to do,
> typically without raising any flags, typically causing downstream
> errors that can be hard to trace. Irreproducibility follows.
> 
> My point is that the structure that you consider burdensome -- at
> least initially -- is desirable exactly because it forces them to
> think more carefully about what they are doing. Debugging, or worse
> yet, failure to realize that debugging is needed, takes far more time
> and is far more consequential.
> 
> As I said, just my opinion, no reply necessary, and I do appreciate
> your thoughtful remarks.
> 
> Best,
> Bert Gunter
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> 
> On Thu, Dec 29, 2016 at 2:16 AM, Erich Subscriptions
> <erich.subs at neuwirth.priv.at> wrote:
>> Well, my few cents again.
>> the packages
>> openxslx and xlsx allow to write dataframes as Excel sheets.
>> (xlsx is Java based, so it has more requirements to run than openxlsx,
>> which is just C++ based)
>> 
>> On Windows, R tools for Visual Studio allows Excel export.
>> For Windows, there also is our Excel add-in RExcel allowing
>> to use R from within Excel, and the R package rcom
>> which also allows to interact with Excel from R (more than just writing Excel workbooks).
>> Our products (rcom and RExcel), however, are not unter a FOSS license.
>> 
>> And a more general remark: There are a lot of things where R is a much better choice than Excel,
>> but there are a few things where it really makes sense  to use spreadsheets.
>> 
>> Spreadsheets offer a totally different paradigm to work with data, or more generally,
>> numbers and formulas.
>> One can interact with the data directly, not hide them behind variable names.
>> And, the interaction is haptic, gesture based, not expressed as a language.
>> 
>> Rearranging the layout of a pivot table by dragging variable ?blocks?
>> is very intuitive and something which R itself doe not offer
>> (in fact, I wrote an add-in for R Commander to implement it).
>> 
>> Of course, Excel is not a good chice for a polished reproducible workflow.
>> But I think quite a few people (including me), when starting a new project,
>> are not ready immediately to set up this ?perfect? workflow,
>> and it is much easier to experiment with the data with a spreadsheet based
>> interface.
>> 
>> For me, working with spreadsheets is more like improvising some Jazz,
>> and writing R code is like writing a score for a composition.
>> 
>> 
>> 
>> 
>> 
>>> On 29 Dec 2016, at 00:15, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>>> 
>>> On 29/12/16 10:45, Bryan Mac wrote:
>>>> Hi,
>>>> 
>>>> How do I export results from R to Excel in a format-friendly way? For
>>>> example, when I copy and paste my results into excel, the formatting
>>>> is messed up.
>>> 
>>> 
>>> Short answer:  *Don't*.  ("Friends don't let friends use excel for statistics.")
>>> 
>>> Longer answer:  Googling on "export R data to excel" yields lots of "useful" hits --- "useful" given the (false) assertion that it is useful to export things to excel.
>>> 
>>> cheers,
>>> 
>>> Rolf Turner
>>> 
>>> --
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Dec 29 23:56:09 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 30 Dec 2016 09:56:09 +1100
Subject: [R] \n and italic() in legend()
In-Reply-To: <1962bf27-980e-cc51-29ba-c20f63173c3f@yahoo.fr>
References: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
	<000401d261b9$7f2e23e0$7d8a6ba0$@bigpond.com>
	<1962bf27-980e-cc51-29ba-c20f63173c3f@yahoo.fr>
Message-ID: <000001d26226$bec58260$3c508720$@bigpond.com>

Hi Marc

I forgot about the other things than atop in my reply. Others seem to have
exhausted base graphics options
Could using grid.text solve your problems ?

e.g. Guide code

plot(1,1)

grid.clip()

vp <- viewport(width = 1, height = 1)
    
 pushViewport(vp)

grid.text( "text", 0.25,0.25)
popViewport(0)

Regards

Duncan

-----Original Message-----
From: Marc Girondot [mailto:marc_grt at yahoo.fr] 
Sent: Friday, 30 December 2016 08:46
To: Duncan Mackay; wjm1 at caa.columbia.edu; R-help Mailing List
Subject: Re: [R] \n and italic() in legend()

Hi,
Thanks a lot to Duncan Mackay for the trick using atop() [but the 
legends are centered and not left aligned] and also for the suggestion 
of William Michels to use simply ",". However this last solution 
prevents to use several legends.

Here is a solution to allow both return within a legend and several legends:
plot(1, 1)
v1 <- c(expression(italic("p")*"-value"), expression("based on 
"*italic("t")*"-test"))
v2 <- c(expression(italic("w")*"-value for A"), expression("and B 
identical models"))
legend("topright", legend=c(v1, v2), lty=c(1, 0, 1, 0), y.intersp = 1, 
bty="n", col=c("black", "", "red", ""))

Thanks again

Marc


Le 29/12/2016 ? 10:54, Duncan Mackay a ?crit :
> Hi Marc
>
> Try atop
>
> plot(1, 1)
> v1 <- expression(atop(italic("p")*"-value","based on
"*italic("t")*"-test"))
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
> Girondot via R-help
> Sent: Thursday, 29 December 2016 20:35
> To: R-help Mailing List
> Subject: [R] \n and italic() in legend()
>
> Hi everyone,
>
> Could someone help me to get both \n (return) and italic() in a legend.
> Here is a little example showing what I would like (but without the
> italic) and second what I get:
>
> plot(1, 1)
> v1 <- "p-value\nbased on t-test"
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
> plot(1, 1)
> v1 <- expression(italic("p")*"-value\nbased on "*italic("t")*"-test")
> legend("topright", legend=v1, y.intersp = 3, bty="n")
>
> The second one shows :
>
> -value
> pbased on t-test
>
> rather than the expected:
>
> p-value
> based on t-test
>
> Thanks a lot,
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wjm1 at caa.columbia.edu  Fri Dec 30 06:12:36 2016
From: wjm1 at caa.columbia.edu (William Michels)
Date: Thu, 29 Dec 2016 21:12:36 -0800
Subject: [R] \n and italic() in legend()
In-Reply-To: <1962bf27-980e-cc51-29ba-c20f63173c3f@yahoo.fr>
References: <8115b3e6-b67a-ba44-ac54-b9743f53a84f@yahoo.fr>
	<000401d261b9$7f2e23e0$7d8a6ba0$@bigpond.com>
	<1962bf27-980e-cc51-29ba-c20f63173c3f@yahoo.fr>
Message-ID: <CAA99HCy6Jngx1ivYxAg12vz_pR20s730nQ6TtoR4k0DyAAa9Ug@mail.gmail.com>

Hi Marc, I think it would be wrong to leave readers with the
impression that it's somehow improper to use c() in drawing a legend,
because in fact, it works so well. What doesn't work so well is mixing
expression() calls with escaped characters like "\n" (or "\r"), and
that's probably due to expression() using plotmath() and
as.graphicsAnnot() to draw text.

Maybe the take-home lesson is to not mix expression() and escaped
characters in a legend? If no expression() call is present, "\n" works
fine:

## legend: two lines per variable, no expression() call
plot(1, 1)
v1 <- c("some great text\nhere")
v2 <- c("some more great\ntext here")
legend("topright", legend=c(v1, v2), y.intersp = 1.5, bty="n",
lty=c(1, 1), lwd = c(2, 2), col=c("black", "red"))

If an expression() is present, every time legend() encounters a new
line (via either a compound expression, or via "\n"), it treats it as
a location to display a new variable. However, taking advantage of
plotmath(), you can simply use scriptstyle() or even
scriptscriptstyle(), to draw smaller text on one line:

## legend: expression() call /w single line per variable
plot(1, 1)
v1 <- expression(italic("p")*"-value based on "*italic("t")*"-test")
v2 <- expression(italic("w")*"-value for A and B identical models")
legend("topright", legend=c(v1, v2), y.intersp = 1.0, bty="n",
lty=c(1, 1), lwd = c(2,2), col=c("black", "red"))

## legend: expression() call /w two lines per variable
## (note lty, lwd, and col correction)
plot(1, 1)
v1 <- expression(italic("p")*"-value", "based on "*italic("t")*"-test")
v2 <- expression(italic("w")*"-value", "for A and B identical models")
legend("topright", legend=c(v1, v2), y.intersp = 1.0, bty="n",
lty=c(1, 0, 1, 0), lwd = c(2, 0, 2, 0), col=c("black", "", "red", ""))

## legend: expression() call /w single line per variable,
## smaller script
plot(1, 1)
v1 <- expression(scriptstyle(bold(italic("p")*"-value based on
"*italic("t")*"-test")))
v2 <- expression(scriptstyle(bold(italic("w")*"-value for A and B
identical models")))
legend("topright", legend=c(v1,v2), y.intersp = 1.0, bty="n", lty=c(1,
1), lwd = c(2,2), col=c("black", "red"))

## legend: expression() call /w single line per variable,
## even smaller script
plot(1, 1)
v1 <- expression(scriptscriptstyle(bold(italic("p")*"-value based on
"*italic("t")*"-test")))
v2 <- expression(scriptscriptstyle(bold(italic("w")*"-value for A and
B identical models")))
legend("topright", legend=c(v1,v2), y.intersp = 1.0, bty="n", lty=c(1,
1), lwd = c(2,2), col=c("black", "red"))

I'm loathe to call your initial finding of  'an italicized character
jumping to the second line when used in conjunction with "\n" ' as a
bug, but maybe others can chime in as to why that happens.

HTH,

Bill
William Michels, Ph.D.



On Thu, Dec 29, 2016 at 1:45 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> Hi,
> Thanks a lot to Duncan Mackay for the trick using atop() [but the legends
> are centered and not left aligned] and also for the suggestion of William
> Michels to use simply ",". However this last solution prevents to use
> several legends.
>
> Here is a solution to allow both return within a legend and several legends:
> plot(1, 1)
> v1 <- c(expression(italic("p")*"-value"), expression("based on
> "*italic("t")*"-test"))
> v2 <- c(expression(italic("w")*"-value for A"), expression("and B identical
> models"))
> legend("topright", legend=c(v1, v2), lty=c(1, 0, 1, 0), y.intersp = 1,
> bty="n", col=c("black", "", "red", ""))
>
> Thanks again
>
> Marc
>
>
> Le 29/12/2016 ? 10:54, Duncan Mackay a ?crit :
>>
>> Hi Marc
>>
>> Try atop
>>
>> plot(1, 1)
>> v1 <- expression(atop(italic("p")*"-value","based on
>> "*italic("t")*"-test"))
>> legend("topright", legend=v1, y.intersp = 3, bty="n")
>>
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc
>> Girondot via R-help
>> Sent: Thursday, 29 December 2016 20:35
>> To: R-help Mailing List
>> Subject: [R] \n and italic() in legend()
>>
>> Hi everyone,
>>
>> Could someone help me to get both \n (return) and italic() in a legend.
>> Here is a little example showing what I would like (but without the
>> italic) and second what I get:
>>
>> plot(1, 1)
>> v1 <- "p-value\nbased on t-test"
>> legend("topright", legend=v1, y.intersp = 3, bty="n")
>>
>> plot(1, 1)
>> v1 <- expression(italic("p")*"-value\nbased on "*italic("t")*"-test")
>> legend("topright", legend=v1, y.intersp = 3, bty="n")
>>
>> The second one shows :
>>
>> -value
>> pbased on t-test
>>
>> rather than the expected:
>>
>> p-value
>> based on t-test
>>
>> Thanks a lot,
>>
>> Marc
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From john.archie.mckown at gmail.com  Fri Dec 30 13:42:39 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 30 Dec 2016 06:42:39 -0600
Subject: [R] [FORGED] Export R output in Excel
In-Reply-To: <1586A022-BEF1-4094-8778-CEF4DC946F3B@neuwirth.priv.at>
References: <E80AE923-0CC9-49ED-86B7-8D7A3A2EA638@gmail.com>
	<40e0f72d-6f0a-0fae-c875-264176a1ad1a@auckland.ac.nz>
	<C2FC0475-D619-40D9-B7AB-D4B08EADCCE9@neuwirth.priv.at>
	<CAGxFJbS=0PUB1RRtbkfe92tcvk6iT09ehNbdvEA6_b-7Wez-Cw@mail.gmail.com>
	<1586A022-BEF1-4094-8778-CEF4DC946F3B@neuwirth.priv.at>
Message-ID: <CAAJSdji-WoiSC8ZBWa4ZXG9vZtnv1JOBQU4Ymi586RYjvPHF=Q@mail.gmail.com>

On Thu, Dec 29, 2016 at 4:32 PM, Erich Subscriptions <
erich.subs at neuwirth.priv.at> wrote:

> Just a very brief footnote.
> I is easy to write badly structured spreadsheets.
> But if people dong this would not have spreadsheets
> and be forded to write code, they probably also
> would write badly structured code.
>

?Very true. ?There is a very old quote: "You can write FORTRAN in any
language." Basically FORTRAN was, I think, the very first "high level"
language (1957 - COBOL was in 1959) and it had very poor (NO) structuring.
Coding it in is much like writing a bad mathematical proof (yes, I know
FORTRAN). When better languages came along, the original programmers wrote
code in the "if it were only FORTRAN" mode.

ref: https://en.wikiquote.org/wiki/Fortran




>
> There is a lot of bad R code around also!
>
>

-- 
Heisenberg may have been here.

http://xkcd.com/1770/

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Fri Dec 30 15:52:56 2016
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Fri, 30 Dec 2016 17:52:56 +0300
Subject: [R] Date Column error: 'origin' must be supplied
Message-ID: <CAGh51gSNOShj_cGLAig5wS-n4nbOWZ90wbDAnF0WAKvcs884Eg@mail.gmail.com>

Hi All,

I am creating date column on my data but getting the following error:

 #add date column dat1$Date=paste(as.Date(dat1$Year,dat1$Month,
dat1$Day, sep="-"))Error in as.Date.numeric(origin, ...) : 'origin'
must be supplied



I will appreciate any help from you guys. Thanks.
Here is the data.


dput(head(dat1))structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L
), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, WindSpeed = c(5L,
4L, 4L, 3L, 5L, 6L), Sunshine = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
), Tmax = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin = c(14.5,
16, 14.4, 14.8, 16.6, 15.4), Hmax = c(100L, 95L, 97L, 100L, 97L,
99L), Hmin = c(45L, 62L, 72L, 55L, 54L, 63L), Station.Name = structure(c(1L,
1L, 1L, 1L, 1L, 1L), .Label = "KIGALI AERO", class = "factor"),
    Elevation = c(1490L, 1490L, 1490L, 1490L, 1490L, 1490L),
    Longitude = c(30.11, 30.11, 30.11, 30.11, 30.11, 30.11),
    Latitude = c(-1.95, -1.95, -1.95, -1.95, -1.95, -1.95)), .Names = c("Year",
"Month", "Day", "WindSpeed", "Sunshine", "Tmax", "Tmin", "Hmax",
"Hmin", "Station.Name", "Elevation", "Longitude", "Latitude"),
row.names = c(NA,
6L), class = "data.frame")


Best Regards,

Fredo


Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Fri Dec 30 15:58:23 2016
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 30 Dec 2016 15:58:23 +0100 (CET)
Subject: [R] Date Column error: 'origin' must be supplied
In-Reply-To: <CAGh51gSNOShj_cGLAig5wS-n4nbOWZ90wbDAnF0WAKvcs884Eg@mail.gmail.com>
References: <CAGh51gSNOShj_cGLAig5wS-n4nbOWZ90wbDAnF0WAKvcs884Eg@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1612301557330.18444@paninaro>

On Fri, 30 Dec 2016, Frederic Ntirenganya wrote:

> Hi All,
>
> I am creating date column on my data but getting the following error:
>
> #add date column dat1$Date=paste(as.Date(dat1$Year,dat1$Month,
> dat1$Day, sep="-"))Error in as.Date.numeric(origin, ...) : 'origin'
> must be supplied

You first need to paste() the character string and the coerce it with 
as.Date() - not the other way around:

as.Date(paste(dat1$Year, dat1$Month, dat1$Day, sep="-"))

>
>
> I will appreciate any help from you guys. Thanks.
> Here is the data.
>
>
> dput(head(dat1))structure(list(Year = c(1984L, 1984L, 1984L, 1984L, 1984L, 1984L
> ), Month = c(1L, 1L, 1L, 1L, 1L, 1L), Day = 1:6, WindSpeed = c(5L,
> 4L, 4L, 3L, 5L, 6L), Sunshine = c(6.3, 4.8, 0.6, 8.2, 7.3, 1.7
> ), Tmax = c(27.4, 26.3, 22.9, 27.7, 28.5, 25.5), Tmin = c(14.5,
> 16, 14.4, 14.8, 16.6, 15.4), Hmax = c(100L, 95L, 97L, 100L, 97L,
> 99L), Hmin = c(45L, 62L, 72L, 55L, 54L, 63L), Station.Name = structure(c(1L,
> 1L, 1L, 1L, 1L, 1L), .Label = "KIGALI AERO", class = "factor"),
>    Elevation = c(1490L, 1490L, 1490L, 1490L, 1490L, 1490L),
>    Longitude = c(30.11, 30.11, 30.11, 30.11, 30.11, 30.11),
>    Latitude = c(-1.95, -1.95, -1.95, -1.95, -1.95, -1.95)), .Names = c("Year",
> "Month", "Day", "WindSpeed", "Sunshine", "Tmax", "Tmin", "Hmax",
> "Hmin", "Station.Name", "Elevation", "Longitude", "Latitude"),
> row.names = c(NA,
> 6L), class = "data.frame")
>
>
> Best Regards,
>
> Fredo
>
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chocold12 at gmail.com  Fri Dec 30 18:40:37 2016
From: chocold12 at gmail.com (lily li)
Date: Fri, 30 Dec 2016 10:40:37 -0700
Subject: [R] about data format in R
Message-ID: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>

Hi R users,

I'm trying to read in data, and then plot time series data. However, I have
some problems. In my dataset, the first column represents time, and in the
format:
mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
10/01/1995-06:00:00, etc.

df:
           date                    evap     precip    intercept
10/01/1995-00:00:00       1.5          2            0.2
10/01/1995-12:00:00       1.7          2.2         0.1
10/02/1995-00:00:00       1.5          1.8         0.3
...

My code is like this
file1 = read.table('df', head=T)

When I read in data, I found that it read incorrectly. How to format when
read in data? Thanks.

	[[alternative HTML version deleted]]


From ed_isfahani at yahoo.com  Fri Dec 30 18:57:12 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Fri, 30 Dec 2016 17:57:12 +0000 (UTC)
Subject: [R] help for
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
Message-ID: <242722337.3953531.1483120632122@mail.yahoo.com>

hi all,?I am following?http://bioinformatics.knowledgeblog.org/2011/06/20/analysing-microarray-data-in-bioconductor/?I need to download phenotypic data in the form of text file that describe chip names, and the source of the biological samples as well as probe that hybridised to them. I can not understand the mean of "Open a new terminal window and type".
i am using command.$ ls data/*.CEL > data/phenodata.txt in R

this returns an error


$ ls data/*.CEL > data/phenodata.txt Error: unexpected '$' in "$"
what should I do now?

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Dec 30 19:08:37 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 30 Dec 2016 13:08:37 -0500
Subject: [R] help for
In-Reply-To: <242722337.3953531.1483120632122@mail.yahoo.com>
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
	<242722337.3953531.1483120632122@mail.yahoo.com>
Message-ID: <CAM_vju=vMbXiMLkSaMhbZWRXTCoT=uSKYSu2R8GkkU_3MwY8tQ@mail.gmail.com>

This isn't an R question, but a linux question.

Open a new terminal window:
The directions you are following tell you how to do that for the
Ubuntu linux being used, right at the beginning:

Open up a terminal (Applications->Accessories->Terminal from the the toolbar)

As for your command, the $ is a prompt. You don't type that. Start with ls

What should you do now? Read a little bit about using linux command line tools

Sarah



On Fri, Dec 30, 2016 at 12:57 PM, Elham - via R-help
<r-help at r-project.org> wrote:
> hi all, I am following http://bioinformatics.knowledgeblog.org/2011/06/20/analysing-microarray-data-in-bioconductor/ I need to download phenotypic data in the form of text file that describe chip names, and the source of the biological samples as well as probe that hybridised to them. I can not understand the mean of "Open a new terminal window and type".
> i am using command.$ ls data/*.CEL > data/phenodata.txt in R
>
> this returns an error
>
>
> $ ls data/*.CEL > data/phenodata.txt Error: unexpected '$' in "$"
> what should I do now?


From ruipbarradas at sapo.pt  Fri Dec 30 19:23:19 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 30 Dec 2016 18:23:19 +0000
Subject: [R] about data format in R
In-Reply-To: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
Message-ID: <5866A617.5080400@sapo.pt>

Hello,

Have you tried

df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")

?

Hope this helps,

Rui Barradas


Em 30-12-2016 17:40, lily li escreveu:
> Hi R users,
>
> I'm trying to read in data, and then plot time series data. However, I have
> some problems. In my dataset, the first column represents time, and in the
> format:
> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
> 10/01/1995-06:00:00, etc.
>
> df:
>             date                    evap     precip    intercept
> 10/01/1995-00:00:00       1.5          2            0.2
> 10/01/1995-12:00:00       1.7          2.2         0.1
> 10/02/1995-00:00:00       1.5          1.8         0.3
> ...
>
> My code is like this
> file1 = read.table('df', head=T)
>
> When I read in data, I found that it read incorrectly. How to format when
> read in data? Thanks.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From robert.b.lynch at gmail.com  Fri Dec 30 19:30:08 2016
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Fri, 30 Dec 2016 10:30:08 -0800
Subject: [R] stacked and dodged bar graph ggplot
Message-ID: <CACYeG1ikQ4XhHz1g7ZUtpgCF1utjnVN1cewa8_AvWuB5AQwMEg@mail.gmail.com>

I have some census data with race and ethnicity for various towns.  I am
trying to make a stacked bar graph where all the race data is in one
stacked bar, and all the ethnicity data is in another.

Below is a minimal reproducible sample.

library("ggplot2")

Demog <-
data.frame(source=c(rep("Davis",4),rep("Dixon",4),rep("Winters",4)),
            group =c("Asian / Pacific Islander","Caucasian","Lantinx","Not
Latinx","African American", "Native American", "Latinx", "Not
Latinx","Mixed race","Other","Latinx", "Not Latinx"),
            number =c(14491, 42571, 8172, 57450, 562, 184, 7426, 10952,
332, 1488, 3469, 3155),
            field = rep(c(rep("race",2),rep("ethnicity",2)),3))

Demog$race <- factor(Demog$group, levels=c("Asian / Pacific Islander",
"Caucasian", "African American", "Native American / Alaska Native",  "mixed
race",  "other"))
Demog$ethn <- factor(Demog$group, levels=c("Latinx","not latinx"))
Demog$location <- factor(Demog$source, levels=c( "Dixon",
"Winters","Davis"))
Demog.bar1 <-ggplot(data = Demog, aes(x = location, y = number, fill =
race))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
coord_flip()

Demog.bar2 <-ggplot(data = Demog, aes(x = location, y = number, fill =
ethn))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
coord_flip()

show(Demog.bar1)
show(Demog.bar2)




Much thanks,
Robert

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Fri Dec 30 19:37:34 2016
From: chocold12 at gmail.com (lily li)
Date: Fri, 30 Dec 2016 11:37:34 -0700
Subject: [R] about data format in R
In-Reply-To: <5866A617.5080400@sapo.pt>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
Message-ID: <CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>

Hi Rui,

Thanks for your reply. When I read in data using my code, the first column
ranges from 0 to 1. So when I use the code you wrote, it shows the error
message:
Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
'origin' must be supplied


On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Have you tried
>
> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>
> ?
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 30-12-2016 17:40, lily li escreveu:
>
>> Hi R users,
>>
>> I'm trying to read in data, and then plot time series data. However, I
>> have
>> some problems. In my dataset, the first column represents time, and in the
>> format:
>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>> 10/01/1995-06:00:00, etc.
>>
>> df:
>>             date                    evap     precip    intercept
>> 10/01/1995-00:00:00       1.5          2            0.2
>> 10/01/1995-12:00:00       1.7          2.2         0.1
>> 10/02/1995-00:00:00       1.5          1.8         0.3
>> ...
>>
>> My code is like this
>> file1 = read.table('df', head=T)
>>
>> When I read in data, I found that it read incorrectly. How to format when
>> read in data? Thanks.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Fri Dec 30 19:46:38 2016
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 30 Dec 2016 12:46:38 -0600
Subject: [R] help for
In-Reply-To: <CAM_vju=vMbXiMLkSaMhbZWRXTCoT=uSKYSu2R8GkkU_3MwY8tQ@mail.gmail.com>
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
	<242722337.3953531.1483120632122@mail.yahoo.com>
	<CAM_vju=vMbXiMLkSaMhbZWRXTCoT=uSKYSu2R8GkkU_3MwY8tQ@mail.gmail.com>
Message-ID: <CAAJSdjjADSEbjMKt_wuNY8a0nXg+UjEcnrvJTYwJs5huud73uA@mail.gmail.com>

On Fri, Dec 30, 2016 at 12:08 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> This isn't an R question, but a linux question.
>
> Open a new terminal window:
> The directions you are following tell you how to do that for the
> Ubuntu linux being used, right at the beginning:
>
> Open up a terminal (Applications->Accessories->Terminal from the the
> toolbar)
>
> As for your command, the $ is a prompt. You don't type that. Start with ls
>
> What should you do now? Read a little bit about using linux command line
> tools
>

?Well, this being the R language forum, perhaps you should enter "R" after
the command prompt?

Seriously, what do you want to accomplish? Since you are using Ubuntu, I
will assume that you are using the default shell program, BASH. There is a
BASH forum you could join called mailto:help-bash at gnu.org . It's easiest to
sign up here:
https://lists.gnu.org/mailman/listinfo/help-bash
This site has some nice articles about BASH and programming (scripting)
using it: http://wiki.bash-hackers.org/
BASH for beginners: http://www.tldp.org/LDP/Bash-Beginners-Guide/html/
Since you seem to be using Ubuntu:
https://help.ubuntu.com/community/Beginners/BashScripting

There are _TONS_ of commands installed in Ubuntu by default. Most of them
have manual (man) pages. Most of the defaults are in the directory
/usr/bin. You can list them simply by entering the command: "ls /usr/bin".
My system has over 6,500 programs stuffed in there. If you see something
interesting, you can get some basic documentation on it by using the
command: "man <cmd-name>". We've mentioned "ls", which lists the contents
of a directory. If you want to know more, try "man ls". In addition to
"man" there is a much more powerful information source called "info". Just
use it instead of "man" as the command name. That is, use "info ls" to get
some real detailed information on the ls command.

Another interesting command is "apropos". Think of it as being similar to
the R systems' double question mark search. As an example, suppose you want
to find out what commands might be helpful with a "zip" file. Enter the
command: "apropos zip". On my system, I get a (truncated) response such as:

bunzip2 (1)          - a block-sorting file compressor, v1.0.6
bzip2 (1)            - a block-sorting file compressor, v1.0.6
bzip2recover (1)     - recovers data from damaged bzip2 files
bzless (1)           - file perusal filter for crt viewing of bzip2
compressed text
decode (n)           - Access to zip archives
encode (n)           - Generation of zip archives
funzip (1)           - filter for extracting from a ZIP archive in a pipe
gunzip (1)           - compress or expand files
gzip (1)             - compress or expand files
IO::Compress::Bzip2 (3pm) - Write bzip2 files/buffers
IO::Compress::Zip (3pm) - Write zip files/buffers
IO::Uncompress::Unzip (3pm) - Read zip files/buffers
unzip (1)            - list, test and extract compressed files in a ZIP
archive
unzipsfx (1)         - self-extracting stub for prepending to ZIP archives
zforce (1)           - force a '.gz' extension on all gzip files
zip (1)              - package and compress (archive) files
zipcloak (1)         - encrypt entries in a zipfile

Note the number in the parentheses after the command. A "1" indicates this
is a normal command. Something which starts with a "3" (like 3pm) means
this is like a subroutine package (The "pm" in 3pm means "Perl Module" -
like an R package, sort of). Also note that some of the entries have
nothing to do with a normal "zip" file; such as the entires with bzip2 in
them - bzip2 is an alternative compressor program).

I'm fairly good with BASH, having programmed for over 3 decades, and used
BASH for about 10 years. Which is both good and bad. The good is that I
understand BASH fairly well. The bad is that I like "tricky coding" (a
personal problem).



>
> Sarah
>
>
-- 
There?s no obfuscated Perl contest because it?s pointless.

?Jeff Polk

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Dec 30 19:47:02 2016
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 30 Dec 2016 13:47:02 -0500
Subject: [R] about data format in R
In-Reply-To: <CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
Message-ID: <CAM_vjunADyTB3GtNcys0eZUDC-5zVgr9+B7nCtb6hoFgxyNnTw@mail.gmail.com>

Probably you need to use

file1 <- read.table('df', header=TRUE, stringsAsFactors=FALSE)

str(file1)

generally shows you all sorts of useful things about the file you have
just imported into R.

Sarah

On Fri, Dec 30, 2016 at 1:37 PM, lily li <chocold12 at gmail.com> wrote:
> Hi Rui,
>
> Thanks for your reply. When I read in data using my code, the first column
> ranges from 0 to 1. So when I use the code you wrote, it shows the error
> message:
> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
> 'origin' must be supplied
>
>
> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Have you tried
>>
>> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>>
>> ?
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Em 30-12-2016 17:40, lily li escreveu:
>>
>>> Hi R users,
>>>
>>> I'm trying to read in data, and then plot time series data. However, I
>>> have
>>> some problems. In my dataset, the first column represents time, and in the
>>> format:
>>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>>> 10/01/1995-06:00:00, etc.
>>>
>>> df:
>>>             date                    evap     precip    intercept
>>> 10/01/1995-00:00:00       1.5          2            0.2
>>> 10/01/1995-12:00:00       1.7          2.2         0.1
>>> 10/02/1995-00:00:00       1.5          1.8         0.3
>>> ...
>>>
>>> My code is like this
>>> file1 = read.table('df', head=T)
>>>
>>> When I read in data, I found that it read incorrectly. How to format when
>>> read in data? Thanks.
>>>


From ruipbarradas at sapo.pt  Fri Dec 30 19:56:12 2016
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 30 Dec 2016 18:56:12 +0000
Subject: [R] about data format in R
In-Reply-To: <CAM_vjunADyTB3GtNcys0eZUDC-5zVgr9+B7nCtb6hoFgxyNnTw@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>	<5866A617.5080400@sapo.pt>	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<CAM_vjunADyTB3GtNcys0eZUDC-5zVgr9+B7nCtb6hoFgxyNnTw@mail.gmail.com>
Message-ID: <5866ADCC.2070409@sapo.pt>

Hello,

What I did was:

DF <- read.table(text = "
date                    evap     precip    intercept
10/01/1995-00:00:00       1.5          2            0.2
10/01/1995-12:00:00       1.7          2.2         0.1
10/02/1995-00:00:00       1.5          1.8         0.3
", header = TRUE, stringsAsFactors = FALSE)

str(DF)

DF$date <- as.POSIXct(DF$date, format = "%m/%d/%Y-%H:%M:%S")
str(DF)

And it worked with no errors.

Rui Barradas

Em 30-12-2016 18:47, Sarah Goslee escreveu:
> Probably you need to use
>
> file1 <- read.table('df', header=TRUE, stringsAsFactors=FALSE)
>
> str(file1)
>
> generally shows you all sorts of useful things about the file you have
> just imported into R.
>
> Sarah
>
> On Fri, Dec 30, 2016 at 1:37 PM, lily li <chocold12 at gmail.com> wrote:
>> Hi Rui,
>>
>> Thanks for your reply. When I read in data using my code, the first column
>> ranges from 0 to 1. So when I use the code you wrote, it shows the error
>> message:
>> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
>> 'origin' must be supplied
>>
>>
>> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>>
>>> Hello,
>>>
>>> Have you tried
>>>
>>> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>>>
>>> ?
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>>> Em 30-12-2016 17:40, lily li escreveu:
>>>
>>>> Hi R users,
>>>>
>>>> I'm trying to read in data, and then plot time series data. However, I
>>>> have
>>>> some problems. In my dataset, the first column represents time, and in the
>>>> format:
>>>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>>>> 10/01/1995-06:00:00, etc.
>>>>
>>>> df:
>>>>              date                    evap     precip    intercept
>>>> 10/01/1995-00:00:00       1.5          2            0.2
>>>> 10/01/1995-12:00:00       1.7          2.2         0.1
>>>> 10/02/1995-00:00:00       1.5          1.8         0.3
>>>> ...
>>>>
>>>> My code is like this
>>>> file1 = read.table('df', head=T)
>>>>
>>>> When I read in data, I found that it read incorrectly. How to format when
>>>> read in data? Thanks.
>>>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Fri Dec 30 20:09:36 2016
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 30 Dec 2016 14:09:36 -0500
Subject: [R] stacked and dodged bar graph ggplot
In-Reply-To: <CACYeG1ikQ4XhHz1g7ZUtpgCF1utjnVN1cewa8_AvWuB5AQwMEg@mail.gmail.com>
References: <CACYeG1ikQ4XhHz1g7ZUtpgCF1utjnVN1cewa8_AvWuB5AQwMEg@mail.gmail.com>
Message-ID: <CAGx1TMDdCuwxLK6hNM=z9GCxV5tJJ2SkzJi0qL16WO8nkGTScQ@mail.gmail.com>

I reproduced your graphs, but I don't understand what you want instead.

There are several problems.
  one group is spelled "Lantinx".
  your factor statements mostly lead to NA values.
  The two panels of the plot do not use the same number of inches of
the plotting window, due to different widths of the legends.


On Fri, Dec 30, 2016 at 1:30 PM, Robert Lynch <robert.b.lynch at gmail.com> wrote:
> I have some census data with race and ethnicity for various towns.  I am
> trying to make a stacked bar graph where all the race data is in one
> stacked bar, and all the ethnicity data is in another.
>
> Below is a minimal reproducible sample.
>
> library("ggplot2")
>
> Demog <-
> data.frame(source=c(rep("Davis",4),rep("Dixon",4),rep("Winters",4)),
>             group =c("Asian / Pacific Islander","Caucasian","Lantinx","Not
> Latinx","African American", "Native American", "Latinx", "Not
> Latinx","Mixed race","Other","Latinx", "Not Latinx"),
>             number =c(14491, 42571, 8172, 57450, 562, 184, 7426, 10952,
> 332, 1488, 3469, 3155),
>             field = rep(c(rep("race",2),rep("ethnicity",2)),3))
>
> Demog$race <- factor(Demog$group, levels=c("Asian / Pacific Islander",
> "Caucasian", "African American", "Native American / Alaska Native",  "mixed
> race",  "other"))
> Demog$ethn <- factor(Demog$group, levels=c("Latinx","not latinx"))
> Demog$location <- factor(Demog$source, levels=c( "Dixon",
> "Winters","Davis"))
> Demog.bar1 <-ggplot(data = Demog, aes(x = location, y = number, fill =
> race))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
> coord_flip()
>
> Demog.bar2 <-ggplot(data = Demog, aes(x = location, y = number, fill =
> ethn))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
> coord_flip()
>
> show(Demog.bar1)
> show(Demog.bar2)
>
>
>
>
> Much thanks,
> Robert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ulrik.stervbo at gmail.com  Fri Dec 30 20:47:17 2016
From: ulrik.stervbo at gmail.com (Ulrik Stervbo)
Date: Fri, 30 Dec 2016 19:47:17 +0000
Subject: [R] stacked and dodged bar graph ggplot
In-Reply-To: <CAGx1TMDdCuwxLK6hNM=z9GCxV5tJJ2SkzJi0qL16WO8nkGTScQ@mail.gmail.com>
References: <CACYeG1ikQ4XhHz1g7ZUtpgCF1utjnVN1cewa8_AvWuB5AQwMEg@mail.gmail.com>
	<CAGx1TMDdCuwxLK6hNM=z9GCxV5tJJ2SkzJi0qL16WO8nkGTScQ@mail.gmail.com>
Message-ID: <CAKVAULNSpGPas6A6cOiPxh0xcgOmYMx17Fx=hTFVJrRjqyO5PQ@mail.gmail.com>

You can use the tidyr package to combine race and enth into one column and
fill by that. Then you get one colour for race and one for enth.

HTH
Ulrik

On Fri, 30 Dec 2016, 20:12 Richard M. Heiberger, <rmh at temple.edu> wrote:

> I reproduced your graphs, but I don't understand what you want instead.
>
> There are several problems.
>   one group is spelled "Lantinx".
>   your factor statements mostly lead to NA values.
>   The two panels of the plot do not use the same number of inches of
> the plotting window, due to different widths of the legends.
>
>
> On Fri, Dec 30, 2016 at 1:30 PM, Robert Lynch <robert.b.lynch at gmail.com>
> wrote:
> > I have some census data with race and ethnicity for various towns.  I am
> > trying to make a stacked bar graph where all the race data is in one
> > stacked bar, and all the ethnicity data is in another.
> >
> > Below is a minimal reproducible sample.
> >
> > library("ggplot2")
> >
> > Demog <-
> > data.frame(source=c(rep("Davis",4),rep("Dixon",4),rep("Winters",4)),
> >             group =c("Asian / Pacific
> Islander","Caucasian","Lantinx","Not
> > Latinx","African American", "Native American", "Latinx", "Not
> > Latinx","Mixed race","Other","Latinx", "Not Latinx"),
> >             number =c(14491, 42571, 8172, 57450, 562, 184, 7426, 10952,
> > 332, 1488, 3469, 3155),
> >             field = rep(c(rep("race",2),rep("ethnicity",2)),3))
> >
> > Demog$race <- factor(Demog$group, levels=c("Asian / Pacific Islander",
> > "Caucasian", "African American", "Native American / Alaska Native",
> "mixed
> > race",  "other"))
> > Demog$ethn <- factor(Demog$group, levels=c("Latinx","not latinx"))
> > Demog$location <- factor(Demog$source, levels=c( "Dixon",
> > "Winters","Davis"))
> > Demog.bar1 <-ggplot(data = Demog, aes(x = location, y = number, fill =
> > race))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
> > coord_flip()
> >
> > Demog.bar2 <-ggplot(data = Demog, aes(x = location, y = number, fill =
> > ethn))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
> > coord_flip()
> >
> > show(Demog.bar1)
> > show(Demog.bar2)
> >
> >
> >
> >
> > Much thanks,
> > Robert
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dulcalma at bigpond.com  Fri Dec 30 23:01:31 2016
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Sat, 31 Dec 2016 09:01:31 +1100
Subject: [R] about data format in R
In-Reply-To: <CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
Message-ID: <000001d262e8$47bcdca0$d73695e0$@bigpond.com>

Hi

Is this the output from Excel?
If so format it in Excel for a date format not a date-time format . 
Depending how the dates were inputted into Excel and the Excel setup a date
may not be a date format.
There are no rules with microsoft formatting so beware!


Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
Sent: Saturday, 31 December 2016 05:38
To: Rui Barradas
Cc: R mailing list
Subject: Re: [R] about data format in R

Hi Rui,

Thanks for your reply. When I read in data using my code, the first column
ranges from 0 to 1. So when I use the code you wrote, it shows the error
message:
Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
'origin' must be supplied


On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Have you tried
>
> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>
> ?
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Em 30-12-2016 17:40, lily li escreveu:
>
>> Hi R users,
>>
>> I'm trying to read in data, and then plot time series data. However, I
>> have
>> some problems. In my dataset, the first column represents time, and in
the
>> format:
>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>> 10/01/1995-06:00:00, etc.
>>
>> df:
>>             date                    evap     precip    intercept
>> 10/01/1995-00:00:00       1.5          2            0.2
>> 10/01/1995-12:00:00       1.7          2.2         0.1
>> 10/02/1995-00:00:00       1.5          1.8         0.3
>> ...
>>
>> My code is like this
>> file1 = read.table('df', head=T)
>>
>> When I read in data, I found that it read incorrectly. How to format when
>> read in data? Thanks.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Fri Dec 30 23:51:29 2016
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 31 Dec 2016 09:51:29 +1100
Subject: [R] stacked and dodged bar graph ggplot
In-Reply-To: <CACYeG1ikQ4XhHz1g7ZUtpgCF1utjnVN1cewa8_AvWuB5AQwMEg@mail.gmail.com>
References: <CACYeG1ikQ4XhHz1g7ZUtpgCF1utjnVN1cewa8_AvWuB5AQwMEg@mail.gmail.com>
Message-ID: <CA+8X3fWNqNcN-ftvZNvr9uVOLWvxmuSRU4-jUJBDHG3+qPUBAA@mail.gmail.com>

Hi Robert,
I realize that this isn't in ggplot, but are you looking for something
like this?

Demog <-
data.frame(source=c(rep("Davis",4),rep("Dixon",4),rep("Winters",4)),
 group =c("Asian / Pacific Islander","Caucasian","Latinx",
 "Not Latinx","African American", "Native American", "Latinx",
 "Not Latinx","Mixed race","Other","Latinx", "Not Latinx"),
 number =c(14491, 42571, 8172, 57450, 562, 184, 7426, 10952,
 332, 1488, 3469, 3155),
 field = rep(c(rep("race",2),rep("ethnicity",2)),3))
library(plotrix)
barpos<-barp(matrix(Demog$number,ncol=3),
 col=matrix(c("lightsalmon","ivory","brown","blanchedalmond","chocolate",
 "orangered","brown","blanchedalmond","khaki","purple","brown",
 "blanchedalmond"),ncol=3),ylab="Frequency",
 names.arg=c("Davis","Dixon","Winters"))
legend(2,50000,c("Asian/Pacific Is.","Caucasian","Latinx","NonLatinx",
 "African American","Native American","Mixed race","Other"),
 fill=c("lightsalmon","ivory","brown","blanchedalmond","chocolate",
 "orangered","khaki","purple"))
mtext(rep(c("race","ethnicity"),3),side=1,line=0.3,
 at=barpos$x[c(1,4),])

Jim

On Sat, Dec 31, 2016 at 5:30 AM, Robert Lynch <robert.b.lynch at gmail.com> wrote:
> I have some census data with race and ethnicity for various towns.  I am
> trying to make a stacked bar graph where all the race data is in one
> stacked bar, and all the ethnicity data is in another.
>
> Below is a minimal reproducible sample.
>
> library("ggplot2")
>
> Demog <-
> data.frame(source=c(rep("Davis",4),rep("Dixon",4),rep("Winters",4)),
>             group =c("Asian / Pacific Islander","Caucasian","Lantinx","Not
> Latinx","African American", "Native American", "Latinx", "Not
> Latinx","Mixed race","Other","Latinx", "Not Latinx"),
>             number =c(14491, 42571, 8172, 57450, 562, 184, 7426, 10952,
> 332, 1488, 3469, 3155),
>             field = rep(c(rep("race",2),rep("ethnicity",2)),3))
>
> Demog$race <- factor(Demog$group, levels=c("Asian / Pacific Islander",
> "Caucasian", "African American", "Native American / Alaska Native",  "mixed
> race",  "other"))
> Demog$ethn <- factor(Demog$group, levels=c("Latinx","not latinx"))
> Demog$location <- factor(Demog$source, levels=c( "Dixon",
> "Winters","Davis"))
> Demog.bar1 <-ggplot(data = Demog, aes(x = location, y = number, fill =
> race))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
> coord_flip()
>
> Demog.bar2 <-ggplot(data = Demog, aes(x = location, y = number, fill =
> ethn))+theme_bw() +geom_bar(stat = "identity",position = "stack") +
> coord_flip()
>
> show(Demog.bar1)
> show(Demog.bar2)
>
>
>
>
> Much thanks,
> Robert
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ed_isfahani at yahoo.com  Sat Dec 31 01:10:29 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Sat, 31 Dec 2016 00:10:29 +0000 (UTC)
Subject: [R] help for
In-Reply-To: <CAAJSdjjADSEbjMKt_wuNY8a0nXg+UjEcnrvJTYwJs5huud73uA@mail.gmail.com>
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
	<242722337.3953531.1483120632122@mail.yahoo.com>
	<CAM_vju=vMbXiMLkSaMhbZWRXTCoT=uSKYSu2R8GkkU_3MwY8tQ@mail.gmail.com>
	<CAAJSdjjADSEbjMKt_wuNY8a0nXg+UjEcnrvJTYwJs5huud73uA@mail.gmail.com>
Message-ID: <590278105.4199777.1483143029932@mail.yahoo.com>

actually I do not work with linux. do you know same of this tutorial for windows? 

    On Friday, December 30, 2016 10:16 PM, John McKown <john.archie.mckown at gmail.com> wrote:
 

 On Fri, Dec 30, 2016 at 12:08 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

This isn't an R question, but a linux question.

Open a new terminal window:
The directions you are following tell you how to do that for the
Ubuntu linux being used, right at the beginning:

Open up a terminal (Applications->Accessories-> Terminal from the the toolbar)

As for your command, the $ is a prompt. You don't type that. Start with ls

What should you do now? Read a little bit about using linux command line tools


?Well, this being the R language forum, perhaps you should enter "R" after the command prompt?
Seriously, what do you want to accomplish? Since you are using Ubuntu, I will assume that you are using the default shell program, BASH. There is a BASH forum you could join called mailto:help-bash at gnu.org . It's easiest to sign up here:?https://lists.gnu.org/mailman/listinfo/help-bashThis site has some nice articles about BASH and programming (scripting) using it:?http://wiki.bash-hackers.org/BASH for beginners:?http://www.tldp.org/LDP/Bash-Beginners-Guide/html/Since you seem to be using Ubuntu:?https://help.ubuntu.com/community/Beginners/BashScripting
There are _TONS_ of commands installed in Ubuntu by default. Most of them have manual (man) pages. Most of the defaults are in the directory /usr/bin. You can list them simply by entering the command: "ls /usr/bin". My system has over 6,500 programs stuffed in there. If you see something interesting, you can get some basic documentation on it by using the command: "man <cmd-name>". We've mentioned "ls", which lists the contents of a directory. If you want to know more, try "man ls". In addition to "man" there is a much more powerful information source called "info". Just use it instead of "man" as the command name. That is, use "info ls" to get some real detailed information on the ls command.
Another interesting command is "apropos". Think of it as being similar to the R systems' double question mark search. As an example, suppose you want to find out what commands might be helpful with a "zip" file. Enter the command: "apropos zip". On my system, I get a (truncated) response such as:
bunzip2 (1) ? ? ? ? ?- a block-sorting file compressor, v1.0.6bzip2 (1) ? ? ? ? ? ?- a block-sorting file compressor, v1.0.6
bzip2recover (1) ? ? - recovers data from damaged bzip2 filesbzless (1) ? ? ? ? ? - file perusal filter for crt viewing of bzip2 compressed textdecode (n) ? ? ? ? ? - Access to zip archives
encode (n) ? ? ? ? ? - Generation of zip archives
funzip (1) ? ? ? ? ? - filter for extracting from a ZIP archive in a pipegunzip (1) ? ? ? ? ? - compress or expand files
gzip (1) ? ? ? ? ? ? - compress or expand filesIO::Compress::Bzip2 (3pm) - Write bzip2 files/buffers
IO::Compress::Zip (3pm) - Write zip files/buffers
IO::Uncompress::Unzip (3pm) - Read zip files/buffers
unzip (1) ? ? ? ? ? ?- list, test and extract compressed files in a ZIP archive
unzipsfx (1) ? ? ? ? - self-extracting stub for prepending to ZIP archiveszforce (1) ? ? ? ? ? - force a '.gz' extension on all gzip fileszip (1) ? ? ? ? ? ? ?- package and compress (archive) fileszipcloak (1) ? ? ? ? - encrypt entries in a zipfile
Note the number in the parentheses after the command. A "1" indicates this is a normal command. Something which starts with a "3" (like 3pm) means this is like a subroutine package (The "pm" in 3pm means "Perl Module" - like an R package, sort of). Also note that some of the entries have nothing to do with a normal "zip" file; such as the entires with bzip2 in them - bzip2 is an alternative compressor program).

I'm fairly good with BASH, having programmed for over 3 decades, and used BASH for about 10 years. Which is both good and bad. The good is that I understand BASH fairly well. The bad is that I like "tricky coding" (a personal problem).
?

Sarah



-- 
There?s no obfuscated Perl contest because it?s pointless.

?Jeff Polk
Maranatha! <><
John McKown

   
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Dec 31 01:20:26 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 30 Dec 2016 16:20:26 -0800
Subject: [R] help for
In-Reply-To: <242722337.3953531.1483120632122@mail.yahoo.com>
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
	<242722337.3953531.1483120632122@mail.yahoo.com>
Message-ID: <7FC94B61-8DDA-4816-8063-25C33E47D634@comcast.net>


> On Dec 30, 2016, at 9:57 AM, Elham - via R-help <r-help at r-project.org> wrote:
> 
> hi all, I am following http://bioinformatics.knowledgeblog.org/2011/06/20/analysing-microarray-data-in-bioconductor/

That page was designed by and for someone with  Linux installation. To quote from the opening paragraph: "Some familiarity with Linux is ideal and the instructions were developed on Ubuntu 11.04, R 2.12.1. For a full code listing for this tutorial and figures resulting from it see the second part of the article."

> I need to download phenotypic data in the form of text file that describe chip names, and the source of the biological samples as well as probe that hybridised to them. I can not understand the mean of "Open a new terminal window and type".
> i am using command.$ ls data/*.CEL > data/phenodata.txt in R
> 
> this returns an error
> 
> 
> $ ls data/*.CEL > data/phenodata.txt Error: unexpected '$' in "$"
> what should I do now?

It later runs out that you are on Windows?  .... ???

> 
> 	[[alternative HTML version deleted]]
> 

There is a help facility for BioC questions. (I think it might now  be web-based unlike this mailing list which remains plain text.)  I suggest you read the Posting Guide more thoroughly that it appears you have so far.


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ed_isfahani at yahoo.com  Sat Dec 31 01:24:03 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Sat, 31 Dec 2016 00:24:03 +0000 (UTC)
Subject: [R] help for
In-Reply-To: <7FC94B61-8DDA-4816-8063-25C33E47D634@comcast.net>
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
	<242722337.3953531.1483120632122@mail.yahoo.com>
	<7FC94B61-8DDA-4816-8063-25C33E47D634@comcast.net>
Message-ID: <599225654.4238252.1483143843222@mail.yahoo.com>

yes me too,but I do not have time to install and learn linux,I need tutorial based on windows 

    On Saturday, December 31, 2016 3:50 AM, David Winsemius <dwinsemius at comcast.net> wrote:
 

 
> On Dec 30, 2016, at 9:57 AM, Elham - via R-help <r-help at r-project.org> wrote:
> 
> hi all, I am following http://bioinformatics.knowledgeblog.org/2011/06/20/analysing-microarray-data-in-bioconductor/

That page was designed by and for someone with? Linux installation. To quote from the opening paragraph: "Some familiarity with Linux is ideal and the instructions were developed on Ubuntu 11.04, R 2.12.1. For a full code listing for this tutorial and figures resulting from it see the second part of the article."

> I need to download phenotypic data in the form of text file that describe chip names, and the source of the biological samples as well as probe that hybridised to them. I can not understand the mean of "Open a new terminal window and type".
> i am using command.$ ls data/*.CEL > data/phenodata.txt in R
> 
> this returns an error
> 
> 
> $ ls data/*.CEL > data/phenodata.txt Error: unexpected '$' in "$"
> what should I do now?

It later runs out that you are on Windows?? .... ???

> 
> ??? [[alternative HTML version deleted]]
> 

There is a help facility for BioC questions. (I think it might now? be web-based unlike this mailing list which remains plain text.)? I suggest you read the Posting Guide more thoroughly that it appears you have so far.


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


   
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Dec 31 01:46:57 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 30 Dec 2016 16:46:57 -0800
Subject: [R] help for
In-Reply-To: <599225654.4238252.1483143843222@mail.yahoo.com>
References: <242722337.3953531.1483120632122.ref@mail.yahoo.com>
	<242722337.3953531.1483120632122@mail.yahoo.com>
	<7FC94B61-8DDA-4816-8063-25C33E47D634@comcast.net>
	<599225654.4238252.1483143843222@mail.yahoo.com>
Message-ID: <8C698BF3-0FE4-435B-A4A0-98A4DAC89832@comcast.net>


> On Dec 30, 2016, at 4:24 PM, Elham - <ed_isfahani at yahoo.com> wrote:
> 
> yes me too,but I do not have time to install and learn linux,I need tutorial based on windows

Fine. But you are asking in the wrong place. It's a BioC question. Most of us here are not Bioc users. Use the forum that is designed for that purpose.

-- 
David.


> 
> 
> On Saturday, December 31, 2016 3:50 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> 
> > On Dec 30, 2016, at 9:57 AM, Elham - via R-help <r-help at r-project.org> wrote:
> > 
> > hi all, I am following http://bioinformatics.knowledgeblog.org/2011/06/20/analysing-microarray-data-in-bioconductor/
> 
> That page was designed by and for someone with  Linux installation. To quote from the opening paragraph: "Some familiarity with Linux is ideal and the instructions were developed on Ubuntu 11.04, R 2.12.1. For a full code listing for this tutorial and figures resulting from it see the second part of the article."
> 
> > I need to download phenotypic data in the form of text file that describe chip names, and the source of the biological samples as well as probe that hybridised to them. I can not understand the mean of "Open a new terminal window and type".
> > i am using command.$ ls data/*.CEL > data/phenodata.txt in R
> > 
> > this returns an error
> > 
> > 
> > $ ls data/*.CEL > data/phenodata.txt Error: unexpected '$' in "$"
> > what should I do now?
> 
> It later runs out that you are on Windows?  .... ???
> 
> > 
> >     [[alternative HTML version deleted]]
> > 
> 
> There is a help facility for BioC questions. (I think it might now  be web-based unlike this mailing list which remains plain text.)  I suggest you read the Posting Guide more thoroughly that it appears you have so far.
> 
> 
> 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 
> 

David Winsemius
Alameda, CA, USA


From chocold12 at gmail.com  Sat Dec 31 18:26:41 2016
From: chocold12 at gmail.com (lily li)
Date: Sat, 31 Dec 2016 10:26:41 -0700
Subject: [R] about data format in R
In-Reply-To: <000001d262e8$47bcdca0$d73695e0$@bigpond.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<000001d262e8$47bcdca0$d73695e0$@bigpond.com>
Message-ID: <CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>

Hi all,

Thanks for your help. Now I can convert data to the format "yyyy-mm-dd
hh:mm:ss", but how to convert it to "yyyy-mm-dd"? The datasets are txt
files, not from excel.

On Fri, Dec 30, 2016 at 3:01 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:

> Hi
>
> Is this the output from Excel?
> If so format it in Excel for a date format not a date-time format .
> Depending how the dates were inputted into Excel and the Excel setup a date
> may not be a date format.
> There are no rules with microsoft formatting so beware!
>
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> Sent: Saturday, 31 December 2016 05:38
> To: Rui Barradas
> Cc: R mailing list
> Subject: Re: [R] about data format in R
>
> Hi Rui,
>
> Thanks for your reply. When I read in data using my code, the first column
> ranges from 0 to 1. So when I use the code you wrote, it shows the error
> message:
> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
> 'origin' must be supplied
>
>
> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt>
> wrote:
>
> > Hello,
> >
> > Have you tried
> >
> > df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
> >
> > ?
> >
> > Hope this helps,
> >
> > Rui Barradas
> >
> >
> >
> > Em 30-12-2016 17:40, lily li escreveu:
> >
> >> Hi R users,
> >>
> >> I'm trying to read in data, and then plot time series data. However, I
> >> have
> >> some problems. In my dataset, the first column represents time, and in
> the
> >> format:
> >> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
> >> 10/01/1995-06:00:00, etc.
> >>
> >> df:
> >>             date                    evap     precip    intercept
> >> 10/01/1995-00:00:00       1.5          2            0.2
> >> 10/01/1995-12:00:00       1.7          2.2         0.1
> >> 10/02/1995-00:00:00       1.5          1.8         0.3
> >> ...
> >>
> >> My code is like this
> >> file1 = read.table('df', head=T)
> >>
> >> When I read in data, I found that it read incorrectly. How to format
> when
> >> read in data? Thanks.
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> ng-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Dec 31 18:36:59 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 31 Dec 2016 09:36:59 -0800
Subject: [R] about data format in R
In-Reply-To: <CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<000001d262e8$47bcdca0$d73695e0$@bigpond.com>
	<CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
Message-ID: <CAGxFJbQ6YinPkN-PQmeZHct+iSU2xktu-p6McA4dg6Ay_1RDPw@mail.gmail.com>

?substring

(among others)

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 31, 2016 at 9:26 AM, lily li <chocold12 at gmail.com> wrote:
> Hi all,
>
> Thanks for your help. Now I can convert data to the format "yyyy-mm-dd
> hh:mm:ss", but how to convert it to "yyyy-mm-dd"? The datasets are txt
> files, not from excel.
>
> On Fri, Dec 30, 2016 at 3:01 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
>
>> Hi
>>
>> Is this the output from Excel?
>> If so format it in Excel for a date format not a date-time format .
>> Depending how the dates were inputted into Excel and the Excel setup a date
>> may not be a date format.
>> There are no rules with microsoft formatting so beware!
>>
>>
>> Regards
>>
>> Duncan
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
>> Sent: Saturday, 31 December 2016 05:38
>> To: Rui Barradas
>> Cc: R mailing list
>> Subject: Re: [R] about data format in R
>>
>> Hi Rui,
>>
>> Thanks for your reply. When I read in data using my code, the first column
>> ranges from 0 to 1. So when I use the code you wrote, it shows the error
>> message:
>> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
>> 'origin' must be supplied
>>
>>
>> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>>
>> > Hello,
>> >
>> > Have you tried
>> >
>> > df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>> >
>> > ?
>> >
>> > Hope this helps,
>> >
>> > Rui Barradas
>> >
>> >
>> >
>> > Em 30-12-2016 17:40, lily li escreveu:
>> >
>> >> Hi R users,
>> >>
>> >> I'm trying to read in data, and then plot time series data. However, I
>> >> have
>> >> some problems. In my dataset, the first column represents time, and in
>> the
>> >> format:
>> >> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>> >> 10/01/1995-06:00:00, etc.
>> >>
>> >> df:
>> >>             date                    evap     precip    intercept
>> >> 10/01/1995-00:00:00       1.5          2            0.2
>> >> 10/01/1995-12:00:00       1.7          2.2         0.1
>> >> 10/02/1995-00:00:00       1.5          1.8         0.3
>> >> ...
>> >>
>> >> My code is like this
>> >> file1 = read.table('df', head=T)
>> >>
>> >> When I read in data, I found that it read incorrectly. How to format
>> when
>> >> read in data? Thanks.
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/posti
>> >> ng-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Sat Dec 31 18:51:54 2016
From: chocold12 at gmail.com (lily li)
Date: Sat, 31 Dec 2016 10:51:54 -0700
Subject: [R] about data format in R
In-Reply-To: <CAGxFJbQ6YinPkN-PQmeZHct+iSU2xktu-p6McA4dg6Ay_1RDPw@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<000001d262e8$47bcdca0$d73695e0$@bigpond.com>
	<CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
	<CAGxFJbQ6YinPkN-PQmeZHct+iSU2xktu-p6McA4dg6Ay_1RDPw@mail.gmail.com>
Message-ID: <CAN5afy-Ki4XyYpf2pEXJ6i88y5WgoB78N+jCH5=9DPW+-yEM9w@mail.gmail.com>

Thanks. It seems that substrings only subset the data, not convert the
format. For example, I use the code below:
DF$time = substring(DF$time, '%Y-%m-%d')

where DF$time has the structure:
'2002-01-01 00:00:00', '2002-01-01 12:00:00', '2003-01-01 00:00:00',
'2003-01-01 12:00:00', etc.
I wanted to convert the 'time' column to '2002-01-01', '2002-01-01',
'2003-01-01', '2003-01-01', etc.

Using the code above, it gives the error message:
Error in as.POSIXlt.character(as.character(x), ...) :
  character string is not in a standard unambiguous format

On Sat, Dec 31, 2016 at 10:36 AM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> ?substring
>
> (among others)
>
> -- Bert
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sat, Dec 31, 2016 at 9:26 AM, lily li <chocold12 at gmail.com> wrote:
> > Hi all,
> >
> > Thanks for your help. Now I can convert data to the format "yyyy-mm-dd
> > hh:mm:ss", but how to convert it to "yyyy-mm-dd"? The datasets are txt
> > files, not from excel.
> >
> > On Fri, Dec 30, 2016 at 3:01 PM, Duncan Mackay <dulcalma at bigpond.com>
> wrote:
> >
> >> Hi
> >>
> >> Is this the output from Excel?
> >> If so format it in Excel for a date format not a date-time format .
> >> Depending how the dates were inputted into Excel and the Excel setup a
> date
> >> may not be a date format.
> >> There are no rules with microsoft formatting so beware!
> >>
> >>
> >> Regards
> >>
> >> Duncan
> >>
> >> Duncan Mackay
> >> Department of Agronomy and Soil Science
> >> University of New England
> >> Armidale NSW 2351
> >> Email: home: mackay at northnet.com.au
> >>
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> >> Sent: Saturday, 31 December 2016 05:38
> >> To: Rui Barradas
> >> Cc: R mailing list
> >> Subject: Re: [R] about data format in R
> >>
> >> Hi Rui,
> >>
> >> Thanks for your reply. When I read in data using my code, the first
> column
> >> ranges from 0 to 1. So when I use the code you wrote, it shows the error
> >> message:
> >> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
> >> 'origin' must be supplied
> >>
> >>
> >> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt>
> >> wrote:
> >>
> >> > Hello,
> >> >
> >> > Have you tried
> >> >
> >> > df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
> >> >
> >> > ?
> >> >
> >> > Hope this helps,
> >> >
> >> > Rui Barradas
> >> >
> >> >
> >> >
> >> > Em 30-12-2016 17:40, lily li escreveu:
> >> >
> >> >> Hi R users,
> >> >>
> >> >> I'm trying to read in data, and then plot time series data. However,
> I
> >> >> have
> >> >> some problems. In my dataset, the first column represents time, and
> in
> >> the
> >> >> format:
> >> >> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
> >> >> 10/01/1995-06:00:00, etc.
> >> >>
> >> >> df:
> >> >>             date                    evap     precip    intercept
> >> >> 10/01/1995-00:00:00       1.5          2            0.2
> >> >> 10/01/1995-12:00:00       1.7          2.2         0.1
> >> >> 10/02/1995-00:00:00       1.5          1.8         0.3
> >> >> ...
> >> >>
> >> >> My code is like this
> >> >> file1 = read.table('df', head=T)
> >> >>
> >> >> When I read in data, I found that it read incorrectly. How to format
> >> when
> >> >> read in data? Thanks.
> >> >>
> >> >>         [[alternative HTML version deleted]]
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide http://www.R-project.org/posti
> >> >> ng-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Dec 31 18:52:45 2016
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 31 Dec 2016 09:52:45 -0800
Subject: [R] about data format in R
In-Reply-To: <CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<000001d262e8$47bcdca0$d73695e0$@bigpond.com>
	<CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
Message-ID: <F5EBA0FF-3ECD-4069-A8FD-5C13025DE982@comcast.net>


> On Dec 31, 2016, at 9:26 AM, lily li <chocold12 at gmail.com> wrote:
> 
> Hi all,
> 
> Thanks for your help. Now I can convert data to the format "yyyy-mm-dd
> hh:mm:ss", but how to convert it to "yyyy-mm-dd"? The datasets are txt
> files, not from excel.

Use: as.Date
> 
> On Fri, Dec 30, 2016 at 3:01 PM, Duncan Mackay <dulcalma at bigpond.com> wrote:
> 
>> Hi
>> 
>> Is this the output from Excel?
>> If so format it in Excel for a date format not a date-time format .
>> Depending how the dates were inputted into Excel and the Excel setup a date
>> may not be a date format.
>> There are no rules with microsoft formatting so beware!
>> 
>> 
>> Regards
>> 
>> Duncan
>> 
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
>> Sent: Saturday, 31 December 2016 05:38
>> To: Rui Barradas
>> Cc: R mailing list
>> Subject: Re: [R] about data format in R
>> 
>> Hi Rui,
>> 
>> Thanks for your reply. When I read in data using my code, the first column
>> ranges from 0 to 1. So when I use the code you wrote, it shows the error
>> message:
>> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
>> 'origin' must be supplied
>> 
>> 
>> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt>
>> wrote:
>> 
>>> Hello,
>>> 
>>> Have you tried
>>> 
>>> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>>> 
>>> ?
>>> 
>>> Hope this helps,
>>> 
>>> Rui Barradas
>>> 
>>> 
>>> 
>>> Em 30-12-2016 17:40, lily li escreveu:
>>> 
>>>> Hi R users,
>>>> 
>>>> I'm trying to read in data, and then plot time series data. However, I
>>>> have
>>>> some problems. In my dataset, the first column represents time, and in
>> the
>>>> format:
>>>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>>>> 10/01/1995-06:00:00, etc.
>>>> 
>>>> df:
>>>>            date                    evap     precip    intercept
>>>> 10/01/1995-00:00:00       1.5          2            0.2
>>>> 10/01/1995-12:00:00       1.7          2.2         0.1
>>>> 10/02/1995-00:00:00       1.5          1.8         0.3
>>>> ...
>>>> 
>>>> My code is like this
>>>> file1 = read.table('df', head=T)
>>>> 
>>>> When I read in data, I found that it read incorrectly. How to format
>> when
>>>> read in data? Thanks.
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>>> ng-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From chocold12 at gmail.com  Sat Dec 31 19:02:41 2016
From: chocold12 at gmail.com (lily li)
Date: Sat, 31 Dec 2016 11:02:41 -0700
Subject: [R] about data format in R
In-Reply-To: <F5EBA0FF-3ECD-4069-A8FD-5C13025DE982@comcast.net>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<000001d262e8$47bcdca0$d73695e0$@bigpond.com>
	<CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
	<F5EBA0FF-3ECD-4069-A8FD-5C13025DE982@comcast.net>
Message-ID: <CAN5afy9Hxm1utQ70u2BG-OZSp0CE9yTtiB8EZ_MoBnVp4V3DbQ@mail.gmail.com>

I tried it, but it doesn't work. The time column is blank then.
DF$time = substring(DF$time, first=as.Date('1999-01-01),
last=as.Date('2005-12-30'))

On Sat, Dec 31, 2016 at 10:52 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Dec 31, 2016, at 9:26 AM, lily li <chocold12 at gmail.com> wrote:
> >
> > Hi all,
> >
> > Thanks for your help. Now I can convert data to the format "yyyy-mm-dd
> > hh:mm:ss", but how to convert it to "yyyy-mm-dd"? The datasets are txt
> > files, not from excel.
>
> Use: as.Date
> >
> > On Fri, Dec 30, 2016 at 3:01 PM, Duncan Mackay <dulcalma at bigpond.com>
> wrote:
> >
> >> Hi
> >>
> >> Is this the output from Excel?
> >> If so format it in Excel for a date format not a date-time format .
> >> Depending how the dates were inputted into Excel and the Excel setup a
> date
> >> may not be a date format.
> >> There are no rules with microsoft formatting so beware!
> >>
> >>
> >> Regards
> >>
> >> Duncan
> >>
> >> Duncan Mackay
> >> Department of Agronomy and Soil Science
> >> University of New England
> >> Armidale NSW 2351
> >> Email: home: mackay at northnet.com.au
> >>
> >> -----Original Message-----
> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily li
> >> Sent: Saturday, 31 December 2016 05:38
> >> To: Rui Barradas
> >> Cc: R mailing list
> >> Subject: Re: [R] about data format in R
> >>
> >> Hi Rui,
> >>
> >> Thanks for your reply. When I read in data using my code, the first
> column
> >> ranges from 0 to 1. So when I use the code you wrote, it shows the error
> >> message:
> >> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
> >> 'origin' must be supplied
> >>
> >>
> >> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt>
> >> wrote:
> >>
> >>> Hello,
> >>>
> >>> Have you tried
> >>>
> >>> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
> >>>
> >>> ?
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>>
> >>>
> >>> Em 30-12-2016 17:40, lily li escreveu:
> >>>
> >>>> Hi R users,
> >>>>
> >>>> I'm trying to read in data, and then plot time series data. However, I
> >>>> have
> >>>> some problems. In my dataset, the first column represents time, and in
> >> the
> >>>> format:
> >>>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
> >>>> 10/01/1995-06:00:00, etc.
> >>>>
> >>>> df:
> >>>>            date                    evap     precip    intercept
> >>>> 10/01/1995-00:00:00       1.5          2            0.2
> >>>> 10/01/1995-12:00:00       1.7          2.2         0.1
> >>>> 10/02/1995-00:00:00       1.5          1.8         0.3
> >>>> ...
> >>>>
> >>>> My code is like this
> >>>> file1 = read.table('df', head=T)
> >>>>
> >>>> When I read in data, I found that it read incorrectly. How to format
> >> when
> >>>> read in data? Thanks.
> >>>>
> >>>>        [[alternative HTML version deleted]]
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
> >>>> ng-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Sat Dec 31 19:16:21 2016
From: chocold12 at gmail.com (lily li)
Date: Sat, 31 Dec 2016 11:16:21 -0700
Subject: [R] about data format in R
In-Reply-To: <CAN5afy9Hxm1utQ70u2BG-OZSp0CE9yTtiB8EZ_MoBnVp4V3DbQ@mail.gmail.com>
References: <CAN5afy9gppAWtfpkLDqtkKUTsxPpZ=jgq8Y=t2TTgYJYoDEbkw@mail.gmail.com>
	<5866A617.5080400@sapo.pt>
	<CAN5afy8RvRtW4Sf9Lemie6TFqkkHtLrgYaXaNPxR3t15p7pDUA@mail.gmail.com>
	<000001d262e8$47bcdca0$d73695e0$@bigpond.com>
	<CAN5afy_qs+r9L-2SgpKG+xK92Lw+KyZTbOsPiO=fHfDi07HaCA@mail.gmail.com>
	<F5EBA0FF-3ECD-4069-A8FD-5C13025DE982@comcast.net>
	<CAN5afy9Hxm1utQ70u2BG-OZSp0CE9yTtiB8EZ_MoBnVp4V3DbQ@mail.gmail.com>
Message-ID: <CAN5afy_roVuORN7EAEpFkgXP351RW9FziMgashPnMk0fZ7BHQg@mail.gmail.com>

Sorry, the problem has been solved. I found that strptime is a good
function for this.
DF$time2 = strptime(DF$time, format='%Y-%m-%d)


On Sat, Dec 31, 2016 at 11:02 AM, lily li <chocold12 at gmail.com> wrote:

> I tried it, but it doesn't work. The time column is blank then.
> DF$time = substring(DF$time, first=as.Date('1999-01-01),
> last=as.Date('2005-12-30'))
>
> On Sat, Dec 31, 2016 at 10:52 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> > On Dec 31, 2016, at 9:26 AM, lily li <chocold12 at gmail.com> wrote:
>> >
>> > Hi all,
>> >
>> > Thanks for your help. Now I can convert data to the format "yyyy-mm-dd
>> > hh:mm:ss", but how to convert it to "yyyy-mm-dd"? The datasets are txt
>> > files, not from excel.
>>
>> Use: as.Date
>> >
>> > On Fri, Dec 30, 2016 at 3:01 PM, Duncan Mackay <dulcalma at bigpond.com>
>> wrote:
>> >
>> >> Hi
>> >>
>> >> Is this the output from Excel?
>> >> If so format it in Excel for a date format not a date-time format .
>> >> Depending how the dates were inputted into Excel and the Excel setup a
>> date
>> >> may not be a date format.
>> >> There are no rules with microsoft formatting so beware!
>> >>
>> >>
>> >> Regards
>> >>
>> >> Duncan
>> >>
>> >> Duncan Mackay
>> >> Department of Agronomy and Soil Science
>> >> University of New England
>> >> Armidale NSW 2351
>> >> Email: home: mackay at northnet.com.au
>> >>
>> >> -----Original Message-----
>> >> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of lily
>> li
>> >> Sent: Saturday, 31 December 2016 05:38
>> >> To: Rui Barradas
>> >> Cc: R mailing list
>> >> Subject: Re: [R] about data format in R
>> >>
>> >> Hi Rui,
>> >>
>> >> Thanks for your reply. When I read in data using my code, the first
>> column
>> >> ranges from 0 to 1. So when I use the code you wrote, it shows the
>> error
>> >> message:
>> >> Error in as.POSIXct.numeric(DF$Date, format = "%m/%d/%Y-%H:%M:%S") :
>> >> 'origin' must be supplied
>> >>
>> >>
>> >> On Fri, Dec 30, 2016 at 11:23 AM, Rui Barradas <ruipbarradas at sapo.pt>
>> >> wrote:
>> >>
>> >>> Hello,
>> >>>
>> >>> Have you tried
>> >>>
>> >>> df$date <- as.POSIXct(dat$date, format = "%m/%d/%Y-%H:%M:%S")
>> >>>
>> >>> ?
>> >>>
>> >>> Hope this helps,
>> >>>
>> >>> Rui Barradas
>> >>>
>> >>>
>> >>>
>> >>> Em 30-12-2016 17:40, lily li escreveu:
>> >>>
>> >>>> Hi R users,
>> >>>>
>> >>>> I'm trying to read in data, and then plot time series data. However,
>> I
>> >>>> have
>> >>>> some problems. In my dataset, the first column represents time, and
>> in
>> >> the
>> >>>> format:
>> >>>> mm/dd/yyyy-hr:min:sec; For example, 10/01/1995-00:00:00,
>> >>>> 10/01/1995-06:00:00, etc.
>> >>>>
>> >>>> df:
>> >>>>            date                    evap     precip    intercept
>> >>>> 10/01/1995-00:00:00       1.5          2            0.2
>> >>>> 10/01/1995-12:00:00       1.7          2.2         0.1
>> >>>> 10/02/1995-00:00:00       1.5          1.8         0.3
>> >>>> ...
>> >>>>
>> >>>> My code is like this
>> >>>> file1 = read.table('df', head=T)
>> >>>>
>> >>>> When I read in data, I found that it read incorrectly. How to format
>> >> when
>> >>>> read in data? Thanks.
>> >>>>
>> >>>>        [[alternative HTML version deleted]]
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide http://www.R-project.org/posti
>> >>>> ng-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible code.
>> >>>>
>> >>>>
>> >>
>> >>        [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> >> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>

	[[alternative HTML version deleted]]


From dan.abner99 at gmail.com  Sat Dec 31 19:36:58 2016
From: dan.abner99 at gmail.com (Dan Abner)
Date: Sat, 31 Dec 2016 13:36:58 -0500
Subject: [R] Extracting non-matching elements of one vector from another
Message-ID: <CAPRGo-kHzVpP-F6-jix1kBK=Oq=iPoX=BQvFFONB2-JS10v+LQ@mail.gmail.com>

Hi all,

I have 2 vectors and need to extract only the elements from v2 that do not
appear in v1. What is the most efficient way to do this?

In the example below, I need to extract "var1".

v1<-"b0"
v2<-c("b0","var1")

Thanks,

Dan

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Dec 31 19:46:32 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 31 Dec 2016 10:46:32 -0800
Subject: [R] Extracting non-matching elements of one vector from another
In-Reply-To: <CAPRGo-kHzVpP-F6-jix1kBK=Oq=iPoX=BQvFFONB2-JS10v+LQ@mail.gmail.com>
References: <CAPRGo-kHzVpP-F6-jix1kBK=Oq=iPoX=BQvFFONB2-JS10v+LQ@mail.gmail.com>
Message-ID: <CAGxFJbRbypPMC5Hz8Dsj5cYEjSc1nwhEFrpW_y=q4R69Y+5zHA@mail.gmail.com>

?setdiff
## It's a wrapper for ?match

setdiff(v2,v1)

You should go through an R tutorial or two to learn about such handy
basic functionality.

-- Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 31, 2016 at 10:36 AM, Dan Abner <dan.abner99 at gmail.com> wrote:
> Hi all,
>
> I have 2 vectors and need to extract only the elements from v2 that do not
> appear in v1. What is the most efficient way to do this?
>
> In the example below, I need to extract "var1".
>
> v1<-"b0"
> v2<-c("b0","var1")
>
> Thanks,
>
> Dan
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Dec 31 19:50:01 2016
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 31 Dec 2016 13:50:01 -0500
Subject: [R] Extracting non-matching elements of one vector from another
In-Reply-To: <CAPRGo-kHzVpP-F6-jix1kBK=Oq=iPoX=BQvFFONB2-JS10v+LQ@mail.gmail.com>
References: <CAPRGo-kHzVpP-F6-jix1kBK=Oq=iPoX=BQvFFONB2-JS10v+LQ@mail.gmail.com>
Message-ID: <a22e12ea-3459-9c30-86ad-b440be68e978@gmail.com>

On 31/12/2016 1:36 PM, Dan Abner wrote:
> Hi all,
>
> I have 2 vectors and need to extract only the elements from v2 that do not
> appear in v1. What is the most efficient way to do this?
>
> In the example below, I need to extract "var1".
>
> v1<-"b0"
> v2<-c("b0","var1")

setdiff(v2, v1)

Duncan Murdoch


From ed_isfahani at yahoo.com  Sat Dec 31 20:22:10 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Sat, 31 Dec 2016 19:22:10 +0000 (UTC)
Subject: [R] GEOquery
References: <648058441.4592341.1483212130106.ref@mail.yahoo.com>
Message-ID: <648058441.4592341.1483212130106@mail.yahoo.com>

hello all,I am following this link?http://genomicsclass.github.io/book/pages/GEOquery.html?for importing data.but I have a problem in a step of (Access GSE Data Tables from GEO).in the example of tutorial there are 266 samples,but by this function
dim(pData(gse[[1]]))head(pData(gse[[1]])[, 1:3]) ?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??the result in R is:

> dim(pData(gse[[1]]))[1] 266 ?47> head(pData(gse[[1]])[, 1:3])? ? ? ? ? title geo_accession ? ? ? ? ? ? ? ?statusGSM540108 ? BC1 ? ? GSM540108 Public on May 05 2010GSM540109 ? BC2 ? ? GSM540109 Public on May 05 2010GSM540110 ? BC3 ? ? GSM540110 Public on May 05 2010GSM540111 ? BC4 ? ? GSM540111 Public on May 05 2010GSM540112 ? BC5 ? ? GSM540112 Public on May 05 2010GSM540113 ? BC6 ? ? GSM540113 Public on May 05 2010
where is another samples??
	[[alternative HTML version deleted]]


From l.vaneijk at uq.edu.au  Sat Dec 31 03:40:52 2016
From: l.vaneijk at uq.edu.au (Liza van Eijk)
Date: Sat, 31 Dec 2016 02:40:52 +0000
Subject: [R]  3D Elliptic Fourier
Message-ID: <0A6D8165-17CB-4A86-ACDC-07F38FA8D2B9@uq.edu.au>

Dear Yingqi,

Have you had any luck finding a way to run an Elliptic Fourier Analysis on 3D coordinates in R?

If so, could you let me know which package you used?

Thank you.

Kind regards,

Liza


	[[alternative HTML version deleted]]


From spencer.graves at effectivedefense.org  Sat Dec 31 20:51:16 2016
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Sat, 31 Dec 2016 13:51:16 -0600
Subject: [R] 3D Elliptic Fourier
In-Reply-To: <0A6D8165-17CB-4A86-ACDC-07F38FA8D2B9@uq.edu.au>
References: <0A6D8165-17CB-4A86-ACDC-07F38FA8D2B9@uq.edu.au>
Message-ID: <36a54505-61e7-7c3c-3d57-92043ac5c89f@effectivedefense.org>

Have you tried findFn{sos}:


 > library(sos)
 > efa <- findFn('Elliptic Fourier Analysis')
found 10 matches;  retrieving 1 page
Downloaded 0 links in 0 packages.
 > mmcs <- ???Morphometrics
found 71 matches;  retrieving 4 pages
2 3 4
Downloaded 0 links in 0 packages.


       I'm not familiar with Elliptic Fourier Analysis, so I don't know 
what other search terms might be helpful for this.


       A similar search at "http://rdocumentation.org" produced nothing 
that seemed relevant.


       However, the building blocks for what you need are most likely 
available in R.


       Hope this helps.
       Spencer Graves


On 2016-12-30 8:40 PM, Liza van Eijk wrote:
> Dear Yingqi,
>
> Have you had any luck finding a way to run an Elliptic Fourier Analysis on 3D coordinates in R?
>
> If so, could you let me know which package you used?
>
> Thank you.
>
> Kind regards,
>
> Liza
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sat Dec 31 22:35:36 2016
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 31 Dec 2016 13:35:36 -0800
Subject: [R] 3D Elliptic Fourier
In-Reply-To: <36a54505-61e7-7c3c-3d57-92043ac5c89f@effectivedefense.org>
References: <0A6D8165-17CB-4A86-ACDC-07F38FA8D2B9@uq.edu.au>
	<36a54505-61e7-7c3c-3d57-92043ac5c89f@effectivedefense.org>
Message-ID: <CAGxFJbSkp+Ls7J4tMfYmXTDwP2HM_nU3cQBOivXdB_cdcFjrDA@mail.gmail.com>

... and on rseek.org, my personal R search favorite,  the same search
term brought up a ton of stuff, most of which seemed related to the
"Momocs" package.

-- Bert
Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sat, Dec 31, 2016 at 11:51 AM, Spencer Graves
<spencer.graves at effectivedefense.org> wrote:
> Have you tried findFn{sos}:
>
>
>> library(sos)
>> efa <- findFn('Elliptic Fourier Analysis')
> found 10 matches;  retrieving 1 page
> Downloaded 0 links in 0 packages.
>> mmcs <- ???Morphometrics
> found 71 matches;  retrieving 4 pages
> 2 3 4
> Downloaded 0 links in 0 packages.
>
>
>       I'm not familiar with Elliptic Fourier Analysis, so I don't know what
> other search terms might be helpful for this.
>
>
>       A similar search at "http://rdocumentation.org" produced nothing that
> seemed relevant.
>
>
>       However, the building blocks for what you need are most likely
> available in R.
>
>
>       Hope this helps.
>       Spencer Graves
>
>
> On 2016-12-30 8:40 PM, Liza van Eijk wrote:
>>
>> Dear Yingqi,
>>
>> Have you had any luck finding a way to run an Elliptic Fourier Analysis on
>> 3D coordinates in R?
>>
>> If so, could you let me know which package you used?
>>
>> Thank you.
>>
>> Kind regards,
>>
>> Liza
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ed_isfahani at yahoo.com  Sat Dec 31 23:03:18 2016
From: ed_isfahani at yahoo.com (Elham -)
Date: Sat, 31 Dec 2016 22:03:18 +0000 (UTC)
Subject: [R] Access GSE Data Tables from GEO by GEOquery
References: <1860281377.4665224.1483221799041.ref@mail.yahoo.com>
Message-ID: <1860281377.4665224.1483221799041@mail.yahoo.com>

hello all,I am following this link?http://genomicsclass.github.io/book/pages/GEOquery.html?for?importing data.but I have a problem in a step of (Access GSE Data Tables from GEO).in the example of tutorial there are 266 samples,but by this function
? ??


? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ??
?the result in R is:



where is another samples?





























?
? ?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 9038 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161231/db30ea68/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: blob.jpg
Type: image/png
Size: 1777 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20161231/db30ea68/attachment-0001.png>

