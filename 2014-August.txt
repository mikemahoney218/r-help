From honkit at stanford.edu  Fri Aug  1 03:51:48 2014
From: honkit at stanford.edu (Stephen HK Wong)
Date: Thu, 31 Jul 2014 18:51:48 -0700 (PDT)
Subject: [R] how to extract word before /// in a data frame contain many
 thousands rows.
Message-ID: <872839643.6978740.1406857908425.JavaMail.zimbra@stanford.edu>

Dear All,

I appreciate if you can help me out this. I have a data frame contains many thousand of rows, with some rows that has /// symbol,  as shown in in row 2, I want to extract word before ///, such as in this case, CDH23. Many thanks.
Probe.Set.ID            Gene.Symbol
1  1552301_a_at                  CORO6
2  1552436_a_at CDH23 /// LOC100653137
3  1552477_a_at                   IRF6
4  1552685_a_at                  GRHL1
5    1552742_at                  KCNH8
6  1552752_a_at                  CADM2
7    1552799_at                TSNARE1
8  1552897_a_at                  KCNG3
9  1552902_a_at                  FOXP2
10   1552903_at               B4GALNT2


structure(list(Probe.Set.ID = c("1552301_a_at", "1552436_a_at", 
"1552477_a_at", "1552685_a_at", "1552742_at", "1552752_a_at", 
"1552799_at", "1552897_a_at", "1552902_a_at", "1552903_at"), 
    Gene.Symbol = c("CORO6", "CDH23 /// LOC100653137", "IRF6", 
    "GRHL1", "KCNH8", "CADM2", "TSNARE1", "KCNG3", "FOXP2", "B4GALNT2"
    )), .Names = c("Probe.Set.ID", "Gene.Symbol"), row.names = c(NA, 
10L), class = "data.frame")


Stephen HK Wong


From dulcalma at bigpond.com  Fri Aug  1 04:03:07 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 1 Aug 2014 12:03:07 +1000
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD3A3B7@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>,
	<000601cfaabd$f568f130$e03ad390$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD39CFE@ebox-prod-srv04.win.su.se>,
	<001201cfac76$57905970$06b10c50$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD3A3B7@ebox-prod-srv04.win.su.se>
Message-ID: <000c01cfad2c$bdaa88f0$38ff9ad0$@bigpond.com>

Hi Anna

I have gone back to doubleYScale because I started following the wrong
section that I had before so it was quicker to do doubleYScale
You need to have 2 lattice objects and components are taken from each  below
so use the function str on the three objects to see

library(lattice)
library(latticeExtra)

yleft <-
 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        col = c(1:3) # for points
         )

 yright <-
 xyplot(mavg ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        type = "l",
        ylab = "mean",
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c(1:3) )

# colours both y axes so change with next command
yboth <-
doubleYScale(yleft, yright, add.ylab2 = TRUE)
yboth

# change y axes col to suit
update(trellis.last.object(),             # left   # right
       par.settings = simpleTheme(col = c("black", "cyan")))

Duncan


-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se] 
Sent: Friday, 1 August 2014 03:11
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan,

Now I have found a solution to my problem. It is complete except for one
tiny detail: I am unable to define different line types for stuff2 and
stuff3 moving averages (see plot2_3).

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# combine averages into mydata
mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

table(mydata$Type)

# split stuff1 from stuff2/3
datamystuff1 <- mydata[(mydata$Type) %in% c("stuff1"), ]
datamystuff23 <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]

table(datamystuff23$Type)
xyplot(Value ~ Year, datamystuff23, groups=Type)
xyplot(mavg ~ Year, datamystuff23, groups=Type)

# plot stuff2/3:
plot2_3 <- xyplot(Value ~ Year, datamystuff23, groups = Type,
                  allow.multiple = T,
                  distribute.type = TRUE,
                  par.settings = list(layout.heights = list(key.top = 1.5)),
                  col = "black", pch=c(2:3),
                  ylab="concentration",
                  subscripts = TRUE,
                  panel = panel.superpose,
                  panel.groups = function(x, y, subscripts,
...,group.number) {
                    panel.xyplot(x, y, ...)
                    panel.xyplot(x, datamystuff23[subscripts,"mavg"], col =
                                   "black", type = "l", lty=c(1:2))  ### Why
can I not define different lty?
                  })
plot2_3 # plot is incorrect!

plot1<- xyplot(Value ~ Year, datamystuff1, groups = Type,
               allow.multiple = T,
               distribute.type = TRUE,
               par.settings = list(layout.heights = list(key.top = 1.5)),
               col = "black", pch=c(2:3),
               subscripts = TRUE,
               ylab="temperature",
               panel = panel.superpose,
               panel.groups = function(x, y, subscripts, ...,group.number) {
                 panel.xyplot(x, y, ...)
                 panel.xyplot(x, mydata[subscripts,"mavg"], col =
                                c(1:3)[group.number], type = "l", lty=3)
               })
plot1 # this plot looks correct!


doubleYScale(plot2_3, plot1, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("nitrogen", "winter temperature", "summer
tempareture"), lty=c(1:3),columns = 2, 
             col=c("black", "black", "black"))
             
update(trellis.last.object(),
                    par.settings = simpleTheme(col = c("black", "black"),
lty=c(1:3), 
                                               pch=c(1:3)))




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 31 July 2014 06:17
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Anna

I am still unsure what you want

1 do you want 1 panel or 3?
2 do you want 1 y axis on the left and 1 on the right
or 1 y axis on the left and 2 on the right
                                         or 1 on the right varying with
groups in a multipanel plot

For starters try

xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c("black","black","black"), # for points
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

OR

  xyplot(Value ~ Year|Type, mydata,
        allow.multiple = T,
        aspect = 0.75,
        layout = c(1,3),
        groups = Type,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        scales = list(alternating = F),
        col = c("black","black","black"),
        subscripts = TRUE,
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

have a look at

 ?lattice::axis.default
for yscale.components

This means that you only need 1 xyplot object

if you use doubleYScale you need to xyplot objects
1 for the points and another for the averages

These are then superimposed with the doubleYScale

Also read and re read ?xyplot
names(trellis.par.get()) give you a list of the names in trellis.par.get()
and trellis.par.get() gives you all the settings used by  argument
par.settings in xyplot and those in the lattice series
par.settings may help you with themes.

http://lmdvr.r-forge.r-project.org/figures/figures.html
may be instructive

Duncan

-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se]
Sent: Wednesday, 30 July 2014 23:59
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan and many thank's for your help!
I could see your first message perfectly.

You solved my problem to some extent. What my problem is, is that I need a
double y plot with two of these moving averages belonging to one axis (both
are temperature measurements, say Stuff 2 and 3, measured in degrees C) the
other one reading off the second axis (a nutrient measurement in mM (say
Stuff1)).

How can I plot Stuff2 and stuff3 moving averages in one plot and stuff1 in
another and then combine them using doubleYscale?

I also have some other annotated questions regarding linetypes. I could
change symbols using pch, but not the line type. Why? See code below:

Many many thank's once again.

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}

mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

xyplot(Value ~ Year, mydata, groups = Type,
       allow.multiple = T,
       distribute.type = TRUE,
       col = c("black","black","black"),
       subscripts = TRUE,
       par.settings = simpleTheme(lty=c(1:3), pch=c(1:3)), #why can I change
symbol (pch), but not line type (lty)?
       panel = panel.superpose,
       panel.groups = function(x, y, subscripts, ...,group.number) {
         panel.xyplot(x, y, ...)
         panel.xyplot(x, mydata[subscripts,"mavg"], col =
                        c("black","black","black")[group.number], type =
"l") # tried to change lty here too lty=c(1:3), but # without success
       })

# how can I add a legend specifying the linetype AS WELL AS symbol?
# I tried using:   text = c("stuff1", "stuff2", "stuff3"), columns = 2  but
could not make it work.




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 29 July 2014 01:45
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

I do not know what happened to my last email as this are set up as plain
text so I am sending the code again so I hope this works

I am not sure what you wanted exactly but this will plot the points and
lines of the average.

I have not worried about the 2nd axis

Here is one way of doing things  by combining the averages into the
dataframe.
It makes it easier that way as you do not have to match up the x values

# combine averages into mydata
 mydata$mavg <-
 c(rep(NA,4), madfStuff1[,3],
   rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
   rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        col = c("red","blue","cyan"),
         subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
                  panel.xyplot(x, y, ...)
                   panel.xyplot(x, mydata[subscripts,"mavg"], col =
c("red","blue","cyan")[group.number], type = "l")
            })

Duncan

BTW libraries are case sensitive as well. Is it you editor putting capitals?

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Monday, 28 July 2014 16:38
To: r-help at r-project.org
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot

Hi lattice users,

I would like to add 5-year moving averages to my double y-plot. I have three
factors needs to be plotted with moving averages in the same plot. One of
these reads off y-axis 1 and two from y-axis 2. I have tried to use the
rollmean function from the zoo-packages, but I fail in insering this into
lattice (I am not an experienced lattice user). I want to keep the data
points in the plot.
Find below dummy data and the script as well as annotations further
describing my question.

thank you in advance!
Anna Zakrisson

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(Lattice)
library(LatticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff12_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}


myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",
                   lty=1, pch=1,
                   ylab = "sweets", strip.left = F,
                   strip=myStripStyle,
                   xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = 1,col = "black")
                    panel.lmline(x,y,col = "black", data=madfStuff1) # here
I presume that panel.lmline is wrong.
                    # I would like to have my 5 year moving average here,
not a straight line.
                  })
myplot1


myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",
                  lty=1, pch=1,
                  ylab = "hours", strip.left = F,
                  strip=myStripStyle,
                  xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = c(2:3),col = "black") ## what
is this "pch" defining? Types?
                    #I would like to have different symbols and line types
for stuff2 and stuff3
                    panel.lmline(x,y,col = "black", data=madfStuff2_3) #
wrong! Need my moving averages here!
                  })
myplot2

doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("stuff1", "stuff2", "stuff3"), columns = 2,
col="black")

# problem here is that I end up with two lines. I need a double y-plot with
one moving average plots that are read off y-axis 1
# and two that reads off y-axis 2. I need to keep the data points in the
plot.

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3),
pch=c(1:3))) # how come that I only get
# lines in my legend text and not the symbols too. I thought "pch" would add
symbols?!?


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`?. . ? `?. .? `?. . ><((((:>`?. . ? `?. .? `?. .><((((:>`?. . ? `?.
.? `?. .><((((:>

        [[alternative HTML version deleted]]


From rsnell at xplornet.com  Fri Aug  1 05:37:35 2014
From: rsnell at xplornet.com (rsnell at xplornet.com)
Date: Thu, 31 Jul 2014 23:37:35 -0400
Subject: [R] hist3D (output control)
Message-ID: <d05e50c01b16428385f1069e07698108@xplornet.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140731/f33790f7/attachment.pl>

From dstr7320 at uni.sydney.edu.au  Fri Aug  1 03:00:21 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Fri, 1 Aug 2014 01:00:21 +0000
Subject: [R] Rmixmod Memory Leak
Message-ID: <1406858590755.67013@uni.sydney.edu.au>

Hello,

I would like to provide a helpful bug report to the maintainer of Rmixmod, but I'm not skilled in memory profiling.

The following example illustrates the problem :

library(Rmixmod)
genes <- matrix(rnorm(5000*50, 9, 2), nrow = 5000, ncol = 50)
selected <- sample(5000, 25)
columns <- split(1:50, rep(1:10, each = 5))
lapply(1:100, function(index) # 100 resamples with replacement
{
  lapply(1:5, function(fold) # 5-fold cross validation
  {
    apply(genes[selected, columns[[fold]]], 1, function(aGene) mixmodCluster(aGene, nbCluster = 1:3))
    return(NULL)
  })
})

Even though no data was assigned to any variables, even if I do gc() after the loop, 5 GB of RAM is used. This makes the software unusable in a loop, because the server freezes when it runs out of RAM.

May someone who is an expert help me ?

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia


From dulcalma at bigpond.com  Fri Aug  1 06:38:07 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 1 Aug 2014 14:38:07 +1000
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>,
	<000601cfaabd$f568f130$e03ad390$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD39CFE@ebox-prod-srv04.win.su.se>,
	<001201cfac76$57905970$06b10c50$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD3A3B7@ebox-prod-srv04.win.su.se>
Message-ID: <000001cfad42$64992a80$2dcb7f80$@bigpond.com>

Hi Anna

I forgot you had problems with lty 
I have cleaned up the yright and put lty in

yright <-
 xyplot(mavg ~ Year, mydata, groups = Type,
        type = "l",
        ylab = "mean",
        lty = 1:3,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c(1:3) )

I did not change for what you wanted on the right as far as labels etc is
concerned

Duncan

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Friday, 1 August 2014 12:03
To: R; 'Anna Zakrisson Braeunlich'
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Anna

I have gone back to doubleYScale because I started following the wrong
section that I had before so it was quicker to do doubleYScale
You need to have 2 lattice objects and components are taken from each  below
so use the function str on the three objects to see

library(lattice)
library(latticeExtra)

yleft <-
 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        col = c(1:3) # for points
         )

 yright <-
 xyplot(mavg ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        type = "l",
        ylab = "mean",
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c(1:3) )

# colours both y axes so change with next command
yboth <-
doubleYScale(yleft, yright, add.ylab2 = TRUE)
yboth

# change y axes col to suit
update(trellis.last.object(),             # left   # right
       par.settings = simpleTheme(col = c("black", "cyan")))

Duncan


-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se] 
Sent: Friday, 1 August 2014 03:11
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan,

Now I have found a solution to my problem. It is complete except for one
tiny detail: I am unable to define different line types for stuff2 and
stuff3 moving averages (see plot2_3).

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# combine averages into mydata
mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

table(mydata$Type)

# split stuff1 from stuff2/3
datamystuff1 <- mydata[(mydata$Type) %in% c("stuff1"), ]
datamystuff23 <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]

table(datamystuff23$Type)
xyplot(Value ~ Year, datamystuff23, groups=Type)
xyplot(mavg ~ Year, datamystuff23, groups=Type)

# plot stuff2/3:
plot2_3 <- xyplot(Value ~ Year, datamystuff23, groups = Type,
                  allow.multiple = T,
                  distribute.type = TRUE,
                  par.settings = list(layout.heights = list(key.top = 1.5)),
                  col = "black", pch=c(2:3),
                  ylab="concentration",
                  subscripts = TRUE,
                  panel = panel.superpose,
                  panel.groups = function(x, y, subscripts,
...,group.number) {
                    panel.xyplot(x, y, ...)
                    panel.xyplot(x, datamystuff23[subscripts,"mavg"], col =
                                   "black", type = "l", lty=c(1:2))  ### Why
can I not define different lty?
                  })
plot2_3 # plot is incorrect!

plot1<- xyplot(Value ~ Year, datamystuff1, groups = Type,
               allow.multiple = T,
               distribute.type = TRUE,
               par.settings = list(layout.heights = list(key.top = 1.5)),
               col = "black", pch=c(2:3),
               subscripts = TRUE,
               ylab="temperature",
               panel = panel.superpose,
               panel.groups = function(x, y, subscripts, ...,group.number) {
                 panel.xyplot(x, y, ...)
                 panel.xyplot(x, mydata[subscripts,"mavg"], col =
                                c(1:3)[group.number], type = "l", lty=3)
               })
plot1 # this plot looks correct!


doubleYScale(plot2_3, plot1, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("nitrogen", "winter temperature", "summer
tempareture"), lty=c(1:3),columns = 2, 
             col=c("black", "black", "black"))
             
update(trellis.last.object(),
                    par.settings = simpleTheme(col = c("black", "black"),
lty=c(1:3), 
                                               pch=c(1:3)))




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 31 July 2014 06:17
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Anna

I am still unsure what you want

1 do you want 1 panel or 3?
2 do you want 1 y axis on the left and 1 on the right
or 1 y axis on the left and 2 on the right
                                         or 1 on the right varying with
groups in a multipanel plot

For starters try

xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c("black","black","black"), # for points
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

OR

  xyplot(Value ~ Year|Type, mydata,
        allow.multiple = T,
        aspect = 0.75,
        layout = c(1,3),
        groups = Type,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        scales = list(alternating = F),
        col = c("black","black","black"),
        subscripts = TRUE,
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

have a look at

 ?lattice::axis.default
for yscale.components

This means that you only need 1 xyplot object

if you use doubleYScale you need to xyplot objects
1 for the points and another for the averages

These are then superimposed with the doubleYScale

Also read and re read ?xyplot
names(trellis.par.get()) give you a list of the names in trellis.par.get()
and trellis.par.get() gives you all the settings used by  argument
par.settings in xyplot and those in the lattice series
par.settings may help you with themes.

http://lmdvr.r-forge.r-project.org/figures/figures.html
may be instructive

Duncan

-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se]
Sent: Wednesday, 30 July 2014 23:59
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan and many thank's for your help!
I could see your first message perfectly.

You solved my problem to some extent. What my problem is, is that I need a
double y plot with two of these moving averages belonging to one axis (both
are temperature measurements, say Stuff 2 and 3, measured in degrees C) the
other one reading off the second axis (a nutrient measurement in mM (say
Stuff1)).

How can I plot Stuff2 and stuff3 moving averages in one plot and stuff1 in
another and then combine them using doubleYscale?

I also have some other annotated questions regarding linetypes. I could
change symbols using pch, but not the line type. Why? See code below:

Many many thank's once again.

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}

mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

xyplot(Value ~ Year, mydata, groups = Type,
       allow.multiple = T,
       distribute.type = TRUE,
       col = c("black","black","black"),
       subscripts = TRUE,
       par.settings = simpleTheme(lty=c(1:3), pch=c(1:3)), #why can I change
symbol (pch), but not line type (lty)?
       panel = panel.superpose,
       panel.groups = function(x, y, subscripts, ...,group.number) {
         panel.xyplot(x, y, ...)
         panel.xyplot(x, mydata[subscripts,"mavg"], col =
                        c("black","black","black")[group.number], type =
"l") # tried to change lty here too lty=c(1:3), but # without success
       })

# how can I add a legend specifying the linetype AS WELL AS symbol?
# I tried using:   text = c("stuff1", "stuff2", "stuff3"), columns = 2  but
could not make it work.




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 29 July 2014 01:45
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

I do not know what happened to my last email as this are set up as plain
text so I am sending the code again so I hope this works

I am not sure what you wanted exactly but this will plot the points and
lines of the average.

I have not worried about the 2nd axis

Here is one way of doing things  by combining the averages into the
dataframe.
It makes it easier that way as you do not have to match up the x values

# combine averages into mydata
 mydata$mavg <-
 c(rep(NA,4), madfStuff1[,3],
   rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
   rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        col = c("red","blue","cyan"),
         subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
                  panel.xyplot(x, y, ...)
                   panel.xyplot(x, mydata[subscripts,"mavg"], col =
c("red","blue","cyan")[group.number], type = "l")
            })

Duncan

BTW libraries are case sensitive as well. Is it you editor putting capitals?

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Monday, 28 July 2014 16:38
To: r-help at r-project.org
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot

Hi lattice users,

I would like to add 5-year moving averages to my double y-plot. I have three
factors needs to be plotted with moving averages in the same plot. One of
these reads off y-axis 1 and two from y-axis 2. I have tried to use the
rollmean function from the zoo-packages, but I fail in insering this into
lattice (I am not an experienced lattice user). I want to keep the data
points in the plot.
Find below dummy data and the script as well as annotations further
describing my question.

thank you in advance!
Anna Zakrisson

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(Lattice)
library(LatticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff12_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}


myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",
                   lty=1, pch=1,
                   ylab = "sweets", strip.left = F,
                   strip=myStripStyle,
                   xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = 1,col = "black")
                    panel.lmline(x,y,col = "black", data=madfStuff1) # here
I presume that panel.lmline is wrong.
                    # I would like to have my 5 year moving average here,
not a straight line.
                  })
myplot1


myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",
                  lty=1, pch=1,
                  ylab = "hours", strip.left = F,
                  strip=myStripStyle,
                  xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = c(2:3),col = "black") ## what
is this "pch" defining? Types?
                    #I would like to have different symbols and line types
for stuff2 and stuff3
                    panel.lmline(x,y,col = "black", data=madfStuff2_3) #
wrong! Need my moving averages here!
                  })
myplot2

doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("stuff1", "stuff2", "stuff3"), columns = 2,
col="black")

# problem here is that I end up with two lines. I need a double y-plot with
one moving average plots that are read off y-axis 1
# and two that reads off y-axis 2. I need to keep the data points in the
plot.

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3),
pch=c(1:3))) # how come that I only get
# lines in my legend text and not the symbols too. I thought "pch" would add
symbols?!?


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`?. . ? `?. .? `?. . ><((((:>`?. . ? `?. .? `?. .><((((:>`?. . ? `?.
.? `?. .><((((:>

        [[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Fri Aug  1 07:28:38 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 31 Jul 2014 22:28:38 -0700
Subject: [R] how to extract word before /// in a data frame contain many
	thousands rows.
In-Reply-To: <872839643.6978740.1406857908425.JavaMail.zimbra@stanford.edu>
References: <872839643.6978740.1406857908425.JavaMail.zimbra@stanford.edu>
Message-ID: <1406870918.87808.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Try:
If dat is the dataset.


?? library(stringr)
??? res <- str_extract(dat$Gene.Symbol, perl('[[:alnum:]]+(?= \\/)'))
?res[!is.na(res)]
?#[1] "CDH23"

A.K.




On Thursday, July 31, 2014 9:54 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
Dear All,

I appreciate if you can help me out this. I have a data frame contains many thousand of rows, with some rows that has /// symbol,? as shown in in row 2, I want to extract word before ///, such as in this case, CDH23. Many thanks.
Probe.Set.ID? ? ? ? ? ? Gene.Symbol
1? 1552301_a_at? ? ? ? ? ? ? ? ? CORO6
2? 1552436_a_at CDH23 /// LOC100653137
3? 1552477_a_at? ? ? ? ? ? ? ? ?  IRF6
4? 1552685_a_at? ? ? ? ? ? ? ? ? GRHL1
5? ? 1552742_at? ? ? ? ? ? ? ? ? KCNH8
6? 1552752_a_at? ? ? ? ? ? ? ? ? CADM2
7? ? 1552799_at? ? ? ? ? ? ? ? TSNARE1
8? 1552897_a_at? ? ? ? ? ? ? ? ? KCNG3
9? 1552902_a_at? ? ? ? ? ? ? ? ? FOXP2
10?  1552903_at? ? ? ? ? ? ?  B4GALNT2


structure(list(Probe.Set.ID = c("1552301_a_at", "1552436_a_at", 
"1552477_a_at", "1552685_a_at", "1552742_at", "1552752_a_at", 
"1552799_at", "1552897_a_at", "1552902_a_at", "1552903_at"), 
? ? Gene.Symbol = c("CORO6", "CDH23 /// LOC100653137", "IRF6", 
? ? "GRHL1", "KCNH8", "CADM2", "TSNARE1", "KCNG3", "FOXP2", "B4GALNT2"
? ? )), .Names = c("Probe.Set.ID", "Gene.Symbol"), row.names = c(NA, 
10L), class = "data.frame")


Stephen HK Wong

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Fri Aug  1 08:55:39 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 31 Jul 2014 23:55:39 -0700
Subject: [R] Rmixmod Memory Leak
In-Reply-To: <1406858590755.67013@uni.sydney.edu.au>
References: <1406858590755.67013@uni.sydney.edu.au>
Message-ID: <f2332b74-98c9-4fcf-8cca-db1d8e609a7b@email.android.com>

Read

?maintainer

and

the Posting Guide mentioned below.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On July 31, 2014 6:00:21 PM PDT, Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:
>Hello,
>
>I would like to provide a helpful bug report to the maintainer of
>Rmixmod, but I'm not skilled in memory profiling.
>
>The following example illustrates the problem :
>
>library(Rmixmod)
>genes <- matrix(rnorm(5000*50, 9, 2), nrow = 5000, ncol = 50)
>selected <- sample(5000, 25)
>columns <- split(1:50, rep(1:10, each = 5))
>lapply(1:100, function(index) # 100 resamples with replacement
>{
>  lapply(1:5, function(fold) # 5-fold cross validation
>  {
>apply(genes[selected, columns[[fold]]], 1, function(aGene)
>mixmodCluster(aGene, nbCluster = 1:3))
>    return(NULL)
>  })
>})
>
>Even though no data was assigned to any variables, even if I do gc()
>after the loop, 5 GB of RAM is used. This makes the software unusable
>in a loop, because the server freezes when it runs out of RAM.
>
>May someone who is an expert help me ?
>
>--------------------------------------
>Dario Strbenac
>PhD Student
>University of Sydney
>Camperdown NSW 2050
>Australia
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Fri Aug  1 09:19:45 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 01 Aug 2014 17:19:45 +1000
Subject: [R] Rmixmod Memory Leak
In-Reply-To: <1406858590755.67013@uni.sydney.edu.au>
References: <1406858590755.67013@uni.sydney.edu.au>
Message-ID: <6367288.fGXbeLhF0X@localhost.localdomain>

Hi Dario,
The maintainer of that package is:

Benjamin Auder

and I have copied him on this message. Usually it is best to include 
the maintainer in this sort of situation.

Jim

On Fri, 1 Aug 2014 01:00:21 AM Dario Strbenac wrote:
> Hello,
> 
> I would like to provide a helpful bug report to the maintainer of 
Rmixmod,
> but I'm not skilled in memory profiling.
> 
> The following example illustrates the problem :
> 
> library(Rmixmod)
> genes <- matrix(rnorm(5000*50, 9, 2), nrow = 5000, ncol = 50)
> selected <- sample(5000, 25)
> columns <- split(1:50, rep(1:10, each = 5))
> lapply(1:100, function(index) # 100 resamples with replacement
> {
>   lapply(1:5, function(fold) # 5-fold cross validation
>   {
>     apply(genes[selected, columns[[fold]]], 1, function(aGene)
> mixmodCluster(aGene, nbCluster = 1:3)) return(NULL)
>   })
> })
> 
> Even though no data was assigned to any variables, even if I do gc() 
after
> the loop, 5 GB of RAM is used. This makes the software unusable in 
a loop,
> because the server freezes when it runs out of RAM.
> 
> May someone who is an expert help me ?
> 
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible 
code.


From btornimbene at yahoo.co.uk  Fri Aug  1 08:25:05 2014
From: btornimbene at yahoo.co.uk (barbara tornimbene)
Date: Fri, 1 Aug 2014 07:25:05 +0100
Subject: [R] Merging outbreak data
Message-ID: <1406874305.95262.YahooMailNeo@web133002.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/a715b07e/attachment.pl>

From petr.pikal at precheza.cz  Fri Aug  1 11:27:32 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 1 Aug 2014 09:27:32 +0000
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <1406817448605-4694850.post@n4.nabble.com>
References: <1406817448605-4694850.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD96A@SRVEXCHMBX.precheza.cz>

Hi

Maybe others will disagree but I find for cycle for this type of task better than sapply.

for(i in 1:length(ind)) {

if (there are more than 3 date items*) {

postscript(ind[i])
do all plotting
dev.off()
}}

If you want to plot with gaps you need to add all relevant YEARs for x axis with missing value in y before plotting. Then R plots it automatically with gap.

x<-1:10
y<-rnorm(10)
y[5:6]<-NA
plot(x,y, type="b")

I would suggest to use merge for this task.

table(dat$ID)
gives you number of unique values for each ID and you can use it for discarding this ID from the list.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of fd
> Sent: Thursday, July 31, 2014 4:37 PM
> To: r-help at r-project.org
> Subject: [R] Multiple plots and postscripts using split function
>
> Hi,
>
> I'm relatively new to R and I would like to do the following:
>
> I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and would
> like to do several xy plots with the year on the x-axis and the data
> values
> (measurements) on the y-axis and after that export the different plots
> to postcript.
>
> My .csv file looks something like this (only an example):
>
> NAME                          ID              YEAR    VALUE
> ADAMS                         885             1988            -2
> ADAMS                         885             1989            0
> BAHIA DEL DIABLO              2665            1999            4
> BAHIA DEL DIABLO              2665            2000            8
> BAHIA DEL DIABLO              2665            2001            19
> BAHIA DEL DIABLO              2665            2002            13
> BAHIA DEL DIABLO              2665            2003            13
> BARTLEY                               893             1983            0
> BARTLEY                               893             1984            -1
> BARTLEY                               893             1985            0
> BARTLEY                               893             1988            2
> BARTLEY                               893             1989            -1
> CANADA                                877             1972            -1
>
> I have split the different items into groups and I'd like the plots to
> have the title of NAME but the filename of the postscript to be
> exported should have the ID as filename.
>
> My code so far:
>
> #Set Working Directory:
> setwd("/Users/Desktop/FV")
> # Read CSV
> dat <- read.csv("FV.csv", sep=";", header=TRUE) # Split Data ind <-
> split(x = dat,f = dat[,'ID']) nam <- names(ind)
>
> sapply(nam, function(x) {
>       postscript(x)
>       par(mar=c(6,8,6,5), cex=0.8)
>       plot(ind[[x]][,c('YEAR','VALUE')],
>       type='b',
>       main = x,
>       xlab="Time [Years]",
>       ylab="Front variation")
>       axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-
> 0.3)
>       axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
> tcl=-0.3)
>
>       dev.off()
> })
>
> This results in plots with the title and filename of the resulting
> postscript being the same. Is there a way to get the plot title out of
> the NAME column and the filename out of the ID?
>
> Additionally I'd only like to plot graphs for items with more than 3
> data values. Is this possible to incorporate in the split command?
>
> Another point is that some items have gaps in the time series where no
> measurements were taken (in my example: BARTLEY from 1983 to 1985 and
> 1988 to 1989). I would like to plot using type= 'b' so that the points
> are connected with lines, but when doing that, the values between 1985
> and 1988 are automatically connected which I don't want. I'd like the
> plot to start again at the value where the gap ends (in my example from
> 1988 onwards). Is there a solution for this?
>
> Any help is kindly appreciated! Thanks for your help.
>
> Kind regards,
> fd
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Multiple-
> plots-and-postscripts-using-split-function-tp4694850.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ligges at statistik.tu-dortmund.de  Fri Aug  1 11:34:27 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 01 Aug 2014 11:34:27 +0200
Subject: [R] how to extract word before /// in a data frame contain many
 thousands rows.
In-Reply-To: <1406870918.87808.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <872839643.6978740.1406857908425.JavaMail.zimbra@stanford.edu>
	<1406870918.87808.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <53DB5F23.5030103@statistik.tu-dortmund.de>



On 01.08.2014 07:28, arun wrote:
> Try:
> If dat is the dataset.
>
>
>     library(stringr)
>      res <- str_extract(dat$Gene.Symbol, perl('[[:alnum:]]+(?= \\/)'))
>   res[!is.na(res)]
>   #[1] "CDH23"


Or without additional packages and if you want to keep all information 
from the other rows of your data.frame:

gsub(" *///.*$", "", dat$Gene.Symbol)

Best,
Uwe Ligges


> A.K.
>
>
>
>
> On Thursday, July 31, 2014 9:54 PM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Dear All,
>
> I appreciate if you can help me out this. I have a data frame contains many thousand of rows, with some rows that has /// symbol,  as shown in in row 2, I want to extract word before ///, such as in this case, CDH23. Many thanks.
> Probe.Set.ID            Gene.Symbol
> 1  1552301_a_at                  CORO6
> 2  1552436_a_at CDH23 /// LOC100653137
> 3  1552477_a_at                   IRF6
> 4  1552685_a_at                  GRHL1
> 5    1552742_at                  KCNH8
> 6  1552752_a_at                  CADM2
> 7    1552799_at                TSNARE1
> 8  1552897_a_at                  KCNG3
> 9  1552902_a_at                  FOXP2
> 10   1552903_at               B4GALNT2
>
>
> structure(list(Probe.Set.ID = c("1552301_a_at", "1552436_a_at",
> "1552477_a_at", "1552685_a_at", "1552742_at", "1552752_a_at",
> "1552799_at", "1552897_a_at", "1552902_a_at", "1552903_at"),
>      Gene.Symbol = c("CORO6", "CDH23 /// LOC100653137", "IRF6",
>      "GRHL1", "KCNH8", "CADM2", "TSNARE1", "KCNG3", "FOXP2", "B4GALNT2"
>      )), .Names = c("Probe.Set.ID", "Gene.Symbol"), row.names = c(NA,
> 10L), class = "data.frame")
>
>
> Stephen HK Wong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jim at bitwrit.com.au  Fri Aug  1 11:56:33 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 01 Aug 2014 19:56:33 +1000
Subject: [R] Merging outbreak data
In-Reply-To: <1406874305.95262.YahooMailNeo@web133002.mail.ir2.yahoo.com>
References: <1406874305.95262.YahooMailNeo@web133002.mail.ir2.yahoo.com>
Message-ID: <4659893.YoUY3gnLDS@localhost.localdomain>

On Fri, 1 Aug 2014 07:25:05 AM barbara tornimbene wrote:
> HI.
> I have a set of disease outbreak data. Each observation have a
> location (spatial coordinates) and a start date. Outbreaks that occur 
in
> the same location within a two week periods have to be merged. 
Basically I
> need to delete duplicates that have same spatial coordinated and 
start
> dates comprised in a two weeks range. I am ok with the first bit
> (coordinates), but It is the date range that I am not sure how to 
define. I
> thought about creating a dummy variable for observations within a 
date
> range, but those might have different locations. Any help would be 
greatly
> appreciated. Thanks

Hi barbara,
I assume that the spatial coordinates have to be within a certain 
distance to be considered the same, unless they are based on 
something like cities or health administration districts. If your 
observations can be ordered by date, the problem is not too difficult.

date_range<-as.Date(c("1/1/2014","1/8/2014"),"%d/%m/%Y")
disease.df<-data.frame(
 onset=sample(seq(date_range[1],date_range[2],by=1),100),
 lat=sample(seq(-33,-35,by=-1),100,TRUE),
 lon=sample(seq(148,151,by=1),100,TRUE))
disease.df<-disease.df[order(disease.df$onset),]
disease.df$drop<-0
nobs<-dim(disease.df)[1]
for(start in 1:(nobs-1)) {
 cat(start,"\n")
 end<-start+1
 while(disease.df$onset[end] < disease.df$onset[start]+14 &&
  end < nobs) end<-end+1
 if(disease.df$onset[end] - disease.df$onset[start] > 14)
  end<-end-1
 sameplace<-
  disease.df$lat[start] == disease.df$lat[(start+1):end] &
  disease.df$lon[start] == disease.df$lon[(start+1):end]
 if(any(sameplace)) {
  disease.df$drop[start]<-1
  disease.df$drop[(start+1):end]<-
   disease.df$drop[(start+1):end]+sameplace
 }
}

Caution - I haven't checked this exhaustively and I have assumed that 
locations must be equal, not within some distance.

Jim


From lawrence.michael at gene.com  Fri Aug  1 12:05:17 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 1 Aug 2014 03:05:17 -0700
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
Message-ID: <CAOQ5NydR9dPzKg9QYX5GYs2pue1DVpCxSuwr1+C3hZ-eHaEYrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/12a90f2e/attachment.pl>

From qxsr at yahoo.com  Fri Aug  1 14:09:18 2014
From: qxsr at yahoo.com (Sam Wong)
Date: Fri, 1 Aug 2014 05:09:18 -0700
Subject: [R] Weighted Logistic Regression in R: Can R do what SAS PROC
	LOGISTIC does?
Message-ID: <1406894958.40282.YahooMailNeo@web120802.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/01ad900d/attachment.pl>

From lingyi.ma at gmail.com  Fri Aug  1 13:41:31 2014
From: lingyi.ma at gmail.com (Lingyi Ma)
Date: Fri, 1 Aug 2014 14:41:31 +0300
Subject: [R] How to avoid the three loops in R?
Message-ID: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/a7bc9f1f/attachment.pl>

From roy.sasson at gmail.com  Fri Aug  1 13:48:25 2014
From: roy.sasson at gmail.com (Roy Sasson)
Date: Fri, 1 Aug 2014 14:48:25 +0300
Subject: [R] installing package 'rqpd' (Regression quantiles for panel data)
	on windows
Message-ID: <CABoSW94+XuJr+JS3N0i3KJvqZDFuVEvXZMnq7nb0v75hdw+Tdg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/d565fef1/attachment.pl>

From pross at xvid.org  Fri Aug  1 14:12:22 2014
From: pross at xvid.org (Peter Ross)
Date: Fri, 1 Aug 2014 22:12:22 +1000
Subject: [R] R sensitivity/fast99 n=65
Message-ID: <20140801121222.GA31609@7fd92687fe0a3d49c8d08da5e44763fb>

Hi,

I have been using the R/fast99 library to work through the Extended FAST paper by Saltelli et al 1999 [1].
In trying to repeat some examples with R, I have encountered the following 'bug' in the implementation.

Synopsis: tell.fast99 gives NA first order sensitivity indices when 'M * omega[1] > (n / 2) - 1'.
This just so happens for n=65,M=4,omega[1]=8, which is described in the paper.


Offending tell.fast99 lines
===========================

  for (i in 1 : p) {
    l <- seq((i - 1) * n + 1, i * n)
    f <- fft(x$y[l], inverse = FALSE)
    Sp <- ( Mod(f[2 : (n / 2)]) / n )^2

                  ^^^^^^^^^^^^^| SP length is (n / 2) - 1

    V[i] <- 2 * sum(Sp)
    D1[i] <- 2 * sum(Sp[(1 : x$M) * x$omega[1]])

                        ^^^^^^^^^^^^^^^^^^^^^^^| now try and read SP[M * omega[1]]

    Dt[i] <- 2 * sum(Sp[1 : (x$omega[1] / 2)])
  }



Worked example (copied from fast99 manpage, with n=65)
=======================================================

> x=fast99(model=ishigami.fun, n=65, factors=3,q="qunif", q.arg=list(min=-pi,max=pi))
> x$M
[1] 4
> x$omega
[1] 8 1 1
> x

Call:
fast99(model = ishigami.fun, factors = 3, n = 65, q = "qunif", q.arg = list(min = -pi, max = pi))

Model runs: 195 

Estimations of the indices:
   first order total order
X1          NA 0.026476165
X2          NA 0.971861619
X3          NA 0.001241782



SimLab (the program that Saltelli uses in his books) gives consistent results for n=65.
Why is the fft result truncated to '2 : (n / 2)'?
If there is a good reason, can it go in the manpage!


[1] A. Saltelli, S. Tarantola and K. Chan, 1999, A quantitative, model independent method
    for global sensitivity analysis of model output, Technometrics, 41, 39-56.

-- Peter
(A907 E02F A6E5 0CD2 34CD 20D2 6760 79C5 AC40 DD6B)
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 181 bytes
Desc: Digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/18ace718/attachment.bin>

From petr.pikal at precheza.cz  Fri Aug  1 15:17:40 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 1 Aug 2014 13:17:40 +0000
Subject: [R] How to avoid the three loops in R?
In-Reply-To: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>
References: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDDB5D@SRVEXCHMBX.precheza.cz>

Hi

I do not see any solution without loops but maybe others find it.

I think that you can do it in one loop. Best structure for loop will be list.

In each cycle you will compute matrix with diagonal NA

mat<-matrix(1,nrow=number of items, ncol=number of items)
diag(mat) <- NA

apply(price chunk * mat, 2, mean, na.rm=T)


So when I named your example as temp I get

fac <- interaction(factor(temp$Product), factor(temp$Year_Month), drop=T)
lll <- split(temp, fac)
for( i in 1:length(lll)) {
 mat <- matrix(1,  nrow=nrow(lll[[i]]), ncol= nrow(lll[[i]]))
 diag(mat) <- NA
 lll[[i]]$others <- apply(mat*lll[[i]][,3], 2, mean, na.rm=T)
 }

> lll
$`1.201204`
  Country Product Price Year_Month others
1      AE       1    20     201204     24
2      DE       1    20     201204     24
3      CN       1    28     201204     20

$`2.201204`
  Country Product Price Year_Month others
4      AE       2    28     201204     25
5      DE       2    28     201204     25
6      CN       2    22     201204     28

$`3.201204`
  Country Product Price Year_Month others
7      AE       3    28     201204     28
8      CN       3    28     201204     28

$`1.201205`
   Country Product Price Year_Month others
9       AE       1    20     201205     24
10      DE       1    20     201205     24
11      CN       1    28     201205     20

$`2.201205`
   Country Product Price Year_Month others
12      AE       2    28     201205     28
13      DE       2    28     201205     28

I did not check speed but it shall be OK.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Lingyi Ma
> Sent: Friday, August 01, 2014 1:42 PM
> To: r-help at r-project.org
> Subject: [R] How to avoid the three loops in R?
>
> I have the following data set:
>
>   Country  Product   Price  Year_Month
>      AE         1           20    201204
>      DE         1           20    201204
>      CN         1           28    201204
>      AE         2           28    201204
>      DE         2           28    201204
>      CN         2           22    201204
>      AE         3           28    201204
>      CN         3           28    201204
>      AE         1           20    201205
>      DE         1           20    201205
>      CN         1           28    201205
>      AE         2           28    201205
>      DE         2           28    201205
>
> I want to create the one more column which is "The average price of the
> product in other areas".
> in other word, for each month, for each product, I calculate the
> average of such product in the other area.
>
> I want sth like:
>
>   Country  Product   Price  Year_Month    Price_average_In_Other_area
>      AE         1           20    201204              14
>      AE         2           28    201204              25
>
> Please avoid the three for loop, I have tried and it never end. I have
>  1070427 rows.  Is there better way to speed up my program?
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Fri Aug  1 15:31:16 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 01 Aug 2014 09:31:16 -0400
Subject: [R] installing package 'rqpd' (Regression quantiles for panel
 data) on windows
In-Reply-To: <CABoSW94+XuJr+JS3N0i3KJvqZDFuVEvXZMnq7nb0v75hdw+Tdg@mail.gmail.com>
References: <CABoSW94+XuJr+JS3N0i3KJvqZDFuVEvXZMnq7nb0v75hdw+Tdg@mail.gmail.com>
Message-ID: <53DB96A4.6060008@gmail.com>

On 01/08/2014 7:48 AM, Roy Sasson wrote:
> hello R community,
> i am trying to install rqpd package on windows, using the following command:
>
> install.packages("rqpd",repos="http://R-Forge.R-project.org")
>
> however, i get the following message:
>
> Warning: unable to access index for repository
> http://R-Forge.R-project.org/bin/windows/contrib/2.15
> Warning message:
> package ?rqpd? is not available (for R version 2.15.1)
>
> i have tried using different versions of R (newer and older), but with no
> luck.
>
> I have also checked out the following thread -
> http://r.789695.n4.nabble.com/installing-package-rqpd-Regression-quantiles-for-panel-data-td4668594.html
>
> but it is not so clear how this problem was resolved eventually.
>
> would appreciate any assistance

You don't say what platform you're working on. On Windows, there is no 
binary for rqpd, but you can get the source. This appears to be an 
R-forge bug, because it will build from source without error. You should 
report this to R-forge. In the meantime, use type="source" when you do 
the install. You shouldn't need any special tools to do this, since it's 
a pure R package, no compiled code.

Duncan Murdoch


From Thierry.ONKELINX at inbo.be  Fri Aug  1 15:40:19 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 1 Aug 2014 13:40:19 +0000
Subject: [R] How to avoid the three loops in R?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDDB5D@SRVEXCHMBX.precheza.cz>
References: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDDB5D@SRVEXCHMBX.precheza.cz>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3AC769F@inbomail.inbo.be>

It is possible to do without loops if you start by calculating the totals. Then is just aggregating and merging data.

Best regards,

Thierry


set.seed(21)
n.country <- 5
average.price <- runif(n.country, max = 200)
price <- expand.grid(
  Product = 1:10,
  Country = factor(LETTERS[seq_len(n.country)]),
  Year = 2000:2010
)
price$Price <- rnorm(nrow(price), mean = average.price[price$Country], sd = 30)
#number and sum of all prices of the product over all countries and years
total.product <- aggregate(
  cbind(Price, N = 1) ~ Product,
  data = price,
  FUN = sum
)
#number and sum of all prices of the product per country over all years
total.product.country <- aggregate(
  cbind(Pricec = Price, Nc = 1) ~ Product + Country,
  data = price,
  FUN = sum
)
#merge both tables
combined.price <- merge(total.product, total.product.country)
with(combined.price, Price / N) #average price
with(combined.price, Pricec / Nc) #average price per country
with(combined.price, (Price - Pricec)/ (N - Nc)) #average price in the other countries



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens PIKAL Petr
Verzonden: vrijdag 1 augustus 2014 15:18
Aan: Lingyi Ma
CC: r-help at r-project.org
Onderwerp: Re: [R] How to avoid the three loops in R?

Hi

I do not see any solution without loops but maybe others find it.

I think that you can do it in one loop. Best structure for loop will be list.

In each cycle you will compute matrix with diagonal NA

mat<-matrix(1,nrow=number of items, ncol=number of items)
diag(mat) <- NA

apply(price chunk * mat, 2, mean, na.rm=T)


So when I named your example as temp I get

fac <- interaction(factor(temp$Product), factor(temp$Year_Month), drop=T) lll <- split(temp, fac) for( i in 1:length(lll)) {  mat <- matrix(1,  nrow=nrow(lll[[i]]), ncol= nrow(lll[[i]]))
 diag(mat) <- NA
 lll[[i]]$others <- apply(mat*lll[[i]][,3], 2, mean, na.rm=T)  }

> lll
$`1.201204`
  Country Product Price Year_Month others
1      AE       1    20     201204     24
2      DE       1    20     201204     24
3      CN       1    28     201204     20

$`2.201204`
  Country Product Price Year_Month others
4      AE       2    28     201204     25
5      DE       2    28     201204     25
6      CN       2    22     201204     28

$`3.201204`
  Country Product Price Year_Month others
7      AE       3    28     201204     28
8      CN       3    28     201204     28

$`1.201205`
   Country Product Price Year_Month others
9       AE       1    20     201205     24
10      DE       1    20     201205     24
11      CN       1    28     201205     20

$`2.201205`
   Country Product Price Year_Month others
12      AE       2    28     201205     28
13      DE       2    28     201205     28

I did not check speed but it shall be OK.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Lingyi Ma
> Sent: Friday, August 01, 2014 1:42 PM
> To: r-help at r-project.org
> Subject: [R] How to avoid the three loops in R?
>
> I have the following data set:
>
>   Country  Product   Price  Year_Month
>      AE         1           20    201204
>      DE         1           20    201204
>      CN         1           28    201204
>      AE         2           28    201204
>      DE         2           28    201204
>      CN         2           22    201204
>      AE         3           28    201204
>      CN         3           28    201204
>      AE         1           20    201205
>      DE         1           20    201205
>      CN         1           28    201205
>      AE         2           28    201205
>      DE         2           28    201205
>
> I want to create the one more column which is "The average price of
> the product in other areas".
> in other word, for each month, for each product, I calculate the
> average of such product in the other area.
>
> I want sth like:
>
>   Country  Product   Price  Year_Month    Price_average_In_Other_area
>      AE         1           20    201204              14
>      AE         2           28    201204              25
>
> Please avoid the three for loop, I have tried and it never end. I have
>  1070427 rows.  Is there better way to speed up my program?
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html and provide commented, minimal, self-contained,
> reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From ripley at stats.ox.ac.uk  Fri Aug  1 15:50:06 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 01 Aug 2014 14:50:06 +0100
Subject: [R] installing package 'rqpd' (Regression quantiles for panel
 data) on windows
In-Reply-To: <53DB96A4.6060008@gmail.com>
References: <CABoSW94+XuJr+JS3N0i3KJvqZDFuVEvXZMnq7nb0v75hdw+Tdg@mail.gmail.com>
	<53DB96A4.6060008@gmail.com>
Message-ID: <53DB9B0E.4080201@stats.ox.ac.uk>

On 01/08/2014 14:31, Duncan Murdoch wrote:
> On 01/08/2014 7:48 AM, Roy Sasson wrote:
>> hello R community,
>> i am trying to install rqpd package on windows, using the following
>> command:
>>
>> install.packages("rqpd",repos="http://R-Forge.R-project.org")
>>
>> however, i get the following message:
>>
>> Warning: unable to access index for repository
>> http://R-Forge.R-project.org/bin/windows/contrib/2.15
>> Warning message:
>> package ?rqpd? is not available (for R version 2.15.1)
>>
>> i have tried using different versions of R (newer and older), but with no
>> luck.
>>
>> I have also checked out the following thread -
>> http://r.789695.n4.nabble.com/installing-package-rqpd-Regression-quantiles-for-panel-data-td4668594.html
>>
>>
>> but it is not so clear how this problem was resolved eventually.
>>
>> would appreciate any assistance
>
> You don't say what platform you're working on. On Windows, there is no

Actually he did, but he did not give the 'an a minimum' information 
asked for in the posting guide.

> binary for rqpd, but you can get the source. This appears to be an
> R-forge bug, because it will build from source without error. You should
> report this to R-forge. In the meantime, use type="source" when you do
> the install. You shouldn't need any special tools to do this, since it's
> a pure R package, no compiled code.

Not an R-Forge bug as his R is too old: R-Forge only builds binary 
packages for current R.  As the posting guide asked, update R before 
posting ....

See also (as per the posting guide):

http://cran.r-project.org/bin/windows/base/rw-FAQ.html#How-can-I-get-a-binary-version-of-a-package_003f
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#No-binary-packages-appear-to-be-available-for-my-version-of-R


>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From deter088 at umn.edu  Fri Aug  1 15:51:00 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 1 Aug 2014 08:51:00 -0500
Subject: [R] simulation dichotomous data
In-Reply-To: <CABLo8nGF7UxuOTSCyOFnfWfcoD7z9jE3_iaiHE=4EW0BXrVp6w@mail.gmail.com>
References: <CABLo8nGjg6kY34-Ym6QAR=D-nbUxz9EdMCe1vTFvPye2CaAzpQ@mail.gmail.com>
	<CAOLJphn4gxmW7_30tUK7BpM_fKQ15eLE7-SuZyOn_QZUURMGiQ@mail.gmail.com>
	<CABLo8nGF7UxuOTSCyOFnfWfcoD7z9jE3_iaiHE=4EW0BXrVp6w@mail.gmail.com>
Message-ID: <CAOLJph=j9wyp6KWnoMKzejWmZ6EicWVFAyvU9b=Cr0ihmvvndQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/27264ae6/attachment.pl>

From john.archie.mckown at gmail.com  Fri Aug  1 16:06:50 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 1 Aug 2014 09:06:50 -0500
Subject: [R] How to avoid the three loops in R?
In-Reply-To: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>
References: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>
Message-ID: <CAAJSdjifSsmJJ2=e1GzZ-5Li+jr2rt=EE4Q7DWn59fHMrHG6Eg@mail.gmail.com>

On Fri, Aug 1, 2014 at 6:41 AM, Lingyi Ma <lingyi.ma at gmail.com> wrote:
> I have the following data set:
>
>   Country  Product   Price  Year_Month
>      AE         1           20    201204
>      DE         1           20    201204
>      CN         1           28    201204
>      AE         2           28    201204
>      DE         2           28    201204
>      CN         2           22    201204
>      AE         3           28    201204
>      CN         3           28    201204
>      AE         1           20    201205
>      DE         1           20    201205
>      CN         1           28    201205
>      AE         2           28    201205
>      DE         2           28    201205
>
> I want to create the one more column which is "The average price of the
> product in other areas".
> in other word, for each month, for each product, I calculate the average of
> such product in the other area.
>
> I want sth like:
>
>   Country  Product   Price  Year_Month    Price_average_In_Other_area
>      AE         1           20    201204              14
>      AE         2           28    201204              25

The output above looks wrong. The Price_average_In_Other_area for AE,
product 1 should be 24?

My possible solution:

# Initialize data.frame & call it "x".
Country <- c("AE","DE","CN","AE","DE","CN","AE","CN","AE","DE","CN","AE","DE");
Product <- c(1,1,1,2,2,2,3,3,1,1,1,2,2);
Price <- c(20,20,28,28,28,22,28,28,20,20,28,28,28);
Year_Month <- c(201204,201204,201204,201204,201204,201204,201204,201204,201205,201205,201205,201205,201205);
x <- data.frame(Country,Product,Price,Year_Month,stringsAsFactors=FALSE);
#
#
library("dplyr");
#
# Get the total Price of all Products and number of Products for each
Product & Year_Month"
y <- summarize(group_by(x, Product,
Year_Month),sumPrice=sum(Price),NoPrice=length(Price));
#
# Merge the above data back into the original data.frame, based on
# Product and Year_Month (similar to SQL inner join).
x <- merge(x=x,y=y);
#
# Now calculate the "other area" average by subtracting the cost in this area
# from the total cost in all areas and divide by the number of areas, minus one.
# Please note that if a Product and Year_Month is unique, i.e. no other areas
# for this Product & Year_Month, this will try to divide by zero.
# This gives "Inf" as an answer.
x$Prive_average_In_Other_area <- (x$sumPrice-x$Price)/(x$NoPrice-1);
# Possible alternate to handle above consideration
x$Avg_other <- ifelse(x$NoPrice>1,(x$sumPrice-x$Price)/(x$NoPrice-1),NA);



>
> Please avoid the three for loop, I have tried and it never end. I have
>  1070427 rows.  Is there better way to speed up my program?

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From smartpink111 at yahoo.com  Fri Aug  1 16:38:01 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Aug 2014 07:38:01 -0700
Subject: [R] How to transform the data frame into the list?
Message-ID: <1406903881.69434.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Use ?split()
split(dat[,-4], dat$Year_Month) #dat is the dataset.

A.K.


?? Country? Product?? Price? Year_Month
???? AE???????? 1?????????? 20??? 201204
???? DE???????? 1?????????? 20??? 201204
???? CN???????? 1?????????? 28??? 201204
???? AE???????? 2?????????? 28??? 201204
???? DE???????? 2?????????? 28??? 201204
???? CN???????? 2?????????? 22??? 201204
???? AE???????? 3?????????? 28??? 201204
???? CN???????? 3?????????? 28??? 201204
???? AE???????? 1?????????? 20??? 201205
???? DE???????? 1?????????? 20??? 201205
???? CN???????? 1?????????? 28??? 201205
???? AE???????? 2?????????? 28??? 201205
???? DE???????? 2?????????? 28??? 201205

How to create the list? which has:
[[201204]]
? Country? Product?? Price? 
???? AE???????? 1?????????? 20??? 
???? DE???????? 1?????????? 20? 
???? CN???????? 1?????????? 28??? 
???? AE???????? 2?????????? 28??? 
???? DE???????? 2?????????? 28??? 
???? CN???????? 2?????????? 22??? 
???? AE???????? 3?????????? 28? 
???? CN???????? 3?????????? 28??? 

[[201205]]
? Country? Product?? Price? 
???? AE???????? 1?????????? 20? 
???? DE???????? 1?????????? 20? 
???? CN???????? 1?????????? 28??? 
???? AE???????? 2?????????? 28??? 
???? DE???????? 2?????????? 28?


From HDoran at air.org  Fri Aug  1 16:46:06 2014
From: HDoran at air.org (Doran, Harold)
Date: Fri, 1 Aug 2014 14:46:06 +0000
Subject: [R] Better use with gsub
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/59e91417/attachment.pl>

From dcarlson at tamu.edu  Fri Aug  1 16:47:27 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 1 Aug 2014 14:47:27 +0000
Subject: [R] How to avoid the three loops in R?
In-Reply-To: <CAAJSdjifSsmJJ2=e1GzZ-5Li+jr2rt=EE4Q7DWn59fHMrHG6Eg@mail.gmail.com>
References: <CACB+=LigevswvBUUzxo09sUgZDDtPwu6YHTKzJYig2vRm_Fg2A@mail.gmail.com>
	<CAAJSdjifSsmJJ2=e1GzZ-5Li+jr2rt=EE4Q7DWn59fHMrHG6Eg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8DC40@mb02.ads.tamu.edu>

Here's another approach:

# First put the data in a format that is easier to transmit using dput():
dta <- structure(list(Country = structure(c(1L, 3L, 2L, 1L, 3L, 2L, 
1L, 2L, 1L, 3L, 2L, 1L, 3L), .Label = c("AE", "CN", "DE"), class = "factor"), 
    Product = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 1L, 1L, 1L, 2L, 
    2L), Price = c(20L, 20L, 28L, 28L, 28L, 22L, 28L, 28L, 20L, 
    20L, 28L, 28L, 28L), Year_Month = c(201204L, 201204L, 201204L, 
    201204L, 201204L, 201204L, 201204L, 201204L, 201205L, 201205L, 
    201205L, 201205L, 201205L)), .Names = c("Country", "Product", 
"Price", "Year_Month"), class = "data.frame", row.names = c(NA, 
-13L))
 # Then
> grp <- aggregate(Price~Product+Year_Month, dta, function(x) c(sum(x),
+      length(x)))
> dtmrg <- merge(dta, grp, by=c("Product", "Year_Month"))
> newdta <- with(dtmrg, data.frame(Country, Product, Price=Price.x,
+      Year_Month, Price_average_in_other_area=(Price.y[,1]-Price.x)/
+      (Price.y[,2]-1)))
> newdta
   Country Product Price Year_Month Price_average_in_other_area
1       AE       1    20     201204                          24
2       DE       1    20     201204                          24
3       CN       1    28     201204                          20
4       AE       1    20     201205                          24
5       DE       1    20     201205                          24
6       CN       1    28     201205                          20
7       AE       2    28     201204                          25
8       DE       2    28     201204                          25
9       CN       2    22     201204                          28
10      AE       2    28     201205                          28
11      DE       2    28     201205                          28
12      AE       3    28     201204                          28
13      CN       3    28     201204                          28

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of John McKown
Sent: Friday, August 1, 2014 9:07 AM
To: Lingyi Ma
Cc: r-help
Subject: Re: [R] How to avoid the three loops in R?

On Fri, Aug 1, 2014 at 6:41 AM, Lingyi Ma <lingyi.ma at gmail.com> wrote:
> I have the following data set:
>
>   Country  Product   Price  Year_Month
>      AE         1           20    201204
>      DE         1           20    201204
>      CN         1           28    201204
>      AE         2           28    201204
>      DE         2           28    201204
>      CN         2           22    201204
>      AE         3           28    201204
>      CN         3           28    201204
>      AE         1           20    201205
>      DE         1           20    201205
>      CN         1           28    201205
>      AE         2           28    201205
>      DE         2           28    201205
>
> I want to create the one more column which is "The average price of the
> product in other areas".
> in other word, for each month, for each product, I calculate the average of
> such product in the other area.
>
> I want sth like:
>
>   Country  Product   Price  Year_Month    Price_average_In_Other_area
>      AE         1           20    201204              14
>      AE         2           28    201204              25

The output above looks wrong. The Price_average_In_Other_area for AE,
product 1 should be 24?

My possible solution:

# Initialize data.frame & call it "x".
Country <- c("AE","DE","CN","AE","DE","CN","AE","CN","AE","DE","CN","AE","DE");
Product <- c(1,1,1,2,2,2,3,3,1,1,1,2,2);
Price <- c(20,20,28,28,28,22,28,28,20,20,28,28,28);
Year_Month <- c(201204,201204,201204,201204,201204,201204,201204,201204,201205,201205,201205,201205,201205);
x <- data.frame(Country,Product,Price,Year_Month,stringsAsFactors=FALSE);
#
#
library("dplyr");
#
# Get the total Price of all Products and number of Products for each
Product & Year_Month"
y <- summarize(group_by(x, Product,
Year_Month),sumPrice=sum(Price),NoPrice=length(Price));
#
# Merge the above data back into the original data.frame, based on
# Product and Year_Month (similar to SQL inner join).
x <- merge(x=x,y=y);
#
# Now calculate the "other area" average by subtracting the cost in this area
# from the total cost in all areas and divide by the number of areas, minus one.
# Please note that if a Product and Year_Month is unique, i.e. no other areas
# for this Product & Year_Month, this will try to divide by zero.
# This gives "Inf" as an answer.
x$Prive_average_In_Other_area <- (x$sumPrice-x$Price)/(x$NoPrice-1);
# Possible alternate to handle above consideration
x$Avg_other <- ifelse(x$NoPrice>1,(x$sumPrice-x$Price)/(x$NoPrice-1),NA);



>
> Please avoid the three for loop, I have tried and it never end. I have
>  1070427 rows.  Is there better way to speed up my program?

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Fri Aug  1 16:54:42 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 1 Aug 2014 10:54:42 -0400
Subject: [R] Better use with gsub
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
Message-ID: <CAP01uRkuQ=bzkb7CPsi5XG272LwPK2ZRkyD4k41QeTN9GEW73g@mail.gmail.com>

On Fri, Aug 1, 2014 at 10:46 AM, Doran, Harold <HDoran at air.org> wrote:
> I have done an embarrassingly bad job using a mixture of gsub and strsplit to solve a problem. Below is sample code showing what I have to start with (the vector xx) and I want to end up with two vectors x and y that contain only the digits found in xx.
>
> Any regex users with advice most welcome
>
> Harold
>
> xx <- c("S24:57",   "S24:86",   "S24:119",  "S24:129",  "S24:138",  "S24:163")
> yy <- gsub("S","\\1", xx)
> a1 <- gsub(":"," ", yy)
> a2 <- sapply(a1, function(x) strsplit(x, ' '))
> x <- as.numeric(sapply(a2, function(x) x[1]))
> y <- as.numeric(sapply(a2, function(x) x[2]))


> library(gsubfn)
> strapply(xx, "\\d+", as.numeric, simplify = TRUE)
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]   24   24   24   24   24   24
[2,]   57   86  119  129  138  163


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Fri Aug  1 17:01:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 01 Aug 2014 11:01:10 -0400
Subject: [R] installing package 'rqpd' (Regression quantiles for panel
 data) on windows
In-Reply-To: <53DB9B0E.4080201@stats.ox.ac.uk>
References: <CABoSW94+XuJr+JS3N0i3KJvqZDFuVEvXZMnq7nb0v75hdw+Tdg@mail.gmail.com>
	<53DB96A4.6060008@gmail.com> <53DB9B0E.4080201@stats.ox.ac.uk>
Message-ID: <53DBABB6.3040700@gmail.com>

On 01/08/2014 9:50 AM, Prof Brian Ripley wrote:
> On 01/08/2014 14:31, Duncan Murdoch wrote:
> > On 01/08/2014 7:48 AM, Roy Sasson wrote:
> >> hello R community,
> >> i am trying to install rqpd package on windows, using the following
> >> command:
> >>
> >> install.packages("rqpd",repos="http://R-Forge.R-project.org")
> >>
> >> however, i get the following message:
> >>
> >> Warning: unable to access index for repository
> >> http://R-Forge.R-project.org/bin/windows/contrib/2.15
> >> Warning message:
> >> package ?rqpd? is not available (for R version 2.15.1)
> >>
> >> i have tried using different versions of R (newer and older), but with no
> >> luck.
> >>
> >> I have also checked out the following thread -
> >> http://r.789695.n4.nabble.com/installing-package-rqpd-Regression-quantiles-for-panel-data-td4668594.html
> >>
> >>
> >> but it is not so clear how this problem was resolved eventually.
> >>
> >> would appreciate any assistance
> >
> > You don't say what platform you're working on. On Windows, there is no
>
> Actually he did, but he did not give the 'an a minimum' information
> asked for in the posting guide.
>
> > binary for rqpd, but you can get the source. This appears to be an
> > R-forge bug, because it will build from source without error. You should
> > report this to R-forge. In the meantime, use type="source" when you do
> > the install. You shouldn't need any special tools to do this, since it's
> > a pure R package, no compiled code.
>
> Not an R-Forge bug as his R is too old: R-Forge only builds binary
> packages for current R.  As the posting guide asked, update R before
> posting ....

We both missed part of the posting:  he said he tried newer R versions 
too.  And I get this (on Windows):

 > install.packages("rqpd",repos="http://R-Forge.R-project.org")

    package ?rqpd? is available as a source package but not as a binary

Warning message:
package ?rqpd? is not available (for R version 3.1.1 Patched)

The log on R-forge shows that it was last built for Windows in 2012.  So 
I think this really is an R-forge bug...

Duncan Murdoch
>
> See also (as per the posting guide):
>
> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#How-can-I-get-a-binary-version-of-a-package_003f
> http://cran.r-project.org/bin/windows/base/rw-FAQ.html#No-binary-packages-appear-to-be-available-for-my-version-of-R
>
>
> >
> > Duncan Murdoch
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


From smartpink111 at yahoo.com  Fri Aug  1 16:59:55 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Aug 2014 07:59:55 -0700
Subject: [R] Better use with gsub
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
Message-ID: <1406905195.28646.YahooMailNeo@web142605.mail.bf1.yahoo.com>



You could try:
library(stringr)
? 
simplify2array(str_extract_all(xx, perl('(?<=[A-Z]|\\:)\\d+')))
???? [,1] [,2] [,3]? [,4]? [,5]? [,6] 
[1,] "24" "24" "24"? "24"? "24"? "24" 
[2,] "57" "86" "119" "129" "138" "163"
A.K.

On Friday, August 1, 2014 10:49 AM, "Doran, Harold" <HDoran at air.org> wrote:
I have done an embarrassingly bad job using a mixture of gsub and strsplit to solve a problem. Below is sample code showing what I have to start with (the vector xx) and I want to end up with two vectors x and y that contain only the digits found in xx.

Any regex users with advice most welcome

Harold

xx <- c("S24:57",?  "S24:86",?  "S24:119",? "S24:129",? "S24:138",? "S24:163")
yy <- gsub("S","\\1", xx)
a1 <- gsub(":"," ", yy)
a2 <- sapply(a1, function(x) strsplit(x, ' '))
x <- as.numeric(sapply(a2, function(x) x[1]))
y <- as.numeric(sapply(a2, function(x) x[2]))

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Aug  1 17:01:30 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Aug 2014 08:01:30 -0700
Subject: [R] Better use with gsub
In-Reply-To: <1406905195.28646.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
	<1406905195.28646.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1406905290.52150.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Forgot about as.numeric.

?sapply(str_extract_all(xx, perl('(?<=[A-Z]|\\:)\\d+')),as.numeric)
???? [,1] [,2] [,3] [,4] [,5] [,6]
[1,]?? 24?? 24?? 24?? 24?? 24?? 24
[2,]?? 57?? 86? 119? 129? 138? 163






On Friday, August 1, 2014 10:59 AM, arun <smartpink111 at yahoo.com> wrote:


You could try:
library(stringr)
? 
simplify2array(str_extract_all(xx, perl('(?<=[A-Z]|\\:)\\d+')))
???? [,1] [,2] [,3]? [,4]? [,5]? [,6] 
[1,] "24" "24" "24"? "24"? "24"? "24" 
[2,] "57" "86" "119" "129" "138" "163"
A.K.




On Friday, August 1, 2014 10:49 AM, "Doran, Harold" <HDoran at air.org> wrote:
I have done an embarrassingly bad job using a mixture of gsub and strsplit to solve a problem. Below is sample code showing what I have to start with (the vector xx) and I want to end up with two vectors x and y that contain only the digits found in xx.

Any regex users with advice most welcome

Harold

xx <- c("S24:57",?? "S24:86",?? "S24:119",? "S24:129",? "S24:138",? "S24:163")
yy <- gsub("S","\\1", xx)
a1 <- gsub(":"," ", yy)
a2 <- sapply(a1, function(x) strsplit(x, ' '))
x <- as.numeric(sapply(a2, function(x) x[1]))
y <- as.numeric(sapply(a2, function(x) x[2]))

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Aug  1 17:06:02 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 01 Aug 2014 10:06:02 -0500
Subject: [R] Better use with gsub
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
Message-ID: <EDD48787-E077-42D8-A864-32269A3A2167@me.com>

On Aug 1, 2014, at 9:46 AM, Doran, Harold <HDoran at air.org> wrote:

> I have done an embarrassingly bad job using a mixture of gsub and strsplit to solve a problem. Below is sample code showing what I have to start with (the vector xx) and I want to end up with two vectors x and y that contain only the digits found in xx.
> 
> Any regex users with advice most welcome
> 
> Harold
> 
> xx <- c("S24:57",   "S24:86",   "S24:119",  "S24:129",  "S24:138",  "S24:163")
> yy <- gsub("S","\\1", xx)
> a1 <- gsub(":"," ", yy)
> a2 <- sapply(a1, function(x) strsplit(x, ' '))
> x <- as.numeric(sapply(a2, function(x) x[1]))
> y <- as.numeric(sapply(a2, function(x) x[2]))


If a matrix is a satisfactory result, rather than two separate vectors:

> sapply(strsplit(gsub("S", "", xx), xx, split = ":"), as.numeric)
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]   24   24   24   24   24   24
[2,]   57   86  119  129  138  163


Regards,

Marc Schwartz


From give_me_more_spam at gazeta.pl  Fri Aug  1 17:10:00 2014
From: give_me_more_spam at gazeta.pl (Marek Szatkowski)
Date: Fri, 1 Aug 2014 17:10:00 +0200
Subject: [R] Better use with gsub
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD68699B11D5D@DC1VEX10MB001.air.org>
Message-ID: <CADw+S_WREug9ifp9hPmu_VPSxPgSqDcwv2Sbj09PQRnrTHMwUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/f9be206d/attachment.pl>

From 538280 at gmail.com  Fri Aug  1 19:29:43 2014
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 1 Aug 2014 11:29:43 -0600
Subject: [R] Need(?) way to create a "picture" (or "plot") of a
	data.frame
In-Reply-To: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
References: <CAAJSdjjUk4rvGLwwff4FL0uWG2_9cUQ_yiGPTc69zewB_YJGyg@mail.gmail.com>
Message-ID: <CAFEqCdwhvR5rm_7C1QBAOGSeGR0+P9qwdMpfAdNv5gxXgLYEsA@mail.gmail.com>

I think it may be time for you to rethink your process.  Yes there are
ways to do what you are asking, but when you start wanting to combine
graphs, tables, r output and descriptions and annotations then it is
time to look into tools like knitr.  With knitr you can create a
template file with R code to create the graphs of interest as well as
tables and output and include any descriptions/annotations that you
want.  Then you process the template into a report with the code being
run for you and the results inserted into the final report.  With
knitr, and the pandoc program, you can generate the final report as a
pdf file, html file, MS Word document, and others.  I don't think that
you can generate Power Point directly yet, but you can generate pdf or
html slides (better than Power point anyways) or put everything of
interest into a Word document that can then be easily cut and paste to
Power Point.

This will require some investment up front and a shift in the way you
are doing things, but in the long run it can be a real time and effort
saver.

On Thu, Jul 31, 2014 at 5:49 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> OK, I'm probably using the wrong tool for this, but I'm doing
> everything else in this project in R, so I'm looking at how to do this
> too. I create a number of graphs using ggplot2. I use the png()
> function before the print(..graph.variable..) in order to create a PNG
> file which can be embedded in a MS PowerPoint display. This is working
> fairly well.
>
> But what I need now is a way to create a png file which is basically a
> "picture" of what you might see when you simply display a data.frame
> using Rstudio or even from the command prompt. I considered just using
> sink() and print(), but I have two problems. First, it doesn't create
> a PNG output. Second, I need to put in text annotations, title, etc.
> So what I need might be what a "geom_data.table" would produce, if
> such a thing existed in ggplot2.
>
> Is there another "plotting" package which will do such a weird thing?
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From honkit at stanford.edu  Fri Aug  1 20:58:10 2014
From: honkit at stanford.edu (Stephen HK Wong)
Date: Fri, 1 Aug 2014 11:58:10 -0700 (PDT)
Subject: [R] How to randomly extract a number of rows in a data frame
Message-ID: <687088457.8022659.1406919490250.JavaMail.zimbra@stanford.edu>

Dear ALL,

I have a dataframe contains 4 columns and several 10 millions of rows like below! I want to extract out "randomly" say 1 millions of rows, can you tell me how to do that in R using base packages? Many Thanks!!!!

Col_1	Col_2	Col_3	Col_4
chr1	3000215	3000250	-
chr1	3000909	3000944	+
chr1	3001025	3001060	+
chr1	3001547	3001582	+
chr1	3002254	3002289	+
chr1	3002324	3002359	-
chr1	3002833	3002868	-
chr1	3004565	3004600	-
chr1	3004945	3004980	+
chr1	3004974	3005009	-
chr1	3005115	3005150	+
chr1	3005124	3005159	+
chr1	3005240	3005275	-
chr1	3005558	3005593	-
chr1	3005890	3005925	+
chr1	3005929	3005964	+
chr1	3005913	3005948	-
chr1	3005913	3005948	-

Stephen HK Wong


From marc_schwartz at me.com  Fri Aug  1 21:08:30 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 01 Aug 2014 14:08:30 -0500
Subject: [R] How to randomly extract a number of rows in a data frame
In-Reply-To: <687088457.8022659.1406919490250.JavaMail.zimbra@stanford.edu>
References: <687088457.8022659.1406919490250.JavaMail.zimbra@stanford.edu>
Message-ID: <D652BF1F-34B0-4D1B-947E-1F2A8E502CB5@me.com>

On Aug 1, 2014, at 1:58 PM, Stephen HK Wong <honkit at stanford.edu> wrote:

> Dear ALL,
> 
> I have a dataframe contains 4 columns and several 10 millions of rows like below! I want to extract out "randomly" say 1 millions of rows, can you tell me how to do that in R using base packages? Many Thanks!!!!
> 
> Col_1	Col_2	Col_3	Col_4
> chr1	3000215	3000250	-
> chr1	3000909	3000944	+
> chr1	3001025	3001060	+
> chr1	3001547	3001582	+
> chr1	3002254	3002289	+
> chr1	3002324	3002359	-
> chr1	3002833	3002868	-
> chr1	3004565	3004600	-
> chr1	3004945	3004980	+
> chr1	3004974	3005009	-
> chr1	3005115	3005150	+
> chr1	3005124	3005159	+
> chr1	3005240	3005275	-
> chr1	3005558	3005593	-
> chr1	3005890	3005925	+
> chr1	3005929	3005964	+
> chr1	3005913	3005948	-
> chr1	3005913	3005948	-
> 
> Stephen HK Wong


If your data frame is called 'DF':

  DF.Rand <- DF[sample(nrow(DF), 1000000), ]

See ?sample which will generate a random sample from a uniform distribution.

In the above, nrow(DF) returns the number of rows in DF and defines the sample space of 1:nrow(DF), from which 1000000 random integer values will be selected and used as indices to return the rows.

Using the built in 'iris' dataset, select 20 random rows from the 150 total:

> iris[sample(nrow(iris), 20), ]
    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species
122          5.6         2.8          4.9         2.0  virginica
79           6.0         2.9          4.5         1.5 versicolor
109          6.7         2.5          5.8         1.8  virginica
106          7.6         3.0          6.6         2.1  virginica
49           5.3         3.7          1.5         0.2     setosa
125          6.7         3.3          5.7         2.1  virginica
1            5.1         3.5          1.4         0.2     setosa
68           5.8         2.7          4.1         1.0 versicolor
84           6.0         2.7          5.1         1.6 versicolor
110          7.2         3.6          6.1         2.5  virginica
113          6.8         3.0          5.5         2.1  virginica
64           6.1         2.9          4.7         1.4 versicolor
102          5.8         2.7          5.1         1.9  virginica
71           5.9         3.2          4.8         1.8 versicolor
69           6.2         2.2          4.5         1.5 versicolor
65           5.6         2.9          3.6         1.3 versicolor
74           6.1         2.8          4.7         1.2 versicolor
99           5.1         2.5          3.0         1.1 versicolor
135          6.1         2.6          5.6         1.4  virginica
41           5.0         3.5          1.3         0.3     setosa



Regards,

Marc Schwartz
 

From wdunlap at tibco.com  Fri Aug  1 21:12:51 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 Aug 2014 12:12:51 -0700
Subject: [R] How to randomly extract a number of rows in a data frame
In-Reply-To: <687088457.8022659.1406919490250.JavaMail.zimbra@stanford.edu>
References: <687088457.8022659.1406919490250.JavaMail.zimbra@stanford.edu>
Message-ID: <CAF8bMcbg4oFCHLPFOv-AeLuXXBxqhxxbGrnjju47qx1e8J8otg@mail.gmail.com>

Do you know how to extract some rows of a data.frame?  A short answer
is with subscripts, either integer,
   first10 <- 1:10
   dFirst10 <- d[first10, ] # I assume your data.frame is called 'd'
or logical
   plus4 <- d[, "Col_4"] == "+"
   dPlus4 <- d[ plus4, ]
If you are not familiar with that sort of thing, read the introduction
to R document that comes with R.

So you can solve your problem if you can generate a vector containing
1 million integers in the range 1:10^7.  Use the sample function for
that.  You must decide if you want to allow duplicate rows or not
(i.e., sampling with or without replacement). Type
  ?sample
to see the details.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 1, 2014 at 11:58 AM, Stephen HK Wong <honkit at stanford.edu> wrote:
> Dear ALL,
>
> I have a dataframe contains 4 columns and several 10 millions of rows like below! I want to extract out "randomly" say 1 millions of rows, can you tell me how to do that in R using base packages? Many Thanks!!!!
>
> Col_1   Col_2   Col_3   Col_4
> chr1    3000215 3000250 -
> chr1    3000909 3000944 +
> chr1    3001025 3001060 +
> chr1    3001547 3001582 +
> chr1    3002254 3002289 +
> chr1    3002324 3002359 -
> chr1    3002833 3002868 -
> chr1    3004565 3004600 -
> chr1    3004945 3004980 +
> chr1    3004974 3005009 -
> chr1    3005115 3005150 +
> chr1    3005124 3005159 +
> chr1    3005240 3005275 -
> chr1    3005558 3005593 -
> chr1    3005890 3005925 +
> chr1    3005929 3005964 +
> chr1    3005913 3005948 -
> chr1    3005913 3005948 -
>
> Stephen HK Wong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarov at gmail.com  Fri Aug  1 17:36:04 2014
From: dcarov at gmail.com (Daniel Caro)
Date: Fri, 1 Aug 2014 16:36:04 +0100
Subject: [R] lm weights argument within function
Message-ID: <CAMeQTh0DWYRAsN6Su2f1rAG9BDVPLH9sqjxnb=eJt+v82omhww@mail.gmail.com>

Hi all,

I need to loop over "lm" within a function using "weights". For example:

mydata = data.frame(y=rnorm(100, 500, 100), x= rnorm(100),
group=rep(c(0,1), 50), myweight=1/runif(100))

reg.by.wt <- function(formula, wt, by, data) {
  if(missing(by)) {
    summary(lm(formula=formula, data=data, weights=data[[wt]]))
  } else {
    lapply(split(data, data[by]), function(i)
summary(lm(formula=formula, data=i, weights=data[[wt]])))
  }
}

reg.by.wt(formula = y ~ x, by="group", data=mydata, wt="myweight")

Error in summary(lm(formula = formula, data = i, weights = data[[wt]])) :
  error in evaluating the argument 'object' in selecting a method for
function 'summary': Error in eval(expr, envir, enclos) : object 'wt'
not found

The functions works if I change "weights=data[[wt]]" for
"weights=myweight", but I need wt to be an argument in quotes, not an
object. It seems the issue is related to ?lm = "All of weights, subset
and offset are evaluated in the same way as variables in formula, that
is first in data and then in the environment of formula., but I can't
figure it out. Can you please provide any advice? Thank you.

Daniel


From kathy at haapi.mn.org  Fri Aug  1 21:56:21 2014
From: kathy at haapi.mn.org (Kathy Haapala)
Date: Fri, 1 Aug 2014 15:56:21 -0400
Subject: [R] Combining Rows from One Data Frame, Outputting into Another
Message-ID: <CAEcORNOR6VL_isgAJM5KMuD65QLBEPQiTrzxWF8+-k_ZnMpiDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140801/a0443820/attachment.pl>

From wdunlap at tibco.com  Sat Aug  2 01:47:28 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 1 Aug 2014 16:47:28 -0700
Subject: [R] lm weights argument within function
In-Reply-To: <CAMeQTh0DWYRAsN6Su2f1rAG9BDVPLH9sqjxnb=eJt+v82omhww@mail.gmail.com>
References: <CAMeQTh0DWYRAsN6Su2f1rAG9BDVPLH9sqjxnb=eJt+v82omhww@mail.gmail.com>
Message-ID: <CAF8bMcaSMveHH-68APan5MKDGA7tkizazfvthOkPkp5ciFRKdA@mail.gmail.com>

One way to accomplish this is to assign a new environment to the
formula, an environment which inherits from the formula's original
environment but one that you can add things to without affecting the
original environment.  Also, since you do this in a function only the
copy of the formula in the function is affected; when the function is
done your formula is not changed.  E.g.,

mydata <- data.frame( # a dataset that one can recreate
    y = log2(1:100),
    x = 1:100,
    group = rep(c(0,1), each = 50),
    myweight = 1/(1:100),
    yourweight = 1:100)

reg.by.wt <- function(formula, wt, by, data) {
  newEnv <- new.env(parent = environment(formula))
  newEnv$wt <- wt
  newEnv$data <- data
  environment(formula) <- newEnv
  if(missing(by)) {
    summary(lm(formula = formula, data = data, weights = data[[wt]]))
  } else {
    lapply(split(data, data[by]),
           function(i) {
               newEnv$i <- i
               summary(lm(formula = formula, data = i, weights = i[[wt]]))
           })
  }
}

try(reg.by.wt(formula = y ~ x, by="group", data=mydata, wt="myweight"))
try(reg.by.wt(formula = y ~ x, data=mydata, wt="myweight"))
try(reg.by.wt(formula = y ~ x, by="group", data=mydata, wt="yourweight"))

There may be less sneaky ways of doing this sort of thing.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 1, 2014 at 8:36 AM, Daniel Caro <dcarov at gmail.com> wrote:
> Hi all,
>
> I need to loop over "lm" within a function using "weights". For example:
>
> mydata = data.frame(y=rnorm(100, 500, 100), x= rnorm(100),
> group=rep(c(0,1), 50), myweight=1/runif(100))
>
> reg.by.wt <- function(formula, wt, by, data) {
>   if(missing(by)) {
>     summary(lm(formula=formula, data=data, weights=data[[wt]]))
>   } else {
>     lapply(split(data, data[by]), function(i)
> summary(lm(formula=formula, data=i, weights=data[[wt]])))
>   }
> }
>
> reg.by.wt(formula = y ~ x, by="group", data=mydata, wt="myweight")
>
> Error in summary(lm(formula = formula, data = i, weights = data[[wt]])) :
>   error in evaluating the argument 'object' in selecting a method for
> function 'summary': Error in eval(expr, envir, enclos) : object 'wt'
> not found
>
> The functions works if I change "weights=data[[wt]]" for
> "weights=myweight", but I need wt to be an argument in quotes, not an
> object. It seems the issue is related to ?lm = "All of weights, subset
> and offset are evaluated in the same way as variables in formula, that
> is first in data and then in the environment of formula., but I can't
> figure it out. Can you please provide any advice? Thank you.
>
> Daniel
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Aug  2 02:01:21 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 01 Aug 2014 17:01:21 -0700
Subject: [R] Combining Rows from One Data Frame, Outputting into Another
In-Reply-To: <CAEcORNOR6VL_isgAJM5KMuD65QLBEPQiTrzxWF8+-k_ZnMpiDg@mail.gmail.com>
References: <CAEcORNOR6VL_isgAJM5KMuD65QLBEPQiTrzxWF8+-k_ZnMpiDg@mail.gmail.com>
Message-ID: <7580ddc3-d1cd-49e3-acb9-3f173eb51968@email.android.com>

library(reshape2)
?dcast

Nice example. So nice that it looks like it could be homework... thus the pointer to docs rather than a full solution. Please read the Posting Guide, and note that HTML email format is not necessarily a what-you-see-is-what-we-see format so you should post in plain text next time.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 1, 2014 12:56:21 PM PDT, Kathy Haapala <kathy at haapi.mn.org> wrote:
>If I have a dataframe x.df as follows:
>> x.df <- data.frame(Year = c(2000, 2000, 2000, 2000, 2000, 2001, 2001,
>2001, 2001, 2002), Group = c(1, 1, 1, 2, 2, 1, 2, 2, 3, 1), Eye_Color =
>c("blue", "blue", "brown", "green", "green", "blue", "brown", "blue",
>"blue", "blue"))
>
>> x.df
>   Year Group Eye_Color
>1  2000     1      blue
>2  2000     1      blue
>3  2000     1     brown
>4  2000     2     green
>5  2000     2     green
>6  2001     1      blue
>7  2001     2     brown
>8  2001     2      blue
>9  2001     3      blue
>10 2002     1      blue
>
>how can I turn it into a new dataframe that would take the data from
>multiple rows of Year/Group combinations and output the data into one
>row
>for each combination, like this:
>> x_new.df
>  Year Group No_blue No_brown No_green
>1 2000     1       2        1        0
>2 2000     2       0        0        2
>3 2001     1       1        0        0
>4 2001     2       1        1        0
>5 2001     3       1        0        0
>6 2002     1       1        0        0
>
>I've been trying to use for loops, but I'm wondering if anyone has a
>better
>or more simple suggestion.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From emammendes at gmail.com  Sat Aug  2 04:36:29 2014
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Fri, 1 Aug 2014 23:36:29 -0300
Subject: [R] How to change print behaviour within a markdown document
Message-ID: <8E810095-836E-42E9-A1B5-8753807AD9B0@gmail.com>

Hello

I have the following chunk of code within a rmarkdown document:

```{r infoA, echo=FALSE, tidy=FALSE}
print(pAinfo,quote=FALSE,justify="center")
```
pAinfo is data.frame with 21 rows and 4 columns. Unfortunately the resulting html (or pdf) file does not show all the four columns together (the fourth column is placed below the first three columns) even though there is plenty of room to accommodate the last column.

Is there a way to control how print or rmarkdown breaks the data.frame in order to get all four columns together? Can I somehow control the font size too?

Many thanks

Ed


From florian.denzinger at uzh.ch  Sat Aug  2 05:22:26 2014
From: florian.denzinger at uzh.ch (Florian Denzinger)
Date: Sat, 2 Aug 2014 05:22:26 +0200
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD96A@SRVEXCHMBX.precheza.cz>
References: <1406817448605-4694850.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD96A@SRVEXCHMBX.precheza.cz>
Message-ID: <728C1BB2-43EE-48BB-810E-646F18B8B807@uzh.ch>

Thank you everyone for your help so far. 

I am still working on the problem to get a merged new dataframe which fills in new rows with NA values for each year that is missing for plotting with gaps ( in the example the item BARTLEY: years 1984 to 1987 should be filled with a row containing NA values). Could someone maybe help me with this? Thank you. 


    NAME               			 ID      	YEAR	VALUE
    ADAMS				885		1988	      -2
    ADAMS				885		1989		0
    BAHIA DEL DIABLO	2665	1999		4
    BAHIA DEL DIABLO	2665	2000		8
    BAHIA DEL DIABLO	2665	2001	      19
    BAHIA DEL DIABLO	2665	2002	      13
    BAHIA DEL DIABLO	2665	2003	      13
    BARTLEY				893		1983		0
    BARTLEY				893		1988		2
    BARTLEY				893		1989	       -1
    CANADA				877		1972	       -1
    CLARK CPI			894		1973	       -3

Am 01.08.2014 um 11:27 schrieb PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
> 
> Maybe others will disagree but I find for cycle for this type of task better than sapply.
> 
> for(i in 1:length(ind)) {
> 
> if (there are more than 3 date items*) {
> 
> postscript(ind[i])
> do all plotting
> dev.off()
> }}
> 
> If you want to plot with gaps you need to add all relevant YEARs for x axis with missing value in y before plotting. Then R plots it automatically with gap.
> 
> x<-1:10
> y<-rnorm(10)
> y[5:6]<-NA
> plot(x,y, type="b")
> 
> I would suggest to use merge for this task.
> 
> table(dat$ID)
> gives you number of unique values for each ID and you can use it for discarding this ID from the list.
> 
> Regards
> Petr
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of fd
>> Sent: Thursday, July 31, 2014 4:37 PM
>> To: r-help at r-project.org
>> Subject: [R] Multiple plots and postscripts using split function
>> 
>> Hi,
>> 
>> I'm relatively new to R and I would like to do the following:
>> 
>> I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and would
>> like to do several xy plots with the year on the x-axis and the data
>> values
>> (measurements) on the y-axis and after that export the different plots
>> to postcript.
>> 
>> My .csv file looks something like this (only an example):
>> 
>> NAME                          ID              YEAR    VALUE
>> ADAMS                         885             1988            -2
>> ADAMS                         885             1989            0
>> BAHIA DEL DIABLO              2665            1999            4
>> BAHIA DEL DIABLO              2665            2000            8
>> BAHIA DEL DIABLO              2665            2001            19
>> BAHIA DEL DIABLO              2665            2002            13
>> BAHIA DEL DIABLO              2665            2003            13
>> BARTLEY                               893             1983            0
>> BARTLEY                               893             1984            -1
>> BARTLEY                               893             1985            0
>> BARTLEY                               893             1988            2
>> BARTLEY                               893             1989            -1
>> CANADA                                877             1972            -1
>> 
>> I have split the different items into groups and I'd like the plots to
>> have the title of NAME but the filename of the postscript to be
>> exported should have the ID as filename.
>> 
>> My code so far:
>> 
>> #Set Working Directory:
>> setwd("/Users/Desktop/FV")
>> # Read CSV
>> dat <- read.csv("FV.csv", sep=";", header=TRUE) # Split Data ind <-
>> split(x = dat,f = dat[,'ID']) nam <- names(ind)
>> 
>> sapply(nam, function(x) {
>>      postscript(x)
>>      par(mar=c(6,8,6,5), cex=0.8)
>>      plot(ind[[x]][,c('YEAR','VALUE')],
>>      type='b',
>>      main = x,
>>      xlab="Time [Years]",
>>      ylab="Front variation")
>>      axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-
>> 0.3)
>>      axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
>> tcl=-0.3)
>> 
>>      dev.off()
>> })
>> 
>> This results in plots with the title and filename of the resulting
>> postscript being the same. Is there a way to get the plot title out of
>> the NAME column and the filename out of the ID?
>> 
>> Additionally I'd only like to plot graphs for items with more than 3
>> data values. Is this possible to incorporate in the split command?
>> 
>> Another point is that some items have gaps in the time series where no
>> measurements were taken (in my example: BARTLEY from 1983 to 1985 and
>> 1988 to 1989). I would like to plot using type= 'b' so that the points
>> are connected with lines, but when doing that, the values between 1985
>> and 1988 are automatically connected which I don't want. I'd like the
>> plot to start again at the value where the gap ends (in my example from
>> 1988 onwards). Is there a solution for this?
>> 
>> Any help is kindly appreciated! Thanks for your help.
>> 
>> Kind regards,
>> fd
>> 
>> 
>> 
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Multiple-
>> plots-and-postscripts-using-split-function-tp4694850.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From jdnewmil at dcn.davis.CA.us  Sat Aug  2 07:54:27 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 01 Aug 2014 22:54:27 -0700
Subject: [R] How to change print behaviour within a markdown document
In-Reply-To: <8E810095-836E-42E9-A1B5-8753807AD9B0@gmail.com>
References: <8E810095-836E-42E9-A1B5-8753807AD9B0@gmail.com>
Message-ID: <2be4da97-c4ce-457f-8fb3-68c8d73d02dd@email.android.com>

Use one of the various functions out there that generate markdown or html tables, and set the chunk option results='asis'.

Google for "kable", "xtable", "pander", or "ascii"... there are probably others as well.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 1, 2014 7:36:29 PM PDT, "Eduardo M. A. M.Mendes" <emammendes at gmail.com> wrote:
>Hello
>
>I have the following chunk of code within a rmarkdown document:
>
>```{r infoA, echo=FALSE, tidy=FALSE}
>print(pAinfo,quote=FALSE,justify="center")
>```
>pAinfo is data.frame with 21 rows and 4 columns. Unfortunately the
>resulting html (or pdf) file does not show all the four columns
>together (the fourth column is placed below the first three columns)
>even though there is plenty of room to accommodate the last column.
>
>Is there a way to control how print or rmarkdown breaks the data.frame
>in order to get all four columns together? Can I somehow control the
>font size too?
>
>Many thanks
>
>Ed
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Aug  2 07:53:58 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 1 Aug 2014 22:53:58 -0700
Subject: [R] Combining Rows from One Data Frame, Outputting into Another
In-Reply-To: <CAEcORNOR6VL_isgAJM5KMuD65QLBEPQiTrzxWF8+-k_ZnMpiDg@mail.gmail.com>
References: <CAEcORNOR6VL_isgAJM5KMuD65QLBEPQiTrzxWF8+-k_ZnMpiDg@mail.gmail.com>
Message-ID: <1406958838.72929.YahooMailNeo@web142605.mail.bf1.yahoo.com>

You could use:

??? library(dplyr)
??? library(tidyr)
????? x.df %>% group_by(Year, Group, Eye_Color) %>% summarize(n=n()) %>% spread(Eye_Color,n, fill=0)
Source: local data frame [6 x 5]

? Year Group blue brown green
1 2000???? 1??? 2???? 1???? 0
2 2000???? 2??? 0???? 0???? 2
3 2001???? 1??? 1???? 0???? 0
4 2001???? 2??? 1???? 1???? 0
5 2001???? 3??? 1???? 0???? 0
6 2002???? 1??? 1???? 0???? 0



Or

library(reshape2)
dcast(x.df, Year+Group~Eye_Color, value.var="Eye_Color")
A.K.


On Friday, August 1, 2014 7:06 PM, Kathy Haapala <kathy at haapi.mn.org> wrote:
If I have a dataframe x.df as follows:
> x.df <- data.frame(Year = c(2000, 2000, 2000, 2000, 2000, 2001, 2001,
2001, 2001, 2002), Group = c(1, 1, 1, 2, 2, 1, 2, 2, 3, 1), Eye_Color =
c("blue", "blue", "brown", "green", "green", "blue", "brown", "blue",
"blue", "blue"))

> x.df
?  Year Group Eye_Color
1? 2000? ?  1? ? ? blue
2? 2000? ?  1? ? ? blue
3? 2000? ?  1? ?  brown
4? 2000? ?  2? ?  green
5? 2000? ?  2? ?  green
6? 2001? ?  1? ? ? blue
7? 2001? ?  2? ?  brown
8? 2001? ?  2? ? ? blue
9? 2001? ?  3? ? ? blue
10 2002? ?  1? ? ? blue

how can I turn it into a new dataframe that would take the data from
multiple rows of Year/Group combinations and output the data into one row
for each combination, like this:
> x_new.df
? Year Group No_blue No_brown No_green
1 2000? ?  1? ? ?  2? ? ? ? 1? ? ? ? 0
2 2000? ?  2? ? ?  0? ? ? ? 0? ? ? ? 2
3 2001? ?  1? ? ?  1? ? ? ? 0? ? ? ? 0
4 2001? ?  2? ? ?  1? ? ? ? 1? ? ? ? 0
5 2001? ?  3? ? ?  1? ? ? ? 0? ? ? ? 0
6 2002? ?  1? ? ?  1? ? ? ? 0? ? ? ? 0

I've been trying to use for loops, but I'm wondering if anyone has a better
or more simple suggestion.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Sat Aug  2 12:07:49 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 02 Aug 2014 20:07:49 +1000
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <728C1BB2-43EE-48BB-810E-646F18B8B807@uzh.ch>
References: <1406817448605-4694850.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD96A@SRVEXCHMBX.precheza.cz>
	<728C1BB2-43EE-48BB-810E-646F18B8B807@uzh.ch>
Message-ID: <2781913.WY0qvN66kB@localhost.localdomain>

On Sat, 2 Aug 2014 05:22:26 AM Florian Denzinger wrote:
> Thank you everyone for your help so far.
> 
> I am still working on the problem to get a merged new dataframe 
which fills
> in new rows with NA values for each year that is missing for plotting 
with
> gaps ( in the example the item BARTLEY: years 1984 to 1987 should 
be filled
> with a row containing NA values). Could someone maybe help me 
with this?

Hi Florian,
This is pretty messy, but it might do what you want:
fddf<-read.table(text="NAME,ID,YEAR,VALUE
ADAMS,885,1988,-2
ADAMS,885,1989,0
BAHIA DEL DIABLO,2665,1999,4
BAHIA DEL DIABLO,2665,2000,8
BAHIA DEL DIABLO,2665,2001,19
BAHIA DEL DIABLO,2665,2002,13
BAHIA DEL DIABLO,2665,2003,13
BARTLEY,893,1983,0
BARTLEY,893,1988,2
BARTLEY,893,1989,-1
CANADA,877,1972,-1
CLARK CPI,894,1973,-3",sep=",",header=TRUE)

fillgaps<-function(x,rangevar,fillvar,fillval=NA) {
 dimx<-dim(x)
 if(dimx[1] > 1) {
  newxrangevar<-min(x[[rangevar]]):max(x[[rangevar]])
  nrows<-length(newxrangevar)
  newx<-list()
  rangevarno<-which(names(x) %in% rangevar)
  fillvarno<-which(names(x) %in% fillvar)
  cat(rangevarno,fillvarno,"\n")
  for(xcol in 1:dimx[2]) {
   if(xcol == rangevarno) {
    newx[[xcol]]<-newxrangevar
   }
   else {
    if(xcol == fillvarno) {
     newx[[xcol]]<-rep(NA,nrows)
     newx[[xcol]][which(newxrangevar %in% x[[rangevar]])]<-x[[fillvar]]
    }
    else {
     if(is.numeric(x[1,xcol]))
      newx[[xcol]]<-rep(x[1,xcol],length.out=nrows)
     else
      newx[[xcol]]<-rep(as.character(x[1,xcol]),nrows)
    }
   }
  }
  newx<-as.data.frame(newx)
  names(newx)<-names(x)
 }
 else newx<-x
 return(newx)
}

fddfn<-levels(fddf$NAME)
for(fdvar in 1:length(fddfnames)) {
 if(fdvar == 1)
  newx<-fillgaps(fddf[fddf$NAME == fddfn[fdvar],],"YEAR","VALUE")
 else
  newx<-rbind(newx,fillgaps(fddf[fddf$NAME == 
fddfn[fdvar],],"YEAR","VALUE"))
}

Jim


From murdoch.duncan at gmail.com  Sat Aug  2 14:26:39 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 02 Aug 2014 08:26:39 -0400
Subject: [R] How to change print behaviour within a markdown document
In-Reply-To: <8E810095-836E-42E9-A1B5-8753807AD9B0@gmail.com>
References: <8E810095-836E-42E9-A1B5-8753807AD9B0@gmail.com>
Message-ID: <53DCD8FF.3080909@gmail.com>

On 01/08/2014, 10:36 PM, Eduardo M. A. M.Mendes wrote:
> Hello
> 
> I have the following chunk of code within a rmarkdown document:
> 
> ```{r infoA, echo=FALSE, tidy=FALSE}
> print(pAinfo,quote=FALSE,justify="center")
> ```
> pAinfo is data.frame with 21 rows and 4 columns. Unfortunately the resulting html (or pdf) file does not show all the four columns together (the fourth column is placed below the first three columns) even though there is plenty of room to accommodate the last column.
> 
> Is there a way to control how print or rmarkdown breaks the data.frame in order to get all four columns together? Can I somehow control the font size too?

I don't know rmarkdown, but it is probably R that is breaking the lines,
based on the width option.  Set options(width=80) for wider lines.

The font is likely controlled by the style sheet.  You need to find how
rmarkdown sets that, and change it.

Duncan Murdoch


From charles.santana at gmail.com  Sat Aug  2 16:01:05 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Sat, 2 Aug 2014 16:01:05 +0200
Subject: [R] How to overlay contourplot of a dataset A and a levelplot of a
 dataset B?
Message-ID: <CAH-FEnhQLUPmJd3jMVKQuHsN_qkeUkD=pR36FM3Msa5A4eFZ2w@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20140802/9c8ae3c6/attachment.pl>

From emammendes at gmail.com  Sat Aug  2 16:37:01 2014
From: emammendes at gmail.com (Eduardo M. A. M. Mendes)
Date: Sat, 2 Aug 2014 11:37:01 -0300
Subject: [R] How to change print behaviour within a markdown document
In-Reply-To: <53DCD8FF.3080909@gmail.com>
References: <8E810095-836E-42E9-A1B5-8753807AD9B0@gmail.com>
	<53DCD8FF.3080909@gmail.com>
Message-ID: <66F109C5-C4BE-4F9F-8B2B-449D0EF3E0C3@gmail.com>

Dear Duncan

Options did the job.  Thank you ever so much.

I will try the other suggestions too. If they work I will post them as well. 

Cheers

Ed


Enviada do meu iPhone

> Em 02/08/2014, ?s 09:26, Duncan Murdoch <murdoch.duncan at gmail.com> escreveu:
> 
>> On 01/08/2014, 10:36 PM, Eduardo M. A. M.Mendes wrote:
>> Hello
>> 
>> I have the following chunk of code within a rmarkdown document:
>> 
>> ```{r infoA, echo=FALSE, tidy=FALSE}
>> print(pAinfo,quote=FALSE,justify="center")
>> ```
>> pAinfo is data.frame with 21 rows and 4 columns. Unfortunately the resulting html (or pdf) file does not show all the four columns together (the fourth column is placed below the first three columns) even though there is plenty of room to accommodate the last column.
>> 
>> Is there a way to control how print or rmarkdown breaks the data.frame in order to get all four columns together? Can I somehow control the font size too?
> 
> I don't know rmarkdown, but it is probably R that is breaking the lines,
> based on the width option.  Set options(width=80) for wider lines.
> 
> The font is likely controlled by the style sheet.  You need to find how
> rmarkdown sets that, and change it.
> 
> Duncan Murdoch
> 


From wdunlap at tibco.com  Sat Aug  2 16:38:28 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 2 Aug 2014 07:38:28 -0700
Subject: [R] Multiple plots and postscripts using split function
In-Reply-To: <728C1BB2-43EE-48BB-810E-646F18B8B807@uzh.ch>
References: <1406817448605-4694850.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDD96A@SRVEXCHMBX.precheza.cz>
	<728C1BB2-43EE-48BB-810E-646F18B8B807@uzh.ch>
Message-ID: <CAF8bMcYQ-YZN3=3We6rB+88NYVGFYEyv-nxzsgC3CXYg0yn5aQ@mail.gmail.com>

Have you tried using the merge() function?  E.g.,

lapply(split(d, d$NAME), function(di)merge(all=TRUE, di,
data.frame(YEAR=seq(min(di$YEAR), max(di$YEAR), by=1))))
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 1, 2014 at 8:22 PM, Florian Denzinger
<florian.denzinger at uzh.ch> wrote:
> Thank you everyone for your help so far.
>
> I am still working on the problem to get a merged new dataframe which fills in new rows with NA values for each year that is missing for plotting with gaps ( in the example the item BARTLEY: years 1984 to 1987 should be filled with a row containing NA values). Could someone maybe help me with this? Thank you.
>
>
>     NAME                                 ID             YEAR    VALUE
>     ADAMS                               885             1988          -2
>     ADAMS                               885             1989            0
>     BAHIA DEL DIABLO    2665    1999            4
>     BAHIA DEL DIABLO    2665    2000            8
>     BAHIA DEL DIABLO    2665    2001          19
>     BAHIA DEL DIABLO    2665    2002          13
>     BAHIA DEL DIABLO    2665    2003          13
>     BARTLEY                             893             1983            0
>     BARTLEY                             893             1988            2
>     BARTLEY                             893             1989           -1
>     CANADA                              877             1972           -1
>     CLARK CPI                   894             1973           -3
>
> Am 01.08.2014 um 11:27 schrieb PIKAL Petr <petr.pikal at precheza.cz>:
>
>> Hi
>>
>> Maybe others will disagree but I find for cycle for this type of task better than sapply.
>>
>> for(i in 1:length(ind)) {
>>
>> if (there are more than 3 date items*) {
>>
>> postscript(ind[i])
>> do all plotting
>> dev.off()
>> }}
>>
>> If you want to plot with gaps you need to add all relevant YEARs for x axis with missing value in y before plotting. Then R plots it automatically with gap.
>>
>> x<-1:10
>> y<-rnorm(10)
>> y[5:6]<-NA
>> plot(x,y, type="b")
>>
>> I would suggest to use merge for this task.
>>
>> table(dat$ID)
>> gives you number of unique values for each ID and you can use it for discarding this ID from the list.
>>
>> Regards
>> Petr
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of fd
>>> Sent: Thursday, July 31, 2014 4:37 PM
>>> To: r-help at r-project.org
>>> Subject: [R] Multiple plots and postscripts using split function
>>>
>>> Hi,
>>>
>>> I'm relatively new to R and I would like to do the following:
>>>
>>> I have a .csv file with four columns (NAME, ID, YEAR, VALUE) and would
>>> like to do several xy plots with the year on the x-axis and the data
>>> values
>>> (measurements) on the y-axis and after that export the different plots
>>> to postcript.
>>>
>>> My .csv file looks something like this (only an example):
>>>
>>> NAME                          ID              YEAR    VALUE
>>> ADAMS                         885             1988            -2
>>> ADAMS                         885             1989            0
>>> BAHIA DEL DIABLO              2665            1999            4
>>> BAHIA DEL DIABLO              2665            2000            8
>>> BAHIA DEL DIABLO              2665            2001            19
>>> BAHIA DEL DIABLO              2665            2002            13
>>> BAHIA DEL DIABLO              2665            2003            13
>>> BARTLEY                               893             1983            0
>>> BARTLEY                               893             1984            -1
>>> BARTLEY                               893             1985            0
>>> BARTLEY                               893             1988            2
>>> BARTLEY                               893             1989            -1
>>> CANADA                                877             1972            -1
>>>
>>> I have split the different items into groups and I'd like the plots to
>>> have the title of NAME but the filename of the postscript to be
>>> exported should have the ID as filename.
>>>
>>> My code so far:
>>>
>>> #Set Working Directory:
>>> setwd("/Users/Desktop/FV")
>>> # Read CSV
>>> dat <- read.csv("FV.csv", sep=";", header=TRUE) # Split Data ind <-
>>> split(x = dat,f = dat[,'ID']) nam <- names(ind)
>>>
>>> sapply(nam, function(x) {
>>>      postscript(x)
>>>      par(mar=c(6,8,6,5), cex=0.8)
>>>      plot(ind[[x]][,c('YEAR','VALUE')],
>>>      type='b',
>>>      main = x,
>>>      xlab="Time [Years]",
>>>      ylab="Front variation")
>>>      axis(1, at = seq(1800,2100,5), cex.axis=1, labels=FALSE, tcl=-
>>> 0.3)
>>>      axis(2, at = seq(-100000,100000,500), cex.axis=1, labels=FALSE,
>>> tcl=-0.3)
>>>
>>>      dev.off()
>>> })
>>>
>>> This results in plots with the title and filename of the resulting
>>> postscript being the same. Is there a way to get the plot title out of
>>> the NAME column and the filename out of the ID?
>>>
>>> Additionally I'd only like to plot graphs for items with more than 3
>>> data values. Is this possible to incorporate in the split command?
>>>
>>> Another point is that some items have gaps in the time series where no
>>> measurements were taken (in my example: BARTLEY from 1983 to 1985 and
>>> 1988 to 1989). I would like to plot using type= 'b' so that the points
>>> are connected with lines, but when doing that, the values between 1985
>>> and 1988 are automatically connected which I don't want. I'd like the
>>> plot to start again at the value where the gap ends (in my example from
>>> 1988 onwards). Is there a solution for this?
>>>
>>> Any help is kindly appreciated! Thanks for your help.
>>>
>>> Kind regards,
>>> fd
>>>
>>>
>>>
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/Multiple-
>>> plots-and-postscripts-using-split-function-tp4694850.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>>
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>>
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>>
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From oriolebaltimore at gmail.com  Sat Aug  2 20:11:13 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Sat, 2 Aug 2014 14:11:13 -0400
Subject: [R] mutually exclusive events
Message-ID: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140802/3cb28888/attachment.pl>

From dwinsemius at comcast.net  Sat Aug  2 20:41:59 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 2 Aug 2014 11:41:59 -0700
Subject: [R] mutually exclusive events
In-Reply-To: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
References: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
Message-ID: <80D8C92F-9568-4913-A698-157B61F4494F@comcast.net>


On Aug 2, 2014, at 11:11 AM, Adrian Johnson wrote:

> Hi:
> 
> I am trying to identify mutually exclusive events from the following
> example:
> 
#-------------
 dat <- read.table(text="Cluster      Gene      Mutated    not_mutated
  1             G1             1              0
  1             G2             1              0
  1             G3             0              1
  1             G4             0              1
  1             G5             1              0
  2             G1             0              1
  2             G2             1              0
  2             G3             1              0
  2             G4             0              0
  2             G5             1              0", header=TRUE, stringsAsFactors=FALSE)

 with(dat, table(Cluster, Gene, Mutated)  )
#----------------
, , Mutated = 0

       Gene
Cluster G1 G2 G3 G4 G5
      1  0  0  1  1  0
      2  1  0  0  1  0

, , Mutated = 1

       Gene
Cluster G1 G2 G3 G4 G5
      1  1  1  0  0  1
      2  0  1  1  0  1
#--------------
Or:
xtabs(Mutated ~ Cluster+Gene, data=dat)
#----------------
       Gene
Cluster G1 G2 G3 G4 G5
      1  1  1  0  0  1
      2  0  1  1  0  1


I'm a bit unclear about your goals. Are you trying to identify the "Gene"s that have only one "Cluster" mutated as the "G1-G3" events and the Gene's that have either-Cluster but not both as the "G2-G5" events?

If so you can choose the columns that have a sum of 2 for the first and columns with sum of 1 for the second.
> 
> 
> In cluster 1 :  G1, G2, G5 are mutated
> 
> In cluster 2:    G2, G3, G5 are mutated.
> 
> 
> I am interested in finding such G2-G5 event and G1-G3 events.
> 
> In total I have a 8 clusters and 150 gene (1200 rows x 4 columns).
> 
> What test could be appropriate to identify such pairs.
> 
> In my naive understanding would a fishers-exact test give such
> combinations.

It's even less clear what sort of "test" you propose. `fisher.test` is a test of association. It doesn't identify combinations.
> 
> Thanks a lot.
> 
> -Adrian
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list.

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dmck at u.washington.edu  Sat Aug  2 20:47:16 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Sat, 2 Aug 2014 11:47:16 -0700
Subject: [R] mutually exclusive events
In-Reply-To: <80D8C92F-9568-4913-A698-157B61F4494F@comcast.net>
References: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
	<80D8C92F-9568-4913-A698-157B61F4494F@comcast.net>
Message-ID: <6D505895-E25C-4E8B-A826-2755B6235C9B@u.washington.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140802/382fdee3/attachment.pl>

From gunter.berton at gene.com  Sat Aug  2 21:09:39 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 2 Aug 2014 12:09:39 -0700
Subject: [R] mutually exclusive events
In-Reply-To: <6D505895-E25C-4E8B-A826-2755B6235C9B@u.washington.edu>
References: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
	<80D8C92F-9568-4913-A698-157B61F4494F@comcast.net>
	<6D505895-E25C-4E8B-A826-2755B6235C9B@u.washington.edu>
Message-ID: <CACk-te2aSob4nhMS3R_W7LAK9JsaDd0AO4eJkiG1qHkEnU9cZg@mail.gmail.com>

Homework?

There is a no homework policy here.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Aug 2, 2014 at 11:47 AM, Don McKenzie <dmck at u.washington.edu> wrote:
> David?s answer assumes a more complicated objective, but obviously we are both unclear as to what you want.  Are you trying to find out which clusters have a unique pattern of mutation? (probably all of them, with so few clusters and so many genes?)
>
> For either objective, this is not a statistical test, but a problem of identification.  For the simpler question, create a data frame with each row being the 150 1s and 0s associated with each cluster, and use duplicated() to identify unique rows. (unique rows will return ?FALSE?)
>
> Untested
>
> On Aug 2, 2014, at 11:41 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>> On Aug 2, 2014, at 11:11 AM, Adrian Johnson wrote:
>>
>>> Hi:
>>>
>>> I am trying to identify mutually exclusive events from the following
>>> example:
>>>
>> #-------------
>> dat <- read.table(text="Cluster      Gene      Mutated    not_mutated
>>  1             G1             1              0
>>  1             G2             1              0
>>  1             G3             0              1
>>  1             G4             0              1
>>  1             G5             1              0
>>  2             G1             0              1
>>  2             G2             1              0
>>  2             G3             1              0
>>  2             G4             0              0
>>  2             G5             1              0", header=TRUE, stringsAsFactors=FALSE)
>>
>> with(dat, table(Cluster, Gene, Mutated)  )
>> #----------------
>> , , Mutated = 0
>>
>>       Gene
>> Cluster G1 G2 G3 G4 G5
>>      1  0  0  1  1  0
>>      2  1  0  0  1  0
>>
>> , , Mutated = 1
>>
>>       Gene
>> Cluster G1 G2 G3 G4 G5
>>      1  1  1  0  0  1
>>      2  0  1  1  0  1
>> #--------------
>> Or:
>> xtabs(Mutated ~ Cluster+Gene, data=dat)
>> #----------------
>>       Gene
>> Cluster G1 G2 G3 G4 G5
>>      1  1  1  0  0  1
>>      2  0  1  1  0  1
>>
>>
>> I'm a bit unclear about your goals. Are you trying to identify the "Gene"s that have only one "Cluster" mutated as the "G1-G3" events and the Gene's that have either-Cluster but not both as the "G2-G5" events?
>>
>> If so you can choose the columns that have a sum of 2 for the first and columns with sum of 1 for the second.
>>>
>>>
>>> In cluster 1 :  G1, G2, G5 are mutated
>>>
>>> In cluster 2:    G2, G3, G5 are mutated.
>>>
>>>
>>> I am interested in finding such G2-G5 event and G1-G3 events.
>>>
>>> In total I have a 8 clusters and 150 gene (1200 rows x 4 columns).
>>>
>>> What test could be appropriate to identify such pairs.
>>>
>>> In my naive understanding would a fishers-exact test give such
>>> combinations.
>>
>> It's even less clear what sort of "test" you propose. `fisher.test` is a test of association. It doesn't identify combinations.
>>>
>>> Thanks a lot.
>>>
>>> -Adrian
>>>
>>>      [[alternative HTML version deleted]]
>>
>> This is a plain text mailing list.
>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.archie.mckown at gmail.com  Sat Aug  2 22:19:43 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 2 Aug 2014 15:19:43 -0500
Subject: [R] mutually exclusive events
In-Reply-To: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
References: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
Message-ID: <CAAJSdji_iVZhqjdkpYztjZs=MyCq+envga0mJvnGn82uF0hhWQ@mail.gmail.com>

On Sat, Aug 2, 2014 at 1:11 PM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hi:
>
> I am trying to identify mutually exclusive events from the following
> example:
>
>
> Cluster      Gene      Mutated    not-mutated
>   1             G1             1              0
>   1             G2             1              0
>   1             G3             0              1
>   1             G4             0              1
>   1             G5             1              0
>   2             G1             0              1
>   2             G2             1              0
>   2             G3             1              0
>   2             G4             0              0
>   2             G5             1              0
>
>
> In cluster 1 :  G1, G2, G5 are mutated
>
> In cluster 2:    G2, G3, G5 are mutated.
>
>
> I am interested in finding such G2-G5 event and G1-G3 events.
>
> In total I have a 8 clusters and 150 gene (1200 rows x 4 columns).
>
> What test could be appropriate to identify such pairs.
>
> In my naive understanding would a fishers-exact test give such
> combinations.
>
> Thanks a lot.
>
> -Adrian

I am having trouble visualizing your data. How about a sample? The
easy is to do something like:

temp <- head(realData,10);
dput(temp);

Then cut'n'paste the output from the dput() into another email here.

But, asuming I have a bit of a grasp, you have four columns (example
only shows 3). If you have a set of columns which are 0 & 1 or FALSE
and TRUE, then you can create a "temp" column which encodes tehm
simply by considering them to be binary digits in a number. I.e.
tempColumn = 1 * column1 + 2 * column2 + 4*column3 + 8*column4. You
can the "group" the data by this value. All rows with the same value
are in the same "group". But I don't know what you want your output to
look like. As an aside any value other than 0, 1, 2,4, or 8 could be
considered invalid because it means that more than one column is TRUE,
which violates your constraint.


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From john.archie.mckown at gmail.com  Sat Aug  2 22:21:13 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 2 Aug 2014 15:21:13 -0500
Subject: [R] mutually exclusive events
In-Reply-To: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
References: <CAL2fYnOSVEQRCwk7cS0R6QU0OxO_sE34LW0=sMC0ZqvOf_CW7g@mail.gmail.com>
Message-ID: <CAAJSdjg1itT4-UU_ovWboRTkKQnYZt0359WnGoX_1NyvTwL2cA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140802/b4ea85f2/attachment.pl>

From emammendes at gmail.com  Sun Aug  3 02:58:29 2014
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Sat, 2 Aug 2014 21:58:29 -0300
Subject: [R] How to remove latex message from a resulting rmarkdown pdf?
Message-ID: <3E424E49-01BB-4534-8873-EF322FBD9C2D@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140802/224b8c36/attachment.pl>

From zilefacelvis at yahoo.com  Sun Aug  3 07:17:46 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sat, 2 Aug 2014 22:17:46 -0700
Subject: [R] Extract particular months from List in R
Message-ID: <1407043066.46069.YahooMailNeo@web160603.mail.bf1.yahoo.com>

Hi ALL,
I have a List object in R. The dataframes in the List have equal rows and columns.
How can I extract from the List, data corresponding to say c(June, July , August)?
Remember, it is a List object, containing 100 dataframes, with daily data arranged by YYMMDD.
Thanks for your thoughtful solutions.
AT.?


From ligges at statistik.tu-dortmund.de  Sun Aug  3 09:44:05 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 03 Aug 2014 09:44:05 +0200
Subject: [R] How to remove latex message from a resulting rmarkdown pdf?
In-Reply-To: <3E424E49-01BB-4534-8873-EF322FBD9C2D@gmail.com>
References: <3E424E49-01BB-4534-8873-EF322FBD9C2D@gmail.com>
Message-ID: <53DDE845.1090005@statistik.tu-dortmund.de>



On 03.08.2014 02:58, Eduardo M. A. M.Mendes wrote:
> Hello
>
> I am using rmarkdown to write the partial results of my research project.  Both html and pdf files are used. In the resulting pdf xtable writes the following msg:
>
> % latex table generated in R 3.1.1 by xtable 1.7-3 package % Sat Aug 2 21:42:16 2014
>
>
> How can I remove such a msg?

Read ?print.xtable, there is some argument (comment?) to switch it off.


Best,
Uwe Ligges


> Many thanks
>
> Ed
>
>
> Below you will find the info on my system and a rmakrdown example to reproduce the msg.
>
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
>
> loaded via a namespace (and not attached):
>   [1] cluster_1.15.2
>   [2] colorspace_1.2-4
>   [3] digest_0.6.4
>   [4] evaluate_0.5.5
>   [5] formatR_0.10
>   [6] gtable_0.1.2
>   [7] htmltools_0.2.4
>   [8] knitr_1.6
>   [9] labeling_0.2
> [10] latticeExtra_0.6-26
> [11] MASS_7.3-33
> [12] munsell_0.4.2
> [13] plyr_1.8.1
> [14] proto_0.3-10
> [15] RColorBrewer_1.0-5
> [16] Rcpp_0.11.2
> [17] reshape2_1.4
> [18] rmarkdown_0.2.53
> [19] scales_0.2.4
> [20] stringr_0.6.2
> [21] tools_3.1.1
> [22] yaml_2.1.13
>
> RStudio - Version 0.98.987
>
> and ExampleA.Rmd
>
> ---
> title: "Example - Latex message on the resulting pdf"
> output: pdf_document
> ---
>
> ```{r r princ, echo=FALSE, warning=FALSE, results='asis', message=FALSE}
> library(xtable,quietly = TRUE,warn.conflicts = FALSE, verbose = FALSE)
> exampleAinfo=data.frame(matrix(runif(84),21,4))
> names(exampleAinfo)=c("Column 1","Column 2","Column 3","Column 4")
> ```
>
>
> # Example
>
> ```{r exampleA, results='asis', echo=FALSE, tidy=FALSE}
> exampleAinfo.table <- xtable(exampleAinfo, caption="Example A", digits=6)
> print(exampleAinfo.table, include.rownames = FALSE, floating=FALSE)
> ```
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sun Aug  3 09:47:36 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 03 Aug 2014 09:47:36 +0200
Subject: [R] Extract particular months from List in R
In-Reply-To: <1407043066.46069.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1407043066.46069.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <53DDE918.1090000@statistik.tu-dortmund.de>



On 03.08.2014 07:17, Zilefac Elvis wrote:
> Hi ALL,
> I have a List object in R. The dataframes in the List have equal rows and columns.
> How can I extract from the List, data corresponding to say c(June, July , August)?
> Remember, it is a List object, containing 100 dataframes, with daily data arranged by YYMMDD.
> Thanks for your thoughtful solutions.

An example would be helpful.
Is the date column a Date, some POSIX.. object, or just a string or 
numeric value?

In principle:
write a function that extracts data for these months from one data.frame 
and then lapply() it to the list.
Given you had provided a small example, we could have given you some 
more specific answer.

Best,
Uwe Ligges




> AT.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From charles.santana at gmail.com  Sun Aug  3 10:59:56 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Sun, 3 Aug 2014 10:59:56 +0200
Subject: [R] How to overlay contourplot of a dataset A and a levelplot
 of a dataset B?
In-Reply-To: <CAH-FEnhQLUPmJd3jMVKQuHsN_qkeUkD=pR36FM3Msa5A4eFZ2w@mail.gmail.com>
References: <CAH-FEnhQLUPmJd3jMVKQuHsN_qkeUkD=pR36FM3Msa5A4eFZ2w@mail.gmail.com>
Message-ID: <CAH-FEnhLr=Rf6WcOdmUqk-gmbisffedDPxhS5mTyDJfC=zNTAw@mail.gmail.com>

Um texto embutido e sem conjunto de caracteres especificado foi limpo...
Nome: n?o dispon?vel
Url: <https://stat.ethz.ch/pipermail/r-help/attachments/20140803/2e222476/attachment.pl>

From emammendes at gmail.com  Sun Aug  3 13:42:47 2014
From: emammendes at gmail.com (Eduardo M. A. M.Mendes)
Date: Sun, 3 Aug 2014 08:42:47 -0300
Subject: [R] How to remove latex message from a resulting rmarkdown pdf?
In-Reply-To: <53DDE845.1090005@statistik.tu-dortmund.de>
References: <3E424E49-01BB-4534-8873-EF322FBD9C2D@gmail.com>
	<53DDE845.1090005@statistik.tu-dortmund.de>
Message-ID: <E43F646F-D26C-4EFD-9B84-418BA9724F7A@gmail.com>

Many thanks.  I was checking print options instead of print.xtable.

Ed


On Aug 3, 2014, at 4:44 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

> 
> 
> On 03.08.2014 02:58, Eduardo M. A. M.Mendes wrote:
>> Hello
>> 
>> I am using rmarkdown to write the partial results of my research project.  Both html and pdf files are used. In the resulting pdf xtable writes the following msg:
>> 
>> % latex table generated in R 3.1.1 by xtable 1.7-3 package % Sat Aug 2 21:42:16 2014
>> 
>> 
>> How can I remove such a msg?
> 
> Read ?print.xtable, there is some argument (comment?) to switch it off.
> 
> 
> Best,
> Uwe Ligges
> 
> 
>> Many thanks
>> 
>> Ed
>> 
>> 
>> Below you will find the info on my system and a rmakrdown example to reproduce the msg.
>> 
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> 
>> loaded via a namespace (and not attached):
>>  [1] cluster_1.15.2
>>  [2] colorspace_1.2-4
>>  [3] digest_0.6.4
>>  [4] evaluate_0.5.5
>>  [5] formatR_0.10
>>  [6] gtable_0.1.2
>>  [7] htmltools_0.2.4
>>  [8] knitr_1.6
>>  [9] labeling_0.2
>> [10] latticeExtra_0.6-26
>> [11] MASS_7.3-33
>> [12] munsell_0.4.2
>> [13] plyr_1.8.1
>> [14] proto_0.3-10
>> [15] RColorBrewer_1.0-5
>> [16] Rcpp_0.11.2
>> [17] reshape2_1.4
>> [18] rmarkdown_0.2.53
>> [19] scales_0.2.4
>> [20] stringr_0.6.2
>> [21] tools_3.1.1
>> [22] yaml_2.1.13
>> 
>> RStudio - Version 0.98.987
>> 
>> and ExampleA.Rmd
>> 
>> ---
>> title: "Example - Latex message on the resulting pdf"
>> output: pdf_document
>> ---
>> 
>> ```{r r princ, echo=FALSE, warning=FALSE, results='asis', message=FALSE}
>> library(xtable,quietly = TRUE,warn.conflicts = FALSE, verbose = FALSE)
>> exampleAinfo=data.frame(matrix(runif(84),21,4))
>> names(exampleAinfo)=c("Column 1","Column 2","Column 3","Column 4")
>> ```
>> 
>> 
>> # Example
>> 
>> ```{r exampleA, results='asis', echo=FALSE, tidy=FALSE}
>> exampleAinfo.table <- xtable(exampleAinfo, caption="Example A", digits=6)
>> print(exampleAinfo.table, include.rownames = FALSE, floating=FALSE)
>> ```
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 


From wickedpuppy at gmail.com  Sun Aug  3 15:57:35 2014
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 3 Aug 2014 21:57:35 +0800
Subject: [R] Rmarkdown Installation error on Shiny server , CentOS 6.4 x64
Message-ID: <CAJ_FNV518VJVofJDfyeGDq-jYZntVvd=B54ub_p1DfDc2N=o1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140803/c7788fc4/attachment.pl>

From dulcalma at bigpond.com  Sun Aug  3 16:43:06 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 4 Aug 2014 00:43:06 +1000
Subject: [R] lattice,
	latticeExtra: Adding moving averages to double y plot
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD3AF47@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD38DC4@ebox-prod-srv04.win.su.se>,
	<000601cfaabd$f568f130$e03ad390$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD39CFE@ebox-prod-srv04.win.su.se>,
	<001201cfac76$57905970$06b10c50$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD3A3B7@ebox-prod-srv04.win.su.se>
	, <000001cfad42$64992a80$2dcb7f80$@bigpond.com>
	<11019DCE9B47004F90B2D9C62FF157921BD3AF47@ebox-prod-srv04.win.su.se>
Message-ID: <001201cfaf29$3dade440$b909acc0$@bigpond.com>

Hi Anna

I got down to 

plot2_3_concentration <-
xyplot(Value ~ Year, datamystuff23, groups = Type, ...

and got an error:
Error in eval(substitute(groups), data, environment(x)) : 
  object 'datamystuff23' not found

so I did not pursue further

Note : from ?doubleYScale
Note that most settings, like main/sub/legend/etc are taken only from obj1;
only the panel, axis and ylab are taken from obj2.

As we are now working with 2 plots you can reduce the complexity of your
plots and you may get away without having to use a panel function.
Try without a panel function and then a panel function. You may then get
away with a panel.xyplot in the panel without having to resort to
panel.groups.

Settings for the key are those found in the trellis.par.get()$superpose. ...
series ie. trellis.par.get()$superpose.line,
trellis.par.get()$superpose.symbol etc
You can setup par.settings adding 
superpose.symbol = list(...),
superpose.line = list( ...)
 
or what I have done

        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        col = c(1:3) # for points
         )

and modify accordingly. I usually find it is easier to have a custom key as
I have to make changes to various parts of the key and it is easier to add
on things there.

Duncan

-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se] 
Sent: Sunday, 3 August 2014 15:10
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan,

I think you have misunderstood my plot. I am able to change lty the way you
have plotted it with points on one axis and moving averages on the other. if
you run the code below, you find the plot that I need to do. data points and
moving averages for factor 1 on one yaxis (temperature) and factor 2 and 3
(data points and moving averages on the second y-axis: summer and winter
concentrations of compound X). See the plot below to better see what I mean.

1. My problem is to change lty for the axis where I have temperature. I
somehow need to specify that lty is depending on factor, which I am not able
to do. I have marked the position in plot2_3 where I have a problem. 

2. The second issue is the symbols (pch). I have managed to change these in
the plot, but cannot make them appear in the legend. How would I go about
this? See comments in script. 

Below is the full script with a correct plot with the issues at hand
labelled.

many thank's for your time!
Anna

############################################################################
#####
############################
mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

# stuff1 is temperature
# stuff 2 and stuff 3 are concentration measurements of compound X

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# combine averages into mydata
mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3],
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

table(mydata$Type)

# split stuff1 from stuff2/3 as they will read off different y-axes
stuff1mavg_points <- mydata[(mydata$Type) %in% c("stuff1"), ] #temperature
stuff23mavg_points <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ] #
concentration

# plot stuff2/3 with data points and moving averages reading off y-axis 1:

plot2_3_concentration <- xyplot(Value ~ Year, datamystuff23, groups = Type,
                  allow.multiple = T,
                  distribute.type = TRUE,
                  par.settings = list(layout.heights = list(key.top = 1.5)),
                  col = "black", pch=c(2,15), 
                  ylab="concentration",
                  subscripts = TRUE,
                  panel = panel.superpose,
                  panel.groups = function(x, y, subscripts,
...,group.number) {
                    panel.xyplot(x, y, ...)
                    panel.xyplot(x, datamystuff23[subscripts,"mavg"], type =
"l", col="black",
                                 lty = c(1:2))  # HERE IS THE PROBLEM!
LTY!!!
                  })
plot2_3_concentration 

# If I  use l lty = c(1:2)[group.number], I get only one line!


# plot stuff 1: with data points and moving averages reading off y-axis 2
plot1_temperature<- xyplot(Value ~ Year, datamystuff1, groups = Type,
               allow.multiple = T,
               distribute.type = TRUE,
               par.settings = list(layout.heights = list(key.top = 1.5)),
               col = "black", pch=4,
               subscripts = TRUE,
               ylab="temperature",
               panel = panel.superpose,
               panel.groups = function(x, y, subscripts, ...,group.number) {
                 panel.xyplot(x, y, ...)
                 panel.xyplot(x, mydata[subscripts,"mavg"], col =
                                c(1:3)[group.number], type = "l", lty=3) #
HERE I AM ABLE TO MODIFY LTY
               })
plot1_temperature


doubleYScale(plot2_3_concentration, plot1_temperature, style1 = 0, style2=0,
add.ylab2 = TRUE,
             text = c("winter concentration cpd X", "summer concentration
cpd X",
                      "temperature"), lty=c(1:3), columns = 2, 
             col=c("black", "black", "black")) # HERE TWO LINES ARE FULLY
DRAWN!

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3), 
                                  pch=c(2,4,15))) # WHY CAN I NOT SEE PCH IN
THE LEGEND?

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 01 August 2014 06:38
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Anna

I forgot you had problems with lty
I have cleaned up the yright and put lty in

yright <-
 xyplot(mavg ~ Year, mydata, groups = Type,
        type = "l",
        ylab = "mean",
        lty = 1:3,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c(1:3) )

I did not change for what you wanted on the right as far as labels etc is
concerned

Duncan

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com]
Sent: Friday, 1 August 2014 12:03
To: R; 'Anna Zakrisson Braeunlich'
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Anna

I have gone back to doubleYScale because I started following the wrong
section that I had before so it was quicker to do doubleYScale
You need to have 2 lattice objects and components are taken from each  below
so use the function str on the three objects to see

library(lattice)
library(latticeExtra)

yleft <-
 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        col = c(1:3) # for points
         )

 yright <-
 xyplot(mavg ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        type = "l",
        ylab = "mean",
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c(1:3) )

# colours both y axes so change with next command
yboth <-
doubleYScale(yleft, yright, add.ylab2 = TRUE)
yboth

# change y axes col to suit
update(trellis.last.object(),             # left   # right
       par.settings = simpleTheme(col = c("black", "cyan")))

Duncan


-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se]
Sent: Friday, 1 August 2014 03:11
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan,

Now I have found a solution to my problem. It is complete except for one
tiny detail: I am unable to define different line types for stuff2 and
stuff3 moving averages (see plot2_3).

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# combine averages into mydata
mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

table(mydata$Type)

# split stuff1 from stuff2/3
datamystuff1 <- mydata[(mydata$Type) %in% c("stuff1"), ]
datamystuff23 <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]

table(datamystuff23$Type)
xyplot(Value ~ Year, datamystuff23, groups=Type)
xyplot(mavg ~ Year, datamystuff23, groups=Type)

# plot stuff2/3:
plot2_3 <- xyplot(Value ~ Year, datamystuff23, groups = Type,
                  allow.multiple = T,
                  distribute.type = TRUE,
                  par.settings = list(layout.heights = list(key.top = 1.5)),
                  col = "black", pch=c(2:3),
                  ylab="concentration",
                  subscripts = TRUE,
                  panel = panel.superpose,
                  panel.groups = function(x, y, subscripts,
...,group.number) {
                    panel.xyplot(x, y, ...)
                    panel.xyplot(x, datamystuff23[subscripts,"mavg"], col =
                                   "black", type = "l", lty=c(1:2))  ### Why
can I not define different lty?
                  })
plot2_3 # plot is incorrect!

plot1<- xyplot(Value ~ Year, datamystuff1, groups = Type,
               allow.multiple = T,
               distribute.type = TRUE,
               par.settings = list(layout.heights = list(key.top = 1.5)),
               col = "black", pch=c(2:3),
               subscripts = TRUE,
               ylab="temperature",
               panel = panel.superpose,
               panel.groups = function(x, y, subscripts, ...,group.number) {
                 panel.xyplot(x, y, ...)
                 panel.xyplot(x, mydata[subscripts,"mavg"], col =
                                c(1:3)[group.number], type = "l", lty=3)
               })
plot1 # this plot looks correct!


doubleYScale(plot2_3, plot1, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("nitrogen", "winter temperature", "summer
tempareture"), lty=c(1:3),columns = 2,
             col=c("black", "black", "black"))

update(trellis.last.object(),
                    par.settings = simpleTheme(col = c("black", "black"),
lty=c(1:3),
                                               pch=c(1:3)))




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 31 July 2014 06:17
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Anna

I am still unsure what you want

1 do you want 1 panel or 3?
2 do you want 1 y axis on the left and 1 on the right
or 1 y axis on the left and 2 on the right
                                         or 1 on the right varying with
groups in a multipanel plot

For starters try

xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        col = c("black","black","black"), # for points
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

OR

  xyplot(Value ~ Year|Type, mydata,
        allow.multiple = T,
        aspect = 0.75,
        layout = c(1,3),
        groups = Type,
        distribute.type = TRUE,
        par.settings = list(layout.heights = list(key.top = 1.5)),  #
separate key from bottom a bit more
        scales = list(alternating = F),
        col = c("black","black","black"),
        subscripts = TRUE,
        key = list(text = list(label = c("stuff1","stuff2","stuff3")),
                   lines = list(col = 1:3),
                   cex   = 0.8,
                   title = "stuff type",
                   cex.title = 0.9,
                   space = "bottom"),
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
          panel.xyplot(x, y, ...)
          panel.xyplot(x, mydata[subscripts,"mavg"], col =
c(1:3)[group.number], type = "l")
 })

have a look at

 ?lattice::axis.default
for yscale.components

This means that you only need 1 xyplot object

if you use doubleYScale you need to xyplot objects
1 for the points and another for the averages

These are then superimposed with the doubleYScale

Also read and re read ?xyplot
names(trellis.par.get()) give you a list of the names in trellis.par.get()
and trellis.par.get() gives you all the settings used by  argument
par.settings in xyplot and those in the lattice series
par.settings may help you with themes.

http://lmdvr.r-forge.r-project.org/figures/figures.html
may be instructive

Duncan

-----Original Message-----
From: Anna Zakrisson Braeunlich [mailto:anna.zakrisson at su.se]
Sent: Wednesday, 30 July 2014 23:59
To: Duncan Mackay
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

Hi Duncan and many thank's for your help!
I could see your first message perfectly.

You solved my problem to some extent. What my problem is, is that I need a
double y plot with two of these moving averages belonging to one axis (both
are temperature measurements, say Stuff 2 and 3, measured in degrees C) the
other one reading off the second axis (a nutrient measurement in mM (say
Stuff1)).

How can I plot Stuff2 and stuff3 moving averages in one plot and stuff1 in
another and then combine them using doubleYscale?

I also have some other annotated questions regarding linetypes. I could
change symbols using pch, but not the line type. Why? See code below:

Many many thank's once again.

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(lattice)
library(latticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff2_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff2_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}

mydata$mavg <-
  c(rep(NA,4), madfStuff1[,3], # what is rep(NA,4) doing?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T), # is "3"
referring to the number of factors?
    rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

xyplot(Value ~ Year, mydata, groups = Type,
       allow.multiple = T,
       distribute.type = TRUE,
       col = c("black","black","black"),
       subscripts = TRUE,
       par.settings = simpleTheme(lty=c(1:3), pch=c(1:3)), #why can I change
symbol (pch), but not line type (lty)?
       panel = panel.superpose,
       panel.groups = function(x, y, subscripts, ...,group.number) {
         panel.xyplot(x, y, ...)
         panel.xyplot(x, mydata[subscripts,"mavg"], col =
                        c("black","black","black")[group.number], type =
"l") # tried to change lty here too lty=c(1:3), but # without success
       })

# how can I add a legend specifying the linetype AS WELL AS symbol?
# I tried using:   text = c("stuff1", "stuff2", "stuff3"), columns = 2  but
could not make it work.




Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?.
.? `?. .><((((?>

________________________________________
From: Duncan Mackay [dulcalma at bigpond.com]
Sent: 29 July 2014 01:45
To: R; Anna Zakrisson Braeunlich
Subject: RE: [R] lattice, latticeExtra: Adding moving averages to double y
plot

I do not know what happened to my last email as this are set up as plain
text so I am sending the code again so I hope this works

I am not sure what you wanted exactly but this will plot the points and
lines of the average.

I have not worried about the 2nd axis

Here is one way of doing things  by combining the averages into the
dataframe.
It makes it easier that way as you do not have to match up the x values

# combine averages into mydata
 mydata$mavg <-
 c(rep(NA,4), madfStuff1[,3],
   rep(NA,4), subset(madfStuff2_3, Type== "stuff2",3, drop = T),
   rep(NA,4), subset(madfStuff2_3, Type== "stuff3",3, drop = T))

 xyplot(Value ~ Year, mydata, groups = Type,
        allow.multiple = T,
        distribute.type = TRUE,
        col = c("red","blue","cyan"),
         subscripts = TRUE,
        panel = panel.superpose,
        panel.groups = function(x, y, subscripts, ...,group.number) {
                  panel.xyplot(x, y, ...)
                   panel.xyplot(x, mydata[subscripts,"mavg"], col =
c("red","blue","cyan")[group.number], type = "l")
            })

Duncan

BTW libraries are case sensitive as well. Is it you editor putting capitals?

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Anna Zakrisson Braeunlich
Sent: Monday, 28 July 2014 16:38
To: r-help at r-project.org
Subject: [R] lattice, latticeExtra: Adding moving averages to double y plot

Hi lattice users,

I would like to add 5-year moving averages to my double y-plot. I have three
factors needs to be plotted with moving averages in the same plot. One of
these reads off y-axis 1 and two from y-axis 2. I have tried to use the
rollmean function from the zoo-packages, but I fail in insering this into
lattice (I am not an experienced lattice user). I want to keep the data
points in the plot.
Find below dummy data and the script as well as annotations further
describing my question.

thank you in advance!
Anna Zakrisson

mydata<- data.frame(
  Year = 1980:2009,
  Type = factor(rep(c("stuff1", "stuff2", "stuff3"), each = 10*3)),
  Value = rnorm(90, mean = seq(90),
                sd = rep(c(6, 7, 3), each = 10)))

library(Lattice)
library(LatticeExtra)

stuff1data <- mydata[(mydata$Type) %in% c("stuff1"), ]
stuff12_3data <- mydata[(mydata$Type) %in% c("stuff2", "stuff3"), ]


# make moving averages function using zoo and rollmean:
library(zoo)
library(plyr)

f <- function(d)
{
  require(zoo)
  data.frame(Year = d$Year[5:length(d$Year)],
             mavg = rollmean(d$Value, 5))
}

# Apply the function to each group as well as both data frames:
madfStuff1 <- ddply(stuff1data, "Type", f)
madfStuff2_3 <- ddply(stuff12_3data, "Type", f)

# Some styles:
myStripStyle <- function(which.panel, factor.levels, ...) {
  panel.rect(0, 0, 1, 1,
             col = bgColors[which.panel],
             border = 1)
  panel.text(x = 0.5, y = 0.5,
             font=2,
             lab = factor.levels[which.panel],
             col = txtColors[which.panel])
}


myplot1 <- xyplot(Value ~ Year, data = stuff1data, col="black",
                   lty=1, pch=1,
                   ylab = "sweets", strip.left = F,
                   strip=myStripStyle,
                   xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = 1,col = "black")
                    panel.lmline(x,y,col = "black", data=madfStuff1) # here
I presume that panel.lmline is wrong.
                    # I would like to have my 5 year moving average here,
not a straight line.
                  })
myplot1


myplot2 <- xyplot(Value ~ Year, data = stuff12_3data, col="black",
                  lty=1, pch=1,
                  ylab = "hours", strip.left = F,
                  strip=myStripStyle,
                  xlab = ("Year"),
                  panel = function(x,y,...,subscripts){
                    panel.xyplot(x, y, pch = c(2:3),col = "black") ## what
is this "pch" defining? Types?
                    #I would like to have different symbols and line types
for stuff2 and stuff3
                    panel.lmline(x,y,col = "black", data=madfStuff2_3) #
wrong! Need my moving averages here!
                  })
myplot2

doubleYScale(myplot1, myplot2, style1 = 0, style2=0, add.ylab2 = TRUE,
             text = c("stuff1", "stuff2", "stuff3"), columns = 2,
col="black")

# problem here is that I end up with two lines. I need a double y-plot with
one moving average plots that are read off y-axis 1
# and two that reads off y-axis 2. I need to keep the data points in the
plot.

update(trellis.last.object(),
       par.settings = simpleTheme(col = c("black", "black"), lty=c(1:3),
pch=c(1:3))) # how come that I only get
# lines in my legend text and not the symbols too. I thought "pch" would add
symbols?!?


Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((:>`?. . ? `?. .? `?. . ><((((:>`?. . ? `?. .? `?. .><((((:>`?. . ? `?.
.? `?. .><((((:>

        [[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Aug  3 18:30:15 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 03 Aug 2014 09:30:15 -0700
Subject: [R] Rmarkdown Installation error on Shiny server ,
	CentOS 6.4 x64
In-Reply-To: <CAJ_FNV518VJVofJDfyeGDq-jYZntVvd=B54ub_p1DfDc2N=o1w@mail.gmail.com>
References: <CAJ_FNV518VJVofJDfyeGDq-jYZntVvd=B54ub_p1DfDc2N=o1w@mail.gmail.com>
Message-ID: <b19fc5da-51d2-4607-94bd-2b9dba2e80d3@email.android.com>

When working on the bleeding edge (which github usually implies) it can be crucial to stay up to date. You might try updating R (your example seems to be working for me on R3.1.1 on Ubuntu 14.04). You should also cc the maintainer of contributed packages (?maintainer). Finally, you should read the Posting Guide, which points out that this is a plain text mailing list (HTML is not a what-you-see-is-what-we-see format).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 3, 2014 6:57:35 AM PDT, billy am <wickedpuppy at gmail.com> wrote:
>Hi ,
>
>I am having difficulty installation rmarkdown on the centos shiny
>server.
>Can anyone help? Thanks!
>
>> devtools::install_github("rstudio/rmarkdown")
>Installing github repo rmarkdown/master from rstudio
>Downloading master.zip from
>https://github.com/rstudio/rmarkdown/archive/master.
>zip
>Installing package from /tmp/Rtmp5i4HDt/master.zip
>arguments 'minimized' and 'invisible' are for Windows only
>Error: Does not appear to be an R package (no DESCRIPTION)
>
>> version
>               _
>platform       x86_64-redhat-linux-gnu
>arch           x86_64
>os             linux-gnu
>system         x86_64, linux-gnu
>status
>major          3
>minor          1.0
>year           2014
>month          04
>day            10
>svn rev        65387
>language       R
>version.string R version 3.1.0 (2014-04-10)
>nickname       Spring Dance
>
>
>Regards
>Billy
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From diregola at gmail.com  Sun Aug  3 18:33:57 2014
From: diregola at gmail.com (Margherita Di Leo)
Date: Sun, 3 Aug 2014 18:33:57 +0200
Subject: [R] Reading specific rows and columns xlsx file: Error in
 strsplit(names(res), "\\.") : non-character argument
Message-ID: <CABa=8Qq0NpfULyaut3C4_1K9v5s7WaguqwAWMs3UfXArdF6bkQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140803/4268c954/attachment.pl>

From diregola at gmail.com  Sun Aug  3 19:37:34 2014
From: diregola at gmail.com (Margherita Di Leo)
Date: Sun, 3 Aug 2014 19:37:34 +0200
Subject: [R] Reading specific rows and columns xlsx file: Error in
 strsplit(names(res), "\\.") : non-character argument
In-Reply-To: <CABa=8Qq0NpfULyaut3C4_1K9v5s7WaguqwAWMs3UfXArdF6bkQ@mail.gmail.com>
References: <CABa=8Qq0NpfULyaut3C4_1K9v5s7WaguqwAWMs3UfXArdF6bkQ@mail.gmail.com>
Message-ID: <CABa=8Qr9naf8=AdKukCW9M0NmtVqDMhMwDOkY7oY-ZDC83OS-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140803/9a84dfe2/attachment.pl>

From zilefacelvis at yahoo.com  Sun Aug  3 21:23:51 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 3 Aug 2014 12:23:51 -0700
Subject: [R] Extract particular months from List in R
In-Reply-To: <53DDE918.1090000@statistik.tu-dortmund.de>
References: <1407043066.46069.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<53DDE918.1090000@statistik.tu-dortmund.de>
Message-ID: <1407093831.73033.YahooMailNeo@web160602.mail.bf1.yahoo.com>

Hi Uwe,
Thanks for replying.
Here is a reproducible example.?
I would like to extract data for the Months of c(6,7,8).?
Output files should have the same number of columns as input files.

Thanks.
-------------------------------------------------------------------------------

list(structure(list(Year = c(2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), Day = c(1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L 
), Site = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = "G101", class = "factor"), 
? ? Tmax = c(-18.4, -11.3, -4.4, 1.1, 1.1, -2.8, -7.9, -11.8, 
? ? -4.2, -4.1, -11.1, -8.9, -6.7, -7.3, -12.2, -14, -1.9, -7.4, 
? ? -14.3, -11.1, -8.4, -0.5, -5.1, -15.5, -6.9, -7.2, -4.2, 
? ? -3.2, -5.8, -5.8, -4.2, -21.8, -14, -8.5, -5.7, -3.1, -7.1, 
? ? -16.2, -17.1, -21.2, -24, -13.9, -13.1, -14.2, -17.1, -12.2, 
? ? -18.6, -12.6, -9.4, -13.3, -17, -13.9, -10.4, -11.8, -7.4, 
? ? -10.5, -16.5, -14.2, -3.7, 2.8, 3.3, -1.5, -3.5, -4.7, -0.9, 
? ? -1.7, -0.5, -1.3, -1.4, -5, -0.9, 3, -0.1, -3.3, 2, 2.9, 
? ? 2.8, 1.1, 4.4, -0.8, -8.8, -9.8, -11.6, -9.8, -6.1, 2.6, 
? ? 5.3, 3, 5.1, 0.7, 1.4, 3.2, 7, 6.7, 8.3, 11.9, 5.8, 8, 6.6, 
? ? 7.2, 10.7, 10.1, 2.5, 9, -4.2, 2.7, 6.8, 13.3, 17.4, 15.2, 
? ? 2.3, 6.7, 12.4, 17.4, 26, 16.1, 18.9, 26.6, 28.3, 24.5, 15, 
? ? 16, 16.8, 22.1, 21.4, 16.9, 9.6, 15.5, 20.3, 13.1, 16, 21.8, 
? ? 25.8, 25.2, 21.6, 25.2, 22.8, 25.5, 21.9, 18.2, 10.7, 8.2, 
? ? 8.6, 16.3, 20.9, 24.7, 21.2, 20.2, 21.9, 20.8, 23.6, 18.4, 
? ? 17.5, 19.8, 22.5, 21.5, 19.8, 23.2, 26.3, 29, 28.9, 25.6, 
? ? 22.5, 18, 16.2, 15.8, 16.3, 20.9, 18.2, 19.2, 20.6, 24, 24.7, 
? ? 30.1, 29.9, 27.1, 22.6, 19, 27.9, 27.3, 17, 19.6, 23.3, 24.5, 
? ? 20.7, 24.1, 26.3, 29, 30.7, 29.1, 24.3, 26.1, 28.1, 29.5, 
? ? 27.1, 28.1, 24.3, 28.1, 30.4, 30.5, 30.3, 30.7, 29.3, 23.3, 
? ? 24.6, 25.8, 23.6, 20.3, 25.8, 24.7, 30, 24.7, 24.1, 26.6, 
? ? 31.4, 33.1, 31, 30.8, 30.3, 28.9, 19.8, 23.6, 25.1, 19.8, 
? ? 24.6, 25.1, 21.3, 25.3, 24.1, 19.4, 24.8, 28.4, 29.1, 27, 
? ? 28.1, 29.3, 27, 27.1, 26.2, 28.3, 25.2, 19.5, 20.4)), .Names = c("Year", 
"Month", "Day", "Site", "Tmax"), class = "data.frame", row.names = c(NA, 
-243L)), structure(list(Year = c(2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 2001L, 
2001L, 2001L, 2001L, 2001L, 2001L), Month = c(1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L), 
? ? Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
? ? 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
? ? 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
? ? 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
? ? 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 
? ? 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
? ? 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
? ? 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
? ? 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
? ? 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 
? ? 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
? ? 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
? ? 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
? ? 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
? ? 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
? ? 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
? ? 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
? ? 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
? ? 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
? ? 27L, 28L, 29L, 30L, 31L), Site = structure(c(1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
? ? 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L 
? ? ), .Label = "G102", class = "factor"), Tmax = c(-15, -7.5, 
? ? -4.5, 2, -8.5, -9, -9, -10, -1.5, -3, -10.5, -5.5, -8, -13, 
? ? -13, -9, -1.5, -16, -12, -5.5, -8, 0, -5, -12, -6, -7.5, 
? ? -4.5, -3, -4.5, -6, -16.5, -20, -12, -9, -5.5, -2.5, -13, 
? ? -16.5, -15.5, -20, -22, -17, -11.5, -12.5, -14, -11.5, -18.5, 
? ? -13, -8.5, -8.5, -21.5, -14, -12, -12.5, -7, -14, -17, -12, 
? ? -5, 4, 4, -2, -3.5, -1.5, -1, -1.5, 0, -1.5, -9.5, -4, -2.5, 
? ? 3.5, 0, -3.5, 3.5, 4, 2.5, 4, 5, -12, -8.5, -12.5, -10.5, 
? ? -8.5, -4.5, 1.5, 2, 3.5, 4.5, 3, 3.5, 5.5, 8.5, 4, 6, 7.5, 
? ? 8, 7.5, 7, 5, 10.5, 8, 1, 5, -4, 1.5, 7, 13.5, 16.5, 12, 
? ? 0, 6.5, 13, 17, 23.5, 13, 16, 25.5, 26.5, 23, 13, 11.5, 12, 
? ? 21, 21, 12.5, 9, 14, 19, 12, 16.5, 19, 22.5, 27, 21, 23, 
? ? 22.5, 25, 21, 16.5, 10.5, 7.5, 9.5, 17, 21.5, 26, 18.5, 18, 
? ? 19.5, 19.5, 21, 18.5, 18, 19, 21.5, 22, 20, 22.5, 24, 27.5, 
? ? 28, 25, 17.5, 16, 16.5, 14.5, 15, 18, 16, 19.5, 19, 24, 25.5, 
? ? 26.5, 27, 24, 21, 16.5, 22, 25.5, 15, 19, 22, 23.5, 19.5, 
? ? 21.5, 25.5, 27, 29.5, 28, 23.5, 25.5, 27, 26, 27, 27.5, 26, 
? ? 27.5, 29, 29, 29.5, 28.5, 29, 19.5, 24.5, 24.5, 21, 21, 26, 
? ? 25.5, 28, 22.5, 24, 27, 32.5, 34, 31, 31, 30, 27, 20.5, 24, 
? ? 25, 20.5, 25, 27, 22, 25.5, 22, 20, 24, 28.5, 28.5, 26, 27.5, 
? ? 29.5, 26, 27.5, 25.5, 27, 24.5, 18.5, 20)), .Names = c("Year", 
"Month", "Day", "Site", "Tmax"), class = "data.frame", row.names = c(NA, 
-243L)))

------------------------------------------------------------------------------------------------------

On Sunday, August 3, 2014 1:47 AM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:


On 03.08.2014 07:17, Zilefac Elvis wrote:
> Hi ALL,
> I have a List object in R. The dataframes in the List have equal rows and columns.
> How can I extract from the List, data corresponding to say c(June, July , August)?
> Remember, it is a List object, containing 100 dataframes, with daily data arranged by YYMMDD.
> Thanks for your thoughtful solutions.

An example would be helpful.
Is the date column a Date, some POSIX.. object, or just a string or 
numeric value?

In principle:
write a function that extracts data for these months from one data.frame 
and then lapply() it to the list.
Given you had provided a small example, we could have given you some 
more specific answer.

Best,
Uwe Ligges







> AT.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

>



From spencer.graves at structuremonitoring.com  Sun Aug  3 21:38:10 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 03 Aug 2014 12:38:10 -0700
Subject: [R] qqnorm with histogram?
Message-ID: <53DE8FA2.1010206@structuremonitoring.com>

       Does a function exist that combines a normal probability plot 
with a histogram and maybe a density estimate on the same plot?


       I'm revising the Wikipedia article on "Normal probability plot", 
and I think it would be good to provide examples of this.


       Thanks,
       Spencer


p.s.  Please reply also with suggestions for how to improve that 
Wikipedia article if you feel so inclined.


From ligges at statistik.tu-dortmund.de  Sun Aug  3 22:12:21 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 03 Aug 2014 22:12:21 +0200
Subject: [R] Extract particular months from List in R
In-Reply-To: <1407093831.73033.YahooMailNeo@web160602.mail.bf1.yahoo.com>
References: <1407043066.46069.YahooMailNeo@web160603.mail.bf1.yahoo.com>	<53DDE918.1090000@statistik.tu-dortmund.de>
	<1407093831.73033.YahooMailNeo@web160602.mail.bf1.yahoo.com>
Message-ID: <53DE97A5.6050303@statistik.tu-dortmund.de>



On 03.08.2014 21:23, Zilefac Elvis wrote:
> Hi Uwe,
> Thanks for replying.
> Here is a reproducible example.
> I would like to extract data for the Months of c(6,7,8).
> Output files should have the same number of columns as input files.
>
> Thanks.

[SNIP]

If your data is in an object "dat", then:


lapply(dat, function(x) x[x[["Month"]] %in% 6:8,])

or in order to combine into one data.frame:

do.call("rbind", lapply(dat, function(x) x[x[["Month"]] %in% 6:8,]))

Best,
Uwe Ligges


From zilefacelvis at yahoo.com  Sun Aug  3 22:25:36 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 3 Aug 2014 13:25:36 -0700
Subject: [R] Extract particular months from List in R
In-Reply-To: <53DE97A5.6050303@statistik.tu-dortmund.de>
References: <1407043066.46069.YahooMailNeo@web160603.mail.bf1.yahoo.com>	<53DDE918.1090000@statistik.tu-dortmund.de>
	<1407093831.73033.YahooMailNeo@web160602.mail.bf1.yahoo.com>
	<53DE97A5.6050303@statistik.tu-dortmund.de>
Message-ID: <1407097536.91420.YahooMailNeo@web160602.mail.bf1.yahoo.com>

Great! Thanks very much Uwe.
AT.


On Sunday, August 3, 2014 2:12 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:


On 03.08.2014 21:23, Zilefac Elvis wrote:
> Hi Uwe,
> Thanks for replying.
> Here is a reproducible example.
> I would like to extract data for the Months of c(6,7,8).
> Output files should have the same number of columns as input files.
>
> Thanks.

[SNIP]

If your data is in an object "dat", then:


lapply(dat, function(x) x[x[["Month"]] %in% 6:8,])

or in order to combine into one data.frame:

do.call("rbind", lapply(dat, function(x) x[x[["Month"]] %in% 6:8,]))




Best,
Uwe Ligges


From jim at bitwrit.com.au  Sun Aug  3 23:59:51 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 04 Aug 2014 07:59:51 +1000
Subject: [R] qqnorm with histogram?
In-Reply-To: <53DE8FA2.1010206@structuremonitoring.com>
References: <53DE8FA2.1010206@structuremonitoring.com>
Message-ID: <2386244.Srmg3LNeA7@localhost.localdomain>

Hi Spencer,
The last example for the twoord.plot function (plotrix) does this.

Jim

On Sun, 3 Aug 2014 12:38:10 PM Spencer Graves wrote:
>        Does a function exist that combines a normal probability plot
> with a histogram and maybe a density estimate on the same plot?
> 
> 
>        I'm revising the Wikipedia article on "Normal probability plot",
> and I think it would be good to provide examples of this.
> 
> 
>        Thanks,
>        Spencer
> 
> 
> p.s.  Please reply also with suggestions for how to improve that
> Wikipedia article if you feel so inclined.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zilefacelvis at yahoo.com  Mon Aug  4 00:12:06 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 3 Aug 2014 15:12:06 -0700
Subject: [R] Convert some columns of List to dataframe R
Message-ID: <1407103926.20001.YahooMailNeo@web160601.mail.bf1.yahoo.com>

Dear All,
I have a List in R and would like to convert it to data.frame.
Below is a reproducible example. I can do something like:?

x1<-do.call(cbind.data.frame, lst3) #OR 
x1<-as.data.frame(lst3).

However, my output looks like this:

Year Site ?x ? Year Site  x 
2001 G101 33.1 2001 G102 34

I would like to have as my output:

Year ?G101 ? G102 
2001 ?33.1 ? 34


Thanks
Atem.
----------------------------------------------------------------------------------


?list(structure(list(Year = 2001L, Site = structure(1L, .Label = "G101", class = "factor"), 
? ? x = 33.1), .Names = c("Year", "Site", "x"), row.names = c(NA, 
-1L), class = "data.frame"), structure(list(Year = 2001L, Site = structure(1L, .Label = "G102", class = "factor"), 
? ? x = 34), .Names = c("Year", "Site", "x"), row.names = c(NA, 
-1L), class = "data.frame"))


From john.archie.mckown at gmail.com  Mon Aug  4 00:54:57 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 3 Aug 2014 17:54:57 -0500
Subject: [R] Convert some columns of List to dataframe R
In-Reply-To: <1407103926.20001.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1407103926.20001.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <CAAJSdjhENVh3d+LhiS_sLGawQ9ahu5G9EUAgUchp3azi-nxGWQ@mail.gmail.com>

On Sun, Aug 3, 2014 at 5:12 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> Dear All,
> I have a List in R and would like to convert it to data.frame.
> Below is a reproducible example. I can do something like:
>
> x1<-do.call(cbind.data.frame, lst3) #OR
> x1<-as.data.frame(lst3).
>
> However, my output looks like this:
>
> Year Site  x   Year Site  x
> 2001 G101 33.1 2001 G102 34
>
> I would like to have as my output:
>
> Year  G101   G102
> 2001  33.1   34
>
>
> Thanks
> Atem.
> ----------------------------------------------------------------------------------
>
>
>  list(structure(list(Year = 2001L, Site = structure(1L, .Label = "G101", class = "factor"),
>     x = 33.1), .Names = c("Year", "Site", "x"), row.names = c(NA,
> -1L), class = "data.frame"), structure(list(Year = 2001L, Site = structure(1L, .Label = "G102", class = "factor"),
>     x = 34), .Names = c("Year", "Site", "x"), row.names = c(NA,
> -1L), class = "data.frame"))
>


Try rbind_all in the dplyr package together with the dcast() function
in the reshpae2 package

output1 <- rbind_all(as.list(lst3));
realOutput <- dcast(output1, Year ~ Site, value.var="x");

Example transcript:

> lst3 <- list(structure(list(Year = 2001L, Site = structure(1L, .Label = "G101", class = "factor"),
+     x = 33.1), .Names = c("Year", "Site", "x"), row.names = c(NA,
+ -1L), class = "data.frame"), structure(list(Year = 2001L, Site =
structure(1L, .Label = "G102", class = "factor"),
+     x = 34), .Names = c("Year", "Site", "x"), row.names = c(NA,
+ -1L), class = "data.frame"))
> library(dplyr);
> rbind_all(lst3);
  Year Site    x
1 2001 G101 33.1
2 2001 G102 34.0
Warning message:
In rbind_all(lst3) : Unequal factor levels: coercing to character
> dcast(output1,Year ~ Site,value.var="x")
  Year G101 G102
1 2001 33.1   34
>


Sorry for the extra reply.  60 hour work weeks and 61 years of age
don't mix well. Back to watching Beakman on Netflix.


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From zilefacelvis at yahoo.com  Mon Aug  4 00:58:00 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Sun, 3 Aug 2014 15:58:00 -0700
Subject: [R] Convert some columns of List to dataframe R
In-Reply-To: <CAAJSdjgL588DfpV0s_A+_5L6c6XEvgx47yqWFt53FMHvYC3WHQ@mail.gmail.com>
References: <1407103926.20001.YahooMailNeo@web160601.mail.bf1.yahoo.com>	<CAAJSdjh8-b2uVrmA=w9TmP-QfQJYALw-MXqerKY2yEYxLEeCqw@mail.gmail.com>
	<CAAJSdjgL588DfpV0s_A+_5L6c6XEvgx47yqWFt53FMHvYC3WHQ@mail.gmail.com>
Message-ID: <1407106680.71150.YahooMailNeo@web160605.mail.bf1.yahoo.com>

Hi John, 
Thanks. As you said, I want the "Site" values to become 
individual variable names whose value is in the "x" column: 
Output should look exactly like: 
Year G101 G102 
2001 33.1 34 
Thanks, 
Atem.



On Sunday, August 3, 2014 4:48 PM, John McKown <john.archie.mckown at gmail.com> wrote:
On Sun, Aug 3, 2014 at 5:43 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Sun, Aug 3, 2014 at 5:12 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
>> Dear All,
>> I have a List in R and would like to convert it to data.frame.
>> Below is a reproducible example. I can do something like:
>>
>> x1<-do.call(cbind.data.frame, lst3) #OR
>> x1<-as.data.frame(lst3).
>>
>> However, my output looks like this:
>>
>> Year Site? x?  Year Site? x
>> 2001 G101 33.1 2001 G102 34
>>
>> I would like to have as my output:
>>
>> Year? G101?  G102
>> 2001? 33.1?  34
>>
>>
>> Thanks
>> Atem.
> <snip>
>
> Try rbind_all in the dplyr package.
>
> output <- rbind_all(as.list(lst3));
>
> Example transcript:
>
>> lst3 <- list(structure(list(Year = 2001L, Site = structure(1L, .Label = "G101", class = "factor"),
> +? ?  x = 33.1), .Names = c("Year", "Site", "x"), row.names = c(NA,
> + -1L), class = "data.frame"), structure(list(Year = 2001L, Site =
> structure(1L, .Label = "G102", class = "factor"),
> +? ?  x = 34), .Names = c("Year", "Site", "x"), row.names = c(NA,
> + -1L), class = "data.frame"))
>> library(dplyr);
>> rbind_all(lst3);
>?  Year Site? ? x
> 1 2001 G101 33.1
> 2 2001 G102 34.0
> Warning message:
> In rbind_all(lst3) : Unequal factor levels: coercing to character

OOPS. Didn't got far enough. You want the "Site" values to become
individual variable names whose value is in the "x" column. Some days
I need more naps. But I think that this is the starting point. More
later. Sorry.

>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown






-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown



From desolator88 at 163.com  Mon Aug  4 04:33:24 2014
From: desolator88 at 163.com (super)
Date: Mon, 4 Aug 2014 10:33:24 +0800 (CST)
Subject: [R]  About a R learning course
Message-ID: <1176411b.9258.1479edd3b17.Coremail.desolator88@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/59ffaa1b/attachment.pl>

From kridox at ymail.com  Mon Aug  4 04:32:50 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 4 Aug 2014 11:32:50 +0900
Subject: [R] How to overlay contourplot of a dataset A and a levelplot
 of a dataset B?
In-Reply-To: <CAH-FEnhLr=Rf6WcOdmUqk-gmbisffedDPxhS5mTyDJfC=zNTAw@mail.gmail.com>
References: <CAH-FEnhQLUPmJd3jMVKQuHsN_qkeUkD=pR36FM3Msa5A4eFZ2w@mail.gmail.com>
	<CAH-FEnhLr=Rf6WcOdmUqk-gmbisffedDPxhS5mTyDJfC=zNTAw@mail.gmail.com>
Message-ID: <CAAcyNCyKkbhmXAK_SS09sr2BwaA-shXex=6RHp1keMsekpb3wA@mail.gmail.com>

Hi Charles,

You don't need "as.layer".

levelplot(z ~ x*y,grid2) + contourplot(z ~ x*y,grid1)

is enough.

Regards,
Pascal

On Sun, Aug 3, 2014 at 5:59 PM, Charles Novaes de Santana
<charles.santana at gmail.com> wrote:
> Dear all,
>
> Just to inform that I have solved my problem in a very elegant way, thanks
> to the layer approach given by package latticeExtra.
>
> After loading my grids like before:
>
> x<-1:10
> y<-1:10
> grid1<-expand.grid(x=x,y=y)
> grid2<-expand.grid(x=x,y=y)
> z1<-grid1$x^2 + grid1$y^2
> z2<-2*grid2$x^2 - grid2$y^2
> grid1$z<-z1
> grid2$z<-z2
>
> I just need to do:
>
> levelplot(z ~ x*y,grid2) + as.layer(contourplot(z ~ x*y,grid1));
>
> The result is a beautiful plot with a contourplot over a levelplot. There
> are some examples of overlay of trellis plots in the manual of
> latticeExtra: http://latticeextra.r-forge.r-project.org/
>
> Thank you for your attention,
>
> Best,
>
> Charles
>
>
> On Sat, Aug 2, 2014 at 4:01 PM, Charles Novaes de Santana <
> charles.santana at gmail.com> wrote:
>
>> Dear all,
>>
>> Does anyone know a way to overlay a contourplot and a levelplot of
>> different datasets, both datasets with the same dimension?
>>
>> Let's say I have 2 10x10 grids, like those below:
>>
>> library(lattice)
>>
>> x<-1:10
>> y<-1:10
>> grid1<-expand.grid(x=x,y=y)
>> grid2<-expand.grid(x=x,y=y)
>> z1<-grid1$x^2 + grid1$y^2
>> z2<-2*grid2$x^2 - grid2$y^2
>> grid1$z<-z1
>> grid2$z<-z2
>>
>> I would like to plot z1 and z2 in the same plot: z1 as a contourline and
>> z2 as a levelplot. I tried to do this in two ways, without success:
>>
>> plot.new();
>> contourplot(z ~ x*y,grid1)
>> par(new=T)
>> levelplot(z ~ x*y,grid2)
>>
>> and
>>
>> levelplot(z ~ x*y,grid1,region=FALSE,contour=TRUE)
>> par(new=T)
>> levelplot(z ~ x*y,grid2,region=TRUE,contour=FALSE)
>>
>> Any clue?
>>
>>  Thank you very much for your time and any help!
>>
>> Charles
>>
>> --
>> Um ax?! :)
>>
>> --
>> Charles Novaes de Santana, PhD
>> http://www.imedea.uib-csic.es/~charles
>>
>
>
>
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From mridul.astro at gmail.com  Mon Aug  4 09:48:09 2014
From: mridul.astro at gmail.com (cosmos science)
Date: Mon, 4 Aug 2014 13:18:09 +0530
Subject: [R] memory corruption in R
Message-ID: <CAOUaUGzUTZhabJ0421MTx-bk71Ag9hognNOdhhzc4nPnMLGoCg@mail.gmail.com>

HI...

I am using R-package CORElearn (
http://cran.r-project.org/web/packages/CORElearn/index.html).

During its application on a dataset, It crashed. The crash message says
*** glibc detected *** /usr/local/lib64/R/bin/exec/R: malloc(): memory
corruption: 0x000000004b9b0788 ***

The error log "cdump.dat" is attached.

I am using R-3.1.1 and CORElearn version is 0.9.43
May I know where is the problem?

Regards
Mridul

From ripley at stats.ox.ac.uk  Mon Aug  4 09:57:35 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 04 Aug 2014 08:57:35 +0100
Subject: [R] memory corruption in R
In-Reply-To: <CAOUaUGzUTZhabJ0421MTx-bk71Ag9hognNOdhhzc4nPnMLGoCg@mail.gmail.com>
References: <CAOUaUGzUTZhabJ0421MTx-bk71Ag9hognNOdhhzc4nPnMLGoCg@mail.gmail.com>
Message-ID: <53DF3CEF.8050200@stats.ox.ac.uk>

On 04/08/2014 08:48, cosmos science wrote:
> HI...
>
> I am using R-package CORElearn (
> http://cran.r-project.org/web/packages/CORElearn/index.html).
>
> During its application on a dataset, It crashed. The crash message says
> *** glibc detected *** /usr/local/lib64/R/bin/exec/R: malloc(): memory
> corruption: 0x000000004b9b0788 ***
>
> The error log "cdump.dat" is attached.
>
> I am using R-3.1.1 and CORElearn version is 0.9.43
> May I know where is the problem?

See 'Writing R Extensions' for how to find out, but all the issues 
reported at 
http://cran.r-project.org/web/checks/check_results_CORElearn.html might 
give you a clue.

What did the CORElearn maintainer say when you asked (see the posting 
guide)?

>
> Regards
> Mridul
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mridul.astro at gmail.com  Mon Aug  4 10:19:33 2014
From: mridul.astro at gmail.com (cosmos science)
Date: Mon, 4 Aug 2014 13:49:33 +0530
Subject: [R] memory corruption in R
In-Reply-To: <CAOUaUGzUTZhabJ0421MTx-bk71Ag9hognNOdhhzc4nPnMLGoCg@mail.gmail.com>
References: <CAOUaUGzUTZhabJ0421MTx-bk71Ag9hognNOdhhzc4nPnMLGoCg@mail.gmail.com>
Message-ID: <CAOUaUGzqhhzXbEx+ruDRaWsfaEA=RcuqbKKvnzGKuEb0NsMV_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/4a2f5177/attachment.pl>

From florian.denzinger at uzh.ch  Mon Aug  4 11:02:07 2014
From: florian.denzinger at uzh.ch (fd)
Date: Mon, 4 Aug 2014 02:02:07 -0700 (PDT)
Subject: [R] Filling in missing values in a column based on previous and
 following values
Message-ID: <1407142927361-4694993.post@n4.nabble.com>

I have the following .csv file containing about 40000 values (here only an
extract and simplified version):

NAME  ;	YEAR; ID;	VALUE; CUMMB
Sample1;	1998;	 354;	45;	   45
Sample1;	1999;	 354;	23;	   68
Sample1;	2000;	 NA;	66;	   134
Sample1;	2001;	 NA;	98;	   232
Sample1;	2002;	 NA;	36;	   268
Sample1;	2003;	 NA;	59;	   327
Sample1;	2004;	 NA;	64;	   391
Sample1;	2005;	 354;	23;	   414
Sample1;	2006;	 354;	69;	   483
Sample1;	2007;	 354;	94;	   577
Sample1;	2008;	 354;	24;	   601
Sample2;	1964;	1342;	7;	      7
Sample2;	1965;	1342;	24;	     31
Sample3;	2002;	 859;	90;	     90
Sample3;	2003;	  NA;	93;	    183
Sample3;	2004;	  NA;	53;	    236
Sample3;	2005;	 859;	98;	    334

What I would like to do is to replace the NA values in ID with the values
from the ID. E.g. all values in ID from Sample 1 should have the value 354;
all values in ID from Sample 3 should have the value 859 etc.

Is there a simple way to do this? 

Thanks for your help.



--
View this message in context: http://r.789695.n4.nabble.com/Filling-in-missing-values-in-a-column-based-on-previous-and-following-values-tp4694993.html
Sent from the R help mailing list archive at Nabble.com.


From Gerrit.Eichner at math.uni-giessen.de  Mon Aug  4 11:31:02 2014
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Mon, 4 Aug 2014 11:31:02 +0200 (MEST)
Subject: [R] Filling in missing values in a column based on
	previousandfollowing values
In-Reply-To: <1407142927361-4694993.post@n4.nabble.com>
References: <1407142927361-4694993.post@n4.nabble.com>
Message-ID: <Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>

Hello, Florian,

function na.locf() from package zoo mightdo what you want.

Hth --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
---------------------------------------------------------------------

On Mon, 4 Aug 2014, fd wrote:

> I have the following .csv file containing about 40000 values (here only an
> extract and simplified version):
>
> NAME  ;	YEAR; ID;	VALUE; CUMMB
> Sample1;	1998;	 354;	45;	   45
> Sample1;	1999;	 354;	23;	   68
> Sample1;	2000;	 NA;	66;	   134
> Sample1;	2001;	 NA;	98;	   232
> Sample1;	2002;	 NA;	36;	   268
> Sample1;	2003;	 NA;	59;	   327
> Sample1;	2004;	 NA;	64;	   391
> Sample1;	2005;	 354;	23;	   414
> Sample1;	2006;	 354;	69;	   483
> Sample1;	2007;	 354;	94;	   577
> Sample1;	2008;	 354;	24;	   601
> Sample2;	1964;	1342;	7;	      7
> Sample2;	1965;	1342;	24;	     31
> Sample3;	2002;	 859;	90;	     90
> Sample3;	2003;	  NA;	93;	    183
> Sample3;	2004;	  NA;	53;	    236
> Sample3;	2005;	 859;	98;	    334
>
> What I would like to do is to replace the NA values in ID with the values
> from the ID. E.g. all values in ID from Sample 1 should have the value 354;
> all values in ID from Sample 3 should have the value 859 etc.
>
> Is there a simple way to do this?
>
> Thanks for your help.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Filling-in-missing-values-in-a-column-based-on-previous-and-following-values-tp4694993.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From florian.denzinger at uzh.ch  Mon Aug  4 11:39:41 2014
From: florian.denzinger at uzh.ch (Florian Denzinger)
Date: Mon, 4 Aug 2014 11:39:41 +0200
Subject: [R] Filling in missing values in a column based on
	previousandfollowing values
In-Reply-To: <Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
References: <1407142927361-4694993.post@n4.nabble.com>
	<Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
Message-ID: <A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>

this is great, thanks! 

one problem I noticed though is that it fills all NA values in every column, is it possible to specify only one column, e.g. only ID (I have NA values in another column I want to keep)

Kind regards,
Florian

 

Am 04.08.2014 um 11:31 schrieb Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de>:

> Hello, Florian,
> 
> function na.locf() from package zoo mightdo what you want.
> 
> Hth --  Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
> ---------------------------------------------------------------------
> 
> On Mon, 4 Aug 2014, fd wrote:
> 
>> I have the following .csv file containing about 40000 values (here only an
>> extract and simplified version):
>> 
>> NAME  ;	YEAR; ID;	VALUE; CUMMB
>> Sample1;	1998;	 354;	45;	   45
>> Sample1;	1999;	 354;	23;	   68
>> Sample1;	2000;	 NA;	66;	   134
>> Sample1;	2001;	 NA;	98;	   232
>> Sample1;	2002;	 NA;	36;	   268
>> Sample1;	2003;	 NA;	59;	   327
>> Sample1;	2004;	 NA;	64;	   391
>> Sample1;	2005;	 354;	23;	   414
>> Sample1;	2006;	 354;	69;	   483
>> Sample1;	2007;	 354;	94;	   577
>> Sample1;	2008;	 354;	24;	   601
>> Sample2;	1964;	1342;	7;	      7
>> Sample2;	1965;	1342;	24;	     31
>> Sample3;	2002;	 859;	90;	     90
>> Sample3;	2003;	  NA;	93;	    183
>> Sample3;	2004;	  NA;	53;	    236
>> Sample3;	2005;	 859;	98;	    334
>> 
>> What I would like to do is to replace the NA values in ID with the values
>> from the ID. E.g. all values in ID from Sample 1 should have the value 354;
>> all values in ID from Sample 3 should have the value 859 etc.
>> 
>> Is there a simple way to do this?
>> 
>> Thanks for your help.
>> 
>> 
>> 
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Filling-in-missing-values-in-a-column-based-on-previous-and-following-values-tp4694993.html
>> Sent from the R help mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From barvazduck at gmail.com  Mon Aug  4 11:53:53 2014
From: barvazduck at gmail.com (raz)
Date: Mon, 4 Aug 2014 12:53:53 +0300
Subject: [R] Compare data in two rows and replace objects in data frame
Message-ID: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/7d3cb9dd/attachment.pl>

From Gerrit.Eichner at math.uni-giessen.de  Mon Aug  4 12:00:14 2014
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Mon, 4 Aug 2014 12:00:14 +0200 (MEST)
Subject: [R] Filling in missing values in a column based on
	previousandfollowingvalues
In-Reply-To: <A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>
References: <1407142927361-4694993.post@n4.nabble.com>
	<Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
	<A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>
Message-ID: <Pine.SOC.4.64.1408041157520.3241@solcom.hrz.uni-giessen.de>

On Mon, 4 Aug 2014, Florian Denzinger wrote:

> this is great, thanks!
>
> one problem I noticed though is that it fills all NA values in every 
> column, is it possible to specify only one column, e.g. only ID (I have 
> NA values in another column I want to keep)

Yes, of course. Just access only one column, not all: Something like

yourdataframe$ID <- na.locf( yourdataframe$ID)

should replace the ID-column with the modified version you want.

Regards  --  Gerrit


> Kind regards,
> Florian
>
>
>
> Am 04.08.2014 um 11:31 schrieb Gerrit Eichner <Gerrit.Eichner at math.uni-giessen.de>:
>
>> Hello, Florian,
>>
>> function na.locf() from package zoo mightdo what you want.
>>
>> Hth --  Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>> ---------------------------------------------------------------------
>>
>> On Mon, 4 Aug 2014, fd wrote:
>>
>>> I have the following .csv file containing about 40000 values (here only an
>>> extract and simplified version):
>>>
>>> NAME  ;	YEAR; ID;	VALUE; CUMMB
>>> Sample1;	1998;	 354;	45;	   45
>>> Sample1;	1999;	 354;	23;	   68
>>> Sample1;	2000;	 NA;	66;	   134
>>> Sample1;	2001;	 NA;	98;	   232
>>> Sample1;	2002;	 NA;	36;	   268
>>> Sample1;	2003;	 NA;	59;	   327
>>> Sample1;	2004;	 NA;	64;	   391
>>> Sample1;	2005;	 354;	23;	   414
>>> Sample1;	2006;	 354;	69;	   483
>>> Sample1;	2007;	 354;	94;	   577
>>> Sample1;	2008;	 354;	24;	   601
>>> Sample2;	1964;	1342;	7;	      7
>>> Sample2;	1965;	1342;	24;	     31
>>> Sample3;	2002;	 859;	90;	     90
>>> Sample3;	2003;	  NA;	93;	    183
>>> Sample3;	2004;	  NA;	53;	    236
>>> Sample3;	2005;	 859;	98;	    334
>>>
>>> What I would like to do is to replace the NA values in ID with the values
>>> from the ID. E.g. all values in ID from Sample 1 should have the value 354;
>>> all values in ID from Sample 3 should have the value 859 etc.
>>>
>>> Is there a simple way to do this?
>>>
>>> Thanks for your help.
>>>
>>>
>>>
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/Filling-in-missing-values-in-a-column-based-on-previous-and-following-values-tp4694993.html
>>> Sent from the R help mailing list archive at Nabble.com.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From Gerrit.Eichner at math.uni-giessen.de  Mon Aug  4 12:47:18 2014
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Mon, 4 Aug 2014 12:47:18 +0200 (MEST)
Subject: [R] Compare data in two rows and replace objects in data frame
In-Reply-To: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
References: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1408041242560.3241@solcom.hrz.uni-giessen.de>

Hello, Raz,

if X is the data frame that contains your data, then using sort of an 
"indexing trick" to circumvent your numerous if-statements as in

aggregate( X[ c( "genotype 2001", "genotype 2002", "genotype 2003")],
            X[ "CloneID"],
            FUN = function( x)
                   c( "11" = "HT",
                      "10" = "A",
                      "01" = "B",
                      "1-" = "Aht",
                      "-1" = "Bht")[ paste( x, collapse = "")])

presumably does what you want (and can certainly be improved).

Hth  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
---------------------------------------------------------------------

On Mon, 4 Aug 2014, raz wrote:

> Dear all,
>
> I have a data frame 144 x 20000 values.
> I need to take every value in the first row and compare to the second row,
> and the same for rows 3-4 and 5-6 and so on.
> the output should be one line for each of the two row comparison.
> the comparison is:
> if row1==1 and row2==1 <-'HT'
> if row1==1 and row2==0 <-'A'
> if row1==0 and row2==1 <-'B'
> if row1==1 and row2=='-' <-'Aht'
> if row1=='-' and row2==1 <-'Bht'
>
> for example:
> if the data is:
> CloneID    genotype 2001    genotype 2002    genotype 2003
> 2471250    1    1    1
> 2471250    0    0    0
> 2433062    0    0    0
> 2433062    1    1    1
> 100021605    1    1    0
> 100021605    1    0    1
> 100005599    1    1    0
> 100005599    1    1    1
> 100002798    1    1    0
> 100002798    1    1    1
>
> then the output should be:
> CloneID    genotype 2001    genotype 2002    genotype 2003
> 2471250    A    A    A
> 2433062    B    B    B
> 100021605    HT    A    B
> 100005599    HT    HT    B
> 100002798    HT    HT    B
>
> I tried this for the whole data, but its so slow:
>
> AX <- data.frame(lapply(AX, as.character), stringsAsFactors=FALSE)
>
>
> for (i in seq(1,nrow(AX),by=2)){
> for (j in 6:144){
> if (AX[i,j]==1 & AX[i+1,j]==0){
> AX[i,j]<-'A'
> }
> if (AX[i,j]==0 & AX[i+1,j]==1){
> AX[i,j]<-'B'
> }
> if (AX[i,j]==1 & AX[i+1,j]==1){
> AX[i,j]<-'HT'
> }
> if (AX[i,j]==1 & AX[i+1,j]=="-"){
> AX[i,j]<-'Aht'
> }
> if (AX[i,j]=="-" & AX[i+1,j]==1){
> AX[i,j]<-'Bht'
> }
> }
> }
>
> AX1<-AX[!duplicated(AX[,3]),]
> AX2<-AX[duplicated(AX[,3]),]
>
> Thanks for any help,
>
> Raz
>
>
>
> -- 
> \m/
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From florian.denzinger at uzh.ch  Mon Aug  4 13:34:06 2014
From: florian.denzinger at uzh.ch (Florian Denzinger)
Date: Mon, 4 Aug 2014 13:34:06 +0200
Subject: [R] Filling in missing values in a column based on
	previousandfollowingvalues
In-Reply-To: <Pine.SOC.4.64.1408041157520.3241@solcom.hrz.uni-giessen.de>
References: <1407142927361-4694993.post@n4.nabble.com>
	<Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
	<A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>
	<Pine.SOC.4.64.1408041157520.3241@solcom.hrz.uni-giessen.de>
Message-ID: <00573A08-B3E4-4467-A120-6BE204B485A1@uzh.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/76e49d1a/attachment.pl>

From smartpink111 at yahoo.com  Mon Aug  4 13:34:45 2014
From: smartpink111 at yahoo.com (arun)
Date: Mon, 4 Aug 2014 04:34:45 -0700
Subject: [R] Compare data in two rows and replace objects in data frame
In-Reply-To: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
References: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
Message-ID: <1407152085.75649.YahooMailNeo@web142603.mail.bf1.yahoo.com>

You could try data.table

#dat is the dataset


library(data.table)
v1 <- setNames(c("HT", "A", "B", "Aht", "Bht"), c("11", "10", "01", "1-", "-1"))
dat2 <- setDT(dat1)[, lapply(.SD, function(x) v1[paste(x, collapse="")]), by=CloneID]

A.K.




On Monday, August 4, 2014 5:55 AM, raz <barvazduck at gmail.com> wrote:
Dear all,

I have a data frame 144 x 20000 values.
I need to take every value in the first row and compare to the second row,
and the same for rows 3-4 and 5-6 and so on.
the output should be one line for each of the two row comparison.
the comparison is:
if row1==1 and row2==1 <-'HT'
if row1==1 and row2==0 <-'A'
if row1==0 and row2==1 <-'B'
if row1==1 and row2=='-' <-'Aht'
if row1=='-' and row2==1 <-'Bht'

for example:
if the data is:
CloneID? ? genotype 2001? ? genotype 2002? ? genotype 2003
2471250? ? 1? ? 1? ? 1
2471250? ? 0? ? 0? ? 0
2433062? ? 0? ? 0? ? 0
2433062? ? 1? ? 1? ? 1
100021605? ? 1? ? 1? ? 0
100021605? ? 1? ? 0? ? 1
100005599? ? 1? ? 1? ? 0
100005599? ? 1? ? 1? ? 1
100002798? ? 1? ? 1? ? 0
100002798? ? 1? ? 1? ? 1

then the output should be:
CloneID? ? genotype 2001? ? genotype 2002? ? genotype 2003
2471250? ? A? ? A? ? A
2433062? ? B? ? B? ? B
100021605? ? HT? ? A? ? B
100005599? ? HT? ? HT? ? B
100002798? ? HT? ? HT? ? B

I tried this for the whole data, but its so slow:

AX <- data.frame(lapply(AX, as.character), stringsAsFactors=FALSE)


for (i in seq(1,nrow(AX),by=2)){
for (j in 6:144){
if (AX[i,j]==1 & AX[i+1,j]==0){
AX[i,j]<-'A'
}
if (AX[i,j]==0 & AX[i+1,j]==1){
AX[i,j]<-'B'
}
if (AX[i,j]==1 & AX[i+1,j]==1){
AX[i,j]<-'HT'
}
if (AX[i,j]==1 & AX[i+1,j]=="-"){
AX[i,j]<-'Aht'
}
if (AX[i,j]=="-" & AX[i+1,j]==1){
AX[i,j]<-'Bht'
}
}
}

AX1<-AX[!duplicated(AX[,3]),]
AX2<-AX[duplicated(AX[,3]),]

Thanks for any help,

Raz



-- 
\m/

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mridul.astro at gmail.com  Mon Aug  4 13:41:02 2014
From: mridul.astro at gmail.com (cosmos science)
Date: Mon, 4 Aug 2014 17:11:02 +0530
Subject: [R] memory corruption in R
In-Reply-To: <CAOUaUGzqhhzXbEx+ruDRaWsfaEA=RcuqbKKvnzGKuEb0NsMV_Q@mail.gmail.com>
References: <CAOUaUGzUTZhabJ0421MTx-bk71Ag9hognNOdhhzc4nPnMLGoCg@mail.gmail.com>
	<CAOUaUGzqhhzXbEx+ruDRaWsfaEA=RcuqbKKvnzGKuEb0NsMV_Q@mail.gmail.com>
Message-ID: <CAOUaUGzibQAo1X7SLW6TezHFcX5QEDt9-bKobLU7ySJpLyKpBg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/d0a9fe1d/attachment.pl>

From john.archie.mckown at gmail.com  Mon Aug  4 14:13:10 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 4 Aug 2014 07:13:10 -0500
Subject: [R] Filling in missing values in a column based on
	previousandfollowingvalues
In-Reply-To: <00573A08-B3E4-4467-A120-6BE204B485A1@uzh.ch>
References: <1407142927361-4694993.post@n4.nabble.com>
	<Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
	<A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>
	<Pine.SOC.4.64.1408041157520.3241@solcom.hrz.uni-giessen.de>
	<00573A08-B3E4-4467-A120-6BE204B485A1@uzh.ch>
Message-ID: <CAAJSdjhzyhPMu5er3-mrWR_CnfDq5eoaZoLX_icnTVk5dCpyqQ@mail.gmail.com>

On Mon, Aug 4, 2014 at 6:34 AM, Florian Denzinger
<florian.denzinger at uzh.ch> wrote:
> Shortly after answering to your first email, I got to solution. Sorry for the unnecessary noise.
>
> Regards,
> F
>

Florian,

I'd be interested in seeing your solution. I need as many techniques
in my "bag of tricks" as I can find.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From florian.denzinger at uzh.ch  Mon Aug  4 16:01:06 2014
From: florian.denzinger at uzh.ch (Florian Denzinger)
Date: Mon, 4 Aug 2014 16:01:06 +0200
Subject: [R] Filling in missing values in a column based on
	previousandfollowingvalues
In-Reply-To: <CAAJSdjhzyhPMu5er3-mrWR_CnfDq5eoaZoLX_icnTVk5dCpyqQ@mail.gmail.com>
References: <1407142927361-4694993.post@n4.nabble.com>
	<Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
	<A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>
	<Pine.SOC.4.64.1408041157520.3241@solcom.hrz.uni-giessen.de>
	<00573A08-B3E4-4467-A120-6BE204B485A1@uzh.ch>
	<CAAJSdjhzyhPMu5er3-mrWR_CnfDq5eoaZoLX_icnTVk5dCpyqQ@mail.gmail.com>
Message-ID: <6C0775C7-184B-4CE7-A0E1-E752D80E32AF@uzh.ch>

Hi John,

I only meant the subsetting of the dataframe by using the zoo function suggested by Gerrit! Not a new solution/function, I am afraid. 
Regards,
F

Am 04.08.2014 um 14:13 schrieb John McKown <john.archie.mckown at gmail.com>:

> On Mon, Aug 4, 2014 at 6:34 AM, Florian Denzinger
> <florian.denzinger at uzh.ch> wrote:
>> Shortly after answering to your first email, I got to solution. Sorry for the unnecessary noise.
>> 
>> Regards,
>> F
>> 
> 
> Florian,
> 
> I'd be interested in seeing your solution. I need as many techniques
> in my "bag of tricks" as I can find.
> 
> -- 
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown


From yun.jiang at student.unsw.edu.au  Mon Aug  4 13:50:41 2014
From: yun.jiang at student.unsw.edu.au (Jenny Jiang)
Date: Mon, 4 Aug 2014 11:50:41 +0000
Subject: [R] Calculation of network centrality measures weighted by network
	size
Message-ID: <1407153040942.39109@student.unsw.edu.au>

Hello,

My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales Australia. Currently my research project involves the calculating of some network centrality measures in R, which are degree, closeness, betweenness and eigen vector. However I am having some issue regarding to the calculation of the weighted centrality measures by network size. For example, currently my code allows me to calculate centrality measures for each firm year, and now I would like to calculate centrality measures weighted by the firm network size for each firm year. I have attached my current R code and a data example for you in .txt format to have a look. If you could provide me the R code regarding to how to do that that would be really helpful.

I cannot be more than appreciated.

Best regards

Jenny
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: data example 2.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/92262aa4/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: centrality code.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/92262aa4/attachment-0001.txt>

From john.archie.mckown at gmail.com  Mon Aug  4 16:36:04 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 4 Aug 2014 09:36:04 -0500
Subject: [R] Filling in missing values in a column based on
	previousandfollowingvalues
In-Reply-To: <6C0775C7-184B-4CE7-A0E1-E752D80E32AF@uzh.ch>
References: <1407142927361-4694993.post@n4.nabble.com>
	<Pine.SOC.4.64.1408041129270.3241@solcom.hrz.uni-giessen.de>
	<A0A73649-E7CA-4C87-ABAC-897227C3AFC7@uzh.ch>
	<Pine.SOC.4.64.1408041157520.3241@solcom.hrz.uni-giessen.de>
	<00573A08-B3E4-4467-A120-6BE204B485A1@uzh.ch>
	<CAAJSdjhzyhPMu5er3-mrWR_CnfDq5eoaZoLX_icnTVk5dCpyqQ@mail.gmail.com>
	<6C0775C7-184B-4CE7-A0E1-E752D80E32AF@uzh.ch>
Message-ID: <CAAJSdjh390Kf_LZcYkbhDyiYgL-aFQRYu36apf_yPvnVefo+SQ@mail.gmail.com>

On Mon, Aug 4, 2014 at 9:01 AM, Florian Denzinger
<florian.denzinger at uzh.ch> wrote:
> Hi John,
>
> I only meant the subsetting of the dataframe by using the zoo function suggested by Gerrit! Not a new solution/function, I am afraid.
> Regards,
> F

I take it that means you _don't_ have a solution. If not, or even if
you do, my solution is below. There likely is a better way to do it.
I'm still learning R and there is a _LOT_ of things in all those
packages which I don't know.

library(reshape2); # needed for dcast()
#
# create variable
florian <- data.frame(
NAME=c('Sample1','Sample1','Sample1','Sample1','Sample1','Sample1','Sample1',
'Sample1','Sample1','Sample1','Sample1','Sample2','Sample2','Sample3','Sample3',
'Sample3','Sample3'),
YEAR=c( 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 1964,
1965, 2002, 2003, 2004, 2005),
ID=c( 354 , 354 ,NA ,NA ,NA ,NA ,NA , 354 , 354 , 354 , 354 , 1342 ,
1342 , 859 ,NA ,NA , 859 ),
VALUE=c( 45 , 23 , 66 , 98 , 36 , 59 , 64 , 23 , 69 , 94 , 24 , 7 , 24 , 90 ,
93 , 53 , 98 ),
CUMMB=c( 45 , 68 , 134 , 232 , 268 , 327 , 391 , 414 , 483 , 577 , 601 , 7 , 31
, 90 , 183 , 236 , 334 ));
#
# start of solution: y is a temporary table I need to
# find the non-NA ID values per NAME value.
# I actually use max() but ASSuME that all non-NA value are ==
# !is.na() is used to remove NA values from consideration.
y <- dcast(florian[!is.na(florian$ID),],NAME ~
.,value.var="ID",fun.aggregate=max,fill=-1,drop=FALSE);
names(y) <- c("NAME","IDy"); # Nicer names that dcast() makes.
#
# The real work is done in merge()
florian <- merge(x=florian,y=y,by=c("NAME"),all.x=TRUE);
florian$ID <- florian$IDy; #copy merged values to ID column
florian$IDy <- NULL; # remove temporary column
rm(y); # erase temporary frame.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jholtman at gmail.com  Mon Aug  4 17:28:21 2014
From: jholtman at gmail.com (jim holtman)
Date: Mon, 4 Aug 2014 11:28:21 -0400
Subject: [R] Count number of change in a specified time interval
In-Reply-To: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>
References: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>
Message-ID: <CAAxdm-4j2-hHqY3za=8xFNY4AbnqBiavQ_tvhsC4RNa2QpqiJg@mail.gmail.com>

Try this, but I only get 2 changes for CB27A instead of you indicated 3:

> require(data.table)
> x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
+ CB26A    201302         1
+ CB26A    201302         0
+ CB26A    201302         0
+ CB26A    201303         1
+ CB26A    201303         1
+ CB26A    201304         0
+ CB26A    201305         1
+ CB26A    201305         0
+ CB26A    201306         1
+ CB27A    201304         0
+ CB27A    201304         0
+ CB27A    201305         1
+ CB27A    201306         1
+ CB27A    201306         0
+ CB27A    201307         0
+ CB27A    201308         1", header = TRUE, as.is = TRUE)
> setDT(x)
> # convert to a Date object for comparison
> x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
> # separate by CASE_ID and only keep the first 3 months
> x[
+     , {
+         # determine the end date as 3 months from the first date
+         endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
+         # extract what is changing
+         changes <- ATT_1[(MYD >= MYD[1L]) & (MYD <= endDate)]
+         # now count the changes
+         list(nChanges = sum(head(changes, -1L) != tail(changes, -1L)))
+       }
+     , by = CASE_ID
+     ]
   CASE_ID nChanges
1:   CB26A        5
2:   CB27A        2

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Jul 30, 2014 at 3:08 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Dear R-helpers,
>
> I want to count the number of times ATT_1 has changed in a period of 3
> months(can be 4months) from the first YEAR_MTH entry for a CASE_ID. So if
> for a CASE_ID we have data only for two distinct YEAR_MTH, then all the
> entries should be considered, otherwise only the relevant entries will be
> considered for calculation.
> E.g. if the first YEAR_MTH entry is 201304 then get the number of changes
> till 201307(inclusive), similarly if the first YEAR_MTH entry is 201302
> then get the number of changes till 201305.
>
> Dataset
> CASE_ID YEAR_MTH ATT_1
> CB26A    201302         1
> CB26A    201302         0
> CB26A    201302         0
> CB26A    201303         1
> CB26A    201303         1
> CB26A    201304         0
> CB26A    201305         1
> CB26A    201305         0
> CB26A    201306         1
> CB27A    201304         0
> CB27A    201304         0
> CB27A    201305         1
> CB27A    201306         1
> CB27A    201306         0
> CB27A    201307         0
> CB27A    201308         1
>
> The final dataset should look like
>
> ID_CASE    No.of changes
> CB26A        5
> CB27A        3
>
> where 'No.of changes' refer to the change in 3 months (201302-201305 for
> CB26A and 201304-201307 for CB27A).
>
> How can this be done in R?
>
> Regards,
> Abhinaba Roy
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Aug  4 17:39:12 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 4 Aug 2014 08:39:12 -0700
Subject: [R] Count number of change in a specified time interval
In-Reply-To: <CAAxdm-4j2-hHqY3za=8xFNY4AbnqBiavQ_tvhsC4RNa2QpqiJg@mail.gmail.com>
References: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>
	<CAAxdm-4j2-hHqY3za=8xFNY4AbnqBiavQ_tvhsC4RNa2QpqiJg@mail.gmail.com>
Message-ID: <A037A4AF-651F-4B5B-9BE8-2750369965C7@gene.com>

Or ?rle

Bert



Sent from my iPhone -- please excuse typos.

> On Aug 4, 2014, at 8:28 AM, jim holtman <jholtman at gmail.com> wrote:
> 
> Try this, but I only get 2 changes for CB27A instead of you indicated 3:
> 
>> require(data.table)
>> x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
> + CB26A    201302         1
> + CB26A    201302         0
> + CB26A    201302         0
> + CB26A    201303         1
> + CB26A    201303         1
> + CB26A    201304         0
> + CB26A    201305         1
> + CB26A    201305         0
> + CB26A    201306         1
> + CB27A    201304         0
> + CB27A    201304         0
> + CB27A    201305         1
> + CB27A    201306         1
> + CB27A    201306         0
> + CB27A    201307         0
> + CB27A    201308         1", header = TRUE, as.is = TRUE)
>> setDT(x)
>> # convert to a Date object for comparison
>> x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
>> # separate by CASE_ID and only keep the first 3 months
>> x[
> +     , {
> +         # determine the end date as 3 months from the first date
> +         endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
> +         # extract what is changing
> +         changes <- ATT_1[(MYD >= MYD[1L]) & (MYD <= endDate)]
> +         # now count the changes
> +         list(nChanges = sum(head(changes, -1L) != tail(changes, -1L)))
> +       }
> +     , by = CASE_ID
> +     ]
>   CASE_ID nChanges
> 1:   CB26A        5
> 2:   CB27A        2
> 
> Jim Holtman
> Data Munger Guru
> 
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
> 
> 
>> On Wed, Jul 30, 2014 at 3:08 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
>> Dear R-helpers,
>> 
>> I want to count the number of times ATT_1 has changed in a period of 3
>> months(can be 4months) from the first YEAR_MTH entry for a CASE_ID. So if
>> for a CASE_ID we have data only for two distinct YEAR_MTH, then all the
>> entries should be considered, otherwise only the relevant entries will be
>> considered for calculation.
>> E.g. if the first YEAR_MTH entry is 201304 then get the number of changes
>> till 201307(inclusive), similarly if the first YEAR_MTH entry is 201302
>> then get the number of changes till 201305.
>> 
>> Dataset
>> CASE_ID YEAR_MTH ATT_1
>> CB26A    201302         1
>> CB26A    201302         0
>> CB26A    201302         0
>> CB26A    201303         1
>> CB26A    201303         1
>> CB26A    201304         0
>> CB26A    201305         1
>> CB26A    201305         0
>> CB26A    201306         1
>> CB27A    201304         0
>> CB27A    201304         0
>> CB27A    201305         1
>> CB27A    201306         1
>> CB27A    201306         0
>> CB27A    201307         0
>> CB27A    201308         1
>> 
>> The final dataset should look like
>> 
>> ID_CASE    No.of changes
>> CB26A        5
>> CB27A        3
>> 
>> where 'No.of changes' refer to the change in 3 months (201302-201305 for
>> CB26A and 201304-201307 for CB27A).
>> 
>> How can this be done in R?
>> 
>> Regards,
>> Abhinaba Roy
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Aug  4 18:06:20 2014
From: jholtman at gmail.com (jim holtman)
Date: Mon, 4 Aug 2014 12:06:20 -0400
Subject: [R] Count number of change in a specified time interval
In-Reply-To: <A037A4AF-651F-4B5B-9BE8-2750369965C7@gene.com>
References: <CANtKHPWGPZQf9SVSi+KE2CPmJkfS5txTJLU2QUHauq6BJMvpgg@mail.gmail.com>
	<CAAxdm-4j2-hHqY3za=8xFNY4AbnqBiavQ_tvhsC4RNa2QpqiJg@mail.gmail.com>
	<A037A4AF-651F-4B5B-9BE8-2750369965C7@gene.com>
Message-ID: <CAAxdm-5pnFTo5xif4pmtD_h=3JNBW9kkGjgpnCJyTreXcGC2Lw@mail.gmail.com>

Here is the solution using 'rle':

> require(data.table)
> x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
+  CB26A    201302         1
+  CB26A    201302         0
+  CB26A    201302         0
+  CB26A    201303         1
+  CB26A    201303         1
+  CB26A    201304         0
+  CB26A    201305         1
+  CB26A    201305         0
+  CB26A    201306         1
+  CB27A    201304         0
+  CB27A    201304         0
+  CB27A    201305         1
+  CB27A    201306         1
+  CB27A    201306         0
+  CB27A    201307         0
+  CB27A    201308         1", header = TRUE, as.is = TRUE)
> setDT(x)
> # convert to a Date object for comparison
> x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
> # separate by CASE_ID and only keep the first 3 months
> x[
+      , {
+          # determine the end date as 3 months from the first date
+          endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
+          # now count the changes
+          list(nChanges = length(rle(ATT_1[(MYD >= MYD[1L]) & (MYD <=
endDate)])[[1L]]) - 1L)
+        }
+      , by = CASE_ID
+      ]
   CASE_ID nChanges
1:   CB26A        5
2:   CB27A        2

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Aug 4, 2014 at 11:39 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> Or ?rle
>
> Bert
>
>
>
> Sent from my iPhone -- please excuse typos.
>
>> On Aug 4, 2014, at 8:28 AM, jim holtman <jholtman at gmail.com> wrote:
>>
>> Try this, but I only get 2 changes for CB27A instead of you indicated 3:
>>
>>> require(data.table)
>>> x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
>> + CB26A    201302         1
>> + CB26A    201302         0
>> + CB26A    201302         0
>> + CB26A    201303         1
>> + CB26A    201303         1
>> + CB26A    201304         0
>> + CB26A    201305         1
>> + CB26A    201305         0
>> + CB26A    201306         1
>> + CB27A    201304         0
>> + CB27A    201304         0
>> + CB27A    201305         1
>> + CB27A    201306         1
>> + CB27A    201306         0
>> + CB27A    201307         0
>> + CB27A    201308         1", header = TRUE, as.is = TRUE)
>>> setDT(x)
>>> # convert to a Date object for comparison
>>> x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
>>> # separate by CASE_ID and only keep the first 3 months
>>> x[
>> +     , {
>> +         # determine the end date as 3 months from the first date
>> +         endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
>> +         # extract what is changing
>> +         changes <- ATT_1[(MYD >= MYD[1L]) & (MYD <= endDate)]
>> +         # now count the changes
>> +         list(nChanges = sum(head(changes, -1L) != tail(changes, -1L)))
>> +       }
>> +     , by = CASE_ID
>> +     ]
>>   CASE_ID nChanges
>> 1:   CB26A        5
>> 2:   CB27A        2
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>>> On Wed, Jul 30, 2014 at 3:08 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
>>> Dear R-helpers,
>>>
>>> I want to count the number of times ATT_1 has changed in a period of 3
>>> months(can be 4months) from the first YEAR_MTH entry for a CASE_ID. So if
>>> for a CASE_ID we have data only for two distinct YEAR_MTH, then all the
>>> entries should be considered, otherwise only the relevant entries will be
>>> considered for calculation.
>>> E.g. if the first YEAR_MTH entry is 201304 then get the number of changes
>>> till 201307(inclusive), similarly if the first YEAR_MTH entry is 201302
>>> then get the number of changes till 201305.
>>>
>>> Dataset
>>> CASE_ID YEAR_MTH ATT_1
>>> CB26A    201302         1
>>> CB26A    201302         0
>>> CB26A    201302         0
>>> CB26A    201303         1
>>> CB26A    201303         1
>>> CB26A    201304         0
>>> CB26A    201305         1
>>> CB26A    201305         0
>>> CB26A    201306         1
>>> CB27A    201304         0
>>> CB27A    201304         0
>>> CB27A    201305         1
>>> CB27A    201306         1
>>> CB27A    201306         0
>>> CB27A    201307         0
>>> CB27A    201308         1
>>>
>>> The final dataset should look like
>>>
>>> ID_CASE    No.of changes
>>> CB26A        5
>>> CB27A        3
>>>
>>> where 'No.of changes' refer to the change in 3 months (201302-201305 for
>>> CB26A and 201304-201307 for CB27A).
>>>
>>> How can this be done in R?
>>>
>>> Regards,
>>> Abhinaba Roy
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From lbagua.cloud at gmail.com  Mon Aug  4 18:24:31 2014
From: lbagua.cloud at gmail.com (Luis Borda de Agua)
Date: Mon, 4 Aug 2014 17:24:31 +0100
Subject: [R] keep information on the number of warnings
Message-ID: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140804/65a4f630/attachment.pl>

From zilefacelvis at yahoo.com  Mon Aug  4 18:37:03 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 4 Aug 2014 09:37:03 -0700
Subject: [R] Convert some columns of List to dataframe R
In-Reply-To: <CAAJSdjhENVh3d+LhiS_sLGawQ9ahu5G9EUAgUchp3azi-nxGWQ@mail.gmail.com>
References: <1407103926.20001.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<CAAJSdjhENVh3d+LhiS_sLGawQ9ahu5G9EUAgUchp3azi-nxGWQ@mail.gmail.com>
Message-ID: <1407170223.80489.YahooMailNeo@web160604.mail.bf1.yahoo.com>

Great! Thanks, John.

For the eye sees not itself, but by reflection and someother things



On Sunday, August 3, 2014 4:54 PM, John McKown <john.archie.mckown at gmail.com> wrote:
On Sun, Aug 3, 2014 at 5:12 PM, Zilefac Elvis <zilefacelvis at yahoo.com> wrote:
> Dear All,
> I have a List in R and would like to convert it to data.frame.
> Below is a reproducible example. I can do something like:
>
> x1<-do.call(cbind.data.frame, lst3) #OR
> x1<-as.data.frame(lst3).
>
> However, my output looks like this:
>
> Year Site? x?  Year Site? x
> 2001 G101 33.1 2001 G102 34
>
> I would like to have as my output:
>
> Year? G101?  G102
> 2001? 33.1?  34
>
>
> Thanks
> Atem.
> ----------------------------------------------------------------------------------
>
>
>? list(structure(list(Year = 2001L, Site = structure(1L, .Label = "G101", class = "factor"),
>? ?  x = 33.1), .Names = c("Year", "Site", "x"), row.names = c(NA,
> -1L), class = "data.frame"), structure(list(Year = 2001L, Site = structure(1L, .Label = "G102", class = "factor"),
>? ?  x = 34), .Names = c("Year", "Site", "x"), row.names = c(NA,
> -1L), class = "data.frame"))
>


Try rbind_all in the dplyr package together with the dcast() function
in the reshpae2 package

output1 <- rbind_all(as.list(lst3));
realOutput <- dcast(output1, Year ~ Site, value.var="x");

Example transcript:

> lst3 <- list(structure(list(Year = 2001L, Site = structure(1L, .Label = "G101", class = "factor"),
+? ?  x = 33.1), .Names = c("Year", "Site", "x"), row.names = c(NA,
+ -1L), class = "data.frame"), structure(list(Year = 2001L, Site =
structure(1L, .Label = "G102", class = "factor"),
+? ?  x = 34), .Names = c("Year", "Site", "x"), row.names = c(NA,
+ -1L), class = "data.frame"))
> library(dplyr);
> rbind_all(lst3);
? Year Site? ? x
1 2001 G101 33.1
2 2001 G102 34.0
Warning message:
In rbind_all(lst3) : Unequal factor levels: coercing to character
> dcast(output1,Year ~ Site,value.var="x")



? Year G101 G102
1 2001 33.1?  34
>


Sorry for the extra reply.? 60 hour work weeks and 61 years of age
don't mix well. Back to watching Beakman on Netflix.


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown



From dwinsemius at comcast.net  Mon Aug  4 18:48:19 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 4 Aug 2014 09:48:19 -0700
Subject: [R] keep information on the number of warnings
In-Reply-To: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>
References: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>
Message-ID: <AD5B03FE-3CD8-4078-BB90-59BE78CBEEFB@comcast.net>


On Aug 4, 2014, at 9:24 AM, Luis Borda de Agua wrote:

> Dear David
> 
> Thank you very much for your reply. I?ve only seen it now.
> I tried length(warnings) and I got a strange result.
> 
> When I used 
> 
> lw <- length(warnings)
> print(lw)
> 
> I obtained lw=36 
> 
> however,  the number of warnings was 38 according to message to screen:
> 
> "There were 38 warnings (use warnings() to see them)"
> 
> (I?m listing the warning messages below.)
> 
> Why should these numbers be different?

I have just disproven my initial hypothesis that I formed upon reading the R code of `warnings` that it had to do with the environment in which the warning was generated:

> f <- function () { g(); warning ("outer warn") }
> g <- function() { warning("inner warn") }
> f()
Warning messages:
1: In g() : inner warn
2: In f() : outer warn
> warnings()
Warning messages:
1: In g() : inner warn
2: In f() : outer warn

So, I simply don't know (and you have provided no example to reproduce the issue). May I remind you to include context from earlier messages? Looking back at your first message the number 36 appears rather than 38. Perhaps the number of warning varies from run to run? You would wnat to compare the number from such a message to the output of length(warnings()) after the run rather than before it.

---------
>> I?m using R 3.1.0 in OS X 10.9.4 (Mavericks)
>> 
>> I?m running a function Y that calls a function X which occasionally generates a warning. 
>> Say that I call the function X 1000 times, and out of these 1000 times I get the following message:
>> 
>> "There were 36 warnings (use warnings() to see them)"
>> 
>> How can I store the number 36 in a variable in function Y?
>> 
>> In other words, how can I extract the information on the number of warnings generated?
> 
> length(warnings())

--------------------

David.

> 
> Thank you in advance, 
> 
> Lu?s
> 
>> warnings()
> Warning messages:
> 1: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 2: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 3: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 4: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 5: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 6: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 7: In stode(y, time, func, parms = parms, ...) :
>  error during factorisation of matrix (dgefa);         singular matrix
> 8: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 9: In stode(y, time, func, parms = parms, ...) :
>  error during factorisation of matrix (dgefa);         singular matrix
> 10: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 11: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 12: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 13: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 14: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 15: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 16: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 17: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 18: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 19: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 20: In stode(y, time, func, parms = parms, ...) :
>  error during factorisation of matrix (dgefa);         singular matrix
> 21: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 22: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 23: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 24: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 25: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 26: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 27: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 28: In stode(y, time, func, parms = parms, ...) :
>  error during factorisation of matrix (dgefa);         singular matrix
> 29: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 30: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 31: In stode(y, time, func, parms = parms, ...) :
>  error during factorisation of matrix (dgefa);         singular matrix
> 32: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 33: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 34: In stode(y, time, func, parms = parms, ...) :
>  error during factorisation of matrix (dgefa);         singular matrix
> 35: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 36: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 37: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 38: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 
> 
> 
> 
> 
> _______________________________
> Lu?s Borda de ?gua
> Centro de Biologia Ambiental
> Faculdade de Ci?ncias
> Universidade de Lisboa
> Edif?cio C2, 6? Piso, Sala 2.6.04/07 
> Campo Grande
> 1749-016 Lisboa, Portugal
> Tel: +351 21 750 00 00 (ext: 22607)
> Fax: +351 21 750 00 28
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From spencer.graves at structuremonitoring.com  Mon Aug  4 18:55:54 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 04 Aug 2014 09:55:54 -0700
Subject: [R] Normal probability plot examples for Wikipedia (was "qqnorm
 with histogram?")
In-Reply-To: <2386244.Srmg3LNeA7@localhost.localdomain>
References: <53DE8FA2.1010206@structuremonitoring.com>
	<2386244.Srmg3LNeA7@localhost.localdomain>
Message-ID: <53DFBB1A.8040000@structuremonitoring.com>

Hi, Jim et al.:


       Thanks for the reply, Jim.


       What are your favorite examples using normal probability plots to 
identify outliers, skewness, kurtosis, mixtures, and the need for 
transformations in plots of raw data and residuals from model fits -- or 
using half-normal plots with estimated parameters?


       I ask, because I believe the current Wikipedia article on "Normal 
probability plot" could be improved dramatically with a set of great 
examples.  I also plan to write a function to display a normal 
probability plot with a histogram, a density estimate, and a boxplot and 
use it with the examples.  My current plan is to create this with a 
function qqnormPlus(..., datax=TRUE, histargs, densityargs, boxplotargs) 
that passes histargs, densityargs and boxplotargs to truehist{MASS}, 
density, and boxplot, respectively.  I plan to add this to the Ecfun 
package (for which I'm the author and maintainer).


       This wikipedia article received 14774 views in the past 90 days, 
averaging not quite 700 per day, so I think it's worth doing.  I could 
use suggestions (and help from other Wikipedians on this list).


       Thanks,
       Spencer


On 8/3/2014 2:59 PM, Jim Lemon wrote:
> Hi Spencer,
> The last example for the twoord.plot function (plotrix) does this.
>
> Jim
>
> On Sun, 3 Aug 2014 12:38:10 PM Spencer Graves wrote:
>>         Does a function exist that combines a normal probability plot
>> with a histogram and maybe a density estimate on the same plot?
>>
>>
>>         I'm revising the Wikipedia article on "Normal probability plot",
>> and I think it would be good to provide examples of this.
>>
>>
>>         Thanks,
>>         Spencer
>>
>>
>> p.s.  Please reply also with suggestions for how to improve that
>> Wikipedia article if you feel so inclined.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From wdunlap at tibco.com  Mon Aug  4 19:04:26 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 4 Aug 2014 10:04:26 -0700
Subject: [R] keep information on the number of warnings
In-Reply-To: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>
References: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>
Message-ID: <CAF8bMcZo+zQ2PsLBmnjcZbWY0gd1+P0EH4p2WyNZA5Z0DogNJg@mail.gmail.com>

Look at withCallngHandlers for another way to capture warnings.  It
will let you attach warnings from an iteration of your function to the
output of the function so you can later track down the root cause of
the warning.

E.g., the attached captureWarningsAndMessagesWithContext attaches
warnings, messages, and errors to the output, along with a traceback
for each.

captureWarningsAndMessagesWithContext <-
function(expr) {

   warnings <- list()
   messages <- list()
   fmt <- function(cond, sysCalls) {
      c(Message = conditionMessage(cond),
        Call = deparse(conditionCall(cond))[1],
        rev(vapply(sysCalls, function(sc)deparse(sc)[1], "")))
   }
   retval <- list(result=withCallingHandlers(try(expr, silent=TRUE),
                                  warning=function(w){
                                      warnings[[length(warnings)+1]]
<<- fmt(w, sys.calls())
                                      invokeRestart("muffleWarning")
                                  },
                                  message=function(m){
                                      messages[[length(messages)+1]]
<<- fmt(m, sys.calls())
                                      invokeRestart("muffleMessage")
                                  }
                                 )
                  )
   # retval$result will have class "try-error" if there was an error,
   # which the caller can check for.
   retval$messages <- messages
   retval$warnings <- warnings
   retval
}

E.g.,

z <- lapply(list(log, lm, function(x)1/x),
function(fun)captureWarningsAndMessagesWithContext(fun(-1)))

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 4, 2014 at 9:24 AM, Luis Borda de Agua
<lbagua.cloud at gmail.com> wrote:
> Dear David
>
> Thank you very much for your reply. I?ve only seen it now.
> I tried length(warnings) and I got a strange result.
>
> When I used
>
> lw <- length(warnings)
> print(lw)
>
> I obtained lw=36
>
> however,  the number of warnings was 38 according to message to screen:
>
> "There were 38 warnings (use warnings() to see them)"
>
> (I?m listing the warning messages below.)
>
> Why should these numbers be different?
>
> Thank you in advance,
>
> Lu?s
>
>> warnings()
> Warning messages:
> 1: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 2: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 3: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 4: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 5: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 6: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 7: In stode(y, time, func, parms = parms, ...) :
>   error during factorisation of matrix (dgefa);         singular matrix
> 8: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 9: In stode(y, time, func, parms = parms, ...) :
>   error during factorisation of matrix (dgefa);         singular matrix
> 10: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 11: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 12: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 13: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 14: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 15: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 16: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 17: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 18: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 19: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 20: In stode(y, time, func, parms = parms, ...) :
>   error during factorisation of matrix (dgefa);         singular matrix
> 21: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 22: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 23: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 24: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 25: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 26: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 27: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 28: In stode(y, time, func, parms = parms, ...) :
>   error during factorisation of matrix (dgefa);         singular matrix
> 29: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 30: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 31: In stode(y, time, func, parms = parms, ...) :
>   error during factorisation of matrix (dgefa);         singular matrix
> 32: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 33: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 34: In stode(y, time, func, parms = parms, ...) :
>   error during factorisation of matrix (dgefa);         singular matrix
> 35: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 36: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 37: In stode(y, time, func, parms = parms, ...) : steady-state not reached
> 38: In stode(y, time, func, parms = parms, ...) : steady-state not reached
>
>
>
>
>
> _______________________________
> Lu?s Borda de ?gua
> Centro de Biologia Ambiental
> Faculdade de Ci?ncias
> Universidade de Lisboa
> Edif?cio C2, 6? Piso, Sala 2.6.04/07
> Campo Grande
> 1749-016 Lisboa, Portugal
> Tel: +351 21 750 00 00 (ext: 22607)
> Fax: +351 21 750 00 28
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From john.archie.mckown at gmail.com  Mon Aug  4 20:21:58 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 4 Aug 2014 13:21:58 -0500
Subject: [R] Compare data in two rows and replace objects in data frame
In-Reply-To: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
References: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
Message-ID: <CAAJSdjh5gorDSfP14xUgpJCsF2Zoky-q1K61fpaoED=jimihCw@mail.gmail.com>

On Mon, Aug 4, 2014 at 4:53 AM, raz <barvazduck at gmail.com> wrote:
> Dear all,
>
> I have a data frame 144 x 20000 values.
> I need to take every value in the first row and compare to the second row,
> and the same for rows 3-4 and 5-6 and so on.
> the output should be one line for each of the two row comparison.
> the comparison is:
> if row1==1 and row2==1 <-'HT'
> if row1==1 and row2==0 <-'A'
> if row1==0 and row2==1 <-'B'
> if row1==1 and row2=='-' <-'Aht'
> if row1=='-' and row2==1 <-'Bht'
>
> for example:
> if the data is:
> CloneID    genotype 2001    genotype 2002    genotype 2003
> 2471250    1    1    1
> 2471250    0    0    0
> 2433062    0    0    0
> 2433062    1    1    1
> 100021605    1    1    0
> 100021605    1    0    1
> 100005599    1    1    0
> 100005599    1    1    1
> 100002798    1    1    0
> 100002798    1    1    1
>
> then the output should be:
> CloneID    genotype 2001    genotype 2002    genotype 2003
> 2471250    A    A    A
> 2433062    B    B    B
> 100021605    HT    A    B
> 100005599    HT    HT    B
> 100002798    HT    HT    B
>
> I tried this for the whole data, but its so slow:
>
> AX <- data.frame(lapply(AX, as.character), stringsAsFactors=FALSE)
>
>
> for (i in seq(1,nrow(AX),by=2)){
> for (j in 6:144){
> if (AX[i,j]==1 & AX[i+1,j]==0){
> AX[i,j]<-'A'
> }
> if (AX[i,j]==0 & AX[i+1,j]==1){
> AX[i,j]<-'B'
> }
> if (AX[i,j]==1 & AX[i+1,j]==1){
> AX[i,j]<-'HT'
> }
> if (AX[i,j]==1 & AX[i+1,j]=="-"){
> AX[i,j]<-'Aht'
> }
> if (AX[i,j]=="-" & AX[i+1,j]==1){
> AX[i,j]<-'Bht'
> }
> }
> }
>
> AX1<-AX[!duplicated(AX[,3]),]
> AX2<-AX[duplicated(AX[,3]),]
>
> Thanks for any help,
>
> Raz

I don't know if you've received a solution as yet. Below is my generic
solution. I don't know how fast it will be, but it does _NOT_ do any
looping. It does do a few if functions. The result is in the variable
new_data. The variables data_odd and data_even are temporaries which
can be removed. Or you can wrap the code up in a function which
returns new_data and they will simply "go away" when the function
ends.

#
# Read in the data
data <- read.csv(file="data.csv",header=TRUE,stringsAsFactors=FALSE);
#
# The criteria
#if row1==1 and row2==1 <-'HT'
#if row1==1 and row2==0 <-'A'
#if row1==0 and row2==1 <-'B'
#if row1==1 and row2=='-' <-'Aht'
#if row1=='-' and row2==1 <-'Bht'
#
# The following assumes that data is properly ordered!
data$rowNumber <- seq(1:nrow(data));
data_odd <-data[data$rowNumber %% 2 == 1,];
data_even <-data[data$rowNumber %% 2 == 0,];
#
# You really need to make sure that
# the CloneID values are correct in data_odd
# and data_even. Something like:
stopifnot(data_odd$CloneID == data_even$CloneID);
CloneIDs <- data_even[,1]; # Get the list of CloneIDs
#data_even[,1] <- NULL; # Remove CloneIDs from even data
#data_odd[,1] <- NULL;  # And also from odd data
#
# Initialize new_data - make everything NA so
# it will stick out later!
new_data <- data_even;
new_data[,colnames(data_even)] <- NA;
#
new_data[data_odd == 1 & data_odd ==1] <- 'HT';
new_data[data_odd == 1 & data_even == 0] <- 'A';
new_data[data_odd == 0 & data_even == 1] <- 'B';
new_data[data_odd == 1 & data_even == '.'] <- 'Aht';
new_data[data_odd == '-' & data_even == 1] <- 'Bht';
new_data$CloneID <- CloneIDs;
new_data$rowNumber<-NULL;
#
#stopifnot( !is.na(new_data)); # Make sure no NAs left




-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jholtman at gmail.com  Mon Aug  4 21:56:29 2014
From: jholtman at gmail.com (jim holtman)
Date: Mon, 4 Aug 2014 15:56:29 -0400
Subject: [R] Compare data in two rows and replace objects in data frame
In-Reply-To: <CAAJSdjh5gorDSfP14xUgpJCsF2Zoky-q1K61fpaoED=jimihCw@mail.gmail.com>
References: <CAGHW+oK6SbRzUXnRG7y0Pc35wnO22vUkqfgvdNDLJnWH3ehgTw@mail.gmail.com>
	<CAAJSdjh5gorDSfP14xUgpJCsF2Zoky-q1K61fpaoED=jimihCw@mail.gmail.com>
Message-ID: <CAAxdm-5wnLTRUm3K9hWg5jXG4yN5jS0M4-2ESJ-68PyJsF0+Zg@mail.gmail.com>

here is another way of doing it using 'tidyr' and 'dplyr'


> x <- read.table(text = "CloneID    genotype2001    genotype2002    genotype2003
+ 2471250    1    1    1
+ 2471250    0    0    0
+ 2433062    0    0    0
+ 2433062    1    1    1
+ 100021605    1    1    0
+ 100021605    1    0    1
+ 100005599    1    1    0
+ 100005599    1    1    1
+ 100002798    1    1    0
+ 100002798    1    1    1", header = TRUE, as.is = TRUE)
> # translation key
> keyTrans <- c(`11` = 'HT'
+       , `10` = "A"
+       , `01` = "B"
+       , `1-` = "Aht"
+       , `-1` = "Bht"
+       )
> require(dplyr)
> require(tidyr)
> x %>%
+     gather(key, val, -CloneID) %>%  # 'melt' the data
+     group_by(CloneID, key) %>%  # group by CloneID
+     summarise(newKey = paste0(val, collapse = '')) %>%  # add concat
to two rows
+     mutate(newVal = keyTrans[newKey]) %>%  # add the new value
+     select(-newKey) %>%  # remove newKey for output
+     spread(key, newVal)
Source: local data frame [5 x 4]

    CloneID genotype2001 genotype2002 genotype2003
1   2433062            B            B            B
2   2471250            A            A            A
3 100002798           HT           HT            B
4 100005599           HT           HT            B
5 100021605           HT            A            B

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Mon, Aug 4, 2014 at 2:21 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Mon, Aug 4, 2014 at 4:53 AM, raz <barvazduck at gmail.com> wrote:
>> Dear all,
>>
>> I have a data frame 144 x 20000 values.
>> I need to take every value in the first row and compare to the second row,
>> and the same for rows 3-4 and 5-6 and so on.
>> the output should be one line for each of the two row comparison.
>> the comparison is:
>> if row1==1 and row2==1 <-'HT'
>> if row1==1 and row2==0 <-'A'
>> if row1==0 and row2==1 <-'B'
>> if row1==1 and row2=='-' <-'Aht'
>> if row1=='-' and row2==1 <-'Bht'
>>
>> for example:
>> if the data is:
>> CloneID    genotype 2001    genotype 2002    genotype 2003
>> 2471250    1    1    1
>> 2471250    0    0    0
>> 2433062    0    0    0
>> 2433062    1    1    1
>> 100021605    1    1    0
>> 100021605    1    0    1
>> 100005599    1    1    0
>> 100005599    1    1    1
>> 100002798    1    1    0
>> 100002798    1    1    1
>>
>> then the output should be:
>> CloneID    genotype 2001    genotype 2002    genotype 2003
>> 2471250    A    A    A
>> 2433062    B    B    B
>> 100021605    HT    A    B
>> 100005599    HT    HT    B
>> 100002798    HT    HT    B
>>
>> I tried this for the whole data, but its so slow:
>>
>> AX <- data.frame(lapply(AX, as.character), stringsAsFactors=FALSE)
>>
>>
>> for (i in seq(1,nrow(AX),by=2)){
>> for (j in 6:144){
>> if (AX[i,j]==1 & AX[i+1,j]==0){
>> AX[i,j]<-'A'
>> }
>> if (AX[i,j]==0 & AX[i+1,j]==1){
>> AX[i,j]<-'B'
>> }
>> if (AX[i,j]==1 & AX[i+1,j]==1){
>> AX[i,j]<-'HT'
>> }
>> if (AX[i,j]==1 & AX[i+1,j]=="-"){
>> AX[i,j]<-'Aht'
>> }
>> if (AX[i,j]=="-" & AX[i+1,j]==1){
>> AX[i,j]<-'Bht'
>> }
>> }
>> }
>>
>> AX1<-AX[!duplicated(AX[,3]),]
>> AX2<-AX[duplicated(AX[,3]),]
>>
>> Thanks for any help,
>>
>> Raz
>
> I don't know if you've received a solution as yet. Below is my generic
> solution. I don't know how fast it will be, but it does _NOT_ do any
> looping. It does do a few if functions. The result is in the variable
> new_data. The variables data_odd and data_even are temporaries which
> can be removed. Or you can wrap the code up in a function which
> returns new_data and they will simply "go away" when the function
> ends.
>
> #
> # Read in the data
> data <- read.csv(file="data.csv",header=TRUE,stringsAsFactors=FALSE);
> #
> # The criteria
> #if row1==1 and row2==1 <-'HT'
> #if row1==1 and row2==0 <-'A'
> #if row1==0 and row2==1 <-'B'
> #if row1==1 and row2=='-' <-'Aht'
> #if row1=='-' and row2==1 <-'Bht'
> #
> # The following assumes that data is properly ordered!
> data$rowNumber <- seq(1:nrow(data));
> data_odd <-data[data$rowNumber %% 2 == 1,];
> data_even <-data[data$rowNumber %% 2 == 0,];
> #
> # You really need to make sure that
> # the CloneID values are correct in data_odd
> # and data_even. Something like:
> stopifnot(data_odd$CloneID == data_even$CloneID);
> CloneIDs <- data_even[,1]; # Get the list of CloneIDs
> #data_even[,1] <- NULL; # Remove CloneIDs from even data
> #data_odd[,1] <- NULL;  # And also from odd data
> #
> # Initialize new_data - make everything NA so
> # it will stick out later!
> new_data <- data_even;
> new_data[,colnames(data_even)] <- NA;
> #
> new_data[data_odd == 1 & data_odd ==1] <- 'HT';
> new_data[data_odd == 1 & data_even == 0] <- 'A';
> new_data[data_odd == 0 & data_even == 1] <- 'B';
> new_data[data_odd == 1 & data_even == '.'] <- 'Aht';
> new_data[data_odd == '-' & data_even == 1] <- 'Bht';
> new_data$CloneID <- CloneIDs;
> new_data$rowNumber<-NULL;
> #
> #stopifnot( !is.na(new_data)); # Make sure no NAs left
>
>
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Mon Aug  4 22:34:15 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Mon, 4 Aug 2014 20:34:15 +0000
Subject: [R] Normal probability plot examples for Wikipedia (was "qqnorm
	with histogram?")
References: <53DE8FA2.1010206@structuremonitoring.com>
	<2386244.Srmg3LNeA7@localhost.localdomain>
	<53DFBB1A.8040000@structuremonitoring.com>
Message-ID: <loom.20140804T222002-310@post.gmane.org>

Spencer Graves <spencer.graves <at> structuremonitoring.com> writes:

> 
> Hi, Jim et al.:
> 
>        Thanks for the reply, Jim.
> 
>        What are your favorite examples using normal probability plots to 
> identify outliers, skewness, kurtosis, mixtures, and the need for 
> transformations in plots of raw data and residuals from model fits -- or 
> using half-normal plots with estimated parameters?
> 

Not sure I have a *favorite*, but the so-called "Fisher's iris data" 
provide an illustration of an obvious mixture and the value of conditioning.

Try:

 qqnorm(iris$Petal.Length,col=as.numeric(iris$Species))
 qqnorm(residuals(lm(Petal.Length~Species,iris)))

As a bonus, you can reference this pretty page:

 http://en.wikipedia.org/wiki/Iris_%28plant%29

where the contributions of the iris to water purification, art, and
symbolism are noted. 

Maybe a section on the iris in statistics... ;-)


HTH,

Chuck


From thanoon.younis80 at gmail.com  Tue Aug  5 03:08:10 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Tue, 5 Aug 2014 04:08:10 +0300
Subject: [R] simulation data with dichotomous varuables
Message-ID: <CABLo8nGMh32m+Ci5sZnQ3DaW_HqinKjZ=j63isWfZheOm7T+6Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/60474848/attachment.pl>

From zilefacelvis at yahoo.com  Tue Aug  5 03:17:23 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Mon, 4 Aug 2014 18:17:23 -0700
Subject: [R] Apply quantile function to each dataframe in a List R
Message-ID: <1407201443.69661.YahooMailNeo@web160603.mail.bf1.yahoo.com>

Hello,
I would like to calculate for each numeric column in a dataframe, quantile(x,probs=o.95).
My list object has 120 dataframes, each dataframe has 102 columns.
Here is an example as well as a reproducible example:

[[120]] 
? Year Site Sim001 Sim002 Sim003 Sim004 Sim005 Sim006 Sim007 Sim008 Sim009 Sim010 Sim011 Sim012 Sim013 Sim014 Sim015
...
1 2001 GGG9 -26.96 -27.30 -31.62 -31.56 -28.58 -33.82 -32.53 -30.56 -34.09 -31.94 -28.85 -30.76 -25.44 -31.83 -32.98 
2 2002 GGG9 -32.57 -39.15 -32.87 -32.91 -32.50 -35.35 -31.82 -38.22 -37.76 -36.70 -38.07 -36.99 -35.78 -33.61 -34.47 
3 2003 GGG9 -37.14 -33.33 -31.53 -32.37 -37.97 -35.00 -31.79 -36.03 -34.48 -43.28 -30.47 -33.91 -39.28 -33.28 -34.13


I have tried something like:

output<-lapply(lst3,function(x) quantile(x,0.95,na.rm = TRUE)) but failed.

Please help.
AT.


list(structure(list(Year = 2001:2005, Site = structure(c(1L, 
1L, 1L, 1L, 1L), .Label = "G100", class = "factor"), Sim001 = c(-33.25, 
-37.52, -34.58, -36.56, -41.62), Sim002 = c(-29.39, -29.35, -36.49, 
-37.82, -31.6), Sim003 = c(-35.24, -35.2, -41.98, -32.87, -35.92 
), Sim004 = c(-33.41, -38.76, -34.92, -34.46, -38.54), Sim005 = c(-38.22, 
-40.83, -37.55, -39.85, -39.02), Sim006 = c(-39.5, -34.35, -35.35, 
-37.08, -31.21), Sim007 = c(-31.24, -32.77, -35.44, -41.1, -31.81 
), Sim008 = c(-31.34, -32.61, -41.48, -49.67, -37.88), Sim009 = c(-33.62, 
-41.62, -35.9, -35.3, -30.11), Sim010 = c(-39.99, -41.97, -36.96, 
-47.55, -30.46), Sim011 = c(-34.39, -39.31, -33.68, -33.83, -39.24 
), Sim012 = c(-33.38, -39.17, -41.91, -42.09, -37.97), Sim013 = c(-31.29, 
-36.91, -34.52, -39.92, -50.34), Sim014 = c(-26, -43.03, -39.93, 
-39.49, -40.47), Sim015 = c(-36.16, -40.72, -41.89, -38.75, -40.51 
), Sim016 = c(-34.6, -47.22, -43.12, -42.55, -31.65), Sim017 = c(-35.47, 
-50.25, -38.42, -39.82, -46.7), Sim018 = c(-40.57, -32.57, -35.16, 
-42.74, -36.55), Sim019 = c(-34.48, -39.42, -33.47, -40.78, -42.11 
), Sim020 = c(-37.23, -43.42, -37, -41.89, -33.36), Sim021 = c(-32.85, 
-37.18, -37.75, -38.22, -36.5), Sim022 = c(-42.2, -31.78, -38.01, 
-43.85, -40.05), Sim023 = c(-36.94, -40.03, -42.37, -33.45, -36.9 
), Sim024 = c(-40.03, -32.38, -45.69, -39.67, -36.97), Sim025 = c(-31.62, 
-45.37, -39.73, -39.7, -40.93), Sim026 = c(-32.57, -38.02, -40.12, 
-39.19, -41.55), Sim027 = c(-35.85, -31.56, -40.41, -47.34, -33.9 
), Sim028 = c(-34.7, -38.88, -46.31, -32.77, -36.01), Sim029 = c(-36.67, 
-51.07, -38.01, -39.3, -34.99), Sim030 = c(-30.54, -42.89, -35.83, 
-42.01, -38.85), Sim031 = c(-31.85, -40.38, -37.87, -38.88, -40.28 
), Sim032 = c(-33.56, -36.81, -37.11, -38.8, -34.17), Sim033 = c(-37.87, 
-38.4, -39.56, -39.82, -36.37), Sim034 = c(-37.13, -32.84, -42.93, 
-37.4, -44.44), Sim035 = c(-26.66, -41.08, -40.88, -39.22, -40.84 
), Sim036 = c(-34.51, -44.35, -39.38, -33.86, -33.55), Sim037 = c(-33.89, 
-33.5, -37.59, -53.07, -36.6), Sim038 = c(-35.14, -34.92, -36.96, 
-43.16, -44.19), Sim039 = c(-31.4, -33.95, -39.67, -39.75, -38.53 
), Sim040 = c(-33.18, -32.84, -36.04, -39.64, -40.71), Sim041 = c(-37.38, 
-32.74, -44.38, -45.02, -43.96), Sim042 = c(-28.09, -34.78, -42.21, 
-43.18, -40.85), Sim043 = c(-36.86, -35.93, -42.46, -41.11, -42.35 
), Sim044 = c(-35.3, -41.2, -36.65, -44.91, -49.74), Sim045 = c(-32.84, 
-37.83, -42.22, -41.14, -37.1), Sim046 = c(-32.85, -41.35, -37.01, 
-35.27, -41.13), Sim047 = c(-38.19, -49.26, -40.83, -35.04, -38.49 
), Sim048 = c(-37.98, -37.82, -40.33, -35.01, -36.94), Sim049 = c(-40.37, 
-34.5, -39.55, -45.6, -31.79), Sim050 = c(-40.67, -36.04, -47.68, 
-38.26, -46.9), Sim051 = c(-37.13, -31.42, -38.49, -36.58, -38.52 
), Sim052 = c(-43.54, -32.82, -37.32, -41.71, -37.87), Sim053 = c(-31.61, 
-37.32, -40.25, -37.24, -49.9), Sim054 = c(-38.85, -33.53, -46.48, 
-38.27, -34.13), Sim055 = c(-30.71, -40.04, -43.77, -33.78, -33.5 
), Sim056 = c(-30.3, -36.91, -38.49, -36.69, -31.43), Sim057 = c(-27.56, 
-37.13, -39.45, -45.52, -33.24), Sim058 = c(-33.47, -35.26, -33.83, 
-42.43, -45.4), Sim059 = c(-36.46, -35.64, -39.62, -37.95, -41.32 
), Sim060 = c(-39.12, -41.71, -36.28, -36.27, -36.94), Sim061 = c(-29.86, 
-45.73, -37.04, -43.84, -36.87), Sim062 = c(-29.46, -40.96, -39.43, 
-41.75, -38.83), Sim063 = c(-36.48, -41.18, -39.59, -41.01, -36.31 
), Sim064 = c(-32.49, -38.86, -33.16, -40.2, -32.65), Sim065 = c(-35.37, 
-39.73, -41.7, -44.36, -41.26), Sim066 = c(-36.78, -38.5, -38.72, 
-42.46, -39.25), Sim067 = c(-38.12, -37.92, -34.8, -35.18, -33.63 
), Sim068 = c(-31.75, -36.77, -32.5, -44.28, -36.65), Sim069 = c(-33.48, 
-46.06, -39.48, -42.89, -39.72), Sim070 = c(-33.53, -36.53, -36.28, 
-37.78, -39.22), Sim071 = c(-36.27, -42.68, -35.28, -38.86, -36.63 
), Sim072 = c(-34.63, -34.58, -41.13, -41.34, -43.57), Sim073 = c(-32.21, 
-31.49, -42.97, -38.86, -34.91), Sim074 = c(-30.95, -35.74, -39.91, 
-41.75, -35.61), Sim075 = c(-39.26, -37.01, -42.23, -49.56, -44.93 
), Sim076 = c(-37.78, -44.19, -36.35, -36.26, -31.09), Sim077 = c(-33.75, 
-37.06, -36.3, -41.04, -40.1), Sim078 = c(-41.82, -40.69, -41.61, 
-37.41, -34.37), Sim079 = c(-30.45, -35.66, -33.88, -39.71, -37.5 
), Sim080 = c(-43.67, -31.8, -38.37, -35.14, -35.67), Sim081 = c(-28.79, 
-37.91, -39.82, -39.59, -41.77), Sim082 = c(-35.58, -37, -37.97, 
-41.14, -47.98), Sim083 = c(-32.37, -34.27, -33.67, -38.93, -40.38 
), Sim084 = c(-33.81, -40.81, -36.3, -42.71, -38.43), Sim085 = c(-30.21, 
-34.81, -40.97, -36.55, -41.82), Sim086 = c(-32.24, -37.59, -40.06, 
-39.55, -40.69), Sim087 = c(-37.48, -38.07, -36.43, -36.04, -39.13 
), Sim088 = c(-34.27, -39.35, -37.89, -42.24, -37.19), Sim089 = c(-36.11, 
-46.55, -32.86, -50.21, -41.44), Sim090 = c(-30.37, -40.42, -49.72, 
-35.55, -40.1), Sim091 = c(-34.51, -35.69, -41, -35.08, -39.19 
), Sim092 = c(-37.19, -41.45, -42.98, -38.96, -33.84), Sim093 = c(-35.54, 
-43.21, -38.24, -43.51, -32.87), Sim094 = c(-35.79, -36.46, -38.3, 
-43, -46.64), Sim095 = c(-34.6, -38.21, -40.7, -41.43, -33.44 
), Sim096 = c(-29.59, -40.29, -37.99, -35.51, -34.79), Sim097 = c(-31.38, 
-40.3, -40.68, -35.82, -38.22), Sim098 = c(-34.85, -37.81, -38.07, 
-38.12, -32.17), Sim099 = c(-32.57, -39.43, -35.26, -41.84, -42.15 
), Sim100 = c(-34.39, -32.95, -37.06, -36.26, -30.58)), .Names = c("Year", 
"Site", "Sim001", "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", 
"Sim007", "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", "Sim013", 
"Sim014", "Sim015", "Sim016", "Sim017", "Sim018", "Sim019", "Sim020", 
"Sim021", "Sim022", "Sim023", "Sim024", "Sim025", "Sim026", "Sim027", 
"Sim028", "Sim029", "Sim030", "Sim031", "Sim032", "Sim033", "Sim034", 
"Sim035", "Sim036", "Sim037", "Sim038", "Sim039", "Sim040", "Sim041", 
"Sim042", "Sim043", "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", 
"Sim049", "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", "Sim055", 
"Sim056", "Sim057", "Sim058", "Sim059", "Sim060", "Sim061", "Sim062", 
"Sim063", "Sim064", "Sim065", "Sim066", "Sim067", "Sim068", "Sim069", 
"Sim070", "Sim071", "Sim072", "Sim073", "Sim074", "Sim075", "Sim076", 
"Sim077", "Sim078", "Sim079", "Sim080", "Sim081", "Sim082", "Sim083", 
"Sim084", "Sim085", "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", 
"Sim091", "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", "Sim097", 
"Sim098", "Sim099", "Sim100"), row.names = c(NA, -5L), class = "data.frame"), 
? ? structure(list(Year = 2001:2005, Site = structure(c(1L, 1L, 
? ? 1L, 1L, 1L), .Label = "G101", class = "factor"), Sim001 = c(-35.72, 
? ? -40.46, -34.77, -36.67, -40.73), Sim002 = c(-31.3, -34.13, 
? ? -39.98, -37.32, -30.51), Sim003 = c(-33.55, -38.12, -36.56, 
? ? -33.5, -38.3), Sim004 = c(-30.05, -33.87, -39.94, -34.18, 
? ? -38.63), Sim005 = c(-37.27, -34.94, -38.96, -42.79, -41.19 
? ? ), Sim006 = c(-35.63, -36.82, -38.13, -36.87, -34.98), Sim007 = c(-27.59, 
? ? -32.98, -36.89, -40.25, -32.3), Sim008 = c(-29.54, -34.74, 
? ? -41.02, -43.63, -40.14), Sim009 = c(-30.72, -44, -35.83, 
? ? -38.21, -36.12), Sim010 = c(-39.46, -38.1, -39.13, -46, -30.59 
? ? ), Sim011 = c(-36.48, -38.52, -36.77, -38.19, -38.11), Sim012 = c(-36.71, 
? ? -38.23, -40.25, -51.31, -42.63), Sim013 = c(-34.24, -40.3, 
? ? -34.01, -39.42, -44.07), Sim014 = c(-33.1, -37.49, -36.55, 
? ? -40.24, -38.44), Sim015 = c(-33.53, -37.84, -41.59, -43.04, 
? ? -44.72), Sim016 = c(-35.15, -44.57, -44.93, -42.42, -35.56 
? ? ), Sim017 = c(-33.02, -48.07, -36.57, -35.63, -50.69), Sim018 = c(-42.67, 
? ? -33.15, -33.92, -48.02, -39.98), Sim019 = c(-33.02, -39.16, 
? ? -34.91, -42.18, -38.37), Sim020 = c(-34.67, -37.89, -38.49, 
? ? -41.72, -35.06), Sim021 = c(-35.24, -35.49, -35.58, -38.7, 
? ? -35.2), Sim022 = c(-41.75, -33, -41.26, -43.6, -39.82), Sim023 = c(-38.13, 
? ? -39.35, -42.01, -40.49, -36.56), Sim024 = c(-32.5, -37.02, 
? ? -43.16, -42.43, -40.16), Sim025 = c(-37.41, -37.95, -39.31, 
? ? -39.6, -39.21), Sim026 = c(-38.24, -36.08, -42.63, -40.08, 
? ? -40.83), Sim027 = c(-35.6, -35.03, -43.19, -42.29, -34.04 
? ? ), Sim028 = c(-35.86, -40.89, -48.83, -36.61, -33.78), Sim029 = c(-35.75, 
? ? -52.6, -40.65, -39.12, -34.27), Sim030 = c(-33.19, -41.71, 
? ? -38.1, -41.99, -36.21), Sim031 = c(-34.71, -31.96, -35.52, 
? ? -42.43, -41.16), Sim032 = c(-34.41, -42.28, -34.63, -40.58, 
? ? -34.14), Sim033 = c(-36.83, -35.83, -37.24, -41.1, -36.8), 
? ? ? ? Sim034 = c(-39.72, -32.03, -45.69, -38.42, -42.68), Sim035 = c(-31.91, 
? ? ? ? -35.69, -39.09, -38.06, -39.2), Sim036 = c(-33.61, -35.02, 
? ? ? ? -36.76, -32.55, -38.27), Sim037 = c(-35.76, -30.48, -36.53, 
? ? ? ? -49.4, -38.2), Sim038 = c(-35, -37.81, -40.07, -41.6, 
? ? ? ? -42.33), Sim039 = c(-33.28, -38.22, -39.09, -37.44, -41.18 
? ? ? ? ), Sim040 = c(-32.33, -36.15, -34.09, -41.64, -46.83), 
? ? ? ? Sim041 = c(-39.17, -31.42, -41.74, -44.58, -39.88), Sim042 = c(-32.27, 
? ? ? ? -33.52, -37.12, -43.51, -43.07), Sim043 = c(-35.33, -36.37, 
? ? ? ? -42.72, -45.01, -41.98), Sim044 = c(-32.73, -36.37, -32.04, 
? ? ? ? -39.35, -48.59), Sim045 = c(-33.78, -33.79, -41.64, -38.53, 
? ? ? ? -42.21), Sim046 = c(-29.21, -36.07, -36.12, -41.03, -38.14 
? ? ? ? ), Sim047 = c(-36.78, -50.09, -44.88, -34.3, -35.55), 
? ? ? ? Sim048 = c(-33.83, -37.92, -41.95, -39.73, -37.8), Sim049 = c(-35.56, 
? ? ? ? -35.14, -37.47, -45.06, -33.87), Sim050 = c(-38.84, -37.11, 
? ? ? ? -44.97, -38.83, -38.13), Sim051 = c(-35, -34.96, -38.11, 
? ? ? ? -34.21, -37.84), Sim052 = c(-45.4, -31.3, -39.58, -42.74, 
? ? ? ? -38.96), Sim053 = c(-36.48, -35.9, -35.84, -38.88, -40.25 
? ? ? ? ), Sim054 = c(-36.2, -36.94, -43.45, -41.74, -32.93), 
? ? ? ? Sim055 = c(-38.29, -48.66, -38.54, -38.47, -44.17), Sim056 = c(-30.97, 
? ? ? ? -39.42, -34.94, -34.87, -36.19), Sim057 = c(-30.09, -37.7, 
? ? ? ? -38.06, -40.45, -35.23), Sim058 = c(-35.06, -37.86, -34.46, 
? ? ? ? -39.21, -43.58), Sim059 = c(-41.69, -36.31, -42.44, -36, 
? ? ? ? -40.72), Sim060 = c(-35.29, -37.92, -39.94, -36.1, -36.01 
? ? ? ? ), Sim061 = c(-32.32, -46.74, -37.7, -40.31, -34.93), 
? ? ? ? Sim062 = c(-30.24, -38.33, -39.18, -44.22, -35.74), Sim063 = c(-36.82, 
? ? ? ? -37.58, -37.82, -37.38, -36.65), Sim064 = c(-36.99, -36.13, 
? ? ? ? -33.74, -48.8, -33.04), Sim065 = c(-40.79, -40.89, -39.36, 
? ? ? ? -41.78, -42.82), Sim066 = c(-35.63, -35.94, -41.35, -39.79, 
? ? ? ? -34.41), Sim067 = c(-32.66, -36.93, -33.61, -36.58, -35.46 
? ? ? ? ), Sim068 = c(-31.08, -32.84, -31.69, -41.63, -37.7), 
? ? ? ? Sim069 = c(-31.23, -50.18, -38.75, -39.19, -37.59), Sim070 = c(-34.93, 
? ? ? ? -38.12, -34.11, -38.38, -38.24), Sim071 = c(-35.74, -42.9, 
? ? ? ? -31.74, -34.78, -44.95), Sim072 = c(-33.39, -38.35, -34.4, 
? ? ? ? -43.7, -37.92), Sim073 = c(-33.88, -33.28, -34.27, -41.27, 
? ? ? ? -41.41), Sim074 = c(-28.67, -42.77, -34.62, -46.53, -34.9 
? ? ? ? ), Sim075 = c(-36.69, -38.74, -38.26, -43.82, -46.61), 
? ? ? ? Sim076 = c(-37.98, -41.69, -37.9, -39.37, -35.59), Sim077 = c(-32.68, 
? ? ? ? -36.56, -33.24, -37.02, -46.38), Sim078 = c(-44.5, -39.4, 
? ? ? ? -37.77, -36.31, -36.6), Sim079 = c(-31.59, -40.09, -35.52, 
? ? ? ? -38.87, -35.44), Sim080 = c(-39.49, -35.56, -35.18, -37.17, 
? ? ? ? -40.51), Sim081 = c(-34.43, -31.35, -41.73, -38.51, -41.08 
? ? ? ? ), Sim082 = c(-35.31, -35.39, -40.4, -39.26, -43.16), 
? ? ? ? Sim083 = c(-31.32, -36.31, -37.74, -38.15, -42.86), Sim084 = c(-35.2, 
? ? ? ? -37.24, -37.75, -37.89, -34.88), Sim085 = c(-29.85, -34.98, 
? ? ? ? -39.61, -42.36, -42.27), Sim086 = c(-33.35, -34.59, -36.62, 
? ? ? ? -34.5, -37.19), Sim087 = c(-33.74, -35.5, -43.51, -39.54, 
? ? ? ? -41.67), Sim088 = c(-33.61, -42.81, -42.08, -41.47, -47.35 
? ? ? ? ), Sim089 = c(-34.98, -40.7, -39.39, -46.97, -38.84), 
? ? ? ? Sim090 = c(-31.32, -35.78, -44.32, -41.76, -36.65), Sim091 = c(-27.79, 
? ? ? ? -35.75, -38.54, -39.24, -42.84), Sim092 = c(-36.96, -43.48, 
? ? ? ? -39.4, -42.39, -30.09), Sim093 = c(-36.98, -38.15, -45, 
? ? ? ? -49.77, -41.58), Sim094 = c(-35.32, -36.29, -45.47, -47.33, 
? ? ? ? -45), Sim095 = c(-31.5, -40.29, -48.72, -43.27, -35.98 
? ? ? ? ), Sim096 = c(-28.22, -33.74, -43.51, -40.02, -36.04), 
? ? ? ? Sim097 = c(-33.17, -36.45, -37.88, -37.84, -42.69), Sim098 = c(-32.03, 
? ? ? ? -37.82, -37.01, -35.38, -32.66), Sim099 = c(-36.53, -40.44, 
? ? ? ? -39.56, -40.32, -37.81), Sim100 = c(-36.95, -36.72, -40.74, 
? ? ? ? -33.22, -34.43)), .Names = c("Year", "Site", "Sim001", 
? ? "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", "Sim007", 
? ? "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", "Sim013", 
? ? "Sim014", "Sim015", "Sim016", "Sim017", "Sim018", "Sim019", 
? ? "Sim020", "Sim021", "Sim022", "Sim023", "Sim024", "Sim025", 
? ? "Sim026", "Sim027", "Sim028", "Sim029", "Sim030", "Sim031", 
? ? "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", "Sim037", 
? ? "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", "Sim043", 
? ? "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", "Sim049", 
? ? "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", "Sim055", 
? ? "Sim056", "Sim057", "Sim058", "Sim059", "Sim060", "Sim061", 
? ? "Sim062", "Sim063", "Sim064", "Sim065", "Sim066", "Sim067", 
? ? "Sim068", "Sim069", "Sim070", "Sim071", "Sim072", "Sim073", 
? ? "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", "Sim079", 
? ? "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", "Sim085", 
? ? "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", "Sim091", 
? ? "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", "Sim097", 
? ? "Sim098", "Sim099", "Sim100"), row.names = c(NA, -5L), class = "data.frame"), 
? ? structure(list(Year = 2001:2005, Site = structure(c(1L, 1L, 
? ? 1L, 1L, 1L), .Label = "G102", class = "factor"), Sim001 = c(-40.62, 
? ? -37.27, -37.53, -43.76, -42.51), Sim002 = c(-33.33, -35.19, 
? ? -42.13, -37.15, -46.41), Sim003 = c(-44.2, -39.86, -46.55, 
? ? -37.25, -38.49), Sim004 = c(-31.5, -37.68, -40.08, -41.95, 
? ? -40.33), Sim005 = c(-37.87, -41.85, -37.11, -38.35, -43.68 
? ? ), Sim006 = c(-41.31, -31.61, -39.66, -35.78, -38.77), Sim007 = c(-36.9, 
? ? -35.99, -34.29, -37.65, -30.86), Sim008 = c(-35.2, -33.42, 
? ? -39.12, -41.26, -35.69), Sim009 = c(-31.93, -43.89, -42.59, 
? ? -38.03, -36.91), Sim010 = c(-38.69, -38.84, -34.32, -44.7, 
? ? -29.88), Sim011 = c(-39.2, -34.19, -34.08, -40.39, -42.32 
? ? ), Sim012 = c(-34.25, -41.45, -43.21, -50.36, -43.02), Sim013 = c(-32.35, 
? ? -39.33, -34.82, -39.06, -45.33), Sim014 = c(-32.33, -43.5, 
? ? -42.81, -47.21, -44.55), Sim015 = c(-31.1, -39.91, -50.22, 
? ? -41.63, -43.79), Sim016 = c(-32.52, -42.62, -48.88, -39.38, 
? ? -34.97), Sim017 = c(-35.47, -52.51, -37.02, -44.71, -52.77 
? ? ), Sim018 = c(-39.97, -34.88, -36.02, -44.74, -33.23), Sim019 = c(-32.58, 
? ? -32.32, -32.29, -43.36, -35.73), Sim020 = c(-32, -37.72, 
? ? -40.59, -34.75, -31.45), Sim021 = c(-37.74, -37.62, -35.17, 
? ? -36.5, -42.72), Sim022 = c(-42.19, -34.63, -38.28, -43.9, 
? ? -41.87), Sim023 = c(-41.18, -42.32, -40.06, -40.63, -33.83 
? ? ), Sim024 = c(-40.14, -40.55, -43.76, -41.95, -50.76), Sim025 = c(-30.44, 
? ? -40.62, -36.87, -45.74, -36.98), Sim026 = c(-38.55, -41.58, 
? ? -49.46, -40.63, -51.32), Sim027 = c(-33.19, -38.66, -42.39, 
? ? -41.83, -33.1), Sim028 = c(-35.83, -35.23, -50.56, -33.6, 
? ? -34.93), Sim029 = c(-33.98, -37.57, -38.01, -40.92, -37.51 
? ? ), Sim030 = c(-38.81, -40.79, -41.1, -42.03, -45.8), Sim031 = c(-34.05, 
? ? -38.83, -37.74, -43.99, -38.18), Sim032 = c(-34.87, -40.79, 
? ? -38.09, -38.43, -42.38), Sim033 = c(-39.74, -38.4, -40.35, 
? ? -45.41, -34.98), Sim034 = c(-36.85, -32.07, -42.36, -39.03, 
? ? -38.68), Sim035 = c(-31.57, -40.68, -37.95, -40.75, -37.13 
? ? ), Sim036 = c(-34.82, -36.98, -44.33, -44.7, -35.61), Sim037 = c(-35.32, 
? ? -37.59, -37.94, -44.46, -40.68), Sim038 = c(-35.71, -36.72, 
? ? -45.25, -38.16, -45.11), Sim039 = c(-36.37, -34.24, -38.03, 
? ? -35.55, -35.8), Sim040 = c(-43.41, -34.82, -33.63, -44, -48.42 
? ? ), Sim041 = c(-43.29, -31.97, -40.91, -46.15, -44.63), Sim042 = c(-34.25, 
? ? -33.76, -42.41, -43.59, -42.92), Sim043 = c(-36.36, -33.15, 
? ? -45.19, -36.73, -51.78), Sim044 = c(-37.85, -44.35, -36.37, 
? ? -41.43, -53.1), Sim045 = c(-38.04, -36.34, -38.05, -43.83, 
? ? -43.02), Sim046 = c(-28.7, -42.97, -34.55, -40.56, -40.94 
? ? ), Sim047 = c(-39.88, -46.68, -41.36, -43.09, -31), Sim048 = c(-37.09, 
? ? -34.54, -37.11, -48.75, -36.7), Sim049 = c(-35.54, -34.34, 
? ? -35.8, -43.58, -35.13), Sim050 = c(-39.59, -45.63, -44.75, 
? ? -35.5, -37.07), Sim051 = c(-38.17, -31.99, -38.92, -38.13, 
? ? -40.66), Sim052 = c(-44.17, -35.03, -45.3, -43.51, -36.45 
? ? ), Sim053 = c(-35.52, -38.32, -34.76, -36.59, -41.24), Sim054 = c(-39.43, 
? ? -39.11, -47.01, -42.33, -35.26), Sim055 = c(-34.33, -43.12, 
? ? -38.63, -43.82, -51.05), Sim056 = c(-34.94, -43.37, -37.49, 
? ? -34.57, -32.98), Sim057 = c(-35.38, -32.65, -49.09, -44.89, 
? ? -40.88), Sim058 = c(-39.09, -43.04, -31.79, -40.37, -41.23 
? ? ), Sim059 = c(-39.47, -40.79, -47.84, -36.72, -49.66), Sim060 = c(-36.48, 
? ? -41.99, -38.48, -39.66, -36.1), Sim061 = c(-39.36, -40.56, 
? ? -44.59, -37.83, -35.45), Sim062 = c(-29.6, -32.92, -39.52, 
? ? -42.98, -45.97), Sim063 = c(-35.06, -44.32, -36.05, -37.41, 
? ? -41.21), Sim064 = c(-33.32, -37.99, -37.85, -43.07, -43.29 
? ? ), Sim065 = c(-38.73, -39.87, -34.27, -42.26, -38.71), Sim066 = c(-35.29, 
? ? -35.61, -38, -40.85, -40.6), Sim067 = c(-30.4, -35.99, -35.96, 
? ? -40.05, -36.87), Sim068 = c(-33.62, -31.69, -34.9, -44.52, 
? ? -42.11), Sim069 = c(-36.36, -41.2, -42.53, -41.74, -44.36 
? ? ), Sim070 = c(-38.29, -39.97, -43.54, -39.9, -40.2), Sim071 = c(-47.72, 
? ? -35.3, -37.38, -38.67, -44.35), Sim072 = c(-32.77, -36.11, 
? ? -48.05, -40.8, -37.5), Sim073 = c(-31.8, -39.98, -40.24, 
? ? -40.68, -39.57), Sim074 = c(-33.81, -36.13, -37.15, -41.12, 
? ? -37.21), Sim075 = c(-40.31, -34.72, -43.92, -44.15, -35.55 
? ? ), Sim076 = c(-37.94, -43.22, -39.26, -40.01, -33.97), Sim077 = c(-33.4, 
? ? -37.88, -33.63, -34.79, -45.12), Sim078 = c(-38.07, -42.02, 
? ? -40.8, -38.25, -37.12), Sim079 = c(-33.46, -37.29, -36.92, 
? ? -41.32, -38.1), Sim080 = c(-46.57, -40.74, -41.11, -42.31, 
? ? -34.04), Sim081 = c(-38.62, -35.2, -36.77, -38.14, -43.05 
? ? ), Sim082 = c(-35.79, -36.56, -46.18, -40.54, -42.1), Sim083 = c(-43.49, 
? ? -33.1, -38, -44.12, -41.49), Sim084 = c(-35.27, -36.59, -38.25, 
? ? -38.27, -43.32), Sim085 = c(-37.58, -38.02, -39.88, -42.14, 
? ? -47.23), Sim086 = c(-35.12, -44.91, -34.98, -36.92, -37.08 
? ? ), Sim087 = c(-38.66, -38.45, -35.04, -41.71, -46.15), Sim088 = c(-33.65, 
? ? -47.5, -40.09, -41.56, -43.83), Sim089 = c(-32.45, -45.71, 
? ? -39.03, -44.84, -40.36), Sim090 = c(-33.14, -31.6, -38.07, 
? ? -40.11, -42.19), Sim091 = c(-31.1, -35.64, -40.64, -38.19, 
? ? -39.22), Sim092 = c(-36.96, -43.76, -46.34, -39.22, -38.1 
? ? ), Sim093 = c(-38.09, -42.55, -40.7, -44.82, -39.33), Sim094 = c(-31.96, 
? ? -38.54, -39.77, -44.94, -45.04), Sim095 = c(-32.6, -47.83, 
? ? -43.8, -45.24, -34.54), Sim096 = c(-36.22, -37.52, -35.93, 
? ? -40.2, -40.46), Sim097 = c(-32.07, -42.11, -44.64, -35.17, 
? ? -41.68), Sim098 = c(-31.02, -38.79, -48.49, -45.02, -38.24 
? ? ), Sim099 = c(-34.04, -39.06, -41.09, -38.55, -40.75), Sim100 = c(-37.59, 
? ? -39.68, -39.13, -43.9, -34.38)), .Names = c("Year", "Site", 
? ? "Sim001", "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", 
? ? "Sim007", "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", 
? ? "Sim013", "Sim014", "Sim015", "Sim016", "Sim017", "Sim018", 
? ? "Sim019", "Sim020", "Sim021", "Sim022", "Sim023", "Sim024", 
? ? "Sim025", "Sim026", "Sim027", "Sim028", "Sim029", "Sim030", 
? ? "Sim031", "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", 
? ? "Sim037", "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", 
? ? "Sim043", "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", 
? ? "Sim049", "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", 
? ? "Sim055", "Sim056", "Sim057", "Sim058", "Sim059", "Sim060", 
? ? "Sim061", "Sim062", "Sim063", "Sim064", "Sim065", "Sim066", 
? ? "Sim067", "Sim068", "Sim069", "Sim070", "Sim071", "Sim072", 
? ? "Sim073", "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", 
? ? "Sim079", "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", 
? ? "Sim085", "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", 
? ? "Sim091", "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", 
? ? "Sim097", "Sim098", "Sim099", "Sim100"), row.names = c(NA, 
? ? -5L), class = "data.frame"), structure(list(Year = 2001:2005, 
? ? ? ? Site = structure(c(1L, 1L, 1L, 1L, 1L), .Label = "G103", class = "factor"), 
? ? ? ? Sim001 = c(-34.91, -42.24, -38.32, -39.49, -41.63), Sim002 = c(-35.11, 
? ? ? ? -37.81, -41.05, -43.21, -50.25), Sim003 = c(-36.13, -40.39, 
? ? ? ? -49.12, -41.86, -47.06), Sim004 = c(-33.37, -33.63, -47.03, 
? ? ? ? -38, -49.28), Sim005 = c(-40.03, -42.55, -42.88, -38.11, 
? ? ? ? -40.87), Sim006 = c(-46.76, -37.75, -38.98, -38.8, -40.65 
? ? ? ? ), Sim007 = c(-40.41, -45.3, -40.05, -49.72, -33.92), 
? ? ? ? Sim008 = c(-31.46, -36.97, -41.32, -40.57, -40.16), Sim009 = c(-39.7, 
? ? ? ? -41.49, -40.46, -44.86, -44.03), Sim010 = c(-37.03, -41.86, 
? ? ? ? -36.02, -51.36, -39.13), Sim011 = c(-36.14, -38.88, -40.28, 
? ? ? ? -45.71, -42.73), Sim012 = c(-37.49, -37.51, -46.96, -37.35, 
? ? ? ? -40.04), Sim013 = c(-36.18, -44.23, -44.28, -40.35, -52.88 
? ? ? ? ), Sim014 = c(-37.27, -44.4, -39.46, -39.44, -44.47), 
? ? ? ? Sim015 = c(-32.21, -40.48, -51.07, -33.53, -41.74), Sim016 = c(-37.68, 
? ? ? ? -45.96, -50.48, -45.77, -36.38), Sim017 = c(-38.25, -50.61, 
? ? ? ? -42.92, -42.78, -38.37), Sim018 = c(-41.61, -46.64, -42.91, 
? ? ? ? -55.36, -35.43), Sim019 = c(-38.72, -45.85, -38.88, -42.35, 
? ? ? ? -42.97), Sim020 = c(-32.26, -39.23, -39.6, -42.26, -34.94 
? ? ? ? ), Sim021 = c(-40.59, -34.78, -41.04, -43.97, -45.7), 
? ? ? ? Sim022 = c(-39.48, -40.89, -40.85, -41.11, -42.33), Sim023 = c(-37.3, 
? ? ? ? -34.49, -47.63, -45.14, -39.37), Sim024 = c(-38.78, -37.49, 
? ? ? ? -44.5, -45.34, -47.99), Sim025 = c(-34.19, -42.08, -36.19, 
? ? ? ? -50.84, -40.62), Sim026 = c(-41.91, -35.46, -37.68, -46.45, 
? ? ? ? -52.34), Sim027 = c(-42.88, -33.61, -36.19, -40.09, -33.83 
? ? ? ? ), Sim028 = c(-40.86, -41.5, -47.46, -35.82, -35.96), 
? ? ? ? Sim029 = c(-34.66, -38.41, -41.58, -45.07, -41.27), Sim030 = c(-44.26, 
? ? ? ? -40.97, -36.97, -39.22, -43), Sim031 = c(-35.2, -37.12, 
? ? ? ? -38.88, -42.92, -38.1), Sim032 = c(-38.09, -47.5, -35.93, 
? ? ? ? -45.35, -39.17), Sim033 = c(-37.09, -40.74, -45.38, -40.93, 
? ? ? ? -42.53), Sim034 = c(-35.89, -43.9, -43.09, -37.7, -40.32 
? ? ? ? ), Sim035 = c(-35.42, -40.64, -36.52, -39.38, -43.69), 
? ? ? ? Sim036 = c(-41.5, -44.56, -37.54, -41.08, -36.99), Sim037 = c(-38.72, 
? ? ? ? -42.6, -39.6, -46.68, -43.74), Sim038 = c(-37.23, -41.2, 
? ? ? ? -40.94, -44.48, -39.99), Sim039 = c(-38.92, -34.03, -38.41, 
? ? ? ? -44.57, -35.76), Sim040 = c(-37.22, -43.06, -32.85, -43.75, 
? ? ? ? -39.27), Sim041 = c(-34.34, -38.87, -38.55, -48.6, -42.69 
? ? ? ? ), Sim042 = c(-35.63, -41.5, -42.8, -46.96, -46.9), Sim043 = c(-39.37, 
? ? ? ? -37.65, -47.55, -43.64, -43.57), Sim044 = c(-31.85, -41.71, 
? ? ? ? -39.78, -41.94, -50.5), Sim045 = c(-35.13, -37.94, -41.3, 
? ? ? ? -42.85, -43.23), Sim046 = c(-37.41, -40.9, -38.73, -43.07, 
? ? ? ? -41.67), Sim047 = c(-33.55, -45.2, -41.38, -38.33, -37.88 
? ? ? ? ), Sim048 = c(-35.3, -40.77, -42.6, -47.29, -36.95), 
? ? ? ? Sim049 = c(-40.23, -38.81, -39.38, -51.63, -36.48), Sim050 = c(-37.63, 
? ? ? ? -47.48, -44.29, -40.44, -38.51), Sim051 = c(-32.98, -38.85, 
? ? ? ? -35.89, -35.81, -40.39), Sim052 = c(-40.74, -41.71, -49.75, 
? ? ? ? -39.13, -37.5), Sim053 = c(-35.83, -45.92, -35.75, -44.91, 
? ? ? ? -48.89), Sim054 = c(-46.45, -36.2, -41.18, -43.26, -34.57 
? ? ? ? ), Sim055 = c(-35.25, -41.67, -40.72, -43.52, -47.1), 
? ? ? ? Sim056 = c(-38.54, -37.55, -42.31, -41.33, -34.96), Sim057 = c(-37.28, 
? ? ? ? -40.86, -58.32, -44.67, -38.59), Sim058 = c(-37.72, -48.88, 
? ? ? ? -39.47, -38.33, -46.02), Sim059 = c(-36.72, -38.11, -41.73, 
? ? ? ? -44.15, -42.25), Sim060 = c(-40.57, -47.78, -40.79, -38.02, 
? ? ? ? -40.6), Sim061 = c(-36.37, -43.07, -42.21, -44.35, -38.35 
? ? ? ? ), Sim062 = c(-32.27, -38.33, -40.9, -37.72, -38.12), 
? ? ? ? Sim063 = c(-39.41, -42.64, -40.81, -41.87, -43.33), Sim064 = c(-41.71, 
? ? ? ? -39.46, -41.42, -43.64, -42.69), Sim065 = c(-33.84, -38.52, 
? ? ? ? -35.67, -43.9, -41.93), Sim066 = c(-36.41, -38.93, -41.07, 
? ? ? ? -43.29, -35.73), Sim067 = c(-34.69, -45.12, -41.62, -38.78, 
? ? ? ? -36.64), Sim068 = c(-36.26, -35.96, -38.58, -39.53, -40.16 
? ? ? ? ), Sim069 = c(-34.69, -47.3, -38.21, -43.42, -46.25), 
? ? ? ? Sim070 = c(-35.01, -38.36, -47.65, -40.83, -41.36), Sim071 = c(-39.15, 
? ? ? ? -41.21, -36.62, -46.28, -42.84), Sim072 = c(-44.71, -45.82, 
? ? ? ? -40.26, -40.4, -41.46), Sim073 = c(-35.74, -33.98, -42.36, 
? ? ? ? -41.69, -37.04), Sim074 = c(-37.99, -37.42, -49.56, -45.38, 
? ? ? ? -41.59), Sim075 = c(-37.44, -44.24, -37.15, -44.85, -41.69 
? ? ? ? ), Sim076 = c(-40.93, -38.26, -41.7, -39.92, -36.81), 
? ? ? ? Sim077 = c(-38.08, -38.67, -33.17, -36.44, -42.84), Sim078 = c(-46.26, 
? ? ? ? -43.16, -37.74, -40.36, -36.77), Sim079 = c(-35.52, -41.16, 
? ? ? ? -33.79, -44.9, -46.44), Sim080 = c(-39.88, -37.29, -41.45, 
? ? ? ? -38.75, -38.25), Sim081 = c(-39.54, -32.9, -43.92, -38.87, 
? ? ? ? -43.6), Sim082 = c(-32.96, -38.36, -39.64, -43.91, -37.25 
? ? ? ? ), Sim083 = c(-36.54, -42.41, -42.34, -43.73, -41.38), 
? ? ? ? Sim084 = c(-41.51, -38.58, -35.42, -38.42, -34.48), Sim085 = c(-35.38, 
? ? ? ? -38.46, -42.68, -44.68, -42.16), Sim086 = c(-35.7, -45.14, 
? ? ? ? -39.84, -34.68, -41.49), Sim087 = c(-36.91, -41.04, -38.04, 
? ? ? ? -49.18, -46.52), Sim088 = c(-31.25, -38.84, -36.13, -49.96, 
? ? ? ? -43.36), Sim089 = c(-26.85, -40.06, -39.45, -48.14, -38.64 
? ? ? ? ), Sim090 = c(-31.54, -34.96, -45.27, -36.24, -41.06), 
? ? ? ? Sim091 = c(-37.09, -37.95, -41.81, -43.44, -41.8), Sim092 = c(-34.37, 
? ? ? ? -42.68, -39.87, -38.18, -32.36), Sim093 = c(-36.61, -38.72, 
? ? ? ? -36.32, -42.26, -48.61), Sim094 = c(-39.41, -39.01, -41.36, 
? ? ? ? -42.44, -47.68), Sim095 = c(-38.78, -42.32, -40.45, -49.57, 
? ? ? ? -37.16), Sim096 = c(-34.61, -41.53, -40.55, -40.74, -33.42 
? ? ? ? ), Sim097 = c(-38.13, -40.1, -44.91, -35.95, -42.76), 
? ? ? ? Sim098 = c(-36.75, -39.87, -41.55, -42.8, -34.67), Sim099 = c(-33.04, 
? ? ? ? -41.33, -41.84, -39.15, -39.98), Sim100 = c(-41.84, -40.85, 
? ? ? ? -47.33, -44.61, -38.4)), .Names = c("Year", "Site", "Sim001", 
? ? "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", "Sim007", 
? ? "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", "Sim013", 
? ? "Sim014", "Sim015", "Sim016", "Sim017", "Sim018", "Sim019", 
? ? "Sim020", "Sim021", "Sim022", "Sim023", "Sim024", "Sim025", 
? ? "Sim026", "Sim027", "Sim028", "Sim029", "Sim030", "Sim031", 
? ? "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", "Sim037", 
? ? "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", "Sim043", 
? ? "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", "Sim049", 
? ? "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", "Sim055", 
? ? "Sim056", "Sim057", "Sim058", "Sim059", "Sim060", "Sim061", 
? ? "Sim062", "Sim063", "Sim064", "Sim065", "Sim066", "Sim067", 
? ? "Sim068", "Sim069", "Sim070", "Sim071", "Sim072", "Sim073", 
? ? "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", "Sim079", 
? ? "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", "Sim085", 
? ? "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", "Sim091", 
? ? "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", "Sim097", 
? ? "Sim098", "Sim099", "Sim100"), row.names = c(NA, -5L), class = "data.frame"), 
? ? structure(list(Year = 2001:2005, Site = structure(c(1L, 1L, 
? ? 1L, 1L, 1L), .Label = "G104", class = "factor"), Sim001 = c(-38.9, 
? ? -34.54, -38.17, -42.04, -39.37), Sim002 = c(-33.01, -38.22, 
? ? -37.76, -36.92, -51.14), Sim003 = c(-36.33, -33.4, -37.7, 
? ? -43.03, -32.22), Sim004 = c(-32.53, -45.02, -45.45, -40.35, 
? ? -43.27), Sim005 = c(-36.05, -38.23, -41.92, -37.98, -49.21 
? ? ), Sim006 = c(-38.92, -35.83, -36.06, -34.24, -35.54), Sim007 = c(-36.53, 
? ? -33.69, -41.31, -45.93, -32.42), Sim008 = c(-34.01, -34.26, 
? ? -42.05, -44.43, -39.2), Sim009 = c(-37.2, -42.21, -36.86, 
? ? -36.7, -34.85), Sim010 = c(-44.79, -38.11, -36.54, -43.57, 
? ? -32.3), Sim011 = c(-40.68, -41.05, -35.3, -41.74, -35.85), 
? ? ? ? Sim012 = c(-38.93, -34.81, -41.23, -42.03, -41.15), Sim013 = c(-36.71, 
? ? ? ? -39.32, -37.85, -41.29, -50.13), Sim014 = c(-33.22, -42.64, 
? ? ? ? -34.95, -41.25, -41.54), Sim015 = c(-27.32, -39.84, -43.44, 
? ? ? ? -43.31, -45.82), Sim016 = c(-36.31, -43.67, -44.39, -44.95, 
? ? ? ? -37.77), Sim017 = c(-35.26, -50.88, -37.54, -45.98, -46.66 
? ? ? ? ), Sim018 = c(-43.28, -41.66, -38.46, -44.32, -35.62), 
? ? ? ? Sim019 = c(-34.7, -41.41, -39.42, -40.32, -39.8), Sim020 = c(-37.55, 
? ? ? ? -37.77, -38.25, -38.65, -33.74), Sim021 = c(-30.2, -35.93, 
? ? ? ? -33.2, -37.85, -41.03), Sim022 = c(-40.31, -38.09, -39.18, 
? ? ? ? -40.87, -51.5), Sim023 = c(-36.85, -40.68, -45.11, -39.73, 
? ? ? ? -39.62), Sim024 = c(-41.48, -35.31, -44.76, -37.24, -46.36 
? ? ? ? ), Sim025 = c(-34.69, -41.95, -43.05, -41.93, -34.23), 
? ? ? ? Sim026 = c(-34.24, -40.88, -39.36, -48.67, -45.18), Sim027 = c(-38.95, 
? ? ? ? -38.1, -35, -45.55, -37.15), Sim028 = c(-34.04, -43.52, 
? ? ? ? -47, -34.74, -39.38), Sim029 = c(-32.5, -40.65, -37.96, 
? ? ? ? -38.2, -37.79), Sim030 = c(-34.43, -42.13, -42.07, -38.1, 
? ? ? ? -42.18), Sim031 = c(-36.69, -41.35, -39.82, -42.21, -37.83 
? ? ? ? ), Sim032 = c(-37.01, -39.77, -35.61, -43.39, -42.19), 
? ? ? ? Sim033 = c(-34.16, -35.87, -37.26, -42.02, -41.65), Sim034 = c(-35.6, 
? ? ? ? -37.43, -36.06, -37.48, -35.07), Sim035 = c(-36.73, -37.46, 
? ? ? ? -39.47, -39.99, -39.92), Sim036 = c(-33.23, -36.53, -41.41, 
? ? ? ? -39.91, -41.29), Sim037 = c(-37.67, -34.37, -45.38, -46.11, 
? ? ? ? -38.67), Sim038 = c(-36.29, -35.77, -42.69, -40.77, -42.59 
? ? ? ? ), Sim039 = c(-36.48, -32.16, -40.69, -36.52, -35.85), 
? ? ? ? Sim040 = c(-36.96, -39.49, -32.89, -39, -44.6), Sim041 = c(-37.45, 
? ? ? ? -38.17, -38.05, -39.96, -43.14), Sim042 = c(-33.89, -38.47, 
? ? ? ? -39.28, -47.24, -40.35), Sim043 = c(-35.8, -39.1, -48.85, 
? ? ? ? -39.82, -40.66), Sim044 = c(-34.71, -36.45, -36.38, -41.85, 
? ? ? ? -48.04), Sim045 = c(-35.27, -40.57, -37.27, -42.86, -43.2 
? ? ? ? ), Sim046 = c(-39.56, -47.44, -42.44, -46.44, -39.22), 
? ? ? ? Sim047 = c(-37.1, -41.25, -39.04, -42.13, -34.86), Sim048 = c(-37.64, 
? ? ? ? -34.26, -37.1, -41.67, -36.88), Sim049 = c(-32.65, -32.27, 
? ? ? ? -41.38, -46.08, -39.3), Sim050 = c(-34.56, -44.51, -40.37, 
? ? ? ? -42.03, -35.15), Sim051 = c(-40.71, -41.49, -38.77, -39.39, 
? ? ? ? -45.27), Sim052 = c(-44.87, -36.76, -37.49, -42.01, -40.1 
? ? ? ? ), Sim053 = c(-42.59, -41.12, -37.51, -40.59, -36.53), 
? ? ? ? Sim054 = c(-45.76, -41.83, -47.43, -36.45, -37.5), Sim055 = c(-36.82, 
? ? ? ? -36.79, -43.26, -42.57, -40.27), Sim056 = c(-32.67, -39.79, 
? ? ? ? -43.04, -37.49, -39.3), Sim057 = c(-34.1, -35.39, -37.94, 
? ? ? ? -50.67, -34.52), Sim058 = c(-34.29, -37.04, -35.8, -40.1, 
? ? ? ? -39.7), Sim059 = c(-39.59, -32.86, -42.71, -38.94, -45.85 
? ? ? ? ), Sim060 = c(-44.08, -42.37, -44.43, -37.32, -39.26), 
? ? ? ? Sim061 = c(-38.05, -39.61, -45.93, -40.56, -39.69), Sim062 = c(-31.21, 
? ? ? ? -35.97, -38.78, -43.4, -37.32), Sim063 = c(-35.34, -40.71, 
? ? ? ? -40.02, -36.25, -40.32), Sim064 = c(-44.73, -36.72, -36.19, 
? ? ? ? -44.45, -48.59), Sim065 = c(-32.72, -45.4, -33.36, -42.75, 
? ? ? ? -50.86), Sim066 = c(-33.12, -40.81, -41.6, -38.42, -35.93 
? ? ? ? ), Sim067 = c(-32.26, -38.45, -36, -39.26, -36.56), Sim068 = c(-36.53, 
? ? ? ? -38.71, -39.94, -40.84, -36.22), Sim069 = c(-39.6, -47.15, 
? ? ? ? -38.72, -46.39, -41.39), Sim070 = c(-37.83, -48.15, -37.94, 
? ? ? ? -39.7, -39.23), Sim071 = c(-49.75, -42.82, -35.91, -35.08, 
? ? ? ? -41.43), Sim072 = c(-40.16, -36.99, -40.09, -39.94, -42.35 
? ? ? ? ), Sim073 = c(-30.3, -41.3, -41.85, -38.41, -45.58), 
? ? ? ? Sim074 = c(-34.4, -36.63, -42.29, -45.9, -47.07), Sim075 = c(-37.47, 
? ? ? ? -43.69, -34.87, -42.15, -46.66), Sim076 = c(-40.79, -37.95, 
? ? ? ? -42.26, -41.58, -36.4), Sim077 = c(-32.54, -38.49, -33.33, 
? ? ? ? -39.02, -37.83), Sim078 = c(-38.54, -41.83, -37.91, -42.65, 
? ? ? ? -37.18), Sim079 = c(-39.13, -38.63, -33.65, -36.41, -43.77 
? ? ? ? ), Sim080 = c(-42.03, -42.47, -43.68, -34.88, -34.89), 
? ? ? ? Sim081 = c(-36.4, -34.11, -41.44, -38.61, -46.57), Sim082 = c(-35.68, 
? ? ? ? -38.53, -38.77, -35.27, -39.6), Sim083 = c(-35.52, -41.8, 
? ? ? ? -36.28, -40.92, -41.15), Sim084 = c(-36.67, -35.51, -36.83, 
? ? ? ? -38.78, -38.03), Sim085 = c(-44.2, -34.53, -39.89, -39.93, 
? ? ? ? -40.49), Sim086 = c(-33.88, -38.81, -34.62, -39.35, -42.93 
? ? ? ? ), Sim087 = c(-37.02, -35.38, -49.91, -42.51, -47.33), 
? ? ? ? Sim088 = c(-33.51, -36.32, -37.01, -39.46, -41.32), Sim089 = c(-29.18, 
? ? ? ? -42.67, -38.41, -45.18, -44.61), Sim090 = c(-29.05, -32.94, 
? ? ? ? -46.38, -34.2, -41.94), Sim091 = c(-32.24, -37.59, -38.77, 
? ? ? ? -40.72, -39.48), Sim092 = c(-42.79, -44.5, -41.99, -40.21, 
? ? ? ? -36.8), Sim093 = c(-36.65, -41.11, -41.12, -44.01, -37.67 
? ? ? ? ), Sim094 = c(-34.95, -44.86, -42.27, -40.73, -56.48), 
? ? ? ? Sim095 = c(-33.53, -38.83, -38.39, -40.82, -34.69), Sim096 = c(-42.41, 
? ? ? ? -36.12, -37.16, -33.86, -43.24), Sim097 = c(-35.1, -38.71, 
? ? ? ? -45.1, -39.18, -42.39), Sim098 = c(-32.08, -39.93, -39.66, 
? ? ? ? -40.71, -31.58), Sim099 = c(-37.41, -42.6, -37.58, -39.89, 
? ? ? ? -39.03), Sim100 = c(-38.75, -38.33, -42.42, -40.29, -35.67 
? ? ? ? )), .Names = c("Year", "Site", "Sim001", "Sim002", "Sim003", 
? ? "Sim004", "Sim005", "Sim006", "Sim007", "Sim008", "Sim009", 
? ? "Sim010", "Sim011", "Sim012", "Sim013", "Sim014", "Sim015", 
? ? "Sim016", "Sim017", "Sim018", "Sim019", "Sim020", "Sim021", 
? ? "Sim022", "Sim023", "Sim024", "Sim025", "Sim026", "Sim027", 
? ? "Sim028", "Sim029", "Sim030", "Sim031", "Sim032", "Sim033", 
? ? "Sim034", "Sim035", "Sim036", "Sim037", "Sim038", "Sim039", 
? ? "Sim040", "Sim041", "Sim042", "Sim043", "Sim044", "Sim045", 
? ? "Sim046", "Sim047", "Sim048", "Sim049", "Sim050", "Sim051", 
? ? "Sim052", "Sim053", "Sim054", "Sim055", "Sim056", "Sim057", 
? ? "Sim058", "Sim059", "Sim060", "Sim061", "Sim062", "Sim063", 
? ? "Sim064", "Sim065", "Sim066", "Sim067", "Sim068", "Sim069", 
? ? "Sim070", "Sim071", "Sim072", "Sim073", "Sim074", "Sim075", 
? ? "Sim076", "Sim077", "Sim078", "Sim079", "Sim080", "Sim081", 
? ? "Sim082", "Sim083", "Sim084", "Sim085", "Sim086", "Sim087", 
? ? "Sim088", "Sim089", "Sim090", "Sim091", "Sim092", "Sim093", 
? ? "Sim094", "Sim095", "Sim096", "Sim097", "Sim098", "Sim099", 
? ? "Sim100"), row.names = c(NA, -5L), class = "data.frame"))



From rhelpmaillist at 163.com  Tue Aug  5 04:58:58 2014
From: rhelpmaillist at 163.com (rhelpmaillist)
Date: Tue, 5 Aug 2014 10:58:58 +0800 (CST)
Subject: [R] Apply quantile function to each dataframe in a List R
In-Reply-To: <1407201443.69661.YahooMailNeo@web160603.mail.bf1.yahoo.com>
References: <1407201443.69661.YahooMailNeo@web160603.mail.bf1.yahoo.com>
Message-ID: <1b8f9ba0.4305.147a41afecc.Coremail.rhelpmaillist@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/f29ab292/attachment.pl>

From dialvac-r at yahoo.de  Tue Aug  5 11:36:36 2014
From: dialvac-r at yahoo.de (Alain D.)
Date: Tue, 5 Aug 2014 11:36:36 +0200 (CEST)
Subject: [R] extract descriptive stats for categorial data from dataframe
Message-ID: <116154108.990531.1407231397559.open-xchange@patina.store>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/2c20205b/attachment.pl>

From lingyi.ma at gmail.com  Tue Aug  5 08:51:56 2014
From: lingyi.ma at gmail.com (Lingyi Ma)
Date: Tue, 5 Aug 2014 09:51:56 +0300
Subject: [R] How to optimizing the code for calculating the launch time
Message-ID: <CACB+=Lif7R0sFJXL2pDJkEntU=-qs9ZG6woaUSFj9tchokrh8A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/d96f2cf1/attachment.pl>

From pdalgd at gmail.com  Tue Aug  5 11:55:17 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 5 Aug 2014 11:55:17 +0200
Subject: [R] Normal probability plot examples for Wikipedia (was "qqnorm
	with histogram?")
In-Reply-To: <53DFBB1A.8040000@structuremonitoring.com>
References: <53DE8FA2.1010206@structuremonitoring.com>
	<2386244.Srmg3LNeA7@localhost.localdomain>
	<53DFBB1A.8040000@structuremonitoring.com>
Message-ID: <6731EB1B-5FA6-4702-BD9F-1DDE5105D5D0@gmail.com>

Not that I want to get deeply involved with this, but techniques that allow you to take the random variation of the plots into account are badly needed in practice. I mean, running qqnorm(rnorm(10)) a dozen times _ought_ to cure you of overinterpreting plots that are not bang-on a straight line but have apparent curvature, outliers, etc., but tell that to students these days... 

Confidence bands would be good to include. Various techniques are in circulation; I believe John Fox implemented one for Rcmdr/car. I seem to recall that these are based on the binomial distribution or its asymptotic approximation. 

If you are qqnorm()-in residuals, the theory for constructing CI's for the normal plot breaks down and you need to resort to simulation techniques, e.g. something like

> Y <-  rgamma(10, 5)
> qqnorm(scale(Y))
> for (i in 1:10) lines(qqnorm(sort(scale(rnorm(10))),plot=FALSE), col="lightgray")

-pd

On 04 Aug 2014, at 18:55 , Spencer Graves <spencer.graves at structuremonitoring.com> wrote:

> Hi, Jim et al.:
> 
> 
>      Thanks for the reply, Jim.
> 
> 
>      What are your favorite examples using normal probability plots to identify outliers, skewness, kurtosis, mixtures, and the need for transformations in plots of raw data and residuals from model fits -- or using half-normal plots with estimated parameters?
> 
> 
>      I ask, because I believe the current Wikipedia article on "Normal probability plot" could be improved dramatically with a set of great examples.  I also plan to write a function to display a normal probability plot with a histogram, a density estimate, and a boxplot and use it with the examples.  My current plan is to create this with a function qqnormPlus(..., datax=TRUE, histargs, densityargs, boxplotargs) that passes histargs, densityargs and boxplotargs to truehist{MASS}, density, and boxplot, respectively.  I plan to add this to the Ecfun package (for which I'm the author and maintainer).
> 
> 
>      This wikipedia article received 14774 views in the past 90 days, averaging not quite 700 per day, so I think it's worth doing.  I could use suggestions (and help from other Wikipedians on this list).
> 
> 
>      Thanks,
>      Spencer
> 
> 
> On 8/3/2014 2:59 PM, Jim Lemon wrote:
>> Hi Spencer,
>> The last example for the twoord.plot function (plotrix) does this.
>> 
>> Jim
>> 
>> On Sun, 3 Aug 2014 12:38:10 PM Spencer Graves wrote:
>>>        Does a function exist that combines a normal probability plot
>>> with a histogram and maybe a density estimate on the same plot?
>>> 
>>> 
>>>        I'm revising the Wikipedia article on "Normal probability plot",
>>> and I think it would be good to provide examples of this.
>>> 
>>> 
>>>        Thanks,
>>>        Spencer
>>> 
>>> 
>>> p.s.  Please reply also with suggestions for how to improve that
>>> Wikipedia article if you feel so inclined.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mestre.frederico at gmail.com  Tue Aug  5 12:27:54 2014
From: mestre.frederico at gmail.com (Frederico Mestre)
Date: Tue, 5 Aug 2014 11:27:54 +0100
Subject: [R] Generate quasi-random positive numbers
Message-ID: <CAPfBvqyvV5H650M9vDaY5AtbAodKDfkYkDFeH2CU2ju+PJgFNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/57b08925/attachment.pl>

From teresamarso at hotmail.com  Tue Aug  5 12:35:19 2014
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Tue, 5 Aug 2014 10:35:19 +0000
Subject: [R] Library(mice) too slow for my dataset
Message-ID: <DUB125-W846D9D3137B365EC5A9732B9E30@phx.gbl>

Hi to everyone

I have a big dataset (40.000 columns (variables) and 50 rows)

I want to impute a lot of ?variables ?with ?library(mice), the problem is that this process is too slow (because of my dataset, the library is brilliant).

I am looking some options like Amazon web services, (?http://aws.amazon.com/es/datapipeline/developer-resources/?)

Has anyone used this service or knows other options?

Any ideas are welcome.

Thanks in advance

 		 	   		  

From Ted.Harding at wlandres.net  Tue Aug  5 12:46:55 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Tue, 05 Aug 2014 11:46:55 +0100 (BST)
Subject: [R] Generate quasi-random positive numbers
In-Reply-To: <CAPfBvqyvV5H650M9vDaY5AtbAodKDfkYkDFeH2CU2ju+PJgFNA@mail.gmail.com>
Message-ID: <XFMail.20140805114655.Ted.Harding@wlandres.net>

On 05-Aug-2014 10:27:54 Frederico Mestre wrote:
> Hello all:
> 
> Is it possible to generate quasi-random positive numbers, given a standard
> deviation and mean? I need all positive values to have the same probability
> of selection (uniform distribution). Something like:
> 
> runif(10, min = 0, max = 100)
> 
> This way I'm generating random positive numbers from a uniform
> distribution. However, using runif I can't previously select SD and mean
> (as in rnorm).
> 
> Alternatively, I'm able to generate a list of quasi-random numbers given a
> SD and a mean.
> 
> b <- (sqrt(SD^2*12)+(MEAN*2))/2
> a <- (MEAN*2) - b
> x1 <- runif(N,a,b)
> 
> However, negative values might be included, since "a" can assume a negative
> value.
> 
> Any help?
> 
> Thanks,
> Frederico

There is an inevitable constraint on MEAN and SD for a uniform
ditribution of positive numbers. Say the parent distribution is
uniform on (a,b) with a >= 0 and b > a.

Then MEAN = (a+b)/2, SD^2 = ((b-a)^2)/12, so

  12*SD^2  = b^2 - 2*a*b + a^2
  4*MEAN^2 = b^2 + 2*a*b + a^2

  4*MEAN^2 - 12*SD^2 = 4*a*b

  MEAN^2 - 3*SD^2 = a*b

Hence for a >= 0 and b > a you must have MEAN^2 >= 3*SD^2.

Once you have MEAN and SD satisfying this constraint, you should
be able to solve the equations for a and b.

Hoping this helps,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 05-Aug-2014  Time: 11:46:52
This message was sent by XFMail


From martyn.byng at nag.co.uk  Tue Aug  5 13:24:14 2014
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Tue, 5 Aug 2014 11:24:14 +0000
Subject: [R] Generate quasi-random positive numbers
In-Reply-To: <CAPfBvqyvV5H650M9vDaY5AtbAodKDfkYkDFeH2CU2ju+PJgFNA@mail.gmail.com>
References: <CAPfBvqyvV5H650M9vDaY5AtbAodKDfkYkDFeH2CU2ju+PJgFNA@mail.gmail.com>
Message-ID: <c5cc03eda3ad426b9d34534fa154ceb6@AM3PR05MB545.eurprd05.prod.outlook.com>

Hi,

As a slight aside, did you mean pseudo-random or quasi-random?

http://en.wikipedia.org/wiki/Pseudorandom_number_generator
http://en.wikipedia.org/wiki/Low-discrepancy_sequence

runif gives a sequence of pseudo-random numbers, for quasi-random numbers you will need something else, for example the Sobol generator from http://cran.r-project.org/web/packages/randtoolbox/index.html.


Martyn

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Frederico Mestre
Sent: 05 August 2014 11:28
To: r-help at r-project.org
Subject: [R] Generate quasi-random positive numbers

Hello all:

Is it possible to generate quasi-random positive numbers, given a standard deviation and mean? I need all positive values to have the same probability of selection (uniform distribution). Something like:

runif(10, min = 0, max = 100)

This way I'm generating random positive numbers from a uniform distribution. However, using runif I can't previously select SD and mean (as in rnorm).

Alternatively, I'm able to generate a list of quasi-random numbers given a SD and a mean.

b <- (sqrt(SD^2*12)+(MEAN*2))/2
a <- (MEAN*2) - b
x1 <- runif(N,a,b)

However, negative values might be included, since "a" can assume a negative value.

Any help?

Thanks,
Frederico

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}


From jim at bitwrit.com.au  Tue Aug  5 14:35:53 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 05 Aug 2014 22:35:53 +1000
Subject: [R] extract descriptive stats for categorial data from dataframe
In-Reply-To: <116154108.990531.1407231397559.open-xchange@patina.store>
References: <116154108.990531.1407231397559.open-xchange@patina.store>
Message-ID: <3628225.i9MZnW4mzH@localhost.localdomain>

On Tue, 5 Aug 2014 11:36:36 AM Alain D. wrote:
> Dear R-List,
> 
> I want to have descriptive stats in a special form and cannot figure 
out a
> nice solution.
> 
> df<-
as.data.frame(cbind(i1=rep("+"),i2=rep("+",10),i3=rep("-",10),i4=c(rep("
> 
-",2),"0",rep("-",7)),i5=rep("+",10),i6=c(rep("-",9),"+"),i7=c(rep("+",4),"0
> 
",rep("+",5)),i8=c(rep(0,4),rep("+",3),"-","+","-"),i9=c(rep("+",5),"-",rep(
> "+",2),rep(0,2))))
> 
> now I want the categories as var labels arranged in cols with IDs as 
first
> col and then frequencies for each category. Something like this:
> 
> var   +   -    0
> i1    10  0    0
> i2    10  0    0
> i3     0 10    0
> i4     0  9    1
> i5    10  0    0
> i6     1  9    0
> i7     9  0    1
> i8     4  2    4
> i9     7  1    2
> 
> I tried different combinations of
> 
> freq<-as.data.frame(df<-lapply(df,table))
> 
> but was not very successful.
> 
> I would be very thankful for an easy solution which is probably to 
obvious
> for me to spot.
> 
Hi Alain,
You can get pretty much what you want if your variables are all factors 
with the same levels like this:

varlevels<-c("+","-","0","1")
df<-data.frame(
 i1=factor(rep("+",10),levels=varlevels),
 i2=factor(rep("+",10),levels=varlevels),
 i3=factor(rep("-",10),levels=varlevels),
 i4=factor(c(rep("-",2),"0",rep("-",7)),levels=varlevels),
 i5=factor(rep("+",10),levels=varlevels),
 i6=factor(c(rep("-",9),"+"),levels=varlevels),
 i7=factor(c(rep("+",4),"0",rep("+",5)),levels=varlevels),
 i8=factor(c(rep(0,4),rep("+",3),"-","+","-"),levels=varlevels),
 i9=factor(c(rep("+",5),"-",rep("+",2),rep(0,2)),levels=varlevels))
library(prettyR)
describe(df,horizontal=TRUE,fname.space=10)

Jim


From dialvac-r at yahoo.de  Tue Aug  5 14:52:57 2014
From: dialvac-r at yahoo.de (Alain D.)
Date: Tue, 5 Aug 2014 14:52:57 +0200 (CEST)
Subject: [R] extract descriptive stats for categorial data from dataframe
In-Reply-To: <3628225.i9MZnW4mzH@localhost.localdomain>
References: <116154108.990531.1407231397559.open-xchange@patina.store>
	<3628225.i9MZnW4mzH@localhost.localdomain>
Message-ID: <1270816321.1038754.1407243178548.open-xchange@patina.store>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/195b672f/attachment.pl>

From smartpink111 at yahoo.com  Tue Aug  5 16:47:02 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 5 Aug 2014 07:47:02 -0700
Subject: [R] extract descriptive stats for categorial data from dataframe
In-Reply-To: <116154108.990531.1407231397559.open-xchange@patina.store>
References: <116154108.990531.1407231397559.open-xchange@patina.store>
Message-ID: <1407250022.50443.YahooMailNeo@web142603.mail.bf1.yahoo.com>

You could try:
lv <- levels(unique(unlist(df)))
as.data.frame(t(apply(df, 2, function(x) table(factor(x, levels=lv)))))
??? +? - 0
i1 10? 0 0
i2 10? 0 0
i3? 0 10 0
i4? 0? 9 1
i5 10? 0 0
i6? 1? 9 0
i7? 9? 0 1
i8? 4? 2 4
i9? 7? 1 2
A.K.




On Tuesday, August 5, 2014 5:36 AM, Alain D. <dialvac-r at yahoo.de> wrote:
Dear R-List,

I want to have descriptive stats in a special form and cannot figure out a nice
solution.

df<-as.data.frame(cbind(i1=rep("+"),i2=rep("+",10),i3=rep("-",10),i4=c(rep("-",2),"0",rep("-",7)),i5=rep("+",10),i6=c(rep("-",9),"+"),i7=c(rep("+",4),"0",rep("+",5)),i8=c(rep(0,4),rep("+",3),"-","+","-"),i9=c(rep("+",5),"-",rep("+",2),rep(0,2))))

now I want the categories as var labels arranged in cols with IDs as first col
and then frequencies for each category. Something like this:

var?  +?  -? ? 0
i1? ? 10? 0? ? 0
i2? ? 10? 0? ? 0
i3? ?  0 10? ? 0
i4? ?  0? 9? ? 1
i5? ? 10? 0? ? 0
i6? ?  1? 9? ? 0
i7? ?  9? 0? ? 1
i8? ?  4? 2? ? 4
i9? ?  7? 1? ? 2

I tried different combinations of

freq<-as.data.frame(df<-lapply(df,table))

but was not very successful.

I would be very thankful for an easy solution which is probably to obvious for
me to spot.

Thank you very much.

Best wishes

Alain
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From spencer.graves at structuremonitoring.com  Tue Aug  5 16:51:20 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 05 Aug 2014 07:51:20 -0700
Subject: [R] Normal probability plot examples for Wikipedia (was "qqnorm
 with histogram?")
In-Reply-To: <6731EB1B-5FA6-4702-BD9F-1DDE5105D5D0@gmail.com>
References: <53DE8FA2.1010206@structuremonitoring.com>
	<2386244.Srmg3LNeA7@localhost.localdomain>
	<53DFBB1A.8040000@structuremonitoring.com>
	<6731EB1B-5FA6-4702-BD9F-1DDE5105D5D0@gmail.com>
Message-ID: <53E0EF68.1080009@structuremonitoring.com>

Thanks to Charles Berry for suggesting "iris{datasets}" and to Peter 
Dalgaard for suggesting Confidence Intervals as produced by qqPlot{car}.


Spencer


On 8/5/2014 2:55 AM, peter dalgaard wrote:
> Not that I want to get deeply involved with this, but techniques that allow you to take the random variation of the plots into account are badly needed in practice. I mean, running qqnorm(rnorm(10)) a dozen times _ought_ to cure you of overinterpreting plots that are not bang-on a straight line but have apparent curvature, outliers, etc., but tell that to students these days...
>
> Confidence bands would be good to include. Various techniques are in circulation; I believe John Fox implemented one for Rcmdr/car. I seem to recall that these are based on the binomial distribution or its asymptotic approximation.
>
> If you are qqnorm()-in residuals, the theory for constructing CI's for the normal plot breaks down and you need to resort to simulation techniques, e.g. something like
>
>> Y <-  rgamma(10, 5)
>> qqnorm(scale(Y))
>> for (i in 1:10) lines(qqnorm(sort(scale(rnorm(10))),plot=FALSE), col="lightgray")
> -pd
>
> On 04 Aug 2014, at 18:55 , Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
>
>> Hi, Jim et al.:
>>
>>
>>       Thanks for the reply, Jim.
>>
>>
>>       What are your favorite examples using normal probability plots to identify outliers, skewness, kurtosis, mixtures, and the need for transformations in plots of raw data and residuals from model fits -- or using half-normal plots with estimated parameters?
>>
>>
>>       I ask, because I believe the current Wikipedia article on "Normal probability plot" could be improved dramatically with a set of great examples.  I also plan to write a function to display a normal probability plot with a histogram, a density estimate, and a boxplot and use it with the examples.  My current plan is to create this with a function qqnormPlus(..., datax=TRUE, histargs, densityargs, boxplotargs) that passes histargs, densityargs and boxplotargs to truehist{MASS}, density, and boxplot, respectively.  I plan to add this to the Ecfun package (for which I'm the author and maintainer).
>>
>>
>>       This wikipedia article received 14774 views in the past 90 days, averaging not quite 700 per day, so I think it's worth doing.  I could use suggestions (and help from other Wikipedians on this list).
>>
>>
>>       Thanks,
>>       Spencer
>>
>>
>> On 8/3/2014 2:59 PM, Jim Lemon wrote:
>>> Hi Spencer,
>>> The last example for the twoord.plot function (plotrix) does this.
>>>
>>> Jim
>>>
>>> On Sun, 3 Aug 2014 12:38:10 PM Spencer Graves wrote:
>>>>         Does a function exist that combines a normal probability plot
>>>> with a histogram and maybe a density estimate on the same plot?
>>>>
>>>>
>>>>         I'm revising the Wikipedia article on "Normal probability plot",
>>>> and I think it would be good to provide examples of this.
>>>>
>>>>
>>>>         Thanks,
>>>>         Spencer
>>>>
>>>>
>>>> p.s.  Please reply also with suggestions for how to improve that
>>>> Wikipedia article if you feel so inclined.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>


From lbagua at gmail.com  Tue Aug  5 16:57:37 2014
From: lbagua at gmail.com (Luis Borda de Agua)
Date: Tue, 5 Aug 2014 15:57:37 +0100
Subject: [R] keep information on the number of warnings
Message-ID: <187401BF-2012-4713-9FA7-4B0DAB45658E@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/a81cc298/attachment.pl>

From dialvac-r at yahoo.de  Tue Aug  5 17:00:49 2014
From: dialvac-r at yahoo.de (Alain D.)
Date: Tue, 5 Aug 2014 17:00:49 +0200 (CEST)
Subject: [R] extract descriptive stats for categorial data from dataframe
In-Reply-To: <1407250022.50443.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <116154108.990531.1407231397559.open-xchange@patina.store>
	<1407250022.50443.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <225044999.1062938.1407250850393.open-xchange@patina.store>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/a2b209a5/attachment.pl>

From william.a.simpson at gmail.com  Tue Aug  5 14:13:38 2014
From: william.a.simpson at gmail.com (William Simpson)
Date: Tue, 5 Aug 2014 13:13:38 +0100
Subject: [R] break loop with keypress
Message-ID: <CAPVh6j7yq6fephd5WB3r=KKSG7DbaO9+9ouQ819yX-DB79qUGg@mail.gmail.com>

This works, but it is not quite what I need:

par(mar=rep(0,4))

while(1)
  {
  img1<-matrix(runif(2500),50,50)
  dev.hold(); image(img1,useRaster=TRUE); dev.flush()
  img2<-matrix(runif(2500),50,50)
  dev.hold(); image(img2,useRaster=TRUE); dev.flush()
  }

I would like to do this:
while(!kbhit())
  {
  ...

where kbhit() polls the keyboard, returning a non-zero integer if the
keyboard buffer has something in it. The animation loop continues
until a key is pressed.

All the ways of getting user input I have seen (e.g. getGraphicsEvent)
are not suitable because they would wait on each pass through the loop
until the key is pressed and therefore no animation would be
presented.

Any ideas on how to present a continuous animation loop which is
broken upon user input (keypress or mouse button press)? I am using
Windows 7. Thanks very much for any help.

Bill


From deepayan.sarkar at r-project.org  Tue Aug  5 09:31:03 2014
From: deepayan.sarkar at r-project.org (Deepayan Sarkar)
Date: Tue, 5 Aug 2014 13:01:03 +0530
Subject: [R] The R Journal, Volume 6, Issue 1
Message-ID: <CADfFDC6u-3VbHZYyr8B6Nk-0bhS-i+zxF5=tjv-E5_CA7wYxLw@mail.gmail.com>

Dear All,

The latest issue of The R Journal is now available at
http://journal.r-project.org/archive/2014-1/

Many thanks to all contributors, and apologies for the delay.

Regards,
-Deepayan

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ntfredo at gmail.com  Tue Aug  5 13:33:33 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 5 Aug 2014 14:33:33 +0300
Subject: [R] object of type 'closure' is not subsettable
Message-ID: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/df531b1f/attachment.pl>

From mail at ahschulz.de  Tue Aug  5 14:28:38 2014
From: mail at ahschulz.de (=?iso-8859-1?Q?Arne_H=2E_Schulz?=)
Date: Tue, 5 Aug 2014 14:28:38 +0200
Subject: [R] =?iso-8859-1?q?Library=28mice=29_too_slow_for_my_dataset?=
In-Reply-To: <DUB125-W846D9D3137B365EC5A9732B9E30@phx.gbl>
References: <DUB125-W846D9D3137B365EC5A9732B9E30@phx.gbl>
Message-ID: <zarafa.53e0cdf7.6cc5.4fc1e90215f751ee@home.ahschulz.de>

Dear Teresa,
using such services will only speed up the imputations significantly if you can split up/parallelize your code.

And maybe you can use more cores on your local machine by using packages like doSNOW, foreach and/or plyr. There are a lot of examples on the web.

Kind regards
Arne

-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von M? Teresa Martinez Soriano
Gesendet: Dienstag, 5. August 2014 12:35
An: r-help at r-project.org
Betreff: [R] Library(mice) too slow for my dataset

Hi to everyone

I have a big dataset (40.000 columns (variables) and 50 rows)

I want to impute a lot of ?variables ?with ?library(mice), the problem is that this process is too slow (because of my dataset, the library is brilliant).

I am looking some options like Amazon web services, (?http://aws.amazon.com/es/datapipeline/developer-resources/?)

Has anyone used this service or knows other options?

Any ideas are welcome.

Thanks in advance

 		 	   		  
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jiangyunbei at y7mail.com  Tue Aug  5 14:46:36 2014
From: jiangyunbei at y7mail.com (Jiang Jenny)
Date: Tue, 5 Aug 2014 22:46:36 +1000
Subject: [R] Calculation of weighted network centrality measures
Message-ID: <67ADD1EE-C8F2-4986-ADC9-BEADCE76147F@y7mail.com>

Hello,

My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales Australia. Currently my research project involves the calculating of some network centrality measures in R, which are degree, closeness, betweenness and eigen vector. However I am having some issue regarding to the calculation of the weighted centrality measures by network size. For example, currently my code allows me to calculate centrality measures for each firm year, and now I would like to calculate centrality measures weighted by the firm network size for each firm year. I have attached my current R code and a data example for you in .txt format to have a look. If you could provide me the R code regarding to how to do that that would be really helpful.

I cannot be more than appreciated.

Best regards

Jenny



From jiangyunbei at y7mail.com  Tue Aug  5 15:04:41 2014
From: jiangyunbei at y7mail.com (Jiang Jenny)
Date: Tue, 5 Aug 2014 23:04:41 +1000
Subject: [R] Calculation of weighted network centrality measures
Message-ID: <1688DF95-E149-4DCE-BA23-3706C78D1B91@y7mail.com>

Hello,

My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales Australia. Currently my research project involves the calculating of some network centrality measures in R, which are degree, closeness, betweenness and eigen vector. However I am having some issue regarding to the calculation of the weighted centrality measures by network size. For example, currently my code allows me to calculate centrality measures for each firm year, and now I would like to calculate centrality measures weighted by the firm network size for each firm year. I have attached my current R code and a data example for you in .txt format to have a look. If you could provide me the R code regarding to how to do that that would be really helpful.

I cannot be more than appreciated.

Best regards

Jenny


From ksumeet40 at gmail.com  Tue Aug  5 15:06:47 2014
From: ksumeet40 at gmail.com (Sumit Khanna)
Date: Tue, 5 Aug 2014 18:36:47 +0530
Subject: [R] Optim function collectively for all Rows in a dataframe
Message-ID: <CAM80V9zHBzUFQ93Sba5OwFT_+C1mMv+ZSREJ+gtvihTkJoYf5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/62e73cd1/attachment.pl>

From jiangyunbei at y7mail.com  Tue Aug  5 15:06:46 2014
From: jiangyunbei at y7mail.com (Jiang Jenny)
Date: Tue, 5 Aug 2014 23:06:46 +1000
Subject: [R] (no subject)
Message-ID: <065AE4FB-FDDC-456E-9DBC-DAE1F27A7990@y7mail.com>

Hello,

My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales Australia. Currently my research project involves the calculating of some network centrality measures in R, which are degree, closeness, betweenness and eigen vector. However I am having some issue regarding to the calculation of the weighted centrality measures by network size. For example, currently my code allows me to calculate centrality measures for each firm year, and now I would like to calculate centrality measures weighted by the firm network size for each firm year. I have attached my current R code and a data example for you in .txt format to have a look. If you could provide me the R code regarding to how to do that that would be really helpful.

I cannot be more than appreciated.

Best regards

Jenny



From sarah.goslee at gmail.com  Tue Aug  5 17:18:40 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 5 Aug 2014 11:18:40 -0400
Subject: [R] Calculation of weighted network centrality measures
In-Reply-To: <1688DF95-E149-4DCE-BA23-3706C78D1B91@y7mail.com>
References: <1688DF95-E149-4DCE-BA23-3706C78D1B91@y7mail.com>
Message-ID: <CAM_vju=6CBpWfRAXcLGGgQckEn99Ct3Z9JBOwMfM5Kve8kDF_A@mail.gmail.com>

Hi,

This list doesn't allow most kinds of attachments. Please see the
following link for some ideas on best practices for formulating your
question and provided a reproducible example:

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example


The posting guide linked at the bottom of this email is also helpful.

Sarah

On Tue, Aug 5, 2014 at 9:04 AM, Jiang Jenny <jiangyunbei at y7mail.com> wrote:
> Hello,
>
> My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales Australia. Currently my research project involves the calculating of some network centrality measures in R, which are degree, closeness, betweenness and eigen vector. However I am having some issue regarding to the calculation of the weighted centrality measures by network size. For example, currently my code allows me to calculate centrality measures for each firm year, and now I would like to calculate centrality measures weighted by the firm network size for each firm year. I have attached my current R code and a data example for you in .txt format to have a look. If you could provide me the R code regarding to how to do that that would be really helpful.
>
> I cannot be more than appreciated.
>
> Best regards
>
> Jenny
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Aug  5 17:20:23 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 5 Aug 2014 11:20:23 -0400
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
References: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
Message-ID: <CAM_vjunhc3f7Z6E1FAhPSqnRE_pbgQOg4D37=stCTKCGZ4spWg@mail.gmail.com>

On Tue, Aug 5, 2014 at 7:33 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Dear All,
>
> I am getting this error: Error in boxplot$Month : object of type 'closure'
> is not subsettable

probably because your dataframe is box_plot while boxplot is the name
of a function.

Try
box_plot$Month

Sarah

> The following is the codes i am using to produce the boxplot I need for
> this daily rainfall data.
>
> ## reading the data
> rm(list=ls(all=TRUE))
> Bungoma=read.csv("/home/fredo/Documents/Maseno/Data/Bungoma_2.csv")
> attach(Bungoma)
> head(Bungoma)
> tail(Bungoma)
> summary(Bungoma)
> # removing missing values
> Bungoma <- na.omit(Bungoma)
> summary(Bungoma)
> ###### split the data by month and boxplot for 0.85mm as the threshold
> box_plot=Bungoma[Bungoma$Rain>0.85,]
> head(box_plot)
> bungoma_boxplot=split(box_plot$Rain,box_plot$Month)
> head(bungoma_boxplot)
> boxplot(bungoma_boxplot,
> names=c("J","F","M","A","M","J","J","A","S","O","N","D"),width =
> table(boxplot$Month))
> title(main="Boxplot of Rain for each month")
>
> Any idea is welcome on how I can make it and overcome the error. Thanks.
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Aug  5 17:26:28 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 5 Aug 2014 11:26:28 -0400
Subject: [R] (no subject)
In-Reply-To: <065AE4FB-FDDC-456E-9DBC-DAE1F27A7990@y7mail.com>
References: <065AE4FB-FDDC-456E-9DBC-DAE1F27A7990@y7mail.com>
Message-ID: <CAM_vjun85tZ5urm8ush9pXeEtSZRn1iF7K=R9oBGFFa7eraV-g@mail.gmail.com>

By my count this is the third time you've posted this.

Please do not do that. Please do read the posting guide. Please do not
try to attach files that the list software will remove. Instead, put
enough data and code in the body of your email that others on the list
can reproduce your problem.

Sarah

On Tue, Aug 5, 2014 at 9:06 AM, Jiang Jenny <jiangyunbei at y7mail.com> wrote:
> Hello,
>
> My name is Jenny Jiang and I am a Finance Honours research student from the University of New South Wales Australia. Currently my research project involves the calculating of some network centrality measures in R, which are degree, closeness, betweenness and eigen vector. However I am having some issue regarding to the calculation of the weighted centrality measures by network size. For example, currently my code allows me to calculate centrality measures for each firm year, and now I would like to calculate centrality measures weighted by the firm network size for each firm year. I have attached my current R code and a data example for you in .txt format to have a look. If you could provide me the R code regarding to how to do that that would be really helpful.
>
> I cannot be more than appreciated.
>
> Best regards
>
> Jenny
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From gyanendra.pokharel at gmail.com  Tue Aug  5 17:28:52 2014
From: gyanendra.pokharel at gmail.com (Gyanendra Pokharel)
Date: Tue, 5 Aug 2014 11:28:52 -0400
Subject: [R] Package gptk, no default option
Message-ID: <CAK=huh629UJ2igpfQDFqCygBLL-9cjmDzD=zQ5dpLuNLQmtNbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/f5891659/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Aug  5 18:12:27 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 05 Aug 2014 09:12:27 -0700
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
References: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
Message-ID: <f131122e-782d-4eee-b309-13bdc61009dc@email.android.com>

"boxplot" is a function ("closure"). You probably meant "bungoma_boxplot$Month"?

Please read the Posting Guide. One point it mentions is that this is a plain text mailing list... HTML format email is not a what-you-see-is-what-we-see format.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 5, 2014 4:33:33 AM PDT, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>Dear All,
>
>I am getting this error: Error in boxplot$Month : object of type
>'closure'
>is not subsettable
>
>The following is the codes i am using to produce the boxplot I need for
>this daily rainfall data.
>
>## reading the data
>rm(list=ls(all=TRUE))
>Bungoma=read.csv("/home/fredo/Documents/Maseno/Data/Bungoma_2.csv")
>attach(Bungoma)
>head(Bungoma)
>tail(Bungoma)
>summary(Bungoma)
># removing missing values
>Bungoma <- na.omit(Bungoma)
>summary(Bungoma)
>###### split the data by month and boxplot for 0.85mm as the threshold
>box_plot=Bungoma[Bungoma$Rain>0.85,]
>head(box_plot)
>bungoma_boxplot=split(box_plot$Rain,box_plot$Month)
>head(bungoma_boxplot)
>boxplot(bungoma_boxplot,
>names=c("J","F","M","A","M","J","J","A","S","O","N","D"),width =
>table(boxplot$Month))
>title(main="Boxplot of Rain for each month")
>
>Any idea is welcome on how I can make it and overcome the error.
>Thanks.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Tue Aug  5 19:20:10 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 05 Aug 2014 10:20:10 -0700
Subject: [R] big data?
Message-ID: <53E1124A.2080603@structuremonitoring.com>

       What tools do you like for working with tab delimited text files 
up to 1.5 GB (under Windows 7 with 8 GB RAM)?


       Standard tools for smaller data sometimes grab all the available 
RAM, after which CPU usage drops to 3% ;-)


       The "bigmemory" project won the 2010 John Chambers Award but "is 
not available (for R version 3.1.0)".


       findFn("big data", 999) downloaded 961 links in 437 packages. 
That contains tools for data PostgreSQL and other formats, but I 
couldn't find anything for large tab delimited text files.


       Absent a better idea, I plan to write a function getField to 
extract a specific field from the data, then use that to split the data 
into 4 smaller files, which I think should be small enough that I can do 
what I want.


       Thanks,
       Spencer


From tring at gvdnet.dk  Tue Aug  5 19:22:11 2014
From: tring at gvdnet.dk (Troels Ring)
Date: Tue, 05 Aug 2014 19:22:11 +0200
Subject: [R] doubleYScale from latticeExtra, problems with style
Message-ID: <53E112C3.6080508@gvdnet.dk>

Dear friends - below is a small example showing a problem I have 
understanding doubleYScale from latticeExtra -
R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

Both obj1 and obj2 are formatted as I wanted - but when combined the 
formatting is lost. How comes?
Best wishes
Troels Ring
Aalborg, Denmark

library(latticeExtra)
T <- seq(1,200,length=100)
Y1 <- 10+2*T+0.05*T^2 + rnorm(100,0,40)
Y2 <- 0.1 + sqrt(T)+rnorm(100,1,1)
tesobj <- data.frame(T=T,Y1=Y1,Y2=Y2)


obj1 <- 
xyplot(Y1~T,tesobj,xlab=list(label="Time",cex=1.5),ylab=list(label="Y1",
cex=1.5),scales=list(y=list(cex=1.2),x=list(cex=1.2)),
panel = function(x,y,...){
panel.xyplot(x,y,...,pch=19)
panel.loess(x,y,...,lwd=3)
})
obj1

obj2 <- 
xyplot(Y2~T,tesobj,xlab=list(label="Time",cex=1.5),ylab=list(label="Y2",
cex=1.5),scales=list(y=list(cex=1.2),x=list(cex=1.2)),
panel = function(x,y,...){
panel.xyplot(x,y,...,pch=20)
panel.loess(x,y,...,lwd=3)})
obj2

(sd <- doubleYScale(obj1,obj2,add.ylab2=TRUE))


From peter.langfelder at gmail.com  Tue Aug  5 19:25:52 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 5 Aug 2014 10:25:52 -0700
Subject: [R] big data?
In-Reply-To: <53E1124A.2080603@structuremonitoring.com>
References: <53E1124A.2080603@structuremonitoring.com>
Message-ID: <CA+hbrhU14Kqt7oJNz8yFhtNZUY4taOitLY-OChFXeW38Nq+tnQ@mail.gmail.com>

Have you tried read.csv.sql from package sqldf?

Peter

On Tue, Aug 5, 2014 at 10:20 AM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
>       What tools do you like for working with tab delimited text files up to
> 1.5 GB (under Windows 7 with 8 GB RAM)?
>
>
>       Standard tools for smaller data sometimes grab all the available RAM,
> after which CPU usage drops to 3% ;-)
>
>
>       The "bigmemory" project won the 2010 John Chambers Award but "is not
> available (for R version 3.1.0)".
>
>
>       findFn("big data", 999) downloaded 961 links in 437 packages. That
> contains tools for data PostgreSQL and other formats, but I couldn't find
> anything for large tab delimited text files.
>
>
>       Absent a better idea, I plan to write a function getField to extract a
> specific field from the data, then use that to split the data into 4 smaller
> files, which I think should be small enough that I can do what I want.
>
>
>       Thanks,
>       Spencer
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Tue Aug  5 19:29:00 2014
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Tue, 5 Aug 2014 13:29:00 -0400
Subject: [R] Equivalent of read.table for object rather than file
Message-ID: <53E1145C.1020602@cognigencorp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/c7a0cb2a/attachment.pl>

From 538280 at gmail.com  Tue Aug  5 19:31:11 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 5 Aug 2014 11:31:11 -0600
Subject: [R] qqnorm with histogram?
In-Reply-To: <53DE8FA2.1010206@structuremonitoring.com>
References: <53DE8FA2.1010206@structuremonitoring.com>
Message-ID: <CAFEqCdzFSohkawrsVHnxt8BG1092BJeokpoz0vw56SdcnyFfmw@mail.gmail.com>

Not a single function, but the subplot function in the TeachingDemos
package can be used to add the histogram and/or density plot in the
empty part of a qqplot.



On Sun, Aug 3, 2014 at 1:38 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
>       Does a function exist that combines a normal probability plot with a
> histogram and maybe a density estimate on the same plot?
>
>
>       I'm revising the Wikipedia article on "Normal probability plot", and I
> think it would be good to provide examples of this.
>
>
>       Thanks,
>       Spencer
>
>
> p.s.  Please reply also with suggestions for how to improve that Wikipedia
> article if you feel so inclined.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ripley at stats.ox.ac.uk  Tue Aug  5 19:40:54 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 05 Aug 2014 18:40:54 +0100
Subject: [R] Equivalent of read.table for object rather than file
In-Reply-To: <53E1145C.1020602@cognigencorp.com>
References: <53E1145C.1020602@cognigencorp.com>
Message-ID: <53E11726.7040102@stats.ox.ac.uk>

On 05/08/2014 18:29, sbihorel wrote:
> Hi,
>
> Let's say that I have a scalar character object called tmp which stores
> the entire content of an ASCII file. Is there a function that would
> process tmp the same way read.table() would process the content of the
> original ASCII file?
>
> The content of tmp will come from a database, and I want to extract the
> data without writing and reading to disk or without asking the database
> to transform the file content into a table.

The equivalent is read.table.  See its 'text' argument:

     text: character string: if ?file? is not supplied and this is, then
           data are read from the value of ?text? via a text connection.
           Notice that a literal string can be used to include (small)
           data sets within R code.

>
> Thank you
>
> Sebastien
> //
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
PLEASE do.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From david at revolutionanalytics.com  Tue Aug  5 19:58:20 2014
From: david at revolutionanalytics.com (David Smith)
Date: Tue, 5 Aug 2014 12:58:20 -0500
Subject: [R] Revolutions blog: July 2014 roundup
Message-ID: <CABgvEC_ub1jmozAQahpo2ST++tkGtnTDs1AzsSzVR+1fgCWr-A@mail.gmail.com>

Revolution Analytics staff and guests write about R every weekday at
the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of July:

The deadline for our contest to visualize the location of R user
groups has been extended to August 16: http://bit.ly/1o9C1N8

Previews of R-related sessions at this year's JSM conference in
Boston: http://bit.ly/1o9C1N7

Coding errors in R graphics scripts serendipitously create some
interesting art: http://bit.ly/1o9C1N6

Another look at the dependency graphs for R packages with the miniCRAN
package: http://bit.ly/1o9C1N9 , following on from this post:
http://bit.ly/1o9C0sz

A Reuters journalist used R for a story about the impact of rising sea
levels: http://bit.ly/1o9C0sy

The DSC 2014 conference featured an interesting discussion on
learnings from alternative R implementations like Renjin and pqR:
http://bit.ly/1o9C1Na

An in-depth look at R's capabilities for agent-based modeling and the
RNetLogo package: http://bit.ly/1o9C0sB

The magrittr package introduces the %>% pipe operator, an elegant way
of chaining R functions together: http://bit.ly/1o9C0sA

Some considerations for choosing a trainer for R courses: http://bit.ly/1o9C1Nb

Cleveland popularized lattice-style graphics by revealing an error in
the "barley" data set, but there may not have been any error after
all: http://bit.ly/1o9C1Nc

A review of R packages for meta-analysis: http://bit.ly/1o9C0sC

Preparing big data for analysis in R with Xplenty: http://bit.ly/1o9C0sD

A free e-book on Machine Learning with R from InsideBigData:
http://bit.ly/1o9C1Nd

Recent research by the IEEE ranks R the 9th most popular of all
programming languages: http://bit.ly/1o9C3o0

A brief summary of the changes in R 3.1.1: http://bit.ly/1o9C23q

Joe Rickert recaps John Chambers' keynote address on the history of R
at useR! 2014: http://bit.ly/1o9C3o4

I recount some personal highlights from the useR! 2014 conference in
Los Angeles: http://bit.ly/1o9C3o3

Reviews and links to materials from some of the R tutorials presented
at useR! 2014: http://bit.ly/1o9C3o2

A 5-minute history of Revolution Analytics, in slides: http://bit.ly/1o9C3o5

Part 2 in a series on constructing a term structure of interest rates
with R: http://bit.ly/1o9C23t

General interest stories (not related to R) in the past month
included: misheard Pearl Jam lyrics (http://bit.ly/1o9C3o6), a pop
song about grammar (http://bit.ly/1o9C23v), a book review of "The
Martian" (http://bit.ly/1o9C3o7), and some of the fuzzy details behind
the definition of "USA" (http://bit.ly/1o9C23u).

Meeting times for local R user groups (http://bit.ly/eC5YQe) can be
found on the updated R Community Calendar at: http://bit.ly/bb3naW

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid

-- 
Try Enterprise R Now!  
<https://aws.amazon.com/marketplace/seller-profile/ref=_ptnr_emailfooter?ie=UTF8&id=3c6536d3-8115-4bc0-a713-be58e257a7be>
Get a 14 Day Free Trial of Revolution R Enterprise on AWS Marketplace


From Sebastien.Bihorel at cognigencorp.com  Tue Aug  5 20:15:40 2014
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Tue, 5 Aug 2014 14:15:40 -0400
Subject: [R] Equivalent of read.table for object rather than file
In-Reply-To: <53E1145C.1020602@cognigencorp.com>
References: <53E1145C.1020602@cognigencorp.com>
Message-ID: <53E11F4C.3000900@cognigencorp.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/6dcfb860/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Aug  5 20:26:03 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 5 Aug 2014 19:26:03 +0100
Subject: [R] Equivalent of read.table for object rather than file
In-Reply-To: <53E11F4C.3000900@cognigencorp.com>
References: <53E1145C.1020602@cognigencorp.com>
	<53E11F4C.3000900@cognigencorp.com>
Message-ID: <53E121BB.1050709@stats.ox.ac.uk>

On 05/08/2014 19:15, sbihorel wrote:
> Hi,
>
> Thanks for the info. Unfortunately, read.table() does not have the text argument in the version of R that I can use.
> Do you know when was this argument introduced?

No, but the posting guide asked you to update *before posting* (have you 
yet read it?: you still sent HTML when asked not to).

In any case, the help text tells you how to do it: use a text connection.

>
> Sebastien
>
> On 05/08/2014 18:29, sbihorel wrote:
>> /  Hi,
> />/
> />/  Let's say that I have a scalar character object called tmp which stores
> />/  the entire content of an ASCII file. Is there a function that would
> />/  process tmp the same way read.table() would process the content of the
> />/  original ASCII file?
> />/
> />/  The content of tmp will come from a database, and I want to extract the
> />/  data without writing and reading to disk or without asking the database
> />/  to transform the file content into a table.
> /
> The equivalent is read.table.  See its 'text' argument:
>
>        text: character string: if 'file' is not supplied and this is, then
>              data are read from the value of 'text' via a text connection.
>              Notice that a literal string can be used to include (small)
>              data sets within R code.
>
>> /
> />/  Thank you
> />/
> />/  Sebastien
> />/  //
> />/
> />/  	[[alternative HTML version deleted]]
> />/
> />/  ______________________________________________
> />/  R-help at r-project.org  <https://stat.ethz.ch/mailman/listinfo/r-help>  mailing list
> />/  https://stat.ethz.ch/mailman/listinfo/r-help
> />/  PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
> />/  and provide commented, minimal, self-contained, reproducible code.
> />/
> /PLEASE do.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Tue Aug  5 20:37:25 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Aug 2014 11:37:25 -0700
Subject: [R] big data?
In-Reply-To: <53E1124A.2080603@structuremonitoring.com>
References: <53E1124A.2080603@structuremonitoring.com>
Message-ID: <34476B18-46F4-4035-B7E9-FC3B83D6643B@comcast.net>


On Aug 5, 2014, at 10:20 AM, Spencer Graves wrote:

>      What tools do you like for working with tab delimited text files up to 1.5 GB (under Windows 7 with 8 GB RAM)?

?data.table::fread

>      Standard tools for smaller data sometimes grab all the available RAM, after which CPU usage drops to 3% ;-)
> 
> 
>      The "bigmemory" project won the 2010 John Chambers Award but "is not available (for R version 3.1.0)".
> 
> 
>      findFn("big data", 999) downloaded 961 links in 437 packages. That contains tools for data PostgreSQL and other formats, but I couldn't find anything for large tab delimited text files.
> 
> 
>      Absent a better idea, I plan to write a function getField to extract a specific field from the data, then use that to split the data into 4 smaller files, which I think should be small enough that I can do what I want.

There is the colbycol package with which I have no experience, but I understand it is designed to partition data into column sized objects.
#--- from its help file-----
cbc.get.col {colbycol}	R Documentation
Reads a single column from the original file into memory

Description

Function cbc.read.table reads a file, stores it column by column in disk file and creates a colbycol object. Functioncbc.get.col queries this object and returns a single column.

>      Thanks,
>      Spencer
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mp.sylvestre at gmail.com  Tue Aug  5 19:39:44 2014
From: mp.sylvestre at gmail.com (Marie-Pierre Sylvestre)
Date: Tue, 5 Aug 2014 13:39:44 -0400
Subject: [R] Frequencies for a list of vectors
Message-ID: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/27105340/attachment.pl>

From ruipbarradas at sapo.pt  Tue Aug  5 22:48:54 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 05 Aug 2014 21:48:54 +0100
Subject: [R] Frequencies for a list of vectors
In-Reply-To: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
References: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
Message-ID: <53E14336.7070800@sapo.pt>

Hello,

Maybe something like

table(unlist(lapply(HTNlist, paste, collapse = '')))


(Untested, it's a bad idea not to use ?dput to give a data example.)
Use

dput(head(HTNlist))  # paste the output of this in a mail


Hope this helps,

Rui Barradas


Em 05-08-2014 18:39, Marie-Pierre Sylvestre escreveu:
> Dear R users,
>
> I have a list of vectors (list is called HTNlist). Each vector is of length
> 1 to 4 and takes only 0 and 1 as values. E.g.
>
> head(HTNlist)
> $`30008`
> [1] 1 0 1 0
>
> $`60008`
> [1] 0 0 1 0
>
> $`90008`
> [1] 0 0 1 0
>
> $`100007`
> [1] 1
>
> $`130001`
> [1] 0 1
>
> $`130007`
> [1] 1 0 1 0
>
> I would like to obtain a frequency table for the elements of the list. I
> want to know how many of
> '1 0 0' I have in the list, how many '1 0 1 0' etc.
>
> Can you please help?
>
> Thank you in advance,
> MP
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Tue Aug  5 22:51:02 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 5 Aug 2014 13:51:02 -0700
Subject: [R] Frequencies for a list of vectors
In-Reply-To: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
References: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
Message-ID: <CAF8bMcYsRJb4A2tB1PFes9NROWdt2xcsqJMUq+c52p5fjBmfeQ@mail.gmail.com>

You can those vectors into character strings and pass them to table().  E.g.,

> d <- list(`30008`=c(1,0,1,0), `60008`=c(0,0,1,0), `90008`=c(0,0,1,0), `100007`=1, `130001`=c(0,1), `130007`=c(1,0,1,0))
> dChar <- vapply(d, FUN=function(di)paste(di, collapse=" "), FUN.VALUE="")
> dTable <- table(dChar)
> dTable
dChar
0 0 1 0     0 1       1 1 0 1 0
      2       1       1       2
> dTable["1 0 1 0"]
1 0 1 0
      2

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Aug 5, 2014 at 10:39 AM, Marie-Pierre Sylvestre
<mp.sylvestre at gmail.com> wrote:
> Dear R users,
>
> I have a list of vectors (list is called HTNlist). Each vector is of length
> 1 to 4 and takes only 0 and 1 as values. E.g.
>
> head(HTNlist)
> $`30008`
> [1] 1 0 1 0
>
> $`60008`
> [1] 0 0 1 0
>
> $`90008`
> [1] 0 0 1 0
>
> $`100007`
> [1] 1
>
> $`130001`
> [1] 0 1
>
> $`130007`
> [1] 1 0 1 0
>
> I would like to obtain a frequency table for the elements of the list. I
> want to know how many of
> '1 0 0' I have in the list, how many '1 0 1 0' etc.
>
> Can you please help?
>
> Thank you in advance,
> MP
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dominic.comtois at gmail.com  Tue Aug  5 22:53:38 2014
From: dominic.comtois at gmail.com (Dominic Comtois)
Date: Tue, 5 Aug 2014 16:53:38 -0400
Subject: [R] =?utf-8?q?R_script_in_batch_mode_=E2=80=94_Echoing_messages_t?=
	=?utf-8?q?o_windows_shell?=
Message-ID: <CAEfsz7qfTov=vapBQtY9GfUgaPzU125cM22-sNVxd0bH1C+RqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/9c31dd2c/attachment.pl>

From Peter.Alspach at plantandfood.co.nz  Tue Aug  5 22:53:48 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 6 Aug 2014 08:53:48 +1200
Subject: [R] Frequencies for a list of vectors
In-Reply-To: <53E14336.7070800@sapo.pt>
References: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
	<53E14336.7070800@sapo.pt>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2281DA600C@AKLEXM01.PFR.CO.NZ>

Alternatively, use sapply instead of lapply ....

marieData <- list('30008'=c(1,0,1,0), '60008'=c(0,0,1,0), '90008'=c(0,0,1,0), '100007'=1, '130001'=c(0,1))
marieData
$`30008`
[1] 1 0 1 0

$`60008`
[1] 0 0 1 0

$`90008`
[1] 0 0 1 0

$`100007`
[1] 1

$`130001`
[1] 0 1

table(sapply(marieData, paste, collapse=''))

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
Sent: Wednesday, 6 August 2014 8:49 a.m.
To: Marie-Pierre Sylvestre; r-help at r-project.org
Subject: Re: [R] Frequencies for a list of vectors

Hello,

Maybe something like

table(unlist(lapply(HTNlist, paste, collapse = '')))


(Untested, it's a bad idea not to use ?dput to give a data example.) Use

dput(head(HTNlist))  # paste the output of this in a mail


Hope this helps,

Rui Barradas


Em 05-08-2014 18:39, Marie-Pierre Sylvestre escreveu:
> Dear R users,
>
> I have a list of vectors (list is called HTNlist). Each vector is of 
> length
> 1 to 4 and takes only 0 and 1 as values. E.g.
>
> head(HTNlist)
> $`30008`
> [1] 1 0 1 0
>
> $`60008`
> [1] 0 0 1 0
>
> $`90008`
> [1] 0 0 1 0
>
> $`100007`
> [1] 1
>
> $`130001`
> [1] 0 1
>
> $`130007`
> [1] 1 0 1 0
>
> I would like to obtain a frequency table for the elements of the list. 
> I want to know how many of
> '1 0 0' I have in the list, how many '1 0 1 0' etc.
>
> Can you please help?
>
> Thank you in advance,
> MP
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From wdunlap at tibco.com  Tue Aug  5 23:09:58 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 5 Aug 2014 14:09:58 -0700
Subject: [R] Frequencies for a list of vectors
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC2281DA600C@AKLEXM01.PFR.CO.NZ>
References: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
	<53E14336.7070800@sapo.pt>
	<ED8CD182D432434485C7D1787FB06DDC2281DA600C@AKLEXM01.PFR.CO.NZ>
Message-ID: <CAF8bMcZrXNzgf-Km0+H+hJKN7n5eN54oQEqJjoX-hccL1A-FzA@mail.gmail.com>

Using vapply instead of sapply or unlist(lapply) here gives you a
little more safety.  vapply insists that you supply a FUN.VALUE
argument that gives a prototype (type and length) of the expected
output of FUN.  It will stop if FUN returns something unexpected.
Compare the following where I misspelled 'collapse'; only vapply
catches the error:

> marieData <- list('30008'=c(1,0,1,0), '60008'=c(0,0,1,0), '90008'=c(0,0,1,0), '100007'=1, '130001'=c(0,1))
> unlist(lapply(marieData, paste, collaps=''))
 300081  300082  300083  300084  600081  600082  600083  600084  900081  900082
   "1 "    "0 "    "1 "    "0 "    "0 "    "0 "    "1 "    "0 "    "0 "    "0 "
 900083  900084  100007 1300011 1300012
   "1 "    "0 "    "1 "    "0 "    "1 "
> sapply(marieData, paste, collaps='')
$`30008`
[1] "1 " "0 " "1 " "0 "

$`60008`
[1] "0 " "0 " "1 " "0 "

$`90008`
[1] "0 " "0 " "1 " "0 "

$`100007`
[1] "1 "

$`130001`
[1] "0 " "1 "

> vapply(marieData, paste, collaps='', FUN.VALUE='')
Error in vapply(marieData, paste, collaps = "", FUN.VALUE = "") :
  values must be length 1,
 but FUN(X[[1]]) result is length 4

vapply(X,FUN,FUN.VALUE) also gives you a better result when length(X)
is 0, meaning that you don't have to write special code to catch that
case.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Aug 5, 2014 at 1:53 PM, Peter Alspach
<Peter.Alspach at plantandfood.co.nz> wrote:
> Alternatively, use sapply instead of lapply ....
>
> marieData <- list('30008'=c(1,0,1,0), '60008'=c(0,0,1,0), '90008'=c(0,0,1,0), '100007'=1, '130001'=c(0,1))
> marieData
> $`30008`
> [1] 1 0 1 0
>
> $`60008`
> [1] 0 0 1 0
>
> $`90008`
> [1] 0 0 1 0
>
> $`100007`
> [1] 1
>
> $`130001`
> [1] 0 1
>
> table(sapply(marieData, paste, collapse=''))
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rui Barradas
> Sent: Wednesday, 6 August 2014 8:49 a.m.
> To: Marie-Pierre Sylvestre; r-help at r-project.org
> Subject: Re: [R] Frequencies for a list of vectors
>
> Hello,
>
> Maybe something like
>
> table(unlist(lapply(HTNlist, paste, collapse = '')))
>
>
> (Untested, it's a bad idea not to use ?dput to give a data example.) Use
>
> dput(head(HTNlist))  # paste the output of this in a mail
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> Em 05-08-2014 18:39, Marie-Pierre Sylvestre escreveu:
>> Dear R users,
>>
>> I have a list of vectors (list is called HTNlist). Each vector is of
>> length
>> 1 to 4 and takes only 0 and 1 as values. E.g.
>>
>> head(HTNlist)
>> $`30008`
>> [1] 1 0 1 0
>>
>> $`60008`
>> [1] 0 0 1 0
>>
>> $`90008`
>> [1] 0 0 1 0
>>
>> $`100007`
>> [1] 1
>>
>> $`130001`
>> [1] 0 1
>>
>> $`130007`
>> [1] 1 0 1 0
>>
>> I would like to obtain a frequency table for the elements of the list.
>> I want to know how many of
>> '1 0 0' I have in the list, how many '1 0 1 0' etc.
>>
>> Can you please help?
>>
>> Thank you in advance,
>> MP
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be ...{{dropped:14}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Aug  5 23:33:29 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 5 Aug 2014 14:33:29 -0700
Subject: [R]
 =?windows-1252?q?R_script_in_batch_mode_=97_Echoing_messages_?=
 =?windows-1252?q?to_windows_shell?=
In-Reply-To: <CAEfsz7qfTov=vapBQtY9GfUgaPzU125cM22-sNVxd0bH1C+RqA@mail.gmail.com>
References: <CAEfsz7qfTov=vapBQtY9GfUgaPzU125cM22-sNVxd0bH1C+RqA@mail.gmail.com>
Message-ID: <A2FC44EB-02B7-4514-8394-E1EB37B515EA@comcast.net>


On Aug 5, 2014, at 1:53 PM, Dominic Comtois wrote:

> I have an R script which is to be run in batch mode from a Windows shell
> and I need to "echo" messages to this shell (reporting that this step has
> succeeded and that other failed, and so on).
> 
> A combination of R CMD BATCH myscript.R con and options(echo=FALSE) is not
> really an option since I also need to generate an .Rout file with all the
> commands and outputs.
> 
> I have tried shell("echo Some text") to no avail.
> 
> Any help most appreciated!
> 
> 	[[alternative HTML version deleted]]

This was just seen on SO:

"If my guess is correct, shell("echo Some test > CON") should work. ?  Harry Johnston 1 min"

If you had read the Posting Guide, you might have seen that cross-posting to multiple sites is deprecated.

-- 

David Winsemius
Alameda, CA, USA


From 538280 at gmail.com  Wed Aug  6 03:41:03 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 5 Aug 2014 19:41:03 -0600
Subject: [R] break loop with keypress
In-Reply-To: <CAPVh6j7yq6fephd5WB3r=KKSG7DbaO9+9ouQ819yX-DB79qUGg@mail.gmail.com>
References: <CAPVh6j7yq6fephd5WB3r=KKSG7DbaO9+9ouQ819yX-DB79qUGg@mail.gmail.com>
Message-ID: <CAFEqCdx4QZdmOT-JXhobK9jHiUKz=pBC9vPsFvdbCMrsUqiDZQ@mail.gmail.com>

You could create a tcltk window that looks for a button click and/or
key press and when that happens change the value of a variable.  Then
in your loop you just look at the value of the same variable and break
when the value changes.

On Tue, Aug 5, 2014 at 6:13 AM, William Simpson
<william.a.simpson at gmail.com> wrote:
> This works, but it is not quite what I need:
>
> par(mar=rep(0,4))
>
> while(1)
>   {
>   img1<-matrix(runif(2500),50,50)
>   dev.hold(); image(img1,useRaster=TRUE); dev.flush()
>   img2<-matrix(runif(2500),50,50)
>   dev.hold(); image(img2,useRaster=TRUE); dev.flush()
>   }
>
> I would like to do this:
> while(!kbhit())
>   {
>   ...
>
> where kbhit() polls the keyboard, returning a non-zero integer if the
> keyboard buffer has something in it. The animation loop continues
> until a key is pressed.
>
> All the ways of getting user input I have seen (e.g. getGraphicsEvent)
> are not suitable because they would wait on each pass through the loop
> until the key is pressed and therefore no animation would be
> presented.
>
> Any ideas on how to present a continuous animation loop which is
> broken upon user input (keypress or mouse button press)? I am using
> Windows 7. Thanks very much for any help.
>
> Bill
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jiangyunbei at y7mail.com  Wed Aug  6 02:50:02 2014
From: jiangyunbei at y7mail.com (Jenny Jiang)
Date: Tue, 5 Aug 2014 17:50:02 -0700
Subject: [R] weighted network centrality measures by network size
Message-ID: <1407286202.88367.YahooMailNeo@web160903.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/6b45c606/attachment.pl>

From peter.salzmanuser at gmail.com  Wed Aug  6 04:59:48 2014
From: peter.salzmanuser at gmail.com (peter salzman)
Date: Tue, 5 Aug 2014 22:59:48 -0400
Subject: [R] Frequencies for a list of vectors
In-Reply-To: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
References: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
Message-ID: <CAHdotinoWsiCLgkLB+pdSLce5Ta+1+C5zq=XRsoccojHzA7Cfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/db0bc963/attachment.pl>

From peter.salzmanuser at gmail.com  Wed Aug  6 05:05:23 2014
From: peter.salzmanuser at gmail.com (peter salzman)
Date: Tue, 5 Aug 2014 23:05:23 -0400
Subject: [R] Frequencies for a list of vectors
In-Reply-To: <CAHdotinoWsiCLgkLB+pdSLce5Ta+1+C5zq=XRsoccojHzA7Cfw@mail.gmail.com>
References: <CAHrHE-TzhuLZJ0fa9yS51QrVz3EobPRbctdh8fb+VT2QpvoxBw@mail.gmail.com>
	<CAHdotinoWsiCLgkLB+pdSLce5Ta+1+C5zq=XRsoccojHzA7Cfw@mail.gmail.com>
Message-ID: <CAHdotikKWDqZ5EzzT-CnBFcOTpE-dAryyzte+vnXy5bsDFB6fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140805/f0457791/attachment.pl>

From tring at gvdnet.dk  Wed Aug  6 08:33:34 2014
From: tring at gvdnet.dk (Troels Ring)
Date: Wed, 06 Aug 2014 08:33:34 +0200
Subject: [R] doubleYScale from latticeExtra, problems with style
In-Reply-To: <CADv2QyGRi971BkaiL8C6zrMyjfFZMzFv2=RYG148pNHj1eseJQ@mail.gmail.com>
References: <53E112C3.6080508@gvdnet.dk>
	<CADv2QyGRi971BkaiL8C6zrMyjfFZMzFv2=RYG148pNHj1eseJQ@mail.gmail.com>
Message-ID: <53E1CC3E.5060500@gvdnet.dk>

Hi Dennis - thanks a lot - I do not seem to make any progress from 
reading the pages in the lattice book or the documentation of the 
doubleYScale function.
All best wishes
Troels



Den 05-08-2014 20:49, Dennis Murphy skrev:
> Hi:
>
> This *partially* works, although I don't see why it shouldn't work completely:
>
> update(sd,
>     par.settings = list(axis.text = list(cex = 1.2),
>                         par.ylab.text = list(cex = 1.5)))
>
> It fixes the y-axis text sizes, but it doesn't fix the size of the
> Y-variable names. See pp. 125-126 of the Lattice book for a
> description.
>
> Dennis
>
> On Tue, Aug 5, 2014 at 10:22 AM, Troels Ring <tring at gvdnet.dk> wrote:
>> Dear friends - below is a small example showing a problem I have
>> understanding doubleYScale from latticeExtra -
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> Both obj1 and obj2 are formatted as I wanted - but when combined the
>> formatting is lost. How comes?
>> Best wishes
>> Troels Ring
>> Aalborg, Denmark
>>
>> library(latticeExtra)
>> T <- seq(1,200,length=100)
>> Y1 <- 10+2*T+0.05*T^2 + rnorm(100,0,40)
>> Y2 <- 0.1 + sqrt(T)+rnorm(100,1,1)
>> tesobj <- data.frame(T=T,Y1=Y1,Y2=Y2)
>>
>>
>> obj1 <-
>> xyplot(Y1~T,tesobj,xlab=list(label="Time",cex=1.5),ylab=list(label="Y1",
>> cex=1.5),scales=list(y=list(cex=1.2),x=list(cex=1.2)),
>> panel = function(x,y,...){
>> panel.xyplot(x,y,...,pch=19)
>> panel.loess(x,y,...,lwd=3)
>> })
>> obj1
>>
>> obj2 <-
>> xyplot(Y2~T,tesobj,xlab=list(label="Time",cex=1.5),ylab=list(label="Y2",
>> cex=1.5),scales=list(y=list(cex=1.2),x=list(cex=1.2)),
>> panel = function(x,y,...){
>> panel.xyplot(x,y,...,pch=20)
>> panel.loess(x,y,...,lwd=3)})
>> obj2
>>
>> (sd <- doubleYScale(obj1,obj2,add.ylab2=TRUE))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rguy at 123mail.org  Wed Aug  6 08:46:17 2014
From: rguy at 123mail.org (Rguy)
Date: Wed, 6 Aug 2014 07:46:17 +0100
Subject: [R] Old g++ in Rtools
Message-ID: <CAEorq2Mn75CxNBVrv+S+cTpemnsOgpQaDobp6yHropFWhqPHmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/2a48c736/attachment.pl>

From ntfredo at gmail.com  Wed Aug  6 07:50:10 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 6 Aug 2014 08:50:10 +0300
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <f131122e-782d-4eee-b309-13bdc61009dc@email.android.com>
References: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
	<f131122e-782d-4eee-b309-13bdc61009dc@email.android.com>
Message-ID: <CAGh51gTREgRM2y1TdEkuEnbJoe=4VDdGHbeS7ntes257mW4Crw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/59b9cbf5/attachment.pl>

From ntfredo at gmail.com  Wed Aug  6 08:39:16 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 6 Aug 2014 09:39:16 +0300
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <CAGh51gTREgRM2y1TdEkuEnbJoe=4VDdGHbeS7ntes257mW4Crw@mail.gmail.com>
References: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
	<f131122e-782d-4eee-b309-13bdc61009dc@email.android.com>
	<CAGh51gTREgRM2y1TdEkuEnbJoe=4VDdGHbeS7ntes257mW4Crw@mail.gmail.com>
Message-ID: <CAGh51gSZkAwLMXumTd1PBJmSKcqQ0wz3joBVk1xwe=dEyaS3Gg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/4a10c331/attachment.pl>

From ntfredo at gmail.com  Wed Aug  6 09:48:06 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 6 Aug 2014 10:48:06 +0300
Subject: [R] object of type 'closure' is not subsettable
In-Reply-To: <CAGh51gSZkAwLMXumTd1PBJmSKcqQ0wz3joBVk1xwe=dEyaS3Gg@mail.gmail.com>
References: <CAGh51gRT5eHctmmvd+1jzgCabWWoc9_jgdoqX_9Gw4pwuObGNQ@mail.gmail.com>
	<f131122e-782d-4eee-b309-13bdc61009dc@email.android.com>
	<CAGh51gTREgRM2y1TdEkuEnbJoe=4VDdGHbeS7ntes257mW4Crw@mail.gmail.com>
	<CAGh51gSZkAwLMXumTd1PBJmSKcqQ0wz3joBVk1xwe=dEyaS3Gg@mail.gmail.com>
Message-ID: <CAGh51gQ9v0_V6_z0COqYU8-4_mhzHEB_fDTt221WvkNeum4EOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/608ca9c1/attachment.pl>

From dmcp at webmail.co.za  Wed Aug  6 09:59:31 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Wed, 06 Aug 2014 09:59:31 +0200
Subject: [R] How to optimizing the code for calculating the launch time
In-Reply-To: <CACB+=Lif7R0sFJXL2pDJkEntU=-qs9ZG6woaUSFj9tchokrh8A@mail.gmail.com>
References: <CACB+=Lif7R0sFJXL2pDJkEntU=-qs9ZG6woaUSFj9tchokrh8A@mail.gmail.com>
Message-ID: <8fb87972f389b59fb4b0debe97a1f756@www.webmail.co.za>

On Tue, 5 Aug 2014 09:51:56 +0300 Lingyi Ma <lingyi.ma at gmail.com> wrote

> My dataset:
> 
>     Item_Id    Year_Month
>  B65623262     201204
>  B58279745     201204
>  B33671102     201204
>  B36630946     201204
>  B63270151     201204
>  B63270133     201204
> 
> 
> 
>  I have written my code to calculate one more column which is the product
> maturity time as the following:
> 
> launchtime<-function(g){
> 
> su<-data.frame(NULL)    #product maturity time
> 
> g<-g[order(g$Item_Id,g$Year_Month),]
> 
> #get the lauching time
> index2<-unique(g$Item_Id)
> 
> for(u in 1:length(index2)){
> m2<-g[g$Item_Id==index2[u],]
> 
> lt<-numeric(0)
> lt[1]<-0
> year<-as.numeric(substring(m2$Year_Month,1,4))
> month<-as.numeric(substring(m2$Year_Month,5,6))
> if(dim(m2)[1]==1){}else{
>  for(i in 1:(dim(m2)[1]-1)){
> j<-i+1
> lt[j]<-(12*(year[j]-year[1])+month[j])-(month[1])
> }}
> g2<-cbind(m2,lt)
> su<-rbind(su,g2)
> }
> 
> return(su)
> 
> }
> 
> 
> 
> How to optimize my code-. it takes so long time to run.
> 
> 
> Kind regards,
> Tammy
> 
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please read the posting guide - and the footer to just about every message on
the list (just above): Do not post html - it makes your messages hard to read.

Sample data and an example of the expected output will also go a long way to
help us understand your problem and help you.

Having writ that, welcome to Circles 1, 2, 3, 3.1, and 8.1.30 of The R Inferno
http://www.burns-stat.com/documents/books/the-r-inferno/
Get a copy. Read it. The time it takes will pay off ten-fold in coping with
common R mistakes. (And we should all thank Dr Burns for providing the
download at the best of all possible prices...) (Don't try and understand it
all at once - take note of the bits that make sense.)

To optimise your code:
* get rid of the inner loop (I don't think you need it)
* do not grow objects if possible, especially do not grow them inside a loop
* to get the results (I think) you want, put in the parentheses you (seem to
have) missed.

My version of your code below. Hopefully the comments will be of assistance.

#====================================================================

launchtime <- function(g) {

  g <- cbind(g[order(g$Item_Id,g$Year_Month),], launch = NA]
  # Inside a function you are working with a copy of the data.
  # This will not change the original and will (should be) safe.

  #get the lauching time
  index2 <- unique(g$Item_Id)

  next_row <- 1

  # for(u in 1:length(index2)){
  #   m2<-g[g$Item_Id==index2[u],]

  # for (u in seq_along(index2)) is better, but in this case I prefer
  for (u in index2) {
    m2 <- g[g$Item_Id == index2]

    year<-as.numeric(substring(m2$Year_Month,1,4))
    month<-as.numeric(substring(m2$Year_Month,5,6))
    # hmmm - probably better to use "as.integer()" in this case. 
    # Also, if Year_Month is already numeric, the following might
    # work better (or not...)
    # year <- floor(m2$Year_Month / 100)
    # month <- m2$Year_Month %% 100

    # I don't think you need to loop...
    lt <- 12 * (year - year[1]) + month - month[1]
    # (Parentheses are mine - but I'm sure you need them)

    g$launch[next_row:(next_row + length(lt) - 1)] <- lt
    next_row <- next_row + length(lt)
    # given that we've eliminated the inner loop, you could probably
    # cbind() and rbind() OK - but this should be (at least a bit)
    # faster
  }
  g

}
#
#====================================================================
Cheers.

____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Cotlands - Shaping tomorrows Heroes http://www.cotlands.org.za/


From amos.elberg at gmail.com  Wed Aug  6 10:22:42 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Wed, 6 Aug 2014 04:22:42 -0400
Subject: [R] Old g++ in Rtools
In-Reply-To: <CAEorq2Mn75CxNBVrv+S+cTpemnsOgpQaDobp6yHropFWhqPHmA@mail.gmail.com>
References: <CAEorq2Mn75CxNBVrv+S+cTpemnsOgpQaDobp6yHropFWhqPHmA@mail.gmail.com>
Message-ID: <etPan.53e1e5d2.625558ec.85a6@Amoss-Mac-Pro-2.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/72f1984e/attachment.pl>

From mail at p-roocks.de  Tue Aug  5 12:48:17 2014
From: mail at p-roocks.de (Patrick Roocks)
Date: Tue, 5 Aug 2014 12:48:17 +0200
Subject: [R] [R-pkgs] rPref - new package for preferences and Skylines
Message-ID: <53E0B671.8000801@p-roocks.de>

rPref is a new package for Skyline computation and some slight 
generalizations (database preferences).

The Skyline of a dataset selects tuples which are Pareto-optimal with 
respect to given optimization goals. Only those tuples are returned, 
which are not dominated by any other tuple. A tuple dominates another 
tuple if it is better than another tuple in all relevant dimensions 
(strictly better at least in one dimension).

rPref offers efficient Skyline computation (algorithms are in C++) and 
some related stuff (e.g. maxima of other preference orders, top-k 
preference selection, some tools for visualization).

Find more information and examples at: http://www.p-roocks.de/rpref

Feel free to send a mail to me for suggestions, bug reports, etc.

Patrick

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From kemphillips at comcast.net  Tue Aug  5 14:31:29 2014
From: kemphillips at comcast.net (Kem Phillips)
Date: Tue, 5 Aug 2014 08:31:29 -0400
Subject: [R] [R-pkgs] New version of the symmoments package
Message-ID: <004701cfb0a9$2f051ea0$8d0f5be0$@comcast.net>

R users,

Version 1 of the symmoments package computed LaTeX expressions for the
central moments of the multivariate normal distribution, and evaluated such
moments at specified variance-covariance matrices.

In version 1.2, symmoments has been augmented to calculate Latex expressions
of non-central multivariate moments, and to calculate the expected values of
such moments, as well as the expected values of multivariate polynomials. In
addition, it is shown in the vignette that first non-central multivariate
moments are in a one-to-one relationship to phylogenetic trees, and
functions making this correspondence and the correspondence with matchings
are provided.

The new functions are as follows:

The toLatex_noncentral function computes the Latex representations of a
non-central moment.

The evaluate_noncentral computes the value of a non-central moment.

The evaluate_expected.polynomial function evaluates the expected value of a
multivariate polynomial defined by a list, multipol object, or mpoly object.

The convert.multipol function converts between multipol objects and
multivariate polynomials defined by lists.

The convert.mpoly function converts between mpoly objects and multivariate
polynomials defined by lists.

The tounsorted function converts a sorted moment (e.g. m123) to an unsorted
moment (e.g. m312).

The make.all.moments function computes all moments up to a specified size
and places them in the symmoments environment.

The integrate.polynomial function integrates a multivariate polynomial
against the normal distribution using ordinary integration.

The functions toMoment, toNewick, and toMatching convert among moment
L-matrices, Newick trees, and ape matching objects.

Please forward any comments or corrections to me at

kemphillips at comcast.net <mailto:kemphillips at comcast.net> 

Thanks.

 

Kem Phillips

 


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From william.a.simpson at gmail.com  Wed Aug  6 11:01:40 2014
From: william.a.simpson at gmail.com (William Simpson)
Date: Wed, 6 Aug 2014 10:01:40 +0100
Subject: [R] break loop with keypress
In-Reply-To: <CAFEqCdx4QZdmOT-JXhobK9jHiUKz=pBC9vPsFvdbCMrsUqiDZQ@mail.gmail.com>
References: <CAPVh6j7yq6fephd5WB3r=KKSG7DbaO9+9ouQ819yX-DB79qUGg@mail.gmail.com>
	<CAFEqCdx4QZdmOT-JXhobK9jHiUKz=pBC9vPsFvdbCMrsUqiDZQ@mail.gmail.com>
Message-ID: <CAPVh6j5numCaLrWo9=ALKZhDtg7a+RoKcAim-EUw2N_kBX+AcQ@mail.gmail.com>

Thanks Greg.
I guess another option is to call a C function directly. On Windows I
see there is a function _kbhit() in conio.h. Not sure if it would be
that simple.
Write a .c file

#include <conio.h>

int main(void)
{
  int ch;
  ch= _kbhit();
  return ch;
}

Then do the necessary stuff to call that from R.
http://mazamascience.com/WorkingWithData/?p=1067

Bill

On 06/08/2014, Greg Snow <538280 at gmail.com> wrote:
> You could create a tcltk window that looks for a button click and/or
> key press and when that happens change the value of a variable.  Then
> in your loop you just look at the value of the same variable and break
> when the value changes.
>
> On Tue, Aug 5, 2014 at 6:13 AM, William Simpson
> <william.a.simpson at gmail.com> wrote:
>> This works, but it is not quite what I need:
>>
>> par(mar=rep(0,4))
>>
>> while(1)
>>   {
>>   img1<-matrix(runif(2500),50,50)
>>   dev.hold(); image(img1,useRaster=TRUE); dev.flush()
>>   img2<-matrix(runif(2500),50,50)
>>   dev.hold(); image(img2,useRaster=TRUE); dev.flush()
>>   }
>>
>> I would like to do this:
>> while(!kbhit())
>>   {
>>   ...
>>
>> where kbhit() polls the keyboard, returning a non-zero integer if the
>> keyboard buffer has something in it. The animation loop continues
>> until a key is pressed.
>>
>> All the ways of getting user input I have seen (e.g. getGraphicsEvent)
>> are not suitable because they would wait on each pass through the loop
>> until the key is pressed and therefore no animation would be
>> presented.
>>
>> Any ideas on how to present a continuous animation loop which is
>> broken upon user input (keypress or mouse button press)? I am using
>> Windows 7. Thanks very much for any help.
>>
>> Bill
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>


From sylvain.willart at gmail.com  Wed Aug  6 13:47:55 2014
From: sylvain.willart at gmail.com (sylvain willart)
Date: Wed, 6 Aug 2014 13:47:55 +0200
Subject: [R] Breusch-Pagan heterosckedasticity test for mixed models - does
 it exist ?
Message-ID: <CABW9NAyeUNvqOaVipgwB54y60V6C257jKGs5c+UxR6rMM_anDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/cdd427e9/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Aug  6 14:44:04 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 06 Aug 2014 05:44:04 -0700
Subject: [R] Old g++ in Rtools
In-Reply-To: <etPan.53e1e5d2.625558ec.85a6@Amoss-Mac-Pro-2.local>
References: <CAEorq2Mn75CxNBVrv+S+cTpemnsOgpQaDobp6yHropFWhqPHmA@mail.gmail.com>
	<etPan.53e1e5d2.625558ec.85a6@Amoss-Mac-Pro-2.local>
Message-ID: <8504cd2b-d6c5-4c7d-af88-1ddaa1c79e2c@email.android.com>

Re why not more discussion... Well, one reason might be that this is topic belongs on the R-devel mailing list.

(Are you really thinking that this is a "free" boost with so many packages that need source edits to compile with the new compilers? There are over 5000 packages on CRAN... are you sending patches to all those maintainers?)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 6, 2014 1:22:42 AM PDT, "Amos B. Elberg" <amos.elberg at gmail.com> wrote:
>I???m working on a Mac so ymmv, but I???ve been running benchmarks of
>vanilla R from cran vs. recompiles with different versions of gcc and
>R, and I see a speedup of 20-30% vs the cran binary after recompiling
>with gnu 4.9. ??Its quite distinct. ??
>
>Each jump in gcc revision (4.7-4.8, 4.8-4.9) seems to improve benchmark
>performance by around 10% over the previous generation. ??
>
>So there may be advantages to recompiling yourself.
>
>On the other hand, there may be potential issues compiling some
>packages. ??Some of the benchmarking I???ve been doing is 3.1.1 vs. pqR
>(distinctly faster than 3.1.1, even without ???helper threads???),
>which is based on R 2.15.0, which in turn forces you to use older
>versions of some packages, some of which have language-compatibility
>issues with recent compilers. ??The version of Rcpp that accepts R
>2.15.0, for example, won???t compile against gcc 4.9. ??You may find
>that the current versions of other packages have similar issues with
>recent gnu compilers, I can???t say. ??
>
>I???m surprised, frankly, that there isn???t more discussion of this,
>considering the size of the data and complexity of the problems people
>are feeding into R, and the possibility of essentially ???free???
>performance boosts.
>
>--??
>Amos Elberg
>Sent with Airmail
>
>From:??Rguy <rguy at 123mail.org>
>Reply:??Rguy <rguy at 123mail.org>>
>Date:??August 6, 2014 at 2:47:47 AM
>To:??r-help at r-project.org <r-help at r-project.org>>
>Subject:?? [R] Old g++ in Rtools  
>
>I recently downloaded Rtools. I see the g++ version is  
>gcc version 4.6.3 20111208 (prerelease) (GCC)  
>
>I also recently downloaded MinGW. Its version of g++ is  
>gcc version 4.8.1 (GCC)  
>
>I believe that later versions of g++ provide better support for C++11. 
>
>Why does Rtools provide a version considerably older than the latest?  
>Any plans to update the version?  
>Is it bad practice to compile with a later version when interfacing
>with R?  
>
>[[alternative HTML version deleted]]  
>
>______________________________________________  
>R-help at r-project.org mailing list  
>https://stat.ethz.ch/mailman/listinfo/r-help  
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html  
>and provide commented, minimal, self-contained, reproducible code.  
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Wed Aug  6 15:03:36 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 6 Aug 2014 09:03:36 -0400
Subject: [R] Old g++ in Rtools
In-Reply-To: <CAEorq2Mn75CxNBVrv+S+cTpemnsOgpQaDobp6yHropFWhqPHmA@mail.gmail.com>
References: <CAEorq2Mn75CxNBVrv+S+cTpemnsOgpQaDobp6yHropFWhqPHmA@mail.gmail.com>
Message-ID: <CAP01uRmKDQ818Bn2H1cck+zPRS=78RMSTt=qQrcZ6qt58X91vA@mail.gmail.com>

On Wed, Aug 6, 2014 at 2:46 AM, Rguy <rguy at 123mail.org> wrote:
> I recently downloaded Rtools. I see the g++ version is
> gcc version 4.6.3 20111208 (prerelease) (GCC)
>
> I also recently downloaded MinGW. Its version of g++ is
> gcc version 4.8.1 (GCC)
>
> I believe that later versions of g++ provide better support for C++11.
> Why does Rtools provide a version considerably older than the latest?
> Any plans to update the version?
> Is it bad practice to compile with a later version when interfacing with R?

Later versions of gcc/g++ also support openmp which 4.6.3 does not.

There may be other C/C++ packages too that can't be used until with
Rtools until it is upgraded to a more recent version.

By the way, there is a MinGW 4.8.2 distribution (slightly more recent
than the one you downloaded) here:
http://nuwen.net/mingw.html


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From Sebastien.Bihorel at cognigencorp.com  Wed Aug  6 16:09:41 2014
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Wed, 6 Aug 2014 10:09:41 -0400
Subject: [R] Equivalent of read.table for object rather than file
In-Reply-To: <53E11F4C.3000900@cognigencorp.com>
References: <53E1145C.1020602@cognigencorp.com>
	<53E11F4C.3000900@cognigencorp.com>
Message-ID: <53E23725.5050404@cognigencorp.com>

Hello,

For some reason, I did not receive your replies on my email client and had to copy-paste the content of the thread
directly from the R archive website. Thank you for pointing out the text connection solution.

Regarding the posting guide, I read it 6-7 years ago when I joined the mailing list and must admit that I did not
read it since. Never had any issues in the past sending post in plain text or HTML format. That being said, I
will be careful about this in the future.

Thank you for your help.

Sebastien


On 05/08/2014 19:15, sbihorel wrote:
>/  Hi,
/>/
/>/  Thanks for the info. Unfortunately, read.table() does not have the text argument in the version of R that I can use.
/>/  Do you know when was this argument introduced?
/
No, but the posting guide asked you to update *before posting* (have you
yet read it?: you still sent HTML when asked not to).

In any case, the help text tells you how to do it: use a text connection.

>/
/>/  Sebastien
/>/
/>/  On 05/08/2014 18:29, sbihorel wrote:
/>>/  /  Hi,
/>/  />/
/>/  />/  Let's say that I have a scalar character object called tmp which stores
/>/  />/  the entire content of an ASCII file. Is there a function that would
/>/  />/  process tmp the same way read.table() would process the content of the
/>/  />/  original ASCII file?
/>/  />/
/>/  />/  The content of tmp will come from a database, and I want to extract the
/>/  />/  data without writing and reading to disk or without asking the database
/>/  />/  to transform the file content into a table.
/>/  /
/>/  The equivalent is read.table.  See its 'text' argument:
/>/
/>/         text: character string: if 'file' is not supplied and this is, then
/>/               data are read from the value of 'text' via a text connection.
/>/               Notice that a literal string can be used to include (small)
/>/               data sets within R code.
/>/
/>>/  /
/>/  />/  Thank you
/>/  />/
/>/  />/  Sebastien
/>/  />/  //
/>/  />/
/>/  />/  	[[alternative HTML version deleted]]
/>/  />/
/>/  />/  ______________________________________________
/>/  />/  R-help at r-project.org  <https://stat.ethz.ch/mailman/listinfo/r-help>  mailing list
/>/  />/https://stat.ethz.ch/mailman/listinfo/r-help
/>/  />/  PLEASE do read the postingguidehttp://www.R-project.org/posting-guide.html
/>/  />/  and provide commented, minimal, self-contained, reproducible code.
/>/  />/
/>/  /PLEASE do.
/>/
/

-- 
Brian D. Ripley,ripley at stats.ox.ac.uk  <https://stat.ethz.ch/mailman/listinfo/r-help>
Professor of Applied Statistics,http://www.stats.ox.ac.uk/~ripley/  <http://www.stats.ox.ac.uk/%7Eripley/>
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lbagua.cloud at gmail.com  Wed Aug  6 14:55:55 2014
From: lbagua.cloud at gmail.com (Luis Borda de Agua)
Date: Wed, 6 Aug 2014 13:55:55 +0100
Subject: [R] keep information on the number of warnings
In-Reply-To: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>
References: <36A5FEF8-75C0-4A24-948E-3EAB707B37C6@gmail.com>
Message-ID: <572124C1-8AC7-42C8-A8E9-DA15BA0EE5D7@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/75584983/attachment.pl>

From jasondonnald4 at gmail.com  Wed Aug  6 16:11:09 2014
From: jasondonnald4 at gmail.com (Jason Donnald)
Date: Wed, 6 Aug 2014 10:11:09 -0400
Subject: [R] How to perform training and testing using DPpackage of R for
 Non parametric Bayesian predictive analysis?
Message-ID: <CAPdWG3t3giEon2v=BDXyBCcHmTUvsvhCQea5CGUDYw8+d+GSRw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/008f23de/attachment.pl>

From ssefick at gmail.com  Wed Aug  6 17:22:56 2014
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 6 Aug 2014 10:22:56 -0500
Subject: [R] R Foundation publish citable Manual for packages
Message-ID: <CADKEMqg62ArpT6OMn2-sZDF5CkYkOxg5q4OdSe+OcmkXEProhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/b89b0f89/attachment.pl>

From stausland.johnsen at iln.uio.no  Wed Aug  6 17:24:55 2014
From: stausland.johnsen at iln.uio.no (Sverre Stausland)
Date: Wed, 6 Aug 2014 17:24:55 +0200
Subject: [R] citation() command doesn't work in R.3.1.1
Message-ID: <CACtaF7zhuvgV8rn3xJqXAdkx-egf8NCOyRJaZBeuO=uD9B2ssw@mail.gmail.com>

> citation()
Error: $ operator is invalid for atomic vectors
In addition: Warning message:
In packageDescription(pkg = package, lib.loc = dirname(dir)) :
  no package 'base' was found

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Norwegian (Bokm?l)_Norway.1252
[2] LC_CTYPE=Norwegian (Bokm?l)_Norway.1252
[3] LC_MONETARY=Norwegian (Bokm?l)_Norway.1252
[4] LC_NUMERIC=C
[5] LC_TIME=Norwegian (Bokm?l)_Norway.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.1

> Sys.getlocale()
[1] "LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian
(Bokm?l)_Norway.1252;LC_MONETARY=Norwegian
(Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian
(Bokm?l)_Norway.1252"


From zilefacelvis at yahoo.com  Wed Aug  6 17:50:12 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 6 Aug 2014 08:50:12 -0700
Subject: [R] Apply quantile function to each dataframe in a List R
In-Reply-To: <1b8f9ba0.4305.147a41afecc.Coremail.rhelpmaillist@163.com>
References: <1407201443.69661.YahooMailNeo@web160603.mail.bf1.yahoo.com>
	<1b8f9ba0.4305.147a41afecc.Coremail.rhelpmaillist@163.com>
Message-ID: <1407340212.65901.YahooMailNeo@web160602.mail.bf1.yahoo.com>

Great! Thanks.
AT.


On Monday, August 4, 2014 8:59 PM, rhelpmaillist <rhelpmaillist at 163.com> wrote:



Try this:
lapply(a,function(x) apply(x[,-c(1,2)],2,quantile,probs=0.95))
# a is your example list
At 2014-08-05 09:17:23, "Zilefac Elvis" <zilefacelvis at yahoo.com> wrote:
>Hello,
>I would like to calculate for each numeric column in a dataframe, quantile(x,probs=o.95).
>My list object has 120 dataframes, each dataframe has 102 columns.
>Here is an example as well as a reproducible example:
>
>[[120]] 
>? Year Site Sim001 Sim002 Sim003 Sim004 Sim005 Sim006 Sim007 Sim008 Sim009 Sim010 Sim011 Sim012 Sim013 Sim014 Sim015
>...
>1 2001 GGG9 -26.96 -27.30 -31.62 -31.56 -28.58 -33.82 -32.53 -30.56 -34.09 -31.94 -28.85 -30.76 -25.44 -31.83 -32.98 
>2 2002 GGG9 -32.57 -39.15 -32.87 -32.91 -32.50 -35.35 -31.82 -38.22 -37.76 -36.70 -38.07 -36.99 -35.78 -33.61 -34.47 
>3 2003 GGG9 -37.14 -33.33 -31.53 -32.37 -37.97 -35.00 -31.79 -36.03 -34.48 -43.28 -30.47 -33.91 -39.28 -33.28 -34.13
>
>
>I have tried something like:
>
>output<-lapply(lst3,function(x) quantile(x,0.95,na.rm = TRUE)) but failed.
>
>Please help.
>AT.
>
>
>list(structure(list(Year = 2001:2005, Site = structure(c(1L, 
>1L, 1L, 1L, 1L), .Label = "G100", class = "factor"), Sim001 = c(-33.25, 
>-37.52, -34.58, -36.56, -41.62), Sim002 = c(-29.39, -29.35, -36.49, 
>-37.82, -31.6), Sim003 = c(-35.24, -35.2, -41.98, -32.87, -35.92 
>), Sim004 = c(-33.41, -38.76, -34.92, -34.46, -38.54), Sim005 = c(-38.22, 
>-40.83, -37.55, -39.85, -39.02), Sim006 = c(-39.5, -34.35, -35.35, 
>-37.08, -31.21), Sim007 = c(-31.24, -32.77, -35.44, -41.1, -31.81 
>), Sim008 = c(-31.34, -32.61, -41.48, -49.67, -37.88), Sim009 = c(-33.62, 
>-41.62, -35.9, -35.3, -30.11), Sim010 = c(-39.99, -41.97, -36.96, 
>-47.55, -30.46), Sim011 = c(-34.39, -39.31, -33.68, -33.83, -39.24 
>), Sim012 = c(-33.38, -39.17, -41.91, -42.09, -37.97), Sim013 = c(-31.29, 
>-36.91, -34.52, -39.92, -50.34), Sim014 = c(-26, -43.03, -39.93, 
>-39.49, -40.47), Sim015 = c(-36.16, -40.72, -41.89, -38.75, -40.51 
>), Sim016 = c(-34.6, -47.22, -43.12, -42.55, -31.65), Sim017 = c(-35.47, 
>-50.25, -38.42, -39.82, -46.7), Sim018 = c(-40.57, -32.57, -35.16, 
>-42.74, -36.55), Sim019 = c(-34.48, -39.42, -33.47, -40.78, -42.11 
>), Sim020 = c(-37.23, -43.42, -37, -41.89, -33.36), Sim021 = c(-32.85, 
>-37.18, -37.75, -38.22, -36.5), Sim022 = c(-42.2, -31.78, -38.01, 
>-43.85, -40.05), Sim023 = c(-36.94, -40.03, -42.37, -33.45, -36.9 
>), Sim024 = c(-40.03, -32.38, -45.69, -39.67, -36.97), Sim025 = c(-31.62, 
>-45.37, -39.73, -39.7, -40.93), Sim026 = c(-32.57, -38.02, -40.12, 
>-39.19, -41.55), Sim027 = c(-35.85, -31.56, -40.41, -47.34, -33.9 
>), Sim028 = c(-34.7, -38.88, -46.31, -32.77, -36.01), Sim029 = c(-36.67, 
>-51.07, -38.01, -39.3, -34.99), Sim030 = c(-30.54, -42.89, -35.83, 
>-42.01, -38.85), Sim031 = c(-31.85, -40.38, -37.87, -38.88, -40.28 
>), Sim032 = c(-33.56, -36.81, -37.11, -38.8, -34.17), Sim033 = c(-37.87, 
>-38.4, -39.56, -39.82, -36.37), Sim034 = c(-37.13, -32.84, -42.93, 
>-37.4, -44.44), Sim035 = c(-26.66, -41.08, -40.88, -39.22, -40.84 
>), Sim036 = c(-34.51, -44.35, -39.38, -33.86, -33.55), Sim037 = c(-33.89, 
>-33.5, -37.59, -53.07, -36.6), Sim038 = c(-35.14, -34.92, -36.96, 
>-43.16, -44.19), Sim039 = c(-31.4, -33.95, -39.67, -39.75, -38.53 
>), Sim040 = c(-33.18, -32.84, -36.04, -39.64, -40.71), Sim041 = c(-37.38, 
>-32.74, -44.38, -45.02, -43.96), Sim042 = c(-28.09, -34.78, -42.21, 
>-43.18, -40.85), Sim043 = c(-36.86, -35.93, -42.46, -41.11, -42.35 
>), Sim044 = c(-35.3, -41.2, -36.65, -44.91, -49.74), Sim045 = c(-32.84, 
>-37.83, -42.22, -41.14, -37.1), Sim046 = c(-32.85, -41.35, -37.01, 
>-35.27, -41.13), Sim047 = c(-38.19, -49.26, -40.83, -35.04, -38.49 
>), Sim048 = c(-37.98, -37.82, -40.33, -35.01, -36.94), Sim049 = c(-40.37, 
>-34.5, -39.55, -45.6, -31.79), Sim050 = c(-40.67, -36.04, -47.68, 
>-38.26, -46.9), Sim051 = c(-37.13, -31.42, -38.49, -36.58, -38.52 
>), Sim052 = c(-43.54, -32.82, -37.32, -41.71, -37.87), Sim053 = c(-31.61, 
>-37.32, -40.25, -37.24, -49.9), Sim054 = c(-38.85, -33.53, -46.48, 
>-38.27, -34.13), Sim055 = c(-30.71, -40.04, -43.77, -33.78, -33.5 
>), Sim056 = c(-30.3, -36.91, -38.49, -36.69, -31.43), Sim057 = c(-27.56, 
>-37.13, -39.45, -45.52, -33.24), Sim058 = c(-33.47, -35.26, -33.83, 
>-42.43, -45.4), Sim059 = c(-36.46, -35.64, -39.62, -37.95, -41.32 
>), Sim060 = c(-39.12, -41.71, -36.28, -36.27, -36.94), Sim061 = c(-29.86, 
>-45.73, -37.04, -43.84, -36.87), Sim062 = c(-29.46, -40.96, -39.43, 
>-41.75, -38.83), Sim063 = c(-36.48, -41.18, -39.59, -41.01, -36.31 
>), Sim064 = c(-32.49, -38.86, -33.16, -40.2, -32.65), Sim065 = c(-35.37, 
>-39.73, -41.7, -44.36, -41.26), Sim066 = c(-36.78, -38.5, -38.72, 
>-42.46, -39.25), Sim067 = c(-38.12, -37.92, -34.8, -35.18, -33.63 
>), Sim068 = c(-31.75, -36.77, -32.5, -44.28, -36.65), Sim069 = c(-33.48, 
>-46.06, -39.48, -42.89, -39.72), Sim070 = c(-33.53, -36.53, -36.28, 
>-37.78, -39.22), Sim071 = c(-36.27, -42.68, -35.28, -38.86, -36.63 
>), Sim072 = c(-34.63, -34.58, -41.13, -41.34, -43.57), Sim073 = c(-32.21, 
>-31.49, -42.97, -38.86, -34.91), Sim074 = c(-30.95, -35.74, -39.91, 
>-41.75, -35.61), Sim075 = c(-39.26, -37.01, -42.23, -49.56, -44.93 
>), Sim076 = c(-37.78, -44.19, -36.35, -36.26, -31.09), Sim077 = c(-33.75, 
>-37.06, -36.3, -41.04, -40.1), Sim078 = c(-41.82, -40.69, -41.61, 
>-37.41, -34.37), Sim079 = c(-30.45, -35.66, -33.88, -39.71, -37.5 
>), Sim080 = c(-43.67, -31.8, -38.37, -35.14, -35.67), Sim081 = c(-28.79, 
>-37.91, -39.82, -39.59, -41.77), Sim082 = c(-35.58, -37, -37.97, 
>-41.14, -47.98), Sim083 = c(-32.37, -34.27, -33.67, -38.93, -40.38 
>), Sim084 = c(-33.81, -40.81, -36.3, -42.71, -38.43), Sim085 = c(-30.21, 
>-34.81, -40.97, -36.55, -41.82), Sim086 = c(-32.24, -37.59, -40.06, 
>-39.55, -40.69), Sim087 = c(-37.48, -38.07, -36.43, -36.04, -39.13 
>), Sim088 = c(-34.27, -39.35, -37.89, -42.24, -37.19), Sim089 = c(-36.11, 
>-46.55, -32.86, -50.21, -41.44), Sim090 = c(-30.37, -40.42, -49.72, 
>-35.55, -40.1), Sim091 = c(-34.51, -35.69, -41, -35.08, -39.19 
>), Sim092 = c(-37.19, -41.45, -42.98, -38.96, -33.84), Sim093 = c(-35.54, 
>-43.21, -38.24, -43.51, -32.87), Sim094 = c(-35.79, -36.46, -38.3, 
>-43, -46.64), Sim095 = c(-34.6, -38.21, -40.7, -41.43, -33.44 
>), Sim096 = c(-29.59, -40.29, -37.99, -35.51, -34.79), Sim097 = c(-31.38, 
>-40.3, -40.68, -35.82, -38.22), Sim098 = c(-34.85, -37.81, -38.07, 
>-38.12, -32.17), Sim099 = c(-32.57, -39.43, -35.26, -41.84, -42.15 
>), Sim100 = c(-34.39, -32.95, -37.06, -36.26, -30.58)), .Names = c("Year", 
>"Site", "Sim001", "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", 
>"Sim007", "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", "Sim013", 
>"Sim014", "Sim015", "Sim016", "Sim017", "Sim018", "Sim019", "Sim020", 
>"Sim021", "Sim022", "Sim023", "Sim024", "Sim025", "Sim026", "Sim027", 
>"Sim028", "Sim029", "Sim030", "Sim031", "Sim032", "Sim033", "Sim034", 
>"Sim035", "Sim036", "Sim037", "Sim038", "Sim039", "Sim040", "Sim041", 
>"Sim042", "Sim043", "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", 
>"Sim049", "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", "Sim055", 
>"Sim056", "Sim057", "Sim058", "Sim059", "Sim060", "Sim061", "Sim062", 
>"Sim063", "Sim064", "Sim065", "Sim066", "Sim067", "Sim068", "Sim069", 
>"Sim070", "Sim071", "Sim072", "Sim073", "Sim074", "Sim075", "Sim076", 
>"Sim077", "Sim078", "Sim079", "Sim080", "Sim081", "Sim082", "Sim083", 
>"Sim084", "Sim085", "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", 
>"Sim091", "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", "Sim097", 
>"Sim098", "Sim099", "Sim100"), row.names = c(NA, -5L), class = "data.frame"), 
>? ? structure(list(Year = 2001:2005, Site = structure(c(1L, 1L, 
>? ? 1L, 1L, 1L), .Label = "G101", class = "factor"), Sim001 = c(-35.72, 
>? ? -40.46, -34.77, -36.67, -40.73), Sim002 = c(-31.3, -34.13, 
>? ? -39.98, -37.32, -30.51), Sim003 = c(-33.55, -38.12, -36.56, 
>? ? -33.5, -38.3), Sim004 = c(-30.05, -33.87, -39.94, -34.18, 
>? ? -38.63), Sim005 = c(-37.27, -34.94, -38.96, -42.79, -41.19 
>? ? ), Sim006 = c(-35.63, -36.82, -38.13, -36.87, -34.98), Sim007 = c(-27.59, 
>? ? -32.98, -36.89, -40.25, -32.3), Sim008 = c(-29.54, -34.74, 
>? ? -41.02, -43.63, -40.14), Sim009 = c(-30.72, -44, -35.83, 
>? ? -38.21, -36.12), Sim010 = c(-39.46, -38.1, -39.13, -46, -30.59 
>? ? ), Sim011 = c(-36.48, -38.52, -36.77, -38.19, -38.11), Sim012 = c(-36.71, 
>? ? -38.23, -40.25, -51.31, -42.63), Sim013 = c(-34.24, -40.3, 
>? ? -34.01, -39.42, -44.07), Sim014 = c(-33.1, -37.49, -36.55, 
>? ? -40.24, -38.44), Sim015 = c(-33.53, -37.84, -41.59, -43.04, 
>? ? -44.72), Sim016 = c(-35.15, -44.57, -44.93, -42.42, -35.56 
>? ? ), Sim017 = c(-33.02, -48.07, -36.57, -35.63, -50.69), Sim018 = c(-42.67, 
>? ? -33.15, -33.92, -48.02, -39.98), Sim019 = c(-33.02, -39.16, 
>? ? -34.91, -42.18, -38.37), Sim020 = c(-34.67, -37.89, -38.49, 
>? ? -41.72, -35.06), Sim021 = c(-35.24, -35.49, -35.58, -38.7, 
>? ? -35.2), Sim022 = c(-41.75, -33, -41.26, -43.6, -39.82), Sim023 = c(-38.13, 
>? ? -39.35, -42.01, -40.49, -36.56), Sim024 = c(-32.5, -37.02, 
>? ? -43.16, -42.43, -40.16), Sim025 = c(-37.41, -37.95, -39.31, 
>? ? -39.6, -39.21), Sim026 = c(-38.24, -36.08, -42.63, -40.08, 
>? ? -40.83), Sim027 = c(-35.6, -35.03, -43.19, -42.29, -34.04 
>? ? ), Sim028 = c(-35.86, -40.89, -48.83, -36.61, -33.78), Sim029 = c(-35.75, 
>? ? -52.6, -40.65, -39.12, -34.27), Sim030 = c(-33.19, -41.71, 
>? ? -38.1, -41.99, -36.21), Sim031 = c(-34.71, -31.96, -35.52, 
>? ? -42.43, -41.16), Sim032 = c(-34.41, -42.28, -34.63, -40.58, 
>? ? -34.14), Sim033 = c(-36.83, -35.83, -37.24, -41.1, -36.8), 
>? ? ? ? Sim034 = c(-39.72, -32.03, -45.69, -38.42, -42.68), Sim035 = c(-31.91, 
>? ? ? ? -35.69, -39.09, -38.06, -39.2), Sim036 = c(-33.61, -35.02, 
>? ? ? ? -36.76, -32.55, -38.27), Sim037 = c(-35.76, -30.48, -36.53, 
>? ? ? ? -49.4, -38.2), Sim038 = c(-35, -37.81, -40.07, -41.6, 
>? ? ? ? -42.33), Sim039 = c(-33.28, -38.22, -39.09, -37.44, -41.18 
>? ? ? ? ), Sim040 = c(-32.33, -36.15, -34.09, -41.64, -46.83), 
>? ? ? ? Sim041 = c(-39.17, -31.42, -41.74, -44.58, -39.88), Sim042 = c(-32.27, 
>? ? ? ? -33.52, -37.12, -43.51, -43.07), Sim043 = c(-35.33, -36.37, 
>? ? ? ? -42.72, -45.01, -41.98), Sim044 = c(-32.73, -36.37, -32.04, 
>? ? ? ? -39.35, -48.59), Sim045 = c(-33.78, -33.79, -41.64, -38.53, 
>? ? ? ? -42.21), Sim046 = c(-29.21, -36.07, -36.12, -41.03, -38.14 
>? ? ? ? ), Sim047 = c(-36.78, -50.09, -44.88, -34.3, -35.55), 
>? ? ? ? Sim048 = c(-33.83, -37.92, -41.95, -39.73, -37.8), Sim049 = c(-35.56, 
>? ? ? ? -35.14, -37.47, -45.06, -33.87), Sim050 = c(-38.84, -37.11, 
>? ? ? ? -44.97, -38.83, -38.13), Sim051 = c(-35, -34.96, -38.11, 
>? ? ? ? -34.21, -37.84), Sim052 = c(-45.4, -31.3, -39.58, -42.74, 
>? ? ? ? -38.96), Sim053 = c(-36.48, -35.9, -35.84, -38.88, -40.25 
>? ? ? ? ), Sim054 = c(-36.2, -36.94, -43.45, -41.74, -32.93), 
>? ? ? ? Sim055 = c(-38.29, -48.66, -38.54, -38.47, -44.17), Sim056 = c(-30.97, 
>? ? ? ? -39.42, -34.94, -34.87, -36.19), Sim057 = c(-30.09, -37.7, 
>? ? ? ? -38.06, -40.45, -35.23), Sim058 = c(-35.06, -37.86, -34.46, 
>? ? ? ? -39.21, -43.58), Sim059 = c(-41.69, -36.31, -42.44, -36, 
>? ? ? ? -40.72), Sim060 = c(-35.29, -37.92, -39.94, -36.1, -36.01 
>? ? ? ? ), Sim061 = c(-32.32, -46.74, -37.7, -40.31, -34.93), 
>? ? ? ? Sim062 = c(-30.24, -38.33, -39.18, -44.22, -35.74), Sim063 = c(-36.82, 
>? ? ? ? -37.58, -37.82, -37.38, -36.65), Sim064 = c(-36.99, -36.13, 
>? ? ? ? -33.74, -48.8, -33.04), Sim065 = c(-40.79, -40.89, -39.36, 
>? ? ? ? -41.78, -42.82), Sim066 = c(-35.63, -35.94, -41.35, -39.79, 
>? ? ? ? -34.41), Sim067 = c(-32.66, -36.93, -33.61, -36.58, -35.46 
>? ? ? ? ), Sim068 = c(-31.08, -32.84, -31.69, -41.63, -37.7), 
>? ? ? ? Sim069 = c(-31.23, -50.18, -38.75, -39.19, -37.59), Sim070 = c(-34.93, 
>? ? ? ? -38.12, -34.11, -38.38, -38.24), Sim071 = c(-35.74, -42.9, 
>? ? ? ? -31.74, -34.78, -44.95), Sim072 = c(-33.39, -38.35, -34.4, 
>? ? ? ? -43.7, -37.92), Sim073 = c(-33.88, -33.28, -34.27, -41.27, 
>? ? ? ? -41.41), Sim074 = c(-28.67, -42.77, -34.62, -46.53, -34.9 
>? ? ? ? ), Sim075 = c(-36.69, -38.74, -38.26, -43.82, -46.61), 
>? ? ? ? Sim076 = c(-37.98, -41.69, -37.9, -39.37, -35.59), Sim077 = c(-32.68, 
>? ? ? ? -36.56, -33.24, -37.02, -46.38), Sim078 = c(-44.5, -39.4, 
>? ? ? ? -37.77, -36.31, -36.6), Sim079 = c(-31.59, -40.09, -35.52, 
>? ? ? ? -38.87, -35.44), Sim080 = c(-39.49, -35.56, -35.18, -37.17, 
>? ? ? ? -40.51), Sim081 = c(-34.43, -31.35, -41.73, -38.51, -41.08 
>? ? ? ? ), Sim082 = c(-35.31, -35.39, -40.4, -39.26, -43.16), 
>? ? ? ? Sim083 = c(-31.32, -36.31, -37.74, -38.15, -42.86), Sim084 = c(-35.2, 
>? ? ? ? -37.24, -37.75, -37.89, -34.88), Sim085 = c(-29.85, -34.98, 
>? ? ? ? -39.61, -42.36, -42.27), Sim086 = c(-33.35, -34.59, -36.62, 
>? ? ? ? -34.5, -37.19), Sim087 = c(-33.74, -35.5, -43.51, -39.54, 
>? ? ? ? -41.67), Sim088 = c(-33.61, -42.81, -42.08, -41.47, -47.35 
>? ? ? ? ), Sim089 = c(-34.98, -40.7, -39.39, -46.97, -38.84), 
>? ? ? ? Sim090 = c(-31.32, -35.78, -44.32, -41.76, -36.65), Sim091 = c(-27.79, 
>? ? ? ? -35.75, -38.54, -39.24, -42.84), Sim092 = c(-36.96, -43.48, 
>? ? ? ? -39.4, -42.39, -30.09), Sim093 = c(-36.98, -38.15, -45, 
>? ? ? ? -49.77, -41.58), Sim094 = c(-35.32, -36.29, -45.47, -47.33, 
>? ? ? ? -45), Sim095 = c(-31.5, -40.29, -48.72, -43.27, -35.98 
>? ? ? ? ), Sim096 = c(-28.22, -33.74, -43.51, -40.02, -36.04), 
>? ? ? ? Sim097 = c(-33.17, -36.45, -37.88, -37.84, -42.69), Sim098 = c(-32.03, 
>? ? ? ? -37.82, -37.01, -35.38, -32.66), Sim099 = c(-36.53, -40.44, 
>? ? ? ? -39.56, -40.32, -37.81), Sim100 = c(-36.95, -36.72, -40.74, 
>? ? ? ? -33.22, -34.43)), .Names = c("Year", "Site", "Sim001", 
>? ? "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", "Sim007", 
>? ? "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", "Sim013", 
>? ? "Sim014", "Sim015", "Sim016", "Sim017", "Sim018", "Sim019", 
>? ? "Sim020", "Sim021", "Sim022", "Sim023", "Sim024", "Sim025", 
>? ? "Sim026", "Sim027", "Sim028", "Sim029", "Sim030", "Sim031", 
>? ? "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", "Sim037", 
>? ? "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", "Sim043", 
>? ? "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", "Sim049", 
>? ? "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", "Sim055", 
>? ? "Sim056", "Sim057", "Sim058", "Sim059", "Sim060", "Sim061", 
>? ? "Sim062", "Sim063", "Sim064", "Sim065", "Sim066", "Sim067", 
>? ? "Sim068", "Sim069", "Sim070", "Sim071", "Sim072", "Sim073", 
>? ? "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", "Sim079", 
>? ? "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", "Sim085", 
>? ? "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", "Sim091", 
>? ? "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", "Sim097", 
>? ? "Sim098", "Sim099", "Sim100"), row.names = c(NA, -5L), class = "data.frame"), 
>? ? structure(list(Year = 2001:2005, Site = structure(c(1L, 1L, 
>? ? 1L, 1L, 1L), .Label = "G102", class = "factor"), Sim001 = c(-40.62, 
>? ? -37.27, -37.53, -43.76, -42.51), Sim002 = c(-33.33, -35.19, 
>? ? -42.13, -37.15, -46.41), Sim003 = c(-44.2, -39.86, -46.55, 
>? ? -37.25, -38.49), Sim004 = c(-31.5, -37.68, -40.08, -41.95, 
>? ? -40.33), Sim005 = c(-37.87, -41.85, -37.11, -38.35, -43.68 
>? ? ), Sim006 = c(-41.31, -31.61, -39.66, -35.78, -38.77), Sim007 = c(-36.9, 
>? ? -35.99, -34.29, -37.65, -30.86), Sim008 = c(-35.2, -33.42, 
>? ? -39.12, -41.26, -35.69), Sim009 = c(-31.93, -43.89, -42.59, 
>? ? -38.03, -36.91), Sim010 = c(-38.69, -38.84, -34.32, -44.7, 
>? ? -29.88), Sim011 = c(-39.2, -34.19, -34.08, -40.39, -42.32 
>? ? ), Sim012 = c(-34.25, -41.45, -43.21, -50.36, -43.02), Sim013 = c(-32.35, 
>? ? -39.33, -34.82, -39.06, -45.33), Sim014 = c(-32.33, -43.5, 
>? ? -42.81, -47.21, -44.55), Sim015 = c(-31.1, -39.91, -50.22, 
>? ? -41.63, -43.79), Sim016 = c(-32.52, -42.62, -48.88, -39.38, 
>? ? -34.97), Sim017 = c(-35.47, -52.51, -37.02, -44.71, -52.77 
>? ? ), Sim018 = c(-39.97, -34.88, -36.02, -44.74, -33.23), Sim019 = c(-32.58, 
>? ? -32.32, -32.29, -43.36, -35.73), Sim020 = c(-32, -37.72, 
>? ? -40.59, -34.75, -31.45), Sim021 = c(-37.74, -37.62, -35.17, 
>? ? -36.5, -42.72), Sim022 = c(-42.19, -34.63, -38.28, -43.9, 
>? ? -41.87), Sim023 = c(-41.18, -42.32, -40.06, -40.63, -33.83 
>? ? ), Sim024 = c(-40.14, -40.55, -43.76, -41.95, -50.76), Sim025 = c(-30.44, 
>? ? -40.62, -36.87, -45.74, -36.98), Sim026 = c(-38.55, -41.58, 
>? ? -49.46, -40.63, -51.32), Sim027 = c(-33.19, -38.66, -42.39, 
>? ? -41.83, -33.1), Sim028 = c(-35.83, -35.23, -50.56, -33.6, 
>? ? -34.93), Sim029 = c(-33.98, -37.57, -38.01, -40.92, -37.51 
>? ? ), Sim030 = c(-38.81, -40.79, -41.1, -42.03, -45.8), Sim031 = c(-34.05, 
>? ? -38.83, -37.74, -43.99, -38.18), Sim032 = c(-34.87, -40.79, 
>? ? -38.09, -38.43, -42.38), Sim033 = c(-39.74, -38.4, -40.35, 
>? ? -45.41, -34.98), Sim034 = c(-36.85, -32.07, -42.36, -39.03, 
>? ? -38.68), Sim035 = c(-31.57, -40.68, -37.95, -40.75, -37.13 
>? ? ), Sim036 = c(-34.82, -36.98, -44.33, -44.7, -35.61), Sim037 = c(-35.32, 
>? ? -37.59, -37.94, -44.46, -40.68), Sim038 = c(-35.71, -36.72, 
>? ? -45.25, -38.16, -45.11), Sim039 = c(-36.37, -34.24, -38.03, 
>? ? -35.55, -35.8), Sim040 = c(-43.41, -34.82, -33.63, -44, -48.42 
>? ? ), Sim041 = c(-43.29, -31.97, -40.91, -46.15, -44.63), Sim042 = c(-34.25, 
>? ? -33.76, -42.41, -43.59, -42.92), Sim043 = c(-36.36, -33.15, 
>? ? -45.19, -36.73, -51.78), Sim044 = c(-37.85, -44.35, -36.37, 
>? ? -41.43, -53.1), Sim045 = c(-38.04, -36.34, -38.05, -43.83, 
>? ? -43.02), Sim046 = c(-28.7, -42.97, -34.55, -40.56, -40.94 
>? ? ), Sim047 = c(-39.88, -46.68, -41.36, -43.09, -31), Sim048 = c(-37.09, 
>? ? -34.54, -37.11, -48.75, -36.7), Sim049 = c(-35.54, -34.34, 
>? ? -35.8, -43.58, -35.13), Sim050 = c(-39.59, -45.63, -44.75, 
>? ? -35.5, -37.07), Sim051 = c(-38.17, -31.99, -38.92, -38.13, 
>? ? -40.66), Sim052 = c(-44.17, -35.03, -45.3, -43.51, -36.45 
>? ? ), Sim053 = c(-35.52, -38.32, -34.76, -36.59, -41.24), Sim054 = c(-39.43, 
>? ? -39.11, -47.01, -42.33, -35.26), Sim055 = c(-34.33, -43.12, 
>? ? -38.63, -43.82, -51.05), Sim056 = c(-34.94, -43.37, -37.49, 
>? ? -34.57, -32.98), Sim057 = c(-35.38, -32.65, -49.09, -44.89, 
>? ? -40.88), Sim058 = c(-39.09, -43.04, -31.79, -40.37, -41.23 
>? ? ), Sim059 = c(-39.47, -40.79, -47.84, -36.72, -49.66), Sim060 = c(-36.48, 
>? ? -41.99, -38.48, -39.66, -36.1), Sim061 = c(-39.36, -40.56, 
>? ? -44.59, -37.83, -35.45), Sim062 = c(-29.6, -32.92, -39.52, 
>? ? -42.98, -45.97), Sim063 = c(-35.06, -44.32, -36.05, -37.41, 
>? ? -41.21), Sim064 = c(-33.32, -37.99, -37.85, -43.07, -43.29 
>? ? ), Sim065 = c(-38.73, -39.87, -34.27, -42.26, -38.71), Sim066 = c(-35.29, 
>? ? -35.61, -38, -40.85, -40.6), Sim067 = c(-30.4, -35.99, -35.96, 
>? ? -40.05, -36.87), Sim068 = c(-33.62, -31.69, -34.9, -44.52, 
>? ? -42.11), Sim069 = c(-36.36, -41.2, -42.53, -41.74, -44.36 
>? ? ), Sim070 = c(-38.29, -39.97, -43.54, -39.9, -40.2), Sim071 = c(-47.72, 
>? ? -35.3, -37.38, -38.67, -44.35), Sim072 = c(-32.77, -36.11, 
>? ? -48.05, -40.8, -37.5), Sim073 = c(-31.8, -39.98, -40.24, 
>? ? -40.68, -39.57), Sim074 = c(-33.81, -36.13, -37.15, -41.12, 
>? ? -37.21), Sim075 = c(-40.31, -34.72, -43.92, -44.15, -35.55 
>? ? ), Sim076 = c(-37.94, -43.22, -39.26, -40.01, -33.97), Sim077 = c(-33.4, 
>? ? -37.88, -33.63, -34.79, -45.12), Sim078 = c(-38.07, -42.02, 
>? ? -40.8, -38.25, -37.12), Sim079 = c(-33.46, -37.29, -36.92, 
>? ? -41.32, -38.1), Sim080 = c(-46.57, -40.74, -41.11, -42.31, 
>? ? -34.04), Sim081 = c(-38.62, -35.2, -36.77, -38.14, -43.05 
>? ? ), Sim082 = c(-35.79, -36.56, -46.18, -40.54, -42.1), Sim083 = c(-43.49, 
>? ? -33.1, -38, -44.12, -41.49), Sim084 = c(-35.27, -36.59, -38.25, 
>? ? -38.27, -43.32), Sim085 = c(-37.58, -38.02, -39.88, -42.14, 
>? ? -47.23), Sim086 = c(-35.12, -44.91, -34.98, -36.92, -37.08 
>? ? ), Sim087 = c(-38.66, -38.45, -35.04, -41.71, -46.15), Sim088 = c(-33.65, 
>? ? -47.5, -40.09, -41.56, -43.83), Sim089 = c(-32.45, -45.71, 
>? ? -39.03, -44.84, -40.36), Sim090 = c(-33.14, -31.6, -38.07, 
>? ? -40.11, -42.19), Sim091 = c(-31.1, -35.64, -40.64, -38.19, 
>? ? -39.22), Sim092 = c(-36.96, -43.76, -46.34, -39.22, -38.1 
>? ? ), Sim093 = c(-38.09, -42.55, -40.7, -44.82, -39.33), Sim094 = c(-31.96, 
>? ? -38.54, -39.77, -44.94, -45.04), Sim095 = c(-32.6, -47.83, 
>? ? -43.8, -45.24, -34.54), Sim096 = c(-36.22, -37.52, -35.93, 
>? ? -40.2, -40.46), Sim097 = c(-32.07, -42.11, -44.64, -35.17, 
>? ? -41.68), Sim098 = c(-31.02, -38.79, -48.49, -45.02, -38.24 
>? ? ), Sim099 = c(-34.04, -39.06, -41.09, -38.55, -40.75), Sim100 = c(-37.59, 
>? ? -39.68, -39.13, -43.9, -34.38)), .Names = c("Year", "Site", 
>? ? "Sim001", "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", 
>? ? "Sim007", "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", 
>? ? "Sim013", "Sim014", "Sim015", "Sim016", "Sim017", "Sim018", 
>? ? "Sim019", "Sim020", "Sim021", "Sim022", "Sim023", "Sim024", 
>? ? "Sim025", "Sim026", "Sim027", "Sim028", "Sim029", "Sim030", 
>? ? "Sim031", "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", 
>? ? "Sim037", "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", 
>? ? "Sim043", "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", 
>? ? "Sim049", "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", 
>? ? "Sim055", "Sim056", "Sim057", "Sim058", "Sim059", "Sim060", 
>? ? "Sim061", "Sim062", "Sim063", "Sim064", "Sim065", "Sim066", 
>? ? "Sim067", "Sim068", "Sim069", "Sim070", "Sim071", "Sim072", 
>? ? "Sim073", "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", 
>? ? "Sim079", "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", 
>? ? "Sim085", "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", 
>? ? "Sim091", "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", 
>? ? "Sim097", "Sim098", "Sim099", "Sim100"), row.names = c(NA, 
>? ? -5L), class = "data.frame"), structure(list(Year = 2001:2005, 
>? ? ? ? Site = structure(c(1L, 1L, 1L, 1L, 1L), .Label = "G103", class = "factor"), 
>? ? ? ? Sim001 = c(-34.91, -42.24, -38.32, -39.49, -41.63), Sim002 = c(-35.11, 
>? ? ? ? -37.81, -41.05, -43.21, -50.25), Sim003 = c(-36.13, -40.39, 
>? ? ? ? -49.12, -41.86, -47.06), Sim004 = c(-33.37, -33.63, -47.03, 
>? ? ? ? -38, -49.28), Sim005 = c(-40.03, -42.55, -42.88, -38.11, 
>? ? ? ? -40.87), Sim006 = c(-46.76, -37.75, -38.98, -38.8, -40.65 
>? ? ? ? ), Sim007 = c(-40.41, -45.3, -40.05, -49.72, -33.92), 
>? ? ? ? Sim008 = c(-31.46, -36.97, -41.32, -40.57, -40.16), Sim009 = c(-39.7, 
>? ? ? ? -41.49, -40.46, -44.86, -44.03), Sim010 = c(-37.03, -41.86, 
>? ? ? ? -36.02, -51.36, -39.13), Sim011 = c(-36.14, -38.88, -40.28, 
>? ? ? ? -45.71, -42.73), Sim012 = c(-37.49, -37.51, -46.96, -37.35, 
>? ? ? ? -40.04), Sim013 = c(-36.18, -44.23, -44.28, -40.35, -52.88 
>? ? ? ? ), Sim014 = c(-37.27, -44.4, -39.46, -39.44, -44.47), 
>? ? ? ? Sim015 = c(-32.21, -40.48, -51.07, -33.53, -41.74), Sim016 = c(-37.68, 
>? ? ? ? -45.96, -50.48, -45.77, -36.38), Sim017 = c(-38.25, -50.61, 
>? ? ? ? -42.92, -42.78, -38.37), Sim018 = c(-41.61, -46.64, -42.91, 
>? ? ? ? -55.36, -35.43), Sim019 = c(-38.72, -45.85, -38.88, -42.35, 
>? ? ? ? -42.97), Sim020 = c(-32.26, -39.23, -39.6, -42.26, -34.94 
>? ? ? ? ), Sim021 = c(-40.59, -34.78, -41.04, -43.97, -45.7), 
>? ? ? ? Sim022 = c(-39.48, -40.89, -40.85, -41.11, -42.33), Sim023 = c(-37.3, 
>? ? ? ? -34.49, -47.63, -45.14, -39.37), Sim024 = c(-38.78, -37.49, 
>? ? ? ? -44.5, -45.34, -47.99), Sim025 = c(-34.19, -42.08, -36.19, 
>? ? ? ? -50.84, -40.62), Sim026 = c(-41.91, -35.46, -37.68, -46.45, 
>? ? ? ? -52.34), Sim027 = c(-42.88, -33.61, -36.19, -40.09, -33.83 
>? ? ? ? ), Sim028 = c(-40.86, -41.5, -47.46, -35.82, -35.96), 
>? ? ? ? Sim029 = c(-34.66, -38.41, -41.58, -45.07, -41.27), Sim030 = c(-44.26, 
>? ? ? ? -40.97, -36.97, -39.22, -43), Sim031 = c(-35.2, -37.12, 
>? ? ? ? -38.88, -42.92, -38.1), Sim032 = c(-38.09, -47.5, -35.93, 
>? ? ? ? -45.35, -39.17), Sim033 = c(-37.09, -40.74, -45.38, -40.93, 
>? ? ? ? -42.53), Sim034 = c(-35.89, -43.9, -43.09, -37.7, -40.32 
>? ? ? ? ), Sim035 = c(-35.42, -40.64, -36.52, -39.38, -43.69), 
>? ? ? ? Sim036 = c(-41.5, -44.56, -37.54, -41.08, -36.99), Sim037 = c(-38.72, 
>? ? ? ? -42.6, -39.6, -46.68, -43.74), Sim038 = c(-37.23, -41.2, 
>? ? ? ? -40.94, -44.48, -39.99), Sim039 = c(-38.92, -34.03, -38.41, 
>? ? ? ? -44.57, -35.76), Sim040 = c(-37.22, -43.06, -32.85, -43.75, 
>? ? ? ? -39.27), Sim041 = c(-34.34, -38.87, -38.55, -48.6, -42.69 
>? ? ? ? ), Sim042 = c(-35.63, -41.5, -42.8, -46.96, -46.9), Sim043 = c(-39.37, 
>? ? ? ? -37.65, -47.55, -43.64, -43.57), Sim044 = c(-31.85, -41.71, 
>? ? ? ? -39.78, -41.94, -50.5), Sim045 = c(-35.13, -37.94, -41.3, 
>? ? ? ? -42.85, -43.23), Sim046 = c(-37.41, -40.9, -38.73, -43.07, 
>? ? ? ? -41.67), Sim047 = c(-33.55, -45.2, -41.38, -38.33, -37.88 
>? ? ? ? ), Sim048 = c(-35.3, -40.77, -42.6, -47.29, -36.95), 
>? ? ? ? Sim049 = c(-40.23, -38.81, -39.38, -51.63, -36.48), Sim050 = c(-37.63, 
>? ? ? ? -47.48, -44.29, -40.44, -38.51), Sim051 = c(-32.98, -38.85, 
>? ? ? ? -35.89, -35.81, -40.39), Sim052 = c(-40.74, -41.71, -49.75, 
>? ? ? ? -39.13, -37.5), Sim053 = c(-35.83, -45.92, -35.75, -44.91, 
>? ? ? ? -48.89), Sim054 = c(-46.45, -36.2, -41.18, -43.26, -34.57 
>? ? ? ? ), Sim055 = c(-35.25, -41.67, -40.72, -43.52, -47.1), 
>? ? ? ? Sim056 = c(-38.54, -37.55, -42.31, -41.33, -34.96), Sim057 = c(-37.28, 
>? ? ? ? -40.86, -58.32, -44.67, -38.59), Sim058 = c(-37.72, -48.88, 
>? ? ? ? -39.47, -38.33, -46.02), Sim059 = c(-36.72, -38.11, -41.73, 
>? ? ? ? -44.15, -42.25), Sim060 = c(-40.57, -47.78, -40.79, -38.02, 
>? ? ? ? -40.6), Sim061 = c(-36.37, -43.07, -42.21, -44.35, -38.35 
>? ? ? ? ), Sim062 = c(-32.27, -38.33, -40.9, -37.72, -38.12), 
>? ? ? ? Sim063 = c(-39.41, -42.64, -40.81, -41.87, -43.33), Sim064 = c(-41.71, 
>? ? ? ? -39.46, -41.42, -43.64, -42.69), Sim065 = c(-33.84, -38.52, 
>? ? ? ? -35.67, -43.9, -41.93), Sim066 = c(-36.41, -38.93, -41.07, 
>? ? ? ? -43.29, -35.73), Sim067 = c(-34.69, -45.12, -41.62, -38.78, 
>? ? ? ? -36.64), Sim068 = c(-36.26, -35.96, -38.58, -39.53, -40.16 
>? ? ? ? ), Sim069 = c(-34.69, -47.3, -38.21, -43.42, -46.25), 
>? ? ? ? Sim070 = c(-35.01, -38.36, -47.65, -40.83, -41.36), Sim071 = c(-39.15, 
>? ? ? ? -41.21, -36.62, -46.28, -42.84), Sim072 = c(-44.71, -45.82, 
>? ? ? ? -40.26, -40.4, -41.46), Sim073 = c(-35.74, -33.98, -42.36, 
>? ? ? ? -41.69, -37.04), Sim074 = c(-37.99, -37.42, -49.56, -45.38, 
>? ? ? ? -41.59), Sim075 = c(-37.44, -44.24, -37.15, -44.85, -41.69 
>? ? ? ? ), Sim076 = c(-40.93, -38.26, -41.7, -39.92, -36.81), 
>? ? ? ? Sim077 = c(-38.08, -38.67, -33.17, -36.44, -42.84), Sim078 = c(-46.26, 
>? ? ? ? -43.16, -37.74, -40.36, -36.77), Sim079 = c(-35.52, -41.16, 
>? ? ? ? -33.79, -44.9, -46.44), Sim080 = c(-39.88, -37.29, -41.45, 
>? ? ? ? -38.75, -38.25), Sim081 = c(-39.54, -32.9, -43.92, -38.87, 
>? ? ? ? -43.6), Sim082 = c(-32.96, -38.36, -39.64, -43.91, -37.25 
>? ? ? ? ), Sim083 = c(-36.54, -42.41, -42.34, -43.73, -41.38), 
>? ? ? ? Sim084 = c(-41.51, -38.58, -35.42, -38.42, -34.48), Sim085 = c(-35.38, 
>? ? ? ? -38.46, -42.68, -44.68, -42.16), Sim086 = c(-35.7, -45.14, 
>? ? ? ? -39.84, -34.68, -41.49), Sim087 = c(-36.91, -41.04, -38.04, 
>? ? ? ? -49.18, -46.52), Sim088 = c(-31.25, -38.84, -36.13, -49.96, 
>? ? ? ? -43.36), Sim089 = c(-26.85, -40.06, -39.45, -48.14, -38.64 
>? ? ? ? ), Sim090 = c(-31.54, -34.96, -45.27, -36.24, -41.06), 
>? ? ? ? Sim091 = c(-37.09, -37.95, -41.81, -43.44, -41.8), Sim092 = c(-34.37, 
>? ? ? ? -42.68, -39.87, -38.18, -32.36), Sim093 = c(-36.61, -38.72, 
>? ? ? ? -36.32, -42.26, -48.61), Sim094 = c(-39.41, -39.01, -41.36, 
>? ? ? ? -42.44, -47.68), Sim095 = c(-38.78, -42.32, -40.45, -49.57, 
>? ? ? ? -37.16), Sim096 = c(-34.61, -41.53, -40.55, -40.74, -33.42 
>? ? ? ? ), Sim097 = c(-38.13, -40.1, -44.91, -35.95, -42.76), 
>? ? ? ? Sim098 = c(-36.75, -39.87, -41.55, -42.8, -34.67), Sim099 = c(-33.04, 
>? ? ? ? -41.33, -41.84, -39.15, -39.98), Sim100 = c(-41.84, -40.85, 
>? ? ? ? -47.33, -44.61, -38.4)), .Names = c("Year", "Site", "Sim001", 
>? ? "Sim002", "Sim003", "Sim004", "Sim005", "Sim006", "Sim007", 
>? ? "Sim008", "Sim009", "Sim010", "Sim011", "Sim012", "Sim013", 
>? ? "Sim014", "Sim015", "Sim016", "Sim017", "Sim018", "Sim019", 
>? ? "Sim020", "Sim021", "Sim022", "Sim023", "Sim024", "Sim025", 
>? ? "Sim026", "Sim027", "Sim028", "Sim029", "Sim030", "Sim031", 
>? ? "Sim032", "Sim033", "Sim034", "Sim035", "Sim036", "Sim037", 
>? ? "Sim038", "Sim039", "Sim040", "Sim041", "Sim042", "Sim043", 
>? ? "Sim044", "Sim045", "Sim046", "Sim047", "Sim048", "Sim049", 
>? ? "Sim050", "Sim051", "Sim052", "Sim053", "Sim054", "Sim055", 
>? ? "Sim056", "Sim057", "Sim058", "Sim059", "Sim060", "Sim061", 
>? ? "Sim062", "Sim063", "Sim064", "Sim065", "Sim066", "Sim067", 
>? ? "Sim068", "Sim069", "Sim070", "Sim071", "Sim072", "Sim073", 
>? ? "Sim074", "Sim075", "Sim076", "Sim077", "Sim078", "Sim079", 
>? ? "Sim080", "Sim081", "Sim082", "Sim083", "Sim084", "Sim085", 
>? ? "Sim086", "Sim087", "Sim088", "Sim089", "Sim090", "Sim091", 
>? ? "Sim092", "Sim093", "Sim094", "Sim095", "Sim096", "Sim097", 
>? ? "Sim098", "Sim099", "Sim100"), row.names = c(NA, -5L), class = "data.frame"), 
>? ? structure(list(Year = 2001:2005, Site = structure(c(1L, 1L, 
>? ? 1L, 1L, 1L), .Label = "G104", class = "factor"), Sim001 = c(-38.9, 
>? ? -34.54, -38.17, -42.04, -39.37), Sim002 = c(-33.01, -38.22, 
>? ? -37.76, -36.92, -51.14), Sim003 = c(-36.33, -33.4, -37.7, 
>? ? -43.03, -32.22), Sim004 = c(-32.53, -45.02, -45.45, -40.35, 
>? ? -43.27), Sim005 = c(-36.05, -38.23, -41.92, -37.98, -49.21 
>? ? ), Sim006 = c(-38.92, -35.83, -36.06, -34.24, -35.54), Sim007 = c(-36.53, 
>? ? -33.69, -41.31, -45.93, -32.42), Sim008 = c(-34.01, -34.26, 
>? ? -42.05, -44.43, -39.2), Sim009 = c(-37.2, -42.21, -36.86, 
>? ? -36.7, -34.85), Sim010 = c(-44.79, -38.11, -36.54, -43.57, 
>? ? -32.3), Sim011 = c(-40.68, -41.05, -35.3, -41.74, -35.85), 
>? ? ? ? Sim012 = c(-38.93, -34.81, -41.23, -42.03, -41.15), Sim013 = c(-36.71, 
>? ? ? ? -39.32, -37.85, -41.29, -50.13), Sim014 = c(-33.22, -42.64, 
>? ? ? ? -34.95, -41.25, -41.54), Sim015 = c(-27.32, -39.84, -43.44, 
>? ? ? ? -43.31, -45.82), Sim016 = c(-36.31, -43.67, -44.39, -44.95, 
>? ? ? ? -37.77), Sim017 = c(-35.26, -50.88, -37.54, -45.98, -46.66 
>? ? ? ? ), Sim018 = c(-43.28, -41.66, -38.46, -44.32, -35.62), 
>? ? ? ? Sim019 = c(-34.7, -41.41, -39.42, -40.32, -39.8), Sim020 = c(-37.55, 
>? ? ? ? -37.77, -38.25, -38.65, -33.74), Sim021 = c(-30.2, -35.93, 
>? ? ? ? -33.2, -37.85, -41.03), Sim022 = c(-40.31, -38.09, -39.18, 
>? ? ? ? -40.87, -51.5), Sim023 = c(-36.85, -40.68, -45.11, -39.73, 
>? ? ? ? -39.62), Sim024 = c(-41.48, -35.31, -44.76, -37.24, -46.36 
>? ? ? ? ), Sim025 = c(-34.69, -41.95, -43.05, -41.93, -34.23), 
>? ? ? ? Sim026 = c(-34.24, -40.88, -39.36, -48.67, -45.18), Sim027 = c(-38.95, 
>? ? ? ? -38.1, -35, -45.55, -37.15), Sim028 = c(-34.04, -43.52, 
>? ? ? ? -47, -34.74, -39.38), Sim029 = c(-32.5, -40.65, -37.96, 
>? ? ? ? -38.2, -37.79), Sim030 = c(-34.43, -42.13, -42.07, -38.1, 
>? ? ? ? -42.18), Sim031 = c(-36.69, -41.35, -39.82, -42.21, -37.83 
>? ? ? ? ), Sim032 = c(-37.01, -39.77, -35.61, -43.39, -42.19), 
>? ? ? ? Sim033 = c(-34.16, -35.87, -37.26, -42.02, -41.65), Sim034 = c(-35.6, 
>? ? ? ? -37.43, -36.06, -37.48, -35.07), Sim035 = c(-36.73, -37.46, 
>? ? ? ? -39.47, -39.99, -39.92), Sim036 = c(-33.23, -36.53, -41.41, 
>? ? ? ? -39.91, -41.29), Sim037 = c(-37.67, -34.37, -45.38, -46.11, 
>? ? ? ? -38.67), Sim038 = c(-36.29, -35.77, -42.69, -40.77, -42.59 
>? ? ? ? ), Sim039 = c(-36.48, -32.16, -40.69, -36.52, -35.85), 
>? ? ? ? Sim040 = c(-36.96, -39.49, -32.89, -39, -44.6), Sim041 = c(-37.45, 
>? ? ? ? -38.17, -38.05, -39.96, -43.14), Sim042 = c(-33.89, -38.47, 
>? ? ? ? -39.28, -47.24, -40.35), Sim043 = c(-35.8, -39.1, -48.85, 
>? ? ? ? -39.82, -40.66), Sim044 = c(-34.71, -36.45, -36.38, -41.85, 
>? ? ? ? -48.04), Sim045 = c(-35.27, -40.57, -37.27, -42.86, -43.2 
>? ? ? ? ), Sim046 = c(-39.56, -47.44, -42.44, -46.44, -39.22), 
>? ? ? ? Sim047 = c(-37.1, -41.25, -39.04, -42.13, -34.86), Sim048 = c(-37.64, 
>? ? ? ? -34.26, -37.1, -41.67, -36.88), Sim049 = c(-32.65, -32.27, 
>? ? ? ? -41.38, -46.08, -39.3), Sim050 = c(-34.56, -44.51, -40.37, 
>? ? ? ? -42.03, -35.15), Sim051 = c(-40.71, -41.49, -38.77, -39.39, 
>? ? ? ? -45.27), Sim052 = c(-44.87, -36.76, -37.49, -42.01, -40.1 
>? ? ? ? ), Sim053 = c(-42.59, -41.12, -37.51, -40.59, -36.53), 
>? ? ? ? Sim054 = c(-45.76, -41.83, -47.43, -36.45, -37.5), Sim055 = c(-36.82, 
>? ? ? ? -36.79, -43.26, -42.57, -40.27), Sim056 = c(-32.67, -39.79, 
>? ? ? ? -43.04, -37.49, -39.3), Sim057 = c(-34.1, -35.39, -37.94, 
>? ? ? ? -50.67, -34.52), Sim058 = c(-34.29, -37.04, -35.8, -40.1, 
>? ? ? ? -39.7), Sim059 = c(-39.59, -32.86, -42.71, -38.94, -45.85 
>? ? ? ? ), Sim060 = c(-44.08, -42.37, -44.43, -37.32, -39.26), 
>? ? ? ? Sim061 = c(-38.05, -39.61, -45.93, -40.56, -39.69), Sim062 = c(-31.21, 
>? ? ? ? -35.97, -38.78, -43.4, -37.32), Sim063 = c(-35.34, -40.71, 
>? ? ? ? -40.02, -36.25, -40.32), Sim064 = c(-44.73, -36.72, -36.19, 
>? ? ? ? -44.45, -48.59), Sim065 = c(-32.72, -45.4, -33.36, -42.75, 
>? ? ? ? -50.86), Sim066 = c(-33.12, -40.81, -41.6, -38.42, -35.93 
>? ? ? ? ), Sim067 = c(-32.26, -38.45, -36, -39.26, -36.56), Sim068 = c(-36.53, 
>? ? ? ? -38.71, -39.94, -40.84, -36.22), Sim069 = c(-39.6, -47.15, 
>? ? ? ? -38.72, -46.39, -41.39), Sim070 = c(-37.83, -48.15, -37.94, 
>? ? ? ? -39.7, -39.23), Sim071 = c(-49.75, -42.82, -35.91, -35.08, 
>? ? ? ? -41.43), Sim072 = c(-40.16, -36.99, -40.09, -39.94, -42.35 
>? ? ? ? ), Sim073 = c(-30.3, -41.3, -41.85, -38.41, -45.58), 
>? ? ? ? Sim074 = c(-34.4, -36.63, -42.29, -45.9, -47.07), Sim075 = c(-37.47, 
>? ? ? ? -43.69, -34.87, -42.15, -46.66), Sim076 = c(-40.79, -37.95, 
>? ? ? ? -42.26, -41.58, -36.4), Sim077 = c(-32.54, -38.49, -33.33, 
>? ? ? ? -39.02, -37.83), Sim078 = c(-38.54, -41.83, -37.91, -42.65, 
>? ? ? ? -37.18), Sim079 = c(-39.13, -38.63, -33.65, -36.41, -43.77 
>? ? ? ? ), Sim080 = c(-42.03, -42.47, -43.68, -34.88, -34.89), 
>? ? ? ? Sim081 = c(-36.4, -34.11, -41.44, -38.61, -46.57), Sim082 = c(-35.68, 
>? ? ? ? -38.53, -38.77, -35.27, -39.6), Sim083 = c(-35.52, -41.8, 
>? ? ? ? -36.28, -40.92, -41.15), Sim084 = c(-36.67, -35.51, -36.83, 
>? ? ? ? -38.78, -38.03), Sim085 = c(-44.2, -34.53, -39.89, -39.93, 
>? ? ? ? -40.49), Sim086 = c(-33.88, -38.81, -34.62, -39.35, -42.93 
>? ? ? ? ), Sim087 = c(-37.02, -35.38, -49.91, -42.51, -47.33), 
>? ? ? ? Sim088 = c(-33.51, -36.32, -37.01, -39.46, -41.32), Sim089 = c(-29.18, 
>? ? ? ? -42.67, -38.41, -45.18, -44.61), Sim090 = c(-29.05, -32.94, 
>? ? ? ? -46.38, -34.2, -41.94), Sim091 = c(-32.24, -37.59, -38.77, 
>? ? ? ? -40.72, -39.48), Sim092 = c(-42.79, -44.5, -41.99, -40.21, 
>? ? ? ? -36.8), Sim093 = c(-36.65, -41.11, -41.12, -44.01, -37.67 
>? ? ? ? ), Sim094 = c(-34.95, -44.86, -42.27, -40.73, -56.48), 
>? ? ? ? Sim095 = c(-33.53, -38.83, -38.39, -40.82, -34.69), Sim096 = c(-42.41, 
>? ? ? ? -36.12, -37.16, -33.86, -43.24), Sim097 = c(-35.1, -38.71, 
>? ? ? ? -45.1, -39.18, -42.39), Sim098 = c(-32.08, -39.93, -39.66, 
>? ? ? ? -40.71, -31.58), Sim099 = c(-37.41, -42.6, -37.58, -39.89, 
>? ? ? ? -39.03), Sim100 = c(-38.75, -38.33, -42.42, -40.29, -35.67 
>? ? ? ? )), .Names = c("Year", "Site", "Sim001", "Sim002", "Sim003", 
>? ? "Sim004", "Sim005", "Sim006", "Sim007", "Sim008", "Sim009", 
>? ? "Sim010", "Sim011", "Sim012", "Sim013", "Sim014", "Sim015", 
>? ? "Sim016", "Sim017", "Sim018", "Sim019", "Sim020", "Sim021", 
>? ? "Sim022", "Sim023", "Sim024", "Sim025", "Sim026", "Sim027", 
>? ? "Sim028", "Sim029", "Sim030", "Sim031", "Sim032", "Sim033", 
>? ? "Sim034", "Sim035", "Sim036", "Sim037", "Sim038", "Sim039", 
>? ? "Sim040", "Sim041", "Sim042", "Sim043", "Sim044", "Sim045", 
>? ? "Sim046", "Sim047", "Sim048", "Sim049", "Sim050", "Sim051", 
>? ? "Sim052", "Sim053", "Sim054", "Sim055", "Sim056", "Sim057", 
>? ? "Sim058", "Sim059", "Sim060", "Sim061", "Sim062", "Sim063", 
>? ? "Sim064", "Sim065", "Sim066", "Sim067", "Sim068", "Sim069", 
>? ? "Sim070", "Sim071", "Sim072", "Sim073", "Sim074", "Sim075", 
>? ? "Sim076", "Sim077", "Sim078", "Sim079", "Sim080", "Sim081", 
>? ? "Sim082", "Sim083", "Sim084", "Sim085", "Sim086", "Sim087", 
>? ? "Sim088", "Sim089", "Sim090", "Sim091", "Sim092", "Sim093", 
>? ? "Sim094", "Sim095", "Sim096", "Sim097", "Sim098", "Sim099", 
>? ? "Sim100"), row.names = c(NA, -5L), class = "data.frame"))
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From joseleopoldo1792 at gmail.com  Wed Aug  6 18:13:56 2014
From: joseleopoldo1792 at gmail.com (Igor Sosa Mayor)
Date: Wed, 6 Aug 2014 18:13:56 +0200
Subject: [R] citation() command doesn't work in R.3.1.1
References: <CACtaF7zhuvgV8rn3xJqXAdkx-egf8NCOyRJaZBeuO=uD9B2ssw@mail.gmail.com>
Message-ID: <8761i538aj.fsf@gmail.com>

Sverre Stausland <stausland.johnsen at iln.uio.no> writes:

>> citation()
> Error: $ operator is invalid for atomic vectors
> In addition: Warning message:
> In packageDescription(pkg = package, lib.loc = dirname(dir)) :
>   no package 'base' was found

strange... I think something is wrong with the compilation, since as far
as I know, the package `base' should be loaded automatically by starting
R... 

-- 
:: Igor Sosa Mayor     :: joseleopoldo1792 at gmail.com ::
:: GnuPG: 0x1C1E2890   :: http://www.gnupg.org/      ::
:: jabberid: rogorido  ::                            ::


From ruipbarradas at sapo.pt  Wed Aug  6 18:50:21 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 06 Aug 2014 17:50:21 +0100
Subject: [R] citation() command doesn't work in R.3.1.1
In-Reply-To: <CACtaF7zhuvgV8rn3xJqXAdkx-egf8NCOyRJaZBeuO=uD9B2ssw@mail.gmail.com>
References: <CACtaF7zhuvgV8rn3xJqXAdkx-egf8NCOyRJaZBeuO=uD9B2ssw@mail.gmail.com>
Message-ID: <53E25CCD.3060709@sapo.pt>

Works with me. And the OS seems to be the same.

 > citation()

To cite R in publications use:

   R Core Team (2014). R: A language and environment for statistical
   computing. R Foundation for Statistical Computing, Vienna, Austria.
   URL http://www.R-project.org/.

A BibTeX entry for LaTeX users is

   @Manual{,
     title = {R: A Language and Environment for Statistical Computing},
     author = {{R Core Team}},
     organization = {R Foundation for Statistical Computing},
     address = {Vienna, Austria},
     year = {2014},
     url = {http://www.R-project.org/},
   }

We have invested a lot of time and effort in creating R, please cite it
when using it for data analysis. See also ?citation("pkgname")? for
citing R packages.

 > sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.1

Rui Barradas

Em 06-08-2014 16:24, Sverre Stausland escreveu:
>> citation()
> Error: $ operator is invalid for atomic vectors
> In addition: Warning message:
> In packageDescription(pkg = package, lib.loc = dirname(dir)) :
>    no package 'base' was found
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Norwegian (Bokm?l)_Norway.1252
> [2] LC_CTYPE=Norwegian (Bokm?l)_Norway.1252
> [3] LC_MONETARY=Norwegian (Bokm?l)_Norway.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=Norwegian (Bokm?l)_Norway.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
>
>> Sys.getlocale()
> [1] "LC_COLLATE=Norwegian (Bokm?l)_Norway.1252;LC_CTYPE=Norwegian
> (Bokm?l)_Norway.1252;LC_MONETARY=Norwegian
> (Bokm?l)_Norway.1252;LC_NUMERIC=C;LC_TIME=Norwegian
> (Bokm?l)_Norway.1252"
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maharwood7 at gmail.com  Wed Aug  6 18:39:41 2014
From: maharwood7 at gmail.com (Mike Harwood)
Date: Wed, 6 Aug 2014 09:39:41 -0700 (PDT)
Subject: [R] big data?
In-Reply-To: <34476B18-46F4-4035-B7E9-FC3B83D6643B@comcast.net>
References: <53E1124A.2080603@structuremonitoring.com>
	<34476B18-46F4-4035-B7E9-FC3B83D6643B@comcast.net>
Message-ID: <d0f80125-b358-431d-b5b5-79631223d591@googlegroups.com>

The read.table.ffdf function in the ff package can read in delimited files 
and store them to disk as individual columns.  The ffbase package provides 
additional data management and analytic functionality.  I have used these 
packages on 15 Gb files of 18 million rows and 250 columns.


On Tuesday, August 5, 2014 1:39:03 PM UTC-5, David Winsemius wrote:
>
>
> On Aug 5, 2014, at 10:20 AM, Spencer Graves wrote: 
>
> >      What tools do you like for working with tab delimited text files up 
> to 1.5 GB (under Windows 7 with 8 GB RAM)? 
>
> ?data.table::fread 
>
> >      Standard tools for smaller data sometimes grab all the available 
> RAM, after which CPU usage drops to 3% ;-) 
> > 
> > 
> >      The "bigmemory" project won the 2010 John Chambers Award but "is 
> not available (for R version 3.1.0)". 
> > 
> > 
> >      findFn("big data", 999) downloaded 961 links in 437 packages. That 
> contains tools for data PostgreSQL and other formats, but I couldn't find 
> anything for large tab delimited text files. 
> > 
> > 
> >      Absent a better idea, I plan to write a function getField to 
> extract a specific field from the data, then use that to split the data 
> into 4 smaller files, which I think should be small enough that I can do 
> what I want. 
>
> There is the colbycol package with which I have no experience, but I 
> understand it is designed to partition data into column sized objects. 
> #--- from its help file----- 
> cbc.get.col {colbycol}        R Documentation 
> Reads a single column from the original file into memory 
>
> Description 
>
> Function cbc.read.table reads a file, stores it column by column in disk 
> file and creates a colbycol object. Functioncbc.get.col queries this object 
> and returns a single column. 
>
> >      Thanks, 
> >      Spencer 
> > 
> > ______________________________________________ 
> > R-h... at r-project.org <javascript:> mailing list 
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> > and provide commented, minimal, self-contained, reproducible code. 
>
> David Winsemius 
> Alameda, CA, USA 
>
> ______________________________________________ 
> R-h... at r-project.org <javascript:> mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code. 
>

From Michael.Folkes at dfo-mpo.gc.ca  Wed Aug  6 22:11:26 2014
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 6 Aug 2014 13:11:26 -0700
Subject: [R] lattice scales format dates
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB00F84E296@pacpbsex01.pac.dfo-mpo.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/0b5ed98e/attachment.pl>

From rawsonk at psychiatry.wustl.edu  Wed Aug  6 22:58:04 2014
From: rawsonk at psychiatry.wustl.edu (Rawson, Kerri)
Date: Wed, 6 Aug 2014 20:58:04 +0000
Subject: [R] Amelia: pool data from multiple imputated datasets - for
 descriptives
Message-ID: <D859E798A8CEA343B78B03D833B08C02617A5632@CITEMB1D.cits.wustl.edu>

I used AmeliaView to create 5 imputed datasets.  I want to pool the 5 imputed datasets into one to get pooled descriptive information (means, SD, min/max, etc) that is needed to calculate RCI scores (corrected for measurement error and practice effects).

The formula to calculate RCI is ((X2 - X1) - (M2 - M1))/S.E.D.  where
X1 is observed pre-test score
X2 is observed post-test score
M1 is the group mean pre-test score
M2 is the group mean post-test score, and
S.E.D. is the standard deviation of the mean observed difference score.

My data is currently in long form.  I have an ID variable, pre/post data, week, and imputed dataset number.

ID      var1    var2    var3    var4    week    impdataset#
555     16      10      8.87    6       3       1
555     18      12      9       6       7       1
777     12      10      9       7       3       2
777     15      13      8       6       7       2


I have searched several sites, but none of the threads exactly answer my question.

For instance:
I was able to bind/append them into one dataset using:
> ameliaimpute <- rbind(imp1, imp2, imp3, imp4, imp5)
I see I can use packages like Zelig to conduct regression on bound data, but I don't see a way to get the descriptives on pooled data.

I also tried MICE - but it is just appending the imputed datasets also.
>cogspss->read.spss("cogvaronly0806.sav",use.value.labels=TRUE, to.data.frame=TRUE)
>imp <-mice(cogspss, maxit=5)
>com <- complete(imp, "long", inc=TRUE)
>com <- cbind(com, Imputation_ = as.integer(com$.imp)-1)
>write.csv(com, "impmicedata.csv")

One person mentions "I know that I can use Rubin's rules (implemented through any multiple imputation package in R) to pool means and standard errors..."
This sounds like it would answer my question but I have not been able to find a tool that does this.

RStudio Version 0.98.953
AmeliaView 1.7.2.
R x64 3.0.2
Windows 7 Enterprise 64 bit

Thank you for your time.
K-Rawson

________________________________
The materials in this message are private and may contain Protected Healthcare Information or other information of a sensitive nature. If you are not the intended recipient, be advised that any unauthorized use, disclosure, copying or the taking of any action in reliance on the contents of this information is strictly prohibited. If you have received this email in error, please immediately notify the sender via telephone or return mail.


From dwinsemius at comcast.net  Wed Aug  6 23:30:51 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 6 Aug 2014 14:30:51 -0700
Subject: [R] lattice scales format dates
In-Reply-To: <63F107BCC37AEA49A75FD94AA3E07CB00F84E296@pacpbsex01.pac.dfo-mpo.ca>
References: <63F107BCC37AEA49A75FD94AA3E07CB00F84E296@pacpbsex01.pac.dfo-mpo.ca>
Message-ID: <CC664651-D0DC-49F6-9380-3FF7BC18307E@comcast.net>


On Aug 6, 2014, at 1:11 PM, Folkes, Michael wrote:

> Hello all,
> 
> Based on the help in ?xyplot,

Which says very little about barchart in particular but rather refers you to 

?panel.barchart

It's really designed expecting  x to be a factor,

> and this suggestion from another request:
> 
> http://stackoverflow.com/questions/20623041/r-formatted-auto-scaling-dat
> e-axis-using-lattice
> 
> I was under the impression that this code should give me the desired x
> axis label date format of: "1911-Jan".

Probably would have if you were using xyplot. But barchart's author assumed that the "x-axis" is a set of disjoint values and that's not really how datetimes are generally considered. Try this:

 barchart(var1~factor(format(date.val, "%Y-%b")), data=dat, horizontal=F,
          scales=list(x=list(rot=45) ) )

> 
> 
> 
> dat  <- data.frame(var1=1:10,
> date.val=as.POSIXct(seq(as.Date("1910/11/1"), as.Date("1911/8/1"),
> "months") ))
> 
> barchart(var1~date.val, data=dat, horizontal=F,
> scales=list(x=list(rot=45, format="%Y-%b")))
> 
> format(dat$date.val,"%Y-%b")
And learn to post in plain text.
> 
> 	[[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From shidaxia at yahoo.com  Wed Aug  6 23:42:45 2014
From: shidaxia at yahoo.com (Shi, Tao)
Date: Wed, 6 Aug 2014 14:42:45 -0700
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <CAOQ5NydR9dPzKg9QYX5GYs2pue1DVpCxSuwr1+C3hZ-eHaEYrQ@mail.gmail.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAOQ5NydR9dPzKg9QYX5GYs2pue1DVpCxSuwr1+C3hZ-eHaEYrQ@mail.gmail.com>
Message-ID: <1407361365.23482.YahooMailNeo@web124706.mail.ne1.yahoo.com>

This is new to me. ?Thanks for suggesting!

Tao



On Friday, August 1, 2014 3:05 AM, Michael Lawrence <lawrence.michael at gene.com> wrote:



You should check out the animint package.

https://github.com/tdhock/animint





On Mon, Jul 28, 2014 at 5:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:

hi list,
>
>I'm comparing the changes of ~100 analytes in multiple treatment conditions. ?I plotted them in several different xy scattter plots. ?It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown. ?I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine). ?rCharts is nice but so far it can only create one scatter plot at a time.?
>
>Any good suggestions?
>
>Many thanks!
>
>Tao
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From Michael.Folkes at dfo-mpo.gc.ca  Wed Aug  6 23:45:14 2014
From: Michael.Folkes at dfo-mpo.gc.ca (Folkes, Michael)
Date: Wed, 6 Aug 2014 14:45:14 -0700
Subject: [R] lattice scales format dates
In-Reply-To: <CC664651-D0DC-49F6-9380-3FF7BC18307E@comcast.net>
References: <63F107BCC37AEA49A75FD94AA3E07CB00F84E296@pacpbsex01.pac.dfo-mpo.ca>
	<CC664651-D0DC-49F6-9380-3FF7BC18307E@comcast.net>
Message-ID: <63F107BCC37AEA49A75FD94AA3E07CB00F84E394@pacpbsex01.pac.dfo-mpo.ca>

Thanks David.
Much appreciated.


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: August-06-14 2:31 PM
To: Folkes, Michael
Cc: r-help at r-project.org
Subject: Re: [R] lattice scales format dates


On Aug 6, 2014, at 1:11 PM, Folkes, Michael wrote:

> Hello all,
> 
> Based on the help in ?xyplot,

Which says very little about barchart in particular but rather refers
you to 

?panel.barchart

It's really designed expecting  x to be a factor,

> and this suggestion from another request:
> 
> http://stackoverflow.com/questions/20623041/r-formatted-auto-scaling-d
> at
> e-axis-using-lattice
> 
> I was under the impression that this code should give me the desired x

> axis label date format of: "1911-Jan".

Probably would have if you were using xyplot. But barchart's author
assumed that the "x-axis" is a set of disjoint values and that's not
really how datetimes are generally considered. Try this:

 barchart(var1~factor(format(date.val, "%Y-%b")), data=dat,
horizontal=F,
          scales=list(x=list(rot=45) ) )

> 
> 
> 
> dat  <- data.frame(var1=1:10,
> date.val=as.POSIXct(seq(as.Date("1910/11/1"), as.Date("1911/8/1"),
> "months") ))
> 
> barchart(var1~date.val, data=dat, horizontal=F, 
> scales=list(x=list(rot=45, format="%Y-%b")))
> 
> format(dat$date.val,"%Y-%b")
And learn to post in plain text.
> 
> 	[[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From shidaxia at yahoo.com  Wed Aug  6 23:41:58 2014
From: shidaxia at yahoo.com (Shi, Tao)
Date: Wed, 6 Aug 2014 14:41:58 -0700
Subject: [R] interactive labeling/highlighting on multiple xy scatter
	plots
In-Reply-To: <CAFEqCdx2u9vRBgp5p0s594HgLp4VfvAq+dTr23Z8P0YJQHmt4A@mail.gmail.com>
References: <1406594932.92269.YahooMailNeo@web124706.mail.ne1.yahoo.com>	<CAFEqCdwrooC=x-n6DP+3=1hC-h4T7G1UScx3FiZT+Y1f5xOVzw@mail.gmail.com>	<CAKO5CYW57PYwRj8fFZUkF2PUDZh-MS972qLB0-s0Pdk-xkHA0Q@mail.gmail.com>	<1406664796.36791.YahooMailNeo@web124706.mail.ne1.yahoo.com>	<CAFEqCdwvRiVG8JrO7Ue2rtsN7v=PQgfTxtf-eHBfesZUC8M0rg@mail.gmail.com>	<CAKO5CYUKnDwHiLq1ix-J7J877iuBPGmLqEUCgr0mH_4eM07z+w@mail.gmail.com>	<1406823468.74506.YahooMailNeo@web124706.mail.ne1.yahoo.com>
	<CAFEqCdx2u9vRBgp5p0s594HgLp4VfvAq+dTr23Z8P0YJQHmt4A@mail.gmail.com>
Message-ID: <1407361318.45449.YahooMailNeo@web124704.mail.ne1.yahoo.com>

Just saw this from the Rstudio webinar too. ?Will explore it more. ?Thanks!

Tao



On Thursday, July 31, 2014 11:11 AM, Greg Snow <538280 at gmail.com> wrote:



The brushing may only be available in the development version of
ggvis.? See here for the example:
https://github.com/rstudio/webinars/tree/master/2014-01


On Thu, Jul 31, 2014 at 10:17 AM, Shi, Tao <shidaxia at yahoo.com> wrote:
> I looked at ggvis briefly before, but didn't notice its brushing capability.? Now you explained.
>
> Thanks, both!
>
> Tao
>
>
>
>
> On Wednesday, July 30, 2014 9:50 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:
>
>
>
> ggvis is an excellent option to do this kind of stuff.
>
> The only limitation currently is that all sorts of interactivity (tooltips, brushing etc.) are done on the server side using Shiny. So you have to upload your HTML to a shiny server for the interactivity to work.
>
> Best,
> Ramnath
>
>
>
> ______________________________________
> Ramnath Vaidyanathan
> Assistant Professor of Operations Management
> Desautels Faculty of Management
> 1001 Sherbrooke Street West
> Montreal, QC H3A 1G5
> Ph: +1 (514) 398-1457
> ______________________________________
>
>
> On Wed, Jul 30, 2014 at 12:45 PM, Greg Snow <538280 at gmail.com> wrote:
>
> Another option that is in developement, but may do what you want is
>>ggvis (http://ggvis.rstudio.com/).? I have seen an example of brushing
>>created with ggvis that can then be embedded in a web page.? I am not
>>sure if you can send the html and support files directly to someone
>>without R (probably Rstudio) or if you need to upload it to a server
>>for others to see, but the later is still an option for collaborators
>>who do not have R installed.
>>
>>
>>On Tue, Jul 29, 2014 at 2:13 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>>> Thank you very much, Greg and Ramnath, for the pointers!? I'll explore more.
>>>
>>>
>>>
>>>
>>> On Tuesday, July 29, 2014 8:10 AM, Ramnath Vaidyanathan <ramnath.vaidyanathan at mcgill.ca> wrote:
>>>
>>>
>>>
>>> There are plugins for rCharts that help you create custom charts.
>>>
>>> Here is a scatterplot matrix example
>>>
>>> http://mostlyconjecture.com/2014/02/09/scatterplot-matrix-with-rcharts/
>>>
>>>
>>> It doesn't support brushing, but I think it won't be hard adding that behavior if you contact its author.
>>>
>>> Hope this helps.
>>>
>>> Best,
>>> Ramnath
>>>
>>>
>>>
>>> ______________________________________
>>> Ramnath Vaidyanathan
>>> Assistant Professor of Operations Management
>>> Desautels Faculty of Management
>>> 1001 Sherbrooke Street West
>>> Montreal, QC H3A 1G5
>>> Ph: +1 (514) 398-1457
>>> ______________________________________
>>>
>>>
>>> On Tue, Jul 29, 2014 at 11:01 AM, Greg Snow <538280 at gmail.com> wrote:
>>>
>>> There is the TkBrush function in the TeachingDemos package that gives
>>>>brushing in a scatterplot matrix using a Tk interface rather than
>>>>ggobi.? There is also the iplots package which allows you to create
>>>>multiple scatterplots, histograms, boxplots, barcharts, etc. and
>>>>points selected in any one of the plots will then be highlighted in
>>>>all the others.? Both of those solutions require R to be installed.
>>>>
>>>>I don't know of any way to get what you want without installing at
>>>>least one of ggobi or R (or some other program of similar complexity
>>>>to install).
>>>>
>>>>On Mon, Jul 28, 2014 at 6:48 PM, Shi, Tao <shidaxia at yahoo.com> wrote:
>>>>> hi list,
>>>>>
>>>>> I'm comparing the changes of ~100 analytes in multiple treatment conditions.? I plotted them in several different xy scattter plots.? It would be nice if I mouse over one point on one scatter plot, the label of the analyte on that scatter plot AS WELL AS on all other scatter plots will be automatically shown.? I know brushing in rggobi does this, but its interface is not good and it needs R or ggobi to run (I want send the results to the collaborators and let them to play with it without the need of installing R or ggobi on their machine).? rCharts is nice but so far it can only create one scatter plot at a time.
>>>>>
>>>>> Any good suggestions?
>>>>>
>>>>> Many thanks!
>>>>>
>>>>> Tao
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>>>--
>>>>Gregory (Greg) L. Snow Ph.D.

>>>>538280 at gmail.com
>>>>
>>
>>
>>
>>--
>>Gregory (Greg) L. Snow Ph.D.
>>538280 at gmail.com
>>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From Achim.Zeileis at uibk.ac.at  Thu Aug  7 00:16:14 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 7 Aug 2014 00:16:14 +0200 (CEST)
Subject: [R] R Foundation publish citable Manual for packages
In-Reply-To: <CADKEMqg62ArpT6OMn2-sZDF5CkYkOxg5q4OdSe+OcmkXEProhw@mail.gmail.com>
References: <CADKEMqg62ArpT6OMn2-sZDF5CkYkOxg5q4OdSe+OcmkXEProhw@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1408070005050.17374@paninaro.uibk.ac.at>

On Wed, 6 Aug 2014, stephen sefick wrote:

> Hi all:
>
> I have had recent issues with citing a package(s) in journals. I have a
> package that has been cited as the Documentation and accepted into
> journals, but I just had a problem with the lme4 package. We are citing the
> submitted paper instead of the documentation. In other words, the citation
> from the citation function was not acceptable to the editor.
>
> Experiences? Thoughts for a solution? Are there standard ways of doing 
> this?

This still keeps coming up from time to time. By now, many editors have 
accepted that a software+manual published on a web page can be something 
that is worth citing - others still don't allow it. But hopefully this 
resistance will die out eventually.

The standard workaround is, of course, to cite a journal paper or book 
about the software. This was always one of the most important objectives 
of JSS: to give software authors something that is considered citable. 
And hopefully there will be a JSS paper on lme4 in the not-so-distant 
future.

> Maybe the R Foundation could publish a manual of which all package
> documentation is a sub-publication kind of like an edited book?

Well CRAN already hosts a web page with a standard URL where the manual is 
posted. So this is considered to be a credible source for many by now and 
it's probably not worth the effort anymore to set up such an artificial 
documentation series with ISSN etc.

> I just am trying to make sure that everyone that makes the R ecosystem so
> useful gets attribution for their work.

Yes, keep up trying and hopefully sooner than later citing the software 
directly (rather than a paper about it) will be accepted by almost all 
editors.

Best,
Z

> Many thanks to everyone involved.
>
> -- 
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                              -Robert Gentleman
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Seeliger.Curt at epa.gov  Thu Aug  7 00:30:28 2014
From: Seeliger.Curt at epa.gov (Seeliger, Curt)
Date: Wed, 6 Aug 2014 22:30:28 +0000
Subject: [R] sendmailR error: if (code == lcode) { : argument is of length
	zero
Message-ID: <49024b4617504c0f879d49eb08ca7030@BN1PR09MB0275.namprd09.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140806/46fecdaf/attachment.pl>

From Scott.Waichler at pnnl.gov  Thu Aug  7 01:21:04 2014
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Wed, 6 Aug 2014 23:21:04 +0000
Subject: [R] Using axis limits with plot3D
Message-ID: <074C83DAD4825242A20B2D83FDBCB888765969@EX10MBOX03.pnnl.gov>

I would like to use the functions in the plot3D package but I am having trouble getting the axis limits to work correctly.  The slices plotted by the code below go beyond the bounds of the persp box and obscure the axis information.  How can I show just the part of the domain within x.limits and y.limits?

library(plot3D)
x <- z <- seq(-4, 4, by=0.2)
y <- seq(-6, 6, by=0.2)
M <- mesh(x,y,z)
R <- with(M, sqrt(x^2 + y^2 +z^2))
p <- sin(2*R)/(R+1e-3)
x.limits <- c(-2, 2)
y.limits <- c(-2, 2)
slice3D(x,y,z, colvar=p, xs=0, ys=c(0, 4), zs=NULL, xlim=x.limits, ylim=y.limits, scale=F, ticktype="detailed")

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA, USA


From makedon1 at sri.utoronto.ca  Thu Aug  7 01:11:16 2014
From: makedon1 at sri.utoronto.ca (makedon1 at sri.utoronto.ca)
Date: Wed, 6 Aug 2014 19:11:16 -0400
Subject: [R] Fractal package - FDWhittle - Estimating the Hurst exponent
Message-ID: <c3bbccd4c3e1fc9aedc35f1ad0c92746.squirrel@webm2.sri.utoronto.ca>

Hello list,

How would one estimate the Hurst exponent of a time series using the Whittle
method in R?

It looks like the Fractal package has a function called FDWhittle, but this
outputs the "FD Parameter" of a time series and not the Hurst exponent.

Any help would be greatly appreciated, as I am very much lost.

Thanks.
IM

FYI - the fractal manual -
http://cran.utstat.utoronto.ca/web/packages/fractal/fractal.pdf


From johnnycz at yeah.net  Thu Aug  7 04:12:14 2014
From: johnnycz at yeah.net (Johnnycz)
Date: Thu, 7 Aug 2014 10:12:14 +0800 (CST)
Subject: [R] ask for help
Message-ID: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/6c332fc0/attachment.pl>

From reckbo at bwh.harvard.edu  Thu Aug  7 06:20:11 2014
From: reckbo at bwh.harvard.edu (Ryan)
Date: Thu, 07 Aug 2014 14:20:11 +1000
Subject: [R] Logical operators and named arguments
Message-ID: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>

Hi,

I'm wondering why calling ">" with named arguments doesn't work as expected:

> args(">")
function (e1, e2) 
NULL

> sapply(c(1,2,3), `>`, e2=0)
[1] TRUE TRUE TRUE

> sapply(c(1,2,3), `>`, e1=0)
[1] TRUE TRUE TRUE

Shouldn't the latter be FALSE?

Thanks for any help,
Ryan


The information in this e-mail is intended only for the ...{{dropped:11}}


From dulcalma at bigpond.com  Thu Aug  7 08:08:54 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 7 Aug 2014 16:08:54 +1000
Subject: [R] doubleYScale from latticeExtra, problems with style
In-Reply-To: <53E1CC3E.5060500@gvdnet.dk>
References: <53E112C3.6080508@gvdnet.dk>	<CADv2QyGRi971BkaiL8C6zrMyjfFZMzFv2=RYG148pNHj1eseJQ@mail.gmail.com>
	<53E1CC3E.5060500@gvdnet.dk>
Message-ID: <001201cfb206$116519a0$342f4ce0$@bigpond.com>

Hi Troels

Try this

(sd1 <- doubleYScale(obj1,obj2,add.ylab2 = TRUE, use.style = FALSE))

update(sd1,
    par.settings = list(axis.text = list(cex = 1.2),
                        par.ylab.text = list(cex = 1.5)))

Amended sd to sd1

Unfortunately doubleYScale uses themes which makes things difficult

The use.style negates the use of styles apparently 
Have a good read of doubleYScale help page 

Duncan

Duncan
Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Troels Ring
Sent: Wednesday, 6 August 2014 16:34
To: Dennis Murphy; r-help at r-project.org
Subject: Re: [R] doubleYScale from latticeExtra, problems with style

Hi Dennis - thanks a lot - I do not seem to make any progress from 
reading the pages in the lattice book or the documentation of the 
doubleYScale function.
All best wishes
Troels



Den 05-08-2014 20:49, Dennis Murphy skrev:
> Hi:
>
> This *partially* works, although I don't see why it shouldn't work
completely:
>
> update(sd,
>     par.settings = list(axis.text = list(cex = 1.2),
>                         par.ylab.text = list(cex = 1.5)))
>
> It fixes the y-axis text sizes, but it doesn't fix the size of the
> Y-variable names. See pp. 125-126 of the Lattice book for a
> description.
>
> Dennis
>
> On Tue, Aug 5, 2014 at 10:22 AM, Troels Ring <tring at gvdnet.dk> wrote:
>> Dear friends - below is a small example showing a problem I have
>> understanding doubleYScale from latticeExtra -
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> Both obj1 and obj2 are formatted as I wanted - but when combined the
>> formatting is lost. How comes?
>> Best wishes
>> Troels Ring
>> Aalborg, Denmark
>>
>> library(latticeExtra)
>> T <- seq(1,200,length=100)
>> Y1 <- 10+2*T+0.05*T^2 + rnorm(100,0,40)
>> Y2 <- 0.1 + sqrt(T)+rnorm(100,1,1)
>> tesobj <- data.frame(T=T,Y1=Y1,Y2=Y2)
>>
>>
>> obj1 <-
>> xyplot(Y1~T,tesobj,xlab=list(label="Time",cex=1.5),ylab=list(label="Y1",
>> cex=1.5),scales=list(y=list(cex=1.2),x=list(cex=1.2)),
>> panel = function(x,y,...){
>> panel.xyplot(x,y,...,pch=19)
>> panel.loess(x,y,...,lwd=3)
>> })
>> obj1
>>
>> obj2 <-
>> xyplot(Y2~T,tesobj,xlab=list(label="Time",cex=1.5),ylab=list(label="Y2",
>> cex=1.5),scales=list(y=list(cex=1.2),x=list(cex=1.2)),
>> panel = function(x,y,...){
>> panel.xyplot(x,y,...,pch=20)
>> panel.loess(x,y,...,lwd=3)})
>> obj2
>>
>> (sd <- doubleYScale(obj1,obj2,add.ylab2=TRUE))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jwiley.psych at gmail.com  Thu Aug  7 08:21:45 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 7 Aug 2014 16:21:45 +1000
Subject: [R] Logical operators and named arguments
In-Reply-To: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>
References: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>
Message-ID: <CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/bd0e2155/attachment.pl>

From tring at gvdnet.dk  Thu Aug  7 08:47:33 2014
From: tring at gvdnet.dk (Troels Ring)
Date: Thu, 07 Aug 2014 08:47:33 +0200
Subject: [R] doubleYScale from latticeExtra, problems with style
In-Reply-To: <001201cfb206$116519a0$342f4ce0$@bigpond.com>
References: <53E112C3.6080508@gvdnet.dk>	<CADv2QyGRi971BkaiL8C6zrMyjfFZMzFv2=RYG148pNHj1eseJQ@mail.gmail.com>	<53E1CC3E.5060500@gvdnet.dk>
	<001201cfb206$116519a0$342f4ce0$@bigpond.com>
Message-ID: <53E32105.3010305@gvdnet.dk>

Thanks Duncan - getting still better! - but "Y2" is still unformatted 
and so different from "Y1" - I have been on the help page but fail to 
find explanations.
Best wishes
Troels

Den 07-08-2014 08:08, Duncan Mackay skrev:
> (sd1 <- doubleYScale(obj1,obj2,add.ylab2 = TRUE, use.style = FALSE))
>
> update(sd1,
>      par.settings = list(axis.text = list(cex = 1.2),
>                          par.ylab.text = list(cex = 1.5)))


From maechler at stat.math.ethz.ch  Thu Aug  7 09:35:04 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 7 Aug 2014 09:35:04 +0200
Subject: [R] citation() command doesn't work in R.3.1.1
In-Reply-To: <8761i538aj.fsf@gmail.com>
References: <CACtaF7zhuvgV8rn3xJqXAdkx-egf8NCOyRJaZBeuO=uD9B2ssw@mail.gmail.com>
	<8761i538aj.fsf@gmail.com>
Message-ID: <21475.11304.681077.696945@stat.math.ethz.ch>

>>>>> Igor Sosa Mayor <joseleopoldo1792 at gmail.com>
>>>>>     on Wed, 6 Aug 2014 18:13:56 +0200 writes:

    > Sverre Stausland <stausland.johnsen at iln.uio.no> writes:
    >>> citation()
    >> Error: $ operator is invalid for atomic vectors In
    >> addition: Warning message: In packageDescription(pkg =
    >> package, lib.loc = dirname(dir)) : no package 'base' was
    >> found

    > strange... I think something is wrong with the
    > compilation, since as far as I know, the package `base'
    > should be loaded automatically by starting R...

Even more: 
R cannot be working at all without the base package. It's not a
package you can be without, ever.
So indeed, the error message maybe a teeny tiny tad misleading.
But to reiterate: It's only the broken state of your R,
not at all R 3.1.1  with this problem.

Please do note that we have tens of thousands of tests that must
have run without fault before R is released.  Calling citation()
and >= 99% of all other base R functions is among these quality
assurance tests of an R release.

Martin Maechler (R core team)


From jholtman at gmail.com  Thu Aug  7 11:16:46 2014
From: jholtman at gmail.com (jim holtman)
Date: Thu, 7 Aug 2014 05:16:46 -0400
Subject: [R] ask for help
In-Reply-To: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
Message-ID: <CAAxdm-62D60Ep7sv3ncg0p-ryJza0e2Cg1z6qHU5-NRM+Y6=LQ@mail.gmail.com>

rle

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Aug 6, 2014 at 10:12 PM, Johnnycz <johnnycz at yeah.net> wrote:
> Hello,everybody,
>          I have a sequence,like a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1),how to get the position of each first 1 and 0, that's to say, how to get b<-c(1,6,16,23) for first 1 and d<-c(4,12,18) for first 0.
>         Many thanks!
> Johnny
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From reckbo at bwh.harvard.edu  Thu Aug  7 08:35:13 2014
From: reckbo at bwh.harvard.edu (Ryan)
Date: Thu, 07 Aug 2014 16:35:13 +1000
Subject: [R] Logical operators and named arguments
In-Reply-To: <CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>
References: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>
	<CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>
Message-ID: <4CC79D33-897F-4A27-8BD3-5E2E52D767B5@bwh.harvard.edu>

Josh,

Thank you for your detailed answer.

Best,
Ryan

On 7 Aug 2014, at 16:21, Joshua Wiley wrote:

> Hi Ryan,
>
> It does work, but the *apply family of functions always pass to the first
> argument, so you can specify e2 = , but not e1 =.  For example:
>
>> sapply(1:3, `>`, e2 = 2)
> [1] FALSE FALSE  TRUE
>
> From ?sapply
>
>    'lapply' returns a list of the same length as 'X', each element of
>    which is the result of applying 'FUN' to the corresponding element
>    of 'X'.
>
> so `>` is applied to each element of 1:3
>
> `>`(1, ...)
> `>`(2, ...)
> `>`(3, ...)
>
> and if e2 is specified than that is passed
>
> `>`(1, 2)
> `>`(2, 2)
> `>`(3, 2)
>
> Further, see ?Ops
>
>  If the members of this group are called as functions, any
>         argument names are removed to ensure that positional matching
>         is always used.
>
> and you can see this at work:
>
>> `>`(e1 = 1, e2 = 2)
> [1] FALSE
>> `>`(e2 = 1, e1 = 2)
> [1] FALSE
>
> If you want to the flexibility to specify which argument the elements of X
> should be *applied to, use a wrapper:
>
>> sapply(1:3, function(x) `>`(x, 2))
> [1] FALSE FALSE  TRUE
>> sapply(1:3, function(x) `>`(2, x))
> [1]  TRUE FALSE FALSE
>
>
> HTH,
>
> Josh
>
>
>
> On Thu, Aug 7, 2014 at 2:20 PM, Ryan <reckbo at bwh.harvard.edu> wrote:
>
>> Hi,
>>
>> I'm wondering why calling ">" with named arguments doesn't work as
>> expected:
>>
>>> args(">")
>> function (e1, e2)
>> NULL
>>
>>> sapply(c(1,2,3), `>`, e2=0)
>> [1] TRUE TRUE TRUE
>>
>>> sapply(c(1,2,3), `>`, e1=0)
>> [1] TRUE TRUE TRUE
>>
>> Shouldn't the latter be FALSE?
>>
>> Thanks for any help,
>> Ryan
>>
>>
>> The information in this e-mail is intended only for t...{{dropped:28}}


From Karline.Soetaert at nioz.nl  Thu Aug  7 12:15:52 2014
From: Karline.Soetaert at nioz.nl (Karline Soetaert)
Date: Thu, 7 Aug 2014 10:15:52 +0000
Subject: [R]  Using axis limits with plot3D
Message-ID: <2233d90f052947919906f373f0510ef6@livia.nioz.nl>

Hi Scott,

The trick is to postpone plotting (plot = FALSE) and then do plotdev() with the required limits:

library(plot3D)
x <- z <- seq(-4, 4, by=0.2)
y <- seq(-6, 6, by=0.2)
M <- mesh(x,y,z)
R <- with(M, sqrt(x^2 + y^2 +z^2))
p <- sin(2*R)/(R+1e-3)
x.limits <- c(-2, 2)
y.limits <- c(-2, 2)
slice3D(x,y,z, colvar=p, xs=0, ys=c(0, 4), zs=NULL, scale=F, ticktype="detailed", plot = FALSE) 

plotdev(xlim=x.limits, ylim=y.limits)


This should work.

Karline

Message: 25
Date: Wed, 6 Aug 2014 23:21:04 +0000
From: "Waichler, Scott R" <Scott.Waichler at pnnl.gov>
To: "R. Help" <r-help at r-project.org>
Cc: "karline.soetaert at nioz.nl" <karline.soetaert at nioz.nl>
Subject: [R] Using axis limits with plot3D
Message-ID:
	<074C83DAD4825242A20B2D83FDBCB888765969 at EX10MBOX03.pnnl.gov>
Content-Type: text/plain; charset="us-ascii"

I would like to use the functions in the plot3D package but I am having trouble getting the axis limits to work correctly.  The slices plotted by the code below go beyond the bounds of the persp box and obscure the axis information.  How can I show just the part of the domain within x.limits and y.limits?

library(plot3D)
x <- z <- seq(-4, 4, by=0.2)
y <- seq(-6, 6, by=0.2)
M <- mesh(x,y,z)
R <- with(M, sqrt(x^2 + y^2 +z^2))
p <- sin(2*R)/(R+1e-3)
x.limits <- c(-2, 2)
y.limits <- c(-2, 2)
slice3D(x,y,z, colvar=p, xs=0, ys=c(0, 4), zs=NULL, xlim=x.limits, ylim=y.limits, scale=F, ticktype="detailed")

Thanks,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA, USA



From msuzen at gmail.com  Thu Aug  7 12:32:06 2014
From: msuzen at gmail.com (Suzen, Mehmet)
Date: Thu, 7 Aug 2014 12:32:06 +0200
Subject: [R] weighted network centrality measures by network size
In-Reply-To: <1407286202.88367.YahooMailNeo@web160903.mail.bf1.yahoo.com>
References: <1407286202.88367.YahooMailNeo@web160903.mail.bf1.yahoo.com>
Message-ID: <CAPtbhHx385PGOJqpqxWAq7SDvuvkxwNCj1TOCxU1gFcnDMpH4w@mail.gmail.com>

Hi Jenny,

Have you tried igraph before?  See, http://igraph.org/r/doc/
There are couple of centrality measures there.

Best,
-m



On 6 August 2014 02:50, Jenny Jiang <jiangyunbei at y7mail.com> wrote:
> Dear R-help,
>
> My name is Jenny Jiang and I am a Finance Honours research
>  student from the University of New South Wales Australia. Currently my
> research project involves the calculating of some network centrality
> measures in R, which are degree, closeness, betweenness and eigenvector. However I am having some issue regarding to the calculation of
> the weighted centrality measures by network size. For example, currently
>  my code allows me to calculate centrality measures for each firm year,
> and now I would like to calculate centrality measures weighted by the
> firm network size for each firm year.
>
> My current code is like the following:
>
> install.packages("statnet")
>
> library(statnet)
>
> #read csv
> data <- read.csv("D:\\Users\\z3377013\\Desktop\\networknew1.csv",header=TRUE)
> #companies <- unique(data$CompanyID_)
> #years <- unique(data$Year)
> pairs <- unique(data[,c(1,3)])
> #directors <- unique(c(data$DirectorID_,data$DirectorID_Connected))
> #director_map <- 1:length(directors)
> #names(director_map) <- c(as.character(directors))
>
> #for (i in 1:nrow(data)) {
> #  data[i,2] = director_map[as.character(data[i,2])]
> #  data[i,4] = director_map[as.character(data[i,4])]
> #}
>
> sink("D:\\Users\\z3377013\\Desktop\\measure1.csv")
> for (i in 1:nrow(pairs)) {
>   d <- subset(data, CompanyID_==pairs[i,1]&Year==pairs[i,2])
>   directors <- unique(c(d$DirectorID_,d$DirectorID_Connected))
>   director_map <- 1:length(directors)
>   names(director_map) <- c(as.character(directors))
>   for (j in 1:nrow(d)) {
>     d[j,2] = director_map[as.character(d[j,2])]
>     d[j,4] = director_map[as.character(d[j,4])]
>   }
>
>   net<-network(d[,c(2,4)],directed=F,loops=F,matrix.type="edgelist")
>
>   degree <- degree(net, cmode="freeman", gmode="graph")
>   closeness <- closeness(net,gmode="graph",cmode="undirected")
>   betweenness <- betweenness(net,gmode="graph",cmode="undirected")
>   evcent <- evcent(net,gmode="graph",use.eigen=TRUE)
>
>   write.csv(cbind(pairs[i,], directors, degree, closeness, betweenness, evcent), row.names=FALSE)
> }
> sink()
>
> And an example of my data structure is like the following:
>
> CompanyID_    DirectorID_    Year    DirectorID_Connected
> 900    3700068021    2003    3699838021
> 900    3700418032    2003    3699838021
> 900    3700598032    2003    3699838021
> 900    3700898032    2003    3699838021
> 900    3703478063    2003    3699838021
> 900    3703628063    2003    3699838021
> 900    3703838063    2003    3699838021
> 900    3703998063    2003    3699838021
> 900    3699838021    2003    3700068021
> 900    3700418032    2003    3700068021
> 900    3700598032    2003    3700068021
> 900    3700898032    2003    3700068021
> 900    3703478063    2003    3700068021
> 900    3703628063    2003    3700068021
> 900    3703838063    2003    3700068021
> 900    3703998063    2003    3700068021
> 900    3699838021    2003    3700418032
> 900    3700068021    2003    3700418032
> 900    3700598032    2003    3700418032
> 900    3700068021    2004    3699838021
> 900    3700418032    2004    3699838021
> 900    3700598032    2004    3699838021
> 900    3700898032    2004    3699838021
> 900    3703478063    2004    3699838021
> 1290    1604538114    2003    427207466
> 1290    3556906472    2003    427207466
> 1290    3701108032    2003    427207466
> 1290    3708458104    2003    427207466
> 1290    3708478104    2003    427207466
> 1290    3711248135    2003    427207466
> 1290    10167110612    2003    427207466
> 1290    10271811383    2003    427207466
>
> where for each firm-year I have a list of directors and their corresponding connected directors within that firm-year.
>
> If you could
> provide me the R code regarding to how to calculate the weighted measures by network size that that would be really
> helpful.
>
> I cannot be more than appreciated.
>
> Best regards
>
> Jenny
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Andre.Ziervogel at psychol.uni-giessen.de  Thu Aug  7 12:19:36 2014
From: Andre.Ziervogel at psychol.uni-giessen.de (=?iso-8859-1?Q?Andr=E9_Ziervogel?=)
Date: Thu, 7 Aug 2014 12:19:36 +0200
Subject: [R] Some hpc problems with doMPI and runmpi (I know there is
	R-SIG-HPC)
Message-ID: <22485BC1-188F-4C0C-8DC1-07CF1CC52A8F@psychol.uni-giessen.de>

Dear R people,

I?ve been doing some hpc using R and openmpi. Unfortunately I?ve encoutred a major problem and it?s nature is hard to pin down:

Essentially I call mpirun Rscipt ? as soon as the script reaches a foreach()%dopar% it halts indefinitely. I?ve attached the qsub script:

#!/bin/bash
#$ -S /bin/bash
#$ -N test_14
#$ -cwd
    
#$ -V  
#$ -o "/fhgfs/g61570/Spectral Databases/log/test_14_"$JOB_ID             
#$ -j y
#$ -q regular
#$ -pe openmpi 8
#$ -l h_rt=00:15:00
#$ -l h_vmem=1.9G  
#$ -m eas          
#$ -M andre.ziervogel at psychol.uni-giessen.de

module add gcc     
module add openmpi/gcc/64/1.6.5
module add R/gcc/3.0.1

date                       #log start time

echo "Number of slots " . $NSLOTS

mpirun Rscript /fhgfs/g61570/Spectral\ Databases/test_10.r > /fhgfs/g61570/Spectral\ Databases/log/test_14.Rout

date

exit

and the R file:

suppressMessages(library('doMPI'))

skylla.cluster <- startMPIcluster()
registerDoMPI(skylla.cluster)

cat(paste("COMM SIZE: ", mpi.comm.size(0), " cluster size: ", clusterSize(skylla.cluster), "\n",sep = ""))

tmp.time <- proc.time()
sample <- foreach(i=seq(from=0, to=1000, by =1),.combine='c',.inorder=TRUE) %do%
{
	r <- sqrt(i^2 + i^2) + .Machine$double.eps  * factorial(i)
  	sin(r) / r
}
cat(paste("Processing seriell time: ", "\n", sep = "  "))
print(proc.time() - tmp.time)
#print(sample)

tmp.time <- proc.time()
sample <- foreach(i=seq(from=0, to=1000, by =1),.combine='c',.inorder=TRUE) %dopar%
{
	r <- sqrt(i^2 + i^2) + .Machine$double.eps  * factorial(i)
  	sin(r) / r
}
cat(paste("Processing parallel time: ", "\n", sep = "  "))
print(proc.time() - tmp.time)
#print(sample)

closeCluster(skylla.cluster)
# mpi.close.Rslaves()
# mpi.exit()
mpi.quit(save='no?) 

Any suggestions would be highly appreciated! Thanks!

Best

Andr?

------------------------------------------------------
Dipl. Psych Andr? Ziervogel
andre.ziervogel at psychol.uni-giessen.de
------------------------------------------------------

-------------- n?chster Teil --------------
Ein Dateianhang mit Bin?rdaten wurde abgetrennt...
Dateiname   : signature.asc
Dateityp    : application/pgp-signature
Dateigr??e  : 842 bytes
Beschreibung: Message signed with OpenPGP using GPGMail
URL         : <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/71438479/attachment.bin>

From a.chandhial at btinternet.com  Thu Aug  7 15:32:56 2014
From: a.chandhial at btinternet.com (amarjit chandhial)
Date: Thu, 7 Aug 2014 14:32:56 +0100 (BST)
Subject: [R] dynamic runSum
Message-ID: <26444746.28619.1407418376914.JavaMail.defaultUser@defaultHost>

Hello,
runSum calculates a running sum looking back a fixed distance n, e.g. 20.  
How do I calculate a dynamic runSum function for an xts object?
In 
otherwords, I want to calculate a running sum at each point in time 
looking back a variable distance. In this example, values governed by 
the vector VL.  
Here's a minimum reproducible example:
 
 library(quantstrat)
symbols = c('^GSPC') 
 
 start.date <- as.Date("2010-01-01")
 end.date <- as.Date("2013-12-31")
 
 getSymbols(symbols, from=as.character(start.date), to=as.character(end.date),adjust=T) 
 
 "acF1" <- function(x, n1=5, n2=10, n3=20, nacF1=25, n0=20, ...) {
    var1 <- x - lag(x,1,na.pad=T)
    var2 <- runSD(x, n=n1, sample=TRUE, cumulative=FALSE) 
    var3 <- runMean(var2, n=n2, cumulative=FALSE) 
    VL <- ifelse( trunc(n3/(var2/var3))>nacF1, nacF1, trunc(n3/(var2/var3)))
    p_pos <- ifelse(var1>=0, var1, 0)
    out1 <- runSum(p_pos,  n=n0, cumulative=FALSE)
 
    res <- cbind(var1, var2, var3, VL, p_pos, out1)
    colnames(res) <- c("var1","var2","var3","VL", "p_pos", "out1")
 
    reclass(res)
 }
 
 
 acf1 <- acF1( GSPC[,c("GSPC.Close")], n1=5, n2=10, n3=20, nacF1=25, n0=20)
 acf1
 
 
So on 
2010-02-02, I want runSum to be looking back 23 points as governed by VL , not 20 points
2010-02-03, I want runSum to be looking back 24 points as governed by VL,  not 20 points
 etc etc 
 2013-12-31, I want runSum to be looking back 25 points as governed by VL, not 20 points 
 
 
Amarjit
 
 
 

From pavneet.arora at uk.rsagroup.com  Thu Aug  7 16:07:19 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Thu, 7 Aug 2014 15:07:19 +0100
Subject: [R] Legend in ggplot2
Message-ID: <OF9DACB6B2.EC91AB2B-ON80257D2D.004D261E-80257D2D.004E336D@uk.royalsun.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/9024bcd7/attachment.pl>

From wdunlap at tibco.com  Thu Aug  7 16:36:41 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 Aug 2014 07:36:41 -0700
Subject: [R] ask for help
In-Reply-To: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
Message-ID: <CAF8bMcZJBAzBMRjJ0d2Xo6-Bvg0+Z_O-D2Xx6yAW0TbLXJE62A@mail.gmail.com>

> a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1)
> which( a==1 & c(TRUE, a[-length(a)]!=1) )
[1]  1  6 16 23
> which( a==0 & c(TRUE, a[-length(a)]!=0) )
[1]  4 12 18

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Aug 6, 2014 at 7:12 PM, Johnnycz <johnnycz at yeah.net> wrote:
> Hello,everybody,
>          I have a sequence,like a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1),how to get the position of each first 1 and 0, that's to say, how to get b<-c(1,6,16,23) for first 1 and d<-c(4,12,18) for first 0.
>         Many thanks!
> Johnny
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Aug  7 16:58:36 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 7 Aug 2014 16:58:36 +0200
Subject: [R] ask for help
In-Reply-To: <CAAxdm-62D60Ep7sv3ncg0p-ryJza0e2Cg1z6qHU5-NRM+Y6=LQ@mail.gmail.com>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
	<CAAxdm-62D60Ep7sv3ncg0p-ryJza0e2Cg1z6qHU5-NRM+Y6=LQ@mail.gmail.com>
Message-ID: <D2BFFDF2-5D3C-474C-9103-F072D96A4D73@gmail.com>


On 07 Aug 2014, at 11:16 , jim holtman <jholtman at gmail.com> wrote:

> rle

...with a little tinkering, like

> m <- c(1,cumsum(rle(a)$lengths)+1)
> m
[1]  1  4  6 12 16 18 23 34

then look at every 2nd element, discarding the last.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wdunlap at tibco.com  Thu Aug  7 17:23:29 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 Aug 2014 08:23:29 -0700
Subject: [R] ask for help
In-Reply-To: <CAF8bMcZJBAzBMRjJ0d2Xo6-Bvg0+Z_O-D2Xx6yAW0TbLXJE62A@mail.gmail.com>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
	<CAF8bMcZJBAzBMRjJ0d2Xo6-Bvg0+Z_O-D2Xx6yAW0TbLXJE62A@mail.gmail.com>
Message-ID: <CAF8bMcYXK3Pb5aW9uoS9nYHX1X3k5HVtnCDeMwyXz80qVq8jBA@mail.gmail.com>

My solution may be a bit clearer if you define the function isFirstInRun
isFirstInRun <- function(x) {
   if (length(x) == 0) {
      logical(0)
   } else {
      c(TRUE, x[-1] != x[-length(x)])
   }
}

Then that solution is equivalent to
   which(isFirstInRun(a) & a==1)

If 'a' contains NA's then you have to decide how to deal with them.

(The call to 'which' is not needed if you are going to be using the
result as a subscript.)

You may also want isLastInRun
isLastInRun <- function(x) {
   if (length(x) == 0) {
      logical(0)
   } else {
      c(x[-1] != x[-length(x)], TRUE)
   }
}
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 7, 2014 at 7:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>> a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1)
>> which( a==1 & c(TRUE, a[-length(a)]!=1) )
> [1]  1  6 16 23
>> which( a==0 & c(TRUE, a[-length(a)]!=0) )
> [1]  4 12 18
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Aug 6, 2014 at 7:12 PM, Johnnycz <johnnycz at yeah.net> wrote:
>> Hello,everybody,
>>          I have a sequence,like a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1),how to get the position of each first 1 and 0, that's to say, how to get b<-c(1,6,16,23) for first 1 and d<-c(4,12,18) for first 0.
>>         Many thanks!
>> Johnny
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From kasterma at kasterma.net  Thu Aug  7 17:28:33 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Thu, 7 Aug 2014 17:28:33 +0200
Subject: [R] ask for help
In-Reply-To: <CAF8bMcYXK3Pb5aW9uoS9nYHX1X3k5HVtnCDeMwyXz80qVq8jBA@mail.gmail.com>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
	<CAF8bMcZJBAzBMRjJ0d2Xo6-Bvg0+Z_O-D2Xx6yAW0TbLXJE62A@mail.gmail.com>
	<CAF8bMcYXK3Pb5aW9uoS9nYHX1X3k5HVtnCDeMwyXz80qVq8jBA@mail.gmail.com>
Message-ID: <409C893A-9C85-45F4-A839-2E0E76144EC7@kasterma.net>

For readability I like:

> b <- c(0,a[-length(a)])
> which(a != b & a == 0)
[1]  4 12 18
> which(a != b & a == 1)
[1]  1  6 16 23


On 07 Aug 2014, at 17:23, William Dunlap <wdunlap at tibco.com> wrote:

> My solution may be a bit clearer if you define the function isFirstInRun
> isFirstInRun <- function(x) {
>   if (length(x) == 0) {
>      logical(0)
>   } else {
>      c(TRUE, x[-1] != x[-length(x)])
>   }
> }
> 
> Then that solution is equivalent to
>   which(isFirstInRun(a) & a==1)
> 
> If 'a' contains NA's then you have to decide how to deal with them.
> 
> (The call to 'which' is not needed if you are going to be using the
> result as a subscript.)
> 
> You may also want isLastInRun
> isLastInRun <- function(x) {
>   if (length(x) == 0) {
>      logical(0)
>   } else {
>      c(x[-1] != x[-length(x)], TRUE)
>   }
> }
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Thu, Aug 7, 2014 at 7:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>> a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1)
>>> which( a==1 & c(TRUE, a[-length(a)]!=1) )
>> [1]  1  6 16 23
>>> which( a==0 & c(TRUE, a[-length(a)]!=0) )
>> [1]  4 12 18
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Wed, Aug 6, 2014 at 7:12 PM, Johnnycz <johnnycz at yeah.net> wrote:
>>> Hello,everybody,
>>>         I have a sequence,like a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1),how to get the position of each first 1 and 0, that's to say, how to get b<-c(1,6,16,23) for first 1 and d<-c(4,12,18) for first 0.
>>>        Many thanks!
>>> Johnny
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kasterma at kasterma.net  Thu Aug  7 17:30:36 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Thu, 7 Aug 2014 17:30:36 +0200
Subject: [R] ask for help
In-Reply-To: <409C893A-9C85-45F4-A839-2E0E76144EC7@kasterma.net>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
	<CAF8bMcZJBAzBMRjJ0d2Xo6-Bvg0+Z_O-D2Xx6yAW0TbLXJE62A@mail.gmail.com>
	<CAF8bMcYXK3Pb5aW9uoS9nYHX1X3k5HVtnCDeMwyXz80qVq8jBA@mail.gmail.com>
	<409C893A-9C85-45F4-A839-2E0E76144EC7@kasterma.net>
Message-ID: <7C35CC8C-6BC0-469D-858D-463CB09EC09B@kasterma.net>

Better:
b <- c(a[1]-1,a[-length(a)])

On 07 Aug 2014, at 17:28, Bart Kastermans <kasterma at kasterma.net> wrote:

> For readability I like:
> 
>> b <- c(0,a[-length(a)])
>> which(a != b & a == 0)
> [1]  4 12 18
>> which(a != b & a == 1)
> [1]  1  6 16 23
> 
> 
> On 07 Aug 2014, at 17:23, William Dunlap <wdunlap at tibco.com> wrote:
> 
>> My solution may be a bit clearer if you define the function isFirstInRun
>> isFirstInRun <- function(x) {
>>  if (length(x) == 0) {
>>     logical(0)
>>  } else {
>>     c(TRUE, x[-1] != x[-length(x)])
>>  }
>> }
>> 
>> Then that solution is equivalent to
>>  which(isFirstInRun(a) & a==1)
>> 
>> If 'a' contains NA's then you have to decide how to deal with them.
>> 
>> (The call to 'which' is not needed if you are going to be using the
>> result as a subscript.)
>> 
>> You may also want isLastInRun
>> isLastInRun <- function(x) {
>>  if (length(x) == 0) {
>>     logical(0)
>>  } else {
>>     c(x[-1] != x[-length(x)], TRUE)
>>  }
>> }
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Thu, Aug 7, 2014 at 7:36 AM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1)
>>>> which( a==1 & c(TRUE, a[-length(a)]!=1) )
>>> [1]  1  6 16 23
>>>> which( a==0 & c(TRUE, a[-length(a)]!=0) )
>>> [1]  4 12 18
>>> 
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> 
>>> On Wed, Aug 6, 2014 at 7:12 PM, Johnnycz <johnnycz at yeah.net> wrote:
>>>> Hello,everybody,
>>>>        I have a sequence,like a<-c(1,1,1,0,0,1,1,1,1,1,1,0,0,0,0,1,1,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1),how to get the position of each first 1 and 0, that's to say, how to get b<-c(1,6,16,23) for first 1 and d<-c(4,12,18) for first 0.
>>>>       Many thanks!
>>>> Johnny
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From wdunlap at tibco.com  Thu Aug  7 17:36:26 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 7 Aug 2014 08:36:26 -0700
Subject: [R] ask for help
In-Reply-To: <7C35CC8C-6BC0-469D-858D-463CB09EC09B@kasterma.net>
References: <1261d9ca.3029.147ae3cee9d.Coremail.johnnycz@yeah.net>
	<CAF8bMcZJBAzBMRjJ0d2Xo6-Bvg0+Z_O-D2Xx6yAW0TbLXJE62A@mail.gmail.com>
	<CAF8bMcYXK3Pb5aW9uoS9nYHX1X3k5HVtnCDeMwyXz80qVq8jBA@mail.gmail.com>
	<409C893A-9C85-45F4-A839-2E0E76144EC7@kasterma.net>
	<7C35CC8C-6BC0-469D-858D-463CB09EC09B@kasterma.net>
Message-ID: <CAF8bMca+ZaiVH0A9wKCgyhV_gO9rchYV_THpyVNOiOrawqjPJQ@mail.gmail.com>

I prefer the idiom
  c(TRUE, a[-1] != a[-length(x)])
because it works for character and other data types as well.

I also find that thinking in terms of runs instead of subscripting
tricks is easier.


From tacsunday at yahoo.fr  Thu Aug  7 15:18:11 2014
From: tacsunday at yahoo.fr (Robert U)
Date: Thu, 7 Aug 2014 14:18:11 +0100
Subject: [R] K-nearest neighbor
Message-ID: <1407417491.79808.YahooMailNeo@web172706.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/5b16a2d2/attachment.pl>

From spencer.graves at structuremonitoring.com  Thu Aug  7 18:09:04 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 07 Aug 2014 09:09:04 -0700
Subject: [R] big data?
In-Reply-To: <d0f80125-b358-431d-b5b5-79631223d591@googlegroups.com>
References: <53E1124A.2080603@structuremonitoring.com>
	<34476B18-46F4-4035-B7E9-FC3B83D6643B@comcast.net>
	<d0f80125-b358-431d-b5b5-79631223d591@googlegroups.com>
Message-ID: <53E3A4A0.5010304@structuremonitoring.com>

       Thanks to all who replied.  For the record, I will summarize here 
what I tried and what I learned:


       Mike Harwood suggested the ff package.  David Winsemius suggested 
data.table and colbycol.  Peter Langfelder suggested sqldf.


       sqldf::read.csv.sql allowed me to create an SQL command to read a 
column or a subset of the rows of a 400 GB tab-delimited file in roughly 
a minute on a 2.3 GHz dual core machine running Windows 7 with 8 GB 
RAM.  It also read a column of a 1.3 GB file in 4 minutes.  The 
documentation was sufficient to allow me to easily get what I wanted 
with a minimum of effort.


       If I needed to work with these data regularly, I might experiment 
with colbycol and ff:  The documentation suggested to me that these 
packages might allow me to get quicker answers from routine tasks after 
some preprocessing.  Of course, I could also do the preprocessing 
manually with sqldf.


       Thanks, again.
       Spencer


On 8/6/2014 9:39 AM, Mike Harwood wrote:
> The read.table.ffdf function in the ff package can read in delimited files
> and store them to disk as individual columns.  The ffbase package provides
> additional data management and analytic functionality.  I have used these
> packages on 15 Gb files of 18 million rows and 250 columns.
>
>
> On Tuesday, August 5, 2014 1:39:03 PM UTC-5, David Winsemius wrote:
>>
>> On Aug 5, 2014, at 10:20 AM, Spencer Graves wrote:
>>
>>>       What tools do you like for working with tab delimited text files up
>> to 1.5 GB (under Windows 7 with 8 GB RAM)?
>>
>> ?data.table::fread
>>
>>>       Standard tools for smaller data sometimes grab all the available
>> RAM, after which CPU usage drops to 3% ;-)
>>>
>>>       The "bigmemory" project won the 2010 John Chambers Award but "is
>> not available (for R version 3.1.0)".
>>>
>>>       findFn("big data", 999) downloaded 961 links in 437 packages. That
>> contains tools for data PostgreSQL and other formats, but I couldn't find
>> anything for large tab delimited text files.
>>>
>>>       Absent a better idea, I plan to write a function getField to
>> extract a specific field from the data, then use that to split the data
>> into 4 smaller files, which I think should be small enough that I can do
>> what I want.
>>
>> There is the colbycol package with which I have no experience, but I
>> understand it is designed to partition data into column sized objects.
>> #--- from its help file-----
>> cbc.get.col {colbycol}        R Documentation
>> Reads a single column from the original file into memory
>>
>> Description
>>
>> Function cbc.read.table reads a file, stores it column by column in disk
>> file and creates a colbycol object. Functioncbc.get.col queries this object
>> and returns a single column.
>>
>>>       Thanks,
>>>       Spencer
>>>
>>> ______________________________________________
>>> R-h... at r-project.org <javascript:> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-h... at r-project.org <javascript:> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From spencer.graves at structuremonitoring.com  Thu Aug  7 19:49:00 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Thu, 07 Aug 2014 10:49:00 -0700
Subject: [R] big data?
In-Reply-To: <d0f80125-b358-431d-b5b5-79631223d591@googlegroups.com>
References: <53E1124A.2080603@structuremonitoring.com>
	<34476B18-46F4-4035-B7E9-FC3B83D6643B@comcast.net>
	<d0f80125-b358-431d-b5b5-79631223d591@googlegroups.com>
Message-ID: <53E3BC0C.3030509@structuremonitoring.com>

correcting a typo (400 MB, not GB.  Thanks to David Winsemius for 
reporting it).  Spencer


###############


       Thanks to all who replied.  For the record, I will summarize here 
what I tried and what I learned:


       Mike Harwood suggested the ff package.  David Winsemius suggested 
data.table and colbycol.  Peter Langfelder suggested sqldf.


       sqldf::read.csv.sql allowed me to create an SQL command to read a 
column or a subset of the rows of a 400 MB tab-delimited file in roughly 
a minute on a 2.3 GHz dual core machine running Windows 7 with 8 GB RAM. 
  It also read a column of a 1.3 GB file in 4 minutes.  The 
documentation was sufficient to allow me to easily get what I wanted 
with a minimum of effort.


       If I needed to work with these data regularly, I might experiment 
with colbycol and ff:  The documentation suggested to me that these 
packages might allow me to get quicker answers from routine tasks after 
some preprocessing.  Of course, I could also do the preprocessing 
manually with sqldf.


       Thanks, again.
       Spencer


On 8/6/2014 9:39 AM, Mike Harwood wrote:
> The read.table.ffdf function in the ff package can read in delimited files
> and store them to disk as individual columns.  The ffbase package provides
> additional data management and analytic functionality.  I have used these
> packages on 15 Gb files of 18 million rows and 250 columns.
>
>
> On Tuesday, August 5, 2014 1:39:03 PM UTC-5, David Winsemius wrote:
>>
>> On Aug 5, 2014, at 10:20 AM, Spencer Graves wrote:
>>
>>>       What tools do you like for working with tab delimited text files up
>> to 1.5 GB (under Windows 7 with 8 GB RAM)?
>>
>> ?data.table::fread
>>
>>>       Standard tools for smaller data sometimes grab all the available
>> RAM, after which CPU usage drops to 3% ;-)
>>>
>>>       The "bigmemory" project won the 2010 John Chambers Award but "is
>> not available (for R version 3.1.0)".
>>>
>>>       findFn("big data", 999) downloaded 961 links in 437 packages. That
>> contains tools for data PostgreSQL and other formats, but I couldn't find
>> anything for large tab delimited text files.
>>>
>>>       Absent a better idea, I plan to write a function getField to
>> extract a specific field from the data, then use that to split the data
>> into 4 smaller files, which I think should be small enough that I can do
>> what I want.
>>
>> There is the colbycol package with which I have no experience, but I
>> understand it is designed to partition data into column sized objects.
>> #--- from its help file-----
>> cbc.get.col {colbycol}        R Documentation
>> Reads a single column from the original file into memory
>>
>> Description
>>
>> Function cbc.read.table reads a file, stores it column by column in disk
>> file and creates a colbycol object. Functioncbc.get.col queries this object
>> and returns a single column.
>>
>>>       Thanks,
>>>       Spencer
>>>
>>> ______________________________________________
>>> R-h... at r-project.org <javascript:> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-h... at r-project.org <javascript:> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From marcelolaia at gmail.com  Thu Aug  7 21:50:05 2014
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Thu, 7 Aug 2014 16:50:05 -0300
Subject: [R] Dose response glmer
In-Reply-To: <20140807175922.GD4802@localhost>
References: <20140807175922.GD4802@localhost>
Message-ID: <20140807195005.GR4802@localhost>

I am trying to do a dose response in my dataset, but nothing go a head.
I am adapting a script shared on the web, but I unable to make it
useful for my dataset. I would like to got the LC50 for each Isolado
and if there are differences between then.
 
My data is https://dl.dropboxusercontent.com/u/34009642/R/dead_alive.csv

Here what I copy and try to modifying:

library(plyr)
library(lattice)
library(lme4)
library(arm)
library(lmerTest)
library(faraway)
library(car)

## Conc are concentration. I input only the coef, but, all, 
## except 0, that is my control (without Isolado), are base
## 10. i.e: 10^4, 10^6 e 10^8.

data <- read.table("dead_alive.csv", sep = "\t", dec=",", header = TRUE)

data$Rep <- factor(data$Rep)

mean_data <- ddply(data, c("Isolado", "Conc", "Day"), numcolwise(mean))

xyplot(Dead/(Dead + Live) ~ Conc|Isolado, groups = Day, type = "l",
ylab='Probability', xlab='Dose', data = mean_data)

xyplot(Dead/(Dead + Live) ~ Day|Isolado, groups = Conc, type = "l",
ylab='Probability', xlab='Dose', data = mean_data)

model.logit <- glmer(cbind(Dead, Live) ~ -1 + Isolado + Isolado:Conc +
(0 + Conc|Day), family=binomial, data = data)

Anova(model.logit)
summary(model.logit)

model.probit <- glmer(cbind(Dead, Live) ~  Isolado + Isolado:Conc + (0
+ Conc|Day), family=binomial(link=probit), data=data)

model.cloglog <- glm(cbind(Dead, Live) ~ Isolado + Isolado:Conc + (1 +
Conc|Day), family=binomial(link=cloglog), data=data)

x <- seq(0,8, by=0.2)

prob.logit <- ilogit(model.logit$coef[1] + model.logit$coef[2]*x)
prob.probit <- pnorm(model.probit$coef[1] + model.probit$coef[2]*x)
prob.cloglog <-  1-exp(-exp((model.cloglog$coef[1] +
model.cloglog$coef[2]*x)))

with(subdata, plot(Dead/(Dead + Live) ~ Conc, group = Day, )

lines(x, prob.logit) # solid curve = logit
lines(x, prob.probit, lty=2) # dashed = probit
lines(x, prob.cloglog, lty=5) # longdash = c-log-log

plot(x, prob.logit, type='l', ylab='Probability', xlab='Dose') # solid
curve = logit
lines(x, prob.probit, lty=2) # dashed = probit
lines(x, prob.cloglog, lty=5) # longdash = c-log-log
matplot(x, cbind(prob.probit/prob.logit,
(1-prob.probit)/(1-prob.logit)), type='l', xlab='Dose', ylab='Ratio')
matplot(x, cbind(prob.cloglog/prob.logit,
(1-prob.cloglog)/(1-prob.logit)), type='l', xlab='Dose', ylab='Ratio')

model.logit.data <- glm(cbind(Dead,Live) ~ Conc, family=binomial,
data=data)
pred2.5 <- predict(model.logit.data, newdata=data.frame(Conc=2.5), se=T)
ilogit(pred2.5$fit)
ilogit(c(pred2.5$fit - 1.96*pred2.5$se.fit, pred2.5$fit +
1.96*pred2.5$se.fit))
## what are this 1.96???? Where it come from?

### If there are several predictors, just put in the code
### above something like:
### newdata=data.frame(conc=2.5,x2=4.6,x3=5.8)
### or whatever is the desired set of predictor values...


### Effective Dose calculation:
# What is the concentration that yields a probability of 0.5 of an
# insect dying?

library(MASS)
dose.p(model.logit.data, p=0.5)

# A 95% CI for the ED50:

c(2 - 1.96*0.1466921, 2 + 1.96*0.1466921)

# What is the concentration that yields a probability of 0.8 of an
# insect dying?

dose.p(model.logit.data, p=0.8)
 
-- 
Laia, ML


From jasondonnald4 at gmail.com  Thu Aug  7 21:21:40 2014
From: jasondonnald4 at gmail.com (Jason Donnald)
Date: Thu, 7 Aug 2014 15:21:40 -0400
Subject: [R] Issues in using GP_fit() of GPfit package
Message-ID: <CAPdWG3s+Ssr9pUX1dtf181UKoVaLG1Hz1jfbe+=dsgO7c=c+OQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/a19383d6/attachment.pl>

From tim.blass at gmail.com  Thu Aug  7 21:59:47 2014
From: tim.blass at gmail.com (Tim Blass)
Date: Thu, 7 Aug 2014 15:59:47 -0400
Subject: [R] problem with labeling plots, possibly in font defaults
Message-ID: <CAFYLTvtxRF8L5hvLhMrjPeUNOAsx20PLhMjwc63iPF7U7J=S2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/c72d0e46/attachment.pl>

From felasa at gmail.com  Thu Aug  7 23:55:50 2014
From: felasa at gmail.com (Federico Lasa)
Date: Thu, 7 Aug 2014 16:55:50 -0500
Subject: [R] Legend in ggplot2
In-Reply-To: <OF9DACB6B2.EC91AB2B-ON80257D2D.004D261E-80257D2D.004E336D@uk.royalsun.com>
References: <OF9DACB6B2.EC91AB2B-ON80257D2D.004D261E-80257D2D.004E336D@uk.royalsun.com>
Message-ID: <CAE8W1T3+JJkNpDibOOu4+EsgL6y44+ruVo4HWQyCBZYnVEtgFw@mail.gmail.com>

The problem is that you are not actually 'mapping' any variables to
the fill and colour aestethics so ggplot wont produce legends for
those. I'm not sure ggplots are appropiate for what you're trying to
do here but you can sure hack around it a bit, for instance try:

ggplot(tabu, aes(x=weeks, y=T))+
  scale_y_continuous(expand=c(0,0),

minor_breaks=seq(round(min(tabu$cusums,tabu$Tupper,tabu$Tlower)),

round(max(tabu$cusums,tabu$Tupper,tabu$Tlower)),
                                      1),
                     breaks=seq(round(min(tabu$cusums,tabu$Tupper,tabu$Tlower)),
                                round(max(tabu$cusums,tabu$Tupper,tabu$Tlower)),
                                2))+
  scale_x_discrete(expand=c(0,0),
                   breaks=seq(min(tabu$weeks),
                              max(tabu$weeks)))+
  geom_bar(data=tabu, aes(y=Tupper, fill="Tupper"),stat="identity")+
  geom_point(aes(y=cusums, colour="Cusum"),size=4,pch=15)+
  geom_bar(data=tabu, aes(y=Tlower, fill="Tlower"),stat="identity")+
  geom_hline(aes(yintercept=0),colour="gray20",size=1)+
  geom_hline(aes(yintercept=5),colour="darkorchid4",size=2,alpha=1/2)+
  geom_hline(aes(yintercept=-5),colour="darkorchid4",size=2,alpha=1/2)+
  geom_hline(aes(yintercept=0.5),colour="gold2",size=2,alpha=1/1.3)+
  geom_hline(aes(yintercept=-0.5),colour="gold2",size=2,alpha=1/1.3)+
  scale_fill_manual(name="Legend",
                  breaks=c("Tupper","Tlower"),
                  values=c("brown3","darkolivegreen4"),
                  labels=c("T","L"))+
  scale_colour_manual(name="Legend",
                        breaks=c("Cusum"),
                        values=c("dodgerblue1"),
                        labels=c("Cusum"))

and fill in the balnks

P.S. your plot is very strange.


On Thu, Aug 7, 2014 at 9:07 AM, Pavneet Arora
<pavneet.arora at uk.rsagroup.com> wrote:
> Hi All
>
> Following is my dataset.
> dput(tabu)
> structure(list(weeks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28,
> 29, 30), values = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04,
> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62,
> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62,
> 11.31, 10.52), deviation = c(-0.550000000000001, -2.01,
> -0.710000000000001,
> 1.66, 2.16, 0.18, -1.96, 1.46, -0.800000000000001, 0.34,
> -0.970000000000001,
> 1.47, 0.51, -0.6, 0.0800000000000001, -0.630000000000001,
> 0.619999999999999,
> 0.31, 0, 3, 0.9, -0.67, 2.29, 1.5, 0.6, 1.08, 0.380000000000001,
> 1.62, 1.31, 0.52), cusums = c(-0.550000000000001, -2.56, -3.27,
> -1.61, 0.549999999999999, 0.729999999999999, -1.23, 0.229999999999999,
> -0.570000000000002, -0.230000000000002, -1.2, 0.269999999999998,
> 0.779999999999998, 0.179999999999998, 0.259999999999998,
> -0.370000000000003,
> 0.249999999999996, 0.559999999999997, 0.559999999999997, 3.56,
> 4.46, 3.79, 6.08, 7.58, 8.18, 9.26, 9.64, 11.26, 12.57, 13.09
> ), Tupper = c(0, 0, 0, 1.16, 2.82, 2.5, 0.0399999999999991, 1,
> 0, 0, 0, 0.970000000000001, 0.98, 0, 0, 0, 0.119999999999999,
> 0, 0, 2.5, 2.9, 1.73, 3.52, 4.52, 4.62, 5.2, 5.08, 6.2, 7.01,
> 7.03), Tlower = c(-0.0500000000000007, -1.56, -1.77, 0, 0, 0,
> -1.46, 0, -0.300000000000001, 0, -0.470000000000001, 0, 0,
> -0.0999999999999996,
> 0, -0.130000000000001, 0, 0, 0, 0, 0, -0.17, 0, 0, 0, 0, 0, 0,
> 0, 0)), .Names = c("weeks", "values", "deviation", "cusums",
> "Tupper", "Tlower"), row.names = c(NA, -30L), class = "data.frame")
>
> I have created a plot using ggplot, whereby it makes both barchart and
> plots points, like following:
> ggplot(tabu,aes(x=week,
>                      ymin=min(tabu$cusums,tabu$Tupper,tabu$Tlower),
>                      ymax=max(tabu$cusums,tabu$Tupper,tabu$Tlower)))+
>   labs(x=NULL,y=NULL)+
>   scale_y_continuous(expand=c(0,0),
>  minor_breaks=seq(round(min(tabu$cusums,tabu$Tupper,tabu$Tlower)),
>  round(max(tabu$cusums,tabu$Tupper,tabu$Tlower)),
>                                       1),
>  breaks=seq(round(min(tabu$cusums,tabu$Tupper,tabu$Tlower)),
>  round(max(tabu$cusums,tabu$Tupper,tabu$Tlower)),
>                                 2))+
>   scale_x_discrete(expand=c(0,0),
>                    breaks=seq(min(tabu$week),
>                               max(tabu$week)))+
>   geom_bar(aes(y=tabu$Tupper),stat="identity",fill="brown3")+
>   geom_bar(aes(y=tabu$Tlower),stat="identity",fill="darkolivegreen4")+
>   geom_point(aes(y=tabu$cusums),size=4,pch=15,colour="dodgerblue1")+
>   geom_hline(aes(yintercept=0),colour="gray20",size=1)+ #geom_hline -
> draws a reference line at 0
>   geom_hline(aes(yintercept=5),colour="darkorchid4",size=2,alpha=1/2)+
> #Out-Of-Signal Lines
>   geom_hline(aes(yintercept=-5),colour="darkorchid4",size=2,alpha=1/2)+
> #Out-Of-Signal Lines
>   geom_hline(aes(yintercept=0.5),colour="gold2",size=2,alpha=1/1.3)+ #K
>   geom_hline(aes(yintercept=-0.5),colour="gold2",size=2,alpha=1/1.3)+ #K
>   scale_color_manual(name="Legend",
>                      breaks=c("Tupper","Tlower","CuSum","?K","?H"),
>  values=c("brown3","darkolivegreen4","dodgerblue1","gold2","darkorchid4"),
>                      labels=c("T","L","C","?K","?H"))
>
> However, I am having trouble getting  a legend. I know its supposed to do
> something with melt function in reshape package. But I can?t get it too
> work! Can someone please help me with this.
> ***********************************************************************************************************************************************************************************************************************
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark?s Court, Chart Way, Horsham, West Sussex, RH12 1XL.
>
> Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
> ************************************************************************************************************************************************************************************************************************
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Fri Aug  8 00:24:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 7 Aug 2014 15:24:46 -0700
Subject: [R] problem with labeling plots, possibly in font defaults
In-Reply-To: <CAFYLTvtxRF8L5hvLhMrjPeUNOAsx20PLhMjwc63iPF7U7J=S2w@mail.gmail.com>
References: <CAFYLTvtxRF8L5hvLhMrjPeUNOAsx20PLhMjwc63iPF7U7J=S2w@mail.gmail.com>
Message-ID: <874189FB-9EAC-4E15-812B-D126FA0F9EE6@comcast.net>


On Aug 7, 2014, at 12:59 PM, Tim Blass wrote:

> Hello,
> 
> I am using R 3.1.1 on a (four year old) MacBook, running OSX 10.9.4.
> 
> I just tried making and labeling a plot as follows:
> 
>> x<-rnorm(10)
>> y<-rnorm(10)
>> plot(x,y)
>> title(main="random points")
> 
> which produces a scatter plot of the random points, but without the title
> and without any numbers along the axes. If I then run
> 
>> par(family="sans")
>> plot(x,y,main="plot title")
> 
> the plot has the title and the numbers on the axes (also and 'x' and 'y'
> appear as default labels for the axes).
> 
> I do not know what is going on, but maybe there is some problem in the
> default font settings (I don't know if that could be an R issue or an issue
> specific to my Mac)?

It hasn't happened to me recently (since updating from Leopard and SnowLeapard to Lion)  but it used to happen pretty frequently that I would get a duplicate font that printed empty square boxes. (I wasn't the only one. It got reported several times on R-SIG-Mac.)  One could fix that sort of problem by deleting the offending duplicate entry using Font Book.app

Since this is happening with the default serif font,  you would probably find the duplicate in Times. (It used to be happening to me with Symbol.)

> quartzFonts()$serif
[1] "Times-Roman"      "Times-Bold"       "Times-Italic"     "Times-BoldItalic"
>


> 
> This is clearly not a big problem (at least for now) since I can put labels
> on plots by running par(), but if it is indicative of a larger underlying
> problem (or if there is a simple fix) I would like to know.
> 
> Thank you!

David Winsemius
Alameda, CA, USA


From fisher at plessthan.com  Fri Aug  8 00:37:37 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Thu, 7 Aug 2014 15:37:37 -0700
Subject: [R] Output from file.info()$mtime
Message-ID: <D8656D97-7314-41DA-B356-2060DE9C41D7@plessthan.com>

R 3.1.1
OS X (and Windows)

Colleagues

I have some code that manages files.  Previously (as late as 3.1.0), the command:
	file.info(FILENAME)$mtime == ??
yielded T/F

Now, it triggers an error:
	Error in as.POSIXlt.character(x, tz, ...) : 
	  character string is not in a standard unambiguous format

I looked through Peter Dalgaard?s list of changes in 3.1.1 and I cannot find anything that would explain the change between versions.  I have fixed the problem.  However, I am concerned that other problems may be lurking (i.e., the changes might affect other commands).

Of note, I ran:
	str(file.info(FILENAME)$mtime)
in both versions of R and the results did not differ

Can anyone explain what changed so that I can search my code efficiently?  

Thanks in advance.

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com


From sarah.goslee at gmail.com  Fri Aug  8 00:46:46 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 7 Aug 2014 18:46:46 -0400
Subject: [R] Output from file.info()$mtime
In-Reply-To: <D8656D97-7314-41DA-B356-2060DE9C41D7@plessthan.com>
References: <D8656D97-7314-41DA-B356-2060DE9C41D7@plessthan.com>
Message-ID: <CAM_vjuks70sbsHA7SPjSnDmNF7B7gThXbc22HtYj9WSTiW0EXg@mail.gmail.com>

Are you aware you have so-called smart quotes in your R code? That can
cause all sorts of interesting errors, though I don't get the exact
one you report.

Sarah

On Thu, Aug 7, 2014 at 6:37 PM, Fisher Dennis <fisher at plessthan.com> wrote:
> R 3.1.1
> OS X (and Windows)
>
> Colleagues
>
> I have some code that manages files.  Previously (as late as 3.1.0), the command:
>         file.info(FILENAME)$mtime == ??
> yielded T/F
>
> Now, it triggers an error:
>         Error in as.POSIXlt.character(x, tz, ...) :
>           character string is not in a standard unambiguous format
>
> I looked through Peter Dalgaard?s list of changes in 3.1.1 and I cannot find anything that would explain the change between versions.  I have fixed the problem.  However, I am concerned that other problems may be lurking (i.e., the changes might affect other commands).
>
> Of note, I ran:
>         str(file.info(FILENAME)$mtime)
> in both versions of R and the results did not differ
>
> Can anyone explain what changed so that I can search my code efficiently?
>
> Thanks in advance.
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From craigaumann at gmail.com  Fri Aug  8 01:32:43 2014
From: craigaumann at gmail.com (Craig Aumann)
Date: Thu, 7 Aug 2014 17:32:43 -0600
Subject: [R] Applying Different Predictive Models over Different Geographic
 subsets of a RasterStack
Message-ID: <CAP86wCbWY=+bk-eZ5vrW99FJ3f-pXBZMPivSGLyNy1NxHfto0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/7277bbd6/attachment.pl>

From mmalten at gmail.com  Fri Aug  8 04:10:48 2014
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Thu, 7 Aug 2014 22:10:48 -0400
Subject: [R] Applying Different Predictive Models over Different
 Geographic subsets of a RasterStack
In-Reply-To: <CAP86wCbWY=+bk-eZ5vrW99FJ3f-pXBZMPivSGLyNy1NxHfto0g@mail.gmail.com>
References: <CAP86wCbWY=+bk-eZ5vrW99FJ3f-pXBZMPivSGLyNy1NxHfto0g@mail.gmail.com>
Message-ID: <CANOgrHZtCZnLF4TA8DNj-48H_dCANgXTh9HO_gtLgQPcwgJt5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/1f5df38d/attachment.pl>

From craigaumann at gmail.com  Fri Aug  8 05:09:44 2014
From: craigaumann at gmail.com (Craig Aumann)
Date: Thu, 7 Aug 2014 21:09:44 -0600
Subject: [R] Applying Different Predictive Models over Different
 Geographic subsets of a RasterStack
In-Reply-To: <CANOgrHZtCZnLF4TA8DNj-48H_dCANgXTh9HO_gtLgQPcwgJt5w@mail.gmail.com>
References: <CAP86wCbWY=+bk-eZ5vrW99FJ3f-pXBZMPivSGLyNy1NxHfto0g@mail.gmail.com>
	<CANOgrHZtCZnLF4TA8DNj-48H_dCANgXTh9HO_gtLgQPcwgJt5w@mail.gmail.com>
Message-ID: <CAP86wCYbcHa=22Uw9xDHcDX53RyW0pvVWUVFgVWm5NcgCEz03Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140807/5fdddf97/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Aug  8 08:33:26 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 08 Aug 2014 07:33:26 +0100
Subject: [R] problem with labeling plots, possibly in font defaults
In-Reply-To: <874189FB-9EAC-4E15-812B-D126FA0F9EE6@comcast.net>
References: <CAFYLTvtxRF8L5hvLhMrjPeUNOAsx20PLhMjwc63iPF7U7J=S2w@mail.gmail.com>
	<874189FB-9EAC-4E15-812B-D126FA0F9EE6@comcast.net>
Message-ID: <53E46F36.4040705@stats.ox.ac.uk>

See 
http://cran.r-project.org/bin/macosx/RMacOSX-FAQ.html#I-see-no-text-in-a-Quartz-plot_0021

And the default font is not serif ... that FAQ says it is Arial, but I 
do not know if that is current.

Mac-specific questions to R-sig-mac please.  (This must be Mac-specific 
as the default device, quartz(), is.)

On 07/08/2014 23:24, David Winsemius wrote:
>
> On Aug 7, 2014, at 12:59 PM, Tim Blass wrote:
>
>> Hello,
>>
>> I am using R 3.1.1 on a (four year old) MacBook, running OSX 10.9.4.
>>
>> I just tried making and labeling a plot as follows:
>>
>>> x<-rnorm(10)
>>> y<-rnorm(10)
>>> plot(x,y)
>>> title(main="random points")
>>
>> which produces a scatter plot of the random points, but without the title
>> and without any numbers along the axes. If I then run
>>
>>> par(family="sans")
>>> plot(x,y,main="plot title")
>>
>> the plot has the title and the numbers on the axes (also and 'x' and 'y'
>> appear as default labels for the axes).
>>
>> I do not know what is going on, but maybe there is some problem in the
>> default font settings (I don't know if that could be an R issue or an issue
>> specific to my Mac)?
>
> It hasn't happened to me recently (since updating from Leopard and SnowLeapard to Lion)  but it used to happen pretty frequently that I would get a duplicate font that printed empty square boxes. (I wasn't the only one. It got reported several times on R-SIG-Mac.)  One could fix that sort of problem by deleting the offending duplicate entry using Font Book.app
>
> Since this is happening with the default serif font,  you would probably find the duplicate in Times. (It used to be happening to me with Symbol.)
>
>> quartzFonts()$serif
> [1] "Times-Roman"      "Times-Bold"       "Times-Italic"     "Times-BoldItalic"
>>
>
>
>>
>> This is clearly not a big problem (at least for now) since I can put labels
>> on plots by running par(), but if it is indicative of a larger underlying
>> problem (or if there is a simple fix) I would like to know.
>>
>> Thank you!
>
> David Winsemius
> Alameda, CA, USA


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From kridox at ymail.com  Fri Aug  8 08:56:51 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 8 Aug 2014 15:56:51 +0900
Subject: [R] Some hpc problems with doMPI and runmpi (I know there is
	R-SIG-HPC)
In-Reply-To: <22485BC1-188F-4C0C-8DC1-07CF1CC52A8F@psychol.uni-giessen.de>
References: <22485BC1-188F-4C0C-8DC1-07CF1CC52A8F@psychol.uni-giessen.de>
Message-ID: <CAAcyNCxvMWm=5Xoa2N4dbKsS-_6=Pp5ro+DOMR6G88UtjdxLuQ@mail.gmail.com>

Hello,

In your email, you speak about foreach()%dopar%, but in your script,
it is foreach()%do%.

Best,
Pascal

On Thu, Aug 7, 2014 at 7:19 PM, Andr? Ziervogel
<Andre.Ziervogel at psychol.uni-giessen.de> wrote:
> Dear R people,
>
> I?ve been doing some hpc using R and openmpi. Unfortunately I?ve encoutred a major problem and it?s nature is hard to pin down:
>
> Essentially I call mpirun Rscipt ? as soon as the script reaches a foreach()%dopar% it halts indefinitely. I?ve attached the qsub script:
>
> #!/bin/bash
> #$ -S /bin/bash
> #$ -N test_14
> #$ -cwd
>
> #$ -V
> #$ -o "/fhgfs/g61570/Spectral Databases/log/test_14_"$JOB_ID
> #$ -j y
> #$ -q regular
> #$ -pe openmpi 8
> #$ -l h_rt=00:15:00
> #$ -l h_vmem=1.9G
> #$ -m eas
> #$ -M andre.ziervogel at psychol.uni-giessen.de
>
> module add gcc
> module add openmpi/gcc/64/1.6.5
> module add R/gcc/3.0.1
>
> date                       #log start time
>
> echo "Number of slots " . $NSLOTS
>
> mpirun Rscript /fhgfs/g61570/Spectral\ Databases/test_10.r > /fhgfs/g61570/Spectral\ Databases/log/test_14.Rout
>
> date
>
> exit
>
> and the R file:
>
> suppressMessages(library('doMPI'))
>
> skylla.cluster <- startMPIcluster()
> registerDoMPI(skylla.cluster)
>
> cat(paste("COMM SIZE: ", mpi.comm.size(0), " cluster size: ", clusterSize(skylla.cluster), "\n",sep = ""))
>
> tmp.time <- proc.time()
> sample <- foreach(i=seq(from=0, to=1000, by =1),.combine='c',.inorder=TRUE) %do%
> {
>         r <- sqrt(i^2 + i^2) + .Machine$double.eps  * factorial(i)
>         sin(r) / r
> }
> cat(paste("Processing seriell time: ", "\n", sep = "  "))
> print(proc.time() - tmp.time)
> #print(sample)
>
> tmp.time <- proc.time()
> sample <- foreach(i=seq(from=0, to=1000, by =1),.combine='c',.inorder=TRUE) %dopar%
> {
>         r <- sqrt(i^2 + i^2) + .Machine$double.eps  * factorial(i)
>         sin(r) / r
> }
> cat(paste("Processing parallel time: ", "\n", sep = "  "))
> print(proc.time() - tmp.time)
> #print(sample)
>
> closeCluster(skylla.cluster)
> # mpi.close.Rslaves()
> # mpi.exit()
> mpi.quit(save='no?)
>
> Any suggestions would be highly appreciated! Thanks!
>
> Best
>
> Andr?
>
> ------------------------------------------------------
> Dipl. Psych Andr? Ziervogel
> andre.ziervogel at psychol.uni-giessen.de
> ------------------------------------------------------
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From ripley at stats.ox.ac.uk  Fri Aug  8 10:54:03 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 8 Aug 2014 09:54:03 +0100
Subject: [R] Output from file.info()$mtime
In-Reply-To: <D8656D97-7314-41DA-B356-2060DE9C41D7@plessthan.com>
References: <D8656D97-7314-41DA-B356-2060DE9C41D7@plessthan.com>
Message-ID: <53E4902B.5040406@stats.ox.ac.uk>

On 07/08/2014 23:37, Fisher Dennis wrote:
> R 3.1.1
> OS X (and Windows)
>
> Colleagues
>
> I have some code that manages files.  Previously (as late as 3.1.0), the command:
> 	file.info(FILENAME)$mtime == ??
> yielded T/F
>
> Now, it triggers an error:
> 	Error in as.POSIXlt.character(x, tz, ...) :
> 	  character string is not in a standard unambiguous format
>
> I looked through Peter Dalgaard?s list of changes in 3.1.1 and I cannot find anything that would explain the change between versions.  I have fixed the problem.  However, I am concerned that other problems may be lurking (i.e., the changes might affect other commands).
>
> Of note, I ran:
> 	str(file.info(FILENAME)$mtime)
> in both versions of R and the results did not differ
>
> Can anyone explain what changed so that I can search my code efficiently?

Can you explain how that managed to give TRUE (sic)?  It was always a 
POSIXct timestamp, and as such is never equal "" (assuming that your 
mail client mangled ASCII double quotes).

I believe the relevant report is 
https://bugs.r-project.org/bugzilla/show_bug.cgi?id=15829



>
> Thanks in advance.
>
> Dennis
>
>
> Dennis Fisher MD
> P < (The "P Less Than" Company)
> Phone: 1-866-PLessThan (1-866-753-7784)
> Fax: 1-866-PLessThan (1-866-753-7784)
> www.PLessThan.com


From oriolebaltimore at gmail.com  Fri Aug  8 15:04:56 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Fri, 8 Aug 2014 09:04:56 -0400
Subject: [R] map column name in matrix to multiple elements
Message-ID: <CAL2fYnO4XUHvz89-zsnKrQ-K+9+=FT3HXvGLaTvaWp12KbHffQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/59e98449/attachment.pl>

From sarah.goslee at gmail.com  Fri Aug  8 15:14:02 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Aug 2014 09:14:02 -0400
Subject: [R] map column name in matrix to multiple elements
In-Reply-To: <CAL2fYnO4XUHvz89-zsnKrQ-K+9+=FT3HXvGLaTvaWp12KbHffQ@mail.gmail.com>
References: <CAL2fYnO4XUHvz89-zsnKrQ-K+9+=FT3HXvGLaTvaWp12KbHffQ@mail.gmail.com>
Message-ID: <CAM_vju=S7XHvaRDCUSQfvvawQ+OVYbJuMSihDVYcK+JbXoZqKQ@mail.gmail.com>

Using dput() to provide your data is enormously easier.

Assuming the original column names of your data frame correspond to
the ColMap column of the second data frame, it's very straightforward:


mat <- structure(list(A = c(0.01, -2, -4), B = c(0.2, 1.4, -3), C = c(-0.3,
2.3, -2), D = c(0.8, 3.1, 0.4), E = c(-1, -2, 2.1)), .Names = c("A",
"B", "C", "D", "E"), class = "data.frame", row.names = c("S1",
"S2", "S3"))


matnames <- structure(list(ColMap = c("A", "A", "A", "B", "B", "B", "C"),
    element = c("Apple", "Arcade", "Almira", "Boy", "Balloon",
    "Bat", "Cat")), .Names = c("ColMap", "element"), class =
"data.frame", row.names = c(NA, -7L))

mat <- mat[, matnames$ColMap]
colnames(mat) <- matnames$element



R> mat
   Apple Arcade Almira  Boy Balloon  Bat  Cat
S1  0.01   0.01   0.01  0.2     0.2  0.2 -0.3
S2 -2.00  -2.00  -2.00  1.4     1.4  1.4  2.3
S3 -4.00  -4.00  -4.00 -3.0    -3.0 -3.0 -2.0


Sarah

On Fri, Aug 8, 2014 at 9:04 AM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hi:
> I am requesting help on matrix mapping.
>
> I have a matrix that is 5000 rows x 3000 columns in R env.
>
> Matrix:
>
>            A          B        C       D      E
>
> S1       0.01     0.2      -0.3     0.8    -1
>
> S2       -2        1.4       2.3      3.1    -2
>
> S3       -4         -3        -2        0.4    2.1
>
>
>
> I have another excel sheet, which when I import will have two columns..
>
>
> ColMap        element
>
> A             Apple
> A             Arcade
> A             Almira
> B             Boy
> B             Balloon
> B             Bat
> C             Cat
> .....
>
>
> I want to create another matrix with elements as column names and map
>  ColMap values onto elements.
>
>
>
> new matrix:
>
>                Apple      Arcade       Almira    Boy   Ballon ....
> S1              0.01     0.01            0.01     0.2       0.2
> S2              -2         -2                -2         1.4     1.4....
> S3              -4         -4                -4          -3      -3  ..
>
>
> I have no idea how I could do this in R.  would any one help please.
>
> Thanks
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From wht_crl at yahoo.com  Fri Aug  8 15:26:35 2014
From: wht_crl at yahoo.com (carol white)
Date: Fri, 8 Aug 2014 06:26:35 -0700
Subject: [R] color palettes
Message-ID: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/31b2c7a0/attachment.pl>

From fisher at plessthan.com  Fri Aug  8 15:58:55 2014
From: fisher at plessthan.com (Fisher Dennis)
Date: Fri, 8 Aug 2014 06:58:55 -0700
Subject: [R] Output from file.info()$mtime
In-Reply-To: <53E4902B.5040406@stats.ox.ac.uk>
References: <D8656D97-7314-41DA-B356-2060DE9C41D7@plessthan.com>
	<53E4902B.5040406@stats.ox.ac.uk>
Message-ID: <B9C849B5-4A5C-425F-B737-9CD5ED92B330@plessthan.com>

Professor Ripley

You asked ?how that managed to give TRUE? (I apologize for the mangled quotes ? the error occurred with plain quotes).
All that I can say is that R versions <= 3.1.0 allowed my code to execute without error.  The bug report appears to address the issue.  I typically review Dalgaard?s list of changes in each new version  ?  it does not contain anything about this bug fix.

Dennis


Dennis Fisher MD
P < (The "P Less Than" Company)
Phone: 1-866-PLessThan (1-866-753-7784)
Fax: 1-866-PLessThan (1-866-753-7784)
www.PLessThan.com



On Aug 8, 2014, at 1:54 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 07/08/2014 23:37, Fisher Dennis wrote:
>> R 3.1.1
>> OS X (and Windows)
>> 
>> Colleagues
>> 
>> I have some code that manages files.  Previously (as late as 3.1.0), the command:
>> 	file.info(FILENAME)$mtime == ??
>> yielded T/F
>> 
>> Now, it triggers an error:
>> 	Error in as.POSIXlt.character(x, tz, ...) :
>> 	  character string is not in a standard unambiguous format
>> 
>> I looked through Peter Dalgaard?s list of changes in 3.1.1 and I cannot find anything that would explain the change between versions.  I have fixed the problem.  However, I am concerned that other problems may be lurking (i.e., the changes might affect other commands).
>> 
>> Of note, I ran:
>> 	str(file.info(FILENAME)$mtime)
>> in both versions of R and the results did not differ
>> 
>> Can anyone explain what changed so that I can search my code efficiently?
> 
> Can you explain how that managed to give TRUE (sic)?  It was always a POSIXct timestamp, and as such is never equal "" (assuming that your mail client mangled ASCII double quotes).
> 
> I believe the relevant report is https://bugs.r-project.org/bugzilla/show_bug.cgi?id=15829
> 
> 
> 
>> 
>> Thanks in advance.
>> 
>> Dennis
>> 
>> 
>> Dennis Fisher MD
>> P < (The "P Less Than" Company)
>> Phone: 1-866-PLessThan (1-866-753-7784)
>> Fax: 1-866-PLessThan (1-866-753-7784)
>> www.PLessThan.com
> 


From dcarlson at tamu.edu  Fri Aug  8 16:38:38 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 8 Aug 2014 14:38:38 +0000
Subject: [R] color palettes
In-Reply-To: <1407506577.95765.YahooMailNeo@web121505.mail.ne1.yahoo.com>
References: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8F238@mb02.ads.tamu.edu>
	<1407506577.95765.YahooMailNeo@web121505.mail.ne1.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8F2E0@mb02.ads.tamu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/625c47e4/attachment.pl>

From sarah.goslee at gmail.com  Fri Aug  8 16:40:56 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 8 Aug 2014 10:40:56 -0400
Subject: [R] color palettes
In-Reply-To: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
References: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
Message-ID: <CAM_vjun2VAi+9bWkw_=9STxs4VYEajAUEm_RjkyP2spYspVfqw@mail.gmail.com>

You might take a look at the RColorBrewer package.

Sarah

On Fri, Aug 8, 2014 at 9:26 AM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> Is there any way to take one color of each color family from a color palettes like rainbow? For ex, if there are different blues differentiated by intensity, hue etc, taking one of them. In this case, when using rainbow(n), then how to select 1 color of each family, for ex 1 blue, 1 red etc? It doesn't matter which intensity, hue etc is taken as long as 1 color from each family is taken.
>
>
> Thanks
>
> Carol

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Fri Aug  8 16:41:07 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 8 Aug 2014 14:41:07 +0000
Subject: [R] FW:  color palettes
References: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com> 
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F8F2F4@mb02.ads.tamu.edu>

I think your question is too vague to answer since we don't know what you are trying to do or how many colors you need. The easy answer is that you don't need to use rainbow() at all, just use color names:

mycolors <- c("red", "green", "blue", "violet")

and you will have one of each. For example, col=mycolors(2) will plot using green (and so will col="green"). There are lots of color names in R:

> length(colors(distinct=TRUE))
[1] 502

The longer answer is that there are many color palettes and ways of selecting, manipulating, and choosing colors. The built in functions include palettes such as rainbow, heat.colors, terrain.colors, topo.colors, cm.colors, and gray and ways of specifying colors (in addition to using names) including rgb, hsv, and hcl. In addition, there are several packages for creating color palettes including RColorBrewer, colortools, colorspace, and munsell.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of carol white
Sent: Friday, August 8, 2014 8:27 AM
To: r-help at r-project.org
Subject: [R] color palettes

Hi,
Is there any way to take one color of each color family from a color palettes like rainbow? For ex, if there are different blues differentiated by intensity, hue etc, taking one of them. In this case, when using rainbow(n), then how to select 1 color of each family, for ex 1 blue, 1 red etc? It doesn't matter which intensity, hue etc is taken as long as 1 color from each family is taken.


Thanks

Carol

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From markknecht at gmail.com  Fri Aug  8 15:55:14 2014
From: markknecht at gmail.com (Mark Knecht)
Date: Fri, 8 Aug 2014 06:55:14 -0700
Subject: [R] color palettes
In-Reply-To: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
References: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
Message-ID: <CAK2H+ee=adQzGH3fnyno5HzcHNch5+V0rJHiGGgtMQRDqHhDwQ@mail.gmail.com>

?rainbow
?col2rgb

rainbow(8)
col2rgb(rainbow(8)[5])

col2rgb(rainbow(8)[5])[1]
col2rgb(rainbow(8)[5])[2]
col2rgb(rainbow(8)[5])[3]

On Fri, Aug 8, 2014 at 6:26 AM, carol white <wht_crl at yahoo.com> wrote:
> Hi,
> Is there any way to take one color of each color family from a color palettes like rainbow? For ex, if there are different blues differentiated by intensity, hue etc, taking one of them. In this case, when using rainbow(n), then how to select 1 color of each family, for ex 1 blue, 1 red etc? It doesn't matter which intensity, hue etc is taken as long as 1 color from each family is taken.
>
>
> Thanks
>
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From luis.a.de.sousa at gmail.com  Fri Aug  8 11:28:17 2014
From: luis.a.de.sousa at gmail.com (=?UTF-8?Q?Lu=C3=ADs_de_Sousa?=)
Date: Fri, 8 Aug 2014 11:28:17 +0200
Subject: [R] Problems installing Packages
Message-ID: <CAEtdG7tNdpb81thoiF3XnMz1gf3JnzEjPEb_frsdPzdFSb9MTQ@mail.gmail.com>

Dear Sven,

I am running into this exact some problem in Ubuntu 14.04. I have R
3.1.1 freshly installed and OpenJDK 7 (I do not need BLAS, as far as I
know).

Trying to install rj and rj.dg I get the exact same error messages as
you were getting "Error: cannot determine complete Java config". Were
you able to solve this and install these packages?

Thank you,

Lu?s


From joue at humtec.rwth-aachen.de  Fri Aug  8 15:07:32 2014
From: joue at humtec.rwth-aachen.de (gj)
Date: Fri, 8 Aug 2014 15:07:32 +0200
Subject: [R] inverse Gaussian data transformation in R?
Message-ID: <53E4CB94.1040509@humtec.rwth-aachen.de>

Anyone know of an R package that will allow me to do an inverse 
Gaussian/Wald distribution transform of my data (reaction times)? Thanks!


From from.d.putto at gmail.com  Fri Aug  8 15:13:35 2014
From: from.d.putto at gmail.com (Sheila the angel)
Date: Fri, 8 Aug 2014 15:13:35 +0200
Subject: [R] glmnet, Error in apply(nz, 1,
	median) : dim(X) must have a positive length
Message-ID: <CAFinXcSHQQePwzyUcJvtZp9FVW1ATNn-btBN1Chm3hQKsgJ2aQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/ef9f8178/attachment.pl>

From k-aravindhan1 at ti.com  Fri Aug  8 16:02:33 2014
From: k-aravindhan1 at ti.com (Aravindhan, K)
Date: Fri, 8 Aug 2014 14:02:33 +0000
Subject: [R] Need help on boot strapping
Message-ID: <EF1CB4B85C8C3D41B75FB3A4E4EEA4E8401A72E0@DBDE04.ent.ti.com>

Dear Team,
I am getting this error while running the boot-strapping functions. 

==================================================
mod.db.hub<-glm(TOTAL~1+IPD,family="poisson",data=db)
fit<-fitted(mod.db.hub)
e<-residuals(mod.db.hub)
X<-model.matrix(mod.db.hub)
boot.huber.fixed<-function(data,indices,maxit=20) {
Y<-fit+e[indices]
mod<-glm(Y~X-1,family="poisson",maxit=maxit)
coefficients(mod)
}
library(boot)
db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
db.fix.boot
boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
boot.ci(db.fix.boot,index=2,type=c("bca","perc","poisson"))
==================================================

Error in eval(expr, envir, enclos) : 
negative values not allowed for the 'Poisson' family
In addition: Warning messages:
1: In dpois(y, mu, log = TRUE) : non-integer x = 25.006412
2: In dpois(y, mu, log = TRUE) : non-integer x = 26.969411
3: In dpois(y, mu, log = TRUE) : non-integer x = 66.352323
4: In dpois(y, mu, log = TRUE) : non-integer x = 61.083519
5: In dpois(y, mu, log = TRUE) : non-integer x = 20.596770
6: In dpois(y, mu, log = TRUE) : non-integer x = 43.428258
7: In dpois(y, mu, log = TRUE) : non-integer x = 1108.263554
8: In dpois(y, mu, log = TRUE) : non-integer x = 61.937982
9: In dpois(y, mu, log = TRUE) : non-integer x = 419.991213
10: In dpois(y, mu, log = TRUE) : non-integer x = 47.369133

Can you explain to me how to get rid of these ?

Thanks
Aravindhan


From vind1971 at yahoo.co.in  Fri Aug  8 16:12:04 2014
From: vind1971 at yahoo.co.in (K Aravindhan)
Date: Fri, 8 Aug 2014 22:12:04 +0800
Subject: [R] boot strapping poisson getting warnings and negative values
Message-ID: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>

Dear Team,
I am getting this error while running the boot-strapping functions. 

==================================================
mod.db.hub<-glm(TOTAL~1+IPD,family="poisson",data=db)
fit<-fitted(mod.db.hub)
e<-residuals(mod.db.hub)
X<-model.matrix(mod.db.hub)
boot.huber.fixed<-function(data,indices,maxit=20) { Y<-fit+e[indices]
mod<-glm(Y~X-1,family="poisson",maxit=maxit)
coefficients(mod)
}
library(boot)
db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
db.fix.boot
boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
boot.ci(db.fix.boot,index=2,type=c("bca","perc","poisson"))
==================================================

Error in eval(expr, envir, enclos) : 
negative values not allowed for the 'Poisson' family In addition: Warning messages:
1: In dpois(y, mu, log = TRUE) : non-integer x = 25.006412
2: In dpois(y, mu, log = TRUE) : non-integer x = 26.969411
3: In dpois(y, mu, log = TRUE) : non-integer x = 66.352323
4: In dpois(y, mu, log = TRUE) : non-integer x = 61.083519
5: In dpois(y, mu, log = TRUE) : non-integer x = 20.596770
6: In dpois(y, mu, log = TRUE) : non-integer x = 43.428258
7: In dpois(y, mu, log = TRUE) : non-integer x = 1108.263554
8: In dpois(y, mu, log = TRUE) : non-integer x = 61.937982
9: In dpois(y, mu, log = TRUE) : non-integer x = 419.991213
10: In dpois(y, mu, log = TRUE) : non-integer x = 47.369133

Can you explain to me how to get rid of these ?

Thanks
Aravindhan


From bhh at xs4all.nl  Fri Aug  8 17:33:25 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 8 Aug 2014 17:33:25 +0200
Subject: [R] boot strapping poisson getting warnings and negative values
In-Reply-To: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>
References: <1407507124.21368.YahooMailBasic@web190104.mail.sg3.yahoo.com>
Message-ID: <51C26BD9-08BC-4204-AD9D-1E81208C6692@xs4all.nl>


On 08-08-2014, at 16:12, K Aravindhan <vind1971 at yahoo.co.in> wrote:

> Dear Team,
> I am getting this error while running the boot-strapping functions. 
> 

do you really have to post identical messages within 4 to 5 minutes?
One message is enough and be patient and wait!

Berend

> ==================================================
> mod.db.hub<-glm(TOTAL~1+IPD,family="poisson",data=db)
> fit<-fitted(mod.db.hub)
> e<-residuals(mod.db.hub)
> X<-model.matrix(mod.db.hub)
> boot.huber.fixed<-function(data,indices,maxit=20) { Y<-fit+e[indices]
> mod<-glm(Y~X-1,family="poisson",maxit=maxit)
> coefficients(mod)
> }
> library(boot)
> db.fix.boot<-boot(db,boot.huber.fixed,2000,maxit=20)
> db.fix.boot
> boot.ci(db.fix.boot,index=1,type=c("bca","perc","poisson"))
> boot.ci(db.fix.boot,index=2,type=c("bca","perc","poisson"))
> ==================================================
> 
> Error in eval(expr, envir, enclos) : 
> negative values not allowed for the 'Poisson' family In addition: Warning messages:
> 1: In dpois(y, mu, log = TRUE) : non-integer x = 25.006412
> 2: In dpois(y, mu, log = TRUE) : non-integer x = 26.969411
> 3: In dpois(y, mu, log = TRUE) : non-integer x = 66.352323
> 4: In dpois(y, mu, log = TRUE) : non-integer x = 61.083519
> 5: In dpois(y, mu, log = TRUE) : non-integer x = 20.596770
> 6: In dpois(y, mu, log = TRUE) : non-integer x = 43.428258
> 7: In dpois(y, mu, log = TRUE) : non-integer x = 1108.263554
> 8: In dpois(y, mu, log = TRUE) : non-integer x = 61.937982
> 9: In dpois(y, mu, log = TRUE) : non-integer x = 419.991213
> 10: In dpois(y, mu, log = TRUE) : non-integer x = 47.369133
> 
> Can you explain to me how to get rid of these ?
> 
> Thanks
> Aravindhan
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Fri Aug  8 18:39:24 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 8 Aug 2014 12:39:24 -0400
Subject: [R] dynamic runSum
In-Reply-To: <26444746.28619.1407418376914.JavaMail.defaultUser@defaultHost>
References: <26444746.28619.1407418376914.JavaMail.defaultUser@defaultHost>
Message-ID: <CAP01uR=kQLfs8khObJejriKWKyXEJXMGJSwKzc5-OBp+pvnM2g@mail.gmail.com>

On Thu, Aug 7, 2014 at 9:32 AM, amarjit chandhial
<a.chandhial at btinternet.com> wrote:
> Hello,
> runSum calculates a running sum looking back a fixed distance n, e.g. 20.
> How do I calculate a dynamic runSum function for an xts object?
> In
> otherwords, I want to calculate a running sum at each point in time
> looking back a variable distance. In this example, values governed by
> the vector VL.

The width argument in rollapplyr in the zoo package can be a vector.
It can't be NA though so we have used 1 in those cases here and at the
end used na.omit to get rid of the junk at the beginning:

na.omit(rollapplyr(acf1, ifelse(is.na(acf1$VL), 1, acf1$VL), sum))


From acefix at rocketmail.com  Fri Aug  8 20:25:37 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Fri, 8 Aug 2014 11:25:37 -0700
Subject: [R] how to process multiple data files using R loop
Message-ID: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/54639272/attachment.pl>

From acefix at rocketmail.com  Fri Aug  8 20:28:20 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Fri, 8 Aug 2014 11:28:20 -0700
Subject: [R] circlize package: some error message
Message-ID: <1407522500.3442.YahooMailNeo@web164603.mail.gq1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/fcb1fb64/attachment.pl>

From holland.aggie at gmail.com  Fri Aug  8 22:29:14 2014
From: holland.aggie at gmail.com (James Holland)
Date: Fri, 8 Aug 2014 15:29:14 -0500
Subject: [R] Installing manual package problem
Message-ID: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/7e3c32ba/attachment.pl>

From jim at bitwrit.com.au  Sat Aug  9 01:32:26 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 09 Aug 2014 09:32:26 +1000
Subject: [R] color palettes
In-Reply-To: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
References: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
Message-ID: <1672998.AETZuBJdh4@localhost.localdomain>

On Fri, 8 Aug 2014 06:26:35 AM carol white wrote:
> Hi,
> Is there any way to take one color of each color family from a color
> palettes like rainbow? For ex, if there are different blues 
differentiated
> by intensity, hue etc, taking one of them. In this case, when using
> rainbow(n), then how to select 1 color of each family, for ex 1 blue, 1 
red
> etc? It doesn't matter which intensity, hue etc is taken as long as 1 
color
> from each family is taken.
> 
> 
Hi Carol,
Since you have asked a question about a fundamental aspect of 
graphic representation, I'll try to answer it. Be warned, it will be a 
rather discursive answer.

Whenever we try to communicate information about a number of 
things, where the information is different for each thing, it is essential 
to securely link the correct information to each thing. In compact 
graphic representations such as R plots, this usually resolves to labels 
of some sort. So we could construct a pie chart of the number of 
emails sent by each person in the present discourse using the names 
of the people involved. If we simply label each sector of the resulting 
plot with the names of the people, it will be reasonably informative in 
displaying each person's contribution.

If we venture beyond the comfortable pale of the R help list and try to 
do this with something like Twitter, where I understand there may be 
thousands or even millions of contributors on a subject, the pie chart 
blurs into a chromatic dazzle with an unintelligible fringe of names. We 
might try to rescue the situation by aggregating the tweets into a few 
categories such as helpful, sarcastic and noise, but this does not solve 
the problem of how to display the comparative contributions of the 
twits involved.

So one answer to your question of "How can I intelligibly label 
hundreds of things with colors?" may be "You can't unless your 
audience is made up of spectrographs." Plots that attempt to display 
information about too many things using line types, symbol types and 
colors often simply confuse the audience.

My feeling is that it is the responsibility of the person choosing the 
method of communication to make sure that it communicates well. So 
if we want to display something meaningful about the hypothetical 
pandemonium of tweets above, we might choose to display the 
categories (helpful, sarcastic and noise) broken down by the sex of the 
twits. Perhaps in your case you might want to break down the 
functional category of the genes you are examining by the up- or 
down-regulation of those genes in different cell types.

Your question touches things like "How many letters should there be in 
the alphabet?" and "How many acronyms for psychological tests can 
be meaningfully used in a paragraph?" At any rate, I thank you for 
giving me an idea about graphic illustration.

Jim


From dwinsemius at comcast.net  Sat Aug  9 01:36:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Aug 2014 16:36:02 -0700
Subject: [R] how to process multiple data files using R loop
In-Reply-To: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
References: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
Message-ID: <B265CA11-D83C-4E38-B3D2-A3F2951B753D@comcast.net>


On Aug 8, 2014, at 11:25 AM, Fix Ace wrote:

> I have 16 files and would like to check the information of their first two lines, what I did: 
> 
> 
>> ls(pattern="P_")
>  [1] "P_3_utr_source_data"               "P_5_utr_source_data"              
>  [3] "P_exon_per_gene_cds_source_data"   "P_exon_per_gene_source_data"      
>  [5] "P_exon_source_data"                "P_first_exon_oncds_source_data"   
>  [7] "P_first_intron_oncds_source_data"  "P_first_intron_ongene_source_data"
>  [9] "P_firt_exon_ongene_source_data"    "P_gene_cds_source_data"           
> [11] "P_gene_source_data"                "P_intron_source_data"             
> [13] "P_last_exon_oncds_source_data"     "P_last_exon_ongene_source_data"   
> [15] "P_last_intron_oncds_source_data"   "P_last_intron_ongene_source_data" 
> 
> 

The results from `ls()` are not actual R names but rather are character vectors. To "promote" a character value to an R language-name you need the `get` function:

> 
>> for(i in ls(pattern="P_")){head(i, 2)}
> 

 for(i in ls(pattern="P_")){ head(get(i), 2)}  # Should work.

David.


> It obviously does not work since nothing came out
> 
> What I would like to see for the output is :
> 
>> head(P_3_utr_source_data,2)
>   V1
> 1  1
> 2  1
>> head(P_5_utr_source_data,2)
>   V1
> 1  1
> 2  1
>> 
> .
> 
> .
> .
> 
> 
> 
> Could anybody help me with this?
> 
> Thank you very much for your time:)
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Aug  9 01:38:11 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Aug 2014 16:38:11 -0700
Subject: [R] circlize package: some error message
In-Reply-To: <1407522500.3442.YahooMailNeo@web164603.mail.gq1.yahoo.com>
References: <1407522500.3442.YahooMailNeo@web164603.mail.gq1.yahoo.com>
Message-ID: <3858A992-C199-41D5-B1AF-D4F0C5822EFB@comcast.net>


On Aug 8, 2014, at 11:28 AM, Fix Ace wrote:

> I recently tried to run some sample code from  R package: circlize,
> and got an error message (please see below) ===== > library(circlize) > circos.genomicInitialize(df) > df = data.frame(name = c("TP53", "TP63", "TP73"), + start = c(7565097, 189349205, 3569084),
> + end = c(7590856, 189615068, 3652765),
> + stringsAsFactors = FALSE) > df name     start       end
> 1 TP53   7565097   7590856
> 2 TP63 189349205 189615068
> 3 TP73   3569084   3652765 > circos.genomicInitialize(df) > circos.clear() > circos.genomicInitialize(df, major.by = 10000) Error in seq.default(xlim[1], 10^nchar(round(max(x2 - x1 + 1))), by =
> major.by) : wrong sign in 'by' argument === And my session information: > sessionInfo() R version 3.1.1 (2014-07-10)
> Platform: x86_64-unknown-linux-gnu (64-bit) locale: [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C [3] LC_TIME=en_US.utf8        LC_COLLATE=C [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8 [7] LC_PAPER=en_US.utf8       LC_NAME=C [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base other attached packages:
> [1] circlize_0.1.0 loaded via a namespace (and not attached): [1] AnnotationDbi_1.26.0    Biobase_2.24.0          BiocGenerics_0.10.0 [4] DBI_0.2-7               DESeq2_1.4.5            GenomeInfoDb_1.0.2 [7] GenomicRanges_1.16.3    IRanges_1.22.9          RColorBrewer_1.0-5
> [10] RSQLite_0.11.4          Rcpp_0.11.2             RcppArmadillo_0.4.320.0
> [13] XML_3.98-1.1            XVector_0.4.0           annotate_1.42.1
> [16] genefilter_1.46.1       geneplotter_1.42.0      grid_3.1.1
> [19] lattice_0.20-29         locfit_1.5-9.1          parallel_3.1.1
> [22] splines_3.1.1           stats4_3.1.1            survival_2.37-7
> [25] xtable_1.7-3 > ===
> 
> Wonder anyone could please help me out with this?
> 
> Thank you very much for your time.:)
> 
> 	[[alternative HTML version deleted]]

Your failure to post in plain text makes this message very difficult to read. Unless there is someone with more patience than I have who responds in the next 12 hours, you might consider reposting after reading the Posing Guide.

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Aug  9 01:50:19 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 8 Aug 2014 16:50:19 -0700
Subject: [R] Installing manual package problem
In-Reply-To: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
Message-ID: <3AC60FEF-1FEC-4D30-803E-FE1FBCE5D2B4@comcast.net>


On Aug 8, 2014, at 1:29 PM, James Holland wrote:

> Running R 3.03 on Windows 7
> 
> I am trying to install a package from a github repository.
> 
> https://github.com/google/glassbox
> 
> I downloaded the repository as a zip file, extracted it to get the glassbox
> folder and re-zipped it with 7-zip.

Why?

> 
> I then ran
> 
> #-----------------Start code-------------------#
> 
> install.packages("C:/Users/jholland/Downloads/glassbox.zip", repos=NULL,
> type="source")
> 

I'm a Mac user but when I look at the directory created by expanding that zip file, it appears ready to just move/drag to the library without further installation. It is, however, not named 'glassbox' but rather 'glassbox-master' so perhaps you forgot to rename it?

> 
> The output message said
> 
> Installing package into ?C:/Users/jholland/Documents/R/win-library/3.0?
> (as ?lib? is unspecified)
> 
>> library(glassbox)
> Error in library(glassbox) : ?glassbox? is not a valid installed package
> 
> I'm not sure what I'm doing wrong.  When I look in the R library folder
> (...R/win-library/3.0) I see the glassbox folder there.


> 
> I'm new to using packages not from the CRAN list so I'm trying to learn
> fast.  I tried some searching and this seems to be what I'm suppossed to
> do, but perhaps I need to use dev mode ?
> 
> Thank you for the help.
> 
> ~James
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list.

-- 


David Winsemius
Alameda, CA, USA


From pburns at pburns.seanet.com  Sat Aug  9 01:56:40 2014
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Sat, 09 Aug 2014 00:56:40 +0100
Subject: [R] Logical operators and named arguments
In-Reply-To: <CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>
References: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>
	<CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>
Message-ID: <53E563B8.10905@pburns.seanet.com>

On 07/08/2014 07:21, Joshua Wiley wrote:
> Hi Ryan,
>
> It does work, but the *apply family of functions always pass to the first
> argument, so you can specify e2 = , but not e1 =.  For example:
>
>> sapply(1:3, `>`, e2 = 2)
> [1] FALSE FALSE  TRUE

That is not true:

gt <- function(x, y) x > y

 > sapply(1:3, gt, y=2)
[1] FALSE FALSE  TRUE
 > sapply(1:3, gt, x=2)
[1]  TRUE FALSE FALSE

Specifying the first argument(s) in an apply
call is a standard way of getting flexibility.

I'd hazard to guess that the reason the original
version doesn't work is because `>` is Primitive.
There's speed at the expense of not behaving quite
the same as typical functions.

Pat

>
>>From ?sapply
>
>       'lapply' returns a list of the same length as 'X', each element of
>       which is the result of applying 'FUN' to the corresponding element
>       of 'X'.
>
> so `>` is applied to each element of 1:3
>
> `>`(1, ...)
> `>`(2, ...)
> `>`(3, ...)
>
> and if e2 is specified than that is passed
>
> `>`(1, 2)
> `>`(2, 2)
> `>`(3, 2)
>
> Further, see ?Ops
>
>     If the members of this group are called as functions, any
>            argument names are removed to ensure that positional matching
>            is always used.
>
> and you can see this at work:
>
>> `>`(e1 = 1, e2 = 2)
> [1] FALSE
>> `>`(e2 = 1, e1 = 2)
> [1] FALSE
>
> If you want to the flexibility to specify which argument the elements of X
> should be *applied to, use a wrapper:
>
>> sapply(1:3, function(x) `>`(x, 2))
> [1] FALSE FALSE  TRUE
>> sapply(1:3, function(x) `>`(2, x))
> [1]  TRUE FALSE FALSE
>
>
> HTH,
>
> Josh
>
>
>
> On Thu, Aug 7, 2014 at 2:20 PM, Ryan <reckbo at bwh.harvard.edu> wrote:
>
>> Hi,
>>
>> I'm wondering why calling ">" with named arguments doesn't work as
>> expected:
>>
>>> args(">")
>> function (e1, e2)
>> NULL
>>
>>> sapply(c(1,2,3), `>`, e2=0)
>> [1] TRUE TRUE TRUE
>>
>>> sapply(c(1,2,3), `>`, e1=0)
>> [1] TRUE TRUE TRUE
>>
>> Shouldn't the latter be FALSE?
>>
>> Thanks for any help,
>> Ryan
>>
>>
>> The information in this e-mail is intended only for th...{{dropped:23}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From wdunlap at tibco.com  Sat Aug  9 01:58:23 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 8 Aug 2014 16:58:23 -0700
Subject: [R] how to process multiple data files using R loop
In-Reply-To: <B265CA11-D83C-4E38-B3D2-A3F2951B753D@comcast.net>
References: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
	<B265CA11-D83C-4E38-B3D2-A3F2951B753D@comcast.net>
Message-ID: <CAF8bMcYmz9t=vRhg_h+-x_kGL=pgmkWT8rTF5ShYMz9Y95iFXw@mail.gmail.com>

>  for(i in ls(pattern="P_")){ head(get(i), 2)}  # Should work.

You also need to use print(head(...)) if you want to see the printed
output from each iteration.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Aug 8, 2014 at 4:36 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 8, 2014, at 11:25 AM, Fix Ace wrote:
>
>> I have 16 files and would like to check the information of their first two lines, what I did:
>>
>>
>>> ls(pattern="P_")
>>  [1] "P_3_utr_source_data"               "P_5_utr_source_data"
>>  [3] "P_exon_per_gene_cds_source_data"   "P_exon_per_gene_source_data"
>>  [5] "P_exon_source_data"                "P_first_exon_oncds_source_data"
>>  [7] "P_first_intron_oncds_source_data"  "P_first_intron_ongene_source_data"
>>  [9] "P_firt_exon_ongene_source_data"    "P_gene_cds_source_data"
>> [11] "P_gene_source_data"                "P_intron_source_data"
>> [13] "P_last_exon_oncds_source_data"     "P_last_exon_ongene_source_data"
>> [15] "P_last_intron_oncds_source_data"   "P_last_intron_ongene_source_data"
>>
>>
>
> The results from `ls()` are not actual R names but rather are character vectors. To "promote" a character value to an R language-name you need the `get` function:
>
>>
>>> for(i in ls(pattern="P_")){head(i, 2)}
>>
>
>  for(i in ls(pattern="P_")){ head(get(i), 2)}  # Should work.
>
> David.
>
>
>> It obviously does not work since nothing came out
>>
>> What I would like to see for the output is :
>>
>>> head(P_3_utr_source_data,2)
>>   V1
>> 1  1
>> 2  1
>>> head(P_5_utr_source_data,2)
>>   V1
>> 1  1
>> 2  1
>>>
>> .
>>
>> .
>> .
>>
>>
>>
>> Could anybody help me with this?
>>
>> Thank you very much for your time:)
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From holland.aggie at gmail.com  Sat Aug  9 01:59:58 2014
From: holland.aggie at gmail.com (James Holland)
Date: Fri, 8 Aug 2014 18:59:58 -0500
Subject: [R] Installing manual package problem
In-Reply-To: <3AC60FEF-1FEC-4D30-803E-FE1FBCE5D2B4@comcast.net>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
	<3AC60FEF-1FEC-4D30-803E-FE1FBCE5D2B4@comcast.net>
Message-ID: <CABdaQ+vYiHKxbYWEtYrNrkfFaqpACw3mXML=a2dGv_qJ5H-76A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/74a84ab3/attachment.pl>

From holland.aggie at gmail.com  Sat Aug  9 02:00:49 2014
From: holland.aggie at gmail.com (James Holland)
Date: Fri, 8 Aug 2014 19:00:49 -0500
Subject: [R] Installing manual package problem
In-Reply-To: <3AC60FEF-1FEC-4D30-803E-FE1FBCE5D2B4@comcast.net>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
	<3AC60FEF-1FEC-4D30-803E-FE1FBCE5D2B4@comcast.net>
Message-ID: <CABdaQ+vvTZAfhrXt_9KC28TpUkf7zW0RWoXATWxdOX2PFmcQbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140808/7a411550/attachment.pl>

From jwiley.psych at gmail.com  Sat Aug  9 02:10:25 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Sat, 9 Aug 2014 10:10:25 +1000
Subject: [R] Logical operators and named arguments
In-Reply-To: <53E563B8.10905@pburns.seanet.com>
References: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>
	<CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>
	<53E563B8.10905@pburns.seanet.com>
Message-ID: <CANz9Z_+C6z89jCsy8iCsB4h_WEJZt8=isW07weA3FzS5_5hbow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/5d5f3798/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Aug  9 04:47:29 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 08 Aug 2014 19:47:29 -0700
Subject: [R] Installing manual package problem
In-Reply-To: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
Message-ID: <77f3a18e-ea35-4451-8481-1798a03ee7ce@email.android.com>

The obvious suggestion is to not repack the package file.

You should also be sure to read the Posting Guide, which points out that this is a plain text mailing list (HTML is not a what-you-see-is-what-we-see format).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 8, 2014 1:29:14 PM PDT, James Holland <holland.aggie at gmail.com> wrote:
>Running R 3.03 on Windows 7
>
>I am trying to install a package from a github repository.
>
>https://github.com/google/glassbox
>
>I downloaded the repository as a zip file, extracted it to get the
>glassbox
>folder and re-zipped it with 7-zip.
>
>I then ran
>
>#-----------------Start code-------------------#
>
>install.packages("C:/Users/jholland/Downloads/glassbox.zip",
>repos=NULL,
>type="source")
>
>#-----------------------------------------------------#
>
>The output message said
>
>Installing package into
>???C:/Users/jholland/Documents/R/win-library/3.0???
>(as ???lib??? is unspecified)
>
>> library(glassbox)
>Error in library(glassbox) : ???glassbox??? is not a valid installed
>package
>
>I'm not sure what I'm doing wrong.  When I look in the R library folder
>(...R/win-library/3.0) I see the glassbox folder there.
>
>I'm new to using packages not from the CRAN list so I'm trying to learn
>fast.  I tried some searching and this seems to be what I'm suppossed
>to
>do, but perhaps I need to use dev mode ?
>
>Thank you for the help.
>
>~James
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sat Aug  9 04:49:20 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 09 Aug 2014 14:49:20 +1200
Subject: [R] how to process multiple data files using R loop
In-Reply-To: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
References: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
Message-ID: <53E58C30.1070208@auckland.ac.nz>

On 09/08/14 06:25, Fix Ace wrote:
> I have 16 files and would like to check the information of their first two lines, what I did:
>
>
>> ls(pattern="P_")
>   [1] "P_3_utr_source_data"               "P_5_utr_source_data"
>   [3] "P_exon_per_gene_cds_source_data"   "P_exon_per_gene_source_data"
>   [5] "P_exon_source_data"                "P_first_exon_oncds_source_data"
>   [7] "P_first_intron_oncds_source_data"  "P_first_intron_ongene_source_data"
>   [9] "P_firt_exon_ongene_source_data"    "P_gene_cds_source_data"
> [11] "P_gene_source_data"                "P_intron_source_data"
> [13] "P_last_exon_oncds_source_data"     "P_last_exon_ongene_source_data"
> [15] "P_last_intron_oncds_source_data"   "P_last_intron_ongene_source_data"

<SNIP>

Point of order:  You do ***NOT*** have 16 files as it stands.  The 
output from ls() indicates that you have 16 ***objects*** (presumably 
data frames) in your "work space" or "global environment".  (If the data 
were originally in 16 separate files, these files have apparently 
already been read into R.)

If you are going to use R, learn to distinguish the relevant concepts 
and to use the appropriate terminology.  Otherwise you will confuse 
everyone, including yourself, and get things totally wrong.  It is 
really no more difficult to use correct terminology than it is to use 
incorrect terminology --- and the former has the advantage of not 
misleading all concerned.


Dave Winsemius has already told you how to solve your immediate problem, 
using get().

cheers,

Rolf Turner


-- 
Rolf Turner
Technical Editor ANZJS


From mfethe1 at vols.utk.edu  Sat Aug  9 07:19:48 2014
From: mfethe1 at vols.utk.edu (Fethe, Michael)
Date: Sat, 9 Aug 2014 05:19:48 +0000
Subject: [R] grofit package problem inputting dataset
Message-ID: <1407561587836.7143@vols.utk.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/fa46db26/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Aug  9 09:06:34 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 09 Aug 2014 00:06:34 -0700
Subject: [R] grofit package problem inputting dataset
In-Reply-To: <1407561587836.7143@vols.utk.edu>
References: <1407561587836.7143@vols.utk.edu>
Message-ID: <713db11b-f7bb-4778-8be4-933c3ffe7323@email.android.com>

Your "csv" output doesn't have any commas in it. Your email is in HTML format so we cannot trust it to show what is really there (read the Posting Guide). The sink function forwards stuff that would have been printed to a file, but that isn't a particularly good way to exchange data with other software.

I use

write.table(foo,"data.csv",sep=",",row.names=FALSE)

to export csv data.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 8, 2014 10:19:48 PM PDT, "Fethe, Michael" <mfethe1 at vols.utk.edu> wrote:
>I've recently wanted to analyze some data sets of growth curves; so, I
>decided to try out the grofit package the dataset inputting gave me
>some issues.
>
>
>I've been trying to replicate the example from the grofit package with
>
>
>R
>
>
>> foo <- ran.data(100, 25)
>
>> time <- foo$time
>> data <- foo$data
>
>
>> write.csv(file="data.csv", foo)
>
>> sink(file="sink.txt")
>
>> foo
>
>> sink()
>
>
>also to see if there is another problem I'm missing i've used sink() to
>see the actual output of this data.
>
>
>The sink call provides a dataframe object, however I'm trying to use my
>own data in this. Is there a way to create the dataframe object in
>excel (I've tried following the example from the write.csv() output).
>
>
>I know there is a problem with the input method by following the .csv
>output and i could use follow the sink() output to create my data frame
>object; however, I'm not sure about how i would do this with a large
>dataset with lets say 1000 data points. Has anyone ran into this issue
>and is there a quick work around?
>
>
>
>the sink() output
>
>
>$data
>X1 X2         X3           X4           X5           X6           X7   
>X8          X9         X10         X11       X12       X13       X14   
>   X15      X16      X17
>1     Test I  A 0.06195419  0.314959772  0.398263408  0.091132317 
>1.012083039  0.35122189  1.78719671  2.47453614  3.25305005 3.9829927
>5.2863775 5.8576975 7.2154323 8.501599 8.405278
>2     Test I  B 0.09543701  0.441797809 -0.345308045  0.462532336 
>1.324153423  1.20722268  1.71422886  2.40135394  2.79558398 3.8981917
>5.3614344 5.8423570 6.8511538 7.192188 8.344946
>3     Test I  C 0.16386938 -0.178975999  0.464790443  0.325264753 
>0.033088580  0.79395919  0.63525411  1.71685521  2.62738577 2.5209004
>4.4535178 4.9102966 6.8867905 6.996433 7.553863
>4     Test I  D 0.14198175  0.100778235 -0.164231759 -0.322266709 
>0.571067561  1.24234632  1.54056165  1.96933568  2.97097469 3.7711348
>3.8414402 5.2768758 5.6688960 7.041779 7.651093
>5     Test I  E 0.25390711  0.039312093 -0.463351713  0.628339527 
>0.418403984  0.56460811  1.26348242  1.56823878  1.93588943 3.3141874
>3.0360158 3.7567956 5.6896075 5.873556 6.524754
>6     Test I  F 0.22319304 -0.076464713  0.074501305 -0.160924707 
>0.384392150  0.76412340  1.36118116  1.50356468  2.53322106 3.4924520
>4.5054475 4.6222326 5.5347148 6.349000 7.482548
>7     Test I  G 0.28095487 -0.728248588  0.479450323  0.542078371 
>0.757460716  0.10292177  1.01113655  1.14448036  2.19976257 3.3030023
>3.0848547 4.1877661 5.2832997 5.485825 6.375234
>8     Test I  A 0.32135093 -0.036980401 -0.068313544 -0.059620107 
>0.440995143  0.48424749  0.65644521  1.38482000  2.05964880 2.2548116
>2.6813025 3.5085200 4.7988415 5.017753 5.405950
>9     Test I  B 0.31930456  0.169104577  0.100637447  0.070003632 
>0.304209263  1.72301034
>
>
>...
>
>
>$time
>[,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]    
>[,9]    [,10]    [,11]    [,12]    [,13]    [,14]    [,15]    [,16]   
>[,17]    [,18]    [,19]    [,20]
>[1,] 1.105562 2.429351 3.303547 4.941900 5.370762 6.939251 7.546835
>8.400435 9.602104 10.85058 11.27732 12.12658 13.80886 14.03953 15.88684
>16.63256 17.85349 18.29452 19.94482 20.74473
>[2,] 1.842357 2.183849 3.528340 4.761010 5.610834 6.473241 7.771216
>8.575116 9.544966 10.79126 11.61007 12.91479 13.21070 14.27869 15.30520
>16.32062 17.71822 18.94936 19.58821 20.46276
>[3,] 1.787510 2.734994 3.063325 4.788528 5.676988 6.096337 7.373838
>8.047332 9.042756 10.35715 11.47604 12.84095 13.14183 14.77351 15.81132
>16.63433 17.37387 18.51372 19.83332 20.74899
>[4,] 1.074662 2.386418 3.734951 4.889867 5.994899 6.483399 7.603956
>8.826142 9.536391 10.01653 11.03079 12.60530 13.00965 14.70169 15.17157
>16.75678 17.85311 18.22975 19.28407 20.73184
>[5,] 1.748113 2.185892 3.236870 4.294671 5.093055 6.910312 7.881226
>8.067719 9.632505 10.26807 11.03523 12.75277 13.66110 14.30814 15.61313
>16.62628 17.98222 18.95378 19.46946 20.17275
>
>
>
>the write.csv() output
>
>data.X1 data.X2 data.X3 data.X4 data.X5 data.X6 data.X7 data.X8 data.X9
>1       Test I  A       0.061954188     0.314959772     0.398263408    
>0.091132317     1.012083039     0.351221894     1.787196715
>2       Test I  B       0.095437013     0.441797809     -0.345308045   
>0.462532336     1.324153423     1.207222678     1.714228858
>3       Test I  C       0.16386938      -0.178975999    0.464790443    
>0.325264753     0.03308858      0.793959194     0.63525411
>4       Test I  D       0.141981749     0.100778235     -0.164231759   
>-0.322266709    0.571067561     1.242346317     1.540561647
>5       Test I  E       0.253907113     0.039312093     -0.463351713   
>0.628339527     0.418403984     0.564608113     1.263482418
>6       Test I  F       0.223193041     -0.076464713    0.074501305    
>-0.160924707    0.38439215      0.764123401     1.361181159
>7       Test I  G       0.280954867     -0.728248588    0.479450323    
>0.542078371     0.757460716     0.102921772     1.011136548
>8       Test I  A       0.321350933     -0.036980401    -0.068313544   
>-0.059620107    0.440995143     0.48424749      0.656445215
>9       Test I  B       0.319304561     0.169104577     0.100637447    
>0.070003632     0.304209263     1.723010338     0.471089175
>10      Test I  C       0.340566295     0.093127169     0.033974387    
>0.245478841     0.393911475     0.203389585     1.005453213
>11      Test I  D       0.333709948     0.333333875     0.617596536    
>-0.155448079    0.610516542     0.198084915     0.436375715
>12      Test I  E       0.447724878     0.143374568     -0.109355736   
>0.51752932      0.798150461     0.195199233     0.401329643
>13      Test I  F       0.390981428     -0.142028672    0.139992973    
>0.350846958     0.674888644     0.760292796     0.364816546
>14      Test I  G       0.495102072     0.428716874     0.448110388    
>0.301635201     0.440899901     1.023213179     0.801876373
>15      Test I  A       0.531173467     -0.148918942    0.05126733     
>-0.454508347    0.487135445     -0.073263324    0.012359952
>16      Test I  B       0.565521033     0.136874075     0.067359297    
>0.199090002     0.251350792     0.73318158      0.41629902
>?
>No luck in mimicking these examples for me.
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sat Aug  9 12:12:47 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 09 Aug 2014 11:12:47 +0100
Subject: [R] Logical operators and named arguments
In-Reply-To: <CANz9Z_+C6z89jCsy8iCsB4h_WEJZt8=isW07weA3FzS5_5hbow@mail.gmail.com>
References: <1F4CCED0-22B9-4CC3-9F47-681F6FCBE2AB@bwh.harvard.edu>	<CANz9Z_JLk++Azw64gbmovScNGJoHRFBauhicqNn8mFvtL61m4g@mail.gmail.com>	<53E563B8.10905@pburns.seanet.com>
	<CANz9Z_+C6z89jCsy8iCsB4h_WEJZt8=isW07weA3FzS5_5hbow@mail.gmail.com>
Message-ID: <53E5F41F.7080600@stats.ox.ac.uk>

On 09/08/2014 01:10, Joshua Wiley wrote:
> On Sat, Aug 9, 2014 at 9:56 AM, Patrick Burns <pburns at pburns.seanet.com>
> wrote:
>
>> On 07/08/2014 07:21, Joshua Wiley wrote:
>>
>>> Hi Ryan,
>>>
>>> It does work, but the *apply family of functions always pass to the first
>>> argument, so you can specify e2 = , but not e1 =.  For example:
>>>
>>>   sapply(1:3, `>`, e2 = 2)
>>>>
>>> [1] FALSE FALSE  TRUE
>>>
>>
>> That is not true:
>>
>
> But it is passed as the first argument, not by name, but positionally.  The
> reason it works with your gt() is because R with regular functions is
> flexible:
>
>> f <- function(x, y) x > y
>> f(1:3, x = 2)
> [1]  TRUE FALSE FALSE
>
> but primitives ARE positionally matched

That's not true either.  Almost all primitives intended to be called as 
functions do have standard argument-matching semantics.  (Once upon a 
time they did not, but I added the requisite code years ago.)  There are 
six exceptions plus binary operators and other language elements.

See 
http://cran.r-project.org/doc/manuals/r-release/R-ints.html#g_t_002eInternal-vs-_002ePrimitive 
  and the comments about primitive functions in ?lapply.

>
>> `>`(1:3, 2)
> [1] FALSE FALSE  TRUE
>> `>`(1:3, e1 = 2)
> [1] FALSE FALSE  TRUE
>
>
>
>>
>> gt <- function(x, y) x > y
>>
>>> sapply(1:3, gt, y=2)
>> [1] FALSE FALSE  TRUE
>>> sapply(1:3, gt, x=2)
>> [1]  TRUE FALSE FALSE
>>
>> Specifying the first argument(s) in an apply
>> call is a standard way of getting flexibility.
>>
>> I'd hazard to guess that the reason the original
>> version doesn't work is because `>` is Primitive.
>> There's speed at the expense of not behaving quite
>> the same as typical functions.
>>
>> Pat
>>
>>
>>>   From ?sapply
>>>>
>>>
>>>        'lapply' returns a list of the same length as 'X', each element of
>>>        which is the result of applying 'FUN' to the corresponding element
>>>        of 'X'.
>>>
>>> so `>` is applied to each element of 1:3
>>>
>>> `>`(1, ...)
>>> `>`(2, ...)
>>> `>`(3, ...)
>>>
>>> and if e2 is specified than that is passed
>>>
>>> `>`(1, 2)
>>> `>`(2, 2)
>>> `>`(3, 2)
>>>
>>> Further, see ?Ops
>>>
>>>      If the members of this group are called as functions, any
>>>             argument names are removed to ensure that positional matching
>>>             is always used.
>>>
>>> and you can see this at work:
>>>
>>>   `>`(e1 = 1, e2 = 2)
>>>>
>>> [1] FALSE
>>>
>>>> `>`(e2 = 1, e1 = 2)
>>>>
>>> [1] FALSE
>>>
>>> If you want to the flexibility to specify which argument the elements of X
>>> should be *applied to, use a wrapper:
>>>
>>>   sapply(1:3, function(x) `>`(x, 2))
>>>>
>>> [1] FALSE FALSE  TRUE
>>>
>>>> sapply(1:3, function(x) `>`(2, x))
>>>>
>>> [1]  TRUE FALSE FALSE
>>>
>>>
>>> HTH,
>>>
>>> Josh
>>>
>>>
>>>
>>> On Thu, Aug 7, 2014 at 2:20 PM, Ryan <reckbo at bwh.harvard.edu> wrote:
>>>
>>>   Hi,
>>>>
>>>> I'm wondering why calling ">" with named arguments doesn't work as
>>>> expected:
>>>>
>>>>   args(">")
>>>>>
>>>> function (e1, e2)
>>>> NULL
>>>>
>>>>   sapply(c(1,2,3), `>`, e2=0)
>>>>>
>>>> [1] TRUE TRUE TRUE
>>>>
>>>>   sapply(c(1,2,3), `>`, e1=0)
>>>>>
>>>> [1] TRUE TRUE TRUE
>>>>
>>>> Shouldn't the latter be FALSE?
>>>>
>>>> Thanks for any help,
>>>> Ryan
>>>>
>>>>
>>>> The information in this e-mail is intended only for th...{{dropped:23}}
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>> --
>> Patrick Burns
>> pburns at pburns.seanet.com
>> twitter: @burnsstat @portfolioprobe
>> http://www.portfolioprobe.com/blog
>> http://www.burns-stat.com
>> (home of:
>>   'Impatient R'
>>   'The R Inferno'
>>   'Tao Te Programming')
>>
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From ron_michael70 at yahoo.com  Sat Aug  9 11:46:42 2014
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Sat, 9 Aug 2014 17:46:42 +0800
Subject: [R] Possible pair of 2 binary vectors
Message-ID: <1407577602.54286.YahooMailNeo@web190503.mail.sg3.yahoo.com>

Hi,

Let say I have?2 binary vectors of length 'd', therefore both these vectors can take only 0-1 values. Now I want to simulate all possible pairs of them. Theoretically there will be 4^d possible pairs.

Is there any R function to directly simulate them?

Thanks for your help.


From oma.gonzales at gmail.com  Sat Aug  9 14:15:46 2014
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sat, 9 Aug 2014 07:15:46 -0500
Subject: [R] R Package for Text Manipulation
Message-ID: <CAM-xyZhpPrR_GByUBmQD1vvDOwcGQ7FOyj6VRL_Mma4OfpbVow@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/a719abe8/attachment.pl>

From jorgeivanvelez at gmail.com  Sat Aug  9 14:49:05 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sat, 9 Aug 2014 22:49:05 +1000
Subject: [R] Possible pair of 2 binary vectors
In-Reply-To: <1407577602.54286.YahooMailNeo@web190503.mail.sg3.yahoo.com>
References: <1407577602.54286.YahooMailNeo@web190503.mail.sg3.yahoo.com>
Message-ID: <CAKL8G3FiO=zoDbcxUOD5HJ7bzZ4ERf2FTc1id=e7o5VbM3kBxw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/f9347cc9/attachment.pl>

From ggrothendieck at gmail.com  Sat Aug  9 15:01:34 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 9 Aug 2014 09:01:34 -0400
Subject: [R] R Package for Text Manipulation
In-Reply-To: <CAM-xyZhpPrR_GByUBmQD1vvDOwcGQ7FOyj6VRL_Mma4OfpbVow@mail.gmail.com>
References: <CAM-xyZhpPrR_GByUBmQD1vvDOwcGQ7FOyj6VRL_Mma4OfpbVow@mail.gmail.com>
Message-ID: <CAP01uRnEoxCAg23JC+Ont8C8erbU5AhcK29huW4m36KSbFyjRw@mail.gmail.com>

On Sat, Aug 9, 2014 at 8:15 AM, Omar Andr? Gonz?les D?az
<oma.gonzales at gmail.com> wrote:
> Hi all,
>
> I want to know, where i can find a package to simulate the functions
> "Search and Replace  and "Find Words that contain - replace them with...",
> that we can use in EXCEL.
>
> I've look in other places and they say: "Reshape2" by Hadley Wickham. How
> ever, i've investigated it and its not exactly what i'm looking (it's main
> functions are "cast" and "melt", sure you know them).
>
> May you help me please? I want to download data from Google Analytics and
> clean it, what is the best approach?
>
>         [[alternative HTML version deleted]]
>

1. The gsubfn function in the gsubfn package can do that.  These
commands extract the words and then apply the function represented in
formula notation in the second argument to them:

library(gsubfn) # home page at http://gsubfn.googlecode.com
s <- "The quick brown fox" # test data

# replace the word quick with QUICK

gsubfn("\\S+", ~ if (x == "quick") "QUICK" else x, s)
## [1] "The QUICK brown fox"

# replace words containing o with ?

gsubfn("\\S+", ~ if (grepl("o", x)) "?" else x, s)
## [1] "The quick ? ?"

2. It can also be done without packages:

# replace quick with QUICK

gsub("\\bquick\\b", "QUICK", s)
## [1] "The QUICK brown fox"

# or the following which first split s into a vector of words and
# operate on that pasting it back into a single string at the end

words <- strsplit(s, "\\s+")[[1]]
paste(replace(words, words == "quick", "QUICK"), collapse = " ")
## [1] "The QUICK brown fox"

# replace words containing o with ?.  Use `words` from above.

paste(replace(words, grepl("o", words), "?"), collapse = " ")
## [1] "The quick ? ?"

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From istazahn at gmail.com  Sat Aug  9 17:11:24 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 9 Aug 2014 11:11:24 -0400
Subject: [R] Installing manual package problem
In-Reply-To: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
Message-ID: <CA+vqiLEzgNUH1DuJVH6P1Jyre4Xmd1ZY0OqUM9dSrRZbva+qnQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/e555aace/attachment.pl>

From holland.aggie at gmail.com  Sat Aug  9 17:40:16 2014
From: holland.aggie at gmail.com (James Holland)
Date: Sat, 9 Aug 2014 10:40:16 -0500
Subject: [R] Installing manual package problem
In-Reply-To: <CA+vqiLEzgNUH1DuJVH6P1Jyre4Xmd1ZY0OqUM9dSrRZbva+qnQ@mail.gmail.com>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>
	<CA+vqiLEzgNUH1DuJVH6P1Jyre4Xmd1ZY0OqUM9dSrRZbva+qnQ@mail.gmail.com>
Message-ID: <CABdaQ+sxaZxwuOqSTeJ-_Xm4EZfmh_RTBwOZbM86i3wrymGjzA@mail.gmail.com>

Thank you all, I didn't know about the install_github function.

Sorry, forgot to switch to plain text

On Sat, Aug 9, 2014 at 10:11 AM, Ista Zahn <istazahn at gmail.com> wrote:
> If you just want to install the package from github, the easy way is to
> first install the devtools package and use the install_github function.
>
> Best,
> Ista
>
> On Aug 8, 2014 4:21 PM, "James Holland" <holland.aggie at gmail.com> wrote:
>>
>> Running R 3.03 on Windows 7
>>
>> I am trying to install a package from a github repository.
>>
>> https://github.com/google/glassbox
>>
>> I downloaded the repository as a zip file, extracted it to get the
>> glassbox
>> folder and re-zipped it with 7-zip.
>>
>> I then ran
>>
>> #-----------------Start code-------------------#
>>
>> install.packages("C:/Users/jholland/Downloads/glassbox.zip", repos=NULL,
>> type="source")
>>
>> #-----------------------------------------------------#
>>
>> The output message said
>>
>> Installing package into ?C:/Users/jholland/Documents/R/win-library/3.0?
>> (as ?lib? is unspecified)
>>
>> > library(glassbox)
>> Error in library(glassbox) : ?glassbox? is not a valid installed package
>>
>> I'm not sure what I'm doing wrong.  When I look in the R library folder
>> (...R/win-library/3.0) I see the glassbox folder there.
>>
>> I'm new to using packages not from the CRAN list so I'm trying to learn
>> fast.  I tried some searching and this seems to be what I'm suppossed to
>> do, but perhaps I need to use dev mode ?
>>
>> Thank you for the help.
>>
>> ~James
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From ligges at statistik.tu-dortmund.de  Sat Aug  9 17:47:21 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 09 Aug 2014 17:47:21 +0200
Subject: [R] Installing manual package problem
In-Reply-To: <CABdaQ+sxaZxwuOqSTeJ-_Xm4EZfmh_RTBwOZbM86i3wrymGjzA@mail.gmail.com>
References: <CABdaQ+vS4OQUhpFXZTCcu0-nFC3Z-J5P+eZ+_R9g5pn3XOwKmw@mail.gmail.com>	<CA+vqiLEzgNUH1DuJVH6P1Jyre4Xmd1ZY0OqUM9dSrRZbva+qnQ@mail.gmail.com>
	<CABdaQ+sxaZxwuOqSTeJ-_Xm4EZfmh_RTBwOZbM86i3wrymGjzA@mail.gmail.com>
Message-ID: <53E64289.6050603@statistik.tu-dortmund.de>



On 09.08.2014 17:40, James Holland wrote:
> Thank you all, I didn't know about the install_github function.
>
> Sorry, forgot to switch to plain text
>
> On Sat, Aug 9, 2014 at 10:11 AM, Ista Zahn <istazahn at gmail.com> wrote:
>> If you just want to install the package from github, the easy way is to
>> first install the devtools package and use the install_github function.


Reason why your former approach did not work:
This is a source package, you need to install source packages via

install.packages(..., type="source")

or from the command line via

R CMD INSTALL package_version.tar.gz

See the R Installation and Administration manual for details.
To build a proper .tar.gz file, do use

R CMD build directory_name

from the command line.

Best,
Uwe Ligges




Best,
Uwe Ligges



>> Best,
>> Ista
>>
>> On Aug 8, 2014 4:21 PM, "James Holland" <holland.aggie at gmail.com> wrote:
>>>
>>> Running R 3.03 on Windows 7
>>>
>>> I am trying to install a package from a github repository.
>>>
>>> https://github.com/google/glassbox
>>>
>>> I downloaded the repository as a zip file, extracted it to get the
>>> glassbox
>>> folder and re-zipped it with 7-zip.
>>>
>>> I then ran
>>>
>>> #-----------------Start code-------------------#
>>>
>>> install.packages("C:/Users/jholland/Downloads/glassbox.zip", repos=NULL,
>>> type="source")
>>>
>>> #-----------------------------------------------------#
>>>
>>> The output message said
>>>
>>> Installing package into ?C:/Users/jholland/Documents/R/win-library/3.0?
>>> (as ?lib? is unspecified)
>>>
>>>> library(glassbox)
>>> Error in library(glassbox) : ?glassbox? is not a valid installed package
>>>
>>> I'm not sure what I'm doing wrong.  When I look in the R library folder
>>> (...R/win-library/3.0) I see the glassbox folder there.
>>>
>>> I'm new to using packages not from the CRAN list so I'm trying to learn
>>> fast.  I tried some searching and this seems to be what I'm suppossed to
>>> do, but perhaps I need to use dev mode ?
>>>
>>> Thank you for the help.
>>>
>>> ~James
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Aug  9 17:54:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 9 Aug 2014 08:54:49 -0700
Subject: [R] R Package for Text Manipulation
In-Reply-To: <CAM-xyZhpPrR_GByUBmQD1vvDOwcGQ7FOyj6VRL_Mma4OfpbVow@mail.gmail.com>
References: <CAM-xyZhpPrR_GByUBmQD1vvDOwcGQ7FOyj6VRL_Mma4OfpbVow@mail.gmail.com>
Message-ID: <45A5DCCA-E8B9-4F29-BF2C-55733A05BABA@comcast.net>


On Aug 9, 2014, at 5:15 AM, Omar Andr? Gonz?les D?az wrote:

> Hi all,
> 
> I want to know, where i can find a package to simulate the functions
> "Search and Replace  and "Find Words that contain - replace them with...",
> that we can use in EXCEL.
> 
> I've look in other places and they say: "Reshape2" by Hadley Wickham. How
> ever, i've investigated it and its not exactly what i'm looking (it's main
> functions are "cast" and "melt", sure you know them).
> 
> May you help me please? I want to download data from Google Analytics and
> clean it, what is the best approach?
> 

That request is on the vague side. You are advised in the Posting Guide to include code that begins an analysis and then requests assistance with specific difficulties. (You are also asked to do this in a plain text message since HTML tends to scramble messages.) The base package offers the `grep`, `sub`, and `gsub` functions which bring the power of regular expression to the R user. There are much more flexible that anything that Excel offers. Please look at:

?grep
?regex


> 	[[alternative HTML version deleted]]

And do :

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David Winsemius
Alameda, CA, USA


From lvilleg at ncsu.edu  Sat Aug  9 22:39:29 2014
From: lvilleg at ncsu.edu (Laura Villegas Ortiz)
Date: Sat, 9 Aug 2014 16:39:29 -0400
Subject: [R] loops with assign() and get()
Message-ID: <CAB5eD-jOxEmGG2YxrGy33Hkp8+r=doH+p5eV6j+=vQF8LEG+RA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/4ae8cf9f/attachment.pl>

From Scott.Waichler at pnnl.gov  Sun Aug 10 00:31:04 2014
From: Scott.Waichler at pnnl.gov (Waichler, Scott R)
Date: Sat, 9 Aug 2014 22:31:04 +0000
Subject: [R] Reading chunks of data from a file more efficiently
Message-ID: <074C83DAD4825242A20B2D83FDBCB888765CDC@EX10MBOX03.pnnl.gov>

Hi,

I have some very large (~1.1 GB) output files from a groundwater model called STOMP that I want to read as efficiently as possible.  For each variable there are over 1 million values to read.  Variables are not organized in columns; instead they are written out in sections in the file, like this:

X-Direction Node Positions, m
 5.931450000E+05  5.931550000E+05  5.931650000E+05  5.931750000E+05
 5.932450000E+05  5.932550000E+05  5.932650000E+05  5.932750000E+05
. . . 
 5.946950000E+05  5.947050000E+05  5.947150000E+05  5.947250000E+05
 5.947950000E+05  5.948050000E+05  5.948150000E+05  5.948250000E+05

Y-Direction Node Positions, m
 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05
 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05
. . . 
 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05
 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05

Z-Direction Node Positions, m
 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01
 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01
. . .

I want to read and use only a subset of the variables.  I wrote the function below to find the line where each target variable begins and then scan the values, but it still seems rather slow, perhaps because I am opening and closing the file for each variable.  Can anyone suggest a faster way?

# Reads original STOMP plot file (plot.*) directly.  Should be useful when the plot files are
# very large with lots of variables, and you just want to retrieve a few of them.  
# Arguments:  1) plot filename, 2) number of nodes, 
# 3) character vector of names of target variables you want to return.
# Returns a list with the selected plot output.
READ.PLOT.OUTPUT6 <- function(plt.file, num.nodes, var.names) {
  lines <- readLines(plt.file)
  num.vars <- length(var.names)
  tmp <- list()
  for(i in 1:num.vars) {
    ind <- grep(var.names[i], lines, fixed=T, useBytes=T)
    if(length(ind) != 1) stop("Not one line in the plot file with matching variable name.\n")
    tmp[[i]] <- scan(plt.file, skip=ind, nmax=num.nodes, quiet=T)
  }
  return(tmp)
}  # end READ.PLOT.OUTPUT6()

Regards,
Scott Waichler
Pacific Northwest National Laboratory
Richland, WA, USA
scott.waichler at pnnl.gov


From wdunlap at tibco.com  Sun Aug 10 00:32:38 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 9 Aug 2014 15:32:38 -0700
Subject: [R] loops with assign() and get()
In-Reply-To: <CAB5eD-jOxEmGG2YxrGy33Hkp8+r=doH+p5eV6j+=vQF8LEG+RA@mail.gmail.com>
References: <CAB5eD-jOxEmGG2YxrGy33Hkp8+r=doH+p5eV6j+=vQF8LEG+RA@mail.gmail.com>
Message-ID: <CAF8bMcYbkxQwAxJ40kN01jaGfJMLnUcg9Q6ZtfDtQsWbgeP5DQ@mail.gmail.com>

> I was able to create 102 distinct dataframes (DFs1, DFs2, DFs3, etc) using
> the assign() in a loop.

The first step to making things easier to do is to put those data.frames
into a list.  I'll call it DFS and your data.frames will now be DFs[[1]],
DFs[[2]], ..., DFs[[length(DFs)]].
    DFs <- lapply(paste0("DFs", 1:102), get)
In the future, I think it would be easier if you skipped the 'assign()'
and just put the data into a list from the start.

Now use lapply to process that list, creating a new list called 'df', where
df[[i]] is the result of processing DFs[[i]]:

df <- lapply(DFs, FUN=function(DFsi) {
                      # your code from the for loop you supplied
                      dfi=DFsi[1,]
                      dfi=dfi[,1:3]
                      names(dfi)=names(DFsi[c(1,4,5)])
                      dfi=rbind(dfi,DFsi[c(1,4,5)])
                      names(dfi)=c("UID","Date","Location")
                      dfi # return this to put in list that lapply is making
                  })

(You didn't supply sample data so I did not run this - there may be typos.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Aug 9, 2014 at 1:39 PM, Laura Villegas Ortiz <lvilleg at ncsu.edu> wrote:
> Dear all,
>
> I was able to create 102 distinct dataframes (DFs1, DFs2, DFs3, etc) using
> the assign() in a loop.
>
> Now, I would like to perform the following transformation for each one of
> these dataframes:
>
> df1=DFs1[1,]
> df1=df1[,1:3]
> names(df1)=names(DFs1[c(1,4,5)])
> df1=rbind(df1,DFs1[c(1,4,5)])
> names(df1)=c("UID","Date","Location")
>
> something like this:
>
> for (i in 1 : nrow(unique)){
>
> dfi=DFsi[1,]
> dfi=dfi[,1:3]
> names(dfi)=names(DFsi[c(1,4,5)])
> dfi=rbind(dfi,DFsi[c(1,4,5)])
> names(dfi)=c("UID","Date","Location")
>
> }
>
> I thought it could be straightforward but has proven the opposite
>
> Many thanks
>
> Laura
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Aug 10 03:14:05 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 9 Aug 2014 18:14:05 -0700 (PDT)
Subject: [R] Reading chunks of data from a file more efficiently
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB888765CDC@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB888765CDC@EX10MBOX03.pnnl.gov>
Message-ID: <alpine.BSF.2.00.1408091758230.3639@pedal.dcn.davis.ca.us>

Informally abbreviating data is not recommended... I faked some, but would 
appreciate if you would make your example reproducible next time.

All I really did for performance was use the data you read in rather than 
re-scanning the file.

# generated by using dput()
lines <- c("X-Direction Node Positions, m",
" 5.931450000E+05  5.931550000E+05  5.931650000E+05  5.931750000E+05",
" 5.932450000E+05  5.932550000E+05  5.932650000E+05  5.932750000E+05",
" 5.946950000E+05  5.947050000E+05  5.947150000E+05  5.947250000E+05",
" 5.947950000E+05  5.948050000E+05  5.948150000E+05  5.948250000E+05",
"",
"Y-Direction Node Positions, m",
" 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05",
" 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05",
" 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05",
" 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05",
"",
"Z-Direction Node Positions, m",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
"",
"X-Direction Node Positions, n",
" 5.931450000E+05  5.931550000E+05  5.931650000E+05  5.931750000E+05",
" 5.932450000E+05  5.932550000E+05  5.932650000E+05  5.932750000E+05",
" 5.946950000E+05  5.947050000E+05  5.947150000E+05  5.947250000E+05",
" 5.947950000E+05  5.948050000E+05  5.948150000E+05  5.948250000E+05",
"",
"Y-Direction Node Positions, n",
" 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05",
" 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05",
" 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05",
" 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05",
"",
"Z-Direction Node Positions, n",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
" 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01",
"", "")

getDimVar <- function( lines, Dim, specifiedvar, starts ) {
   vstart <- grep( paste0( "^", Dim, "-Direction Node Positions, "
                         , specifiedvar, "$" ), lines )
   startv <- match( vstart, starts )
   if ( 0 == length( startv ) ) {
     stop( "Variable ", specifiedvar, " not found" )
   }
   if ( length( starts ) == startv ) {
     vend <- length( lines )
   } else {
     vend <- starts[ startv + 1 ] - 1
   }
   tcon <- textConnection( lines[ seq( vstart + 1, vend ) ] )
   result <- scan( tcon )
   close( tcon )
   result
}

starts <- grep( "^[XYZ]-Direction Node Positions, ", lines )

specifiedvar <- "n"
n <- data.frame( X=getDimVar( lines, "X", specifiedvar, starts )
                , Y=getDimVar( lines, "Y", specifiedvar, starts )
                , Z=getDimVar( lines, "Z", specifiedvar, starts ) )

# test a variable that doesn't exist
specifiedvar <- "o"
o <- data.frame( X=getDimVar( lines, "X", specifiedvar, starts )
                , Y=getDimVar( lines, "Y", specifiedvar, starts )
                , Z=getDimVar( lines, "Z", specifiedvar, starts ) )


On Sat, 9 Aug 2014, Waichler, Scott R wrote:

> Hi,
>
> I have some very large (~1.1 GB) output files from a groundwater model called STOMP that I want to read as efficiently as possible.  For each variable there are over 1 million values to read.  Variables are not organized in columns; instead they are written out in sections in the file, like this:
>
> X-Direction Node Positions, m
> 5.931450000E+05  5.931550000E+05  5.931650000E+05  5.931750000E+05
> 5.932450000E+05  5.932550000E+05  5.932650000E+05  5.932750000E+05
> . . .
> 5.946950000E+05  5.947050000E+05  5.947150000E+05  5.947250000E+05
> 5.947950000E+05  5.948050000E+05  5.948150000E+05  5.948250000E+05
>
> Y-Direction Node Positions, m
> 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05
> 1.148050000E+05  1.148050000E+05  1.148050000E+05  1.148050000E+05
> . . .
> 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05
> 1.171950000E+05  1.171950000E+05  1.171950000E+05  1.171950000E+05
>
> Z-Direction Node Positions, m
> 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01
> 9.550000000E+01  9.550000000E+01  9.550000000E+01  9.550000000E+01
> . . .
>
> I want to read and use only a subset of the variables.  I wrote the function below to find the line where each target variable begins and then scan the values, but it still seems rather slow, perhaps because I am opening and closing the file for each variable.  Can anyone suggest a faster way?
>
> # Reads original STOMP plot file (plot.*) directly.  Should be useful when the plot files are
> # very large with lots of variables, and you just want to retrieve a few of them.
> # Arguments:  1) plot filename, 2) number of nodes,
> # 3) character vector of names of target variables you want to return.
> # Returns a list with the selected plot output.
> READ.PLOT.OUTPUT6 <- function(plt.file, num.nodes, var.names) {
>  lines <- readLines(plt.file)
>  num.vars <- length(var.names)
>  tmp <- list()
>  for(i in 1:num.vars) {
>    ind <- grep(var.names[i], lines, fixed=T, useBytes=T)
>    if(length(ind) != 1) stop("Not one line in the plot file with matching variable name.\n")
>    tmp[[i]] <- scan(plt.file, skip=ind, nmax=num.nodes, quiet=T)
>  }
>  return(tmp)
> }  # end READ.PLOT.OUTPUT6()
>
> Regards,
> Scott Waichler
> Pacific Northwest National Laboratory
> Richland, WA, USA
> scott.waichler at pnnl.gov
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From tmiles at kinaxis.com  Sun Aug 10 00:46:20 2014
From: tmiles at kinaxis.com (Trevor Miles)
Date: Sat, 9 Aug 2014 22:46:20 +0000
Subject: [R] Time series analysis for a large number of series
Message-ID: <55E623B22559EB419EC94585BCAD05B191E48242@ottvmpex2.kinaxis.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140809/e47d0eed/attachment.pl>

From wht_crl at yahoo.com  Sun Aug 10 13:32:32 2014
From: wht_crl at yahoo.com (carol white)
Date: Sun, 10 Aug 2014 04:32:32 -0700
Subject: [R] color palettes
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F8F2E0@mb02.ads.tamu.edu>
References: <1407504395.6032.YahooMailNeo@web121503.mail.ne1.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8F238@mb02.ads.tamu.edu>
	<1407506577.95765.YahooMailNeo@web121505.mail.ne1.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8F2E0@mb02.ads.tamu.edu>
Message-ID: <1407670352.94319.YahooMailNeo@web121506.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140810/ef551bb8/attachment.pl>

From gcr at wisdomandwonder.com  Sun Aug 10 20:51:22 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Sun, 10 Aug 2014 13:51:22 -0500
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
Message-ID: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>

Good afternoon,

Today I was working on a practice problem. It was simple, and perhaps
even realistic. It looked like this:

? Get a list of all the data files in a directory
? Load each file into a dataframe
? Merge them into a single data frame

Because all of the columns were the same, the simplest solution in my
mind was to `Reduce' the vector of dataframes with a call to
`merge'. That worked fine, I got what was expected. That is key
actually. It is literally a one-liner, and there will never be index
or scoping errors with it.

Now with that in mind, what is the idiomatic way? Do people usually do
something else because it is /faster/ (by some definition)?

Kind regards,

Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


From jdnewmil at dcn.davis.CA.us  Sun Aug 10 23:22:06 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 10 Aug 2014 14:22:06 -0700
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
Message-ID: <9a56dbd3-1422-4ee5-bc78-c432e9426ae6@email.android.com>

Just load the data frames into a list and give that list to rbind. It is way more efficient to be able to identify how big the final data frame is going to have to be at the beginning and preallocate the result memory than to incrementally allocate larger and larger data frames along the way using Reduce.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 10, 2014 11:51:22 AM PDT, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>Good afternoon,
>
>Today I was working on a practice problem. It was simple, and perhaps
>even realistic. It looked like this:
>
>? Get a list of all the data files in a directory
>? Load each file into a dataframe
>? Merge them into a single data frame
>
>Because all of the columns were the same, the simplest solution in my
>mind was to `Reduce' the vector of dataframes with a call to
>`merge'. That worked fine, I got what was expected. That is key
>actually. It is literally a one-liner, and there will never be index
>or scoping errors with it.
>
>Now with that in mind, what is the idiomatic way? Do people usually do
>something else because it is /faster/ (by some definition)?
>
>Kind regards,
>
>Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
>gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
>?Wisdom begins in wonder.? --Socrates
>((? (x) (x x)) (? (x) (x x)))
>?Life has become immeasurably better since I have been forced to stop
>taking it seriously.? --Thompson
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lists at revelle.net  Sun Aug 10 23:59:35 2014
From: lists at revelle.net (William Revelle)
Date: Sun, 10 Aug 2014 16:59:35 -0500
Subject: [R] simulation data with dichotomous varuables
In-Reply-To: <CABLo8nGMh32m+Ci5sZnQ3DaW_HqinKjZ=j63isWfZheOm7T+6Q@mail.gmail.com>
References: <CABLo8nGMh32m+Ci5sZnQ3DaW_HqinKjZ=j63isWfZheOm7T+6Q@mail.gmail.com>
Message-ID: <794D5617-8DCD-4BBC-9747-C1A03DE25344@revelle.net>

Dear Thanoon,
 You might look at the various item simulation functions in the psych package.

In particular, for your problem:

R1 <- sim.irt(10,1000,a=3,low = -2, high=2)
R2 <-  sim.irt(10,1000,a=3,low = -2, high=2)
R12 <- data.frame(R1$items,R2$items)
#this gives you 20 items, grouped with high correlations within the first 10, and the second 10, no correlation between the first and second sets.
rho <- tetrachoric(R12)$rho  #find the tetrachoric correlation between the items
lowerMat(rho)  #show the correlations
cor.plot(rho,numbers=TRUE)   #show a heat map of the correlations

Bill


On Aug 4, 2014, at 8:08 PM, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> Dear R-users
> i need your help to solve my problem in the code below, i  want to simulate
> two different samples R1 and R2 and each sample has 10 variables and 1000
> observations so i want to simulate a data with high correlation between
> var. in R1 and also in R2 and no correlation between R1 and R2 also i have
> a problem with correlation coefficient between tow dichotomous var. the R-
> program supports just these types of correlation coefficients such as
> pearson, spearman,kendall.
> 
> thanks alot in advance
> 
> Thanoon
> 
> 
> ords <- seq(0,1)
> p <- 10
> N <- 1000
> percent_change <- 0.9
> 
> R1 <- as.data.frame(replicate(p, sample(ords, N, replace = T)))
> R2 <- as.data.frame(replicate(p, sample(ords, N, replace = T)))
> # pearson is more appropriate for dichotomous data
> cor(R1, R2, method = "pearson")
> 
> 
> # subset variable to have a stronger correlation
> 
> 
> v1 <- R1[,1, drop = FALSE]
> v1 <- R2[,1, drop = FALSE]
> # randomly choose which rows to retain
> keep <- sample(as.numeric(rownames(v1)), size = percent_change*nrow(v1))
> change <- as.numeric(rownames(v1)[-keep])
> 
> # randomly choose new values for changing
> new.change <- sample(ords, ((1-percent_change)*N)+1, replace = T)
> 
> # replace values in copy of original column
> v1.samp <- v1
> v1.samp[change,] <- new.change
> 
> # closer correlation
> cor(v1, v1.samp, method = "pearson")
> 
> # set correlated column as one of your other columns
> R1[,2] <- v1.samp
> R2[,2] <- v1.samp
> R1
> R2
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 5 minutes to midnight	   http://www.thebulletin.org


From lists at revelle.net  Mon Aug 11 00:20:22 2014
From: lists at revelle.net (William Revelle)
Date: Sun, 10 Aug 2014 17:20:22 -0500
Subject: [R] Is there a package for EFA with multiple groups?
In-Reply-To: <CANz9Z_KiFYB1oOgW0L6aXC=Sz1ncUPL7+StAiMKehMxzU3CPFA@mail.gmail.com>
References: <CAC_aMJCJnrd-vsgDLjp0E6kS2qSp0EhJtBW01eR3coMBg2E5yQ@mail.gmail.com>
	<CANz9Z_KiFYB1oOgW0L6aXC=Sz1ncUPL7+StAiMKehMxzU3CPFA@mail.gmail.com>
Message-ID: <C777D4B8-EEE2-47FF-A8C8-D3107C54F6DE@revelle.net>

Dear Josh and Elizabeth,

Josh suggested one way of doing it with the psych package.  As of today, the psych package (version psych_1.4.8) , I have included a new function (faBy) that will work with the statsBy function to do EFA for each of multiple groups.

Basically, it just calls the statsBy function to get correlations for each subgroup, and then applies fa to that output.

Thus,

sb <- statsBy(data, group=?grouping variable?,cors=TRUE)
fb <- faBy(sb,nfactors= how ever many you want)

This version is working its way through the CRAN distribution channels, but can be obtained from the personality-project repository at 
http://personality-project.org/r/   (if using a Mac) or http://personality-project.org/r/src/contrib/   if using a PC.
Look for version 1.4.8

Bill



On Jul 28, 2014, at 5:22 AM, Joshua Wiley <jwiley.psych at gmail.com> wrote:

> Hi Elizabeth,
> 
> In confirmatory factor analysis with multiple groups, the reason one needs
> to estimate the models simultaneously is that, typically, one is interested
> in applying constraints (e.g., forcing all or some of the factor loadings
> to be equal across groups).  In exploratory factor analysis, constraints
> are uncommon (they are somewhat un-exploratory).
> 
> I would suggest simply using the psych package and subsetting your data to
> the particular group, as in:
> 
> efa( data = subset(data, Group == "Group1") )
> 
> efa( data = subset(data, Group == "Group2") )
> 
> etc.
> 
> As you noted, lavaan will allow you to test multiple group CFAs, so if/when
> you are ready to see whether the same configural factor structure or any
> other level of invariance holds across your groups, you can use it.
> 
> Sincerely,
> 
> Josh
> 
> 
> 
> 
> On Mon, Jul 28, 2014 at 2:46 PM, Elizabeth Barrett-Cheetham <
> ebarrettcheetham at gmail.com> wrote:
> 
>> Hello R users,
>> 
>> I?m hoping to run an exploratory and confirmatory factor analysis on a
>> psychology survey instrument. The data has been collected from
>> multiple groups, and it?s likely that the data is hierarchical/has 2nd
>> order factors.
>> 
>> It appears that the lavaan package allows me to run a multiple group
>> hierarchical confirmatory factor analysis. Yet, I can?t locate a
>> package that can run the equivalent exploratory analysis.
>> 
>> Could anyone please direct me to an appropriate package?
>> 
>> Many thanks,
>> 
>> Elizabeth
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology
> http://joshuawiley.com/
> Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

William Revelle		           http://personality-project.org/revelle.html
Professor			           http://personality-project.org
Department of Psychology   http://www.wcas.northwestern.edu/psych/
Northwestern University	   http://www.northwestern.edu/
Use R for psychology             http://personality-project.org/r
It is 5 minutes to midnight	   http://www.thebulletin.org


From dwinsemius at comcast.net  Mon Aug 11 00:24:00 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 10 Aug 2014 15:24:00 -0700
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
Message-ID: <EFA73A4C-1E87-49E1-AFAC-3B26018FBD10@comcast.net>


On Aug 10, 2014, at 11:51 AM, Grant Rettke wrote:

> Good afternoon,
> 
> Today I was working on a practice problem. It was simple, and perhaps
> even realistic. It looked like this:
> 
> ? Get a list of all the data files in a directory
> ? Load each file into a dataframe
> ? Merge them into a single data frame

Something along these lines:

all <- do.call( rbind, 
                 lapply( list.files(path=getwd(), pattern=".csv"), 
                         read.csv) )

Possibly:

all <- sapply( list.files(path=getwd(), pattern=".csv"), 
                         read.csv)

Untested since no reproducible example was offered. This skips the task of individually assigning names to the input dataframes. There are quite a few variations on this in the Archives. You should learn to search them. Rseek.org or MarkMail are effective for me.

http://www.rseek.org/

http://markmail.org/search/?q=list%3Aorg.r-project.r-help

> 
> Because all of the columns were the same, the simplest solution in my
> mind was to `Reduce' the vector of dataframes with a call to
> `merge'. That worked fine, I got what was expected. That is key
> actually. It is literally a one-liner, and there will never be index
> or scoping errors with it.

You might have forced `merge` to work with the correct choice of arguments but I would have silently eliminated duplicate rows. Seems unlikely to me that it would be efficient for the purpose of just stacking dataframe values.
> 
> > merge( data.frame(a=1, b=2), data.frame(a=3, b=4) )
[1] a b
<0 rows> (or 0-length row.names)

> merge( data.frame(a=1, b=2), data.frame(a=3, b=4) , all=TRUE)
  a b
1 1 2
2 3 4
> merge( data.frame(a=1, b=2), data.frame(a=1, b=2) )
  a b
1 1 2

> rbind( data.frame(a=1, b=2), data.frame(a=1, b=2) )
  a b
1 1 2
2 1 2

> Now with that in mind, what is the idiomatic way? Do people usually do
> something else because it is /faster/ (by some definition)?
> 
> Kind regards,
> 

-- 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Mon Aug 11 01:07:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 10 Aug 2014 16:07:48 -0700
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <9a56dbd3-1422-4ee5-bc78-c432e9426ae6@email.android.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
	<9a56dbd3-1422-4ee5-bc78-c432e9426ae6@email.android.com>
Message-ID: <37c13300-dc8d-47c2-b58e-fe7b0e680fa4@email.android.com>

Err... sorry... you have to use do.call with base rbind as David illustrates. I am spoiled by rbind.fill from the plyr package. rbind.fill accepts the list directly and also fills in any missing columns with NA, which avoids having to dig through all the files to find any oddballs.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 10, 2014 2:22:06 PM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>Just load the data frames into a list and give that list to rbind. It
>is way more efficient to be able to identify how big the final data
>frame is going to have to be at the beginning and preallocate the
>result memory than to incrementally allocate larger and larger data
>frames along the way using Reduce.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On August 10, 2014 11:51:22 AM PDT, Grant Rettke
><gcr at wisdomandwonder.com> wrote:
>>Good afternoon,
>>
>>Today I was working on a practice problem. It was simple, and perhaps
>>even realistic. It looked like this:
>>
>>? Get a list of all the data files in a directory
>>? Load each file into a dataframe
>>? Merge them into a single data frame
>>
>>Because all of the columns were the same, the simplest solution in my
>>mind was to `Reduce' the vector of dataframes with a call to
>>`merge'. That worked fine, I got what was expected. That is key
>>actually. It is literally a one-liner, and there will never be index
>>or scoping errors with it.
>>
>>Now with that in mind, what is the idiomatic way? Do people usually do
>>something else because it is /faster/ (by some definition)?
>>
>>Kind regards,
>>
>>Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
>>gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
>>?Wisdom begins in wonder.? --Socrates
>>((? (x) (x x)) (? (x) (x x)))
>>?Life has become immeasurably better since I have been forced to stop
>>taking it seriously.? --Thompson
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Mon Aug 11 01:50:14 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 10 Aug 2014 18:50:14 -0500
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
Message-ID: <CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>

On Sun, Aug 10, 2014 at 1:51 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>
> Good afternoon,
>
> Today I was working on a practice problem. It was simple, and perhaps
> even realistic. It looked like this:
>
> ? Get a list of all the data files in a directory


OK, I assume this results in a vector of file names in a variable,
like you'd get from list.files();

>
> ? Load each file into a dataframe


Why? Do you need them in separate data frames?

>
> ? Merge them into a single data frame

The meat of the question. If you don't need the files in separate data
frames, and the files do _NOT_ have headers, then I would just load
them all into a single frame. I used Linux and so my solution may not
work on Windows. Something like:

list_of_files = list.files(pattern=".*data$"); # list of data files
#
# command to list contents of all files to stdout:
command <- pipe(paste('cat',list_of_files));
read.table(command,header=FALSE);

I would guess that Windows has something equivalent to cat, is it
"type"? I have a vague memory of that.

The above will work with header=TRUE, but the headers in the second
and subsequent files are taken as data. And if you have row.names in
the data, such as write.csv() does, then this is really not for you.
Well, at least it would not be as simple. There are ways around it
using a more intelligent "copy" program than "cat". Such as AWK. If
you need an AWK example, I can fake one up. It would strip the headers
from the 2nd and subsequent files and remove the first column
"row.names" values. Not really all that difficult, but "fiddly".

>
> Because all of the columns were the same, the simplest solution in my
> mind was to `Reduce' the vector of dataframes with a call to
> `merge'. That worked fine, I got what was expected. That is key
> actually. It is literally a one-liner, and there will never be index
> or scoping errors with it.
>
> Now with that in mind, what is the idiomatic way? Do people usually do
> something else because it is /faster/ (by some definition)?
>
> Kind regards,
>
>


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From john.archie.mckown at gmail.com  Mon Aug 11 03:34:12 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 10 Aug 2014 20:34:12 -0500
Subject: [R] Just stumbled across this: Advanced R programming text & code -
	from Hadley
Message-ID: <CAAJSdjg2Gddw6Z-tvS1TLU_UX-hMMY+bRWku6amH2U9rx3-Z7w@mail.gmail.com>

Well, it says that it's from Hadley Wickham.

https://github.com/hadley/adv-r
<quote>

This is code and text behind the Advanced R programming book.

The site is built using jekyll, with a custom plugin to render .rmd
files with knitr and pandoc. To create the site, you need:

jekyll and s3_websiter gems: gem install jekyll s3_website
pandoc
knitr: install.packages("knitr")

</quote>

This contains a Rstudio project file. I know because I've done a git
clone on it and loaded it into Rstudio, on Linux. If you don't have
git, there is a "download zip" option on the site too.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From michimaurin at hotmail.com  Mon Aug 11 04:08:37 2014
From: michimaurin at hotmail.com (michelle maurin)
Date: Sun, 10 Aug 2014 22:08:37 -0400
Subject: [R] Problem with assignment 1 part 1
Message-ID: <BAY169-W975DF7085B55724652F98BA5ED0@phx.gbl>

I think my code is very close I can seem to be able to debug it Might be something very simple I know the problem is on the last 3 lines of code can you please help?
Thanks 
Michelle  		 	   		  

From hasan.diwan at gmail.com  Mon Aug 11 05:02:31 2014
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Sun, 10 Aug 2014 20:02:31 -0700
Subject: [R] Problem with assignment 1 part 1
In-Reply-To: <BAY169-W975DF7085B55724652F98BA5ED0@phx.gbl>
References: <BAY169-W975DF7085B55724652F98BA5ED0@phx.gbl>
Message-ID: <CAP+bYWA3NWAREoZ64yyb0A3CG5zAS_Mg552ptU1wHvWTu-a4qg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140810/fea8c89f/attachment.pl>

From john.archie.mckown at gmail.com  Mon Aug 11 05:06:38 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 10 Aug 2014 22:06:38 -0500
Subject: [R] Problem with assignment 1 part 1
In-Reply-To: <BAY169-W975DF7085B55724652F98BA5ED0@phx.gbl>
References: <BAY169-W975DF7085B55724652F98BA5ED0@phx.gbl>
Message-ID: <CAAJSdjh+rdHLs=TndHM0S6o4VX7YEt8v94ZxCHNjuyJ1Y3_7Tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140810/82042884/attachment.pl>

From statistics84 at hotmail.com  Mon Aug 11 10:17:11 2014
From: statistics84 at hotmail.com (pari hesabi)
Date: Mon, 11 Aug 2014 08:17:11 +0000
Subject: [R] C.D.F
Message-ID: <DUB125-W352497DED0595A92B57C7AC6ED0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/26e4dae0/attachment.pl>

From dim.plamen at gmail.com  Mon Aug 11 10:05:06 2014
From: dim.plamen at gmail.com (Plamen Dimitrov)
Date: Mon, 11 Aug 2014 10:05:06 +0200
Subject: [R] GSoC 2014 - an R package for working with RRD files
Message-ID: <CA+HXsfZ844yrc_vLshEpw_WYSzE2GSS4eAyrppWmcpBodRW5Rw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/707d6536/attachment.pl>

From rhelpmaillist at 163.com  Mon Aug 11 10:24:22 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 11 Aug 2014 16:24:22 +0800 (CST)
Subject: [R]  Need help in using Rcpp
Message-ID: <7021a75b.a127.147c42b1023.Coremail.rhelpmaillist@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/77068417/attachment.pl>

From rhelpmaillist at 163.com  Mon Aug 11 05:22:36 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 11 Aug 2014 11:22:36 +0800 (CST)
Subject: [R] loops with assign() and get()
In-Reply-To: <CAF8bMcYbkxQwAxJ40kN01jaGfJMLnUcg9Q6ZtfDtQsWbgeP5DQ@mail.gmail.com>
References: <CAB5eD-jOxEmGG2YxrGy33Hkp8+r=doH+p5eV6j+=vQF8LEG+RA@mail.gmail.com>
	<CAF8bMcYbkxQwAxJ40kN01jaGfJMLnUcg9Q6ZtfDtQsWbgeP5DQ@mail.gmail.com>
Message-ID: <41b89990.4e26.147c316cb5f.Coremail.rhelpmaillist@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/f0dd7aa4/attachment.pl>

From Matthias.Kohl at stamats.de  Mon Aug 11 11:13:13 2014
From: Matthias.Kohl at stamats.de (Prof. Dr. Matthias Kohl)
Date: Mon, 11 Aug 2014 11:13:13 +0200
Subject: [R] C.D.F
In-Reply-To: <DUB125-W352497DED0595A92B57C7AC6ED0@phx.gbl>
References: <DUB125-W352497DED0595A92B57C7AC6ED0@phx.gbl>
Message-ID: <53E88929.3090904@stamats.de>

Dear Diba,

you could try package distr; eg.

library(distr)
G1 <- Gammad(scale = 0.7, shape = 0.5)
G2 <- Gammad(scale = 2.1, shape = 1.7)
G3 <- G1+G2 # convolution
G3

For the convolution exact formulas are applied if available, otherwise 
we use FFT; see also http://www.jstatsoft.org/v59/i04/ (will appear 
soon) resp. a previous version at http://arxiv.org/abs/1006.0764

hth
Matthias

Am 11.08.2014 um 10:17 schrieb pari hesabi:
> Hello everybody,
>
> Can anybody help me to write a program for the CDF of sum of two independent gamma random  variables ( covolution of two gamma distributions)  with different amounts of parameters( the shape parameters are the same)?
>
> Thank you
>
> Diba
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Prof. Dr. Matthias Kohl
www.stamats.de


From r.turner at auckland.ac.nz  Mon Aug 11 12:11:05 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 11 Aug 2014 22:11:05 +1200
Subject: [R] C.D.F
In-Reply-To: <DUB125-W352497DED0595A92B57C7AC6ED0@phx.gbl>
References: <DUB125-W352497DED0595A92B57C7AC6ED0@phx.gbl>
Message-ID: <53E896B9.7080705@auckland.ac.nz>

On 11/08/14 20:17, pari hesabi wrote:
> Hello everybody,
>
> Can anybody help me to write a program for the CDF of sum of two
> independent gamma random  variables ( covolution of two gamma
> distributions)  with different amounts of parameters( the shape
> parameters are the same)?
>

Is this homework?  The list has a no homework policy.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From h.wickham at gmail.com  Mon Aug 11 14:38:09 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 11 Aug 2014 08:38:09 -0400
Subject: [R] Just stumbled across this: Advanced R programming text &
 code - from Hadley
In-Reply-To: <CAAJSdjg2Gddw6Z-tvS1TLU_UX-hMMY+bRWku6amH2U9rx3-Z7w@mail.gmail.com>
References: <CAAJSdjg2Gddw6Z-tvS1TLU_UX-hMMY+bRWku6amH2U9rx3-Z7w@mail.gmail.com>
Message-ID: <CABdHhvGfLWqg7j-hFe6rOizk2Zs+2SMedgTBBhnQG_+JuHu_aw@mail.gmail.com>

Or just go to http://adv-r.had.co.nz/ ...

Hadley

On Sun, Aug 10, 2014 at 9:34 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> Well, it says that it's from Hadley Wickham.
>
> https://github.com/hadley/adv-r
> <quote>
>
> This is code and text behind the Advanced R programming book.
>
> The site is built using jekyll, with a custom plugin to render .rmd
> files with knitr and pandoc. To create the site, you need:
>
> jekyll and s3_websiter gems: gem install jekyll s3_website
> pandoc
> knitr: install.packages("knitr")
>
> </quote>
>
> This contains a Rstudio project file. I know because I've done a git
> clone on it and loaded it into Rstudio, on Linux. If you don't have
> git, there is a "download zip" option on the site too.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From mmalten at gmail.com  Mon Aug 11 15:02:53 2014
From: mmalten at gmail.com (Mitchell Maltenfort)
Date: Mon, 11 Aug 2014 09:02:53 -0400
Subject: [R] Just stumbled across this: Advanced R programming text &
 code - from Hadley
In-Reply-To: <CABdHhvGfLWqg7j-hFe6rOizk2Zs+2SMedgTBBhnQG_+JuHu_aw@mail.gmail.com>
References: <CAAJSdjg2Gddw6Z-tvS1TLU_UX-hMMY+bRWku6amH2U9rx3-Z7w@mail.gmail.com>
	<CABdHhvGfLWqg7j-hFe6rOizk2Zs+2SMedgTBBhnQG_+JuHu_aw@mail.gmail.com>
Message-ID: <CANOgrHbcQLLFzC76V6f2xLMrK9xE-_v_O7obPNBrubC3y5Ehkw@mail.gmail.com>

Ah, what do you know anyway? -- as the book critic said to the author.
____________________________
Ersatzistician and Chutzpahthologist

I can answer any question.  "I don't know" is an answer. "I don't know
yet" is a better answer.

"I can write better than anybody who can write faster, and I can write
faster than anybody who can write better" AJ Leibling


On Mon, Aug 11, 2014 at 8:38 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> Or just go to http://adv-r.had.co.nz/ ...
>
> Hadley
>
> On Sun, Aug 10, 2014 at 9:34 PM, John McKown
> <john.archie.mckown at gmail.com> wrote:
>> Well, it says that it's from Hadley Wickham.
>>
>> https://github.com/hadley/adv-r
>> <quote>
>>
>> This is code and text behind the Advanced R programming book.
>>
>> The site is built using jekyll, with a custom plugin to render .rmd
>> files with knitr and pandoc. To create the site, you need:
>>
>> jekyll and s3_websiter gems: gem install jekyll s3_website
>> pandoc
>> knitr: install.packages("knitr")
>>
>> </quote>
>>
>> This contains a Rstudio project file. I know because I've done a git
>> clone on it and loaded it into Rstudio, on Linux. If you don't have
>> git, there is a "download zip" option on the site too.
>>
>> --
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>>
>> Maranatha! <><
>> John McKown
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jamilnaser79 at gmail.com  Mon Aug 11 11:06:08 2014
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Mon, 11 Aug 2014 10:06:08 +0100
Subject: [R] Superimposing graphs
Message-ID: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/2388f7f7/attachment.pl>

From trichter at uni-bremen.de  Mon Aug 11 13:05:16 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Mon, 11 Aug 2014 13:05:16 +0200
Subject: [R] [vegan]Envfit, pvalues and ggplot2
Message-ID: <53E8A36C.1060502@uni-bremen.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/02029ca2/attachment.pl>

From t.s.farewell at cranfield.ac.uk  Mon Aug 11 15:06:21 2014
From: t.s.farewell at cranfield.ac.uk (Farewell, Timothy)
Date: Mon, 11 Aug 2014 13:06:21 +0000
Subject: [R] building a BIGLM model from three tables (related)
Message-ID: <33E070D19A459341A57BEB886721E6EC57B093F8@CCEXCHMBX-3.central.cranfield.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/3abbf6af/attachment.pl>

From rmh at temple.edu  Mon Aug 11 16:22:59 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 11 Aug 2014 10:22:59 -0400
Subject: [R] Superimposing graphs
In-Reply-To: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
References: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
Message-ID: <CAGx1TMD1fOnzhe99==A-qQu5_4dDtn78BoXQLMGO7Pw3F_EXUw@mail.gmail.com>

I think this is what you are looking for.

library(latticeExtra)
t.tmp <-seq(0,30, .01)
P1 + layer(panel.xyplot(y=f1(0.5,0.5,0.06, t.tmp), x=t.tmp, type="l",
col="black"))

Notice that t is a very bad name for your variable as it is the name
of a function.
I used t.tmp instead.

Rich


On Mon, Aug 11, 2014 at 5:06 AM, Naser Jamil <jamilnaser79 at gmail.com> wrote:
> Dear R-user,
> May I seek your help to sort out a little problem. I have the following
> codes
> to draw two graphs. I want to superimpose the second one on each of the
> first one.
>
> ########################################
>
> library(nlme)
> subject<-c(1,1,1,2,2,2,3,3,3)
> time<-c(0.0,5.4,21.0,0.0,5.4,21.0,0.0,5.4,21.0)
> con.cohort<-c(1.10971703,0.54535512,0.07176724,0.75912539,0.47825282,
> 0.10593292,1.20808375,0.47638394,0.02808967)
>
> data.d=data.frame(subject=subject,time=time,conc=con.cohort)
> grouped.data<-groupedData(formula=conc~time | subject, data =data.d)
>
> plot(grouped.data)
>
> ##########################################
>
> f1<-function(x,v,cl,t) {
> (x/v)*exp(-(cl/v)*t)
>                               }
> t<-seq(0,30, .01)
> plot(t,f1(0.5,0.5,0.06,t),type="l",pch=18, ylim=c(), xlab="time",
> ylab="conc")
>
>
> ###########################################
>
> Any suggestion will really be helpful.
>
>
> Regards,
>
> Jamil.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Mon Aug 11 16:46:51 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 11 Aug 2014 09:46:51 -0500
Subject: [R] Problem with assignment 1 part 1
In-Reply-To: <BAY169-W7001C142FDE98DBCEC1486A5ED0@phx.gbl>
References: <BAY169-W975DF7085B55724652F98BA5ED0@phx.gbl>
	<CAAJSdjh+rdHLs=TndHM0S6o4VX7YEt8v94ZxCHNjuyJ1Y3_7Tw@mail.gmail.com>
	<BAY169-W7001C142FDE98DBCEC1486A5ED0@phx.gbl>
Message-ID: <CAAJSdji0pWFY0k9efrSqETgSPcaVxCmZjo_bG5LH33YDNZE01A@mail.gmail.com>

On Mon, Aug 11, 2014 at 9:00 AM, michelle maurin
<michimaurin at hotmail.com> wrote:
> see code below
>
>
> pollutantmean <- function(directory, pollutant, id = 1:332) {
>   files_list <- list.files(directory, full.names=TRUE) #creates a list of
> files
>   dat <- data.frame()#creates an empty data frame
>   for (i in 1:332) {
>   dat <- rbind(dat, read.csv(files_list[i]))#loops through the files,
> rbinding them together
>   }
>
> #subsets the rows that match the 'pollutant' argument
>   median(dat_subset$pollutant, na.rm=TRUE) #identifies the median of the
> subset
> }
>
>
>
> ##I highlighted the area that I think has the problem , I helped my self
> using the tutorial found on the forum ,for assignment 1

I really think your not where you believe you are. This is an email
list for general questions on the R language. I am not aware of an
"the tutorial found on the forum". But I do think that I have an idea
of what your problem is. Basically you want to find all the rows in
"dat" which have a pollutant (dat$pollutant) of either "sulfate" or
"nitrate". The which() function isn't going to do that for you. The
which() function takes a logical vector of TRUE and FALSE values. It
return an integer vector which has the index values of the TRUE
entries. For example:
> which(c(TRUE,FALSE,FALSE,TRUE,FALSE,TRUE))
[1] 1 4 6
I realise how this can be thought of as how to do this. And if could
work, but is unnecessary in this case. But the real problem is the
segment:
dat["suflate","nitrate"] == pollutant

If you would try this (I can't because I don't have the data files),
you would see that this is not asking the right question. You want to
see if dat$pollutant is either "suflate" or "nitrate". Or, expanding a
bit you want to ask: 'is dat$pollutant equal to "suflate"? If not, is
it equal to 'nitrate"?'. The answer to this question will be the
proper logical vector that you can either use in the which() function,
or directly as a row selector. The hint on how to ask this question is
to use the ifelse() function properly.

So your line (with the critical method of the proper use of ifelse)
should look something like:

dat_subset <- dat[which(ifelse(????),];
#or, equivalently
dat_subset <- dat[ifelse(???),];

This latter is valid because the R language will accept a logical
vector as a "selector" and only return the data where the logical
value is TRUE.

I am deliberately leaving the challenge of how to use the ifelse() for
you. Remember, from the documentation, that the form of the ifelse()
is: ifelse(condition,result-if-condition-true,result-if-condition-false.)

Hopefully this is a sufficient clew to get you going.

I won't comment on the rest of the code because I don't know the
problem. Or what "forum" you're talking about.

>
>  Best regards
>
>
>
> Michelle
>
>
>
> ________________________________
> Date: Sun, 10 Aug 2014 22:06:38 -0500
> Subject: Re: [R] Problem with assignment 1 part 1
> From: john.archie.mckown at gmail.com
> To: michimaurin at hotmail.com
> CC: r-help at r-project.org
>
> What code.
>
> Also, the forum has a "no homework" policy. Your subject implies this is
> homework, so you might not get any answers. You might get a hint or two
> though.
>
> On Aug 10, 2014 10:00 PM, "michelle maurin" <michimaurin at hotmail.com> wrote:
>
> I think my code is very close I can seem to be able to debug it Might be
> something very simple I know the problem is on the last 3 lines of code can
> you please help?
> Thanks
> Michelle
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From rhelpmaillist at 163.com  Mon Aug 11 17:26:11 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 11 Aug 2014 23:26:11 +0800 (CST)
Subject: [R] Just stumbled across this: Advanced R programming text &
 code - from Hadley
In-Reply-To: <CANOgrHbcQLLFzC76V6f2xLMrK9xE-_v_O7obPNBrubC3y5Ehkw@mail.gmail.com>
References: <CAAJSdjg2Gddw6Z-tvS1TLU_UX-hMMY+bRWku6amH2U9rx3-Z7w@mail.gmail.com>
	<CABdHhvGfLWqg7j-hFe6rOizk2Zs+2SMedgTBBhnQG_+JuHu_aw@mail.gmail.com>
	<CANOgrHbcQLLFzC76V6f2xLMrK9xE-_v_O7obPNBrubC3y5Ehkw@mail.gmail.com>
Message-ID: <2c3e6b13.e75a.147c5ad3f20.Coremail.rhelpmaillist@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/3a3e671c/attachment.pl>

From rmh at temple.edu  Mon Aug 11 17:41:04 2014
From: rmh at temple.edu (Rmh)
Date: Mon, 11 Aug 2014 11:41:04 -0400
Subject: [R] Superimposing graphs
In-Reply-To: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
References: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
Message-ID: <F8658678-860B-44F0-A1C1-D83A191D3011@temple.edu>

whoops

P1<- plot(grouped.data)

Sent from my iPhone

> On Aug 11, 2014, at 5:06, Naser Jamil <jamilnaser79 at gmail.com> wrote:
> 
> Dear R-user,
> May I seek your help to sort out a little problem. I have the following
> codes
> to draw two graphs. I want to superimpose the second one on each of the
> first one.
> 
> ########################################
> 
> library(nlme)
> subject<-c(1,1,1,2,2,2,3,3,3)
> time<-c(0.0,5.4,21.0,0.0,5.4,21.0,0.0,5.4,21.0)
> con.cohort<-c(1.10971703,0.54535512,0.07176724,0.75912539,0.47825282,
> 0.10593292,1.20808375,0.47638394,0.02808967)
> 
> data.d=data.frame(subject=subject,time=time,conc=con.cohort)
> grouped.data<-groupedData(formula=conc~time | subject, data =data.d)
> 
> plot(grouped.data)
> 
> ##########################################
> 
> f1<-function(x,v,cl,t) {
> (x/v)*exp(-(cl/v)*t)
>                              }
> t<-seq(0,30, .01)
> plot(t,f1(0.5,0.5,0.06,t),type="l",pch=18, ylim=c(), xlab="time",
> ylab="conc")
> 
> 
> ###########################################
> 
> Any suggestion will really be helpful.
> 
> 
> Regards,
> 
> Jamil.
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Aug 11 18:04:46 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Aug 2014 09:04:46 -0700
Subject: [R] loops with assign() and get()
In-Reply-To: <41b89990.4e26.147c316cb5f.Coremail.rhelpmaillist@163.com>
References: <CAB5eD-jOxEmGG2YxrGy33Hkp8+r=doH+p5eV6j+=vQF8LEG+RA@mail.gmail.com>
	<CAF8bMcYbkxQwAxJ40kN01jaGfJMLnUcg9Q6ZtfDtQsWbgeP5DQ@mail.gmail.com>
	<41b89990.4e26.147c316cb5f.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMca0Lu4kzqwhsZPA-=k9hPy3naFj9C1=ZhruhcejYrY7BQ@mail.gmail.com>

That code will not work.  get() and assign() are troublesome for a
variety of reasons.  E.g.,

* adding made-up names to the current environment is dangerous.  They
may clobber fixed names in the environment.  You may be confused about
what the current environment is (especially when refactoring code).
You can avoid this by using dataEnv <- new.env() to make an
environment for your related objects and using the envir=dataEnv
argument to get() and assign() to put the objects in there.  However,
once you go this route, you may as well use the syntax dataEnv[[name]]
to refer to your objects instead of get(name, envir=dataEnv) and
assign(name, value, envir=dataEnv).

* replacement syntax like
    names(get(someName)) <- c("One", "Two")
will not work.  You have to use kludgy code like
    tmp <- get(someName)
    names(tmp) <- c("One", "Two")
    assign(someName, tmp)
If you use the dataEnv[[name]] syntax then you can use the more normal looking
    names(dataEnv[[name]]) <- c("One", "Two")

By the way, I do not think your suggested code will work - you call
assign() before making a bunch of changes to dfi instead of after
making the changes.
I have not measured the memory implications of your method vs. using
lapply on lists, but I don't think there is much of a difference in
this case.  (There can be a big difference when you are replacing the
inputs by the outputs.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Aug 10, 2014 at 8:22 PM, PO SU <rhelpmaillist at 163.com> wrote:
>
> It's a great method, but there is  a memory problem, DFS would occupy a
> large memory. So from this point of view, i prefer the loop.
>
>>> for (i in 1 : nrow(unique)){
>>> tmp=get(past0("DF",i))[1,]
>>> assign(paste0("df",i),tmp)
>>> dfi=dfi[,1:3]
>>> names(dfi)=names(tmp[c(1,4,5)])
>>> dfi=rbind(dfi,tmp[c(1,4,5)])
>>> names(dfi)=c("UID","Date","Location")
>>>}
>
> NB: The code above  without any test!
>
>
>
> --
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
> At 2014-08-10 06:32:38, "William Dunlap" <wdunlap at tibco.com> wrote:
>>> I was able to create 102 distinct dataframes (DFs1, DFs2, DFs3, etc)
>>> using
>>> the assign() in a loop.
>>
>>The first step to making things easier to do is to put those data.frames
>>into a list.  I'll call it DFS and your data.frames will now be DFs[[1]],
>>DFs[[2]], ..., DFs[[length(DFs)]].
>>    DFs <- lapply(paste0("DFs", 1:102), get)
>>In the future, I think it would be easier if you skipped the 'assign()'
>>and just put the data into a list from the start.
>>
>>Now use lapply to process that list, creating a new list called 'df', where
>>df[[i]] is the result of processing DFs[[i]]:
>>
>>df <- lapply(DFs, FUN=function(DFsi) {
>>                      # your code from the for loop you supplied
>>                      dfi=DFsi[1,]
>>                      dfi=dfi[,1:3]
>>                      names(dfi)=names(DFsi[c(1,4,5)])
>>                      dfi=rbind(dfi,DFsi[c(1,4,5)])
>>                      names(dfi)=c("UID","Date","Location")
>>                      dfi # return this to put in list that lapply is
>> making
>>                  })
>>
>>(You didn't supply sample data so I did not run this - there may be typos.)
>>
>>Bill Dunlap
>>TIBCO Software
>>wdunlap tibco.com
>>
>>
>>On Sat, Aug 9, 2014 at 1:39 PM, Laura Villegas Ortiz <lvilleg at ncsu.edu>
>> wrote:
>>> Dear all,
>>>
>>> I was able to create 102 distinct dataframes (DFs1, DFs2, DFs3, etc)
>>> using
>>> the assign() in a loop.
>>>
>>> Now, I would like to perform the following transformation for each one of
>>> these dataframes:
>>>
>>> df1=DFs1[1,]
>>> df1=df1[,1:3]
>>> names(df1)=names(DFs1[c(1,4,5)])
>>> df1=rbind(df1,DFs1[c(1,4,5)])
>>> names(df1)=c("UID","Date","Location")
>>>
>>> something like this:
>>>
>>> for (i in 1 : nrow(unique)){
>>>
>>> dfi=DFsi[1,]
>>> dfi=dfi[,1:3]
>>> names(dfi)=names(DFsi[c(1,4,5)])
>>> dfi=rbind(dfi,DFsi[c(1,4,5)])
>>> names(dfi)=c("UID","Date","Location")
>>>
>>> }
>>>
>>> I thought it could be straightforward but has proven the opposite
>>>
>>> Many thanks
>>>
>>> Laura
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>
>


From 538280 at gmail.com  Mon Aug 11 18:04:58 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 11 Aug 2014 10:04:58 -0600
Subject: [R] how to process multiple data files using R loop
In-Reply-To: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
References: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
Message-ID: <CAFEqCdwW-PtodZjbUETmFMbK+ww0+FGoD2SaZkWy2HY6=M5fjQ@mail.gmail.com>

In addition to the solution and comments that you have already
received, here are a couple of additional comments:

This is a variant on FAQ 7.21, if you had found that FAQ then it would
have told you about the get function.

The most important part of the answer in FAQ 7.21 is the last part
where it says that it is better to use a list.  If all the objects of
interest are related and you want to do the same or similar things to
each one, then having them all stored in a single list can simplify
things for the future.  You can collect all the objects into a single
list using the mget command, e.g.:

P_objects <- mget( ls(pattern='P_'))

Now that they are in a list you can do the equivalent of your loop,
but simpler with the lapply function, e.g.:

lapply( P_objects, head, 2 )

And if you want to do other things with all these objects, such as
save them, plot them, do a regression analysis on them, delete them,
etc. then you can do that using lapply/sapply as well in a simpler way
than looping.


On Fri, Aug 8, 2014 at 12:25 PM, Fix Ace <acefix at rocketmail.com> wrote:
> I have 16 files and would like to check the information of their first two lines, what I did:
>
>
>> ls(pattern="P_")
>  [1] "P_3_utr_source_data"               "P_5_utr_source_data"
>  [3] "P_exon_per_gene_cds_source_data"   "P_exon_per_gene_source_data"
>  [5] "P_exon_source_data"                "P_first_exon_oncds_source_data"
>  [7] "P_first_intron_oncds_source_data"  "P_first_intron_ongene_source_data"
>  [9] "P_firt_exon_ongene_source_data"    "P_gene_cds_source_data"
> [11] "P_gene_source_data"                "P_intron_source_data"
> [13] "P_last_exon_oncds_source_data"     "P_last_exon_ongene_source_data"
> [15] "P_last_intron_oncds_source_data"   "P_last_intron_ongene_source_data"
>
>
>
>>for(i in ls(pattern="P_")){head(i, 2)}
>
> It obviously does not work since nothing came out
>
> What I would like to see for the output is :
>
>> head(P_3_utr_source_data,2)
>   V1
> 1  1
> 2  1
>> head(P_5_utr_source_data,2)
>   V1
> 1  1
> 2  1
>>
> .
>
> .
> .
>
>
>
> Could anybody help me with this?
>
> Thank you very much for your time:)
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From jszhao at yeah.net  Mon Aug 11 23:40:05 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 11 Aug 2014 14:40:05 -0700
Subject: [R] efficient way to replace a range of numeric with a integer in a
	matrix
Message-ID: <53E93835.7030908@yeah.net>

Hi there,

I hope to replace a range of numeric in a matrix with a integer. For 
example, in the following matrix, I want to use 1 to replace the 
elements range from 0.0 to 1.0, and all larger than 1. with 2.

 > (m <- matrix(runif(16, 0, 2), nrow = 4))
           [,1]       [,2]      [,3]     [,4]
[1,] 0.7115088 0.55370418 0.1586146 1.882931
[2,] 0.9068198 0.38081423 0.9172629 1.713592
[3,] 1.5210150 0.93900649 1.2609942 1.744456
[4,] 0.3779058 0.03130103 0.1893477 1.601181

so I want to get something like:

      [,1] [,2] [,3] [,4]
[1,]    1    1    1    2
[2,]    1    1    1    2
[3,]    2    1    2    2
[4,]    1    1    1    2

I wrote a function to do such thing:

fun <- function(x) {
     if (is.na(x)) {
         NA
     } else if (x > 0.0 && x <= 1.0) {
         1
     } else if (x > 1.0) {
         2
     } else {
         x
     }
}

Then run it as:

 > apply(m,2,function(i) sapply(i, fun))

However, it seems that this method is not efficient when the dimension 
is large, e.g., 5000x5000 matrix.

Any suggestions? Thanks in advance!

Best regards,
Jinsong


From rmh at temple.edu  Mon Aug 11 23:43:49 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Mon, 11 Aug 2014 17:43:49 -0400
Subject: [R] efficient way to replace a range of numeric with a integer
 in a matrix
In-Reply-To: <53E93835.7030908@yeah.net>
References: <53E93835.7030908@yeah.net>
Message-ID: <CAGx1TMB3ZXdPwRe34b=19+kE4qN_Qxjv=NfU1wGiEPqx2S-+9Q@mail.gmail.com>

(m>1)+1

On Mon, Aug 11, 2014 at 5:40 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I hope to replace a range of numeric in a matrix with a integer. For
> example, in the following matrix, I want to use 1 to replace the elements
> range from 0.0 to 1.0, and all larger than 1. with 2.
>
>> (m <- matrix(runif(16, 0, 2), nrow = 4))
>           [,1]       [,2]      [,3]     [,4]
> [1,] 0.7115088 0.55370418 0.1586146 1.882931
> [2,] 0.9068198 0.38081423 0.9172629 1.713592
> [3,] 1.5210150 0.93900649 1.2609942 1.744456
> [4,] 0.3779058 0.03130103 0.1893477 1.601181
>
> so I want to get something like:
>
>      [,1] [,2] [,3] [,4]
> [1,]    1    1    1    2
> [2,]    1    1    1    2
> [3,]    2    1    2    2
> [4,]    1    1    1    2
>
> I wrote a function to do such thing:
>
> fun <- function(x) {
>     if (is.na(x)) {
>         NA
>     } else if (x > 0.0 && x <= 1.0) {
>         1
>     } else if (x > 1.0) {
>         2
>     } else {
>         x
>     }
> }
>
> Then run it as:
>
>> apply(m,2,function(i) sapply(i, fun))
>
> However, it seems that this method is not efficient when the dimension is
> large, e.g., 5000x5000 matrix.
>
> Any suggestions? Thanks in advance!
>
> Best regards,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Aug 11 23:50:05 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Aug 2014 14:50:05 -0700
Subject: [R] efficient way to replace a range of numeric with a integer
 in a matrix
In-Reply-To: <53E93835.7030908@yeah.net>
References: <53E93835.7030908@yeah.net>
Message-ID: <CAF8bMcZ2B5n-dWtvk00sEFxfOJ8GfNn_c4n=v5P+=1oMdkaVng@mail.gmail.com>

You can use
    m[m > 0 & m <= 1.0] <- 1
    m[m > 1 ] <- 2
or, if you have lots of intervals, something based on findInterval().  E.g.,
    m[] <- findInterval(m, c(-Inf, 0, 1, Inf)) - 1

(What do you want to do with non-positive numbers?)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 11, 2014 at 2:40 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I hope to replace a range of numeric in a matrix with a integer. For
> example, in the following matrix, I want to use 1 to replace the elements
> range from 0.0 to 1.0, and all larger than 1. with 2.
>
>> (m <- matrix(runif(16, 0, 2), nrow = 4))
>           [,1]       [,2]      [,3]     [,4]
> [1,] 0.7115088 0.55370418 0.1586146 1.882931
> [2,] 0.9068198 0.38081423 0.9172629 1.713592
> [3,] 1.5210150 0.93900649 1.2609942 1.744456
> [4,] 0.3779058 0.03130103 0.1893477 1.601181
>
> so I want to get something like:
>
>      [,1] [,2] [,3] [,4]
> [1,]    1    1    1    2
> [2,]    1    1    1    2
> [3,]    2    1    2    2
> [4,]    1    1    1    2
>
> I wrote a function to do such thing:
>
> fun <- function(x) {
>     if (is.na(x)) {
>         NA
>     } else if (x > 0.0 && x <= 1.0) {
>         1
>     } else if (x > 1.0) {
>         2
>     } else {
>         x
>     }
> }
>
> Then run it as:
>
>> apply(m,2,function(i) sapply(i, fun))
>
> However, it seems that this method is not efficient when the dimension is
> large, e.g., 5000x5000 matrix.
>
> Any suggestions? Thanks in advance!
>
> Best regards,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jszhao at yeah.net  Tue Aug 12 00:27:36 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 11 Aug 2014 15:27:36 -0700
Subject: [R] efficient way to replace a range of numeric with a integer
 in a matrix
In-Reply-To: <CAF8bMcZ2B5n-dWtvk00sEFxfOJ8GfNn_c4n=v5P+=1oMdkaVng@mail.gmail.com>
References: <53E93835.7030908@yeah.net>
	<CAF8bMcZ2B5n-dWtvk00sEFxfOJ8GfNn_c4n=v5P+=1oMdkaVng@mail.gmail.com>
Message-ID: <53E94358.4050505@yeah.net>

On 2014/8/11 14:50, William Dunlap wrote:
> You can use
>      m[m > 0 & m <= 1.0] <- 1
>      m[m > 1 ] <- 2
> or, if you have lots of intervals, something based on findInterval().  E.g.,
>      m[] <- findInterval(m, c(-Inf, 0, 1, Inf)) - 1
>
> (What do you want to do with non-positive numbers?)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com

Thank you very much.

I think findInterval() is what I want.

Regards,
Jinsong

>
>
> On Mon, Aug 11, 2014 at 2:40 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
>> Hi there,
>>
>> I hope to replace a range of numeric in a matrix with a integer. For
>> example, in the following matrix, I want to use 1 to replace the elements
>> range from 0.0 to 1.0, and all larger than 1. with 2.
>>
>>> (m <- matrix(runif(16, 0, 2), nrow = 4))
>>            [,1]       [,2]      [,3]     [,4]
>> [1,] 0.7115088 0.55370418 0.1586146 1.882931
>> [2,] 0.9068198 0.38081423 0.9172629 1.713592
>> [3,] 1.5210150 0.93900649 1.2609942 1.744456
>> [4,] 0.3779058 0.03130103 0.1893477 1.601181
>>
>> so I want to get something like:
>>
>>       [,1] [,2] [,3] [,4]
>> [1,]    1    1    1    2
>> [2,]    1    1    1    2
>> [3,]    2    1    2    2
>> [4,]    1    1    1    2
>>
>> I wrote a function to do such thing:
>>
>> fun <- function(x) {
>>      if (is.na(x)) {
>>          NA
>>      } else if (x > 0.0 && x <= 1.0) {
>>          1
>>      } else if (x > 1.0) {
>>          2
>>      } else {
>>          x
>>      }
>> }
>>
>> Then run it as:
>>
>>> apply(m,2,function(i) sapply(i, fun))
>>
>> However, it seems that this method is not efficient when the dimension is
>> large, e.g., 5000x5000 matrix.
>>
>> Any suggestions? Thanks in advance!
>>
>> Best regards,
>> Jinsong
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Tue Aug 12 01:49:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 11 Aug 2014 16:49:33 -0700
Subject: [R] efficient way to replace a range of numeric with a integer
	in a matrix
In-Reply-To: <53E94358.4050505@yeah.net>
References: <53E93835.7030908@yeah.net>
	<CAF8bMcZ2B5n-dWtvk00sEFxfOJ8GfNn_c4n=v5P+=1oMdkaVng@mail.gmail.com>
	<53E94358.4050505@yeah.net>
Message-ID: <5889E22D-82A8-4D4E-953D-43E5105C72AC@comcast.net>


On Aug 11, 2014, at 3:27 PM, Jinsong Zhao wrote:

> On 2014/8/11 14:50, William Dunlap wrote:
>> You can use
>>     m[m > 0 & m <= 1.0] <- 1
>>     m[m > 1 ] <- 2
>> or, if you have lots of intervals, something based on findInterval().  E.g.,
>>     m[] <- findInterval(m, c(-Inf, 0, 1, Inf)) - 1
>> 

OR, if you have irregularly spaced intervals or particular values to match to the intervals,  you can use findInterval to define categories and select with "[":

> set.seed(42); m <- matrix( rnorm(100, 10, 5), 10)
> round( m, 2)
       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
 [1,] 16.85 16.52  8.47 12.28 11.03 11.61  8.16  4.78 17.56 16.96
 [2,]  7.18 21.43  1.09 13.52  8.19  6.08 10.93  9.55 11.29  7.62
 [3,] 11.82  3.06  9.14 15.18 13.79 17.88 12.91 13.12 10.44 13.25
 [4,] 13.16  8.61 16.07  6.96  6.37 13.21 17.00  5.23  9.40 16.96
 [5,] 12.02  9.33 19.48 12.52  3.16 10.45  6.36  7.29  4.03  4.45
 [6,]  9.47 13.18  7.85  1.41 12.16 11.38 16.51 12.90 13.06  5.70
 [7,] 17.56  8.58  8.71  6.08  5.94 13.40 11.68 13.84  8.91  4.34
 [8,]  9.53 -3.28  1.18  5.75 17.22 10.45 15.19 12.32  9.09  2.70
 [9,] 20.09 -2.20 12.30 -2.07  7.84 -4.97 14.60  5.57 14.67 10.40
[10,]  9.69 16.60  6.80 10.18 13.28 11.42 13.60  4.50 14.11 13.27

> m[] <- c(1,2,4,8,16, 32) [ findInterval(m, c(-Inf, 2, 5, 10, 15, 18, Inf) ) ]
> m
      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
 [1,]   16   16    4    8    8    8    4    2   16    16
 [2,]    4   32    1    8    4    4    8    4    8     4
 [3,]    8    2    4   16    8   16    8    8    8     8
 [4,]    8    4   16    4    4    8   16    4    4    16
 [5,]    8    4   32    8    2    8    4    4    2     2
 [6,]    4    8    4    1    8    8   16    8    8     4
 [7,]   16    4    4    4    4    8    8    8    4     2
 [8,]    4    1    1    4   16    8   16    8    4     2
 [9,]   32    1    8    1    4    1    8    4    8     8
[10,]    4   16    4    8    8    8    8    2    8     8

-- 
David.


>> (What do you want to do with non-positive numbers?)
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
> 
> Thank you very much.
> 
> I think findInterval() is what I want.
> 
> Regards,
> Jinsong
> 
>> 
>> 
>> On Mon, Aug 11, 2014 at 2:40 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
>>> Hi there,
>>> 
>>> I hope to replace a range of numeric in a matrix with a integer. For
>>> example, in the following matrix, I want to use 1 to replace the elements
>>> range from 0.0 to 1.0, and all larger than 1. with 2.
>>> 
>>>> (m <- matrix(runif(16, 0, 2), nrow = 4))
>>>           [,1]       [,2]      [,3]     [,4]
>>> [1,] 0.7115088 0.55370418 0.1586146 1.882931
>>> [2,] 0.9068198 0.38081423 0.9172629 1.713592
>>> [3,] 1.5210150 0.93900649 1.2609942 1.744456
>>> [4,] 0.3779058 0.03130103 0.1893477 1.601181
>>> 
>>> so I want to get something like:
>>> 
>>>      [,1] [,2] [,3] [,4]
>>> [1,]    1    1    1    2
>>> [2,]    1    1    1    2
>>> [3,]    2    1    2    2
>>> [4,]    1    1    1    2
>>> 
>>> I wrote a function to do such thing:
>>> 
>>> fun <- function(x) {
>>>     if (is.na(x)) {
>>>         NA
>>>     } else if (x > 0.0 && x <= 1.0) {
>>>         1
>>>     } else if (x > 1.0) {
>>>         2
>>>     } else {
>>>         x
>>>     }
>>> }
>>> 
>>> Then run it as:
>>> 
>>>> apply(m,2,function(i) sapply(i, fun))
>>> 
>>> However, it seems that this method is not efficient when the dimension is
>>> large, e.g., 5000x5000 matrix.
>>> 
>>> Any suggestions? Thanks in advance!
>>> 
>>> Best regards,
>>> Jinsong

> 

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Tue Aug 12 02:22:33 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Tue, 12 Aug 2014 10:22:33 +1000
Subject: [R] Superimposing graphs
In-Reply-To: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
References: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
Message-ID: <000701cfb5c3$8358f890$8a0ae9b0$@bigpond.com>

Hi

If you want a 1 package and 1 function approach try this

xyplot(conc ~ time | factor(subject, levels = c(2,1,3)), data = data.d,
        par.settings = list(strip.background = list(col = "transparent")),
        layout = c(3,1),
        aspect = 1,
        type   = c("b","g"),
        scales = list(alternating = FALSE),
        panel = function(x,y,...){
        
                  panel.xyplot(x,y,...)

                  # f1<-function(x,v,cl,t)
                  # (x/v)*exp(-(cl/v)*t) f1(0.5,0.5,0.06,t),
                  panel.curve((0.5/0.5)*exp(-(0.06/0.5)*x),0,30)
        
                }
 )

# par.settings ... if you are publishing show text better
# with factor if you want 1:3 omit the levels
# has advantage of doing more things than in groupedData as Doug Bates has
said

Regards

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Naser Jamil
Sent: Monday, 11 August 2014 19:06
To: R help
Subject: [R] Superimposing graphs

Dear R-user,
May I seek your help to sort out a little problem. I have the following
codes
to draw two graphs. I want to superimpose the second one on each of the
first one.

########################################

library(nlme)
subject<-c(1,1,1,2,2,2,3,3,3)
time<-c(0.0,5.4,21.0,0.0,5.4,21.0,0.0,5.4,21.0)
con.cohort<-c(1.10971703,0.54535512,0.07176724,0.75912539,0.47825282,
0.10593292,1.20808375,0.47638394,0.02808967)

data.d=data.frame(subject=subject,time=time,conc=con.cohort)
grouped.data<-groupedData(formula=conc~time | subject, data =data.d)

plot(grouped.data)

##########################################

f1<-function(x,v,cl,t) {
(x/v)*exp(-(cl/v)*t)
                              }
t<-seq(0,30, .01)
plot(t,f1(0.5,0.5,0.06,t),type="l",pch=18, ylim=c(), xlab="time",
ylab="conc")


###########################################

Any suggestion will really be helpful.


Regards,

Jamil.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From peter.salzmanuser at gmail.com  Tue Aug 12 03:34:58 2014
From: peter.salzmanuser at gmail.com (peter salzman)
Date: Mon, 11 Aug 2014 21:34:58 -0400
Subject: [R] Reading chunks of data from a file more efficiently
In-Reply-To: <074C83DAD4825242A20B2D83FDBCB888765CDC@EX10MBOX03.pnnl.gov>
References: <074C83DAD4825242A20B2D83FDBCB888765CDC@EX10MBOX03.pnnl.gov>
Message-ID: <CAHdotinsWQmB-DGZk43_nS5MtqiWDTLru9GEark_PjLXOak58Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/d5cf0a81/attachment.pl>

From gcr at wisdomandwonder.com  Mon Aug 11 18:01:28 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Mon, 11 Aug 2014 11:01:28 -0500
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
	<CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>
Message-ID: <CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>

On Sun, Aug 10, 2014 at 6:50 PM, John McKown
<john.archie.mckown at gmail.com> wrote:

> OK, I assume this results in a vector of file names in a variable,
> like you'd get from list.files();

Yes.

> Why? Do you need them in separate data frames?

I do not.

> The meat of the question. If you don't need the files in separate data
> frames, and the files do _NOT_ have headers, then I would just load
> them all into a single frame. I used Linux and so my solution may not
> work on Windows. Something like:

Excellent point. All of the files do have the same header. I'm on OSX
so there must be a nice
one liner to concatenate all of the individual files, dropping the
first line for all but the first.  Danke!


From tea3rd at gmail.com  Tue Aug 12 04:43:39 2014
From: tea3rd at gmail.com (Thomas Adams)
Date: Mon, 11 Aug 2014 22:43:39 -0400
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
	<CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>
	<CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>
Message-ID: <CAGxgkWj_iL+GkvPP0S7i27NmHJu8BHFCNkreVtdMjTqEYigryA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140811/b607cb22/attachment.pl>

From john.archie.mckown at gmail.com  Tue Aug 12 05:01:15 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 11 Aug 2014 22:01:15 -0500
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAGxgkWj_iL+GkvPP0S7i27NmHJu8BHFCNkreVtdMjTqEYigryA@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
	<CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>
	<CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>
	<CAGxgkWj_iL+GkvPP0S7i27NmHJu8BHFCNkreVtdMjTqEYigryA@mail.gmail.com>
Message-ID: <CAAJSdjgh554dvJEfqb8kXmNa7E=u50=wc+io+xx7jHpfUZ_sAg@mail.gmail.com>

On Mon, Aug 11, 2014 at 9:43 PM, Thomas Adams <tea3rd at gmail.com> wrote:
> Grant,
>
> Assuming all your filenames are something like file1.txt,
> file2.txt,file3.txt... And using the Mac OSX terminal app (after you cd to
> the directory where your files are located...
>
> This will strip off the 1st lines, that is, your header lines:
>
> for file in *.txt;do
> sed -i '1d'${file};
> done
>
> Then, do this:
>
> cat *.txt > newfilename.txt
>
> Doing both should only take a few seconds, depending on your file sizes.
>
> Cheers!
> Tom
>

Using sed hadn't occurred to me. I guess I'm just "awk-ward" <grin/>.
A slightly different way would be:

for file in *.txt;do
  sed '1d' ${file}
done >newfilename.txt

that way the original files are not modified.  But it strips out the
header on the 1st file as well. Not a big deal, but the read.table
will need to be changed to accommodate that. Also, it creates an
otherwise unnecessary intermediate file "newfilename.txt". To get the
1st file's header, the script could:

head -1 >newfilename.txt
for file in *.txt;do
   sed '1d' ${file}
done >>newfilename.txt

I really like having multiple answers to a given problem. Especially
since I have a poorly implemented version of "awk" on one of my
systems. It is the vendor's "awk" and conforms exactly to the POSIX
definition with no additions. So I don't have the FNR built-in
variable. Your implementation would work well on that system. Well, if
there were a version of R for it. It is a branded UNIX system which
was designed to be totally __and only__ POSIX compliant, with few
(maybe no) extensions at all. IOW, it stinks. No, it can't be
replaced. It is the z/OS system from IBM which is EBCDIC based and
runs on the "big iron" mainframe, system z.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From dwinsemius at comcast.net  Tue Aug 12 08:07:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 11 Aug 2014 23:07:13 -0700
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <CAAJSdjgh554dvJEfqb8kXmNa7E=u50=wc+io+xx7jHpfUZ_sAg@mail.gmail.com>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
	<CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>
	<CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>
	<CAGxgkWj_iL+GkvPP0S7i27NmHJu8BHFCNkreVtdMjTqEYigryA@mail.gmail.com>
	<CAAJSdjgh554dvJEfqb8kXmNa7E=u50=wc+io+xx7jHpfUZ_sAg@mail.gmail.com>
Message-ID: <22685F54-6B50-4A75-82F3-15B3823F6C6B@comcast.net>


On Aug 11, 2014, at 8:01 PM, John McKown wrote:

> On Mon, Aug 11, 2014 at 9:43 PM, Thomas Adams <tea3rd at gmail.com> wrote:
>> Grant,
>> 
>> Assuming all your filenames are something like file1.txt,
>> file2.txt,file3.txt... And using the Mac OSX terminal app (after you cd to
>> the directory where your files are located...
>> 
>> This will strip off the 1st lines, that is, your header lines:
>> 
>> for file in *.txt;do
>> sed -i '1d'${file};
>> done
>> 
>> Then, do this:
>> 
>> cat *.txt > newfilename.txt
>> 
>> Doing both should only take a few seconds, depending on your file sizes.
>> 
>> Cheers!
>> Tom
>> 
> 
> Using sed hadn't occurred to me. I guess I'm just "awk-ward" <grin/>.
> A slightly different way would be:
> 
> for file in *.txt;do
>  sed '1d' ${file}
> done >newfilename.txt
> 
> that way the original files are not modified.  But it strips out the
> header on the 1st file as well. Not a big deal, but the read.table
> will need to be changed to accommodate that. Also, it creates an
> otherwise unnecessary intermediate file "newfilename.txt". To get the
> 1st file's header, the script could:
> 
> head -1 >newfilename.txt
> for file in *.txt;do
>   sed '1d' ${file}
> done >>newfilename.txt
> 
> I really like having multiple answers to a given problem. Especially
> since I have a poorly implemented version of "awk" on one of my
> systems. It is the vendor's "awk" and conforms exactly to the POSIX
> definition with no additions. So I don't have the FNR built-in
> variable. Your implementation would work well on that system. Well, if
> there were a version of R for it. It is a branded UNIX system which
> was designed to be totally __and only__ POSIX compliant, with few
> (maybe no) extensions at all. IOW, it stinks. No, it can't be
> replaced. It is the z/OS system from IBM which is EBCDIC based and
> runs on the "big iron" mainframe, system z.
> 
> -- 

On the Mac the awk equivalent is gawk. Within R you would use `system()` possibly using paste0() to construct a string to send.

-- 



David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Tue Aug 12 08:56:14 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 12 Aug 2014 07:56:14 +0100
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <22685F54-6B50-4A75-82F3-15B3823F6C6B@comcast.net>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>	<CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>	<CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>	<CAGxgkWj_iL+GkvPP0S7i27NmHJu8BHFCNkreVtdMjTqEYigryA@mail.gmail.com>	<CAAJSdjgh554dvJEfqb8kXmNa7E=u50=wc+io+xx7jHpfUZ_sAg@mail.gmail.com>
	<22685F54-6B50-4A75-82F3-15B3823F6C6B@comcast.net>
Message-ID: <53E9BA8E.9010700@stats.ox.ac.uk>

On 12/08/2014 07:07, David Winsemius wrote:
>
> On Aug 11, 2014, at 8:01 PM, John McKown wrote:
>
>> On Mon, Aug 11, 2014 at 9:43 PM, Thomas Adams <tea3rd at gmail.com> wrote:
>>> Grant,
>>>
>>> Assuming all your filenames are something like file1.txt,
>>> file2.txt,file3.txt... And using the Mac OSX terminal app (after you cd to
>>> the directory where your files are located...
>>>
>>> This will strip off the 1st lines, that is, your header lines:
>>>
>>> for file in *.txt;do
>>> sed -i '1d'${file};
>>> done
>>>
>>> Then, do this:
>>>
>>> cat *.txt > newfilename.txt
>>>
>>> Doing both should only take a few seconds, depending on your file sizes.
>>>
>>> Cheers!
>>> Tom
>>>
>>
>> Using sed hadn't occurred to me. I guess I'm just "awk-ward" <grin/>.
>> A slightly different way would be:
>>
>> for file in *.txt;do
>>   sed '1d' ${file}
>> done >newfilename.txt
>>
>> that way the original files are not modified.  But it strips out the
>> header on the 1st file as well. Not a big deal, but the read.table
>> will need to be changed to accommodate that. Also, it creates an
>> otherwise unnecessary intermediate file "newfilename.txt". To get the
>> 1st file's header, the script could:
>>
>> head -1 >newfilename.txt
>> for file in *.txt;do
>>    sed '1d' ${file}
>> done >>newfilename.txt
>>
>> I really like having multiple answers to a given problem. Especially
>> since I have a poorly implemented version of "awk" on one of my
>> systems. It is the vendor's "awk" and conforms exactly to the POSIX
>> definition with no additions. So I don't have the FNR built-in
>> variable. Your implementation would work well on that system. Well, if
>> there were a version of R for it. It is a branded UNIX system which
>> was designed to be totally __and only__ POSIX compliant, with few
>> (maybe no) extensions at all. IOW, it stinks. No, it can't be
>> replaced. It is the z/OS system from IBM which is EBCDIC based and
>> runs on the "big iron" mainframe, system z.
>>
>> --
>
> On the Mac the awk equivalent is gawk. Within R you would use `system()` possibly using paste0() to construct a string to send.

For historical reasons this is actually part of R's configuration: see 
the AWK entry in R_HOME/etc/Makeconf.  (There is an SED entry too: not 
all sed's in current OSes are POSIX-compliant.)

Using system2() rather than system() is recommended for new code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jan.stanstrup at fmach.it  Tue Aug 12 09:23:18 2014
From: jan.stanstrup at fmach.it (Jan Stanstrup)
Date: Tue, 12 Aug 2014 09:23:18 +0200
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
Message-ID: <53E9C0E6.6040101@fmach.it>

Hi,

I am trying to find a way to estimate prediction intervals (PI) for a 
monotonic loess curve using bootstrapping.

At the moment my approach is to use the boot function from the boot 
package to bootstrap my loess model, which consist of loess + monoproc 
from the monoproc package (to force the fit to be monotonic which gives 
me much improved results with my particular data). The output from the 
monoproc package is simply the fitted y values at each x-value.
I then use boot.ci (again from the boot package) to get confidence 
intervals. The problem is that this gives me confidence intervals (CI) 
for the "fit" (is there a proper way to specify this?) and not a 
prediction interval. The interval is thus way too optimistic to give me 
an idea of the confidence interval of a predicted value.

For linear models predict.lm can give PI instead of CI by setting 
interval = "prediction". Further discussion of that here:
http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.

However I don't see a way to do that for boot.ci. Does there exist a way 
to get PIs after bootstrapping? If some sample code is required I am 
more than happy to supply it but I thought the question was general 
enough to be understandable without it.


Any hints are highly appreciated.


----------------------
Jan Stanstrup
Postdoc

Metabolomics
Food Quality and Nutrition
Fondazione Edmund Mach


From veraoliveira523 at hotmail.com  Tue Aug 12 14:09:09 2014
From: veraoliveira523 at hotmail.com (=?iso-8859-1?B?VmVyYSBNaWd16Wlz?=)
Date: Tue, 12 Aug 2014 12:09:09 +0000
Subject: [R] Multivariate tobit regression
In-Reply-To: <mailman.2552.1407774434.4543.r-help@r-project.org>
References: <mailman.2552.1407774434.4543.r-help@r-project.org>
Message-ID: <DUB129-W776088E67EE5C80DD08382F8EA0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140812/e18e5899/attachment.pl>

From maicel at infomed.sld.cu  Tue Aug 12 14:42:13 2014
From: maicel at infomed.sld.cu (=?iso-8859-1?Q?Maicel_Monz=F3n_P=E9rez?=)
Date: Tue, 12 Aug 2014 08:42:13 -0400
Subject: [R] script to data clear
Message-ID: <000401cfb62b$21cc4d80$6564e880$@infomed.sld.cu>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140812/cac99e0f/attachment.pl>

From jamilnaser79 at gmail.com  Tue Aug 12 13:26:02 2014
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Tue, 12 Aug 2014 12:26:02 +0100
Subject: [R] Superimposing graphs
In-Reply-To: <000701cfb5c3$8358f890$8a0ae9b0$@bigpond.com>
References: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
	<000701cfb5c3$8358f890$8a0ae9b0$@bigpond.com>
Message-ID: <CAJK=5YmVysntwx=p=zaccqrcAPU_Kf7CFWKCQApPKpnjS2aAQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140812/6a55c06f/attachment.pl>

From timothy.benham at uqconnect.edu.au  Tue Aug 12 14:11:36 2014
From: timothy.benham at uqconnect.edu.au (tjb)
Date: Tue, 12 Aug 2014 05:11:36 -0700 (PDT)
Subject: [R] bugs and misfeatures in polr(MASS).... fixed!
In-Reply-To: <1407838446409-4695392.post@n4.nabble.com>
References: <C08763D1D53F524588A0EBE660E0C13311C659ED@BL2PRD0103MB052.prod.exchangelabs.com>
	<1289080849085-3030405.post@n4.nabble.com>
	<1350561918976-4646600.post@n4.nabble.com>
	<CACc=JvGzqT1j8v1krJ+EbUVS_Zz9y2MSPvC9V_EeSvebf==Q6w@mail.gmail.com>
	<1351082280801-4647311.post@n4.nabble.com>
	<CACc=JvG1yRDY9ndZ=9zrmDhU76G1nb0mYuLejftOYqaYNJ1Zxg@mail.gmail.com>
	<1407838446409-4695392.post@n4.nabble.com>
Message-ID: <CACc=JvEPd2g3k3iSYSDERb6Q9fmC8sFazFQn3GVLcu81emaqpw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140812/81a87425/attachment.pl>

From rmh at temple.edu  Tue Aug 12 15:32:10 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 12 Aug 2014 09:32:10 -0400
Subject: [R] Superimposing graphs
In-Reply-To: <CAJK=5YmVysntwx=p=zaccqrcAPU_Kf7CFWKCQApPKpnjS2aAQQ@mail.gmail.com>
References: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
	<000701cfb5c3$8358f890$8a0ae9b0$@bigpond.com>
	<CAJK=5YmVysntwx=p=zaccqrcAPU_Kf7CFWKCQApPKpnjS2aAQQ@mail.gmail.com>
Message-ID: <CAGx1TMBPgDg0+aHhNPcqDhVJs6FoL+00=s1ZawD6JnuMcrMP9A@mail.gmail.com>

Yes, use xlim=c(0, 30) in your definition of P1

On Tue, Aug 12, 2014 at 7:26 AM, Naser Jamil <jamilnaser79 at gmail.com> wrote:
> Dear Richard and Duncan,
> your suggestions are absolutely serving what I need. But I would like to
> see x-axis to be up to 30 instead of 20. Do you have any suggestion on that?
>
> Many thanks for your kind help.
>
> Regards,
>
> Jamil.
>
>
> On 12 August 2014 01:22, Duncan Mackay <dulcalma at bigpond.com> wrote:
>
>> Hi
>>
>> If you want a 1 package and 1 function approach try this
>>
>> xyplot(conc ~ time | factor(subject, levels = c(2,1,3)), data = data.d,
>>         par.settings = list(strip.background = list(col = "transparent")),
>>         layout = c(3,1),
>>         aspect = 1,
>>         type   = c("b","g"),
>>         scales = list(alternating = FALSE),
>>         panel = function(x,y,...){
>>
>>                   panel.xyplot(x,y,...)
>>
>>                   # f1<-function(x,v,cl,t)
>>                   # (x/v)*exp(-(cl/v)*t) f1(0.5,0.5,0.06,t),
>>                   panel.curve((0.5/0.5)*exp(-(0.06/0.5)*x),0,30)
>>
>>                 }
>>  )
>>
>> # par.settings ... if you are publishing show text better
>> # with factor if you want 1:3 omit the levels
>> # has advantage of doing more things than in groupedData as Doug Bates has
>> said
>>
>> Regards
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On
>> Behalf Of Naser Jamil
>> Sent: Monday, 11 August 2014 19:06
>> To: R help
>> Subject: [R] Superimposing graphs
>>
>> Dear R-user,
>> May I seek your help to sort out a little problem. I have the following
>> codes
>> to draw two graphs. I want to superimpose the second one on each of the
>> first one.
>>
>> ########################################
>>
>> library(nlme)
>> subject<-c(1,1,1,2,2,2,3,3,3)
>> time<-c(0.0,5.4,21.0,0.0,5.4,21.0,0.0,5.4,21.0)
>> con.cohort<-c(1.10971703,0.54535512,0.07176724,0.75912539,0.47825282,
>> 0.10593292,1.20808375,0.47638394,0.02808967)
>>
>> data.d=data.frame(subject=subject,time=time,conc=con.cohort)
>> grouped.data<-groupedData(formula=conc~time | subject, data =data.d)
>>
>> plot(grouped.data)
>>
>> ##########################################
>>
>> f1<-function(x,v,cl,t) {
>> (x/v)*exp(-(cl/v)*t)
>>                               }
>> t<-seq(0,30, .01)
>> plot(t,f1(0.5,0.5,0.06,t),type="l",pch=18, ylim=c(), xlab="time",
>> ylab="conc")
>>
>>
>> ###########################################
>>
>> Any suggestion will really be helpful.
>>
>>
>> Regards,
>>
>> Jamil.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jamilnaser79 at gmail.com  Tue Aug 12 15:40:08 2014
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Tue, 12 Aug 2014 14:40:08 +0100
Subject: [R] Superimposing graphs
In-Reply-To: <CAGx1TMBPgDg0+aHhNPcqDhVJs6FoL+00=s1ZawD6JnuMcrMP9A@mail.gmail.com>
References: <CAJK=5Yk1hR2Wwa9Fy9itXvYAjFpqhQD6RgS2C7-0i2KuO_O7tw@mail.gmail.com>
	<000701cfb5c3$8358f890$8a0ae9b0$@bigpond.com>
	<CAJK=5YmVysntwx=p=zaccqrcAPU_Kf7CFWKCQApPKpnjS2aAQQ@mail.gmail.com>
	<CAGx1TMBPgDg0+aHhNPcqDhVJs6FoL+00=s1ZawD6JnuMcrMP9A@mail.gmail.com>
Message-ID: <CAJK=5Yk441qaQpBO-tO7cCtp3h1bjeQde4UjXvzHaO-YfWuhmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140812/2b38b5ba/attachment.pl>

From grettke at acm.org  Tue Aug 12 15:48:11 2014
From: grettke at acm.org (Grant Rettke)
Date: Tue, 12 Aug 2014 08:48:11 -0500
Subject: [R] "Best" way to merge 300+ .5MB dataframes?
In-Reply-To: <22685F54-6B50-4A75-82F3-15B3823F6C6B@comcast.net>
References: <CAAjq1mfNBJFQdu7othNzosr8WkHSvgXtYH4hx-om3P=SQ9k-gg@mail.gmail.com>
	<CAAJSdjjOaV4S1uREMHbZaAjyjP+S5Hmv6_JJ1ZMGJStbeS_uoA@mail.gmail.com>
	<CAAjq1mfpZHQgq+Yqgw9B_X7gLCDXM6Xcx_Oo8N7dSsus10N-Sg@mail.gmail.com>
	<CAGxgkWj_iL+GkvPP0S7i27NmHJu8BHFCNkreVtdMjTqEYigryA@mail.gmail.com>
	<CAAJSdjgh554dvJEfqb8kXmNa7E=u50=wc+io+xx7jHpfUZ_sAg@mail.gmail.com>
	<22685F54-6B50-4A75-82F3-15B3823F6C6B@comcast.net>
Message-ID: <CAAjq1mdKEy-A+aHnjAekyuYb0z1TMGPTaABXOmQ9r2RRLviLTQ@mail.gmail.com>

Thank you all kindly.
Grant Rettke | ACM, AMA, COG, IEEE
grettke at acm.org | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Tue, Aug 12, 2014 at 1:07 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 11, 2014, at 8:01 PM, John McKown wrote:
>
>> On Mon, Aug 11, 2014 at 9:43 PM, Thomas Adams <tea3rd at gmail.com> wrote:
>>> Grant,
>>>
>>> Assuming all your filenames are something like file1.txt,
>>> file2.txt,file3.txt... And using the Mac OSX terminal app (after you cd to
>>> the directory where your files are located...
>>>
>>> This will strip off the 1st lines, that is, your header lines:
>>>
>>> for file in *.txt;do
>>> sed -i '1d'${file};
>>> done
>>>
>>> Then, do this:
>>>
>>> cat *.txt > newfilename.txt
>>>
>>> Doing both should only take a few seconds, depending on your file sizes.
>>>
>>> Cheers!
>>> Tom
>>>
>>
>> Using sed hadn't occurred to me. I guess I'm just "awk-ward" <grin/>.
>> A slightly different way would be:
>>
>> for file in *.txt;do
>>  sed '1d' ${file}
>> done >newfilename.txt
>>
>> that way the original files are not modified.  But it strips out the
>> header on the 1st file as well. Not a big deal, but the read.table
>> will need to be changed to accommodate that. Also, it creates an
>> otherwise unnecessary intermediate file "newfilename.txt". To get the
>> 1st file's header, the script could:
>>
>> head -1 >newfilename.txt
>> for file in *.txt;do
>>   sed '1d' ${file}
>> done >>newfilename.txt
>>
>> I really like having multiple answers to a given problem. Especially
>> since I have a poorly implemented version of "awk" on one of my
>> systems. It is the vendor's "awk" and conforms exactly to the POSIX
>> definition with no additions. So I don't have the FNR built-in
>> variable. Your implementation would work well on that system. Well, if
>> there were a version of R for it. It is a branded UNIX system which
>> was designed to be totally __and only__ POSIX compliant, with few
>> (maybe no) extensions at all. IOW, it stinks. No, it can't be
>> replaced. It is the z/OS system from IBM which is EBCDIC based and
>> runs on the "big iron" mainframe, system z.
>>
>> --
>
> On the Mac the awk equivalent is gawk. Within R you would use `system()` possibly using paste0() to construct a string to send.
>
> --
>
>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Aug 12 17:06:49 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 12 Aug 2014 08:06:49 -0700
Subject: [R] script to data clear
In-Reply-To: <000401cfb62b$21cc4d80$6564e880$@infomed.sld.cu>
References: <000401cfb62b$21cc4d80$6564e880$@infomed.sld.cu>
Message-ID: <6b2de355-f307-449f-b8ba-170a32875c71@email.android.com>

Without a representative sample of data, it is very hard to understand your question or to be specific about suggestions. See [1] for some ideas about how to communicate questions online.

Not that "clearing" data would usually mean deleting it, as in rm(data). From context I assume you mean "cleaning", where invalid characters need to be removed.

Also assuming that you have a data frame with some columns that are categorical data:

1) If the values are contaminated or incomplete (don't have rows representing every possible category) then it is almost always better to delay converting to factor until after data are cleaned. The read.table family of functions include a "stringsAsFactors=FALSE" option that will prevent automatic conversion of columns with unknown types into factors. This is also useful for contaminated numeric columns. Only after the vector of character data is clean and as complete as it can be should you convert to factor.

Note that most data sets have a variety of column types, and even after resolving issues discussed here your function is not necessarily going to work with every input data file that you encounter. Specifically, not every column of data should be converted to factor. With this in mind, it can be helpful to look for ways to confirm that the date you are processing is what you expect it to be. Often this is implemented by confirming that specific columns have specific kinds of data in them. That is using a loop may be TOO flexible... apply this cleaning loop cautiously.

2) Most functions in R can process whole vectors of data at once, so your inner loop should not be necessary. Specifically, the line

data[[i]] <- gsub( " +", " ", data[[i]] )

would replace all sequences of one or more spaces in every element of the vector with a single space.

(Your j loop also goes too many times... str_replace_all(data[[i]], "  ", " ") is affecting the whole column, but you repeat it unnecessarily.)

 3) I don't know what a "depurate" value is.

4) You should be able to convert your cleaned character column to factor with the "factor" function... like

data[[i]] <- factor( data[[i]] )

Note that if you know certain levels should be possible but not all of them are actually present (e.g. "Small", "Medium", and "Large" but no data with "Small" are present) then you will need to specify the levels as a parameter to the factor function. See the help file ?factor.

5) You have several lines of code at the end that appear to execute regardless of whether the column is a factor or not. They should be within the braces of the if statement.

6) Please read the Posting Guide mentioned at the end of this and every post on this list, specifically regarding posting in plain text. Your code was partially damaged by the HTML email format.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 12, 2014 5:42:13 AM PDT, "Maicel Monz?n P?rez" <maicel at infomed.sld.cu> wrote:
>Hello List,
>
>I did this script to clear data after import (I don?t know is ok ).
>After
>its execution levels and label values got lost. Could some explain me
>to
>reassign levels again in the script (new depurate value)? 
>
>Best regard
>
>Maicel Monzon MD, PHD
>
>Center of Cybernetic Apply to Medicine
>
># data cleaning  script
>
>library(stringr)
>
>for(i in 1:length(data)) { 
>
>  if (is.factor(data[[i]])==T) 
>
>  {for(j in 1:sum(str_detect(data[,i], "  "))) 
>
>  {data[[i]]<-str_replace_all(data[[i]], "  ", " ")}}
>
>  data[[i]]<-str_trim (data[[i]],side = "both")
>
>  data[[i]]<-tolower(data[[i]])
>
>}
>
>Note: ?   ? is 2 blank space  and ? ?  only one
>
> 
>
>
>
>--
>Nunca digas nunca, di mejor: gracias, permiso, disculpe.
>
>Este mensaje le ha llegado mediante el servicio de correo electronico
>que ofrece Infomed para respaldar el cumplimiento de las misiones del
>Sistema Nacional de Salud. La persona que envia este correo asume el
>compromiso de usar el servicio a tales fines y cumplir con las
>regulaciones establecidas
>
>Infomed: http://www.sld.cu/
>
>
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Aug 12 17:20:06 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 12 Aug 2014 08:20:06 -0700
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
	loess curve using bootstrapping
In-Reply-To: <53E9C0E6.6040101@fmach.it>
References: <53E9C0E6.6040101@fmach.it>
Message-ID: <10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>


On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:

> Hi,
> 
> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
> 
> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
> 
> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
> 
> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
> 

Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
-- 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Tue Aug 12 17:40:44 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Aug 2014 08:40:44 -0700
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
In-Reply-To: <10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
Message-ID: <CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>

PI's of what? -- future individual values or mean values?

I assume quantreg provides quantiles for the latter, not the former.
(See ?predict.lm for a terse explanation of the difference). Both are
obtainable from bootstrapping but the details depend on what you are
prepared to assume. Consult references or your local statistician for
help if needed.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>
>> Hi,
>>
>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>
>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>
>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>
>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>
>
> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From danmbox at gmail.com  Tue Aug 12 17:55:35 2014
From: danmbox at gmail.com (Dan Muresan)
Date: Tue, 12 Aug 2014 18:55:35 +0300
Subject: [R] pass vector binding to DBI parameter (rsqlite)
Message-ID: <CAJ6Zc6PdDGU+9qF5AoirLX937y4vqvgiFhvmw7epki6QnjuxjA@mail.gmail.com>

Hi, is there a way to bind vectors to DBI query parameters? The
following tells me that vectors are sent as separate values:

> library("RSQLite")
> c <- dbConnect (SQLite())
> dbGetQuery(c, "create table tst (x int, y int)")
> dbGetQuery(c, "insert into tst values (?, ?)", data.frame(x=c (1,2,1,2), y=c(3, 4, 5, 6)))
> dbReadTable(c, "tst")
  x y
1 1 3
2 2 4
3 1 5
4 2 6
> dbGetQuery(c, "select * from tst where y not in (?)", c(7,6))
  x y
1 1 3
2 2 4
3 1 5
4 2 6
5 1 3
6 2 4
7 1 5

This looks like 2 result sets (4 + 3 entries), not one.

Is there to send multiple values to a '?' binding? Is this at all
possible using the R DBI interface (not necessarily with rsqlite)?


From acefix at rocketmail.com  Tue Aug 12 17:39:34 2014
From: acefix at rocketmail.com (Fix Ace)
Date: Tue, 12 Aug 2014 08:39:34 -0700
Subject: [R] how to process multiple data files using R loop
In-Reply-To: <CAFEqCdwW-PtodZjbUETmFMbK+ww0+FGoD2SaZkWy2HY6=M5fjQ@mail.gmail.com>
References: <1407522337.18454.YahooMailNeo@web164604.mail.gq1.yahoo.com>
	<CAFEqCdwW-PtodZjbUETmFMbK+ww0+FGoD2SaZkWy2HY6=M5fjQ@mail.gmail.com>
Message-ID: <1407857974.65495.YahooMailNeo@web164602.mail.gq1.yahoo.com>

Thank you very much for all replies:) Here is my working code:

for(i in ls(pattern="P_")){print(head(get(i),2))}



On Monday, August 11, 2014 11:04 AM, Greg Snow <538280 at gmail.com> wrote:
 


In addition to the solution and comments that you have already
received, here are a couple of additional comments:

This is a variant on FAQ 7.21, if you had found that FAQ then it would
have told you about the get function.

The most important part of the answer in FAQ 7.21 is the last part
where it says that it is better to use a list.? If all the objects of
interest are related and you want to do the same or similar things to
each one, then having them all stored in a single list can simplify
things for the future.? You can collect all the objects into a single
list using the mget command, e.g.:

P_objects <- mget( ls(pattern='P_'))

Now that they are in a list you can do the equivalent of your loop,
but simpler with the lapply function, e.g.:

lapply( P_objects, head, 2 )

And if you want to do other things with all these objects, such as
save them, plot them, do a regression analysis on them, delete them,
etc. then you can do that using lapply/sapply as well in a simpler way
than looping.



On Fri, Aug 8, 2014 at 12:25 PM, Fix Ace <acefix at rocketmail.com> wrote:
> I have 16 files and would like to check the information of their first two lines, what I did:
>
>
>> ls(pattern="P_")
>? [1] "P_3_utr_source_data"? ? ? ? ? ? ?  "P_5_utr_source_data"
>? [3] "P_exon_per_gene_cds_source_data"?  "P_exon_per_gene_source_data"
>? [5] "P_exon_source_data"? ? ? ? ? ? ? ? "P_first_exon_oncds_source_data"
>? [7] "P_first_intron_oncds_source_data"? "P_first_intron_ongene_source_data"
>? [9] "P_firt_exon_ongene_source_data"? ? "P_gene_cds_source_data"
> [11] "P_gene_source_data"? ? ? ? ? ? ? ? "P_intron_source_data"
> [13] "P_last_exon_oncds_source_data"? ?  "P_last_exon_ongene_source_data"
> [15] "P_last_intron_oncds_source_data"?  "P_last_intron_ongene_source_data"
>
>
>
>>for(i in ls(pattern="P_")){head(i, 2)}
>
> It obviously does not work since nothing came out
>
> What I would like to see for the output is :
>
>> head(P_3_utr_source_data,2)
>?  V1
> 1? 1
> 2? 1
>> head(P_5_utr_source_data,2)
>?  V1
> 1? 1
> 2? 1
>>
> .
>
> .
> .
>
>
>
> Could anybody help me with this?
>
> Thank you very much for your time:)
>? ? ? ?  [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com
	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue Aug 12 19:45:00 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 12:45:00 -0500
Subject: [R] pass vector binding to DBI parameter (rsqlite)
In-Reply-To: <CAJ6Zc6PdDGU+9qF5AoirLX937y4vqvgiFhvmw7epki6QnjuxjA@mail.gmail.com>
References: <CAJ6Zc6PdDGU+9qF5AoirLX937y4vqvgiFhvmw7epki6QnjuxjA@mail.gmail.com>
Message-ID: <CAAJSdjj7s=2yp4fxuKykA9Zq1BeVQoM_6aa-uJ=GWZ1H-PXL-w@mail.gmail.com>

On Tue, Aug 12, 2014 at 10:55 AM, Dan Muresan <danmbox at gmail.com> wrote:
> Hi, is there a way to bind vectors to DBI query parameters? The
> following tells me that vectors are sent as separate values:
>
>> library("RSQLite")
>> c <- dbConnect (SQLite())
>> dbGetQuery(c, "create table tst (x int, y int)")
>> dbGetQuery(c, "insert into tst values (?, ?)", data.frame(x=c (1,2,1,2), y=c(3, 4, 5, 6)))
>> dbReadTable(c, "tst")
>   x y
> 1 1 3
> 2 2 4
> 3 1 5
> 4 2 6
>> dbGetQuery(c, "select * from tst where y not in (?)", c(7,6))
>   x y
> 1 1 3
> 2 2 4
> 3 1 5
> 4 2 6
> 5 1 3
> 6 2 4
> 7 1 5
>
> This looks like 2 result sets (4 + 3 entries), not one.
>
> Is there to send multiple values to a '?' binding? Is this at all
> possible using the R DBI interface (not necessarily with rsqlite)?

I don't really _know_ much, but what I would try would be something like:

dbGetQuery(c,"select * from tst where y not in (?)",paste(c(7,6),collapse=','));

The paste(c(7,6),collapse=',') results in the string "6,7". You could
always subject yourself to a SQL injection attack by doing:

dbGetQuery(c,paste("select * from tst where y not in
(",c(7,6),")",collapse=','));

If you do this and use a variable instead of the c(7,6), make sure you
"cleanse" the contents of the variable. Just as making sure that there
is no "bare" semi-colon in it. And other things that don't come to
mind off hand.

Hum, perhaps better:

values<-c(7,6);
dbGetQuery(c,paste("select * from tst where y not in (",
                                paste(rep('?',length(values)),collapse=','),
                                ")"),
                        values);

As you can see, this dynamically adjusts the number of ? marks in the
SELECT statement, based on the number of elements in the "values"
variable.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From erinm.hodgess at gmail.com  Tue Aug 12 20:51:16 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 12 Aug 2014 14:51:16 -0400
Subject: [R]  generating a sequence of seconds
Message-ID: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>

Hello!

If I would like to generate a sequence of seconds for a date, I would do
the following:

x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
23:59:59),by="secs")

What if I just want the seconds vector without the date, please?  Is there
a convenient way to create such a vector, please?

thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From armel.kaptue at sdstate.edu  Tue Aug 12 20:57:23 2014
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Tue, 12 Aug 2014 18:57:23 +0000
Subject: [R] Validation of the Markov chain assumption
Message-ID: <bd67fcecf2a64550bb41aac13f8cb9db@BLUPR06MB595.namprd06.prod.outlook.com>

Hi,
I 'm modelling the occurrence of daily rainfall with a first order Markov chain.
I would like to know if there is a statistic test implemented in R that could allow me to asses that the observed rainfall time series verifies the Markov assumption.
Thanks
P.S. My apologies for cross-posting since I send this question by mistake to an inadequate R mailing list.



	[[alternative HTML version deleted]]


From mazatlanmexico at yahoo.com  Tue Aug 12 19:16:53 2014
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Tue, 12 Aug 2014 10:16:53 -0700
Subject: [R] t.test of matching columns from two datasets using plyr
Message-ID: <1407863813.79959.YahooMailNeo@web126002.mail.ne1.yahoo.com>

Hi,
I Have two datasets df1 and df2 with 3 matching columns. I need to do a t.test
of sp1, sp2 and sp3? and var1, var2 and var3 where the year, month and location match. 
I can do it with sapply or mapply but I want the end result to be a data.frame. I prefer to do it with
plyr or dplyr as I have been using these packages throughout this project. My final
dataframe should have the t.test statistic and the p.value.
?
Sample datasets
first dataframe
df1 <- structure(list(Year = c(1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 
1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 
1995L, 1995L, 1995L, 1995L, 1995L, 1995L), month = c("Feb", "Mar", 
"Mar", "Mar", "Mar", "Mar", "Mar", "Mar", "Mar", "Mar", "Mar", 
"Mar", "Mar", "Mar", "Mar", "Apr", "Apr", "Apr", "Apr", "Apr", 
"Apr"), location = structure(c(5L, 5L, 5L, 5L, 5L, 5L, 2L, 4L, 
4L, 1L, 4L, 4L, 3L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 2L), .Label = c("Far West", 
"North", "Other", "South", "West"), class = "factor"), var1 = c(111.6, 
0, 0, 0, 0, 0, 0, 14, 0, 0, 0, 31.4, 245.9, 46.3, 59.8, 206.1, 
200.3, 88, 73.4, 33.9, 7.1), var2 = c(0, 4.7, 4.4, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 159.8, 0, 0, 142.2, 94.3, 0, 0, 0, 0), var3 = c(180.2, 
14.1, 123.7, 17.4, 5.5, 12.9, 39.3, 21, 66.6, 12.2, 13.6, 15.7, 
36.9, 0, 143.5, 35.5, 235.6, 51.3, 230.6, 81.3, 190.9)), .Names = c("Year", 
"month", "location", "var1", "var2", "var3"), row.names = 17093:17113, class = "data.frame")
second dataframe
df2 <- structure(list(Year = c(1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 
1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 1995L, 
1995L, 1995L, 1995L, 1995L, 1995L, 1995L), month = c("Apr", "Apr", 
"Apr", "Apr", "Apr", "Apr", "Apr", "Apr", "May", "May", "May", 
"May", "May", "May", "May", "May", "May", "May", "May", "May", 
"May"), location = structure(c(3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
1L, 1L, 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("Far West", 
"North", "South", "West"), class = "factor"), sp1 = c(853.0055629, 
147.7158909, 160.1536518, 65.01652491, 2332.609706, 701.4706852, 
11.36420842, 0, 2645.671425, 2769.409257, 523.4284249, 135.1274855, 
72.22498557, 35.07497333, 572.087043, 150.4768424, 111.5881472, 
61.21848041, 392.0651906, 0, 771.0337355), sp2 = c(10.27717546, 
0, 0, 0, 0, 10.16624181, 0, 0, 0, 307.7121397, 52.34284249, 19.30392649, 
24.07499519, 0, 35.75544018, 42.99338354, 0, 40.81232027, 0, 
90.9210806, 622.7580172), sp3 = c(92.49457911, 128.0204387, 203.8319205, 
175.5446173, 120.6522262, 71.1636927, 107.95998, 57.14456898, 
43.37166271, 153.8560698, 104.685685, 77.21570598, 96.29998075, 
187.0665244, 0, 0, 111.5881472, 163.2492811, 26.13767938, 45.4605403, 
207.5860057)), .Names = c("Year", "month", "location", "sp1", 
"sp2", "sp3"), row.names = 30:50, class = "data.frame")
?
Thank you much.
	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Aug 12 21:05:35 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 12 Aug 2014 14:05:35 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
Message-ID: <B1431919-AC52-480D-AFD5-869146F4E747@me.com>


On Aug 12, 2014, at 1:51 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello!
> 
> If I would like to generate a sequence of seconds for a date, I would do
> the following:
> 
> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
> 23:59:59),by="secs")
> 
> What if I just want the seconds vector without the date, please?  Is there
> a convenient way to create such a vector, please?
> 
> thanks,
> Erin


Erin,

Do you want just the numeric vector of seconds, with the first value being 0, incrementing by 1 to the final value?

x <- seq(from = as.POSIXct("2014-08-12 00:00:00"), 
         to = as.POSIXct("2014-08-12 23:59:59"), 
         by = "secs")

> head(x)
[1] "2014-08-12 00:00:00 CDT" "2014-08-12 00:00:01 CDT"
[3] "2014-08-12 00:00:02 CDT" "2014-08-12 00:00:03 CDT"
[5] "2014-08-12 00:00:04 CDT" "2014-08-12 00:00:05 CDT"

> tail(x)
[1] "2014-08-12 23:59:54 CDT" "2014-08-12 23:59:55 CDT"
[3] "2014-08-12 23:59:56 CDT" "2014-08-12 23:59:57 CDT"
[5] "2014-08-12 23:59:58 CDT" "2014-08-12 23:59:59 CDT"


> head(as.numeric(x - x[1]))
[1] 0 1 2 3 4 5

> tail(as.numeric(x - x[1]))
[1] 86394 86395 86396 86397 86398 86399


Regards,

Marc Schwartz


From wdunlap at tibco.com  Tue Aug 12 21:14:25 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 12 Aug 2014 12:14:25 -0700
Subject: [R] generating a sequence of seconds
In-Reply-To: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
Message-ID: <CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>

> What if I just want the seconds vector without the date, please?  Is there
> a convenient way to create such a vector, please?

Why do you want such a thing?  E.g., do you want it to print the time
of day without the date?  Or are you trying to avoid numeric problems
when you do regressions with the seconds-since-1970 numbers around
1414918800?  Or is there another problem you want solved?

Note that the number of seconds in a day depends on the day and the
time zone.  In US/Pacific time I get:

  > length(seq(from=as.POSIXct("2014-08-12
00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
  [1] 86400
  > length(seq(from=as.POSIXct("2014-03-09
00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
  [1] 82800
  > length(seq(from=as.POSIXct("2014-11-02
00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
  [1] 90000

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> If I would like to generate a sequence of seconds for a date, I would do
> the following:
>
> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
> 23:59:59),by="secs")
>
> What if I just want the seconds vector without the date, please?  Is there
> a convenient way to create such a vector, please?
>
> thanks,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Tue Aug 12 21:26:33 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 12 Aug 2014 15:26:33 -0400
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
Message-ID: <CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>

What I would like to do is to look at several days and determine activities
that happened at times on those days.  I don't really care which days, I
just care about what time.

Thank you!




On Tue, Aug 12, 2014 at 3:14 PM, William Dunlap <wdunlap at tibco.com> wrote:

> > What if I just want the seconds vector without the date, please?  Is
> there
> > a convenient way to create such a vector, please?
>
> Why do you want such a thing?  E.g., do you want it to print the time
> of day without the date?  Or are you trying to avoid numeric problems
> when you do regressions with the seconds-since-1970 numbers around
> 1414918800?  Or is there another problem you want solved?
>
> Note that the number of seconds in a day depends on the day and the
> time zone.  In US/Pacific time I get:
>
>   > length(seq(from=as.POSIXct("2014-08-12
> 00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
>   [1] 86400
>   > length(seq(from=as.POSIXct("2014-03-09
> 00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
>   [1] 82800
>   > length(seq(from=as.POSIXct("2014-11-02
> 00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
>   [1] 90000
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> > Hello!
> >
> > If I would like to generate a sequence of seconds for a date, I would do
> > the following:
> >
> > x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
> > 23:59:59),by="secs")
> >
> > What if I just want the seconds vector without the date, please?  Is
> there
> > a convenient way to create such a vector, please?
> >
> > thanks,
> > Erin
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics
> > University of Houston - Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Aug 12 21:33:25 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 12 Aug 2014 12:33:25 -0700
Subject: [R] generating a sequence of seconds
In-Reply-To: <CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
Message-ID: <CAF8bMcZpXwaVVEo1S8wrmMyUuUMqauW=BLR_nCU777OrOiKPOQ@mail.gmail.com>

If your activities of interest are mainly during the workday then
seconds-since-3am might give good results, avoiding most daylight
savings time issues.  If they are more biologically oriented then
something like seconds before or after sunrise or sunset might be
better.  Both can be expressed as differences between POSIXct times.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Aug 12, 2014 at 12:26 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> What I would like to do is to look at several days and determine activities
> that happened at times on those days.  I don't really care which days, I
> just care about what time.
>
> Thank you!
>
>
>
>
> On Tue, Aug 12, 2014 at 3:14 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> > What if I just want the seconds vector without the date, please?  Is
>> > there
>> > a convenient way to create such a vector, please?
>>
>> Why do you want such a thing?  E.g., do you want it to print the time
>> of day without the date?  Or are you trying to avoid numeric problems
>> when you do regressions with the seconds-since-1970 numbers around
>> 1414918800?  Or is there another problem you want solved?
>>
>> Note that the number of seconds in a day depends on the day and the
>> time zone.  In US/Pacific time I get:
>>
>>   > length(seq(from=as.POSIXct("2014-08-12
>> 00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
>>   [1] 86400
>>   > length(seq(from=as.POSIXct("2014-03-09
>> 00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
>>   [1] 82800
>>   > length(seq(from=as.POSIXct("2014-11-02
>> 00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
>>   [1] 90000
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com>
>> wrote:
>> > Hello!
>> >
>> > If I would like to generate a sequence of seconds for a date, I would do
>> > the following:
>> >
>> > x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
>> > 23:59:59),by="secs")
>> >
>> > What if I just want the seconds vector without the date, please?  Is
>> > there
>> > a convenient way to create such a vector, please?
>> >
>> > thanks,
>> > Erin
>> >
>> >
>> > --
>> > Erin Hodgess
>> > Associate Professor
>> > Department of Mathematical and Statistics
>> > University of Houston - Downtown
>> > mailto: erinm.hodgess at gmail.com
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com


From john.archie.mckown at gmail.com  Tue Aug 12 21:40:26 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 14:40:26 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
Message-ID: <CAAJSdjgmXQhb-_oCW5BZdKyk4S-yTaHqmN-xUDKqrJGPG+H4hA@mail.gmail.com>

On Tue, Aug 12, 2014 at 1:51 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> If I would like to generate a sequence of seconds for a date, I would do
> the following:
>
> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
> 23:59:59),by="secs")
>
> What if I just want the seconds vector without the date, please?  Is there
> a convenient way to create such a vector, please?
>
> thanks,
> Erin
>
>
> --
> Erin Hodgess

I'm a bit confused by this request. The definition of a POSIXct is:
Class "POSIXct" represents the (signed) number of seconds since the
beginning of 1970 (in the UTC time zone) as a numeric vector.

So I don't really know what you mean by the "seconds portion". There
are 24*60*60 or 86,400 seconds in a day. Those seconds are from +0 at
00:00:00 to +86399 for 23:59:59. Is this what you were asking?

seconds_vector <-0:86399; #is the simple way to get the above.

By the definition given above, there is no such thing as a POSIXct
value without a date portion. Any number value will convert to a
date+time. Like a timestamp variable in SQL vs. a time variable.

If you want to display the seconds_vector as "HH:MM:SS" for some
reason, the simple way is:

character_time=sprintf("%02d:%02d:%02d", # C-style formatting string
                                 seconds_vector/3600, # hour value
                                 (seconds_vector%%3600)/60, #minute value
                                 seconds_vector%%60); #second value

You can simply make that a function

getTimePortion <- function(POSIXct_value) {
                            value_in_seconds=as.integer(POSIXct_value);
                            sprintf("%02d:%02d:%02d", # C-style
formatting string
                                     seconds_vector/3600, # hour value
                                     (seconds_vector%%3600)/60, #minute value
                                     seconds_vector%%60); #second value
                  };

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From marc_schwartz at me.com  Tue Aug 12 21:43:54 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 12 Aug 2014 14:43:54 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
Message-ID: <0381C532-F90E-41CE-AB23-CA978AF2FEF0@me.com>

Erin,

Is a sequential resolution of seconds required, as per your original post?

If so, then using my approach and specifying the start and end dates and times will work, with the coercion of the resultant vector to numeric as I included. The method I used (subtracting the first value) will also give you the starting second as 0, or you can alter the math to adjust the origin of the vector as you desire.

As Bill notes, there will be some days where the number of seconds in the day will be something other than 86,400. In Bill's example, it is due to his choosing the start and end dates of daylight savings time in a relevant time zone. Thus, his second date is short an hour, while the third has an extra hour.

Regards,

Marc


On Aug 12, 2014, at 2:26 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> What I would like to do is to look at several days and determine activities
> that happened at times on those days.  I don't really care which days, I
> just care about what time.
> 
> Thank you!
> 
> 
> 
> 
> On Tue, Aug 12, 2014 at 3:14 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
>>> What if I just want the seconds vector without the date, please?  Is
>> there
>>> a convenient way to create such a vector, please?
>> 
>> Why do you want such a thing?  E.g., do you want it to print the time
>> of day without the date?  Or are you trying to avoid numeric problems
>> when you do regressions with the seconds-since-1970 numbers around
>> 1414918800?  Or is there another problem you want solved?
>> 
>> Note that the number of seconds in a day depends on the day and the
>> time zone.  In US/Pacific time I get:
>> 
>>> length(seq(from=as.POSIXct("2014-08-12
>> 00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
>>  [1] 86400
>>> length(seq(from=as.POSIXct("2014-03-09
>> 00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
>>  [1] 82800
>>> length(seq(from=as.POSIXct("2014-11-02
>> 00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
>>  [1] 90000
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com>
>> wrote:
>>> Hello!
>>> 
>>> If I would like to generate a sequence of seconds for a date, I would do
>>> the following:
>>> 
>>> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
>>> 23:59:59),by="secs")
>>> 
>>> What if I just want the seconds vector without the date, please?  Is
>> there
>>> a convenient way to create such a vector, please?
>>> 
>>> thanks,
>>> Erin


From john.archie.mckown at gmail.com  Tue Aug 12 21:44:58 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 14:44:58 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAAJSdjgmXQhb-_oCW5BZdKyk4S-yTaHqmN-xUDKqrJGPG+H4hA@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAAJSdjgmXQhb-_oCW5BZdKyk4S-yTaHqmN-xUDKqrJGPG+H4hA@mail.gmail.com>
Message-ID: <CAAJSdjiUa=8oXBazX0-Wo_zsjzxXEa71Ush5xT-q1o0Ge2y4VA@mail.gmail.com>

On Tue, Aug 12, 2014 at 2:40 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
<snip>
> You can simply make that a function
>
> getTimePortion <- function(POSIXct_value) {
>                             value_in_seconds=as.integer(POSIXct_value);
>                             sprintf("%02d:%02d:%02d", # C-style
> formatting string
>                                      seconds_vector/3600, # hour value
>                                      (seconds_vector%%3600)/60, #minute value
>                                      seconds_vector%%60); #second value
>                   };
>

Sorry, cut'n'pasted that incorrectly

getTimePortion <- function(POSIXct_value) {
                            value_in_seconds=as.integer(POSIXct_value);
                            sprintf("%02d:%02d:%02d", # C-style
                                     value_in_seconds/3600, # hour value
                                     (value_in_seconds%%3600)/60, #minute value
                                     value_in_seconds_vector%%60); #second value
                  };

And the above is "vectorized" and will work if argument has multiple
values in it.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From danmbox at gmail.com  Tue Aug 12 21:46:30 2014
From: danmbox at gmail.com (Dan Muresan)
Date: Tue, 12 Aug 2014 22:46:30 +0300
Subject: [R] pass vector binding to DBI parameter (rsqlite)
In-Reply-To: <CAAJSdjj7s=2yp4fxuKykA9Zq1BeVQoM_6aa-uJ=GWZ1H-PXL-w@mail.gmail.com>
References: <CAJ6Zc6PdDGU+9qF5AoirLX937y4vqvgiFhvmw7epki6QnjuxjA@mail.gmail.com>
	<CAAJSdjj7s=2yp4fxuKykA9Zq1BeVQoM_6aa-uJ=GWZ1H-PXL-w@mail.gmail.com>
Message-ID: <CAJ6Zc6NQ8sJH41rX8Mrg=cRMDwCSfopDaaGqNgQFaVaVD5CS2A@mail.gmail.com>

Yes, of course, that's an obvious work-around, thanks. Another one is
to use temporary tables.

But I'd like to know if binding a vector to an SQL parameter is
possible in rsqlite (or even in the DBI API or with other drivers --
it seems to me it isn't). This seems like a nasty shortcoming
(especially in light of SQL injection, but there are other
considerations).

On 8/12/14, John McKown <john.archie.mckown at gmail.com> wrote:
> On Tue, Aug 12, 2014 at 10:55 AM, Dan Muresan <danmbox at gmail.com> wrote:
>> Hi, is there a way to bind vectors to DBI query parameters? The
>> following tells me that vectors are sent as separate values:
>>
>>> library("RSQLite")
>>> c <- dbConnect (SQLite())
>>> dbGetQuery(c, "create table tst (x int, y int)")
>>> dbGetQuery(c, "insert into tst values (?, ?)", data.frame(x=c (1,2,1,2),
>>> y=c(3, 4, 5, 6)))
>>> dbReadTable(c, "tst")
>>   x y
>> 1 1 3
>> 2 2 4
>> 3 1 5
>> 4 2 6
>>> dbGetQuery(c, "select * from tst where y not in (?)", c(7,6))
>>   x y
>> 1 1 3
>> 2 2 4
>> 3 1 5
>> 4 2 6
>> 5 1 3
>> 6 2 4
>> 7 1 5
>>
>> This looks like 2 result sets (4 + 3 entries), not one.
>>
>> Is there to send multiple values to a '?' binding? Is this at all
>> possible using the R DBI interface (not necessarily with rsqlite)?
>
> I don't really _know_ much, but what I would try would be something like:
>
> dbGetQuery(c,"select * from tst where y not in
> (?)",paste(c(7,6),collapse=','));
>
> The paste(c(7,6),collapse=',') results in the string "6,7". You could
> always subject yourself to a SQL injection attack by doing:
>
> dbGetQuery(c,paste("select * from tst where y not in
> (",c(7,6),")",collapse=','));
>
> If you do this and use a variable instead of the c(7,6), make sure you
> "cleanse" the contents of the variable. Just as making sure that there
> is no "bare" semi-colon in it. And other things that don't come to
> mind off hand.
>
> Hum, perhaps better:
>
> values<-c(7,6);
> dbGetQuery(c,paste("select * from tst where y not in (",
>
> paste(rep('?',length(values)),collapse=','),
>                                 ")"),
>                         values);
>
> As you can see, this dynamically adjusts the number of ? marks in the
> SELECT statement, based on the number of elements in the "values"
> variable.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>


From john.archie.mckown at gmail.com  Tue Aug 12 21:49:21 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 14:49:21 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
Message-ID: <CAAJSdjirLs9NCn03dD8wYWXTGC2CWRPyUATK8641y+FULhYK9Q@mail.gmail.com>

And some people wonder why I absolutely abhor daylight saving time.
I'm not really fond of leap years and leap seconds either. Somebody
needs to fix the Earth's rotation and orbit!

On Tue, Aug 12, 2014 at 2:14 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> What if I just want the seconds vector without the date, please?  Is there
>> a convenient way to create such a vector, please?
>
> Why do you want such a thing?  E.g., do you want it to print the time
> of day without the date?  Or are you trying to avoid numeric problems
> when you do regressions with the seconds-since-1970 numbers around
> 1414918800?  Or is there another problem you want solved?
>
> Note that the number of seconds in a day depends on the day and the
> time zone.  In US/Pacific time I get:
>
>   > length(seq(from=as.POSIXct("2014-08-12
> 00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
>   [1] 86400
>   > length(seq(from=as.POSIXct("2014-03-09
> 00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
>   [1] 82800
>   > length(seq(from=as.POSIXct("2014-11-02
> 00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
>   [1] 90000
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>> Hello!
>>
>> If I would like to generate a sequence of seconds for a date, I would do
>> the following:
>>
>> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
>> 23:59:59),by="secs")
>>
>> What if I just want the seconds vector without the date, please?  Is there
>> a convenient way to create such a vector, please?
>>
>> thanks,
>> Erin
>>
>>
>> --
>> Erin Hodgess
>> Associate Professor
>> Department of Mathematical and Statistics
>> University of Houston - Downtown
>> mailto: erinm.hodgess at gmail.com
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From marc_schwartz at me.com  Tue Aug 12 22:10:56 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 12 Aug 2014 15:10:56 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAAJSdjirLs9NCn03dD8wYWXTGC2CWRPyUATK8641y+FULhYK9Q@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CAAJSdjirLs9NCn03dD8wYWXTGC2CWRPyUATK8641y+FULhYK9Q@mail.gmail.com>
Message-ID: <F4222709-FD83-4794-AB52-1DC42605FD49@me.com>


On Aug 12, 2014, at 2:49 PM, John McKown <john.archie.mckown at gmail.com> wrote:

> And some people wonder why I absolutely abhor daylight saving time.
> I'm not really fond of leap years and leap seconds either. Somebody
> needs to fix the Earth's rotation and orbit!


I have been a longtime proponent of slowing the rotation of the Earth on its axis, so that we could have longer days to be more productive.

Unfortunately, so far, my wish has gone unfulfilled...at least as it is relevant within human lifetimes.

;-)

Regards,

Marc


> 
> On Tue, Aug 12, 2014 at 2:14 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> What if I just want the seconds vector without the date, please?  Is there
>>> a convenient way to create such a vector, please?
>> 
>> Why do you want such a thing?  E.g., do you want it to print the time
>> of day without the date?  Or are you trying to avoid numeric problems
>> when you do regressions with the seconds-since-1970 numbers around
>> 1414918800?  Or is there another problem you want solved?
>> 
>> Note that the number of seconds in a day depends on the day and the
>> time zone.  In US/Pacific time I get:
>> 
>>> length(seq(from=as.POSIXct("2014-08-12
>> 00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
>>  [1] 86400
>>> length(seq(from=as.POSIXct("2014-03-09
>> 00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
>>  [1] 82800
>>> length(seq(from=as.POSIXct("2014-11-02
>> 00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
>>  [1] 90000
>> 
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>> 
>> 
>> On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>> Hello!
>>> 
>>> If I would like to generate a sequence of seconds for a date, I would do
>>> the following:
>>> 
>>> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
>>> 23:59:59),by="secs")
>>> 
>>> What if I just want the seconds vector without the date, please?  Is there
>>> a convenient way to create such a vector, please?
>>> 
>>> thanks,
>>> Erin


From john.archie.mckown at gmail.com  Tue Aug 12 22:16:13 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 15:16:13 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
Message-ID: <CAAJSdjhhz4SQ_s6yW5wFVff9URKt6ZdKHsUbiMschQQ6NqkwtA@mail.gmail.com>

On Tue, Aug 12, 2014 at 2:26 PM, Erin Hodgess <erinm.hodgess at gmail.com>
wrote:
> What I would like to do is to look at several days and determine
activities
> that happened at times on those days.  I don't really care which days, I
> just care about what time.
>
> Thank you!
>

Ah! A light dawns. You want to subset your data based on some part of the
time. Such as "between 13:23:00 and 15:10:01 of each day in the sample."
Ignoring the DST issue, which I shouldn't. It is left as an exercise for
the reader. But usually 13:23 is 13*3600+23*60, 48180, seconds after
midnight. 15:10:01 is 15*3600+10*60+1, 54601, seconds after midnight.
Suppose you have a data.frame() in a variable called myData. Further
suppose that the POSIXct variable in this data.frame is called "when". You
want to subset this into another data.frame() and call it subsetMyData.

subsetMyData<-myData[as.integer(myData$when)%%86400 >= 48180 &
as.integer(myData$when)%%86400 <= 54601,];

Yes, this is ugly. You might make it look nicer, and be easier to
understand, by:

startTime <- as.integer(as.difftime("13:23:00",units="secs")); # start on
or after 1:23 p.m.
endTime <- as.integer(as.difftime("15:10:01",units="secs")); # end on or
before 3:10:01 p.m.
testTime <- as.integer(myData$when)%%86400; #convert to seconds and
eliminate date portion.
subsetMyData <-myData[testTime >= startTime & testTime <= endTime,];

This will work best if myData$when is in GMT instead of local time. Why? No
DST worries. Again, in my opinion, all time date should be recorded in GMT.
Only convert to local time when displaying the data to an ignorant user who
can't handle GMT. Personally, I love to tell people something like: "it is
13:59:30 zulu". In my time zone, today, that is 08:59:30 a.m.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Aug 12 22:23:57 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 12 Aug 2014 13:23:57 -0700
Subject: [R] generating a sequence of seconds
In-Reply-To: <F4222709-FD83-4794-AB52-1DC42605FD49@me.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CAAJSdjirLs9NCn03dD8wYWXTGC2CWRPyUATK8641y+FULhYK9Q@mail.gmail.com>
	<F4222709-FD83-4794-AB52-1DC42605FD49@me.com>
Message-ID: <CACk-te0Qpit7Wg_AcQd5orKswHPKeiCKw7Oj6gVaAqR6D_NxJA@mail.gmail.com>

Marc:

You just need to be more patient -- this is already happening:

http://en.wikipedia.org/wiki/Tidal_acceleration

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Aug 12, 2014 at 1:10 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>
> On Aug 12, 2014, at 2:49 PM, John McKown <john.archie.mckown at gmail.com> wrote:
>
>> And some people wonder why I absolutely abhor daylight saving time.
>> I'm not really fond of leap years and leap seconds either. Somebody
>> needs to fix the Earth's rotation and orbit!
>
>
> I have been a longtime proponent of slowing the rotation of the Earth on its axis, so that we could have longer days to be more productive.
>
> Unfortunately, so far, my wish has gone unfulfilled...at least as it is relevant within human lifetimes.
>
> ;-)
>
> Regards,
>
> Marc
>
>
>>
>> On Tue, Aug 12, 2014 at 2:14 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> What if I just want the seconds vector without the date, please?  Is there
>>>> a convenient way to create such a vector, please?
>>>
>>> Why do you want such a thing?  E.g., do you want it to print the time
>>> of day without the date?  Or are you trying to avoid numeric problems
>>> when you do regressions with the seconds-since-1970 numbers around
>>> 1414918800?  Or is there another problem you want solved?
>>>
>>> Note that the number of seconds in a day depends on the day and the
>>> time zone.  In US/Pacific time I get:
>>>
>>>> length(seq(from=as.POSIXct("2014-08-12
>>> 00:00:00"),to=as.POSIXct("2014-08-12 23:59:59"), by="secs"))
>>>  [1] 86400
>>>> length(seq(from=as.POSIXct("2014-03-09
>>> 00:00:00"),to=as.POSIXct("2014-03-09 23:59:59"), by="secs"))
>>>  [1] 82800
>>>> length(seq(from=as.POSIXct("2014-11-02
>>> 00:00:00"),to=as.POSIXct("2014-11-02 23:59:59"), by="secs"))
>>>  [1] 90000
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Tue, Aug 12, 2014 at 11:51 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>>>> Hello!
>>>>
>>>> If I would like to generate a sequence of seconds for a date, I would do
>>>> the following:
>>>>
>>>> x <- seq(from=as.POSIXct(2014-08-12 00:00:00),to=as.POSIXct(2014-08-12
>>>> 23:59:59),by="secs")
>>>>
>>>> What if I just want the seconds vector without the date, please?  Is there
>>>> a convenient way to create such a vector, please?
>>>>
>>>> thanks,
>>>> Erin
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Aug 12 22:23:48 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 12 Aug 2014 13:23:48 -0700
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAAJSdjhhz4SQ_s6yW5wFVff9URKt6ZdKHsUbiMschQQ6NqkwtA@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
	<CAAJSdjhhz4SQ_s6yW5wFVff9URKt6ZdKHsUbiMschQQ6NqkwtA@mail.gmail.com>
Message-ID: <CAF8bMcbyD26kvAKWhLympNuRGQr=nMViLP-AEqu7FRjWWLi1KQ@mail.gmail.com>

>  Again, in my opinion, all time date should be recorded in GMT.

It depends on context.  If you are studying traffic flow or
electricity usage, then you want local time with all its warts
(perhaps stated as time since 3am so any daylight savings time
problems are confined to a small portion of the data), perhaps along
with time since sunrise and time since sunset.

If you are studying astronomy, then UTC is appropropriate.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Aug 12, 2014 at 1:16 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Tue, Aug 12, 2014 at 2:26 PM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
>> What I would like to do is to look at several days and determine
>> activities
>> that happened at times on those days.  I don't really care which days, I
>> just care about what time.
>>
>> Thank you!
>>
>
> Ah! A light dawns. You want to subset your data based on some part of the
> time. Such as "between 13:23:00 and 15:10:01 of each day in the sample."
> Ignoring the DST issue, which I shouldn't. It is left as an exercise for the
> reader. But usually 13:23 is 13*3600+23*60, 48180, seconds after midnight.
> 15:10:01 is 15*3600+10*60+1, 54601, seconds after midnight. Suppose you have
> a data.frame() in a variable called myData. Further suppose that the POSIXct
> variable in this data.frame is called "when". You want to subset this into
> another data.frame() and call it subsetMyData.
>
> subsetMyData<-myData[as.integer(myData$when)%%86400 >= 48180 &
> as.integer(myData$when)%%86400 <= 54601,];
>
> Yes, this is ugly. You might make it look nicer, and be easier to
> understand, by:
>
> startTime <- as.integer(as.difftime("13:23:00",units="secs")); # start on or
> after 1:23 p.m.
> endTime <- as.integer(as.difftime("15:10:01",units="secs")); # end on or
> before 3:10:01 p.m.
> testTime <- as.integer(myData$when)%%86400; #convert to seconds and
> eliminate date portion.
> subsetMyData <-myData[testTime >= startTime & testTime <= endTime,];
>
> This will work best if myData$when is in GMT instead of local time. Why? No
> DST worries. Again, in my opinion, all time date should be recorded in GMT.
> Only convert to local time when displaying the data to an ignorant user who
> can't handle GMT. Personally, I love to tell people something like: "it is
> 13:59:30 zulu". In my time zone, today, that is 08:59:30 a.m.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown


From john.archie.mckown at gmail.com  Tue Aug 12 22:31:09 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 15:31:09 -0500
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAF8bMcbyD26kvAKWhLympNuRGQr=nMViLP-AEqu7FRjWWLi1KQ@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
	<CAAJSdjhhz4SQ_s6yW5wFVff9URKt6ZdKHsUbiMschQQ6NqkwtA@mail.gmail.com>
	<CAF8bMcbyD26kvAKWhLympNuRGQr=nMViLP-AEqu7FRjWWLi1KQ@mail.gmail.com>
Message-ID: <CAAJSdjh_HuZ9COJxA+Roe7Z4--_6O_GAPvy6o0DktCN2DjC7=w@mail.gmail.com>

On Tue, Aug 12, 2014 at 3:23 PM, William Dunlap <wdunlap at tibco.com> wrote:

> >  Again, in my opinion, all time date should be recorded in GMT.
>
> It depends on context.  If you are studying traffic flow or
> electricity usage, then you want local time with all its warts
> (perhaps stated as time since 3am so any daylight savings time
> problems are confined to a small portion of the data), perhaps along
> with time since sunrise and time since sunset.
>

I see your point. But if my data is in GMT, that is a unique timestamp
value. And, given that, along with location information, I should then be
able to generate a local time for "human activity". E.g. when do people go
to lunch? Another plus of this is that there is no confusion during "fall
back" whether this is the 1st or 2nd instance of something like 02:27:00.
Long ago, I worked for a city government. The recorded everything on the
machine in local time. Including police log entries. Always made me wonder
why some lawyer didn't have a nice window of confusion if something
allegedly happened on time change day and was logged as 02:30:00.


>
> If you are studying astronomy, then UTC is appropropriate.
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Tue Aug 12 22:34:52 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 12 Aug 2014 15:34:52 -0500
Subject: [R] pass vector binding to DBI parameter (rsqlite)
In-Reply-To: <CAJ6Zc6NQ8sJH41rX8Mrg=cRMDwCSfopDaaGqNgQFaVaVD5CS2A@mail.gmail.com>
References: <CAJ6Zc6PdDGU+9qF5AoirLX937y4vqvgiFhvmw7epki6QnjuxjA@mail.gmail.com>
	<CAAJSdjj7s=2yp4fxuKykA9Zq1BeVQoM_6aa-uJ=GWZ1H-PXL-w@mail.gmail.com>
	<CAJ6Zc6NQ8sJH41rX8Mrg=cRMDwCSfopDaaGqNgQFaVaVD5CS2A@mail.gmail.com>
Message-ID: <CAAJSdjisvnp9EBYF3iQ0GRDU98GPQbxHWgbek6j+9447P3yt3Q@mail.gmail.com>

On Tue, Aug 12, 2014 at 2:46 PM, Dan Muresan <danmbox at gmail.com> wrote:

> Yes, of course, that's an obvious work-around, thanks. Another one is
> to use temporary tables.
>
> But I'd like to know if binding a vector to an SQL parameter is
> possible in rsqlite (or even in the DBI API or with other drivers --
> it seems to me it isn't). This seems like a nasty shortcoming
> (especially in light of SQL injection, but there are other
> considerations).
>
>
That type of binding seems to be something that was overlooked when the API
was being designed. Or, as some vendor might say: "we considered that, but
decided to reject it due to the difficulty of implementation and lack of
need in the vast majority of cases".

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From ron_michael70 at yahoo.com  Tue Aug 12 21:57:29 2014
From: ron_michael70 at yahoo.com (Ron Michael)
Date: Wed, 13 Aug 2014 03:57:29 +0800
Subject: [R] A basic statistics question
Message-ID: <1407873449.69033.YahooMailNeo@web190501.mail.sg3.yahoo.com>

Hi,

I would need to get a clarification on a quite fundamental statistics property, hope expeRts here would not mind if I post that here.

I leant that variance-covariance matrix of the standardized data is equal to the correlation matrix for the unstandardized data. So I used following data.

Data <- structure(c(7L, 5L, 9L, 7L, 8L, 7L, 6L, 6L, 5L, 7L, 8L, 6L, 7L,  7L, 6L, 7L, 7L, 6L, 8L, 6L, 7L, 7L, 7L, 8L, 7L, 9L, 8L, 7L, 7L,  0L, 10L, 10L, 10L, 7L, 6L, 8L, 5L, 5L, 6L, 6L, 7L, 11L, 9L, 10L,  0L, 13L, 13L, 10L, 7L, 7L, 7L, 10L, 7L, 5L, 8L, 7L, 10L, 10L,  10L, 6L, 7L, 6L, 6L, 8L, 8L, 7L, 7L, 7L, 7L, 8L, 7L, 8L, 6L,  6L, 8L, 7L, 4L, 7L, 7L, 10L, 10L, 6L, 7L, 7L, 12L, 12L, 8L, 5L,  5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 5L, 4L, 5L, 5L, 5L, 6L,  7L, 5L, 7L, 5L, 7L, 7L, 7L, 7L, 8L, 7L, 6L, 7L, 7L, 6L, 7L, 7L,  6L, 4L, 4L, 6L, 6L, 7L, 8L, 7L, 11L, 10L, 8L, 7L, 6L, 6L, 11L,  5L, 4L, 6L, 6L, 6L, 7L, 8L, 7L, 12L, 4L, 4L, 2L, 5L, 6L, 7L,  6L, 6L, 5L, 6L, 5L, 7L, 7L, 7L, 6L, 5L, 6L, 6L, 5L, 5L, 6L, 6L,  4L, 4L, 5L, 10L, 10L, 7L, 7L, 6L, 4L, 6L, 10L, 7L, 4L, 6L, 6L,  6L, 8L, 8L, 8L, 7L, 8L, 9L, 10L, 7L, 6L, 6L, 8L, 6L, 8L, 3L,  3L, 4L, 5L, 5L, 6L, 5L, 5L, 6L, 4L, 8L, 7L, 3L, 5L, 6L, 9L, 8L,  9L, 10L, 8L, 9L, 8L, 9L, 8L, 8L, 9L, 11L, 10L, 9L, 9L, 13L,
 13L,  10L, 7L, 7L, 7L, 9L, 8L, 7L, 6L, 10L, 8L, 7L, 8L, 8L, 3L, 4L,  3L, 7L, 6L, 6L, 6L, 6L, 5L, 6L, 6L, 6L, 2L, 5L, 7L, 9L, 8L, 9L,  10L, 8L, 8L, 9L, 9L, 11L, 11L, 11L, 10L, 9L, 9L, 11L, 2L, 3L,  2L, 2L, 2L, 1L, 4L, 4L, 2L, 2L, 1L, 1L, 1L, 3L, 3L, 4L, 6L, 4L,  5L, 2L, 3L, 5L, 4L, 4L, 2L, 4L, 4L, 5L, 4L, 2L, 7L, 3L, 3L, 10L,  13L, 11L, 9L, 9L, 7L, 8L, 9L, 6L, 7L, 6L, 5L, 3L, 13L, 3L, 3L,  0L, 1L, 4L, 5L, 3L, 3L, 0L, 2L, 20L, 3L, 2L, 6L, 5L, 5L, 5L,  2L, 2L, 5L, 5L, 5L, 4L, 3L, 4L, 4L, 3L, 4L, 10L, 10L, 9L, 8L,  4L, 4L, 8L, 7L, 10L, 3L, 1L, 9L, 5L, 11L, 9L), .Dim = c(45L,  8L), .Dimnames = list(NULL, c("V1", "V7", "V13", "V19", "V25",  "V31", "V37", "V43"))) 

????	
Data_Normalized <- apply(Data, 2, function(x) return((x - mean(x))/sd(x))) 

(t(Data_Normalized) %*% Data_Normalized)/dim(Data_Normalized)[1]



Point is that I am not getting exact?CORR matrix. Can somebody point me what I am missing here?

Thanks for your pointer.?


From erinm.hodgess at gmail.com  Tue Aug 12 23:07:04 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 12 Aug 2014 17:07:04 -0400
Subject: [R] generating a sequence of seconds
In-Reply-To: <CAAJSdjh_HuZ9COJxA+Roe7Z4--_6O_GAPvy6o0DktCN2DjC7=w@mail.gmail.com>
References: <CACxE24kujUVv0fTmbdYP1QNSrHozMuWYXDekSmZbKOdztM9=+g@mail.gmail.com>
	<CAF8bMcZuwyydgMv+q16Q5ONOVVifJNrNgVBaeqf3ZrStamN9FA@mail.gmail.com>
	<CACxE24nMGvYHueRSq7cT6T8PjXP0JOXDW_tT4kk4o7Bw_sC8Vg@mail.gmail.com>
	<CAAJSdjhhz4SQ_s6yW5wFVff9URKt6ZdKHsUbiMschQQ6NqkwtA@mail.gmail.com>
	<CAF8bMcbyD26kvAKWhLympNuRGQr=nMViLP-AEqu7FRjWWLi1KQ@mail.gmail.com>
	<CAAJSdjh_HuZ9COJxA+Roe7Z4--_6O_GAPvy6o0DktCN2DjC7=w@mail.gmail.com>
Message-ID: <CACxE24mX3R3ZW3gBchpUW3M6JNH7yjMTrXn8bMoJO_35f-GtOQ@mail.gmail.com>

Great!

Thank you!

I think the function with the C-like function should do the trick.




On Tue, Aug 12, 2014 at 4:31 PM, John McKown <john.archie.mckown at gmail.com>
wrote:

> On Tue, Aug 12, 2014 at 3:23 PM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> >  Again, in my opinion, all time date should be recorded in GMT.
>>
>> It depends on context.  If you are studying traffic flow or
>> electricity usage, then you want local time with all its warts
>> (perhaps stated as time since 3am so any daylight savings time
>> problems are confined to a small portion of the data), perhaps along
>> with time since sunrise and time since sunset.
>>
>
> I see your point. But if my data is in GMT, that is a unique timestamp
> value. And, given that, along with location information, I should then be
> able to generate a local time for "human activity". E.g. when do people go
> to lunch? Another plus of this is that there is no confusion during "fall
> back" whether this is the 1st or 2nd instance of something like 02:27:00.
> Long ago, I worked for a city government. The recorded everything on the
> machine in local time. Including police log entries. Always made me wonder
> why some lawyer didn't have a nice window of confusion if something
> allegedly happened on time change day and was logged as 02:30:00.
>
>
>>
>> If you are studying astronomy, then UTC is appropropriate.
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From Ted.Harding at wlandres.net  Tue Aug 12 23:32:32 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Tue, 12 Aug 2014 22:32:32 +0100 (BST)
Subject: [R] A basic statistics question
In-Reply-To: <1407873449.69033.YahooMailNeo@web190501.mail.sg3.yahoo.com>
Message-ID: <XFMail.20140812223232.Ted.Harding@wlandres.net>

On 12-Aug-2014 19:57:29 Ron Michael wrote:
> Hi,
> 
> I would need to get a clarification on a quite fundamental statistics
> property, hope expeRts here would not mind if I post that here.
> 
> I leant that variance-covariance matrix of the standardized data is equal to
> the correlation matrix for the unstandardized data. So I used following data.
> 
> Data <- structure(c(7L, 5L, 9L, 7L, 8L, 7L, 6L, 6L, 5L, 7L, 8L, 6L, 7L,  7L,
> 6L, 7L, 7L, 6L, 8L, 6L, 7L, 7L, 7L, 8L, 7L, 9L, 8L, 7L, 7L,  0L, 10L, 10L,
> 10L, 7L, 6L, 8L, 5L, 5L, 6L, 6L, 7L, 11L, 9L, 10L,  0L, 13L, 13L, 10L, 7L,
> 7L, 7L, 10L, 7L, 5L, 8L, 7L, 10L, 10L,  10L, 6L, 7L, 6L, 6L, 8L, 8L, 7L, 7L,
> 7L, 7L, 8L, 7L, 8L, 6L,  6L, 8L, 7L, 4L, 7L, 7L, 10L, 10L, 6L, 7L, 7L, 12L,
> 12L, 8L, 5L,  5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 5L, 4L, 5L, 5L, 5L, 6L,
> 7L, 5L, 7L, 5L, 7L, 7L, 7L, 7L, 8L, 7L, 6L, 7L, 7L, 6L, 7L, 7L,  6L, 4L, 4L,
> 6L, 6L, 7L, 8L, 7L, 11L, 10L, 8L, 7L, 6L, 6L, 11L,  5L, 4L, 6L, 6L, 6L, 7L,
> 8L, 7L, 12L, 4L, 4L, 2L, 5L, 6L, 7L,  6L, 6L, 5L, 6L, 5L, 7L, 7L, 7L, 6L, 5L,
> 6L, 6L, 5L, 5L, 6L, 6L,  4L, 4L, 5L, 10L, 10L, 7L, 7L, 6L, 4L, 6L, 10L, 7L,
> 4L, 6L, 6L,  6L, 8L, 8L, 8L, 7L, 8L, 9L, 10L, 7L, 6L, 6L, 8L, 6L, 8L, 3L, 
> 3L, 4L, 5L, 5L, 6L, 5L, 5L, 6L, 4L, 8L, 7L, 3L, 5L, 6L, 9L, 8L,  9L, 10L, 8L,
> 9L, 8L, 9L, 8L, 8L, 9L, 11L, 10L, 9L, 9L, 13L,
>  13L,  10L, 7L, 7L, 7L, 9L, 8L, 7L, 6L, 10L, 8L, 7L, 8L, 8L, 3L, 4L,  3L, 7L,
> 6L, 6L, 6L, 6L, 5L, 6L, 6L, 6L, 2L, 5L, 7L, 9L, 8L, 9L,  10L, 8L, 8L, 9L, 9L,
> 11L, 11L, 11L, 10L, 9L, 9L, 11L, 2L, 3L,  2L, 2L, 2L, 1L, 4L, 4L, 2L, 2L, 1L,
> 1L, 1L, 3L, 3L, 4L, 6L, 4L,  5L, 2L, 3L, 5L, 4L, 4L, 2L, 4L, 4L, 5L, 4L, 2L,
> 7L, 3L, 3L, 10L,  13L, 11L, 9L, 9L, 7L, 8L, 9L, 6L, 7L, 6L, 5L, 3L, 13L, 3L,
> 3L,  0L, 1L, 4L, 5L, 3L, 3L, 0L, 2L, 20L, 3L, 2L, 6L, 5L, 5L, 5L,  2L, 2L,
> 5L, 5L, 5L, 4L, 3L, 4L, 4L, 3L, 4L, 10L, 10L, 9L, 8L,  4L, 4L, 8L, 7L, 10L,
> 3L, 1L, 9L, 5L, 11L, 9L), .Dim = c(45L,  8L), .Dimnames = list(NULL, c("V1",
> "V7", "V13", "V19", "V25",  "V31", "V37", "V43"))) 
> 
> ____  
> Data_Normalized <- apply(Data, 2, function(x) return((x - mean(x))/sd(x))) 
> 
> (t(Data_Normalized) %*% Data_Normalized)/dim(Data_Normalized)[1]
> 
> 
> 
> Point is that I am not getting exact CORR matrix. Can somebody point me
> what I am missing here?
> 
> Thanks for your pointer.

Try:
  Data_Normalized <- apply(Data, 2, function(x) return((x - mean(x))/sd(x)))
  (t(Data_Normalized) %*% Data_Normalized)/(dim(Data_Normalized)[1]-1)

and compare the result with

  cor(Data)

And why? Look at

  ?sd

and note that:

  Details:
     Like 'var' this uses denominator n - 1.

Hoping this helps,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 12-Aug-2014  Time: 22:32:26
This message was sent by XFMail


From r.turner at auckland.ac.nz  Tue Aug 12 23:41:52 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 13 Aug 2014 09:41:52 +1200
Subject: [R] A basic statistics question
In-Reply-To: <1407873449.69033.YahooMailNeo@web190501.mail.sg3.yahoo.com>
References: <1407873449.69033.YahooMailNeo@web190501.mail.sg3.yahoo.com>
Message-ID: <53EA8A20.5070500@auckland.ac.nz>

On 13/08/14 07:57, Ron Michael wrote:
> Hi,
>
> I would need to get a clarification on a quite fundamental statistics property, hope expeRts here would not mind if I post that here.
>
> I leant that variance-covariance matrix of the standardized data is equal to the correlation matrix for the unstandardized data. So I used following data.

<SNIP>

> (t(Data_Normalized) %*% Data_Normalized)/dim(Data_Normalized)[1]
>
>
>
> Point is that I am not getting exact CORR matrix. Can somebody point me what I am missing here?

You are using a denominator of "n" in calculating your "covariance" 
matrix for your normalized data.  But these data were normalized using 
the sd() function which (correctly) uses a denominator of n-1 so as to 
obtain an unbiased estimator of the population standard deviation.

If you calculated

    (t(Data_Normalized) %*% Data_Normalized)/(dim(Data_Normalized)[1]-1)

then you would get the same result as you get from cor(Data) (to within 
about 1e-15).

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From Ted.Harding at wlandres.net  Wed Aug 13 00:22:13 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Tue, 12 Aug 2014 23:22:13 +0100 (BST)
Subject: [R] A basic statistics question
In-Reply-To: <53EA8A20.5070500@auckland.ac.nz>
Message-ID: <XFMail.20140812232213.Ted.Harding@wlandres.net>

On 12-Aug-2014 21:41:52 Rolf Turner wrote:
> On 13/08/14 07:57, Ron Michael wrote:
>> Hi,
>>
>> I would need to get a clarification on a quite fundamental statistics
>> property, hope expeRts here would not mind if I post that here.
>>
>> I leant that variance-covariance matrix of the standardized data is equal to
>> the correlation matrix for the unstandardized data. So I used following
>> data.
> 
> <SNIP>
> 
>> (t(Data_Normalized) %*% Data_Normalized)/dim(Data_Normalized)[1]
>>
>> Point is that I am not getting exact CORR matrix. Can somebody point
>> me what I am missing here?
> 
> You are using a denominator of "n" in calculating your "covariance" 
> matrix for your normalized data.  But these data were normalized using 
> the sd() function which (correctly) uses a denominator of n-1 so as to 
> obtain an unbiased estimator of the population standard deviation.
> 
> If you calculated
> 
>     (t(Data_Normalized) %*% Data_Normalized)/(dim(Data_Normalized)[1]-1)
> 
> then you would get the same result as you get from cor(Data) (to within 
> about 1e-15).
> 
> cheers,
> Rolf Turner

One could argue about "(correctly)"!

>From the "descriptive statistics" point of view, if one is given a single
number x, then this dataset has no variation, so one could say that
sd(x) = 0. And this is what one would get with a denominator of "n".

But if the single value x is viewed as sampled from a distribution
(with positive dispersion), then the value of x gives no information
about the SD of the distribution. If you use denominator (n-1) then
sd(x) = NA, i.e. is indeterminate (as it should be in this application).

The important thing when using pre-programmed functions is to know
which is being used. R uses (n-1), and this can be found from
looking at

  ?sd

or (with more detail) at

  ?cor

Ron had assumed that the denominator was n, apparently not being aware
that R uses (n-1).

Just a few thoughts ...
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 12-Aug-2014  Time: 23:22:09
This message was sent by XFMail


From jdnewmil at dcn.davis.CA.us  Wed Aug 13 02:01:44 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 12 Aug 2014 17:01:44 -0700
Subject: [R] pass vector binding to DBI parameter (rsqlite)
In-Reply-To: <CAJ6Zc6NQ8sJH41rX8Mrg=cRMDwCSfopDaaGqNgQFaVaVD5CS2A@mail.gmail.com>
References: <CAJ6Zc6PdDGU+9qF5AoirLX937y4vqvgiFhvmw7epki6QnjuxjA@mail.gmail.com>
	<CAAJSdjj7s=2yp4fxuKykA9Zq1BeVQoM_6aa-uJ=GWZ1H-PXL-w@mail.gmail.com>
	<CAJ6Zc6NQ8sJH41rX8Mrg=cRMDwCSfopDaaGqNgQFaVaVD5CS2A@mail.gmail.com>
Message-ID: <5f826837-cce7-4c9c-9c34-ca585dbf01dd@email.android.com>

I am not quite sure what you are complaining about. The ODBC interface definition is not vectorized, and that has nothing to do with R... that applies across all platforms I have seen. The DBI API is consistent with that. There are some proprietary APIs that implement bulk data transfers, but then you are stuck with that API.
It might be appropriate to discuss this on R-sig-db if you have better information than I do.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 12, 2014 12:46:30 PM PDT, Dan Muresan <danmbox at gmail.com> wrote:
>Yes, of course, that's an obvious work-around, thanks. Another one is
>to use temporary tables.
>
>But I'd like to know if binding a vector to an SQL parameter is
>possible in rsqlite (or even in the DBI API or with other drivers --
>it seems to me it isn't). This seems like a nasty shortcoming
>(especially in light of SQL injection, but there are other
>considerations).
>
>On 8/12/14, John McKown <john.archie.mckown at gmail.com> wrote:
>> On Tue, Aug 12, 2014 at 10:55 AM, Dan Muresan <danmbox at gmail.com>
>wrote:
>>> Hi, is there a way to bind vectors to DBI query parameters? The
>>> following tells me that vectors are sent as separate values:
>>>
>>>> library("RSQLite")
>>>> c <- dbConnect (SQLite())
>>>> dbGetQuery(c, "create table tst (x int, y int)")
>>>> dbGetQuery(c, "insert into tst values (?, ?)", data.frame(x=c
>(1,2,1,2),
>>>> y=c(3, 4, 5, 6)))
>>>> dbReadTable(c, "tst")
>>>   x y
>>> 1 1 3
>>> 2 2 4
>>> 3 1 5
>>> 4 2 6
>>>> dbGetQuery(c, "select * from tst where y not in (?)", c(7,6))
>>>   x y
>>> 1 1 3
>>> 2 2 4
>>> 3 1 5
>>> 4 2 6
>>> 5 1 3
>>> 6 2 4
>>> 7 1 5
>>>
>>> This looks like 2 result sets (4 + 3 entries), not one.
>>>
>>> Is there to send multiple values to a '?' binding? Is this at all
>>> possible using the R DBI interface (not necessarily with rsqlite)?
>>
>> I don't really _know_ much, but what I would try would be something
>like:
>>
>> dbGetQuery(c,"select * from tst where y not in
>> (?)",paste(c(7,6),collapse=','));
>>
>> The paste(c(7,6),collapse=',') results in the string "6,7". You could
>> always subject yourself to a SQL injection attack by doing:
>>
>> dbGetQuery(c,paste("select * from tst where y not in
>> (",c(7,6),")",collapse=','));
>>
>> If you do this and use a variable instead of the c(7,6), make sure
>you
>> "cleanse" the contents of the variable. Just as making sure that
>there
>> is no "bare" semi-colon in it. And other things that don't come to
>> mind off hand.
>>
>> Hum, perhaps better:
>>
>> values<-c(7,6);
>> dbGetQuery(c,paste("select * from tst where y not in (",
>>
>> paste(rep('?',length(values)),collapse=','),
>>                                 ")"),
>>                         values);
>>
>> As you can see, this dynamically adjusts the number of ? marks in the
>> SELECT statement, based on the number of elements in the "values"
>> variable.
>>
>> --
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>>
>> Maranatha! <><
>> John McKown
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From oriolebaltimore at gmail.com  Wed Aug 13 02:14:50 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Tue, 12 Aug 2014 20:14:50 -0400
Subject: [R] populating matrix with binary variable after matching data from
	data frame
Message-ID: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>

Hi:
sorry I have a basic question.

I have a data frame with two columns:
> x1
      V1       V2
1   AKT3    TCL1A
2  AKTIP    VPS41
3  AKTIP    PDPK1
4  AKTIP   GTF3C1
5  AKTIP    HOOK2
6  AKTIP    POLA2
7  AKTIP KIAA1377
8  AKTIP FAM160A2
9  AKTIP    VPS16
10 AKTIP    VPS18


I have a matrix 1211x1211 (using some elements in x1$V1 and some from
x1$V2). I want to populate for every match for example AKT3 = TCL1A = 1
whereas AKT3 - VPS41 gets 0)
How can i map this binary relations in x.


>x
       TCLA1 VPS41 ABCA13 ABCA4
AKT3       0     0      0     0
AKTIP      0     0      0     0
ABCA13     0     0      0     0
ABCA4      0     0      0     0


dput -

x = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim =
c(4L,
4L), .Dimnames = list(c("AKT3", "AKTIP", "ABCA13", "ABCA4"
), c("TCLA1", "VPS41", "ABCA13", "ABCA4")))

x1 = structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
"AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
"VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
"VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
10L), class = "data.frame")



Thanks
Adrian

	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Wed Aug 13 05:27:23 2014
From: smartpink111 at yahoo.com (arun)
Date: Tue, 12 Aug 2014 20:27:23 -0700
Subject: [R] populating matrix with binary variable after matching data
	from	data frame
In-Reply-To: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
Message-ID: <1407900443.55200.YahooMailNeo@web142601.mail.bf1.yahoo.com>

You could try:
x1$V2[1] <- "TCLA1"


? x[outer(rownames(x), colnames(x), FUN=paste) %in% as.character(interaction(x1, sep=" "))] <- 1
x
?????? TCLA1 VPS41 ABCA13 ABCA4
AKT3?????? 1???? 0????? 0???? 0
AKTIP????? 0???? 1????? 0???? 0
ABCA13???? 0???? 0????? 0???? 0
ABCA4????? 0???? 0????? 0???? 0
A.K.


On Tuesday, August 12, 2014 8:16 PM, Adrian Johnson <oriolebaltimore at gmail.com> wrote:
Hi:
sorry I have a basic question.

I have a data frame with two columns:
> x1
? ? ? V1? ? ?  V2
1?  AKT3? ? TCL1A
2? AKTIP? ? VPS41
3? AKTIP? ? PDPK1
4? AKTIP?  GTF3C1
5? AKTIP? ? HOOK2
6? AKTIP? ? POLA2
7? AKTIP KIAA1377
8? AKTIP FAM160A2
9? AKTIP? ? VPS16
10 AKTIP? ? VPS18


I have a matrix 1211x1211 (using some elements in x1$V1 and some from
x1$V2). I want to populate for every match for example AKT3 = TCL1A = 1
whereas AKT3 - VPS41 gets 0)
How can i map this binary relations in x.


>x
? ? ?  TCLA1 VPS41 ABCA13 ABCA4
AKT3? ? ?  0? ?  0? ? ? 0? ?  0
AKTIP? ? ? 0? ?  0? ? ? 0? ?  0
ABCA13? ?  0? ?  0? ? ? 0? ?  0
ABCA4? ? ? 0? ?  0? ? ? 0? ?  0


dput -

x = structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim =
c(4L,
4L), .Dimnames = list(c("AKT3", "AKTIP", "ABCA13", "ABCA4"
), c("TCLA1", "VPS41", "ABCA13", "ABCA4")))

x1 = structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
"AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
"VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
"VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
10L), class = "data.frame")



Thanks
Adrian

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From john.pura at duke.edu  Wed Aug 13 06:42:06 2014
From: john.pura at duke.edu (John Pura)
Date: Wed, 13 Aug 2014 04:42:06 +0000
Subject: [R] Cox regression model for matched data with replacement
Message-ID: <9E8C049A006DEE48BAB785BC6BCD7FE31895B1C7@ex-mbg-04.win.duke.edu>

I am curious about this problem as well. How do you go about creating the weights for each pair, and are you suggesting that we can just incorporate a weight statement in the model as opposed to the strata statement? And Dr. Therneau, let's say I have 140 cases matched with replacement to 2 controls. Is my id variable the number of cases?

Thanks,
John

	[[alternative HTML version deleted]]


From neotropical.bats at gmail.com  Wed Aug 13 13:26:29 2014
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Wed, 13 Aug 2014 07:26:29 -0400
Subject: [R] New reshape2 question
In-Reply-To: <1366653815.44106.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <51729E37.6090901@gmail.com>
	<1366563896.71414.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<517449B8.6070304@gmail.com>
	<1366580336.79468.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517465D3.3060403@gmail.com>
	<1366589915.23423.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1366590216.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51748DC2.5070901@gmail.com>
	<1366593591.56084.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51749599.1070203@gmail.com>
	<1366595143.96394.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51750644.3080306@gmail.com>
	<1366634744.51811.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<5175395A.90703@gmail.com>
	<1366638500.75965.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517545FF.4090006@gmail.com>
	<1366643420.91270.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<517557FC.8020605@gmail.com>
	<1366647379.43478.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51756B86.7050302@gmail.com>
	<1366653815.44106.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <53EB4B65.5030209@gmail.com>

Hi all,

Thanks go out to those who provided helpful suggestions last year with a 
similar issue.

I am working with a new data set and trying what I assumed was a simple 
aggregation in reshape2 but is not working.  I have a large number of 
similar data sets to run so getting the code correct is important.

I have tried this code line in bold (both plyr and reshape2 are loaded):

 > ChenaPond <- read.table("C:/Bat papers in prep/Chile/Data & 
analyses/ChenaPond.txt",header=T,sep="\t",quote="")
dat1<-ChenaPond
 >*res2<-ddply(dat1,.(Location,Species),summarize, Time=sum(Time))*

*Error in Summary.factor(c(3L, 4L, 5L, 15L, 39L, 45L, 18L, 24L, 25L, 
26L,  :
   sum not meaningful for factors*

Attached is the data.  Not sure why it is all factors and when I tried 
changing to double precision the times were corrupted.  I recall that R 
does not do well with time values.  Do I need a line using chron as well 
beforehand?

I even tried for several hours looking at the ReshapeGUI package to see 
what I may have been doing incorrectly to no avail.

 1. What I need to do to analyze all the data in another program is to
    reformat it so that I have a Species by Time matrix summarized in 5
    minute time blocks.  The result needs to be Species as rows, and
    time intervals are arranged chronologically in columns.
 2. Then I need the matrix converted such that each unique Species will
    have proportional abundances of time (0 to 100) so totals for each
    species should be the same (or 100%).


What do folks suggest?
Plyr, Reshape2 or try tables?

Thanks,

Bruce



-- 
Bruce W. Miller, PhD.
Neotropical bat risk assessments

If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet

Using acoustic sampling to map species distributions for >15 years.

Providing Interactive identification keys to the vocal signatures of New World Bats

For various project details see:

https://sites.google.com/site/batsoundservices/

-------------- next part --------------
Species	Location	Date	Time
Myochi	Chena  pond	5/26/09	18:38
Lascin	Chena  pond	5/26/09	18:51
Lascin	Chena  pond	5/26/09	19:38
Lascin	Chena  pond	5/26/09	19:39
Tadbra	Chena  pond	5/26/09	19:47
Lasvar	Chena  pond	5/26/09	20:12
Lasvar	Chena  pond	5/26/09	20:16
Lasvar	Chena  pond	5/26/09	20:56
Lascin	Chena  pond	5/26/09	21:19
Tadbra	Chena  pond	5/26/09	21:20
Lascin	Chena  pond	5/26/09	22:47
Lascin	Chena  pond	5/26/09	22:56
Lasvar	Chena  pond	10/15/09	20:51
Lasvar	Chena  pond	10/15/09	20:55
Lasvar	Chena  pond	10/15/09	20:56
Lasvar	Chena  pond	10/15/09	20:57
Lasvar	Chena  pond	10/15/09	20:59
Myochi	Chena  pond	10/15/09	21:00
Myochi	Chena  pond	10/15/09	21:26
Lascin	Chena  pond	10/15/09	21:29
Lasvar	Chena  pond	10/15/09	21:33
Lasvar	Chena  pond	10/15/09	21:34
Lasvar	Chena  pond	10/15/09	21:35
Myochi	Chena  pond	10/15/09	21:55
Lasvar	Chena  pond	10/15/09	21:56
Lascin	Chena  pond	10/15/09	21:59
Lascin	Chena  pond	10/15/09	22:00
Lascin	Chena  pond	10/15/09	22:01
Myochi	Chena  pond	10/15/09	22:03
Myochi	Chena  pond	10/15/09	22:08
Myochi	Chena  pond	10/15/09	22:08
Myochi	Chena  pond	10/15/09	22:09
Lascin	Chena  pond	10/15/09	22:17
Lasvar	Chena  pond	10/15/09	22:23
Lasvar	Chena  pond	10/15/09	22:24
Myochi	Chena  pond	10/15/09	22:26
Lasvar	Chena  pond	10/15/09	22:30
Lasvar	Chena  pond	10/15/09	22:31
Lascin	Chena  pond	10/15/09	22:42
Lasvar	Chena  pond	10/15/09	22:42
Lasvar	Chena  pond	10/15/09	22:44
Lascin	Chena  pond	10/15/09	22:46
Lascin	Chena  pond	10/15/09	22:49
Tadbra	Chena  pond	10/15/09	22:49
Lascin	Chena  pond	10/15/09	22:50
Lascin	Chena  pond	10/15/09	22:51
Lascin	Chena  pond	10/15/09	22:53
Lascin	Chena  pond	10/15/09	22:54
Lascin	Chena  pond	10/15/09	22:57
Lasvar	Chena  pond	10/15/09	23:01
Lasvar	Chena  pond	10/15/09	23:06
Lascin	Chena  pond	10/15/09	23:08
Lasvar	Chena  pond	10/15/09	23:09
Tadbra	Chena  pond	10/15/09	23:14
Myochi	Chena  pond	10/15/09	23:30
Myochi	Chena  pond	10/15/09	23:31
Lasvar	Chena  pond	10/15/09	23:33
Myochi	Chena  pond	10/15/09	23:35
Myochi	Chena  pond	10/15/09	23:35
Myochi	Chena  pond	10/15/09	23:38
Lasvar	Chena  pond	10/15/09	23:39
Lasvar	Chena  pond	10/15/09	23:44
Tadbra	Chena  pond	10/15/09	23:45
Lasvar	Chena  pond	10/15/09	23:47
Lasvar	Chena  pond	10/15/09	23:52
Lasvar	Chena  pond	10/15/09	23:59
Tadbra	Chena  pond	10/16/09	0:00



From therneau at mayo.edu  Wed Aug 13 14:18:11 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 13 Aug 2014 07:18:11 -0500
Subject: [R] Cox regression model for matched data with replacement
In-Reply-To: <mailman.23.1407924008.3188.r-help@r-project.org>
References: <mailman.23.1407924008.3188.r-help@r-project.org>
Message-ID: <27747b$92apsc@ironport10.mayo.edu>



On 08/13/2014 05:00 AM, John Purda wrote:
> I am curious about this problem as well. How do you go about creating the weights for each pair, and are you suggesting that we can just incorporate a weight statement in the model as opposed to the strata statement? And Dr. Therneau, let's say I have 140 cases matched with replacement to 2 controls. Is my id variable the number of cases?
>

  The above has an incorrect assumption that I notice ALL survival questions on the list 
-- which was false in this case.  Could you clue me in as to the original question and 
discussion -- assuming that you want "Dr Therneau" to respond intelligently :-)

Terry T.


From john.archie.mckown at gmail.com  Wed Aug 13 14:28:06 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 13 Aug 2014 07:28:06 -0500
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
Message-ID: <CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>

On Tue, Aug 12, 2014 at 7:14 PM, Adrian Johnson <oriolebaltimore at gmail.com>
wrote:

> Hi:
> sorry I have a basic question.
>
> I have a data frame with two columns:
> > x1
>       V1       V2
> 1   AKT3    TCL1A
> 2  AKTIP    VPS41
> 3  AKTIP    PDPK1
> 4  AKTIP   GTF3C1
> 5  AKTIP    HOOK2
> 6  AKTIP    POLA2
> 7  AKTIP KIAA1377
> 8  AKTIP FAM160A2
> 9  AKTIP    VPS16
> 10 AKTIP    VPS18
>
>
> I have a matrix 1211x1211 (using some elements in x1$V1 and some from
> x1$V2). I want to populate for every match for example AKT3 = TCL1A = 1
> whereas AKT3 - VPS41 gets 0)
> How can i map this binary relations in x.
>
>
> >x
>        TCLA1 VPS41 ABCA13 ABCA4
> AKT3       0     0      0     0
> AKTIP      0     0      0     0
> ABCA13     0     0      0     0
> ABCA4      0     0      0     0
>
>
<snip>

I'm not totally sure that I understand your data structure. So I will
rephrase a bit so that I can be corrected, if necessary. You have an
1211x1121 matrix already. Every cell in the matrix is initialized to 0. It
has column names such as TCLA1, VPS41, ABCA13, ABCA4, ... and it has row
names such as AKT3 AKTPI, ABCA13, ABCA4. The list "x1" has columns named V1
and V2. V1 values are row names in the matrix. V2 values are column names
in the matrix. The following should do what you want. It is not a _good_
solution because it is iterative. But it is a start

for (i in nrow(x1)) {
   x[x1$V1[i], x1$V2[i]] <- 1;
}


>
> Thanks
> Adrian
>
>         [[alternative HTML version deleted]]
>
>
Please post in plain text, per the mailing list "rules".

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From pavneet.arora at uk.rsagroup.com  Wed Aug 13 15:01:39 2014
From: pavneet.arora at uk.rsagroup.com (Pavneet Arora)
Date: Wed, 13 Aug 2014 14:01:39 +0100
Subject: [R] scale_*_manual in ggplot2
Message-ID: <OFFC4B249C.965E7CE8-ON80257D33.00438F6F-80257D33.00482F97@uk.royalsun.com>

Data
this is the data I used for the following problems:

dput(sdf)
structure(list(weeks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 
13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 
29, 30), values = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04, 
11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62, 
10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62, 
11.31, 10.52), deviation = c(-0.550000000000001, -2.01, 
-0.710000000000001, 
1.66, 2.16, 0.18, -1.96, 1.46, -0.800000000000001, 0.34, 
-0.970000000000001, 
1.47, 0.51, -0.6, 0.0800000000000001, -0.630000000000001, 
0.619999999999999, 
0.31, 0, 3, 0.9, -0.67, 2.29, 1.5, 0.6, 1.08, 0.380000000000001, 
1.62, 1.31, 0.52), cusums = c(-0.550000000000001, -2.56, -3.27, 
-1.61, 0.549999999999999, 0.729999999999999, -1.23, 0.229999999999999, 
-0.570000000000002, -0.230000000000002, -1.2, 0.269999999999998, 
0.779999999999998, 0.179999999999998, 0.259999999999998, 
-0.370000000000003, 
0.249999999999996, 0.559999999999997, 0.559999999999997, 3.56, 
4.46, 3.79, 6.08, 7.58, 8.18, 9.26, 9.64, 11.26, 12.57, 13.09
), ma = c(NA, 1.46, 1.3, 2.37, 0.5, 1.98, 2.14, 3.42, 2.26, 1.14, 
1.31, 2.44, 0.960000000000001, 1.11, 0.68, 0.710000000000001, 
1.25, 0.309999999999999, 0.31, 3, 2.1, 1.57, 2.96, 0.789999999999999, 
0.9, 0.48, 0.699999999999999, 1.24, 0.309999999999999, 0.790000000000001
), Vupper = c(32.59, 32.09, 31.59, 31.09, 30.59, 30.09, 29.59, 
29.09, 28.59, 28.09, 27.59, 27.09, 26.59, 26.09, 25.59, 25.09, 
24.59, 24.09, 23.59, 23.09, 22.59, 22.09, 21.59, 21.09, 20.59, 
20.09, 19.59, 19.09, 18.59, 18.09), Vlower = c(-6.41, -5.91, 
-5.41, -4.91, -4.41, -3.91, -3.41, -2.91, -2.41, -1.91, -1.41, 
-0.910000000000004, -0.410000000000004, 0.0899999999999963, 
0.589999999999996, 
1.09, 1.59, 2.09, 2.59, 3.09, 3.59, 4.09, 4.59, 5.09, 5.59, 6.09, 
6.59, 7.09, 7.59, 8.09)), .Names = c("weeks", "values", "deviation", 
"cusums", "ma", "Vupper", "Vlower"), row.names = c(NA, -30L), class = 
"data.frame")

Problem1:
I am trying to create a chart using ggplot2. This plot contains 2 
geom_lines and 1geom_point.
But for some reason the geom_point is not being picked up by the legend. 
Can someone help me explain why that maybe?
This is the code I have used for the above data.

vmaskPlot <- ggplot(sdf,aes(ymin=min(sdf$cusums,sdf$Vupper,sdf$Vlower),
                        ymax=(max(sdf$cusums,sdf$Vupper,sdf$Vlower)),
                        x=week))+
  labs(x=NULL,y=NULL)+
  #   theme (panel.grid.major=element_line(color="white",size=0.5),
  #          panel.grid.minor=element_blank(),
  #          panel.grid.major.x=element_blank(),
  #          axis.line.y=element_line(color="black"),
  #          panel.background=element_rect(fill="lightgray"))+
  #   guide=guide_legend(direction="horizontal", 
  #                      title.position="top",
  #                      label.position="bottom",
  #                      label.hjust=0.5,
  #                      label.vjust=0.5,
  #                      label.theme=element_text(angle=90))+
scale_y_continuous()+
  scale_x_discrete(breaks=seq(min(sdf$week),
                              max(sdf$week)))+
  geom_point(aes(y=cusums,colour="Cusum"),size=4,pch=15)+
  geom_line(aes(y=Vupper,colour="Vupper"),size=2.5,alpha=1/2)+ #alpha = 
determines the ? of transparency 
  geom_line(aes(y=Vlower,colour="Vlower"),size=2.5,alpha=1/2)+
  geom_hline(aes(yintercept=0),colour="gray20",size=1)+ #geom_hline - 
draws a reference line at 0
  ggtitle("V-Mask Cusum")+
  theme(legend.position=c(0.9,0.9),
        plot.title=element_text(family="Times",
                                face="bold",
                                size=20))+
  scale_color_manual(name="Legend",
                     breaks=c("cusums","Vupper","Vlower"),
                     values=c("dodgerblue1","brown3","darkolivegreen4"),
                     labels=c("CuSums","Upper V-Mask ","Lower V-Mask "))
 
vmaskPlot
Problem2:
In this ggplot, the legend is coming in separate boxes ? is there any way 
I can combine them in same? Also where it says ?tabuCusum$cusums? ? I just 
want it to say ?CuSums?. I thought I had mentioned this in my code, so why 
is it not picking up?
Furthermore, the code doesn?t seem to pick up the colours I suggested, 
except for the bars ? which are exactly like I want them to be.
But I want the pink dots to dodgerblue1. The 2 horizontal lines close to 
y=0 were supposed to be gold2 colour and the 2 outer horizontal lines were 
supposed to be darkorchid colour as mentioned in the code. 
Does anyone know why it?s not picking up the colours mentioned?
Following is my code:
ggplot(sdf,aes(x=weeks,
                     ymin=min(sdf$cusums,sdf$Tupper,sdf$Tlower)-3,
                     ymax=max(sdf$cusums,sdf$Tupper,sdf$Tlower)+3))+
  labs(x=NULL,y=NULL)+
  scale_y_continuous(expand=c(0,0),
                     minor_breaks=seq(round(min(sdf$cusums,sdf$Tupper,
sdf$Tlower)-2),
                                      round(max(sdf$cusums,sdf$Tupper,
sdf$Tlower)+2),
                                      1),
                     breaks=seq(round(min(sdf$cusums,sdf$Tupper,sdf$Tlower
)-2),
                                round(max(sdf$cusums,sdf$Tupper,sdf$Tlower
)+2),
                                2))+
  scale_x_discrete(expand=c(0,0),
                   breaks=seq(min(sdf$weeks),
                              max(sdf$weeks)))+
  geom_bar(data=sdf,aes(y=sdf$Tupper,fill="sdf$Tupper"),stat="identity")+
  geom_bar(data=sdf,aes(y=sdf$Tlower,fill="sdf$Tlower"),stat="identity")+
  geom_point(aes(y=sdf$cusums,colour="sdf$cusums"),size=4,pch=15)+
  geom_hline(aes(yintercept=0,colour="Line1"),size=1)+ 
  geom_hline(aes(yintercept=5,colour="Line2"),size=2,alpha=1/1.3)+ 
#Out-Of-Signal Lines
  geom_hline(aes(yintercept=-5,colour="Line3"),size=2,alpha=1/1.3)+ 
#Out-Of-Signal Lines
  geom_hline(aes(yintercept=0.5,colour="Line4"),size=2,alpha=1/1.3)+ #K 
  geom_hline(aes(yintercept=-0.5,colour="Line5"),size=2,alpha=1/1.3)+ #K
  theme(legend.position=c(0.1,0.7),
        plot.title=element_text(family="Times",
                                face="bold",
                                size=20))+
#   guides(linetype = guide_legend(override.aes = list(colour = 
c("gray20","darkorchid","darkorchid","gold2","gold2"))))+
# 
override.aes=list(colour=c("gray20","darkorchid","darkorchid","gold2","gold2")) 
 
  # LEGEND FOR BAR CHART
  scale_fill_manual(name="Legend",
                    breaks=c("sdf$Tlower","sdf$Tupper","sdf$cusums",
                             "Line1","Line2","Line3","Line4","Line5"),
                    values=c("darkolivegreen4","brown3","dodgerblue1",
                             "gray20","darkorchid","darkorchid","gold2",
"gold2"),
                    labels=c("Lower Tabular Mask","Upper Tabular Mask",
"Cusum",
                             "Line1","Line2","Line3","Line4","Line5"))

***********************************************************************************************************************************************************************************************************************
MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark?s Court, Chart Way, Horsham, West Sussex, RH12 1XL. 

Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
************************************************************************************************************************************************************************************************************************

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Aug 13 15:24:07 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 13 Aug 2014 08:24:07 -0500
Subject: [R] Cox regression model for matched data with replacement
In-Reply-To: <9E8C049A006DEE48BAB785BC6BCD7FE31895B1E9@ex-mbg-04.win.duke.edu>
References: <27747b$92aq3h@ironport10.mayo.edu>
	<9E8C049A006DEE48BAB785BC6BCD7FE31895B1E9@ex-mbg-04.win.duke.edu>
Message-ID: <27747b$92b71q@ironport10.mayo.edu>

Ok, I will try to do a short tutorial answer.

1. The score statistic for a Cox model is a sum of (x - xbar), where "x" is the covariate 
vector of the subject who had an event, and xbar is the mean covariate vector for the 
population, at that event time.
   - the usual Cox model uses the mean of {everyone still at risk} as xbar
   - matched Cox models use a mean of {some subset of those at risk}, and work fine as 
long as that subset is an honest estimate of xbar.  You do, of course, have to sample from 
those still at risk at the time point, since that is the xbar you are trying to estimate. 
  Someone who dies or is censored at time 10 can't be a control at time 20.
   - in an ordinary Cox model the program figures out who belongs in each xbar average all 
on its own, using the time variable.  In a matched model you need to supply the "who 
dances with who" information.  The usual way is to assign each of the sets {subject who 
died + their controls} to a separate stratum.  (If there is only one death in each stratum 
then the time variable will not be needed and you can plug in a dummy value; this is what 
clogit does.)  You can have more than one control per case by the way.

2. Variance.  In the matched model you run the risk, a quite small risk, that the same 
person would be picked again and again as the control.  If this unfortunate thing were to 
happen then the usual model based variance would be too optimistic --- because of its 
overdependence on one single subject the fit is more unstable than it looks.  Three 
solutions: a) don't worry about it (my usual approach),  b) when selecting controls, 
ensure that this doesn't happen (classic matched case control),  c) use a robust variance. 
  For the latter make sure that each subject in the data set has a unique value for some 
variable "id" and add "+ cluster(id)" to the model statement.

3. The most common mistake in matching is to exclude, at a given death time t, any subject 
with a future event from the list of potential controls at time t.  This does not lead to 
an unbiased estimate of xbar, and the resulting numerical bias in the coefficients is 
shockingly large.
   There are more clever ways to pick the subset at each event time, e.g., if you had some 
prior information on all the subjects that can classify them into high/medium/low risk. 
Survey sampling principles come into play for selection and the xbar at each time is 
replaced with an appropriate weighted survey estimate.  See various papers by Brian Langholz.

Terry T


On 08/13/2014 07:26 AM, John Pura wrote:
> Hi Dr. Therneau,
>
> The original question on the forum was:
>
> My problem was how to build a Cox model for the matched data (1:n) with
> replacement. Usually, we can use stratified Cox regression model when the
> data were matched without replacement. However, if the data were matched
> with replacement, due to the re-use of subjects, we should give a weight
> for each pair, then how to incorporate this weight into a Cox model. I also
> checked the "clogit" function in survival package, it seems suitable to the
> logistic model for the matched data with replacement, rather than Cox
> model. Because it sets the time to a constant. Anyone can give me some
> suggestions?
>
> I?m facing a very similar situation, in which I have multiple controls to multiple cases.
> How would I go about taking that dependency into account in a Cox model? Is this weighting
> appropriate and to get robust sandwich estimates, can I take my id variable to be the id
> for the unique cases?
>
> Thanks,
>
> John

> On 08/13/2014 05:00 AM, John Purda wrote:
>
>> I am curious about this problem as well. How do you go about creating the weights for each pair, and are you suggesting that we can just incorporate a weight statement in the model as opposed to the strata statement? And Dr. Therneau, let's say I have 140 cases matched with replacement to 2 controls. Is my id variable the number of cases?
>
>>
>
>
>
>   The above has an incorrect assumption that I notice ALL survival questions on the list
>
> -- which was false in this case.  Could you clue me in as to the original question and
>
> discussion -- assuming that you want "Dr Therneau" to respond intelligently :-)
>
>
>
> Terry T.
>


From therneau at mayo.edu  Wed Aug 13 16:19:52 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 13 Aug 2014 09:19:52 -0500
Subject: [R] Cox regression model for matched data with replacement
In-Reply-To: <9E8C049A006DEE48BAB785BC6BCD7FE31895B204@ex-mbg-04.win.duke.edu>
References: <27747b$92aq3h@ironport10.mayo.edu>
	<9E8C049A006DEE48BAB785BC6BCD7FE31895B1E9@ex-mbg-04.win.duke.edu>
	<9025b1$i79ste@ironport9.mayo.edu>
	<9E8C049A006DEE48BAB785BC6BCD7FE31895B204@ex-mbg-04.win.duke.edu>
Message-ID: <9025b1$i7bdbd@ironport9.mayo.edu>



On 08/13/2014 08:38 AM, John Pura wrote:
> Thank you for the reply. However, I think I may not have clarified what my cases are. I'm studying the effect of radiation treatment (vs. none) on survival. My cases are patients who received radiation and controls are those who did not. I used a propensity score model to match cases to controls in a 1:2 fashion. However, because the matching was done with replacement, some controls were matched to more than one case. How can I go about analyzing this - would frequency weighting work?
>
> Thanks,
> John

We went down the wrong path.  When people use the word "case" it almost always refers to 
"subjects who had the outcome".  If I read the above correctly you have the more simple 
situation of subset selection.  Subjects were chosen to be in the model without reference 
to their outcome status, with the goal of balancing treatment wrt other predictive 
factors.  Correct?   If so, my preferred modeling strategy, in order.

1. coxph(Surv(time, status) ~ treatment, data=one)
   Where data set "one" has one copy of each subject selected to be in the study.  If they 
were nominated twice they still appear once.  Optional: give each control a case weight 
equal to the number of times they were selected.  This will better balance the data set 
wrt the factors.

2. Same model, with covariates.  The argument about whether covariates on which you have 
balanced should be included in the model is as old the hills --- "belt AND suspenders?" 
--- with proponents on both sides.  Meh.  Unless there are too many of course. I still 
like the 10-20 events per covarate rule to choose the maximum number of predictors.

3. coxph(Surv(time, status) ~ treatment + strata(group), data=two)
  I veiw this as model 2 with paranoia.  "The covariate effects are so odd that we'll 
never model them correctly, so treat each combination as unique."   The data set two needs 
to have each treated subject + their controls in a separate stratum.  Even though some 
controls are in the data set twice, they don't need case weights since they are in any 
given stratum only once.

For any  of the above you can add a robust variance.  Required if case weights are used.

Terry T


From jan.stanstrup at fmach.it  Wed Aug 13 16:59:41 2014
From: jan.stanstrup at fmach.it (Jan Stanstrup)
Date: Wed, 13 Aug 2014 16:59:41 +0200
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
In-Reply-To: <CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
References: <53E9C0E6.6040101@fmach.it>	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
Message-ID: <53EB7D5D.6050206@fmach.it>

Thanks to all of you for your suggestions and comments. I really 
appreciate it.

Some comments to Dennis' comments:
1) I am not concerned about predicting outside the original range. That 
would be nonsense anyway considering the physical phenomenon I am 
modeling. I am, however, concerned that the bootstrapping leads to 
extremely wide CIs at the extremes of the range when there are few data 
points. But I guess there is not much I can do about that as long as I 
rely on bootstrapping?

2) I have made a function that does the interpolation to the requested 
new x's from the original modeling data to get the residual variance and 
the model variance. Then it interpolates the combined SDs back the the 
new x values. See below.

3) I understand that. For this project it is not that important that the 
final prediction intervals are super accurate. But I need to hit the 
ballpark. I am only trying to do something that doesn't crossly 
underestimate the prediction error and doesn't make statisticians loose 
their lunch a first glance.
I also cannot avoid that my data contains erroneous values and I will 
need to build many models unsupervised. But the fit should be good 
enough that I plan to eliminate values outside some multiple of the 
prediction interval and then re-calculate. And if the model is not good 
in any range I will throw it out completely.


Based on the formula of my last message I have made a function that at 
least gives less optimistic intervals than what I could get with the 
other methods I have tried. The function and example data can be found 
here 
https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R 
in case anymore has any comments, suggestions or expletives to my 
implementation.


----------------------
Jan Stanstrup
Postdoc

Metabolomics
Food Quality and Nutrition
Fondazione Edmund Mach



On 08/12/2014 05:40 PM, Bert Gunter wrote:
> PI's of what? -- future individual values or mean values?
>
> I assume quantreg provides quantiles for the latter, not the former.
> (See ?predict.lm for a terse explanation of the difference). Both are
> obtainable from bootstrapping but the details depend on what you are
> prepared to assume. Consult references or your local statistician for
> help if needed.
>
> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>
>>> Hi,
>>>
>>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>>
>>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>>
>>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>
>>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>>
>> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rkoenker at illinois.edu  Wed Aug 13 17:09:16 2014
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 13 Aug 2014 10:09:16 -0500
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
	loess curve using bootstrapping
In-Reply-To: <244a1395cc4c4c41a80394287f0cdb84@CITESHT4.ad.uillinois.edu>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<244a1395cc4c4c41a80394287f0cdb84@CITESHT4.ad.uillinois.edu>
Message-ID: <4767ADCD-EDA5-42D8-9E34-595CBC3F10FE@illinois.edu>

To follow up on David's suggestion on this thread,  I might add that the demo(predemo)
in my quantreg package illustrates a variety of approaches to prediction intervals for
quantile regression estimates.  Adapting this to monotone nonparametric estimation 
using rqss() or cobs would be quite straightforward, although the theory for such bands
is rather difficult and still under construction.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

On Aug 13, 2014, at 9:59 AM, Jan Stanstrup <jan.stanstrup at fmach.it> wrote:

> Thanks to all of you for your suggestions and comments. I really 
> appreciate it.
> 
> Some comments to Dennis' comments:
> 1) I am not concerned about predicting outside the original range. That 
> would be nonsense anyway considering the physical phenomenon I am 
> modeling. I am, however, concerned that the bootstrapping leads to 
> extremely wide CIs at the extremes of the range when there are few data 
> points. But I guess there is not much I can do about that as long as I 
> rely on bootstrapping?
> 
> 2) I have made a function that does the interpolation to the requested 
> new x's from the original modeling data to get the residual variance and 
> the model variance. Then it interpolates the combined SDs back the the 
> new x values. See below.
> 
> 3) I understand that. For this project it is not that important that the 
> final prediction intervals are super accurate. But I need to hit the 
> ballpark. I am only trying to do something that doesn't crossly 
> underestimate the prediction error and doesn't make statisticians loose 
> their lunch a first glance.
> I also cannot avoid that my data contains erroneous values and I will 
> need to build many models unsupervised. But the fit should be good 
> enough that I plan to eliminate values outside some multiple of the 
> prediction interval and then re-calculate. And if the model is not good 
> in any range I will throw it out completely.
> 
> 
> Based on the formula of my last message I have made a function that at 
> least gives less optimistic intervals than what I could get with the 
> other methods I have tried. The function and example data can be found 
> here 
> https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R 
> in case anymore has any comments, suggestions or expletives to my 
> implementation.
> 
> 
> ----------------------
> Jan Stanstrup
> Postdoc
> 
> Metabolomics
> Food Quality and Nutrition
> Fondazione Edmund Mach
> 
> 
> 
> On 08/12/2014 05:40 PM, Bert Gunter wrote:
>> PI's of what? -- future individual values or mean values?
>> 
>> I assume quantreg provides quantiles for the latter, not the former.
>> (See ?predict.lm for a terse explanation of the difference). Both are
>> obtainable from bootstrapping but the details depend on what you are
>> prepared to assume. Consult references or your local statistician for
>> help if needed.
>> 
>> -- Bert
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>> 
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>> 
>> 
>> 
>> 
>> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>> 
>>>> Hi,
>>>> 
>>>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>>> 
>>>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>>>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>>> 
>>>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>> 
>>>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>>> 
>>> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
>>> --
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From madhvi.gupta at orkash.com  Wed Aug 13 13:33:11 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Wed, 13 Aug 2014 17:03:11 +0530
Subject: [R] Parameter of a function used after $ in a data frame
Message-ID: <53EB4CF7.80209@orkash.com>

Hi,
Can anyone please tell me how to use a argument of a function after $ 
sign of a data frame.That argument is one of the column name of the data 
frame.

Thanks,
Madhvi


From oriolebaltimore at gmail.com  Wed Aug 13 17:44:42 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 13 Aug 2014 11:44:42 -0400
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
Message-ID: <CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>

Hi.
Thank you for your help.
yes, thats exactly right - but the 1211x1211 matrix has some
row/column elements that may not be present in x1.
Is that the reason I get this error?

My matrix row names and column names are identical. I changed the
order in my dput code for representational purpose so that they can
have 1 for conveying question easily.

Thanks


    A  B C D E
A
B
C
D




> for (i in nrow(x1)) {
+   x[x1$V1[i], x1$V2[i]] <- 1;
+ }
Error in `[<-`(`*tmp*`, x1[i, ]$V1, x1[i, ]$V2, value = 1) :
  subscript out of bounds







On Wed, Aug 13, 2014 at 8:28 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Tue, Aug 12, 2014 at 7:14 PM, Adrian Johnson <oriolebaltimore at gmail.com>
> wrote:
>>
>> Hi:
>> sorry I have a basic question.
>>
>> I have a data frame with two columns:
>> > x1
>>       V1       V2
>> 1   AKT3    TCL1A
>> 2  AKTIP    VPS41
>> 3  AKTIP    PDPK1
>> 4  AKTIP   GTF3C1
>> 5  AKTIP    HOOK2
>> 6  AKTIP    POLA2
>> 7  AKTIP KIAA1377
>> 8  AKTIP FAM160A2
>> 9  AKTIP    VPS16
>> 10 AKTIP    VPS18
>>
>>
>> I have a matrix 1211x1211 (using some elements in x1$V1 and some from
>> x1$V2). I want to populate for every match for example AKT3 = TCL1A = 1
>> whereas AKT3 - VPS41 gets 0)
>> How can i map this binary relations in x.
>>
>>
>> >x
>>        TCLA1 VPS41 ABCA13 ABCA4
>> AKT3       0     0      0     0
>> AKTIP      0     0      0     0
>> ABCA13     0     0      0     0
>> ABCA4      0     0      0     0
>>
>
> <snip>
>
> I'm not totally sure that I understand your data structure. So I will
> rephrase a bit so that I can be corrected, if necessary. You have an
> 1211x1121 matrix already. Every cell in the matrix is initialized to 0. It
> has column names such as TCLA1, VPS41, ABCA13, ABCA4, ... and it has row
> names such as AKT3 AKTPI, ABCA13, ABCA4. The list "x1" has columns named V1
> and V2. V1 values are row names in the matrix. V2 values are column names in
> the matrix. The following should do what you want. It is not a _good_
> solution because it is iterative. But it is a start
>
> for (i in nrow(x1)) {
>    x[x1$V1[i], x1$V2[i]] <- 1;
> }
>
>>
>>
>> Thanks
>> Adrian
>>
>>         [[alternative HTML version deleted]]
>>
>
> Please post in plain text, per the mailing list "rules".
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown


From ruipbarradas at sapo.pt  Wed Aug 13 18:25:05 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 13 Aug 2014 17:25:05 +0100
Subject: [R] Parameter of a function used after $ in a data frame
In-Reply-To: <53EB4CF7.80209@orkash.com>
References: <53EB4CF7.80209@orkash.com>
Message-ID: <53EB9161.5080000@sapo.pt>

I don't believe I understand your question, but here it goes.

dat <- data.frame(x = rnorm(100), y = runif(100))

mean(dat$x)

Hope this helps,

Rui Barradas

Em 13-08-2014 12:33, madhvi.gupta escreveu:
> Hi,
> Can anyone please tell me how to use a argument of a function after $
> sign of a data frame.That argument is one of the column name of the data
> frame.
>
> Thanks,
> Madhvi
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Aug 13 18:36:21 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Aug 2014 09:36:21 -0700
Subject: [R] Parameter of a function used after $ in a data frame
In-Reply-To: <53EB4CF7.80209@orkash.com>
References: <53EB4CF7.80209@orkash.com>
Message-ID: <CAF8bMcafd_Fo2j-fFKpRajfpEzgA+TBzEX8SQLTF36-kSRUdHQ@mail.gmail.com>

Use [[ instead of $.   E.g.,

f <- function(columnName) {
    d <- data.frame(x=1, y=2, z=3)
    d[[columnName]]
}
f("z") # 3
cName <- "y"
f(cName) # 2

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Aug 13, 2014 at 4:33 AM, madhvi.gupta <madhvi.gupta at orkash.com> wrote:
> Hi,
> Can anyone please tell me how to use a argument of a function after $ sign
> of a data frame.That argument is one of the column name of the data frame.
>
> Thanks,
> Madhvi
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Aug 13 18:51:37 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Aug 2014 09:51:37 -0700
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
	<CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
Message-ID: <CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>

You can replace the loop
> for (i in nrow(x1)) {
>    x[x1$V1[i], x1$V2[i]] <- 1;
> }
by
f <- function(x, x1) {
  i <- as.matrix(x1[, c("V1","V2")]) # 2-column matrix to use as a subscript
  x[ i ] <- 1
  x
}
f(x, x1)

You will get an error if not all the strings in the subscript matrix
are in the row or
column names of x.  What do you want to happen in this case.  You can choose
to first omit the bad rows in the subscript matrix
    goodRows <- is.element(i[,1], dimnames(x)[1]) &  is.element(i[,2],
dimnames(x)[2])
    i <- i[goodRows, , drop=FALSE]
    x[ i ] <- 1
or you can choose to expand x to include all the names found in x1.

It would be good if you included some toy data to better illustrate
what you want to do.
E.g., with
  x <- array(0, c(3,3), list(Row=paste0("R",1:3),Col=paste0("C",1:3)))
  x1 <- data.frame(V1=c("R1","R3"), V2=c("C2","C1"))
the above f() gives
> f(x, x1)
    Col
Row  C1 C2 C3
  R1  0  1  0
  R2  0  0  0
  R3  1  0  0
Is that what you are looking for?


From Ted.Harding at wlandres.net  Wed Aug 13 20:49:05 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Wed, 13 Aug 2014 19:49:05 +0100 (BST)
Subject: [R] A basic statistics question
In-Reply-To: <XFMail.20140812232213.Ted.Harding@wlandres.net>
Message-ID: <XFMail.20140813194905.Ted.Harding@wlandres.net>

On 12-Aug-2014 22:22:13 Ted Harding wrote:
> On 12-Aug-2014 21:41:52 Rolf Turner wrote:
>> On 13/08/14 07:57, Ron Michael wrote:
>>> Hi,
>>>
>>> I would need to get a clarification on a quite fundamental statistics
>>> property, hope expeRts here would not mind if I post that here.
>>>
>>> I leant that variance-covariance matrix of the standardized data is
>>> equal to the correlation matrix for the unstandardized data. So I
>>> used following data.
>> 
>> <SNIP>
>> 
>>> (t(Data_Normalized) %*% Data_Normalized)/dim(Data_Normalized)[1]
>>>
>>> Point is that I am not getting exact CORR matrix. Can somebody point
>>> me what I am missing here?
>> 
>> You are using a denominator of "n" in calculating your "covariance" 
>> matrix for your normalized data.  But these data were normalized using 
>> the sd() function which (correctly) uses a denominator of n-1 so as to 
>> obtain an unbiased estimator of the population standard deviation.
>> 
>> If you calculated
>> 
>>     (t(Data_Normalized) %*% Data_Normalized)/(dim(Data_Normalized)[1]-1)
>> 
>> then you would get the same result as you get from cor(Data) (to within 
>> about 1e-15).
>> 
>> cheers,
>> Rolf Turner
> 
> One could argue about "(correctly)"!
> 
>>From the "descriptive statistics" point of view, if one is given a single
> number x, then this dataset has no variation, so one could say that
> sd(x) = 0. And this is what one would get with a denominator of "n".
> 
> But if the single value x is viewed as sampled from a distribution
> (with positive dispersion), then the value of x gives no information
> about the SD of the distribution. If you use denominator (n-1) then
> sd(x) = NA, i.e. is indeterminate (as it should be in this application).
> 
> The important thing when using pre-programmed functions is to know
> which is being used. R uses (n-1), and this can be found from
> looking at
> 
>   ?sd
> 
> or (with more detail) at
> 
>   ?cor
> 
> Ron had assumed that the denominator was n, apparently not being aware
> that R uses (n-1).
> 
> Just a few thoughts ...
> Ted.
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 12-Aug-2014  Time: 23:22:09

After some hesitation (not wanting to prolong a thread whose original
query has been effectively settled), nevertheless I think it may be
worth stating the general picture, for the sake of users who might
be confused or misled regarding the use of  the functions var(), cov(),
cor(), sd() etc.

The distinction to become aware of is between "summary" statistics
and statistics which will be used for estimation/inference.

Given a set of numbers, x[1], x[2], ... , x[N], they have a mean

  MEAN = sum(x)/N

and their variance VAR is the mean of the deviations between the x[i]
and MEAN:

  VAR = (sum(x - MEAN)^2)/N

If a random value X is drawn from {x[1], x[2], ... , x[N]}, with
uniform probability, then the expectation of X is again

  E(X) = MEAN

and the variance of X is again

  Var(X) = E((X - MEAN)^2) = VAR

with MEAN and VAR as given above. And the R function mean(x) will
return MEAN is its value. However, the R function var(x) will not
return VAR -- it will return (N/(N-1))*VAR

The above definitions of MEAN and VAR use division by N, i.e.
"denominator = N". But the R functions var(x), sd(x) etc. divide by
(N-1), i.e. use "denominator = N-1", as explained in
  ?var
  ?sd
etc.

The basic reason for this is that, given a random sample X[1], ... ,X[n]
of size n from {x[1], x[2], ... , x[N]}, the expectation of

  sum((X - mean(X))^2)

is (n-1)*VAR, so to obtain an unbiased estimate of VAR from the X
sample one must use the "bias-corrected" sample variance

  var(X) = sum((X - mean(X))^2)/(n-1)

i.e. "denominator = (n-1)" as described in the help pages.

So the function var(), with denominator = (n-1), is "correct" for
obtaining an unbiased estimator. But it will not be correct for the
variance sum((X - mean(X))^2)/n of the numbers X[1], ... ,X[n].

Since sd() also uses denominator = (n-1), sd(X) is the square root
of var(X). But, while var(X) is unbiased for VAR, sd(X) is not
unbiased for SD = sqrt(VAR), since, for a positive ransom variable Y,
in general

  E(sqrt(Y)) < sqrt(E(Y))

i.e. E(sd(X)) = E(sqrt(var(X))) < sqrt(E(var(X))) = sqrt(VAR) = SD.

The R functions var() etc., which use denominator = (n-1), do not
have an option which allows the user to choose denominator = n.

Therefore, in particular, a user who has a set of numbers
  {x[1], x[2], ... , x[N]}
(e.g. a record of a popuation) and wants the SD of these (e.g. for
use in summary statistics Mean and SD), could inadvertently use
R's sd(x), expecting SD, without being alerted to the fact that it
will give the wrong answer. And the only way round it is to explicitly
write one's own correction, e.g.

  SD <- function(x){n<-length(x); sd(x)*sqrt((n-1)/n)}

Indeed, this topic has got me wondering how many times I may have
blindly used sd(x) in the past, as if it were going to give me the
standard (sum(x - mean(x))^2)/length(x) result!

As I wrote earlier, when there is more than one definition which
might be used, the important thing is to know which one is being used,
and to correct accordingly if it is not the one you want.

Best wishes to all,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 13-Aug-2014  Time: 19:49:02
This message was sent by XFMail


From mccormack at molbio.mgh.harvard.edu  Wed Aug 13 20:56:31 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Wed, 13 Aug 2014 14:56:31 -0400
Subject: [R] find the data frames in list of objects and make a list of them
Message-ID: <53EBB4DF.7030709@molbio.mgh.harvard.edu>

Hi everyone,

    I would like the find which objects are data frames in all the 
objects I have created ( in other words in what you get when you type: 
ls()  ), then I would like to make a list of these data frames.

Explained in other words; after typing ls(), you get the names of 
objects. Which objects are data frames ?  How to then make a list of 
these data frames.

    A second question: is this the best way to make a list of data 
frames without having to manually type c(dataframe1, dataframe2, ...)  ?

Matthew


From jholtman at gmail.com  Wed Aug 13 21:06:27 2014
From: jholtman at gmail.com (jim holtman)
Date: Wed, 13 Aug 2014 15:06:27 -0400
Subject: [R] find the data frames in list of objects and make a list of
	them
In-Reply-To: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
References: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
Message-ID: <CAAxdm-4sgHss1yNw9JnreUiqMLL+t4NFadLKuok8P=vfrmEKyg@mail.gmail.com>

Here is a function that I use that might give you the results you want:

=================
> my.ls()
                       Size      Class  Length         Dim
.Random.seed          2,544    integer     626
.remapHeaderFile     40,440 data.frame       2     373 x 2
colID                   216  character       3
delDate                 104  character       1
deliv                15,752 data.table       7     164 x 7
f_drawPallet         36,896   function       1
i                        96  character       1
indx                168,816  character    1782
pallet              172,696 data.table       3    1782 x 3
pallets             405,736 data.table      14   1782 x 14
picks            26,572,856 data.table      19 154247 x 19
wb                      656   Workbook       1
wSplit           68,043,136       list    1782
x                        56    numeric       2
**Total          95,460,000    ------- -------     -------

====================
> my.ls
function (pos = 1, sorted = FALSE, envir = as.environment(pos))
{
    .result <- sapply(ls(envir = envir, all.names = TRUE),
function(..x) object.size(eval(as.symbol(..x),
        envir = envir)))
    if (length(.result) == 0)
        return("No objects to list")
    if (sorted) {
        .result <- rev(sort(.result))
    }
    .ls <- as.data.frame(rbind(as.matrix(.result), `**Total` = sum(.result)))
    names(.ls) <- "Size"
    .ls$Size <- formatC(.ls$Size, big.mark = ",", digits = 0,
        format = "f")
    .ls$Class <- c(unlist(lapply(rownames(.ls)[-nrow(.ls)],
function(x) class(eval(as.symbol(x),
        envir = envir))[1L])), "-------")
    .ls$Length <- c(unlist(lapply(rownames(.ls)[-nrow(.ls)],
        function(x) length(eval(as.symbol(x), envir = envir)))),
        "-------")
    .ls$Dim <- c(unlist(lapply(rownames(.ls)[-nrow(.ls)], function(x)
paste(dim(eval(as.symbol(x),
        envir = envir)), collapse = " x "))), "-------")
    .ls
}
========================

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Aug 13, 2014 at 2:56 PM, Matthew
<mccormack at molbio.mgh.harvard.edu> wrote:
> Hi everyone,
>
>    I would like the find which objects are data frames in all the objects I
> have created ( in other words in what you get when you type: ls()  ), then I
> would like to make a list of these data frames.
>
> Explained in other words; after typing ls(), you get the names of objects.
> Which objects are data frames ?  How to then make a list of these data
> frames.
>
>    A second question: is this the best way to make a list of data frames
> without having to manually type c(dataframe1, dataframe2, ...)  ?
>
> Matthew
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Aug 13 21:12:27 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 13 Aug 2014 15:12:27 -0400
Subject: [R] find the data frames in list of objects and make a list of
	them
In-Reply-To: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
References: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
Message-ID: <CAGx1TMCE8gk=Z2tU9=P=A=coGifbZfmZ+chgbsXWVvxos=rSTw@mail.gmail.com>

I would do something like this

lsDataFrame <- function(xx=ls()) xx[sapply(xx, function(x)
is.data.frame(get(x)))]
ls("package:datasets")
lsDataFrame(ls("package:datasets"))

On Wed, Aug 13, 2014 at 2:56 PM, Matthew
<mccormack at molbio.mgh.harvard.edu> wrote:
> Hi everyone,
>
>    I would like the find which objects are data frames in all the objects I
> have created ( in other words in what you get when you type: ls()  ), then I
> would like to make a list of these data frames.
>
> Explained in other words; after typing ls(), you get the names of objects.
> Which objects are data frames ?  How to then make a list of these data
> frames.
>
>    A second question: is this the best way to make a list of data frames
> without having to manually type c(dataframe1, dataframe2, ...)  ?
>
> Matthew
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mccormack at molbio.mgh.harvard.edu  Wed Aug 13 21:32:19 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Wed, 13 Aug 2014 15:32:19 -0400
Subject: [R] find the data frames in list of objects and make a list of
 them
In-Reply-To: <CAAxdm-4sgHss1yNw9JnreUiqMLL+t4NFadLKuok8P=vfrmEKyg@mail.gmail.com>
References: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
	<CAAxdm-4sgHss1yNw9JnreUiqMLL+t4NFadLKuok8P=vfrmEKyg@mail.gmail.com>
Message-ID: <53EBBD43.1060109@molbio.mgh.harvard.edu>

Jim, Wow that was cooool !   This function is *really* useful.  Thank 
you very much !  (It is also way beyond my capability).

I need to make a list of data frames because then I am going to bind 
them with plyr using 'dplyr::rbind_all(listOfDataFrames)'. This will 
make a single data frame, and from that single data frame I can make a 
heat map of all the data.

   For example, when I use your fantastic function, my.ls(), I get:

my.ls()
                                                              Size      Class  Length      Dim
.Random.seed                                                2,544    integer     626
cpl                                                        28,664  character     512
filenames                                                   2,120  character      19
filepath                                                      216  character       1
i                                                             152  character       1
Mer7_1-1_160-226A_1_gene_exp_diff_filt_hc_log2.txt         81,152 data.frame       3  529 x 3
Mer7_1-1_Mer7_1-2_gene_exp_diff_filt_hc_log2.txt           31,624 data.frame       3  199 x 3
Mer7_1-1_S150-160-226A_1_gene_exp_diff_filt_hc_log2.txt    81,152 data.frame       3  529 x 3
Mer7_1-1_W29_1_gene_exp_diff_filt_hc_log2.txt             129,376 data.frame       3  849 x 3
Mer7_1-1_W29_S150-226A_1_gene_exp_diff_filt_hc_log2.txt   126,816 data.frame       3  835 x 3
Mer7_1-1_W29_S160-162A_1_gene_exp_diff_filt_hc_log2.txt    82,792 data.frame       3  537 x 3
Mer7_1-1_W29_S226A_1_gene_exp_diff_filt_hc_log2.txt       115,008 data.frame       3  756 x 3
Mer7_1-2_160-226A_1_gene_exp_diff_filt_hc_log2.txt         79,936 data.frame       3  519 x 3
Mer7_1-2_S150-160-226A_1_gene_exp_diff_filt_hc_log2.txt    84,512 data.frame       3  548 x 3
Mer7_1-2_W29_1_gene_exp_diff_filt_hc_log2.txt             130,568 data.frame       3  857 x 3
Mer7_1-2_W29_S160-162A_1_gene_exp_diff_filt_hc_log2.txt    83,768 data.frame       3  542 x 3
Mer7_1-2_W29_S226A_1_gene_exp_diff_filt_hc_log2.txt       119,008 data.frame       3  783 x 3
Mer7_2-1_160-226A_2_gene_exp_diff_filt_hc_log2.txt        105,344 data.frame       3  685 x 3
Mer7_2-1_Mer7_2-2_gene_exp_diff_filt_hc_log2.txt           26,216 data.frame       3  166 x 3
Mer7_2-1_S150-160-226A_2_gene_exp_diff_filt_hc_log2.txt   106,368 data.frame       3  693 x 3
Mer7_2-1_W29_2_gene_exp_diff_filt_hc_log2.txt             160,200 data.frame       3 1053 x 3
Mer7_2-1_W29_S150-226A_2_gene_exp_diff_filt_hc_log2.txt   152,696 data.frame       3 1005 x 3
Mer7_2-1_W29_S160-162A_2_gene_exp_diff_filt_hc_log2.txt   113,992 data.frame       3  743 x 3
Mer7_2-1_W29_S226A_2_gene_exp_diff_filt_hc_log2.txt       138,944 data.frame       3  914 x 3
my.ls                                                      35,624   function       1
myfiles                                                     2,120  character      19
names                                                       2,424       list      19
test                                                          680  character       5
whatisthis                                                  2,424       list      19
**Total                                                 2,026,440    ------- -------  -------



   What I need is make the list of data frames for the dplyr command, 
dplyr::rbind_all(listOfDataFrames). Ideally, this would also be a 
specific subset of all the data frames, say the data frames with W29 in 
the name. This is something we, our lab, would be doing routinely and at 
various times of the day, so I want to automate the process so it does 
not need anyone to manually sit at the computer and type the list of 
data frames.

Matthew


On 8/13/2014 3:06 PM, jim holtman wrote:
> Here is a function that I use that might give you the results you want:
>
> =================
>> my.ls()
>                         Size      Class  Length         Dim
> .Random.seed          2,544    integer     626
> .remapHeaderFile     40,440 data.frame       2     373 x 2
> colID                   216  character       3
> delDate                 104  character       1
> deliv                15,752 data.table       7     164 x 7
> f_drawPallet         36,896   function       1
> i                        96  character       1
> indx                168,816  character    1782
> pallet              172,696 data.table       3    1782 x 3
> pallets             405,736 data.table      14   1782 x 14
> picks            26,572,856 data.table      19 154247 x 19
> wb                      656   Workbook       1
> wSplit           68,043,136       list    1782
> x                        56    numeric       2
> **Total          95,460,000    ------- -------     -------
>
> ====================
>> my.ls
> function (pos = 1, sorted = FALSE, envir = as.environment(pos))
> {
>      .result <- sapply(ls(envir = envir, all.names = TRUE),
> function(..x) object.size(eval(as.symbol(..x),
>          envir = envir)))
>      if (length(.result) == 0)
>          return("No objects to list")
>      if (sorted) {
>          .result <- rev(sort(.result))
>      }
>      .ls <- as.data.frame(rbind(as.matrix(.result), `**Total` = sum(.result)))
>      names(.ls) <- "Size"
>      .ls$Size <- formatC(.ls$Size, big.mark = ",", digits = 0,
>          format = "f")
>      .ls$Class <- c(unlist(lapply(rownames(.ls)[-nrow(.ls)],
> function(x) class(eval(as.symbol(x),
>          envir = envir))[1L])), "-------")
>      .ls$Length <- c(unlist(lapply(rownames(.ls)[-nrow(.ls)],
>          function(x) length(eval(as.symbol(x), envir = envir)))),
>          "-------")
>      .ls$Dim <- c(unlist(lapply(rownames(.ls)[-nrow(.ls)], function(x)
> paste(dim(eval(as.symbol(x),
>          envir = envir)), collapse = " x "))), "-------")
>      .ls
> }
> ========================
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Wed, Aug 13, 2014 at 2:56 PM, Matthew
> <mccormack at molbio.mgh.harvard.edu> wrote:
>> Hi everyone,
>>
>>     I would like the find which objects are data frames in all the objects I
>> have created ( in other words in what you get when you type: ls()  ), then I
>> would like to make a list of these data frames.
>>
>> Explained in other words; after typing ls(), you get the names of objects.
>> Which objects are data frames ?  How to then make a list of these data
>> frames.
>>
>>     A second question: is this the best way to make a list of data frames
>> without having to manually type c(dataframe1, dataframe2, ...)  ?
>>
>> Matthew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From tianwenlan at gmail.com  Wed Aug 13 21:43:31 2014
From: tianwenlan at gmail.com (Wenlan Tian)
Date: Wed, 13 Aug 2014 15:43:31 -0400
Subject: [R] save results in a loop
Message-ID: <CAFkuWq706fLV=-O8PnT_EkUwqc+MqzG3r84f8k22bTZbt5rgkw@mail.gmail.com>

Hi, i'm new to R. I have a question about how to save results in a loop to
a file. Here is an example:

for (i in 6:n){
Tukey1 = HSD.test(lm(sdata_mg[,n] ~
sdata_mg$Medium+sdata_mg$color+sdata_mg$type+sdata_mg$Micro),
'sdata_mg$Micro')
}


I don't know how to do it with the loop for all data, so i just tried one
of them,
Tukey1 = HSD.test(lm(sdata_mg[,1] ~
sdata_mg$Medium+sdata_mg$color+sdata_mg$type+sdata_mg$Micro),
'sdata_mg$Micro')
Tukey1

The results look like this:

$statistics
      Mean       CV   MSerror       HSD r.harmonic
  11.87421 3.102479 0.1357148 0.5288771   7.384615

$parameters
  Df ntr StudentizedRange
  24   4         3.901262

$means
       sdata_mg[, 6]       std  r      Min      Max
111d                  11.86369 0.5317421  6 11.08623 12.45651
125d                  11.74433 0.1663130  6 11.53504 12.02412
14d                   11.54073 0.3877921  8 10.80300 11.96797
Ground                12.16673 0.3391952 12 11.56278 12.86199

$comparison
NULL

$groups
     trt    means  M
1 Ground 12.16673  a
2 111d   11.86369 ab
3 125d   11.74433 ab
4 14d    11.54073  b


How could i get all the results in the loop?

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Wed Aug 13 23:27:41 2014
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 13 Aug 2014 15:27:41 -0600
Subject: [R] save results in a loop
In-Reply-To: <CAFkuWq706fLV=-O8PnT_EkUwqc+MqzG3r84f8k22bTZbt5rgkw@mail.gmail.com>
References: <CAFkuWq706fLV=-O8PnT_EkUwqc+MqzG3r84f8k22bTZbt5rgkw@mail.gmail.com>
Message-ID: <CAFEqCdwa_8e3NrHy_q3Lx+dc56JMFUpqVpY+JVUXO8OTuv5UqQ@mail.gmail.com>

Generally if you want to save the results of a loop then it is time to
learn to use the lapply and sapply functions instead.

Try something like:

Tukey <- lapply( 6:n, function(i) Tukey1 = HSD.test(lm(sdata_mg[,i] ~
sdata_mg$Medium+sdata_mg$color+sdata_mg$type+sdata_mg$Micro),
'sdata_mg$Micro') )

though that is still ugly with all those subscripting `$`s.  A little
nicer might be:

tmpfun <- function(vname) {
  tmp.f <- as.formula( paste( vname, '~ Medium + color + type + Micro') )
  HSD.test( lm(tmp.f, data=sdata_mg), 'Micro' )
}

Tukey <- lapply( names(sdata_mg)[6:n], tmpfun )

or

tmpfun <- function(vname) {
  vname <- as.name(vname)
  HSD.test(
    eval(substitute(
       lm(vname ~ Medium + color + type + Micro, data=sdata_mg)
    )), 'Micro')
}

Tukey <- lapply(names(sdata_mg)[6:n], tmpfun)



On Wed, Aug 13, 2014 at 1:43 PM, Wenlan Tian <tianwenlan at gmail.com> wrote:
> Hi, i'm new to R. I have a question about how to save results in a loop to
> a file. Here is an example:
>
> for (i in 6:n){
> Tukey1 = HSD.test(lm(sdata_mg[,n] ~
> sdata_mg$Medium+sdata_mg$color+sdata_mg$type+sdata_mg$Micro),
> 'sdata_mg$Micro')
> }
>
>
> I don't know how to do it with the loop for all data, so i just tried one
> of them,
> Tukey1 = HSD.test(lm(sdata_mg[,1] ~
> sdata_mg$Medium+sdata_mg$color+sdata_mg$type+sdata_mg$Micro),
> 'sdata_mg$Micro')
> Tukey1
>
> The results look like this:
>
> $statistics
>       Mean       CV   MSerror       HSD r.harmonic
>   11.87421 3.102479 0.1357148 0.5288771   7.384615
>
> $parameters
>   Df ntr StudentizedRange
>   24   4         3.901262
>
> $means
>        sdata_mg[, 6]       std  r      Min      Max
> 111d                  11.86369 0.5317421  6 11.08623 12.45651
> 125d                  11.74433 0.1663130  6 11.53504 12.02412
> 14d                   11.54073 0.3877921  8 10.80300 11.96797
> Ground                12.16673 0.3391952 12 11.56278 12.86199
>
> $comparison
> NULL
>
> $groups
>      trt    means  M
> 1 Ground 12.16673  a
> 2 111d   11.86369 ab
> 3 125d   11.74433 ab
> 4 14d    11.54073  b
>
>
> How could i get all the results in the loop?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From oriolebaltimore at gmail.com  Wed Aug 13 23:33:24 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Wed, 13 Aug 2014 17:33:24 -0400
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
	<CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
	<CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>
Message-ID: <CAL2fYnNvWuOz5On5epFXuJpQofu9pg4a_8zcG=wHCdRuPn4afw@mail.gmail.com>

Hello again. sorry for question again.

may be I was not clear in asking before.

 I don't want to remove rows from matrix, since row names and column
names are identical in matrix.


I tried your suggestion and here is what I get:

> fx <- function(x,x1){
+ i <- as.matrix(x1[,c("V1","V2")])
+ x[i]<-1
+ x
+ }
> fx(x, x1)

Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds




> x[1:4,1:4]
       ABCA10 ABCA12 ABCA13 ABCA4
ABCA10      0      0      0     0
ABCA12      0      0      0     0
ABCA13      0      0      0     0
ABCA4       0      0      0     0


> x1[1:10,]
      V1       V2
1   AKT3    TCL1A
2  AKTIP    VPS41
3  AKTIP    PDPK1
4  AKTIP   GTF3C1
5  AKTIP    HOOK2
6  AKTIP    POLA2
7  AKTIP KIAA1377
8  AKTIP FAM160A2
9  AKTIP    VPS16
10 AKTIP    VPS18


For instance, now I will loop over x1, I go to first row, I get V1 and
check if if I have a row in x that have item in V1 and then check V2
exist in colnames, if match then I assign 1. If not I go to row 2.

In some rows, it is possible that I will only see element in V2 that
exist in row names  and since element in V1 does not exist in X
matrix, I will give 0. (since matrix X has identical row and column
names, i feel it does not matter to check an element in column names
after we check in row names)



now for instance, If in X1 if I see ABCA10 in x1$V1 and ABCA10 in
x1$V2 then in matrix X column 1 and row 1  should get 1.

dput - follows..

x <- structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(4L,
4L), .Dimnames = list(c("ABCA10", "ABCA12", "ABCA13", "ABCA4"
), c("ABCA10", "ABCA12", "ABCA13", "ABCA4")))


x1 <- structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
"AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
"VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
"VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
10L), class = "data.frame")



Thanks for your time.




On Wed, Aug 13, 2014 at 12:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You can replace the loop
>> for (i in nrow(x1)) {
>>    x[x1$V1[i], x1$V2[i]] <- 1;
>> }
> by
> f <- function(x, x1) {
>   i <- as.matrix(x1[, c("V1","V2")]) # 2-column matrix to use as a subscript
>   x[ i ] <- 1
>   x
> }
> f(x, x1)
>
> You will get an error if not all the strings in the subscript matrix
> are in the row or
> column names of x.  What do you want to happen in this case.  You can choose
> to first omit the bad rows in the subscript matrix
>     goodRows <- is.element(i[,1], dimnames(x)[1]) &  is.element(i[,2],
> dimnames(x)[2])
>     i <- i[goodRows, , drop=FALSE]
>     x[ i ] <- 1
> or you can choose to expand x to include all the names found in x1.
>
> It would be good if you included some toy data to better illustrate
> what you want to do.
> E.g., with
>   x <- array(0, c(3,3), list(Row=paste0("R",1:3),Col=paste0("C",1:3)))
>   x1 <- data.frame(V1=c("R1","R3"), V2=c("C2","C1"))
> the above f() gives
>> f(x, x1)
>     Col
> Row  C1 C2 C3
>   R1  0  1  0
>   R2  0  0  0
>   R3  1  0  0
> Is that what you are looking for?


From john.archie.mckown at gmail.com  Wed Aug 13 23:41:46 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 13 Aug 2014 16:41:46 -0500
Subject: [R] opinion - sharing problem data and other stuff.
Message-ID: <CAAJSdjg77LFyKB2dOdYPhTYcky2RiiWT2XywTeGjndRmwGa9uw@mail.gmail.com>

This is just a thought that has occurred to me. I don't know if it is
an "Oh, WOW!" or an "Are you KIDDING?!?" type thought. So I thought
I'd ask here.

I use github for a few things. Nothing great, but maybe nice. Anyway,
one feature of GitHub is the GIST feature. What I am used to github
being for is a project consisting of many complete files. A gist can
contain many files, but is really for a set of snippets. Such as code
sequences. Or maybe the output from a dput().

If I have a "big" problem where I think that having all the data and
my attempted solutions available, I think it would be far kinder of me
to put a _good_ synopsis of the problem here on the list. And a
clickable URL to the gist I have created for the problem. That would
decrease the bandwidth on the email server. And save space on it. And,
lets face it, in many cases only a few people are going to really look
at any given problem "in depth", so why have a huge email go out to
the entire community?

My idea may not be useful, I really am not sure. But my motive is
trying to keep everybody's inbox from overflowing. And make it easier
to supply really good data, but only to those who are interested.

Thanks for any feedback.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From sarah.goslee at gmail.com  Wed Aug 13 23:50:16 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 13 Aug 2014 17:50:16 -0400
Subject: [R] opinion - sharing problem data and other stuff.
In-Reply-To: <CAAJSdjg77LFyKB2dOdYPhTYcky2RiiWT2XywTeGjndRmwGa9uw@mail.gmail.com>
References: <CAAJSdjg77LFyKB2dOdYPhTYcky2RiiWT2XywTeGjndRmwGa9uw@mail.gmail.com>
Message-ID: <CAM_vjumpp9RQwg=SW0biWcKpRv+OyFbJFo3gUiuS_AG56xmUDg@mail.gmail.com>

Hi John,

People do sometimes link to external data and code, though I'm not
sure I've seen any in that particular format.

But, two things to consider.

A. I'm lazy. If the problem is fully-formed in the email, I'm more
likely to try to solve it than if I have to go download something and
figure out what's in it. (Even leaving aside the potential issues with
downloading random things.)

B. A *small* reproducible example is usually a good thing. There are
not that many cases where the whole big dataset is necessary. Further,
the exercise of creating a small reproducible example is often enough
to solve the problem, without ever needed to bother R-help at all.

Granted, I'm also likely to skip posts to the list with enormous
dput() data dumps too. I'm a big fan of the "small" part.

Sarah

On Wed, Aug 13, 2014 at 5:41 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
> This is just a thought that has occurred to me. I don't know if it is
> an "Oh, WOW!" or an "Are you KIDDING?!?" type thought. So I thought
> I'd ask here.
>
> I use github for a few things. Nothing great, but maybe nice. Anyway,
> one feature of GitHub is the GIST feature. What I am used to github
> being for is a project consisting of many complete files. A gist can
> contain many files, but is really for a set of snippets. Such as code
> sequences. Or maybe the output from a dput().
>
> If I have a "big" problem where I think that having all the data and
> my attempted solutions available, I think it would be far kinder of me
> to put a _good_ synopsis of the problem here on the list. And a
> clickable URL to the gist I have created for the problem. That would
> decrease the bandwidth on the email server. And save space on it. And,
> lets face it, in many cases only a few people are going to really look
> at any given problem "in depth", so why have a huge email go out to
> the entire community?
>
> My idea may not be useful, I really am not sure. But my motive is
> trying to keep everybody's inbox from overflowing. And make it easier
> to supply really good data, but only to those who are interested.
>
> Thanks for any feedback.
>
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Wed Aug 13 23:51:39 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Aug 2014 14:51:39 -0700
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAL2fYnNvWuOz5On5epFXuJpQofu9pg4a_8zcG=wHCdRuPn4afw@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
	<CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
	<CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>
	<CAL2fYnNvWuOz5On5epFXuJpQofu9pg4a_8zcG=wHCdRuPn4afw@mail.gmail.com>
Message-ID: <CAF8bMcZMabVE5VW1YtreBgZykXx02S51M4hu+W4V3+R5L-1zvA@mail.gmail.com>

I may have missed something, but I didn't see the result you want for
your example.  Also,
none of the entries in the x1 you showed are row or column names in x,
making it hard to show what you want to happen.

Here is a function that gives you the choice of
    *error: stop if any row of x1 is 'bad'
    *omitRows: ignore rows of x1 are 'bad'
    *expandX: expand the x matrix to include all rows or columns named in x1
(Row i of x1 is 'bad' if that x1[,1] is not a rowname of x or x1[,2]
is not a column name of x).

f
function (x, x1, badEntryAction = c("error", "omitRows", "expandX"))
{
    badEntryAction <- match.arg(badEntryAction)
    i <- as.matrix(x1[, c("V1", "V2")])
    if (badEntryAction == "omitRows") {
        i <- i[is.element(i[, 1], dimnames(x)[[1]]) & is.element(i[,
            2], dimnames(x)[[2]]), , drop = FALSE]
    }
    else if (badEntryAction == "expandX") {
        extraDimnames <- lapply(1:2, function(k) setdiff(i[,
            k], dimnames(x)[[k]]))
        # if you want the same dimnames on both axes, take union of
the 2 extraDimnames
        if ((n <- length(extraDimnames[[1]])) > 0) {
            x <- rbind(x, array(0, c(n, ncol(x)), dimnames =
list(extraDimnames[[1]],
                NULL)))
        }
        if ((n <- length(extraDimnames[[2]])) > 0) {
            x <- cbind(x, array(0, c(nrow(x), n), dimnames = list(NULL,
                extraDimnames[[2]])))
        }
    }
    x[i] <- 1
    x
}

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Aug 13, 2014 at 2:33 PM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hello again. sorry for question again.
>
> may be I was not clear in asking before.
>
>  I don't want to remove rows from matrix, since row names and column
> names are identical in matrix.
>
>
> I tried your suggestion and here is what I get:
>
>> fx <- function(x,x1){
> + i <- as.matrix(x1[,c("V1","V2")])
> + x[i]<-1
> + x
> + }
>> fx(x, x1)
>
> Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds
>
>
>
>
>> x[1:4,1:4]
>        ABCA10 ABCA12 ABCA13 ABCA4
> ABCA10      0      0      0     0
> ABCA12      0      0      0     0
> ABCA13      0      0      0     0
> ABCA4       0      0      0     0
>
>
>> x1[1:10,]
>       V1       V2
> 1   AKT3    TCL1A
> 2  AKTIP    VPS41
> 3  AKTIP    PDPK1
> 4  AKTIP   GTF3C1
> 5  AKTIP    HOOK2
> 6  AKTIP    POLA2
> 7  AKTIP KIAA1377
> 8  AKTIP FAM160A2
> 9  AKTIP    VPS16
> 10 AKTIP    VPS18
>
>
> For instance, now I will loop over x1, I go to first row, I get V1 and
> check if if I have a row in x that have item in V1 and then check V2
> exist in colnames, if match then I assign 1. If not I go to row 2.
>
> In some rows, it is possible that I will only see element in V2 that
> exist in row names  and since element in V1 does not exist in X
> matrix, I will give 0. (since matrix X has identical row and column
> names, i feel it does not matter to check an element in column names
> after we check in row names)
>
>
>
> now for instance, If in X1 if I see ABCA10 in x1$V1 and ABCA10 in
> x1$V2 then in matrix X column 1 and row 1  should get 1.
>
> dput - follows..
>
> x <- structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(4L,
> 4L), .Dimnames = list(c("ABCA10", "ABCA12", "ABCA13", "ABCA4"
> ), c("ABCA10", "ABCA12", "ABCA13", "ABCA4")))
>
>
> x1 <- structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
> "AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
> "VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
> "VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
> 10L), class = "data.frame")
>
>
>
> Thanks for your time.
>
>
>
>
> On Wed, Aug 13, 2014 at 12:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> You can replace the loop
>>> for (i in nrow(x1)) {
>>>    x[x1$V1[i], x1$V2[i]] <- 1;
>>> }
>> by
>> f <- function(x, x1) {
>>   i <- as.matrix(x1[, c("V1","V2")]) # 2-column matrix to use as a subscript
>>   x[ i ] <- 1
>>   x
>> }
>> f(x, x1)
>>
>> You will get an error if not all the strings in the subscript matrix
>> are in the row or
>> column names of x.  What do you want to happen in this case.  You can choose
>> to first omit the bad rows in the subscript matrix
>>     goodRows <- is.element(i[,1], dimnames(x)[1]) &  is.element(i[,2],
>> dimnames(x)[2])
>>     i <- i[goodRows, , drop=FALSE]
>>     x[ i ] <- 1
>> or you can choose to expand x to include all the names found in x1.
>>
>> It would be good if you included some toy data to better illustrate
>> what you want to do.
>> E.g., with
>>   x <- array(0, c(3,3), list(Row=paste0("R",1:3),Col=paste0("C",1:3)))
>>   x1 <- data.frame(V1=c("R1","R3"), V2=c("C2","C1"))
>> the above f() gives
>>> f(x, x1)
>>     Col
>> Row  C1 C2 C3
>>   R1  0  1  0
>>   R2  0  0  0
>>   R3  1  0  0
>> Is that what you are looking for?


From wdunlap at tibco.com  Thu Aug 14 00:02:10 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Aug 2014 15:02:10 -0700
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAF8bMcZMabVE5VW1YtreBgZykXx02S51M4hu+W4V3+R5L-1zvA@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
	<CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
	<CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>
	<CAL2fYnNvWuOz5On5epFXuJpQofu9pg4a_8zcG=wHCdRuPn4afw@mail.gmail.com>
	<CAF8bMcZMabVE5VW1YtreBgZykXx02S51M4hu+W4V3+R5L-1zvA@mail.gmail.com>
Message-ID: <CAF8bMcZseF6mYJZKk=fTeYm+guc+ENi6=mXiCNghbHojX6Vyvg@mail.gmail.com>

Another solution is to use table to generate your x matrix, instead of
trying to make one and adding to it.  If you want the table to have
the same dimnames on both sides, make factors out of the columns of x1
with the same factor levels in both.  E.g., using a *small* example:

> X1 <- data.frame(V1=c("A","A","B"), V2=c("C","C","A"))
> X <- table(lapply(X1, factor, levels=union(levels(X1[[1]]), levels(X1[[2]]))))
> X
   V2
V1  A B C
  A 0 0 2
  B 1 0 0
  C 0 0 0

If you don't want counts, but just a TRUE for presence and FALSE for
absence, use X>0.  If you want 1 for presence and 0 for absence you
can use pmin(X, 1).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Aug 13, 2014 at 2:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I may have missed something, but I didn't see the result you want for
> your example.  Also,
> none of the entries in the x1 you showed are row or column names in x,
> making it hard to show what you want to happen.
>
> Here is a function that gives you the choice of
>     *error: stop if any row of x1 is 'bad'
>     *omitRows: ignore rows of x1 are 'bad'
>     *expandX: expand the x matrix to include all rows or columns named in x1
> (Row i of x1 is 'bad' if that x1[,1] is not a rowname of x or x1[,2]
> is not a column name of x).
>
> f
> function (x, x1, badEntryAction = c("error", "omitRows", "expandX"))
> {
>     badEntryAction <- match.arg(badEntryAction)
>     i <- as.matrix(x1[, c("V1", "V2")])
>     if (badEntryAction == "omitRows") {
>         i <- i[is.element(i[, 1], dimnames(x)[[1]]) & is.element(i[,
>             2], dimnames(x)[[2]]), , drop = FALSE]
>     }
>     else if (badEntryAction == "expandX") {
>         extraDimnames <- lapply(1:2, function(k) setdiff(i[,
>             k], dimnames(x)[[k]]))
>         # if you want the same dimnames on both axes, take union of
> the 2 extraDimnames
>         if ((n <- length(extraDimnames[[1]])) > 0) {
>             x <- rbind(x, array(0, c(n, ncol(x)), dimnames =
> list(extraDimnames[[1]],
>                 NULL)))
>         }
>         if ((n <- length(extraDimnames[[2]])) > 0) {
>             x <- cbind(x, array(0, c(nrow(x), n), dimnames = list(NULL,
>                 extraDimnames[[2]])))
>         }
>     }
>     x[i] <- 1
>     x
> }
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Aug 13, 2014 at 2:33 PM, Adrian Johnson
> <oriolebaltimore at gmail.com> wrote:
>> Hello again. sorry for question again.
>>
>> may be I was not clear in asking before.
>>
>>  I don't want to remove rows from matrix, since row names and column
>> names are identical in matrix.
>>
>>
>> I tried your suggestion and here is what I get:
>>
>>> fx <- function(x,x1){
>> + i <- as.matrix(x1[,c("V1","V2")])
>> + x[i]<-1
>> + x
>> + }
>>> fx(x, x1)
>>
>> Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds
>>
>>
>>
>>
>>> x[1:4,1:4]
>>        ABCA10 ABCA12 ABCA13 ABCA4
>> ABCA10      0      0      0     0
>> ABCA12      0      0      0     0
>> ABCA13      0      0      0     0
>> ABCA4       0      0      0     0
>>
>>
>>> x1[1:10,]
>>       V1       V2
>> 1   AKT3    TCL1A
>> 2  AKTIP    VPS41
>> 3  AKTIP    PDPK1
>> 4  AKTIP   GTF3C1
>> 5  AKTIP    HOOK2
>> 6  AKTIP    POLA2
>> 7  AKTIP KIAA1377
>> 8  AKTIP FAM160A2
>> 9  AKTIP    VPS16
>> 10 AKTIP    VPS18
>>
>>
>> For instance, now I will loop over x1, I go to first row, I get V1 and
>> check if if I have a row in x that have item in V1 and then check V2
>> exist in colnames, if match then I assign 1. If not I go to row 2.
>>
>> In some rows, it is possible that I will only see element in V2 that
>> exist in row names  and since element in V1 does not exist in X
>> matrix, I will give 0. (since matrix X has identical row and column
>> names, i feel it does not matter to check an element in column names
>> after we check in row names)
>>
>>
>>
>> now for instance, If in X1 if I see ABCA10 in x1$V1 and ABCA10 in
>> x1$V2 then in matrix X column 1 and row 1  should get 1.
>>
>> dput - follows..
>>
>> x <- structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(4L,
>> 4L), .Dimnames = list(c("ABCA10", "ABCA12", "ABCA13", "ABCA4"
>> ), c("ABCA10", "ABCA12", "ABCA13", "ABCA4")))
>>
>>
>> x1 <- structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
>> "AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
>> "VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
>> "VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
>> 10L), class = "data.frame")
>>
>>
>>
>> Thanks for your time.
>>
>>
>>
>>
>> On Wed, Aug 13, 2014 at 12:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> You can replace the loop
>>>> for (i in nrow(x1)) {
>>>>    x[x1$V1[i], x1$V2[i]] <- 1;
>>>> }
>>> by
>>> f <- function(x, x1) {
>>>   i <- as.matrix(x1[, c("V1","V2")]) # 2-column matrix to use as a subscript
>>>   x[ i ] <- 1
>>>   x
>>> }
>>> f(x, x1)
>>>
>>> You will get an error if not all the strings in the subscript matrix
>>> are in the row or
>>> column names of x.  What do you want to happen in this case.  You can choose
>>> to first omit the bad rows in the subscript matrix
>>>     goodRows <- is.element(i[,1], dimnames(x)[1]) &  is.element(i[,2],
>>> dimnames(x)[2])
>>>     i <- i[goodRows, , drop=FALSE]
>>>     x[ i ] <- 1
>>> or you can choose to expand x to include all the names found in x1.
>>>
>>> It would be good if you included some toy data to better illustrate
>>> what you want to do.
>>> E.g., with
>>>   x <- array(0, c(3,3), list(Row=paste0("R",1:3),Col=paste0("C",1:3)))
>>>   x1 <- data.frame(V1=c("R1","R3"), V2=c("C2","C1"))
>>> the above f() gives
>>>> f(x, x1)
>>>     Col
>>> Row  C1 C2 C3
>>>   R1  0  1  0
>>>   R2  0  0  0
>>>   R3  1  0  0
>>> Is that what you are looking for?


From jdnewmil at dcn.davis.CA.us  Thu Aug 14 00:14:15 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 13 Aug 2014 15:14:15 -0700
Subject: [R] opinion - sharing problem data and other stuff.
In-Reply-To: <CAM_vjumpp9RQwg=SW0biWcKpRv+OyFbJFo3gUiuS_AG56xmUDg@mail.gmail.com>
References: <CAAJSdjg77LFyKB2dOdYPhTYcky2RiiWT2XywTeGjndRmwGa9uw@mail.gmail.com>
	<CAM_vjumpp9RQwg=SW0biWcKpRv+OyFbJFo3gUiuS_AG56xmUDg@mail.gmail.com>
Message-ID: <fe697e91-bf8b-48c1-b26e-d0939d9a18a9@email.android.com>

Hear, hear. Getting the questioner to slow down and look at what they really want is key, because if they don't know what they want then their question will be unclear, and I hate answering a question that was never really what the OP was looking for in the first place.

One problem I have encountered is questions where key information is in a linked web page that goes away, rendering the posting archive useless. I suppose as long as gists don't "age out" they can be okay for some questions, but I am still way less likely to go digging there to answer questions in the first place.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 13, 2014 2:50:16 PM PDT, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>Hi John,
>
>People do sometimes link to external data and code, though I'm not
>sure I've seen any in that particular format.
>
>But, two things to consider.
>
>A. I'm lazy. If the problem is fully-formed in the email, I'm more
>likely to try to solve it than if I have to go download something and
>figure out what's in it. (Even leaving aside the potential issues with
>downloading random things.)
>
>B. A *small* reproducible example is usually a good thing. There are
>not that many cases where the whole big dataset is necessary. Further,
>the exercise of creating a small reproducible example is often enough
>to solve the problem, without ever needed to bother R-help at all.
>
>Granted, I'm also likely to skip posts to the list with enormous
>dput() data dumps too. I'm a big fan of the "small" part.
>
>Sarah
>
>On Wed, Aug 13, 2014 at 5:41 PM, John McKown
><john.archie.mckown at gmail.com> wrote:
>> This is just a thought that has occurred to me. I don't know if it is
>> an "Oh, WOW!" or an "Are you KIDDING?!?" type thought. So I thought
>> I'd ask here.
>>
>> I use github for a few things. Nothing great, but maybe nice. Anyway,
>> one feature of GitHub is the GIST feature. What I am used to github
>> being for is a project consisting of many complete files. A gist can
>> contain many files, but is really for a set of snippets. Such as code
>> sequences. Or maybe the output from a dput().
>>
>> If I have a "big" problem where I think that having all the data and
>> my attempted solutions available, I think it would be far kinder of
>me
>> to put a _good_ synopsis of the problem here on the list. And a
>> clickable URL to the gist I have created for the problem. That would
>> decrease the bandwidth on the email server. And save space on it.
>And,
>> lets face it, in many cases only a few people are going to really
>look
>> at any given problem "in depth", so why have a huge email go out to
>> the entire community?
>>
>> My idea may not be useful, I really am not sure. But my motive is
>> trying to keep everybody's inbox from overflowing. And make it easier
>> to supply really good data, but only to those who are interested.
>>
>> Thanks for any feedback.
>>
>>


From mccormack at molbio.mgh.harvard.edu  Thu Aug 14 00:49:51 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Wed, 13 Aug 2014 18:49:51 -0400
Subject: [R] find the data frames in list of objects and make a list of
 them
In-Reply-To: <CAGx1TMCE8gk=Z2tU9=P=A=coGifbZfmZ+chgbsXWVvxos=rSTw@mail.gmail.com>
References: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
	<CAGx1TMCE8gk=Z2tU9=P=A=coGifbZfmZ+chgbsXWVvxos=rSTw@mail.gmail.com>
Message-ID: <53EBEB8F.4080805@molbio.mgh.harvard.edu>

Hi Richard,

     Thank you very much for your reply and your code.
Your code is doing just what I asked for, but does not seem to be what I 
need.

I will need to review some basic R before I can continue.

I am trying to list data frames in order to bind them into 1 single data 
frame with something like: dplyr::rbind_all(list of data frames), but 
when I try dplyr::rbind_all(lsDataFrame(ls())), I get the error: object 
at index 1 not a data.frame. So, I am going to have to learn some more 
about lists in R before proceding.

Thank you for your help and code.

Matthew





Matthew

On 8/13/2014 3:12 PM, Richard M. Heiberger wrote:
> I would do something like this
>
> lsDataFrame <- function(xx=ls()) xx[sapply(xx, function(x)
> is.data.frame(get(x)))]
> ls("package:datasets")
> lsDataFrame(ls("package:datasets"))
>
> On Wed, Aug 13, 2014 at 2:56 PM, Matthew
> <mccormack at molbio.mgh.harvard.edu> wrote:
>> Hi everyone,
>>
>>     I would like the find which objects are data frames in all the objects I
>> have created ( in other words in what you get when you type: ls()  ), then I
>> would like to make a list of these data frames.
>>
>> Explained in other words; after typing ls(), you get the names of objects.
>> Which objects are data frames ?  How to then make a list of these data
>> frames.
>>
>>     A second question: is this the best way to make a list of data frames
>> without having to manually type c(dataframe1, dataframe2, ...)  ?
>>
>> Matthew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Aug 14 01:40:32 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 13 Aug 2014 16:40:32 -0700
Subject: [R] find the data frames in list of objects and make a list of
	them
In-Reply-To: <53EBEB8F.4080805@molbio.mgh.harvard.edu>
References: <53EBB4DF.7030709@molbio.mgh.harvard.edu>
	<CAGx1TMCE8gk=Z2tU9=P=A=coGifbZfmZ+chgbsXWVvxos=rSTw@mail.gmail.com>
	<53EBEB8F.4080805@molbio.mgh.harvard.edu>
Message-ID: <CAF8bMcZ=HF4TeU4qeq4R0hQpb2gLoR71hoRsWC7ToAwnGEYEcg@mail.gmail.com>

Previously you asked
>     A second question: is this the best way to make a list
>    of data frames without having to manually type c(dataframe1, dataframe2, ...)  ?

If you use 'c' there you will not get a list of data.frames - you will
get a list of all the columns in the data.frame you supplied.  Use
'list' instead of 'c' if you are taking that route.

The *apply functions are helpful  here.  To make list of all
data.frames in an environment you can use the following function,
which takes the environment to search as an argument.

f <- function(envir = globalenv()) {
    tmp <- eapply(envir,
                           all.names=TRUE,
                           FUN=function(obj) if (is.data.frame(obj))
obj else NULL)
    # remove NULL's now
    tmp[!vapply(tmp, is.null, TRUE)]
}

Use is as
  allDataFrames <- f(globalenv()) # or just f()






Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Aug 13, 2014 at 3:49 PM, Matthew
<mccormack at molbio.mgh.harvard.edu> wrote:
> Hi Richard,
>
>     Thank you very much for your reply and your code.
> Your code is doing just what I asked for, but does not seem to be what I
> need.
>
> I will need to review some basic R before I can continue.
>
> I am trying to list data frames in order to bind them into 1 single data
> frame with something like: dplyr::rbind_all(list of data frames), but when I
> try dplyr::rbind_all(lsDataFrame(ls())), I get the error: object at index 1
> not a data.frame. So, I am going to have to learn some more about lists in R
> before proceding.
>
> Thank you for your help and code.
>
> Matthew
>
>
>
>
>
> Matthew
>
> On 8/13/2014 3:12 PM, Richard M. Heiberger wrote:
>>
>> I would do something like this
>>
>> lsDataFrame <- function(xx=ls()) xx[sapply(xx, function(x)
>> is.data.frame(get(x)))]
>> ls("package:datasets")
>> lsDataFrame(ls("package:datasets"))
>>
>> On Wed, Aug 13, 2014 at 2:56 PM, Matthew
>> <mccormack at molbio.mgh.harvard.edu> wrote:
>>>
>>> Hi everyone,
>>>
>>>     I would like the find which objects are data frames in all the
>>> objects I
>>> have created ( in other words in what you get when you type: ls()  ),
>>> then I
>>> would like to make a list of these data frames.
>>>
>>> Explained in other words; after typing ls(), you get the names of
>>> objects.
>>> Which objects are data frames ?  How to then make a list of these data
>>> frames.
>>>
>>>     A second question: is this the best way to make a list of data frames
>>> without having to manually type c(dataframe1, dataframe2, ...)  ?
>>>
>>> Matthew
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Aug 14 02:02:41 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 13 Aug 2014 17:02:41 -0700
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
	loess curve using bootstrapping
In-Reply-To: <CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
Message-ID: <F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>


On Aug 12, 2014, at 8:40 AM, Bert Gunter wrote:

> PI's of what? -- future individual values or mean values?
> 
> I assume quantreg provides quantiles for the latter, not the former.
> (See ?predict.lm for a terse explanation of the difference).

I probably should have questioned the poster about what was meant by a "prediction interval for a monotonic loess curve". I was suggesting quantile regression for estimation of a chosen quantile, say the 90th percentile. I was thinking it could produce the analogue of a 90th percentile value (with no reference to a mean value or use of presumed distribution within adjacent windows of say 100-150 points. I had experience using the cobs function (in the package of the same name) as Koenker illustrates:

age <- runif(1000,min=60,max=85)
 
 analyte <- rlnorm(1000,4*(age/60),age/60)
 plot(age,analyte)

 library(cobs)
 library(quantreg)
 Rbs.9 <- cobs(age,analyte, constraint="increase",tau=0.9) 
Rbs.median <- cobs(age,analyte,constraint="increase",tau=0.5)

png("cobs.png"); plot(age,analyte, ylim=c(0,2000))
 lines(predict(Rbs.9), col = "red", lwd = 1.5)
lines(predict(Rbs.median), col = "blue", lwd = 1.5)
 dev.off()


-- David


> obtainable from bootstrapping but the details depend on what you are
> prepared to assume. Consult references or your local statistician for
> help if needed.
> 
> -- Bert
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
> Clifford Stoll
> 
> 
> 
> 
> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>> 
>>> Hi,
>>> 
>>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>> 
>>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>> 
>>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>> 
>>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>> 
>> 
>> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Thu Aug 14 04:21:21 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 13 Aug 2014 19:21:21 -0700
Subject: [R] Multivariate tobit regression
In-Reply-To: <DUB129-W776088E67EE5C80DD08382F8EA0@phx.gbl>
References: <mailman.2552.1407774434.4543.r-help@r-project.org>
	<DUB129-W776088E67EE5C80DD08382F8EA0@phx.gbl>
Message-ID: <f8d1deca-95b9-428e-abc8-2051028ab450@email.android.com>

RSiteSearch("tobit")
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 12, 2014 5:09:09 AM PDT, "Vera Migu?is" <veraoliveira523 at hotmail.com> wrote:
>Dear R-users,
> 
>I would like to run a multivariate tobit model in R. Is there any
>package
>available to perform this task?
> 
>Best regards,
>Printil
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Thu Aug 14 08:19:47 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 13 Aug 2014 23:19:47 -0700 (PDT)
Subject: [R] New reshape2 question
In-Reply-To: <53EB4B65.5030209@gmail.com>
References: <51729E37.6090901@gmail.com> <517449B8.6070304@gmail.com>
	<1366580336.79468.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517465D3.3060403@gmail.com>
	<1366589915.23423.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1366590216.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51748DC2.5070901@gmail.com>
	<1366593591.56084.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51749599.1070203@gmail.com>
	<1366595143.96394.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51750644.3080306@gmail.com>
	<1366634744.51811.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<5175395A.90703@gmail.com>
	<1366638500.75965.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517545FF.4090006@gmail.com>
	<1366643420.91270.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<517557FC.8020605@gmail.com>
	<1366647379.43478.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51756B86.7050302@gmail.com>
	<1366653815.44106.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<53EB4B65.5030209@gmail.com>
Message-ID: <alpine.BSF.2.00.1408132235500.68478@pedal.dcn.davis.ca.us>

See below.

On Wed, 13 Aug 2014, Neotropical bat risk assessments wrote:

> Hi all,
>
> Thanks go out to those who provided helpful suggestions last year with a 
> similar issue.
>
> I am working with a new data set and trying what I assumed was a simple 
> aggregation in reshape2 but is not working.  I have a large number of similar 
> data sets to run so getting the code correct is important.
>
> I have tried this code line in bold (both plyr and reshape2 are loaded):
>
>> ChenaPond <- read.table("C:/Bat papers in prep/Chile/Data & 
> analyses/ChenaPond.txt",header=T,sep="\t",quote="")

I find it most efficient to use the "stringsAsFactors=FALSE" option and
only convert to factor those columns that I know I want to be factors.

In particular, dates and times can be challenging to read in directly as 
date/times... I find it most clear to read them in as strings and
convert them using specific conversion statements.

> dat1<-ChenaPond
>> *res2<-ddply(dat1,.(Location,Species),summarize, Time=sum(Time))*
>
> *Error in Summary.factor(c(3L, 4L, 5L, 15L, 39L, 45L, 18L, 24L, 25L, 26L,  :
>  sum not meaningful for factors*
>
> Attached is the data.  Not sure why it is all factors and when I tried 
> changing to double precision the times were corrupted.  I recall that R does 
> not do well with time values.  Do I need a line using chron as well 
> beforehand?

R is actually much more specific about time values than, say, Excel. This
may make it appear to be a hassle, but it is actually capable of 
considerably more than Excel in regards to dates and times with a minimum 
of additional work. The hardest part is understanding how our calendar 
and timezones actually work.


chron is certainly an option, but I typically use POSIXt so that is what I 
am more familiar with.  You can read [1] and decide what you would prefer. 
Word to the wise: you will probably get into trouble if you convert POSIXt 
types to numeric... chron may be more forgiving.

> I even tried for several hours looking at the ReshapeGUI package to see what 
> I may have been doing incorrectly to no avail.

I am completely baffled why you chose to focus on the reshaping method 
rather than following the lead of your error above which pointed to 
factors as the problem.

>
> 1. What I need to do to analyze all the data in another program is to
>   reformat it so that I have a Species by Time matrix summarized in 5
>   minute time blocks.  The result needs to be Species as rows, and
>   time intervals are arranged chronologically in columns.

Below is one way to proceed. I suggest you step through it one piece at a 
time interspersed with appropriate use of the str() function to clarify 
what the data looks like at each step.  You probably ought to read 
?DateTimeClasses and follow links from there as well.

The follwing statement is the output of the "dput" function, which is 
recommended in [2].

dta <- structure(list(
   Species = c("Myochi", "Lascin", "Lascin", "Lascin",
     "Tadbra", "Lasvar", "Lasvar", "Lasvar", "Lascin", "Tadbra", "Lascin",
     "Lascin", "Lasvar", "Lasvar", "Lasvar", "Lasvar", "Lasvar", "Myochi",
     "Myochi", "Lascin", "Lasvar", "Lasvar", "Lasvar", "Myochi", "Lasvar",
     "Lascin", "Lascin", "Lascin", "Myochi", "Myochi", "Myochi", "Myochi",
     "Lascin", "Lasvar", "Lasvar", "Myochi", "Lasvar", "Lasvar", "Lascin",
     "Lasvar", "Lasvar", "Lascin", "Lascin", "Tadbra", "Lascin", "Lascin",
     "Lascin", "Lascin", "Lascin", "Lasvar", "Lasvar", "Lascin", "Lasvar",
     "Tadbra", "Myochi", "Myochi", "Lasvar", "Myochi", "Myochi", "Myochi",
     "Lasvar", "Lasvar", "Tadbra", "Lasvar", "Lasvar", "Lasvar", "Tadbra"
  ), Location = c("Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond",
     "Chena  pond", "Chena  pond", "Chena  pond", "Chena  pond"),
   Date = c("5/26/09", "5/26/09", "5/26/09", "5/26/09", "5/26/09",
     "5/26/09", "5/26/09", "5/26/09", "5/26/09", "5/26/09", "5/26/09",
     "5/26/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/15/09", "10/15/09", "10/15/09", "10/15/09", "10/15/09",
     "10/16/09"),
   Time = c("18:38", "18:51", "19:38", "19:39",
     "19:47", "20:12", "20:16", "20:56", "21:19", "21:20", "22:47",
     "22:56", "20:51", "20:55", "20:56", "20:57", "20:59", "21:00",
     "21:26", "21:29", "21:33", "21:34", "21:35", "21:55", "21:56",
     "21:59", "22:00", "22:01", "22:03", "22:08", "22:08", "22:09",
     "22:17", "22:23", "22:24", "22:26", "22:30", "22:31", "22:42",
     "22:42", "22:44", "22:46", "22:49", "22:49", "22:50", "22:51",
     "22:53", "22:54", "22:57", "23:01", "23:06", "23:08", "23:09",
     "23:14", "23:30", "23:31", "23:33", "23:35", "23:35", "23:38",
     "23:39", "23:44", "23:45", "23:47", "23:52", "23:59", "0:00"
   )),
  .Names = c("Species", "Location", "Date", "Time")
  , class = "data.frame", row.names = c(NA, -67L))

library(lubridate)
library(reshape2)
# set time zone to something that doesn't use daylight savings
# this may not be how your data are actually recorded... look
# up ?timezones ... the short answer is you may need to look
# at the names of some files on your system or in your R install
# directory to find out what labels correspond to your data's timezone.
Sys.setenv( TZ="Etc/GMT+5" )
dta$Dtm <- mdy_hm( paste( dta$Date, dta$Time ) )
floor5 <- function( dtm ) {
   # break up the POSIXct (number of seconds since 1/1/1970 GMT)
   dtmlt <- as.POSIXlt( dtm )
   # floor the minutes and seconds to the next lower 5 minutes
   dtmlt$sec <- 0
   dtmlt$min <- 5 * ( dtmlt$min %/% 5 )
   as.POSIXct( dtmlt )
}
dta$Dtm5 <- floor5( dta$Dtm )

# can be done with table
#table( dta$Dtm5, dta$Species )
# I prefer data frames, so reshape2 helps out
dtat <- dcast( dta, Dtm5~Species, fun.aggregate = length, value.var="Dtm5" )


> 2. Then I need the matrix converted such that each unique Species will
>   have proportional abundances of time (0 to 100) so totals for each
>   species should be the same (or 100%).

I don't like to do all the work for other people. Is dividing some vectors 
by their sums something you need help with?

> What do folks suggest?
> Plyr, Reshape2 or try tables?

Any of these... depending on your preference. You just need to get a grip 
on how R handles time. [1]

> Thanks,
>
> Bruce
>
> -- 
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
>
> If we lose the bats, we may lose much of the tropical vegetation and the 
> lungs of the planet
>
> Using acoustic sampling to map species distributions for >15 years.
>
> Providing Interactive identification keys to the vocal signatures of New 
> World Bats
>
> For various project details see:
>
> https://sites.google.com/site/batsoundservices/
>
>

[1] http://www.r-project.org/doc/Rnews/Rnews_2004-1.pdf starting on page 29

[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Thu Aug 14 08:53:01 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 13 Aug 2014 23:53:01 -0700 (PDT)
Subject: [R] scale_*_manual in ggplot2
In-Reply-To: <OFFC4B249C.965E7CE8-ON80257D33.00438F6F-80257D33.00482F97@uk.royalsun.com>
References: <OFFC4B249C.965E7CE8-ON80257D33.00438F6F-80257D33.00482F97@uk.royalsun.com>
Message-ID: <alpine.BSF.2.00.1408132322440.76651@pedal.dcn.davis.ca.us>

There is a difference between specifying a scale inside the aes or 
aes_string functions, and doing it in the arguments to the geom function. 
Inside the aes function call it creates a mapping from your input data to 
the layer variables, and you do not want to specify strings such as 
"Cusum" but rather always specify variables such as Cusum. Outside the aes 
function among the geom parameters, you can create ad-hoc settings for 
that geom that might specify colors as strings.  However, AFAIK you cannot 
build a legend in ggplot2 that describes those ad-hoc settings, so if you 
want a legend that mentions them then you need to create your data to 
contain e.g. all colour settings in one or more columns of a "long" 
version of your data (it definitely works best to have them all in one 
column). You can use the subset option to partition your "long" data among 
the different geoms even while having all the colour settings in the same 
column. The "reshape2" package is useful for creating these special 
display-ready data frames that stack variables together to fit the 
graphic you are mapping it to.

I could not get your sample code to run, and I am daunted by the 
complexity of your sample code. Perhaps the above tips will help, or you 
can post a simpler example.  One way or another, you will need to learn 
the language of visualization that ggplot2 is designed around... perhaps 
read Hadley Wickhams "ggplot" book. If that paradigm doesn't fit your way 
of thinking, then you might have more success using lattice plots.

On Wed, 13 Aug 2014, Pavneet Arora wrote:

> Data
> this is the data I used for the following problems:
>
> dput(sdf)
> structure(list(weeks = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 
> 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 
> 29, 30), values = c(9.45, 7.99, 9.29, 11.66, 12.16, 10.18, 8.04, 
> 11.46, 9.2, 10.34, 9.03, 11.47, 10.51, 9.4, 10.08, 9.37, 10.62, 
> 10.31, 10, 13, 10.9, 9.33, 12.29, 11.5, 10.6, 11.08, 10.38, 11.62, 
> 11.31, 10.52), deviation = c(-0.550000000000001, -2.01, 
> -0.710000000000001, 
> 1.66, 2.16, 0.18, -1.96, 1.46, -0.800000000000001, 0.34, 
> -0.970000000000001, 
> 1.47, 0.51, -0.6, 0.0800000000000001, -0.630000000000001, 
> 0.619999999999999, 
> 0.31, 0, 3, 0.9, -0.67, 2.29, 1.5, 0.6, 1.08, 0.380000000000001, 
> 1.62, 1.31, 0.52), cusums = c(-0.550000000000001, -2.56, -3.27, 
> -1.61, 0.549999999999999, 0.729999999999999, -1.23, 0.229999999999999, 
> -0.570000000000002, -0.230000000000002, -1.2, 0.269999999999998, 
> 0.779999999999998, 0.179999999999998, 0.259999999999998, 
> -0.370000000000003, 
> 0.249999999999996, 0.559999999999997, 0.559999999999997, 3.56, 
> 4.46, 3.79, 6.08, 7.58, 8.18, 9.26, 9.64, 11.26, 12.57, 13.09
> ), ma = c(NA, 1.46, 1.3, 2.37, 0.5, 1.98, 2.14, 3.42, 2.26, 1.14, 
> 1.31, 2.44, 0.960000000000001, 1.11, 0.68, 0.710000000000001, 
> 1.25, 0.309999999999999, 0.31, 3, 2.1, 1.57, 2.96, 0.789999999999999, 
> 0.9, 0.48, 0.699999999999999, 1.24, 0.309999999999999, 0.790000000000001
> ), Vupper = c(32.59, 32.09, 31.59, 31.09, 30.59, 30.09, 29.59, 
> 29.09, 28.59, 28.09, 27.59, 27.09, 26.59, 26.09, 25.59, 25.09, 
> 24.59, 24.09, 23.59, 23.09, 22.59, 22.09, 21.59, 21.09, 20.59, 
> 20.09, 19.59, 19.09, 18.59, 18.09), Vlower = c(-6.41, -5.91, 
> -5.41, -4.91, -4.41, -3.91, -3.41, -2.91, -2.41, -1.91, -1.41, 
> -0.910000000000004, -0.410000000000004, 0.0899999999999963, 
> 0.589999999999996, 
> 1.09, 1.59, 2.09, 2.59, 3.09, 3.59, 4.09, 4.59, 5.09, 5.59, 6.09, 
> 6.59, 7.09, 7.59, 8.09)), .Names = c("weeks", "values", "deviation", 
> "cusums", "ma", "Vupper", "Vlower"), row.names = c(NA, -30L), class = 
> "data.frame")
>
> Problem1:
> I am trying to create a chart using ggplot2. This plot contains 2 
> geom_lines and 1geom_point.
> But for some reason the geom_point is not being picked up by the legend. 
> Can someone help me explain why that maybe?
> This is the code I have used for the above data.
>
> vmaskPlot <- ggplot(sdf,aes(ymin=min(sdf$cusums,sdf$Vupper,sdf$Vlower),
>                        ymax=(max(sdf$cusums,sdf$Vupper,sdf$Vlower)),
>                        x=week))+
>  labs(x=NULL,y=NULL)+
>  #   theme (panel.grid.major=element_line(color="white",size=0.5),
>  #          panel.grid.minor=element_blank(),
>  #          panel.grid.major.x=element_blank(),
>  #          axis.line.y=element_line(color="black"),
>  #          panel.background=element_rect(fill="lightgray"))+
>  #   guide=guide_legend(direction="horizontal",
>  #                      title.position="top",
>  #                      label.position="bottom",
>  #                      label.hjust=0.5,
>  #                      label.vjust=0.5,
>  #                      label.theme=element_text(angle=90))+
> scale_y_continuous()+
>  scale_x_discrete(breaks=seq(min(sdf$week),
>                              max(sdf$week)))+
>  geom_point(aes(y=cusums,colour="Cusum"),size=4,pch=15)+
>  geom_line(aes(y=Vupper,colour="Vupper"),size=2.5,alpha=1/2)+ #alpha = 
> determines the ? of transparency
>  geom_line(aes(y=Vlower,colour="Vlower"),size=2.5,alpha=1/2)+
>  geom_hline(aes(yintercept=0),colour="gray20",size=1)+ #geom_hline - 
> draws a reference line at 0
>  ggtitle("V-Mask Cusum")+
>  theme(legend.position=c(0.9,0.9),
>        plot.title=element_text(family="Times",
>                                face="bold",
>                                size=20))+
>  scale_color_manual(name="Legend",
>                     breaks=c("cusums","Vupper","Vlower"),
>                     values=c("dodgerblue1","brown3","darkolivegreen4"),
>                     labels=c("CuSums","Upper V-Mask ","Lower V-Mask "))
> 
> vmaskPlot
> Problem2:
> In this ggplot, the legend is coming in separate boxes ? is there any way 
> I can combine them in same? Also where it says ?tabuCusum$cusums? ? I just 
> want it to say ?CuSums?. I thought I had mentioned this in my code, so why 
> is it not picking up?
> Furthermore, the code doesn?t seem to pick up the colours I suggested, 
> except for the bars ? which are exactly like I want them to be.
> But I want the pink dots to dodgerblue1. The 2 horizontal lines close to 
> y=0 were supposed to be gold2 colour and the 2 outer horizontal lines were 
> supposed to be darkorchid colour as mentioned in the code. 
> Does anyone know why it?s not picking up the colours mentioned?
> Following is my code:
> ggplot(sdf,aes(x=weeks,
>                     ymin=min(sdf$cusums,sdf$Tupper,sdf$Tlower)-3,
>                     ymax=max(sdf$cusums,sdf$Tupper,sdf$Tlower)+3))+
>  labs(x=NULL,y=NULL)+
>  scale_y_continuous(expand=c(0,0),
>                     minor_breaks=seq(round(min(sdf$cusums,sdf$Tupper,
> sdf$Tlower)-2),
>                                      round(max(sdf$cusums,sdf$Tupper,
> sdf$Tlower)+2),
>                                      1),
>                     breaks=seq(round(min(sdf$cusums,sdf$Tupper,sdf$Tlower
> )-2),
>                                round(max(sdf$cusums,sdf$Tupper,sdf$Tlower
> )+2),
>                                2))+
>  scale_x_discrete(expand=c(0,0),
>                   breaks=seq(min(sdf$weeks),
>                              max(sdf$weeks)))+
>  geom_bar(data=sdf,aes(y=sdf$Tupper,fill="sdf$Tupper"),stat="identity")+
>  geom_bar(data=sdf,aes(y=sdf$Tlower,fill="sdf$Tlower"),stat="identity")+
>  geom_point(aes(y=sdf$cusums,colour="sdf$cusums"),size=4,pch=15)+
>  geom_hline(aes(yintercept=0,colour="Line1"),size=1)+
>  geom_hline(aes(yintercept=5,colour="Line2"),size=2,alpha=1/1.3)+ 
> #Out-Of-Signal Lines
>  geom_hline(aes(yintercept=-5,colour="Line3"),size=2,alpha=1/1.3)+ 
> #Out-Of-Signal Lines
>  geom_hline(aes(yintercept=0.5,colour="Line4"),size=2,alpha=1/1.3)+ #K
>  geom_hline(aes(yintercept=-0.5,colour="Line5"),size=2,alpha=1/1.3)+ #K
>  theme(legend.position=c(0.1,0.7),
>        plot.title=element_text(family="Times",
>                                face="bold",
>                                size=20))+
> #   guides(linetype = guide_legend(override.aes = list(colour = 
> c("gray20","darkorchid","darkorchid","gold2","gold2"))))+
> # 
> override.aes=list(colour=c("gray20","darkorchid","darkorchid","gold2","gold2")) 
>
>  # LEGEND FOR BAR CHART
>  scale_fill_manual(name="Legend",
>                    breaks=c("sdf$Tlower","sdf$Tupper","sdf$cusums",
>                             "Line1","Line2","Line3","Line4","Line5"),
>                    values=c("darkolivegreen4","brown3","dodgerblue1",
>                             "gray20","darkorchid","darkorchid","gold2",
> "gold2"),
>                    labels=c("Lower Tabular Mask","Upper Tabular Mask",
> "Cusum",
>                             "Line1","Line2","Line3","Line4","Line5"))
>
> ***********************************************************************************************************************************************************************************************************************
> MORE TH>N is a trading style of Royal & Sun Alliance Insurance plc (No. 93792). Registered in England and Wales at St. Mark?s Court, Chart Way, Horsham, West Sussex, RH12 1XL. 
>
> Authorised by the Prudential Regulation Authority and regulated by the Financial Conduct Authority and the Prudential Regulation Authority.
> ************************************************************************************************************************************************************************************************************************
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From neotropical.bats at gmail.com  Thu Aug 14 15:25:13 2014
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Thu, 14 Aug 2014 09:25:13 -0400
Subject: [R] New reshape2 question answered
In-Reply-To: <1366653815.44106.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <51729E37.6090901@gmail.com>
	<1366563896.71414.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<517449B8.6070304@gmail.com>
	<1366580336.79468.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517465D3.3060403@gmail.com>
	<1366589915.23423.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1366590216.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51748DC2.5070901@gmail.com>
	<1366593591.56084.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51749599.1070203@gmail.com>
	<1366595143.96394.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51750644.3080306@gmail.com>
	<1366634744.51811.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<5175395A.90703@gmail.com>
	<1366638500.75965.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517545FF.4090006@gmail.com>
	<1366643420.91270.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<517557FC.8020605@gmail.com>
	<1366647379.43478.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51756B86.7050302@gmail.com>
	<1366653815.44106.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <53ECB8B9.7010304@gmail.com>

Hi all,

Thanks all who replied. Arun, Jim and Jeff.

Seems like there are always multiple ways to achieve the same goals with R!

Jim Holtman suggested using the base functions.

Not PLYR or RESHAPE

x <- read.table(text = "Species Location Date Time...
Myochi Chena   5/26/09 18:38
	remaining data table, as.is = TRUE, header = TRUE)
# convert time to 15 minute intervals
z <- do.call(rbind, strsplit(x$Time, ":"))
mode(z) <- 'numeric'  # convert to numeric
# create 15 minute intervals
x$int15 <- floor(z %*% c(60/15, 1/15)) + 1  # make first interval 1
# create count by species
count <- do.call(rbind, lapply(split(x, x$Species), function(a){
     c(tabulate(a$int15), rep(0,96))[1:96]  # pad out to 96 values if required
     }
     )
)

percent <- t(apply(count, 1, function(a) a / sum(a) * 100))


++++++++++++++++++++++++++
Jeff Newmiller suggested I step through the problem one piece at a
time interspersed with appropriate use of the str() function to clarify
what the data looks like at each step.  Also suggested I ought to read
?DateTimeClasses and follow links from there as well.
So some homework there for me.


He suggested a better means to handling dates with this:
library(lubridate)
library(reshape2)

# set time zone to something that doesn't use daylight savings
# this may not be how your data are actually recorded... look
# up ?timezones ... the short answer is you may need to look
# at the names of some files on your system or in your R install
# directory to find out what labels correspond to your data's timezone.
Sys.setenv( TZ="Etc/GMT+5" )
dta$Dtm <- mdy_hm( paste( dta$Date, dta$Time ) )
floor5 <- function( dtm ) {

   # break up the POSIXct (number of seconds since 1/1/1970 GMT)
   dtmlt <- as.POSIXlt( dtm )
   # floor the minutes and seconds to the next lower 5 minutes
   dtmlt$sec <- 0
   dtmlt$min <- 5 * ( dtmlt$min %/% 5 )
   as.POSIXct( dtmlt )
}

dta$Dtm5 <- floor5( dta$Dtm )
# can be done with table
#table( dta$Dtm5, dta$Species )
# I prefer data frames, so reshape2 helps out
dtat <- dcast( dta, Dtm5~Species, fun.aggregate = length, value.var="Dtm5" )


From jdnewmil at dcn.davis.CA.us  Thu Aug 14 16:24:12 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 14 Aug 2014 07:24:12 -0700
Subject: [R] New reshape2 question
In-Reply-To: <53ECB9B3.2090008@gmail.com>
References: <51729E37.6090901@gmail.com>
	<1366580336.79468.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517465D3.3060403@gmail.com>
	<1366589915.23423.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1366590216.1721.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51748DC2.5070901@gmail.com>
	<1366593591.56084.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<51749599.1070203@gmail.com>
	<1366595143.96394.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51750644.3080306@gmail.com>
	<1366634744.51811.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<5175395A.90703@gmail.com>
	<1366638500.75965.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<517545FF.4090006@gmail.com>
	<1366643420.91270.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<517557FC.8020605@gmail.com>
	<1366647379.43478.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<51756B86.7050302@gmail.com>
	<1366653815.44106.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<53EB4B65.5030209@gmail.com>
	<alpine.BSF.2.00.1408132235500.68478@pedal.dcn.davis.ca.us>
	<53ECB9B3.2090008@gmail.com>
Message-ID: <48ede722-233e-4467-b5f3-ee7fcc81df6f@email.android.com>

You shouldn't need to worry about your system clock (time)  for analyzing time data from files, but only your system timezone. The default value of TZ leads to assuming system timezone... setting it explicitly changes the assumed timezone for the purposes of the current instance of R. 
I prefer to keep the conversation on list so others can chime in or learn from the exchange or correct my mistakes.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 14, 2014 6:29:23 AM PDT, Neotropical bat risk assessments <neotropical.bats at gmail.com> wrote:
>Tnx Jeff,
>
>I will work through your suggestions.
>The time zone is actually in Chile and not U.S. time zones.
>
>The use of POSIXt is something I need to get up to speed with.
>It may make more sense ecologically to combine the dates and times then
>
>summarize into 15 minute time blocks.  I will need to read carefully
>how 
>to avoid using my workstation system clock in doing this for data 
>conversions of times from other time zones.
>
>Bruce


From oriolebaltimore at gmail.com  Thu Aug 14 17:15:04 2014
From: oriolebaltimore at gmail.com (Adrian Johnson)
Date: Thu, 14 Aug 2014 11:15:04 -0400
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAF8bMcZseF6mYJZKk=fTeYm+guc+ENi6=mXiCNghbHojX6Vyvg@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
	<CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
	<CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>
	<CAL2fYnNvWuOz5On5epFXuJpQofu9pg4a_8zcG=wHCdRuPn4afw@mail.gmail.com>
	<CAF8bMcZMabVE5VW1YtreBgZykXx02S51M4hu+W4V3+R5L-1zvA@mail.gmail.com>
	<CAF8bMcZseF6mYJZKk=fTeYm+guc+ENi6=mXiCNghbHojX6Vyvg@mail.gmail.com>
Message-ID: <CAL2fYnPFDCCXn4n6EKu2p4T=DfiR5jpf9GYd_JCJ0+Pr1Uq+iA@mail.gmail.com>

Hi Bill,
sorry for trouble. It did not work both solutions.
Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds


my x matrix is may not have  items that x1 has.

say x only has A,B, C, D  , whereas x1 has K, L, M , A and D.  However
x1 does not have any relationship between B and C thus B-C will be a
zero anyway.

x1 :

K   L
D  A
K  M
M  A
Although M associates with A, since M is not present in X - we will
not map this association with 1. Since A and D are present in X - we
will assign 1.



   A  B  C  D

A 0  0  0  0

B 0  0  0  0

C 0  0  0  0

D  1 0  0  0


I tried this simple for loop but I get same subset error:


for(k in nrow(x1)){
x[x1[k,]$V1,x1[k,]$V2] <- 1
x[x1[,k]$V1,x1[,k]$V2] <- 1
x[x1[,k]$V2,x1[,k]$V1] <- 1
}

Error in `[<-`(`*tmp*`, hprd[x, ]$V1, hprd[x, ]$V2, value = 1) :
  subscript out of bounds

Thanks again.

On Wed, Aug 13, 2014 at 6:02 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Another solution is to use table to generate your x matrix, instead of
> trying to make one and adding to it.  If you want the table to have
> the same dimnames on both sides, make factors out of the columns of x1
> with the same factor levels in both.  E.g., using a *small* example:
>
>> X1 <- data.frame(V1=c("A","A","B"), V2=c("C","C","A"))
>> X <- table(lapply(X1, factor, levels=union(levels(X1[[1]]), levels(X1[[2]]))))
>> X
>    V2
> V1  A B C
>   A 0 0 2
>   B 1 0 0
>   C 0 0 0
>
> If you don't want counts, but just a TRUE for presence and FALSE for
> absence, use X>0.  If you want 1 for presence and 0 for absence you
> can use pmin(X, 1).
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Aug 13, 2014 at 2:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> I may have missed something, but I didn't see the result you want for
>> your example.  Also,
>> none of the entries in the x1 you showed are row or column names in x,
>> making it hard to show what you want to happen.
>>
>> Here is a function that gives you the choice of
>>     *error: stop if any row of x1 is 'bad'
>>     *omitRows: ignore rows of x1 are 'bad'
>>     *expandX: expand the x matrix to include all rows or columns named in x1
>> (Row i of x1 is 'bad' if that x1[,1] is not a rowname of x or x1[,2]
>> is not a column name of x).
>>
>> f
>> function (x, x1, badEntryAction = c("error", "omitRows", "expandX"))
>> {
>>     badEntryAction <- match.arg(badEntryAction)
>>     i <- as.matrix(x1[, c("V1", "V2")])
>>     if (badEntryAction == "omitRows") {
>>         i <- i[is.element(i[, 1], dimnames(x)[[1]]) & is.element(i[,
>>             2], dimnames(x)[[2]]), , drop = FALSE]
>>     }
>>     else if (badEntryAction == "expandX") {
>>         extraDimnames <- lapply(1:2, function(k) setdiff(i[,
>>             k], dimnames(x)[[k]]))
>>         # if you want the same dimnames on both axes, take union of
>> the 2 extraDimnames
>>         if ((n <- length(extraDimnames[[1]])) > 0) {
>>             x <- rbind(x, array(0, c(n, ncol(x)), dimnames =
>> list(extraDimnames[[1]],
>>                 NULL)))
>>         }
>>         if ((n <- length(extraDimnames[[2]])) > 0) {
>>             x <- cbind(x, array(0, c(nrow(x), n), dimnames = list(NULL,
>>                 extraDimnames[[2]])))
>>         }
>>     }
>>     x[i] <- 1
>>     x
>> }
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Aug 13, 2014 at 2:33 PM, Adrian Johnson
>> <oriolebaltimore at gmail.com> wrote:
>>> Hello again. sorry for question again.
>>>
>>> may be I was not clear in asking before.
>>>
>>>  I don't want to remove rows from matrix, since row names and column
>>> names are identical in matrix.
>>>
>>>
>>> I tried your suggestion and here is what I get:
>>>
>>>> fx <- function(x,x1){
>>> + i <- as.matrix(x1[,c("V1","V2")])
>>> + x[i]<-1
>>> + x
>>> + }
>>>> fx(x, x1)
>>>
>>> Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds
>>>
>>>
>>>
>>>
>>>> x[1:4,1:4]
>>>        ABCA10 ABCA12 ABCA13 ABCA4
>>> ABCA10      0      0      0     0
>>> ABCA12      0      0      0     0
>>> ABCA13      0      0      0     0
>>> ABCA4       0      0      0     0
>>>
>>>
>>>> x1[1:10,]
>>>       V1       V2
>>> 1   AKT3    TCL1A
>>> 2  AKTIP    VPS41
>>> 3  AKTIP    PDPK1
>>> 4  AKTIP   GTF3C1
>>> 5  AKTIP    HOOK2
>>> 6  AKTIP    POLA2
>>> 7  AKTIP KIAA1377
>>> 8  AKTIP FAM160A2
>>> 9  AKTIP    VPS16
>>> 10 AKTIP    VPS18
>>>
>>>
>>> For instance, now I will loop over x1, I go to first row, I get V1 and
>>> check if if I have a row in x that have item in V1 and then check V2
>>> exist in colnames, if match then I assign 1. If not I go to row 2.
>>>
>>> In some rows, it is possible that I will only see element in V2 that
>>> exist in row names  and since element in V1 does not exist in X
>>> matrix, I will give 0. (since matrix X has identical row and column
>>> names, i feel it does not matter to check an element in column names
>>> after we check in row names)
>>>
>>>
>>>
>>> now for instance, If in X1 if I see ABCA10 in x1$V1 and ABCA10 in
>>> x1$V2 then in matrix X column 1 and row 1  should get 1.
>>>
>>> dput - follows..
>>>
>>> x <- structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(4L,
>>> 4L), .Dimnames = list(c("ABCA10", "ABCA12", "ABCA13", "ABCA4"
>>> ), c("ABCA10", "ABCA12", "ABCA13", "ABCA4")))
>>>
>>>
>>> x1 <- structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
>>> "AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
>>> "VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
>>> "VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
>>> 10L), class = "data.frame")
>>>
>>>
>>>
>>> Thanks for your time.
>>>
>>>
>>>
>>>
>>> On Wed, Aug 13, 2014 at 12:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> You can replace the loop
>>>>> for (i in nrow(x1)) {
>>>>>    x[x1$V1[i], x1$V2[i]] <- 1;
>>>>> }
>>>> by
>>>> f <- function(x, x1) {
>>>>   i <- as.matrix(x1[, c("V1","V2")]) # 2-column matrix to use as a subscript
>>>>   x[ i ] <- 1
>>>>   x
>>>> }
>>>> f(x, x1)
>>>>
>>>> You will get an error if not all the strings in the subscript matrix
>>>> are in the row or
>>>> column names of x.  What do you want to happen in this case.  You can choose
>>>> to first omit the bad rows in the subscript matrix
>>>>     goodRows <- is.element(i[,1], dimnames(x)[1]) &  is.element(i[,2],
>>>> dimnames(x)[2])
>>>>     i <- i[goodRows, , drop=FALSE]
>>>>     x[ i ] <- 1
>>>> or you can choose to expand x to include all the names found in x1.
>>>>
>>>> It would be good if you included some toy data to better illustrate
>>>> what you want to do.
>>>> E.g., with
>>>>   x <- array(0, c(3,3), list(Row=paste0("R",1:3),Col=paste0("C",1:3)))
>>>>   x1 <- data.frame(V1=c("R1","R3"), V2=c("C2","C1"))
>>>> the above f() gives
>>>>> f(x, x1)
>>>>     Col
>>>> Row  C1 C2 C3
>>>>   R1  0  1  0
>>>>   R2  0  0  0
>>>>   R3  1  0  0
>>>> Is that what you are looking for?


From wdunlap at tibco.com  Thu Aug 14 18:00:23 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 Aug 2014 09:00:23 -0700
Subject: [R] populating matrix with binary variable after matching data
 from data frame
In-Reply-To: <CAL2fYnPFDCCXn4n6EKu2p4T=DfiR5jpf9GYd_JCJ0+Pr1Uq+iA@mail.gmail.com>
References: <CAL2fYnOcRumWFiOX_qKj02a6G-wDtEh+PH_E0G7ONkCNd+SKUg@mail.gmail.com>
	<CAAJSdjhM6Y6ge3YaMJ3R3Ws3hek4tXXKEgUzWCfU18-dbqQ=Zg@mail.gmail.com>
	<CAL2fYnMduzyyZ4jZ6U_CTgNabTokLbeCSh86kT9zMPLfz_JjbA@mail.gmail.com>
	<CAF8bMcYa-z-ycfSF2_Pdaev2g4O7d8y3=vsuyR30chw1Nv=5KQ@mail.gmail.com>
	<CAL2fYnNvWuOz5On5epFXuJpQofu9pg4a_8zcG=wHCdRuPn4afw@mail.gmail.com>
	<CAF8bMcZMabVE5VW1YtreBgZykXx02S51M4hu+W4V3+R5L-1zvA@mail.gmail.com>
	<CAF8bMcZseF6mYJZKk=fTeYm+guc+ENi6=mXiCNghbHojX6Vyvg@mail.gmail.com>
	<CAL2fYnPFDCCXn4n6EKu2p4T=DfiR5jpf9GYd_JCJ0+Pr1Uq+iA@mail.gmail.com>
Message-ID: <CAF8bMcZ63+B+XbDB2VGPHyE7giKEa2iwOTcgu-NkRR76EyY95g@mail.gmail.com>

This is what I got:
> x1 <- data.frame(V1=c("K","D","K","M"), V2=c("L","A","M","A"))
> X <- array(0, c(4,4), rep(list(LETTERS[1:4]), 2))
> f(X, x1, badEntryAction="omitRows")
  A B C D
A 0 0 0 0
B 0 0 0 0
C 0 0 0 0
D 1 0 0 0
> table(lapply(x1, factor, levels=LETTERS[1:4]))
   V2
V1  A B C D
  A 0 0 0 0
  B 0 0 0 0
  C 0 0 0 0
  D 1 0 0 0

I think you should sort out how your attempts went wrong.

My original 'f' assumed, perhaps foolishly, that x1 had columns names
"V1" and "V2",
perhaps it should have said just i<-as.matrix(x1) and checked that the result
was a 2-column matrix of character data.  E.g.,
f <- function (x, x1, badEntryAction = c("error", "omitRows", "expandX"))
{
    badEntryAction <- match.arg(badEntryAction)
    i <- as.matrix(x1)
    stopifnot(is.character(i), ncol(i)==2)
    if (badEntryAction == "omitRows") {
        i <- i[is.element(i[, 1], dimnames(x)[[1]]) &
               is.element(i[, 2], dimnames(x)[[2]]), , drop = FALSE]
    }
    else if (badEntryAction == "expandX") {
        extraDimnames <- lapply(1:2, function(k) setdiff(i[,
            k], dimnames(x)[[k]]))
        # if you want the same dimnames on both axes,
        # take union of the 2 extraDimnames
        if ((n <- length(extraDimnames[[1]])) > 0) {
            x <- rbind(x, array(0, c(n, ncol(x)),
                       dimnames = list(extraDimnames[[1]], NULL)))
        }
        if ((n <- length(extraDimnames[[2]])) > 0) {
            x <- cbind(x, array(0, c(nrow(x), n), dimnames = list(NULL,
                extraDimnames[[2]])))
        }
    }
    x[i] <- 1
    x
}

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 14, 2014 at 8:15 AM, Adrian Johnson
<oriolebaltimore at gmail.com> wrote:
> Hi Bill,
> sorry for trouble. It did not work both solutions.
> Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds
>
>
> my x matrix is may not have  items that x1 has.
>
> say x only has A,B, C, D  , whereas x1 has K, L, M , A and D.  However
> x1 does not have any relationship between B and C thus B-C will be a
> zero anyway.
>
> x1 :
>
> K   L
> D  A
> K  M
> M  A
> Although M associates with A, since M is not present in X - we will
> not map this association with 1. Since A and D are present in X - we
> will assign 1.
>
>
>
>    A  B  C  D
>
> A 0  0  0  0
>
> B 0  0  0  0
>
> C 0  0  0  0
>
> D  1 0  0  0
>
>
> I tried this simple for loop but I get same subset error:
>
>
> for(k in nrow(x1)){
> x[x1[k,]$V1,x1[k,]$V2] <- 1
> x[x1[,k]$V1,x1[,k]$V2] <- 1
> x[x1[,k]$V2,x1[,k]$V1] <- 1
> }
>
> Error in `[<-`(`*tmp*`, hprd[x, ]$V1, hprd[x, ]$V2, value = 1) :
>   subscript out of bounds
>
> Thanks again.
>
> On Wed, Aug 13, 2014 at 6:02 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> Another solution is to use table to generate your x matrix, instead of
>> trying to make one and adding to it.  If you want the table to have
>> the same dimnames on both sides, make factors out of the columns of x1
>> with the same factor levels in both.  E.g., using a *small* example:
>>
>>> X1 <- data.frame(V1=c("A","A","B"), V2=c("C","C","A"))
>>> X <- table(lapply(X1, factor, levels=union(levels(X1[[1]]), levels(X1[[2]]))))
>>> X
>>    V2
>> V1  A B C
>>   A 0 0 2
>>   B 1 0 0
>>   C 0 0 0
>>
>> If you don't want counts, but just a TRUE for presence and FALSE for
>> absence, use X>0.  If you want 1 for presence and 0 for absence you
>> can use pmin(X, 1).
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Aug 13, 2014 at 2:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> I may have missed something, but I didn't see the result you want for
>>> your example.  Also,
>>> none of the entries in the x1 you showed are row or column names in x,
>>> making it hard to show what you want to happen.
>>>
>>> Here is a function that gives you the choice of
>>>     *error: stop if any row of x1 is 'bad'
>>>     *omitRows: ignore rows of x1 are 'bad'
>>>     *expandX: expand the x matrix to include all rows or columns named in x1
>>> (Row i of x1 is 'bad' if that x1[,1] is not a rowname of x or x1[,2]
>>> is not a column name of x).
>>>
>>> f
>>> function (x, x1, badEntryAction = c("error", "omitRows", "expandX"))
>>> {
>>>     badEntryAction <- match.arg(badEntryAction)
>>>     i <- as.matrix(x1[, c("V1", "V2")])
>>>     if (badEntryAction == "omitRows") {
>>>         i <- i[is.element(i[, 1], dimnames(x)[[1]]) & is.element(i[,
>>>             2], dimnames(x)[[2]]), , drop = FALSE]
>>>     }
>>>     else if (badEntryAction == "expandX") {
>>>         extraDimnames <- lapply(1:2, function(k) setdiff(i[,
>>>             k], dimnames(x)[[k]]))
>>>         # if you want the same dimnames on both axes, take union of
>>> the 2 extraDimnames
>>>         if ((n <- length(extraDimnames[[1]])) > 0) {
>>>             x <- rbind(x, array(0, c(n, ncol(x)), dimnames =
>>> list(extraDimnames[[1]],
>>>                 NULL)))
>>>         }
>>>         if ((n <- length(extraDimnames[[2]])) > 0) {
>>>             x <- cbind(x, array(0, c(nrow(x), n), dimnames = list(NULL,
>>>                 extraDimnames[[2]])))
>>>         }
>>>     }
>>>     x[i] <- 1
>>>     x
>>> }
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Wed, Aug 13, 2014 at 2:33 PM, Adrian Johnson
>>> <oriolebaltimore at gmail.com> wrote:
>>>> Hello again. sorry for question again.
>>>>
>>>> may be I was not clear in asking before.
>>>>
>>>>  I don't want to remove rows from matrix, since row names and column
>>>> names are identical in matrix.
>>>>
>>>>
>>>> I tried your suggestion and here is what I get:
>>>>
>>>>> fx <- function(x,x1){
>>>> + i <- as.matrix(x1[,c("V1","V2")])
>>>> + x[i]<-1
>>>> + x
>>>> + }
>>>>> fx(x, x1)
>>>>
>>>> Error in `[<-`(`*tmp*`, i, value = 1) : subscript out of bounds
>>>>
>>>>
>>>>
>>>>
>>>>> x[1:4,1:4]
>>>>        ABCA10 ABCA12 ABCA13 ABCA4
>>>> ABCA10      0      0      0     0
>>>> ABCA12      0      0      0     0
>>>> ABCA13      0      0      0     0
>>>> ABCA4       0      0      0     0
>>>>
>>>>
>>>>> x1[1:10,]
>>>>       V1       V2
>>>> 1   AKT3    TCL1A
>>>> 2  AKTIP    VPS41
>>>> 3  AKTIP    PDPK1
>>>> 4  AKTIP   GTF3C1
>>>> 5  AKTIP    HOOK2
>>>> 6  AKTIP    POLA2
>>>> 7  AKTIP KIAA1377
>>>> 8  AKTIP FAM160A2
>>>> 9  AKTIP    VPS16
>>>> 10 AKTIP    VPS18
>>>>
>>>>
>>>> For instance, now I will loop over x1, I go to first row, I get V1 and
>>>> check if if I have a row in x that have item in V1 and then check V2
>>>> exist in colnames, if match then I assign 1. If not I go to row 2.
>>>>
>>>> In some rows, it is possible that I will only see element in V2 that
>>>> exist in row names  and since element in V1 does not exist in X
>>>> matrix, I will give 0. (since matrix X has identical row and column
>>>> names, i feel it does not matter to check an element in column names
>>>> after we check in row names)
>>>>
>>>>
>>>>
>>>> now for instance, If in X1 if I see ABCA10 in x1$V1 and ABCA10 in
>>>> x1$V2 then in matrix X column 1 and row 1  should get 1.
>>>>
>>>> dput - follows..
>>>>
>>>> x <- structure(c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), .Dim = c(4L,
>>>> 4L), .Dimnames = list(c("ABCA10", "ABCA12", "ABCA13", "ABCA4"
>>>> ), c("ABCA10", "ABCA12", "ABCA13", "ABCA4")))
>>>>
>>>>
>>>> x1 <- structure(list(V1 = c("AKT3", "AKTIP", "AKTIP", "AKTIP", "AKTIP",
>>>> "AKTIP", "AKTIP", "AKTIP", "AKTIP", "AKTIP"), V2 = c("TCL1A",
>>>> "VPS41", "PDPK1", "GTF3C1", "HOOK2", "POLA2", "KIAA1377", "FAM160A2",
>>>> "VPS16", "VPS18")), .Names = c("V1", "V2"), row.names = c(NA,
>>>> 10L), class = "data.frame")
>>>>
>>>>
>>>>
>>>> Thanks for your time.
>>>>
>>>>
>>>>
>>>>
>>>> On Wed, Aug 13, 2014 at 12:51 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>>> You can replace the loop
>>>>>> for (i in nrow(x1)) {
>>>>>>    x[x1$V1[i], x1$V2[i]] <- 1;
>>>>>> }
>>>>> by
>>>>> f <- function(x, x1) {
>>>>>   i <- as.matrix(x1[, c("V1","V2")]) # 2-column matrix to use as a subscript
>>>>>   x[ i ] <- 1
>>>>>   x
>>>>> }
>>>>> f(x, x1)
>>>>>
>>>>> You will get an error if not all the strings in the subscript matrix
>>>>> are in the row or
>>>>> column names of x.  What do you want to happen in this case.  You can choose
>>>>> to first omit the bad rows in the subscript matrix
>>>>>     goodRows <- is.element(i[,1], dimnames(x)[1]) &  is.element(i[,2],
>>>>> dimnames(x)[2])
>>>>>     i <- i[goodRows, , drop=FALSE]
>>>>>     x[ i ] <- 1
>>>>> or you can choose to expand x to include all the names found in x1.
>>>>>
>>>>> It would be good if you included some toy data to better illustrate
>>>>> what you want to do.
>>>>> E.g., with
>>>>>   x <- array(0, c(3,3), list(Row=paste0("R",1:3),Col=paste0("C",1:3)))
>>>>>   x1 <- data.frame(V1=c("R1","R3"), V2=c("C2","C1"))
>>>>> the above f() gives
>>>>>> f(x, x1)
>>>>>     Col
>>>>> Row  C1 C2 C3
>>>>>   R1  0  1  0
>>>>>   R2  0  0  0
>>>>>   R3  1  0  0
>>>>> Is that what you are looking for?


From pharavee-jaiprasart at ouhsc.edu  Thu Aug 14 17:07:33 2014
From: pharavee-jaiprasart at ouhsc.edu (Jaiprasart, Pharavee (HSC))
Date: Thu, 14 Aug 2014 15:07:33 +0000
Subject: [R] Operating on the value from row i and row i+1
Message-ID: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>

Hi all,



I'd like to make a step plot of Time vs Response graph.

This is the example of my data frame - the real data frame has more than a thousand rows.



Time          Duration of infusion           Infusion Rate            Response               Subtype

0                         3                                                     2                         5                                     0

3                         6                                                     3                         6                                     0

9                         6                                                     4                         4                                     0



I cannot just use type = c("s") for this because I also want to use the value of the in between time for further calculation too (If I ask the program for Response of time == 4, I want it to return "6").



The way I think the script should work is that:



For all rows that has subtype ==0, if time is between the value of row /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column "Dummy" and return the value of row /i/ from the Response column (e.g. 5 in this

example) , and do these for all rows (e.g. any time between row 2 and 3 which is 3-9, make a new column and return 6). Then I can say if Time>0 (value in column1) and <3 (value from column 1+2), y = value in Dummy



Is there any way to do this in R?



Thanks!

Pharavee


	[[alternative HTML version deleted]]


From subscriptions at simonplace.net  Thu Aug 14 08:57:47 2014
From: subscriptions at simonplace.net (Peter Brady)
Date: Thu, 14 Aug 2014 16:57:47 +1000
Subject: [R] How Can SVD Reconstruct a Matrix
Message-ID: <53EC5DEB.9040803@simonplace.net>

Hi All,

I've inherited some R code that I can't work out what they've done.  It
appears to work and give sort of reasonable answers, I'm just trying to
work out why they've done what they have.  I suspect that this is a
simple vector identity that I've just been staring at too long and have
forgotten...

The code:

GGt <- M0 - M1 %*% M0inv %*% t(M1)
svdGG <- svd(GGt)
Gmat <- svdGG$u %*% diag(sqrt(svdGG$d))

It is supposed to solve:

G*G^T = M0 - M1*M0^-1*M1^T

for G, where G^T is the transpose of G.  It is designed to reproduce a
numerical method described in two papers:

Srikanthan and Pegram, Journal of Hydrology, 371 (2009) 142-153,
Equation A13, who suggest the SVD method but don't describe the
specifics, eg: "...G is found by singular value decomposition..."

Alternatively, Matalas (1967) Water Resources Research 3 (4) 937-945,
Equation 17, say that the above can be solved using Principle Component
Analysis (PCA).

I use PCA (specifically POD) and SVD to look at the components after
decomposition, so I'm a bit lost as to how the original matrix G can be
constructed in this case from only the singular values and the left
singular vectors.  Like I said earlier, I suspect that this is a simple
array identity that I've forgotten.  My Google Fu is letting me down at
this point.

My questions:
1) What is the proof, or where can I better find it to satisfy myself,
that the above works?

2) Alternatively, can anyone suggest how I could apply PCA in R to
compute the same?

Thanks in advance,
-pete

-- 
Peter Brady
Email: pdbrady at ans.com.au
Skype: pbrady77


From jan.stanstrup at fmach.it  Thu Aug 14 16:17:47 2014
From: jan.stanstrup at fmach.it (Jan Stanstrup)
Date: Thu, 14 Aug 2014 16:17:47 +0200
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
In-Reply-To: <F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
Message-ID: <53ECC50B.3000606@fmach.it>

Thank you very much for this snippet!

I used it on my data and indeed it does give intervals which appear 
quite realistic (script and data here 
https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R).
I also tried getting the intervals with predict.cobs but the methods 
available there gave very narrow bands.
The only problem I can see is that the fit tend to be a bit on the 
smooth side. See for example the upper interval limits at x = 2 to 3 and 
x =1.2. If then I set lambda to something low like 0.05 the band narrows 
to nearly nothing when there are few points. For example at x = 2.5. Is 
there some other parameter I would be adjusting?



----------------------
Jan Stanstrup
Postdoc

Metabolomics
Food Quality and Nutrition
Fondazione Edmund Mach



On 08/14/2014 02:02 AM, David Winsemius wrote:
>
> On Aug 12, 2014, at 8:40 AM, Bert Gunter wrote:
>
>> PI's of what? -- future individual values or mean values?
>>
>> I assume quantreg provides quantiles for the latter, not the former.
>> (See ?predict.lm for a terse explanation of the difference).
>
> I probably should have questioned the poster about what was meant by a 
> "prediction interval for a monotonic loess curve". I was suggesting 
> quantile regression for estimation of a chosen quantile, say the 90th 
> percentile. I was thinking it could produce the analogue of a 90th 
> percentile value (with no reference to a mean value or use of presumed 
> distribution within adjacent windows of say 100-150 points. I had 
> experience using the cobs function (in the package of the same name) 
> as Koenker illustrates:
>
> age <- runif(1000,min=60,max=85)
>
>  analyte <- rlnorm(1000,4*(age/60),age/60)
>  plot(age,analyte)
>
>  library(cobs)
>  library(quantreg)
>  Rbs.9 <- cobs(age,analyte, constraint="increase",tau=0.9)
> Rbs.median <- cobs(age,analyte,constraint="increase",tau=0.5)
>
> png("cobs.png"); plot(age,analyte, ylim=c(0,2000))
>  lines(predict(Rbs.9), col = "red", lwd = 1.5)
> lines(predict(Rbs.median), col = "blue", lwd = 1.5)
>  dev.off()
>
> -- David
>
>
>> obtainable from bootstrapping but the details depend on what you are
>> prepared to assume. Consult references or your local statistician for
>> help if needed.
>>
>> -- Bert
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> (650) 467-7374
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>> Clifford Stoll
>>
>>
>>
>>
>> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius 
>> <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>>>
>>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>>
>>>> Hi,
>>>>
>>>> I am trying to find a way to estimate prediction intervals (PI) for 
>>>> a monotonic loess curve using bootstrapping.
>>>>
>>>> At the moment my approach is to use the boot function from the boot 
>>>> package to bootstrap my loess model, which consist of loess + 
>>>> monoproc from the monoproc package (to force the fit to be 
>>>> monotonic which gives me much improved results with my particular 
>>>> data). The output from the monoproc package is simply the fitted y 
>>>> values at each x-value.
>>>> I then use boot.ci (again from the boot package) to get confidence 
>>>> intervals. The problem is that this gives me confidence intervals 
>>>> (CI) for the "fit" (is there a proper way to specify this?) and not 
>>>> a prediction interval. The interval is thus way too optimistic to 
>>>> give me an idea of the confidence interval of a predicted value.
>>>>
>>>> For linear models predict.lm can give PI instead of CI by setting 
>>>> interval = "prediction". Further discussion of that here:
>>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>>
>>>> However I don't see a way to do that for boot.ci. Does there exist 
>>>> a way to get PIs after bootstrapping? If some sample code is 
>>>> required I am more than happy to supply it but I thought the 
>>>> question was general enough to be understandable without it.
>>>>
>>>
>>> Why not use the quantreg package to estimate the quantiles of 
>>> interest to you? That way you would not be depending on Normal 
>>> theory assumptions which you apparently don't trust. I've used it 
>>> with the `cobs` function from the package of the same name to 
>>> implement the monotonic constraint. I think there is a worked 
>>> example in the quantreg package, but since I bought Koenker's book, 
>>> I may be remembering from there.
>>> --
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide 
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: boot2ci_PI.png
Type: image/png
Size: 35198 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140814/a61c0f40/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cobs.png
Type: image/png
Size: 32916 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140814/a61c0f40/attachment-0001.png>

From dwinsemius at comcast.net  Thu Aug 14 18:06:54 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 Aug 2014 09:06:54 -0700
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
	loess curve using bootstrapping
In-Reply-To: <53ECC50B.3000606@fmach.it>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
	<53ECC50B.3000606@fmach.it>
Message-ID: <A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>


On Aug 14, 2014, at 7:17 AM, Jan Stanstrup wrote:

> Thank you very much for this snippet!
> 
> I used it on my data and indeed it does give intervals which appear quite realistic (script and data here https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R).
> I also tried getting the intervals with predict.cobs but the methods available there gave very narrow bands.
> The only problem I can see is that the fit tend to be a bit on the smooth side. See for example the upper interval limits at x = 2 to 3 and x =1.2. If then I set lambda to something low like 0.05 the band narrows to nearly nothing when there are few points. For example at x = 2.5. Is there some other parameter I would be adjusting?
> 

Try specifying the number and location of the knots (using my example data):

> Rbs.9 <- cobs(age,analyte,constraint="increase",tau=0.9, nknots=6, knots=seq(60,85,by=5))
> plot(age,analyte, ylim=c(0,2000))
>  lines(predict(Rbs.9), col = 2, lwd = 1.5)



-- 
David.

> 
> 
> ---------------------- 
> Jan Stanstrup 
> Postdoc 
> 
> Metabolomics 
> Food Quality and Nutrition 
> Fondazione Edmund Mach 
> 
> 
> 
> On 08/14/2014 02:02 AM, David Winsemius wrote:
>> 
>> On Aug 12, 2014, at 8:40 AM, Bert Gunter wrote:
>> 
>>> PI's of what? -- future individual values or mean values?
>>> 
>>> I assume quantreg provides quantiles for the latter, not the former.
>>> (See ?predict.lm for a terse explanation of the difference).
>> 
>> I probably should have questioned the poster about what was meant by a "prediction interval for a monotonic loess curve". I was suggesting quantile regression for estimation of a chosen quantile, say the 90th percentile. I was thinking it could produce the analogue of a 90th percentile value (with no         reference to a mean value or use of presumed distribution within adjacent windows of say 100-150 points. I had experience using the cobs function (in the package of the same name) as Koenker illustrates:
>> 
>> age <- runif(1000,min=60,max=85)
>>  
>>  analyte <- rlnorm(1000,4*(age/60),age/60)
>>  plot(age,analyte)
>> 
>>  library(cobs)
>>  library(quantreg)
>>  Rbs.9 <- cobs(age,analyte, constraint="increase",tau=0.9) 
>> Rbs.median <- cobs(age,analyte,constraint="increase",tau=0.5)
>> 
>> png("cobs.png"); plot(age,analyte, ylim=c(0,2000))
>>  lines(predict(Rbs.9), col = "red", lwd = 1.5)
>> lines(predict(Rbs.median), col = "blue", lwd = 1.5)
>>  dev.off()
>> <Mail Attachment.png>
>> 
>> -- David
>> 
>> 
>>> obtainable from bootstrapping but the details depend on what you are
>>> prepared to assume. Consult references or your local statistician for
>>> help if needed.
>>> 
>>> -- Bert
>>> 
>>> Bert Gunter
>>> Genentech Nonclinical Biostatistics
>>> (650) 467-7374
>>> 
>>> "Data is not information. Information is not knowledge. And knowledge
>>> is certainly not wisdom."
>>> Clifford Stoll
>>> 
>>> 
>>> 
>>> 
>>> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>> 
>>>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>>> 
>>>>> Hi,
>>>>> 
>>>>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>>>> 
>>>>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>>>>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>>>> 
>>>>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>>>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>>> 
>>>>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>>>> 
>>>> 
>>>> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
>>>> --
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 
> <boot2ci_PI.png><cobs.png>

David Winsemius
Alameda, CA, USA


From gupta567varun at gmail.com  Thu Aug 14 18:15:58 2014
From: gupta567varun at gmail.com (VG)
Date: Thu, 14 Aug 2014 12:15:58 -0400
Subject: [R] Installation of R version 3.1.0
Message-ID: <CAN7A_QwAV5hmQovfXDZsqbVRghB89nnDMzr2v6mCvFeauyA5Tw@mail.gmail.com>

Hi Everyone,
I am currently using *R version 3.0.0 RC (2013-03-28 r62434) -- "Masked
Marvel"*

I am using Ubuntu 10.04 LTS- the Lucid Lynx.

I downloaded the  tar.gz of R 3.1.0 under my Downloads folder.
I changed my directory to Downloads folder and then used following commands
to install the version.

I used
tar -xzf tar.gz
cd R-3.1.0
./configure
make
make check

Now i can see a bin folder under R-3.1.0 which has R.
On the terminal when I use R it still gives me

R version 3.0.0 RC (2013-03-28 r62434) -- "Masked Marvel"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: i686-pc-linux-gnu (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

How can I use R 3.1.0 version.
I also want to use that version on R studio.

I guess it is just the path issue?
Any help

Regards
VG

	[[alternative HTML version deleted]]


From rmh at temple.edu  Thu Aug 14 18:16:01 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 14 Aug 2014 12:16:01 -0400
Subject: [R] How Can SVD Reconstruct a Matrix
In-Reply-To: <53EC5DEB.9040803@simonplace.net>
References: <53EC5DEB.9040803@simonplace.net>
Message-ID: <CAGx1TMCRJE1wJ0=8Tb-OWmR-B3mA4uu8LhcfdhT+U=fkS9htdg@mail.gmail.com>

This looks like a variant of the Woodbury formula
http://en.wikipedia.org/wiki/Woodbury_matrix_identity

On Thu, Aug 14, 2014 at 2:57 AM, Peter Brady
<subscriptions at simonplace.net> wrote:
> Hi All,
>
> I've inherited some R code that I can't work out what they've done.  It
> appears to work and give sort of reasonable answers, I'm just trying to
> work out why they've done what they have.  I suspect that this is a
> simple vector identity that I've just been staring at too long and have
> forgotten...
>
> The code:
>
> GGt <- M0 - M1 %*% M0inv %*% t(M1)
> svdGG <- svd(GGt)
> Gmat <- svdGG$u %*% diag(sqrt(svdGG$d))
>
> It is supposed to solve:
>
> G*G^T = M0 - M1*M0^-1*M1^T
>
> for G, where G^T is the transpose of G.  It is designed to reproduce a
> numerical method described in two papers:
>
> Srikanthan and Pegram, Journal of Hydrology, 371 (2009) 142-153,
> Equation A13, who suggest the SVD method but don't describe the
> specifics, eg: "...G is found by singular value decomposition..."
>
> Alternatively, Matalas (1967) Water Resources Research 3 (4) 937-945,
> Equation 17, say that the above can be solved using Principle Component
> Analysis (PCA).
>
> I use PCA (specifically POD) and SVD to look at the components after
> decomposition, so I'm a bit lost as to how the original matrix G can be
> constructed in this case from only the singular values and the left
> singular vectors.  Like I said earlier, I suspect that this is a simple
> array identity that I've forgotten.  My Google Fu is letting me down at
> this point.
>
> My questions:
> 1) What is the proof, or where can I better find it to satisfy myself,
> that the above works?
>
> 2) Alternatively, can anyone suggest how I could apply PCA in R to
> compute the same?
>
> Thanks in advance,
> -pete
>
> --
> Peter Brady
> Email: pdbrady at ans.com.au
> Skype: pbrady77
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Aug 14 18:26:55 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 14 Aug 2014 09:26:55 -0700
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
Message-ID: <CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>

Your query is a bit unclear, but I suspect

?plot

and a **careful read** about types "s" and "S" therein
would address your problem.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC)
<pharavee-jaiprasart at ouhsc.edu> wrote:
> Hi all,
>
>
>
> I'd like to make a step plot of Time vs Response graph.
>
> This is the example of my data frame - the real data frame has more than a thousand rows.
>
>
>
> Time          Duration of infusion           Infusion Rate            Response               Subtype
>
> 0                         3                                                     2                         5                                     0
>
> 3                         6                                                     3                         6                                     0
>
> 9                         6                                                     4                         4                                     0
>
>
>
> I cannot just use type = c("s") for this because I also want to use the value of the in between time for further calculation too (If I ask the program for Response of time == 4, I want it to return "6").
>
>
>
> The way I think the script should work is that:
>
>
>
> For all rows that has subtype ==0, if time is between the value of row /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column "Dummy" and return the value of row /i/ from the Response column (e.g. 5 in this
>
> example) , and do these for all rows (e.g. any time between row 2 and 3 which is 3-9, make a new column and return 6). Then I can say if Time>0 (value in column1) and <3 (value from column 1+2), y = value in Dummy
>
>
>
> Is there any way to do this in R?
>
>
>
> Thanks!
>
> Pharavee
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From martyn.byng at nag.co.uk  Thu Aug 14 18:38:51 2014
From: martyn.byng at nag.co.uk (Martyn Byng)
Date: Thu, 14 Aug 2014 16:38:51 +0000
Subject: [R] How Can SVD Reconstruct a Matrix
In-Reply-To: <53EC5DEB.9040803@simonplace.net>
References: <53EC5DEB.9040803@simonplace.net>
Message-ID: <6a4f3f14247e49b49c02172bd378f3df@AM3PR05MB545.eurprd05.prod.outlook.com>

Hi,

The G matrix can be constructed from the SVD because GGt is square and symmetric, so the matrices of the left and right singular values (i.e. U and V) are the same.

Martyn

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Peter Brady
Sent: 14 August 2014 07:58
To: r-help at r-project.org
Subject: [R] How Can SVD Reconstruct a Matrix

Hi All,

I've inherited some R code that I can't work out what they've done.  It appears to work and give sort of reasonable answers, I'm just trying to work out why they've done what they have.  I suspect that this is a simple vector identity that I've just been staring at too long and have forgotten...

The code:

GGt <- M0 - M1 %*% M0inv %*% t(M1)
svdGG <- svd(GGt)
Gmat <- svdGG$u %*% diag(sqrt(svdGG$d))

It is supposed to solve:

G*G^T = M0 - M1*M0^-1*M1^T

for G, where G^T is the transpose of G.  It is designed to reproduce a numerical method described in two papers:

Srikanthan and Pegram, Journal of Hydrology, 371 (2009) 142-153, Equation A13, who suggest the SVD method but don't describe the specifics, eg: "...G is found by singular value decomposition..."

Alternatively, Matalas (1967) Water Resources Research 3 (4) 937-945, Equation 17, say that the above can be solved using Principle Component Analysis (PCA).

I use PCA (specifically POD) and SVD to look at the components after decomposition, so I'm a bit lost as to how the original matrix G can be constructed in this case from only the singular values and the left singular vectors.  Like I said earlier, I suspect that this is a simple array identity that I've forgotten.  My Google Fu is letting me down at this point.

My questions:
1) What is the proof, or where can I better find it to satisfy myself, that the above works?

2) Alternatively, can anyone suggest how I could apply PCA in R to compute the same?

Thanks in advance,
-pete

--
Peter Brady
Email: pdbrady at ans.com.au
Skype: pbrady77

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________________________________________________
This e-mail has been scanned for all viruses by Star.\ _...{{dropped:3}}


From peter.langfelder at gmail.com  Thu Aug 14 18:40:24 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 14 Aug 2014 09:40:24 -0700
Subject: [R] How Can SVD Reconstruct a Matrix
In-Reply-To: <53EC5DEB.9040803@simonplace.net>
References: <53EC5DEB.9040803@simonplace.net>
Message-ID: <CA+hbrhU68YaycHsDavP3y0_MyCiQEXXhTPhykFMN4-TX672dzg@mail.gmail.com>

On Wed, Aug 13, 2014 at 11:57 PM, Peter Brady
<subscriptions at simonplace.net> wrote:
> Hi All,
>
> I've inherited some R code that I can't work out what they've done.  It
> appears to work and give sort of reasonable answers, I'm just trying to
> work out why they've done what they have.  I suspect that this is a
> simple vector identity that I've just been staring at too long and have
> forgotten...
>
> The code:
>
> GGt <- M0 - M1 %*% M0inv %*% t(M1)
> svdGG <- svd(GGt)
> Gmat <- svdGG$u %*% diag(sqrt(svdGG$d))
>
> It is supposed to solve:
>
> G*G^T = M0 - M1*M0^-1*M1^T
>
> for G, where G^T is the transpose of G.  It is designed to reproduce a
> numerical method described in two papers:
>
> Srikanthan and Pegram, Journal of Hydrology, 371 (2009) 142-153,
> Equation A13, who suggest the SVD method but don't describe the
> specifics, eg: "...G is found by singular value decomposition..."
>
> Alternatively, Matalas (1967) Water Resources Research 3 (4) 937-945,
> Equation 17, say that the above can be solved using Principle Component
> Analysis (PCA).
>
> I use PCA (specifically POD) and SVD to look at the components after
> decomposition, so I'm a bit lost as to how the original matrix G can be
> constructed in this case from only the singular values and the left
> singular vectors.

GG' is a symmetric matrix, so left- and right-singular vectors are the
same. If I recall right, in general it is impossible to find G from
GG' (I denote the transpose by ') since, given an orthogonal
transformation U (that is, UU'=1), GUU'G' = GG', so you can only find
G up to multiplication with an orthogonal transformation matrix.

Since SVD decomposes a matrix X = UDV', the decomposition for GG' is

GG' = UDU'; setting S = sqrt(D) (i.e., diagonal matrix with elements
that are sqrt of those in D), GG' = USSU' = USS'U', so one solution is
G = US which is the solution used.

You could use PCA on G, which is roughly equivalent to doing SVD on
GG' (up to centering and scaling of the columns of G). I am not very
familiar with PCA in R since I always use SVD, but here's what the
help file for prcomp (PCA in R) says:

   The calculation is done by a singular value decomposition of the
     (centered and possibly scaled) data matrix, not by using ?eigen?
     on the covariance matrix.  This is generally the preferred method
     for numerical accuracy.

HTH,

Peter


> Like I said earlier, I suspect that this is a simple
> array identity that I've forgotten.  My Google Fu is letting me down at
> this point.
>
> My questions:
> 1) What is the proof, or where can I better find it to satisfy myself,
> that the above works?
>
> 2) Alternatively, can anyone suggest how I could apply PCA in R to
> compute the same?
>
> Thanks in advance,
> -pete
>
> --
> Peter Brady
> Email: pdbrady at ans.com.au
> Skype: pbrady77
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Thu Aug 14 18:47:42 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 Aug 2014 17:47:42 +0100
Subject: [R] Installation of R version 3.1.0
In-Reply-To: <CAN7A_QwAV5hmQovfXDZsqbVRghB89nnDMzr2v6mCvFeauyA5Tw@mail.gmail.com>
References: <CAN7A_QwAV5hmQovfXDZsqbVRghB89nnDMzr2v6mCvFeauyA5Tw@mail.gmail.com>
Message-ID: <53ECE82E.2070405@stats.ox.ac.uk>

On 14/08/2014 17:15, VG wrote:
> Hi Everyone,
> I am currently using *R version 3.0.0 RC (2013-03-28 r62434) -- "Masked
> Marvel"*
>
> I am using Ubuntu 10.04 LTS- the Lucid Lynx.
>
> I downloaded the  tar.gz of R 3.1.0 under my Downloads folder.

Why?  3.1.1 is current.

> I changed my directory to Downloads folder and then used following commands
> to install the version.
>
> I used
> tar -xzf tar.gz
> cd R-3.1.0
> ./configure
> make
> make check

But you did not install it ... see the 'R Installation and 
Administration Manual' which file INSTALL directed you to.  You are 
missing some variant on 'make install'.

>
> Now i can see a bin folder under R-3.1.0 which has R.
> On the terminal when I use R it still gives me
>
> R version 3.0.0 RC (2013-03-28 r62434) -- "Masked Marvel"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: i686-pc-linux-gnu (32-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> How can I use R 3.1.0 version.
> I also want to use that version on R studio.
>
> I guess it is just the path issue?
> Any help
>
> Regards
> VG
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From dwinsemius at comcast.net  Thu Aug 14 19:22:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 14 Aug 2014 10:22:46 -0700
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
	loess curve using bootstrapping
In-Reply-To: <A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
	<53ECC50B.3000606@fmach.it>
	<A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
Message-ID: <49B6CD8C-AA13-4465-A668-050C0AB4665C@comcast.net>


On Aug 14, 2014, at 9:06 AM, David Winsemius wrote:

> 
> On Aug 14, 2014, at 7:17 AM, Jan Stanstrup wrote:
> 
>> Thank you very much for this snippet!
>> 
>> I used it on my data and indeed it does give intervals which appear quite realistic (script and data here https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R).
>> I also tried getting the intervals with predict.cobs but the methods available there gave very narrow bands.
>> The only problem I can see is that the fit tend to be a bit on the smooth side. See for example the upper interval limits at x = 2 to 3 and x =1.2. If then I set lambda to something low like 0.05 the band narrows to nearly nothing when there are few points. For example at x = 2.5. Is there some other parameter I would be adjusting?
>> 
> 
> Try specifying the number and location of the knots (using my example data):
> 
>> Rbs.9 <- cobs(age,analyte,constraint="increase",tau=0.9, nknots=6, knots=seq(60,85,by=5))
>> plot(age,analyte, ylim=c(0,2000))
>> lines(predict(Rbs.9), col = 2, lwd = 1.5)

My png file seems to have gotten stripped (try again):




(Not responding directly to Jan Stanstrup because his email address seems to force holdup in the moderation queue.)

-- 
David.
> 
> 
> 
> -- 
> David.
> 
>> 
>> 
>> ---------------------- 
>> Jan Stanstrup 
>> Postdoc 
>> 
>> Metabolomics 
>> Food Quality and Nutrition 
>> Fondazione Edmund Mach 
>> 
>> 
>> 
>> On 08/14/2014 02:02 AM, David Winsemius wrote:
>>> 
>>> On Aug 12, 2014, at 8:40 AM, Bert Gunter wrote:
>>> 
>>>> PI's of what? -- future individual values or mean values?
>>>> 
>>>> I assume quantreg provides quantiles for the latter, not the former.
>>>> (See ?predict.lm for a terse explanation of the difference).
>>> 
>>> I probably should have questioned the poster about what was meant by a "prediction interval for a monotonic loess curve". I was suggesting quantile regression for estimation of a chosen quantile, say the 90th percentile. I was thinking it could produce the analogue of a 90th percentile value (with no         reference to a mean value or use of presumed distribution within adjacent windows of say 100-150 points. I had experience using the cobs function (in the package of the same name) as Koenker illustrates:
>>> 
>>> age <- runif(1000,min=60,max=85)
>>> 
>>> analyte <- rlnorm(1000,4*(age/60),age/60)
>>> plot(age,analyte)
>>> 
>>> library(cobs)
>>> library(quantreg)
>>> Rbs.9 <- cobs(age,analyte, constraint="increase",tau=0.9) 
>>> Rbs.median <- cobs(age,analyte,constraint="increase",tau=0.5)
>>> 
>>> png("cobs.png"); plot(age,analyte, ylim=c(0,2000))
>>> lines(predict(Rbs.9), col = "red", lwd = 1.5)
>>> lines(predict(Rbs.median), col = "blue", lwd = 1.5)
>>> dev.off()
>>> <Mail Attachment.png>
>>> 
>>> -- David
>>> 
>>> 
>>>> obtainable from bootstrapping but the details depend on what you are
>>>> prepared to assume. Consult references or your local statistician for
>>>> help if needed.
>>>> 
>>>> -- Bert
>>>> 
>>>> Bert Gunter
>>>> Genentech Nonclinical Biostatistics
>>>> (650) 467-7374
>>>> 
>>>> "Data is not information. Information is not knowledge. And knowledge
>>>> is certainly not wisdom."
>>>> Clifford Stoll
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>> 
>>>>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>>>> 
>>>>>> Hi,
>>>>>> 
>>>>>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>>>>> 
>>>>>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>>>>>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>>>>> 
>>>>>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>>>>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>>>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>>>> 
>>>>>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>>>>> 
>>>>> 
>>>>> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
>>>>> --
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>> 
>> <boot2ci_PI.png><cobs.png>
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From pharavee-jaiprasart at ouhsc.edu  Thu Aug 14 18:39:34 2014
From: pharavee-jaiprasart at ouhsc.edu (Jaiprasart, Pharavee (HSC))
Date: Thu, 14 Aug 2014 16:39:34 +0000
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
	<CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
Message-ID: <C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>

Hi Bert,

I should have phrased my question differently.

I actually want to do two things. 

First is to make a step plot. The "s"/"S" is a typo on my part.

The second is to write a script that when I ask the program for Response of time == 4, I want it to return "6", or if I ask for response of time == 12, it will return "4", and so on.

Pharavee


-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: Thursday, August 14, 2014 11:27 AM
To: Jaiprasart, Pharavee (HSC)
Cc: r-help at r-project.org
Subject: Re: [R] Operating on the value from row i and row i+1

Your query is a bit unclear, but I suspect

?plot

and a **careful read** about types "s" and "S" therein would address your problem.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
Clifford Stoll




On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC) <pharavee-jaiprasart at ouhsc.edu> wrote:
> Hi all,
>
>
>
> I'd like to make a step plot of Time vs Response graph.
>
> This is the example of my data frame - the real data frame has more than a thousand rows.
>
>
>
> Time          Duration of infusion           Infusion Rate            Response               Subtype
>
> 0                         3                                                     2                         5                                     0
>
> 3                         6                                                     3                         6                                     0
>
> 9                         6                                                     4                         4                                     0
>
>
>
> I cannot just use type = c("s") for this because I also want to use the value of the in between time for further calculation too (If I ask the program for Response of time == 4, I want it to return "6").
>
>
>
> The way I think the script should work is that:
>
>
>
> For all rows that has subtype ==0, if time is between the value of row 
> /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column 
> "Dummy" and return the value of row /i/ from the Response column (e.g. 
> 5 in this
>
> example) , and do these for all rows (e.g. any time between row 2 and 
> 3 which is 3-9, make a new column and return 6). Then I can say if 
> Time>0 (value in column1) and <3 (value from column 1+2), y = value in 
> Dummy
>
>
>
> Is there any way to do this in R?
>
>
>
> Thanks!
>
> Pharavee
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
> n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
> spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0
> k79BnWO1L%2FRUs%3D%0A&s=8d0ca7ccfe0e7c4bac733aa2e8fe9a7068ffcf501cb181
> e4261e95efc1b0e31a PLEASE do read the posting guide 
> https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
> sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
> pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0k
> 79BnWO1L%2FRUs%3D%0A&s=7ca8e5a21aa512fa8bc5669fb6f4ea587d530d4a20146fd
> 526148d17a3d198bc and provide commented, minimal, self-contained, 
> reproducible code.

From gunter.berton at gene.com  Thu Aug 14 20:21:07 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 14 Aug 2014 11:21:07 -0700
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
	<CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
	<C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
Message-ID: <CACk-te3+OXcrF+v4nXjNW4=VHjSxW+qMbQNH9Spg6OMUMD2CoQ@mail.gmail.com>

?findInterval

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Aug 14, 2014 at 9:39 AM, Jaiprasart, Pharavee (HSC)
<pharavee-jaiprasart at ouhsc.edu> wrote:
> Hi Bert,
>
> I should have phrased my question differently.
>
> I actually want to do two things.
>
> First is to make a step plot. The "s"/"S" is a typo on my part.
>
> The second is to write a script that when I ask the program for Response of time == 4, I want it to return "6", or if I ask for response of time == 12, it will return "4", and so on.
>
> Pharavee
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Thursday, August 14, 2014 11:27 AM
> To: Jaiprasart, Pharavee (HSC)
> Cc: r-help at r-project.org
> Subject: Re: [R] Operating on the value from row i and row i+1
>
> Your query is a bit unclear, but I suspect
>
> ?plot
>
> and a **careful read** about types "s" and "S" therein would address your problem.
>
> Cheers,
> Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC) <pharavee-jaiprasart at ouhsc.edu> wrote:
>> Hi all,
>>
>>
>>
>> I'd like to make a step plot of Time vs Response graph.
>>
>> This is the example of my data frame - the real data frame has more than a thousand rows.
>>
>>
>>
>> Time          Duration of infusion           Infusion Rate            Response               Subtype
>>
>> 0                         3                                                     2                         5                                     0
>>
>> 3                         6                                                     3                         6                                     0
>>
>> 9                         6                                                     4                         4                                     0
>>
>>
>>
>> I cannot just use type = c("s") for this because I also want to use the value of the in between time for further calculation too (If I ask the program for Response of time == 4, I want it to return "6").
>>
>>
>>
>> The way I think the script should work is that:
>>
>>
>>
>> For all rows that has subtype ==0, if time is between the value of row
>> /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column
>> "Dummy" and return the value of row /i/ from the Response column (e.g.
>> 5 in this
>>
>> example) , and do these for all rows (e.g. any time between row 2 and
>> 3 which is 3-9, make a new column and return 6). Then I can say if
>> Time>0 (value in column1) and <3 (value from column 1+2), y = value in
>> Dummy
>>
>>
>>
>> Is there any way to do this in R?
>>
>>
>>
>> Thanks!
>>
>> Pharavee
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>> n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>> spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0
>> k79BnWO1L%2FRUs%3D%0A&s=8d0ca7ccfe0e7c4bac733aa2e8fe9a7068ffcf501cb181
>> e4261e95efc1b0e31a PLEASE do read the posting guide
>> https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>> sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>> pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0k
>> 79BnWO1L%2FRUs%3D%0A&s=7ca8e5a21aa512fa8bc5669fb6f4ea587d530d4a20146fd
>> 526148d17a3d198bc and provide commented, minimal, self-contained,
>> reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Aug 14 20:27:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 14 Aug 2014 11:27:51 -0700
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
	<CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
	<C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
Message-ID: <a91811a4-b78a-4fe9-bd45-c7aab3bf83f5@email.android.com>

So for part one it seems you already have your answer.

For part two you should look at time series types like "zoo", with which you can merge NAs at the new times at which you want "interpolated" answers and use the na.locf function to fill in values.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 14, 2014 9:39:34 AM PDT, "Jaiprasart, Pharavee (HSC)" <pharavee-jaiprasart at ouhsc.edu> wrote:
>Hi Bert,
>
>I should have phrased my question differently.
>
>I actually want to do two things. 
>
>First is to make a step plot. The "s"/"S" is a typo on my part.
>
>The second is to write a script that when I ask the program for
>Response of time == 4, I want it to return "6", or if I ask for
>response of time == 12, it will return "4", and so on.
>
>Pharavee
>
>
>-----Original Message-----
>From: Bert Gunter [mailto:gunter.berton at gene.com] 
>Sent: Thursday, August 14, 2014 11:27 AM
>To: Jaiprasart, Pharavee (HSC)
>Cc: r-help at r-project.org
>Subject: Re: [R] Operating on the value from row i and row i+1
>
>Your query is a bit unclear, but I suspect
>
>?plot
>
>and a **careful read** about types "s" and "S" therein would address
>your problem.
>
>Cheers,
>Bert
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>(650) 467-7374
>
>"Data is not information. Information is not knowledge. And knowledge
>is certainly not wisdom."
>Clifford Stoll
>
>
>
>
>On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC)
><pharavee-jaiprasart at ouhsc.edu> wrote:
>> Hi all,
>>
>>
>>
>> I'd like to make a step plot of Time vs Response graph.
>>
>> This is the example of my data frame - the real data frame has more
>than a thousand rows.
>>
>>
>>
>> Time          Duration of infusion           Infusion Rate           
>Response               Subtype
>>
>> 0                         3                                          
>      2                         5                                     0
>>
>> 3                         6                                          
>      3                         6                                     0
>>
>> 9                         6                                          
>      4                         4                                     0
>>
>>
>>
>> I cannot just use type = c("s") for this because I also want to use
>the value of the in between time for further calculation too (If I ask
>the program for Response of time == 4, I want it to return "6").
>>
>>
>>
>> The way I think the script should work is that:
>>
>>
>>
>> For all rows that has subtype ==0, if time is between the value of
>row 
>> /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column 
>> "Dummy" and return the value of row /i/ from the Response column
>(e.g. 
>> 5 in this
>>
>> example) , and do these for all rows (e.g. any time between row 2 and
>
>> 3 which is 3-9, make a new column and return 6). Then I can say if 
>> Time>0 (value in column1) and <3 (value from column 1+2), y = value
>in 
>> Dummy
>>
>>
>>
>> Is there any way to do this in R?
>>
>>
>>
>> Thanks!
>>
>> Pharavee
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>>
>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>>
>n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>>
>spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0
>>
>k79BnWO1L%2FRUs%3D%0A&s=8d0ca7ccfe0e7c4bac733aa2e8fe9a7068ffcf501cb181
>> e4261e95efc1b0e31a PLEASE do read the posting guide 
>>
>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>>
>sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>>
>pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0k
>>
>79BnWO1L%2FRUs%3D%0A&s=7ca8e5a21aa512fa8bc5669fb6f4ea587d530d4a20146fd
>> 526148d17a3d198bc and provide commented, minimal, self-contained, 
>> reproducible code.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dhimanbhadra at gmail.com  Thu Aug 14 20:30:46 2014
From: dhimanbhadra at gmail.com (DHIMAN BHADRA)
Date: Fri, 15 Aug 2014 00:00:46 +0530
Subject: [R] Pollution-mortality prediction.
Message-ID: <CAMD1hnh4OHN62nBVPEh2XsG8iCJrBwLhSSKTMddNM+Kd5gM4tA@mail.gmail.com>

Dear all.

I am trying to relate daily deaths in a given city with air pollution
values. The model I am using is as follows:

model <- glm(deaths ~ pollution + ns(time, 13) + ns(temp, 7) + ns(rh, 5) +
dow + holiday, family=quasipoisson, data=city)

Where -
deaths: daily number of deaths
pollution: daily measured levels of air pollution
ns(time, 13): smooth function (i.e. cubic spline) of time with 13 degrees
of freedom
ns(temp, 7): smooth function (i.e. cubic spline) of temperature with 7
degrees of freedom
ns(rh, 5): smooth function (i.e. cubic spline) of humidity with 5 degrees
of freedom
dow: day of the week
holiday: dummy variable to indicate public holidays

Having run this model, how do I obtain predicted values of deaths for any
given set of pollution values?

Thanks in advance,
Dhiman Bhadra
Assistant professor.
IIM Ahmedabad.

	[[alternative HTML version deleted]]


From sneha.bishnoi at gmail.com  Thu Aug 14 21:47:59 2014
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Thu, 14 Aug 2014 15:47:59 -0400
Subject: [R] Sldf command returns negative value for date
Message-ID: <CAOsJHwDButp9jQyZJdJu9+kXo8Na3EeCXzAkoFtHTKTSZCUK5Q@mail.gmail.com>

Hi All!

I am trying to increment date column of data frame so as to merge it with
another data frame using sqldf:
my query is :
merge<-sqldf("select m.* ,e.* from mdata as m left join event as e on
date(m.Datest,'+1 day')=e.Start")

The query returns null for all columns related to event table.
When I investigated further with query :
sqldf("select date(Datest,'+1 day')") from eventflight;")
 gives me -ve valued dates like : -4671-02-15

However this works:
sqldf("select date(('2009-05-01'),'+1')")

Dataframes are as follows:
mdata :
LOS Arrivals BookRange   Datest
 1     1283       0-4            2009-05-01
 1     1650       0-4            2009-05-08
 1     1302       5-9            2009-05-15

event:
 Event.Name  Event.location          Start           End
 Birthday        Texas (US)           2009-05-02    2009-05-03
 Anni              Texas (US)          2009-05-09     2009-01-11

What am I doing wrong?

Thanks in advance
SB

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Aug 14 22:06:00 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 14 Aug 2014 20:06:00 +0000
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <a91811a4-b78a-4fe9-bd45-c7aab3bf83f5@email.android.com>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
	<CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
	<C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
	<a91811a4-b78a-4fe9-bd45-c7aab3bf83f5@email.android.com>
Message-ID: <D0126380.1078A7%macqueen1@llnl.gov>

You didn?t say why you want it to return 6 and 4 for times 4 and 12
respectively, so I made an assumption. On that basis, try this example:


mydf <- data.frame(time=c(0,3,9), resp=c(5,6,4))

myint <- approx( mydf$time, mydf$resp, xout=c(6,12),
                 method='constant', f=0, rule=2)

It reproduces your two example desired results.

print(myint)
$x
[1] 6 12
$y
[1] 6 4


(aside)
If my assumption is correct, this is an example of a case where a simple
R-supplied function does the job and there?s no need to use anything else.
Simple tools for simple jobs. The approx() function has been in R since
the very beginning.


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/14/14, 11:27 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

>So for part one it seems you already have your answer.
>
>For part two you should look at time series types like "zoo", with which
>you can merge NAs at the new times at which you want "interpolated"
>answers and use the na.locf function to fill in values.
>--------------------------------------------------------------------------
>-
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.
>rocks...1k
>--------------------------------------------------------------------------
>- 
>Sent from my phone. Please excuse my brevity.
>
>On August 14, 2014 9:39:34 AM PDT, "Jaiprasart, Pharavee (HSC)"
><pharavee-jaiprasart at ouhsc.edu> wrote:
>>Hi Bert,
>>
>>I should have phrased my question differently.
>>
>>I actually want to do two things.
>>
>>First is to make a step plot. The "s"/"S" is a typo on my part.
>>
>>The second is to write a script that when I ask the program for
>>Response of time == 4, I want it to return "6", or if I ask for
>>response of time == 12, it will return "4", and so on.
>>
>>Pharavee
>>
>>
>>-----Original Message-----
>>From: Bert Gunter [mailto:gunter.berton at gene.com]
>>Sent: Thursday, August 14, 2014 11:27 AM
>>To: Jaiprasart, Pharavee (HSC)
>>Cc: r-help at r-project.org
>>Subject: Re: [R] Operating on the value from row i and row i+1
>>
>>Your query is a bit unclear, but I suspect
>>
>>?plot
>>
>>and a **careful read** about types "s" and "S" therein would address
>>your problem.
>>
>>Cheers,
>>Bert
>>
>>Bert Gunter
>>Genentech Nonclinical Biostatistics
>>(650) 467-7374
>>
>>"Data is not information. Information is not knowledge. And knowledge
>>is certainly not wisdom."
>>Clifford Stoll
>>
>>
>>
>>
>>On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC)
>><pharavee-jaiprasart at ouhsc.edu> wrote:
>>> Hi all,
>>>
>>>
>>>
>>> I'd like to make a step plot of Time vs Response graph.
>>>
>>> This is the example of my data frame - the real data frame has more
>>than a thousand rows.
>>>
>>>
>>>
>>> Time          Duration of infusion           Infusion Rate
>>Response               Subtype
>>>
>>> 0                         3
>>      2                         5                                     0
>>>
>>> 3                         6
>>      3                         6                                     0
>>>
>>> 9                         6
>>      4                         4                                     0
>>>
>>>
>>>
>>> I cannot just use type = c("s") for this because I also want to use
>>the value of the in between time for further calculation too (If I ask
>>the program for Response of time == 4, I want it to return "6").
>>>
>>>
>>>
>>> The way I think the script should work is that:
>>>
>>>
>>>
>>> For all rows that has subtype ==0, if time is between the value of
>>row 
>>> /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column
>>> "Dummy" and return the value of row /i/ from the Response column
>>(e.g. 
>>> 5 in this
>>>
>>> example) , and do these for all rows (e.g. any time between row 2 and
>>
>>> 3 which is 3-9, make a new column and return 6). Then I can say if
>>> Time>0 (value in column1) and <3 (value from column 1+2), y = value
>>in 
>>> Dummy
>>>
>>>
>>>
>>> Is there any way to do this in R?
>>>
>>>
>>>
>>> Thanks!
>>>
>>> Pharavee
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>>
>>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>>>
>>n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>>>
>>spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0
>>>
>>k79BnWO1L%2FRUs%3D%0A&s=8d0ca7ccfe0e7c4bac733aa2e8fe9a7068ffcf501cb181
>>> e4261e95efc1b0e31a PLEASE do read the posting guide
>>>
>>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>>>
>>sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>>>
>>pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0k
>>>
>>79BnWO1L%2FRUs%3D%0A&s=7ca8e5a21aa512fa8bc5669fb6f4ea587d530d4a20146fd
>>> 526148d17a3d198bc and provide commented, minimal, self-contained,
>>> reproducible code.
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Thu Aug 14 22:35:20 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 14 Aug 2014 16:35:20 -0400
Subject: [R] Sldf command returns negative value for date
In-Reply-To: <CAOsJHwDButp9jQyZJdJu9+kXo8Na3EeCXzAkoFtHTKTSZCUK5Q@mail.gmail.com>
References: <CAOsJHwDButp9jQyZJdJu9+kXo8Na3EeCXzAkoFtHTKTSZCUK5Q@mail.gmail.com>
Message-ID: <CAP01uRn5npGcVXDPRoEkWkpiR0_Cv7NpCgbh6N7jJRe3zwfn5g@mail.gmail.com>

On Thu, Aug 14, 2014 at 3:47 PM, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:
> Hi All!
>
> I am trying to increment date column of data frame so as to merge it with
> another data frame using sqldf:
> my query is :
> merge<-sqldf("select m.* ,e.* from mdata as m left join event as e on
> date(m.Datest,'+1 day')=e.Start")
>
> The query returns null for all columns related to event table.
> When I investigated further with query :
> sqldf("select date(Datest,'+1 day')") from eventflight;")
>  gives me -ve valued dates like : -4671-02-15
>
> However this works:
> sqldf("select date(('2009-05-01'),'+1')")
>
> Dataframes are as follows:
> mdata :
> LOS Arrivals BookRange   Datest
>  1     1283       0-4            2009-05-01
>  1     1650       0-4            2009-05-08
>  1     1302       5-9            2009-05-15
>
> event:
>  Event.Name  Event.location          Start           End
>  Birthday        Texas (US)           2009-05-02    2009-05-03
>  Anni              Texas (US)          2009-05-09     2009-01-11
>
> What am I doing wrong?

This is a FAQ.   See #4 here: http://sqldf.googlecode.com .

The SQLite date function assumes its argument is a timestring but R
"Date" class variables are transferred to SQLite as days since
1970-01-01 so just add 1.

   sqldf("select * from mdata as m left join event on Datest+1 = Start")



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From K.Sawicka at pgr.reading.ac.uk  Thu Aug 14 23:56:30 2014
From: K.Sawicka at pgr.reading.ac.uk (Katarzyna Sawicka)
Date: Thu, 14 Aug 2014 21:56:30 +0000
Subject: [R] Coding up GAMMs for multi-site trends analysis.
Message-ID: <bcf1a4c146ce4e7490e78c393456ca4d@DB3PR01MB0458.eurprd01.prod.exchangelabs.com>

Dear R users,

I would like to ask you for help with coding up. I would like to recreate a
method from a paper of Malcolm et al. (2014) (MALCOLM, I. A., GIBBINS, C.
N., FRYER, R. J., KEAY, J., TETZLAFF, D. & SOULSBY, C. 2014.
 The influence of forestry on acidification and recovery: Insights from
long-term hydrochemical and invertebrate data. Ecological Indicators, 37,
Part B, 317-329.) for multi-site long-term hydrochemistry trends analysis
using GAMMs and mgcv package.


 The method description says:
 "For a chemical determinant (e.g. water pH) a model was ?tted with: (a)
site included as a factor, (b) a common trend (i.e. a temporal (annual)
smoother common across sites), (c) site-speci?c temporal smoothers measuring
departures from the common trend. Each site-speci?c smoother was constrained
to have the same degrees of freedom assuming common temporal drivers. Three
normally distributed random effects were also included: (i) an
autocorrelated year effect (year treated as a factor) common across sites,
(ii) site-speci?c year effects (year treated as a factor) autocorrelated
within sites but independent between sites (with variance and
autocorrelation assumed common across sites), (iii) an independent residual
term weighted by the square root of the annual sample number to account for
changing sampling effort over time; this weighting, one of several tried,
gave residuals with homogenous variance for all determinants.
[...] the models were ?tted with the variance structure held ?xed at that
estimated by REML and with
the smooths estimated by generalized cross-validation. Smooths with zero edf
(i.e. where the term drops out of the model) where also considered in the
optimisation process".


Let's have some example data:

tmpData = as.data.frame(matrix(data = NA, ncol = 3, nrow = 30))
colnames(tmpData) = c("Determinant", "Year", "Site")
tmpData$Determinant =
c(4.1,4.7,4.5,4.6,4.7,5.6,5.2,
5.6,5.9,5.5,4.9,4.8,4.1,4.2,4.2,4.0,3.9,4.7,4.6,4.5,5.5,5.2,5.1,5.2,5.5,5.7,5.5,5.6,5.8,5.9)
tmpData$Year = c(rep(c(1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001,
2002), 3))
tmpData$Site = c(rep("Site A", 10), rep("Site B", 10), rep("Site C", 10))

So, I would imagine this should start like:

library(mgcv)
model = gamm(Determinant ~ factor(Site) + s(Year, bs = "cr") + ... +
                           random = list(factor(Year) = ~1, ...),
                           method = "REML", data = tmpData)


But I know only little about capabilities of mixed effect models and how
possibly code up in this case (c) site-speci?c temporal smoothers measuring
departures from
the common trend, and the random effects in this case.

If anyone could supply me with any tip or a hint, I will be very grateful.

Thank you.

Kasia Sawicka


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Aug 15 00:57:05 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 Aug 2014 15:57:05 -0700
Subject: [R] identicalFiles(filename1, filename2)?
Message-ID: <CAF8bMcbfuXMjz89a_VV54ddzxZcgi+_oOdASUyoP9fvFn9qaJQ@mail.gmail.com>

Is there a function in core R that takes 2 strings and returns TRUE if
they refer to the same file?  (If either does not refer to a file, I
think it would be fine if it returned FALSE.)

Compariing inode/device numbers on Unix-like systems and the output of
normalizePath on Windows would probably do it.   Comparing files on
non-native file systems can mess things up so perhaps we should not
promise much.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


From jsc.eco at gmail.com  Fri Aug 15 06:44:29 2014
From: jsc.eco at gmail.com (Janet Choate)
Date: Thu, 14 Aug 2014 21:44:29 -0700
Subject: [R] Using Moran.I
Message-ID: <CAEqw1VyEUYaaSBc+Nw6X8LBL2gXP0Zx_Mzo4ZgH3p7C=a92s_g@mail.gmail.com>

Dear R community,
i am attempting to use Moran.I for the first time, and am not quite sure on
the inputs needed....
i have loaded the ape library.

i have a data frame that includes concentrations of nutrients (no3, nh4,
po4) and the percentage of different land use types (urb, ag, ud, comm, sr,
dp, park) contributing to the locations where the measurements were taken.
it (fwr) looks like this (but longer):

fwr
     no3   nh4    po4  urb   ag   ud comm   sr   dp park
1 558.77 10.79 147.95 0.50 0.09 0.37 0.17 0.15 0.18 0.05
2 403.70  9.27  25.11 0.49 0.09 0.37 0.16 0.16 0.17 0.05
3 365.77  9.61 127.22 0.46 0.09 0.40 0.15 0.15 0.16 0.04
4  93.95  1.78  11.34 0.45 0.08 0.42 0.13 0.18 0.14 0.06
5  63.20 21.44  47.17 0.47 0.08 0.40 0.13 0.19 0.15 0.06
6  14.80  4.47  27.06 0.49 0.07 0.38 0.13 0.21 0.15 0.06

i was asked to do multiple regression, and plot the residuals:
no3.mr = lm(no3 ~ urb+ag+ud+comm+sr+dp+park)

then asked to do a Moran's I on the residuals.

i am not sure about the input necessary to do a Moran's I. do i need
coordinate locations? or/and how do i assign the weights?
i think i assign the weights to the land use types -
how would i use the results of the multiple regression (no3.mr) to perform
the Morans.I on the residuals?

thank you for any assistance,
Janet

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Fri Aug 15 07:30:09 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 Aug 2014 06:30:09 +0100
Subject: [R] identicalFiles(filename1, filename2)?
In-Reply-To: <CAF8bMcbfuXMjz89a_VV54ddzxZcgi+_oOdASUyoP9fvFn9qaJQ@mail.gmail.com>
References: <CAF8bMcbfuXMjz89a_VV54ddzxZcgi+_oOdASUyoP9fvFn9qaJQ@mail.gmail.com>
Message-ID: <53ED9AE1.6000607@stats.ox.ac.uk>

On 14/08/2014 23:57, William Dunlap wrote:
> Is there a function in core R that takes 2 strings and returns TRUE if
> they refer to the same file?  (If either does not refer to a file, I
> think it would be fine if it returned FALSE.)

No, but equality for normalizePath() works well enough on most OSes 
(Unix-alikes do follow links, although if you have a file system mounted 
in multiple places I have no idea how well it copes).

>
> Compariing inode/device numbers on Unix-like systems and the output of
> normalizePath on Windows would probably do it.   Comparing files on
> non-native file systems can mess things up so perhaps we should not
> promise much.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jwd at surewest.net  Fri Aug 15 07:36:23 2014
From: jwd at surewest.net (jwd)
Date: Thu, 14 Aug 2014 22:36:23 -0700
Subject: [R] Installation of R version 3.1.0
In-Reply-To: <CAN7A_QwAV5hmQovfXDZsqbVRghB89nnDMzr2v6mCvFeauyA5Tw@mail.gmail.com>
References: <CAN7A_QwAV5hmQovfXDZsqbVRghB89nnDMzr2v6mCvFeauyA5Tw@mail.gmail.com>
Message-ID: <20140814223623.795cbbc8@draco>

On Thu, 14 Aug 2014 12:15:58 -0400
VG <gupta567varun at gmail.com> wrote:

> Hi Everyone,
> I am currently using *R version 3.0.0 RC (2013-03-28 r62434) --
> "Masked Marvel"*
> 
> I am using Ubuntu 10.04 LTS- the Lucid Lynx.
> 
> I downloaded the  tar.gz of R 3.1.0 under my Downloads folder.
> I changed my directory to Downloads folder and then used following
> commands to install the version.
> 
> I used
> tar -xzf tar.gz
> cd R-3.1.0
> ./configure
> make
> make check
> 
Currently you've compiled and verified compilation.  You need to
install it.  
Go to the R-3.10 directory, the one you compile from and run
sudo make install


From dhimanbhadra at gmail.com  Fri Aug 15 07:54:17 2014
From: dhimanbhadra at gmail.com (DHIMAN BHADRA)
Date: Fri, 15 Aug 2014 11:24:17 +0530
Subject: [R] Obtaining predicted values for glm() function
Message-ID: <CAMD1hnhzSiB9zdtoTOg68nz0d3yjG6ka2EEiEavu-hchMLHr4g@mail.gmail.com>

Dear all.

I am trying to relate daily deaths in a given city with air pollution
values. The model I am using is as follows:

model <- glm(deaths ~ pollution + ns(time, 13) + ns(temp, 7) + ns(rh, 5) +
dow + holiday, family=quasipoisson, data=city)

Where -
deaths: daily number of deaths
pollution: daily measured levels of air pollution
ns(time, 13): smooth function (i.e. cubic spline) of time with 13 degrees
of freedom
ns(temp, 7): smooth function (i.e. cubic spline) of temperature with 7
degrees of freedom
ns(rh, 5): smooth function (i.e. cubic spline) of humidity with 5 degrees
of freedom
dow: day of the week
holiday: dummy variable to indicate public holidays

Having run this model, how do I obtain predicted values of deaths for any
given set of pollution values? Any suggestions will be much appreciated.

Thanks in advance,
Dhiman Bhadra
Assistant professor.
IIM Ahmedabad.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Aug 15 08:22:49 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 14 Aug 2014 23:22:49 -0700
Subject: [R] Obtaining predicted values for glm() function
In-Reply-To: <CAMD1hnhzSiB9zdtoTOg68nz0d3yjG6ka2EEiEavu-hchMLHr4g@mail.gmail.com>
References: <CAMD1hnhzSiB9zdtoTOg68nz0d3yjG6ka2EEiEavu-hchMLHr4g@mail.gmail.com>
Message-ID: <dd9cc62b-ea27-4794-afa0-7855a34b9d16@email.android.com>

Please don't repeat post. In fact, you should definitely read the Posting Guide mentioned at the bottom if this or any other post from the list and follow its advice.

The usual way to predict output of a model in R is to use the predict function appropriate to your model object class. You might find reading the help file ?predict.glm helpful. If not, then you might be needing to study some more basic use cases of R so you can interpret the help files.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 14, 2014 10:54:17 PM PDT, DHIMAN BHADRA <dhimanbhadra at gmail.com> wrote:
>Dear all.
>
>I am trying to relate daily deaths in a given city with air pollution
>values. The model I am using is as follows:
>
>model <- glm(deaths ~ pollution + ns(time, 13) + ns(temp, 7) + ns(rh,
>5) +
>dow + holiday, family=quasipoisson, data=city)
>
>Where -
>deaths: daily number of deaths
>pollution: daily measured levels of air pollution
>ns(time, 13): smooth function (i.e. cubic spline) of time with 13
>degrees
>of freedom
>ns(temp, 7): smooth function (i.e. cubic spline) of temperature with 7
>degrees of freedom
>ns(rh, 5): smooth function (i.e. cubic spline) of humidity with 5
>degrees
>of freedom
>dow: day of the week
>holiday: dummy variable to indicate public holidays
>
>Having run this model, how do I obtain predicted values of deaths for
>any
>given set of pollution values? Any suggestions will be much
>appreciated.
>
>Thanks in advance,
>Dhiman Bhadra
>Assistant professor.
>IIM Ahmedabad.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mary.pfauth at alaska.gov  Thu Aug 14 23:53:31 2014
From: mary.pfauth at alaska.gov (Pfauth, Mary C (DEC))
Date: Thu, 14 Aug 2014 21:53:31 +0000
Subject: [R] unable to call certain functions
Message-ID: <5E38825F94505143B3FAC2BEB6DFEEE4C7D23023@SOAANCEXMB9.soa.alaska.gov>

Hello R users,
    I am new to R and, so far, am finding it relatively easy to use. I have run into what seems to me to be an odd problem. I have tried using the "import" and calendarPlot" functions while in the open air package. I get a message returned stating "unable to find function." I know that the package is loaded properly because I have tried to reload/reinstall and get a message that it is running already. The help function displays descriptions of these functions so I know they must be in there somewhere! The only relevant thing I could find in the FAQs related to being sure that the package was actually loaded/installed. Has anyone else had this problem and, if so, what was the fix?
Appreciatively,
Mary Pfauth

Mary Pfauth
Alaska Department of Environmental Conservation
Air Quality Division
619 E. Ship Creek Ave. #249
Anchorage, AK 99501
(907) 269-6879
mary.pfauth at alaska.gov




	[[alternative HTML version deleted]]


From sohail13 at gmail.com  Fri Aug 15 00:08:51 2014
From: sohail13 at gmail.com (Sohail Khan)
Date: Thu, 14 Aug 2014 18:08:51 -0400
Subject: [R] reshape a dataset
Message-ID: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>

Hi
I have data set as follows:
  A 92315  A 35018  A 56710  B 52700  B 92315  B 15135  C 35018  C 52700
I would like to transform this data set into:
  ID 92315 35018 56710 52700 15135  A 1 1 1 0 0  B 1 0 0 1 1  C 0 1 0 1 0
I looked into reshape package to no avail.
I would appreciate any suggestions.

-Sohail

	[[alternative HTML version deleted]]


From pharavee-jaiprasart at ouhsc.edu  Fri Aug 15 00:14:35 2014
From: pharavee-jaiprasart at ouhsc.edu (Jaiprasart, Pharavee (HSC))
Date: Thu, 14 Aug 2014 22:14:35 +0000
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <D0126380.1078A7%macqueen1@llnl.gov>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
	<CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
	<C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
	<a91811a4-b78a-4fe9-bd45-c7aab3bf83f5@email.android.com>
	<D0126380.1078A7%macqueen1@llnl.gov>
Message-ID: <C0737CD3E51ABA43BE288766515C35DC1035371F@VANQUISH.hsc.net.ou.edu>

Hi Don.

The reason I want to do this is that I have the recorded infusion rate of time 1, 2, 6, 8 but I have the recorded response of time 1.5, 3, 4, 12. Notice that the time does not match between the two. Ultimately I want to plot Response VS Infusion Rate. If I just use xyplot between the two column, I'll just get a blank.  

The approx() function cannot do what I want. The problem is that the data frame has data from different patients, with different patients have different response (y) when given the drug at the same infusion rate (x). If I use approx() then all the patients with the same x will return the same y. Do you have any other suggestions? 

Thanks!
Pharavee



-----Original Message-----
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Thursday, August 14, 2014 3:06 PM
To: Jaiprasart, Pharavee (HSC)
Cc: r-help at r-project.org; Jeff Newmiller; Bert Gunter
Subject: Re: [R] Operating on the value from row i and row i+1

You didn?t say why you want it to return 6 and 4 for times 4 and 12 respectively, so I made an assumption. On that basis, try this example:


mydf <- data.frame(time=c(0,3,9), resp=c(5,6,4))

myint <- approx( mydf$time, mydf$resp, xout=c(6,12),
                 method='constant', f=0, rule=2)

It reproduces your two example desired results.

print(myint)
$x
[1] 6 12
$y
[1] 6 4


(aside)
If my assumption is correct, this is an example of a case where a simple R-supplied function does the job and there?s no need to use anything else.
Simple tools for simple jobs. The approx() function has been in R since the very beginning.


--
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/14/14, 11:27 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:

>So for part one it seems you already have your answer.
>
>For part two you should look at time series types like "zoo", with 
>which you can merge NAs at the new times at which you want "interpolated"
>answers and use the na.locf function to fill in values.
>-----------------------------------------------------------------------
>---
>-
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.
>rocks...1k
>-----------------------------------------------------------------------
>---
>-
>Sent from my phone. Please excuse my brevity.
>
>On August 14, 2014 9:39:34 AM PDT, "Jaiprasart, Pharavee (HSC)"
><pharavee-jaiprasart at ouhsc.edu> wrote:
>>Hi Bert,
>>
>>I should have phrased my question differently.
>>
>>I actually want to do two things.
>>
>>First is to make a step plot. The "s"/"S" is a typo on my part.
>>
>>The second is to write a script that when I ask the program for 
>>Response of time == 4, I want it to return "6", or if I ask for 
>>response of time == 12, it will return "4", and so on.
>>
>>Pharavee
>>
>>
>>-----Original Message-----
>>From: Bert Gunter [mailto:gunter.berton at gene.com]
>>Sent: Thursday, August 14, 2014 11:27 AM
>>To: Jaiprasart, Pharavee (HSC)
>>Cc: r-help at r-project.org
>>Subject: Re: [R] Operating on the value from row i and row i+1
>>
>>Your query is a bit unclear, but I suspect
>>
>>?plot
>>
>>and a **careful read** about types "s" and "S" therein would address 
>>your problem.
>>
>>Cheers,
>>Bert
>>
>>Bert Gunter
>>Genentech Nonclinical Biostatistics
>>(650) 467-7374
>>
>>"Data is not information. Information is not knowledge. And knowledge 
>>is certainly not wisdom."
>>Clifford Stoll
>>
>>
>>
>>
>>On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC) 
>><pharavee-jaiprasart at ouhsc.edu> wrote:
>>> Hi all,
>>>
>>>
>>>
>>> I'd like to make a step plot of Time vs Response graph.
>>>
>>> This is the example of my data frame - the real data frame has more
>>than a thousand rows.
>>>
>>>
>>>
>>> Time          Duration of infusion           Infusion Rate
>>Response               Subtype
>>>
>>> 0                         3
>>      2                         5                                     0
>>>
>>> 3                         6
>>      3                         6                                     0
>>>
>>> 9                         6
>>      4                         4                                     0
>>>
>>>
>>>
>>> I cannot just use type = c("s") for this because I also want to use
>>the value of the in between time for further calculation too (If I ask 
>>the program for Response of time == 4, I want it to return "6").
>>>
>>>
>>>
>>> The way I think the script should work is that:
>>>
>>>
>>>
>>> For all rows that has subtype ==0, if time is between the value of
>>row
>>> /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column 
>>> "Dummy" and return the value of row /i/ from the Response column
>>(e.g. 
>>> 5 in this
>>>
>>> example) , and do these for all rows (e.g. any time between row 2 
>>> and
>>
>>> 3 which is 3-9, make a new column and return 6). Then I can say if
>>> Time>0 (value in column1) and <3 (value from column 1+2), y = value
>>in
>>> Dummy
>>>
>>>
>>>
>>> Is there any way to do this in R?
>>>
>>>
>>>
>>> Thanks!
>>>
>>> Pharavee
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>>
>>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>>>
>>n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>>>
>>spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0
>>>
>>k79BnWO1L%2FRUs%3D%0A&s=8d0ca7ccfe0e7c4bac733aa2e8fe9a7068ffcf501cb181
>>> e4261e95efc1b0e31a PLEASE do read the posting guide
>>>
>>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>>>
>>sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>>>
>>pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0k
>>>
>>79BnWO1L%2FRUs%3D%0A&s=7ca8e5a21aa512fa8bc5669fb6f4ea587d530d4a20146fd
>>> 526148d17a3d198bc and provide commented, minimal, self-contained, 
>>> reproducible code.
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>>n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>>spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7v
>>lfodRikcrIpl0UQ%3D%0A&s=67e8bf2791e73de4b63127d329bb86d4c97dbba4a03e97
>>4b239131baea91d77a
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>>sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>>pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7vl
>>fodRikcrIpl0UQ%3D%0A&s=2bd5a814cb6e6636a0486fe20551fc29d7087799a5944aa
>>65c458edf76daea25 and provide commented, minimal, self-contained, 
>>reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailman
>/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnssp
>JiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7vlfo
>dRikcrIpl0UQ%3D%0A&s=67e8bf2791e73de4b63127d329bb86d4c97dbba4a03e974b23
>9131baea91d77a
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/pos
>ting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnsspJ
>iRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7vlfod
>RikcrIpl0UQ%3D%0A&s=2bd5a814cb6e6636a0486fe20551fc29d7087799a5944aa65c4
>58edf76daea25 and provide commented, minimal, self-contained, 
>reproducible code.


From subscriptions at simonplace.net  Fri Aug 15 02:52:08 2014
From: subscriptions at simonplace.net (Peter Brady)
Date: Fri, 15 Aug 2014 10:52:08 +1000
Subject: [R] How Can SVD Reconstruct a Matrix
In-Reply-To: <CA+hbrhU68YaycHsDavP3y0_MyCiQEXXhTPhykFMN4-TX672dzg@mail.gmail.com>
References: <53EC5DEB.9040803@simonplace.net>
	<CA+hbrhU68YaycHsDavP3y0_MyCiQEXXhTPhykFMN4-TX672dzg@mail.gmail.com>
Message-ID: <53ED59B8.9030101@simonplace.net>

On 15/08/2014 2:40 am, Peter Langfelder wrote:
> On Wed, Aug 13, 2014 at 11:57 PM, Peter Brady
> <subscriptions at simonplace.net> wrote:
>> > Hi All,
>> >
>> > I've inherited some R code that I can't work out what they've done.  It
>> > appears to work and give sort of reasonable answers, I'm just trying to
>> > work out why they've done what they have.  I suspect that this is a
>> > simple vector identity that I've just been staring at too long and have
>> > forgotten...
>> >
>> > The code:
>> >
>> > GGt <- M0 - M1 %*% M0inv %*% t(M1)
>> > svdGG <- svd(GGt)
>> > Gmat <- svdGG$u %*% diag(sqrt(svdGG$d))
>> >
>> > It is supposed to solve:
>> >
>> > G*G^T = M0 - M1*M0^-1*M1^T
>> >
>> > for G, where G^T is the transpose of G.  It is designed to reproduce a
>> > numerical method described in two papers:
>> >
>> > Srikanthan and Pegram, Journal of Hydrology, 371 (2009) 142-153,
>> > Equation A13, who suggest the SVD method but don't describe the
>> > specifics, eg: "...G is found by singular value decomposition..."
>> >
>> > Alternatively, Matalas (1967) Water Resources Research 3 (4) 937-945,
>> > Equation 17, say that the above can be solved using Principle Component
>> > Analysis (PCA).
>> >
>> > I use PCA (specifically POD) and SVD to look at the components after
>> > decomposition, so I'm a bit lost as to how the original matrix G can be
>> > constructed in this case from only the singular values and the left
>> > singular vectors.
> GG' is a symmetric matrix, so left- and right-singular vectors are the
> same. If I recall right, in general it is impossible to find G from
> GG' (I denote the transpose by ') since, given an orthogonal
> transformation U (that is, UU'=1), GUU'G' = GG', so you can only find
> G up to multiplication with an orthogonal transformation matrix.
> 
> Since SVD decomposes a matrix X = UDV', the decomposition for GG' is
> 
> GG' = UDU'; setting S = sqrt(D) (i.e., diagonal matrix with elements
> that are sqrt of those in D), GG' = USSU' = USS'U', so one solution is
> G = US which is the solution used.
> 
> You could use PCA on G, which is roughly equivalent to doing SVD on
> GG' (up to centering and scaling of the columns of G). I am not very
> familiar with PCA in R since I always use SVD, but here's what the
> help file for prcomp (PCA in R) says:
> 
>    The calculation is done by a singular value decomposition of the
>      (centered and possibly scaled) data matrix, not by using ?eigen?
>      on the covariance matrix.  This is generally the preferred method
>      for numerical accuracy.

YES!  Thank you and to Martyn for the same comment.  The identity that I
was missing was that for a symmetric matrix the left and right singular
values are equal, i.e.:

U = V and, by extrapolation, U' == V'

Then, back to the text books, original papers and google I get the
following:

1) G itself is also symmetric as it is a spatial (and perhaps temporal)
correlation matrix.

2) PCA: "we basically try to find eigenvalues and eigenvectors of the
covariance matrix, C. We showed that C = (AA') / (n-1), and thus finding
the eigenvalues and eigenvectors of C is the same as finding the
eigenvalues and eigenvectors of AA'."

3) Further, from some algebra of SVD results it can be shown that from
  A = U S V'
we can get:
  AA' = U S^2 U'

Hence, in my notation scheme the PCA decomposition of GG' via SVD is:

GG' = U S^2 U'

and the corresponding SVD of G is:

G = U S V'

but as U'=V' I can substitute:

G = U S U'

Hence, I can compute G from the SVD of GG'.  This, unfortunately leads
to the conclusion that there is a bug in the code, which can be
verified, and fixed, in the sample code:

rm(list=ls())

# Make this repeatable for testing
set.seed(12003)

# Generate a dummy set of 1000 months of rain at 10 measurement stations
tsLength <- 1000;
nStations <- 10;
syntheticRain <- runif(tsLength * nStations, 0, 10)
syntheticRain <- matrix(syntheticRain, nrow = tsLength, ncol = nStations)

# Normalise the rainfall before further processing as is standard
practice in
# statistical hydrology. NB: this step should not matter though for the
method
# as the correlation will eliminate the scale and means.
syntheticRain <- scale(syntheticRain)

# Compute the spatial correlation of the stations
spatialCor <- cor(syntheticRain)

# Our dummy GGt:
GGt <- spatialCor %*% t(spatialCor)

# Now attempt the back calculation to verify
svdGGT <- svd(GGt)
spatialCorfromSVD1 <- svdGGT$u %*% diag(sqrt(svdGGT$d))
spatialCorfromSVD2 <- svdGGT$u %*% diag(sqrt(svdGGT$d)) %*% t(svdGGT$u)


Thanks very much all
-pete

-- 
Peter Brady
Email: pdbrady at ans.com.au
Skype: pbrady77

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 881 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140815/82e27245/attachment.bin>

From jim at bitwrit.com.au  Fri Aug 15 10:45:58 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 15 Aug 2014 18:45:58 +1000
Subject: [R] unable to call certain functions
In-Reply-To: <5E38825F94505143B3FAC2BEB6DFEEE4C7D23023@SOAANCEXMB9.soa.alaska.gov>
References: <5E38825F94505143B3FAC2BEB6DFEEE4C7D23023@SOAANCEXMB9.soa.alaska.gov>
Message-ID: <1768075.cB8B5D53xN@localhost.localdomain>

On Thu, 14 Aug 2014 09:53:31 PM Pfauth, Mary C wrote:
> Hello R users,
>     I am new to R and, so far, am finding it relatively easy to use. I 
have
> run into what seems to me to be an odd problem. I have tried using 
the
> "import" and calendarPlot" functions while in the open air package. I 
get a
> message returned stating "unable to find function." I know that the 
package
> is loaded properly because I have tried to reload/reinstall and get a
> message that it is running already. The help function displays 
descriptions
> of these functions so I know they must be in there somewhere! The 
only
> relevant thing I could find in the FAQs related to being sure that the
> package was actually loaded/installed. Has anyone else had this 
problem
> and, if so, what was the fix? Appreciatively,
> Mary Pfauth
> 
> Mary Pfauth
> Alaska Department of Environmental Conservation
> Air Quality Division
> 619 E. Ship Creek Ave. #249
> Anchorage, AK 99501
> (907) 269-6879
> mary.pfauth at alaska.gov
> 
> 
Hi Mary,
I don't have openair installed, but the problem might be simple. Get 
an R session going and try this:

library(openair)
# use a filename that you actually have
myairq<-import("airq.csv")
calendarPlot(myairq)

and paste the output into an email. 

Jim


From jim at bitwrit.com.au  Fri Aug 15 11:19:11 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 15 Aug 2014 19:19:11 +1000
Subject: [R] reshape a dataset
In-Reply-To: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>
References: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>
Message-ID: <2709208.etJG4SVCS1@localhost.localdomain>

On Thu, 14 Aug 2014 06:08:51 PM Sohail Khan wrote:
> Hi
> I have data set as follows:
>   A 92315  A 35018  A 56710  B 52700  B 92315  B 15135  C 35018  C 
52700
> I would like to transform this data set into:
>   ID 92315 35018 56710 52700 15135  A 1 1 1 0 0  B 1 0 0 1 1  C 0 1 0 
1 0
> I looked into reshape package to no avail.
> I would appreciate any suggestions.
> 
> -Sohail
> 
Hi Sohail,
You are doing a bit more than reshaping. This may get you there:

skdat<-read.table(text="A 92315
A 35018
A 56710
B 52700
B 92315
B 15135
C 35018
C 52700",stringsAsFactors=FALSE)
names(skdat)<-c("lettertag","ID")
ID<-unique(skdat$ID)
lettertags<-unique(skdat$lettertag)
newskdat<-list(ID)
for(i in 1:length(lettertags))
 newskdat[[i+1]]<-
  as.numeric(ID %in% skdat$ID[skdat$lettertag==lettertags[i]])
names(newskdat)<-c("ID",lettertags)

I'm assuming that you don't really want your answer as a single string.

Jim


From dhimanbhadra at gmail.com  Fri Aug 15 11:28:01 2014
From: dhimanbhadra at gmail.com (DHIMAN BHADRA)
Date: Fri, 15 Aug 2014 14:58:01 +0530
Subject: [R] Obtaining predicted values for glm() function
In-Reply-To: <dd9cc62b-ea27-4794-afa0-7855a34b9d16@email.android.com>
References: <CAMD1hnhzSiB9zdtoTOg68nz0d3yjG6ka2EEiEavu-hchMLHr4g@mail.gmail.com>
	<dd9cc62b-ea27-4794-afa0-7855a34b9d16@email.android.com>
Message-ID: <CAMD1hniJCCMd3=irtrGt4upzPUn7Q1pGnB6coOj4Ttq-CFg+nQ@mail.gmail.com>

Thanks Jeff for the suggestion - will explore the predict function. So far
I was working on the fitted() function but it seems to generate fitted
(response) values only for predictor values in the original data set, not
for values beyond that.

I never intended to spam the mailing list. I re-posted only when I did not
find my original post in my inbox, which led to think that my query has not
reached the R-family.

Thanks again for your suggestion,
Dhiman


On Fri, Aug 15, 2014 at 11:52 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please don't repeat post. In fact, you should definitely read the Posting
> Guide mentioned at the bottom if this or any other post from the list and
> follow its advice.
>
> The usual way to predict output of a model in R is to use the predict
> function appropriate to your model object class. You might find reading the
> help file ?predict.glm helpful. If not, then you might be needing to study
> some more basic use cases of R so you can interpret the help files.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 14, 2014 10:54:17 PM PDT, DHIMAN BHADRA <dhimanbhadra at gmail.com>
> wrote:
> >Dear all.
> >
> >I am trying to relate daily deaths in a given city with air pollution
> >values. The model I am using is as follows:
> >
> >model <- glm(deaths ~ pollution + ns(time, 13) + ns(temp, 7) + ns(rh,
> >5) +
> >dow + holiday, family=quasipoisson, data=city)
> >
> >Where -
> >deaths: daily number of deaths
> >pollution: daily measured levels of air pollution
> >ns(time, 13): smooth function (i.e. cubic spline) of time with 13
> >degrees
> >of freedom
> >ns(temp, 7): smooth function (i.e. cubic spline) of temperature with 7
> >degrees of freedom
> >ns(rh, 5): smooth function (i.e. cubic spline) of humidity with 5
> >degrees
> >of freedom
> >dow: day of the week
> >holiday: dummy variable to indicate public holidays
> >
> >Having run this model, how do I obtain predicted values of deaths for
> >any
> >given set of pollution values? Any suggestions will be much
> >appreciated.
> >
> >Thanks in advance,
> >Dhiman Bhadra
> >Assistant professor.
> >IIM Ahmedabad.
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Fri Aug 15 11:37:49 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Fri, 15 Aug 2014 19:37:49 +1000
Subject: [R] reshape a dataset
In-Reply-To: <2709208.etJG4SVCS1@localhost.localdomain>
References: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>
	<2709208.etJG4SVCS1@localhost.localdomain>
Message-ID: <CAKL8G3HiAaZp1kyQBnxPTv5O6ExCawDodJ0wYCcwjQHxTBqA7A@mail.gmail.com>

Dear Sohail,

Using Jim's data set skdat, two more options would be

# first option
d <- with(skdat, table(ID, lettertag))
names <- colnames(d)
d <- c(list(rownames(d)), lapply(1:ncol(d), function(i) as.numeric(d[,i])))
names(d) <- c('ID', names)
d

# second option
d <- with(skdat, table(ID, lettertag))
res <- c(list(rownames(d)), sapply(apply(d, 2, list), "[", 1))
names(res)[1] <- "ID"
res

HTH,
Jorge.-



On Fri, Aug 15, 2014 at 7:19 PM, Jim Lemon <jim at bitwrit.com.au> wrote:

> On Thu, 14 Aug 2014 06:08:51 PM Sohail Khan wrote:
> > Hi
> > I have data set as follows:
> >   A 92315  A 35018  A 56710  B 52700  B 92315  B 15135  C 35018  C
> 52700
> > I would like to transform this data set into:
> >   ID 92315 35018 56710 52700 15135  A 1 1 1 0 0  B 1 0 0 1 1  C 0 1 0
> 1 0
> > I looked into reshape package to no avail.
> > I would appreciate any suggestions.
> >
> > -Sohail
> >
> Hi Sohail,
> You are doing a bit more than reshaping. This may get you there:
>
> skdat<-read.table(text="A 92315
> A 35018
> A 56710
> B 52700
> B 92315
> B 15135
> C 35018
> C 52700",stringsAsFactors=FALSE)
> names(skdat)<-c("lettertag","ID")
> ID<-unique(skdat$ID)
> lettertags<-unique(skdat$lettertag)
> newskdat<-list(ID)
> for(i in 1:length(lettertags))
>  newskdat[[i+1]]<-
>   as.numeric(ID %in% skdat$ID[skdat$lettertag==lettertags[i]])
> names(newskdat)<-c("ID",lettertags)
>
> I'm assuming that you don't really want your answer as a single string.
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sohail13 at gmail.com  Fri Aug 15 12:22:53 2014
From: sohail13 at gmail.com (Sohail Khan)
Date: Fri, 15 Aug 2014 06:22:53 -0400
Subject: [R] reshape a dataset
In-Reply-To: <CAKL8G3HiAaZp1kyQBnxPTv5O6ExCawDodJ0wYCcwjQHxTBqA7A@mail.gmail.com>
References: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>
	<2709208.etJG4SVCS1@localhost.localdomain>
	<CAKL8G3HiAaZp1kyQBnxPTv5O6ExCawDodJ0wYCcwjQHxTBqA7A@mail.gmail.com>
Message-ID: <CABUTPBkxDrNwSrPJ1pj5RAyJAphfAqLooVUDf5OeAoGvYa3RRA@mail.gmail.com>

Thanks Jim and Jorge,
Clever solutions, the final output is a list.
How do I covert it back a dataframe?
-Sohail


On Fri, Aug 15, 2014 at 5:37 AM, Jorge I Velez <jorgeivanvelez at gmail.com>
wrote:

> Dear Sohail,
>
> Using Jim's data set skdat, two more options would be
>
> # first option
> d <- with(skdat, table(ID, lettertag))
> names <- colnames(d)
> d <- c(list(rownames(d)), lapply(1:ncol(d), function(i) as.numeric(d[,i])))
> names(d) <- c('ID', names)
> d
>
> # second option
> d <- with(skdat, table(ID, lettertag))
> res <- c(list(rownames(d)), sapply(apply(d, 2, list), "[", 1))
> names(res)[1] <- "ID"
> res
>
> HTH,
> Jorge.-
>
>
>
> On Fri, Aug 15, 2014 at 7:19 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
>
> > On Thu, 14 Aug 2014 06:08:51 PM Sohail Khan wrote:
> > > Hi
> > > I have data set as follows:
> > >   A 92315  A 35018  A 56710  B 52700  B 92315  B 15135  C 35018  C
> > 52700
> > > I would like to transform this data set into:
> > >   ID 92315 35018 56710 52700 15135  A 1 1 1 0 0  B 1 0 0 1 1  C 0 1 0
> > 1 0
> > > I looked into reshape package to no avail.
> > > I would appreciate any suggestions.
> > >
> > > -Sohail
> > >
> > Hi Sohail,
> > You are doing a bit more than reshaping. This may get you there:
> >
> > skdat<-read.table(text="A 92315
> > A 35018
> > A 56710
> > B 52700
> > B 92315
> > B 15135
> > C 35018
> > C 52700",stringsAsFactors=FALSE)
> > names(skdat)<-c("lettertag","ID")
> > ID<-unique(skdat$ID)
> > lettertags<-unique(skdat$lettertag)
> > newskdat<-list(ID)
> > for(i in 1:length(lettertags))
> >  newskdat[[i+1]]<-
> >   as.numeric(ID %in% skdat$ID[skdat$lettertag==lettertags[i]])
> > names(newskdat)<-c("ID",lettertags)
> >
> > I'm assuming that you don't really want your answer as a single string.
> >
> > Jim
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Fri Aug 15 12:41:54 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 15 Aug 2014 20:41:54 +1000
Subject: [R] reshape a dataset
In-Reply-To: <CABUTPBkxDrNwSrPJ1pj5RAyJAphfAqLooVUDf5OeAoGvYa3RRA@mail.gmail.com>
References: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>
	<CAKL8G3HiAaZp1kyQBnxPTv5O6ExCawDodJ0wYCcwjQHxTBqA7A@mail.gmail.com>
	<CABUTPBkxDrNwSrPJ1pj5RAyJAphfAqLooVUDf5OeAoGvYa3RRA@mail.gmail.com>
Message-ID: <11543132.LiBnLfWHQE@localhost.localdomain>

On Fri, 15 Aug 2014 06:22:53 AM Sohail Khan wrote:
> Thanks Jim and Jorge,
> Clever solutions, the final output is a list.
> How do I covert it back a dataframe?
> -Sohail
> 
as.data.frame(newskdat)

or for Jorge's

as.data.frame(res)

Jim


From pdalgd at gmail.com  Fri Aug 15 14:41:07 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 15 Aug 2014 14:41:07 +0200
Subject: [R] A basic statistics question
In-Reply-To: <XFMail.20140813194905.Ted.Harding@wlandres.net>
References: <XFMail.20140813194905.Ted.Harding@wlandres.net>
Message-ID: <A64B6CD9-67C7-46E0-B03E-FB3811C9064A@gmail.com>


On 13 Aug 2014, at 20:49 , (Ted Harding) <ted.harding at wlandres.net> wrote:

> Indeed, this topic has got me wondering how many times I may have
> blindly used sd(x) in the past, as if it were going to give me the
> standard (sum(x - mean(x))^2)/length(x) result!


At the risk of flogging a horse that has been dead for the better part of a century, I don't think there is anything "standard" about an SD with a divisor of N, and the biasedness of the version with N-1 divisor is not really the crucial issue. Rather, the distinction is between 

- one sample from a known finite distribution
- multiple samples from an unknown distribution

and in particular between whether the mean is estimated or known. 

One argument for the N-1 divisor in the normal case is that you can transform data to one observation with unknown mean and N-1 independent observations with mean known to be 0. The variance estimate will be a function of the N-1 variables, and thus there is no reason to let the mere existence of the uninformative Nth variable change the estimator.

Of course few people really care about N vs. N-1 but in larger linear models, it becomes N-p and p can be a sizeable fraction of N.  

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sneha.bishnoi at gmail.com  Fri Aug 15 14:47:50 2014
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Fri, 15 Aug 2014 08:47:50 -0400
Subject: [R] Sldf command returns negative value for date
In-Reply-To: <CAP01uRn5npGcVXDPRoEkWkpiR0_Cv7NpCgbh6N7jJRe3zwfn5g@mail.gmail.com>
References: <CAOsJHwDButp9jQyZJdJu9+kXo8Na3EeCXzAkoFtHTKTSZCUK5Q@mail.gmail.com>
	<CAP01uRn5npGcVXDPRoEkWkpiR0_Cv7NpCgbh6N7jJRe3zwfn5g@mail.gmail.com>
Message-ID: <CAOsJHwD0nRnNQUvdCHN-+eEiXoE+KfmwXmgc=QeqT9K6GtdChw@mail.gmail.com>

It works :) Thanks so much! I tried searching a lot but I guess i missed
this fact!


On Thu, Aug 14, 2014 at 4:35 PM, Gabor Grothendieck <ggrothendieck at gmail.com
> wrote:

> On Thu, Aug 14, 2014 at 3:47 PM, Sneha Bishnoi <sneha.bishnoi at gmail.com>
> wrote:
> > Hi All!
> >
> > I am trying to increment date column of data frame so as to merge it with
> > another data frame using sqldf:
> > my query is :
> > merge<-sqldf("select m.* ,e.* from mdata as m left join event as e on
> > date(m.Datest,'+1 day')=e.Start")
> >
> > The query returns null for all columns related to event table.
> > When I investigated further with query :
> > sqldf("select date(Datest,'+1 day')") from eventflight;")
> >  gives me -ve valued dates like : -4671-02-15
> >
> > However this works:
> > sqldf("select date(('2009-05-01'),'+1')")
> >
> > Dataframes are as follows:
> > mdata :
> > LOS Arrivals BookRange   Datest
> >  1     1283       0-4            2009-05-01
> >  1     1650       0-4            2009-05-08
> >  1     1302       5-9            2009-05-15
> >
> > event:
> >  Event.Name  Event.location          Start           End
> >  Birthday        Texas (US)           2009-05-02    2009-05-03
> >  Anni              Texas (US)          2009-05-09     2009-01-11
> >
> > What am I doing wrong?
>
> This is a FAQ.   See #4 here: http://sqldf.googlecode.com .
>
> The SQLite date function assumes its argument is a timestring but R
> "Date" class variables are transferred to SQLite as days since
> 1970-01-01 so just add 1.
>
>    sqldf("select * from mdata as m left join event on Datest+1 = Start")
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
Sneha Bishnoi
+14047235469
H. Milton Stewart School of Industrial &  Systems Engineering
Georgia Tech

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Fri Aug 15 14:53:52 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Fri, 15 Aug 2014 22:53:52 +1000
Subject: [R] reshape a dataset
In-Reply-To: <CABUTPBkxDrNwSrPJ1pj5RAyJAphfAqLooVUDf5OeAoGvYa3RRA@mail.gmail.com>
References: <CABUTPBnomppW-AgQMDTbpgP5qVEa+Hc8jCfStbgP47r5WGY-DQ@mail.gmail.com>
	<2709208.etJG4SVCS1@localhost.localdomain>
	<CAKL8G3HiAaZp1kyQBnxPTv5O6ExCawDodJ0wYCcwjQHxTBqA7A@mail.gmail.com>
	<CABUTPBkxDrNwSrPJ1pj5RAyJAphfAqLooVUDf5OeAoGvYa3RRA@mail.gmail.com>
Message-ID: <CAKL8G3HDV9BBTanq1g0z-paBoDzdHGY3sL7xMpysS_iqUmo7tA@mail.gmail.com>

If that's the case, you could do the following:

d <- with(skdat, table(ID, lettertag))
d <- data.frame(cbind(ID = rownames(d), d))
rownames(d) <- NULL
d

HTH,
Jorge.-



On Fri, Aug 15, 2014 at 8:22 PM, Sohail Khan <sohail13 at gmail.com> wrote:

> Thanks Jim and Jorge,
> Clever solutions, the final output is a list.
> How do I covert it back a dataframe?
> -Sohail
>
>
>  On Fri, Aug 15, 2014 at 5:37 AM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
>
>>  Dear Sohail,
>>
>> Using Jim's data set skdat, two more options would be
>>
>> # first option
>> d <- with(skdat, table(ID, lettertag))
>> names <- colnames(d)
>> d <- c(list(rownames(d)), lapply(1:ncol(d), function(i)
>> as.numeric(d[,i])))
>> names(d) <- c('ID', names)
>> d
>>
>> # second option
>> d <- with(skdat, table(ID, lettertag))
>> res <- c(list(rownames(d)), sapply(apply(d, 2, list), "[", 1))
>> names(res)[1] <- "ID"
>> res
>>
>> HTH,
>> Jorge.-
>>
>>
>>
>> On Fri, Aug 15, 2014 at 7:19 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
>>
>> > On Thu, 14 Aug 2014 06:08:51 PM Sohail Khan wrote:
>> > > Hi
>> > > I have data set as follows:
>> > >   A 92315  A 35018  A 56710  B 52700  B 92315  B 15135  C 35018  C
>> > 52700
>> > > I would like to transform this data set into:
>> > >   ID 92315 35018 56710 52700 15135  A 1 1 1 0 0  B 1 0 0 1 1  C 0 1 0
>> > 1 0
>> > > I looked into reshape package to no avail.
>> > > I would appreciate any suggestions.
>> > >
>> > > -Sohail
>> > >
>> > Hi Sohail,
>> > You are doing a bit more than reshaping. This may get you there:
>> >
>> > skdat<-read.table(text="A 92315
>> > A 35018
>> > A 56710
>> > B 52700
>> > B 92315
>> > B 15135
>> > C 35018
>> > C 52700",stringsAsFactors=FALSE)
>> > names(skdat)<-c("lettertag","ID")
>> > ID<-unique(skdat$ID)
>> > lettertags<-unique(skdat$lettertag)
>> > newskdat<-list(ID)
>> > for(i in 1:length(lettertags))
>> >  newskdat[[i+1]]<-
>> >   as.numeric(ID %in% skdat$ID[skdat$lettertag==lettertags[i]])
>> > names(newskdat)<-c("ID",lettertags)
>> >
>> > I'm assuming that you don't really want your answer as a single string.
>> >
>> > Jim
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jwiley.psych at gmail.com  Fri Aug 15 15:29:35 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 15 Aug 2014 23:29:35 +1000
Subject: [R] A basic statistics question
In-Reply-To: <53EA8A20.5070500@auckland.ac.nz>
References: <1407873449.69033.YahooMailNeo@web190501.mail.sg3.yahoo.com>
	<53EA8A20.5070500@auckland.ac.nz>
Message-ID: <CANz9Z_+P8fnfKBskqu2bXPa-LKRpX_2PLeXNBduy_M6MVU2=GQ@mail.gmail.com>

On Wed, Aug 13, 2014 at 7:41 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 13/08/14 07:57, Ron Michael wrote:
>
>> Hi,
>>
>> I would need to get a clarification on a quite fundamental statistics
>> property, hope expeRts here would not mind if I post that here.
>>
>> I leant that variance-covariance matrix of the standardized data is equal
>> to the correlation matrix for the unstandardized data. So I used following
>> data.
>>
>
> <SNIP>
>
>
>  (t(Data_Normalized) %*% Data_Normalized)/dim(Data_Normalized)[1]
>>
>>
>>
>> Point is that I am not getting exact CORR matrix. Can somebody point me
>> what I am missing here?
>>
>
> You are using a denominator of "n" in calculating your "covariance" matrix
> for your normalized data.  But these data were normalized using the sd()
> function which (correctly) uses a denominator of n-1 so as to obtain an
> unbiased estimator of the population standard deviation.
>

As a small point n - 1 is not _quite_ an unbiased estimator of the
population SD see Cureton. (1968).
Unbiased Estimation of the Standard Deviation, The American Statistician,
22(1).

To see this in action:

res <- unlist(parLapply(cl, 1:1e7, function(i) sd(rnorm(10, mean = 0, sd =
1))))
correction <- function(n) {
    gamma((n-1)/2) * sqrt((n-1)/2) / gamma(n/2)
}
mean(res)
# 0.972583
mean(res * correction(10))
# 0.9999216

The calculation for sample variance is an unbiased estimate of the
population variance, but square root is a nonlinear function and the square
root of an unbiased estimator is not itself necessarily unbiased.




>
> If you calculated
>
>
>    (t(Data_Normalized) %*% Data_Normalized)/(dim(Data_Normalized)[1]-1)
>
> then you would get the same result as you get from cor(Data) (to within
> about 1e-15).
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From rni.boh at gmail.com  Fri Aug 15 16:51:37 2014
From: rni.boh at gmail.com (Bob O'Hara)
Date: Fri, 15 Aug 2014 16:51:37 +0200
Subject: [R] Generating a polygon around points
Message-ID: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>

I've been struggling for half a day on what should be a simple problem...

I have a data frame of lat/long coordinates that describe a region, and I
want to draw a polygon around them so I can use that as a boundary (to be
thrown at INLA, but those details aren't important). The coordinates are
almost on a regular grid: there is some variation in latitude (because
we're on a globe).

If the coordinates were on a regular grid, I could use as.owin() to create
a mask, and go on from there (I have code that will work). But as.owin()
doesn't like unevenly spaced points.

Can anyone suggest a way to sort this out? Preferable without having to
mess around transforming the coordinates.

Bob

-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Aug 15 17:07:28 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 15 Aug 2014 15:07:28 +0000
Subject: [R] Obtaining predicted values for glm() function
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9096E@mb02.ads.tamu.edu>

You don't show us your function call, so it is hard to be certain what the problem is. Have you read the manual page? 

?predict.glm

Have you used the newdata= argument? If not, you should know that R's ability to read your mind will not be available until the 4.0 release.


David Carlson

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of DHIMAN BHADRA
Sent: Friday, August 15, 2014 4:28 AM
To: Jeff Newmiller
Cc: r-help at r-project.org
Subject: Re: [R] Obtaining predicted values for glm() function

Thanks Jeff for the suggestion - will explore the predict function. So far
I was working on the fitted() function but it seems to generate fitted
(response) values only for predictor values in the original data set, not
for values beyond that.

I never intended to spam the mailing list. I re-posted only when I did not
find my original post in my inbox, which led to think that my query has not
reached the R-family.

Thanks again for your suggestion,
Dhiman


On Fri, Aug 15, 2014 at 11:52 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Please don't repeat post. In fact, you should definitely read the Posting
> Guide mentioned at the bottom if this or any other post from the list and
> follow its advice.
>
> The usual way to predict output of a model in R is to use the predict
> function appropriate to your model object class. You might find reading the
> help file ?predict.glm helpful. If not, then you might be needing to study
> some more basic use cases of R so you can interpret the help files.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 14, 2014 10:54:17 PM PDT, DHIMAN BHADRA <dhimanbhadra at gmail.com>
> wrote:
> >Dear all.
> >
> >I am trying to relate daily deaths in a given city with air pollution
> >values. The model I am using is as follows:
> >
> >model <- glm(deaths ~ pollution + ns(time, 13) + ns(temp, 7) + ns(rh,
> >5) +
> >dow + holiday, family=quasipoisson, data=city)
> >
> >Where -
> >deaths: daily number of deaths
> >pollution: daily measured levels of air pollution
> >ns(time, 13): smooth function (i.e. cubic spline) of time with 13
> >degrees
> >of freedom
> >ns(temp, 7): smooth function (i.e. cubic spline) of temperature with 7
> >degrees of freedom
> >ns(rh, 5): smooth function (i.e. cubic spline) of humidity with 5
> >degrees
> >of freedom
> >dow: day of the week
> >holiday: dummy variable to indicate public holidays
> >
> >Having run this model, how do I obtain predicted values of deaths for
> >any
> >given set of pollution values? Any suggestions will be much
> >appreciated.
> >
> >Thanks in advance,
> >Dhiman Bhadra
> >Assistant professor.
> >IIM Ahmedabad.
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Aug 15 17:15:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 15 Aug 2014 08:15:01 -0700
Subject: [R] Generating a polygon around points
In-Reply-To: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
Message-ID: <7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>

Not really sure I understand your constraints, but perhaps

RSiteSearch("convex hull ")

might help?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 15, 2014 7:51:37 AM PDT, Bob O'Hara <rni.boh at gmail.com> wrote:
>I've been struggling for half a day on what should be a simple
>problem...
>
>I have a data frame of lat/long coordinates that describe a region, and
>I
>want to draw a polygon around them so I can use that as a boundary (to
>be
>thrown at INLA, but those details aren't important). The coordinates
>are
>almost on a regular grid: there is some variation in latitude (because
>we're on a globe).
>
>If the coordinates were on a regular grid, I could use as.owin() to
>create
>a mask, and go on from there (I have code that will work). But
>as.owin()
>doesn't like unevenly spaced points.
>
>Can anyone suggest a way to sort this out? Preferable without having to
>mess around transforming the coordinates.
>
>Bob


From rni.boh at gmail.com  Fri Aug 15 17:22:55 2014
From: rni.boh at gmail.com (Bob O'Hara)
Date: Fri, 15 Aug 2014 17:22:55 +0200
Subject: [R] Generating a polygon around points
In-Reply-To: <7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>
Message-ID: <CAN-Z0xV2RDKU8-rcP_Ko_=n6RjSq=sBf3TJT2mhn8sVEP_Xmkw@mail.gmail.com>

Unfortunately my region isn't convex, and I don't want to end up predicting
the distribution of a forest-dwelling bird in the Atlantic ocean...

Bob


On 15 August 2014 17:15, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Not really sure I understand your constraints, but perhaps
>
> RSiteSearch("convex hull ")
>
> might help?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 15, 2014 7:51:37 AM PDT, Bob O'Hara <rni.boh at gmail.com> wrote:
> >I've been struggling for half a day on what should be a simple
> >problem...
> >
> >I have a data frame of lat/long coordinates that describe a region, and
> >I
> >want to draw a polygon around them so I can use that as a boundary (to
> >be
> >thrown at INLA, but those details aren't important). The coordinates
> >are
> >almost on a regular grid: there is some variation in latitude (because
> >we're on a globe).
> >
> >If the coordinates were on a regular grid, I could use as.owin() to
> >create
> >a mask, and go on from there (I have code that will work). But
> >as.owin()
> >doesn't like unevenly spaced points.
> >
> >Can anyone suggest a way to sort this out? Preferable without having to
> >mess around transforming the coordinates.
> >
> >Bob
>
>


-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Fri Aug 15 17:25:42 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 15 Aug 2014 08:25:42 -0700
Subject: [R] Generating a polygon around points
In-Reply-To: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1408150822570.5860@aeolus.ecy.wa.gov>

Your question seems to need an answer to, "How do you find a convex hull 
on a sphere?"  Google has many references.

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 15 Aug 2014, Bob O'Hara wrote:

> I've been struggling for half a day on what should be a simple problem...
>
> I have a data frame of lat/long coordinates that describe a region, and I
> want to draw a polygon around them so I can use that as a boundary (to be
> thrown at INLA, but those details aren't important). The coordinates are
> almost on a regular grid: there is some variation in latitude (because
> we're on a globe).
>
> If the coordinates were on a regular grid, I could use as.owin() to create
> a mask, and go on from there (I have code that will work). But as.owin()
> doesn't like unevenly spaced points.
>
> Can anyone suggest a way to sort this out? Preferable without having to
> mess around transforming the coordinates.
>
> Bob
>
> -- 
> Bob O'Hara
>
> Biodiversity and Climate Research Centre
> Senckenberganlage 25
> D-60325 Frankfurt am Main,
> Germany
>
> Tel: +49 69 798 40226
> Mobile: +49 1515 888 5440
> WWW:   http://www.bik-f.de/root/index.php?page_id=219
> Blog: http://occamstypewriter.org/boboh/
> Journal of Negative Results - EEB: www.jnr-eeb.org
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Fri Aug 15 17:55:40 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Aug 2014 08:55:40 -0700
Subject: [R] Generating a polygon around points
In-Reply-To: <7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>
Message-ID: <A0F07872-CFC5-49B4-8EA9-905ED24414AD@comcast.net>


On Aug 15, 2014, at 8:15 AM, Jeff Newmiller wrote:

> Not really sure I understand your constraints, but perhaps
> 
> RSiteSearch("convex hull ")

RSiteSearch has really been broken for some time now. (You get the headers but the links are all broken. A more effective way of searching the existing CRAN package base (but I think r-forge and github will be missed) is:

install.packages("sos")
library(sos)
findFn("convex hull ")

I use Markmail to search the archives, but one can also use Gmane or Rseek.org. 

Both markmail and gmane have the defect that copied code comes to my console or editor without line-ends. If anyone has a hint on how to avoid that annoyance, I'll be in your debt.

http://markmail.org/search/?q=list%3Aorg.r-project.r-help

-- 
David
> 
> might help?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On August 15, 2014 7:51:37 AM PDT, Bob O'Hara <rni.boh at gmail.com> wrote:
>> I've been struggling for half a day on what should be a simple
>> problem...
>> 
>> I have a data frame of lat/long coordinates that describe a region, and
>> I
>> want to draw a polygon around them so I can use that as a boundary (to
>> be
>> thrown at INLA, but those details aren't important). The coordinates
>> are
>> almost on a regular grid: there is some variation in latitude (because
>> we're on a globe).
>> 
>> If the coordinates were on a regular grid, I could use as.owin() to
>> create
>> a mask, and go on from there (I have code that will work). But
>> as.owin()
>> doesn't like unevenly spaced points.
>> 
>> Can anyone suggest a way to sort this out? Preferable without having to
>> mess around transforming the coordinates.
>> 
>> Bob
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Fri Aug 15 17:58:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 15 Aug 2014 08:58:16 -0700
Subject: [R] Generating a polygon around points
In-Reply-To: <CAN-Z0xV2RDKU8-rcP_Ko_=n6RjSq=sBf3TJT2mhn8sVEP_Xmkw@mail.gmail.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>
	<CAN-Z0xV2RDKU8-rcP_Ko_=n6RjSq=sBf3TJT2mhn8sVEP_Xmkw@mail.gmail.com>
Message-ID: <c2958d7d-7cbb-4bb8-b575-ddbcc67b5449@email.android.com>

No wonder I didn't understand your constraints... you didn't state them. In fact, I think you still haven't stated them. Perhaps you need a map outline? Or, you could just create a polygon manually? Isocline of a two-D kernel density estimate or kriging fit? Manually partition your data into regions which are convex? There might be precedents in the literature on your topic. Appropriate selection of of algorithms is not really on topic here, though.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 15, 2014 8:22:55 AM PDT, Bob O'Hara <rni.boh at gmail.com> wrote:
>Unfortunately my region isn't convex, and I don't want to end up
>predicting
>the distribution of a forest-dwelling bird in the Atlantic ocean...
>
>Bob
>
>
>On 15 August 2014 17:15, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Not really sure I understand your constraints, but perhaps
>>
>> RSiteSearch("convex hull ")
>>
>> might help?
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On August 15, 2014 7:51:37 AM PDT, Bob O'Hara <rni.boh at gmail.com>
>wrote:
>> >I've been struggling for half a day on what should be a simple
>> >problem...
>> >
>> >I have a data frame of lat/long coordinates that describe a region,
>and
>> >I
>> >want to draw a polygon around them so I can use that as a boundary
>(to
>> >be
>> >thrown at INLA, but those details aren't important). The coordinates
>> >are
>> >almost on a regular grid: there is some variation in latitude
>(because
>> >we're on a globe).
>> >
>> >If the coordinates were on a regular grid, I could use as.owin() to
>> >create
>> >a mask, and go on from there (I have code that will work). But
>> >as.owin()
>> >doesn't like unevenly spaced points.
>> >
>> >Can anyone suggest a way to sort this out? Preferable without having
>to
>> >mess around transforming the coordinates.
>> >
>> >Bob
>>
>>


From sohail13 at gmail.com  Fri Aug 15 18:06:51 2014
From: sohail13 at gmail.com (=?utf-8?B?c29oYWlsMTNAZ21haWwuY29t?=)
Date: Fri, 15 Aug 2014 09:06:51 -0700 (PDT)
Subject: [R] reshape a dataset
Message-ID: <000f4242.64782c6072778aff@gmail.com>

Great! Thanks

Sent from my LG G Flex, an AT&T 4G LTE smartphone


------ Original message------
From: Jorge I Velez
Date: Fri, Aug 15, 2014 8:54 AM
To: Sohail Khan;
Cc: Jim Lemon;R Help;
Subject:Re: [R] reshape a dataset

If that's the case, you could do the following:

d <- with(skdat, table(ID, lettertag))
d <- data.frame(cbind(ID = rownames(d), d))
rownames(d) <- NULL
d

HTH,
Jorge.-




On Fri, Aug 15, 2014 at 8:22 PM, Sohail Khan <sohail13 at gmail.com> wrote:
Thanks Jim and Jorge,
Clever solutions, the final output is a list.
How do I covert it back a dataframe?
-Sohail


On Fri, Aug 15, 2014 at 5:37 AM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
Dear Sohail,

Using Jim's data set skdat, two more options would be

# first option
d <- with(skdat, table(ID, lettertag))
names <- colnames(d)
d <- c(list(rownames(d)), lapply(1:ncol(d), function(i) as.numeric(d[,i])))
names(d) <- c('ID', names)
d

# second option
d <- with(skdat, table(ID, lettertag))
res <- c(list(rownames(d)), sapply(apply(d, 2, list), "[", 1))
names(res)[1] <- "ID"
res

HTH,
Jorge.-



On Fri, Aug 15, 2014 at 7:19 PM, Jim Lemon <jim at bitwrit.com.au> wrote:

> On Thu, 14 Aug 2014 06:08:51 PM Sohail Khan wrote:
> > Hi
> > I have data set as follows:
> >   A 92315  A 35018  A 56710  B 52700  B 92315  B 15135  C 35018  C
> 52700
> > I would like to transform this data set into:
> >   ID 92315 35018 56710 52700 15135  A 1 1 1 0 0  B 1 0 0 1 1  C 0 1 0
> 1 0
> > I looked into reshape package to no avail.
> > I would appreciate any suggestions.
> >
> > -Sohail
> >
> Hi Sohail,
> You are doing a bit more than reshaping. This may get you there:
>
> skdat<-read.table(text="A 92315
> A 35018
> A 56710
> B 52700
> B 92315
> B 15135
> C 35018
> C 52700",stringsAsFactors=FALSE)
> names(skdat)<-c("lettertag","ID")
> ID<-unique(skdat$ID)
> lettertags<-unique(skdat$lettertag)
> newskdat<-list(ID)
> for(i in 1:length(lettertags))
>  newskdat[[i+1]]<-
>   as.numeric(ID %in% skdat$ID[skdat$lettertag==lettertags[i]])
> names(newskdat)<-c("ID",lettertags)
>
> I'm assuming that you don't really want your answer as a single string.
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

        [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From tom at maladmin.com  Fri Aug 15 18:18:55 2014
From: tom at maladmin.com (Tom Wright)
Date: Fri, 15 Aug 2014 12:18:55 -0400
Subject: [R] regex pattern assistance
Message-ID: <1408119535.2063.16.camel@tom-laptop>

Hi,
Can anyone please assist.

given the string 

> x<-"/mnt/AO/AO Data/S01-012/120824/"

I would like to extract "S01-012"

require(stringr)
> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")

both nearly work. I expected I would use something like:
> str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")

but I don't seem able to get the square bracket grouping to work
correctly. Can someone please show me where I am going wrong?

Thanks,
Tom


From S.Ellison at LGCGroup.com  Fri Aug 15 18:36:57 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 15 Aug 2014 17:36:57 +0100
Subject: [R] regex pattern assistance
In-Reply-To: <1408119535.2063.16.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED60631C4DF8@GOLD.corp.lgc-group.com>



> -----Original Message-----
> > x<-"/mnt/AO/AO Data/S01-012/120824/"
> 
> I would like to extract "S01-012"


> gsub("/mnt/AO/AO Data/(.+)/.+", "\\1", x)

#does it, as does
> gsub("/mnt/AO/AO Data/([\\w-]+)/.+", "\\1", x, perl=TRUE)    # \w is perl RE; the default is POSIX, which would be. 
> gsub("/mnt/AO/AO Data/([[:alnum:]-]+)/.+", "\\1", x)  

#and
> str_match(x,"/mnt/AO/AO Data/(.+)/.+")
> str_match(x,"/mnt/AO/AO Data/([[:alnum:]-]+)/.+")   #again, needs POSIX, not perl RE

You had also, btw, missed the '.' in the closing '.+', meaning that your regex was looking for '/+', that is, multiple instances of '/'

Steve E



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From marc_schwartz at me.com  Fri Aug 15 18:41:42 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 15 Aug 2014 11:41:42 -0500
Subject: [R] regex pattern assistance
In-Reply-To: <1408119535.2063.16.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
Message-ID: <AFFA4A28-67EC-4008-955A-1477F1E479C5@me.com>

On Aug 15, 2014, at 11:18 AM, Tom Wright <tom at maladmin.com> wrote:

> Hi,
> Can anyone please assist.
> 
> given the string 
> 
>> x<-"/mnt/AO/AO Data/S01-012/120824/"
> 
> I would like to extract "S01-012"
> 
> require(stringr)
>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")
> 
> both nearly work. I expected I would use something like:
>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")
> 
> but I don't seem able to get the square bracket grouping to work
> correctly. Can someone please show me where I am going wrong?
> 
> Thanks,
> Tom


Is the desired substring always in the same relative position in the path?

If so:

> strsplit(x, "/")
[[1]]
[1] ""        "mnt"     "AO"      "AO Data" "S01-012" "120824" 

> unlist(strsplit(x, "/"))[5]
[1] "S01-012"



Alternatively, again, presuming the same position:

> gsub("/mnt/AO/AO Data/([^/]+)/.+", "\\1", x)
[1] "S01-012"


You don't need all of the double backslashes in your regex above. The '/' character is not a special regex character, whereas '\' is and needs to be escaped.

Regards,

Marc Schwartz


From ruipbarradas at sapo.pt  Fri Aug 15 18:47:57 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 15 Aug 2014 17:47:57 +0100
Subject: [R] regex pattern assistance
In-Reply-To: <1408119535.2063.16.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
Message-ID: <53EE39BD.8070306@sapo.pt>

Hello,

I don't believe you need an extra package for that. Try


sub("\\/mnt\\/AO\\/AO Data\\/([-[:alnum:]]*)\\/.+", "\\1", x)

or, with package stringr,

str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/.+")


Hope this helps,

Rui Barradas

Em 15-08-2014 17:18, Tom Wright escreveu:
> Hi,
> Can anyone please assist.
>
> given the string
>
>> x<-"/mnt/AO/AO Data/S01-012/120824/"
>
> I would like to extract "S01-012"
>
> require(stringr)
>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")
>
> both nearly work. I expected I would use something like:
>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")
>
> but I don't seem able to get the square bracket grouping to work
> correctly. Can someone please show me where I am going wrong?
>
> Thanks,
> Tom
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tom at maladmin.com  Fri Aug 15 18:56:21 2014
From: tom at maladmin.com (Tom Wright)
Date: Fri, 15 Aug 2014 12:56:21 -0400
Subject: [R] regex pattern assistance
In-Reply-To: <1408119535.2063.16.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
Message-ID: <1408121781.2063.25.camel@tom-laptop>

WOW!!!

What can I say 4 answers in less than 4 minutes. Thank you everyone. If
I can't make it work now I don't deserve to. 

btw. the strsplit approach wouldn't work for me as:
a) I wanted to play with regex and 
b) the location isn't consistent.

Nice to see email support still works, not everything has moved to
linkedin and stackoverflow.


Thanks again,
Tom


On Fri, 2014-08-15 at 12:18 -0400, Tom Wright wrote:
> Hi,
> Can anyone please assist.
> 
> given the string 
> 
> > x<-"/mnt/AO/AO Data/S01-012/120824/"
> 
> I would like to extract "S01-012"
> 
> require(stringr)
> > str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
> > str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")
> 
> both nearly work. I expected I would use something like:
> > str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")
> 
> but I don't seem able to get the square bracket grouping to work
> correctly. Can someone please show me where I am going wrong?
> 
> Thanks,
> Tom
>


From jdnewmil at dcn.davis.CA.us  Fri Aug 15 19:10:34 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 15 Aug 2014 10:10:34 -0700
Subject: [R] Generating a polygon around points
In-Reply-To: <A0F07872-CFC5-49B4-8EA9-905ED24414AD@comcast.net>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>
	<A0F07872-CFC5-49B4-8EA9-905ED24414AD@comcast.net>
Message-ID: <540ff24b-89b6-4943-9bff-6a88a3af8f0b@email.android.com>

I use RSiteSearch regularly with no problems. Perhaps I have just had a lucky streak? I wonder what the odds are... :-)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 15, 2014 8:55:40 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>On Aug 15, 2014, at 8:15 AM, Jeff Newmiller wrote:
>
>> Not really sure I understand your constraints, but perhaps
>> 
>> RSiteSearch("convex hull ")
>
>RSiteSearch has really been broken for some time now. (You get the
>headers but the links are all broken. A more effective way of searching
>the existing CRAN package base (but I think r-forge and github will be
>missed) is:
>
>install.packages("sos")
>library(sos)
>findFn("convex hull ")
>
>I use Markmail to search the archives, but one can also use Gmane or
>Rseek.org. 
>
>Both markmail and gmane have the defect that copied code comes to my
>console or editor without line-ends. If anyone has a hint on how to
>avoid that annoyance, I'll be in your debt.
>
>http://markmail.org/search/?q=list%3Aorg.r-project.r-help


From jdnewmil at dcn.davis.CA.us  Fri Aug 15 19:13:07 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 15 Aug 2014 10:13:07 -0700
Subject: [R] regex pattern assistance
In-Reply-To: <1408121781.2063.25.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
	<1408121781.2063.25.camel@tom-laptop>
Message-ID: <ba9cbfec-083d-4b75-9c0e-1bb93d5d11b8@email.android.com>

Must be another lucky streak. :-)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 15, 2014 9:56:21 AM PDT, Tom Wright <tom at maladmin.com> wrote:
>WOW!!!
>
>What can I say 4 answers in less than 4 minutes. Thank you everyone. If
>I can't make it work now I don't deserve to. 
>
>btw. the strsplit approach wouldn't work for me as:
>a) I wanted to play with regex and 
>b) the location isn't consistent.
>
>Nice to see email support still works, not everything has moved to
>linkedin and stackoverflow.
>
>
>Thanks again,
>Tom
>
>
>On Fri, 2014-08-15 at 12:18 -0400, Tom Wright wrote:
>> Hi,
>> Can anyone please assist.
>> 
>> given the string 
>> 
>> > x<-"/mnt/AO/AO Data/S01-012/120824/"
>> 
>> I would like to extract "S01-012"
>> 
>> require(stringr)
>> > str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
>> > str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")
>> 
>> both nearly work. I expected I would use something like:
>> > str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")
>> 
>> but I don't seem able to get the square bracket grouping to work
>> correctly. Can someone please show me where I am going wrong?
>> 
>> Thanks,
>> Tom
>>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Fri Aug 15 19:25:32 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 15 Aug 2014 12:25:32 -0500
Subject: [R] regex pattern assistance
In-Reply-To: <1408121781.2063.25.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
	<1408121781.2063.25.camel@tom-laptop>
Message-ID: <8C8B9846-AB34-4055-8AFC-E7A9CDF33743@me.com>


On Aug 15, 2014, at 11:56 AM, Tom Wright <tom at maladmin.com> wrote:

> WOW!!!
> 
> What can I say 4 answers in less than 4 minutes. Thank you everyone. If
> I can't make it work now I don't deserve to. 
> 
> btw. the strsplit approach wouldn't work for me as:
> a) I wanted to play with regex and 
> b) the location isn't consistent.


Tom,

If not in the same relative position, is the substring pattern always the same? That is 3 characters, a hyphen, then 3 characters? If so, would any other part of the path follow the same pattern or is it unique?

If the pattern is the same and is unique in the path:

> gsub(".*([[:alnum:]]{3}-[[:alnum:]]{3}).*", "\\1", x)
[1] "S01-012"


is another possible alternative and more flexible:

y <- "/mnt/AO/AO Data/Another Level/Yet Another Level/S01-012/120824/"

> gsub(".*([[:alnum:]]{3}-[[:alnum:]]{3}).*", "\\1", y)
[1] "S01-012"


z <- "/mnt/AO/AO Data/Another Level/Yet Another Level/S01-012/One More Level/120824/"

> gsub(".*([[:alnum:]]{3}-[[:alnum:]]{3}).*", "\\1", z)
[1] "S01-012"


> 
> Nice to see email support still works, not everything has moved to
> linkedin and stackoverflow.


Stackoverflow?  ;-)

Regards,

Marc


> 
> 
> Thanks again,
> Tom
> 
> 
> On Fri, 2014-08-15 at 12:18 -0400, Tom Wright wrote:
>> Hi,
>> Can anyone please assist.
>> 
>> given the string 
>> 
>>> x<-"/mnt/AO/AO Data/S01-012/120824/"
>> 
>> I would like to extract "S01-012"
>> 
>> require(stringr)
>>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
>>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")
>> 
>> both nearly work. I expected I would use something like:
>>> str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")
>> 
>> but I don't seem able to get the square bracket grouping to work
>> correctly. Can someone please show me where I am going wrong?
>> 
>> Thanks,
>> Tom


From macqueen1 at llnl.gov  Fri Aug 15 19:46:07 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 15 Aug 2014 17:46:07 +0000
Subject: [R] Operating on the value from row i and row i+1
In-Reply-To: <C0737CD3E51ABA43BE288766515C35DC1035371F@VANQUISH.hsc.net.ou.edu>
References: <C0737CD3E51ABA43BE288766515C35DC10353472@VANQUISH.hsc.net.ou.edu>
	<CACk-te3yWG7opPHoL5UGrT6Z5WqnHs5ywG1OoJ1DaUzvjx3YDg@mail.gmail.com>
	<C0737CD3E51ABA43BE288766515C35DC10353506@VANQUISH.hsc.net.ou.edu>
	<a91811a4-b78a-4fe9-bd45-c7aab3bf83f5@email.android.com>
	<D0126380.1078A7%macqueen1@llnl.gov>
	<C0737CD3E51ABA43BE288766515C35DC1035371F@VANQUISH.hsc.net.ou.edu>
Message-ID: <D0139403.107A21%macqueen1@llnl.gov>

Perhaps use approx() separately for each patient.

But your new example, with times 1, 2, 6, 8 does not match your first
example with times 0, 3, 9. Nor had you mentioned having multiple patients
before. So it is difficult to understand what you are really asking for.

None the less, approx() does reproduce the results you described in your
first description of the problem, so if your first example was meant to
represent one patient, then perhaps using approx() separately for each
patient will do the job.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/14/14, 3:14 PM, "Jaiprasart, Pharavee (HSC)"
<pharavee-jaiprasart at ouhsc.edu> wrote:

>Hi Don.
>
>The reason I want to do this is that I have the recorded infusion rate of
>time 1, 2, 6, 8 but I have the recorded response of time 1.5, 3, 4, 12.
>Notice that the time does not match between the two. Ultimately I want to
>plot Response VS Infusion Rate. If I just use xyplot between the two
>column, I'll just get a blank.
>
>The approx() function cannot do what I want. The problem is that the data
>frame has data from different patients, with different patients have
>different response (y) when given the drug at the same infusion rate (x).
>If I use approx() then all the patients with the same x will return the
>same y. Do you have any other suggestions?
>
>Thanks!
>Pharavee
>
>
>
>-----Original Message-----
>From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
>Sent: Thursday, August 14, 2014 3:06 PM
>To: Jaiprasart, Pharavee (HSC)
>Cc: r-help at r-project.org; Jeff Newmiller; Bert Gunter
>Subject: Re: [R] Operating on the value from row i and row i+1
>
>You didn?t say why you want it to return 6 and 4 for times 4 and 12
>respectively, so I made an assumption. On that basis, try this example:
>
>
>mydf <- data.frame(time=c(0,3,9), resp=c(5,6,4))
>
>myint <- approx( mydf$time, mydf$resp, xout=c(6,12),
>                 method='constant', f=0, rule=2)
>
>It reproduces your two example desired results.
>
>print(myint)
>$x
>[1] 6 12
>$y
>[1] 6 4
>
>
>(aside)
>If my assumption is correct, this is an example of a case where a simple
>R-supplied function does the job and there?s no need to use anything else.
>Simple tools for simple jobs. The approx() function has been in R since
>the very beginning.
>
>
>--
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 8/14/14, 11:27 AM, "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us> wrote:
>
>>So for part one it seems you already have your answer.
>>
>>For part two you should look at time series types like "zoo", with
>>which you can merge NAs at the new times at which you want "interpolated"
>>answers and use the na.locf function to fill in values.
>>-----------------------------------------------------------------------
>>---
>>-
>>Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>/Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>-----------------------------------------------------------------------
>>---
>>-
>>Sent from my phone. Please excuse my brevity.
>>
>>On August 14, 2014 9:39:34 AM PDT, "Jaiprasart, Pharavee (HSC)"
>><pharavee-jaiprasart at ouhsc.edu> wrote:
>>>Hi Bert,
>>>
>>>I should have phrased my question differently.
>>>
>>>I actually want to do two things.
>>>
>>>First is to make a step plot. The "s"/"S" is a typo on my part.
>>>
>>>The second is to write a script that when I ask the program for
>>>Response of time == 4, I want it to return "6", or if I ask for
>>>response of time == 12, it will return "4", and so on.
>>>
>>>Pharavee
>>>
>>>
>>>-----Original Message-----
>>>From: Bert Gunter [mailto:gunter.berton at gene.com]
>>>Sent: Thursday, August 14, 2014 11:27 AM
>>>To: Jaiprasart, Pharavee (HSC)
>>>Cc: r-help at r-project.org
>>>Subject: Re: [R] Operating on the value from row i and row i+1
>>>
>>>Your query is a bit unclear, but I suspect
>>>
>>>?plot
>>>
>>>and a **careful read** about types "s" and "S" therein would address
>>>your problem.
>>>
>>>Cheers,
>>>Bert
>>>
>>>Bert Gunter
>>>Genentech Nonclinical Biostatistics
>>>(650) 467-7374
>>>
>>>"Data is not information. Information is not knowledge. And knowledge
>>>is certainly not wisdom."
>>>Clifford Stoll
>>>
>>>
>>>
>>>
>>>On Thu, Aug 14, 2014 at 8:07 AM, Jaiprasart, Pharavee (HSC)
>>><pharavee-jaiprasart at ouhsc.edu> wrote:
>>>> Hi all,
>>>>
>>>>
>>>>
>>>> I'd like to make a step plot of Time vs Response graph.
>>>>
>>>> This is the example of my data frame - the real data frame has more
>>>than a thousand rows.
>>>>
>>>>
>>>>
>>>> Time          Duration of infusion           Infusion Rate
>>>Response               Subtype
>>>>
>>>> 0                         3
>>>      2                         5                                     0
>>>>
>>>> 3                         6
>>>      3                         6                                     0
>>>>
>>>> 9                         6
>>>      4                         4                                     0
>>>>
>>>>
>>>>
>>>> I cannot just use type = c("s") for this because I also want to use
>>>the value of the in between time for further calculation too (If I ask
>>>the program for Response of time == 4, I want it to return "6").
>>>>
>>>>
>>>>
>>>> The way I think the script should work is that:
>>>>
>>>>
>>>>
>>>> For all rows that has subtype ==0, if time is between the value of
>>>row
>>>> /i/ and /i+1/ (e.g. row 1 and 2 which is 0-3), make a new column
>>>> "Dummy" and return the value of row /i/ from the Response column
>>>(e.g. 
>>>> 5 in this
>>>>
>>>> example) , and do these for all rows (e.g. any time between row 2
>>>> and
>>>
>>>> 3 which is 3-9, make a new column and return 6). Then I can say if
>>>> Time>0 (value in column1) and <3 (value from column 1+2), y = value
>>>in
>>>> Dummy
>>>>
>>>>
>>>>
>>>> Is there any way to do this in R?
>>>>
>>>>
>>>>
>>>> Thanks!
>>>>
>>>> Pharavee
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>>
>>>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>>>>
>>>n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>>>>
>>>spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0
>>>>
>>>k79BnWO1L%2FRUs%3D%0A&s=8d0ca7ccfe0e7c4bac733aa2e8fe9a7068ffcf501cb181
>>>> e4261e95efc1b0e31a PLEASE do read the posting guide
>>>>
>>>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>>>>
>>>sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>>>>
>>>pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=wxyqWjigDlACZVtOk8tgsAt8iaUOs0k
>>>>
>>>79BnWO1L%2FRUs%3D%0A&s=7ca8e5a21aa512fa8bc5669fb6f4ea587d530d4a20146fd
>>>> 526148d17a3d198bc and provide commented, minimal, self-contained,
>>>> reproducible code.
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailma
>>>n/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxns
>>>spJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7v
>>>lfodRikcrIpl0UQ%3D%0A&s=67e8bf2791e73de4b63127d329bb86d4c97dbba4a03e97
>>>4b239131baea91d77a
>>>PLEASE do read the posting guide
>>>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/po
>>>sting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnss
>>>pJiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7vl
>>>fodRikcrIpl0UQ%3D%0A&s=2bd5a814cb6e6636a0486fe20551fc29d7087799a5944aa
>>>65c458edf76daea25 and provide commented, minimal, self-contained,
>>>reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://urldefense.proofpoint.com/v1/url?u=https://stat.ethz.ch/mailman
>>/listinfo/r-help&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnssp
>>JiRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7vlfo
>>dRikcrIpl0UQ%3D%0A&s=67e8bf2791e73de4b63127d329bb86d4c97dbba4a03e974b23
>>9131baea91d77a
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v1/url?u=http://www.r-project.org/pos
>>ting-guide.html&k=7DHVT22D9IhC0F3WohFMBA%3D%3D%0A&r=s1Xjgqw9bK2MQxnsspJ
>>iRNsjZKIq%2B8%2Fhu084PPVY11o%3D%0A&m=KapsT69UNIvTgB7cU%2FzF9qjl0u7vlfod
>>RikcrIpl0UQ%3D%0A&s=2bd5a814cb6e6636a0486fe20551fc29d7087799a5944aa65c4
>>58edf76daea25 and provide commented, minimal, self-contained,
>>reproducible code.
>


From macqueen1 at llnl.gov  Fri Aug 15 20:04:46 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 15 Aug 2014 18:04:46 +0000
Subject: [R] Generating a polygon around points
In-Reply-To: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
Message-ID: <D01396A5.107A32%macqueen1@llnl.gov>

I have been using a process like the following to create polygons that
(closely) surround a non-convex set of points.

  buf1 <- gBuffer(tmpb.ne, width=bstart, byid=TRUE)
  buf2 <- gUnaryUnion(buf1)
  buf <-  gBuffer(buf2, width=bshrink)

These functions are from the rgeos package. In my case, tmpb.ne is a
SpatialPointsDataFrame (sp package) whose coordinates slot has the
coordinates of interest. You would have to tinker with the values for the
two width arguments.


The first gBuffer() puts a buffer (a circle) around each individual point.

The gUnaryUnion() joins those circles into one or more polygons, depending
on how they overlap.

The second gBuffer() shrinks the polygons to make the polygon(s) surround
the points more closely.


It will even respect holes, for example if all your points are on land,
but there?s a lake in the middle somewhere.

I use it with projected coordinates, and the width parameters are in the
same units as the projection. I have never tried it with lat/long.

R-sig-geo would be a good place to follow-up. I think that was where I
found the above solution (I didn?t figure out by myself!)


-Don



-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/15/14, 7:51 AM, "Bob O'Hara" <rni.boh at gmail.com> wrote:

>I've been struggling for half a day on what should be a simple problem...
>
>I have a data frame of lat/long coordinates that describe a region, and I
>want to draw a polygon around them so I can use that as a boundary (to be
>thrown at INLA, but those details aren't important). The coordinates are
>almost on a regular grid: there is some variation in latitude (because
>we're on a globe).
>
>If the coordinates were on a regular grid, I could use as.owin() to create
>a mask, and go on from there (I have code that will work). But as.owin()
>doesn't like unevenly spaced points.
>
>Can anyone suggest a way to sort this out? Preferable without having to
>mess around transforming the coordinates.
>
>Bob
>
>-- 
>Bob O'Hara
>
>Biodiversity and Climate Research Centre
>Senckenberganlage 25
>D-60325 Frankfurt am Main,
>Germany
>
>Tel: +49 69 798 40226
>Mobile: +49 1515 888 5440
>WWW:   http://www.bik-f.de/root/index.php?page_id=219
>Blog: http://occamstypewriter.org/boboh/
>Journal of Negative Results - EEB: www.jnr-eeb.org
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lotte.devries2 at student.uva.nl  Fri Aug 15 17:06:36 2014
From: lotte.devries2 at student.uva.nl (Charlotte de Vries)
Date: Fri, 15 Aug 2014 15:06:36 +0000
Subject: [R] unable to use functions require DLL from package
References: <17086783.post@talk.nabble.com>
	<alpine.LFD.1.10.0805062222200.3080@auk.stats.ox.ac.uk>
	<17101073.post@talk.nabble.com>
Message-ID: <loom.20140815T170558-587@post.gmane.org>

Hey there!

I'm having problems with the same code, but I get a different error: 

Error in .C("spline_coef", method = as.integer(method), n = n, x = 
as.double(x),  : 
  "spline_coef" not available for .C() for package "stats"


I'm using R3.1.0 on windows 8 and I've never used R before, so I might have 
made some terrible newby error (I have programmed quite a bit before, but in C 
and Matlab). 

Thank you!

Best, 
Lotte


From tianwenlan at gmail.com  Fri Aug 15 16:36:40 2014
From: tianwenlan at gmail.com (Wenlan Tian)
Date: Fri, 15 Aug 2014 10:36:40 -0400
Subject: [R] how to avoid change string to number automaticlly in r
Message-ID: <CAFkuWq41M35h-7mO3RLd4FLb_=LC_vhZBPKA6m9rjW+_YK_Ksg@mail.gmail.com>

I was trying to save some string into a matrix, but it automatically
changed to numbers (levels). How can i avoid it??

Here is the original table:

  trt    means  M1 0   12.16673  a2 111 11.86369 ab3 125 11.74433 ab4
14  11.54073  b

I wanna to save to a matrix like:
J0001 a ab ab b

But, what i get is:
J0001 1 2 2 3

How can i avoid this?

	[[alternative HTML version deleted]]


From valentina.lauria at plymouth.ac.uk  Fri Aug 15 17:15:28 2014
From: valentina.lauria at plymouth.ac.uk (Valentina Lauria)
Date: Fri, 15 Aug 2014 15:15:28 +0000
Subject: [R] NA error with the dredge function
Message-ID: <5D38408CEC987343BA4DEA61AD7C8B8846E0E6@TIS101.uopnet.plymouth.ac.uk>

Dear members,

I am experiencing a strange error using the dredge function of the package MuMIn. I am not sure what is happening here as this script worked in the past and I have no idea about this new error, I do not have any NA in my data.

> full_m<- gam(nep~ s(depth, k=4) + s(sed, k=4) + s(slope, k=4) + s(vrm, k=4), family=gaussian, gamma=1.4, data = datafit_aran1)
> dredge(full_m)

Error in dredge(full_m) :
  'global.model''s 'na.action' argument is not set and options('na.action') is "na.omit"

Can anyone help me?

Thank you very much in advance,
Valentina
















________________________________
[http://www.plymouth.ac.uk/images/email_footer.gif]<http://www.plymouth.ac.uk/worldclass>

This email and any files with it are confidential and intended solely for the use of the recipient to whom it is addressed. If you are not the intended recipient then copying, distribution or other use of the information contained is strictly prohibited and you should not rely on it. If you have received this email in error please let the sender know immediately and delete it from your system(s). Internet emails are not necessarily secure. While we take every care, Plymouth University accepts no responsibility for viruses and it is your responsibility to scan emails and their attachments. Plymouth University does not accept responsibility for any changes made after it was sent. Nothing in this email or its attachments constitutes an order for goods or services unless accompanied by an official order form.


From tsjerkw at gmail.com  Fri Aug 15 17:31:45 2014
From: tsjerkw at gmail.com (Tsjerk Wassenaar)
Date: Fri, 15 Aug 2014 17:31:45 +0200
Subject: [R] Generating a polygon around points
In-Reply-To: <alpine.LRH.2.11.1408150822570.5860@aeolus.ecy.wa.gov>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
	<alpine.LRH.2.11.1408150822570.5860@aeolus.ecy.wa.gov>
Message-ID: <CABzE1SjdxDGQAG1wB9u9to4jNOQC=Lv1A7eEDuzejd5zzFj0Jg@mail.gmail.com>

Hi Bob,

You probably want to have a look at the package alphahull.

Cheers,

Tsjerk


On Fri, Aug 15, 2014 at 5:25 PM, Clint Bowman <clint at ecy.wa.gov> wrote:

> Your question seems to need an answer to, "How do you find a convex hull
> on a sphere?"  Google has many references.
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
>
> On Fri, 15 Aug 2014, Bob O'Hara wrote:
>
>  I've been struggling for half a day on what should be a simple problem...
>>
>> I have a data frame of lat/long coordinates that describe a region, and I
>> want to draw a polygon around them so I can use that as a boundary (to be
>> thrown at INLA, but those details aren't important). The coordinates are
>> almost on a regular grid: there is some variation in latitude (because
>> we're on a globe).
>>
>> If the coordinates were on a regular grid, I could use as.owin() to create
>> a mask, and go on from there (I have code that will work). But as.owin()
>> doesn't like unevenly spaced points.
>>
>> Can anyone suggest a way to sort this out? Preferable without having to
>> mess around transforming the coordinates.
>>
>> Bob
>>
>> --
>> Bob O'Hara
>>
>> Biodiversity and Climate Research Centre
>> Senckenberganlage 25
>> D-60325 Frankfurt am Main,
>> Germany
>>
>> Tel: +49 69 798 40226
>> Mobile: +49 1515 888 5440
>> WWW:   http://www.bik-f.de/root/index.php?page_id=219
>> Blog: http://occamstypewriter.org/boboh/
>> Journal of Negative Results - EEB: www.jnr-eeb.org
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Tsjerk A. Wassenaar, Ph.D.

	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Fri Aug 15 20:27:27 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 15 Aug 2014 11:27:27 -0700
Subject: [R] how to avoid change string to number automaticlly in r
In-Reply-To: <CAFkuWq41M35h-7mO3RLd4FLb_=LC_vhZBPKA6m9rjW+_YK_Ksg@mail.gmail.com>
References: <CAFkuWq41M35h-7mO3RLd4FLb_=LC_vhZBPKA6m9rjW+_YK_Ksg@mail.gmail.com>
Message-ID: <1408127247.34349.YahooMailNeo@web142606.mail.bf1.yahoo.com>

A similar post was found in stackoverflow (http://stackoverflow.com/questions/25328311/how-to-avoid-change-string-to-number-automaticlly-in-r), which already got an accepted reply.

A.K.




On Friday, August 15, 2014 2:18 PM, Wenlan Tian <tianwenlan at gmail.com> wrote:
I was trying to save some string into a matrix, but it automatically
changed to numbers (levels). How can i avoid it??

Here is the original table:

? trt? ? means? M1 0?  12.16673? a2 111 11.86369 ab3 125 11.74433 ab4
14? 11.54073? b

I wanna to save to a matrix like:
J0001 a ab ab b

But, what i get is:
J0001 1 2 2 3

How can i avoid this?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Aug 15 20:37:23 2014
From: smartpink111 at yahoo.com (arun)
Date: Fri, 15 Aug 2014 11:37:23 -0700
Subject: [R] regex pattern assistance
In-Reply-To: <1408119535.2063.16.camel@tom-laptop>
References: <1408119535.2063.16.camel@tom-laptop>
Message-ID: <1408127843.57071.YahooMailNeo@web142601.mail.bf1.yahoo.com>



Hi Tom,
You could try:
library(stringr)
str_extract(x, perl("(?<=[A-Za-z]{4}/).*(?=/[0-9])"))
#[1] "S01-012"
A.K.



On Friday, August 15, 2014 12:20 PM, Tom Wright <tom at maladmin.com> wrote:
Hi,
Can anyone please assist.

given the string 

> x<-"/mnt/AO/AO Data/S01-012/120824/"

I would like to extract "S01-012"

require(stringr)
> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(.+)\\/+")
> str_match(x,"\\/mnt\\/AO\\/AO Data\\/(\\w+)\\/+")

both nearly work. I expected I would use something like:
> str_match(x,"\\/mnt\\/AO\\/AO Data\\/([\\w -]+)\\/+")

but I don't seem able to get the square bracket grouping to work
correctly. Can someone please show me where I am going wrong?

Thanks,
Tom

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug 15 20:54:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Aug 2014 11:54:23 -0700
Subject: [R] unable to use functions require DLL from package
In-Reply-To: <loom.20140815T170558-587@post.gmane.org>
References: <17086783.post@talk.nabble.com>
	<alpine.LFD.1.10.0805062222200.3080@auk.stats.ox.ac.uk>
	<17101073.post@talk.nabble.com>
	<loom.20140815T170558-587@post.gmane.org>
Message-ID: <E3BFBE59-5A60-4E83-AC25-9B3ED38E0A06@comcast.net>


On Aug 15, 2014, at 8:06 AM, Charlotte de Vries wrote:

> Hey there!
> 
> I'm having problems with the same code, but I get a different error: 

This is apparently yet another example demonstrating why the Posting Guide suggests that you include the text of any earlier posting to which you want us to consider. At the moment I see no posting that has this subject.

> 
> Error in .C("spline_coef", method = as.integer(method), n = n, x = 
> as.double(x),  : 
>  "spline_coef" not available for .C() for package "stats"
> 
> 
> I'm using R3.1.0 on windows 8 and I've never used R before, so I might have 
> made some terrible newby error (I have programmed quite a bit before, but in C 
> and Matlab). 
> 
> Thank you!
> 
> Best,

David Winsemius
Alameda, CA, USA


From sjkiss at gmail.com  Fri Aug 15 22:58:16 2014
From: sjkiss at gmail.com (Simon Kiss)
Date: Fri, 15 Aug 2014 16:58:16 -0400
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A
	Data	Frame
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
Message-ID: <696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>


Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
Have I explained this problem sufficiently? 
I didn't think it would cause such a problem so I didn't include it in the original problem definition.
Yours, Simon
On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
> 
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> + "green", "yellow")))))
>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>> colnames(mydf2) <- levels(mydf$rank1)
>> head(mydf)
>   rank1  rank2  rank3 rank4
> 1 yellow  green    red  blue
> 2  green   blue yellow   red
> 3  green yellow    red  blue
> 4 yellow    red  green  blue
> 5 yellow    red  green  blue
> 6 yellow    red   blue green
>> head(mydf2)
>  blue green red yellow
> 1    4     2   3      1
> 2    2     1   4      3
> 3    4     1   3      2
> 4    4     3   2      1
> 5    4     3   2      1
> 6    3     4   2      1
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
> Sent: Friday, July 25, 2014 2:34 PM
> To: r-help at r-project.org
> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> Hello:
> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
> 
> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
> Thank you
> Simon
> #Reproducible code
> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
> 
> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606


From r.turner at auckland.ac.nz  Fri Aug 15 23:49:31 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Aug 2014 09:49:31 +1200
Subject: [R] A basic statistics question
In-Reply-To: <CANz9Z_+P8fnfKBskqu2bXPa-LKRpX_2PLeXNBduy_M6MVU2=GQ@mail.gmail.com>
References: <1407873449.69033.YahooMailNeo@web190501.mail.sg3.yahoo.com>
	<53EA8A20.5070500@auckland.ac.nz>
	<CANz9Z_+P8fnfKBskqu2bXPa-LKRpX_2PLeXNBduy_M6MVU2=GQ@mail.gmail.com>
Message-ID: <53EE806B.6060805@auckland.ac.nz>

On 16/08/14 01:29, Joshua Wiley wrote:
>
> On Wed, Aug 13, 2014 at 7:41 AM, Rolf Turner <r.turner at auckland.ac.nz
> <mailto:r.turner at auckland.ac.nz>> wrote:
>
>     On 13/08/14 07:57, Ron Michael wrote:
>
>         Hi,
>
>         I would need to get a clarification on a quite fundamental
>         statistics property, hope expeRts here would not mind if I post
>         that here.
>
>         I leant that variance-covariance matrix of the standardized data
>         is equal to the correlation matrix for the unstandardized data.
>         So I used following data.
>
>
>     <SNIP>
>
>
>         (t(Data_Normalized) %*% Data_Normalized)/dim(Data___Normalized)[1]
>
>
>
>         Point is that I am not getting exact CORR matrix. Can somebody
>         point me what I am missing here?
>
>
>     You are using a denominator of "n" in calculating your "covariance"
>     matrix for your normalized data.  But these data were normalized
>     using the sd() function which (correctly) uses a denominator of n-1
>     so as to obtain an unbiased estimator of the population standard
>     deviation.
>
>
> As a small point n - 1 is not _quite_ an unbiased estimator of the
> population SD see Cureton. (1968).
> Unbiased Estimation of the Standard Deviation, The American
> Statistician, 22(1).
>
> To see this in action:
>
> res <- unlist(parLapply(cl, 1:1e7, function(i) sd(rnorm(10, mean = 0, sd
> = 1))))
> correction <- function(n) {
>      gamma((n-1)/2) * sqrt((n-1)/2) / gamma(n/2)
> }
> mean(res)
> # 0.972583
> mean(res * correction(10))
> # 0.9999216
>
> The calculation for sample variance is an unbiased estimate of the
> population variance, but square root is a nonlinear function and the
> square root of an unbiased estimator is not itself necessarily unbiased.


Aaaaarrrggghhh.  Yes of course.  I *know* that you don't get an unbiased 
estimate of the sd by using n-1 in the denominator; you get an unbiased 
estimate of the variance and as you say, sqrt() is a non-linear function 
.....

I just didn't think carefully enuff before I wrote.  Thanks for pulling 
me up on this error.

cheers,

Rolf


-- 
Rolf Turner
Technical Editor ANZJS


From r.turner at auckland.ac.nz  Sat Aug 16 00:06:41 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Aug 2014 10:06:41 +1200
Subject: [R] Generating a polygon around points
In-Reply-To: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
Message-ID: <53EE8471.2050205@auckland.ac.nz>

On 16/08/14 02:51, Bob O'Hara wrote:
> I've been struggling for half a day on what should be a simple problem...
>
> I have a data frame of lat/long coordinates that describe a region, and I
> want to draw a polygon around them so I can use that as a boundary (to be
> thrown at INLA, but those details aren't important). The coordinates are
> almost on a regular grid: there is some variation in latitude (because
> we're on a globe).
>
> If the coordinates were on a regular grid, I could use as.owin() to create
> a mask, and go on from there (I have code that will work). But as.owin()
> doesn't like unevenly spaced points.
>
> Can anyone suggest a way to sort this out? Preferable without having to
> mess around transforming the coordinates.

You need to be able to tell owin() the vertices of the polygon that you 
want to use as your window.  It is possible that alphahull, as someone 
suggested, might give what you want; I don't know, I am not familiar 
with this function.  OTOH R is still lacking a mind_read() function so 
it probably would NOT give you *exactly* what you want.

If you want to get "exactly the right polygon" you probably will have to 
select out the vertices of the polygon (in the appropriate order) in 
some "by hand" manner.  It's possible that clickpoly() might be of help 
to you.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From r.turner at auckland.ac.nz  Sat Aug 16 00:11:02 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Aug 2014 10:11:02 +1200
Subject: [R] Generating a polygon around points
In-Reply-To: <540ff24b-89b6-4943-9bff-6a88a3af8f0b@email.android.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>	<A0F07872-CFC5-49B4-8EA9-905ED24414AD@comcast.net>
	<540ff24b-89b6-4943-9bff-6a88a3af8f0b@email.android.com>
Message-ID: <53EE8576.4060707@auckland.ac.nz>

On 16/08/14 05:10, Jeff Newmiller wrote:
> I use RSiteSearch regularly with no problems. Perhaps I have just had
> a lucky streak? I wonder what the odds are... :-)


<SNIP>

> On August 15, 2014 8:55:40 AM PDT, David Winsemius
> <dwinsemius at comcast.net> wrote:
>>
>> On Aug 15, 2014, at 8:15 AM, Jeff Newmiller wrote:
>>
>>> Not really sure I understand your constraints, but perhaps
>>>
>>> RSiteSearch("convex hull ")
>>
>> RSiteSearch has really been broken for some time now. (You get the
>> headers but the links are all broken.

<SNIP>

I tried RSiteSearch("convex hull") just now, as an experiment, and it 
seemed to work just fine.  I think that the Universe is picking on Dave
(instead of on me, for once!). :-)

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS


From dwinsemius at comcast.net  Sat Aug 16 01:01:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Aug 2014 16:01:49 -0700
Subject: [R] Generating a polygon around points
In-Reply-To: <53EE8576.4060707@auckland.ac.nz>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>	<A0F07872-CFC5-49B4-8EA9-905ED24414AD@comcast.net>
	<540ff24b-89b6-4943-9bff-6a88a3af8f0b@email.android.com>
	<53EE8576.4060707@auckland.ac.nz>
Message-ID: <42FE8629-3993-490E-A58F-0C4FBFE46247@comcast.net>


On Aug 15, 2014, at 3:11 PM, Rolf Turner wrote:

> On 16/08/14 05:10, Jeff Newmiller wrote:
>> I use RSiteSearch regularly with no problems. Perhaps I have just had
>> a lucky streak? I wonder what the odds are... :-)
> 
> 
> <SNIP>
> 
>> On August 15, 2014 8:55:40 AM PDT, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>> 
>>> On Aug 15, 2014, at 8:15 AM, Jeff Newmiller wrote:
>>> 
>>>> Not really sure I understand your constraints, but perhaps
>>>> 
>>>> RSiteSearch("convex hull ")
>>> 
>>> RSiteSearch has really been broken for some time now. (You get the
>>> headers but the links are all broken.
> 
> <SNIP>
> 
> I tried RSiteSearch("convex hull") just now, as an experiment, and it seemed to work just fine.  I think that the Universe is picking on Dave
> (instead of on me, for once!). :-)

RSiteSearch("convex hull") does produce a page on my web-browser, but have you tried to follow links on the page? I got 404's about a third of the time , although admittedly I was earlier generalizing on the basis of 3 404's in a row. And I was further generalizing from earlier experience when support for searching the rhelp archive was abandoned.
 
-- 
David Winsemius
Alameda, CA, USA


From lotte.devries2 at student.uva.nl  Fri Aug 15 23:56:30 2014
From: lotte.devries2 at student.uva.nl (Charlotte de Vries)
Date: Fri, 15 Aug 2014 21:56:30 +0000
Subject: [R] unable to use functions require DLL from package
References: <17086783.post@talk.nabble.com>
	<alpine.LFD.1.10.0805062222200.3080@auk.stats.ox.ac.uk>
	<17101073.post@talk.nabble.com>
	<loom.20140815T170558-587@post.gmane.org>
	<E3BFBE59-5A60-4E83-AC25-9B3ED38E0A06@comcast.net>
Message-ID: <loom.20140815T234525-449@post.gmane.org>

David Winsemius <dwinsemius <at> comcast.net> writes:

> 
> 
> On Aug 15, 2014, at 8:06 AM, Charlotte de Vries wrote:
> 
> > Hey there!
> > 
> > I'm having problems with the same code, but I get a different error: 
> 
> This is apparently yet another example demonstrating why the Posting Guide 
suggests that you include the
> text of any earlier posting to which you want us to consider. At the 
moment I see no posting that has this subject.
> 
> > 
> > Error in .C("spline_coef", method = as.integer(method), n = n, x = 
> > as.double(x),  : 
> >  "spline_coef" not available for .C() for package "stats"
> > 
> > 
> > I'm using R3.1.0 on windows 8 and I've never used R before, so I might 
have 
> > made some terrible newby error (I have programmed quite a bit before, 
but in C 
> > and Matlab). 
> > 
> > Thank you!
> > 
> > Best,
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

Hi David, 

Thank you for answering. The original message I replied to was this message 
(http://comments.gmane.org/gmane.comp.lang.r.general/113245):

**********************************************
Hi all, 

I have issues using some basic functions in R such as these ones : 

> pp.test(R) (where is a vector of returns)
Error in .C("R_approx", as.double(x), as.double(y), as.integer(nx), xout =
as.double(xout),  : 
  C symbol name "R_approx" not in DLL for package "base"

>boxcox(reg,plotit=T)  (where reg is an lm object)
Error in .C("spline_coef", method = as.integer(method), n = as.integer(nx), 
: 
  C symbol name "spline_coef" not in DLL for package "base"

as I do miss some symbol names. 

How can I overcome this serious problem ? 
***********************************

But someone else reported a very similar problem (oddly enough using the 
same function spline_coef but this time from the package stats rather than 
base (http://comments.gmane.org/gmane.comp.lang.r.general/115420): 

************************************
Subject: Missing "spline_coef" DLL and Rob Hyndmans monotonic	interpolator

Hello R help

I have been trying to use Rob Hyndman's monotonically increasing spline
function.  But like another user or two seem have a problem with a
missing DLL (namely "spline_coef").  None of the previous help postings
seemed to have any solutions to this problem.  As per a Ripley
suggestion I have deleted all previous versions of R and reinstalled R
2.7.0 and the problem persists.

Thanks

Paul.

x <- seq(0,4,l=20) 

y <- sort(rnorm(20)) 

plot(x,y) 
lines(spline(x, y, n = 201), col = 2) # Not necessarily monotonic
lines(cm.spline(x, y, n = 201), col = 3)
>Error in .C("spline_coef", method = as.integer(method), n = nx, x = x,
: 
        C symbol name "spline_coef" not in DLL for package "stats"

Cm.spline code from
http://www-personal.buseco.monash.edu.au/~hyndman/Rlibrary/interpcode.R
**********************************

I hope that helps, thank you :)! I've tried calling spline_coef from both 
stats and base, but I get the same error for both packages. I've also tried 
the solution suggested to these people, which was to remove any other R 
versions on my laptop.

Best, 
Lotte


From dwinsemius at comcast.net  Sat Aug 16 03:24:01 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 15 Aug 2014 18:24:01 -0700
Subject: [R] unable to use functions require DLL from package
In-Reply-To: <loom.20140815T234525-449@post.gmane.org>
References: <17086783.post@talk.nabble.com>
	<alpine.LFD.1.10.0805062222200.3080@auk.stats.ox.ac.uk>
	<17101073.post@talk.nabble.com>
	<loom.20140815T170558-587@post.gmane.org>
	<E3BFBE59-5A60-4E83-AC25-9B3ED38E0A06@comcast.net>
	<loom.20140815T234525-449@post.gmane.org>
Message-ID: <C517A915-3A63-47AD-B30B-7A3F7FE32D8F@comcast.net>


On Aug 15, 2014, at 2:56 PM, Charlotte de Vries wrote:

> David Winsemius <dwinsemius <at> comcast.net> writes:
> 
>> 
>> 
>> On Aug 15, 2014, at 8:06 AM, Charlotte de Vries wrote:
>> 
>>> Hey there!
>>> 
>>> I'm having problems with the same code, but I get a different error: 
>> 
>> This is apparently yet another example demonstrating why the Posting Guide 
> suggests that you include the
>> text of any earlier posting to which you want us to consider. At the 
> moment I see no posting that has this subject.
>> 
>>> 
>>> Error in .C("spline_coef", method = as.integer(method), n = n, x = 
>>> as.double(x),  : 
>>> "spline_coef" not available for .C() for package "stats"
>>> 
>>> 
>>> I'm using R3.1.0 on windows 8 and I've never used R before, so I might 
> have 
>>> made some terrible newby error (I have programmed quite a bit before, 
> but in C 
>>> and Matlab). 
>>> 
>>> Thank you!
>>> 
>>> Best,
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
> 
> Hi David, 
> 
> Thank you for answering. The original message I replied to was this message 
> (http://comments.gmane.org/gmane.comp.lang.r.general/113245):
> 
> **********************************************

Well, that explains why I don't have a copy on my machine. It's dated 6 May 18:15 2008


> Hi all, 
> 
> I have issues using some basic functions in R such as these ones : 

pp.test is not a "basic R function". I get this:

> ?pp.test
No documentation for ?pp.test? in specified packages and libraries:
you could try ???pp.test?

You are asked to include the package name for non-base R functions.

> 
>> pp.test(R) (where is a vector of returns)
> Error in .C("R_approx", as.double(x), as.double(y), as.integer(nx), xout =
> as.double(xout),  : 
>  C symbol name "R_approx" not in DLL for package "base"
> 
>> boxcox(reg,plotit=T)  (where reg is an lm object)
> Error in .C("spline_coef", method = as.integer(method), n = as.integer(nx), 
> : 
>  C symbol name "spline_coef" not in DLL for package "base"

Well I do have the MASS package from which that function was loaded. 

I get no error with the example in the help page:

 boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
         lambda = seq(-0.05, 0.45, len = 20), plotit=TRUE)

... and you are not providing a reproducible example that provokes the error, nor are you providing the version numbers of R or MASS.


> 
> as I do miss some symbol names. 
> 
> How can I overcome this serious problem ? 
> ***********************************
> 
> But someone else reported a very similar problem (oddly enough using the 
> same function spline_coef but this time from the package stats rather than 
> base (http://comments.gmane.org/gmane.comp.lang.r.general/115420): 

Which was in turn dated: 2 Jun 06:04 2008


> ************************************
> Subject: Missing "spline_coef" DLL and Rob Hyndmans monotonic	interpolator
> 
> Hello R help
> 
> I have been trying to use Rob Hyndman's monotonically increasing spline
> function.  But like another user or two seem have a problem with a
> missing DLL (namely "spline_coef").  None of the previous help postings
> seemed to have any solutions to this problem.  As per a Ripley
> suggestion I have deleted all previous versions of R and reinstalled R
> 2.7.0 and the problem persists.
> 
> Thanks
> 
> Paul.
> 
> x <- seq(0,4,l=20) 
> 
> y <- sort(rnorm(20)) 
> 
> plot(x,y) 
> lines(spline(x, y, n = 201), col = 2) # Not necessarily monotonic
> lines(cm.spline(x, y, n = 201), col = 3)

I get no error after:

library(demography)

# And then running that code.

I have an almost up-to-date version of R running on a mac (and at the moment I have way too many packages loaded:

> sessionInfo()
R version 3.1.0 Patched (2014-04-21 r65431)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] grDevices datasets  splines   graphics  utils     stats    
[7] grid      methods   base     

other attached packages:
 [1] demography_1.17  ftsa_3.9         rainbow_3.2     
 [4] pcaPP_1.9-49     forecast_5.4     timeDate_3010.98
 [7] zoo_1.7-11       XML_3.98-1.1     RCurl_1.95-4.3  
[10] bitops_1.0-6     subplex_1.1-4    MASS_7.3-31     
[13] cobs_1.2-2       quantreg_5.05    gplots_2.13.0   
[16] reshape2_1.2.2   ggplot2_0.9.3.1  multcomp_1.3-1  
[19] TH.data_1.0-3    mvtnorm_0.9-9999 data.table_1.9.2
[22] muhaz_1.2.5      downloader_0.3   RJSONIO_1.3-0   
[25] plot3D_1.0-1     rms_4.2-0        SparseM_1.03    
[28] Hmisc_3.14-4     Formula_1.1-1    survival_2.37-7 
[31] sos_1.3-8        brew_1.0-6       lattice_0.20-29 

loaded via a namespace (and not attached):
 [1] caTools_1.16        cluster_1.15.2      colorspace_1.2-4   
 [4] descr_1.0.3         dichromat_2.0-0     digest_0.6.4       
 [7] fracdiff_1.4-2      gdata_2.13.3        gtable_0.1.2       
[10] gtools_3.4.0        hdrcde_3.1          KernSmooth_2.23-12 
[13] ks_1.9.1            labeling_0.2        latticeExtra_0.6-26
[16] Matrix_1.1-3        mgcv_1.7-29         misc3d_0.8-4       
[19] munsell_0.4.2       nlme_3.1-117        nnet_7.3-8         
[22] parallel_3.1.0      plyr_1.8.1          proto_0.3-10       
[25] quadprog_1.5-5      RColorBrewer_1.0-5  Rcpp_0.11.1        
[28] rgl_0.93.996        sandwich_2.3-0      scales_0.2.3       
[31] stringr_0.6.2       tools_3.1.0         tseries_0.10-32    
[34] xtable_1.7-3       


So that shows you how to provide some of the needed information (which neither of the postings to which you resonded had done.)  PLEASE read the Posting Guide.


>> Error in .C("spline_coef", method = as.integer(method), n = nx, x = x,
> : 
>        C symbol name "spline_coef" not in DLL for package "stats"
> 
> Cm.spline code from
> http://www-personal.buseco.monash.edu.au/~hyndman/Rlibrary/interpcode.R
> **********************************
> 
> I hope that helps, thank you :)! I've tried calling spline_coef from both 
> stats and base, but I get the same error for both packages. I've also tried 
> the solution suggested to these people, which was to remove any other R 
> versions on my laptop.
> 
> Best, 
> Lotte
> 
> 

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Sat Aug 16 05:17:06 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 16 Aug 2014 15:17:06 +1200
Subject: [R] Generating a polygon around points
In-Reply-To: <42FE8629-3993-490E-A58F-0C4FBFE46247@comcast.net>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>	<7bfcd4af-f256-4caa-a287-5f87938e5db4@email.android.com>	<A0F07872-CFC5-49B4-8EA9-905ED24414AD@comcast.net>
	<540ff24b-89b6-4943-9bff-6a88a3af8f0b@email.android.com>
	<53EE8576.4060707@auckland.ac.nz>
	<42FE8629-3993-490E-A58F-0C4FBFE46247@comcast.net>
Message-ID: <53EECD32.6030909@auckland.ac.nz>

On 16/08/14 11:01, David Winsemius wrote:
>
> On Aug 15, 2014, at 3:11 PM, Rolf Turner wrote:

<SNIP>

>>

>> I tried RSiteSearch("convex hull") just now, as an experiment, and
>> it seemed to work just fine.  I think that the Universe is picking
>> on Dave (instead of on me, for once!). :-)
>
> RSiteSearch("convex hull") does produce a page on my web-browser, but
> have you tried to follow links on the page? I got 404's about a third
> of the time , although admittedly I was earlier generalizing on the
> basis of 3 404's in a row. And I was further generalizing from
> earlier experience when support for searching the rhelp archive was
> abandoned.

Well, I tried a couple of links and the pages opened without any 
reluctance.  I didn't try them *all* ....

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS


From 538280 at gmail.com  Sat Aug 16 15:57:38 2014
From: 538280 at gmail.com (Greg Snow)
Date: Sat, 16 Aug 2014 07:57:38 -0600
Subject: [R] Generating a polygon around points
In-Reply-To: <53EE8471.2050205@auckland.ac.nz>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>
	<53EE8471.2050205@auckland.ac.nz>
Message-ID: <CAFEqCdz3U_kOox6BUEMEzuAQ2rxip16g=ZsOr+b3VA2dx0ygbQ@mail.gmail.com>

On Fri, Aug 15, 2014 at 4:06 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> OTOH R is still lacking a mind_read() function so it probably
> would NOT give you *exactly* what you want.

We can try the (very pre-alpha) esp package:

> source('g:/R/esp/esp.R')
> esp()
[1] "piccalilli crawlspace mole swarthy thunderhead forever"

Somehow I doubt that that is *exactly* what the original poster wants.

I guess it still needs work.

-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From dwinsemius at comcast.net  Sat Aug 16 20:04:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 16 Aug 2014 11:04:02 -0700
Subject: [R] unable to use functions require DLL from package
In-Reply-To: <CADkGAKe38niRiJ4W8dKHPPpT4A6cJPOxLyBFqd3nbgKqb66Lpw@mail.gmail.com>
References: <17086783.post@talk.nabble.com>
	<alpine.LFD.1.10.0805062222200.3080@auk.stats.ox.ac.uk>
	<17101073.post@talk.nabble.com>
	<loom.20140815T170558-587@post.gmane.org>
	<E3BFBE59-5A60-4E83-AC25-9B3ED38E0A06@comcast.net>
	<loom.20140815T234525-449@post.gmane.org>
	<C517A915-3A63-47AD-B30B-7A3F7FE32D8F@comcast.net>
	<CADkGAKe38niRiJ4W8dKHPPpT4A6cJPOxLyBFqd3nbgKqb66Lpw@mail.gmail.com>
Message-ID: <7C4F22E8-B49B-481A-B289-D0C00275C0B8@comcast.net>


On Aug 16, 2014, at 1:54 AM, Lotte de Vries wrote:
snipped all of your and my earlier material because you have included everything needed for an answer in your current question..

> > 
> 
> Hi David, 
> 
> Let me try this again, apologies. 
> 
> I'm trying to run the package posum
> (http://www.maths.bath.ac.uk/~sw283/simon/posum.html), 
> which is an old package and therefore relies on an old version 
> of the package mgcv (version 0.8-7). 
> 
> I'm trying to run these packages using R version 3.1.0 on 
> windows 8 computer( x86_64-w64-mingw32/x64 (64-bit)). 
> 
> When I run the example code given in the posum package I get 
> an error. The code I'm trying to run is: 
> 
> data<-population.data(fam="p",adult=TRUE) #simulate data
> b<-posum(data,fam="p")
> 
> The second line gives an error and a warning: 
> 
> Error in .C("spline_coef", method = as.integer(method), 
> n = n, x = as.double(x),  : 
>   "spline_coef" not available for .C() for package "stats"
> In addition: Warning message:
> In if (d < 0) stop("d can not be negative in call to 
> null.space.dimension().") :
>   the condition has length > 1 and only the first element 
> will be used
> 
> The part of the posum code that this error refers to is the 
> following:
> 
> 
> cm.splinefun<-function(x, y = NULL, method = "fmm",gulim=0) 
> 
> # modification of base package splinefun to produce co-monotonic 
> #interpolant
> # by Hyman Filtering. if gulim!=0 then it is taken as the upper 
> # limit on the gradient. 
> {   x <- xy.coords(x, y)
>     y <- x$y
>     x <- x$x
>     n <- length(x)
>     method <- match(method, c("periodic", "natural", "fmm"))
>     if (is.na(method)) 
>         stop("splinefun: invalid interpolation method")
>     if (any(diff(x) < 0)) {
>         z <- order(x)
>         x <- x[z]
>         y <- y[z]
>     }
>     if (method == 1 && y[1] != y[n]) {
>         warning("first and last y values differ in spline - 
> using y[1] for both")
>         y[n] <- y[1]
>     }
>     z <- .C("spline_coef", method = as.integer(method), n = n, 
>         x = as.double(x), y = as.double(y), b = double(n), 
> c = double(n), d = double(n), 
>         e = double(if (method == 1) n else 0), PACKAGE = "stats")
>     
>     z$y<-z$y-z$x*gulim # trick to impose upper
>     z$b<-z$b-gulim     # limit on interpolator gradient
>     
>     z<-hyman.filter(z) # filter gradients for co-monotonicity
>     
>     z$y<-z$y+z$x*gulim # undo trick 
>     z$b<-z$b+gulim     # transformation
>     
>     z<-spl.coef.conv(z) # force other coefficients to consistency
>    
>     rm(x, y, n, method)
>     function(x) {
>         .C("spline_eval", z$method, length(x), x = as.double(x), 
>             y = double(length(x)), z$n, z$x, z$y, z$b, z$c, z$d, 
>             PACKAGE = "stats")$y
>     }
> }
> 
> 
> And finally: 
> 
> > sessionInfo()
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=
> English_United Kingdom.1252   
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C                           
> [5] LC_TIME=English_United Kingdom.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods  base     
> 
> other attached packages:
> [1] posum_2.0-0 mgcv_0.8-7 
> 
> loaded via a namespace (and not attached):
> [1] tools_3.1.0
> 
> 
> I hope this is a more acceptable formulation of the problem! 

Yes, it is, although the answer will not be to your liking. You cannot mix old packages that are written in older versions of R with a current version of R. That is an ancient version of mgcv. The current version is 1.8-2. (I'm surprised you were able to install it, much less get it to load.) The usual advice in such instances is to figure out a combination of R, and all of the packages that existed at a particular time.

I was able to find : www.maths.bath.ac.uk/~sw283/simon/posum.html

If you look at the archives:

http://cran.r-project.org/src/contrib/Archive

....   to get an idea when mgcv 0.8-7 was current you find:

	mgcv_0.8-7.tar.gz	06-Nov-2002 09:12  	155K	 

The version of R that corresponds to that date might be:

	R-1.6.1.tgz	01-Nov-2002 12:22  	8.2M	 

The problem you may face however is that your operating system may not be compatible and you may need to find a machine that corresponds to that era of R-history. .... say Windows XP?

Might be easier to remedy the defects that exist in posum that prevent it from being a current package and working with the current mgcv. (I also checked to see if it had been submitted to CRAN in that era:

http://cran.r-project.org/bin/windows/contrib/1.7/

But it's not there.)

 I looked at the code and it does not require compilation. You can probably find current functions that can substitute for some of functionality implemented by broken code using the .C calls. For instance the current version of `cm.splinefun` in package:demography simply calls splinefun with method = 'hyman'


> cm.splinefun
function (x, y = NULL, ...) 
{
    splinefun(x, y, method = "hyman")
}
<bytecode: 0x2e7bbd158>
<environment: namespace:demography>



--- 
David Winsemius
Alameda, CA, USA


From kate.ignatius at gmail.com  Sat Aug 16 21:42:04 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 16 Aug 2014 15:42:04 -0400
Subject: [R] data.table/ifelse conditional new variable question
Message-ID: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>

Hi,

I have a data.table question (as well as if else statement query).

I have a large list of families (file has 935 individuals that are
sorted by famiy of varying sizes).  At the moment the file has the
columns:

SampleID FamilyID Relationship

To prevent from having to make a pedigree file by hand - ie adding a
PaternalID and a MaternalID one by one I want to try write a script
that will quickly do this for me  (I eventually want to run this
through a program such as plink)   Is there a way to use data.table
(maybe in conjucntion with ifelse to do this effectively)?

An example of the file is something like:

Family.ID Sample.ID Relationship
14           62  sibling
14          94  father
14           63  sibling
14           59 mother
17         6004  father
17           6003 mother
17         6005   sibling
17         368   sibling
130           202 mother
130           203  father
130           204   sibling
130           205   sibling
130           206   sibling
222         9 mother
222         45  sibling
222         34  sibling
222         10  sibling
222         11  sibling
222         18  father

But the goal is to have a file like this:

Family.ID Sample.ID Relationship PID MID
14           62  sibling 94 59
14          94  father 0 0
14           63  sibling 94 59
14           59 mother 0 0
17         6004  father 0 0
17           6003 mother 0 0
17         6005   sibling 6004 6003
17         368   sibling 6004 6003
130           202 mother 0 0
130           203  father 0 0
130           204   sibling 203 202
130           205   sibling 203 202
130           206   sibling 203 202
222         9 mother 0 0
222         45  sibling 18 9
222         34  sibling 18 9
222         10  sibling 18 9
222         11  sibling 18 9
222         18  father 0 0

I've tried searches for this but with no luck.  Greatly appreciate any
help - even if its just a link to a great example/solution!

Thanks!


From jorgeivanvelez at gmail.com  Sun Aug 17 00:48:31 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sun, 17 Aug 2014 08:48:31 +1000
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
Message-ID: <CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>

Dear Kate,

Assuming you have nuclear families, one option would be:

x <- read.table(textConnection("Family.ID Sample.ID Relationship
14           62  sibling
14          94  father
14           63  sibling
14           59 mother
17         6004  father
17           6003 mother
17         6005   sibling
17         368   sibling
130           202 mother
130           203  father
130           204   sibling
130           205   sibling
130           206   sibling
222         9 mother
222         45  sibling
222         34  sibling
222         10  sibling
222         11  sibling
222         18  father"), header = TRUE)
closeAllConnections()

xs <- with(x, split(x, Family.ID))
res <- do.call(rbind, lapply(xs, function(l){
l$PID <- l$MID <- 0
 father <- with(l, Relationship == 'father')
 mother <- with(l, Relationship == 'mother')
 l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
 l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
l
 }))
res

HTH,
Jorge.-


Best regards,
Jorge.-



On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> Hi,
>
> I have a data.table question (as well as if else statement query).
>
> I have a large list of families (file has 935 individuals that are
> sorted by famiy of varying sizes).  At the moment the file has the
> columns:
>
> SampleID FamilyID Relationship
>
> To prevent from having to make a pedigree file by hand - ie adding a
> PaternalID and a MaternalID one by one I want to try write a script
> that will quickly do this for me  (I eventually want to run this
> through a program such as plink)   Is there a way to use data.table
> (maybe in conjucntion with ifelse to do this effectively)?
>
> An example of the file is something like:
>
> Family.ID Sample.ID Relationship
> 14           62  sibling
> 14          94  father
> 14           63  sibling
> 14           59 mother
> 17         6004  father
> 17           6003 mother
> 17         6005   sibling
> 17         368   sibling
> 130           202 mother
> 130           203  father
> 130           204   sibling
> 130           205   sibling
> 130           206   sibling
> 222         9 mother
> 222         45  sibling
> 222         34  sibling
> 222         10  sibling
> 222         11  sibling
> 222         18  father
>
> But the goal is to have a file like this:
>
> Family.ID Sample.ID Relationship PID MID
> 14           62  sibling 94 59
> 14          94  father 0 0
> 14           63  sibling 94 59
> 14           59 mother 0 0
> 17         6004  father 0 0
> 17           6003 mother 0 0
> 17         6005   sibling 6004 6003
> 17         368   sibling 6004 6003
> 130           202 mother 0 0
> 130           203  father 0 0
> 130           204   sibling 203 202
> 130           205   sibling 203 202
> 130           206   sibling 203 202
> 222         9 mother 0 0
> 222         45  sibling 18 9
> 222         34  sibling 18 9
> 222         10  sibling 18 9
> 222         11  sibling 18 9
> 222         18  father 0 0
>
> I've tried searches for this but with no luck.  Greatly appreciate any
> help - even if its just a link to a great example/solution!
>
> Thanks!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Aug 17 01:54:07 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 17 Aug 2014 11:54:07 +1200
Subject: [R] Generating a polygon around points
In-Reply-To: <CAFEqCdz3U_kOox6BUEMEzuAQ2rxip16g=ZsOr+b3VA2dx0ygbQ@mail.gmail.com>
References: <CAN-Z0xXfj8QYRy1F8ffg+wvsWGHw544dYXz7vn-OrpMWcVdBtQ@mail.gmail.com>	<53EE8471.2050205@auckland.ac.nz>
	<CAFEqCdz3U_kOox6BUEMEzuAQ2rxip16g=ZsOr+b3VA2dx0ygbQ@mail.gmail.com>
Message-ID: <53EFEF1F.5070706@auckland.ac.nz>

On 17/08/14 01:57, Greg Snow wrote:
> On Fri, Aug 15, 2014 at 4:06 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>> OTOH R is still lacking a mind_read() function so it probably
>> would NOT give you *exactly* what you want.
>
> We can try the (very pre-alpha) esp package:
>
>> source('g:/R/esp/esp.R')
>> esp()
> [1] "piccalilli crawlspace mole swarthy thunderhead forever"
>
> Somehow I doubt that that is *exactly* what the original poster wants.
>
> I guess it still needs work.


ROFL!!!  (As contrasted with "ROLF". :-) )


-- 
Rolf Turner
Technical Editor ANZJS


From kate.ignatius at gmail.com  Sun Aug 17 02:02:30 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 16 Aug 2014 20:02:30 -0400
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
Message-ID: <CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>

Thanks!

I think I know what is being done here but not sure how to fix the
following error:

Error in l$PID[l$\Relationship == "sibling"] <- l$Sample.ID[father] :
  replacement has length zero



On Sat, Aug 16, 2014 at 6:48 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
> Dear Kate,
>
> Assuming you have nuclear families, one option would be:
>
> x <- read.table(textConnection("Family.ID Sample.ID Relationship
> 14           62  sibling
> 14          94  father
> 14           63  sibling
> 14           59 mother
> 17         6004  father
> 17           6003 mother
> 17         6005   sibling
> 17         368   sibling
> 130           202 mother
> 130           203  father
> 130           204   sibling
> 130           205   sibling
> 130           206   sibling
> 222         9 mother
> 222         45  sibling
> 222         34  sibling
> 222         10  sibling
> 222         11  sibling
> 222         18  father"), header = TRUE)
> closeAllConnections()
>
> xs <- with(x, split(x, Family.ID))
> res <- do.call(rbind, lapply(xs, function(l){
> l$PID <- l$MID <- 0
> father <- with(l, Relationship == 'father')
> mother <- with(l, Relationship == 'mother')
> l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
> l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
> l
> }))
> res
>
> HTH,
> Jorge.-
>
>
> Best regards,
> Jorge.-
>
>
>
> On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
>>
>> Hi,
>>
>> I have a data.table question (as well as if else statement query).
>>
>> I have a large list of families (file has 935 individuals that are
>> sorted by famiy of varying sizes).  At the moment the file has the
>> columns:
>>
>> SampleID FamilyID Relationship
>>
>> To prevent from having to make a pedigree file by hand - ie adding a
>> PaternalID and a MaternalID one by one I want to try write a script
>> that will quickly do this for me  (I eventually want to run this
>> through a program such as plink)   Is there a way to use data.table
>> (maybe in conjucntion with ifelse to do this effectively)?
>>
>> An example of the file is something like:
>>
>> Family.ID Sample.ID Relationship
>> 14           62  sibling
>> 14          94  father
>> 14           63  sibling
>> 14           59 mother
>> 17         6004  father
>> 17           6003 mother
>> 17         6005   sibling
>> 17         368   sibling
>> 130           202 mother
>> 130           203  father
>> 130           204   sibling
>> 130           205   sibling
>> 130           206   sibling
>> 222         9 mother
>> 222         45  sibling
>> 222         34  sibling
>> 222         10  sibling
>> 222         11  sibling
>> 222         18  father
>>
>> But the goal is to have a file like this:
>>
>> Family.ID Sample.ID Relationship PID MID
>> 14           62  sibling 94 59
>> 14          94  father 0 0
>> 14           63  sibling 94 59
>> 14           59 mother 0 0
>> 17         6004  father 0 0
>> 17           6003 mother 0 0
>> 17         6005   sibling 6004 6003
>> 17         368   sibling 6004 6003
>> 130           202 mother 0 0
>> 130           203  father 0 0
>> 130           204   sibling 203 202
>> 130           205   sibling 203 202
>> 130           206   sibling 203 202
>> 222         9 mother 0 0
>> 222         45  sibling 18 9
>> 222         34  sibling 18 9
>> 222         10  sibling 18 9
>> 222         11  sibling 18 9
>> 222         18  father 0 0
>>
>> I've tried searches for this but with no luck.  Greatly appreciate any
>> help - even if its just a link to a great example/solution!
>>
>> Thanks!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From kate.ignatius at gmail.com  Sun Aug 17 02:58:47 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 16 Aug 2014 20:58:47 -0400
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
	<CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
Message-ID: <CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>

Actually - I didn't check this before, but these are not all nuclear
families (as I assumed they were).  That is, some don't have a father
or don't have a mother.... Usually if this is the case PID or MID will
become 0, respectively, for the child.  How can the code be edit to
account for this?

On Sat, Aug 16, 2014 at 8:02 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Thanks!
>
> I think I know what is being done here but not sure how to fix the
> following error:
>
> Error in l$PID[l$\Relationship == "sibling"] <- l$Sample.ID[father] :
>   replacement has length zero
>
>
>
> On Sat, Aug 16, 2014 at 6:48 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
>> Dear Kate,
>>
>> Assuming you have nuclear families, one option would be:
>>
>> x <- read.table(textConnection("Family.ID Sample.ID Relationship
>> 14           62  sibling
>> 14          94  father
>> 14           63  sibling
>> 14           59 mother
>> 17         6004  father
>> 17           6003 mother
>> 17         6005   sibling
>> 17         368   sibling
>> 130           202 mother
>> 130           203  father
>> 130           204   sibling
>> 130           205   sibling
>> 130           206   sibling
>> 222         9 mother
>> 222         45  sibling
>> 222         34  sibling
>> 222         10  sibling
>> 222         11  sibling
>> 222         18  father"), header = TRUE)
>> closeAllConnections()
>>
>> xs <- with(x, split(x, Family.ID))
>> res <- do.call(rbind, lapply(xs, function(l){
>> l$PID <- l$MID <- 0
>> father <- with(l, Relationship == 'father')
>> mother <- with(l, Relationship == 'mother')
>> l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
>> l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
>> l
>> }))
>> res
>>
>> HTH,
>> Jorge.-
>>
>>
>> Best regards,
>> Jorge.-
>>
>>
>>
>> On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius <kate.ignatius at gmail.com>
>> wrote:
>>>
>>> Hi,
>>>
>>> I have a data.table question (as well as if else statement query).
>>>
>>> I have a large list of families (file has 935 individuals that are
>>> sorted by famiy of varying sizes).  At the moment the file has the
>>> columns:
>>>
>>> SampleID FamilyID Relationship
>>>
>>> To prevent from having to make a pedigree file by hand - ie adding a
>>> PaternalID and a MaternalID one by one I want to try write a script
>>> that will quickly do this for me  (I eventually want to run this
>>> through a program such as plink)   Is there a way to use data.table
>>> (maybe in conjucntion with ifelse to do this effectively)?
>>>
>>> An example of the file is something like:
>>>
>>> Family.ID Sample.ID Relationship
>>> 14           62  sibling
>>> 14          94  father
>>> 14           63  sibling
>>> 14           59 mother
>>> 17         6004  father
>>> 17           6003 mother
>>> 17         6005   sibling
>>> 17         368   sibling
>>> 130           202 mother
>>> 130           203  father
>>> 130           204   sibling
>>> 130           205   sibling
>>> 130           206   sibling
>>> 222         9 mother
>>> 222         45  sibling
>>> 222         34  sibling
>>> 222         10  sibling
>>> 222         11  sibling
>>> 222         18  father
>>>
>>> But the goal is to have a file like this:
>>>
>>> Family.ID Sample.ID Relationship PID MID
>>> 14           62  sibling 94 59
>>> 14          94  father 0 0
>>> 14           63  sibling 94 59
>>> 14           59 mother 0 0
>>> 17         6004  father 0 0
>>> 17           6003 mother 0 0
>>> 17         6005   sibling 6004 6003
>>> 17         368   sibling 6004 6003
>>> 130           202 mother 0 0
>>> 130           203  father 0 0
>>> 130           204   sibling 203 202
>>> 130           205   sibling 203 202
>>> 130           206   sibling 203 202
>>> 222         9 mother 0 0
>>> 222         45  sibling 18 9
>>> 222         34  sibling 18 9
>>> 222         10  sibling 18 9
>>> 222         11  sibling 18 9
>>> 222         18  father 0 0
>>>
>>> I've tried searches for this but with no luck.  Greatly appreciate any
>>> help - even if its just a link to a great example/solution!
>>>
>>> Thanks!
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>


From kate.ignatius at gmail.com  Sun Aug 17 03:47:41 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 16 Aug 2014 21:47:41 -0400
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAKL8G3FMFVbYo8vdAxU-j-Kv-ieo+2x8phcFrdsYXODa0La1FQ@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
	<CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
	<CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>
	<CAKL8G3FMFVbYo8vdAxU-j-Kv-ieo+2x8phcFrdsYXODa0La1FQ@mail.gmail.com>
Message-ID: <CAE6QMsYzRbUF5qZHwNJ=ADqfg8G6+Wn0kN3mR0C+PgzYEXY1AQ@mail.gmail.com>

Yep - you're right - missing parents are indicated as zero in the M/PID field.

The above code worked with a few errors:

1: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
  number of items to replace is not a multiple of replacement length
2: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
  number of items to replace is not a multiple of replacement length
3: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
  number of items to replace is not a multiple of replacement length
4: In l$MID[l$Relationship == "sibling"] <- l$Sample.ID[mother] :
  number of items to replace is not a multiple of replacement length

looking at the output I get numbers where the father/mother ID should
be in the M/PID field.  For example:

2702  349       mother   0   0
2702  3456  sibling   0 842
2702  9980  sibling   0 842
3064  3  father   0   0
3064  4  mother   0   0
3064  5    sibling 879 880
3064  86   sibling 879 880
3064  87   sibling 879 880

On Sat, Aug 16, 2014 at 9:31 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
> Dear Kate,
>
> Try this:
>
> res <- do.call(rbind, lapply(xs, function(l){
> l$PID <- l$MID <- 0
> father <- with(l, Relationship == 'father')
> mother <- with(l, Relationship == 'mother')
> if(sum(father) == 0)
> l$PID[l$Relationship == 'sibling'] <- 0
> else l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
> if(sum(mother) == 0)
> l$MID[l$Relationship == 'sibling'] <- 0
> else l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
> l
> }))
>
> It is assumed that when either parent is not available the M/PID is 0.
>
> Best,
> Jorge.-
>
>
> On Sun, Aug 17, 2014 at 10:58 AM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
>>
>> Actually - I didn't check this before, but these are not all nuclear
>> families (as I assumed they were).  That is, some don't have a father
>> or don't have a mother.... Usually if this is the case PID or MID will
>> become 0, respectively, for the child.  How can the code be edit to
>> account for this?
>>
>> On Sat, Aug 16, 2014 at 8:02 PM, Kate Ignatius <kate.ignatius at gmail.com>
>> wrote:
>> > Thanks!
>> >
>> > I think I know what is being done here but not sure how to fix the
>> > following error:
>> >
>> > Error in l$PID[l$\Relationship == "sibling"] <- l$Sample.ID[father] :
>> >   replacement has length zero
>> >
>> >
>> >
>> > On Sat, Aug 16, 2014 at 6:48 PM, Jorge I Velez
>> > <jorgeivanvelez at gmail.com> wrote:
>> >> Dear Kate,
>> >>
>> >> Assuming you have nuclear families, one option would be:
>> >>
>> >> x <- read.table(textConnection("Family.ID Sample.ID Relationship
>> >> 14           62  sibling
>> >> 14          94  father
>> >> 14           63  sibling
>> >> 14           59 mother
>> >> 17         6004  father
>> >> 17           6003 mother
>> >> 17         6005   sibling
>> >> 17         368   sibling
>> >> 130           202 mother
>> >> 130           203  father
>> >> 130           204   sibling
>> >> 130           205   sibling
>> >> 130           206   sibling
>> >> 222         9 mother
>> >> 222         45  sibling
>> >> 222         34  sibling
>> >> 222         10  sibling
>> >> 222         11  sibling
>> >> 222         18  father"), header = TRUE)
>> >> closeAllConnections()
>> >>
>> >> xs <- with(x, split(x, Family.ID))
>> >> res <- do.call(rbind, lapply(xs, function(l){
>> >> l$PID <- l$MID <- 0
>> >> father <- with(l, Relationship == 'father')
>> >> mother <- with(l, Relationship == 'mother')
>> >> l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
>> >> l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
>> >> l
>> >> }))
>> >> res
>> >>
>> >> HTH,
>> >> Jorge.-
>> >>
>> >>
>> >> Best regards,
>> >> Jorge.-
>> >>
>> >>
>> >>
>> >> On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius
>> >> <kate.ignatius at gmail.com>
>> >> wrote:
>> >>>
>> >>> Hi,
>> >>>
>> >>> I have a data.table question (as well as if else statement query).
>> >>>
>> >>> I have a large list of families (file has 935 individuals that are
>> >>> sorted by famiy of varying sizes).  At the moment the file has the
>> >>> columns:
>> >>>
>> >>> SampleID FamilyID Relationship
>> >>>
>> >>> To prevent from having to make a pedigree file by hand - ie adding a
>> >>> PaternalID and a MaternalID one by one I want to try write a script
>> >>> that will quickly do this for me  (I eventually want to run this
>> >>> through a program such as plink)   Is there a way to use data.table
>> >>> (maybe in conjucntion with ifelse to do this effectively)?
>> >>>
>> >>> An example of the file is something like:
>> >>>
>> >>> Family.ID Sample.ID Relationship
>> >>> 14           62  sibling
>> >>> 14          94  father
>> >>> 14           63  sibling
>> >>> 14           59 mother
>> >>> 17         6004  father
>> >>> 17           6003 mother
>> >>> 17         6005   sibling
>> >>> 17         368   sibling
>> >>> 130           202 mother
>> >>> 130           203  father
>> >>> 130           204   sibling
>> >>> 130           205   sibling
>> >>> 130           206   sibling
>> >>> 222         9 mother
>> >>> 222         45  sibling
>> >>> 222         34  sibling
>> >>> 222         10  sibling
>> >>> 222         11  sibling
>> >>> 222         18  father
>> >>>
>> >>> But the goal is to have a file like this:
>> >>>
>> >>> Family.ID Sample.ID Relationship PID MID
>> >>> 14           62  sibling 94 59
>> >>> 14          94  father 0 0
>> >>> 14           63  sibling 94 59
>> >>> 14           59 mother 0 0
>> >>> 17         6004  father 0 0
>> >>> 17           6003 mother 0 0
>> >>> 17         6005   sibling 6004 6003
>> >>> 17         368   sibling 6004 6003
>> >>> 130           202 mother 0 0
>> >>> 130           203  father 0 0
>> >>> 130           204   sibling 203 202
>> >>> 130           205   sibling 203 202
>> >>> 130           206   sibling 203 202
>> >>> 222         9 mother 0 0
>> >>> 222         45  sibling 18 9
>> >>> 222         34  sibling 18 9
>> >>> 222         10  sibling 18 9
>> >>> 222         11  sibling 18 9
>> >>> 222         18  father 0 0
>> >>>
>> >>> I've tried searches for this but with no luck.  Greatly appreciate any
>> >>> help - even if its just a link to a great example/solution!
>> >>>
>> >>> Thanks!
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >>
>
>


From kate.ignatius at gmail.com  Sun Aug 17 04:02:55 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sat, 16 Aug 2014 22:02:55 -0400
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAKL8G3F=a3w_fVeMOtZZFyaFVHHX2dSeh5XJOj9epJjd2f676w@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
	<CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
	<CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>
	<CAKL8G3FMFVbYo8vdAxU-j-Kv-ieo+2x8phcFrdsYXODa0La1FQ@mail.gmail.com>
	<CAE6QMsYzRbUF5qZHwNJ=ADqfg8G6+Wn0kN3mR0C+PgzYEXY1AQ@mail.gmail.com>
	<CAKL8G3F=a3w_fVeMOtZZFyaFVHHX2dSeh5XJOj9epJjd2f676w@mail.gmail.com>
Message-ID: <CAE6QMsbzk9Shx4SXiW13Zm6-E4TAgh2oeNUVVwjLvXoB9ET4mQ@mail.gmail.com>

Actually - your code is not wrong... because this is a large file I
went through the file to see if there was anything wrong with it -
looks like there are two fathers or three mothers in some families.
Taking these duplicates out fixed the problem.

Sorry about the confusion!  And thanks so much for your help!

On Sat, Aug 16, 2014 at 9:53 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:
> Perhaps I am missing something but I do not get the same result:
>
> x <- read.table(textConnection("Family.ID Sample.ID Relationship
> 2702  349       mother
> 2702  3456  sibling
> 2702  9980  sibling
> 3064  3  father
> 3064  4  mother
> 3064  5    sibling
> 3064  86   sibling
> 3064  87   sibling"), header = TRUE)
> closeAllConnections()
>
> xs <- with(x, split(x, Family.ID))
> res <- do.call(rbind, lapply(xs, function(l){
> l$PID <- l$MID <- 0
> father <- with(l, Relationship == 'father')
> mother <- with(l, Relationship == 'mother')
> if(sum(father) == 0)
> l$PID[l$Relationship == 'sibling'] <- 0
> else l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
> if(sum(mother) == 0)
> l$MID[l$Relationship == 'sibling'] <- 0
> else l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
> l
> }))
> #Family.ID Sample.ID Relationship MID PID
> #2702.1      2702       349       mother   0   0
> #2702.2      2702      3456      sibling 349   0
> #2702.3      2702      9980      sibling 349   0
> #3064.4      3064         3       father   0   0
> #3064.5      3064         4       mother   0   0
> #3064.6      3064         5      sibling   4   3
> #3064.7      3064        86      sibling   4   3
> #3064.8      3064        87      sibling   4   3
>
> HTH,
> Jorge.-
>
>
>
>
> On Sun, Aug 17, 2014 at 11:47 AM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
>>
>> Yep - you're right - missing parents are indicated as zero in the M/PID
>> field.
>>
>> The above code worked with a few errors:
>>
>> 1: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
>>   number of items to replace is not a multiple of replacement length
>> 2: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
>>   number of items to replace is not a multiple of replacement length
>> 3: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
>>   number of items to replace is not a multiple of replacement length
>> 4: In l$MID[l$Relationship == "sibling"] <- l$Sample.ID[mother] :
>>   number of items to replace is not a multiple of replacement length
>>
>> looking at the output I get numbers where the father/mother ID should
>> be in the M/PID field.  For example:
>>
>> 2702  349       mother   0   0
>> 2702  3456  sibling   0 842
>> 2702  9980  sibling   0 842
>> 3064  3  father   0   0
>> 3064  4  mother   0   0
>> 3064  5    sibling 879 880
>> 3064  86   sibling 879 880
>> 3064  87   sibling 879 880
>>
>> On Sat, Aug 16, 2014 at 9:31 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
>> wrote:
>> > Dear Kate,
>> >
>> > Try this:
>> >
>> > res <- do.call(rbind, lapply(xs, function(l){
>> > l$PID <- l$MID <- 0
>> > father <- with(l, Relationship == 'father')
>> > mother <- with(l, Relationship == 'mother')
>> > if(sum(father) == 0)
>> > l$PID[l$Relationship == 'sibling'] <- 0
>> > else l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
>> > if(sum(mother) == 0)
>> > l$MID[l$Relationship == 'sibling'] <- 0
>> > else l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
>> > l
>> > }))
>> >
>> > It is assumed that when either parent is not available the M/PID is 0.
>> >
>> > Best,
>> > Jorge.-
>> >
>> >
>> > On Sun, Aug 17, 2014 at 10:58 AM, Kate Ignatius
>> > <kate.ignatius at gmail.com>
>> > wrote:
>> >>
>> >> Actually - I didn't check this before, but these are not all nuclear
>> >> families (as I assumed they were).  That is, some don't have a father
>> >> or don't have a mother.... Usually if this is the case PID or MID will
>> >> become 0, respectively, for the child.  How can the code be edit to
>> >> account for this?
>> >>
>> >> On Sat, Aug 16, 2014 at 8:02 PM, Kate Ignatius
>> >> <kate.ignatius at gmail.com>
>> >> wrote:
>> >> > Thanks!
>> >> >
>> >> > I think I know what is being done here but not sure how to fix the
>> >> > following error:
>> >> >
>> >> > Error in l$PID[l$\Relationship == "sibling"] <- l$Sample.ID[father] :
>> >> >   replacement has length zero
>> >> >
>> >> >
>> >> >
>> >> > On Sat, Aug 16, 2014 at 6:48 PM, Jorge I Velez
>> >> > <jorgeivanvelez at gmail.com> wrote:
>> >> >> Dear Kate,
>> >> >>
>> >> >> Assuming you have nuclear families, one option would be:
>> >> >>
>> >> >> x <- read.table(textConnection("Family.ID Sample.ID Relationship
>> >> >> 14           62  sibling
>> >> >> 14          94  father
>> >> >> 14           63  sibling
>> >> >> 14           59 mother
>> >> >> 17         6004  father
>> >> >> 17           6003 mother
>> >> >> 17         6005   sibling
>> >> >> 17         368   sibling
>> >> >> 130           202 mother
>> >> >> 130           203  father
>> >> >> 130           204   sibling
>> >> >> 130           205   sibling
>> >> >> 130           206   sibling
>> >> >> 222         9 mother
>> >> >> 222         45  sibling
>> >> >> 222         34  sibling
>> >> >> 222         10  sibling
>> >> >> 222         11  sibling
>> >> >> 222         18  father"), header = TRUE)
>> >> >> closeAllConnections()
>> >> >>
>> >> >> xs <- with(x, split(x, Family.ID))
>> >> >> res <- do.call(rbind, lapply(xs, function(l){
>> >> >> l$PID <- l$MID <- 0
>> >> >> father <- with(l, Relationship == 'father')
>> >> >> mother <- with(l, Relationship == 'mother')
>> >> >> l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
>> >> >> l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
>> >> >> l
>> >> >> }))
>> >> >> res
>> >> >>
>> >> >> HTH,
>> >> >> Jorge.-
>> >> >>
>> >> >>
>> >> >> Best regards,
>> >> >> Jorge.-
>> >> >>
>> >> >>
>> >> >>
>> >> >> On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius
>> >> >> <kate.ignatius at gmail.com>
>> >> >> wrote:
>> >> >>>
>> >> >>> Hi,
>> >> >>>
>> >> >>> I have a data.table question (as well as if else statement query).
>> >> >>>
>> >> >>> I have a large list of families (file has 935 individuals that are
>> >> >>> sorted by famiy of varying sizes).  At the moment the file has the
>> >> >>> columns:
>> >> >>>
>> >> >>> SampleID FamilyID Relationship
>> >> >>>
>> >> >>> To prevent from having to make a pedigree file by hand - ie adding
>> >> >>> a
>> >> >>> PaternalID and a MaternalID one by one I want to try write a script
>> >> >>> that will quickly do this for me  (I eventually want to run this
>> >> >>> through a program such as plink)   Is there a way to use data.table
>> >> >>> (maybe in conjucntion with ifelse to do this effectively)?
>> >> >>>
>> >> >>> An example of the file is something like:
>> >> >>>
>> >> >>> Family.ID Sample.ID Relationship
>> >> >>> 14           62  sibling
>> >> >>> 14          94  father
>> >> >>> 14           63  sibling
>> >> >>> 14           59 mother
>> >> >>> 17         6004  father
>> >> >>> 17           6003 mother
>> >> >>> 17         6005   sibling
>> >> >>> 17         368   sibling
>> >> >>> 130           202 mother
>> >> >>> 130           203  father
>> >> >>> 130           204   sibling
>> >> >>> 130           205   sibling
>> >> >>> 130           206   sibling
>> >> >>> 222         9 mother
>> >> >>> 222         45  sibling
>> >> >>> 222         34  sibling
>> >> >>> 222         10  sibling
>> >> >>> 222         11  sibling
>> >> >>> 222         18  father
>> >> >>>
>> >> >>> But the goal is to have a file like this:
>> >> >>>
>> >> >>> Family.ID Sample.ID Relationship PID MID
>> >> >>> 14           62  sibling 94 59
>> >> >>> 14          94  father 0 0
>> >> >>> 14           63  sibling 94 59
>> >> >>> 14           59 mother 0 0
>> >> >>> 17         6004  father 0 0
>> >> >>> 17           6003 mother 0 0
>> >> >>> 17         6005   sibling 6004 6003
>> >> >>> 17         368   sibling 6004 6003
>> >> >>> 130           202 mother 0 0
>> >> >>> 130           203  father 0 0
>> >> >>> 130           204   sibling 203 202
>> >> >>> 130           205   sibling 203 202
>> >> >>> 130           206   sibling 203 202
>> >> >>> 222         9 mother 0 0
>> >> >>> 222         45  sibling 18 9
>> >> >>> 222         34  sibling 18 9
>> >> >>> 222         10  sibling 18 9
>> >> >>> 222         11  sibling 18 9
>> >> >>> 222         18  father 0 0
>> >> >>>
>> >> >>> I've tried searches for this but with no luck.  Greatly appreciate
>> >> >>> any
>> >> >>> help - even if its just a link to a great example/solution!
>> >> >>>
>> >> >>> Thanks!
>> >> >>>
>> >> >>> ______________________________________________
>> >> >>> R-help at r-project.org mailing list
>> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>> PLEASE do read the posting guide
>> >> >>> http://www.R-project.org/posting-guide.html
>> >> >>> and provide commented, minimal, self-contained, reproducible code.
>> >> >>
>> >> >>
>> >
>> >
>
>


From john.archie.mckown at gmail.com  Sun Aug 17 05:24:26 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 16 Aug 2014 22:24:26 -0500
Subject: [R] Fwd:  opinion - sharing problem data and other stuff.
In-Reply-To: <CAAJSdjjLdHv4r0KF_=2NsqCzrhK828=gPMR3kFOQj7-dyCERAw@mail.gmail.com>
References: <CAAJSdjg77LFyKB2dOdYPhTYcky2RiiWT2XywTeGjndRmwGa9uw@mail.gmail.com>
	<CAM_vjumpp9RQwg=SW0biWcKpRv+OyFbJFo3gUiuS_AG56xmUDg@mail.gmail.com>
	<fe697e91-bf8b-48c1-b26e-d0939d9a18a9@email.android.com>
	<CAAJSdjjLdHv4r0KF_=2NsqCzrhK828=gPMR3kFOQj7-dyCERAw@mail.gmail.com>
Message-ID: <CAAJSdjinHkyBOsbgmbFwWbuUA3+UcBSzqTUH87DgaU0_Z8VWhA@mail.gmail.com>

Thanks for your thoughts, Sarah and Jeff! I do appreciate the time and
effort. I will refrain from posting a link to a GIST as the main part of my
response. But I still like the idea, but I'm going to modify it a bit. For
any replies that I make which are not 3 or 4 lines, I'm going to create a
new GIST. This is be mainly for myself. But more often, if I see a
technique that I really like (and I have seen some good stuff), I am going
to create a GIST from that so that I have a good, "cloud" based place which
contains it. That way, I'm less likely to totally forget how somebody else
fixed a problem. Being a public archive, anybody here will be able to grab
anything they want from if, should there be anything of any use to others.
Being a bit anal about it, I will try very hard to keep the proper
attribution of the poster's name (as logged here on the list). I don't want
to claim credit (or blame, for that matter <grin>) for something that is
not my work.


On Wed, Aug 13, 2014 at 5:14 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Hear, hear. Getting the questioner to slow down and look at what they
> really want is key, because if they don't know what they want then their
> question will be unclear, and I hate answering a question that was never
> really what the OP was looking for in the first place.
>
> One problem I have encountered is questions where key information is in a
> linked web page that goes away, rendering the posting archive useless. I
> suppose as long as gists don't "age out" they can be okay for some
> questions, but I am still way less likely to go digging there to answer
> questions in the first place.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On August 13, 2014 2:50:16 PM PDT, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> >Hi John,
> >
> >People do sometimes link to external data and code, though I'm not
> >sure I've seen any in that particular format.
> >
> >But, two things to consider.
> >
> >A. I'm lazy. If the problem is fully-formed in the email, I'm more
> >likely to try to solve it than if I have to go download something and
> >figure out what's in it. (Even leaving aside the potential issues with
> >downloading random things.)
> >
> >B. A *small* reproducible example is usually a good thing. There are
> >not that many cases where the whole big dataset is necessary. Further,
> >the exercise of creating a small reproducible example is often enough
> >to solve the problem, without ever needed to bother R-help at all.
> >
> >Granted, I'm also likely to skip posts to the list with enormous
> >dput() data dumps too. I'm a big fan of the "small" part.
> >
> >Sarah
> >
> >On Wed, Aug 13, 2014 at 5:41 PM, John McKown
> ><john.archie.mckown at gmail.com> wrote:
> >> This is just a thought that has occurred to me. I don't know if it is
> >> an "Oh, WOW!" or an "Are you KIDDING?!?" type thought. So I thought
> >> I'd ask here.
> >>
> >> I use github for a few things. Nothing great, but maybe nice. Anyway,
> >> one feature of GitHub is the GIST feature. What I am used to github
> >> being for is a project consisting of many complete files. A gist can
> >> contain many files, but is really for a set of snippets. Such as code
> >> sequences. Or maybe the output from a dput().
> >>
> >> If I have a "big" problem where I think that having all the data and
> >> my attempted solutions available, I think it would be far kinder of
> >me
> >> to put a _good_ synopsis of the problem here on the list. And a
> >> clickable URL to the gist I have created for the problem. That would
> >> decrease the bandwidth on the email server. And save space on it.
> >And,
> >> lets face it, in many cases only a few people are going to really
> >look
> >> at any given problem "in depth", so why have a huge email go out to
> >> the entire community?
> >>
> >> My idea may not be useful, I really am not sure. But my motive is
> >> trying to keep everybody's inbox from overflowing. And make it easier
> >> to supply really good data, but only to those who are interested.
> >>
> >> Thanks for any feedback.
> >>
> >>
>
>


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Sun Aug 17 05:50:33 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 16 Aug 2014 22:50:33 -0500
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAE6QMsbzk9Shx4SXiW13Zm6-E4TAgh2oeNUVVwjLvXoB9ET4mQ@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
	<CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
	<CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>
	<CAKL8G3FMFVbYo8vdAxU-j-Kv-ieo+2x8phcFrdsYXODa0La1FQ@mail.gmail.com>
	<CAE6QMsYzRbUF5qZHwNJ=ADqfg8G6+Wn0kN3mR0C+PgzYEXY1AQ@mail.gmail.com>
	<CAKL8G3F=a3w_fVeMOtZZFyaFVHHX2dSeh5XJOj9epJjd2f676w@mail.gmail.com>
	<CAE6QMsbzk9Shx4SXiW13Zm6-E4TAgh2oeNUVVwjLvXoB9ET4mQ@mail.gmail.com>
Message-ID: <CAAJSdji8LU=toOSS_Q9C42Nd6DauiWns3FZgcoNXnk0ZpeTu3Q@mail.gmail.com>

On Sat, Aug 16, 2014 at 9:02 PM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> Actually - your code is not wrong... because this is a large file I
> went through the file to see if there was anything wrong with it -
> looks like there are two fathers or three mothers in some families.
> Taking these duplicates out fixed the problem.
>
> Sorry about the confusion!  And thanks so much for your help!
>
>
Kate,
I hope you don't mind, but I have a curiosity question on my part. Were the
families with multiple fathers or mothers a mistake, just duplicates (same
Family.ID & Sample.ID), or more like an "intermixed" family due to divorce
and remarriage. Or even, like in some countries, a case of polygamy? Sorry,
I just get curious about the strangest things sometimes.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From lotte.devries2 at student.uva.nl  Sat Aug 16 10:54:24 2014
From: lotte.devries2 at student.uva.nl (Lotte de Vries)
Date: Sat, 16 Aug 2014 10:54:24 +0200
Subject: [R] unable to use functions require DLL from package
In-Reply-To: <C517A915-3A63-47AD-B30B-7A3F7FE32D8F@comcast.net>
References: <17086783.post@talk.nabble.com>
	<alpine.LFD.1.10.0805062222200.3080@auk.stats.ox.ac.uk>
	<17101073.post@talk.nabble.com>
	<loom.20140815T170558-587@post.gmane.org>
	<E3BFBE59-5A60-4E83-AC25-9B3ED38E0A06@comcast.net>
	<loom.20140815T234525-449@post.gmane.org>
	<C517A915-3A63-47AD-B30B-7A3F7FE32D8F@comcast.net>
Message-ID: <CADkGAKe38niRiJ4W8dKHPPpT4A6cJPOxLyBFqd3nbgKqb66Lpw@mail.gmail.com>

David Winsemius <dwinsemius <at> comcast.net> writes:

>
> Well I do have the MASS package from which that function was
loaded.
>
> I get no error with the example in the help page:
>
>  boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
>          lambda = seq(-0.05, 0.45, len = 20), plotit=TRUE)
>
> ... and you are not providing a reproducible example that
provokes the
error, nor are you providing the
> version numbers of R or MASS.
>
> >
> > as I do miss some symbol names.
> >
> > How can I overcome this serious problem ?
> > ***********************************

> > ************************************
> > Subject: Missing "spline_coef" DLL and Rob Hyndmans monotonic
interpolator
> >
> >
> > x <- seq(0,4,l=20)
> >
> > y <- sort(rnorm(20))
> >
> > plot(x,y)
> > lines(spline(x, y, n = 201), col = 2) # Not necessarily monotonic
> > lines(cm.spline(x, y, n = 201), col = 3)
>
> I get no error after:
>
> library(demography)
>
> # And then running that code.
>
> I have an almost up-to-date version of R running on a mac
(and at the
moment I have way too many packages loaded:
>
> > sessionInfo()
> R version 3.1.0 Patched (2014-04-21 r65431)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] grDevices datasets  splines   graphics  utils     stats
> [7] grid      methods   base
>
> other attached packages:
>  [1] demography_1.17  ftsa_3.9         rainbow_3.2
>  [4] pcaPP_1.9-49     forecast_5.4     timeDate_3010.98
>  [7] zoo_1.7-11       XML_3.98-1.1     RCurl_1.95-4.3
> [10] bitops_1.0-6     subplex_1.1-4    MASS_7.3-31
> [13] cobs_1.2-2       quantreg_5.05    gplots_2.13.0
> [16] reshape2_1.2.2   ggplot2_0.9.3.1  multcomp_1.3-1
> [19] TH.data_1.0-3    mvtnorm_0.9-9999 data.table_1.9.2
> [22] muhaz_1.2.5      downloader_0.3   RJSONIO_1.3-0
> [25] plot3D_1.0-1     rms_4.2-0        SparseM_1.03
> [28] Hmisc_3.14-4     Formula_1.1-1    survival_2.37-7
> [31] sos_1.3-8        brew_1.0-6       lattice_0.20-29
>
> loaded via a namespace (and not attached):
>
> So that shows you how to provide some of the needed information
(which
neither of the postings to which you
> resonded had done.)  PLEASE read the Posting Guide.
>
>
> David Winsemius
> Alameda, CA, USA
>
>

Hi David,

Let me try this again, apologies.

I'm trying to run the package posum
(http://www.maths.bath.ac.uk/~sw283/simon/posum.html),
which is an old package and therefore relies on an old version
of the package mgcv (version 0.8-7).

I'm trying to run these packages using R version 3.1.0 on
windows 8 computer( x86_64-w64-mingw32/x64 (64-bit)).

When I run the example code given in the posum package I get
an error. The code I'm trying to run is:

data<-population.data(fam="p",adult=TRUE) #simulate data
b<-posum(data,fam="p")

The second line gives an error and a warning:

Error in .C("spline_coef", method = as.integer(method),
n = n, x = as.double(x),  :
  "spline_coef" not available for .C() for package "stats"
In addition: Warning message:
In if (d < 0) stop("d can not be negative in call to
null.space.dimension().") :
  the condition has length > 1 and only the first element
will be used

The part of the posum code that this error refers to is the
following:


cm.splinefun<-function(x, y = NULL, method = "fmm",gulim=0)

# modification of base package splinefun to produce co-monotonic
#interpolant
# by Hyman Filtering. if gulim!=0 then it is taken as the upper
# limit on the gradient.
{   x <- xy.coords(x, y)
    y <- x$y
    x <- x$x
    n <- length(x)
    method <- match(method, c("periodic", "natural", "fmm"))
    if (is.na(method))
        stop("splinefun: invalid interpolation method")
    if (any(diff(x) < 0)) {
        z <- order(x)
        x <- x[z]
        y <- y[z]
    }
    if (method == 1 && y[1] != y[n]) {
        warning("first and last y values differ in spline -
using y[1] for both")
        y[n] <- y[1]
    }
    z <- .C("spline_coef", method = as.integer(method), n = n,
        x = as.double(x), y = as.double(y), b = double(n),
c = double(n), d = double(n),
        e = double(if (method == 1) n else 0), PACKAGE = "stats")

    z$y<-z$y-z$x*gulim # trick to impose upper
    z$b<-z$b-gulim     # limit on interpolator gradient

    z<-hyman.filter(z) # filter gradients for co-monotonicity

    z$y<-z$y+z$x*gulim # undo trick
    z$b<-z$b+gulim     # transformation

    z<-spl.coef.conv(z) # force other coefficients to consistency

    rm(x, y, n, method)
    function(x) {
        .C("spline_eval", z$method, length(x), x = as.double(x),
            y = double(length(x)), z$n, z$x, z$y, z$b, z$c, z$d,
            PACKAGE = "stats")$y
    }
}


And finally:

> sessionInfo()
R version 3.1.0 (2014-04-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=
English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C

[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  base

other attached packages:
[1] posum_2.0-0 mgcv_0.8-7

loaded via a namespace (and not attached):
[1] tools_3.1.0


I hope this is a more acceptable formulation of the problem!

Best wishes,
Lotte de Vries (Master student theoretical biology)



On Sat, Aug 16, 2014 at 3:24 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Aug 15, 2014, at 2:56 PM, Charlotte de Vries wrote:
>
> > David Winsemius <dwinsemius <at> comcast.net> writes:
> >
> >>
> >>
> >> On Aug 15, 2014, at 8:06 AM, Charlotte de Vries wrote:
> >>
> >>> Hey there!
> >>>
> >>> I'm having problems with the same code, but I get a different error:
> >>
> >> This is apparently yet another example demonstrating why the Posting
> Guide
> > suggests that you include the
> >> text of any earlier posting to which you want us to consider. At the
> > moment I see no posting that has this subject.
> >>
> >>>
> >>> Error in .C("spline_coef", method = as.integer(method), n = n, x =
> >>> as.double(x),  :
> >>> "spline_coef" not available for .C() for package "stats"
> >>>
> >>>
> >>> I'm using R3.1.0 on windows 8 and I've never used R before, so I might
> > have
> >>> made some terrible newby error (I have programmed quite a bit before,
> > but in C
> >>> and Matlab).
> >>>
> >>> Thank you!
> >>>
> >>> Best,
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >>
> >>
> >
> > Hi David,
> >
> > Thank you for answering. The original message I replied to was this
> message
> > (http://comments.gmane.org/gmane.comp.lang.r.general/113245):
> >
> > **********************************************
>
> Well, that explains why I don't have a copy on my machine. It's dated 6
> May 18:15 2008
>
>
> > Hi all,
> >
> > I have issues using some basic functions in R such as these ones :
>
> pp.test is not a "basic R function". I get this:
>
> > ?pp.test
> No documentation for ?pp.test? in specified packages and libraries:
> you could try ???pp.test?
>
> You are asked to include the package name for non-base R functions.
>
> >
> >> pp.test(R) (where is a vector of returns)
> > Error in .C("R_approx", as.double(x), as.double(y), as.integer(nx), xout
> =
> > as.double(xout),  :
> >  C symbol name "R_approx" not in DLL for package "base"
> >
> >> boxcox(reg,plotit=T)  (where reg is an lm object)
> > Error in .C("spline_coef", method = as.integer(method), n =
> as.integer(nx),
> > :
> >  C symbol name "spline_coef" not in DLL for package "base"
>
> Well I do have the MASS package from which that function was loaded.
>
> I get no error with the example in the help page:
>
>  boxcox(Days+1 ~ Eth*Sex*Age*Lrn, data = quine,
>          lambda = seq(-0.05, 0.45, len = 20), plotit=TRUE)
>
> ... and you are not providing a reproducible example that provokes the
> error, nor are you providing the version numbers of R or MASS.
>
>
> >
> > as I do miss some symbol names.
> >
> > How can I overcome this serious problem ?
> > ***********************************
> >
> > But someone else reported a very similar problem (oddly enough using the
> > same function spline_coef but this time from the package stats rather
> than
> > base (http://comments.gmane.org/gmane.comp.lang.r.general/115420):
>
> Which was in turn dated: 2 Jun 06:04 2008
>
>
> > ************************************
> > Subject: Missing "spline_coef" DLL and Rob Hyndmans monotonic
> interpolator
> >
> > Hello R help
> >
> > I have been trying to use Rob Hyndman's monotonically increasing spline
> > function.  But like another user or two seem have a problem with a
> > missing DLL (namely "spline_coef").  None of the previous help postings
> > seemed to have any solutions to this problem.  As per a Ripley
> > suggestion I have deleted all previous versions of R and reinstalled R
> > 2.7.0 and the problem persists.
> >
> > Thanks
> >
> > Paul.
> >
> > x <- seq(0,4,l=20)
> >
> > y <- sort(rnorm(20))
> >
> > plot(x,y)
> > lines(spline(x, y, n = 201), col = 2) # Not necessarily monotonic
> > lines(cm.spline(x, y, n = 201), col = 3)
>
> I get no error after:
>
> library(demography)
>
> # And then running that code.
>
> I have an almost up-to-date version of R running on a mac (and at the
> moment I have way too many packages loaded:
>
> > sessionInfo()
> R version 3.1.0 Patched (2014-04-21 r65431)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] grDevices datasets  splines   graphics  utils     stats
> [7] grid      methods   base
>
> other attached packages:
>  [1] demography_1.17  ftsa_3.9         rainbow_3.2
>  [4] pcaPP_1.9-49     forecast_5.4     timeDate_3010.98
>  [7] zoo_1.7-11       XML_3.98-1.1     RCurl_1.95-4.3
> [10] bitops_1.0-6     subplex_1.1-4    MASS_7.3-31
> [13] cobs_1.2-2       quantreg_5.05    gplots_2.13.0
> [16] reshape2_1.2.2   ggplot2_0.9.3.1  multcomp_1.3-1
> [19] TH.data_1.0-3    mvtnorm_0.9-9999 data.table_1.9.2
> [22] muhaz_1.2.5      downloader_0.3   RJSONIO_1.3-0
> [25] plot3D_1.0-1     rms_4.2-0        SparseM_1.03
> [28] Hmisc_3.14-4     Formula_1.1-1    survival_2.37-7
> [31] sos_1.3-8        brew_1.0-6       lattice_0.20-29
>
> loaded via a namespace (and not attached):
>  [1] caTools_1.16        cluster_1.15.2      colorspace_1.2-4
>  [4] descr_1.0.3         dichromat_2.0-0     digest_0.6.4
>  [7] fracdiff_1.4-2      gdata_2.13.3        gtable_0.1.2
> [10] gtools_3.4.0        hdrcde_3.1          KernSmooth_2.23-12
> [13] ks_1.9.1            labeling_0.2        latticeExtra_0.6-26
> [16] Matrix_1.1-3        mgcv_1.7-29         misc3d_0.8-4
> [19] munsell_0.4.2       nlme_3.1-117        nnet_7.3-8
> [22] parallel_3.1.0      plyr_1.8.1          proto_0.3-10
> [25] quadprog_1.5-5      RColorBrewer_1.0-5  Rcpp_0.11.1
> [28] rgl_0.93.996        sandwich_2.3-0      scales_0.2.3
> [31] stringr_0.6.2       tools_3.1.0         tseries_0.10-32
> [34] xtable_1.7-3
>
>
> So that shows you how to provide some of the needed information (which
> neither of the postings to which you resonded had done.)  PLEASE read the
> Posting Guide.
>
>
> >> Error in .C("spline_coef", method = as.integer(method), n = nx, x = x,
> > :
> >        C symbol name "spline_coef" not in DLL for package "stats"
> >
> > Cm.spline code from
> > http://www-personal.buseco.monash.edu.au/~hyndman/Rlibrary/interpcode.R
> > **********************************
> >
> > I hope that helps, thank you :)! I've tried calling spline_coef from both
> > stats and base, but I get the same error for both packages. I've also
> tried
> > the solution suggested to these people, which was to remove any other R
> > versions on my laptop.
> >
> > Best,
> > Lotte
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From kevin2059 at 163.com  Sun Aug 17 01:32:19 2014
From: kevin2059 at 163.com (kevin2059)
Date: Sun, 17 Aug 2014 07:32:19 +0800 (CST)
Subject: [R] BNF description for R
Message-ID: <5296eb1a.219.147e12a1f4e.Coremail.kevin2059@163.com>

HOW can I get a completely BNF description for R? I try to  write a parser for R now.
	[[alternative HTML version deleted]]


From contact.dtb at gmail.com  Sun Aug 17 03:36:39 2014
From: contact.dtb at gmail.com (Daniel Braithwaite)
Date: Sat, 16 Aug 2014 20:36:39 -0500
Subject: [R] "no visible binding for global variable" and with() vs. within()
Message-ID: <CAJb81Sns6GODzXpoHyRdAFwg8JiDWkX9TSAdDmPMmjp1RWhWUw@mail.gmail.com>

R CMD check does not object to this code when checking a package:

foo1 <- function (bar) {
    with(bar, {
        x })
}

but produces a warning:

foo2: no visible binding for global variable 'x'

in response to this:

foo2 <- function (bar) {
    within(bar, {
        x })
}

Is this an R bug, or at least, an inadvertent inconsistency?  Here is
sessionInfo() from my machine, right after starting an interactive session:

R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Sun Aug 17 03:31:11 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sun, 17 Aug 2014 11:31:11 +1000
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
	<CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
	<CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>
Message-ID: <CAKL8G3FMFVbYo8vdAxU-j-Kv-ieo+2x8phcFrdsYXODa0La1FQ@mail.gmail.com>

Dear Kate,

Try this:

res <- do.call(rbind, lapply(xs, function(l){
 l$PID <- l$MID <- 0
father <- with(l, Relationship == 'father')
 mother <- with(l, Relationship == 'mother')
 if(sum(father) == 0)
l$PID[l$Relationship == 'sibling'] <- 0
 else l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
 if(sum(mother) == 0)
l$MID[l$Relationship == 'sibling'] <- 0
 else l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
 l
}))

It is assumed that when either parent is not available the M/PID is 0.

Best,
Jorge.-


On Sun, Aug 17, 2014 at 10:58 AM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> Actually - I didn't check this before, but these are not all nuclear
> families (as I assumed they were).  That is, some don't have a father
> or don't have a mother.... Usually if this is the case PID or MID will
> become 0, respectively, for the child.  How can the code be edit to
> account for this?
>
> On Sat, Aug 16, 2014 at 8:02 PM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
> > Thanks!
> >
> > I think I know what is being done here but not sure how to fix the
> > following error:
> >
> > Error in l$PID[l$\Relationship == "sibling"] <- l$Sample.ID[father] :
> >   replacement has length zero
> >
> >
> >
> > On Sat, Aug 16, 2014 at 6:48 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
> >> Dear Kate,
> >>
> >> Assuming you have nuclear families, one option would be:
> >>
> >> x <- read.table(textConnection("Family.ID Sample.ID Relationship
> >> 14           62  sibling
> >> 14          94  father
> >> 14           63  sibling
> >> 14           59 mother
> >> 17         6004  father
> >> 17           6003 mother
> >> 17         6005   sibling
> >> 17         368   sibling
> >> 130           202 mother
> >> 130           203  father
> >> 130           204   sibling
> >> 130           205   sibling
> >> 130           206   sibling
> >> 222         9 mother
> >> 222         45  sibling
> >> 222         34  sibling
> >> 222         10  sibling
> >> 222         11  sibling
> >> 222         18  father"), header = TRUE)
> >> closeAllConnections()
> >>
> >> xs <- with(x, split(x, Family.ID))
> >> res <- do.call(rbind, lapply(xs, function(l){
> >> l$PID <- l$MID <- 0
> >> father <- with(l, Relationship == 'father')
> >> mother <- with(l, Relationship == 'mother')
> >> l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
> >> l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
> >> l
> >> }))
> >> res
> >>
> >> HTH,
> >> Jorge.-
> >>
> >>
> >> Best regards,
> >> Jorge.-
> >>
> >>
> >>
> >> On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius <kate.ignatius at gmail.com
> >
> >> wrote:
> >>>
> >>> Hi,
> >>>
> >>> I have a data.table question (as well as if else statement query).
> >>>
> >>> I have a large list of families (file has 935 individuals that are
> >>> sorted by famiy of varying sizes).  At the moment the file has the
> >>> columns:
> >>>
> >>> SampleID FamilyID Relationship
> >>>
> >>> To prevent from having to make a pedigree file by hand - ie adding a
> >>> PaternalID and a MaternalID one by one I want to try write a script
> >>> that will quickly do this for me  (I eventually want to run this
> >>> through a program such as plink)   Is there a way to use data.table
> >>> (maybe in conjucntion with ifelse to do this effectively)?
> >>>
> >>> An example of the file is something like:
> >>>
> >>> Family.ID Sample.ID Relationship
> >>> 14           62  sibling
> >>> 14          94  father
> >>> 14           63  sibling
> >>> 14           59 mother
> >>> 17         6004  father
> >>> 17           6003 mother
> >>> 17         6005   sibling
> >>> 17         368   sibling
> >>> 130           202 mother
> >>> 130           203  father
> >>> 130           204   sibling
> >>> 130           205   sibling
> >>> 130           206   sibling
> >>> 222         9 mother
> >>> 222         45  sibling
> >>> 222         34  sibling
> >>> 222         10  sibling
> >>> 222         11  sibling
> >>> 222         18  father
> >>>
> >>> But the goal is to have a file like this:
> >>>
> >>> Family.ID Sample.ID Relationship PID MID
> >>> 14           62  sibling 94 59
> >>> 14          94  father 0 0
> >>> 14           63  sibling 94 59
> >>> 14           59 mother 0 0
> >>> 17         6004  father 0 0
> >>> 17           6003 mother 0 0
> >>> 17         6005   sibling 6004 6003
> >>> 17         368   sibling 6004 6003
> >>> 130           202 mother 0 0
> >>> 130           203  father 0 0
> >>> 130           204   sibling 203 202
> >>> 130           205   sibling 203 202
> >>> 130           206   sibling 203 202
> >>> 222         9 mother 0 0
> >>> 222         45  sibling 18 9
> >>> 222         34  sibling 18 9
> >>> 222         10  sibling 18 9
> >>> 222         11  sibling 18 9
> >>> 222         18  father 0 0
> >>>
> >>> I've tried searches for this but with no luck.  Greatly appreciate any
> >>> help - even if its just a link to a great example/solution!
> >>>
> >>> Thanks!
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
>

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Sun Aug 17 03:53:08 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Sun, 17 Aug 2014 11:53:08 +1000
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAE6QMsYzRbUF5qZHwNJ=ADqfg8G6+Wn0kN3mR0C+PgzYEXY1AQ@mail.gmail.com>
References: <CAE6QMsa2WtCBQK33jYQQsOobfg7ppoYxLnAwrHgOxmeaFjQt6g@mail.gmail.com>
	<CAKL8G3HGo3Ph2WPoHTuhx6ryKOh8oKDTd9QG1CHGjRzuDqdCQg@mail.gmail.com>
	<CAE6QMsa4XW_LGKQnrUM=v1aY6AbmBGj0ENMu1nwGdeoe1KJsog@mail.gmail.com>
	<CAE6QMsZ-Wh+L8PstCk6yPV5efZk8RysmhfJ776ri6DChg21f5A@mail.gmail.com>
	<CAKL8G3FMFVbYo8vdAxU-j-Kv-ieo+2x8phcFrdsYXODa0La1FQ@mail.gmail.com>
	<CAE6QMsYzRbUF5qZHwNJ=ADqfg8G6+Wn0kN3mR0C+PgzYEXY1AQ@mail.gmail.com>
Message-ID: <CAKL8G3F=a3w_fVeMOtZZFyaFVHHX2dSeh5XJOj9epJjd2f676w@mail.gmail.com>

Perhaps I am missing something but I do not get the same result:

x <- read.table(textConnection("Family.ID Sample.ID Relationship
2702  349       mother
2702  3456  sibling
2702  9980  sibling
3064  3  father
3064  4  mother
3064  5    sibling
3064  86   sibling
3064  87   sibling"), header = TRUE)
closeAllConnections()

xs <- with(x, split(x, Family.ID))
res <- do.call(rbind, lapply(xs, function(l){
 l$PID <- l$MID <- 0
father <- with(l, Relationship == 'father')
 mother <- with(l, Relationship == 'mother')
 if(sum(father) == 0)
l$PID[l$Relationship == 'sibling'] <- 0
 else l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
 if(sum(mother) == 0)
l$MID[l$Relationship == 'sibling'] <- 0
 else l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
 l
}))
 #Family.ID Sample.ID Relationship MID PID
#2702.1      2702       349       mother   0   0
#2702.2      2702      3456      sibling 349   0
#2702.3      2702      9980      sibling 349   0
#3064.4      3064         3       father   0   0
#3064.5      3064         4       mother   0   0
#3064.6      3064         5      sibling   4   3
#3064.7      3064        86      sibling   4   3
#3064.8      3064        87      sibling   4   3

HTH,
Jorge.-




On Sun, Aug 17, 2014 at 11:47 AM, Kate Ignatius <kate.ignatius at gmail.com>
wrote:

> Yep - you're right - missing parents are indicated as zero in the M/PID
> field.
>
> The above code worked with a few errors:
>
> 1: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
>   number of items to replace is not a multiple of replacement length
> 2: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
>   number of items to replace is not a multiple of replacement length
> 3: In l$PID[l$Relationship == "sibling"] <- l$Sample.ID[father] :
>   number of items to replace is not a multiple of replacement length
> 4: In l$MID[l$Relationship == "sibling"] <- l$Sample.ID[mother] :
>   number of items to replace is not a multiple of replacement length
>
> looking at the output I get numbers where the father/mother ID should
> be in the M/PID field.  For example:
>
> 2702  349       mother   0   0
> 2702  3456  sibling   0 842
> 2702  9980  sibling   0 842
> 3064  3  father   0   0
> 3064  4  mother   0   0
> 3064  5    sibling 879 880
> 3064  86   sibling 879 880
> 3064  87   sibling 879 880
>
> On Sat, Aug 16, 2014 at 9:31 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
> > Dear Kate,
> >
> > Try this:
> >
> > res <- do.call(rbind, lapply(xs, function(l){
> > l$PID <- l$MID <- 0
> > father <- with(l, Relationship == 'father')
> > mother <- with(l, Relationship == 'mother')
> > if(sum(father) == 0)
> > l$PID[l$Relationship == 'sibling'] <- 0
> > else l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
> > if(sum(mother) == 0)
> > l$MID[l$Relationship == 'sibling'] <- 0
> > else l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
> > l
> > }))
> >
> > It is assumed that when either parent is not available the M/PID is 0.
> >
> > Best,
> > Jorge.-
> >
> >
> > On Sun, Aug 17, 2014 at 10:58 AM, Kate Ignatius <kate.ignatius at gmail.com
> >
> > wrote:
> >>
> >> Actually - I didn't check this before, but these are not all nuclear
> >> families (as I assumed they were).  That is, some don't have a father
> >> or don't have a mother.... Usually if this is the case PID or MID will
> >> become 0, respectively, for the child.  How can the code be edit to
> >> account for this?
> >>
> >> On Sat, Aug 16, 2014 at 8:02 PM, Kate Ignatius <kate.ignatius at gmail.com
> >
> >> wrote:
> >> > Thanks!
> >> >
> >> > I think I know what is being done here but not sure how to fix the
> >> > following error:
> >> >
> >> > Error in l$PID[l$\Relationship == "sibling"] <- l$Sample.ID[father] :
> >> >   replacement has length zero
> >> >
> >> >
> >> >
> >> > On Sat, Aug 16, 2014 at 6:48 PM, Jorge I Velez
> >> > <jorgeivanvelez at gmail.com> wrote:
> >> >> Dear Kate,
> >> >>
> >> >> Assuming you have nuclear families, one option would be:
> >> >>
> >> >> x <- read.table(textConnection("Family.ID Sample.ID Relationship
> >> >> 14           62  sibling
> >> >> 14          94  father
> >> >> 14           63  sibling
> >> >> 14           59 mother
> >> >> 17         6004  father
> >> >> 17           6003 mother
> >> >> 17         6005   sibling
> >> >> 17         368   sibling
> >> >> 130           202 mother
> >> >> 130           203  father
> >> >> 130           204   sibling
> >> >> 130           205   sibling
> >> >> 130           206   sibling
> >> >> 222         9 mother
> >> >> 222         45  sibling
> >> >> 222         34  sibling
> >> >> 222         10  sibling
> >> >> 222         11  sibling
> >> >> 222         18  father"), header = TRUE)
> >> >> closeAllConnections()
> >> >>
> >> >> xs <- with(x, split(x, Family.ID))
> >> >> res <- do.call(rbind, lapply(xs, function(l){
> >> >> l$PID <- l$MID <- 0
> >> >> father <- with(l, Relationship == 'father')
> >> >> mother <- with(l, Relationship == 'mother')
> >> >> l$PID[l$Relationship == 'sibling'] <- l$Sample.ID[father]
> >> >> l$MID[l$Relationship == 'sibling'] <- l$Sample.ID[mother]
> >> >> l
> >> >> }))
> >> >> res
> >> >>
> >> >> HTH,
> >> >> Jorge.-
> >> >>
> >> >>
> >> >> Best regards,
> >> >> Jorge.-
> >> >>
> >> >>
> >> >>
> >> >> On Sun, Aug 17, 2014 at 5:42 AM, Kate Ignatius
> >> >> <kate.ignatius at gmail.com>
> >> >> wrote:
> >> >>>
> >> >>> Hi,
> >> >>>
> >> >>> I have a data.table question (as well as if else statement query).
> >> >>>
> >> >>> I have a large list of families (file has 935 individuals that are
> >> >>> sorted by famiy of varying sizes).  At the moment the file has the
> >> >>> columns:
> >> >>>
> >> >>> SampleID FamilyID Relationship
> >> >>>
> >> >>> To prevent from having to make a pedigree file by hand - ie adding a
> >> >>> PaternalID and a MaternalID one by one I want to try write a script
> >> >>> that will quickly do this for me  (I eventually want to run this
> >> >>> through a program such as plink)   Is there a way to use data.table
> >> >>> (maybe in conjucntion with ifelse to do this effectively)?
> >> >>>
> >> >>> An example of the file is something like:
> >> >>>
> >> >>> Family.ID Sample.ID Relationship
> >> >>> 14           62  sibling
> >> >>> 14          94  father
> >> >>> 14           63  sibling
> >> >>> 14           59 mother
> >> >>> 17         6004  father
> >> >>> 17           6003 mother
> >> >>> 17         6005   sibling
> >> >>> 17         368   sibling
> >> >>> 130           202 mother
> >> >>> 130           203  father
> >> >>> 130           204   sibling
> >> >>> 130           205   sibling
> >> >>> 130           206   sibling
> >> >>> 222         9 mother
> >> >>> 222         45  sibling
> >> >>> 222         34  sibling
> >> >>> 222         10  sibling
> >> >>> 222         11  sibling
> >> >>> 222         18  father
> >> >>>
> >> >>> But the goal is to have a file like this:
> >> >>>
> >> >>> Family.ID Sample.ID Relationship PID MID
> >> >>> 14           62  sibling 94 59
> >> >>> 14          94  father 0 0
> >> >>> 14           63  sibling 94 59
> >> >>> 14           59 mother 0 0
> >> >>> 17         6004  father 0 0
> >> >>> 17           6003 mother 0 0
> >> >>> 17         6005   sibling 6004 6003
> >> >>> 17         368   sibling 6004 6003
> >> >>> 130           202 mother 0 0
> >> >>> 130           203  father 0 0
> >> >>> 130           204   sibling 203 202
> >> >>> 130           205   sibling 203 202
> >> >>> 130           206   sibling 203 202
> >> >>> 222         9 mother 0 0
> >> >>> 222         45  sibling 18 9
> >> >>> 222         34  sibling 18 9
> >> >>> 222         10  sibling 18 9
> >> >>> 222         11  sibling 18 9
> >> >>> 222         18  father 0 0
> >> >>>
> >> >>> I've tried searches for this but with no luck.  Greatly appreciate
> any
> >> >>> help - even if its just a link to a great example/solution!
> >> >>>
> >> >>> Thanks!
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-help at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> PLEASE do read the posting guide
> >> >>> http://www.R-project.org/posting-guide.html
> >> >>> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >>
> >
> >
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Aug 17 13:05:52 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 17 Aug 2014 07:05:52 -0400
Subject: [R] "no visible binding for global variable" and with() vs.
	within()
In-Reply-To: <CAJb81Sns6GODzXpoHyRdAFwg8JiDWkX9TSAdDmPMmjp1RWhWUw@mail.gmail.com>
References: <CAJb81Sns6GODzXpoHyRdAFwg8JiDWkX9TSAdDmPMmjp1RWhWUw@mail.gmail.com>
Message-ID: <53F08C90.70902@gmail.com>

On 16/08/2014, 9:36 PM, Daniel Braithwaite wrote:
> R CMD check does not object to this code when checking a package:
> 
> foo1 <- function (bar) {
>     with(bar, {
>         x })
> }
> 
> but produces a warning:
> 
> foo2: no visible binding for global variable 'x'
> 
> in response to this:
> 
> foo2 <- function (bar) {
>     within(bar, {
>         x })
> }
> 
> Is this an R bug, or at least, an inadvertent inconsistency?  Here is
> sessionInfo() from my machine, right after starting an interactive session:

I'm not sure, but I suspect it's an intentional inconsistency.  The code
that checks for use of globals can't do anything in with() or within()
code, so bugs can slip by if you use those.  I think with() had been
around for a long time and was in wide use when that test was added, but
within() is newer, and it was less disruptive to warn about it, so the
warning has been left in.  (I don't remember whether the test came
before or after within() was introduced.)

So if you want to avoid the warning, don't use within().

Duncan Murdoch

> 
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Sun Aug 17 13:09:00 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 17 Aug 2014 07:09:00 -0400
Subject: [R] BNF description for R
In-Reply-To: <5296eb1a.219.147e12a1f4e.Coremail.kevin2059@163.com>
References: <5296eb1a.219.147e12a1f4e.Coremail.kevin2059@163.com>
Message-ID: <53F08D4C.90606@gmail.com>

On 16/08/2014, 7:32 PM, kevin2059 wrote:
> HOW can I get a completely BNF description for R? I try to  write a parser for R now.

The R grammar is defined in the src/main/gram.y file (in Bison format).
 You can get that file from
https://svn.r-project.org/R/trunk/src/main/gram.y.

Duncan Murdoch


From kate.ignatius at gmail.com  Sun Aug 17 18:32:02 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Sun, 17 Aug 2014 12:32:02 -0400
Subject: [R] ggplot2/heat map/duplicated level problem
Message-ID: <CAE6QMsZNyYA=t9_2qpLdWBFiQVYJYif2GLVNt2qddMRU-TqaSg@mail.gmail.com>

Hi,

I hope I can explain my problem clearly....

I have a plink output file that I want to graph a heat map of the
PI_HAT estimates.  I have the following code that I has worked in the
past but this time I'm getting the error:

In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else
paste0(labels,  :
  duplicated levels in factors are deprecated

My code:

require("ggplot2")

image = (p <- ggplot(db, aes(IID1, IID2)) +
   geom_tile(aes(fill = PI_HAT), colour = "white") +
   scale_fill_gradient2(low = "blue", high = "red") +
   labs(x = "Individual 1",y = "Individual 2")
   opts(axis.text.x = theme_text(angle=90)) +
   opts(title="",legend.position = "right"))

I'm trying to figure out whether this is a problem with duplicated
PI-HAT estimates or duplicated ID pairings (though the latter
shouldn't be the case as I've used similar files in the past).

What else could be the problem?

P.S.  My file is quite large (300K lines) so its pretty hard to
decipher the problem off the bat but the usual plink output file for
this type of file has the heading:

    FID1       IID1    FID2       IID2 RT    EZ      Z0      Z1      Z2  PI_HAT


From Ted.Harding at wlandres.net  Sun Aug 17 20:41:48 2014
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sun, 17 Aug 2014 19:41:48 +0100 (BST)
Subject: [R] data.table/ifelse conditional new variable question
In-Reply-To: <CAAJSdji8LU=toOSS_Q9C42Nd6DauiWns3FZgcoNXnk0ZpeTu3Q@mail.gmail.com>
Message-ID: <XFMail.20140817194148.Ted.Harding@wlandres.net>

On 17-Aug-2014 03:50:33 John McKown wrote:
> On Sat, Aug 16, 2014 at 9:02 PM, Kate Ignatius <kate.ignatius at gmail.com>
> wrote:
> 
>> Actually - your code is not wrong... because this is a large file I
>> went through the file to see if there was anything wrong with it -
>> looks like there are two fathers or three mothers in some families.
>> Taking these duplicates out fixed the problem.
>>
>> Sorry about the confusion!  And thanks so much for your help!
>>
>>
> Kate,
> I hope you don't mind, but I have a curiosity question on my part.
> Were the families with multiple fathers or mothers a mistake, just
> duplicates (same Family.ID & Sample.ID), or more like an "intermixed"
> family due to divorce and remarriage. Or even, like in some countries,
> a case of polygamy? Sorry, I just get curious about the strangest
> things sometimes.
> -- 
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown

When Kate first posted her query, similar thoughts to John's occurred
to me. The potential for convoluted ancestry and kinship is enormous!

For perhaps (or perhaps not) ultimate convolution, try reconstructing
a canine pedigree from a breeding register of thoroughbreds, where
again the primary data is for each individual is
  * ID of individual
  * ID of litter the individual was born in ("family")
  * ID of male parent
  * ID of female parent
(as, for instance, registered with the UK Kennel Club).

Similar convolutions can be found with race-horses.

But even humans can compete. Here is a little challenge for anyone
who has an R program that will work out a pedigree from data such as
described above. I have used Kate's notation. Individuals are numbered
from 1 up (with a gap): Sample.ID; Families from 101 up: Family.ID.
Relationships are "sibling", "father", "mother".

ID for father/mother may be "NA" (data not given).

Family.ID Sample.ID Relationship
101       01        sibling
101       02        father
101       03        mother

102       02        sibling
102       04        father
102       05        mother

103       03        sibling
103       06        father
103       07        mother

104       04        sibling
104       08        father
104       09        mother

104       05        sibling
104       08        father
104       09        mother

104       06        sibling
104       08        father
104       09        mother

104       15        sibling
104       08        father
104       09        mother

105       07        sibling
105       04        father
105       15        mother

106       08        sibling
106       16        father
106       17        mother

106       18        sibling
106       16        father
106       17        mother

106       19        sibling
106       16        father
106       17        mother

107       09        sibling
107       18        father
107       19        mother

108       16        sibling
108       NA        father
108       NA        mother

109       17        sibling
109       NA        father
109       NA        mother

That's the data. Now a little quiz question: Can you guess the
identity of the person with sample.ID = 01 ?

Best wishes to all,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 17-Aug-2014  Time: 19:41:38
This message was sent by XFMail


From _ at thomaslevine.com  Sun Aug 17 21:58:07 2014
From: _ at thomaslevine.com (Thomas Levine)
Date: Sun, 17 Aug 2014 19:58:07 +0000
Subject: [R] Making my own graphics device
Message-ID: <20140817195807.GA18595@d1stkfactory>

I want to make my own graphics device am thus looking for
documentation about graphics devices.

The only thing I've found so far is these directions for
making graphics devices with the RGraphicsDevice package.
http://www.omegahat.org/RGraphicsDevice/

Could someone point me to any other resources? Or just
some documentation about how to edit base R? If I don't
get anything, I'm just going to stare at the grDevices
section of the R source code (src/library/grDevices/src)
until I figure out how it works.

In case you're curious, I want to make a graphics device
that saves the graph in Hewlett-Packard Graphics Language.
https://en.wikipedia.org/wiki/HPGL

Thanks

Tom


From rkoenker at illinois.edu  Sun Aug 17 22:11:23 2014
From: rkoenker at illinois.edu (Roger Koenker)
Date: Sun, 17 Aug 2014 15:11:23 -0500
Subject: [R] Making my own graphics device
In-Reply-To: <19b52ccd351d49608ba55683be137d00@CITESHT2.ad.uillinois.edu>
References: <19b52ccd351d49608ba55683be137d00@CITESHT2.ad.uillinois.edu>
Message-ID: <C78CAECB-57BB-4994-80A3-EE9D4E0C1676@illinois.edu>

In ancient times, ie circa 1981,  the S language certainly supported HP pen plotters
so there should be code somewhere that could be resuscitated, he said naively.

url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801
On Aug 17, 2014, at 2:58 PM, Thomas Levine <_ at thomaslevine.com> wrote:

> I want to make my own graphics device am thus looking for
> documentation about graphics devices.
> 
> The only thing I've found so far is these directions for
> making graphics devices with the RGraphicsDevice package.
> http://www.omegahat.org/RGraphicsDevice/
> 
> Could someone point me to any other resources? Or just
> some documentation about how to edit base R? If I don't
> get anything, I'm just going to stare at the grDevices
> section of the R source code (src/library/grDevices/src)
> until I figure out how it works.
> 
> In case you're curious, I want to make a graphics device
> that saves the graph in Hewlett-Packard Graphics Language.
> https://en.wikipedia.org/wiki/HPGL
> 
> Thanks
> 
> Tom
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Sun Aug 17 22:47:36 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Mon, 18 Aug 2014 08:47:36 +1200
Subject: [R] "no visible binding for global variable" and with() vs.
	within()
In-Reply-To: <53F08C90.70902@gmail.com>
References: <CAJb81Sns6GODzXpoHyRdAFwg8JiDWkX9TSAdDmPMmjp1RWhWUw@mail.gmail.com>
	<53F08C90.70902@gmail.com>
Message-ID: <53F114E8.9090108@auckland.ac.nz>

On 17/08/14 23:05, Duncan Murdoch wrote:
> On 16/08/2014, 9:36 PM, Daniel Braithwaite wrote:
>> R CMD check does not object to this code when checking a package:
>>
>> foo1 <- function (bar) {
>>      with(bar, {
>>          x })
>> }
>>
>> but produces a warning:
>>
>> foo2: no visible binding for global variable 'x'
>>
>> in response to this:
>>
>> foo2 <- function (bar) {
>>      within(bar, {
>>          x })
>> }
>>
>> Is this an R bug, or at least, an inadvertent inconsistency?  Here is
>> sessionInfo() from my machine, right after starting an interactive session:
>
> I'm not sure, but I suspect it's an intentional inconsistency.  The code
> that checks for use of globals can't do anything in with() or within()
> code, so bugs can slip by if you use those.  I think with() had been
> around for a long time and was in wide use when that test was added, but
> within() is newer, and it was less disruptive to warn about it, so the
> warning has been left in.  (I don't remember whether the test came
> before or after within() was introduced.)
>
> So if you want to avoid the warning, don't use within().

Or you could have a file, say "melvin.R", in the R directory of your
package, containing the line:

  utils::globalVariables("x")

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS


From dwinsemius at comcast.net  Sun Aug 17 23:07:47 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 17 Aug 2014 14:07:47 -0700
Subject: [R] Making my own graphics device
In-Reply-To: <20140817195807.GA18595@d1stkfactory>
References: <20140817195807.GA18595@d1stkfactory>
Message-ID: <08E0FE2E-3AB6-4C64-8C8E-F12E2F31FB7E@comcast.net>


On Aug 17, 2014, at 12:58 PM, Thomas Levine wrote:

> I want to make my own graphics device am thus looking for
> documentation about graphics devices.
> 
> The only thing I've found so far is these directions for
> making graphics devices with the RGraphicsDevice package.
> http://www.omegahat.org/RGraphicsDevice/
> 
> Could someone point me to any other resources? Or just
> some documentation about how to edit base R? If I don't
> get anything, I'm just going to stare at the grDevices
> section of the R source code (src/library/grDevices/src)
> until I figure out how it works.
> 
> In case you're curious, I want to make a graphics device
> that saves the graph in Hewlett-Packard Graphics Language.
> https://en.wikipedia.org/wiki/HPGL
> 

I went out searching and thought I had found an answer in the archives, but I see it was authored by you, so it must not have been entirely satisfactory:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+hpgl#query:list%3Aorg.r-project.r-help%20hpgl+page:1+mid:sxly4345y6tbj4dw+state:results

I also saw the suggestion from Koenker. The current holder of the rights to the S language (at least on PC's)  would be TIBCO. They do list the acronym `hpgl` on one page in the S+ documentation, but it is in the "deprecated functions" section (p 39):

http://www.uni-koeln.de/themen/statistik/software/s/v81/functionguide.pdf

Good luck.

-- 

David Winsemius
Alameda, CA, USA


From _ at thomaslevine.com  Sun Aug 17 23:17:04 2014
From: _ at thomaslevine.com (Thomas Levine)
Date: Sun, 17 Aug 2014 21:17:04 +0000
Subject: [R] Making my own graphics device
In-Reply-To: <C78CAECB-57BB-4994-80A3-EE9D4E0C1676@illinois.edu>
References: <19b52ccd351d49608ba55683be137d00@CITESHT2.ad.uillinois.edu>
	<C78CAECB-57BB-4994-80A3-EE9D4E0C1676@illinois.edu>
Message-ID: <20140817211704.GA18816@d1stkfactory>

Thanks for this! I had a feeling that was the case;
the R graphics functions are so clearly designed for
use with pen plotters that I was puzzled by the absense
of an HPGL device.

And now I've found a list of some other interesting
devices on page 71 of Modern Applied Statistics with S.

This Wikipedia article says that S source code was released
in 1981. (I never knew!)
https://en.wikipedia.org/wiki/S_%28programming_language%29

So I'm going to look for publications related to S from 1981.
Say something if you have any tips for my search.

On 17 Aug 15:11, Roger Koenker wrote:
> In ancient times, ie circa 1981,  the S language certainly supported HP pen plotters
> so there should be code somewhere that could be resuscitated, he said naively.
> 
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
> On Aug 17, 2014, at 2:58 PM, Thomas Levine <_ at thomaslevine.com> wrote:
> 
> > I want to make my own graphics device am thus looking for
> > documentation about graphics devices.
> > 
> > The only thing I've found so far is these directions for
> > making graphics devices with the RGraphicsDevice package.
> > http://www.omegahat.org/RGraphicsDevice/
> > 
> > Could someone point me to any other resources? Or just
> > some documentation about how to edit base R? If I don't
> > get anything, I'm just going to stare at the grDevices
> > section of the R source code (src/library/grDevices/src)
> > until I figure out how it works.
> > 
> > In case you're curious, I want to make a graphics device
> > that saves the graph in Hewlett-Packard Graphics Language.
> > https://en.wikipedia.org/wiki/HPGL
> > 
> > Thanks
> > 
> > Tom
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From paul at stat.auckland.ac.nz  Sun Aug 17 23:35:02 2014
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Mon, 18 Aug 2014 09:35:02 +1200
Subject: [R] Making my own graphics device
In-Reply-To: <20140817195807.GA18595@d1stkfactory>
References: <20140817195807.GA18595@d1stkfactory>
Message-ID: <53F12006.2030309@stat.auckland.ac.nz>

Hi

On 08/18/14 07:58, Thomas Levine wrote:
> I want to make my own graphics device am thus looking for
> documentation about graphics devices.
>
> The only thing I've found so far is these directions for
> making graphics devices with the RGraphicsDevice package.
> http://www.omegahat.org/RGraphicsDevice/

That is certainly a good way to get something going quickly at least
(I used it just the other day and had something up and running in under 
an hour, based on the inst/examples/SVG/svgDev.R example)

> Could someone point me to any other resources? Or just
> some documentation about how to edit base R? If I don't
> get anything, I'm just going to stare at the grDevices
> section of the R source code (src/library/grDevices/src)
> until I figure out how it works.

The "canonical" approach is to look at the source code for one of the 
built-in devices in the R source code and change it to do what you want 
(e.g., src/modules/X11/devX11.c).  The file 
src/include/R_ext/GraphicsDevice.h has comments describing how the 
graphics device should be set up.  See the RSvgDevice package for an 
example of a device implemented in a package.

Paul

> In case you're curious, I want to make a graphics device
> that saves the graph in Hewlett-Packard Graphics Language.
> https://en.wikipedia.org/wiki/HPGL
>
> Thanks
>
> Tom
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From murdoch.duncan at gmail.com  Sun Aug 17 23:58:49 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 17 Aug 2014 17:58:49 -0400
Subject: [R] Making my own graphics device
In-Reply-To: <C78CAECB-57BB-4994-80A3-EE9D4E0C1676@illinois.edu>
References: <19b52ccd351d49608ba55683be137d00@CITESHT2.ad.uillinois.edu>
	<C78CAECB-57BB-4994-80A3-EE9D4E0C1676@illinois.edu>
Message-ID: <53F12599.5090405@gmail.com>


> On Aug 17, 2014, at 2:58 PM, Thomas Levine <_ at thomaslevine.com> wrote:
> 
>> I want to make my own graphics device am thus looking for
>> documentation about graphics devices.
>>
>> The only thing I've found so far is these directions for
>> making graphics devices with the RGraphicsDevice package.
>> http://www.omegahat.org/RGraphicsDevice/
>>
>> Could someone point me to any other resources? Or just
>> some documentation about how to edit base R? If I don't
>> get anything, I'm just going to stare at the grDevices
>> section of the R source code (src/library/grDevices/src)
>> until I figure out how it works.
>>
>> In case you're curious, I want to make a graphics device
>> that saves the graph in Hewlett-Packard Graphics Language.
>> https://en.wikipedia.org/wiki/HPGL


There's a chapter on this in the R Internals manual.

Duncan Murdoch


From dwinsemius at comcast.net  Mon Aug 18 00:23:43 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 17 Aug 2014 15:23:43 -0700
Subject: [R] Making my own graphics device
In-Reply-To: <53F12006.2030309@stat.auckland.ac.nz>
References: <20140817195807.GA18595@d1stkfactory>
	<53F12006.2030309@stat.auckland.ac.nz>
Message-ID: <2A78B637-70FC-4F8A-8A85-1C6C27092190@comcast.net>


On Aug 17, 2014, at 2:35 PM, Paul Murrell wrote:

> Hi
> 
> On 08/18/14 07:58, Thomas Levine wrote:
>> I want to make my own graphics device am thus looking for
>> documentation about graphics devices.
>> 
>> The only thing I've found so far is these directions for
>> making graphics devices with the RGraphicsDevice package.
>> http://www.omegahat.org/RGraphicsDevice/
> 
> That is certainly a good way to get something going quickly at least
> (I used it just the other day and had something up and running in under an hour, based on the inst/examples/SVG/svgDev.R example)
> 
>> Could someone point me to any other resources? Or just
>> some documentation about how to edit base R? If I don't
>> get anything, I'm just going to stare at the grDevices
>> section of the R source code (src/library/grDevices/src)
>> until I figure out how it works.
> 
> The "canonical" approach is to look at the source code for one of the built-in devices in the R source code and change it to do what you want (e.g., src/modules/X11/devX11.c).  The file src/include/R_ext/GraphicsDevice.h has comments describing how the graphics device should be set up.  See the RSvgDevice package for an example of a device implemented in a package.

It may be useful to look at existing interfaces to an HPGL device in other graphics applications. One such application is xgraph and here is the C code for one implementation:

http://xgraph.sourcearchive.com/documentation/12.1-3/hpgl_8c-source.html

The other option might be to enlist an external program such as GNUPLOT that has an HPGL output and use it as a driver to which you send an image in a file format that R can produce.

-- 
David.
> 
> Paul
> 
>> In case you're curious, I want to make a graphics device
>> that saves the graph in Hewlett-Packard Graphics Language.
>> https://en.wikipedia.org/wiki/HPGL
>> 
>> Thanks
>> 
>> Tom
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kindlychung at gmail.com  Mon Aug 18 01:13:10 2014
From: kindlychung at gmail.com (Kaiyin Zhong (Victor Chung))
Date: Mon, 18 Aug 2014 01:13:10 +0200
Subject: [R] (no subject)
Message-ID: <CAOHtMfUtdosB8t5D48nUfqM9B86x5_a7c_u+qH29fJ7SgxaOBQ@mail.gmail.com>

Hi all.

I am having problems with inheritance in reference class, here is a small
example:

Myclass = setRefClass("Myclass",
                       fields = list(
                           fa = "numeric",
                           fb = "numeric",
                           filename = "character",
                           data = "data.frame"
                       ))


Myclass$methods(
    initialize = function(fa = 0, fb = 0, filename = "") {
        message("Initializing object in class...")
        .self$fa = fa
        .self$fb = fb
        .self$data = read.table(.self$filename, header=TRUE)
    })

# Myclass1 = setRefClass("Myclass1",#                        fields =
list(#                            fc = "numeric"#
  ),#                        contains = "Myclass"# )# #
Myclass1$methods(#     initialize = function(..., fc = 0) {#
message("Initializing object in class1...")#         callSuper(...)#
      .self$fc = fc#     }# )# # Myclass2 = setRefClass("Myclass3",#
                     fields = list(#                            fd =
"numeric"#                        ),#                        contains
= "Myclass1"# )# # Myclass2$methods(#     initialize = function(...,
fe = 0) {#         message("Initializing object in class2...")#
 callSuper(...)#         .self$fe = fe#     }# )

This loads ok. But if you uncomment the subclasses R will complain when
loading:

==> R CMD INSTALL --no-multiarch --with-keep.source testLoadRef
* installing to library
?/Library/Frameworks/R.framework/Versions/3.1/Resources/library?*
installing *source* package ?testLoadRef? ...** R** preparing package
for lazy loading
Initializing object in class...
Error in file(file, "rt") : invalid 'description' argument
Error : unable to load R code in package ?testLoadRef?
ERROR: lazy loading failed for package ?testLoadRef?* removing
?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/testLoadRef?*
restoring previous
?/Library/Frameworks/R.framework/Versions/3.1/Resources/library/testLoadRef?

Exited with status 1.


Best regards,

Kaiyin ZHONG
________________________________
FMB, Erasmus MC
http://kaiyin.co.vu
k.zhong at erasmusmc.nl
kindlychung at gmail.com

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Aug 18 01:31:56 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 17 Aug 2014 23:31:56 +0000
Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing
	A	Data	Frame
In-Reply-To: <696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
	<696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>

There is probably an easier way to do this, but

> set.seed(42)
> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
+  "green", "yellow", NA), 4))))
> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
> head(mydf)
   rank1  rank2  rank3 rank4
1   <NA> yellow    red  blue
2 yellow  green   <NA>   red
3 yellow  green   blue  <NA>
4   <NA>   blue yellow green
5   <NA>    red   blue green
6   <NA>    red  green  blue
> lvls <- levels(mydf$rank1)
> # convert color factors to numeric
> for (i in seq_along(mydf)) mydf[,i] <- as.numeric(mydf[,i]) 
> # stack the columns
> mydf2 <- stack(mydf)
> # convert rank factor to numeric
> mydf2$ind <- as.numeric(mydf2$ind)
> # add row numbers
> mydf2 <- data.frame(rows=1:100, mydf2)
> # Create table
> mytbl <- xtabs(ind~rows+values, mydf2)
> # convert to data frame
> mydf3 <- data.frame(unclass(mytbl))
> colnames(mydf3) <- lvls
> head(mydf3)
  blue green red yellow
1    4     0   3      2
2    0     2   4      1
3    3     2   0      1
4    2     4   0      3
5    3     4   2      0
6    4     3   2      0

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
Sent: Friday, August 15, 2014 3:58 PM
To: r-help at r-project.org
Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame


Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
Have I explained this problem sufficiently? 
I didn't think it would cause such a problem so I didn't include it in the original problem definition.
Yours, Simon
On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
> 
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> + "green", "yellow")))))
>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>> colnames(mydf2) <- levels(mydf$rank1)
>> head(mydf)
>   rank1  rank2  rank3 rank4
> 1 yellow  green    red  blue
> 2  green   blue yellow   red
> 3  green yellow    red  blue
> 4 yellow    red  green  blue
> 5 yellow    red  green  blue
> 6 yellow    red   blue green
>> head(mydf2)
>  blue green red yellow
> 1    4     2   3      1
> 2    2     1   4      3
> 3    4     1   3      2
> 4    4     3   2      1
> 5    4     3   2      1
> 6    3     4   2      1
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
> Sent: Friday, July 25, 2014 2:34 PM
> To: r-help at r-project.org
> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> Hello:
> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
> 
> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
> Thank you
> Simon
> #Reproducible code
> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
> 
> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From madhvi.gupta at orkash.com  Mon Aug 18 07:45:49 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Mon, 18 Aug 2014 11:15:49 +0530
Subject: [R] Fwd: error in installing rpud package
In-Reply-To: <53F1833D.3000906@orkash.com>
References: <53F1833D.3000906@orkash.com>
Message-ID: <53F1930D.2020106@orkash.com>




-------- Original Message --------
Subject: 	error in installing rpud package
Date: 	Mon, 18 Aug 2014 10:08:21 +0530
From: 	madhvi.gupta <madhvi.gupta at orkash.com>
To: 	r-help-request at r-project.org



Hello,
I am trying to install rpud package on R eith version 3.1.1 and i am 
getting this error

install.packages("rpud")
Installing package into '/home/shweta/R/x86_64-pc-linux-gnu-library/3.1'
(as 'lib' is unspecified)
trying URL 'http://cran.rstudio.com/src/contrib/rpud_0.0.2.tar.gz'
Content type 'application/x-gzip' length 78113 bytes (76 Kb)
opened URL
==================================================
downloaded 76 Kb

* installing *source* package 'rpud' ...
checking "environment variable CUDA_HOME"... "CUDA_HOME not set; using 
default /usr/local/cuda"
checking for /usr/local/cuda/bin/nvcc... yes
"nvcc found"
checking "whether this is the 64 bit linux version of CUDA"... checking 
for /usr/local/cuda/lib64/libcublas.so... yes
"yes -- using /usr/local/cuda/lib64 for CUDA libs"
"using -I/usr/share/R/include for R header files"
"using -Wl,--export-dynamic -fopenmp -L/usr/lib64/R/lib -lR -lrt -ldl 
-lm for R shared libraries"
configure: creating ./config.status
config.status: creating src/Makefile
** libs
** arch -
/usr/local/cuda/bin/nvcc -c -I/usr/local/cuda/include -Xcompiler 
"-I/usr/share/R/include -fpic" rpud.cu -o rpud.o
/usr/local/cuda/bin/nvcc -c -I/usr/local/cuda/include -Xcompiler 
"-I/usr/share/R/include -fpic" rpudist.cu -o rpudist.o
rpudist.cu(159): warning: use of "=" where "==" may have been intended

rpudist.cu(159): warning: use of "=" where "==" may have been intended

ptxas /tmp/tmpxft_000007b2_00000000-5_rpudist.ptx, line 904; warning : 
Double is not supported. Demoting to float
/usr/local/cuda/bin/nvcc -shared -Xlinker "-Wl,--export-dynamic -fopenmp 
-L/usr/lib64/R/lib -lR -lrt -ldl -lm -Wl,-rpath,/usr/local/cuda/lib64" 
-L/usr/local/cuda/lib64 -lcublas -lcuda rpud.o rpudist.o -o rpud.so
/usr/bin/ld: unrecognized option '-Wl'
/usr/bin/ld: use the --help option for usage information
collect2: ld returned 1 exit status
make: *** [rpud.so] Error 1
ERROR: compilation failed for package 'rpud'
* removing '/home/shweta/R/x86_64-pc-linux-gnu-library/3.1/rpud'
Warning in install.packages :
installation of package 'rpud' had non-zero exit status

The downloaded source packages are in
'/tmp/RtmpX5lR2g/downloaded_packages'

so please help me to get out of this.




	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Aug 18 08:16:21 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 17 Aug 2014 23:16:21 -0700
Subject: [R] Fwd: error in installing rpud package
In-Reply-To: <53F1930D.2020106@orkash.com>
References: <53F1833D.3000906@orkash.com> <53F1930D.2020106@orkash.com>
Message-ID: <51efe517-9191-4532-90c5-4dcc5b591e07@email.android.com>

Did you read the install instructions? I don't even know what this package does but it does have special instructions for installation.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 17, 2014 10:45:49 PM PDT, "madhvi.gupta" <madhvi.gupta at orkash.com> wrote:
>
>
>
>-------- Original Message --------
>Subject: 	error in installing rpud package
>Date: 	Mon, 18 Aug 2014 10:08:21 +0530
>From: 	madhvi.gupta <madhvi.gupta at orkash.com>
>To: 	r-help-request at r-project.org
>
>
>
>Hello,
>I am trying to install rpud package on R eith version 3.1.1 and i am 
>getting this error
>
>install.packages("rpud")
>Installing package into
>'/home/shweta/R/x86_64-pc-linux-gnu-library/3.1'
>(as 'lib' is unspecified)
>trying URL 'http://cran.rstudio.com/src/contrib/rpud_0.0.2.tar.gz'
>Content type 'application/x-gzip' length 78113 bytes (76 Kb)
>opened URL
>==================================================
>downloaded 76 Kb
>
>* installing *source* package 'rpud' ...
>checking "environment variable CUDA_HOME"... "CUDA_HOME not set; using 
>default /usr/local/cuda"
>checking for /usr/local/cuda/bin/nvcc... yes
>"nvcc found"
>checking "whether this is the 64 bit linux version of CUDA"... checking
>
>for /usr/local/cuda/lib64/libcublas.so... yes
>"yes -- using /usr/local/cuda/lib64 for CUDA libs"
>"using -I/usr/share/R/include for R header files"
>"using -Wl,--export-dynamic -fopenmp -L/usr/lib64/R/lib -lR -lrt -ldl 
>-lm for R shared libraries"
>configure: creating ./config.status
>config.status: creating src/Makefile
>** libs
>** arch -
>/usr/local/cuda/bin/nvcc -c -I/usr/local/cuda/include -Xcompiler 
>"-I/usr/share/R/include -fpic" rpud.cu -o rpud.o
>/usr/local/cuda/bin/nvcc -c -I/usr/local/cuda/include -Xcompiler 
>"-I/usr/share/R/include -fpic" rpudist.cu -o rpudist.o
>rpudist.cu(159): warning: use of "=" where "==" may have been intended
>
>rpudist.cu(159): warning: use of "=" where "==" may have been intended
>
>ptxas /tmp/tmpxft_000007b2_00000000-5_rpudist.ptx, line 904; warning : 
>Double is not supported. Demoting to float
>/usr/local/cuda/bin/nvcc -shared -Xlinker "-Wl,--export-dynamic
>-fopenmp 
>-L/usr/lib64/R/lib -lR -lrt -ldl -lm -Wl,-rpath,/usr/local/cuda/lib64" 
>-L/usr/local/cuda/lib64 -lcublas -lcuda rpud.o rpudist.o -o rpud.so
>/usr/bin/ld: unrecognized option '-Wl'
>/usr/bin/ld: use the --help option for usage information
>collect2: ld returned 1 exit status
>make: *** [rpud.so] Error 1
>ERROR: compilation failed for package 'rpud'
>* removing '/home/shweta/R/x86_64-pc-linux-gnu-library/3.1/rpud'
>Warning in install.packages :
>installation of package 'rpud' had non-zero exit status
>
>The downloaded source packages are in
>'/tmp/RtmpX5lR2g/downloaded_packages'
>
>so please help me to get out of this.
>
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From _ at thomaslevine.com  Mon Aug 18 08:25:55 2014
From: _ at thomaslevine.com (Thomas Levine)
Date: Mon, 18 Aug 2014 06:25:55 +0000
Subject: [R] Making my own graphics device
In-Reply-To: <2A78B637-70FC-4F8A-8A85-1C6C27092190@comcast.net>
References: <20140817195807.GA18595@d1stkfactory>
	<53F12006.2030309@stat.auckland.ac.nz>
	<2A78B637-70FC-4F8A-8A85-1C6C27092190@comcast.net>
Message-ID: <20140818062555.GA20565@d1stkfactory>

Thanks for the further tips! I'll look at the R Internals manual,
the other built-in devices, and the RSvgDevice package. And I'm
still looking for the S source code, but I have a feeling that I'll
wind up writing the device before I find the source code.

> It may be useful to look at existing interfaces to an HPGL device in other graphics applications. One such application is xgraph and here is the C code for one implementation:
> 
> http://xgraph.sourcearchive.com/documentation/12.1-3/hpgl_8c-source.html
> 
> The other option might be to enlist an external program such as GNUPLOT that has an HPGL output and use it as a driver to which you send an image in a file format that R can produce.

While this would be a good idea for pretty much any other file format,
it probably will make things more complicated for HPGL as the structure
of base R graphics is kind of exactly the same as HPGL.

Tom


From Haiko.Lietz at gesis.org  Mon Aug 18 10:51:57 2014
From: Haiko.Lietz at gesis.org (Lietz, Haiko)
Date: Mon, 18 Aug 2014 08:51:57 +0000
Subject: [R] filled.contour key axis
Message-ID: <D57FB3A7BE5E14479A21F7832D5F1B344FCE77BE@svboexc02.gesis.intra>

Hi all,

Using filled.contour...

foo <- matrix(seq(0.1, 0.9, 0.1), ncol = 3)
filled.contour(foo)

how can I set the key axis to give percentages?

And is there a way to automatically label the key axis except for placing text there?

Thanks

Haiko


Haiko Lietz
GESIS - Leibniz Institute for the Social Sciences
Department of Computational Social Science
Unter Sachsenhausen 6-8, D-50667 K?ln
Tel: + 49 (0) 221 / 476 94 -223
eMail: haiko.lietz at gesis.org<mailto:haiko.lietz at gesis.org>
Web: http://www.gesis.org<http://www.gesis.org/>


	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Mon Aug 18 14:41:40 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 18 Aug 2014 22:41:40 +1000
Subject: [R] filled.contour key axis
In-Reply-To: <D57FB3A7BE5E14479A21F7832D5F1B344FCE77BE@svboexc02.gesis.intra>
References: <D57FB3A7BE5E14479A21F7832D5F1B344FCE77BE@svboexc02.gesis.intra>
Message-ID: <7150397.LoKGASRY3C@localhost.localdomain>

On Mon, 18 Aug 2014 08:51:57 AM Lietz, Haiko wrote:
> Hi all,
> 
> Using filled.contour...
> 
> foo <- matrix(seq(0.1, 0.9, 0.1), ncol = 3)
> filled.contour(foo)
> 
> how can I set the key axis to give percentages?
> 
> And is there a way to automatically label the key axis except for 
placing
> text there?
> 
> Thanks
> 
> Haiko

Hi Haiko,
Try this:

filled.contour(foo,
 plot.axes={axis(1);
 axis(2,at=seq(0,1,by=0.2),labels=seq(0,100,by=20))},
 key.axes=
 {axis(4,at=seq(0,1,by=0.2),labels=seq(0,100,by=20))})

Jim


From oma.gonzales at gmail.com  Mon Aug 18 11:13:28 2014
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Mon, 18 Aug 2014 04:13:28 -0500
Subject: [R] GSUB function and regex problem
Message-ID: <CAM-xyZgfQri2XmfEv+6wFazbz3fY0KfBCRaCcXgxfvGqdWPdHw@mail.gmail.com>

Hi all, i have this data.frame with 3 columns: "campa?a", "visitas",
"compras".

This is the actual data.frame:

 Campa?a                  Visitas       Compras
1 facebook-Ads1       524                   2
2 faceBOOK-Ads1     487                   24
3 fcebook-ads12        258                  4
4        Email1              8                      7
5         mail1               224                  2
6     referral1              147                  7

And i want to replace all the entries on the "campa?a" :

from this: "facebook-Ads1" or this: "faceBOOK-Ads1"--> to this: "FBAds".

These are my steps:

1) I load the CSV file into R:

DataGoogle1 <- read.csv(file = "DataGoogle2.csv", header = T)

2) and then use:

gsub("facebook-Ads1", "FBAds", DataGoogle1)

But the result is not what i'm expecting:

i get:

> gsub(pattern = "facebook-Ads1", "FBAds", DataGoogle1)
[1] "c(2, 3, 4, 1, 5, 6, 7, 8, 9)"                "c(524, 487, 258, 8, 224,
147, 87, 863, 145)"
[3] "c(2, 24, 4, 7, 2, 7, 5, 23, 14)"

May you help me to understand why it is not working? Thanks! :D

	[[alternative HTML version deleted]]


From jan.stanstrup at fmach.it  Mon Aug 18 13:56:12 2014
From: jan.stanstrup at fmach.it (Jan Stanstrup)
Date: Mon, 18 Aug 2014 13:56:12 +0200
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
In-Reply-To: <A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
	<53ECC50B.3000606@fmach.it>
	<A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
Message-ID: <53F1E9DC.9000302@fmach.it>

The knots are deleted anyway ("Deleting unnecessary knots ..."). It 
seems to make no difference.



On 08/14/2014 06:06 PM, David Winsemius wrote:
>
> On Aug 14, 2014, at 7:17 AM, Jan Stanstrup wrote:
>
>> Thank you very much for this snippet!
>>
>> I used it on my data and indeed it does give intervals which 
>> appear quite realistic (script and data here 
>> https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R).
>> I also tried getting the intervals with predict.cobs but the 
>> methods available there gave very narrow bands.
>> The only problem I can see is that the fit tend to be a bit on 
>> the smooth side. See for example the upper interval limits at x = 2 
>> to 3 and x =1.2. If then I set lambda to something low like 0.05 
>> the band narrows to nearly nothing when there are few points. For 
>> example at x = 2.5. Is there some other parameter I would be adjusting?
>>
>
> Try specifying the number and location of the knots (using my example 
> data):
>
> > Rbs.9 <- cobs(age,analyte,constraint="increase",tau=0.9, nknots=6, 
> knots=seq(60,85,by=5))
> > plot(age,analyte, ylim=c(0,2000))
> >  lines(predict(Rbs.9), col = 2, lwd = 1.5)
>
>
> -- 
> David.
>
>>
>>
>> ----------------------
>> Jan Stanstrup
>> Postdoc
>>
>> Metabolomics
>> Food Quality and Nutrition
>> Fondazione Edmund Mach
>>
>>
>>
>> On 08/14/2014 02:02 AM, David Winsemius wrote:
>>>
>>> On Aug 12, 2014, at 8:40 AM, Bert Gunter wrote:
>>>
>>>> PI's of what? -- future individual values or mean values?
>>>>
>>>> I assume quantreg provides quantiles for the latter, not the former.
>>>> (See ?predict.lm for a terse explanation of the difference).
>>>
>>> I probably should have questioned the poster about what was meant by 
>>> a "prediction interval for a monotonic loess curve". I was 
>>> suggesting quantile regression for estimation of a chosen quantile, 
>>> say the 90th percentile. I was thinking it could produce the 
>>> analogue of a 90th percentile value (with no         reference to a 
>>> mean value or use of presumed distribution within adjacent windows 
>>> of say 100-150 points. I had experience using the cobs function (in 
>>> the package of the same name) as Koenker illustrates:
>>>
>>> age <- runif(1000,min=60,max=85)
>>>
>>>  analyte <- rlnorm(1000,4*(age/60),age/60)
>>>  plot(age,analyte)
>>>
>>>  library(cobs)
>>>  library(quantreg)
>>>  Rbs.9 <- cobs(age,analyte, constraint="increase",tau=0.9)
>>> Rbs.median <- cobs(age,analyte,constraint="increase",tau=0.5)
>>>
>>> png("cobs.png"); plot(age,analyte, ylim=c(0,2000))
>>>  lines(predict(Rbs.9), col = "red", lwd = 1.5)
>>> lines(predict(Rbs.median), col = "blue", lwd = 1.5)
>>>  dev.off()
>>> <Mail Attachment.png>
>>>
>>> -- David
>>>
>>>
>>>> obtainable from bootstrapping but the details depend on what you are
>>>> prepared to assume. Consult references or your local statistician for
>>>> help if needed.
>>>>
>>>> -- Bert
>>>>
>>>> Bert Gunter
>>>> Genentech Nonclinical Biostatistics
>>>> (650) 467-7374
>>>>
>>>> "Data is not information. Information is not knowledge. And knowledge
>>>> is certainly not wisdom."
>>>> Clifford Stoll
>>>>
>>>>
>>>>
>>>>
>>>> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius 
>>>> <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>>>>>
>>>>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>>>>
>>>>>> Hi,
>>>>>>
>>>>>> I am trying to find a way to estimate prediction intervals (PI) 
>>>>>> for a monotonic loess curve using bootstrapping.
>>>>>>
>>>>>> At the moment my approach is to use the boot function from the 
>>>>>> boot package to bootstrap my loess model, which consist of loess 
>>>>>> + monoproc from the monoproc package (to force the fit to 
>>>>>> be monotonic which gives me much improved results with my 
>>>>>> particular data). The output from the monoproc package is 
>>>>>> simply the fitted y values at each x-value.
>>>>>> I then use boot.ci (again from the boot package) to get 
>>>>>> confidence intervals. The problem is that this gives me 
>>>>>> confidence intervals (CI) for the "fit" (is there a proper way to 
>>>>>> specify this?) and not a prediction interval. The interval is 
>>>>>> thus way too optimistic to give me an idea of the confidence 
>>>>>> interval of a predicted value.
>>>>>>
>>>>>> For linear models predict.lm can give PI instead of CI by setting 
>>>>>> interval = "prediction". Further discussion of that here:
>>>>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>>>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>>>>
>>>>>> However I don't see a way to do that for boot.ci. Does there 
>>>>>> exist a way to get PIs after bootstrapping? If some sample code 
>>>>>> is required I am more than happy to supply it but I 
>>>>>> thought the question was general enough to be understandable 
>>>>>> without it.
>>>>>>
>>>>>
>>>>> Why not use the quantreg package to estimate the quantiles of 
>>>>> interest to you? That way you would not be depending on Normal 
>>>>> theory assumptions which you apparently don't trust. I've used it 
>>>>> with the `cobs` function from the package of the same name to 
>>>>> implement the monotonic constraint. I think there is a 
>>>>> worked example in the quantreg package, but since I 
>>>>> bought Koenker's book, I may be remembering from there.
>>>>> --
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting 
>>>>> guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>
>> <boot2ci_PI.png><cobs.png>
>
> David Winsemius
> Alameda, CA, USA
>


From hugues.francois at irstea.fr  Mon Aug 18 15:35:37 2014
From: hugues.francois at irstea.fr (=?iso-8859-1?Q?Hugues_Fran=E7ois?=)
Date: Mon, 18 Aug 2014 15:35:37 +0200
Subject: [R] About radial.labels in plotrix
Message-ID: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>

Hello,

 

As you can read in the small code below, I do not represent directly my data but its inverse in the limits of my radial plot and I would like to reorder grid labelling from the upper value at the center and the lower one at the graph's border. In my example I would like to have 40 at the center and 0 on the border.

 

http://oi62.tinypic.com/9zrntv.jpg

 

I tried to find examples of radial.labels parameter on the web but I didn't find any.

 

Here is my code :

 

radial.plot(

                mylim-data2[data2[,1]==sta,2:length(data2)],

                labels=c("N","NE","E","SE","S","SW","W","NW"),

                rp.type="p",

                radial.lim=c(0,mylim),

                line.col="#648bda",

                lwd = 2,

                start=1.56,

                clockwise = T)

 

Regards,

 

Hugues.


	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Aug 18 16:44:16 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 18 Aug 2014 14:44:16 +0000
Subject: [R] Turn Rank Ordering Into Numerical Scores By
	Transposing	A	Data	Frame
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>
References: <C7D70D49-B6D5-4E15-AD98-AB15E1AEA468@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F8C34B@mb02.ads.tamu.edu>
	<696C4B48-C745-4E5A-A3A1-05D2E93991A2@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F910CA@mb02.ads.tamu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9132B@mb02.ads.tamu.edu>

Another approach using reshape2:

> library(reshape2)
> # Construct data/ add column of row numbers
> set.seed(42)
> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
+   "green", "yellow", NA), 4))))
> mydf <- data.frame(rows=1:100, mydf)
> colnames(mydf) <- c("row", "rank1", "rank2", "rank3", "rank4")
> head(mydf)
  row  rank1  rank2  rank3 rank4
1   1   <NA> yellow    red  blue
2   2 yellow  green   <NA>   red
3   3 yellow  green   blue  <NA>
4   4   <NA>   blue yellow green
5   5   <NA>    red   blue green
6   6   <NA>    red  green  blue
> # Reshape
> mymelt <- melt(mydf, id.vars=1, measure.vars=2:5, 
+     variable.name="rank", value.name="color")
> # Convert rank to numeric
> mymelt$rank <- as.numeric(mymelt$rank)
> mycast <- dcast(mymelt, row~color, value.var="rank", fill=0)
> head(mycast)
  row blue green red yellow NA
1   1    4     0   3      2  1
2   2    0     2   4      1  3
3   3    3     2   0      1  4
4   4    2     4   0      3  1
5   5    3     4   2      0  1
6   6    4     3   2      0  1

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Sunday, August 17, 2014 6:32 PM
To: Simon Kiss; r-help at r-project.org
Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame

There is probably an easier way to do this, but

> set.seed(42)
> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
+  "green", "yellow", NA), 4))))
> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
> head(mydf)
   rank1  rank2  rank3 rank4
1   <NA> yellow    red  blue
2 yellow  green   <NA>   red
3 yellow  green   blue  <NA>
4   <NA>   blue yellow green
5   <NA>    red   blue green
6   <NA>    red  green  blue
> lvls <- levels(mydf$rank1)
> # convert color factors to numeric
> for (i in seq_along(mydf)) mydf[,i] <- as.numeric(mydf[,i]) 
> # stack the columns
> mydf2 <- stack(mydf)
> # convert rank factor to numeric
> mydf2$ind <- as.numeric(mydf2$ind)
> # add row numbers
> mydf2 <- data.frame(rows=1:100, mydf2)
> # Create table
> mytbl <- xtabs(ind~rows+values, mydf2)
> # convert to data frame
> mydf3 <- data.frame(unclass(mytbl))
> colnames(mydf3) <- lvls
> head(mydf3)
  blue green red yellow
1    4     0   3      2
2    0     2   4      1
3    3     2   0      1
4    2     4   0      3
5    3     4   2      0
6    4     3   2      0

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
Sent: Friday, August 15, 2014 3:58 PM
To: r-help at r-project.org
Subject: Re: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame


Both the suggestions I got work very well, but what I didn't realize is that NA values would cause serious problems.  Where there is a missing value, using the argument na.last=NA to order just returns the the order of the factor levels, but excludes the missing values, but I have no idea where those occur in the or rather which of those variables were actually missing.  
Have I explained this problem sufficiently? 
I didn't think it would cause such a problem so I didn't include it in the original problem definition.
Yours, Simon
On Jul 25, 2014, at 4:58 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> I think this gets what you want. But your data are not reproducible since they are randomly drawn without setting a seed and the two data sets have no relationship to one another.
> 
>> set.seed(42)
>> mydf <- data.frame(t(replicate(100, sample(c("red", "blue",
> + "green", "yellow")))))
>> colnames(mydf) <- c("rank1", "rank2", "rank3", "rank4")
>> mydf2 <- data.frame(t(apply(mydf, 1, order)))
>> colnames(mydf2) <- levels(mydf$rank1)
>> head(mydf)
>   rank1  rank2  rank3 rank4
> 1 yellow  green    red  blue
> 2  green   blue yellow   red
> 3  green yellow    red  blue
> 4 yellow    red  green  blue
> 5 yellow    red  green  blue
> 6 yellow    red   blue green
>> head(mydf2)
>  blue green red yellow
> 1    4     2   3      1
> 2    2     1   4      3
> 3    4     1   3      2
> 4    4     3   2      1
> 5    4     3   2      1
> 6    3     4   2      1
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Simon Kiss
> Sent: Friday, July 25, 2014 2:34 PM
> To: r-help at r-project.org
> Subject: [R] Turn Rank Ordering Into Numerical Scores By Transposing A Data Frame
> 
> Hello:
> I have data that looks like mydf, below.  It is the results of a survey where participants were to put a number of statements (in this case colours) in their order of preference. In this case, the rank number is the variable, and the factor level for each respondent is which colour they assigned to that rank.  I would like to find a way to effectively transpose the data frame so that it looks like mydf2, also below, where the colours the participants were able to choose are the variables and the variable score is what that person ranked that variable. 
> 
> Ultimately what I would like to do is a factor analysis on these items, so I'd like to be able to see if people ranked red and yellow higher together but ranked green and blue together lower, that sort of thing.  
> I have played around with different variations of t(), melt(), ifelse() and if() but can't find a solution. 
> Thank you
> Simon
> #Reproducible code
> mydf<-data.frame(rank1=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank2=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank3=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100), rank4=sample(c('red', 'blue', 'green', 'yellow'), replace=TRUE, size=100))
> 
> mydf2<-data.frame(red=sample(c(1,2,3,4), replace=TRUE,size=100),blue=sample(c(1,2,3,4), replace=TRUE,size=100),green=sample(c(1,2,3,4), replace=TRUE,size=100) ,yellow=sample(c(1,2,3,4), replace=TRUE,size=100))
> *********************************
> Simon J. Kiss, PhD
> Assistant Professor, Wilfrid Laurier University
> 73 George Street
> Brantford, Ontario, Canada
> N3T 2C9
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9
Cell: +1 905 746 7606

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Aug 18 16:45:24 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 18 Aug 2014 10:45:24 -0400
Subject: [R] About radial.labels in plotrix
In-Reply-To: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>
References: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>
Message-ID: <53F21184.3010909@gmail.com>

On 18/08/2014 9:35 AM, Hugues Fran?ois wrote:
> Hello,
>
>   
>
> As you can read in the small code below, I do not represent directly my data but its inverse in the limits of my radial plot and I would like to reorder grid labelling from the upper value at the center and the lower one at the graph's border. In my example I would like to have 40 at the center and 0 on the border.
>
>   
>
> http://oi62.tinypic.com/9zrntv.jpg
>
>   
>
> I tried to find examples of radial.labels parameter on the web but I didn't find any.
>
>   
>
> Here is my code :
>
>   
>
> radial.plot(
>
>                  mylim-data2[data2[,1]==sta,2:length(data2)],
>
>                  labels=c("N","NE","E","SE","S","SW","W","NW"),
>
>                  rp.type="p",
>
>                  radial.lim=c(0,mylim),
>
>                  line.col="#648bda",
>
>                  lwd = 2,
>
>                  start=1.56,
>
>                  clockwise = T)
>
>   
>

 From the help page, it looks as though radial.labels should allow you 
to set that.  You didn't post any data to demonstrate with, but I would 
assume it's a character vector (or numeric that will be coerced to 
character) of the same length as radial.lim.

Duncan Murdoch


From wdunlap at tibco.com  Mon Aug 18 17:14:09 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 18 Aug 2014 08:14:09 -0700
Subject: [R] GSUB function and regex problem
In-Reply-To: <CAM-xyZgfQri2XmfEv+6wFazbz3fY0KfBCRaCcXgxfvGqdWPdHw@mail.gmail.com>
References: <CAM-xyZgfQri2XmfEv+6wFazbz3fY0KfBCRaCcXgxfvGqdWPdHw@mail.gmail.com>
Message-ID: <CAF8bMcbPCFdOigRFwCn6g9QDPYr1_XBFHHg3TQ-tpRDz+VMLYQ@mail.gmail.com>

gsub will work on a column of a data.frame, not an entire data.frame.
> gsub(pattern = "facebook-Ads1", "FBAds", DataGoogle1$Campa?a)
[1] "FBAds"         "faceBOOK-Ads1" "fcebook-ads12" "Email1"
"mail1"
[6] "referral1"

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 18, 2014 at 2:13 AM, Omar Andr? Gonz?les D?az
<oma.gonzales at gmail.com> wrote:
> Hi all, i have this data.frame with 3 columns: "campa?a", "visitas",
> "compras".
>
> This is the actual data.frame:
>
>  Campa?a                  Visitas       Compras
> 1 facebook-Ads1       524                   2
> 2 faceBOOK-Ads1     487                   24
> 3 fcebook-ads12        258                  4
> 4        Email1              8                      7
> 5         mail1               224                  2
> 6     referral1              147                  7
>
> And i want to replace all the entries on the "campa?a" :
>
> from this: "facebook-Ads1" or this: "faceBOOK-Ads1"--> to this: "FBAds".
>
> These are my steps:
>
> 1) I load the CSV file into R:
>
> DataGoogle1 <- read.csv(file = "DataGoogle2.csv", header = T)
>
> 2) and then use:
>
> gsub("facebook-Ads1", "FBAds", DataGoogle1)
>
> But the result is not what i'm expecting:
>
> i get:
>
>> gsub(pattern = "facebook-Ads1", "FBAds", DataGoogle1)
> [1] "c(2, 3, 4, 1, 5, 6, 7, 8, 9)"                "c(524, 487, 258, 8, 224,
> 147, 87, 863, 145)"
> [3] "c(2, 24, 4, 7, 2, 7, 5, 23, 14)"
>
> May you help me to understand why it is not working? Thanks! :D
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Aug 18 17:16:49 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 18 Aug 2014 16:16:49 +0100
Subject: [R] GSUB function and regex problem
In-Reply-To: <CAM-xyZgfQri2XmfEv+6wFazbz3fY0KfBCRaCcXgxfvGqdWPdHw@mail.gmail.com>
References: <CAM-xyZgfQri2XmfEv+6wFazbz3fY0KfBCRaCcXgxfvGqdWPdHw@mail.gmail.com>
Message-ID: <53F218E1.3070106@sapo.pt>

Hello,

Try reading your data with option stringsAsFactors = FALSE. It seems 
that your strings are being read as factors, which are coded as integers.

DataGoogle1 <- read.csv(file = "DataGoogle2.csv", header = T, 
stringsAsFactors = FALSE)


Hope this helps,

Rui Barradas

Em 18-08-2014 10:13, Omar Andr? Gonz?les D?az escreveu:
> Hi all, i have this data.frame with 3 columns: "campa?a", "visitas",
> "compras".
>
> This is the actual data.frame:
>
>   Campa?a                  Visitas       Compras
> 1 facebook-Ads1       524                   2
> 2 faceBOOK-Ads1     487                   24
> 3 fcebook-ads12        258                  4
> 4        Email1              8                      7
> 5         mail1               224                  2
> 6     referral1              147                  7
>
> And i want to replace all the entries on the "campa?a" :
>
> from this: "facebook-Ads1" or this: "faceBOOK-Ads1"--> to this: "FBAds".
>
> These are my steps:
>
> 1) I load the CSV file into R:
>
> DataGoogle1 <- read.csv(file = "DataGoogle2.csv", header = T)
>
> 2) and then use:
>
> gsub("facebook-Ads1", "FBAds", DataGoogle1)
>
> But the result is not what i'm expecting:
>
> i get:
>
>> gsub(pattern = "facebook-Ads1", "FBAds", DataGoogle1)
> [1] "c(2, 3, 4, 1, 5, 6, 7, 8, 9)"                "c(524, 487, 258, 8, 224,
> 147, 87, 863, 145)"
> [3] "c(2, 24, 4, 7, 2, 7, 5, 23, 14)"
>
> May you help me to understand why it is not working? Thanks! :D
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hugues.francois at irstea.fr  Mon Aug 18 18:25:37 2014
From: hugues.francois at irstea.fr (=?iso-8859-1?Q?Hugues_Fran=E7ois?=)
Date: Mon, 18 Aug 2014 18:25:37 +0200
Subject: [R] About radial.labels in plotrix
In-Reply-To: <53F21184.3010909@gmail.com>
References: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>
	<53F21184.3010909@gmail.com>
Message-ID: <3CB901080554B04881D30F111F62D930041BCBB3@nadia.grenoble.cemagref.fr>

Hello,

Thanks for your answer. Of course I read the help but I didn't understand how to retrieve data from radial.lim. Maybe it is trivial for you but not for me.

Attached to this message you will find some test data but you will need to cast them using reshape and this line (assuming you import the test data as "data"):

data2 <- cast(data, gid ~ azimut, value = "angle")

Regards,

Hugues.


-----Message d'origine-----
De?: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Envoy??: lundi 18 ao?t 2014 16:45
??: Hugues Fran?ois; r-help at r-project.org
Objet?: Re: [R] About radial.labels in plotrix

On 18/08/2014 9:35 AM, Hugues Fran?ois wrote:
> Hello,
>
>   
>
> As you can read in the small code below, I do not represent directly my data but its inverse in the limits of my radial plot and I would like to reorder grid labelling from the upper value at the center and the lower one at the graph's border. In my example I would like to have 40 at the center and 0 on the border.
>
>   
>
> http://oi62.tinypic.com/9zrntv.jpg
>
>   
>
> I tried to find examples of radial.labels parameter on the web but I didn't find any.
>
>   
>
> Here is my code :
>
>   
>
> radial.plot(
>
>                  mylim-data2[data2[,1]==sta,2:length(data2)],
>
>                  labels=c("N","NE","E","SE","S","SW","W","NW"),
>
>                  rp.type="p",
>
>                  radial.lim=c(0,mylim),
>
>                  line.col="#648bda",
>
>                  lwd = 2,
>
>                  start=1.56,
>
>                  clockwise = T)
>
>   
>

 From the help page, it looks as though radial.labels should allow you to set that.  You didn't post any data to demonstrate with, but I would assume it's a character vector (or numeric that will be coerced to
character) of the same length as radial.lim.

Duncan Murdoch

From murdoch.duncan at gmail.com  Mon Aug 18 18:42:44 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 18 Aug 2014 12:42:44 -0400
Subject: [R] About radial.labels in plotrix
In-Reply-To: <3CB901080554B04881D30F111F62D930041BCBB3@nadia.grenoble.cemagref.fr>
References: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>
	<53F21184.3010909@gmail.com>
	<3CB901080554B04881D30F111F62D930041BCBB3@nadia.grenoble.cemagref.fr>
Message-ID: <53F22D04.2050508@gmail.com>

On 18/08/2014 12:25 PM, Hugues Fran?ois wrote:
> Hello,
>
> Thanks for your answer. Of course I read the help but I didn't understand how to retrieve data from radial.lim. Maybe it is trivial for you but not for me.
>
> Attached to this message you will find some test data but you will need to cast them using reshape and this line (assuming you import the test data as "data"):
>
> data2 <- cast(data, gid ~ azimut, value = "angle")

But I don't know how you have set "mylim" or "sta", so I still can't run 
your code.  Generally the best way to get useful help is to post a 
minimal, self-contained example that illustrates your problem.

I was assuming mylim was a vector of values, but if it is a single 
value, then it's trickier, because plotrix does some fancy stuff if 
mylim is length 2, and doesn't document it very clearly.

So I'd have 2 suggestions:  you could try to figure out the fancy stuff 
that plotrix is doing (I think it's probably pretty(radial.lim), but I'm 
not sure), or you could explicitly enter the values where you want 
radial lines and labels, e.g.

radial.plot(
                   mylim-data2[data2[,1]==sta,2:length(data2)],
                   labels=c("N","NE","E","SE","S","SW","W","NW"),
                   rp.type="p",
                   radial.lim=c(0,1,2,3),
                   radial.labels=c(3,2,1,0),
                   line.col="#648bda",
                   lwd = 2,
                   start=1.56,
                   clockwise = T)

Duncan Murdoch
>
> Regards,
>
> Hugues.
>
>
> -----Message d'origine-----
> De : Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Envoy? : lundi 18 ao?t 2014 16:45
> ? : Hugues Fran?ois; r-help at r-project.org
> Objet : Re: [R] About radial.labels in plotrix
>
> On 18/08/2014 9:35 AM, Hugues Fran?ois wrote:
> > Hello,
> >
> >
> >
> > As you can read in the small code below, I do not represent directly my data but its inverse in the limits of my radial plot and I would like to reorder grid labelling from the upper value at the center and the lower one at the graph's border. In my example I would like to have 40 at the center and 0 on the border.
> >
> >
> >
> > http://oi62.tinypic.com/9zrntv.jpg
> >
> >
> >
> > I tried to find examples of radial.labels parameter on the web but I didn't find any.
> >
> >
> >
> > Here is my code :
> >
> >
> >
> > radial.plot(
> >
> >                  mylim-data2[data2[,1]==sta,2:length(data2)],
> >
> >                  labels=c("N","NE","E","SE","S","SW","W","NW"),
> >
> >                  rp.type="p",
> >
> >                  radial.lim=c(0,mylim),
> >
> >                  line.col="#648bda",
> >
> >                  lwd = 2,
> >
> >                  start=1.56,
> >
> >                  clockwise = T)
> >
> >
> >
>
>   From the help page, it looks as though radial.labels should allow you to set that.  You didn't post any data to demonstrate with, but I would assume it's a character vector (or numeric that will be coerced to
> character) of the same length as radial.lim.
>
> Duncan Murdoch


From hugues.francois at irstea.fr  Mon Aug 18 19:00:32 2014
From: hugues.francois at irstea.fr (=?iso-8859-1?Q?Hugues_Fran=E7ois?=)
Date: Mon, 18 Aug 2014 19:00:32 +0200
Subject: [R] About radial.labels in plotrix
In-Reply-To: <53F22D04.2050508@gmail.com>
References: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>
	<53F21184.3010909@gmail.com>
	<3CB901080554B04881D30F111F62D930041BCBB3@nadia.grenoble.cemagref.fr>
	<53F22D04.2050508@gmail.com>
Message-ID: <3CB901080554B04881D30F111F62D930041BCBB4@nadia.grenoble.cemagref.fr>

Really sorry for this mistake... I have several graph to do for different weather station and mylim and sta are elements to loop on each one. For the example, the code should be the one below.

Sometimes I feel dumb since I have read the "pretty" thing but I didn't understand the syntax "pretty(range(lengths))" and I tried to call directly radial.lim in radial.labels. Reading your mail, I understood... And add this simple line radial.labels=sort(pretty(c(0,mylim)), decreasing=T) which works perfectly ! Effectively, it was trivial

Thanks :D

Hugues.

data2 <- cast(data, gid ~ azimut, value = "angle")

radial.plot(
	40-data2[,2:length(data2)],
	labels=c("N","NE","E","SE","S","SW","W","NW"),
	rp.type="p",
	radial.lim=c(0,40),
	line.col="#648bda",
	lwd = 2,
	start=1.56,
	clockwise = T)

Of c



-----Message d'origine-----
De?: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Envoy??: lundi 18 ao?t 2014 18:43
??: Hugues Fran?ois; r-help at r-project.org
Objet?: Re: [R] About radial.labels in plotrix

On 18/08/2014 12:25 PM, Hugues Fran?ois wrote:
> Hello,
>
> Thanks for your answer. Of course I read the help but I didn't understand how to retrieve data from radial.lim. Maybe it is trivial for you but not for me.
>
> Attached to this message you will find some test data but you will need to cast them using reshape and this line (assuming you import the test data as "data"):
>
> data2 <- cast(data, gid ~ azimut, value = "angle")

But I don't know how you have set "mylim" or "sta", so I still can't run your code.  Generally the best way to get useful help is to post a minimal, self-contained example that illustrates your problem.

I was assuming mylim was a vector of values, but if it is a single value, then it's trickier, because plotrix does some fancy stuff if mylim is length 2, and doesn't document it very clearly.

So I'd have 2 suggestions:  you could try to figure out the fancy stuff that plotrix is doing (I think it's probably pretty(radial.lim), but I'm not sure), or you could explicitly enter the values where you want radial lines and labels, e.g.

radial.plot(
                   mylim-data2[data2[,1]==sta,2:length(data2)],
                   labels=c("N","NE","E","SE","S","SW","W","NW"),
                   rp.type="p",
                   radial.lim=c(0,1,2,3),
                   radial.labels=c(3,2,1,0),
                   line.col="#648bda",
                   lwd = 2,
                   start=1.56,
                   clockwise = T)

Duncan Murdoch
>
> Regards,
>
> Hugues.
>
>
> -----Message d'origine-----
> De : Duncan Murdoch [mailto:murdoch.duncan at gmail.com] Envoy? : lundi 
> 18 ao?t 2014 16:45 ? : Hugues Fran?ois; r-help at r-project.org Objet : 
> Re: [R] About radial.labels in plotrix
>
> On 18/08/2014 9:35 AM, Hugues Fran?ois wrote:
> > Hello,
> >
> >
> >
> > As you can read in the small code below, I do not represent directly my data but its inverse in the limits of my radial plot and I would like to reorder grid labelling from the upper value at the center and the lower one at the graph's border. In my example I would like to have 40 at the center and 0 on the border.
> >
> >
> >
> > http://oi62.tinypic.com/9zrntv.jpg
> >
> >
> >
> > I tried to find examples of radial.labels parameter on the web but I didn't find any.
> >
> >
> >
> > Here is my code :
> >
> >
> >
> > radial.plot(
> >
> >                  mylim-data2[data2[,1]==sta,2:length(data2)],
> >
> >                  labels=c("N","NE","E","SE","S","SW","W","NW"),
> >
> >                  rp.type="p",
> >
> >                  radial.lim=c(0,mylim),
> >
> >                  line.col="#648bda",
> >
> >                  lwd = 2,
> >
> >                  start=1.56,
> >
> >                  clockwise = T)
> >
> >
> >
>
>   From the help page, it looks as though radial.labels should allow 
> you to set that.  You didn't post any data to demonstrate with, but I 
> would assume it's a character vector (or numeric that will be coerced 
> to
> character) of the same length as radial.lim.
>
> Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Aug 18 20:04:11 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 18 Aug 2014 14:04:11 -0400
Subject: [R] About radial.labels in plotrix
In-Reply-To: <3CB901080554B04881D30F111F62D930041BCBB4@nadia.grenoble.cemagref.fr>
References: <3CB901080554B04881D30F111F62D930041BCB6F@nadia.grenoble.cemagref.fr>
	<53F21184.3010909@gmail.com>
	<3CB901080554B04881D30F111F62D930041BCBB3@nadia.grenoble.cemagref.fr>
	<53F22D04.2050508@gmail.com>
	<3CB901080554B04881D30F111F62D930041BCBB4@nadia.grenoble.cemagref.fr>
Message-ID: <53F2401B.7050405@gmail.com>

On 18/08/2014 1:00 PM, Hugues Fran?ois wrote:
> Really sorry for this mistake... I have several graph to do for different weather station and mylim and sta are elements to loop on each one. For the example, the code should be the one below.
>
> Sometimes I feel dumb since I have read the "pretty" thing but I didn't understand the syntax "pretty(range(lengths))" and I tried to call directly radial.lim in radial.labels. Reading your mail, I understood... And add this simple line radial.labels=sort(pretty(c(0,mylim)), decreasing=T) which works perfectly ! Effectively, it was trivial

One minor suggestion:  pretty() will always give an increasing sequence, 
so rev(pretty(c(0,mylim))) will give the corresponding decreasing one.  
No need to call sort(..., decreasing=TRUE).

Duncan
>
> Thanks :D
>
> Hugues.
>
> data2 <- cast(data, gid ~ azimut, value = "angle")
>
> radial.plot(
> 	40-data2[,2:length(data2)],
> 	labels=c("N","NE","E","SE","S","SW","W","NW"),
> 	rp.type="p",
> 	radial.lim=c(0,40),
> 	line.col="#648bda",
> 	lwd = 2,
> 	start=1.56,
> 	clockwise = T)
>
> Of c
>
>
>
> -----Message d'origine-----
> De : Duncan Murdoch [mailto:murdoch.duncan at gmail.com]
> Envoy? : lundi 18 ao?t 2014 18:43
> ? : Hugues Fran?ois; r-help at r-project.org
> Objet : Re: [R] About radial.labels in plotrix
>
> On 18/08/2014 12:25 PM, Hugues Fran?ois wrote:
> > Hello,
> >
> > Thanks for your answer. Of course I read the help but I didn't understand how to retrieve data from radial.lim. Maybe it is trivial for you but not for me.
> >
> > Attached to this message you will find some test data but you will need to cast them using reshape and this line (assuming you import the test data as "data"):
> >
> > data2 <- cast(data, gid ~ azimut, value = "angle")
>
> But I don't know how you have set "mylim" or "sta", so I still can't run your code.  Generally the best way to get useful help is to post a minimal, self-contained example that illustrates your problem.
>
> I was assuming mylim was a vector of values, but if it is a single value, then it's trickier, because plotrix does some fancy stuff if mylim is length 2, and doesn't document it very clearly.
>
> So I'd have 2 suggestions:  you could try to figure out the fancy stuff that plotrix is doing (I think it's probably pretty(radial.lim), but I'm not sure), or you could explicitly enter the values where you want radial lines and labels, e.g.
>
> radial.plot(
>                     mylim-data2[data2[,1]==sta,2:length(data2)],
>                     labels=c("N","NE","E","SE","S","SW","W","NW"),
>                     rp.type="p",
>                     radial.lim=c(0,1,2,3),
>                     radial.labels=c(3,2,1,0),
>                     line.col="#648bda",
>                     lwd = 2,
>                     start=1.56,
>                     clockwise = T)
>
> Duncan Murdoch
> >
> > Regards,
> >
> > Hugues.
> >
> >
> > -----Message d'origine-----
> > De : Duncan Murdoch [mailto:murdoch.duncan at gmail.com] Envoy? : lundi
> > 18 ao?t 2014 16:45 ? : Hugues Fran?ois; r-help at r-project.org Objet :
> > Re: [R] About radial.labels in plotrix
> >
> > On 18/08/2014 9:35 AM, Hugues Fran?ois wrote:
> > > Hello,
> > >
> > >
> > >
> > > As you can read in the small code below, I do not represent directly my data but its inverse in the limits of my radial plot and I would like to reorder grid labelling from the upper value at the center and the lower one at the graph's border. In my example I would like to have 40 at the center and 0 on the border.
> > >
> > >
> > >
> > > http://oi62.tinypic.com/9zrntv.jpg
> > >
> > >
> > >
> > > I tried to find examples of radial.labels parameter on the web but I didn't find any.
> > >
> > >
> > >
> > > Here is my code :
> > >
> > >
> > >
> > > radial.plot(
> > >
> > >                  mylim-data2[data2[,1]==sta,2:length(data2)],
> > >
> > >                  labels=c("N","NE","E","SE","S","SW","W","NW"),
> > >
> > >                  rp.type="p",
> > >
> > >                  radial.lim=c(0,mylim),
> > >
> > >                  line.col="#648bda",
> > >
> > >                  lwd = 2,
> > >
> > >                  start=1.56,
> > >
> > >                  clockwise = T)
> > >
> > >
> > >
> >
> >   From the help page, it looks as though radial.labels should allow
> > you to set that.  You didn't post any data to demonstrate with, but I
> > would assume it's a character vector (or numeric that will be coerced
> > to
> > character) of the same length as radial.lim.
> >
> > Duncan Murdoch


From dwinsemius at comcast.net  Mon Aug 18 20:14:29 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 18 Aug 2014 11:14:29 -0700
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
	loess curve using bootstrapping
In-Reply-To: <53F1E9DC.9000302@fmach.it>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
	<53ECC50B.3000606@fmach.it>
	<A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
	<53F1E9DC.9000302@fmach.it>
Message-ID: <507AB734-9E08-4F65-9FEB-2FB547691B1E@comcast.net>

I had that result sometimes when testing as well. You don't offer any code so there's nothing I can do to follow-up.

-- 
David.
On Aug 18, 2014, at 4:56 AM, Jan Stanstrup wrote:

> The knots are deleted anyway ("Deleting unnecessary knots ..."). It seems to make no difference.
> 
> 
> 
> On 08/14/2014 06:06 PM, David Winsemius wrote:
>> 
>> On Aug 14, 2014, at 7:17 AM, Jan Stanstrup wrote:
>> 
>>> Thank you very much for this snippet!
>>> 
>>> I used it on my data and indeed it does give intervals which appear quite realistic (script and data here https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R).
>>> I also tried getting the intervals with predict.cobs but the methods available there gave very narrow bands.
>>> The only problem I can see is that the fit tend to be a bit on the smooth side. See for example the upper interval limits at x = 2 to 3 and x =1.2. If then I set lambda to something low like 0.05 the band narrows to nearly nothing when there are few points. For example at x = 2.5. Is there some other parameter I would be adjusting?
>>> 
>> 
>> Try specifying the number and location of the knots (using my example data):
>> 
>> > Rbs.9 <- cobs(age,analyte,constraint="increase",tau=0.9, nknots=6, knots=seq(60,85,by=5))
>> > plot(age,analyte, ylim=c(0,2000))
>> >  lines(predict(Rbs.9), col = 2, lwd = 1.5)
>> 
>> <Mail Attachment.png>
>> 
>> -- 
>> David.
>> 
>>> 
>>> 
>>> ---------------------- 
>>> Jan Stanstrup 
>>> Postdoc 
>>> 
>>> Metabolomics 
>>> Food Quality and Nutrition 
>>> Fondazione Edmund Mach 
>>> 
>>> 
>>> 
>>> On 08/14/2014 02:02 AM, David Winsemius wrote:
>>>> 
>>>> On Aug 12, 2014, at 8:40 AM, Bert Gunter wrote:
>>>> 
>>>>> PI's of what? -- future individual values or mean values?
>>>>> 
>>>>> I assume quantreg provides quantiles for the latter, not the former.
>>>>> (See ?predict.lm for a terse explanation of the difference).
>>>> 
>>>> I probably should have questioned the poster about what was meant by a "prediction interval for a monotonic loess curve". I was suggesting quantile regression for estimation of a chosen quantile, say the 90th percentile. I was thinking it could produce the analogue of a 90th percentile value (with no         reference to a mean value or use of presumed distribution within adjacent windows of say 100-150 points. I had experience using the cobs function (in the package of the same name) as Koenker illustrates:
>>>> 
>>>> age <- runif(1000,min=60,max=85)
>>>>  
>>>>  analyte <- rlnorm(1000,4*(age/60),age/60)
>>>>  plot(age,analyte)
>>>> 
>>>>  library(cobs)
>>>>  library(quantreg)
>>>>  Rbs.9 <- cobs(age,analyte, constraint="increase",tau=0.9) 
>>>> Rbs.median <- cobs(age,analyte,constraint="increase",tau=0.5)
>>>> 
>>>> png("cobs.png"); plot(age,analyte, ylim=c(0,2000))
>>>>  lines(predict(Rbs.9), col = "red", lwd = 1.5)
>>>> lines(predict(Rbs.median), col = "blue", lwd = 1.5)
>>>>  dev.off()
>>>> <Mail Attachment.png>
>>>> 
>>>> -- David
>>>> 
>>>> 
>>>>> obtainable from bootstrapping but the details depend on what you are
>>>>> prepared to assume. Consult references or your local statistician for
>>>>> help if needed.
>>>>> 
>>>>> -- Bert
>>>>> 
>>>>> Bert Gunter
>>>>> Genentech Nonclinical Biostatistics
>>>>> (650) 467-7374
>>>>> 
>>>>> "Data is not information. Information is not knowledge. And knowledge
>>>>> is certainly not wisdom."
>>>>> Clifford Stoll
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> On Tue, Aug 12, 2014 at 8:20 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>> 
>>>>>> On Aug 12, 2014, at 12:23 AM, Jan Stanstrup wrote:
>>>>>> 
>>>>>>> Hi,
>>>>>>> 
>>>>>>> I am trying to find a way to estimate prediction intervals (PI) for a monotonic loess curve using bootstrapping.
>>>>>>> 
>>>>>>> At the moment my approach is to use the boot function from the boot package to bootstrap my loess model, which consist of loess + monoproc from the monoproc package (to force the fit to be monotonic which gives me much improved results with my particular data). The output from the monoproc package is simply the fitted y values at each x-value.
>>>>>>> I then use boot.ci (again from the boot package) to get confidence intervals. The problem is that this gives me confidence intervals (CI) for the "fit" (is there a proper way to specify                     this?) and not a prediction interval. The interval is thus way too optimistic to give me an idea of the confidence interval of a predicted value.
>>>>>>> 
>>>>>>> For linear models predict.lm can give PI instead of CI by setting interval = "prediction". Further discussion of that here:
>>>>>>> http://stats.stackexchange.com/questions/82603/understanding-the-confidence-band-from-a-polynomial-regression
>>>>>>> http://stats.stackexchange.com/questions/44860/how-to-prediction-intervals-for-linear-regression-via-bootstrapping.
>>>>>>> 
>>>>>>> However I don't see a way to do that for boot.ci. Does there exist a way to get PIs after bootstrapping? If some sample code is required I am more than happy to supply it but I thought the question was general enough to be understandable without it.
>>>>>>> 
>>>>>> 
>>>>>> Why not use the quantreg package to estimate the quantiles of interest to you? That way you would not be depending on Normal theory assumptions which you apparently don't trust. I've used it with the `cobs` function from the package of the same name to implement the monotonic constraint. I think there is a worked example in the quantreg package, but since I bought Koenker's book, I may be remembering from there.
>>>>>> --
>>>>>> 
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>>> 
>>> <boot2ci_PI.png><cobs.png>
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
> 

David Winsemius
Alameda, CA, USA


From jagrimsasl at gmail.com  Mon Aug 18 21:58:57 2014
From: jagrimsasl at gmail.com (Andrew Agrimson)
Date: Mon, 18 Aug 2014 14:58:57 -0500
Subject: [R] Building and scoring multiple models with dplyr functions
Message-ID: <CAOfxo3MTa0nzJc35sfrCkFx0LfRMQgEi53Ohpt_+q2RXKmg8Ng@mail.gmail.com>

Hello All,

I have a question regarding building multiple models and then scoring new
data with these models. I have been tasked with converting existing SAS
modeling code into equivalent R code, but unfortunately I rarely use R so
I'm in unfamiliar territory. I've think I've found a good way to build the
models using dplyr functions, however I'm having difficulty figuring out
how to use the models to score new data.


*The SAS code I'm converting builds multiple binomial models using the "BY"
statement in the GLIMMIX procedure. The results of the modeling fitting
process are stored using the "STORE" statement. *

*proc* *glimmix* data = model_data;

by group;

model y/n = var1-var10/dist=bin;

store model;

*quit*;


*The next step is to score a new data set using the PLM procedure. The "New
Data" is also grouped by "group" and PLM is able to match and apply the
appropriate model with the appropriate "by" value. *

*proc* *plm* restore=model;

score data=new_data out=scored predicted=p/ilink;

*run*;


*In R I've been able to reproduce the first model building step using dplyr
functions and it seems to work quite well. In fact it's much faster than my
SAS implementation.*

by_group <- group_by(model_data, group)

models <- by_group %>% do(mod = glm(cbind(y,n) ~ var1 + var2 + var3 + var4
+ var5 + var6 + var7 + var8 + var9 + var10,
                                family = binomial, data = .))


*As stated above, I cannot figure out how to apply these models to new
data.  I've scoured the internet and the documentation for an example but
so far no luck. I want to extract the model objects out of the data frame
"models" and apply the "predict" function, but my novice knowledge of R and
dplyr specifically is making this very difficult.*

*Any help or advice would be greatly appreciated.*


*Thanks,*

*Andy*

	[[alternative HTML version deleted]]


From jmromansic at gmail.com  Tue Aug 19 01:31:59 2014
From: jmromansic at gmail.com (John Romansic)
Date: Mon, 18 Aug 2014 16:31:59 -0700
Subject: [R] principle component values on PCA plots do not match
Message-ID: <CAG+2bO786bBE35e-H2sm9D=PUvWkDEGjgJEoHL+SUjy5ZRo=iw@mail.gmail.com>

Hi all,

I am using prcomp to do Principle Components Analysis and have run into a
problem regarding the scale of the axes on my plots.  I am using prcomp to
analyze a set of 25 morphological measurements taken on each of 161
individual frogs. I used the biplot function to produce a figure of PC1 vs
PC2 for each of the individual frogs and arrows that represent the loadings
of the different morphological measurements on PC1 and PC2. Then I
constructed a separate, similar plot, using my own coding, that provides a
number for each individual frogs corresponding to its species as determined
by genetic analysis, without the arrows. The y-axis on the first plot
ranges shows PC2 values ranging from about -11 to 11, but the y-axis on the
second plot shows PC2 values ranging from about -4 to 4, although all the
data points seem to show up on the figure. I would like to show the same
PCA results on both plots and I do not understand why the y-axes on these
two plots do not match. By the way, the x-axes on these two plots seem to
match, but I think that is just a coincidence. I suspect that my coding for
the second plot is missing a command regarding scaling of the principle
components, but it's not obvious to me why those data would have to be
re-scaled. I thought the scaling is dealt with by prcomp. Within prcomp, I
used scale=TRUE, which I understand re-scales the original data so that all
the variables have equal variance.

Does anyone have any suggestions on what might be wrong with my coding?

Below is an example, using a truncated data set, which produces different
numbers than the example I described above, since this time only 5
measurements are included for each frog. Nevertheless, the second plot (the
one with my coding) has the same problem.

> frogs
    Genetic.species   SVL    HL    HW   BED   FED
1                27 47.75 16.46 14.63 13.27  8.29
2                25 44.87 16.35 14.67 13.50  8.69
3                24 52.57 19.82 16.62 15.12  9.35
4                24 56.60 21.18 19.55 17.73 11.09
5                20 47.66 18.48 16.33 14.98  9.37
6                19 65.96 23.33 20.00 18.88 12.19
7                19 58.67 21.12 18.12 17.37 10.47
8                19 64.33 23.16 19.99 19.20 11.88
9                19 61.03 21.98 19.42 18.22  1.16
10               19 62.88 21.90 19.71 17.92 11.65
11               19 62.77 21.31 19.30 18.47 11.85
12               19 58.64 21.30 19.55 18.17 11.14
13               19 63.40 20.74 19.59 18.25 11.03
14               19 58.22 19.87 18.82 16.85 10.73
15               18 55.43 19.80 18.27 16.01  9.52
16               17 60.46 21.40 19.37 16.67 10.44
17               16 58.32 19.48 17.55 16.42  9.96
18               14 44.64 16.35 14.41 12.77  8.42
19               14 48.32 17.88 16.23 14.34  9.01
20               13 42.32 15.43 14.40 12.47  7.43
21               13 41.87 15.97 14.97 12.46  7.42
22               13 45.71 16.87 15.98 13.08  7.77
23               12 47.38 17.48 15.77 13.99  9.08
24               12 50.28 18.48 17.28 14.87  9.46
25               12 48.00 18.52 17.60 15.40  9.63
26               12 50.98 18.61 17.87 16.00  9.59
27               12 50.76 18.24 17.61 17.72  9.54
28               12 50.83 18.90 18.28 15.02  9.53
29               11 46.80 19.13 17.10 15.22  9.01
30               10 37.55 14.21 12.42 10.79  6.15
31               10 40.39 15.32 13.81 11.89  6.80
32               10 42.39 14.77 14.72 11.87  6.78
33                9 44.08 16.37 15.99 13.09  8.50
34                9 47.36 16.16 16.14 13.50  7.72
35                8 41.43 15.53 12.73 11.01  6.37
36                8 41.45 15.63 13.68 11.32  7.20
37                8 38.86 13.82 12.13 10.39  6.28
38                8 40.51 14.25 12.68 10.40  6.41
39                8 44.64 15.37 13.75 11.37  6.82
40                8 45.08 15.64 14.25 11.17  6.68
41                8 45.10 16.43 15.03 13.16  7.89
42                8 48.94 17.35 16.28 12.31  8.24
43                6 44.05 16.60 12.96 12.51  8.19
44                6 44.56 16.24 13.86 13.02  8.17
45                6 48.01 17.64 15.26 14.59  9.02
46                6 48.67 17.84 15.59 14.44  9.36
47                6 46.87 18.37 16.18 14.59  9.21
48                6 44.32 16.81 14.87 13.55  8.50
49                6 44.79 16.14 14.38 13.40  8.91
50                6 45.30 16.31 14.62 12.89  8.41
51                6 46.36 17.26 15.48 13.30  8.83
52                6 46.80 17.55 15.77 13.87  9.01
53                6 43.14 15.61 14.23 12.78  8.63
54                6 47.99 16.63 15.54 14.00  9.06
55                4 63.12 22.52 20.40 17.77 11.60
56                4 57.22 20.02 18.44 16.07 10.77
57                4 65.55 22.32 20.56 17.53 11.57
58                4 60.61 20.74 19.33 16.61 10.20
59                4 64.82 22.17 21.27 17.99 10.95
60                4 63.03 21.97 21.11 18.25 11.37
61                4 64.96 22.93 22.16 19.07 12.30
62                4 61.89 21.47 20.78 17.97 10.83
63                4 63.34 21.74 21.38 17.60 10.40
64                4 65.01 21.74 22.18 19.11 11.47
65                4 64.52 21.76 22.49 18.35 10.90
66                3 41.34 15.17 12.84 11.87  7.26
67                3 48.11 18.45 15.83 14.28  8.65
68                3 47.59 17.37 15.01 13.34  8.67
69                3 49.25 17.87 15.64 13.74  8.82
70                3 44.82 16.47 14.42 13.05  8.35
71                3 46.21 16.71 14.70 12.88  8.57
72                3 56.24 20.34 18.08 14.72  9.22
73                3 53.38 19.64 17.51 14.82  9.12
74                3 52.59 19.16 17.23 14.44  9.46
75                3 46.27 16.19 14.57 12.39  8.20
76                3 49.18 17.68 15.96 14.03  8.98
77                3 53.90 20.01 18.20 14.89  9.46
78                2 47.62 18.08 15.88 15.02  9.64
79                2 48.20 18.04 15.89 14.89  9.23
80                2 46.27 16.55 15.19 14.04  8.64
81                2 54.04 18.73 17.68 15.79  3.97
82                1 53.34 19.76 16.52 15.04  9.36
83                1 50.41 17.85 14.96 14.24  8.80
84                1 51.71 19.12 16.22 15.16  9.37
85                1 49.73 16.91 14.44 13.49  8.64
86                1 51.73 18.79 16.07 14.58  8.51
87                1 54.50 20.21 17.33 15.45  9.68
88                1 54.08 19.96 17.15 15.76  9.78
89                1 53.26 18.25 15.70 14.76  9.35
90                1 53.20 18.63 16.07 14.79  9.57
91                1 47.54 16.61 14.33 13.56  8.33
92                1 51.20 18.22 15.73 14.46  9.07
93                1 53.56 19.31 16.68 15.33  9.19
94                1 48.11 17.11 14.80 13.98  8.15
95                1 48.10 17.08 14.78 14.14  8.52
96                1 55.97 20.96 18.15 16.06 10.06
97                1 56.18 20.43 17.81 16.18 10.27
98                1 51.21 18.67 16.34 15.03  9.55
99                1 52.25 18.67 16.36 14.26  8.88
100               1 51.78 18.58 16.30 14.91  9.21
101               1 51.39 18.26 16.02 14.57  9.54
102               1 48.45 17.55 15.41 14.16  8.56
103               1 54.30 19.08 16.80 15.22  9.69
104               1 49.33 16.67 14.73 13.84  8.04
105               1 53.41 19.05 16.84 14.86  9.70
106               1 48.80 18.56 16.44 14.88  9.31
107               1 49.70 18.08 16.03 14.69  9.60
108               1 48.28 16.74 14.87 13.72  8.45
109               1 51.35 17.86 15.92 14.22  9.07
110               1 51.01 17.26 15.39 14.63  9.47
111               1 49.89 17.17 15.31 14.21  9.04
112               1 54.15 19.69 17.58 15.38 10.17
113               1 56.28 20.37 18.20 15.83 10.49
114               1 55.30 19.96 17.86 15.66 10.93
115               1 44.53 15.56 13.96 12.69  7.81
116               1 54.15 18.86 16.93 15.08  9.82
117               1 50.59 17.75 15.95 14.66  9.25
118               1 52.55 19.63 17.71 15.21  9.98
119               1 53.86 19.56 17.66 15.18  9.52
120               1 49.91 17.75 16.04 14.21  8.98
121               1 52.78 19.21 17.37 15.49  9.92
122               1 51.94 18.79 17.00 14.79 10.14
123               1 56.60 20.19 18.29 15.86 10.03
124               1 51.23 17.66 16.02 14.37  9.30
125               1 51.80 19.05 17.30 15.12 10.23
126               1 52.78 18.52 16.85 14.80  9.58
127               1 51.41 18.13 16.53 14.36  9.02
128               1 50.41 18.10 16.52 14.87  9.18
129               1 53.48 18.69 17.07 15.19  9.52
130               1 53.87 18.60 17.00 15.28  9.92
131               1 51.98 18.51 16.93 15.12  9.52
132               1 50.56 18.13 16.61 15.12  8.94
133               1 50.64 18.16 16.68 14.38  9.04
134               1 53.06 18.56 17.06 14.74  9.68
135               1 54.64 18.96 17.44 15.61  9.81
136               1 48.13 16.91 15.56 14.30  8.96
137               1 57.97 21.17 19.48 17.01 10.99
138               1 49.93 18.24 16.80 15.20  9.14
139               1 47.38 17.02 15.72 14.18  9.14
140               1 54.24 19.01 17.60 15.18  9.86
141               1 50.17 17.59 16.31 14.53  9.23
142               1 49.78 16.77 15.55 13.83  9.12
143               1 51.81 18.41 17.09 14.87  9.82
144               1 50.84 18.71 17.38 14.79  9.42
145               1 49.57 16.41 15.26 13.35  8.80
146               1 55.81 19.27 17.92 16.06  9.97
147               1 58.03 20.13 18.73 16.28 10.50
148               1 48.72 16.62 15.50 14.06  8.60
149               1 48.39 17.12 15.97 14.01  9.13
150               1 49.01 18.24 17.10 14.76  9.54
151               1 50.31 18.23 17.10 15.15  9.76
152               1 49.10 17.15 16.11 14.47  8.83
153               1 60.04 21.20 19.95 17.53 11.53
154               1 46.99 16.87 15.97 13.93  9.10
155               1 53.63 19.00 18.08 15.89 10.03
156               1 57.88 20.21 19.35 17.34 10.18
157               1 54.89 20.06 19.27 16.76 10.78
158               1 53.56 19.18 18.52 16.39 10.64
159               1 51.50 18.23 17.62 15.21  9.62
160               1 63.47 22.12 21.40 17.79 11.65
161               1 51.46 17.21 16.90 15.37 10.00
> frogspca<-prcomp(frogs[2:6],scale=TRUE)
> summary(frogspca)
Importance of components:
                          PC1     PC2     PC3     PC4     PC5
Standard deviation     2.0950 0.65315 0.27219 0.25087 0.21737
Proportion of Variance 0.8778 0.08532 0.01482 0.01259 0.00945
Cumulative Proportion  0.8778 0.96315 0.97796 0.99055 1.00000
> plot(frogspca)
> biplot(frogspca)
> plot( frogspca$x[,1], frogspca$x[,2] , type="n", xlab="PC1", ylab="PC2")
> text( frogspca$x[,1], frogspca$x[,2], labels=c(Genetic.species))
>
Thank you very much for any suggestions you might have,
John Romansic

	[[alternative HTML version deleted]]


From jszhao at yeah.net  Tue Aug 19 02:30:36 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 18 Aug 2014 17:30:36 -0700
Subject: [R] loading saved files with objects in same names
Message-ID: <53F29AAC.8000009@yeah.net>

Hi there,

I have several saved data files (e.g., A.RData, B.RData and C.RData). In 
each file, there are some objects with same names but different 
contents. Now, I need to compare those objects through plotting. 
However, I can't find a way to load them into a workspace. The only 
thing I can do is to rename them and then save and load again.

Is there a convenient to load those objects?

Thanks a lot in advance.

Best regards,
Jinsong


From jszhao at yeah.net  Tue Aug 19 02:41:54 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 18 Aug 2014 17:41:54 -0700
Subject: [R] principle component values on PCA plots do not match
In-Reply-To: <CAG+2bO786bBE35e-H2sm9D=PUvWkDEGjgJEoHL+SUjy5ZRo=iw@mail.gmail.com>
References: <CAG+2bO786bBE35e-H2sm9D=PUvWkDEGjgJEoHL+SUjy5ZRo=iw@mail.gmail.com>
Message-ID: <53F29D52.9070701@yeah.net>

Hi,

There is a scale factor associated with biplot when plotting the PCA 
result. Please read the help page of biplot.princomp or/and the source 
code of this function.

HIH,
Jinsong

On 2014/8/18 16:31, John Romansic wrote:
> Hi all,
>
> I am using prcomp to do Principle Components Analysis and have run into a
> problem regarding the scale of the axes on my plots.  I am using prcomp to
> analyze a set of 25 morphological measurements taken on each of 161
> individual frogs. I used the biplot function to produce a figure of PC1 vs
> PC2 for each of the individual frogs and arrows that represent the loadings
> of the different morphological measurements on PC1 and PC2. Then I
> constructed a separate, similar plot, using my own coding, that provides a
> number for each individual frogs corresponding to its species as determined
> by genetic analysis, without the arrows. The y-axis on the first plot
> ranges shows PC2 values ranging from about -11 to 11, but the y-axis on the
> second plot shows PC2 values ranging from about -4 to 4, although all the
> data points seem to show up on the figure. I would like to show the same
> PCA results on both plots and I do not understand why the y-axes on these
> two plots do not match. By the way, the x-axes on these two plots seem to
> match, but I think that is just a coincidence. I suspect that my coding for
> the second plot is missing a command regarding scaling of the principle
> components, but it's not obvious to me why those data would have to be
> re-scaled. I thought the scaling is dealt with by prcomp. Within prcomp, I
> used scale=TRUE, which I understand re-scales the original data so that all
> the variables have equal variance.
>
> Does anyone have any suggestions on what might be wrong with my coding?
>
> Below is an example, using a truncated data set, which produces different
> numbers than the example I described above, since this time only 5
> measurements are included for each frog. Nevertheless, the second plot (the
> one with my coding) has the same problem.
>
>> frogs
>      Genetic.species   SVL    HL    HW   BED   FED
> 1                27 47.75 16.46 14.63 13.27  8.29
> 2                25 44.87 16.35 14.67 13.50  8.69
> 3                24 52.57 19.82 16.62 15.12  9.35
> 4                24 56.60 21.18 19.55 17.73 11.09
> 5                20 47.66 18.48 16.33 14.98  9.37
> 6                19 65.96 23.33 20.00 18.88 12.19
> 7                19 58.67 21.12 18.12 17.37 10.47
> 8                19 64.33 23.16 19.99 19.20 11.88
> 9                19 61.03 21.98 19.42 18.22  1.16
> 10               19 62.88 21.90 19.71 17.92 11.65
> 11               19 62.77 21.31 19.30 18.47 11.85
> 12               19 58.64 21.30 19.55 18.17 11.14
> 13               19 63.40 20.74 19.59 18.25 11.03
> 14               19 58.22 19.87 18.82 16.85 10.73
> 15               18 55.43 19.80 18.27 16.01  9.52
> 16               17 60.46 21.40 19.37 16.67 10.44
> 17               16 58.32 19.48 17.55 16.42  9.96
> 18               14 44.64 16.35 14.41 12.77  8.42
> 19               14 48.32 17.88 16.23 14.34  9.01
> 20               13 42.32 15.43 14.40 12.47  7.43
> 21               13 41.87 15.97 14.97 12.46  7.42
> 22               13 45.71 16.87 15.98 13.08  7.77
> 23               12 47.38 17.48 15.77 13.99  9.08
> 24               12 50.28 18.48 17.28 14.87  9.46
> 25               12 48.00 18.52 17.60 15.40  9.63
> 26               12 50.98 18.61 17.87 16.00  9.59
> 27               12 50.76 18.24 17.61 17.72  9.54
> 28               12 50.83 18.90 18.28 15.02  9.53
> 29               11 46.80 19.13 17.10 15.22  9.01
> 30               10 37.55 14.21 12.42 10.79  6.15
> 31               10 40.39 15.32 13.81 11.89  6.80
> 32               10 42.39 14.77 14.72 11.87  6.78
> 33                9 44.08 16.37 15.99 13.09  8.50
> 34                9 47.36 16.16 16.14 13.50  7.72
> 35                8 41.43 15.53 12.73 11.01  6.37
> 36                8 41.45 15.63 13.68 11.32  7.20
> 37                8 38.86 13.82 12.13 10.39  6.28
> 38                8 40.51 14.25 12.68 10.40  6.41
> 39                8 44.64 15.37 13.75 11.37  6.82
> 40                8 45.08 15.64 14.25 11.17  6.68
> 41                8 45.10 16.43 15.03 13.16  7.89
> 42                8 48.94 17.35 16.28 12.31  8.24
> 43                6 44.05 16.60 12.96 12.51  8.19
> 44                6 44.56 16.24 13.86 13.02  8.17
> 45                6 48.01 17.64 15.26 14.59  9.02
> 46                6 48.67 17.84 15.59 14.44  9.36
> 47                6 46.87 18.37 16.18 14.59  9.21
> 48                6 44.32 16.81 14.87 13.55  8.50
> 49                6 44.79 16.14 14.38 13.40  8.91
> 50                6 45.30 16.31 14.62 12.89  8.41
> 51                6 46.36 17.26 15.48 13.30  8.83
> 52                6 46.80 17.55 15.77 13.87  9.01
> 53                6 43.14 15.61 14.23 12.78  8.63
> 54                6 47.99 16.63 15.54 14.00  9.06
> 55                4 63.12 22.52 20.40 17.77 11.60
> 56                4 57.22 20.02 18.44 16.07 10.77
> 57                4 65.55 22.32 20.56 17.53 11.57
> 58                4 60.61 20.74 19.33 16.61 10.20
> 59                4 64.82 22.17 21.27 17.99 10.95
> 60                4 63.03 21.97 21.11 18.25 11.37
> 61                4 64.96 22.93 22.16 19.07 12.30
> 62                4 61.89 21.47 20.78 17.97 10.83
> 63                4 63.34 21.74 21.38 17.60 10.40
> 64                4 65.01 21.74 22.18 19.11 11.47
> 65                4 64.52 21.76 22.49 18.35 10.90
> 66                3 41.34 15.17 12.84 11.87  7.26
> 67                3 48.11 18.45 15.83 14.28  8.65
> 68                3 47.59 17.37 15.01 13.34  8.67
> 69                3 49.25 17.87 15.64 13.74  8.82
> 70                3 44.82 16.47 14.42 13.05  8.35
> 71                3 46.21 16.71 14.70 12.88  8.57
> 72                3 56.24 20.34 18.08 14.72  9.22
> 73                3 53.38 19.64 17.51 14.82  9.12
> 74                3 52.59 19.16 17.23 14.44  9.46
> 75                3 46.27 16.19 14.57 12.39  8.20
> 76                3 49.18 17.68 15.96 14.03  8.98
> 77                3 53.90 20.01 18.20 14.89  9.46
> 78                2 47.62 18.08 15.88 15.02  9.64
> 79                2 48.20 18.04 15.89 14.89  9.23
> 80                2 46.27 16.55 15.19 14.04  8.64
> 81                2 54.04 18.73 17.68 15.79  3.97
> 82                1 53.34 19.76 16.52 15.04  9.36
> 83                1 50.41 17.85 14.96 14.24  8.80
> 84                1 51.71 19.12 16.22 15.16  9.37
> 85                1 49.73 16.91 14.44 13.49  8.64
> 86                1 51.73 18.79 16.07 14.58  8.51
> 87                1 54.50 20.21 17.33 15.45  9.68
> 88                1 54.08 19.96 17.15 15.76  9.78
> 89                1 53.26 18.25 15.70 14.76  9.35
> 90                1 53.20 18.63 16.07 14.79  9.57
> 91                1 47.54 16.61 14.33 13.56  8.33
> 92                1 51.20 18.22 15.73 14.46  9.07
> 93                1 53.56 19.31 16.68 15.33  9.19
> 94                1 48.11 17.11 14.80 13.98  8.15
> 95                1 48.10 17.08 14.78 14.14  8.52
> 96                1 55.97 20.96 18.15 16.06 10.06
> 97                1 56.18 20.43 17.81 16.18 10.27
> 98                1 51.21 18.67 16.34 15.03  9.55
> 99                1 52.25 18.67 16.36 14.26  8.88
> 100               1 51.78 18.58 16.30 14.91  9.21
> 101               1 51.39 18.26 16.02 14.57  9.54
> 102               1 48.45 17.55 15.41 14.16  8.56
> 103               1 54.30 19.08 16.80 15.22  9.69
> 104               1 49.33 16.67 14.73 13.84  8.04
> 105               1 53.41 19.05 16.84 14.86  9.70
> 106               1 48.80 18.56 16.44 14.88  9.31
> 107               1 49.70 18.08 16.03 14.69  9.60
> 108               1 48.28 16.74 14.87 13.72  8.45
> 109               1 51.35 17.86 15.92 14.22  9.07
> 110               1 51.01 17.26 15.39 14.63  9.47
> 111               1 49.89 17.17 15.31 14.21  9.04
> 112               1 54.15 19.69 17.58 15.38 10.17
> 113               1 56.28 20.37 18.20 15.83 10.49
> 114               1 55.30 19.96 17.86 15.66 10.93
> 115               1 44.53 15.56 13.96 12.69  7.81
> 116               1 54.15 18.86 16.93 15.08  9.82
> 117               1 50.59 17.75 15.95 14.66  9.25
> 118               1 52.55 19.63 17.71 15.21  9.98
> 119               1 53.86 19.56 17.66 15.18  9.52
> 120               1 49.91 17.75 16.04 14.21  8.98
> 121               1 52.78 19.21 17.37 15.49  9.92
> 122               1 51.94 18.79 17.00 14.79 10.14
> 123               1 56.60 20.19 18.29 15.86 10.03
> 124               1 51.23 17.66 16.02 14.37  9.30
> 125               1 51.80 19.05 17.30 15.12 10.23
> 126               1 52.78 18.52 16.85 14.80  9.58
> 127               1 51.41 18.13 16.53 14.36  9.02
> 128               1 50.41 18.10 16.52 14.87  9.18
> 129               1 53.48 18.69 17.07 15.19  9.52
> 130               1 53.87 18.60 17.00 15.28  9.92
> 131               1 51.98 18.51 16.93 15.12  9.52
> 132               1 50.56 18.13 16.61 15.12  8.94
> 133               1 50.64 18.16 16.68 14.38  9.04
> 134               1 53.06 18.56 17.06 14.74  9.68
> 135               1 54.64 18.96 17.44 15.61  9.81
> 136               1 48.13 16.91 15.56 14.30  8.96
> 137               1 57.97 21.17 19.48 17.01 10.99
> 138               1 49.93 18.24 16.80 15.20  9.14
> 139               1 47.38 17.02 15.72 14.18  9.14
> 140               1 54.24 19.01 17.60 15.18  9.86
> 141               1 50.17 17.59 16.31 14.53  9.23
> 142               1 49.78 16.77 15.55 13.83  9.12
> 143               1 51.81 18.41 17.09 14.87  9.82
> 144               1 50.84 18.71 17.38 14.79  9.42
> 145               1 49.57 16.41 15.26 13.35  8.80
> 146               1 55.81 19.27 17.92 16.06  9.97
> 147               1 58.03 20.13 18.73 16.28 10.50
> 148               1 48.72 16.62 15.50 14.06  8.60
> 149               1 48.39 17.12 15.97 14.01  9.13
> 150               1 49.01 18.24 17.10 14.76  9.54
> 151               1 50.31 18.23 17.10 15.15  9.76
> 152               1 49.10 17.15 16.11 14.47  8.83
> 153               1 60.04 21.20 19.95 17.53 11.53
> 154               1 46.99 16.87 15.97 13.93  9.10
> 155               1 53.63 19.00 18.08 15.89 10.03
> 156               1 57.88 20.21 19.35 17.34 10.18
> 157               1 54.89 20.06 19.27 16.76 10.78
> 158               1 53.56 19.18 18.52 16.39 10.64
> 159               1 51.50 18.23 17.62 15.21  9.62
> 160               1 63.47 22.12 21.40 17.79 11.65
> 161               1 51.46 17.21 16.90 15.37 10.00
>> frogspca<-prcomp(frogs[2:6],scale=TRUE)
>> summary(frogspca)
> Importance of components:
>                            PC1     PC2     PC3     PC4     PC5
> Standard deviation     2.0950 0.65315 0.27219 0.25087 0.21737
> Proportion of Variance 0.8778 0.08532 0.01482 0.01259 0.00945
> Cumulative Proportion  0.8778 0.96315 0.97796 0.99055 1.00000
>> plot(frogspca)
>> biplot(frogspca)
>> plot( frogspca$x[,1], frogspca$x[,2] , type="n", xlab="PC1", ylab="PC2")
>> text( frogspca$x[,1], frogspca$x[,2], labels=c(Genetic.species))
>>
> Thank you very much for any suggestions you might have,
> John Romansic
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From istazahn at gmail.com  Tue Aug 19 03:09:02 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 18 Aug 2014 21:09:02 -0400
Subject: [R] Building and scoring multiple models with dplyr functions
In-Reply-To: <CAOfxo3MTa0nzJc35sfrCkFx0LfRMQgEi53Ohpt_+q2RXKmg8Ng@mail.gmail.com>
References: <CAOfxo3MTa0nzJc35sfrCkFx0LfRMQgEi53Ohpt_+q2RXKmg8Ng@mail.gmail.com>
Message-ID: <CA+vqiLGtS7SnEZjiRokzmzGaKj1tcfa+Xw_qPwxrvPXeiToMJw@mail.gmail.com>

At the risk of being old-fashioned, I suggest doing this in a
for-loop. Why struggle to fit this into the dplyr framework when a
straight-forward loop will do the trick?

This is untested in the absence of example data, but something along
the lines of

models <- list()
predictions <- list()
for(g in unique(model_data$group)) {
    models[[g]] <- glm(cbind(y,n) ~ var1 + var2 +
                           var3 + var4 + var5 +
                           var6 + var7 + var8 +
                           var9 + var10,
                       family = binomial,
                       data = subset(model_data, group == g)
                       )
    predictions[[g]] <- predict(models[[g]],
                                newdata = subset(new_data, group == g))
}

should do it.

Best,
Ista

On Mon, Aug 18, 2014 at 3:58 PM, Andrew Agrimson <jagrimsasl at gmail.com> wrote:
> Hello All,
>
> I have a question regarding building multiple models and then scoring new
> data with these models. I have been tasked with converting existing SAS
> modeling code into equivalent R code, but unfortunately I rarely use R so
> I'm in unfamiliar territory. I've think I've found a good way to build the
> models using dplyr functions, however I'm having difficulty figuring out
> how to use the models to score new data.
>
>
> *The SAS code I'm converting builds multiple binomial models using the "BY"
> statement in the GLIMMIX procedure. The results of the modeling fitting
> process are stored using the "STORE" statement. *
>
> *proc* *glimmix* data = model_data;
>
> by group;
>
> model y/n = var1-var10/dist=bin;
>
> store model;
>
> *quit*;
>
>
> *The next step is to score a new data set using the PLM procedure. The "New
> Data" is also grouped by "group" and PLM is able to match and apply the
> appropriate model with the appropriate "by" value. *
>
> *proc* *plm* restore=model;
>
> score data=new_data out=scored predicted=p/ilink;
>
> *run*;
>
>
> *In R I've been able to reproduce the first model building step using dplyr
> functions and it seems to work quite well. In fact it's much faster than my
> SAS implementation.*
>
> by_group <- group_by(model_data, group)
>
> models <- by_group %>% do(mod = glm(cbind(y,n) ~ var1 + var2 + var3 + var4
> + var5 + var6 + var7 + var8 + var9 + var10,
>                                 family = binomial, data = .))
>
>
> *As stated above, I cannot figure out how to apply these models to new
> data.  I've scoured the internet and the documentation for an example but
> so far no luck. I want to extract the model objects out of the data frame
> "models" and apply the "predict" function, but my novice knowledge of R and
> dplyr specifically is making this very difficult.*
>
> *Any help or advice would be greatly appreciated.*
>
>
> *Thanks,*
>
> *Andy*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Aug 19 04:20:31 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 18 Aug 2014 19:20:31 -0700
Subject: [R] loading saved files with objects in same names
In-Reply-To: <53F29AAC.8000009@yeah.net>
References: <53F29AAC.8000009@yeah.net>
Message-ID: <CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>

Have you tried the 'envir' argument to load()?  E.g.,
   envA <- new.environment()
   load("A.RData", envir=envA)
   envB <- new.environment()
   load("B.RData", envir=envB)
   plot(A$object, B$object)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 18, 2014 at 5:30 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
> each file, there are some objects with same names but different contents.
> Now, I need to compare those objects through plotting. However, I can't find
> a way to load them into a workspace. The only thing I can do is to rename
> them and then save and load again.
>
> Is there a convenient to load those objects?
>
> Thanks a lot in advance.
>
> Best regards,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Aug 19 04:52:49 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 19 Aug 2014 14:52:49 +1200
Subject: [R] loading saved files with objects in same names
In-Reply-To: <CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
References: <53F29AAC.8000009@yeah.net>
	<CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
Message-ID: <53F2BC01.3000506@auckland.ac.nz>

On 19/08/14 14:20, William Dunlap wrote:
> Have you tried the 'envir' argument to load()?  E.g.,
>     envA <- new.environment()
>     load("A.RData", envir=envA)
>     envB <- new.environment()
>     load("B.RData", envir=envB)
>     plot(A$object, B$object)


Did you mean

      plot(envA$object, envB$object)

???  Or am I misunderstanding something?

cheers,

Rolf



-- 
Rolf Turner
Technical Editor ANZJS


From wdunlap at tibco.com  Tue Aug 19 05:03:02 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 18 Aug 2014 20:03:02 -0700
Subject: [R] loading saved files with objects in same names
In-Reply-To: <53F2BC01.3000506@auckland.ac.nz>
References: <53F29AAC.8000009@yeah.net>
	<CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
	<53F2BC01.3000506@auckland.ac.nz>
Message-ID: <CAF8bMcYrNZr9Px0sJBq0Eq+xOxHtqGUEgNqPQwYwYKy=Lhx+6Q@mail.gmail.com>

Rolf,
   Yes, I meant to write envA$object, etc, but did not read it twice
before running off to dinner.  Thanks.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 18, 2014 at 7:52 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 19/08/14 14:20, William Dunlap wrote:
>>
>> Have you tried the 'envir' argument to load()?  E.g.,
>>     envA <- new.environment()
>>     load("A.RData", envir=envA)
>>     envB <- new.environment()
>>     load("B.RData", envir=envB)
>>     plot(A$object, B$object)
>
>
>
> Did you mean
>
>      plot(envA$object, envB$object)
>
> ???  Or am I misunderstanding something?
>
> cheers,
>
> Rolf
>
>
>
> --
> Rolf Turner
> Technical Editor ANZJS


From untungk at bps.go.id  Tue Aug 19 06:34:43 2014
From: untungk at bps.go.id (Untung Kurniawan)
Date: Tue, 19 Aug 2014 11:34:43 +0700 (WIT)
Subject: [R] programme bivariate binomial negative
Message-ID: <1878477202.52484.1408422883989.JavaMail.root@bps.go.id>

I'm making a thesis with bonimial negative bivariate regression, please help me to be delivered program. thank you.


From jszhao at yeah.net  Tue Aug 19 07:26:34 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Mon, 18 Aug 2014 22:26:34 -0700
Subject: [R] loading saved files with objects in same names
In-Reply-To: <CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
References: <53F29AAC.8000009@yeah.net>
	<CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
Message-ID: <53F2E00A.5070602@yeah.net>

On 2014/8/18 19:20, William Dunlap wrote:
> Have you tried the 'envir' argument to load()?  E.g.,
>     envA <- new.environment()
>     load("A.RData", envir=envA)
>     envB <- new.environment()
>     load("B.RData", envir=envB)
>     plot(A$object, B$object)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>

Thank you very much. It is what I want.
new.environment() is not defined in R 3.1.1. There is new.env().

Best,
Jinsong

>
> On Mon, Aug 18, 2014 at 5:30 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
>> Hi there,
>>
>> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
>> each file, there are some objects with same names but different contents.
>> Now, I need to compare those objects through plotting. However, I can't find
>> a way to load them into a workspace. The only thing I can do is to rename
>> them and then save and load again.
>>
>> Is there a convenient to load those objects?
>>
>> Thanks a lot in advance.
>>
>> Best regards,
>> Jinsong
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From jan.stanstrup at fmach.it  Tue Aug 19 09:44:39 2014
From: jan.stanstrup at fmach.it (Jan Stanstrup)
Date: Tue, 19 Aug 2014 09:44:39 +0200
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
In-Reply-To: <507AB734-9E08-4F65-9FEB-2FB547691B1E@comcast.net>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
	<53ECC50B.3000606@fmach.it>
	<A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
	<53F1E9DC.9000302@fmach.it>
	<507AB734-9E08-4F65-9FEB-2FB547691B1E@comcast.net>
Message-ID: <53F30067.90600@fmach.it>

Sorry. I have updated the code to have include the knot selection 
(https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R). 
I am working on the "Good data" at the moment.


- Jan.




On 08/18/2014 08:14 PM, David Winsemius wrote:
> I had that result sometimes when testing as well. You don't offer any code so there's nothing I can do to follow-up.
>


	[[alternative HTML version deleted]]


From jan.stanstrup at fmach.it  Tue Aug 19 09:56:07 2014
From: jan.stanstrup at fmach.it (Jan Stanstrup)
Date: Tue, 19 Aug 2014 09:56:07 +0200
Subject: [R] Prediction intervals (i.e. not CI of the fit) for monotonic
 loess curve using bootstrapping
In-Reply-To: <53F30067.90600@fmach.it>
References: <53E9C0E6.6040101@fmach.it>
	<10330A1C-0BDB-437A-9920-B010850CFA54@comcast.net>
	<CACk-te0jShqHkPdWdiDzNHSr26JZoLauhSd_X=_DwLUwXvC=3w@mail.gmail.com>
	<F077C858-3C95-4C8F-9C15-7396BC88BF41@comcast.net>
	<53ECC50B.3000606@fmach.it>
	<A35B1DA7-EE52-4E9F-8333-B0DFDFF1E00D@comcast.net>
	<53F1E9DC.9000302@fmach.it>
	<507AB734-9E08-4F65-9FEB-2FB547691B1E@comcast.net>
	<53F30067.90600@fmach.it>
Message-ID: <53F30317.9060806@fmach.it>

And just then I realized the problem. nknots need to be length(knots). 
Otherwise knots are deleted.

I am not so sure this works equally well as my original loess fit 
though. The fit I get with cobs is highly dependent on the "knot step 
size". At 0.4 for example it seems ok. At 0.3 I get points with 
basically zero width intervals. At 0.2 it breaks ("There is at least one 
pair of adjacent knots that contains no observation."). Not so great for 
my use case where I need to build many models unsupervised.



- Jan.




On 08/19/2014 09:44 AM, Jan Stanstrup wrote:
> Sorry. I have updated the code to have include the knot selection 
> (https://github.com/stanstrup/retpred_shiny/blob/master/retdb_admin/make_predictions_CI_tests.R). 
> I am working on the "Good data" at the moment.
>
>
> - Jan.
>
>
>
>
> On 08/18/2014 08:14 PM, David Winsemius wrote:
>> I had that result sometimes when testing as well. You don't offer any code so there's nothing I can do to follow-up.
>>
>


	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Tue Aug 19 12:14:46 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 19 Aug 2014 18:14:46 +0800 (CST)
Subject: [R]     A question  in Rinternals.h
Message-ID: <4e6016c3.c722.147edc30494.Coremail.rhelpmaillist@163.com>



Dear Rusers,
    when i am reading Rinternals.h file, i can't understand the following codes in lines 395-407:


#define CHAR(x)R_CHAR(x)
const char *(R_CHAR)(SEXP x);
/* Various tests with macro versions below */
Rboolean (Rf_isNull)(SEXP s);
Rboolean (Rf_isSymbol)(SEXP s);
Rboolean (Rf_isLogical)(SEXP s);
Rboolean (Rf_isReal)(SEXP s);
Rboolean (Rf_isComplex)(SEXP s);
Rboolean (Rf_isExpression)(SEXP s);
Rboolean (Rf_isEnvironment)(SEXP s);
Rboolean (Rf_isString)(SEXP s);
Rboolean (Rf_isObject)(SEXP s);


I can't figure out what are "R_CHAR,Rf_isNull....Rf_isObject" meaning, they seem like function declarations, Rf_XXX maybe function pointers?
I need your help.




--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU
	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Tue Aug 19 12:28:06 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 19 Aug 2014 11:28:06 +0100
Subject: [R] A question  in Rinternals.h
In-Reply-To: <4e6016c3.c722.147edc30494.Coremail.rhelpmaillist@163.com>
References: <4e6016c3.c722.147edc30494.Coremail.rhelpmaillist@163.com>
Message-ID: <53F326B6.6010507@stats.ox.ac.uk>

Please do read the posting guide (clearly you have not as you sent HTML).

- This is the wrong list: it is a question about C code.

- In any case, it is about C.  The R Internals manual may help you, 
otherwise you need to talk to a local C adviser.  (Even if this were not 
off-topic here, we do not know what it is you cannot 'figure out' and 
you need to interact with someone.)

On 19/08/2014 11:14, PO SU wrote:
>
>
> Dear Rusers,
>      when i am reading Rinternals.h file, i can't understand the following codes in lines 395-407:
>
>
> #define CHAR(x)R_CHAR(x)
> const char *(R_CHAR)(SEXP x);
> /* Various tests with macro versions below */
> Rboolean (Rf_isNull)(SEXP s);
> Rboolean (Rf_isSymbol)(SEXP s);
> Rboolean (Rf_isLogical)(SEXP s);
> Rboolean (Rf_isReal)(SEXP s);
> Rboolean (Rf_isComplex)(SEXP s);
> Rboolean (Rf_isExpression)(SEXP s);
> Rboolean (Rf_isEnvironment)(SEXP s);
> Rboolean (Rf_isString)(SEXP s);
> Rboolean (Rf_isObject)(SEXP s);
>
>
> I can't figure out what are "R_CHAR,Rf_isNull....Rf_isObject" meaning, they seem like function declarations, Rf_XXX maybe function pointers?
> I need your help.
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From info at aghmed.fsnet.co.uk  Tue Aug 19 12:37:11 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Tue, 19 Aug 2014 11:37:11 +0100
Subject: [R] programme bivariate binomial negative
In-Reply-To: <1878477202.52484.1408422883989.JavaMail.root@bps.go.id>
References: <1878477202.52484.1408422883989.JavaMail.root@bps.go.id>
Message-ID: <Zen-1XJgn2-0002hG-Ry@smarthost01c.mail.zen.net.uk>

At 05:34 19/08/2014, Untung Kurniawan wrote:
>I'm making a thesis with bonimial negative bivariate regression, 
>please help me to be delivered program. thank you.

library(sos) # install sos first if you do not already have it
findFn("negative binomial bivariate regression")

This gives you quite a list of posibilities


Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From oma.gonzales at gmail.com  Tue Aug 19 11:21:19 2014
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Tue, 19 Aug 2014 04:21:19 -0500
Subject: [R] GSUB and Data.frame format lost
Message-ID: <CAM-xyZhkWcm18xTQt8jVtWNDHBPsc1jhNo60-goHB0xZS99oxw@mail.gmail.com>

Hi all,

please, i'm trying to understand how using "Gsub" for some search and
replace of text, makes my data frame lost it's format.

This is my code:

<code>

DataGoogle1 <- read.csv(file = "DataGoogle2.csv", header = T,
stringsAsFactors = F)
head(DataGoogle1)

</code>

Result 1:

Campa?a                    Visitas     Compras
1 facebook-Ads1         524         2
2 faceBOOK-Ads1       487         24
3 fcebook-ads12          258         4
4        Email1                8             7
5         mail1                 224         2
6     referral1                147         7


Then i apply the GSUB function like this:

<code> DataGoogle2 <- as.data.frame(gsub("facebook-Ads1", "FBAds",
DataGoogle1$Campa?a)) </code>

And the result is:

DataGoogle2
   gsub..facebook.Ads1....FBAds...DataGoogle1.Campa?a.
1                                                FBAds
2                                        faceBOOK-Ads1
3                                        fcebook-ads12
4                                               Email1
5                                                mail1
6                                            referral1

...

The Search and Replace works, but my data.frame does not. Even if i use:
"as.data.frame" before of the "gsub" function. Please, tell me what can i
do... Cheers!

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Aug 19 15:36:16 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 19 Aug 2014 13:36:16 +0000
Subject: [R] principle component values on PCA plots do not match
In-Reply-To: <53F29D52.9070701@yeah.net>
References: <CAG+2bO786bBE35e-H2sm9D=PUvWkDEGjgJEoHL+SUjy5ZRo=iw@mail.gmail.com>
	<53F29D52.9070701@yeah.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F91681@mb02.ads.tamu.edu>

Try using scale=0 with the biplot function).

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jinsong Zhao
Sent: Monday, August 18, 2014 7:42 PM
To: r-help at r-project.org
Subject: Re: [R] principle component values on PCA plots do not match

Hi,

There is a scale factor associated with biplot when plotting the PCA 
result. Please read the help page of biplot.princomp or/and the source 
code of this function.

HIH,
Jinsong

On 2014/8/18 16:31, John Romansic wrote:
> Hi all,
>
> I am using prcomp to do Principle Components Analysis and have run into a
> problem regarding the scale of the axes on my plots.  I am using prcomp to
> analyze a set of 25 morphological measurements taken on each of 161
> individual frogs. I used the biplot function to produce a figure of PC1 vs
> PC2 for each of the individual frogs and arrows that represent the loadings
> of the different morphological measurements on PC1 and PC2. Then I
> constructed a separate, similar plot, using my own coding, that provides a
> number for each individual frogs corresponding to its species as determined
> by genetic analysis, without the arrows. The y-axis on the first plot
> ranges shows PC2 values ranging from about -11 to 11, but the y-axis on the
> second plot shows PC2 values ranging from about -4 to 4, although all the
> data points seem to show up on the figure. I would like to show the same
> PCA results on both plots and I do not understand why the y-axes on these
> two plots do not match. By the way, the x-axes on these two plots seem to
> match, but I think that is just a coincidence. I suspect that my coding for
> the second plot is missing a command regarding scaling of the principle
> components, but it's not obvious to me why those data would have to be
> re-scaled. I thought the scaling is dealt with by prcomp. Within prcomp, I
> used scale=TRUE, which I understand re-scales the original data so that all
> the variables have equal variance.
>
> Does anyone have any suggestions on what might be wrong with my coding?
>
> Below is an example, using a truncated data set, which produces different
> numbers than the example I described above, since this time only 5
> measurements are included for each frog. Nevertheless, the second plot (the
> one with my coding) has the same problem.
>
>> frogs
>      Genetic.species   SVL    HL    HW   BED   FED
> 1                27 47.75 16.46 14.63 13.27  8.29
> 2                25 44.87 16.35 14.67 13.50  8.69
> 3                24 52.57 19.82 16.62 15.12  9.35
> 4                24 56.60 21.18 19.55 17.73 11.09
> 5                20 47.66 18.48 16.33 14.98  9.37
> 6                19 65.96 23.33 20.00 18.88 12.19
> 7                19 58.67 21.12 18.12 17.37 10.47
> 8                19 64.33 23.16 19.99 19.20 11.88
> 9                19 61.03 21.98 19.42 18.22  1.16
> 10               19 62.88 21.90 19.71 17.92 11.65
> 11               19 62.77 21.31 19.30 18.47 11.85
> 12               19 58.64 21.30 19.55 18.17 11.14
> 13               19 63.40 20.74 19.59 18.25 11.03
> 14               19 58.22 19.87 18.82 16.85 10.73
> 15               18 55.43 19.80 18.27 16.01  9.52
> 16               17 60.46 21.40 19.37 16.67 10.44
> 17               16 58.32 19.48 17.55 16.42  9.96
> 18               14 44.64 16.35 14.41 12.77  8.42
> 19               14 48.32 17.88 16.23 14.34  9.01
> 20               13 42.32 15.43 14.40 12.47  7.43
> 21               13 41.87 15.97 14.97 12.46  7.42
> 22               13 45.71 16.87 15.98 13.08  7.77
> 23               12 47.38 17.48 15.77 13.99  9.08
> 24               12 50.28 18.48 17.28 14.87  9.46
> 25               12 48.00 18.52 17.60 15.40  9.63
> 26               12 50.98 18.61 17.87 16.00  9.59
> 27               12 50.76 18.24 17.61 17.72  9.54
> 28               12 50.83 18.90 18.28 15.02  9.53
> 29               11 46.80 19.13 17.10 15.22  9.01
> 30               10 37.55 14.21 12.42 10.79  6.15
> 31               10 40.39 15.32 13.81 11.89  6.80
> 32               10 42.39 14.77 14.72 11.87  6.78
> 33                9 44.08 16.37 15.99 13.09  8.50
> 34                9 47.36 16.16 16.14 13.50  7.72
> 35                8 41.43 15.53 12.73 11.01  6.37
> 36                8 41.45 15.63 13.68 11.32  7.20
> 37                8 38.86 13.82 12.13 10.39  6.28
> 38                8 40.51 14.25 12.68 10.40  6.41
> 39                8 44.64 15.37 13.75 11.37  6.82
> 40                8 45.08 15.64 14.25 11.17  6.68
> 41                8 45.10 16.43 15.03 13.16  7.89
> 42                8 48.94 17.35 16.28 12.31  8.24
> 43                6 44.05 16.60 12.96 12.51  8.19
> 44                6 44.56 16.24 13.86 13.02  8.17
> 45                6 48.01 17.64 15.26 14.59  9.02
> 46                6 48.67 17.84 15.59 14.44  9.36
> 47                6 46.87 18.37 16.18 14.59  9.21
> 48                6 44.32 16.81 14.87 13.55  8.50
> 49                6 44.79 16.14 14.38 13.40  8.91
> 50                6 45.30 16.31 14.62 12.89  8.41
> 51                6 46.36 17.26 15.48 13.30  8.83
> 52                6 46.80 17.55 15.77 13.87  9.01
> 53                6 43.14 15.61 14.23 12.78  8.63
> 54                6 47.99 16.63 15.54 14.00  9.06
> 55                4 63.12 22.52 20.40 17.77 11.60
> 56                4 57.22 20.02 18.44 16.07 10.77
> 57                4 65.55 22.32 20.56 17.53 11.57
> 58                4 60.61 20.74 19.33 16.61 10.20
> 59                4 64.82 22.17 21.27 17.99 10.95
> 60                4 63.03 21.97 21.11 18.25 11.37
> 61                4 64.96 22.93 22.16 19.07 12.30
> 62                4 61.89 21.47 20.78 17.97 10.83
> 63                4 63.34 21.74 21.38 17.60 10.40
> 64                4 65.01 21.74 22.18 19.11 11.47
> 65                4 64.52 21.76 22.49 18.35 10.90
> 66                3 41.34 15.17 12.84 11.87  7.26
> 67                3 48.11 18.45 15.83 14.28  8.65
> 68                3 47.59 17.37 15.01 13.34  8.67
> 69                3 49.25 17.87 15.64 13.74  8.82
> 70                3 44.82 16.47 14.42 13.05  8.35
> 71                3 46.21 16.71 14.70 12.88  8.57
> 72                3 56.24 20.34 18.08 14.72  9.22
> 73                3 53.38 19.64 17.51 14.82  9.12
> 74                3 52.59 19.16 17.23 14.44  9.46
> 75                3 46.27 16.19 14.57 12.39  8.20
> 76                3 49.18 17.68 15.96 14.03  8.98
> 77                3 53.90 20.01 18.20 14.89  9.46
> 78                2 47.62 18.08 15.88 15.02  9.64
> 79                2 48.20 18.04 15.89 14.89  9.23
> 80                2 46.27 16.55 15.19 14.04  8.64
> 81                2 54.04 18.73 17.68 15.79  3.97
> 82                1 53.34 19.76 16.52 15.04  9.36
> 83                1 50.41 17.85 14.96 14.24  8.80
> 84                1 51.71 19.12 16.22 15.16  9.37
> 85                1 49.73 16.91 14.44 13.49  8.64
> 86                1 51.73 18.79 16.07 14.58  8.51
> 87                1 54.50 20.21 17.33 15.45  9.68
> 88                1 54.08 19.96 17.15 15.76  9.78
> 89                1 53.26 18.25 15.70 14.76  9.35
> 90                1 53.20 18.63 16.07 14.79  9.57
> 91                1 47.54 16.61 14.33 13.56  8.33
> 92                1 51.20 18.22 15.73 14.46  9.07
> 93                1 53.56 19.31 16.68 15.33  9.19
> 94                1 48.11 17.11 14.80 13.98  8.15
> 95                1 48.10 17.08 14.78 14.14  8.52
> 96                1 55.97 20.96 18.15 16.06 10.06
> 97                1 56.18 20.43 17.81 16.18 10.27
> 98                1 51.21 18.67 16.34 15.03  9.55
> 99                1 52.25 18.67 16.36 14.26  8.88
> 100               1 51.78 18.58 16.30 14.91  9.21
> 101               1 51.39 18.26 16.02 14.57  9.54
> 102               1 48.45 17.55 15.41 14.16  8.56
> 103               1 54.30 19.08 16.80 15.22  9.69
> 104               1 49.33 16.67 14.73 13.84  8.04
> 105               1 53.41 19.05 16.84 14.86  9.70
> 106               1 48.80 18.56 16.44 14.88  9.31
> 107               1 49.70 18.08 16.03 14.69  9.60
> 108               1 48.28 16.74 14.87 13.72  8.45
> 109               1 51.35 17.86 15.92 14.22  9.07
> 110               1 51.01 17.26 15.39 14.63  9.47
> 111               1 49.89 17.17 15.31 14.21  9.04
> 112               1 54.15 19.69 17.58 15.38 10.17
> 113               1 56.28 20.37 18.20 15.83 10.49
> 114               1 55.30 19.96 17.86 15.66 10.93
> 115               1 44.53 15.56 13.96 12.69  7.81
> 116               1 54.15 18.86 16.93 15.08  9.82
> 117               1 50.59 17.75 15.95 14.66  9.25
> 118               1 52.55 19.63 17.71 15.21  9.98
> 119               1 53.86 19.56 17.66 15.18  9.52
> 120               1 49.91 17.75 16.04 14.21  8.98
> 121               1 52.78 19.21 17.37 15.49  9.92
> 122               1 51.94 18.79 17.00 14.79 10.14
> 123               1 56.60 20.19 18.29 15.86 10.03
> 124               1 51.23 17.66 16.02 14.37  9.30
> 125               1 51.80 19.05 17.30 15.12 10.23
> 126               1 52.78 18.52 16.85 14.80  9.58
> 127               1 51.41 18.13 16.53 14.36  9.02
> 128               1 50.41 18.10 16.52 14.87  9.18
> 129               1 53.48 18.69 17.07 15.19  9.52
> 130               1 53.87 18.60 17.00 15.28  9.92
> 131               1 51.98 18.51 16.93 15.12  9.52
> 132               1 50.56 18.13 16.61 15.12  8.94
> 133               1 50.64 18.16 16.68 14.38  9.04
> 134               1 53.06 18.56 17.06 14.74  9.68
> 135               1 54.64 18.96 17.44 15.61  9.81
> 136               1 48.13 16.91 15.56 14.30  8.96
> 137               1 57.97 21.17 19.48 17.01 10.99
> 138               1 49.93 18.24 16.80 15.20  9.14
> 139               1 47.38 17.02 15.72 14.18  9.14
> 140               1 54.24 19.01 17.60 15.18  9.86
> 141               1 50.17 17.59 16.31 14.53  9.23
> 142               1 49.78 16.77 15.55 13.83  9.12
> 143               1 51.81 18.41 17.09 14.87  9.82
> 144               1 50.84 18.71 17.38 14.79  9.42
> 145               1 49.57 16.41 15.26 13.35  8.80
> 146               1 55.81 19.27 17.92 16.06  9.97
> 147               1 58.03 20.13 18.73 16.28 10.50
> 148               1 48.72 16.62 15.50 14.06  8.60
> 149               1 48.39 17.12 15.97 14.01  9.13
> 150               1 49.01 18.24 17.10 14.76  9.54
> 151               1 50.31 18.23 17.10 15.15  9.76
> 152               1 49.10 17.15 16.11 14.47  8.83
> 153               1 60.04 21.20 19.95 17.53 11.53
> 154               1 46.99 16.87 15.97 13.93  9.10
> 155               1 53.63 19.00 18.08 15.89 10.03
> 156               1 57.88 20.21 19.35 17.34 10.18
> 157               1 54.89 20.06 19.27 16.76 10.78
> 158               1 53.56 19.18 18.52 16.39 10.64
> 159               1 51.50 18.23 17.62 15.21  9.62
> 160               1 63.47 22.12 21.40 17.79 11.65
> 161               1 51.46 17.21 16.90 15.37 10.00
>> frogspca<-prcomp(frogs[2:6],scale=TRUE)
>> summary(frogspca)
> Importance of components:
>                            PC1     PC2     PC3     PC4     PC5
> Standard deviation     2.0950 0.65315 0.27219 0.25087 0.21737
> Proportion of Variance 0.8778 0.08532 0.01482 0.01259 0.00945
> Cumulative Proportion  0.8778 0.96315 0.97796 0.99055 1.00000
>> plot(frogspca)
>> biplot(frogspca)
>> plot( frogspca$x[,1], frogspca$x[,2] , type="n", xlab="PC1", ylab="PC2")
>> text( frogspca$x[,1], frogspca$x[,2], labels=c(Genetic.species))
>>
> Thank you very much for any suggestions you might have,
> John Romansic
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at u-bourgogne.fr  Tue Aug 19 15:41:10 2014
From: ivan.calandra at u-bourgogne.fr (Ivan Calandra)
Date: Tue, 19 Aug 2014 15:41:10 +0200
Subject: [R] GSUB and Data.frame format lost
In-Reply-To: <CAM-xyZhkWcm18xTQt8jVtWNDHBPsc1jhNo60-goHB0xZS99oxw@mail.gmail.com>
References: <CAM-xyZhkWcm18xTQt8jVtWNDHBPsc1jhNo60-goHB0xZS99oxw@mail.gmail.com>
Message-ID: <53F353F6.7000102@u-bourgogne.fr>

Hi,

If I understand you well, the problem is that DataGoogle2 is a 1-column 
data.frame and this is expected based on your code!

I think you want something like this to change the 1st column of the 
data.frame:
DataGoogle2 <- DataGoogle1
DataGoogle2$Campa?a <- gsub("facebook-Ads1", "FBAds", DataGoogle2$Campa?a)

HTH,
Ivan

--
Ivan Calandra
University of Franche-Comt?
Laboratoire Chrono-Environnement
Bureau ATER -107L
16, Route de Gray
25030 Besan?on Cedex, France
ivan.calandra at univ-fcomte.fr
+33 (0) 381 66 20 60
http://chrono-environnement.univ-fcomte.fr/spip.php?article1830

Le 19/08/14 11:21, Omar Andr? Gonz?les D?az a ?crit :
> Hi all,
>
> please, i'm trying to understand how using "Gsub" for some search and
> replace of text, makes my data frame lost it's format.
>
> This is my code:
>
> <code>
>
> DataGoogle1 <- read.csv(file = "DataGoogle2.csv", header = T,
> stringsAsFactors = F)
> head(DataGoogle1)
>
> </code>
>
> Result 1:
>
> Campa?a                    Visitas     Compras
> 1 facebook-Ads1         524         2
> 2 faceBOOK-Ads1       487         24
> 3 fcebook-ads12          258         4
> 4        Email1                8             7
> 5         mail1                 224         2
> 6     referral1                147         7
>
>
> Then i apply the GSUB function like this:
>
> <code> DataGoogle2 <- as.data.frame(gsub("facebook-Ads1", "FBAds",
> DataGoogle1$Campa?a)) </code>
>
> And the result is:
>
> DataGoogle2
>     gsub..facebook.Ads1....FBAds...DataGoogle1.Campa?a.
> 1                                                FBAds
> 2                                        faceBOOK-Ads1
> 3                                        fcebook-ads12
> 4                                               Email1
> 5                                                mail1
> 6                                            referral1
>
> ...
>
> The Search and Replace works, but my data.frame does not. Even if i use:
> "as.data.frame" before of the "gsub" function. Please, tell me what can i
> do... Cheers!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Tue Aug 19 17:22:13 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 19 Aug 2014 23:22:13 +0800 (CST)
Subject: [R] A question  in Rinternals.h
In-Reply-To: <53F326B6.6010507@stats.ox.ac.uk>
References: <4e6016c3.c722.147edc30494.Coremail.rhelpmaillist@163.com>
	<53F326B6.6010507@stats.ox.ac.uk>
Message-ID: <6b0fb285.13cdb.147eedc7dcb.Coremail.rhelpmaillist@163.com>

Tks for your guide, but before i know which maillist should i ask the question, i could only ask it here.  'figure out'  i mean 'understand'. Forgive my pool english :).


--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2014-08-19 06:28:06, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>Please do read the posting guide (clearly you have not as you sent HTML).
>
>- This is the wrong list: it is a question about C code.
>
>- In any case, it is about C.  The R Internals manual may help you, 
>otherwise you need to talk to a local C adviser.  (Even if this were not 
>off-topic here, we do not know what it is you cannot 'figure out' and 
>you need to interact with someone.)
>
>On 19/08/2014 11:14, PO SU wrote:
>>
>>
>> Dear Rusers,
>>      when i am reading Rinternals.h file, i can't understand the following codes in lines 395-407:
>>
>>
>> #define CHAR(x)R_CHAR(x)
>> const char *(R_CHAR)(SEXP x);
>> /* Various tests with macro versions below */
>> Rboolean (Rf_isNull)(SEXP s);
>> Rboolean (Rf_isSymbol)(SEXP s);
>> Rboolean (Rf_isLogical)(SEXP s);
>> Rboolean (Rf_isReal)(SEXP s);
>> Rboolean (Rf_isComplex)(SEXP s);
>> Rboolean (Rf_isExpression)(SEXP s);
>> Rboolean (Rf_isEnvironment)(SEXP s);
>> Rboolean (Rf_isString)(SEXP s);
>> Rboolean (Rf_isObject)(SEXP s);
>>
>>
>> I can't figure out what are "R_CHAR,Rf_isNull....Rf_isObject" meaning, they seem like function declarations, Rf_XXX maybe function pointers?
>> I need your help.
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Emeritus Professor of Applied Statistics, University of Oxford
>1 South Parks Road, Oxford OX1 3TG, UK

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Tue Aug 19 17:26:47 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 19 Aug 2014 23:26:47 +0800 (CST)
Subject: [R] A question  in Rinternals.h
In-Reply-To: <53F326B6.6010507@stats.ox.ac.uk>
References: <4e6016c3.c722.147edc30494.Coremail.rhelpmaillist@163.com>
	<53F326B6.6010507@stats.ox.ac.uk>
Message-ID: <7f486829.13d73.147eee0ad22.Coremail.rhelpmaillist@163.com>




BTW, you say i always send html format email, finally i find that it is my mail server which send mail in html format by default., i should change the format eveytime before sending a mail.......


--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-08-19 06:28:06, "Prof Brian Ripley" <ripley at stats.ox.ac.uk> wrote:
>Please do read the posting guide (clearly you have not as you sent HTML).
>
>- This is the wrong list: it is a question about C code.
>
>- In any case, it is about C.  The R Internals manual may help you, 
>otherwise you need to talk to a local C adviser.  (Even if this were not 
>off-topic here, we do not know what it is you cannot 'figure out' and 
>you need to interact with someone.)
>
>On 19/08/2014 11:14, PO SU wrote:
>>
>>
>> Dear Rusers,
>>      when i am reading Rinternals.h file, i can't understand the following codes in lines 395-407:
>>
>>
>> #define CHAR(x)R_CHAR(x)
>> const char *(R_CHAR)(SEXP x);
>> /* Various tests with macro versions below */
>> Rboolean (Rf_isNull)(SEXP s);
>> Rboolean (Rf_isSymbol)(SEXP s);
>> Rboolean (Rf_isLogical)(SEXP s);
>> Rboolean (Rf_isReal)(SEXP s);
>> Rboolean (Rf_isComplex)(SEXP s);
>> Rboolean (Rf_isExpression)(SEXP s);
>> Rboolean (Rf_isEnvironment)(SEXP s);
>> Rboolean (Rf_isString)(SEXP s);
>> Rboolean (Rf_isObject)(SEXP s);
>>
>>
>> I can't figure out what are "R_CHAR,Rf_isNull....Rf_isObject" meaning, they seem like function declarations, Rf_XXX maybe function pointers?
>> I need your help.
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>-- 
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Emeritus Professor of Applied Statistics, University of Oxford
>1 South Parks Road, Oxford OX1 3TG, UK

From Alexander.Sommer at tu-dortmund.de  Tue Aug 19 16:01:33 2014
From: Alexander.Sommer at tu-dortmund.de (Alexander Sommer)
Date: Tue, 19 Aug 2014 16:01:33 +0200
Subject: [R] Weighted Mann-Whitney-Wilcoxon-Test
Message-ID: <000301cfbbb6$18c55020$4a4ff060$@tu-dortmund.de>

Hi fellow R-users,

well, say I got two groups, A and B. Nested within each group are subgroups and in each subgroup are objects with values x and y to a certain attribute. So, I can compute the portion of x-objects for each subgroup as #x/(#x?+?#y).

Artificial example with 12 subgroups in group A and 8 subgroups in group B:

set.seed(123)
count.x <- NULL
count.y <- NULL
j <- 1
for (i in sample(x = 10:20, size = 20, replace = TRUE)){
 count.x[j] <- sample(x = 0:i, size = 1)
 count.y[j] <- i - count.x[j]
 j          <- j + 1
}
data <- data.frame(x.portion = (count.x/(count.x + count.y)),
                   x.portion = (count.y/(count.x + count.y)),
                   group     = c(rep("A", 12), rep("B", 8),
                   weight    = (count.x + count.y)
                  )

I am now interested in whether or not there is a difference in the portions of x-objects between group A and B and consider it a good idea ? as seen in the example above ? to weight for the total number of objects in each subgroup. Given data that is not considered a realization of some normal distribution, thinking of a test that uses ranks still does not look like a natural solution to this problem. But I guess it is possible. Though, Xie & Priebe (2002)* are not exactly aiming at this, their paper might give an idea how weighting may look like in the special case of the Mann/Whitney/Wilcoxon statistic. (Despite the hint by John & Priebe (2007)** that this ?is not a candidate for the practitioner?s toolbox?.)

Anyway, trying to apply the Wilcoxon rank sum test to weighted data, I was first tempted to replicate each portion by its weight. (Bad idea: data bloat, ties and probably a number of problems even worse.) Function wilcox_test in package coin has got a weight argument, but

library(coin)
wilcox_test(formula = x.portion ~ group, data = data, weight = ~ weight)

leads to warning ?Rank transformation doesn?t take weights into account?. Though, results differ from

wilcox_test(formula = x.portion ~ group, data = data)

and

wilcox.test(formula = x.portion ~ group, data = data)

The code in wilcox_test() and the functions it depends on looks a little bit interlaced to me, but I guess it is not what I am after.

tl;dr: I am looking for a nonparametric alternative to wtd.t.test in package weights.

Is anyone aware of an(other) implementation in R?

Cheers,

Alex


PS: For real, it is a little bit trickier as there are more than two values and maybe even more than two groups. So Kruskal-Wallis test might be of interest, but I thought I keep it simple for the moment.

* Jingdong Xie & Carey E. Priebe: A weighted generalization of the Mann?Whitney?Wilcoxon statistic. In: Journal of Statistical Planning and Inference 102 (2), 2002-04-01, pages 441?466. (http://dx.doi.org/10.1016/S0378-3758(01)00111-2.)
** Majnu John & Carey E. Priebe: A data-adaptive methodology for finding an optimal weighted generalized Mann-Whitney-Wilcoxon statistic. In: Computational Statistics & Data Analysis 51 (9), 2007-05-15, pages 4337?4353. (http://dx.doi.org/10.1016/j.csda.2006.06.003.)


-- 
Alexander Sommer
wissenschaftlicher Mitarbeiter

Technische Universit?t Dortmund 
Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
Vogelpothsweg 78
44227 Dortmund

Telefon: +49 231 755-8189
Fax:     +49 231 755-6553
E-Mail:  Alexander.Sommer at tu-dortmund.de
WWW:     http://www.forschungsverbund.tu-dortmund.de/


From tlumley at uw.edu  Tue Aug 19 21:45:33 2014
From: tlumley at uw.edu (Thomas Lumley)
Date: Wed, 20 Aug 2014 07:45:33 +1200
Subject: [R] Weighted Mann-Whitney-Wilcoxon-Test
In-Reply-To: <000301cfbbb6$18c55020$4a4ff060$@tu-dortmund.de>
References: <000301cfbbb6$18c55020$4a4ff060$@tu-dortmund.de>
Message-ID: <CAJ55+d+hRv7Ou5DwUaFwStnf2oftPKXd4zJnyg+F9AEVvz-ymA@mail.gmail.com>

]On Wed, Aug 20, 2014 at 2:01 AM, Alexander Sommer
<Alexander.Sommer at tu-dortmund.de> wrote:

> tl;dr: I am looking for a nonparametric alternative to wtd.t.test in package weights.
>
> Is anyone aware of an(other) implementation in R?


survey::svyranktest

T. Lumley and A.J. Scott (2013). Two-sample rank tests under complex
sampling. Biometrika, 100, 831-842.


   -thomas


-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From sam_l_cruickshank at hotmail.com  Tue Aug 19 20:09:13 2014
From: sam_l_cruickshank at hotmail.com (sam cruickshank)
Date: Tue, 19 Aug 2014 19:09:13 +0100
Subject: [R] Negative values on output
In-Reply-To: <mailman.3170.1408470679.4543.r-help@r-project.org>
References: <mailman.3170.1408470679.4543.r-help@r-project.org>
Message-ID: <DUB127-W2142A0CDDDA3BFC27BAC02A6D50@phx.gbl>






Good afternoon,
I am completed a linear regression model which I personally am happy with the output and residual charts (although they are a bit bunched).  I have been using visreg() to visualise my data, and although I have logged the dependent variable (as it is cost data), on one of the graphical outputs I am getting negative fitted values for one of the Continents.  Attached is the data used, below is the code for the model and graph.  If anyone has any ideas I would hugely appreciate it, I tried a glm with log link too and this didn't help.
LM22 <- lm(logTotal ~ logArea + Continent + factor(Method1) + Popdens, data=dummy)
Output Residuals:     Min       1Q   Median       3Q      Max -1.22742 -0.31675 -0.00909  0.28885  1.20224 
Coefficients:                       Estimate Std. Error t value Pr(>|t|)    (Intercept)            -1.40972    0.77661  -1.815 0.081506 .  logArea                 0.03811    0.04041   0.943 0.354619    ContinentAsia           3.51165    0.80009   4.389 0.000182 ***ContinentAustralasia    3.48549    0.97433   3.577 0.001454 ** ContinentEurope         2.44829    0.82369   2.972 0.006452 ** ContinentGlobal         2.37910    1.00668   2.363 0.026197 *  ContinentNorth America  2.27953    0.62960   3.621 0.001303 ** ContinentSouth America  3.60997    0.77627   4.650 9.22e-05 ***factor(Method1)2        1.11259    0.38386   2.898 0.007696 ** factor(Method1)3        0.82519    0.47470   1.738 0.094459 .  factor(Method1)4       -0.06737    0.67341  -0.100 0.921104    Popdens                -0.14261    0.31675  -0.450 0.656435    ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
Residual standard error: 0.6151 on 25 degrees of freedom  (12 observations deleted due to missingness)Multiple R-squared:  0.6998,	Adjusted R-squared:  0.5677 F-statistic: 5.297 on 11 and 25 DF,  p-value: 0.0002714
visreg(LM22) gives me a graph with "Africa" being within the realm of negative "Total" which is impossible.  If you tell me how  can provide the data and graphs, but the email was kicked back with them in. 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Aug 19 22:33:55 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 19 Aug 2014 13:33:55 -0700
Subject: [R] Negative values on output
In-Reply-To: <DUB127-W2142A0CDDDA3BFC27BAC02A6D50@phx.gbl>
References: <mailman.3170.1408470679.4543.r-help@r-project.org>
	<DUB127-W2142A0CDDDA3BFC27BAC02A6D50@phx.gbl>
Message-ID: <CACk-te3sRfNUuZUOr89OusS7HBOX--Qte2pVAfKJvdVnY5T=YA@mail.gmail.com>

Please follow the posting guide and post in plain text, not HTML,  so
that helpeRs do have to try to decipher this mess.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Aug 19, 2014 at 11:09 AM, sam cruickshank
<sam_l_cruickshank at hotmail.com> wrote:
>
>
>
>
>
> Good afternoon,
> I am completed a linear regression model which I personally am happy with the output and residual charts (although they are a bit bunched).  I have been using visreg() to visualise my data, and although I have logged the dependent variable (as it is cost data), on one of the graphical outputs I am getting negative fitted values for one of the Continents.  Attached is the data used, below is the code for the model and graph.  If anyone has any ideas I would hugely appreciate it, I tried a glm with log link too and this didn't help.
> LM22 <- lm(logTotal ~ logArea + Continent + factor(Method1) + Popdens, data=dummy)
> Output Residuals:     Min       1Q   Median       3Q      Max -1.22742 -0.31675 -0.00909  0.28885  1.20224
> Coefficients:                       Estimate Std. Error t value Pr(>|t|)    (Intercept)            -1.40972    0.77661  -1.815 0.081506 .  logArea                 0.03811    0.04041   0.943 0.354619    ContinentAsia           3.51165    0.80009   4.389 0.000182 ***ContinentAustralasia    3.48549    0.97433   3.577 0.001454 ** ContinentEurope         2.44829    0.82369   2.972 0.006452 ** ContinentGlobal         2.37910    1.00668   2.363 0.026197 *  ContinentNorth America  2.27953    0.62960   3.621 0.001303 ** ContinentSouth America  3.60997    0.77627   4.650 9.22e-05 ***factor(Method1)2        1.11259    0.38386   2.898 0.007696 ** factor(Method1)3        0.82519    0.47470   1.738 0.094459 .  factor(Method1)4       -0.06737    0.67341  -0.100 0.921104    Popdens                -0.14261    0.31675  -0.450 0.656435    ---Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> Residual standard error: 0.6151 on 25 degrees of freedom  (12 observations deleted due to missingness)Multiple R-squared:  0.6998,      Adjusted R-squared:  0.5677 F-statistic: 5.297 on 11 and 25 DF,  p-value: 0.0002714
> visreg(LM22) gives me a graph with "Africa" being within the realm of negative "Total" which is impossible.  If you tell me how  can provide the data and graphs, but the email was kicked back with them in.
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sneha.bishnoi at gmail.com  Wed Aug 20 13:53:41 2014
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Wed, 20 Aug 2014 07:53:41 -0400
Subject: [R] DateTime wrong when exporting to csv in R
Message-ID: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>

Hi All!

This seems to be trival but I am not able to find a solution for it.
I have a dataframe with datetime columns in form of  ("%d/%m/%y %H:%M:%OS").

I write it to csv file. Whne i open the csv file the date time format are
in some number form .
So even if I use custome settings from excel to change it into date time
format, it gives me wrong value.

My data frame is as below:

 PostDate                            Status                 ArrTime
               NumGuests
 2014-08-14 16:13:08.850       O                    2012-01-13 00:00:00.000
     6
 2014-08-14 16:13:08.850       A


-SB

	[[alternative HTML version deleted]]


From sneha.bishnoi at gmail.com  Wed Aug 20 14:13:36 2014
From: sneha.bishnoi at gmail.com (Sneha Bishnoi)
Date: Wed, 20 Aug 2014 08:13:36 -0400
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <CABnEqmcf_ho3ZUx5YXNC_fCKCPwCOpbGEH_TuABLixP5YSqaZg@mail.gmail.com>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
	<CABnEqmcf_ho3ZUx5YXNC_fCKCPwCOpbGEH_TuABLixP5YSqaZg@mail.gmail.com>
Message-ID: <CAOsJHwAFThJy3mbpP-=DW4_c6KpdZBvd66abE1euSjXfTdnc4A@mail.gmail.com>

Tried that..does not help :(



On Wed, Aug 20, 2014 at 8:03 AM, Saurabh Agrawal <sagrawal at idrcglobal.com>
wrote:

> Maybe converting POSIXct to character string using "format" before writing
> to csv will help.
>
>
>
> On 20 August 2014 17:23, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:
>
>> Hi All!
>>
>> This seems to be trival but I am not able to find a solution for it.
>> I have a dataframe with datetime columns in form of  ("%d/%m/%y
>> %H:%M:%OS").
>>
>> I write it to csv file. Whne i open the csv file the date time format are
>> in some number form .
>> So even if I use custome settings from excel to change it into date time
>> format, it gives me wrong value.
>>
>> My data frame is as below:
>>
>>  PostDate                            Status                 ArrTime
>>                NumGuests
>>  2014-08-14 16:13:08.850       O                    2012-01-13
>> 00:00:00.000
>>      6
>>  2014-08-14 16:13:08.850       A
>>
>>
>> -SB
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Sneha Bishnoi
+14047235469
H. Milton Stewart School of Industrial &  Systems Engineering
Georgia Tech

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Aug 20 14:55:49 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 20 Aug 2014 05:55:49 -0700
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
Message-ID: <373ac6ad-6f1d-4f2a-ac92-2dd145b9872c@email.android.com>

This problem is in Excel or your use thereof, not in R, and is therefore not technically "on topic" here.

FWIW I am aware that localization of Excel can change the default date formats for input. I suspect that your installation of Excel has a different default date format than you are using in R (like MDY) that is attempting to convert the file before you start messing with formats. This would incorrectly interpret some cells and fail entirely for others (leaving those cells as strings). My suggestion is to have R output MDY rather than DMY. If that is not satisfactory then you probably ought to ask for help in an Excel forum.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 20, 2014 4:53:41 AM PDT, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:
>Hi All!
>
>This seems to be trival but I am not able to find a solution for it.
>I have a dataframe with datetime columns in form of  ("%d/%m/%y
>%H:%M:%OS").
>
>I write it to csv file. Whne i open the csv file the date time format
>are
>in some number form .
>So even if I use custome settings from excel to change it into date
>time
>format, it gives me wrong value.
>
>My data frame is as below:
>
> PostDate                            Status                 ArrTime
>               NumGuests
>2014-08-14 16:13:08.850       O                    2012-01-13
>00:00:00.000
>     6
> 2014-08-14 16:13:08.850       A
>
>
>-SB
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Wed Aug 20 14:58:04 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 20 Aug 2014 13:58:04 +0100
Subject: [R] loading saved files with objects in same names
In-Reply-To: <86077b1e665c4dc283a17c7e6098c766@EX-0-HT0.lancs.local>
References: <86077b1e665c4dc283a17c7e6098c766@EX-0-HT0.lancs.local>
Message-ID: <CANVKczMem0BchZ66zN8FeUtN7-e_qiKPX785QjH9jo6Y=nWtww@mail.gmail.com>

On Tue, Aug 19, 2014 at 1:30 AM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
> each file, there are some objects with same names but different
> contents. Now, I need to compare those objects through plotting.
> However, I can't find a way to load them into a workspace. The only
> thing I can do is to rename them and then save and load again.
>
> Is there a convenient to load those objects?
>
> Thanks a lot in advance.

The technique of loading into an environment already mentioned can be
cleaned up and put into a function.

First lets save a thing called "x" into two files with different values:

 > x="first"
 > save(x,file="f.RData")
 > x="second"
 > save(x,file="s.RData")

This little function wraps the loading:

 > getFrom=function(file, name){e=new.env();load(file,env=e);e[[name]]}

So now I can get 'x' from the first file - the value is returned from
`getFrom` so I can assign it to anything:

 > x1 =  getFrom("f.RData","x")
 > x1
[1] "first"
 > x2 = getFrom("s.RData","x")
 > x2
[1] "second"

And I can even loop over RData files and read in all the `x`s into a vector:

 > sapply(c("f.RData","s.RData"),function(f){getFrom(f,"x")})
  f.RData  s.RData
  "first" "second"

(on second thoughts, possibly 'loadFrom' is a better name)

Barry


From murdoch.duncan at gmail.com  Wed Aug 20 15:12:04 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 20 Aug 2014 09:12:04 -0400
Subject: [R] loading saved files with objects in same names
In-Reply-To: <CANVKczMem0BchZ66zN8FeUtN7-e_qiKPX785QjH9jo6Y=nWtww@mail.gmail.com>
References: <86077b1e665c4dc283a17c7e6098c766@EX-0-HT0.lancs.local>
	<CANVKczMem0BchZ66zN8FeUtN7-e_qiKPX785QjH9jo6Y=nWtww@mail.gmail.com>
Message-ID: <53F49EA4.9060607@gmail.com>

On 20/08/2014, 8:58 AM, Barry Rowlingson wrote:
> On Tue, Aug 19, 2014 at 1:30 AM, Jinsong Zhao <jszhao at yeah.net> wrote:
>> Hi there,
>>
>> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
>> each file, there are some objects with same names but different
>> contents. Now, I need to compare those objects through plotting.
>> However, I can't find a way to load them into a workspace. The only
>> thing I can do is to rename them and then save and load again.
>>
>> Is there a convenient to load those objects?
>>
>> Thanks a lot in advance.
> 
> The technique of loading into an environment already mentioned can be
> cleaned up and put into a function.
> 
> First lets save a thing called "x" into two files with different values:
> 
>  > x="first"
>  > save(x,file="f.RData"))
>  > x="second"
>  > save(x,file="s.RData")
> 
> This little function wraps the loading:
> 
>  > getFrom=function(file, name){e=new.env();load(file,env=e);e[[name]]}
> 
> So now I can get 'x' from the first file - the value is returned from
> `getFrom` so I can assign it to anything:
> 
>  > x1 =  getFrom("f.RData","x")
>  > x1
> [1] "first"
>  > x2 = getFrom("s.RData","x")
>  > x2
> [1] "second"
> 
> And I can even loop over RData files and read in all the `x`s into a vector:
> 
>  > sapply(c("f.RData","s.RData"),function(f){getFrom(f,"x")})
>   f.RData  s.RData
>   "first" "second"
> 
> (on second thoughts, possibly 'loadFrom' is a better name)

That's a nice little function.  You could also have lsFrom, that lists
the objects stored in the file, along the same lines:

lsFrom <- function(file, all.names = FALSE, pattern) {
  e <- new.env()
  load(file, envir = e)
  ls(e, all.names = all.names, pattern = pattern)
}

Duncan Murdoch


From dulcalma at bigpond.com  Wed Aug 20 15:44:21 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 20 Aug 2014 23:44:21 +1000
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <CAOsJHwAFThJy3mbpP-=DW4_c6KpdZBvd66abE1euSjXfTdnc4A@mail.gmail.com>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>	<CABnEqmcf_ho3ZUx5YXNC_fCKCPwCOpbGEH_TuABLixP5YSqaZg@mail.gmail.com>
	<CAOsJHwAFThJy3mbpP-=DW4_c6KpdZBvd66abE1euSjXfTdnc4A@mail.gmail.com>
Message-ID: <000601cfbc7c$d8c5ec10$8a51c430$@bigpond.com>

Hi

If you really need to have minutes and seconds etc in excel then use a
package that can write datetime columns that excel can read eg. access
rather that csv.
Microsoft is well known for changing dates and date formats - remember excel
is a worksheet application not a database - caveat emptor.

If you use a formatted date that excel can recognize then excel has less of
a tendency to change it.

Datetime is a pain in any language because of the irregularity of time.
Beware MS does not get it right if you are using dates from ca 1890 to 1910

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Sneha Bishnoi
Sent: Wednesday, 20 August 2014 22:14
To: Saurabh Agrawal
Cc: r-help
Subject: Re: [R] DateTime wrong when exporting to csv in R

Tried that..does not help :(



On Wed, Aug 20, 2014 at 8:03 AM, Saurabh Agrawal <sagrawal at idrcglobal.com>
wrote:

> Maybe converting POSIXct to character string using "format" before writing
> to csv will help.
>
>
>
> On 20 August 2014 17:23, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:
>
>> Hi All!
>>
>> This seems to be trival but I am not able to find a solution for it.
>> I have a dataframe with datetime columns in form of  ("%d/%m/%y
>> %H:%M:%OS").
>>
>> I write it to csv file. Whne i open the csv file the date time format are
>> in some number form .
>> So even if I use custome settings from excel to change it into date time
>> format, it gives me wrong value.
>>
>> My data frame is as below:
>>
>>  PostDate                            Status                 ArrTime
>>                NumGuests
>>  2014-08-14 16:13:08.850       O                    2012-01-13
>> 00:00:00.000
>>      6
>>  2014-08-14 16:13:08.850       A
>>
>>
>> -SB
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Sneha Bishnoi
+14047235469
H. Milton Stewart School of Industrial &  Systems Engineering
Georgia Tech

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Wed Aug 20 17:15:06 2014
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 20 Aug 2014 07:15:06 -0800
Subject: [R] Negative values on output
In-Reply-To: <DUB127-W2142A0CDDDA3BFC27BAC02A6D50@phx.gbl>
References: <mailman.3170.1408470679.4543.r-help@r-project.org>
Message-ID: <A5D9A6F66F1.0000073Cjrkrideau@inbox.com>

It appears you posted in HTML and what we get is an almost useles set of data.  It is much better to supply it using dput() (and always post to the list in plain text not HTML.

See https://github.com/hadley/devtools/wiki/Reproducibility of http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for some helpful hints on how to post to the R-Help list/


John Kane
Kingston ON Canada


> -----Original Message-----
> From: sam_l_cruickshank at hotmail.com
> Sent: Tue, 19 Aug 2014 19:09:13 +0100
> To: r-help at r-project.org
> Subject: [R] Negative values on output
> 
> 
> 
> 
> 
> 
> Good afternoon,
> I am completed a linear regression model which I personally am happy with
> the output and residual charts (although they are a bit bunched).  I have
> been using visreg() to visualise my data, and although I have logged the
> dependent variable (as it is cost data), on one of the graphical outputs
> I am getting negative fitted values for one of the Continents.  Attached
> is the data used, below is the code for the model and graph.  If anyone
> has any ideas I would hugely appreciate it, I tried a glm with log link
> too and this didn't help.
> LM22 <- lm(logTotal ~ logArea + Continent + factor(Method1) + Popdens,
> data=dummy)
> Output Residuals:     Min       1Q   Median       3Q      Max -1.22742
> -0.31675 -0.00909  0.28885  1.20224
> Coefficients:                       Estimate Std. Error t value Pr(>|t|)
> (Intercept)            -1.40972    0.77661  -1.815 0.081506 .  logArea
> 0.03811    0.04041   0.943 0.354619    ContinentAsia           3.51165
> 0.80009   4.389 0.000182 ***ContinentAustralasia    3.48549    0.97433
> 3.577 0.001454 ** ContinentEurope         2.44829    0.82369   2.972
> 0.006452 ** ContinentGlobal         2.37910    1.00668   2.363 0.026197 *
> ContinentNorth America  2.27953    0.62960   3.621 0.001303 **
> ContinentSouth America  3.60997    0.77627   4.650 9.22e-05
> ***factor(Method1)2        1.11259    0.38386   2.898 0.007696 **
> factor(Method1)3        0.82519    0.47470   1.738 0.094459 .
> factor(Method1)4       -0.06737    0.67341  -0.100 0.921104    Popdens
> -0.14261    0.31675  -0.450 0.656435    ---Signif. codes:  0 *** 0.001 **
> 0.01 * 0.05 . 0.1   1
> Residual standard error: 0.6151 on 25 degrees of freedom  (12
> observations deleted due to missingness)Multiple R-squared:  0.6998,
> Adjusted R-squared:  0.5677 F-statistic: 5.297 on 11 and 25 DF,  p-value:
> 0.0002714
> visreg(LM22) gives me a graph with "Africa" being within the realm of
> negative "Total" which is impossible.  If you tell me how  can provide
> the data and graphs, but the email was kicked back with them in.
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From peter.langfelder at gmail.com  Wed Aug 20 20:56:09 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 20 Aug 2014 11:56:09 -0700
Subject: [R] as.Date woes
Message-ID: <CA+hbrhW-UUfk9Rb_Fb3Kz=oESamgWQKbNf2iJ28s88UyDCcO-Q@mail.gmail.com>

Hi all,

I have recently started working with Date objects and find the
experience unsettling, to put it mildly.

The help for as.Date says, in part:

     ## S3 method for class 'character'
     as.Date(x, format = "", ...)

       x: An object to be converted.

  format: A character string.  If not specified, it will try
          ?"%Y-%m-%d"? then ?"%Y/%m/%d"? on the first non-?NA? element,
          and give an error if neither works.


If I read this correctly,

as.Date("2012-04-30") and
as.Date("2012-04-30", format = "")

should give the same results, but they don't:

> as.Date("2012-04-30")
[1] "2012-04-30"
> as.Date("2012-04-30", format = "")
[1] "2014-08-20"

Note the latter gives today's date, without any warning or message.

What method is called in the latter case?

Another issue I am running into, that is probably connected to the
'format' argument above, is trying to convert a numeric or character
in the same call. Basically, I would like to call

as.Date(object, format = "", origin = "1970-1-1")

where object can be a Date, numeric or character, in the hope that the
appropriate method will be selected and will ignore unnecessary
arguments.

Here's what I get:

> as.Date( as.numeric(Sys.Date()), origin = "1970-1-1")
[1] "2014-08-20"   #### Correct
> as.Date( as.numeric(Sys.Date()), origin = "1970-1-1", format = "")
[1] "2059-04-08"   #### ???

Excuse the coarse language, but WTF??? The first call confirms that
the origin is specified correctly, and the second gives a date removed
from the origin by twice the number of days than the actual input??

> as.numeric(Sys.Date())
[1] 16302
> as.numeric(as.Date( as.numeric(Sys.Date()), origin = "1970-1-1"))
[1] 16302
> as.numeric(as.Date( as.numeric(Sys.Date()), origin = "1970-1-1", format = ""))
[1] 32604


Thanks in advance for any pointers!

Peter

PS: I know my R is not the most up to date, but I haven't found
anything about Date mentioned in the changelog for the 3.x series.


> sessionInfo()
R version 3.0.2 Patched (2013-10-08 r64039)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
 [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
 [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
 [7] LC_PAPER=en_US.utf8       LC_NAME=C
 [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


From peter.langfelder at gmail.com  Wed Aug 20 21:27:57 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 20 Aug 2014 12:27:57 -0700
Subject: [R] as.Date woes
In-Reply-To: <CA+hbrhW-UUfk9Rb_Fb3Kz=oESamgWQKbNf2iJ28s88UyDCcO-Q@mail.gmail.com>
References: <CA+hbrhW-UUfk9Rb_Fb3Kz=oESamgWQKbNf2iJ28s88UyDCcO-Q@mail.gmail.com>
Message-ID: <CA+hbrhVuP_6qrrcgQbe0Hg3GMgz9+eiso96QmX+di5CvtYpHMQ@mail.gmail.com>

Never mind... the solution was to read the source code of
as.Date.character. It turns out the default format="" is meaningless.
If 'format' is not given in the call to as.Date, it is NOT assumed to
be "", and the function gives very different results from a call where
the argument format="" is given. Grrrr...

Peter

On Wed, Aug 20, 2014 at 11:56 AM, Peter Langfelder
<peter.langfelder at gmail.com> wrote:
> Hi all,
>
> I have recently started working with Date objects and find the
> experience unsettling, to put it mildly.
>
> The help for as.Date says, in part:
>
>      ## S3 method for class 'character'
>      as.Date(x, format = "", ...)
>
>        x: An object to be converted.
>
>   format: A character string.  If not specified, it will try
>           ?"%Y-%m-%d"? then ?"%Y/%m/%d"? on the first non-?NA? element,
>           and give an error if neither works.
>
>
> If I read this correctly,
>
> as.Date("2012-04-30") and
> as.Date("2012-04-30", format = "")
>
> should give the same results, but they don't:
>
>> as.Date("2012-04-30")
> [1] "2012-04-30"
>> as.Date("2012-04-30", format = "")
> [1] "2014-08-20"
>
> Note the latter gives today's date, without any warning or message.
>
> What method is called in the latter case?
>
> Another issue I am running into, that is probably connected to the
> 'format' argument above, is trying to convert a numeric or character
> in the same call. Basically, I would like to call
>
> as.Date(object, format = "", origin = "1970-1-1")
>
> where object can be a Date, numeric or character, in the hope that the
> appropriate method will be selected and will ignore unnecessary
> arguments.
>
> Here's what I get:
>
>> as.Date( as.numeric(Sys.Date()), origin = "1970-1-1")
> [1] "2014-08-20"   #### Correct
>> as.Date( as.numeric(Sys.Date()), origin = "1970-1-1", format = "")
> [1] "2059-04-08"   #### ???
>
> Excuse the coarse language, but WTF??? The first call confirms that
> the origin is specified correctly, and the second gives a date removed
> from the origin by twice the number of days than the actual input??
>
>> as.numeric(Sys.Date())
> [1] 16302
>> as.numeric(as.Date( as.numeric(Sys.Date()), origin = "1970-1-1"))
> [1] 16302
>> as.numeric(as.Date( as.numeric(Sys.Date()), origin = "1970-1-1", format = ""))
> [1] 32604
>
>
> Thanks in advance for any pointers!
>
> Peter
>
> PS: I know my R is not the most up to date, but I haven't found
> anything about Date mentioned in the changelog for the 3.x series.
>
>
>> sessionInfo()
> R version 3.0.2 Patched (2013-10-08 r64039)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>  [7] LC_PAPER=en_US.utf8       LC_NAME=C
>  [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base


From sagrawal at idrcglobal.com  Wed Aug 20 14:03:30 2014
From: sagrawal at idrcglobal.com (Saurabh Agrawal)
Date: Wed, 20 Aug 2014 17:33:30 +0530
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
Message-ID: <CABnEqmcf_ho3ZUx5YXNC_fCKCPwCOpbGEH_TuABLixP5YSqaZg@mail.gmail.com>

Maybe converting POSIXct to character string using "format" before writing
to csv will help.



On 20 August 2014 17:23, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:

> Hi All!
>
> This seems to be trival but I am not able to find a solution for it.
> I have a dataframe with datetime columns in form of  ("%d/%m/%y
> %H:%M:%OS").
>
> I write it to csv file. Whne i open the csv file the date time format are
> in some number form .
> So even if I use custome settings from excel to change it into date time
> format, it gives me wrong value.
>
> My data frame is as below:
>
>  PostDate                            Status                 ArrTime
>                NumGuests
>  2014-08-14 16:13:08.850       O                    2012-01-13 00:00:00.000
>      6
>  2014-08-14 16:13:08.850       A
>
>
> -SB
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sagrawal at idrcglobal.com  Wed Aug 20 14:20:36 2014
From: sagrawal at idrcglobal.com (Saurabh Agrawal)
Date: Wed, 20 Aug 2014 17:50:36 +0530
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <CAOsJHwAFThJy3mbpP-=DW4_c6KpdZBvd66abE1euSjXfTdnc4A@mail.gmail.com>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
	<CABnEqmcf_ho3ZUx5YXNC_fCKCPwCOpbGEH_TuABLixP5YSqaZg@mail.gmail.com>
	<CAOsJHwAFThJy3mbpP-=DW4_c6KpdZBvd66abE1euSjXfTdnc4A@mail.gmail.com>
Message-ID: <CABnEqmf3vZasa3eKo8Nq7LwxaKuDm=8EsTfRHHMYBfBXP8fSPg@mail.gmail.com>

Could you please post your code and some sample data?

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example



On 20 August 2014 17:43, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:

> Tried that..does not help :(
>
>
>
> On Wed, Aug 20, 2014 at 8:03 AM, Saurabh Agrawal <sagrawal at idrcglobal.com>
> wrote:
>
>> Maybe converting POSIXct to character string using "format" before
>> writing to csv will help.
>>
>>
>>
>> On 20 August 2014 17:23, Sneha Bishnoi <sneha.bishnoi at gmail.com> wrote:
>>
>>> Hi All!
>>>
>>> This seems to be trival but I am not able to find a solution for it.
>>> I have a dataframe with datetime columns in form of  ("%d/%m/%y
>>> %H:%M:%OS").
>>>
>>> I write it to csv file. Whne i open the csv file the date time format are
>>> in some number form .
>>> So even if I use custome settings from excel to change it into date time
>>> format, it gives me wrong value.
>>>
>>> My data frame is as below:
>>>
>>>  PostDate                            Status                 ArrTime
>>>                NumGuests
>>>  2014-08-14 16:13:08.850       O                    2012-01-13
>>> 00:00:00.000
>>>      6
>>>  2014-08-14 16:13:08.850       A
>>>
>>>
>>> -SB
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
> Sneha Bishnoi
> +14047235469
> H. Milton Stewart School of Industrial &  Systems Engineering
> Georgia Tech
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Aug 20 22:48:14 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Aug 2014 13:48:14 -0700
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
Message-ID: <469D03FE-E515-4092-86EA-C9DCAAF9BC1B@comcast.net>


On Aug 20, 2014, at 4:53 AM, Sneha Bishnoi wrote:

> Hi All!
> 
> This seems to be trival but I am not able to find a solution for it.
> I have a dataframe with datetime columns in form of  ("%d/%m/%y %H:%M:%OS").
> 
> I write it to csv file. Whne i open the csv file the date time format are
> in some number form .

What does "same number form" mean?

> So even if I use custome settings from excel to change it into date time
> format, it gives me wrong value.
> 
> My data frame is as below:
> 

PostDate                            Status                 ArrTime              NumGuests
2014-08-14 16:13:08.850       O                    2012-01-13 00:00:00.000    6
2014-08-14 16:13:08.850       A

> 
> -SB
> 
> 	[[alternative HTML version deleted]]

The reason you are asked to post in plain text is to avoid the line wrapping and other mangling of data that html formatting causes. I've reformatted your posting to be what appears to be a very incomplete representation of your file.

I substituted tabs for the varying number of space
-- opened and empty excel workbook
-- formatted the first and third columns with a custom format for a date-time in the POSIX standard format (or a close as I can get to that in Excel, anyway)  as illustrated in the attached .png file.



-- open the tab-separated file.

Dates and times all agree.




> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From patzelt at g.harvard.edu  Wed Aug 20 22:12:58 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Wed, 20 Aug 2014 16:12:58 -0400
Subject: [R] Euclidean Distance in 3 Dimensions
Message-ID: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>

R Community -

I am attempting to write a function that will calculate the distance
between points in 3 dimensional space for unique regions (e.g. localized
brain regions such as the frontal lobe).

For example I'm looking to compare each point in region 45 to every other
region in 45 to establish if they are a distance of 8 or more apart. I can
do this linearly comparing each distance to the previous but this is not
comparing all points.

structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
)), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
c(NA,
20L), class = "data.frame")

mainDat <- data.frame()
for(i in 2:nrow(dat)){
tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
(dat$z[i] - dat$z[i-1])^2))
dat$X[i] <- c(tempDist)
if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
mainDat <- rbind(mainDat, dat[i,])
}
if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
if(tempDist > 8){
mainDat <- rbind(mainDat, dat[i,])
}
}
}




-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University *

	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Wed Aug 20 22:57:49 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 20 Aug 2014 13:57:49 -0700
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
Message-ID: <E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>

?dist

from the help

dist {stats}	R Documentation
Distance Matrix Computation

Description

This function computes and returns the distance matrix computed by using the specified distance measure to compute the distances between the rows of a data matrix.

Is this what you want?  Computing on a matrix whose rows are your x, y, and z values?


On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:

> R Community -
> 
> I am attempting to write a function that will calculate the distance
> between points in 3 dimensional space for unique regions (e.g. localized
> brain regions such as the frontal lobe).
> 
> For example I'm looking to compare each point in region 45 to every other
> region in 45 to establish if they are a distance of 8 or more apart. I can
> do this linearly comparing each distance to the previous but this is not
> comparing all points.
> 
> structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
> 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
> 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
> 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
> 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
> 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
> 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
> 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
> 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
> 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
> 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
> 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
> 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
> 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
> )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
> c(NA,
> 20L), class = "data.frame")
> 
> mainDat <- data.frame()
> for(i in 2:nrow(dat)){
> tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
> (dat$z[i] - dat$z[i-1])^2))
> dat$X[i] <- c(tempDist)
> if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
> mainDat <- rbind(mainDat, dat[i,])
> }
> if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
> if(tempDist > 8){
> mainDat <- rbind(mainDat, dat[i,])
> }
> }
> }
> 
> 
> 
> 
> -- 
> 
> *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> University *
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From f.calboli at imperial.ac.uk  Wed Aug 20 23:01:30 2014
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Wed, 20 Aug 2014 22:01:30 +0100
Subject: [R] ordinary kriging: the edges of the polygons are ignored
Message-ID: <7EAF9447-D09E-488D-8284-102C7DC9B754@imperial.ac.uk>

Hi All,

I am trying to do some kriging of a floor, based on a number of heat sensors.

My data looks like this:

   sensor        temp    x    y
1       1  1.25437406  390 2960
2       2  0.64384594  830 2960
3       3  1.52067733 1420 2960
4       4  1.21441928 3127 2920
5       5  1.04227694 4005 2920
6       6  1.90084852  400 1960
7       7  1.58530250  835 1880
8       8  1.23060971 1130 1960
9       9  0.92749453 1550 1950
10     10  0.76638878 1995 1960
11     11  0.84247092 2540 1950
12     12  0.93999929 3300 1880
13     13  0.61610170 4000 1870
14     14  1.06967332  395 1330
15     15  0.72970917  845 1330
16     16  0.60216970 1135 1300
17     17  0.44648551 1570 1275
18     18  2.49863724 2010 1290
19     19  0.71619206 2540 1320
20     20  1.50984666 3140 1275
21     21 -0.06540552 4000 1258
22     22  1.20017747  400  685
23     23  1.05820693 1575  640
24     24  2.25086655 1830  625
25     25  0.69296059 3120  625
26     26  0.69324786 3990  605

and the floor plan describes the edges of the floor thus:

      x    y
1   210 3200
2   210  420
3  1510  420
4  1510  100
5  4090  100
6  4090 3200
7  2947 3200
8  2947 2850
9  1647 2850
10 1647 3200
11  210 3200
12  210 3200

I run these commands:

house2 <- list(data.frame(house$x, house$y))
plot(house.y ~house.x, type = 'l', house2[[1]])
points(U[,3], U[,4], pch = 20)
housekrig=kriging(U[,3],U[,4],U[,2],polygons=house2,lags = 5) 
image(housekrig, xlim = extendrange(U[,3]), ylim = extendrange(U[,4]), col = rev(heat.colors(100)))

and I noticed that the kriging area does not respect the floor plan.  In fact, if I do:

points(U[,3], U[,4], pch = 20)

the sensors and not in the same place, and the kriging has ignored the edges of the polygons altogether.

So my question is, how do I have a kriging of the *whole* surface, based on my sensors?  Any suggestion is welcome, especially if the data does not require reformatting (or if the reformatting is straightforward)!

Best

F

PS I have contacted the maintainer of the package about the issue but I had no reply, and I?d need to solve this one way or another sooner, rather than later.


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140820/e0d9c100/attachment.bin>

From dwinsemius at comcast.net  Thu Aug 21 00:08:47 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Aug 2014 15:08:47 -0700
Subject: [R] Fwd:  DateTime wrong when exporting to csv in R
References: <469D03FE-E515-4092-86EA-C9DCAAF9BC1B@comcast.net>
Message-ID: <6BB20CFB-6FC3-4006-A04C-7A34A128C405@comcast.net>

The image file I prepared and attached did not make it through. Trying again.

-- 
David

Begin forwarded message:

> From: David Winsemius <dwinsemius at comcast.net>
> Subject: Re: [R] DateTime wrong when exporting to csv in R
> Date: August 20, 2014 1:48:14 PM PDT
> To: Sneha Bishnoi <sneha.bishnoi at gmail.com>
> Cc: r-help <R-help at r-project.org>
> 
> 
> On Aug 20, 2014, at 4:53 AM, Sneha Bishnoi wrote:
> 
>> Hi All!
>> 
>> This seems to be trival but I am not able to find a solution for it.
>> I have a dataframe with datetime columns in form of  ("%d/%m/%y %H:%M:%OS").
>> 
>> I write it to csv file. Whne i open the csv file the date time format are
>> in some number form .
> 
> What does "same number form" mean?
> 
>> So even if I use custome settings from excel to change it into date time
>> format, it gives me wrong value.
>> 
>> My data frame is as below:
>> 
> 
> PostDate                            Status                 ArrTime              NumGuests
> 2014-08-14 16:13:08.850       O                    2012-01-13 00:00:00.000    6
> 2014-08-14 16:13:08.850       A
> 
>> 
>> -SB
>> 
>> 	[[alternative HTML version deleted]]
> 
> The reason you are asked to post in plain text is to avoid the line wrapping and other mangling of data that html formatting causes. I've reformatted your posting to be what appears to be a very incomplete representation of your file.
> 
> I substituted tabs for the varying number of space
> -- opened and empty excel workbook
> -- formatted the first and third columns with a custom format for a date-time in the POSIX standard format (or a close as I can get to that in Excel, anyway)  as illustrated in the attached .png file.
> 
> 
> 
> -- open the tab-separated file.
> 
> Dates and times all agree.
> 
> 
> 
> 
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Aug 21 00:32:57 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 20 Aug 2014 15:32:57 -0700
Subject: [R] DateTime wrong when exporting to csv in R
In-Reply-To: <469D03FE-E515-4092-86EA-C9DCAAF9BC1B@comcast.net>
References: <CAOsJHwCa+Rq5R5or5PTfsE8TxdA2Pa3UBUc_6Ye48Ofny5NTrw@mail.gmail.com>
	<469D03FE-E515-4092-86EA-C9DCAAF9BC1B@comcast.net>
Message-ID: <9CA8A063-FAD3-4985-BDD4-0E94FA67153C@comcast.net>


On Aug 20, 2014, at 1:48 PM, David Winsemius wrote:

> 
> On Aug 20, 2014, at 4:53 AM, Sneha Bishnoi wrote:
> 
>> Hi All!
>> 
>> This seems to be trival but I am not able to find a solution for it.
>> I have a dataframe with datetime columns in form of  ("%d/%m/%y %H:%M:%OS").
>> 
>> I write it to csv file. Whne i open the csv file the date time format are
>> in some number form .
> 
> What does "same number form" mean?
> 
>> So even if I use custome settings from excel to change it into date time
>> format, it gives me wrong value.
>> 
>> My data frame is as below:
>> 
> 
> PostDate                            Status                 ArrTime              NumGuests
> 2014-08-14 16:13:08.850       O                    2012-01-13 00:00:00.000    6
> 2014-08-14 16:13:08.850       A
> 
>> 
>> -SB
>> 
>> 	[[alternative HTML version deleted]]
> 
> The reason you are asked to post in plain text is to avoid the line wrapping and other mangling of data that html formatting causes. I've reformatted your posting to be what appears to be a very incomplete representation of your file.
> 
> I substituted tabs for the varying number of space
> -- opened and empty excel workbook
> -- formatted the first and third columns with a custom format for a date-time in the POSIX standard format (or a close as I can get to that in Excel, anyway)  as illustrated in the attached .png file.

The server seems to be rejecting PNG files (although they were accpted earlier). So trying with a PDF version of the PNG file:

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Excel_dat_fmt.pdf
Type: application/pdf
Size: 81483 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140820/1c97b9ed/attachment.pdf>
-------------- next part --------------


-- 
David.
> 
> -- open the tab-separated file.
> 
> Dates and times all agree.
> 
> 
> 
> 
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From williamdeese at gmail.com  Thu Aug 21 00:43:44 2014
From: williamdeese at gmail.com (William Deese)
Date: Wed, 20 Aug 2014 18:43:44 -0400
Subject: [R] Installing RODBC
Message-ID: <CAFg4Ao83p5Gh8HNb3h0bsZb9kTjsnts+1ErJ2J7khLBD9-RfUA@mail.gmail.com>

I tried installing RODBC but got the following message:

Checks were yes until the following

checking sql.h usability... no
checking sql.h presence... no
checking for sql.h... no
checking sqlext.h usability... no
checking sqlext.h presence... no
checking for sqlext.h... no
configure: error: "ODBC headers sql.h and sqlext.h not found"
ERROR: configuration failed for package ?RODBC?
* removing ?/home/bill/R/x86_64-pc-linux-gnu-library/3.1/RODBC?

Apparently RODBC was there when R was installed, but library() shows
it is not there now, although the DBI package is. Best ideas for
installing RODBC?

Bill


From marc_schwartz at me.com  Thu Aug 21 01:03:52 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 20 Aug 2014 18:03:52 -0500
Subject: [R] Installing RODBC
In-Reply-To: <CAFg4Ao83p5Gh8HNb3h0bsZb9kTjsnts+1ErJ2J7khLBD9-RfUA@mail.gmail.com>
References: <CAFg4Ao83p5Gh8HNb3h0bsZb9kTjsnts+1ErJ2J7khLBD9-RfUA@mail.gmail.com>
Message-ID: <DD6D71C2-9F3E-4795-B752-D3EBC9F7E6D6@me.com>

On Aug 20, 2014, at 5:43 PM, William Deese <williamdeese at gmail.com> wrote:

> I tried installing RODBC but got the following message:
> 
> Checks were yes until the following
> 
> checking sql.h usability... no
> checking sql.h presence... no
> checking for sql.h... no
> checking sqlext.h usability... no
> checking sqlext.h presence... no
> checking for sqlext.h... no
> configure: error: "ODBC headers sql.h and sqlext.h not found"
> ERROR: configuration failed for package ?RODBC?
> * removing ?/home/bill/R/x86_64-pc-linux-gnu-library/3.1/RODBC?
> 
> Apparently RODBC was there when R was installed, but library() shows
> it is not there now, although the DBI package is. Best ideas for
> installing RODBC?
> 
> Bill


You are missing the indicated header files, which are required if you are building the package from source.

As per the extensive vignette that Prof. Ripley has provided:

  http://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf

in Appendix A, which describes Installation, you will find:

"For other systems the driver manager of choice is likely to be unixODBC, part of almost all Linux distributions and with sources downloadable from http://www.unixODBC.org. In Linux binary distributions it is likely that package unixODBC-devel or unixodbc-dev or some such will be needed."

Thus, for whatever Linux distribution you are using, install the relevant RPMs or Debs or ...

Also, for future reference, there is a specific mailing list for DB related queries:

  https://stat.ethz.ch/mailman/listinfo/r-sig-db

and a search of the list archives, for example using rseek.org, would likely result in your finding queries and answers to this same issue over the years.

Regards,

Marc Schwartz


From waseq_ziaie007 at hotmail.com  Thu Aug 21 00:54:55 2014
From: waseq_ziaie007 at hotmail.com (Waseq Ziaie)
Date: Wed, 20 Aug 2014 23:54:55 +0100
Subject: [R]  Line Graph greater than 2 variables on plot
Message-ID: <BLU436-SMTP9311262968F8674FD81270A8D20@phx.gbl>

Hi all,

I was wondering if anyone knew how to construct a multiple line graph on R, where there  are 2 (or more) sets of data points plotted against some x axis of
data, and you can draw a line on the graph connecting each set of data points.
for example:
  time..years. 		incidence	 rural	 urban
1         2004     	295.4 		19.01 	 9.50
2         2005     	824.1 		19.95 	 9.98
3         2006    	1078.0		 20.70 	10.35
4         2007    	1258.0  		 21.26 	10.63
5         2008    	1800.0 		 21.83	 10.91
6         2009   		 1890.0		 18.93 	  9.47
7         2010   		 1999.0 		  19.41	  9.71
8         2011 		   2261.0 	 19.89 	  9.95
9         2012    	   2321.0		   20.28 	  10.14

Idea:
a) I am planning plot a graph of data illustrated above where on Y-axis we can have data in sets INCIDENCE, RURAL and URBAN and on X-axis the points in set TIME..YEARS.
b) Would like to be able to draw three lines ,connecting the points for each set of INCIDENCE, RURAL and URBAN over TIME..YEARS.

I have tried really hard to find something but wasn't successful, the latest information I received after doing the command shown underneath was:

> plot(data1$time..years.,data1$incidence,main="Plot illustrating diarrhoeal incidence over time", xlab="Time(years)",ylab="Diarrhoeal incidence",ylim=range(data[c("incidence","rural","urban")]),type"l", col=2)
Error: unexpected string constant in "plot(data1$time..years.,data1$incidence,main="Plot illustrating diarrhoeal incidence over time", xlab="Time(years)",ylab="Diarrhoeal incidence",ylim=range(data[c("incidence","rural","urban")])"

Many thanks,
W
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Aug 21 01:19:52 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 20 Aug 2014 16:19:52 -0700
Subject: [R] Installing RODBC
In-Reply-To: <CAFg4Ao83p5Gh8HNb3h0bsZb9kTjsnts+1ErJ2J7khLBD9-RfUA@mail.gmail.com>
References: <CAFg4Ao83p5Gh8HNb3h0bsZb9kTjsnts+1ErJ2J7khLBD9-RfUA@mail.gmail.com>
Message-ID: <fe640fd1-1df5-4286-a006-a1e93242ecde@email.android.com>

My guess is that you do not have the appropriate ODBC development library for your operating system installed. It is not unusual that R packages that provide interfaces to outside APIs require that those resources be installed and configured in the operating system before the relevant R library can be installed.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 20, 2014 3:43:44 PM PDT, William Deese <williamdeese at gmail.com> wrote:
>I tried installing RODBC but got the following message:
>
>Checks were yes until the following
>
>checking sql.h usability... no
>checking sql.h presence... no
>checking for sql.h... no
>checking sqlext.h usability... no
>checking sqlext.h presence... no
>checking for sqlext.h... no
>configure: error: "ODBC headers sql.h and sqlext.h not found"
>ERROR: configuration failed for package ?RODBC?
>* removing ?/home/bill/R/x86_64-pc-linux-gnu-library/3.1/RODBC?
>
>Apparently RODBC was there when R was installed, but library() shows
>it is not there now, although the DBI package is. Best ideas for
>installing RODBC?
>
>Bill
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Thu Aug 21 01:55:29 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 21 Aug 2014 09:55:29 +1000
Subject: [R] Line Graph greater than 2 variables on plot
In-Reply-To: <BLU436-SMTP9311262968F8674FD81270A8D20@phx.gbl>
References: <BLU436-SMTP9311262968F8674FD81270A8D20@phx.gbl>
Message-ID: <000e01cfbcd2$38f925c0$aaeb7140$@bigpond.com>

Hi

Try something like (as you have not given a reproducible example)

library(lattice)

xyplot(y1 + y2+ y3 ... ~ x, data = your data.frame, type = "b",
allow.multiple = TRUE)

Read ?xyplot CAREFULLY as there are many possibilities

you may want to have a look at 

library(lattice)
?useOuterStrips

and other functions in the package

See 

http://lmdvr.r-forge.r-project.org/figures/figures.html

for ideas

Regards

Duncan 

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Waseq Ziaie
Sent: Thursday, 21 August 2014 08:55
To: r-help at r-project.org
Subject: [R] Line Graph greater than 2 variables on plot

Hi all,

I was wondering if anyone knew how to construct a multiple line graph on R,
where there  are 2 (or more) sets of data points plotted against some x axis
of
data, and you can draw a line on the graph connecting each set of data
points.
for example:
  time..years. 		incidence	 rural	 urban
1         2004     	295.4 		19.01 	 9.50
2         2005     	824.1 		19.95 	 9.98
3         2006    	1078.0		 20.70 	10.35
4         2007    	1258.0  		 21.26 	10.63
5         2008    	1800.0 		 21.83	 10.91
6         2009   		 1890.0		 18.93 	  9.47
7         2010   		 1999.0 		  19.41	  9.71
8         2011 		   2261.0 	 19.89 	  9.95
9         2012    	   2321.0		   20.28 	  10.14

Idea:
a) I am planning plot a graph of data illustrated above where on Y-axis we
can have data in sets INCIDENCE, RURAL and URBAN and on X-axis the points in
set TIME..YEARS.
b) Would like to be able to draw three lines ,connecting the points for each
set of INCIDENCE, RURAL and URBAN over TIME..YEARS.

I have tried really hard to find something but wasn't successful, the latest
information I received after doing the command shown underneath was:

> plot(data1$time..years.,data1$incidence,main="Plot illustrating diarrhoeal
incidence over time", xlab="Time(years)",ylab="Diarrhoeal
incidence",ylim=range(data[c("incidence","rural","urban")]),type"l", col=2)
Error: unexpected string constant in
"plot(data1$time..years.,data1$incidence,main="Plot illustrating diarrhoeal
incidence over time", xlab="Time(years)",ylab="Diarrhoeal
incidence",ylim=range(data[c("incidence","rural","urban")])"

Many thanks,
W
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dromano at stanford.edu  Thu Aug 21 01:56:04 2014
From: dromano at stanford.edu (David Romano)
Date: Wed, 20 Aug 2014 16:56:04 -0700
Subject: [R] ggplot2: how to jitter spaghetti plot so slopes are preserved
Message-ID: <CAO81HcQj96uFfTqtP9KFB=V2-q7u4pThc0EKOxYOGtpqgdaXmg@mail.gmail.com>

Hi,

Suppose I have a the data frame given by:
> dput(toy.df)
structure(list(id = c(1, 2, 1, 2), time = c(1L, 1L, 2L, 2L),
    value = c(1, 2, 2, 3)), .Names = c("id", "time", "value"), row.names = c(NA,
4L), class = "data.frame")

that is:
> toy.df
  id time value
1  1    1     1
2  2    1     2
3  1    2     2
4  2    2     3

I can create a "spaghetti" plot with the command:
> ggplot(toy.df,aes(x=time,y=value,group=id,color=factor(id))) + geom_line()

What I'd like to be able to do is jitter the lines themselves by
translation so that their slopes are preserved, but so far my attempts
to jitter -- within ggplot, as opposed to first jittering toy.df by
hand -- seem to always jitter the two points for a given id
independently, and thus change the slopes.

I'd be grateful for any guidance!

Thanks,
David


From jdnewmil at dcn.davis.CA.us  Thu Aug 21 02:23:12 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 20 Aug 2014 17:23:12 -0700
Subject: [R] ggplot2: how to jitter spaghetti plot so slopes are
	preserved
In-Reply-To: <CAO81HcQj96uFfTqtP9KFB=V2-q7u4pThc0EKOxYOGtpqgdaXmg@mail.gmail.com>
References: <CAO81HcQj96uFfTqtP9KFB=V2-q7u4pThc0EKOxYOGtpqgdaXmg@mail.gmail.com>
Message-ID: <0cac986b-5787-4506-be6b-b20c7277e86d@email.android.com>

Do the jittering yourself before you give the data to ggplot. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 20, 2014 4:56:04 PM PDT, David Romano <dromano at stanford.edu> wrote:
>Hi,
>
>Suppose I have a the data frame given by:
>> dput(toy.df)
>structure(list(id = c(1, 2, 1, 2), time = c(1L, 1L, 2L, 2L),
>value = c(1, 2, 2, 3)), .Names = c("id", "time", "value"), row.names =
>c(NA,
>4L), class = "data.frame")
>
>that is:
>> toy.df
>  id time value
>1  1    1     1
>2  2    1     2
>3  1    2     2
>4  2    2     3
>
>I can create a "spaghetti" plot with the command:
>> ggplot(toy.df,aes(x=time,y=value,group=id,color=factor(id))) +
>geom_line()
>
>What I'd like to be able to do is jitter the lines themselves by
>translation so that their slopes are preserved, but so far my attempts
>to jitter -- within ggplot, as opposed to first jittering toy.df by
>hand -- seem to always jitter the two points for a given id
>independently, and thus change the slopes.
>
>I'd be grateful for any guidance!
>
>Thanks,
>David
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Thu Aug 21 05:19:15 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 21 Aug 2014 11:19:15 +0800 (CST)
Subject: [R]  file.show() may have some bug?
Message-ID: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>

Dear Rusers,
   when i try file.show(" xxx.h") in Rstudio which using R3.0.2, it doesn't show anything. But when i use file.edit("xxx.h"),it shows the right file,  It is the same thing happen to xxx.c file.
May you explain it to me?





--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU
	[[alternative HTML version deleted]]


From jon.skoien at jrc.ec.europa.eu  Thu Aug 21 08:58:28 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Thu, 21 Aug 2014 08:58:28 +0200
Subject: [R] ordinary kriging: the edges of the polygons are ignored
In-Reply-To: <7EAF9447-D09E-488D-8284-102C7DC9B754@imperial.ac.uk>
References: <7EAF9447-D09E-488D-8284-102C7DC9B754@imperial.ac.uk>
Message-ID: <53F59894.30303@jrc.ec.europa.eu>


Hi Frederico,

The kriging function seems to come from the kriging package (please give 
also the package next time you ask a question), which I dont know. I can 
therefore not tell you why it does not give you the correct result. But 
R has a huge number of packages which can krige, and autoKrige from 
automap should fairly easy be able to give you what you want.

# You have to create a SpatialPolygon of your house first, from which 
you can sample:
pts = cbind(house$x, house$y)
pts = rbind(pts, pts[1,]) # Repeating the first coordinates, just to 
close the polygon
house2 = SpatialPolygons( list( Polygons(list(Polygon(pts)), 1)))
housegrid = spsample(house2, 10000, "regular") # Sampling 10000 points 
on a regular grid
gridded(housegrid) = TRUE # Defining this to be a grid, not a collection 
of points

# You need to make a SpatialPointsDataFrame of your temperature data, 
and then you can interpolate
coordinates(U) = ~x+y
res = autoKrige(temp~1, U, housegrid)
spplot(res$krige_output, col.regions = rev(heat.colors(100)))
# Your result is in the var1.pred-variable of res$krige_output

You will generally get more and quicker answers to questions about 
spatial data and methods from the r-sig-geo list.

Best wishes,
Jon


On 8/20/2014 11:01 PM, Federico Calboli wrote:
> Hi All,
>
> I am trying to do some kriging of a floor, based on a number of heat sensors.
>
> My data looks like this:
>
>     sensor        temp    x    y
> 1       1  1.25437406  390 2960
> 2       2  0.64384594  830 2960
> 3       3  1.52067733 1420 2960
> 4       4  1.21441928 3127 2920
> 5       5  1.04227694 4005 2920
> 6       6  1.90084852  400 1960
> 7       7  1.58530250  835 1880
> 8       8  1.23060971 1130 1960
> 9       9  0.92749453 1550 1950
> 10     10  0.76638878 1995 1960
> 11     11  0.84247092 2540 1950
> 12     12  0.93999929 3300 1880
> 13     13  0.61610170 4000 1870
> 14     14  1.06967332  395 1330
> 15     15  0.72970917  845 1330
> 16     16  0.60216970 1135 1300
> 17     17  0.44648551 1570 1275
> 18     18  2.49863724 2010 1290
> 19     19  0.71619206 2540 1320
> 20     20  1.50984666 3140 1275
> 21     21 -0.06540552 4000 1258
> 22     22  1.20017747  400  685
> 23     23  1.05820693 1575  640
> 24     24  2.25086655 1830  625
> 25     25  0.69296059 3120  625
> 26     26  0.69324786 3990  605
>
> and the floor plan describes the edges of the floor thus:
>
>        x    y
> 1   210 3200
> 2   210  420
> 3  1510  420
> 4  1510  100
> 5  4090  100
> 6  4090 3200
> 7  2947 3200
> 8  2947 2850
> 9  1647 2850
> 10 1647 3200
> 11  210 3200
> 12  210 3200
>
> I run these commands:
>
> house2 <- list(data.frame(house$x, house$y))
> plot(house.y ~house.x, type = 'l', house2[[1]])
> points(U[,3], U[,4], pch = 20)
> housekrig=kriging(U[,3],U[,4],U[,2],polygons=house2,lags = 5)
> image(housekrig, xlim = extendrange(U[,3]), ylim = extendrange(U[,4]), col = rev(heat.colors(100)))
>
> and I noticed that the kriging area does not respect the floor plan.  In fact, if I do:
>
> points(U[,3], U[,4], pch = 20)
>
> the sensors and not in the same place, and the kriging has ignored the edges of the polygons altogether.
>
> So my question is, how do I have a kriging of the *whole* surface, based on my sensors?  Any suggestion is welcome, especially if the data does not require reformatting (or if the reformatting is straightforward)!
>
> Best
>
> F
>
> PS I have contacted the maintainer of the package about the issue but I had no reply, and I?d need to solve this one way or another sooner, rather than later.
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Thu Aug 21 09:12:06 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 21 Aug 2014 09:12:06 +0200
Subject: [R] file.show() may have some bug?
In-Reply-To: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>
References: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>
Message-ID: <0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>


On 21-08-2014, at 05:19, PO SU <rhelpmaillist at 163.com> wrote:

> Dear Rusers,
>   when i try file.show(" xxx.h") in Rstudio which using R3.0.2, it doesn't show anything. But when i use file.edit("xxx.h"),it shows the right file,  It is the same thing happen to xxx.c file.
> May you explain it to me?
> 

How about leaving out the space in file.show(" xxx.h?)?
Use file.show("xxx.h?)

Berend


From rhelpmaillist at 163.com  Thu Aug 21 09:50:07 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 21 Aug 2014 15:50:07 +0800 (CST)
Subject: [R] file.show() may have some bug?
In-Reply-To: <0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>
References: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>
	<0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>
Message-ID: <4de7d678.5d47.147f78b4c6a.Coremail.rhelpmaillist@163.com>




Sorry for my bad typing,?file.show("xxx.h") still not work.


--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-08-21 03:12:06, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>
>On 21-08-2014, at 05:19, PO SU <rhelpmaillist at 163.com> wrote:
>
>> Dear Rusers,
>>   when i try file.show(" xxx.h") in Rstudio which using R3.0.2, it doesn't show anything. But when i use file.edit("xxx.h"),it shows the right file,  It is the same thing happen to xxx.c file.
>> May you explain it to me?
>> 
>
>How about leaving out the space in file.show(" xxx.h?)?
>Use file.show("xxx.h?)
>
>Berend
>

From ripley at stats.ox.ac.uk  Thu Aug 21 10:13:19 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 21 Aug 2014 09:13:19 +0100
Subject: [R] file.show() may have some bug?
In-Reply-To: <4de7d678.5d47.147f78b4c6a.Coremail.rhelpmaillist@163.com>
References: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>	<0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>
	<4de7d678.5d47.147f78b4c6a.Coremail.rhelpmaillist@163.com>
Message-ID: <53F5AA1F.8050002@stats.ox.ac.uk>

On 21/08/2014 08:50, PO SU wrote:
>
>
>
> Sorry for my bad typing, file.show("xxx.h") still not work.

But note that file.show() uses facilities of the front-end, so report 
RStudio problems to them not the R community.

Also note that the posting guide asked you to update before posting: 
your R is 3 versions old.

>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-08-21 03:12:06, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>>
>> On 21-08-2014, at 05:19, PO SU <rhelpmaillist at 163.com> wrote:
>>
>>> Dear Rusers,
>>>    when i try file.show(" xxx.h") in Rstudio which using R3.0.2, it doesn't show anything. But when i use file.edit("xxx.h"),it shows the right file,  It is the same thing happen to xxx.c file.
>>> May you explain it to me?
>>>
>>
>> How about leaving out the space in file.show(" xxx.h?)?
>> Use file.show("xxx.h?)
>>
>> Berend
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From pdalgd at gmail.com  Thu Aug 21 10:40:10 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 Aug 2014 10:40:10 +0200
Subject: [R] file.show() may have some bug?
In-Reply-To: <53F5AA1F.8050002@stats.ox.ac.uk>
References: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>	<0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>
	<4de7d678.5d47.147f78b4c6a.Coremail.rhelpmaillist@163.com>
	<53F5AA1F.8050002@stats.ox.ac.uk>
Message-ID: <F16833B4-6A20-482D-91A8-C29F18CCCD06@gmail.com>


On 21 Aug 2014, at 10:13 , Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:

> On 21/08/2014 08:50, PO SU wrote:
>> 
>> 
>> 
>> Sorry for my bad typing, file.show("xxx.h") still not work.
> 
> But note that file.show() uses facilities of the front-end, so report RStudio problems to them not the R community.
> 
> Also note that the posting guide asked you to update before posting: your R is 3 versions old.


And it does seem to work in R-3.1.1/Rstudio 0.98.939 (the latter is in for an update, but hey, preachers can't be practitioners...).

-pd

> 
>> 
>> 
>> --
>> 
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> 
>> 
>> 
>> At 2014-08-21 03:12:06, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>>> 
>>> On 21-08-2014, at 05:19, PO SU <rhelpmaillist at 163.com> wrote:
>>> 
>>>> Dear Rusers,
>>>>   when i try file.show(" xxx.h") in Rstudio which using R3.0.2, it doesn't show anything. But when i use file.edit("xxx.h"),it shows the right file,  It is the same thing happen to xxx.c file.
>>>> May you explain it to me?
>>>> 
>>> 
>>> How about leaving out the space in file.show(" xxx.h?)?
>>> Use file.show("xxx.h?)
>>> 
>>> Berend
>>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dmcp at webmail.co.za  Thu Aug 21 13:26:21 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Thu, 21 Aug 2014 13:26:21 +0200
Subject: [R] Line Graph greater than 2 variables on plot
In-Reply-To: <000e01cfbcd2$38f925c0$aaeb7140$@bigpond.com>
References: <BLU436-SMTP9311262968F8674FD81270A8D20@phx.gbl>,
	<000e01cfbcd2$38f925c0$aaeb7140$@bigpond.com>
Message-ID: <882c0d33328f192019a7898060faf5b9@www.webmail.co.za>

You could also try matplot(data_object[, 1], data_object[, -1], ...)
?matplot

Cheers.

On Thu, 21 Aug 2014 09:55:29 +1000 "Duncan Mackay" <dulcalma at bigpond.com>
wrote

> Hi
> 
> Try something like (as you have not given a reproducible example)
> 
> library(lattice)
> 
> xyplot(y1 + y2+ y3 ... ~ x, data = your data.frame, type = "b",
> allow.multiple = TRUE)
> 
> Read ?xyplot CAREFULLY as there are many possibilities
> 
> you may want to have a look at 
> 
> library(lattice)
> ?useOuterStrips
> 
> and other functions in the package
> 
> See 
> 
> http://lmdvr.r-forge.r-project.org/figures/figures.html
> 
> for ideas
> 
> Regards
> 
> Duncan 
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Waseq Ziaie
> Sent: Thursday, 21 August 2014 08:55
> To: r-help at r-project.org
> Subject: [R] Line Graph greater than 2 variables on plot
> 
> Hi all,
> 
> I was wondering if anyone knew how to construct a multiple line graph on R,
> where there  are 2 (or more) sets of data points plotted against some x axis
> of
> data, and you can draw a line on the graph connecting each set of data
> points.
> for example:
>   time..years.         incidence     rural     urban
> 1         2004         295.4         19.01      9.50
> 2         2005         824.1         19.95      9.98
> 3         2006        1078.0         20.70     10.35
> 4         2007        1258.0           21.26     10.63
> 5         2008        1800.0          21.83     10.91
> 6         2009            1890.0         18.93       9.47
> 7         2010            1999.0           19.41      9.71
> 8         2011            2261.0      19.89       9.95
> 9         2012           2321.0           20.28       10.14
> 
> Idea:
> a) I am planning plot a graph of data illustrated above where on Y-axis we
> can have data in sets INCIDENCE, RURAL and URBAN and on X-axis the points in
> set TIME..YEARS.
> b) Would like to be able to draw three lines ,connecting the points for each
> set of INCIDENCE, RURAL and URBAN over TIME..YEARS.
> 
> I have tried really hard to find something but wasn't successful, the latest
> information I received after doing the command shown underneath was:
> 
> > plot(data1$time..years.,data1$incidence,main="Plot illustrating diarrhoeal
> incidence over time", xlab="Time(years)",ylab="Diarrhoeal
> incidence",ylim=range(data[c("incidence","rural","urban")]),type"l", col=2)
> Error: unexpected string constant in
> "plot(data1$time..years.,data1$incidence,main="Plot illustrating diarrhoeal
> incidence over time", xlab="Time(years)",ylab="Diarrhoeal
> incidence",ylim=range(data[c("incidence","rural","urban")])"
> 
> Many thanks,
> W
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Cotlands - Shaping tomorrows Heroes http://www.cotlands.org.za/


From andrewcd at gmail.com  Thu Aug 21 13:53:58 2014
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Thu, 21 Aug 2014 14:53:58 +0300
Subject: [R] bam (mgcv) not using the specified number of cores
Message-ID: <53F5DDD6.8000006@gmail.com>

I am getting strange behavior when trying to fit models to large 
datasets using bam.  I am working on a 4-core machine, but I think that 
there may be 2 physical cores that the computer uses as 4 cores in some 
sense that I don't understand.

When I run the bam using makeCluster(3), the model runs on one core.  
But when I run it on makeCluster(2), top shoes me that three of my cores 
are taken up to full capacity, and my computer slows down or crashes.

How can I get it to truly run on 2 cores?

I'm on a thinkpad X230, running ubuntu.

Thanks,
Andrew


From rhelpmaillist at 163.com  Thu Aug 21 15:13:10 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Thu, 21 Aug 2014 21:13:10 +0800 (CST)
Subject: [R] file.show() may have some bug?
In-Reply-To: <F16833B4-6A20-482D-91A8-C29F18CCCD06@gmail.com>
References: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>
	<0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>
	<4de7d678.5d47.147f78b4c6a.Coremail.rhelpmaillist@163.com>
	<53F5AA1F.8050002@stats.ox.ac.uk>
	<F16833B4-6A20-482D-91A8-C29F18CCCD06@gmail.com>
Message-ID: <62bc8958.d0b7.147f8b30eea.Coremail.rhelpmaillist@163.com>

Because the update of R is rather a trouble thing, i mean that you should have to install every package you have installed. So i do not follow the newest version.




--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2014-08-21 04:40:10, "peter dalgaard" <pdalgd at gmail.com> wrote:
>
>On 21 Aug 2014, at 10:13 , Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
>
>> On 21/08/2014 08:50, PO SU wrote:
>>> 
>>> 
>>> 
>>> Sorry for my bad typing, file.show("xxx.h") still not work.
>> 
>> But note that file.show() uses facilities of the front-end, so report RStudio problems to them not the R community.
>> 
>> Also note that the posting guide asked you to update before posting: your R is 3 versions old.
>
>
>And it does seem to work in R-3.1.1/Rstudio 0.98.939 (the latter is in for an update, but hey, preachers can't be practitioners...).
>
>-pd
>
>> 
>>> 
>>> 
>>> --
>>> 
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> 
>>> 
>>> 
>>> At 2014-08-21 03:12:06, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>>>> 
>>>> On 21-08-2014, at 05:19, PO SU <rhelpmaillist at 163.com> wrote:
>>>> 
>>>>> Dear Rusers,
>>>>>   when i try file.show(" xxx.h") in Rstudio which using R3.0.2, it doesn't show anything. But when i use file.edit("xxx.h"),it shows the right file,  It is the same thing happen to xxx.c file.
>>>>> May you explain it to me?
>>>>> 
>>>> 
>>>> How about leaving out the space in file.show(" xxx.h??)?
>>>> Use file.show("xxx.h??)
>>>> 
>>>> Berend
>>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> -- 
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Peter Dalgaard, Professor,
>Center for Statistics, Copenhagen Business School
>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>Phone: (+45)38153501
>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From s.wood at bath.ac.uk  Thu Aug 21 15:29:26 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Thu, 21 Aug 2014 14:29:26 +0100
Subject: [R] bam (mgcv) not using the specified number of cores
In-Reply-To: <53F5DDD6.8000006@gmail.com>
References: <53F5DDD6.8000006@gmail.com>
Message-ID: <53F5F436.70704@bath.ac.uk>

Hi Andrew,

Could you provide a bit more information, please. In particular the 
results of sessionInfo() and the code that caused this weird behaviour 
(+ an indication of dataset size).

best,
Simon

On 21/08/14 12:53, Andrew Crane-Droesch wrote:
> I am getting strange behavior when trying to fit models to large
> datasets using bam.  I am working on a 4-core machine, but I think that
> there may be 2 physical cores that the computer uses as 4 cores in some
> sense that I don't understand.
>
> When I run the bam using makeCluster(3), the model runs on one core. But
> when I run it on makeCluster(2), top shoes me that three of my cores are
> taken up to full capacity, and my computer slows down or crashes.
>
> How can I get it to truly run on 2 cores?
>
> I'm on a thinkpad X230, running ubuntu.
>
> Thanks,
> Andrew
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From f.calboli at imperial.ac.uk  Thu Aug 21 15:30:06 2014
From: f.calboli at imperial.ac.uk (Federico Calboli)
Date: Thu, 21 Aug 2014 14:30:06 +0100
Subject: [R] ordinary kriging: the edges of the polygons are ignored
In-Reply-To: <53F59894.30303@jrc.ec.europa.eu>
References: <7EAF9447-D09E-488D-8284-102C7DC9B754@imperial.ac.uk>
	<53F59894.30303@jrc.ec.europa.eu>
Message-ID: <F133F335-598C-4B74-A711-DDFB33B25F9D@imperial.ac.uk>

Hi Jon,

thanks for your reply ? it solves my issues completely.

Best

F



On 21 Aug 2014, at 07:58, Jon Skoien <jon.skoien at jrc.ec.europa.eu> wrote:

> 
> Hi Frederico,
> 
> The kriging function seems to come from the kriging package (please give also the package next time you ask a question), which I dont know. I can therefore not tell you why it does not give you the correct result. But R has a huge number of packages which can krige, and autoKrige from automap should fairly easy be able to give you what you want. 
> 
> # You have to create a SpatialPolygon of your house first, from which you can sample:
> pts = cbind(house$x, house$y)
> pts = rbind(pts, pts[1,]) # Repeating the first coordinates, just to close the polygon
> house2 = SpatialPolygons( list( Polygons(list(Polygon(pts)), 1)))
> housegrid = spsample(house2, 10000, "regular") # Sampling 10000 points on a regular grid
> gridded(housegrid) = TRUE # Defining this to be a grid, not a collection of points
> 
> # You need to make a SpatialPointsDataFrame of your temperature data, and then you can interpolate
> coordinates(U) = ~x+y
> res = autoKrige(temp~1, U, housegrid)
> spplot(res$krige_output, col.regions = rev(heat.colors(100)))
> # Your result is in the var1.pred-variable of res$krige_output
> 
> You will generally get more and quicker answers to questions about spatial data and methods from the r-sig-geo list.
> 
> Best wishes,
> Jon
> 
> 
> On 8/20/2014 11:01 PM, Federico Calboli wrote:
>> Hi All,
>> 
>> I am trying to do some kriging of a floor, based on a number of heat sensors.
>> 
>> My data looks like this:
>> 
>>    sensor        temp    x    y
>> 1       1  1.25437406  390 2960
>> 2       2  0.64384594  830 2960
>> 3       3  1.52067733 1420 2960
>> 4       4  1.21441928 3127 2920
>> 5       5  1.04227694 4005 2920
>> 6       6  1.90084852  400 1960
>> 7       7  1.58530250  835 1880
>> 8       8  1.23060971 1130 1960
>> 9       9  0.92749453 1550 1950
>> 10     10  0.76638878 1995 1960
>> 11     11  0.84247092 2540 1950
>> 12     12  0.93999929 3300 1880
>> 13     13  0.61610170 4000 1870
>> 14     14  1.06967332  395 1330
>> 15     15  0.72970917  845 1330
>> 16     16  0.60216970 1135 1300
>> 17     17  0.44648551 1570 1275
>> 18     18  2.49863724 2010 1290
>> 19     19  0.71619206 2540 1320
>> 20     20  1.50984666 3140 1275
>> 21     21 -0.06540552 4000 1258
>> 22     22  1.20017747  400  685
>> 23     23  1.05820693 1575  640
>> 24     24  2.25086655 1830  625
>> 25     25  0.69296059 3120  625
>> 26     26  0.69324786 3990  605
>> 
>> and the floor plan describes the edges of the floor thus:
>> 
>>       x    y
>> 1   210 3200
>> 2   210  420
>> 3  1510  420
>> 4  1510  100
>> 5  4090  100
>> 6  4090 3200
>> 7  2947 3200
>> 8  2947 2850
>> 9  1647 2850
>> 10 1647 3200
>> 11  210 3200
>> 12  210 3200
>> 
>> I run these commands:
>> 
>> house2 <- list(data.frame(house$x, house$y))
>> plot(house.y ~house.x, type = 'l', house2[[1]])
>> points(U[,3], U[,4], pch = 20)
>> housekrig=kriging(U[,3],U[,4],U[,2],polygons=house2,lags = 5) 
>> image(housekrig, xlim = extendrange(U[,3]), ylim = extendrange(U[,4]), col = rev(heat.colors(100)))
>> 
>> and I noticed that the kriging area does not respect the floor plan.  In fact, if I do:
>> 
>> points(U[,3], U[,4], pch = 20)
>> 
>> the sensors and not in the same place, and the kriging has ignored the edges of the polygons altogether.
>> 
>> So my question is, how do I have a kriging of the *whole* surface, based on my sensors?  Any suggestion is welcome, especially if the data does not require reformatting (or if the reformatting is straightforward)!
>> 
>> Best
>> 
>> F
>> 
>> PS I have contacted the maintainer of the package about the issue but I had no reply, and I?d need to solve this one way or another sooner, rather than later.
>> 
>> 
>> 
>> 
>> 
>> ______________________________________________
>> 
>> R-help at r-project.org
>>  mailing list
>> 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> 
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> 
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 842 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140821/78983425/attachment.bin>

From jun.shen.ut at gmail.com  Thu Aug 21 16:20:43 2014
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 21 Aug 2014 10:20:43 -0400
Subject: [R] How to view the whole dataset that is imported through
	sasxport.get
Message-ID: <CAMCXXmpBp5-ERURzW8_2ddt-MeoPcT4p9L6767LNOaUtCOx9gA@mail.gmail.com>

Dear list,

I used sasxport.get to import a SAS xpt file. Although it is a data frame
but i can't view it through the "fix" command. Also when I see its
structure, it brings up attributes I am not really interested in (which
seems part of the SAS labels) and it doesn't seem to tell me the mode of
each column. How do I suppress those attributes and view it through "fix"?
Thanks.

Jun

	[[alternative HTML version deleted]]


From smileismystyl at gmail.com  Thu Aug 21 11:00:43 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Thu, 21 Aug 2014 14:30:43 +0530
Subject: [R] Error - "cannot coerce type 'closure' to vector of type
	'character' "
Message-ID: <CAG1d=2D9miVSKwMYfYaDjOnM=TpKPkH49Wtni6K1W7ihKhgf6g@mail.gmail.com>

Dear group,

Im new to R, I find it comfortable using this with the help of tutorials,
But Im stuck up at a point
when I run - points= readOGR(points,sub(".shp","",points))
it shows the error- "cannot coerce type 'closure' to vector of type
'character' ".
What could it be. With my browse efforts, I found that It could be some
startup issues. Like if the variable isnt well declared or started. Is that?
-- 
Girija
Research in National Remote Sensing Centre, ISRO
Master of Science in Geo-Informatics, University of Twente
Bachelor of Technology in Information Technology, JNTU

	[[alternative HTML version deleted]]


From lynn.govaert at gmail.com  Thu Aug 21 11:12:56 2014
From: lynn.govaert at gmail.com (Lynn Govaert)
Date: Thu, 21 Aug 2014 11:12:56 +0200
Subject: [R] Calculating contrasts in Anova with interaction term
Message-ID: <CAPDfU8-EQqZ1+gOOaDKUjXQYdegHd1KZM1avV9m0jjKcvX3q5g@mail.gmail.com>

Hi all,

I have the following variables: a trait z,  Treatment A and B, Population 1
and 2 (each having undergo the treatment), and their interaction. Now, I'm
doing an Anova as follows

aov( z ~ Treatment * Population )

I now want to compare the values of population 1 which underwent treatment
A with the values of population 2 which underwent treatment B using
contrasts. I found a very useful explanation for calculating contrasts on
the internet (
http://r-eco-evo.blogspot.be/2007/10/one-of-most-neglected-topics-in_06.html),
however, they did not explain it for an interaction term. Now I thought, if
I just make a new variable for my interaction term, which is a categorical
variable having 4 levels (level 1: pop 1 with treatment A, level 2: pop 1
with treatment B, level 3: pop 2 treatment A and level 4: pop 2 treatment
B).

If I then construct my contrast vector as con <- c(1,0,0,-1)
Then do contrasts(data$trait) <- con
Then my model
model <- aov( z ~ Treatment + Population + InteractionTerm ) with the
InteractionTerm the new created variable
and then do what they did
summary(model, split = list(trait = list("comparison"=1)))
I get the following result

Treatment                    1 0.00246 0.00246   3.059   0.0816 .
Population                   1 0.05643 0.05643  70.241 4.75e-15 ***
IntTerm                        1 0.02869 0.02869  35.713 8.37e-09 ***
  IntTerm: comparison   1 0.02869 0.02869  35.713 8.37e-09 ***
Residuals                236 0.18959 0.00080

It is just so strange that the two last rows are exactly the same. So I
guess I'm doing something wrong.


As a second related question. I also found another method to calculate
contrasts. Using the Phia package in R. It works fine, but I don't find how
I can make a link between my two variables, so it takes pop 1 with
treatment A and pop 2 with treatment B to compare those two. I only find
how I can make combination within my treatment variable or within my
population variable. And that is not what I want. You can find the
information on
http://cran.r-project.org/web/packages/phia/vignettes/phia.pdf

If anyone knows what I'm doing wrong in the first example or if it makes
sence that they could be the same. Or an answer to my second question. I
would be very happy.

Thanks in advance!
Lynn

	[[alternative HTML version deleted]]


From lynn.govaert at gmail.com  Thu Aug 21 12:08:38 2014
From: lynn.govaert at gmail.com (Lynn Govaert)
Date: Thu, 21 Aug 2014 12:08:38 +0200
Subject: [R] anova
Message-ID: <CAPDfU8-UjgA7HDyuYai=_WB3vkY4F_h+TP4dVygwr2rwYnKxPg@mail.gmail.com>

Hi all,

I have troubles with doing an anova. So I have the following variables: a
variable group with two levels, a continuous variable trait and within each
group we have 12 organisms (clone) and for each clone we have 5 replicates.
So we want to see if for the variable trait the two groups differ,
including the information for the clones.

So the dataset looks like:

trait          group

	[[alternative HTML version deleted]]


From lynn.govaert at gmail.com  Thu Aug 21 12:13:13 2014
From: lynn.govaert at gmail.com (Lynn Govaert)
Date: Thu, 21 Aug 2014 12:13:13 +0200
Subject: [R] anova
In-Reply-To: <CAPDfU8-UjgA7HDyuYai=_WB3vkY4F_h+TP4dVygwr2rwYnKxPg@mail.gmail.com>
References: <CAPDfU8-UjgA7HDyuYai=_WB3vkY4F_h+TP4dVygwr2rwYnKxPg@mail.gmail.com>
Message-ID: <CAPDfU89u2ij6LbLDjmiFOQN5ZkuBPONr9kexG88m0e2WGpKAUQ@mail.gmail.com>

I pressed enter to soon.

Again

Hi all,

I have troubles with doing an anova. So I have the following variables: a
variable group with two levels, a continuous variable trait and within each
group we have 12 organisms (clone) and for each clone we have 5 replicates.
So we want to see if for the variable trait the two groups differ,
including the information for the clones.

So the dataset looks like:

trait          group            clone
...              1                   a1
...              1                   a2
...
...              1                   a12
...              1                    a1
...
...               2                    b1
...               2                    b2

etc

trait are just some numbers.
So clone is nested in group.

Then I don't understand how to make the anova,
I was thinking we want to see if there is an effect of group

So we built the model aov(trait ~group)
but because we also want to include the effect of clone which is a random
effect we do

aov(trait ~ group + Error(clone))
but because Clone is nested in group
we do
aov(trait ~ group + Error(group/clone))

but if I do this I get the following output


Error: PopulationTNFMF
                Df  Sum Sq Mean Sq
PopulationTNFMF  1 0.00917 0.00917

Error: PopulationTNFMF:CloneTNFMF
          Df    Sum Sq   Mean Sq F value Pr(>F)
Residuals  1 0.0001849 0.0001849

Error: Within
           Df  Sum Sq   Mean Sq F value Pr(>F)
Residuals 117 0.02107 0.0001801


and I don't get any p-values, so I guess I'm doing something wrong.
Can someone help?

Thank you in advance
Lynn


2014-08-21 12:08 GMT+02:00 Lynn Govaert <lynn.govaert at gmail.com>:

> Hi all,
>
> I have troubles with doing an anova. So I have the following variables: a
> variable group with two levels, a continuous variable trait and within each
> group we have 12 organisms (clone) and for each clone we have 5 replicates.
> So we want to see if for the variable trait the two groups differ,
> including the information for the clones.
>
> So the dataset looks like:
>
> trait          group
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Aug 21 16:32:35 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 21 Aug 2014 10:32:35 -0400
Subject: [R] anova
In-Reply-To: <CAPDfU8-UjgA7HDyuYai=_WB3vkY4F_h+TP4dVygwr2rwYnKxPg@mail.gmail.com>
References: <CAPDfU8-UjgA7HDyuYai=_WB3vkY4F_h+TP4dVygwr2rwYnKxPg@mail.gmail.com>
Message-ID: <CAM_vju=gVuLVNxerPPK=UhyFn4UDyZoZmAyb5NdtYhvoB3z=OA@mail.gmail.com>

Hi Lynn,

Please read the posting guide, this document:
http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

and don't post in HTML. (See your own email copied below for why.)

Sarah

On Thu, Aug 21, 2014 at 6:08 AM, Lynn Govaert <lynn.govaert at gmail.com> wrote:
> Hi all,
>
> I have troubles with doing an anova. So I have the following variables: a
> variable group with two levels, a continuous variable trait and within each
> group we have 12 organisms (clone) and for each clone we have 5 replicates.
> So we want to see if for the variable trait the two groups differ,
> including the information for the clones.
>
> So the dataset looks like:
>
> trait          group
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From gunter.berton at gene.com  Thu Aug 21 16:37:38 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 21 Aug 2014 07:37:38 -0700
Subject: [R] anova
In-Reply-To: <CAPDfU89u2ij6LbLDjmiFOQN5ZkuBPONr9kexG88m0e2WGpKAUQ@mail.gmail.com>
References: <CAPDfU8-UjgA7HDyuYai=_WB3vkY4F_h+TP4dVygwr2rwYnKxPg@mail.gmail.com>
	<CAPDfU89u2ij6LbLDjmiFOQN5ZkuBPONr9kexG88m0e2WGpKAUQ@mail.gmail.com>
Message-ID: <CACk-te2RqJK=mwN=KZ_8gV_NOjGsPftanAceqxKSRLNQELGTPA@mail.gmail.com>

... and you do get P values; you just don't understand what you're
looking at, which is more or less what you said.

This is not a statistical help site. You should seek local statistical
consulting advice or post on a statistical help site (caveat emptor!)
like stats.stackexchange.com, not here.

Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Thu, Aug 21, 2014 at 3:13 AM, Lynn Govaert <lynn.govaert at gmail.com> wrote:
> I pressed enter to soon.
>
> Again
>
> Hi all,
>
> I have troubles with doing an anova. So I have the following variables: a
> variable group with two levels, a continuous variable trait and within each
> group we have 12 organisms (clone) and for each clone we have 5 replicates.
> So we want to see if for the variable trait the two groups differ,
> including the information for the clones.
>
> So the dataset looks like:
>
> trait          group            clone
> ...              1                   a1
> ...              1                   a2
> ...
> ...              1                   a12
> ...              1                    a1
> ...
> ...               2                    b1
> ...               2                    b2
>
> etc
>
> trait are just some numbers.
> So clone is nested in group.
>
> Then I don't understand how to make the anova,
> I was thinking we want to see if there is an effect of group
>
> So we built the model aov(trait ~group)
> but because we also want to include the effect of clone which is a random
> effect we do
>
> aov(trait ~ group + Error(clone))
> but because Clone is nested in group
> we do
> aov(trait ~ group + Error(group/clone))
>
> but if I do this I get the following output
>
>
> Error: PopulationTNFMF
>                 Df  Sum Sq Mean Sq
> PopulationTNFMF  1 0.00917 0.00917
>
> Error: PopulationTNFMF:CloneTNFMF
>           Df    Sum Sq   Mean Sq F value Pr(>F)
> Residuals  1 0.0001849 0.0001849
>
> Error: Within
>            Df  Sum Sq   Mean Sq F value Pr(>F)
> Residuals 117 0.02107 0.0001801
>
>
> and I don't get any p-values, so I guess I'm doing something wrong.
> Can someone help?
>
> Thank you in advance
> Lynn
>
>
> 2014-08-21 12:08 GMT+02:00 Lynn Govaert <lynn.govaert at gmail.com>:
>
>> Hi all,
>>
>> I have troubles with doing an anova. So I have the following variables: a
>> variable group with two levels, a continuous variable trait and within each
>> group we have 12 organisms (clone) and for each clone we have 5 replicates.
>> So we want to see if for the variable trait the two groups differ,
>> including the information for the clones.
>>
>> So the dataset looks like:
>>
>> trait          group
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Aug 21 16:38:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 21 Aug 2014 07:38:01 -0700
Subject: [R] file.show() may have some bug?
In-Reply-To: <62bc8958.d0b7.147f8b30eea.Coremail.rhelpmaillist@163.com>
References: <c7579d0.2f6c.147f6935214.Coremail.rhelpmaillist@163.com>
	<0A7E019B-FA12-4875-AB7D-2E539CF58DE3@xs4all.nl>
	<4de7d678.5d47.147f78b4c6a.Coremail.rhelpmaillist@163.com>
	<53F5AA1F.8050002@stats.ox.ac.uk>
	<F16833B4-6A20-482D-91A8-C29F18CCCD06@gmail.com>
	<62bc8958.d0b7.147f8b30eea.Coremail.rhelpmaillist@163.com>
Message-ID: <0f91b8e8-5cab-4cfe-8b5c-60644ba6c683@email.android.com>

Answering your questions is a "trouble thing" also. You are asked to solve those problems that already have easy fixes on your own, first, to make reproducing your problem on our end less mysterious. The Posting Guide is intended to help you to help us identify your problem... please use it. It may help you understand if you remember: we are not here to solve your problem... we are here to help you solve your own problem. The more possible problems you can rule out without the hassle of us guessing wrong, the sooner you will be able to move on.

There are workarounds that you can find by searching on the internet to simplify carrying forward your library of contributed packages quite easily. Also, for the purposes of asking for help you can install multiple versions of R and run your (small!) example in the latest version with a minimum of packages if only to prepare your question for the list. Having two versions may be "trouble" to you, but having dozens of versions on hand so we can reliably answer your particular question among all the other questions out there is just not feasible.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 21, 2014 6:13:10 AM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>Because the update of R is rather a trouble thing, i mean that you
>should have to install every package you have installed. So i do not
>follow the newest version.
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com
>Majored in Statistics from SJTU
>
>
>
>At 2014-08-21 04:40:10, "peter dalgaard" <pdalgd at gmail.com> wrote:
>>
>>On 21 Aug 2014, at 10:13 , Prof Brian Ripley <ripley at stats.ox.ac.uk>
>wrote:
>>
>>> On 21/08/2014 08:50, PO SU wrote:
>>>> 
>>>> 
>>>> 
>>>> Sorry for my bad typing, file.show("xxx.h") still not work.
>>> 
>>> But note that file.show() uses facilities of the front-end, so
>report RStudio problems to them not the R community.
>>> 
>>> Also note that the posting guide asked you to update before posting:
>your R is 3 versions old.
>>
>>
>>And it does seem to work in R-3.1.1/Rstudio 0.98.939 (the latter is in
>for an update, but hey, preachers can't be practitioners...).
>>
>>-pd
>>
>>> 
>>>> 
>>>> 
>>>> --
>>>> 
>>>> PO SU
>>>> mail: desolator88 at 163.com
>>>> Majored in Statistics from SJTU
>>>> 
>>>> 
>>>> 
>>>> At 2014-08-21 03:12:06, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>>>>> 
>>>>> On 21-08-2014, at 05:19, PO SU <rhelpmaillist at 163.com> wrote:
>>>>> 
>>>>>> Dear Rusers,
>>>>>>   when i try file.show(" xxx.h") in Rstudio which using R3.0.2,
>it doesn't show anything. But when i use file.edit("xxx.h"),it shows
>the right file,  It is the same thing happen to xxx.c file.
>>>>>> May you explain it to me?
>>>>>> 
>>>>> 
>>>>> How about leaving out the space in file.show(" xxx.h??)?
>>>>> Use file.show("xxx.h??)
>>>>> 
>>>>> Berend
>>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>>> -- 
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Emeritus Professor of Applied Statistics, University of Oxford
>>> 1 South Parks Road, Oxford OX1 3TG, UK
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>-- 
>>Peter Dalgaard, Professor,
>>Center for Statistics, Copenhagen Business School
>>Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>Phone: (+45)38153501
>>Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-fcomte.fr  Thu Aug 21 16:38:43 2014
From: ivan.calandra at univ-fcomte.fr (Ivan Calandra)
Date: Thu, 21 Aug 2014 16:38:43 +0200
Subject: [R] require() but for source()d files
Message-ID: <53F60473.4020601@univ-fcomte.fr>

Dear useRs,

I'm looking for something like require() but which will work on 
source()d files.

I have a .R file with lots of functions and I'm writing a new function 
(say, 'foo') that depends on the functions from this file.

Until now, I have always source()d the .R file before running 'foo'.
But I would like to include some code in 'foo' to source() the file only 
if it hasn't been done yet, and do nothing if the file has already been 
source()d in the session.
So, the same behavior as require() with packages, but with a .R file.

Does it make sense? I could provide an example if you think it would help.

Thank you in advance,
Ivan

-- 
Ivan Calandra
University of Franche-Comt?
Laboratoire Chrono-Environnement
Bureau ATER -107L
16, Route de Gray
25030 Besan?on Cedex, France
ivan.calandra at univ-fcomte.fr
+33 (0) 381 66 20 60
http://chrono-environnement.univ-fcomte.fr/spip.php?article1830


From ruipbarradas at sapo.pt  Thu Aug 21 17:42:20 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 21 Aug 2014 16:42:20 +0100
Subject: [R] Error - "cannot coerce type 'closure' to vector of type
 'character' "
In-Reply-To: <CAG1d=2D9miVSKwMYfYaDjOnM=TpKPkH49Wtni6K1W7ihKhgf6g@mail.gmail.com>
References: <CAG1d=2D9miVSKwMYfYaDjOnM=TpKPkH49Wtni6K1W7ihKhgf6g@mail.gmail.com>
Message-ID: <53F6135C.2090007@sapo.pt>

Hello,

'points' is an R function (a closure) and either readOGR() or sub() or 
both are expecting a vector. Use a different name, like pnts.

Hope this helps,

Rui Barradas

Em 21-08-2014 10:00, Girija Kalyani escreveu:
> Dear group,
>
> Im new to R, I find it comfortable using this with the help of tutorials,
> But Im stuck up at a point
> when I run - points= readOGR(points,sub(".shp","",points))
> it shows the error- "cannot coerce type 'closure' to vector of type
> 'character' ".
> What could it be. With my browse efforts, I found that It could be some
> startup issues. Like if the variable isnt well declared or started. Is that?
>


From dwinsemius at comcast.net  Thu Aug 21 17:53:12 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 21 Aug 2014 08:53:12 -0700
Subject: [R] How to view the whole dataset that is imported through
	sasxport.get
In-Reply-To: <CAMCXXmpBp5-ERURzW8_2ddt-MeoPcT4p9L6767LNOaUtCOx9gA@mail.gmail.com>
References: <CAMCXXmpBp5-ERURzW8_2ddt-MeoPcT4p9L6767LNOaUtCOx9gA@mail.gmail.com>
Message-ID: <D7C70B22-A899-44F7-AA84-283959D925F8@comcast.net>


On Aug 21, 2014, at 7:20 AM, Jun Shen wrote:

> Dear list,
> 
> I used sasxport.get to import a SAS xpt file. Although it is a data frame
> but i can't view it through the "fix" command. Also when I see its
> structure, it brings up attributes I am not really interested in (which
> seems part of the SAS labels) and it doesn't seem to tell me the mode of
> each column. How do I suppress those attributes and view it through "fix"?
> Thanks.

It would have helped a lot if you had offered outout of: str(dataset)

I don't use fix() so I'm not sure I help you there. I do notice in looking at the documentation that the function may return a list of dataframes rather than just a dataframe, so perhaps you need to extract the dataframe object. (Just a guess.)

 I generally look at my files with names(), and Hmisc::describe() and use table() for the factor or character values that I expect to have manageable numbers of discrete categories. (Using `fix()` to edit gigabyte sized objects is the way to madness.) You should probably read the Posting Guide because you are failing to mention that the sasxport.get() function is part of the Hmisc package. If you want to get rid of your attributes (which is where the labels are stored)  then the attr() function should allow you to NULL them out:

> x <- 1:10
> attr(x,"dim") <- c(2, 5)
> 
> x
     [,1] [,2] [,3] [,4] [,5]
[1,]    1    3    5    7    9
[2,]    2    4    6    8   10
> attr(x,"dim")
[1] 2 5
> attr(x,"dim") <- NULL
> x
 [1]  1  2  3  4  5  6  7  8  9 10

It also appears the there is a `label<-` function, so you could probably use that to NULL them out.

-- 

David Winsemius
Alameda, CA, USA


From hb at biostat.ucsf.edu  Thu Aug 21 18:15:50 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 21 Aug 2014 09:15:50 -0700
Subject: [R] require() but for source()d files
In-Reply-To: <53F60473.4020601@univ-fcomte.fr>
References: <53F60473.4020601@univ-fcomte.fr>
Message-ID: <CAFDcVCSoXdW=s-ag3DnLYLUZu-5wQPjb9a2E8nS4qWz3TPzvEA@mail.gmail.com>

On Aug 21, 2014 7:40 AM, "Ivan Calandra" <ivan.calandra at univ-fcomte.fr>
wrote:
>
> Dear useRs,
>
> I'm looking for something like require() but which will work on source()d
files.
>
> I have a .R file with lots of functions and I'm writing a new function
(say, 'foo') that depends on the functions from this file.
>
> Until now, I have always source()d the .R file before running 'foo'.
> But I would like to include some code in 'foo' to source() the file only
if it hasn't been done yet, and do nothing if the file has already been
source()d in the session.

R.utils::sourceTo(file, modifiedOnly=TRUE)

should do it. It will always source the file once. Also, contrary to
source() it default is to use local=TRUE.

Henrik

> So, the same behavior as require() with packages, but with a .R file.
>
> Does it make sense? I could provide an example if you think it would help.
>
> Thank you in advance,
> Ivan
>
> --
> Ivan Calandra
> University of Franche-Comt?
> Laboratoire Chrono-Environnement
> Bureau ATER -107L
> 16, Route de Gray
> 25030 Besan?on Cedex, France
> ivan.calandra at univ-fcomte.fr
> +33 (0) 381 66 20 60
> http://chrono-environnement.univ-fcomte.fr/spip.php?article1830
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From andrewcd at gmail.com  Thu Aug 21 18:05:01 2014
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Thu, 21 Aug 2014 19:05:01 +0300
Subject: [R] bam (mgcv) not using the specified number of cores
In-Reply-To: <53F5F436.70704@bath.ac.uk>
References: <53F5DDD6.8000006@gmail.com> <53F5F436.70704@bath.ac.uk>
Message-ID: <53F618AD.4070804@gmail.com>

Hi Simon,

Thanks for the reply.  I've tried to reproduce the error, but I don't 
know how to show output from `top` any other way than to attach 
screenshots, so please excuse that.

I'm attaching screenshots of what happens when I run with two and three 
cores.  In the former, it seems to be working on one core, and in the 
latter, it appears to be working on three.  When reproducing the error, 
I'm getting odd behavior that isn't entirely consistent -- sometimes it 
"behaves" and operates on the asked-for number of cores, and other times 
not.

I'm also attaching a screenshot showing terminal output from a remote 
cluster when I run my full model (N=67K) rather than a subset (N=7K) -- 
I get that error "Error in qr.qty(qrx, f) : right-hand side should have 
60650 not 118451 rows ..."  I suppose this is a memory overload 
problem?  Any suggestions on how to get bam to not call for more memory 
than the node has available would be welcome, though I suspect that is a 
supercomputing problem rather than a R problem.

Thanks,
Andrew

sessionInfo() for local machine:
1> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils datasets  methods
[8] base

other attached packages:
[1] mgcv_1.7-26  nlme_3.1-111

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-23 Matrix_1.1-4
1>





On 08/21/2014 04:29 PM, Simon Wood wrote:
> Hi Andrew,
>
> Could you provide a bit more information, please. In particular the 
> results of sessionInfo() and the code that caused this weird behaviour 
> (+ an indication of dataset size).
>
> best,
> Simon
>
> On 21/08/14 12:53, Andrew Crane-Droesch wrote:
>> I am getting strange behavior when trying to fit models to large
>> datasets using bam.  I am working on a 4-core machine, but I think that
>> there may be 2 physical cores that the computer uses as 4 cores in some
>> sense that I don't understand.
>>
>> When I run the bam using makeCluster(3), the model runs on one core. But
>> when I run it on makeCluster(2), top shoes me that three of my cores are
>> taken up to full capacity, and my computer slows down or crashes.
>>
>> How can I get it to truly run on 2 cores?
>>
>> I'm on a thinkpad X230, running ubuntu.
>>
>> Thanks,
>> Andrew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2014-08-21 18:33:36.png
Type: image/png
Size: 576802 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140821/41be1e87/attachment-0003.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2014-08-21 18:34:42.png
Type: image/png
Size: 387719 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140821/41be1e87/attachment-0004.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2014-08-21 18:36:08.png
Type: image/png
Size: 388816 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140821/41be1e87/attachment-0005.png>

From matz at ieee.org  Thu Aug 21 19:19:57 2014
From: matz at ieee.org (Steven M. Matz)
Date: Thu, 21 Aug 2014 13:19:57 -0400
Subject: [R] R version of MATLAB interpn?
Message-ID: <CA+DcPSQ9ZuE4bkiD_iFeDKuWV8sJdDcY6F75RJg8vTsLVjSe8Q@mail.gmail.com>

Is there an existing R function to perform n-dimensional linear
interpolation, like MATLAB's interpn (
http://www.mathworks.com/help/matlab/ref/interpn.html; a Python version is
here: https://github.com/scipy/scipy/issues/2246#issuecomment-17028264)? My
searches didn't turn up anything.

Maybe not terribly difficult to implement, but I didn't want to reinvent
the wheel...


Thanks,
Steven Matz

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Thu Aug 21 19:59:40 2014
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 21 Aug 2014 13:59:40 -0400
Subject: [R] How to view the whole dataset that is imported through
	sasxport.get
In-Reply-To: <D7C70B22-A899-44F7-AA84-283959D925F8@comcast.net>
References: <CAMCXXmpBp5-ERURzW8_2ddt-MeoPcT4p9L6767LNOaUtCOx9gA@mail.gmail.com>
	<D7C70B22-A899-44F7-AA84-283959D925F8@comcast.net>
Message-ID: <CAMCXXmqQH4c4T4WzZ4jBencOb-xEzYUcCxgBQ3aY+yPF_k4pLQ@mail.gmail.com>

David,
Thanks for your reply.
Here is some of the output of str()

'data.frame':	1991 obs. of  5 variables:
 $ SID :Class 'labelled'  atomic [1:1991] 01018 01018 01018 01018 ...
  .. ..- attr(*, "label")= chr "Subject ID"
 $ DV  :Class 'labelled'  atomic [1:1991] NA 8.52 463 364 240 278 237
167 83.7 260 ...
  .. ..- attr(*, "label")= chr "Numeric Result in Standard Unit"
 $ VISI:Class 'labelled'  atomic [1:1991] 1 1 1 1 1 1 1 1 1 7 ...
  .. ..- attr(*, "label")= chr "Planned Study Day of Visit"
 $ NRT :Class 'labelled'  atomic [1:1991] 0 0.75 1.5 3 4 6 9 12 24 0 ...
  .. ..- attr(*, "label")= chr "Nominal Relative Time"
 $ TIME:Class 'labelled'  atomic [1:1991] -1.1 0.8 1.5 3 4 ...
  .. ..- attr(*, "label")= chr "Actual Relative Time"




On Thu, Aug 21, 2014 at 11:53 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Aug 21, 2014, at 7:20 AM, Jun Shen wrote:
>
> > Dear list,
> >
> > I used sasxport.get to import a SAS xpt file. Although it is a data frame
> > but i can't view it through the "fix" command. Also when I see its
> > structure, it brings up attributes I am not really interested in (which
> > seems part of the SAS labels) and it doesn't seem to tell me the mode of
> > each column. How do I suppress those attributes and view it through
> "fix"?
> > Thanks.
>
> It would have helped a lot if you had offered outout of: str(dataset)
>
> I don't use fix() so I'm not sure I help you there. I do notice in looking
> at the documentation that the function may return a list of dataframes
> rather than just a dataframe, so perhaps you need to extract the dataframe
> object. (Just a guess.)
>
>  I generally look at my files with names(), and Hmisc::describe() and use
> table() for the factor or character values that I expect to have manageable
> numbers of discrete categories. (Using `fix()` to edit gigabyte sized
> objects is the way to madness.) You should probably read the Posting Guide
> because you are failing to mention that the sasxport.get() function is part
> of the Hmisc package. If you want to get rid of your attributes (which is
> where the labels are stored)  then the attr() function should allow you to
> NULL them out:
>
> > x <- 1:10
> > attr(x,"dim") <- c(2, 5)
> >
> > x
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    1    3    5    7    9
> [2,]    2    4    6    8   10
> > attr(x,"dim")
> [1] 2 5
> > attr(x,"dim") <- NULL
> > x
>  [1]  1  2  3  4  5  6  7  8  9 10
>
> It also appears the there is a `label<-` function, so you could probably
> use that to NULL them out.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Thu Aug 21 20:43:37 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 21 Aug 2014 11:43:37 -0700
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
	<E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
	<CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
Message-ID: <7F2BCF0A-6D99-413F-9ABA-B9432AAEA1E2@u.washington.edu>

Ugh sorry.  I misread your message obviously. Cc?ing back to the list (as is the protocol)

I?m surprised no one else has replied. I?m a lightweight compared to others on the list.  It looks as if the dist() function has compiled code, 
which suggests that there is some gnarly linear algebra underneath to speed it up even in 2D. Not for the faint-of-heart to hack.

Others?  ?dist3D??

On Aug 21, 2014, at 11:34 AM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:

> This function unfortunately does not work in 3d space.
> 
> Thoughts?
> 
> 
> On Wed, Aug 20, 2014 at 4:57 PM, Don McKenzie <dmck at u.washington.edu> wrote:
> ?dist
> 
> from the help
> 
> dist {stats}    R Documentation
> Distance Matrix Computation
> 
> Description
> 
> This function computes and returns the distance matrix computed by using the specified distance measure to compute the distances between the rows of a data matrix.
> 
> Is this what you want?  Computing on a matrix whose rows are your x, y, and z values?
> 
> 
> On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:
> 
> > R Community -
> >
> > I am attempting to write a function that will calculate the distance
> > between points in 3 dimensional space for unique regions (e.g. localized
> > brain regions such as the frontal lobe).
> >
> > For example I'm looking to compare each point in region 45 to every other
> > region in 45 to establish if they are a distance of 8 or more apart. I can
> > do this linearly comparing each distance to the previous but this is not
> > comparing all points.
> >
> > structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
> > 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
> > 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
> > 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
> > 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
> > 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
> > 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
> > 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
> > 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
> > 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
> > 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
> > 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
> > 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
> > 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
> > )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
> > c(NA,
> > 20L), class = "data.frame")
> >
> > mainDat <- data.frame()
> > for(i in 2:nrow(dat)){
> > tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
> > (dat$z[i] - dat$z[i-1])^2))
> > dat$X[i] <- c(tempDist)
> > if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
> > if(tempDist > 8){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > }
> > }
> >
> >
> >
> >
> > --
> >
> > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> > University *
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
> 
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
> 
> 
> 
> 
> 
> 
> 
> -- 
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University 
> 
>  

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu





	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Thu Aug 21 21:35:50 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 21 Aug 2014 19:35:50 +0000
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <7F2BCF0A-6D99-413F-9ABA-B9432AAEA1E2@u.washington.edu>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
	<E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
	<CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
	<7F2BCF0A-6D99-413F-9ABA-B9432AAEA1E2@u.washington.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9200D@mb02.ads.tamu.edu>

The dist() function works just fine in 2d or 3d or 100d. Your description of what you want to accomplish is not clear. Your code compares rows 1 and 2, then 2 and 3, then 3 and 4, and so on. You are comparing only adjacent points, but your description makes it sound like you want to compare point 1 to all the other points and see if they are in the same group and over 8 or in another group. If you type the following command you will see that your dat$X is just the diagonal of the distance matrix: 1 with 2, 2 with 3, 3 with 4 etc:

dist(dat[, 3:5])

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Don McKenzie
Sent: Thursday, August 21, 2014 1:44 PM
To: Patzelt, Edward
Cc: R-help at r-project.org
Subject: Re: [R] Euclidean Distance in 3 Dimensions

Ugh sorry.  I misread your message obviously. Cc?ing back to the list (as is the protocol)

I?m surprised no one else has replied. I?m a lightweight compared to others on the list.  It looks as if the dist() function has compiled code,
which suggests that there is some gnarly linear algebra underneath to speed it up even in 2D. Not for the faint-of-heart to hack.

Others?  ?dist3D??

On Aug 21, 2014, at 11:34 AM, Patzelt, Edward <patzelt at g.harvard.edu<mailto:patzelt at g.harvard.edu>> wrote:

> This function unfortunately does not work in 3d space.
>
> Thoughts?
>
>
> On Wed, Aug 20, 2014 at 4:57 PM, Don McKenzie <dmck at u.washington.edu<mailto:dmck at u.washington.edu>> wrote:
> ?dist
>
> from the help
>
> dist {stats}    R Documentation
> Distance Matrix Computation
>
> Description
>
> This function computes and returns the distance matrix computed by using the specified distance measure to compute the distances between the rows of a data matrix.
>
> Is this what you want?  Computing on a matrix whose rows are your x, y, and z values?
>
>
> On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu<mailto:patzelt at g.harvard.edu>> wrote:
>
> > R Community -
> >
> > I am attempting to write a function that will calculate the distance
> > between points in 3 dimensional space for unique regions (e.g. localized
> > brain regions such as the frontal lobe).
> >
> > For example I'm looking to compare each point in region 45 to every other
> > region in 45 to establish if they are a distance of 8 or more apart. I can
> > do this linearly comparing each distance to the previous but this is not
> > comparing all points.
> >
> > structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
> > 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
> > 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
> > 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
> > 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
> > 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
> > 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
> > 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
> > 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
> > 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
> > 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
> > 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
> > 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
> > 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
> > )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
> > c(NA,
> > 20L), class = "data.frame")
> >
> > mainDat <- data.frame()
> > for(i in 2:nrow(dat)){
> > tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
> > (dat$z[i] - dat$z[i-1])^2))
> > dat$X[i] <- c(tempDist)
> > if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
> > if(tempDist > 8){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > }
> > }
> >
> >
> >
> >
> > --
> >
> > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> > University *
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu<mailto:dmck at uw.edu>
>
>
>
>
>
>
>
> --
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University
>
>

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu<mailto:dmck at uw.edu>





        [[alternative HTML version deleted]]
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Aug 21 21:39:41 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 21 Aug 2014 19:39:41 +0000
Subject: [R] How to view the whole dataset that is imported through
 sasxport.get
In-Reply-To: <CAMCXXmqQH4c4T4WzZ4jBencOb-xEzYUcCxgBQ3aY+yPF_k4pLQ@mail.gmail.com>
References: <CAMCXXmpBp5-ERURzW8_2ddt-MeoPcT4p9L6767LNOaUtCOx9gA@mail.gmail.com>
	<D7C70B22-A899-44F7-AA84-283959D925F8@comcast.net>
	<CAMCXXmqQH4c4T4WzZ4jBencOb-xEzYUcCxgBQ3aY+yPF_k4pLQ@mail.gmail.com>
Message-ID: <D01B980B.1080F2%macqueen1@llnl.gov>

So it?s now pretty clear that sasexport.get() gave each variable in the
data frame a class of ?labelled?. The fix() function likely does not know
what to do with that class. So you want to get rid of the labels, and
possibly other attributes.

I?s suggest you study the Hmisc help pages for information about labeling.
Perhaps there?s a function named ?label? or ?labelled?. The help page for
sasexport.get() probably has something as well.

Something similar to this (not tested) might do the job:

  for (ic in seq(nrow(mydata))) mydata[[ic]] <- unclass(mydata[[ic]])

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/21/14, 10:59 AM, "Jun Shen" <jun.shen.ut at gmail.com> wrote:

>David,
>Thanks for your reply.
>Here is some of the output of str()
>
>'data.frame':	1991 obs. of  5 variables:
> $ SID :Class 'labelled'  atomic [1:1991] 01018 01018 01018 01018 ...
>  .. ..- attr(*, "label")= chr "Subject ID"
> $ DV  :Class 'labelled'  atomic [1:1991] NA 8.52 463 364 240 278 237
>167 83.7 260 ...
>  .. ..- attr(*, "label")= chr "Numeric Result in Standard Unit"
> $ VISI:Class 'labelled'  atomic [1:1991] 1 1 1 1 1 1 1 1 1 7 ...
>  .. ..- attr(*, "label")= chr "Planned Study Day of Visit"
> $ NRT :Class 'labelled'  atomic [1:1991] 0 0.75 1.5 3 4 6 9 12 24 0 ...
>  .. ..- attr(*, "label")= chr "Nominal Relative Time"
> $ TIME:Class 'labelled'  atomic [1:1991] -1.1 0.8 1.5 3 4 ...
>  .. ..- attr(*, "label")= chr "Actual Relative Time"
>
>
>
>
>On Thu, Aug 21, 2014 at 11:53 AM, David Winsemius <dwinsemius at comcast.net>
>wrote:
>
>>
>> On Aug 21, 2014, at 7:20 AM, Jun Shen wrote:
>>
>> > Dear list,
>> >
>> > I used sasxport.get to import a SAS xpt file. Although it is a data
>>frame
>> > but i can't view it through the "fix" command. Also when I see its
>> > structure, it brings up attributes I am not really interested in
>>(which
>> > seems part of the SAS labels) and it doesn't seem to tell me the mode
>>of
>> > each column. How do I suppress those attributes and view it through
>> "fix"?
>> > Thanks.
>>
>> It would have helped a lot if you had offered outout of: str(dataset)
>>
>> I don't use fix() so I'm not sure I help you there. I do notice in
>>looking
>> at the documentation that the function may return a list of dataframes
>> rather than just a dataframe, so perhaps you need to extract the
>>dataframe
>> object. (Just a guess.)
>>
>>  I generally look at my files with names(), and Hmisc::describe() and
>>use
>> table() for the factor or character values that I expect to have
>>manageable
>> numbers of discrete categories. (Using `fix()` to edit gigabyte sized
>> objects is the way to madness.) You should probably read the Posting
>>Guide
>> because you are failing to mention that the sasxport.get() function is
>>part
>> of the Hmisc package. If you want to get rid of your attributes (which
>>is
>> where the labels are stored)  then the attr() function should allow you
>>to
>> NULL them out:
>>
>> > x <- 1:10
>> > attr(x,"dim") <- c(2, 5)
>> >
>> > x
>>      [,1] [,2] [,3] [,4] [,5]
>> [1,]    1    3    5    7    9
>> [2,]    2    4    6    8   10
>> > attr(x,"dim")
>> [1] 2 5
>> > attr(x,"dim") <- NULL
>> > x
>>  [1]  1  2  3  4  5  6  7  8  9 10
>>
>> It also appears the there is a `label<-` function, so you could probably
>> use that to NULL them out.
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From markleeds2 at gmail.com  Thu Aug 21 22:57:01 2014
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 21 Aug 2014 16:57:01 -0400
Subject: [R] hadley's book
Message-ID: <CAHz+bWYC9Gmz5ZUH1BOVejFG0DWT-TFD0EJHpMA=NfGLEtUxEQ@mail.gmail.com>

I have a feeling hadley's book will be quite popular so just a heads up
that it
can now be pre-ordered on amazon.

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Aug 21 23:04:12 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 21 Aug 2014 14:04:12 -0700
Subject: [R] How to view the whole dataset that is imported through
	sasxport.get
In-Reply-To: <CAMCXXmqQH4c4T4WzZ4jBencOb-xEzYUcCxgBQ3aY+yPF_k4pLQ@mail.gmail.com>
References: <CAMCXXmpBp5-ERURzW8_2ddt-MeoPcT4p9L6767LNOaUtCOx9gA@mail.gmail.com>
	<D7C70B22-A899-44F7-AA84-283959D925F8@comcast.net>
	<CAMCXXmqQH4c4T4WzZ4jBencOb-xEzYUcCxgBQ3aY+yPF_k4pLQ@mail.gmail.com>
Message-ID: <EAE01C17-1651-42E8-A374-7A5A7C53006D@comcast.net>


On Aug 21, 2014, at 10:59 AM, Jun Shen wrote:

> David,
> Thanks for your reply.
> Here is some of the output of str()
> 
> 'data.frame':	1991 obs. of  5 variables:
>  $ SID :Class 'labelled'  atomic [1:1991] 01018 01018 01018 01018 ...
>   .. ..- attr(*, "label")= chr "Subject ID"
>  $ DV  :Class 'labelled'  atomic [1:1991] NA 8.52 463 364 240 278 237 167 83.7 260 ...
>   .. ..- attr(*, "label")= chr "Numeric Result in Standard Unit"
>  $ VISI:Class 'labelled'  atomic [1:1991] 1 1 1 1 1 1 1 1 1 7 ...
>   .. ..- attr(*, "label")= chr "Planned Study Day of Visit"
>  $ NRT :Class 'labelled'  atomic [1:1991] 0 0.75 1.5 3 4 6 9 12 24 0 ...
>   .. ..- attr(*, "label")= chr "Nominal Relative Time"
>  $ TIME:Class 'labelled'  atomic [1:1991] -1.1 0.8 1.5 3 4 ...
>   .. ..- attr(*, "label")= chr "Actual Relative Time"
> 

If you don't want those to be "labelled"-class, then just:

dfrm2 <- data.frame( lapply(dfrm1, unclass) )

> 
> 
> On Thu, Aug 21, 2014 at 11:53 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Aug 21, 2014, at 7:20 AM, Jun Shen wrote:
> 
> > Dear list,
> >
> > I used sasxport.get to import a SAS xpt file. Although it is a data frame
> > but i can't view it through the "fix" command. Also when I see its
> > structure, it brings up attributes I am not really interested in (which
> > seems part of the SAS labels) and it doesn't seem to tell me the mode of
> > each column. How do I suppress those attributes and view it through "fix"?
> > Thanks.
> 
> It would have helped a lot if you had offered outout of: str(dataset)
> 
> I don't use fix() so I'm not sure I help you there. I do notice in looking at the documentation that the function may return a list of dataframes rather than just a dataframe, so perhaps you need to extract the dataframe object. (Just a guess.)
> 
>  I generally look at my files with names(), and Hmisc::describe() and use table() for the factor or character values that I expect to have manageable numbers of discrete categories. (Using `fix()` to edit gigabyte sized objects is the way to madness.) You should probably read the Posting Guide because you are failing to mention that the sasxport.get() function is part of the Hmisc package. If you want to get rid of your attributes (which is where the labels are stored)  then the attr() function should allow you to NULL them out:
> 
> > x <- 1:10
> > attr(x,"dim") <- c(2, 5)
> >
> > x
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    1    3    5    7    9
> [2,]    2    4    6    8   10
> > attr(x,"dim")
> [1] 2 5
> > attr(x,"dim") <- NULL
> > x
>  [1]  1  2  3  4  5  6  7  8  9 10
> 
> It also appears the there is a `label<-` function, so you could probably use that to NULL them out.
> 
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Thu Aug 21 23:08:55 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 21 Aug 2014 21:08:55 +0000
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <CAB9UfhRoXKxq1rVzj9GNA35DYL4itg3qpb1e=4px0YBg1h0r7g@mail.gmail.com>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
	<E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
	<CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
	<7F2BCF0A-6D99-413F-9ABA-B9432AAEA1E2@u.washington.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9200D@mb02.ads.tamu.edu>
	<CAB9UfhRoXKxq1rVzj9GNA35DYL4itg3qpb1e=4px0YBg1h0r7g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F92051@mb02.ads.tamu.edu>

So these two commands split the data frame by Cluster.Index and save them as a list, Clusters and then compute distance matrices on each group and save them as a list, Dists:

Clusters <- split(dta, dta$Cluster.Index)
Clusters
Dists <- lapply(Clusters, dist)
Dists

You should be able to process the matrices in each list to get what you want.

David C

From: Patzelt, Edward [mailto:patzelt at g.harvard.edu]
Sent: Thursday, August 21, 2014 2:58 PM
To: David L Carlson
Cc: Don McKenzie; R-help at r-project.org
Subject: Re: [R] Euclidean Distance in 3 Dimensions

Your first description is correct with slight modification "compare point 1 to all the other points in that Cluster.Index and see if any of euclidean distances are greater than 8; do this for each point (i.e. point 2, point 3) in that specific Cluster.Index (i.e. 45)"



On Thu, Aug 21, 2014 at 3:35 PM, David L Carlson <dcarlson at tamu.edu<mailto:dcarlson at tamu.edu>> wrote:
The dist() function works just fine in 2d or 3d or 100d. Your description of what you want to accomplish is not clear. Your code compares rows 1 and 2, then 2 and 3, then 3 and 4, and so on. You are comparing only adjacent points, but your description makes it sound like you want to compare point 1 to all the other points and see if they are in the same group and over 8 or in another group. If you type the following command you will see that your dat$X is just the diagonal of the distance matrix: 1 with 2, 2 with 3, 3 with 4 etc:

dist(dat[, 3:5])

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Don McKenzie
Sent: Thursday, August 21, 2014 1:44 PM
To: Patzelt, Edward
Cc: R-help at r-project.org<mailto:R-help at r-project.org>
Subject: Re: [R] Euclidean Distance in 3 Dimensions

Ugh sorry.  I misread your message obviously. Cc?ing back to the list (as is the protocol)

I?m surprised no one else has replied. I?m a lightweight compared to others on the list.  It looks as if the dist() function has compiled code,
which suggests that there is some gnarly linear algebra underneath to speed it up even in 2D. Not for the faint-of-heart to hack.

Others?  ?dist3D??

On Aug 21, 2014, at 11:34 AM, Patzelt, Edward <patzelt at g.harvard.edu<mailto:patzelt at g.harvard.edu>> wrote:

> This function unfortunately does not work in 3d space.
>
> Thoughts?
>
>
> On Wed, Aug 20, 2014 at 4:57 PM, Don McKenzie <dmck at u.washington.edu<mailto:dmck at u.washington.edu>> wrote:
> ?dist
>
> from the help
>
> dist {stats}    R Documentation
> Distance Matrix Computation
>
> Description
>
> This function computes and returns the distance matrix computed by using the specified distance measure to compute the distances between the rows of a data matrix.
>
> Is this what you want?  Computing on a matrix whose rows are your x, y, and z values?
>
>
> On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu<mailto:patzelt at g.harvard.edu>> wrote:
>
> > R Community -
> >
> > I am attempting to write a function that will calculate the distance
> > between points in 3 dimensional space for unique regions (e.g. localized
> > brain regions such as the frontal lobe).
> >
> > For example I'm looking to compare each point in region 45 to every other
> > region in 45 to establish if they are a distance of 8 or more apart. I can
> > do this linearly comparing each distance to the previous but this is not
> > comparing all points.
> >
> > structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
> > 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
> > 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
> > 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
> > 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
> > 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
> > 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
> > 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
> > 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
> > 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
> > 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
> > 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
> > 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
> > 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
> > )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
> > c(NA,
> > 20L), class = "data.frame")
> >
> > mainDat <- data.frame()
> > for(i in 2:nrow(dat)){
> > tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
> > (dat$z[i] - dat$z[i-1])^2))
> > dat$X[i] <- c(tempDist)
> > if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
> > if(tempDist > 8){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > }
> > }
> >
> >
> >
> >
> > --
> >
> > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> > University *
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu<mailto:dmck at uw.edu>
>
>
>
>
>
>
>
> --
> Edward H Patzelt | Clinical Science PhD Student
> Psychology | Harvard University
>
>

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu<mailto:dmck at uw.edu>





        [[alternative HTML version deleted]]
______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



--
Edward H Patzelt | Clinical Science PhD Student
Psychology | Harvard University



	[[alternative HTML version deleted]]


From gyanendra.pokharel at gmail.com  Fri Aug 22 00:15:53 2014
From: gyanendra.pokharel at gmail.com (Gyanendra Pokharel)
Date: Thu, 21 Aug 2014 18:15:53 -0400
Subject: [R] Help to install package "mlegp"
Message-ID: <CAK=huh7GGRBES9crog18ZX2OFvGZETqMuxAFbPb1WP26vVBiBw@mail.gmail.com>

Hi R users,

I have successfully downloaded the package "mlegp", but when I tried
installing it says the following massage.

package ?mlegp? successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package ?mlegp?

> library(mlegp)
Error in library(mlegp) : there is no package called ?mlegp?

Can some one suggest me whats going on?

Gyanendra Pokharel
University of Guelph
Guelph, ON

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Fri Aug 22 00:36:43 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 22 Aug 2014 00:36:43 +0200
Subject: [R] Help to install package "mlegp"
In-Reply-To: <CAK=huh7GGRBES9crog18ZX2OFvGZETqMuxAFbPb1WP26vVBiBw@mail.gmail.com>
References: <CAK=huh7GGRBES9crog18ZX2OFvGZETqMuxAFbPb1WP26vVBiBw@mail.gmail.com>
Message-ID: <53F6747B.8060300@statistik.tu-dortmund.de>



On 22.08.2014 00:15, Gyanendra Pokharel wrote:
> Hi R users,
>
> I have successfully downloaded the package "mlegp", but when I tried
> installing it says the following massage.
>
> package ?mlegp? successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package ?mlegp?
>
>> library(mlegp)
> Error in library(mlegp) : there is no package called ?mlegp?
>
> Can some one suggest me whats going on?

Start a fresh R session and reinstall without loading it in advance.

Best,
Uwe Ligges


>
> Gyanendra Pokharel
> University of Guelph
> Guelph, ON
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gyanendra.pokharel at gmail.com  Fri Aug 22 01:06:23 2014
From: gyanendra.pokharel at gmail.com (Gyanendra Pokharel)
Date: Thu, 21 Aug 2014 19:06:23 -0400
Subject: [R] Help to install package "mlegp"
In-Reply-To: <53F6747B.8060300@statistik.tu-dortmund.de>
References: <CAK=huh7GGRBES9crog18ZX2OFvGZETqMuxAFbPb1WP26vVBiBw@mail.gmail.com>
	<53F6747B.8060300@statistik.tu-dortmund.de>
Message-ID: <CAK=huh7ox3MmDWWo47+eOb=Ji0GDK=LzxPCDQkLQi6wCsGLvgA@mail.gmail.com>

Thanks Uwe! I re-install R and re-install  the package "mlegp" and I
successfully installed it.
Thanks again !

Gyan

Gyanendra Pokharel
University of Guelph
Guelph, ON


On Thu, Aug 21, 2014 at 6:36 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

>
>
> On 22.08.2014 00:15, Gyanendra Pokharel wrote:
>
>> Hi R users,
>>
>> I have successfully downloaded the package "mlegp", but when I tried
>> installing it says the following massage.
>>
>> package ?mlegp? successfully unpacked and MD5 sums checked
>> Warning: cannot remove prior installation of package ?mlegp?
>>
>>  library(mlegp)
>>>
>> Error in library(mlegp) : there is no package called ?mlegp?
>>
>> Can some one suggest me whats going on?
>>
>
> Start a fresh R session and reinstall without loading it in advance.
>
> Best,
> Uwe Ligges
>
>
>
>> Gyanendra Pokharel
>> University of Guelph
>> Guelph, ON
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Aug 22 05:30:03 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 22 Aug 2014 11:30:03 +0800
Subject: [R] hadley's book
In-Reply-To: <CAHz+bWYC9Gmz5ZUH1BOVejFG0DWT-TFD0EJHpMA=NfGLEtUxEQ@mail.gmail.com>
References: <CAHz+bWYC9Gmz5ZUH1BOVejFG0DWT-TFD0EJHpMA=NfGLEtUxEQ@mail.gmail.com>
Message-ID: <48f4e43e.1333c.147fbc39176.Coremail.rhelpmaillist@163.com>





Haha, i have already read the advanced r programming part of the book. As you said, it will be quite popular in future years. 

--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2014-08-22 04:57:01, "Mark Leeds" <markleeds2 at gmail.com> wrote:
>I have a feeling hadley's book will be quite popular so just a heads up
>that it
>can now be pre-ordered on amazon.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From andrewcd at gmail.com  Fri Aug 22 07:13:43 2014
From: andrewcd at gmail.com (Andrew Crane-Droesch)
Date: Fri, 22 Aug 2014 08:13:43 +0300
Subject: [R] bam (mgcv) not using the specified number of cores
In-Reply-To: <53F5F436.70704@bath.ac.uk>
References: <53F5DDD6.8000006@gmail.com> <53F5F436.70704@bath.ac.uk>
Message-ID: <53F6D187.1030401@gmail.com>

Hi Simon,

(resending with all images as imgur so as to not bounce from list)

Thanks for the reply.  I've tried to reproduce the error, but I don't 
know how to show output from `top` any other way than with screenshots, 
so please excuse that.

Here are screenshots of what happens when I run with two
http://imgur.com/i26GKPo

and three
http://imgur.com/8SL7scy

cores.  In the former, it seems to be working on one core, and in the 
latter, it appears to be working on three.  When reproducing the error, 
I'm getting behavior that isn't entirely consistent -- sometimes it 
"behaves" and operates on the asked-for number of cores, and other times 
not.

I'm also attaching a screenshot
http://imgur.com/bJfuS6R
showing terminal output from a remote cluster when I run my full model 
(N=67K) rather than a subset (N=7K) -- I get that error "Error in 
qr.qty(qrx, f) : right-hand side should have 60650 not 118451 rows ..."  
I suppose this is a memory overload problem?  Any suggestions on how to 
get bam to not call for more memory than the node has available would be 
welcome, though I suspect that is a supercomputing problem rather than a 
mgcv problem.  I don't know much about memory management, except that R 
doesn't do it explicitly.

Thanks,
Andrew

sessionInfo() for local machine:
1> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] parallel  stats     graphics  grDevices utils datasets  methods
[8] base

other attached packages:
[1] mgcv_1.7-26  nlme_3.1-111

loaded via a namespace (and not attached):
[1] grid_3.0.2      lattice_0.20-23 Matrix_1.1-4
1>
On 08/21/2014 04:29 PM, Simon Wood wrote:
> Hi Andrew,
>
> Could you provide a bit more information, please. In particular the 
> results of sessionInfo() and the code that caused this weird behaviour 
> (+ an indication of dataset size).
>
> best,
> Simon
>
> On 21/08/14 12:53, Andrew Crane-Droesch wrote:
>> I am getting strange behavior when trying to fit models to large
>> datasets using bam.  I am working on a 4-core machine, but I think that
>> there may be 2 physical cores that the computer uses as 4 cores in some
>> sense that I don't understand.
>>
>> When I run the bam using makeCluster(3), the model runs on one core. But
>> when I run it on makeCluster(2), top shoes me that three of my cores are
>> taken up to full capacity, and my computer slows down or crashes.
>>
>> How can I get it to truly run on 2 cores?
>>
>> I'm on a thinkpad X230, running ubuntu.
>>
>> Thanks,
>> Andrew
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From patzelt at g.harvard.edu  Thu Aug 21 20:34:09 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Thu, 21 Aug 2014 14:34:09 -0400
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
	<E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
Message-ID: <CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>

This function unfortunately does not work in 3d space.

Thoughts?


On Wed, Aug 20, 2014 at 4:57 PM, Don McKenzie <dmck at u.washington.edu> wrote:

> ?dist
>
> from the help
>
> dist {stats}    R Documentation
> Distance Matrix Computation
>
> Description
>
> This function computes and returns the distance matrix computed by using
> the specified distance measure to compute the distances between the rows of
> a data matrix.
>
> Is this what you want?  Computing on a matrix whose rows are your x, y,
> and z values?
>
>
> On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu>
> wrote:
>
> > R Community -
> >
> > I am attempting to write a function that will calculate the distance
> > between points in 3 dimensional space for unique regions (e.g. localized
> > brain regions such as the frontal lobe).
> >
> > For example I'm looking to compare each point in region 45 to every other
> > region in 45 to establish if they are a distance of 8 or more apart. I
> can
> > do this linearly comparing each distance to the previous but this is not
> > comparing all points.
> >
> > structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
> > 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
> > 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
> > 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
> > 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
> > 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
> > 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
> > 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
> > 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
> > 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
> > 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
> > 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
> > 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
> > 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
> > )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
> > c(NA,
> > 20L), class = "data.frame")
> >
> > mainDat <- data.frame()
> > for(i in 2:nrow(dat)){
> > tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
> > (dat$z[i] - dat$z[i-1])^2))
> > dat$X[i] <- c(tempDist)
> > if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
> > if(tempDist > 8){
> > mainDat <- rbind(mainDat, dat[i,])
> > }
> > }
> > }
> >
> >
> >
> >
> > --
> >
> > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> > University *
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
>
>
>
>
>


-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University *

	[[alternative HTML version deleted]]


From patzelt at g.harvard.edu  Thu Aug 21 21:58:05 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Thu, 21 Aug 2014 15:58:05 -0400
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9200D@mb02.ads.tamu.edu>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
	<E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
	<CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
	<7F2BCF0A-6D99-413F-9ABA-B9432AAEA1E2@u.washington.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9200D@mb02.ads.tamu.edu>
Message-ID: <CAB9UfhRoXKxq1rVzj9GNA35DYL4itg3qpb1e=4px0YBg1h0r7g@mail.gmail.com>

Your first description is correct with slight modification "compare point 1
to all the other points in that Cluster.Index and see if any of euclidean
distances are greater than 8; do this for each point (i.e. point 2, point
3) in that specific Cluster.Index (i.e. 45)"




On Thu, Aug 21, 2014 at 3:35 PM, David L Carlson <dcarlson at tamu.edu> wrote:

>  The dist() function works just fine in 2d or 3d or 100d. Your
> description of what you want to accomplish is not clear. Your code compares
> rows 1 and 2, then 2 and 3, then 3 and 4, and so on. You are comparing only
> adjacent points, but your description makes it sound like you want to
> compare point 1 to all the other points and see if they are in the same
> group and over 8 or in another group. If you type the following command you
> will see that your dat$X is just the diagonal of the distance matrix: 1
> with 2, 2 with 3, 3 with 4 etc:
>
>
>
> dist(dat[, 3:5])
>
>
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> *From:* r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> *On Behalf Of *Don McKenzie
> *Sent:* Thursday, August 21, 2014 1:44 PM
> *To:* Patzelt, Edward
> *Cc:* R-help at r-project.org
> *Subject:* Re: [R] Euclidean Distance in 3 Dimensions
>
>
>
> Ugh sorry.  I misread your message obviously. Cc?ing back to the list (as
> is the protocol)
>
> I?m surprised no one else has replied. I?m a lightweight compared to
> others on the list.  It looks as if the dist() function has compiled code,
> which suggests that there is some gnarly linear algebra underneath to
> speed it up even in 2D. Not for the faint-of-heart to hack.
>
> Others?  ?dist3D??
>
> On Aug 21, 2014, at 11:34 AM, Patzelt, Edward <patzelt at g.harvard.edu>
> wrote:
>
> > This function unfortunately does not work in 3d space.
> >
> > Thoughts?
> >
> >
> > On Wed, Aug 20, 2014 at 4:57 PM, Don McKenzie <dmck at u.washington.edu>
> wrote:
> > ?dist
> >
> > from the help
> >
> > dist {stats}    R Documentation
> > Distance Matrix Computation
> >
> > Description
> >
> > This function computes and returns the distance matrix computed by using
> the specified distance measure to compute the distances between the rows of
> a data matrix.
> >
> > Is this what you want?  Computing on a matrix whose rows are your x, y,
> and z values?
> >
> >
> > On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu>
> wrote:
> >
> > > R Community -
> > >
> > > I am attempting to write a function that will calculate the distance
> > > between points in 3 dimensional space for unique regions (e.g.
> localized
> > > brain regions such as the frontal lobe).
> > >
> > > For example I'm looking to compare each point in region 45 to every
> other
> > > region in 45 to establish if they are a distance of 8 or more apart. I
> can
> > > do this linearly comparing each distance to the previous but this is
> not
> > > comparing all points.
> > >
> > > structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
> > > 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
> > > 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
> > > 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
> > > 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
> > > 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
> > > 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
> > > 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
> > > 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
> > > 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838,
> 2.44948974278318,
> > > 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
> > > 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
> > > 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
> > > 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
> > > )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"),
> row.names =
> > > c(NA,
> > > 20L), class = "data.frame")
> > >
> > > mainDat <- data.frame()
> > > for(i in 2:nrow(dat)){
> > > tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] -
> dat$y[i-1])^2 +
> > > (dat$z[i] - dat$z[i-1])^2))
> > > dat$X[i] <- c(tempDist)
> > > if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
> > > mainDat <- rbind(mainDat, dat[i,])
> > > }
> > > if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
> > > if(tempDist > 8){
> > > mainDat <- rbind(mainDat, dat[i,])
> > > }
> > > }
> > > }
> > >
> > >
> > >
> > >
> > > --
> > >
> > > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> > > University *
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > Don McKenzie
> > Research Ecologist
> > Pacific Wildland Fire Sciences Lab
> > US Forest Service
> >
> > Affiliate Professor
> > School of Environmental and Forest Sciences
> > University of Washington
> > dmck at uw.edu
> >
> >
> >
> >
> >
> >
> >
> > --
> > Edward H Patzelt | Clinical Science PhD Student
> > Psychology | Harvard University
> >
> >
>
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
>
> Affiliate Professor
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University *

	[[alternative HTML version deleted]]


From Angela.Boag at colorado.edu  Thu Aug 21 23:45:38 2014
From: Angela.Boag at colorado.edu (Angela Boag)
Date: Thu, 21 Aug 2014 15:45:38 -0600
Subject: [R] Subsetting data for split-sample validation,
	then repeating 1000x
Message-ID: <CAHaDdYFhLSyfcd2rLYKz4msXJC8gf1xx4+2SVQVtf4CM-Q1_mw@mail.gmail.com>

Hi all,

I'm doing some within-dataset model validation and would like to subset a
dataset 70/30 and fit a model to 70% of the data (the training data), then
validate it by predicting the remaining 30% (the testing data), and I would
like to do this split-sample validation 1000 times and average the
correlation coefficient and r2 between the training and testing data.

I have the following working for a single iteration, and would like to know
how to use either the replicate() or for-loop functions to average the 1000
'r2' and 'cor' outputs.

--

# create 70% training sample
A.samp <- sample(1:nrow(A),floor(0.7*nrow(A)), replace = TRUE)

# Fit model (I'm modeling native plant richness, 'nat.r')
A.model <- glmmadmb(nat.r ~ isl.sz + nr.mead, random = ~ 1 | site, family =
"poisson", data = A[A.samp,])

# Use the model to predict the remaining 30% of the data
A.pred <- predict(A.model, newdata = A[-A.samp,], type = "response")

# Correlation between predicted 30% and actual 30%
cor <- cor(A[-A.samp,]$nat.r, A.pred, method = "pearson")

# r2 between predicted and observed
lm.A <- lm(A.pred ~ A[-A.samp,]$nat.r)
r2 <- summary(lm.A)$r.squared

# print values
r2
cor

--

Thanks for your time!

Cheers,
Angela

--
Angela E. Boag
Ph.D. Student, Environmental Studies
CAFOR Project Researcher
University of Colorado, Boulder
Mobile: 720-212-6505

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Fri Aug 22 10:02:35 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Aug 2014 10:02:35 +0200
Subject: [R] loading saved files with objects in same names
In-Reply-To: <CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
References: <53F29AAC.8000009@yeah.net>
	<CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
Message-ID: <21494.63771.286716.385765@stat.math.ethz.ch>


> Have you tried the 'envir' argument to load()?  E.g.,
>    envA <- new.environment()
>    load("A.RData", envir=envA)
>    envB <- new.environment()
>    load("B.RData", envir=envB)
>    plot(A$object, B$object)

> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com

An alternative that I have been advocating is using

  attach("A.RData")

etc. It does something similar as the above, but more
conveniently:
It loads the objects into a new environment  *and* attaches that
environment to your search()  path, so you can access them
directly, but attach() will never accidentally destroy existing
R objects in your global environment ( = search()[[1]] ).

Martin





> On Mon, Aug 18, 2014 at 5:30 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
> each file, there are some objects with same names but different contents.
> Now, I need to compare those objects through plotting. However, I can't find
> a way to load them into a workspace. The only thing I can do is to rename
> them and then save and load again.
>
> Is there a convenient to load those objects?
>
> Thanks a lot in advance.
>
> Best regards,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From J.Cameron at hermes.co.uk  Fri Aug 22 09:36:37 2014
From: J.Cameron at hermes.co.uk (Jon-Paul Cameron)
Date: Fri, 22 Aug 2014 08:36:37 +0100
Subject: [R] Help on installing "R" packages in a Citrix
Message-ID: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>

Hi



We are currently trying to migrate 3 users of "R" to a citrix based environment, but are coming across major issues trying to install the packages to the relevant image. Can someone please contact me around how the install should be done - as we can find no supporting documentation or help on this matter.



I already sent this request to "R-packages" for help, but was told this was the correct Forum for info of this type.



Many thanks



Jon-Paul Cameron

Systems Support Manager




Jon-Paul Cameron
Systems Support Manager


Direct tel: + 44  (0)20  7680 8046
Email: J.Cameron at hermes.co.uk<mailto:J.Cameron at hermes.co.uk>

Hermes Fund Managers
1 Portsoken Street
London, E1 8HZ
Switchboard: +44 (0)20 7702 0888

www.hermesfundmanagers.com<http://www.hermesfundmanagers.com/>





**********************************************************************
Hermes Fund Managers Limited
Registered in England No. 1661776, 1 Portsoken Street, London E1 8HZ

***Please read the Hermes email disclaimer at http://www.hermes.co.uk/email_terms.htm before acting on this email or opening any attachment***
The contents of this email are confidential.  If you hav...{{dropped:20}}


From dwinsemius at comcast.net  Fri Aug 22 10:29:14 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Aug 2014 01:29:14 -0700
Subject: [R] Help on installing "R" packages in a Citrix
In-Reply-To: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
References: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
Message-ID: <52BC2569-96F8-4BAB-884A-AC2343DC9948@comcast.net>


On Aug 22, 2014, at 12:36 AM, Jon-Paul Cameron wrote:

> Hi
> 
> We are currently trying to migrate 3 users of "R" to a citrix based environment,

Windows?, Linux? "Citrix" isn't usually thought of as an OS is it?


> but are coming across major issues trying to install the packages to the relevant image. Can someone please contact me around how the install should be done - as we can find no supporting documentation or help on this matter.

http://cran.us.r-project.org/manuals.html

> 
> I already sent this request to "R-packages" for help, but was told this was the correct Forum for info of this type.

Have you installed R? Which OS? Which version?

-- 
David Winsemius
Alameda, CA, USA


From maechler at stat.math.ethz.ch  Fri Aug 22 11:40:15 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Aug 2014 11:40:15 +0200
Subject: [R] "no visible binding for global variable" and with()
	vs.	within()
In-Reply-To: <53F114E8.9090108@auckland.ac.nz>
References: <CAJb81Sns6GODzXpoHyRdAFwg8JiDWkX9TSAdDmPMmjp1RWhWUw@mail.gmail.com>
	<53F08C90.70902@gmail.com> <53F114E8.9090108@auckland.ac.nz>
Message-ID: <21495.4095.461950.270410@stat.math.ethz.ch>

>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>     on Mon, 18 Aug 2014 08:47:36 +1200 writes:

    > On 17/08/14 23:05, Duncan Murdoch wrote:
    >> On 16/08/2014, 9:36 PM, Daniel Braithwaite wrote:
    >>> R CMD check does not object to this code when checking a
    >>> package:
    >>> 
    >>> foo1 <- function (bar) { with(bar, { x }) }
    >>> 
    >>> but produces a warning:
    >>> 
    >>> foo2: no visible binding for global variable 'x'
    >>> 
    >>> in response to this:
    >>> 
    >>> foo2 <- function (bar) { within(bar, { x }) }
    >>> 
    >>> Is this an R bug, or at least, an inadvertent
    >>> inconsistency?  Here is sessionInfo() from my machine,
    >>> right after starting an interactive session:
    >> 
    >> I'm not sure, but I suspect it's an intentional
    >> inconsistency.  The code that checks for use of globals
    >> can't do anything in with() or within() code, so bugs can
    >> slip by if you use those.  I think with() had been around
    >> for a long time and was in wide use when that test was
    >> added, but within() is newer, and it was less disruptive
    >> to warn about it, so the warning has been left in.  (I
    >> don't remember whether the test came before or after
    >> within() was introduced.)
    >> 
    >> So if you want to avoid the warning, don't use within().

    > Or you could have a file, say "melvin.R", in the R
    > directory of your package, containing the line:

    >   utils::globalVariables("x")

Yes,  but that would be a quite bad idea, IMHO:

The checking code {from package 'codetools' BTW}
would no longer warn you about any accidental global 'x'
variable in any of your functions in your package.

After all, these codetools checks *are* very helpful in
detecting typos and thinkos.
Consequently, I'd strongly advise to only use
globalVariables(.) on *rare* variable names.

Martin Maechler, 
ETH Zurich


From maechler at stat.math.ethz.ch  Fri Aug 22 11:46:52 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Fri, 22 Aug 2014 11:46:52 +0200
Subject: [R] loading saved files with objects in same names
In-Reply-To: <53F49EA4.9060607@gmail.com>
References: <86077b1e665c4dc283a17c7e6098c766@EX-0-HT0.lancs.local>
	<CANVKczMem0BchZ66zN8FeUtN7-e_qiKPX785QjH9jo6Y=nWtww@mail.gmail.com>
	<53F49EA4.9060607@gmail.com>
Message-ID: <21495.4492.159211.265972@stat.math.ethz.ch>

> On 20/08/2014, 8:58 AM, Barry Rowlingson wrote:
> > On Tue, Aug 19, 2014 at 1:30 AM, Jinsong Zhao <jszhao at yeah.net> wrote:
> >> Hi there,
> >>
> >> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
> >> each file, there are some objects with same names but different
> >> contents. Now, I need to compare those objects through plotting.
> >> However, I can't find a way to load them into a workspace. The only
> >> thing I can do is to rename them and then save and load again.
> >>
> >> Is there a convenient to load those objects?
> >>
> >> Thanks a lot in advance.
> > 
> > The technique of loading into an environment already mentioned can be
> > cleaned up and put into a function.
> > 
> > First lets save a thing called "x" into two files with different values:
> > 
> >  > x="first"
> >  > save(x,file="f.RData"))
> >  > x="second"
> >  > save(x,file="s.RData")
> > 
> > This little function wraps the loading:
> > 
> >  > getFrom=function(file, name){e=new.env();load(file,env=e);e[[name]]}
> > 
> > So now I can get 'x' from the first file - the value is returned from
> > `getFrom` so I can assign it to anything:
> > 
> >  > x1 =  getFrom("f.RData","x")
> >  > x1
> > [1] "first"
> >  > x2 = getFrom("s.RData","x")
> >  > x2
> > [1] "second"
> > 
> > And I can even loop over RData files and read in all the `x`s into a vector:
> > 
> >  > sapply(c("f.RData","s.RData"),function(f){getFrom(f,"x")})
> >   f.RData  s.RData
> >   "first" "second"
> > 
> > (on second thoughts, possibly 'loadFrom' is a better name)

> That's a nice little function.  You could also have lsFrom, that lists
> the objects stored in the file, along the same lines:

> lsFrom <- function(file, all.names = FALSE, pattern) {
>   e <- new.env()
>   load(file, envir = e)
>   ls(e, all.names = all.names, pattern = pattern)
> }

> Duncan Murdoch

Note that the solution of simply using 

     attach("f.RData")

makes the use of  ls()  very natural, 
and for Rstudio and similar gui users, even automatically part of
their GUI.

Martin Maechler


From kasterma at kasterma.net  Fri Aug 22 12:02:53 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Fri, 22 Aug 2014 12:02:53 +0200
Subject: [R] knitr and stopifnot replacement.
Message-ID: <C1E5430B-F134-42E9-8D6D-1FB4FFCBF5CE@kasterma.net>

I have a daily generated report in which I put a check using stopifnot.  Unfortunately
I didn?t check the effect very well, turns out that if the condition checked fails
this is not shown in the knitr output (I only get an error much later due to a missing
object).

So my question is, what is the correct way to use assertions in a <filename>.Rnw
file.  I want to perform a check, and if it fails everything should stop with a message
I can generate.

Thanks,

Best,
Bart

From murdoch.duncan at gmail.com  Fri Aug 22 12:39:55 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 22 Aug 2014 06:39:55 -0400
Subject: [R] knitr and stopifnot replacement.
In-Reply-To: <C1E5430B-F134-42E9-8D6D-1FB4FFCBF5CE@kasterma.net>
References: <C1E5430B-F134-42E9-8D6D-1FB4FFCBF5CE@kasterma.net>
Message-ID: <53F71DFB.60909@gmail.com>

On 22/08/2014, 6:02 AM, Bart Kastermans wrote:
> I have a daily generated report in which I put a check using stopifnot.  Unfortunately
> I didn?t check the effect very well, turns out that if the condition checked fails
> this is not shown in the knitr output (I only get an error much later due to a missing
> object).
> 
> So my question is, what is the correct way to use assertions in a <filename>.Rnw
> file.  I want to perform a check, and if it fails everything should stop with a message
> I can generate.
> 

One of the differences between knitr and Sweave is that knitr handles
errors, and Sweave doesn't.  I expect there's some knitr option to tell
it to quit in case of error (a hook?), but you'll have to check the
documentation to find it.

Duncan Murdoch


From kasterma at kasterma.net  Fri Aug 22 13:35:41 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Fri, 22 Aug 2014 13:35:41 +0200
Subject: [R] knitr and stopifnot replacement.
In-Reply-To: <53F71DFB.60909@gmail.com>
References: <C1E5430B-F134-42E9-8D6D-1FB4FFCBF5CE@kasterma.net>
	<53F71DFB.60909@gmail.com>
Message-ID: <856018ED-E530-44EC-A1D2-75DBC51975EA@kasterma.net>

On 22 Aug 2014, at 12:39, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 22/08/2014, 6:02 AM, Bart Kastermans wrote:
>> I have a daily generated report in which I put a check using stopifnot.  Unfortunately
>> I didn?t check the effect very well, turns out that if the condition checked fails
>> this is not shown in the knitr output (I only get an error much later due to a missing
>> object).
>> 
>> So my question is, what is the correct way to use assertions in a <filename>.Rnw
>> file.  I want to perform a check, and if it fails everything should stop with a message
>> I can generate.
>> 
> 
> One of the differences between knitr and Sweave is that knitr handles
> errors, and Sweave doesn't.  I expect there's some knitr option to tell
> it to quit in case of error (a hook?), but you'll have to check the
> documentation to find it.

Thanks; that helped me to find the exact right option:

<<filelist, error=FALSE>>=
# check all files exist before continuing
stopifnot(all(sapply(files, file.exists)))
@


> 
> Duncan Murdoch
> 


From S.Ellison at LGCGroup.com  Fri Aug 22 14:03:07 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 22 Aug 2014 13:03:07 +0100
Subject: [R] Help on installing "R" packages in a Citrix
In-Reply-To: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
References: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED63AE8D9081@GOLD.corp.lgc-group.com>

> We are currently trying to migrate 3 users of "R" to a citrix based
> environment, but are coming across major issues trying to install the
> packages to the relevant image. 

Why can't you open a virtualised OS instance, install and start R in the normal way, install the packages normally in R using install.packages and then save the image for re-use?

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From arnaud.gaboury at gmail.com  Fri Aug 22 14:15:03 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Fri, 22 Aug 2014 14:15:03 +0200
Subject: [R] Help on installing "R" packages in a Citrix
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED63AE8D9081@GOLD.corp.lgc-group.com>
References: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
	<A4E5A0B016B8CB41A485FC629B633CED63AE8D9081@GOLD.corp.lgc-group.com>
Message-ID: <CAK1hC9vtD0H2PA1TL_LVVro6a5HP8n7aMcvfsUH2v+E8xfOwOA@mail.gmail.com>

On Fri, Aug 22, 2014 at 2:03 PM, S Ellison <S.Ellison at lgcgroup.com> wrote:
>> We are currently trying to migrate 3 users of "R" to a citrix based
>> environment, but are coming across major issues trying to install the
>> packages to the relevant image.
>

Please be more precised in your issue.


From A.Mcculloch at leedsmet.ac.uk  Fri Aug 22 13:51:16 2014
From: A.Mcculloch at leedsmet.ac.uk (McCulloch, Andrew)
Date: Fri, 22 Aug 2014 11:51:16 +0000
Subject: [R] Help with analysis of variance
Message-ID: <DD6C802B693C6F43BE52C7F34E7812DF6B2E43@EXC-MBX02.leedsmet.ac.uk>

Hi,



I have an observational dataset which consists of eight annual observations (year) for children (id) recording the rate of unemployment in the neighbourhood in which they lived (rate). I know if children move home so the data also has an identifier for spells in the same neighbourhood (spell). I want to decompose the overall variation in children's experience of area unemployment, given by the sum of (rate - mean rate)^2, into a) the component within a residential spell, sum of (rate - spell mean of rate)^2, b) the component between spells, sum of (spell mean), and c) the component between children, sum of (rate - mean rate for child). I think I can do this longhand using the calculations below:



mobility <- structure(list(year = c(2002L, 2003L, 2004L, 2005L, 2006L, 2007L,2008L, 2002L, 2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2002L,

2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2002L, 2003L, 2004L,

2005L, 2006L, 2007L, 2008L, 2002L, 2003L, 2004L, 2005L, 2006L,

2007L, 2008L), rate = c(13.08962, 14.27165, 4.496403, 3.89839,

4.60199, 5.138746, 5.251025, 4.874652, 5.880996, 5.813953, 6.204044,

6.93802, 6.866853, 7.614808, 4.405841, 4.826733, 4.760742, 3.762136,

4.60199, 5.138746, 5.251025, 4.405841, 4.826733, 4.760742, 3.762136,

4.60199, 5.138746, 5.251025, 4.405841, 5.789474, 5.889423, 4.61211,

4.642526, 6.838906, 9.683488), spell = c(1L, 2L, 2L, 3L, 3L,

3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L), id = c(1L,

1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,

3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,

5L, 5L)), .Names = c("year", "rate", "spell", "id"), row.names = c(NA,

-35L), class = "data.frame")



mobility$id <- factor(mobility$id)

mobility$spell <- factor(mobility$spell)



mobility$spellmean <- ave(mobility$rate,mobility$id,mobility$spell,FUN=mean)

mobility$personmean <- ave(mobility$rate,mobility$id,FUN=mean)

mobility$totalmean <- mean(mobility$rate,na.rm=TRUE)

N <- dim(mobility)[1]

# observation deviation from overall mean

sum(((mobility$rate-mobility$totalmean)^2)/N)

5.159846

# observation deviation from spell mean

sum(((mobility$rate-mobility$spellmean)^2)/N)

2.039461

# deviation of spell mean from person mean

sum(((mobility$spellmean-mobility$personmean)^2)/N)

2.13787

# deviation of person mean from overall mean

sum(((mobility$personmean-mobility$totalmean)^2)/N)

0.982515



I think this is correct because the sum of the three components of variation sums to the total:

2.039461+2.13787+0.982515 = 5.159846



Can someone show me how to use the analysis of variance functions in R to get the same result. Thanks.

Andrew McCulloch
Leeds Metropolitan University






>From 22 September 2014 Leeds Metropolitan University will become Leeds Beckett University.
Find out more at http://www.leedsbeckett.ac.uk
To view the terms under which this email is distributed, please go to:-
http://www.leedsmet.ac.uk/email-disclaimer.htm

	[[alternative HTML version deleted]]


From zwei0428 at hotmail.com  Fri Aug 22 14:18:04 2014
From: zwei0428 at hotmail.com (James Wei)
Date: Fri, 22 Aug 2014 12:18:04 +0000
Subject: [R] print vectors with consecutive numbers
Message-ID: <BAY176-W344E0B16685F17D2A3E912C0D00@phx.gbl>



Hi all,

I have a matrix with consecutive and non-consecutive numbers
in columns. For example, the first 2 columns have consecutive numbers. I want R
to print only columns with consecutive numbers. Here is the matrix and how I
did using conditional statement: 

##

mat=matrix(data=c(9,2,3,4,5,6,10,13,15,17,19,22,
25,27,29,31,34,37,39,41),ncol=5)

mat

difference = diff(mat)==1

difference

y1=difference[1,]

y2=difference[2,]

y3=difference[3,]

y=(y1|y2|y3)

y

 

if (y=="TRUE") mat else 0

## 

However, R still print all 5 columns, not the first 2
columns I wanted. I got the Warning message:

In if (y == "TRUE") mat else 0 :

  the condition has
length > 1 and only the first element will be used 

How can I change the code to get only the first 2 columns
with consecutive numbers printed? I am new to R.  

Thanks in advance for your help. James  

 		 	   		  
	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Fri Aug 22 14:28:40 2014
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Fri, 22 Aug 2014 22:28:40 +1000
Subject: [R] print vectors with consecutive numbers
In-Reply-To: <BAY176-W344E0B16685F17D2A3E912C0D00@phx.gbl>
References: <BAY176-W344E0B16685F17D2A3E912C0D00@phx.gbl>
Message-ID: <CAKL8G3EctHzXXTtvtVQk2TZKh_dvK+yLiGmrSgJL4CiXaCCp2Q@mail.gmail.com>

Hi James,

Try

mat[, apply(mat, 2, function(x) any(diff(x) == 1))]

HTH,
Jorge.-



On Fri, Aug 22, 2014 at 10:18 PM, James Wei <zwei0428 at hotmail.com> wrote:

>
>
> Hi all,
>
> I have a matrix with consecutive and non-consecutive numbers
> in columns. For example, the first 2 columns have consecutive numbers. I
> want R
> to print only columns with consecutive numbers. Here is the matrix and how
> I
> did using conditional statement:
>
> ##
>
> mat=matrix(data=c(9,2,3,4,5,6,10,13,15,17,19,22,
> 25,27,29,31,34,37,39,41),ncol=5)
>
> mat
>
> difference = diff(mat)==1
>
> difference
>
> y1=difference[1,]
>
> y2=difference[2,]
>
> y3=difference[3,]
>
> y=(y1|y2|y3)
>
> y
>
>
>
> if (y=="TRUE") mat else 0
>
> ##
>
> However, R still print all 5 columns, not the first 2
> columns I wanted. I got the Warning message:
>
> In if (y == "TRUE") mat else 0 :
>
>   the condition has
> length > 1 and only the first element will be used
>
> How can I change the code to get only the first 2 columns
> with consecutive numbers printed? I am new to R.
>
> Thanks in advance for your help. James
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh at temple.edu  Fri Aug 22 17:35:25 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 22 Aug 2014 11:35:25 -0400
Subject: [R] Help with analysis of variance
In-Reply-To: <DD6C802B693C6F43BE52C7F34E7812DF6B2E43@EXC-MBX02.leedsmet.ac.uk>
References: <DD6C802B693C6F43BE52C7F34E7812DF6B2E43@EXC-MBX02.leedsmet.ac.uk>
Message-ID: <CAGx1TMBwrn3kDFL37Cu6W8BZUwE9B3+atgfW3ndc5SYoQP6J7Q@mail.gmail.com>

Andrew,

I plotted your data first.  Then I made id, spell, year into factors
and did the ANOVA.
>From the graph, it looks like the two ids who had more than one spell
show variability in rate.
The ANOVA table agrees by showing high significance for the id:spell
interaction.
The numbers in this ANOVA table are not similar to your numbers.

Rich

mobility$id <- factor(mobility$id)
mobility$spell <- factor(mobility$spell)
mobility$year <- factor(mobility$year)

xyplot(rate ~ year | id, group=spell, data=mobility,
       pch=19, layout=c(1,5), scales=list(alternating=FALSE),
       between=list(y=1),
       strip=FALSE, strip.left=strip.custom(strip.names=c(TRUE,TRUE)))

mobility.aov <- aov(rate ~ year + id/spell, data=mobility)
anova(mobility.aov)


On Fri, Aug 22, 2014 at 7:51 AM, McCulloch, Andrew
<A.Mcculloch at leedsmet.ac.uk> wrote:
> Hi,
>
>
>
> I have an observational dataset which consists of eight annual observations (year) for children (id) recording the rate of unemployment in the neighbourhood in which they lived (rate). I know if children move home so the data also has an identifier for spells in the same neighbourhood (spell). I want to decompose the overall variation in children's experience of area unemployment, given by the sum of (rate - mean rate)^2, into a) the component within a residential spell, sum of (rate - spell mean of rate)^2, b) the component between spells, sum of (spell mean), and c) the component between children, sum of (rate - mean rate for child). I think I can do this longhand using the calculations below:
>
>
>
> mobility <- structure(list(year = c(2002L, 2003L, 2004L, 2005L, 2006L, 2007L,2008L, 2002L, 2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2002L,
>
> 2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2002L, 2003L, 2004L,
>
> 2005L, 2006L, 2007L, 2008L, 2002L, 2003L, 2004L, 2005L, 2006L,
>
> 2007L, 2008L), rate = c(13.08962, 14.27165, 4.496403, 3.89839,
>
> 4.60199, 5.138746, 5.251025, 4.874652, 5.880996, 5.813953, 6.204044,
>
> 6.93802, 6.866853, 7.614808, 4.405841, 4.826733, 4.760742, 3.762136,
>
> 4.60199, 5.138746, 5.251025, 4.405841, 4.826733, 4.760742, 3.762136,
>
> 4.60199, 5.138746, 5.251025, 4.405841, 5.789474, 5.889423, 4.61211,
>
> 4.642526, 6.838906, 9.683488), spell = c(1L, 2L, 2L, 3L, 3L,
>
> 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L), id = c(1L,
>
> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
>
> 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L,
>
> 5L, 5L)), .Names = c("year", "rate", "spell", "id"), row.names = c(NA,
>
> -35L), class = "data.frame")
>
>
>
> mobility$id <- factor(mobility$id)
>
> mobility$spell <- factor(mobility$spell)
>
>
>
> mobility$spellmean <- ave(mobility$rate,mobility$id,mobility$spell,FUN=mean)
>
> mobility$personmean <- ave(mobility$rate,mobility$id,FUN=mean)
>
> mobility$totalmean <- mean(mobility$rate,na.rm=TRUE)
>
> N <- dim(mobility)[1]
>
> # observation deviation from overall mean
>
> sum(((mobility$rate-mobility$totalmean)^2)/N)
>
> 5.159846
>
> # observation deviation from spell mean
>
> sum(((mobility$rate-mobility$spellmean)^2)/N)
>
> 2.039461
>
> # deviation of spell mean from person mean
>
> sum(((mobility$spellmean-mobility$personmean)^2)/N)
>
> 2.13787
>
> # deviation of person mean from overall mean
>
> sum(((mobility$personmean-mobility$totalmean)^2)/N)
>
> 0.982515
>
>
>
> I think this is correct because the sum of the three components of variation sums to the total:
>
> 2.039461+2.13787+0.982515 = 5.159846
>
>
>
> Can someone show me how to use the analysis of variance functions in R to get the same result. Thanks.
>
> Andrew McCulloch
> Leeds Metropolitan University
>
>
>
>
>
>
> >From 22 September 2014 Leeds Metropolitan University will become Leeds Beckett University.
> Find out more at http://www.leedsbeckett.ac.uk
> To view the terms under which this email is distributed, please go to:-
> http://www.leedsmet.ac.uk/email-disclaimer.htm
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From xie at yihui.name  Fri Aug 22 17:42:59 2014
From: xie at yihui.name (Yihui Xie)
Date: Fri, 22 Aug 2014 10:42:59 -0500
Subject: [R] knitr and stopifnot replacement.
In-Reply-To: <856018ED-E530-44EC-A1D2-75DBC51975EA@kasterma.net>
References: <C1E5430B-F134-42E9-8D6D-1FB4FFCBF5CE@kasterma.net>
	<53F71DFB.60909@gmail.com>
	<856018ED-E530-44EC-A1D2-75DBC51975EA@kasterma.net>
Message-ID: <CANROs4dNRRQ5yTT3YRY6uZupUtzyjmHVTSS_efspjqxiDLmx1A@mail.gmail.com>

Yep, that is exactly the answer.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Fri, Aug 22, 2014 at 6:35 AM, Bart Kastermans <kasterma at kasterma.net> wrote:
> On 22 Aug 2014, at 12:39, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 22/08/2014, 6:02 AM, Bart Kastermans wrote:
>>> I have a daily generated report in which I put a check using stopifnot.  Unfortunately
>>> I didn?t check the effect very well, turns out that if the condition checked fails
>>> this is not shown in the knitr output (I only get an error much later due to a missing
>>> object).
>>>
>>> So my question is, what is the correct way to use assertions in a <filename>.Rnw
>>> file.  I want to perform a check, and if it fails everything should stop with a message
>>> I can generate.
>>>
>>
>> One of the differences between knitr and Sweave is that knitr handles
>> errors, and Sweave doesn't.  I expect there's some knitr option to tell
>> it to quit in case of error (a hook?), but you'll have to check the
>> documentation to find it.
>
> Thanks; that helped me to find the exact right option:
>
> <<filelist, error=FALSE>>=
> # check all files exist before continuing
> stopifnot(all(sapply(files, file.exists)))
> @


From wdunlap at tibco.com  Fri Aug 22 17:43:43 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 22 Aug 2014 08:43:43 -0700
Subject: [R] Euclidean Distance in 3 Dimensions
In-Reply-To: <CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
References: <CAB9UfhTa1G5NEdKJG5ywRcpHsouGW+EewkeXvtq3Heg6k42njw@mail.gmail.com>
	<E2B512A3-5113-47FF-BE2B-A59A96F5C068@u.washington.edu>
	<CAB9UfhRTn42-W=HaA17ARXuvyuZ=w-njNsLvuu89d2e9vGRn6Q@mail.gmail.com>
Message-ID: <CAF8bMcZV++Bafm8aBgObenQsqRQ-AVLokxBCsEjGpM=pgW_74w@mail.gmail.com>

> This function unfortunately does not work in 3d space.

[I think 'this' is refering to the 'dist' function.]

Can you show how it is not working for you?  I.e., what does it
produce compared to what you want for a given input?

dist() does work on a 3-column (or n-column) matrix or data.frame,
which is how R generally represents 3 dimensional (or n dimensional)
data.  E.g.,

  > d <- data.frame(One=1:3, Two=c(3,5,8), Three=c(4,8,16))
  > d
    One Two Three
  1   1   3     4
  2   2   5     8
  3   3   8    16
  > dist(d)
            1         2
  2  4.582576
  3 13.152946  8.602325
  > as.matrix(dist(d)) # the matrix format makes further compuations easier
            1        2         3
  1  0.000000 4.582576 13.152946
  2  4.582576 0.000000  8.602325
  3 13.152946 8.602325  0.000000
  > which(as.matrix(dist(d))>8, arr.ind=TRUE)
    row col
  3   3   1
  3   3   2
  1   1   3
  2   2   3
  > sqrt(sum((d[,2] - d[,3])^2)) # the 2,3 or 3,2 element, by hand
  [1] 8.602325

I think it would help if you restated your problem.  I found the original
description confusing.  A small example, with the expected output, would
be very helpful.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 21, 2014 at 11:34 AM, Patzelt, Edward <patzelt at g.harvard.edu> wrote:
> This function unfortunately does not work in 3d space.
>
> Thoughts?
>
>
> On Wed, Aug 20, 2014 at 4:57 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>
>> ?dist
>>
>> from the help
>>
>> dist {stats}    R Documentation
>> Distance Matrix Computation
>>
>> Description
>>
>> This function computes and returns the distance matrix computed by using
>> the specified distance measure to compute the distances between the rows of
>> a data matrix.
>>
>> Is this what you want?  Computing on a matrix whose rows are your x, y,
>> and z values?
>>
>>
>> On Aug 20, 2014, at 1:12 PM, Patzelt, Edward <patzelt at g.harvard.edu>
>> wrote:
>>
>> > R Community -
>> >
>> > I am attempting to write a function that will calculate the distance
>> > between points in 3 dimensional space for unique regions (e.g. localized
>> > brain regions such as the frontal lobe).
>> >
>> > For example I'm looking to compare each point in region 45 to every other
>> > region in 45 to establish if they are a distance of 8 or more apart. I
>> can
>> > do this linearly comparing each distance to the previous but this is not
>> > comparing all points.
>> >
>> > structure(list(Cluster.Index = c(46L, 46L, 46L, 46L, 46L, 45L,
>> > 45L, 45L, 45L, 45L, 44L, 44L, 44L, 44L, 44L, 43L, 43L, 43L, 43L,
>> > 43L), Value = c(8.21, 7.96, 7.85, 7.83, 7.8, 5.38, 4.56, 4.5,
>> > 4, 3.99, 5.42, 4.82, 4.21, 4.18, 3.91, 4.79, 4.27, 3.24, 3.06,
>> > 3.04), x = c(33L, 38L, 37L, 36L, 38L, 47L, 42L, 43L, 44L, 42L,
>> > 50L, 41L, 39L, 41L, 44L, 46L, 45L, 45L, 41L, 46L), y = c(15L,
>> > 12L, 12L, 13L, 13L, 91L, 84L, 84L, 95L, 96L, 69L, 70L, 65L, 65L,
>> > 59L, 41L, 40L, 46L, 44L, 47L), z = c(41L, 38L, 41L, 39L, 33L,
>> > 39L, 40L, 42L, 44L, 45L, 34L, 36L, 30L, 35L, 39L, 53L, 47L, 61L,
>> > 52L, 57L), X = c(NA, 6.557438524302, 3.16227766016838, 2.44948974278318,
>> > 6.32455532033676, 78.7464284904401, 8.66025403784439, 2.23606797749979,
>> > 11.2249721603218, 2.44948974278318, 30.2324329156619, 9.2736184954957,
>> > 8.06225774829855, 5.3851648071345, 7.81024967590665, 22.8910462845192,
>> > 6.16441400296898, 15.2315462117278, 10.0498756211209, 7.68114574786861
>> > )), .Names = c("Cluster.Index", "Value", "x", "y", "z", "X"), row.names =
>> > c(NA,
>> > 20L), class = "data.frame")
>> >
>> > mainDat <- data.frame()
>> > for(i in 2:nrow(dat)){
>> > tempDist <- (sqrt((dat$x[i] - dat$x[i-1])^2 + (dat$y[i] - dat$y[i-1])^2 +
>> > (dat$z[i] - dat$z[i-1])^2))
>> > dat$X[i] <- c(tempDist)
>> > if(dat$Cluster.Index[i] != dat$Cluster.Index[i-1]){
>> > mainDat <- rbind(mainDat, dat[i,])
>> > }
>> > if((dat$Cluster.Index[i] == dat$Cluster.Index[i-1])) {
>> > if(tempDist > 8){
>> > mainDat <- rbind(mainDat, dat[i,])
>> > }
>> > }
>> > }
>> >
>> >
>> >
>> >
>> > --
>> >
>> > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
>> > University *
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> Don McKenzie
>> Research Ecologist
>> Pacific Wildland Fire Sciences Lab
>> US Forest Service
>>
>> Affiliate Professor
>> School of Environmental and Forest Sciences
>> University of Washington
>> dmck at uw.edu
>>
>>
>>
>>
>>
>
>
> --
>
> *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> University *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug 22 18:13:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Aug 2014 09:13:50 -0700
Subject: [R] Help on installing "R" packages in a Citrix
In-Reply-To: <710F58EBFD14514198D3F4860E46DCCA2CD763FDE2@MBXCLUS.int.hermes.co.uk>
References: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
	<52BC2569-96F8-4BAB-884A-AC2343DC9948@comcast.net>
	<710F58EBFD14514198D3F4860E46DCCA2CD763FDE2@MBXCLUS.int.hermes.co.uk>
Message-ID: <9C953B7A-81BF-4261-BCDC-FF8BA9CAC1B3@comcast.net>


On Aug 22, 2014, at 7:37 AM, Chirag Patel wrote:

> Hi David
>  
> I have installed R Version 2.15.1 on the image but having problems install rcom and rscproxy.

Those are commercial packages and not maintained or supported by R-Core

(That is also a rather old version of R and would have gotten the advice to update before further comments were offered if the above sentence were not applicable.)

Since the error message says the packages are nota available for R 2.15.1 I would go to the author's website and see what versions those packages are available for. Standard message to users: read the error messages for meaning.

-- 
David.
>  
> I'm following this guide:
>  
> http://homepage.univie.ac.at/erich.neuwirth/php/rcomwiki/doku.php?id=wiki:how_to_install#installation_of_r_r_d_com_server_and_rexcel
>  
> Download the statconn DCOM server and execute the program you downloaded
> Start R as administrator (on Windows 7 you need to right-click the R icon and click the corresponding item)
> In R, run the following commands (you must start R as administrator to do this)
>  
> install.packages(c("rscproxy","rcom"),repos="http://rcom.univie.ac.at/download",lib=.Library)
> library(rcom)
> comRegisterRegistry()
>  
> i get the following message:
>  
> <image001.png>
> Please can you help me?
>  
> Many Thanks
>  
> Chirag Patel
>  
>  
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: 22 August 2014 09:29
> To: Jon-Paul Cameron
> Cc: 'r-help at R-project.org'; Scott Waters; #BST - Citrix Support
> Subject: Re: [R] Help on installing "R" packages in a Citrix
>  
>  
> On Aug 22, 2014, at 12:36 AM, Jon-Paul Cameron wrote:
>  
> > Hi
> >
> > We are currently trying to migrate 3 users of "R" to a citrix based environment,
>  
> Windows?, Linux? "Citrix" isn't usually thought of as an OS is it?
>  
>  
> > but are coming across major issues trying to install the packages to the relevant image. Can someone please contact me around how the install should be done - as we can find no supporting documentation or help on this matter.
>  
> http://cran.us.r-project.org/manuals.html
>  
> >
> > I already sent this request to "R-packages" for help, but was told this was the correct Forum for info of this type.
>  
> Have you installed R? Which OS? Which version?
>  
> --
> David Winsemius
> Alameda, CA, USA
>  
> ______________________________


David Winsemius
Alameda, CA, USA


From zwei0428 at hotmail.com  Fri Aug 22 16:16:58 2014
From: zwei0428 at hotmail.com (James Wei)
Date: Fri, 22 Aug 2014 14:16:58 +0000
Subject: [R] print vectors with consecutive numbers
In-Reply-To: <CAKL8G3EctHzXXTtvtVQk2TZKh_dvK+yLiGmrSgJL4CiXaCCp2Q@mail.gmail.com>
References: <BAY176-W344E0B16685F17D2A3E912C0D00@phx.gbl>,
	<CAKL8G3EctHzXXTtvtVQk2TZKh_dvK+yLiGmrSgJL4CiXaCCp2Q@mail.gmail.com>
Message-ID: <BAY176-W48FD171F41667C57998D0AC0D00@phx.gbl>

Hi Jorge,
 
Thanks so much, it is working perfectly. There are so many for me to learn.
 
Cheers.
 
James
 
From: jorgeivanvelez at gmail.com
Date: Fri, 22 Aug 2014 22:28:40 +1000
Subject: Re: [R] print vectors with consecutive numbers
To: zwei0428 at hotmail.com
CC: r-help at r-project.org

Hi James,


Try
mat[, apply(mat, 2, function(x) any(diff(x) == 1))]



HTH,

Jorge.-


On Fri, Aug 22, 2014 at 10:18 PM, James Wei <zwei0428 at hotmail.com> wrote:






Hi all,



I have a matrix with consecutive and non-consecutive numbers

in columns. For example, the first 2 columns have consecutive numbers. I want R

to print only columns with consecutive numbers. Here is the matrix and how I

did using conditional statement:



##



mat=matrix(data=c(9,2,3,4,5,6,10,13,15,17,19,22,

25,27,29,31,34,37,39,41),ncol=5)



mat



difference = diff(mat)==1



difference



y1=difference[1,]



y2=difference[2,]



y3=difference[3,]



y=(y1|y2|y3)



y







if (y=="TRUE") mat else 0



##



However, R still print all 5 columns, not the first 2

columns I wanted. I got the Warning message:



In if (y == "TRUE") mat else 0 :



  the condition has

length > 1 and only the first element will be used



How can I change the code to get only the first 2 columns

with consecutive numbers printed? I am new to R.



Thanks in advance for your help. James





        [[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.


 		 	   		  
	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Fri Aug 22 19:08:32 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 22 Aug 2014 10:08:32 -0700
Subject: [R] print vectors with consecutive numbers
In-Reply-To: <BAY176-W48FD171F41667C57998D0AC0D00@phx.gbl>
References: <BAY176-W344E0B16685F17D2A3E912C0D00@phx.gbl>
	<CAKL8G3EctHzXXTtvtVQk2TZKh_dvK+yLiGmrSgJL4CiXaCCp2Q@mail.gmail.com>
	<BAY176-W48FD171F41667C57998D0AC0D00@phx.gbl>
Message-ID: <CACk-te03y=wDADLh9ERN7xoE5OFOAk_U6iL5edMJrkGoffxczg@mail.gmail.com>

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Aug 22, 2014 at 7:16 AM, James Wei <zwei0428 at hotmail.com> wrote:
> Hi Jorge,
>
> Thanks so much, it is working perfectly. There are so many for me to learn.

Have you done an R tutorial?  e.g.

http://cran.r-project.org/doc/manuals/R-intro.pdf

(This ships with R. There are many others around the web. Just search).

If not, please do not post further until you have done so. You cannot
complain of ignorance when you have not made an honest effort to
learn. And if you have already, post away.

Cheers,
Bert

>
> Cheers.
>
> James
>
> From: jorgeivanvelez at gmail.com
> Date: Fri, 22 Aug 2014 22:28:40 +1000
> Subject: Re: [R] print vectors with consecutive numbers
> To: zwei0428 at hotmail.com
> CC: r-help at r-project.org
>
> Hi James,
>
>
> Try
> mat[, apply(mat, 2, function(x) any(diff(x) == 1))]
>
>
>
> HTH,
>
> Jorge.-
>
>
> On Fri, Aug 22, 2014 at 10:18 PM, James Wei <zwei0428 at hotmail.com> wrote:
>
>
>
>
>
>
> Hi all,
>
>
>
> I have a matrix with consecutive and non-consecutive numbers
>
> in columns. For example, the first 2 columns have consecutive numbers. I want R
>
> to print only columns with consecutive numbers. Here is the matrix and how I
>
> did using conditional statement:
>
>
>
> ##
>
>
>
> mat=matrix(data=c(9,2,3,4,5,6,10,13,15,17,19,22,
>
> 25,27,29,31,34,37,39,41),ncol=5)
>
>
>
> mat
>
>
>
> difference = diff(mat)==1
>
>
>
> difference
>
>
>
> y1=difference[1,]
>
>
>
> y2=difference[2,]
>
>
>
> y3=difference[3,]
>
>
>
> y=(y1|y2|y3)
>
>
>
> y
>
>
>
>
>
>
>
> if (y=="TRUE") mat else 0
>
>
>
> ##
>
>
>
> However, R still print all 5 columns, not the first 2
>
> columns I wanted. I got the Warning message:
>
>
>
> In if (y == "TRUE") mat else 0 :
>
>
>
>   the condition has
>
> length > 1 and only the first element will be used
>
>
>
> How can I change the code to get only the first 2 columns
>
> with consecutive numbers printed? I am new to R.
>
>
>
> Thanks in advance for your help. James
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
>
> R-help at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Fri Aug 22 19:09:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Aug 2014 10:09:18 -0700
Subject: [R] Help on installing "R" packages in a Citrix
In-Reply-To: <9C953B7A-81BF-4261-BCDC-FF8BA9CAC1B3@comcast.net>
References: <FCD4A35EA26A8547B1FB23F9BFA9603E369C42F479@MBXCLUS.int.hermes.co.uk>
	<52BC2569-96F8-4BAB-884A-AC2343DC9948@comcast.net>
	<710F58EBFD14514198D3F4860E46DCCA2CD763FDE2@MBXCLUS.int.hermes.co.uk>
	<9C953B7A-81BF-4261-BCDC-FF8BA9CAC1B3@comcast.net>
Message-ID: <0CC21B04-5414-4E2A-872E-3B060A02885C@comcast.net>


On Aug 22, 2014, at 9:13 AM, David Winsemius wrote:

> 
> On Aug 22, 2014, at 7:37 AM, Chirag Patel wrote:
> 
>> Hi David
>> 
>> I have installed R Version 2.15.1 on the image but having problems install rcom and rscproxy.
> 
> Those are commercial packages and not maintained or supported by R-Core

I need to clarify that statement:

http://homepage.univie.ac.at/erich.neuwirth/php/rcomwiki/doku.php?id=wiki:how_to_install

rcom is placed on CRAN but authored by the people who distribute RExcel, so technically it's not a commercial product itself but it is made available to support a commercial product. You will notice in its requirements statconnDCOM:

And it's wiki says rcom does not comply with CRAN open source requirements anymore:

http://homepage.univie.ac.at/erich.neuwirth/php/rcomwiki/doku.php?id=start

-- 
David.

> 
> (That is also a rather old version of R and would have gotten the advice to update before further comments were offered if the above sentence were not applicable.)
> 
> Since the error message says the packages are nota available for R 2.15.1 I would go to the author's website and see what versions those packages are available for. Standard message to users: read the error messages for meaning.
> 
> -- 
> David.
>> 
>> I'm following this guide:
>> 
>> http://homepage.univie.ac.at/erich.neuwirth/php/rcomwiki/doku.php?id=wiki:how_to_install#installation_of_r_r_d_com_server_and_rexcel
>> 
>> Download the statconn DCOM server and execute the program you downloaded
>> Start R as administrator (on Windows 7 you need to right-click the R icon and click the corresponding item)
>> In R, run the following commands (you must start R as administrator to do this)
>> 
>> install.packages(c("rscproxy","rcom"),repos="http://rcom.univie.ac.at/download",lib=.Library)
>> library(rcom)
>> comRegisterRegistry()
>> 
>> i get the following message:
>> 
>> <image001.png>
>> Please can you help me?
>> 
>> Many Thanks
>> 
>> Chirag Patel
>> 
>> 
>> -----Original Message-----
>> From: David Winsemius [mailto:dwinsemius at comcast.net] 
>> Sent: 22 August 2014 09:29
>> To: Jon-Paul Cameron
>> Cc: 'r-help at R-project.org'; Scott Waters; #BST - Citrix Support
>> Subject: Re: [R] Help on installing "R" packages in a Citrix
>> 
>> 
>> On Aug 22, 2014, at 12:36 AM, Jon-Paul Cameron wrote:
>> 
>>> Hi
>>> 
>>> We are currently trying to migrate 3 users of "R" to a citrix based environment,
>> 
>> Windows?, Linux? "Citrix" isn't usually thought of as an OS is it?
>> 
>> 
>>> but are coming across major issues trying to install the packages to the relevant image. Can someone please contact me around how the install should be done - as we can find no supporting documentation or help on this matter.
>> 
>> http://cran.us.r-project.org/manuals.html
>> 
>>> 
>>> I already sent this request to "R-packages" for help, but was told this was the correct Forum for info of this type.
>> 
>> Have you installed R? Which OS? Which version?
>> 
>> --
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________
> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jszhao at yeah.net  Fri Aug 22 19:14:36 2014
From: jszhao at yeah.net (Jinsong Zhao)
Date: Fri, 22 Aug 2014 10:14:36 -0700
Subject: [R] loading saved files with objects in same names
In-Reply-To: <21494.63771.286716.385765@stat.math.ethz.ch>
References: <53F29AAC.8000009@yeah.net>	<CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>
	<21494.63771.286716.385765@stat.math.ethz.ch>
Message-ID: <53F77A7C.7060004@yeah.net>

On 2014/8/22 1:02, Martin Maechler wrote:
>
>> Have you tried the 'envir' argument to load()?  E.g.,
>>     envA <- new.environment()
>>     load("A.RData", envir=envA)
>>     envB <- new.environment()
>>     load("B.RData", envir=envB)
>>     plot(A$object, B$object)
>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>
> An alternative that I have been advocating is using
>
>    attach("A.RData")
>
> etc. It does something similar as the above, but more
> conveniently:
> It loads the objects into a new environment  *and* attaches that
> environment to your search()  path, so you can access them
> directly, but attach() will never accidentally destroy existing
> R objects in your global environment ( = search()[[1]] ).
>
> Martin
>

Thanks a lot.

I try your method, and I got:

 > attach("D2.1.RData")
The following objects are masked _by_ .GlobalEnv:

     coda.jags.1, df.1, jags.1, Mean, N

In this case, how to access the masked objects?

Best,
Jinsong

>
>
>
>
>> On Mon, Aug 18, 2014 at 5:30 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
>> Hi there,
>>
>> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
>> each file, there are some objects with same names but different contents.
>> Now, I need to compare those objects through plotting. However, I can't find
>> a way to load them into a workspace. The only thing I can do is to rename
>> them and then save and load again.
>>
>> Is there a convenient to load those objects?
>>
>> Thanks a lot in advance.
>>
>> Best regards,
>> Jinsong
>>


From Haiko.Lietz at gesis.org  Fri Aug 22 19:36:23 2014
From: Haiko.Lietz at gesis.org (Lietz, Haiko)
Date: Fri, 22 Aug 2014 17:36:23 +0000
Subject: [R] filled.contour key axis
In-Reply-To: <7150397.LoKGASRY3C@localhost.localdomain>
References: <D57FB3A7BE5E14479A21F7832D5F1B344FCE77BE@svboexc02.gesis.intra>,
	<7150397.LoKGASRY3C@localhost.localdomain>
Message-ID: <D57FB3A7BE5E14479A21F7832D5F1B344FCE8B92@svboexc02.gesis.intra>

Hi Jim, all,

Thx, I was hoping for percentage scores, such that R puts numbers with "%" there.

And by "automatically labeling" I meant giving the axis a title, sorry for mixing that up.

I havn't found an option in the parameters for filled.contour.

Haiko


________________________________________
Von: Jim Lemon [jim at bitwrit.com.au]
Gesendet: Montag, 18. August 2014 14:41
An: r-help at r-project.org
Cc: Lietz, Haiko
Betreff: Re: [R] filled.contour key axis

On Mon, 18 Aug 2014 08:51:57 AM Lietz, Haiko wrote:
> Hi all,
>
> Using filled.contour...
>
> foo <- matrix(seq(0.1, 0.9, 0.1), ncol = 3)
> filled.contour(foo)
>
> how can I set the key axis to give percentages?
>
> And is there a way to automatically label the key axis except for
placing
> text there?
>
> Thanks
>
> Haiko

Hi Haiko,
Try this:

filled.contour(foo,
 plot.axes={axis(1);
 axis(2,at=seq(0,1,by=0.2),labels=seq(0,100,by=20))},
 key.axes=
 {axis(4,at=seq(0,1,by=0.2),labels=seq(0,100,by=20))})

Jim



From hb at biostat.ucsf.edu  Fri Aug 22 20:38:33 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 22 Aug 2014 11:38:33 -0700
Subject: [R] "no visible binding for global variable" and with() vs.
	within()
In-Reply-To: <21495.4095.461950.270410@stat.math.ethz.ch>
References: <CAJb81Sns6GODzXpoHyRdAFwg8JiDWkX9TSAdDmPMmjp1RWhWUw@mail.gmail.com>
	<53F08C90.70902@gmail.com> <53F114E8.9090108@auckland.ac.nz>
	<21495.4095.461950.270410@stat.math.ethz.ch>
Message-ID: <CAFDcVCRy463ab0_NG0oqa+i_QCh++LqkvaNXQx0-EgcvZrKJpg@mail.gmail.com>

I'm dealing with these type of false NOTEs as:

foo1 <- function (bar) {
   # To please R CMD check
   x <- NULL; rm(list="x")

   with(bar, {
     x })
}

Of course, that may one day break with more clever code inspections.

My $.02

/Henrik

On Fri, Aug 22, 2014 at 2:40 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Rolf Turner <r.turner at auckland.ac.nz>
>>>>>>     on Mon, 18 Aug 2014 08:47:36 +1200 writes:
>
>     > On 17/08/14 23:05, Duncan Murdoch wrote:
>     >> On 16/08/2014, 9:36 PM, Daniel Braithwaite wrote:
>     >>> R CMD check does not object to this code when checking a
>     >>> package:
>     >>>
>     >>> foo1 <- function (bar) { with(bar, { x }) }
>     >>>
>     >>> but produces a warning:
>     >>>
>     >>> foo2: no visible binding for global variable 'x'
>     >>>
>     >>> in response to this:
>     >>>
>     >>> foo2 <- function (bar) { within(bar, { x }) }
>     >>>
>     >>> Is this an R bug, or at least, an inadvertent
>     >>> inconsistency?  Here is sessionInfo() from my machine,
>     >>> right after starting an interactive session:
>     >>
>     >> I'm not sure, but I suspect it's an intentional
>     >> inconsistency.  The code that checks for use of globals
>     >> can't do anything in with() or within() code, so bugs can
>     >> slip by if you use those.  I think with() had been around
>     >> for a long time and was in wide use when that test was
>     >> added, but within() is newer, and it was less disruptive
>     >> to warn about it, so the warning has been left in.  (I
>     >> don't remember whether the test came before or after
>     >> within() was introduced.)
>     >>
>     >> So if you want to avoid the warning, don't use within().
>
>     > Or you could have a file, say "melvin.R", in the R
>     > directory of your package, containing the line:
>
>     >   utils::globalVariables("x")
>
> Yes,  but that would be a quite bad idea, IMHO:
>
> The checking code {from package 'codetools' BTW}
> would no longer warn you about any accidental global 'x'
> variable in any of your functions in your package.
>
> After all, these codetools checks *are* very helpful in
> detecting typos and thinkos.
> Consequently, I'd strongly advise to only use
> globalVariables(.) on *rare* variable names.
>
> Martin Maechler,
> ETH Zurich
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Aug 22 21:01:04 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 22 Aug 2014 12:01:04 -0700
Subject: [R] filled.contour key axis
In-Reply-To: <D57FB3A7BE5E14479A21F7832D5F1B344FCE8B92@svboexc02.gesis.intra>
References: <D57FB3A7BE5E14479A21F7832D5F1B344FCE77BE@svboexc02.gesis.intra>,
	<7150397.LoKGASRY3C@localhost.localdomain>
	<D57FB3A7BE5E14479A21F7832D5F1B344FCE8B92@svboexc02.gesis.intra>
Message-ID: <64ee3450-b0a5-4e7c-b754-1f514c30d8d3@email.android.com>

You seem to be thinking of Excel. R does not dress up numbers for you... if you want them represented in a particular way, you need to format them into a character string. There are plenty of options for doing that.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 22, 2014 10:36:23 AM PDT, "Lietz, Haiko" <Haiko.Lietz at gesis.org> wrote:
>Hi Jim, all,
>
>Thx, I was hoping for percentage scores, such that R puts numbers with
>"%" there.
>
>And by "automatically labeling" I meant giving the axis a title, sorry
>for mixing that up.
>
>I havn't found an option in the parameters for filled.contour.
>
>Haiko
>
>
>________________________________________
>Von: Jim Lemon [jim at bitwrit.com.au]
>Gesendet: Montag, 18. August 2014 14:41
>An: r-help at r-project.org
>Cc: Lietz, Haiko
>Betreff: Re: [R] filled.contour key axis
>
>On Mon, 18 Aug 2014 08:51:57 AM Lietz, Haiko wrote:
>> Hi all,
>>
>> Using filled.contour...
>>
>> foo <- matrix(seq(0.1, 0.9, 0.1), ncol = 3)
>> filled.contour(foo)
>>
>> how can I set the key axis to give percentages?
>>
>> And is there a way to automatically label the key axis except for
>placing
>> text there?
>>
>> Thanks
>>
>> Haiko
>
>Hi Haiko,
>Try this:
>
>filled.contour(foo,
> plot.axes={axis(1);
> axis(2,at=seq(0,1,by=0.2),labels=seq(0,100,by=20))},
> key.axes=
> {axis(4,at=seq(0,1,by=0.2),labels=seq(0,100,by=20))})
>
>Jim
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Aug 22 22:46:25 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 22 Aug 2014 20:46:25 +0000
Subject: [R] Subsetting data for split-sample validation,
 then repeating 1000x
In-Reply-To: <CAHaDdYFhLSyfcd2rLYKz4msXJC8gf1xx4+2SVQVtf4CM-Q1_mw@mail.gmail.com>
References: <CAHaDdYFhLSyfcd2rLYKz4msXJC8gf1xx4+2SVQVtf4CM-Q1_mw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F92379@mb02.ads.tamu.edu>

You can use replicate() or a for (i in 1:1000){} loop to do your replications, but you have other issues first. 

1. You are sampling with replacement which makes no sense at all. Your 70% sample will contain some observations multiple times and will use less than 70% of the data most of the time.

2. You compute r using cor() and r.squared using summary.lm(). Why? Once you have computed r, r*r or r^2 is equal to r.squared for the simple linear model you are using.

# To split your data, you need to sample without replacement, e.g.

train <- sample.int(nrow(A), floor(nrow(A)*.7))
test <- (1:nrow(A))[-train]

# Now run your analysis on A[train,] and test it on A[test,] 

# Fit model (I'm modeling native plant richness, 'nat.r')
A.model <- glmmadmb(nat.r ~ isl.sz + nr.mead, random = ~ 1 | site, family =
"poisson", data = A[train,])

# Correlation between predicted 30% and actual 30%
cor <- cor(Atest$nat.r, predict(A.model, newdata = A[test,], type = "response"))


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Angela Boag
Sent: Thursday, August 21, 2014 4:46 PM
To: r-help at r-project.org
Subject: [R] Subsetting data for split-sample validation, then repeating 1000x

Hi all,

I'm doing some within-dataset model validation and would like to subset a
dataset 70/30 and fit a model to 70% of the data (the training data), then
validate it by predicting the remaining 30% (the testing data), and I would
like to do this split-sample validation 1000 times and average the
correlation coefficient and r2 between the training and testing data.

I have the following working for a single iteration, and would like to know
how to use either the replicate() or for-loop functions to average the 1000
'r2' and 'cor' outputs.

--

# create 70% training sample
A.samp <- sample(1:nrow(A),floor(0.7*nrow(A)), replace = TRUE)

# Fit model (I'm modeling native plant richness, 'nat.r')
A.model <- glmmadmb(nat.r ~ isl.sz + nr.mead, random = ~ 1 | site, family =
"poisson", data = A[A.samp,])

# Use the model to predict the remaining 30% of the data
A.pred <- predict(A.model, newdata = A[-A.samp,], type = "response")

# Correlation between predicted 30% and actual 30%
cor <- cor(A[-A.samp,]$nat.r, A.pred, method = "pearson")

# r2 between predicted and observed
lm.A <- lm(A.pred ~ A[-A.samp,]$nat.r)
r2 <- summary(lm.A)$r.squared

# print values
r2
cor

--

Thanks for your time!

Cheers,
Angela

--
Angela E. Boag
Ph.D. Student, Environmental Studies
CAFOR Project Researcher
University of Colorado, Boulder
Mobile: 720-212-6505

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Aug 22 23:18:47 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 22 Aug 2014 21:18:47 +0000
Subject: [R] Subsetting data for split-sample validation,
 then repeating 1000x
In-Reply-To: <CAHaDdYGjc3xBNC9vcMAUrQtCPdJw2ZZ1Fste3qcfsdwDaALs-g@mail.gmail.com>
References: <CAHaDdYFhLSyfcd2rLYKz4msXJC8gf1xx4+2SVQVtf4CM-Q1_mw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F92379@mb02.ads.tamu.edu>
	<CAHaDdYGjc3xBNC9vcMAUrQtCPdJw2ZZ1Fste3qcfsdwDaALs-g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F923E1@mb02.ads.tamu.edu>

Combine your code into a function:

Plant <- function() {
    train <- sample.int(nrow(A), floor(nrow(A)*.7))
    test <- (1:nrow(A))[-train]
    A.model <- glmmadmb(nat.r ~ isl.sz + nr.mead, random = ~ 1 | site, family =
        "poisson", data = A[train,])
    cor(Atest$nat.r, predict(A.model, newdata = A[test,], type = "response"))
}

Test the function. It should return a single correlation and no errors or warnings.

Plant()

If not, debug and run it again. When it works:

Out <- replicate(1000, Plant())

Out should be a vector with 1000 correlation values.
hist(Out) # for a histogram of the correlation values

David C


From: Angela Boag [mailto:Angela.Boag at Colorado.EDU] 
Sent: Friday, August 22, 2014 4:01 PM
To: David L Carlson
Subject: Re: [R] Subsetting data for split-sample validation, then repeating 1000x

Hi David,
Thanks for the feedback. I actually sampled without replacement initially but it's been a while since I looked at this code and just changed it because I thought it made more sense logically, but you've reassured me that my original hunch was right.
The real issue I'm having is how to use either the replicate() or for(i in 1:1000){} loop code to get the average r value of 1000 repetitions as my output. I'm not familiar with either tool, so any suggestions on what that code would look like would be very helpful.

Thanks!
Angela 


--
Angela E. Boag
Ph.D. Student, Environmental Studies
CAFOR Project Researcher
University of Colorado, Boulder
Mobile: 720-212-6505


On Fri, Aug 22, 2014 at 2:46 PM, David L Carlson <dcarlson at tamu.edu> wrote:
You can use replicate() or a for (i in 1:1000){} loop to do your replications, but you have other issues first.

1. You are sampling with replacement which makes no sense at all. Your 70% sample will contain some observations multiple times and will use less than 70% of the data most of the time.

2. You compute r using cor() and r.squared using summary.lm(). Why? Once you have computed r, r*r or r^2 is equal to r.squared for the simple linear model you are using.

# To split your data, you need to sample without replacement, e.g.

train <- sample.int(nrow(A), floor(nrow(A)*.7))
test <- (1:nrow(A))[-train]

# Now run your analysis on A[train,] and test it on A[test,]

# Fit model (I'm modeling native plant richness, 'nat.r')
A.model <- glmmadmb(nat.r ~ isl.sz + nr.mead, random = ~ 1 | site, family =
"poisson", data = A[train,])

# Correlation between predicted 30% and actual 30%
cor <- cor(Atest$nat.r, predict(A.model, newdata = A[test,], type = "response"))


-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Angela Boag
Sent: Thursday, August 21, 2014 4:46 PM
To: r-help at r-project.org
Subject: [R] Subsetting data for split-sample validation, then repeating 1000x

Hi all,

I'm doing some within-dataset model validation and would like to subset a
dataset 70/30 and fit a model to 70% of the data (the training data), then
validate it by predicting the remaining 30% (the testing data), and I would
like to do this split-sample validation 1000 times and average the
correlation coefficient and r2 between the training and testing data.

I have the following working for a single iteration, and would like to know
how to use either the replicate() or for-loop functions to average the 1000
'r2' and 'cor' outputs.

--

# create 70% training sample
A.samp <- sample(1:nrow(A),floor(0.7*nrow(A)), replace = TRUE)

# Fit model (I'm modeling native plant richness, 'nat.r')
A.model <- glmmadmb(nat.r ~ isl.sz + nr.mead, random = ~ 1 | site, family =
"poisson", data = A[A.samp,])

# Use the model to predict the remaining 30% of the data
A.pred <- predict(A.model, newdata = A[-A.samp,], type = "response")

# Correlation between predicted 30% and actual 30%
cor <- cor(A[-A.samp,]$nat.r, A.pred, method = "pearson")

# r2 between predicted and observed
lm.A <- lm(A.pred ~ A[-A.samp,]$nat.r)
r2 <- summary(lm.A)$r.squared

# print values
r2
cor

--

Thanks for your time!

Cheers,
Angela

--
Angela E. Boag
Ph.D. Student, Environmental Studies
CAFOR Project Researcher
University of Colorado, Boulder
Mobile: 720-212-6505
? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Aug 23 01:09:27 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 22 Aug 2014 19:09:27 -0400
Subject: [R] loading saved files with objects in same names
In-Reply-To: <53F77A7C.7060004@yeah.net>
References: <53F29AAC.8000009@yeah.net>	<CAF8bMcaHp4VeqR==jyTtpsU9OjM9iOo+w51da3+aagcn1qhVWQ@mail.gmail.com>	<21494.63771.286716.385765@stat.math.ethz.ch>
	<53F77A7C.7060004@yeah.net>
Message-ID: <53F7CDA7.5080505@gmail.com>

On 22/08/2014, 1:14 PM, Jinsong Zhao wrote:
> On 2014/8/22 1:02, Martin Maechler wrote:
>>
>>> Have you tried the 'envir' argument to load()?  E.g.,
>>>     envA <- new.environment()
>>>     load("A.RData", envir=envA)
>>>     envB <- new.environment()
>>>     load("B.RData", envir=envB)
>>>     plot(A$object, B$object)
>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>
>> An alternative that I have been advocating is using
>>
>>    attach("A.RData")
>>
>> etc. It does something similar as the above, but more
>> conveniently:
>> It loads the objects into a new environment  *and* attaches that
>> environment to your search()  path, so you can access them
>> directly, but attach() will never accidentally destroy existing
>> R objects in your global environment ( = search()[[1]] ).
>>
>> Martin
>>
> 
> Thanks a lot.
> 
> I try your method, and I got:
> 
>  > attach("D2.1.RData")
> The following objects are masked _by_ .GlobalEnv:
> 
>      coda.jags.1, df.1, jags.1, Mean, N
> 
> In this case, how to access the masked objects?

Don't ever use attach(), and this won't be a problem.  Martin gave you
bad advice.

Duncan Murdoch


From kevin2059 at 163.com  Sat Aug 23 04:33:54 2014
From: kevin2059 at 163.com (kevin2059)
Date: Sat, 23 Aug 2014 10:33:54 +0800 (CST)
Subject: [R] BNF description for R
In-Reply-To: <53F08D4C.90606@gmail.com>
References: <5296eb1a.219.147e12a1f4e.Coremail.kevin2059@163.com>
	<53F08D4C.90606@gmail.com>
Message-ID: <188c6c4f.4f0.14800b6840d.Coremail.kevin2059@163.com>

Thank you,that help a lot.
At 2014-08-17 19:09:00,"Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 16/08/2014, 7:32 PM, kevin2059 wrote:
>> HOW can I get a completely BNF description for R? I try to  write a parser for R now.
>
>The R grammar is defined in the src/main/gram.y file (in Bison format).
> You can get that file from
>https://svn.r-project.org/R/trunk/src/main/gram.y.
>
>Duncan Murdoch

From jim at bitwrit.com.au  Sat Aug 23 06:40:11 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 23 Aug 2014 14:40:11 +1000
Subject: [R] filled.contour key axis
In-Reply-To: <D57FB3A7BE5E14479A21F7832D5F1B344FCE8B92@svboexc02.gesis.intra>
References: <D57FB3A7BE5E14479A21F7832D5F1B344FCE77BE@svboexc02.gesis.intra>
	<7150397.LoKGASRY3C@localhost.localdomain>
	<D57FB3A7BE5E14479A21F7832D5F1B344FCE8B92@svboexc02.gesis.intra>
Message-ID: <1427199.W0QNLHfTWZ@localhost.localdomain>

On Fri, 22 Aug 2014 05:36:23 PM Lietz, Haiko wrote:
> Hi Jim, all,
> 
> Thx, I was hoping for percentage scores, such that R puts numbers 
with "%"
> there.
> 
> And by "automatically labeling" I meant giving the axis a title, sorry for
> mixing that up.
> 
> I havn't found an option in the parameters for filled.contour.
> 
> Haiko
> 
Hi Haiko,
I think what Jeff meant was:
 
filled.contour(foo,
 plot.axes={axis(1);
 axis(2,at=seq(0,1,by=0.2),
  labels=paste(seq(0,100,by=20),"%"))},
 key.axes=
 {axis(4,at=seq(0,1,by=0.2),
  labels=paste(seq(0,100,by=20),"%"))})

Even Excel can't read your mind, although it sometimes thinks it can.

Jim


From lloyd.relaxed at gmail.com  Fri Aug 22 20:00:51 2014
From: lloyd.relaxed at gmail.com (lloyd no_last_name)
Date: Fri, 22 Aug 2014 12:00:51 -0600
Subject: [R] I cannot register but I have a burning Question about mcmcPack
Message-ID: <CAM6-qg593pRqX+DjTZPRxmwqg=Stfw3iovxA3m1PYCt=ZYYHCA@mail.gmail.com>

I want to construct a simple MCMC Neural Net with normal errors


 library(nnet)


 nn.ts <- nnet( y=response, x = data.frame(result$bestColSpace), size = 2,
skip = T, softmax=F, entropy=F, linout = T, maxit = 150, Hess = F, trace =
F, Wts=result$coefficients[[1]] )


 L1Metric(nn.ts$residuals)

[1] 0.6978838


 # I created a maximum likelihood version of

# my regular nn function


 *mcmcNN = function( proposed.nwts, # proposed wts in Neural Net *

*y=result$response, # response vector *

*X=result$bestColSpace ) # matrix same rows as y*

*{ *

result$coefficients = proposed.nwts

uHat = pureNN( result )$fit;

# expected values of the NN given X, y and proposed parms

singlelikelihoods = dnorm(y, mean = uHat, sd = sd(x=(y-uHat)), log = T)

LL = sum(singlelikelihoods)


 return( LL );


 *} # end of function mcmcNN*

# function for metropolis-hastings



 and I ran the Metropolis-hastings in


 library(mcmcPack);


 *post.samp <- MCMCmetrop1R( mcmcNN, theta.init = nn.ts$wts,*

 X=result$bestColSpace, y=response,

 V=NULL, # or =covV

 thin=4, mcmc=12000, burnin=12000,

 tune=rep( 0.55, length(nn.ts$wts) ),

logfun=TRUE, force.samp=T )


 # with each row of parms ( neural net weights ) in the posterior sample

# I computed the fitted.values with my neural net function

# next, I located the best fit of all of these 12,000 models

# I even started init.theta with the nnet weights


 > minErr # from all proposed paramaters ( NN wts ) with fixed X and y

[1] 0.8727279


 This is significantly worse than nnet;


 The neural net, being nonlinear regression, is sensitive to initial
values. Therefore, it will find a local minimum. I expected mcmc to return
the global minimum ( average absolute deviation ).




 Thanx,

Lloyd L


 Is there some way I can help R-users?

	[[alternative HTML version deleted]]


From neelesh0 at gmail.com  Sat Aug 23 09:31:55 2014
From: neelesh0 at gmail.com (Neel G)
Date: Sat, 23 Aug 2014 13:01:55 +0530
Subject: [R] Banking Data Profiling: Need suggestion on R packages
Message-ID: <CAOZ5VVJAYOXS4hxW4-A0UBq50CpCf2y9-eZitcTq8A+F0CXP9w@mail.gmail.com>

Hello Members,
I have started a project to profile banking data so as to identify any
early data quality issues and present the output a way which will be easy
to understand.

It will be very helpful if you can suggest me some packages in R which is
from your understanding will help me in data profiling as well as in
presentation

Regards,
Neelesh

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Sat Aug 23 17:22:06 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sat, 23 Aug 2014 18:22:06 +0300
Subject: [R] simulation data with dichotomous variables
Message-ID: <CABLo8nHe=woEatrHAH+m_5eKFfnq_Hd9WzYPJk_bMA5MY7532g@mail.gmail.com>

dear all members
i have a problem with the code below, my problem in this code i want to put
a high correlation between variables in group R1 and also put a high
correlation between variables in group R2. after checking the correlation
between variables in R1 also between variables in R2 i didn't find any
correlation btween variables in R1 and between variables in R2.
many thanks to Dr. William to help me to write this code and i hope to help
me to complete it.

many thanks to all

library(psych)
ords <- seq(0,1)
p <- 10
N <- 1000
percent_change <- 0.9
R1 <- sim.irt(10,1000,a=3,low = -2, high=2)
R2 <-  sim.irt(10,1000,a=3,low = -2, high=2)
R12 <- data.frame(R1$items,R2$items)
#this gives you 20 items, grouped with high correlations within the first
10, and the second 10, no correlation between the first and second sets.
rho <- tetrachoric(R12)$rho  #find the tetrachoric correlation between the
items
lowerMat(rho)  #show the correlations
cor.plot(rho,numbers=TRUE)   #show a heat map of the correlations

R1 <- as.data.frame(replicate(p, sample(ords, N, replace = T)))
R2 <- as.data.frame(replicate(p, sample(ords, N, replace = T)))
rho <- tetrachoric(R12)$rho  #find the tetrachoric correlation between the
items
lowerMat(rho)  #show the correlations
R1
R2

	[[alternative HTML version deleted]]


From lx900902 at qq.com  Sat Aug 23 14:22:53 2014
From: lx900902 at qq.com (=?utf-8?B?6KW/6aOO5Y+k6YGT?=)
Date: Sat, 23 Aug 2014 20:22:53 +0800
Subject: [R] How can I let the dimension change via the circulation?
Message-ID: <tencent_3EE2E7647824398D5F449C1F@qq.com>

Here is the fraction of Matlab code for the Generalized Sup ADF Test for the bubble testing: 

The dimension of the matrix rwadft may vary via the circulation. I then imitate this code by the R program as the following: 
for (dim0 in 1:30){ 
rwadf<-numeric(dim0) 
.... 
 in the circulation but it does not work. The dimension of the rwadf do not vary and I can not get the right answer. 
I want to know if I can let the dimension of the rwadf change via the circulation. How should I write the R code??
	[[alternative HTML version deleted]]


From leila_janani at yahoo.com  Sat Aug 23 17:00:29 2014
From: leila_janani at yahoo.com (leila janani)
Date: Sat, 23 Aug 2014 08:00:29 -0700
Subject: [R] Error in geeglm
Message-ID: <1408806029.45425.YahooMailNeo@web140802.mail.bf1.yahoo.com>

Hello everyone,
I want to fit a following model as an alternative to log
binomial model (Thomas Lumley,et al?2006).
But I come across with this error: ? Error in eval(expr,
envir, enclos) : cannot find valid starting values: please specify some?
geeglm (outcome ~ treatment,
data = dat, family=gaussian(link="log"), id=subject_id)

Using SAS (Genmod) I can run this model without any problem:

proc genmod data=dat
DESCENDING;
model outcome = treatment / dist=normal ?link=log;
repeated subject=subject_id;
run; 

Could anyone offer some suggestions?
Thank you
Leila

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Sun Aug 24 02:37:54 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 23 Aug 2014 17:37:54 -0700
Subject: [R] How can I let the dimension change via the circulation?
In-Reply-To: <tencent_3EE2E7647824398D5F449C1F@qq.com>
References: <tencent_3EE2E7647824398D5F449C1F@qq.com>
Message-ID: <CACk-te2MBbB5caVEEucgqddK+z8b-xtoLdSg-pdOq5tH-MENeQ@mail.gmail.com>

Huh?

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Aug 23, 2014 at 5:22 AM, ???? <lx900902 at qq.com> wrote:
> Here is the fraction of Matlab code for the Generalized Sup ADF Test for the bubble testing:
>
> The dimension of the matrix rwadft may vary via the circulation. I then imitate this code by the R program as the following:
> for (dim0 in 1:30){
> rwadf<-numeric(dim0)
> ....
>  in the circulation but it does not work. The dimension of the rwadf do not vary and I can not get the right answer.
> I want to know if I can let the dimension of the rwadf change via the circulation. How should I write the R code??
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From william108 at gmail.com  Sun Aug 24 02:52:35 2014
From: william108 at gmail.com (Bill)
Date: Sun, 24 Aug 2014 09:52:35 +0900
Subject: [R] converting dataframe into multiple time series
Message-ID: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>

Hello. Can someone suggest how to do this:

for (i in 2:length(colnames(allvar.df))) {
var=colnames(allvar.df)[i]
timeSeriesName = paste(var,".time.series")
varRef=paste(var,".df$",var)
varDate=paste(var,".df$date")
timeSeriesName <- ts(varRef,
start = c(year(min(varDate)),month(min(varDate))),
end = c(year(max(varDate)),month(max(varDate))),
frequency=12)
}

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Sun Aug 24 03:18:27 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 23 Aug 2014 20:18:27 -0500
Subject: [R] How can I let the dimension change via the circulation?
In-Reply-To: <tencent_3EE2E7647824398D5F449C1F@qq.com>
References: <tencent_3EE2E7647824398D5F449C1F@qq.com>
Message-ID: <CAAJSdjh5KYhbx0E=UkLFnc3jjQ3ELrC209PNruTriiPMiiXpwQ@mail.gmail.com>

Apparently part of your message was removed by the email software. You MUST
NOT use HTML encoded messages on this forum because the list software
removes all HTML encoded information before sending it to us. It appears
that the Matlab code was a victim of this removal. Also, don't try to paste
a "screen snap shot" or "picture". You really need to paste in just plain
text.

I tried to make a decent guess, but the only thing I can find that _might_
be what you are asking about is the Agumented Dickey-Fuller Test. I don't
even know what that _is_, even after reading the Wikipedia article.  But
that article mentioned the "tseries" package in R. It contains a function
called "adf.test()". I don't know if this is what you need or not. But you
can review it by installing "tseries" by entering the R command:
install.packages("tseries") at the R prompt. I am a system admin &
programmer, not a statistician or economist. What I read:
http://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test . But I
don't understand it.


On Sat, Aug 23, 2014 at 7:22 AM, ???? <lx900902 at qq.com> wrote:

> Here is the fraction of Matlab code for the Generalized Sup ADF Test for
> the bubble testing:
>
> The dimension of the matrix rwadft may vary via the circulation. I then
> imitate this code by the R program as the following:
> for (dim0 in 1:30){
> rwadf<-numeric(dim0)
> ....
>  in the circulation but it does not work. The dimension of the rwadf do
> not vary and I can not get the right answer.
> I want to know if I can let the dimension of the rwadf change via the
> circulation. How should I write the R code??
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Sun Aug 24 03:43:17 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 24 Aug 2014 11:43:17 +1000
Subject: [R] How can I let the dimension change via the circulation?
In-Reply-To: <CAAJSdjh5KYhbx0E=UkLFnc3jjQ3ELrC209PNruTriiPMiiXpwQ@mail.gmail.com>
References: <tencent_3EE2E7647824398D5F449C1F@qq.com>
	<CAAJSdjh5KYhbx0E=UkLFnc3jjQ3ELrC209PNruTriiPMiiXpwQ@mail.gmail.com>
Message-ID: <1905165.6u9ODf8Z01@localhost.localdomain>

On Sat, 23 Aug 2014 08:18:27 PM John McKown wrote:
> Apparently part of your message was removed by the email software. 
You MUST
> NOT use HTML encoded messages on this forum because the list 
software
> removes all HTML encoded information before sending it to us. It 
appears
> that the Matlab code was a victim of this removal. Also, don't try to 
paste
> a "screen snap shot" or "picture". You really need to paste in just plain
> text.
> 
> I tried to make a decent guess, but the only thing I can find that 
_might_
> be what you are asking about is the Agumented Dickey-Fuller Test. I 
don't
> even know what that _is_, even after reading the Wikipedia article.  But
> that article mentioned the "tseries" package in R. It contains a function
> called "adf.test()". I don't know if this is what you need or not. But you
> can review it by installing "tseries" by entering the R command:
> install.packages("tseries") at the R prompt. I am a system admin &
> programmer, not a statistician or economist. What I read:
> http://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test . 
But I
> don't understand it.

That is a very cool answer to a really difficult question.

Jim


From dwinsemius at comcast.net  Sun Aug 24 03:45:34 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 23 Aug 2014 18:45:34 -0700
Subject: [R] converting dataframe into multiple time series
In-Reply-To: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>
References: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>
Message-ID: <0B5C0197-BD92-46C6-A249-76D28A3440C4@comcast.net>


On Aug 23, 2014, at 5:52 PM, Bill wrote:

> Hello. Can someone suggest how to do this:
> 

Do? .... what? If you are failing with a language that is not your native tongue, then perhaps trying to explain the background and then the goals in English will make the task more understandable, to both you and your audience.

> for (i in 2:length(colnames(allvar.df))) {

We need to know the structure of all.df.

> var=colnames(allvar.df)[i]
> timeSeriesName = paste(var,".time.series")

> varRef=paste(var,".df$",var)
> varDate=paste(var,".df$date")

That could be many things. Have you looked to see what it is? Offhand I would guess that it is a multi-element character vector.

> timeSeriesName <- ts(varRef,

ts takes an object-name as its first argument. A length-1 character vector, which is probably what varRef now is, is not an R name. Perhaps get(varRef) would return the object you seek.


> start = c(year(min(varDate)),month(min(varDate))),

I suspect a similar problem with not understanding R syntax will be setting you up for failure here. `varDate` is a character vector since you created it with `paste`, not an R name. R is not a macro language.

> end = c(year(max(varDate)),month(max(varDate))),
> frequency=12)
> }
> 
> 	[[alternative HTML version deleted]]

Have you read the Posting Guide? (And have you worked through "Introduction to R"?)

> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From h.wickham at gmail.com  Sun Aug 24 04:07:07 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 23 Aug 2014 21:07:07 -0500
Subject: [R] loading saved files with objects in same names
In-Reply-To: <53F29AAC.8000009@yeah.net>
References: <53F29AAC.8000009@yeah.net>
Message-ID: <CABdHhvF=h9fOfi3ZqsgGMrM_Jb5_oj8e_KU9w0C-it68ThdsvQ@mail.gmail.com>

In the future, you can avoid this problem by using saveRDS and readRDS.

Hadley

On Mon, Aug 18, 2014 at 7:30 PM, Jinsong Zhao <jszhao at yeah.net> wrote:
> Hi there,
>
> I have several saved data files (e.g., A.RData, B.RData and C.RData). In
> each file, there are some objects with same names but different contents.
> Now, I need to compare those objects through plotting. However, I can't find
> a way to load them into a workspace. The only thing I can do is to rename
> them and then save and load again.
>
> Is there a convenient to load those objects?
>
> Thanks a lot in advance.
>
> Best regards,
> Jinsong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From j.tosovsky at email.cz  Sun Aug 24 09:51:03 2014
From: j.tosovsky at email.cz (Jan Tosovsky)
Date: Sun, 24 Aug 2014 09:51:03 +0200
Subject: [R] Filled vector contours
Message-ID: <001701cfbf70$2797dce0$76c796a0$@tosovsky@email.cz>

Dear All,

I am trying to create vector output (SVG) of filled contours. 

I've found two approaches so far:

(1)
library('lattice')
svg("D:/test.svg")
filled.contour(volcano)
#levelplot(volcano, panel=panel.levelplot.raster) # panel.levelplot.raster
will make it raster
dev.off()

(2)
library("raster")
svg("D:/test.svg")
rr <- raster(t(volcano))
rc <- cut(rr, breaks= 10)
pols <- rasterToPolygons(rc, dissolve=T)
spplot(pols)
dev.off()

But I'd like to get smooth closed polygons not broken into small cells.

Are there better methods in R ?

Thanks, Jan


From ripley at stats.ox.ac.uk  Sun Aug 24 12:19:38 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 24 Aug 2014 11:19:38 +0100
Subject: [R] Filled vector contours
In-Reply-To: <001701cfbf70$2797dce0$76c796a0$@tosovsky@email.cz>
References: <001701cfbf70$2797dce0$76c796a0$@tosovsky@email.cz>
Message-ID: <53F9BC3A.4070405@stats.ox.ac.uk>

On 24/08/2014 08:51, Jan Tosovsky wrote:
> Dear All,
>
> I am trying to create vector output (SVG) of filled contours.
>
> I've found two approaches so far:
>
> (1)
> library('lattice')
> svg("D:/test.svg")
> filled.contour(volcano)
> #levelplot(volcano, panel=panel.levelplot.raster) # panel.levelplot.raster
> will make it raster
> dev.off()
>
> (2)
> library("raster")
> svg("D:/test.svg")
> rr <- raster(t(volcano))
> rc <- cut(rr, breaks= 10)
> pols <- rasterToPolygons(rc, dissolve=T)
> spplot(pols)
> dev.off()
>
> But I'd like to get smooth closed polygons not broken into small cells.

But the region between two contours is not in general a closed polygon.

> Are there better methods in R ?

Neither of those are 'in R'!

So you need to define your terms, precisely.  How can a polygon (with 
piecewise linear boundaries) be 'smooth'?

But you could get a long way by looking at the following

?contourLines
?polygon
?grid::grid.polygon

all of which are part of R.  R is a fully-fledged programming language 
and you could write SVG directly from R: using the svg device is limited 
by the steps to the R graphics primitives (see the 'R Internals' manual) 
and cairographics.

> Thanks, Jan



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From john.archie.mckown at gmail.com  Sun Aug 24 16:56:51 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 24 Aug 2014 09:56:51 -0500
Subject: [R] How can I let the dimension change via the circulation?
In-Reply-To: <tencent_26C7F2BC0E716D5D3801D154@qq.com>
References: <tencent_3EE2E7647824398D5F449C1F@qq.com>
	<CAAJSdjh5KYhbx0E=UkLFnc3jjQ3ELrC209PNruTriiPMiiXpwQ@mail.gmail.com>
	<tencent_26C7F2BC0E716D5D3801D154@qq.com>
Message-ID: <CAAJSdjjtnJi2+9GKk5edV_RXescpEd7=7k89AS3_BR-CAjs24w@mail.gmail.com>

You replied only to me. But I'm replying to you directly and the r-help
list as well. Hopefully someone there will be able to help you with this
statistical methodology. Please remember that I'm very ignorant of
statistics (I made a C in it in college). Your reply did seem quite
understandable to me, given my abysmal ignorance of statistics. Given that,
I am bowing out of this discussion because I would only add confusion and
not enlightenment.


On Sat, Aug 23, 2014 at 10:25 PM, ???? <lx900902 at qq.com> wrote:

> I would like to know hou to do the recursive regression in R. Suppose
> there are 400 observations. The regression starts at the r1th of the
> sequence and ends at r2th. First let the regression sequence start at 1st
> obesrvations and end at 40th. We get the first t-statistics from that
> regression. Then let the end point increase 1 in turn. The starting point
> also varies. For instance, during the second regression , first we run the
> regression via the sample 1-41 and then we run the regression via the
> sample 2-41. We get two t-statistics and we choose the max of the two. If
> the end point is 42, we choose the maximum t-statistics from the following
> three regression : sample 1-42,2-42,3-42.
>
>
> ------------------ ???? ------------------
> *???:* "John McKown";<john.archie.mckown at gmail.com>;
> *????:* 2014?8?24?(???) ??9:18
> *???:* "????"<lx900902 at qq.com>;
> *??:* "r-help"<r-help at r-project.org>;
> *??:* Re: [R] How can I let the dimension change via the circulation?
>
> Apparently part of your message was removed by the email software. You
> MUST NOT use HTML encoded messages on this forum because the list software
> removes all HTML encoded information before sending it to us. It appears
> that the Matlab code was a victim of this removal. Also, don't try to paste
> a "screen snap shot" or "picture". You really need to paste in just plain
> text.
>
> I tried to make a decent guess, but the only thing I can find that _might_
> be what you are asking about is the Agumented Dickey-Fuller Test. I don't
> even know what that _is_, even after reading the Wikipedia article.  But
> that article mentioned the "tseries" package in R. It contains a function
> called "adf.test()". I don't know if this is what you need or not. But you
> can review it by installing "tseries" by entering the R command:
> install.packages("tseries") at the R prompt. I am a system admin &
> programmer, not a statistician or economist. What I read:
> http://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test . But I
> don't understand it.
>
>
> On Sat, Aug 23, 2014 at 7:22 AM, ???? <lx900902 at qq.com> wrote:
>
>> Here is the fraction of Matlab code for the Generalized Sup ADF Test for
>> the bubble testing:
>>
>> The dimension of the matrix rwadft may vary via the circulation. I then
>> imitate this code by the R program as the following:
>> for (dim0 in 1:30){
>> rwadf<-numeric(dim0)
>> ....
>>  in the circulation but it does not work. The dimension of the rwadf do
>> not vary and I can not get the right answer.
>> I want to know if I can let the dimension of the rwadf change via the
>> circulation. How should I write the R code??
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown
>



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Aug 24 17:26:10 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 24 Aug 2014 08:26:10 -0700
Subject: [R] How can I let the dimension change via the circulation?
In-Reply-To: <CAAJSdjjtnJi2+9GKk5edV_RXescpEd7=7k89AS3_BR-CAjs24w@mail.gmail.com>
References: <tencent_3EE2E7647824398D5F449C1F@qq.com>
	<CAAJSdjh5KYhbx0E=UkLFnc3jjQ3ELrC209PNruTriiPMiiXpwQ@mail.gmail.com>
	<tencent_26C7F2BC0E716D5D3801D154@qq.com>
	<CAAJSdjjtnJi2+9GKk5edV_RXescpEd7=7k89AS3_BR-CAjs24w@mail.gmail.com>
Message-ID: <722E4E2E-9028-4B24-8093-D024645CCE60@comcast.net>


On Aug 24, 2014, at 7:56 AM, John McKown wrote:

> You replied only to me. But I'm replying to you directly and the r-help
> list as well. Hopefully someone there will be able to help you with this
> statistical methodology. Please remember that I'm very ignorant of
> statistics (I made a C in it in college). Your reply did seem quite
> understandable to me, given my abysmal ignorance of statistics. Given that,
> I am bowing out of this discussion because I would only add confusion and
> not enlightenment.
> 
> 
> On Sat, Aug 23, 2014 at 10:25 PM, ???? <lx900902 at qq.com> wrote:
> 
>> I would like to know hou to do the recursive regression in R.

To lx900902;

I would not have used that term for the procedure that is described but when I do searches with that phrase is am able find several citations to similar question on R-help in the past. So you should "learn to search"

http://www.rseek.org/

-- 
David.


>> Suppose
>> there are 400 observations. The regression starts at the r1th of the
>> sequence and ends at r2th. First let the regression sequence start at 1st
>> obesrvations and end at 40th. We get the first t-statistics from that
>> regression. Then let the end point increase 1 in turn. The starting point
>> also varies. For instance, during the second regression , first we run the
>> regression via the sample 1-41 and then we run the regression via the
>> sample 2-41. We get two t-statistics and we choose the max of the two. If
>> the end point is 42, we choose the maximum t-statistics from the following
>> three regression : sample 1-42,2-42,3-42.
>> 
>> 
>> ------------------ ???? ------------------
>> *???:* "John McKown";<john.archie.mckown at gmail.com>;
>> *????:* 2014?8?24?(???) ??9:18
>> *???:* "????"<lx900902 at qq.com>;
>> *??:* "r-help"<r-help at r-project.org>;
>> *??:* Re: [R] How can I let the dimension change via the circulation?
>> 
>> Apparently part of your message was removed by the email software. You
>> MUST NOT use HTML encoded messages on this forum because the list software
>> removes all HTML encoded information before sending it to us. It appears
>> that the Matlab code was a victim of this removal. Also, don't try to paste
>> a "screen snap shot" or "picture". You really need to paste in just plain
>> text.
>> 
>> I tried to make a decent guess, but the only thing I can find that _might_
>> be what you are asking about is the Agumented Dickey-Fuller Test. I don't
>> even know what that _is_, even after reading the Wikipedia article.  But
>> that article mentioned the "tseries" package in R. It contains a function
>> called "adf.test()". I don't know if this is what you need or not. But you
>> can review it by installing "tseries" by entering the R command:
>> install.packages("tseries") at the R prompt. I am a system admin &
>> programmer, not a statistician or economist. What I read:
>> http://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test . But I
>> don't understand it.
>> 
>> 
>> On Sat, Aug 23, 2014 at 7:22 AM, ???? <lx900902 at qq.com> wrote:
>> 
>>> Here is the fraction of Matlab code for the Generalized Sup ADF Test for
>>> the bubble testing:
>>> 
>>> The dimension of the matrix rwadft may vary via the circulation. I then
>>> imitate this code by the R program as the following:
>>> for (dim0 in 1:30){
>>> rwadf<-numeric(dim0)
>>> ....
>>> in the circulation but it does not work. The dimension of the rwadf do
>>> not vary and I can not get the right answer.
>>> I want to know if I can let the dimension of the rwadf change via the
>>> circulation. How should I write the R code??
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> --
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>> 
>> Maranatha! <><
>> John McKown
>> 
> 
> 
> 
> -- 
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
> 
> Maranatha! <><
> John McKown
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From john.archie.mckown at gmail.com  Sun Aug 24 19:17:40 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sun, 24 Aug 2014 12:17:40 -0500
Subject: [R] converting dataframe into multiple time series
In-Reply-To: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>
References: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>
Message-ID: <CAAJSdjhcnB0Na0KSm+tViEmwPT1zmoP967wLm2PKSWExOrLeuw@mail.gmail.com>

On Aug 23, 2014 7:54 PM, "Bill" <william108 at gmail.com> wrote:
>
> Hello. Can someone suggest how to do this:
>
> for (i in 2:length(colnames(allvar.df))) {
> var=colnames(allvar.df)[i]
> timeSeriesName = paste(var,".time.series")
> varRef=paste(var,".df$",var)
> varDate=paste(var,".df$date")
> timeSeriesName <- ts(varRef,
> start = c(year(min(varDate)),month(min(varDate))),
> end = c(year(max(varDate)),month(max(varDate))),
> frequency=12)
> }
>

Please don't post in HTML. I understand that most email  clients default to
this. Thanks.

Instead of using R-line pseudo-code, you might want to just tell us,
inplain English, what your desired results are. Also, if you can would you
please paste a small subset of your data, from allvar.df, using the dput()
function. Perhaps from a command like:
dput(head(allvar.df));
That way we can easily cut and paste that into an R session for
experimentation.

=== guessing ===

My guess is that you have a data frame, named allvar.df. This data.frame
contains a number of columns. The first column is called "date". The 2nd
and subsequent columns are independent data. You want to separate each of
those columns into its own time series. You want each time series to exist
in the current environment (global?) as separate variables where the name
of each variable is the name of the original column, suffixed with
".time.series". Some of your code is confusing to me, however. Such as:
what is "varRef" and "varDate"? I would have thought that they are columns
in the allvar.df, but the code isn't anything like that. The code says that
for each column in allvar.df, there already exists another data.frame whose
name is the column name, suffixed with ".df". And it contains the desired
date and data for the time series. This simply doesn't make sense to me.

I will assume that the data are indeed in columns in allvar.df. But that
leads to why are varDate, start, and end assigned in the for() loop? They
should be invariant if they are indeed in allvar.df. In any case, I will
give you some code which echos my, likely incorrect, assumptions.

local( ( # run all the below in a local environment
  # so as to not corrupt the surrounding environment.
 # get names of columns
 all.col.names <- colnames(allvar.df);
 #drop the first one
 all.col.names <- all.col.names[2:length(all.col.names)];
 # make the date field a POSIXlt for easy of use later
 temp.date <- as.POSIXlt(allvar.df$date);
 ts.start <- c(min(temp.date$year)+1900,min(temp.date$mon)+1);
 ts.end <- c(max(temp.date$year)+1900,max(temp.date$mon)+1);
 for(col.name in all.col.names) {
   x <- ts(allvar.df[col.name],
           start=ts.start,
           end=ts.end,
           frequency=12);
 # create, or replace, a global variable using assign()
   assign(paste0(col.name,".time.series"),x, envir=.GlobalEnv);
 }
} ); # end of local environment

Well, the above is my "best guess" at what you might want. I think that
what you really needed to know was about the assign() function to create a
new variable in an environment and the fact that you can reference the
column of a data.frame() simply by indexing by the column name as a
character string. Those are the "magic" ingredients above.

	[[alternative HTML version deleted]]


From j.tosovsky at email.cz  Sun Aug 24 22:30:19 2014
From: j.tosovsky at email.cz (Jan Tosovsky)
Date: Sun, 24 Aug 2014 22:30:19 +0200
Subject: [R] Filled vector contours
In-Reply-To: <53F9BC3A.4070405@stats.ox.ac.uk>
References: <001701cfbf70$2797dce0$76c796a0$@tosovsky@email.cz>
	<53F9BC3A.4070405@stats.ox.ac.uk>
Message-ID: <000901cfbfda$392beef0$ab83ccd0$@tosovsky@email.cz>

On 2014-08-24 Prof Brian Ripley wrote:
> On 24/08/2014 08:51, Jan Tosovsky wrote:
> >
> > I am trying to create vector output (SVG) of filled contours.
> >
> > I've found two approaches so far:
> >
> > (1)
> > library('lattice')
> > svg("D:/test.svg")
> > filled.contour(volcano)
> > #levelplot(volcano, panel=panel.levelplot.raster)
> > dev.off()
> >
> > (2)
> > library("raster")
> > svg("D:/test.svg")
> > rr <- raster(t(volcano))
> > rc <- cut(rr, breaks= 10)
> > pols <- rasterToPolygons(rc, dissolve=T)
> > spplot(pols)
> > dev.off()
> >
> > But I'd like to get smooth closed polygons not broken into small
> > cells.
>
> How can a polygon be 'smooth'?

This was related to the result of example (2), which is more coarse
comparing it to the result of (1).

>
> But the region between two contours is not in general a closed polygon.

I appologize for not being precise here.

My goal is to get something like this:
http://drifted.in/other/contours/composition.svg

which is a composition of level plots, e.g.
http://drifted.in/other/contours/level_plot.svg

By 'level plot' I mean the cut of the data at certain level. It is always a
closed polygon (or multiple polygons) consisting of contour lines connected,
if required, by border lines. 

For me it is preferred way over 'isoband', which doesn't include areas
hidden by upper levels:
http://drifted.in/other/contours/isoband.svg

Please note I am not sure if this terminology (isoband, level plot, etc) is
correct.

> > Are there better methods in R ?
> 
> Neither of those are 'in R'!
> But you could get a long way by looking at the following
> 
> ?contourLines
> ?polygon
> ?grid::grid.polygon
> 
> all of which are part of R.  R is a fully-fledged programming 
> language and you could write SVG directly from R: using the svg device 
> is limited by the steps to the R graphics primitives (see the 'R 
> Internals' manual) and cairographics.
> 

Thanks a lot for detailed explanation. Now I understand it more.

Most of contouring libraries create the list of line fragments. And this
seems to be the case also of R's 'contourLines'.

But filling the areas requires a further post-processing (joining line
fragments, joining contours, set the correct direction to preserve holes).
And if I understand correctly, this is let to R 'libraries'. Unfortunately,
none of these two is optimal for my use case.

If there is any hidden option or another library (implementing e.g. Marching
squares) which could produce output similar to that linked SVG file, I am
one big ear.

Thanks, Jan


From dwinsemius at comcast.net  Mon Aug 25 00:58:27 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 24 Aug 2014 15:58:27 -0700
Subject: [R] Filled vector contours
In-Reply-To: <000901cfbfda$392beef0$ab83ccd0$@tosovsky@email.cz>
References: <001701cfbf70$2797dce0$76c796a0$@tosovsky@email.cz>
	<53F9BC3A.4070405@stats.ox.ac.uk>
	<000901cfbfda$392beef0$ab83ccd0$@tosovsky@email.cz>
Message-ID: <C046DE03-F803-4911-B042-E14114B6E19B@comcast.net>


On Aug 24, 2014, at 1:30 PM, Jan Tosovsky wrote:

> On 2014-08-24 Prof Brian Ripley wrote:
>> On 24/08/2014 08:51, Jan Tosovsky wrote:
>>> 
>>> I am trying to create vector output (SVG) of filled contours.
>>> 
>>> I've found two approaches so far:
>>> 
>>> (1)
>>> library('lattice')
>>> svg("D:/test.svg")
>>> filled.contour(volcano)
>>> #levelplot(volcano, panel=panel.levelplot.raster)
>>> dev.off()
>>> 
>>> (2)
>>> library("raster")
>>> svg("D:/test.svg")
>>> rr <- raster(t(volcano))
>>> rc <- cut(rr, breaks= 10)
>>> pols <- rasterToPolygons(rc, dissolve=T)
>>> spplot(pols)
>>> dev.off()
>>> 
>>> But I'd like to get smooth closed polygons not broken into small
>>> cells.
>> 
>> How can a polygon be 'smooth'?
> 
> This was related to the result of example (2), which is more coarse
> comparing it to the result of (1).
> 
>> 
>> But the region between two contours is not in general a closed polygon.
> 
> I appologize for not being precise here.
> 
> My goal is to get something like this:
> http://drifted.in/other/contours/composition.svg
> 
> which is a composition of level plots, e.g.
> http://drifted.in/other/contours/level_plot.svg
> 
> By 'level plot' I mean the cut of the data at certain level. It is always a
> closed polygon (or multiple polygons) consisting of contour lines connected,
> if required, by border lines. 
> 
> For me it is preferred way over 'isoband', which doesn't include areas
> hidden by upper levels:
> http://drifted.in/other/contours/isoband.svg
> 
> Please note I am not sure if this terminology (isoband, level plot, etc) is
> correct.
> 

Most people with any R experience would have thought that "levelplot" referred to something like:
(Example 6.9 from Lattice, by Deepayan Sarkar to which I have only added the contour line parameter which it appears is what you were seeking.)

env <- environmental 
env$ozone <- env$ozone^(1/3) 
env$Radiation <- equal.count(env$radiation, 4)
fm1.env <- lm(ozone ~ radiation * temperature * wind, env) 
fm2.env <- loess(ozone ~ wind * temperature * radiation, env, span = 0.75, degree = 1) 
fm3.env <- loess(ozone ~ wind * temperature * radiation, env, parametric = c("radiation", "wind"), span = 0.75, degree = 2) 
library("locfit") ; library(lattice)
fm4.env <- locfit(ozone ~ wind * temperature * radiation, env) 
w.mesh <- with(env, do.breaks(range(wind), 50)) 
t.mesh <- with(env, do.breaks(range(temperature), 50)) 
r.mesh <- with(env, do.breaks(range(radiation), 3)) 
grid <- expand.grid(wind = w.mesh, temperature = t.mesh, radiation = r.mesh) 
grid[["fit.linear"]] <- predict(fm1.env, newdata = grid) 
grid[["fit.loess.1"]] <- as.vector(predict(fm2.env, newdata = grid)) 
grid[["fit.loess.2"]] <- as.vector(predict(fm3.env, newdata = grid)) 
grid[["fit.locfit"]] <- predict(fm4.env, newdata = grid)

png()
print(levelplot(fit.linear + fit.loess.1 + fit.loess.2 + fit.locfit ~ wind * temperature | radiation, data = grid, contour=TRUE))
dev.off()



-- 
David.

>>> Are there better methods in R ?
>> 
>> Neither of those are 'in R'!
>> But you could get a long way by looking at the following
>> 
>> ?contourLines
>> ?polygon
>> ?grid::grid.polygon
>> 
>> all of which are part of R.  R is a fully-fledged programming 
>> language and you could write SVG directly from R: using the svg device 
>> is limited by the steps to the R graphics primitives (see the 'R 
>> Internals' manual) and cairographics.
>> 
> 
> Thanks a lot for detailed explanation. Now I understand it more.
> 
> Most of contouring libraries create the list of line fragments. And this
> seems to be the case also of R's 'contourLines'.
> 
> But filling the areas requires a further post-processing (joining line
> fragments, joining contours, set the correct direction to preserve holes).
> And if I understand correctly, this is let to R 'libraries'. Unfortunately,
> none of these two is optimal for my use case.
> 
> If there is any hidden option or another library (implementing e.g. Marching
> squares) which could produce output similar to that linked SVG file, I am
> one big ear.
> 
> Thanks, Jan
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jwd at surewest.net  Mon Aug 25 03:53:52 2014
From: jwd at surewest.net (jwd)
Date: Sun, 24 Aug 2014 18:53:52 -0700
Subject: [R] converting dataframe into multiple time series
In-Reply-To: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>
References: <CAJnbHtL-Cgngmb3u1zfzOn8m_DZrmP=TjGNkEBmU1BOMAO+9zw@mail.gmail.com>
Message-ID: <20140824185352.47dd9853@draco>

On Sun, 24 Aug 2014 09:52:35 +0900
Bill <william108 at gmail.com> wrote:

> Hello. Can someone suggest how to do this:
> 
> for (i in 2:length(colnames(allvar.df))) {
> var=colnames(allvar.df)[i]
> timeSeriesName = paste(var,".time.series")
> varRef=paste(var,".df$",var)
> varDate=paste(var,".df$date")
> timeSeriesName <- ts(varRef,
> start = c(year(min(varDate)),month(min(varDate))),
> end = c(year(max(varDate)),month(max(varDate))),
> frequency=12)
> }
> 
First, you should probably do some reading.  For starters look at
Modern Applied Statics with S by Venables and Ripley, possibly
Adler's R In a Nutshel and Maindonald and Brown's Data Analysis and
Graphics Using R, and definitely Shumway and Stoffer's Time Series
Analysis and Its Applications: With Examples in R.  READ the sections
on time series. You also want to look into - minimally - xts and zoo.
Depending on the nature of your data - examples are really necessary -
either xts or zoo may be what you want.  Or, you could simply export
each variable in your data.frame to a separate time series.  

JWDougherty


From rainersachs at berkeley.edu  Mon Aug 25 06:01:37 2014
From: rainersachs at berkeley.edu (Rainer K. SACHS)
Date: Sun, 24 Aug 2014 21:01:37 -0700
Subject: [R] adaptivetau with time-dependent rate "parameters";
 non-autonomous population dynamics via Monte Carlo
Message-ID: <CA+G8hjycB7Mw03dyN0dKsrvEhX8ukzgEVdofc02UCGuqH03Qtg@mail.gmail.com>

I am interested in "non-autonomous" population dynamics. The simplest
example is the deterministic ode of exponential growth or decay of a cell
population with average size s(t)>0:
ds/dt=M(t) s. Here M(t), instead of being constant, is an explicit function
of time and is independent of s, as can occur if the environment of s, e.g.
the temperature, changes in time due to external process independent of s.

Of course this equation, as well as some of its stochastic analogues, can
be solved explicitly, but more complicated stochastic models require Monte
Carlo approaches. I thought adaptivetau should work but it seems to balk at
such externally imposed time dependence. For example in the R-script
attached (an artificial example where one doesn't really need adaptivetau
because exact solutions happen to be available) k=0 gives an autonomous
problem and adaptivetau works, but for k=1 one gets time-dependent rates
per cell and adaptivetau appears to just use the initial parameter values
(corresponding to M(0) above) and give nonsense.


I read the package description and the vignettes by Johnson but didn't find
a solution. Is there a simple one?

From rhelpmaillist at 163.com  Mon Aug 25 08:07:06 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 25 Aug 2014 14:07:06 +0800 (CST)
Subject: [R]  What the difference between .Golbalenv and package:base?
Message-ID: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>



Dear rusers,

? ? As we know, there are a lot of environments in the search() path, such as?? .Golbalenv and package:base .
And ?i can just use ?.Golbalenv$a ,.Golbalenv$b to use the virable, ?but i must use as.envrionment("package:base") to find virable, i feel it not very convenient.


For example, when i use the following codes to add a new env into the search() path.



> tmp<-attach(NULL,name="new_name")
> assign("a",2,envir=as.environment("new_name"))
> a
[1] 2
> as.environment("new_name")$a
[1] 2
?I must always convert the name to the environment, How can i just use the following form:



> tmp<-attach(NULL,name="new_name")
> assign("a",2,envir=new_name) ? #like using ?.GlobalEnv
> a
[1] 2
> new_name$a

[1] 2







--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From ivan.calandra at univ-fcomte.fr  Mon Aug 25 09:23:19 2014
From: ivan.calandra at univ-fcomte.fr (Ivan Calandra)
Date: Mon, 25 Aug 2014 09:23:19 +0200
Subject: [R] require() but for source()d files
In-Reply-To: <CAFDcVCSoXdW=s-ag3DnLYLUZu-5wQPjb9a2E8nS4qWz3TPzvEA@mail.gmail.com>
References: <53F60473.4020601@univ-fcomte.fr>
	<CAFDcVCSoXdW=s-ag3DnLYLUZu-5wQPjb9a2E8nS4qWz3TPzvEA@mail.gmail.com>
Message-ID: <53FAE467.2050903@univ-fcomte.fr>

Thank you Henrik, that's exactly what I'm looking for!
Ivan

--
Ivan Calandra
University of Franche-Comt?
Laboratoire Chrono-Environnement
Bureau ATER -107L
16, Route de Gray
25030 Besan?on Cedex, France
ivan.calandra at univ-fcomte.fr
+33 (0) 381 66 20 60
http://chrono-environnement.univ-fcomte.fr/spip.php?article1830

Le 21/08/14 18:15, Henrik Bengtsson a ?crit :
>
> On Aug 21, 2014 7:40 AM, "Ivan Calandra" <ivan.calandra at univ-fcomte.fr 
> <mailto:ivan.calandra at univ-fcomte.fr>> wrote:
> >
> > Dear useRs,
> >
> > I'm looking for something like require() but which will work on 
> source()d files.
> >
> > I have a .R file with lots of functions and I'm writing a new 
> function (say, 'foo') that depends on the functions from this file.
> >
> > Until now, I have always source()d the .R file before running 'foo'.
> > But I would like to include some code in 'foo' to source() the file 
> only if it hasn't been done yet, and do nothing if the file has 
> already been source()d in the session.
>
> R.utils::sourceTo(file, modifiedOnly=TRUE)
>
> should do it. It will always source the file once. Also, contrary to 
> source() it default is to use local=TRUE.
>
> Henrik
>
> > So, the same behavior as require() with packages, but with a .R file.
> >
> > Does it make sense? I could provide an example if you think it would 
> help.
> >
> > Thank you in advance,
> > Ivan
> >
> > --
> > Ivan Calandra
> > University of Franche-Comt?
> > Laboratoire Chrono-Environnement
> > Bureau ATER -107L
> > 16, Route de Gray
> > 25030 Besan?on Cedex, France
> > ivan.calandra at univ-fcomte.fr <mailto:ivan.calandra at univ-fcomte.fr>
> > +33 (0) 381 66 20 60
> > http://chrono-environnement.univ-fcomte.fr/spip.php?article1830
> >
> > ______________________________________________
> > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From s.wood at bath.ac.uk  Mon Aug 25 14:20:45 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 25 Aug 2014 13:20:45 +0100
Subject: [R] bam (mgcv) not using the specified number of cores
In-Reply-To: <53F6D187.1030401@gmail.com>
References: <53F5DDD6.8000006@gmail.com> <53F5F436.70704@bath.ac.uk>
	<53F6D187.1030401@gmail.com>
Message-ID: <53FB2A1D.7060602@bath.ac.uk>

Hi Andrew,

In some of the shots you sent then top was reporting several cores 
working. I think the problem here may be to do with the way bam is 
parallelized - at present only part of the computation is in parallel - 
the model matrix QR decomposition part. The smoothing parameter 
selection is still single cored (although we are working on that), so if 
you watch top, you'll usually see multi-core and single core phases 
alternating with each other. The strategy works best in n>>p situations 
with few smoothing parameters.

For the case where you used 31 cores, there was a bug in earlier mgcv 
versions in which it was assumed that when the model matrix is split 
into chunks for processing, each chunk would have more rows than 
columns. If you upgrade to the current mgcv version then this is fixed. 
However using 31 cores is liable to actually be less efficient than 
using fewer cores with the n to p (number of data to number of 
coefficients) ratio that you seem to have. This is because the work 
being done by each core is rather little, so that the overhead of 
stitching the cores' work back together becomes too high. Using 
'use.chol=TRUE' would reduce the overheads here (although it uses a 
slightly less stable algorithm than the default).

best,
Simon


On 22/08/14 06:13, Andrew Crane-Droesch wrote:
> Hi Simon,
>
> (resending with all images as imgur so as to not bounce from list)
>
> Thanks for the reply.  I've tried to reproduce the error, but I don't
> know how to show output from `top` any other way than with screenshots,
> so please excuse that.
>
> Here are screenshots of what happens when I run with two
> http://imgur.com/i26GKPo
>
> and three
> http://imgur.com/8SL7scy
>
> cores.  In the former, it seems to be working on one core, and in the
> latter, it appears to be working on three.  When reproducing the error,
> I'm getting behavior that isn't entirely consistent -- sometimes it
> "behaves" and operates on the asked-for number of cores, and other times
> not.
>
> I'm also attaching a screenshot
> http://imgur.com/bJfuS6R
> showing terminal output from a remote cluster when I run my full model
> (N=67K) rather than a subset (N=7K) -- I get that error "Error in
> qr.qty(qrx, f) : right-hand side should have 60650 not 118451 rows ..."
> I suppose this is a memory overload problem?  Any suggestions on how to
> get bam to not call for more memory than the node has available would be
> welcome, though I suspect that is a supercomputing problem rather than a
> mgcv problem.  I don't know much about memory management, except that R
> doesn't do it explicitly.
>
> Thanks,
> Andrew
>
> sessionInfo() for local machine:
> 1> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] parallel  stats     graphics  grDevices utils datasets  methods
> [8] base
>
> other attached packages:
> [1] mgcv_1.7-26  nlme_3.1-111
>
> loaded via a namespace (and not attached):
> [1] grid_3.0.2      lattice_0.20-23 Matrix_1.1-4
> 1>
> On 08/21/2014 04:29 PM, Simon Wood wrote:
>> Hi Andrew,
>>
>> Could you provide a bit more information, please. In particular the
>> results of sessionInfo() and the code that caused this weird behaviour
>> (+ an indication of dataset size).
>>
>> best,
>> Simon
>>
>> On 21/08/14 12:53, Andrew Crane-Droesch wrote:
>>> I am getting strange behavior when trying to fit models to large
>>> datasets using bam.  I am working on a 4-core machine, but I think that
>>> there may be 2 physical cores that the computer uses as 4 cores in some
>>> sense that I don't understand.
>>>
>>> When I run the bam using makeCluster(3), the model runs on one core. But
>>> when I run it on makeCluster(2), top shoes me that three of my cores are
>>> taken up to full capacity, and my computer slows down or crashes.
>>>
>>> How can I get it to truly run on 2 cores?
>>>
>>> I'm on a thinkpad X230, running ubuntu.
>>>
>>> Thanks,
>>> Andrew
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From s.wood at bath.ac.uk  Mon Aug 25 15:16:53 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Mon, 25 Aug 2014 14:16:53 +0100
Subject: [R] bam (mgcv) not using the specified number of cores
In-Reply-To: <53FB2A1D.7060602@bath.ac.uk>
References: <53F5DDD6.8000006@gmail.com>
	<53F5F436.70704@bath.ac.uk>	<53F6D187.1030401@gmail.com>
	<53FB2A1D.7060602@bath.ac.uk>
Message-ID: <53FB3745.3010600@bath.ac.uk>

oops, I just realised that the fix referred to below is in mgcv 1.8-3 - 
not yet on CRAN.

On 25/08/14 13:20, Simon Wood wrote:
> Hi Andrew,
>
> In some of the shots you sent then top was reporting several cores
> working. I think the problem here may be to do with the way bam is
> parallelized - at present only part of the computation is in parallel -
> the model matrix QR decomposition part. The smoothing parameter
> selection is still single cored (although we are working on that), so if
> you watch top, you'll usually see multi-core and single core phases
> alternating with each other. The strategy works best in n>>p situations
> with few smoothing parameters.
>
> For the case where you used 31 cores, there was a bug in earlier mgcv
> versions in which it was assumed that when the model matrix is split
> into chunks for processing, each chunk would have more rows than
> columns. If you upgrade to the current mgcv version then this is fixed.
> However using 31 cores is liable to actually be less efficient than
> using fewer cores with the n to p (number of data to number of
> coefficients) ratio that you seem to have. This is because the work
> being done by each core is rather little, so that the overhead of
> stitching the cores' work back together becomes too high. Using
> 'use.chol=TRUE' would reduce the overheads here (although it uses a
> slightly less stable algorithm than the default).
>
> best,
> Simon
>
>
> On 22/08/14 06:13, Andrew Crane-Droesch wrote:
>> Hi Simon,
>>
>> (resending with all images as imgur so as to not bounce from list)
>>
>> Thanks for the reply.  I've tried to reproduce the error, but I don't
>> know how to show output from `top` any other way than with screenshots,
>> so please excuse that.
>>
>> Here are screenshots of what happens when I run with two
>> http://imgur.com/i26GKPo
>>
>> and three
>> http://imgur.com/8SL7scy
>>
>> cores.  In the former, it seems to be working on one core, and in the
>> latter, it appears to be working on three.  When reproducing the error,
>> I'm getting behavior that isn't entirely consistent -- sometimes it
>> "behaves" and operates on the asked-for number of cores, and other times
>> not.
>>
>> I'm also attaching a screenshot
>> http://imgur.com/bJfuS6R
>> showing terminal output from a remote cluster when I run my full model
>> (N=67K) rather than a subset (N=7K) -- I get that error "Error in
>> qr.qty(qrx, f) : right-hand side should have 60650 not 118451 rows ..."
>> I suppose this is a memory overload problem?  Any suggestions on how to
>> get bam to not call for more memory than the node has available would be
>> welcome, though I suspect that is a supercomputing problem rather than a
>> mgcv problem.  I don't know much about memory management, except that R
>> doesn't do it explicitly.
>>
>> Thanks,
>> Andrew
>>
>> sessionInfo() for local machine:
>> 1> sessionInfo()
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] parallel  stats     graphics  grDevices utils datasets  methods
>> [8] base
>>
>> other attached packages:
>> [1] mgcv_1.7-26  nlme_3.1-111
>>
>> loaded via a namespace (and not attached):
>> [1] grid_3.0.2      lattice_0.20-23 Matrix_1.1-4
>> 1>
>> On 08/21/2014 04:29 PM, Simon Wood wrote:
>>> Hi Andrew,
>>>
>>> Could you provide a bit more information, please. In particular the
>>> results of sessionInfo() and the code that caused this weird behaviour
>>> (+ an indication of dataset size).
>>>
>>> best,
>>> Simon
>>>
>>> On 21/08/14 12:53, Andrew Crane-Droesch wrote:
>>>> I am getting strange behavior when trying to fit models to large
>>>> datasets using bam.  I am working on a 4-core machine, but I think that
>>>> there may be 2 physical cores that the computer uses as 4 cores in some
>>>> sense that I don't understand.
>>>>
>>>> When I run the bam using makeCluster(3), the model runs on one core.
>>>> But
>>>> when I run it on makeCluster(2), top shoes me that three of my cores
>>>> are
>>>> taken up to full capacity, and my computer slows down or crashes.
>>>>
>>>> How can I get it to truly run on 2 cores?
>>>>
>>>> I'm on a thinkpad X230, running ubuntu.
>>>>
>>>> Thanks,
>>>> Andrew
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From john.archie.mckown at gmail.com  Mon Aug 25 15:53:37 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 25 Aug 2014 08:53:37 -0500
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>

On Mon, Aug 25, 2014 at 1:07 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
>
> Dear rusers,
>
>     As we know, there are a lot of environments in the search() path, such as   .Golbalenv and package:base .
> And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable,  but i must use as.envrionment("package:base") to find virable, i feel it not very convenient.
>
>
> For example, when i use the following codes to add a new env into the search() path.
>
>
>
>> tmp<-attach(NULL,name="new_name")
>> assign("a",2,envir=as.environment("new_name"))
>> a
> [1] 2
>> as.environment("new_name")$a
> [1] 2
>  I must always convert the name to the environment, How can i just use the following form:
>
>
>
>> tmp<-attach(NULL,name="new_name")
>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>> a
> [1] 2
>> new_name$a
>
> [1] 2
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU

You might want to try:

new_name <- new.env();
# or if you prefer (such as in a function)
assign("new_name",new.env(),envir=.GlobalEnv);
#
# You may now assign variable into this similar to:
new_name$a <- 2;
gvar <- new_name$a; # get the variable a from environment new_name
gvar <- get("a",envir=new_name); #same thing, but wordy
attach(new_name);
a
gvar <- a;


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From dstr7320 at uni.sydney.edu.au  Mon Aug 25 14:00:09 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Mon, 25 Aug 2014 12:00:09 +0000
Subject: [R] yaxs Causes Boundary Line Colour to Change
Message-ID: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>

Why is the bottom boundary plotted in a different colour to the other three sides ?

set.seed(4444)
data <- rpois(10, 2)
plot(density(data), ann = FALSE, yaxs = 'i') # Grey bottom boundary.
plot(density(data), ann = FALSE) # All boundaries are black.

Ideally, there would be black lines on all four sides. The documentation doesn't say the colour will change.

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-unknown-linux-gnu (64-bit)

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia


From jon at thon.cc  Mon Aug 25 11:58:21 2014
From: jon at thon.cc (Jonathon Love)
Date: Mon, 25 Aug 2014 11:58:21 +0200
Subject: [R] Preventing loading of user packages
Message-ID: <53FB08BD.5030600@thon.cc>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Hi,

I'm trying to prevent the loading of packages from the 'personal
library' on an OS X machine. i.e. the packages that are normally
placed somewhere like:

~/Library/R/3.0/library

There is a file in the R.framwork directory:

/Versions/3.0/Resources/etc/Renviron

which contains a line:

R_LIBS_USER=${R_LIBS_USER-'~/Library/R/3.0/library'}

but commenting this out does not prevent R from loading from that
location.

is there a way to prevent loading from that location?

with thanks

jonathon

- -- 

JASP - A Fresh Way to Do Statistics
http://jasp-stats.org/

- --

How happy is he born and taught,
That serveth not another's will;
Whose armour is his honest thought,
And simple truth his utmost skill

This man is freed from servile bands
Of hope to rise, or fear to fall:
Lord of himself, though not of lands,
And, having nothing, yet hath all.

  -- Sir Henry Wotton





-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJT+wi9AAoJEH277gjmPGDYzkkP/0rA4bwVK9+E7Y9S2f/8+mpY
QTgGS8Q19YfFd9ZgQICM+Zb9s+cZiC60EwC8IBlBpf2fMGioKFtv8fGFrTKOFpOl
8H758D/HdkvzwpQ/XCDP+sNQQ3VNxryoKzgXV7O5vusKjnfRO8nmpldjqURnIoze
LUvUYgp3ySK3JfjZwBlpcGzahnhl95KBWQzpW2cXSJH0SaJ9jzfO6OHVEZPmJaVi
llePJqJJ36ZlI1XUt9XZIySfsw7o1efcjLNdFq2UYFExEI17bqa3DihuXRAzBBSF
1sWPQGmTGAn6N9MT7EJ7UxBiSMTvnbO/fjKNxjRGk+p89h+bmrdVmnn408QGkIe/
d+os4++sG9nLVywLduJ/tCemMfWjRVDBCwlCbTrRbehi95UqX3UF5K6a2Iq7FMV7
3Y4oan2DcRdFzNClLIkDbNVYTPz08fsr3xhTNgfXr1ewhaF6ZPqp0WOBk1yMOw8D
6Gy/T/xy295jx4KeMsYL+bJz69xOrfb0+1tbdy4PeFHU2VzF2GauGjhVSGI5AV/b
WETcfCEGuSqCiJQJQTuZpq4efQDQUGh3dhhelzFZ7CNJuHXzRIeW6OCgylaUhvl6
rG5hr/wIcx4jctiu/8ho0GnaV7UFgPBt5PmJtpZeSXYoLUJD0o0TdJ4X2dJX2cMC
yBw4k89c84TcSQcwoxSf
=hnwc
-----END PGP SIGNATURE-----


From smileismystyl at gmail.com  Mon Aug 25 10:57:37 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Mon, 25 Aug 2014 14:27:37 +0530
Subject: [R] rJAVA and JGR doesnot get installed,
Message-ID: <CAG1d=2CD8QgWbeba1eJWkJid1tVXKfznq5o4R7GEmFNyaJEJdw@mail.gmail.com>

Im very much new to R-studio.
Can anyone answer this. I have installed many packages but this
doesnot work. What could be the reason. I want to run Maxent through R

Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: inDL(x, as.logical(local), as.logical(now), ...)
  error: unable to load shared object
'G:/Software/R-3.1.1/library/rJava/libs/x64/rJava.dll':


system configuration:

64bit-windows

R stats- 3.1.1

Java-1.7

	[[alternative HTML version deleted]]


From wbonat at gmail.com  Mon Aug 25 10:31:41 2014
From: wbonat at gmail.com (Wagner Bonat)
Date: Mon, 25 Aug 2014 10:31:41 +0200
Subject: [R] Trace and inverse of big matrices
Message-ID: <CANt=4Mi66Svom4H91RB0Tbop=2pR9YAfZP3zjC7kBXZjg2VojA@mail.gmail.com>

I need to compute two equations related with trace and inverse of a around
30000 x 30000 density matrices. The equations are

-trace( W_i %**% C) and -trace(W_i %**% C %*% W_j C)

I know W_i, W_j and inverse of C. These equations are related with Pearson
estimating functions. I am trying to use R and package Matrix, but I
couldn't compute the C matrix, using solve() or chol() and chol2inv(). I do
not know with is possible using solve() to solve a system of equation and
after compute the trace. It is common to use solve function to compute
something like C^{-1} W = solve(C, W), but my equation is a little bit
different. Any help is welcome. I am thinking about to use RcppArmadillo,
but I am not sure that it is able to compute my equations.

Thank you everyone.

-- 
Wagner Hugo Bonat
LEG - Laborat?rio de Estat?stica e Geoinforma??o
UFPR - Universidade Federal do Paran?

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon Aug 25 16:11:45 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 25 Aug 2014 10:11:45 -0400
Subject: [R] Preventing loading of user packages
In-Reply-To: <53FB08BD.5030600@thon.cc>
References: <53FB08BD.5030600@thon.cc>
Message-ID: <CA+vqiLEOCuapA-fFqTHV8NGKKFuq2hi42JOJB50dyKVTObOhKg@mail.gmail.com>

On Mon, Aug 25, 2014 at 5:58 AM, Jonathon Love <jon at thon.cc> wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> Hi,
>
> I'm trying to prevent the loading of packages from the 'personal
> library'

Of behalf of the users you are about to cripple, please, do not do that!

-Ista

on an OS X machine. i.e. the packages that are normally
> placed somewhere like:
>
> ~/Library/R/3.0/library
>
> There is a file in the R.framwork directory:
>
> /Versions/3.0/Resources/etc/Renviron
>
> which contains a line:
>
> R_LIBS_USER=${R_LIBS_USER-'~/Library/R/3.0/library'}
>
> but commenting this out does not prevent R from loading from that
> location.
>
> is there a way to prevent loading from that location?
>
> with thanks
>
> jonathon
>
> - --
>
> JASP - A Fresh Way to Do Statistics
> http://jasp-stats.org/
>
> - --
>
> How happy is he born and taught,
> That serveth not another's will;
> Whose armour is his honest thought,
> And simple truth his utmost skill
>
> This man is freed from servile bands
> Of hope to rise, or fear to fall:
> Lord of himself, though not of lands,
> And, having nothing, yet hath all.
>
>   -- Sir Henry Wotton
>
>
>
>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
> Comment: GPGTools - https://gpgtools.org
>
> iQIcBAEBCgAGBQJT+wi9AAoJEH277gjmPGDYzkkP/0rA4bwVK9+E7Y9S2f/8+mpY
> QTgGS8Q19YfFd9ZgQICM+Zb9s+cZiC60EwC8IBlBpf2fMGioKFtv8fGFrTKOFpOl
> 8H758D/HdkvzwpQ/XCDP+sNQQ3VNxryoKzgXV7O5vusKjnfRO8nmpldjqURnIoze
> LUvUYgp3ySK3JfjZwBlpcGzahnhl95KBWQzpW2cXSJH0SaJ9jzfO6OHVEZPmJaVi
> llePJqJJ36ZlI1XUt9XZIySfsw7o1efcjLNdFq2UYFExEI17bqa3DihuXRAzBBSF
> 1sWPQGmTGAn6N9MT7EJ7UxBiSMTvnbO/fjKNxjRGk+p89h+bmrdVmnn408QGkIe/
> d+os4++sG9nLVywLduJ/tCemMfWjRVDBCwlCbTrRbehi95UqX3UF5K6a2Iq7FMV7
> 3Y4oan2DcRdFzNClLIkDbNVYTPz08fsr3xhTNgfXr1ewhaF6ZPqp0WOBk1yMOw8D
> 6Gy/T/xy295jx4KeMsYL+bJz69xOrfb0+1tbdy4PeFHU2VzF2GauGjhVSGI5AV/b
> WETcfCEGuSqCiJQJQTuZpq4efQDQUGh3dhhelzFZ7CNJuHXzRIeW6OCgylaUhvl6
> rG5hr/wIcx4jctiu/8ho0GnaV7UFgPBt5PmJtpZeSXYoLUJD0o0TdJ4X2dJX2cMC
> yBw4k89c84TcSQcwoxSf
> =hnwc
> -----END PGP SIGNATURE-----
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Mon Aug 25 16:15:38 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 25 Aug 2014 10:15:38 -0400
Subject: [R] yaxs Causes Boundary Line Colour to Change
In-Reply-To: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
References: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
Message-ID: <CAM_vjumjKaaeH6rrgZuKnMHEbTKbkj66YMcGwrRR7XziOB1RSw@mail.gmail.com>

I can't reproduce this on R 3.1.0 on linux or R 3.1.1 on Mac, using
the default graphics device on each.

What graphics device are you using?

If all else fails, you could use box() to draw over it.

Sarah

On Mon, Aug 25, 2014 at 8:00 AM, Dario Strbenac
<dstr7320 at uni.sydney.edu.au> wrote:
> Why is the bottom boundary plotted in a different colour to the other three sides ?
>
> set.seed(4444)
> data <- rpois(10, 2)
> plot(density(data), ann = FALSE, yaxs = 'i') # Grey bottom boundary.
> plot(density(data), ann = FALSE) # All boundaries are black.
>
> Ideally, there would be black lines on all four sides. The documentation doesn't say the colour will change.
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From dgdillon at gmail.com  Mon Aug 25 16:31:57 2014
From: dgdillon at gmail.com (Dan Dillon)
Date: Mon, 25 Aug 2014 10:31:57 -0400
Subject: [R] Help with lsmeans
Message-ID: <CAMdATGofn5ywDkddn2c=oT9Kf6APRVT7Jewb+EyrqqkVjbhd3A@mail.gmail.com>

Colleagues:

I am running two regressions with lme4 and using lsmeans to digest the
results, and lsmeans works fine with one regression but hangs with the
other one--I'm not sure why, and I am hoping someone can help me debug. I
am running R version 3.1.1 in the IPython notebook, and I've got lsmeans
version 2.11.

My data are from a behavioral experiment in which two groups of subjects
complete 200+ trials of a task with two conditions. Each subject is tested
in one of four separate locations. I record accuracy (0 or 1) and response
time (RT) on each trial--these are the DVs for the two regressions. Thus,
my dataframe has columns "location", "group", "subject", "trial",
"condition", "accuracy", and "RT".

The regression model for accuracy looks like this:

acc.fm = glmer(accuracy ~ location + group*condition + (1|subject),
family=binomial, data=my_data)


The results look as expected and I'm using lsmeans to do some follow-up
analyses. For example, to compare accuracy by group and condition, I'm
doing this:

acc.lsm <- lsmeans(acc.fm, ~group|condition)

pairs(acc.lsm)


All this works fine. But when I try the same approach with the RT data, my
machine hangs and I do not get any output. Here is my model for the RT data
(RT is a continuous variable so no logistic regression here):

rt.fm = lmer(rt ~ location + group*condition*accuracy + (1|subject),
data=my_data)


The results from this regression look fine, but if I try this . . .

rt.lsm <- lsmeans(rt.fm ~ group|condition)

. . . or if I try to specify a reference grid like this . . .

rt.rg <- ref.grid(rt.fm)

. . . my machine hangs.

Can anyone advise me? I'm not sure why lsmeans is working with the accuracy
data but not the RT data, and I'm not sure what I can do to debug. I have
much more experience with ANOVA than regression so I am thinking I may be
missing something obvious here.

Dan

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Aug 25 17:01:39 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 25 Aug 2014 08:01:39 -0700
Subject: [R] yaxs Causes Boundary Line Colour to Change
In-Reply-To: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
References: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
Message-ID: <CAF8bMcbYwXzizBjoNZy=i96oN94SYeiJRV8Xj2HFgOjOOv_e_Q@mail.gmail.com>

Add zero.line=FALSE to the call to plot() to get rid of the gray line.
help(plot.density) should say something about it.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 25, 2014 at 5:00 AM, Dario Strbenac
<dstr7320 at uni.sydney.edu.au> wrote:
> Why is the bottom boundary plotted in a different colour to the other three sides ?
>
> set.seed(4444)
> data <- rpois(10, 2)
> plot(density(data), ann = FALSE, yaxs = 'i') # Grey bottom boundary.
> plot(density(data), ann = FALSE) # All boundaries are black.
>
> Ideally, there would be black lines on all four sides. The documentation doesn't say the colour will change.
>
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> --------------------------------------
> Dario Strbenac
> PhD Student
> University of Sydney
> Camperdown NSW 2050
> Australia
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Aug 25 17:44:12 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 25 Aug 2014 08:44:12 -0700
Subject: [R] rJAVA and JGR doesnot get installed,
In-Reply-To: <CAG1d=2CD8QgWbeba1eJWkJid1tVXKfznq5o4R7GEmFNyaJEJdw@mail.gmail.com>
References: <CAG1d=2CD8QgWbeba1eJWkJid1tVXKfznq5o4R7GEmFNyaJEJdw@mail.gmail.com>
Message-ID: <3410f3a2-8085-4546-add5-70caf1e58977@email.android.com>

"What could be the reason" might be that you don't have 64bit Java runtime installed. Either install that, or if you have 32bit Java runtime installed then you could try running the 32 bit version of R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 25, 2014 1:57:37 AM PDT, Girija Kalyani <smileismystyl at gmail.com> wrote:
>Im very much new to R-studio.
>Can anyone answer this. I have installed many packages but this
>doesnot work. What could be the reason. I want to run Maxent through R
>
>Error : .onLoad failed in loadNamespace() for 'rJava', details:
>  call: inDL(x, as.logical(local), as.logical(now), ...)
>  error: unable to load shared object
>'G:/Software/R-3.1.1/library/rJava/libs/x64/rJava.dll':
>
>
>system configuration:
>
>64bit-windows
>
>R stats- 3.1.1
>
>Java-1.7
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Mon Aug 25 18:09:39 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 25 Aug 2014 18:09:39 +0200
Subject: [R] yaxs Causes Boundary Line Colour to Change
In-Reply-To: <CAF8bMcbYwXzizBjoNZy=i96oN94SYeiJRV8Xj2HFgOjOOv_e_Q@mail.gmail.com>
References: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
	<CAF8bMcbYwXzizBjoNZy=i96oN94SYeiJRV8Xj2HFgOjOOv_e_Q@mail.gmail.com>
Message-ID: <21499.24515.922842.206629@stat.math.ethz.ch>

>>>>> William Dunlap <wdunlap at tibco.com>
>>>>>     on Mon, 25 Aug 2014 08:01:39 -0700 writes:

    > Add zero.line=FALSE to the call to plot() to get rid of
    > the gray line.  

Thank you, Bill.

    > help(plot.density) should say something about it.

    >  Bill Dunlap TIBCO Software wdunlap tibco.com

But it does already... I assume you mean it should say *more*
than now.  I'm open for adding a bit more and thankful for
wording suggestions (off line probably).

Martin Maechler, 
ETH Zurich



    > On Mon, Aug 25, 2014 at 5:00 AM, Dario Strbenac
    > <dstr7320 at uni.sydney.edu.au> wrote:
    >> Why is the bottom boundary plotted in a different colour
    >> to the other three sides ?
    >> 
    >> set.seed(4444) data <- rpois(10, 2) plot(density(data),
    >> ann = FALSE, yaxs = 'i') # Grey bottom boundary.
    >> plot(density(data), ann = FALSE) # All boundaries are
    >> black.
    >> 
    >> Ideally, there would be black lines on all four
    >> sides. The documentation doesn't say the colour will
    >> change.
    >> 
    >>> sessionInfo()
    >> R version 3.1.1 (2014-07-10) Platform:
    >> x86_64-unknown-linux-gnu (64-bit)
    >> 
    >> --------------------------------------
    >> Dario Strbenac PhD Student University of Sydney
    >> Camperdown NSW 2050 Australia
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    >> read the posting guide
    >> http://www.R-project.org/posting-guide.html and provide
    >> commented, minimal, self-contained, reproducible code.

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
    > read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Mon Aug 25 18:19:54 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 26 Aug 2014 00:19:54 +0800 (CST)
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>
Message-ID: <63a7380d.f1b7.1480df77508.Coremail.rhelpmaillist@163.com>

As you know, in the search path, there is .GlobalEnv, package:stats and so on, why do we need to convert the character "package:stats" to the stats environment.
I mean, why don't let package:stats be a environment type object like .GlobalEnv,but let it be a string ?
Hope you understand my meaning for my pool english expression way.





--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2014-08-25 09:53:37, "John McKown" <john.archie.mckown at gmail.com> wrote:
>On Mon, Aug 25, 2014 at 1:07 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>
>>
>> Dear rusers,
>>
>>     As we know, there are a lot of environments in the search() path, such as   .Golbalenv and package:base .
>> And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable,  but i must use as.envrionment("package:base") to find virable, i feel it not very convenient.
>>
>>
>> For example, when i use the following codes to add a new env into the search() path.
>>
>>
>>
>>> tmp<-attach(NULL,name="new_name")
>>> assign("a",2,envir=as.environment("new_name"))
>>> a
>> [1] 2
>>> as.environment("new_name")$a
>> [1] 2
>>  I must always convert the name to the environment, How can i just use the following form:
>>
>>
>>
>>> tmp<-attach(NULL,name="new_name")
>>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>>> a
>> [1] 2
>>> new_name$a
>>
>> [1] 2
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>
>You might want to try:
>
>new_name <- new.env();
># or if you prefer (such as in a function)
>assign("new_name",new.env(),envir=.GlobalEnv);
>#
># You may now assign variable into this similar to:
>new_name$a <- 2;
>gvar <- new_name$a; # get the variable a from environment new_name
>gvar <- get("a",envir=new_name); #same thing, but wordy
>attach(new_name);
>a
>gvar <- a;
>
>
>-- 
>There is nothing more pleasant than traveling and meeting new people!
>Genghis Khan
>
>Maranatha! <><
>John McKown

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Aug 25 18:29:40 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 25 Aug 2014 18:29:40 +0200
Subject: [R] Trace and inverse of big matrices
In-Reply-To: <CANt=4Mi66Svom4H91RB0Tbop=2pR9YAfZP3zjC7kBXZjg2VojA@mail.gmail.com>
References: <CANt=4Mi66Svom4H91RB0Tbop=2pR9YAfZP3zjC7kBXZjg2VojA@mail.gmail.com>
Message-ID: <21499.25716.510908.319472@stat.math.ethz.ch>

>>>>> Wagner Bonat <wbonat at gmail.com>
>>>>>     on Mon, 25 Aug 2014 10:31:41 +0200 writes:

    > I need to compute two equations related with trace and inverse of a around
    > 30000 x 30000 density matrices. The equations are

    > -trace( W_i %**% C) and -trace(W_i %**% C %*% W_j C)

[I assume that 2nd eq is missing a %*% ]

    > I know W_i, W_j and inverse of C. These equations are related with Pearson
    > estimating functions. I am trying to use R and package Matrix, but I
    > couldn't compute the C matrix, using solve() or chol() and chol2inv(). I do
    > not know with is possible using solve() to solve a system of equation and
    > after compute the trace. It is common to use solve function to compute
    > something like C^{-1} W = solve(C, W), but my equation is a little bit
    > different. 

Not too much different, fortunately for you.

First, note that, mathematically,
      
   tr(A %*% B)  ==  tr(B %*% A)

whenever both matrix products are valid, e.g. when the matrices
are square of the same dimension.
Consequently, you typically can interchange the order of the
matrices in the product __ when inside the trace __

As you know  D := C^{-1}  and really need C = D^{-1}, let's
better use D notation, so you want

 t1 <- -trace(W_i %**% D^{-1})
 t2 <- -trace(W_i %**% D^{-1} %*% W_j %*% D^{-1})

so, if  
    	CWi <- solve(D, W_i)   {for 'i' and 'j' !}

 t1 <- -trace(CWi)
 t2 <- -trace(CWi %*% CWj)

Now, this alone will still not be good enough to get done
quickly, using Matrix:
The most important question really is if  D ( = C^{-1} ) is
a *sparse* matrix and possibly the W_j are sparse as well.
In some (but not most) such cases, C will be sparse, too, and
the whole computations are done very efficiently using the
Matrix - underlying C libraries.

I'm interested to hear more about your matrices.
To find their sparse, apply
   nnzeros( M )
and possibly 
   nnzeros(zapsmall( M ))
to your matrices M.
Also of interest here is
   isSymmetric(D)

Martin Maechler,
ETH Zurich 
and Maintainer of the 'Matrix' package


    > Any help is welcome. I am thinking about to use RcppArmadillo, but I am not sure that it is able to compute my equations.

    > Thank you everyone.

    > -- 
    > Wagner Hugo Bonat
    > LEG - Laborat?rio de Estat?stica e Geoinforma??o
    > UFPR - Universidade Federal do Paran?


From john.archie.mckown at gmail.com  Mon Aug 25 19:26:28 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 25 Aug 2014 12:26:28 -0500
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <63a7380d.f1b7.1480df77508.Coremail.rhelpmaillist@163.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>
	<63a7380d.f1b7.1480df77508.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAJSdjh4aTXH=+bnm2D11+5gjhc=L1PqkWT2MNewYZ3zYHS=Mw@mail.gmail.com>

On Mon, Aug 25, 2014 at 11:19 AM, PO SU <rhelpmaillist at 163.com> wrote:
> As you know, in the search path, there is .GlobalEnv, package:stats and so
> on, why do we need to convert the character "package:stats" to the stats
> environment.
> I mean, why don't let package:stats be a environment type object like
> .GlobalEnv,but let it be a string ?
> Hope you understand my meaning for my pool english expression way.
>

Yes, you have  Sorry for my misunderstanding of what were originally
saying. I _think_ that I now understand. The fault is likely my
concentrating on the wrong part of your original email. To test my
ability to understand, I submit the following possibility:

> new_name<-new.env();
> attach(new_name)
> search()
 [1] ".GlobalEnv"        "new_name"          "new_name"
"tools:rstudio"
 [5] "package:graphics"  "package:grDevices" "package:utils"
"package:datasets"
 [9] "package:methods"   "Autoloads"         "package:base"
> assign("a",2,pos="new_name")
> a
[1] 2
> ls()
[1] "new_name"
> ls(pos="new_name")
[1] "a"
>

Note the use of pos= instead of envir=. That seems to be the key here.
I hope this was of more use to you. One problem that I have noticed is
that you can not get to the value of "a" by using "new_name$a", but
must use the get() function like: get('a',pos='new_name');

Please be very aware of the following, very confusing fact:
Referencing a variable can not have the expected results.

> new_name <- new.env()
> attach(new_name)
> search()
 [1] ".GlobalEnv"        "new_name"          "tools:rstudio"
"package:stats"
 [5] "package:graphics"  "package:grDevices" "package:utils"
"package:datasets"
 [9] "package:methods"   "Autoloads"         "package:base"
> assign("a",2,"new_name")
> ls()
[1] "new_name"
> new_name$a
NULL
> get("a",pos="new_name")
[1] 2
> new_name$a <- 'x'
> new_name$a;
[1] "x"
> get("a",pos="new_name")
[1] 2
>

If you wanted to use string values in the first two commands above,
then perhaps:

> attach(NULL,name="new_name")
> search()
 [1] ".GlobalEnv"        "new_name"          "tools:rstudio"
"package:graphics"
 [5] "package:grDevices" "package:utils"     "package:datasets"
"package:methods"
 [9] "Autoloads"         "package:base"
> assign("a",2,pos="new_name")
> ls()
character(0)
> ls(pos="new_name")
[1] "a"
> a
[1] 2
># or even
> ls("new_name")
[1] "a"
>

Likewise you can do:

> search()
 [1] ".GlobalEnv"        "tools:rstudio"     "package:stats"
"package:graphics"
 [5] "package:grDevices" "package:utils"     "package:datasets"
"package:methods"
 [9] "Autoloads"         "package:base"
> ls(pos="package:stats")
  [1] "acf"                  "acf2AR"               "add.scope"
  [4] "add1"                 "addmargins"           "aggregate"
  [7] "aggregate.data.frame" "aggregate.ts"         "AIC"
 [10] "alias"                "anova"                "ansari.test"
...
[436] "variable.names"       "varimax"              "vcov"
[439] "weighted.mean"        "weighted.residuals"   "weights"
[442] "wilcox.test"          "window"               "window<-"
[445] "write.ftable"         "xtabs"
>
> get("time",pos="package:stats")
function (x, ...)
UseMethod("time")
<bytecode: 0x000000000a4e8b00>
<environment: namespace:stats>
> x<-get("time",pos="package:stats")
> x
function (x, ...)
UseMethod("time")
<bytecode: 0x000000000a4e8b00>
<environment: namespace:stats>
> # note that the get() basically created a variable in the global environment whose value was
> # the same as in the package. But you can change the value of "x" in the global environment
> # and it won't affect the value in the package. And vice versa, if you could update "x" in
> # the package, but that can't be done because packages seem to be locked and read-only.

>
>
>
> --
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From dileepkunjaai at gmail.com  Mon Aug 25 19:39:17 2014
From: dileepkunjaai at gmail.com (=?UTF-8?B?4LSV4LWB4LSe4LWN4LSe4LS+4LSv4LS/IGt1bmphYWk=?=)
Date: Mon, 25 Aug 2014 23:09:17 +0530
Subject: [R] How to plot multiple density plot and scatter plot together
Message-ID: <CALTF6snpw23ipea1GvX+u7pumOBV0nw5UiOryuJnN2Rt7q_i9g@mail.gmail.com>

Dear all,
 I want to plot kernal density of two set of data (theses both data set
have same shape) and I want to insert  scatter line segment plot (
http://stackoverflow.com/questions/24931006/r-simple-scatter-plot-with-vertical-lines)
on this same plot.

I can make two density plot together(I have attached that plot), but
together with these density plot, I cannot include scatter line-segment
plot on this density plot.

Thank you all in advance
-- 
DILEEPKUMAR. R
J R F, IIT DELHI
-------------- next part --------------
A non-text attachment was scrubbed...
Name: airi_jjas.3.pdf
Type: application/pdf
Size: 10327 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20140825/a3648067/attachment.pdf>

From kabalaandrew at gmail.com  Mon Aug 25 17:34:57 2014
From: kabalaandrew at gmail.com (Andrew Kabala)
Date: Mon, 25 Aug 2014 18:34:57 +0300
Subject: [R] recording age into different variables
Message-ID: <CAGyx_WCgXczrz0ZuJ_mNw+nd1ERjsQ3tzREF1HE_h3tr3u1A4A@mail.gmail.com>

Hi,
I am new to R, I would like to know how i can summarize age data into
different categories i.e.
Age
14
16
20
60
45
.
.
I would like to generate a summary for example showing the frequencies in
each custom defined group
0-10 yrs  11-20 years 21-30 years
20             5               6

many thanks
Andrew

	[[alternative HTML version deleted]]


From john.archie.mckown at gmail.com  Mon Aug 25 19:55:32 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 25 Aug 2014 12:55:32 -0500
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <CAAJSdjh4aTXH=+bnm2D11+5gjhc=L1PqkWT2MNewYZ3zYHS=Mw@mail.gmail.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>
	<63a7380d.f1b7.1480df77508.Coremail.rhelpmaillist@163.com>
	<CAAJSdjh4aTXH=+bnm2D11+5gjhc=L1PqkWT2MNewYZ3zYHS=Mw@mail.gmail.com>
Message-ID: <CAAJSdjjuHo9Za0AFSVfMuiry=V1LbYkDq5cK+w7kAcyEy-9c4g@mail.gmail.com>

On Mon, Aug 25, 2014 at 12:26 PM, John McKown
<john.archie.mckown at gmail.com> wrote:
<snip>
> Please be very aware of the following, very confusing fact:
> Referencing a variable can not have the expected results.
>
>> new_name <- new.env()
>> attach(new_name)
>> search()
>  [1] ".GlobalEnv"        "new_name"          "tools:rstudio"
> "package:stats"
>  [5] "package:graphics"  "package:grDevices" "package:utils"
> "package:datasets"
>  [9] "package:methods"   "Autoloads"         "package:base"
>> assign("a",2,"new_name")
>> ls()
> [1] "new_name"
>> new_name$a
> NULL
>> get("a",pos="new_name")
> [1] 2
>> new_name$a <- 'x'
>> new_name$a;
> [1] "x"
>> get("a",pos="new_name")
> [1] 2
>>

The above does not work because I did it incorrectly. The code below
is the proper way to do this.

> attach(NULL,name="new_name")
> new_name<-as.environment("new_name")
> assign("a",2,pos="new_name")
> get("a",pos="new_name")
[1] 2
> new_name$a
[1] 2
> ls(pos="new_name")
[1] "a"
> new_name$b<-'b'
> ls(pos="new_name")
[1] "a" "b"
> get('b',pos='new_name')
[1] "b"
>

It appears that what happens in the original is that the attach() does
not point to the environment, but creates its own copy. In the second
case, attach() creates the environment, then the new line assigns a
"pointer" to that same physical environment to the variable new_name.
I'm learning some _interesting_ things from this discussion.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From gunter.berton at gene.com  Mon Aug 25 19:57:58 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 25 Aug 2014 10:57:58 -0700
Subject: [R] recording age into different variables
In-Reply-To: <CAGyx_WCgXczrz0ZuJ_mNw+nd1ERjsQ3tzREF1HE_h3tr3u1A4A@mail.gmail.com>
References: <CAGyx_WCgXczrz0ZuJ_mNw+nd1ERjsQ3tzREF1HE_h3tr3u1A4A@mail.gmail.com>
Message-ID: <CACk-te0Twwcaf8o6=LWL9sGGPF-3Wov7uymiLHr8-8Uc-HJy4Q@mail.gmail.com>

Before posting further:

1. Read the posting guide linked to at the bottom of this message. In
particular note: no HTML,please.

2. Do your due diligence. Spend some time with an R tutorial to learn
the basics -- we should not have to answer questions that with minimal
effort you could answer for yourself. This one ships with R, but there
are many other good ones on the web:

http://cran.r-project.org/doc/manuals/R-intro.pdf

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Mon, Aug 25, 2014 at 8:34 AM, Andrew Kabala <kabalaandrew at gmail.com> wrote:
> Hi,
> I am new to R, I would like to know how i can summarize age data into
> different categories i.e.
> Age
> 14
> 16
> 20
> 60
> 45
> .
> .
> I would like to generate a summary for example showing the frequencies in
> each custom defined group
> 0-10 yrs  11-20 years 21-30 years
> 20             5               6
>
> many thanks
> Andrew
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Mon Aug 25 19:59:42 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 25 Aug 2014 13:59:42 -0400
Subject: [R] recording age into different variables
In-Reply-To: <CAGyx_WCgXczrz0ZuJ_mNw+nd1ERjsQ3tzREF1HE_h3tr3u1A4A@mail.gmail.com>
References: <CAGyx_WCgXczrz0ZuJ_mNw+nd1ERjsQ3tzREF1HE_h3tr3u1A4A@mail.gmail.com>
Message-ID: <CA+vqiLFN91h6e2eLnbBe394Xxwm1TMVBGMpyx79+JiAAV8WMTA@mail.gmail.com>

Hi Andrew,

See ?cut and ?table, e.g.,

table(cut(Age, c(0, 10, 20, 30), include.lowest=TRUE))

should do it.

Best,
Ista

On Mon, Aug 25, 2014 at 11:34 AM, Andrew Kabala <kabalaandrew at gmail.com> wrote:
> Hi,
> I am new to R, I would like to know how i can summarize age data into
> different categories i.e.
> Age
> 14
> 16
> 20
> 60
> 45
> .
> .
> I would like to generate a summary for example showing the frequencies in
> each custom defined group
> 0-10 yrs  11-20 years 21-30 years
> 20             5               6
>
> many thanks
> Andrew
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rhelpmaillist at 163.com  Mon Aug 25 20:08:50 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 26 Aug 2014 02:08:50 +0800 (CST)
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <CAAJSdjh4aTXH=+bnm2D11+5gjhc=L1PqkWT2MNewYZ3zYHS=Mw@mail.gmail.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>
	<63a7380d.f1b7.1480df77508.Coremail.rhelpmaillist@163.com>
	<CAAJSdjh4aTXH=+bnm2D11+5gjhc=L1PqkWT2MNewYZ3zYHS=Mw@mail.gmail.com>
Message-ID: <2d5bab9.a520.1480e5b325e.Coremail.rhelpmaillist@163.com>


Tks for all your details, after your introduction, i really read the ?attach carefully, and i now understand the argument "pos" now, but in my opnion, the details in the function "attach" may do the as.environment(pos) for me.?
And i also understand that, "attach" will copy the attached envir,and add the copied envir into the search path list as you showed ?the examples to me.
After all, i want to ask a last question:
I notice that,

> environmentName(.GlobalEnv)
[1] "R_GlobalEnv"
> as.environment(".GlobalEnv")
<environment: R_GlobalEnv>

>as.environment("R_GlobalEnv")
Error in as.environment("R_GlobalEnv") :?
? no item called "R_GlobalEnv" on the search list
> .GlobalEnv
<environment: R_GlobalEnv>

> environmentName("package:stats")
[1] ""
>?as.environment("package:stats")
<environment: package:stats>
attr(,"name")
[1] "package:stats"
attr(,"path")
[1] "C:/Program Files/R/R-3.1.1/library/stats"


I am really confused now, while?as.environment("package:stats") can be work by convert the name of the environment stats, the?environmentName returns "" !
And get the .GlobalEnv from ".GlobalEnv" ,but can't form?"R_GlobalEnv" which is actually the name of the environment.
















--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-08-26 01:26:28, "John McKown" <john.archie.mckown at gmail.com> wrote:
>On Mon, Aug 25, 2014 at 11:19 AM, PO SU <rhelpmaillist at 163.com> wrote:
>> As you know, in the search path, there is .GlobalEnv, package:stats and so
>> on, why do we need to convert the character "package:stats" to the stats
>> environment.
>> I mean, why don't let package:stats be a environment type object like
>> .GlobalEnv,but let it be a string ?
>> Hope you understand my meaning for my pool english expression way.
>>
>
>Yes, you have  Sorry for my misunderstanding of what were originally
>saying. I _think_ that I now understand. The fault is likely my
>concentrating on the wrong part of your original email. To test my
>ability to understand, I submit the following possibility:
>
>> new_name<-new.env();
>> attach(new_name)
>> search()
> [1] ".GlobalEnv"        "new_name"          "new_name"
>"tools:rstudio"
> [5] "package:graphics"  "package:grDevices" "package:utils"
>"package:datasets"
> [9] "package:methods"   "Autoloads"         "package:base"
>> assign("a",2,pos="new_name")
>> a
>[1] 2
>> ls()
>[1] "new_name"
>> ls(pos="new_name")
>[1] "a"
>>
>
>Note the use of pos= instead of envir=. That seems to be the key here.
>I hope this was of more use to you. One problem that I have noticed is
>that you can not get to the value of "a" by using "new_name$a", but
>must use the get() function like: get('a',pos='new_name');
>
>Please be very aware of the following, very confusing fact:
>Referencing a variable can not have the expected results.
>
>> new_name <- new.env()
>> attach(new_name)
>> search()
> [1] ".GlobalEnv"        "new_name"          "tools:rstudio"
>"package:stats"
> [5] "package:graphics"  "package:grDevices" "package:utils"
>"package:datasets"
> [9] "package:methods"   "Autoloads"         "package:base"
>> assign("a",2,"new_name")
>> ls()
>[1] "new_name"
>> new_name$a
>NULL
>> get("a",pos="new_name")
>[1] 2
>> new_name$a <- 'x'
>> new_name$a;
>[1] "x"
>> get("a",pos="new_name")
>[1] 2
>>
>
>If you wanted to use string values in the first two commands above,
>then perhaps:
>
>> attach(NULL,name="new_name")
>> search()
> [1] ".GlobalEnv"        "new_name"          "tools:rstudio"
>"package:graphics"
> [5] "package:grDevices" "package:utils"     "package:datasets"
>"package:methods"
> [9] "Autoloads"         "package:base"
>> assign("a",2,pos="new_name")
>> ls()
>character(0)
>> ls(pos="new_name")
>[1] "a"
>> a
>[1] 2
>># or even
>> ls("new_name")
>[1] "a"
>>
>
>Likewise you can do:
>
>> search()
> [1] ".GlobalEnv"        "tools:rstudio"     "package:stats"
>"package:graphics"
> [5] "package:grDevices" "package:utils"     "package:datasets"
>"package:methods"
> [9] "Autoloads"         "package:base"
>> ls(pos="package:stats")
>  [1] "acf"                  "acf2AR"               "add.scope"
>  [4] "add1"                 "addmargins"           "aggregate"
>  [7] "aggregate.data.frame" "aggregate.ts"         "AIC"
> [10] "alias"                "anova"                "ansari.test"
>...
>[436] "variable.names"       "varimax"              "vcov"
>[439] "weighted.mean"        "weighted.residuals"   "weights"
>[442] "wilcox.test"          "window"               "window<-"
>[445] "write.ftable"         "xtabs"
>>
>> get("time",pos="package:stats")
>function (x, ...)
>UseMethod("time")
><bytecode: 0x000000000a4e8b00>
><environment: namespace:stats>
>> x<-get("time",pos="package:stats")
>> x
>function (x, ...)
>UseMethod("time")
><bytecode: 0x000000000a4e8b00>
><environment: namespace:stats>
>> # note that the get() basically created a variable in the global environment whose value was
>> # the same as in the package. But you can change the value of "x" in the global environment
>> # and it won't affect the value in the package. And vice versa, if you could update "x" in
>> # the package, but that can't be done because packages seem to be locked and read-only.
>
>>
>>
>>
>> --
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>
>
>-- 
>There is nothing more pleasant than traveling and meeting new people!
>Genghis Khan
>
>Maranatha! <><
>John McKown

From john.archie.mckown at gmail.com  Mon Aug 25 20:22:39 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 25 Aug 2014 13:22:39 -0500
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <2d5bab9.a520.1480e5b325e.Coremail.rhelpmaillist@163.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<CAAJSdjhp6L7qBUCrzDFugw2u=3CWqaPh8bALvY1htce9fcaZXw@mail.gmail.com>
	<63a7380d.f1b7.1480df77508.Coremail.rhelpmaillist@163.com>
	<CAAJSdjh4aTXH=+bnm2D11+5gjhc=L1PqkWT2MNewYZ3zYHS=Mw@mail.gmail.com>
	<2d5bab9.a520.1480e5b325e.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAJSdjhvgETZWBuvafj7EA_SY2_SKOzCqsxqiHsyc=hRJ3dPBQ@mail.gmail.com>

On Mon, Aug 25, 2014 at 1:08 PM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Tks for all your details, after your introduction, i really read the ?attach carefully, and i now understand the argument "pos" now, but in my opnion, the details in the function "attach" may do the as.environment(pos) for me.
> And i also understand that, "attach" will copy the attached envir,and add the copied envir into the search path list as you showed  the examples to me.
> After all, i want to ask a last question:
> I notice that,
>
>> environmentName(.GlobalEnv)
> [1] "R_GlobalEnv"
>> as.environment(".GlobalEnv")
> <environment: R_GlobalEnv>
>
>>as.environment("R_GlobalEnv")
> Error in as.environment("R_GlobalEnv") :
>   no item called "R_GlobalEnv" on the search list
>> .GlobalEnv
> <environment: R_GlobalEnv>
>
>> environmentName("package:stats")
> [1] ""
>> as.environment("package:stats")
> <environment: package:stats>
> attr(,"name")
> [1] "package:stats"
> attr(,"path")
> [1] "C:/Program Files/R/R-3.1.1/library/stats"
>
>
> I am really confused now, while as.environment("package:stats") can be work by convert the name of the environment stats, the environmentName returns "" !
> And get the .GlobalEnv from ".GlobalEnv" ,but can't form "R_GlobalEnv" which is actually the name of the environment.
>

You are now much deeper into the internals of R than my knowledge.
Perhaps one of the truly wise ones here knows. Or this may be a better
question for the people on r-devel. It is really getting more towards
the "why" of R rather than the "how to".

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From macqueen1 at llnl.gov  Mon Aug 25 20:51:54 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 25 Aug 2014 18:51:54 +0000
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
Message-ID: <D020D0E6.108627%macqueen1@llnl.gov>

Put simply,
   .GlobalEnv    stores objects you create
   package:base  contains functions and objects provided by R itself

You don?t need to use   .GlobalEnv$a   to use the variable named a. Just
is ?a? by itself.

 a <- 4
 b <- 2*a
print(a)
print(b)

Not necessary to use
  print(.GlobalEnv$a)

Similarly, to find an object in the base package, just type its name.

I don?t know what you are trying to do, or why you think you have to use
.GlobalEnv$a   
But in more than 20 years of using R for many different tasks, I have
never had to do that.

Furthermore, if you are new to R (which I would guess is the case), it
seems unlikely to me that you need to work with environments or use
attach() or assign(). In the vast majority of cases there are simpler ways
that are easier to understand.

You are aware, I hope, that
  > ls('.GlobalEnv')
  > ls(1)
  > ls()
all return the same result?


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/24/14, 11:07 PM, "PO SU" <rhelpmaillist at 163.com> wrote:

>
>
>Dear rusers,
>
>    As we know, there are a lot of environments in the search() path,
>such as   .Golbalenv and package:base .
>And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable,  but
>i must use as.envrionment("package:base") to find virable, i feel it not
>very convenient.
>
>
>For example, when i use the following codes to add a new env into the
>search() path.
>
>
>
>> tmp<-attach(NULL,name="new_name")
>> assign("a",2,envir=as.environment("new_name"))
>> a
>[1] 2
>> as.environment("new_name")$a
>[1] 2
> I must always convert the name to the environment, How can i just use
>the following form:
>
>
>
>> tmp<-attach(NULL,name="new_name")
>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>> a
>[1] 2
>> new_name$a
>
>[1] 2
>
>
>
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Aug 25 21:55:38 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 25 Aug 2014 19:55:38 +0000
Subject: [R] How to plot multiple density plot and scatter plot together
In-Reply-To: <CALTF6snpw23ipea1GvX+u7pumOBV0nw5UiOryuJnN2Rt7q_i9g@mail.gmail.com>
References: <CALTF6snpw23ipea1GvX+u7pumOBV0nw5UiOryuJnN2Rt7q_i9g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F928F2@mb02.ads.tamu.edu>

Assuming the y-axis is different for the scatter line segment plot, you probably want to use twoord.plot() in package plotrix to construct overlapping plots using different ordinate (y-axis) scales. For examples see

http://rgm.ogalab.net/RGM/R_image_list?package=plotrix&rd_name=twoord.plot&data_source=R_CC&init=true

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of ???????? kunjaai
Sent: Monday, August 25, 2014 12:39 PM
To: r-help at r-project.org
Subject: [R] How to plot multiple density plot and scatter plot together

Dear all,
 I want to plot kernal density of two set of data (theses both data set
have same shape) and I want to insert  scatter line segment plot (
http://stackoverflow.com/questions/24931006/r-simple-scatter-plot-with-vertical-lines)
on this same plot.

I can make two density plot together(I have attached that plot), but
together with these density plot, I cannot include scatter line-segment
plot on this density plot.

Thank you all in advance
-- 
DILEEPKUMAR. R
J R F, IIT DELHI

From dwinsemius at comcast.net  Mon Aug 25 21:59:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 25 Aug 2014 12:59:02 -0700
Subject: [R] Preventing loading of user packages
In-Reply-To: <CA+vqiLEOCuapA-fFqTHV8NGKKFuq2hi42JOJB50dyKVTObOhKg@mail.gmail.com>
References: <53FB08BD.5030600@thon.cc>
	<CA+vqiLEOCuapA-fFqTHV8NGKKFuq2hi42JOJB50dyKVTObOhKg@mail.gmail.com>
Message-ID: <DBEA1E00-AC23-495A-8398-D99B76387C1C@comcast.net>


On Aug 25, 2014, at 7:11 AM, Ista Zahn wrote:

> On Mon, Aug 25, 2014 at 5:58 AM, Jonathon Love <jon at thon.cc> wrote:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA512
>> 
>> Hi,
>> 
>> I'm trying to prevent the loading of packages from the 'personal
>> library'
> 
> Of behalf of the users you are about to cripple, please, do not do that!

Hello jonathon and Ista;

(I think this might be the first time I've seriously with Ista.) I've been in the situation where I had multiple copies of packages in 2 different libraries and wanted to do exactly what was requested. I'm assuming that the "main" library directory is something other than '~/Library/R/3.0/library' and permissions allow packages to be accessed and placed there. A quick method would simply be to execute this at the command line (or if it needed to be repeated in .Rprofile) :

.libPaths( .libPaths()[!which(.libPaths() == '~/Library/R/3.0/library')] )

I suppose you could wrap some testing around this to prevent the removal of that path if it were the only one or if it were the path to the base and stats packages. Fo me this reports correctly that my base package is not there:

> grepl("~/Library/R/3.0/library" , attr(packageDescription('base'), "file") )
[1] FALSE

But this raises the question. Why is this happening and why don't you just delete the directory?

-- 
David.

> 
> -Ista
> 
> on an OS X machine. i.e. the packages that are normally
>> placed somewhere like:
>> 
>> ~/Library/R/3.0/library
>> 
>> There is a file in the R.framwork directory:
>> 
>> /Versions/3.0/Resources/etc/Renviron
>> 
>> which contains a line:
>> 
>> R_LIBS_USER=${R_LIBS_USER-'~/Library/R/3.0/library'}
>> 
>> but commenting this out does not prevent R from loading from that
>> location.
>> 
>> is there a way to prevent loading from that location?
>> 
>> with thanks
>> 
>> jonathon
>> 
>> - --
>> 


David Winsemius
Alameda, CA, USA


From j.tosovsky at email.cz  Mon Aug 25 22:17:44 2014
From: j.tosovsky at email.cz (Jan Tosovsky)
Date: Mon, 25 Aug 2014 22:17:44 +0200
Subject: [R] Filled vector contours
In-Reply-To: <C046DE03-F803-4911-B042-E14114B6E19B@comcast.net>
References: <001701cfbf70$2797dce0$76c796a0$@tosovsky@email.cz>
	<53F9BC3A.4070405@stats.ox.ac.uk>
	<000901cfbfda$392beef0$ab83ccd0$@tosovsky@email.cz>
	<C046DE03-F803-4911-B042-E14114B6E19B@comcast.net>
Message-ID: <008401cfc0a1$a1cf9fc0$e56edf40$@tosovsky@email.cz>

On 2014-08-25 David Winsemius wrote:
> On 2014-08-24 Jan Tosovsky wrote:
> > On 2014-08-24 Prof Brian Ripley wrote:
> > > On 24/08/2014 08:51, Jan Tosovsky wrote:
> > > >
> > > > I am trying to create vector output (SVG) of filled contours.
> > > >
> > > > I've found two approaches so far:
> > > >
> > > > (1)
> > > > library('lattice')
> > > > svg("D:/test.svg")
> > > > filled.contour(volcano)
> > > > #levelplot(volcano, panel=panel.levelplot.raster)
> > > > dev.off()
> > > >
> > > > (2)
> > > > library("raster")
> > > > svg("D:/test.svg")
> > > > rr <- raster(t(volcano))
> > > > rc <- cut(rr, breaks= 10)
> > > > pols <- rasterToPolygons(rc, dissolve=T)
> > > > spplot(pols)
> > > > dev.off()
> > > >
> > > > But I'd like to get smooth closed polygons not broken into small
> > > > cells.
> > >
> > > But the region between two contours is not in general a closed
> > > polygon.
> > 
> > I appologize for not being precise here.
> > 
> > My goal is to get something like this:
> > http://drifted.in/other/contours/composition.svg
> > 
> > which is a composition of level plots, e.g.
> > http://drifted.in/other/contours/level_plot.svg
> > 
> > By 'level plot' I mean the cut of the data at certain level. It is
> > always a closed polygon (or multiple polygons) consisting of contour 
> > lines connected, if required, by border lines.
> > 
> > For me it is preferred way over 'isoband', which doesn't include areas
> > hidden by upper levels:
> > http://drifted.in/other/contours/isoband.svg
> > 
> 
> Most people with any R experience would have thought that "levelplot"
> referred to something like:
> (Example 6.9 from Lattice, by Deepayan Sarkar to which I have only
> added the contour line parameter which it appears is what you were 
> seeking.)
>
> library("locfit") ; library(lattice)
> env <- environmental
> env$ozone <- env$ozone^(1/3)
> env$Radiation <- equal.count(env$radiation, 4)
> fm1.env <- lm(ozone ~ radiation * temperature * wind, env)
> fm2.env <- loess(ozone ~ wind * temperature * radiation, env, span =
> 0.75, degree = 1)
> fm3.env <- loess(ozone ~ wind * temperature * radiation, env,
> parametric
> = c("radiation", "wind"), span = 0.75, degree = 2)
> > fm4.env <- locfit(ozone ~ wind * temperature * radiation, env)
> w.mesh <- with(env, do.breaks(range(wind), 50))
> t.mesh <- with(env, do.breaks(range(temperature), 50))
> r.mesh <- with(env, do.breaks(range(radiation), 3))
> grid <- expand.grid(wind = w.mesh, temperature = t.mesh, radiation =
> r.mesh)
> grid[["fit.linear"]] <- predict(fm1.env, newdata = grid)
> grid[["fit.loess.1"]] <- as.vector(predict(fm2.env, newdata = grid))
> grid[["fit.loess.2"]] <- as.vector(predict(fm3.env, newdata = grid))
> grid[["fit.locfit"]] <- predict(fm4.env, newdata = grid)
> 
> png()
> print(levelplot(fit.linear + fit.loess.1 + fit.loess.2 + fit.locfit ~
> wind * temperature | radiation, data = grid, contour=TRUE))
> dev.off()

Thanks, it looks similar, but in reality countours are just polylines not
connected into polygons and the fill is made from individual cells. But good
to know there is another way. I've realized it is a variant of commented
line in (1). So here is a simplified version:

(3)
library('lattice')
svg("D:/test.svg")
levelplot(volcano, contour=TRUE)
dev.off()

In the meantime I've found fourth one (based on Grid2Polygons library
example):

library(sp)
library(Grid2Polygons)
data(meuse.grid)
coordinates(meuse.grid) <- ~ x + y
gridded(meuse.grid) <- TRUE
meuse.grid <- as(meuse.grid, "SpatialGridDataFrame")
meuse.plys.lev <- Grid2Polygons(meuse.grid, "dist", level = TRUE)

svg("D:/meuse.svg")
plot(meuse.plys.lev, col = heat.colors(length(meuse.plys.lev)))
dev.off()

It is similar to (2). It actually doesn't produce smooth countours, just
joins cells into areas of the same fill/level. And these areas are
'isobands', not 'level plots' (or rather isolevels?).

I am leaving this open. For the future reference it would be nice to modify
code (4) for volcano data. I am lost here ;-)

Thanks, Jan


From berryboessenkool at hotmail.com  Mon Aug 25 23:05:51 2014
From: berryboessenkool at hotmail.com (Berry Boessenkool)
Date: Mon, 25 Aug 2014 23:05:51 +0200
Subject: [R] Display warning only once in session
Message-ID: <DUB123-W2675D5276EF7152EBEECC8D5DF0@phx.gbl>


Hi,

I'm writing a function that gives a warning in a certain scenario.
Reading this once per R session will be enough.
i.e. it's not necessary to be shown in subsequent function calls.

What's the best way to implement this?
Some package-specific option?
Where would I find good information on that?

searching with the keywords I'm using as the subject of this message didn't dig up any results.
Maybe it will be enough to give me some better keywords...

Thanks ahead,
Berry

RclickHandbuch.wordpress.com 


 		 	   		  

From jon at thon.cc  Mon Aug 25 23:08:24 2014
From: jon at thon.cc (Jonathon Love)
Date: Mon, 25 Aug 2014 23:08:24 +0200
Subject: [R] Preventing loading of user packages
In-Reply-To: <DBEA1E00-AC23-495A-8398-D99B76387C1C@comcast.net>
References: <53FB08BD.5030600@thon.cc>
	<CA+vqiLEOCuapA-fFqTHV8NGKKFuq2hi42JOJB50dyKVTObOhKg@mail.gmail.com>
	<DBEA1E00-AC23-495A-8398-D99B76387C1C@comcast.net>
Message-ID: <53FBA5C8.5070601@thon.cc>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

hey,

i was able to solve the problem by explicitly putting

R_LIBS_USER=''

in the /etc/Renviron file (it isn't enough simply to comment the entry
out, because it has a default value that magically comes from
somewhere else)

cheers


On 25/08/2014 9:59 pm, David Winsemius wrote:
> 
> On Aug 25, 2014, at 7:11 AM, Ista Zahn wrote:
> 
>> On Mon, Aug 25, 2014 at 5:58 AM, Jonathon Love <jon at thon.cc>
>> wrote:
>>> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA512
>>> 
>>> Hi,
>>> 
>>> I'm trying to prevent the loading of packages from the
>>> 'personal library'
>> 
>> Of behalf of the users you are about to cripple, please, do not
>> do that!
> 
> Hello jonathon and Ista;
> 
> (I think this might be the first time I've seriously with Ista.)
> I've been in the situation where I had multiple copies of packages
> in 2 different libraries and wanted to do exactly what was
> requested. I'm assuming that the "main" library directory is
> something other than '~/Library/R/3.0/library' and permissions
> allow packages to be accessed and placed there. A quick method
> would simply be to execute this at the command line (or if it
> needed to be repeated in .Rprofile) :
> 
> .libPaths( .libPaths()[!which(.libPaths() ==
> '~/Library/R/3.0/library')] )
> 
> I suppose you could wrap some testing around this to prevent the
> removal of that path if it were the only one or if it were the path
> to the base and stats packages. Fo me this reports correctly that
> my base package is not there:
> 
>> grepl("~/Library/R/3.0/library" ,
>> attr(packageDescription('base'), "file") )
> [1] FALSE
> 
> But this raises the question. Why is this happening and why don't
> you just delete the directory?
> 


- -- 

JASP - A Fresh Way to Do Statistics
http://jasp-stats.org/

- --

How happy is he born and taught,
That serveth not another's will;
Whose armour is his honest thought,
And simple truth his utmost skill

This man is freed from servile bands
Of hope to rise, or fear to fall:
Lord of himself, though not of lands,
And, having nothing, yet hath all.

  -- Sir Henry Wotton





-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2.0.20 (Darwin)
Comment: GPGTools - https://gpgtools.org

iQIcBAEBCgAGBQJT+6XIAAoJEH277gjmPGDYU8sP/1zd8KOdkCfP0RMvuuD/H8vm
nfyByHbTIPrSc/ERWYm8aoc1UAFO95U6tjxdPQzsVXli00RgRLpr9aa58HXsr8TI
i+2P5Hrq/b7nXG6rUIjN6YBoKW/cuYmujQhecvcD2VyLAGqAbSnRMq/9XSk2ghba
fIKsOgMj+VqVEiBjb2bpeq0UeGl0JmPzQ29s7A+ncKX7L9rDrPCV9Rf2wG205dIl
wZftqilwcwvKmIidnc//WMSZawNWUZZKmfxui+u1RqjkqgP9sNbtS8dsAHzZo/gY
N+BNBmZ7uQa7ewLkGUU0/gmAzPaAYUNfidMhEFhzXrpR1ncEAcdwgV/FKtJIOuij
ngttf2AsbB779S0cLz+I2uwxcUPh1WqJXAGWNHk+xDmyA/eUZIqxrPHtathDohJb
Z0IU7+ld2gI2qo/OGp4m47HktHOM1ky+bgGPQnE5CCgM4XxavIhgWvzXW9tq4nVo
YQEjGzhRW4WMTdpaF0DgjneNeYVUjtWy6uckdn4L3nP87qgPJSUwByWWZpzjEBjZ
WAvyIK8VAVgIQKeegN9Rr82Uw1JZXvnueTHE5sH/Mwur4T1wxl9CaHE2cDi2BnMJ
n1MCbPMp2rS+Zae7lJAhmXCM9P3wTtOfQVw5LyaXWIC4VF6MhZVVyFW7uWD0Z1pJ
h0GN6g/DUUImGhve9Oqs
=IjO5
-----END PGP SIGNATURE-----


From wdunlap at tibco.com  Mon Aug 25 23:50:29 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 25 Aug 2014 14:50:29 -0700
Subject: [R] Display warning only once in session
In-Reply-To: <DUB123-W2675D5276EF7152EBEECC8D5DF0@phx.gbl>
References: <DUB123-W2675D5276EF7152EBEECC8D5DF0@phx.gbl>
Message-ID: <CAF8bMcZc3EirUXi9PfuGyiVEKzMKD5mnUeFgpr3J78eDdL46gA@mail.gmail.com>

You could use local() to associate a state variable with your function:
   myFunc <- local({
       notWarnedYet <- TRUE
       function(x) {
           if (notWarnedYet) {
               warning("myFunc is funky")
               notWarnedYet <<- FALSE # note use of <<-
           }
           sqrt(log2(x))
      }
   })
E.g.,
   > myFunc(1:5)
   [1] 0.000000 1.000000 1.258953 1.414214 1.523787
   Warning message:
   In myFunc(1:5) : myFunc is funky
   > myFunc(1:5)
   [1] 0.000000 1.000000 1.258953 1.414214 1.523787
   > myFunc(1:5)
   [1] 0.000000 1.000000 1.258953 1.414214 1.523787

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 25, 2014 at 2:05 PM, Berry Boessenkool
<berryboessenkool at hotmail.com> wrote:
>
> Hi,
>
> I'm writing a function that gives a warning in a certain scenario.
> Reading this once per R session will be enough.
> i.e. it's not necessary to be shown in subsequent function calls.
>
> What's the best way to implement this?
> Some package-specific option?
> Where would I find good information on that?
>
> searching with the keywords I'm using as the subject of this message didn't dig up any results.
> Maybe it will be enough to give me some better keywords...
>
> Thanks ahead,
> Berry
>
> RclickHandbuch.wordpress.com
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From brian.s.diggs at gmail.com  Tue Aug 26 01:25:20 2014
From: brian.s.diggs at gmail.com (Brian Diggs)
Date: Mon, 25 Aug 2014 16:25:20 -0700
Subject: [R] Preventing loading of user packages
In-Reply-To: <53FBA5C8.5070601@thon.cc>
References: <53FB08BD.5030600@thon.cc>	<CA+vqiLEOCuapA-fFqTHV8NGKKFuq2hi42JOJB50dyKVTObOhKg@mail.gmail.com>	<DBEA1E00-AC23-495A-8398-D99B76387C1C@comcast.net>
	<53FBA5C8.5070601@thon.cc>
Message-ID: <53FBC5E0.70204@gmail.com>

On 8/25/2014 2:08 PM, Jonathon Love wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA512
>
> hey,
>
> i was able to solve the problem by explicitly putting
>
> R_LIBS_USER=''
>
> in the /etc/Renviron file (it isn't enough simply to comment the entry
> out, because it has a default value that magically comes from
> somewhere else)

It is worth pointing out that what you have done is removed the personal 
library from the default list of libraries. So when loading a library, 
it won't be found in a (the) personal library. However, a user can 
circumvent this easily if they wish, either by adding a directory to the 
library path list via .libPaths() or by specifying lib.loc in a call to 
library() (or a variety of other ways). In other words, a user can still 
"load[...] user packages" with a little additional effort. For your use 
case, this may be sufficient. But I didn't want you to have the 
impression that this made it impossible to load additional packages.

> cheers
>
>
> On 25/08/2014 9:59 pm, David Winsemius wrote:
>>
>> On Aug 25, 2014, at 7:11 AM, Ista Zahn wrote:
>>
>>> On Mon, Aug 25, 2014 at 5:58 AM, Jonathon Love <jon at thon.cc>
>>> wrote:
>>>> -----BEGIN PGP SIGNED MESSAGE----- Hash: SHA512
>>>>
>>>> Hi,
>>>>
>>>> I'm trying to prevent the loading of packages from the
>>>> 'personal library'
>>>
>>> Of behalf of the users you are about to cripple, please, do not
>>> do that!
>>
>> Hello jonathon and Ista;
>>
>> (I think this might be the first time I've seriously with Ista.)
>> I've been in the situation where I had multiple copies of packages
>> in 2 different libraries and wanted to do exactly what was
>> requested. I'm assuming that the "main" library directory is
>> something other than '~/Library/R/3.0/library' and permissions
>> allow packages to be accessed and placed there. A quick method
>> would simply be to execute this at the command line (or if it
>> needed to be repeated in .Rprofile) :
>>
>> .libPaths( .libPaths()[!which(.libPaths() ==
>> '~/Library/R/3.0/library')] )
>>
>> I suppose you could wrap some testing around this to prevent the
>> removal of that path if it were the only one or if it were the path
>> to the base and stats packages. Fo me this reports correctly that
>> my base package is not there:
>>
>>> grepl("~/Library/R/3.0/library" ,
>>> attr(packageDescription('base'), "file") )
>> [1] FALSE
>>
>> But this raises the question. Why is this happening and why don't
>> you just delete the directory?
>>

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From wdunlap at tibco.com  Tue Aug 26 02:38:12 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 25 Aug 2014 17:38:12 -0700
Subject: [R] Display warning only once in session
In-Reply-To: <CAAjq1mdZAB+7=nDUArKsJJ0ECk7d=X1Vx-FpGyw6Q2M4rTUiRw@mail.gmail.com>
References: <DUB123-W2675D5276EF7152EBEECC8D5DF0@phx.gbl>
	<CAF8bMcZc3EirUXi9PfuGyiVEKzMKD5mnUeFgpr3J78eDdL46gA@mail.gmail.com>
	<CAAjq1mdZAB+7=nDUArKsJJ0ECk7d=X1Vx-FpGyw6Q2M4rTUiRw@mail.gmail.com>
Message-ID: <CAF8bMcYOGTndTrkK5Dgw8FtSLELjAw=xWFKCDjLkxhQ8KBMMsw@mail.gmail.com>

> Is local preferred to prevent *any* access to the internal environment
> of the returned function?

You can gain access to the environment of the function by using
environment(myFunc), with either local() or your suggestion of
making a factory function and calling it.

> How is it different than this?
>
> myFunc <- function() {
>     notWarnedYet <- TRUE
>     function(x) {
>         if (notWarnedYet) {
>             warning("myFunc is funky")
>             notWarnedYet <<- FALSE # note use of <<-
>         }
>         sqrt(log2(x))
>     }
> }

That function, when called, would return a function that warned just
once; it is not a function that warns just once.  You could call it
myFuncFactory and make myFunc itself with myFunc <- myFuncFactory().
That would be equivalent to my example calling local().  The factory
approach is good for making a series of functions, each with its own
state (say counters or random number generators).  local() is
convenient for singleton functions-with-state.  You can also supply an
environment to local() so you can make a set of functions sharing a
common environment.  I think reference classes encapsulate both of
these cases.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 25, 2014 at 5:15 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
> Is local preferred to prevent *any* access to the internal environment
> of the returned function?
>
> How is it different than this?
>
> myFunc <- function() {
>     notWarnedYet <- TRUE
>     function(x) {
>         if (notWarnedYet) {
>             warning("myFunc is funky")
>             notWarnedYet <<- FALSE # note use of <<-
>         }
>         sqrt(log2(x))
>     }
> }
> Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
> gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
> ?Wisdom begins in wonder.? --Socrates
> ((? (x) (x x)) (? (x) (x x)))
> ?Life has become immeasurably better since I have been forced to stop
> taking it seriously.? --Thompson
>
>
> On Mon, Aug 25, 2014 at 4:50 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> You could use local() to associate a state variable with your function:
>>    myFunc <- local({
>>        notWarnedYet <- TRUE
>>        function(x) {
>>            if (notWarnedYet) {
>>                warning("myFunc is funky")
>>                notWarnedYet <<- FALSE # note use of <<-
>>            }
>>            sqrt(log2(x))
>>       }
>>    })
>> E.g.,
>>    > myFunc(1:5)
>>    [1] 0.000000 1.000000 1.258953 1.414214 1.523787
>>    Warning message:
>>    In myFunc(1:5) : myFunc is funky
>>    > myFunc(1:5)
>>    [1] 0.000000 1.000000 1.258953 1.414214 1.523787
>>    > myFunc(1:5)
>>    [1] 0.000000 1.000000 1.258953 1.414214 1.523787
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Mon, Aug 25, 2014 at 2:05 PM, Berry Boessenkool
>> <berryboessenkool at hotmail.com> wrote:
>>>
>>> Hi,
>>>
>>> I'm writing a function that gives a warning in a certain scenario.
>>> Reading this once per R session will be enough.
>>> i.e. it's not necessary to be shown in subsequent function calls.
>>>
>>> What's the best way to implement this?
>>> Some package-specific option?
>>> Where would I find good information on that?
>>>
>>> searching with the keywords I'm using as the subject of this message didn't dig up any results.
>>> Maybe it will be enough to give me some better keywords...
>>>
>>> Thanks ahead,
>>> Berry
>>>
>>> RclickHandbuch.wordpress.com
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gcr at wisdomandwonder.com  Tue Aug 26 02:15:25 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Mon, 25 Aug 2014 19:15:25 -0500
Subject: [R] Display warning only once in session
In-Reply-To: <CAF8bMcZc3EirUXi9PfuGyiVEKzMKD5mnUeFgpr3J78eDdL46gA@mail.gmail.com>
References: <DUB123-W2675D5276EF7152EBEECC8D5DF0@phx.gbl>
	<CAF8bMcZc3EirUXi9PfuGyiVEKzMKD5mnUeFgpr3J78eDdL46gA@mail.gmail.com>
Message-ID: <CAAjq1mdZAB+7=nDUArKsJJ0ECk7d=X1Vx-FpGyw6Q2M4rTUiRw@mail.gmail.com>

Is local preferred to prevent *any* access to the internal environment
of the returned function?

How is it different than this?

myFunc <- function() {
    notWarnedYet <- TRUE
    function(x) {
        if (notWarnedYet) {
            warning("myFunc is funky")
            notWarnedYet <<- FALSE # note use of <<-
        }
        sqrt(log2(x))
    }
}
Grant Rettke | ACM, ASA, FSF, IEEE, SIAM
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson


On Mon, Aug 25, 2014 at 4:50 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You could use local() to associate a state variable with your function:
>    myFunc <- local({
>        notWarnedYet <- TRUE
>        function(x) {
>            if (notWarnedYet) {
>                warning("myFunc is funky")
>                notWarnedYet <<- FALSE # note use of <<-
>            }
>            sqrt(log2(x))
>       }
>    })
> E.g.,
>    > myFunc(1:5)
>    [1] 0.000000 1.000000 1.258953 1.414214 1.523787
>    Warning message:
>    In myFunc(1:5) : myFunc is funky
>    > myFunc(1:5)
>    [1] 0.000000 1.000000 1.258953 1.414214 1.523787
>    > myFunc(1:5)
>    [1] 0.000000 1.000000 1.258953 1.414214 1.523787
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Aug 25, 2014 at 2:05 PM, Berry Boessenkool
> <berryboessenkool at hotmail.com> wrote:
>>
>> Hi,
>>
>> I'm writing a function that gives a warning in a certain scenario.
>> Reading this once per R session will be enough.
>> i.e. it's not necessary to be shown in subsequent function calls.
>>
>> What's the best way to implement this?
>> Some package-specific option?
>> Where would I find good information on that?
>>
>> searching with the keywords I'm using as the subject of this message didn't dig up any results.
>> Maybe it will be enough to give me some better keywords...
>>
>> Thanks ahead,
>> Berry
>>
>> RclickHandbuch.wordpress.com
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dstr7320 at uni.sydney.edu.au  Tue Aug 26 02:00:12 2014
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Tue, 26 Aug 2014 00:00:12 +0000
Subject: [R] yaxs Causes Boundary Line Colour to Change
In-Reply-To: <21499.24515.922842.206629@stat.math.ethz.ch>
References: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
	<CAF8bMcbYwXzizBjoNZy=i96oN94SYeiJRV8Xj2HFgOjOOv_e_Q@mail.gmail.com>,
	<21499.24515.922842.206629@stat.math.ethz.ch>
Message-ID: <1409011210480.78325@uni.sydney.edu.au>

Thanks for drawing my attention to the zero.line argument. I had only checked the help page for par.

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia

From emma.gerald at gmail.com  Tue Aug 26 02:51:33 2014
From: emma.gerald at gmail.com (Emma Gerald Boyer)
Date: Mon, 25 Aug 2014 20:51:33 -0400
Subject: [R] panel.cor NA's
Message-ID: <CAHKoFnrTBDHmK5nwyzs-6uCaKFTj2JGvUWr5QxQgcquXLxtaew@mail.gmail.com>

I am running the code below and receiving NA's in many of the boxes that
are supposed to contain  r values.  Could anyone tell me what that means?
and possibly how to fix it?

Thanks,
EGB

panel.cor <- function(x, y, digits=2, prefix="", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits=digits)[1]
  txt <- paste(prefix, txt, sep="")
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * r)
}
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
}

panel.diagonalLine <- function (x, y, col = par("col"), bg = NA, pch =
par("pch"),
                                cex = 1, col.diagLine = "red", ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok))
    abline(a=0, b=1, col=col.diagLine)
}
panel.lmLine <- function (x, y, col = par("col"), bg = NA, pch =
par("pch"),
                          cex = 1, col.diagLine = "red", ...)
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)


  ok <- is.finite(x) & is.finite(y)
  if (any(ok))
    g <- lm(y~x)
  abline(g, col=col.diagLine)
}

	[[alternative HTML version deleted]]


From my1stbox at 163.com  Tue Aug 26 03:26:10 2014
From: my1stbox at 163.com (my1stbox)
Date: Tue, 26 Aug 2014 09:26:10 +0800
Subject: [R] How to do t.test to rows of a dataframe using apply family
	function?
Message-ID: <9bf55c3.1013.1480febec6e.Coremail.my1stbox@163.com>

Hi All?
How to do t.test  to rows (with two levels, or in other words, groups of samples) of a dataframe using apply family function? I have done that using function and loops. And my overall purpose is to calculate DE genes from two groups of miRNA microarray samples. And I know limma can do that, but it seems limma doesn't support paired t-test.

t.test.df=function(df,paired){
  df.t=c()
  for(i in 1:nrow(df)){
    df.t=rbind(df.t,unlist(t.test(df[i,grp1],df[i,grp2],paired=paired)))
  }
  rownames(df.t)=rownames(df)
  df.t
}

Bests!
Allen Chiu

2014-08-26
	[[alternative HTML version deleted]]


From my1stbox at 163.com  Tue Aug 26 03:42:32 2014
From: my1stbox at 163.com (my1stbox)
Date: Tue, 26 Aug 2014 09:42:32 +0800
Subject: [R] What is RVM t test? Is it possible to use it in R?
Message-ID: <6e5ba2f6.13ec.1480ffae6ee.Coremail.my1stbox@163.com>

Hi All,
What is RVM t test? Is it possible to use it in R? And How?
Bests,
Allen Chiu

2014-08-26
	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Tue Aug 26 06:07:58 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 26 Aug 2014 12:07:58 +0800 (CST)
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <D020D0E6.108627%macqueen1@llnl.gov>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<D020D0E6.108627%macqueen1@llnl.gov>
Message-ID: <6b939ebc.14d38.148107fb8f2.Coremail.rhelpmaillist@163.com>

First, sorry for my pool english expression which make you misunderstanding of my original purpose.

Sometimes, suppose ?a object in both stats and base, then i type the object name, then after R search the search() list, R will use the object in stats, is it right?( I just suppose, stats can be any package which libraried into R.)
Then i know that, .GlobalEnv or globalenv() is the global environment object, baseenv() returns the base environment object.
I also know that, i can convert the environment name into the real environment object by using stats<-as.environment("package:stats"), ?And the stats environment's name can be obtained using environmentName(stats), but it returns "". ? (why?)
Then i use ?environmentName(.GlobalEnv) then i get "R_GlobalEnv", then i use?as.environment("R_GlobalEnv"), it does't work.(why?)


In one word, as.environment(x), x is somthing not the environment's name.?


But, when i add a environment into the search() list, after i attr(newenvir,"name")<-"new_name"
I can use the??as.environment("new_name") to obtain the added environment. (why?)


Hope you understand my meaning :)












--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-08-26 02:51:54, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>Put simply,
>   .GlobalEnv    stores objects you create
>   package:base  contains functions and objects provided by R itself
>
>You don?t need to use   .GlobalEnv$a   to use the variable named a. Just
>is ?a? by itself.
>
> a <- 4
> b <- 2*a
>print(a)
>print(b)
>
>Not necessary to use
>  print(.GlobalEnv$a)
>
>Similarly, to find an object in the base package, just type its name.
>
>I don?t know what you are trying to do, or why you think you have to use
>.GlobalEnv$a   
>But in more than 20 years of using R for many different tasks, I have
>never had to do that.
>
>Furthermore, if you are new to R (which I would guess is the case), it
>seems unlikely to me that you need to work with environments or use
>attach() or assign(). In the vast majority of cases there are simpler ways
>that are easier to understand.
>
>You are aware, I hope, that
>  > ls('.GlobalEnv')
>  > ls(1)
>  > ls()
>all return the same result?
>
>
>-- 
>Don MacQueen
>
>Lawrence Livermore National Laboratory
>7000 East Ave., L-627
>Livermore, CA 94550
>925-423-1062
>
>
>
>
>
>On 8/24/14, 11:07 PM, "PO SU" <rhelpmaillist at 163.com> wrote:
>
>>
>>
>>Dear rusers,
>>
>>    As we know, there are a lot of environments in the search() path,
>>such as   .Golbalenv and package:base .
>>And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable,  but
>>i must use as.envrionment("package:base") to find virable, i feel it not
>>very convenient.
>>
>>
>>For example, when i use the following codes to add a new env into the
>>search() path.
>>
>>
>>
>>> tmp<-attach(NULL,name="new_name")
>>> assign("a",2,envir=as.environment("new_name"))
>>> a
>>[1] 2
>>> as.environment("new_name")$a
>>[1] 2
>> I must always convert the name to the environment, How can i just use
>>the following form:
>>
>>
>>
>>> tmp<-attach(NULL,name="new_name")
>>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>>> a
>>[1] 2
>>> new_name$a
>>
>>[1] 2
>>
>>
>>
>>
>>
>>
>>
>>--
>>
>>PO SU
>>mail: desolator88 at 163.com
>>Majored in Statistics from SJTU
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>

From jdnewmil at dcn.davis.CA.us  Tue Aug 26 06:35:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 25 Aug 2014 21:35:51 -0700
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <6b939ebc.14d38.148107fb8f2.Coremail.rhelpmaillist@163.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<D020D0E6.108627%macqueen1@llnl.gov>
	<6b939ebc.14d38.148107fb8f2.Coremail.rhelpmaillist@163.com>
Message-ID: <df74941d-d744-48d7-bc5c-618e92b47e0d@email.android.com>

I would refer to base::somename or stat::somename if necessary, and I never use attach, get or assign.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 25, 2014 9:07:58 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>First, sorry for my pool english expression which make you
>misunderstanding of my original purpose.
>
>Sometimes, suppose ?a object in both stats and base, then i type the
>object name, then after R search the search() list, R will use the
>object in stats, is it right?( I just suppose, stats can be any package
>which libraried into R.)
>Then i know that, .GlobalEnv or globalenv() is the global environment
>object, baseenv() returns the base environment object.
>I also know that, i can convert the environment name into the real
>environment object by using stats<-as.environment("package:stats"),
>?And the stats environment's name can be obtained using
>environmentName(stats), but it returns "". ? (why?)
>Then i use ?environmentName(.GlobalEnv) then i get "R_GlobalEnv", then
>i use?as.environment("R_GlobalEnv"), it does't work.(why?)
>
>
>In one word, as.environment(x), x is somthing not the environment's
>name.?
>
>
>But, when i add a environment into the search() list, after i
>attr(newenvir,"name")<-"new_name"
>I can use the??as.environment("new_name") to obtain the added
>environment. (why?)
>
>
>Hope you understand my meaning :)
>
>
>
>
>
>
>
>
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>
>
>
>At 2014-08-26 02:51:54, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>>Put simply,
>>   .GlobalEnv    stores objects you create
>>   package:base  contains functions and objects provided by R itself
>>
>>You don?t need to use   .GlobalEnv$a   to use the variable named a.
>Just
>>is ?a? by itself.
>>
>> a <- 4
>> b <- 2*a
>>print(a)
>>print(b)
>>
>>Not necessary to use
>>  print(.GlobalEnv$a)
>>
>>Similarly, to find an object in the base package, just type its name.
>>
>>I don?t know what you are trying to do, or why you think you have to
>use
>>.GlobalEnv$a   
>>But in more than 20 years of using R for many different tasks, I have
>>never had to do that.
>>
>>Furthermore, if you are new to R (which I would guess is the case), it
>>seems unlikely to me that you need to work with environments or use
>>attach() or assign(). In the vast majority of cases there are simpler
>ways
>>that are easier to understand.
>>
>>You are aware, I hope, that
>>  > ls('.GlobalEnv')
>>  > ls(1)
>>  > ls()
>>all return the same result?
>>
>>
>>-- 
>>Don MacQueen
>>
>>Lawrence Livermore National Laboratory
>>7000 East Ave., L-627
>>Livermore, CA 94550
>>925-423-1062
>>
>>
>>
>>
>>
>>On 8/24/14, 11:07 PM, "PO SU" <rhelpmaillist at 163.com> wrote:
>>
>>>
>>>
>>>Dear rusers,
>>>
>>>    As we know, there are a lot of environments in the search() path,
>>>such as   .Golbalenv and package:base .
>>>And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable, 
>but
>>>i must use as.envrionment("package:base") to find virable, i feel it
>not
>>>very convenient.
>>>
>>>
>>>For example, when i use the following codes to add a new env into the
>>>search() path.
>>>
>>>
>>>
>>>> tmp<-attach(NULL,name="new_name")
>>>> assign("a",2,envir=as.environment("new_name"))
>>>> a
>>>[1] 2
>>>> as.environment("new_name")$a
>>>[1] 2
>>> I must always convert the name to the environment, How can i just
>use
>>>the following form:
>>>
>>>
>>>
>>>> tmp<-attach(NULL,name="new_name")
>>>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>>>> a
>>>[1] 2
>>>> new_name$a
>>>
>>>[1] 2
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>--
>>>
>>>PO SU
>>>mail: desolator88 at 163.com
>>>Majored in Statistics from SJTU
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Aug 26 08:33:07 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 26 Aug 2014 06:33:07 +0000
Subject: [R] How to do t.test to rows of a dataframe using apply
	family	function?
In-Reply-To: <9bf55c3.1013.1480febec6e.Coremail.my1stbox@163.com>
References: <9bf55c3.1013.1480febec6e.Coremail.my1stbox@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF7B2@SRVEXCHMBX.precheza.cz>

Hi

If your function works for you why to bother with apply? If it does not give you required results, please post some data and show us what is expected.

I would remove unlist from your function and declare list for storing data, which seems to me more natural for storing results.

t.test.list=function(df,paired){
   lll<-vector("list", length=nrow(df))
   for(i in 1:nrow(df)){

 lll[[i]]=t.test(df[i,grp1],df[i,grp2],paired=paired)
   }
  names(lll)=rownames(df)
   lll
> }

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of my1stbox
> Sent: Tuesday, August 26, 2014 3:26 AM
> To: R Help
> Subject: [R] How to do t.test to rows of a dataframe using apply family
> function?
>
> Hi All?
> How to do t.test  to rows (with two levels, or in other words, groups
> of samples) of a dataframe using apply family function? I have done
> that using function and loops. And my overall purpose is to calculate
> DE genes from two groups of miRNA microarray samples. And I know limma
> can do that, but it seems limma doesn't support paired t-test.
>
> t.test.df=function(df,paired){
>   df.t=c()
>   for(i in 1:nrow(df)){
>
> df.t=rbind(df.t,unlist(t.test(df[i,grp1],df[i,grp2],paired=paired)))
>   }
>   rownames(df.t)=rownames(df)
>   df.t
> }
>
> Bests!
> Allen Chiu
>
> 2014-08-26
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From p_connolly at slingshot.co.nz  Tue Aug 26 08:47:40 2014
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Tue, 26 Aug 2014 18:47:40 +1200
Subject: [R] yaxs Causes Boundary Line Colour to Change
In-Reply-To: <CAM_vjumjKaaeH6rrgZuKnMHEbTKbkj66YMcGwrRR7XziOB1RSw@mail.gmail.com>
References: <a4f0a13fc9cf44009758c664c212d223@BLUPR01MB035.prod.exchangelabs.com>
	<CAM_vjumjKaaeH6rrgZuKnMHEbTKbkj66YMcGwrRR7XziOB1RSw@mail.gmail.com>
Message-ID: <20140826064740.GA3192@slingshot.co.nz>

I can't reproduce it either using x11 or pdf devices.  I'm curious to
know just how you manage to get that result.


On Mon, 25-Aug-2014 at 10:15AM -0400, Sarah Goslee wrote:

|> I can't reproduce this on R 3.1.0 on linux or R 3.1.1 on Mac, using
|> the default graphics device on each.
|> 
|> What graphics device are you using?
|> 
|> If all else fails, you could use box() to draw over it.
|> 
|> Sarah
|> 
|> On Mon, Aug 25, 2014 at 8:00 AM, Dario Strbenac
|> <dstr7320 at uni.sydney.edu.au> wrote:
|> > Why is the bottom boundary plotted in a different colour to the other three sides ?
|> >
|> > set.seed(4444)
|> > data <- rpois(10, 2)
|> > plot(density(data), ann = FALSE, yaxs = 'i') # Grey bottom boundary.
|> > plot(density(data), ann = FALSE) # All boundaries are black.
|> >
|> > Ideally, there would be black lines on all four sides. The documentation doesn't say the colour will change.
|> >
|> >> sessionInfo()
|> > R version 3.1.1 (2014-07-10)
|> > Platform: x86_64-unknown-linux-gnu (64-bit)
|> >
|> > --------------------------------------
|> > Dario Strbenac
|> > PhD Student
|> > University of Sydney
|> > Camperdown NSW 2050
|> > Australia
|> >
|> > ______________________________________________
|> > R-help at r-project.org mailing list
|> > https://stat.ethz.ch/mailman/listinfo/r-help
|> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> > and provide commented, minimal, self-contained, reproducible code.
|> 
|> 
|> 
|> -- 
|> Sarah Goslee
|> http://www.functionaldiversity.org
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From debruinjj at gmail.com  Tue Aug 26 10:30:08 2014
From: debruinjj at gmail.com (Jurgens de Bruin)
Date: Tue, 26 Aug 2014 10:30:08 +0200
Subject: [R] VennDiagram
Message-ID: <CAMrqo6wFc7BrBOUfv7RGZ_Ne0EBCR1rN_LcY=5VKVBRPDcLXJA@mail.gmail.com>

Hi,

I am new to R and dont use it very often so I would appreciate some help.

I would like to create a VennDiagram based on the following, I have
analyzed experimental results using different methods and captured the
results of each analysis.
I would like the VennDiagram to show the overlap in results for the
different analysis.

Sample data:
 Analysis   Results
       A              1-5
       B               8-9
       C               4-7
       B               1-5
       A               20-50
       C               8-9

So in this simple example analysis A and B have a single sample overlap and
Analysis B and C also have a single overlap but C and A have no overlap.


-- 
Regards/Groete/Mit freundlichen Gr??en/recuerdos/meilleures salutations/
distinti saluti/siong/du? y?/??????

Jurgens de Bruin

	[[alternative HTML version deleted]]


From joao.patricio at gmx.pt  Tue Aug 26 10:35:59 2014
From: joao.patricio at gmx.pt (=?ISO-8859-1?Q?Jo=E3o_Azevedo_Patr=EDcio?=)
Date: Tue, 26 Aug 2014 09:35:59 +0100
Subject: [R] VennDiagram
In-Reply-To: <CAMrqo6wFc7BrBOUfv7RGZ_Ne0EBCR1rN_LcY=5VKVBRPDcLXJA@mail.gmail.com>
References: <CAMrqo6wFc7BrBOUfv7RGZ_Ne0EBCR1rN_LcY=5VKVBRPDcLXJA@mail.gmail.com>
Message-ID: <53FC46EF.30503@gmx.pt>

Em 26-08-2014 09:30, Jurgens de Bruin escreveu:
> Hi,
>
> I am new to R and dont use it very often so I would appreciate some help.
>
> I would like to create a VennDiagram based on the following, I have
> analyzed experimental results using different methods and captured the
> results of each analysis.
> I would like the VennDiagram to show the overlap in results for the
> different analysis.
>
> Sample data:
>   Analysis   Results
>         A              1-5
>         B               8-9
>         C               4-7
>         B               1-5
>         A               20-50
>         C               8-9
>
> So in this simple example analysis A and B have a single sample overlap and
> Analysis B and C also have a single overlap but C and A have no overlap.
>
>
Hi,

I don't know how to do it, but made a search and found this, see if it 
helps you

http://www.ats.ucla.edu/stat/r/faq/venn.htm

-- 
Jo?o Azevedo Patr?cio
Tel.: +31 91 400 53 63
Portugal
@ http://tripaforra.bl.ee

"Take 2 seconds to think before you act"


From debruinjj at gmail.com  Tue Aug 26 11:08:14 2014
From: debruinjj at gmail.com (Jurgens de Bruin)
Date: Tue, 26 Aug 2014 11:08:14 +0200
Subject: [R] VennDiagram
In-Reply-To: <53FC46EF.30503@gmx.pt>
References: <CAMrqo6wFc7BrBOUfv7RGZ_Ne0EBCR1rN_LcY=5VKVBRPDcLXJA@mail.gmail.com>
	<53FC46EF.30503@gmx.pt>
Message-ID: <CAMrqo6zmNnLZPwesBpPm0=x+wb0EWB2d+7NhmHrU-yQhEGdP5g@mail.gmail.com>

Hi,,
Thanks for the link, I have tried that but it seems my data is in the wrong
format for that to work.


On 26 August 2014 10:35, Jo?o Azevedo Patr?cio <joao.patricio at gmx.pt> wrote:

> Em 26-08-2014 09:30, Jurgens de Bruin escreveu:
>
>  Hi,
>>
>> I am new to R and dont use it very often so I would appreciate some help.
>>
>> I would like to create a VennDiagram based on the following, I have
>> analyzed experimental results using different methods and captured the
>> results of each analysis.
>> I would like the VennDiagram to show the overlap in results for the
>> different analysis.
>>
>> Sample data:
>>   Analysis   Results
>>         A              1-5
>>         B               8-9
>>         C               4-7
>>         B               1-5
>>         A               20-50
>>         C               8-9
>>
>> So in this simple example analysis A and B have a single sample overlap
>> and
>> Analysis B and C also have a single overlap but C and A have no overlap.
>>
>>
>>  Hi,
>
> I don't know how to do it, but made a search and found this, see if it
> helps you
>
> http://www.ats.ucla.edu/stat/r/faq/venn.htm
>
> --
> Jo?o Azevedo Patr?cio
> Tel.: +31 91 400 53 63
> Portugal
> @ http://tripaforra.bl.ee
>
> "Take 2 seconds to think before you act"
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Regards/Groete/Mit freundlichen Gr??en/recuerdos/meilleures salutations/
distinti saluti/siong/du? y?/??????

Jurgens de Bruin

	[[alternative HTML version deleted]]


From my1stbox at 163.com  Tue Aug 26 11:08:07 2014
From: my1stbox at 163.com (my1stbox)
Date: Tue, 26 Aug 2014 17:08:07 +0800
Subject: [R] What would a typical miRNA microarray analysis workflow look
	like?
Message-ID: <6510f373.31ba.1481192d74f.Coremail.my1stbox@163.com>

Hi all,
What would a typical miRNA microarray analysis workflow look like? Say just a test group of 5 replicates from bladder cancer tumor and corresponding control group from normal tissue of the same patients. What could I do to make the analysis seems more sophisticated. I have done differential expression analysis, target gene prediction, and GO, pathway enrichments of target genes. What else could I do? It would be better if you can specify some packages or codes.
Regards,
Allen

PS: Is paired (t)-test necessery? I found that DE gene number from paired t-test is about half of that from normal limma functions( which I don't know how to do paired test if it could).

2014-08-26
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Aug 26 11:58:35 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 26 Aug 2014 09:58:35 +0000
Subject: [R] How to do t.test to rows of a dataframe using apply
 family	function?
In-Reply-To: <7dc9a0cb.5ab4.148117c9a68.Coremail.my1stbox@163.com>
References: <9bf55c3.1013.1480febec6e.Coremail.my1stbox@163.com><6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF7B2@SRVEXCHMBX.precheza.cz>
	<7dc9a0cb.5ab4.148117c9a68.Coremail.my1stbox@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF899@SRVEXCHMBX.precheza.cz>

Hi
Please reply also to rhelp, maybe others can offer better answer.
Well, are you aware that by unlist you get all results as character values and not numbers?
Personally I would use lapply and do.call on final result to get it as data frame.
Here is example
Some model list data
lll<-vector("list",length=2)
lll
[[1]]
NULL
[[2]]
NULL
lll[[1]]<-t.test(rnorm(20), rnorm(20))
lll[[2]]<-t.test(rnorm(20), rnorm(20))
str(unlist(lll))
Named chr [1:22] "0.0091599930484716" "37.9972278626102" ...
- attr(*, "names")= chr [1:22] "statistic.t" "parameter.df" "p.value" "conf.int1" ...
do.call(rbind, lapply(lll, rbind))
     statistic   parameter p.value   conf.int  estimate  null.value alternative
[1,] 0.009159993 37.99723  0.9927394 Numeric,2 Numeric,2 0          "two.sided"
[2,] 0.1256267   32.93057  0.9007913 Numeric,2 Numeric,2 0          "two.sided"
     method                    data.name
[1,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
[2,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
Regards
Petr

From: my1stbox [mailto:my1stbox at 163.com]
Sent: Tuesday, August 26, 2014 10:44 AM
To: PIKAL Petr
Subject: Re: RE: [R] How to do t.test to rows of a dataframe using apply family function?

Hi Petr?
Thank you! I use unlist() and rbind() because I want the result to be in the form of a matrix.
Regards
Allen

2014-08-26
________________________________

________________________________
????PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
?????2014-08-26 14:33
???RE: [R] How to do t.test to rows of a dataframe using apply family function?
????"my1stbox"<my1stbox at 163.com<mailto:my1stbox at 163.com>>,"R Help"<r-help at r-project.org<mailto:r-help at r-project.org>>
???

Hi

If your function works for you why to bother with apply? If it does not give you required results, please post some data and show us what is expected.

I would remove unlist from your function and declare list for storing data, which seems to me more natural for storing results.

t.test.list=function(df,paired){
   lll<-vector("list", length=nrow(df))
   for(i in 1:nrow(df)){

 lll[[i]]=t.test(df[i,grp1],df[i,grp2],paired=paired)
   }
  names(lll)=rownames(df)
   lll
> }

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-
> project.org] On Behalf Of my1stbox
> Sent: Tuesday, August 26, 2014 3:26 AM
> To: R Help
> Subject: [R] How to do t.test to rows of a dataframe using apply family
> function?
>
> Hi All?
> How to do t.test  to rows (with two levels, or in other words, groups
> of samples) of a dataframe using apply family function? I have done
> that using function and loops. And my overall purpose is to calculate
> DE genes from two groups of miRNA microarray samples. And I know limma
> can do that, but it seems limma doesn't support paired t-test.
>
> t.test.df=function(df,paired){
>   df.t=c()
>   for(i in 1:nrow(df)){
>
> df.t=rbind(df.t,unlist(t.test(df[i,grp1],df[i,grp2],paired=paired)))
>   }
>   rownames(df.t)=rownames(df)
>   df.t
> }
>
> Bests!
> Allen Chiu
>
> 2014-08-26
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From my1stbox at 163.com  Tue Aug 26 12:24:13 2014
From: my1stbox at 163.com (my1stbox)
Date: Tue, 26 Aug 2014 18:24:13 +0800
Subject: [R] How to do t.test to rows of a dataframe using apply
 family	function?
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF899@SRVEXCHMBX.precheza.cz>
References: <9bf55c3.1013.1480febec6e.Coremail.my1stbox@163.com><6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF7B2@SRVEXCHMBX.precheza.cz>
	<7dc9a0cb.5ab4.148117c9a68.Coremail.my1stbox@163.com><6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF899@SRVEXCHMBX.precheza.cz>
Message-ID: <4e03bf24.6a9c.14811d885a3.Coremail.my1stbox@163.com>

Thank you so much!
Why do do.call(rbind,lapply(lll,rbind)) and rbind(lapply(lll,rbind)) act so differently? What is the tricky part of that?
> do.call(rbind,lapply(lll,rbind))
statistic parameter p.value conf.int estimate null.value alternative
[1,] 2.775282 37.99977 0.008509272 Numeric,2 Numeric,2 0 "two.sided"
[2,] -1.498133 37.31294 0.1425116 Numeric,2 Numeric,2 0 "two.sided"
method data.name 
[1,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
[2,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
> rbind(lapply(lll,rbind))
[,1] [,2] 
[1,] List,9 List,9

2014-08-26 






????PIKAL Petr <petr.pikal at precheza.cz>
?????2014-08-26 17:58
???RE: RE: [R] How to do t.test to rows of a dataframe using apply family function?
????"my1stbox"<my1stbox at 163.com>
???"R Help"<r-help at r-project.org>

Hi
Please reply also to rhelp, maybe others can offer better answer.
Well, are you aware that by unlist you get all results as character values and not numbers?
Personally I would use lapply and do.call on final result to get it as data frame.
Here is example
Some model list data
lll<-vector("list",length=2)
lll
[[1]]
NULL
[[2]]
NULL
lll[[1]]<-t.test(rnorm(20), rnorm(20))
lll[[2]]<-t.test(rnorm(20), rnorm(20))
str(unlist(lll))
Named chr [1:22] "0.0091599930484716" "37.9972278626102" ...
- attr(*, "names")= chr [1:22] "statistic.t" "parameter.df" "p.value" "conf.int1" ...
do.call(rbind, lapply(lll, rbind))
     statistic   parameter p.value   conf.int  estimate  null.value alternative
[1,] 0.009159993 37.99723  0.9927394 Numeric,2 Numeric,2 0          "two.sided"
[2,] 0.1256267   32.93057  0.9007913 Numeric,2 Numeric,2 0          "two.sided"
     method                    data.name                
[1,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
[2,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
Regards
Petr

From: my1stbox [mailto:my1stbox at 163.com] 
Sent: Tuesday, August 26, 2014 10:44 AM
To: PIKAL Petr
Subject: Re: RE: [R] How to do t.test to rows of a dataframe using apply family function?

Hi Petr?
Thank you! I use unlist() and rbind() because I want the result to be in the form of a matrix.
Regards
Allen

2014-08-26 







????PIKAL Petr <petr.pikal at precheza.cz>
?????2014-08-26 14:33
???RE: [R] How to do t.test to rows of a dataframe using apply family function?
????"my1stbox"<my1stbox at 163.com>,"R Help"<r-help at r-project.org>
???

Hi 

If your function works for you why to bother with apply? If it does not give you required results, please post some data and show us what is expected. 

I would remove unlist from your function and declare list for storing data, which seems to me more natural for storing results. 

t.test.list=function(df,paired){ 
   lll<-vector("list", length=nrow(df)) 
   for(i in 1:nrow(df)){ 

 lll[[i]]=t.test(df[i,grp1],df[i,grp2],paired=paired) 
   } 
  names(lll)=rownames(df) 
   lll 
> } 

Regards 
Petr 


> -----Original Message----- 
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r- 
> project.org] On Behalf Of my1stbox 
> Sent: Tuesday, August 26, 2014 3:26 AM 
> To: R Help 
> Subject: [R] How to do t.test to rows of a dataframe using apply family 
> function? 
> 
> Hi All? 
> How to do t.test  to rows (with two levels, or in other words, groups 
> of samples) of a dataframe using apply family function? I have done 
> that using function and loops. And my overall purpose is to calculate 
> DE genes from two groups of miRNA microarray samples. And I know limma 
> can do that, but it seems limma doesn't support paired t-test. 
> 
> t.test.df=function(df,paired){ 
>   df.t=c() 
>   for(i in 1:nrow(df)){ 
> 
> df.t=rbind(df.t,unlist(t.test(df[i,grp1],df[i,grp2],paired=paired))) 
>   } 
>   rownames(df.t)=rownames(df) 
>   df.t 
> } 
> 
> Bests! 
> Allen Chiu 
> 
> 2014-08-26 
>       [[alternative HTML version deleted]] 
> 
> ______________________________________________ 
> R-help at r-project.org mailing list 
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html 
> and provide commented, minimal, self-contained, reproducible code. 

________________________________ 
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m. 
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu. 
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat. 
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu. 

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?: 
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu. 
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou. 
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech. 
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?. 

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients. 
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system. 
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner. 
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email. 

In case that this e-mail forms part of business dealings: 
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning. 
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation. 
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects. 
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient. 



Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Aug 26 14:21:26 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 26 Aug 2014 12:21:26 +0000
Subject: [R] How to do t.test to rows of a dataframe using apply
 family	function?
In-Reply-To: <4e03bf24.6a9c.14811d885a3.Coremail.my1stbox@163.com>
References: <9bf55c3.1013.1480febec6e.Coremail.my1stbox@163.com><6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF7B2@SRVEXCHMBX.precheza.cz>
	<7dc9a0cb.5ab4.148117c9a68.Coremail.my1stbox@163.com><6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF899@SRVEXCHMBX.precheza.cz>
	<4e03bf24.6a9c.14811d885a3.Coremail.my1stbox@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDF903@SRVEXCHMBX.precheza.cz>

Hi
That is because do.call is one function and rbind another. For both functions you can find its help page and read:
rbind
vectors or matrices. These can be given as named arguments. Other R objects will be coerced as appropriate: see sections ?Details? and ?Value?.

The type of a matrix result determined from the highest type of any of the inputs in the hierarchy raw < logical < integer < double < complex < character < list .
do.call
what

either a function or a non-empty character string naming the function to be called.

args

a list of arguments to the function call. The names attribute of args gives the argument names.

Actually inner lapply was not necessary and simple
do.call("rbind", lll)
gives the same result.
From what I understand from help page, when argument in rbind is list of lists it returns matrix of lists which are printed as
    [,1]   [,2]
lll List,9 List,9
do.call takes rbind and uses it on each node of list and this node is coerced to matrix, which is suitable for changing to data frame.
as.data.frame(do.call("rbind", lll))
It is some magic of R which I use although I do not know much about its internals. If you are interested, the source code is available.
Regards
Petr
From: my1stbox [mailto:my1stbox at 163.com]
Sent: Tuesday, August 26, 2014 12:24 PM
To: PIKAL Petr
Cc: R Help
Subject: Re: RE: RE: [R] How to do t.test to rows of a dataframe using apply family function?

Thank you so much!
Why do do.call(rbind,lapply(lll,rbind)) and rbind(lapply(lll,rbind)) act so differently? What is the tricky part of that?
> do.call(rbind,lapply(lll,rbind))
statistic parameter p.value conf.int estimate null.value alternative
[1,] 2.775282 37.99977 0.008509272 Numeric,2 Numeric,2 0 "two.sided"
[2,] -1.498133 37.31294 0.1425116 Numeric,2 Numeric,2 0 "two.sided"
method data.name
[1,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
[2,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
> rbind(lapply(lll,rbind))
[,1] [,2]
[1,] List,9 List,9

2014-08-26
________________________________

________________________________
????PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
?????2014-08-26 17:58
???RE: RE: [R] How to do t.test to rows of a dataframe using apply family function?
????"my1stbox"<my1stbox at 163.com<mailto:my1stbox at 163.com>>
???"R Help"<r-help at r-project.org<mailto:r-help at r-project.org>>

Hi
Please reply also to rhelp, maybe others can offer better answer.
Well, are you aware that by unlist you get all results as character values and not numbers?
Personally I would use lapply and do.call on final result to get it as data frame.
Here is example
Some model list data
lll<-vector("list",length=2)
lll
[[1]]
NULL
[[2]]
NULL
lll[[1]]<-t.test(rnorm(20), rnorm(20))
lll[[2]]<-t.test(rnorm(20), rnorm(20))
str(unlist(lll))
Named chr [1:22] "0.0091599930484716" "37.9972278626102" ...
- attr(*, "names")= chr [1:22] "statistic.t" "parameter.df" "p.value" "conf.int1" ...
do.call(rbind, lapply(lll, rbind))
     statistic   parameter p.value   conf.int  estimate  null.value alternative
[1,] 0.009159993 37.99723  0.9927394 Numeric,2 Numeric,2 0          "two.sided"
[2,] 0.1256267   32.93057  0.9007913 Numeric,2 Numeric,2 0          "two.sided"
     method                    data.name
[1,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
[2,] "Welch Two Sample t-test" "rnorm(20) and rnorm(20)"
Regards
Petr

From: my1stbox [mailto:my1stbox at 163.com]
Sent: Tuesday, August 26, 2014 10:44 AM
To: PIKAL Petr
Subject: Re: RE: [R] How to do t.test to rows of a dataframe using apply family function?

Hi Petr?
Thank you! I use unlist() and rbind() because I want the result to be in the form of a matrix.
Regards
Allen

2014-08-26
________________________________

________________________________
????PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>>
?????2014-08-26 14:33
???RE: [R] How to do t.test to rows of a dataframe using apply family function?
????"my1stbox"<my1stbox at 163.com<mailto:my1stbox at 163.com>>,"R Help"<r-help at r-project.org<mailto:r-help at r-project.org>>
???

Hi

If your function works for you why to bother with apply? If it does not give you required results, please post some data and show us what is expected.

I would remove unlist from your function and declare list for storing data, which seems to me more natural for storing results.

t.test.list=function(df,paired){
   lll<-vector("list", length=nrow(df))
   for(i in 1:nrow(df)){

 lll[[i]]=t.test(df[i,grp1],df[i,grp2],paired=paired)
   }
  names(lll)=rownames(df)
   lll
> }

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-
> project.org] On Behalf Of my1stbox
> Sent: Tuesday, August 26, 2014 3:26 AM
> To: R Help
> Subject: [R] How to do t.test to rows of a dataframe using apply family
> function?
>
> Hi All?
> How to do t.test  to rows (with two levels, or in other words, groups
> of samples) of a dataframe using apply family function? I have done
> that using function and loops. And my overall purpose is to calculate
> DE genes from two groups of miRNA microarray samples. And I know limma
> can do that, but it seems limma doesn't support paired t-test.
>
> t.test.df=function(df,paired){
>   df.t=c()
>   for(i in 1:nrow(df)){
>
> df.t=rbind(df.t,unlist(t.test(df[i,grp1],df[i,grp2],paired=paired)))
>   }
>   rownames(df.t)=rownames(df)
>   df.t
> }
>
> Bests!
> Allen Chiu
>
> 2014-08-26
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Tue Aug 26 14:57:36 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 26 Aug 2014 12:57:36 +0000
Subject: [R] VennDiagram
In-Reply-To: <CAMrqo6zmNnLZPwesBpPm0=x+wb0EWB2d+7NhmHrU-yQhEGdP5g@mail.gmail.com>
References: <CAMrqo6wFc7BrBOUfv7RGZ_Ne0EBCR1rN_LcY=5VKVBRPDcLXJA@mail.gmail.com>
	<53FC46EF.30503@gmx.pt>
	<CAMrqo6zmNnLZPwesBpPm0=x+wb0EWB2d+7NhmHrU-yQhEGdP5g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F92B87@mb02.ads.tamu.edu>

Assuming your sample data is called dta:

> table(dta$Results, dta$Analysis)
       
        A B C
  1-5   1 1 0
  20-50 1 0 0
  4-7   0 0 1
  8-9   0 1 1


David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jurgens de Bruin
Sent: Tuesday, August 26, 2014 4:08 AM
To: Jo?o Azevedo Patr?cio
Cc: r-help at r-project.org
Subject: Re: [R] VennDiagram

Hi,,
Thanks for the link, I have tried that but it seems my data is in the wrong format for that to work.


On 26 August 2014 10:35, Jo?o Azevedo Patr?cio <joao.patricio at gmx.pt> wrote:

> Em 26-08-2014 09:30, Jurgens de Bruin escreveu:
>
>  Hi,
>>
>> I am new to R and dont use it very often so I would appreciate some help.
>>
>> I would like to create a VennDiagram based on the following, I have 
>> analyzed experimental results using different methods and captured 
>> the results of each analysis.
>> I would like the VennDiagram to show the overlap in results for the 
>> different analysis.
>>
>> Sample data:
>>   Analysis   Results
>>         A              1-5
>>         B               8-9
>>         C               4-7
>>         B               1-5
>>         A               20-50
>>         C               8-9
>>
>> So in this simple example analysis A and B have a single sample 
>> overlap and Analysis B and C also have a single overlap but C and A 
>> have no overlap.
>>
>>
>>  Hi,
>
> I don't know how to do it, but made a search and found this, see if it 
> helps you
>
> http://www.ats.ucla.edu/stat/r/faq/venn.htm
>
> --
> Jo?o Azevedo Patr?cio
> Tel.: +31 91 400 53 63
> Portugal
> @ http://tripaforra.bl.ee
>
> "Take 2 seconds to think before you act"
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/ 
> posting-guide.html and provide commented, minimal, self-contained, 
> reproducible code.
>



--
Regards/Groete/Mit freundlichen Gr??en/recuerdos/meilleures salutations/ distinti saluti/siong/du? y?/??????

Jurgens de Bruin

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From kulupp at online.de  Tue Aug 26 15:03:20 2014
From: kulupp at online.de (Kulupp)
Date: Tue, 26 Aug 2014 15:03:20 +0200
Subject: [R] package 'gradientForest' and 'extendedForest'
Message-ID: <53FC8598.4030104@online.de>

Dear experts,

I have 5 environmental predictors and abundance data (300 samples, 60 
species, transformation: log(x + min(x,x > 0) and use the function 
'gradientForest' to estimate (R?-weighted) predictor importance 
(regression trees). The resulting predictor importance in decreasing 
order is as follows: pred1, pred2, pred3, pred4, pred5. The two species 
with the highest R? (goodness-of-fit; output value 'result' of function 
'gradientForest') are species 1 (R?=0.76), species 2 (R?=0.74), and 
species 3 (R?=0.72). To my understanding this means that the model (i.e. 
the predictor importance ranking) fits best to species 1, 2, and 3 in 
decreasing order. In a further step I want to know which predictors are 
the most important for selected species. Thus, I ran separate forests 
using the 'extendedForest' function with the same parameter settings 
(and the same set.seed()) as in the function call of 'gradientForest' 
for species 1, 2, and 3 (and others). Now the resulting predictor 
importance is (in decreasing order): species1: pred1, pred2, pred4, 
pred3, pred5; species2: pred1, pred4, pred2, pred5, pred3; species3: 
pred2, pred4, pred5, pred1, pred3. This seems strange to me, because I 
believed that the 'extendedForest' function should give similar 
predictor importance rankings as the 'gradientForest' predictor 
importance ranking for the species with the highest R? values obtained 
by 'gradientForest' . I'd be grateful for any help. Thanks a lot in 
anticipation.

Best regards

Thomas


	[[alternative HTML version deleted]]


From silong.liao at hotmail.com  Tue Aug 26 13:17:14 2014
From: silong.liao at hotmail.com (Silong Liao)
Date: Tue, 26 Aug 2014 11:17:14 +0000
Subject: [R] Plot survreg and intcox
Message-ID: <DUB122-W11361C61E8FFE9490E922CFADC0@phx.gbl>

Dear R users,
I'm trying to plot survival probability against time(in years) using "survreg" and "intcox". Please can you help me with this problem?
My code shows below:>mod.reg1=survreg(s_new~type+sex+eye+preopiop+preopva,dist="weibull")>summary(mod.reg1)
Call:survreg(formula = s_new ~ type + sex + eye + preopiop + preopva,     dist = "weibull")             Value Std. Error      z        p(Intercept) 40.539     20.582  1.970 4.89e-02typeTrab    -6.606      4.279 -1.544 1.23e-01sexM        -1.055      3.765 -0.280 7.79e-01eyeR        -2.112      3.587 -0.589 5.56e-01preopiop    -0.308      0.269 -1.147 2.52e-01preopva     -0.461      1.771 -0.260 7.95e-01Log(scale)   2.058      0.285  7.222 5.12e-13
Scale= 7.83 
Weibull distributionLoglik(model)= -78.7   Loglik(intercept only)= -81.4	Chisq= 5.37 on 5 degrees of freedom, p= 0.37 Number of Newton-Raphson Iterations: 10 n= 339
------------------------------------------------------------------------------------------------------------->cox.fit=intcox(s_new~type+eye+sex+age+preopiop+preopva,data=glaucoma_new)>summary(cox.fit)Call:intcox(formula = s_new ~ type + eye + sex + age + preopiop +     preopva, data = glaucoma_new)
  n= 339
             coef exp(coef) se(coef)  z Pr(>|z|)typeTrab  0.59391   1.81106       NA NA       NAeyeR      0.28419   1.32868       NA NA       NAsexM     -0.11597   0.89050       NA NA       NAage      -0.06556   0.93655       NA NA       NApreopiop  0.03903   1.03980       NA NA       NApreopva  -0.05517   0.94632       NA NA       NA
         exp(coef) exp(-coef) lower .95 upper .95typeTrab    1.8111     0.5522        NA        NAeyeR        1.3287     0.7526        NA        NAsexM        0.8905     1.1230        NA        NAage         0.9365     1.0678        NA        NApreopiop    1.0398     0.9617        NA        NApreopva     0.9463     1.0567        NA        NA
Rsquare= NA   (max possible= 0.327 )Likelihood ratio test= NA  on 6 df,   p=NAWald test            = NA  on 6 df,   p=NAScore (logrank) test = NA  on 6 df,   p=NA


Kind regards,Sid

 		 	   		  
	[[alternative HTML version deleted]]


From guilhermeleite.bio at gmail.com  Tue Aug 26 15:21:06 2014
From: guilhermeleite.bio at gmail.com (Guilherme Leite)
Date: Tue, 26 Aug 2014 10:21:06 -0300
Subject: [R] StackRaster problem
Message-ID: <CADDObQh6AoJDra08nAS8BPZNFiUV_t9viTxW64f+wjy38ktTwg@mail.gmail.com>

Hi,

This is the process I want to do:

> files <- list.files(path=paste(system.file(package="dismo"), '/ex',
sep=''), pattern='grd', full.names=TRUE )

> # The above finds all the files with extension "grd" in the
> # examples ("ex") directory of the dismo package. You do not
> # need such a complex statement to get your own files.

> files
[1] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio1.grd"
[2] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio12.grd"
[3] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio16.grd"
[4] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio17.grd"
[5] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio5.grd"
[6] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio6.grd"
[7] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio7.grd"
[8] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio8.grd"
[9] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/biome.grd"

> predictors <- stack(files)
> predictors

class : RasterStack
dimensions : 192, 186, 35712, 9 (nrow, ncol, ncell, nlayers)
resolution : 0.5, 0.5 (x, y)
extent : -125, -32, -56, 40 (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
names : bio1, bio12, bio16, bio17, bio5, bio6, bio7, bio8, biome
min values : -23, 0, 0, 0, 61, -212, 60, -66, 1
max values : 289, 7682, 2458, 1496, 422, 242, 461, 323, 14

But what happen is:

> files <- list.files(path=paste(system.file(package="dismo"), '/ex',
sep=''), pattern='grd', full.names=TRUE )

> files

[1] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio1.grd"
[2] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio12.grd"
[3] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio16.grd"
[4] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio17.grd"
[5] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio5.grd"
[6] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio6.grd"
[7] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio7.grd"
[8] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio8.grd"
[9] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/biome.grd"

> predictors <- stack(files)
Error in rep.int(names(x), lapply(x, length)) : invalid 'times' value

Do you know how to fix it?

Thank you,
Guilherme

	[[alternative HTML version deleted]]


From Alexander.Sommer at tu-dortmund.de  Tue Aug 26 15:28:38 2014
From: Alexander.Sommer at tu-dortmund.de (Alexander Sommer)
Date: Tue, 26 Aug 2014 15:28:38 +0200
Subject: [R]  Weighted Mann-Whitney-Wilcoxon-Test
In-Reply-To: <CAJ55+d+hRv7Ou5DwUaFwStnf2oftPKXd4zJnyg+F9AEVvz-ymA@mail.gmail.com>
References: <000301cfbbb6$18c55020$4a4ff060$@tu-dortmund.de>
	<CAJ55+d+hRv7Ou5DwUaFwStnf2oftPKXd4zJnyg+F9AEVvz-ymA@mail.gmail.com>
Message-ID: <000a01cfc131$a8710090$f95301b0$@tu-dortmund.de>

On Tuesday, August 19, 2014 9:46 PM Thomas Lumley <tlumley at uw.edu> wrote:

>> Is anyone aware of an(other) implementation in R?
> survey::svyranktest

Oh, that easy. Thanks a lot.

Actually, in my case the weights do not derive from some selection probabilities, but your test works anyway.


For completeness (and this time with a working example):

set.seed(seed = 123)
count.x <- NULL
count.y <- NULL
j <- 1
for (i in sample(x = 10:20, size = 20, replace = TRUE)){
 count.x[j] <- sample(x = 0:i, size = 1)
 count.y[j] <- i - count.x[j]
 j          <- j + 1
}
data <- data.frame(x.portion = (count.x/(count.x + count.y)),
                   y.portion = (count.y/(count.x + count.y)),
                   group     = c(rep("A", 12), rep("B", 8)),
                   weight    = (count.x + count.y)
                  )

I first considered the unweighted case with

library(package = survey)
design <- svydesign(ids = ~0, data = data)
svyranktest(formula = x.portion ~ group, design = design)

and compared it to the default Wilcoxon test by

wilcox.test(formula = x.portion ~ group, data = data, exact = FALSE, correct = FALSE)

Or, if you prefer

library(package = coin)
wilcox_test(formula = x.portion ~ group, data = data)

The resulting p-values differ, as I understood due to an approximation in package /survey/.

Now, finally, the weighted case:

design <- svydesign(ids = ~0, data = data, weights = ~weight)
svyranktest(formula = x.portion ~ group, design)

And, by the way, package /survey/ seems also to be the preferable way, if you want to go for a parametric test. Once again, the unweighted case first:

design <- svydesign(ids = ~0, data = data)
svyttest(formula = x.portion ~ group, design)

And, yet again, the results differ from the default t test

t.test(formula = x.portion ~ group, data = data)

This time, I guess, it is due to the way standard errors are computed.

Finally (this time for real), the weighted case:

design <- svydesign(ids = ~0, data = data, weights = ~weight)
svyttest(x.portion ~ group, design)

Note that function /wtd.t.test/ from package /weights/ depends on the scale of the weights, /svyttest/ not.


Thomas, one more time: thank you for your help.

Cheers,

Alex


-- 
Alexander Sommer
wissenschaftlicher Mitarbeiter

Technische Universit?t Dortmund 
Fakult?t Erziehungswissenschaft, Psychologie und Soziologie
Forschungsverbund Deutsches Jugendinstitut/Technische Universit?t Dortmund
Vogelpothsweg 78
44227 Dortmund

Telefon: +49 231 755-8189
Fax:     +49 231 755-6553
E-Mail:  Alexander.Sommer at tu-dortmund.de
WWW:     http://www.forschungsverbund.tu-dortmund.de/


From jon.skoien at jrc.ec.europa.eu  Tue Aug 26 17:15:32 2014
From: jon.skoien at jrc.ec.europa.eu (Jon Skoien)
Date: Tue, 26 Aug 2014 17:15:32 +0200
Subject: [R] StackRaster problem
In-Reply-To: <CADDObQh6AoJDra08nAS8BPZNFiUV_t9viTxW64f+wjy38ktTwg@mail.gmail.com>
References: <CADDObQh6AoJDra08nAS8BPZNFiUV_t9viTxW64f+wjy38ktTwg@mail.gmail.com>
Message-ID: <53FCA494.7040607@jrc.ec.europa.eu>

Did you attach the raster package with library(raster)? It seems the 
newest version of dismo does not depend on raster, so you will not be 
able to use raster-functions if you only attach dismo.
This error message typically comes when R tries to use 
utils:::stack.default instead of the stack-function defined in the 
raster-package.

If this is not the case, please give the output from sessionInfo().

Cheers,
Jon

On 8/26/2014 3:21 PM, Guilherme Leite wrote:
> Hi,
>
> This is the process I want to do:
>
>> files <- list.files(path=paste(system.file(package="dismo"), '/ex',
> sep=''), pattern='grd', full.names=TRUE )
>
>> # The above finds all the files with extension "grd" in the
>> # examples ("ex") directory of the dismo package. You do not
>> # need such a complex statement to get your own files.
>
>> files
> [1] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio1.grd"
> [2] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio12.grd"
> [3] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio16.grd"
> [4] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio17.grd"
> [5] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio5.grd"
> [6] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio6.grd"
> [7] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio7.grd"
> [8] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio8.grd"
> [9] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/biome.grd"
>
>> predictors <- stack(files)
>> predictors
>
> class : RasterStack
> dimensions : 192, 186, 35712, 9 (nrow, ncol, ncell, nlayers)
> resolution : 0.5, 0.5 (x, y)
> extent : -125, -32, -56, 40 (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> names : bio1, bio12, bio16, bio17, bio5, bio6, bio7, bio8, biome
> min values : -23, 0, 0, 0, 61, -212, 60, -66, 1
> max values : 289, 7682, 2458, 1496, 422, 242, 461, 323, 14
>
> But what happen is:
>
>> files <- list.files(path=paste(system.file(package="dismo"), '/ex',
> sep=''), pattern='grd', full.names=TRUE )
>
>> files
>
> [1] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio1.grd"
> [2] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio12.grd"
> [3] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio16.grd"
> [4] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio17.grd"
> [5] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio5.grd"
> [6] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio6.grd"
> [7] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio7.grd"
> [8] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/bio8.grd"
> [9] "d:/temp/Rtmp8Mttik/Rinst1fe4202d2ea5/dismo/ex/biome.grd"
>
>> predictors <- stack(files)
> Error in rep.int(names(x), lapply(x, length)) : invalid 'times' value
>
> Do you know how to fix it?
>
> Thank you,
> Guilherme
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Climate Risk Management Unit

Via Fermi 2749, TP 100-01,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual 
and do not necessarily represent official views of the European Commission.


From wdunlap at tibco.com  Tue Aug 26 18:02:07 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 26 Aug 2014 09:02:07 -0700
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <6b939ebc.14d38.148107fb8f2.Coremail.rhelpmaillist@163.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<D020D0E6.108627%macqueen1@llnl.gov>
	<6b939ebc.14d38.148107fb8f2.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMcaG89cn3qFcytaxiuN92kP1Z6FNUMUGvDkZ01Kg_qtZ-Q@mail.gmail.com>

as.environment(characterString) maps an entry from the output of
search() to the environment at the named position in the search list.
as.environment(number) maps an index into the output of search() to
the the environment at that position in the search list.  If
'characterString' is not in the output of search() or 'number' is not
in seq_along(search()) then as.environment throws an error.  As far as
I can tell, as.environment does not deal with the name of the
environment at all.  (When you attach an environment, attach will add
a name attribute to the copied environment so the attached
environment's name matches the name on the output of search(), but I
don't think as.environment ever looks at that attribute.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Aug 25, 2014 at 9:07 PM, PO SU <rhelpmaillist at 163.com> wrote:
> First, sorry for my pool english expression which make you misunderstanding of my original purpose.
>
> Sometimes, suppose  a object in both stats and base, then i type the object name, then after R search the search() list, R will use the object in stats, is it right?( I just suppose, stats can be any package which libraried into R.)
> Then i know that, .GlobalEnv or globalenv() is the global environment object, baseenv() returns the base environment object.
> I also know that, i can convert the environment name into the real environment object by using stats<-as.environment("package:stats"),  And the stats environment's name can be obtained using environmentName(stats), but it returns "".   (why?)
> Then i use  environmentName(.GlobalEnv) then i get "R_GlobalEnv", then i use as.environment("R_GlobalEnv"), it does't work.(why?)
>
>
> In one word, as.environment(x), x is somthing not the environment's name.
>
>
> But, when i add a environment into the search() list, after i attr(newenvir,"name")<-"new_name"
> I can use the  as.environment("new_name") to obtain the added environment. (why?)
>
>
> Hope you understand my meaning :)
>
>
>
>
>
>
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-08-26 02:51:54, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>>Put simply,
>>   .GlobalEnv    stores objects you create
>>   package:base  contains functions and objects provided by R itself
>>
>>You don?t need to use   .GlobalEnv$a   to use the variable named a. Just
>>is ?a? by itself.
>>
>> a <- 4
>> b <- 2*a
>>print(a)
>>print(b)
>>
>>Not necessary to use
>>  print(.GlobalEnv$a)
>>
>>Similarly, to find an object in the base package, just type its name.
>>
>>I don?t know what you are trying to do, or why you think you have to use
>>.GlobalEnv$a
>>But in more than 20 years of using R for many different tasks, I have
>>never had to do that.
>>
>>Furthermore, if you are new to R (which I would guess is the case), it
>>seems unlikely to me that you need to work with environments or use
>>attach() or assign(). In the vast majority of cases there are simpler ways
>>that are easier to understand.
>>
>>You are aware, I hope, that
>>  > ls('.GlobalEnv')
>>  > ls(1)
>>  > ls()
>>all return the same result?
>>
>>
>>--
>>Don MacQueen
>>
>>Lawrence Livermore National Laboratory
>>7000 East Ave., L-627
>>Livermore, CA 94550
>>925-423-1062
>>
>>
>>
>>
>>
>>On 8/24/14, 11:07 PM, "PO SU" <rhelpmaillist at 163.com> wrote:
>>
>>>
>>>
>>>Dear rusers,
>>>
>>>    As we know, there are a lot of environments in the search() path,
>>>such as   .Golbalenv and package:base .
>>>And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable,  but
>>>i must use as.envrionment("package:base") to find virable, i feel it not
>>>very convenient.
>>>
>>>
>>>For example, when i use the following codes to add a new env into the
>>>search() path.
>>>
>>>
>>>
>>>> tmp<-attach(NULL,name="new_name")
>>>> assign("a",2,envir=as.environment("new_name"))
>>>> a
>>>[1] 2
>>>> as.environment("new_name")$a
>>>[1] 2
>>> I must always convert the name to the environment, How can i just use
>>>the following form:
>>>
>>>
>>>
>>>> tmp<-attach(NULL,name="new_name")
>>>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>>>> a
>>>[1] 2
>>>> new_name$a
>>>
>>>[1] 2
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>--
>>>
>>>PO SU
>>>mail: desolator88 at 163.com
>>>Majored in Statistics from SJTU
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Aug 26 18:53:45 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 Aug 2014 09:53:45 -0700
Subject: [R] Plot survreg and intcox
In-Reply-To: <DUB122-W11361C61E8FFE9490E922CFADC0@phx.gbl>
References: <DUB122-W11361C61E8FFE9490E922CFADC0@phx.gbl>
Message-ID: <13002F86-9702-4A3F-9812-BAFB0355C999@comcast.net>


On Aug 26, 2014, at 4:17 AM, Silong Liao wrote:

> Dear R users,
> I'm trying to plot survival probability against time(in years) using "survreg" and "intcox". Please can you help me with this problem?

That line at the bottom of the message delivered to the list subscribers saying that the HTL version was deleted explains why this is such a mess. Please read the Posting Guide and post in plain text:

-- 
David.
> My code shows below:>mod.reg1=survreg(s_new~type+sex+eye+preopiop+preopva,dist="weibull")>summary(mod.reg1)
> Call:survreg(formula = s_new ~ type + sex + eye + preopiop + preopva,     dist = "weibull")             Value Std. Error      z        p(Intercept) 40.539     20.582  1.970 4.89e-02typeTrab    -6.606      4.279 -1.544 1.23e-01sexM        -1.055      3.765 -0.280 7.79e-01eyeR        -2.112      3.587 -0.589 5.56e-01preopiop    -0.308      0.269 -1.147 2.52e-01preopva     -0.461      1.771 -0.260 7.95e-01Log(scale)   2.058      0.285  7.222 5.12e-13
> Scale= 7.83 
> Weibull distributionLoglik(model)= -78.7   Loglik(intercept only)= -81.4	Chisq= 5.37 on 5 degrees of freedom, p= 0.37 Number of Newton-Raphson Iterations: 10 n= 339
> ------------------------------------------------------------------------------------------------------------->cox.fit=intcox(s_new~type+eye+sex+age+preopiop+preopva,data=glaucoma_new)>summary(cox.fit)Call:intcox(formula = s_new ~ type + eye + sex + age + preopiop +     preopva, data = glaucoma_new)
>  n= 339
>             coef exp(coef) se(coef)  z Pr(>|z|)typeTrab  0.59391   1.81106       NA NA       NAeyeR      0.28419   1.32868       NA NA       NAsexM     -0.11597   0.89050       NA NA       NAage      -0.06556   0.93655       NA NA       NApreopiop  0.03903   1.03980       NA NA       NApreopva  -0.05517   0.94632       NA NA       NA
>         exp(coef) exp(-coef) lower .95 upper .95typeTrab    1.8111     0.5522        NA        NAeyeR        1.3287     0.7526        NA        NAsexM        0.8905     1.1230        NA        NAage         0.9365     1.0678        NA        NApreopiop    1.0398     0.9617        NA        NApreopva     0.9463     1.0567        NA        NA
> Rsquare= NA   (max possible= 0.327 )Likelihood ratio test= NA  on 6 df,   p=NAWald test            = NA  on 6 df,   p=NAScore (logrank) test = NA  on 6 df,   p=NA
> 
> 
> Kind regards,Sid
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kmezhoud at gmail.com  Tue Aug 26 20:45:07 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Tue, 26 Aug 2014 19:45:07 +0100
Subject: [R] buit a package using Rstudio and existing R files
Message-ID: <CALJKBv-df19G6yfnMBUGAmvzLxSwZc76=L8mYRcHBm44sW=Z3A@mail.gmail.com>

Dear All,
I am trying to built for the first time a package. I am following this
tutorial:
https://support.rstudio.com/hc/en-us/articles/200486488-Developing-Packages-with-RStudio

I create a new Project (package) and I added 44 .R sources files
(functions).
After, I got error message when I built and reload the project (please, see
bellow).

Any suggestion?

I need to fill the doc informations (title, manual, vignette, description).
Can I do these directly from Rd files located in Man folder?
Thanks!

Karim

#####00install.out############
* installing *source* package ?CanceR? ...
** R
** preparing package for lazy loading
** help
Warning:
/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR-package.Rd:33:
All text must be in a section
Warning:
/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR-package.Rd:34:
All text must be in a section
Warning:
/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR-package.Rd:35:
All text must be in a section
*** installing help indices
Error in Rd_info(db[[i]]) :
  missing/empty \title field in
'/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR.Rd'
Rd files must have a non-empty \title.
See chapter 'Writing R documentation' in manual 'Writing R Extensions'.
* removing ?/home/mezhoud/CGDS-R/CanceR.Rcheck/CanceR?

###CanceR-package.Rd  #################

\name{CanceR-package}
\alias{CanceR-package}
\alias{CanceR}
\docType{package}
\title{
What the package does (short line)
~~ package title ~~
}
\description{
More about what it does (maybe more than one line)
~~ A concise (1-5 lines) description of the package ~~
}
\details{
\tabular{ll}{
Package: \tab CanceR\cr
Type: \tab Package\cr
Version: \tab 1.0\cr
Date: \tab 2014-08-26\cr
License: \tab What license is it under?\cr
}
~~ An overview of how to use the package, ~~
~~ including the most important functions ~~
}
\author{
Who wrote it

Maintainer: Who to complain to <yourfault at somewhere.net>
~~ The author and/or maintainer of the package ~~
}
\references{
~~ Literature or other references for background information ~~
}
~~ Optionally other standard keywords, ~~
~~ one per line, from file KEYWORDS in ~~
~~ the R documentation directory ~~
\keyword{ package }
\seealso{
~~ Optional links to other man pages, e.g. ~~
~~ \code{\link[<pkg>:<pkg>-package]{<pkg>}} ~~
}
\examples{
~~ simple examples of the most important functions ~~
}

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Tue Aug 26 23:07:22 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 Aug 2014 21:07:22 +0000
Subject: [R] Help with lsmeans
References: <CAMdATGofn5ywDkddn2c=oT9Kf6APRVT7Jewb+EyrqqkVjbhd3A@mail.gmail.com>
Message-ID: <loom.20140826T225542-67@post.gmane.org>

Dan Dillon <dgdillon <at> gmail.com> writes:

> 
> Colleagues:
> 

 [snip]

> 
> My data are from a behavioral experiment in which two groups of subjects
> complete 200+ trials of a task with two conditions. Each subject is tested
> in one of four separate locations. I record accuracy (0 or 1) and response
> time (RT) on each trial--these are the DVs for the two regressions. Thus,
> my dataframe has columns "location", "group", "subject", "trial",
> "condition", "accuracy", and "RT".
> 
> The regression model for accuracy looks like this:
> 
> acc.fm = glmer(accuracy ~ location + group*condition + (1|subject),
> family=binomial, data=my_data)
> 
> The results look as expected and I'm using lsmeans to do some follow-up
> analyses. For example, to compare accuracy by group and condition, I'm
> doing this:
> 
> acc.lsm <- lsmeans(acc.fm, ~group|condition)
> 
> pairs(acc.lsm)
> 
>

 [snip]

> Here is my model for the RT data
> (RT is a continuous variable so no logistic regression here):
> 
> rt.fm = lmer(rt ~ location + group*condition*accuracy + (1|subject),
> data=my_data)
> 
> The results from this regression look fine, but if I try this . . .
> 
> rt.lsm <- lsmeans(rt.fm ~ group|condition)
> 
> . . . or if I try to specify a reference grid like this . . .
> 
> rt.rg <- ref.grid(rt.fm)
> 
> . . . my machine hangs.
> 

  [snip]

  It's a little hard to say without a reproducible example, and
this question would probably be slightly more appropriate for
r-sig-mixed-models at r-project.org (although I can't actually tell
for sure whether it is an lme4-specific problem or a more general
ls.means::ref.grid question), but: how big a reference is ref.grid()
trying to construct?  Is it fairly high-resolution/high-dimensional?
I would probably try some experiments with small subsets of your data
to see how the results scale.


From jdnewmil at dcn.davis.CA.us  Tue Aug 26 23:31:32 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 26 Aug 2014 14:31:32 -0700
Subject: [R] buit a package using Rstudio and existing R files
In-Reply-To: <CALJKBv-df19G6yfnMBUGAmvzLxSwZc76=L8mYRcHBm44sW=Z3A@mail.gmail.com>
References: <CALJKBv-df19G6yfnMBUGAmvzLxSwZc76=L8mYRcHBm44sW=Z3A@mail.gmail.com>
Message-ID: <dd763e8f-4cbf-4956-831d-9fed3afc3ff3@email.android.com>

I would suggest building your first package with as few functions as you can (one?). Once you get that working, try adding more functions and keep rebuilding as you go so the error messages don't drown you. In any event, your immediate problem is that CanceR-package.Rd has not been properly edited.

You should take the advice given in your error message and read the Writing R Extensions manual. While there are some shortcuts such as roxygen to creating the required files, when things go wrong the errors will generally be about files that are documented in the WRE document.

You should also read the Posting Guide which among other things mentions that this is a plain text mailing list. We are more likely to be able to decipher your email if you don't let your email program format it as HTML.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 26, 2014 11:45:07 AM PDT, Karim Mezhoud <kmezhoud at gmail.com> wrote:
>Dear All,
>I am trying to built for the first time a package. I am following this
>tutorial:
>https://support.rstudio.com/hc/en-us/articles/200486488-Developing-Packages-with-RStudio
>
>I create a new Project (package) and I added 44 .R sources files
>(functions).
>After, I got error message when I built and reload the project (please,
>see
>bellow).
>
>Any suggestion?
>
>I need to fill the doc informations (title, manual, vignette,
>description).
>Can I do these directly from Rd files located in Man folder?
>Thanks!
>
>Karim
>
>#####00install.out############
>* installing *source* package ?CanceR? ...
>** R
>** preparing package for lazy loading
>** help
>Warning:
>/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR-package.Rd:33:
>All text must be in a section
>Warning:
>/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR-package.Rd:34:
>All text must be in a section
>Warning:
>/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR-package.Rd:35:
>All text must be in a section
>*** installing help indices
>Error in Rd_info(db[[i]]) :
>  missing/empty \title field in
>'/home/mezhoud/CGDS-R/CanceR.Rcheck/00_pkg_src/CanceR/man/CanceR.Rd'
>Rd files must have a non-empty \title.
>See chapter 'Writing R documentation' in manual 'Writing R Extensions'.
>* removing ?/home/mezhoud/CGDS-R/CanceR.Rcheck/CanceR?
>
>###CanceR-package.Rd  #################
>
>\name{CanceR-package}
>\alias{CanceR-package}
>\alias{CanceR}
>\docType{package}
>\title{
>What the package does (short line)
>~~ package title ~~
>}
>\description{
>More about what it does (maybe more than one line)
>~~ A concise (1-5 lines) description of the package ~~
>}
>\details{
>\tabular{ll}{
>Package: \tab CanceR\cr
>Type: \tab Package\cr
>Version: \tab 1.0\cr
>Date: \tab 2014-08-26\cr
>License: \tab What license is it under?\cr
>}
>~~ An overview of how to use the package, ~~
>~~ including the most important functions ~~
>}
>\author{
>Who wrote it
>
>Maintainer: Who to complain to <yourfault at somewhere.net>
>~~ The author and/or maintainer of the package ~~
>}
>\references{
>~~ Literature or other references for background information ~~
>}
>~~ Optionally other standard keywords, ~~
>~~ one per line, from file KEYWORDS in ~~
>~~ the R documentation directory ~~
>\keyword{ package }
>\seealso{
>~~ Optional links to other man pages, e.g. ~~
>~~ \code{\link[<pkg>:<pkg>-package]{<pkg>}} ~~
>}
>\examples{
>~~ simple examples of the most important functions ~~
>}
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From silong.liao at hotmail.com  Tue Aug 26 23:33:22 2014
From: silong.liao at hotmail.com (Silong Liao)
Date: Tue, 26 Aug 2014 21:33:22 +0000
Subject: [R] plot for "survreg" and "intcox" (rewritten)
Message-ID: <DUB122-W41B64A76D958B4790A05DFADC0@phx.gbl>

Dear R users,

I'm trying to plot survival probability against time(in years) using "survreg" and "intcox". Please can you help me with this problem? (I have rewritten using plain text.) I tried to use "curve" function but have no clue.

For survreg,
>mod.reg1=survreg(s_new~type+sex+eye+preopiop+preopva,dist="weibull")
>summary(mod.reg1)
Call:
survreg(formula = s_new ~ type + sex + eye + preopiop + preopva, dist = "weibull")
Value Std. Error z p
(Intercept) 40.539 20.582 1.970 4.89e-02
typeTrab -6.606 4.279 -1.544 1.23e-01
sexM -1.055 3.765 -0.280 7.79e-01
eyeR -2.112 3.587 -0.589 5.56e-01
preopiop -0.308 0.269 -1.147 2.52e-01
preopva -0.461 1.771 -0.260 7.95e-01
Log(scale) 2.058 0.285 7.222 5.12e-13

Scale= 7.83
Weibull distribution
Loglik(model)= -78.7 Loglik(intercept only)= -81.4
Chisq= 5.37 on 5 degrees of freedom, p= 0.37
Number of Newton-Raphson Iterations: 10
n= 339

For intcox,
>cox.fit=intcox(s_new~type+eye+sex+age+preopiop+preopva,data=glaucoma_new)
>summary(cox.fit)
Call:
intcox(formula = s_new ~ type + eye + sex + age + preopiop +preopva, data = glaucoma_new)

n= 339

coef exp(coef) se(coef) z Pr(>|z|)
typeTrab 0.59391 1.81106 NA NA NA
eyeR 0.28419 1.32868 NA NA NA
sexM -0.11597 0.89050 NA NA NA
age -0.06556 0.93655 NA NA NA
preopiop 0.03903 1.03980 NA NA NA
preopva -0.05517 0.94632 NA NA NA

exp(coef) exp(-coef) lower .95 upper .95
typeTrab 1.8111 0.5522 NA NA
eyeR 1.3287 0.7526 NA NA
sexM 0.8905 1.1230 NA NA
age 0.9365 1.0678 NA NA
preopiop 1.0398 0.9617 NA NA
preopva 0.9463 1.0567 NA NA

Rsquare= NA (max possible= 0.327 )
Likelihood ratio test= NA on 6 df, p=NA
Wald test = NA on 6 df, p=NA
Score (logrank) test = NA on 6 df, p=NA
 		 	   		  

From dwinsemius at comcast.net  Tue Aug 26 23:57:16 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 Aug 2014 14:57:16 -0700
Subject: [R] plot for "survreg" and "intcox" (rewritten)
In-Reply-To: <DUB122-W41B64A76D958B4790A05DFADC0@phx.gbl>
References: <DUB122-W41B64A76D958B4790A05DFADC0@phx.gbl>
Message-ID: <FCC4EC8E-9BB7-4B8B-9CF1-7F8244B208BE@comcast.net>


On Aug 26, 2014, at 2:33 PM, Silong Liao wrote:

> Dear R users,
> 
> I'm trying to plot survival probability against time(in years) using "survreg" and "intcox". Please can you help me with this problem? (I have rewritten using plain text.) I tried to use "curve" function but have no clue.
> 

I suspect you want survfit (in the survial package which is where I suspect survreg is coming from. It returns an object that has a plot method. You could also scroll through help(pack=survival) to see other plotting functions.

You could also use survest in the rms package.

> For survreg,
>> mod.reg1=survreg(s_new~type+sex+eye+preopiop+preopva,dist="weibull")
>> summary(mod.reg1)
> Call:
> survreg(formula = s_new ~ type + sex + eye + preopiop + preopva, dist = "weibull")
> Value Std. Error z p
> (Intercept) 40.539 20.582 1.970 4.89e-02
> typeTrab -6.606 4.279 -1.544 1.23e-01
> sexM -1.055 3.765 -0.280 7.79e-01
> eyeR -2.112 3.587 -0.589 5.56e-01
> preopiop -0.308 0.269 -1.147 2.52e-01
> preopva -0.461 1.771 -0.260 7.95e-01
> Log(scale) 2.058 0.285 7.222 5.12e-13
> 
> Scale= 7.83
> Weibull distribution
> Loglik(model)= -78.7 Loglik(intercept only)= -81.4
> Chisq= 5.37 on 5 degrees of freedom, p= 0.37
> Number of Newton-Raphson Iterations: 10
> n= 339
> 
> For intcox,

You are asked to provide the package name  for functions that are not in the base or default packages. I have quite a few packages loaded including survival_2.37-7 , coxme_2.2-3, and rms_4.2-0  but I get:

> ?intcox
No documentation for ?intcox? in specified packages and libraries:
you could try ???intcox?
> 

-- 
David.


 
>> cox.fit=intcox(s_new~type+eye+sex+age+preopiop+preopva,data=glaucoma_new)
>> summary(cox.fit)
> Call:
> intcox(formula = s_new ~ type + eye + sex + age + preopiop +preopva, data = glaucoma_new)
> 
> n= 339
> 
> coef exp(coef) se(coef) z Pr(>|z|)
> typeTrab 0.59391 1.81106 NA NA NA
> eyeR 0.28419 1.32868 NA NA NA
> sexM -0.11597 0.89050 NA NA NA
> age -0.06556 0.93655 NA NA NA
> preopiop 0.03903 1.03980 NA NA NA
> preopva -0.05517 0.94632 NA NA NA
> 
> exp(coef) exp(-coef) lower .95 upper .95
> typeTrab 1.8111 0.5522 NA NA
> eyeR 1.3287 0.7526 NA NA
> sexM 0.8905 1.1230 NA NA
> age 0.9365 1.0678 NA NA
> preopiop 1.0398 0.9617 NA NA
> preopva 0.9463 1.0567 NA NA
> 
> Rsquare= NA (max possible= 0.327 )
> Likelihood ratio test= NA on 6 df, p=NA
> Wald test = NA on 6 df, p=NA
> Score (logrank) test = NA on 6 df, p=NA
> 		 	   		  
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From btyner at gmail.com  Wed Aug 27 00:25:48 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Tue, 26 Aug 2014 18:25:48 -0400
Subject: [R] lattice: packet.number() versus panel.number()
Message-ID: <53FD096C.9070808@gmail.com>

Hi,

According to
https://svn.r-project.org/R-packages/trunk/lattice/R/print.trellis.R,

    "[panel.number] is usually the same as, but can be different from
packet.number"

and I had been under the impression that as long as the user is not
using a custom index.cond nor perm.cond, the panel.number would in fact
be the same as the packet.number.

However, I have recently come across a case where the two are *not* the
same, even though I am not using a custom index.cond nor perm.cond.

So my question is, what might be some other possible situations in which
the two would be expected to differ?

Regards,
Ben


From nature.aseem at gmail.com  Wed Aug 27 01:46:13 2014
From: nature.aseem at gmail.com (Aseem Sharma)
Date: Tue, 26 Aug 2014 16:46:13 -0700
Subject: [R] Clip smaller domain from large domain netCDF file
Message-ID: <CAPB42UwpgTT_XK3yMSJ+QJtTHGsey3zAgsv6NMQe=iZsVErthA@mail.gmail.com>

Hi,
I have this huge ( ~30GB) .nc file (NC_FORMAT_NETCDF4_CLASSIC)) for the
whole country 141.00 to 52.00 W, 41.00 to 84.00 N".
I am trying to clip this big dataset for a small region specific domain
(120.00 to 130.00 W, 50.00 to 60.00 N).
I am trying to do using netCDF4 r package but could not figure out how to
do so.
Kindly please suggest me how should i proceed.


Thank you,

	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Wed Aug 27 02:24:47 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 26 Aug 2014 17:24:47 -0700
Subject: [R] Mixed sorting/ordering of strings acknowledging roman numerals?
Message-ID: <CAFDcVCT1kukpFiDCwtyMebQdvTCYEggy3dzAL6_DqzM7L=5RMw@mail.gmail.com>

Hi,

does anyone know of an implementation/function that sorts strings that
*contain* roman numerals (I, II, III, IV, V, ...) which are treated as
numbers.  In 'gtools' there is mixedsort() which does this for strings
that contains (decimal) numbers.  I'm looking for a "mixedsortroman()"
function that does the same but with roman numbers, e.g.

## DECIMAL NUMBERS
> x <- sprintf("chr %d", 12:1)
> x
 [1] "chr 12" "chr 11" "chr 10" "chr 9"  "chr 8"
 [6] "chr 7"  "chr 6"  "chr 5"  "chr 4"  "chr 3"
[11] "chr 2"  "chr 1"

> sort(x)
 [1] "chr 1"  "chr 10" "chr 11" "chr 12" "chr 2"
 [6] "chr 3"  "chr 4"  "chr 5"  "chr 6"  "chr 7"
[11] "chr 8"  "chr 9"

> gtools::mixedsort(x)
 [1] "chr 1"  "chr 2"  "chr 3"  "chr 4"  "chr 5"
 [6] "chr 6"  "chr 7"  "chr 8"  "chr 9"  "chr 10"
[11] "chr 11" "chr 12"


## ROMAN NUMBERS
> y <- sprintf("chr %s", as.roman(12:1))
> y
 [1] "chr XII"  "chr XI"   "chr X"    "chr IX"
 [5] "chr VIII" "chr VII"  "chr VI"   "chr V"
 [9] "chr IV"   "chr III"  "chr II"   "chr I"

> sort(y)
 [1] "chr I"    "chr II"   "chr III"  "chr IV"
 [5] "chr IX"   "chr V"    "chr VI"   "chr VII"
 [9] "chr VIII" "chr X"    "chr XI"   "chr XII"

> mixedsortroman(y)
 [1] "chr I"    "chr II"   "chr III"  "chr IV"
 [5] "chr V"    "chr VI"   "chr VII"  "chr VIII"
 [9] "chr IX"   "chr X"    "chr XI"   "chr XII"

The latter is what I'm looking for.

Before hacking together something myself (e.g. identify roman numerals
substrings, translate them to decimal numbers, use gtools::mixedsort()
to sort them and then translate them back to roman numbers), I'd like
to hear if someone already has this implemented/know of a package that
does this.

Thanks,

Henrik


From roy.mendelssohn at noaa.gov  Wed Aug 27 02:52:31 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Tue, 26 Aug 2014 17:52:31 -0700
Subject: [R] Clip smaller domain from large domain netCDF file
In-Reply-To: <CAPB42UwpgTT_XK3yMSJ+QJtTHGsey3zAgsv6NMQe=iZsVErthA@mail.gmail.com>
References: <CAPB42UwpgTT_XK3yMSJ+QJtTHGsey3zAgsv6NMQe=iZsVErthA@mail.gmail.com>
Message-ID: <ACB264BC-B374-4418-A810-9A54FEC6DDE9@noaa.gov>

Using the ncdf4 library  requires some knowledge of netcdf files and how they work.  However, if you can provide the following information I may be able to provide some pointers.  I am assuming your file is named "myFile.nc".  Where you see that replace with the actual name.

library(ncdf4)
myFile<-nc_open('myFile.nc')
str(myFile)


The output of the last command will show what is basically a dump of metadata content of the file, showing its structure.    From the bounds I assume this is a Canadian dataset?

-Roy

On Aug 26, 2014, at 4:46 PM, Aseem Sharma <nature.aseem at gmail.com> wrote:

> Hi,
> I have this huge ( ~30GB) .nc file (NC_FORMAT_NETCDF4_CLASSIC)) for the
> whole country 141.00 to 52.00 W, 41.00 to 84.00 N".
> I am trying to clip this big dataset for a small region specific domain
> (120.00 to 130.00 W, 50.00 to 60.00 N).
> I am trying to do using netCDF4 r package but could not figure out how to
> do so.
> Kindly please suggest me how should i proceed.
> 
> 
> Thank you,
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From dwinsemius at comcast.net  Wed Aug 27 03:46:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 Aug 2014 18:46:49 -0700
Subject: [R] Mixed sorting/ordering of strings acknowledging roman
	numerals?
In-Reply-To: <CAFDcVCT1kukpFiDCwtyMebQdvTCYEggy3dzAL6_DqzM7L=5RMw@mail.gmail.com>
References: <CAFDcVCT1kukpFiDCwtyMebQdvTCYEggy3dzAL6_DqzM7L=5RMw@mail.gmail.com>
Message-ID: <E3C40F2D-0666-406C-BB68-0B05951892FA@comcast.net>


On Aug 26, 2014, at 5:24 PM, Henrik Bengtsson wrote:

> Hi,
> 
> does anyone know of an implementation/function that sorts strings that
> *contain* roman numerals (I, II, III, IV, V, ...) which are treated as
> numbers.  In 'gtools' there is mixedsort() which does this for strings
> that contains (decimal) numbers.  I'm looking for a "mixedsortroman()"
> function that does the same but with roman numbers, e.g.

It's pretty easy to sort something you know to be congruent with the existing roman class:

romanC <- as.character( as.roman(1:3899) )
match(c("I", "II", "III","X","V"), romanC)
#[1]  1  2  3 10  5

But I guess you already know that, so you want a regex approach to parsing. Looking at the path taken by Warnes, it would involve doing something like his regex based insertion of a delimiter for "Roman numeral" but simpler because he needed to deal with decimal points and signs and exponent notation, none of which you appear to need. If you only need to consider character and Roman, then this hack of Warnes tools succeeds:

 mixedorderRoman <- function (x) 
{
    if (length(x) < 1) 
        return(NULL)
    else if (length(x) == 1) 
        return(1)
    if (is.numeric(x)) 
        return(order(x))
    delim = "\\$\\@\\$"
    roman <- function(x) {
        suppressWarnings(match(x, romanC))
    }
    nonnumeric <- function(x) {
        suppressWarnings(ifelse(is.na(as.numeric(x)), toupper(x), 
            NA))
    }
    x <- as.character(x)
    which.nas <- which(is.na(x))
    which.blanks <- which(x == "")
    if (length(which.blanks) > 0) 
        x[which.blanks] <- -Inf
    if (length(which.nas) > 0) 
        x[which.nas] <- Inf
    delimited <- gsub("([IVXCL]+)", 
        paste(delim, "\\1", delim, sep = ""), x)
    step1 <- strsplit(delimited, delim)
    step1 <- lapply(step1, function(x) x[x > ""])
    step1.roman <- lapply(step1, roman)
    step1.character <- lapply(step1, nonnumeric)
    maxelem <- max(sapply(step1, length))
    step1.roman.t <- lapply(1:maxelem, function(i) sapply(step1.roman, 
        function(x) x[i]))
    step1.character.t <- lapply(1:maxelem, function(i) sapply(step1.character, 
        function(x) x[i]))
    rank.roman <- sapply(step1.roman.t, rank)
    rank.character <- sapply(step1.character.t, function(x) as.numeric(factor(x)))
    rank.roman[!is.na(rank.character)] <- 0
    rank.character <- t(t(rank.character) + apply(matrix(rank.roman), 
        2, max, na.rm = TRUE))
    rank.overall <- ifelse(is.na(rank.character), rank.numeric, 
        rank.character)
    order.frame <- as.data.frame(rank.overall)
    if (length(which.nas) > 0) 
        order.frame[which.nas, ] <- Inf
    retval <- do.call("order", order.frame)
    return(retval)
}

y[mixedorderRoman(y)]
 [1] "chr I"    "chr II"   "chr III"  "chr IV"   "chr IX"  
 [6] "chr V"    "chr VI"   "chr VII"  "chr VIII" "chr X"   
[11] "chr XI"   "chr XII" 


-- 
David.
> 
> ## DECIMAL NUMBERS
>> x <- sprintf("chr %d", 12:1)
>> x
> [1] "chr 12" "chr 11" "chr 10" "chr 9"  "chr 8"
> [6] "chr 7"  "chr 6"  "chr 5"  "chr 4"  "chr 3"
> [11] "chr 2"  "chr 1"
> 
>> sort(x)
> [1] "chr 1"  "chr 10" "chr 11" "chr 12" "chr 2"
> [6] "chr 3"  "chr 4"  "chr 5"  "chr 6"  "chr 7"
> [11] "chr 8"  "chr 9"
> 
>> gtools::mixedsort(x)
> [1] "chr 1"  "chr 2"  "chr 3"  "chr 4"  "chr 5"
> [6] "chr 6"  "chr 7"  "chr 8"  "chr 9"  "chr 10"
> [11] "chr 11" "chr 12"
> 
> 
> ## ROMAN NUMBERS
>> y <- sprintf("chr %s", as.roman(12:1))
>> y
> [1] "chr XII"  "chr XI"   "chr X"    "chr IX"
> [5] "chr VIII" "chr VII"  "chr VI"   "chr V"
> [9] "chr IV"   "chr III"  "chr II"   "chr I"
> 
>> sort(y)
> [1] "chr I"    "chr II"   "chr III"  "chr IV"
> [5] "chr IX"   "chr V"    "chr VI"   "chr VII"
> [9] "chr VIII" "chr X"    "chr XI"   "chr XII"
> 
>> mixedsortroman(y)
> [1] "chr I"    "chr II"   "chr III"  "chr IV"
> [5] "chr V"    "chr VI"   "chr VII"  "chr VIII"
> [9] "chr IX"   "chr X"    "chr XI"   "chr XII"
> 
> The latter is what I'm looking for.
> 
> Before hacking together something myself (e.g. identify roman numerals
> substrings, translate them to decimal numbers, use gtools::mixedsort()
> to sort them and then translate them back to roman numbers), I'd like
> to hear if someone already has this implemented/know of a package that
> does this.
> 
> Thanks,
> 
> Henrik
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From marius.hofert at math.ethz.ch  Wed Aug 27 05:14:29 2014
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Tue, 26 Aug 2014 23:14:29 -0400
Subject: [R] Where to find source of C_pbinom?
Message-ID: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>

Dear expeRts,

I would like to find out how R computes pbinom(). A grep in the
source code reveiled src/library/stats/R/distn.R:146:
.External(C_pbinom, q, size, prob, lower.tail, log.p), so
'C_pbinom' refers to compiled C/C++ code loaded into R. Where can
I find the source code of C_pbinom?

Cheers,

Marius


From rhelpmaillist at 163.com  Wed Aug 27 05:44:47 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 27 Aug 2014 11:44:47 +0800 (CST)
Subject: [R] What the difference between .Golbalenv and package:base?
In-Reply-To: <CAF8bMcaG89cn3qFcytaxiuN92kP1Z6FNUMUGvDkZ01Kg_qtZ-Q@mail.gmail.com>
References: <436b2d80.9c8e.1480bc66d99.Coremail.rhelpmaillist@163.com>
	<D020D0E6.108627%macqueen1@llnl.gov>
	<6b939ebc.14d38.148107fb8f2.Coremail.rhelpmaillist@163.com>
	<CAF8bMcaG89cn3qFcytaxiuN92kP1Z6FNUMUGvDkZ01Kg_qtZ-Q@mail.gmail.com>
Message-ID: <269ac4c8.7529.1481590da6a.Coremail.rhelpmaillist@163.com>

So, the decisive factor is  whether the input string be on the search() name list, and not related with the envir's name attribute.
When we using attach, it is becasue the name attribute just match the search() name list(or say,search() name list just use the name attribute), so as.environment() can work  well. 
Tks!


--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2014-08-27 00:02:07, "William Dunlap" <wdunlap at tibco.com> wrote:
>as.environment(characterString) maps an entry from the output of
>search() to the environment at the named position in the search list.
>as.environment(number) maps an index into the output of search() to
>the the environment at that position in the search list.  If
>'characterString' is not in the output of search() or 'number' is not
>in seq_along(search()) then as.environment throws an error.  As far as
>I can tell, as.environment does not deal with the name of the
>environment at all.  (When you attach an environment, attach will add
>a name attribute to the copied environment so the attached
>environment's name matches the name on the output of search(), but I
>don't think as.environment ever looks at that attribute.)
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Mon, Aug 25, 2014 at 9:07 PM, PO SU <rhelpmaillist at 163.com> wrote:
>> First, sorry for my pool english expression which make you misunderstanding of my original purpose.
>>
>> Sometimes, suppose  a object in both stats and base, then i type the object name, then after R search the search() list, R will use the object in stats, is it right?( I just suppose, stats can be any package which libraried into R.)
>> Then i know that, .GlobalEnv or globalenv() is the global environment object, baseenv() returns the base environment object.
>> I also know that, i can convert the environment name into the real environment object by using stats<-as.environment("package:stats"),  And the stats environment's name can be obtained using environmentName(stats), but it returns "".   (why?)
>> Then i use  environmentName(.GlobalEnv) then i get "R_GlobalEnv", then i use as.environment("R_GlobalEnv"), it does't work.(why?)
>>
>>
>> In one word, as.environment(x), x is somthing not the environment's name.
>>
>>
>> But, when i add a environment into the search() list, after i attr(newenvir,"name")<-"new_name"
>> I can use the  as.environment("new_name") to obtain the added environment. (why?)
>>
>>
>> Hope you understand my meaning :)
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>> At 2014-08-26 02:51:54, "MacQueen, Don" <macqueen1 at llnl.gov> wrote:
>>>Put simply,
>>>   .GlobalEnv    stores objects you create
>>>   package:base  contains functions and objects provided by R itself
>>>
>>>You don?t need to use   .GlobalEnv$a   to use the variable named a. Just
>>>is ?a? by itself.
>>>
>>> a <- 4
>>> b <- 2*a
>>>print(a)
>>>print(b)
>>>
>>>Not necessary to use
>>>  print(.GlobalEnv$a)
>>>
>>>Similarly, to find an object in the base package, just type its name.
>>>
>>>I don?t know what you are trying to do, or why you think you have to use
>>>.GlobalEnv$a
>>>But in more than 20 years of using R for many different tasks, I have
>>>never had to do that.
>>>
>>>Furthermore, if you are new to R (which I would guess is the case), it
>>>seems unlikely to me that you need to work with environments or use
>>>attach() or assign(). In the vast majority of cases there are simpler ways
>>>that are easier to understand.
>>>
>>>You are aware, I hope, that
>>>  > ls('.GlobalEnv')
>>>  > ls(1)
>>>  > ls()
>>>all return the same result?
>>>
>>>
>>>--
>>>Don MacQueen
>>>
>>>Lawrence Livermore National Laboratory
>>>7000 East Ave., L-627
>>>Livermore, CA 94550
>>>925-423-1062
>>>
>>>
>>>
>>>
>>>
>>>On 8/24/14, 11:07 PM, "PO SU" <rhelpmaillist at 163.com> wrote:
>>>
>>>>
>>>>
>>>>Dear rusers,
>>>>
>>>>    As we know, there are a lot of environments in the search() path,
>>>>such as   .Golbalenv and package:base .
>>>>And  i can just use  .Golbalenv$a ,.Golbalenv$b to use the virable,  but
>>>>i must use as.envrionment("package:base") to find virable, i feel it not
>>>>very convenient.
>>>>
>>>>
>>>>For example, when i use the following codes to add a new env into the
>>>>search() path.
>>>>
>>>>
>>>>
>>>>> tmp<-attach(NULL,name="new_name")
>>>>> assign("a",2,envir=as.environment("new_name"))
>>>>> a
>>>>[1] 2
>>>>> as.environment("new_name")$a
>>>>[1] 2
>>>> I must always convert the name to the environment, How can i just use
>>>>the following form:
>>>>
>>>>
>>>>
>>>>> tmp<-attach(NULL,name="new_name")
>>>>> assign("a",2,envir=new_name)   #like using  .GlobalEnv
>>>>> a
>>>>[1] 2
>>>>> new_name$a
>>>>
>>>>[1] 2
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>--
>>>>
>>>>PO SU
>>>>mail: desolator88 at 163.com
>>>>Majored in Statistics from SJTU
>>>>______________________________________________
>>>>R-help at r-project.org mailing list
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From madhvi.gupta at orkash.com  Wed Aug 27 06:56:32 2014
From: madhvi.gupta at orkash.com (madhvi.gupta)
Date: Wed, 27 Aug 2014 10:26:32 +0530
Subject: [R] NA's introduced by coercion
Message-ID: <53FD6500.9070101@orkash.com>

Hi,

I am applyin function as.numeric to a vector having many values as NA 
and it is giving :
Warning message:
NAs introduced by coercion

Can anyone help me to know how to remove this warning and sor it out?

Thanks
Madhvi


From lianoglou.steve at gene.com  Wed Aug 27 07:12:48 2014
From: lianoglou.steve at gene.com (Steve Lianoglou)
Date: Tue, 26 Aug 2014 22:12:48 -0700
Subject: [R] NA's introduced by coercion
In-Reply-To: <53FD6500.9070101@orkash.com>
References: <53FD6500.9070101@orkash.com>
Message-ID: <CAHA9McOpTBTGs3JwR=j72PeKqdDHxefkjzukC9fJq4mEYnZ3FQ@mail.gmail.com>

Hi,

On Tue, Aug 26, 2014 at 9:56 PM, madhvi.gupta <madhvi.gupta at orkash.com> wrote:
> Hi,
>
> I am applyin function as.numeric to a vector having many values as NA and it
> is giving :
> Warning message:
> NAs introduced by coercion
>
> Can anyone help me to know how to remove this warning and sor it out?

Let's say that the vector you are calling `as.numeric` over is called
`x`. If you could show us the output of the following command:

R> head(x[is.na(as.numeric(x))])

You'll see why you are getting the warning.

How you choose to sort it out probably depends on what you are trying
to do with your data after you convert it to a "numeric"

-steve

-- 
Steve Lianoglou
Computational Biologist
Genentech


From dwinsemius at comcast.net  Wed Aug 27 08:01:26 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 Aug 2014 23:01:26 -0700
Subject: [R] NA's introduced by coercion
In-Reply-To: <53FD6500.9070101@orkash.com>
References: <53FD6500.9070101@orkash.com>
Message-ID: <FA27294A-CF80-43AC-A6D7-353AFC4055B4@comcast.net>


On Aug 26, 2014, at 9:56 PM, madhvi.gupta wrote:

> Hi,
> 
> I am applyin function as.numeric to a vector having many values as NA and it is giving :
> Warning message:
> NAs introduced by coercion
> 
> Can anyone help me to know how to remove this warning and sor it out?

You are the one that needs to identify the cause of hte warning: look at the difference in console output for these two examples:

> as.numeric( c("a", 1, NA_character_) )
[1] NA  1 NA
Warning message:
NAs introduced by coercion 

> as.numeric( c("2", 1, NA_character_) )
[1]  2  1 NA

So it is not the NA's in that character vector but rather values that were coerce to NA because the conversion could not be accomplished.



-- 

David Winsemius
Alameda, CA, USA


From anna_pannas at yahoo.co.uk  Wed Aug 27 05:54:44 2014
From: anna_pannas at yahoo.co.uk (anna pannas)
Date: Wed, 27 Aug 2014 04:54:44 +0100
Subject: [R] working with matrices
Message-ID: <1409111684.62821.YahooMailNeo@web171801.mail.ir2.yahoo.com>

hello

i want to fill a matrix by its upper off diagonal elements

specifically I want to take the first and second column of? the matrix and I apply a function to then that returns a single number which I want to place in the (1,2) entry of the matrix, then I want to take the first and third column of the matrix and apply the same function, get the single number and place it to (2,3) entry of the matrix and so on

how can i do it?

thanks
anna

	[[alternative HTML version deleted]]


From lianogls at gene.com  Wed Aug 27 07:21:19 2014
From: lianogls at gene.com (Steve Lianoglou)
Date: Tue, 26 Aug 2014 22:21:19 -0700
Subject: [R] NA's introduced by coercion
In-Reply-To: <53FD697C.80005@orkash.com>
References: <53FD6500.9070101@orkash.com>
	<CAHA9McOpTBTGs3JwR=j72PeKqdDHxefkjzukC9fJq4mEYnZ3FQ@mail.gmail.com>
	<53FD697C.80005@orkash.com>
Message-ID: <EA52258C-0A78-4313-8A23-298B168C5F2A@gene.com>

Hi Madhvi,

First, please use "reply-all" when responding to emails form this list 
so that others can help (and benefit from) the discussion.

Comment down below:

On 26 Aug 2014, at 22:15, madhvi.gupta wrote:

> On 08/27/2014 10:42 AM, Steve Lianoglou wrote:
>> Hi,
>>
>> On Tue, Aug 26, 2014 at 9:56 PM, madhvi.gupta 
>> <madhvi.gupta at orkash.com> wrote:
>>> Hi,
>>>
>>> I am applyin function as.numeric to a vector having many values as 
>>> NA and it
>>> is giving :
>>> Warning message:
>>> NAs introduced by coercion
>>>
>>> Can anyone help me to know how to remove this warning and sor it 
>>> out?
>> Let's say that the vector you are calling `as.numeric` over is called
>> `x`. If you could show us the output of the following command:
>>
>> R> head(x[is.na(as.numeric(x))])
>>
>> You'll see why you are getting the warning.
>>
>> How you choose to sort it out probably depends on what you are trying
>> to do with your data after you convert it to a "numeric"
>>
>> -steve
>>
>> Hi,
> I am having this error bacouse vector contains value NA but i want to 
> convert that vector to numeric

I don't quite follow what the problem is, then ... what is the end 
result that you want to happen?

When you convert the vector to a numeric, the NA's that were in it 
originally, will remain as NAs (but they will be of a 'numeric' type).

What would you like to do with the NA values? Do you just want to keep 
them, but want to silence the warning?

If so, you can do:

R> suppressWarnings(y <- as.numeric(x))

-steve

--
Steve Lianoglou
Computational Biologist
Genentech


From dwinsemius at comcast.net  Wed Aug 27 08:10:23 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 26 Aug 2014 23:10:23 -0700
Subject: [R] lattice: packet.number() versus panel.number()
In-Reply-To: <53FD096C.9070808@gmail.com>
References: <53FD096C.9070808@gmail.com>
Message-ID: <D1947AA3-6297-4A41-B294-903A0FF802C3@comcast.net>


On Aug 26, 2014, at 3:25 PM, Benjamin Tyner wrote:

> Hi,
> 
> According to
> https://svn.r-project.org/R-packages/trunk/lattice/R/print.trellis.R,
> 
>    "[panel.number] is usually the same as, but can be different from
> packet.number"
> 
> and I had been under the impression that as long as the user is not
> using a custom index.cond nor perm.cond, the panel.number would in fact
> be the same as the packet.number.
> 
> However, I have recently come across a case where the two are *not* the
> same, even though I am not using a custom index.cond nor perm.cond.
> 
> So my question is, what might be some other possible situations in which
> the two would be expected to differ?

The immediate hypothesis that leaps to mind is cases where there are multiple pages. On each page I suspect the upper left numbering restarts with 1, but I suspect the packet numbers are sequential increasing.

-- 

David Winsemius
Alameda, CA, USA


From rhelpmaillist at 163.com  Wed Aug 27 09:01:40 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Wed, 27 Aug 2014 15:01:40 +0800 (CST)
Subject: [R]   21 R navigation tools
Message-ID: <2e413a59.57ab.148164519ff.Coremail.rhelpmaillist@163.com>


I think the article from?burns-stat is very worth reading , You can google it ,and hope you find it useful.






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From dwinsemius at comcast.net  Wed Aug 27 09:36:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Aug 2014 00:36:18 -0700
Subject: [R] Where to find source of C_pbinom?
In-Reply-To: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
References: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
Message-ID: <85C46F30-C3EC-491D-A4B4-303BE7C8EED2@comcast.net>


On Aug 26, 2014, at 8:14 PM, Marius Hofert wrote:

> Dear expeRts,
>
> I would like to find out how R computes pbinom(). A grep in the
> source code reveiled src/library/stats/R/distn.R:146:
> .External(C_pbinom, q, size, prob, lower.tail, log.p), so
> 'C_pbinom' refers to compiled C/C++ code loaded into R. Where can
> I find the source code of C_pbinom?
>

> www.r-project.org/doc/Rnews/Rnews_2006-4.pdf
Pages 43-54

-- 

David Winsemius, MD
Alameda, CA, USA


From ingo at gfz-potsdam.de  Wed Aug 27 11:18:33 2014
From: ingo at gfz-potsdam.de (Ingo Wardinski)
Date: Wed, 27 Aug 2014 11:18:33 +0200
Subject: [R] simple plotting wcor (Rssa) question
Message-ID: <53FDA269.4000402@gfz-potsdam.de>

Hello,
I try to plot w-correlation matrix of singular spectrum analysis by 
using the package Rssa. This is an example:
 > library(Rssa)
 > s <- ssa(co2)
 > w <- wcor(s, groups = 1:20)
 > plot(w,cex.label=3),scales=list(at=c(10,20,30,40)))

However cex.label dos not have any effect. Also I would like to change 
the tick labels, currently they show up as F1, F2 etc., and I would like 
to have them as 1, 2, etc.

Any help would be very much appreciated
ingo


From ingo at gfz-potsdam.de  Wed Aug 27 11:33:10 2014
From: ingo at gfz-potsdam.de (Ingo Wardinski)
Date: Wed, 27 Aug 2014 11:33:10 +0200
Subject: [R] simple plotting wcor (Rssa) question
In-Reply-To: <53FDA269.4000402@gfz-potsdam.de>
References: <53FDA269.4000402@gfz-potsdam.de>
Message-ID: <53FDA5D6.6060200@gfz-potsdam.de>

On 08/27/2014 11:18 AM, Ingo Wardinski wrote:
> Hello,
> I try to plot w-correlation matrix of singular spectrum analysis by
> using the package Rssa. This is an example:
>  > library(Rssa)
>  > s <- ssa(co2)
>  > w <- wcor(s, groups = 1:20)
>  > plot(w,cex.label=3),scales=list(at=c(10,20,30,40)))

I was wrong here:
cex.lab=3
and cex.axis=3 do not show any effect. And I have to say that I want to 
magnify the tick annotations.

>
> However cex.label dos not have any effect. Also I would like to change
> the tick labels, currently they show up as F1, F2 etc., and I would like
> to have them as 1, 2, etc.
>
> Any help would be very much appreciated
> ingo
>


From elie.guichard at inserm.fr  Wed Aug 27 11:58:50 2014
From: elie.guichard at inserm.fr (eguichard)
Date: Wed, 27 Aug 2014 02:58:50 -0700 (PDT)
Subject: [R] problem when I Call C subfunction in void function
Message-ID: <1409133530888-4696073.post@n4.nabble.com>

Hi everybody,
I am including some C code in R program using the .C interface.
I would like use a C subfunction calling by C void function.

/double essai (double Px[], int tailleP)
{
	Rprintf ("I print Px %d\t", Px[1]);
	return 57;
}

void test_essai (double *Px, int *tailleP, double *res)
{
	*res = essai(*Px, *tailleP);
}/

This program doesn?t work. When I compile it, I have the following error : 
?In function ?test_essai :
-	Error: incompatible type for argument 1 of ?essai?
-	Note : expected ?double*? but argument is of type ?double? ?

Does anyone have solution ? 
Thank all, Elie 




--
View this message in context: http://r.789695.n4.nabble.com/problem-when-I-Call-C-subfunction-in-void-function-tp4696073.html
Sent from the R help mailing list archive at Nabble.com.


From sarah.goslee at gmail.com  Wed Aug 27 13:28:55 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 27 Aug 2014 07:28:55 -0400
Subject: [R] Where to find source of C_pbinom?
In-Reply-To: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
References: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
Message-ID: <CAM_vjun3QcTM806zxRvwHJ1QHZe0Hzece77vmO=ck_5G-U99aw@mail.gmail.com>

R FAQ 7.40

http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-access-the-source-code-for-a-function_003f

Sarah

On Tuesday, August 26, 2014, Marius Hofert <marius.hofert at math.ethz.ch>
wrote:

> Dear expeRts,
>
> I would like to find out how R computes pbinom(). A grep in the
> source code reveiled src/library/stats/R/distn.R:146:
> .External(C_pbinom, q, size, prob, lower.tail, log.p), so
> 'C_pbinom' refers to compiled C/C++ code loaded into R. Where can
> I find the source code of C_pbinom?
>
> Cheers,
>
> Marius
>
>

-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From b.owen11 at imperial.ac.uk  Wed Aug 27 13:48:07 2014
From: b.owen11 at imperial.ac.uk (Owen, Branwen)
Date: Wed, 27 Aug 2014 11:48:07 +0000
Subject: [R] Metafor -can't calculate heterogeneity with non-positive
 sampling variances
Message-ID: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BAB@icexch-m4.ic.ac.uk>

Hi, I'm doing a meta-analysis in metafor. All is fine except when there are 0s in the values that i'm pooling, then i get a pooled estimate but not the I2 that i am also interested in.
for example:

summary(rma.1<-rma(yi,vi,data=mix,method="ML",knha=F,weighted=F,intercept=T))
(where yi are the study outcomes, one of which is 0, and vi is the variance of the study outcomes)

Random-Effects Model (k = 17; tau^2 estimator: ML)

  logLik  deviance       AIC       BIC      AICc  
 13.0539       Inf  -22.1077  -20.4413  -21.2506  

tau^2 (estimated amount of total heterogeneity): 0.0119 (SE = 0.0043)
tau (square root of estimated tau^2 value):      0.1089

Model Results:

estimate       se     zval     pval    ci.lb    ci.ub          
  0.1837   0.0274   6.7154   <.0001   0.1301   0.2374      ***

---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Warning messages:
1: In rma(yi, vi, data = mix, method = "ML", knha = F, weighted = F,  :
  There are outcomes with non-positive sampling variances.
2: In rma(yi, vi, data = mix, method = "ML", knha = F, weighted = F,  :
  Cannot compute Q-test, I^2, or H^2 with non-positive sampling variances.

Is there any way around this?
thanks
Branwen
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of r-help-owner at r-project.org [r-help-owner at r-project.org]
Sent: 27 August 2014 13:36
To: Owen, Branwen
Subject: Metafor -can't calculate heterogeneity with non-positive sampling variances

Message rejected by filter rule match



From jfox at mcmaster.ca  Wed Aug 27 13:53:58 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 27 Aug 2014 07:53:58 -0400
Subject: [R] working with matrices
In-Reply-To: <1409111684.62821.YahooMailNeo@web171801.mail.ir2.yahoo.com>
References: <1409111684.62821.YahooMailNeo@web171801.mail.ir2.yahoo.com>
Message-ID: <web-524114207@cgpsrv2.cis.mcmaster.ca>

Dear anna,

Unless the original matrix has a massive number of columns, why not just use loops? R programmers often have an unnecessary phobia of loops, and will puzzle over a programming problem for hours that can be solved by loops in seconds.

You don't say what specifically you want to do, but, for example:

> f <- function(X){
+   nc <- ncol(X)
+   Y <- matrix(0, nc, nc)
+   for (i in 1:(nc - 1)){
+     for (j in (i+1):nc){
+       Y[i, j] <- sum(X[, i] * X[, j])
+     }
+   }
+   return(Y)
+ }
> 

> (A <- matrix(1:12, 4, 3))
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

> f(A)
     [,1] [,2] [,3]
[1,]    0   70  110
[2,]    0    0  278
[3,]    0    0    0

The example is artificial, since it just computes part of the matrix product,

> upper.tri(diag(3)) * (t(A) %*% A)
     [,1] [,2] [,3]
[1,]    0   70  110
[2,]    0    0  278
[3,]    0    0    0
>

but it has the structure that you outlined (if I understand it correctly).

For a moderate number of columns (you don't say how many you have), the computation isn't prohibitively slow:

> B <- matrix(rnorm(1e5), 100, 1000)
> system.time(f(B))
   user  system elapsed 
   4.12    0.01    4.15 

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
On Wed, 27 Aug 2014 04:54:44 +0100
 anna pannas <anna_pannas at yahoo.co.uk> wrote:
> hello
> 
> i want to fill a matrix by its upper off diagonal elements
> 
> specifically I want to take the first and second column of? the matrix and I apply a function to then that returns a single number which I want to place in the (1,2) entry of the matrix, then I want to take the first and third column of the matrix and apply the same function, get the single number and place it to (2,3) entry of the matrix and so on
> 
> how can i do it?
> 
> thanks
> anna
> 
> 	[[alternative HTML version deleted]]
>


From petr.pikal at precheza.cz  Wed Aug 27 13:59:55 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 27 Aug 2014 11:59:55 +0000
Subject: [R] working with matrices
In-Reply-To: <1409111684.62821.YahooMailNeo@web171801.mail.ir2.yahoo.com>
References: <1409111684.62821.YahooMailNeo@web171801.mail.ir2.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BDFBCD@SRVEXCHMBX.precheza.cz>

Hi

Please be more specific and try to post some example to simplify elaborating answer.

How big is your matrix. Double loop seems to be the first which come to my mind however it can be unpractical when dealing with big matrix or if you want to do this task repeatedly.

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of anna pannas
> Sent: Wednesday, August 27, 2014 5:55 AM
> To: r-help at r-project.org
> Subject: [R] working with matrices
>
> hello
>
> i want to fill a matrix by its upper off diagonal elements
>
> specifically I want to take the first and second column of? the matrix
> and I apply a function to then that returns a single number which I
> want to place in the (1,2) entry of the matrix, then I want to take the
> first and third column of the matrix and apply the same function, get
> the single number and place it to (2,3) entry of the matrix and so on
>
> how can i do it?
>
> thanks
> anna
>
>       [[alternative HTML version deleted]]


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From john.archie.mckown at gmail.com  Wed Aug 27 14:09:10 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 27 Aug 2014 07:09:10 -0500
Subject: [R] problem when I Call C subfunction in void function
In-Reply-To: <1409133530888-4696073.post@n4.nabble.com>
References: <1409133530888-4696073.post@n4.nabble.com>
Message-ID: <CAAJSdjiP1_vCahjEkk30DXtP5UU9FQM0stWO6bV27xSWGxHmOg@mail.gmail.com>

On Wed, Aug 27, 2014 at 4:58 AM, eguichard <elie.guichard at inserm.fr> wrote:
> Hi everybody,
> I am including some C code in R program using the .C interface.
> I would like use a C subfunction calling by C void function.
>
> /double essai (double Px[], int tailleP)
> {
>         Rprintf ("I print Px %d\t", Px[1]);
>         return 57;
> }
>
> void test_essai (double *Px, int *tailleP, double *res)
> {
>         *res = essai(*Px, *tailleP);

This line is wrong. Try:
           *res = essi(Px, *tailleP);

Note that double *Px and double Px[] are basically different ways to
say pretty much the same thing. At least in C. Not in C++ or many
other languages. But further discussion would be even more off topic.

> }/
>
> This program doesn?t work. When I compile it, I have the following error :
> ?In function ?test_essai :
> -       Error: incompatible type for argument 1 of ?essai?
> -       Note : expected ?double*? but argument is of type ?double? ?
>
> Does anyone have solution ?
> Thank all, Elie

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From pdalgd at gmail.com  Wed Aug 27 15:03:05 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Aug 2014 15:03:05 +0200
Subject: [R] 21 R navigation tools
In-Reply-To: <2e413a59.57ab.148164519ff.Coremail.rhelpmaillist@163.com>
References: <2e413a59.57ab.148164519ff.Coremail.rhelpmaillist@163.com>
Message-ID: <842952C4-1D93-4853-8AF5-6154D2FBD45B@gmail.com>

C'mon! Already now, Google gives a handful of links to Twitter or R-help or r-bloggers or other places that talk _about_ the write-up.

It's

http://www.burns-stat.com/r-navigation-tools

-pd


On 27 Aug 2014, at 09:01 , PO SU <rhelpmaillist at 163.com> wrote:

> 
> I think the article from burns-stat is very worth reading , You can google it ,and hope you find it useful.
> 
> 
> 
> 
> 
> 
> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From marongiu.luigi at gmail.com  Wed Aug 27 15:42:08 2014
From: marongiu.luigi at gmail.com (Luigi Marongiu)
Date: Wed, 27 Aug 2014 14:42:08 +0100
Subject: [R] scatterplot using plot() function with factorial data
Message-ID: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>

Dear all,
I would like to ask whether is possible to draw a scatterplot using
the simple plot() function when the data is factorial. Without the
addition of the argument factor(), plot() represent the factorial data
on a linear scale whereas using this argument transforms plot() from a
scatterplot to a boxplot. Even adding factor directly in the
arrangement of the dataset does not alter the result.
The stripchart() function does the job I am looking for (essentially
draw the individual points of the dataset on proper axis reference,
that is categorical/factorial), but I was wondering whether is
possible to use plot() directly.
Best regards,
Luigi

----
my.data<-structure(list(
  row = 1:60,
  x = c(
0, 0, 0, 1, 1, 1, 2, 2, 2,
3, 3, 3, 4, 4, 4, 0, 0, 0,
1, 1, 1, 2, 2, 2, 3, 3, 3,
4, 4, 4, 0, 0, 0, 1, 1, 1,
2, 2, 2, 3, 3, 3, 4, 4, 4,
3, 3, 3, 0, 0, 0, 1, 1, 1,
2, 2, 2, 3, 3, 3, 4, 4, 4),
  y = c(
2073.928223, 2131.830067, 2131.830067, 0.143912883,
2191.348468, 2073.928223, 2117.20479, 2017.59903, 1896.388977,
1976.358448, 2003.757427, 1883.378928, 2283.756186,
2363.732429, 2315.416732, 2206.485917, 2191.348468,
2176.314869, 1990.010783, 2059.700178, 1976.358448,
617.4528799, 613.2168858, 617.4528799, 1686.950197,
1819.655315, 1832.225173, 1480.122531, 1298.652866,
1212.260417, 495.3736815, 505.7106218, 538.0337432,
383.9842946, 365.919416, 330.0195927, 505.7106218,
541.7503854, 498.7956356, 512.7214729, 584.3675585,
564.5956413, 604.8318804, 604.8318804, 592.4688595,
1272.107849, 1298.652866, 1298.652866, 1935.96084,
2088.254554, 1962.799773, 4452.994159, 4422.444691,
4128.243033, 312.3359691, 316.6659968, 332.2993098,
1500.642011, 1531.95584, 1430.042989),
  z = c(
0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2,
3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3)),
 row.names = c(NA, -60L),  class = "data.frame")
attach(my.data)
my.data$z<-factor(my.data$z, levels = c(0, 1, 2, 3))
levels(my.data$z)<-c("A", "B", "C", "D")

par(mfrow=c(1,3))  # 1 row, 2 columns
plot(y~z)
plot(y~factor(z))
stripchart(y~z, vertical = TRUE, pch=19)


From dcarlson at tamu.edu  Wed Aug 27 15:58:45 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 27 Aug 2014 13:58:45 +0000
Subject: [R] scatterplot using plot() function with factorial data
In-Reply-To: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>
References: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9310C@mb02.ads.tamu.edu>

It is, but stripchart() is simpler.

plot(y~as.numeric(z), my.data, xlab="x", xaxt="n", pch=19)
axis(1, 1:4, LETTERS[1:4])

If you want more spacing along the x-axis try

plot(y~as.numeric(z), my.data, xlab="x", xaxt="n", 
    xlim=c(.5, 4.5), pch=19)
axis(1, 1:4, LETTERS[1:4])

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Luigi Marongiu
Sent: Wednesday, August 27, 2014 8:42 AM
To: r-help at r-project.org
Subject: [R] scatterplot using plot() function with factorial data

Dear all,
I would like to ask whether is possible to draw a scatterplot using
the simple plot() function when the data is factorial. Without the
addition of the argument factor(), plot() represent the factorial data
on a linear scale whereas using this argument transforms plot() from a
scatterplot to a boxplot. Even adding factor directly in the
arrangement of the dataset does not alter the result.
The stripchart() function does the job I am looking for (essentially
draw the individual points of the dataset on proper axis reference,
that is categorical/factorial), but I was wondering whether is
possible to use plot() directly.
Best regards,
Luigi

----
my.data<-structure(list(
  row = 1:60,
  x = c(
0, 0, 0, 1, 1, 1, 2, 2, 2,
3, 3, 3, 4, 4, 4, 0, 0, 0,
1, 1, 1, 2, 2, 2, 3, 3, 3,
4, 4, 4, 0, 0, 0, 1, 1, 1,
2, 2, 2, 3, 3, 3, 4, 4, 4,
3, 3, 3, 0, 0, 0, 1, 1, 1,
2, 2, 2, 3, 3, 3, 4, 4, 4),
  y = c(
2073.928223, 2131.830067, 2131.830067, 0.143912883,
2191.348468, 2073.928223, 2117.20479, 2017.59903, 1896.388977,
1976.358448, 2003.757427, 1883.378928, 2283.756186,
2363.732429, 2315.416732, 2206.485917, 2191.348468,
2176.314869, 1990.010783, 2059.700178, 1976.358448,
617.4528799, 613.2168858, 617.4528799, 1686.950197,
1819.655315, 1832.225173, 1480.122531, 1298.652866,
1212.260417, 495.3736815, 505.7106218, 538.0337432,
383.9842946, 365.919416, 330.0195927, 505.7106218,
541.7503854, 498.7956356, 512.7214729, 584.3675585,
564.5956413, 604.8318804, 604.8318804, 592.4688595,
1272.107849, 1298.652866, 1298.652866, 1935.96084,
2088.254554, 1962.799773, 4452.994159, 4422.444691,
4128.243033, 312.3359691, 316.6659968, 332.2993098,
1500.642011, 1531.95584, 1430.042989),
  z = c(
0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 2, 2, 2, 2, 2, 2,
2, 2, 2, 2, 2, 2, 2, 2, 2,
3, 3, 3, 3, 3, 3, 3, 3, 3,
3, 3, 3, 3, 3, 3)),
 row.names = c(NA, -60L),  class = "data.frame")
attach(my.data)
my.data$z<-factor(my.data$z, levels = c(0, 1, 2, 3))
levels(my.data$z)<-c("A", "B", "C", "D")

par(mfrow=c(1,3))  # 1 row, 2 columns
plot(y~z)
plot(y~factor(z))
stripchart(y~z, vertical = TRUE, pch=19)

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Aug 27 16:09:06 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 27 Aug 2014 10:09:06 -0400
Subject: [R] scatterplot using plot() function with factorial data
In-Reply-To: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>
References: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>
Message-ID: <CAGx1TMAonpxRhD5d1MExbK4JfkeuY-bGNjM3NvO2PJ=ohusiXA@mail.gmail.com>

With lattice graphics, yes

libary(lattice)
xyplot(y ~ z, data=my.data)
bwplot(y ~ z, data=my.data)
stripplot(y ~ z, data=my.data)

With base graphics, probably not.

More importantly, don't use attach.  It will get you into trouble.
In this case, it didn't work for me because I had a variable named y
in my global environment.
Use the data= argument instead.

Your examples done with the data= argument are

plot(y ~ z, data=my.data)
plot(y ~ factor(z), data=my.data)
stripchart(y ~ z, vertical = TRUE, pch=19, data=my.data)

On Wed, Aug 27, 2014 at 9:42 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I would like to ask whether is possible to draw a scatterplot using
> the simple plot() function when the data is factorial. Without the
> addition of the argument factor(), plot() represent the factorial data
> on a linear scale whereas using this argument transforms plot() from a
> scatterplot to a boxplot. Even adding factor directly in the
> arrangement of the dataset does not alter the result.
> The stripchart() function does the job I am looking for (essentially
> draw the individual points of the dataset on proper axis reference,
> that is categorical/factorial), but I was wondering whether is
> possible to use plot() directly.
> Best regards,
> Luigi
>
> ----
> my.data<-structure(list(
>   row = 1:60,
>   x = c(
> 0, 0, 0, 1, 1, 1, 2, 2, 2,
> 3, 3, 3, 4, 4, 4, 0, 0, 0,
> 1, 1, 1, 2, 2, 2, 3, 3, 3,
> 4, 4, 4, 0, 0, 0, 1, 1, 1,
> 2, 2, 2, 3, 3, 3, 4, 4, 4,
> 3, 3, 3, 0, 0, 0, 1, 1, 1,
> 2, 2, 2, 3, 3, 3, 4, 4, 4),
>   y = c(
> 2073.928223, 2131.830067, 2131.830067, 0.143912883,
> 2191.348468, 2073.928223, 2117.20479, 2017.59903, 1896.388977,
> 1976.358448, 2003.757427, 1883.378928, 2283.756186,
> 2363.732429, 2315.416732, 2206.485917, 2191.348468,
> 2176.314869, 1990.010783, 2059.700178, 1976.358448,
> 617.4528799, 613.2168858, 617.4528799, 1686.950197,
> 1819.655315, 1832.225173, 1480.122531, 1298.652866,
> 1212.260417, 495.3736815, 505.7106218, 538.0337432,
> 383.9842946, 365.919416, 330.0195927, 505.7106218,
> 541.7503854, 498.7956356, 512.7214729, 584.3675585,
> 564.5956413, 604.8318804, 604.8318804, 592.4688595,
> 1272.107849, 1298.652866, 1298.652866, 1935.96084,
> 2088.254554, 1962.799773, 4452.994159, 4422.444691,
> 4128.243033, 312.3359691, 316.6659968, 332.2993098,
> 1500.642011, 1531.95584, 1430.042989),
>   z = c(
> 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3)),
>  row.names = c(NA, -60L),  class = "data.frame")
> attach(my.data)
> my.data$z<-factor(my.data$z, levels = c(0, 1, 2, 3))
> levels(my.data$z)<-c("A", "B", "C", "D")
>
> par(mfrow=c(1,3))  # 1 row, 2 columns
> plot(y~z)
> plot(y~factor(z))
> stripchart(y~z, vertical = TRUE, pch=19)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Aug 27 16:15:21 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 27 Aug 2014 10:15:21 -0400
Subject: [R] scatterplot using plot() function with factorial data
In-Reply-To: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>
References: <CAMk+s2QRQNNE5-f8dg4M+JDH1wFhr2pU7s2nB036bdNPic2GaA@mail.gmail.com>
Message-ID: <CA+vqiLG2XB-nFF6e1JYLB=bZ3-MSH1LRwWjWuBSEKNTyRkwLAQ@mail.gmail.com>

Hi Luigi,

See in line.

On Wed, Aug 27, 2014 at 9:42 AM, Luigi Marongiu
<marongiu.luigi at gmail.com> wrote:
> Dear all,
> I would like to ask whether is possible to draw a scatterplot using
> the simple plot() function when the data is factorial. Without the
> addition of the argument factor(), plot() represent the factorial data
> on a linear scale whereas using this argument transforms plot() from a
> scatterplot to a boxplot. Even adding factor directly in the
> arrangement of the dataset does not alter the result.
> The stripchart() function does the job I am looking for (essentially
> draw the individual points of the dataset on proper axis reference,
> that is categorical/factorial), but I was wondering whether is
> possible to use plot() directly.
> Best regards,
> Luigi
>
> ----
> my.data<-structure(list(
>   row = 1:60,
>   x = c(
> 0, 0, 0, 1, 1, 1, 2, 2, 2,
> 3, 3, 3, 4, 4, 4, 0, 0, 0,
> 1, 1, 1, 2, 2, 2, 3, 3, 3,
> 4, 4, 4, 0, 0, 0, 1, 1, 1,
> 2, 2, 2, 3, 3, 3, 4, 4, 4,
> 3, 3, 3, 0, 0, 0, 1, 1, 1,
> 2, 2, 2, 3, 3, 3, 4, 4, 4),
>   y = c(
> 2073.928223, 2131.830067, 2131.830067, 0.143912883,
> 2191.348468, 2073.928223, 2117.20479, 2017.59903, 1896.388977,
> 1976.358448, 2003.757427, 1883.378928, 2283.756186,
> 2363.732429, 2315.416732, 2206.485917, 2191.348468,
> 2176.314869, 1990.010783, 2059.700178, 1976.358448,
> 617.4528799, 613.2168858, 617.4528799, 1686.950197,
> 1819.655315, 1832.225173, 1480.122531, 1298.652866,
> 1212.260417, 495.3736815, 505.7106218, 538.0337432,
> 383.9842946, 365.919416, 330.0195927, 505.7106218,
> 541.7503854, 498.7956356, 512.7214729, 584.3675585,
> 564.5956413, 604.8318804, 604.8318804, 592.4688595,
> 1272.107849, 1298.652866, 1298.652866, 1935.96084,
> 2088.254554, 1962.799773, 4452.994159, 4422.444691,
> 4128.243033, 312.3359691, 316.6659968, 332.2993098,
> 1500.642011, 1531.95584, 1430.042989),
>   z = c(
> 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 2, 2, 2, 2, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 2, 2,
> 3, 3, 3, 3, 3, 3, 3, 3, 3,
> 3, 3, 3, 3, 3, 3)),
>  row.names = c(NA, -60L),  class = "data.frame")

Your data.frame is broken; x has 63 values, the rest have only 60.

> attach(my.data)

don't do that, it screws you up later on

> my.data$z<-factor(my.data$z, levels = c(0, 1, 2, 3))

If your are expecting this to modify the attached value of z you will
be disappointed. It does not.

> levels(my.data$z)<-c("A", "B", "C", "D")

ditto

>
> par(mfrow=c(1,3))  # 1 row, 2 columns
> plot(y~z)

this is finding the attached value of z, which is not a factor

> plot(y~factor(z))
> stripchart(y~z, vertical = TRUE, pch=19)

once you fix your data and get rid of attach, something like

with(my.data, plot(y ~ as.numeric(z), xaxt = "n")
axis(1, 1:4, labels = levels(z)))

should do it.

Best,
Ista

>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marius.hofert at math.ethz.ch  Wed Aug 27 14:34:11 2014
From: marius.hofert at math.ethz.ch (Marius Hofert)
Date: Wed, 27 Aug 2014 08:34:11 -0400
Subject: [R] Where to find source of C_pbinom?
In-Reply-To: <CAM_vjun3QcTM806zxRvwHJ1QHZe0Hzece77vmO=ck_5G-U99aw@mail.gmail.com>
References: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
	<CAM_vjun3QcTM806zxRvwHJ1QHZe0Hzece77vmO=ck_5G-U99aw@mail.gmail.com>
Message-ID: <CAM3-KjYEr-WCuKD9mQ0Us24nfdFnzuKziWSsbBEpjrdH=Az6uA@mail.gmail.com>

Dear Sarah, Dear David,

thanks for helping. I know the FAQ and I know the R News article, but
I still couldn't figure it out. First, pbinom calls
.External(C_pbinom,...). Grepping for C_pbinom reveals... nothing
(except the appearance in .External). Going to ./src/main/names.c
reveals "{"pbinom", do_math3, 5, 11, 3+2, {PP_FUNCALL, PREC_FN, 0}},",
so the next step is to grep for do_math3 (which also applies for
"dbeta", "pbeta",..., "qnbinom_mu"). There is a connection to pbinom
again in ./src/main/arithmetic.c (SEXP attribute_hidden do_math3):
Math3_2(args, pbinom) is called. src/library/stats/src/distn.c then
shows that "Math3_2(args, pbinom)" is called. Since we just already
grepped for Math3_2, the trip ends here.

So how can one find the source code of pbinom() in this case?

Cheers,

Marius


On Wed, Aug 27, 2014 at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> R FAQ 7.40
>
> http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-access-the-source-code-for-a-function_003f
>
> Sarah
>
>
> On Tuesday, August 26, 2014, Marius Hofert <marius.hofert at math.ethz.ch>
> wrote:
>>
>> Dear expeRts,
>>
>> I would like to find out how R computes pbinom(). A grep in the
>> source code reveiled src/library/stats/R/distn.R:146:
>> .External(C_pbinom, q, size, prob, lower.tail, log.p), so
>> 'C_pbinom' refers to compiled C/C++ code loaded into R. Where can
>> I find the source code of C_pbinom?
>>
>> Cheers,
>>
>> Marius
>>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed Aug 27 17:30:30 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 27 Aug 2014 17:30:30 +0200
Subject: [R] Metafor -can't calculate heterogeneity with non-positive
 sampling variances
In-Reply-To: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BAB@icexch-m4.ic.ac.uk>
References: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BAB@icexch-m4.ic.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DCA0C89D5@UM-MAIL4112.unimaas.nl>

The warning message pretty much says it: When one of the variances is zero, then the I^2 statistic (and various other things) cannot be computed, at least if one sticks to the usual equations/methods. So, if you think the 0 sampling variances really make sense and you really want to get something like I^2, you will have to come up with a creative solution.

On the metafor package website, I explain how I^2 is computed (for the random-effects model):

http://www.metafor-project.org/doku.php/faq#how_are_i_2_and_h_2_computed_i

The crux of the problem is how to compute the 'typical' within-study variance (s^2). With any vi=0, you get division by zero in the equation given. So, you will have to compute s^2 in a different way. You could leave out the studies where vi=0, but this doesn't seem quite right, because this will inflate s^2. You could just take the simple average of the vi values and use that for s^2, but then it's not really I^2 anymore (it's I^2-like).

My question would be: How come you have studies where the sampling variance is estimated to be zero and does that really make sense? Maybe the solution is not to fix the computation of I^2, but to consider if vi=0 is really sensible.

Best,
Wolfgang

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Owen, Branwen
> Sent: Wednesday, August 27, 2014 13:48
> To: r-help at r-project.org
> Subject: [R] Metafor -can't calculate heterogeneity with non-positive
> sampling variances
> 
> Hi, I'm doing a meta-analysis in metafor. All is fine except when there
> are 0s in the values that i'm pooling, then i get a pooled estimate but
> not the I2 that i am also interested in.
> for example:
> 
> summary(rma.1<-
> rma(yi,vi,data=mix,method="ML",knha=F,weighted=F,intercept=T))
> (where yi are the study outcomes, one of which is 0, and vi is the
> variance of the study outcomes)
> 
> Random-Effects Model (k = 17; tau^2 estimator: ML)
> 
>   logLik  deviance       AIC       BIC      AICc
>  13.0539       Inf  -22.1077  -20.4413  -21.2506
> 
> tau^2 (estimated amount of total heterogeneity): 0.0119 (SE = 0.0043)
> tau (square root of estimated tau^2 value):      0.1089
> 
> Model Results:
> 
> estimate       se     zval     pval    ci.lb    ci.ub
>   0.1837   0.0274   6.7154   <.0001   0.1301   0.2374      ***
> 
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Warning messages:
> 1: In rma(yi, vi, data = mix, method = "ML", knha = F, weighted = F,  :
>   There are outcomes with non-positive sampling variances.
> 2: In rma(yi, vi, data = mix, method = "ML", knha = F, weighted = F,  :
>   Cannot compute Q-test, I^2, or H^2 with non-positive sampling
> variances.
> 
> Is there any way around this?
> thanks
> Branwen
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on
> behalf of r-help-owner at r-project.org [r-help-owner at r-project.org]
> Sent: 27 August 2014 13:36
> To: Owen, Branwen
> Subject: Metafor -can't calculate heterogeneity with non-positive
> sampling variances
> 
> Message rejected by filter rule match
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From b.owen11 at imperial.ac.uk  Wed Aug 27 17:38:26 2014
From: b.owen11 at imperial.ac.uk (Owen, Branwen)
Date: Wed, 27 Aug 2014 15:38:26 +0000
Subject: [R] Metafor -can't calculate heterogeneity with non-positive
 sampling variances
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730DCA0C89D5@UM-MAIL4112.unimaas.nl>
References: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BAB@icexch-m4.ic.ac.uk>,
	<077E31A57DA26E46AB0D493C9966AC730DCA0C89D5@UM-MAIL4112.unimaas.nl>
Message-ID: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BD0@icexch-m4.ic.ac.uk>

Thank you very much for your quick reply Wolfgang. The 0 does make sense - I'm working on some behavioural data and in one study none reported that particular behaviour. Up til now I have been calculating I2 without that study, as it's on the small side I don't think it makes much difference. I'm just beginning to wonder if there is another way. 

I'll think about it some more
best wishes
Branwen
________________________________________
From: Viechtbauer Wolfgang (STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl]
Sent: 27 August 2014 17:30
To: Owen, Branwen; r-help at r-project.org
Subject: RE: [R] Metafor -can't calculate heterogeneity with non-positive sampling variances

The warning message pretty much says it: When one of the variances is zero, then the I^2 statistic (and various other things) cannot be computed, at least if one sticks to the usual equations/methods. So, if you think the 0 sampling variances really make sense and you really want to get something like I^2, you will have to come up with a creative solution.

On the metafor package website, I explain how I^2 is computed (for the random-effects model):

http://www.metafor-project.org/doku.php/faq#how_are_i_2_and_h_2_computed_i

The crux of the problem is how to compute the 'typical' within-study variance (s^2). With any vi=0, you get division by zero in the equation given. So, you will have to compute s^2 in a different way. You could leave out the studies where vi=0, but this doesn't seem quite right, because this will inflate s^2. You could just take the simple average of the vi values and use that for s^2, but then it's not really I^2 anymore (it's I^2-like).

My question would be: How come you have studies where the sampling variance is estimated to be zero and does that really make sense? Maybe the solution is not to fix the computation of I^2, but to consider if vi=0 is really sensible.

Best,
Wolfgang

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Owen, Branwen
> Sent: Wednesday, August 27, 2014 13:48
> To: r-help at r-project.org
> Subject: [R] Metafor -can't calculate heterogeneity with non-positive
> sampling variances
>
> Hi, I'm doing a meta-analysis in metafor. All is fine except when there
> are 0s in the values that i'm pooling, then i get a pooled estimate but
> not the I2 that i am also interested in.
> for example:
>
> summary(rma.1<-
> rma(yi,vi,data=mix,method="ML",knha=F,weighted=F,intercept=T))
> (where yi are the study outcomes, one of which is 0, and vi is the
> variance of the study outcomes)
>
> Random-Effects Model (k = 17; tau^2 estimator: ML)
>
>   logLik  deviance       AIC       BIC      AICc
>  13.0539       Inf  -22.1077  -20.4413  -21.2506
>
> tau^2 (estimated amount of total heterogeneity): 0.0119 (SE = 0.0043)
> tau (square root of estimated tau^2 value):      0.1089
>
> Model Results:
>
> estimate       se     zval     pval    ci.lb    ci.ub
>   0.1837   0.0274   6.7154   <.0001   0.1301   0.2374      ***
>
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> Warning messages:
> 1: In rma(yi, vi, data = mix, method = "ML", knha = F, weighted = F,  :
>   There are outcomes with non-positive sampling variances.
> 2: In rma(yi, vi, data = mix, method = "ML", knha = F, weighted = F,  :
>   Cannot compute Q-test, I^2, or H^2 with non-positive sampling
> variances.
>
> Is there any way around this?
> thanks
> Branwen
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on
> behalf of r-help-owner at r-project.org [r-help-owner at r-project.org]
> Sent: 27 August 2014 13:36
> To: Owen, Branwen
> Subject: Metafor -can't calculate heterogeneity with non-positive
> sampling variances
>
> Message rejected by filter rule match
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maitra.mbox.ignored at inbox.com  Wed Aug 27 18:09:10 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Wed, 27 Aug 2014 11:09:10 -0500
Subject: [R] Where to find source of C_pbinom?
In-Reply-To: <CAM3-KjYEr-WCuKD9mQ0Us24nfdFnzuKziWSsbBEpjrdH=Az6uA@mail.gmail.com>
References: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
	<CAM_vjun3QcTM806zxRvwHJ1QHZe0Hzece77vmO=ck_5G-U99aw@mail.gmail.com>
	<CAM3-KjYEr-WCuKD9mQ0Us24nfdFnzuKziWSsbBEpjrdH=Az6uA@mail.gmail.com>
Message-ID: <20140827110910.3320a6d54ceab8bbf4589f92@inbox.com>

Hi,

I have not followed the e-mail trail, but if you are looking for the C
source code for pbinom, then it is pbinom.c in src/nmath.

HTH,
Ranjan


On Wed, 27 Aug 2014 08:34:11 -0400 Marius Hofert
<marius.hofert at math.ethz.ch> wrote:

> Dear Sarah, Dear David,
> 
> thanks for helping. I know the FAQ and I know the R News article, but
> I still couldn't figure it out. First, pbinom calls
> .External(C_pbinom,...). Grepping for C_pbinom reveals... nothing
> (except the appearance in .External). Going to ./src/main/names.c
> reveals "{"pbinom", do_math3, 5, 11, 3+2, {PP_FUNCALL, PREC_FN, 0}},",
> so the next step is to grep for do_math3 (which also applies for
> "dbeta", "pbeta",..., "qnbinom_mu"). There is a connection to pbinom
> again in ./src/main/arithmetic.c (SEXP attribute_hidden do_math3):
> Math3_2(args, pbinom) is called. src/library/stats/src/distn.c then
> shows that "Math3_2(args, pbinom)" is called. Since we just already
> grepped for Math3_2, the trip ends here.
> 
> So how can one find the source code of pbinom() in this case?
> 
> Cheers,
> 
> Marius
> 
> 
> On Wed, Aug 27, 2014 at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> > R FAQ 7.40
> >
> > http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-access-the-source-code-for-a-function_003f
> >
> > Sarah
> >
> >
> > On Tuesday, August 26, 2014, Marius Hofert <marius.hofert at math.ethz.ch>
> > wrote:
> >>
> >> Dear expeRts,
> >>
> >> I would like to find out how R computes pbinom(). A grep in the
> >> source code reveiled src/library/stats/R/distn.R:146:
> >> .External(C_pbinom, q, size, prob, lower.tail, log.p), so
> >> 'C_pbinom' refers to compiled C/C++ code loaded into R. Where can
> >> I find the source code of C_pbinom?
> >>
> >> Cheers,
> >>
> >> Marius
> >>
> >
> >
> > --
> > Sarah Goslee
> > http://www.stringpage.com
> > http://www.sarahgoslee.com
> > http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. Please respond to the mailing list if appropriate.
For those needing to send personal or professional e-mail, please use
appropriate addresses.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From dwinsemius at comcast.net  Wed Aug 27 18:47:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Aug 2014 09:47:56 -0700
Subject: [R] simple plotting wcor (Rssa) question
In-Reply-To: <53FDA269.4000402@gfz-potsdam.de>
References: <53FDA269.4000402@gfz-potsdam.de>
Message-ID: <1AD354D2-980D-4294-87D6-88EE1C6C176B@comcast.net>


On Aug 27, 2014, at 2:18 AM, Ingo Wardinski wrote:

> Hello,
> I try to plot w-correlation matrix of singular spectrum analysis by using the package Rssa. This is an example:
> > library(Rssa)
> > s <- ssa(co2)
> > w <- wcor(s, groups = 1:20)
> > plot(w,cex.label=3),scales=list(at=c(10,20,30,40)))
                      ^ throws an error because of extra paren.
> 
> However cex.label dos not have any effect. Also I would like to change the tick labels, currently they show up as F1, F2 etc., and I would like to have them as 1, 2, etc.

The fact that the plot function for this sort of object has a 'scales' argument suggests to me that it is based on lattice plot functions rather than on base plot functions. If I'm correct, (and I just checked the code and I was) then you should read ?xyplot for the scales arguments. There are a couple of pages to scroll through. Arguments like cex.label that are typical of base plotting functions would likely not have any effect, and unlike base plot methods which complain about extraneous arguments, lattice plot functions generally just ignore such.

For me they do not show up as F1,F2 in your example.

 It doesn't make much sense to request the at values of 30 and 40 since you only gave it a matrix that was 20 x 20.

-- 

David Winsemius
Alameda, CA, USA


From gangchen6 at gmail.com  Wed Aug 27 20:19:11 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 27 Aug 2014 14:19:11 -0400
Subject: [R] Issue with formula conversion
Message-ID: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>

A random effect formulation for R package nlme is read in as a string
of characters from an input file:

ranEff <- "pdCompSymm(~1+Age)"

I need to convert 'ranEff' to a formula class. However, as shown below:

> as.formula(ranEff)
~1 + Age

the "pdCompSymm" is lost in the conversion. Any solutions? Thanks!

Gang


From dwinsemius at comcast.net  Wed Aug 27 21:34:16 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Aug 2014 12:34:16 -0700
Subject: [R] Issue with formula conversion
In-Reply-To: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
Message-ID: <67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>


On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:

> A random effect formulation for R package nlme is read in as a string
> of characters from an input file:
> 
> ranEff <- "pdCompSymm(~1+Age)"
> 
> I need to convert 'ranEff' to a formula class. However, as shown below:
> 
>> as.formula(ranEff)
> ~1 + Age
> 
> the "pdCompSymm" is lost in the conversion. Any solutions? 

as.formula(paste("~",ranEff))
~pdCompSymm(~1 + Age)
-- 

David Winsemius
Alameda, CA, USA


From c.danyluck at gmail.com  Wed Aug 27 18:22:00 2014
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Wed, 27 Aug 2014 12:22:00 -0400
Subject: [R] Problems bootstrapping multigroup SEM
Message-ID: <CA+_f+RFmRj8QGD2sy7KmqUVCeLxfKAUY=qXnj9Opz2+J53MSWw@mail.gmail.com>

Hello,

I am having difficulty resolving an error I receive trying to bootstrap a
multigroup SEM. The error (below) indicates that the model called to
bootSem doesn't contain matrices. This is true, sort of, because I created
a list of two covariance matrices for the model to call. All of this syntax
works fine (a summary of "MAP.mg.sem" will produce parameter estimates,
goodness of fit indices, etc.), however, the bootSem function does not run.
Any ideas on a workaround?

MLM.MAP.Data$IAT.factor <- as.factor(IAT)
IAT.factor <- MLM.MAP.Data$IAT.factor
evaluative.MAP.data <- subset(data.frame(IAT.factor, exp.race,
meditation.experience, years.meditate, repeated.iat, repeated.ERN, age,
acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
FCz.eval.150.cor), IAT==2)
stereotype.MAP.data <- subset(data.frame(IAT.factor, exp.race,
meditation.experience, years.meditate, repeated.iat, repeated.ERN, age,
acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
FCz.eval.150.cor), IAT==1)

MAP.stereotype.cov <- cov(na.omit(stereotype.MAP.data[,-1]))
MAP.evaluative.cov <- cov(na.omit(evaluative.MAP.data[,-1]))
MAP.cov.list <- list(stereotype=MAP.stereotype.cov,
evaluative=MAP.evaluative.cov)

#### Specify your MSEM path model: Years Meditating, ERN, IAT####
MAP.msem.model <- specifyModel()
years.meditate -> repeated.ERN, path1
years.meditate -> repeated.iat, path2
repeated.ERN -> repeated.iat, path3
age -> repeated.iat, path4
years.meditate <-> years.meditate, var1
repeated.ERN <-> repeated.ERN, var2
age <-> age, var3
age <-> years.meditate, cov1
repeated.iat <-> repeated.iat, d1

MAP.mg.mod <- multigroupModel(MAP.msem.model, groups=c("stereotype",
"evaluative"))

MAP.mg.sem <- sem(MAP.mg.mod, MAP.cov.list, c(nrow(stereotype.MAP.data),
nrow(evaluative.MAP.data)), group="IAT.factor")

system.time(bootSem(MAP.mg.sem, R=100, MAP.cov.list))

Error in bootSem.msem(MAP.mg.sem.2, MAP.cov.list, R = 100) :
  the model object doesn't contain data matrices

-- 
Chad M. Danyluck
PhD Candidate, Psychology
University of Toronto
Lab: http://embodiedsocialcognition.com


?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From elie.guichard at inserm.fr  Wed Aug 27 17:36:56 2014
From: elie.guichard at inserm.fr (eguichard)
Date: Wed, 27 Aug 2014 08:36:56 -0700 (PDT)
Subject: [R] problem when I Call C subfunction in void function
In-Reply-To: <CAAJSdjiP1_vCahjEkk30DXtP5UU9FQM0stWO6bV27xSWGxHmOg@mail.gmail.com>
References: <1409133530888-4696073.post@n4.nabble.com>
	<CAAJSdjiP1_vCahjEkk30DXtP5UU9FQM0stWO6bV27xSWGxHmOg@mail.gmail.com>
Message-ID: <1409153816294-4696103.post@n4.nabble.com>

Thank you. 
I can improve my program with your response but I have an other problem. 

/double essai (double *Px, int *tailleP)
{
	int i;
	for (i = 0; i < *tailleP; i++)
	{
		Px[i]=Px[i]*2;
		Rprintf ("I print Px %f\t", Px[i]);
	}
	Rprintf("\n");
	return *Px; 
}

void test_essai (double *Px, int *tailleP, double *res)
{
	int i;
	*res = essai(Px, tailleP); 
	for (i = 0; i < *tailleP; i++)
	{
		Rprintf ("I print res %f\t", res[i]);
	}
}/

When I compile it in R 
/trajPx <- c(2,5,5,4)
.C("test_essai",Px = as.numeric(trajPx),tailleP =
as.integer(length(trajPx)),res = numeric(4))/

I have the following result: 

I print Px 4.000000     I print Px 10.000000    I print Px 10.000000    I
print Px 8.000000     
I print res 4.000000    I print res 0.000000    I print res 0.000000    I
print res 0.000000   
 $Px
[1]  4 10 10  8

$tailleP
[1] 4

$res
[1] 4 0 0 0
 
I haven't problem in "essai" function but I can't correctly return "Px"
vector.
I d'ont understand why I get only the first number (number 4 in my exemple)
?




--
View this message in context: http://r.789695.n4.nabble.com/problem-when-I-Call-C-subfunction-in-void-function-tp4696073p4696103.html
Sent from the R help mailing list archive at Nabble.com.


From gangchen6 at gmail.com  Wed Aug 27 21:44:12 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 27 Aug 2014 15:44:12 -0400
Subject: [R] Issue with formula conversion
In-Reply-To: <67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
Message-ID: <CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>

Thanks for the help! However, I just need to get

pdCompSymm(~1 + Age)

without a tilde (~) at the beginning.

On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>
>> A random effect formulation for R package nlme is read in as a string
>> of characters from an input file:
>>
>> ranEff <- "pdCompSymm(~1+Age)"
>>
>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>
>>> as.formula(ranEff)
>> ~1 + Age
>>
>> the "pdCompSymm" is lost in the conversion. Any solutions?
>
> as.formula(paste("~",ranEff))
> ~pdCompSymm(~1 + Age)
> --
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Wed Aug 27 21:49:21 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Aug 2014 12:49:21 -0700
Subject: [R] Issue with formula conversion
In-Reply-To: <CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
Message-ID: <27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>


On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:

> Thanks for the help! However, I just need to get
> 
> pdCompSymm(~1 + Age)

That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?

-- 
David.
> 
> without a tilde (~) at the beginning.
> 
> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>> 
>>> A random effect formulation for R package nlme is read in as a string
>>> of characters from an input file:
>>> 
>>> ranEff <- "pdCompSymm(~1+Age)"
>>> 
>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>> 
>>>> as.formula(ranEff)
>>> ~1 + Age
>>> 
>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>> 
>> as.formula(paste("~",ranEff))
>> ~pdCompSymm(~1 + Age)
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From motyocska at yahoo.com  Wed Aug 27 21:52:59 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Wed, 27 Aug 2014 12:52:59 -0700
Subject: [R] nlxb generating no SE
Message-ID: <1409169179.90920.YahooMailBasic@web161605.mail.bf1.yahoo.com>

Dear All

please provide insights to the following, if possible:
 we have

E <-c(8.2638 ,7.9634, 7.5636, 6.8669, 5.7599, 8.1890, 8.2960, 8.1481, 8.1371, 8.1322 ,7.9488, 7.8416, 8.0650,
 8.1753, 8.0986 ,8.0224, 8.0942, 8.0357, 7.8794, 7.8691, 8.0660, 8.0753, 8.0447, 7.8647, 7.8837, 7.8416,
 7.6967, 7.4922, 7.7161, 7.6378 ,7.5128 ,7.4886, 7.4667, 7.3940, 7.2450, 7.1756, 6.7253, 6.7213, 6.9897,
 6.7053, 6.3637, 6.8318 ,5.5420, 6.8955, 6.6074, 7.0689, 0.0010 ,1.3010, 1.3010 ,0.0010, 0.0010)

D1<-  c(0.00,  0.00,  0.00 , 0.00,  0.00,  0.25,  0.50 , 1.00 , 2.00,  4.00,  8.00, 16.00, 32.00,  0.25,  0.50,  1.00,
 2.00,  4.00,  8.00, 16.00, 32.00 , 0.25  ,0.50,  1.00 , 2.00,  4.00 , 8.00, 16.00 ,32.00 , 0.25 , 0.50 , 1.00
,  2.00,  4.00,  8.00, 16.00 , 0.25,  0.50 , 1.00  ,2.00,  4.00,  8.00 ,16.00,  0.25,  0.50,  1.00,  4.00,  8.00,
16.00, 32.00, 32.00)
D2 <-c(4 , 8, 16, 32, 64,  0,  0,  0,  0,  0,  0,  0,  0,  4,  4,  4,  4,  4,  4,  4,  4,  8,  8,  8,  8,  8,  8,  8,  8, 16 ,16 ,16,
16, 16, 16, 16, 32 ,32 ,32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64, 64, 32)
y <-rep(1,length(E))
raw <-data.frame(D1,D2,E,y)

require(nlmrt)
start <-list(p1=60,p2=9,p3=-8.01258,p4=-1.74327,p5=-5,p6=82.8655)
print(nlxb <-nlxb(y ~D1/(p1*((E/(p2-E))^(1/p3)))+D2/(p6*((E/(p2-E))^(1/p4)))+(p5*D1*D2)/(p1*p6*((E/(p2-E))^(0.5/p3+0.5/p4))), start=start,data=raw, lower=-Inf, upper=Inf))

and once you run the code you will see the "best" I was able to get out of this data set using the model. "Best" here means the result that made most sense from the perspective of applying it to life science.... My question is related to the lack of calculated SEs (standard errors, correct me if I am wrong)... I would like to calculate CIs for the parameters, and as far as I understand SEs would be needed to be able to do that. Any suggestions for how we may establish 95% CIs for the estimated parameters?

appreciate your input,

thanks,

Andras


From gangchen6 at gmail.com  Wed Aug 27 22:11:12 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 27 Aug 2014 16:11:12 -0400
Subject: [R] Issue with formula conversion
In-Reply-To: <27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
	<27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
Message-ID: <CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>

Good point!

Here is an example:

library(nlme)
fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdComSymm(~Variety-1)))

Now the problem I'm facing is that the following part

pdComSymm(~Variety-1)

is read in as a string of characters from an external source:

ranEff <- 'pdComSymm(~Variety-1)'

The following

(ranEff1 <- as.formula(ranEff))
~Variety - 1

is not what I want. Even though

fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdCompSymm(ranEff1)))

works, I don't know the 'pdCompSymm' part in advance and would like to
make the process automatic.

On Wed, Aug 27, 2014 at 3:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:
>
>> Thanks for the help! However, I just need to get
>>
>> pdCompSymm(~1 + Age)
>
> That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?
>
> --
> David.
>>
>> without a tilde (~) at the beginning.
>>
>> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>>>
>>>> A random effect formulation for R package nlme is read in as a string
>>>> of characters from an input file:
>>>>
>>>> ranEff <- "pdCompSymm(~1+Age)"
>>>>
>>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>>>
>>>>> as.formula(ranEff)
>>>> ~1 + Age
>>>>
>>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>>>
>>> as.formula(paste("~",ranEff))
>>> ~pdCompSymm(~1 + Age)
>>> --
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Wed Aug 27 22:22:42 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Aug 2014 13:22:42 -0700
Subject: [R] Issue with formula conversion
In-Reply-To: <CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
	<27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
	<CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
Message-ID: <2B503B3D-C827-49E2-B6B8-79A3230C53B9@comcast.net>


On Aug 27, 2014, at 1:11 PM, Gang Chen wrote:

> Good point!
> 
> Here is an example:
> 
> library(nlme)
> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdComSymm(~Variety-1)))
> 

One problem is that youa re misspelling the function name.


> Now the problem I'm facing is that the following part
> 
> pdComSymm(~Variety-1)
> 
> is read in as a string of characters from an external source:
> 
> ranEff <- 'pdComSymm(~Variety-1)'
> 
> The following
> 
> (ranEff1 <- as.formula(ranEff))
> ~Variety - 1
> 
> is not what I want. Even though
> 
> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdCompSymm(ranEff1)))

> ranEff <- 'pdCompSymm(~Variety-1)'
> tt <- parse(text=ranEff)

# Returns an unevaluated expression

> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=eval(tt) ))
> fm
Linear mixed-effects model fit by REML
  Data: Oats 
  Log-restricted-likelihood: -296.5209
  Fixed: yield ~ nitro 
(Intercept)       nitro 
   81.87222    73.66667 
snipped rest of output.

-- 
David

> 
> works, I don't know the 'pdCompSymm' part in advance and would like to
> make the process automatic.
> 
> On Wed, Aug 27, 2014 at 3:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:
>> 
>>> Thanks for the help! However, I just need to get
>>> 
>>> pdCompSymm(~1 + Age)
>> 
>> That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?
>> 
>> --
>> David.
>>> 
>>> without a tilde (~) at the beginning.
>>> 
>>> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>> 
>>>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>>>> 
>>>>> A random effect formulation for R package nlme is read in as a string
>>>>> of characters from an input file:
>>>>> 
>>>>> ranEff <- "pdCompSymm(~1+Age)"
>>>>> 
>>>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>>>> 
>>>>>> as.formula(ranEff)
>>>>> ~1 + Age
>>>>> 
>>>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>>>> 
>>>> as.formula(paste("~",ranEff))
>>>> ~pdCompSymm(~1 + Age)
>>>> --
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From gangchen6 at gmail.com  Wed Aug 27 22:29:26 2014
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 27 Aug 2014 16:29:26 -0400
Subject: [R] Issue with formula conversion
In-Reply-To: <2B503B3D-C827-49E2-B6B8-79A3230C53B9@comcast.net>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
	<27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
	<CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
	<2B503B3D-C827-49E2-B6B8-79A3230C53B9@comcast.net>
Message-ID: <CAHmzXO5Bm2CzxwwDoBb7cwBh0doV+-SHcaTo=oTTpC19+BmFTw@mail.gmail.com>

Sorry for the misspelling! And more importantly, thanks a lot for the
nice solution and for the quick help!

On Wed, Aug 27, 2014 at 4:22 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 27, 2014, at 1:11 PM, Gang Chen wrote:
>
>> Good point!
>>
>> Here is an example:
>>
>> library(nlme)
>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdComSymm(~Variety-1)))
>>
>
> One problem is that youa re misspelling the function name.
>
>
>> Now the problem I'm facing is that the following part
>>
>> pdComSymm(~Variety-1)
>>
>> is read in as a string of characters from an external source:
>>
>> ranEff <- 'pdComSymm(~Variety-1)'
>>
>> The following
>>
>> (ranEff1 <- as.formula(ranEff))
>> ~Variety - 1
>>
>> is not what I want. Even though
>>
>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdCompSymm(ranEff1)))
>
>> ranEff <- 'pdCompSymm(~Variety-1)'
>> tt <- parse(text=ranEff)
>
> # Returns an unevaluated expression
>
>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=eval(tt) ))
>> fm
> Linear mixed-effects model fit by REML
>   Data: Oats
>   Log-restricted-likelihood: -296.5209
>   Fixed: yield ~ nitro
> (Intercept)       nitro
>    81.87222    73.66667
> snipped rest of output.
>
> --
> David
>
>>
>> works, I don't know the 'pdCompSymm' part in advance and would like to
>> make the process automatic.
>>
>> On Wed, Aug 27, 2014 at 3:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>
>>> On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:
>>>
>>>> Thanks for the help! However, I just need to get
>>>>
>>>> pdCompSymm(~1 + Age)
>>>
>>> That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?
>>>
>>> --
>>> David.
>>>>
>>>> without a tilde (~) at the beginning.
>>>>
>>>> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>
>>>>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>>>>>
>>>>>> A random effect formulation for R package nlme is read in as a string
>>>>>> of characters from an input file:
>>>>>>
>>>>>> ranEff <- "pdCompSymm(~1+Age)"
>>>>>>
>>>>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>>>>>
>>>>>>> as.formula(ranEff)
>>>>>> ~1 + Age
>>>>>>
>>>>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>>>>>
>>>>> as.formula(paste("~",ranEff))
>>>>> ~pdCompSymm(~1 + Age)
>>>>> --
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From rmh at temple.edu  Wed Aug 27 22:33:58 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 27 Aug 2014 16:33:58 -0400
Subject: [R] Issue with formula conversion
In-Reply-To: <CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
	<27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
	<CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
Message-ID: <CAGx1TMCgWBr91NMGhcyb76VB056Pf95QX0Psx83ZRmA9JE0M-w@mail.gmail.com>

do you have control over the external source?

if so, then something like

BlockFunction <- "pdComSymm"
ranEff1 <- "~Variety -1"

fm <- lme(yield ~ nitro, data=Oats,
random=list(Block=get(BlockFunction)(ranEff1)))

The above is untested.  An example if get() is
> get("sum")(1:4)
[1] 10

The main problem with David's solution, which does work, is the use
of the eval(parse()) idiom.  This is usually strongly discouraged.  See, for
example,

> fortunes::fortune(106)

If the answer is parse() you should usually rethink the question.
   -- Thomas Lumley
      R-help (February 2005)

On Wed, Aug 27, 2014 at 4:11 PM, Gang Chen <gangchen6 at gmail.com> wrote:
> Good point!
>
> Here is an example:
>
> library(nlme)
> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdComSymm(~Variety-1)))
>
> Now the problem I'm facing is that the following part
>
> pdComSymm(~Variety-1)
>
> is read in as a string of characters from an external source:
>
> ranEff <- 'pdComSymm(~Variety-1)'
>
> The following
>
> (ranEff1 <- as.formula(ranEff))
> ~Variety - 1
>
> is not what I want. Even though
>
> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdCompSymm(ranEff1)))
>
> works, I don't know the 'pdCompSymm' part in advance and would like to
> make the process automatic.
>
> On Wed, Aug 27, 2014 at 3:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:
>>
>>> Thanks for the help! However, I just need to get
>>>
>>> pdCompSymm(~1 + Age)
>>
>> That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?
>>
>> --
>> David.
>>>
>>> without a tilde (~) at the beginning.
>>>
>>> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>>>>
>>>>> A random effect formulation for R package nlme is read in as a string
>>>>> of characters from an input file:
>>>>>
>>>>> ranEff <- "pdCompSymm(~1+Age)"
>>>>>
>>>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>>>>
>>>>>> as.formula(ranEff)
>>>>> ~1 + Age
>>>>>
>>>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>>>>
>>>> as.formula(paste("~",ranEff))
>>>> ~pdCompSymm(~1 + Age)
>>>> --
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Aug 27 22:41:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 27 Aug 2014 13:41:33 -0700
Subject: [R] Issue with formula conversion
In-Reply-To: <CAGx1TMCgWBr91NMGhcyb76VB056Pf95QX0Psx83ZRmA9JE0M-w@mail.gmail.com>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
	<27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
	<CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
	<CAGx1TMCgWBr91NMGhcyb76VB056Pf95QX0Psx83ZRmA9JE0M-w@mail.gmail.com>
Message-ID: <55CBC576-C2B4-4F87-858E-62D8FC1D7E69@comcast.net>


On Aug 27, 2014, at 1:33 PM, Richard M. Heiberger wrote:

> do you have control over the external source?
> 
> if so, then something like
> 
> BlockFunction <- "pdComSymm"
> ranEff1 <- "~Variety -1"

I doubt that would work, since it is not a formula object.
> 
> fm <- lme(yield ~ nitro, data=Oats,
> random=list(Block=get(BlockFunction)(ranEff1)))

After correcting the misspelling of the function name, I tested this approach:

 BlockFunction <- "pdCompSymm"
 ranEff1 <- as.formula("~Variety -1")
 fm <- lme(yield ~ nitro, data=Oats, random=list(Block=do.call(BlockFunction, list(form=ranEff1) )
  ))
 fm
#----------
Linear mixed-effects model fit by REML
  Data: Oats 
  Log-restricted-likelihood: -296.5209
  Fixed: yield ~ nitro 
snipped

-- 
David.
> 
> The above is untested.  An example if get() is
>> get("sum")(1:4)
> [1] 10
> 
> The main problem with David's solution, which does work, is the use
> of the eval(parse()) idiom.  This is usually strongly discouraged.  See, for
> example,
> 
>> fortunes::fortune(106)
> 
> If the answer is parse() you should usually rethink the question.
>   -- Thomas Lumley
>      R-help (February 2005)
> 
> On Wed, Aug 27, 2014 at 4:11 PM, Gang Chen <gangchen6 at gmail.com> wrote:
>> Good point!
>> 
>> Here is an example:
>> 
>> library(nlme)
>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdComSymm(~Variety-1)))
>> 
>> Now the problem I'm facing is that the following part
>> 
>> pdComSymm(~Variety-1)
>> 
>> is read in as a string of characters from an external source:
>> 
>> ranEff <- 'pdComSymm(~Variety-1)'
>> 
>> The following
>> 
>> (ranEff1 <- as.formula(ranEff))
>> ~Variety - 1
>> 
>> is not what I want. Even though
>> 
>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdCompSymm(ranEff1)))
>> 
>> works, I don't know the 'pdCompSymm' part in advance and would like to
>> make the process automatic.
>> 
>> On Wed, Aug 27, 2014 at 3:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:
>>> 
>>>> Thanks for the help! However, I just need to get
>>>> 
>>>> pdCompSymm(~1 + Age)
>>> 
>>> That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?
>>> 
>>> --
>>> David.
>>>> 
>>>> without a tilde (~) at the beginning.
>>>> 
>>>> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>> 
>>>>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>>>>> 
>>>>>> A random effect formulation for R package nlme is read in as a string
>>>>>> of characters from an input file:
>>>>>> 
>>>>>> ranEff <- "pdCompSymm(~1+Age)"
>>>>>> 
>>>>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>>>>> 
>>>>>>> as.formula(ranEff)
>>>>>> ~1 + Age
>>>>>> 
>>>>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>>>>> 
>>>>> as.formula(paste("~",ranEff))
>>>>> ~pdCompSymm(~1 + Age)
>>>>> --
>>>>> 
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>> 
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From therneau at mayo.edu  Wed Aug 27 22:47:38 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 27 Aug 2014 15:47:38 -0500
Subject: [R] plot for "survreg" and "intcox" (rewritten)
In-Reply-To: <582E7B9B-AFC6-433F-9499-44CD61770029@comcast.net>
References: <DUB122-W41B64A76D958B4790A05DFADC0@phx.gbl>
	<FCC4EC8E-9BB7-4B8B-9CF1-7F8244B208BE@comcast.net>
	<DUB122-W50206D6BF8E7AC34EC1BEFADC0@phx.gbl>
	<582E7B9B-AFC6-433F-9499-44CD61770029@comcast.net>
Message-ID: <74e190$idl6sj@ironport9.mayo.edu>

I missed this question.

1. For survreg.
   help("predict.survreg") shows an example of drawing a survival curve

Adding a survfit method has been on my list for a long time, since it would make this 
information easier to find.


2. intcox.  I had not been familiar with this function.  Even though the authors have 
decided to label the result with a "coxph" class, presumably so the coxph print function 
will work, almost none of the coxph methods will work on the result.
   However, reading their manual page it seems that the hazard and its time points are 
returned as a part of the result.  I tried running an example to see if the result is a 
hazard or a cumulative hazard but the run failed and it's time to run to a meeting. 
Assume it is cumulative hazard.  Then exp(-fit$lambda0) will give the baseline survival curve.

Terry T


On 08/27/2014 02:47 PM, David Winsemius wrote:
> On Aug 26, 2014, at 3:34 PM, Silong Liao wrote:
>
>> >Hello,
>> >
>> >My data is interval censoring, and I use intcox package which deals with this situation.
>> >
>> >I guess survest is only for survfit, and I would like to plot parametric model "survreg".....Since I use dist="weibull", I tried curve function but plot seems unreasonable.
>> >
>>> >>mod.reg1=survreg(s_new~type+sex+eye+age+preopiop+preopva,dist="weibull")
>>> >>intercept=-19.155
>>> >>scale=8.12
>>> >>curve(pweibull(x,scale=exp(coef(mod.reg1)),shape=1/mod.reg1$scale,lower.tail=FALSE),from=0,to=40)
>> >
> You are asked to reply to the list. ( I am taking the liberty of forwarding to Terry Therneau since I don't want to misquote him.)
>
> I remember Terry Therneau saying that plotting survival curves from interval-censored data seemed difficult at best and nonsensical at worst. (If it's difficult for him it's likely to be impossible for me.) I don't know if the assumption of a parametric form might aid in that effort.
>
> I also remember warnings (in both the documentation and repeated many times by Therneau on rhelp) that the parameters of the weibull distribution used in the survival package were different than those used in the stats package weibull function.
>
> -- David.
>> >----------------------------------------
>>> >>Subject: Re: [R] plot for "survreg" and "intcox" (rewritten)
>>> >>From:dwinsemius at comcast.net
>>> >>Date: Tue, 26 Aug 2014 14:57:16 -0700
>>> >>CC:r-help at r-project.org
>>> >>To:silong.liao at hotmail.com
>>> >>
>>> >>
>>> >>On Aug 26, 2014, at 2:33 PM, Silong Liao wrote:
>>> >>
>>>> >>>Dear R users,
>>>> >>>
>>>> >>>I'm trying to plot survival probability against time(in years) using "survreg" and "intcox". Please can you help me with this problem? (I have rewritten using plain text.) I tried to use "curve" function but have no clue.
>>>> >>>
>>> >>
>>> >>I suspect you want survfit (in the survial package which is where I suspect survreg is coming from. It returns an object that has a plot method. You could also scroll through help(pack=survival) to see other plotting functions.
>>> >>
>>> >>You could also use survest in the rms package.
>>> >>
>>>> >>>For survreg,
>>>>> >>>>mod.reg1=survreg(s_new~type+sex+eye+preopiop+preopva,dist="weibull")
>>>>> >>>>summary(mod.reg1)
>>>> >>>Call:
>>>> >>>survreg(formula = s_new ~ type + sex + eye + preopiop + preopva, dist = "weibull")
>>>> >>>Value Std. Error z p
>>>> >>>(Intercept) 40.539 20.582 1.970 4.89e-02
>>>> >>>typeTrab -6.606 4.279 -1.544 1.23e-01
>>>> >>>sexM -1.055 3.765 -0.280 7.79e-01
>>>> >>>eyeR -2.112 3.587 -0.589 5.56e-01
>>>> >>>preopiop -0.308 0.269 -1.147 2.52e-01
>>>> >>>preopva -0.461 1.771 -0.260 7.95e-01
>>>> >>>Log(scale) 2.058 0.285 7.222 5.12e-13
>>>> >>>
>>>> >>>Scale= 7.83
>>>> >>>Weibull distribution
>>>> >>>Loglik(model)= -78.7 Loglik(intercept only)= -81.4
>>>> >>>Chisq= 5.37 on 5 degrees of freedom, p= 0.37
>>>> >>>Number of Newton-Raphson Iterations: 10
>>>> >>>n= 339
>>>> >>>
>>>> >>>For intcox,
>>> >>
>>> >>You are asked to provide the package name for functions that are not in the base or default packages. I have quite a few packages loaded including survival_2.37-7 , coxme_2.2-3, and rms_4.2-0 but I get:
>>> >>
>>>> >>>?intcox
>>> >>No documentation for ?intcox? in specified packages and libraries:
>>> >>you could try ???intcox?
>>>> >>>
>>> >>
>>> >>--
>>> >>David.
>>> >>
>>> >>
>>> >>
>>>>> >>>>cox.fit=intcox(s_new~type+eye+sex+age+preopiop+preopva,data=glaucoma_new)
>>>>> >>>>summary(cox.fit)
>>>> >>>Call:
>>>> >>>intcox(formula = s_new ~ type + eye + sex + age + preopiop +preopva, data = glaucoma_new)
>>>> >>>
>>>> >>>n= 339
>>>> >>>
>>>> >>>coef exp(coef) se(coef) z Pr(>|z|)
>>>> >>>typeTrab 0.59391 1.81106 NA NA NA
>>>> >>>eyeR 0.28419 1.32868 NA NA NA
>>>> >>>sexM -0.11597 0.89050 NA NA NA
>>>> >>>age -0.06556 0.93655 NA NA NA
>>>> >>>preopiop 0.03903 1.03980 NA NA NA
>>>> >>>preopva -0.05517 0.94632 NA NA NA
>>>> >>>
>>>> >>>exp(coef) exp(-coef) lower .95 upper .95
>>>> >>>typeTrab 1.8111 0.5522 NA NA
>>>> >>>eyeR 1.3287 0.7526 NA NA
>>>> >>>sexM 0.8905 1.1230 NA NA
>>>> >>>age 0.9365 1.0678 NA NA
>>>> >>>preopiop 1.0398 0.9617 NA NA
>>>> >>>preopva 0.9463 1.0567 NA NA
>>>> >>>
>>>> >>>Rsquare= NA (max possible= 0.327 )
>>>> >>>Likelihood ratio test= NA on 6 df, p=NA
>>>> >>>Wald test = NA on 6 df, p=NA
>>>> >>>Score (logrank) test = NA on 6 df, p=NA
>>>> >>>
>>>> >>>______________________________________________
>>>> >>>R-help at r-project.org  mailing list
>>>> >>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >>>PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>>> >>>and provide commented, minimal, self-contained, reproducible code.
>>> >>
>>> >>David Winsemius
>>> >>Alameda, CA, USA
>>> >>
>> >		 	   		  <Rplot.jpeg>
> David Winsemius
> Alameda, CA, USA
>


From rmh at temple.edu  Wed Aug 27 22:47:37 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 27 Aug 2014 16:47:37 -0400
Subject: [R] Issue with formula conversion
In-Reply-To: <55CBC576-C2B4-4F87-858E-62D8FC1D7E69@comcast.net>
References: <CAHmzXO7DNwLne_1epBVPAyTvZs464W2SEhT6QVCPBO-h0V=ZWg@mail.gmail.com>
	<67E5AF23-8948-463A-B054-BD04264B7E9D@comcast.net>
	<CAHmzXO5q5=T=D34rosOmcxQ9ZhjGCgXtznAuQzpX=NW_Qr=gQQ@mail.gmail.com>
	<27AD3578-A2A6-4E7B-BBB6-C8B3DC9A4198@comcast.net>
	<CAHmzXO76GO7xDZiEHx1g8abi3dzeU24ZGogP9a04kzPyzZXkLg@mail.gmail.com>
	<CAGx1TMCgWBr91NMGhcyb76VB056Pf95QX0Psx83ZRmA9JE0M-w@mail.gmail.com>
	<55CBC576-C2B4-4F87-858E-62D8FC1D7E69@comcast.net>
Message-ID: <CAGx1TMBk9ZPQ5if3K_e7gavWTRjbjsgFr_knm3U=UwBFhTgHnw@mail.gmail.com>

David,

you caught my typo of excess quotation marks.  this should work

ranEff1 <- ~Variety -1
random=list(Block=get(BlockFunction)(ranEff1)))

On Wed, Aug 27, 2014 at 4:41 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Aug 27, 2014, at 1:33 PM, Richard M. Heiberger wrote:
>
>> do you have control over the external source?
>>
>> if so, then something like
>>
>> BlockFunction <- "pdComSymm"
>> ranEff1 <- "~Variety -1"
>
> I doubt that would work, since it is not a formula object.
>>
>> fm <- lme(yield ~ nitro, data=Oats,
>> random=list(Block=get(BlockFunction)(ranEff1)))
>
> After correcting the misspelling of the function name, I tested this approach:
>
>  BlockFunction <- "pdCompSymm"
>  ranEff1 <- as.formula("~Variety -1")
>  fm <- lme(yield ~ nitro, data=Oats, random=list(Block=do.call(BlockFunction, list(form=ranEff1) )
>   ))
>  fm
> #----------
> Linear mixed-effects model fit by REML
>   Data: Oats
>   Log-restricted-likelihood: -296.5209
>   Fixed: yield ~ nitro
> snipped
>
> --
> David.
>>
>> The above is untested.  An example if get() is
>>> get("sum")(1:4)
>> [1] 10
>>
>> The main problem with David's solution, which does work, is the use
>> of the eval(parse()) idiom.  This is usually strongly discouraged.  See, for
>> example,
>>
>>> fortunes::fortune(106)
>>
>> If the answer is parse() you should usually rethink the question.
>>   -- Thomas Lumley
>>      R-help (February 2005)
>>
>> On Wed, Aug 27, 2014 at 4:11 PM, Gang Chen <gangchen6 at gmail.com> wrote:
>>> Good point!
>>>
>>> Here is an example:
>>>
>>> library(nlme)
>>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdComSymm(~Variety-1)))
>>>
>>> Now the problem I'm facing is that the following part
>>>
>>> pdComSymm(~Variety-1)
>>>
>>> is read in as a string of characters from an external source:
>>>
>>> ranEff <- 'pdComSymm(~Variety-1)'
>>>
>>> The following
>>>
>>> (ranEff1 <- as.formula(ranEff))
>>> ~Variety - 1
>>>
>>> is not what I want. Even though
>>>
>>> fm <- lme(yield ~ nitro, data=Oats, random=list(Block=pdCompSymm(ranEff1)))
>>>
>>> works, I don't know the 'pdCompSymm' part in advance and would like to
>>> make the process automatic.
>>>
>>> On Wed, Aug 27, 2014 at 3:49 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>
>>>> On Aug 27, 2014, at 12:44 PM, Gang Chen wrote:
>>>>
>>>>> Thanks for the help! However, I just need to get
>>>>>
>>>>> pdCompSymm(~1 + Age)
>>>>
>>>> That's not a formula in the R sense of the word. You should do a better job of posting a use case. Perhaps you want an expression?
>>>>
>>>> --
>>>> David.
>>>>>
>>>>> without a tilde (~) at the beginning.
>>>>>
>>>>> On Wed, Aug 27, 2014 at 3:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>>>>>
>>>>>> On Aug 27, 2014, at 11:19 AM, Gang Chen wrote:
>>>>>>
>>>>>>> A random effect formulation for R package nlme is read in as a string
>>>>>>> of characters from an input file:
>>>>>>>
>>>>>>> ranEff <- "pdCompSymm(~1+Age)"
>>>>>>>
>>>>>>> I need to convert 'ranEff' to a formula class. However, as shown below:
>>>>>>>
>>>>>>>> as.formula(ranEff)
>>>>>>> ~1 + Age
>>>>>>>
>>>>>>> the "pdCompSymm" is lost in the conversion. Any solutions?
>>>>>>
>>>>>> as.formula(paste("~",ranEff))
>>>>>> ~pdCompSymm(~1 + Age)
>>>>>> --
>>>>>>
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>>
>>>>
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From marius.hofert at uwaterloo.ca  Wed Aug 27 23:57:19 2014
From: marius.hofert at uwaterloo.ca (Marius Hofert)
Date: Wed, 27 Aug 2014 17:57:19 -0400
Subject: [R] Where to find source of C_pbinom?
In-Reply-To: <CAM3-KjYEr-WCuKD9mQ0Us24nfdFnzuKziWSsbBEpjrdH=Az6uA@mail.gmail.com>
References: <CAM3-KjYQjegy=92EDafi3fGMLZWbrmaLrzb_M7ACWCZQ=gi52A@mail.gmail.com>
	<CAM_vjun3QcTM806zxRvwHJ1QHZe0Hzece77vmO=ck_5G-U99aw@mail.gmail.com>
	<CAM3-KjYEr-WCuKD9mQ0Us24nfdFnzuKziWSsbBEpjrdH=Az6uA@mail.gmail.com>
Message-ID: <CAM3-KjYiE2O0WMo_BwpFd0xLtY7+Zjr6+BoCaezEeu7mMSwFnw@mail.gmail.com>

Dear Ranjan,

thanks, that was what I was looking for. Somehow my 'grep' must have
missed that.

Cheers,

Marius


On Wed, Aug 27, 2014 at 8:34 AM, Marius Hofert
<marius.hofert at math.ethz.ch> wrote:
> Dear Sarah, Dear David,
>
> thanks for helping. I know the FAQ and I know the R News article, but
> I still couldn't figure it out. First, pbinom calls
> .External(C_pbinom,...). Grepping for C_pbinom reveals... nothing
> (except the appearance in .External). Going to ./src/main/names.c
> reveals "{"pbinom", do_math3, 5, 11, 3+2, {PP_FUNCALL, PREC_FN, 0}},",
> so the next step is to grep for do_math3 (which also applies for
> "dbeta", "pbeta",..., "qnbinom_mu"). There is a connection to pbinom
> again in ./src/main/arithmetic.c (SEXP attribute_hidden do_math3):
> Math3_2(args, pbinom) is called. src/library/stats/src/distn.c then
> shows that "Math3_2(args, pbinom)" is called. Since we just already
> grepped for Math3_2, the trip ends here.
>
> So how can one find the source code of pbinom() in this case?
>
> Cheers,
>
> Marius
>
>
> On Wed, Aug 27, 2014 at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> R FAQ 7.40
>>
>> http://cran.r-project.org/doc/FAQ/R-FAQ.html#How-do-I-access-the-source-code-for-a-function_003f
>>
>> Sarah
>>
>>
>> On Tuesday, August 26, 2014, Marius Hofert <marius.hofert at math.ethz.ch>
>> wrote:
>>>
>>> Dear expeRts,
>>>
>>> I would like to find out how R computes pbinom(). A grep in the
>>> source code reveiled src/library/stats/R/distn.R:146:
>>> .External(C_pbinom, q, size, prob, lower.tail, log.p), so
>>> 'C_pbinom' refers to compiled C/C++ code loaded into R. Where can
>>> I find the source code of C_pbinom?
>>>
>>> Cheers,
>>>
>>> Marius
>>>
>>
>>
>> --
>> Sarah Goslee
>> http://www.stringpage.com
>> http://www.sarahgoslee.com
>> http://www.functionaldiversity.org


From jfox at mcmaster.ca  Thu Aug 28 00:59:33 2014
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 27 Aug 2014 18:59:33 -0400
Subject: [R] Problems bootstrapping multigroup SEM
In-Reply-To: <CA+_f+RFmRj8QGD2sy7KmqUVCeLxfKAUY=qXnj9Opz2+J53MSWw@mail.gmail.com>
References: <CA+_f+RFmRj8QGD2sy7KmqUVCeLxfKAUY=qXnj9Opz2+J53MSWw@mail.gmail.com>
Message-ID: <004401cfc24a$91247dd0$b36d7970$@mcmaster.ca>

Dear Chad,

It's possible that I don't understand properly what you've done, but it appears as if you're passing to bootSem() the covariance matrices for the observed data rather than the case-by-variable data sets themselves. That's also what you say you're doing, and it's what the error message says. 

Moreover, if you look at the documentation in ?bootSem, you'll is that the Cov argument isn't a covariance matrix, but "a function to compute the input covariance or moment matrix; the default is cov. Use cor if the model is fit to the correlation matrix. The function hetcor in the polycor package will compute product-moment, polychoric, and polyserial correlations among mixed continuous and ordinal variables (see the first example below for an illustration)."

So what is there to bootstrap if bootSem() doesn't have access to the original data sets? I suppose that one could do a parametric bootstrap of some sort, but that's not what bootSem() does -- in implements a nonoparametric bootstrap, which requires the original data.

I hope this helps,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Chad Danyluck
> Sent: Wednesday, August 27, 2014 12:22 PM
> To: r-help at r-project.org
> Subject: [R] Problems bootstrapping multigroup SEM
> 
> Hello,
> 
> I am having difficulty resolving an error I receive trying to bootstrap
> a
> multigroup SEM. The error (below) indicates that the model called to
> bootSem doesn't contain matrices. This is true, sort of, because I
> created
> a list of two covariance matrices for the model to call. All of this
> syntax
> works fine (a summary of "MAP.mg.sem" will produce parameter estimates,
> goodness of fit indices, etc.), however, the bootSem function does not
> run.
> Any ideas on a workaround?
> 
> MLM.MAP.Data$IAT.factor <- as.factor(IAT)
> IAT.factor <- MLM.MAP.Data$IAT.factor
> evaluative.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> meditation.experience, years.meditate, repeated.iat, repeated.ERN, age,
> acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> FCz.eval.150.cor), IAT==2)
> stereotype.MAP.data <- subset(data.frame(IAT.factor, exp.race,
> meditation.experience, years.meditate, repeated.iat, repeated.ERN, age,
> acceptance, awareness, FCz.GNG.150.incor, FCz.GNG.150.cor,
> FCz.stereo.150.incor, FCz.stereo.150.cor, FCz.eval.150.incor,
> FCz.eval.150.cor), IAT==1)
> 
> MAP.stereotype.cov <- cov(na.omit(stereotype.MAP.data[,-1]))
> MAP.evaluative.cov <- cov(na.omit(evaluative.MAP.data[,-1]))
> MAP.cov.list <- list(stereotype=MAP.stereotype.cov,
> evaluative=MAP.evaluative.cov)
> 
> #### Specify your MSEM path model: Years Meditating, ERN, IAT####
> MAP.msem.model <- specifyModel()
> years.meditate -> repeated.ERN, path1
> years.meditate -> repeated.iat, path2
> repeated.ERN -> repeated.iat, path3
> age -> repeated.iat, path4
> years.meditate <-> years.meditate, var1
> repeated.ERN <-> repeated.ERN, var2
> age <-> age, var3
> age <-> years.meditate, cov1
> repeated.iat <-> repeated.iat, d1
> 
> MAP.mg.mod <- multigroupModel(MAP.msem.model, groups=c("stereotype",
> "evaluative"))
> 
> MAP.mg.sem <- sem(MAP.mg.mod, MAP.cov.list,
> c(nrow(stereotype.MAP.data),
> nrow(evaluative.MAP.data)), group="IAT.factor")
> 
> system.time(bootSem(MAP.mg.sem, R=100, MAP.cov.list))
> 
> Error in bootSem.msem(MAP.mg.sem.2, MAP.cov.list, R = 100) :
>   the model object doesn't contain data matrices
> 
> --
> Chad M. Danyluck
> PhD Candidate, Psychology
> University of Toronto
> Lab: http://embodiedsocialcognition.com
> 
> 
> ?There is nothing either good or bad but thinking makes it so.? -
> William
> Shakespeare
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gcr at wisdomandwonder.com  Thu Aug 28 01:01:59 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Wed, 27 Aug 2014 18:01:59 -0500
Subject: [R] Best cross-platform OSS GUI CSV management application?
Message-ID: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>

Good evening,

Suppose that /the business/ want to store tabular data inside of a
file. They want manage that file using a GUI program that runs on OSX,
Linux, and Windows.  Additionally, it needs to be OSS and *not* MS Word.

Two options that immediately come to mind are [LibreOffice] and
[OpenOffice.]

The desire is that they could manage it in a format exportable to CSV so
that `R' could use it.

Specifically, they are looking for a tool that would export the data to
a CSV format that `R' was happy with /right out of the box/.

Have you found any good solutions that are similar or identical to this
and what are they?

Kind regards,


[LibreOffice] https://www.libreoffice.org/

[OpenOffice.] https://www.openoffice.org/

Grant Rettke | ACM, ASA, FSF
gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
?Wisdom begins in wonder.? --Socrates
((? (x) (x x)) (? (x) (x x)))
?Life has become immeasurably better since I have been forced to stop
taking it seriously.? --Thompson

	[[alternative HTML version deleted]]


From btyner at gmail.com  Thu Aug 28 02:07:36 2014
From: btyner at gmail.com (Benjamin Tyner)
Date: Wed, 27 Aug 2014 20:07:36 -0400
Subject: [R] lattice: packet.number() versus panel.number()
In-Reply-To: <D1947AA3-6297-4A41-B294-903A0FF802C3@comcast.net>
References: <53FD096C.9070808@gmail.com>
	<D1947AA3-6297-4A41-B294-903A0FF802C3@comcast.net>
Message-ID: <53FE72C8.7010309@gmail.com>

Thanks David. It turns out that I was in fact using a custom index.perm,
but not on purpose. What happened was I used the "[" method on the
trellis object ( lattice:::`[.trellis`), which of course is nothing but
a short-cut for updating the index.perm. Lesson learned...

Regards,
Ben

On 08/27/2014 02:10 AM, David Winsemius wrote:
> On Aug 26, 2014, at 3:25 PM, Benjamin Tyner wrote:
>
>> Hi,
>>
>> According to
>> https://svn.r-project.org/R-packages/trunk/lattice/R/print.trellis.R,
>>
>>    "[panel.number] is usually the same as, but can be different from
>> packet.number"
>>
>> and I had been under the impression that as long as the user is not
>> using a custom index.cond nor perm.cond, the panel.number would in fact
>> be the same as the packet.number.
>>
>> However, I have recently come across a case where the two are *not* the
>> same, even though I am not using a custom index.cond nor perm.cond.
>>
>> So my question is, what might be some other possible situations in which
>> the two would be expected to differ?
> The immediate hypothesis that leaps to mind is cases where there are multiple pages. On each page I suspect the upper left numbering restarts with 1, but I suspect the packet numbers are sequential increasing.
>



From nature.aseem at gmail.com  Thu Aug 28 00:29:24 2014
From: nature.aseem at gmail.com (Aseem Sharma)
Date: Wed, 27 Aug 2014 15:29:24 -0700
Subject: [R] Clip smaller domain from large domain netCDF file
In-Reply-To: <ACB264BC-B374-4418-A810-9A54FEC6DDE9@noaa.gov>
References: <CAPB42UwpgTT_XK3yMSJ+QJtTHGsey3zAgsv6NMQe=iZsVErthA@mail.gmail.com>
	<ACB264BC-B374-4418-A810-9A54FEC6DDE9@noaa.gov>
Message-ID: <CAPB42Uz1yjcrFWVdg56s0wG77xhxjWCxBHRsoC3n4HSKqD0jOg@mail.gmail.com>

Hi,
Yes this is the canadian domain data.
I want to extract only for parts of western Canada.
Further, this data has three variable namely pr, tmax and tmin. I am trying
to extract three different .nc files of each parameters for a smaller
domain.
below is the results of str(myfile).
> str(ncold)
List of 12
 $ filename  : chr "ddf.nc"
 $ writable  : logi FALSE
 $ id        : int 65536
 $ format    : chr "NC_FORMAT_NETCDF4_CLASSIC"
 $ is_GMT    : logi FALSE
 $ groups    :List of 1
  ..$ :List of 7
  .. ..$ id   : int 65536
  .. ..$ name : chr ""
  .. ..$ ndims: int 3
  .. ..$ nvars: int 6
  .. ..$ natts: int 10
  .. ..$ dimid: int [1:3(1d)] 0 1 2
  .. ..$ fqgn : chr ""
  .. ..- attr(*, "class")= chr "ncgroup4"
 $ ndims     : num 3
 $ natts     : num 10
 $ dim       :List of 3
  ..$ lon :List of 10
  .. ..$ name         : chr "lon"
  .. ..$ len          : int 1068
  .. ..$ unlim        : logi FALSE
  .. ..$ group_index  : int 1
  .. ..$ group_id     : int 65536
  .. ..$ id           : int 0
  .. ..$ dimvarid     :List of 5
  .. .. ..$ id         : int 0
  .. .. ..$ group_index: int 1
  .. .. ..$ group_id   : int 65536
  .. .. ..$ list_index : num -1
  .. .. ..$ isdimvar   : logi TRUE
  .. .. ..- attr(*, "class")= chr "ncid4"
  .. ..$ units        : chr "degrees_east"
  .. ..$ vals         : num [1:1068(1d)] -141 -141 -141 -141 -141 ...
  .. ..$ create_dimvar: logi TRUE
  .. ..- attr(*, "class")= chr "ncdim4"
  ..$ lat :List of 10
  .. ..$ name         : chr "lat"
  .. ..$ len          : int 510
  .. ..$ unlim        : logi FALSE
  .. ..$ group_index  : int 1
  .. ..$ group_id     : int 65536
  .. ..$ id           : int 1
  .. ..$ dimvarid     :List of 5
  .. .. ..$ id         : int 1
  .. .. ..$ group_index: int 1
  .. .. ..$ group_id   : int 65536
  .. .. ..$ list_index : num -1
  .. .. ..$ isdimvar   : logi TRUE
  .. .. ..- attr(*, "class")= chr "ncid4"
  .. ..$ units        : chr "degrees_north"
  .. ..$ vals         : num [1:510(1d)] 41 41.1 41.2 41.3 41.4 ...
  .. ..$ create_dimvar: logi TRUE
  .. ..- attr(*, "class")= chr "ncdim4"
  ..$ time:List of 11
  .. ..$ name         : chr "time"
  .. ..$ len          : int 22280
  .. ..$ unlim        : logi TRUE
  .. ..$ group_index  : int 1
  .. ..$ group_id     : int 65536
  .. ..$ id           : int 2
  .. ..$ dimvarid     :List of 5
  .. .. ..$ id         : int 2
  .. .. ..$ group_index: int 1
  .. .. ..$ group_id   : int 65536
  .. .. ..$ list_index : num -1
  .. .. ..$ isdimvar   : logi TRUE
  .. .. ..- attr(*, "class")= chr "ncid4"
  .. ..$ units        : chr "days since 1950-01-01 00:00:00"
  .. ..$ calendar     : chr "standard"
  .. ..$ vals         : num [1:22280(1d)] 0 1 2 3 4 5 6 7 8 9 ...
  .. ..$ create_dimvar: logi TRUE
  .. ..- attr(*, "class")= chr "ncdim4"
 $ unlimdimid: num 3
 $ nvars     : num 3
 $ var       :List of 3
  ..$ pr    :List of 22
  .. ..$ id                :List of 5
  .. .. ..$ id         : num 3
  .. .. ..$ group_index: num -1
  .. .. ..$ group_id   : int 65536
  .. .. ..$ list_index : num 1
  .. .. ..$ isdimvar   : logi FALSE
  .. .. ..- attr(*, "class")= chr "ncid4"
  .. ..$ name              : chr "pr"
  .. ..$ ndims             : int 3
  .. ..$ natts             : int 5
  .. ..$ size              : int [1:3] 1068 510 22280
  .. ..$ dimids            : int [1:3] 0 1 2
  .. ..$ prec              : chr "float"
  .. ..$ units             : chr "mm day-1"
  .. ..$ longname          : chr "Precipitation"
  .. ..$ group_index       : int 1
  .. ..$ chunksizes        : logi NA
  .. ..$ storage           : num 2
  .. ..$ shuffle           : logi FALSE
  .. ..$ compression       : logi NA
  .. ..$ dims              : list()
  .. ..$ dim               :List of 3
  .. .. ..$ :List of 10
  .. .. .. ..$ name         : chr "lon"
  .. .. .. ..$ len          : int 1068
  .. .. .. ..$ unlim        : logi FALSE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 0
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 0
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "degrees_east"
  .. .. .. ..$ vals         : num [1:1068(1d)] -141 -141 -141 -141 -141 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. .. ..$ :List of 10
  .. .. .. ..$ name         : chr "lat"
  .. .. .. ..$ len          : int 510
  .. .. .. ..$ unlim        : logi FALSE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 1
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 1
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "degrees_north"
  .. .. .. ..$ vals         : num [1:510(1d)] 41 41.1 41.2 41.3 41.4 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. .. ..$ :List of 11
  .. .. .. ..$ name         : chr "time"
  .. .. .. ..$ len          : int 22280
  .. .. .. ..$ unlim        : logi TRUE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 2
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 2
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "days since 1950-01-01 00:00:00"
  .. .. .. ..$ calendar     : chr "standard"
  .. .. .. ..$ vals         : num [1:22280(1d)] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. ..$ varsize           : int [1:3] 1068 510 22280
  .. ..$ unlim             : logi TRUE
  .. ..$ make_missing_value: logi TRUE
  .. ..$ missval           : num -32768
  .. ..$ hasAddOffset      : logi FALSE
  .. ..$ hasScaleFact      : logi FALSE
  .. ..- attr(*, "class")= chr "ncvar4"
  ..$ tasmax:List of 22
  .. ..$ id                :List of 5
  .. .. ..$ id         : num 4
  .. .. ..$ group_index: num -1
  .. .. ..$ group_id   : int 65536
  .. .. ..$ list_index : num 2
  .. .. ..$ isdimvar   : logi FALSE
  .. .. ..- attr(*, "class")= chr "ncid4"
  .. ..$ name              : chr "tasmax"
  .. ..$ ndims             : int 3
  .. ..$ natts             : int 5
  .. ..$ size              : int [1:3] 1068 510 22280
  .. ..$ dimids            : int [1:3] 0 1 2
  .. ..$ prec              : chr "float"
  .. ..$ units             : chr "degC"
  .. ..$ longname          : chr "Daily Maximum Near-Surface Air
Temperature"
  .. ..$ group_index       : int 1
  .. ..$ chunksizes        : logi NA
  .. ..$ storage           : num 2
  .. ..$ shuffle           : logi FALSE
  .. ..$ compression       : logi NA
  .. ..$ dims              : list()
  .. ..$ dim               :List of 3
  .. .. ..$ :List of 10
  .. .. .. ..$ name         : chr "lon"
  .. .. .. ..$ len          : int 1068
  .. .. .. ..$ unlim        : logi FALSE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 0
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 0
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "degrees_east"
  .. .. .. ..$ vals         : num [1:1068(1d)] -141 -141 -141 -141 -141 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. .. ..$ :List of 10
  .. .. .. ..$ name         : chr "lat"
  .. .. .. ..$ len          : int 510
  .. .. .. ..$ unlim        : logi FALSE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 1
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 1
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "degrees_north"
  .. .. .. ..$ vals         : num [1:510(1d)] 41 41.1 41.2 41.3 41.4 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. .. ..$ :List of 11
  .. .. .. ..$ name         : chr "time"
  .. .. .. ..$ len          : int 22280
  .. .. .. ..$ unlim        : logi TRUE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 2
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 2
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "days since 1950-01-01 00:00:00"
  .. .. .. ..$ calendar     : chr "standard"
  .. .. .. ..$ vals         : num [1:22280(1d)] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. ..$ varsize           : int [1:3] 1068 510 22280
  .. ..$ unlim             : logi TRUE
  .. ..$ make_missing_value: logi TRUE
  .. ..$ missval           : num -32768
  .. ..$ hasAddOffset      : logi FALSE
  .. ..$ hasScaleFact      : logi FALSE
  .. ..- attr(*, "class")= chr "ncvar4"
  ..$ tasmin:List of 22
  .. ..$ id                :List of 5
  .. .. ..$ id         : num 5
  .. .. ..$ group_index: num -1
  .. .. ..$ group_id   : int 65536
  .. .. ..$ list_index : num 3
  .. .. ..$ isdimvar   : logi FALSE
  .. .. ..- attr(*, "class")= chr "ncid4"
  .. ..$ name              : chr "tasmin"
  .. ..$ ndims             : int 3
  .. ..$ natts             : int 5
  .. ..$ size              : int [1:3] 1068 510 22280
  .. ..$ dimids            : int [1:3] 0 1 2
  .. ..$ prec              : chr "float"
  .. ..$ units             : chr "degC"
  .. ..$ longname          : chr "Daily Minimum Near-Surface Air
Temperature"
  .. ..$ group_index       : int 1
  .. ..$ chunksizes        : logi NA
  .. ..$ storage           : num 2
  .. ..$ shuffle           : logi FALSE
  .. ..$ compression       : logi NA
  .. ..$ dims              : list()
  .. ..$ dim               :List of 3
  .. .. ..$ :List of 10
  .. .. .. ..$ name         : chr "lon"
  .. .. .. ..$ len          : int 1068
  .. .. .. ..$ unlim        : logi FALSE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 0
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 0
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "degrees_east"
  .. .. .. ..$ vals         : num [1:1068(1d)] -141 -141 -141 -141 -141 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. .. ..$ :List of 10
  .. .. .. ..$ name         : chr "lat"
  .. .. .. ..$ len          : int 510
  .. .. .. ..$ unlim        : logi FALSE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 1
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 1
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "degrees_north"
  .. .. .. ..$ vals         : num [1:510(1d)] 41 41.1 41.2 41.3 41.4 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. .. ..$ :List of 11
  .. .. .. ..$ name         : chr "time"
  .. .. .. ..$ len          : int 22280
  .. .. .. ..$ unlim        : logi TRUE
  .. .. .. ..$ group_index  : int 1
  .. .. .. ..$ group_id     : int 65536
  .. .. .. ..$ id           : int 2
  .. .. .. ..$ dimvarid     :List of 5
  .. .. .. .. ..$ id         : int 2
  .. .. .. .. ..$ group_index: int 1
  .. .. .. .. ..$ group_id   : int 65536
  .. .. .. .. ..$ list_index : num -1
  .. .. .. .. ..$ isdimvar   : logi TRUE
  .. .. .. .. ..- attr(*, "class")= chr "ncid4"
  .. .. .. ..$ units        : chr "days since 1950-01-01 00:00:00"
  .. .. .. ..$ calendar     : chr "standard"
  .. .. .. ..$ vals         : num [1:22280(1d)] 0 1 2 3 4 5 6 7 8 9 ...
  .. .. .. ..$ create_dimvar: logi TRUE
  .. .. .. ..- attr(*, "class")= chr "ncdim4"
  .. ..$ varsize           : int [1:3] 1068 510 22280
  .. ..$ unlim             : logi TRUE
  .. ..$ make_missing_value: logi TRUE
  .. ..$ missval           : num -32768
  .. ..$ hasAddOffset      : logi FALSE
  .. ..$ hasScaleFact      : logi FALSE
  .. ..- attr(*, "class")= chr "ncvar4"
 - attr(*, "class")= chr "ncdf4"


Thank you,



------------------

"Namaste ??????"

Aseem Sharma

Graduate Research Assistant

Northern Hydrometeorology Group(NHG)

Natural Resources and Environmental Studies Institute(NRESi)

University of Northern British Columbia

Prince George, BC, V2N 4Z9, Canada

Tel: 250-960-5427

Web: http://www.unbc.ca/


 "All know the Way, but few actually walk it."
"????? ?????? ???? ?"




On Tue, Aug 26, 2014 at 5:52 PM, Roy Mendelssohn <roy.mendelssohn at noaa.gov>
wrote:

> Using the ncdf4 library  requires some knowledge of netcdf files and how
> they work.  However, if you can provide the following information I may be
> able to provide some pointers.  I am assuming your file is named
> "myFile.nc".  Where you see that replace with the actual name.
>
> library(ncdf4)
> myFile<-nc_open('myFile.nc')
> str(myFile)
>
>
> The output of the last command will show what is basically a dump of
> metadata content of the file, showing its structure.    From the bounds I
> assume this is a Canadian dataset?
>
> -Roy
>
> On Aug 26, 2014, at 4:46 PM, Aseem Sharma <nature.aseem at gmail.com> wrote:
>
> > Hi,
> > I have this huge ( ~30GB) .nc file (NC_FORMAT_NETCDF4_CLASSIC)) for the
> > whole country 141.00 to 52.00 W, 41.00 to 84.00 N".
> > I am trying to clip this big dataset for a small region specific domain
> > (120.00 to 130.00 W, 50.00 to 60.00 N).
> > I am trying to do using netCDF4 r package but could not figure out how to
> > do so.
> > Kindly please suggest me how should i proceed.
> >
> >
> > Thank you,
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> **********************
> "The contents of this message do not reflect any position of the U.S.
> Government or NOAA."
> **********************
> Roy Mendelssohn
> Supervisory Operations Research Analyst
> NOAA/NMFS
> Environmental Research Division
> Southwest Fisheries Science Center
> ***Note new address and phone***
> 110 Shaffer Road
> Santa Cruz, CA 95060
> Phone: (831)-420-3666
> Fax: (831) 420-3980
> e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/
>
> "Old age and treachery will overcome youth and skill."
> "From those who have been given much, much will be expected"
> "the arc of the moral universe is long, but it bends toward justice" -MLK
> Jr.
>
>

	[[alternative HTML version deleted]]


From M.Rosario.Garcia at slu.se  Wed Aug 27 22:16:40 2014
From: M.Rosario.Garcia at slu.se (Rosario Garcia Gil)
Date: Wed, 27 Aug 2014 20:16:40 +0000
Subject: [R] ANOVA MS residuals estimation: two models
Message-ID: <A1C4DF829DB4AE45BF8447F83C7EAFFE2232343F@exchange2-3>

Hello

I have an experiment with two factors MANAGEMENT and REGION. And I have three MANAGEMENT types and three REGIONS. Like this.

REGION: A, B and C
MANAGEMENT: N, P, ST
the independent variable is called PHt

I have set the aov in R in two possible ways. The first model I understand, but I do not understand how the second model set the df for each variable. I understood that the second model is the most correct for a two-way ANOVA without repetition, is that correct?:

- aov(PHt~REGION+MANAGEMENT+REGION*MANAGEMENT, data=data)
- aov(PHt~REGION*MANAGEMENT+Error(subject/(REGION*MANAGEMENT)),data=data)

I attach the results of the two models.

Best regards
Rosario


From jdnewmil at dcn.davis.CA.us  Thu Aug 28 02:10:51 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 27 Aug 2014 17:10:51 -0700
Subject: [R] Best cross-platform OSS GUI CSV management application?
In-Reply-To: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
References: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
Message-ID: <cf44e620-f058-4d68-816c-9d20c7fc9e3e@email.android.com>

Please stop posting on this plain text list using HTML. You are not a freshman any more.

Is anyone really considering the use of a word processor (equivalent to MS Word) for managing this tabular data?

The usual quick-and-dirty solution typically involves a spreadsheet program, but they are so lax that any significant amount of manual "management" often corrupts the file with text data in numeric fields and the like. You also end up with versionitis problems if you store the data in the native format for that program.

A better solution is to create a SQL database, which R can read almost as easily as a CSV file but can be configured to restrict data types per column. The drawback is that such solutions are not quick and dirty... someone needs to stick around who understands it. The real question is which flavor of SQL to use. A file-based option that LibreOffice can interact with is sqlite, but I have to admit I don't have much experience using it with that front end. A server-based solution that LibreOffice can talk to like MySQL would be more scalable for multiple users, but one computer would have to act as a server for everyone and the admin skillset takes another step up.

None of these tools are on topic here, but that may get you going toward trying some things out.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 27, 2014 4:01:59 PM PDT, Grant Rettke <gcr at wisdomandwonder.com> wrote:
>Good evening,
>
>Suppose that /the business/ want to store tabular data inside of a
>file. They want manage that file using a GUI program that runs on OSX,
>Linux, and Windows.  Additionally, it needs to be OSS and *not* MS
>Word.
>
>Two options that immediately come to mind are [LibreOffice] and
>[OpenOffice.]
>
>The desire is that they could manage it in a format exportable to CSV
>so
>that `R' could use it.
>
>Specifically, they are looking for a tool that would export the data to
>a CSV format that `R' was happy with /right out of the box/.
>
>Have you found any good solutions that are similar or identical to this
>and what are they?
>
>Kind regards,
>
>
>[LibreOffice] https://www.libreoffice.org/
>
>[OpenOffice.] https://www.openoffice.org/
>
>Grant Rettke | ACM, ASA, FSF
>gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
>?Wisdom begins in wonder.? --Socrates
>((? (x) (x x)) (? (x) (x x)))
>?Life has become immeasurably better since I have been forced to stop
>taking it seriously.? --Thompson
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Aug 28 02:40:54 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 27 Aug 2014 20:40:54 -0400
Subject: [R] Best cross-platform OSS GUI CSV management application?
In-Reply-To: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
References: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
Message-ID: <CA+vqiLHxt47FxsDsrZq4sMU68=y+qyH0BOwBtnFJMF=ghS7j+g@mail.gmail.com>

Not an R question, so off topic here. But I think this is what they
invented wikipedia for: see
http://en.wikipedia.org/wiki/Comparison_of_spreadsheet_software

Best,
Ista

On Wed, Aug 27, 2014 at 7:01 PM, Grant Rettke <gcr at wisdomandwonder.com> wrote:
> Good evening,
>
> Suppose that /the business/ want to store tabular data inside of a
> file. They want manage that file using a GUI program that runs on OSX,
> Linux, and Windows.  Additionally, it needs to be OSS and *not* MS Word.
>
> Two options that immediately come to mind are [LibreOffice] and
> [OpenOffice.]
>
> The desire is that they could manage it in a format exportable to CSV so
> that `R' could use it.
>
> Specifically, they are looking for a tool that would export the data to
> a CSV format that `R' was happy with /right out of the box/.
>
> Have you found any good solutions that are similar or identical to this
> and what are they?
>
> Kind regards,
>
>
> [LibreOffice] https://www.libreoffice.org/
>
> [OpenOffice.] https://www.openoffice.org/
>
> Grant Rettke | ACM, ASA, FSF
> gcr at wisdomandwonder.com | http://www.wisdomandwonder.com/
> ?Wisdom begins in wonder.? --Socrates
> ((? (x) (x x)) (? (x) (x x)))
> ?Life has become immeasurably better since I have been forced to stop
> taking it seriously.? --Thompson
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tlumley at uw.edu  Thu Aug 28 03:21:46 2014
From: tlumley at uw.edu (Thomas Lumley)
Date: Thu, 28 Aug 2014 13:21:46 +1200
Subject: [R] problem when I Call C subfunction in void function
In-Reply-To: <1409153816294-4696103.post@n4.nabble.com>
References: <1409133530888-4696073.post@n4.nabble.com>
	<CAAJSdjiP1_vCahjEkk30DXtP5UU9FQM0stWO6bV27xSWGxHmOg@mail.gmail.com>
	<1409153816294-4696103.post@n4.nabble.com>
Message-ID: <CAJ55+dJ3LEWGtjisUojFDcYLK=PfkhaODdC=72DAb5bErAuE8Q@mail.gmail.com>

On Thu, Aug 28, 2014 at 3:36 AM, eguichard <elie.guichard at inserm.fr> wrote:
> Thank you.
> I can improve my program with your response but I have an other problem.
>
> /double essai (double *Px, int *tailleP)
> {
>         int i;
>         for (i = 0; i < *tailleP; i++)
>         {
>                 Px[i]=Px[i]*2;
>                 Rprintf ("I print Px %f\t", Px[i]);
>         }
>         Rprintf("\n");
>         return *Px;
> }

*Px is a single double, the same as Px[0]

>
> void test_essai (double *Px, int *tailleP, double *res)
> {
>         int i;
>         *res = essai(Px, tailleP);

This is more clearly written as
          res[0] = essai(Px, tailleP);

It sets the first element of res to the double returned by essai()

If you want essai() to modify all the elements of the array that res
points to, you need to pass res to the function.

>         for (i = 0; i < *tailleP; i++)
>         {
>                 Rprintf ("I print res %f\t", res[i]);
>         }
> }/
>
> When I compile it in R
> /trajPx <- c(2,5,5,4)
> .C("test_essai",Px = as.numeric(trajPx),tailleP =
> as.integer(length(trajPx)),res = numeric(4))/
>
> I have the following result:
>
> I print Px 4.000000     I print Px 10.000000    I print Px 10.000000    I
> print Px 8.000000
> I print res 4.000000    I print res 0.000000    I print res 0.000000    I
> print res 0.000000
>  $Px
> [1]  4 10 10  8
>
> $tailleP
> [1] 4
>
> $res
> [1] 4 0 0 0
>
> I haven't problem in "essai" function but I can't correctly return "Px"
> vector.
> I d'ont understand why I get only the first number (number 4 in my exemple)
> ?
>
>



-- 
Thomas Lumley
Professor of Biostatistics
University of Auckland


From roy.mendelssohn at noaa.gov  Thu Aug 28 06:40:53 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Wed, 27 Aug 2014 21:40:53 -0700
Subject: [R] Clip smaller domain from large domain netCDF file
In-Reply-To: <CAPB42Uz1yjcrFWVdg56s0wG77xhxjWCxBHRsoC3n4HSKqD0jOg@mail.gmail.com>
References: <CAPB42UwpgTT_XK3yMSJ+QJtTHGsey3zAgsv6NMQe=iZsVErthA@mail.gmail.com>
	<ACB264BC-B374-4418-A810-9A54FEC6DDE9@noaa.gov>
	<CAPB42Uz1yjcrFWVdg56s0wG77xhxjWCxBHRsoC3n4HSKqD0jOg@mail.gmail.com>
Message-ID: <56CD8812-320E-49F1-9B51-46F94D587451@noaa.gov>

Hi Aseem:

I will try to keep this as short as possible, because a lot of the issue here is more with understanding netcdf file structure than with R, because once you understand the former using ncdf4 is pretty straightforward..  So if you want a more detailed response we should probably take it off line.

Netcdf gridded field are comprised of dimensions or coordinate variables  (which are booth index values and variables that hold the values of the dimensions), and of parameters defined on those dimensions.

From what you send me I see:

>  $ ndims     : num 3

which means your file has three dimensions, "lon", "lat" and "time", dimension as lon(1068), lat(510) and time(22280).

The file says you have 6 variables:

>  nvars: int 6

but 3 of those are the variables holding the lon,lat and time values, the others  (with their dimensions):
pr(lon,lat,time)
tasmax(lon,lat,time)
lasmin(lon,lat,time)

When you called nc_open, you actually already have the coordinate values in the structure, for example  (and I hope I don't skip a leveling the structure), 
the longitude are at ncold$dim$lon$vals, and similar for the others.  So say we have set lon,lat and time as these values, the steps to subset the data would be:

1.  Find the indexes of the variable lon that fall in the subset you want  (lets say for samples 10:19
2. Find the indexes of the variable lat that fall int subset you want  (let's say 20:29)
3. FInd the indexes of the times that fall int subset you want  (let's say 1:5)

than to subset the variable "pr" you would make a call like:

pr<-ncvar_get(ncold,'pr',start=c(10,20,1), count=c(10,10,5))

Note the values of "start" are the same as the first values of the indices given above for the three dimensions, and the count values are the number of elements to read in each dimensions  (i.e. 19-10+1, 29-20+1, 5-1+1).  pr will then contain the subset of the data.

Be certain to close the file:

nc_close(ncold)

Hope this gives you some idea of how to proceed.

-Roy

On Aug 27, 2014, at 3:29 PM, Aseem Sharma <nature.aseem at gmail.com> wrote:


**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From pburns at pburns.seanet.com  Thu Aug 28 08:53:07 2014
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 28 Aug 2014 07:53:07 +0100
Subject: [R] 21 R navigation tools
In-Reply-To: <842952C4-1D93-4853-8AF5-6154D2FBD45B@gmail.com>
References: <2e413a59.57ab.148164519ff.Coremail.rhelpmaillist@163.com>
	<842952C4-1D93-4853-8AF5-6154D2FBD45B@gmail.com>
Message-ID: <53FED1D3.2070401@pburns.seanet.com>

Peter and Po Su, thanks.

For those who haven't read it, it attempts
three things:

* provide an overview of the world of R
(from the point of view of an R session)

* tell of ways to find objects and information

* push you towards organizing your attack
on a problem

Pat


On 27/08/2014 14:03, peter dalgaard wrote:
> C'mon! Already now, Google gives a handful of links to Twitter or R-help or r-bloggers or other places that talk _about_ the write-up.
>
> It's
>
> http://www.burns-stat.com/r-navigation-tools
>
> -pd
>
>
> On 27 Aug 2014, at 09:01 , PO SU <rhelpmaillist at 163.com> wrote:
>
>>
>> I think the article from burns-stat is very worth reading , You can google it ,and hope you find it useful.
>>
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From wbonat at gmail.com  Thu Aug 28 09:49:39 2014
From: wbonat at gmail.com (Wagner Bonat)
Date: Thu, 28 Aug 2014 09:49:39 +0200
Subject: [R] Trace and inverse of big matrices
In-Reply-To: <21499.25716.510908.319472@stat.math.ethz.ch>
References: <CANt=4Mi66Svom4H91RB0Tbop=2pR9YAfZP3zjC7kBXZjg2VojA@mail.gmail.com>
	<21499.25716.510908.319472@stat.math.ethz.ch>
Message-ID: <CANt=4Mi4r=6akeF71z45B+dH13MqMEQcCs08jL_grHXMJg28hg@mail.gmail.com>

Thank you Martin for your advices.

Let me give more information about my matrices. I am working on a
space-time model, it is a very simple model based on second-moment
assumption. My model is

E(Y) = g(X%*%beta) -> g is a suitable link function
V(Y) = C = V^{1/2} Omega V^{1/2} -> It is my variance-covariance matrix


It is my general formulation, for this specific case I am trying to use
similar structure used in Bayesian inference, based on Gaussian Markov
Random Fields, in general these models are specified by their inverse or
precision matrix, and all these matrices are sparse. Specifically  I am
using a CAR (Conditional autoregressive structure) for spatial effects and
RW1( first order random walk) for time effects. Then, my
variance-covariance matrix perhaps I should call dispersion matrix is the
form,

C^{-1} = V^{-1/2} Omega^{-1} V^{-1/2} where V = diag(E[Y]^power) is a
diagonal matrix with the variance function. In this case power variance
function, because I am fitting a Tweedie model. I assume that the
Omega^{-1} can be written as a linear combination of known matrices,

Omega^{-1} = tau0*I + tau1*R_t + tau2*R_s + tau3*R_ts

where R_t, R_s and R_ts are suitable matrices to describe the dependence
structure of the time, space and interaction (space*time), all matrices are
sparse. I use these functions to build these matrices (see below). The full
matrix is given by

Omega^{-1} = tau0* Diagonal(n.obs, 1) + tau1*kronecker(Diagonal(n.time,1),
R_s) + tau2*kronecker(R_t, Diagonal(n.space,1) + tau3*kronecker(R_t, R_s)

This is my space-time model with interaction term. To make inference I am
using the quasi-score function for regression (similar GEE approach) and
Pearson estimating fnuction for covariance parameters, in this case power,
tau0, tau1,tau2 and tau3. The Pearson estimating functions are

phi(p, tau0,tau1,tau2,tau3)_p = t(res)%*%W_p%*%res - tr(W_p%*%C) -> It is
for the power parameter
phi(p, tau0,tau1,tau2,tau3) = t(res)%*%W_tau0%*%res - tr(W_tau0%*%C) -> It
is for the tau0 parameter
phi(p, tau0,tau1,tau2,tau3) = t(res)%*%W_tau1%*%res - tr(W_tau1%*%C) -> It
is for the tau1 parameter

Similar for tau2 and tau3. The W matrices are weights matrices, defined by
the negative the derivative of C matrix with respect every parameter, in
this case very easy for example for tau0 is

W_tau0 = V^{-1/2} I V{-1/2}
W_tau1 = V^{-1/2} kronecker(Diagonal(n.time,1), R_s) V{-1/2} and similar
for tau2, tau3.

The weights matrices are simple and sparse, my problem is to compute the
trace tr(W%*%C) where I need to solve of the C^{-1} or as you called D
matrix.

Thank you for your time !


## Space matrix
mat.espacial <- function(list.viz,ncol,nrow){
vizi <- Matrix(0,nrow=nrow,ncol=ncol, sparse = TRUE)
diagonal <- c()
for(i in 1:ncol){
  diagonal[i] <- length(list.viz[[i]])}
diag(vizi) <- diagonal
for(i in 1:ncol){
vizi[i,c(list.viz[[i]])] <- -1}
return(vizi)}

## Time matrix
mat.temporal <- function(nrow,ncol){
R <- Matrix(0,nrow=nrow,ncol=ncol, sparse = TRUE)
## Restri??es de borda
R[1,c(1,2)] <- c(1,-1)
R[ncol,c(ncol-1,ncol)] <- c(-1,1)
## Corpo da matriz
n <- ncol-1
for(i in 2:n){
R[i,c(i-1,i,i+1)] <- c(-1,2,-1)}
R <- as(R, "symmetricMatrix")
return(R)}







2014-08-25 18:29 GMT+02:00 Martin Maechler <maechler at stat.math.ethz.ch>:

> >>>>> Wagner Bonat <wbonat at gmail.com>
> >>>>>     on Mon, 25 Aug 2014 10:31:41 +0200 writes:
>
>     > I need to compute two equations related with trace and inverse of a
> around
>     > 30000 x 30000 density matrices. The equations are
>
>     > -trace( W_i %**% C) and -trace(W_i %**% C %*% W_j C)
>
> [I assume that 2nd eq is missing a %*% ]
>
>     > I know W_i, W_j and inverse of C. These equations are related with
> Pearson
>     > estimating functions. I am trying to use R and package Matrix, but I
>     > couldn't compute the C matrix, using solve() or chol() and
> chol2inv(). I do
>     > not know with is possible using solve() to solve a system of
> equation and
>     > after compute the trace. It is common to use solve function to
> compute
>     > something like C^{-1} W = solve(C, W), but my equation is a little
> bit
>     > different.
>
> Not too much different, fortunately for you.
>
> First, note that, mathematically,
>
>    tr(A %*% B)  ==  tr(B %*% A)
>
> whenever both matrix products are valid, e.g. when the matrices
> are square of the same dimension.
> Consequently, you typically can interchange the order of the
> matrices in the product __ when inside the trace __
>
> As you know  D := C^{-1}  and really need C = D^{-1}, let's
> better use D notation, so you want
>
>  t1 <- -trace(W_i %**% D^{-1})
>  t2 <- -trace(W_i %**% D^{-1} %*% W_j %*% D^{-1})
>
> so, if
>         CWi <- solve(D, W_i)   {for 'i' and 'j' !}
>
>  t1 <- -trace(CWi)
>  t2 <- -trace(CWi %*% CWj)
>
> Now, this alone will still not be good enough to get done
> quickly, using Matrix:
> The most important question really is if  D ( = C^{-1} ) is
> a *sparse* matrix and possibly the W_j are sparse as well.
> In some (but not most) such cases, C will be sparse, too, and
> the whole computations are done very efficiently using the
> Matrix - underlying C libraries.
>
> I'm interested to hear more about your matrices.
> To find their sparse, apply
>    nnzeros( M )
> and possibly
>    nnzeros(zapsmall( M ))
> to your matrices M.
> Also of interest here is
>    isSymmetric(D)
>
> Martin Maechler,
> ETH Zurich
> and Maintainer of the 'Matrix' package
>
>
>     > Any help is welcome. I am thinking about to use RcppArmadillo, but I
> am not sure that it is able to compute my equations.
>
>     > Thank you everyone.
>
>     > --
>     > Wagner Hugo Bonat
>     > LEG - Laborat?rio de Estat?stica e Geoinforma??o
>     > UFPR - Universidade Federal do Paran?
>



-- 
Wagner Hugo Bonat
LEG - Laborat?rio de Estat?stica e Geoinforma??o
UFPR - Universidade Federal do Paran?

	[[alternative HTML version deleted]]


From ragia11 at hotmail.com  Thu Aug 28 09:56:38 2014
From: ragia11 at hotmail.com (Ragia Ibrahim)
Date: Thu, 28 Aug 2014 09:56:38 +0200
Subject: [R] re arrange according to first positions
In-Reply-To: <mailman.26.1409133612.20308.r-help@r-project.org>
References: <mailman.26.1409133612.20308.r-help@r-project.org>
Message-ID: <DUB125-W817722037DA7363DBBA240B3DA0@phx.gbl>

Dear all,
I have a data frame, where multible process and ordering done  ..can I re arrange (re order ) it regarding  it' s original ROW index ? how?
example
   Xi      items         numrber_list_items
3    8  8, 7, 3, 4                4
2    7     7, 3, 4                0
1   10          10                1
result should be starting from row index 1 to 3.

thanks in advance
Ragia
 
 		 	   		  
	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Aug 28 10:50:11 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 28 Aug 2014 09:50:11 +0100
Subject: [R] re arrange according to first positions
In-Reply-To: <DUB125-W817722037DA7363DBBA240B3DA0@phx.gbl>
References: <mailman.26.1409133612.20308.r-help@r-project.org>
	<DUB125-W817722037DA7363DBBA240B3DA0@phx.gbl>
Message-ID: <53FEED43.90801@sapo.pt>

Hello,

If your data.frame is named 'dat', try something like the following.

dat[order(rownames(dat)), ]


Hope this helps,

Rui Barradas

Em 28-08-2014 08:56, Ragia Ibrahim escreveu:
> Dear all,
> I have a data frame, where multible process and ordering done  ..can I re arrange (re order ) it regarding  it' s original ROW index ? how?
> example
>     Xi      items         numrber_list_items
> 3    8  8, 7, 3, 4                4
> 2    7     7, 3, 4                0
> 1   10          10                1
> result should be starting from row index 1 to 3.
>
> thanks in advance
> Ragia
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From spindler at mea.mpisoc.mpg.de  Thu Aug 28 11:45:56 2014
From: spindler at mea.mpisoc.mpg.de (Martin Spindler)
Date: Thu, 28 Aug 2014 11:45:56 +0200
Subject: [R] Using openBLAS in R under Unix / Linux
Message-ID: <53FEFA54.2040605@mea.mpisoc.mpg.de>

Dear all,
I would like to us openBLAS in R under Linux / Unix.
Which steps do I have to undertake? Does someone know a detailed 
description? (I found some sources on the web, but none was really 
helpful for me.)
Thanks and best,
Martin

	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Thu Aug 28 12:33:06 2014
From: smartpink111 at yahoo.com (arun)
Date: Thu, 28 Aug 2014 03:33:06 -0700
Subject: [R] ANY ONE HERE PLZ Urgent
Message-ID: <1409221986.4154.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Try:

format(as.Date("05/07/2014", "%m/%d/%Y"), "%m")
#[1] "05"

#or
strptime("05/07/2014", "%m/%d/%Y")$mon+1
#[1] 5



A.K.


How to extract a Month from Date object?

almost 13 peoples visited my Question with out replying in New to R , i have task yaar



don't mind plz could you HELP ME

How to extract a Month from Date object?

as.month("05/07/2014", format = "%m")

tried wityh this


From smileismystyl at gmail.com  Thu Aug 28 07:41:23 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Thu, 28 Aug 2014 11:11:23 +0530
Subject: [R] R ERROR- Error in file(file, "rt") : cannot open the connection
Message-ID: <CAG1d=2B9jJJ6uFuPfasD9qOaUHZq7jAiWw-WeNnGh40=ML+CFA@mail.gmail.com>

Dear R Group,

I have an species occurence file stored in dismo/ex/abc.csv.
When i read the file, it shows error.
Error in file(file, "rt") : cannot open the connection
In addition: Warning message:
In file(file, "rt") :  cannot open file
'G:/Software/R-3.1.1/library/dismo/ex/occurence.csv': No such file or
directory
What could b the reason, it shows no such file in directory, but i saved my
file in the place where i have mentioned in d code.
Can someone help me out with this?
Thanx in advanvce

	[[alternative HTML version deleted]]


From nospam at lisse.NA  Thu Aug 28 11:28:43 2014
From: nospam at lisse.NA (Dr Eberhard Lisse)
Date: Thu, 28 Aug 2014 10:28:43 +0100
Subject: [R] Best cross-platform OSS GUI CSV management application?
In-Reply-To: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
References: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
Message-ID: <53FEF64B.6080007@lisse.NA>

Put it into a SQL database, MySQL or PostgreSQL.

el

on 2014-08-28, 00:01 Grant Rettke said the following:
> Good evening,
> 
> Suppose that /the business/ want to store tabular data inside of a
> file. They want manage that file using a GUI program that runs on OSX,
> Linux, and Windows.  Additionally, it needs to be OSS and *not* MS Word.
> 
> Two options that immediately come to mind are [LibreOffice] and
> [OpenOffice.]
> 
> The desire is that they could manage it in a format exportable to CSV so
> that `R' could use it.
> 
> Specifically, they are looking for a tool that would export the data to
> a CSV format that `R' was happy with /right out of the box/.
> 
> Have you found any good solutions that are similar or identical to this
> and what are they?
> 
> Kind regards,
> 
> 
> [LibreOffice] https://www.libreoffice.org/
> 
> [OpenOffice.] https://www.openoffice.org/
> 
> Grant Rettke | ACM, ASA, FSF
[...]


From sarah.goslee at gmail.com  Thu Aug 28 14:44:25 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 28 Aug 2014 08:44:25 -0400
Subject: [R] R ERROR- Error in file(file,
	"rt") : cannot open the connection
In-Reply-To: <CAG1d=2B9jJJ6uFuPfasD9qOaUHZq7jAiWw-WeNnGh40=ML+CFA@mail.gmail.com>
References: <CAG1d=2B9jJJ6uFuPfasD9qOaUHZq7jAiWw-WeNnGh40=ML+CFA@mail.gmail.com>
Message-ID: <CAM_vjukaVJS_JcwQP2XzKNuUTsf1BMEQ2=GeKiAAfgEeE-KLOw@mail.gmail.com>

Hi,

You don't show us your code, and you really should, but most likely
you did not put the file where you thought you did, or there's a typo
in the name.

Using file.choose() may help.

Also, I think it's bad practice to put user files in the R library
directory. You should make a working directory in your own workspace.

Sarah


On Thu, Aug 28, 2014 at 1:41 AM, Girija Kalyani <smileismystyl at gmail.com> wrote:
> Dear R Group,
>
> I have an species occurence file stored in dismo/ex/abc.csv.
> When i read the file, it shows error.
> Error in file(file, "rt") : cannot open the connection
> In addition: Warning message:
> In file(file, "rt") :  cannot open file
> 'G:/Software/R-3.1.1/library/dismo/ex/occurence.csv': No such file or
> directory
> What could b the reason, it shows no such file in directory, but i saved my
> file in the place where i have mentioned in d code.
> Can someone help me out with this?
> Thanx in advanvce
>
-- 
Sarah Gosle
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org


From info at aghmed.fsnet.co.uk  Thu Aug 28 15:25:52 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 28 Aug 2014 14:25:52 +0100
Subject: [R] Metafor -can't calculate heterogeneity with non-positive
 sampling variances
In-Reply-To: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BD0@icexch-m4.ic.ac.u
 k>
References: <5A54ABD88E3B50479FD0E7F7C97BEB32628C0BAB@icexch-m4.ic.ac.uk>
	<077E31A57DA26E46AB0D493C9966AC730DCA0C89D5@UM-MAIL4112.unimaas.nl>
	<5A54ABD88E3B50479FD0E7F7C97BEB32628C0BD0@icexch-m4.ic.ac.uk>
Message-ID: <Zen-1XMziC-0009yp-GU@smarthost01b.mail.zen.net.uk>

At 16:38 27/08/2014, Owen, Branwen wrote:
>Thank you very much for your quick reply Wolfgang. The 0 does make 
>sense - I'm working on some behavioural data and in one study none 
>reported that particular behaviour. Up til now I have been 
>calculating I2 without that study, as it's on the small side I don't 
>think it makes much difference. I'm just beginning to wonder if 
>there is another way.

Branwen
I have not tried this but if your dataset contains proportions as 
your text implies then why not supply xi and ni to rma.uni and then 
get it to compute one of the range of options outlined in the 
documentation for escalc? The Freeman-Tukey one might be worth considering.

Of course I may have misunderstood your brief description.

>I'll think about it some more best wishes Branwen 
>________________________________________ From: Viechtbauer Wolfgang 
>(STAT) [wolfgang.viechtbauer at maastrichtuniversity.nl] Sent: 27 
>August 2014 17:30 To: Owen, Branwen; r-help at r-project.org Subject: 
>RE: [R] Metafor -can't calculate heterogeneity with non-positive 
>sampling variances The warning message pretty much says it: When one 
>of the variances is zero, then the I^2 statistic (and various other 
>things) cannot be computed, at least if one sticks to the usual 
>equations/methods. So, if you think the 0 sampling variances really 
>make sense and you really want to get something like I^2, you will 
>have to come up with a creative solution. On the metafor package 
>website, I explain how I^2 is computed (for the random-effects 
>model): 
>http://www.metafor-project.org/doku.php/faq#how_are_i_2_and_h_2_computed_i 
>The crux of the problem is how to compute the 'typical' within-study 
>variance (s^2). With any vi=0, you get division by zero in the 
>equation given. So, you will have to compute s^2 in a different way. 
>You could leave out the studies where vi=0, but this doesn't seem 
>quite right, because this will inflate s^2. You could just take the 
>simple average of the vi values and use that for s^2, but then it's 
>not really I^2 anymore (it's I^2-like). My question would be: How 
>come you have studies where the sampling variance is estimated to be 
>zero and does that really make sense? Maybe the solution is not to 
>fix the computation of I^2, but to consider if vi=0 is really 
>sensible. Best, Wolfgang > -----Original Message----- > From: 
>r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] > 
>On Behalf Of Owen, Branwen > Sent: Wednesday, August 27, 2014 
>13:48 > To: r-help at r-project.org > Subject: [R] Metafor -can't 
>calculate heterogeneity with non-positive > sampling variances > > 
>Hi, I'm doing a meta-analysis in metafor. All is fine except when 
>there > are 0s in the values that i'm pooling, then i get a pooled 
>estimate but > not the I2 that i am also interested in. > for 
>example: > > summary(rma.1<- > 
>rma(yi,vi,data=mix,method="ML",knha=F,weighted=F,intercept=T)) > 
>(where yi are the study outcomes, one of which is 0, and vi is the > 
>variance of the study outcomes) > > Random-Effects Model (k = 17; 
>tau^2 estimator: 
>ML) > >   logLik  deviance       AIC       BIC      AICc >  13.0539 
>      Inf  -22.1077  -20.4413  -21.2506 > > tau^2 (estimated amount 
>of total heterogeneity): 0.0119 (SE = 0.0043) > tau (square root of 
>estimated tau^2 value):      0.1089 > > Model Results: > > 
>estimate       se     zval     pval    ci.lb    ci.ub >   0.1837 
>0.0274   6.7154   <.0001   0.1301   0.2374      *** > > --- > 
>Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 > > 
>Warning messages: > 1: In rma(yi, vi, data = mix, method = "ML", 
>knha = F, weighted = F,  : >   There are outcomes with non-positive 
>sampling variances. > 2: In rma(yi, vi, data = mix, method = "ML", 
>knha = F, weighted = F,  : >   Cannot compute Q-test, I^2, or H^2 
>with non-positive sampling > variances. > > Is there any way around 
>this? > thanks > Branwen > 
>________________________________________ > From: 
>r-help-bounces at r-project.org [r-help-bounces at r-project.org] on > 
>behalf of r-help-owner at r-project.org [r-help-owner at r-project.org] > 
>Sent: 27 August 2014 13:36 > To: Owen, Branwen > Subject: Metafor 
>-can't calculate heterogeneity with non-positive > sampling 
>variances > > Message rejected by filter rule match > > > 
>______________________________________________ > 
>R-help at r-project.org mailing list > 
>https://stat.ethz.ch/mailman/listinfo/r-help > PLEASE do read the 
>posting guide http://www.R-project.org/posting- > guide.html > and 
>provide commented, minimal, self-contained, reproducible code.

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From nashjc at uottawa.ca  Thu Aug 28 15:25:59 2014
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 28 Aug 2014 09:25:59 -0400
Subject: [R]  nlxb generating no SE
In-Reply-To: <mailman.19.1409220008.27425.r-help@r-project.org>
References: <mailman.19.1409220008.27425.r-help@r-project.org>
Message-ID: <53FF2DE7.3080009@uottawa.ca>

You didn't give your results (but DID give a script -- hooray!). I made
a small change -- got rid of the bounds and added trace=TRUE, and got
the output

##     after  5001    Jacobian and  6997 function evaluations
##   name            coeff          SE       tstat      pval
gradient    JSingval
## p1               53.1753            NA         NA         NA
0.01591   1.158e+13
## p2                 8.296            NA         NA         NA
8.959e+11       4.549
## p3              -7.47638            NA         NA         NA
-0.002521      0.3049
## p4              -1.64963            NA         NA         NA
-0.003805      0.1073
## p5               1.44299            NA         NA         NA
0.001269     0.02521
## p6               91.1994            NA         NA         NA
-0.01548     0.01474
## >

Sorry that this doesn't display correctly in plain text emailer (wrapped
lines). However, it shows

1) This is a pretty nasty problem that has NOT got to the convergence
point, as indicated by 5001 Jacobians. In that case I don't give the
summary(). That is a hint to provide more diagnostics when I do some
upgrade (in process -- new nls14() with Duncan Murdoch is on r-forge
now, but much work to be done).

2) The Jacobian is effectively singular.

3) The parameter scaling is awful.

Maybe time to reformulate.

Best, JN



On 14-08-28 06:00 AM, r-help-request at r-project.org wrote:
> Message: 23
> Date: Wed, 27 Aug 2014 12:52:59 -0700
> From: Andras Farkas <motyocska at yahoo.com>
> To: r-help at r-project.org
> Subject: [R] nlxb generating no SE
> Message-ID:
> 	<1409169179.90920.YahooMailBasic at web161605.mail.bf1.yahoo.com>
> Content-Type: text/plain; charset=us-ascii
> 
> Dear All
> 
> please provide insights to the following, if possible:
>  we have
> 
> E <-c(8.2638 ,7.9634, 7.5636, 6.8669, 5.7599, 8.1890, 8.2960, 8.1481, 8.1371, 8.1322 ,7.9488, 7.8416, 8.0650,
>  8.1753, 8.0986 ,8.0224, 8.0942, 8.0357, 7.8794, 7.8691, 8.0660, 8.0753, 8.0447, 7.8647, 7.8837, 7.8416,
>  7.6967, 7.4922, 7.7161, 7.6378 ,7.5128 ,7.4886, 7.4667, 7.3940, 7.2450, 7.1756, 6.7253, 6.7213, 6.9897,
>  6.7053, 6.3637, 6.8318 ,5.5420, 6.8955, 6.6074, 7.0689, 0.0010 ,1.3010, 1.3010 ,0.0010, 0.0010)
> 
> D1<-  c(0.00,  0.00,  0.00 , 0.00,  0.00,  0.25,  0.50 , 1.00 , 2.00,  4.00,  8.00, 16.00, 32.00,  0.25,  0.50,  1.00,
>  2.00,  4.00,  8.00, 16.00, 32.00 , 0.25  ,0.50,  1.00 , 2.00,  4.00 , 8.00, 16.00 ,32.00 , 0.25 , 0.50 , 1.00
> ,  2.00,  4.00,  8.00, 16.00 , 0.25,  0.50 , 1.00  ,2.00,  4.00,  8.00 ,16.00,  0.25,  0.50,  1.00,  4.00,  8.00,
> 16.00, 32.00, 32.00)
> D2 <-c(4 , 8, 16, 32, 64,  0,  0,  0,  0,  0,  0,  0,  0,  4,  4,  4,  4,  4,  4,  4,  4,  8,  8,  8,  8,  8,  8,  8,  8, 16 ,16 ,16,
> 16, 16, 16, 16, 32 ,32 ,32, 32, 32, 32, 32, 64, 64, 64, 64, 64, 64, 64, 32)
> y <-rep(1,length(E))
> raw <-data.frame(D1,D2,E,y)
> 
> require(nlmrt)
> start <-list(p1=60,p2=9,p3=-8.01258,p4=-1.74327,p5=-5,p6=82.8655)
> print(nlxb <-nlxb(y ~D1/(p1*((E/(p2-E))^(1/p3)))+D2/(p6*((E/(p2-E))^(1/p4)))+(p5*D1*D2)/(p1*p6*((E/(p2-E))^(0.5/p3+0.5/p4))), start=start,data=raw, lower=-Inf, upper=Inf))
> 
> and once you run the code you will see the "best" I was able to get out of this data set using the model. "Best" here means the result that made most sense from the perspective of applying it to life science.... My question is related to the lack of calculated SEs (standard errors, correct me if I am wrong)... I would like to calculate CIs for the parameters, and as far as I understand SEs would be needed to be able to do that. Any suggestions for how we may establish 95% CIs for the estimated parameters?
> 
> appreciate your input,
> 
> thanks,
> 
> Andras


From jdnewmil at dcn.davis.CA.us  Thu Aug 28 15:36:00 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 28 Aug 2014 06:36:00 -0700
Subject: [R] R ERROR- Error in file(file,
	"rt") : cannot open the connection
In-Reply-To: <CAG1d=2B9jJJ6uFuPfasD9qOaUHZq7jAiWw-WeNnGh40=ML+CFA@mail.gmail.com>
References: <CAG1d=2B9jJJ6uFuPfasD9qOaUHZq7jAiWw-WeNnGh40=ML+CFA@mail.gmail.com>
Message-ID: <f0512d88-0b91-49aa-a9b9-4d923cbfde7f@email.android.com>

Such problems usually come from not understanding where files really are, though sometimes odd file permissions can be the culprit. Understanding how backslashes work in R strings also sometimes causes problems, though you seem to be using forward slashes so that may not apply here.

You may find that reading the help files could provide more accurate picture about the file system from R's point of view than you currently have in your mind.

?list.files
list.files()
?getwd
getwd()
list.files("G:/Software/R-3.1.1/library/dismo/ex")

You should not have to use setwd() to successfully read a file, but it can be convenient.

If you confirm the directory is there but you only see a subset of files that you expect, then you may have a permissions problem. My advice is to stay away from changing permissions if at all possible... it usually only occurs because you were doing something "As Administrator" when you shouldn't have been, and fixing that is a pit of despair and off topic here.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 27, 2014 10:41:23 PM PDT, Girija Kalyani <smileismystyl at gmail.com> wrote:
>Dear R Group,
>
>I have an species occurence file stored in dismo/ex/abc.csv.
>When i read the file, it shows error.
>Error in file(file, "rt") : cannot open the connection
>In addition: Warning message:
>In file(file, "rt") :  cannot open file
>'G:/Software/R-3.1.1/library/dismo/ex/occurence.csv': No such file or
>directory
>What could b the reason, it shows no such file in directory, but i
>saved my
>file in the place where i have mentioned in d code.
>Can someone help me out with this?
>Thanx in advanvce
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From arnaud.gaboury at gmail.com  Thu Aug 28 16:01:29 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 28 Aug 2014 16:01:29 +0200
Subject: [R] Using openBLAS in R under Unix / Linux
In-Reply-To: <53FEFA54.2040605@mea.mpisoc.mpg.de>
References: <53FEFA54.2040605@mea.mpisoc.mpg.de>
Message-ID: <CAK1hC9tGMh+QLUQvTFpmuYY-JPOMVB4krH5iMJ=BdGt56PnoRw@mail.gmail.com>

On Thu, Aug 28, 2014 at 11:45 AM, Martin Spindler
<spindler at mea.mpisoc.mpg.de> wrote:
> Dear all,
> I would like to us openBLAS in R under Linux / Unix.
> Which steps do I have to undertake? Does someone know a detailed
> description? (I found some sources on the web, but none was really
> helpful for me.)
> Thanks and best,
> Martin

I run it on my Archlinux. Please visit R archwiki[1]
Do not hesitate to ask, I will help.

[1]https://wiki.archlinux.org/index.php/R




--


From jvadams at usgs.gov  Thu Aug 28 16:35:00 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 28 Aug 2014 09:35:00 -0500
Subject: [R] ASA Conf. on Stats Practice - deadline TUESDAY
Message-ID: <CAN5YmCHvnN8y8CsCqWVLNifGBBr40_dEZbeR-OZXtgayRgkT9Q@mail.gmail.com>

R users,

Abstracts are now being accepted for electronic poster presentations at the
2015 ASA Conference on Statistical Practice, February 19-21, New Orleans,
Louisiana, USA.

If you are interested, you may submit your abstract on the website,
 http://www.amstat.org/meetings/csp/2015/abstracts.cfm
The deadline for submission is Tuesday, September 2.

Thank you.

Jean V. Adams
on behalf of the ASA-CSP 2015 Steering Committee


`?.,,  ><(((?>   `?.,,  ><(((?>   `?.,,  ><(((?>

Jean V. Adams
Statistician
U.S. Geological Survey
Great Lakes Science Center
223 East Steinfest Road
Antigo, WI 54409  USA
715-627-4317, ext. 3125  (Office)
715-216-8014  (Cell)
715-623-6773  (FAX)
http://www.glsc.usgs.gov  (GLSC web site)
http://profile.usgs.gov/jvadams  (My home page)

	[[alternative HTML version deleted]]


From jun.shen.ut at gmail.com  Thu Aug 28 19:41:45 2014
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 28 Aug 2014 13:41:45 -0400
Subject: [R] split a string a keep the last part
Message-ID: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>

Hi everyone,

I believe I am not the first one to have this problem but couldn't find a
relevant thread on the list.

Say I have a string (actually it is the whole column in a data frame) in a
format like this:

test<- 'AF14-485-502-89-00235'

I would like to split the test string and keep the last part. I think I can
do the following

sub('.*-.*-.*-.*-(.*)','\\1', test)

to keep the fifth part of the string. But this won't work if other strings
have more or fewer parts separated by '-'. Is there a general way to do it?
Thanks.

Jun

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Aug 28 20:05:59 2014
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 28 Aug 2014 14:05:59 -0400
Subject: [R] split a string a keep the last part
In-Reply-To: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
References: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
Message-ID: <CAM_vjunzLiaJXywL7mQ=poi7n23fMFdHOR_D7wKFuyGJs8WSZg@mail.gmail.com>

Here's one way:

R> test<- 'AF14-485-502-89-00235'
R> test2 <- strsplit(test, "-")
R> test2
[[1]]
[1] "AF14"  "485"   "502"   "89"    "00235"

R> test2[[1]][length(test2[[1]])]
[1] "00235"

On Thu, Aug 28, 2014 at 1:41 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Hi everyone,
>
> I believe I am not the first one to have this problem but couldn't find a
> relevant thread on the list.
>
> Say I have a string (actually it is the whole column in a data frame) in a
> format like this:
>
> test<- 'AF14-485-502-89-00235'
>
> I would like to split the test string and keep the last part. I think I can
> do the following
>
> sub('.*-.*-.*-.*-(.*)','\\1', test)
>
> to keep the fifth part of the string. But this won't work if other strings
> have more or fewer parts separated by '-'. Is there a general way to do it?
> Thanks.
>
> Jun
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Thu Aug 28 20:08:22 2014
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 28 Aug 2014 13:08:22 -0500
Subject: [R] split a string a keep the last part
In-Reply-To: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
References: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
Message-ID: <098047E7-7E91-4A36-96AC-04E31FCA0D85@me.com>


On Aug 28, 2014, at 12:41 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:

> Hi everyone,
> 
> I believe I am not the first one to have this problem but couldn't find a
> relevant thread on the list.
> 
> Say I have a string (actually it is the whole column in a data frame) in a
> format like this:
> 
> test<- 'AF14-485-502-89-00235'
> 
> I would like to split the test string and keep the last part. I think I can
> do the following
> 
> sub('.*-.*-.*-.*-(.*)','\\1', test)
> 
> to keep the fifth part of the string. But this won't work if other strings
> have more or fewer parts separated by '-'. Is there a general way to do it?
> Thanks.
> 
> Jun


Try this:

test <- 'AF14-485-502-89-00235'

> sub("^.*-(.*)$", "\\1", test)
[1] "00235"


test <- 'AF14-485-502-89-00235-1234'

> sub("^.*-(.*)$", "\\1", test)
[1] "1234"


Another option:

> tail(unlist(strsplit(test, "-")), 1)
[1] "1234"


Regards,

Marc Schwartz


From es at enricoschumann.net  Thu Aug 28 20:11:33 2014
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 28 Aug 2014 20:11:33 +0200
Subject: [R] split a string a keep the last part
In-Reply-To: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
	(Jun Shen's message of "Thu, 28 Aug 2014 13:41:45 -0400")
References: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
Message-ID: <87fvggjxgq.fsf@enricoschumann.net>

On Thu, 28 Aug 2014, Jun Shen <jun.shen.ut at gmail.com> writes:

> Hi everyone,
>
> I believe I am not the first one to have this problem but couldn't find a
> relevant thread on the list.
>
> Say I have a string (actually it is the whole column in a data frame) in a
> format like this:
>
> test<- 'AF14-485-502-89-00235'
>
> I would like to split the test string and keep the last part. I think I can
> do the following
>
> sub('.*-.*-.*-.*-(.*)','\\1', test)
>
> to keep the fifth part of the string. But this won't work if other strings
> have more or fewer parts separated by '-'. Is there a general way to do it?
> Thanks.
>
> Jun

This should work for your example:

  gsub(".*-([^-]*)$", "\\1", test)



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From jun.shen.ut at gmail.com  Thu Aug 28 20:18:12 2014
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Thu, 28 Aug 2014 14:18:12 -0400
Subject: [R] split a string a keep the last part
In-Reply-To: <87fvggjxgq.fsf@enricoschumann.net>
References: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
	<87fvggjxgq.fsf@enricoschumann.net>
Message-ID: <CAMCXXmpP-gxpzuCNcYiyYDm0ekQV1q0Bd6MW0VkX7fX5r=Q8Yw@mail.gmail.com>

Thanks for everyone who replied with those wonderful solutions!

Jun


On Thu, Aug 28, 2014 at 2:11 PM, Enrico Schumann <es at enricoschumann.net>
wrote:

> On Thu, 28 Aug 2014, Jun Shen <jun.shen.ut at gmail.com> writes:
>
> > Hi everyone,
> >
> > I believe I am not the first one to have this problem but couldn't find a
> > relevant thread on the list.
> >
> > Say I have a string (actually it is the whole column in a data frame) in
> a
> > format like this:
> >
> > test<- 'AF14-485-502-89-00235'
> >
> > I would like to split the test string and keep the last part. I think I
> can
> > do the following
> >
> > sub('.*-.*-.*-.*-(.*)','\\1', test)
> >
> > to keep the fifth part of the string. But this won't work if other
> strings
> > have more or fewer parts separated by '-'. Is there a general way to do
> it?
> > Thanks.
> >
> > Jun
>
> This should work for your example:
>
>   gsub(".*-([^-]*)$", "\\1", test)
>
>
>
> --
> Enrico Schumann
> Lucerne, Switzerland
> http://enricoschumann.net
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu Aug 28 20:20:25 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 28 Aug 2014 11:20:25 -0700
Subject: [R] split a string a keep the last part
In-Reply-To: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
References: <CAMCXXmqeZx3SXzkoqnONm=Lh9OG57Sqr-ux_ZxhvsfNF2hzFgA@mail.gmail.com>
Message-ID: <CAF8bMcZFhJ3zF1x8oeLanLHzH29PMQDB1UFPTX6Vjg-KT7qk9Q@mail.gmail.com>

Delete all characters up to and including the last hyphen with
     sub(".*-", "", test)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Aug 28, 2014 at 10:41 AM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Hi everyone,
>
> I believe I am not the first one to have this problem but couldn't find a
> relevant thread on the list.
>
> Say I have a string (actually it is the whole column in a data frame) in a
> format like this:
>
> test<- 'AF14-485-502-89-00235'
>
> I would like to split the test string and keep the last part. I think I can
> do the following
>
> sub('.*-.*-.*-.*-(.*)','\\1', test)
>
> to keep the fifth part of the string. But this won't work if other strings
> have more or fewer parts separated by '-'. Is there a general way to do it?
> Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From walmeszeviani at gmail.com  Thu Aug 28 21:06:30 2014
From: walmeszeviani at gmail.com (walmes .)
Date: Thu, 28 Aug 2014 16:06:30 -0300
Subject: [R] Apply rmarkdown::render() outside the RStudio don't find pandoc
Message-ID: <CAFU=EkZoDEsjYmiV11oVoAOcJPjozQ4WfCLUL0-tPksBrJBaqQ@mail.gmail.com>

Hello,

I want to render a Rmd file using rmarkdown::render() function but I'm used
to edit files with Emacs and I open a linux terminal session to compile
this file with knitr::knit2html()

## On the linux terminal.
$ echo "require(knitr); knit2html('teste01.Rmd')" | R --vanilla

I want to use rmarkdown::render instead. When I tried this, with a R
session open in the linux terminal, I get the message

## In a R session inside the linux terminal
> rmarkdown::render("teste01.Rmd")
Error: pandoc version 1.12.3 or higher is required and was not found.

So I open the the teste01.Rmd file in RStudio and clicked on the "knit
HTML" button and it works. The output is bellow.

## Output in the RStudio after clicking on the "Knit HTML" button.

processing file: teste01.Rmd
  |.............                                                    |  20%
  ordinary text without R code

  |..........................                                       |  40%
label: unnamed-chunk-1
  |.......................................                          |  60%
  ordinary text without R code

  |....................................................             |  80%
label: unnamed-chunk-2 (with options)
List of 1
 $ echo: logi FALSE

  |.................................................................| 100%
  ordinary text without R code


output file: teste01.knit.md

*/usr/lib/rstudio/bin/pandoc/pandoc* teste01.utf8.md --to html --from
markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures
--output teste01.html --smart --email-obfuscation none --standalone
--section-divs --table-of-contents --toc-depth 3 --template
/home/walmes/R/x86_64-pc-linux-gnu-library/3.1/rmarkdown/rmd/h/default.html
--css /home/walmes/Dropbox/ridiculas/markdown/ridiculas.css --variable
theme:cerulean --include-in-header
/tmp/RtmpkgSjDp/rmarkdown-str4aee5c225085.html --mathjax --variable
mathjax-url:
https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML
--no-highlight --variable highlightjs=teste01_files/highlight --variable
highlightjs-theme=textmate

Output created: teste01.html

Its possible to see that RStudio call the pandoc that is at
*/usr/lib/rstudio/bin/pandoc/* and not the old version of pandoc in my
system.

I try overcome this by creating an alias
*pandoc='/usr/lib/rstudio/bin/pandoc/pandoc'*, bus this doesn't work.
Someone has any idea to solve this? I want to use rmarkdown::render()
outside the RStudio.

Thanks.
Walmes.

==========================================================================
Walmes Marques Zeviani
LEG (Laborat?rio de Estat?stica e Geoinforma??o, 25.450418 S, 49.231759 W)
Departamento de Estat?stica - Universidade Federal do Paran?
fone: (+55) 41 3361 3573
skype: walmeszeviani
homepage: http://www.leg.ufpr.br/~walmes
linux user number: 531218
==========================================================================

	[[alternative HTML version deleted]]


From xie at yihui.name  Thu Aug 28 21:56:15 2014
From: xie at yihui.name (Yihui Xie)
Date: Thu, 28 Aug 2014 14:56:15 -0500
Subject: [R] Apply rmarkdown::render() outside the RStudio don't find
	pandoc
In-Reply-To: <CAFU=EkZoDEsjYmiV11oVoAOcJPjozQ4WfCLUL0-tPksBrJBaqQ@mail.gmail.com>
References: <CAFU=EkZoDEsjYmiV11oVoAOcJPjozQ4WfCLUL0-tPksBrJBaqQ@mail.gmail.com>
Message-ID: <CANROs4e1XU5durx_3dC7txE6ZhwH2cbOR=5R4YKuBf1DB1mcNg@mail.gmail.com>

Please check out the instructions here:
https://github.com/rstudio/rmarkdown/blob/master/PANDOC.md

Creating an alias might work, although I have not really tried. What I
have been doing is to uninstall the old version of Pandoc in my
system, and create symlinks following the instructions above. You said

> I try overcome this by creating an alias
> *pandoc='/usr/lib/rstudio/bin/pandoc/pandoc'*, bus this doesn't work.

but you did not describe what "this doesn't work" really means
(whenever you report something that does not work, please attach the
error message so we do not have to imagine what could be wrong).
Anyway, at least you have to let your system know where is
pandoc-citeproc (per instructions above again), which may or may not
be the problem given the missing error message.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Thu, Aug 28, 2014 at 2:06 PM, walmes . <walmeszeviani at gmail.com> wrote:
> Hello,
>
> I want to render a Rmd file using rmarkdown::render() function but I'm used
> to edit files with Emacs and I open a linux terminal session to compile
> this file with knitr::knit2html()
>
> ## On the linux terminal.
> $ echo "require(knitr); knit2html('teste01.Rmd')" | R --vanilla
>
> I want to use rmarkdown::render instead. When I tried this, with a R
> session open in the linux terminal, I get the message
>
> ## In a R session inside the linux terminal
>> rmarkdown::render("teste01.Rmd")
> Error: pandoc version 1.12.3 or higher is required and was not found.
>
> So I open the the teste01.Rmd file in RStudio and clicked on the "knit
> HTML" button and it works. The output is bellow.
>
> ## Output in the RStudio after clicking on the "Knit HTML" button.
>
> processing file: teste01.Rmd
>   |.............                                                    |  20%
>   ordinary text without R code
>
>   |..........................                                       |  40%
> label: unnamed-chunk-1
>   |.......................................                          |  60%
>   ordinary text without R code
>
>   |....................................................             |  80%
> label: unnamed-chunk-2 (with options)
> List of 1
>  $ echo: logi FALSE
>
>   |.................................................................| 100%
>   ordinary text without R code
>
>
> output file: teste01.knit.md
>
> */usr/lib/rstudio/bin/pandoc/pandoc* teste01.utf8.md --to html --from
> markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures
> --output teste01.html --smart --email-obfuscation none --standalone
> --section-divs --table-of-contents --toc-depth 3 --template
> /home/walmes/R/x86_64-pc-linux-gnu-library/3.1/rmarkdown/rmd/h/default.html
> --css /home/walmes/Dropbox/ridiculas/markdown/ridiculas.css --variable
> theme:cerulean --include-in-header
> /tmp/RtmpkgSjDp/rmarkdown-str4aee5c225085.html --mathjax --variable
> mathjax-url:
> https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML
> --no-highlight --variable highlightjs=teste01_files/highlight --variable
> highlightjs-theme=textmate
>
> Output created: teste01.html
>
> Its possible to see that RStudio call the pandoc that is at
> */usr/lib/rstudio/bin/pandoc/* and not the old version of pandoc in my
> system.
>
> I try overcome this by creating an alias
> *pandoc='/usr/lib/rstudio/bin/pandoc/pandoc'*, bus this doesn't work.
> Someone has any idea to solve this? I want to use rmarkdown::render()
> outside the RStudio.
>
> Thanks.
> Walmes.
>
> ==========================================================================
> Walmes Marques Zeviani
> LEG (Laborat?rio de Estat?stica e Geoinforma??o, 25.450418 S, 49.231759 W)
> Departamento de Estat?stica - Universidade Federal do Paran?
> fone: (+55) 41 3361 3573
> skype: walmeszeviani
> homepage: http://www.leg.ufpr.br/~walmes
> linux user number: 531218
> ==========================================================================


From varinsacha at yahoo.fr  Thu Aug 28 21:29:45 2014
From: varinsacha at yahoo.fr (varin sacha)
Date: Thu, 28 Aug 2014 20:29:45 +0100
Subject: [R] R packages for power analysis
Message-ID: <1409254185.12685.YahooMailNeo@web171301.mail.ir2.yahoo.com>

Dear all,

I do know very well the pwr packages from St?phane Champely.?
I would have known if somebody knows others packages for power analysis ??
I think here more about the calculation of the power analysis of the nonparametric tests like the mann whitney or the kruskall wallis.

Best Regards,

Sacha
	[[alternative HTML version deleted]]


From ronald.hylton at citi.com  Thu Aug 28 22:29:36 2014
From: ronald.hylton at citi.com (Hylton, Ronald )
Date: Thu, 28 Aug 2014 20:29:36 +0000
Subject: [R] Using mlogit with case weights
Message-ID: <308570D749E74F45B529733FF1E70C88926E8D@EXTXMB51.nam.nsroot.net>

I have a set of data with ~ 250,000 observations summarized in ~ 1000 rows that I'm trying to analyze with mlogit.  Based on the discussion in
https://stat.ethz.ch/pipermail/r-help/2010-June/241161.html
I understand that using weights= does not (fully) do what I need.  I tried expanding my data to one row per observation to sidestep this issue but after waiting several hours for mlogit to finish I decided this was not a feasible strategy and I needed to use weights= and make whatever adjustments are necessary for the inferences.

My solution is the following:
Define W = sum(weights) / length(weights)
Multiply the Log-Likelihood by W
Divide the Std. Error's by sqrt(W) (and therefore multiply the t-value's by sqrt(W))

Can anyone confirm that this is correct (at least as a large-N approximation)?

The code below provides a test case where I compare duplicating rows to using weights and adjusting the inferences (the original code was from Kenneth Train's exercises using the mlogit package for R).  The last few lines printed (Ratios: ...) show that the coefficients in the two cases are the same to a high accuracy and the Log-Likelihood, Std. Error's and t-value's also have the expected ratios to a decent accuracy.  However it would be good to know that this approach is conceptually sound.

Thanks,
Ron

library("mlogit")
data("Heating", package = "mlogit")
H <- mlogit.data(Heating, shape="wide", choice="depvar", varying=c(3:12))
m <- mlogit(depvar~ic+oc|0, H)
# print(summary(m))

w <- sample(1:200, nrow(Heating), replace=TRUE) # random weights
i <- rep(1:nrow(Heating), times=w) # index vector for duplicating rows according to the weights
H2 <- mlogit.data(Heating[i,], shape="wide", choice="depvar", varying=c(3:12))
m2 <- mlogit(depvar~ic+oc|0, H2)
# print(summary(m2))
m3 <- mlogit(depvar~ic+oc|0, H, weights=rep(w,each=5))
# print(summary(m3))
print(all.equal(coef(m2),coef(m3)))

f2 <- fitted(m2)[cumsum(w)]
f3 <- fitted(m3)
names(f2) <- names(f3)
print(all.equal(f2,f3))

cat("\nRatios:", m2$logLik/m3$logLik, sum(w)/length(w), sqrt(sum(w)/length(w)), sqrt(length(w)/sum(w)), "\n\n")

s2 <- summary(m2)
s3 <- summary(m3)

print(s2$CoefTable / s3$CoefTable)


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Aug 28 23:01:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 Aug 2014 14:01:13 -0700
Subject: [R] R packages for power analysis
In-Reply-To: <1409254185.12685.YahooMailNeo@web171301.mail.ir2.yahoo.com>
References: <1409254185.12685.YahooMailNeo@web171301.mail.ir2.yahoo.com>
Message-ID: <4E0293F7-1920-4F8F-8F4A-7AEAC505C314@comcast.net>


On Aug 28, 2014, at 12:29 PM, varin sacha wrote:

> Dear all,
> 
> I do know very well the pwr packages from St?phane Champely. 
> I would have known if somebody knows others packages for power analysis ? 

The Hmisc/rms package combo has some power oriented functions and I have a vague memory that Harrell has suggested that some of them can be configured to give powpr analysis for M-W. Search the Archives.


> I think here more about the calculation of the power analysis of the nonparametric tests like the mann whitney or the kruskall wallis.
> 
> Best Regards,
> 
> Sacha
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From therneau at mayo.edu  Thu Aug 28 23:03:31 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 28 Aug 2014 16:03:31 -0500
Subject: [R] Linear relative rate / excess relative risk models
In-Reply-To: <mailman.17.1406714407.7806.r-help@r-project.org>
References: <mailman.17.1406714407.7806.r-help@r-project.org>
Message-ID: <31062c$94hg92@ironport10.mayo.edu>



On 07/30/2014 05:00 AM, r-help-request at r-project.org wrote:
> A while ago, I inquired about fitting excess relative risk models in R. This is a follow-up about what I ended up doing in case the question pops up again.
>
> While I was not successful in using standard tools, switching to Bayesian modeling using rstan (mc-stan.org/rstan.html) worked better. The results closely match those from Epicure.
>
> Using the data here:http://dwoll.de/err/dat.txt
> The stan model fit below replicates the results from Epicure here:http://dwoll.de/err/epicure.log
>
> Of course I am still interested in learning about other options or approaches.
>
> Daniel


A good paper on issues and solutions is Lumley, Kronmal and Ma,  2006,
Relative Risk Regression in Medical Research: Models, Contrasts, Estimators, and Algorithms


From walmeszeviani at gmail.com  Thu Aug 28 23:14:09 2014
From: walmeszeviani at gmail.com (walmes .)
Date: Thu, 28 Aug 2014 18:14:09 -0300
Subject: [R] Apply rmarkdown::render() outside the RStudio don't find
	pandoc
In-Reply-To: <CANROs4e1XU5durx_3dC7txE6ZhwH2cbOR=5R4YKuBf1DB1mcNg@mail.gmail.com>
References: <CAFU=EkZoDEsjYmiV11oVoAOcJPjozQ4WfCLUL0-tPksBrJBaqQ@mail.gmail.com>
	<CANROs4e1XU5durx_3dC7txE6ZhwH2cbOR=5R4YKuBf1DB1mcNg@mail.gmail.com>
Message-ID: <CAFU=EkYt5FpP6Y+jWfve6i5ESG8RnPo5Wug_J2AJi=X-CUcNrA@mail.gmail.com>

Yihui,

Thank you so much. I read the PANDOC.md as you suggested and this solved my
issue. I've created the soft-links and then I run in linux terminal

$ echo "rmarkdown::render('teste01.Rmd')" | R --vanilla

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)
... skip ...

> rmarkdown::render('teste01.Rmd')

processing file: teste01.Rmd
  |.............                                                    |  20%

label: unnamed-chunk-2 (with options)
List of 1
 $ echo: logi FALSE

  |.................................................................| 100%
  ordinary text without R code


output file: teste01.knit.md

/usr/local/bin/pandoc teste01.utf8.md --to html --from
markdown+autolink_bare_uris+ascii_identifiers+tex_math_single_backslash-implicit_figures
--output teste01.html --smart --email-obfuscation none --standalone
--section-divs --table-of-contents --toc-depth 3 --template
/home/walmes/R/x86_64-pc-linux-gnu-library/3.1/rmarkdown/rmd/h/default.html
--css /home/walmes/Dropbox/ridiculas/markdown/ridiculas.css --variable
theme:bootstrap --include-in-header
/tmp/RtmpW1cQMQ/rmarkdown-str14a07b76054a.html --mathjax --variable
mathjax-url:
https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML
--no-highlight --variable highlightjs=teste01_files/highlight

Output created: teste01.html

Everything works! Thanks you.

W.


?

	[[alternative HTML version deleted]]


From 538280 at gmail.com  Thu Aug 28 23:35:22 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 28 Aug 2014 15:35:22 -0600
Subject: [R] R packages for power analysis
In-Reply-To: <1409254185.12685.YahooMailNeo@web171301.mail.ir2.yahoo.com>
References: <1409254185.12685.YahooMailNeo@web171301.mail.ir2.yahoo.com>
Message-ID: <CAFEqCdzMk7yEW7mvypnekQ+P9PqPSz6mJdo+sTv56GQwGai88w@mail.gmail.com>

While there are tools that claim to compute power for tests beyond
what you find in the pwr package, I don't like to use them because
either I don't agree with the assumptions that they make, or I don't
know what assumptions are being made (and therefore I don't know
whether I agree with them or not).  Once you are beyond the basics
there are a lot more assumptions/conditions to think about.  A tool
that you can just plug a few values into will need to make some
assumptions for you.  To do a proper power analysis without having the
assumptions made for us you need a tool that is more a programming
language than a plug-and-chug toy.  Luckily R is such a programming
language.  You can compute power using simulation with just the main R
packages.  Here is some sample code for a simulation to compute power
for the Mann-Whitney (also called the Wilcoxon) test:

simfun <- function(n1=25, n2=n1, mu1=5, mu2=mu1) {
x1 <- rexp(n1, 1/mu1)
x2 <- rexp(n2, 1/mu2)
wilcox.test(x1,x2)$p.value
}

out <- replicate(10000, simfun(mu1=5,mu2=8))
hist(out)
abline(v=0.05,col='red')
mean(out <= 0.05)

Change the means/sample sizes/etc. and rerun for additional information.

On Thu, Aug 28, 2014 at 1:29 PM, varin sacha <varinsacha at yahoo.fr> wrote:
> Dear all,
>
> I do know very well the pwr packages from St?phane Champely.
> I would have known if somebody knows others packages for power analysis ?
> I think here more about the calculation of the power analysis of the nonparametric tests like the mann whitney or the kruskall wallis.
>
> Best Regards,
>
> Sacha
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ivarbra at gmail.com  Thu Aug 28 22:46:26 2014
From: ivarbra at gmail.com (Ivar Bratberg)
Date: Thu, 28 Aug 2014 23:46:26 +0300
Subject: [R] minimum r installation to run a script
Message-ID: <CA+ApD3PsTG_gn7wwc4D55DWcixGdwTttV_nfXKaebuREGTQnoQ@mail.gmail.com>

Hi,
I would like to deploy a R script such that it can be run as batch commando
on generic Window machines.

After reading a bit about deploy possibilities I see that the recommended
way is to include the whole R installation catalog and then run R from
command line from within that catalog.

However this catalog is in total 90 MB, and I am confident that I am using
only a small percentage of the libraries which are bundled.

Is there a package to help me find the minimal number of files necessary to
bundle with the script in order to make it run ?

Thank you for your attention.
IB

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Fri Aug 29 02:24:38 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 29 Aug 2014 00:24:38 +0000
Subject: [R] re arrange according to first positions
In-Reply-To: <DUB125-W817722037DA7363DBBA240B3DA0@phx.gbl>
References: <mailman.26.1409133612.20308.r-help@r-project.org>
	<DUB125-W817722037DA7363DBBA240B3DA0@phx.gbl>
Message-ID: <D02515BA.108F9C%macqueen1@llnl.gov>

For future reference, perhaps creating an index variable when the data
frame is first created and before ?multiple process and ordering? is done
would be good.

  mydat$index <- seq(nrow(mydat))


-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 8/28/14, 12:56 AM, "Ragia Ibrahim" <ragia11 at hotmail.com> wrote:

>Dear all,
>I have a data frame, where multible process and ordering done  ..can I re
>arrange (re order ) it regarding  it' s original ROW index ? how?
>example
>   Xi      items         numrber_list_items
>3    8  8, 7, 3, 4                4
>2    7     7, 3, 4                0
>1   10          10                1
>result should be starting from row index 1 to 3.
>
>thanks in advance
>Ragia
> 
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From clfiore at gmail.com  Fri Aug 29 02:01:36 2014
From: clfiore at gmail.com (Cara Fiore)
Date: Thu, 28 Aug 2014 20:01:36 -0400
Subject: [R] distance matrix from metaMDS
Message-ID: <CAEjKTpaNf1=884s+7KqCJ+cK9AmnV8qPLVDz2TOScipzy1=cwg@mail.gmail.com>

Dear R users,

I would like to access the distance matrix generated by metaMDS as well as
use the dist function to calculate the euclidean distance for each axis in
the NMDS. I am having trouble finding a way to access these variables and
any help is greatly appreciated.

For the distance matrix I know I could just calculate the bray-curtis
distance but it would be nice to know how to get it from the NMDS function.
For the euclidean distance, the only thing I can find within metaMDS is the
score function but there must be some way for me to call on/access the
ordination distance for one axis right?

The reason for this is I would like to do something like the stressplot
function but for each axis.

Thank you,
Cara

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Aug 29 04:19:35 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 29 Aug 2014 02:19:35 +0000
Subject: [R] distance matrix from metaMDS
In-Reply-To: <CAEjKTpaNf1=884s+7KqCJ+cK9AmnV8qPLVDz2TOScipzy1=cwg@mail.gmail.com>
References: <CAEjKTpaNf1=884s+7KqCJ+cK9AmnV8qPLVDz2TOScipzy1=cwg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F937F4@mb02.ads.tamu.edu>

Don't the functions metaMDSdist() and metaMDSredist() that are documented on the metaMDS manual page give you the distance matrix? If you want to compute the distances based on a single axis, you could use vegdist(). 

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Cara Fiore
Sent: Thursday, August 28, 2014 7:02 PM
To: r-help at r-project.org
Subject: [R] distance matrix from metaMDS

Dear R users,

I would like to access the distance matrix generated by metaMDS as well as use the dist function to calculate the euclidean distance for each axis in the NMDS. I am having trouble finding a way to access these variables and any help is greatly appreciated.

For the distance matrix I know I could just calculate the bray-curtis distance but it would be nice to know how to get it from the NMDS function.
For the euclidean distance, the only thing I can find within metaMDS is the score function but there must be some way for me to call on/access the ordination distance for one axis right?

The reason for this is I would like to do something like the stressplot function but for each axis.

Thank you,
Cara

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From msharp at txbiomed.org  Fri Aug 29 04:31:25 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Thu, 28 Aug 2014 21:31:25 -0500
Subject: [R] ANY ONE HERE PLZ Urgent
In-Reply-To: <1409221986.4154.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1409221986.4154.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <5AA3750E-7167-47BE-B0F4-73BF2790CD5B@txbiomed.org>

If you use the lubridate package, this is very easy.
See the help file for month() within lubridate for more examples.

library(lubridate)
x <- now()
month(x)
month(x, label = TRUE)
month(x, label = TRUE, abbr = FALSE)
as.character(month(x, label = TRUE, abbr = FALSE))

When you run the above your get the following.

> library(lubridate)
> x <- now()
> month(x)
[1] 8
> month(x, label = TRUE)
[1] Aug
Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < Oct < Nov < Dec
> month(x, label = TRUE, abbr = FALSE)
[1] August
12 Levels: January < February < March < April < May < June < July < ... < December
> as.character(month(x, label = TRUE, abbr = FALSE))
[1] "August"

Mark

On Aug 28, 2014, at 5:33 AM, arun <smartpink111 at yahoo.com> wrote:

> Try:
>
> format(as.Date("05/07/2014", "%m/%d/%Y"), "%m")
> #[1] "05"
>
> #or
> strptime("05/07/2014", "%m/%d/%Y")$mon+1
> #[1] 5
>
>
>
> A.K.
>
>
> How to extract a Month from Date object?
>
> almost 13 peoples visited my Question with out replying in New to R , i have task yaar
>
>
>
> don't mind plz could you HELP ME
>
> How to extract a Month from Date object?
>
> as.month("05/07/2014", format = "%m")
>
> tried wityh this
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From pmaclean2011 at yahoo.com  Fri Aug 29 03:48:55 2014
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Fri, 29 Aug 2014 01:48:55 -0000
Subject: [R] How to add a legend with symbols()
Message-ID: <1407669194.73247.YahooMailNeo@web122406.mail.ne1.yahoo.com>

?#How to add a legend for this bubble plot 
#I prefer p2 with a legend for each bubble 
library(graphics) 
set.seed(1234) 
n=20 
x <- rnorm(n)*2 
y <- rnorm(n) * 1/10 
Z <- rnorm(n)+ 100 
df$r <- sqrt(z/pi) 
df$l <- replicate(n, paste(sample(LETTERS, 3, replace=TRUE), collapse="")) 
?
N <- nrow(df) 
p1 <- with(df, { 
op <- palette(rainbow(N, end = 0.9)) 
symbols(x, y, circles = r, inches = 0.2, bg = 1:N, fg = "blue", main = "") 
palette(op) 
text(x, y, l, cex=0.8) 
abline(v=0, h=0)
}) 
?
p2 <- with(df, { 
op <- palette(rainbow(N, end = 0.9)) 
symbols(x, y, circles = r, inches = 0.2, bg = 1:N, fg = "blue", main = "") 
palette(op) 
abline(v=0, h=0) }) 
?

Peter Maclean
Department of Economics
UDSM


From nlivingston at ymail.com  Fri Aug 29 05:57:26 2014
From: nlivingston at ymail.com (Nick Livingston)
Date: Thu, 28 Aug 2014 20:57:26 -0700
Subject: [R] Question regarding the discrepancy between count model
	parameter estimates between "pscl" and "MASS"
Message-ID: <1409284646.24415.YahooMailBasic@web142401.mail.bf1.yahoo.com>

I have sought consultation online and in person, to no avail. I hope someone
on here might have some insight. Any feedback would be most welcome.

I am attempting to plot predicted values from a two-component hurdle model
(logistic [suicide attempt yes/no] and negative binomial count [number of
attempts thereafter]). To do so, I estimated each component separately using
glm (MASS). While I am able to reproduce hurdle results for the logit
portion in glm, estimates for the negative binomial count component are
different.

Call:
hurdle(formula = Suicide. ~ Age + gender + Victimization * FamilySupport |
Age + gender + Victimization * FamilySupport, dist = "negbin", link =
"logit")

Pearson residuals:
? ? Min? ? ? 1Q? Median? ? ? 3Q? ???Max
-0.9816 -0.5187 -0.4094? 0.2974? 5.8820

Count model coefficients (truncated negbin with log link):
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error z value
Pr(>|z|)???
(Intercept)? ? ? ? ? ? ? ? ? ? ? ? ? -0.29150? ? 0.33127? -0.880???0.3789???
Age? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.17068? ? 0.07556???2.259???0.0239
*
gender? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ???0.28273? ? 0.31614???0.894???0.3712???
Victimization? ? ? ? ? ? ? ? ? ? ? ???1.08405? ? 0.18157???5.971 2.36e-09
***
FamilySupport? ? ? ? ? ? ? ? ? ? ? 0.33629? ? 0.29302???1.148???0.2511???
Victimization:FamilySupport -0.96831? ? 0.46841? -2.067???0.0387 *
Log(theta)? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.12245? ? 0.54102???0.226???0.8209???
Zero hurdle model coefficients (binomial with logit link):
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ???Estimate Std. Error z value
Pr(>|z|)???
(Intercept)? ? ? ? ? ? ? ? ? ? ? ? ???-0.547051???0.215981? -2.533? 0.01131
*
Age? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ???-0.154493???0.063994? -2.414
0.01577 *
gender? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ???-0.030942???0.284868? -0.109? 0.91350? ???
Victimization? ? ? ? ? ? ? ? ? ? ? ? ? 1.073956???0.338015???3.177? 0.00149
**
FamilySupport? ? ? ? ? ? ? ? ? ? ???-0.380360???0.247530? -1.537? 0.12439???
Victimization\:FamilySupport? -0.813329???0.399905? -2.034? 0.04197 *
---
Signif. codes:? 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Theta: count = 1.1303
Number of iterations in BFGS optimization: 23
Log-likelihood: -374.3 on 25 Df
> summary(logistic)




Call:
glm(formula = SuicideBinary ~ Age + gender = Victimization * FamilySupport,
family = "binomial")

Deviance Residuals:
? ? Min? ? ???1Q???Median? ? ???3Q? ? ? Max
-1.9948? -0.8470? -0.6686???1.1160???2.0805

Coefficients:
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ???Estimate Std. Error z value
Pr(>|z|)???
(Intercept)? ? ? ? ? ? ? ? ? ? ? ? ? -0.547051???0.215981? -2.533? 0.01131 *
Age? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -0.154493???0.063994? -2.414? 0.01577
*
gender? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? -0.030942???0.284868? -0.109? 0.91350???
Victimization? ? ? ? ? ? ? ? ? ? ? ???1.073956???0.338014???3.177? 0.00149
**
FamilySupport? ? ? ? ? ? ? ? ? ? ? -0.380360???0.247530? -1.537? 0.12439???
Victimization:FamilySupport? -0.813329???0.399904? -2.034? 0.04197 *
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

? ? Null deviance: 452.54? on 359? degrees of freedom
Residual deviance: 408.24? on 348? degrees of freedom
? (52 observations deleted due to missingness)
AIC: 432.24

Number of Fisher Scoring iterations: 4

> summary(Count1)






Call:
glm(formula = NegBinSuicide ~ Age + gender + Victimization * FamilySupport,
family = negative.binomial(theta = 1.1303))

Deviance Residuals:
? ? Min? ? ???1Q???Median? ? ???3Q? ? ? Max
-1.6393? -0.4504? -0.1679???0.2350???2.1676

Coefficients:
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Estimate Std. Error t value
Pr(>|t|)???
(Intercept)? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.60820? ? 0.13779???4.414 2.49e-05
***
Age? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.08836? ? 0.04189???2.109???0.0373
*
gender? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.10983? ? 0.17873???0.615???0.5402???
Victimization? ? ? ? ? ? ? ? ? ? ? ? ? 0.73270? ? 0.10776???6.799 6.82e-10
***
FamilySupport? ? ? ? ? ? ? ? ? ? ? ? 0.10213? ? 0.15979???0.639???0.5241???
Victimization:FamilySupport???-0.60146? ? 0.24532? -2.452???0.0159 *
---
Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for Negative Binomial(1.1303) family taken to be
0.4549082)

? ? Null deviance: 76.159? on 115? degrees of freedom
Residual deviance: 35.101? on 104? degrees of freedom
? (296 observations deleted due to missingness)
AIC: 480.6

Number of Fisher Scoring iterations: 15


Alternatively, if there is a simpler way to plot hurdle regression output, or if anyone is award of another means of estimating NB models (I haven't had much luck with vglm from VGAM either), I would be happy to hear about that as well. I'm currently using the "visreg"
package for plotting.

Thanks!
 
???
 
??? 


From adolfoyanes at gmail.com  Fri Aug 29 06:12:32 2014
From: adolfoyanes at gmail.com (Adolfo Yanes)
Date: Thu, 28 Aug 2014 23:42:32 -0430
Subject: [R] new error with QuantMod getSymbols
Message-ID: <CAGTCEXYbLBgA6aCQGTot-LF9g=BcijK7Ft9eyfEsL9GC0w4_eA@mail.gmail.com>

Hello,

I use getSymbols function daily to run some models with stock data. Today
when I tried to update the stock info i get this error

Error in charToDate(x) :
  character string is not in a standard unambiguous format

Sometimes I get it after 2 symbols, other times after 150 symbols, another
time after 40 symbols, then after 203 symbols.

The code for the symbol list is:

lista<-read.csv("lista.csv", header=FALSE)



lista.list.ana<-vector('list',nrow(lista))

names(lista.list.ana) <- lista[,1]

lista.sum<-as.vector(lista[,1])


##actualizar la lista

lista_simbolos<-download_symbols(lista.sum, lista.list.ana)



*The code for the function download_symbols is:*


download_symbols<- function(lista.sum.,lista.list.ana..){

  newnames.<- c("Open", "High", "Low", "Close", "Volume", "Adjusted")

for (m in 1:length(lista.sum.))


{

print(paste(c("Downloading symbol ", lista.sum.[m], ". ", length(lista.sum.
)-m, " symbols missing"), sep="", collapse=""))

temp<-get(loadSymbols(lista.sum.[m]))

names(temp)<-newnames.

#lista.list.ana..[[m]]<-loadSymbols(lista.sum.[m])

lista.list.ana..[[m]]<-temp

}

 return(lista.list.ana..)

}


Is it something wrong with yahoo? I tried google and got another error
Error in `colnames<-`(`*tmp*`, value = c("Open", "High", "Low", "Close",  :
  length of 'dimnames' [2] not equal to array extent

Thanks for your help


-- 
Adolfo Yanes Musetti

	[[alternative HTML version deleted]]


From my1stbox at 163.com  Fri Aug 29 08:47:02 2014
From: my1stbox at 163.com (my1stbox)
Date: Fri, 29 Aug 2014 14:47:02 +0800
Subject: [R] How should I do GO enrichment of differential expressed miRNA?
Message-ID: <62182dc9.4174.1482084d03c.Coremail.my1stbox@163.com>

Hi all,
First, I carried out GO enrichment to predicted/validated target genes of those miRNA using GOstats package. Then I find myself in a dead end. So what is the good practice? Is it possible to directly do GO enrichment to miRNAs? Are they included in GO database?
Regards,
Allen
	[[alternative HTML version deleted]]


From villarino.ernesto at gmail.com  Fri Aug 29 09:31:37 2014
From: villarino.ernesto at gmail.com (Ernesto Villarino)
Date: Fri, 29 Aug 2014 09:31:37 +0200
Subject: [R] dont remenber my password
Message-ID: <CAAmrVFofs=5MD9tby0j867UuqS6Odeh5V7619td12FvwfQPJgQ@mail.gmail.com>



	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Aug 29 10:44:29 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 29 Aug 2014 16:44:29 +0800 (CST)
Subject: [R] what 's meaning of setting options() through .onLoad() funtion
 in making a package?
Message-ID: <2d97679a.9ba2.14820eff584.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? ?I am now reading a book which teaching how to make ?a ?r package, i investigated from ?options but nothing said about in making a package. The help document only just introduce some option keys to me in some basic r packages.
? But i want to know, why need to ?set some options in make a r package, e.g.
? If i use options(a=3) in my package, what's usage of a ?


The following code is from Hadley wickham's book , i attach it for your better understanding my quesion:


.onLoad <- function(libname, pkgname) {
op <- options()
op.devtools <- list(
devtools.path = "~/R-dev",
devtools.install.args = "",
devtools.name = "Your name goes here",
devtools.desc.author = '"First Last <first.last at example.com> [aut, cre]"',
devtools.desc.license = "What license is it under?",
devtools.desc.suggests = NULL,
devtools.desc = list()
)
toset <- !(names(op.devtools) %in% names(op))
if(any(toset)) options(op.devtools[toset])
invisible()
}

--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From ashisdeb83 at gmail.com  Fri Aug 29 11:26:51 2014
From: ashisdeb83 at gmail.com (Ashis Deb)
Date: Fri, 29 Aug 2014 02:26:51 -0700
Subject: [R] HANDLER FUNCTION PROBLEM
Message-ID: <CAFcJUTrqvNm7R=Kf6sohoO+_Yg1rZ6vEopVFSxWWDvjU5CznhQ@mail.gmail.com>

Hello   ,



I  have  a  function  handler  using  gWidgets like  below   ,,  i  had
declared  a  function  inside  this   function   .   But  dont  have  the
idea  how   to  call   the  function  outside  the  handler   function.



 addHandlerClicked(AAS,handler=function(h,...)
  {

ga()                                    <<<  THIS  IS THE  FUNCTION  TO  BE
CALLED  OUTSIDE

{

}


})


ga()   <<---    WANTED  IT  OUTSIDE



  can  anyone  help  please

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Aug 29 13:13:35 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 29 Aug 2014 13:13:35 +0200
Subject: [R] Question regarding the discrepancy between count model
	parameter estimates between "pscl" and "MASS"
In-Reply-To: <1409284646.24415.YahooMailBasic@web142401.mail.bf1.yahoo.com>
References: <1409284646.24415.YahooMailBasic@web142401.mail.bf1.yahoo.com>
Message-ID: <91DBC08D-FD19-4CAF-A754-F18AF7AAE45A@gmail.com>

I'm no expert on hurdle models, but it seems that you are unaware that the negative binomial and the truncated negative binomial are quite different things.

-pd


On 29 Aug 2014, at 05:57 , Nick Livingston <nlivingston at ymail.com> wrote:

> I have sought consultation online and in person, to no avail. I hope someone
> on here might have some insight. Any feedback would be most welcome.
> 
> I am attempting to plot predicted values from a two-component hurdle model
> (logistic [suicide attempt yes/no] and negative binomial count [number of
> attempts thereafter]). To do so, I estimated each component separately using
> glm (MASS). While I am able to reproduce hurdle results for the logit
> portion in glm, estimates for the negative binomial count component are
> different.
> 
> Call:
> hurdle(formula = Suicide. ~ Age + gender + Victimization * FamilySupport |
> Age + gender + Victimization * FamilySupport, dist = "negbin", link =
> "logit")
> 
> Pearson residuals:
>     Min      1Q  Median      3Q     Max
> -0.9816 -0.5187 -0.4094  0.2974  5.8820
> 
> Count model coefficients (truncated negbin with log link):
>                                                 Estimate Std. Error z value
> Pr(>|z|)   
> (Intercept)                          -0.29150    0.33127  -0.880   0.3789   
> Age                                      0.17068    0.07556   2.259   0.0239
> *
> gender                                 0.28273    0.31614   0.894   0.3712   
> Victimization                         1.08405    0.18157   5.971 2.36e-09
> ***
> FamilySupport                      0.33629    0.29302   1.148   0.2511   
> Victimization:FamilySupport -0.96831    0.46841  -2.067   0.0387 *
> Log(theta)                            0.12245    0.54102   0.226   0.8209   
> Zero hurdle model coefficients (binomial with logit link):
>                                                  Estimate Std. Error z value
> Pr(>|z|)   
> (Intercept)                           -0.547051   0.215981  -2.533  0.01131
> *
> Age                                     -0.154493   0.063994  -2.414
> 0.01577 *
> gender                                 -0.030942   0.284868  -0.109  0.91350     
> Victimization                          1.073956   0.338015   3.177  0.00149
> **
> FamilySupport                       -0.380360   0.247530  -1.537  0.12439   
> Victimization\:FamilySupport  -0.813329   0.399905  -2.034  0.04197 *
> ---
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Theta: count = 1.1303
> Number of iterations in BFGS optimization: 23
> Log-likelihood: -374.3 on 25 Df
>> summary(logistic)
> 
> 
> 
> 
> Call:
> glm(formula = SuicideBinary ~ Age + gender = Victimization * FamilySupport,
> family = "binomial")
> 
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -1.9948  -0.8470  -0.6686   1.1160   2.0805
> 
> Coefficients:
>                                                  Estimate Std. Error z value
> Pr(>|z|)   
> (Intercept)                          -0.547051   0.215981  -2.533  0.01131 *
> Age                                    -0.154493   0.063994  -2.414  0.01577
> *
> gender                                -0.030942   0.284868  -0.109  0.91350   
> Victimization                         1.073956   0.338014   3.177  0.00149
> **
> FamilySupport                      -0.380360   0.247530  -1.537  0.12439   
> Victimization:FamilySupport  -0.813329   0.399904  -2.034  0.04197 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for binomial family taken to be 1)
> 
>     Null deviance: 452.54  on 359  degrees of freedom
> Residual deviance: 408.24  on 348  degrees of freedom
>   (52 observations deleted due to missingness)
> AIC: 432.24
> 
> Number of Fisher Scoring iterations: 4
> 
>> summary(Count1)
> 
> 
> 
> 
> 
> 
> Call:
> glm(formula = NegBinSuicide ~ Age + gender + Victimization * FamilySupport,
> family = negative.binomial(theta = 1.1303))
> 
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -1.6393  -0.4504  -0.1679   0.2350   2.1676
> 
> Coefficients:
>                                                 Estimate Std. Error t value
> Pr(>|t|)   
> (Intercept)                            0.60820    0.13779   4.414 2.49e-05
> ***
> Age                                      0.08836    0.04189   2.109   0.0373
> *
> gender                                  0.10983    0.17873   0.615   0.5402   
> Victimization                          0.73270    0.10776   6.799 6.82e-10
> ***
> FamilySupport                        0.10213    0.15979   0.639   0.5241   
> Victimization:FamilySupport   -0.60146    0.24532  -2.452   0.0159 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> (Dispersion parameter for Negative Binomial(1.1303) family taken to be
> 0.4549082)
> 
>     Null deviance: 76.159  on 115  degrees of freedom
> Residual deviance: 35.101  on 104  degrees of freedom
>   (296 observations deleted due to missingness)
> AIC: 480.6
> 
> Number of Fisher Scoring iterations: 15
> 
> 
> Alternatively, if there is a simpler way to plot hurdle regression output, or if anyone is award of another means of estimating NB models (I haven't had much luck with vglm from VGAM either), I would be happy to hear about that as well. I'm currently using the "visreg"
> package for plotting.
> 
> Thanks!
> 
>    
> 
>     
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Achim.Zeileis at uibk.ac.at  Fri Aug 29 13:26:00 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 29 Aug 2014 13:26:00 +0200 (CEST)
Subject: [R] Question regarding the discrepancy between count model
 parameter estimates between "pscl" and "MASS"
In-Reply-To: <91DBC08D-FD19-4CAF-A754-F18AF7AAE45A@gmail.com>
References: <1409284646.24415.YahooMailBasic@web142401.mail.bf1.yahoo.com>
	<91DBC08D-FD19-4CAF-A754-F18AF7AAE45A@gmail.com>
Message-ID: <alpine.DEB.2.11.1408291324490.6175@paninaro.uibk.ac.at>

On Fri, 29 Aug 2014, peter dalgaard wrote:

> I'm no expert on hurdle models, but it seems that you are unaware that 
> the negative binomial and the truncated negative binomial are quite 
> different things.

Yes. You can replicate the truncated count part of the hurdle model with 
the zerotrunc() function from the "countreg" package. The package is not 
yet on CRAN but can be easily installed from R-Forge.

> -pd
>
>
> On 29 Aug 2014, at 05:57 , Nick Livingston <nlivingston at ymail.com> wrote:
>
>> I have sought consultation online and in person, to no avail. I hope someone
>> on here might have some insight. Any feedback would be most welcome.
>>
>> I am attempting to plot predicted values from a two-component hurdle model
>> (logistic [suicide attempt yes/no] and negative binomial count [number of
>> attempts thereafter]). To do so, I estimated each component separately using
>> glm (MASS). While I am able to reproduce hurdle results for the logit
>> portion in glm, estimates for the negative binomial count component are
>> different.
>>
>> Call:
>> hurdle(formula = Suicide. ~ Age + gender + Victimization * FamilySupport |
>> Age + gender + Victimization * FamilySupport, dist = "negbin", link =
>> "logit")
>>
>> Pearson residuals:
>>     Min      1Q  Median      3Q     Max
>> -0.9816 -0.5187 -0.4094  0.2974  5.8820
>>
>> Count model coefficients (truncated negbin with log link):
>>                                                 Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept)                          -0.29150    0.33127  -0.880   0.3789
>> Age                                      0.17068    0.07556   2.259   0.0239
>> *
>> gender                                 0.28273    0.31614   0.894   0.3712
>> Victimization                         1.08405    0.18157   5.971 2.36e-09
>> ***
>> FamilySupport                      0.33629    0.29302   1.148   0.2511
>> Victimization:FamilySupport -0.96831    0.46841  -2.067   0.0387 *
>> Log(theta)                            0.12245    0.54102   0.226   0.8209
>> Zero hurdle model coefficients (binomial with logit link):
>>                                                  Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept)                           -0.547051   0.215981  -2.533  0.01131
>> *
>> Age                                     -0.154493   0.063994  -2.414
>> 0.01577 *
>> gender                                 -0.030942   0.284868  -0.109  0.91350
>> Victimization                          1.073956   0.338015   3.177  0.00149
>> **
>> FamilySupport                       -0.380360   0.247530  -1.537  0.12439
>> Victimization\:FamilySupport  -0.813329   0.399905  -2.034  0.04197 *
>> ---
>> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Theta: count = 1.1303
>> Number of iterations in BFGS optimization: 23
>> Log-likelihood: -374.3 on 25 Df
>>> summary(logistic)
>>
>>
>>
>>
>> Call:
>> glm(formula = SuicideBinary ~ Age + gender = Victimization * FamilySupport,
>> family = "binomial")
>>
>> Deviance Residuals:
>>     Min       1Q   Median       3Q      Max
>> -1.9948  -0.8470  -0.6686   1.1160   2.0805
>>
>> Coefficients:
>>                                                  Estimate Std. Error z value
>> Pr(>|z|)
>> (Intercept)                          -0.547051   0.215981  -2.533  0.01131 *
>> Age                                    -0.154493   0.063994  -2.414  0.01577
>> *
>> gender                                -0.030942   0.284868  -0.109  0.91350
>> Victimization                         1.073956   0.338014   3.177  0.00149
>> **
>> FamilySupport                      -0.380360   0.247530  -1.537  0.12439
>> Victimization:FamilySupport  -0.813329   0.399904  -2.034  0.04197 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> (Dispersion parameter for binomial family taken to be 1)
>>
>>     Null deviance: 452.54  on 359  degrees of freedom
>> Residual deviance: 408.24  on 348  degrees of freedom
>>   (52 observations deleted due to missingness)
>> AIC: 432.24
>>
>> Number of Fisher Scoring iterations: 4
>>
>>> summary(Count1)
>>
>>
>>
>>
>>
>>
>> Call:
>> glm(formula = NegBinSuicide ~ Age + gender + Victimization * FamilySupport,
>> family = negative.binomial(theta = 1.1303))
>>
>> Deviance Residuals:
>>     Min       1Q   Median       3Q      Max
>> -1.6393  -0.4504  -0.1679   0.2350   2.1676
>>
>> Coefficients:
>>                                                 Estimate Std. Error t value
>> Pr(>|t|)
>> (Intercept)                            0.60820    0.13779   4.414 2.49e-05
>> ***
>> Age                                      0.08836    0.04189   2.109   0.0373
>> *
>> gender                                  0.10983    0.17873   0.615   0.5402
>> Victimization                          0.73270    0.10776   6.799 6.82e-10
>> ***
>> FamilySupport                        0.10213    0.15979   0.639   0.5241
>> Victimization:FamilySupport   -0.60146    0.24532  -2.452   0.0159 *
>> ---
>> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>
>> (Dispersion parameter for Negative Binomial(1.1303) family taken to be
>> 0.4549082)
>>
>>     Null deviance: 76.159  on 115  degrees of freedom
>> Residual deviance: 35.101  on 104  degrees of freedom
>>   (296 observations deleted due to missingness)
>> AIC: 480.6
>>
>> Number of Fisher Scoring iterations: 15
>>
>>
>> Alternatively, if there is a simpler way to plot hurdle regression output, or if anyone is award of another means of estimating NB models (I haven't had much luck with vglm from VGAM either), I would be happy to hear about that as well. I'm currently using the "visreg"
>> package for plotting.
>>
>> Thanks!
>>
>>
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From angel.rodriguez at matiainstituto.net  Fri Aug 29 10:53:47 2014
From: angel.rodriguez at matiainstituto.net (Angel Rodriguez)
Date: Fri, 29 Aug 2014 10:53:47 +0200
Subject: [R] Unexpected behavior when giving a value to a new variable based
	on the value of another variable
Message-ID: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>


Dear subscribers,

I've found that if there is a variable in the dataframe with a name very similar to a new variable, R does not give the correct values to this latter variable based on the values of a third value:


> M <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58)),.Names = c("age"), row.names = c(NA, -9L), 
+                class = "data.frame")
> M$sample[M$age >= 65] <- 1 
> M
  age sample
1  67      1
2  62     NA
3  74      1
4  61     NA
5  60     NA
6  55     NA
7  60     NA
8  59     NA
9  58     NA
> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58), V2 = c(NA, 1, 1, 1, 1,1,1,1,NA)), 
+                     .Names = c("age","samplem"), row.names = c(NA, -9L), class = "data.frame")
> N$sample[N$age >= 65] <- 1 
> N
  age samplem sample
1  67      NA      1
2  62       1      1
3  74       1      1
4  61       1      1
5  60       1      1
6  55       1      1
7  60       1      1
8  59       1      1
9  58      NA     NA



Any clue for this behavior?



My specifications:

R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252    LC_MONETARY=Spanish_Spain.1252
[4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] foreign_0.8-61

loaded via a namespace (and not attached):
[1] tools_3.1.1




Thank you very much.

Angel Rodriguez-Laso
Research project manager
Matia Instituto Gerontologico


	[[alternative HTML version deleted]]


From vik at vlr.cc  Fri Aug 29 11:27:28 2014
From: vik at vlr.cc (Vik Rubenfeld)
Date: Fri, 29 Aug 2014 02:27:28 -0700
Subject: [R] Conjoint Package
Message-ID: <57197C3D-00D8-43BA-98F6-A5759865017E@vlr.cc>

I?m very glad to see the Conjoint Package for R. The documentation for it does not appear to specify methods for data acquisition. Are the cards to be individually scored by each respondent (most clients would rather see a choice-based methodology)?

SurveyGizmo, an excellent online survey host which I use, has in beta a Conjoint question type. However, it does not appear to calculate respondent-level utility values at this time. 

SurveyGizmo supports a conjoint question design in which each respondent is shown 3 cards at a time, and permitted to identify one of the three as Best, and one as Worst. (SG supports additional conjoint question designs as well).

Data acquired by SurveyGizmo conjoint looks like this for each respondent:

> Set #1
> Model Attribute	Model Value
> Price	$300
> Size	7"
> Memory	128 gb
> Score:	50
> 
> Set #2
> Model Attribute	Model Value
> Price	$100
> Size	4"
> Memory	16 gb
> Score:	0
> 
> Set #3
> Model Attribute	Model Value
> Price	$200
> Size	6"
> Memory	64 gb
> Score:	100
> 
> Set #4
> Model Attribute	Model Value
> Price	$100
> Size	5"
> Memory	32 gb
> Score:	100
> 
> Set #5
> Model Attribute	Model Value
> Price	$200
> Size	5"
> Memory	32 gb
> Score:	0

Score 100 = Best 
Score 50 = Not selected
Score 0 = Worst

Is it possible to use R-Project Conjoint Package with such a data file, to calculate respondent-level utility values?

Thanks very much in advance to all for any info!

Best,


-Vik

From ravi at websynergies.biz  Fri Aug 29 06:41:19 2014
From: ravi at websynergies.biz (Ravi Kumar Rupakula)
Date: Fri, 29 Aug 2014 04:41:19 +0000
Subject: [R] R-tool - OS compatibility help
Message-ID: <dbfec8d830054f6a953c3f07d8016e41@SINPR02MB073.apcprd02.prod.outlook.com>

Dear Support,

Please let us know Windows 2008R2 OS compatibility for "R" tool is available or not?
If available, please let us know the details.
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
RaviKumar Rupakula | HP: +65-98537306 | Email: ravi at websynergies.biz<mailto:ravi at websynergies.biz> | Web Synergies (S) Pte Ltd


	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Aug 29 14:45:52 2014
From: jholtman at gmail.com (jim holtman)
Date: Fri, 29 Aug 2014 08:45:52 -0400
Subject: [R] Unexpected behavior when giving a value to a new variable
 based on the value of another variable
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
Message-ID: <CAAxdm-5+nE_ioq+ykEdOvBVdmBvkFUBXoUvqBQVpf17UJB3gWw@mail.gmail.com>

You are being bitten by the "partial matching" of the "$" operator
(see  ?"$" for a better explanation).  Here is solution that works:


**original**
> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58), V2 = c(NA, 1, 1, 1, 1,1,1,1,NA)),
+                     .Names = c("age","samplem"), row.names = c(NA,
-9L), class = "data.frame")
> N$sample[N$age >= 65] <- 1
> N
  age samplem sample
1  67      NA      1
2  62       1      1
3  74       1      1
4  61       1      1
5  60       1      1
6  55       1      1
7  60       1      1
8  59       1      1
9  58      NA     NA
>
>
> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58), V2 = c(NA, 1, 1, 1, 1,1,1,1,NA)),
+                     .Names = c("age","samplem"), row.names = c(NA,
-9L), class = "data.frame")
> N[["sample"]][N$age >= 65] <- 1  # use the '[[' operation for complete matching
> N
  age samplem sample
1  67      NA      1
2  62       1     NA
3  74       1      1
4  61       1     NA
5  60       1     NA
6  55       1     NA
7  60       1     NA
8  59       1     NA
9  58      NA     NA

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Aug 29, 2014 at 4:53 AM, Angel Rodriguez
<angel.rodriguez at matiainstituto.net> wrote:
>
> Dear subscribers,
>
> I've found that if there is a variable in the dataframe with a name very similar to a new variable, R does not give the correct values to this latter variable based on the values of a third value:
>
>
>> M <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58)),.Names = c("age"), row.names = c(NA, -9L),
> +                class = "data.frame")
>> M$sample[M$age >= 65] <- 1
>> M
>   age sample
> 1  67      1
> 2  62     NA
> 3  74      1
> 4  61     NA
> 5  60     NA
> 6  55     NA
> 7  60     NA
> 8  59     NA
> 9  58     NA
>> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58), V2 = c(NA, 1, 1, 1, 1,1,1,1,NA)),
> +                     .Names = c("age","samplem"), row.names = c(NA, -9L), class = "data.frame")
>> N$sample[N$age >= 65] <- 1
>> N
>   age samplem sample
> 1  67      NA      1
> 2  62       1      1
> 3  74       1      1
> 4  61       1      1
> 5  60       1      1
> 6  55       1      1
> 7  60       1      1
> 8  59       1      1
> 9  58      NA     NA
>
>
>
> Any clue for this behavior?
>
>
>
> My specifications:
>
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252    LC_MONETARY=Spanish_Spain.1252
> [4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] foreign_0.8-61
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
>
>
>
>
> Thank you very much.
>
> Angel Rodriguez-Laso
> Research project manager
> Matia Instituto Gerontologico
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Fri Aug 29 14:46:35 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 29 Aug 2014 07:46:35 -0500
Subject: [R] Unexpected behavior when giving a value to a new variable
 based on the value of another variable
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
Message-ID: <CAAJSdjhPM_=A4Hs3E=Tr9C_iOdfj5pMCJCgjq0Z5FK8RmNBVcw@mail.gmail.com>

On Fri, Aug 29, 2014 at 3:53 AM, Angel Rodriguez
<angel.rodriguez at matiainstituto.net> wrote:
>
> Dear subscribers,
>
> I've found that if there is a variable in the dataframe with a name very similar to a new variable, R does not give the correct values to this latter variable based on the values of a third value:
>
>
<snip>
>
> Any clue for this behavior?
>
<snip>
>
> Thank you very much.
>
> Angel Rodriguez-Laso
> Research project manager
> Matia Instituto Gerontologico

That is unusual, but appears to be documented in a section from

?`[`

<quote>
Character indices

Character indices can in some circumstances be partially matched (see
pmatch) to the names or dimnames of the object being subsetted (but
never for subassignment). Unlike S (Becker et al p. 358)), R never
uses partial matching when extracting by [, and partial matching is
not by default used by [[ (see argument exact).

Thus the default behaviour is to use partial matching only when
extracting from recursive objects (except environments) by $. Even in
that case, warnings can be switched on by
options(warnPartialMatchDollar = TRUE).

Neither empty ("") nor NA indices match any names, not even empty nor
missing names. If any object has no names or appropriate dimnames,
they are taken as all "" and so match nothing.
</quote>

Note the commend about "partial matching" in the middle paragraph in
the quote above.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From jdnewmil at dcn.davis.CA.us  Fri Aug 29 15:33:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 29 Aug 2014 06:33:01 -0700
Subject: [R] Unexpected behavior when giving a value to a new variable
	based	on the value of another variable
In-Reply-To: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>
Message-ID: <c5647c24-15fa-4f14-8f68-02f7eeda5924@email.android.com>

One clue is the help file for "$"...

?" $"

In particular there see the discussion of character indices and the "exact" argument.

You can also find this discussed in the Introduction to R document that comes with the software.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On August 29, 2014 1:53:47 AM PDT, Angel Rodriguez <angel.rodriguez at matiainstituto.net> wrote:
>
>Dear subscribers,
>
>I've found that if there is a variable in the dataframe with a name
>very similar to a new variable, R does not give the correct values to
>this latter variable based on the values of a third value:
>
>
>> M <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59,
>58)),.Names = c("age"), row.names = c(NA, -9L), 
>+                class = "data.frame")
>> M$sample[M$age >= 65] <- 1 
>> M
>  age sample
>1  67      1
>2  62     NA
>3  74      1
>4  61     NA
>5  60     NA
>6  55     NA
>7  60     NA
>8  59     NA
>9  58     NA
>> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58), V2 =
>c(NA, 1, 1, 1, 1,1,1,1,NA)), 
>+                     .Names = c("age","samplem"), row.names = c(NA,
>-9L), class = "data.frame")
>> N$sample[N$age >= 65] <- 1 
>> N
>  age samplem sample
>1  67      NA      1
>2  62       1      1
>3  74       1      1
>4  61       1      1
>5  60       1      1
>6  55       1      1
>7  60       1      1
>8  59       1      1
>9  58      NA     NA
>
>
>
>Any clue for this behavior?
>
>
>
>My specifications:
>
>R version 3.1.1 (2014-07-10)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>locale:
>[1] LC_COLLATE=Spanish_Spain.1252  LC_CTYPE=Spanish_Spain.1252   
>LC_MONETARY=Spanish_Spain.1252
>[4] LC_NUMERIC=C                   LC_TIME=Spanish_Spain.1252    
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base   
> 
>
>other attached packages:
>[1] foreign_0.8-61
>
>loaded via a namespace (and not attached):
>[1] tools_3.1.1
>
>
>
>
>Thank you very much.
>
>Angel Rodriguez-Laso
>Research project manager
>Matia Instituto Gerontologico
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mtmorgan at fhcrc.org  Fri Aug 29 15:55:42 2014
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Fri, 29 Aug 2014 06:55:42 -0700
Subject: [R] How should I do GO enrichment of differential expressed
	miRNA?
In-Reply-To: <62182dc9.4174.1482084d03c.Coremail.my1stbox@163.com>
References: <62182dc9.4174.1482084d03c.Coremail.my1stbox@163.com>
Message-ID: <5400865E.2040201@fhcrc.org>

On 08/28/2014 11:47 PM, my1stbox wrote:
> Hi all,
> First, I carried out GO enrichment to predicted/validated target genes of those miRNA using GOstats package. Then I find myself in a dead end. So what is the good practice? Is it possible to directly do GO enrichment to miRNAs? Are they included in GO database?

The Bioconductor mailing list

   http://bioconductor.org/help/mailing-list/mailform/

is a more appropriate forum for discussion of Bioconductor packages (like 
topGO). It's better to be more specific about what your question / problem is; 
'dead end' might mean that you had technical problems, or that you managed to 
get results but that they were unsatisfactory for some specific reason, or...

Martin

> Regards,
> Allen
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From gunter.berton at gene.com  Fri Aug 29 16:32:44 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 29 Aug 2014 07:32:44 -0700
Subject: [R] HANDLER FUNCTION PROBLEM
In-Reply-To: <CAFcJUTrqvNm7R=Kf6sohoO+_Yg1rZ6vEopVFSxWWDvjU5CznhQ@mail.gmail.com>
References: <CAFcJUTrqvNm7R=Kf6sohoO+_Yg1rZ6vEopVFSxWWDvjU5CznhQ@mail.gmail.com>
Message-ID: <CACk-te2ARU1_UK9+uqnnfN2EKDU1-ywhv7hwfcqa+g7EYh0wFQ@mail.gmail.com>

1, Please post in plain text, not HTML, as requested by the posting guide.

2. R is not C, You define, not declare, functions, whose scope and
availability are then determined appropriately. Where is ga() defined?

3. Have you read an Introduction to R or other R tutorial? If not, do
so before posting further. You need to do due diligence before
requesting help.

4. If you have, read the R Language Definition Ref for details of how
scoping in R is determined. R is a functional type language (like LISP
or Scheme)

5. Functions are fully first class objects and can be returned by
other functions.

Cheers,

Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Fri, Aug 29, 2014 at 2:26 AM, Ashis Deb <ashisdeb83 at gmail.com> wrote:
> Hello   ,
>
>
>
> I  have  a  function  handler  using  gWidgets like  below   ,,  i  had
> declared  a  function  inside  this   function   .   But  dont  have  the
> idea  how   to  call   the  function  outside  the  handler   function.
>
>
>
>  addHandlerClicked(AAS,handler=function(h,...)
>   {
>
> ga()                                    <<<  THIS  IS THE  FUNCTION  TO  BE
> CALLED  OUTSIDE
>
> {
>
> }
>
>
> })
>
>
> ga()   <<---    WANTED  IT  OUTSIDE
>
>
>
>   can  anyone  help  please
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From clfiore at gmail.com  Fri Aug 29 16:45:50 2014
From: clfiore at gmail.com (Cara Fiore)
Date: Fri, 29 Aug 2014 10:45:50 -0400
Subject: [R] distance matrix from metaMDS
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F937F4@mb02.ads.tamu.edu>
References: <CAEjKTpaNf1=884s+7KqCJ+cK9AmnV8qPLVDz2TOScipzy1=cwg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F937F4@mb02.ads.tamu.edu>
Message-ID: <CAEjKTpbifhD6VDqvZxcV_K=t7TCBxx5nZUFm=mBbgtK2_QKi3A@mail.gmail.com>

Yes I looked at this and I tried metaMDSdist but got an error and for some
reason I didn't try metaMDSredist which seems to be the right thing. So the
main thing I was confused about was what to call dist() on -i.e., getting
the correct ordinal distance, and then if I assume that the NMDS scores are
the coordinates, which I believe they are, then how do I call dist() on one
column? But, I just found the answer in a translation from matlab to R -
you have to use drop=FALSE (and hopefully I am calling dist() on the right
thing)

euc.dist.axis1=dist(NMDS2[,1, drop=FALSE], method="euclidean")


Maybe this is obvious to other folks but just in case there is anyone like
me out there I figured I'd write back. Thanks for the info I have never
written to this list before because I always found what I needed online. I
appreciate your help and patience.


Cara



On Thu, Aug 28, 2014 at 10:19 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Don't the functions metaMDSdist() and metaMDSredist() that are documented
> on the metaMDS manual page give you the distance matrix? If you want to
> compute the distances based on a single axis, you could use vegdist().
>
> David C
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Cara Fiore
> Sent: Thursday, August 28, 2014 7:02 PM
> To: r-help at r-project.org
> Subject: [R] distance matrix from metaMDS
>
> Dear R users,
>
> I would like to access the distance matrix generated by metaMDS as well as
> use the dist function to calculate the euclidean distance for each axis in
> the NMDS. I am having trouble finding a way to access these variables and
> any help is greatly appreciated.
>
> For the distance matrix I know I could just calculate the bray-curtis
> distance but it would be nice to know how to get it from the NMDS function.
> For the euclidean distance, the only thing I can find within metaMDS is
> the score function but there must be some way for me to call on/access the
> ordination distance for one axis right?
>
> The reason for this is I would like to do something like the stressplot
> function but for each axis.
>
> Thank you,
> Cara
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Fri Aug 29 16:54:22 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 29 Aug 2014 14:54:22 +0000
Subject: [R] dont remenber my password
In-Reply-To: <CAAmrVFofs=5MD9tby0j867UuqS6Odeh5V7619td12FvwfQPJgQ@mail.gmail.com>
References: <CAAmrVFofs=5MD9tby0j867UuqS6Odeh5V7619td12FvwfQPJgQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE0164@SRVEXCHMBX.precheza.cz>

That is bad, especially if it is password to your bank account. Maybe you shall write it down somewhere next time.

Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ernesto Villarino
> Sent: Friday, August 29, 2014 9:32 AM
> To: r-help at r-project.org
> Subject: [R] dont remenber my password
>
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From emmanuel.blondel1 at gmail.com  Thu Aug 28 18:06:49 2014
From: emmanuel.blondel1 at gmail.com (Emmanuel Blondel)
Date: Thu, 28 Aug 2014 18:06:49 +0200
Subject: [R] [R-pkgs] rsdmx - a package to read SDMX data and metadata
Message-ID: <53FF5399.6060209@gmail.com>

Dear all,

The rsdmx package has been published in CRAN 
http://cran.r-project.org/web/packages/rsdmx/index.html.
rsdmx allows to read SDMX (Statistical Data and Metadata EXchange) data 
and metadata files, available in SDMX-ML format (XML).

For your information, its source code is managed at the following 
repository https://github.com/opensdmx/rsdmx

The current version is 0.3, and a change history is available at: 
https://github.com/opensdmx/rsdmx/wiki/Change-History. I also recommend 
to check out the rsdmx wiki page available at: 
https://github.com/opensdmx/rsdmx/wiki

I sincerely hope you will enjoy working with rsdmx. Feel free to contact 
me for questions or other feedback,

Emmanuel

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dwinsemius at comcast.net  Fri Aug 29 18:00:46 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 Aug 2014 09:00:46 -0700
Subject: [R] dont remenber my password
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE0164@SRVEXCHMBX.precheza.cz>
References: <CAAmrVFofs=5MD9tby0j867UuqS6Odeh5V7619td12FvwfQPJgQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE0164@SRVEXCHMBX.precheza.cz>
Message-ID: <EEB1FF30-1F9D-44F3-9DCB-09926BBEFF5B@comcast.net>

Your password is sent via email every month or so. 

-- 

David

On Aug 29, 2014, at 7:54 AM, PIKAL Petr wrote:

> That is bad, especially if it is password to your bank account. Maybe you shall write it down somewhere next time.
> 
> Petr
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Ernesto Villarino
>> Sent: Friday, August 29, 2014 9:32 AM
>> To: r-help at r-project.org
>> Subject: [R] dont remenber my password
>> 
>> 
>> 
snip

David Winsemius
Alameda, CA, USA


From francisco.goes at celpa.pt  Fri Aug 29 16:11:30 2014
From: francisco.goes at celpa.pt (Francisco Goes)
Date: Fri, 29 Aug 2014 15:11:30 +0100
Subject: [R] nlsystemfit help
Message-ID: <!&!AAAAAAAAAAAYAAAAAAAAAEYGiRTpmBBFhYuEmNXtV4rCgAAAEAAAAIXHx5txlaZHv31S9D7vuhIBAAAAAA==@celpa.pt>

Hello,

 

For my master thesis I have fitted an individual tree diameter growth model
and a survival probability model separately using R, but I was told that
simultaneous estimation of these two models would minimize overall errors
and provide a variance-covariance matrix as a whole.

 

In that respect, can you please tell me if I can do it with nlssystemfit
using SUR (seemingly unrelated regression) method? If not, do you know how
can I do it in R?

 

My equations are:

 

-         tree diameter growth model

 

d_richards_k<-d2~A*(1-exp(-(k0+k1*puro+k2*GL1/100+k3*1/G1+k4*Tmedmax/100+k5*
Perc_G_ec1))*(1-(d1/A)^(1-m)))^(1/(1-m))

nls_d_richards_k<-nlsLM(d_richards_k,start=list(A=100,k0=0.6,k1=0,k2=0,k3=0,
k4=0,k5=0,m=0.6),control=nls.lm.control(maxiter=500))

 

-         survival probability model

 

mortal_final<-glm(sobrev~Verao+alto_fuste:puro+IC1arv+G1+Perc_G_ec1,family=b
inomial)

 

Thank you!

 

Best regards,

 

Francisco Goes


	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Fri Aug 29 18:18:58 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Aug 2014 17:18:58 +0100
Subject: [R] dont remenber my password
In-Reply-To: <EEB1FF30-1F9D-44F3-9DCB-09926BBEFF5B@comcast.net>
References: <CAAmrVFofs=5MD9tby0j867UuqS6Odeh5V7619td12FvwfQPJgQ@mail.gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE0164@SRVEXCHMBX.precheza.cz>
	<EEB1FF30-1F9D-44F3-9DCB-09926BBEFF5B@comcast.net>
Message-ID: <5400A7F2.3090908@stats.ox.ac.uk>

On 29/08/2014 17:00, David Winsemius wrote:
> Your password is sent via email every month or so.
>
And sending by email can be requested from 
https://stat.ethz.ch/mailman/listinfo/r-help, at least if you know the 
email address which you used to subscribe (otherwise look in the headers 
of messages sent from R-help).

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From msharp at txbiomed.org  Fri Aug 29 19:28:10 2014
From: msharp at txbiomed.org (Mark Sharp)
Date: Fri, 29 Aug 2014 12:28:10 -0500
Subject: [R] R-tool - OS compatibility help
In-Reply-To: <dbfec8d830054f6a953c3f07d8016e41@SINPR02MB073.apcprd02.prod.outlook.com>
References: <dbfec8d830054f6a953c3f07d8016e41@SINPR02MB073.apcprd02.prod.outlook.com>
Message-ID: <30406789-180B-4F0A-B21B-E9A96254CEAF@TxBiomed.org>

See
http://cran.r-project.org/
On Aug 28, 2014, at 11:41 PM, Ravi Kumar Rupakula wrote:

> Dear Support,
>
> Please let us know Windows 2008R2 OS compatibility for "R" tool is available or not?
> If available, please let us know the details.
> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
> RaviKumar Rupakula | HP: +65-98537306 | Email: ravi at websynergies.biz<mailto:ravi at websynergies.biz> | Web Synergies (S) Pte Ltd
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.


From erinm.hodgess at gmail.com  Fri Aug 29 19:49:03 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 29 Aug 2014 13:49:03 -0400
Subject: [R]  environment question
Message-ID: <CACxE24mqKPJyoPxvjjCicM7Xw0y+9L0SkBWazbvczNnK=05ywA@mail.gmail.com>

Hello!

Here is yet another question which I strongly suspect has a simple answer.

I build an RcmdrPlugin package and saved my workspace when I came out of R.

For some reason, it save the namespace of the plugin as an environment.

When I load the workspace back in, 2 environments appear,

<environment namespace: RcmdrPlugin.gstats>

and the regular global environment.

How do I remove the plugin environment from my workspace, please?

I've tried:
rm(namespace: RcmdrPlugin.gstats)
rm("namespace: RcmdrPlugin.gstats")
rm(RcmdrPlugin.gstats)
rm("RcmdrPlugin.gstats")

all to no avail.

Any help would be much appreciated.

sincerely,
Erin



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Fri Aug 29 19:50:36 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Aug 2014 18:50:36 +0100
Subject: [R] R-tool - OS compatibility help
In-Reply-To: <30406789-180B-4F0A-B21B-E9A96254CEAF@TxBiomed.org>
References: <dbfec8d830054f6a953c3f07d8016e41@SINPR02MB073.apcprd02.prod.outlook.com>
	<30406789-180B-4F0A-B21B-E9A96254CEAF@TxBiomed.org>
Message-ID: <5400BD6C.3060703@stats.ox.ac.uk>

On 29/08/2014 18:28, Mark Sharp wrote:
> See
> http://cran.r-project.org/

Specifically, 
http://cran.r-project.org/bin/windows/base/rw-FAQ.html#Installation-and-Usage 
mentions Windows 2008.

The posting guide (see the footer of this message) asks you to look at 
the FAQs before posting.

> On Aug 28, 2014, at 11:41 PM, Ravi Kumar Rupakula wrote:
>
>> Dear Support,
>>
>> Please let us know Windows 2008R2 OS compatibility for "R" tool is available or not?
>> If available, please let us know the details.
>> --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>> RaviKumar Rupakula | HP: +65-98537306 | Email: ravi at websynergies.biz<mailto:ravi at websynergies.biz> | Web Synergies (S) Pte Ltd
>>
>>
>>        [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> NOTICE:  This E-Mail (including attachments) is confidential and may be legally privileged.  It is covered by the Electronic Communications Privacy Act, 18 U.S.C.2510-2521.  If you are not the intended recipient, you are hereby notified that any retention, dissemination, distribution or copying of this communication is strictly prohibited.  Please reply to the sender that you have received this message in error, then delete it.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From vik at vlr.cc  Fri Aug 29 18:30:52 2014
From: vik at vlr.cc (Vik Rubenfeld)
Date: Fri, 29 Aug 2014 09:30:52 -0700
Subject: [R] Conjoint Package
Message-ID: <D2D607C5-5F0C-483C-BC25-103C4DC1AEC8@vlr.cc>

I?m very glad to see the Conjoint Package for R. The documentation for it does not appear to specify methods for data acquisition. Are the cards to be individually scored by each respondent (most clients would rather see a choice-based methodology)?

SurveyGizmo, an excellent online survey host which I use, has in beta a Conjoint question type. However, it does not appear to calculate respondent-level utility values at this time. 

SurveyGizmo supports a conjoint question design in which each respondent is shown 3 cards at a time, and permitted to identify one of the three as Best, and one as Worst. (SG supports additional conjoint question designs as well).

Data acquired by SurveyGizmo conjoint looks like this for each respondent:

> Set #1
> Model Attribute	Model Value
> Price	$300
> Size	7"
> Memory	128 gb
> Score:	50
> 
> Set #2
> Model Attribute	Model Value
> Price	$100
> Size	4"
> Memory	16 gb
> Score:	0
> 
> Set #3
> Model Attribute	Model Value
> Price	$200
> Size	6"
> Memory	64 gb
> Score:	100
> 
> Set #4
> Model Attribute	Model Value
> Price	$100
> Size	5"
> Memory	32 gb
> Score:	100
> 
> Set #5
> Model Attribute	Model Value
> Price	$200
> Size	5"
> Memory	32 gb
> Score:	0

Score 100 = Best 
Score 50 = Not selected
Score 0 = Worst

Is it possible to use the R-Project Conjoint Package with a data file like this, to calculate respondent-level utility values? In other words, are the scores (100, 50, 0) input that the Conjoint Package can use?

Thanks very much in advance to all for any info!

Best,


-Vik

From nlivingston at ymail.com  Fri Aug 29 18:46:36 2014
From: nlivingston at ymail.com (Nick Livingston)
Date: Fri, 29 Aug 2014 09:46:36 -0700
Subject: [R] Question regarding the discrepancy between count model
	parameter estimates between "pscl" and "MASS"
Message-ID: <1409330796.89710.YahooMailBasic@web142406.mail.bf1.yahoo.com>

Thank you for your responses. 

Since my previous attempt to manually truncate my DV didn't work, I'm very interested in trying again using the zerotrun() function. However, I attempted to install "countreg" but received the following notification:

? ? ? ? Warning in install.packages :
? ? ? ? ? ? ? unable to access index for repository http://R-Forge.R-project.org/bin/macosx/contrib/3.0

? ? ? ? ? ? ? package ?countreg? is available as a source package but not as a binary
 
? ? ? ???Warning in install.packages :
? ? ? ? ? ? ? package ?countreg? is not available (for R version 3.0.3)

I received the same message when attempting to install it in version 3.1.0, and the latest version, 3.1.1. Am I missing something?

Thank you again. I appreciate your input.

-Nick
--------------------------------------------
On Fri, 8/29/14, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:

 Subject: Re: [R] Question regarding the discrepancy between count model parameter estimates between "pscl" and "MASS"
 To: "peter dalgaard" <pdalgd at gmail.com>
 Cc: "Nick Livingston" <nlivingston at ymail.com>, r-help at r-project.org
 Date: Friday, August 29, 2014, 5:26 AM

 On Fri, 29 Aug 2014,
 peter dalgaard wrote:

 >
 I'm no expert on hurdle models, but it seems that you
 are unaware that 
 > the negative binomial
 and the truncated negative binomial are quite 
 > different things.

 Yes. You can replicate the truncated count part
 of the hurdle model with 
 the zerotrunc()
 function from the "countreg" package. The package
 is not 
 yet on CRAN but can be easily
 installed from R-Forge.

 > -pd
 >
 >
 > On 29 Aug 2014, at
 05:57 , Nick Livingston <nlivingston at ymail.com>
 wrote:
 >
 >> I have
 sought consultation online and in person, to no avail. I
 hope someone
 >> on here might have
 some insight. Any feedback would be most welcome.
 >>
 >> I am
 attempting to plot predicted values from a two-component
 hurdle model
 >> (logistic [suicide
 attempt yes/no] and negative binomial count [number of
 >> attempts thereafter]). To do so, I
 estimated each component separately using
 >> glm (MASS). While I am able to
 reproduce hurdle results for the logit
 >> portion in glm, estimates for the
 negative binomial count component are
 >> different.
 >>
 >> Call:
 >>
 hurdle(formula = Suicide. ~ Age + gender + Victimization *
 FamilySupport |
 >> Age + gender +
 Victimization * FamilySupport, dist = "negbin",
 link =
 >> "logit")
 >>
 >> Pearson
 residuals:
 >>? ???Min? ?
 ? 1Q? Median? ? ? 3Q? ???Max
 >> -0.9816 -0.5187 -0.4094? 0.2974?
 5.8820
 >>
 >>
 Count model coefficients (truncated negbin with log
 link):
 >>? ? ? ? ? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???Estimate Std. Error z value
 >> Pr(>|z|)
 >>
 (Intercept)? ? ? ? ? ? ? ? ? ? ? ? ? -0.29150?
 ? 0.33127? -0.880???0.3789
 >> Age? ? ? ? ? ? ? ? ? ? ? ?
 ? ? ? ? ? ? ? 0.17068? ?
 0.07556???2.259???0.0239
 >> *
 >> gender? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???0.28273? ?
 0.31614???0.894???0.3712
 >> Victimization? ? ? ? ? ? ? ?
 ? ? ? ???1.08405? ?
 0.18157???5.971 2.36e-09
 >>
 ***
 >> FamilySupport? ? ? ? ? ?
 ? ? ? ? ? 0.33629? ?
 0.29302???1.148???0.2511
 >> Victimization:FamilySupport -0.96831?
 ? 0.46841? -2.067???0.0387 *
 >> Log(theta)? ? ? ? ? ? ? ? ?
 ? ? ? ? ? 0.12245? ?
 0.54102???0.226???0.8209
 >> Zero hurdle model coefficients
 (binomial with logit link):
 >>? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ? ? Estimate Std. Error z value
 >>
 Pr(>|z|)
 >> (Intercept)? ? ? ?
 ? ? ? ? ? ? ? ?
 ???-0.547051???0.215981? -2.533?
 0.01131
 >> *
 >>
 Age? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???-0.154493???0.063994? -2.414
 >> 0.01577 *
 >>
 gender? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???-0.030942???0.284868? -0.109?
 0.91350
 >> Victimization? ? ? ? ?
 ? ? ? ? ? ? ? ?
 1.073956???0.338015???3.177?
 0.00149
 >> **
 >>
 FamilySupport? ? ? ? ? ? ? ? ? ?
 ???-0.380360???0.247530? -1.537?
 0.12439
 >>
 Victimization\:FamilySupport?
 -0.813329???0.399905? -2.034? 0.04197 *
 >> ---
 >> Signif.
 codes:? 0 '***' 0.001 '**' 0.01 '*'
 0.05 '.' 0.1 ' ' 1
 >>
 >> Theta: count
 = 1.1303
 >> Number of iterations in
 BFGS optimization: 23
 >>
 Log-likelihood: -374.3 on 25 Df
 >>>
 summary(logistic)
 >>
 >>
 >>
 >>
 >> Call:
 >> glm(formula = SuicideBinary ~ Age +
 gender = Victimization * FamilySupport,
 >> family = "binomial")
 >>
 >> Deviance
 Residuals:
 >>? ???Min? ?
 ???1Q???Median? ? ???3Q?
 ? ? Max
 >> -1.9948? -0.8470?
 -0.6686???1.1160???2.0805
 >>
 >>
 Coefficients:
 >>? ? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 Estimate Std. Error z value
 >>
 Pr(>|z|)
 >> (Intercept)? ? ? ?
 ? ? ? ? ? ? ? ? ? -0.547051???0.215981?
 -2.533? 0.01131 *
 >> Age? ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 -0.154493???0.063994? -2.414? 0.01577
 >> *
 >> gender? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 -0.030942???0.284868? -0.109? 0.91350
 >> Victimization? ? ? ? ? ? ? ?
 ? ? ?
 ???1.073956???0.338014???3.177?
 0.00149
 >> **
 >>
 FamilySupport? ? ? ? ? ? ? ? ? ? ?
 -0.380360???0.247530? -1.537? 0.12439
 >> Victimization:FamilySupport?
 -0.813329???0.399904? -2.034? 0.04197 *
 >> ---
 >> Signif.
 codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 >>
 >> (Dispersion
 parameter for binomial family taken to be 1)
 >>
 >>?
 ???Null deviance: 452.54? on 359? degrees of
 freedom
 >> Residual deviance: 408.24?
 on 348? degrees of freedom
 >>???(52 observations deleted
 due to missingness)
 >> AIC: 432.24
 >>
 >> Number of
 Fisher Scoring iterations: 4
 >>
 >>> summary(Count1)
 >>
 >>
 >>
 >>
 >>
 >>
 >> Call:
 >>
 glm(formula = NegBinSuicide ~ Age + gender + Victimization *
 FamilySupport,
 >> family =
 negative.binomial(theta = 1.1303))
 >>
 >> Deviance
 Residuals:
 >>? ???Min? ?
 ???1Q???Median? ? ???3Q?
 ? ? Max
 >> -1.6393? -0.4504?
 -0.1679???0.2350???2.1676
 >>
 >>
 Coefficients:
 >>? ? ? ? ? ? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
 ???Estimate Std. Error t value
 >> Pr(>|t|)
 >>
 (Intercept)? ? ? ? ? ? ? ? ? ? ? ? ? ?
 0.60820? ? 0.13779???4.414 2.49e-05
 >> ***
 >> Age? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.08836?
 ? 0.04189???2.109???0.0373
 >> *
 >> gender? ?
 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 0.10983? ?
 0.17873???0.615???0.5402
 >> Victimization? ? ? ? ? ? ? ?
 ? ? ? ? ? 0.73270? ? 0.10776???6.799
 6.82e-10
 >> ***
 >> FamilySupport? ? ? ? ? ? ? ?
 ? ? ? ? 0.10213? ?
 0.15979???0.639???0.5241
 >>
 Victimization:FamilySupport???-0.60146? ?
 0.24532? -2.452???0.0159 *
 >> ---
 >> Signif.
 codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
 >>
 >> (Dispersion
 parameter for Negative Binomial(1.1303) family taken to
 be
 >> 0.4549082)
 >>
 >>?
 ???Null deviance: 76.159? on 115? degrees of
 freedom
 >> Residual deviance: 35.101?
 on 104? degrees of freedom
 >>???(296 observations deleted
 due to missingness)
 >> AIC: 480.6
 >>
 >> Number of
 Fisher Scoring iterations: 15
 >>
 >>
 >>
 Alternatively, if there is a simpler way to plot hurdle
 regression output, or if anyone is award of another means of
 estimating NB models (I haven't had much luck with vglm
 from VGAM either), I would be happy to hear about that as
 well. I'm currently using the "visreg"
 >> package for plotting.
 >>
 >> Thanks!
 >>
 >>
 >>
 >>
 >>
 >>
 ______________________________________________
 >> R-help at r-project.org
 mailing list
 >> https://stat.ethz.ch/mailman/listinfo/r-help
 >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 >> and provide commented, minimal,
 self-contained, reproducible code.
 >
 > -- 
 > Peter Dalgaard,
 Professor,
 > Center for Statistics,
 Copenhagen Business School
 > Solbjerg
 Plads 3, 2000 Frederiksberg, Denmark
 >
 Phone: (+45)38153501
 > Email: pd.mes at cbs.dk? Priv:
 PDalgd at gmail.com
 >
 >
 ______________________________________________
 > R-help at r-project.org
 mailing list
 > https://stat.ethz.ch/mailman/listinfo/r-help
 > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 > and provide commented, minimal,
 self-contained, reproducible code.
 >


From dwinsemius at comcast.net  Fri Aug 29 20:36:07 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 29 Aug 2014 11:36:07 -0700
Subject: [R] Question regarding the discrepancy between count model
	parameter estimates between "pscl" and "MASS"
In-Reply-To: <1409330796.89710.YahooMailBasic@web142406.mail.bf1.yahoo.com>
References: <1409330796.89710.YahooMailBasic@web142406.mail.bf1.yahoo.com>
Message-ID: <410AC696-D41A-4EBA-B095-0D13116C3CEF@comcast.net>


On Aug 29, 2014, at 9:46 AM, Nick Livingston wrote:

> Thank you for your responses. 
> 
> Since my previous attempt to manually truncate my DV didn't work, I'm very interested in trying again using the zerotrun() function. However, I attempted to install "countreg" but received the following notification:
> 
>         Warning in install.packages :
>               unable to access index for repository http://R-Forge.R-project.org/bin/macosx/contrib/3.0
> 
>               package ?countreg? is available as a source package but not as a binary
> 
>          Warning in install.packages :
>               package ?countreg? is not available (for R version 3.0.3)
> 
> I received the same message when attempting to install it in version 3.1.0, and the latest version, 3.1.1. Am I missing something?

Apparently understanding that R-forge is not CRAN.  If the package has any compiled code, then you need to have the proper tools installed. See the R-Mac-FAQ if those are needed. I generally download the source file and install from disk. 

install.packages("~/countreg_0.1-1.tar.gz", repo=NULL, type="source")

(That reported success on a SL Mac R 3.1.0 machine. And there did not appear to be any compiled code so the Mac "tool chain" was not needed. The other way to check for that possibility is to look at the DESCRIPTION file.)

-- 
David.

> 
> Thank you again. I appreciate your input.
> 
> -Nick
> --------------------------------------------
> On Fri, 8/29/14, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
> 
> Subject: Re: [R] Question regarding the discrepancy between count model parameter estimates between "pscl" and "MASS"
> To: "peter dalgaard" <pdalgd at gmail.com>
> Cc: "Nick Livingston" <nlivingston at ymail.com>, r-help at r-project.org
> Date: Friday, August 29, 2014, 5:26 AM
> 
> On Fri, 29 Aug 2014,
> peter dalgaard wrote:
> 
>> 
> I'm no expert on hurdle models, but it seems that you
> are unaware that 
>> the negative binomial
> and the truncated negative binomial are quite 
>> different things.
> 
> Yes. You can replicate the truncated count part
> of the hurdle model with 
> the zerotrunc()
> function from the "countreg" package. The package
> is not 
> yet on CRAN but can be easily
> installed from R-Forge.
> 
>> -pd
>> 
>> 
>> On 29 Aug 2014, at
> 05:57 , Nick Livingston <nlivingston at ymail.com>
> wrote:
>> 
>>> I have
> sought consultation online and in person, to no avail. I
> hope someone
>>> on here might have
> some insight. Any feedback would be most welcome.
>>> 
>>> I am
> attempting to plot predicted values from a two-component
> hurdle model
>>> (logistic [suicide
> attempt yes/no] and negative binomial count [number of
>>> attempts thereafter]). To do so, I
> estimated each component separately using
>>> glm (MASS). While I am able to
> reproduce hurdle results for the logit
>>> portion in glm, estimates for the
> negative binomial count component are
>>> different.
>>> 
>>> Call:
>>> 
> hurdle(formula = Suicide. ~ Age + gender + Victimization *
> FamilySupport |
>>> Age + gender +
> Victimization * FamilySupport, dist = "negbin",
> link =
>>> "logit")
>>> 
>>> Pearson
> residuals:
>>>      Min   
>   1Q  Median      3Q     Max
>>> -0.9816 -0.5187 -0.4094  0.2974 
> 5.8820
>>> 
>>> 
> Count model coefficients (truncated negbin with log
> link):
>>>                    
>                          
>    Estimate Std. Error z value
>>> Pr(>|z|)
>>> 
> (Intercept)                          -0.29150 
>   0.33127  -0.880   0.3789
>>> Age                       
>               0.17068   
> 0.07556   2.259   0.0239
>>> *
>>> gender   
>                          
>    0.28273   
> 0.31614   0.894   0.3712
>>> Victimization               
>          1.08405   
> 0.18157   5.971 2.36e-09
>>> 
> ***
>>> FamilySupport           
>           0.33629   
> 0.29302   1.148   0.2511
>>> Victimization:FamilySupport -0.96831 
>   0.46841  -2.067   0.0387 *
>>> Log(theta)                 
>           0.12245   
> 0.54102   0.226   0.8209
>>> Zero hurdle model coefficients
> (binomial with logit link):
>>>      
>                                        
>     Estimate Std. Error z value
>>> 
> Pr(>|z|)
>>> (Intercept)       
>                
>    -0.547051   0.215981  -2.533 
> 0.01131
>>> *
>>> 
> Age                                 
>    -0.154493   0.063994  -2.414
>>> 0.01577 *
>>> 
> gender                             
>    -0.030942   0.284868  -0.109 
> 0.91350
>>> Victimization         
>                
> 1.073956   0.338015   3.177 
> 0.00149
>>> **
>>> 
> FamilySupport                   
>    -0.380360   0.247530  -1.537 
> 0.12439
>>> 
> Victimization\:FamilySupport 
> -0.813329   0.399905  -2.034  0.04197 *
>>> ---
>>> Signif.
> codes:  0 '***' 0.001 '**' 0.01 '*'
> 0.05 '.' 0.1 ' ' 1
>>> 
>>> Theta: count
> = 1.1303
>>> Number of iterations in
> BFGS optimization: 23
>>> 
> Log-likelihood: -374.3 on 25 Df
>>>> 
> summary(logistic)
>>> 
>>> 
>>> 
>>> 
>>> Call:
>>> glm(formula = SuicideBinary ~ Age +
> gender = Victimization * FamilySupport,
>>> family = "binomial")
>>> 
>>> Deviance
> Residuals:
>>>      Min   
>    1Q   Median       3Q 
>     Max
>>> -1.9948  -0.8470 
> -0.6686   1.1160   2.0805
>>> 
>>> 
> Coefficients:
>>>              
>                                    
> Estimate Std. Error z value
>>> 
> Pr(>|z|)
>>> (Intercept)       
>                   -0.547051   0.215981 
> -2.533  0.01131 *
>>> Age       
>                            
> -0.154493   0.063994  -2.414  0.01577
>>> *
>>> gender   
>                            
> -0.030942   0.284868  -0.109  0.91350
>>> Victimization               
>      
>    1.073956   0.338014   3.177 
> 0.00149
>>> **
>>> 
> FamilySupport                     
> -0.380360   0.247530  -1.537  0.12439
>>> Victimization:FamilySupport 
> -0.813329   0.399904  -2.034  0.04197 *
>>> ---
>>> Signif.
> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> (Dispersion
> parameter for binomial family taken to be 1)
>>> 
>>>  
>    Null deviance: 452.54  on 359  degrees of
> freedom
>>> Residual deviance: 408.24 
> on 348  degrees of freedom
>>>    (52 observations deleted
> due to missingness)
>>> AIC: 432.24
>>> 
>>> Number of
> Fisher Scoring iterations: 4
>>> 
>>>> summary(Count1)
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
>>> Call:
>>> 
> glm(formula = NegBinSuicide ~ Age + gender + Victimization *
> FamilySupport,
>>> family =
> negative.binomial(theta = 1.1303))
>>> 
>>> Deviance
> Residuals:
>>>      Min   
>    1Q   Median       3Q 
>     Max
>>> -1.6393  -0.4504 
> -0.1679   0.2350   2.1676
>>> 
>>> 
> Coefficients:
>>>              
>                                
>    Estimate Std. Error t value
>>> Pr(>|t|)
>>> 
> (Intercept)                           
> 0.60820    0.13779   4.414 2.49e-05
>>> ***
>>> Age   
>                                   0.08836 
>   0.04189   2.109   0.0373
>>> *
>>> gender   
>                               0.10983   
> 0.17873   0.615   0.5402
>>> Victimization               
>           0.73270    0.10776   6.799
> 6.82e-10
>>> ***
>>> FamilySupport               
>         0.10213   
> 0.15979   0.639   0.5241
>>> 
> Victimization:FamilySupport   -0.60146   
> 0.24532  -2.452   0.0159 *
>>> ---
>>> Signif.
> codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>>> 
>>> (Dispersion
> parameter for Negative Binomial(1.1303) family taken to
> be
>>> 0.4549082)
>>> 
>>>  
>    Null deviance: 76.159  on 115  degrees of
> freedom
>>> Residual deviance: 35.101 
> on 104  degrees of freedom
>>>    (296 observations deleted
> due to missingness)
>>> AIC: 480.6
>>> 
>>> Number of
> Fisher Scoring iterations: 15
>>> 
>>> 
>>> 
> Alternatively, if there is a simpler way to plot hurdle
> regression output, or if anyone is award of another means of
> estimating NB models (I haven't had much luck with vglm
> from VGAM either), I would be happy to hear about that as
> well. I'm currently using the "visreg"
>>> package for plotting.
>>> 
>>> Thanks!
>>> 
>>> 
>>> 
>>> 
>>> 
>>> 
> ______________________________________________
>>> R-help at r-project.org
> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal,
> self-contained, reproducible code.
>> 
>> -- 
>> Peter Dalgaard,
> Professor,
>> Center for Statistics,
> Copenhagen Business School
>> Solbjerg
> Plads 3, 2000 Frederiksberg, Denmark
>> 
> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv:
> PDalgd at gmail.com
>> 
>> 
> ______________________________________________
>> R-help at r-project.org
> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal,
> self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ripley at stats.ox.ac.uk  Fri Aug 29 20:36:52 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 29 Aug 2014 19:36:52 +0100
Subject: [R] Question regarding the discrepancy between count model
 parameter estimates between "pscl" and "MASS"
In-Reply-To: <1409330796.89710.YahooMailBasic@web142406.mail.bf1.yahoo.com>
References: <1409330796.89710.YahooMailBasic@web142406.mail.bf1.yahoo.com>
Message-ID: <5400C844.3060901@stats.ox.ac.uk>

On 29/08/2014 17:46, Nick Livingston wrote:
> Thank you for your responses.
>
> Since my previous attempt to manually truncate my DV didn't work, I'm very interested in trying again using the zerotrun() function. However, I attempted to install "countreg" but received the following notification:
>
>          Warning in install.packages :
>                unable to access index for repository http://R-Forge.R-project.org/bin/macosx/contrib/3.0
>
>                package ?countreg? is available as a source package but not as a binary
>
>           Warning in install.packages :
>                package ?countreg? is not available (for R version 3.0.3)
>
> I received the same message when attempting to install it in version 3.1.0, and the latest version, 3.1.1. Am I missing something?

As the package does not contain compiled code, you can simply install 
from the sources.  (I just did so in the GUI: just untick 'binary'.)

> Thank you again. I appreciate your input.
>
> -Nick
> --------------------------------------------
> On Fri, 8/29/14, Achim Zeileis <Achim.Zeileis at uibk.ac.at> wrote:
>
>   Subject: Re: [R] Question regarding the discrepancy between count model parameter estimates between "pscl" and "MASS"
>   To: "peter dalgaard" <pdalgd at gmail.com>
>   Cc: "Nick Livingston" <nlivingston at ymail.com>, r-help at r-project.org
>   Date: Friday, August 29, 2014, 5:26 AM
>
>   On Fri, 29 Aug 2014,
>   peter dalgaard wrote:
>
>   >
>   I'm no expert on hurdle models, but it seems that you
>   are unaware that
>   > the negative binomial
>   and the truncated negative binomial are quite
>   > different things.
>
>   Yes. You can replicate the truncated count part
>   of the hurdle model with
>   the zerotrunc()
>   function from the "countreg" package. The package
>   is not
>   yet on CRAN but can be easily
>   installed from R-Forge.
>
>   > -pd
>   >
>   >
>   > On 29 Aug 2014, at
>   05:57 , Nick Livingston <nlivingston at ymail.com>
>   wrote:
>   >
>   >> I have
>   sought consultation online and in person, to no avail. I
>   hope someone
>   >> on here might have
>   some insight. Any feedback would be most welcome.
>   >>
>   >> I am
>   attempting to plot predicted values from a two-component
>   hurdle model
>   >> (logistic [suicide
>   attempt yes/no] and negative binomial count [number of
>   >> attempts thereafter]). To do so, I
>   estimated each component separately using
>   >> glm (MASS). While I am able to
>   reproduce hurdle results for the logit
>   >> portion in glm, estimates for the
>   negative binomial count component are
>   >> different.
>   >>
>   >> Call:
>   >>
>   hurdle(formula = Suicide. ~ Age + gender + Victimization *
>   FamilySupport |
>   >> Age + gender +
>   Victimization * FamilySupport, dist = "negbin",
>   link =
>   >> "logit")
>   >>
>   >> Pearson
>   residuals:
>   >>     Min
>     1Q  Median      3Q     Max
>   >> -0.9816 -0.5187 -0.4094  0.2974
>   5.8820
>   >>
>   >>
>   Count model coefficients (truncated negbin with log
>   link):
>   >>
>
>      Estimate Std. Error z value
>   >> Pr(>|z|)
>   >>
>   (Intercept)                          -0.29150
>     0.33127  -0.880   0.3789
>   >> Age
>                 0.17068
>   0.07556   2.259   0.0239
>   >> *
>   >> gender
>
>      0.28273
>   0.31614   0.894   0.3712
>   >> Victimization
>            1.08405
>   0.18157   5.971 2.36e-09
>   >>
>   ***
>   >> FamilySupport
>             0.33629
>   0.29302   1.148   0.2511
>   >> Victimization:FamilySupport -0.96831
>     0.46841  -2.067   0.0387 *
>   >> Log(theta)
>             0.12245
>   0.54102   0.226   0.8209
>   >> Zero hurdle model coefficients
>   (binomial with logit link):
>   >>
>
>       Estimate Std. Error z value
>   >>
>   Pr(>|z|)
>   >> (Intercept)
>
>      -0.547051   0.215981  -2.533
>   0.01131
>   >> *
>   >>
>   Age
>      -0.154493   0.063994  -2.414
>   >> 0.01577 *
>   >>
>   gender
>      -0.030942   0.284868  -0.109
>   0.91350
>   >> Victimization
>
>   1.073956   0.338015   3.177
>   0.00149
>   >> **
>   >>
>   FamilySupport
>      -0.380360   0.247530  -1.537
>   0.12439
>   >>
>   Victimization\:FamilySupport
>   -0.813329   0.399905  -2.034  0.04197 *
>   >> ---
>   >> Signif.
>   codes:  0 '***' 0.001 '**' 0.01 '*'
>   0.05 '.' 0.1 ' ' 1
>   >>
>   >> Theta: count
>   = 1.1303
>   >> Number of iterations in
>   BFGS optimization: 23
>   >>
>   Log-likelihood: -374.3 on 25 Df
>   >>>
>   summary(logistic)
>   >>
>   >>
>   >>
>   >>
>   >> Call:
>   >> glm(formula = SuicideBinary ~ Age +
>   gender = Victimization * FamilySupport,
>   >> family = "binomial")
>   >>
>   >> Deviance
>   Residuals:
>   >>     Min
>      1Q   Median       3Q
>       Max
>   >> -1.9948  -0.8470
>   -0.6686   1.1160   2.0805
>   >>
>   >>
>   Coefficients:
>   >>
>
>   Estimate Std. Error z value
>   >>
>   Pr(>|z|)
>   >> (Intercept)
>                     -0.547051   0.215981
>   -2.533  0.01131 *
>   >> Age
>
>   -0.154493   0.063994  -2.414  0.01577
>   >> *
>   >> gender
>
>   -0.030942   0.284868  -0.109  0.91350
>   >> Victimization
>
>      1.073956   0.338014   3.177
>   0.00149
>   >> **
>   >>
>   FamilySupport
>   -0.380360   0.247530  -1.537  0.12439
>   >> Victimization:FamilySupport
>   -0.813329   0.399904  -2.034  0.04197 *
>   >> ---
>   >> Signif.
>   codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>   >>
>   >> (Dispersion
>   parameter for binomial family taken to be 1)
>   >>
>   >>
>      Null deviance: 452.54  on 359  degrees of
>   freedom
>   >> Residual deviance: 408.24
>   on 348  degrees of freedom
>   >>   (52 observations deleted
>   due to missingness)
>   >> AIC: 432.24
>   >>
>   >> Number of
>   Fisher Scoring iterations: 4
>   >>
>   >>> summary(Count1)
>   >>
>   >>
>   >>
>   >>
>   >>
>   >>
>   >> Call:
>   >>
>   glm(formula = NegBinSuicide ~ Age + gender + Victimization *
>   FamilySupport,
>   >> family =
>   negative.binomial(theta = 1.1303))
>   >>
>   >> Deviance
>   Residuals:
>   >>     Min
>      1Q   Median       3Q
>       Max
>   >> -1.6393  -0.4504
>   -0.1679   0.2350   2.1676
>   >>
>   >>
>   Coefficients:
>   >>
>
>      Estimate Std. Error t value
>   >> Pr(>|t|)
>   >>
>   (Intercept)
>   0.60820    0.13779   4.414 2.49e-05
>   >> ***
>   >> Age
>                                     0.08836
>     0.04189   2.109   0.0373
>   >> *
>   >> gender
>                                 0.10983
>   0.17873   0.615   0.5402
>   >> Victimization
>             0.73270    0.10776   6.799
>   6.82e-10
>   >> ***
>   >> FamilySupport
>           0.10213
>   0.15979   0.639   0.5241
>   >>
>   Victimization:FamilySupport   -0.60146
>   0.24532  -2.452   0.0159 *
>   >> ---
>   >> Signif.
>   codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>   >>
>   >> (Dispersion
>   parameter for Negative Binomial(1.1303) family taken to
>   be
>   >> 0.4549082)
>   >>
>   >>
>      Null deviance: 76.159  on 115  degrees of
>   freedom
>   >> Residual deviance: 35.101
>   on 104  degrees of freedom
>   >>   (296 observations deleted
>   due to missingness)
>   >> AIC: 480.6
>   >>
>   >> Number of
>   Fisher Scoring iterations: 15
>   >>
>   >>
>   >>
>   Alternatively, if there is a simpler way to plot hurdle
>   regression output, or if anyone is award of another means of
>   estimating NB models (I haven't had much luck with vglm
>   from VGAM either), I would be happy to hear about that as
>   well. I'm currently using the "visreg"
>   >> package for plotting.
>   >>
>   >> Thanks!
>   >>
>   >>
>   >>
>   >>
>   >>
>   >>
>   ______________________________________________
>   >> R-help at r-project.org
>   mailing list
>   >> https://stat.ethz.ch/mailman/listinfo/r-help
>   >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>   >> and provide commented, minimal,
>   self-contained, reproducible code.
>   >
>   > --
>   > Peter Dalgaard,
>   Professor,
>   > Center for Statistics,
>   Copenhagen Business School
>   > Solbjerg
>   Plads 3, 2000 Frederiksberg, Denmark
>   >
>   Phone: (+45)38153501
>   > Email: pd.mes at cbs.dk  Priv:
>   PDalgd at gmail.com
>   >
>   >
>   ______________________________________________
>   > R-help at r-project.org
>   mailing list
>   > https://stat.ethz.ch/mailman/listinfo/r-help
>   > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>   > and provide commented, minimal,
>   self-contained, reproducible code.
>   >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From gcr at wisdomandwonder.com  Fri Aug 29 20:42:53 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Fri, 29 Aug 2014 13:42:53 -0500
Subject: [R] Best cross-platform OSS GUI CSV management application?
In-Reply-To: <cf44e620-f058-4d68-816c-9d20c7fc9e3e@email.android.com>
References: <CAAjq1mcYaOCS7orNORVgR-VQ3k+CWcM6yW2_beRE8EP2JqcLcQ@mail.gmail.com>
	<cf44e620-f058-4d68-816c-9d20c7fc9e3e@email.android.com>
Message-ID: <CAAjq1meDLyGGBgm0gHyp5FAmPzdb2szRp3UajgUZ2oj0ZRmhnQ@mail.gmail.com>

On Wed, Aug 27, 2014 at 7:10 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Please stop posting on this plain text list using HTML. You are not a freshman any more.

My sincere apologies, will do, accidentally left Gmail configured as such.

> Is anyone really considering the use of a word processor (equivalent to MS Word) for managing this tabular
> data?

Excel.

> A better solution is to create a SQL database

Gotcha.


From marc_grt at yahoo.fr  Fri Aug 29 21:20:15 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Fri, 29 Aug 2014 22:20:15 +0300
Subject: [R] Not display message when using system()
Message-ID: <5400D26F.7050709@yahoo.fr>

Dear list members,

My question concerns the use of system() in R version 3.1.1 patched and 
MacosX 10.9.4.
I want capture the result of a system command without displaying error 
message. I give exemple.

In terminal, if I do this command:
find $HOME -type f -name 'PuertoSanJose.csv'

I get the correct answer but also a message about Permission denied for 
one directory:
/Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
find: /Users/marc/Library/Saved Application 
State/com.adobe.flashplayer.installmanager.savedState/data.data: 
Permission denied

I want get the output of this command in R; then I do:
 > pathfile <- system("find $HOME -type f -name 'PuertoSanJose.csv'", 
intern=TRUE, ignore.stderr = TRUE)
Message d'avis :
l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv' 
2>/dev/null' renvoie un statut 1

In pathfile, I have the correct answer but I have also a message that I 
don't want.

My question is then: How to prevent display this message?

I try the following:
 > pathfile <- capture.output(system("find $HOME -type f -name 
'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
Message d'avis :
l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv' 
2>/dev/null' renvoie un statut 1

The same

I try also:
 > pathfile <- suppressMessages(system("find $HOME -type f -name 
'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
Message d'avis :
l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv' 
2>/dev/null' renvoie un statut 1

The same

The only solution to not see this message is:
 > pathfile <- system("find $HOME -type f -name 'PuertoSanJose.csv'", 
intern=FALSE, ignore.stderr = TRUE)
/Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
 > pathfile
[1] 1

But pathfile does not capture the output.

And the use of capture.output() does not help:
 > pathfile <- capture.output(system("find $HOME -type f -name 
'PuertoSanJose.csv'", intern=FALSE, ignore.stderr = TRUE))
/Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
 > pathfile
character(0)


I really don't know how to not see this message...
If someone knows, I will appreciate !

Marc


From hb at biostat.ucsf.edu  Fri Aug 29 21:33:31 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 29 Aug 2014 12:33:31 -0700
Subject: [R] Not display message when using system()
In-Reply-To: <5400D26F.7050709@yahoo.fr>
References: <5400D26F.7050709@yahoo.fr>
Message-ID: <CAFDcVCQ0wm0g1tsNBDR6sTbobiAm-CaiFysd8=mOEtzfHSv0pQ@mail.gmail.com>

As a start try to use system2() instead and look at its argument for how to
capture stdout and/or stderr. It's a neater function.

It may be that those messages cannot be captured easily, but hopefully they
are.

My $0.02

Henrik
On Aug 29, 2014 12:21 PM, "Marc Girondot" <marc_grt at yahoo.fr> wrote:

> Dear list members,
>
> My question concerns the use of system() in R version 3.1.1 patched and
> MacosX 10.9.4.
> I want capture the result of a system command without displaying error
> message. I give exemple.
>
> In terminal, if I do this command:
> find $HOME -type f -name 'PuertoSanJose.csv'
>
> I get the correct answer but also a message about Permission denied for
> one directory:
> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
> find: /Users/marc/Library/Saved Application State/com.adobe.flashplayer.
> installmanager.savedState/data.data: Permission denied
>
> I want get the output of this command in R; then I do:
> > pathfile <- system("find $HOME -type f -name 'PuertoSanJose.csv'",
> intern=TRUE, ignore.stderr = TRUE)
> Message d'avis :
> l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv'
> 2>/dev/null' renvoie un statut 1
>
> In pathfile, I have the correct answer but I have also a message that I
> don't want.
>
> My question is then: How to prevent display this message?
>
> I try the following:
> > pathfile <- capture.output(system("find $HOME -type f -name
> 'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
> Message d'avis :
> l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv'
> 2>/dev/null' renvoie un statut 1
>
> The same
>
> I try also:
> > pathfile <- suppressMessages(system("find $HOME -type f -name
> 'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
> Message d'avis :
> l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv'
> 2>/dev/null' renvoie un statut 1
>
> The same
>
> The only solution to not see this message is:
> > pathfile <- system("find $HOME -type f -name 'PuertoSanJose.csv'",
> intern=FALSE, ignore.stderr = TRUE)
> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
> > pathfile
> [1] 1
>
> But pathfile does not capture the output.
>
> And the use of capture.output() does not help:
> > pathfile <- capture.output(system("find $HOME -type f -name
> 'PuertoSanJose.csv'", intern=FALSE, ignore.stderr = TRUE))
> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
> > pathfile
> character(0)
>
>
> I really don't know how to not see this message...
> If someone knows, I will appreciate !
>
> Marc
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fneiman at monticello.org  Fri Aug 29 23:13:53 2014
From: fneiman at monticello.org (Fraser D. Neiman)
Date: Fri, 29 Aug 2014 21:13:53 +0000
Subject: [R] posterior probabilities from lda.predict
Message-ID: <2176AD174D58CB4ABBDA99F3458C20172068B4CD@GRANGER.monticello.org>

Dear All,

I have used the lda() function in the MASS library to estimate a set of discriminant functions to assign samples from a training set to one of six groups.  The cross validation generates nearly perfect predictions for samples in the training set.  Hooray!

Now I want to use lda.predict() to estimate both discriminant function scores and probabilities of group membership for a second set of samples whose group membership is unknown.  For each unknown sample, lda.predict() produces a six probabilities. These probabilities sum to one. So lda.predict() seems to assume that the unknown samples do, in fact, belong to one of the six groups.  

The problem is that it is nearly certain that some of the unknown samples in the second set do not belong to any of the six groups. For those samples, probabilities of group membership should be close to zero for all six groups.  In fact, identifying which samples are unlikely to belong to any of the six groups is a major goal of the analysis. 

So the question is, what is lda.predict() doing behind the scenes to force the group membership probabilities to sum to one? How do I get it to not do this and produce probabilities that accurately reflect the large Mahalanobis distances of some of the unknown sample from any group centroid?\

I have searched the R-list archive on this and have found several folks asking similar questions, but no helpful answers.

Thanks very much!

Fraser

From alaw005 at gmail.com  Sat Aug 30 02:46:17 2014
From: alaw005 at gmail.com (Adam Lawrence)
Date: Sat, 30 Aug 2014 12:46:17 +1200
Subject: [R] Bus stop sequence matching problem
Message-ID: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>

I am hoping someone can help me with a bus stop sequencing problem in R,
where I need to match counts of people getting on and off a bus to the
correct stop in the bus route stop sequence. I have tried looking
online/forums for sequence matching but seems to refer to numeric sequences
or DNA matching and over my head. I am after a simple example if anyone can
please help.

I have two data series as per below (from database), that I want to
combine. In this example ?stop_sequence? includes the equence (seq) of bus
stops and ?stop_onoff? is a count of people getting on and off at certain
stops (there is no entry if noone gets on or off).

stop_sequence <- data.frame(seq=c(10,20,30,40,50,60),
ref=c('A','B','C','D','B','A'))
##   seq ref
## 1  10   A
## 2  20   B
## 3  30   C
## 4  40   D
## 5  50   B
## 6  60   A
stop_onoff <-
data.frame(ref=c('A','D','B','A'),on=c(5,0,10,0),off=c(0,2,2,6))
##   ref on off
## 1   A  5   0
## 2   D  0   2
## 3   B 10   2
## 4   A  0   6

I need to match the stop_onoff numbers in the right sto sequence, with the
correctly matched output as follows (load is a cumulative count of on and
off)

desired_output <- data.frame(seq=c(10,20,30,40,50,60),
ref=c('A','B','C','D','B','A'),
on=c(5,'-','-',0,10,0),off=c(0,'-','-',2,2,6), load=c(5,0,0,3,11,5))
##   seq ref on off load
## 1  10   A  5   0    5
## 2  20   B  -   -    0
## 3  30   C  -   -    0
## 4  40   D  0   2    3
## 5  50   B 10   2   11
## 6  60   A  0   6    5

In this example the stop ?B? is matched to the second stop ?B? in the stop
sequence and not the first because the onoff data is after stop ?D?.

Any guidance much appreciated.

Regards
Adam

	[[alternative HTML version deleted]]


From dmcp at webmail.co.za  Sat Aug 30 05:54:20 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Sat, 30 Aug 2014 05:54:20 +0200
Subject: [R] Unexpected behavior when giving a value to a new variable
 basedon the value of another variable
In-Reply-To: <c5647c24-15fa-4f14-8f68-02f7eeda5924@email.android.com>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>, 
	<c5647c24-15fa-4f14-8f68-02f7eeda5924@email.android.com>
Message-ID: <fabdf424437bc7b81f57bf6329ae0b33@www.webmail.co.za>

On Fri, 29 Aug 2014 06:33:01 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote

> One clue is the help file for "$"...
> 
> ?" $"
> 
> In particular there see the discussion of character indices and the "exact"
> argument. 
>

<...snip...>
> 
> On August 29, 2014 1:53:47 AM PDT, Angel Rodriguez
> <angel.rodriguez at matiainstituto.net> wrote: >
> >Dear subscribers,
> >
> >I've found that if there is a variable in the dataframe with a name
<...sip...>
> >> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58), V2 =
> >c(NA, 1, 1, 1, 1,1,1,1,NA)), 
> >+                     .Names = c("age","samplem"), row.names = c(NA,
> >-9L), class = "data.frame")
> >> N$sample[N$age >= 65] <- 1 
> >> N
> >  age samplem sample
> >1  67      NA      1
> >2  62       1      1
> >3  74       1      1
> >4  61       1      1
> >5  60       1      1
> >6  55       1      1
> >7  60       1      1
> >8  59       1      1
> >9  58      NA     NA
<...snip...>

Having seen all the responses about partial matching I almost understand. I've
also replicated the behaviour on R 2.11.1 so it's been around awhile. This
tells me it ain't a bug - so if any of the cognoscenti have the time and
inclination can someone give me a brief (and hopefully simple) explanation of
what is going on under the hood?

It looks (to me) like N$sample[N$age >= 65] <- 1 copies N$samplem to N$sample
and then does the assignment. If partial matching is the problem (which it
clearly is) my expectation is that  the  output should look like

   age samplem
1   67       1
2   62       1
3   74       1
4   61       1
5   60       1
6   55       1
7   60       1
8   59       1
9   58      NA
That is - no new column.
(and I just hate it when the world doesn't live up to my expectations!)

Bewildered and confused,
DMcP

____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Cotlands - Shaping tomorrows Heroes http://www.cotlands.org.za/


From ggrothendieck at gmail.com  Sat Aug 30 15:08:46 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 30 Aug 2014 09:08:46 -0400
Subject: [R] Bus stop sequence matching problem
In-Reply-To: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>
References: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>
Message-ID: <CAP01uR=6DCA9_mreFsRRgEs9ck6jqxfjQOm4KXzyb32BJqAUxw@mail.gmail.com>

Try dtw.  First convert ref to numeric since dtw does not handle
character input.  Then align using dtw and NA out repeated values in
the alignment.  Finally zap ugly row names and calculate loading:

library(dtw)
s1 <- as.numeric(stop_sequence$ref)
s2 <- as.numeric(factor(as.character(stop_onoff$ref),
levels(stop_sequence$ref)))
a <- dtw(s1, s2)
DF <- cbind(stop_sequence,
      stop_onoff[replace(a$index2, c(FALSE, diff(a$index2) == 0), NA), ])[-3]
rownames(DF) <- NULL
transform(DF, loading = cumsum(ifelse(is.na(on), 0, on)) -
                        cumsum(ifelse(is.na(off), 0, off)))

giving:

  seq ref on off loading
1  10   A  5   0       5
2  20   B NA  NA       5
3  30   C NA  NA       5
4  40   D  0   2       3
5  50   B 10   2      11
6  60   A  0   6       5

You will need to test this with more data and tweak it if necessary
via the various dtw arguments.


On Fri, Aug 29, 2014 at 8:46 PM, Adam Lawrence <alaw005 at gmail.com> wrote:
> I am hoping someone can help me with a bus stop sequencing problem in R,
> where I need to match counts of people getting on and off a bus to the
> correct stop in the bus route stop sequence. I have tried looking
> online/forums for sequence matching but seems to refer to numeric sequences
> or DNA matching and over my head. I am after a simple example if anyone can
> please help.
>
> I have two data series as per below (from database), that I want to
> combine. In this example ?stop_sequence? includes the equence (seq) of bus
> stops and ?stop_onoff? is a count of people getting on and off at certain
> stops (there is no entry if noone gets on or off).
>
> stop_sequence <- data.frame(seq=c(10,20,30,40,50,60),
> ref=c('A','B','C','D','B','A'))
> ##   seq ref
> ## 1  10   A
> ## 2  20   B
> ## 3  30   C
> ## 4  40   D
> ## 5  50   B
> ## 6  60   A
> stop_onoff <-
> data.frame(ref=c('A','D','B','A'),on=c(5,0,10,0),off=c(0,2,2,6))
> ##   ref on off
> ## 1   A  5   0
> ## 2   D  0   2
> ## 3   B 10   2
> ## 4   A  0   6
>
> I need to match the stop_onoff numbers in the right sto sequence, with the
> correctly matched output as follows (load is a cumulative count of on and
> off)
>
> desired_output <- data.frame(seq=c(10,20,30,40,50,60),
> ref=c('A','B','C','D','B','A'),
> on=c(5,'-','-',0,10,0),off=c(0,'-','-',2,2,6), load=c(5,0,0,3,11,5))
> ##   seq ref on off load
> ## 1  10   A  5   0    5
> ## 2  20   B  -   -    0
> ## 3  30   C  -   -    0
> ## 4  40   D  0   2    3
> ## 5  50   B 10   2   11
> ## 6  60   A  0   6    5
>
> In this example the stop ?B? is matched to the second stop ?B? in the stop
> sequence and not the first because the onoff data is after stop ?D?.
>
> Any guidance much appreciated.
>
> Regards
> Adam
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From dmcp at webmail.co.za  Sat Aug 30 09:54:02 2014
From: dmcp at webmail.co.za (David McPearson)
Date: Sat, 30 Aug 2014 09:54:02 +0200
Subject: [R] Bus stop sequence matching problem
In-Reply-To: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>
References: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>
Message-ID: <89fb7798819561c96e6cde2d14ee602a@www.webmail.co.za>

Homework? The list has a no homework policy - but perhaps I'll be forgiven por
posting hints.
In general terms, this is how I appraoched the problem:
* Loop through the rows of stop_onoff - for (idx in ...someething...) {...
* For each row, find the first of "ref" in a suitably filtered subset of
stop_sequence, and keep track of these row numbers
* Update columns "on" and "off"
* Use cumsum to calculate the number of passengers on the bus

Note the loop. Someone cleverer than I might be able to vectorise that step,
but I couldn't see how.

By the way, if this is homework...

Are you sure you're desired_output is correct? I would expect someething like
  seq ref on off load
1  10   A  5   0    5
2  20   B  0   0    5
3  30   C  0   0    5
4  40   D  0   2    3
5  50   B 10   2   11
6  60   A  0   6    5

Are you aware that you're "ref" ccolumns are factors and not characters? If
you use "stringsAsFactors = FALSE" or
stop_onoff <-
data.frame(ref=factor(c('A','D','B','A'), levels =
levels(stop_sequence$ref)),on=c(5,0,10,0),off=c(0,2,2,6))
it will simplify your'e analysis (or at least reduce some typing).

Type the following in an R console
?data.frame
?factor
and have a read.

Now, if this ain't homework, or you just want someone to do it for you, e-mail
me offline and I'll send you my appraoch. If it is homework, let me know - I'm
happy to help anyway, but I will be trying to help you solve this for
yourself.

Cheers,
DMcP

On Sat, 30 Aug 2014 12:46:17 +1200 Adam Lawrence <alaw005 at gmail.com> wrote

> I am hoping someone can help me with a bus stop sequencing problem in R,
> where I need to match counts of people getting on and off a bus to the
> correct stop in the bus route stop sequence. I have tried looking
> online/forums for sequence matching but seems to refer to numeric sequences
> or DNA matching and over my head. I am after a simple example if anyone can
> please help.
> 
> I have two data series as per below (from database), that I want to
> combine. In this example ?stop_sequence? includes the equence (seq) of
bus
> stops and ?stop_onoff? is a count of people getting on and off at
certain
> stops (there is no entry if noone gets on or off).
> 
> stop_sequence <- data.frame(seq=c(10,20,30,40,50,60),
> ref=c('A','B','C','D','B','A'))
> ##   seq ref
> ## 1  10   A
> ## 2  20   B
> ## 3  30   C
> ## 4  40   D
> ## 5  50   B
> ## 6  60   A
> stop_onoff <-
> data.frame(ref=c('A','D','B','A'),on=c(5,0,10,0),off=c(0,2,2,6))
> ##   ref on off
> ## 1   A  5   0
> ## 2   D  0   2
> ## 3   B 10   2
> ## 4   A  0   6
> 
> I need to match the stop_onoff numbers in the right sto sequence, with the
> correctly matched output as follows (load is a cumulative count of on and
> off)
> 
> desired_output <- data.frame(seq=c(10,20,30,40,50,60),
> ref=c('A','B','C','D','B','A'),
> on=c(5,'-','-',0,10,0),off=c(0,'-','-',2,2,6), load=c(5,0,0,3,11,5))
> ##   seq ref on off load
> ## 1  10   A  5   0    5
> ## 2  20   B  -   -    0
> ## 3  30   C  -   -    0
> ## 4  40   D  0   2    3
> ## 5  50   B 10   2   11
> ## 6  60   A  0   6    5
> 
> In this example the stop ?B? is matched to the second stop ?B? in
the stop
> sequence and not the first because the onoff data is after stop ?D?.
> 
> Any guidance much appreciated.
> 
> Regards
> Adam
> 
>     [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 



____________________________________________________________
South Africas premier free email service - www.webmail.co.za 

Cheapest Insurance Quotes!
https://www.outsurance.co.za/insurance-quote/personal/?source=msn&cr=Postit14_468x60_gif&cid=322


From a.anusha140 at gmail.com  Sat Aug 30 12:14:11 2014
From: a.anusha140 at gmail.com (G)
Date: Sat, 30 Aug 2014 10:14:11 +0000
Subject: [R] Problem with sapa package and spectral density function
	(SDF)
In-Reply-To: <CACuLAKPxfVhnGCXPe8WWG1ouZWGp8NcB979mAcUOZCZFUoVWhg@mail.gmail.com>
Message-ID: <em8b2c80a5-c479-4e46-b7ad-5bc689be089c@anusha-pc>

Hello,

Did you find a solution to this problem in the R mailing list ?
I am having the same problem but there were apparently no replies to 
your question or didnt find them ?

Thanks
Anusha
	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Sat Aug 30 17:45:01 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 30 Aug 2014 10:45:01 -0500
Subject: [R] new error with QuantMod getSymbols
In-Reply-To: <CAGTCEXYbLBgA6aCQGTot-LF9g=BcijK7Ft9eyfEsL9GC0w4_eA@mail.gmail.com>
References: <CAGTCEXYbLBgA6aCQGTot-LF9g=BcijK7Ft9eyfEsL9GC0w4_eA@mail.gmail.com>
Message-ID: <CAPPM_gQhL-azgjo6zogRw7ooAWTTWTEDg8LtU2hEH=AOj0yBuQ@mail.gmail.com>

You didn't provide the file "lista.csv", so it's not possible to
reproduce any of these errors.  And there's no call to getSymbols in
your code.  You use loadSymbols, and I am not familiar with that
function.

That said, this sounds like an issue with some of the data being sent
by Yahoo Finance.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Thu, Aug 28, 2014 at 11:12 PM, Adolfo Yanes <adolfoyanes at gmail.com> wrote:
> Hello,
>
> I use getSymbols function daily to run some models with stock data. Today
> when I tried to update the stock info i get this error
>
> Error in charToDate(x) :
>   character string is not in a standard unambiguous format
>
> Sometimes I get it after 2 symbols, other times after 150 symbols, another
> time after 40 symbols, then after 203 symbols.
>
> The code for the symbol list is:
>
> lista<-read.csv("lista.csv", header=FALSE)
>
>
>
> lista.list.ana<-vector('list',nrow(lista))
>
> names(lista.list.ana) <- lista[,1]
>
> lista.sum<-as.vector(lista[,1])
>
>
> ##actualizar la lista
>
> lista_simbolos<-download_symbols(lista.sum, lista.list.ana)
>
>
>
> *The code for the function download_symbols is:*
>
>
> download_symbols<- function(lista.sum.,lista.list.ana..){
>
>   newnames.<- c("Open", "High", "Low", "Close", "Volume", "Adjusted")
>
> for (m in 1:length(lista.sum.))
>
>
> {
>
> print(paste(c("Downloading symbol ", lista.sum.[m], ". ", length(lista.sum.
> )-m, " symbols missing"), sep="", collapse=""))
>
> temp<-get(loadSymbols(lista.sum.[m]))
>
> names(temp)<-newnames.
>
> #lista.list.ana..[[m]]<-loadSymbols(lista.sum.[m])
>
> lista.list.ana..[[m]]<-temp
>
> }
>
>  return(lista.list.ana..)
>
> }
>
>
> Is it something wrong with yahoo? I tried google and got another error
> Error in `colnames<-`(`*tmp*`, value = c("Open", "High", "Low", "Close",  :
>   length of 'dimnames' [2] not equal to array extent
>
> Thanks for your help
>
>
> --
> Adolfo Yanes Musetti
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ccberry at ucsd.edu  Sat Aug 30 20:00:24 2014
From: ccberry at ucsd.edu (Charles Berry)
Date: Sat, 30 Aug 2014 18:00:24 +0000
Subject: [R] Bus stop sequence matching problem
References: <CAA_YnRwA=_7BQ5Xxi14ENAqaVE51WVXY5aLajdg=b+YXgkx3Yw@mail.gmail.com>
Message-ID: <loom.20140830T194420-765@post.gmane.org>

Adam Lawrence <alaw005 <at> gmail.com> writes:

> 
> I am hoping someone can help me with a bus stop sequencing problem in R,
> where I need to match counts of people getting on and off a bus to the
> correct stop in the bus route stop sequence. I have tried looking
> online/forums for sequence matching but seems to refer to numeric 
> sequences
> or DNA matching and over my head. I am after a simple example if anyone 
> can
> please help.
> 

Adam,

Yet another way...

See inline code. BTW, you should have mentioned that you are
a transit planner or included a signature block so folks would know this
is not a homework question.

As others have noted/hinted, there are some unstated assumptions, so
you need to try some test cases to be sure any solution always works.

You only have one outbound/inbound cycle in stop_onoff, right??
If not, I think almost any approach can fail given the right
sequence of 'seq's.


> I have two data series as per below (from database), that I want to
> combine. In this example ?stop_sequence? includes the equence (seq) of bus
> stops and ?stop_onoff? is a count of people getting on and off at certain
> stops (there is no entry if noone gets on or off).
> 
> stop_sequence <- data.frame(seq=c(10,20,30,40,50,60),
> ref=c('A','B','C','D','B','A'))
> ##   seq ref
> ## 1  10   A
> ## 2  20   B
> ## 3  30   C
> ## 4  40   D
> ## 5  50   B
> ## 6  60   A
> stop_onoff <-
> data.frame(ref=c('A','D','B','A'),on=c(5,0,10,0),off=c(0,2,2,6))
> ##   ref on off
> ## 1   A  5   0
> ## 2   D  0   2
> ## 3   B 10   2
> ## 4   A  0   6
> 
> I need to match the stop_onoff numbers in the right sto sequence, with the
> correctly matched output as follows (load is a cumulative count of on and
> off)
> 
> desired_output <- data.frame(seq=c(10,20,30,40,50,60),
> ref=c('A','B','C','D','B','A'),
> on=c(5,'-','-',0,10,0),off=c(0,'-','-',2,2,6), load=c(5,0,0,3,11,5))
> ##   seq ref on off load
> ## 1  10   A  5   0    5
> ## 2  20   B  -   -    0
> ## 3  30   C  -   -    0
> ## 4  40   D  0   2    3
> ## 5  50   B 10   2   11
> ## 6  60   A  0   6    5
> 

Start here:

> stop_onoff$load <- with(stop_onoff,cumsum(on)-cumsum(off))
> split.ref <- with(stop_sequence,split(seq,ref))
> split.ref.onoff <- split.ref[as.character(stop_onoff$ref)]
> stop.mat <- sapply(split.ref.onoff,rep,length=2)
> inout <- cbind(stop.mat,c(0,Inf))>cbind(c(0,Inf),stop.mat)
> stop_onoff$seq <- head(stop.mat[inout],-1)
> merge(stop_sequence[c("ref","seq")],stop_onoff[-1],by="seq",all.x=T)
  seq ref on off load
1  10   A  5   0    5
2  20   B NA  NA   NA
3  30   C NA  NA   NA
4  40   D  0   2    3
5  50   B 10   2   11
6  60   A  0   6    5

You can take care of turning the NA's to zeroes or '-'s, I think.

HTH,

Chuck


From spencer.graves at structuremonitoring.com  Sat Aug 30 22:30:08 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 30 Aug 2014 13:30:08 -0700
Subject: [R] clean email addresses?
Message-ID: <54023450.7020305@structuremonitoring.com>

       Does anyone have suggestions for cleaning a list of email addresses?


       I ask, because I can read into R data on registered voters that 
includes an "email address" field.  I wondered if anyone had experience 
doing such, especially in R.  (I found an article on "How to Clean Large 
Email Contact Lists for Email Marketing Campaigns"; 
"www.wikihow.com/Clean-Large-Email-Contact-Lists-for-Email-Marketing-Campaigns". 
Before I went further with this, I felt a need to ask.


       Thanks,
       Spencer Graves


From mazatlanmexico at yahoo.com  Sat Aug 30 23:11:14 2014
From: mazatlanmexico at yahoo.com (Felipe Carrillo)
Date: Sat, 30 Aug 2014 14:11:14 -0700
Subject: [R] ddply question
Message-ID: <1409433074.68081.YahooMailNeo@web126001.mail.ne1.yahoo.com>

I apologize about cross posting but my question keeps bouncing back from the list
 
 How come pct doesn't work in this ddply call?
I am trying to get a percent of 'TotalCount' by SampleDate and Age
 library(plyr)
b <- structure(list(SampleDate = structure(c(1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L), .Label = "5/8/1996", class = "factor"), TotalCount = c(1L,
2L, 1L, 1L, 4L, 3L, 1L, 10L, 3L), ForkLength = c(61L, 22L, NA,
NA, 72L, 34L, 100L, 23L, 25L), TotalSalvage = c(12L, 24L, 12L,
12L, 17L, 23L, 31L, 12L, 15L), Age = c(1L, 0L, NA, NA, 1L, 0L,
1L, 0L, 0L)), .Names = c("SampleDate", "TotalCount", "ForkLength",
"TotalSalvage", "Age"), class = "data.frame", row.names = c(NA,
-9L))
b
ddply(b,.(SampleDate,Age),summarise,salvage=sum(TotalSalvage),pct=TotalCount/sum(TotalCount))
Error: expecting result of length one, got : 4
 
#Computing TotalCount inside ddply works but the pct seems wrong...
ddply(b,.(SampleDate,Age),summarise,salvage=sum(TotalSalvage),Count=sum(TotalCount),pct=Count/sum(Count))
	[[alternative HTML version deleted]]


From adolfoyanes at gmail.com  Sat Aug 30 18:41:35 2014
From: adolfoyanes at gmail.com (adolfoyanes at gmail.com)
Date: Sat, 30 Aug 2014 16:41:35 +0000
Subject: [R] new error with QuantMod getSymbols
In-Reply-To: <CAPPM_gQhL-azgjo6zogRw7ooAWTTWTEDg8LtU2hEH=AOj0yBuQ@mail.gmail.com>
References: <CAGTCEXYbLBgA6aCQGTot-LF9g=BcijK7Ft9eyfEsL9GC0w4_eA@mail.gmail.com>
	<CAPPM_gQhL-azgjo6zogRw7ooAWTTWTEDg8LtU2hEH=AOj0yBuQ@mail.gmail.com>
Message-ID: <1527414001-1409416896-cardhu_decombobulator_blackberry.rim.net-1123265934-@b14.c2.bise6.blackberry>

Thank you very much Joshua. Pardon me  for confusing loadSymbols with getSymbols and not sending the file lista.csv .. Apparently the issue was with Yahoo Finance that day. The next day it worked perfectlty.

Best Regards,

Adolfo Yanes
Enviado desde mi BlackBerry de Movistar

-----Original Message-----
From: Joshua Ulrich <josh.m.ulrich at gmail.com>
Date: Sat, 30 Aug 2014 10:45:01 
To: Adolfo Yanes<adolfoyanes at gmail.com>
Cc: R-Help<r-help at r-project.org>
Subject: Re: [R] new error with QuantMod getSymbols

You didn't provide the file "lista.csv", so it's not possible to
reproduce any of these errors.  And there's no call to getSymbols in
your code.  You use loadSymbols, and I am not familiar with that
function.

That said, this sounds like an issue with some of the data being sent
by Yahoo Finance.
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Thu, Aug 28, 2014 at 11:12 PM, Adolfo Yanes <adolfoyanes at gmail.com> wrote:
> Hello,
>
> I use getSymbols function daily to run some models with stock data. Today
> when I tried to update the stock info i get this error
>
> Error in charToDate(x) :
>   character string is not in a standard unambiguous format
>
> Sometimes I get it after 2 symbols, other times after 150 symbols, another
> time after 40 symbols, then after 203 symbols.
>
> The code for the symbol list is:
>
> lista<-read.csv("lista.csv", header=FALSE)
>
>
>
> lista.list.ana<-vector('list',nrow(lista))
>
> names(lista.list.ana) <- lista[,1]
>
> lista.sum<-as.vector(lista[,1])
>
>
> ##actualizar la lista
>
> lista_simbolos<-download_symbols(lista.sum, lista.list.ana)
>
>
>
> *The code for the function download_symbols is:*
>
>
> download_symbols<- function(lista.sum.,lista.list.ana..){
>
>   newnames.<- c("Open", "High", "Low", "Close", "Volume", "Adjusted")
>
> for (m in 1:length(lista.sum.))
>
>
> {
>
> print(paste(c("Downloading symbol ", lista.sum.[m], ". ", length(lista.sum.
> )-m, " symbols missing"), sep="", collapse=""))
>
> temp<-get(loadSymbols(lista.sum.[m]))
>
> names(temp)<-newnames.
>
> #lista.list.ana..[[m]]<-loadSymbols(lista.sum.[m])
>
> lista.list.ana..[[m]]<-temp
>
> }
>
>  return(lista.list.ana..)
>
> }
>
>
> Is it something wrong with yahoo? I tried google and got another error
> Error in `colnames<-`(`*tmp*`, value = c("Open", "High", "Low", "Close",  :
>   length of 'dimnames' [2] not equal to array extent
>
> Thanks for your help
>
>
> --
> Adolfo Yanes Musetti
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From smileismystyl at gmail.com  Sat Aug 30 22:40:59 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Sun, 31 Aug 2014 02:10:59 +0530
Subject: [R] Error in inDL(x, as.logical(local), as.logical(now), ...)
Message-ID: <CAG1d=2BrnvQAhdodB9t_oqFf8w1pce_Qi-coooe0i+EF4+akvw@mail.gmail.com>

Dear Group,

I get this error when loadin RCurl. What could be the reason?
My configuration:
R-version : 3.1.1
Windows- 32,

Error in inDL(x, as.logical(local), as.logical(now), ...) :
  unable to load shared object 'C:/Program
Files/R/R-3.1.1/library/RCurl/libs/i386/RCurl.dll':
  LoadLibrary failure:  The specified procedure could not be found.


how do i solve this.
Since RCurl seems mandatory to install Rgbif.
-- 
:) Smile is my Style :)

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Sun Aug 31 01:20:49 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 30 Aug 2014 23:20:49 +0000
Subject: [R] posterior probabilities from lda.predict
In-Reply-To: <2176AD174D58CB4ABBDA99F3458C20172068B4CD@GRANGER.monticello.org>
References: <2176AD174D58CB4ABBDA99F3458C20172068B4CD@GRANGER.monticello.org>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F93F52@mb02.ads.tamu.edu>

Function predict.lda() is just answering a different question from the one you are posing. It is answering the question, given the values on this object what is the probability of membership in each of the groups used to construct the discriminant functions in the first place. Those probabilities sum to 1 and are generally called the posterior probabilities. Your question is somewhat different, if this object was a member of group x, what is the probability that it would have values like these. These are typicality probabilities (how typical is this observation in this group). 

There are two ways to compute typicality probabilities. One is to use the reduced space defined by the discriminant functions and measure the distance of a new observation to the centroid of the group. This is the approach taken by SPSS which provides the typicality for the group which has the highest posterior probability. Huberty and Olejink recommend this procedure on the grounds that the probability distribution is known. The alternate approach which is used commonly in compositional analysis is to use Mahalanobis distance with the probability assumed to follow a chi square distribution. I am not aware of a package that has a function to produce either of these.

Huberty, Carl J. and Stephen Olejink. 2006. Applied Manova and Discriminant Analysis. Second Edition. Wiley-Interscience.

David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Fraser D. Neiman
Sent: Friday, August 29, 2014 4:14 PM
To: r-help at r-project.org
Subject: [R] posterior probabilities from lda.predict

Dear All,

I have used the lda() function in the MASS library to estimate a set of discriminant functions to assign samples from a training set to one of six groups.  The cross validation generates nearly perfect predictions for samples in the training set.  Hooray!

Now I want to use lda.predict() to estimate both discriminant function scores and probabilities of group membership for a second set of samples whose group membership is unknown.  For each unknown sample, lda.predict() produces a six probabilities. These probabilities sum to one. So lda.predict() seems to assume that the unknown samples do, in fact, belong to one of the six groups.  

The problem is that it is nearly certain that some of the unknown samples in the second set do not belong to any of the six groups. For those samples, probabilities of group membership should be close to zero for all six groups.  In fact, identifying which samples are unlikely to belong to any of the six groups is a major goal of the analysis. 

So the question is, what is lda.predict() doing behind the scenes to force the group membership probabilities to sum to one? How do I get it to not do this and produce probabilities that accurately reflect the large Mahalanobis distances of some of the unknown sample from any group centroid?\

I have searched the R-list archive on this and have found several folks asking similar questions, but no helpful answers.

Thanks very much!

Fraser
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Aug 31 04:38:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 Aug 2014 19:38:30 -0700
Subject: [R] Unexpected behavior when giving a value to a new variable
	basedon the value of another variable
In-Reply-To: <fabdf424437bc7b81f57bf6329ae0b33@www.webmail.co.za>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>,
	<c5647c24-15fa-4f14-8f68-02f7eeda5924@email.android.com>
	<fabdf424437bc7b81f57bf6329ae0b33@www.webmail.co.za>
Message-ID: <B17EA927-D125-4D1D-82A8-62139A4F01DF@comcast.net>


On Aug 29, 2014, at 8:54 PM, David McPearson wrote:

> On Fri, 29 Aug 2014 06:33:01 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us 
> >
> wrote
>
>> One clue is the help file for "$"...
>>
>> ?" $"
>>
>> In particular there see the discussion of character indices and the  
>> "exact"
>> argument.
>>
>
> <...snip...>
>>
>> On August 29, 2014 1:53:47 AM PDT, Angel Rodriguez
>> <angel.rodriguez at matiainstituto.net> wrote: >
>>> Dear subscribers,
>>>
>>> I've found that if there is a variable in the dataframe with a name
> <...sip...>
>>>> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58),  
>>>> V2 =
>>> c(NA, 1, 1, 1, 1,1,1,1,NA)),
>>> +                     .Names = c("age","samplem"), row.names = c(NA,
>>> -9L), class = "data.frame")
>>>> N$sample[N$age >= 65] <- 1
>>>> N
>>> age samplem sample
>>> 1  67      NA      1
>>> 2  62       1      1
>>> 3  74       1      1
>>> 4  61       1      1
>>> 5  60       1      1
>>> 6  55       1      1
>>> 7  60       1      1
>>> 8  59       1      1
>>> 9  58      NA     NA
> <...snip...>
>
> Having seen all the responses about partial matching I almost  
> understand. I've
> also replicated the behaviour on R 2.11.1 so it's been around  
> awhile. This
> tells me it ain't a bug - so if any of the cognoscenti have the time  
> and
> inclination can someone give me a brief (and hopefully simple)  
> explanation of
> what is going on under the hood?
>
> It looks (to me) like N$sample[N$age >= 65] <- 1 copies N$samplem to  
> N$sample
> and then does the assignment. If partial matching is the problem  
> (which it
> clearly is) my expectation is that  the  output should look like
>
>   age samplem
> 1   67       1
> 2   62       1
> 3   74       1
> 4   61       1
> 5   60       1
> 6   55       1
> 7   60       1
> 8   59       1
> 9   58      NA
> That is - no new column.
> (and I just hate it when the world doesn't live up to my  
> expectations!)

Not sure what you are seeing. I am seeing what you expected:

 > test <- data.frame(age=1:10, sample=1)
 > test$sample[test$age<5] <- 2
 > test
    age sample
1    1      2
2    2      2
3    3      2
4    4      2
5    5      1
6    6      1
7    7      1
8    8      1
9    9      1
10  10      1

-- 
David
>
> Bewildered and confused,
> DMcP
>
> ____________________________________________________________
> South Africas premier free email service - www.webmail.co.za
>
> Cotlands - Shaping tomorrows Heroes http://www.cotlands.org.za/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From tal.galili at gmail.com  Sun Aug 31 06:03:16 2014
From: tal.galili at gmail.com (Tal Galili)
Date: Sun, 31 Aug 2014 07:03:16 +0300
Subject: [R] Split PVClust plot
In-Reply-To: <C1A5238848713043B7C18ED38FFEF1F812B962DA@STWMB01.ad.okstate.edu>
References: <C1A5238848713043B7C18ED38FFEF1F812B962DA@STWMB01.ad.okstate.edu>
Message-ID: <CANdJ3dVrywbapRQLQf1Ht3-OhROEro+xZr8hSsXK61gnoprMMQ@mail.gmail.com>

Hi Tom,

There is a "as.dendrogram.pvclust" function in the package dendextend.
(it is on CRAN: http://cran.r-project.org/web/packages/dendextend/)

You can run:

install.packages('dendextend')
library(dendextend)
result2  <- as.dendrogram(result)
# You can then also use the "prune" function in dendextend, to get the
subtree you are interested in.

Also, there is an example of pvclust in the package vignette (just
search pvclust
here):
http://cran.r-project.org/web/packages/dendextend/vignettes/introduction.html
The example shows how to highlight significant branches (with line width
and color).

With regards,
Tal






----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------



On Tue, Jul 29, 2014 at 12:40 AM, Worthington, Thomas A <
thomas.worthington at okstate.edu> wrote:

> Dear All
>
> I'm using PVClust to perform hierarchical clustering, for the output plot
> I can control most of the graphical I need, however the plot is large and I
> would like to split it vertically into two panels one above the other. Is
> there a way to plot only part of a PVClust plot, I tried to convert it to a
> dendrogram with
>
> result2  = as.dendrogram(result)
>
> however I get the error message "no applicable method for 'as.dendrogram'
> applied to an object of class "pvclust". I also wondered whether it would
> be possible to convert to a phylogenetic tree and use the functions in the
> 'ape' package?
>
> Any suggestion on how to split up a PVclust plot would be greatly
> appreciated  (code for the plot below)
>
> Thanks
> Tom
>
>
> result <- pvclust(df.1, method.dist="uncentered",
> method.hclust="average",nboot=10)
> par(mar=c(0,0,0,0))
> par(oma=c(0,0,0,0))
> plot(result, print.pv =FALSE, col.pv=c("red","",""), print.num=FALSE,
> float = 0.02, font=1,
>         axes=T, cex =0.85, main="", sub="", xlab="", ylab= "",
> labels=NULL, hang=-1)
> pvrect(result, alpha=0.95)
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Aug 31 06:28:58 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 30 Aug 2014 21:28:58 -0700
Subject: [R] Unexpected behavior when giving a value to a new variable
	basedon the value of another variable
In-Reply-To: <B17EA927-D125-4D1D-82A8-62139A4F01DF@comcast.net>
References: <8564BCD7D26E0D40872F1A132C8BBB250258B239@MATIAEXCH.matiaf.local>,
	<c5647c24-15fa-4f14-8f68-02f7eeda5924@email.android.com>
	<fabdf424437bc7b81f57bf6329ae0b33@www.webmail.co.za>
	<B17EA927-D125-4D1D-82A8-62139A4F01DF@comcast.net>
Message-ID: <654AE3E7-D607-4351-9735-D380CD0DAE57@comcast.net>


On Aug 30, 2014, at 7:38 PM, David Winsemius wrote:

>
> On Aug 29, 2014, at 8:54 PM, David McPearson wrote:
>
>> On Fri, 29 Aug 2014 06:33:01 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us 
>> >
>> wrote
>>
>>> One clue is the help file for "$"...
>>>
>>> ?" $"
>>>
>>> In particular there see the discussion of character indices and  
>>> the "exact"
>>> argument.
>>>
>>
>> <...snip...>
>>>
>>> On August 29, 2014 1:53:47 AM PDT, Angel Rodriguez
>>> <angel.rodriguez at matiainstituto.net> wrote: >
>>>> Dear subscribers,
>>>>
>>>> I've found that if there is a variable in the dataframe with a name
>> <...sip...>
>>>>> N <- structure(list(V1 = c(67, 62, 74, 61, 60, 55, 60, 59, 58),  
>>>>> V2 =
>>>> c(NA, 1, 1, 1, 1,1,1,1,NA)),
>>>> +                     .Names = c("age","samplem"), row.names =  
>>>> c(NA,
>>>> -9L), class = "data.frame")
>>>>> N$sample[N$age >= 65] <- 1
>>>>> N
>>>> age samplem sample
>>>> 1  67      NA      1
>>>> 2  62       1      1
>>>> 3  74       1      1
>>>> 4  61       1      1
>>>> 5  60       1      1
>>>> 6  55       1      1
>>>> 7  60       1      1
>>>> 8  59       1      1
>>>> 9  58      NA     NA
>> <...snip...>
>>
>> Having seen all the responses about partial matching I almost  
>> understand. I've
>> also replicated the behaviour on R 2.11.1 so it's been around  
>> awhile. This
>> tells me it ain't a bug - so if any of the cognoscenti have the  
>> time and
>> inclination can someone give me a brief (and hopefully simple)  
>> explanation of
>> what is going on under the hood?
>>
>> It looks (to me) like N$sample[N$age >= 65] <- 1 copies N$samplem  
>> to N$sample
>> and then does the assignment. If partial matching is the problem  
>> (which it
>> clearly is) my expectation is that  the  output should look like
>>
>>  age samplem
>> 1   67       1
>> 2   62       1
>> 3   74       1
>> 4   61       1
>> 5   60       1
>> 6   55       1
>> 7   60       1
>> 8   59       1
>> 9   58      NA
>> That is - no new column.
>> (and I just hate it when the world doesn't live up to my  
>> expectations!)
>
> Not sure what you are seeing. I am seeing what you expected:
>
> > test <- data.frame(age=1:10, sample=1)
> > test$sample[test$age<5] <- 2
> > test
>   age sample
> 1    1      2
> 2    2      2
> 3    3      2
> 4    4      2
> 5    5      1
> 6    6      1
> 7    7      1
> 8    8      1
> 9    9      1
> 10  10      1


I realized later that I had not constructed a test of you behavior and  
that when I did I see the creation of a third column. The answer is to  
read the help page:

?`[<-`

"Character indices can in some circumstances be partially matched (see  
pmatch) to the names or dimnames of the object being subsetted (but  
never for subassignment). "

Note the caveat in parentheses.

-- 

David Winsemius, MD
Alameda, CA, USA


From rhelpmaillist at 163.com  Sun Aug 31 07:04:29 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sun, 31 Aug 2014 13:04:29 +0800 (CST)
Subject: [R] what happened when copying a function definition into R prompt
 then press Enter?
Message-ID: <19e264b.2ccd.1482a733fcd.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? ? That's to say,what happened when loading source code ?into memory? what's the difference between it and loading installed code into memory? Do they related with .Rdata?
? ?
? ? ? ?




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From ruipbarradas at sapo.pt  Sun Aug 31 13:31:11 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 31 Aug 2014 12:31:11 +0100
Subject: [R] help.start() has a faulty link
Message-ID: <5403077F.20306@sapo.pt>

Hello,

With 'help.start()' an HTML browser interface to help pops up.
In the section 'Miscellaneous Material' if you click on 'User Manuals' 
an error occurs:

Error in vignettes[i, "PDF"] : subscript out of bounds

Is this a bug? A missing link?

Rui Barradas


From marc_grt at yahoo.fr  Sun Aug 31 15:49:42 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 31 Aug 2014 15:49:42 +0200
Subject: [R] Not display message when using system()
In-Reply-To: <CAFDcVCQ0wm0g1tsNBDR6sTbobiAm-CaiFysd8=mOEtzfHSv0pQ@mail.gmail.com>
References: <5400D26F.7050709@yahoo.fr>
	<CAFDcVCQ0wm0g1tsNBDR6sTbobiAm-CaiFysd8=mOEtzfHSv0pQ@mail.gmail.com>
Message-ID: <540327F6.3060205@yahoo.fr>

Dear Henrik and list-members,

Thanks for your proposition but it is the same:

For example, no error message but no result:
 > pathfile <- system2(command="find", args="$HOME -type f -name 
'PuertoSanJose.csv'", stderr = FALSE, stdout="")
/Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
 > pathfile
[1] 1

Example 2 with error message but I get the result !
 > pathfile <- system2(command="find", args="$HOME -type f -name 
'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)
Message d'avis :
l'ex?cution de la commande ''find' $HOME -type f -name 
'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1
 > pathfile
[1] "/Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv"
attr(,"status")
[1] 1

I try another solution with options(warn=2) and try(xxx, silent=TRUE) to 
convert the warning in error and mask the error, but I cannot get the 
result anymore:
 > options(warn=2)
 > pathfile <- try(system2(command="find", args="$HOME -type f -name 
'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE), silent=TRUE)
 > pathfile
[1] "Error : (converti depuis l'avis) l'ex?cution de la commande ''find' 
$HOME -type f -name 'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError: (converti depuis l'avis) l'ex?cution de la commande 
''find' $HOME -type f -name 'PuertoSanJose.csv' 2>/dev/null' renvoie un 
statut 1>

I try also this combinations but without success:
 > pathfile <- ""
 > try(assign("pathfile", system2(command="find", args="$HOME -type f 
-name 'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE), 
envir=globalenv()), silent=TRUE)
 > pathfile
[1] ""
 > try({pathfile <<- system2(command="find", args="$HOME -type f -name 
'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)}, silent=TRUE)
 > pathfile
[1] ""

Sooo... any other idea ?

Thanks a lot

Marc

Le 29/08/2014 22:33, Henrik Bengtsson a ?crit :
>
> As a start try to use system2() instead and look at its argument for 
> how to capture stdout and/or stderr. It's a neater function.
>
> It may be that those messages cannot be captured easily, but hopefully 
> they are.
>
> My $0.02
>
> Henrik
>
> On Aug 29, 2014 12:21 PM, "Marc Girondot" <marc_grt at yahoo.fr 
> <mailto:marc_grt at yahoo.fr>> wrote:
>
>     Dear list members,
>
>     My question concerns the use of system() in R version 3.1.1
>     patched and MacosX 10.9.4.
>     I want capture the result of a system command without displaying
>     error message. I give exemple.
>
>     In terminal, if I do this command:
>     find $HOME -type f -name 'PuertoSanJose.csv'
>
>     I get the correct answer but also a message about Permission
>     denied for one directory:
>     /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>     find: /Users/marc/Library/Saved Application
>     State/com.adobe.flashplayer.installmanager.savedState/data.data:
>     Permission denied
>
>     I want get the output of this command in R; then I do:
>     > pathfile <- system("find $HOME -type f -name
>     'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE)
>     Message d'avis :
>     l'ex?cution de la commande 'find $HOME -type f -name
>     'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1
>
>     In pathfile, I have the correct answer but I have also a message
>     that I don't want.
>
>     My question is then: How to prevent display this message?
>
>     I try the following:
>     > pathfile <- capture.output(system("find $HOME -type f -name
>     'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
>     Message d'avis :
>     l'ex?cution de la commande 'find $HOME -type f -name
>     'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1
>
>     The same
>
>     I try also:
>     > pathfile <- suppressMessages(system("find $HOME -type f -name
>     'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
>     Message d'avis :
>     l'ex?cution de la commande 'find $HOME -type f -name
>     'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1
>
>     The same
>
>     The only solution to not see this message is:
>     > pathfile <- system("find $HOME -type f -name
>     'PuertoSanJose.csv'", intern=FALSE, ignore.stderr = TRUE)
>     /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>     > pathfile
>     [1] 1
>
>     But pathfile does not capture the output.
>
>     And the use of capture.output() does not help:
>     > pathfile <- capture.output(system("find $HOME -type f -name
>     'PuertoSanJose.csv'", intern=FALSE, ignore.stderr = TRUE))
>     /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>     > pathfile
>     character(0)
>
>
>     I really don't know how to not see this message...
>     If someone knows, I will appreciate !
>
>     Marc
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From mei_yuan at dragon.nchu.edu.tw  Sun Aug 31 16:52:24 2014
From: mei_yuan at dragon.nchu.edu.tw (mei_yuan)
Date: Sun, 31 Aug 2014 22:52:24 +0800 (CST)
Subject: [R] estimation for growth incidence curve
Message-ID: <1409496744.1395.mei_yuan@dragon.nchu.edu.tw>

Hi,

Is there anyone who knows about estimating growth incidence curve with R?

Mei-Yuan 

Dept. of Finance
National Chung Hsing University 


From spencer.graves at structuremonitoring.com  Sun Aug 31 17:22:16 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 31 Aug 2014 08:22:16 -0700
Subject: [R] estimation for growth incidence curve
In-Reply-To: <1409496744.1395.mei_yuan@dragon.nchu.edu.tw>
References: <1409496744.1395.mei_yuan@dragon.nchu.edu.tw>
Message-ID: <54033DA8.9070607@structuremonitoring.com>

On 8/31/2014 7:52 AM, mei_yuan wrote:
> Hi,
>
> Is there anyone who knows about estimating growth incidence curve with R?


library(sos)
(gi <-findFn('growth incidence') # 11 links in 4 packages
(gc <- findFn("growth curve") # 253 links in 96 packages
g. <- gi|gc
writeFindFn2xls(g.)
# writes an Excel workbook to getwd();
# first sheet = package summary;
# see package vignette
installPackages(g.)
writeFindFn2xls(g.) # produces a more informative package summary


       hope this helps.
       Spencer


>
> Mei-Yuan
>
> Dept. of Finance
> National Chung Hsing University
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com

      type="cite">
      <pre wrap="">

Mei-Yuan 

Dept. of Finance
National Chung Hsing University 

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
</pre>
    </blockquote>
    <br>
    <br>
    <pre class="moz-signature" cols="72">-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com
</pre>
  </body>
</html>


From ripley at stats.ox.ac.uk  Sun Aug 31 18:19:39 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 31 Aug 2014 17:19:39 +0100
Subject: [R] help.start() has a faulty link
In-Reply-To: <5403077F.20306@sapo.pt>
References: <5403077F.20306@sapo.pt>
Message-ID: <54034B1B.9010901@stats.ox.ac.uk>

On 31/08/2014 12:31, Rui Barradas wrote:
> Hello,
>
> With 'help.start()' an HTML browser interface to help pops up.
> In the section 'Miscellaneous Material' if you click on 'User Manuals'
> an error occurs:
>
> Error in vignettes[i, "PDF"] : subscript out of bounds
>
> Is this a bug? A missing link?

We have very little idea: you have not told us the 'at a minumum' 
information required in the posting guide.

But it works for me in R 3.1.1: most likely there is a bug in the way 
you installed R (whatever that was ...).  For example, maybe you did not 
install the vignette PDFs ....

>
> Rui Barradas
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From hb at biostat.ucsf.edu  Sun Aug 31 18:31:44 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 31 Aug 2014 09:31:44 -0700
Subject: [R] Not display message when using system()
In-Reply-To: <540327F6.3060205@yahoo.fr>
References: <5400D26F.7050709@yahoo.fr>
	<CAFDcVCQ0wm0g1tsNBDR6sTbobiAm-CaiFysd8=mOEtzfHSv0pQ@mail.gmail.com>
	<540327F6.3060205@yahoo.fr>
Message-ID: <CAFDcVCRCJpj8QeLhOeqEmuSgVLA1S+x9yOiED_-Fqzhj_-rBdw@mail.gmail.com>

On Sun, Aug 31, 2014 at 6:49 AM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> Dear Henrik and list-members,
>
> Thanks for your proposition but it is the same:
>
> For example, no error message but no result:
>> pathfile <- system2(command="find", args="$HOME -type f -name
>> 'PuertoSanJose.csv'", stderr = FALSE, stdout="")
> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>> pathfile
> [1] 1

Yes as documented in Section 'Value' of help("system2"); "In other
cases, the return value is an error code...".

>
> Example 2 with error message but I get the result !
>> pathfile <- system2(command="find", args="$HOME -type f -name
>> 'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)
>
> Message d'avis :
> l'ex?cution de la commande ''find' $HOME -type f -name 'PuertoSanJose.csv'
> 2>/dev/null' renvoie un statut 1
>> pathfile
> [1] "/Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv"
> attr(,"status")
> [1] 1

Yes you capture the standard output as documented also in Section
'Value'; "If stdout = TRUE or stderr = TRUE, a character vector giving
the output of the command...".  You also explicitly say you want to
discard any output that the 'find' command sends to standard error
(technical details: that is why that "2>/dev/null" is part of the
call) - if you would have used stderr=TRUE, then an such messages
would be interweaved into the returned value ('pathname').

More from Section 'Value': "If command runs but gives a non-zero exit
status this will be reported with a warning and in the attribute
"status" of the result: an attribute "errmsg" may also be available."
 This explains why you get a warning ("Message d'avis"); the 'status'
of the call is 1.  I don't know why 'find' does that, that is
something 'man find' would explain.

However, since you now properly capture 'pathname' and you get a
warning in R, all you have to do is to suppress that warnings in R.
Use suppressWarning() to do that, e.g.

pathfile <- suppressWarning(system2(command="find", args="$HOME -type
f -name 'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE))

The following also works:

suppressWarning({
  pathfile <- system2(command="find", args="$HOME -type f -name
'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)
})

>
> I try another solution with options(warn=2) and try(xxx, silent=TRUE) to
> convert the warning in error and mask the error, but I cannot get the result
> anymore:
>> options(warn=2)

This will force R to turn a warning into an error as soon as the
warning is generated.

>> pathfile <- try(system2(command="find", args="$HOME -type f -name
>> 'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE), silent=TRUE)
>> pathfile
> [1] "Error : (converti depuis l'avis) l'ex?cution de la commande ''find'
> $HOME -type f -name 'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1\n"
> attr(,"class")
> [1] "try-error"
> attr(,"condition")
> <simpleError: (converti depuis l'avis) l'ex?cution de la commande ''find'
> $HOME -type f -name 'PuertoSanJose.csv' 2>/dev/null' renvoie un statut 1>

...so then you decide to catch that error.  This also works as
expected.  system2() generates a warning which is turned into an error
which causes system2() to pre-emptively exit/return and try() captures
that and generates a return object explaining what happened.  Note
that system2() never returns anything.  This is more clear if you
would use:

pathfile <- "not yet assigned"
res <- try({
  pathfile <- system2(command="find", args="$HOME -type f -name
'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)
}, silent=TRUE)

Here 'pathfile' would still be "not yet assigned" and 'res' would
contain "Error : (converti depuis l'avis) l'ex?cution de la commande
''find' ..." (as above).
>
> I try also this combinations but without success:
>> pathfile <- ""
>> try(assign("pathfile", system2(command="find", args="$HOME -type f -name
>> 'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE), envir=globalenv()),
>> silent=TRUE)
>> pathfile
> [1] ""

This is no difference from:

pathfile <- ""
res <- try({
  pathfile <- system2(command="find", args="$HOME -type f -name
'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)
}, silent=TRUE)

So, as above.


>> try({pathfile <<- system2(command="find", args="$HOME -type f -name
>> 'PuertoSanJose.csv'", stderr = FALSE, stdout=TRUE)}, silent=TRUE)
>> pathfile
> [1] ""

Very similar.  FYI, if you ever find yourself using assign() or '<<-'
that's a pretty good sign you're out on dangerous waters and you're
most likely are doing something wrong (unless you really really really
really really know what you're doing).  In such cases, ask for help...

>
> Sooo... any other idea ?

...as you did.

/Henrik

>
> Thanks a lot
>
> Marc
>
> Le 29/08/2014 22:33, Henrik Bengtsson a ?crit :
>
> As a start try to use system2() instead and look at its argument for how to
> capture stdout and/or stderr. It's a neater function.
>
> It may be that those messages cannot be captured easily, but hopefully they
> are.
>
> My $0.02
>
> Henrik
>
> On Aug 29, 2014 12:21 PM, "Marc Girondot" <marc_grt at yahoo.fr> wrote:
>>
>> Dear list members,
>>
>> My question concerns the use of system() in R version 3.1.1 patched and
>> MacosX 10.9.4.
>> I want capture the result of a system command without displaying error
>> message. I give exemple.
>>
>> In terminal, if I do this command:
>> find $HOME -type f -name 'PuertoSanJose.csv'
>>
>> I get the correct answer but also a message about Permission denied for
>> one directory:
>> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>> find: /Users/marc/Library/Saved Application
>> State/com.adobe.flashplayer.installmanager.savedState/data.data: Permission
>> denied
>>
>> I want get the output of this command in R; then I do:
>> > pathfile <- system("find $HOME -type f -name 'PuertoSanJose.csv'",
>> > intern=TRUE, ignore.stderr = TRUE)
>> Message d'avis :
>> l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv'
>> 2>/dev/null' renvoie un statut 1
>>
>> In pathfile, I have the correct answer but I have also a message that I
>> don't want.
>>
>> My question is then: How to prevent display this message?
>>
>> I try the following:
>> > pathfile <- capture.output(system("find $HOME -type f -name
>> > 'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
>> Message d'avis :
>> l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv'
>> 2>/dev/null' renvoie un statut 1
>>
>> The same
>>
>> I try also:
>> > pathfile <- suppressMessages(system("find $HOME -type f -name
>> > 'PuertoSanJose.csv'", intern=TRUE, ignore.stderr = TRUE))
>> Message d'avis :
>> l'ex?cution de la commande 'find $HOME -type f -name 'PuertoSanJose.csv'
>> 2>/dev/null' renvoie un statut 1
>>
>> The same
>>
>> The only solution to not see this message is:
>> > pathfile <- system("find $HOME -type f -name 'PuertoSanJose.csv'",
>> > intern=FALSE, ignore.stderr = TRUE)
>> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>> > pathfile
>> [1] 1
>>
>> But pathfile does not capture the output.
>>
>> And the use of capture.output() does not help:
>> > pathfile <- capture.output(system("find $HOME -type f -name
>> > 'PuertoSanJose.csv'", intern=FALSE, ignore.stderr = TRUE))
>> /Users/marc/Dropbox/DropBoxPerso/Data_Ale/Original/PuertoSanJose.csv
>> > pathfile
>> character(0)
>>
>>
>> I really don't know how to not see this message...
>> If someone knows, I will appreciate !
>>
>> Marc
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From ruipbarradas at sapo.pt  Sun Aug 31 19:26:41 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 31 Aug 2014 18:26:41 +0100
Subject: [R] help.start() has a faulty link
In-Reply-To: <54034B1B.9010901@stats.ox.ac.uk>
References: <5403077F.20306@sapo.pt> <54034B1B.9010901@stats.ox.ac.uk>
Message-ID: <54035AD1.8050408@sapo.pt>

Hello,

Sorry, I forgot to include sessionInfo. It's R 3.1.1 on Windows 7.
As for the vignette PDFs, you're right, they are missing. I always use 
the default installation of the R for Windows binary file, shouldn't 
they also be installed?

sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Portugal.1252 
LC_CTYPE=Portuguese_Portugal.1252
[3] LC_MONETARY=Portuguese_Portugal.1252 LC_NUMERIC=C 

[5] LC_TIME=Portuguese_Portugal.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.1


Rui Barradas

Em 31-08-2014 17:19, Prof Brian Ripley escreveu:
> On 31/08/2014 12:31, Rui Barradas wrote:
>> Hello,
>>
>> With 'help.start()' an HTML browser interface to help pops up.
>> In the section 'Miscellaneous Material' if you click on 'User Manuals'
>> an error occurs:
>>
>> Error in vignettes[i, "PDF"] : subscript out of bounds
>>
>> Is this a bug? A missing link?
>
> We have very little idea: you have not told us the 'at a minumum'
> information required in the posting guide.
>
> But it works for me in R 3.1.1: most likely there is a bug in the way
> you installed R (whatever that was ...).  For example, maybe you did not
> install the vignette PDFs ....
>
>>
>> Rui Barradas
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From smileismystyl at gmail.com  Sun Aug 31 19:39:19 2014
From: smileismystyl at gmail.com (Girija Kalyani)
Date: Sun, 31 Aug 2014 23:09:19 +0530
Subject: [R] Rcurl error
Message-ID: <CAG1d=2ACK6oyOFee650V8JjiuTxMsr=boxyKfKFJN1SZLC+s=g@mail.gmail.com>

Any package I try to download and install,
I get the folloing error.
My configuration:
R-3.1.1
Windows-32 bit

Error in inDL(x, as.logical(local), as.logical(now), ...) :
  unable to load shared object 'C:/Program
Files/R/R-3.1.1/library/RCurl/libs/i386/RCurl.dll':
  LoadLibrary failure:  The specified procedure could not be found.

Thanx in advance

-- 
:) Smile is my Style :)

	[[alternative HTML version deleted]]


From dominic.roye at gmail.com  Sun Aug 31 21:37:34 2014
From: dominic.roye at gmail.com (Dominic Roye)
Date: Sun, 31 Aug 2014 21:37:34 +0200
Subject: [R] Netcdf
Message-ID: <CALvVS-GqNFUS7HJnA3QD34mMk-U3beQyg+EmMW8vV=HC8us3BA@mail.gmail.com>

Hello,

I have an issue with a conection to a ncdf file.

ftp://ftp.cdc.noaa.gov/Public/www/X91.116.178.214.242.12.49.49.nc

open.ncdf("X91.116.178.214.242.12.49.49.nc")
Error in R_nc_open: NetCDF: Unknown file format
Error in open.ncdf("X91.116.178.214.242.12.49.49.nc") :
  Error in open.ncdf trying to open file X91.116.178.214.242.12.49.49.nc


Anyone knows a solution?

Thanks,

	[[alternative HTML version deleted]]


From roy.mendelssohn at noaa.gov  Sun Aug 31 23:23:47 2014
From: roy.mendelssohn at noaa.gov (Roy Mendelssohn)
Date: Sun, 31 Aug 2014 14:23:47 -0700
Subject: [R] Netcdf
In-Reply-To: <CALvVS-GqNFUS7HJnA3QD34mMk-U3beQyg+EmMW8vV=HC8us3BA@mail.gmail.com>
References: <CALvVS-GqNFUS7HJnA3QD34mMk-U3beQyg+EmMW8vV=HC8us3BA@mail.gmail.com>
Message-ID: <F7221F8F-F611-484D-B33B-D7DDC4C4774A@noaa.gov>

Not enough information to be of much help.  it is unclear if you downloaded the file and failed to open from your computer, or if you are trying to connect to a remote file.

If the former, when I click on the URL you posted, I get an error, but when I correct the URL I get a proper file so the file may not have been downloaded properly.  And, the file type is netCDF-4 classic model, which may not be supported by ncdf  (ncdf is deprecated, try using ncdf4).

If the latter (a remote file), ncdf can open remote files served by OPeNDAP, but that is not in what you gave.

HTH,

-Roy M.
 
On Aug 31, 2014, at 12:37 PM, Dominic Roye <dominic.roye at gmail.com> wrote:

> Hello,
> 
> I have an issue with a conection to a ncdf file.
> 
> ftp://ftp.cdc.noaa.gov/Public/www/X91.116.178.214.242.12.49.49.nc
> 
> open.ncdf("X91.116.178.214.242.12.49.49.nc")
> Error in R_nc_open: NetCDF: Unknown file format
> Error in open.ncdf("X91.116.178.214.242.12.49.49.nc") :
>  Error in open.ncdf trying to open file X91.116.178.214.242.12.49.49.nc
> 
> 
> Anyone knows a solution?
> 
> Thanks,
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

**********************
"The contents of this message do not reflect any position of the U.S. Government or NOAA."
**********************
Roy Mendelssohn
Supervisory Operations Research Analyst
NOAA/NMFS
Environmental Research Division
Southwest Fisheries Science Center
***Note new address and phone***
110 Shaffer Road
Santa Cruz, CA 95060
Phone: (831)-420-3666
Fax: (831) 420-3980
e-mail: Roy.Mendelssohn at noaa.gov www: http://www.pfeg.noaa.gov/

"Old age and treachery will overcome youth and skill."
"From those who have been given much, much will be expected" 
"the arc of the moral universe is long, but it bends toward justice" -MLK Jr.


From ross at biostat.ucsf.edu  Thu Aug 28 01:08:55 2014
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 27 Aug 2014 16:08:55 -0700
Subject: [R] favorable mention and use of R on the net
Message-ID: <1409180935.9201.1.camel@localhost>

http://equitablegrowth.org/2014/08/26/moving-corrected-calculations-last-weeks-shiller-stock-market-posts-r-afternoon-note/
Begins 

> Because only people who really, really, really want to make bad
> mistakes do things in the un-debuggable Excel (or Numbers)?
> 
and then proceeds with an extended analysis in R.  He may have used
Excel in the earlier posts; the comment is certainly a reference to an
infamous series of errors in a spreadsheet behind a much publicized
claim that it was disastrous for countries to have debt > 90% GDP.  See
http://en.wikipedia.org/wiki/Growth_in_a_Time_of_Debt for details.

The background question to the blog post is whether current stock market
valuations indicate stocks are likely to be a poor medium-term
investment (10 years).

A quick look does not reveal to me what, if any, substantive changes to
the conclusions resulted from using R not Excel (or even if is previous
conclusions were based on Excel).  In fact, it's kind of hard to tell
what the conclusion is!


A couple of more technical comments:

DeLong (the post's author) uses simple regression (lm) and then observes

> The significance levels that R reports are wrong: its naive regression
> package assumes that each of the 1482 observed 10-year returns is
> independent of each of the others. They are not.
I assume R has some tools that can do proper time series analyses; I'm
not sure why he didn't use them.  DeLong is an economic historian, not
an econometrician.

One important observation stems from something even simpler than
regression:
> Basically what we know about expected returns is that on the one
> occasion when CAPE rose above 30, the dot-com crash of 2000 was in the
> near future and the housing crash of 2008 came into the ten-year
> return window. That is not much information on which to base a
> long-run "sell" decision.
> 
Ross Boylan


