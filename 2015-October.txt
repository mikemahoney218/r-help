From f.harrell at vanderbilt.edu  Thu Oct  1 00:48:58 2015
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Wed, 30 Sep 2015 17:48:58 -0500
Subject: [R] [R-pkgs] Major updates to Hmisc and rms packages
Message-ID: <560C66DA.7090803@vanderbilt.edu>

New versions of Hmisc and rms are available on CRAN.  Changes are listed 
below.

The most significant change to Hmisc is the addition of the ffCompress 
function that creates an optimal ff package object for large data frames 
by computing the maximum number of bits used by each numeric or logical 
variable in the data frame.  And the html.latex method now implements 
conversion of latex code generated by Hmisc to html for dynamic 
insertion in R Markdown documents (if you install the system package 
TeX4ht).

The most significant changes to rms are the correct handling of offset 
variables and updating the demos.
----------------------------------------------------------------------------------------------------------------------------

Hmisc Changes in version 3.17-0 (2015-09-20)
    * format.df (used by latex.default): added space after textless, 
textgreater
      * label: changed default for units to value of plot
      * getRs: replaced where argument with guser, grepo, gdir, dir to 
allow easy fetching of updated functions from Hmisc etc.
      * Separated sas.get source code from other .get functions and from 
upData/cleanup.import by putting into 3 separate files.  Moved stata.get 
into misc.get.s
      * upData: for Stat/Transfer exported R workspaces, change 
variables into factors to incorporate value labels when present; added 
subset argument and reporting of number of observations pre and post 
subsetting
      * latex.default: added comma after botcap directive for ctable.  
Thanks: Paul Trowbridge
    * Hmisc-internal.Rd: removed  alias{[.terms}
      * latex.default: for longtable when no caption is given, subtract 
one from table counter
      * latex.summaryM: quit ignoring insert.bottom if it is a character 
string (thanks: JoAnn Alvarez)
      * minor.tick: revised version by Earl Belllinger that fixes 
problem reported in https://github.com/harrelfe/Hmisc/issues/28
      * several functions: used new names when assigning temporary functions
      * NAMESPACE: add imports to base functions to avoid new R CMD 
CHECK warnings
      * ffCompress: new function
      * knitrSet: changed fig.path default to '' instead of NULL to work 
with knitr 1.11
      * html.latex: added argument rmarkdown
      * htmltools: added to suggests in DESCRIPTION
      * tests: new test script latex-html.Rmd for latex -> html under 
Rmarkdown/knitr/Rstudio, new test for cut2
      * plsmo, panel.plsmo: added method='intervals', mobs, ifun arguments


rms Changes in version 4.4-0 (2015-09-28)
    * contrast.rms: made SE a vector not a matrix, added 4 list logic 
for nvary, added new test from JoAnn Alvarez
      * plot.summary.rms: correct bug where pch was ignored.  Thanks: 
Tamas Ferenci
      * prModFit: fix print(fit, latex=FALSE) when fit is result of 
robcov, bootcov
      * NAMESPACE: added imports for base functions used to avoid 
warnings with R CMD CHECK; new test rcs.r
      * prModFit: added rmarkdown argument.  All print.* methods can 
pass this argument.
      * All print methods for fit objects: left result as prModFit 
instead of invisible() so that rmarkdown will work
      * demo/all.R: updated for plot and ggplot methods, npsurv
      * cph, predictrms, rms, rms.trans, rmsMisc: changed Design 
function to return new objects sformula (formula without cluster()) and 
mmcolnames which provides a new way to get rid of strat() main effects 
and interactions involving non-reference cells; handle offsets in cph 
and predict() (not yet in Predict); new internal function 
removeFormulaTerms that does character manipulation to remove terms like 
cluster() or offset() or the dependent variable(s).  This gets around 
the problem with [.terms messing up offset terms when you subset on 
non-offset terms
      * Glm, ols: fixed offset
      * bj, Gls, lrm, orm, psm, Rq: change to new offset method and sformula
      * Predict: added offset=list(offsetvariable=value)
      * several: made temporary function names unique to avoid warnings 
with R CMD CHECK
      * ggplot.Predict: changed facet_wrap_labeller to not mess with 
class of returned object from ggplotGrob
      * Design: fixed column names for matrix predictors
      * Design, cph: handled special case where model is fit on a fit$x 
matrix
      * dxy.cens: exported
      * cph: added debug argument
      * tests/cph4.r: new tests for various predictor types
      * rms: changed warning to error if an ordered factor appears in 
the model and options(contrasts) is not set properly
      * rms transformation functions: made more robust by checking ! 
length instead of is.null


-- 
------------------------------------------------------------------------
Frank E Harrell Jr 	Professor and Chairman 	School of Medicine

	Department of *Biostatistics* 	*Vanderbilt University*


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From putra_autumn86 at yahoo.com  Thu Oct  1 04:47:14 2015
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Thu, 1 Oct 2015 02:47:14 +0000 (UTC)
Subject: [R] Count number of rain more than zero in matrix form
Message-ID: <233989687.2807383.1443667634271.JavaMail.yahoo@mail.yahoo.com>

Hello R-users,
I want to ask how to count the number of daily rain data.? My data using dput() as below:
structure(list(Year = c(1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L), Month = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L), Amount = c(0.3, 0, 0, 0, 0, 2.7, 7.1, 14, 
12.6, 11.1, 5.5, 1.2, 1.2, 1, 5.3, 2.5, 0, 0, 0.5, 14.6, 130.4, 
66.5, 4.1, 3.7, 1.4, 2, 9.1, 8.8, 7.4, 2.5, 0, 0, 0, 10.1, 5.5, 
6.8, 6.3, 1.5, 0, 0, 0, 0, 0, 2.5, 11.7, 6.2, 0.5, 0.7, 0.3, 
2.5, 2.3, 1, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 16.2, 18.6, 15.2, 48.3, 26.7, 2.9, 0.2, 0, 0, 
0, 0, 0, 1.1, 1.4, 0.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.1, 
2.5, 5.2, 2.6, 0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 6.1, 4.7, 2.8, 
1, 0.5, 1.6, 2.1, 0.7, 0, 6.4, 3.5, 0.2, 0, 0, 0, 0, 0, 0, 0, 
21.3, 10.7, 2, 4.2, 1.9, 2.8, 21.1, 9.9, 0.7, 2, 10.4, 5.3, 29.6, 
14.7, 0, 0, 0, 4.4, 2.2, 0, 0, 0.8, 0.4, 0, 3.3, 3.1, 1.9, 0.6, 
0, 4.7, 2.4, 0, 0, 0, 0, 5.9, 25.7, 11.4, 0, 0, 0, 0, 2.7, 1.3, 
0, 0, 0, 0, 0, 0, 5.9, 28.1, 12.6, 68.2, 34.4, 0.6, 8.2, 4.3, 
0.2, 17.9, 30.6, 21.1, 5.1, 0, 0, 0.1, 3.6, 8.7, 8.9, 6.7, 13.7, 
10, 2.1, 11.8, 5.9, 0, 0, 0, 0, 0, 19.5, 31.1, 38.3, 20, 3.1, 
5.1, 6.4, 12.4, 5.2, 2.5, 9, 4, 0.1, 0.1, 0.5, 17, 8.8, 0.6, 
0.2, 0, 0, 0, 40.3, 20.1, 5.1, 14.3, 20.2, 13.2, 4.8, 1.4, 0.2, 
0, 1, 0.5, 0, 0, 0, 3.7, 1.8, 15.4, 7.7, 0, 3.9, 8, 3, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 45.5, 22.8, 9.9, 5, 4.4, 2.7, 0.2, 
0.8, 3.4, 10.3, 6.2, 7.5, 7.3, 20.3, 22, 28.9, 31.7, 39.2, 14.5, 
10.5, 34.8, 43.7, 43.5, 144.9, 143, 68, 18.2, 1.8, 0.5, 16.1, 
15.5, 3.8, 51.6, 25.8, 0.7, 1.5, 13.8, 27.2, 10.3, 1.5, 1.7, 
5.9, 12, 4.6, 1.7, 6.4, 11.7, 16.5, 38.3, 35.8, 16.7, 3.5, 1.8, 
35.9, 58.1, 40.9, 15, 14.5, 6.1, 0, 0, 3.3, 13.5, 6.9, 1.2, 2.7, 
1.2, 15.2, 16, 12.5, 14.4, 9.3, 2.1, 2.5, 25.6, 96.8, 99.5, 39.9, 
23.9, 9.1, 1.7, 3.8, 12, 6.4, 15.4, 8.8, 1.5, 10.7, 26.5, 20.9, 
7.7, 1.7, 1.2, 0.8, 0.6, 1, 0.4, 0, 6.1, 3.5, 0.2, 0, 0, 0, 0.8, 
3.7, 12.8, 8.9, 5.3, 1.8, 0, 0, 0, 0, 0, 0, 0, 4.4, 2.2, 0, 0, 
5.1, 5.9, 10.6, 9.3, 7.6, 4.1, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 22.1, 11.1, 0, 0, 23.1, 25.4, 12.8, 
2.9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 11.8, 13.9, 6, 
19.9, 35.9, 13.2, 0, 0, 0, 0, 0, 0, 0, 0, 3.2, 1.6, 0.8, 16.6, 
8.1, 11.3, 5.8, 10.9, 7.1, 0.8, 0, 0, 0, 0, 11, 37.3, 18.9, 14.4, 
14.5, 4, 0, 0, 1, 0.5, 0.3, 3.7, 1.8, 0, 0, 0, 9.8, 4.9, 3, 1.5, 
0, 0, 0, 0, 0, 0, 7.6, 3.8, 0, 0, 2.3, 1.2, 2.5, 1.3, 0.8, 0.4, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27.1, 44.3, 17.4, 1.7, 0.3, 
0, 5.4, 2.7, 0, 2.5, 1.3, 0, 0, 4.4, 2.2, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0.5, 0.2, 0, 25, 12.5, 0, 7.4, 7.6, 1.9, 2.5, 1.3, 0, 
0, 35.9, 37.1, 20.6, 7.5, 1, 0, 0.1, 0.2, 3.1, 1.5, 0, 0, 0, 
0, 0, 12.7, 6.3, 0, 0, 0, 0.1, 4.8, 4.9, 2.1, 23.4, 11.5, 6.9, 
31.2, 36.9, 11.5, 32, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 
0.1, 0, 0, 6.7, 17, 25.8, 9.5, 6.4, 9.6, 10.3, 5.5, 36.5, 17.9, 
0.1, 0.3, 0.2, 14.2, 7.1, 0, 0, 21.5, 30.2, 10.1, 0.2, 0, 9.6, 
4.8, 2, 13.3, 13.2, 3.5, 13.7, 12.9, 33.5, 15.2, 0, 5.7, 5.2, 
1.2, 10.8, 51.9, 24.3, 1.8, 0.7, 4.9, 21.9, 17.5, 5, 4.4, 1.9, 
5.9, 2.9, 0, 8.1, 4, 0, 0.3, 15.7, 71.2, 116, 62.9, 48.5, 28.3, 
19.8, 35.7, 20.1, 9.8, 31.3, 32.6, 30.6, 28.4, 15.6, 4.8, 7.8, 
44.3, 29.7, 18.2, 6.8, 3.9, 6.5, 31.9, 45.1, 37.3, 14.9, 11.5, 
24.9, 25.3, 143.9, 101.9, 28.2, 21.7, 32.2, 13.8, 9.6, 28.9, 
12.6, 9.6, 30.5, 12.9, 1.5, 1.9, 0.9, 25.4, 46.4, 28.2, 22.2, 
10.8, 7.3, 3, 34.2, 84.8, 71, 28.7, 16.9, 62.1, 104.4, 89.8, 
42.9, 9.3, 3.1, 3.5, 2.1, 0.8, 0.2, 0, 0, 0, 5.1, 6.1, 5.8, 4, 
1, 4.4, 4.2, 6.1, 7.1, 2.3, 1.5, 2.5, 0.9, 0, 0, 0, 0, 0, 19.3, 
10.6, 0.6, 0.1, 0, 1.5, 3.3, 1.3, 3, 1.5, 0, 0.1, 0.1, 0, 0, 
0, 0, 0, 0, 0, 0, 0.3, 0.3, 0.5, 0.2, 0, 0, 0, 0.3, 1.6, 0.7, 
0, 0, 6.6, 13.6, 6.6, 4.1, 12.7, 31.4, 13.1, 0.1, 0, 0, 0, 0.5, 
0.4, 0.1, 0, 5.5, 2.8, 0, 0, 0, 0, 0, 0, 1.1, 25.4, 15.3, 16.6, 
7.6, 0, 0, 0.5, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 0, 5.4, 2.7, 
0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 0, 0, 0.5, 0.2, 32.7, 16.3, 0, 
12.9, 6.4, 0, 7.7, 4.2, 6, 2.9, 5.1, 2.7, 0.1, 0, 3.5, 1.8, 0, 
0, 8.9, 4.5, 0, 0, 0, 3.9, 1.9, 0, 0, 49.4, 25.7, 0.5, 0, 0, 
3.9, 1.9, 0.5, 0.2, 0, 31.6, 20.5, 14.5, 6.1, 0.7, 0.3, 0, 29.9, 
39, 12, 7.1, 3.5, 18.9, 9.9, 9.5, 4.6, 0, 1.3, 8.9, 4.1, 4.5, 
7.3, 2.5, 0, 0, 0, 18.9, 16.9, 19.8, 8, 3.3, 1.7, 8.4, 13.3, 
19.2, 7.3, 2, 6.2, 2.6, 0, 0, 0, 6.6, 3.3, 0.5, 0.2, 0, 0.8, 
34.2, 28.9, 28.3, 23.3, 6.1, 0, 1, 0.5, 12.7, 9.2, 6.2, 20, 15.4, 
18.8, 28.7, 25.7, 14.2, 3.3, 30.1, 17.7, 23.3, 32.3, 18.7, 5.8, 
0.9, 13.9, 11.7, 2.4, 64.7, 54.3, 11.8, 1.1, 8.7, 4.2, 2.3, 31.1, 
16.6, 1.2, 5, 2.4, 0, 0, 0, 0, 18.9, 9.5, 10.1, 26.5, 10.9, 7, 
3.6, 26.8, 13.4, 7.4, 5.4, 0.8, 2.3, 2.5, 0.7, 0.3, 0.8, 0.7, 
0.3, 0.1, 0, 5.2, 4.3, 4, 17.3, 14.6, 24, 27, 22.6, 13, 29.8, 
30.8, 8.7, 25.7, 29.9, 36.3, 14.5, 0.3, 0, 0, 0, 0, 37.7, 29.3, 
13, 3.9, 1.1, 37.1, 18.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
6.9, 3.5, 26.1, 101, 51.1, 5.3, 8, 25, 109.7, 104.5, 90.3, 50.7, 
10.4, 0.5, 0.4, 1.5, 5.1, 4.5, 1.8, 0.3, 0, 0.8, 0.9, 55.8, 44.3, 
15.3, 10.3, 5.2, 8.3, 4.5, 4.4, 2, 0.3, 0.2, 0, 0, 25, 13.3, 
1.7, 33.3, 74.1, 29.3, 6.1, 15.6, 13.7, 4.2, 0.2, 0, 0, 0.1, 
0.1, 1, 0.8, 8.6, 11.8, 3.9, 0.2, 0.1, 10.3, 5.1, 0, 0.1, 0.1, 
0, 13.3, 9.9, 7, 3.7, 2, 0.7, 0, 0, 0, 0.3, 6.9, 3.5, 0.1, 0, 
0, 0, 1.7, 2.6, 0.9, 0, 0, 0.1, 0.1, 1.5, 0.7, 0, 0, 0, 1.1, 
3.8, 4.9, 2.3, 0.3, 2.7, 2.7, 0.7, 0, 0, 0.1, 0.1, 0.3, 0.2, 
0, 0, 0.5, 2, 1, 0.7, 0.3, 0, 1.8, 0.9, 1, 0.5, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.3, 16.2, 7.7, 0.1, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0.2, 
32, 16.8, 0.4, 0, 0.1, 0.1, 0, 6.7, 8.6, 2.6, 0, 6.2, 9, 9.9, 
3.5, 0, 3, 1.5, 0, 0, 0, 6.4, 3.2, 0, 0.5, 4.4, 2.1, 0, 2.7, 
9.7, 22.8, 10.3, 5.7, 2.6, 8.6, 23.8, 14.5, 2.4, 1.7, 0.8, 0, 
0, 0.3, 0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 4.4, 3.5, 0.7, 0, 0, 
0, 0, 0, 3.2, 1.6, 3.5, 1.8, 0.5, 12.2, 6.8, 1.9, 3.4, 7.7, 3.2, 
0, 6.9, 3.5, 44.7, 22.3, 0, 5.2, 2.6, 4.2, 6.1, 2, 0, 0, 0.5, 
0.2, 4.2, 2.1, 0, 4.9, 5, 2.4, 0.6, 0, 0, 10.5, 9.4, 6.6, 2.7, 
11.7, 20.4, 9.5, 39.2, 24.6, 5.8, 10.6, 17.4, 6.4, 0, 0, 0, 0, 
3.9, 3.7, 0.9, 0, 0, 0, 0, 9.8, 4.9, 1.5, 0.7, 0, 0, 0, 5.2, 
2.9, 0.2, 0.5, 0.2, 0.1, 0.7, 0.3, 3.9, 1.9, 4.2, 2.1, 0.7, 0.3, 
1, 6.7, 4.2, 35.1, 17.3, 7.9, 6.8, 1.4, 20.1, 23.6, 20.1, 6.7, 
0, 0.7, 2.5, 1.1, 2.3, 1.5, 0.2, 0, 0, 1.1, 0.7, 0.1, 4.2, 2.1, 
0.5, 0.2, 3.5, 19.8, 36.2, 58.5, 34.4, 6, 9.3, 16.1, 5.7, 4.4, 
4.2, 47.3, 63.2, 32.9, 10.1, 3.3, 0.7, 11.7, 49.3, 48.8, 27.5, 
32.5, 42.9, 37.9, 14.4, 18, 85.1, 42.3, 1.9, 0, 0, 0, 0, 2.5, 
8.9, 3.8, 0, 0, 0, 0, 15.2, 16.9, 20.8, 12.8, 6.8, 2.5, 1, 11.7, 
10.2, 2.3, 0, 0.3, 1.5, 1.1, 1.4, 2.2, 1.6, 0.4, 7.3, 12, 8.9, 
4.6, 1.2, 0.1, 0, 0, 0, 0.5, 9.4, 4.6, 0, 35.5, 17.8, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 21.3, 15.4, 3.2, 4.9, 9.9, 3.8, 0, 
0, 1.1, 30, 19.8, 6.2, 5.8, 15.9, 30.9, 25, 9.8, 1.7, 0, 0.7, 
2.9, 2.6, 2.7, 5.2, 3.8, 1.6, 4.4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 1.1, 1.9, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5, 118.1, 
100.7, 21.1, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0, 0, 0, 22, 11.5, 0.2, 
0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.5, 1.7, 0.8, 
0, 0, 0, 1.3, 32.3, 16.6, 0.4, 0, 0, 0, 1.3, 0.7, 0, 5.2, 2.6, 
0, 6.7, 10.8, 3.7, 0, 17.4, 8.7, 0, 0, 0.8, 1.4, 0.5, 0, 0, 0, 
10.5, 5.2, 12.9, 7.4, 0.5, 0, 9.6, 4.8, 0, 2, 2.1, 5, 2.2, 0, 
0, 0, 0, 0, 0, 0, 0, 14.3, 7.2, 0, 0, 0, 0, 0.5, 0.2, 1.7, 0.8, 
0, 8.3, 4.1, 0, 0, 4.4, 2.2, 0, 0, 0, 2.5, 1.3, 5.2, 3.6, 0.5, 
15.4, 8.2, 4.1, 2.3, 0.2, 0, 0, 0, 0, 8.9, 4.5, 1, 0.5, 3.3, 
1.7, 2.7, 12.5, 5.6, 23.3, 11.7, 0, 0, 0, 0.1, 0.1, 1.1, 0.6, 
6.6, 3.3, 21.1, 37.3, 13.4, 24.3, 12.2, 2.5, 1.3, 23.7, 16.9, 
3.5, 0.5, 0, 0, 0, 0, 0, 0, 9.3, 23.4, 9.4, 0, 0, 0, 0.5, 0.2, 
0, 0, 8.5, 4.2, 6.1, 19.9, 12.3, 9, 11.3, 4, 10.2, 5.1, 6.2, 
4.2, 0.6, 0.1, 11.5, 5.7, 0, 13.2, 19.5, 8.1, 0.8, 0, 1, 0.5, 
0, 0, 1.1, 0.6, 1.3, 0.7, 0, 6.1, 3.5, 0.2, 3.7, 1.8, 19.5, 30, 
10.1, 14.7, 7.3, 10.7, 5.3, 7.6, 4.6, 5.5, 2.9, 2.4, 7.8, 5.9, 
1.3, 2.7, 2.5, 1.2, 5.7, 32.3, 14.8, 0, 0, 0, 0, 0, 17.3, 8.6, 
1, 5.2, 3.8, 0.7, 11, 8.7, 2.4, 1.1, 17.9, 40.6, 16.2, 33.8, 
38.8, 28.7, 10.9, 12.3, 6.3, 2.5, 3.4, 1.2, 0.7, 5.2, 2.4, 3.9, 
6.7, 9.1, 3.5, 34.9, 19.4, 3.5, 1.7, 0.2, 0, 9.1, 5, 63.4, 31.6, 
21.5, 62.7, 31, 4.2, 3.4, 15.3, 11.7, 23.5, 13.1, 1.4, 4.3, 5.1, 
3.7, 1.1, 0, 0, 0, 0, 0, 2.2, 1.1, 0, 0, 0, 0, 2.3, 1.2, 0, 0.1, 
0.4, 0.2, 2.3, 1.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.5, 0.7, 0, 
0.1, 0.4, 10.3, 5.4, 0.6, 0.2, 0.5, 0.7, 0.2, 2.9, 4.6, 1.6, 
2.2, 1.2, 0.1, 0, 0, 0, 1.7, 0.8, 0, 0, 0, 0, 2, 58.5, 28.8, 
0.3, 0.2, 1.7, 0.8, 0, 1.3, 0.7, 0, 0.1, 2.3, 1.1, 0, 0, 0, 8.9, 
4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10.7, 5.3, 0, 0, 1.7, 0.8, 
0, 4.4, 2.2, 0, 0, 46.7, 23.4, 0, 0, 0, 2.3, 12.5, 31.9, 14.1, 
2.7, 1.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.4, 4, 
0.8, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8, 0.4, 1.1, 1.6, 0.5, 
4.9, 2.4, 0.3, 2.8, 3.5, 7.7, 20.4, 8.5, 15.2, 7.6, 17.4, 8.7, 
0, 7.6, 3.8, 2.3, 4.4, 8.3, 8.1, 2.4, 0, 5.9, 8, 3.2, 18.6, 9.1, 
0, 0, 18.6, 9.3, 0, 0, 0, 17.7, 12.7, 16.5, 31.3, 12, 2.7, 11.1, 
4.9, 16.9, 8.4, 0, 8.8, 6.2, 6.4, 6.1, 1.7, 1, 7.4, 4.5, 0.5, 
0, 3.2, 3.6, 3.2, 1.1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2.5, 21.5, 
11.9, 1, 0.1, 9.1, 5.6, 1.2, 11, 18.9, 6.8, 0, 0, 0, 0, 0, 0, 
0, 0, 7.4, 5, 6.9, 31.4, 14.1, 8.4, 4.5, 4.6, 2.2, 0, 1, 31.4, 
34.6, 9.6, 0, 1.1, 2, 0.7, 9.5, 5.2, 0.6, 10, 5.7, 5.3, 5.4, 
8.4, 3.5, 1, 1.6, 0.6, 2.2, 1.1, 0.5, 10, 10.8, 36.9, 17, 0, 
36.5, 18.3, 1.8, 0.9, 1, 0.5, 4.7, 4, 1.2, 0.2, 0, 0, 0, 5.5, 
30.7, 14, 0, 0, 0, 0.3, 0.2, 54.5, 27.2, 0, 0, 0, 0.5, 28.8, 
44.1, 80.8, 37.8, 2.4, 3, 1.5, 0.1, 23.2, 11.6, 0.1, 0.1, 11, 
25.1, 11.5, 0.8, 0, 3.5, 2.4, 3.5, 1.6, 0, 14, 9.7, 18.6, 10.4, 
0.9, 2, 20.1, 16.3, 9.4, 9.1, 17.7, 22.7, 15.1, 8.2, 11.5, 9.5, 
14.9, 18.9, 74.4, 124.4, 114.6, 241.6, 132.2, 114.4, 91.5, 22.4, 
71.2, 78.2, 45.8, 33.3, 41.7, 16, 0.6, 5.6, 3.5, 31.7, 54.2, 
77.8, 69.5, 37.7, 15.5, 19.6, 18.6, 30.1, 22.2, 18.6, 11.9, 9.1, 
18.5, 23, 15.1, 4.7, 1, 2.4)), .Names = c("Year", "Month", "Day", 
"Amount"), class = "data.frame", row.names = c(NA, -2192L))

i want the counting number of rain as follows:

??????????? Jan??????? Feb??????? Mar??? Apr??? May??? Jun??? Jul??? Aug??? Sep??? Oct??? Nov??? Dec
1960 ?????? x19611962196319641965


x = number of rain for > 0.000001

Thanks for your help. 
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Oct  1 08:38:12 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 1 Oct 2015 06:38:12 +0000
Subject: [R] Count number of rain more than zero in matrix form
In-Reply-To: <233989687.2807383.1443667634271.JavaMail.yahoo@mail.yahoo.com>
References: <233989687.2807383.1443667634271.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C42FA3@SRVEXCHMBX.precheza.cz>

Hi

Great that you used dput, bad that you send HTML email which somehow scrambled it.

2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
Error: unexpected numeric constant in:
"

I tried to find a way how to repair it but after inspecting 200 rows I gave up and made some fake data

mydat<-expand.grid(year=1960:1961, month=1:3, day=1:5, amount=1)
mydat$amount<-abs(rnorm(30))*10

Number of days with amount > 3 in whole dataset
> sum(mydat$amount>3)
[1] 24

Number of days with amount > 3 in each year and month.
> aggregate(mydat$amount>3, list(mydat$month, mydat$year), sum)
  Group.1 Group.2 x
1       1    1960 4
2       2    1960 3
3       3    1960 5
4       1    1961 4
5       2    1961 5
6       3    1961 3

HTH

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of smart
> hendsome
> Sent: Thursday, October 01, 2015 4:47 AM
> To: r-help at r-project.org
> Subject: [R] Count number of rain more than zero in matrix form
>
> Hello R-users,
> I want to ask how to count the number of daily rain data.  My data
> using dput() as below:
> structure(list(Year = c(1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L), Month = c(1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L), Amount = c(0.3, 0,
> 0, 0, 0, 2.7, 7.1, 14, 12.6, 11.1, 5.5, 1.2, 1.2, 1, 5.3, 2.5, 0, 0,
> 0.5, 14.6, 130.4, 66.5, 4.1, 3.7, 1.4, 2, 9.1, 8.8, 7.4, 2.5, 0, 0, 0,
> 10.1, 5.5, 6.8, 6.3, 1.5, 0, 0, 0, 0, 0, 2.5, 11.7, 6.2, 0.5, 0.7, 0.3,
> 2.5, 2.3, 1, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 16.2, 18.6, 15.2, 48.3, 26.7, 2.9, 0.2, 0, 0, 0, 0, 0, 1.1, 1.4, 0.4,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.1, 2.5, 5.2, 2.6, 0.3, 0.2, 1.7,
> 0.8, 0, 0, 0, 0, 6.1, 4.7, 2.8, 1, 0.5, 1.6, 2.1, 0.7, 0, 6.4, 3.5,
> 0.2, 0, 0, 0, 0, 0, 0, 0, 21.3, 10.7, 2, 4.2, 1.9, 2.8, 21.1, 9.9, 0.7,
> 2, 10.4, 5.3, 29.6, 14.7, 0, 0, 0, 4.4, 2.2, 0, 0, 0.8, 0.4, 0, 3.3,
> 3.1, 1.9, 0.6, 0, 4.7, 2.4, 0, 0, 0, 0, 5.9, 25.7, 11.4, 0, 0, 0, 0,
> 2.7, 1.3, 0, 0, 0, 0, 0, 0, 5.9, 28.1, 12.6, 68.2, 34.4, 0.6, 8.2, 4.3,
> 0.2, 17.9, 30.6, 21.1, 5.1, 0, 0, 0.1, 3.6, 8.7, 8.9, 6.7, 13.7, 10,
> 2.1, 11.8, 5.9, 0, 0, 0, 0, 0, 19.5, 31.1, 38.3, 20, 3.1, 5.1, 6.4,
> 12.4, 5.2, 2.5, 9, 4, 0.1, 0.1, 0.5, 17, 8.8, 0.6, 0.2, 0, 0, 0, 40.3,
> 20.1, 5.1, 14.3, 20.2, 13.2, 4.8, 1.4, 0.2, 0, 1, 0.5, 0, 0, 0, 3.7,
> 1.8, 15.4, 7.7, 0, 3.9, 8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45.5,
> 22.8, 9.9, 5, 4.4, 2.7, 0.2, 0.8, 3.4, 10.3, 6.2, 7.5, 7.3, 20.3, 22,
> 28.9, 31.7, 39.2, 14.5, 10.5, 34.8, 43.7, 43.5, 144.9, 143, 68, 18.2,
> 1.8, 0.5, 16.1, 15.5, 3.8, 51.6, 25.8, 0.7, 1.5, 13.8, 27.2, 10.3, 1.5,
> 1.7, 5.9, 12, 4.6, 1.7, 6.4, 11.7, 16.5, 38.3, 35.8, 16.7, 3.5, 1.8,
> 35.9, 58.1, 40.9, 15, 14.5, 6.1, 0, 0, 3.3, 13.5, 6.9, 1.2, 2.7, 1.2,
> 15.2, 16, 12.5, 14.4, 9.3, 2.1, 2.5, 25.6, 96.8, 99.5, 39.9, 23.9, 9.1,
> 1.7, 3.8, 12, 6.4, 15.4, 8.8, 1.5, 10.7, 26.5, 20.9, 7.7, 1.7, 1.2,
> 0.8, 0.6, 1, 0.4, 0, 6.1, 3.5, 0.2, 0, 0, 0, 0.8, 3.7, 12.8, 8.9, 5.3,
> 1.8, 0, 0, 0, 0, 0, 0, 0, 4.4, 2.2, 0, 0, 5.1, 5.9, 10.6, 9.3, 7.6,
> 4.1, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22.1,
> 11.1, 0, 0, 23.1, 25.4, 12.8, 2.9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0.3, 11.8, 13.9, 6, 19.9, 35.9, 13.2, 0, 0, 0, 0, 0, 0, 0, 0, 3.2, 1.6,
> 0.8, 16.6, 8.1, 11.3, 5.8, 10.9, 7.1, 0.8, 0, 0, 0, 0, 11, 37.3, 18.9,
> 14.4, 14.5, 4, 0, 0, 1, 0.5, 0.3, 3.7, 1.8, 0, 0, 0, 9.8, 4.9, 3, 1.5,
> 0, 0, 0, 0, 0, 0, 7.6, 3.8, 0, 0, 2.3, 1.2, 2.5, 1.3, 0.8, 0.4, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27.1, 44.3, 17.4, 1.7, 0.3, 0, 5.4, 2.7,
> 0, 2.5, 1.3, 0, 0, 4.4, 2.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0.2, 0,
> 25, 12.5, 0, 7.4, 7.6, 1.9, 2.5, 1.3, 0, 0, 35.9, 37.1, 20.6, 7.5, 1,
> 0, 0.1, 0.2, 3.1, 1.5, 0, 0, 0, 0, 0, 12.7, 6.3, 0, 0, 0, 0.1, 4.8,
> 4.9, 2.1, 23.4, 11.5, 6.9, 31.2, 36.9, 11.5, 32, 16, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0.1, 0.1, 0, 0, 6.7, 17, 25.8, 9.5, 6.4, 9.6, 10.3, 5.5,
> 36.5, 17.9, 0.1, 0.3, 0.2, 14.2, 7.1, 0, 0, 21.5, 30.2, 10.1, 0.2, 0,
> 9.6, 4.8, 2, 13.3, 13.2, 3.5, 13.7, 12.9, 33.5, 15.2, 0, 5.7, 5.2, 1.2,
> 10.8, 51.9, 24.3, 1.8, 0.7, 4.9, 21.9, 17.5, 5, 4.4, 1.9, 5.9, 2.9, 0,
> 8.1, 4, 0, 0.3, 15.7, 71.2, 116, 62.9, 48.5, 28.3, 19.8, 35.7, 20.1,
> 9.8, 31.3, 32.6, 30.6, 28.4, 15.6, 4.8, 7.8, 44.3, 29.7, 18.2, 6.8,
> 3.9, 6.5, 31.9, 45.1, 37.3, 14.9, 11.5, 24.9, 25.3, 143.9, 101.9, 28.2,
> 21.7, 32.2, 13.8, 9.6, 28.9, 12.6, 9.6, 30.5, 12.9, 1.5, 1.9, 0.9,
> 25.4, 46.4, 28.2, 22.2, 10.8, 7.3, 3, 34.2, 84.8, 71, 28.7, 16.9, 62.1,
> 104.4, 89.8, 42.9, 9.3, 3.1, 3.5, 2.1, 0.8, 0.2, 0, 0, 0, 5.1, 6.1,
> 5.8, 4, 1, 4.4, 4.2, 6.1, 7.1, 2.3, 1.5, 2.5, 0.9, 0, 0, 0, 0, 0, 19.3,
> 10.6, 0.6, 0.1, 0, 1.5, 3.3, 1.3, 3, 1.5, 0, 0.1, 0.1, 0, 0, 0, 0, 0,
> 0, 0, 0, 0.3, 0.3, 0.5, 0.2, 0, 0, 0, 0.3, 1.6, 0.7, 0, 0, 6.6, 13.6,
> 6.6, 4.1, 12.7, 31.4, 13.1, 0.1, 0, 0, 0, 0.5, 0.4, 0.1, 0, 5.5, 2.8,
> 0, 0, 0, 0, 0, 0, 1.1, 25.4, 15.3, 16.6, 7.6, 0, 0, 0.5, 0.2, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0.7, 0.3, 0, 5.4, 2.7, 0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 0, 0, 0.5,
> 0.2, 32.7, 16.3, 0, 12.9, 6.4, 0, 7.7, 4.2, 6, 2.9, 5.1, 2.7, 0.1, 0,
> 3.5, 1.8, 0, 0, 8.9, 4.5, 0, 0, 0, 3.9, 1.9, 0, 0, 49.4, 25.7, 0.5, 0,
> 0, 3.9, 1.9, 0.5, 0.2, 0, 31.6, 20.5, 14.5, 6.1, 0.7, 0.3, 0, 29.9, 39,
> 12, 7.1, 3.5, 18.9, 9.9, 9.5, 4.6, 0, 1.3, 8.9, 4.1, 4.5, 7.3, 2.5, 0,
> 0, 0, 18.9, 16.9, 19.8, 8, 3.3, 1.7, 8.4, 13.3, 19.2, 7.3, 2, 6.2, 2.6,
> 0, 0, 0, 6.6, 3.3, 0.5, 0.2, 0, 0.8, 34.2, 28.9, 28.3, 23.3, 6.1, 0, 1,
> 0.5, 12.7, 9.2, 6.2, 20, 15.4, 18.8, 28.7, 25.7, 14.2, 3.3, 30.1, 17.7,
> 23.3, 32.3, 18.7, 5.8, 0.9, 13.9, 11.7, 2.4, 64.7, 54.3, 11.8, 1.1,
> 8.7, 4.2, 2.3, 31.1, 16.6, 1.2, 5, 2.4, 0, 0, 0, 0, 18.9, 9.5, 10.1,
> 26.5, 10.9, 7, 3.6, 26.8, 13.4, 7.4, 5.4, 0.8, 2.3, 2.5, 0.7, 0.3, 0.8,
> 0.7, 0.3, 0.1, 0, 5.2, 4.3, 4, 17.3, 14.6, 24, 27, 22.6, 13, 29.8,
> 30.8, 8.7, 25.7, 29.9, 36.3, 14.5, 0.3, 0, 0, 0, 0, 37.7, 29.3, 13,
> 3.9, 1.1, 37.1, 18.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6.9, 3.5,
> 26.1, 101, 51.1, 5.3, 8, 25, 109.7, 104.5, 90.3, 50.7, 10.4, 0.5, 0.4,
> 1.5, 5.1, 4.5, 1.8, 0.3, 0, 0.8, 0.9, 55.8, 44.3, 15.3, 10.3, 5.2, 8.3,
> 4.5, 4.4, 2, 0.3, 0.2, 0, 0, 25, 13.3, 1.7, 33.3, 74.1, 29.3, 6.1,
> 15.6, 13.7, 4.2, 0.2, 0, 0, 0.1, 0.1, 1, 0.8, 8.6, 11.8, 3.9, 0.2, 0.1,
> 10.3, 5.1, 0, 0.1, 0.1, 0, 13.3, 9.9, 7, 3.7, 2, 0.7, 0, 0, 0, 0.3,
> 6.9, 3.5, 0.1, 0, 0, 0, 1.7, 2.6, 0.9, 0, 0, 0.1, 0.1, 1.5, 0.7, 0, 0,
> 0, 1.1, 3.8, 4.9, 2.3, 0.3, 2.7, 2.7, 0.7, 0, 0, 0.1, 0.1, 0.3, 0.2, 0,
> 0, 0.5, 2, 1, 0.7, 0.3, 0, 1.8, 0.9, 1, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 2.3, 16.2, 7.7, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0.3, 0.2, 32, 16.8, 0.4, 0, 0.1, 0.1, 0, 6.7, 8.6,
> 2.6, 0, 6.2, 9, 9.9, 3.5, 0, 3, 1.5, 0, 0, 0, 6.4, 3.2, 0, 0.5, 4.4,
> 2.1, 0, 2.7, 9.7, 22.8, 10.3, 5.7, 2.6, 8.6, 23.8, 14.5, 2.4, 1.7, 0.8,
> 0, 0, 0.3, 0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 4.4, 3.5, 0.7, 0, 0, 0, 0,
> 0, 3.2, 1.6, 3.5, 1.8, 0.5, 12.2, 6.8, 1.9, 3.4, 7.7, 3.2, 0, 6.9, 3.5,
> 44.7, 22.3, 0, 5.2, 2.6, 4.2, 6.1, 2, 0, 0, 0.5, 0.2, 4.2, 2.1, 0, 4.9,
> 5, 2.4, 0.6, 0, 0, 10.5, 9.4, 6.6, 2.7, 11.7, 20.4, 9.5, 39.2, 24.6,
> 5.8, 10.6, 17.4, 6.4, 0, 0, 0, 0, 3.9, 3.7, 0.9, 0, 0, 0, 0, 9.8, 4.9,
> 1.5, 0.7, 0, 0, 0, 5.2, 2.9, 0.2, 0.5, 0.2, 0.1, 0.7, 0.3, 3.9, 1.9,
> 4.2, 2.1, 0.7, 0.3, 1, 6.7, 4.2, 35.1, 17.3, 7.9, 6.8, 1.4, 20.1, 23.6,
> 20.1, 6.7, 0, 0.7, 2.5, 1.1, 2.3, 1.5, 0.2, 0, 0, 1.1, 0.7, 0.1, 4.2,
> 2.1, 0.5, 0.2, 3.5, 19.8, 36.2, 58.5, 34.4, 6, 9.3, 16.1, 5.7, 4.4,
> 4.2, 47.3, 63.2, 32.9, 10.1, 3.3, 0.7, 11.7, 49.3, 48.8, 27.5, 32.5,
> 42.9, 37.9, 14.4, 18, 85.1, 42.3, 1.9, 0, 0, 0, 0, 2.5, 8.9, 3.8, 0, 0,
> 0, 0, 15.2, 16.9, 20.8, 12.8, 6.8, 2.5, 1, 11.7, 10.2, 2.3, 0, 0.3,
> 1.5, 1.1, 1.4, 2.2, 1.6, 0.4, 7.3, 12, 8.9, 4.6, 1.2, 0.1, 0, 0, 0,
> 0.5, 9.4, 4.6, 0, 35.5, 17.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21.3,
> 15.4, 3.2, 4.9, 9.9, 3.8, 0, 0, 1.1, 30, 19.8, 6.2, 5.8, 15.9, 30.9,
> 25, 9.8, 1.7, 0, 0.7, 2.9, 2.6, 2.7, 5.2, 3.8, 1.6, 4.4, 2, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 1.1, 1.9, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5,
> 118.1, 100.7, 21.1, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0, 0, 0, 22, 11.5, 0.2,
> 0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.5, 1.7, 0.8, 0, 0, 0,
> 1.3, 32.3, 16.6, 0.4, 0, 0, 0, 1.3, 0.7, 0, 5.2, 2.6, 0, 6.7, 10.8,
> 3.7, 0, 17.4, 8.7, 0, 0, 0.8, 1.4, 0.5, 0, 0, 0, 10.5, 5.2, 12.9, 7.4,
> 0.5, 0, 9.6, 4.8, 0, 2, 2.1, 5, 2.2, 0, 0, 0, 0, 0, 0, 0, 0, 14.3, 7.2,
> 0, 0, 0, 0, 0.5, 0.2, 1.7, 0.8, 0, 8.3, 4.1, 0, 0, 4.4, 2.2, 0, 0, 0,
> 2.5, 1.3, 5.2, 3.6, 0.5, 15.4, 8.2, 4.1, 2.3, 0.2, 0, 0, 0, 0, 8.9,
> 4.5, 1, 0.5, 3.3, 1.7, 2.7, 12.5, 5.6, 23.3, 11.7, 0, 0, 0, 0.1, 0.1,
> 1.1, 0.6, 6.6, 3.3, 21.1, 37.3, 13.4, 24.3, 12.2, 2.5, 1.3, 23.7, 16.9,
> 3.5, 0.5, 0, 0, 0, 0, 0, 0, 9.3, 23.4, 9.4, 0, 0, 0, 0.5, 0.2, 0, 0,
> 8.5, 4.2, 6.1, 19.9, 12.3, 9, 11.3, 4, 10.2, 5.1, 6.2, 4.2, 0.6, 0.1,
> 11.5, 5.7, 0, 13.2, 19.5, 8.1, 0.8, 0, 1, 0.5, 0, 0, 1.1, 0.6, 1.3,
> 0.7, 0, 6.1, 3.5, 0.2, 3.7, 1.8, 19.5, 30, 10.1, 14.7, 7.3, 10.7, 5.3,
> 7.6, 4.6, 5.5, 2.9, 2.4, 7.8, 5.9, 1.3, 2.7, 2.5, 1.2, 5.7, 32.3, 14.8,
> 0, 0, 0, 0, 0, 17.3, 8.6, 1, 5.2, 3.8, 0.7, 11, 8.7, 2.4, 1.1, 17.9,
> 40.6, 16.2, 33.8, 38.8, 28.7, 10.9, 12.3, 6.3, 2.5, 3.4, 1.2, 0.7, 5.2,
> 2.4, 3.9, 6.7, 9.1, 3.5, 34.9, 19.4, 3.5, 1.7, 0.2, 0, 9.1, 5, 63.4,
> 31.6, 21.5, 62.7, 31, 4.2, 3.4, 15.3, 11.7, 23.5, 13.1, 1.4, 4.3, 5.1,
> 3.7, 1.1, 0, 0, 0, 0, 0, 2.2, 1.1, 0, 0, 0, 0, 2.3, 1.2, 0, 0.1, 0.4,
> 0.2, 2.3, 1.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.5, 0.7, 0, 0.1, 0.4,
> 10.3, 5.4, 0.6, 0.2, 0.5, 0.7, 0.2, 2.9, 4.6, 1.6, 2.2, 1.2, 0.1, 0, 0,
> 0, 1.7, 0.8, 0, 0, 0, 0, 2, 58.5, 28.8, 0.3, 0.2, 1.7, 0.8, 0, 1.3,
> 0.7, 0, 0.1, 2.3, 1.1, 0, 0, 0, 8.9, 4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 10.7, 5.3, 0, 0, 1.7, 0.8, 0, 4.4, 2.2, 0, 0, 46.7, 23.4, 0, 0, 0,
> 2.3, 12.5, 31.9, 14.1, 2.7, 1.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 5.4, 4, 0.8, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8, 0.4, 1.1, 1.6,
> 0.5, 4.9, 2.4, 0.3, 2.8, 3.5, 7.7, 20.4, 8.5, 15.2, 7.6, 17.4, 8.7, 0,
> 7.6, 3.8, 2.3, 4.4, 8.3, 8.1, 2.4, 0, 5.9, 8, 3.2, 18.6, 9.1, 0, 0,
> 18.6, 9.3, 0, 0, 0, 17.7, 12.7, 16.5, 31.3, 12, 2.7, 11.1, 4.9, 16.9,
> 8.4, 0, 8.8, 6.2, 6.4, 6.1, 1.7, 1, 7.4, 4.5, 0.5, 0, 3.2, 3.6, 3.2,
> 1.1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2.5, 21.5, 11.9, 1, 0.1, 9.1, 5.6, 1.2,
> 11, 18.9, 6.8, 0, 0, 0, 0, 0, 0, 0, 0, 7.4, 5, 6.9, 31.4, 14.1, 8.4,
> 4.5, 4.6, 2.2, 0, 1, 31.4, 34.6, 9.6, 0, 1.1, 2, 0.7, 9.5, 5.2, 0.6,
> 10, 5.7, 5.3, 5.4, 8.4, 3.5, 1, 1.6, 0.6, 2.2, 1.1, 0.5, 10, 10.8,
> 36.9, 17, 0, 36.5, 18.3, 1.8, 0.9, 1, 0.5, 4.7, 4, 1.2, 0.2, 0, 0, 0,
> 5.5, 30.7, 14, 0, 0, 0, 0.3, 0.2, 54.5, 27.2, 0, 0, 0, 0.5, 28.8, 44.1,
> 80.8, 37.8, 2.4, 3, 1.5, 0.1, 23.2, 11.6, 0.1, 0.1, 11, 25.1, 11.5,
> 0.8, 0, 3.5, 2.4, 3.5, 1.6, 0, 14, 9.7, 18.6, 10.4, 0.9, 2, 20.1, 16.3,
> 9.4, 9.1, 17.7, 22.7, 15.1, 8.2, 11.5, 9.5, 14.9, 18.9, 74.4, 124.4,
> 114.6, 241.6, 132.2, 114.4, 91.5, 22.4, 71.2, 78.2, 45.8, 33.3, 41.7,
> 16, 0.6, 5.6, 3.5, 31.7, 54.2, 77.8, 69.5, 37.7, 15.5, 19.6, 18.6,
> 30.1, 22.2, 18.6, 11.9, 9.1, 18.5, 23, 15.1, 4.7, 1, 2.4)), .Names =
> c("Year", "Month", "Day", "Amount"), class = "data.frame", row.names =
> c(NA, -2192L))
>
> i want the counting number of rain as follows:
>
>             Jan        Feb        Mar    Apr    May    Jun    Jul
> Aug    Sep    Oct    Nov    Dec 1960        x19611962196319641965
>
>
> x = number of rain for > 0.000001
>
> Thanks for your help.
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Oct  1 09:22:48 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 1 Oct 2015 07:22:48 +0000
Subject: [R] Count number of rain more than zero in matrix form
In-Reply-To: <1682685464.3880438.1443682398660.JavaMail.yahoo@mail.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C42FA3@SRVEXCHMBX.precheza.cz>
	<1682685464.3880438.1443682398660.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43008@SRVEXCHMBX.precheza.cz>

Hi

keep the conversation on list, others can help you too. Your dput sending was OK but HTML post tends to twist the message content  unexpectedly so it negated your effort.

I still insist that

aggregate(mydat$amount>0.001, list(mydat$month, mydat$year), sum)

gives you the answer you want. Did you try it?

You can format the result e.g. by using function dcast from reshape2 package.

Length does not offer the result as it gives you length of whole vector regardless of the vector content.

Cheers
Petr

From: smart hendsome [mailto:putra_autumn86 at yahoo.com]
Sent: Thursday, October 01, 2015 8:53 AM
To: PIKAL Petr
Subject: Re: [R] Count number of rain more than zero in matrix form

Hi PIKAL,

Thanks for your reply, I dont know how to send my data after using the dput(). I also attached my real data in csv format.

I have tried using the function length but not working. Can you help me to count the no of rain in that month as my file name " No of rain"? Thanks for your help.


On Thursday, October 1, 2015 2:38 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:

Hi

Great that you used dput, bad that you send HTML email which somehow scrambled it.

2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L
Error: unexpected numeric constant in:
"

I tried to find a way how to repair it but after inspecting 200 rows I gave up and made some fake data

mydat<-expand.grid(year=1960:1961, month=1:3, day=1:5, amount=1)
mydat$amount<-abs(rnorm(30))*10

Number of days with amount > 3 in whole dataset
> sum(mydat$amount>3)
[1] 24

Number of days with amount > 3 in each year and month.
> aggregate(mydat$amount>3, list(mydat$month, mydat$year), sum)
  Group.1 Group.2 x
1      1    1960 4
2      2    1960 3
3      3    1960 5
4      1    1961 4
5      2    1961 5
6      3    1961 3

HTH

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of smart
> hendsome
> Sent: Thursday, October 01, 2015 4:47 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Count number of rain more than zero in matrix form
>
> Hello R-users,
> I want to ask how to count the number of daily rain data.  My data
> using dput() as below:
> structure(list(Year = c(1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L,
> 1961L, 1961L, 1961L, 1961L, 1961L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L,
> 1963L, 1963L, 1963L, 1963L, 1963L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L,
> 1964L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L,
> 1965L, 1965L, 1965L, 1965L, 1965L, 1965L), Month = c(1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L,
> 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L), Amount = c(0.3, 0,
> 0, 0, 0, 2.7, 7.1, 14, 12.6, 11.1, 5.5, 1.2, 1.2, 1, 5.3, 2.5, 0, 0,
> 0.5, 14.6, 130.4, 66.5, 4.1, 3.7, 1.4, 2, 9.1, 8.8, 7.4, 2.5, 0, 0, 0,
> 10.1, 5.5, 6.8, 6.3, 1.5, 0, 0, 0, 0, 0, 2.5, 11.7, 6.2, 0.5, 0.7, 0.3,
> 2.5, 2.3, 1, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 16.2, 18.6, 15.2, 48.3, 26.7, 2.9, 0.2, 0, 0, 0, 0, 0, 1.1, 1.4, 0.4,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.1, 2.5, 5.2, 2.6, 0.3, 0.2, 1.7,
> 0.8, 0, 0, 0, 0, 6.1, 4.7, 2.8, 1, 0.5, 1.6, 2.1, 0.7, 0, 6.4, 3.5,
> 0.2, 0, 0, 0, 0, 0, 0, 0, 21.3, 10.7, 2, 4.2, 1.9, 2.8, 21.1, 9.9, 0.7,
> 2, 10.4, 5.3, 29.6, 14.7, 0, 0, 0, 4.4, 2.2, 0, 0, 0.8, 0.4, 0, 3.3,
> 3.1, 1.9, 0.6, 0, 4.7, 2.4, 0, 0, 0, 0, 5.9, 25.7, 11.4, 0, 0, 0, 0,
> 2.7, 1.3, 0, 0, 0, 0, 0, 0, 5.9, 28.1, 12.6, 68.2, 34.4, 0.6, 8.2, 4.3,
> 0.2, 17.9, 30.6, 21.1, 5.1, 0, 0, 0.1, 3.6, 8.7, 8.9, 6.7, 13.7, 10,
> 2.1, 11.8, 5.9, 0, 0, 0, 0, 0, 19.5, 31.1, 38.3, 20, 3.1, 5.1, 6.4,
> 12.4, 5.2, 2.5, 9, 4, 0.1, 0.1, 0.5, 17, 8.8, 0.6, 0.2, 0, 0, 0, 40.3,
> 20.1, 5.1, 14.3, 20.2, 13.2, 4.8, 1.4, 0.2, 0, 1, 0.5, 0, 0, 0, 3.7,
> 1.8, 15.4, 7.7, 0, 3.9, 8, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45.5,
> 22.8, 9.9, 5, 4.4, 2.7, 0.2, 0.8, 3.4, 10.3, 6.2, 7.5, 7.3, 20.3, 22,
> 28.9, 31.7, 39.2, 14.5, 10.5, 34.8, 43.7, 43.5, 144.9, 143, 68, 18.2,
> 1.8, 0.5, 16.1, 15.5, 3.8, 51.6, 25.8, 0.7, 1.5, 13.8, 27.2, 10.3, 1.5,
> 1.7, 5.9, 12, 4.6, 1.7, 6.4, 11.7, 16.5, 38.3, 35.8, 16.7, 3.5, 1.8,
> 35.9, 58.1, 40.9, 15, 14.5, 6.1, 0, 0, 3.3, 13.5, 6.9, 1.2, 2.7, 1.2,
> 15.2, 16, 12.5, 14.4, 9.3, 2.1, 2.5, 25.6, 96.8, 99.5, 39.9, 23.9, 9.1,
> 1.7, 3.8, 12, 6.4, 15.4, 8.8, 1.5, 10.7, 26.5, 20.9, 7.7, 1.7, 1.2,
> 0.8, 0.6, 1, 0.4, 0, 6.1, 3.5, 0.2, 0, 0, 0, 0.8, 3.7, 12.8, 8.9, 5.3,
> 1.8, 0, 0, 0, 0, 0, 0, 0, 4.4, 2.2, 0, 0, 5.1, 5.9, 10.6, 9.3, 7.6,
> 4.1, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 22.1,
> 11.1, 0, 0, 23.1, 25.4, 12.8, 2.9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0.3, 11.8, 13.9, 6, 19.9, 35.9, 13.2, 0, 0, 0, 0, 0, 0, 0, 0, 3.2, 1.6,
> 0.8, 16.6, 8.1, 11.3, 5.8, 10.9, 7.1, 0.8, 0, 0, 0, 0, 11, 37.3, 18.9,
> 14.4, 14.5, 4, 0, 0, 1, 0.5, 0.3, 3.7, 1.8, 0, 0, 0, 9.8, 4.9, 3, 1.5,
> 0, 0, 0, 0, 0, 0, 7.6, 3.8, 0, 0, 2.3, 1.2, 2.5, 1.3, 0.8, 0.4, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27.1, 44.3, 17.4, 1.7, 0.3, 0, 5.4, 2.7,
> 0, 2.5, 1.3, 0, 0, 4.4, 2.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.5, 0.2, 0,
> 25, 12.5, 0, 7.4, 7.6, 1.9, 2.5, 1.3, 0, 0, 35.9, 37.1, 20.6, 7.5, 1,
> 0, 0.1, 0.2, 3.1, 1.5, 0, 0, 0, 0, 0, 12.7, 6.3, 0, 0, 0, 0.1, 4.8,
> 4.9, 2.1, 23.4, 11.5, 6.9, 31.2, 36.9, 11.5, 32, 16, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0.1, 0.1, 0, 0, 6.7, 17, 25.8, 9.5, 6.4, 9.6, 10.3, 5.5,
> 36.5, 17.9, 0.1, 0.3, 0.2, 14.2, 7.1, 0, 0, 21.5, 30.2, 10.1, 0.2, 0,
> 9.6, 4.8, 2, 13.3, 13.2, 3.5, 13.7, 12.9, 33.5, 15.2, 0, 5.7, 5.2, 1.2,
> 10.8, 51.9, 24.3, 1.8, 0.7, 4.9, 21.9, 17.5, 5, 4.4, 1.9, 5.9, 2.9, 0,
> 8.1, 4, 0, 0.3, 15.7, 71.2, 116, 62.9, 48.5, 28.3, 19.8, 35.7, 20.1,
> 9.8, 31.3, 32.6, 30.6, 28.4, 15.6, 4.8, 7.8, 44.3, 29.7, 18.2, 6.8,
> 3.9, 6.5, 31.9, 45.1, 37.3, 14.9, 11.5, 24.9, 25.3, 143.9, 101.9, 28.2,
> 21.7, 32.2, 13.8, 9.6, 28.9, 12.6, 9.6, 30.5, 12.9, 1.5, 1.9, 0.9,
> 25.4, 46.4, 28.2, 22.2, 10.8, 7.3, 3, 34.2, 84.8, 71, 28.7, 16.9, 62.1,
> 104.4, 89.8, 42.9, 9.3, 3.1, 3.5, 2.1, 0.8, 0.2, 0, 0, 0, 5.1, 6.1,
> 5.8, 4, 1, 4.4, 4.2, 6.1, 7.1, 2.3, 1.5, 2.5, 0.9, 0, 0, 0, 0, 0, 19.3,
> 10.6, 0.6, 0.1, 0, 1.5, 3.3, 1.3, 3, 1.5, 0, 0.1, 0.1, 0, 0, 0, 0, 0,
> 0, 0, 0, 0.3, 0.3, 0.5, 0.2, 0, 0, 0, 0.3, 1.6, 0.7, 0, 0, 6.6, 13.6,
> 6.6, 4.1, 12.7, 31.4, 13.1, 0.1, 0, 0, 0, 0.5, 0.4, 0.1, 0, 5.5, 2.8,
> 0, 0, 0, 0, 0, 0, 1.1, 25.4, 15.3, 16.6, 7.6, 0, 0, 0.5, 0.2, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0.7, 0.3, 0, 5.4, 2.7, 0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 0, 0, 0.5,
> 0.2, 32.7, 16.3, 0, 12.9, 6.4, 0, 7.7, 4.2, 6, 2.9, 5.1, 2.7, 0.1, 0,
> 3.5, 1.8, 0, 0, 8.9, 4.5, 0, 0, 0, 3.9, 1.9, 0, 0, 49.4, 25.7, 0.5, 0,
> 0, 3.9, 1.9, 0.5, 0.2, 0, 31.6, 20.5, 14.5, 6.1, 0.7, 0.3, 0, 29.9, 39,
> 12, 7.1, 3.5, 18.9, 9.9, 9.5, 4.6, 0, 1.3, 8.9, 4.1, 4.5, 7.3, 2.5, 0,
> 0, 0, 18.9, 16.9, 19.8, 8, 3.3, 1.7, 8.4, 13.3, 19.2, 7.3, 2, 6.2, 2.6,
> 0, 0, 0, 6.6, 3.3, 0.5, 0.2, 0, 0.8, 34.2, 28.9, 28.3, 23.3, 6.1, 0, 1,
> 0.5, 12.7, 9.2, 6.2, 20, 15.4, 18.8, 28.7, 25.7, 14.2, 3.3, 30.1, 17.7,
> 23.3, 32.3, 18.7, 5.8, 0.9, 13.9, 11.7, 2.4, 64.7, 54.3, 11.8, 1.1,
> 8.7, 4.2, 2.3, 31.1, 16.6, 1.2, 5, 2.4, 0, 0, 0, 0, 18.9, 9.5, 10.1,
> 26.5, 10.9, 7, 3.6, 26.8, 13.4, 7.4, 5.4, 0.8, 2.3, 2.5, 0.7, 0.3, 0.8,
> 0.7, 0.3, 0.1, 0, 5.2, 4.3, 4, 17.3, 14.6, 24, 27, 22.6, 13, 29.8,
> 30.8, 8.7, 25.7, 29.9, 36.3, 14.5, 0.3, 0, 0, 0, 0, 37.7, 29.3, 13,
> 3.9, 1.1, 37.1, 18.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6.9, 3.5,
> 26.1, 101, 51.1, 5.3, 8, 25, 109.7, 104.5, 90.3, 50.7, 10.4, 0.5, 0.4,
> 1.5, 5.1, 4.5, 1.8, 0.3, 0, 0.8, 0.9, 55.8, 44.3, 15.3, 10.3, 5.2, 8.3,
> 4.5, 4.4, 2, 0.3, 0.2, 0, 0, 25, 13.3, 1.7, 33.3, 74.1, 29.3, 6.1,
> 15.6, 13.7, 4.2, 0.2, 0, 0, 0.1, 0.1, 1, 0.8, 8.6, 11.8, 3.9, 0.2, 0.1,
> 10.3, 5.1, 0, 0.1, 0.1, 0, 13.3, 9.9, 7, 3.7, 2, 0.7, 0, 0, 0, 0.3,
> 6.9, 3.5, 0.1, 0, 0, 0, 1.7, 2.6, 0.9, 0, 0, 0.1, 0.1, 1.5, 0.7, 0, 0,
> 0, 1.1, 3.8, 4.9, 2.3, 0.3, 2.7, 2.7, 0.7, 0, 0, 0.1, 0.1, 0.3, 0.2, 0,
> 0, 0.5, 2, 1, 0.7, 0.3, 0, 1.8, 0.9, 1, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 2.3, 16.2, 7.7, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0.3, 0.2, 32, 16.8, 0.4, 0, 0.1, 0.1, 0, 6.7, 8.6,
> 2.6, 0, 6.2, 9, 9.9, 3.5, 0, 3, 1.5, 0, 0, 0, 6.4, 3.2, 0, 0.5, 4.4,
> 2.1, 0, 2.7, 9.7, 22.8, 10.3, 5.7, 2.6, 8.6, 23.8, 14.5, 2.4, 1.7, 0.8,
> 0, 0, 0.3, 0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 4.4, 3.5, 0.7, 0, 0, 0, 0,
> 0, 3.2, 1.6, 3.5, 1.8, 0.5, 12.2, 6.8, 1.9, 3.4, 7.7, 3.2, 0, 6.9, 3.5,
> 44.7, 22.3, 0, 5.2, 2.6, 4.2, 6.1, 2, 0, 0, 0.5, 0.2, 4.2, 2.1, 0, 4.9,
> 5, 2.4, 0.6, 0, 0, 10.5, 9.4, 6.6, 2.7, 11.7, 20.4, 9.5, 39.2, 24.6,
> 5.8, 10.6, 17.4, 6.4, 0, 0, 0, 0, 3.9, 3.7, 0.9, 0, 0, 0, 0, 9.8, 4.9,
> 1.5, 0.7, 0, 0, 0, 5.2, 2.9, 0.2, 0.5, 0.2, 0.1, 0.7, 0.3, 3.9, 1.9,
> 4.2, 2.1, 0.7, 0.3, 1, 6.7, 4.2, 35.1, 17.3, 7.9, 6.8, 1.4, 20.1, 23.6,
> 20.1, 6.7, 0, 0.7, 2.5, 1.1, 2.3, 1.5, 0.2, 0, 0, 1.1, 0.7, 0.1, 4.2,
> 2.1, 0.5, 0.2, 3.5, 19.8, 36.2, 58.5, 34.4, 6, 9.3, 16.1, 5.7, 4.4,
> 4.2, 47.3, 63.2, 32.9, 10.1, 3.3, 0.7, 11.7, 49.3, 48.8, 27.5, 32.5,
> 42.9, 37.9, 14.4, 18, 85.1, 42.3, 1.9, 0, 0, 0, 0, 2.5, 8.9, 3.8, 0, 0,
> 0, 0, 15.2, 16.9, 20.8, 12.8, 6.8, 2.5, 1, 11.7, 10.2, 2.3, 0, 0.3,
> 1.5, 1.1, 1.4, 2.2, 1.6, 0.4, 7.3, 12, 8.9, 4.6, 1.2, 0.1, 0, 0, 0,
> 0.5, 9.4, 4.6, 0, 35.5, 17.8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21.3,
> 15.4, 3.2, 4.9, 9.9, 3.8, 0, 0, 1.1, 30, 19.8, 6.2, 5.8, 15.9, 30.9,
> 25, 9.8, 1.7, 0, 0.7, 2.9, 2.6, 2.7, 5.2, 3.8, 1.6, 4.4, 2, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 1.1, 1.9, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5,
> 118.1, 100.7, 21.1, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0, 0, 0, 22, 11.5, 0.2,
> 0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.5, 1.7, 0.8, 0, 0, 0,
> 1.3, 32.3, 16.6, 0.4, 0, 0, 0, 1.3, 0.7, 0, 5.2, 2.6, 0, 6.7, 10.8,
> 3.7, 0, 17.4, 8.7, 0, 0, 0.8, 1.4, 0.5, 0, 0, 0, 10.5, 5.2, 12.9, 7.4,
> 0.5, 0, 9.6, 4.8, 0, 2, 2.1, 5, 2.2, 0, 0, 0, 0, 0, 0, 0, 0, 14.3, 7.2,
> 0, 0, 0, 0, 0.5, 0.2, 1.7, 0.8, 0, 8.3, 4.1, 0, 0, 4.4, 2.2, 0, 0, 0,
> 2.5, 1.3, 5.2, 3.6, 0.5, 15.4, 8.2, 4.1, 2.3, 0.2, 0, 0, 0, 0, 8.9,
> 4.5, 1, 0.5, 3.3, 1.7, 2.7, 12.5, 5.6, 23.3, 11.7, 0, 0, 0, 0.1, 0.1,
> 1.1, 0.6, 6.6, 3.3, 21.1, 37.3, 13.4, 24.3, 12.2, 2.5, 1.3, 23.7, 16.9,
> 3.5, 0.5, 0, 0, 0, 0, 0, 0, 9.3, 23.4, 9.4, 0, 0, 0, 0.5, 0.2, 0, 0,
> 8.5, 4.2, 6.1, 19.9, 12.3, 9, 11.3, 4, 10.2, 5.1, 6.2, 4.2, 0.6, 0.1,
> 11.5, 5.7, 0, 13.2, 19.5, 8.1, 0.8, 0, 1, 0.5, 0, 0, 1.1, 0.6, 1.3,
> 0.7, 0, 6.1, 3.5, 0.2, 3.7, 1.8, 19.5, 30, 10.1, 14.7, 7.3, 10.7, 5.3,
> 7.6, 4.6, 5.5, 2.9, 2.4, 7.8, 5.9, 1.3, 2.7, 2.5, 1.2, 5.7, 32.3, 14.8,
> 0, 0, 0, 0, 0, 17.3, 8.6, 1, 5.2, 3.8, 0.7, 11, 8.7, 2.4, 1.1, 17.9,
> 40.6, 16.2, 33.8, 38.8, 28.7, 10.9, 12.3, 6.3, 2.5, 3.4, 1.2, 0.7, 5.2,
> 2.4, 3.9, 6.7, 9.1, 3.5, 34.9, 19.4, 3.5, 1.7, 0.2, 0, 9.1, 5, 63.4,
> 31.6, 21.5, 62.7, 31, 4.2, 3.4, 15.3, 11.7, 23.5, 13.1, 1.4, 4.3, 5.1,
> 3.7, 1.1, 0, 0, 0, 0, 0, 2.2, 1.1, 0, 0, 0, 0, 2.3, 1.2, 0, 0.1, 0.4,
> 0.2, 2.3, 1.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.5, 0.7, 0, 0.1, 0.4,
> 10.3, 5.4, 0.6, 0.2, 0.5, 0.7, 0.2, 2.9, 4.6, 1.6, 2.2, 1.2, 0.1, 0, 0,
> 0, 1.7, 0.8, 0, 0, 0, 0, 2, 58.5, 28.8, 0.3, 0.2, 1.7, 0.8, 0, 1.3,
> 0.7, 0, 0.1, 2.3, 1.1, 0, 0, 0, 8.9, 4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 10.7, 5.3, 0, 0, 1.7, 0.8, 0, 4.4, 2.2, 0, 0, 46.7, 23.4, 0, 0, 0,
> 2.3, 12.5, 31.9, 14.1, 2.7, 1.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 5.4, 4, 0.8, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8, 0.4, 1.1, 1.6,
> 0.5, 4.9, 2.4, 0.3, 2.8, 3.5, 7.7, 20.4, 8.5, 15.2, 7.6, 17.4, 8.7, 0,
> 7.6, 3.8, 2.3, 4.4, 8.3, 8.1, 2.4, 0, 5.9, 8, 3.2, 18.6, 9.1, 0, 0,
> 18.6, 9.3, 0, 0, 0, 17.7, 12.7, 16.5, 31.3, 12, 2.7, 11.1, 4.9, 16.9,
> 8.4, 0, 8.8, 6.2, 6.4, 6.1, 1.7, 1, 7.4, 4.5, 0.5, 0, 3.2, 3.6, 3.2,
> 1.1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2.5, 21.5, 11.9, 1, 0.1, 9.1, 5.6, 1.2,
> 11, 18.9, 6.8, 0, 0, 0, 0, 0, 0, 0, 0, 7.4, 5, 6.9, 31.4, 14.1, 8.4,
> 4.5, 4.6, 2.2, 0, 1, 31.4, 34.6, 9.6, 0, 1.1, 2, 0.7, 9.5, 5.2, 0.6,
> 10, 5.7, 5.3, 5.4, 8.4, 3.5, 1, 1.6, 0.6, 2.2, 1.1, 0.5, 10, 10.8,
> 36.9, 17, 0, 36.5, 18.3, 1.8, 0.9, 1, 0.5, 4.7, 4, 1.2, 0.2, 0, 0, 0,
> 5.5, 30.7, 14, 0, 0, 0, 0.3, 0.2, 54.5, 27.2, 0, 0, 0, 0.5, 28.8, 44.1,
> 80.8, 37.8, 2.4, 3, 1.5, 0.1, 23.2, 11.6, 0.1, 0.1, 11, 25.1, 11.5,
> 0.8, 0, 3.5, 2.4, 3.5, 1.6, 0, 14, 9.7, 18.6, 10.4, 0.9, 2, 20.1, 16.3,
> 9.4, 9.1, 17.7, 22.7, 15.1, 8.2, 11.5, 9.5, 14.9, 18.9, 74.4, 124.4,
> 114.6, 241.6, 132.2, 114.4, 91.5, 22.4, 71.2, 78.2, 45.8, 33.3, 41.7,
> 16, 0.6, 5.6, 3.5, 31.7, 54.2, 77.8, 69.5, 37.7, 15.5, 19.6, 18.6,
> 30.1, 22.2, 18.6, 11.9, 9.1, 18.5, 23, 15.1, 4.7, 1, 2.4)), .Names =
> c("Year", "Month", "Day", "Amount"), class = "data.frame", row.names =
> c(NA, -2192L))
>
> i want the counting number of rain as follows:
>
>            Jan        Feb        Mar    Apr    May    Jun    Jul
> Aug    Sep    Oct    Nov    Dec 1960        x19611962196319641965
>
>
> x = number of rain for > 0.000001
>
> Thanks for your help.
>      [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-<http://www.r-project.org/posting->
> guide.html
> and provide commented, minimal, self-contained, reproducible code.



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Thu Oct  1 09:37:11 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 01 Oct 2015 09:37:11 +0200
Subject: [R] optimizing with non-linear constraints
In-Reply-To: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	(Ravi Varadhan's message of "Wed, 30 Sep 2015 17:21:56 +0000")
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
Message-ID: <m2pp0z11lk.fsf@krugs.de>

Ravi Varadhan <ravi.varadhan at jhu.edu> writes:

> Hi Rainer,
> It is very simple to specify the constraints (linear or nonlinear) in
> "alabama" .  They are specified in a function called `hin', where the
> constraints are written such that they are positive.

OK - I somehow missed the part that, when the values x are valid, i.e. in
the range as defined by the conditions, the result of hin(x) that they
are all positive.

> Your two nonlinear constraints would be written as follows:
>
> hin <- function(x, LAI) {
> h <- rep(NA, 2)
> h[1] <- LAI^x[2] / x[3] + x[1]
> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
> h
> }

Makes perfect sense.

>
> Please take a look at the help page.  If it is still not clear, you can contact me offline.

Yup - I did. But I somehow missed the fact stated above.

I am using constrOptim() and constrOptim.nl() for a paper
and am compiling a separate document which explains how to get the
constraints for the two functions step by step - I will make it
available as a blog post and a pdf.

I might have further questions concerning the different fitting
functions and which ones are the most appropriate in my case.

Thanks a lot,

Rainer


> Best,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor,  Department of Oncology
> Division of Biostatistics & Bionformatics
> Sidney Kimmel Comprehensive Cancer Center
> Johns Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
> 	[[alternative HTML version deleted]]
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151001/aba6f3ad/attachment.bin>

From Thomas.Chesney at nottingham.ac.uk  Thu Oct  1 12:04:12 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Thu, 1 Oct 2015 10:04:12 +0000
Subject: [R] Increment certain values in a vector
Message-ID: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>

How can I manipulate values of only certain entries in a vector, based on what the existing values are?

So for instance if I want to add one to each of the following values, or multiply them by a specific factor:

agents[which(agent$membership == 1)]

how would I do this please?

If there was just one value to manipulate I'd just do this:

value <- value + 1

and this would let me set the values:

agents[which(agent$membership == 1)] <- 100

but how to essentially achieve this:

agents[which(agent$membership == 1)] <- agents[which(agent$membership == 1)] + 1

Thank you!



This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From kirsada at hotmail.com  Thu Oct  1 11:26:39 2015
From: kirsada at hotmail.com (kirsada)
Date: Thu, 1 Oct 2015 02:26:39 -0700 (PDT)
Subject: [R] Help with improveProb function in Hmisc in R
Message-ID: <1443691599854-4713004.post@n4.nabble.com>

Please bear with me, I am very new to R.

My question is regarding the use of the improveProb function in the Hmisc
package. I have two logistic models, the only difference being that the
second model contains my novel marker of interest. I am trying to calculate
NRI and IDI to compare models.

I have the PredRisks for both models - PredRisk1 and PredRisk2, and my
outcome is disease 0/1. How do I define this in R in order to run

improveProb(x1, x2, y)?

Many thanks in advance



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-improveProb-function-in-Hmisc-in-R-tp4713004.html
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at me.com  Thu Oct  1 12:55:10 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 01 Oct 2015 05:55:10 -0500
Subject: [R] Announcement - The Use Of Nabble For Posting To R-Help Will No
 Longer Be Supported Effective October 15, 2015
Message-ID: <90471313-C179-464E-8A84-91C2BCE66CAD@me.com>

Greetings all,

On behalf of The R Foundation for Statistical Computing, this is an announcement that, effective October 15, 2015, the Nabble online forums will no longer be a supported vehicle for posting new threads and/or replying to existing threads on R-Help.

This decision was not made lightly and is the result of issues that have developed over the past several years. These issues include:

1. The lack of any context for thread-replies in posts submitted via Nabble. This compels readers to take extra time to click on a link in the post and visit the Nabble web site to read the reply in context. Many email-based R-Help users do not take the time to do this, and therefore do not reply to Nabble-based posts.

2. The use of Nabble by a number of folks who have not subscribed to the R email lists directly. Since subscriptions to the R email lists are required for posting, these posts are held for moderation, which results in a substantial increase in the workload of the **volunteer** list moderators. The moderators must take additional time to log into the administrative web site interfaces for the R lists to manually review, and approve or reject, posts submitted via Nabble.

3. An increasing level of both publicly and privately expressed animosity and frustration on the R lists towards Nabble-based posts because of the above and related issues.

Over the past several months, the R Foundation, in cooperation with Nabble, has incrementally removed the ability of multiple Nabble archives to post new threads on the R email lists, respond to existing threads, and privately reply to authors via the Nabble web site.

R-Help, because it is the highest volume of the R lists, is the last R email list to undergo this transition. We are announcing the change two weeks in advance to afford Nabble users the opportunity to directly subscribe to and use the R email-based support lists in the manner originally intended.

Information on the various R email lists, including R-Help, is available here:

 https://www.r-project.org/mail.html

The existing relevant Nabble archives will become just that -- read only and searchable archives -- as a valuable alternative to other R email list archives that are available online.

We wish to express our sincere thanks to Hugo Teixeira at Nabble for his assistance over the past several months in this process.

For those folks who prefer to use a web-based interface for R-related support matters, as opposed to email-based interactions, StackOverflow, as one example, provides such a vehicle at:

 http://stackoverflow.com/questions/tagged/r

For those who have general statistical support queries, as per the R Posting Guide, StackExchange/Cross Validated at:

 http://stats.stackexchange.com

provides a similar platform.

The R Foundation does not support or endorse the above third-party resources, but is simply mentioning them as popular, web-based alternatives to the R email lists, which remain our recommended vehicles for focused community support for R.

Thank you,

Marc Schwartz
On Behalf of the R Foundation for Statistical Computing


From petr.pikal at precheza.cz  Thu Oct  1 13:00:51 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 1 Oct 2015 11:00:51 +0000
Subject: [R] Increment certain values in a vector
In-Reply-To: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>
References: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43100@SRVEXCHMBX.precheza.cz>

Hi

Are agents and agent different objects? Or it is a typo? Better would be to provide some real or fake data by dput or at least result of str(agent) and str(agents)

Actually your code shall work in case agent and agents have same length and expected order.

agents[which(agent$membership == 1)] <- agents[which(agent$membership == 1)] + 1

For less typing you can do:

sel <- which(agent$membership == 1)
agents[sel] <- agents[sel] + 1

The code can be different if agent or agents are objects like matrix or array. Actually from the code xxx$yyy I presume it is data frame or list.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> Chesney
> Sent: Thursday, October 01, 2015 12:04 PM
> To: r-help at r-project.org
> Subject: [R] Increment certain values in a vector
>
> How can I manipulate values of only certain entries in a vector, based
> on what the existing values are?
>
> So for instance if I want to add one to each of the following values,
> or multiply them by a specific factor:
>
> agents[which(agent$membership == 1)]
>
> how would I do this please?
>
> If there was just one value to manipulate I'd just do this:
>
> value <- value + 1
>
> and this would let me set the values:
>
> agents[which(agent$membership == 1)] <- 100
>
> but how to essentially achieve this:
>
> agents[which(agent$membership == 1)] <- agents[which(agent$membership
> == 1)] + 1
>
> Thank you!
>
>
>
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
>
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
>
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From sarah.goslee at gmail.com  Thu Oct  1 13:01:02 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 1 Oct 2015 07:01:02 -0400
Subject: [R] Increment certain values in a vector
In-Reply-To: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>
References: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>
Message-ID: <CAM_vjuk0z7zVXuPJbK=M4nwG8Ud4Cipb95XUSV-Dxbhh5SeinA@mail.gmail.com>

Hi,

On Thursday, October 1, 2015, Thomas Chesney <
Thomas.Chesney at nottingham.ac.uk> wrote:

> How can I manipulate values of only certain entries in a vector, based on
> what the existing values are?
>
> So for instance if I want to add one to each of the following values, or
> multiply them by a specific factor:
>
> agents[which(agent$membership == 1)]
>
> how would I do this please?
>
> If there was just one value to manipulate I'd just do this:
>
> value <- value + 1
>
> and this would let me set the values:
>
> agents[which(agent$membership == 1)] <- 100
>
> but how to essentially achieve this:
>
> agents[which(agent$membership == 1)] <- agents[which(agent$membership ==
> 1)] + 1


Did you try that? I'd do it without the which() because I'm lazy, but
it should work.




-- 
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Oct  1 13:16:54 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 1 Oct 2015 11:16:54 +0000
Subject: [R] Increment certain values in a vector
In-Reply-To: <CAM_vjuk0z7zVXuPJbK=M4nwG8Ud4Cipb95XUSV-Dxbhh5SeinA@mail.gmail.com>
References: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>
	<CAM_vjuk0z7zVXuPJbK=M4nwG8Ud4Cipb95XUSV-Dxbhh5SeinA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43132@SRVEXCHMBX.precheza.cz>

Hi Sarah


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Sarah
> Goslee
> Sent: Thursday, October 01, 2015 1:01 PM
> To: Thomas Chesney
> Cc: r-help at r-project.org
> Subject: Re: [R] Increment certain values in a vector
>
> Hi,
>
> On Thursday, October 1, 2015, Thomas Chesney <
> Thomas.Chesney at nottingham.ac.uk> wrote:
>
> > How can I manipulate values of only certain entries in a vector,
> based
> > on what the existing values are?
> >
> > So for instance if I want to add one to each of the following values,
> > or multiply them by a specific factor:
> >
> > agents[which(agent$membership == 1)]
> >
> > how would I do this please?
> >
> > If there was just one value to manipulate I'd just do this:
> >
> > value <- value + 1
> >
> > and this would let me set the values:
> >
> > agents[which(agent$membership == 1)] <- 100
> >
> > but how to essentially achieve this:
> >
> > agents[which(agent$membership == 1)] <- agents[which(agent$membership
> > == 1)] + 1
>
>
> Did you try that? I'd do it without the which() because I'm lazy, but
> it should work.

But only if you do not have vector with NA values.

> x<-1:10
> x[c(4,6)]<-NA
> x>5
 [1] FALSE FALSE FALSE    NA FALSE    NA  TRUE  TRUE  TRUE  TRUE
> x[x>5]<-x[x>5]+10
Error in x[x > 5] <- x[x > 5] + 10 :
  NAs are not allowed in subscripted assignments
> x[which(x>5)]<-x[which(x>5)]+10
> x
 [1]  1  2  3 NA  5 NA 17 18 19 20

Cheers
Petr




>
>
>
>
> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From john.archie.mckown at gmail.com  Thu Oct  1 13:18:03 2015
From: john.archie.mckown at gmail.com (John McKown)
Date: Thu, 1 Oct 2015 06:18:03 -0500
Subject: [R] Announcement - The Use Of Nabble For Posting To R-Help Will
 No Longer Be Supported Effective October 15, 2015
In-Reply-To: <90471313-C179-464E-8A84-91C2BCE66CAD@me.com>
References: <90471313-C179-464E-8A84-91C2BCE66CAD@me.com>
Message-ID: <CAAJSdjj2oP2eZR=JoG11CU_CBD88anEAnx58YYNEtBXCQpzwFg@mail.gmail.com>

+1

On Thu, Oct 1, 2015 at 5:55 AM, Marc Schwartz <marc_schwartz at me.com> wrote:

> Greetings all,
>
> On behalf of The R Foundation for Statistical Computing, this is an
> announcement that, effective October 15, 2015, the Nabble online forums
> will no longer be a supported vehicle for posting new threads and/or
> replying to existing threads on R-Help.
>
> This decision was not made lightly and is the result of issues that have
> developed over the past several years. These issues include:
>
> 1. The lack of any context for thread-replies in posts submitted via
> Nabble. This compels readers to take extra time to click on a link in the
> post and visit the Nabble web site to read the reply in context. Many
> email-based R-Help users do not take the time to do this, and therefore do
> not reply to Nabble-based posts.
>
> 2. The use of Nabble by a number of folks who have not subscribed to the R
> email lists directly. Since subscriptions to the R email lists are required
> for posting, these posts are held for moderation, which results in a
> substantial increase in the workload of the **volunteer** list moderators.
> The moderators must take additional time to log into the administrative web
> site interfaces for the R lists to manually review, and approve or reject,
> posts submitted via Nabble.
>
> 3. An increasing level of both publicly and privately expressed animosity
> and frustration on the R lists towards Nabble-based posts because of the
> above and related issues.
>
> Over the past several months, the R Foundation, in cooperation with
> Nabble, has incrementally removed the ability of multiple Nabble archives
> to post new threads on the R email lists, respond to existing threads, and
> privately reply to authors via the Nabble web site.
>
> R-Help, because it is the highest volume of the R lists, is the last R
> email list to undergo this transition. We are announcing the change two
> weeks in advance to afford Nabble users the opportunity to directly
> subscribe to and use the R email-based support lists in the manner
> originally intended.
>
> Information on the various R email lists, including R-Help, is available
> here:
>
>  https://www.r-project.org/mail.html
>
> The existing relevant Nabble archives will become just that -- read only
> and searchable archives -- as a valuable alternative to other R email list
> archives that are available online.
>
> We wish to express our sincere thanks to Hugo Teixeira at Nabble for his
> assistance over the past several months in this process.
>
> For those folks who prefer to use a web-based interface for R-related
> support matters, as opposed to email-based interactions, StackOverflow, as
> one example, provides such a vehicle at:
>
>  http://stackoverflow.com/questions/tagged/r
>
> For those who have general statistical support queries, as per the R
> Posting Guide, StackExchange/Cross Validated at:
>
>  http://stats.stackexchange.com
>
> provides a similar platform.
>
> The R Foundation does not support or endorse the above third-party
> resources, but is simply mentioning them as popular, web-based alternatives
> to the R email lists, which remain our recommended vehicles for focused
> community support for R.
>
> Thank you,
>
> Marc Schwartz
> On Behalf of the R Foundation for Statistical Computing
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Schrodinger's backup: The condition of any backup is unknown until a
restore is attempted.

Yoda of Borg, we are. Futile, resistance is, yes. Assimilated, you will be.

He's about as useful as a wax frying pan.

10 to the 12th power microphones = 1 Megaphone

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Thu Oct  1 13:21:38 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Thu, 1 Oct 2015 13:21:38 +0200
Subject: [R] (subscript) logical subscript too long
In-Reply-To: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
Message-ID: <CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>

Thanks Giorgio, I got it.

 I managed to reach the matrix s whose rows represent  all the possible
combinations. Here is the code:

> n=12
> m=7
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))
> ED<-as.matrix(ED)
> lk<-which(rowSums(ED)<=(n-m))
> s<-ED[lk,]

The problem now is that the code works only for relatively small values of
n and m, but when I use, for ex., n=20 and m=9, I got this error

> n=20
> m=9
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))

*Error: cannot allocate vector of size 1.6 Gb*

*Any Suggestions please?*

*Thanks Again.*
*Maram*

On 30 September 2015 at 17:41, Giorgio Garziano <
giorgio.garziano at ericsson.com> wrote:

> Be:
>
> log <- (rowSums(ED) <= (n - m))
>
>
> Compare the following two values:
>
>
>
>
>
> length(log)
>
>
>
>
>
> nrow(w)
>
>
>
>
>
> --
>
> GG
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Thomas.Chesney at nottingham.ac.uk  Thu Oct  1 13:29:29 2015
From: Thomas.Chesney at nottingham.ac.uk (Thomas Chesney)
Date: Thu, 1 Oct 2015 11:29:29 +0000
Subject: [R] Increment certain values in a vector
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43100@SRVEXCHMBX.precheza.cz>
References: <32EB850C-6B2C-464C-899C-4181EE3B48F8@exmail.nottingham.ac.uk>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43100@SRVEXCHMBX.precheza.cz>
Message-ID: <D21E4684-4ED8-41EB-9018-80FA2C4132E7@exmail.nottingham.ac.uk>

I got it sorted thank you. As you point out, the original code works fine (there was a type mismatch with it).


On 1 Oct 2015, at 12:00, PIKAL Petr <petr.pikal at precheza.cz> wrote:

Hi

Are agents and agent different objects? Or it is a typo? Better would be to provide some real or fake data by dput or at least result of str(agent) and str(agents)

Actually your code shall work in case agent and agents have same length and expected order.

agents[which(agent$membership == 1)] <- agents[which(agent$membership == 1)] + 1

For less typing you can do:

sel <- which(agent$membership == 1)
agents[sel] <- agents[sel] + 1

The code can be different if agent or agents are objects like matrix or array. Actually from the code xxx$yyy I presume it is data frame or list.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Thomas
> Chesney
> Sent: Thursday, October 01, 2015 12:04 PM
> To: r-help at r-project.org
> Subject: [R] Increment certain values in a vector
> 
> How can I manipulate values of only certain entries in a vector, based
> on what the existing values are?
> 
> So for instance if I want to add one to each of the following values,
> or multiply them by a specific factor:
> 
> agents[which(agent$membership == 1)]
> 
> how would I do this please?
> 
> If there was just one value to manipulate I'd just do this:
> 
> value <- value + 1
> 
> and this would let me set the values:
> 
> agents[which(agent$membership == 1)] <- 100
> 
> but how to essentially achieve this:
> 
> agents[which(agent$membership == 1)] <- agents[which(agent$membership
> == 1)] + 1
> 
> Thank you!
> 
> 
> 
> This message and any attachment are intended solely for the addressee
> and may contain confidential information. If you have received this
> message in error, please send it back to me, and immediately delete it.
> 
> Please do not use, copy or disclose the information contained in this
> message or in any attachment.  Any views or opinions expressed by the
> author of this email do not necessarily reflect the views of the
> University of Nottingham.
> 
> This message has been checked for viruses but the contents of an
> attachment may still contain software viruses which could damage your
> computer system, you are advised to perform your own checks. Email
> communications with the University of Nottingham may be monitored as
> permitted by UK legislation.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.





This message and any attachment are intended solely for the addressee
and may contain confidential information. If you have received this
message in error, please send it back to me, and immediately delete it. 

Please do not use, copy or disclose the information contained in this
message or in any attachment.  Any views or opinions expressed by the
author of this email do not necessarily reflect the views of the
University of Nottingham.

This message has been checked for viruses but the contents of an
attachment may still contain software viruses which could damage your
computer system, you are advised to perform your own checks. Email
communications with the University of Nottingham may be monitored as
permitted by UK legislation.


From giorgio.garziano at ericsson.com  Thu Oct  1 13:37:25 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 1 Oct 2015 11:37:25 +0000
Subject: [R] (subscript) logical subscript too long
In-Reply-To: <CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>
References: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
	<CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>
Message-ID: <248E6FA047A8C746BA491485764190F5220958EC@ESESSMB207.ericsson.se>

Check your memory size by:

memory.limit()

try to increase it by:

memory.limit(size=4096)



From: Maram SAlem [mailto:marammagdysalem at gmail.com]
Sent: gioved? 1 ottobre 2015 13:22
To: Giorgio Garziano
Cc: r-help at r-project.org
Subject: Re: [R] (subscript) logical subscript too long

Thanks Giorgio, I got it.

 I managed to reach the matrix s whose rows represent  all the possible combinations. Here is the code:

> n=12
> m=7
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))
> ED<-as.matrix(ED)
> lk<-which(rowSums(ED)<=(n-m))
> s<-ED[lk,]

The problem now is that the code works only for relatively small values of n and m, but when I use, for ex., n=20 and m=9, I got this error

> n=20
> m=9
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))

Error: cannot allocate vector of size 1.6 Gb

Any Suggestions please?

Thanks Again.
Maram

On 30 September 2015 at 17:41, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Be:

log <- (rowSums(ED) <= (n - m))


Compare the following two values:





length(log)





nrow(w)





--

GG


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Thu Oct  1 14:11:37 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Thu, 1 Oct 2015 14:11:37 +0200
Subject: [R] (subscript) logical subscript too long
In-Reply-To: <248E6FA047A8C746BA491485764190F5220958EC@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
	<CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F5220958EC@ESESSMB207.ericsson.se>
Message-ID: <CAPLSCn0faSoqj25wtS9e6cwu8_XcnuDi0PE6wENLri0-d1iMbA@mail.gmail.com>

Thanks a lot Giorgio, I used

memory.limit(size=4096)

but got

 don't be silly!: your machine has a 4Gb address limit

I'm working on my Ph.D. thesis and I have a huge code of which this is just
a very small part, so does this error mean that I need a new computer with
extended capabilites to be able to execute my code?? I'm currently using
intel core i3, windows 7

Thanks for helping.

Maram


On 1 October 2015 at 13:37, Giorgio Garziano <giorgio.garziano at ericsson.com>
wrote:

> Check your memory size by:
>
>
>
> memory.limit()
>
>
>
> try to increase it by:
>
>
>
> memory.limit(size=4096)
>
>
>
>
>
>
>
> *From:* Maram SAlem [mailto:marammagdysalem at gmail.com]
> *Sent:* gioved? 1 ottobre 2015 13:22
> *To:* Giorgio Garziano
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] (subscript) logical subscript too long
>
>
>
> Thanks Giorgio, I got it.
>
>
>
>  I managed to reach the matrix s whose rows represent  all the possible
> combinations. Here is the code:
>
>
>
> > n=12
>
> > m=7
>
> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>
> > for (i in 1:m-1)
>
> +  {
>
> + D[,i]<-seq(0,n-m,1)
>
> +  }
>
> > ED <- do.call(`expand.grid`,as.data.frame(D))
>
> > ED<-as.matrix(ED)
>
> > lk<-which(rowSums(ED)<=(n-m))
>
> > s<-ED[lk,]
>
>
>
> The problem now is that the code works only for relatively small values of
> n and m, but when I use, for ex., n=20 and m=9, I got this error
>
>
>
> > n=20
>
> > m=9
>
> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>
> > for (i in 1:m-1)
>
> +  {
>
> + D[,i]<-seq(0,n-m,1)
>
> +  }
>
> > ED <- do.call(`expand.grid`,as.data.frame(D))
>
>
>
> *Error: cannot allocate vector of size 1.6 Gb*
>
>
>
> *Any Suggestions please?*
>
>
>
> *Thanks Again.*
>
> *Maram*
>
>
>
> On 30 September 2015 at 17:41, Giorgio Garziano <
> giorgio.garziano at ericsson.com> wrote:
>
> Be:
>
> log <- (rowSums(ED) <= (n - m))
>
>
> Compare the following two values:
>
>
>
>
>
> length(log)
>
>
>
>
>
> nrow(w)
>
>
>
>
>
> --
>
> GG
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Thu Oct  1 14:15:29 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 1 Oct 2015 12:15:29 +0000
Subject: [R] (subscript) logical subscript too long
In-Reply-To: <CAPLSCn0faSoqj25wtS9e6cwu8_XcnuDi0PE6wENLri0-d1iMbA@mail.gmail.com>
References: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
	<CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F5220958EC@ESESSMB207.ericsson.se>
	<CAPLSCn0faSoqj25wtS9e6cwu8_XcnuDi0PE6wENLri0-d1iMbA@mail.gmail.com>
Message-ID: <248E6FA047A8C746BA491485764190F522095962@ESESSMB207.ericsson.se>

The ?4096? was just an example.

Try:

memory.limit(size=3968)


Furthermore, to overcome memory size limits vs. in memory R data management beyond your 4Gb,
you may explore package ?ff?.

--
Cheers,

GG

From: Maram SAlem [mailto:marammagdysalem at gmail.com]
Sent: gioved? 1 ottobre 2015 14:12
To: Giorgio Garziano
Cc: r-help at r-project.org
Subject: Re: [R] (subscript) logical subscript too long

Thanks a lot Giorgio, I used

memory.limit(size=4096)

but got

 don't be silly!: your machine has a 4Gb address limit

I'm working on my Ph.D. thesis and I have a huge code of which this is just a very small part, so does this error mean that I need a new computer with extended capabilites to be able to execute my code?? I'm currently using intel core i3, windows 7

Thanks for helping.

Maram


On 1 October 2015 at 13:37, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Check your memory size by:

memory.limit()

try to increase it by:

memory.limit(size=4096)



From: Maram SAlem [mailto:marammagdysalem at gmail.com<mailto:marammagdysalem at gmail.com>]
Sent: gioved? 1 ottobre 2015 13:22
To: Giorgio Garziano
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] (subscript) logical subscript too long

Thanks Giorgio, I got it.

 I managed to reach the matrix s whose rows represent  all the possible combinations. Here is the code:

> n=12
> m=7
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))
> ED<-as.matrix(ED)
> lk<-which(rowSums(ED)<=(n-m))
> s<-ED[lk,]

The problem now is that the code works only for relatively small values of n and m, but when I use, for ex., n=20 and m=9, I got this error

> n=20
> m=9
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))

Error: cannot allocate vector of size 1.6 Gb

Any Suggestions please?

Thanks Again.
Maram

On 30 September 2015 at 17:41, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Be:

log <- (rowSums(ED) <= (n - m))


Compare the following two values:





length(log)





nrow(w)





--

GG


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Thu Oct  1 14:27:52 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 1 Oct 2015 12:27:52 +0000
Subject: [R] (subscript) logical subscript too long
In-Reply-To: <CAPLSCn0faSoqj25wtS9e6cwu8_XcnuDi0PE6wENLri0-d1iMbA@mail.gmail.com>
References: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
	<CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F5220958EC@ESESSMB207.ericsson.se>
	<CAPLSCn0faSoqj25wtS9e6cwu8_XcnuDi0PE6wENLri0-d1iMbA@mail.gmail.com>
Message-ID: <248E6FA047A8C746BA491485764190F522095986@ESESSMB207.ericsson.se>

If you are running a 32-bit Windows, there are following upper limits:

https://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-uses_0021


starts by:

memory.limit(size=1920)

and try increasing value of size as a parameter for memory.limit().


I use Intel i5 Windows-7 64-bit 16GB RAM.


GG



From: Maram SAlem [mailto:marammagdysalem at gmail.com]
Sent: gioved? 1 ottobre 2015 14:12
To: Giorgio Garziano
Cc: r-help at r-project.org
Subject: Re: [R] (subscript) logical subscript too long

Thanks a lot Giorgio, I used

memory.limit(size=4096)

but got

 don't be silly!: your machine has a 4Gb address limit

I'm working on my Ph.D. thesis and I have a huge code of which this is just a very small part, so does this error mean that I need a new computer with extended capabilites to be able to execute my code?? I'm currently using intel core i3, windows 7

Thanks for helping.

Maram


On 1 October 2015 at 13:37, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Check your memory size by:

memory.limit()

try to increase it by:

memory.limit(size=4096)



From: Maram SAlem [mailto:marammagdysalem at gmail.com<mailto:marammagdysalem at gmail.com>]
Sent: gioved? 1 ottobre 2015 13:22
To: Giorgio Garziano
Cc: r-help at r-project.org<mailto:r-help at r-project.org>
Subject: Re: [R] (subscript) logical subscript too long

Thanks Giorgio, I got it.

 I managed to reach the matrix s whose rows represent  all the possible combinations. Here is the code:

> n=12
> m=7
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))
> ED<-as.matrix(ED)
> lk<-which(rowSums(ED)<=(n-m))
> s<-ED[lk,]

The problem now is that the code works only for relatively small values of n and m, but when I use, for ex., n=20 and m=9, I got this error

> n=20
> m=9
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))

Error: cannot allocate vector of size 1.6 Gb

Any Suggestions please?

Thanks Again.
Maram

On 30 September 2015 at 17:41, Giorgio Garziano <giorgio.garziano at ericsson.com<mailto:giorgio.garziano at ericsson.com>> wrote:
Be:

log <- (rowSums(ED) <= (n - m))


Compare the following two values:





length(log)





nrow(w)





--

GG


        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From butt_its_me at hotmail.com  Thu Oct  1 14:40:42 2015
From: butt_its_me at hotmail.com (Jhon Grey)
Date: Thu, 1 Oct 2015 18:10:42 +0530
Subject: [R] GBM predict
Message-ID: <BAY178-W192305FBE349E86BF88BBCBE4C0@phx.gbl>

I am new to GBM and I am trying to run it on "train.1" dataset(dim(train.1)   39947    43) and checking predictions on "test"(dim(test) 20000 192) using the codes:
gbmFit1 <- train(as.factor(train.1$Labels)~., data = train.1[,-43], method = "gbm", trControl = fitControl,verbose = FALSE)
gbm_dev <- predict(gbmFit1,test,type= "prob")[,2]
However the results of my predictions are having length(gbm_dev) as 3226 !!
What am I doing wrong? 		 	   		  
	[[alternative HTML version deleted]]


From Michael.Laviolette at dhhs.state.nh.us  Thu Oct  1 14:42:24 2015
From: Michael.Laviolette at dhhs.state.nh.us (Michael.Laviolette at dhhs.state.nh.us)
Date: Thu, 1 Oct 2015 08:42:24 -0400
Subject: [R] Splitting data frame into columns with dplyr
Message-ID: <OFF948EF2B.3637B75D-ON85257ECA.006403D5-85257ED1.0045CD03@dhhs.state.nh.us>


I have a data frame with a structure similar to the following. The variable
z is a grouping variable; x and y are measurement variables.

library(dplyr)
df <- data.frame(z = rep(c("A", "B")), x = 1:6, y = 7:12) %>%
  arrange(z)

  z x  y
1 A 1  7
2 A 3  9
3 A 5 11
4 B 2  8
5 B 4 10
6 B 6 12

I need to reshape into one column for each group-measurement combination as
below. Preferably using dplyr functions, how can I get to this?

  A.x   A.y   B.x   B.y
1   1     7     2     8
2   3     9     4    10
3   5    11     6    12

Thanks,
M.L.


From marammagdysalem at gmail.com  Thu Oct  1 14:44:29 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Thu, 1 Oct 2015 14:44:29 +0200
Subject: [R] (subscript) logical subscript too long
In-Reply-To: <248E6FA047A8C746BA491485764190F522095986@ESESSMB207.ericsson.se>
References: <248E6FA047A8C746BA491485764190F52209557A@ESESSMB207.ericsson.se>
	<CAPLSCn1DMgPuq6w2pxMomsGbY1dcU9X_Z7L-KCfPAb8ejibe6g@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F5220958EC@ESESSMB207.ericsson.se>
	<CAPLSCn0faSoqj25wtS9e6cwu8_XcnuDi0PE6wENLri0-d1iMbA@mail.gmail.com>
	<248E6FA047A8C746BA491485764190F522095986@ESESSMB207.ericsson.se>
Message-ID: <CAPLSCn30z-0HwoBQXnERm7EybM4R66nx=YEFzHd6tj1Mwe8X5Q@mail.gmail.com>

Thanks a lot Giorgio for your Help
Regards,
Maram

On 1 October 2015 at 14:27, Giorgio Garziano <giorgio.garziano at ericsson.com>
wrote:

> If you are running a 32-bit Windows, there are following upper limits:
>
>
>
>
> https://cran.r-project.org/bin/windows/base/rw-FAQ.html#There-seems-to-be-a-limit-on-the-memory-it-uses_0021
>
>
>
>
>
> starts by:
>
>
>
> memory.limit(size=1920)
>
>
>
> and try increasing value of size as a parameter for memory.limit().
>
>
>
>
>
> I use Intel i5 Windows-7 64-bit 16GB RAM.
>
>
>
>
>
> GG
>
>
>
>
>
>
>
> *From:* Maram SAlem [mailto:marammagdysalem at gmail.com]
> *Sent:* gioved? 1 ottobre 2015 14:12
>
> *To:* Giorgio Garziano
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] (subscript) logical subscript too long
>
>
>
> Thanks a lot Giorgio, I used
>
>
>
> memory.limit(size=4096)
>
>
>
> but got
>
>
>
>  don't be silly!: your machine has a 4Gb address limit
>
>
>
> I'm working on my Ph.D. thesis and I have a huge code of which this is
> just a very small part, so does this error mean that I need a new computer
> with extended capabilites to be able to execute my code?? I'm currently
> using intel core i3, windows 7
>
>
>
> Thanks for helping.
>
>
>
> Maram
>
>
>
>
>
> On 1 October 2015 at 13:37, Giorgio Garziano <
> giorgio.garziano at ericsson.com> wrote:
>
> Check your memory size by:
>
>
>
> memory.limit()
>
>
>
> try to increase it by:
>
>
>
> memory.limit(size=4096)
>
>
>
>
>
>
>
> *From:* Maram SAlem [mailto:marammagdysalem at gmail.com]
> *Sent:* gioved? 1 ottobre 2015 13:22
> *To:* Giorgio Garziano
> *Cc:* r-help at r-project.org
> *Subject:* Re: [R] (subscript) logical subscript too long
>
>
>
> Thanks Giorgio, I got it.
>
>
>
>  I managed to reach the matrix s whose rows represent  all the possible
> combinations. Here is the code:
>
>
>
> > n=12
>
> > m=7
>
> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>
> > for (i in 1:m-1)
>
> +  {
>
> + D[,i]<-seq(0,n-m,1)
>
> +  }
>
> > ED <- do.call(`expand.grid`,as.data.frame(D))
>
> > ED<-as.matrix(ED)
>
> > lk<-which(rowSums(ED)<=(n-m))
>
> > s<-ED[lk,]
>
>
>
> The problem now is that the code works only for relatively small values of
> n and m, but when I use, for ex., n=20 and m=9, I got this error
>
>
>
> > n=20
>
> > m=9
>
> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>
> > for (i in 1:m-1)
>
> +  {
>
> + D[,i]<-seq(0,n-m,1)
>
> +  }
>
> > ED <- do.call(`expand.grid`,as.data.frame(D))
>
>
>
> *Error: cannot allocate vector of size 1.6 Gb*
>
>
>
> *Any Suggestions please?*
>
>
>
> *Thanks Again.*
>
> *Maram*
>
>
>
> On 30 September 2015 at 17:41, Giorgio Garziano <
> giorgio.garziano at ericsson.com> wrote:
>
> Be:
>
> log <- (rowSums(ED) <= (n - m))
>
>
> Compare the following two values:
>
>
>
>
>
> length(log)
>
>
>
>
>
> nrow(w)
>
>
>
>
>
> --
>
> GG
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Thu Oct  1 15:24:46 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Thu, 1 Oct 2015 15:24:46 +0200
Subject: [R] Splitting data frame into columns with dplyr
In-Reply-To: <OFF948EF2B.3637B75D-ON85257ECA.006403D5-85257ED1.0045CD03@dhhs.state.nh.us>
References: <OFF948EF2B.3637B75D-ON85257ECA.006403D5-85257ED1.0045CD03@dhhs.state.nh.us>
Message-ID: <CAJuCY5yN6hiiR4b1sgTqBKXZ1FShvnsMW5j_fv3qThcHW7cmBw@mail.gmail.com>

Dear Michael,

You'll need a combination of dplyr and tidyr

library(dplyr)
library(tidyr)

data.frame(id = rep(1:3, 2), z = rep(c("A", "B")), x = 1:6, y = 7:12) %>%
  arrange(z) %>%
  gather(variable, value, -z, -id) %>%
  mutate(newcol = paste(z, variable, sep = ".")) %>%
  select(-z, -variable) %>%
  spread(newcol, value)


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-01 14:42 GMT+02:00 <Michael.Laviolette at dhhs.state.nh.us>:

>
> I have a data frame with a structure similar to the following. The variable
> z is a grouping variable; x and y are measurement variables.
>
> library(dplyr)
> df <- data.frame(z = rep(c("A", "B")), x = 1:6, y = 7:12) %>%
>   arrange(z)
>
>   z x  y
> 1 A 1  7
> 2 A 3  9
> 3 A 5 11
> 4 B 2  8
> 5 B 4 10
> 6 B 6 12
>
> I need to reshape into one column for each group-measurement combination as
> below. Preferably using dplyr functions, how can I get to this?
>
>   A.x   A.y   B.x   B.y
> 1   1     7     2     8
> 2   3     9     4    10
> 3   5    11     6    12
>
> Thanks,
> M.L.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tal.galili at gmail.com  Thu Oct  1 15:25:08 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Thu, 1 Oct 2015 16:25:08 +0300
Subject: [R] Making as.hclust.phylo for non binary trees work?
Message-ID: <CANdJ3dUfEg4MpUysx_UCyO2Wtti0qZi2pQfs-e49xoaKEdcWaQ@mail.gmail.com>

Dear R-help mailing list (and Emmanuel, the ape package maintainer),

I would like to change a non binary phylo object to hclust, but this does
not seem to work smoothly.

Here is a small R code to demonstrate the problem:

# an hclust tree with 3 branches from the root
hc <- hclust(dist(c(1:2, 4,5, 7,8)), method = "single")
plot(hc)

# we can change it to phylo just fine:
library(ape)
phy <- as.phylo(hc)
plot(phy)
# for some reason it claims the object is binary
is.binary.tree(phy) # TRUE

# it turns to hclust
hc2 <- as.hclust(phy)
# but the plotting fails:
plot(hc2)
# Error in plot.hclust(hc2) : 'merge' matrix has invalid contents
cutree(hc2, 2) # works, but doesn't give any warning that it actually can't
provide with only 2 clusters...



Thanks upfront for any help.

Best,
Tal



----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Thu Oct  1 15:42:51 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 1 Oct 2015 13:42:51 +0000
Subject: [R] Splitting data frame into columns with dplyr
Message-ID: <248E6FA047A8C746BA491485764190F522095A35@ESESSMB207.ericsson.se>

library(dplyr)
df <- data.frame(z = rep(c("A", "B")), x = 1:6, y = 7:12) %>%
arrange(z)

temp <- reshape(df, v.names = c("x", "y"), idvar = c("x", "y"), timevar = "z", direction = "wide")
lA <- na.omit(temp[,c("x.A", "y.A")])
lB <- na.omit(temp[,c("x.B", "y.B")])
df.long <- as.data.frame(cbind(lA,lB))
colnames(df.long) <- c("A.x", "A.y", "B.x", "B.y")
df.long

  A.x A.y B.x B.y
1   1   7   2   8
2   3   9   4  10
3   5  11   6  12


Reference:

http://blog.wildintellect.com/blog/reshape


--
GG




	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Thu Oct  1 15:17:07 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 1 Oct 2015 13:17:07 +0000
Subject: [R] optimizing with non-linear constraints
In-Reply-To: <m2pp0z11lk.fsf@krugs.de>
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	<m2pp0z11lk.fsf@krugs.de>
Message-ID: <3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>

I would recommend that you use auglag() rather than constrOptim.nl() in the package "alabama."  It is a better algorithm, and it does not require feasible starting values.
Best,
Ravi  

-----Original Message-----
From: Rainer M Krug [mailto:Rainer at krugs.de] 
Sent: Thursday, October 01, 2015 3:37 AM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: 'r-help at r-project.org' <r-help at r-project.org>
Subject: Re: optimizing with non-linear constraints

Ravi Varadhan <ravi.varadhan at jhu.edu> writes:

> Hi Rainer,
> It is very simple to specify the constraints (linear or nonlinear) in 
> "alabama" .  They are specified in a function called `hin', where the 
> constraints are written such that they are positive.

OK - I somehow missed the part that, when the values x are valid, i.e. in the range as defined by the conditions, the result of hin(x) that they are all positive.

> Your two nonlinear constraints would be written as follows:
>
> hin <- function(x, LAI) {
> h <- rep(NA, 2)
> h[1] <- LAI^x[2] / x[3] + x[1]
> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
> h
> }

Makes perfect sense.

>
> Please take a look at the help page.  If it is still not clear, you can contact me offline.

Yup - I did. But I somehow missed the fact stated above.

I am using constrOptim() and constrOptim.nl() for a paper and am compiling a separate document which explains how to get the constraints for the two functions step by step - I will make it available as a blog post and a pdf.

I might have further questions concerning the different fitting functions and which ones are the most appropriate in my case.

Thanks a lot,

Rainer


> Best,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
> Associate Professor,  Department of Oncology Division of Biostatistics 
> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns 
> Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
> 	[[alternative HTML version deleted]]
>

--
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982


From r.m.krug at gmail.com  Thu Oct  1 15:44:31 2015
From: r.m.krug at gmail.com (Rainer M Krug)
Date: Thu, 1 Oct 2015 15:44:31 +0200
Subject: [R] optimizing with non-linear constraints
In-Reply-To: <3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	<m2pp0z11lk.fsf@krugs.de>
	<3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>
Message-ID: <3237162B-493D-414E-A6BC-1B975F68C0C2@gmail.com>



Envoy? de mon iPhone

> Le 1 oct. 2015 ? 15:17, Ravi Varadhan <ravi.varadhan at jhu.edu> a ?crit :
> 
> I would recommend that you use auglag() rather than constrOptim.nl() in the package "alabama."  It is a better algorithm, and it does not require feasible starting values.

Thanks - that was one question I wanted to ask later. 

I will do so,

Rainer

> Best,
> Ravi  
> 
> -----Original Message-----
> From: Rainer M Krug [mailto:Rainer at krugs.de] 
> Sent: Thursday, October 01, 2015 3:37 AM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: 'r-help at r-project.org' <r-help at r-project.org>
> Subject: Re: optimizing with non-linear constraints
> 
> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
> 
>> Hi Rainer,
>> It is very simple to specify the constraints (linear or nonlinear) in 
>> "alabama" .  They are specified in a function called `hin', where the 
>> constraints are written such that they are positive.
> 
> OK - I somehow missed the part that, when the values x are valid, i.e. in the range as defined by the conditions, the result of hin(x) that they are all positive.
> 
>> Your two nonlinear constraints would be written as follows:
>> 
>> hin <- function(x, LAI) {
>> h <- rep(NA, 2)
>> h[1] <- LAI^x[2] / x[3] + x[1]
>> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
>> h
>> }
> 
> Makes perfect sense.
> 
>> 
>> Please take a look at the help page.  If it is still not clear, you can contact me offline.
> 
> Yup - I did. But I somehow missed the fact stated above.
> 
> I am using constrOptim() and constrOptim.nl() for a paper and am compiling a separate document which explains how to get the constraints for the two functions step by step - I will make it available as a blog post and a pdf.
> 
> I might have further questions concerning the different fitting functions and which ones are the most appropriate in my case.
> 
> Thanks a lot,
> 
> Rainer
> 
> 
>> Best,
>> Ravi
>> 
>> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
>> Associate Professor,  Department of Oncology Division of Biostatistics 
>> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns 
>> Hopkins University
>> 550 N. Broadway, Suite 1111-E
>> Baltimore, MD 21205
>> 410-502-2619
>> 
>> 
>>    [[alternative HTML version deleted]]
>> 
> 
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982


From dulcalma at bigpond.com  Thu Oct  1 16:38:56 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Fri, 2 Oct 2015 00:38:56 +1000
Subject: [R] Count number of rain more than zero in matrix form
In-Reply-To: <233989687.2807383.1443667634271.JavaMail.yahoo@mail.yahoo.com>
References: <233989687.2807383.1443667634271.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <000d01d0fc56$e73dfa10$b5b9ee30$@bigpond.com>

Hi

Assuming you data.frame is dat
then you have to restrict the data going to a function to be counted so that it counts values > 0

with(dat, tapply(Amount, list(Year, Month), function(x) length(x[x > 0])) )
gives

      1  2  3  4  5  6  7  8  9 10 11 12
1960 24 15  2 12 19 22 18 24 22 20 30 29
1961 26  9 10 18 18 11 18 14 24 28 30 31
1962 22 14 19  2 18 19 27 26 26 29 15 28
1963 27 17 15  4  9 23 16 24 19 28 30 22
1964 15 25  9 13 19 14 23 20 24 30 25 27
1965 13 21 12 10 21 24 22 21 28 23 28 31

If you want to have years and months in date format you could use
the as.yearmon function from library(zoo) after converting year month day to a date format with as.Date
and go on from there

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of smart hendsome
Sent: Thursday, 1 October 2015 12:47
To: r-help at r-project.org
Subject: [R] Count number of rain more than zero in matrix form

Hello R-users,
I want to ask how to count the number of daily rain data.  My data using dput() as below:
structure(list(Year = c(1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L), Month = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L), Amount = c(0.3, 0, 0, 0, 0, 2.7, 7.1, 14, 
12.6, 11.1, 5.5, 1.2, 1.2, 1, 5.3, 2.5, 0, 0, 0.5, 14.6, 130.4, 
66.5, 4.1, 3.7, 1.4, 2, 9.1, 8.8, 7.4, 2.5, 0, 0, 0, 10.1, 5.5, 
6.8, 6.3, 1.5, 0, 0, 0, 0, 0, 2.5, 11.7, 6.2, 0.5, 0.7, 0.3, 
2.5, 2.3, 1, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 16.2, 18.6, 15.2, 48.3, 26.7, 2.9, 0.2, 0, 0, 
0, 0, 0, 1.1, 1.4, 0.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.1, 
2.5, 5.2, 2.6, 0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 6.1, 4.7, 2.8, 
1, 0.5, 1.6, 2.1, 0.7, 0, 6.4, 3.5, 0.2, 0, 0, 0, 0, 0, 0, 0, 
21.3, 10.7, 2, 4.2, 1.9, 2.8, 21.1, 9.9, 0.7, 2, 10.4, 5.3, 29.6, 
14.7, 0, 0, 0, 4.4, 2.2, 0, 0, 0.8, 0.4, 0, 3.3, 3.1, 1.9, 0.6, 
0, 4.7, 2.4, 0, 0, 0, 0, 5.9, 25.7, 11.4, 0, 0, 0, 0, 2.7, 1.3, 
0, 0, 0, 0, 0, 0, 5.9, 28.1, 12.6, 68.2, 34.4, 0.6, 8.2, 4.3, 
0.2, 17.9, 30.6, 21.1, 5.1, 0, 0, 0.1, 3.6, 8.7, 8.9, 6.7, 13.7, 
10, 2.1, 11.8, 5.9, 0, 0, 0, 0, 0, 19.5, 31.1, 38.3, 20, 3.1, 
5.1, 6.4, 12.4, 5.2, 2.5, 9, 4, 0.1, 0.1, 0.5, 17, 8.8, 0.6, 
0.2, 0, 0, 0, 40.3, 20.1, 5.1, 14.3, 20.2, 13.2, 4.8, 1.4, 0.2, 
0, 1, 0.5, 0, 0, 0, 3.7, 1.8, 15.4, 7.7, 0, 3.9, 8, 3, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 45.5, 22.8, 9.9, 5, 4.4, 2.7, 0.2, 
0.8, 3.4, 10.3, 6.2, 7.5, 7.3, 20.3, 22, 28.9, 31.7, 39.2, 14.5, 
10.5, 34.8, 43.7, 43.5, 144.9, 143, 68, 18.2, 1.8, 0.5, 16.1, 
15.5, 3.8, 51.6, 25.8, 0.7, 1.5, 13.8, 27.2, 10.3, 1.5, 1.7, 
5.9, 12, 4.6, 1.7, 6.4, 11.7, 16.5, 38.3, 35.8, 16.7, 3.5, 1.8, 
35.9, 58.1, 40.9, 15, 14.5, 6.1, 0, 0, 3.3, 13.5, 6.9, 1.2, 2.7, 
1.2, 15.2, 16, 12.5, 14.4, 9.3, 2.1, 2.5, 25.6, 96.8, 99.5, 39.9, 
23.9, 9.1, 1.7, 3.8, 12, 6.4, 15.4, 8.8, 1.5, 10.7, 26.5, 20.9, 
7.7, 1.7, 1.2, 0.8, 0.6, 1, 0.4, 0, 6.1, 3.5, 0.2, 0, 0, 0, 0.8, 
3.7, 12.8, 8.9, 5.3, 1.8, 0, 0, 0, 0, 0, 0, 0, 4.4, 2.2, 0, 0, 
5.1, 5.9, 10.6, 9.3, 7.6, 4.1, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 22.1, 11.1, 0, 0, 23.1, 25.4, 12.8, 
2.9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 11.8, 13.9, 6, 
19.9, 35.9, 13.2, 0, 0, 0, 0, 0, 0, 0, 0, 3.2, 1.6, 0.8, 16.6, 
8.1, 11.3, 5.8, 10.9, 7.1, 0.8, 0, 0, 0, 0, 11, 37.3, 18.9, 14.4, 
14.5, 4, 0, 0, 1, 0.5, 0.3, 3.7, 1.8, 0, 0, 0, 9.8, 4.9, 3, 1.5, 
0, 0, 0, 0, 0, 0, 7.6, 3.8, 0, 0, 2.3, 1.2, 2.5, 1.3, 0.8, 0.4, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27.1, 44.3, 17.4, 1.7, 0.3, 
0, 5.4, 2.7, 0, 2.5, 1.3, 0, 0, 4.4, 2.2, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0.5, 0.2, 0, 25, 12.5, 0, 7.4, 7.6, 1.9, 2.5, 1.3, 0, 
0, 35.9, 37.1, 20.6, 7.5, 1, 0, 0.1, 0.2, 3.1, 1.5, 0, 0, 0, 
0, 0, 12.7, 6.3, 0, 0, 0, 0.1, 4.8, 4.9, 2.1, 23.4, 11.5, 6.9, 
31.2, 36.9, 11.5, 32, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 
0.1, 0, 0, 6.7, 17, 25.8, 9.5, 6.4, 9.6, 10.3, 5.5, 36.5, 17.9, 
0.1, 0.3, 0.2, 14.2, 7.1, 0, 0, 21.5, 30.2, 10.1, 0.2, 0, 9.6, 
4.8, 2, 13.3, 13.2, 3.5, 13.7, 12.9, 33.5, 15.2, 0, 5.7, 5.2, 
1.2, 10.8, 51.9, 24.3, 1.8, 0.7, 4.9, 21.9, 17.5, 5, 4.4, 1.9, 
5.9, 2.9, 0, 8.1, 4, 0, 0.3, 15.7, 71.2, 116, 62.9, 48.5, 28.3, 
19.8, 35.7, 20.1, 9.8, 31.3, 32.6, 30.6, 28.4, 15.6, 4.8, 7.8, 
44.3, 29.7, 18.2, 6.8, 3.9, 6.5, 31.9, 45.1, 37.3, 14.9, 11.5, 
24.9, 25.3, 143.9, 101.9, 28.2, 21.7, 32.2, 13.8, 9.6, 28.9, 
12.6, 9.6, 30.5, 12.9, 1.5, 1.9, 0.9, 25.4, 46.4, 28.2, 22.2, 
10.8, 7.3, 3, 34.2, 84.8, 71, 28.7, 16.9, 62.1, 104.4, 89.8, 
42.9, 9.3, 3.1, 3.5, 2.1, 0.8, 0.2, 0, 0, 0, 5.1, 6.1, 5.8, 4, 
1, 4.4, 4.2, 6.1, 7.1, 2.3, 1.5, 2.5, 0.9, 0, 0, 0, 0, 0, 19.3, 
10.6, 0.6, 0.1, 0, 1.5, 3.3, 1.3, 3, 1.5, 0, 0.1, 0.1, 0, 0, 
0, 0, 0, 0, 0, 0, 0.3, 0.3, 0.5, 0.2, 0, 0, 0, 0.3, 1.6, 0.7, 
0, 0, 6.6, 13.6, 6.6, 4.1, 12.7, 31.4, 13.1, 0.1, 0, 0, 0, 0.5, 
0.4, 0.1, 0, 5.5, 2.8, 0, 0, 0, 0, 0, 0, 1.1, 25.4, 15.3, 16.6, 
7.6, 0, 0, 0.5, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 0, 5.4, 2.7, 
0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 0, 0, 0.5, 0.2, 32.7, 16.3, 0, 
12.9, 6.4, 0, 7.7, 4.2, 6, 2.9, 5.1, 2.7, 0.1, 0, 3.5, 1.8, 0, 
0, 8.9, 4.5, 0, 0, 0, 3.9, 1.9, 0, 0, 49.4, 25.7, 0.5, 0, 0, 
3.9, 1.9, 0.5, 0.2, 0, 31.6, 20.5, 14.5, 6.1, 0.7, 0.3, 0, 29.9, 
39, 12, 7.1, 3.5, 18.9, 9.9, 9.5, 4.6, 0, 1.3, 8.9, 4.1, 4.5, 
7.3, 2.5, 0, 0, 0, 18.9, 16.9, 19.8, 8, 3.3, 1.7, 8.4, 13.3, 
19.2, 7.3, 2, 6.2, 2.6, 0, 0, 0, 6.6, 3.3, 0.5, 0.2, 0, 0.8, 
34.2, 28.9, 28.3, 23.3, 6.1, 0, 1, 0.5, 12.7, 9.2, 6.2, 20, 15.4, 
18.8, 28.7, 25.7, 14.2, 3.3, 30.1, 17.7, 23.3, 32.3, 18.7, 5.8, 
0.9, 13.9, 11.7, 2.4, 64.7, 54.3, 11.8, 1.1, 8.7, 4.2, 2.3, 31.1, 
16.6, 1.2, 5, 2.4, 0, 0, 0, 0, 18.9, 9.5, 10.1, 26.5, 10.9, 7, 
3.6, 26.8, 13.4, 7.4, 5.4, 0.8, 2.3, 2.5, 0.7, 0.3, 0.8, 0.7, 
0.3, 0.1, 0, 5.2, 4.3, 4, 17.3, 14.6, 24, 27, 22.6, 13, 29.8, 
30.8, 8.7, 25.7, 29.9, 36.3, 14.5, 0.3, 0, 0, 0, 0, 37.7, 29.3, 
13, 3.9, 1.1, 37.1, 18.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
6.9, 3.5, 26.1, 101, 51.1, 5.3, 8, 25, 109.7, 104.5, 90.3, 50.7, 
10.4, 0.5, 0.4, 1.5, 5.1, 4.5, 1.8, 0.3, 0, 0.8, 0.9, 55.8, 44.3, 
15.3, 10.3, 5.2, 8.3, 4.5, 4.4, 2, 0.3, 0.2, 0, 0, 25, 13.3, 
1.7, 33.3, 74.1, 29.3, 6.1, 15.6, 13.7, 4.2, 0.2, 0, 0, 0.1, 
0.1, 1, 0.8, 8.6, 11.8, 3.9, 0.2, 0.1, 10.3, 5.1, 0, 0.1, 0.1, 
0, 13.3, 9.9, 7, 3.7, 2, 0.7, 0, 0, 0, 0.3, 6.9, 3.5, 0.1, 0, 
0, 0, 1.7, 2.6, 0.9, 0, 0, 0.1, 0.1, 1.5, 0.7, 0, 0, 0, 1.1, 
3.8, 4.9, 2.3, 0.3, 2.7, 2.7, 0.7, 0, 0, 0.1, 0.1, 0.3, 0.2, 
0, 0, 0.5, 2, 1, 0.7, 0.3, 0, 1.8, 0.9, 1, 0.5, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.3, 16.2, 7.7, 0.1, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0.2, 
32, 16.8, 0.4, 0, 0.1, 0.1, 0, 6.7, 8.6, 2.6, 0, 6.2, 9, 9.9, 
3.5, 0, 3, 1.5, 0, 0, 0, 6.4, 3.2, 0, 0.5, 4.4, 2.1, 0, 2.7, 
9.7, 22.8, 10.3, 5.7, 2.6, 8.6, 23.8, 14.5, 2.4, 1.7, 0.8, 0, 
0, 0.3, 0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 4.4, 3.5, 0.7, 0, 0, 
0, 0, 0, 3.2, 1.6, 3.5, 1.8, 0.5, 12.2, 6.8, 1.9, 3.4, 7.7, 3.2, 
0, 6.9, 3.5, 44.7, 22.3, 0, 5.2, 2.6, 4.2, 6.1, 2, 0, 0, 0.5, 
0.2, 4.2, 2.1, 0, 4.9, 5, 2.4, 0.6, 0, 0, 10.5, 9.4, 6.6, 2.7, 
11.7, 20.4, 9.5, 39.2, 24.6, 5.8, 10.6, 17.4, 6.4, 0, 0, 0, 0, 
3.9, 3.7, 0.9, 0, 0, 0, 0, 9.8, 4.9, 1.5, 0.7, 0, 0, 0, 5.2, 
2.9, 0.2, 0.5, 0.2, 0.1, 0.7, 0.3, 3.9, 1.9, 4.2, 2.1, 0.7, 0.3, 
1, 6.7, 4.2, 35.1, 17.3, 7.9, 6.8, 1.4, 20.1, 23.6, 20.1, 6.7, 
0, 0.7, 2.5, 1.1, 2.3, 1.5, 0.2, 0, 0, 1.1, 0.7, 0.1, 4.2, 2.1, 
0.5, 0.2, 3.5, 19.8, 36.2, 58.5, 34.4, 6, 9.3, 16.1, 5.7, 4.4, 
4.2, 47.3, 63.2, 32.9, 10.1, 3.3, 0.7, 11.7, 49.3, 48.8, 27.5, 
32.5, 42.9, 37.9, 14.4, 18, 85.1, 42.3, 1.9, 0, 0, 0, 0, 2.5, 
8.9, 3.8, 0, 0, 0, 0, 15.2, 16.9, 20.8, 12.8, 6.8, 2.5, 1, 11.7, 
10.2, 2.3, 0, 0.3, 1.5, 1.1, 1.4, 2.2, 1.6, 0.4, 7.3, 12, 8.9, 
4.6, 1.2, 0.1, 0, 0, 0, 0.5, 9.4, 4.6, 0, 35.5, 17.8, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 21.3, 15.4, 3.2, 4.9, 9.9, 3.8, 0, 
0, 1.1, 30, 19.8, 6.2, 5.8, 15.9, 30.9, 25, 9.8, 1.7, 0, 0.7, 
2.9, 2.6, 2.7, 5.2, 3.8, 1.6, 4.4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 1.1, 1.9, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5, 118.1, 
100.7, 21.1, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0, 0, 0, 22, 11.5, 0.2, 
0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.5, 1.7, 0.8, 
0, 0, 0, 1.3, 32.3, 16.6, 0.4, 0, 0, 0, 1.3, 0.7, 0, 5.2, 2.6, 
0, 6.7, 10.8, 3.7, 0, 17.4, 8.7, 0, 0, 0.8, 1.4, 0.5, 0, 0, 0, 
10.5, 5.2, 12.9, 7.4, 0.5, 0, 9.6, 4.8, 0, 2, 2.1, 5, 2.2, 0, 
0, 0, 0, 0, 0, 0, 0, 14.3, 7.2, 0, 0, 0, 0, 0.5, 0.2, 1.7, 0.8, 
0, 8.3, 4.1, 0, 0, 4.4, 2.2, 0, 0, 0, 2.5, 1.3, 5.2, 3.6, 0.5, 
15.4, 8.2, 4.1, 2.3, 0.2, 0, 0, 0, 0, 8.9, 4.5, 1, 0.5, 3.3, 
1.7, 2.7, 12.5, 5.6, 23.3, 11.7, 0, 0, 0, 0.1, 0.1, 1.1, 0.6, 
6.6, 3.3, 21.1, 37.3, 13.4, 24.3, 12.2, 2.5, 1.3, 23.7, 16.9, 
3.5, 0.5, 0, 0, 0, 0, 0, 0, 9.3, 23.4, 9.4, 0, 0, 0, 0.5, 0.2, 
0, 0, 8.5, 4.2, 6.1, 19.9, 12.3, 9, 11.3, 4, 10.2, 5.1, 6.2, 
4.2, 0.6, 0.1, 11.5, 5.7, 0, 13.2, 19.5, 8.1, 0.8, 0, 1, 0.5, 
0, 0, 1.1, 0.6, 1.3, 0.7, 0, 6.1, 3.5, 0.2, 3.7, 1.8, 19.5, 30, 
10.1, 14.7, 7.3, 10.7, 5.3, 7.6, 4.6, 5.5, 2.9, 2.4, 7.8, 5.9, 
1.3, 2.7, 2.5, 1.2, 5.7, 32.3, 14.8, 0, 0, 0, 0, 0, 17.3, 8.6, 
1, 5.2, 3.8, 0.7, 11, 8.7, 2.4, 1.1, 17.9, 40.6, 16.2, 33.8, 
38.8, 28.7, 10.9, 12.3, 6.3, 2.5, 3.4, 1.2, 0.7, 5.2, 2.4, 3.9, 
6.7, 9.1, 3.5, 34.9, 19.4, 3.5, 1.7, 0.2, 0, 9.1, 5, 63.4, 31.6, 
21.5, 62.7, 31, 4.2, 3.4, 15.3, 11.7, 23.5, 13.1, 1.4, 4.3, 5.1, 
3.7, 1.1, 0, 0, 0, 0, 0, 2.2, 1.1, 0, 0, 0, 0, 2.3, 1.2, 0, 0.1, 
0.4, 0.2, 2.3, 1.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.5, 0.7, 0, 
0.1, 0.4, 10.3, 5.4, 0.6, 0.2, 0.5, 0.7, 0.2, 2.9, 4.6, 1.6, 
2.2, 1.2, 0.1, 0, 0, 0, 1.7, 0.8, 0, 0, 0, 0, 2, 58.5, 28.8, 
0.3, 0.2, 1.7, 0.8, 0, 1.3, 0.7, 0, 0.1, 2.3, 1.1, 0, 0, 0, 8.9, 
4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10.7, 5.3, 0, 0, 1.7, 0.8, 
0, 4.4, 2.2, 0, 0, 46.7, 23.4, 0, 0, 0, 2.3, 12.5, 31.9, 14.1, 
2.7, 1.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.4, 4, 
0.8, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8, 0.4, 1.1, 1.6, 0.5, 
4.9, 2.4, 0.3, 2.8, 3.5, 7.7, 20.4, 8.5, 15.2, 7.6, 17.4, 8.7, 
0, 7.6, 3.8, 2.3, 4.4, 8.3, 8.1, 2.4, 0, 5.9, 8, 3.2, 18.6, 9.1, 
0, 0, 18.6, 9.3, 0, 0, 0, 17.7, 12.7, 16.5, 31.3, 12, 2.7, 11.1, 
4.9, 16.9, 8.4, 0, 8.8, 6.2, 6.4, 6.1, 1.7, 1, 7.4, 4.5, 0.5, 
0, 3.2, 3.6, 3.2, 1.1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2.5, 21.5, 
11.9, 1, 0.1, 9.1, 5.6, 1.2, 11, 18.9, 6.8, 0, 0, 0, 0, 0, 0, 
0, 0, 7.4, 5, 6.9, 31.4, 14.1, 8.4, 4.5, 4.6, 2.2, 0, 1, 31.4, 
34.6, 9.6, 0, 1.1, 2, 0.7, 9.5, 5.2, 0.6, 10, 5.7, 5.3, 5.4, 
8.4, 3.5, 1, 1.6, 0.6, 2.2, 1.1, 0.5, 10, 10.8, 36.9, 17, 0, 
36.5, 18.3, 1.8, 0.9, 1, 0.5, 4.7, 4, 1.2, 0.2, 0, 0, 0, 5.5, 
30.7, 14, 0, 0, 0, 0.3, 0.2, 54.5, 27.2, 0, 0, 0, 0.5, 28.8, 
44.1, 80.8, 37.8, 2.4, 3, 1.5, 0.1, 23.2, 11.6, 0.1, 0.1, 11, 
25.1, 11.5, 0.8, 0, 3.5, 2.4, 3.5, 1.6, 0, 14, 9.7, 18.6, 10.4, 
0.9, 2, 20.1, 16.3, 9.4, 9.1, 17.7, 22.7, 15.1, 8.2, 11.5, 9.5, 
14.9, 18.9, 74.4, 124.4, 114.6, 241.6, 132.2, 114.4, 91.5, 22.4, 
71.2, 78.2, 45.8, 33.3, 41.7, 16, 0.6, 5.6, 3.5, 31.7, 54.2, 
77.8, 69.5, 37.7, 15.5, 19.6, 18.6, 30.1, 22.2, 18.6, 11.9, 9.1, 
18.5, 23, 15.1, 4.7, 1, 2.4)), .Names = c("Year", "Month", "Day", 
"Amount"), class = "data.frame", row.names = c(NA, -2192L))

i want the counting number of rain as follows:

            Jan        Feb        Mar    Apr    May    Jun    Jul    Aug    Sep    Oct    Nov    Dec
1960        x19611962196319641965


x = number of rain for > 0.000001

Thanks for your help. 
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Thu Oct  1 16:45:47 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 1 Oct 2015 14:45:47 +0000
Subject: [R] Counting number of rain
In-Reply-To: <1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>

You should always reply to the list since other posters may have other suggestions. Assuming your data frame is called rain:

> str(rain)
'data.frame':   2192 obs. of  4 variables:
 $ Year  : int  1960 1960 1960 1960 1960 1960 1960 1960 1960 1960 ...
 $ Month : int  1 1 1 1 1 1 1 1 1 1 ...
 $ Day   : int  1 2 3 4 5 6 7 8 9 10 ...
 $ Amount: num  0.3 0 0 0 0 2.7 7.1 14 12.6 11.1 ...

> tbl <- xtabs(~Year+Month, rain, subset=Amount > 0.000001)
> tbl
      Month
Year    1  2  3  4  5  6  7  8  9 10 11 12
  1960 24 15  2 12 19 22 18 24 22 20 30 29
  1961 26  9 10 18 18 11 18 14 24 28 30 31
  1962 22 14 19  2 18 19 27 26 26 29 15 28
  1963 27 17 15  4  9 23 16 24 19 28 30 22
  1964 15 25  9 13 19 14 23 20 24 30 25 27
  1965 13 21 12 10 21 24 22 21 28 23 28 31

If you want the month names:

> mnt <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
+ "July", "Aug", "Sep", "Oct", "Nov", "Dec")
> dimnames(tbl)$Month <- mnt
> tbl
      Month
Year   Jan Feb Mar Apr May Jun July Aug Sep Oct Nov Dec
  1960  24  15   2  12  19  22   18  24  22  20  30  29
  1961  26   9  10  18  18  11   18  14  24  28  30  31
  1962  22  14  19   2  18  19   27  26  26  29  15  28
  1963  27  17  15   4   9  23   16  24  19  28  30  22
  1964  15  25   9  13  19  14   23  20  24  30  25  27
  1965  13  21  12  10  21  24   22  21  28  23  28  31

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

From: smart hendsome [mailto:putra_autumn86 at yahoo.com] 
Sent: Wednesday, September 30, 2015 9:24 PM
To: David L Carlson
Subject: Re: [R] Counting number of rain

Hi David,

Thanks for your reply, this is my data using dput;

structure(list(Year = c(1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 1960L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 1961L, 
1961L, 1961L, 1961L, 1961L, 1961L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 1962L, 
1962L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 
1963L, 1963L, 1963L, 1963L, 1963L, 1963L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 1964L, 
1964L, 1964L, 1964L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 
1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L, 1965L), Month = c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L), Amount = c(0.3, 0, 0, 0, 0, 2.7, 7.1, 14, 
12.6, 11.1, 5.5, 1.2, 1.2, 1, 5.3, 2.5, 0, 0, 0.5, 14.6, 130.4, 
66.5, 4.1, 3.7, 1.4, 2, 9.1, 8.8, 7.4, 2.5, 0, 0, 0, 10.1, 5.5, 
6.8, 6.3, 1.5, 0, 0, 0, 0, 0, 2.5, 11.7, 6.2, 0.5, 0.7, 0.3, 
2.5, 2.3, 1, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 16.2, 18.6, 15.2, 48.3, 26.7, 2.9, 0.2, 0, 0, 
0, 0, 0, 1.1, 1.4, 0.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.1, 
2.5, 5.2, 2.6, 0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 6.1, 4.7, 2.8, 
1, 0.5, 1.6, 2.1, 0.7, 0, 6.4, 3.5, 0.2, 0, 0, 0, 0, 0, 0, 0, 
21.3, 10.7, 2, 4.2, 1.9, 2.8, 21.1, 9.9, 0.7, 2, 10.4, 5.3, 29.6, 
14.7, 0, 0, 0, 4.4, 2.2, 0, 0, 0.8, 0.4, 0, 3.3, 3.1, 1.9, 0.6, 
0, 4.7, 2.4, 0, 0, 0, 0, 5.9, 25.7, 11.4, 0, 0, 0, 0, 2.7, 1.3, 
0, 0, 0, 0, 0, 0, 5.9, 28.1, 12.6, 68.2, 34.4, 0.6, 8.2, 4.3, 
0.2, 17.9, 30.6, 21.1, 5.1, 0, 0, 0.1, 3.6, 8.7, 8.9, 6.7, 13.7, 
10, 2.1, 11.8, 5.9, 0, 0, 0, 0, 0, 19.5, 31.1, 38.3, 20, 3.1, 
5.1, 6.4, 12.4, 5.2, 2.5, 9, 4, 0.1, 0.1, 0.5, 17, 8.8, 0.6, 
0.2, 0, 0, 0, 40.3, 20.1, 5.1, 14.3, 20.2, 13.2, 4.8, 1.4, 0.2, 
0, 1, 0.5, 0, 0, 0, 3.7, 1.8, 15.4, 7.7, 0, 3.9, 8, 3, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 45.5, 22.8, 9.9, 5, 4.4, 2.7, 0.2, 
0.8, 3.4, 10.3, 6.2, 7.5, 7.3, 20.3, 22, 28.9, 31.7, 39.2, 14.5, 
10.5, 34.8, 43.7, 43.5, 144.9, 143, 68, 18.2, 1.8, 0.5, 16.1, 
15.5, 3.8, 51.6, 25.8, 0.7, 1.5, 13.8, 27.2, 10.3, 1.5, 1.7, 
5.9, 12, 4.6, 1.7, 6.4, 11.7, 16.5, 38.3, 35.8, 16.7, 3.5, 1.8, 
35.9, 58.1, 40.9, 15, 14.5, 6.1, 0, 0, 3.3, 13.5, 6.9, 1.2, 2.7, 
1.2, 15.2, 16, 12.5, 14.4, 9.3, 2.1, 2.5, 25.6, 96.8, 99.5, 39.9, 
23.9, 9.1, 1.7, 3.8, 12, 6.4, 15.4, 8.8, 1.5, 10.7, 26.5, 20.9, 
7.7, 1.7, 1.2, 0.8, 0.6, 1, 0.4, 0, 6.1, 3.5, 0.2, 0, 0, 0, 0.8, 
3.7, 12.8, 8.9, 5.3, 1.8, 0, 0, 0, 0, 0, 0, 0, 4.4, 2.2, 0, 0, 
5.1, 5.9, 10.6, 9.3, 7.6, 4.1, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 22.1, 11.1, 0, 0, 23.1, 25.4, 12.8, 
2.9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 11.8, 13.9, 6, 
19.9, 35.9, 13.2, 0, 0, 0, 0, 0, 0, 0, 0, 3.2, 1.6, 0.8, 16.6, 
8.1, 11.3, 5.8, 10.9, 7.1, 0.8, 0, 0, 0, 0, 11, 37.3, 18.9, 14.4, 
14.5, 4, 0, 0, 1, 0.5, 0.3, 3.7, 1.8, 0, 0, 0, 9.8, 4.9, 3, 1.5, 
0, 0, 0, 0, 0, 0, 7.6, 3.8, 0, 0, 2.3, 1.2, 2.5, 1.3, 0.8, 0.4, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27.1, 44.3, 17.4, 1.7, 0.3, 
0, 5.4, 2.7, 0, 2.5, 1.3, 0, 0, 4.4, 2.2, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0.5, 0.2, 0, 25, 12.5, 0, 7.4, 7.6, 1.9, 2.5, 1.3, 0, 
0, 35.9, 37.1, 20.6, 7.5, 1, 0, 0.1, 0.2, 3.1, 1.5, 0, 0, 0, 
0, 0, 12.7, 6.3, 0, 0, 0, 0.1, 4.8, 4.9, 2.1, 23.4, 11.5, 6.9, 
31.2, 36.9, 11.5, 32, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.1, 
0.1, 0, 0, 6.7, 17, 25.8, 9.5, 6.4, 9.6, 10.3, 5.5, 36.5, 17.9, 
0.1, 0.3, 0.2, 14.2, 7.1, 0, 0, 21.5, 30.2, 10.1, 0.2, 0, 9.6, 
4.8, 2, 13.3, 13.2, 3.5, 13.7, 12.9, 33.5, 15.2, 0, 5.7, 5.2, 
1.2, 10.8, 51.9, 24.3, 1.8, 0.7, 4.9, 21.9, 17.5, 5, 4.4, 1.9, 
5.9, 2.9, 0, 8.1, 4, 0, 0.3, 15.7, 71.2, 116, 62.9, 48.5, 28.3, 
19.8, 35.7, 20.1, 9.8, 31.3, 32.6, 30.6, 28.4, 15.6, 4.8, 7.8, 
44.3, 29.7, 18.2, 6.8, 3.9, 6.5, 31.9, 45.1, 37.3, 14.9, 11.5, 
24.9, 25.3, 143.9, 101.9, 28.2, 21.7, 32.2, 13.8, 9.6, 28.9, 
12.6, 9.6, 30.5, 12.9, 1.5, 1.9, 0.9, 25.4, 46.4, 28.2, 22.2, 
10.8, 7.3, 3, 34.2, 84.8, 71, 28.7, 16.9, 62.1, 104.4, 89.8, 
42.9, 9.3, 3.1, 3.5, 2.1, 0.8, 0.2, 0, 0, 0, 5.1, 6.1, 5.8, 4, 
1, 4.4, 4.2, 6.1, 7.1, 2.3, 1.5, 2.5, 0.9, 0, 0, 0, 0, 0, 19.3, 
10.6, 0.6, 0.1, 0, 1.5, 3.3, 1.3, 3, 1.5, 0, 0.1, 0.1, 0, 0, 
0, 0, 0, 0, 0, 0, 0.3, 0.3, 0.5, 0.2, 0, 0, 0, 0.3, 1.6, 0.7, 
0, 0, 6.6, 13.6, 6.6, 4.1, 12.7, 31.4, 13.1, 0.1, 0, 0, 0, 0.5, 
0.4, 0.1, 0, 5.5, 2.8, 0, 0, 0, 0, 0, 0, 1.1, 25.4, 15.3, 16.6, 
7.6, 0, 0, 0.5, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.7, 0.3, 0, 5.4, 2.7, 
0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 0, 0, 0.5, 0.2, 32.7, 16.3, 0, 
12.9, 6.4, 0, 7.7, 4.2, 6, 2.9, 5.1, 2.7, 0.1, 0, 3.5, 1.8, 0, 
0, 8.9, 4.5, 0, 0, 0, 3.9, 1.9, 0, 0, 49.4, 25.7, 0.5, 0, 0, 
3.9, 1.9, 0.5, 0.2, 0, 31.6, 20.5, 14.5, 6.1, 0.7, 0.3, 0, 29.9, 
39, 12, 7.1, 3.5, 18.9, 9.9, 9.5, 4.6, 0, 1.3, 8.9, 4.1, 4.5, 
7.3, 2.5, 0, 0, 0, 18.9, 16.9, 19.8, 8, 3.3, 1.7, 8.4, 13.3, 
19.2, 7.3, 2, 6.2, 2.6, 0, 0, 0, 6.6, 3.3, 0.5, 0.2, 0, 0.8, 
34.2, 28.9, 28.3, 23.3, 6.1, 0, 1, 0.5, 12.7, 9.2, 6.2, 20, 15.4, 
18.8, 28.7, 25.7, 14.2, 3.3, 30.1, 17.7, 23.3, 32.3, 18.7, 5.8, 
0.9, 13.9, 11.7, 2.4, 64.7, 54.3, 11.8, 1.1, 8.7, 4.2, 2.3, 31.1, 
16.6, 1.2, 5, 2.4, 0, 0, 0, 0, 18.9, 9.5, 10.1, 26.5, 10.9, 7, 
3.6, 26.8, 13.4, 7.4, 5.4, 0.8, 2.3, 2.5, 0.7, 0.3, 0.8, 0.7, 
0.3, 0.1, 0, 5.2, 4.3, 4, 17.3, 14.6, 24, 27, 22.6, 13, 29.8, 
30.8, 8.7, 25.7, 29.9, 36.3, 14.5, 0.3, 0, 0, 0, 0, 37.7, 29.3, 
13, 3.9, 1.1, 37.1, 18.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
6.9, 3.5, 26.1, 101, 51.1, 5.3, 8, 25, 109.7, 104.5, 90.3, 50.7, 
10.4, 0.5, 0.4, 1.5, 5.1, 4.5, 1.8, 0.3, 0, 0.8, 0.9, 55.8, 44.3, 
15.3, 10.3, 5.2, 8.3, 4.5, 4.4, 2, 0.3, 0.2, 0, 0, 25, 13.3, 
1.7, 33.3, 74.1, 29.3, 6.1, 15.6, 13.7, 4.2, 0.2, 0, 0, 0.1, 
0.1, 1, 0.8, 8.6, 11.8, 3.9, 0.2, 0.1, 10.3, 5.1, 0, 0.1, 0.1, 
0, 13.3, 9.9, 7, 3.7, 2, 0.7, 0, 0, 0, 0.3, 6.9, 3.5, 0.1, 0, 
0, 0, 1.7, 2.6, 0.9, 0, 0, 0.1, 0.1, 1.5, 0.7, 0, 0, 0, 1.1, 
3.8, 4.9, 2.3, 0.3, 2.7, 2.7, 0.7, 0, 0, 0.1, 0.1, 0.3, 0.2, 
0, 0, 0.5, 2, 1, 0.7, 0.3, 0, 1.8, 0.9, 1, 0.5, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.3, 16.2, 7.7, 0.1, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.3, 0.2, 
32, 16.8, 0.4, 0, 0.1, 0.1, 0, 6.7, 8.6, 2.6, 0, 6.2, 9, 9.9, 
3.5, 0, 3, 1.5, 0, 0, 0, 6.4, 3.2, 0, 0.5, 4.4, 2.1, 0, 2.7, 
9.7, 22.8, 10.3, 5.7, 2.6, 8.6, 23.8, 14.5, 2.4, 1.7, 0.8, 0, 
0, 0.3, 0.3, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 4.4, 3.5, 0.7, 0, 0, 
0, 0, 0, 3.2, 1.6, 3.5, 1.8, 0.5, 12.2, 6.8, 1.9, 3.4, 7.7, 3.2, 
0, 6.9, 3.5, 44.7, 22.3, 0, 5.2, 2.6, 4.2, 6.1, 2, 0, 0, 0.5, 
0.2, 4.2, 2.1, 0, 4.9, 5, 2.4, 0.6, 0, 0, 10.5, 9.4, 6.6, 2.7, 
11.7, 20.4, 9.5, 39.2, 24.6, 5.8, 10.6, 17.4, 6.4, 0, 0, 0, 0, 
3.9, 3.7, 0.9, 0, 0, 0, 0, 9.8, 4.9, 1.5, 0.7, 0, 0, 0, 5.2, 
2.9, 0.2, 0.5, 0.2, 0.1, 0.7, 0.3, 3.9, 1.9, 4.2, 2.1, 0.7, 0.3, 
1, 6.7, 4.2, 35.1, 17.3, 7.9, 6.8, 1.4, 20.1, 23.6, 20.1, 6.7, 
0, 0.7, 2.5, 1.1, 2.3, 1.5, 0.2, 0, 0, 1.1, 0.7, 0.1, 4.2, 2.1, 
0.5, 0.2, 3.5, 19.8, 36.2, 58.5, 34.4, 6, 9.3, 16.1, 5.7, 4.4, 
4.2, 47.3, 63.2, 32.9, 10.1, 3.3, 0.7, 11.7, 49.3, 48.8, 27.5, 
32.5, 42.9, 37.9, 14.4, 18, 85.1, 42.3, 1.9, 0, 0, 0, 0, 2.5, 
8.9, 3.8, 0, 0, 0, 0, 15.2, 16.9, 20.8, 12.8, 6.8, 2.5, 1, 11.7, 
10.2, 2.3, 0, 0.3, 1.5, 1.1, 1.4, 2.2, 1.6, 0.4, 7.3, 12, 8.9, 
4.6, 1.2, 0.1, 0, 0, 0, 0.5, 9.4, 4.6, 0, 35.5, 17.8, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 21.3, 15.4, 3.2, 4.9, 9.9, 3.8, 0, 
0, 1.1, 30, 19.8, 6.2, 5.8, 15.9, 30.9, 25, 9.8, 1.7, 0, 0.7, 
2.9, 2.6, 2.7, 5.2, 3.8, 1.6, 4.4, 2, 0, 0, 0, 0, 0, 0, 0, 0, 
0, 0, 1.1, 1.9, 0.7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5, 118.1, 
100.7, 21.1, 0, 0, 0.1, 0.1, 0, 0, 0, 0, 0, 0, 0, 22, 11.5, 0.2, 
0.3, 0.2, 1.7, 0.8, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0.5, 1.7, 0.8, 
0, 0, 0, 1.3, 32.3, 16.6, 0.4, 0, 0, 0, 1.3, 0.7, 0, 5.2, 2.6, 
0, 6.7, 10.8, 3.7, 0, 17.4, 8.7, 0, 0, 0.8, 1.4, 0.5, 0, 0, 0, 
10.5, 5.2, 12.9, 7.4, 0.5, 0, 9.6, 4.8, 0, 2, 2.1, 5, 2.2, 0, 
0, 0, 0, 0, 0, 0, 0, 14.3, 7.2, 0, 0, 0, 0, 0.5, 0.2, 1.7, 0.8, 
0, 8.3, 4.1, 0, 0, 4.4, 2.2, 0, 0, 0, 2.5, 1.3, 5.2, 3.6, 0.5, 
15.4, 8.2, 4.1, 2.3, 0.2, 0, 0, 0, 0, 8.9, 4.5, 1, 0.5, 3.3, 
1.7, 2.7, 12.5, 5.6, 23.3, 11.7, 0, 0, 0, 0.1, 0.1, 1.1, 0.6, 
6.6, 3.3, 21.1, 37.3, 13.4, 24.3, 12.2, 2.5, 1.3, 23.7, 16.9, 
3.5, 0.5, 0, 0, 0, 0, 0, 0, 9.3, 23.4, 9.4, 0, 0, 0, 0.5, 0.2, 
0, 0, 8.5, 4.2, 6.1, 19.9, 12.3, 9, 11.3, 4, 10.2, 5.1, 6.2, 
4.2, 0.6, 0.1, 11.5, 5.7, 0, 13.2, 19.5, 8.1, 0.8, 0, 1, 0.5, 
0, 0, 1.1, 0.6, 1.3, 0.7, 0, 6.1, 3.5, 0.2, 3.7, 1.8, 19.5, 30, 
10.1, 14.7, 7.3, 10.7, 5.3, 7.6, 4.6, 5.5, 2.9, 2.4, 7.8, 5.9, 
1.3, 2.7, 2.5, 1.2, 5.7, 32.3, 14.8, 0, 0, 0, 0, 0, 17.3, 8.6, 
1, 5.2, 3.8, 0.7, 11, 8.7, 2.4, 1.1, 17.9, 40.6, 16.2, 33.8, 
38.8, 28.7, 10.9, 12.3, 6.3, 2.5, 3.4, 1.2, 0.7, 5.2, 2.4, 3.9, 
6.7, 9.1, 3.5, 34.9, 19.4, 3.5, 1.7, 0.2, 0, 9.1, 5, 63.4, 31.6, 
21.5, 62.7, 31, 4.2, 3.4, 15.3, 11.7, 23.5, 13.1, 1.4, 4.3, 5.1, 
3.7, 1.1, 0, 0, 0, 0, 0, 2.2, 1.1, 0, 0, 0, 0, 2.3, 1.2, 0, 0.1, 
0.4, 0.2, 2.3, 1.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.5, 0.7, 0, 
0.1, 0.4, 10.3, 5.4, 0.6, 0.2, 0.5, 0.7, 0.2, 2.9, 4.6, 1.6, 
2.2, 1.2, 0.1, 0, 0, 0, 1.7, 0.8, 0, 0, 0, 0, 2, 58.5, 28.8, 
0.3, 0.2, 1.7, 0.8, 0, 1.3, 0.7, 0, 0.1, 2.3, 1.1, 0, 0, 0, 8.9, 
4.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10.7, 5.3, 0, 0, 1.7, 0.8, 
0, 4.4, 2.2, 0, 0, 46.7, 23.4, 0, 0, 0, 2.3, 12.5, 31.9, 14.1, 
2.7, 1.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.4, 4, 
0.8, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.8, 0.4, 1.1, 1.6, 0.5, 
4.9, 2.4, 0.3, 2.8, 3.5, 7.7, 20.4, 8.5, 15.2, 7.6, 17.4, 8.7, 
0, 7.6, 3.8, 2.3, 4.4, 8.3, 8.1, 2.4, 0, 5.9, 8, 3.2, 18.6, 9.1, 
0, 0, 18.6, 9.3, 0, 0, 0, 17.7, 12.7, 16.5, 31.3, 12, 2.7, 11.1, 
4.9, 16.9, 8.4, 0, 8.8, 6.2, 6.4, 6.1, 1.7, 1, 7.4, 4.5, 0.5, 
0, 3.2, 3.6, 3.2, 1.1, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2.5, 21.5, 
11.9, 1, 0.1, 9.1, 5.6, 1.2, 11, 18.9, 6.8, 0, 0, 0, 0, 0, 0, 
0, 0, 7.4, 5, 6.9, 31.4, 14.1, 8.4, 4.5, 4.6, 2.2, 0, 1, 31.4, 
34.6, 9.6, 0, 1.1, 2, 0.7, 9.5, 5.2, 0.6, 10, 5.7, 5.3, 5.4, 
8.4, 3.5, 1, 1.6, 0.6, 2.2, 1.1, 0.5, 10, 10.8, 36.9, 17, 0, 
36.5, 18.3, 1.8, 0.9, 1, 0.5, 4.7, 4, 1.2, 0.2, 0, 0, 0, 5.5, 
30.7, 14, 0, 0, 0, 0.3, 0.2, 54.5, 27.2, 0, 0, 0, 0.5, 28.8, 
44.1, 80.8, 37.8, 2.4, 3, 1.5, 0.1, 23.2, 11.6, 0.1, 0.1, 11, 
25.1, 11.5, 0.8, 0, 3.5, 2.4, 3.5, 1.6, 0, 14, 9.7, 18.6, 10.4, 
0.9, 2, 20.1, 16.3, 9.4, 9.1, 17.7, 22.7, 15.1, 8.2, 11.5, 9.5, 
14.9, 18.9, 74.4, 124.4, 114.6, 241.6, 132.2, 114.4, 91.5, 22.4, 
71.2, 78.2, 45.8, 33.3, 41.7, 16, 0.6, 5.6, 3.5, 31.7, 54.2, 
77.8, 69.5, 37.7, 15.5, 19.6, 18.6, 30.1, 22.2, 18.6, 11.9, 9.1, 
18.5, 23, 15.1, 4.7, 1, 2.4)), .Names = c("Year", "Month", "Day", 
"Amount"), class = "data.frame", row.names = c(NA, -2192L))

i want the counting number of rain as follows:


??????????? Jan??????? Feb??????? Mar??? Apr??? May??? Jun??? Jul??? Aug??? Sep??? Oct??? Nov??? Dec
1960 ?????? x
1961
1962
1963
1964
1965


x = number of rain for > 0.000001

Thanks for your help. 


On Tuesday, September 8, 2015 10:27 PM, David L Carlson <dcarlson at tamu.edu> wrote:

Sorry we don't do homework and you didn't follow the list guidelines

1. NO HTML - look at the mess below to see why.
2. Use dput() to include your data in the list.

Your question is pretty simple, once you have spent a little time reading about R:

https://cran.r-project.org/manuals.html - Official manuals 

https://cran.r-project.org/other-docs.html - Contributed tutorials

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of smart hendsome via R-help
Sent: Tuesday, September 8, 2015 1:59 AM
To: r-help at r-project.org
Subject: [R] Counting number of rain

Hello R-users,
I want to ask how to count the number of daily rain data.? My data as below:
Year Month Day Amount 1901 1 1 0 1901 1 2 3 1901 1 3 0 1901 1 4 0.5 1901 1 5 0 1901 1 6 0? 1901 1 7 0.3 1901 1 8 0 1901 1 9 0 1901 1 10 0 1901 1 11 0.5 1901 1 12 1.8 1901 1 13 0 1901 1 14 0 1901 1 15 2.5 1901 1 16 0 1901 1 17 0 1901 1 18 0 1901 1 19 0 1901 1 20 0 1901 1 21 0 1901 1 22 0 1901 1 23 0 1901 1 24 0 1901 1 25 0 1901 1 26 16.5 1901 1 27 0.3 1901 1 28 0 1901 1 29 0 1901 1 30 0 1901 1 31 0 1901 2 1 0 1901 2 2 0 1901 2 3 0 1901 2 4 0 1901 2 5 0 1901 2 6 0 1901 2 7 0 1901 2 8 0.3 1901 2 9 0 1901 2 10 0 1901 2 11 0 1901 2 12 1 1901 2 13 0.3 1901 2 14 0 1901 2 15 0 1901 2 16 0 1901 2 17 0 1901 2 18 0 1901 2 19 0 1901 2 20 0 1901 2 21 0 1901 2 22 0 1901 2 23 0.3 1901 2 24 0 1901 2 25 0 1901 2 26 0.3 1901 2 27 0 1901 2 28 0 1901 3 1 0 1901 3 2 0.8 1901 3 3 2.3 1901 3 4 0 1901 3 5 0 1901 3 6 0 1901 3 7 0 1901 3 8 0 1901 3 9 0 1901 3 10 2 1901 3 11 0 1901 3 12 0 1901 3 13 0 1901 3 14 0 1901 3 15 0 1901 3 16 0 1901 3 17 0 1901 3 18 0 1901 3 19 0 1901 3 20 0 1901 3 21 0 1901 3 22 1.5 1901 3 23 1.3 1901 3 24 0 1901 3 25 0 1901 3 26 0 1901 3 27 0 1901 3 28 0.3 1901 3 29 0.3? 1901 3 30 4.6 1901 3 31 0 1901 4 1 0 1901 4 2 4.6 1901 4 3 30.7 1901 4 4 0 1901 4 5 0 1901 4 6 0 1901 4 7 0 1901 4 8 0 1901 4 9 0 1901 4 10 0 1901 4 11 0 1901 4 12 0 1901 4 13 0 1901 4 14 0 1901 4 15 0.3 1901 4 16 1.3 1901 4 17 0 1901 4 18 0 1901 4 19 0.3 1901 4 20 1 1901 4 21 9.4 1901 4 22 0.5 1901 4 23 0.3 1901 4 24 0 1901 4 25 0 1901 4 26 0 1901 4 27 0 1901 4 28 0 1901 4 29 0 1901 4 30 0 1901 5 1 0 1901 5 2 0 1901 5 3 0 1901 5 4 0 1901 5 5 0 1901? 5 6 0 1901 5 7 0 1901 5 8 0.5 1901 5 9 2.3 1901 5 10 0.3 1901 5 11 0 1901 5 12 0 1901 5 13 0 1901 5 14 0 1901 5 15 0 1901 5 16 0 1901 5 17 0 1901 5 18 0 1901 5 19 0 1901 5 20 0 1901 5 21 0.5 1901 5 22 0 1901 5 23 0 1901 5 24 0 1901 5 25 0 1901 5 26 4.8 1901 5 27 10.9 1901 5 28 3.6 1901 5 29 0 1901 5 30 0 1901 5 31 5.1 1901 6 1 0.5 1901 6 2 0 1901 6 3 2 1901 6 4 0? 1901 6 5 10.2 1901 6 6 33.3 1901 6 7 0.3 1901 6 8 0 1901 6 9 0 1901 6 10 0.5 1901 6 11 0.5 1901 6 12 0.3 1901 6 13 2.8 1901 6 14 5.6 1901 6 15 0.3 1901 6 16 6.6 1901 6 17 14.2 1901 6 18 4.8? 1901 6 19 8.4 1901 6 20 1.8 1901 6 21 1.8 1901 6 22 0.3 1901 6 23 8.6 1901 6 24 0 1901 6 25 0? 1901 6 26 0 1901 6 27 0 1901 6 28 0 1901 6 29 0 1901 6 30 0 1901 7 1 0 1901 7 2 0 1901 7 3 0 1901 7 4 0 1901 7 5 1 1901 7 6 0.5 1901 7 7 0.3 1901 7 8 0.3 1901 7 9 6.1 1901 7 10 0.3? 1901 7 11 1.5 1901 7 12 0 1901 7 13 1.5 1901 7 14 0.3 1901 7 15 3.3 1901 7 16 2.3 1901 7 17 0.5? 1901 7 18 0 1901 7 19 0 1901 7 20 0 1901 7 21 1.8 1901 7 22 0 1901 7 23 1 1901 7 24 0.3 1901? 7 25 0.3 1901 7 26 1.3 1901 7 27 17 1901 7 28 6.6 1901 7 29 6.1 1901 7 30 0.5 1901 7 31 0.3 1901 8 1 0 1901 8 2 0 1901 8 3 0 1901 8 4 0 1901 8 5 0 1901 8 6 3.3 1901 8 7 4.1 1901 8 8 0.3? 1901 8 9 0 1901 8 10 0 1901 8 11 0 1901 8 12 0 1901 8 13 0 1901 8 14 0 1901 8 15 0 1901 8 16 0 1901 8 17 0.5 1901 8 18 0 1901 8 19 0 1901 8 20 0 1901 8 21 0 1901 8 22 0 1901 8 23 0.3 1901 8 24 1 1901 8 25 0 1901 8 26 0 1901 8 27 10.2 1901 8 28 1.5 1901 8 29 0.5 1901 8 30 1.3? 1901 8 31 0 1901 9 1 0 1901 9 2 3 1901 9 3 1 1901 9 4 0.5 1901 9 5 0.3 1901 9 6 0 1901 9 7 0 1901 9 8 2.3 1901 9 9 0.3 1901 9 10 0 1901 9 11 0 1901 9 12 0 1901 9 13 0 1901 9 14 0? 1901 9 15 0 1901 9 16 0 1901 9 17 0 1901 9 18 1.8 1901 9 19 8.1 1901 9 20 0.3 1901 9 21 5.8 1901 9 22 4.1 1901 9 23 0.3 1901 9 24 1.8 1901 9 25 0 1901 9 26 0 1901 9 27 0 1901 9 28 0 1901? 9 29 1.8 1901 9 30 0.8 1901 10 1 0 1901 10 2 0 1901 10 3 0 1901 10 4 0 1901 10 5 0.3 1901 10 6 0 1901 10 7 0 1901 10 8 0 1901 10 9 0 1901 10 10 0 1901 10 11 0.3 1901 10 12 3.8 1901 10 13 0.4 1901 10 14 9 1901 10 15 2 1901 10 16 1 1901 10 17 0 1901 10 18 0 1901 10 19 0 1901 10 20 0.3 1901 10 21 0 1901 10 22 0 1901 10 23 0 1901 10 24 0 1901 10 25 0 1901 10 26 0 1901 10 27 14.5? 1901 10 28 6.4 1901 10 29 0.8 1901 10 30 0 1901 10 31 0 1901 11 1 0 1901 11 2 0 1901 11 3 0? 1901 11 4 0 1901 11 5 0 1901 11 6 0 1901 11 7 0 1901 11 8 0 1901 11 9 0 1901 11 10 0 1901 11 11 0 1901 11 12 5.1 1901 11 13 0.3 1901 11 14 5.8 1901 11 15 0 1901 11 16 0 1901 11 17 1 1901 11 18 0.5 1901 11 19 0 1901 11 20 0 1901 11 21 0 1901 11 22 0 1901 11 23 0 1901 11 24 0 1901 11 25 0.3 1901 11 26 0 1901 11 27 0 1901 11 28 0 1901 11 29 0 1901 11 30 3.3 1901 12 1 0 1901 12 2 0 1901 12 3 0 1901 12 4 0 1901 12 5 0 1901 12 6 0 1901 12 7 0 1901 12 8 0 1901 12 9 0 1901 12 10 0 1901 12 11 0 1901 12 12 0 1901 12 13 0 1901 12 14 0 1901 12 15 0 1901 12 16 0 1901 12 17 0 1901 12 18 0 1901 12 19 0 1901 12 20 0 1901 12 21 6.1 1901 12 22 5.6 1901 12 23 0 1901 12 24 0 1901 12 25 0 1901 12 26 0 1901 12 27 0 1901 12 28 0 1901 12 29 0 1901 12 30 0 1901 12 31 9.9 1902 1 1 0 1902 1 2 0 1902 1 3 0 1902 1 4 4.1 1902 1 5 0 1902 1 6 0 1902 1 7 0 1902 1 8 0 1902 1 9 2.5 1902 1 10 0 1902 1 11 0 1902 1 12 0 1902 1 13 0.3 1902 1 14 0 1902 1 15 0 1902 1 16 0 1902 1 17 0 1902 1 18 0 1902 1 19 0 1902 1 20 0.3 1902 1 21 0.8 1902 1 22 1.8? 1902 1 23 0 1902 1 24 0 1902 1 25 0 1902 1 26 2.8 1902 1 27 0 1902 1 28 0.3 1902 1 29 0 1902 1 30 0 1902 1 31 0 1902 2 1 2.8 1902 2 2 0 1902 2 3 0.3 1902 2 4 0 1902 2 5 0 1902 2 6 0 1902 2 7 0 1902 2 8 0 1902 2 9 0 1902 2 10 0 1902 2 11 0 1902 2 12 5.6 1902 2 13 0 1902? 2 14 0 1902 2 15 0 1902 2 16 0 1902 2 17 0 1902 2 18 0 1902 2 19 0 1902 2 20 0.8 1902 2 21 0 1902 2 22 0 1902 2 23 0 1902 2 24 2.8 1902 2 25 2.8 1902 2 26 0 1902 2 27 0 1902 2 28 0 1902 3 1 0 1902 3 2 0 1902 3 3 0 1902 3 4 0 1902 3 5 0 1902 3 6 0 1902 3 7 0 1902 3 8 0? 1902 3 9 0 1902 3 10 0 1902 3 11 0 1902 3 12 0 1902 3 13 0 1902 3 14 0 1902 3 15 0 1902 3 16 0 1902 3 17 0 1902 3 18 0 1902 3 19 0 1902 3 20 0 1902 3 21 0 1902 3 22 0 1902 3 23 0? 1902 3 24 0 1902 3 25 4.8 1902 3 26 11.9 1902 3 27 3.8 1902 3 28 1.8 1902 3 29 0 1902 3 30 0 1902 3 31 0 1902 4 1 0 1902 4 2 0 1902 4 3 0 1902 4 4 0 1902 4 5 0 1902 4 6 0 1902 4 7 0? 1902 4 8 0 1902 4 9 2.5 1902 4 10 0 1902 4 11 0 1902 4 12 0 1902 4 13 0 1902 4 14 0 1902 4 15 0 1902 4 16 0 1902 4 17 0 1902 4 18 0 1902 4 19 0 1902 4 20 0 1902 4 21 0 1902 4 22 0? 1902 4 23 0 1902 4 24 0 1902 4 25 0 1902 4 26 1.3 1902 4 27 8.1 1902 4 28 0 1902 4 29 0 1902 4 30 0 1902 5 1 0 1902 5 2 0 1902 5 3 0 1902 5 4 0 1902 5 5 0 1902 5 6 3 1902 5 7 3.8? 1902 5 8 4.3 1902 5 9 2.8 1902 5 10 3 1902 5 11 0 1902 5 12 0.5 1902 5 13 2 1902 5 14 0 1902 5 15 0.3 1902 5 16 0.8 1902 5 17 0.3 1902 5 18 0 1902 5 19 0 1902 5 20 0 1902 5 21 0 1902 5? 22 0 1902 5 23 0 1902 5 24 0 1902 5 25 0 1902 5 26 0 1902 5 27 0 1902 5 28 0 1902 5 29 0.3? 1902 5 30 1.8 1902 5 31 0 1902 6 1 5.3 1902 6 2 0 1902 6 3 0 1902 6 4 0.3 1902 6 5 0 1902 6 6 0 1902 6 7 4.6 1902 6 8 5.1 1902 6 9 12.4 1902 6 10 5.3 1902 6 11 0.3 1902 6 12 0 1902 6 13 0 1902 6 14 3 1902 6 15 4.1 1902 6 16 7.4 1902 6 17 5.1 1902 6 18 8.1 1902 6 19 18.3 1902 6 20 3.3 1902 6 21 16.5 1902 6 22 0.5 1902 6 23 0 1902 6 24 0 1902 6 25 0 1902 6 26 0 1902 6 27 0 1902 6 28 0 1902 6 29 0 1902 6 30 0 1902 7 1 0 1902 7 2 0 1902 7 3 0 1902 7 4 0 1902 7? 5 0 1902 7 6 1.8 1902 7 7 0 1902 7 8 0 1902 7 9 0 1902 7 10 1 1902 7 11 0.3 1902 7 12 0? 1902 7 13 0.8 1902 7 14 0 1902 7 15 0 1902 7 16 0 1902 7 17 0.8 1902 7 18 0 1902 7 19 1.3 1902 7 20 0.5 1902 7 21 0 1902 7 22 1.5 1902 7 23 1.3 1902 7 24 2.5 1902 7 25 9.4 1902 7 26 0.3 1902 7 27 0 1902 7 28 0 1902 7 29 0 1902 7 30 5.1 1902 7 31 2 1902 8 1 0 1902 8 2 3 1902 8 3 1.8 1902 8 4 0 1902 8 5 0.5 1902 8 6 3.3 1902 8 7 3.8 1902 8 8 0 1902 8 9 0 1902 8 10 0 1902 8 11 0.3 1902 8 12 0 1902 8 13 0 1902 8 14 0 1902 8 15 0 1902 8 16 0 1902 8 17 0 1902 8 18 0 1902 8 19 0 1902 8 20 0 1902 8 21 0 1902 8 22 0 1902 8 23 1.5 1902 8 24 2.8 1902 8 25 0? 1902 8 26 0 1902 8 27 5.8 1902 8 28 0 1902 8 29 1.5 1902 8 30 0 1902 8 31 0 1902 9 1 0 1902 9 2 2.5 1902 9 3 0.8 1902 9 4 0.8 1902 9 5 0 1902 9 6 0 1902 9 7 0 1902 9 8 0 1902 9 9 0? 1902 9 10 0 1902 9 11 9.4 1902 9 12 0.5 1902 9 13 6.6 1902 9 14 0.5 1902 9 15 2.8 1902 9 16 4.1? 1902 9 17 6.9 1902 9 18 0.5 1902 9 19 0 1902 9 20 0 1902 9 21 0 1902 9 22 0 1902 9 23 0 1902 9 24 0 1902 9 25 0 1902 9 26 1.8 1902 9 27 0.3 1902 9 28 0.3 1902 9 29 0 1902 9 30 0 1902 10? 1 0.8 1902 10 2 1.5 1902 10 3 2 1902 10 4 0 1902 10 5 0 1902 10 6 0.3 1902 10 7 0.5 1902 10 8? 1 1902 10 9 0 1902 10 10 1 1902 10 11 10.9 1902 10 12 0.3 1902 10 13 0 1902 10 14 0 1902 10 15 0 1902 10 16 0 1902 10 17 0 1902 10 18 2.3 1902 10 19 0.3 1902 10 20 0 1902 10 21 0 1902 10 22 1.8 1902 10 23 0.5 1902 10 24 1.5 1902 10 25 0 1902 10 26 0 1902 10 27 1 1902 10 28 5.3 1902 10 29 0 1902 10 30 0 1902 10 31 0 1902 11 1 0 1902 11 2 0 1902 11 3 0 1902 11 4 0 1902 11 5 0 1902 11 6 0.8 1902 11 7 0.3 1902 11 8 0.5 1902 11 9 1 1902 11 10 0 1902 11 11 0 1902 11 12 0 1902 11 13 7.1 1902 11 14 0.3 1902 11 15 0 1902 11 16 0 1902 11 17 0 1902 11 18 0 1902 11 19 0.3 1902 11 20 1 1902 11 21 0 1902 11 22 0 1902 11 23 0 1902 11 24 0 1902 11 25 0 1902 11 26 0 1902 11 27 0 1902 11 28 0 1902 11 29 0 1902 11 30 0 1902 12 1 0 1902 12 2 0 1902 12 3 0 1902 12 4? 0 1902 12 5 1.8 1902 12 6 6.9 1902 12 7 0 1902 12 8 0 1902 12 9 0 1902 12 10 0.5 1902 12 11 4.8 1902 12 12 0 1902 12 13 0 1902 12 14 0 1902 12 15 0 1902 12 16 0.8 1902 12 17 15.5 1902 12 18 11.7 1902 12 19 9.4 1902 12 20 0.3 1902 12 21 0 1902 12 22 0 1902 12 23 0 1902 12 24 0.3 1902 12 25 0.3 1902 12 26 0 1902 12 27 0 1902 12 28 0 1902 12 29 0 1902 12 30 0 1902 12 31 0 1903 1 1 0 1903 1 2 0 1903 1 3 1.3 1903 1 4 2 1903 1 5 0 1903 1 6 3.6 1903 1 7 0 1903 1 8 0 1903 1 9 0 1903 1 10 0 1903 1 11 0 1903 1 12 0 1903 1 13 0 1903 1 14 0 1903 1 15 0 1903 1 16 0? 1903 1 17 0 1903 1 18 0 1903 1 19 0 1903 1 20 0 1903 1 21 10.2 1903 1 22 3 1903 1 23 0 1903 1 24 0 1903 1 25 0 1903 1 26 0 1903 1 27 0 1903 1 28 0 1903 1 29 0 1903 1 30 0 1903 1 31 0? 1903 2 1 0 1903 2 2 0.3 1903 2 3 0 1903 2 4 0 1903 2 5 0 1903 2 6 0 1903 2 7 0 1903 2 8 0 1903 2 9 0 1903 2 10 0 1903 2 11 0 1903 2 12 0 1903 2 13 0 1903 2 14 10.2 1903 2 15 13.5? 1903 2 16 7.9 1903 2 17 0.5 1903 2 18 0 1903 2 19 0 1903 2 20 0 1903 2 21 0 1903 2 22 0 1903 2 23 0 1903 2 24 0 1903 2 25 0 1903 2 26 0 1903 2 27 0 1903 2 28 0 1903 3 1 0 1903 3 2 0.5 1903 3 3 0 1903 3 4 21.3 1903 3 5 2 1903 3 6 0 1903 3 7 0 1903 3 8 20.1 1903 3 9 21.6 1903 3 10 0 1903 3 11 0 1903 3 12 0 1903 3 13 0 1903 3 14 3.3 1903 3 15 0 1903 3 16 0 1903 3 17 0 1903 3 18 0 1903 3 19 0 1903 3 20 0 1903 3 21 0 1903 3 22 0 1903 3 23 0 1903 3 24 2.8? 1903 3 25 0 1903 3 26 0 1903 3 27 0 1903 3 28 0 1903 3 29 0 1903 3 30 0 1903 3 31 0 1903 4? 1 0 1903 4 2 0 1903 4 3 0 1903 4 4 6.6 1903 4 5 17.5 1903 4 6 3.3 1903 4 7 0 1903 4 8 0? 1903 4 9 0 1903 4 10 0 1903 4 11 5.8 1903 4 12 0 1903 4 13 0 1903 4 14 0 1903 4 15 0 1903 4? 16 0 1903 4 17 2 1903 4 18 1.5 1903 4 19 0 1903 4 20 0 1903 4 21 0 1903 4 22 0.3 1903 4 23 0 1903 4 24 2.3 1903 4 25 8.6 1903 4 26 15.2 1903 4 27 3.3 1903 4 28 0 1903 4 29 0 1903 4 30 2? 1903 5 1 1.3 1903 5 2 0 1903 5 3 0 1903 5 4 0 1903 5 5 0 1903 5 6 0 1903 5 7 0 1903 5 8? 11.4 1903 5 9 0 1903 5 10 0 1903 5 11 1.3 1903 5 12 0 1903 5 13 0 1903 5 14 0 1903 5 15 0? 1903 5 16 0 1903 5 17 0 1903 5 18 0 1903 5 19 0.3 1903 5 20 11.7 1903 5 21 11.2 1903 5 22 3.3 1903 5 23 0.3 1903 5 24 0 1903 5 25 0 1903 5 26 1 1903 5 27 0 1903 5 28 0 1903 5 29 0 1903 5 30 2.5 1903 5 31 0 1903 6 1 0 1903 6 2 0 1903 6 3 3 1903 6 4 5.1 1903 6 5 4.3 1903 6 6 11.7? 1903 6 7 15.7 1903 6 8 10.7 1903 6 9 1.5 1903 6 10 2 1903 6 11 5.8 1903 6 12 3.3 1903 6 13 1? 1903 6 14 1.5 1903 6 15 4.6 1903 6 16 5.1 1903 6 17 0.3 1903 6 18 0 1903 6 19 1.3 1903 6 20 0.5? 1903 6 21 0 1903 6 22 0 1903 6 23 8.9 1903 6 24 0.3 1903 6 25 0 1903 6 26 5.1 1903 6 27 0 1903 6 28 0 1903 6 29 0 1903 6 30 0 1903 7 1 0.3 1903 7 2 7.1 1903 7 3 0.5 1903 7 4 9.4 1903 7 5 0.5 1903 7 6 4.8 1903 7 7 0.3 1903 7 8 0 1903 7 9 4.1 1903 7 10 0.3 1903 7 11 0 1903 7 12 0? 1903 7 13 0 1903 7 14 3.6 1903 7 15 4.6 1903 7 16 0 1903 7 17 0 1903 7 18 0 1903 7 19 11.2 1903 7 20 0.3 1903 7 21 0 1903 7 22 0 1903 7 23 0 1903 7 24 0 1903 7 25 0 1903 7 26 0 1903 7 27 0 1903 7 28 5.1 1903 7 29 4.8 1903 7 30 0.8 1903 7 31 1.3 1903 8 1 0.3 1903 8 2 0.5 1903 8 3 0 1903 8 4 0.8 1903 8 5 0.3 1903 8 6 0 1903 8 7 0 1903 8 8 0 1903 8 9 0 1903 8 10 0 1903 8 11 2.5 1903 8 12 1.3 1903 8 13 0 1903 8 14 0 1903 8 15 0 1903 8 16 2 1903 8 17 0 1903 8 18 1.5 1903 8 19 0 1903 8 20 0.8 1903 8 21 6.1 1903 8 22 0 1903 8 23 0.5 1903 8 24 0 1903 8 25 0 1903 8 26 0.5 1903 8 27 0 1903 8 28 0 1903 8 29 0 1903 8 30 0.5 1903 8 31 34.5 1903 9 1 0.3? 1903 9 2 6.1 1903 9 3 0 1903 9 4 0 1903 9 5 6.9 1903 9 6 2.5 1903 9 7 3.6 1903 9 8 0.5 1903 9 9 0 1903 9 10 0 1903 9 11 0 1903 9 12 0 1903 9 13 4.1 1903 9 14 0 1903 9 15 0 1903 9 16 0 1903 9 17 15.7 1903 9 18 4.1 1903 9 19 0.3 1903 9 20 0 1903 9 21 0 1903 9 22 0 1903 9 23 0.8? 1903 9 24 1.3 1903 9 25 10.4 1903 9 26 0 1903 9 27 0 1903 9 28 0.5 1903 9 29 9.7 1903 9 30 0? 1903 10 1 0.3 1903 10 2 0 1903 10 3 0.3 1903 10 4 0 1903 10 5 0 1903 10 6 0 1903 10 7 0 1903? 10 8 0 1903 10 9 0 1903 10 10 2.3 1903 10 11 0.3 1903 10 12 0 1903 10 13 0 1903 10 14 0 1903 10 15 4.6 1903 10 16 1 1903 10 17 0 1903 10 18 0 1903 10 19 0 1903 10 20 5.8 1903 10 21 0 1903 10 22 0.3 1903 10 23 0 1903 10 24 0.5 1903 10 25 0 1903 10 26 0 1903 10 27 0 1903 10 28 0 1903 10? 29 0 1903 10 30 0 1903 10 31 0 1903 11 1 14.5 1903 11 2 0 1903 11 3 0 1903 11 4 0 1903 11 5 0 1903 11 6 0 1903 11 7 0 1903 11 8 0 1903 11 9 0 1903 11 10 0.8 1903 11 11 0.8 1903 11 12 0? 1903 11 13 0 1903 11 14 0 1903 11 15 1.7 1903 11 16 2.1 1903 11 17 0 1903 11 18 0 1903 11 19 0? 1903 11 20 0 1903 11 21 0 1903 11 22 0 1903 11 23 1 1903 11 24 2.5 1903 11 25 0.3 1903 11 26 9.1? 1903 11 27 2.5 1903 11 28 9.9 1903 11 29 16.8 1903 11 30 0.8 1903 12 1 0 1903 12 2 0 1903 12 3 0? 1903 12 4 0 1903 12 5 0 1903 12 6 0 1903 12 7 0 1903 12 8 0 1903 12 9 0 1903 12 10 0 1903 12 11 15.5 1903 12 12 0.5 1903 12 13 1.8 1903 12 14 15.7 1903 12 15 0 1903 12 16 0 1903 12 17 0 1903 12 18 0 1903 12 19 0.3 1903 12 20 2.8 1903 12 21 0 1903 12 22 0 1903 12 23 0 1903 12 24 0 1903 12 25 0 1903 12 26 0 1903 12 27 33.5 1903 12 28 0 1903 12 29 0 1903 12 30 0 1903 12 31 0 1904? 1 1 2 1904 1 2 2 1904 1 3 33.8 1904 1 4 0.3 1904 1 5 0 1904 1 6 0 1904 1 7 0 1904 1 8 0? 1904 1 9 0 1904 1 10 0 1904 1 11 0 1904 1 12 0 1904 1 13 0 1904 1 14 0 1904 1 15 0 1904 1? 16 0 1904 1 17 0 1904 1 18 0 1904 1 19 0 1904 1 20 0 1904 1 21 2.8 1904 1 22 18 1904 1 23 1.8 1904 1 24 0 1904 1 25 0 1904 1 26 2 1904 1 27 4.6 1904 1 28 0 1904 1 29 0 1904 1 30 0 1904 1 31 0 1904 2 1 0 1904 2 2 0 1904 2 3 0 1904 2 4 0 1904 2 5 0 1904 2 6 1.8 1904 2 7 0? 1904 2 8 0 1904 2 9 0 1904 2 10 0 1904 2 11 0 1904 2 12 0.8 1904 2 13 0 1904 2 14 0 1904 2 15 0 1904 2 16 0 1904 2 17 0 1904 2 18 0 1904 2 19 1.3 1904 2 20 0 1904 2 21 0 1904 2 22 0.5 1904 2 23 0 1904 2 24 0.3 1904 2 25 0 1904 2 26 8.9 1904 2 27 1.5 1904 2 28 0 1904 2 29 0? 1904 3 1 0 1904 3 2 0 1904 3 3 0 1904 3 4 0 1904 3 5 0 1904 3 6 0 1904 3 7 0 1904 3 8 0 1904 3 9 0 1904 3 10 0 1904 3 11 0 1904 3 12 0 1904 3 13 0 1904 3 14 0 1904 3 15 0 1904 3 16 6.1 1904 3 17 0 1904 3 18 0 1904 3 19 0 1904 3 20 1.5 1904 3 21 0.8 1904 3 22 0 1904 3 23 0 1904 3 24 0 1904 3 25 0 1904 3 26 0 1904 3 27 0 1904 3 28 0 1904 3 29 0 1904 3 30 0 1904 3 31 0 1904 4 1 0 1904 4 2 0 1904 4 3 0 1904 4 4 0 1904 4 5 0 1904 4 6 0 1904 4 7 0? 1904 4 8 0 1904 4 9 0 1904 4 10 0 1904 4 11 0 1904 4 12 0 1904 4 13 0 1904 4 14 0 1904 4? 15 0 1904 4 16 0 1904 4 17 0 1904 4 18 23.6 1904 4 19 10.9 1904 4 20 0 1904 4 21 2.5 1904 4 22 1.8 1904 4 23 0 1904 4 24 0 1904 4 25 0 1904 4 26 0 1904 4 27 2 1904 4 28 1 1904 4 29 0 1904 4 30 0 1904 5 1 0 1904 5 2 0 1904 5 3 0 1904 5 4 0.5 1904 5 5 0 1904 5 6 7.4 1904 5 7? 0.3 1904 5 8 0 1904 5 9 3.8 1904 5 10 0 1904 5 11 0 1904 5 12 0 1904 5 13 0 1904 5 14 0 1904 5 15 0 1904 5 16 3.6 1904 5 17 8.6 1904 5 18 0 1904 5 19 0 1904 5 20 0 1904 5 21 5.3 1904 5 22 4.3 1904 5 23 0 1904 5 24 0 1904 5 25 0 1904 5 26 0 1904 5 27 0 1904 5 28 0 1904 5 29 0 1904 5 30 18.8 1904 5 31 5.3 1904 6 1 1 1904 6 2 0.3 1904 6 3 0 1904 6 4 0 1904 6 5 0 1904 6 6 0 1904 6 7 1.3 1904 6 8 0 1904 6 9 0 1904 6 10 0 1904 6 11 1.8 1904 6 12 8.4 1904 6 13 0 1904 6 14 0.8 1904 6 15 0 1904 6 16 0.3 1904 6 17 15.2 1904 6 18 13.7 1904 6 19 1.8 1904 6 20 0.5 1904 6 21 0 1904 6 22 7.6 1904 6 23 5.1 1904 6 24 1.3 1904 6 25 0 1904 6 26 0 1904 6 27 0 1904 6 28 0.5 1904 6 29 13 1904 6 30 30.5 1904 7 1 8.6 1904 7 2 1.5 1904 7 3 1.3 1904 7 4 0? 1904 7 5 0 1904 7 6 0.8 1904 7 7 1 1904 7 8 1 1904 7 9 0 1904 7 10 0 1904 7 11 0 1904 7 12 0 1904 7 13 11.2 1904 7 14 4.8 1904 7 15 7.6 1904 7 16 3.6 1904 7 17 0 1904 7 18 0.5 1904 7 19 0 1904 7 20 0.3 1904 7 21 0 1904 7 22 0 1904 7 23 0 1904 7 24 15.5 1904 7 25 4.6 1904 7 26 1.3 1904 7 27 1 1904 7 28 0.5 1904 7 29 0 1904 7 30 0 1904 7 31 0 1904 8 1 0 1904 8 2 0 1904 8 3 0 1904 8 4 0 1904 8 5 0 1904 8 6 0 1904 8 7 3.8 1904 8 8 0 1904 8 9 0 1904 8 10 0? 1904 8 11 0 1904 8 12 0 1904 8 13 9.1 1904 8 14 0 1904 8 15 0 1904 8 16 1.3 1904 8 17 0 1904 8 18 0.5 1904 8 19 2.5 1904 8 20 7.1 1904 8 21 0 1904 8 22 0 1904 8 23 2.5 1904 8 24 2.8 1904 8 25 0 1904 8 26 0.3 
i want the counting number of rain as follows:

??????????? Jan??????? Feb??????? Mar??? Apr??? May??? Jun??? Jul??? Aug??? Sep??? Oct??? Nov??? Dec
1901??????? x190219031904

x = number of rain for > 0.000001

Thanks for your help.


??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From rshepard at appl-ecosys.com  Thu Oct  1 17:07:31 2015
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 1 Oct 2015 08:07:31 -0700 (PDT)
Subject: [R] Announcement - The Use Of Nabble For Posting To R-Help Will
 No Longer Be Supported Effective October 15, 2015
In-Reply-To: <90471313-C179-464E-8A84-91C2BCE66CAD@me.com>
References: <90471313-C179-464E-8A84-91C2BCE66CAD@me.com>
Message-ID: <alpine.LNX.2.11.1510010807070.18215@localhost>

On Thu, 1 Oct 2015, Marc Schwartz wrote:

> On behalf of The R Foundation for Statistical Computing, this is an
> announcement that, effective October 15, 2015, the Nabble online forums
> will no longer be a supported vehicle for posting new threads and/or
> replying to existing threads on R-Help.

+2

Rich


From giorgio.garziano at ericsson.com  Thu Oct  1 17:26:30 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 1 Oct 2015 15:26:30 +0000
Subject: [R] merging tables based on both row and column names
Message-ID: <248E6FA047A8C746BA491485764190F522095B39@ESESSMB207.ericsson.se>

I reworked Frank Schwidom's solution to make it shorter than its original version.

  test1 <- (rbind(c(0.1,0.2),0.3,0.1))
  rownames(test1)=c('y1','y2','y3')
  colnames(test1) = c('x1','x2');
  test2 <- (rbind(c(0.8,0.9,0.5),c(0.5,0.1,0.6)))
  rownames(test2) = c('y2','y5')
  colnames(test2) = c('x1','x3','x2')

  lTest12 <- list(test1, test2)
  namesRow <- unique( unlist( lapply(lTest12, rownames)))
  namesCol <- unique( unlist( lapply(lTest12, colnames)))

# here reworked code starts

  tmp1 <- sapply(lTest12, function(x) as.vector( x[match(namesRow, rownames(x)), match(namesCol, colnames(x))]))
  tmp2 <- apply(tmp1, 1, function(x) { na.omit(x) })
  dimnames1 <- list(namesRow, namesCol)
  tmp3 <- array(data = tmp2, dim = sapply(dimnames1, length), dimnames = dimnames1)
  tmp3

  > paste(tmp3)
  [1] "0.1"         "c(0.3, 0.8)" "0.1"         "0.5"         "0.2"
  [6] "c(0.3, 0.5)" "0.1"         "0.6"         "numeric(0)"  "0.9"
  [11] "numeric(0)"  "0.1"

  > tmp3
  x1           x2        x3
  y1 0.1       0.2       Numeric,0
  y2 Numeric,2 Numeric,2 0.9
  y3 0.1       0.1       Numeric,0
  y5 0.5       0.6       0.1
  >

  > tmp3["y2","x1"]
  [[1]]
  [1] 0.3 0.8

  > tmp3["y2","x2"]
  [[1]]
  [1] 0.3 0.5


	[[alternative HTML version deleted]]


From smd71092 at yahoo.com  Thu Oct  1 16:48:30 2015
From: smd71092 at yahoo.com (Moe Daniels)
Date: Thu, 1 Oct 2015 14:48:30 +0000 (UTC)
Subject: [R] Generalized ordered logit model
Message-ID: <1431255457.3775730.1443710910635.JavaMail.yahoo@mail.yahoo.com>

I have limited statistical experience from my coursework in undergrad running simple linear regressions and performing chi-square tests. I have some data, ~5000 survey results on individuals, each with a score from a scale of 1-12 on how security conscious they are (determined by their answers to previous security related questions) and we also asked multiple choice questions on income (USD 0-USD 19,999; USD 20,000-USD 39,999; etc.), age (21-30, 31-40, etc.) and level of education (High School, Undergraduate, Masters, and Doctoral). I wanted to know how I would set this up to determine which is the biggest factor in determining their security consciousness with statistical significance. Here is a pivot table from my Excel file with random data. 

I believe I will need to run a generalized ordered logit but I am not sure how to do so in R. I have very little experience using R and I don't think this can be performed in Excel which would be my preference. Any help at all would be greatly appreciated!

| ? |
| ? |  | ? | ? | ? | ? | ? |
|  |
|  |
| View on i.stack.imgur.com | Preview by Yahoo |
|  |
| ? |



	[[alternative HTML version deleted]]


From eandresens at gmail.com  Thu Oct  1 16:59:09 2015
From: eandresens at gmail.com (Ellen Andresen)
Date: Thu, 1 Oct 2015 09:59:09 -0500
Subject: [R] glmm: random term, overdispersion and comparisons
Message-ID: <CANfdbE20MLACstrd-HJzpg9s81BOu4nso4HiJCB-mDSMB6r_3Q@mail.gmail.com>

Hello,
I studied the effect of a hurricane in Cozumel on understory birds. I
have bird abundances (i.e. counts) registered always on the SAME six
sites (i.e. blocks). I have data for: before the hurricane, first year
after the hurricane, second year after the hurricane. I each of these
time periods, I also have data for summer season and for winter
season. I do not have a balanced design, in one of the time periods I
only have data for 5 of the six sites, and for another period I only
have data for 3 of the six sites.
I am defining Poisson error distrubution for the response variable.
I am using 'glmer' with two fixed factors, and I am interested in
their interaction:
- factor hurricane (three levels: before, after 1 y, after 2 y)
- factor season (two levels: summer, winter)
I am also specifying a random factor (sites), and I am specifying the
nested structure of the design. However, I don't know if I am
specifying the random part of the model in the correct way; this is
what I am doing:
       abundance ~ hurricane*season + (1|site/hurricane/season)

I have three questions:
1. Is the random part specified correctly?
2. How do I check for overdispersion, and how can I correct for it?
(for each site I only have one observation; sites are my replicates)
3. How do I make the following comparisons: I am interested in testing
for each season separately, after 1 y vs. before the hurricane, and
after 2 years vs. before the hurricane.

Thank you so much!
Ellen Andresen
UNAM-Mexico


From dwinsemius at comcast.net  Thu Oct  1 17:38:55 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Oct 2015 08:38:55 -0700
Subject: [R] Help with improveProb function in Hmisc in R
In-Reply-To: <1443691599854-4713004.post@n4.nabble.com>
References: <1443691599854-4713004.post@n4.nabble.com>
Message-ID: <3701E28C-BE67-40C7-979A-249667C230B1@comcast.net>


On Oct 1, 2015, at 2:26 AM, kirsada wrote:

> Please bear with me, I am very new to R.
> 
> My question is regarding the use of the improveProb function in the Hmisc
> package. I have two logistic models, the only difference being that the
> second model contains my novel marker of interest. I am trying to calculate
> NRI and IDI to compare models.
> 
> I have the PredRisks for both models - PredRisk1 and PredRisk2, and my
> outcome is disease 0/1. How do I define this in R in order to run
> 
> improveProb(x1, x2, y)?

If you are saying that you have two numerical values each of length one, than I do not think you can pass those to a function that expects raw data. If your "PredRisk" variables are vectors of the same length as y and having a range of [0,1] as befits a probability, then what problems are you experiencing?

-- 
David Winsemius
Alameda, CA, USA


From giorgio.garziano at ericsson.com  Thu Oct  1 21:23:08 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 1 Oct 2015 19:23:08 +0000
Subject: [R] merging tables based on both row and column names
Message-ID: <248E6FA047A8C746BA491485764190F522095DF0@ESESSMB207.ericsson.se>

Replacing na.omit() with !is.na() appears to improve performance with time.

  rm(list=ls())

  test1 <- (rbind(c(0.1,0.2),0.3,0.1))
  rownames(test1)=c('y1','y2','y3')
  colnames(test1) = c('x1','x2');
  test2 <- (rbind(c(0.8,0.9,0.5),c(0.5,0.1,0.6)))
  rownames(test2) = c('y2','y5')
  colnames(test2) = c('x1','x3','x2')

  solution_3 <- function(test1, test2) {
    lTest12 <- list(test1, test2)
    namesRow <- unique( unlist( lapply(lTest12, rownames)))
    namesCol <- unique( unlist( lapply(lTest12, colnames)))
    tmp1 <- sapply(lTest12, function(x) as.vector(x[match(namesRow, rownames(x)), match(namesCol, colnames(x))]))
    tmp2 <- apply(tmp1, 1, function(x) { x[!is.na(x)] })
    dimnames1 <- list(namesRow, namesCol)
    tmp3 <- array(data = tmp2, dim = sapply(dimnames1, length), dimnames = dimnames1)
    tmp3
  }

  system.time(for(i in 1:10000) {solution_3(test1, test2)})




	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Oct  1 23:04:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 2 Oct 2015 10:04:59 +1300
Subject: [R] Counting number of rain
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
Message-ID: <560D9FFB.6090001@auckland.ac.nz>

On 02/10/15 03:45, David L Carlson wrote:

<SNIP>

> If you want the month names:
>
>> mnt <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
> + "July", "Aug", "Sep", "Oct", "Nov", "Dec")
>> dimnames(tbl)$Month <- mnt

<SNIP>

Unnecessary typing; there is a built-in data set "month.abb" (in the
"base" package) that is identical to your "mnt".

Difficult (nearly impossible!) to find, but, if you can't quite remember 
the name!  I *knew* I'd seen it, so I persisted and eventually tracked 
it down.

Strangely ??month or help.search("month") yield no trace of it.  Pages 
and pages of (useless!) output but no sign of "month.abb" (nor of 
"month.name" which gives the unabbreviated month names).

Can anyone explain to me why "??" and help.search() are of no help here?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From pdalgd at gmail.com  Thu Oct  1 23:54:36 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 1 Oct 2015 23:54:36 +0200
Subject: [R] Counting number of rain
In-Reply-To: <560D9FFB.6090001@auckland.ac.nz>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
Message-ID: <BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>


> On 01 Oct 2015, at 23:04 , Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
> On 02/10/15 03:45, David L Carlson wrote:
> 
> <SNIP>
> 
>> If you want the month names:
>> 
>>> mnt <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
>> + "July", "Aug", "Sep", "Oct", "Nov", "Dec")
>>> dimnames(tbl)$Month <- mnt
> 
> <SNIP>
> 
> Unnecessary typing; there is a built-in data set "month.abb" (in the
> "base" package) that is identical to your "mnt".
> 
> Difficult (nearly impossible!) to find, but, if you can't quite remember the name!  I *knew* I'd seen it, so I persisted and eventually tracked it down.
> 
> Strangely ??month or help.search("month") yield no trace of it.  Pages and pages of (useless!) output but no sign of "month.abb" (nor of "month.name" which gives the unabbreviated month names).
> 
> Can anyone explain to me why "??" and help.search() are of no help here?

Umm,

-------
Help files with alias or concept or title matching ?month? using fuzzy
matching:


base::Constants         Built-in Constants
  Aliases: month.abb, month.name
....
-------

Also, entering "month<TAB><TAB>" gives the completions

> month
month.abb      monthplot      months.Date    
month.name     months         months.POSIXt  

-pd

> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From lauren.spirko at temple.edu  Thu Oct  1 20:10:59 2015
From: lauren.spirko at temple.edu (lspirk)
Date: Thu, 1 Oct 2015 11:10:59 -0700 (PDT)
Subject: [R] Variance of parameter Beta under the null for Prop.Odds
Message-ID: <1443723059992-4713037.post@n4.nabble.com>

Hi all,

I am trying to calculate the variance-covariance matrix for parameter Beta
under the null (Ho) using the "prop.odds" function in the timereg package. 
In other words, I am looking for Var(Beta under the null). 

For the Cox PH model, I used the "vcov" function and did the following:

	cox <- coxph(Surv(time, censor) ~ x, iter = 0, init = 0, data = dat)	
	sig2 <- vcov(cox)  

Is there something similar to use for a prop.odds model?  

Note: Here is a simple example of how I fit a prop.odds model
po <- prop.odds(Event(time, censor) ~ x, data = dat)

Thanks for the help!



--
View this message in context: http://r.789695.n4.nabble.com/Variance-of-parameter-Beta-under-the-null-for-Prop-Odds-tp4713037.html
Sent from the R help mailing list archive at Nabble.com.


From johanna.vonbahr at gmail.com  Thu Oct  1 21:15:04 2015
From: johanna.vonbahr at gmail.com (Johanna von Bahr)
Date: Thu, 1 Oct 2015 21:15:04 +0200
Subject: [R] Regressing the residuals on the country dummies
Message-ID: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>

I?m trying to estimate a model regressing the residuals on the country dummies as follows;
model.resC <- lm(model2$res ~ as.factor(Country))
summary(model.resC)

As I call the model I get the following results regarding the residuals:

"ALL 90 residuals are 0: no residual degrees of freedom!"

What has gone wrong?

From duo_wan at yahoo.com  Thu Oct  1 22:44:01 2015
From: duo_wan at yahoo.com (duo wan)
Date: Thu, 1 Oct 2015 20:44:01 +0000 (UTC)
Subject: [R] problem of Mahalanobis distance matching using MatchIT
Message-ID: <2096669818.3986502.1443732241499.JavaMail.yahoo@mail.yahoo.com>

Dear All,
I am trying to use simulation to test?mahalanobis distance matching method. ?Somehow I do not think Matchit is giving me what I want
Below is the code:
n<-100
x1_contr<-runif(n,0,5)
x2_contr<-runif(n,0,5)
x_contr<-cbind(x1=x1_contr,x2=x2_contr)
x1_treat<-runif(n,1,6)
x2_treat<-runif(n,1,6)
x_treat<-cbind(x1=x1_treat,x2=x2_treat)
T<-c(rep(0,n),rep(1,n))
X.all<-rbind(x_contr,x_treat)

my.data<-data.frame(T,X.all)
rownames(my.data)<-paste("ID",1:dim(my.data)[1])

###MDM ###
mdm.out<-matchit(T~x1+x2,data=my.data,distance="mahalanobis",mahvars 
=c("x1","x2"), caliper=0.05,replace=FALSE)

summary(mdm.out)
Sample sizes:
          Control Treated
All           100     100
Matched       100     100
Unmatched       0       0
Discarded       0       0> match.data(m.out2)
                Y    T         x1       x2    distance weights
Y ID 1    6.2242654 0 4.04492572 2.49487149       NA       1
Y ID 2    3.7789825 0 0.08779960 3.02116199       NA       1
Y ID 3    4.5557875 0 2.18233171 1.58540582       NA       1
Y ID 4    5.4625778 0 1.49701910 4.68757127       NA       1
Y ID 5    0.2351840 0 2.64143227 0.08412851       NA       1
Y ID 6    4.5206068 0 3.57662464 1.56089398       NA       1
How can all cases and controls be matched? The data are simulated to have some imbalances between cases and controls. Also why distance is "NA"? I changed caliper values but got the same results. ?Any suggestion will be appreciated.
Vincent

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Oct  2 03:22:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 2 Oct 2015 14:22:59 +1300
Subject: [R] Counting number of rain
In-Reply-To: <BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
Message-ID: <560DDC73.9020405@auckland.ac.nz>

On 02/10/15 10:54, peter dalgaard wrote:

>> On 01 Oct 2015, at 23:04 , Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>
>> On 02/10/15 03:45, David L Carlson wrote:
>>
>> <SNIP>
>>
>>> If you want the month names:
>>>
>>>> mnt <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
>>> + "July", "Aug", "Sep", "Oct", "Nov", "Dec")
>>>> dimnames(tbl)$Month <- mnt
>>
>> <SNIP>
>>
>> Unnecessary typing; there is a built-in data set "month.abb" (in
>> the "base" package) that is identical to your "mnt".
>>
>> Difficult (nearly impossible!) to find, but, if you can't quite
>> remember the name!  I *knew* I'd seen it, so I persisted and
>> eventually tracked it down.
>>
>> Strangely ??month or help.search("month") yield no trace of it.
>> Pages and pages of (useless!) output but no sign of "month.abb"
>> (nor of "month.name" which gives the unabbreviated month names).
>>
>> Can anyone explain to me why "??" and help.search() are of no help
>> here?
>
> Umm,
>
> ------- Help files with alias or concept or title matching ?month?
> using fuzzy matching:
>
>
> base::Constants         Built-in Constants Aliases: month.abb,
> month.name .... -------

Hmm. When I did ??month I got a completely different display. It
contained *absolutely no* mention of month.abb. That *seems* to be
because I have help_type set to "html". When I re-set help_type to
"text", I get a display like unto the one that you obtained (and it does 
indeed lead one to month.abb).

It seems to me ver' strange that one gets a different collection of
information under help_type="text" than one does under help_type="html".
If I were me, I would classify this as a bug.

> Also, entering "month<TAB><TAB>" gives the completions
>
>> month
> month.abb      monthplot      months.Date month.name     months
> months.POSIXt

Yes, I eventually managed to come up with this trick as well.  But that 
is not really relevant to the phenomenon that "??" or help.search() 
don't work effectively, or at least not consistently (the effectiveness 
appearing to depend --- for some bizarre reason --- on the value of 
help_type).

cheers,

Rolf

P.S. I have been unable to find a corresponding vector of the names of 
the days of the week, although I have a very vague recollection of the 
existence of such a vector.  Does it exist, and if so what is it called?
Or is my recollection an illusion brought on by advancing senility?

R.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ddalthorp at usgs.gov  Fri Oct  2 03:32:02 2015
From: ddalthorp at usgs.gov (Dan D)
Date: Thu, 1 Oct 2015 18:32:02 -0700 (PDT)
Subject: [R] tcltk table properties
Message-ID: <1443749522506-4713045.post@n4.nabble.com>

I have a tkwidget table (say, tbl1) that may be reconfigured at various times
depending on user input. Is there an easy way to later extract table
properties? Something like...

nrow<-tkgetproperties(tbl1, rows)

Muchas thanks in advance.

-Dan



--
View this message in context: http://r.789695.n4.nabble.com/tcltk-table-properties-tp4713045.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Oct  2 04:47:39 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Oct 2015 19:47:39 -0700
Subject: [R] Counting number of rain
In-Reply-To: <560DDC73.9020405@auckland.ac.nz>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
	<560DDC73.9020405@auckland.ac.nz>
Message-ID: <DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>


On Oct 1, 2015, at 6:22 PM, Rolf Turner wrote:

> On 02/10/15 10:54, peter dalgaard wrote:
> 
>>> On 01 Oct 2015, at 23:04 , Rolf Turner <r.turner at auckland.ac.nz>
>>> wrote:
>>> 
>>> On 02/10/15 03:45, David L Carlson wrote:
>>> 
>>> <SNIP>
>>> 
>>>> If you want the month names:
>>>> 
>>>>> mnt <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun",
>>>> + "July", "Aug", "Sep", "Oct", "Nov", "Dec")
>>>>> dimnames(tbl)$Month <- mnt
>>> 
>>> <SNIP>
>>> 
>>> Unnecessary typing; there is a built-in data set "month.abb" (in
>>> the "base" package) that is identical to your "mnt".
>>> 
>>> Difficult (nearly impossible!) to find, but, if you can't quite
>>> remember the name!  I *knew* I'd seen it, so I persisted and
>>> eventually tracked it down.
>>> 
>>> Strangely ??month or help.search("month") yield no trace of it.
>>> Pages and pages of (useless!) output but no sign of "month.abb"
>>> (nor of "month.name" which gives the unabbreviated month names).
>>> 
>>> Can anyone explain to me why "??" and help.search() are of no help
>>> here?
>> 
>> Umm,
>> 
>> ------- Help files with alias or concept or title matching ?month?
>> using fuzzy matching:
>> 
>> 
>> base::Constants         Built-in Constants Aliases: month.abb,
>> month.name .... -------
> 
> Hmm. When I did ??month I got a completely different display. It
> contained *absolutely no* mention of month.abb. That *seems* to be
> because I have help_type set to "html". When I re-set help_type to
> "text", I get a display like unto the one that you obtained (and it does indeed lead one to month.abb).
> 
> It seems to me ver' strange that one gets a different collection of
> information under help_type="text" than one does under help_type="html".
> If I were me, I would classify this as a bug.
> 
>> Also, entering "month<TAB><TAB>" gives the completions
>> 
>>> month
>> month.abb      monthplot      months.Date month.name     months
>> months.POSIXt
> 
> Yes, I eventually managed to come up with this trick as well.  But that is not really relevant to the phenomenon that "??" or help.search() don't work effectively, or at least not consistently (the effectiveness appearing to depend --- for some bizarre reason --- on the value of help_type).
> 
> cheers,
> 
> Rolf
> 
> P.S. I have been unable to find a corresponding vector of the names of the days of the week, although I have a very vague recollection of the existence of such a vector.  Does it exist, and if so what is it called?

It's could called up by strptime because it is mapped to a character vector by the internationalization database:

> format( as.Date(1:7)+2, format="%A")
[1] "Sunday"    "Monday"    "Tuesday"   "Wednesday" "Thursday"  "Friday"   
[7] "Saturday" 


> Or is my recollection an illusion brought on by advancing senility?
> 
> R.
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Fri Oct  2 05:29:59 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 2 Oct 2015 16:29:59 +1300
Subject: [R] Counting number of rain
In-Reply-To: <DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
	<560DDC73.9020405@auckland.ac.nz>
	<DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>
Message-ID: <560DFA37.6050801@auckland.ac.nz>

On 02/10/15 15:47, David Winsemius wrote:

<SNIP>

> On Oct 1, 2015, at 6:22 PM, Rolf Turner wrote:
>>
>> P.S. I have been unable to find a corresponding vector of the names
>> of the days of the week, although I have a very vague recollection
>> of the existence of such a vector.  Does it exist, and if so what
>> is it called?
>
> It's could called up by strptime because it is mapped to a character
> vector by the internationalization database:
>
>> format( as.Date(1:7)+2, format="%A")
> [1] "Sunday"    "Monday"    "Tuesday"   "Wednesday" "Thursday"
> "Friday" [7] "Saturday"

<SNIP>

When I try that (copying and pasting your code so that there's no chance 
of fumble-fingering) I get:

> Error in as.Date.numeric(1:7) : 'origin' must be supplied

Why do these things always happen to *me*???

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Fri Oct  2 06:33:03 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Oct 2015 21:33:03 -0700
Subject: [R] Counting number of rain
In-Reply-To: <560DFA37.6050801@auckland.ac.nz>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
	<560DDC73.9020405@auckland.ac.nz>
	<DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>
	<560DFA37.6050801@auckland.ac.nz>
Message-ID: <B16028E9-D3DE-41AA-A211-66E6B41587EA@comcast.net>


On Oct 1, 2015, at 8:29 PM, Rolf Turner wrote:

> On 02/10/15 15:47, David Winsemius wrote:
> 
> <SNIP>
> 
>> On Oct 1, 2015, at 6:22 PM, Rolf Turner wrote:
>>> 
>>> P.S. I have been unable to find a corresponding vector of the names
>>> of the days of the week, although I have a very vague recollection
>>> of the existence of such a vector.  Does it exist, and if so what
>>> is it called?
>> 
>> It's could called up by strptime because it is mapped to a character
>> vector by the internationalization database:
>> 
>>> format( as.Date(1:7)+2, format="%A")
>> [1] "Sunday"    "Monday"    "Tuesday"   "Wednesday" "Thursday"
>> "Friday" [7] "Saturday"
> 
> <SNIP>
> 
> When I try that (copying and pasting your code so that there's no chance of fumble-fingering) I get:
> 
>> Error in as.Date.numeric(1:7) : 'origin' must be supplied
> 
> Why do these things always happen to *me*???

Or why am I so lucky as to avoid the need for an origin when the help page says the call is:

## S3 method for class 'numeric'
as.Date(x, origin, ...)            # noting no default in the formals


The code says that origin should be supplied if it is missing:

> as.Date.numeric
function (x, origin, ...) 
{
    if (missing(origin)) 
        origin <- "1970-01-01"
    if (identical(origin, "0000-00-00")) 
        origin <- as.Date("0000-01-01", ...) - 1
    as.Date(origin, ...) + x
}


-- 

David Winsemius
Alameda, CA, USA


From markleeds2 at gmail.com  Fri Oct  2 08:03:48 2015
From: markleeds2 at gmail.com (Mark Leeds)
Date: Fri, 2 Oct 2015 02:03:48 -0400
Subject: [R] Regressing the residuals on the country dummies
In-Reply-To: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
References: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
Message-ID: <CAHz+bWahbGi+GusiVddqOjD1y5ACqQAhpbeo8myXE9Ty3jYQ-Q@mail.gmail.com>

Hi: You'd have to provide a dput of "model2" and "Country" for anyone to
give a definitive answer but my guess is that you have an orthogonal X
matrix which is causing you to fit the
model perfectly which causes the model residuals to be zero.

Also, you didn't explain what you're doing but modelling residuals by using
purely factors doesn't sound like something one would want to do ? I could
be mistaken since
I don't know the context but  you should explain what exactly what your
goal is and your reasoning for doing what you're doing.








On Thu, Oct 1, 2015 at 3:15 PM, Johanna von Bahr <johanna.vonbahr at gmail.com>
wrote:

> I?m trying to estimate a model regressing the residuals on the country
> dummies as follows;
> model.resC <- lm(model2$res ~ as.factor(Country))
> summary(model.resC)
>
> As I call the model I get the following results regarding the residuals:
>
> "ALL 90 residuals are 0: no residual degrees of freedom!"
>
> What has gone wrong?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From cagomezt at uvic.ca  Thu Oct  1 22:55:02 2015
From: cagomezt at uvic.ca (Carlos Gomez)
Date: Thu, 1 Oct 2015 13:55:02 -0700
Subject: [R] Researching the R Community
Message-ID: <039f65ba7ec805bc5690f80bf07d5fa3.squirrel@wm3.uvic.ca>

Dear r-help mailing list,

Some colleagues and I are working on a series of research studies related
to mailing list, and Stack Overflow. While I do understand that this
announcement would be technically off topic - it's about a study that
could involve R-Help users. So, please, If you have time and want to help
me on this research, I will really appreciate your collaboration.

THE SURVEY: http://goo.gl/alZN4t


I would like to invite you to participate in an academic survey namely
"Towards understanding communication channels within a community".

We are Carlos Gomez and Margaret-Anne Storey, researchers from the
Computer Human Interaction and Software Engineering Lab (CHISEL) in the
Department of Computer Science at the University of Victoria, invite you
to participate in the study. We'd be grateful if you could help us
understand the current use of communication tools, the importance of using
an adequate communication tool, and the interplay between tools and the
development process by completing an on-line survey
(http://goo.gl/alZN4t). The survey should take about 10 to 15 minutes

General remarks: This is a purely academic research project with no
commercial interests. We will openly publish the results so everyone can
benefit from them, but will anonymize everything before doing so; your
responses will be handled confidentially. Responses -unless explicitly
stated otherwise- cannot be traced back to individual respondents. Please
note that you are not obligated to participate in the survey.

Target audience: Users and developers of R.

Note:
 - The survey is available in English and Spanish.
 - For an example of related studies from our lab, please visit Lief
Singer's work, How Software Developers Use Twitter (http://goo.gl/OO61Vf)
 - I do understand that this email would be technically off topic - it's
about a study that could involve R-Help users - not about coding in R.
 - This project is based on an open challenge presented by Bogdan
Vasilescu on his dissertation (http://goo.gl/IKsf2e)

Thank you for your consideration!

Best regards,
Carlos Gomez
Contact information: cagomezt(at)uvic(dot)ca
CHISEL Web site: http://thechiselgroup.org
Canada, BC, Victoria


From thierry.onkelinx at inbo.be  Fri Oct  2 10:03:36 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Fri, 2 Oct 2015 10:03:36 +0200
Subject: [R] glmm: random term, overdispersion and comparisons
In-Reply-To: <CANfdbE20MLACstrd-HJzpg9s81BOu4nso4HiJCB-mDSMB6r_3Q@mail.gmail.com>
References: <CANfdbE20MLACstrd-HJzpg9s81BOu4nso4HiJCB-mDSMB6r_3Q@mail.gmail.com>
Message-ID: <CAJuCY5xVxvR0OhmGiNYAmvN0fKVBoMOfCTbf8fKYeSMX8PUUew@mail.gmail.com>

Dear Ellen,

You're using the Poisson distribution. There is no error (noise) term in a
glmm with Poisson distribution.

1) The random part seems to be quite complicated given the sample size.
(1|site) is probably sufficient. Note that your design is not nested but
crossed.
2) Overdispersion is likely in bird abundance. You could use a negative
binomial distribution instead of a Poisson distribution. Then the
overdispersion is modeled. Use the glmer.nb() function.
3) Have a look at the glht() function in the multcomp package. That allows
you to test specific contrasts of your model parameters.

Note that the r-sig-mixedmodels list is more appropriate for follow-up
questions.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-01 16:59 GMT+02:00 Ellen Andresen <eandresens at gmail.com>:

> Hello,
> I studied the effect of a hurricane in Cozumel on understory birds. I
> have bird abundances (i.e. counts) registered always on the SAME six
> sites (i.e. blocks). I have data for: before the hurricane, first year
> after the hurricane, second year after the hurricane. I each of these
> time periods, I also have data for summer season and for winter
> season. I do not have a balanced design, in one of the time periods I
> only have data for 5 of the six sites, and for another period I only
> have data for 3 of the six sites.
> I am defining Poisson error distrubution for the response variable.
> I am using 'glmer' with two fixed factors, and I am interested in
> their interaction:
> - factor hurricane (three levels: before, after 1 y, after 2 y)
> - factor season (two levels: summer, winter)
> I am also specifying a random factor (sites), and I am specifying the
> nested structure of the design. However, I don't know if I am
> specifying the random part of the model in the correct way; this is
> what I am doing:
>        abundance ~ hurricane*season + (1|site/hurricane/season)
>
> I have three questions:
> 1. Is the random part specified correctly?
> 2. How do I check for overdispersion, and how can I correct for it?
> (for each site I only have one observation; sites are my replicates)
> 3. How do I make the following comparisons: I am interested in testing
> for each season separately, after 1 y vs. before the hurricane, and
> after 2 years vs. before the hurricane.
>
> Thank you so much!
> Ellen Andresen
> UNAM-Mexico
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct  2 10:55:20 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 2 Oct 2015 10:55:20 +0200
Subject: [R] tcltk table properties
In-Reply-To: <1443749522506-4713045.post@n4.nabble.com>
References: <1443749522506-4713045.post@n4.nabble.com>
Message-ID: <69FC1002-A0E4-4CBA-ADA0-4812493B9CBF@gmail.com>


On 02 Oct 2015, at 03:32 , Dan D <ddalthorp at usgs.gov> wrote:

> I have a tkwidget table (say, tbl1) that may be reconfigured at various times
> depending on user input. Is there an easy way to later extract table
> properties? Something like...
> 
> nrow<-tkgetproperties(tbl1, rows)
> 

More like

tkcget(tbl1, rows=NULL)


> Muchas thanks in advance.
> 
> -Dan
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/tcltk-table-properties-tp4713045.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Fri Oct  2 11:33:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 2 Oct 2015 05:33:48 -0400
Subject: [R] Counting number of rain
In-Reply-To: <560DFA37.6050801@auckland.ac.nz>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
	<560DDC73.9020405@auckland.ac.nz>
	<DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>
	<560DFA37.6050801@auckland.ac.nz>
Message-ID: <560E4F7C.9010707@gmail.com>

On 01/10/2015 11:29 PM, Rolf Turner wrote:
> On 02/10/15 15:47, David Winsemius wrote:
> 
> <SNIP>
> 
>> On Oct 1, 2015, at 6:22 PM, Rolf Turner wrote:
>>>
>>> P.S. I have been unable to find a corresponding vector of the names
>>> of the days of the week, although I have a very vague recollection
>>> of the existence of such a vector.  Does it exist, and if so what
>>> is it called?
>>
>> It's could called up by strptime because it is mapped to a character
>> vector by the internationalization database:
>>
>>> format( as.Date(1:7)+2, format="%A")
>> [1] "Sunday"    "Monday"    "Tuesday"   "Wednesday" "Thursday"
>> "Friday" [7] "Saturday"
> 
> <SNIP>
> 
> When I try that (copying and pasting your code so that there's no chance 
> of fumble-fingering) I get:
> 
>> Error in as.Date.numeric(1:7) : 'origin' must be supplied
> 
> Why do these things always happen to *me*???

The zoo package replaces as.Date.numeric() with a function that assumes
an origin of "1970-01-01".  There may be other packages that also make a
replacement like this.  David appears to have one of them attached, and
you don't.

Duncan Murdoch


From infojomy at gmail.com  Fri Oct  2 14:24:21 2015
From: infojomy at gmail.com (Jomy Jose)
Date: Fri, 2 Oct 2015 17:54:21 +0530
Subject: [R] Rayleigh Distribution
Message-ID: <CADGufDGQqJV+oh1uQeBLgE2nCWY4oOPvM3aPh4m40W-C8Q=-0A@mail.gmail.com>

Is it possible to code in R to get Q-Q plot for Rayleigh distribution

Jose

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Fri Oct  2 14:41:32 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 2 Oct 2015 12:41:32 +0000
Subject: [R] problem of Mahalanobis distance matching using MatchIT
Message-ID: <248E6FA047A8C746BA491485764190F522096402@ESESSMB207.ericsson.se>

About the "distance = NA" issue, please see if this comment helps:

https://lists.gking.harvard.edu/pipermail/matchit/2011-January/000174.html


Furthermore, the Mahalanobis NA distance values are hard-wired in the code, file matchit.R:

  ## no distance for full mahalanobis matching
  if(fn1=="distance2mahalanobis"){
    distance[1:length(distance)] <- NA
    class(out2) <- c("matchit.mahalanobis","matchit")
  }


About the resulting MDM matrix, I was able to create some "unmatching" by changing T1
so that its values do not always exactly map 1:1 to a pair of values each one taken
from the distribution values set control and treated (x1_.., x2_..).

n<-100
set.seed(1023)
x1_contr<-runif(n,0,5)
x2_contr<-runif(n,0,5)
x_contr<-cbind(x1=x1_contr,x2=x2_contr)
x1_treat<-runif(n,1,6)
x2_treat<-runif(n,1,6)

x_treat<-cbind(x1=x1_treat,x2=x2_treat)

T1<-c(rep(0,n/2),rep(1,3*n/2))

X.all<-rbind(x_contr,x_treat)

my.data<-data.frame(T1,X.all)
rownames(my.data)<-paste("ID",1:dim(my.data)[1])

library(MatchIt)
mdm.out<-matchit(T1~x1+x2,data=my.data, method="nearest", distance="mahalanobis",
                 mahvars=c("x1","x2"), caliper=0.15, replace=FALSE)

Sample sizes:
          Control Treated
All            50     150
Matched        50      50
Unmatched       0     100
Discarded       0       0


Hope this helps.

--

GG

	[[alternative HTML version deleted]]


From f.harrell at Vanderbilt.Edu  Fri Oct  2 14:50:03 2015
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Fri, 2 Oct 2015 07:50:03 -0500
Subject: [R] Help with improveProb function in Hmisc in R
Message-ID: <560E7D7B.8090207@vanderbilt.edu>

Please note that Kirsten is cross-posting to stats.stackexchange.com 
creating extra work for everyone.

-- 
------------------------------------------------------------------------
Frank E Harrell Jr 	Professor and Chairman 	School of Medicine

	Department of *Biostatistics* 	*Vanderbilt University*


	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Fri Oct  2 14:59:09 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 2 Oct 2015 12:59:09 +0000
Subject: [R] Rayleigh Distribution
Message-ID: <248E6FA047A8C746BA491485764190F522096422@ESESSMB207.ericsson.se>

Similarly to what can be read on help(qqplot), however using Rayleigh distribution:

library(VGAM)
p <- ppoints(100)
x <- qrayleigh(p)
y <- rrayleigh(100)
qqplot(x,y)
qqline(y, distribution = function(p) qrayleigh(p),
       prob = c(0.1, 0.6), col = 2)

--
GG

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Oct  2 15:54:52 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 2 Oct 2015 09:54:52 -0400
Subject: [R] Rayleigh Distribution
In-Reply-To: <CADGufDGQqJV+oh1uQeBLgE2nCWY4oOPvM3aPh4m40W-C8Q=-0A@mail.gmail.com>
References: <CADGufDGQqJV+oh1uQeBLgE2nCWY4oOPvM3aPh4m40W-C8Q=-0A@mail.gmail.com>
Message-ID: <560E8CAC.1060700@gmail.com>

On 02/10/2015 8:24 AM, Jomy Jose wrote:
> Is it possible to code in R to get Q-Q plot for Rayleigh distribution

If you have a quantile function for any distribution, you can make a QQ
plot using ppoints() and the quantile function.

The Rayleigh distribution isn't in base R, but Google says it is in the
VGAM, lmomco, reliaR, etc. packages.  Pick one of those, e.g. VGAM,
which calls the quantile function "qrayleigh".  Then if you have a
sample x and want to compare to Rayleigh with scale 1, you do

library(VGAM)
qqplot(qrayleigh(ppoints(length(x))), x)


Duncan Murdoch


From dwinsemius at comcast.net  Fri Oct  2 17:42:29 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 2 Oct 2015 08:42:29 -0700
Subject: [R] Counting number of rain
In-Reply-To: <560E4F7C.9010707@gmail.com>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
	<560DDC73.9020405@auckland.ac.nz>
	<DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>
	<560DFA37.6050801@auckland.ac.nz> <560E4F7C.9010707@gmail.com>
Message-ID: <EBFFE570-F1E0-42AF-8C7A-8BE513F9B57A@comcast.net>


On Oct 2, 2015, at 2:33 AM, Duncan Murdoch wrote:

> On 01/10/2015 11:29 PM, Rolf Turner wrote:
>> On 02/10/15 15:47, David Winsemius wrote:
>> 
>> <SNIP>
>> 
>>> On Oct 1, 2015, at 6:22 PM, Rolf Turner wrote:
>>>> 
>>>> P.S. I have been unable to find a corresponding vector of the names
>>>> of the days of the week, although I have a very vague recollection
>>>> of the existence of such a vector.  Does it exist, and if so what
>>>> is it called?
>>> 
>>> It's could called up by strptime because it is mapped to a character
>>> vector by the internationalization database:
>>> 
>>>> format( as.Date(1:7)+2, format="%A")
>>> [1] "Sunday"    "Monday"    "Tuesday"   "Wednesday" "Thursday"
>>> "Friday" [7] "Saturday"
>> 
>> <SNIP>
>> 
>> When I try that (copying and pasting your code so that there's no chance 
>> of fumble-fingering) I get:
>> 
>>> Error in as.Date.numeric(1:7) : 'origin' must be supplied
>> 
>> Why do these things always happen to *me*???
> 
> The zoo package replaces as.Date.numeric() with a function that assumes
> an origin of "1970-01-01".  There may be other packages that also make a
> replacement like this.  David appears to have one of them attached, and
> you don't.

Quite right, Duncan. I failed to include the <environment: namespace:zoo> even though it was staring me in the face. My wife says I have an extreme case of "refrigerator blindness" which now seems to be spreading to other areas of my cognitive activities.

Sorry, Rolf.
-- 
David.

> 
> Duncan Murdoch
> 

David Winsemius
Alameda, CA, USA


From infojomy at gmail.com  Fri Oct  2 17:45:58 2015
From: infojomy at gmail.com (Jomy Jose)
Date: Fri, 2 Oct 2015 21:15:58 +0530
Subject: [R] Rayleigh Distribution
Message-ID: <CADGufDFVjx15L8D=hk4bPbEMy3t6S3aywj-mim2egJcF+O+psg@mail.gmail.com>

Thank you,how to add correct reference line to this Rayleigh Q-Q plot.

Jose

	[[alternative HTML version deleted]]


From kirsada at hotmail.com  Fri Oct  2 09:02:49 2015
From: kirsada at hotmail.com (kirsada)
Date: Fri, 2 Oct 2015 00:02:49 -0700 (PDT)
Subject: [R] Help with improveProb function in Hmisc in R
In-Reply-To: <3701E28C-BE67-40C7-979A-249667C230B1@comcast.net>
References: <1443691599854-4713004.post@n4.nabble.com>
	<3701E28C-BE67-40C7-979A-249667C230B1@comcast.net>
Message-ID: <1443769369929-4713053.post@n4.nabble.com>

Hi David,

Thanks for your response. I have discovered that my first and second models
differed in length, and have since fixed them.

Kirsten



--
View this message in context: http://r.789695.n4.nabble.com/Help-with-improveProb-function-in-Hmisc-in-R-tp4713004p4713053.html
Sent from the R help mailing list archive at Nabble.com.


From infojomy at gmail.com  Fri Oct  2 18:40:47 2015
From: infojomy at gmail.com (Jomy Jose)
Date: Fri, 2 Oct 2015 22:10:47 +0530
Subject: [R] Q-Q plot reference line
Message-ID: <CADGufDHZMNr3iROpsqTZVWcMupTnfdPUvGF8h9WA=K73KNUZcg@mail.gmail.com>

How can the reference line be  drawn for various distributions like
Rayleigh and Log logistic Q-Q plots.

Thanks
Jomy

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct  2 19:08:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 02 Oct 2015 10:08:37 -0700
Subject: [R] Q-Q plot reference line
In-Reply-To: <CADGufDHZMNr3iROpsqTZVWcMupTnfdPUvGF8h9WA=K73KNUZcg@mail.gmail.com>
References: <CADGufDHZMNr3iROpsqTZVWcMupTnfdPUvGF8h9WA=K73KNUZcg@mail.gmail.com>
Message-ID: <40C476D7-E013-471C-9384-5AA348858530@dcn.davis.CA.us>

You sound sad, lost and wandering about in the wilderness. Fortunately there is help for you in the Posting Guide (mentioned at the bottom of every email on this list), which advises you to keep replying on the same thread of emails as long as the topic has not changed, post using plain text rather than using HTML format, including context from the preceding thread to remind readers who don't have the whole thread to refer to, and provide a reproducible example showing how much progress you have made so far.

To that I will add that there are explanations online about what a reproducible example is. [1]. Did you read Duncan Murdoch's response in your previous thread? Can you demonstrate what is not sufficient about that with an example?

Finally, one definition of insanity is trying to solve a problem by repeating the same strategy that did not work the last time... in this case, sending essentially the same ineffective email to the list multiple times in rapid succession. I hope you get better soon.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 2, 2015 9:40:47 AM PDT, Jomy Jose <infojomy at gmail.com> wrote:
>How can the reference line be  drawn for various distributions like
>Rayleigh and Log logistic Q-Q plots.
>
>Thanks
>Jomy
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From holtermann at hwwi.org  Fri Oct  2 21:31:07 2015
From: holtermann at hwwi.org (Linus Holtermann)
Date: Fri, 2 Oct 2015 19:31:07 +0000
Subject: [R] Regressing the residuals on the country dummies
In-Reply-To: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
References: <776A2CBA-3D1B-4A99-B455-C23F06D5345A@gmail.com>
Message-ID: <2fceb07ed4414d0c96462f26bc41e192@winhexbeeu15.win.mail>

Hi,

You have panel data or cross-sectional data? In the case you use cross-sectional data and "countries" are your observations (no repeated measure of them) and you regress the country-dummies on your residuals of the forgone regression, then there are as many regressors as observations. Consequently, is it not possible to estimate such a model since there are no degrees of freedom left.

Mit freundlichen Gr??en


Linus Holtermann
Hamburgisches WeltWirtschaftsInstitut gemeinn?tzige GmbH (HWWI)
Heimhuder Stra?e 71
20148 Hamburg
Tel +49-(0)40-340576-336
Fax+49-(0)40-340576-776
Internet: www.hwwi.org
Email: holtermann at hwwi.org
?
Amtsgericht Hamburg HRB 94303
Gesch?ftsf?hrer: Prof. Dr. Henning V?pel
Prokura: Dipl. Kauffrau Alexis Malchin
Umsatzsteuer-ID: DE 241849425


-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Johanna von Bahr
Gesendet: Donnerstag, 1. Oktober 2015 21:15
An: r-help at r-project.org
Betreff: [R] Regressing the residuals on the country dummies

I?m trying to estimate a model regressing the residuals on the country dummies as follows; model.resC <- lm(model2$res ~ as.factor(Country))
summary(model.resC)

As I call the model I get the following results regarding the residuals:

"ALL 90 residuals are 0: no residual degrees of freedom!"

What has gone wrong?
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From johannes at huesing.name  Fri Oct  2 22:09:10 2015
From: johannes at huesing.name (Johannes Huesing)
Date: Fri, 2 Oct 2015 22:09:10 +0200
Subject: [R] Rayleigh Distribution
In-Reply-To: <CADGufDFVjx15L8D=hk4bPbEMy3t6S3aywj-mim2egJcF+O+psg@mail.gmail.com>
References: <CADGufDFVjx15L8D=hk4bPbEMy3t6S3aywj-mim2egJcF+O+psg@mail.gmail.com>
Message-ID: <20151002200910.GA32445@huesing.name>

Jomy Jose <infojomy at gmail.com> [Fri, Oct 02, 2015 at 05:45:58PM CEST]:
>Thank you,how to add correct reference line to this Rayleigh Q-Q plot.

?abline

-- 
Johannes H?sing               
http://derwisch.wikidot.com
Threema-ID: VHVJYH3H


From r.turner at auckland.ac.nz  Fri Oct  2 22:28:17 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 3 Oct 2015 09:28:17 +1300
Subject: [R] Q-Q plot reference line
In-Reply-To: <40C476D7-E013-471C-9384-5AA348858530@dcn.davis.CA.us>
References: <CADGufDHZMNr3iROpsqTZVWcMupTnfdPUvGF8h9WA=K73KNUZcg@mail.gmail.com>
	<40C476D7-E013-471C-9384-5AA348858530@dcn.davis.CA.us>
Message-ID: <560EE8E1.3010303@auckland.ac.nz>

On 03/10/15 06:08, Jeff Newmiller wrote:

<SNIP>

> Finally, one definition of insanity is trying to solve a problem by
> repeating the same strategy that did not work the last time... in
> this case, sending essentially the same ineffective email to the list
> multiple times in rapid succession. I hope you get better soon.


Fortune!!!

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From r.turner at auckland.ac.nz  Fri Oct  2 22:39:17 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 3 Oct 2015 09:39:17 +1300
Subject: [R] Counting number of rain
In-Reply-To: <EBFFE570-F1E0-42AF-8C7A-8BE513F9B57A@comcast.net>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6BE78D@mb02.ads.tamu.edu>
	<1737132018.3770305.1443666232222.JavaMail.yahoo@mail.yahoo.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6C991F@mb02.ads.tamu.edu>
	<560D9FFB.6090001@auckland.ac.nz>
	<BD29FE8A-8091-4D21-822A-DFD6522281FF@gmail.com>
	<560DDC73.9020405@auckland.ac.nz>
	<DFABDCEA-8908-4CF1-9268-C6D34C9EAD20@comcast.net>
	<560DFA37.6050801@auckland.ac.nz> <560E4F7C.9010707@gmail.com>
	<EBFFE570-F1E0-42AF-8C7A-8BE513F9B57A@comcast.net>
Message-ID: <560EEB75.3000402@auckland.ac.nz>

On 03/10/15 04:42, David Winsemius wrote:
>
> On Oct 2, 2015, at 2:33 AM, Duncan Murdoch wrote:

<SNIP>

>> The zoo package replaces as.Date.numeric() with a function that
>> assumes an origin of "1970-01-01".  There may be other packages
>> that also make a replacement like this.  David appears to have one
>> of them attached, and you don't.
>
> Quite right, Duncan. I failed to include the <environment:
> namespace:zoo> even though it was staring me in the face. My wife
> says I have an extreme case of "refrigerator blindness" which now
> seems to be spreading to other areas of my cognitive activities.
>
> Sorry, Rolf.

Quite alright.  The syndrome is *very* familiar to me! :-)

cheers,

Rolf



-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From jonathanreardon at outlook.com  Fri Oct  2 18:26:11 2015
From: jonathanreardon at outlook.com (Jon1985)
Date: Fri, 2 Oct 2015 09:26:11 -0700 (PDT)
Subject: [R] Adding a decimal point at the second mark in R
Message-ID: <1443803171471-4713069.post@n4.nabble.com>

Using R, I have two columns (onset, duration) containing milliseconds in a
data frame. I want to add a decimal point at the second mark for all data
points in both columns i.e. turning 1541ms into 1.541s AND turning 638ms
into 0.638s.

Could someone tell me how to do this? 

Thanks
Jon



--
View this message in context: http://r.789695.n4.nabble.com/Adding-a-decimal-point-at-the-second-mark-in-R-tp4713069.html
Sent from the R help mailing list archive at Nabble.com.


From noel.hunt at gmail.com  Fri Oct  2 23:39:33 2015
From: noel.hunt at gmail.com (Noel Hunt)
Date: Sat, 3 Oct 2015 07:39:33 +1000
Subject: [R] Package compilation errors
Message-ID: <CAGfO01yR=ZgbYi84=q0Zp9FD8GQbktnh9puWW_yYfFpkmxCvWw@mail.gmail.com>

I have a few packages for which compilation has
failed. The errors are simple compile-time errors
I could fix if the configured source was left
untouched and not removed.

I have found out how to stop source being removed
but I want the whole set of extracted, configured files
left, so I can fix the errors and restart the
installation.

I haven't found out how to do this; is it possible?

	[[alternative HTML version deleted]]


From patrick-breheny at uiowa.edu  Fri Oct  2 23:51:56 2015
From: patrick-breheny at uiowa.edu (Patrick Breheny)
Date: Fri, 2 Oct 2015 16:51:56 -0500
Subject: [R] John M. Chambers Statistical Software Award
Message-ID: <560EFC7C.50604@uiowa.edu>

John M. Chambers Statistical Software Award 2016

The Statistical Computing Section of the American Statistical 
Association announces the competition for the John M. Chambers 
Statistical Software Award. In 1998 the Association for Computing 
Machinery presented its Software System Award to John Chambers for the 
design and development of S. Dr. Chambers generously donated his award 
to the Statistical Computing Section to endow an annual prize for 
statistical software written by, or in collaboration with, an 
undergraduate or graduate student. The prize carries with it a cash 
award of $1,000.

Teams of up to 3 people can participate in the competition. To be 
eligible, the team must have designed and implemented a piece of 
statistical software. At least one individual within the team must have 
begun the development while a student and must either currently be a 
student, or have completed all requirements for her/his last degree 
after January 1, 2015. The award will be given to the student, or split 
between student team members if the team consists of multiple students.

To apply for the award, teams must provide the following materials:

* Current CV's of all team members.

* A letter from a faculty mentor at the academic institution of the 
individual indicated to receive the travel award. The letter should 
confirm that the individual had substantial participation in the 
development of the software, certify her/his student status when the 
software began to be developed (and either the current student status or 
the date of degree completion), and briefly discuss the importance of 
the software to statistical practice.

* A brief, one to two page description of the software, summarizing what 
it does, how it does it, and why it is an important contribution. If any 
student team member has continued developing the software after 
finishing her/his studies, the description should indicate what was 
developed when the individual was a student and what has been added since.

* An installable software package with its source code for use by the 
award committee. It should be accompanied by enough information to allow 
the judges to effectively use and evaluate the software (including its 
design considerations). This information can be provided in a variety of 
ways, including but not limited to a user manual, a manuscript, a URL, 
and online help to the system.

All materials must be in English. We prefer that electronic text be 
submitted in Postscript or PDF. The entries will be judged on a variety 
of dimensions, including the importance and relevance for statistical 
practice of the tasks performed by the software, ease of use, clarity of 
description, elegance and availability for use by the statistical 
community. Preference will be given to those entries that are grounded 
in software design rather than calculation. The decision of the award 
committee is final.

All application materials must be received by Tuesday, December 15, 2015 
and should be sent to the e-mail address below.  The winner will be 
announced by January 15.  The award will be presented at the 2016 Joint 
Statistical Meetings, and the winner(s) will be given an opportunity to 
present their work in a topic-contributed session at the meetings.

Patrick Breheny
Department of Biostatistics
University of Iowa
patrick-breheny at uiowa.edu

-- 
Patrick Breheny
Assistant Professor
Department of Biostatistics
University of Iowa
N336 College of Public Health Building
319-384-1584


From r.turner at auckland.ac.nz  Sat Oct  3 01:21:40 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 3 Oct 2015 12:21:40 +1300
Subject: [R] Adding a decimal point at the second mark in R
In-Reply-To: <1443803171471-4713069.post@n4.nabble.com>
References: <1443803171471-4713069.post@n4.nabble.com>
Message-ID: <560F1184.60804@auckland.ac.nz>


On 03/10/15 05:26, Jon1985 wrote:

> Using R, I have two columns (onset, duration) containing milliseconds in a
> data frame. I want to add a decimal point at the second mark for all data
> points in both columns i.e. turning 1541ms into 1.541s AND turning 638ms
> into 0.638s.
>
> Could someone tell me how to do this?

How about

    X$onset    <- X$onset/1000
    X$duration <- X$duration/1000

???

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From damicogreg78 at gmail.com  Sat Oct  3 01:09:26 2015
From: damicogreg78 at gmail.com (Greg Damico)
Date: Fri, 2 Oct 2015 16:09:26 -0700
Subject: [R] "split" and loop functions
Message-ID: <CANzuictxyWNAmPN4_cinO1Rh2_RZswUMnp4EU8kDfYLnE8JEMw@mail.gmail.com>

Hello,

I wonder if you might be able to help me.  I'm enrolled in an R programming
course through Coursera.  I've done well so far--though it's been
challenging!--but I'm having trouble understanding exactly how "split" and
the loop functions (like "lapply") work.

I keep getting an error that says:  "group length is 0 but data length >0",
and I'm not sure what that means.  "Group" refers, I suppose, to the
factor-individuated bits I create through "split", but then I don't see why
that should be 0....

I'm trying to split a data frame into pieces and then isolate the nth
(user-inputted) row of each bit.  So I've been trying code like:

s2<-split(s1, s1$State, drop = TRUE)
ans<-as.data.frame(lapply(s2, function(elt) elt[as.numeric(num),c(1,2)])),

where s1 is the pre-arranged data frame (and the "State" column is
inherited from the unarranged data frame).  Maybe there's something wrong
(or illicit) in my anonymous function?

I'd appreciate any help you can give me.

Greg Damico

	[[alternative HTML version deleted]]


From climberjeff at gmail.com  Sat Oct  3 01:34:19 2015
From: climberjeff at gmail.com (Jeff Tostenrude)
Date: Fri, 2 Oct 2015 16:34:19 -0700
Subject: [R] scatter3d
Message-ID: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>

I am using scatter3d in R Commander to plot a group of regression surfaces.
However, I only want to display the surfaces. How do I remove the points?

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Sat Oct  3 02:22:15 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 3 Oct 2015 00:22:15 +0000
Subject: [R] scatter3d
In-Reply-To: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>

Dear Jeff,

I'm tempted to say that a scatterplot without points is an oxymoron, but that wouldn't be very helpful.

Actually, the scatter3d() function used by the Rcmdr is in the car package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing the points, but if you add radius=rep(0, n) to the command that's generated, where you'd replace n with the number of cases in the dataset, that would do the trick by plotting spheres of 0 radius. For example, try

	scatter3d(prestige ~ income + education, data=Duncan, radius=rep(0, 45), residuals=FALSE)

either in the Rcmdr or at the R command prompt.

For more information see ?scatter3d or press the Help button in the Rcmdr 3D scatterplot dialog and follow the link to scatter3d.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> Tostenrude
> Sent: October 2, 2015 7:34 PM
> To: r-help at r-project.org
> Subject: [R] scatter3d
> 
> I am using scatter3d in R Commander to plot a group of regression surfaces.
> However, I only want to display the surfaces. How do I remove the points?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sat Oct  3 02:23:10 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 2 Oct 2015 17:23:10 -0700
Subject: [R] "split" and loop functions
In-Reply-To: <CANzuictxyWNAmPN4_cinO1Rh2_RZswUMnp4EU8kDfYLnE8JEMw@mail.gmail.com>
References: <CANzuictxyWNAmPN4_cinO1Rh2_RZswUMnp4EU8kDfYLnE8JEMw@mail.gmail.com>
Message-ID: <CAF8bMcZtszXXgPe3J5R_MXbPAedadGXCB4PD833gubzeb34AgA@mail.gmail.com>

You should really be asking Coursera for help with its course.
However you can figure this out by breaking down your commands
into small steps and seeing what each step gives.   This is an advantage
of an interactive system like R.  E.g., suppose you start with
  > s1 <- data.frame(state=c("Rhode Island","Rhode Island","Montana"),
x=c(1,2,3))
  > s2 <- split(s1, s1$State)
Error in split.default(x = seq_len(nrow(x)), f = f, drop = drop, ...) :
  group length is 0 but data length > 0
Do not proceed to compute something that depends on s2 if there
was an error computing s2, but look at the arguments you gave to
split when trying to compute s2:
  > s1
           state x
  1 Rhode Island 1
  2 Rhode Island 2
  3      Montana 3
  > s1$State
  NULL
  > length(s1$State)
  [1] 0
That length 0 object, s1$State, that you gave as the group argument
to split, would cause that error message.  Fix the s1$State and you
can procede.


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 2, 2015 at 4:09 PM, Greg Damico <damicogreg78 at gmail.com> wrote:
> Hello,
>
> I wonder if you might be able to help me.  I'm enrolled in an R programming
> course through Coursera.  I've done well so far--though it's been
> challenging!--but I'm having trouble understanding exactly how "split" and
> the loop functions (like "lapply") work.
>
> I keep getting an error that says:  "group length is 0 but data length >0",
> and I'm not sure what that means.  "Group" refers, I suppose, to the
> factor-individuated bits I create through "split", but then I don't see why
> that should be 0....
>
> I'm trying to split a data frame into pieces and then isolate the nth
> (user-inputted) row of each bit.  So I've been trying code like:
>
> s2<-split(s1, s1$State, drop = TRUE)
> ans<-as.data.frame(lapply(s2, function(elt) elt[as.numeric(num),c(1,2)])),
>
> where s1 is the pre-arranged data frame (and the "State" column is
> inherited from the unarranged data frame).  Maybe there's something wrong
> (or illicit) in my anonymous function?
>
> I'd appreciate any help you can give me.
>
> Greg Damico
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Oct  3 02:26:45 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 02 Oct 2015 17:26:45 -0700
Subject: [R] scatter3d
In-Reply-To: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
Message-ID: <EE3B1F5E-A279-48CE-BBDA-847539B4F650@dcn.davis.CA.us>

Wouldn't you just stop using scatter3d?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 2, 2015 4:34:19 PM PDT, Jeff Tostenrude <climberjeff at gmail.com> wrote:
>I am using scatter3d in R Commander to plot a group of regression
>surfaces.
>However, I only want to display the surfaces. How do I remove the
>points?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Oct  3 02:51:55 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 02 Oct 2015 17:51:55 -0700
Subject: [R] Package compilation errors
In-Reply-To: <CAGfO01yR=ZgbYi84=q0Zp9FD8GQbktnh9puWW_yYfFpkmxCvWw@mail.gmail.com>
References: <CAGfO01yR=ZgbYi84=q0Zp9FD8GQbktnh9puWW_yYfFpkmxCvWw@mail.gmail.com>
Message-ID: <110F28CD-FB5D-4137-B679-CA98779AC2C0@dcn.davis.CA.us>

No, don't get in the way of install.packages(). Download the source versions of the packages and unpack them yourself and fix the source files and update the DESCRIPTION files. Then follow the instructions in the "Writing R Extensions" document at the command line (I.e. R CMD check, R CMD build, etc.) to rebuild/reinstall each package. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 2, 2015 2:39:33 PM PDT, Noel Hunt <noel.hunt at gmail.com> wrote:
>I have a few packages for which compilation has
>failed. The errors are simple compile-time errors
>I could fix if the configured source was left
>untouched and not removed.
>
>I have found out how to stop source being removed
>but I want the whole set of extracted, configured files
>left, so I can fix the errors and restart the
>installation.
>
>I haven't found out how to do this; is it possible?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From climberjeff at gmail.com  Sat Oct  3 05:45:37 2015
From: climberjeff at gmail.com (Jeff Tostenrude)
Date: Fri, 2 Oct 2015 20:45:37 -0700
Subject: [R] scatter3d
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>

Thank you for the suggestion. Yes, it does seem to be a bit
counter-intuitive, but that is the output I am being asked to produce. I
have only been using R for a few weeks, so there is probably a better way
to do it.

Anyway, your suggestion did work, but only up to 337 data points. I am
dealing with ~100,000 data points so this doesn't really work for me. Is
there another method you would suggest? My goal is to plot multiple
regression planes (without points) in an interactive 3d plot.

Thank you,
Jeff

On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Jeff,
>
> I'm tempted to say that a scatterplot without points is an oxymoron, but
> that wouldn't be very helpful.
>
> Actually, the scatter3d() function used by the Rcmdr is in the car
> package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing
> the points, but if you add radius=rep(0, n) to the command that's
> generated, where you'd replace n with the number of cases in the dataset,
> that would do the trick by plotting spheres of 0 radius. For example, try
>
>         scatter3d(prestige ~ income + education, data=Duncan,
> radius=rep(0, 45), residuals=FALSE)
>
> either in the Rcmdr or at the R command prompt.
>
> For more information see ?scatter3d or press the Help button in the Rcmdr
> 3D scatterplot dialog and follow the link to scatter3d.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> > Tostenrude
> > Sent: October 2, 2015 7:34 PM
> > To: r-help at r-project.org
> > Subject: [R] scatter3d
> >
> > I am using scatter3d in R Commander to plot a group of regression
> surfaces.
> > However, I only want to display the surfaces. How do I remove the points?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From matteo.richiardi at gmail.com  Sat Oct  3 10:16:49 2015
From: matteo.richiardi at gmail.com (Matteo Richiardi)
Date: Sat, 3 Oct 2015 09:16:49 +0100
Subject: [R] denstrip package: densregion when density is not provided
Message-ID: <CABSrU1J5L3-OdWH6NKx4VYuCaKS9gRmamG8cD2cvneWvH6-X-Q@mail.gmail.com>

I have several estimated time series, running from 2013 to 2050. 'y' values
are constrained between 0 and 1. I would like to plot them using shaded
colours of decreasing intensity, depending on an estimated density at each
point x in 2013-2050.

This is what I have done:

require(denstrip)
x <- 2013:2015
y <- seq(0, 1, length=100)
z <- read.delim("clipboard")
densregion(x, y, z)

where I imported 'z' from MS Excel. 'z' looks like (I copied only the first
2 columns, l but I have 100 of them):

        run1      run2
1  0.6932324 0.7732179
2  0.6773456 0.7971804
...
37 0.7260790 0.8724961
38 0.7290335 0.8755433

I get the following error message:
Error in `[.data.frame`(x, order(x, na.last = na.last, decreasing =
decreasing)) :
  undefined columns selected

Could anybody please help me with fixing this? Thanks in advance

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Sat Oct  3 10:47:21 2015
From: syen04 at gmail.com (Steven Yen)
Date: Sat, 3 Oct 2015 04:47:21 -0400
Subject: [R] Calling external file
Message-ID: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>

Hi
I collect a list of calls to a package in a function (routine) so that I do
not need to repeat the same sets of codes from program to program. In the
following, inserting the function into each program works. Then, I place
the function elsewhere in a PC folder, and include in with a 'source'
command. This does not work; it complains about a function (fn below) not
defined.
Compiling the function into a library file does not work either (with all
sorts of error messages saying this and that not defined).
Steven Yen

fn <- function(beta){
  f<-... (define f in this routine)
return(f)
}

max.calls<-function(method){
# *******************************************************
# Call maxLike with alternative algorithms
# *******************************************************
  many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
  if (method %in% many){
    ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
               method,print.level,constraints=NULL, ...)}
return(ML)
}
# This works:
ML<-max.calls(method)

# Does not work:
source("z:\\R\\yenlib\\lib\\max.calls.R")
ML<-max.calls(method)

Error: object 'fn' not found

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Oct  3 12:18:02 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 3 Oct 2015 12:18:02 +0200
Subject: [R] scatter3d
In-Reply-To: <CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
Message-ID: <560FAB5A.3060602@statistik.tu-dortmund.de>

On 03.10.2015 05:45, Jeff Tostenrude wrote:
> Thank you for the suggestion. Yes, it does seem to be a bit
> counter-intuitive, but that is the output I am being asked to produce. I
> have only been using R for a few weeks, so there is probably a better way
> to do it.
>
> Anyway, your suggestion did work, but only up to 337 data points. I am
> dealing with ~100,000 data points so this doesn't really work for me. Is
> there another method you would suggest? My goal is to plot multiple
> regression planes (without points) in an interactive 3d plot.

What does "interactive" mean here? Do you want to turnit around or do 
you want brushing like interactivity?

For the former, I highly suggest to look at the rgl package

Best,
Uwe Ligges


> Thank you,
> Jeff
>
> On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca> wrote:
>
>> Dear Jeff,
>>
>> I'm tempted to say that a scatterplot without points is an oxymoron, but
>> that wouldn't be very helpful.
>>
>> Actually, the scatter3d() function used by the Rcmdr is in the car
>> package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing
>> the points, but if you add radius=rep(0, n) to the command that's
>> generated, where you'd replace n with the number of cases in the dataset,
>> that would do the trick by plotting spheres of 0 radius. For example, try
>>
>>          scatter3d(prestige ~ income + education, data=Duncan,
>> radius=rep(0, 45), residuals=FALSE)
>>
>> either in the Rcmdr or at the R command prompt.
>>
>> For more information see ?scatter3d or press the Help button in the Rcmdr
>> 3D scatterplot dialog and follow the link to scatter3d.
>>
>> I hope this helps,
>>   John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
>>> Tostenrude
>>> Sent: October 2, 2015 7:34 PM
>>> To: r-help at r-project.org
>>> Subject: [R] scatter3d
>>>
>>> I am using scatter3d in R Commander to plot a group of regression
>> surfaces.
>>> However, I only want to display the surfaces. How do I remove the points?
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Sat Oct  3 13:52:24 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 3 Oct 2015 07:52:24 -0400
Subject: [R] scatter3d
In-Reply-To: <CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
Message-ID: <560FC178.1010100@gmail.com>

On 02/10/2015 11:45 PM, Jeff Tostenrude wrote:
> Thank you for the suggestion. Yes, it does seem to be a bit
> counter-intuitive, but that is the output I am being asked to produce. I
> have only been using R for a few weeks, so there is probably a better way
> to do it.
> 
> Anyway, your suggestion did work, but only up to 337 data points. I am
> dealing with ~100,000 data points so this doesn't really work for me. Is
> there another method you would suggest? My goal is to plot multiple
> regression planes (without points) in an interactive 3d plot.

The problem there would be that 100000 spheres will overwhelm the
graphics system, even if they are of size zero.

The ?planes3d help page shows how to plot a plane based on a linear fit.
 It won't include the grid that scatter3d includes; you would need to
program that separately.  You should avoid using the rgl.lines and
rgl.quads calls that scatter3d uses; you're better off with lines3d and
quads3d.

If you don't include any points, you'll need to specify the range of the
axes explicitly --- use the xlim, ylim and zlim arguments to decorate3d
to do that.

Duncan Murdoch

> 
> Thank you,
> Jeff
> 
> On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca> wrote:
> 
>> Dear Jeff,
>>
>> I'm tempted to say that a scatterplot without points is an oxymoron, but
>> that wouldn't be very helpful.
>>
>> Actually, the scatter3d() function used by the Rcmdr is in the car
>> package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing
>> the points, but if you add radius=rep(0, n) to the command that's
>> generated, where you'd replace n with the number of cases in the dataset,
>> that would do the trick by plotting spheres of 0 radius. For example, try
>>
>>         scatter3d(prestige ~ income + education, data=Duncan,
>> radius=rep(0, 45), residuals=FALSE)
>>
>> either in the Rcmdr or at the R command prompt.
>>
>> For more information see ?scatter3d or press the Help button in the Rcmdr
>> 3D scatterplot dialog and follow the link to scatter3d.
>>
>> I hope this helps,
>>  John
>>
>> -----------------------------
>> John Fox, Professor
>> McMaster University
>> Hamilton, Ontario
>> Canada L8S 4M4
>> Web: socserv.mcmaster.ca/jfox
>>
>>
>>
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
>>> Tostenrude
>>> Sent: October 2, 2015 7:34 PM
>>> To: r-help at r-project.org
>>> Subject: [R] scatter3d
>>>
>>> I am using scatter3d in R Commander to plot a group of regression
>> surfaces.
>>> However, I only want to display the surfaces. How do I remove the points?
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ligges at statistik.tu-dortmund.de  Sat Oct  3 14:36:19 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 3 Oct 2015 14:36:19 +0200
Subject: [R] scatter3d
In-Reply-To: <560FC178.1010100@gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
	<560FC178.1010100@gmail.com>
Message-ID: <560FCBC3.90506@statistik.tu-dortmund.de>

Oh yes, I meant for plotting planes, not points, of course.

Uwe


On 03.10.2015 13:52, Duncan Murdoch wrote:
> On 02/10/2015 11:45 PM, Jeff Tostenrude wrote:
>> Thank you for the suggestion. Yes, it does seem to be a bit
>> counter-intuitive, but that is the output I am being asked to produce. I
>> have only been using R for a few weeks, so there is probably a better way
>> to do it.
>>
>> Anyway, your suggestion did work, but only up to 337 data points. I am
>> dealing with ~100,000 data points so this doesn't really work for me. Is
>> there another method you would suggest? My goal is to plot multiple
>> regression planes (without points) in an interactive 3d plot.
>
> The problem there would be that 100000 spheres will overwhelm the
> graphics system, even if they are of size zero.
>
> The ?planes3d help page shows how to plot a plane based on a linear fit.
>   It won't include the grid that scatter3d includes; you would need to
> program that separately.  You should avoid using the rgl.lines and
> rgl.quads calls that scatter3d uses; you're better off with lines3d and
> quads3d.
>
> If you don't include any points, you'll need to specify the range of the
> axes explicitly --- use the xlim, ylim and zlim arguments to decorate3d
> to do that.
>
> Duncan Murdoch
>
>>
>> Thank you,
>> Jeff
>>
>> On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca> wrote:
>>
>>> Dear Jeff,
>>>
>>> I'm tempted to say that a scatterplot without points is an oxymoron, but
>>> that wouldn't be very helpful.
>>>
>>> Actually, the scatter3d() function used by the Rcmdr is in the car
>>> package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing
>>> the points, but if you add radius=rep(0, n) to the command that's
>>> generated, where you'd replace n with the number of cases in the dataset,
>>> that would do the trick by plotting spheres of 0 radius. For example, try
>>>
>>>          scatter3d(prestige ~ income + education, data=Duncan,
>>> radius=rep(0, 45), residuals=FALSE)
>>>
>>> either in the Rcmdr or at the R command prompt.
>>>
>>> For more information see ?scatter3d or press the Help button in the Rcmdr
>>> 3D scatterplot dialog and follow the link to scatter3d.
>>>
>>> I hope this helps,
>>>   John
>>>
>>> -----------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario
>>> Canada L8S 4M4
>>> Web: socserv.mcmaster.ca/jfox
>>>
>>>
>>>
>>>> -----Original Message-----
>>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
>>>> Tostenrude
>>>> Sent: October 2, 2015 7:34 PM
>>>> To: r-help at r-project.org
>>>> Subject: [R] scatter3d
>>>>
>>>> I am using scatter3d in R Commander to plot a group of regression
>>> surfaces.
>>>> However, I only want to display the surfaces. How do I remove the points?
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lists at dewey.myzen.co.uk  Sat Oct  3 14:47:01 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sat, 3 Oct 2015 13:47:01 +0100
Subject: [R] Calling external file
In-Reply-To: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
References: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
Message-ID: <560FCE45.8040909@dewey.myzen.co.uk>

You did put the declaration of the function fn into the file you are 
sourcing, didn't you?

If it were me I would
1 - make fn a parameter of max.calls
2 - use the ellipsis ... so I could pass other arguments in to MaxLike
3 - fix the errors I got from making it a package. It does not lie when 
it tells you things are undefined and, who knows, they may need to be 
defined.

On 03/10/2015 09:47, Steven Yen wrote:
> Hi
> I collect a list of calls to a package in a function (routine) so that I do
> not need to repeat the same sets of codes from program to program. In the
> following, inserting the function into each program works. Then, I place
> the function elsewhere in a PC folder, and include in with a 'source'
> command. This does not work; it complains about a function (fn below) not
> defined.
> Compiling the function into a library file does not work either (with all
> sorts of error messages saying this and that not defined).
> Steven Yen
>
> fn <- function(beta){
>    f<-... (define f in this routine)
> return(f)
> }
>
> max.calls<-function(method){
> # *******************************************************
> # Call maxLike with alternative algorithms
> # *******************************************************
>    many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
>    if (method %in% many){
>      ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
>                 method,print.level,constraints=NULL, ...)}
> return(ML)
> }
> # This works:
> ML<-max.calls(method)
>
> # Does not work:
> source("z:\\R\\yenlib\\lib\\max.calls.R")
> ML<-max.calls(method)
>
> Error: object 'fn' not found
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From jfox at mcmaster.ca  Sat Oct  3 16:07:13 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 3 Oct 2015 14:07:13 +0000
Subject: [R] scatter3d
In-Reply-To: <CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F2B5A4@FHSDB2D11-2.csu.mcmaster.ca>

Dear Jeff,

> -----Original Message-----
> From: Jeff Tostenrude [mailto:climberjeff at gmail.com]
> Sent: October 2, 2015 11:46 PM
> To: Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org
> Subject: Re: [R] scatter3d
> 
> Thank you for the suggestion. Yes, it does seem to be a bit counter-intuitive, but
> that is the output I am being asked to produce. I have only been using R for a
> few weeks, so there is probably a better way to do it.
> 
> Anyway, your suggestion did work, but only up to 337 data points. I am dealing
> with ~100,000 data points so this doesn't really work for me. Is there another
> method you would suggest? My goal is to plot multiple regression planes
> (without points) in an interactive 3d plot.

I don't think that you said in your initial posting that you have so many points.

The scatter3d() function in the car package uses functions in the rgl package to draw 3D scatterplots. As Uwe Ligges and Duncan Murdoch have pointed out, you can use the rgl package directly to make your graph. One approach would be to adapt the scatter3d() code, removing the part of the code that plots the points. 

As Duncan points out, scatter3d(), which was initially written a long time ago, uses both older rgl.*() functions and newer, and in a sense better-behaved, *3d() functions in the rgl package, which isn't recommended. Because scatter3d() works properly, I haven't changed that (maybe I should). If you write your own function or script, you can take Duncan's advice and use only the *3d() functions.

Best,
 John

> 
> Thank you,
> Jeff
> 
> On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca> > wrote:
> 
> 
> 	Dear Jeff,
> 
> 	I'm tempted to say that a scatterplot without points is an oxymoron, but
> that wouldn't be very helpful.
> 
> 	Actually, the scatter3d() function used by the Rcmdr is in the car
> package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing the
> points, but if you add radius=rep(0, n) to the command that's generated, where
> you'd replace n with the number of cases in the dataset, that would do the trick
> by plotting spheres of 0 radius. For example, try
> 
> 	        scatter3d(prestige ~ income + education, data=Duncan,
> radius=rep(0, 45), residuals=FALSE)
> 
> 	either in the Rcmdr or at the R command prompt.
> 
> 	For more information see ?scatter3d or press the Help button in the
> Rcmdr 3D scatterplot dialog and follow the link to scatter3d.
> 
> 	I hope this helps,
> 	 John
> 
> 	-----------------------------
> 	John Fox, Professor
> 	McMaster University
> 	Hamilton, Ontario
> 	Canada L8S 4M4
> 	Web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> 
> 
> 
> 
> 	> -----Original Message-----
> 	> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org> ] On Behalf Of Jeff
> 	> Tostenrude
> 	> Sent: October 2, 2015 7:34 PM
> 	> To: r-help at r-project.org <mailto:r-help at r-project.org>
> 	> Subject: [R] scatter3d
> 	>
> 	> I am using scatter3d in R Commander to plot a group of regression
> surfaces.
> 	> However, I only want to display the surfaces. How do I remove the
> points?
> 	>
> 
> 	>       [[alternative HTML version deleted]]
> 	>
> 	> ______________________________________________
> 	> R-help at r-project.org <mailto:R-help at r-project.org>  mailing list -- To
> UNSUBSCRIBE and more, see
> 	> https://stat.ethz.ch/mailman/listinfo/r-help
> 	> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> 	> and provide commented, minimal, self-contained, reproducible code.
> 
> 


From giorgio.garziano at ericsson.com  Sat Oct  3 17:17:54 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sat, 3 Oct 2015 15:17:54 +0000
Subject: [R] denstrip package: densregion when density is not provided
Message-ID: <248E6FA047A8C746BA491485764190F52209BD50@ESESSMB210.ericsson.se>

>From the "densregion" help page I can read that:

z is a matrix of densities on the grid defined by x and y,
with rows corresponding to elements of x
and columns corresponding to elements of y.

So in your scenario z must be a 3 rows x 100 columns matrix, if you like to
take advantage of densregion().

z cannot be a data frame, otherwise you get the error you mentioned.

Run this to verify.

require(denstrip)
set.seed(11)

x <- 0:2
nx <- length(x)
y <- seq(0, 1, length=100)
ny <- length(y)

# z is a matrix
z <- matrix(nrow=nx, ncol=ny)
for(i in 1:nx)
  z[i,] <- dnorm(y, 0, 1)

dim(z)
class(z)

# works
plot(x, type="n", ylim=c(-1, 1))
densregion(x, y, z, colmax="darkgreen")

# does not work
z.df <- data.frame(z)
densregion(x, y, z.df, colmax="darkgreen")

Error in `[.data.frame`(x, order(x, na.last = na.last, decreasing = decreasing)) :
  undefined columns selected


--
GG


	[[alternative HTML version deleted]]


From maicel at infomed.sld.cu  Sat Oct  3 17:25:30 2015
From: maicel at infomed.sld.cu (maicel)
Date: Sat, 3 Oct 2015 11:25:30 -0400
Subject: [R] read Epidata level labels from R
Message-ID: <000201d0fdef$beb41b70$3c1c5250$@infomed.sld.cu>

Hello List, 
I need import data from Epidata version 3.1 to R data frame.  My problem is
that I need to import the level labels of from categorical variables to
factors. Epidata has two files, .red and .chk. I read on a post that the
best choice was to export them to .dta in epidat, and them to read the data
from R. I've used the functions stata.get from the library Hmisc,
read_statafrom library haven and read.dta from library foreign. Two of this
functions allow me to import the labels of the dataframe variables, not the
level labels of the factors I would like to get. How can I do it?
 Thanks for your help. Best regards,

Maicel Monzon ,MD
National Center of Clinical Trials
Havana, Cuba


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From climberjeff at gmail.com  Sat Oct  3 17:53:20 2015
From: climberjeff at gmail.com (Jeff Tostenrude)
Date: Sat, 3 Oct 2015 08:53:20 -0700
Subject: [R] scatter3d
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F2B5A4@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B5A4@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAAcp1BejfYgTzfojaiScQsndfUiG6dHqxoUzzvHS3rahM=azXA@mail.gmail.com>

Thank you for the advice, I will try you suggestions on Monday.

Uwe, by interactive I just mean the ability to spin the plot.

On Sat, Oct 3, 2015 at 7:07 AM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Jeff,
>
> > -----Original Message-----
> > From: Jeff Tostenrude [mailto:climberjeff at gmail.com]
> > Sent: October 2, 2015 11:46 PM
> > To: Fox, John <jfox at mcmaster.ca>
> > Cc: r-help at r-project.org
> > Subject: Re: [R] scatter3d
> >
> > Thank you for the suggestion. Yes, it does seem to be a bit
> counter-intuitive, but
> > that is the output I am being asked to produce. I have only been using R
> for a
> > few weeks, so there is probably a better way to do it.
> >
> > Anyway, your suggestion did work, but only up to 337 data points. I am
> dealing
> > with ~100,000 data points so this doesn't really work for me. Is there
> another
> > method you would suggest? My goal is to plot multiple regression planes
> > (without points) in an interactive 3d plot.
>
> I don't think that you said in your initial posting that you have so many
> points.
>
> The scatter3d() function in the car package uses functions in the rgl
> package to draw 3D scatterplots. As Uwe Ligges and Duncan Murdoch have
> pointed out, you can use the rgl package directly to make your graph. One
> approach would be to adapt the scatter3d() code, removing the part of the
> code that plots the points.
>
> As Duncan points out, scatter3d(), which was initially written a long time
> ago, uses both older rgl.*() functions and newer, and in a sense
> better-behaved, *3d() functions in the rgl package, which isn't
> recommended. Because scatter3d() works properly, I haven't changed that
> (maybe I should). If you write your own function or script, you can take
> Duncan's advice and use only the *3d() functions.
>
> Best,
>  John
>
> >
> > Thank you,
> > Jeff
> >
> > On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca> > wrote:
> >
> >
> >       Dear Jeff,
> >
> >       I'm tempted to say that a scatterplot without points is an
> oxymoron, but
> > that wouldn't be very helpful.
> >
> >       Actually, the scatter3d() function used by the Rcmdr is in the car
> > package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing
> the
> > points, but if you add radius=rep(0, n) to the command that's generated,
> where
> > you'd replace n with the number of cases in the dataset, that would do
> the trick
> > by plotting spheres of 0 radius. For example, try
> >
> >               scatter3d(prestige ~ income + education, data=Duncan,
> > radius=rep(0, 45), residuals=FALSE)
> >
> >       either in the Rcmdr or at the R command prompt.
> >
> >       For more information see ?scatter3d or press the Help button in the
> > Rcmdr 3D scatterplot dialog and follow the link to scatter3d.
> >
> >       I hope this helps,
> >        John
> >
> >       -----------------------------
> >       John Fox, Professor
> >       McMaster University
> >       Hamilton, Ontario
> >       Canada L8S 4M4
> >       Web: socserv.mcmaster.ca/jfox <http://socserv.mcmaster.ca/jfox>
> >
> >
> >
> >
> >       > -----Original Message-----
> >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:
> r-help-
> > bounces at r-project.org> ] On Behalf Of Jeff
> >       > Tostenrude
> >       > Sent: October 2, 2015 7:34 PM
> >       > To: r-help at r-project.org <mailto:r-help at r-project.org>
> >       > Subject: [R] scatter3d
> >       >
> >       > I am using scatter3d in R Commander to plot a group of regression
> > surfaces.
> >       > However, I only want to display the surfaces. How do I remove the
> > points?
> >       >
> >
> >       >       [[alternative HTML version deleted]]
> >       >
> >       > ______________________________________________
> >       > R-help at r-project.org <mailto:R-help at r-project.org>  mailing
> list -- To
> > UNSUBSCRIBE and more, see
> >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >       > PLEASE do read the posting guide
> http://www.R-project.org/posting-
> > guide.html
> >       > and provide commented, minimal, self-contained, reproducible
> code.
> >
> >
>
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat Oct  3 21:23:40 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 3 Oct 2015 21:23:40 +0200
Subject: [R] scatter3d
In-Reply-To: <CAAcp1BejfYgTzfojaiScQsndfUiG6dHqxoUzzvHS3rahM=azXA@mail.gmail.com>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B5A4@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BejfYgTzfojaiScQsndfUiG6dHqxoUzzvHS3rahM=azXA@mail.gmail.com>
Message-ID: <56102B3C.6070203@statistik.tu-dortmund.de>



On 03.10.2015 17:53, Jeff Tostenrude wrote:
> Thank you for the advice, I will try you suggestions on Monday.
>
> Uwe, by interactive I just mean the ability to spin the plot.

If you can calculate the planes by some functions, I reall suggest to 
use functions from rgl that are able to plot planes (rather than points).

Best,
Uwe Ligges

>
> On Sat, Oct 3, 2015 at 7:07 AM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca>> wrote:
>
>     Dear Jeff,
>
>     > -----Original Message-----
>     > From: Jeff Tostenrude [mailto:climberjeff at gmail.com <mailto:climberjeff at gmail.com>]
>     > Sent: October 2, 2015 11:46 PM
>     > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
>     > Cc:r-help at r-project.org <mailto:r-help at r-project.org>
>     > Subject: Re: [R] scatter3d
>     >
>     > Thank you for the suggestion. Yes, it does seem to be a bit counter-intuitive, but
>     > that is the output I am being asked to produce. I have only been using R for a
>     > few weeks, so there is probably a better way to do it.
>     >
>     > Anyway, your suggestion did work, but only up to 337 data points. I am dealing
>     > with ~100,000 data points so this doesn't really work for me. Is there another
>     > method you would suggest? My goal is to plot multiple regression planes
>     > (without points) in an interactive 3d plot.
>
>     I don't think that you said in your initial posting that you have so
>     many points.
>
>     The scatter3d() function in the car package uses functions in the
>     rgl package to draw 3D scatterplots. As Uwe Ligges and Duncan
>     Murdoch have pointed out, you can use the rgl package directly to
>     make your graph. One approach would be to adapt the scatter3d()
>     code, removing the part of the code that plots the points.
>
>     As Duncan points out, scatter3d(), which was initially written a
>     long time ago, uses both older rgl.*() functions and newer, and in a
>     sense better-behaved, *3d() functions in the rgl package, which
>     isn't recommended. Because scatter3d() works properly, I haven't
>     changed that (maybe I should). If you write your own function or
>     script, you can take Duncan's advice and use only the *3d() functions.
>
>     Best,
>       John
>
>     >
>     > Thank you,
>     > Jeff
>     >
>     > On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>
>     > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>> > wrote:
>     >
>     >
>     >       Dear Jeff,
>     >
>     >       I'm tempted to say that a scatterplot without points is an oxymoron, but
>     > that wouldn't be very helpful.
>     >
>     >       Actually, the scatter3d() function used by the Rcmdr is in the car
>     > package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing the
>     > points, but if you add radius=rep(0, n) to the command that's generated, where
>     > you'd replace n with the number of cases in the dataset, that would do the trick
>     > by plotting spheres of 0 radius. For example, try
>     >
>     >               scatter3d(prestige ~ income + education, data=Duncan,
>     > radius=rep(0, 45), residuals=FALSE)
>     >
>     >       either in the Rcmdr or at the R command prompt.
>     >
>     >       For more information see ?scatter3d or press the Help button in the
>     > Rcmdr 3D scatterplot dialog and follow the link to scatter3d.
>     >
>     >       I hope this helps,
>     >        John
>     >
>     >       -----------------------------
>     >       John Fox, Professor
>     >       McMaster University
>     >       Hamilton, Ontario
>     >       Canada L8S 4M4
>      >       Web: socserv.mcmaster.ca/jfox
>     <http://socserv.mcmaster.ca/jfox> <http://socserv.mcmaster.ca/jfox>
>     >
>     >
>     >
>     >
>     >       > -----Original Message-----
>     >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org>
>     <mailto:r-help- <mailto:r-help->
>     >bounces at r-project.org <mailto:bounces at r-project.org>> ] On Behalf Of
>     Jeff
>     >       > Tostenrude
>     >       > Sent: October 2, 2015 7:34 PM
>     >       > To:r-help at r-project.org <mailto:r-help at r-project.org>
>     <mailto:r-help at r-project.org <mailto:r-help at r-project.org>>
>     >       > Subject: [R] scatter3d
>     >       >
>     >       > I am using scatter3d in R Commander to plot a group of regression
>     > surfaces.
>     >       > However, I only want to display the surfaces. How do I remove the
>     > points?
>     >       >
>     >
>     >       >       [[alternative HTML version deleted]]
>     >       >
>     >       > ______________________________________________
>      >       > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>  mailing
>     list -- To
>      > UNSUBSCRIBE and more, see
>      >       > https://stat.ethz.ch/mailman/listinfo/r-help
>      >       > PLEASE do read the posting guide
>     http://www.R-project.org/posting-
>      > guide.html
>      >       > and provide commented, minimal, self-contained,
>     reproducible code.
>      >
>      >
>
>


From jfox at mcmaster.ca  Sat Oct  3 21:50:34 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 3 Oct 2015 19:50:34 +0000
Subject: [R] scatter3d
In-Reply-To: <56102B3C.6070203@statistik.tu-dortmund.de>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B5A4@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BejfYgTzfojaiScQsndfUiG6dHqxoUzzvHS3rahM=azXA@mail.gmail.com>
	<56102B3C.6070203@statistik.tu-dortmund.de>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F2B6A0@FHSDB2D11-2.csu.mcmaster.ca>

Dear Uwe,

> -----Original Message-----
> From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de]
> Sent: October 3, 2015 3:24 PM
> To: Jeff Tostenrude <climberjeff at gmail.com>; Fox, John <jfox at mcmaster.ca>
> Cc: r-help at r-project.org; Duncan Murdoch <murdoch.duncan at gmail.com>
> Subject: Re: [R] scatter3d
> 
> 
> 
> On 03.10.2015 17:53, Jeff Tostenrude wrote:
> > Thank you for the advice, I will try you suggestions on Monday.
> >
> > Uwe, by interactive I just mean the ability to spin the plot.
> 
> If you can calculate the planes by some functions, I reall suggest to use
> functions from rgl that are able to plot planes (rather than points).

Indeed, this is what scatter3d() does -- plots regression surfaces, including planes, along with points. One approach, as I suggested, is simply to get rid of the points, and plot just the regression surfaces.

Best,
 John

> 
> Best,
> Uwe Ligges
> 
> >
> > On Sat, Oct 3, 2015 at 7:07 AM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>> wrote:
> >
> >     Dear Jeff,
> >
> >     > -----Original Message-----
> >     > From: Jeff Tostenrude [mailto:climberjeff at gmail.com
> <mailto:climberjeff at gmail.com>]
> >     > Sent: October 2, 2015 11:46 PM
> >     > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> >     > Cc:r-help at r-project.org <mailto:r-help at r-project.org>
> >     > Subject: Re: [R] scatter3d
> >     >
> >     > Thank you for the suggestion. Yes, it does seem to be a bit counter-
> intuitive, but
> >     > that is the output I am being asked to produce. I have only been using R for
> a
> >     > few weeks, so there is probably a better way to do it.
> >     >
> >     > Anyway, your suggestion did work, but only up to 337 data points. I am
> dealing
> >     > with ~100,000 data points so this doesn't really work for me. Is there
> another
> >     > method you would suggest? My goal is to plot multiple regression planes
> >     > (without points) in an interactive 3d plot.
> >
> >     I don't think that you said in your initial posting that you have so
> >     many points.
> >
> >     The scatter3d() function in the car package uses functions in the
> >     rgl package to draw 3D scatterplots. As Uwe Ligges and Duncan
> >     Murdoch have pointed out, you can use the rgl package directly to
> >     make your graph. One approach would be to adapt the scatter3d()
> >     code, removing the part of the code that plots the points.
> >
> >     As Duncan points out, scatter3d(), which was initially written a
> >     long time ago, uses both older rgl.*() functions and newer, and in a
> >     sense better-behaved, *3d() functions in the rgl package, which
> >     isn't recommended. Because scatter3d() works properly, I haven't
> >     changed that (maybe I should). If you write your own function or
> >     script, you can take Duncan's advice and use only the *3d() functions.
> >
> >     Best,
> >       John
> >
> >     >
> >     > Thank you,
> >     > Jeff
> >     >
> >     > On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca
> <mailto:jfox at mcmaster.ca>
> >     > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>> > wrote:
> >     >
> >     >
> >     >       Dear Jeff,
> >     >
> >     >       I'm tempted to say that a scatterplot without points is an oxymoron,
> but
> >     > that wouldn't be very helpful.
> >     >
> >     >       Actually, the scatter3d() function used by the Rcmdr is in the car
> >     > package. The Rcmdr 3D scatterplot dialog doesn't provide for suppressing
> the
> >     > points, but if you add radius=rep(0, n) to the command that's generated,
> where
> >     > you'd replace n with the number of cases in the dataset, that would do the
> trick
> >     > by plotting spheres of 0 radius. For example, try
> >     >
> >     >               scatter3d(prestige ~ income + education, data=Duncan,
> >     > radius=rep(0, 45), residuals=FALSE)
> >     >
> >     >       either in the Rcmdr or at the R command prompt.
> >     >
> >     >       For more information see ?scatter3d or press the Help button in the
> >     > Rcmdr 3D scatterplot dialog and follow the link to scatter3d.
> >     >
> >     >       I hope this helps,
> >     >        John
> >     >
> >     >       -----------------------------
> >     >       John Fox, Professor
> >     >       McMaster University
> >     >       Hamilton, Ontario
> >     >       Canada L8S 4M4
> >      >       Web: socserv.mcmaster.ca/jfox
> >     <http://socserv.mcmaster.ca/jfox> <http://socserv.mcmaster.ca/jfox>
> >     >
> >     >
> >     >
> >     >
> >     >       > -----Original Message-----
> >     >       > From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-
> bounces at r-project.org>
> >     <mailto:r-help- <mailto:r-help->
> >     >bounces at r-project.org <mailto:bounces at r-project.org>> ] On Behalf Of
> >     Jeff
> >     >       > Tostenrude
> >     >       > Sent: October 2, 2015 7:34 PM
> >     >       > To:r-help at r-project.org <mailto:r-help at r-project.org>
> >     <mailto:r-help at r-project.org <mailto:r-help at r-project.org>>
> >     >       > Subject: [R] scatter3d
> >     >       >
> >     >       > I am using scatter3d in R Commander to plot a group of regression
> >     > surfaces.
> >     >       > However, I only want to display the surfaces. How do I remove the
> >     > points?
> >     >       >
> >     >
> >     >       >       [[alternative HTML version deleted]]
> >     >       >
> >     >       > ______________________________________________
> >      >       > R-help at r-project.org <mailto:R-help at r-project.org>
> >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>  mailing
> >     list -- To
> >      > UNSUBSCRIBE and more, see
> >      >       > https://stat.ethz.ch/mailman/listinfo/r-help
> >      >       > PLEASE do read the posting guide
> >     http://www.R-project.org/posting-
> >      > guide.html
> >      >       > and provide commented, minimal, self-contained,
> >     reproducible code.
> >      >
> >      >
> >
> >

From syen04 at gmail.com  Sat Oct  3 22:53:01 2015
From: syen04 at gmail.com (Steven Yen)
Date: Sat, 3 Oct 2015 16:53:01 -0400
Subject: [R] Calling external file
In-Reply-To: <560FCE45.8040909@dewey.myzen.co.uk>
References: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
	<560FCE45.8040909@dewey.myzen.co.uk>
Message-ID: <CAKTtY6QpFJnhtY87iUbZNZFpjEgLrfKF_GW1ooxarHhhipg6bA@mail.gmail.com>

Thanks Michael. I am a new hand with R so this is over my head. I will
slowly explore all options suggested but for now I'd glad to get one option
to work. How do you 'declare the function into the routine I am sourcing,
i.e., max.calls? Is there something I can read?

On Sat, Oct 3, 2015 at 8:47 AM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> You did put the declaration of the function fn into the file you are
> sourcing, didn't you?
>
> If it were me I would
> 1 - make fn a parameter of max.calls
> 2 - use the ellipsis ... so I could pass other arguments in to MaxLike
> 3 - fix the errors I got from making it a package. It does not lie when it
> tells you things are undefined and, who knows, they may need to be defined.
>
>
> On 03/10/2015 09:47, Steven Yen wrote:
>
>> Hi
>> I collect a list of calls to a package in a function (routine) so that I
>> do
>> not need to repeat the same sets of codes from program to program. In the
>> following, inserting the function into each program works. Then, I place
>> the function elsewhere in a PC folder, and include in with a 'source'
>> command. This does not work; it complains about a function (fn below) not
>> defined.
>> Compiling the function into a library file does not work either (with all
>> sorts of error messages saying this and that not defined).
>> Steven Yen
>>
>> fn <- function(beta){
>>    f<-... (define f in this routine)
>> return(f)
>> }
>>
>> max.calls<-function(method){
>> # *******************************************************
>> # Call maxLike with alternative algorithms
>> # *******************************************************
>>    many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
>>    if (method %in% many){
>>      ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
>>                 method,print.level,constraints=NULL, ...)}
>> return(ML)
>> }
>> # This works:
>> ML<-max.calls(method)
>>
>> # Does not work:
>> source("z:\\R\\yenlib\\lib\\max.calls.R")
>> ML<-max.calls(method)
>>
>> Error: object 'fn' not found
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Oct  4 00:37:18 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 3 Oct 2015 15:37:18 -0700
Subject: [R] Calling external file
In-Reply-To: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
References: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
Message-ID: <CAF8bMcZJY-gq+TxU2t8mf5b6SBYCggg=vVB8hTm2wv8cksSqQQ@mail.gmail.com>

Does an object called 'fn' exist anywhere after you call source()?
Start looking by typing
   fn
and see if it is the global environment.

You will have to show what is in the file "z:\\R\\yenlib\\lib\\max.calls.R".
Some people like to start such files with things like
    remove(list=objects())
(This is a really bad practice, but I've seen it on this list.)
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Oct 3, 2015 at 1:47 AM, Steven Yen <syen04 at gmail.com> wrote:
> Hi
> I collect a list of calls to a package in a function (routine) so that I do
> not need to repeat the same sets of codes from program to program. In the
> following, inserting the function into each program works. Then, I place
> the function elsewhere in a PC folder, and include in with a 'source'
> command. This does not work; it complains about a function (fn below) not
> defined.
> Compiling the function into a library file does not work either (with all
> sorts of error messages saying this and that not defined).
> Steven Yen
>
> fn <- function(beta){
>   f<-... (define f in this routine)
> return(f)
> }
>
> max.calls<-function(method){
> # *******************************************************
> # Call maxLike with alternative algorithms
> # *******************************************************
>   many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
>   if (method %in% many){
>     ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
>                method,print.level,constraints=NULL, ...)}
> return(ML)
> }
> # This works:
> ML<-max.calls(method)
>
> # Does not work:
> source("z:\\R\\yenlib\\lib\\max.calls.R")
> ML<-max.calls(method)
>
> Error: object 'fn' not found
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Sun Oct  4 00:56:25 2015
From: syen04 at gmail.com (Steven Yen)
Date: Sat, 3 Oct 2015 18:56:25 -0400
Subject: [R] Calling external file
In-Reply-To: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
References: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
Message-ID: <CAKTtY6RRkiW2CVA-B6dJYTtp4-GDF48+SPx22mxuvXCrhJ-B2A@mail.gmail.com>

Thanks Bill. Simplified content of max.calls.R (with repeated calls to
maxLik removed) are shown below in the message. No, fn does not exist in
the environment. I call a routine (say probit.R compiled into a library) to
use maxLik. Inside this routine,
1. In probit.R. likelihood function is defined yet in another nested
routine;
2. Function "max.calls" is also nested in that  probit.R;
Then, a call to max.calls works.

What I am trying to accomplish is, instead of inserting the identical
function (or set of lines) in every routine like probit.R, I like to either
compile max.calls.R or source it from inside probit.R. Thanks.


On Sat, Oct 3, 2015 at 4:47 AM, Steven Yen <syen04 at gmail.com> wrote:

> Hi
> I collect a list of calls to a package in a function (routine) so that I
> do not need to repeat the same sets of codes from program to program. In
> the following, inserting the function into each program works. Then, I
> place the function elsewhere in a PC folder, and include in with a 'source'
> command. This does not work; it complains about a function (fn below) not
> defined.
> Compiling the function into a library file does not work either (with all
> sorts of error messages saying this and that not defined).
> Steven Yen
>
> fn <- function(beta){
>   f<-... (define f in this routine)
> return(f)
> }
>
> max.calls<-function(method){
> # *******************************************************
> # Call maxLike with alternative algorithms
> # *******************************************************
>   many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
>   if (method %in% many){
>     ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
>                method,print.level,constraints=NULL, ...)}
> return(ML)
> }
> # This works:
> ML<-max.calls(method)
>
> # Does not work:
> source("z:\\R\\yenlib\\lib\\max.calls.R")
> ML<-max.calls(method)
>
> Error: object 'fn' not found
>
>

	[[alternative HTML version deleted]]


From matteo.richiardi at gmail.com  Sun Oct  4 09:02:10 2015
From: matteo.richiardi at gmail.com (Matteo Richiardi)
Date: Sun, 4 Oct 2015 08:02:10 +0100
Subject: [R] denstrip package: densregion when density is not provided
Message-ID: <CABSrU1J1BX7ZM+1A0Bh90WZow0svL9+7AQo2N_Lf111WC80HXA@mail.gmail.com>

I need to estimate the density from the other time series, similarly to what
denstrip does (however, I need a whole region, and not just a strip).

This is my updated example, where I tried to estimate the density from my
bootstrapped projections using density() - as in denstrip:

require(denstrip)
x <- 2013:2015
y0.df <- read.delim("clipboard")
y0.num <- data.matrix(y0.df, rownames.force = NA)
y.df <- read.delim("clipboard")
y.num <- data.matrix(y.df, rownames.force = NA)
z <- density(y.num)
densregion(x, y, z)

where y0.num contains my "central" projection:
> head(y0.num)
       default
[1,] 0.7086428
[2,] 0.7111570
[3,] 0.7117583
[4,] 0.7124711
[5,] 0.7166852
[6,] 0.7167453

and y.num contains the bootstrapped projections:
          run1      run2      run3      run4      run5      run6
[1,] 0.6932324 0.7732179 0.6201226 0.6712345 0.6974636 0.7399447
[2,] 0.6773456 0.7971804 0.5810890 0.6775887 0.7134176 0.7480797
[3,] 0.6704025 0.8122599 0.5655451 0.6836657 0.7438639 0.7540193
[4,] 0.6671754 0.8235685 0.5663680 0.6828320 0.7650042 0.7605239
[5,] 0.6644370 0.8287378 0.5643008 0.6846030 0.7921467 0.7655395
[6,] 0.6630486 0.8333708 0.5612197 0.6882252 0.8183746 0.7687452

This is the error I get:

Error in rank(x, ties.method = "min", na.last = "keep") :
  unimplemented type 'list' in 'greater'

Matteo

On 3 October 2015 at 09:16, Matteo Richiardi <matteo.richiardi at gmail.com>
wrote:

> I have several estimated time series, running from 2013 to 2050. 'y'
> values are constrained between 0 and 1. I would like to plot them using
> shaded colours of decreasing intensity, depending on an estimated density
> at each point x in 2013-2050.
>
> This is what I have done:
>
> require(denstrip)
> x <- 2013:2015
> y <- seq(0, 1, length=100)
> z <- read.delim("clipboard")
> densregion(x, y, z)
>
> where I imported 'z' from MS Excel. 'z' looks like (I copied only the
> first 2 columns, l but I have 100 of them):
>
>         run1      run2
> 1  0.6932324 0.7732179
> 2  0.6773456 0.7971804
> ...
> 37 0.7260790 0.8724961
> 38 0.7290335 0.8755433
>
> I get the following error message:
> Error in `[.data.frame`(x, order(x, na.last = na.last, decreasing =
> decreasing)) :
>   undefined columns selected
>
> Could anybody please help me with fixing this? Thanks in advance
>

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Sun Oct  4 13:41:42 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 4 Oct 2015 12:41:42 +0100
Subject: [R] Calling external file
In-Reply-To: <CAKTtY6RRkiW2CVA-B6dJYTtp4-GDF48+SPx22mxuvXCrhJ-B2A@mail.gmail.com>
References: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
	<CAKTtY6RRkiW2CVA-B6dJYTtp4-GDF48+SPx22mxuvXCrhJ-B2A@mail.gmail.com>
Message-ID: <56111076.9030901@dewey.myzen.co.uk>

In line

On 03/10/2015 23:56, Steven Yen wrote:
> Thanks Bill. Simplified content of max.calls.R (with repeated calls to
> maxLik removed) are shown below in the message. No, fn does not exist in
> the environment.

Which explains why R cannot find it.

  I call a routine (say probit.R compiled into a library) to
> use maxLik. Inside this routine,
> 1. In probit.R. likelihood function is defined yet in another nested
> routine;

If I understand you correctly it is that function which you need to pass 
to max.calls. So alter max.calls as below

> 2. Function "max.calls" is also nested in that  probit.R;
> Then, a call to max.calls works.
>
> What I am trying to accomplish is, instead of inserting the identical
> function (or set of lines) in every routine like probit.R, I like to either
> compile max.calls.R or source it from inside probit.R. Thanks.
>
>
> On Sat, Oct 3, 2015 at 4:47 AM, Steven Yen <syen04 at gmail.com> wrote:
>
>> Hi
>> I collect a list of calls to a package in a function (routine) so that I
>> do not need to repeat the same sets of codes from program to program. In
>> the following, inserting the function into each program works. Then, I
>> place the function elsewhere in a PC folder, and include in with a 'source'
>> command. This does not work; it complains about a function (fn below) not
>> defined.
>> Compiling the function into a library file does not work either (with all
>> sorts of error messages saying this and that not defined).
>> Steven Yen
>>
>> fn <- function(beta){
>>    f<-... (define f in this routine)
>> return(f)
>> }
>>
>> max.calls<-function(method){

max.calls <- function(method, fn = NULL) {
    if(is.null(fn)) warning("You forgot to supply fn)
>> # *******************************************************
>> # Call maxLike with alternative algorithms
>> # *******************************************************
>>    many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
>>    if (method %in% many){
>>      ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
>>                 method,print.level,constraints=NULL, ...)}
>> return(ML)
>> }
>> # This works:
>> ML<-max.calls(method)

Now in probit.R replace the call to max.calls(method) with
max.calls(method, whatever_function_you 
defined_in_probit.R_for_the_likelihood)

Of course I may have completely misunderstood what you are driving at.

>>
>> # Does not work:
>> source("z:\\R\\yenlib\\lib\\max.calls.R")
>> ML<-max.calls(method)
>>
>> Error: object 'fn' not found
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From giorgio.garziano at ericsson.com  Sun Oct  4 13:44:38 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 4 Oct 2015 11:44:38 +0000
Subject: [R] denstrip package: densregion when density is not provided
Message-ID: <248E6FA047A8C746BA491485764190F52209DEB4@ESESSMB210.ericsson.se>

It is likely you have some list structure you should not.
Check the class of the elements of your matrixes, to see if any list class shows up.

Not clear from your code what is "y" passed to densregion(..).

Anyway, one way to reproduce your error is the following:

# this does not work
> a <- list(a=1:10, b=30:40)
> a
$a
[1]  1  2  3  4  5  6  7  8  9 10

$b
[1] 30 31 32 33 34 35 36 37 38 39 40

rank(a, ties.method = "min", na.last = "keep")

Error in rank(a, ties.method = "min", na.last = "keep") :
  unimplemented type 'list' in 'greater'

# this works
b <- sample(1:10)
> b
[1]  8  9  5  2  4  1  7 10  3  6
> rank(b)
[1]  8  9  5  2  4  1  7 10  3  6
>

You may also try to debug the densregion() function.
Using RStudio it pretty straightforward.
Call this before running your code.

debug(densregion)

when executing densregion() the RStudio source-viewer will show up the densregion.default code and
step by step (F10) you can go through the code lines see what is going wrong.

To stop debugging, click red Stop button on console pane and then if you do not need to re-run the debugging,
call:

undebug(densregion)


Good luck.

--
GG

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sun Oct  4 18:22:41 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 4 Oct 2015 09:22:41 -0700
Subject: [R] Calling external file
In-Reply-To: <CAKTtY6RRkiW2CVA-B6dJYTtp4-GDF48+SPx22mxuvXCrhJ-B2A@mail.gmail.com>
References: <CAKTtY6R=6GdrowJozS9KHhyh0m35Y9eUzSstghLep2rAD790MQ@mail.gmail.com>
	<CAKTtY6RRkiW2CVA-B6dJYTtp4-GDF48+SPx22mxuvXCrhJ-B2A@mail.gmail.com>
Message-ID: <CAF8bMcb45D+dnvegZUxXnWJw_40WzaRWkuAENS9kTV26X6PXTA@mail.gmail.com>

Does the following pattern resemble what you have?

Here are a couple of functions that use the same code for finding the
location of the minimum of a function fn:
   f1 <- function(x) {
       fn <- function(beta) {
           sum((x-beta)^2)
       }
       argMinFn <- function() {
           beta <- seq(0, 1, len=129)
           beta[which.min(vapply(beta, fn, 0))]
       }
       argMinFn()
   }
   f2 <- function(x) {
       fn <- function(beta) {
           sum(abs(x-beta))
       }
       argMinFn <- function() {
           beta <- seq(0, 1, len=129)
           beta[which.min(vapply(beta, fn, 0))]
       }
       argMinFn()
   }
used as
   > f1(1/(1:10)) # approx. mean of 1/(1:10)
   [1] 0.2890625
   > f2(1/(1:10)) # approx median of 1/(1:10)
   [1] 0.171875

I think you are trying to avoid copying that argMinFn into every
function of this sort
so you move it out of the f1 and f2 functions:
       argMinFn.bad <- function() {
           beta <- seq(0, 1, len=129)
           beta[which.min(vapply(beta, fn, 0))]
       }
and omit it from f1 and f2
     f1a.bad <- function(x) {
       fn <- function(beta) {
           sum((x-beta)^2)
       }
       argMinFn.bad()
   }
Then you get the sort of error you describe
  > f1a.bad(1/(1:10))
  Error in match.fun(FUN) : object 'fn' not found
The problem is that a function first looks for objects defined in its own
environment, then in the environment in which the function was created,
then the parent of that environment, etc.  The stand-along argMinFn
was defined in the global environment so it does not look in the environment
of f1a.bad for fn.

The fix is to make fn an argument to the stand-along argMinFn and have
f1a.good pass fn into the environment of argMinFn via the argument list.
     argMinFn.good <- function(fn) {
         beta <- seq(0, 1, len=129)
         beta[which.min(vapply(beta, fn, 0))]
     }
     f1a.good <- function(x)
     {
        fn <- function(beta) {
          sum((x-beta)^2)
        }
        argMinFn.good(fn)
     }
e.g
    > f1a.good(1/(1:10))
    [1] 0.2890625

How functions look up variables is called 'scoping' and R's method is
called 'lexical scoping'.  You can find lots more information on this with
google.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Oct 3, 2015 at 3:56 PM, Steven Yen <syen04 at gmail.com> wrote:
> Thanks Bill. Simplified content of max.calls.R (with repeated calls to
> maxLik removed) are shown below in the message. No, fn does not exist in
> the environment. I call a routine (say probit.R compiled into a library) to
> use maxLik. Inside this routine,
> 1. In probit.R. likelihood function is defined yet in another nested
> routine;
> 2. Function "max.calls" is also nested in that  probit.R;
> Then, a call to max.calls works.
>
> What I am trying to accomplish is, instead of inserting the identical
> function (or set of lines) in every routine like probit.R, I like to either
> compile max.calls.R or source it from inside probit.R. Thanks.
>
>
> On Sat, Oct 3, 2015 at 4:47 AM, Steven Yen <syen04 at gmail.com> wrote:
>
>> Hi
>> I collect a list of calls to a package in a function (routine) so that I
>> do not need to repeat the same sets of codes from program to program. In
>> the following, inserting the function into each program works. Then, I
>> place the function elsewhere in a PC folder, and include in with a 'source'
>> command. This does not work; it complains about a function (fn below) not
>> defined.
>> Compiling the function into a library file does not work either (with all
>> sorts of error messages saying this and that not defined).
>> Steven Yen
>>
>> fn <- function(beta){
>>   f<-... (define f in this routine)
>> return(f)
>> }
>>
>> max.calls<-function(method){
>> # *******************************************************
>> # Call maxLike with alternative algorithms
>> # *******************************************************
>>   many<-c("NR","BFGS","BFGSR","BHHH","SANN","CG","NM")
>>   if (method %in% many){
>>     ML<-maxLik(logLik=fn,grad=NULL,hess=NULL,start,
>>                method,print.level,constraints=NULL, ...)}
>> return(ML)
>> }
>> # This works:
>> ML<-max.calls(method)
>>
>> # Does not work:
>> source("z:\\R\\yenlib\\lib\\max.calls.R")
>> ML<-max.calls(method)
>>
>> Error: object 'fn' not found
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lordpreetam at gmail.com  Sun Oct  4 18:43:14 2015
From: lordpreetam at gmail.com (Preetam Pal)
Date: Sun, 4 Oct 2015 22:13:14 +0530
Subject: [R] Johansen Test of Cointegration:How to access rows in R output
Message-ID: <CAHVFrXH6NJZ9i-zH5uQ5NpVjy3V0b3+yT0jCdxm9kPus7HDaJg@mail.gmail.com>

Hi guys,

I ran ca.jo(data,type="trace", ecdet="none",k=2) i.e. Johansen's Trace test
on R-Studio (package: "urca")and got the output below:

I have 3 questions about this:

A> How do I programmatically access the columns("test", "10pct" etc) in any
row corresponding to, say, r < = 1 in the output?  I mean, I shall only
provide the r-value as an input and all the (column name, column value)
pairs will be outputted to me.

B> How do I write a code that will check if the null hypotheses for r =0,
<= 1, <= 2 and so on  (in this order) are rejected or not; and in case one
of them is rejected, it checks the next higher value of r and gives the
final inference , something like "Null not rejected for r <= *appropriate
r-value from this table* " or "All nulls rejected" or "No null rejected'.

C> Also, I need to extract the eigen vectors from the Cointegration Matrix
below to get the cointegrated transfoms.

I have attached the data for your perusal. If I need to provide anything
more, please let me know.

Regards,
Preetam

######################
# Johansen-Procedure #
######################

Test type: trace statistic , with linear trend in cointegration

Eigenvalues (lambda):
[1] 7.935953e-01 5.444372e-01 4.985327e-01 2.562245e-01 5.551115e-16

Values of teststatistic and critical values of test:

          test 10pct  5pct  1pct
r <= 3 |  6.81 10.49 12.25 16.26
r <= 2 | 22.68 22.76 25.32 30.45
r <= 1 | 40.77 39.06 42.44 48.45
r = 0  | 77.06 59.14 62.99 70.05

Eigenvectors, normalised to first column:
(These are the cointegration relations)

               GDP.l2     HPA.l2       FX.l2        Y.l2   trend.l2
GDP.l2    1.000000000  1.0000000  1.00000000  1.00000000  1.0000000
HPA.l2    2.525511110  0.1569079  0.08077351 -0.22777550 -0.9178250
FX.l2    -8.643729121 -2.5815150  0.17158404 -0.47053012 -4.8528875
Y.l2      0.805229998 -1.4241546  0.07767540  0.02303305  0.5213294
trend.l2  0.006283314  0.0385276 -0.01512016  0.01986813 -0.9516072

Weights W:
(This is the loading matrix)

           GDP.l2      HPA.l2      FX.l2        Y.l2      trend.l2
GDP.d  0.03055313 -0.04681978 -0.8376985 -0.04220534 -1.271960e-17
HPA.d -0.22649596 -0.24287691 -1.6358880  2.03813569 -8.002467e-17
FX.d   0.10327579  0.15150469 -0.1649066  0.37449910 -2.570250e-18
Y.d   -0.35200485  0.56808024 -5.7829738  0.01000965  1.730461e-16
-------------- next part --------------
GDP	HPA	FX	Y
0.514662421	0.635997077	1.37802145	1.773342598
0.936722	3.127683176	1.391916535	3.709809052
0.101482324	1.270555421	0.831157511	0.226267793
0.017548634	2.456061547	1.003945759	9.510258161
0.236462416	0.988324147	0.223682679	5.026671536
0.372005149	2.177631629	0.904226065	4.219235789
0.153915709	4.620341653	0.033410743	3.17396006
0.524887329	1.050861084	0.518201484	7.950098612
0.776616937	0.503349512	0.666089868	3.320938471
0.760074361	3.635853456	0.470220952	6.380945175
0.802986662	1.260738545	0.452674872	1.036040804
0.375145127	0.20035625	1.837306306	6.486871565
0.002568896	3.532359526	0.556752154	8.536594244
0.754309276	3.952381767	0.247402168	8.559081716
0.585966577	4.01463047	1.184382133	0.148121669
0.39767356	1.553753452	0.983129422	5.378373676
0.859898623	4.73191381	0.828795696	3.367809329
0.741376169	4.993350692	1.758051281	5.516460988
0.329240391	3.465836416	1.701655508	1.249497907
0.078661064	3.298298811	0.04575857	5.132921426
0.270971873	0.46627043	1.739487411	4.94697541
0.731072625	0.940642982	0.728747166	7.583041122
0.385038046	3.51048946	0.021866584	7.361148458
0.530760376	1.204422978	0.415530715	1.163503483
0.555323667	4.777712592	1.844184811	8.596644394

From fernando.mansito at gmail.com  Sun Oct  4 20:31:26 2015
From: fernando.mansito at gmail.com (FERNANDO MANSITO CABALLERO)
Date: Sun, 4 Oct 2015 20:31:26 +0200
Subject: [R] (no subject)
Message-ID: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>

Dear Madam/Sir,

I  am   trying to understand  R and I have come to a stumbling block. i
have written:

>Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
+child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
+child.ages=c(14,17)))
>Empl[c(2,4)]$family$spouse
[1] "Fred"
>#instead of [1] "Fred" "Mary"

Where am I wrong?

Thank you very much for your patience
Yours truly,
Fernando Mansito

	[[alternative HTML version deleted]]


From naresh_gurbuxani at hotmail.com  Sun Oct  4 21:30:22 2015
From: naresh_gurbuxani at hotmail.com (Naresh Gurbuxani)
Date: Sun, 4 Oct 2015 15:30:22 -0400
Subject: [R] lattice plot: points and lines for different variables in same
 plotlattice plot
Message-ID: <SNT150-W5747367DCE430E534944D5FA490@phx.gbl>

I want to draw scatter plot and a fitted line in the same lattice plot.  My problem is that either both can be plotted as points or both as lines.  The code that attempts to plot points for data and lines for fitted line does not work.  

Thanks,
Naresh

library(lattice)
library(plyr)

my.df <- data.frame(x = rnorm(100), y = rnorm(100), name = "A")

temp.df <- data.frame(x = rnorm(100), name = "B")
temp.df <- within(temp.df, {y <- x + 0.2 * rnorm(100)})
my.df <- rbind(my.df, temp.df)

temp.df <- data.frame(x = rnorm(100), name = "C")
temp.df <- within(temp.df, {y <- x + 0.5 * x^2 + 0.2 * rnorm(100)})
my.df <- rbind(my.df, temp.df)

my.df <- ddply(my.df, c("name"), mutate, y.fit = lm(y ~ x + I(x^2))$fitted.values)

my.df <- my.df[order(my.df$name, my.df$x),]

# This works
xyplot(y + y.fit ~ x | name, data = my.df, type = c("l"))

# This does not work.  Line plot seems wrong.
xyplot(y + y.fit ~ x | name, data = my.df, type = c("l"), y.prime = my.df$y.fit, panel = function(x, y, y.prime, ...){panel.xyplot(x, y); panel.lines(x, y.prime, type = "l")})


 		 	   		  
	[[alternative HTML version deleted]]


From b.rowlingson at lancaster.ac.uk  Sun Oct  4 21:41:16 2015
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Sun, 4 Oct 2015 20:41:16 +0100
Subject: [R] (no subject)
In-Reply-To: <f02add80d97a42e4aaf4a94020b17ab6@EX-0-HT0.lancs.local>
References: <f02add80d97a42e4aaf4a94020b17ab6@EX-0-HT0.lancs.local>
Message-ID: <CANVKczPhDUH1EHM6HCTxApiFpnLkmhFfX9UJ7vbvkQqjkjDa8w@mail.gmail.com>

lists in R can have multiple elements with the same name but if you
try and access elements by name you only get the first.

For example:

 > a = list(x=99, x=23, x=456)
 > a$x
 [1] 99

Its just the way it is.

Note you might find the `str` function useful to see the structure of R objects:

 > str(Empl)
List of 4
 $ employee: chr "Anna"
 $ family  :List of 3
  ..$ spouse    : chr "Fred"
  ..$ children  : num 3
  ..$ child.ages: num [1:3] 4 7 9
 $ employee: chr "John"
 $ family  :List of 3
  ..$ spouse    : chr "Mary"
  ..$ children  : num 2
  ..$ child.ages: num [1:2] 14 17
 > str(Empl[c(2,4)])
List of 2
 $ family:List of 3
  ..$ spouse    : chr "Fred"
  ..$ children  : num 3
  ..$ child.ages: num [1:3] 4 7 9
 $ family:List of 3
  ..$ spouse    : chr "Mary"
  ..$ children  : num 2
  ..$ child.ages: num [1:2] 14 17
 > str(Empl[c(2,4)]$family)
List of 3
 $ spouse    : chr "Fred"
 $ children  : num 3
 $ child.ages: num [1:3] 4 7 9

With your current data structure you might need to use the
list-processing functions like `sapply` and `lapply` to get out the
spouse names from your list:

 > sapply(Empl[c(2,4)], function(x){x$spouse})
 family family
 "Fred" "Mary"

Keep at it!

On Sun, Oct 4, 2015 at 7:31 PM, FERNANDO MANSITO CABALLERO
<fernando.mansito at gmail.com> wrote:
> Dear Madam/Sir,
>
> I  am   trying to understand  R and I have come to a stumbling block. i
> have written:
>
>>Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
> +child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
> +child.ages=c(14,17)))
>>Empl[c(2,4)]$family$spouse
> [1] "Fred"
>>#instead of [1] "Fred" "Mary"
>
> Where am I wrong?
>
> Thank you very much for your patience
> Yours truly,
> Fernando Mansito
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Sun Oct  4 21:44:51 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 4 Oct 2015 15:44:51 -0400
Subject: [R] (no subject)
In-Reply-To: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
References: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
Message-ID: <CAAxdm-5JjREYjr5buin74KUhguxM1pAWHf14wjs_2DFDQuL1Wg@mail.gmail.com>

You need to break down your expression into parts and see what the data is:

> Empl[c(2,4)]
$family
$family$spouse
[1] "Fred"

$family$children
[1] 3

$family$child.ages
[1] 4 7 9


$family
$family$spouse
[1] "Mary"

$family$children
[1] 2

$family$child.ages
[1] 14 17


> Empl[c(2,4)]$family  #>> notice only picks the first object
$spouse
[1] "Fred"

$children
[1] 3

$child.ages
[1] 4 7 9


To get multiple objects, then you need to use some of the 'apply'
functions; in this case 'sapply':

 > sapply(Empl[c(2,4)], '[[', 'spouse')
family family
"Fred" "Mary"



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Oct 4, 2015 at 2:31 PM, FERNANDO MANSITO CABALLERO <
fernando.mansito at gmail.com> wrote:

> Dear Madam/Sir,
>
> I  am   trying to understand  R and I have come to a stumbling block. i
> have written:
>
> >Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
> +child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
> +child.ages=c(14,17)))
> >Empl[c(2,4)]$family$spouse
> [1] "Fred"
> >#instead of [1] "Fred" "Mary"
>
> Where am I wrong?
>
> Thank you very much for your patience
> Yours truly,
> Fernando Mansito
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Sun Oct  4 21:49:33 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Sun, 4 Oct 2015 19:49:33 +0000
Subject: [R] (no subject)
Message-ID: <248E6FA047A8C746BA491485764190F52209DF19@ESESSMB210.ericsson.se>

Good question.

> str(Empl[c(2,4)])
List of 2
$ family:List of 3
  ..$ spouse    : chr "Fred"
  ..$ children  : num 3
  ..$ child.ages: num [1:3] 4 7 9
$ family:List of 3
  ..$ spouse    : chr "Mary"
  ..$ children  : num 2
  ..$ child.ages: num [1:2] 14 17
>

> Empl[c(2,4)][1]
$family
$family$spouse
[1] "Fred"

$family$children
[1] 3

$family$child.ages
[1] 4 7 9


> Empl[c(2,4)][2]
$family
$family$spouse
[1] "Mary"

$family$children
[1] 2

$family$child.ages
[1] 14 17


> Empl[c(2,4)][[1]][1]
$spouse
[1] "Fred"

> Empl[c(2,4)][[2]][1]
$spouse
[1] "Mary"


> Empl[c(2,4)][[1]]$spouse
[1] "Fred"


> Empl[c(2,4)][[2]]$spouse
[1] "Mary"


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Oct  4 22:34:27 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 4 Oct 2015 13:34:27 -0700
Subject: [R] (no subject)
In-Reply-To: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
References: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
Message-ID: <BDCF159C-6A73-4C98-89D1-2D108E08A69B@comcast.net>


On Oct 4, 2015, at 11:31 AM, FERNANDO MANSITO CABALLERO wrote:

> Dear Madam/Sir,
> 
> I  am   trying to understand  R and I have come to a stumbling block. i
> have written:
> 
>> Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
> +child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
> +child.ages=c(14,17)))
>> $family$spouse
> [1] "Fred"
>> #instead of [1] "Fred" "Mary"
> 
> Where am I wrong?

The $ function is short-hand for "[[" (with an unevaluated argument). The "[[" function is not able to deliver multiple values. You might think you needed to use:

sapply( Empl[c(2,4)], function(x){ x$family$spouse )


And you cannot use that construction or its equivalent, because sapply and lapply do not pass the names of their arguments:

> sapply( Empl[c(2,4)], function(x){ x[['family']]['spouse']} )
$family
NULL

$family
NULL

#-----------


This succeeds:

> sapply( Empl[grepl('family', names(Empl)) ], function(x){x$spouse})
family family 
"Fred" "Mary" 


-- 

David Winsemius
Alameda, CA, USA


From jw at witch.westfalen.de  Sun Oct  4 21:31:26 2015
From: jw at witch.westfalen.de (Jutta Wrage)
Date: Sun, 4 Oct 2015 21:31:26 +0200
Subject: [R] Barplot - Beginners Question
Message-ID: <369EDEDA-BAA4-4A79-B055-85FFBE44F1A4@witch.westfalen.de>

Hi!

According to this I tried to create a barplot:

https://de.wikibooks.org/wiki/GNU_R:_barplot

Input Data (Tab delimeted)

Range   Anzahl  Prozent
36-40   12      1.92
41-45   21      3.36
46-50   48      7.68
51-55   87      13.92
56-60   92      14.72
61-65   131     20.96
66-70   67      10.72

I read the table using this command:
> datentabelle <- read.table( "stats-test.txt", header = TRUE, sep = "\t", dec = ".", row.names=1)
> datentabelle
      Anzahl Prozent
36-40     12    1.92
41-45     21    3.36
46-50     48    7.68
51-55     87   13.92
56-60     92   14.72
61-65    131   20.96
66-70     67   10.72
71-75     52    8.32
76-80     25    4.00
> is.data.frame(datentabelle)
[1] TRUE
>

Looking ate the table it looks like VADeaths

Then I try to plot as described in wikibooks

> barplot(datentabelle[,1], main= "Altersverteilung")

The plot I get looks lie that using VADeaths with one difference:
I do not ret the rownames in my table as labels for the bars

So what am I missing?

I expect something like I get from
> barplot(VADeaths[,1], main= "Altersverteilung")

Jutta



--
http://www.witch.westfalen.de

-------------- n?chster Teil --------------
Ein Dateianhang mit Bin?rdaten wurde abgetrennt...
Dateiname   : signature.asc
Dateityp    : application/pgp-signature
Dateigr??e  : 234 bytes
Beschreibung: Message signed with OpenPGP using GPGMail
URL         : <https://stat.ethz.ch/pipermail/r-help/attachments/20151004/ee568d85/attachment.bin>

From murdoch.duncan at gmail.com  Mon Oct  5 01:39:54 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 4 Oct 2015 19:39:54 -0400
Subject: [R] Barplot - Beginners Question
In-Reply-To: <369EDEDA-BAA4-4A79-B055-85FFBE44F1A4@witch.westfalen.de>
References: <369EDEDA-BAA4-4A79-B055-85FFBE44F1A4@witch.westfalen.de>
Message-ID: <5611B8CA.3020304@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

On 04/10/2015 3:31 PM, Jutta Wrage wrote:
> Hi!
> 
> According to this I tried to create a barplot:
> 
> https://de.wikibooks.org/wiki/GNU_R:_barplot
> 
> Input Data (Tab delimeted)
> 
> Range   Anzahl  Prozent 36-40   12      1.92 41-45   21      3.36 
> 46-50   48      7.68 51-55   87      13.92 56-60   92      14.72 
> 61-65   131     20.96 66-70   67      10.72
> 
> I read the table using this command:
>> datentabelle <- read.table( "stats-test.txt", header = TRUE, sep
>> = "\t", dec = ".", row.names=1) datentabelle
> Anzahl Prozent 36-40     12    1.92 41-45     21    3.36 46-50
> 48    7.68 51-55     87   13.92 56-60     92   14.72 61-65    131
> 20.96 66-70     67   10.72 71-75     52    8.32 76-80     25
> 4.00
>> is.data.frame(datentabelle)
> [1] TRUE
>> 
> 
> Looking ate the table it looks like VADeaths
> 
> Then I try to plot as described in wikibooks
> 
>> barplot(datentabelle[,1], main= "Altersverteilung")
> 
> The plot I get looks lie that using VADeaths with one difference: I
> do not ret the rownames in my table as labels for the bars
> 
> So what am I missing?

Your data is a dataframe, VADeaths is a matrix.  For some dim
historical reason, pulling a column from a matrix keeps the row names,
but pulling a column from a dataframe doesn't.

You'll get what you want if you use as.matrix(datentabelle)[,1]
instead of datentabelle[,1].

Duncan Murdoch

> 
> I expect something like I get from
>> barplot(VADeaths[,1], main= "Altersverteilung")
> 
> Jutta
> 
> 
> 
> -- http://www.witch.westfalen.de
> 
> 
> 
> ______________________________________________ R-help at r-project.org
> mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
> posting guide http://www.R-project.org/posting-guide.html and
> provide commented, minimal, self-contained, reproducible code.
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG/MacGPG2 v2
Comment: GPGTools - https://gpgtools.org

iQEcBAEBCgAGBQJWEbjKAAoJEHE2Kz23YMZyx8sH/iX62bx7uRmXHFSbJbYMBUxf
+WTDZyO0nQFq8fLwti2NWuTchWvu/hBoIWheIGPCe7xF9ApoJydHmAc4DIf6xoqT
nngQS2F9mGyjgfMagnH68pvMI/W8bwOW3VIJ2nb5nhpSPF/yQZsKLewcyI+L1uiZ
uDPeol7Ig6ij7amGnz4haa1g7wRhUp/mAcFn8gBuDOh5Y4vFpqdba1NcRUQP5Kj8
4x+wN4eKqX0uT2IV0GkGfNT1R4sYR6g+Ardml+vQZ5E+fRrZxi6SoOSRWgptiBAM
cqad7Mfll6RdPWTVCwTlctTYw0arIzNsMaUoG7E+QlcbKviMCNx8IRZUScJP/5c=
=B1u9
-----END PGP SIGNATURE-----


From boris.steipe at utoronto.ca  Mon Oct  5 03:59:36 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 4 Oct 2015 21:59:36 -0400
Subject: [R] Barplot - Beginners Question
In-Reply-To: <5611B8CA.3020304@gmail.com>
References: <369EDEDA-BAA4-4A79-B055-85FFBE44F1A4@witch.westfalen.de>
	<5611B8CA.3020304@gmail.com>
Message-ID: <4714F5F2-E90D-4C31-8C76-144316B2BF14@utoronto.ca>

On Oct 4, 2015, at 7:39 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> You'll get what you want if you use as.matrix(datentabelle)[,1]
> instead of datentabelle[,1].

This happens to work in this particular case, but fails if the data frame contains text columns.
Example:
   datentabelle <- cbind(datentabelle, text = sample(letters, nrow(datentabelle)))
   barplot(as.matrix(datentabelle)[,1])
   R>  Error in -0.01 * height : non-numeric argument to binary operator

Therefore I would get the row names from your data frame with rownames(datentabelle), and use them as the names.arg argument of barplot():

  barplot(datentabelle[,1], names.arg=rownames(datentabelle))

Cheers,
Boris


From dulcalma at bigpond.com  Mon Oct  5 04:55:29 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Mon, 5 Oct 2015 12:55:29 +1000
Subject: [R] lattice plot: points and lines for different variables in
	same plotlattice plot
In-Reply-To: <SNT150-W5747367DCE430E534944D5FA490@phx.gbl>
References: <SNT150-W5747367DCE430E534944D5FA490@phx.gbl>
Message-ID: <000d01d0ff19$4b436e40$e1ca4ac0$@bigpond.com>

Hi Naresh

Try

xyplot(y + y.fit ~ x | name, data = my.df,
         type = c("p","l"),
         distribute.type = TRUE,
         panel = panel.superpose
)

Your code seems to be a direct copy from the command line; sometimes it
makes it clearer to arguments and functions within the panel function on
their own line

Regards
Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Naresh
Gurbuxani
Sent: Monday, 5 October 2015 05:30
To: r-help at r-project.org
Subject: [R] lattice plot: points and lines for different variables in same
plotlattice plot

I want to draw scatter plot and a fitted line in the same lattice plot.  My
problem is that either both can be plotted as points or both as lines.  The
code that attempts to plot points for data and lines for fitted line does
not work.  

Thanks,
Naresh

library(lattice)
library(plyr)

my.df <- data.frame(x = rnorm(100), y = rnorm(100), name = "A")

temp.df <- data.frame(x = rnorm(100), name = "B")
temp.df <- within(temp.df, {y <- x + 0.2 * rnorm(100)})
my.df <- rbind(my.df, temp.df)

temp.df <- data.frame(x = rnorm(100), name = "C")
temp.df <- within(temp.df, {y <- x + 0.5 * x^2 + 0.2 * rnorm(100)})
my.df <- rbind(my.df, temp.df)

my.df <- ddply(my.df, c("name"), mutate, y.fit = lm(y ~ x +
I(x^2))$fitted.values)

my.df <- my.df[order(my.df$name, my.df$x),]

# This works
xyplot(y + y.fit ~ x | name, data = my.df, type = c("l"))

# This does not work.  Line plot seems wrong.
xyplot(y + y.fit ~ x | name, data = my.df, type = c("l"), y.prime =
my.df$y.fit, panel = function(x, y, y.prime, ...){panel.xyplot(x, y);
panel.lines(x, y.prime, type = "l")})


 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Bernhard_Pfaff at fra.invesco.com  Mon Oct  5 09:39:57 2015
From: Bernhard_Pfaff at fra.invesco.com (Pfaff, Bernhard Dr.)
Date: Mon, 5 Oct 2015 07:39:57 +0000
Subject: [R] Johansen Test of Cointegration:How to access rows in R
 output
In-Reply-To: <CAHVFrXH6NJZ9i-zH5uQ5NpVjy3V0b3+yT0jCdxm9kPus7HDaJg@mail.gmail.com>
References: <CAHVFrXH6NJZ9i-zH5uQ5NpVjy3V0b3+yT0jCdxm9kPus7HDaJg@mail.gmail.com>
Message-ID: <FCD9A33C859ACC469587CB09DD5C6C711348E47E@GBLONXMB13.corp.amvescap.net>

RTFM: help("ca.jo-class")

library(urca)
example(ca.jo)
class(sjf.vecm)
slotNames(sjf.vecm)
slot(sjf.vecm, "cval")
slot(sjf.vecm, "teststat")
slot(sjf.vecm, "V")
slot(sjf.vecm, "Vorg")

Best,
Bernhard

-----Urspr?ngliche Nachricht-----
Von: R-help [mailto:r-help-bounces at r-project.org] Im Auftrag von Preetam Pal
Gesendet: Sonntag, 4. Oktober 2015 18:43
An: r-help at r-project.org
Betreff: [R] Johansen Test of Cointegration:How to access rows in R output

Hi guys,

I ran ca.jo(data,type="trace", ecdet="none",k=2) i.e. Johansen's Trace test on R-Studio (package: "urca")and got the output below:

I have 3 questions about this:

A> How do I programmatically access the columns("test", "10pct" etc) in 
A> any
row corresponding to, say, r < = 1 in the output?  I mean, I shall only provide the r-value as an input and all the (column name, column value) pairs will be outputted to me.

B> How do I write a code that will check if the null hypotheses for r 
B> =0,
<= 1, <= 2 and so on  (in this order) are rejected or not; and in case one of them is rejected, it checks the next higher value of r and gives the final inference , something like "Null not rejected for r <= *appropriate r-value from this table* " or "All nulls rejected" or "No null rejected'.

C> Also, I need to extract the eigen vectors from the Cointegration 
C> Matrix
below to get the cointegrated transfoms.

I have attached the data for your perusal. If I need to provide anything more, please let me know.

Regards,
Preetam

######################
# Johansen-Procedure #
######################

Test type: trace statistic , with linear trend in cointegration

Eigenvalues (lambda):
[1] 7.935953e-01 5.444372e-01 4.985327e-01 2.562245e-01 5.551115e-16

Values of teststatistic and critical values of test:

          test 10pct  5pct  1pct
r <= 3 |  6.81 10.49 12.25 16.26
r <= 2 | 22.68 22.76 25.32 30.45
r <= 1 | 40.77 39.06 42.44 48.45
r = 0  | 77.06 59.14 62.99 70.05

Eigenvectors, normalised to first column:
(These are the cointegration relations)

               GDP.l2     HPA.l2       FX.l2        Y.l2   trend.l2
GDP.l2    1.000000000  1.0000000  1.00000000  1.00000000  1.0000000
HPA.l2    2.525511110  0.1569079  0.08077351 -0.22777550 -0.9178250
FX.l2    -8.643729121 -2.5815150  0.17158404 -0.47053012 -4.8528875
Y.l2      0.805229998 -1.4241546  0.07767540  0.02303305  0.5213294
trend.l2  0.006283314  0.0385276 -0.01512016  0.01986813 -0.9516072

Weights W:
(This is the loading matrix)

           GDP.l2      HPA.l2      FX.l2        Y.l2      trend.l2
GDP.d  0.03055313 -0.04681978 -0.8376985 -0.04220534 -1.271960e-17 HPA.d -0.22649596 -0.24287691 -1.6358880  2.03813569 -8.002467e-17
FX.d   0.10327579  0.15150469 -0.1649066  0.37449910 -2.570250e-18
Y.d   -0.35200485  0.56808024 -5.7829738  0.01000965  1.730461e-16
*****************************************************************
Confidentiality Note: The information contained in this message,
and any attachments, may contain confidential and/or privileged
material. It is intended solely for the person(s) or entity to
which it is addressed. Any review, retransmission, dissemination,
or taking of any action in reliance upon this information by
persons or entities other than the intended recipient(s) is
prohibited. If you received this in error, please contact the
sender and delete the material from any computer.
*****************************************************************

From jw at witch.westfalen.de  Mon Oct  5 10:36:28 2015
From: jw at witch.westfalen.de (Jutta Wrage)
Date: Mon, 5 Oct 2015 10:36:28 +0200
Subject: [R] Package Installation: Repository for 3.2.1
Message-ID: <87E6DD5F-0F90-4303-89D4-843C992DAC83@witch.westfalen.de>

Hi!

Guess, I got in trouble somehow now.
Not sure whether this question is placed well in this list. Do I have to ask my question in R-SIG-MAC?

Installed R version: 3.2.1 for OS X up to 10.8

I did update the package list from within R application and installed some new package versions.

Now I get a warning:

Warnmeldung:
Paket ?knitr? wurde unter R Version 3.2.2 erstellt
3.2.2 is only available for OS X up from 10.9

1. Which URL do I have to put in preferences to get only packages for my Computer?
2. How do I repair things now? - If needed

> library()
tells me everything is in ?/Library/Frameworks/R.framework/Versions/3.2/Resources/library?

Jutta


--
http://www.witch.westfalen.de

-------------- n?chster Teil --------------
Ein Dateianhang mit Bin?rdaten wurde abgetrennt...
Dateiname   : signature.asc
Dateityp    : application/pgp-signature
Dateigr??e  : 234 bytes
Beschreibung: Message signed with OpenPGP using GPGMail
URL         : <https://stat.ethz.ch/pipermail/r-help/attachments/20151005/03473c23/attachment.bin>

From lordpreetam at gmail.com  Mon Oct  5 17:27:02 2015
From: lordpreetam at gmail.com (Preetam Pal)
Date: Mon, 5 Oct 2015 20:57:02 +0530
Subject: [R] Quantile Regression without intercept
Message-ID: <56129643.aa9f420a.9f59f.08b9@mx.google.com>

Hi guys, 

Can you instruct me please how to run quantile regression without the intercept term? I only know about the rq function under quantreg package, but it automatically uses an intercept model. Icant change that, it seems.

I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and Unemployment). Their sizes are 125 each.

Appreciate your help with this.

Regards, 
Preetam
	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Mon Oct  5 17:27:09 2015
From: hannah.hlx at gmail.com (li li)
Date: Mon, 5 Oct 2015 11:27:09 -0400
Subject: [R] correlated binomial random variables
Message-ID: <CAHLnndZdzs1AJ5cTMHbsucJt=QYq8h+p0TS71b5+0J1JV_W=KQ@mail.gmail.com>


From rkoenker at illinois.edu  Mon Oct  5 17:28:57 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Mon, 5 Oct 2015 10:28:57 -0500
Subject: [R] Quantile Regression without intercept
In-Reply-To: <ed257460dfaa42c89970e0068c65c4e9@CITESHT3.ad.uillinois.edu>
References: <ed257460dfaa42c89970e0068c65c4e9@CITESHT3.ad.uillinois.edu>
Message-ID: <B9C6617E-AB10-44A2-94B7-5BF2CCA1D526@illinois.edu>

as for lm()  or any other linear model fitting?.

	rq( y ~ x - 1, ? )


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Oct 5, 2015, at 10:27 AM, Preetam Pal <lordpreetam at gmail.com> wrote:
> 
> Hi guys, 
> 
> Can you instruct me please how to run quantile regression without the intercept term? I only know about the rq function under quantreg package, but it automatically uses an intercept model. Icant change that, it seems.
> 
> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and Unemployment). Their sizes are 125 each.
> 
> Appreciate your help with this.
> 
> Regards, 
> Preetam
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ssefick at gmail.com  Mon Oct  5 17:31:27 2015
From: ssefick at gmail.com (stephen sefick)
Date: Mon, 5 Oct 2015 10:31:27 -0500
Subject: [R] Quantile Regression without intercept
In-Reply-To: <56129643.aa9f420a.9f59f.08b9@mx.google.com>
References: <56129643.aa9f420a.9f59f.08b9@mx.google.com>
Message-ID: <CADKEMqg+qu81n5nKnbaWST=+LftJf2rFkntGXWYz_D0QDOgWAw@mail.gmail.com>

I have never used this, but does the formula interface work like lm? Y~X-1?

On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com> wrote:

> Hi guys,
>
> Can you instruct me please how to run quantile regression without the
> intercept term? I only know about the rq function under quantreg package,
> but it automatically uses an intercept model. Icant change that, it seems.
>
> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
> Unemployment). Their sizes are 125 each.
>
> Appreciate your help with this.
>
> Regards,
> Preetam
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From lordpreetam at gmail.com  Mon Oct  5 17:44:04 2015
From: lordpreetam at gmail.com (Preetam Pal)
Date: Mon, 5 Oct 2015 21:14:04 +0530
Subject: [R] Quantile Regression without intercept
In-Reply-To: <CADKEMqg+qu81n5nKnbaWST=+LftJf2rFkntGXWYz_D0QDOgWAw@mail.gmail.com>
References: <56129643.aa9f420a.9f59f.08b9@mx.google.com>
	<CADKEMqg+qu81n5nKnbaWST=+LftJf2rFkntGXWYz_D0QDOgWAw@mail.gmail.com>
Message-ID: <56129a41.025f440a.b1cf4.fffff5ee@mx.google.com>

Yes..it works. .... Thanks ?? 

-----Original Message-----
From: "stephen sefick" <ssefick at gmail.com>
Sent: ?05-?10-?2015 09:01 PM
To: "Preetam Pal" <lordpreetam at gmail.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] Quantile Regression without intercept

I have never used this, but does the formula interface work like lm? Y~X-1?


On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com> wrote:

Hi guys,

Can you instruct me please how to run quantile regression without the intercept term? I only know about the rq function under quantreg package, but it automatically uses an intercept model. Icant change that, it seems.

I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and Unemployment). Their sizes are 125 each.

Appreciate your help with this.

Regards,
Preetam
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.






-- 

Stephen Sefick
**************************************************
Auburn University                                         
Biological Sciences                                      
331 Funchess Hall                                       
Auburn, Alabama                                        
36849                                                           
**************************************************
sas0025 at auburn.edu                                  
http://www.auburn.edu/~sas0025                 
**************************************************

Let's not spend our time and resources thinking about things that are so little or so large that all they really do for us is puff us up and make us feel like gods.  We are mammals, and have not exhausted the annoying little problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal science."

                              -Robert Gentleman
	[[alternative HTML version deleted]]


From hannah.hlx at gmail.com  Mon Oct  5 17:43:59 2015
From: hannah.hlx at gmail.com (li li)
Date: Mon, 5 Oct 2015 11:43:59 -0400
Subject: [R] correlated binomial random variables
In-Reply-To: <CAHLnndZdzs1AJ5cTMHbsucJt=QYq8h+p0TS71b5+0J1JV_W=KQ@mail.gmail.com>
References: <CAHLnndZdzs1AJ5cTMHbsucJt=QYq8h+p0TS71b5+0J1JV_W=KQ@mail.gmail.com>
Message-ID: <CAHLnndbYXB=QKNM4vb67rZYvSo7z4XpLCoMgeWy-rsnpZirW5w@mail.gmail.com>

Hi all,
   Using the "bindata" package, it is possible to gerenerate
correlated binomial random variables both with the same number of
trials, say n. I am wondering whether there is an R function to
calculate the joint probability distribution of the correlated
binomial random variables. Say if X is binomial (n, p1) and Y is
binomial (n, p2) and the correlation between X and Y is rho and we
want to calculate
P(X <= c, Y <= c).
   Thanks so much!
     Hanna

2015-10-05 11:27 GMT-04:00, li li <hannah.hlx at gmail.com>:
>
>


From ii54250 at msn.com  Mon Oct  5 18:10:29 2015
From: ii54250 at msn.com (IOANNA IOANNOU)
Date: Mon, 5 Oct 2015 17:10:29 +0100
Subject: [R] Change values of a column based on the values of a third
Message-ID: <DUB116-DS77AE0083D0EC264CF962FF3480@phx.gbl>

Hello all, 

 

I have a rather easy question. I want to add a column to the database which
will change the values of vector a based on the values to vector b. Any
ideas how?

 

For example:

 

Dat <- data.frame(a= c('A','A','C','B','D','D','B'),

                                  b= c('N','N','Y','N','Y','N','N') )

 

I want to add a column c which will change 'C' to 'D' if column b is 'Y'.

 


> Dat

  a b c

1 A N A

2 A N A

3 C Y D

4 B N B

5 C Y D

6 C N C

7 B N B

	


Any ideas?

 

Best, 

ioanna

 


	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Mon Oct  5 18:40:16 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 5 Oct 2015 12:40:16 -0400
Subject: [R] Change values of a column based on the values of a third
In-Reply-To: <DUB116-DS77AE0083D0EC264CF962FF3480@phx.gbl>
References: <DUB116-DS77AE0083D0EC264CF962FF3480@phx.gbl>
Message-ID: <CAM_vju=nYTMvq3XSd8cez=WPBqP74e0NRqJcFG5ZW2oe1Zm2gg@mail.gmail.com>

?ifelse

I changed Dat to a. have character type instead of factor, and b.
actually match what you show in your example instead of already having
D.

Dat <- data.frame(a= c('A','A','C','B','C','C','B'),
b= c('N','N','Y','N','Y','N','N'), stringsAsFactors=FALSE )

Dat$c <- with(Dat, ifelse(b == "Y" & a == "C", "D", a))

In general, I'd recommend you read one of the many excellent R
introductory guides out there.

On Mon, Oct 5, 2015 at 12:10 PM, IOANNA IOANNOU <ii54250 at msn.com> wrote:
> Hello all,
>
>
>
> I have a rather easy question. I want to add a column to the database which
> will change the values of vector a based on the values to vector b. Any
> ideas how?
>
>
>
> For example:
>
>
>
> Dat <- data.frame(a= c('A','A','C','B','D','D','B'),
>
>                                   b= c('N','N','Y','N','Y','N','N') )
>
>
>
> I want to add a column c which will change 'C' to 'D' if column b is 'Y'.
>
>
>
>
>> Dat
>
>   a b c
>
> 1 A N A
>
> 2 A N A
>
> 3 C Y D
>
> 4 B N B
>
> 5 C Y D
>
> 6 C N C
>
> 7 B N B
>
>
>
>
> Any ideas?
>
>
>
> Best,
>
> ioanna
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Mon Oct  5 18:42:09 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 05 Oct 2015 09:42:09 -0700
Subject: [R] Change values of a column based on the values of a third
In-Reply-To: <DUB116-DS77AE0083D0EC264CF962FF3480@phx.gbl>
References: <DUB116-DS77AE0083D0EC264CF962FF3480@phx.gbl>
Message-ID: <983A923D-A7FD-46AE-92F1-7A12B2FD3920@dcn.davis.CA.us>

Either

Dat$c <- ifelse( "Y"==Dat$b, rep( "D", nrow(Dat) ), Dat$a )

Or (more efficiently)

Dat$c <- Dat$a
Dat$c[ "Y"==Dat$b ] <- "D"

Also, beware of creating data frames without using the stringsAsFactors=FALSE option if you plan to replace levels like this.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 5, 2015 9:10:29 AM PDT, IOANNA IOANNOU <ii54250 at msn.com> wrote:
>Hello all, 
>
> 
>
>I have a rather easy question. I want to add a column to the database
>which
>will change the values of vector a based on the values to vector b. Any
>ideas how?
>
> 
>
>For example:
>
> 
>
>Dat <- data.frame(a= c('A','A','C','B','D','D','B'),
>
>                                  b= c('N','N','Y','N','Y','N','N') )
>
> 
>
>I want to add a column c which will change 'C' to 'D' if column b is
>'Y'.
>
> 
>
>
>> Dat
>
>  a b c
>
>1 A N A
>
>2 A N A
>
>3 C Y D
>
>4 B N B
>
>5 C Y D
>
>6 C N C
>
>7 B N B
>
>	
>
>
>Any ideas?
>
> 
>
>Best, 
>
>ioanna
>
> 
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Oct  5 19:00:52 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Oct 2015 10:00:52 -0700
Subject: [R] Package Installation: Repository for 3.2.1
In-Reply-To: <87E6DD5F-0F90-4303-89D4-843C992DAC83@witch.westfalen.de>
References: <87E6DD5F-0F90-4303-89D4-843C992DAC83@witch.westfalen.de>
Message-ID: <346635FD-2A34-4023-8D0F-EFDDA9781FD4@comcast.net>


On Oct 5, 2015, at 1:36 AM, Jutta Wrage wrote:

> Hi!
> 
> Guess, I got in trouble somehow now.
> Not sure whether this question is placed well in this list. Do I have to ask my question in R-SIG-MAC?
> 
> Installed R version: 3.2.1 for OS X up to 10.8
> 
> I did update the package list from within R application and installed some new package versions.
> 
> Now I get a warning:
> 
> Warnmeldung:
> Paket ?knitr? wurde unter R Version 3.2.2 erstellt
> 3.2.2 is only available for OS X up from 10.9
> 
> 1. Which URL do I have to put in preferences to get only packages for my Computer?
> 2. How do I repair things now? - If needed

It's only a warning. There's no simple method for getting binary packages for older R versions. Generally packages built with a minor version upgrade will still work with one version back (but I have no experience doing that with knitr). You can build older packages from the source files in the Archives if needed. 

Things might become more problematic in the future if you stay with OSX version 10.8, because I don't know if the dual SnowLeppard and Mavericks forks will continue to be maintained. It was announced very recently that the build machine was now running El Capitan, i.e. OSX 10.11

You should ask Mac specific questions on R-SIG-Mac.


> 
>> library()
> tells me everything is in ?/Library/Frameworks/R.framework/Versions/3.2/Resources/library?
> 
> Jutta
> 


David Winsemius
Alameda, CA, USA


From fernando.mansito at gmail.com  Mon Oct  5 17:58:19 2015
From: fernando.mansito at gmail.com (FERNANDO MANSITO CABALLERO)
Date: Mon, 5 Oct 2015 17:58:19 +0200
Subject: [R] (no subject)
In-Reply-To: <BDCF159C-6A73-4C98-89D1-2D108E08A69B@comcast.net>
References: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
	<BDCF159C-6A73-4C98-89D1-2D108E08A69B@comcast.net>
Message-ID: <CABOXfwM72j_7BLATLXFC00jyjv2f_46cg2MP=0Rn2n0wdVMCPA@mail.gmail.com>

Hi

Thanks a lot to all of you for your solutions and explanations.

On Sun, Oct 4, 2015 at 10:34 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Oct 4, 2015, at 11:31 AM, FERNANDO MANSITO CABALLERO wrote:
>
> > Dear Madam/Sir,
> >
> > I  am   trying to understand  R and I have come to a stumbling block. i
> > have written:
> >
> >> Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
> >
> +child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
> > +child.ages=c(14,17)))
> >> $family$spouse
> > [1] "Fred"
> >> #instead of [1] "Fred" "Mary"
> >
> > Where am I wrong?
>
> The $ function is short-hand for "[[" (with an unevaluated argument). The
> "[[" function is not able to deliver multiple values. You might think you
> needed to use:
>
> sapply( Empl[c(2,4)], function(x){ x$family$spouse )
>
>
> And you cannot use that construction or its equivalent, because sapply and
> lapply do not pass the names of their arguments:
>
> > sapply( Empl[c(2,4)], function(x){ x[['family']]['spouse']} )
> $family
> NULL
>
> $family
> NULL
>
> #-----------
>
>
> This succeeds:
>
> > sapply( Empl[grepl('family', names(Empl)) ], function(x){x$spouse})
> family family
> "Fred" "Mary"
>
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From rm.tech at mac.com  Mon Oct  5 16:03:45 2015
From: rm.tech at mac.com (R Martinez)
Date: Mon, 05 Oct 2015 07:03:45 -0700
Subject: [R] Does R work on Mac OS 10.11?
Message-ID: <8E76D1C8-29E6-4072-9F8A-836944FAB2A3@mac.com>

Has anyone tried to use R 3.2.2 on a Mac running OS 10.11 El Capitan? Did it work? Were any problems installing and running it?

Thanks in advance,

Raul Martinez 




Sent from my iPad 4

From asengupta94404 at yahoo.com  Mon Oct  5 21:14:33 2015
From: asengupta94404 at yahoo.com (Amit Sengupta)
Date: Mon, 5 Oct 2015 19:14:33 +0000 (UTC)
Subject: [R] preprocessing problem
Message-ID: <401722906.832178.1444072473467.JavaMail.yahoo@mail.yahoo.com>

Hi,I am having a problem with the ReadAffy() in the university R programming environment. I install affyPLM and invoke library(affyPLM) in the following way. I have the cel files in the craig subdirectory. Please let me know how to resolve the problem.Amit
source("http://bioconductor.org/biocLite.R")  biocLite("affyPLM") biocLite("gcrma") library(affyPLM)> setwd("c:/Users/amit.sengupta/Desktop/myRfolder/craig")
> craig.data=ReadAffy()
Error in AllButCelsForReadAffy(..., filenames = filenames, widget = widget,? : 
? No cel filennames specified and no cel files in specified directory:c:/Users/amit.sengupta/Desktop/myRfolder/craig
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Oct  6 00:00:58 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 6 Oct 2015 11:00:58 +1300
Subject: [R] [FORGED] Re:  correlated binomial random variables
In-Reply-To: <CAHLnndbYXB=QKNM4vb67rZYvSo7z4XpLCoMgeWy-rsnpZirW5w@mail.gmail.com>
References: <CAHLnndZdzs1AJ5cTMHbsucJt=QYq8h+p0TS71b5+0J1JV_W=KQ@mail.gmail.com>
	<CAHLnndbYXB=QKNM4vb67rZYvSo7z4XpLCoMgeWy-rsnpZirW5w@mail.gmail.com>
Message-ID: <5612F31A.6040108@auckland.ac.nz>

On 06/10/15 04:43, li li wrote:
> Hi all,
>     Using the "bindata" package, it is possible to gerenerate
> correlated binomial random variables both with the same number of
> trials, say n. I am wondering whether there is an R function to
> calculate the joint probability distribution of the correlated
> binomial random variables. Say if X is binomial (n, p1) and Y is
> binomial (n, p2) and the correlation between X and Y is rho and we
> want to calculate
> P(X <= c, Y <= c).

(1) The use of correlation in the context of binary or binomial variates 
makes little or no sense, it seems to me.  Correlation is basically 
useful for quantifying linear relationships between continuous variates. 
Linear relationships between count variates are of at best limited interest.

(2) I suspect that the correlation does not determine a unique joint 
distribution of X and Y.  If my suspicion is correct then there is not a 
unique (well-defined) answer to the question "What is
Pr(X <= x, Y <= y)?"

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bob at rudis.net  Tue Oct  6 00:01:38 2015
From: bob at rudis.net (boB Rudis)
Date: Mon, 5 Oct 2015 18:01:38 -0400
Subject: [R] Does R work on Mac OS 10.11?
In-Reply-To: <8E76D1C8-29E6-4072-9F8A-836944FAB2A3@mac.com>
References: <8E76D1C8-29E6-4072-9F8A-836944FAB2A3@mac.com>
Message-ID: <CAJ4QxaM5RfOryZMG6yRpc09C3u0M+HD1x0K1wKr9Uv=Aofs1Xw@mail.gmail.com>

I use it daily (hourly, really) on 10.11 (including the new betas). No issues.

On Mon, Oct 5, 2015 at 10:03 AM, R Martinez <rm.tech at mac.com> wrote:
> Has anyone tried to use R 3.2.2 on a Mac running OS 10.11 El Capitan? Did it work? Were any problems installing and running it?
>
> Thanks in advance,
>
> Raul Martinez
>
>
>
>
> Sent from my iPad 4
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Oct  6 00:03:55 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Oct 2015 15:03:55 -0700
Subject: [R] Does R work on Mac OS 10.11?
In-Reply-To: <8E76D1C8-29E6-4072-9F8A-836944FAB2A3@mac.com>
References: <8E76D1C8-29E6-4072-9F8A-836944FAB2A3@mac.com>
Message-ID: <1D86E2F2-1359-4A4D-907C-89B540A06707@comcast.net>

Prof Ripley made an announcement on R-SIG-Mac that the development machine was recently (as in yesterday)  changed to El Capitan.

https://stat.ethz.ch/pipermail/r-sig-mac/2015-October/011632.html

You should subscribe to the correct mailing list.


On Oct 5, 2015, at 7:03 AM, R Martinez wrote:

> Has anyone tried to use R 3.2.2 on a Mac running OS 10.11 El Capitan? Did it work? Were any problems installing and running it?
> 
> Thanks in advance,
> 
> Raul Martinez 
> _______________________________________________

R-SIG-Mac mailing list
R-SIG-Mac at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-mac

-- 

David Winsemius
Alameda, CA, USA


From climberjeff at gmail.com  Tue Oct  6 00:20:51 2015
From: climberjeff at gmail.com (Jeff Tostenrude)
Date: Mon, 5 Oct 2015 15:20:51 -0700
Subject: [R] scatter3d
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F2B6A0@FHSDB2D11-2.csu.mcmaster.ca>
References: <CAAcp1BcvPMFvnWpY0tBNajsX+6Z-tQ1zaQG91qV3eZURZbDrVQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B42D@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BcKTK5RkrpU8t7stc7jipwNuYGuSQvddse9-FC0U7f-KA@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B5A4@FHSDB2D11-2.csu.mcmaster.ca>
	<CAAcp1BejfYgTzfojaiScQsndfUiG6dHqxoUzzvHS3rahM=azXA@mail.gmail.com>
	<56102B3C.6070203@statistik.tu-dortmund.de>
	<ACD1644AA6C67E4FBD0C350625508EC810F2B6A0@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CAAcp1BdFSZ0SFOrWjM=Qut7OU7Gw9ii6pJYF3-U931DuZx7OoQ@mail.gmail.com>

So once I commented out 12 lines of code in the scatter3d function it
plotted just the planes, as desired. Thanks for the help!

On Sat, Oct 3, 2015 at 12:50 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Uwe,
>
> > -----Original Message-----
> > From: Uwe Ligges [mailto:ligges at statistik.tu-dortmund.de]
> > Sent: October 3, 2015 3:24 PM
> > To: Jeff Tostenrude <climberjeff at gmail.com>; Fox, John <jfox at mcmaster.ca
> >
> > Cc: r-help at r-project.org; Duncan Murdoch <murdoch.duncan at gmail.com>
> > Subject: Re: [R] scatter3d
> >
> >
> >
> > On 03.10.2015 17:53, Jeff Tostenrude wrote:
> > > Thank you for the advice, I will try you suggestions on Monday.
> > >
> > > Uwe, by interactive I just mean the ability to spin the plot.
> >
> > If you can calculate the planes by some functions, I reall suggest to use
> > functions from rgl that are able to plot planes (rather than points).
>
> Indeed, this is what scatter3d() does -- plots regression surfaces,
> including planes, along with points. One approach, as I suggested, is
> simply to get rid of the points, and plot just the regression surfaces.
>
> Best,
>  John
>
> >
> > Best,
> > Uwe Ligges
> >
> > >
> > > On Sat, Oct 3, 2015 at 7:07 AM, Fox, John <jfox at mcmaster.ca
> > > <mailto:jfox at mcmaster.ca>> wrote:
> > >
> > >     Dear Jeff,
> > >
> > >     > -----Original Message-----
> > >     > From: Jeff Tostenrude [mailto:climberjeff at gmail.com
> > <mailto:climberjeff at gmail.com>]
> > >     > Sent: October 2, 2015 11:46 PM
> > >     > To: Fox, John <jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>>
> > >     > Cc:r-help at r-project.org <mailto:r-help at r-project.org>
> > >     > Subject: Re: [R] scatter3d
> > >     >
> > >     > Thank you for the suggestion. Yes, it does seem to be a bit
> counter-
> > intuitive, but
> > >     > that is the output I am being asked to produce. I have only been
> using R for
> > a
> > >     > few weeks, so there is probably a better way to do it.
> > >     >
> > >     > Anyway, your suggestion did work, but only up to 337 data
> points. I am
> > dealing
> > >     > with ~100,000 data points so this doesn't really work for me. Is
> there
> > another
> > >     > method you would suggest? My goal is to plot multiple regression
> planes
> > >     > (without points) in an interactive 3d plot.
> > >
> > >     I don't think that you said in your initial posting that you have
> so
> > >     many points.
> > >
> > >     The scatter3d() function in the car package uses functions in the
> > >     rgl package to draw 3D scatterplots. As Uwe Ligges and Duncan
> > >     Murdoch have pointed out, you can use the rgl package directly to
> > >     make your graph. One approach would be to adapt the scatter3d()
> > >     code, removing the part of the code that plots the points.
> > >
> > >     As Duncan points out, scatter3d(), which was initially written a
> > >     long time ago, uses both older rgl.*() functions and newer, and in
> a
> > >     sense better-behaved, *3d() functions in the rgl package, which
> > >     isn't recommended. Because scatter3d() works properly, I haven't
> > >     changed that (maybe I should). If you write your own function or
> > >     script, you can take Duncan's advice and use only the *3d()
> functions.
> > >
> > >     Best,
> > >       John
> > >
> > >     >
> > >     > Thank you,
> > >     > Jeff
> > >     >
> > >     > On Fri, Oct 2, 2015 at 5:22 PM, Fox, John <jfox at mcmaster.ca
> > <mailto:jfox at mcmaster.ca>
> > >     > <mailto:jfox at mcmaster.ca <mailto:jfox at mcmaster.ca>> > wrote:
> > >     >
> > >     >
> > >     >       Dear Jeff,
> > >     >
> > >     >       I'm tempted to say that a scatterplot without points is an
> oxymoron,
> > but
> > >     > that wouldn't be very helpful.
> > >     >
> > >     >       Actually, the scatter3d() function used by the Rcmdr is in
> the car
> > >     > package. The Rcmdr 3D scatterplot dialog doesn't provide for
> suppressing
> > the
> > >     > points, but if you add radius=rep(0, n) to the command that's
> generated,
> > where
> > >     > you'd replace n with the number of cases in the dataset, that
> would do the
> > trick
> > >     > by plotting spheres of 0 radius. For example, try
> > >     >
> > >     >               scatter3d(prestige ~ income + education,
> data=Duncan,
> > >     > radius=rep(0, 45), residuals=FALSE)
> > >     >
> > >     >       either in the Rcmdr or at the R command prompt.
> > >     >
> > >     >       For more information see ?scatter3d or press the Help
> button in the
> > >     > Rcmdr 3D scatterplot dialog and follow the link to scatter3d.
> > >     >
> > >     >       I hope this helps,
> > >     >        John
> > >     >
> > >     >       -----------------------------
> > >     >       John Fox, Professor
> > >     >       McMaster University
> > >     >       Hamilton, Ontario
> > >     >       Canada L8S 4M4
> > >      >       Web: socserv.mcmaster.ca/jfox
> > >     <http://socserv.mcmaster.ca/jfox> <http://socserv.mcmaster.ca/jfox
> >
> > >     >
> > >     >
> > >     >
> > >     >
> > >     >       > -----Original Message-----
> > >     >       > From: R-help [mailto:r-help-bounces at r-project.org
> <mailto:r-help-
> > bounces at r-project.org>
> > >     <mailto:r-help- <mailto:r-help->
> > >     >bounces at r-project.org <mailto:bounces at r-project.org>> ] On
> Behalf Of
> > >     Jeff
> > >     >       > Tostenrude
> > >     >       > Sent: October 2, 2015 7:34 PM
> > >     >       > To:r-help at r-project.org <mailto:r-help at r-project.org>
> > >     <mailto:r-help at r-project.org <mailto:r-help at r-project.org>>
> > >     >       > Subject: [R] scatter3d
> > >     >       >
> > >     >       > I am using scatter3d in R Commander to plot a group of
> regression
> > >     > surfaces.
> > >     >       > However, I only want to display the surfaces. How do I
> remove the
> > >     > points?
> > >     >       >
> > >     >
> > >     >       >       [[alternative HTML version deleted]]
> > >     >       >
> > >     >       > ______________________________________________
> > >      >       > R-help at r-project.org <mailto:R-help at r-project.org>
> > >     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
> mailing
> > >     list -- To
> > >      > UNSUBSCRIBE and more, see
> > >      >       > https://stat.ethz.ch/mailman/listinfo/r-help
> > >      >       > PLEASE do read the posting guide
> > >     http://www.R-project.org/posting-
> > >      > guide.html
> > >      >       > and provide commented, minimal, self-contained,
> > >     reproducible code.
> > >      >
> > >      >
> > >
> > >
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Tue Oct  6 01:00:59 2015
From: valkremk at gmail.com (Val)
Date: Mon, 5 Oct 2015 18:00:59 -0500
Subject: [R] count by category
Message-ID: <CAJOiR6Zr62ZmVb3JGR1kbVSbX-StRZ+2-TvL2gYeM2U6zOQnpQ@mail.gmail.com>

Hi All,

I have a data set ( region,  city,  town and district). The data looks like
region, city, town, district
1  1  1  1
1  1  1  2
1  1  1  3
1  1  2  1
1  1  2  2
1  2  1  1

I want the  counts for   region, city and town.  Here region 1 has 6
records, city 1 has 5 records and city 2 has 1 record. Similarly, town 1
has 3 records and town 2 has 2  and so  on.
Desired out put to a file
1  1  1  1  6 5 3
1  1  1  2  6 5 3
1  1  1  3  6 5 3
1  1  2  1  6 5 2
1  1  2  2  6 5 2
1  2  3  1  6 1 1

Thank you in advance

	[[alternative HTML version deleted]]


From podolsky at yorku.ca  Tue Oct  6 00:03:02 2015
From: podolsky at yorku.ca (Mark Podolsky)
Date: Mon, 5 Oct 2015 18:03:02 -0400
Subject: [R] SEM Packages for Testing Multilevel Mediation
Message-ID: <7B122DDA-2999-4349-8E69-D811731C397D@yorku.ca>

I am looking for SEM packages in R that can test multilevel mediation with multiple simultaneous mediators. It looks like the ?Mediation? package will do this. Are there others?

Thanks,

Mark

From teotjunk at hotmail.com  Tue Oct  6 05:20:18 2015
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Tue, 6 Oct 2015 11:20:18 +0800
Subject: [R] CSimca
Message-ID: <SNT152-W506A5BDB4D35501F152D32DF370@phx.gbl>

Does anyone knows how to return the prediction probabilities for CSimca function for rrcovHD package?
 		 	   		  
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Oct  6 06:32:21 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 6 Oct 2015 04:32:21 +0000
Subject: [R] count by category
In-Reply-To: <CAJOiR6Zr62ZmVb3JGR1kbVSbX-StRZ+2-TvL2gYeM2U6zOQnpQ@mail.gmail.com>
References: <CAJOiR6Zr62ZmVb3JGR1kbVSbX-StRZ+2-TvL2gYeM2U6zOQnpQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C4394A@SRVEXCHMBX.precheza.cz>

Hi

there are maybe better solutions but I would use ave with length function for each column separately to add new column.

See ?ave

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
> Sent: Tuesday, October 06, 2015 1:01 AM
> To: r-help at r-project.org
> Subject: [R] count by category
>
> Hi All,
>
> I have a data set ( region,  city,  town and district). The data looks
> like region, city, town, district
> 1  1  1  1
> 1  1  1  2
> 1  1  1  3
> 1  1  2  1
> 1  1  2  2
> 1  2  1  1
>
> I want the  counts for   region, city and town.  Here region 1 has 6
> records, city 1 has 5 records and city 2 has 1 record. Similarly, town
> 1 has 3 records and town 2 has 2  and so  on.
> Desired out put to a file
> 1  1  1  1  6 5 3
> 1  1  1  2  6 5 3
> 1  1  1  3  6 5 3
> 1  1  2  1  6 5 2
> 1  1  2  2  6 5 2
> 1  2  3  1  6 1 1
>
> Thank you in advance
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From neverstop at hotmail.it  Tue Oct  6 09:24:59 2015
From: neverstop at hotmail.it (Neverstop)
Date: Tue, 6 Oct 2015 00:24:59 -0700 (PDT)
Subject: [R] Strange Bug in R
Message-ID: <1444116299375-4713175.post@n4.nabble.com>

Hi all.
I don't understand why R works this way:
> rm(list=ls())
> require(foreign)
> dataset <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")
> min(dataset$gpa)
[1] 1.9
> min(dataset$gpa)>=1.90
[1] FALSE
> min(dataset$gpa)>=1.9
[1] FALSE
> min(dataset$gpa)>1.89
[1] TRUE
Shouldn't I get 3 TRUEs?
Am I missing something?
Thank you.




--
View this message in context: http://r.789695.n4.nabble.com/Strange-Bug-in-R-tp4713175.html
Sent from the R help mailing list archive at Nabble.com.


From thierry.onkelinx at inbo.be  Tue Oct  6 10:01:38 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 6 Oct 2015 10:01:38 +0200
Subject: [R] count by category
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C4394A@SRVEXCHMBX.precheza.cz>
References: <CAJOiR6Zr62ZmVb3JGR1kbVSbX-StRZ+2-TvL2gYeM2U6zOQnpQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C4394A@SRVEXCHMBX.precheza.cz>
Message-ID: <CAJuCY5yWjBjaBu4WiE1goxh8S6osYB4=mfWhW=Dh_wvxC4tanA@mail.gmail.com>

Here is a solution using dplyr.

dataset <- data.frame(
  region = rep(1:2, c(6, 1)),
  city = rep(1:2, c(5, 2)),
  town = rep(1:2, c(4, 3)),
  district = rep(1:3, c(2, 2, 3))
)
library(dplyr)
dataset %>%
  group_by(region) %>%
  mutate(n.region = n()) %>%
  group_by(city, add = TRUE) %>%
  mutate(n.city = n()) %>%
  group_by(town, add = TRUE) %>%
  mutate(n.town = n()) %>%
  group_by(district, add = TRUE) %>%
  mutate(n.district = n())


ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-06 6:32 GMT+02:00 PIKAL Petr <petr.pikal at precheza.cz>:

> Hi
>
> there are maybe better solutions but I would use ave with length function
> for each column separately to add new column.
>
> See ?ave
>
> Cheers
> Petr
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
> > Sent: Tuesday, October 06, 2015 1:01 AM
> > To: r-help at r-project.org
> > Subject: [R] count by category
> >
> > Hi All,
> >
> > I have a data set ( region,  city,  town and district). The data looks
> > like region, city, town, district
> > 1  1  1  1
> > 1  1  1  2
> > 1  1  1  3
> > 1  1  2  1
> > 1  1  2  2
> > 1  2  1  1
> >
> > I want the  counts for   region, city and town.  Here region 1 has 6
> > records, city 1 has 5 records and city 2 has 1 record. Similarly, town
> > 1 has 3 records and town 2 has 2  and so  on.
> > Desired out put to a file
> > 1  1  1  1  6 5 3
> > 1  1  1  2  6 5 3
> > 1  1  1  3  6 5 3
> > 1  1  2  1  6 5 2
> > 1  1  2  2  6 5 2
> > 1  2  3  1  6 1 1
> >
> > Thank you in advance
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Oct  6 10:11:28 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 6 Oct 2015 21:11:28 +1300
Subject: [R] Strange Bug in R
In-Reply-To: <1444116299375-4713175.post@n4.nabble.com>
References: <1444116299375-4713175.post@n4.nabble.com>
Message-ID: <56138230.1070700@auckland.ac.nz>

On 06/10/15 20:24, Neverstop wrote:
> Hi all.
> I don't understand why R works this way:
>> rm(list=ls())
>> require(foreign)
>> dataset <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")
>> min(dataset$gpa)
> [1] 1.9
>> min(dataset$gpa)>=1.90
> [1] FALSE
>> min(dataset$gpa)>=1.9
> [1] FALSE
>> min(dataset$gpa)>1.89
> [1] TRUE
> Shouldn't I get 3 TRUEs?

No.

> Am I missing something?

Comprehension of significant digits and the storage of floating point 
numbers.

Try:

    print(min(dataset$gpa),digits=10)

Please don't refer to phenomena as "bugs" unless you are really sure 
that they are not simply instances of things that you don't understand.
R was designed and written by very clever people and has been used, 
tested and pushed to its limits by a wide variety of users for over 20 
years.  It is highly improbable that you would stumble upon a real bug 
in such a simple context.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bhh at xs4all.nl  Tue Oct  6 10:28:35 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 6 Oct 2015 10:28:35 +0200
Subject: [R] Strange Bug in R
In-Reply-To: <1444116299375-4713175.post@n4.nabble.com>
References: <1444116299375-4713175.post@n4.nabble.com>
Message-ID: <8AC41084-1B01-46E4-A47A-2BBB6F7DBBDA@xs4all.nl>


> On 6 Oct 2015, at 09:24, Neverstop <neverstop at hotmail.it> wrote:
> 
> Hi all.
> I don't understand why R works this way:
>> rm(list=ls())
>> require(foreign)
>> dataset <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")
>> min(dataset$gpa)
> [1] 1.9
>> min(dataset$gpa)>=1.90
> [1] FALSE
>> min(dataset$gpa)>=1.9
> [1] FALSE
>> min(dataset$gpa)>1.89
> [1] TRUE
> Shouldn't I get 3 TRUEs?
> Am I missing something?
> Thank you.
> 
> 

See R FAQ 7.31  in https://cran.r-project.org/doc/FAQ/R-FAQ.html
It should provide clarification for your puzzlement.

Berend


> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Strange-Bug-in-R-tp4713175.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Oct  6 10:51:39 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Oct 2015 19:51:39 +1100
Subject: [R] count by category
In-Reply-To: <CAJOiR6Zr62ZmVb3JGR1kbVSbX-StRZ+2-TvL2gYeM2U6zOQnpQ@mail.gmail.com>
References: <CAJOiR6Zr62ZmVb3JGR1kbVSbX-StRZ+2-TvL2gYeM2U6zOQnpQ@mail.gmail.com>
Message-ID: <CA+8X3fUA7jjRGKrz-aGR3zJZVn53UoDcEEuuOsoObHiV0xDoxQ@mail.gmail.com>

Hi Val,
You can even get a graphic illustration of this quite easily:

library(plotrix)
sizetree(dataset)

Jim


On Tue, Oct 6, 2015 at 10:00 AM, Val <valkremk at gmail.com> wrote:

> Hi All,
>
> I have a data set ( region,  city,  town and district). The data looks like
> region, city, town, district
> 1  1  1  1
> 1  1  1  2
> 1  1  1  3
> 1  1  2  1
> 1  1  2  2
> 1  2  1  1
>
> I want the  counts for   region, city and town.  Here region 1 has 6
> records, city 1 has 5 records and city 2 has 1 record. Similarly, town 1
> has 3 records and town 2 has 2  and so  on.
> Desired out put to a file
> 1  1  1  1  6 5 3
> 1  1  1  2  6 5 3
> 1  1  1  3  6 5 3
> 1  1  2  1  6 5 2
> 1  1  2  2  6 5 2
> 1  2  3  1  6 1 1
>
> Thank you in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Tue Oct  6 10:53:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 6 Oct 2015 21:53:20 +1300
Subject: [R] Strange Bug in R
In-Reply-To: <8AC41084-1B01-46E4-A47A-2BBB6F7DBBDA@xs4all.nl>
References: <1444116299375-4713175.post@n4.nabble.com>
	<8AC41084-1B01-46E4-A47A-2BBB6F7DBBDA@xs4all.nl>
Message-ID: <56138C00.8090003@auckland.ac.nz>

On 06/10/15 21:28, Berend Hasselman wrote:
>
>> On 6 Oct 2015, at 09:24, Neverstop <neverstop at hotmail.it> wrote:
>>
>> Hi all.
>> I don't understand why R works this way:
>>> rm(list=ls())
>>> require(foreign)
>>> dataset <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")
>>> min(dataset$gpa)
>> [1] 1.9
>>> min(dataset$gpa)>=1.90
>> [1] FALSE
>>> min(dataset$gpa)>=1.9
>> [1] FALSE
>>> min(dataset$gpa)>1.89
>> [1] TRUE
>> Shouldn't I get 3 TRUEs?
>> Am I missing something?
>> Thank you.
>>
>>
>
> See R FAQ 7.31  in https://cran.r-project.org/doc/FAQ/R-FAQ.html
> It should provide clarification for your puzzlement.

Not really.  The problem is one of the precision to which a floating 
point number is *printed* rather than one of the way that floating point 
numbers are *calculated*.  Hence it is not an instance of the 
counter-intuitive nature of floating point arithmetic.  I.e. you could 
have numbers a and b that were calculated and stored to *infinite* 
precision, appear to be equal when printed to some default number of 
significant figures, but are not actually equal.

The problems are related and both involve having some understanding of 
floating point numbers, but they are not the same problem.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From kridox at ymail.com  Tue Oct  6 11:18:35 2015
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 6 Oct 2015 18:18:35 +0900
Subject: [R] Strange Bug in R
In-Reply-To: <1444116299375-4713175.post@n4.nabble.com>
References: <1444116299375-4713175.post@n4.nabble.com>
Message-ID: <CAAcyNCz2o-iLzp8QNK0MFKsR4cfKpiX50=kpYHpuFtQGk4QNCw@mail.gmail.com>

Hello,

1) Please don't put rm(list=ls()) in a script you submit to this list.
This is considered as bad manner.

2) Please read https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
and http://stackoverflow.com/a/9508558/3710546

Regards,
Pascal

On Tue, Oct 6, 2015 at 4:24 PM, Neverstop <neverstop at hotmail.it> wrote:
> Hi all.
> I don't understand why R works this way:
>> rm(list=ls())
>> require(foreign)
>> dataset <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")
>> min(dataset$gpa)
> [1] 1.9
>> min(dataset$gpa)>=1.90
> [1] FALSE
>> min(dataset$gpa)>=1.9
> [1] FALSE
>> min(dataset$gpa)>1.89
> [1] TRUE
> Shouldn't I get 3 TRUEs?
> Am I missing something?
> Thank you.
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Strange-Bug-in-R-tp4713175.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From maicel at infomed.sld.cu  Tue Oct  6 12:49:42 2015
From: maicel at infomed.sld.cu (maicel)
Date: Tue, 6 Oct 2015 06:49:42 -0400
Subject: [R] extract all dataframes from list
Message-ID: <000001d10024$b6704a10$2350de30$@infomed.sld.cu>

Hello List, I have list of named dataframe. How can I extract all dataframes
from this list? The dataframe names should be the same of the original list.
May I use the lapply function?

Thanks for your help. Best regards,
Maicel Monzon, MD
National Center of Clinical Trials
Havana, Cuba




--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/


From lordpreetam at gmail.com  Tue Oct  6 12:52:43 2015
From: lordpreetam at gmail.com (Preetam Pal)
Date: Tue, 6 Oct 2015 16:22:43 +0530
Subject: [R] Error Correction Model under Cointegration
Message-ID: <5613a781.e403450a.21583.ffffd335@mx.google.com>

Hi All,

I have a time series y_t and 2  other time series x1_t and x2t as regressors. I know that these 3 series are cointegrated via the Johansen tests. Hence I want to implement an error correction model with 1 lag for each variable (i.e. Lag y, lag x1 and lag x2) for projection purposes (suppose, I have future values for the regressors).
Is there an R function I can use for this ECM model usage? Note that manually it is a bit challenging to pull off because the RHS of this model would have a lagged residual term, for which we have no future observations.

Any help here would be appreciated.

Regards,
Preetam
	[[alternative HTML version deleted]]


From lorenz at usgs.gov  Tue Oct  6 14:58:28 2015
From: lorenz at usgs.gov (Lorenz, David)
Date: Tue, 6 Oct 2015 07:58:28 -0500
Subject: [R] Quantile Regression without intercept
Message-ID: <CALxY2LcsbfupMXMpHkOEXJt0pCrVGo3a97s9s9_DPPEHamLkNw@mail.gmail.com>

Did you verify that the correct percentages were above/below the regression
lines? I did a quick check and for example did not consistently get 50% of
the observed response values greater than the tau=.5 line. I did when I
included the nonzero intercept term.



> Date: Mon, 5 Oct 2015 21:14:04 +0530
> From: Preetam Pal <lordpreetam at gmail.com>
> To: stephen sefick <ssefick at gmail.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Subject: Re: [R] Quantile Regression without intercept
> Message-ID: <56129a41.025f440a.b1cf4.fffff5ee at mx.google.com>
> Content-Type: text/plain; charset="UTF-8"
>
> Yes..it works. .... Thanks ??
>
> -----Original Message-----
> From: "stephen sefick" <ssefick at gmail.com>
> Sent: ?05-?10-?2015 09:01 PM
> To: "Preetam Pal" <lordpreetam at gmail.com>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Subject: Re: [R] Quantile Regression without intercept
>
> I have never used this, but does the formula interface work like lm? Y~X-1?
>
>
> On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com>
> wrote:
>
> Hi guys,
>
> Can you instruct me please how to run quantile regression without the
> intercept term? I only know about the rq function under quantreg package,
> but it automatically uses an intercept model. Icant change that, it seems.
>
> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
> Unemployment). Their sizes are 125 each.
>
> Appreciate your help with this.
>
> Regards,
> Preetam
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
> --
>
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>         [[alternative HTML version deleted]]
>
>
>
>

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Tue Oct  6 15:03:58 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Tue, 6 Oct 2015 08:03:58 -0500
Subject: [R] Quantile Regression without intercept
In-Reply-To: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
References: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
Message-ID: <3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>


> On Oct 6, 2015, at 7:58 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> 
> Did you verify that the correct percentages were above/below the regression
> lines? I did a quick check and for example did not consistently get 50% of
> the observed response values greater than the tau=.5 line. I did when I
> included the nonzero intercept term.

Your "correct percentages" are only correct when you have an intercept in the model,
without an intercept there is no gradient condition to ensure that.
> 
> 
> 
>> Date: Mon, 5 Oct 2015 21:14:04 +0530
>> From: Preetam Pal <lordpreetam at gmail.com>
>> To: stephen sefick <ssefick at gmail.com>
>> Cc: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: Re: [R] Quantile Regression without intercept
>> Message-ID: <56129a41.025f440a.b1cf4.fffff5ee at mx.google.com>
>> Content-Type: text/plain; charset="UTF-8"
>> 
>> Yes..it works. .... Thanks ??
>> 
>> -----Original Message-----
>> From: "stephen sefick" <ssefick at gmail.com>
>> Sent: ?05-?10-?2015 09:01 PM
>> To: "Preetam Pal" <lordpreetam at gmail.com>
>> Cc: "r-help at r-project.org" <r-help at r-project.org>
>> Subject: Re: [R] Quantile Regression without intercept
>> 
>> I have never used this, but does the formula interface work like lm? Y~X-1?
>> 
>> 
>> On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com>
>> wrote:
>> 
>> Hi guys,
>> 
>> Can you instruct me please how to run quantile regression without the
>> intercept term? I only know about the rq function under quantreg package,
>> but it automatically uses an intercept model. Icant change that, it seems.
>> 
>> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
>> Unemployment). Their sizes are 125 each.
>> 
>> Appreciate your help with this.
>> 
>> Regards,
>> Preetam
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> 
>> 
>> 
>> --
>> 
>> Stephen Sefick
>> **************************************************
>> Auburn University
>> Biological Sciences
>> 331 Funchess Hall
>> Auburn, Alabama
>> 36849
>> **************************************************
>> sas0025 at auburn.edu
>> http://www.auburn.edu/~sas0025
>> **************************************************
>> 
>> Let's not spend our time and resources thinking about things that are so
>> little or so large that all they really do for us is puff us up and make us
>> feel like gods.  We are mammals, and have not exhausted the annoying little
>> problems of being mammals.
>> 
>>                                -K. Mullis
>> 
>> "A big computer, a complex algorithm and a long time does not equal
>> science."
>> 
>>                              -Robert Gentleman
>>        [[alternative HTML version deleted]]
>> 
>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From neverstop at hotmail.it  Tue Oct  6 12:08:27 2015
From: neverstop at hotmail.it (Neverstop)
Date: Tue, 6 Oct 2015 03:08:27 -0700 (PDT)
Subject: [R] Strange Bug in R
In-Reply-To: <1444116299375-4713175.post@n4.nabble.com>
References: <1444116299375-4713175.post@n4.nabble.com>
Message-ID: <1444126107565-4713182.post@n4.nabble.com>

Thank you all very much for the explanations!



--
View this message in context: http://r.789695.n4.nabble.com/Strange-Bug-in-R-tp4713175p4713182.html
Sent from the R help mailing list archive at Nabble.com.


From putra_autumn86 at yahoo.com  Tue Oct  6 08:33:42 2015
From: putra_autumn86 at yahoo.com (smart hendsome)
Date: Tue, 6 Oct 2015 06:33:42 +0000 (UTC)
Subject: [R] Result error using the function
In-Reply-To: <1332761623.1148383.1444111836911.JavaMail.yahoo@mail.yahoo.com>
References: <1332761623.1148383.1444111836911.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <619937521.1165942.1444113222865.JavaMail.yahoo@mail.yahoo.com>

Hi R-users,


I am new to R.? I try to code using the function in R as below:
?monthly_summary <- function(dt,r)
{? tol <- 1E-6
?? mn? <- vector(length=12, mode="numeric")
?? lambda? <- vector(length=12, mode="numeric")
?? ag? <- aggregate(dt[,4] > tol, list (dt[,2], dt[,1]), sum)
?? names(ag) <- c("Year", "Month","Amount")
?? mt1 <- matrix(ag[,3],nrow=r,ncol=12,byrow=T)
?? rownames(mt1) <- 1950:1951
?? colnames(mt1) <- c("Jan","Feb","Mar","Apr","May","June","July",
??????????????????? ? ? ? ? ? ?? "Aug","Sept","Oct","Nov","Dec")

? for (i in 1:ncol(mt1))
? {
????? {? xi???? <- mt1[,i]
???????? mn[i]? <- mean(xi)??????????????????????????????? ## calc mean
????? }
?
????? if? (mt1[,c(1,3,5,7,8,10,12)]) 
????????? {
?????????? lambda[i]? <- (31/mn[i])?????????????????????? ## calc lambda for month with 31 days
????????? }
????????? else if? (mt1[,2])
?????????????? {
?????????????????? lambda[i]? <- (28/mn[i])????????????? ? ## calc lambda for month with 28 days
?????????????? }
?????????????????? else
?????????????????????? {
????????????????????????????? lambda[i]? <- (30/mn[i])????? ## calc lambda for month with 30 days
?????????????????????? }
???? 
? ## result
? mt1 <- round(mt1, 0)
? mn <-?? round(mn, 3)
? lambda <- round(lambda, 3)
? 
}? 
? comb <- rbind(mt1, mn = mn, lambda = lambda)
}

## call function
m_sum <- monthly_summary(J1,2); m_sum

The problems are:
1)the value of count rain in decimals 
2) the value lambda is wrong3)i dont know how to account the leap years in february
Anyone can help me?
I also provide my data using dput(). Thanks so much.
structure(list(Year = c(1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 
1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 
1951L, 1951L, 1951L, 1951L), Month = c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 
10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L
), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 
3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 
17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 
30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 
9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 
22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 
24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 
28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 
25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 
21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 
4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 
18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 
31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 
14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 
27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 
10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 
23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 
7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 
20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 
29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 
13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 
26L, 27L, 28L, 29L, 30L, 31L), Amount = c(0, 35.5, 17.8, 24.5, 
12.3, 11.5, 5.7, 13.2, 11.3, 14.7, 11.9, 17.5, 8.1, 0.4, 0, 19.5, 
10.7, 0.5, 12.7, 6.3, 16.1, 11.4, 1.7, 0.8, 0.4, 0, 2.9, 5.3, 
2.9, 0.5, 5.9, 2.9, 0, 16.2, 15.5, 21.8, 11.4, 1.2, 0, 0, 0, 
0, 1.3, 9.5, 4.4, 4.2, 2.1, 0, 0, 0, 0, 0, 0, 0, 28.4, 14.2, 
0, 0, 3.3, 1.7, 4.9, 3.6, 12, 16.7, 5.5, 1.1, 0.6, 2.7, 1.3, 
0, 0, 34.2, 43.8, 27.2, 10.6, 3.8, 2.3, 34, 16.7, 0, 47.1, 23.5, 
28.9, 18.1, 4.8, 5.5, 3.3, 3, 1.2, 3.3, 1.7, 1.8, 1.7, 0.7, 17, 
8.4, 7.7, 3.9, 5.9, 2.9, 0, 1, 0.5, 0.8, 0.4, 4.2, 2.1, 0, 0, 
0, 17.9, 9, 1.7, 1.6, 5.1, 2.8, 0.6, 0.2, 1.7, 0.8, 2.5, 1.3, 
3.2, 1.9, 0.3, 3.4, 1.7, 4.5, 2.3, 0, 1.7, 0.8, 0, 0, 0, 0, 0, 
16.9, 13.8, 11.1, 5.5, 2.3, 0.8, 0, 0, 28.7, 26.2, 9.6, 1.8, 
0, 0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 53.1, 26.6, 41.1, 20.6, 18.1, 
9, 0, 0, 0, 0, 6.9, 3.5, 0, 13.5, 6.8, 0, 0, 17.7, 8.9, 0, 0.1, 
0.1, 0, 11, 5.5, 1, 1.3, 6.5, 3.5, 0.2, 1.1, 0.6, 18.6, 28.8, 
9.7, 4.4, 8.4, 3.1, 0, 0.5, 0.2, 15.7, 8.2, 0.2, 0, 0, 0, 0, 
0, 0.8, 0.4, 5.1, 2.5, 0, 0, 3.3, 1.7, 3, 1.5, 0, 0, 0, 0, 0, 
0, 9.8, 38.7, 17.6, 17.2, 39.2, 16.4, 0.5, 0, 0, 0, 0, 16.4, 
11.4, 1.9, 18.8, 48.6, 19.6, 24.3, 19.4, 4.4, 20.5, 14.1, 2, 
0, 0, 0, 0, 0, 0.1, 0.1, 22.5, 11.2, 0.8, 0.4, 0, 5.5, 2.8, 2.9, 
1.4, 22.7, 16.1, 32.2, 25.2, 5.5, 0.2, 0, 0, 0, 35.7, 17.8, 1.5, 
1.1, 0.2, 0, 3.3, 1.8, 6.5, 14.2, 10.2, 11.6, 4.6, 20.8, 10.7, 
1.8, 2.5, 12, 32.6, 13.5, 1, 0.5, 12.7, 6.3, 0.3, 0.2, 5.7, 2.9, 
0, 0, 29.6, 14.9, 7.7, 3.8, 11, 11.2, 2.9, 2.5, 1.3, 0.8, 25.7, 
21.9, 13, 15.5, 5.7, 22, 11, 16.4, 32.7, 12.3, 0, 0, 6.9, 8.5, 
3.3, 9.9, 5.9, 7.8, 14.3, 12.6, 3.6, 0.8, 0.7, 0.2, 0.3, 5.2, 
2.5, 0, 0.8, 1.4, 0.5, 0, 2.7, 5.5, 15.1, 6.8, 0.5, 0.2, 6.4, 
9.1, 6.5, 9.4, 3.8, 0, 0, 2.7, 1.3, 0, 7.6, 10.5, 3.4, 0, 6.2, 
36.9, 16.9, 4.5, 20.2, 9.3, 0.2, 14, 46.1, 38.1, 9.3, 0.8, 51.1, 
113, 52.2, 18.5, 29.2, 48.9, 41.7, 18.1, 10.4, 3.5, 7.6, 3.8, 
0, 1.3, 31.1, 18.2, 1.5, 0, 0, 0, 0, 10.1, 5.1, 0, 0, 0, 0, 6.7, 
3.4, 26.2, 13.8, 8.1, 3.9, 74.8, 48.7, 23.7, 15.4, 4.3, 8.3, 
3.9, 19.1, 13.2, 2.8, 2.3, 6.1, 14.1, 5.7, 0, 0, 0, 0, 7.6, 39.7, 
17.9, 0, 5.1, 4.5, 1.3, 0.2, 0, 0, 0, 0, 0, 0, 0, 32.5, 16.2, 
0, 0.5, 0.2, 0, 2.3, 2.2, 0.5, 0, 9.3, 11.9, 4.8, 0.6, 0, 32.5, 
18.8, 11.4, 5.1, 0, 17.1, 8.5, 1.1, 0.6, 4.7, 2.4, 36.4, 21.1, 
1.4, 0, 0, 0, 0, 0, 0, 1.1, 0.6, 0, 3.2, 2.6, 3.2, 9.1, 19.9, 
8, 0, 0, 7.1, 3.5, 6.2, 3.1, 0, 1.7, 13.5, 21.5, 7.6, 0, 0, 0, 
0, 15.2, 7.6, 0, 0, 0, 5.4, 17.9, 7.6, 11.1, 6, 1.9, 6.7, 2.9, 
29.1, 14.5, 14.3, 16.4, 4.6, 0, 0, 0, 0, 31.3, 15.6, 0, 0, 0, 
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14.3, 7.2, 0.8, 1.2, 30, 14.8, 
0, 0, 0, 0, 0, 0, 0, 4.2, 2.1, 4.2, 3.8, 5, 44.4, 25.3, 2.9, 
0.4, 0, 8.4, 4.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31.1, 
15.6, 0, 13.5, 6.8, 0, 0, 0.8, 0.4, 24.5, 12.6, 29.6, 14.7, 39.3, 
19.6, 0, 0, 0, 0, 0, 0, 0, 5.7, 27.1, 12.1, 25.7, 18.9, 15.4, 
6.2, 0, 3.2, 1.6, 0, 0, 0, 0, 0, 2.3, 1.2, 15.2, 13.3, 31.8, 
17.5, 1.5, 1.3, 3.2, 1.3, 0, 0, 0, 0, 18.6, 9.3, 0, 0, 0, 3.3, 
11.1, 36.9, 48.9, 24, 3.8, 0.8, 0.4, 0, 0, 0, 0, 0, 0, 0, 0, 
4.2, 2.1, 0, 1.1, 0.6, 0.8, 0.4, 36.4, 18.2, 8.4, 22.3, 9, 0, 
33.8, 17.7, 13.3, 6.4, 0.7, 0.3, 0, 0, 0, 10.3, 15.3, 12.3, 7.8, 
2.1, 0, 0, 31.3, 15.6, 6.7, 19.4, 9.4, 0.7, 10.1, 5.9, 0.4, 0.8, 
7.1, 3.4, 9.9, 5, 0, 6.6, 9.2, 2.9, 0.3, 0.2, 0.3, 17, 8.4, 7.1, 
3.5, 15.2, 55.3, 75.1, 59.6, 17, 0, 0.5, 0.2, 2.9, 2.9, 3.7, 
1.5, 0, 0, 0, 0, 2.5, 1.7, 0.2, 39.7, 19.9, 33, 16.5, 1.5, 0.7, 
1.5, 0.9, 19.3)), .Names = c("Year", "Month", "Day", "Amount"
), class = "data.frame", row.names = c(NA, -730L))




   
	[[alternative HTML version deleted]]


From Rainer at krugs.de  Tue Oct  6 15:20:42 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 06 Oct 2015 15:20:42 +0200
Subject: [R] Bug in auglag?
In-Reply-To: <3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>
	(Ravi Varadhan's message of "Thu, 1 Oct 2015 13:17:07 +0000")
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	<m2pp0z11lk.fsf@krugs.de>
	<3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>
Message-ID: <m2io6kb0b9.fsf_-_@krugs.de>

Hi Ravi,

I would like come back to your offer. I have a problem which possibly is
caused by a bug or by something I don't understand:

My function to be minimised is executed even when an element in hin() is
negative.

My hin looks as follow:

--8<---------------cut here---------------start------------->8---
hinMahat <- function(x, hauteur, na, zjoint, y, LAI, ...) {
    if (x[1] < 0) {
        cat(names(list(...)), "\n")
        cat(..., "\n")
        cat(x, "|", hauteur, LAI, y, "\n")
    }

    h <- rep(NA, 8)
    if (!missing(na)) {
        x <- c(na, x )
    }
    if (!missing(y)) {
        x <- c(x, y)
    }
    if (!missing(zjoint)) {
        x <- c(x[1], zjoint, x[2])
    }
    
    ##
    dep <- hauteur * (0.05 + LAI^0.02 / 2) + (x[3] - 1)/20
    h[1] <- dep
    h[2] <- hauteur - dep
    ## if (h[2]==0) {
    ##     h[2] <- -1
    ## }
    ##
    z0 <- hauteur * (0.23 + LAI^0.25 / 10) + (x[3] - 1)/67
    h[3] <- z0
    ## if (h[3]==0) {
    ##     h[3] <- -1
    ## }
    h[4] <- hauteur - z0
    ##
    h[5] <- x[1]
    ##
    h[6] <- x[2]
    h[7] <- hauteur - x[2]
    ##
    h[8] <- hauteur - dep - z0
    if (any(h<=0)) {
        cat(h, "\n")
        cat("\n")
    }
    return(h)
}
--8<---------------cut here---------------end--------------->8---

the x contains up to three elements: c(na=, zjoint=, y=) and I fit these
three, unless one or two are specified explicitely.

The values going into hin are:

,----
| ... (z  u ua za z0sol )
| 3 11 17 23 29 37 0.315 0.422 0.458 0.556 1.567 1.747 1.747 37 0.001 
| 
| x(na, zjoint): -8.875735 24.51316
| hauteur: 28
| na:      8.1
| y:       3 
| 
| the resulting hin() is:
| 16.09815 11.90185 11.19352 16.80648 -8.875735 24.51316 3.486843 0.708335 
`----


Which is negative in element 5 as x[2]=na is negative.

So I would expect that the function fn is not evaluated. But it is, and
raises an error:

,----
| Error in wpLELMahat(z = z, ua = ua, na = ifelse(missing(na), par[1], na),  : 
|   na has to be larger or equal than zero!
`----

Is this a misunderstanding on my part, or is it an error in the function
auglag?


Below is the function which is doing the minimisation.

If I replace auglag() with constrOptim.nl(), the optimisation is working
as expected.

So I think this is a bug in auglag?

Let me know if you need further information.

Cheers,

Rainer

--8<---------------cut here---------------start------------->8---
fitAuglag.wpLEL.mahat.single <- function(
                                         z,
                                         u,
                                         LAI,
                                         initial = c(na=9, zjoint=0.2*2, y=3),
                                         na, zjoint, y,
                                         h      = 28,
                                         za     = 37,
                                         z0sol  = 0.001,
                                         hin,
                                         ...
                                         ) {
    if (missing(hin)) {
        hin <- hinMahat
    }

    wpLELMin <- function(par, na, zjoint, y, z, u, ua, hauteur, za, z0sol, LAI) {
        result <- NA
        try({
            p <- wpLELMahat(
                z      = z,
                ua     = ua,
                na     = ifelse(missing(na), par[1], na), 
                zjoint = ifelse(missing(zjoint), par[2], zjoint),
                h      = hauteur,
                za     = za,
                z0sol  = z0sol,
                LAI    = LAI,
                y      = ifelse(missing(y), par[3], y)
            )
            result <- sum( ( (p$u - u)^2 ) / length(u) )
        },
        silent = FALSE
        )
        ## cat("From wpLELMin", par, "\n")
        return( result )
    }

    ua <- u[length(u)]
    result <- list()
    result$method <- "fitAuglag.wpLEL.mahat.single"
    result$initial <-  initial
    result$dot <- list(...)
    result$z <- z
    result$u <- u

    result$fit <- auglag(
        par = initial,
        fn    = wpLELMin,
        hin   = hin,
        na     = na, 
        zjoint = zjoint, 
        y      = y,
        ##
        z     = z,
        u     = u,
        ua    = ua,
        hauteur = h,
        za    = za,
        z0sol = z0sol,
        LAI   = LAI,
        ...
    )
    result$wp <- wpLELMahat(
        z      = z,
        ua     = ua,
        na     = ifelse ( missing(na), result$fit$par["na"], na),
        zjoint = ifelse ( missing(zjoint), result$fit$par["zjoint"], zjoint),
        h      = h,
        za     = za,
        z0sol  = z0sol,
        LAI    = LAI,
        y      = ifelse ( missing(y), result$fit$par["y"], y)
    )
    
    class(result) <- c(class(result), "wpLELFit")
    return(result)
}
#+end_src--8<---------------cut here---------------end--------------->8---



Ravi Varadhan <ravi.varadhan at jhu.edu> writes:

> I would recommend that you use auglag() rather than constrOptim.nl()
> in the package "alabama."  It is a better algorithm, and it does not
> require feasible starting values.
> Best,
> Ravi  
>
> -----Original Message-----
> From: Rainer M Krug [mailto:Rainer at krugs.de] 
> Sent: Thursday, October 01, 2015 3:37 AM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: 'r-help at r-project.org' <r-help at r-project.org>
> Subject: Re: optimizing with non-linear constraints
>
> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
>
>> Hi Rainer,
>> It is very simple to specify the constraints (linear or nonlinear) in 
>> "alabama" .  They are specified in a function called `hin', where the 
>> constraints are written such that they are positive.
>
> OK - I somehow missed the part that, when the values x are valid,
>> i.e. in the range as defined by the conditions, the result of hin(x)
>> that they are all positive.
>
>> Your two nonlinear constraints would be written as follows:
>>
>> hin <- function(x, LAI) {
>> h <- rep(NA, 2)
>> h[1] <- LAI^x[2] / x[3] + x[1]
>> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
>> h
>> }
>
> Makes perfect sense.
>
>>
>> Please take a look at the help page.  If it is still not clear, you can contact me offline.
>
> Yup - I did. But I somehow missed the fact stated above.
>
> I am using constrOptim() and constrOptim.nl() for a paper and am
>> compiling a separate document which explains how to get the
>> constraints for the two functions step by step - I will make it
>> available as a blog post and a pdf.
>
> I might have further questions concerning the different fitting
>> functions and which ones are the most appropriate in my case.
>
> Thanks a lot,
>
> Rainer
>
>
>> Best,
>> Ravi
>>
>> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
>> Associate Professor,  Department of Oncology Division of Biostatistics 
>> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns 
>> Hopkins University
>> 550 N. Broadway, Suite 1111-E
>> Baltimore, MD 21205
>> 410-502-2619
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151006/51e4da9e/attachment.bin>

From Rainer at krugs.de  Tue Oct  6 15:27:58 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 06 Oct 2015 15:27:58 +0200
Subject: [R] Bug in auglag?
In-Reply-To: <m2io6kb0b9.fsf_-_@krugs.de> (Rainer M. Krug's message of "Tue,
	06 Oct 2015 15:20:42 +0200")
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	<m2pp0z11lk.fsf@krugs.de>
	<3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>
	<m2io6kb0b9.fsf_-_@krugs.de>
Message-ID: <m2egh8azz5.fsf@krugs.de>

Please ignore - list members - accidentally CCd.

Rainer


Rainer M Krug <Rainer at krugs.de> writes:

> Hi Ravi,
>
> I would like come back to your offer. I have a problem which possibly is
> caused by a bug or by something I don't understand:
>
> My function to be minimised is executed even when an element in hin() is
> negative.
>
> My hin looks as follow:
>
> hinMahat <- function(x, hauteur, na, zjoint, y, LAI, ...) {
>     if (x[1] < 0) {
>         cat(names(list(...)), "\n")
>         cat(..., "\n")
>         cat(x, "|", hauteur, LAI, y, "\n")
>     }
>
>     h <- rep(NA, 8)
>     if (!missing(na)) {
>         x <- c(na, x )
>     }
>     if (!missing(y)) {
>         x <- c(x, y)
>     }
>     if (!missing(zjoint)) {
>         x <- c(x[1], zjoint, x[2])
>     }
>     
>     ##
>     dep <- hauteur * (0.05 + LAI^0.02 / 2) + (x[3] - 1)/20
>     h[1] <- dep
>     h[2] <- hauteur - dep
>     ## if (h[2]==0) {
>     ##     h[2] <- -1
>     ## }
>     ##
>     z0 <- hauteur * (0.23 + LAI^0.25 / 10) + (x[3] - 1)/67
>     h[3] <- z0
>     ## if (h[3]==0) {
>     ##     h[3] <- -1
>     ## }
>     h[4] <- hauteur - z0
>     ##
>     h[5] <- x[1]
>     ##
>     h[6] <- x[2]
>     h[7] <- hauteur - x[2]
>     ##
>     h[8] <- hauteur - dep - z0
>     if (any(h<=0)) {
>         cat(h, "\n")
>         cat("\n")
>     }
>     return(h)
> }
>
> the x contains up to three elements: c(na=, zjoint=, y=) and I fit these
> three, unless one or two are specified explicitely.
>
> The values going into hin are:
>
> ,----
> | ... (z  u ua za z0sol )
> | 3 11 17 23 29 37 0.315 0.422 0.458 0.556 1.567 1.747 1.747 37 0.001 
> | 
> | x(na, zjoint): -8.875735 24.51316
> | hauteur: 28
> | na:      8.1
> | y:       3 
> | 
> | the resulting hin() is:
> | 16.09815 11.90185 11.19352 16.80648 -8.875735 24.51316 3.486843 0.708335 
> `----
>
>
> Which is negative in element 5 as x[2]=na is negative.
>
> So I would expect that the function fn is not evaluated. But it is, and
> raises an error:
>
> ,----
> | Error in wpLELMahat(z = z, ua = ua, na = ifelse(missing(na), par[1], na),  : 
> |   na has to be larger or equal than zero!
> `----
>
> Is this a misunderstanding on my part, or is it an error in the function
> auglag?
>
>
> Below is the function which is doing the minimisation.
>
> If I replace auglag() with constrOptim.nl(), the optimisation is working
> as expected.
>
> So I think this is a bug in auglag?
>
> Let me know if you need further information.
>
> Cheers,
>
> Rainer
>
> --8<---------------cut here---------------start------------->8---
> fitAuglag.wpLEL.mahat.single <- function(
>                                          z,
>                                          u,
>                                          LAI,
>                                          initial = c(na=9, zjoint=0.2*2, y=3),
>                                          na, zjoint, y,
>                                          h      = 28,
>                                          za     = 37,
>                                          z0sol  = 0.001,
>                                          hin,
>                                          ...
>                                          ) {
>     if (missing(hin)) {
>         hin <- hinMahat
>     }
>
>     wpLELMin <- function(par, na, zjoint, y, z, u, ua, hauteur, za, z0sol, LAI) {
>         result <- NA
>         try({
>             p <- wpLELMahat(
>                 z      = z,
>                 ua     = ua,
>                 na     = ifelse(missing(na), par[1], na), 
>                 zjoint = ifelse(missing(zjoint), par[2], zjoint),
>                 h      = hauteur,
>                 za     = za,
>                 z0sol  = z0sol,
>                 LAI    = LAI,
>                 y      = ifelse(missing(y), par[3], y)
>             )
>             result <- sum( ( (p$u - u)^2 ) / length(u) )
>         },
>         silent = FALSE
>         )
>         ## cat("From wpLELMin", par, "\n")
>         return( result )
>     }
>
>     ua <- u[length(u)]
>     result <- list()
>     result$method <- "fitAuglag.wpLEL.mahat.single"
>     result$initial <-  initial
>     result$dot <- list(...)
>     result$z <- z
>     result$u <- u
>
>     result$fit <- auglag(
>         par = initial,
>         fn    = wpLELMin,
>         hin   = hin,
>         na     = na, 
>         zjoint = zjoint, 
>         y      = y,
>         ##
>         z     = z,
>         u     = u,
>         ua    = ua,
>         hauteur = h,
>         za    = za,
>         z0sol = z0sol,
>         LAI   = LAI,
>         ...
>     )
>     result$wp <- wpLELMahat(
>         z      = z,
>         ua     = ua,
>         na     = ifelse ( missing(na), result$fit$par["na"], na),
>         zjoint = ifelse ( missing(zjoint), result$fit$par["zjoint"], zjoint),
>         h      = h,
>         za     = za,
>         z0sol  = z0sol,
>         LAI    = LAI,
>         y      = ifelse ( missing(y), result$fit$par["y"], y)
>     )
>     
>     class(result) <- c(class(result), "wpLELFit")
>     return(result)
> }
> #+end_src--8<---------------cut here---------------end--------------->8---
>
>
>
> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
>
>> I would recommend that you use auglag() rather than constrOptim.nl()
>> in the package "alabama."  It is a better algorithm, and it does not
>> require feasible starting values.
>> Best,
>> Ravi  
>>
>> -----Original Message-----
>> From: Rainer M Krug [mailto:Rainer at krugs.de] 
>> Sent: Thursday, October 01, 2015 3:37 AM
>> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
>> Cc: 'r-help at r-project.org' <r-help at r-project.org>
>> Subject: Re: optimizing with non-linear constraints
>>
>> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
>>
>>> Hi Rainer,
>>> It is very simple to specify the constraints (linear or nonlinear) in 
>>> "alabama" .  They are specified in a function called `hin', where the 
>>> constraints are written such that they are positive.
>>
>> OK - I somehow missed the part that, when the values x are valid,
>>> i.e. in the range as defined by the conditions, the result of hin(x)
>>> that they are all positive.
>>
>>> Your two nonlinear constraints would be written as follows:
>>>
>>> hin <- function(x, LAI) {
>>> h <- rep(NA, 2)
>>> h[1] <- LAI^x[2] / x[3] + x[1]
>>> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
>>> h
>>> }
>>
>> Makes perfect sense.
>>
>>>
>>> Please take a look at the help page.  If it is still not clear, you can contact me offline.
>>
>> Yup - I did. But I somehow missed the fact stated above.
>>
>> I am using constrOptim() and constrOptim.nl() for a paper and am
>>> compiling a separate document which explains how to get the
>>> constraints for the two functions step by step - I will make it
>>> available as a blog post and a pdf.
>>
>> I might have further questions concerning the different fitting
>>> functions and which ones are the most appropriate in my case.
>>
>> Thanks a lot,
>>
>> Rainer
>>
>>
>>> Best,
>>> Ravi
>>>
>>> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
>>> Associate Professor,  Department of Oncology Division of Biostatistics 
>>> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns 
>>> Hopkins University
>>> 550 N. Broadway, Suite 1111-E
>>> Baltimore, MD 21205
>>> 410-502-2619
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982
>>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151006/0da07742/attachment.bin>

From lorenz at usgs.gov  Tue Oct  6 15:32:21 2015
From: lorenz at usgs.gov (Lorenz, David)
Date: Tue, 6 Oct 2015 08:32:21 -0500
Subject: [R] Quantile Regression without intercept
In-Reply-To: <3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>
References: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
	<3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>
Message-ID: <CALxY2LdxoPyzRKH8phisOTZocy8WXQrpn2MMmC0NSbP+0TXTvQ@mail.gmail.com>

Thanks for the details, I suspected something like that.
I think that begs the question: what is the meaning of quantile regression
through the origin? If the tau=.5 line does not pass through 1/2 the data
how do I interpret the line?


On Tue, Oct 6, 2015 at 8:03 AM, Roger Koenker <rkoenker at illinois.edu> wrote:

>
> > On Oct 6, 2015, at 7:58 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> >
> > Did you verify that the correct percentages were above/below the
> regression
> > lines? I did a quick check and for example did not consistently get 50%
> of
> > the observed response values greater than the tau=.5 line. I did when I
> > included the nonzero intercept term.
>
> Your "correct percentages" are only correct when you have an intercept in
> the model,
> without an intercept there is no gradient condition to ensure that.
> >
> >
> >
> >> Date: Mon, 5 Oct 2015 21:14:04 +0530
> >> From: Preetam Pal <lordpreetam at gmail.com>
> >> To: stephen sefick <ssefick at gmail.com>
> >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> >> Subject: Re: [R] Quantile Regression without intercept
> >> Message-ID: <56129a41.025f440a.b1cf4.fffff5ee at mx.google.com>
> >> Content-Type: text/plain; charset="UTF-8"
> >>
> >> Yes..it works. .... Thanks ??
> >>
> >> -----Original Message-----
> >> From: "stephen sefick" <ssefick at gmail.com>
> >> Sent: ?05-?10-?2015 09:01 PM
> >> To: "Preetam Pal" <lordpreetam at gmail.com>
> >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> >> Subject: Re: [R] Quantile Regression without intercept
> >>
> >> I have never used this, but does the formula interface work like lm?
> Y~X-1?
> >>
> >>
> >> On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com>
> >> wrote:
> >>
> >> Hi guys,
> >>
> >> Can you instruct me please how to run quantile regression without the
> >> intercept term? I only know about the rq function under quantreg
> package,
> >> but it automatically uses an intercept model. Icant change that, it
> seems.
> >>
> >> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
> >> Unemployment). Their sizes are 125 each.
> >>
> >> Appreciate your help with this.
> >>
> >> Regards,
> >> Preetam
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> Stephen Sefick
> >> **************************************************
> >> Auburn University
> >> Biological Sciences
> >> 331 Funchess Hall
> >> Auburn, Alabama
> >> 36849
> >> **************************************************
> >> sas0025 at auburn.edu
> >> http://www.auburn.edu/~sas0025
> >> **************************************************
> >>
> >> Let's not spend our time and resources thinking about things that are so
> >> little or so large that all they really do for us is puff us up and
> make us
> >> feel like gods.  We are mammals, and have not exhausted the annoying
> little
> >> problems of being mammals.
> >>
> >>                                -K. Mullis
> >>
> >> "A big computer, a complex algorithm and a long time does not equal
> >> science."
> >>
> >>                              -Robert Gentleman
> >>        [[alternative HTML version deleted]]
> >>
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Tue Oct  6 15:38:13 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Tue, 6 Oct 2015 08:38:13 -0500
Subject: [R] Quantile Regression without intercept
In-Reply-To: <91a5e46eba48442abc188905e1de2dbd@CHIHT3.ad.uillinois.edu>
References: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
	<3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>
	<91a5e46eba48442abc188905e1de2dbd@CHIHT3.ad.uillinois.edu>
Message-ID: <8CE4F61D-E77B-4F65-B4E1-C1F90E01F3DD@illinois.edu>


> On Oct 6, 2015, at 8:32 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> 
> Thanks for the details, I suspected something like that.
> I think that begs the question: what is the meaning of quantile regression through the origin? If the tau=.5 line does not pass through 1/2 the data how do I interpret the line?

As an estimate of the conditional median (quantile) function when constrained to pass through
the origin? as with least squares fitting without an intercept, you do this at your peril.
> 
> 
> On Tue, Oct 6, 2015 at 8:03 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
> 
> > On Oct 6, 2015, at 7:58 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> >
> > Did you verify that the correct percentages were above/below the regression
> > lines? I did a quick check and for example did not consistently get 50% of
> > the observed response values greater than the tau=.5 line. I did when I
> > included the nonzero intercept term.
> 
> Your "correct percentages" are only correct when you have an intercept in the model,
> without an intercept there is no gradient condition to ensure that.
> >
> >
> >
> >> Date: Mon, 5 Oct 2015 21:14:04 +0530
> >> From: Preetam Pal <lordpreetam at gmail.com>
> >> To: stephen sefick <ssefick at gmail.com>
> >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> >> Subject: Re: [R] Quantile Regression without intercept
> >> Message-ID: <56129a41.025f440a.b1cf4.fffff5ee at mx.google.com>
> >> Content-Type: text/plain; charset="UTF-8"
> >>
> >> Yes..it works. .... Thanks ??
> >>
> >> -----Original Message-----
> >> From: "stephen sefick" <ssefick at gmail.com>
> >> Sent: ?05-?10-?2015 09:01 PM
> >> To: "Preetam Pal" <lordpreetam at gmail.com>
> >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> >> Subject: Re: [R] Quantile Regression without intercept
> >>
> >> I have never used this, but does the formula interface work like lm? Y~X-1?
> >>
> >>
> >> On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com>
> >> wrote:
> >>
> >> Hi guys,
> >>
> >> Can you instruct me please how to run quantile regression without the
> >> intercept term? I only know about the rq function under quantreg package,
> >> but it automatically uses an intercept model. Icant change that, it seems.
> >>
> >> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
> >> Unemployment). Their sizes are 125 each.
> >>
> >> Appreciate your help with this.
> >>
> >> Regards,
> >> Preetam
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> Stephen Sefick
> >> **************************************************
> >> Auburn University
> >> Biological Sciences
> >> 331 Funchess Hall
> >> Auburn, Alabama
> >> 36849
> >> **************************************************
> >> sas0025 at auburn.edu
> >> http://www.auburn.edu/~sas0025
> >> **************************************************
> >>
> >> Let's not spend our time and resources thinking about things that are so
> >> little or so large that all they really do for us is puff us up and make us
> >> feel like gods.  We are mammals, and have not exhausted the annoying little
> >> problems of being mammals.
> >>
> >>                                -K. Mullis
> >>
> >> "A big computer, a complex algorithm and a long time does not equal
> >> science."
> >>
> >>                              -Robert Gentleman
> >>        [[alternative HTML version deleted]]
> >>
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 


From pdalgd at gmail.com  Tue Oct  6 16:13:15 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 6 Oct 2015 16:13:15 +0200
Subject: [R] Quantile Regression without intercept
In-Reply-To: <8CE4F61D-E77B-4F65-B4E1-C1F90E01F3DD@illinois.edu>
References: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
	<3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>
	<91a5e46eba48442abc188905e1de2dbd@CHIHT3.ad.uillinois.edu>
	<8CE4F61D-E77B-4F65-B4E1-C1F90E01F3DD@illinois.edu>
Message-ID: <B29FD67F-2DD2-436E-ABB5-A854D3902767@gmail.com>

To wit:

> y <- rnorm(100, 10)
> x <- 1:100
> sum(resid(lm(y~x)))
[1] 1.047773e-15
> sum(resid(lm(y~x-1)))
[1] 243.0583

and replicating this should convince you that the mean residual really is not zero in the severely misspecified model with no intercept. (This has to do with the fact that residuals for small x will be positive but have little leverage on the slope of the regression line.) 

With a correctly specified model, the theoretical mean residual is in fact zero, but it won't be exactly zero for any individual fit. Try e.g.

> x <- 1:100
> r <- replicate(10000, {y <- rnorm(100, x); mean(resid(lm(y~x-1)))})
> hist(r)

-pd

On 06 Oct 2015, at 15:38 , Roger Koenker <rkoenker at illinois.edu> wrote:

> 
>> On Oct 6, 2015, at 8:32 AM, Lorenz, David <lorenz at usgs.gov> wrote:
>> 
>> Thanks for the details, I suspected something like that.
>> I think that begs the question: what is the meaning of quantile regression through the origin? If the tau=.5 line does not pass through 1/2 the data how do I interpret the line?
> 
> As an estimate of the conditional median (quantile) function when constrained to pass through
> the origin? as with least squares fitting without an intercept, you do this at your peril.
>> 
>> 
>> On Tue, Oct 6, 2015 at 8:03 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
>> 
>>> On Oct 6, 2015, at 7:58 AM, Lorenz, David <lorenz at usgs.gov> wrote:
>>> 
>>> Did you verify that the correct percentages were above/below the regression
>>> lines? I did a quick check and for example did not consistently get 50% of
>>> the observed response values greater than the tau=.5 line. I did when I
>>> included the nonzero intercept term.
>> 
>> Your "correct percentages" are only correct when you have an intercept in the model,
>> without an intercept there is no gradient condition to ensure that.

[snip]

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dcarlson at tamu.edu  Tue Oct  6 15:31:55 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 6 Oct 2015 13:31:55 +0000
Subject: [R] Strange Bug in R
In-Reply-To: <56138C00.8090003@auckland.ac.nz>
References: <1444116299375-4713175.post@n4.nabble.com>
	<8AC41084-1B01-46E4-A47A-2BBB6F7DBBDA@xs4all.nl>
	<56138C00.8090003@auckland.ac.nz>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CBF3D@mb02.ads.tamu.edu>

There is a simple way to get closer to how a floating point number is stored in R with dput():

> dput(min(dataset$gpa))
1.89999997615814
> dput(dataset$gpa[290])
1.89999997615814

So you can see, the minimum is not 1.9, just very close to 1.9.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Rolf Turner
Sent: Tuesday, October 6, 2015 3:53 AM
To: Berend Hasselman
Cc: r-help at r-project.org; Neverstop
Subject: Re: [R] Strange Bug in R

On 06/10/15 21:28, Berend Hasselman wrote:
>
>> On 6 Oct 2015, at 09:24, Neverstop <neverstop at hotmail.it> wrote:
>>
>> Hi all.
>> I don't understand why R works this way:
>>> rm(list=ls())
>>> require(foreign)
>>> dataset <- read.dta("http://www.ats.ucla.edu/stat/data/ologit.dta")
>>> min(dataset$gpa)
>> [1] 1.9
>>> min(dataset$gpa)>=1.90
>> [1] FALSE
>>> min(dataset$gpa)>=1.9
>> [1] FALSE
>>> min(dataset$gpa)>1.89
>> [1] TRUE
>> Shouldn't I get 3 TRUEs?
>> Am I missing something?
>> Thank you.
>>
>>
>
> See R FAQ 7.31  in https://cran.r-project.org/doc/FAQ/R-FAQ.html
> It should provide clarification for your puzzlement.

Not really.  The problem is one of the precision to which a floating 
point number is *printed* rather than one of the way that floating point 
numbers are *calculated*.  Hence it is not an instance of the 
counter-intuitive nature of floating point arithmetic.  I.e. you could 
have numbers a and b that were calculated and stored to *infinite* 
precision, appear to be equal when printed to some default number of 
significant figures, but are not actually equal.

The problems are related and both involve having some understanding of 
floating point numbers, but they are not the same problem.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From johannesradinger at gmail.com  Tue Oct  6 16:38:11 2015
From: johannesradinger at gmail.com (Johannes Radinger)
Date: Tue, 6 Oct 2015 16:38:11 +0200
Subject: [R] regex sub with specified number of characters
Message-ID: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>

Hi

I'd like to remove a leading "3" if my number is 7 digits long, if it is
only 6 I don't want to anything.
I think this should be possible with a 1-liner using sub() but I am not
sure how to define the number of characters following the leading one.

For example my vector:

a <- c(3593857,384723,4395843,3398374)

with sub("^3","",a) I also remove the leading from the second element which
is only 6 digits long. So how to restrict that using sub? The final result
should be

a <- c(593857,384723,4395843,398374)

Any suggestions?

Best regards,
Johannes

	[[alternative HTML version deleted]]


From ivan.calandra at univ-reims.fr  Tue Oct  6 16:42:17 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 6 Oct 2015 16:42:17 +0200
Subject: [R] vector graphics
Message-ID: <5613DDC9.5030400@univ-reims.fr>

Dear useRs,

A colleague of mine is having a problem with graphic devices. The goal 
is to save into a vector graphic format that can be edited with 
Illustrator CS4.

On my Mac (Snow Leopard), I use RSvgDevice::devSVG() and it works fine.
But on her Windows Vista computer, I cannot find an alternative.> 
sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows Vista (build 6002) Service Pack 2

I have tried:
- pdf(): I cannot dissociate the graphical elements (no problem with text)
- cairo_pdf(): the text is replaced by symbols
- cairo_ps(): fine except that the text is not text but object (it is 
then a bit troublesome, as any text modification requires the text to be 
completely rewritten)
- svg(): the graphic is completely screwed up (it seems to be a scaling 
problem, with symbols and letters all very large and superposed)
- RSvgDevice cannot be installed on the Windows machine, neither as 
binary nor from source.

Is there any other device that could work? If not, is it a matter of 
settings? So, basically, what can I do?

Thank you in advance,
Ivan

-- 
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra


From ivan.calandra at univ-reims.fr  Tue Oct  6 16:47:00 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 6 Oct 2015 16:47:00 +0200
Subject: [R] regex sub with specified number of characters
In-Reply-To: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>
References: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>
Message-ID: <5613DEE4.8010100@univ-reims.fr>

Hi Johannes,

Not sure if this can be done with sub() only, but combining it with 
ifelse() apparently does what you want:
ifelse(nchar(a)==7, sub("^3","",a), a)

HTH,
Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 06/10/15 16:38, Johannes Radinger a ?crit :
> Hi
>
> I'd like to remove a leading "3" if my number is 7 digits long, if it is
> only 6 I don't want to anything.
> I think this should be possible with a 1-liner using sub() but I am not
> sure how to define the number of characters following the leading one.
>
> For example my vector:
>
> a <- c(3593857,384723,4395843,3398374)
>
> with sub("^3","",a) I also remove the leading from the second element which
> is only 6 digits long. So how to restrict that using sub? The final result
> should be
>
> a <- c(593857,384723,4395843,398374)
>
> Any suggestions?
>
> Best regards,
> Johannes
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_schwartz at me.com  Tue Oct  6 16:50:08 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 06 Oct 2015 09:50:08 -0500
Subject: [R] regex sub with specified number of characters
In-Reply-To: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>
References: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>
Message-ID: <F93E1847-A937-450B-9E4E-7C174446CD85@me.com>


> On Oct 6, 2015, at 9:38 AM, Johannes Radinger <johannesradinger at gmail.com> wrote:
> 
> Hi
> 
> I'd like to remove a leading "3" if my number is 7 digits long, if it is
> only 6 I don't want to anything.
> I think this should be possible with a 1-liner using sub() but I am not
> sure how to define the number of characters following the leading one.
> 
> For example my vector:
> 
> a <- c(3593857,384723,4395843,3398374)
> 
> with sub("^3","",a) I also remove the leading from the second element which
> is only 6 digits long. So how to restrict that using sub? The final result
> should be
> 
> a <- c(593857,384723,4395843,398374)
> 
> Any suggestions?
> 
> Best regards,
> Johannes


Hi,

> gsub("^3([0-9]{6})$", "\\1", a)
[1] "593857"  "384723"  "4395843" "398374" 

or

> sub("^3([0-9]{6})$", "\\1", a)
[1] "593857"  "384723"  "4395843" "398374" 


If the source begins with a 3 followed by 6 digits only from 0 to 9, it will return the 6 digits part of the regex within the parens.

Otherwise, the source is returned unchanged.

See ?regex

Regards,

Marc Schwartz


From dwinsemius at comcast.net  Tue Oct  6 16:51:27 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 6 Oct 2015 07:51:27 -0700
Subject: [R] regex sub with specified number of characters
In-Reply-To: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>
References: <CABsGe_w6p9tLvDA3kN4CUrt9qOS-2Wg5cnb_MYmnHc_pXMu1_A@mail.gmail.com>
Message-ID: <C89BBC46-95A0-43D7-8F3D-2462E969E9FB@comcast.net>


On Oct 6, 2015, at 7:38 AM, Johannes Radinger wrote:

> Hi
> 
> I'd like to remove a leading "3" if my number is 7 digits long, if it is
> only 6 I don't want to anything.
> I think this should be possible with a 1-liner using sub() but I am not
> sure how to define the number of characters following the leading one.
> 
> For example my vector:
> 
> a <- c(3593857,384723,4395843,3398374)
> 
> with sub("^3","",a) I also remove the leading from the second element which
> is only 6 digits long. So how to restrict that using sub? The final result
> should be
> 
> a <- c(593857,384723,4395843,398374)

Use a wild-card capture class of the correct length:

> sub("^3(.{6})$", "\\1", a)
[1] "593857"  "384723"  "4395843" "398374" 

> 
> 	[[alternative HTML version deleted]]

It doesn't affect this post but you are requested to post in plain text.

-- 

David Winsemius
Alameda, CA, USA


From bgnumis at gmail.com  Tue Oct  6 15:20:10 2015
From: bgnumis at gmail.com (bgnumis bgnum)
Date: Tue, 6 Oct 2015 15:20:10 +0200
Subject: [R] Polygon shade
Message-ID: <CAN25tHT=mCO_qs6uXK4PNaHJZJUjRhvbZ8RFXWds4WdC+0xSwQ@mail.gmail.com>

Hi All,

I want to shade the area below "f" variable and it doesn?t draw:

plot(z$Dateh[nn:length(z$Dateh)],f,type="l",col="black", xlab="Time",
ylab="Line")
grid()
polygon(c(1, 1:st, st),c(0, f, 0), col = "blue")

st is the length of f.

But if I plot

plot(f,type="l",col="black", xlab="Time", ylab="Correlation")
grid()
polygon(c(1, 1:st, st),c(0, f, 0), col = "blue")

But the axis doesn?t refect the date labels.

?What should I do in the first code to achive it draws the blue?

?If not? How can I ommit the axis in the scond code and to add the
z$Dateh[nn:length(z$Dateh)?

Hope someone can help me.

	[[alternative HTML version deleted]]


From marco.otoya.chavarria at una.cr  Tue Oct  6 17:14:45 2015
From: marco.otoya.chavarria at una.cr (Marco Otoya Chavarria)
Date: Tue, 6 Oct 2015 09:14:45 -0600
Subject: [R] help with problem
Message-ID: <CACrOZ1_PJ7_FpGoLp1c2BDE+=pe7PTRBXwKkojH89VuZDAw_Eg@mail.gmail.com>

*When i tried to read a table i**n .csv or .txt format R i get the
following message and give some problem in orden to run the data o
make test, etc*

*Warning message*

*In read.table(file = file, header = header, sep =";")
*>*  incomplete final line found by readTableHeader on 'test.csv*

*I tried Uninstall R and Excel, and install again but the problem doesnt fix.*

*Regard*

	[[alternative HTML version deleted]]


From timilsinaamit87 at huskers.unl.edu  Tue Oct  6 17:31:33 2015
From: timilsinaamit87 at huskers.unl.edu (timilsina)
Date: Tue, 6 Oct 2015 08:31:33 -0700 (PDT)
Subject: [R] Getting monthly mean
Message-ID: <1444145493692-4713209.post@n4.nabble.com>

Hi all,

How can I get the monthly means from netcdf files using R? If there is any
examples already on web resources? Please share with me.



Regards,
Amit



--
View this message in context: http://r.789695.n4.nabble.com/Getting-monthly-mean-tp4713209.html
Sent from the R help mailing list archive at Nabble.com.


From amwootte at ncsu.edu  Tue Oct  6 19:42:26 2015
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 6 Oct 2015 13:42:26 -0400
Subject: [R] apply regression to an array
Message-ID: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>

R-Helpers,

I've seen some similar threads about this question online, but not quite
what I'm looking for.  I apologize in advance if someone's already answered
this and I just can't find it online.

Say that I have an array like test3 in the little example code I have below:

test1 = array(rep(1:10,each = 25),dim=c(5,5,10))
test2 = array(rnorm(250,0,0.35),dim=c(5,5,10))
test3 = test1+test2 # array with 5 rows, 5 columns, 10 slices

time=1:10

Where the dimensions are x, y, and time.  What I'd like to do is run a
regression (for the sake of this example, say lm) on each x,y in time.  So
for a single cell the formula might be test3[1,1,]~time, but I'd like to
that for all cells.  The only way I can immediately think of is to use a
loop, but I'm wondering if there's a way to do this without a loop.
Perhaps with tapply?

I'm actually doing a fourth order regression with a much larger array, but
this simple example illustrates the question I have.

Many thanks for the help! Sorry if someone's already answered this and I
can't find it.

Adrienne

-- 
Adrienne Wootten
Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Tue Oct  6 19:47:18 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 6 Oct 2015 13:47:18 -0400
Subject: [R] help with problem
In-Reply-To: <CACrOZ1_PJ7_FpGoLp1c2BDE+=pe7PTRBXwKkojH89VuZDAw_Eg@mail.gmail.com>
References: <CACrOZ1_PJ7_FpGoLp1c2BDE+=pe7PTRBXwKkojH89VuZDAw_Eg@mail.gmail.com>
Message-ID: <CAM_vjumvaQ1wr65U=1pmbc3T4TBQrFpPV0sctac8hEXYfpBPbg@mail.gmail.com>

http://stackoverflow.com/questions/5990654/incomplete-final-line-warning-when-trying-to-read-a-csv-file-into-r

On Tue, Oct 6, 2015 at 11:14 AM, Marco Otoya Chavarria
<marco.otoya.chavarria at una.cr> wrote:
> *When i tried to read a table i**n .csv or .txt format R i get the
> following message and give some problem in orden to run the data o
> make test, etc*
>
> *Warning message*
>
> *In read.table(file = file, header = header, sep =";")
> *>*  incomplete final line found by readTableHeader on 'test.csv*
>
> *I tried Uninstall R and Excel, and install again but the problem doesnt fix.*
>
> *Regard*
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Oct  6 19:49:11 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 6 Oct 2015 13:49:11 -0400
Subject: [R] Getting monthly mean
In-Reply-To: <1444145493692-4713209.post@n4.nabble.com>
References: <1444145493692-4713209.post@n4.nabble.com>
Message-ID: <CAM_vjumULAsKkJD33nR_VD1f_OPpDfVCTHY35JKnJzk2foSoAw@mail.gmail.com>

There are various tools available; searching for netcdf on rseek.org
or browsing CRAN will get you quite a few.

Meanwhile this might help you get started:
http://disc.sci.gsfc.nasa.gov/recipes/?q=recipes/How-to-Read-Data-in-netCDF-Format-with-R

Sarah

On Tue, Oct 6, 2015 at 11:31 AM, timilsina
<timilsinaamit87 at huskers.unl.edu> wrote:
> Hi all,
>
> How can I get the monthly means from netcdf files using R? If there is any
> examples already on web resources? Please share with me.
>
>
>
> Regards,
> Amit
>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From alamsharique45 at gmail.com  Tue Oct  6 19:25:47 2015
From: alamsharique45 at gmail.com (Sharique Alam)
Date: Tue, 6 Oct 2015 22:55:47 +0530
Subject: [R] R implementation on windows server
Message-ID: <CACcZPv5aZP7YPqq8rUAMid81GWM-_49bKPexXB_bcEcKu1qCJw@mail.gmail.com>

Hi Team,

We are required to install r on a windows server

Request you to kindly help us in below queries:

1> Pre requisite for installing R if any
2> Do we have to install R and R studio both
3> Users also want to utilize shiny package ,so do we only need to install
shiny package or will have to install shiny server also and configure it

	[[alternative HTML version deleted]]


From amwootte at ncsu.edu  Tue Oct  6 20:41:31 2015
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 6 Oct 2015 14:41:31 -0400
Subject: [R] apply regression to an array
In-Reply-To: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
References: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
Message-ID: <CAOV3wDCjjGE_o0FOUFQ=QDXYsnnTyi=aNB2z7jQk_AGWitqCwQ@mail.gmail.com>

FYI I did try something like this:

test = apply(test3,c(1,2),lmfunc,input=t)

but that gives me an array that is 10 rows by 5 columns by 5 slices, and I
need it to keep the same dimensions as test3 (5x5x10)

A

On Tue, Oct 6, 2015 at 1:42 PM, Adrienne Wootten <amwootte at ncsu.edu> wrote:

> R-Helpers,
>
> I've seen some similar threads about this question online, but not quite
> what I'm looking for.  I apologize in advance if someone's already answered
> this and I just can't find it online.
>
> Say that I have an array like test3 in the little example code I have
> below:
>
> test1 = array(rep(1:10,each = 25),dim=c(5,5,10))
> test2 = array(rnorm(250,0,0.35),dim=c(5,5,10))
> test3 = test1+test2 # array with 5 rows, 5 columns, 10 slices
>
> time=1:10
>
> Where the dimensions are x, y, and time.  What I'd like to do is run a
> regression (for the sake of this example, say lm) on each x,y in time.  So
> for a single cell the formula might be test3[1,1,]~time, but I'd like to
> that for all cells.  The only way I can immediately think of is to use a
> loop, but I'm wondering if there's a way to do this without a loop.
> Perhaps with tapply?
>
> I'm actually doing a fourth order regression with a much larger array, but
> this simple example illustrates the question I have.
>
> Many thanks for the help! Sorry if someone's already answered this and I
> can't find it.
>
> Adrienne
>
> --
> Adrienne Wootten
> Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
>



-- 
Adrienne Wootten
Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From amwootte at ncsu.edu  Tue Oct  6 20:42:30 2015
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 6 Oct 2015 14:42:30 -0400
Subject: [R] apply regression to an array
In-Reply-To: <CAOV3wDCjjGE_o0FOUFQ=QDXYsnnTyi=aNB2z7jQk_AGWitqCwQ@mail.gmail.com>
References: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
	<CAOV3wDCjjGE_o0FOUFQ=QDXYsnnTyi=aNB2z7jQk_AGWitqCwQ@mail.gmail.com>
Message-ID: <CAOV3wDBJ26h1j4C=R9Y8PCv3-Fn7o=R09J+H_c3D8nXNk4A4Rw@mail.gmail.com>

Almost forgot that function lmfunc is this:

lmfunc = function(valist,input){
  fitted.values(lm(valist~input))
}

A


On Tue, Oct 6, 2015 at 2:41 PM, Adrienne Wootten <amwootte at ncsu.edu> wrote:

> FYI I did try something like this:
>
> test = apply(test3,c(1,2),lmfunc,input=t)
>
> but that gives me an array that is 10 rows by 5 columns by 5 slices, and I
> need it to keep the same dimensions as test3 (5x5x10)
>
> A
>
> On Tue, Oct 6, 2015 at 1:42 PM, Adrienne Wootten <amwootte at ncsu.edu>
> wrote:
>
>> R-Helpers,
>>
>> I've seen some similar threads about this question online, but not quite
>> what I'm looking for.  I apologize in advance if someone's already answered
>> this and I just can't find it online.
>>
>> Say that I have an array like test3 in the little example code I have
>> below:
>>
>> test1 = array(rep(1:10,each = 25),dim=c(5,5,10))
>> test2 = array(rnorm(250,0,0.35),dim=c(5,5,10))
>> test3 = test1+test2 # array with 5 rows, 5 columns, 10 slices
>>
>> time=1:10
>>
>> Where the dimensions are x, y, and time.  What I'd like to do is run a
>> regression (for the sake of this example, say lm) on each x,y in time.  So
>> for a single cell the formula might be test3[1,1,]~time, but I'd like to
>> that for all cells.  The only way I can immediately think of is to use a
>> loop, but I'm wondering if there's a way to do this without a loop.
>> Perhaps with tapply?
>>
>> I'm actually doing a fourth order regression with a much larger array,
>> but this simple example illustrates the question I have.
>>
>> Many thanks for the help! Sorry if someone's already answered this and I
>> can't find it.
>>
>> Adrienne
>>
>> --
>> Adrienne Wootten
>> Graduate Research Assistant
>> State Climate Office of North Carolina
>> Department of Marine, Earth and Atmospheric Sciences
>> North Carolina State University
>>
>
>
>
> --
> Adrienne Wootten
> Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
>



-- 
Adrienne Wootten
Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct  6 20:56:38 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Oct 2015 11:56:38 -0700
Subject: [R] apply regression to an array
In-Reply-To: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
References: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
Message-ID: <CAF8bMcYz5QedOcxyr=ADjKo3Zr47DJ0mx5NTB87BaB01C1OOBQ@mail.gmail.com>

Since the model matrix, cbind(1,time) is the same for all your
response variables,
you can calculate this on one call to lm, but you have to rearrange the response
values so that each x,y set is in one column.  I think the following
function does it:

f <- function (time, y)
{
    stopifnot(length(dim(y)) == 3, dim(y)[3] == length(time))
    yMatrix <- matrix(aperm(y, c(3, 1, 2)), dim(y)[3])
    fit <- lm(yMatrix ~ time)
    aperm(array(fitted.values(fit), dim(y)[c(3, 1, 2)]), c(2,
        3, 1))
}

E.g.,
> fitted.values(lm(test1[2,5,]~time))
 1  2  3  4  5  6  7  8  9 10
 1  2  3  4  5  6  7  8  9 10
> f(time, test1)[2,5,]
 [1]  1  2  3  4  5  6  7  8  9 10


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Oct 6, 2015 at 10:42 AM, Adrienne Wootten <amwootte at ncsu.edu> wrote:
> R-Helpers,
>
> I've seen some similar threads about this question online, but not quite
> what I'm looking for.  I apologize in advance if someone's already answered
> this and I just can't find it online.
>
> Say that I have an array like test3 in the little example code I have below:
>
> test1 = array(rep(1:10,each = 25),dim=c(5,5,10))
> test2 = array(rnorm(250,0,0.35),dim=c(5,5,10))
> test3 = test1+test2 # array with 5 rows, 5 columns, 10 slices
>
> time=1:10
>
> Where the dimensions are x, y, and time.  What I'd like to do is run a
> regression (for the sake of this example, say lm) on each x,y in time.  So
> for a single cell the formula might be test3[1,1,]~time, but I'd like to
> that for all cells.  The only way I can immediately think of is to use a
> loop, but I'm wondering if there's a way to do this without a loop.
> Perhaps with tapply?
>
> I'm actually doing a fourth order regression with a much larger array, but
> this simple example illustrates the question I have.
>
> Many thanks for the help! Sorry if someone's already answered this and I
> can't find it.
>
> Adrienne
>
> --
> Adrienne Wootten
> Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lauren.spirko at temple.edu  Tue Oct  6 20:54:47 2015
From: lauren.spirko at temple.edu (lspirk)
Date: Tue, 6 Oct 2015 11:54:47 -0700 (PDT)
Subject: [R] variance of beta using prop.odds function in timereg package
Message-ID: <1444157687044-4713220.post@n4.nabble.com>

Hi all,

I am trying to calculate the variance-covariance matrix for parameter Beta
under the null (Ho) using the "prop.odds" function in the timereg package.

For the Cox PH model, I used the "vcov" function and did the following:

        cox <- coxph(Surv(time, censor) ~ x, iter = 0, init = 0, data = dat)
        sig2 <- vcov(cox)

However, this vcov() does not work with the object created from "prop.odds".

Is there something similar I can do to get this value from a prop.odds
model?

Thanks for the help!



--
View this message in context: http://r.789695.n4.nabble.com/variance-of-beta-using-prop-odds-function-in-timereg-package-tp4713220.html
Sent from the R help mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Tue Oct  6 21:07:30 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 6 Oct 2015 15:07:30 -0400
Subject: [R] R implementation on windows server
In-Reply-To: <CACcZPv5aZP7YPqq8rUAMid81GWM-_49bKPexXB_bcEcKu1qCJw@mail.gmail.com>
References: <CACcZPv5aZP7YPqq8rUAMid81GWM-_49bKPexXB_bcEcKu1qCJw@mail.gmail.com>
Message-ID: <56141BF2.40409@gmail.com>

On 06/10/2015 1:25 PM, Sharique Alam wrote:
> Hi Team,
>
> We are required to install r on a windows server
>
> Request you to kindly help us in below queries:
>
> 1> Pre requisite for installing R if any

There are none.
> 2> Do we have to install R and R studio both

R Studio is a separate product; it is a front end for R.  If your users 
want it, you'll need to install it separately.
> 3> Users also want to utilize shiny package ,so do we only need to install
> shiny package or will have to install shiny server also and configure it

Shiny is a package within R.  I don't think it requires R Studio, though 
they're by the same people and work together well.  The server is 
optional --- it will allow your users to make their Shiny applications 
available to others.  If your users want that, it's a separate install.  
The company that produced RStudio and Shiny also runs a service hosting 
Shiny applications; it's free for small demos, but you would pay for 
heavier use.

Duncan Murdoch


From amwootte at ncsu.edu  Tue Oct  6 21:42:04 2015
From: amwootte at ncsu.edu (Adrienne Wootten)
Date: Tue, 6 Oct 2015 15:42:04 -0400
Subject: [R] apply regression to an array
In-Reply-To: <CAF8bMcYz5QedOcxyr=ADjKo3Zr47DJ0mx5NTB87BaB01C1OOBQ@mail.gmail.com>
References: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
	<CAF8bMcYz5QedOcxyr=ADjKo3Zr47DJ0mx5NTB87BaB01C1OOBQ@mail.gmail.com>
Message-ID: <CAOV3wDB4-SLt9bsJO=_XwsiDqKnz4mTRdrs_OS7VWo09XvwiAg@mail.gmail.com>

Bill,

Thanks a bunch that works great!

A

On Tue, Oct 6, 2015 at 2:56 PM, William Dunlap <wdunlap at tibco.com> wrote:

> Since the model matrix, cbind(1,time) is the same for all your
> response variables,
> you can calculate this on one call to lm, but you have to rearrange the
> response
> values so that each x,y set is in one column.  I think the following
> function does it:
>
> f <- function (time, y)
> {
>     stopifnot(length(dim(y)) == 3, dim(y)[3] == length(time))
>     yMatrix <- matrix(aperm(y, c(3, 1, 2)), dim(y)[3])
>     fit <- lm(yMatrix ~ time)
>     aperm(array(fitted.values(fit), dim(y)[c(3, 1, 2)]), c(2,
>         3, 1))
> }
>
> E.g.,
> > fitted.values(lm(test1[2,5,]~time))
>  1  2  3  4  5  6  7  8  9 10
>  1  2  3  4  5  6  7  8  9 10
> > f(time, test1)[2,5,]
>  [1]  1  2  3  4  5  6  7  8  9 10
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Oct 6, 2015 at 10:42 AM, Adrienne Wootten <amwootte at ncsu.edu>
> wrote:
> > R-Helpers,
> >
> > I've seen some similar threads about this question online, but not quite
> > what I'm looking for.  I apologize in advance if someone's already
> answered
> > this and I just can't find it online.
> >
> > Say that I have an array like test3 in the little example code I have
> below:
> >
> > test1 = array(rep(1:10,each = 25),dim=c(5,5,10))
> > test2 = array(rnorm(250,0,0.35),dim=c(5,5,10))
> > test3 = test1+test2 # array with 5 rows, 5 columns, 10 slices
> >
> > time=1:10
> >
> > Where the dimensions are x, y, and time.  What I'd like to do is run a
> > regression (for the sake of this example, say lm) on each x,y in time.
> So
> > for a single cell the formula might be test3[1,1,]~time, but I'd like to
> > that for all cells.  The only way I can immediately think of is to use a
> > loop, but I'm wondering if there's a way to do this without a loop.
> > Perhaps with tapply?
> >
> > I'm actually doing a fourth order regression with a much larger array,
> but
> > this simple example illustrates the question I have.
> >
> > Many thanks for the help! Sorry if someone's already answered this and I
> > can't find it.
> >
> > Adrienne
> >
> > --
> > Adrienne Wootten
> > Graduate Research Assistant
> > State Climate Office of North Carolina
> > Department of Marine, Earth and Atmospheric Sciences
> > North Carolina State University
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Adrienne Wootten
Graduate Research Assistant
State Climate Office of North Carolina
Department of Marine, Earth and Atmospheric Sciences
North Carolina State University

	[[alternative HTML version deleted]]


From hnorpois at gmail.com  Tue Oct  6 21:20:13 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 6 Oct 2015 21:20:13 +0200
Subject: [R] cut - strange NA as output
Message-ID: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>

Hello,

why do I get NA for the following:

cut (x, seq (0, max(x), by=1), label=FALSE)
 [1] 1322 1175 1155 1149 1295 1173 1289 1197   NA 1129

dput (x)
c(1321.55376901374, 1174.35657200935, 1154.02042504008, 1148.60981925942,
1294.6166388941, 1172.45806806869, 1288.31933914639, 1196.26080041462,
1355.88836502166, 1128.09901883228)

Thanks
Hermann

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct  6 21:54:56 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Oct 2015 12:54:56 -0700
Subject: [R] cut - strange NA as output
In-Reply-To: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
References: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
Message-ID: <CAF8bMca9tZz6JpAJ=9Ft9HV+yZYtpzCEXQcVp5ufja+LtcOjHQ@mail.gmail.com>

Because
  > tail(seq(0, max(x), by=1))
  [1] 1350 1351 1352 1353 1354 1355
  > tail(seq(0, ceiling(max(x)), by=1))
  [1] 1351 1352 1353 1354 1355 1356
and max(x)=1355.88836502166 is beyond the range
of the former.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Oct 6, 2015 at 12:20 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> why do I get NA for the following:
>
> cut (x, seq (0, max(x), by=1), label=FALSE)
>  [1] 1322 1175 1155 1149 1295 1173 1289 1197   NA 1129
>
> dput (x)
> c(1321.55376901374, 1174.35657200935, 1154.02042504008, 1148.60981925942,
> 1294.6166388941, 1172.45806806869, 1288.31933914639, 1196.26080041462,
> 1355.88836502166, 1128.09901883228)
>
> Thanks
> Hermann
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Tue Oct  6 21:57:59 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 06 Oct 2015 14:57:59 -0500
Subject: [R] cut - strange NA as output
In-Reply-To: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
References: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
Message-ID: <AB37EDC3-9ADB-4237-A1F9-444A9745C99B@me.com>


> On Oct 6, 2015, at 2:20 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> 
> Hello,
> 
> why do I get NA for the following:
> 
> cut (x, seq (0, max(x), by=1), label=FALSE)
> [1] 1322 1175 1155 1149 1295 1173 1289 1197   NA 1129
> 
> dput (x)
> c(1321.55376901374, 1174.35657200935, 1154.02042504008, 1148.60981925942,
> 1294.6166388941, 1172.45806806869, 1288.31933914639, 1196.26080041462,
> 1355.88836502166, 1128.09901883228)
> 
> Thanks
> Hermann


> max(x)
[1] 1355.888

> range(seq(0, max(x), by = 1))
[1]    0 1355


max(x) is outside (above) the range of the integer sequence of break points for cut() that you specified above. Thus, when cut() gets to the 9th element in x, the value is undefined.

> cut (x, seq(0, max(x) + 1, by = 1), label=FALSE)
 [1] 1322 1175 1155 1149 1295 1173 1289 1197 1356 1129

or

> cut (x, seq(0, ceiling(max(x)), by = 1), label=FALSE)
 [1] 1322 1175 1155 1149 1295 1173 1289 1197 1356 1129


Both of the above approaches will increment the sequence 0:max(x) to 1356:

> range(seq(0, max(x) + 1, by = 1))
[1]    0 1356

> range(seq(0, ceiling(max(x)), by = 1))
[1]    0 1356


Regards,

Marc Schwartz


From olivier.crouzet at univ-nantes.fr  Tue Oct  6 22:05:45 2015
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Tue, 6 Oct 2015 22:05:45 +0200
Subject: [R] cut - strange NA as output
In-Reply-To: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
References: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
Message-ID: <20151006220545.aa593d0cc33240d54fca80e3@univ-nantes.fr>

Hi,

On Tue, 6 Oct 2015 21:20:13 +0200
Hermann Norpois <hnorpois at gmail.com> wrote:

> Hello,
> 
> why do I get NA for the following:
> 
> cut (x, seq (0, max(x), by=1), label=FALSE)
>  [1] 1322 1175 1155 1149 1295 1173 1289 1197   NA 1129

The NA comes from your max value and it's due to your seq(0, max(x),
by = 1) creating a sequence that will stop BEFORE your decimal max
(x)... Therefore the element of x which equals 1355.888 is not part of
the allowed outputs of cut().

Are you sure you would not rather use either round (x) or ceiling
(x)? Not sure however what you really want from this...

Olivier.

> 
> dput (x)
> c(1321.55376901374, 1174.35657200935, 1154.02042504008,
> 1148.60981925942, 1294.6166388941, 1172.45806806869,
> 1288.31933914639, 1196.26080041462, 1355.88836502166,
> 1128.09901883228)
> 
> Thanks
> Hermann
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From dcarlson at tamu.edu  Tue Oct  6 22:59:28 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 6 Oct 2015 20:59:28 +0000
Subject: [R] help with problem
In-Reply-To: <CACrOZ1_PJ7_FpGoLp1c2BDE+=pe7PTRBXwKkojH89VuZDAw_Eg@mail.gmail.com>
References: <CACrOZ1_PJ7_FpGoLp1c2BDE+=pe7PTRBXwKkojH89VuZDAw_Eg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CC4AC@mb02.ads.tamu.edu>

You have a warning, not an error. The command ran but there was a problem with the .csv or .txt file. 

You should have a partial data set in R. Try using the str() function to see what variables and what rows were read. Adding the fill=TRUE argument to read.table() will pad incomplete rows with blanks, but you should check the data to make sure you have what you were expecting.

Without the data it is impossible to be sure, but you may have an incomplete line at the end of your data file. Use a text editor to look at your data so see if the last line is incomplete. 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco Otoya Chavarria
Sent: Tuesday, October 6, 2015 10:15 AM
To: r-help at r-project.org
Subject: [R] help with problem

*When i tried to read a table i**n .csv or .txt format R i get the
following message and give some problem in orden to run the data o
make test, etc*

*Warning message*

*In read.table(file = file, header = header, sep =";")
*>*  incomplete final line found by readTableHeader on 'test.csv*

*I tried Uninstall R and Excel, and install again but the problem doesnt fix.*

*Regard*

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Oct  6 23:39:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 6 Oct 2015 14:39:18 -0700
Subject: [R] apply regression to an array
In-Reply-To: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
References: <CAOV3wDDY3vxmH1xzqD5yQ+9NOQK7-PF2d+nv+YagvUXE9dExuw@mail.gmail.com>
Message-ID: <D13ED158-0352-46C0-AEFF-C20F0A2745FF@comcast.net>


On Oct 6, 2015, at 10:42 AM, Adrienne Wootten wrote:

> R-Helpers,
> 
> I've seen some similar threads about this question online, but not quite
> what I'm looking for.  I apologize in advance if someone's already answered
> this and I just can't find it online.
> 
> Say that I have an array like test3 in the little example code I have below:
> 
> test1 = array(rep(1:10,each = 25),dim=c(5,5,10))
> test2 = array(rnorm(250,0,0.35),dim=c(5,5,10))
> test3 = test1+test2 # array with 5 rows, 5 columns, 10 slices
> 
> time=1:10
> 
> Where the dimensions are x, y, and time.  What I'd like to do is run a
> regression (for the sake of this example, say lm) on each x,y in time.  So
> for a single cell the formula might be test3[1,1,]~time, but I'd like to
> that for all cells.  The only way I can immediately think of is to use a
> loop, but I'm wondering if there's a way to do this without a loop.
> Perhaps with tapply?

 Would not be expecting a 5x5x10 results since you are using the last dimension to calculate a two parameters for each row and col. Why not use a loop? Doing it with an index is just a a disguised loop:

apply( test3, 1:2, function(x) coef(lm(x~time) ) ) # iterates over rows and cols.
# results is 5 x 5 x2

> 
> I'm actually doing a fourth order regression with a much larger array, but
> this simple example illustrates the question I have.
> 
> Many thanks for the help! Sorry if someone's already answered this and I
> can't find it.
> 
> Adrienne
> 
> -- 
> Adrienne Wootten
> Graduate Research Assistant
> State Climate Office of North Carolina
> Department of Marine, Earth and Atmospheric Sciences
> North Carolina State University
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jvadams at usgs.gov  Wed Oct  7 00:16:13 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 6 Oct 2015 17:16:13 -0500
Subject: [R] vector graphics
In-Reply-To: <5613DDC9.5030400@univ-reims.fr>
References: <5613DDC9.5030400@univ-reims.fr>
Message-ID: <CAN5YmCGcos5h0LCnksi3GZg5nT+Hmo28vt=EjizQcT=puy4sfA@mail.gmail.com>

Perhaps the discussion at this link will be helpful ...
http://stackoverflow.com/questions/9555889/producing-a-vector-graphics-image-i-e-metafile-in-r-suitable-for-printing-in

Jean

On Tue, Oct 6, 2015 at 9:42 AM, Ivan Calandra <ivan.calandra at univ-reims.fr>
wrote:

> Dear useRs,
>
> A colleague of mine is having a problem with graphic devices. The goal is
> to save into a vector graphic format that can be edited with Illustrator
> CS4.
>
> On my Mac (Snow Leopard), I use RSvgDevice::devSVG() and it works fine.
> But on her Windows Vista computer, I cannot find an alternative.>
> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows Vista (build 6002) Service Pack 2
>
> I have tried:
> - pdf(): I cannot dissociate the graphical elements (no problem with text)
> - cairo_pdf(): the text is replaced by symbols
> - cairo_ps(): fine except that the text is not text but object (it is then
> a bit troublesome, as any text modification requires the text to be
> completely rewritten)
> - svg(): the graphic is completely screwed up (it seems to be a scaling
> problem, with symbols and letters all very large and superposed)
> - RSvgDevice cannot be installed on the Windows machine, neither as binary
> nor from source.
>
> Is there any other device that could work? If not, is it a matter of
> settings? So, basically, what can I do?
>
> Thank you in advance,
> Ivan
>
> --
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> https://www.researchgate.net/profile/Ivan_Calandra
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ckmsasi at gmail.com  Wed Oct  7 00:59:15 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Tue, 6 Oct 2015 15:59:15 -0700
Subject: [R] Installing pre-compiled R in Linux
Message-ID: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>

Hi,

I have downloaded the pre-compiled version of R package:
r-base-core(3.2.2-1) for i386 platform. Unzipped the package under my tmp
directory (/tmp). The directories "et"c and "usr" got created with binaries
R and Rscript under /tmp/usr/bin/.

Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt) reports
the below error,

./usr/bin/R
                                             ./usr/bin/R: line 238:
/usr/lib/R/etc/ldpaths: No such file or directory
ERROR: R_HOME ('/usr/lib/R') not found

How to reconfigure the R environment variables? Because, i tried setting
the R_HOME directory to "/tmp/usr/lib/R" but still not working.

The Linux version i am using is  2.6.32. Please help me with the steps to
install the R correctly. Thanks.

Regards
Sasi

	[[alternative HTML version deleted]]


From hnorpois at gmail.com  Tue Oct  6 22:59:12 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 6 Oct 2015 22:59:12 +0200
Subject: [R] Measure the frequencies of pairs in a matrix
Message-ID: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>

Hello,

I have a matrix mat (see dput(mat))

> mat
      [,1] [,2]
 [1,]    5    6
 [2,]    6    5
 [3,]    5    4
 [4,]    5    5
 ....

 I want the frequencies of the pairs in a new matrix, whereas the
combination 5 and 6 is the same as 6 and 5 (see the first two rows of mat).
In other words: What is the probability of each combination (each row)
ignoring the order in the combination. As a result I would like to have a
matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not appear
in my matrix.

 dput (mat)
structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))

Thanks
Hermann

	[[alternative HTML version deleted]]


From hnorpois at gmail.com  Tue Oct  6 23:07:28 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 6 Oct 2015 23:07:28 +0200
Subject: [R] cut - strange NA as output
In-Reply-To: <AB37EDC3-9ADB-4237-A1F9-444A9745C99B@me.com>
References: <CAKyZeBs7m07u6Qpn_MFKNQ=S14qWvC86cMtW4XxV5YEUTtt_ag@mail.gmail.com>
	<AB37EDC3-9ADB-4237-A1F9-444A9745C99B@me.com>
Message-ID: <CAKyZeBtO-40cTmiQG=Qo85vDWynOd4QSM+XBZ18xEe1JCARasQ@mail.gmail.com>

Thanks this was very helpful.

@Olivier Crouzet: Yes, round (x) would do the job but it was a principal
confusion ...

2015-10-06 21:57 GMT+02:00 Marc Schwartz <marc_schwartz at me.com>:

>
> > On Oct 6, 2015, at 2:20 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> >
> > Hello,
> >
> > why do I get NA for the following:
> >
> > cut (x, seq (0, max(x), by=1), label=FALSE)
> > [1] 1322 1175 1155 1149 1295 1173 1289 1197   NA 1129
> >
> > dput (x)
> > c(1321.55376901374, 1174.35657200935, 1154.02042504008, 1148.60981925942,
> > 1294.6166388941, 1172.45806806869, 1288.31933914639, 1196.26080041462,
> > 1355.88836502166, 1128.09901883228)
> >
> > Thanks
> > Hermann
>
>
> > max(x)
> [1] 1355.888
>
> > range(seq(0, max(x), by = 1))
> [1]    0 1355
>
>
> max(x) is outside (above) the range of the integer sequence of break
> points for cut() that you specified above. Thus, when cut() gets to the 9th
> element in x, the value is undefined.
>
> > cut (x, seq(0, max(x) + 1, by = 1), label=FALSE)
>  [1] 1322 1175 1155 1149 1295 1173 1289 1197 1356 1129
>
> or
>
> > cut (x, seq(0, ceiling(max(x)), by = 1), label=FALSE)
>  [1] 1322 1175 1155 1149 1295 1173 1289 1197 1356 1129
>
>
> Both of the above approaches will increment the sequence 0:max(x) to 1356:
>
> > range(seq(0, max(x) + 1, by = 1))
> [1]    0 1356
>
> > range(seq(0, ceiling(max(x)), by = 1))
> [1]    0 1356
>
>
> Regards,
>
> Marc Schwartz
>
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Tue Oct  6 22:58:53 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 6 Oct 2015 20:58:53 +0000
Subject: [R] Bug in auglag?
In-Reply-To: <m2io6kb0b9.fsf_-_@krugs.de>
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	<m2pp0z11lk.fsf@krugs.de>
	<3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>,
	<m2io6kb0b9.fsf_-_@krugs.de>
Message-ID: <1444165119904.26937@jhu.edu>

Dear Rainer,
This is NOT a bug in auglag.  I already mentioned that auglag() can work with infeasible starting values, which also implies that the function must be evaluable at infeasible values.  A simple solution to your problem would be to fix up your objective function such that it evaluates to `Inf' or some large value, when the parameter values are not in the constrained domain.  constrOptim.nl() is a barrier method so it forces the initial value and the subsequent iterates to be feasible.
Best,
Ravi
________________________________________
From: Rainer M Krug <Rainer at krugs.de>
Sent: Tuesday, October 6, 2015 9:20 AM
To: Ravi Varadhan
Cc: 'r-help at r-project.org'
Subject: Bug in auglag?

Hi Ravi,

I would like come back to your offer. I have a problem which possibly is
caused by a bug or by something I don't understand:

My function to be minimised is executed even when an element in hin() is
negative.

My hin looks as follow:

--8<---------------cut here---------------start------------->8---
hinMahat <- function(x, hauteur, na, zjoint, y, LAI, ...) {
    if (x[1] < 0) {
        cat(names(list(...)), "\n")
        cat(..., "\n")
        cat(x, "|", hauteur, LAI, y, "\n")
    }

    h <- rep(NA, 8)
    if (!missing(na)) {
        x <- c(na, x )
    }
    if (!missing(y)) {
        x <- c(x, y)
    }
    if (!missing(zjoint)) {
        x <- c(x[1], zjoint, x[2])
    }

    ##
    dep <- hauteur * (0.05 + LAI^0.02 / 2) + (x[3] - 1)/20
    h[1] <- dep
    h[2] <- hauteur - dep
    ## if (h[2]==0) {
    ##     h[2] <- -1
    ## }
    ##
    z0 <- hauteur * (0.23 + LAI^0.25 / 10) + (x[3] - 1)/67
    h[3] <- z0
    ## if (h[3]==0) {
    ##     h[3] <- -1
    ## }
    h[4] <- hauteur - z0
    ##
    h[5] <- x[1]
    ##
    h[6] <- x[2]
    h[7] <- hauteur - x[2]
    ##
    h[8] <- hauteur - dep - z0
    if (any(h<=0)) {
        cat(h, "\n")
        cat("\n")
    }
    return(h)
}
--8<---------------cut here---------------end--------------->8---

the x contains up to three elements: c(na=, zjoint=, y=) and I fit these
three, unless one or two are specified explicitely.

The values going into hin are:

,----
| ... (z  u ua za z0sol )
| 3 11 17 23 29 37 0.315 0.422 0.458 0.556 1.567 1.747 1.747 37 0.001
|
| x(na, zjoint): -8.875735 24.51316
| hauteur: 28
| na:      8.1
| y:       3
|
| the resulting hin() is:
| 16.09815 11.90185 11.19352 16.80648 -8.875735 24.51316 3.486843 0.708335
`----


Which is negative in element 5 as x[2]=na is negative.

So I would expect that the function fn is not evaluated. But it is, and
raises an error:

,----
| Error in wpLELMahat(z = z, ua = ua, na = ifelse(missing(na), par[1], na),  :
|   na has to be larger or equal than zero!
`----

Is this a misunderstanding on my part, or is it an error in the function
auglag?


Below is the function which is doing the minimisation.

If I replace auglag() with constrOptim.nl(), the optimisation is working
as expected.

So I think this is a bug in auglag?

Let me know if you need further information.

Cheers,

Rainer

--8<---------------cut here---------------start------------->8---
fitAuglag.wpLEL.mahat.single <- function(
                                         z,
                                         u,
                                         LAI,
                                         initial = c(na=9, zjoint=0.2*2, y=3),
                                         na, zjoint, y,
                                         h      = 28,
                                         za     = 37,
                                         z0sol  = 0.001,
                                         hin,
                                         ...
                                         ) {
    if (missing(hin)) {
        hin <- hinMahat
    }

    wpLELMin <- function(par, na, zjoint, y, z, u, ua, hauteur, za, z0sol, LAI) {
        result <- NA
        try({
            p <- wpLELMahat(
                z      = z,
                ua     = ua,
                na     = ifelse(missing(na), par[1], na),
                zjoint = ifelse(missing(zjoint), par[2], zjoint),
                h      = hauteur,
                za     = za,
                z0sol  = z0sol,
                LAI    = LAI,
                y      = ifelse(missing(y), par[3], y)
            )
            result <- sum( ( (p$u - u)^2 ) / length(u) )
        },
        silent = FALSE
        )
        ## cat("From wpLELMin", par, "\n")
        return( result )
    }

    ua <- u[length(u)]
    result <- list()
    result$method <- "fitAuglag.wpLEL.mahat.single"
    result$initial <-  initial
    result$dot <- list(...)
    result$z <- z
    result$u <- u

    result$fit <- auglag(
        par = initial,
        fn    = wpLELMin,
        hin   = hin,
        na     = na,
        zjoint = zjoint,
        y      = y,
        ##
        z     = z,
        u     = u,
        ua    = ua,
        hauteur = h,
        za    = za,
        z0sol = z0sol,
        LAI   = LAI,
        ...
    )
    result$wp <- wpLELMahat(
        z      = z,
        ua     = ua,
        na     = ifelse ( missing(na), result$fit$par["na"], na),
        zjoint = ifelse ( missing(zjoint), result$fit$par["zjoint"], zjoint),
        h      = h,
        za     = za,
        z0sol  = z0sol,
        LAI    = LAI,
        y      = ifelse ( missing(y), result$fit$par["y"], y)
    )

    class(result) <- c(class(result), "wpLELFit")
    return(result)
}
#+end_src--8<---------------cut here---------------end--------------->8---



Ravi Varadhan <ravi.varadhan at jhu.edu> writes:

> I would recommend that you use auglag() rather than constrOptim.nl()
> in the package "alabama."  It is a better algorithm, and it does not
> require feasible starting values.
> Best,
> Ravi
>
> -----Original Message-----
> From: Rainer M Krug [mailto:Rainer at krugs.de]
> Sent: Thursday, October 01, 2015 3:37 AM
> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
> Cc: 'r-help at r-project.org' <r-help at r-project.org>
> Subject: Re: optimizing with non-linear constraints
>
> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
>
>> Hi Rainer,
>> It is very simple to specify the constraints (linear or nonlinear) in
>> "alabama" .  They are specified in a function called `hin', where the
>> constraints are written such that they are positive.
>
> OK - I somehow missed the part that, when the values x are valid,
>> i.e. in the range as defined by the conditions, the result of hin(x)
>> that they are all positive.
>
>> Your two nonlinear constraints would be written as follows:
>>
>> hin <- function(x, LAI) {
>> h <- rep(NA, 2)
>> h[1] <- LAI^x[2] / x[3] + x[1]
>> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
>> h
>> }
>
> Makes perfect sense.
>
>>
>> Please take a look at the help page.  If it is still not clear, you can contact me offline.
>
> Yup - I did. But I somehow missed the fact stated above.
>
> I am using constrOptim() and constrOptim.nl() for a paper and am
>> compiling a separate document which explains how to get the
>> constraints for the two functions step by step - I will make it
>> available as a blog post and a pdf.
>
> I might have further questions concerning the different fitting
>> functions and which ones are the most appropriate in my case.
>
> Thanks a lot,
>
> Rainer
>
>
>> Best,
>> Ravi
>>
>> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
>> Associate Professor,  Department of Oncology Division of Biostatistics
>> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns
>> Hopkins University
>> 550 N. Broadway, Suite 1111-E
>> Baltimore, MD 21205
>> 410-502-2619
>>
>>
>>      [[alternative HTML version deleted]]
>>
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>

--
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982


From sarah.hardy at maine.edu  Wed Oct  7 00:17:30 2015
From: sarah.hardy at maine.edu (Sarah Hardy)
Date: Tue, 6 Oct 2015 18:17:30 -0400
Subject: [R] help with problem
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CC4AC@mb02.ads.tamu.edu>
References: <CACrOZ1_PJ7_FpGoLp1c2BDE+=pe7PTRBXwKkojH89VuZDAw_Eg@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6CC4AC@mb02.ads.tamu.edu>
Message-ID: <CAFg2G_uiwsfA537mStfepQO+4dydzwxf0_T_2JhN2d8UUW_dBg@mail.gmail.com>

It's possible that you have some invisible characters in the last line(s)
of the csv file.
You can use a text editor as Davis suggested or in Excel delete a bunch of
the blank rows after the end of the data rows.
If that doesn't work cut-and paste the rows you do want into a fresh
spreadsheet.

Sarah


On Tue, Oct 6, 2015 at 4:59 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> You have a warning, not an error. The command ran but there was a problem
> with the .csv or .txt file.
>
> You should have a partial data set in R. Try using the str() function to
> see what variables and what rows were read. Adding the fill=TRUE argument
> to read.table() will pad incomplete rows with blanks, but you should check
> the data to make sure you have what you were expecting.
>
> Without the data it is impossible to be sure, but you may have an
> incomplete line at the end of your data file. Use a text editor to look at
> your data so see if the last line is incomplete.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marco
> Otoya Chavarria
> Sent: Tuesday, October 6, 2015 10:15 AM
> To: r-help at r-project.org
> Subject: [R] help with problem
>
> *When i tried to read a table i**n .csv or .txt format R i get the
> following message and give some problem in orden to run the data o
> make test, etc*
>
> *Warning message*
>
> *In read.table(file = file, header = header, sep =";")
> *>*  incomplete final line found by readTableHeader on 'test.csv*
>
> *I tried Uninstall R and Excel, and install again but the problem doesnt
> fix.*
>
> *Regard*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Sarah Hardy, PhD
Associate Professor of Mathematics
University of Maine Farmington
207-778-7124    Office: Brinkman 100

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Oct  7 02:40:34 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 6 Oct 2015 20:40:34 -0400
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
Message-ID: <C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>

Since order is not important to you, you can order your pairs (e.g. decreasing) before compiling the frequencies.
But I don't understand the second part about values "that do not appear in the matrix". Do you mean you want to assess all combinations? If that's the case I would think about a hash table or other indexed data structure, rather than iterating through a matrix.


B.



On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:

> Hello,
> 
> I have a matrix mat (see dput(mat))
> 
>> mat
>      [,1] [,2]
> [1,]    5    6
> [2,]    6    5
> [3,]    5    4
> [4,]    5    5
> ....
> 
> I want the frequencies of the pairs in a new matrix, whereas the
> combination 5 and 6 is the same as 6 and 5 (see the first two rows of mat).
> In other words: What is the probability of each combination (each row)
> ignoring the order in the combination. As a result I would like to have a
> matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not appear
> in my matrix.
> 
> dput (mat)
> structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> 
> Thanks
> Hermann
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Wed Oct  7 02:57:14 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Tue, 6 Oct 2015 17:57:14 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
Message-ID: <CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>

It's very likely that there is already an R package for your linux
system, and, if so, you'd probably be well-served to use that one.
You've given us the version of the kernel you're using (not a recent
one, BTW), but what linux distribution are you using?

-- Mike


On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
> Hi,
>
> I have downloaded the pre-compiled version of R package:
> r-base-core(3.2.2-1) for i386 platform. Unzipped the package under my tmp
> directory (/tmp). The directories "et"c and "usr" got created with binaries
> R and Rscript under /tmp/usr/bin/.
>
> Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt) reports
> the below error,
>
> ./usr/bin/R
>                                              ./usr/bin/R: line 238:
> /usr/lib/R/etc/ldpaths: No such file or directory
> ERROR: R_HOME ('/usr/lib/R') not found
>
> How to reconfigure the R environment variables? Because, i tried setting
> the R_HOME directory to "/tmp/usr/lib/R" but still not working.
>
> The Linux version i am using is  2.6.32. Please help me with the steps to
> install the R correctly. Thanks.
>
> Regards
> Sasi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Wed Oct  7 03:17:20 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 6 Oct 2015 20:17:20 -0500
Subject: [R] Result error using the function
In-Reply-To: <619937521.1165942.1444113222865.JavaMail.yahoo@mail.yahoo.com>
References: <1332761623.1148383.1444111836911.JavaMail.yahoo@mail.yahoo.com>
	<619937521.1165942.1444113222865.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCFke=G-Vc3UPfDNd668ieiiF9kaAv365KnXG+aNBxeHow@mail.gmail.com>

I have simplified your function.  And I have transposed your results such
that resulting metrics are in columns rather than rows.  So, it's not
exactly what you were after, but perhaps you will find it useful.

monthly_summary <- function(dt, r, tol=1E-6) {
  # number of days with above tol by year and month
  mt1 <- tapply(dt[, "Amount"] > tol, dt[, c("Month", "Year")], sum)
  # mean number of days with above tol by month
  mn <- apply(mt1, 1, mean)
  # proportion of days with above tol by year and month
  pd1 <- tapply(dt[, "Amount"] > tol, dt[, c("Month", "Year")], mean)
  # mean proportion of days with above tol by month
  mnp <- apply(mt1, 1, mean)
  # inverse of this proportion
  lambda <- 1/mnp
  cbind(mt1, mn, lambda)
}

m_sum <- monthly_summary(J1, 2)
m_sum

Jean


On Tue, Oct 6, 2015 at 1:33 AM, smart hendsome <putra_autumn86 at yahoo.com>
wrote:

> Hi R-users,
>
>
> I am new to R.  I try to code using the function in R as below:
>  monthly_summary <- function(dt,r)
> {  tol <- 1E-6
>    mn  <- vector(length=12, mode="numeric")
>    lambda  <- vector(length=12, mode="numeric")
>    ag  <- aggregate(dt[,4] > tol, list (dt[,2], dt[,1]), sum)
>    names(ag) <- c("Year", "Month","Amount")
>    mt1 <- matrix(ag[,3],nrow=r,ncol=12,byrow=T)
>    rownames(mt1) <- 1950:1951
>    colnames(mt1) <- c("Jan","Feb","Mar","Apr","May","June","July",
>                                  "Aug","Sept","Oct","Nov","Dec")
>
>   for (i in 1:ncol(mt1))
>   {
>       {  xi     <- mt1[,i]
>          mn[i]  <- mean(xi)                                ## calc mean
>       }
>
>       if  (mt1[,c(1,3,5,7,8,10,12)])
>           {
>            lambda[i]  <- (31/mn[i])                       ## calc lambda
> for month with 31 days
>           }
>           else if  (mt1[,2])
>                {
>                    lambda[i]  <- (28/mn[i])                ## calc lambda
> for month with 28 days
>                }
>                    else
>                        {
>                               lambda[i]  <- (30/mn[i])      ## calc lambda
> for month with 30 days
>                        }
>
>   ## result
>   mt1 <- round(mt1, 0)
>   mn <-   round(mn, 3)
>   lambda <- round(lambda, 3)
>
> }
>   comb <- rbind(mt1, mn = mn, lambda = lambda)
> }
>
> ## call function
> m_sum <- monthly_summary(J1,2); m_sum
>
> The problems are:
> 1)the value of count rain in decimals
> 2) the value lambda is wrong3)i dont know how to account the leap years in
> february
> Anyone can help me?
> I also provide my data using dput(). Thanks so much.
> structure(list(Year = c(1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L,
> 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1950L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L, 1951L,
> 1951L, 1951L, 1951L, 1951L), Month = c(1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
> 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
> 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
> 10L, 10L, 10L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
> 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
> 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L
> ), Day = c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L,
> 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L,
> 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,
> 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,
> 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L,
> 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L,
> 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
> 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 1L, 2L, 3L, 4L,
> 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L,
> 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L,
> 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
> 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L,
> 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L,
> 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
> 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L,
> 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L,
> 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L,
> 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L,
> 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L,
> 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
> 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L,
> 27L, 28L, 29L, 30L, 31L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L,
> 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L,
> 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L,
> 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,
> 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 1L,
> 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L,
> 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L,
> 29L, 30L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L,
> 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L,
> 26L, 27L, 28L, 29L, 30L, 31L), Amount = c(0, 35.5, 17.8, 24.5,
> 12.3, 11.5, 5.7, 13.2, 11.3, 14.7, 11.9, 17.5, 8.1, 0.4, 0, 19.5,
> 10.7, 0.5, 12.7, 6.3, 16.1, 11.4, 1.7, 0.8, 0.4, 0, 2.9, 5.3,
> 2.9, 0.5, 5.9, 2.9, 0, 16.2, 15.5, 21.8, 11.4, 1.2, 0, 0, 0,
> 0, 1.3, 9.5, 4.4, 4.2, 2.1, 0, 0, 0, 0, 0, 0, 0, 28.4, 14.2,
> 0, 0, 3.3, 1.7, 4.9, 3.6, 12, 16.7, 5.5, 1.1, 0.6, 2.7, 1.3,
> 0, 0, 34.2, 43.8, 27.2, 10.6, 3.8, 2.3, 34, 16.7, 0, 47.1, 23.5,
> 28.9, 18.1, 4.8, 5.5, 3.3, 3, 1.2, 3.3, 1.7, 1.8, 1.7, 0.7, 17,
> 8.4, 7.7, 3.9, 5.9, 2.9, 0, 1, 0.5, 0.8, 0.4, 4.2, 2.1, 0, 0,
> 0, 17.9, 9, 1.7, 1.6, 5.1, 2.8, 0.6, 0.2, 1.7, 0.8, 2.5, 1.3,
> 3.2, 1.9, 0.3, 3.4, 1.7, 4.5, 2.3, 0, 1.7, 0.8, 0, 0, 0, 0, 0,
> 16.9, 13.8, 11.1, 5.5, 2.3, 0.8, 0, 0, 28.7, 26.2, 9.6, 1.8,
> 0, 0, 0, 0, 0, 0, 0.3, 0.2, 0, 0, 53.1, 26.6, 41.1, 20.6, 18.1,
> 9, 0, 0, 0, 0, 6.9, 3.5, 0, 13.5, 6.8, 0, 0, 17.7, 8.9, 0, 0.1,
> 0.1, 0, 11, 5.5, 1, 1.3, 6.5, 3.5, 0.2, 1.1, 0.6, 18.6, 28.8,
> 9.7, 4.4, 8.4, 3.1, 0, 0.5, 0.2, 15.7, 8.2, 0.2, 0, 0, 0, 0,
> 0, 0.8, 0.4, 5.1, 2.5, 0, 0, 3.3, 1.7, 3, 1.5, 0, 0, 0, 0, 0,
> 0, 9.8, 38.7, 17.6, 17.2, 39.2, 16.4, 0.5, 0, 0, 0, 0, 16.4,
> 11.4, 1.9, 18.8, 48.6, 19.6, 24.3, 19.4, 4.4, 20.5, 14.1, 2,
> 0, 0, 0, 0, 0, 0.1, 0.1, 22.5, 11.2, 0.8, 0.4, 0, 5.5, 2.8, 2.9,
> 1.4, 22.7, 16.1, 32.2, 25.2, 5.5, 0.2, 0, 0, 0, 35.7, 17.8, 1.5,
> 1.1, 0.2, 0, 3.3, 1.8, 6.5, 14.2, 10.2, 11.6, 4.6, 20.8, 10.7,
> 1.8, 2.5, 12, 32.6, 13.5, 1, 0.5, 12.7, 6.3, 0.3, 0.2, 5.7, 2.9,
> 0, 0, 29.6, 14.9, 7.7, 3.8, 11, 11.2, 2.9, 2.5, 1.3, 0.8, 25.7,
> 21.9, 13, 15.5, 5.7, 22, 11, 16.4, 32.7, 12.3, 0, 0, 6.9, 8.5,
> 3.3, 9.9, 5.9, 7.8, 14.3, 12.6, 3.6, 0.8, 0.7, 0.2, 0.3, 5.2,
> 2.5, 0, 0.8, 1.4, 0.5, 0, 2.7, 5.5, 15.1, 6.8, 0.5, 0.2, 6.4,
> 9.1, 6.5, 9.4, 3.8, 0, 0, 2.7, 1.3, 0, 7.6, 10.5, 3.4, 0, 6.2,
> 36.9, 16.9, 4.5, 20.2, 9.3, 0.2, 14, 46.1, 38.1, 9.3, 0.8, 51.1,
> 113, 52.2, 18.5, 29.2, 48.9, 41.7, 18.1, 10.4, 3.5, 7.6, 3.8,
> 0, 1.3, 31.1, 18.2, 1.5, 0, 0, 0, 0, 10.1, 5.1, 0, 0, 0, 0, 6.7,
> 3.4, 26.2, 13.8, 8.1, 3.9, 74.8, 48.7, 23.7, 15.4, 4.3, 8.3,
> 3.9, 19.1, 13.2, 2.8, 2.3, 6.1, 14.1, 5.7, 0, 0, 0, 0, 7.6, 39.7,
> 17.9, 0, 5.1, 4.5, 1.3, 0.2, 0, 0, 0, 0, 0, 0, 0, 32.5, 16.2,
> 0, 0.5, 0.2, 0, 2.3, 2.2, 0.5, 0, 9.3, 11.9, 4.8, 0.6, 0, 32.5,
> 18.8, 11.4, 5.1, 0, 17.1, 8.5, 1.1, 0.6, 4.7, 2.4, 36.4, 21.1,
> 1.4, 0, 0, 0, 0, 0, 0, 1.1, 0.6, 0, 3.2, 2.6, 3.2, 9.1, 19.9,
> 8, 0, 0, 7.1, 3.5, 6.2, 3.1, 0, 1.7, 13.5, 21.5, 7.6, 0, 0, 0,
> 0, 15.2, 7.6, 0, 0, 0, 5.4, 17.9, 7.6, 11.1, 6, 1.9, 6.7, 2.9,
> 29.1, 14.5, 14.3, 16.4, 4.6, 0, 0, 0, 0, 31.3, 15.6, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14.3, 7.2, 0.8, 1.2, 30, 14.8,
> 0, 0, 0, 0, 0, 0, 0, 4.2, 2.1, 4.2, 3.8, 5, 44.4, 25.3, 2.9,
> 0.4, 0, 8.4, 4.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 31.1,
> 15.6, 0, 13.5, 6.8, 0, 0, 0.8, 0.4, 24.5, 12.6, 29.6, 14.7, 39.3,
> 19.6, 0, 0, 0, 0, 0, 0, 0, 5.7, 27.1, 12.1, 25.7, 18.9, 15.4,
> 6.2, 0, 3.2, 1.6, 0, 0, 0, 0, 0, 2.3, 1.2, 15.2, 13.3, 31.8,
> 17.5, 1.5, 1.3, 3.2, 1.3, 0, 0, 0, 0, 18.6, 9.3, 0, 0, 0, 3.3,
> 11.1, 36.9, 48.9, 24, 3.8, 0.8, 0.4, 0, 0, 0, 0, 0, 0, 0, 0,
> 4.2, 2.1, 0, 1.1, 0.6, 0.8, 0.4, 36.4, 18.2, 8.4, 22.3, 9, 0,
> 33.8, 17.7, 13.3, 6.4, 0.7, 0.3, 0, 0, 0, 10.3, 15.3, 12.3, 7.8,
> 2.1, 0, 0, 31.3, 15.6, 6.7, 19.4, 9.4, 0.7, 10.1, 5.9, 0.4, 0.8,
> 7.1, 3.4, 9.9, 5, 0, 6.6, 9.2, 2.9, 0.3, 0.2, 0.3, 17, 8.4, 7.1,
> 3.5, 15.2, 55.3, 75.1, 59.6, 17, 0, 0.5, 0.2, 2.9, 2.9, 3.7,
> 1.5, 0, 0, 0, 0, 2.5, 1.7, 0.2, 39.7, 19.9, 33, 16.5, 1.5, 0.7,
> 1.5, 0.9, 19.3)), .Names = c("Year", "Month", "Day", "Amount"
> ), class = "data.frame", row.names = c(NA, -730L))
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From luca.cerone at gmail.com  Wed Oct  7 08:14:23 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Wed, 7 Oct 2015 08:14:23 +0200
Subject: [R] Installing different R versions
Message-ID: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>

Dear all,
on one shared machine we have an older R version installed. Some packages
have known issues with that version that are fixed in newer R versions.

Since that is a production machine with many jobs running we would like to
keep things as they are. However I would also like to keep advantage of the
newest version and the bug fixes introduced.

What would be the best way to install a newer version along the one that
already exists? Is it possible to install it for a specific user only?

Cheers,
Luca

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Oct  7 08:32:10 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 7 Oct 2015 06:32:10 +0000
Subject: [R] extract all dataframes from list
In-Reply-To: <000001d10024$b6704a10$2350de30$@infomed.sld.cu>
References: <000001d10024$b6704a10$2350de30$@infomed.sld.cu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43B95@SRVEXCHMBX.precheza.cz>

Hi

Or basically you can use for cycle. This can be as effective as lapply and if you plan to do some operations on your data frames maybe more manageable.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of maicel
> Sent: Tuesday, October 06, 2015 12:50 PM
> To: r-help at r-project.org
> Subject: [R] extract all dataframes from list
>
> Hello List, I have list of named dataframe. How can I extract all
> dataframes from this list? The dataframe names should be the same of
> the original list.
> May I use the lapply function?
>
> Thanks for your help. Best regards,
> Maicel Monzon, MD
> National Center of Clinical Trials
> Havana, Cuba
>
>
>
>
> --
> Este mensaje le ha llegado mediante el servicio de correo electronico
> que ofrece Infomed para respaldar el cumplimiento de las misiones del
> Sistema Nacional de Salud. La persona que envia este correo asume el
> compromiso de usar el servicio a tales fines y cumplir con las
> regulaciones establecidas
>
> Infomed: http://www.sld.cu/
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Gerrit.Eichner at math.uni-giessen.de  Wed Oct  7 08:43:57 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Wed, 7 Oct 2015 08:43:57 +0200 (MEST)
Subject: [R] extract all dataframes from list
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43B95@SRVEXCHMBX.precheza.cz>
References: <000001d10024$b6704a10$2350de30$@infomed.sld.cu>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802C43B95@SRVEXCHMBX.precheza.cz>
Message-ID: <Pine.SOC.4.64.1510070839120.24410@solcom.hrz.uni-giessen.de>

Hello, Maicel,

if you only want to extract info from those data frames, maybe it is 
enough to attach the list to the search path using attach (and afterwards 
detach()); see ?attach. Otherwise the online help page of assign() might 
be a starting point for you.

  Hth  --  Gerrit

> Hi
>
> Or basically you can use for cycle. This can be as effective as lapply 
> and if you plan to do some operations on your data frames maybe more 
> manageable.
>
> Cheers
> Petr
>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of maicel
>> Sent: Tuesday, October 06, 2015 12:50 PM
>> To: r-help at r-project.org
>> Subject: [R] extract all dataframes from list
>>
>> Hello List, I have list of named dataframe. How can I extract all
>> dataframes from this list? The dataframe names should be the same of
>> the original list.
>> May I use the lapply function?
>>
>> Thanks for your help. Best regards,
>> Maicel Monzon, MD
>> National Center of Clinical Trials
>> Havana, Cuba
>>
> ....
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From loris.bennett at fu-berlin.de  Wed Oct  7 09:04:47 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Wed, 7 Oct 2015 09:04:47 +0200
Subject: [R] Installing different R versions
References: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>
Message-ID: <87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>

Dear Luca,

Luca Cerone <luca.cerone at gmail.com> writes:

> Dear all,
> on one shared machine we have an older R version installed. Some packages
> have known issues with that version that are fixed in newer R versions.
>
> Since that is a production machine with many jobs running we would like to
> keep things as they are. However I would also like to keep advantage of the
> newest version and the bug fixes introduced.
>
> What would be the best way to install a newer version along the one that
> already exists? Is it possible to install it for a specific user only?
>
> Cheers,
> Luca

If you are on a Unix-like platform, a standard way of dealing with
multiple versions of a piece of software installed in parallel is
"Environment Modules":

http://modules.sourceforge.net/

Packages for various Linux distributions are available.

You could make a version available for a specific user by setting
appropriate file permissions of the module file which is used to set up
the environment.  However, I would consider this a somewhat unusual
configuration.  If you are worried about people using the wrong version
by mistake, you can either have the standard version available without
using modules, or you can define a default version within the modules
setup.

HTH

Loris

-- 
This signature is currently under construction.


From ivan.calandra at univ-reims.fr  Wed Oct  7 10:05:31 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 7 Oct 2015 10:05:31 +0200
Subject: [R] vector graphics
In-Reply-To: <CAN5YmCGcos5h0LCnksi3GZg5nT+Hmo28vt=EjizQcT=puy4sfA@mail.gmail.com>
References: <5613DDC9.5030400@univ-reims.fr>
	<CAN5YmCGcos5h0LCnksi3GZg5nT+Hmo28vt=EjizQcT=puy4sfA@mail.gmail.com>
Message-ID: <5614D24B.3080809@univ-reims.fr>

Thanks Jean for the tip.
I'll try postscript() and devEMF::emf() and see if it works.
Still, it's very complicated to export vector graphics in R...

Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 07/10/15 00:16, Adams, Jean a ?crit :
> Perhaps the discussion at this link will be helpful ... 
> http://stackoverflow.com/questions/9555889/producing-a-vector-graphics-image-i-e-metafile-in-r-suitable-for-printing-in
>
> Jean
>
> On Tue, Oct 6, 2015 at 9:42 AM, Ivan Calandra 
> <ivan.calandra at univ-reims.fr <mailto:ivan.calandra at univ-reims.fr>> wrote:
>
>     Dear useRs,
>
>     A colleague of mine is having a problem with graphic devices. The
>     goal is to save into a vector graphic format that can be edited
>     with Illustrator CS4.
>
>     On my Mac (Snow Leopard), I use RSvgDevice::devSVG() and it works
>     fine.
>     But on her Windows Vista computer, I cannot find an alternative.>
>     sessionInfo()
>     R version 3.2.2 (2015-08-14)
>     Platform: i386-w64-mingw32/i386 (32-bit)
>     Running under: Windows Vista (build 6002) Service Pack 2
>
>     I have tried:
>     - pdf(): I cannot dissociate the graphical elements (no problem
>     with text)
>     - cairo_pdf(): the text is replaced by symbols
>     - cairo_ps(): fine except that the text is not text but object (it
>     is then a bit troublesome, as any text modification requires the
>     text to be completely rewritten)
>     - svg(): the graphic is completely screwed up (it seems to be a
>     scaling problem, with symbols and letters all very large and
>     superposed)
>     - RSvgDevice cannot be installed on the Windows machine, neither
>     as binary nor from source.
>
>     Is there any other device that could work? If not, is it a matter
>     of settings? So, basically, what can I do?
>
>     Thank you in advance,
>     Ivan
>
>     -- 
>     Ivan Calandra, PhD
>     University of Reims Champagne-Ardenne
>     GEGENAA - EA 3795
>     CREA - 2 esplanade Roland Garros
>     51100 Reims, France
>     +33(0)3 26 77 36 89
>     ivan.calandra at univ-reims.fr <mailto:ivan.calandra at univ-reims.fr>
>     https://www.researchgate.net/profile/Ivan_Calandra
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From drjimlemon at gmail.com  Wed Oct  7 10:06:52 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 7 Oct 2015 19:06:52 +1100
Subject: [R] Polygon shade
In-Reply-To: <CAN25tHT=mCO_qs6uXK4PNaHJZJUjRhvbZ8RFXWds4WdC+0xSwQ@mail.gmail.com>
References: <CAN25tHT=mCO_qs6uXK4PNaHJZJUjRhvbZ8RFXWds4WdC+0xSwQ@mail.gmail.com>
Message-ID: <CA+8X3fWC6dKntdK61XvCudqTTdHnyOETwbO7ZTbNOgQzi2WYOQ@mail.gmail.com>

Hi bgnum,
You can try something like this:

testdates<-as.Date(paste(1:30,"Sep",2015),"%d %b %Y")
nemails<-sample(10:30,30,TRUE)
library(plotrix)
stackpoly(testdates,nemails,col="blue")

Jim


On Wed, Oct 7, 2015 at 12:20 AM, bgnumis bgnum <bgnumis at gmail.com> wrote:

> Hi All,
>
> I want to shade the area below "f" variable and it doesn?t draw:
>
> plot(z$Dateh[nn:length(z$Dateh)],f,type="l",col="black", xlab="Time",
> ylab="Line")
> grid()
> polygon(c(1, 1:st, st),c(0, f, 0), col = "blue")
>
> st is the length of f.
>
> But if I plot
>
> plot(f,type="l",col="black", xlab="Time", ylab="Correlation")
> grid()
> polygon(c(1, 1:st, st),c(0, f, 0), col = "blue")
>
> But the axis doesn?t refect the date labels.
>
> ?What should I do in the first code to achive it draws the blue?
>
> ?If not? How can I ommit the axis in the scond code and to add the
> z$Dateh[nn:length(z$Dateh)?
>
> Hope someone can help me.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Wed Oct  7 10:19:59 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Wed, 07 Oct 2015 10:19:59 +0200
Subject: [R] Bug in auglag?
In-Reply-To: <1444165119904.26937@jhu.edu> (Ravi Varadhan's message of "Tue, 6
	Oct 2015 20:58:53 +0000")
References: <da9cabb003544e4cb1f59c02aabee698@DOM-EB1-2013.win.ad.jhu.edu>
	<m2pp0z11lk.fsf@krugs.de>
	<3afec3be35a74257a9087d616e9ae509@DOM-EB1-2013.win.ad.jhu.edu>
	<m2io6kb0b9.fsf_-_@krugs.de> <1444165119904.26937@jhu.edu>
Message-ID: <m2y4ff9jkg.fsf@krugs.de>

Thanks a lot Ravi for the clarification and it makes sense - bug in my
understanding  acknowledged.

I'll change the objective function as suggested.

Thanks,

Rainer

Ravi Varadhan <ravi.varadhan at jhu.edu> writes:

> Dear Rainer,
> This is NOT a bug in auglag.  I already mentioned that auglag() can
> work with infeasible starting values, which also implies that the
> function must be evaluable at infeasible values.  A simple solution to
> your problem would be to fix up your objective function such that it
> evaluates to `Inf' or some large value, when the parameter values are
> not in the constrained domain.  constrOptim.nl() is a barrier method
> so it forces the initial value and the subsequent iterates to be
> feasible.
> Best,
> Ravi
> ________________________________________
> From: Rainer M Krug <Rainer at krugs.de>
> Sent: Tuesday, October 6, 2015 9:20 AM
> To: Ravi Varadhan
> Cc: 'r-help at r-project.org'
> Subject: Bug in auglag?
>
> Hi Ravi,
>
> I would like come back to your offer. I have a problem which possibly is
> caused by a bug or by something I don't understand:
>
> My function to be minimised is executed even when an element in hin() is
> negative.
>
> My hin looks as follow:
>
> hinMahat <- function(x, hauteur, na, zjoint, y, LAI, ...) {
>     if (x[1] < 0) {
>         cat(names(list(...)), "\n")
>         cat(..., "\n")
>         cat(x, "|", hauteur, LAI, y, "\n")
>     }
>
>     h <- rep(NA, 8)
>     if (!missing(na)) {
>         x <- c(na, x )
>     }
>     if (!missing(y)) {
>         x <- c(x, y)
>     }
>     if (!missing(zjoint)) {
>         x <- c(x[1], zjoint, x[2])
>     }
>
>     ##
>     dep <- hauteur * (0.05 + LAI^0.02 / 2) + (x[3] - 1)/20
>     h[1] <- dep
>     h[2] <- hauteur - dep
>     ## if (h[2]==0) {
>     ##     h[2] <- -1
>     ## }
>     ##
>     z0 <- hauteur * (0.23 + LAI^0.25 / 10) + (x[3] - 1)/67
>     h[3] <- z0
>     ## if (h[3]==0) {
>     ##     h[3] <- -1
>     ## }
>     h[4] <- hauteur - z0
>     ##
>     h[5] <- x[1]
>     ##
>     h[6] <- x[2]
>     h[7] <- hauteur - x[2]
>     ##
>     h[8] <- hauteur - dep - z0
>     if (any(h<=0)) {
>         cat(h, "\n")
>         cat("\n")
>     }
>     return(h)
> }
>
> the x contains up to three elements: c(na=, zjoint=, y=) and I fit these
> three, unless one or two are specified explicitely.
>
> The values going into hin are:
>
> ,----
> | ... (z  u ua za z0sol )
> | 3 11 17 23 29 37 0.315 0.422 0.458 0.556 1.567 1.747 1.747 37 0.001
> |
> | x(na, zjoint): -8.875735 24.51316
> | hauteur: 28
> | na:      8.1
> | y:       3
> |
> | the resulting hin() is:
> | 16.09815 11.90185 11.19352 16.80648 -8.875735 24.51316 3.486843 0.708335
> `----
>
>
> Which is negative in element 5 as x[2]=na is negative.
>
> So I would expect that the function fn is not evaluated. But it is, and
> raises an error:
>
> ,----
> | Error in wpLELMahat(z = z, ua = ua, na = ifelse(missing(na), par[1], na),  :
> |   na has to be larger or equal than zero!
> `----
>
> Is this a misunderstanding on my part, or is it an error in the function
> auglag?
>
>
> Below is the function which is doing the minimisation.
>
> If I replace auglag() with constrOptim.nl(), the optimisation is working
> as expected.
>
> So I think this is a bug in auglag?
>
> Let me know if you need further information.
>
> Cheers,
>
> Rainer
>
> --8<---------------cut here---------------start------------->8---
> fitAuglag.wpLEL.mahat.single <- function(
>                                          z,
>                                          u,
>                                          LAI,
>                                          initial = c(na=9, zjoint=0.2*2, y=3),
>                                          na, zjoint, y,
>                                          h      = 28,
>                                          za     = 37,
>                                          z0sol  = 0.001,
>                                          hin,
>                                          ...
>                                          ) {
>     if (missing(hin)) {
>         hin <- hinMahat
>     }
>
>     wpLELMin <- function(par, na, zjoint, y, z, u, ua, hauteur, za, z0sol, LAI) {
>         result <- NA
>         try({
>             p <- wpLELMahat(
>                 z      = z,
>                 ua     = ua,
>                 na     = ifelse(missing(na), par[1], na),
>                 zjoint = ifelse(missing(zjoint), par[2], zjoint),
>                 h      = hauteur,
>                 za     = za,
>                 z0sol  = z0sol,
>                 LAI    = LAI,
>                 y      = ifelse(missing(y), par[3], y)
>             )
>             result <- sum( ( (p$u - u)^2 ) / length(u) )
>         },
>         silent = FALSE
>         )
>         ## cat("From wpLELMin", par, "\n")
>         return( result )
>     }
>
>     ua <- u[length(u)]
>     result <- list()
>     result$method <- "fitAuglag.wpLEL.mahat.single"
>     result$initial <-  initial
>     result$dot <- list(...)
>     result$z <- z
>     result$u <- u
>
>     result$fit <- auglag(
>         par = initial,
>         fn    = wpLELMin,
>         hin   = hin,
>         na     = na,
>         zjoint = zjoint,
>         y      = y,
>         ##
>         z     = z,
>         u     = u,
>         ua    = ua,
>         hauteur = h,
>         za    = za,
>         z0sol = z0sol,
>         LAI   = LAI,
>         ...
>     )
>     result$wp <- wpLELMahat(
>         z      = z,
>         ua     = ua,
>         na     = ifelse ( missing(na), result$fit$par["na"], na),
>         zjoint = ifelse ( missing(zjoint), result$fit$par["zjoint"], zjoint),
>         h      = h,
>         za     = za,
>         z0sol  = z0sol,
>         LAI    = LAI,
>         y      = ifelse ( missing(y), result$fit$par["y"], y)
>     )
>
>     class(result) <- c(class(result), "wpLELFit")
>     return(result)
> }
> #+end_src--8<---------------cut here---------------end--------------->8---
>
>
>
> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
>
>> I would recommend that you use auglag() rather than constrOptim.nl()
>> in the package "alabama."  It is a better algorithm, and it does not
>> require feasible starting values.
>> Best,
>> Ravi
>>
>> -----Original Message-----
>> From: Rainer M Krug [mailto:Rainer at krugs.de]
>> Sent: Thursday, October 01, 2015 3:37 AM
>> To: Ravi Varadhan <ravi.varadhan at jhu.edu>
>> Cc: 'r-help at r-project.org' <r-help at r-project.org>
>> Subject: Re: optimizing with non-linear constraints
>>
>> Ravi Varadhan <ravi.varadhan at jhu.edu> writes:
>>
>>> Hi Rainer,
>>> It is very simple to specify the constraints (linear or nonlinear) in
>>> "alabama" .  They are specified in a function called `hin', where the
>>> constraints are written such that they are positive.
>>
>> OK - I somehow missed the part that, when the values x are valid,
>>> i.e. in the range as defined by the conditions, the result of hin(x)
>>> that they are all positive.
>>
>>> Your two nonlinear constraints would be written as follows:
>>>
>>> hin <- function(x, LAI) {
>>> h <- rep(NA, 2)
>>> h[1] <- LAI^x[2] / x[3] + x[1]
>>> h[2] <- 1 - x[1] - LAI^x[2] / x[3]
>>> h
>>> }
>>
>> Makes perfect sense.
>>
>>>
>>> Please take a look at the help page.  If it is still not clear, you can contact me offline.
>>
>> Yup - I did. But I somehow missed the fact stated above.
>>
>> I am using constrOptim() and constrOptim.nl() for a paper and am
>>> compiling a separate document which explains how to get the
>>> constraints for the two functions step by step - I will make it
>>> available as a blog post and a pdf.
>>
>> I might have further questions concerning the different fitting
>>> functions and which ones are the most appropriate in my case.
>>
>> Thanks a lot,
>>
>> Rainer
>>
>>
>>> Best,
>>> Ravi
>>>
>>> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
>>> Associate Professor,  Department of Oncology Division of Biostatistics
>>> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns
>>> Hopkins University
>>> 550 N. Broadway, Suite 1111-E
>>> Baltimore, MD 21205
>>> 410-502-2619
>>>
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>
>> --
>> Rainer M. Krug
>> email: Rainer<at>krugs<dot>de
>> PGP: 0x0F52F982
>>
>
> --
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
>
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
>
> Fax (D):    +49 - (0)3 21 21 25 22 44
>
> email:      Rainer at krugs.de
>
> Skype:      RMkrug
>
> PGP: 0x0F52F982
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151007/8fd1540b/attachment.bin>

From jmhannon.ucdavis at gmail.com  Wed Oct  7 10:46:02 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 7 Oct 2015 01:46:02 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
Message-ID: <CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>

I don't think kernel compatibility is a significant issue for most
applications.  I can say for certain that I update the kernels on my
linux boxes without having to reinstall R.

There *are* R packages for RHEL and friends.  Have a look at:

https://cran.r-project.org/bin/linux/redhat/README

Note that there's a bit of fiddling required, but I don't think it's
particularly complicated.

It's usually not particularly difficult to install R from source.  If
you prefer to do that, have a look at:

https://cran.r-project.org/doc/manuals/r-release/R-admin.html

Also, you don't specify your requirements, but don't overlook the
possibility of installing a virtual machine on your RHEL server.
(It's somewhat easier to get an R package for Fedora or Ubuntu than
for RHEL, for instance.)

I don't know the answer to your question about embedded systems.  I
would think R would not be a great choice for an embedded system, but
I don't know what your requirements are.

-- Mike


On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
> Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
> Linux Server release 6.2".
>
> Also, couple of clarifications,
>
> 1. Do we have a R package compatibility matrix against the Linux kernel
> version? Or for the Red Hat Linux with kernel version 2.6.32-279, do you
> have any suggestion/recommendation on R package to be used?
>
> 2. If we need to use Rscripts in embedded systems such as routers and
> switches, do we need to install the complete R package in the  system also?
> Or just libR.so and Rscript should be ok?
>
> Thanks again Mike.
>
> Regards
> Sasi
>
> On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon <jmhannon.ucdavis at gmail.com>
> wrote:
>>
>> It's very likely that there is already an R package for your linux
>> system, and, if so, you'd probably be well-served to use that one.
>> You've given us the version of the kernel you're using (not a recent
>> one, BTW), but what linux distribution are you using?
>>
>> -- Mike
>>
>>
>> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com>
>> wrote:
>> > Hi,
>> >
>> > I have downloaded the pre-compiled version of R package:
>> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package under my
>> > tmp
>> > directory (/tmp). The directories "et"c and "usr" got created with
>> > binaries
>> > R and Rscript under /tmp/usr/bin/.
>> >
>> > Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt)
>> > reports
>> > the below error,
>> >
>> > ./usr/bin/R
>> >                                              ./usr/bin/R: line 238:
>> > /usr/lib/R/etc/ldpaths: No such file or directory
>> > ERROR: R_HOME ('/usr/lib/R') not found
>> >
>> > How to reconfigure the R environment variables? Because, i tried setting
>> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
>> >
>> > The Linux version i am using is  2.6.32. Please help me with the steps
>> > to
>> > install the R correctly. Thanks.
>> >
>> > Regards
>> > Sasi
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From jeroen.ooms at stat.ucla.edu  Wed Oct  7 13:05:15 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Wed, 7 Oct 2015 13:05:15 +0200
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
Message-ID: <CABFfbXs8X8u6kah4Q4Bg+ETY_bvsazrKWJ7OM1HT1-KF_dkvhA@mail.gmail.com>

> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
>> Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
>> Linux Server release 6.2".

On RHEL and CentOS the easiest and most reliable way to get R and R
packages is via EPEL. Simply add the EPEL repositories and from there
on you can install R and R packages as you would do on Fedora.


From pdalgd at gmail.com  Wed Oct  7 13:32:25 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 7 Oct 2015 13:32:25 +0200
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CABFfbXs8X8u6kah4Q4Bg+ETY_bvsazrKWJ7OM1HT1-KF_dkvhA@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
	<CABFfbXs8X8u6kah4Q4Bg+ETY_bvsazrKWJ7OM1HT1-KF_dkvhA@mail.gmail.com>
Message-ID: <73439926-72A6-4F3A-90BE-4108090369B5@gmail.com>


On 07 Oct 2015, at 13:05 , Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:

>> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
>>> Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
>>> Linux Server release 6.2".
> 
> On RHEL and CentOS the easiest and most reliable way to get R and R
> packages is via EPEL. Simply add the EPEL repositories and from there
> on you can install R and R packages as you would do on Fedora.
> 

Pretty much no Linux distribution expects you to install anything by "unzipping compiled code". They generally have a packaging format like .rpm or .deb, and even then you can't mix them freely between different distributions -- SUSE .rpm are usually not interchangeable with RedHat and vice versa. You generally access them from curated package repositories using tools like yum or apt-get. One exception may be Slackware. At any rate, whereever you got your zipfile from, it is most likely wrong for RHEL.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From boris.steipe at utoronto.ca  Wed Oct  7 15:09:54 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 7 Oct 2015 09:09:54 -0400
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
	<C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
	<CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
Message-ID: <12891EBD-B790-4333-9732-820A826DCAF5@utoronto.ca>

Still not sure I understand. But here is what I think you might mean:

# Your data
mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))

# Create a square matrix with enough space to have an element for each pair. Since
# order is not important, only the upper triangle is used. If the matrix is
# large and sparse, a different approach might be needed.
freq <- matrix(numeric(max(mat) * max(mat)),  nrow = max(mat), ncol = max(mat))

# Loop over your input
for (i in 1:nrow(mat)) {
    # Sort the elements of a row by size.
    x <- sort(mat[i,])
    # Increment the corresponding element of the frequency matrix
    freq[x[1], x[2]] <- freq[x[1], x[2]] + 1
}

freq


Cheers,
B.
 




On Oct 7, 2015, at 1:17 AM, Hermann Norpois <hnorpois at gmail.com> wrote:

> Ok, this was misleading. And was not that important. My result matrix should look like this: 
> 
>   1    2   3   4   5   6   7 ...
> 1 p1 p2
> 2 p
> 3
> 4
> 
> p1 etc are the frequencies of the combinations
> 
> 1 and 2 for instance do not appear in my example. So the values would be zero. Actually, this part is not too important. I would be happy enough to solve the challenge with the frequencies of the pairs.
> Thanks Hermann
> 
> 2015-10-07 2:40 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
> Since order is not important to you, you can order your pairs (e.g. decreasing) before compiling the frequencies.
> But I don't understand the second part about values "that do not appear in the matrix". Do you mean you want to assess all combinations? If that's the case I would think about a hash table or other indexed data structure, rather than iterating through a matrix.
> 
> 
> B.
> 
> 
> 
> On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> 
> > Hello,
> >
> > I have a matrix mat (see dput(mat))
> >
> >> mat
> >      [,1] [,2]
> > [1,]    5    6
> > [2,]    6    5
> > [3,]    5    4
> > [4,]    5    5
> > ....
> >
> > I want the frequencies of the pairs in a new matrix, whereas the
> > combination 5 and 6 is the same as 6 and 5 (see the first two rows of mat).
> > In other words: What is the probability of each combination (each row)
> > ignoring the order in the combination. As a result I would like to have a
> > matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not appear
> > in my matrix.
> >
> > dput (mat)
> > structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> >
> > Thanks
> > Hermann
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From ivan.calandra at univ-reims.fr  Wed Oct  7 15:27:58 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 7 Oct 2015 15:27:58 +0200
Subject: [R] vector graphics
In-Reply-To: <5614D24B.3080809@univ-reims.fr>
References: <5613DDC9.5030400@univ-reims.fr>
	<CAN5YmCGcos5h0LCnksi3GZg5nT+Hmo28vt=EjizQcT=puy4sfA@mail.gmail.com>
	<5614D24B.3080809@univ-reims.fr>
Message-ID: <56151DDE.70309@univ-reims.fr>

For the record, it seems that devEMF::emf() works fine on the Windows 
Vista SP2 machine with R3.2.2 and Illustrator CS4: the text is 
recognized as text and every point/line can be dissociated.

Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 07/10/15 10:05, Ivan Calandra a ?crit :
> Thanks Jean for the tip.
> I'll try postscript() and devEMF::emf() and see if it works.
> Still, it's very complicated to export vector graphics in R...
>
> Ivan
>
> -- 
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> https://www.researchgate.net/profile/Ivan_Calandra
>
> Le 07/10/15 00:16, Adams, Jean a ?crit :
>> Perhaps the discussion at this link will be helpful ... 
>> http://stackoverflow.com/questions/9555889/producing-a-vector-graphics-image-i-e-metafile-in-r-suitable-for-printing-in
>>
>> Jean
>>
>> On Tue, Oct 6, 2015 at 9:42 AM, Ivan Calandra 
>> <ivan.calandra at univ-reims.fr <mailto:ivan.calandra at univ-reims.fr>> 
>> wrote:
>>
>>     Dear useRs,
>>
>>     A colleague of mine is having a problem with graphic devices. The
>>     goal is to save into a vector graphic format that can be edited
>>     with Illustrator CS4.
>>
>>     On my Mac (Snow Leopard), I use RSvgDevice::devSVG() and it works
>>     fine.
>>     But on her Windows Vista computer, I cannot find an alternative.>
>>     sessionInfo()
>>     R version 3.2.2 (2015-08-14)
>>     Platform: i386-w64-mingw32/i386 (32-bit)
>>     Running under: Windows Vista (build 6002) Service Pack 2
>>
>>     I have tried:
>>     - pdf(): I cannot dissociate the graphical elements (no problem
>>     with text)
>>     - cairo_pdf(): the text is replaced by symbols
>>     - cairo_ps(): fine except that the text is not text but object (it
>>     is then a bit troublesome, as any text modification requires the
>>     text to be completely rewritten)
>>     - svg(): the graphic is completely screwed up (it seems to be a
>>     scaling problem, with symbols and letters all very large and
>>     superposed)
>>     - RSvgDevice cannot be installed on the Windows machine, neither
>>     as binary nor from source.
>>
>>     Is there any other device that could work? If not, is it a matter
>>     of settings? So, basically, what can I do?
>>
>>     Thank you in advance,
>>     Ivan
>>
>>     --     Ivan Calandra, PhD
>>     University of Reims Champagne-Ardenne
>>     GEGENAA - EA 3795
>>     CREA - 2 esplanade Roland Garros
>>     51100 Reims, France
>>     +33(0)3 26 77 36 89
>>     ivan.calandra at univ-reims.fr <mailto:ivan.calandra at univ-reims.fr>
>>     https://www.researchgate.net/profile/Ivan_Calandra
>>
>>     ______________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>>     To UNSUBSCRIBE and more, see
>>     https://stat.ethz.ch/mailman/listinfo/r-help
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/posting-guide.html
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From ssefick at gmail.com  Wed Oct  7 16:18:12 2015
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 7 Oct 2015 09:18:12 -0500
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <73439926-72A6-4F3A-90BE-4108090369B5@gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
	<CABFfbXs8X8u6kah4Q4Bg+ETY_bvsazrKWJ7OM1HT1-KF_dkvhA@mail.gmail.com>
	<73439926-72A6-4F3A-90BE-4108090369B5@gmail.com>
Message-ID: <CADKEMqiCeYnHy1_9eMKvQe-i6tPPVyuBVRmi8DhEtcsgXXAMMA@mail.gmail.com>

I couldn't tell from the OP's message what distribution they have
installed. If it is redhat (or a derivative), the extra packages for
enterprise linux (epel) has up-to-date R packages to install with yum. I
have had some minor issues with installing A FEW (mostly GIS related)
packages that were easily solved with google and careful reading of the
error messages.
HTH,

Stephen

On Wed, Oct 7, 2015 at 6:32 AM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 07 Oct 2015, at 13:05 , Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
>
> >> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com>
> wrote:
> >>> Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
> >>> Linux Server release 6.2".
> >
> > On RHEL and CentOS the easiest and most reliable way to get R and R
> > packages is via EPEL. Simply add the EPEL repositories and from there
> > on you can install R and R packages as you would do on Fedora.
> >
>
> Pretty much no Linux distribution expects you to install anything by
> "unzipping compiled code". They generally have a packaging format like .rpm
> or .deb, and even then you can't mix them freely between different
> distributions -- SUSE .rpm are usually not interchangeable with RedHat and
> vice versa. You generally access them from curated package repositories
> using tools like yum or apt-get. One exception may be Slackware. At any
> rate, whereever you got your zipfile from, it is most likely wrong for RHEL.
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From wolfgang.raffelsberger at gmail.com  Wed Oct  7 16:27:37 2015
From: wolfgang.raffelsberger at gmail.com (Wolfgang Raffelsberger)
Date: Wed, 7 Oct 2015 16:27:37 +0200
Subject: [R] Installing different R versions
In-Reply-To: <87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>
References: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>
	<87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <CALDESV82515ieKFe5y5HbB5J0MP9CJ3hVzs0Rro+OuYOTQT+wA@mail.gmail.com>

check out the official document
*R Installation and Administration*
from https://cran.r-project.org/manuals.html
There you'll find how to define a specific path for each installation.

(Since a number of years I administrate multiple versions of R at different
platforms, of course including Linux)

Wolfgang

2015-10-07 9:04 GMT+02:00 Loris Bennett <loris.bennett at fu-berlin.de>:

> Dear Luca,
>
> Luca Cerone <luca.cerone at gmail.com> writes:
>
> > Dear all,
> > on one shared machine we have an older R version installed. Some packages
> > have known issues with that version that are fixed in newer R versions.
> >
> > Since that is a production machine with many jobs running we would like
> to
> > keep things as they are. However I would also like to keep advantage of
> the
> > newest version and the bug fixes introduced.
> >
> > What would be the best way to install a newer version along the one that
> > already exists? Is it possible to install it for a specific user only?
> >
> > Cheers,
> > Luca
>
> If you are on a Unix-like platform, a standard way of dealing with
> multiple versions of a piece of software installed in parallel is
> "Environment Modules":
>
> http://modules.sourceforge.net/
>
> Packages for various Linux distributions are available.
>
> You could make a version available for a specific user by setting
> appropriate file permissions of the module file which is used to set up
> the environment.  However, I would consider this a somewhat unusual
> configuration.  If you are worried about people using the wrong version
> by mistake, you can either have the standard version available without
> using modules, or you can define a default version within the modules
> setup.
>
> HTH
>
> Loris
>
> --
> This signature is currently under construction.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Wed Oct  7 16:36:47 2015
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 7 Oct 2015 10:36:47 -0400
Subject: [R] F-test of equality of variances - but weighted?
Message-ID: <CAN2xGJbHknWHNK_TKtJtfnN9DMEW6ai2scs4n2GoMXqvzaxgbA@mail.gmail.com>

I would like to use an F-Test for Equality of Variances on a variable
to compare two groups. Normally, this would be done with 'var.test'.
However, the data need to be weighted (individual-level weights).

R's package 'survey' is geared at running analyses with complex
sampling weights. But, unless I have overlooked something, it doesn't
seem able to do an F-test for Equality of Variances (or a similar
test) on weighted data.

Any pointers what to do in this situation?

Or should I simply calculate weighted variances for both groups, sd1
and sd2 and say:
F = var1/var2
With df's of weighted n1-1 for group 1 and weighted n2-1 for group 2?

Would it be kosher from statistical perspective?


Thanks a lot!

-- 
Dimitri Liakhovitski


From dcarlson at tamu.edu  Wed Oct  7 17:30:45 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 7 Oct 2015 15:30:45 +0000
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <12891EBD-B790-4333-9732-820A826DCAF5@utoronto.ca>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
	<C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
	<CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
	<12891EBD-B790-4333-9732-820A826DCAF5@utoronto.ca>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CC7C6@mb02.ads.tamu.edu>

As with Boris, I'm not sure what you are looking for, but this may help

> # To get all possibilities, create a grid
> grd <- expand.grid(0:9, 0:9)
> # Extract those with smaller first column values
> grd <- grd[grd$Var1 <= grd$Var2,]
> # Tabulate after pasting first and second column
> grd2 <- data.frame(table(apply(grd, 1, paste0, collapse=" - ")))
> 
> # Combine the two tables and subtract 1 to get rid of the counts from grd2$Freq
> dta2 <- rbind(grd2, dta)
> freqs <- data.frame(xtabs(Freq~Var1, dta2) - 1)
> str(freqs)
'data.frame':   55 obs. of  2 variables:
 $ Var1: Factor w/ 55 levels "0 - 0","0 - 1",..: 1 2 3 4 5 6 7 8 9 10 ...
 $ Freq: num  0 0 0 0 0 0 0 0 0 0 ...
> freqs[c(40:50), ]
    Var1 Freq
40 4 - 9    0
41 5 - 5    2
42 5 - 6   10
43 5 - 7    4
44 5 - 8    0
45 5 - 9    0
46 6 - 6    0
47 6 - 7    2
48 6 - 8    0
49 6 - 9    0
50 7 - 7    0

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Boris Steipe
Sent: Wednesday, October 7, 2015 8:10 AM
To: Hermann Norpois
Cc: r-help
Subject: Re: [R] Measure the frequencies of pairs in a matrix

Still not sure I understand. But here is what I think you might mean:

# Your data
mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))

# Create a square matrix with enough space to have an element for each pair. Since
# order is not important, only the upper triangle is used. If the matrix is
# large and sparse, a different approach might be needed.
freq <- matrix(numeric(max(mat) * max(mat)),  nrow = max(mat), ncol = max(mat))

# Loop over your input
for (i in 1:nrow(mat)) {
    # Sort the elements of a row by size.
    x <- sort(mat[i,])
    # Increment the corresponding element of the frequency matrix
    freq[x[1], x[2]] <- freq[x[1], x[2]] + 1
}

freq


Cheers,
B.





On Oct 7, 2015, at 1:17 AM, Hermann Norpois <hnorpois at gmail.com> wrote:

> Ok, this was misleading. And was not that important. My result matrix should look like this: 
> 
>   1    2   3   4   5   6   7 ...
> 1 p1 p2
> 2 p
> 3
> 4
> 
> p1 etc are the frequencies of the combinations
> 
> 1 and 2 for instance do not appear in my example. So the values would be zero. Actually, this part is not too important. I would be happy enough to solve the challenge with the frequencies of the pairs.
> Thanks Hermann
> 
> 2015-10-07 2:40 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
> Since order is not important to you, you can order your pairs (e.g. decreasing) before compiling the frequencies.
> But I don't understand the second part about values "that do not appear in the matrix". Do you mean you want to assess all combinations? If that's the case I would think about a hash table or other indexed data structure, rather than iterating through a matrix.
> 
> 
> B.
> 
> 
> 
> On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> 
> > Hello,
> >
> > I have a matrix mat (see dput(mat))
> >
> >> mat
> >      [,1] [,2]
> > [1,]    5    6
> > [2,]    6    5
> > [3,]    5    4
> > [4,]    5    5
> > ....
> >
> > I want the frequencies of the pairs in a new matrix, whereas the
> > combination 5 and 6 is the same as 6 and 5 (see the first two rows of mat).
> > In other words: What is the probability of each combination (each row)
> > ignoring the order in the combination. As a result I would like to have a
> > matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not appear
> > in my matrix.
> >
> > dput (mat)
> > structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> >
> > Thanks
> > Hermann
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Oct  7 18:39:11 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 7 Oct 2015 09:39:11 -0700
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <12891EBD-B790-4333-9732-820A826DCAF5@utoronto.ca>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
	<C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
	<CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
	<12891EBD-B790-4333-9732-820A826DCAF5@utoronto.ca>
Message-ID: <CAF8bMcbyJU3weMTdkPLoiynv2HObQBQD6e3JPVsiE-=WrySpXw@mail.gmail.com>

You could also call table() on the columns of the input matrix, first
converting them
to factors with levels 1:max.  Then add together the upper and lower
triangles of
the table if order is not important.  E.g.,
f2 <- function (mat)
{
    maxMat <- max(mat)
    stopifnot(is.matrix(mat), all(mat %in% seq_len(maxMat)))
    L <- split(factor(mat, levels = seq_len(maxMat)), col(mat))
    Table <- do.call(table, unname(L))
    ignoreOrder <- function(M) {
        stopifnot(length(dim(M)) == 2)
        lower <- lower.tri(M, diag = FALSE)
        upper <- upper.tri(M, diag = FALSE)
        M[lower] <- M[lower] + t(M)[lower]
        M[upper] <- t(M)[upper]
        M
    }
    ignoreOrder(Table)
}

> mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> f2(mat)

     1  2  3  4  5  6  7
  1  0  0  0  0  0  0  0
  2  0  0  0  0  0  0  0
  3  0  0  0  2  0  0  2
  4  0  0  2  0  4  0  0
  5  0  0  0  4  2 10  4
  6  0  0  0  0 10  0  2
  7  0  0  2  0  4  2  0
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 7, 2015 at 6:09 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> Still not sure I understand. But here is what I think you might mean:
>
> # Your data
> mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
>
> # Create a square matrix with enough space to have an element for each pair. Since
> # order is not important, only the upper triangle is used. If the matrix is
> # large and sparse, a different approach might be needed.
> freq <- matrix(numeric(max(mat) * max(mat)),  nrow = max(mat), ncol = max(mat))
>
> # Loop over your input
> for (i in 1:nrow(mat)) {
>     # Sort the elements of a row by size.
>     x <- sort(mat[i,])
>     # Increment the corresponding element of the frequency matrix
>     freq[x[1], x[2]] <- freq[x[1], x[2]] + 1
> }
>
> freq
>
>
> Cheers,
> B.
>
>
>
>
>
> On Oct 7, 2015, at 1:17 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
>
>> Ok, this was misleading. And was not that important. My result matrix should look like this:
>>
>>   1    2   3   4   5   6   7 ...
>> 1 p1 p2
>> 2 p
>> 3
>> 4
>>
>> p1 etc are the frequencies of the combinations
>>
>> 1 and 2 for instance do not appear in my example. So the values would be zero. Actually, this part is not too important. I would be happy enough to solve the challenge with the frequencies of the pairs.
>> Thanks Hermann
>>
>> 2015-10-07 2:40 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
>> Since order is not important to you, you can order your pairs (e.g. decreasing) before compiling the frequencies.
>> But I don't understand the second part about values "that do not appear in the matrix". Do you mean you want to assess all combinations? If that's the case I would think about a hash table or other indexed data structure, rather than iterating through a matrix.
>>
>>
>> B.
>>
>>
>>
>> On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
>>
>> > Hello,
>> >
>> > I have a matrix mat (see dput(mat))
>> >
>> >> mat
>> >      [,1] [,2]
>> > [1,]    5    6
>> > [2,]    6    5
>> > [3,]    5    4
>> > [4,]    5    5
>> > ....
>> >
>> > I want the frequencies of the pairs in a new matrix, whereas the
>> > combination 5 and 6 is the same as 6 and 5 (see the first two rows of mat).
>> > In other words: What is the probability of each combination (each row)
>> > ignoring the order in the combination. As a result I would like to have a
>> > matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not appear
>> > in my matrix.
>> >
>> > dput (mat)
>> > structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
>> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
>> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
>> >
>> > Thanks
>> > Hermann
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From John.Szumiloski at bms.com  Wed Oct  7 19:40:04 2015
From: John.Szumiloski at bms.com (Szumiloski, John)
Date: Wed, 7 Oct 2015 17:40:04 +0000
Subject: [R] [lattice::xyplot] Using (panel:.)abline with panel.superpose?
Message-ID: <00fbfd48499c4824b3e7fd5792509e38@CO2PR26MB0011.067d.mgd.msft.net>

Dear useRs,

I recently had a query concerning how to customize the graphics parameters in lattice::xyplot to change not only the color but also the pch symbols, lty and lwd line parameters, etc., within each grouping variable in the plot.  (https://stat.ethz.ch/pipermail/r-help/2015-July/430285.html).  Many thanks to Mark Leeds who described the solution using panel.superpose as the panel function and defining a custom panel.groups function using the subscripts argument.

Here is a crude example.  Note how the pch parameter varies with grouping variable as well as color.  I have commented out two lines which are not important for the example but are for my main question.

#### begin code 1

# R version 3.2.2 release, lattice version 0.20-33, Windows 7.

    dat <- data.frame(Trt=rep(c('1','2'), each=10),
                      Sbj=rep(c('1','2'), each=5),
                      X=rep(c(0,1,2,3,4), times=4),
                      Y=c(1,3,3,3,1, 2,4,4,4,2,
                          3,1,1,1,3, 4,2,2,2,4)
                     )

    xgrid <- seq(0L, 4L)
    ygrid <- seq(0L, 5L)

    require(lattice)
    xyplot(Y ~ X | Trt, data=dat, groups=Sbj, type='b', lty=1, cex=2, lwd=3,
           scales=list(x=list(at=xgrid), y=list(at=ygrid)),
           ### abline=list(h=ygrid, v=xgrid, col=gray(0.8)),
           mycol=c('red', 'blue'), mypch=c(16,17),
           panel=panel.superpose,
           panel.groups=function(x, y, subscripts,
                                  mycol, mypch, col.line, col.symbol, pch, ...) {
                                 ### panel.abline(h=ygrid, v=xgrid, col=gray(0.8))
                                 panel.xyplot(x, y, ...,
                                                     pch = mypch[dat[['Sbj']][subscripts]],
                                              col.symbol = mycol[dat[['Sbj']][subscripts]],
                                                col.line = mycol[dat[['Sbj']][subscripts]]
                                             )
                                } # function
          ) # xyplot

### end code 1

My question involves the commented out lines.  I would like to draw a light grid in the panels.  If I used panel.grid() it would be impossible to get the gridlines into arbitrary positions, as it seems to pick values similar to pretty() (I would love to be corrected on this).  So we can use an abline argument to the main xyplot call, or a panel.abline() call in the panel.groups function.

But either way leads to a problem.  The ablines seem to be rerendered for each level of the grouping variable, thus only the final level is plotted without being the grid rendered on top of it.  Try it by uncommenting either line.

This is not totally surprising as it does mention somewhere in the documentation that panel.groups() is called for each value of the grouping variable.  So my question: How do I render the grid just once, before actually rendering the data, so as to avoid this problem?

I realized a good place to start might be to include panel.abline in the panel function itself, rather in the panel.groups function called several times per panel.  Thus something like this:

### begin code 2

    xyplot(Y~X|Trt, data=dat, groups=Sbj, type='b', lty=1, cex=2, lwd=3,
           scales=list(x=list(at=xgrid), y=list(at=ygrid)),
           mycol=c('red', 'blue'), mypch=c(16,17),
           panel=function(x, y, ...) {   ##########  <---------------- new panel function
                          panel.abline(h=ygrid, v=xgrid, col=gray(0.9))
                          panel.superpose(x, y, ...)
                         },
           panel.groups=function(x, y, subscripts,
                                  mycol, mypch, col.line, col.symbol, pch, ...) {
                                 panel.xyplot(x, y, ...,
                                                     pch = mypch[dat[['Sbj']][subscripts]],
                                              col.symbol = mycol[dat[['Sbj']][subscripts]],
                                                col.line = mycol[dat[['Sbj']][subscripts]]
                                             )
                                } # function
          ) # xyplot

### end code 2

Of course this won't work as written, I need to replace the ... arguments with the right ones.  Here is where I am having trouble.  I have tried all kinds of permutations of the mycol etc., xgrid etc., subscripts etc., and never got the plot to render the ablines once, then the data correctly.

Any assistance greatly appreciated.
John
John Szumiloski, Ph.D.
Principal Scientist, Statistician
Analytical and Bioanalytical Development
NBR105-1-1411

Bristol-Myers Squibb
P.O. Box 191
1 Squibb Drive
New Brunswick, NJ
08903-0191
USA

(732) 227-7167



________________________________
 This message (including any attachments) may contain co...{{dropped:8}}


From lordpreetam at gmail.com  Wed Oct  7 22:46:40 2015
From: lordpreetam at gmail.com (Preetam Pal)
Date: Thu, 8 Oct 2015 02:16:40 +0530
Subject: [R] Quantile Regression without intercept
In-Reply-To: <8CE4F61D-E77B-4F65-B4E1-C1F90E01F3DD@illinois.edu>
References: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
	<3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>
	<91a5e46eba48442abc188905e1de2dbd@CHIHT3.ad.uillinois.edu>
	<8CE4F61D-E77B-4F65-B4E1-C1F90E01F3DD@illinois.edu>
Message-ID: <56158437.e1c4440a.25497.4533@mx.google.com>

So, what does weighted quantile regression even aim to achieve? Invariably, this plane would not split the data set into the requisite fractions.....

-----Original Message-----
From: "Roger Koenker" <rkoenker at illinois.edu>
Sent: ?06-?10-?2015 07:09 PM
To: "Lorenz, David" <lorenz at usgs.gov>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] Quantile Regression without intercept


> On Oct 6, 2015, at 8:32 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> 
> Thanks for the details, I suspected something like that.
> I think that begs the question: what is the meaning of quantile regression through the origin? If the tau=.5 line does not pass through 1/2 the data how do I interpret the line?

As an estimate of the conditional median (quantile) function when constrained to pass through
the origin? as with least squares fitting without an intercept, you do this at your peril.
> 
> 
> On Tue, Oct 6, 2015 at 8:03 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
> 
> > On Oct 6, 2015, at 7:58 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> >
> > Did you verify that the correct percentages were above/below the regression
> > lines? I did a quick check and for example did not consistently get 50% of
> > the observed response values greater than the tau=.5 line. I did when I
> > included the nonzero intercept term.
> 
> Your "correct percentages" are only correct when you have an intercept in the model,
> without an intercept there is no gradient condition to ensure that.
> >
> >
> >
> >> Date: Mon, 5 Oct 2015 21:14:04 +0530
> >> From: Preetam Pal <lordpreetam at gmail.com>
> >> To: stephen sefick <ssefick at gmail.com>
> >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> >> Subject: Re: [R] Quantile Regression without intercept
> >> Message-ID: <56129a41.025f440a.b1cf4.fffff5ee at mx.google.com>
> >> Content-Type: text/plain; charset="UTF-8"
> >>
> >> Yes..it works. .... Thanks ??
> >>
> >> -----Original Message-----
> >> From: "stephen sefick" <ssefick at gmail.com>
> >> Sent: ?05-?10-?2015 09:01 PM
> >> To: "Preetam Pal" <lordpreetam at gmail.com>
> >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> >> Subject: Re: [R] Quantile Regression without intercept
> >>
> >> I have never used this, but does the formula interface work like lm? Y~X-1?
> >>
> >>
> >> On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com>
> >> wrote:
> >>
> >> Hi guys,
> >>
> >> Can you instruct me please how to run quantile regression without the
> >> intercept term? I only know about the rq function under quantreg package,
> >> but it automatically uses an intercept model. Icant change that, it seems.
> >>
> >> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
> >> Unemployment). Their sizes are 125 each.
> >>
> >> Appreciate your help with this.
> >>
> >> Regards,
> >> Preetam
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >>
> >>
> >>
> >>
> >> --
> >>
> >> Stephen Sefick
> >> **************************************************
> >> Auburn University
> >> Biological Sciences
> >> 331 Funchess Hall
> >> Auburn, Alabama
> >> 36849
> >> **************************************************
> >> sas0025 at auburn.edu
> >> http://www.auburn.edu/~sas0025
> >> **************************************************
> >>
> >> Let's not spend our time and resources thinking about things that are so
> >> little or so large that all they really do for us is puff us up and make us
> >> feel like gods.  We are mammals, and have not exhausted the annoying little
> >> problems of being mammals.
> >>
> >>                                -K. Mullis
> >>
> >> "A big computer, a complex algorithm and a long time does not equal
> >> science."
> >>
> >>                              -Robert Gentleman
> >>        [[alternative HTML version deleted]]
> >>
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mxfomin at gmail.com  Wed Oct  7 09:43:25 2015
From: mxfomin at gmail.com (Maxim Fomin)
Date: Wed, 7 Oct 2015 10:43:25 +0300
Subject: [R] MSwM R package: model and state probability significance
	(p00+p11=1)
Message-ID: <CALB30JBUjzdY-amVP32uWY8JP+gtPgrXW428s0iQxSBuy8PFDA@mail.gmail.com>

 Dear  R community,

It seems that MSwM package provides three model diagnostic tools:
pooled residuals plot, QQ plot and ACFs plot (via plotDiag). However, I cannot
find any statistic to test the whole model significance (and even for
each reported regime only multiple R^2 is provided).

After searching for the answer I found one paper (Lec-Markov_note.pdf
in web) which states  that there are two tests for MRSM model. The
first has long description and essentially links to Hansen (1992)
paper -  it tests whether switching parameters are nuisance. The
second test is H0: p00+p11=1 and can be tested with Wald test.

So, my question is follows. How the first test can be performed in R
and where to get variance of state probabilities to perform Wald test
of second hypothesis (I couldn't find relevant data in MSM.lm object)?

Thanks in advance,
Best regards,
Maxim Fomin


From ckmsasi at gmail.com  Wed Oct  7 06:42:54 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Tue, 6 Oct 2015 21:42:54 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
Message-ID: <CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>

Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
Linux Server release 6.2".

Also, couple of clarifications,

1. Do we have a R package compatibility matrix against the Linux kernel
version? Or for the Red Hat Linux with kernel version 2.6.32-279, do you
have any suggestion/recommendation on R package to be used?

2. If we need to use Rscripts in embedded systems such as routers and
switches, do we need to install the complete R package in the  system also?
Or just libR.so and Rscript should be ok?

Thanks again Mike.

Regards
Sasi

On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon <jmhannon.ucdavis at gmail.com>
wrote:

> It's very likely that there is already an R package for your linux
> system, and, if so, you'd probably be well-served to use that one.
> You've given us the version of the kernel you're using (not a recent
> one, BTW), but what linux distribution are you using?
>
> -- Mike
>
>
> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com>
> wrote:
> > Hi,
> >
> > I have downloaded the pre-compiled version of R package:
> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package under my tmp
> > directory (/tmp). The directories "et"c and "usr" got created with
> binaries
> > R and Rscript under /tmp/usr/bin/.
> >
> > Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt) reports
> > the below error,
> >
> > ./usr/bin/R
> >                                              ./usr/bin/R: line 238:
> > /usr/lib/R/etc/ldpaths: No such file or directory
> > ERROR: R_HOME ('/usr/lib/R') not found
> >
> > How to reconfigure the R environment variables? Because, i tried setting
> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
> >
> > The Linux version i am using is  2.6.32. Please help me with the steps to
> > install the R correctly. Thanks.
> >
> > Regards
> > Sasi
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From hnorpois at gmail.com  Wed Oct  7 07:17:18 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Wed, 7 Oct 2015 07:17:18 +0200
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
	<C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
Message-ID: <CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>

Ok, this was misleading. And was not that important. My result matrix
should look like this:

  1    2   3   4   5   6   7 ...
1 p1 p2
2 p
3
4

p1 etc are the frequencies of the combinations

1 and 2 for instance do not appear in my example. So the values would be
zero. Actually, this part is not too important. I would be happy enough to
solve the challenge with the frequencies of the pairs.
Thanks Hermann

2015-10-07 2:40 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:

> Since order is not important to you, you can order your pairs (e.g.
> decreasing) before compiling the frequencies.
> But I don't understand the second part about values "that do not appear in
> the matrix". Do you mean you want to assess all combinations? If that's the
> case I would think about a hash table or other indexed data structure,
> rather than iterating through a matrix.
>
>
> B.
>
>
>
> On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
>
> > Hello,
> >
> > I have a matrix mat (see dput(mat))
> >
> >> mat
> >      [,1] [,2]
> > [1,]    5    6
> > [2,]    6    5
> > [3,]    5    4
> > [4,]    5    5
> > ....
> >
> > I want the frequencies of the pairs in a new matrix, whereas the
> > combination 5 and 6 is the same as 6 and 5 (see the first two rows of
> mat).
> > In other words: What is the probability of each combination (each row)
> > ignoring the order in the combination. As a result I would like to have a
> > matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not
> appear
> > in my matrix.
> >
> > dput (mat)
> > structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> >
> > Thanks
> > Hermann
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From simon.heintz at gadz.org  Wed Oct  7 10:32:28 2015
From: simon.heintz at gadz.org (simon.heintz)
Date: Wed, 7 Oct 2015 01:32:28 -0700 (PDT)
Subject: [R] RSM in R, optimize/minimize a response
Message-ID: <1444206748374-4713256.post@n4.nabble.com>

Good morning
I'm trying to optimize (minimize actually) a response from a DOE with 4
factors. The 4 factors were built from a Latin Hypercube DOE design type.
Then I proceeded this experiment on 28 different cases, so each case will
include 2000 experiments.
I would like to find the factor quartet that will minimize globally the
response.
How can I find it? I built the script shown below, and I take the eigen
values from the rsm summary, but it's wrong, isn't it ?
I hope it's clear :)
Thank you in advance
Regards

I built the following script:

setwd("C:/Folder")
data <- read.table("File.txt",header=TRUE)
str(data)
summary(data)
data$block <- rep(1:28, each=2000)
library(rsm)
subset <- seq(from=min(data$Case),to=max(data$Case),by=1)
resu <- rsm(Response ~ block + SO(A,B,C,D),data=data[subset,])
summary(resu)

The file looks like the following:

Case	A	B	C	D	Response
1	1.05243	1.32528	0.974352	1.03963	0.01615749
2	1.10323	1.055	0.937314	1.19282	0.017107937
3	1.12744	1.06457	0.772495	1.44226	0.016988281
4	1.17818	1.07334	1.40521	1.73733	0.016978022
5	1.17297	1.07055	0.910072	1.15935	0.017274737
6	1.14439	0.705105	0.91889	1.78162	0.01699969
7	1.0403	0.778101	1.02743	1.41937	0.017164506
8	1.0847	0.770317	1.16855	1.04109	0.017394582
9	1.03789	1.23609	1.43767	1.52393	0.015932553
10	1.12329	0.68861	1.23011	1.49413	0.01698659
...
11	...
...
2150	...
...
55999	1.19111	1.48329	0.880659	1.82682	0.037803564
56000	1.11901	1.12973	0.523026	1.92828	0.038733914



--
View this message in context: http://r.789695.n4.nabble.com/RSM-in-R-optimize-minimize-a-response-tp4713256.html
Sent from the R help mailing list archive at Nabble.com.


From neverstop at hotmail.it  Wed Oct  7 12:33:23 2015
From: neverstop at hotmail.it (Neverstop)
Date: Wed, 7 Oct 2015 03:33:23 -0700 (PDT)
Subject: [R] additive proportional odds model in R
Message-ID: <1444214003583-4713259.post@n4.nabble.com>

Hi all!
I'm looking for a way to fit an additive proportional odds model in R since
I need to analyse ordinal data. 
The polr() function of the MASS package of R allows only to fit a linear
proportional odds model so I can't use it. 
The gam() function of the gam package of R allows to fit additive models and
generalized additive models. This package uses smoothing splines and loess
as smoothers. I've read the documentation and it doesn't seem to be possible
to fit an additive proportional odds model in R.      
Do you know which function should I use?
Thank you in advance.



--
View this message in context: http://r.789695.n4.nabble.com/additive-proportional-odds-model-in-R-tp4713259.html
Sent from the R help mailing list archive at Nabble.com.


From j.terheyden at t-online.de  Wed Oct  7 12:40:05 2015
From: j.terheyden at t-online.de (begrinner)
Date: Wed, 7 Oct 2015 03:40:05 -0700 (PDT)
Subject: [R] changing colors in filled.contour
Message-ID: <1444214405711-4713260.post@n4.nabble.com>

Dear R community!

I haven't worked with R before but I found it has some nice abilities to
create graphics. I made it to create a filled.contour with the settings I
want but unfortunately I don't seem to be able to change colors. Instead of
the standard colors, I'd like to get dark gray or black for higher values
(instead of pink) and light gray or white for lower values (instead of
cyan).  A second option I'd like to try is having colors change from green
(low values) to red (high values)... but right now it seems like I'm miles
away from that.

This is what I have so far:

model=function(a, b){+4+0.5*a-0.2*b}
x=seq(-10, 10, by = 2)
y=seq(0, 100, by = 10)
z=outer(x, y, model)
contour(x,y,z,nlevels=12)
mylevels <- seq(0,10,10)
filled.contour(x,y,z, main="Title")

But when I try to Change the Color theme like this -

filled.contour(x,y,z,levels=mylevels,col=grey(seq(0,1,length=length(mylevels))))

 - I just get one white and one black bar. 

Does anyone of you know a solution?

Thanks in advance, you'd help me a lot as I've been working on these few
lines for a couple already.

J




--
View this message in context: http://r.789695.n4.nabble.com/changing-colors-in-filled-contour-tp4713260.html
Sent from the R help mailing list archive at Nabble.com.


From kishor.tappita at gmail.com  Wed Oct  7 13:38:34 2015
From: kishor.tappita at gmail.com (Kishor Tappita)
Date: Wed, 7 Oct 2015 17:08:34 +0530
Subject: [R] rpart cutpoint interpretation
Message-ID: <CAL_RqETpQuLyjo_7xYBkieySPj98wqBrSnh3k2SjQ7PT117qvg@mail.gmail.com>

Hi All,

I am trying to derive cutpoint/threshold with a poisson distributed
dependent variable. I know how to interpret cutpoint with binary dependent
variable based on direction. Can some on help me to intrepret cutpoint for
poisson case with one independent variable with the derived threshold.

Thanks in advance.

Regards,
Kishor

	[[alternative HTML version deleted]]


From ahaywood3 at gmail.com  Wed Oct  7 15:50:01 2015
From: ahaywood3 at gmail.com (andrew haywood)
Date: Wed, 7 Oct 2015 21:50:01 +0800
Subject: [R] Error with Segmented package
Message-ID: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>

Dear List,

I am trying to run a simple pieewise regression using the segmented package.

When running the following code

library(segmented)
data = data.frame(x=c(50,60,70,80,90,100,110) , y=
c(703.786,705.857,708.153,711.056,709.257, 707.4, 705.6))

model.lm = segmented(lm(y~x,data = data),seg.Z = ~x, psi = NA, control =
seg.control(K=1))

I get the following error.

Error in if (psi == Inf) psi <- median(XREGseg) :
  missing value where TRUE/FALSE needed

Any advice would be greatly appreciated.

Kind regards
Andrew

	[[alternative HTML version deleted]]


From wiebke.ullmann at uni-potsdam.de  Wed Oct  7 18:15:18 2015
From: wiebke.ullmann at uni-potsdam.de (Wiebke Ullmann)
Date: Wed, 7 Oct 2015 16:15:18 +0000
Subject: [R] ltraj contains irregular data
Message-ID: <COL130-W72A3DE036AFA1D01F8D5C8BA360@phx.gbl>

Dear everyone,

as far as I understood the setNA function in adhabitat is there to produce rows in a location dataset that have not been recorded by the GPS collar. I just can not figure out where the problem is. Hope somebody can help me.



>daten$timestamp <- strptime(daten$study.local.timestamp,
format="%Y-%m-%d %H:%M")

>format(round(daten$timestamp, units="hours"),
format="%Y-%m-%d %H:%M:%S")

>daten$timestamp <-
as.POSIXct(daten$timestamp,format="%Y-%m-%d %H:%M:%S")

 

>u<-as.ltraj(daten[,c("utm.easting","utm.northing")],

             
daten$timestamp,id=daten$tag.local.identifier,

             
infolocs=daten[,c("tag.local.identifier",

              "individual.local.identifier")])

>head([[1]])

 

       x      
y                date            dx            dy         dist

407063.1
5911535 2014-05-12 16:00:00      53.75844
-8.434472e+01     100.0200

407116.9
5911451 2014-05-12 17:00:00 -417115.85704 -5.921450e+06 5936122.8652

 -9999.0   -9999
2014-05-12 18:00:00       0.00000  0.000000e+00       0.0000

 -9999.0   -9999
2014-05-12 20:00:00  417008.07372  5.921561e+06 5936226.4139

407009.1
5911562 2014-05-12 21:00:00    
156.63876  1.096218e+02     191.1874

407165.7
5911672 2014-05-12 23:00:00           
NA            NA           NA

        dt          R2n  abs.angle 
rel.angle

3600
3.523851e+13 -1.0033541 -2.5038352

3600
3.523755e+13 -1.6411217 -0.6377675

7200
0.000000e+00         NA         NA

3600
0.000000e+00  1.5004904 -3.1415732

7200
3.523878e+13  0.6106172 -0.8898732

NA   3.524021e+13         NA         NA

 

 

>nex <- setNA(u,u[[1]]$date[1], 1*3600)

 

Fehler in
FUN(X[[i]], ...) : 

  ltraj
contains irregular data (time lag > or < tol)



If you need any additional information on what I have done I am happy to provide it (I am
not sure what you need to be able to help).

Thank you soo much in advance.

Cheers,
Wiebke

 		 	   		  
	[[alternative HTML version deleted]]


From yongnam.kim at wisc.edu  Wed Oct  7 21:53:53 2015
From: yongnam.kim at wisc.edu (Yongnam Kim)
Date: Wed, 07 Oct 2015 19:53:53 +0000
Subject: [R] how to suppress to bring value labels with memisc pkg
Message-ID: <CAEazi5-XbEbbJJ+N_bYznAwkyAZ_5thB3xBFeccGFkVgcEB3qA@mail.gmail.com>

Hello all,

I know how to suppress to bring value labels from SPSS when importing sav
file using foreign package by "use.value.labels = FALSE" in read.spss
function. But, I don't know how to do the same thing when using memisc pkg,
in particular, with the spss.system.file function.

Many thanks!

	[[alternative HTML version deleted]]


From juan.munoz-garcia at bioch.ox.ac.uk  Wed Oct  7 23:00:06 2015
From: juan.munoz-garcia at bioch.ox.ac.uk (Juan Munoz-Garcia)
Date: Wed, 7 Oct 2015 21:00:06 +0000
Subject: [R] non-linear fit and statistical significance
Message-ID: <84178BF7-3F21-441F-B694-C35F420C9F77@bioch.ox.ac.uk>

Dear R users,

I?m using the constrOptim.nl<http://constrOptim.nl> to carry out non-linear fit with constraints between experimental and modelled data. As far as I understand the parameter ?fval" indicates the goodness of this fit.
My first question is: Is the fval parameter similar to commonly used chi^2 parameter?
Second: if you?d need to decide which set of models best fit your experimental data by comparing the different fval values obtained, how can you use R to determine if the differences between fval values is statistically significant?

I?d appreciate your feedback.
Regards.
Juan C. Munoz-Garc?a

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Wed Oct  7 23:08:46 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 7 Oct 2015 16:08:46 -0500
Subject: [R] Quantile Regression without intercept
In-Reply-To: <ffe5ff39c0c2470eb4d696a203563ede@CHIHT3.ad.uillinois.edu>
References: <55c8829c74a14713a765c5a5674479ce@CITESHT2.ad.uillinois.edu>
	<3D29A067-A8B1-4551-8207-BC6EE83D2650@illinois.edu>
	<91a5e46eba48442abc188905e1de2dbd@CHIHT3.ad.uillinois.edu>
	<8CE4F61D-E77B-4F65-B4E1-C1F90E01F3DD@illinois.edu>
	<ffe5ff39c0c2470eb4d696a203563ede@CHIHT3.ad.uillinois.edu>
Message-ID: <6EBD747D-E626-485C-92D7-4A10CF80BDE3@illinois.edu>


> On Oct 7, 2015, at 3:46 PM, Preetam Pal <lordpreetam at gmail.com> wrote:
> 
> So, what does weighted quantile regression even aim to achieve? Invariably, this plane would not split the data set into the requisite fractions?..


This officially ties this thread into a loop, since the OP wants to know why he wanted to do what he originally
requested.   If one ?knows? that the intercept is zero, then it is always good to impose this, but like I said one
does this at one?s peril.  An example from economics might help:  suppose you are estimating Engel curves
in an unwelfare state, so 0 income implies 0 expenditure, then all (quantile)  Engel curves pass through the origin and
one might want to impose this.  On the other hand maybe not...


> From: Roger Koenker
> Sent: ?06-?10-?2015 07:09 PM
> To: Lorenz, David
> Cc: r-help at r-project.org
> Subject: Re: [R] Quantile Regression without intercept
> 
> 
> > On Oct 6, 2015, at 8:32 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> > 
> > Thanks for the details, I suspected something like that.
> > I think that begs the question: what is the meaning of quantile regression through the origin? If the tau=.5 line does not pass through 1/2 the data how do I interpret the line?
> 
> As an estimate of the conditional median (quantile) function when constrained to pass through
> the origin? as with least squares fitting without an intercept, you do this at your peril.
> > 
> > 
> > On Tue, Oct 6, 2015 at 8:03 AM, Roger Koenker <rkoenker at illinois.edu> wrote:
> > 
> > > On Oct 6, 2015, at 7:58 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> > >
> > > Did you verify that the correct percentages were above/below the regression
> > > lines? I did a quick check and for example did not consistently get 50% of
> > > the observed response values greater than the tau=.5 line. I did when I
> > > included the nonzero intercept term.
> > 
> > Your "correct percentages" are only correct when you have an intercept in the model,
> > without an intercept there is no gradient condition to ensure that.
> > >
> > >
> > >
> > >> Date: Mon, 5 Oct 2015 21:14:04 +0530
> > >> From: Preetam Pal <lordpreetam at gmail.com>
> > >> To: stephen sefick <ssefick at gmail.com>
> > >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> > >> Subject: Re: [R] Quantile Regression without intercept
> > >> Message-ID: <56129a41.025f440a.b1cf4.fffff5ee at mx.google.com>
> > >> Content-Type: text/plain; charset="UTF-8"
> > >>
> > >> Yes..it works. .... Thanks ??
> > >>
> > >> -----Original Message-----
> > >> From: "stephen sefick" <ssefick at gmail.com>
> > >> Sent: ?05-?10-?2015 09:01 PM
> > >> To: "Preetam Pal" <lordpreetam at gmail.com>
> > >> Cc: "r-help at r-project.org" <r-help at r-project.org>
> > >> Subject: Re: [R] Quantile Regression without intercept
> > >>
> > >> I have never used this, but does the formula interface work like lm? Y~X-1?
> > >>
> > >>
> > >> On Mon, Oct 5, 2015 at 10:27 AM, Preetam Pal <lordpreetam at gmail.com>
> > >> wrote:
> > >>
> > >> Hi guys,
> > >>
> > >> Can you instruct me please how to run quantile regression without the
> > >> intercept term? I only know about the rq function under quantreg package,
> > >> but it automatically uses an intercept model. Icant change that, it seems.
> > >>
> > >> I have numeric data on Y variable (Gdp) and 2 X variables (Hpa and
> > >> Unemployment). Their sizes are 125 each.
> > >>
> > >> Appreciate your help with this.
> > >>
> > >> Regards,
> > >> Preetam
> > >>        [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >>
> > >>
> > >>
> > >>
> > >>
> > >> --
> > >>
> > >> Stephen Sefick
> > >> **************************************************
> > >> Auburn University
> > >> Biological Sciences
> > >> 331 Funchess Hall
> > >> Auburn, Alabama
> > >> 36849
> > >> **************************************************
> > >> sas0025 at auburn.edu
> > >> http://www.auburn.edu/~sas0025
> > >> **************************************************
> > >>
> > >> Let's not spend our time and resources thinking about things that are so
> > >> little or so large that all they really do for us is puff us up and make us
> > >> feel like gods.  We are mammals, and have not exhausted the annoying little
> > >> problems of being mammals.
> > >>
> > >>                                -K. Mullis
> > >>
> > >> "A big computer, a complex algorithm and a long time does not equal
> > >> science."
> > >>
> > >>                              -Robert Gentleman
> > >>        [[alternative HTML version deleted]]
> > >>
> > >>
> > >>
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > 
> > 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Oct  7 23:22:56 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 7 Oct 2015 14:22:56 -0700
Subject: [R] changing colors in filled.contour
In-Reply-To: <1444214405711-4713260.post@n4.nabble.com>
References: <1444214405711-4713260.post@n4.nabble.com>
Message-ID: <CAF8bMcYt-Ma-k3t5enmQ2PzocbvvR5HveWYL6O7Rda9YungteA@mail.gmail.com>

After
     mylevels <- seq(0,10,10)
mylevels has length 2, hence you get 2 colors.  Use length=10,


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Oct 7, 2015 at 3:40 AM, begrinner <j.terheyden at t-online.de> wrote:

> Dear R community!
>
> I haven't worked with R before but I found it has some nice abilities to
> create graphics. I made it to create a filled.contour with the settings I
> want but unfortunately I don't seem to be able to change colors. Instead of
> the standard colors, I'd like to get dark gray or black for higher values
> (instead of pink) and light gray or white for lower values (instead of
> cyan).  A second option I'd like to try is having colors change from green
> (low values) to red (high values)... but right now it seems like I'm miles
> away from that.
>
> This is what I have so far:
>
> model=function(a, b){+4+0.5*a-0.2*b}
> x=seq(-10, 10, by = 2)
> y=seq(0, 100, by = 10)
> z=outer(x, y, model)
> contour(x,y,z,nlevels=12)
> mylevels <- seq(0,10,10)
> filled.contour(x,y,z, main="Title")
>
> But when I try to Change the Color theme like this -
>
>
> filled.contour(x,y,z,levels=mylevels,col=grey(seq(0,1,length=length(mylevels))))
>
>  - I just get one white and one black bar.
>
> Does anyone of you know a solution?
>
> Thanks in advance, you'd help me a lot as I've been working on these few
> lines for a couple already.
>
> J
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/changing-colors-in-filled-contour-tp4713260.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Thu Oct  8 01:02:56 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 7 Oct 2015 16:02:56 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
	<CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>
Message-ID: <CACdH2ZaBG5RtNKQTvMg4RPdW9PyCVhVJqij81f2B+dV=Ogd-Ag@mail.gmail.com>

Hi, Sasi.  Yes, I think that getting familiar with R in a "friendly"
context before dealing with your embedded system is a good idea.  Note
that the non-GUI part of R is more or less identical across platforms.
Hence, you could experiment with it on a Macbook, a Surface tablet,
etc., etc., if you're just seeking to get established in R.

The hardware configuration of your embedded system seems reasonable,
but again, I don't know what your run-time requirements will be.  Note
in particular that R likes to have objects resident in memory, so if
you're trying to process a 40GB data file on your embedded system,
you're probably out of luck.

I would certainly start by trying to install the Debian package for R.
Even if you don't have apt-get, I would think you'd at least have the
"dpkg" utility:

https://www.debian.org/doc/manuals/debian-faq/ch-pkgtools.en.html

If so, you could use that to install R (provided you have managed to
download the appropriate <*.deb> package for R).



On Wed, Oct 7, 2015 at 3:45 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
> Thanks Mike. From source, i am able to compile and use R in my red hat linux
> box. I was trying to get hands on using R in linux box before trying R on
> the embedded box.
>
> My requirement is to run R (R scripts) on my embedded box which has
> customized debian linux (kernel version 2.6.32) in batch mode without GUI
> support. The embedded box have multi-core MIPS processor with nearly 30GB
> RAM. I hope hardware resources on the embedded box shouldn't be an issue to
> run R (correct me if i am wrong), but linux version running here is an
> customized one with limited supporting services such as light weight shell
> etc.
>
> Given this, do i need to cross compile R package for my embedded box or i
> can directly install the debian MIPS version of R package. But there is no
> apt-get or other installer in the embedded box.
>
>
> Regards
> Sasi
>
> On Wed, Oct 7, 2015 at 1:46 AM, Michael Hannon <jmhannon.ucdavis at gmail.com>
> wrote:
>>
>> I don't think kernel compatibility is a significant issue for most
>> applications.  I can say for certain that I update the kernels on my
>> linux boxes without having to reinstall R.
>>
>> There *are* R packages for RHEL and friends.  Have a look at:
>>
>> https://cran.r-project.org/bin/linux/redhat/README
>>
>> Note that there's a bit of fiddling required, but I don't think it's
>> particularly complicated.
>>
>> It's usually not particularly difficult to install R from source.  If
>> you prefer to do that, have a look at:
>>
>> https://cran.r-project.org/doc/manuals/r-release/R-admin.html
>>
>> Also, you don't specify your requirements, but don't overlook the
>> possibility of installing a virtual machine on your RHEL server.
>> (It's somewhat easier to get an R package for Fedora or Ubuntu than
>> for RHEL, for instance.)
>>
>> I don't know the answer to your question about embedded systems.  I
>> would think R would not be a great choice for an embedded system, but
>> I don't know what your requirements are.
>>
>> -- Mike
>>
>>
>> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com>
>> wrote:
>> > Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
>> > Linux Server release 6.2".
>> >
>> > Also, couple of clarifications,
>> >
>> > 1. Do we have a R package compatibility matrix against the Linux kernel
>> > version? Or for the Red Hat Linux with kernel version 2.6.32-279, do you
>> > have any suggestion/recommendation on R package to be used?
>> >
>> > 2. If we need to use Rscripts in embedded systems such as routers and
>> > switches, do we need to install the complete R package in the  system
>> > also?
>> > Or just libR.so and Rscript should be ok?
>> >
>> > Thanks again Mike.
>> >
>> > Regards
>> > Sasi
>> >
>> > On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon
>> > <jmhannon.ucdavis at gmail.com>
>> > wrote:
>> >>
>> >> It's very likely that there is already an R package for your linux
>> >> system, and, if so, you'd probably be well-served to use that one.
>> >> You've given us the version of the kernel you're using (not a recent
>> >> one, BTW), but what linux distribution are you using?
>> >>
>> >> -- Mike
>> >>
>> >>
>> >> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy
>> >> <ckmsasi at gmail.com>
>> >> wrote:
>> >> > Hi,
>> >> >
>> >> > I have downloaded the pre-compiled version of R package:
>> >> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package under my
>> >> > tmp
>> >> > directory (/tmp). The directories "et"c and "usr" got created with
>> >> > binaries
>> >> > R and Rscript under /tmp/usr/bin/.
>> >> >
>> >> > Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt)
>> >> > reports
>> >> > the below error,
>> >> >
>> >> > ./usr/bin/R
>> >> >                                              ./usr/bin/R: line 238:
>> >> > /usr/lib/R/etc/ldpaths: No such file or directory
>> >> > ERROR: R_HOME ('/usr/lib/R') not found
>> >> >
>> >> > How to reconfigure the R environment variables? Because, i tried
>> >> > setting
>> >> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
>> >> >
>> >> > The Linux version i am using is  2.6.32. Please help me with the
>> >> > steps
>> >> > to
>> >> > install the R correctly. Thanks.
>> >> >
>> >> > Regards
>> >> > Sasi
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From paumarc at gmail.com  Thu Oct  8 01:10:47 2015
From: paumarc at gmail.com (=?UTF-8?Q?Pau_Marc_Mu=C3=B1oz_Torres?=)
Date: Thu, 8 Oct 2015 01:10:47 +0200
Subject: [R] problem with dataframes
Message-ID: <CADFuJLiEY5qR0E6UYizcPM3dgzLL-iqOE+0nv1u_xdrsr+Ecng@mail.gmail.com>

Hello everybody,

 I am using the library rapidr of bioconductor, I am running it without
problems as follows;

library("RAPIDR")
makeBinnedCountsFile("SRR611842_2.bam","SRR611842_2.bam.bai","binnecounts.r",mask=NULL,k=20000)
> SampleID=c("SRR611842_2")
> DX=c("T21")
> Gender=c("Male")
> frame= data.frame(SampleID, DX, Gender)

No problems until here , but when i do

> createReferenceSetFromCounts("binnecounts.r",frame)
Loading binned counts file
Checking every sampleID has an outcome
No outcomes for Sample SRR611842_2.bam.bai
*Error in `[.data.frame`(sampleIDs.with.outcomes, , "Gender") :*
*  undefined columns selected*


I do not understand this error, it seems as if the column DX is not read by
the function and I do not know why. I have tried both spellings Dx and DX
with the same result.

I also cheked for the DX columns  doing

> frame
     SampleID  DX Gender
1 SRR611842_2 T21   Male
> frame$DX
[1] T21
Levels: T21
> names(frame)
[1] "SampleID" "DX"       "Gender"


 Can anyone suggest me what to do?


Pau Marc Mu?oz Torres
skype: pau_marc
http://www.linkedin.com/in/paumarc
http://www.researchgate.net/profile/Pau_Marc_Torres3/info/

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Oct  8 01:11:26 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 7 Oct 2015 16:11:26 -0700
Subject: [R] Error with Segmented package
In-Reply-To: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>
References: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>
Message-ID: <7F3DAEAD-077F-44EE-99D7-E9B8D1AE99A7@comcast.net>


On Oct 7, 2015, at 6:50 AM, andrew haywood wrote:

> Dear List,
> 
> I am trying to run a simple pieewise regression using the segmented package.
> 
> When running the following code
> 
> library(segmented)
> data = data.frame(x=c(50,60,70,80,90,100,110) , y=
> c(703.786,705.857,708.153,711.056,709.257, 707.4, 705.6))
> 
> model.lm = segmented(lm(y~x,data = data),seg.Z = ~x, psi = NA, control =
> seg.control(K=1))
> 
> I get the following error.
> 
> Error in if (psi == Inf) psi <- median(XREGseg) :
>  missing value where TRUE/FALSE needed

I don't get any error, despite being a bit behind the times. You need to specify the versions (OS, R, segmented) and prepare for some debugging efforts. Easiest way to do this is with the output of sessionInfo(). 

R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin10.8.0 (64-bit)

I also have an embarrassing number of packages loaded.

other attached packages:
 [1] segmented_0.5-1.1   boot_1.3-17         sqldf_0.4-10      
 
(remaining 48 are omitted)


> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Thu Oct  8 02:04:18 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 7 Oct 2015 17:04:18 -0700
Subject: [R] additive proportional odds model in R
In-Reply-To: <1444214003583-4713259.post@n4.nabble.com>
References: <1444214003583-4713259.post@n4.nabble.com>
Message-ID: <FE52D669-6CE4-4DFC-A26D-16668B6BEF62@comcast.net>


On Oct 7, 2015, at 3:33 AM, Neverstop wrote:

> Hi all!
> I'm looking for a way to fit an additive proportional odds model in R since
> I need to analyse ordinal data. 
> The polr() function of the MASS package of R allows only to fit a linear
> proportional odds model so I can't use it. 

Can you explain the additional requirements you understand for your request. The polr function is additive on the log-odds scale.

> The gam() function of the gam package of R allows to fit additive models and
> generalized additive models. This package uses smoothing splines and loess
> as smoothers. I've read the documentation and it doesn't seem to be possible
> to fit an additive proportional odds model in R.      

Are you looking for an identity link with binomial errors? 

> Do you know which function should I use?

I doubt that it would allow a identity link, but the `lrm` function in `pkg:rms` is also used for ordinal proportional odds models. It supports several spline representations of functional form.


> Thank you in advance.
> --
> View this message in context: http://r.789695.n4.nabble.com/additive-proportional-odds-model-in-R-tp4713259.html
> Sent from the R help mailing list archive at Nabble.com.

I think you should understand that Nabble postings to R-help will soon not be allowed.

> ______   So you _should_ read    ________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From dulcalma at bigpond.com  Thu Oct  8 02:12:41 2015
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 8 Oct 2015 10:12:41 +1000
Subject: [R] [lattice::xyplot] Using (panel:.)abline with
	panel.superpose?
References: <00fbfd48499c4824b3e7fd5792509e38@CO2PR26MB0011.067d.mgd.msft.net>
Message-ID: <000401d1015e$0c7dce20$25796a60$@bigpond.com>

Forgot to send to list

-----Original Message-----
From: Duncan Mackay [mailto:dulcalma at bigpond.com] 
Sent: Thursday, 8 October 2015 08:44
To: 'Szumiloski, John'
Subject: RE: [R] [lattice::xyplot] Using (panel:.)abline with
panel.superpose?

Hi John

I only got grid lines on your # code 2 with same lattice version on win 7
and blank for the first code

Try

xyplot(Y~X|Trt, data=dat,
       groups=Sbj,
       type='b',
       lty=1,
       cex=2,
       lwd=3,
       scales=list(x=list(at=xgrid), y=list(at=ygrid)),
       col=c('red', 'blue'),
       pch=c(16,17),
       panel= panel.superpose,
       panel.groups = function(x,y, ...){

                        panel.abline(h=ygrid, v=xgrid, col = gray(0.9) )

                        panel.xyplot(x,y, ...)

                      }# panel
) # xyplot

It produces grid lines over the lines and points so one way around it is to
use alpha settings.
Not all devices will accept alpha.

xyplot(Y~X|Trt, data=dat,
       groups=Sbj,
       type='b',
       lty=1,
       cex=2,
       lwd=3,
       alpha = 1,
       scales=list(x=list(at=xgrid), y=list(at=ygrid)),
       col=c('red', 'blue'),
       pch=c(16,17),
       panel= panel.superpose,
       panel.groups = function(x,y,alpha, ...){

                        panel.abline(h=ygrid, v=xgrid, col=1, alpha = 0.1)
                        
                        panel.xyplot(x,y, alpha = 1, ...)
       
                      }# panel
) # xyplot

If you use par.settings it will give correct colours lines etc to auto key

xyplot(Y~X|Trt, data=dat,
       groups=Sbj,
       type='b',
       par.settings = list(strip.background = list(col = "transparent"),
                           superpose.line = list(col = c('red', 'blue'),
                                                 alpha = 1,
                                                 lty=1,lwd=3),
                           superpose.symbol = list(col=c('red', 'blue'),
                                                   alpha = 1,
                                                   pch=c(16,17),
                                                   cex=2)),
       scales=list(x=list(at=xgrid), y=list(at=ygrid)),
     auto.key = T,
       panel= panel.superpose,
       panel.groups = function(x,y,alpha, ...){

                        panel.abline(h=ygrid, v = xgrid, col=1, alpha = 0.1)

                        panel.xyplot(x,y, alpha = 1, ...)

                      }# panel
) # xyplot

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Szumiloski,
John
Sent: Thursday, 8 October 2015 03:40
To: r-help at r-project.org
Subject: [R] [lattice::xyplot] Using (panel:.)abline with panel.superpose?

Dear useRs,

I recently had a query concerning how to customize the graphics parameters
in lattice::xyplot to change not only the color but also the pch symbols,
lty and lwd line parameters, etc., within each grouping variable in the
plot.  (https://stat.ethz.ch/pipermail/r-help/2015-July/430285.html).  Many
thanks to Mark Leeds who described the solution using panel.superpose as the
panel function and defining a custom panel.groups function using the
subscripts argument.

Here is a crude example.  Note how the pch parameter varies with grouping
variable as well as color.  I have commented out two lines which are not
important for the example but are for my main question.

#### begin code 1

# R version 3.2.2 release, lattice version 0.20-33, Windows 7.

    dat <- data.frame(Trt=rep(c('1','2'), each=10),
                      Sbj=rep(c('1','2'), each=5),
                      X=rep(c(0,1,2,3,4), times=4),
                      Y=c(1,3,3,3,1, 2,4,4,4,2,
                          3,1,1,1,3, 4,2,2,2,4)
                     )

    xgrid <- seq(0L, 4L)
    ygrid <- seq(0L, 5L)

    require(lattice)
    xyplot(Y ~ X | Trt, data=dat, groups=Sbj, type='b', lty=1, cex=2, lwd=3,
           scales=list(x=list(at=xgrid), y=list(at=ygrid)),
           ### abline=list(h=ygrid, v=xgrid, col=gray(0.8)),
           mycol=c('red', 'blue'), mypch=c(16,17),
           panel=panel.superpose,
           panel.groups=function(x, y, subscripts,
                                  mycol, mypch, col.line, col.symbol, pch,
...) {
                                 ### panel.abline(h=ygrid, v=xgrid,
col=gray(0.8))
                                 panel.xyplot(x, y, ...,
                                                     pch =
mypch[dat[['Sbj']][subscripts]],
                                              col.symbol =
mycol[dat[['Sbj']][subscripts]],
                                                col.line =
mycol[dat[['Sbj']][subscripts]]
                                             )
                                } # function
          ) # xyplot

### end code 1

My question involves the commented out lines.  I would like to draw a light
grid in the panels.  If I used panel.grid() it would be impossible to get
the gridlines into arbitrary positions, as it seems to pick values similar
to pretty() (I would love to be corrected on this).  So we can use an abline
argument to the main xyplot call, or a panel.abline() call in the
panel.groups function.

But either way leads to a problem.  The ablines seem to be rerendered for
each level of the grouping variable, thus only the final level is plotted
without being the grid rendered on top of it.  Try it by uncommenting either
line.

This is not totally surprising as it does mention somewhere in the
documentation that panel.groups() is called for each value of the grouping
variable.  So my question: How do I render the grid just once, before
actually rendering the data, so as to avoid this problem?

I realized a good place to start might be to include panel.abline in the
panel function itself, rather in the panel.groups function called several
times per panel.  Thus something like this:

### begin code 2

    xyplot(Y~X|Trt, data=dat, groups=Sbj, type='b', lty=1, cex=2, lwd=3,
           scales=list(x=list(at=xgrid), y=list(at=ygrid)),
           mycol=c('red', 'blue'), mypch=c(16,17),
           panel=function(x, y, ...) {   ##########  <---------------- new
panel function
                          panel.abline(h=ygrid, v=xgrid, col=gray(0.9))
                          panel.superpose(x, y, ...)
                         },
           panel.groups=function(x, y, subscripts,
                                  mycol, mypch, col.line, col.symbol, pch,
...) {
                                 panel.xyplot(x, y, ...,
                                                     pch =
mypch[dat[['Sbj']][subscripts]],
                                              col.symbol =
mycol[dat[['Sbj']][subscripts]],
                                                col.line =
mycol[dat[['Sbj']][subscripts]]
                                             )
                                } # function
          ) # xyplot

### end code 2

Of course this won't work as written, I need to replace the ... arguments
with the right ones.  Here is where I am having trouble.  I have tried all
kinds of permutations of the mycol etc., xgrid etc., subscripts etc., and
never got the plot to render the ablines once, then the data correctly.

Any assistance greatly appreciated.
John
John Szumiloski, Ph.D.
Principal Scientist, Statistician
Analytical and Bioanalytical Development
NBR105-1-1411

Bristol-Myers Squibb
P.O. Box 191
1 Squibb Drive
New Brunswick, NJ
08903-0191
USA

(732) 227-7167



________________________________
 This message (including any attachments) may contain co...{{dropped:8}}


From dwinsemius at comcast.net  Thu Oct  8 04:33:49 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 7 Oct 2015 19:33:49 -0700
Subject: [R] Error with Segmented package
In-Reply-To: <CAEDDhTCx8y_0QKZ5bi7dLo0N48YrTdk_mQU3j+gXBOvG5q=s_Q@mail.gmail.com>
References: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>
	<7F3DAEAD-077F-44EE-99D7-E9B8D1AE99A7@comcast.net>
	<CAEDDhTCx8y_0QKZ5bi7dLo0N48YrTdk_mQU3j+gXBOvG5q=s_Q@mail.gmail.com>
Message-ID: <E236D07A-A9F8-439B-AB5C-202653B8F8A6@comcast.net>


On Oct 7, 2015, at 6:10 PM, andrew haywood wrote:

> Thanks David, 
> 
> I apologies for not posting the versions.
> 
> I am running
> 
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252 
> [2] LC_CTYPE=English_United Kingdom.1252   
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C                           
> [5] LC_TIME=English_United Kingdom.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
> 
> other attached packages:
> [1] segmented_0.5-1.2
> 
> And I still get the error. What is the best way to debug the error?

The first thing I do is run traceback() immediately after the error. If that fails to illuminate the problem, my next step is falling back to:

options(error="browser") 
# which should allow you to examine the system-state at the time of the error.

And at that point I start considering sending an email to the maintainer with my reproducible example, especially so since it fails with a more recent version. It may be that the maintainer has the same OS as you have.

-- 
David.
> 
> Kind regards teht
> Andrew
> 
> 
> On Thu, Oct 8, 2015 at 7:11 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Oct 7, 2015, at 6:50 AM, andrew haywood wrote:
> 
> > Dear List,
> >
> > I am trying to run a simple pieewise regression using the segmented package.
> >
> > When running the following code
> >
> > library(segmented)
> > data = data.frame(x=c(50,60,70,80,90,100,110) , y=
> > c(703.786,705.857,708.153,711.056,709.257, 707.4, 705.6))
> >
> > model.lm = segmented(lm(y~x,data = data),seg.Z = ~x, psi = NA, control =
> > seg.control(K=1))
> >
> > I get the following error.
> >
> > Error in if (psi == Inf) psi <- median(XREGseg) :
> >  missing value where TRUE/FALSE needed
> 
> I don't get any error, despite being a bit behind the times. You need to specify the versions (OS, R, segmented) and prepare for some debugging efforts. Easiest way to do this is with the output of sessionInfo().
> 
> R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
> Copyright (C) 2015 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
> 
> I also have an embarrassing number of packages loaded.
> 
> other attached packages:
>  [1] segmented_0.5-1.1   boot_1.3-17         sqldf_0.4-10
> 
> (remaining 48 are omitted)
> 
> 
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From zodjones at gmail.com  Wed Oct  7 23:23:42 2015
From: zodjones at gmail.com (zod jones)
Date: Wed, 7 Oct 2015 16:23:42 -0500
Subject: [R] Time Series Daily Frequency Part of a Year
Message-ID: <CAEPzg1Qkf3D_ETa9w2us5TUw7FYH0x63YZqAwB+FTrVVS286bg@mail.gmail.com>

My data consist of daily sales figures for multiple products but only for a
3 month period each year (Oct., Nov., Dec). The goal is to forecast the
daily sales figures for the following year *by day* (the following Oct.,
Nov., Dec.) So, I'd like to forecast what sales for product X will be on
Nov. 12th of the next year (and each day of those three months), for
example.

I am just conceptually stuck on the fact that the time series is "yearly"
in one sense but the daily observations only occur for those 3 months. The
rest of the year is not really 0 -- the products are not even for sale the
rest of the year (these are tickets for events). The frequency seems like
it should be 92 days.

Hoping someone can just point me in the right direction conceptually.

Thanks,

Zodran

	[[alternative HTML version deleted]]


From ckmsasi at gmail.com  Thu Oct  8 00:45:45 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Wed, 7 Oct 2015 15:45:45 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
Message-ID: <CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>

Thanks Mike. From source, i am able to compile and use R in my red hat
linux box. I was trying to get hands on using R in linux box before trying
R on the embedded box.

My requirement is to run R (R scripts) on my embedded box which has
customized debian linux (kernel version 2.6.32) in batch mode without GUI
support. The embedded box have multi-core MIPS processor with nearly 30GB
RAM. I hope hardware resources on the embedded box shouldn't be an issue to
run R (correct me if i am wrong), but linux version running here is an
customized one with limited supporting services such as light weight shell
etc.

Given this, do i need to cross compile R package for my embedded box or i
can directly install the debian MIPS version of R package. But there is no
apt-get or other installer in the embedded box.


Regards
Sasi

On Wed, Oct 7, 2015 at 1:46 AM, Michael Hannon <jmhannon.ucdavis at gmail.com>
wrote:

> I don't think kernel compatibility is a significant issue for most
> applications.  I can say for certain that I update the kernels on my
> linux boxes without having to reinstall R.
>
> There *are* R packages for RHEL and friends.  Have a look at:
>
> https://cran.r-project.org/bin/linux/redhat/README
>
> Note that there's a bit of fiddling required, but I don't think it's
> particularly complicated.
>
> It's usually not particularly difficult to install R from source.  If
> you prefer to do that, have a look at:
>
> https://cran.r-project.org/doc/manuals/r-release/R-admin.html
>
> Also, you don't specify your requirements, but don't overlook the
> possibility of installing a virtual machine on your RHEL server.
> (It's somewhat easier to get an R package for Fedora or Ubuntu than
> for RHEL, for instance.)
>
> I don't know the answer to your question about embedded systems.  I
> would think R would not be a great choice for an embedded system, but
> I don't know what your requirements are.
>
> -- Mike
>
>
> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com>
> wrote:
> > Thanks a lot Mike. The Linux distribution we use is "Red Hat Enterprise
> > Linux Server release 6.2".
> >
> > Also, couple of clarifications,
> >
> > 1. Do we have a R package compatibility matrix against the Linux kernel
> > version? Or for the Red Hat Linux with kernel version 2.6.32-279, do you
> > have any suggestion/recommendation on R package to be used?
> >
> > 2. If we need to use Rscripts in embedded systems such as routers and
> > switches, do we need to install the complete R package in the  system
> also?
> > Or just libR.so and Rscript should be ok?
> >
> > Thanks again Mike.
> >
> > Regards
> > Sasi
> >
> > On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon <
> jmhannon.ucdavis at gmail.com>
> > wrote:
> >>
> >> It's very likely that there is already an R package for your linux
> >> system, and, if so, you'd probably be well-served to use that one.
> >> You've given us the version of the kernel you're using (not a recent
> >> one, BTW), but what linux distribution are you using?
> >>
> >> -- Mike
> >>
> >>
> >> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com
> >
> >> wrote:
> >> > Hi,
> >> >
> >> > I have downloaded the pre-compiled version of R package:
> >> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package under my
> >> > tmp
> >> > directory (/tmp). The directories "et"c and "usr" got created with
> >> > binaries
> >> > R and Rscript under /tmp/usr/bin/.
> >> >
> >> > Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt)
> >> > reports
> >> > the below error,
> >> >
> >> > ./usr/bin/R
> >> >                                              ./usr/bin/R: line 238:
> >> > /usr/lib/R/etc/ldpaths: No such file or directory
> >> > ERROR: R_HOME ('/usr/lib/R') not found
> >> >
> >> > How to reconfigure the R environment variables? Because, i tried
> setting
> >> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
> >> >
> >> > The Linux version i am using is  2.6.32. Please help me with the steps
> >> > to
> >> > install the R correctly. Thanks.
> >> >
> >> > Regards
> >> > Sasi
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From ckmsasi at gmail.com  Thu Oct  8 02:18:29 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Wed, 7 Oct 2015 17:18:29 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CACdH2ZaBG5RtNKQTvMg4RPdW9PyCVhVJqij81f2B+dV=Ogd-Ag@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
	<CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>
	<CACdH2ZaBG5RtNKQTvMg4RPdW9PyCVhVJqij81f2B+dV=Ogd-Ag@mail.gmail.com>
Message-ID: <CABbvK+HLLZaL+ZH_o49acOwi8rME6KiLBF7=Ejhmqs7J_hQCAA@mail.gmail.com>

Thanks a lot Mike & others for the valuable input. I was wrong on debian
linux on the embedded box, it is monta vista embedded linux.

I hope, there is no R core package available for monta vista distribution
and i may need to cross compile from R source. Please correct me if i am
wrong.

Thanks & Regards
Sasi

On Wed, Oct 7, 2015 at 4:02 PM, Michael Hannon <jmhannon.ucdavis at gmail.com>
wrote:

> Hi, Sasi.  Yes, I think that getting familiar with R in a "friendly"
> context before dealing with your embedded system is a good idea.  Note
> that the non-GUI part of R is more or less identical across platforms.
> Hence, you could experiment with it on a Macbook, a Surface tablet,
> etc., etc., if you're just seeking to get established in R.
>
> The hardware configuration of your embedded system seems reasonable,
> but again, I don't know what your run-time requirements will be.  Note
> in particular that R likes to have objects resident in memory, so if
> you're trying to process a 40GB data file on your embedded system,
> you're probably out of luck.
>
> I would certainly start by trying to install the Debian package for R.
> Even if you don't have apt-get, I would think you'd at least have the
> "dpkg" utility:
>
> https://www.debian.org/doc/manuals/debian-faq/ch-pkgtools.en.html
>
> If so, you could use that to install R (provided you have managed to
> download the appropriate <*.deb> package for R).
>
>
>
> On Wed, Oct 7, 2015 at 3:45 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com>
> wrote:
> > Thanks Mike. From source, i am able to compile and use R in my red hat
> linux
> > box. I was trying to get hands on using R in linux box before trying R on
> > the embedded box.
> >
> > My requirement is to run R (R scripts) on my embedded box which has
> > customized debian linux (kernel version 2.6.32) in batch mode without GUI
> > support. The embedded box have multi-core MIPS processor with nearly 30GB
> > RAM. I hope hardware resources on the embedded box shouldn't be an issue
> to
> > run R (correct me if i am wrong), but linux version running here is an
> > customized one with limited supporting services such as light weight
> shell
> > etc.
> >
> > Given this, do i need to cross compile R package for my embedded box or i
> > can directly install the debian MIPS version of R package. But there is
> no
> > apt-get or other installer in the embedded box.
> >
> >
> > Regards
> > Sasi
> >
> > On Wed, Oct 7, 2015 at 1:46 AM, Michael Hannon <
> jmhannon.ucdavis at gmail.com>
> > wrote:
> >>
> >> I don't think kernel compatibility is a significant issue for most
> >> applications.  I can say for certain that I update the kernels on my
> >> linux boxes without having to reinstall R.
> >>
> >> There *are* R packages for RHEL and friends.  Have a look at:
> >>
> >> https://cran.r-project.org/bin/linux/redhat/README
> >>
> >> Note that there's a bit of fiddling required, but I don't think it's
> >> particularly complicated.
> >>
> >> It's usually not particularly difficult to install R from source.  If
> >> you prefer to do that, have a look at:
> >>
> >> https://cran.r-project.org/doc/manuals/r-release/R-admin.html
> >>
> >> Also, you don't specify your requirements, but don't overlook the
> >> possibility of installing a virtual machine on your RHEL server.
> >> (It's somewhat easier to get an R package for Fedora or Ubuntu than
> >> for RHEL, for instance.)
> >>
> >> I don't know the answer to your question about embedded systems.  I
> >> would think R would not be a great choice for an embedded system, but
> >> I don't know what your requirements are.
> >>
> >> -- Mike
> >>
> >>
> >> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy <ckmsasi at gmail.com
> >
> >> wrote:
> >> > Thanks a lot Mike. The Linux distribution we use is "Red Hat
> Enterprise
> >> > Linux Server release 6.2".
> >> >
> >> > Also, couple of clarifications,
> >> >
> >> > 1. Do we have a R package compatibility matrix against the Linux
> kernel
> >> > version? Or for the Red Hat Linux with kernel version 2.6.32-279, do
> you
> >> > have any suggestion/recommendation on R package to be used?
> >> >
> >> > 2. If we need to use Rscripts in embedded systems such as routers and
> >> > switches, do we need to install the complete R package in the  system
> >> > also?
> >> > Or just libR.so and Rscript should be ok?
> >> >
> >> > Thanks again Mike.
> >> >
> >> > Regards
> >> > Sasi
> >> >
> >> > On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon
> >> > <jmhannon.ucdavis at gmail.com>
> >> > wrote:
> >> >>
> >> >> It's very likely that there is already an R package for your linux
> >> >> system, and, if so, you'd probably be well-served to use that one.
> >> >> You've given us the version of the kernel you're using (not a recent
> >> >> one, BTW), but what linux distribution are you using?
> >> >>
> >> >> -- Mike
> >> >>
> >> >>
> >> >> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy
> >> >> <ckmsasi at gmail.com>
> >> >> wrote:
> >> >> > Hi,
> >> >> >
> >> >> > I have downloaded the pre-compiled version of R package:
> >> >> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package under
> my
> >> >> > tmp
> >> >> > directory (/tmp). The directories "et"c and "usr" got created with
> >> >> > binaries
> >> >> > R and Rscript under /tmp/usr/bin/.
> >> >> >
> >> >> > Executing the R (/tmp/usr/bin/R) or Rscript (/tmp/usr/bin/Rscipt)
> >> >> > reports
> >> >> > the below error,
> >> >> >
> >> >> > ./usr/bin/R
> >> >> >                                              ./usr/bin/R: line 238:
> >> >> > /usr/lib/R/etc/ldpaths: No such file or directory
> >> >> > ERROR: R_HOME ('/usr/lib/R') not found
> >> >> >
> >> >> > How to reconfigure the R environment variables? Because, i tried
> >> >> > setting
> >> >> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
> >> >> >
> >> >> > The Linux version i am using is  2.6.32. Please help me with the
> >> >> > steps
> >> >> > to
> >> >> > install the R correctly. Thanks.
> >> >> >
> >> >> > Regards
> >> >> > Sasi
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From ahaywood3 at gmail.com  Thu Oct  8 03:10:22 2015
From: ahaywood3 at gmail.com (andrew haywood)
Date: Thu, 8 Oct 2015 09:10:22 +0800
Subject: [R] Error with Segmented package
In-Reply-To: <7F3DAEAD-077F-44EE-99D7-E9B8D1AE99A7@comcast.net>
References: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>
	<7F3DAEAD-077F-44EE-99D7-E9B8D1AE99A7@comcast.net>
Message-ID: <CAEDDhTCx8y_0QKZ5bi7dLo0N48YrTdk_mQU3j+gXBOvG5q=s_Q@mail.gmail.com>

Thanks David,

I apologies for not posting the versions.

I am running

R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] segmented_0.5-1.2

And I still get the error. What is the best way to debug the error?

Kind regards
Andrew


On Thu, Oct 8, 2015 at 7:11 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Oct 7, 2015, at 6:50 AM, andrew haywood wrote:
>
> > Dear List,
> >
> > I am trying to run a simple pieewise regression using the segmented
> package.
> >
> > When running the following code
> >
> > library(segmented)
> > data = data.frame(x=c(50,60,70,80,90,100,110) , y=
> > c(703.786,705.857,708.153,711.056,709.257, 707.4, 705.6))
> >
> > model.lm = segmented(lm(y~x,data = data),seg.Z = ~x, psi = NA, control =
> > seg.control(K=1))
> >
> > I get the following error.
> >
> > Error in if (psi == Inf) psi <- median(XREGseg) :
> >  missing value where TRUE/FALSE needed
>
> I don't get any error, despite being a bit behind the times. You need to
> specify the versions (OS, R, segmented) and prepare for some debugging
> efforts. Easiest way to do this is with the output of sessionInfo().
>
> R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
> Copyright (C) 2015 The R Foundation for Statistical Computing
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> I also have an embarrassing number of packages loaded.
>
> other attached packages:
>  [1] segmented_0.5-1.1   boot_1.3-17         sqldf_0.4-10
>
> (remaining 48 are omitted)
>
>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From clfiore at gmail.com  Thu Oct  8 05:19:44 2015
From: clfiore at gmail.com (Cara Fiore)
Date: Wed, 7 Oct 2015 23:19:44 -0400
Subject: [R] duplicate rows with rbind in a loop
Message-ID: <CAEjKTpYs55rDHVS_Erxe6oiobUbrmig6fKiJWw2=V_BSb61rgQ@mail.gmail.com>

Dear R users,

I wrote a simple script to change the header lines in a fasta file that
contains DNA sequences in a format:

>header1
sequence1
>header2
sequence2

I am basically trying to replace the "header" in this file with a line from
another file (taxonomy file). In order to do that I have to find the
matching header in the taxonomy file.

The output should be in fasta format and it is, but the rows repeat so the
output file is huge and it looks like:

>header1
sequence1
>header1
sequence1
>header2
sequence2

The code I have is:

tax=read.table("taxonomy_file.txt", header=F, quote="", sep="\t")
tax2=data.frame(tax)

library("Biostrings")
seqs=readDNAStringSet("File.fasta")
header=names(seqs)
seqs2=paste(seqs)

new.final=NULL
i=1

#Go through tax file and match the header in tax file to header in seqs file
for(i in 1:length(tax[,1])){
  sampleID=NULL
  match=NULL
  sampleID=as.character(tax2[i,1])  #sample ID in taxonomy header
  match=which(sampleID==header) #index for match in header file
  if(match>0){
    newH1=NULL
    newH2=NULL
    seqline=NULL
    new.header=NULL
    newH1=as.character(tax2[i,1])
    newH2=as.character(tax2[i,2])
    seqline=seqs2[match]
    new.header=paste(">",newH1,"|",newH2, sep="")
    new.final=rbind(new.final, new.header, seqline)
  }
  print(paste("percent complete =", round((i/length(tax2[,1]))*100,3),
"%",sep=" "))
  write.table(new.final, file="Test_output.txt", quote=FALSE, sep="\n",
col.names=FALSE, row.names=FALSE, append=TRUE)
  i=i+1
}


Something about rbind is repeating all of the rows every time it writes to
the output file. I have not been able to find anything about this online or
in the r help for rbind, although perhaps I am missing something obvious
about this.

I greatly appreciate any help with this!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Oct  8 09:11:44 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 08 Oct 2015 00:11:44 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
	<CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>
Message-ID: <A98AEE9F-B6BD-4F79-B20F-3B65DDAFC569@dcn.davis.CA.us>

There is a manual for compiling and installing R. There is also a mailing list (described in the Posting Guide) called R-devel where topics like compiling R are actually on topic, unlike here. If you have to cross-compile then you probably have a bit more work ahead of you than most users would have, so be prepared to roll up your sleeves and get familiar with the innards of R so you can decide exactly which features you need. I have not heard of anyone rolling R into an embedded system, but this list would not be the place to hear about it so that probably doesn't mean much.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 7, 2015 3:45:45 PM PDT, Sasikumar Kandhasamy <ckmsasi at gmail.com> wrote:
>Thanks Mike. From source, i am able to compile and use R in my red hat
>linux box. I was trying to get hands on using R in linux box before
>trying
>R on the embedded box.
>
>My requirement is to run R (R scripts) on my embedded box which has
>customized debian linux (kernel version 2.6.32) in batch mode without
>GUI
>support. The embedded box have multi-core MIPS processor with nearly
>30GB
>RAM. I hope hardware resources on the embedded box shouldn't be an
>issue to
>run R (correct me if i am wrong), but linux version running here is an
>customized one with limited supporting services such as light weight
>shell
>etc.
>
>Given this, do i need to cross compile R package for my embedded box or
>i
>can directly install the debian MIPS version of R package. But there is
>no
>apt-get or other installer in the embedded box.
>
>
>Regards
>Sasi
>
>On Wed, Oct 7, 2015 at 1:46 AM, Michael Hannon
><jmhannon.ucdavis at gmail.com>
>wrote:
>
>> I don't think kernel compatibility is a significant issue for most
>> applications.  I can say for certain that I update the kernels on my
>> linux boxes without having to reinstall R.
>>
>> There *are* R packages for RHEL and friends.  Have a look at:
>>
>> https://cran.r-project.org/bin/linux/redhat/README
>>
>> Note that there's a bit of fiddling required, but I don't think it's
>> particularly complicated.
>>
>> It's usually not particularly difficult to install R from source.  If
>> you prefer to do that, have a look at:
>>
>> https://cran.r-project.org/doc/manuals/r-release/R-admin.html
>>
>> Also, you don't specify your requirements, but don't overlook the
>> possibility of installing a virtual machine on your RHEL server.
>> (It's somewhat easier to get an R package for Fedora or Ubuntu than
>> for RHEL, for instance.)
>>
>> I don't know the answer to your question about embedded systems.  I
>> would think R would not be a great choice for an embedded system, but
>> I don't know what your requirements are.
>>
>> -- Mike
>>
>>
>> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy
><ckmsasi at gmail.com>
>> wrote:
>> > Thanks a lot Mike. The Linux distribution we use is "Red Hat
>Enterprise
>> > Linux Server release 6.2".
>> >
>> > Also, couple of clarifications,
>> >
>> > 1. Do we have a R package compatibility matrix against the Linux
>kernel
>> > version? Or for the Red Hat Linux with kernel version 2.6.32-279,
>do you
>> > have any suggestion/recommendation on R package to be used?
>> >
>> > 2. If we need to use Rscripts in embedded systems such as routers
>and
>> > switches, do we need to install the complete R package in the 
>system
>> also?
>> > Or just libR.so and Rscript should be ok?
>> >
>> > Thanks again Mike.
>> >
>> > Regards
>> > Sasi
>> >
>> > On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon <
>> jmhannon.ucdavis at gmail.com>
>> > wrote:
>> >>
>> >> It's very likely that there is already an R package for your linux
>> >> system, and, if so, you'd probably be well-served to use that one.
>> >> You've given us the version of the kernel you're using (not a
>recent
>> >> one, BTW), but what linux distribution are you using?
>> >>
>> >> -- Mike
>> >>
>> >>
>> >> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy
><ckmsasi at gmail.com
>> >
>> >> wrote:
>> >> > Hi,
>> >> >
>> >> > I have downloaded the pre-compiled version of R package:
>> >> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package
>under my
>> >> > tmp
>> >> > directory (/tmp). The directories "et"c and "usr" got created
>with
>> >> > binaries
>> >> > R and Rscript under /tmp/usr/bin/.
>> >> >
>> >> > Executing the R (/tmp/usr/bin/R) or Rscript
>(/tmp/usr/bin/Rscipt)
>> >> > reports
>> >> > the below error,
>> >> >
>> >> > ./usr/bin/R
>> >> >                                              ./usr/bin/R: line
>238:
>> >> > /usr/lib/R/etc/ldpaths: No such file or directory
>> >> > ERROR: R_HOME ('/usr/lib/R') not found
>> >> >
>> >> > How to reconfigure the R environment variables? Because, i tried
>> setting
>> >> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
>> >> >
>> >> > The Linux version i am using is  2.6.32. Please help me with the
>steps
>> >> > to
>> >> > install the R correctly. Thanks.
>> >> >
>> >> > Regards
>> >> > Sasi
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >
>> >
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From luca.cerone at gmail.com  Thu Oct  8 11:43:40 2015
From: luca.cerone at gmail.com (Luca Cerone)
Date: Thu, 8 Oct 2015 11:43:40 +0200
Subject: [R] Installing different R versions
In-Reply-To: <CALDESV82515ieKFe5y5HbB5J0MP9CJ3hVzs0Rro+OuYOTQT+wA@mail.gmail.com>
References: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>
	<87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>
	<CALDESV82515ieKFe5y5HbB5J0MP9CJ3hVzs0Rro+OuYOTQT+wA@mail.gmail.com>
Message-ID: <CAFnz2-8dzcYebRbj=PrRf22wVnkrXWmZfga-DdzxDVKmQckGLw@mail.gmail.com>

Dear Loris and Wolfgang,
thanks a lot for the help!

I wasn't aware of the module project. I'd rather use the "official"
way of having co-existent R versions in this case,
but is a good tool to know!

Thanks again for the help!

Cheers,
Luca

On Wed, Oct 7, 2015 at 4:27 PM, Wolfgang Raffelsberger
<wolfgang.raffelsberger at gmail.com> wrote:
> check out the official document
> *R Installation and Administration*
> from https://cran.r-project.org/manuals.html
> There you'll find how to define a specific path for each installation.
>
> (Since a number of years I administrate multiple versions of R at different
> platforms, of course including Linux)
>
> Wolfgang
>
> 2015-10-07 9:04 GMT+02:00 Loris Bennett <loris.bennett at fu-berlin.de>:
>
>> Dear Luca,
>>
>> Luca Cerone <luca.cerone at gmail.com> writes:
>>
>> > Dear all,
>> > on one shared machine we have an older R version installed. Some packages
>> > have known issues with that version that are fixed in newer R versions.
>> >
>> > Since that is a production machine with many jobs running we would like
>> to
>> > keep things as they are. However I would also like to keep advantage of
>> the
>> > newest version and the bug fixes introduced.
>> >
>> > What would be the best way to install a newer version along the one that
>> > already exists? Is it possible to install it for a specific user only?
>> >
>> > Cheers,
>> > Luca
>>
>> If you are on a Unix-like platform, a standard way of dealing with
>> multiple versions of a piece of software installed in parallel is
>> "Environment Modules":
>>
>> http://modules.sourceforge.net/
>>
>> Packages for various Linux distributions are available.
>>
>> You could make a version available for a specific user by setting
>> appropriate file permissions of the module file which is used to set up
>> the environment.  However, I would consider this a somewhat unusual
>> configuration.  If you are worried about people using the wrong version
>> by mistake, you can either have the standard version available without
>> using modules, or you can define a default version within the modules
>> setup.
>>
>> HTH
>>
>> Loris
>>
>> --
>> This signature is currently under construction.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Martin.Morgan at roswellpark.org  Thu Oct  8 11:46:15 2015
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Thu, 8 Oct 2015 09:46:15 +0000
Subject: [R] duplicate rows with rbind in a loop
In-Reply-To: <CAEjKTpYs55rDHVS_Erxe6oiobUbrmig6fKiJWw2=V_BSb61rgQ@mail.gmail.com>
References: <CAEjKTpYs55rDHVS_Erxe6oiobUbrmig6fKiJWw2=V_BSb61rgQ@mail.gmail.com>
Message-ID: <DF23DAC5A53912408040FF04D8B780AADF11B3@EXMB3RSC.roswellpark.org>



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Cara Fiore
> Sent: Wednesday, October 07, 2015 11:20 PM
> To: r-help at r-project.org
> Subject: [R] duplicate rows with rbind in a loop
> 
> Dear R users,
> 
> I wrote a simple script to change the header lines in a fasta file that contains
> DNA sequences in a format:
> 
> >header1
> sequence1
> >header2
> sequence2
> 
> I am basically trying to replace the "header" in this file with a line from
> another file (taxonomy file). In order to do that I have to find the matching
> header in the taxonomy file.
> 
> The output should be in fasta format and it is, but the rows repeat so the
> output file is huge and it looks like:
> 
> >header1
> sequence1
> >header1
> sequence1
> >header2
> sequence2
> 
> The code I have is:
> 
> tax=read.table("taxonomy_file.txt", header=F, quote="", sep="\t")
> tax2=data.frame(tax)
> 
> library("Biostrings")
> seqs=readDNAStringSet("File.fasta")
> header=names(seqs)
> seqs2=paste(seqs)
> 
> new.final=NULL
> i=1
> 
> #Go through tax file and match the header in tax file to header in seqs file
> for(i in 1:length(tax[,1])){

Hi Cara - it is usually better to ask questions about Bioconductor packages on the Bioconductor support site, https://support.bioconductor .org.

For your case, something like

  names(seqs) = tax[match(names(seqs), tax[,1]), 2] 

maps, in a 'vectorized' way, the names of the sequences to the names of the taxon ids, and updates the names in the DNAStringSet. Then

  writeXStringSet(seqs, "output.fasta")

outputs the results as a fasta file. Probably you want read.table(..., stringsAsFactors=FALSE) earlier in your code.

Martin

>   sampleID=NULL
>   match=NULL
>   sampleID=as.character(tax2[i,1])  #sample ID in taxonomy header
>   match=which(sampleID==header) #index for match in header file
>   if(match>0){
>     newH1=NULL
>     newH2=NULL
>     seqline=NULL
>     new.header=NULL
>     newH1=as.character(tax2[i,1])
>     newH2=as.character(tax2[i,2])
>     seqline=seqs2[match]
>     new.header=paste(">",newH1,"|",newH2, sep="")
>     new.final=rbind(new.final, new.header, seqline)
>   }
>   print(paste("percent complete =", round((i/length(tax2[,1]))*100,3),
> "%",sep=" "))
>   write.table(new.final, file="Test_output.txt", quote=FALSE, sep="\n",
> col.names=FALSE, row.names=FALSE, append=TRUE)
>   i=i+1
> }
> 
> 
> Something about rbind is repeating all of the rows every time it writes to the
> output file. I have not been able to find anything about this online or in the r
> help for rbind, although perhaps I am missing something obvious about this.
> 
> I greatly appreciate any help with this!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

From loris.bennett at fu-berlin.de  Thu Oct  8 12:07:20 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 8 Oct 2015 12:07:20 +0200
Subject: [R] Installing different R versions
References: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>
	<87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>
	<CALDESV82515ieKFe5y5HbB5J0MP9CJ3hVzs0Rro+OuYOTQT+wA@mail.gmail.com>
	<CAFnz2-8dzcYebRbj=PrRf22wVnkrXWmZfga-DdzxDVKmQckGLw@mail.gmail.com>
Message-ID: <87h9m1znaf.fsf@hornfels.zedat.fu-berlin.de>

Dear Luca,

Luca Cerone <luca.cerone at gmail.com> writes:

> Dear Loris and Wolfgang,
> thanks a lot for the help!
>
> I wasn't aware of the module project. I'd rather use the "official"
> way of having co-existent R versions in this case,
> but is a good tool to know!

As far as I can tell from a quick look, "R Installation and
Administration", as referred to by Wolfgang, just tells you how to
install different versions in different places by using the
configuration option --prefix (for Linux at least).  This is some thing
you always have to do, if you want to install several versions in
parallel.

However, once you have multiple versions installed, you need a mechanism
to allow users to choose between them.  This is where Environment
Modules come in.  At the simplest level, they just allow environment
variables to be set and unset in an easy and consistent way.

So it is not a question of "using the 'official' way of having
co-existent R versions", but rather of installing various versions and
then enabling people to choose easily between them.

Or have I missed some intrinsic feature of R which will allow me to
switch between installed versions without having to explicitly tweak
environment variables?

Cheers,

Loris

-- 
This signature is currently under construction.


From maechler at stat.math.ethz.ch  Thu Oct  8 13:15:29 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Oct 2015 13:15:29 +0200
Subject: [R] Installing different R versions
In-Reply-To: <87h9m1znaf.fsf@hornfels.zedat.fu-berlin.de>
References: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>
	<87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>
	<CALDESV82515ieKFe5y5HbB5J0MP9CJ3hVzs0Rro+OuYOTQT+wA@mail.gmail.com>
	<CAFnz2-8dzcYebRbj=PrRf22wVnkrXWmZfga-DdzxDVKmQckGLw@mail.gmail.com>
	<87h9m1znaf.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <22038.20561.451457.646333@stat.math.ethz.ch>

>>>>> Loris Bennett <loris.bennett at fu-berlin.de>
>>>>>     on Thu, 8 Oct 2015 12:07:20 +0200 writes:

    > Dear Luca, Luca Cerone <luca.cerone at gmail.com> writes:

    >> Dear Loris and Wolfgang, thanks a lot for the help!
    >> 
    >> I wasn't aware of the module project. I'd rather use the
    >> "official" way of having co-existent R versions in this
    >> case, but is a good tool to know!

    > As far as I can tell from a quick look, "R Installation
    > and Administration", as referred to by Wolfgang, just
    > tells you how to install different versions in different
    > places by using the configuration option --prefix (for
    > Linux at least).  This is some thing you always have to
    > do, if you want to install several versions in parallel.

    > However, once you have multiple versions installed, you
    > need a mechanism to allow users to choose between them.
    > This is where Environment Modules come in.  At the
    > simplest level, they just allow environment variables to
    > be set and unset in an easy and consistent way.

    > So it is not a question of "using the 'official' way of
    > having co-existent R versions", but rather of installing
    > various versions and then enabling people to choose easily
    > between them.

    > Or have I missed some intrinsic feature of R which will
    > allow me to switch between installed versions without
    > having to explicitly tweak environment variables?

Yes, you have missed something.
I have installed many dozen versions of R simultaneously both at
work and on my laptop ... all under Linux.
(Yes, I am extreme - as R Core member wanting to be able to go
 back and see ...)

I don't need any environment variables, but just symbolic links
to define 'R', 'R-devel', 'R-patched', 'R-3.2.2', etc etc. in
our default PATH.
So these work from the shell (or similar), and 
even ESS (Emacs Speaks Statistics) is automagically picking up
all these, so I can use
   M-x R
   M-x R-3.2.2
   M-x R-devel
   etc
   
to have different versions of R running simultaneously "inside" ESS.

Martin

    > Cheers,

    > Loris

    > -- 
    > This signature is currently under construction.
(let's you'll converge ;-)


From loris.bennett at fu-berlin.de  Thu Oct  8 14:21:41 2015
From: loris.bennett at fu-berlin.de (Loris Bennett)
Date: Thu, 8 Oct 2015 14:21:41 +0200
Subject: [R] Installing different R versions
References: <CAFnz2-98+xc=vgSKZyLzHBB07ngXMZTvYnT6ZefMskFR8+=2Ow@mail.gmail.com>
	<87io6jp3ao.fsf@hornfels.zedat.fu-berlin.de>
	<CALDESV82515ieKFe5y5HbB5J0MP9CJ3hVzs0Rro+OuYOTQT+wA@mail.gmail.com>
	<CAFnz2-8dzcYebRbj=PrRf22wVnkrXWmZfga-DdzxDVKmQckGLw@mail.gmail.com>
	<87h9m1znaf.fsf@hornfels.zedat.fu-berlin.de>
	<22038.20561.451457.646333@stat.math.ethz.ch>
Message-ID: <87a8rtzh2i.fsf@hornfels.zedat.fu-berlin.de>

Martin Maechler <maechler at stat.math.ethz.ch> writes:

>>>>>> Loris Bennett <loris.bennett at fu-berlin.de>
>>>>>>     on Thu, 8 Oct 2015 12:07:20 +0200 writes:
>
>     > Dear Luca, Luca Cerone <luca.cerone at gmail.com> writes:
>
>     >> Dear Loris and Wolfgang, thanks a lot for the help!
>     >> 
>     >> I wasn't aware of the module project. I'd rather use the
>     >> "official" way of having co-existent R versions in this
>     >> case, but is a good tool to know!
>
>     > As far as I can tell from a quick look, "R Installation
>     > and Administration", as referred to by Wolfgang, just
>     > tells you how to install different versions in different
>     > places by using the configuration option --prefix (for
>     > Linux at least).  This is some thing you always have to
>     > do, if you want to install several versions in parallel.
>
>     > However, once you have multiple versions installed, you
>     > need a mechanism to allow users to choose between them.
>     > This is where Environment Modules come in.  At the
>     > simplest level, they just allow environment variables to
>     > be set and unset in an easy and consistent way.
>
>     > So it is not a question of "using the 'official' way of
>     > having co-existent R versions", but rather of installing
>     > various versions and then enabling people to choose easily
>     > between them.
>
>     > Or have I missed some intrinsic feature of R which will
>     > allow me to switch between installed versions without
>     > having to explicitly tweak environment variables?
>
> Yes, you have missed something.
> I have installed many dozen versions of R simultaneously both at
> work and on my laptop ... all under Linux.
> (Yes, I am extreme - as R Core member wanting to be able to go
>  back and see ...)
>
> I don't need any environment variables, but just symbolic links
> to define 'R', 'R-devel', 'R-patched', 'R-3.2.2', etc etc. in
> our default PATH.
> So these work from the shell (or similar), and 
> even ESS (Emacs Speaks Statistics) is automagically picking up
> all these, so I can use
>    M-x R
>    M-x R-3.2.2
>    M-x R-devel
>    etc
>    
> to have different versions of R running simultaneously "inside" ESS.

Well, I'm not sure I would consider symbolic links to be an "intrinsic
feature of R" that I have missed.

In a module file I would do, say,

set             root          /nfs/software/R/$version
setenv          R_HOME        $root/lib64/R
prepend-path    PATH          $root/bin

Whilst in many cases setting $R_HOME or $R_PROFILE may not be necessary,
if they are needed, then this becomes a great deal easier with a
mechanism such a environment modules.

Another advantage of environment modules is that, if you compile R
against an external library, such as Intel's MKL or an MPI library, you
can also set up the necessary variables and paths via the module files.

However, in general the modules approach is probably only worthwhile if
you have a lot of software in a lot of different versions, which I do.

Cheers,

Loris

-- 
This signature is currently under construction.


From therneau at mayo.edu  Thu Oct  8 14:33:49 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 08 Oct 2015 07:33:49 -0500
Subject: [R] rpart cutpoint interpretation
In-Reply-To: <mailman.3.1444298401.26851.r-help@r-project.org>
References: <mailman.3.1444298401.26851.r-help@r-project.org>
Message-ID: <c10f8b$1jm3hl@ironport10.mayo.edu>

The cutpoint is on the predictor, so the interpretation is the same as it is for any other 
rpart model.  The subjects with predictor < cutpoint form one group and those > cutpoint 
the other.  The cutpoint is chosen to give the greatest difference in "average y" between 
the groups.  For poisson "averge y" is an event rate.

On 10/08/2015 05:00 AM, r-help-request at r-project.org wrote:
> I am trying to derive cutpoint/threshold with a poisson distributed
> dependent variable. I know how to interpret cutpoint with binary dependent
> variable based on direction. Can some on help me to intrepret cutpoint for
> poisson case with one independent variable with the derived threshold.


From emmanuel.blondel1 at gmail.com  Mon Oct  5 18:22:07 2015
From: emmanuel.blondel1 at gmail.com (Emmanuel Blondel)
Date: Mon, 5 Oct 2015 18:22:07 +0200
Subject: [R] [R-pkgs] cleangeo - Cleaning Geometries from Spatial Objects
In-Reply-To: <560D05CE.4070408@gmail.com>
References: <560D05CE.4070408@gmail.com>
Message-ID: <5612A3AF.7070507@gmail.com>

Dear all,

I've published a new package in CRAN named "cleangeo", that aims to 
facilitate the cleaning of geometries from spatial objects. cleangeo was 
initially born from some assistance provided to users that were facing 
issues in processing spatial data in R (see the original post at 
http://gis.stackexchange.com/questions/113964/fixing-orphaned-holes-in-r).
<https://github.com/eblondel/cleangeo>
A presentation of the package including a small tutorial is available 
at: 
http://fr.slideshare.net/EmmanuelBlondel/cleangeo-cleaning-geometries-from-spatial-objects-in-r
The project page is available at: https://github.com/eblondel/cleangeo

Best,
Emmanuel Blondel

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dcarlson at tamu.edu  Thu Oct  8 15:08:35 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 8 Oct 2015 13:08:35 +0000
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
	<C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
	<CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CCFAE@mb02.ads.tamu.edu>

More like this?

> mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
+ 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
+ 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> 
> # Convert columns in mat so first column is always smaller
> mat2 <- data.frame(t(apply(mat, 1, range)))
> mat2$X1 <- factor(mat2$X1, 1:9)
> mat2$X2 <- factor(mat2$X2, 1:9)
> tbl <- xtabs(~X1+X2, mat2)
> tbl.p <- tbl/sum(tbl)
> round(tbl.p, 2)
   X2
X1     1    2    3    4    5    6    7    8    9
  1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
  2 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
  3 0.00 0.00 0.00 0.08 0.00 0.00 0.08 0.00 0.00
  4 0.00 0.00 0.00 0.00 0.15 0.00 0.00 0.00 0.00
  5 0.00 0.00 0.00 0.00 0.08 0.38 0.15 0.00 0.00
  6 0.00 0.00 0.00 0.00 0.00 0.00 0.08 0.00 0.00
  7 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
  8 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
  9 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00

This puts everything on the diagonal and upper triangle. To get the lower triangle just use

> tbl <- xtabs(~X2+X1, mat2)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Hermann Norpois
Sent: Wednesday, October 7, 2015 12:17 AM
To: Boris Steipe; r-help
Subject: Re: [R] Measure the frequencies of pairs in a matrix

Ok, this was misleading. And was not that important. My result matrix
should look like this:

  1    2   3   4   5   6   7 ...
1 p1 p2
2 p
3
4

p1 etc are the frequencies of the combinations

1 and 2 for instance do not appear in my example. So the values would be
zero. Actually, this part is not too important. I would be happy enough to
solve the challenge with the frequencies of the pairs.
Thanks Hermann

2015-10-07 2:40 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:

> Since order is not important to you, you can order your pairs (e.g.
> decreasing) before compiling the frequencies.
> But I don't understand the second part about values "that do not appear in
> the matrix". Do you mean you want to assess all combinations? If that's the
> case I would think about a hash table or other indexed data structure,
> rather than iterating through a matrix.
>
>
> B.
>
>
>
> On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
>
> > Hello,
> >
> > I have a matrix mat (see dput(mat))
> >
> >> mat
> >      [,1] [,2]
> > [1,]    5    6
> > [2,]    6    5
> > [3,]    5    4
> > [4,]    5    5
> > ....
> >
> > I want the frequencies of the pairs in a new matrix, whereas the
> > combination 5 and 6 is the same as 6 and 5 (see the first two rows of
> mat).
> > In other words: What is the probability of each combination (each row)
> > ignoring the order in the combination. As a result I would like to have a
> > matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not
> appear
> > in my matrix.
> >
> > dput (mat)
> > structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> >
> > Thanks
> > Hermann
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From partners at packtpub.com  Thu Oct  8 12:36:00 2015
From: partners at packtpub.com (Partners)
Date: Thu, 8 Oct 2015 11:36:00 +0100 (BST)
Subject: [R] Books on R
In-Reply-To: <5337879.2380.1444300538539.JavaMail.poonamg@PPMUM13CPU0470>
Message-ID: <1422810.2389.1444300564254.JavaMail.poonamg@PPMUM13CPU0470>

Hi, 

My name is Poonam and I work with Packt Publishing. 

I would like to inform you that we have published the following books on R recently: 
Mastering R for Quantitative Finance 
Machine learning with R Cookbook 
R Data Analysis Cookbook 
R High Performance Programming 
R Data Visualization Cookbook 
Learning Data mining with R 
Mastering Scientific Computing with R 
Data Manipulation with R - Second Edition 

It would be great if we could feature these books under the 'documentation' section of the website ( https://www.r-project.org/doc/bib/R-books.html ) 

Also, we will be glad to send you review copies of these books if you need. 
Please do let me know if you need any further information about these books. 

Best regards, 



Poonam Gupta 
Online Marketing Executive 




From tim.besser at agroscope.admin.ch  Thu Oct  8 08:55:40 2015
From: tim.besser at agroscope.admin.ch (beti)
Date: Wed, 7 Oct 2015 23:55:40 -0700 (PDT)
Subject: [R] Getting McFadden's Pseudo R2 for Mixed Logit models using
 'gmnl' package
Message-ID: <1444287340549-4713313.post@n4.nabble.com>

I'd like to run *Mixed Logit (MIXL)* models and *Latent Class (LC)* models to
analyze Discrete Choice data.

Initially, I used the /mlogit /package and function for MIXL where the
/summary()/ also prints out the /McFadden's Pseudo R2/. However, to my
knowledge it is not possible to run an LC model using the /mlogit /package.
Thus, I wanted to use the /gmnl / package which includes both model types. 

Now, the summary of the /gmnl()/ function does not print a Pseudo R2. I can
imagine that this was not included in the summary on purpose as Pseudo R2
measures are often subject to debates, nevertheless, I would like to deduct
it from the model partly to compare results from the /gmnl /with those from
the /mlogit /models.

 1. Is there a function somewhere out there (like /pR2()/ from /pscl/
    or like /PseudoR2()/ from /BaylorEdPsych/ packages) that also works
    for `gmnl` models?
 2. How could you alternatively calculate the Pseudo R2 manually? I know
that it is done by using the 1-(L0/L1), but my problem is that I don't know
how I can update a /mlogit / or /gmnl / formula in the update function in a
way that it gives me the null model. Which random parameter do you feed the
MIXL? So far I tried it by using 

/update(full_model, . ~ 1 | 1, rpar = c("1:(intercept)" = "n",
"2:(intercept)" = "n"))/

and other solutions but nothing worked. I compared my manually calculated
R2s with those of the /mlogit / summary output but could replicate the
results. 

Any suggestions on how a could approach this problem would be helpful. I
have looked everywhere but could not find a comparable discussion on this
topic.





--
View this message in context: http://r.789695.n4.nabble.com/Getting-McFadden-s-Pseudo-R2-for-Mixed-Logit-models-using-gmnl-package-tp4713313.html
Sent from the R help mailing list archive at Nabble.com.


From neverstop at hotmail.it  Thu Oct  8 11:38:26 2015
From: neverstop at hotmail.it (Neverstop)
Date: Thu, 8 Oct 2015 02:38:26 -0700 (PDT)
Subject: [R] additive proportional odds model in R
In-Reply-To: <FE52D669-6CE4-4DFC-A26D-16668B6BEF62@comcast.net>
References: <1444214003583-4713259.post@n4.nabble.com>
	<FE52D669-6CE4-4DFC-A26D-16668B6BEF62@comcast.net>
Message-ID: <1444297106476-4713317.post@n4.nabble.com>

Thank you David Winsemius for the answer.

With the ambiguous term "additive proportional odds model", I meant the
nonparametrical generalization of the parametrical proportional odds model.
In other words, I meant to fit a generalized additive model (GAM) with a
cumulative logit as link function.

>I think you should understand that Nabble postings to R-help will soon not
be allowed. 
I didn't know that. Why? Should I post this topic somewhere else?



--
View this message in context: http://r.789695.n4.nabble.com/additive-proportional-odds-model-in-R-tp4713259p4713317.html
Sent from the R help mailing list archive at Nabble.com.


From j.terheyden at t-online.de  Thu Oct  8 12:39:51 2015
From: j.terheyden at t-online.de (begrinner)
Date: Thu, 8 Oct 2015 03:39:51 -0700 (PDT)
Subject: [R] changing colors in filled.contour
In-Reply-To: <1444214405711-4713260.post@n4.nabble.com>
References: <1444214405711-4713260.post@n4.nabble.com>
Message-ID: <1444300791065-4713319.post@n4.nabble.com>

Thanks a lot! 
I see more bars now but still, more than half of the diagram is white now.
Any suggestion to change that?

And is it possible to invert the color scheme?  (black does now stand for
lower values instead of higher ones)
  mylevels <- seq(10,0,length=10)  does not seem to work.



--
View this message in context: http://r.789695.n4.nabble.com/changing-colors-in-filled-contour-tp4713260p4713319.html
Sent from the R help mailing list archive at Nabble.com.


From fernando.mansito at gmail.com  Thu Oct  8 13:12:05 2015
From: fernando.mansito at gmail.com (FERNANDO MANSITO CABALLERO)
Date: Thu, 8 Oct 2015 13:12:05 +0200
Subject: [R] How to install packages without internet
Message-ID: <CABOXfwOSAmt=0wwrK8CPTuWrVgpSJUfeNd3dngQEydEGm8hLng@mail.gmail.com>

Dear Madam/Sir,

I am trying to understand how to install packages without internet and I
have come to a dead end.

I choose polynom (Venables & Ripley) which I first successfully installed
on a computer with internet. I found that the installed package comprises a
void "polynom" folder and a "polynom_1.3-8.tar" folder which only contains
a zipped container with the same name.

I then donloaded the package successfully using download.packages(). I
unzipped the .tar.gz downloaded package then successfully installed the
unzipped polynom package using its path and repos=NULL in
install.packages() on a computer without internet..

However, when I wrote "library(polynom)" on the computer without internet,
R3.2.2 answers with an error "polynom is not a valid installed package".

What am I doing wrong?

Yours truly
Fernando Mansito

	[[alternative HTML version deleted]]


From hnorpois at gmail.com  Thu Oct  8 13:44:31 2015
From: hnorpois at gmail.com (Hermann Norpois)
Date: Thu, 8 Oct 2015 13:44:31 +0200
Subject: [R] Measure the frequencies of pairs in a matrix
In-Reply-To: <CAF8bMcbyJU3weMTdkPLoiynv2HObQBQD6e3JPVsiE-=WrySpXw@mail.gmail.com>
References: <CAKyZeBtmDgdKLA1nbxGqHp68fmMLsmWN-fLOQBrh+-bY=dudqA@mail.gmail.com>
	<C84681EB-D32F-4A14-BD9B-548012EFFF6A@utoronto.ca>
	<CAKyZeBvAeN6gTQwMoxZDNnihLg_6Fwhb4EKCWC_2Wbg2caNBiA@mail.gmail.com>
	<12891EBD-B790-4333-9732-820A826DCAF5@utoronto.ca>
	<CAF8bMcbyJU3weMTdkPLoiynv2HObQBQD6e3JPVsiE-=WrySpXw@mail.gmail.com>
Message-ID: <CAKyZeBv2SAwzQeNAHDh4ODkCF9q18C7p5=WRj84DBpotL0uYYw@mail.gmail.com>

Thanks a lot. This was very helpful. I want to apologise for being
unprecise. My favourite solution was William's.
Thanks again.

2015-10-07 18:39 GMT+02:00 William Dunlap <wdunlap at tibco.com>:

> You could also call table() on the columns of the input matrix, first
> converting them
> to factors with levels 1:max.  Then add together the upper and lower
> triangles of
> the table if order is not important.  E.g.,
> f2 <- function (mat)
> {
>     maxMat <- max(mat)
>     stopifnot(is.matrix(mat), all(mat %in% seq_len(maxMat)))
>     L <- split(factor(mat, levels = seq_len(maxMat)), col(mat))
>     Table <- do.call(table, unname(L))
>     ignoreOrder <- function(M) {
>         stopifnot(length(dim(M)) == 2)
>         lower <- lower.tri(M, diag = FALSE)
>         upper <- upper.tri(M, diag = FALSE)
>         M[lower] <- M[lower] + t(M)[lower]
>         M[upper] <- t(M)[upper]
>         M
>     }
>     ignoreOrder(Table)
> }
>
> > mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> > f2(mat)
>
>      1  2  3  4  5  6  7
>   1  0  0  0  0  0  0  0
>   2  0  0  0  0  0  0  0
>   3  0  0  0  2  0  0  2
>   4  0  0  2  0  4  0  0
>   5  0  0  0  4  2 10  4
>   6  0  0  0  0 10  0  2
>   7  0  0  2  0  4  2  0
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Oct 7, 2015 at 6:09 AM, Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> > Still not sure I understand. But here is what I think you might mean:
> >
> > # Your data
> > mat <- structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> >
> > # Create a square matrix with enough space to have an element for each
> pair. Since
> > # order is not important, only the upper triangle is used. If the matrix
> is
> > # large and sparse, a different approach might be needed.
> > freq <- matrix(numeric(max(mat) * max(mat)),  nrow = max(mat), ncol =
> max(mat))
> >
> > # Loop over your input
> > for (i in 1:nrow(mat)) {
> >     # Sort the elements of a row by size.
> >     x <- sort(mat[i,])
> >     # Increment the corresponding element of the frequency matrix
> >     freq[x[1], x[2]] <- freq[x[1], x[2]] + 1
> > }
> >
> > freq
> >
> >
> > Cheers,
> > B.
> >
> >
> >
> >
> >
> > On Oct 7, 2015, at 1:17 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
> >
> >> Ok, this was misleading. And was not that important. My result matrix
> should look like this:
> >>
> >>   1    2   3   4   5   6   7 ...
> >> 1 p1 p2
> >> 2 p
> >> 3
> >> 4
> >>
> >> p1 etc are the frequencies of the combinations
> >>
> >> 1 and 2 for instance do not appear in my example. So the values would
> be zero. Actually, this part is not too important. I would be happy enough
> to solve the challenge with the frequencies of the pairs.
> >> Thanks Hermann
> >>
> >> 2015-10-07 2:40 GMT+02:00 Boris Steipe <boris.steipe at utoronto.ca>:
> >> Since order is not important to you, you can order your pairs (e.g.
> decreasing) before compiling the frequencies.
> >> But I don't understand the second part about values "that do not appear
> in the matrix". Do you mean you want to assess all combinations? If that's
> the case I would think about a hash table or other indexed data structure,
> rather than iterating through a matrix.
> >>
> >>
> >> B.
> >>
> >>
> >>
> >> On Oct 6, 2015, at 4:59 PM, Hermann Norpois <hnorpois at gmail.com> wrote:
> >>
> >> > Hello,
> >> >
> >> > I have a matrix mat (see dput(mat))
> >> >
> >> >> mat
> >> >      [,1] [,2]
> >> > [1,]    5    6
> >> > [2,]    6    5
> >> > [3,]    5    4
> >> > [4,]    5    5
> >> > ....
> >> >
> >> > I want the frequencies of the pairs in a new matrix, whereas the
> >> > combination 5 and 6 is the same as 6 and 5 (see the first two rows of
> mat).
> >> > In other words: What is the probability of each combination (each row)
> >> > ignoring the order in the combination. As a result I would like to
> have a
> >> > matrix that includes rows and cols 0, 1, 2 ... max (mat) that do not
> appear
> >> > in my matrix.
> >> >
> >> > dput (mat)
> >> > structure(c(5, 6, 5, 5, 4, 3, 6, 7, 4, 7, 5, 5, 5, 5, 6, 5, 5,
> >> > 4, 3, 6, 7, 4, 7, 5, 5, 5, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7,
> >> > 6, 6, 5, 4, 5, 5, 7, 5, 6, 3, 5, 6, 7, 6), .Dim = c(26L, 2L))
> >> >
> >> > Thanks
> >> > Hermann
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Oct  8 16:29:31 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 8 Oct 2015 10:29:31 -0400
Subject: [R] How to install packages without internet
In-Reply-To: <CABOXfwOSAmt=0wwrK8CPTuWrVgpSJUfeNd3dngQEydEGm8hLng@mail.gmail.com>
References: <CABOXfwOSAmt=0wwrK8CPTuWrVgpSJUfeNd3dngQEydEGm8hLng@mail.gmail.com>
Message-ID: <CAM_vjukc0QBP-gvS8roCg-vxF6uStMV9fH=uHiQJd-qKqQRdKg@mail.gmail.com>

Don't uncompress the package first.

Either from within R:

install.packages("/path/to/pgk.tar.gz", repos=NULL)

or at command line

R CMD INSTALL /path/to/pgk.tar.gz

In either case, pay attention to any messages that R returns

Sarah

On Thu, Oct 8, 2015 at 7:12 AM, FERNANDO MANSITO CABALLERO
<fernando.mansito at gmail.com> wrote:
> Dear Madam/Sir,
>
> I am trying to understand how to install packages without internet and I
> have come to a dead end.
>
> I choose polynom (Venables & Ripley) which I first successfully installed
> on a computer with internet. I found that the installed package comprises a
> void "polynom" folder and a "polynom_1.3-8.tar" folder which only contains
> a zipped container with the same name.
>
> I then donloaded the package successfully using download.packages(). I
> unzipped the .tar.gz downloaded package then successfully installed the
> unzipped polynom package using its path and repos=NULL in
> install.packages() on a computer without internet..
>
> However, when I wrote "library(polynom)" on the computer without internet,
> R3.2.2 answers with an error "polynom is not a valid installed package".
>
> What am I doing wrong?
>
> Yours truly
> Fernando Mansito
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From marc_schwartz at me.com  Thu Oct  8 16:56:06 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 08 Oct 2015 09:56:06 -0500
Subject: [R] additive proportional odds model in R
In-Reply-To: <1444297106476-4713317.post@n4.nabble.com>
References: <1444214003583-4713259.post@n4.nabble.com>
	<FE52D669-6CE4-4DFC-A26D-16668B6BEF62@comcast.net>
	<1444297106476-4713317.post@n4.nabble.com>
Message-ID: <9CD7E6F7-2B1D-4E7C-BDF8-79035278E259@me.com>


> On Oct 8, 2015, at 4:38 AM, Neverstop <neverstop at hotmail.it> wrote:
> 
> Thank you David Winsemius for the answer.
> 
> With the ambiguous term "additive proportional odds model", I meant the
> nonparametrical generalization of the parametrical proportional odds model.
> In other words, I meant to fit a generalized additive model (GAM) with a
> cumulative logit as link function.
> 
>> I think you should understand that Nabble postings to R-help will soon not
> be allowed. 
> I didn't know that. Why? Should I post this topic somewhere else?
> 

Hi,

To your primary question, see the VGAM package on CRAN:
 
  https://cran.r-project.org/web/packages/VGAM/

There is also a reference here that you might find helpful:

  http://www.stat.ufl.edu/~aa/ordinal/R_examples.pdf


To your question regarding David's comment on Nabble:

  https://stat.ethz.ch/pipermail/r-help/2015-October/432752.html


Regards,

Marc Schwartz


From salnsg at gmail.com  Thu Oct  8 17:05:42 2015
From: salnsg at gmail.com (=?UTF-8?B?0KHQtdGA0LPQtdC5INChLg==?=)
Date: Thu, 8 Oct 2015 19:05:42 +0400
Subject: [R] =?utf-8?q?=E2=80=8B_use_of_PPML_=28Poisson_Pseudo_Maximum_Lik?=
	=?utf-8?q?elihood=29?=
Message-ID: <CAM9wezr6W0WR2OFh5JoAM6SvfVx_fZZ6R023Vmsox9fw9QO2Pw@mail.gmail.com>

Dear Colleagues!


We use R for research. We would like to perform calculations (gravity model
of trade) with the
??
use of PPML (Poisson Pseudo Maximum Likelihood).

Please explain:

1. What package in R enables us to make calculations in accordance with the
PPML?

We used the command
glm()

with the parameter

family=quasipoisson(link="log").

Does this command procedure PPML? If not, then what command allows us to
use PPML?

2. For calculations using a linear model the quality factor is R^2. What is
the analogue of this indicator for PPML in system R?

Thank you very much in advance!

	[[alternative HTML version deleted]]


From yongnam.kim at wisc.edu  Thu Oct  8 16:20:21 2015
From: yongnam.kim at wisc.edu (Yongnam Kim)
Date: Thu, 08 Oct 2015 14:20:21 +0000
Subject: [R] suppress to bring value label with spss.system.file
Message-ID: <CAEazi59CPcFOpRxVOPrH60AzGd=S0joKVXHJU+wq0Gup2NzmyA@mail.gmail.com>

Hello all,

I know how to suppress to bring value labels from SPSS when importing sav
file using foreign package by "use.value.labels = FALSE" in read.spss
function. But, I don't know how to do the same thing when using memisc pkg,
in particular, with the spss.system.file function.

Many thanks!

	[[alternative HTML version deleted]]


From Achim.Zeileis at uibk.ac.at  Thu Oct  8 18:55:32 2015
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 8 Oct 2015 18:55:32 +0200 (CEST)
Subject: [R]
	=?utf-8?q?=E2=80=8B_use_of_PPML_=28Poisson_Pseudo_Maximum_Lik?=
	=?utf-8?q?elihood=29?=
In-Reply-To: <CAM9wezr6W0WR2OFh5JoAM6SvfVx_fZZ6R023Vmsox9fw9QO2Pw@mail.gmail.com>
References: <CAM9wezr6W0WR2OFh5JoAM6SvfVx_fZZ6R023Vmsox9fw9QO2Pw@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1510081851490.7664@paninaro.uibk.ac.at>

On Thu, 8 Oct 2015, ?????? ?. wrote:

> Dear Colleagues!
>
>
> We use R for research. We would like to perform calculations (gravity model
> of trade) with the
> ??
> use of PPML (Poisson Pseudo Maximum Likelihood).
>
> Please explain:
>
> 1. What package in R enables us to make calculations in accordance with the
> PPML?
>
> We used the command
> glm()

Yes.

> with the parameter
>
> family=quasipoisson(link="log").

That is one option. In econometrics, the quasi-Poisson version is less 
commonly used than in statistics, though. Alternatively, so-called 
"robust" sandwich standard errors can be applied, i.e.,

m <- glm(..., family = poisson)

library("lmtest")
library("sandwich")
coeftest(m, vcov = sandwich)

> Does this command procedure PPML? If not, then what command allows us to
> use PPML?
>
> 2. For calculations using a linear model the quality factor is R^2. What 
> is the analogue of this indicator for PPML in system R?

That is not really an R question. Sometimes people use pseudo-R-squared 
measures, e.g., available in package "pscl". Whether or not this is really 
useful is a different question, though.

> Thank you very much in advance!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Oct  8 19:53:39 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 8 Oct 2015 10:53:39 -0700
Subject: [R] How to install packages without internet
In-Reply-To: <CAM_vjukc0QBP-gvS8roCg-vxF6uStMV9fH=uHiQJd-qKqQRdKg@mail.gmail.com>
References: <CABOXfwOSAmt=0wwrK8CPTuWrVgpSJUfeNd3dngQEydEGm8hLng@mail.gmail.com>
	<CAM_vjukc0QBP-gvS8roCg-vxF6uStMV9fH=uHiQJd-qKqQRdKg@mail.gmail.com>
Message-ID: <44C9F321-2885-4721-9CFE-17E03F2B9648@comcast.net>


On Oct 8, 2015, at 7:29 AM, Sarah Goslee wrote:

> Don't uncompress the package first.
> 
> Either from within R:
> 
> install.packages("/path/to/pgk.tar.gz", repos=NULL)

I think at least one OS will require that you also include type="source" and I would advise including dependencies=TRUE.


> or at command line
> 
> R CMD INSTALL /path/to/pgk.tar.gz
> 
> In either case, pay attention to any messages that R returns
> 
> Sarah
> 
> On Thu, Oct 8, 2015 at 7:12 AM, FERNANDO MANSITO CABALLERO
> <fernando.mansito at gmail.com> wrote:
>> Dear Madam/Sir,
>> 
>> I am trying to understand how to install packages without internet and I
>> have come to a dead end.
>> 
>> I choose polynom (Venables & Ripley) which I first successfully installed
>> on a computer with internet. I found that the installed package comprises a
>> void "polynom" folder and a "polynom_1.3-8.tar" folder which only contains
>> a zipped container with the same name.
>> 
>> I then donloaded the package successfully using download.packages(). I
>> unzipped the .tar.gz downloaded package then successfully installed the
>> unzipped polynom package using its path and repos=NULL in
>> install.packages() on a computer without internet..

Generally one does not need to unzip source versions of packages unless you want to look at the contents separately. With Windoze and Macs you need to specify type="source" [unless getOption("pkgType") is set to that value] and may need to have the appropriate system tools. You did not show your exact call to install.packages().

>> 
>> However, when I wrote "library(polynom)" on the computer without internet,
>> R3.2.2 answers with an error "polynom is not a valid installed package".

The problem description doesn't allow a definite answer. If problems persist, then you should post more complete descriptions of your methods, your OS and R versions.

>> 
>> What am I doing wrong?
>> 
> 

-- 

David Winsemius
Alameda, CA, USA


From lucam1968 at gmail.com  Thu Oct  8 20:06:50 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Thu, 8 Oct 2015 20:06:50 +0200
Subject: [R] How to remove the grid around the plot(ca(...)) function?
Message-ID: <CABQyo865rohyny+J_nhhzko9+Dq_c53ywr+9N=ByqJ6d31mZig@mail.gmail.com>

Hello R-experts,

Could anyone suggest how I can remove the grid coming out of the
plot(ca(...)) function?

For instance I have:

library(ca)
v1 <- c(10,15,20,15,25)
v2 <- c(23,4,7,12,2)
v3 <- c(10,70,2,3,7)
d1 <- data.frame(v1,v2,v3)
rownames(d1) <- c("B1","B2","B3","B4","B5")
plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="")

As you can I could remove the X and Y axis label, but basically I am
looking for a chart containing only the data points - with relative inertia
represented by their size - and labels with no extra lines or number, any
clue on how I can do that?

Thank you,

Luca

	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Thu Oct  8 18:49:17 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Thu, 8 Oct 2015 09:49:17 -0700
Subject: [R] Attaching a pdf file to an email generated with sendmailR?
Message-ID: <E30D0E7822EEB443A5B9CC8273D99C74B649AD9A32@EXVMBX018-3.exch018.msoutlookonline.net>

For some time I have been using sendmailR to generate a simple message when a report was done running.

Recently, I started adding a couple of pertinent statistics in the body of the email.

Now, I've finally decided that what the heck, I ought to simply attach the report itself to the email. The report is generated as a pdf file.

I can't seem to get this to work in any simple way with mime_part; if I specify a path to the file it simply assumes that "P:/blablabla/thefile.pdf" is a message I want to put in a text file attachment.

I assume I am doing something incorrectly and likely something simple. But maybe there is a clever trick I am missing. My send line is simply:

sendmail(from,to,subject,body,control=list(smtpServer="mail.optonline.net"))

where body is something like this:

body <- list("Here's your stupid file",mime_part(x="P:/partofpath/ thefile.pdf",name="file.pdf"))

Any suggestions are welcome!

Thanks,

Mike

________________________________
This email and any attachments are confidential and inte...{{dropped:9}}


From ckmsasi at gmail.com  Thu Oct  8 19:28:42 2015
From: ckmsasi at gmail.com (Sasikumar Kandhasamy)
Date: Thu, 8 Oct 2015 10:28:42 -0700
Subject: [R] Installing pre-compiled R in Linux
In-Reply-To: <A98AEE9F-B6BD-4F79-B20F-3B65DDAFC569@dcn.davis.CA.us>
References: <CABbvK+EzEvnMhgoQjL2DH=6PHM4V6o=hveaXNUJ2iVmtKYMfcQ@mail.gmail.com>
	<CACdH2Za8V+WreAVJYc++YJ_iF86BApUsBR+FPQ5cNuT54rOyNA@mail.gmail.com>
	<CABbvK+HD6y7-eP+jZ8piB1pC6RTQwmCRAdtbypDqAdeyJFbPxA@mail.gmail.com>
	<CACdH2Za+Cu8dwAwkTxF6m1MDcciGiYCX8YT1Mx3G7kgxC2U1rg@mail.gmail.com>
	<CABbvK+E8bo+XoGnEGNhFRUGDz2kzcHA=AZqiRsGnRSJockvopQ@mail.gmail.com>
	<A98AEE9F-B6BD-4F79-B20F-3B65DDAFC569@dcn.davis.CA.us>
Message-ID: <CABbvK+FUbAXKz3pzxb1C6-j=K925YS_F+e2C_2ANcGZTC1yVHA@mail.gmail.com>

Sure Jeff, thanks a lot for the references. Will explore more and will also
try to contact R-devel list for further help on cross compile. Thanks again
to all for the quick responses.

Thanks & Regards
Sasi

On Thu, Oct 8, 2015 at 12:11 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> There is a manual for compiling and installing R. There is also a mailing
> list (described in the Posting Guide) called R-devel where topics like
> compiling R are actually on topic, unlike here. If you have to
> cross-compile then you probably have a bit more work ahead of you than most
> users would have, so be prepared to roll up your sleeves and get familiar
> with the innards of R so you can decide exactly which features you need. I
> have not heard of anyone rolling R into an embedded system, but this list
> would not be the place to hear about it so that probably doesn't mean much.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 7, 2015 3:45:45 PM PDT, Sasikumar Kandhasamy <ckmsasi at gmail.com>
> wrote:
> >Thanks Mike. From source, i am able to compile and use R in my red hat
> >linux box. I was trying to get hands on using R in linux box before
> >trying
> >R on the embedded box.
> >
> >My requirement is to run R (R scripts) on my embedded box which has
> >customized debian linux (kernel version 2.6.32) in batch mode without
> >GUI
> >support. The embedded box have multi-core MIPS processor with nearly
> >30GB
> >RAM. I hope hardware resources on the embedded box shouldn't be an
> >issue to
> >run R (correct me if i am wrong), but linux version running here is an
> >customized one with limited supporting services such as light weight
> >shell
> >etc.
> >
> >Given this, do i need to cross compile R package for my embedded box or
> >i
> >can directly install the debian MIPS version of R package. But there is
> >no
> >apt-get or other installer in the embedded box.
> >
> >
> >Regards
> >Sasi
> >
> >On Wed, Oct 7, 2015 at 1:46 AM, Michael Hannon
> ><jmhannon.ucdavis at gmail.com>
> >wrote:
> >
> >> I don't think kernel compatibility is a significant issue for most
> >> applications.  I can say for certain that I update the kernels on my
> >> linux boxes without having to reinstall R.
> >>
> >> There *are* R packages for RHEL and friends.  Have a look at:
> >>
> >> https://cran.r-project.org/bin/linux/redhat/README
> >>
> >> Note that there's a bit of fiddling required, but I don't think it's
> >> particularly complicated.
> >>
> >> It's usually not particularly difficult to install R from source.  If
> >> you prefer to do that, have a look at:
> >>
> >> https://cran.r-project.org/doc/manuals/r-release/R-admin.html
> >>
> >> Also, you don't specify your requirements, but don't overlook the
> >> possibility of installing a virtual machine on your RHEL server.
> >> (It's somewhat easier to get an R package for Fedora or Ubuntu than
> >> for RHEL, for instance.)
> >>
> >> I don't know the answer to your question about embedded systems.  I
> >> would think R would not be a great choice for an embedded system, but
> >> I don't know what your requirements are.
> >>
> >> -- Mike
> >>
> >>
> >> On Tue, Oct 6, 2015 at 9:42 PM, Sasikumar Kandhasamy
> ><ckmsasi at gmail.com>
> >> wrote:
> >> > Thanks a lot Mike. The Linux distribution we use is "Red Hat
> >Enterprise
> >> > Linux Server release 6.2".
> >> >
> >> > Also, couple of clarifications,
> >> >
> >> > 1. Do we have a R package compatibility matrix against the Linux
> >kernel
> >> > version? Or for the Red Hat Linux with kernel version 2.6.32-279,
> >do you
> >> > have any suggestion/recommendation on R package to be used?
> >> >
> >> > 2. If we need to use Rscripts in embedded systems such as routers
> >and
> >> > switches, do we need to install the complete R package in the
> >system
> >> also?
> >> > Or just libR.so and Rscript should be ok?
> >> >
> >> > Thanks again Mike.
> >> >
> >> > Regards
> >> > Sasi
> >> >
> >> > On Tue, Oct 6, 2015 at 5:57 PM, Michael Hannon <
> >> jmhannon.ucdavis at gmail.com>
> >> > wrote:
> >> >>
> >> >> It's very likely that there is already an R package for your linux
> >> >> system, and, if so, you'd probably be well-served to use that one.
> >> >> You've given us the version of the kernel you're using (not a
> >recent
> >> >> one, BTW), but what linux distribution are you using?
> >> >>
> >> >> -- Mike
> >> >>
> >> >>
> >> >> On Tue, Oct 6, 2015 at 3:59 PM, Sasikumar Kandhasamy
> ><ckmsasi at gmail.com
> >> >
> >> >> wrote:
> >> >> > Hi,
> >> >> >
> >> >> > I have downloaded the pre-compiled version of R package:
> >> >> > r-base-core(3.2.2-1) for i386 platform. Unzipped the package
> >under my
> >> >> > tmp
> >> >> > directory (/tmp). The directories "et"c and "usr" got created
> >with
> >> >> > binaries
> >> >> > R and Rscript under /tmp/usr/bin/.
> >> >> >
> >> >> > Executing the R (/tmp/usr/bin/R) or Rscript
> >(/tmp/usr/bin/Rscipt)
> >> >> > reports
> >> >> > the below error,
> >> >> >
> >> >> > ./usr/bin/R
> >> >> >                                              ./usr/bin/R: line
> >238:
> >> >> > /usr/lib/R/etc/ldpaths: No such file or directory
> >> >> > ERROR: R_HOME ('/usr/lib/R') not found
> >> >> >
> >> >> > How to reconfigure the R environment variables? Because, i tried
> >> setting
> >> >> > the R_HOME directory to "/tmp/usr/lib/R" but still not working.
> >> >> >
> >> >> > The Linux version i am using is  2.6.32. Please help me with the
> >steps
> >> >> > to
> >> >> > install the R correctly. Thanks.
> >> >> >
> >> >> > Regards
> >> >> > Sasi
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible
> >code.
> >> >
> >> >
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From dawn1313 at gmail.com  Thu Oct  8 19:32:27 2015
From: dawn1313 at gmail.com (Dawn)
Date: Thu, 8 Oct 2015 10:32:27 -0700
Subject: [R] can't install DESEq2 on Mac
Message-ID: <CABtBq8EhKU5-6jXT6NOpyzAk465kMbPp=K=_1a_r58pA+1adoA@mail.gmail.com>

Hi,

I can't install DESEq2 on my iMac, as follows:

> source("http://bioconductor.org/biocLite.R")
Bioconductor version 3.1 (BiocInstaller 1.18.4), ?biocLite for help
> biocLite("DESeq2")
BioC_mirror: http://bioconductor.org
Using Bioconductor version 3.1 (BiocInstaller 1.18.4), R version 3.2.2.
Installing package(s) ?DESeq2?
Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!

Can you please help that? Thank you!
Dawn

	[[alternative HTML version deleted]]


From salnsg at gmail.com  Thu Oct  8 20:31:16 2015
From: salnsg at gmail.com (=?UTF-8?B?0KHQtdGA0LPQtdC5INChLg==?=)
Date: Thu, 08 Oct 2015 21:31:16 +0300
Subject: [R]
 =?utf-8?q?=E2=80=8B_use_of_PPML_=28Poisson_Pseudo_Maximum_Lik?=
 =?utf-8?q?elihood=29?=
Message-ID: <2gojfernisre34a2afunwtf9.1444329076946@email.android.com>

?Thank you very much!!!


?????????? ?? ?????????

-------- ???????? ????????? --------
??: Achim Zeileis <Achim.Zeileis at uibk.ac.at> 
????: 2015.10.08  19:55  (GMT+03:00) 
????: "?????? ?." <salnsg at gmail.com> 
Cc: r-help at r-project.org 
????: Re: [R] ? use of PPML (Poisson Pseudo Maximum Likelihood) 
 
On Thu, 8 Oct 2015, ?????? ?. wrote:

> Dear Colleagues!
>
>
> We use R for research. We would like to perform calculations (gravity model
> of trade) with the
> ??
> use of PPML (Poisson Pseudo Maximum Likelihood).
>
> Please explain:
>
> 1. What package in R enables us to make calculations in accordance with the
> PPML?
>
> We used the command
> glm()

Yes.

> with the parameter
>
> family=quasipoisson(link="log").

That is one option. In econometrics, the quasi-Poisson version is less 
commonly used than in statistics, though. Alternatively, so-called 
"robust" sandwich standard errors can be applied, i.e.,

m <- glm(..., family = poisson)

library("lmtest")
library("sandwich")
coeftest(m, vcov = sandwich)

> Does this command procedure PPML? If not, then what command allows us to
> use PPML?
>
> 2. For calculations using a linear model the quality factor is R^2. What 
> is the analogue of this indicator for PPML in system R?

That is not really an R question. Sometimes people use pseudo-R-squared 
measures, e.g., available in package "pscl". Whether or not this is really 
useful is a different question, though.

> Thank you very much in advance!
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From kishor.tappita at gmail.com  Thu Oct  8 20:59:58 2015
From: kishor.tappita at gmail.com (Kishor Tappita)
Date: Fri, 9 Oct 2015 00:29:58 +0530
Subject: [R] rpart cutpoint interpretation
In-Reply-To: <c10f8b$1jm3hk@ironport10.mayo.edu>
References: <mailman.3.1444298401.26851.r-help@r-project.org>
	<c10f8b$1jm3hk@ironport10.mayo.edu>
Message-ID: <CAL_RqET30xTrHSXfCB702Lojm1WBfoUMTnFOFx0XKoY9kb3YMw@mail.gmail.com>

Thank you so much for the clarification Terry.

On Thu, Oct 8, 2015 at 6:03 PM, Therneau, Terry M., Ph.D. <therneau at mayo.edu
> wrote:

> The cutpoint is on the predictor, so the interpretation is the same as it
> is for any other rpart model.  The subjects with predictor < cutpoint form
> one group and those > cutpoint the other.  The cutpoint is chosen to give
> the greatest difference in "average y" between the groups.  For poisson
> "averge y" is an event rate.
>
>
> On 10/08/2015 05:00 AM, r-help-request at r-project.org wrote:
>
>> I am trying to derive cutpoint/threshold with a poisson distributed
>> dependent variable. I know how to interpret cutpoint with binary dependent
>> variable based on direction. Can some on help me to intrepret cutpoint for
>> poisson case with one independent variable with the derived threshold.
>>
>

	[[alternative HTML version deleted]]


From fransiepansiekevertje at gmail.com  Thu Oct  8 22:49:22 2015
From: fransiepansiekevertje at gmail.com (Frans Marcelissen)
Date: Thu, 8 Oct 2015 22:49:22 +0200
Subject: [R] Attaching a pdf file to an email generated with sendmailR?
In-Reply-To: <E30D0E7822EEB443A5B9CC8273D99C74B649AD9A32@EXVMBX018-3.exch018.msoutlookonline.net>
References: <E30D0E7822EEB443A5B9CC8273D99C74B649AD9A32@EXVMBX018-3.exch018.msoutlookonline.net>
Message-ID: <CAFFQM6Ygw53nmCjiVeN=8+Tj_kyYYNYYZrcT04Cb2CmXOb7tnw@mail.gmail.com>

Hi Michael,
I don't know whether there is a particulal reason for using sendmailR, but
I use mailR for this without any problem.
mailR::send.mail(from, to, subject = "", body = "", encoding = "iso-8859-1",
  html = FALSE, inline = FALSE, smtp = list(), authenticate = FALSE,
  send = TRUE, attach.files = NULL, debug = FALSE, ...)

If you use an external smtp server, enter login name and password in
parameter smtp as follows:
smtp = list(host.name = "smtp.XXXXX", port = XXXXX, user.name = "XXXXX",
passwd = "XXXXX", ssl = XXXXX)

2015-10-08 18:49 GMT+02:00 Michael Ashton <m.ashton at enduringinvestments.com>
:

> For some time I have been using sendmailR to generate a simple message
> when a report was done running.
>
> Recently, I started adding a couple of pertinent statistics in the body of
> the email.
>
> Now, I've finally decided that what the heck, I ought to simply attach the
> report itself to the email. The report is generated as a pdf file.
>
> I can't seem to get this to work in any simple way with mime_part; if I
> specify a path to the file it simply assumes that
> "P:/blablabla/thefile.pdf" is a message I want to put in a text file
> attachment.
>
> I assume I am doing something incorrectly and likely something simple. But
> maybe there is a clever trick I am missing. My send line is simply:
>
> sendmail(from,to,subject,body,control=list(smtpServer="mail.optonline.net
> "))
>
> where body is something like this:
>
> body <- list("Here's your stupid file",mime_part(x="P:/partofpath/
> thefile.pdf",name="file.pdf"))
>
> Any suggestions are welcome!
>
> Thanks,
>
> Mike
>
> ________________________________
> This email and any attachments are confidential and in...{{dropped:13}}


From Martin.Morgan at roswellpark.org  Thu Oct  8 23:30:24 2015
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Thu, 8 Oct 2015 21:30:24 +0000
Subject: [R] can't install DESEq2 on Mac
In-Reply-To: <CABtBq8EhKU5-6jXT6NOpyzAk465kMbPp=K=_1a_r58pA+1adoA@mail.gmail.com>
References: <CABtBq8EhKU5-6jXT6NOpyzAk465kMbPp=K=_1a_r58pA+1adoA@mail.gmail.com>
Message-ID: <DF23DAC5A53912408040FF04D8B780AADF1745@EXMB3RSC.roswellpark.org>

Please ask questions about Bioconductor packages on the Bioconductor support site, https://support.bioconductor.org. This looks like R encountered an http error instead of the file it was expecting. Martin

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dawn
> Sent: Thursday, October 08, 2015 1:32 PM
> To: r-help mailing list
> Subject: [R] can't install DESEq2 on Mac
> 
> Hi,
> 
> I can't install DESEq2 on my iMac, as follows:
> 
> > source("http://bioconductor.org/biocLite.R")
> Bioconductor version 3.1 (BiocInstaller 1.18.4), ?biocLite for help
> > biocLite("DESeq2")
> BioC_mirror: http://bioconductor.org
> Using Bioconductor version 3.1 (BiocInstaller 1.18.4), R version 3.2.2.
> Installing package(s) ?DESeq2?
> Error: Line starting '<!DOCTYPE HTML PUBLI ...' is malformed!
> 
> Can you please help that? Thank you!
> Dawn
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

From dcarlson at tamu.edu  Thu Oct  8 23:52:43 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 8 Oct 2015 21:52:43 +0000
Subject: [R] How to remove the grid around the plot(ca(...)) function?
In-Reply-To: <CABQyo865rohyny+J_nhhzko9+Dq_c53ywr+9N=ByqJ6d31mZig@mail.gmail.com>
References: <CABQyo865rohyny+J_nhhzko9+Dq_c53ywr+9N=ByqJ6d31mZig@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CD527@mb02.ads.tamu.edu>

You will have to construct it yourself using plot(), points(), and text():

> d1.ca <- ca(d1)
> d1.plt <- plot(d1.ca)

d1.ca$rowmass will contain the row masses and d1.ca$colmass the column masses
d1.ca$rownames and d1.ca$colnames, the names

d1.plt$rows has the row coordinates and d1.plt$cols, the column coordinates.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Luca Meyer
Sent: Thursday, October 8, 2015 1:07 PM
To: r-help
Subject: [R] How to remove the grid around the plot(ca(...)) function?

Hello R-experts,

Could anyone suggest how I can remove the grid coming out of the
plot(ca(...)) function?

For instance I have:

library(ca)
v1 <- c(10,15,20,15,25)
v2 <- c(23,4,7,12,2)
v3 <- c(10,70,2,3,7)
d1 <- data.frame(v1,v2,v3)
rownames(d1) <- c("B1","B2","B3","B4","B5")
plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="")

As you can I could remove the X and Y axis label, but basically I am
looking for a chart containing only the data points - with relative inertia
represented by their size - and labels with no extra lines or number, any
clue on how I can do that?

Thank you,

Luca

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgnumis at gmail.com  Thu Oct  8 22:07:03 2015
From: bgnumis at gmail.com (bgnumis bgnum)
Date: Thu, 8 Oct 2015 22:07:03 +0200
Subject: [R] Smoth matplot
Message-ID: <CAN25tHQiSFLqgVgAnUYU5FsaMSf2ka0yLpxkqahdU6Mh3bYCqQ@mail.gmail.com>

   Hi all,

I have a matrix data and I use to plot matplot, it is suposed each column
is a temporal series. As you see in the example the matrix o data have
"peaks" I want to plot (using matplot or what yoy can say me) this matrix
but with and smoothed line envoloving the values of the matrix so when
plotted all the appearce of the lines will be smoth bell. Do you think is
it possible.

Can anyone suggest to make a tranform?

Could be smotthing the lines plotted (columns) will be achieved but not
suere if it is possible.







       [,1]      [,2]      [,3]      [,4]     [,5]      [,6]      [,7]
[1,] 100.00000 100.00000 100.00000 100.00000 100.0000 100.00000 100.00000
[2,] 100.54163  99.23893 100.77238  98.95058 100.2250  99.18830 100.18801
[3,]  99.61230 102.12813  99.34499  97.52805 101.8252  99.97846  95.91478
[4,] 102.04546 100.38053 100.80122 100.10281 100.4912  98.04112 101.17684
[5,]  97.27201 100.19247 100.43301 101.04954 102.9921  98.25110  98.31890
[6,] 103.68170 104.95366  99.03839  99.81437 100.7232 102.47300  99.17555
          [,8]
[1,] 100.00000
[2,] 101.10791
[3,] 102.90392
[4,] 100.16137
[5,] 100.98710
[6,]  99.09212

	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Thu Oct  8 23:24:07 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Thu, 8 Oct 2015 14:24:07 -0700
Subject: [R] Attaching a pdf file to an email generated with sendmailR?
In-Reply-To: <CAFFQM6Ygw53nmCjiVeN=8+Tj_kyYYNYYZrcT04Cb2CmXOb7tnw@mail.gmail.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74B649AD9A32@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAFFQM6Ygw53nmCjiVeN=8+Tj_kyYYNYYZrcT04Cb2CmXOb7tnw@mail.gmail.com>
Message-ID: <26D2A71D-FA31-4479-A535-BA7A96535EC7@enduringinvestments.com>

No particular reason for sendmailR...I will try mailR and thanks!



On Oct 8, 2015, at 4:49 PM, Frans Marcelissen <fransiepansiekevertje at gmail.com<mailto:fransiepansiekevertje at gmail.com>> wrote:

Hi Michael,
I don't know whether there is a particulal reason for using sendmailR, but I use mailR for this without any problem.
mailR::send.mail(from, to, subject = "", body = "", encoding = "iso-8859-1",
  html = FALSE, inline = FALSE, smtp = list(), authenticate = FALSE,
  send = TRUE, attach.files = NULL, debug = FALSE, ...)

If you use an external smtp server, enter login name and password in parameter smtp as follows:
smtp = list(host.name<http://host.name> = "smtp.XXXXX", port = XXXXX, user.name<http://user.name> = "XXXXX", passwd = "XXXXX", ssl = XXXXX)

2015-10-08 18:49 GMT+02:00 Michael Ashton <m.ashton at enduringinvestments.com<mailto:m.ashton at enduringinvestments.com>>:
For some time I have been using sendmailR to generate a simple message when a report was done running.

Recently, I started adding a couple of pertinent statistics in the body of the email.

Now, I've finally decided that what the heck, I ought to simply attach the report itself to the email. The report is generated as a pdf file.

I can't seem to get this to work in any simple way with mime_part; if I specify a path to the file it simply assumes that "P:/blablabla/thefile.pdf" is a message I want to put in a text file attachment.

I assume I am doing something incorrectly and likely something simple. But maybe there is a clever trick I am missing. My send line is simply:

sendmail(from,to,subject,body,control=list(smtpServer="mail.optonline.net<http://mail.optonline.net>"))

where body is something like this:

body <- list("Here's your stupid file",mime_part(x="P:/partofpath/ thefile.pdf",name="file.pdf"))

Any suggestions are welcome!

Thanks,

Mike

________________________________
This email and any attachments are confidential and inte...{{dropped:9}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.

	[[alternative HTML version deleted]]


From paul at stat.auckland.ac.nz  Fri Oct  9 00:11:35 2015
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Fri, 9 Oct 2015 11:11:35 +1300
Subject: [R] [FORGED] How to remove the grid around the plot(ca(...))
 function?
In-Reply-To: <CABQyo865rohyny+J_nhhzko9+Dq_c53ywr+9N=ByqJ6d31mZig@mail.gmail.com>
References: <CABQyo865rohyny+J_nhhzko9+Dq_c53ywr+9N=ByqJ6d31mZig@mail.gmail.com>
Message-ID: <5616EA17.6020204@stat.auckland.ac.nz>

Hi

The plot.ca() function contains explicit calls to axis(), box(), and 
abline(), so, for example, ...

  plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="", axes=FALSE)

... does not work.

One option is draw-it-yourself (as suggested by David Carlson), another 
option is to copy the function source and write your own version that 
has those axis(), box(), and abline() calls removed (not recommended for 
a number of reasons), and another option is like this ...

# Draw original plot
plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="")
# Generate 'grid' version of the plot
library(gridGraphics)
grid.echo()
# What has been drawn?
grid.ls()
# Remove whichever bits you want
grid.remove("axis", grep=TRUE, global=TRUE)
grid.remove("box", grep=TRUE)
grid.remove("abline", grep=TRUE, global=TRUE)

Paul

On 09/10/15 07:06, Luca Meyer wrote:
> Hello R-experts,
>
> Could anyone suggest how I can remove the grid coming out of the
> plot(ca(...)) function?
>
> For instance I have:
>
> library(ca)
> v1 <- c(10,15,20,15,25)
> v2 <- c(23,4,7,12,2)
> v3 <- c(10,70,2,3,7)
> d1 <- data.frame(v1,v2,v3)
> rownames(d1) <- c("B1","B2","B3","B4","B5")
> plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="")
>
> As you can I could remove the X and Y axis label, but basically I am
> looking for a chart containing only the data points - with relative inertia
> represented by their size - and labels with no extra lines or number, any
> clue on how I can do that?
>
> Thank you,
>
> Luca
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From r.turner at auckland.ac.nz  Fri Oct  9 00:19:56 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 9 Oct 2015 11:19:56 +1300
Subject: [R] [FORGED]  Time Series Daily Frequency Part of a Year
In-Reply-To: <CAEPzg1Qkf3D_ETa9w2us5TUw7FYH0x63YZqAwB+FTrVVS286bg@mail.gmail.com>
References: <CAEPzg1Qkf3D_ETa9w2us5TUw7FYH0x63YZqAwB+FTrVVS286bg@mail.gmail.com>
Message-ID: <5616EC0C.1030103@auckland.ac.nz>


I have made no attempt to think deeply about this, but it seems to me 
that the structure of your data does not fit into any "standard" time 
series model.

You would appear to have a number (how many?) of *intrinsically finite* 
time series.  In a sense you have a number of "multivariate" 
observations, where the dimension of your observations is 92.

You may be able to model the covariance structure of your data in some 
time-series-ish way (ARMA, I guess).

Is it reasonable to assume that your observations are iid over years
(i.e. that the mean level or trend is the same from year to year)?

I'm pretty sure that you will need to assume that the covariance 
structure is the same from year to year, in order to get anywhere.

There *may* be material on models for this sort of data somewhere in the 
literature.  Googling "multiple short time series" turned up a number of 
hits, some of which could be useful to you.  If not, then you've got a 
bit of a research project on your hands.

Almost surely you will have to write your own fitting code to fit a 
model to such data.

Good luck!

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 08/10/15 10:23, zod jones wrote:
> My data consist of daily sales figures for multiple products but only for a
> 3 month period each year (Oct., Nov., Dec). The goal is to forecast the
> daily sales figures for the following year *by day* (the following Oct.,
> Nov., Dec.) So, I'd like to forecast what sales for product X will be on
> Nov. 12th of the next year (and each day of those three months), for
> example.
>
> I am just conceptually stuck on the fact that the time series is "yearly"
> in one sense but the daily observations only occur for those 3 months. The
> rest of the year is not really 0 -- the products are not even for sale the
> rest of the year (these are tickets for events). The frequency seems like
> it should be 92 days.
>
> Hoping someone can just point me in the right direction conceptually.


From oma.gonzales at gmail.com  Fri Oct  9 00:45:13 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Thu, 8 Oct 2015 17:45:13 -0500
Subject: [R] regex - extracting 2 numbers and " from strings
Message-ID: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>

Hi I have a vector of 100 elementos like this ones:

a <- c("SMART TV LCD FHD 70\" LC70LE660", "LED FULL HD 58'' LE58D3140")

I want to put just the (70\") and (58'') in a vector b.

This is my try, but is not working:

b <- grepl('^[0-9]{2}""$',a)

Any hint is welcome, thanks.

	[[alternative HTML version deleted]]


From r at catwhisker.org  Fri Oct  9 01:03:32 2015
From: r at catwhisker.org (David Wolfskill)
Date: Thu, 8 Oct 2015 16:03:32 -0700
Subject: [R] regex - extracting 2 numbers and " from strings
In-Reply-To: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>
References: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>
Message-ID: <20151008230332.GB1337@albert.catwhisker.org>

On Thu, Oct 08, 2015 at 05:45:13PM -0500, Omar Andr? Gonz?les D?az wrote:
> Hi I have a vector of 100 elementos like this ones:
> 
> a <- c("SMART TV LCD FHD 70\" LC70LE660", "LED FULL HD 58'' LE58D3140")
> 
> I want to put just the (70\") and (58'') in a vector b.
> 
> This is my try, but is not working:
> 
> b <- grepl('^[0-9]{2}""$',a)
> 
> Any hint is welcome, thanks.
> ...

Perhaps:

> a <- c("SMART TV LCD FHD 70\" LC70LE660", "LED FULL HD 58''
LE58D3140")
> b <- sub('^.* ([0-9]{2}(\'\'|")) .*$', "\\1", a)
> b
[1] "70\"" "58''"
> 

Peace,
david
-- 
David H. Wolfskill				r at catwhisker.org
Those who would murder in the name of God or prophet are blasphemous cowards.

See http://www.catwhisker.org/~david/publickey.gpg for my public key.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 949 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151008/69642c95/attachment.bin>

From dwinsemius at comcast.net  Fri Oct  9 01:14:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 8 Oct 2015 16:14:10 -0700
Subject: [R] regex - extracting 2 numbers and " from strings
In-Reply-To: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>
References: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>
Message-ID: <7C89AA14-6D21-49DF-B973-9C53D9409D03@comcast.net>


On Oct 8, 2015, at 3:45 PM, Omar Andr? Gonz?les D?az wrote:

> Hi I have a vector of 100 elementos like this ones:
> 
> a <- c("SMART TV LCD FHD 70\" LC70LE660", "LED FULL HD 58'' LE58D3140")
> 
> I want to put just the (70\") and (58'') in a vector b.

> sub("(^.+ )(\\d+)([\"]|[']{2})(.+$)", "\\2\\3", a)
[1] "70\"" "58''"

Also. The `stringr` package uses the code in the `stringi` package to give more compact expressions. You might want to look at 

str_extract	Extract matching patterns from a string.
str_extract_all	Extract matching patterns from a string.


> 
> This is my try, but is not working:
> 
> b <- grepl('^[0-9]{2}""$',a)
> 
> Any hint is welcome, thanks.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Oct  9 03:07:37 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 8 Oct 2015 18:07:37 -0700
Subject: [R] regex - extracting 2 numbers and " from strings
In-Reply-To: <CAM-xyZjRht4EVmYXPckd8ETxKJiLeK2upzRx2f8HDghTcqfVMA@mail.gmail.com>
References: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>
	<7C89AA14-6D21-49DF-B973-9C53D9409D03@comcast.net>
	<CAM-xyZjRht4EVmYXPckd8ETxKJiLeK2upzRx2f8HDghTcqfVMA@mail.gmail.com>
Message-ID: <CAD4AEC5-764B-481E-B8E6-75AAB1EF9870@comcast.net>


On Oct 8, 2015, at 4:50 PM, Omar Andr? Gonz?les D?az wrote:

> David, it does work but not in all cases:

It should work if you change the "+" to  "*" in the last capture class. It makes trailing non-digit characters entirely optional.

> sub("(^.+ )(\\d+)([\"]|[']{2})(.*$)", "\\2\\3", b)
 [1] "40''" "40''" "49\"" "49\"" "28\"" "40\"" "32''" "32''" "40\"" "55\""
[11] "40\"" "24\"" "42''" "50\"" "48\"" "48\"" "48\"" "48''" "50\"" "50''"
[21] "50\"" "55\"" "55''" "55\"" "55''" "55\"" "65''" "65\"" "65''" "75\""


Moral of the story: Always post an example with the necessary complexity.
> 
> This is now my b vector, after your solution:
> 
> b <- c("40''", "40''", "49\"", "49\"", "HAIER TELEVISOR LED LE28F6600 28\"", 
> "40\"", "32''", "32''", "40\"", "55\"", "HAIER TV LED LE40B8000 FULL HD 40\"", 
> "24\"", "42''", "HAIER TELEVISOR LED LE50K5000N 50\"", "48\"", 
> "48\"", "48\"", "48''", "50\"", "50''", "50\"", "55\"", "55''", 
> "55\"", "55''", "55\"", "65''", "SAMSUNG SMART TV 65JU6500 LED UHD 65\"", 
> "65''", "75\"")
> 
> 2015-10-08 18:14 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Oct 8, 2015, at 3:45 PM, Omar Andr? Gonz?les D?az wrote:
> 
> > Hi I have a vector of 100 elementos like this ones:
> >
> > a <- c("SMART TV LCD FHD 70\" LC70LE660", "LED FULL HD 58'' LE58D3140")
> >
> > I want to put just the (70\") and (58'') in a vector b.
> 
> > sub("(^.+ )(\\d+)([\"]|[']{2})(.+$)", "\\2\\3", a)
> [1] "70\"" "58''"
> 
> Also. The `stringr` package uses the code in the `stringi` package to give more compact expressions. You might want to look at
> 
> str_extract     Extract matching patterns from a string.
> str_extract_all Extract matching patterns from a string.
> 
> 
> >
> > This is my try, but is not working:
> >
> > b <- grepl('^[0-9]{2}""$',a)
> >
> > Any hint is welcome, thanks.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From hannah.hlx at gmail.com  Fri Oct  9 04:32:18 2015
From: hannah.hlx at gmail.com (li li)
Date: Thu, 8 Oct 2015 22:32:18 -0400
Subject: [R] [FORGED] Re:  correlated binomial random variables
In-Reply-To: <5612F31A.6040108@auckland.ac.nz>
References: <CAHLnndZdzs1AJ5cTMHbsucJt=QYq8h+p0TS71b5+0J1JV_W=KQ@mail.gmail.com>
	<CAHLnndbYXB=QKNM4vb67rZYvSo7z4XpLCoMgeWy-rsnpZirW5w@mail.gmail.com>
	<5612F31A.6040108@auckland.ac.nz>
Message-ID: <CAHLnndbZjuxWqV2b_VgP4CoY06THmDCZ3qPqysU8WW92pJ+W4w@mail.gmail.com>

Thanks Dennis and Rolf. Yes. Simulation is one way. I think
correlation does not determine the joint distribution so it will not
be unique. Under specific settings, the joint probability of X, Y can
be calculated. For example, let X=X_0+X_1 and Y=X_0+X_2, with X_0
being Binomial(n_0, p) and X_1, and X_2 are both Binomial(n, p). X_0,
X_1, and X_2 are all independent. Then X, Y are correlated and P(X <=
t, Y <= t) can be exactly calculated.

Thanks!
   Hanna

2015-10-05 18:00 GMT-04:00, Rolf Turner <r.turner at auckland.ac.nz>:
> On 06/10/15 04:43, li li wrote:
>> Hi all,
>>     Using the "bindata" package, it is possible to gerenerate
>> correlated binomial random variables both with the same number of
>> trials, say n. I am wondering whether there is an R function to
>> calculate the joint probability distribution of the correlated
>> binomial random variables. Say if X is binomial (n, p1) and Y is
>> binomial (n, p2) and the correlation between X and Y is rho and we
>> want to calculate
>> P(X <= c, Y <= c).
>
> (1) The use of correlation in the context of binary or binomial variates
> makes little or no sense, it seems to me.  Correlation is basically
> useful for quantifying linear relationships between continuous variates.
> Linear relationships between count variates are of at best limited
> interest.
>
> (2) I suspect that the correlation does not determine a unique joint
> distribution of X and Y.  If my suspicion is correct then there is not a
> unique (well-defined) answer to the question "What is
> Pr(X <= x, Y <= y)?"
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>


From zodjones at gmail.com  Fri Oct  9 00:44:39 2015
From: zodjones at gmail.com (zod jones)
Date: Thu, 8 Oct 2015 17:44:39 -0500
Subject: [R] [FORGED]  Time Series Daily Frequency Part of a Year
In-Reply-To: <5616EC0C.1030103@auckland.ac.nz>
References: <CAEPzg1Qkf3D_ETa9w2us5TUw7FYH0x63YZqAwB+FTrVVS286bg@mail.gmail.com>
	<5616EC0C.1030103@auckland.ac.nz>
Message-ID: <CAEPzg1Q5qtLh=zGO0-JW-csMiYybpQNQD7a9nM10VM7hTMXb2w@mail.gmail.com>

Thanks for the reply. I thought I'd find more on this by searching for
course enrollment forecasting because the events I'm dealing with are
essentially like courses that need to be compared year on year (over many
years). But the info I found relating to models for enrollment were only
aggregated (university enrollment overall and not specific courses only for
one term or semester compared year on year by date, etc.) I think maybe the
"date" part is just throwing me off -- they are really 92 data points and
not part of normal time series. That is my guess, anyway.

I'll do more research on multiple short time series and see where I get.
Thanks! Zodran

	[[alternative HTML version deleted]]


From curtis_browne97 at hotmail.com  Fri Oct  9 01:37:19 2015
From: curtis_browne97 at hotmail.com (Curtis Browne)
Date: Fri, 9 Oct 2015 09:37:19 +1000
Subject: [R] Help using "replicate()" for two commands
Message-ID: <BLU407-EAS671E01EBB4B5F501C491F497350@phx.gbl>

I would like to essentially do a randomization p-test (10,000 replications in this case) to check how often I would see a linear correlation in my data as strong or stronger than I did with the original data (with a correlation value of 0.9796619). The code which I thought would work is below:

sum(replicate(10000,data$Scram <- sample(data$Changeinmass,10, replace = FALSE); with(data,cor(Current,data$Scram))>=0.9796619))/10000

With the error:

Error: unexpected ';' in "sum(replicate(10000,data$Scram <- sample(data$Changeinmass,10, replace = FALSE);"

Is there any method of replicating both the function of assigning a random sample of the data to a column, and the function of then performing a Pearson correlation test between data$Current and data$Scram?

	[[alternative HTML version deleted]]


From kpmainali at gmail.com  Fri Oct  9 07:15:18 2015
From: kpmainali at gmail.com (Kumar Mainali)
Date: Fri, 9 Oct 2015 01:15:18 -0400
Subject: [R] Help with color.scale {plotrix}
Message-ID: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>

Hi Jim and others:

I needed color code for some color gradients in color.scale function. I
found that the following translates to green to yellow to
red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
gradient? I would like to know the gradient code for red to yellow, yellow
to green and other ranges.

Thanks,
Kumar Mainali

Postdoctoral Associate
Department of Biology
University of Maryland, College Park

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct  9 09:22:17 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 9 Oct 2015 09:22:17 +0200
Subject: [R] Help using "replicate()" for two commands
In-Reply-To: <BLU407-EAS671E01EBB4B5F501C491F497350@phx.gbl>
References: <BLU407-EAS671E01EBB4B5F501C491F497350@phx.gbl>
Message-ID: <E6CE2D3B-05D4-46A7-8D9E-5DDCAD5F448A@gmail.com>

A set of curlies should help.

As in
> replicate(5, {y <- runif(20); mean(y)})
[1] 0.4926800 0.5356511 0.5343938 0.5313422 0.5287927

-pd

BTW: sum(replicate(10000,...))/10000 is simpler and less error-prone written as mean(replicate(10000,....))

> On 09 Oct 2015, at 01:37 , Curtis Browne <curtis_browne97 at hotmail.com> wrote:
> 
> I would like to essentially do a randomization p-test (10,000 replications in this case) to check how often I would see a linear correlation in my data as strong or stronger than I did with the original data (with a correlation value of 0.9796619). The code which I thought would work is below:
> 
> sum(replicate(10000,data$Scram <- sample(data$Changeinmass,10, replace = FALSE); with(data,cor(Current,data$Scram))>=0.9796619))/10000
> 
> With the error:
> 
> Error: unexpected ';' in "sum(replicate(10000,data$Scram <- sample(data$Changeinmass,10, replace = FALSE);"
> 
> Is there any method of replicating both the function of assigning a random sample of the data to a column, and the function of then performing a Pearson correlation test between data$Current and data$Scram?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From drjimlemon at gmail.com  Fri Oct  9 11:01:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 9 Oct 2015 20:01:57 +1100
Subject: [R] Smoth matplot
In-Reply-To: <CAN25tHQiSFLqgVgAnUYU5FsaMSf2ka0yLpxkqahdU6Mh3bYCqQ@mail.gmail.com>
References: <CAN25tHQiSFLqgVgAnUYU5FsaMSf2ka0yLpxkqahdU6Mh3bYCqQ@mail.gmail.com>
Message-ID: <CA+8X3fUwhXVQ2u_3tTDyV6Hsc1JL+tq6C_rzptE0tZ0cuXUVbQ@mail.gmail.com>

Hi bgnumis,
This is definitely a guess at what you want to do:

flatbat<-read.table(text="100.00000 100.00000 100.00000 100.00000 100.0000
100.00000 100.00000 100.00000
 100.54163  99.23893 100.77238  98.95058 100.2250  99.18830 100.18801
101.10791
  99.61230 102.12813  99.34499  97.52805 101.8252  99.97846  95.91478
102.90392
 102.04546 100.38053 100.80122 100.10281 100.4912  98.04112 101.17684
100.16137
  97.27201 100.19247 100.43301 101.04954 102.9921  98.25110  98.31890
100.98710
 103.68170 104.95366  99.03839  99.81437 100.7232 102.47300  99.17555
 99.09212")
# define a function that will return a data frame with smoothed values
smother<-function(x) return(supsmu(1:length(x),x)$y)
# apply it to the original data frame
flatmat<-sapply(flatbat,smother)
# plot it
matplot(flatmat,type="l")

I still haven't worked out what you mean by a "smoth bell".

Jim



On Fri, Oct 9, 2015 at 7:07 AM, bgnumis bgnum <bgnumis at gmail.com> wrote:

>    Hi all,
>
> I have a matrix data and I use to plot matplot, it is suposed each column
> is a temporal series. As you see in the example the matrix o data have
> "peaks" I want to plot (using matplot or what yoy can say me) this matrix
> but with and smoothed line envoloving the values of the matrix so when
> plotted all the appearce of the lines will be smoth bell. Do you think is
> it possible.
>
> Can anyone suggest to make a tranform?
>
> Could be smotthing the lines plotted (columns) will be achieved but not
> suere if it is possible.
>
>
>
>
>
>
>
>        [,1]      [,2]      [,3]      [,4]     [,5]      [,6]      [,7]
> [1,] 100.00000 100.00000 100.00000 100.00000 100.0000 100.00000 100.00000
> [2,] 100.54163  99.23893 100.77238  98.95058 100.2250  99.18830 100.18801
> [3,]  99.61230 102.12813  99.34499  97.52805 101.8252  99.97846  95.91478
> [4,] 102.04546 100.38053 100.80122 100.10281 100.4912  98.04112 101.17684
> [5,]  97.27201 100.19247 100.43301 101.04954 102.9921  98.25110  98.31890
> [6,] 103.68170 104.95366  99.03839  99.81437 100.7232 102.47300  99.17555
>           [,8]
> [1,] 100.00000
> [2,] 101.10791
> [3,] 102.90392
> [4,] 100.16137
> [5,] 100.98710
> [6,]  99.09212
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Fri Oct  9 13:17:39 2015
From: lucam1968 at gmail.com (Luca Meyer)
Date: Fri, 9 Oct 2015 13:17:39 +0200
Subject: [R] [FORGED] How to remove the grid around the plot(ca(...))
	function?
In-Reply-To: <5616EA17.6020204@stat.auckland.ac.nz>
References: <CABQyo865rohyny+J_nhhzko9+Dq_c53ywr+9N=ByqJ6d31mZig@mail.gmail.com>
	<5616EA17.6020204@stat.auckland.ac.nz>
Message-ID: <CABQyo86=+3wgsqvYsK_3eeLPz-ngtNfsKN13Mu6ruAsugNs59A@mail.gmail.com>

That worked just fine.

Thanks Paul!

Luca

2015-10-09 0:11 GMT+02:00 Paul Murrell <paul at stat.auckland.ac.nz>:

> Hi
>
> The plot.ca() function contains explicit calls to axis(), box(), and
> abline(), so, for example, ...
>
>  plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="", axes=FALSE)
>
> ... does not work.
>
> One option is draw-it-yourself (as suggested by David Carlson), another
> option is to copy the function source and write your own version that has
> those axis(), box(), and abline() calls removed (not recommended for a
> number of reasons), and another option is like this ...
>
> # Draw original plot
> plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="")
> # Generate 'grid' version of the plot
> library(gridGraphics)
> grid.echo()
> # What has been drawn?
> grid.ls()
> # Remove whichever bits you want
> grid.remove("axis", grep=TRUE, global=TRUE)
> grid.remove("box", grep=TRUE)
> grid.remove("abline", grep=TRUE, global=TRUE)
>
> Paul
>
> On 09/10/15 07:06, Luca Meyer wrote:
>
>> Hello R-experts,
>>
>> Could anyone suggest how I can remove the grid coming out of the
>> plot(ca(...)) function?
>>
>> For instance I have:
>>
>> library(ca)
>> v1 <- c(10,15,20,15,25)
>> v2 <- c(23,4,7,12,2)
>> v3 <- c(10,70,2,3,7)
>> d1 <- data.frame(v1,v2,v3)
>> rownames(d1) <- c("B1","B2","B3","B4","B5")
>> plot(ca(d1), mass = c(TRUE,FALSE), xlab="", ylab="")
>>
>> As you can I could remove the X and Y axis label, but basically I am
>> looking for a chart containing only the data points - with relative
>> inertia
>> represented by their size - and labels with no extra lines or number, any
>> clue on how I can do that?
>>
>> Thank you,
>>
>> Luca
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Fri Oct  9 13:24:18 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Fri, 9 Oct 2015 22:24:18 +1100
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
Message-ID: <CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>

Hi Kumar,
The color.scale function translates numeric values into one or more
intervals of color by a linear transformation into the numeric values that
specify colors. One of three color spaces (rgb, hcl and hsv) can be
specified, and the endpoints can be specified as "extremes=c(<minimum
color>,<maximum color>" or as three vectors of numbers. By default, the RGB
color space is used, so:

# starts at RGB #FF0000 and finishes at RGB #FFFF00
red to yellow - extremes=c("red","yellow") OR cs1=c(1,1),cs2=(c(0,1),cs3=0
# starts at RGB #FFFF00 and finishes at RGB #00FF00
yellow to green - extremes=c("yellow","green") OR
cs1=c(1,0),cs2=(c(1,1),cs3=0

Obviously the shades of colors that you want may differ from the above, so
you have to play with the values to get the ones you want. In many cases,
you will have to specify more than two numbers for the color specs to get
the "in between" colors right, especially if the span of the colors is
large.

Jim

On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com> wrote:

> Hi Jim and others:
>
> I needed color code for some color gradients in color.scale function. I
> found that the following translates to green to yellow to
> red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
> gradient? I would like to know the gradient code for red to yellow, yellow
> to green and other ranges.
>
> Thanks,
> Kumar Mainali
>
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
>

	[[alternative HTML version deleted]]


From roger.bos at rothschild.com  Fri Oct  9 14:55:28 2015
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 9 Oct 2015 12:55:28 +0000
Subject: [R] Attaching a pdf file to an email generated with sendmailR?
In-Reply-To: <26D2A71D-FA31-4479-A535-BA7A96535EC7@enduringinvestments.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74B649AD9A32@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAFFQM6Ygw53nmCjiVeN=8+Tj_kyYYNYYZrcT04Cb2CmXOb7tnw@mail.gmail.com>
	<26D2A71D-FA31-4479-A535-BA7A96535EC7@enduringinvestments.com>
Message-ID: <0765308CD028654885F30322557308D81EFA1423@NYCSM0208.rth.ad.rothschild.com>

Michael,

I use sendmailR to attached a file to an email and it does work.  I remember there was something non-intuitive when I was figuring it out.  I use both the attachPath and the attachName.  The attachPath has the full path including the filename and the attachName just has the filename.  I don't why it wants the filename in both parameters, but it works for me.

emailR(to = "someone at email.com", subject = "Morning Notes", msg = msg, attachPath = newwd %+% fnameNotes, attachName = fnameNotes)

> fnameNotes
[1] "morningNotes_20151009.html"
> newwd %+% fnameNotes
[1] "//rinnycs0051/research/R_HOME_Research/Markdown/morningNotes/morningNotes_20151009.html"
> fnameNotes
[1] "morningNotes_20151009.html"

Thanks,

Roger







***************************************************************
This message and any attachments are for the intended recipient's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies.  You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Ashton
Sent: Thursday, October 08, 2015 5:24 PM
To: Frans Marcelissen
Cc: r-help at r-project.org
Subject: Re: [R] Attaching a pdf file to an email generated with sendmailR?

No particular reason for sendmailR...I will try mailR and thanks!



On Oct 8, 2015, at 4:49 PM, Frans Marcelissen <fransiepansiekevertje at gmail.com<mailto:fransiepansiekevertje at gmail.com>> wrote:

Hi Michael,
I don't know whether there is a particulal reason for using sendmailR, but I use mailR for this without any problem.
mailR::send.mail(from, to, subject = "", body = "", encoding = "iso-8859-1",
  html = FALSE, inline = FALSE, smtp = list(), authenticate = FALSE,
  send = TRUE, attach.files = NULL, debug = FALSE, ...)

If you use an external smtp server, enter login name and password in parameter smtp as follows:
smtp = list(host.name<http://host.name> = "smtp.XXXXX", port = XXXXX, user.name<http://user.name> = "XXXXX", passwd = "XXXXX", ssl = XXXXX)

2015-10-08 18:49 GMT+02:00 Michael Ashton <m.ashton at enduringinvestments.com<mailto:m.ashton at enduringinvestments.com>>:
For some time I have been using sendmailR to generate a simple message when a report was done running.

Recently, I started adding a couple of pertinent statistics in the body of the email.

Now, I've finally decided that what the heck, I ought to simply attach the report itself to the email. The report is generated as a pdf file.

I can't seem to get this to work in any simple way with mime_part; if I specify a path to the file it simply assumes that "P:/blablabla/thefile.pdf" is a message I want to put in a text file attachment.

I assume I am doing something incorrectly and likely something simple. But maybe there is a clever trick I am missing. My send line is simply:

sendmail(from,to,subject,body,control=list(smtpServer="mail.optonline.net<http://mail.optonline.net>"))

where body is something like this:

body <- list("Here's your stupid file",mime_part(x="P:/partofpath/ thefile.pdf",name="file.pdf"))

Any suggestions are welcome!

Thanks,

Mike

________________________________
This email and any attachments are confidential and inte...{{dropped:9}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


________________________________
This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From kpmainali at gmail.com  Fri Oct  9 17:16:42 2015
From: kpmainali at gmail.com (Kumar Mainali)
Date: Fri, 9 Oct 2015 11:16:42 -0400
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
Message-ID: <CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>

Hi Jim,

Thank you! Your color code does work. I still do not understand how red to
yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In other
words, I have RGB values for red and yellow. How do I go from there to the
code you sent?

Another question: some of my matrices have missing cells and I do not want
to assign any colors to the missing cells. The following code gives me
error. I am trying to use the output (cellcol) to the
function color2D.matplot.

> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
  NAs are not allowed in subscripted assignments
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
?

Postdoctoral Associate
Department of Biology
University of Maryland, College Park

On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Kumar,
> The color.scale function translates numeric values into one or more
> intervals of color by a linear transformation into the numeric values that
> specify colors. One of three color spaces (rgb, hcl and hsv) can be
> specified, and the endpoints can be specified as "extremes=c(<minimum
> color>,<maximum color>" or as three vectors of numbers. By default, the RGB
> color space is used, so:
>
> # starts at RGB #FF0000 and finishes at RGB #FFFF00
> red to yellow - extremes=c("red","yellow") OR cs1=c(1,1),cs2=(c(0,1),cs3=0
> # starts at RGB #FFFF00 and finishes at RGB #00FF00
> yellow to green - extremes=c("yellow","green") OR
> cs1=c(1,0),cs2=(c(1,1),cs3=0
>
> Obviously the shades of colors that you want may differ from the above, so
> you have to play with the values to get the ones you want. In many cases,
> you will have to specify more than two numbers for the color specs to get
> the "in between" colors right, especially if the span of the colors is
> large.
>
> Jim
>
> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com> wrote:
>
>> Hi Jim and others:
>>
>> I needed color code for some color gradients in color.scale function. I
>> found that the following translates to green to yellow to
>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
>> gradient? I would like to know the gradient code for red to yellow, yellow
>> to green and other ranges.
>>
>> Thanks,
>> Kumar Mainali
>>
>> Postdoctoral Associate
>> Department of Biology
>> University of Maryland, College Park
>>
>
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Fri Oct  9 17:43:39 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Fri, 9 Oct 2015 16:43:39 +0100 (BST)
Subject: [R] Why can I reset directory in using setwd on desktop but not on
 laptop
Message-ID: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>

Hi  I am running the same r routine on both my desktop and my laptop, and
writing results in the form of csv files into storage folders in the respective
users/documents files of both machines  My desktop machine allows me to reset
the directory in the course of the r programme so that I can write the files
into different folders which makes it easier to keep track of what's what,
whereas my laptop won't allow me to reset the directory by a setwd command, and
I have to set the directory manually using the r studio tabs, so basically on
the laptop every results file is going into the same folder, which is not
unworkable but not as easy to use later

As far as I know I have the same r studio on both machines.  Does anyone out
there know a) why I can't use a setwd command on the laptop, and b)is there
anything I can do to put this right?

Thanks beforehand, as it were

Nick Wray
	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Oct  9 17:48:14 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Oct 2015 11:48:14 -0400
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
	<CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
Message-ID: <CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>

Hi Kumar,

You're overthinking it:

in RGB, colorspace, cs1 is red, cs2 is green, cs3 is blue.
So if cs1=c(1,1),cs2=(c(0,1),cs3=0 (or c(0,0) because of R's recycling)
the first color in the sequence is c(1, 0, 0) or red ##FF0000 and the
second color is c(1, 1, 0) #FFFF00 or yellow.

Sarah

On Fri, Oct 9, 2015 at 11:16 AM, Kumar Mainali <kpmainali at gmail.com> wrote:
> Hi Jim,
>
> Thank you! Your color code does work. I still do not understand how red to
> yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In other
> words, I have RGB values for red and yellow. How do I go from there to the
> code you sent?
>
> Another question: some of my matrices have missing cells and I do not want
> to assign any colors to the missing cells. The following code gives me
> error. I am trying to use the output (cellcol) to the
> function color2D.matplot.
>
>> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
>> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
> Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
>   NAs are not allowed in subscripted assignments
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
> ?
>
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
>
> On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Kumar,
>> The color.scale function translates numeric values into one or more
>> intervals of color by a linear transformation into the numeric values that
>> specify colors. One of three color spaces (rgb, hcl and hsv) can be
>> specified, and the endpoints can be specified as "extremes=c(<minimum
>> color>,<maximum color>" or as three vectors of numbers. By default, the RGB
>> color space is used, so:
>>
>> # starts at RGB #FF0000 and finishes at RGB #FFFF00
>> red to yellow - extremes=c("red","yellow") OR cs1=c(1,1),cs2=(c(0,1),cs3=0
>> # starts at RGB #FFFF00 and finishes at RGB #00FF00
>> yellow to green - extremes=c("yellow","green") OR
>> cs1=c(1,0),cs2=(c(1,1),cs3=0
>>
>> Obviously the shades of colors that you want may differ from the above, so
>> you have to play with the values to get the ones you want. In many cases,
>> you will have to specify more than two numbers for the color specs to get
>> the "in between" colors right, especially if the span of the colors is
>> large.
>>
>> Jim
>>
>> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com> wrote:
>>
>>> Hi Jim and others:
>>>
>>> I needed color code for some color gradients in color.scale function. I
>>> found that the following translates to green to yellow to
>>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
>>> gradient? I would like to know the gradient code for red to yellow, yellow
>>> to green and other ranges.
>>>
>>> Thanks,
>>> Kumar Mainali
>>>


From sarah.goslee at gmail.com  Fri Oct  9 17:51:06 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Oct 2015 11:51:06 -0400
Subject: [R] Why can I reset directory in using setwd on desktop but not
 on laptop
In-Reply-To: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
References: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
Message-ID: <CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>

Sounds like an RStudio question to me. Someone might be able to help,
but this mailing list is for R.

You should also provide sessionInfo() output when asking potentially
OS-related questions.

You can always specify path as part of the write.csv() or other output
command; you don't need to change the working directory necessarily.

Sarah

On Fri, Oct 9, 2015 at 11:43 AM, WRAY NICHOLAS
<nicholas.wray at ntlworld.com> wrote:
> Hi  I am running the same r routine on both my desktop and my laptop, and
> writing results in the form of csv files into storage folders in the respective
> users/documents files of both machines  My desktop machine allows me to reset
> the directory in the course of the r programme so that I can write the files
> into different folders which makes it easier to keep track of what's what,
> whereas my laptop won't allow me to reset the directory by a setwd command, and
> I have to set the directory manually using the r studio tabs, so basically on
> the laptop every results file is going into the same folder, which is not
> unworkable but not as easy to use later
>
> As far as I know I have the same r studio on both machines.  Does anyone out
> there know a) why I can't use a setwd command on the laptop, and b)is there
> anything I can do to put this right?
>
> Thanks beforehand, as it were
>
> Nick Wray


From nicholas.wray at ntlworld.com  Fri Oct  9 17:58:24 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Fri, 9 Oct 2015 16:58:24 +0100 (BST)
Subject: [R] Why can I reset directory in using setwd on desktop but not
 on laptop
In-Reply-To: <CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>
References: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
	<CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>
Message-ID: <1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>

Thanks Sarah  I didn't realise that there was a distinction between between
asking about R per se and asking about r-studio...  I shall try specifying the
path and see whether that helps   Thanks, Nick

> 
>     On 09 October 2015 at 16:51 Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> 
>     Sounds like an RStudio question to me. Someone might be able to help,
>     but this mailing list is for R.
> 
>     You should also provide sessionInfo() output when asking potentially
>     OS-related questions.
> 
>     You can always specify path as part of the write.csv() or other output
>     command; you don't need to change the working directory necessarily.
> 
>     Sarah
> 
>     On Fri, Oct 9, 2015 at 11:43 AM, WRAY NICHOLAS
>     <nicholas.wray at ntlworld.com> wrote:
>     > Hi I am running the same r routine on both my desktop and my laptop, and
>     > writing results in the form of csv files into storage folders in the
>     > respective
>     > users/documents files of both machines My desktop machine allows me to
>     > reset
>     > the directory in the course of the r programme so that I can write the
>     > files
>     > into different folders which makes it easier to keep track of what's
>     > what,
>     > whereas my laptop won't allow me to reset the directory by a setwd
>     > command, and
>     > I have to set the directory manually using the r studio tabs, so
>     > basically on
>     > the laptop every results file is going into the same folder, which is
>     > not
>     > unworkable but not as easy to use later
>     >
>     > As far as I know I have the same r studio on both machines. Does anyone
>     > out
>     > there know a) why I can't use a setwd command on the laptop, and b)is
>     > there
>     > anything I can do to put this right?
>     >
>     > Thanks beforehand, as it were
>     >
>     > Nick Wray
> 
	[[alternative HTML version deleted]]


From davidsmi at microsoft.com  Fri Oct  9 18:14:46 2015
From: davidsmi at microsoft.com (David Smith)
Date: Fri, 9 Oct 2015 16:14:46 +0000
Subject: [R] Revolutions blog: September 2015 roundup
Message-ID: <850C9E2E-688B-4DB5-864D-4E06889171FA@microsoft.com>

Since 2008, Revolution Analytics (and now Microsoft) staff and guests have written about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month of particular interest to readers of r-help. 

In case you missed them, here are some articles related to R from the month of September:

A tutorial on using R with Jupyter Notebooks http://blog.revolutionanalytics.com/2015/09/using-r-with-jupyter-notebooks.html and how to control the size of R graphics therein: http://blog.revolutionanalytics.com/2015/09/resizing-plots-in-the-r-kernel-for-jupyter-notebooks.html

A new version of Revolution R Open is available, featuring multi-threaded computing for R 3.2.2: http://blog.revolutionanalytics.com/2015/09/revolution-r-open-322-now-available.html 

One benefit of fitting statistical models to large data sets: learning curves http://blog.revolutionanalytics.com/2015/09/why-big-data-learning-curves.html

Using the AzureML package to publish R functions as web services: http://blog.revolutionanalytics.com/2015/09/publishing-r-models-as-a-service-with-azure-ml.html

The R Consortium forms a committee to oversee projects, headed by Hadley Wickham: http://blog.revolutionanalytics.com/2015/09/the-r-consortium-gears-up-for-business.html

Functions for interpolation in R: http://blog.revolutionanalytics.com/2015/09/interpolation-and-smoothing-functions-in-base-r.html

The EARL London conference (preview here: http://blog.revolutionanalytics.com/2015/09/a-preview-of-the-earl-conference.html) included many applications of R, from AstraZeneca, Allstate, Douwe Egberts coffee and others: http://blog.revolutionanalytics.com/2015/09/applications-of-r-at-earl-2015.html

A new online Data Science and Machine Learning course, featuring R and sponsored by Microsoft: http://blog.revolutionanalytics.com/2015/09/edx-data-science.html

Reading financial time series data into R with the zoo package: http://blog.revolutionanalytics.com/2015/09/reading-financial-time-series-with-r.html

An update to the checkpoint package brings support for knitr and rmarkdown documents in reproducible projects: http://blog.revolutionanalytics.com/2015/09/new-features-in-checkpoint-v0315-now-on-cran.html

The new Microsoft Data Science User Group Program offers sponsorships for R user groups worldwide: http://blog.revolutionanalytics.com/2015/09/the-new-microsoft-data-science-user-group-program.html

A series on model validation in R using: basic methods http://blog.revolutionanalytics.com/2015/09/how-do-you-know-if-yoru-model-is-going-to-work-part-1-the-problem.html; in-training set measures http://blog.revolutionanalytics.com/2015/09/how-do-you-know-if-your-model-is-going-to-work-part-2-in-training-set-measures.html; out-of-sample procedures http://blog.revolutionanalytics.com/2015/09/how-do-you-know-if-your-model-is-going-to-work-part-3-out-of-sample-procedures.html; and cross-validation techniques http://blog.revolutionanalytics.com/2015/09/how-do-you-know-if-your-model-is-going-to-work-part-4-cross-validation-techniques-1.html 

BlueSky Statistics, a new open-source GUI for R: http://blog.revolutionanalytics.com/2015/09/bluesky-statistics.html

Accessing data in Google spreadsheets with the googlesheets package: http://blog.revolutionanalytics.com/2015/09/using-the-googlesheets-package-to-work-with-google-sheets.html

Antony Unwin on the care of datasets in R packages: http://blog.revolutionanalytics.com/2015/09/looking-after-datasets.html

General interest stories (not related to R) in the past month included: building a scale model of the solar system (http://blog.revolutionanalytics.com/2015/09/a-scale-model-of-the-solar-system.html), a new way to visualize the DFT (http://blog.revolutionanalytics.com/2015/09/because-its-friday-visualizing-ffts.html), and a Portal-themed remodel (http://blog.revolutionanalytics.com/2015/09/portal-bedroom.html).

Meeting times for local R user groups (http://blog.revolutionanalytics.com/local-r-groups.html) can be found on the updated R Community Calendar at: http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries from previous months at http://blog.revolutionanalytics.com/roundups/. You can receive daily blog posts via email using services like blogtrottr.com, or join the Revolution Analytics mailing list at http://revolutionanalytics.com/newsletter to be alerted to new articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions to me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David


-- 
David M Smith <davidsmi at microsoft.com>
R Community Lead, Microsoft
Twitter: @revodavid
Blog:  http://blog.revolutionanalytics.com <http://blog.revolutionanalytics.com/>
We?re hiring! http://azuremljobs.github.io/

From sarah.goslee at gmail.com  Fri Oct  9 18:19:29 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Oct 2015 12:19:29 -0400
Subject: [R] Why can I reset directory in using setwd on desktop but not
 on laptop
In-Reply-To: <1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
References: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
	<CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>
	<1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
Message-ID: <CAM_vjun8Bknb2QuVnOiiOtNG1FQzJh_qRGZ7MXnKqMQbT71sfA@mail.gmail.com>

On Fri, Oct 9, 2015 at 11:58 AM, WRAY NICHOLAS
<nicholas.wray at ntlworld.com> wrote:
> Thanks Sarah  I didn't realise that there was a distinction between between
> asking about R per se and asking about r-studio...  I shall try specifying
> the path and see whether that helps   Thanks, Nick

Yes, R-Studio is a commercial product (with a free and OSS version)
that builds on R, and not part of the R Project. You can get R-Studio
support here:
https://support.rstudio.com/hc/en-us


> On 09 October 2015 at 16:51 Sarah Goslee <sarah.goslee at gmail.com> wrote:
>
>
> Sounds like an RStudio question to me. Someone might be able to help,
> but this mailing list is for R.
>
> You should also provide sessionInfo() output when asking potentially
> OS-related questions.
>
> You can always specify path as part of the write.csv() or other output
> command; you don't need to change the working directory necessarily.
>
> Sarah
>
> On Fri, Oct 9, 2015 at 11:43 AM, WRAY NICHOLAS
> <nicholas.wray at ntlworld.com> wrote:
>> Hi I am running the same r routine on both my desktop and my laptop, and
>> writing results in the form of csv files into storage folders in the
>> respective
>> users/documents files of both machines My desktop machine allows me to
>> reset
>> the directory in the course of the r programme so that I can write the
>> files
>> into different folders which makes it easier to keep track of what's what,
>> whereas my laptop won't allow me to reset the directory by a setwd
>> command, and
>> I have to set the directory manually using the r studio tabs, so basically
>> on
>> the laptop every results file is going into the same folder, which is not
>> unworkable but not as easy to use later
>>
>> As far as I know I have the same r studio on both machines. Does anyone
>> out
>> there know a) why I can't use a setwd command on the laptop, and b)is
>> there
>> anything I can do to put this right?
>>
>> Thanks beforehand, as it were
>>
>> Nick Wray


From yongnam.kim at wisc.edu  Fri Oct  9 18:19:18 2015
From: yongnam.kim at wisc.edu (Yongnam Kim)
Date: Fri, 09 Oct 2015 16:19:18 +0000
Subject: [R] importing spss files without value labels
Message-ID: <CAEazi5_hDktZ0B7FgWkdggJerUQZgS2h=Ufu8cibO=4qnJum6Q@mail.gmail.com>

Hi all,

I know how to import spss data file (.sav) to R using foreign pkg like
read.spss(file, use.value.labels = FALSE,...) but I like to use a different
pkg, in particular, memisc. Is there any corresponding way to drop the
value labels when importing?

Many thanks,

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct  9 20:43:47 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Oct 2015 11:43:47 -0700
Subject: [R] importing spss files without value labels
In-Reply-To: <CAEazi5_hDktZ0B7FgWkdggJerUQZgS2h=Ufu8cibO=4qnJum6Q@mail.gmail.com>
References: <CAEazi5_hDktZ0B7FgWkdggJerUQZgS2h=Ufu8cibO=4qnJum6Q@mail.gmail.com>
Message-ID: <5D38B93F-22FD-4F77-BF49-7753D62A327E@comcast.net>


On Oct 9, 2015, at 9:19 AM, Yongnam Kim wrote:

> Hi all,
> 
> I know how to import spss data file (.sav) to R using foreign pkg like
> read.spss(file, use.value.labels = FALSE,...) but I like to use a different
> pkg, in particular, memisc. Is there any corresponding way to drop the
> value labels when importing?
> 
> Many thanks,
> 
> 	[[alternative HTML version deleted]]

This is the third day in a row that you have posted an identical message. You should be asking yourself why you have not gotten any answers. One possibility is that people do not have any copies of an spss file that they can use for testing. You might consider posting a link to one. You should also read the Posting Guide: 

  http://www.R-project.org/posting-guide.html

And also read the linked classic article by Eric Raymond that discusses how to proerly ask a technical question on a technical forum.

> 

And as always .... do post in plain text.

-- 

David Winsemius
Alameda, CA, USA


From oma.gonzales at gmail.com  Fri Oct  9 20:53:14 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 9 Oct 2015 13:53:14 -0500
Subject: [R] regex - extracting 2 numbers and " from strings
In-Reply-To: <CAD4AEC5-764B-481E-B8E6-75AAB1EF9870@comcast.net>
References: <CAM-xyZjcNG-Wpuk3GQ3S51h3HnfuL39WNyqxpY14-UsSuy7fvg@mail.gmail.com>
	<7C89AA14-6D21-49DF-B973-9C53D9409D03@comcast.net>
	<CAM-xyZjRht4EVmYXPckd8ETxKJiLeK2upzRx2f8HDghTcqfVMA@mail.gmail.com>
	<CAD4AEC5-764B-481E-B8E6-75AAB1EF9870@comcast.net>
Message-ID: <CAM-xyZj4pgHrNCKCNoJu0i_VjGY28uPCS3Jjs-ByrWoUGTnXbQ@mail.gmail.com>

Yes, you are right. Thank you.

2015-10-08 20:07 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Oct 8, 2015, at 4:50 PM, Omar Andr? Gonz?les D?az wrote:
>
> > David, it does work but not in all cases:
>
> It should work if you change the "+" to  "*" in the last capture class. It
> makes trailing non-digit characters entirely optional.
>
> > sub("(^.+ )(\\d+)([\"]|[']{2})(.*$)", "\\2\\3", b)
>  [1] "40''" "40''" "49\"" "49\"" "28\"" "40\"" "32''" "32''" "40\"" "55\""
> [11] "40\"" "24\"" "42''" "50\"" "48\"" "48\"" "48\"" "48''" "50\"" "50''"
> [21] "50\"" "55\"" "55''" "55\"" "55''" "55\"" "65''" "65\"" "65''" "75\""
>
>
> Moral of the story: Always post an example with the necessary complexity.
> >
> > This is now my b vector, after your solution:
> >
> > b <- c("40''", "40''", "49\"", "49\"", "HAIER TELEVISOR LED LE28F6600
> 28\"",
> > "40\"", "32''", "32''", "40\"", "55\"", "HAIER TV LED LE40B8000 FULL HD
> 40\"",
> > "24\"", "42''", "HAIER TELEVISOR LED LE50K5000N 50\"", "48\"",
> > "48\"", "48\"", "48''", "50\"", "50''", "50\"", "55\"", "55''",
> > "55\"", "55''", "55\"", "65''", "SAMSUNG SMART TV 65JU6500 LED UHD 65\"",
> > "65''", "75\"")
> >
> > 2015-10-08 18:14 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > On Oct 8, 2015, at 3:45 PM, Omar Andr? Gonz?les D?az wrote:
> >
> > > Hi I have a vector of 100 elementos like this ones:
> > >
> > > a <- c("SMART TV LCD FHD 70\" LC70LE660", "LED FULL HD 58'' LE58D3140")
> > >
> > > I want to put just the (70\") and (58'') in a vector b.
> >
> > > sub("(^.+ )(\\d+)([\"]|[']{2})(.+$)", "\\2\\3", a)
> > [1] "70\"" "58''"
> >
> > Also. The `stringr` package uses the code in the `stringi` package to
> give more compact expressions. You might want to look at
> >
> > str_extract     Extract matching patterns from a string.
> > str_extract_all Extract matching patterns from a string.
> >
> >
> > >
> > > This is my try, but is not working:
> > >
> > > b <- grepl('^[0-9]{2}""$',a)
> > >
> > > Any hint is welcome, thanks.
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From kpmainali at gmail.com  Fri Oct  9 21:26:40 2015
From: kpmainali at gmail.com (Kumar Mainali)
Date: Fri, 9 Oct 2015 15:26:40 -0400
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
	<CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
	<CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>
Message-ID: <CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>

Hi Sarah,

Thanks for the explanation. This solves my first problem. I hope somebody
will be able to answer my second question. Copied here from previous email
>>

Another question: some of my matrices have missing cells and I do not want
to assign any colors to the missing cells. The following code gives me
error. I am trying to use the output (cellcol) to the
function color2D.matplot.

> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
  NAs are not allowed in subscripted assignments
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf
?

Postdoctoral Associate
Department of Biology
University of Maryland, College Park

On Fri, Oct 9, 2015 at 11:48 AM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> Hi Kumar,
>
> You're overthinking it:
>
> in RGB, colorspace, cs1 is red, cs2 is green, cs3 is blue.
> So if cs1=c(1,1),cs2=(c(0,1),cs3=0 (or c(0,0) because of R's recycling)
> the first color in the sequence is c(1, 0, 0) or red ##FF0000 and the
> second color is c(1, 1, 0) #FFFF00 or yellow.
>
> Sarah
>
> On Fri, Oct 9, 2015 at 11:16 AM, Kumar Mainali <kpmainali at gmail.com>
> wrote:
> > Hi Jim,
> >
> > Thank you! Your color code does work. I still do not understand how red
> to
> > yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In other
> > words, I have RGB values for red and yellow. How do I go from there to
> the
> > code you sent?
> >
> > Another question: some of my matrices have missing cells and I do not
> want
> > to assign any colors to the missing cells. The following code gives me
> > error. I am trying to use the output (cellcol) to the
> > function color2D.matplot.
> >
> >> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> >> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
> > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
> >   NAs are not allowed in subscripted assignments
> > In addition: Warning messages:
> > 1: In min(x) : no non-missing arguments to min; returning Inf
> > 2: In max(x) : no non-missing arguments to max; returning -Inf
> > ?
> >
> > Postdoctoral Associate
> > Department of Biology
> > University of Maryland, College Park
> >
> > On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >
> >> Hi Kumar,
> >> The color.scale function translates numeric values into one or more
> >> intervals of color by a linear transformation into the numeric values
> that
> >> specify colors. One of three color spaces (rgb, hcl and hsv) can be
> >> specified, and the endpoints can be specified as "extremes=c(<minimum
> >> color>,<maximum color>" or as three vectors of numbers. By default, the
> RGB
> >> color space is used, so:
> >>
> >> # starts at RGB #FF0000 and finishes at RGB #FFFF00
> >> red to yellow - extremes=c("red","yellow") OR
> cs1=c(1,1),cs2=(c(0,1),cs3=0
> >> # starts at RGB #FFFF00 and finishes at RGB #00FF00
> >> yellow to green - extremes=c("yellow","green") OR
> >> cs1=c(1,0),cs2=(c(1,1),cs3=0
> >>
> >> Obviously the shades of colors that you want may differ from the above,
> so
> >> you have to play with the values to get the ones you want. In many
> cases,
> >> you will have to specify more than two numbers for the color specs to
> get
> >> the "in between" colors right, especially if the span of the colors is
> >> large.
> >>
> >> Jim
> >>
> >> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com>
> wrote:
> >>
> >>> Hi Jim and others:
> >>>
> >>> I needed color code for some color gradients in color.scale function. I
> >>> found that the following translates to green to yellow to
> >>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
> >>> gradient? I would like to know the gradient code for red to yellow,
> yellow
> >>> to green and other ranges.
> >>>
> >>> Thanks,
> >>> Kumar Mainali
> >>>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct  9 21:29:18 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 9 Oct 2015 21:29:18 +0200
Subject: [R] Why can I reset directory in using setwd on desktop but not
	on laptop
In-Reply-To: <1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
References: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
	<CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>
	<1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
Message-ID: <8871DA6E-D127-4567-9329-5E6A0443BAAF@gmail.com>


> On 09 Oct 2015, at 17:58 , WRAY NICHOLAS <nicholas.wray at ntlworld.com> wrote:
> 
> Thanks Sarah  I didn't realise that there was a distinction between between
> asking about R per se and asking about r-studio...  I shall try specifying the
> path and see whether that helps   Thanks, Nick

The key part of the story is not necessarily Rstudio specific, though:

You said that your laptop  "won't allow me to reset the directory by a setwd command".

Now what makes you think that? I can imagine a number of misinterpretations that might lead you there without it actually being true. So:

- Is there an error message? 
- What exactly did you type in?
- Does the directory actually exist on both machines?
- Are we talking about machines with the same architecure? (e.g., is one a PC and the other one a Mac?)
- If you do a getwd() before and after the setwd(), what happens?

-pd

> 
>> 
>>    On 09 October 2015 at 16:51 Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> 
>> 
>>    Sounds like an RStudio question to me. Someone might be able to help,
>>    but this mailing list is for R.
>> 
>>    You should also provide sessionInfo() output when asking potentially
>>    OS-related questions.
>> 
>>    You can always specify path as part of the write.csv() or other output
>>    command; you don't need to change the working directory necessarily.
>> 
>>    Sarah
>> 
>>    On Fri, Oct 9, 2015 at 11:43 AM, WRAY NICHOLAS
>>    <nicholas.wray at ntlworld.com> wrote:
>>> Hi I am running the same r routine on both my desktop and my laptop, and
>>> writing results in the form of csv files into storage folders in the
>>> respective
>>> users/documents files of both machines My desktop machine allows me to
>>> reset
>>> the directory in the course of the r programme so that I can write the
>>> files
>>> into different folders which makes it easier to keep track of what's
>>> what,
>>> whereas my laptop won't allow me to reset the directory by a setwd
>>> command, and
>>> I have to set the directory manually using the r studio tabs, so
>>> basically on
>>> the laptop every results file is going into the same folder, which is
>>> not
>>> unworkable but not as easy to use later
>>> 
>>> As far as I know I have the same r studio on both machines. Does anyone
>>> out
>>> there know a) why I can't use a setwd command on the laptop, and b)is
>>> there
>>> anything I can do to put this right?
>>> 
>>> Thanks beforehand, as it were
>>> 
>>> Nick Wray
>> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From oma.gonzales at gmail.com  Fri Oct  9 21:59:48 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 9 Oct 2015 14:59:48 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
Message-ID: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>

I need to extract an ID from the product column of my df.

I was able to extract the ids for some scenearios, but when applying my
code for the next type of ids (there are some other combinations), the
results of my first line of code got NAs.


ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
ripley.tv$producto,
ignore.case = T)

ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
ripley.tv$producto,
ignore.case = T)

ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
ripley.tv$producto, ignore.case = T)


Also I've tried to use the ifelse function, but got "/2" as result.


ripley.tv <- ripley.tv %>%
        mutate(id = NA,
              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{1}[0-9]{4})(.*)",
ripley.tv$producto) == T, "\\2",id),
              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)",
ripley.tv$producto) == T, "\\2",id),
              id =
ifelse(grepl("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", ripley.tv$producto)
== T, "\\2",id))



And also str_extract:


ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{1}[0-9]{4}")
ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{2}[0-9]{4}")
ripley.tv$id <- str_extract(ripley.tv$producto,
"[A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}")

This is my data:


ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
"PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
"HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
"LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
"LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
"SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
"SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
"SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
"LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
"SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
"PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
48J6400",
"SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
"TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
"TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD 55\" -
LE55B8000",
"TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
"TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
"SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
"SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
55JS9000",
"SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
"SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD 65''
3D 65JS9000",
"SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
"SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD 40LF6350",
"SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
42LF6450",
"TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
3D",
"TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
"TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD 4K",
"SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART TV
55UF7700",
"SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD 4K
3D",
"TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K SMART
TC-50CX640W",
"SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K CINEMA
SMART UG8700",
"TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD 3D",
"SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD KDL-40R354B",
"SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50'' 50J5500",
"TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
"SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D 40J6400",
"TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD KDL-40R555C
- NEGRO",
"SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
"TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
"TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
KDL-65W855C",
"SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
"TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
"TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
LE32W454F",
"TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
KDL-55W805C",
"TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
XBR-55X855C",
"TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\" ULTRA HD
4K 3D XBR-75X945C",
"TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
ULTRA HD 4K LC60UE30U",
"SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD 4K
LC80UE30U",
"SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\" ULTRA HD
4K 3D",
"SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA HD
4K 3D",
"SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\" 32J4300",
"TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700 55\"
ULTRA HD 4K 3D",
"SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL HD
3D",
"TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD 50''
TC-50AS600L",
"TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U 70''",
"TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
"TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO 55HU8700",
"TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
"SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes = c(2799L,
1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 - S/.2500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
"> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
"> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
"> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
"> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
"S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
"S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
"> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
"S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
"> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
"> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
"S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
"S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names = c("id",
"marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
"dif.precios", "dif.porcentual", "rangos"), class = "data.frame", row.names
= c(NA,
-97L))

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Fri Oct  9 22:00:37 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Oct 2015 16:00:37 -0400
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
	<CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
	<CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>
	<CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>
Message-ID: <CAM_vjukQca7WJd_H_HZ46Q4k7r9RSofy80-05KzCJs5sOqQm-A@mail.gmail.com>

Presumably you need something like
cellcol[x < 0.33 & !is.na(x)]
just as the error message suggests. I don't think it's a color.scale issue.
On Oct 9, 2015 3:27 PM, "Kumar Mainali" <kpmainali at gmail.com> wrote:

> Hi Sarah,
>
> Thanks for the explanation. This solves my first problem. I hope somebody
> will be able to answer my second question. Copied here from previous email
> >>
>
> Another question: some of my matrices have missing cells and I do not want
> to assign any colors to the missing cells. The following code gives me
> error. I am trying to use the output (cellcol) to the
> function color2D.matplot.
>
> > cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> > cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
> Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
>   NAs are not allowed in subscripted assignments
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
> ?
>
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
>
> On Fri, Oct 9, 2015 at 11:48 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> Hi Kumar,
>>
>> You're overthinking it:
>>
>> in RGB, colorspace, cs1 is red, cs2 is green, cs3 is blue.
>> So if cs1=c(1,1),cs2=(c(0,1),cs3=0 (or c(0,0) because of R's recycling)
>> the first color in the sequence is c(1, 0, 0) or red ##FF0000 and the
>> second color is c(1, 1, 0) #FFFF00 or yellow.
>>
>> Sarah
>>
>> On Fri, Oct 9, 2015 at 11:16 AM, Kumar Mainali <kpmainali at gmail.com>
>> wrote:
>> > Hi Jim,
>> >
>> > Thank you! Your color code does work. I still do not understand how red
>> to
>> > yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In other
>> > words, I have RGB values for red and yellow. How do I go from there to
>> the
>> > code you sent?
>> >
>> > Another question: some of my matrices have missing cells and I do not
>> want
>> > to assign any colors to the missing cells. The following code gives me
>> > error. I am trying to use the output (cellcol) to the
>> > function color2D.matplot.
>> >
>> >> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
>> >> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0,
>> na.color=NA)
>> > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,
>> :
>> >   NAs are not allowed in subscripted assignments
>> > In addition: Warning messages:
>> > 1: In min(x) : no non-missing arguments to min; returning Inf
>> > 2: In max(x) : no non-missing arguments to max; returning -Inf
>> > ?
>> >
>> > Postdoctoral Associate
>> > Department of Biology
>> > University of Maryland, College Park
>> >
>> > On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> >
>> >> Hi Kumar,
>> >> The color.scale function translates numeric values into one or more
>> >> intervals of color by a linear transformation into the numeric values
>> that
>> >> specify colors. One of three color spaces (rgb, hcl and hsv) can be
>> >> specified, and the endpoints can be specified as "extremes=c(<minimum
>> >> color>,<maximum color>" or as three vectors of numbers. By default,
>> the RGB
>> >> color space is used, so:
>> >>
>> >> # starts at RGB #FF0000 and finishes at RGB #FFFF00
>> >> red to yellow - extremes=c("red","yellow") OR
>> cs1=c(1,1),cs2=(c(0,1),cs3=0
>> >> # starts at RGB #FFFF00 and finishes at RGB #00FF00
>> >> yellow to green - extremes=c("yellow","green") OR
>> >> cs1=c(1,0),cs2=(c(1,1),cs3=0
>> >>
>> >> Obviously the shades of colors that you want may differ from the
>> above, so
>> >> you have to play with the values to get the ones you want. In many
>> cases,
>> >> you will have to specify more than two numbers for the color specs to
>> get
>> >> the "in between" colors right, especially if the span of the colors is
>> >> large.
>> >>
>> >> Jim
>> >>
>> >> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com>
>> wrote:
>> >>
>> >>> Hi Jim and others:
>> >>>
>> >>> I needed color code for some color gradients in color.scale function.
>> I
>> >>> found that the following translates to green to yellow to
>> >>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
>> >>> gradient? I would like to know the gradient code for red to yellow,
>> yellow
>> >>> to green and other ranges.
>> >>>
>> >>> Thanks,
>> >>> Kumar Mainali
>> >>>
>>
>
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Fri Oct  9 22:34:16 2015
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Fri, 9 Oct 2015 21:34:16 +0100 (BST)
Subject: [R] Why can I reset directory in using setwd on desktop but not
 on laptop
In-Reply-To: <819300068.371295.1444422821664.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
References: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
	<CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>
	<1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
	<8871DA6E-D127-4567-9329-5E6A0443BAAF@gmail.com>
	<819300068.371295.1444422821664.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
Message-ID: <1547802837.371315.1444422856431.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>


> ---------- Original Message ----------
>     From: WRAY NICHOLAS <nicholas.wray at ntlworld.com>
>     To: peter dalgaard <pdalgd at gmail.com>
>     Date: 09 October 2015 at 21:33
>     Subject: Re: [R] Why can I reset directory in using setwd on desktop but
> not on laptop
> 
> 
>     Thanks for your questions Peter
> 
>     Both machines are PCs
> 
>     In the R routine on my desktop I am changing the place where I store the
> various csv  files by commands like
> 
>     setwd("C:/Users/Nick/Documents/08915Trent/Outmatstore") where I'm storing
> particulur matrices (outmats) as csv files.  If I then say
> 
>     setwd("C:/Users/Nick/Documents/08915Trent/Resmatstore") to store another
> kind of matrix (resmats) as csv files elsewhere, the desktop is quite happy
> with this and lets me change and read.csv and write.csv without problems
> 
>     But, having created on my laptop exactly the same path ie
> C:/Users/Nick/Documents/08915Trent/Outmatstore or Resmatstore etc (that is, I
> have exactly the same folders nested in the same way on both machines), if I
> try to change horses in midstream, so to speak, I get an error message
> 
>     Error in setwd("C:/Users/Nick/08915Trent/Resmatstore") : 
>       cannot change working directory
> 
>     Not only this, but the laptop will not let me write to any path except one
> involving C:/Users/Nick etc that is if I try to write to any folder not part
> of the main administrator's path then it won't let me
> 
>     If I do getwd() on either machine before or after the attempt
> (unsuccessful on laptop) tochange directory I get whichever is the current
> directory, ie the new one on the desktop and the old one on the laptop...
> 
>     ?
> 
>     Thanks, Nick
> 
>         > > 
> >         On 09 October 2015 at 20:29 peter dalgaard <pdalgd at gmail.com> wrote:
> > 
> > 
> > 
> >         > On 09 Oct 2015, at 17:58 , WRAY NICHOLAS
> >         > <nicholas.wray at ntlworld.com> wrote:
> >         >
> >         > Thanks Sarah I didn't realise that there was a distinction between
> >         > between
> >         > asking about R per se and asking about r-studio... I shall try
> >         > specifying the
> >         > path and see whether that helps Thanks, Nick
> > 
> >         The key part of the story is not necessarily Rstudio specific,
> > though:
> > 
> >         You said that your laptop "won't allow me to reset the directory by
> > a setwd command".
> > 
> >         Now what makes you think that? I can imagine a number of
> > misinterpretations that might lead you there without it actually being true.
> > So:
> > 
> >         - Is there an error message?
> >         - What exactly did you type in?
> >         - Does the directory actually exist on both machines?
> >         - Are we talking about machines with the same architecure? (e.g., is
> > one a PC and the other one a Mac?)
> >         - If you do a getwd() before and after the setwd(), what happens?
> > 
> >         -pd
> > 
> >         >
> >         >>
> >         >> On 09 October 2015 at 16:51 Sarah Goslee <sarah.goslee at gmail.com>
> >         >> wrote:
> >         >>
> >         >>
> >         >> Sounds like an RStudio question to me. Someone might be able to
> >         >> help,
> >         >> but this mailing list is for R.
> >         >>
> >         >> You should also provide sessionInfo() output when asking
> >         >> potentially
> >         >> OS-related questions.
> >         >>
> >         >> You can always specify path as part of the write.csv() or other
> >         >> output
> >         >> command; you don't need to change the working directory
> >         >> necessarily.
> >         >>
> >         >> Sarah
> >         >>
> >         >> On Fri, Oct 9, 2015 at 11:43 AM, WRAY NICHOLAS
> >         >> <nicholas.wray at ntlworld.com> wrote:
> >         >>> Hi I am running the same r routine on both my desktop and my
> >         >>> laptop, and
> >         >>> writing results in the form of csv files into storage folders in
> >         >>> the
> >         >>> respective
> >         >>> users/documents files of both machines My desktop machine allows
> >         >>> me to
> >         >>> reset
> >         >>> the directory in the course of the r programme so that I can
> >         >>> write the
> >         >>> files
> >         >>> into different folders which makes it easier to keep track of
> >         >>> what's
> >         >>> what,
> >         >>> whereas my laptop won't allow me to reset the directory by a
> >         >>> setwd
> >         >>> command, and
> >         >>> I have to set the directory manually using the r studio tabs, so
> >         >>> basically on
> >         >>> the laptop every results file is going into the same folder,
> >         >>> which is
> >         >>> not
> >         >>> unworkable but not as easy to use later
> >         >>>
> >         >>> As far as I know I have the same r studio on both machines. Does
> >         >>> anyone
> >         >>> out
> >         >>> there know a) why I can't use a setwd command on the laptop, and
> >         >>> b)is
> >         >>> there
> >         >>> anything I can do to put this right?
> >         >>>
> >         >>> Thanks beforehand, as it were
> >         >>>
> >         >>> Nick Wray
> >         >>
> >         > [[alternative HTML version deleted]]
> >         >
> >         > ______________________________________________
> >         > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >         > https://stat.ethz.ch/mailman/listinfo/r-help
> >         > PLEASE do read the posting guide
> >         > http://www.R-project.org/posting-guide.html
> >         > and provide commented, minimal, self-contained, reproducible code.
> > 
> >         --
> >         Peter Dalgaard, Professor,
> >         Center for Statistics, Copenhagen Business School
> >         Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >         Phone: (+45)38153501
> >         Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> > 
> >     > 
>     >
> 


 
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct  9 22:37:12 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Oct 2015 13:37:12 -0700
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
Message-ID: <326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>


On Oct 9, 2015, at 12:59 PM, Omar Andr? Gonz?les D?az wrote:

> I need to extract an ID from the product column of my df.
> 
> I was able to extract the ids for some scenearios, but when applying my
> code for the next type of ids (there are some other combinations), the
> results of my first line of code got NAs.
> 
> 
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> ripley.tv$producto,
> ignore.case = T)

I think you need to examine the implicit logic of your pattern argument against the realities of your data:

> as.matrix(head(ripley.tv$producto, 10))
      [,1]                               
 [1,] "SMART TV LED FHD 48\" 3D\n48J6400"
 [2,] "SMART TV LED FHD 40\" 40J5300"    
 [3,] "TV LED FULL HD 40'' TC-40CS600L"  
 [4,] "TELEVISOR LED LE28F6600 28\""     
 [5,] "SMART TV 40\" HD LE40K5000N"      
 [6,] "TV LED HD 32'' LE32B7000"         
 [7,] "SMART TV  32'' LE32K5000N"        
 [8,] "TV LED FHD 55\" -\nLE55B8000"     
 [9,] "TV LED LE40B8000 FULL HD 40\""    
[10,] "TV LE24B8000 LED HD 24\" - NEGRO" 

So the first value and most of the other values do not have a space before the segment of characters that you want to match, The third item has two character inside the flanking numbers.

I tried fixing that by removing the space and putting in optional length values and discovered that some of you id's have only 3 trailing digit-characters: 

 head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{4})(.*)", "\\2",
 ripley.tv$producto,
 ignore.case = T), 20
  )
#-----------
 [1] "48J6400"                         "40J5300"                        
 [3] "TV LED FULL HD 40'' TC-40CS600L" "28F6600"                        
 [5] "40K5000"                         "32B7000"                        
 [7] "32K5000"                         "55B8000"                        
 [9] "40B8000"                         "24B8000"                        
[11] "TV LED FULL HD 42'' TC-42AS610"  "50K5000"                        
[13] "40JU6500"                        "48JU6500"                       
[15] "50JU6500"                        "55JS9000"                       
[17] "55JU6500"                        "55JU6700"                       
[19] "55JU7500"                        "65JS9000"      
                 
 head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{3,4})(.*)", "\\2",
 ripley.tv$producto,
 ignore.case = T), 20
  )
#--------------
 [1] "48J6400"  "40J5300"  "40CS600"  "28F6600"  "40K5000"  "32B7000" 
 [7] "32K5000"  "55B8000"  "40B8000"  "24B8000"  "42AS610"  "50K5000" 
[13] "40JU6500" "48JU6500" "50JU6500" "55JS9000" "55JU6500" "55JU6700"
[19] "55JU7500" "65JS9000"

> 
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> ripley.tv$producto,
> ignore.case = T)
> 
> ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
> ripley.tv$producto, ignore.case = T)
> 
> 
> Also I've tried to use the ifelse function, but got "/2" as result.

I think you will find that `ifelse` delivers strange results when used with factors as values. It strips attributes.



-- 
david.
> 
> 
> ripley.tv <- ripley.tv %>%
>        mutate(id = NA,
>              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{1}[0-9]{4})(.*)",
> ripley.tv$producto) == T, "\\2",id),
>              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)",
> ripley.tv$producto) == T, "\\2",id),
>              id =
> ifelse(grepl("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", ripley.tv$producto)
> == T, "\\2",id))
> 
> 
> 
> And also str_extract:
> 
> 
> ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{1}[0-9]{4}")
> ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{2}[0-9]{4}")
> ripley.tv$id <- str_extract(ripley.tv$producto,
> "[A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}")
> 
> This is my data:
> 
> 
> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> 48J6400",
> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD 55\" -
> LE55B8000",
> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> 55JS9000",
> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD 65''
> 3D 65JS9000",
> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD 40LF6350",
> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> 42LF6450",
> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> 3D",
> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD 4K",
> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART TV
> 55UF7700",
> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD 4K
> 3D",
> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K SMART
> TC-50CX640W",
> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K CINEMA
> SMART UG8700",
> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD 3D",
> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD KDL-40R354B",
> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50'' 50J5500",
> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D 40J6400",
> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD KDL-40R555C
> - NEGRO",
> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> KDL-65W855C",
> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> LE32W454F",
> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> KDL-55W805C",
> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> XBR-55X855C",
> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\" ULTRA HD
> 4K 3D XBR-75X945C",
> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> ULTRA HD 4K LC60UE30U",
> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD 4K
> LC80UE30U",
> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\" ULTRA HD
> 4K 3D",
> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA HD
> 4K 3D",
> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\" 32J4300",
> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700 55\"
> ULTRA HD 4K 3D",
> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL HD
> 3D",
> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD 50''
> TC-50AS600L",
> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U 70''",
> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO 55HU8700",
> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes = c(2799L,
> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 - S/.2500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names = c("id",
> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame", row.names
> = c(NA,
> -97L))
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From m.ashton at enduringinvestments.com  Fri Oct  9 15:05:12 2015
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Fri, 9 Oct 2015 06:05:12 -0700
Subject: [R] Attaching a pdf file to an email generated with sendmailR?
In-Reply-To: <0765308CD028654885F30322557308D81EFA1423@NYCSM0208.rth.ad.rothschild.com>
References: <E30D0E7822EEB443A5B9CC8273D99C74B649AD9A32@EXVMBX018-3.exch018.msoutlookonline.net>
	<CAFFQM6Ygw53nmCjiVeN=8+Tj_kyYYNYYZrcT04Cb2CmXOb7tnw@mail.gmail.com>
	<26D2A71D-FA31-4479-A535-BA7A96535EC7@enduringinvestments.com>
	<0765308CD028654885F30322557308D81EFA1423@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <57432C6C-C4CC-4888-A18D-67AD6BEDAC8D@enduringinvestments.com>

I seem to be able to get sendmailR to work with a text file, and maybe html is the same way...I tried this with a Pdf file and it didn't seem to work. But I will try again to be sure. Thanks for the suggestion.



> On Oct 9, 2015, at 7:55 AM, Bos, Roger <roger.bos at rothschild.com> wrote:
>
> Michael,
>
> I use sendmailR to attached a file to an email and it does work.  I remember there was something non-intuitive when I was figuring it out.  I use both the attachPath and the attachName.  The attachPath has the full path including the filename and the attachName just has the filename.  I don't why it wants the filename in both parameters, but it works for me.
>
> emailR(to = "someone at email.com", subject = "Morning Notes", msg = msg, attachPath = newwd %+% fnameNotes, attachName = fnameNotes)
>
>> fnameNotes
> [1] "morningNotes_20151009.html"
>> newwd %+% fnameNotes
> [1] "//rinnycs0051/research/R_HOME_Research/Markdown/morningNotes/morningNotes_20151009.html"
>> fnameNotes
> [1] "morningNotes_20151009.html"
>
> Thanks,
>
> Roger
>
>
>
>
>
>
>
> ***************************************************************
> This message and any attachments are for the intended recipient's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message, any attachments and all
> copies from your system and destroy any hard copies.  You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message or any attachments if you are not
> the intended recipient.
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Michael Ashton
> Sent: Thursday, October 08, 2015 5:24 PM
> To: Frans Marcelissen
> Cc: r-help at r-project.org
> Subject: Re: [R] Attaching a pdf file to an email generated with sendmailR?
>
> No particular reason for sendmailR...I will try mailR and thanks!
>
>
>
> On Oct 8, 2015, at 4:49 PM, Frans Marcelissen <fransiepansiekevertje at gmail.com<mailto:fransiepansiekevertje at gmail.com>> wrote:
>
> Hi Michael,
> I don't know whether there is a particulal reason for using sendmailR, but I use mailR for this without any problem.
> mailR::send.mail(from, to, subject = "", body = "", encoding = "iso-8859-1",
>  html = FALSE, inline = FALSE, smtp = list(), authenticate = FALSE,
>  send = TRUE, attach.files = NULL, debug = FALSE, ...)
>
> If you use an external smtp server, enter login name and password in parameter smtp as follows:
> smtp = list(host.name<http://host.name> = "smtp.XXXXX", port = XXXXX, user.name<http://user.name> = "XXXXX", passwd = "XXXXX", ssl = XXXXX)
>
> 2015-10-08 18:49 GMT+02:00 Michael Ashton <m.ashton at enduringinvestments.com<mailto:m.ashton at enduringinvestments.com>>:
> For some time I have been using sendmailR to generate a simple message when a report was done running.
>
> Recently, I started adding a couple of pertinent statistics in the body of the email.
>
> Now, I've finally decided that what the heck, I ought to simply attach the report itself to the email. The report is generated as a pdf file.
>
> I can't seem to get this to work in any simple way with mime_part; if I specify a path to the file it simply assumes that "P:/blablabla/thefile.pdf" is a message I want to put in a text file attachment.
>
> I assume I am doing something incorrectly and likely something simple. But maybe there is a clever trick I am missing. My send line is simply:
>
> sendmail(from,to,subject,body,control=list(smtpServer="mail.optonline.net<http://mail.optonline.net>"))
>
> where body is something like this:
>
> body <- list("Here's your stupid file",mime_part(x="P:/partofpath/ thefile.pdf",name="file.pdf"))
>
> Any suggestions are welcome!
>
> Thanks,
>
> Mike
>
> ________________________________
> This email and any attachments are confidential and inte...{{dropped:9}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ________________________________
> This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.
>
>        [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

This email and any attachments are confidential and intended only for the recipient noted above. You are hereby notified that any use, printing, copying or disclosure is strictly prohibited without the permission of Enduring Investments LLC. For further information please contact: Management at EnduringInvestments.com; (973) 457-4602.


From ruettenauer at sowi.uni-kl.de  Fri Oct  9 16:54:30 2015
From: ruettenauer at sowi.uni-kl.de (=?iso-8859-1?Q?Tobias_R=FCttenauer?=)
Date: Fri, 9 Oct 2015 16:54:30 +0200
Subject: [R] Time series in spatial regression model (spautolm)
Message-ID: <005d01d102a2$674f1ad0$35ed5070$@sowi.uni-kl.de>

Dear r-sig-geo team,

I started working with spatial analysis some month ago, so I'm quite new
(and unknowing ) in this field. However, my aim is to connect time series
analysis with spatial analysis, what seems to be quite difficult (to me).

The dataset I am working with a spatial polygons data frame, containing 402
spatial polygons for the years 2007-2011.

In a first step, I want to estimate a SAR model which accounts only for the
spatial autoregressive error term within a year. So what I am basically
trying is to construct a weights list object, containing only weights for
neighbors in the same year (excluding the linkages to the "self" spatial
unit (in different years) and neighboring units in different years). So what
I tried was to expand the original weights matrix by duplicating the
original matrix on the main diagonal while filling all the other linkages
(e.g. linkages between 2007 spatial units and 2008 spatial units) with zero
by the following code:


# Queens links:
> data.nb<-poly2nb(data_subset.spdf)
> 
> # Remove temporal links
> data2.nb<-aggregate(data.nb, data_subset.spdf$id, remove.self = TRUE)
> 
> # Get matrix
> tmp.mat<-nb2mat(data2.nb)
> 
> # Expand matrix
> zero1.mat<-matrix(0, 402, 402)
> zero2.mat<-matrix(0, 402, 402)
> zero3.mat<-matrix(0, 402, 402)
> zero4.mat<-matrix(0, 402, 402)
> zero5.mat<-matrix(0, 402, 402)
> 
> tmp2.mat<-tmp.mat
> tmp3.mat<-tmp.mat
> tmp4.mat<-tmp.mat
> tmp5.mat<-tmp.mat
> 
> row.names(zero1.mat)<-paste("2007", as.numeric(row.names(tmp.mat)), 
> sep="_") row.names(zero2.mat)<-paste("2008", 
> as.numeric(row.names(tmp.mat)), sep="_") 
> row.names(zero3.mat)<-paste("2009", as.numeric(row.names(tmp.mat)), 
> sep="_") row.names(zero4.mat)<-paste("2010", 
> as.numeric(row.names(tmp.mat)), sep="_") 
> row.names(zero5.mat)<-paste("2011", as.numeric(row.names(tmp.mat)), 
> sep="_")
> 
> row.names(tmp.mat)<-paste("2007", as.numeric(row.names(tmp2.mat)), 
> sep="_") row.names(tmp2.mat)<-paste("2008", 
> as.numeric(row.names(tmp2.mat)), sep="_") 
> row.names(tmp3.mat)<-paste("2009", as.numeric(row.names(tmp3.mat)), 
> sep="_") row.names(tmp4.mat)<-paste("2010", 
> as.numeric(row.names(tmp4.mat)), sep="_") 
> row.names(tmp5.mat)<-paste("2011", as.numeric(row.names(tmp5.mat)), 
> sep="_")
> 
> tmp1<-rbind(tmp.mat, zero2.mat, zero3.mat, zero4.mat, zero5.mat) 
> tmp2<-rbind(zero1.mat, tmp2.mat, zero3.mat, zero4.mat, zero5.mat) 
> tmp3<-rbind(zero1.mat, zero2.mat, tmp3.mat, zero4.mat, zero5.mat) 
> tmp4<-rbind(zero1.mat, zero2.mat, zero3.mat, tmp4.mat, zero5.mat) 
> tmp5<-rbind(zero1.mat, zero2.mat, zero3.mat, zero4.mat, tmp5.mat)
> 
> nb.mat<-cbind(tmp1, tmp2, tmp3, tmp4, tmp5)
> 
> data_sub.lw<-mat2listw(data.matrix(nb.mat))
> 
> any(is.na(nb.mat))
[1] FALSE

So I get a weights list object including 2010 observations (5 years with 402
observations, which fits the spatial polygon data frame with 2010
observations), but after running a spautolm model, I get the following error
message:

> spreg.mod<-spautolm(sqrt(fortzuege_gem) ~ v1 + v2,
+                 data=data_subset.spdf, listw=data_sub.lw,
weights=area_sqkm, 
+                 zero.policy=TRUE)
Error in subset.listw(listw, subset, zero.policy = zero.policy) : 
  Not yet able to subset general weights lists

Elsewhere, it is mentioned that this error messages occurs if the weights
matrix contains missing values, but that's not the case here. I assume that
there is some mistake in creating the weights matrix. Do you have any ideas?


Another thing I was trying to estimate is a SAR model with unit fixed
effects, just by including the id dummies into the equation (for the test I
include the total list weights objects, containing all linkages).

> data_total.nb<-poly2nb(data_subset.spdf)
> data_total.lw<-nb2listw(data.nb, style="W")
> 
> spreg_false.mod<-spautolm(sqrt(fortzuege_gem) ~ id  + v1 + v2,
+                     data=data_subset.spdf, listw=data_total.lw,
weights=area_sqkm, 
+                     zero.policy=TRUE)
Error in solve.default(crossprod(X, as.matrix(IlW %*% X)), tol = tol.solve)
: 
  system is computationally singular: reciprocal condition number =
1.01026e-16
>

So I assume there occurs some conflict, between using ID dummies and a
weights matrix in one model? Is there any way to solve this problem? This
may be a stupid question for some who is (totally) aware of the mathematics
behind the model. 

I would be really happy about any help!

Thank you in advance and best wishes,
Tobi


From maw90 at aber.ac.uk  Fri Oct  9 17:08:56 2015
From: maw90 at aber.ac.uk (mnw)
Date: Fri, 9 Oct 2015 08:08:56 -0700 (PDT)
Subject: [R] for loop not working
Message-ID: <1444403336163-4713392.post@n4.nabble.com>

Hi. I have some code which loops through raw GPS data. This initial loop
calculates distance, angle, speed etc between successive coordinates as well
as type of movement e.g.left, right, forward. I want to construct a second
loop that goes through the movements and records 'Changes' as either '0' or
'1' depending on whether the movement changed or not. I have put the whole
code in for reference but the additional loop begins at the object 'holder.'
I want to store movements in holder and then loop through holder to
determine 'changes.' At the moment it gives me 'Error in holder[[t - 1]] :
attempt to select less than one element.' The moment i make holder [[t]] it
works but just gives a list of '0's. I have tried many different things and
just cannot get it to work, so any help would be very much appreciated.
Again, sorry for the long post.




lst <- list() # temporary list to store the results
for (i in seq(1, nrow(R) - 1)){ # loop through each row of the 'R' matrix
  lat1 <- deg2rad(R[i, 4])
  long1 <- deg2rad(R[i, 5])
  lat2 <- deg2rad(R[i + 1, 4])
  long2 <- deg2rad(R[i + 1, 5])
  gcd_vif <- gcd.vif(lat1, long1, lat2, long2)
  
  # calc estimated speed by mean of speeds between two GPS records
  estSpeed <- (R[i, 6] + R[i+1, 6])/2
  
  # calculate acceleration (velocity)
  accel <- (R[i+1, 6] - R[i, 6]) / GPSSample
  
  # calculate absolute heading 
  heading <- absoluteHeading(lat1, long1, lat2, long2)

  # calculate bearing relative to previous GPS record
  relAngle <- 0
  # if the number of GPS records is less than 3 then no change in track
  if (i < 1) relAngle = heading
  # otherwise consider the previous heading in order to calculate the new
track
  else if (i > 0) {
    relAngle = (previousHeading - heading)
  
  }

  
  # determine whether movement is occurring and if so what type
  # if there are insufficient history items then just record movement types
discretely
   if (i < historyLength) movement <- movementType(relAngle, angleThreshold)
  
  else if (i > historyLength-1) {
    # Array to store speeds
    speedHistory <- array(historyLength)
    n = historyLength-1
    # get the speeds from the previous n (hisoryLength) "Movements" 
    for (j in seq(1, length(historyLength))){
      speedHistory [n] = R[i-j, 6]
      n-1
      }
      
      if (!bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
"non-moving" 
      else if(bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
movementType(relAngle, angleThreshold)
  
   
  }
  
  
  holder <- list(movement)
  holder [[i]] <- (movement)
  
  
  for (t in length(holder)){
    if (holder[[t]] == holder[[t-1]]) 
      changes <- 0
    else changes <- 1
    
  }
    
  
    
  # update previous heading information
  previousHeading = heading
 





  # Store the input data and the results
  lst[[i]] <- c(
    latitude_position_1 = lat1, 
    longtude_position_1 = long1, 
    latitude_position_2 = lat2, 
    longtude_position_2 = long2, 
    Distance = gcd_vif,
    Speed = estSpeed,
    Acceleration = accel,
    Absolute_Heading = heading,
    Relative_Heading = relAngle,
    Movement = movement,
    Changes = changes
  
  )
  
}  
Results <- as.data.frame(do.call(rbind, lst)) # store the input data and the
results in a data frame
Results



--
View this message in context: http://r.789695.n4.nabble.com/for-loop-not-working-tp4713392.html
Sent from the R help mailing list archive at Nabble.com.


From fernando.mansito at gmail.com  Fri Oct  9 19:09:31 2015
From: fernando.mansito at gmail.com (FERNANDO MANSITO CABALLERO)
Date: Fri, 9 Oct 2015 19:09:31 +0200
Subject: [R] How to install packages without internet
In-Reply-To: <44C9F321-2885-4721-9CFE-17E03F2B9648@comcast.net>
References: <CABOXfwOSAmt=0wwrK8CPTuWrVgpSJUfeNd3dngQEydEGm8hLng@mail.gmail.com>
	<CAM_vjukc0QBP-gvS8roCg-vxF6uStMV9fH=uHiQJd-qKqQRdKg@mail.gmail.com>
	<44C9F321-2885-4721-9CFE-17E03F2B9648@comcast.net>
Message-ID: <CABOXfwP4pOdZ96WAh8WGuYtC1bX+bT1ZMQppzc4+GspDSKc_6g@mail.gmail.com>

Thank you very much David. I will also follow your advice. I think polynom
was finally successfully installed  from source without mentioning it in
 the call under type..
Fernando

On Thu, Oct 8, 2015 at 7:53 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Oct 8, 2015, at 7:29 AM, Sarah Goslee wrote:
>
> > Don't uncompress the package first.
> >
> > Either from within R:
> >
> > install.packages("/path/to/pgk.tar.gz", repos=NULL)
>
> I think at least one OS will require that you also include type="source"
> and I would advise including dependencies=TRUE.
>
>
> > or at command line
> >
> > R CMD INSTALL /path/to/pgk.tar.gz
> >
> > In either case, pay attention to any messages that R returns
> >
> > Sarah
> >
> > On Thu, Oct 8, 2015 at 7:12 AM, FERNANDO MANSITO CABALLERO
> > <fernando.mansito at gmail.com> wrote:
> >> Dear Madam/Sir,
> >>
> >> I am trying to understand how to install packages without internet and I
> >> have come to a dead end.
> >>
> >> I choose polynom (Venables & Ripley) which I first successfully
> installed
> >> on a computer with internet. I found that the installed package
> comprises a
> >> void "polynom" folder and a "polynom_1.3-8.tar" folder which only
> contains
> >> a zipped container with the same name.
> >>
> >> I then donloaded the package successfully using download.packages(). I
> >> unzipped the .tar.gz downloaded package then successfully installed the
> >> unzipped polynom package using its path and repos=NULL in
> >> install.packages() on a computer without internet..
>
> Generally one does not need to unzip source versions of packages unless
> you want to look at the contents separately. With Windoze and Macs you need
> to specify type="source" [unless getOption("pkgType") is set to that value]
> and may need to have the appropriate system tools. You did not show your
> exact call to install.packages().
>
> >>
> >> However, when I wrote "library(polynom)" on the computer without
> internet,
> >> R3.2.2 answers with an error "polynom is not a valid installed package".
>
> The problem description doesn't allow a definite answer. If problems
> persist, then you should post more complete descriptions of your methods,
> your OS and R versions.
>
> >>
> >> What am I doing wrong?
> >>
> >
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From liqunhan at yahoo.com  Fri Oct  9 22:15:16 2015
From: liqunhan at yahoo.com (liqunhan at yahoo.com)
Date: Fri, 9 Oct 2015 20:15:16 +0000 (UTC)
Subject: [R] R lappy, sapply or mapply question
In-Reply-To: <7539129727B06D42A9F1A56D2C597F851139BF13@FHSDB2D11-2.csu.mcmaster.ca>
References: <7539129727B06D42A9F1A56D2C597F851139BF13@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>



Hello, R-experts,
In R-program,?I have a question about the apply-family.
I want to use apply-family to replace a for-loop in my R-code,But, lapply returns a list of 3 (each component is the same), sapply returns a matrix, and mapply with error message.
how to use apply-family function so that it returns a vector, as it does when using for-loop in my R-codes below?
Hope to hear back soon!
Thank you very much!



#-------------------------------------------------------------------------
# Below is my R-codes:
#-----------? begin of ?R code --------------------------------------
# suppose list1 returned by fun1()
# fun1() is a R-script with about 200 lines
list1 <- list(u=3.8, v=53.42)# suppose list2 returned by fun2()
# fun2() is a R-script with about 5000 lines
list2 <- list(x=3.8, y=-9,3)# demo fun3(), the actual function is much more complicated
fun3 <- function(xlist1, xlist2, xlist3) {
? 
? x1 <- xlist1$u
? x2 <- xlist1$v
? 
? x3 <- xlist2$x
? x4 <- xlist2$y
? 
? x5 <- xlist3$x5
? x6 <- xlist3$x6
? x7 <- xlist3$x7
? 
? w <- x1^2 + sqrt(x2+x3) - 0.75*x4 + exp(x5)
? z <- sin(x2)/x7 + x6/(x3+x4)
? return(w+z)
}dailyrecord <- data.frame(a = rnorm(50000), b = rnorm(50000), c = rnorm(50000),
????????????????????????? d = rnorm(50000), e = rnorm(50000), f = rnorm(50000), 
????????????????????????? g = rnorm(50000))
result_forloop <- rep(0, 50000)
# use for - loop ## how to avoid the for-loop ??for (k in 1 : 50000) {
? xlist <- list(x5 = dailyrecord$a[k], x6 = dailyrecord$e[k], x7 = dailyrecord$f[k])
? result_forloop[k] <- fun3(list1, list2, xlist)
}# use lapply? #--- return a list of 3 ------------
xlst <- list(x5=dailyrecord$a, x6 = dailyrecord$e, x7 = dailyrecord$f)
result_lapply <- lapply(xlst, function(s) fun3(list1, list2, xlst))

# use sapply? #--- return a matrix? -------
result_sapply <- sapply(xlst, function(s) fun3(list1, list2, xlst))

# use mapply? #--- error? -------
result_mapply <- mapply(fun3, xlist1 = list1, xlist2 = list2, xlist3 = xlst)

#-----------??end of?R code --------------------------------------

  
	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Fri Oct  9 22:50:02 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 9 Oct 2015 15:50:02 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
Message-ID: <CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>

David,

this is a working case. I know that all cases for ID are not covered with
my current code.

The question is:

ID stars as NAs.

1.- How to extract 1 type of ID, and keep the rest of entries as they are.

2.- Then keep the first extraction, and search for second type of ID.

3.- An so on with all types of IDs in product column.

I think it can be achieve with some ifelse construction I think... that's
why my initial lines of code.

Any hint is welcome.







2015-10-09 15:37 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Oct 9, 2015, at 12:59 PM, Omar Andr? Gonz?les D?az wrote:
>
> > I need to extract an ID from the product column of my df.
> >
> > I was able to extract the ids for some scenearios, but when applying my
> > code for the next type of ids (there are some other combinations), the
> > results of my first line of code got NAs.
> >
> >
> > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> > ripley.tv$producto,
> > ignore.case = T)
>
> I think you need to examine the implicit logic of your pattern argument
> against the realities of your data:
>
> > as.matrix(head(ripley.tv$producto, 10))
>       [,1]
>  [1,] "SMART TV LED FHD 48\" 3D\n48J6400"
>  [2,] "SMART TV LED FHD 40\" 40J5300"
>  [3,] "TV LED FULL HD 40'' TC-40CS600L"
>  [4,] "TELEVISOR LED LE28F6600 28\""
>  [5,] "SMART TV 40\" HD LE40K5000N"
>  [6,] "TV LED HD 32'' LE32B7000"
>  [7,] "SMART TV  32'' LE32K5000N"
>  [8,] "TV LED FHD 55\" -\nLE55B8000"
>  [9,] "TV LED LE40B8000 FULL HD 40\""
> [10,] "TV LE24B8000 LED HD 24\" - NEGRO"
>
> So the first value and most of the other values do not have a space before
> the segment of characters that you want to match, The third item has two
> character inside the flanking numbers.
>
> I tried fixing that by removing the space and putting in optional length
> values and discovered that some of you id's have only 3 trailing
> digit-characters:
>
>  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{4})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T), 20
>   )
> #-----------
>  [1] "48J6400"                         "40J5300"
>  [3] "TV LED FULL HD 40'' TC-40CS600L" "28F6600"
>  [5] "40K5000"                         "32B7000"
>  [7] "32K5000"                         "55B8000"
>  [9] "40B8000"                         "24B8000"
> [11] "TV LED FULL HD 42'' TC-42AS610"  "50K5000"
> [13] "40JU6500"                        "48JU6500"
> [15] "50JU6500"                        "55JS9000"
> [17] "55JU6500"                        "55JU6700"
> [19] "55JU7500"                        "65JS9000"
>
>  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{3,4})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T), 20
>   )
> #--------------
>  [1] "48J6400"  "40J5300"  "40CS600"  "28F6600"  "40K5000"  "32B7000"
>  [7] "32K5000"  "55B8000"  "40B8000"  "24B8000"  "42AS610"  "50K5000"
> [13] "40JU6500" "48JU6500" "50JU6500" "55JS9000" "55JU6500" "55JU6700"
> [19] "55JU7500" "65JS9000"
>
> >
> > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> > ripley.tv$producto,
> > ignore.case = T)
> >
> > ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)",
> "\\2",
> > ripley.tv$producto, ignore.case = T)
> >
> >
> > Also I've tried to use the ifelse function, but got "/2" as result.
>
> I think you will find that `ifelse` delivers strange results when used
> with factors as values. It strips attributes.
>
>
>
> --
> david.
> >
> >
> > ripley.tv <- ripley.tv %>%
> >        mutate(id = NA,
> >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{1}[0-9]{4})(.*)",
> > ripley.tv$producto) == T, "\\2",id),
> >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)",
> > ripley.tv$producto) == T, "\\2",id),
> >              id =
> > ifelse(grepl("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", ripley.tv
> $producto)
> > == T, "\\2",id))
> >
> >
> >
> > And also str_extract:
> >
> >
> > ripley.tv$id <- str_extract(ripley.tv$producto,
> "[0-9]{2}[A-Z]{1}[0-9]{4}")
> > ripley.tv$id <- str_extract(ripley.tv$producto,
> "[0-9]{2}[A-Z]{2}[0-9]{4}")
> > ripley.tv$id <- str_extract(ripley.tv$producto,
> > "[A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}")
> >
> > This is my data:
> >
> >
> > ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> > "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> > "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> > "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> > "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> > "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> > "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> > "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> > "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> > "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> > "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> > 48J6400",
> > "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> > "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> > "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
> 55\" -
> > LE55B8000",
> > "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> > "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> > "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> > "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> > 55JS9000",
> > "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> > "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
> 65''
> > 3D 65JS9000",
> > "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> > "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> 40LF6350",
> > "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> > 42LF6450",
> > "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> > 3D",
> > "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> > "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
> 4K",
> > "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART TV
> > 55UF7700",
> > "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD 4K
> > 3D",
> > "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
> SMART
> > TC-50CX640W",
> > "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
> CINEMA
> > SMART UG8700",
> > "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
> 3D",
> > "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD KDL-40R354B",
> > "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50'' 50J5500",
> > "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> > "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D 40J6400",
> > "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> KDL-40R555C
> > - NEGRO",
> > "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> > "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> > "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> > KDL-65W855C",
> > "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> > "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> > "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> > LE32W454F",
> > "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> > KDL-55W805C",
> > "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> > XBR-55X855C",
> > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\" ULTRA
> HD
> > 4K 3D XBR-75X945C",
> > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> > ULTRA HD 4K LC60UE30U",
> > "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD 4K
> > LC80UE30U",
> > "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\" ULTRA
> HD
> > 4K 3D",
> > "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA HD
> > 4K 3D",
> > "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\" 32J4300",
> > "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700 55\"
> > ULTRA HD 4K 3D",
> > "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL HD
> > 3D",
> > "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
> 50''
> > TC-50AS600L",
> > "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
> 70''",
> > "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> > "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> 55HU8700",
> > "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> > "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> > ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> > 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> > 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> > 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> > 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> > 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> > 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> > 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> c(2799L,
> > 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> > 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> > 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> > 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> > 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> > 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> > 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> > 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> > 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> > 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> > 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> > 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> > 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> > 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> > 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> > 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> > 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> > 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> > 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> > 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> > 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> > 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> > 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> > 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> > 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> > 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> > 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> > 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> > 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> > 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> > 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> > 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> > 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> > 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> > 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> > 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> > 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> > 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> S/.2500",
> > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> > S/.1500",
> > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> S/.1500",
> > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> S/.2500",
> > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> > "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> > "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> > "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> S/.1500",
> > "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> > "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> > "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> S/.2500",
> > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> c("id",
> > "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> > "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> row.names
> > = c(NA,
> > -97L))
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From c.danyluck at gmail.com  Fri Oct  9 23:01:31 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Fri, 9 Oct 2015 17:01:31 -0400
Subject: [R] Reformatting dataframe for use with icc()
Message-ID: <CA+_f+RGz6T3i5HA=Dp=_YBwvtT_JD7GDD+a=BPB=bsVk0A_ugw@mail.gmail.com>

Hello,

I want to determine the inter-rater reliability of ratings made from a
random selection of observers and observations. I plan to use the irr
package to calculate the ICC, however, my dataframe is not organized in a
way that the icc() function can handle. The icc() function works with
dataframes in the following format:

                     rater1 rater2 rater3...
observation
1                           6       7      NA
2                           4    NA          6
3                         NA       2         4
...

My dataframe is organized in the following format:

rater.id               1  2  1  3  2  3 ...
observation       1  1  2  2  3  3 ...
rating                 6  7  4  6  2  4 ...

I would like to reformat my dataframe as it is organized in the first
example but I am not sure how to go about doing this. Any suggestions would
be appreciated.

Kind regards,

Chad

-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct  9 23:16:39 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Oct 2015 14:16:39 -0700
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
Message-ID: <F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>


On Oct 9, 2015, at 1:50 PM, Omar Andr? Gonz?les D?az wrote:

> David,
> 
> this is a working case. I know that all cases for ID are not covered with my current code. 
> 
> The question is: 
> 
> ID stars as NAs.
> 
> 1.- How to extract 1 type of ID, and keep the rest of entries as they are.
> 
> 2.- Then keep the first extraction, and search for second type of ID.

If you want to use that workflow then you can replace $id with teh output of sub on $procuto the first time and then contiue workign on the results using $id as the input. The sub function returns the original values when there is no match.

ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
ripley.tv$producto,
ignore.case = T)

ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
ripley.tv$id,
ignore.case = T)

ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
ripley.tv$id, ignore.case = T)

> head(ripley.tv$id, 20)
 [1] "SMART TV LED FHD 48\" 3D\n48J6400"   " 40J5300"                           
 [3] "TV LED FULL HD 40'' TC-40CS600L"     " LE28F6600 "                        
 [5] "SMART TV 40\" HD LE40K5000N"         "TV LED HD 32'' LE32B7000"           
 [7] "SMART TV  32'' LE32K5000N"           "TV LED FHD 55\" -\nLE55B8000"       
 [9] " LE40B8000 "                         " LE24B8000 "                        
[11] "TV LED FULL HD 42'' TC-42AS610"      "TELEVISOR LED LE50K5000N 50\""      
[13] "SMART TV LED UHD 40\" 40JU6500"      "SMART TV ULTRA HD 48'' 48JU6500"    
[15] " 50JU6500 "                          "SMART TV ULTRA HD 55'' 3D\n55JS9000"
[17] "SMART TV LED UHD 55\" 55JU6500"      "SMART TV ULTRA HD 55'' 55JU6700"    
[19] " 55JU7500 "                          "SMART TV ULTRA HD 65''\n3D 65JS9000"

> 

That shows all your failures. You can incremetally fix them I suppose.

-- 
David.
> 3.- An so on with all types of IDs in product column.
> 
> I think it can be achieve with some ifelse construction I think... that's why my initial lines of code.
> 
> Any hint is welcome.
> 
> 
> 
> 
> 
> 
> 
> 2015-10-09 15:37 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Oct 9, 2015, at 12:59 PM, Omar Andr? Gonz?les D?az wrote:
> 
> > I need to extract an ID from the product column of my df.
> >
> > I was able to extract the ids for some scenearios, but when applying my
> > code for the next type of ids (there are some other combinations), the
> > results of my first line of code got NAs.
> >
> >
> > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> > ripley.tv$producto,
> > ignore.case = T)
> 
> I think you need to examine the implicit logic of your pattern argument against the realities of your data:
> 
> > as.matrix(head(ripley.tv$producto, 10))
>       [,1]
>  [1,] "SMART TV LED FHD 48\" 3D\n48J6400"
>  [2,] "SMART TV LED FHD 40\" 40J5300"
>  [3,] "TV LED FULL HD 40'' TC-40CS600L"
>  [4,] "TELEVISOR LED LE28F6600 28\""
>  [5,] "SMART TV 40\" HD LE40K5000N"
>  [6,] "TV LED HD 32'' LE32B7000"
>  [7,] "SMART TV  32'' LE32K5000N"
>  [8,] "TV LED FHD 55\" -\nLE55B8000"
>  [9,] "TV LED LE40B8000 FULL HD 40\""
> [10,] "TV LE24B8000 LED HD 24\" - NEGRO"
> 
> So the first value and most of the other values do not have a space before the segment of characters that you want to match, The third item has two character inside the flanking numbers.
> 
> I tried fixing that by removing the space and putting in optional length values and discovered that some of you id's have only 3 trailing digit-characters:
> 
>  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{4})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T), 20
>   )
> #-----------
>  [1] "48J6400"                         "40J5300"
>  [3] "TV LED FULL HD 40'' TC-40CS600L" "28F6600"
>  [5] "40K5000"                         "32B7000"
>  [7] "32K5000"                         "55B8000"
>  [9] "40B8000"                         "24B8000"
> [11] "TV LED FULL HD 42'' TC-42AS610"  "50K5000"
> [13] "40JU6500"                        "48JU6500"
> [15] "50JU6500"                        "55JS9000"
> [17] "55JU6500"                        "55JU6700"
> [19] "55JU7500"                        "65JS9000"
> 
>  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{3,4})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T), 20
>   )
> #--------------
>  [1] "48J6400"  "40J5300"  "40CS600"  "28F6600"  "40K5000"  "32B7000"
>  [7] "32K5000"  "55B8000"  "40B8000"  "24B8000"  "42AS610"  "50K5000"
> [13] "40JU6500" "48JU6500" "50JU6500" "55JS9000" "55JU6500" "55JU6700"
> [19] "55JU7500" "65JS9000"
> 
> >
> > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> > ripley.tv$producto,
> > ignore.case = T)
> >
> > ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
> > ripley.tv$producto, ignore.case = T)
> >
> >
> > Also I've tried to use the ifelse function, but got "/2" as result.
> 
> I think you will find that `ifelse` delivers strange results when used with factors as values. It strips attributes.
> 
> 
> 
> --
> david.
> >
> >
> > ripley.tv <- ripley.tv %>%
> >        mutate(id = NA,
> >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{1}[0-9]{4})(.*)",
> > ripley.tv$producto) == T, "\\2",id),
> >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)",
> > ripley.tv$producto) == T, "\\2",id),
> >              id =
> > ifelse(grepl("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", ripley.tv$producto)
> > == T, "\\2",id))
> >
> >
> >
> > And also str_extract:
> >
> >
> > ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{1}[0-9]{4}")
> > ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{2}[0-9]{4}")
> > ripley.tv$id <- str_extract(ripley.tv$producto,
> > "[A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}")
> >
> > This is my data:
> >
> >
> > ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> > "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> > "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> > "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> > "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> > "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> > "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> > "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> > "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> > "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> > "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> > 48J6400",
> > "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> > "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> > "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD 55\" -
> > LE55B8000",
> > "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> > "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> > "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> > "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> > 55JS9000",
> > "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> > "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD 65''
> > 3D 65JS9000",
> > "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> > "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD 40LF6350",
> > "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> > 42LF6450",
> > "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> > 3D",
> > "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> > "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD 4K",
> > "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART TV
> > 55UF7700",
> > "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD 4K
> > 3D",
> > "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K SMART
> > TC-50CX640W",
> > "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K CINEMA
> > SMART UG8700",
> > "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD 3D",
> > "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD KDL-40R354B",
> > "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50'' 50J5500",
> > "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> > "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D 40J6400",
> > "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD KDL-40R555C
> > - NEGRO",
> > "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> > "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> > "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> > KDL-65W855C",
> > "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> > "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> > "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> > LE32W454F",
> > "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> > KDL-55W805C",
> > "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> > XBR-55X855C",
> > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\" ULTRA HD
> > 4K 3D XBR-75X945C",
> > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> > ULTRA HD 4K LC60UE30U",
> > "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD 4K
> > LC80UE30U",
> > "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\" ULTRA HD
> > 4K 3D",
> > "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA HD
> > 4K 3D",
> > "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\" 32J4300",
> > "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700 55\"
> > ULTRA HD 4K 3D",
> > "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL HD
> > 3D",
> > "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD 50''
> > TC-50AS600L",
> > "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U 70''",
> > "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> > "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO 55HU8700",
> > "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> > "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> > ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> > 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> > 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> > 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> > 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> > 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> > 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> > 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes = c(2799L,
> > 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> > 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> > 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> > 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> > 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> > 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> > 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> > 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> > 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> > 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> > 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> > 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> > 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> > 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> > 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> > 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> > 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> > 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> > 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> > 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> > 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> > 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> > 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> > 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> > 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> > 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> > 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> > 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> > 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> > 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> > 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> > 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> > 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> > 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> > 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> > 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> > 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> > 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 - S/.2500",
> > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> > S/.1500",
> > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> > "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> > "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> > "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> > "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> > "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> > "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names = c("id",
> > "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> > "dif.precios", "dif.porcentual", "rangos"), class = "data.frame", row.names
> > = c(NA,
> > -97L))
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From oma.gonzales at gmail.com  Fri Oct  9 23:48:55 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 9 Oct 2015 16:48:55 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
Message-ID: <CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>

Thank you, David. You put me in the right direction.

At the end, I've used a lot of lines, to my taste, for this task.

Is there a more elegant way, of doing this?


ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
                    ripley.tv$producto,
                    ignore.case = T)

ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
                    ripley.tv$id,
                    ignore.case = T)

ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)



ripley.tv$id <-
sub("(.*)([A-Z]{2}\\-[0-9]{2}[A-Z]{2}[0-9]{3}[A-Z]{1})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}[A-Z]{1})(.*)",
"\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([A-Z]{2}\\-[0-9]{2}[A-Z]{2}[0-9]{3})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{4})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <-
sub("(.*)([A-Z]{3}\\-[0-9]{2}[A-Z]{2}[0-9]{2}[A-Z]{1})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([A-Z]{3}[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)",
"\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <-
sub("(.*)([A-Z]{3}\\-[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


ripley.tv$id <- sub("(.*)([0-9]{2}[A-Z]{2}[0-9]{3}[A-Z]{1})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)



ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{2}[0-9]{2}[A-Z]{1})(.*)",
"\\2",
                    ripley.tv$id, ignore.case = T)



ripley.tv$id <-
sub("(.*)([A-Z]{2}\\-[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)



ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)",
"\\2",
                    ripley.tv$id, ignore.case = T)



ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{2}[0-9]{3})(.*)", "\\2",
                    ripley.tv$id, ignore.case = T)


2015-10-09 16:16 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Oct 9, 2015, at 1:50 PM, Omar Andr? Gonz?les D?az wrote:
>
> > David,
> >
> > this is a working case. I know that all cases for ID are not covered
> with my current code.
> >
> > The question is:
> >
> > ID stars as NAs.
> >
> > 1.- How to extract 1 type of ID, and keep the rest of entries as they
> are.
> >
> > 2.- Then keep the first extraction, and search for second type of ID.
>
> If you want to use that workflow then you can replace $id with teh output
> of sub on $procuto the first time and then contiue workign on the results
> using $id as the input. The sub function returns the original values when
> there is no match.
>
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> ripley.tv$producto,
> ignore.case = T)
>
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> ripley.tv$id,
> ignore.case = T)
>
> ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
> ripley.tv$id, ignore.case = T)
>
> > head(ripley.tv$id, 20)
>  [1] "SMART TV LED FHD 48\" 3D\n48J6400"   " 40J5300"
>  [3] "TV LED FULL HD 40'' TC-40CS600L"     " LE28F6600 "
>  [5] "SMART TV 40\" HD LE40K5000N"         "TV LED HD 32'' LE32B7000"
>  [7] "SMART TV  32'' LE32K5000N"           "TV LED FHD 55\" -\nLE55B8000"
>  [9] " LE40B8000 "                         " LE24B8000 "
> [11] "TV LED FULL HD 42'' TC-42AS610"      "TELEVISOR LED LE50K5000N 50\""
> [13] "SMART TV LED UHD 40\" 40JU6500"      "SMART TV ULTRA HD 48''
> 48JU6500"
> [15] " 50JU6500 "                          "SMART TV ULTRA HD 55''
> 3D\n55JS9000"
> [17] "SMART TV LED UHD 55\" 55JU6500"      "SMART TV ULTRA HD 55''
> 55JU6700"
> [19] " 55JU7500 "                          "SMART TV ULTRA HD 65''\n3D
> 65JS9000"
>
> >
>
> That shows all your failures. You can incremetally fix them I suppose.
>
> --
> David.
> > 3.- An so on with all types of IDs in product column.
> >
> > I think it can be achieve with some ifelse construction I think...
> that's why my initial lines of code.
> >
> > Any hint is welcome.
> >
> >
> >
> >
> >
> >
> >
> > 2015-10-09 15:37 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > On Oct 9, 2015, at 12:59 PM, Omar Andr? Gonz?les D?az wrote:
> >
> > > I need to extract an ID from the product column of my df.
> > >
> > > I was able to extract the ids for some scenearios, but when applying my
> > > code for the next type of ids (there are some other combinations), the
> > > results of my first line of code got NAs.
> > >
> > >
> > > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> > > ripley.tv$producto,
> > > ignore.case = T)
> >
> > I think you need to examine the implicit logic of your pattern argument
> against the realities of your data:
> >
> > > as.matrix(head(ripley.tv$producto, 10))
> >       [,1]
> >  [1,] "SMART TV LED FHD 48\" 3D\n48J6400"
> >  [2,] "SMART TV LED FHD 40\" 40J5300"
> >  [3,] "TV LED FULL HD 40'' TC-40CS600L"
> >  [4,] "TELEVISOR LED LE28F6600 28\""
> >  [5,] "SMART TV 40\" HD LE40K5000N"
> >  [6,] "TV LED HD 32'' LE32B7000"
> >  [7,] "SMART TV  32'' LE32K5000N"
> >  [8,] "TV LED FHD 55\" -\nLE55B8000"
> >  [9,] "TV LED LE40B8000 FULL HD 40\""
> > [10,] "TV LE24B8000 LED HD 24\" - NEGRO"
> >
> > So the first value and most of the other values do not have a space
> before the segment of characters that you want to match, The third item has
> two character inside the flanking numbers.
> >
> > I tried fixing that by removing the space and putting in optional length
> values and discovered that some of you id's have only 3 trailing
> digit-characters:
> >
> >  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{4})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T), 20
> >   )
> > #-----------
> >  [1] "48J6400"                         "40J5300"
> >  [3] "TV LED FULL HD 40'' TC-40CS600L" "28F6600"
> >  [5] "40K5000"                         "32B7000"
> >  [7] "32K5000"                         "55B8000"
> >  [9] "40B8000"                         "24B8000"
> > [11] "TV LED FULL HD 42'' TC-42AS610"  "50K5000"
> > [13] "40JU6500"                        "48JU6500"
> > [15] "50JU6500"                        "55JS9000"
> > [17] "55JU6500"                        "55JU6700"
> > [19] "55JU7500"                        "65JS9000"
> >
> >  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{3,4})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T), 20
> >   )
> > #--------------
> >  [1] "48J6400"  "40J5300"  "40CS600"  "28F6600"  "40K5000"  "32B7000"
> >  [7] "32K5000"  "55B8000"  "40B8000"  "24B8000"  "42AS610"  "50K5000"
> > [13] "40JU6500" "48JU6500" "50JU6500" "55JS9000" "55JU6500" "55JU6700"
> > [19] "55JU7500" "65JS9000"
> >
> > >
> > > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> > > ripley.tv$producto,
> > > ignore.case = T)
> > >
> > > ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)",
> "\\2",
> > > ripley.tv$producto, ignore.case = T)
> > >
> > >
> > > Also I've tried to use the ifelse function, but got "/2" as result.
> >
> > I think you will find that `ifelse` delivers strange results when used
> with factors as values. It strips attributes.
> >
> >
> >
> > --
> > david.
> > >
> > >
> > > ripley.tv <- ripley.tv %>%
> > >        mutate(id = NA,
> > >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{1}[0-9]{4})(.*)",
> > > ripley.tv$producto) == T, "\\2",id),
> > >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)",
> > > ripley.tv$producto) == T, "\\2",id),
> > >              id =
> > > ifelse(grepl("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", ripley.tv
> $producto)
> > > == T, "\\2",id))
> > >
> > >
> > >
> > > And also str_extract:
> > >
> > >
> > > ripley.tv$id <- str_extract(ripley.tv$producto,
> "[0-9]{2}[A-Z]{1}[0-9]{4}")
> > > ripley.tv$id <- str_extract(ripley.tv$producto,
> "[0-9]{2}[A-Z]{2}[0-9]{4}")
> > > ripley.tv$id <- str_extract(ripley.tv$producto,
> > > "[A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}")
> > >
> > > This is my data:
> > >
> > >
> > > ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> > > "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> > > "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > > "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> > > "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> > > "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> > > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> > > "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> > > "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> > > "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> > > "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> > > "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> > > "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> > > 48J6400",
> > > "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> > > "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> > > "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
> 55\" -
> > > LE55B8000",
> > > "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> > > "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> > > "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> > > "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> > > 55JS9000",
> > > "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> > > "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
> 65''
> > > 3D 65JS9000",
> > > "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> > > "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> 40LF6350",
> > > "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> > > 42LF6450",
> > > "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> > > 3D",
> > > "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> > > "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
> 4K",
> > > "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
> TV
> > > 55UF7700",
> > > "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD
> 4K
> > > 3D",
> > > "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
> SMART
> > > TC-50CX640W",
> > > "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
> CINEMA
> > > SMART UG8700",
> > > "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
> 3D",
> > > "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> KDL-40R354B",
> > > "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> 50J5500",
> > > "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> > > "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> 40J6400",
> > > "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> KDL-40R555C
> > > - NEGRO",
> > > "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> > > "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> > > "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> > > KDL-65W855C",
> > > "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> > > "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> > > "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> > > LE32W454F",
> > > "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> > > KDL-55W805C",
> > > "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> > > XBR-55X855C",
> > > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
> ULTRA HD
> > > 4K 3D XBR-75X945C",
> > > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> > > ULTRA HD 4K LC60UE30U",
> > > "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD
> 4K
> > > LC80UE30U",
> > > "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
> ULTRA HD
> > > 4K 3D",
> > > "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA
> HD
> > > 4K 3D",
> > > "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> 32J4300",
> > > "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
> 55\"
> > > ULTRA HD 4K 3D",
> > > "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
> HD
> > > 3D",
> > > "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
> 50''
> > > TC-50AS600L",
> > > "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
> 70''",
> > > "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> > > "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> 55HU8700",
> > > "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> > > "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> > > ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> > > 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> > > 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> > > 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> > > 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> > > 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> > > 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> > > 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> c(2799L,
> > > 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> > > 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> > > 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> > > 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> > > 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> > > 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> > > 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> > > 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> > > 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> > > 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> > > 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> > > 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> > > 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> > > 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> > > 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> > > 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> > > 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> > > 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> > > 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> > > 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> > > 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> > > 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> > > 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> > > 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> > > 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> > > 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> > > 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> > > 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> > > 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> > > 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> > > 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> > > 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> > > 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> > > 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> > > 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> > > 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> > > 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> > > 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> S/.2500",
> > > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> > > S/.1500",
> > > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> S/.2500",
> > > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > > "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> > > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> S/.1500",
> > > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> S/.2500",
> > > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> > > "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> > > "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> > > "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> > > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> > > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> S/.1500",
> > > "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> > > "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> > > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > > "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> > > "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> S/.2500",
> > > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > > "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > > "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> c("id",
> > > "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> > > "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> row.names
> > > = c(NA,
> > > -97L))
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct  9 23:49:36 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 9 Oct 2015 14:49:36 -0700
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
	<CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
	<CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>
	<CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>
Message-ID: <CAF8bMcaz_5kgaDQTLxHPZQmvj3wGFE__22QUifMvCGZtySsgZg@mail.gmail.com>

Try setting the na.color argument of color.scale to a color string,
not NA.  "#00000000" (alpha = 0 is the key part) is transparent so it it
might
suit your needs.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 9, 2015 at 12:26 PM, Kumar Mainali <kpmainali at gmail.com> wrote:

> Hi Sarah,
>
> Thanks for the explanation. This solves my first problem. I hope somebody
> will be able to answer my second question. Copied here from previous email
> >>
>
> Another question: some of my matrices have missing cells and I do not want
> to assign any colors to the missing cells. The following code gives me
> error. I am trying to use the output (cellcol) to the
> function color2D.matplot.
>
> > cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> > cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
> Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
>   NAs are not allowed in subscripted assignments
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
> ?
>
> Postdoctoral Associate
> Department of Biology
> University of Maryland, College Park
>
> On Fri, Oct 9, 2015 at 11:48 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
> > Hi Kumar,
> >
> > You're overthinking it:
> >
> > in RGB, colorspace, cs1 is red, cs2 is green, cs3 is blue.
> > So if cs1=c(1,1),cs2=(c(0,1),cs3=0 (or c(0,0) because of R's recycling)
> > the first color in the sequence is c(1, 0, 0) or red ##FF0000 and the
> > second color is c(1, 1, 0) #FFFF00 or yellow.
> >
> > Sarah
> >
> > On Fri, Oct 9, 2015 at 11:16 AM, Kumar Mainali <kpmainali at gmail.com>
> > wrote:
> > > Hi Jim,
> > >
> > > Thank you! Your color code does work. I still do not understand how red
> > to
> > > yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In
> other
> > > words, I have RGB values for red and yellow. How do I go from there to
> > the
> > > code you sent?
> > >
> > > Another question: some of my matrices have missing cells and I do not
> > want
> > > to assign any colors to the missing cells. The following code gives me
> > > error. I am trying to use the output (cellcol) to the
> > > function color2D.matplot.
> > >
> > >> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> > >> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0,
> na.color=NA)
> > > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8),
> c(0,  :
> > >   NAs are not allowed in subscripted assignments
> > > In addition: Warning messages:
> > > 1: In min(x) : no non-missing arguments to min; returning Inf
> > > 2: In max(x) : no non-missing arguments to max; returning -Inf
> > > ?
> > >
> > > Postdoctoral Associate
> > > Department of Biology
> > > University of Maryland, College Park
> > >
> > > On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> > >
> > >> Hi Kumar,
> > >> The color.scale function translates numeric values into one or more
> > >> intervals of color by a linear transformation into the numeric values
> > that
> > >> specify colors. One of three color spaces (rgb, hcl and hsv) can be
> > >> specified, and the endpoints can be specified as "extremes=c(<minimum
> > >> color>,<maximum color>" or as three vectors of numbers. By default,
> the
> > RGB
> > >> color space is used, so:
> > >>
> > >> # starts at RGB #FF0000 and finishes at RGB #FFFF00
> > >> red to yellow - extremes=c("red","yellow") OR
> > cs1=c(1,1),cs2=(c(0,1),cs3=0
> > >> # starts at RGB #FFFF00 and finishes at RGB #00FF00
> > >> yellow to green - extremes=c("yellow","green") OR
> > >> cs1=c(1,0),cs2=(c(1,1),cs3=0
> > >>
> > >> Obviously the shades of colors that you want may differ from the
> above,
> > so
> > >> you have to play with the values to get the ones you want. In many
> > cases,
> > >> you will have to specify more than two numbers for the color specs to
> > get
> > >> the "in between" colors right, especially if the span of the colors is
> > >> large.
> > >>
> > >> Jim
> > >>
> > >> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com>
> > wrote:
> > >>
> > >>> Hi Jim and others:
> > >>>
> > >>> I needed color code for some color gradients in color.scale
> function. I
> > >>> found that the following translates to green to yellow to
> > >>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the color
> > >>> gradient? I would like to know the gradient code for red to yellow,
> > yellow
> > >>> to green and other ranges.
> > >>>
> > >>> Thanks,
> > >>> Kumar Mainali
> > >>>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Fri Oct  9 23:56:15 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 9 Oct 2015 16:56:15 -0500
Subject: [R] R lappy, sapply or mapply question
In-Reply-To: <1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>
References: <7539129727B06D42A9F1A56D2C597F851139BF13@FHSDB2D11-2.csu.mcmaster.ca>
	<1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAN5YmCGwnfgKeUp0=AtZK-XwEGwGrzfu9kkP=UNdPRPHsrJQrg@mail.gmail.com>

You were very close.  Try this.

df <- data.frame(x5=dailyrecord$a, x6 = dailyrecord$e, x7 = dailyrecord$f)
apply(df, 1, function(row) fun3(list1, list2, as.list(row)))

Jean

On Fri, Oct 9, 2015 at 3:15 PM, liqunhan--- via R-help <r-help at r-project.org
> wrote:

>
>
> Hello, R-experts,
> In R-program, I have a question about the apply-family.
> I want to use apply-family to replace a for-loop in my R-code,But, lapply
> returns a list of 3 (each component is the same), sapply returns a matrix,
> and mapply with error message.
> how to use apply-family function so that it returns a vector, as it does
> when using for-loop in my R-codes below?
> Hope to hear back soon!
> Thank you very much!
>
>
>
> #-------------------------------------------------------------------------
> # Below is my R-codes:
> #-----------  begin of  R code --------------------------------------
> # suppose list1 returned by fun1()
> # fun1() is a R-script with about 200 lines
> list1 <- list(u=3.8, v=53.42)# suppose list2 returned by fun2()
> # fun2() is a R-script with about 5000 lines
> list2 <- list(x=3.8, y=-9,3)# demo fun3(), the actual function is much
> more complicated
> fun3 <- function(xlist1, xlist2, xlist3) {
>
>   x1 <- xlist1$u
>   x2 <- xlist1$v
>
>   x3 <- xlist2$x
>   x4 <- xlist2$y
>
>   x5 <- xlist3$x5
>   x6 <- xlist3$x6
>   x7 <- xlist3$x7
>
>   w <- x1^2 + sqrt(x2+x3) - 0.75*x4 + exp(x5)
>   z <- sin(x2)/x7 + x6/(x3+x4)
>   return(w+z)
> }dailyrecord <- data.frame(a = rnorm(50000), b = rnorm(50000), c =
> rnorm(50000),
>                           d = rnorm(50000), e = rnorm(50000), f =
> rnorm(50000),
>                           g = rnorm(50000))
> result_forloop <- rep(0, 50000)
> # use for - loop ## how to avoid the for-loop ??for (k in 1 : 50000) {
>   xlist <- list(x5 = dailyrecord$a[k], x6 = dailyrecord$e[k], x7 =
> dailyrecord$f[k])
>   result_forloop[k] <- fun3(list1, list2, xlist)
> }# use lapply  #--- return a list of 3 ------------
> xlst <- list(x5=dailyrecord$a, x6 = dailyrecord$e, x7 = dailyrecord$f)
> result_lapply <- lapply(xlst, function(s) fun3(list1, list2, xlst))
>
> # use sapply  #--- return a matrix  -------
> result_sapply <- sapply(xlst, function(s) fun3(list1, list2, xlst))
>
> # use mapply  #--- error  -------
> result_mapply <- mapply(fun3, xlist1 = list1, xlist2 = list2, xlist3 =
> xlst)
>
> #-----------  end of R code --------------------------------------
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Oct 10 00:02:26 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 9 Oct 2015 18:02:26 -0400
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CAF8bMcaz_5kgaDQTLxHPZQmvj3wGFE__22QUifMvCGZtySsgZg@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
	<CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
	<CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>
	<CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>
	<CAF8bMcaz_5kgaDQTLxHPZQmvj3wGFE__22QUifMvCGZtySsgZg@mail.gmail.com>
Message-ID: <CAM_vjumTs2tHOu7GGRuS7mzw4-KTBGUXqP18v9Sga_-A2Sb9eg@mail.gmail.com>

This is the error message:

> > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
> >   NAs are not allowed in subscripted assignments

x has NA values, but is being used for subscripting.

either use

cellcol[!is.na(x) & x < 0.33]

or specify a NA value for color.scale() and let it handle the missing values.

> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
  NAs are not allowed in subscripted assignments


vs

> cellcol <- color.scale(x, c(1,0.8),c(0,0.8),0, na.color=NA)

Which doesn't help with the < 0.33 part, but you could set the values
> 0.33 to NA first.




On Fri, Oct 9, 2015 at 5:49 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Try setting the na.color argument of color.scale to a color string,
> not NA.  "#00000000" (alpha = 0 is the key part) is transparent so it it
> might
> suit your needs.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 9, 2015 at 12:26 PM, Kumar Mainali <kpmainali at gmail.com> wrote:
>>
>> Hi Sarah,
>>
>> Thanks for the explanation. This solves my first problem. I hope somebody
>> will be able to answer my second question. Copied here from previous email
>> >>
>>
>> Another question: some of my matrices have missing cells and I do not want
>> to assign any colors to the missing cells. The following code gives me
>> error. I am trying to use the output (cellcol) to the
>> function color2D.matplot.
>>
>> > cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
>> > cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
>> Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
>>   NAs are not allowed in subscripted assignments
>> In addition: Warning messages:
>> 1: In min(x) : no non-missing arguments to min; returning Inf
>> 2: In max(x) : no non-missing arguments to max; returning -Inf
>> ?
>>
>> Postdoctoral Associate
>> Department of Biology
>> University of Maryland, College Park
>>
>> On Fri, Oct 9, 2015 at 11:48 AM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>
>> > Hi Kumar,
>> >
>> > You're overthinking it:
>> >
>> > in RGB, colorspace, cs1 is red, cs2 is green, cs3 is blue.
>> > So if cs1=c(1,1),cs2=(c(0,1),cs3=0 (or c(0,0) because of R's recycling)
>> > the first color in the sequence is c(1, 0, 0) or red ##FF0000 and the
>> > second color is c(1, 1, 0) #FFFF00 or yellow.
>> >
>> > Sarah
>> >
>> > On Fri, Oct 9, 2015 at 11:16 AM, Kumar Mainali <kpmainali at gmail.com>
>> > wrote:
>> > > Hi Jim,
>> > >
>> > > Thank you! Your color code does work. I still do not understand how
>> > > red
>> > to
>> > > yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In
>> > > other
>> > > words, I have RGB values for red and yellow. How do I go from there to
>> > the
>> > > code you sent?
>> > >
>> > > Another question: some of my matrices have missing cells and I do not
>> > want
>> > > to assign any colors to the missing cells. The following code gives me
>> > > error. I am trying to use the output (cellcol) to the
>> > > function color2D.matplot.
>> > >
>> > >> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
>> > >> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0,
>> > >> na.color=NA)
>> > > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,
>> > > :
>> > >   NAs are not allowed in subscripted assignments
>> > > In addition: Warning messages:
>> > > 1: In min(x) : no non-missing arguments to min; returning Inf
>> > > 2: In max(x) : no non-missing arguments to max; returning -Inf
>> > > ?
>> > >
>> > > Postdoctoral Associate
>> > > Department of Biology
>> > > University of Maryland, College Park
>> > >
>> > > On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com>
>> > > wrote:
>> > >
>> > >> Hi Kumar,
>> > >> The color.scale function translates numeric values into one or more
>> > >> intervals of color by a linear transformation into the numeric values
>> > that
>> > >> specify colors. One of three color spaces (rgb, hcl and hsv) can be
>> > >> specified, and the endpoints can be specified as "extremes=c(<minimum
>> > >> color>,<maximum color>" or as three vectors of numbers. By default,
>> > >> the
>> > RGB
>> > >> color space is used, so:
>> > >>
>> > >> # starts at RGB #FF0000 and finishes at RGB #FFFF00
>> > >> red to yellow - extremes=c("red","yellow") OR
>> > cs1=c(1,1),cs2=(c(0,1),cs3=0
>> > >> # starts at RGB #FFFF00 and finishes at RGB #00FF00
>> > >> yellow to green - extremes=c("yellow","green") OR
>> > >> cs1=c(1,0),cs2=(c(1,1),cs3=0
>> > >>
>> > >> Obviously the shades of colors that you want may differ from the
>> > >> above,
>> > so
>> > >> you have to play with the values to get the ones you want. In many
>> > cases,
>> > >> you will have to specify more than two numbers for the color specs to
>> > get
>> > >> the "in between" colors right, especially if the span of the colors
>> > >> is
>> > >> large.
>> > >>
>> > >> Jim
>> > >>
>> > >> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com>
>> > wrote:
>> > >>
>> > >>> Hi Jim and others:
>> > >>>
>> > >>> I needed color code for some color gradients in color.scale
>> > >>> function. I
>> > >>> found that the following translates to green to yellow to
>> > >>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the
>> > >>> color
>> > >>> gradient? I would like to know the gradient code for red to yellow,
>> > yellow
>> > >>> to green and other ranges.
>> > >>>
>> > >>> Thanks,
>> > >>> Kumar Mainali
>> > >>>
>> >


From kpmainali at gmail.com  Sat Oct 10 00:08:33 2015
From: kpmainali at gmail.com (Kumar Mainali)
Date: Fri, 9 Oct 2015 18:08:33 -0400
Subject: [R] Help with color.scale {plotrix}
In-Reply-To: <CAM_vjumTs2tHOu7GGRuS7mzw4-KTBGUXqP18v9Sga_-A2Sb9eg@mail.gmail.com>
References: <CABK368jCgGRZUmyq1roDS5AW1ggwX-LXaUG9JAoYXjuPHkadJg@mail.gmail.com>
	<CA+8X3fVETWHaMuWRNjQ8L_AjYXyeS62NBrxxVJ7UMVboNczS5A@mail.gmail.com>
	<CABK368jL4XmuJD-wq9dtHNzNbeeT9GKSMfoD1gC2eX1k_3eiGA@mail.gmail.com>
	<CAM_vjunMb8g2xWoS52Ju9Gu1JVepVz0p3LdNW_dGuDK6SWgCyQ@mail.gmail.com>
	<CABK368j_XxLXhV9Hipfce=qWkhaMHqKFp06FQag5fvHboX840g@mail.gmail.com>
	<CAF8bMcaz_5kgaDQTLxHPZQmvj3wGFE__22QUifMvCGZtySsgZg@mail.gmail.com>
	<CAM_vjumTs2tHOu7GGRuS7mzw4-KTBGUXqP18v9Sga_-A2Sb9eg@mail.gmail.com>
Message-ID: <CABK368jG3o9r63jXXn=UzDmKfSfy0mA+6wHNs3f7hUNwthmRfg@mail.gmail.com>

Sarah, what you suggested solved the problem. Below is the code:

cellcol[x<0.33 & !is.na(x)] <- color.scale(x[x<0.33 & !is.na(x)],
c(1,1),c(0,1),c(0,1), xrange=c(0,0.33))

Including xrange in color.scale function makes a slight difference in my
plot. I want to use the same scale to many matrices so that the color scale
can be compared across plots which can differ in range. I believe setting
xrange solves the problem.

?

Postdoctoral Associate
Department of Biology
University of Maryland, College Park

On Fri, Oct 9, 2015 at 6:02 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> This is the error message:
>
> > > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8),
> c(0,  :
> > >   NAs are not allowed in subscripted assignments
>
> x has NA values, but is being used for subscripting.
>
> either use
>
> cellcol[!is.na(x) & x < 0.33]
>
> or specify a NA value for color.scale() and let it handle the missing
> values.
>
> > cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0, na.color=NA)
> Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,  :
>   NAs are not allowed in subscripted assignments
>
>
> vs
>
> > cellcol <- color.scale(x, c(1,0.8),c(0,0.8),0, na.color=NA)
>
> Which doesn't help with the < 0.33 part, but you could set the values
> > 0.33 to NA first.
>
>
>
>
> On Fri, Oct 9, 2015 at 5:49 PM, William Dunlap <wdunlap at tibco.com> wrote:
> > Try setting the na.color argument of color.scale to a color string,
> > not NA.  "#00000000" (alpha = 0 is the key part) is transparent so it it
> > might
> > suit your needs.
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Fri, Oct 9, 2015 at 12:26 PM, Kumar Mainali <kpmainali at gmail.com>
> wrote:
> >>
> >> Hi Sarah,
> >>
> >> Thanks for the explanation. This solves my first problem. I hope
> somebody
> >> will be able to answer my second question. Copied here from previous
> email
> >> >>
> >>
> >> Another question: some of my matrices have missing cells and I do not
> want
> >> to assign any colors to the missing cells. The following code gives me
> >> error. I am trying to use the output (cellcol) to the
> >> function color2D.matplot.
> >>
> >> > cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> >> > cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0,
> na.color=NA)
> >> Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8), c(0,
> :
> >>   NAs are not allowed in subscripted assignments
> >> In addition: Warning messages:
> >> 1: In min(x) : no non-missing arguments to min; returning Inf
> >> 2: In max(x) : no non-missing arguments to max; returning -Inf
> >> ?
> >>
> >> Postdoctoral Associate
> >> Department of Biology
> >> University of Maryland, College Park
> >>
> >> On Fri, Oct 9, 2015 at 11:48 AM, Sarah Goslee <sarah.goslee at gmail.com>
> >> wrote:
> >>
> >> > Hi Kumar,
> >> >
> >> > You're overthinking it:
> >> >
> >> > in RGB, colorspace, cs1 is red, cs2 is green, cs3 is blue.
> >> > So if cs1=c(1,1),cs2=(c(0,1),cs3=0 (or c(0,0) because of R's
> recycling)
> >> > the first color in the sequence is c(1, 0, 0) or red ##FF0000 and the
> >> > second color is c(1, 1, 0) #FFFF00 or yellow.
> >> >
> >> > Sarah
> >> >
> >> > On Fri, Oct 9, 2015 at 11:16 AM, Kumar Mainali <kpmainali at gmail.com>
> >> > wrote:
> >> > > Hi Jim,
> >> > >
> >> > > Thank you! Your color code does work. I still do not understand how
> >> > > red
> >> > to
> >> > > yellow in RGB space translates to cs1=c(1,1),cs2=(c(0,1),cs3=0. In
> >> > > other
> >> > > words, I have RGB values for red and yellow. How do I go from there
> to
> >> > the
> >> > > code you sent?
> >> > >
> >> > > Another question: some of my matrices have missing cells and I do
> not
> >> > want
> >> > > to assign any colors to the missing cells. The following code gives
> me
> >> > > error. I am trying to use the output (cellcol) to the
> >> > > function color2D.matplot.
> >> > >
> >> > >> cellcol<-matrix("#000000", nrow=nrow(plotdata),ncol=ncol(plotdata))
> >> > >> cellcol[x<0.33]<-color.scale(x[x<0.33],c(1,0.8),c(0,0.8),0,
> >> > >> na.color=NA)
> >> > > Error in cellcol[x < 0.33] <- color.scale(x[x < 0.33], c(1, 0.8),
> c(0,
> >> > > :
> >> > >   NAs are not allowed in subscripted assignments
> >> > > In addition: Warning messages:
> >> > > 1: In min(x) : no non-missing arguments to min; returning Inf
> >> > > 2: In max(x) : no non-missing arguments to max; returning -Inf
> >> > > ?
> >> > >
> >> > > Postdoctoral Associate
> >> > > Department of Biology
> >> > > University of Maryland, College Park
> >> > >
> >> > > On Fri, Oct 9, 2015 at 7:24 AM, Jim Lemon <drjimlemon at gmail.com>
> >> > > wrote:
> >> > >
> >> > >> Hi Kumar,
> >> > >> The color.scale function translates numeric values into one or more
> >> > >> intervals of color by a linear transformation into the numeric
> values
> >> > that
> >> > >> specify colors. One of three color spaces (rgb, hcl and hsv) can be
> >> > >> specified, and the endpoints can be specified as
> "extremes=c(<minimum
> >> > >> color>,<maximum color>" or as three vectors of numbers. By default,
> >> > >> the
> >> > RGB
> >> > >> color space is used, so:
> >> > >>
> >> > >> # starts at RGB #FF0000 and finishes at RGB #FFFF00
> >> > >> red to yellow - extremes=c("red","yellow") OR
> >> > cs1=c(1,1),cs2=(c(0,1),cs3=0
> >> > >> # starts at RGB #FFFF00 and finishes at RGB #00FF00
> >> > >> yellow to green - extremes=c("yellow","green") OR
> >> > >> cs1=c(1,0),cs2=(c(1,1),cs3=0
> >> > >>
> >> > >> Obviously the shades of colors that you want may differ from the
> >> > >> above,
> >> > so
> >> > >> you have to play with the values to get the ones you want. In many
> >> > cases,
> >> > >> you will have to specify more than two numbers for the color specs
> to
> >> > get
> >> > >> the "in between" colors right, especially if the span of the colors
> >> > >> is
> >> > >> large.
> >> > >>
> >> > >> Jim
> >> > >>
> >> > >> On Fri, Oct 9, 2015 at 4:15 PM, Kumar Mainali <kpmainali at gmail.com
> >
> >> > wrote:
> >> > >>
> >> > >>> Hi Jim and others:
> >> > >>>
> >> > >>> I needed color code for some color gradients in color.scale
> >> > >>> function. I
> >> > >>> found that the following translates to green to yellow to
> >> > >>> red: c(0,1,1),c(1,1,0),0. How does this string translate to the
> >> > >>> color
> >> > >>> gradient? I would like to know the gradient code for red to
> yellow,
> >> > yellow
> >> > >>> to green and other ranges.
> >> > >>>
> >> > >>> Thanks,
> >> > >>> Kumar Mainali
> >> > >>>
> >> >
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Oct 10 00:51:17 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Oct 2015 15:51:17 -0700
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
Message-ID: <A4D5C47D-AC02-4653-AF84-4579273BC30A@comcast.net>


On Oct 9, 2015, at 2:48 PM, Omar Andr? Gonz?les D?az wrote:

> Thank you, David. You put me in the right direction. 
> 
> At the end, I've used a lot of lines, to my taste, for this task.
> 
> Is there a more elegant way, of doing this?

There are conditional capture-classes in rexex in addition to the variable span {.,.} operators, but when I suggested using more general patterns, you turned them down, with a desire for the more incremental approach.

his pattern extracts a larger number of cases:

 sub("(.*)([a-z]{0,3}[-]{0,1}[0-9]{2}[a-z]{1,2}[0-9]{2,4}[a-z]{0,1})(.*)", "\\2",
ripley.tv$producto,
ignore.case = T)

If I take out the leading space in the capture group then I get all cases extracted but it trims down the size of many of them. This with a trailing character class that has space or "\n" as an separator seems to be very successfull in one pass:

 sub("(.*[ \n])([a-z]{0,3}[-]{0,1}[0-9]{0,2}[a-z]{1,2}[0-9]{2,4}[a-z]{0,1})(.*)", "\\2",
 ripley.tv$producto,
 ignore.case = T)

 [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N" 
 [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"  
[11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"   
[16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"   
[21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"   
[26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"   
[31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"   
[36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"     
[41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"    
[46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"    
[51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"   
[56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"  
[61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"   
[66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C" "XBR-75X945C"
[71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"    
[76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"    
[81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"   
[86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"   "XBR-79X905B"
[91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"   "TC-42AS650L"
[96] "LC70LE660"   "LE58D3140"  
> 



-- 
David
> 
> 
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
>                     ripley.tv$producto,
>                     ignore.case = T)
> 
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
>                     ripley.tv$id,
>                     ignore.case = T)
> 
> ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}\\-[0-9]{2}[A-Z]{2}[0-9]{3}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}\\-[0-9]{2}[A-Z]{2}[0-9]{3})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{4})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{3}\\-[0-9]{2}[A-Z]{2}[0-9]{2}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{3}[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{3}\\-[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> ripley.tv$id <- sub("(.*)([0-9]{2}[A-Z]{2}[0-9]{3}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{2}[0-9]{2}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}\\-[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{3}[A-Z]{1})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> 
> ripley.tv$id <- sub("(.*)([A-Z]{2}[0-9]{2}[A-Z]{2}[0-9]{3})(.*)", "\\2",
>                     ripley.tv$id, ignore.case = T)
> 
> 
> 2015-10-09 16:16 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Oct 9, 2015, at 1:50 PM, Omar Andr? Gonz?les D?az wrote:
> 
> > David,
> >
> > this is a working case. I know that all cases for ID are not covered with my current code.
> >
> > The question is:
> >
> > ID stars as NAs.
> >
> > 1.- How to extract 1 type of ID, and keep the rest of entries as they are.
> >
> > 2.- Then keep the first extraction, and search for second type of ID.
> 
> If you want to use that workflow then you can replace $id with teh output of sub on $procuto the first time and then contiue workign on the results using $id as the input. The sub function returns the original values when there is no match.
> 
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> ripley.tv$producto,
> ignore.case = T)
> 
> ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> ripley.tv$id,
> ignore.case = T)
> 
> ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
> ripley.tv$id, ignore.case = T)
> 
> > head(ripley.tv$id, 20)
>  [1] "SMART TV LED FHD 48\" 3D\n48J6400"   " 40J5300"
>  [3] "TV LED FULL HD 40'' TC-40CS600L"     " LE28F6600 "
>  [5] "SMART TV 40\" HD LE40K5000N"         "TV LED HD 32'' LE32B7000"
>  [7] "SMART TV  32'' LE32K5000N"           "TV LED FHD 55\" -\nLE55B8000"
>  [9] " LE40B8000 "                         " LE24B8000 "
> [11] "TV LED FULL HD 42'' TC-42AS610"      "TELEVISOR LED LE50K5000N 50\""
> [13] "SMART TV LED UHD 40\" 40JU6500"      "SMART TV ULTRA HD 48'' 48JU6500"
> [15] " 50JU6500 "                          "SMART TV ULTRA HD 55'' 3D\n55JS9000"
> [17] "SMART TV LED UHD 55\" 55JU6500"      "SMART TV ULTRA HD 55'' 55JU6700"
> [19] " 55JU7500 "                          "SMART TV ULTRA HD 65''\n3D 65JS9000"
> 
> >
> 
> That shows all your failures. You can incremetally fix them I suppose.
> 
> --
> David.
> > 3.- An so on with all types of IDs in product column.
> >
> > I think it can be achieve with some ifelse construction I think... that's why my initial lines of code.
> >
> > Any hint is welcome.
> >
> >
> >
> >
> >
> >
> >
> > 2015-10-09 15:37 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > On Oct 9, 2015, at 12:59 PM, Omar Andr? Gonz?les D?az wrote:
> >
> > > I need to extract an ID from the product column of my df.
> > >
> > > I was able to extract the ids for some scenearios, but when applying my
> > > code for the next type of ids (there are some other combinations), the
> > > results of my first line of code got NAs.
> > >
> > >
> > > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{1}[0-9]{4})(.*)", "\\2",
> > > ripley.tv$producto,
> > > ignore.case = T)
> >
> > I think you need to examine the implicit logic of your pattern argument against the realities of your data:
> >
> > > as.matrix(head(ripley.tv$producto, 10))
> >       [,1]
> >  [1,] "SMART TV LED FHD 48\" 3D\n48J6400"
> >  [2,] "SMART TV LED FHD 40\" 40J5300"
> >  [3,] "TV LED FULL HD 40'' TC-40CS600L"
> >  [4,] "TELEVISOR LED LE28F6600 28\""
> >  [5,] "SMART TV 40\" HD LE40K5000N"
> >  [6,] "TV LED HD 32'' LE32B7000"
> >  [7,] "SMART TV  32'' LE32K5000N"
> >  [8,] "TV LED FHD 55\" -\nLE55B8000"
> >  [9,] "TV LED LE40B8000 FULL HD 40\""
> > [10,] "TV LE24B8000 LED HD 24\" - NEGRO"
> >
> > So the first value and most of the other values do not have a space before the segment of characters that you want to match, The third item has two character inside the flanking numbers.
> >
> > I tried fixing that by removing the space and putting in optional length values and discovered that some of you id's have only 3 trailing digit-characters:
> >
> >  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{4})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T), 20
> >   )
> > #-----------
> >  [1] "48J6400"                         "40J5300"
> >  [3] "TV LED FULL HD 40'' TC-40CS600L" "28F6600"
> >  [5] "40K5000"                         "32B7000"
> >  [7] "32K5000"                         "55B8000"
> >  [9] "40B8000"                         "24B8000"
> > [11] "TV LED FULL HD 42'' TC-42AS610"  "50K5000"
> > [13] "40JU6500"                        "48JU6500"
> > [15] "50JU6500"                        "55JS9000"
> > [17] "55JU6500"                        "55JU6700"
> > [19] "55JU7500"                        "65JS9000"
> >
> >  head( sub("(.*)([0-9]{2}[a-z]{1,2}[0-9]{3,4})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T), 20
> >   )
> > #--------------
> >  [1] "48J6400"  "40J5300"  "40CS600"  "28F6600"  "40K5000"  "32B7000"
> >  [7] "32K5000"  "55B8000"  "40B8000"  "24B8000"  "42AS610"  "50K5000"
> > [13] "40JU6500" "48JU6500" "50JU6500" "55JS9000" "55JU6500" "55JU6700"
> > [19] "55JU7500" "65JS9000"
> >
> > >
> > > ripley.tv$id <- sub("(.*)( [0-9]{2}[a-z]{2}[0-9]{4} )(.*)", "\\2",
> > > ripley.tv$producto,
> > > ignore.case = T)
> > >
> > > ripley.tv$id <- sub("(.*)( [a-z]{2}[0-9]{2}[a-z]{1}[0-9]{4} )(.*)", "\\2",
> > > ripley.tv$producto, ignore.case = T)
> > >
> > >
> > > Also I've tried to use the ifelse function, but got "/2" as result.
> >
> > I think you will find that `ifelse` delivers strange results when used with factors as values. It strips attributes.
> >
> >
> >
> > --
> > david.
> > >
> > >
> > > ripley.tv <- ripley.tv %>%
> > >        mutate(id = NA,
> > >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{1}[0-9]{4})(.*)",
> > > ripley.tv$producto) == T, "\\2",id),
> > >              id = ifelse(grepl("(.*)([0-9]{2}[A-Z]{2}[0-9]{4})(.*)",
> > > ripley.tv$producto) == T, "\\2",id),
> > >              id =
> > > ifelse(grepl("(.*)([A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4})(.*)", ripley.tv$producto)
> > > == T, "\\2",id))
> > >
> > >
> > >
> > > And also str_extract:
> > >
> > >
> > > ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{1}[0-9]{4}")
> > > ripley.tv$id <- str_extract(ripley.tv$producto, "[0-9]{2}[A-Z]{2}[0-9]{4}")
> > > ripley.tv$id <- str_extract(ripley.tv$producto,
> > > "[A-Z]{2}[0-9]{2}[A-Z]{1}[0-9]{4}")
> > >
> > > This is my data:
> > >
> > >
> > > ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > > NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> > > "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> > > "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > > "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> > > "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> > > "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> > > "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> > > "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> > > "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> > > "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> > > "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> > > "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> > > "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> > > 48J6400",
> > > "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> > > "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> > > "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD 55\" -
> > > LE55B8000",
> > > "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> > > "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> > > "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> > > "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> > > 55JS9000",
> > > "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> > > "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD 65''
> > > 3D 65JS9000",
> > > "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> > > "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD 40LF6350",
> > > "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> > > 42LF6450",
> > > "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> > > 3D",
> > > "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> > > "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD 4K",
> > > "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART TV
> > > 55UF7700",
> > > "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD 4K
> > > 3D",
> > > "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K SMART
> > > TC-50CX640W",
> > > "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K CINEMA
> > > SMART UG8700",
> > > "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD 3D",
> > > "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD KDL-40R354B",
> > > "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50'' 50J5500",
> > > "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> > > "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D 40J6400",
> > > "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD KDL-40R555C
> > > - NEGRO",
> > > "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> > > "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> > > "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> > > KDL-65W855C",
> > > "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> > > "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> > > "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> > > LE32W454F",
> > > "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> > > KDL-55W805C",
> > > "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> > > XBR-55X855C",
> > > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\" ULTRA HD
> > > 4K 3D XBR-75X945C",
> > > "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> > > ULTRA HD 4K LC60UE30U",
> > > "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD 4K
> > > LC80UE30U",
> > > "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\" ULTRA HD
> > > 4K 3D",
> > > "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA HD
> > > 4K 3D",
> > > "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\" 32J4300",
> > > "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700 55\"
> > > ULTRA HD 4K 3D",
> > > "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL HD
> > > 3D",
> > > "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD 50''
> > > TC-50AS600L",
> > > "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U 70''",
> > > "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> > > "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO 55HU8700",
> > > "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> > > "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> > > ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> > > 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> > > 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> > > 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> > > 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> > > 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> > > 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> > > 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes = c(2799L,
> > > 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> > > 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> > > 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> > > 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> > > 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> > > 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> > > 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> > > 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> > > 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> > > 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> > > 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> > > 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> > > 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> > > 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> > > 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> > > 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> > > 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> > > 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> > > 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> > > 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> > > 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> > > 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> > > 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> > > 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> > > 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> > > 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> > > 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> > > 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> > > 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> > > 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> > > 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> > > 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> > > 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> > > 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> > > 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> > > 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> > > 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> > > 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 - S/.2500",
> > > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> > > S/.1500",
> > > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > > "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> > > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> > > "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> > > "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> > > "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> > > "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> > > "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> > > "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> > > "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> > > "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > > "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> > > "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > > "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > > "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > > "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names = c("id",
> > > "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> > > "dif.precios", "dif.porcentual", "rangos"), class = "data.frame", row.names
> > > = c(NA,
> > > -97L))
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From boris.steipe at utoronto.ca  Sat Oct 10 01:21:06 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 9 Oct 2015 19:21:06 -0400
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
Message-ID: <FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>

I think you are going into the wrong direction here and this is a classical example of what we mean by "technical debt" of code. Rather than tell to your regular expression what you are looking for, you are handling special cases with redundant code. This is ugly, brittle and impossible to maintain.

Respect to you that you have recognized this.


The solution is rather simple: 

A) Isolate tokens. Your IDs contain only a limited set of characters. Split your strings along the characters that are not found in IDs to isolate candidate tokens, place them into a vector.

B) Evaluate your tokens: as far as I can see IDs all contain letters AND numbers. This is a unique characteristic. Thus it is sufficient to grep for a letter/number pair in a token to identify it as an ID.

Should you ever find a need to accommodate differently formed IDs, there are only two, well defined places with clearly delegated roles where changes might be needed.

Here is the code:

for (i in 1:nrow(ripley.tv)) {
	v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) # isolate tokens
	ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and store
}



Cheers,
Boris



On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:

>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
>>>> 48J6400",
>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
>> 55\" -
>>>> LE55B8000",
>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
>>>> 55JS9000",
>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
>> 65''
>>>> 3D 65JS9000",
>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
>> 40LF6350",
>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
>>>> 42LF6450",
>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
>>>> 3D",
>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
>> 4K",
>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
>> TV
>>>> 55UF7700",
>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD
>> 4K
>>>> 3D",
>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
>> SMART
>>>> TC-50CX640W",
>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
>> CINEMA
>>>> SMART UG8700",
>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
>> 3D",
>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
>> KDL-40R354B",
>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
>> 50J5500",
>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
>> 40J6400",
>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
>> KDL-40R555C
>>>> - NEGRO",
>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
>>>> KDL-65W855C",
>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
>>>> LE32W454F",
>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
>>>> KDL-55W805C",
>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
>>>> XBR-55X855C",
>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
>> ULTRA HD
>>>> 4K 3D XBR-75X945C",
>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
>>>> ULTRA HD 4K LC60UE30U",
>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD
>> 4K
>>>> LC80UE30U",
>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
>> ULTRA HD
>>>> 4K 3D",
>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA
>> HD
>>>> 4K 3D",
>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
>> 32J4300",
>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
>> 55\"
>>>> ULTRA HD 4K 3D",
>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
>> HD
>>>> 3D",
>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
>> 50''
>>>> TC-50AS600L",
>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
>> 70''",
>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
>> 55HU8700",
>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
>> c(2799L,
>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
>> S/.2500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>>> S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
>> S/.2500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
>> S/.1500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
>> S/.2500",
>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
>> S/.1500",
>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
>> S/.2500",
>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
>> c("id",
>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
>> row.names
>>>> = c(NA,
>>>> -97L))


From r.turner at auckland.ac.nz  Sat Oct 10 01:28:16 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 10 Oct 2015 12:28:16 +1300
Subject: [R] [FORGED] Re:  R lappy, sapply or mapply question
In-Reply-To: <CAN5YmCGwnfgKeUp0=AtZK-XwEGwGrzfu9kkP=UNdPRPHsrJQrg@mail.gmail.com>
References: <7539129727B06D42A9F1A56D2C597F851139BF13@FHSDB2D11-2.csu.mcmaster.ca>
	<1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>
	<CAN5YmCGwnfgKeUp0=AtZK-XwEGwGrzfu9kkP=UNdPRPHsrJQrg@mail.gmail.com>
Message-ID: <56184D90.3030108@auckland.ac.nz>

On 10/10/15 10:56, Adams, Jean wrote:
> You were very close.  Try this.
>
> df <- data.frame(x5=dailyrecord$a, x6 = dailyrecord$e, x7 = dailyrecord$f)
> apply(df, 1, function(row) fun3(list1, list2, as.list(row)))


There could in general be problems with this approach.  The apply() 
function works on *matrices* and if handed a data frame coerces it to a 
matrix.  This is (usually!) OK if all columns of the data frame are of 
the same type, but the world could end if they are not. It is a good 
idea to *start* with a matrix if a matrix is what is required.  And do 
not confuse data frames with matrices.  They are very different animals.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From dwinsemius at comcast.net  Sat Oct 10 01:32:59 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Oct 2015 16:32:59 -0700
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
Message-ID: <D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>


On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:

> I think you are going into the wrong direction here and this is a classical example of what we mean by "technical debt" of code. Rather than tell to your regular expression what you are looking for, you are handling special cases with redundant code. This is ugly, brittle and impossible to maintain.
> 
> Respect to you that you have recognized this.
> 
> 
> The solution is rather simple: 
> 
> A) Isolate tokens. Your IDs contain only a limited set of characters. Split your strings along the characters that are not found in IDs to isolate candidate tokens, place them into a vector.
> 
> B) Evaluate your tokens: as far as I can see IDs all contain letters AND numbers. This is a unique characteristic. Thus it is sufficient to grep for a letter/number pair in a token to identify it as an ID.
> 
> Should you ever find a need to accommodate differently formed IDs, there are only two, well defined places with clearly delegated roles where changes might be needed.
> 
> Here is the code:
> 
> for (i in 1:nrow(ripley.tv)) {
> 	v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) # isolate tokens
> 	ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and store
> }

That logic actually simplifies the regex strategy as well:

 sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
 ripley.tv$producto,
 ignore.case = T)

 
Almost succeeds, with a few all-character words, but if you require one number in the middle you get full results:

 sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
 ripley.tv$producto,
 ignore.case = T)

 [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N" 
 [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"  
[11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"   
[16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"   
[21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"   
[26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"   
[31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"   
[36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"     
[41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"    
[46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"    
[51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"   
[56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"  
[61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"   
[66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C" "XBR-75X945C"
[71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"    
[76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"    
[81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"   
[86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"   "XBR-79X905B"
[91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"   "TC-42AS650L"
[96] "LC70LE660"   "LE58D3140"  

> 
> 
> 
> Cheers,
> Boris
> 
> 
> 
> On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:
> 
>>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA,
>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
>>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
>>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
>>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
>>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
>>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
>>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
>>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
>>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
>>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
>>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
>>>>> 48J6400",
>>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
>>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
>>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
>>> 55\" -
>>>>> LE55B8000",
>>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
>>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
>>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
>>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
>>>>> 55JS9000",
>>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
>>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
>>> 65''
>>>>> 3D 65JS9000",
>>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
>>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
>>> 40LF6350",
>>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
>>>>> 42LF6450",
>>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
>>>>> 3D",
>>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
>>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
>>> 4K",
>>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
>>> TV
>>>>> 55UF7700",
>>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD
>>> 4K
>>>>> 3D",
>>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
>>> SMART
>>>>> TC-50CX640W",
>>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
>>> CINEMA
>>>>> SMART UG8700",
>>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
>>> 3D",
>>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
>>> KDL-40R354B",
>>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
>>> 50J5500",
>>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
>>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
>>> 40J6400",
>>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
>>> KDL-40R555C
>>>>> - NEGRO",
>>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
>>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
>>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
>>>>> KDL-65W855C",
>>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
>>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
>>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
>>>>> LE32W454F",
>>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
>>>>> KDL-55W805C",
>>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
>>>>> XBR-55X855C",
>>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
>>> ULTRA HD
>>>>> 4K 3D XBR-75X945C",
>>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
>>>>> ULTRA HD 4K LC60UE30U",
>>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD
>>> 4K
>>>>> LC80UE30U",
>>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
>>> ULTRA HD
>>>>> 4K 3D",
>>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA
>>> HD
>>>>> 4K 3D",
>>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
>>> 32J4300",
>>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
>>> 55\"
>>>>> ULTRA HD 4K 3D",
>>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
>>> HD
>>>>> 3D",
>>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
>>> 50''
>>>>> TC-50AS600L",
>>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
>>> 70''",
>>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
>>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
>>> 55HU8700",
>>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
>>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
>>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
>>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
>>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
>>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
>>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
>>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
>>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
>>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
>>> c(2799L,
>>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
>>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
>>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
>>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
>>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
>>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
>>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
>>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
>>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
>>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
>>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
>>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
>>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
>>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
>>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
>>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
>>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
>>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
>>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
>>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
>>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
>>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
>>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
>>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
>>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
>>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
>>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
>>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
>>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
>>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
>>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
>>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
>>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
>>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
>>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
>>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
>>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
>>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
>>> S/.2500",
>>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>>>> S/.1500",
>>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
>>> S/.2500",
>>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
>>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
>>> S/.1500",
>>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
>>> S/.2500",
>>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
>>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
>>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
>>> S/.1500",
>>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
>>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
>>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
>>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
>>> S/.2500",
>>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
>>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
>>> c("id",
>>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
>>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
>>> row.names
>>>>> = c(NA,
>>>>> -97L))
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From erin.conlisk at gmail.com  Sat Oct 10 02:00:55 2015
From: erin.conlisk at gmail.com (Erin Conlisk)
Date: Fri, 9 Oct 2015 17:00:55 -0700
Subject: [R] Problem with binomial gam{mgcv}
Message-ID: <CAMsrtkjc48tz4bcQ3e7tpKufWp1Kc4Gq9tY+-9GpU2LRC5AWRQ@mail.gmail.com>

Hello,

I am having trouble testing for the significance using a binomial model in
gam{mgcv}.  Have I stumbled on a bug?  I doubt I would be so lucky, so
could someone tell me what I am doing wrong?

Please see the following code:
________________________________

# PROBLEM USING cbind

x1 <- runif(500, 0, 100)  # Create 500 random variables to use as my
explanatory variable

y1 <- floor(runif(500, 0, 100)) # Create 500 random counts to serve as
binomial "successes"

y2 <- 100-y1 # Create 500 binomial "failures", assuming a total of 100
trials and the successes recorded in y1

Model <- gam(cbind(y1, y2) ? 1 + s(x1), family=binomial)
summary(Model)
________________________________

The result is that my random variable, x1, is highly significant.  This
can't be right...

So what happens when I change the observations from a "batch" of 100 trials
to individual successes and failures?
________________________________

# NOW MAKE ALL THESE DATA 0 and 1

r01<-rep(0,500)
data01<-cbind(x1, y1, y2, r01)
rownames(data01)<-seq(1,500, 1)
colnames(data01)<-c('x1', 'y1', 'y2', 'r01')
data01<-data.frame(data01)

expanded0 <- data01[rep(row.names(data01), data01$y1), 1:4]  # Creates a
replicate of the      #  explanatory variables for each individual "success"

r01<-rep(1,500)
data01<-cbind(x1, y1, y2, r01)
rownames(data01)<-seq(1,500, 1)
colnames(data01)<-c('x1', 'y1', 'y2', 'r01')
data01<-data.frame(data01)

expanded1 <- data01[rep(row.names(data01), data01$y2), 1:4]  # Creates a
replicate of the      #  explanatory variables for each individual "failure"

data01<-rbind(expanded0,expanded1)

Model2 <- gam(r01 ? 1 + s(x1), family=binomial)
summary(Model2)
___________________________________

The result is what I expect.  Now my random variable, x1, is NOT
significant.

What is going on here?

I should say that I didn't just make this up.  My question arose playing
with my real data, where I was getting high significance, but a terrible
proportion of deviance explained.

My apologies if this is explained elsewhere, but I have spent hours
searching for an answer online.

Thank you kindly,
Erin Conlisk

-- 
Postdoctoral Researcher
UC Berkeley
Energy and Resources Group
310 Barrows Hall
Berkeley, CA 94720

cell: 858-776-2939

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Sat Oct 10 06:38:21 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Fri, 9 Oct 2015 23:38:21 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
Message-ID: <CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>

David, Boris, so thankfull for your help. Both approaches are very good. I
got this solve with David's help.

I find very insteresting Bori's for loop. And I need a little help
understanding the regex part on it.

- The strsplit function: strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")

I understand for this: split every row by a sequence of any number or
letter or "-" that appears at leat once (+ operator).

1.- What does mena the "^" symbol? If you remove it, just appeare blanks.
2.- Why is there the necessity of "+" after the closing "]"?

3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
     Identifies also the IDs where "-" is present. Here the regex does not
have the "-" included.


Also, I notice that David used the "-" at the begining of the
matching: [-A-Z0-9],
without the "^" (stars with) at the beginning.

I would appreciate a response from you, gentlemen.

Thanks again.











2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
>
> > I think you are going into the wrong direction here and this is a
> classical example of what we mean by "technical debt" of code. Rather than
> tell to your regular expression what you are looking for, you are handling
> special cases with redundant code. This is ugly, brittle and impossible to
> maintain.
> >
> > Respect to you that you have recognized this.
> >
> >
> > The solution is rather simple:
> >
> > A) Isolate tokens. Your IDs contain only a limited set of characters.
> Split your strings along the characters that are not found in IDs to
> isolate candidate tokens, place them into a vector.
> >
> > B) Evaluate your tokens: as far as I can see IDs all contain letters AND
> numbers. This is a unique characteristic. Thus it is sufficient to grep for
> a letter/number pair in a token to identify it as an ID.
> >
> > Should you ever find a need to accommodate differently formed IDs, there
> are only two, well defined places with clearly delegated roles where
> changes might be needed.
> >
> > Here is the code:
> >
> > for (i in 1:nrow(ripley.tv)) {
> >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) #
> isolate tokens
> >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and
> store
> > }
>
> That logic actually simplifies the regex strategy as well:
>
>  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T)
>
>
> Almost succeeds, with a few all-character words, but if you require one
> number in the middle you get full results:
>
>  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T)
>
>  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N"
>  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"
> [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"
> [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"
> [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"
> [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"
> [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"
> [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
> [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
> [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
> [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"
> [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"
> [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"
> [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C" "XBR-75X945C"
> [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
> [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
> [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"
> [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"   "XBR-79X905B"
> [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"   "TC-42AS650L"
> [96] "LC70LE660"   "LE58D3140"
>
> >
> >
> >
> > Cheers,
> > Boris
> >
> >
> >
> > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com> wrote:
> >
> >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
> >>> NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
> "SAMSUNG",
> >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> >>>>> 48J6400",
> >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
> >>> 55\" -
> >>>>> LE55B8000",
> >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> >>>>> 55JS9000",
> >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
> >>> 65''
> >>>>> 3D 65JS9000",
> >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> >>> 40LF6350",
> >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> >>>>> 42LF6450",
> >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL
> HD
> >>>>> 3D",
> >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
> >>> 4K",
> >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
> >>> TV
> >>>>> 55UF7700",
> >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA
> HD
> >>> 4K
> >>>>> 3D",
> >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
> >>> SMART
> >>>>> TC-50CX640W",
> >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
> >>> CINEMA
> >>>>> SMART UG8700",
> >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL
> HD
> >>> 3D",
> >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> >>> KDL-40R354B",
> >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> >>> 50J5500",
> >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> >>> 40J6400",
> >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> >>> KDL-40R555C
> >>>>> - NEGRO",
> >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" -
> NEGRO",
> >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> >>>>> KDL-65W855C",
> >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> >>>>> LE32W454F",
> >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> >>>>> KDL-55W805C",
> >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> >>>>> XBR-55X855C",
> >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
> >>> ULTRA HD
> >>>>> 4K 3D XBR-75X945C",
> >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED
> 60''
> >>>>> ULTRA HD 4K LC60UE30U",
> >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA
> HD
> >>> 4K
> >>>>> LC80UE30U",
> >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
> >>> ULTRA HD
> >>>>> 4K 3D",
> >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\"
> ULTRA
> >>> HD
> >>>>> 4K 3D",
> >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> >>> 32J4300",
> >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
> >>> 55\"
> >>>>> ULTRA HD 4K 3D",
> >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
> >>> HD
> >>>>> 3D",
> >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL
> HD
> >>> 50''
> >>>>> TC-50AS600L",
> >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
> >>> 70''",
> >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
> TC-40A400L",
> >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> >>> 55HU8700",
> >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
> TC-42AS650L",
> >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> >>> c(2799L,
> >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> >>> S/.2500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> >>>>> S/.1500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> >>> S/.1500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> >>> S/.1500",
> >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> >>> c("id",
> >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> >>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> >>> row.names
> >>>>> = c(NA,
> >>>>> -97L))
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Oct 10 06:59:17 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 9 Oct 2015 21:59:17 -0700
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
Message-ID: <70089707-9CE1-4A5F-8D57-9E3EF551006C@comcast.net>


On Oct 9, 2015, at 9:38 PM, Omar Andr? Gonz?les D?az wrote:

> David, Boris, so thankfull for your help. Both approaches are very good. I got this solve with David's help. 
> 
> I find very insteresting Bori's for loop. And I need a little help understanding the regex part on it.
> 
> - The strsplit function: strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")
> 
> I understand for this: split every row by a sequence of any number or letter or "-" that appears at leat once (+ operator).
> 
> 1.- What does mena the "^" symbol? If you remove it, just appeare blanks.

Read the section of ?regex on character classes. A leading caret is a negation flag for the rest of the symbols inside the flanking "[]".


> 2.- Why is there the necessity of "+" after the closing "]"?

Might not be necessary but it means that double or tripled separators get handled as a single split.


> 
> 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>      Identifies also the IDs where "-" is present. Here the regex does not have the "-" included.

<character>-<character> is a range within character classes.

> 
> 
> Also, I notice that David used the "-" at the begining of the matching: [-A-Z0-9], without the "^" (stars with) at the beginning. 

Right. If it's the leading symbol, then "-" is interpreted as a literal rather than a range.

-- 
David.
> 
> I would appreciate a response from you, gentlemen. 
> 
> Thanks again.
> 
> 
> 
> 
> 
> 
> 
>  
> 
> 
> 
> 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
> 
> > I think you are going into the wrong direction here and this is a classical example of what we mean by "technical debt" of code. Rather than tell to your regular expression what you are looking for, you are handling special cases with redundant code. This is ugly, brittle and impossible to maintain.
> >
> > Respect to you that you have recognized this.
> >
> >
> > The solution is rather simple:
> >
> > A) Isolate tokens. Your IDs contain only a limited set of characters. Split your strings along the characters that are not found in IDs to isolate candidate tokens, place them into a vector.
> >
> > B) Evaluate your tokens: as far as I can see IDs all contain letters AND numbers. This is a unique characteristic. Thus it is sufficient to grep for a letter/number pair in a token to identify it as an ID.
> >
> > Should you ever find a need to accommodate differently formed IDs, there are only two, well defined places with clearly delegated roles where changes might be needed.
> >
> > Here is the code:
> >
> > for (i in 1:nrow(ripley.tv)) {
> >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) # isolate tokens
> >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and store
> > }
> 
> That logic actually simplifies the regex strategy as well:
> 
>  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T)
> 
> 
> Almost succeeds, with a few all-character words, but if you require one number in the middle you get full results:
> 
>  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T)
> 
>  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N"
>  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"
> [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"
> [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"
> [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"
> [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"
> [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"
> [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
> [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
> [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
> [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"
> [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"
> [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"
> [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C" "XBR-75X945C"
> [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
> [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
> [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"
> [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"   "XBR-79X905B"
> [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"   "TC-42AS650L"
> [96] "LC70LE660"   "LE58D3140"
> 
> >
> >
> >
> > Cheers,
> > Boris
> >
> >
> >
> > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:
> >
> >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
> >>> NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> >>>>> 48J6400",
> >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
> >>> 55\" -
> >>>>> LE55B8000",
> >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> >>>>> 55JS9000",
> >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
> >>> 65''
> >>>>> 3D 65JS9000",
> >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> >>> 40LF6350",
> >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> >>>>> 42LF6450",
> >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> >>>>> 3D",
> >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
> >>> 4K",
> >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
> >>> TV
> >>>>> 55UF7700",
> >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD
> >>> 4K
> >>>>> 3D",
> >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
> >>> SMART
> >>>>> TC-50CX640W",
> >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
> >>> CINEMA
> >>>>> SMART UG8700",
> >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
> >>> 3D",
> >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> >>> KDL-40R354B",
> >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> >>> 50J5500",
> >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> >>> 40J6400",
> >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> >>> KDL-40R555C
> >>>>> - NEGRO",
> >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> >>>>> KDL-65W855C",
> >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> >>>>> LE32W454F",
> >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> >>>>> KDL-55W805C",
> >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> >>>>> XBR-55X855C",
> >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
> >>> ULTRA HD
> >>>>> 4K 3D XBR-75X945C",
> >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> >>>>> ULTRA HD 4K LC60UE30U",
> >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD
> >>> 4K
> >>>>> LC80UE30U",
> >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
> >>> ULTRA HD
> >>>>> 4K 3D",
> >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA
> >>> HD
> >>>>> 4K 3D",
> >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> >>> 32J4300",
> >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
> >>> 55\"
> >>>>> ULTRA HD 4K 3D",
> >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
> >>> HD
> >>>>> 3D",
> >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
> >>> 50''
> >>>>> TC-50AS600L",
> >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
> >>> 70''",
> >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> >>> 55HU8700",
> >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> >>> c(2799L,
> >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> >>> S/.2500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> >>>>> S/.1500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> >>> S/.1500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> >>> S/.1500",
> >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> >>> c("id",
> >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> >>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> >>> row.names
> >>>>> = c(NA,
> >>>>> -97L))
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From syen04 at gmail.com  Sat Oct 10 07:57:06 2015
From: syen04 at gmail.com (Steven Yen)
Date: Sat, 10 Oct 2015 01:57:06 -0400
Subject: [R] Construct a lower-triangular matrix
Message-ID: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>

Dear
How do you construct a lower triangular matrix from a vector.

I want to make vector

a <- 1:10

into a triangular matrix

1 0 0  0
2 3 0  0
4 5 6  0
7 8 9 10

Thank you!

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sat Oct 10 08:11:44 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 10 Oct 2015 02:11:44 -0400
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
Message-ID: <217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>

David answered most of this. Just a two short notes inline.




On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:

> David, Boris, so thankfull for your help. Both approaches are very good. I got this solve with David's help. 
> 
> I find very insteresting Bori's for loop. And I need a little help understanding the regex part on it.
> 
> - The strsplit function: strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")
> 
> I understand for this: split every row by a sequence of any number or letter or "-" that appears at leat once (+ operator).
> 
> 1.- What does mena the "^" symbol? If you remove it, just appeare blanks.
> 2.- Why is there the necessity of "+" after the closing "]"?
> 
> 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>      Identifies also the IDs where "-" is present. Here the regex does not have the "-" included.

Yes. I am not matching the entire token here. Note there is no "+": The two character-class expressions match exactly one uppercase character adjacent to exactly one number. If this is found in a token, grep returns TRUE. It doesn't matter what else the token contains - the first regex already took care of removing everything that's not needed. The vector of FALSEs and a single TRUE that grep() returns goes inside the square brackets, and selects the token from v. 



> Also, I notice that David used the "-" at the begining of the matching: [-A-Z0-9], without the "^" (stars with) at the beginning. 

This can be very confusing about regular expressions: the same character can mean different things depending on where it is found. Between two characters in a character class expresssion, the hyphen means "range". Elsewhere it is a literal hyphen. David put his at the beginning, I had it at the end (in the first regex). Another tricky character is "?" which can mean 0,1 matches, or turn "greedy" matching off... 

Online regex testers are invaluable to develop a regex - one I frequently use is regexpal.com

Cheers,
B.


> 
> I would appreciate a response from you, gentlemen. 
> 
> Thanks again.
> 
> 
> 
> 
> 
> 
> 
>  
> 
> 
> 
> 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> 
> On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
> 
> > I think you are going into the wrong direction here and this is a classical example of what we mean by "technical debt" of code. Rather than tell to your regular expression what you are looking for, you are handling special cases with redundant code. This is ugly, brittle and impossible to maintain.
> >
> > Respect to you that you have recognized this.
> >
> >
> > The solution is rather simple:
> >
> > A) Isolate tokens. Your IDs contain only a limited set of characters. Split your strings along the characters that are not found in IDs to isolate candidate tokens, place them into a vector.
> >
> > B) Evaluate your tokens: as far as I can see IDs all contain letters AND numbers. This is a unique characteristic. Thus it is sufficient to grep for a letter/number pair in a token to identify it as an ID.
> >
> > Should you ever find a need to accommodate differently formed IDs, there are only two, well defined places with clearly delegated roles where changes might be needed.
> >
> > Here is the code:
> >
> > for (i in 1:nrow(ripley.tv)) {
> >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) # isolate tokens
> >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and store
> > }
> 
> That logic actually simplifies the regex strategy as well:
> 
>  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T)
> 
> 
> Almost succeeds, with a few all-character words, but if you require one number in the middle you get full results:
> 
>  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>  ripley.tv$producto,
>  ignore.case = T)
> 
>  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N"
>  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"
> [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"
> [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"
> [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"
> [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"
> [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"
> [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
> [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
> [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
> [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"
> [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"
> [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"
> [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C" "XBR-75X945C"
> [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
> [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
> [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"
> [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"   "XBR-79X905B"
> [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"   "TC-42AS650L"
> [96] "LC70LE660"   "LE58D3140"
> 
> >
> >
> >
> > Cheers,
> > Boris
> >
> >
> >
> > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:
> >
> >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
> >>> NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> >>>>> 48J6400",
> >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
> >>> 55\" -
> >>>>> LE55B8000",
> >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> >>>>> 55JS9000",
> >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
> >>> 65''
> >>>>> 3D 65JS9000",
> >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> >>> 40LF6350",
> >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> >>>>> 42LF6450",
> >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> >>>>> 3D",
> >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
> >>> 4K",
> >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
> >>> TV
> >>>>> 55UF7700",
> >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD
> >>> 4K
> >>>>> 3D",
> >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
> >>> SMART
> >>>>> TC-50CX640W",
> >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
> >>> CINEMA
> >>>>> SMART UG8700",
> >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
> >>> 3D",
> >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> >>> KDL-40R354B",
> >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> >>> 50J5500",
> >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> >>> 40J6400",
> >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> >>> KDL-40R555C
> >>>>> - NEGRO",
> >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> >>>>> KDL-65W855C",
> >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> >>>>> LE32W454F",
> >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> >>>>> KDL-55W805C",
> >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> >>>>> XBR-55X855C",
> >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
> >>> ULTRA HD
> >>>>> 4K 3D XBR-75X945C",
> >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> >>>>> ULTRA HD 4K LC60UE30U",
> >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD
> >>> 4K
> >>>>> LC80UE30U",
> >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
> >>> ULTRA HD
> >>>>> 4K 3D",
> >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA
> >>> HD
> >>>>> 4K 3D",
> >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> >>> 32J4300",
> >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
> >>> 55\"
> >>>>> ULTRA HD 4K 3D",
> >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
> >>> HD
> >>>>> 3D",
> >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
> >>> 50''
> >>>>> TC-50AS600L",
> >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
> >>> 70''",
> >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> >>> 55HU8700",
> >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> >>> c(2799L,
> >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> >>> S/.2500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> >>>>> S/.1500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> >>> S/.1500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> >>> S/.1500",
> >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> >>> S/.2500",
> >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> >>> c("id",
> >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> >>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> >>> row.names
> >>>>> = c(NA,
> >>>>> -97L))
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 


From dwinsemius at comcast.net  Sat Oct 10 10:00:48 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 10 Oct 2015 01:00:48 -0700
Subject: [R] Construct a lower-triangular matrix
In-Reply-To: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>
References: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>
Message-ID: <4880E324-8914-461C-9093-3B06E9DF96E4@comcast.net>


On Oct 9, 2015, at 10:57 PM, Steven Yen wrote:

> Dear
> How do you construct a lower triangular matrix from a vector.
> 
> I want to make vector
> 
> a <- 1:10
> 
> into a triangular matrix
> 
> 1 0 0  0
> 2 3 0  0
> 4 5 6  0
> 7 8 9 10
> 

I'm not sure this method with logical indexing will be the most elegant:

?lower.tri
?col

> b=matrix(0, sqrt(10)+1,sqrt(10)+1)

> b[lower.tri(b)| row(b)==col(b)] <- 1:10
> b
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    2    5    0    0
[3,]    3    6    8    0
[4,]    4    7    9   10

> Thank you!
> 
> 	[[alternative HTML version deleted]]


David Winsemius
Alameda, CA, USA


From bhh at xs4all.nl  Sat Oct 10 10:49:55 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 10 Oct 2015 10:49:55 +0200
Subject: [R] Construct a lower-triangular matrix
In-Reply-To: <4880E324-8914-461C-9093-3B06E9DF96E4@comcast.net>
References: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>
	<4880E324-8914-461C-9093-3B06E9DF96E4@comcast.net>
Message-ID: <093D92EB-BE22-49D2-A920-2B0EF202395B@xs4all.nl>


> On 10 Oct 2015, at 10:00, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On Oct 9, 2015, at 10:57 PM, Steven Yen wrote:
> 
>> Dear
>> How do you construct a lower triangular matrix from a vector.
>> 
>> I want to make vector
>> 
>> a <- 1:10
>> 
>> into a triangular matrix
>> 
>> 1 0 0  0
>> 2 3 0  0
>> 4 5 6  0
>> 7 8 9 10
>> 
> 
> I'm not sure this method with logical indexing will be the most elegant:
> 
> ?lower.tri
> ?col
> 
>> b=matrix(0, sqrt(10)+1,sqrt(10)+1)
> 
>> b[lower.tri(b)| row(b)==col(b)] <- 1:10
>> b
>     [,1] [,2] [,3] [,4]
> [1,]    1    0    0    0
> [2,]    2    5    0    0
> [3,]    3    6    8    0
> [4,]    4    7    9   10
> 

That doesn?t seem to be what the OP wanted.

This should do it.

a <- 1:10
C <- matrix(0, sqrt(length(a))+1,sqrt(length(a))+1)
i.upr <- which(upper.tri(C, diag = TRUE), arr.ind=TRUE)
C[i.upr] <- a
t(C)

resulting in

     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    2    3    0    0
[3,]    4    5    6    0
[4,]    7    8    9   10

I found this here: http://stackoverflow.com/questions/24472060/indexing-upper-or-lower-triangle-in-matrix-with-diagonal

Berend


From arnaud.gaboury at gmail.com  Sat Oct 10 12:24:07 2015
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Sat, 10 Oct 2015 12:24:07 +0200
Subject: [R] R environment variables
Message-ID: <CAK1hC9t3ST0mBtXwOk3oF3YyPPy4TqjBT1nZ0RWiQ+YSbXxMLw@mail.gmail.com>

I was doing some cleaning ony my linux machine and, among others, I
try to clean my R environment variables accordingly [0] and [1].
I am not really sure how to declare in a clean manner these startup variables.

Here is my setup:

1- my home folder
-$ ls ~/.config/R
env/  helper/  Renviron  Rprofile.r

2- system R install
/usr/lib/R

3- user library
/developement/language/r/library

4- system configuration files: (NOTE: /usr/lib/R/etc/ are symlnks to
the below files)
$ ls /etc/R/
javaconf  ldpaths  Makeconf  Renviron  repositories

--------------------------------

Most important R environment variables for my system:
R_HOME, R_LIBS, R_LIBS_SITE,R_LIBS_USER,R_ENVIRON,R_ENVIRON_USER,R_PROFILE_USER

As far I can understand, in my setup, these above variables would be:
R_LIBS_SITE=/usr/lib/R/library
R_LIBS_USER=/developement/language/r/library
R_ENVIRON=/usr/lib/R/etc/Renviron
R_ENVIRON_USER=~/.config/R/Renviron
R_PROFILE_USER=~/.config/R/Rprofile.r

I have a doubt about two variables:
R_HOME=/usr/lib/R/ right ? Is there any need to export it in my environment?
R_LIBS=${R_LIBS_USER}:${R_LIBS_SITE} right ?

Do I need to export all these mentioned variables in my user
environment? Until now, I jsut export R_ENVIRON_USER,R_PROFILE_USER
via my /etc/profile file.

$ cat ~/.config/r/Renviron
....
R_HOME=/usr/lib/R
R_HOME_USER=/developement/language/r
R_LIBS_USER=${R_HOME_USER}/library
R_LIBS=${R_LIBS_USER}:${R_HOME}/library
R_HISTFILE=/developement/language/r/R.Rhistory
R_HELPER=/home/gabx/.config/r/helper
R_HISTSIZE=5000
............

Are the above variables correctly set ?

On a R session, Sys.getenv() returns correctly everything, except
R_LIBS_SITE which is empty. Why? Do I need to export it somewhere ?
R_LIBS        /developement/language/r/library:/usr/lib/R/library  Is
this the correct way for R to see R_LIBS? Then, when I upgrade
packages, do I need to upgrade separatly site library and user
library, or just one ligne upgardaing jusr R_LIBS?

Thank you for any advice on my current variable declaration setup.



[0]http://stat.ethz.ch/R-manual/R-devel/library/base/html/EnvVar.html
[1]http://stat.ethz.ch/R-manual/R-devel/library/base/html/Startup.html
-- 

google.com/+arnaudgabourygabx


From drjimlemon at gmail.com  Sat Oct 10 13:03:52 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 10 Oct 2015 22:03:52 +1100
Subject: [R] for loop not working
In-Reply-To: <1444403336163-4713392.post@n4.nabble.com>
References: <1444403336163-4713392.post@n4.nabble.com>
Message-ID: <CA+8X3fVVvb9EoLB4z77fCZkEz+o3U9A6b887dy8WT0Gu02Bogw@mail.gmail.com>

Hi mnw,
It looks to me as though you are testing the entire "holder" list each time
you go through the function. First, I'm not sure that a simple "==" is the
test you want. "movement" seems to be more than a single value and so you
might want to write a function that tests whether all of the components of
two "movement" objects are equal e.g.:

move_change<-function(currentx,previousx) {
 if(currentx$speed == previousx$speed) {
  if(currentx$heading == previousx$heading) return(0)
 }
 return(1)
}

Second, you probably don't want to test the entire list each time you loop
through the function. Just use:

 if(i > 1) changes<-move_change(movement,holder)
 holder<-movement

Jim


On Sat, Oct 10, 2015 at 2:08 AM, mnw <maw90 at aber.ac.uk> wrote:

> Hi. I have some code which loops through raw GPS data. This initial loop
> calculates distance, angle, speed etc between successive coordinates as
> well
> as type of movement e.g.left, right, forward. I want to construct a second
> loop that goes through the movements and records 'Changes' as either '0' or
> '1' depending on whether the movement changed or not. I have put the whole
> code in for reference but the additional loop begins at the object
> 'holder.'
> I want to store movements in holder and then loop through holder to
> determine 'changes.' At the moment it gives me 'Error in holder[[t - 1]] :
> attempt to select less than one element.' The moment i make holder [[t]] it
> works but just gives a list of '0's. I have tried many different things and
> just cannot get it to work, so any help would be very much appreciated.
> Again, sorry for the long post.
>
>
>
>
> lst <- list() # temporary list to store the results
> for (i in seq(1, nrow(R) - 1)){ # loop through each row of the 'R' matrix
>   lat1 <- deg2rad(R[i, 4])
>   long1 <- deg2rad(R[i, 5])
>   lat2 <- deg2rad(R[i + 1, 4])
>   long2 <- deg2rad(R[i + 1, 5])
>   gcd_vif <- gcd.vif(lat1, long1, lat2, long2)
>
>   # calc estimated speed by mean of speeds between two GPS records
>   estSpeed <- (R[i, 6] + R[i+1, 6])/2
>
>   # calculate acceleration (velocity)
>   accel <- (R[i+1, 6] - R[i, 6]) / GPSSample
>
>   # calculate absolute heading
>   heading <- absoluteHeading(lat1, long1, lat2, long2)
>
>   # calculate bearing relative to previous GPS record
>   relAngle <- 0
>   # if the number of GPS records is less than 3 then no change in track
>   if (i < 1) relAngle = heading
>   # otherwise consider the previous heading in order to calculate the new
> track
>   else if (i > 0) {
>     relAngle = (previousHeading - heading)
>
>   }
>
>
>   # determine whether movement is occurring and if so what type
>   # if there are insufficient history items then just record movement types
> discretely
>    if (i < historyLength) movement <- movementType(relAngle,
> angleThreshold)
>
>   else if (i > historyLength-1) {
>     # Array to store speeds
>     speedHistory <- array(historyLength)
>     n = historyLength-1
>     # get the speeds from the previous n (hisoryLength) "Movements"
>     for (j in seq(1, length(historyLength))){
>       speedHistory [n] = R[i-j, 6]
>       n-1
>       }
>
>       if (!bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
> "non-moving"
>       else if(bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
> movementType(relAngle, angleThreshold)
>
>
>   }
>
>
>   holder <- list(movement)
>   holder [[i]] <- (movement)
>
>
>   for (t in length(holder)){
>     if (holder[[t]] == holder[[t-1]])
>       changes <- 0
>     else changes <- 1
>
>   }
>
>
>
>   # update previous heading information
>   previousHeading = heading
>
>
>
>
>
>
>   # Store the input data and the results
>   lst[[i]] <- c(
>     latitude_position_1 = lat1,
>     longtude_position_1 = long1,
>     latitude_position_2 = lat2,
>     longtude_position_2 = long2,
>     Distance = gcd_vif,
>     Speed = estSpeed,
>     Acceleration = accel,
>     Absolute_Heading = heading,
>     Relative_Heading = relAngle,
>     Movement = movement,
>     Changes = changes
>
>   )
>
> }
> Results <- as.data.frame(do.call(rbind, lst)) # store the input data and
> the
> results in a data frame
> Results
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/for-loop-not-working-tp4713392.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat Oct 10 13:39:14 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 10 Oct 2015 13:39:14 +0200
Subject: [R] Construct a lower-triangular matrix
In-Reply-To: <093D92EB-BE22-49D2-A920-2B0EF202395B@xs4all.nl>
References: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>
	<4880E324-8914-461C-9093-3B06E9DF96E4@comcast.net>
	<093D92EB-BE22-49D2-A920-2B0EF202395B@xs4all.nl>
Message-ID: <CFB69BB9-9014-40DC-A164-E725225E3290@gmail.com>


> On 10 Oct 2015, at 10:49 , Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 10 Oct 2015, at 10:00, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> 
>> On Oct 9, 2015, at 10:57 PM, Steven Yen wrote:
>> 
>>> Dear
>>> How do you construct a lower triangular matrix from a vector.
>>> 
>>> I want to make vector
>>> 
>>> a <- 1:10
>>> 
>>> into a triangular matrix
>>> 
>>> 1 0 0  0
>>> 2 3 0  0
>>> 4 5 6  0
>>> 7 8 9 10
>>> 
>> 
>> I'm not sure this method with logical indexing will be the most elegant:
>> 
>> ?lower.tri
>> ?col
>> 
>>> b=matrix(0, sqrt(10)+1,sqrt(10)+1)
>> 
>>> b[lower.tri(b)| row(b)==col(b)] <- 1:10
>>> b
>>    [,1] [,2] [,3] [,4]
>> [1,]    1    0    0    0
>> [2,]    2    5    0    0
>> [3,]    3    6    8    0
>> [4,]    4    7    9   10
>> 
> 
> That doesn?t seem to be what the OP wanted.
> 
> This should do it.
> 
> a <- 1:10
> C <- matrix(0, sqrt(length(a))+1,sqrt(length(a))+1)
> i.upr <- which(upper.tri(C, diag = TRUE), arr.ind=TRUE)
> C[i.upr] <- a
> t(C)
> 
> resulting in
> 
>     [,1] [,2] [,3] [,4]
> [1,]    1    0    0    0
> [2,]    2    3    0    0
> [3,]    4    5    6    0
> [4,]    7    8    9   10
> 
> I found this here: http://stackoverflow.com/questions/24472060/indexing-upper-or-lower-triangle-in-matrix-with-diagonal

It's crossing the creek a couple of times too many, though. This'll do:

> M <- matrix(0,4,4)
> M[upper.tri(M,TRUE)] <- 1:10 
> t(M)
     [,1] [,2] [,3] [,4]
[1,]    1    0    0    0
[2,]    2    3    0    0
[3,]    4    5    6    0
[4,]    7    8    9   10

I'm also not buying the sqrt(length(a))+1 bit --- floor(2*length(a)) is more like it.

(The generic answer is "with some care". In particular, avoid being trapped by column-major storage layout and by in/excluding the diagonal.)

-pd

> 
> Berend
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Sat Oct 10 13:40:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 10 Oct 2015 07:40:07 -0400
Subject: [R] Problem with binomial gam{mgcv}
In-Reply-To: <CAMsrtkjc48tz4bcQ3e7tpKufWp1Kc4Gq9tY+-9GpU2LRC5AWRQ@mail.gmail.com>
References: <CAMsrtkjc48tz4bcQ3e7tpKufWp1Kc4Gq9tY+-9GpU2LRC5AWRQ@mail.gmail.com>
Message-ID: <5618F917.3080104@gmail.com>

On 09/10/2015 8:00 PM, Erin Conlisk wrote:
> Hello,
> 
> I am having trouble testing for the significance using a binomial model in
> gam{mgcv}.  Have I stumbled on a bug?  I doubt I would be so lucky, so
> could someone tell me what I am doing wrong?
> 
> Please see the following code:
> ________________________________
> 
> # PROBLEM USING cbind
> 
> x1 <- runif(500, 0, 100)  # Create 500 random variables to use as my
> explanatory variable
> 
> y1 <- floor(runif(500, 0, 100)) # Create 500 random counts to serve as
> binomial "successes"
> 
> y2 <- 100-y1 # Create 500 binomial "failures", assuming a total of 100
> trials and the successes recorded in y1
> 
> Model <- gam(cbind(y1, y2) ? 1 + s(x1), family=binomial)
> summary(Model)
> ________________________________
> 
> The result is that my random variable, x1, is highly significant.  This
> can't be right...

The problem is that statistical significance of a test doesn't mean that
the alternative you have in mind is right, it just means that the null
is wrong (or you were unlucky, but let's ignore that).

The null hypothesis here is that all of the y1 values are independent
binomial values with a common n=100 and common unspecifed probability of
success.

Since in fact y1 comes from a discrete uniform distribution, that's
false, and the p-value is not anywhere near being a random Unif(0,1) value.

If you wanted the null hypothesis to be true, you'd need to choose a
success probability p somehow, then set y1 <- rbinom(500, size=100, prob
= p).  The random uniform has a far larger variance, and that leads to a
larger deviance in gam, hence significance.

Duncan Murdoch

> 
> So what happens when I change the observations from a "batch" of 100 trials
> to individual successes and failures?
> ________________________________
> 
> # NOW MAKE ALL THESE DATA 0 and 1
> 
> r01<-rep(0,500)
> data01<-cbind(x1, y1, y2, r01)
> rownames(data01)<-seq(1,500, 1)
> colnames(data01)<-c('x1', 'y1', 'y2', 'r01')
> data01<-data.frame(data01)
> 
> expanded0 <- data01[rep(row.names(data01), data01$y1), 1:4]  # Creates a
> replicate of the      #  explanatory variables for each individual "success"
> 
> r01<-rep(1,500)
> data01<-cbind(x1, y1, y2, r01)
> rownames(data01)<-seq(1,500, 1)
> colnames(data01)<-c('x1', 'y1', 'y2', 'r01')
> data01<-data.frame(data01)
> 
> expanded1 <- data01[rep(row.names(data01), data01$y2), 1:4]  # Creates a
> replicate of the      #  explanatory variables for each individual "failure"
> 
> data01<-rbind(expanded0,expanded1)
> 
> Model2 <- gam(r01 ? 1 + s(x1), family=binomial)
> summary(Model2)
> ___________________________________
> 
> The result is what I expect.  Now my random variable, x1, is NOT
> significant.
> 
> What is going on here?
> 
> I should say that I didn't just make this up.  My question arose playing
> with my real data, where I was getting high significance, but a terrible
> proportion of deviance explained.
> 
> My apologies if this is explained elsewhere, but I have spent hours
> searching for an answer online.
> 
> Thank you kindly,
> Erin Conlisk
>


From pdalgd at gmail.com  Sat Oct 10 13:48:58 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 10 Oct 2015 13:48:58 +0200
Subject: [R] Why can I reset directory in using setwd on desktop but not
	on laptop
In-Reply-To: <819300068.371295.1444422821664.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
References: <302515137.459871.1444405419311.JavaMail.open-xchange@oxbe11.tb.ukmail.iss.as9143.net>
	<CAM_vju=fXm+LY2p_1yJd-mjtAm+KAOz5kgX-UytrAPF0+XrA0w@mail.gmail.com>
	<1720394784.361635.1444406304873.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
	<8871DA6E-D127-4567-9329-5E6A0443BAAF@gmail.com>
	<819300068.371295.1444422821664.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
Message-ID: <3325DC78-46A4-43F3-A28B-7219794009E0@gmail.com>

The most likely cause is that permissions and/or ownership of the directory or one of its parents is different between the two machines. It is also thinkable that the ownership of the R process is the problem (in which case it might be an RStudio issue after all).

You likely need a better PC expert than me...

-pd

> On 09 Oct 2015, at 22:33 , WRAY NICHOLAS <nicholas.wray at ntlworld.com> wrote:
> 
> Thanks for your questions Peter
> 
> Both machines are PCs
> 
> In the R routine on my desktop I am changing the place where I store the various csv  files by commands like 
> 
> setwd("C:/Users/Nick/Documents/08915Trent/Outmatstore") where I'm storing particulur matrices (outmats) as csv files.  If I then say
> 
> setwd("C:/Users/Nick/Documents/08915Trent/Resmatstore") to store another kind of matrix (resmats) as csv files elsewhere, the desktop is quite happy with this and lets me change and read.csv and write.csv without problems
> 
> But, having created on my laptop exactly the same path ie C:/Users/Nick/Documents/08915Trent/Outmatstore or Resmatstore etc (that is, I have exactly the same folders nested in the same way on both machines), if I try to change horses in midstream, so to speak, I get an error message 
> 
> Error in setwd("C:/Users/Nick/08915Trent/Resmatstore") : 
>   cannot change working directory
> 
> Not only this, but the laptop will not let me write to any path except one involving C:/Users/Nick etc that is if I try to write to any folder not part of the main administrator's path then it won't let me
> 
> If I do getwd() on either machine before or after the attempt (unsuccessful on laptop) tochange directory I get whichever is the current directory, ie the new one on the desktop and the old one on the laptop... 
> 
> ?
> 
> Thanks, Nick
> 
>> On 09 October 2015 at 20:29 peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> 
>> 
>> > On 09 Oct 2015, at 17:58 , WRAY NICHOLAS <nicholas.wray at ntlworld.com> wrote:
>> > 
>> > Thanks Sarah I didn't realise that there was a distinction between between
>> > asking about R per se and asking about r-studio... I shall try specifying the
>> > path and see whether that helps Thanks, Nick
>> 
>> The key part of the story is not necessarily Rstudio specific, though:
>> 
>> You said that your laptop "won't allow me to reset the directory by a setwd command".
>> 
>> Now what makes you think that? I can imagine a number of misinterpretations that might lead you there without it actually being true. So:
>> 
>> - Is there an error message? 
>> - What exactly did you type in?
>> - Does the directory actually exist on both machines?
>> - Are we talking about machines with the same architecure? (e.g., is one a PC and the other one a Mac?)
>> - If you do a getwd() before and after the setwd(), what happens?
>> 
>> -pd
>> 
>> > 
>> >> 
>> >> On 09 October 2015 at 16:51 Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> >> 
>> >> 
>> >> Sounds like an RStudio question to me. Someone might be able to help,
>> >> but this mailing list is for R.
>> >> 
>> >> You should also provide sessionInfo() output when asking potentially
>> >> OS-related questions.
>> >> 
>> >> You can always specify path as part of the write.csv() or other output
>> >> command; you don't need to change the working directory necessarily.
>> >> 
>> >> Sarah
>> >> 
>> >> On Fri, Oct 9, 2015 at 11:43 AM, WRAY NICHOLAS
>> >> <nicholas.wray at ntlworld.com> wrote:
>> >>> Hi I am running the same r routine on both my desktop and my laptop, and
>> >>> writing results in the form of csv files into storage folders in the
>> >>> respective
>> >>> users/documents files of both machines My desktop machine allows me to
>> >>> reset
>> >>> the directory in the course of the r programme so that I can write the
>> >>> files
>> >>> into different folders which makes it easier to keep track of what's
>> >>> what,
>> >>> whereas my laptop won't allow me to reset the directory by a setwd
>> >>> command, and
>> >>> I have to set the directory manually using the r studio tabs, so
>> >>> basically on
>> >>> the laptop every results file is going into the same folder, which is
>> >>> not
>> >>> unworkable but not as easy to use later
>> >>> 
>> >>> As far as I know I have the same r studio on both machines. Does anyone
>> >>> out
>> >>> there know a) why I can't use a setwd command on the laptop, and b)is
>> >>> there
>> >>> anything I can do to put this right?
>> >>> 
>> >>> Thanks beforehand, as it were
>> >>> 
>> >>> Nick Wray
>> >> 
>> > [[alternative HTML version deleted]]
>> > 
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> >
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bhh at xs4all.nl  Sat Oct 10 14:48:29 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 10 Oct 2015 14:48:29 +0200
Subject: [R] Construct a lower-triangular matrix
In-Reply-To: <CFB69BB9-9014-40DC-A164-E725225E3290@gmail.com>
References: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>
	<4880E324-8914-461C-9093-3B06E9DF96E4@comcast.net>
	<093D92EB-BE22-49D2-A920-2B0EF202395B@xs4all.nl>
	<CFB69BB9-9014-40DC-A164-E725225E3290@gmail.com>
Message-ID: <DEE364A3-DB1A-4E24-836B-40DB6DF027F2@xs4all.nl>


> On 10 Oct 2015, at 13:39, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On 10 Oct 2015, at 10:49 , Berend Hasselman <bhh at xs4all.nl> wrote:
>> 
>>> 
>>> On 10 Oct 2015, at 10:00, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> 
>>> On Oct 9, 2015, at 10:57 PM, Steven Yen wrote:
>>> 
>>>> Dear
>>>> How do you construct a lower triangular matrix from a vector.
>>>> 
>>>> I want to make vector
>>>> 
>>>> a <- 1:10
>>>> 
>>>> into a triangular matrix
>>>> 
>>>> 1 0 0  0
>>>> 2 3 0  0
>>>> 4 5 6  0
>>>> 7 8 9 10
>>>> 
>>> 
>>> I'm not sure this method with logical indexing will be the most elegant:
>>> 
>>> ?lower.tri
>>> ?col
>>> 
>>>> b=matrix(0, sqrt(10)+1,sqrt(10)+1)
>>> 
>>>> b[lower.tri(b)| row(b)==col(b)] <- 1:10
>>>> b
>>>   [,1] [,2] [,3] [,4]
>>> [1,]    1    0    0    0
>>> [2,]    2    5    0    0
>>> [3,]    3    6    8    0
>>> [4,]    4    7    9   10
>>> 
>> 
>> That doesn?t seem to be what the OP wanted.
>> 
>> This should do it.
>> 
>> a <- 1:10
>> C <- matrix(0, sqrt(length(a))+1,sqrt(length(a))+1)
>> i.upr <- which(upper.tri(C, diag = TRUE), arr.ind=TRUE)
>> C[i.upr] <- a
>> t(C)
>> 
>> resulting in
>> 
>>    [,1] [,2] [,3] [,4]
>> [1,]    1    0    0    0
>> [2,]    2    3    0    0
>> [3,]    4    5    6    0
>> [4,]    7    8    9   10
>> 
>> I found this here: http://stackoverflow.com/questions/24472060/indexing-upper-or-lower-triangle-in-matrix-with-diagonal
> 
> It's crossing the creek a couple of times too many, though. This'll do:
> 
>> M <- matrix(0,4,4)
>> M[upper.tri(M,TRUE)] <- 1:10 
>> t(M)
>     [,1] [,2] [,3] [,4]
> [1,]    1    0    0    0
> [2,]    2    3    0    0
> [3,]    4    5    6    0
> [4,]    7    8    9   10
> 
> I'm also not buying the sqrt(length(a))+1 bit --- floor(2*length(a)) is more like it.
> 

Shouldn?t that be

m <- sqrt(floor(2*length(a)))
M <- matrix(0,m,m)

for the general case?

Berend


From pdalgd at gmail.com  Sat Oct 10 15:21:20 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 10 Oct 2015 15:21:20 +0200
Subject: [R] Construct a lower-triangular matrix
In-Reply-To: <DEE364A3-DB1A-4E24-836B-40DB6DF027F2@xs4all.nl>
References: <CAKTtY6TL-58O4e479WoDhVCu2+EbyTh12D6Kkho9L1z_jrTGTw@mail.gmail.com>
	<4880E324-8914-461C-9093-3B06E9DF96E4@comcast.net>
	<093D92EB-BE22-49D2-A920-2B0EF202395B@xs4all.nl>
	<CFB69BB9-9014-40DC-A164-E725225E3290@gmail.com>
	<DEE364A3-DB1A-4E24-836B-40DB6DF027F2@xs4all.nl>
Message-ID: <8EBED4BF-2619-4625-BF70-4098222F0041@gmail.com>


>> 
>> I'm also not buying the sqrt(length(a))+1 bit --- floor(2*length(a)) is more like it.
>> 
> 
> Shouldn?t that be
> 
> m <- sqrt(floor(2*length(a)))
> M <- matrix(0,m,m)
> 
> for the general case?
> 
> Berend
> 

Closer, but I actually meant:

floor(sqrt(2*length(a)))

if k is m*(m+1)/2, 2*k will be between m^2 and (m+1)^2, so sqrt(2*k) will be between m and m+1. QED.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From schwidom at gmx.net  Sat Oct 10 16:08:39 2015
From: schwidom at gmx.net (Frank Schwidom)
Date: Sat, 10 Oct 2015 16:08:39 +0200
Subject: [R] R lappy, sapply or mapply question
In-Reply-To: <1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>
References: <7539129727B06D42A9F1A56D2C597F851139BF13@FHSDB2D11-2.csu.mcmaster.ca>
	<1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20151010140839.GA9967@debian64>

On 2015-10-09 20:15:16, liqunhan--- via R-help wrote:

> for (k in 1 : 50000) {
> ? xlist <- list(x5 = dailyrecord$a[k], x6 = dailyrecord$e[k], x7 = dailyrecord$f[k])
> ? result_forloop[k] <- fun3(list1, list2, xlist)
> }

result_forloop <- lapply( 1 : 50000, function( k) {

 tmpRow <- dailyrecord[ k, ]

 xlist <- with( df, list( x5= a, x6= e, x7= f))

 fun3(list1, list2, xlist)

})


From schwidom at gmx.net  Sat Oct 10 16:10:40 2015
From: schwidom at gmx.net (Frank Schwidom)
Date: Sat, 10 Oct 2015 16:10:40 +0200
Subject: [R] R lappy, sapply or mapply question
In-Reply-To: <20151010140839.GA9967@debian64>
References: <7539129727B06D42A9F1A56D2C597F851139BF13@FHSDB2D11-2.csu.mcmaster.ca>
	<1097033103.1520308.1444421716159.JavaMail.yahoo@mail.yahoo.com>
	<20151010140839.GA9967@debian64>
Message-ID: <20151010141040.GB9967@debian64>


correction:

On 2015-10-10 16:08:39, Frank Schwidom wrote:
> On 2015-10-09 20:15:16, liqunhan--- via R-help wrote:
> 
> > for (k in 1 : 50000) {
> > ? xlist <- list(x5 = dailyrecord$a[k], x6 = dailyrecord$e[k], x7 = dailyrecord$f[k])
> > ? result_forloop[k] <- fun3(list1, list2, xlist)
> > }
> 
> result_forloop <- lapply( 1 : 50000, function( k) {
> 
>  tmpRow <- dailyrecord[ k, ]
> 
>  xlist <- with( tmpRow, list( x5= a, x6= e, x7= f))
> 
>  fun3(list1, list2, xlist)
> 
> })
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From caciquesamurai at gmail.com  Sat Oct 10 17:38:00 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Sat, 10 Oct 2015 12:38:00 -0300
Subject: [R] Data-frame selection
Message-ID: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>

Hello R-Helpers!

I have a data-frame as below (dput in the end of mail) and need to
select just the first sequence of occurrence of each "Group" in each
"ID".

For example, for ID "1" I have two sequential occurrences of T2 and
two sequential occurrences of T3:

> test [test$ID == 1, ]
   ID Group  Var
3   1    T2 2.94
4   1    T2 3.23
5   1    T2 1.40
6   1    T2 1.62
7   1    T2 2.43
8   1    T2 2.53
9   1    T2 2.25
10  1    T3 1.66
11  1    T3 2.86
12  1    T3 0.53
13  1    T3 1.66
14  1    T3 3.24
15  1    T3 1.34
16  1    T2 1.86
17  1    T2 3.03
18  1    T3 3.63
19  1    T3 2.78
20  1    T3 1.49

As output, I need just the first group of T2 and T3 for this ID, like:

 ID Group  Var
3   1    T2 2.94
4   1    T2 3.23
5   1    T2 1.40
6   1    T2 1.62
7   1    T2 2.43
8   1    T2 2.53
9   1    T2 2.25
10  1    T3 1.66
11  1    T3 2.86
12  1    T3 0.53
13  1    T3 1.66
14  1    T3 3.24
15  1    T3 1.34

For others ID I have just one occurrence or sequence of occurrence of
each Group.

I tried to use a labeling variable, but cannot figure out do this
without many many loops..

Thanks in advanced,

Raoni

 dput (teste)
structure(list(ID = structure(c(3L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2",
"3", "4"), class = "factor"), Group = structure(c(1L, 2L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L,
2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L,
2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), .Label = c("T2",
"T3"), class = "factor"), Var = c(0.32, 1.59, 2.94, 3.23, 1.4,
1.62, 2.43, 2.53, 2.25, 1.66, 2.86, 0.53, 1.66, 3.24, 1.34, 1.86,
3.03, 3.63, 2.78, 1.49, 2, 2.39, 1.65, 2.05, 2.75, 2.23, 1.39,
2.66, 1.05, 2.52, 2.49, 2.97, 0.43, 1.36, 0.79, 1.71, 1.95, 2.73,
2.73, 2.39, 2.17, 2.34, 2.42, 1.75, 0.66, 1.64, 0.24, 2.11, 2.11,
1.18)), .Names = c("ID", "Group", "Var"), row.names = c(NA, 50L
), class = "data.frame")


From jdnewmil at dcn.davis.CA.us  Sat Oct 10 18:13:12 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 10 Oct 2015 09:13:12 -0700
Subject: [R] Data-frame selection
In-Reply-To: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
Message-ID: <6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>

?aggregate

in base R. Make a short function that returns the first element of a vector and give that to aggregate.

Or...

library(dplyr)
( test %>% group_by( ID, Group ) %>% summarise( Var=first( Var ) ) %>% as.data.frame )
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 10, 2015 8:38:00 AM PDT, Cacique Samurai <caciquesamurai at gmail.com> wrote:
>Hello R-Helpers!
>
>I have a data-frame as below (dput in the end of mail) and need to
>select just the first sequence of occurrence of each "Group" in each
>"ID".
>
>For example, for ID "1" I have two sequential occurrences of T2 and
>two sequential occurrences of T3:
>
>> test [test$ID == 1, ]
>   ID Group  Var
>3   1    T2 2.94
>4   1    T2 3.23
>5   1    T2 1.40
>6   1    T2 1.62
>7   1    T2 2.43
>8   1    T2 2.53
>9   1    T2 2.25
>10  1    T3 1.66
>11  1    T3 2.86
>12  1    T3 0.53
>13  1    T3 1.66
>14  1    T3 3.24
>15  1    T3 1.34
>16  1    T2 1.86
>17  1    T2 3.03
>18  1    T3 3.63
>19  1    T3 2.78
>20  1    T3 1.49
>
>As output, I need just the first group of T2 and T3 for this ID, like:
>
> ID Group  Var
>3   1    T2 2.94
>4   1    T2 3.23
>5   1    T2 1.40
>6   1    T2 1.62
>7   1    T2 2.43
>8   1    T2 2.53
>9   1    T2 2.25
>10  1    T3 1.66
>11  1    T3 2.86
>12  1    T3 0.53
>13  1    T3 1.66
>14  1    T3 3.24
>15  1    T3 1.34
>
>For others ID I have just one occurrence or sequence of occurrence of
>each Group.
>
>I tried to use a labeling variable, but cannot figure out do this
>without many many loops..
>
>Thanks in advanced,
>
>Raoni
>
> dput (teste)
>structure(list(ID = structure(c(3L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2",
>"3", "4"), class = "factor"), Group = structure(c(1L, 2L, 1L,
>1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L,
>2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L,
>2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), .Label =
>c("T2",
>"T3"), class = "factor"), Var = c(0.32, 1.59, 2.94, 3.23, 1.4,
>1.62, 2.43, 2.53, 2.25, 1.66, 2.86, 0.53, 1.66, 3.24, 1.34, 1.86,
>3.03, 3.63, 2.78, 1.49, 2, 2.39, 1.65, 2.05, 2.75, 2.23, 1.39,
>2.66, 1.05, 2.52, 2.49, 2.97, 0.43, 1.36, 0.79, 1.71, 1.95, 2.73,
>2.73, 2.39, 2.17, 2.34, 2.42, 1.75, 0.66, 1.64, 0.24, 2.11, 2.11,
>1.18)), .Names = c("ID", "Group", "Var"), row.names = c(NA, 50L
>), class = "data.frame")
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From oma.gonzales at gmail.com  Sat Oct 10 18:55:52 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sat, 10 Oct 2015 11:55:52 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
Message-ID: <CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>

Thank you very much to both of you. This information is very enlightening
to me.

Cheers.


2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:

> David answered most of this. Just a two short notes inline.
>
>
>
>
> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com> wrote:
>
> > David, Boris, so thankfull for your help. Both approaches are very good.
> I got this solve with David's help.
> >
> > I find very insteresting Bori's for loop. And I need a little help
> understanding the regex part on it.
> >
> > - The strsplit function: strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")
> >
> > I understand for this: split every row by a sequence of any number or
> letter or "-" that appears at leat once (+ operator).
> >
> > 1.- What does mena the "^" symbol? If you remove it, just appeare blanks.
> > 2.- Why is there the necessity of "+" after the closing "]"?
> >
> > 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
> >      Identifies also the IDs where "-" is present. Here the regex does
> not have the "-" included.
>
> Yes. I am not matching the entire token here. Note there is no "+": The
> two character-class expressions match exactly one uppercase character
> adjacent to exactly one number. If this is found in a token, grep returns
> TRUE. It doesn't matter what else the token contains - the first regex
> already took care of removing everything that's not needed. The vector of
> FALSEs and a single TRUE that grep() returns goes inside the square
> brackets, and selects the token from v.
>
>
>
> > Also, I notice that David used the "-" at the begining of the matching:
> [-A-Z0-9], without the "^" (stars with) at the beginning.
>
> This can be very confusing about regular expressions: the same character
> can mean different things depending on where it is found. Between two
> characters in a character class expresssion, the hyphen means "range".
> Elsewhere it is a literal hyphen. David put his at the beginning, I had it
> at the end (in the first regex). Another tricky character is "?" which can
> mean 0,1 matches, or turn "greedy" matching off...
>
> Online regex testers are invaluable to develop a regex - one I frequently
> use is regexpal.com
>
> Cheers,
> B.
>
>
> >
> > I would appreciate a response from you, gentlemen.
> >
> > Thanks again.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
> >
> > > I think you are going into the wrong direction here and this is a
> classical example of what we mean by "technical debt" of code. Rather than
> tell to your regular expression what you are looking for, you are handling
> special cases with redundant code. This is ugly, brittle and impossible to
> maintain.
> > >
> > > Respect to you that you have recognized this.
> > >
> > >
> > > The solution is rather simple:
> > >
> > > A) Isolate tokens. Your IDs contain only a limited set of characters.
> Split your strings along the characters that are not found in IDs to
> isolate candidate tokens, place them into a vector.
> > >
> > > B) Evaluate your tokens: as far as I can see IDs all contain letters
> AND numbers. This is a unique characteristic. Thus it is sufficient to grep
> for a letter/number pair in a token to identify it as an ID.
> > >
> > > Should you ever find a need to accommodate differently formed IDs,
> there are only two, well defined places with clearly delegated roles where
> changes might be needed.
> > >
> > > Here is the code:
> > >
> > > for (i in 1:nrow(ripley.tv)) {
> > >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) #
> isolate tokens
> > >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and
> store
> > > }
> >
> > That logic actually simplifies the regex strategy as well:
> >
> >  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T)
> >
> >
> > Almost succeeds, with a few all-character words, but if you require one
> number in the middle you get full results:
> >
> >  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T)
> >
> >  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N"
> >  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"
> > [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"
> > [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"
> > [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"
> > [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"
> > [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"
> > [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
> > [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
> > [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
> > [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"
> > [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"
> > [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"
> > [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C"
> "XBR-75X945C"
> > [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
> > [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
> > [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"
> > [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"
>  "XBR-79X905B"
> > [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"
>  "TC-42AS650L"
> > [96] "LC70LE660"   "LE58D3140"
> >
> > >
> > >
> > >
> > > Cheers,
> > > Boris
> > >
> > >
> > >
> > > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com> wrote:
> > >
> > >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
> > >>> NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> > >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> > >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> > >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> > >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
> "SAMSUNG",
> > >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> > >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> > >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> > >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> > >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> > >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\"
> 3D
> > >>>>> 48J6400",
> > >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> > >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> > >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED
> FHD
> > >>> 55\" -
> > >>>>> LE55B8000",
> > >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" -
> NEGRO",
> > >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> > >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48''
> 48JU6500",
> > >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55''
> 3D
> > >>>>> 55JS9000",
> > >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55''
> 55JU6700",
> > >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA
> HD
> > >>> 65''
> > >>>>> 3D 65JS9000",
> > >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65''
> 65JU7500",
> > >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> > >>> 40LF6350",
> > >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> > >>>>> 42LF6450",
> > >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\"
> FULL HD
> > >>>>> 3D",
> > >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> > >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA
> HD
> > >>> 4K",
> > >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D
> SMART
> > >>> TV
> > >>>>> 55UF7700",
> > >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\"
> ULTRA HD
> > >>> 4K
> > >>>>> 3D",
> > >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD
> 4K
> > >>> SMART
> > >>>>> TC-50CX640W",
> > >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD
> 4K
> > >>> CINEMA
> > >>>>> SMART UG8700",
> > >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\"
> FULL HD
> > >>> 3D",
> > >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> > >>> KDL-40R354B",
> > >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> > >>> 50J5500",
> > >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> > >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> > >>> 40J6400",
> > >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> > >>> KDL-40R555C
> > >>>>> - NEGRO",
> > >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" -
> NEGRO",
> > >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" -
> BLANCO",
> > >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> > >>>>> KDL-65W855C",
> > >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> > >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> > >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> > >>>>> LE32W454F",
> > >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART
> 3D
> > >>>>> KDL-55W805C",
> > >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> > >>>>> XBR-55X855C",
> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
> > >>> ULTRA HD
> > >>>>> 4K 3D XBR-75X945C",
> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED
> 60''
> > >>>>> ULTRA HD 4K LC60UE30U",
> > >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80''
> ULTRA HD
> > >>> 4K
> > >>>>> LC80UE30U",
> > >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
> > >>> ULTRA HD
> > >>>>> 4K 3D",
> > >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\"
> ULTRA
> > >>> HD
> > >>>>> 4K 3D",
> > >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> > >>> 32J4300",
> > >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
> > >>> 55\"
> > >>>>> ULTRA HD 4K 3D",
> > >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\"
> FULL
> > >>> HD
> > >>>>> 3D",
> > >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED
> FULL HD
> > >>> 50''
> > >>>>> TC-50AS600L",
> > >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K
> LC70SQ17U
> > >>> 70''",
> > >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
> TC-40A400L",
> > >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> > >>> 55HU8700",
> > >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
> TC-42AS650L",
> > >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> > >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> > >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> > >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> > >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> > >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> > >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> > >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> > >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> > >>> c(2799L,
> > >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> > >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> > >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> > >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> > >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> > >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> > >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> > >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> > >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> > >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> > >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> > >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> > >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> > >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> > >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> > >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> > >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> > >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> > >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> > >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> > >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> > >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> > >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> > >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> > >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> > >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> > >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> > >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> > >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> > >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> > >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> > >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> > >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> > >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> > >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> > >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> > >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> > >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "S/.500 -
> > >>>>> S/.1500",
> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", ">
> S/.4,500",
> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> > >>> S/.1500",
> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 -
> S/.4500",
> > >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 -
> S/.4500",
> > >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> > >>> S/.1500",
> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> > >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", ">
> S/.4,500",
> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", ">
> S/.4,500",
> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", ">
> S/.4,500",
> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> > >>> c("id",
> > >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> > >>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> > >>> row.names
> > >>>>> = c(NA,
> > >>>>> -97L))
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Oct 10 19:50:20 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 10 Oct 2015 10:50:20 -0700
Subject: [R] Error with Segmented package
In-Reply-To: <CAEDDhTDHp6j0HvRM62xHeXU5CJ0xRg_xGi2eRjW56CQa+qjB4A@mail.gmail.com>
References: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>
	<7F3DAEAD-077F-44EE-99D7-E9B8D1AE99A7@comcast.net>
	<CAEDDhTCx8y_0QKZ5bi7dLo0N48YrTdk_mQU3j+gXBOvG5q=s_Q@mail.gmail.com>
	<E236D07A-A9F8-439B-AB5C-202653B8F8A6@comcast.net>
	<CAEDDhTDHp6j0HvRM62xHeXU5CJ0xRg_xGi2eRjW56CQa+qjB4A@mail.gmail.com>
Message-ID: <358AE4FE-3706-4B45-892F-E2468C4B8131@comcast.net>


On Oct 10, 2015, at 6:58 AM, andrew haywood wrote:

> Thanks Dave, 
> 
> when I run traceback() the following output
> 
> Error in if (psi == Inf) psi <- median(XREGseg) : 
>   missing value where TRUE/FALSE needed
> > traceback()
> 2: segmented.lm(lm(y ~ x, data = data), seg.Z = ~x, psi = NA, control = seg.control(K = 1))
> 1: segmented(lm(y ~ x, data = data), seg.Z = ~x, psi = NA, control = seg.control(K = 1))
> 
> 
> I am unsure how to interpret this. 
> 
> In addition when I run the command 
> 
> options(error="browser")

Sorry. Should have been:

options(error = recover) 

See ?recover and ?browser

-- 
David.

> 
> 
> I get the following error
> 
> Error in options(error = "browser") : invalid value for 'error'
> 
> 
> 
> Any help would be greatly appreciated. 
> 
> Kind regards
> Andrew
> 
> On Thu, Oct 8, 2015 at 10:33 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On Oct 7, 2015, at 6:10 PM, andrew haywood wrote:
> 
> > Thanks David,
> >
> > I apologies for not posting the versions.
> >
> > I am running
> >
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=English_United Kingdom.1252
> > [2] LC_CTYPE=English_United Kingdom.1252
> > [3] LC_MONETARY=English_United Kingdom.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United Kingdom.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] segmented_0.5-1.2
> >
> > And I still get the error. What is the best way to debug the error?
> 
> The first thing I do is run traceback() immediately after the error. If that fails to illuminate the problem, my next step is falling back to:
> 
> options(error="browser")
> # which should allow you to examine the system-state at the time of the error.
> 
> And at that point I start considering sending an email to the maintainer with my reproducible example, especially so since it fails with a more recent version. It may be that the maintainer has the same OS as you have.
> 
> --
> David.
> >
> > Kind regards teht
> > Andrew
> >
> >
> > On Thu, Oct 8, 2015 at 7:11 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > On Oct 7, 2015, at 6:50 AM, andrew haywood wrote:
> >
> > > Dear List,
> > >
> > > I am trying to run a simple pieewise regression using the segmented package.
> > >
> > > When running the following code
> > >
> > > library(segmented)
> > > data = data.frame(x=c(50,60,70,80,90,100,110) , y=
> > > c(703.786,705.857,708.153,711.056,709.257, 707.4, 705.6))
> > >
> > > model.lm = segmented(lm(y~x,data = data),seg.Z = ~x, psi = NA, control =
> > > seg.control(K=1))
> > >
> > > I get the following error.
> > >
> > > Error in if (psi == Inf) psi <- median(XREGseg) :
> > >  missing value where TRUE/FALSE needed
> >
> > I don't get any error, despite being a bit behind the times. You need to specify the versions (OS, R, segmented) and prepare for some debugging efforts. Easiest way to do this is with the output of sessionInfo().
> >
> > R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
> > Copyright (C) 2015 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin10.8.0 (64-bit)
> >
> > I also have an embarrassing number of packages loaded.
> >
> > other attached packages:
> >  [1] segmented_0.5-1.1   boot_1.3-17         sqldf_0.4-10
> >
> > (remaining 48 are omitted)
> >
> >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Sat Oct 10 20:00:57 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 10 Oct 2015 18:00:57 +0000
Subject: [R] for loop not working
In-Reply-To: <CA+8X3fVVvb9EoLB4z77fCZkEz+o3U9A6b887dy8WT0Gu02Bogw@mail.gmail.com>
References: <1444403336163-4713392.post@n4.nabble.com>
	<CA+8X3fVVvb9EoLB4z77fCZkEz+o3U9A6b887dy8WT0Gu02Bogw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CE17A@mb02.ads.tamu.edu>

In addition to Jim's comments you would benefit by learning more about how R works. You are using loops for operations that could easily be vectorized. It is not clear where your functions are coming from (eg. deg2rad and gcd.vif) but package geosphere will get your distances and bearings directly without looping. 

> install.packages("geosphere")
> library(geosphere)
> Cities <- c("New York", "Miami", "Los Angeles", "Seattle", "Chicago")
> Lat <- c(40.7127, 25.7753, 34.05, 47.6097, 41.8369)
> Long <- c(-74.0059, -80.2089, -118.250, -122.3331, -87.6847)
> Places <- data.frame(Cities, Lat, Long)
> Places
       Cities     Lat      Long
1    New York 40.7127  -74.0059
2       Miami 25.7753  -80.2089
3 Los Angeles 34.0500 -118.2500
4     Seattle 47.6097 -122.3331
5     Chicago 41.8369  -87.6847
> n <- nrow(Places)
> distVincentyEllipsoid(Places[1:(n-1), 3:2], Places[2:n, 3:2])
[1] 1753420 3763369 1544119 2794013
> bearing(Places[1:(n-1), 3:2], Places[2:n, 3:2])
[1] -158.98140  -66.71221  -11.57217   90.36231


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jim Lemon
Sent: Saturday, October 10, 2015 6:04 AM
To: mnw <maw90 at aber.ac.uk>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] for loop not working

Hi mnw,
It looks to me as though you are testing the entire "holder" list each time
you go through the function. First, I'm not sure that a simple "==" is the
test you want. "movement" seems to be more than a single value and so you
might want to write a function that tests whether all of the components of
two "movement" objects are equal e.g.:

move_change<-function(currentx,previousx) {
 if(currentx$speed == previousx$speed) {
  if(currentx$heading == previousx$heading) return(0)
 }
 return(1)
}

Second, you probably don't want to test the entire list each time you loop
through the function. Just use:

 if(i > 1) changes<-move_change(movement,holder)
 holder<-movement

Jim


On Sat, Oct 10, 2015 at 2:08 AM, mnw <maw90 at aber.ac.uk> wrote:

> Hi. I have some code which loops through raw GPS data. This initial loop
> calculates distance, angle, speed etc between successive coordinates as
> well
> as type of movement e.g.left, right, forward. I want to construct a second
> loop that goes through the movements and records 'Changes' as either '0' or
> '1' depending on whether the movement changed or not. I have put the whole
> code in for reference but the additional loop begins at the object
> 'holder.'
> I want to store movements in holder and then loop through holder to
> determine 'changes.' At the moment it gives me 'Error in holder[[t - 1]] :
> attempt to select less than one element.' The moment i make holder [[t]] it
> works but just gives a list of '0's. I have tried many different things and
> just cannot get it to work, so any help would be very much appreciated.
> Again, sorry for the long post.
>
>
>
>
> lst <- list() # temporary list to store the results
> for (i in seq(1, nrow(R) - 1)){ # loop through each row of the 'R' matrix
>   lat1 <- deg2rad(R[i, 4])
>   long1 <- deg2rad(R[i, 5])
>   lat2 <- deg2rad(R[i + 1, 4])
>   long2 <- deg2rad(R[i + 1, 5])
>   gcd_vif <- gcd.vif(lat1, long1, lat2, long2)
>
>   # calc estimated speed by mean of speeds between two GPS records
>   estSpeed <- (R[i, 6] + R[i+1, 6])/2
>
>   # calculate acceleration (velocity)
>   accel <- (R[i+1, 6] - R[i, 6]) / GPSSample
>
>   # calculate absolute heading
>   heading <- absoluteHeading(lat1, long1, lat2, long2)
>
>   # calculate bearing relative to previous GPS record
>   relAngle <- 0
>   # if the number of GPS records is less than 3 then no change in track
>   if (i < 1) relAngle = heading
>   # otherwise consider the previous heading in order to calculate the new
> track
>   else if (i > 0) {
>     relAngle = (previousHeading - heading)
>
>   }
>
>
>   # determine whether movement is occurring and if so what type
>   # if there are insufficient history items then just record movement types
> discretely
>    if (i < historyLength) movement <- movementType(relAngle,
> angleThreshold)
>
>   else if (i > historyLength-1) {
>     # Array to store speeds
>     speedHistory <- array(historyLength)
>     n = historyLength-1
>     # get the speeds from the previous n (hisoryLength) "Movements"
>     for (j in seq(1, length(historyLength))){
>       speedHistory [n] = R[i-j, 6]
>       n-1
>       }
>
>       if (!bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
> "non-moving"
>       else if(bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
> movementType(relAngle, angleThreshold)
>
>
>   }
>
>
>   holder <- list(movement)
>   holder [[i]] <- (movement)
>
>
>   for (t in length(holder)){
>     if (holder[[t]] == holder[[t-1]])
>       changes <- 0
>     else changes <- 1
>
>   }
>
>
>
>   # update previous heading information
>   previousHeading = heading
>
>
>
>
>
>
>   # Store the input data and the results
>   lst[[i]] <- c(
>     latitude_position_1 = lat1,
>     longtude_position_1 = long1,
>     latitude_position_2 = lat2,
>     longtude_position_2 = long2,
>     Distance = gcd_vif,
>     Speed = estSpeed,
>     Acceleration = accel,
>     Absolute_Heading = heading,
>     Relative_Heading = relAngle,
>     Movement = movement,
>     Changes = changes
>
>   )
>
> }
> Results <- as.data.frame(do.call(rbind, lst)) # store the input data and
> the
> results in a data frame
> Results
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/for-loop-not-working-tp4713392.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sat Oct 10 20:15:04 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sat, 10 Oct 2015 18:15:04 +0000
Subject: [R] Reformatting dataframe for use with icc()
In-Reply-To: <CA+_f+RGz6T3i5HA=Dp=_YBwvtT_JD7GDD+a=BPB=bsVk0A_ugw@mail.gmail.com>
References: <CA+_f+RGz6T3i5HA=Dp=_YBwvtT_JD7GDD+a=BPB=bsVk0A_ugw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CE1FA@mb02.ads.tamu.edu>

Don't post in html, the list scrambles your tables. Assuming your data looks like this

> rater.id <- c(1, 2, 1, 3, 2, 3)
> observation <- c(1, 1, 2, 2, 3, 3)
> rating <- c(6, 7, 4, 6, 2, 4)
> dat <- data.frame(rbind(rater.id, observation, rating))
> dat
            X1 X2 X3 X4 X5 X6
rater.id     1  2  1  3  2  3
observation  1  1  2  2  3  3
rating       6  7  4  6  2  4

We need to transpose the data and then use xtabs(). This will work as long as there is not more than one rating on an observation by the same rater:

> t(dat)
   rater.id observation rating
X1        1           1      6
X2        2           1      7
X3        1           2      4
X4        3           2      6
X5        2           3      2
X6        3           3      4

> tbl <- xtabs(rating~observation+rater.id, t(dat))
> tbl
           rater.id
observation 1 2 3
          1 6 7 0
          2 4 0 6
          3 0 2 4

If the 0's are a problem:

> tbl[tbl==0] <- NA
> print(tbl, na.print=NA)
           rater.id
observation    1    2    3
          1    6    7 <NA>
          2    4 <NA>    6
          3 <NA>    2    4


David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chad Danyluck
Sent: Friday, October 9, 2015 4:02 PM
To: r-help at r-project.org
Subject: [R] Reformatting dataframe for use with icc()

Hello,

I want to determine the inter-rater reliability of ratings made from a
random selection of observers and observations. I plan to use the irr
package to calculate the ICC, however, my dataframe is not organized in a
way that the icc() function can handle. The icc() function works with
dataframes in the following format:

                     rater1 rater2 rater3...
observation
1                           6       7      NA
2                           4    NA          6
3                         NA       2         4
...

My dataframe is organized in the following format:

rater.id               1  2  1  3  2  3 ...
observation       1  1  2  2  3  3 ...
rating                 6  7  4  6  2  4 ...

I would like to reformat my dataframe as it is organized in the first
example but I am not sure how to go about doing this. Any suggestions would
be appreciated.

Kind regards,

Chad

-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From ahaywood3 at gmail.com  Sat Oct 10 15:58:47 2015
From: ahaywood3 at gmail.com (andrew haywood)
Date: Sat, 10 Oct 2015 21:58:47 +0800
Subject: [R] Error with Segmented package
In-Reply-To: <E236D07A-A9F8-439B-AB5C-202653B8F8A6@comcast.net>
References: <CAEDDhTAjAFTQbt7uec4KjU-OcAHD4avUUTZUNFWhvct5dMFB7g@mail.gmail.com>
	<7F3DAEAD-077F-44EE-99D7-E9B8D1AE99A7@comcast.net>
	<CAEDDhTCx8y_0QKZ5bi7dLo0N48YrTdk_mQU3j+gXBOvG5q=s_Q@mail.gmail.com>
	<E236D07A-A9F8-439B-AB5C-202653B8F8A6@comcast.net>
Message-ID: <CAEDDhTDHp6j0HvRM62xHeXU5CJ0xRg_xGi2eRjW56CQa+qjB4A@mail.gmail.com>

Thanks Dave,

when I run traceback() the following output

Error in if (psi == Inf) psi <- median(XREGseg) :
  missing value where TRUE/FALSE needed
> traceback()
2: segmented.lm(lm(y ~ x, data = data), seg.Z = ~x, psi = NA, control =
seg.control(K = 1))
1: segmented(lm(y ~ x, data = data), seg.Z = ~x, psi = NA, control =
seg.control(K = 1))


I am unsure how to interpret this.

In addition when I run the command

options(error="browser")


I get the following error

Error in options(error = "browser") : invalid value for 'error'



Any help would be greatly appreciated.

Kind regards
Andrew

On Thu, Oct 8, 2015 at 10:33 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Oct 7, 2015, at 6:10 PM, andrew haywood wrote:
>
> > Thanks David,
> >
> > I apologies for not posting the versions.
> >
> > I am running
> >
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=English_United Kingdom.1252
> > [2] LC_CTYPE=English_United Kingdom.1252
> > [3] LC_MONETARY=English_United Kingdom.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United Kingdom.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] segmented_0.5-1.2
> >
> > And I still get the error. What is the best way to debug the error?
>
> The first thing I do is run traceback() immediately after the error. If
> that fails to illuminate the problem, my next step is falling back to:
>
> options(error="browser")
> # which should allow you to examine the system-state at the time of the
> error.
>
> And at that point I start considering sending an email to the maintainer
> with my reproducible example, especially so since it fails with a more
> recent version. It may be that the maintainer has the same OS as you have.
>
> --
> David.
> >
> > Kind regards teht
> > Andrew
> >
> >
> > On Thu, Oct 8, 2015 at 7:11 AM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > On Oct 7, 2015, at 6:50 AM, andrew haywood wrote:
> >
> > > Dear List,
> > >
> > > I am trying to run a simple pieewise regression using the segmented
> package.
> > >
> > > When running the following code
> > >
> > > library(segmented)
> > > data = data.frame(x=c(50,60,70,80,90,100,110) , y=
> > > c(703.786,705.857,708.153,711.056,709.257, 707.4, 705.6))
> > >
> > > model.lm = segmented(lm(y~x,data = data),seg.Z = ~x, psi = NA, control
> =
> > > seg.control(K=1))
> > >
> > > I get the following error.
> > >
> > > Error in if (psi == Inf) psi <- median(XREGseg) :
> > >  missing value where TRUE/FALSE needed
> >
> > I don't get any error, despite being a bit behind the times. You need to
> specify the versions (OS, R, segmented) and prepare for some debugging
> efforts. Easiest way to do this is with the output of sessionInfo().
> >
> > R version 3.2.1 (2015-06-18) -- "World-Famous Astronaut"
> > Copyright (C) 2015 The R Foundation for Statistical Computing
> > Platform: x86_64-apple-darwin10.8.0 (64-bit)
> >
> > I also have an embarrassing number of packages loaded.
> >
> > other attached packages:
> >  [1] segmented_0.5-1.1   boot_1.3-17         sqldf_0.4-10
> >
> > (remaining 48 are omitted)
> >
> >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From liqunhan at yahoo.com  Sat Oct 10 18:17:17 2015
From: liqunhan at yahoo.com (liqunhan at yahoo.com)
Date: Sat, 10 Oct 2015 16:17:17 +0000 (UTC)
Subject: [R] [FORGED] Re:  R lappy, sapply or mapply question
In-Reply-To: <56184D90.3030108@auckland.ac.nz>
References: <56184D90.3030108@auckland.ac.nz>
Message-ID: <414936133.1879267.1444493837478.JavaMail.yahoo@mail.yahoo.com>

Dear Rolf and Adams,
Thanks for?your help!?works perfectly.though all columns are of the same type,?for "safe",?it is?changed from data.frame to data.matrix as follows:
dmatrix <- data.matrix(dailyrecord[c("a", "e", "f")])
colnames(dmatrix) <- c("x5", "x6", "x7")
apply(dmatrix, 1, function(row) fun3(list1, list2, as.list(row)))
Thanks again!
Bests,LQ?
?     From: Rolf Turner <r.turner at auckland.ac.nz>
 To: "Adams, Jean" <jvadams at usgs.gov>; liqunhan at yahoo.com 
Cc: "r-help at r-project.org" <r-help at r-project.org> 
 Sent: Friday, October 9, 2015 7:28 PM
 Subject: Re: [FORGED] Re: [R] R lappy, sapply or mapply question
   
On 10/10/15 10:56, Adams, Jean wrote:


> You were very close.? Try this.
>
> df <- data.frame(x5=dailyrecord$a, x6 = dailyrecord$e, x7 = dailyrecord$f)
> apply(df, 1, function(row) fun3(list1, list2, as.list(row)))


There could in general be problems with this approach.? The apply() 
function works on *matrices* and if handed a data frame coerces it to a 
matrix.? This is (usually!) OK if all columns of the data frame are of 
the same type, but the world could end if they are not. It is a good 
idea to *start* with a matrix if a matrix is what is required.? And do 
not confuse data frames with matrices.? They are very different animals.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


  
	[[alternative HTML version deleted]]


From ahaywood3 at gmail.com  Sat Oct 10 19:27:03 2015
From: ahaywood3 at gmail.com (andrew haywood)
Date: Sun, 11 Oct 2015 01:27:03 +0800
Subject: [R] Fwd: Error Message when using VarSelection in YaiImpute package
 with the randomForest
In-Reply-To: <CAEDDhTA_p0kjQWUmJNrppZ4s30=-hMY24UcpxGCvnexdVcmqDg@mail.gmail.com>
References: <CAEDDhTA_p0kjQWUmJNrppZ4s30=-hMY24UcpxGCvnexdVcmqDg@mail.gmail.com>
Message-ID: <CAEDDhTBc+xKUW5-NPJjxZeK3LwJZM=jvz6e4J=f529iY25L20A@mail.gmail.com>

Dear All,

as I new to the R-help list. I didnt realise I should provide the following
information

R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=ms_MY.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=ms_MY.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=ms_MY.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=ms_MY.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] yaImpute_1.0-26   strucchange_1.5-1 sandwich_2.3-4    zoo_1.7-12
[5] segmented_0.5-1.2

loaded via a namespace (and not attached):
[1] grid_3.0.2          lattice_0.20-33     randomForest_4.6-12
[4] tools_3.0.2


Running traceback() I get the following

> traceback()
10: yai(x = xa, y = y, method = yaiMethod, bootstrap = bootstrap,
        ...)
9: withCallingHandlers(expr, warning = function(w)
invokeRestart("muffleWarning"))
8: suppressWarnings(yai(x = xa, y = y, method = yaiMethod, bootstrap =
bootstrap,
       ...))
7: grmsd(one = suppressWarnings(yai(x = xa, y = y, method = yaiMethod,
       bootstrap = bootstrap, ...)), ancillaryData = y, wts = wts)
6: withCallingHandlers(expr, warning = function(w)
invokeRestart("muffleWarning"))
5: suppressWarnings(grmsd(one = suppressWarnings(yai(x = xa, y = y,
       method = yaiMethod, bootstrap = bootstrap, ...)), ancillaryData = y,
       wts = wts))
4: FUN(1:5[[1L]], ...)
3: myapply(1:max(1, nboot), function(i, xa, y, wts, yaiMethod, bootstrap,
       ...) suppressWarnings(grmsd(one = suppressWarnings(yai(x = xa,
       y = y, method = yaiMethod, bootstrap = bootstrap, ...)),
       ancillaryData = y, wts = wts)), xa, y, wts, yaiMethod, bootstrap,
       ...)
2: unlist(myapply(1:max(1, nboot), function(i, xa, y, wts, yaiMethod,
       bootstrap, ...) suppressWarnings(grmsd(one = suppressWarnings(yai(x
= xa,
       y = y, method = yaiMethod, bootstrap = bootstrap, ...)),
       ancillaryData = y, wts = wts)), xa, y, wts, yaiMethod, bootstrap,
       ...))
1: varSelection(x = x, y = y, nboot = 5, yaiMethod = "randomForest",
       useParallel = FALSE)


Any help/guidance would be greatly appreciated.

Kind regards
Andrew

---------- Forwarded message ----------
From: andrew haywood <ahaywood3 at gmail.com>
Date: Thu, Sep 17, 2015 at 1:57 AM
Subject: Error Message when using VarSelection in YaiImpute package with
the randomForest
To: r-help at r-project.org


Dear All,

when using the following code

x <- iris[,1:2]  # Sepal.Length Sepal.Width
y <- iris[,3:4]  # Petal.Length Petal.Width
vsel <-
varSelection(x=x,y=y,nboot=5,yaiMethod="randomForest",useParallel=FALSE)


I get the following error code

Error in yai(x = xa, y = y, method = yaiMethod, bootstrap = bootstrap,  :
  object 'xcvRefs' not found


If anybody could tell me what I am doing wrong.

Cheers
Andrew

	[[alternative HTML version deleted]]


From caciquesamurai at gmail.com  Sat Oct 10 22:27:28 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Sat, 10 Oct 2015 17:27:28 -0300
Subject: [R] Data-frame selection
In-Reply-To: <6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
	<6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
Message-ID: <CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>

Hello Jeff!

Thanks very much for your prompt reply, but this is not exactly what I
need. I need the first sequence of records. In example that I send, I
need the first seven lines of group "T2" in ID "1" (lines 3 to 9) and
others six lines of group "T3" in ID "1" (lines 10 to 15). I have to
discard lines 16 to 20, that represent repeated sequential records of
those groups in same ID.

Others ID (I sent just a small piece of my data) I have much more
sequential lines of records of each group in each ID, and many
sequential records that should be discarded. I some cases, I have just
one record of a group in an ID.

As I told, I tried to use a labeling variable, that mark first seven
lines 3 to 9 as 1 (first sequence of T2 in ID 1), lines 10 to 15 as 1
(first sequence of T3 in ID 1), lines 16 and 17 as 2 (second sequence
of T2 in ID 1) and lines 18 to 20 as 2 (second sequence of T3 in ID
1), and so on... Then will be easy take just the first record by each
ID. But the code that I made was a long long loop sequence that at end
did not work as I want to.

Once more, thanks in advanced for your atention and help,

Raoni

2015-10-10 13:13 GMT-03:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
> ?aggregate
>
> in base R. Make a short function that returns the first element of a vector and give that to aggregate.
>
> Or...
>
> library(dplyr)
> ( test %>% group_by( ID, Group ) %>% summarise( Var=first( Var ) ) %>% as.data.frame )
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 10, 2015 8:38:00 AM PDT, Cacique Samurai <caciquesamurai at gmail.com> wrote:
>>Hello R-Helpers!
>>
>>I have a data-frame as below (dput in the end of mail) and need to
>>select just the first sequence of occurrence of each "Group" in each
>>"ID".
>>
>>For example, for ID "1" I have two sequential occurrences of T2 and
>>two sequential occurrences of T3:
>>
>>> test [test$ID == 1, ]
>>   ID Group  Var
>>3   1    T2 2.94
>>4   1    T2 3.23
>>5   1    T2 1.40
>>6   1    T2 1.62
>>7   1    T2 2.43
>>8   1    T2 2.53
>>9   1    T2 2.25
>>10  1    T3 1.66
>>11  1    T3 2.86
>>12  1    T3 0.53
>>13  1    T3 1.66
>>14  1    T3 3.24
>>15  1    T3 1.34
>>16  1    T2 1.86
>>17  1    T2 3.03
>>18  1    T3 3.63
>>19  1    T3 2.78
>>20  1    T3 1.49
>>
>>As output, I need just the first group of T2 and T3 for this ID, like:
>>
>> ID Group  Var
>>3   1    T2 2.94
>>4   1    T2 3.23
>>5   1    T2 1.40
>>6   1    T2 1.62
>>7   1    T2 2.43
>>8   1    T2 2.53
>>9   1    T2 2.25
>>10  1    T3 1.66
>>11  1    T3 2.86
>>12  1    T3 0.53
>>13  1    T3 1.66
>>14  1    T3 3.24
>>15  1    T3 1.34
>>
>>For others ID I have just one occurrence or sequence of occurrence of
>>each Group.
>>
>>I tried to use a labeling variable, but cannot figure out do this
>>without many many loops..
>>
>>Thanks in advanced,
>>
>>Raoni
>>
>> dput (teste)
>>structure(list(ID = structure(c(3L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2",
>>"3", "4"), class = "factor"), Group = structure(c(1L, 2L, 1L,
>>1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L,
>>2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L,
>>2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), .Label =
>>c("T2",
>>"T3"), class = "factor"), Var = c(0.32, 1.59, 2.94, 3.23, 1.4,
>>1.62, 2.43, 2.53, 2.25, 1.66, 2.86, 0.53, 1.66, 3.24, 1.34, 1.86,
>>3.03, 3.63, 2.78, 1.49, 2, 2.39, 1.65, 2.05, 2.75, 2.23, 1.39,
>>2.66, 1.05, 2.52, 2.49, 2.97, 0.43, 1.36, 0.79, 1.71, 1.95, 2.73,
>>2.73, 2.39, 2.17, 2.34, 2.42, 1.75, 0.66, 1.64, 0.24, 2.11, 2.11,
>>1.18)), .Names = c("ID", "Group", "Var"), row.names = c(NA, 50L
>>), class = "data.frame")
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>



-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From fransiepansiekevertje at gmail.com  Sat Oct 10 22:56:28 2015
From: fransiepansiekevertje at gmail.com (Frans Marcelissen)
Date: Sat, 10 Oct 2015 22:56:28 +0200
Subject: [R] Reformatting dataframe for use with icc()
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6CE1FA@mb02.ads.tamu.edu>
References: <CA+_f+RGz6T3i5HA=Dp=_YBwvtT_JD7GDD+a=BPB=bsVk0A_ugw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6CE1FA@mb02.ads.tamu.edu>
Message-ID: <CAFFQM6YYH1vxXCsLenQHxKj2dNSN5PYMrQeU3Dv4B4VJAHvCEg@mail.gmail.com>

I think this is what reshape is made for...
Frans
--------------------------------------

rater.id <- c(1, 2, 1, 3, 2, 3)
observation <- c(1, 1, 2, 2, 3, 3)
rating <- c(6, 7, 4, 6, 2, 4)
dat=data.frame(rater.id,observation,rating)

library(reshape)
dat2<-melt(dat, id.vars = c('rater.id','observation'))
cast(dat2,observation~rater.id)
observation  1  2  3
               1  6  7 NA
               2  4 NA  6
               3 NA  2  4

2015-10-10 20:15 GMT+02:00 David L Carlson <dcarlson at tamu.edu>:

> Don't post in html, the list scrambles your tables. Assuming your data
> looks like this
>
> > rater.id <- c(1, 2, 1, 3, 2, 3)
> > observation <- c(1, 1, 2, 2, 3, 3)
> > rating <- c(6, 7, 4, 6, 2, 4)
> > dat <- data.frame(rbind(rater.id, observation, rating))
> > dat
>             X1 X2 X3 X4 X5 X6
> rater.id     1  2  1  3  2  3
> observation  1  1  2  2  3  3
> rating       6  7  4  6  2  4
>
> We need to transpose the data and then use xtabs(). This will work as long
> as there is not more than one rating on an observation by the same rater:
>
> > t(dat)
>    rater.id observation rating
> X1        1           1      6
> X2        2           1      7
> X3        1           2      4
> X4        3           2      6
> X5        2           3      2
> X6        3           3      4
>
> > tbl <- xtabs(rating~observation+rater.id, t(dat))
> > tbl
>            rater.id
> observation 1 2 3
>           1 6 7 0
>           2 4 0 6
>           3 0 2 4
>
> If the 0's are a problem:
>
> > tbl[tbl==0] <- NA
> > print(tbl, na.print=NA)
>            rater.id
> observation    1    2    3
>           1    6    7 <NA>
>           2    4 <NA>    6
>           3 <NA>    2    4
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chad
> Danyluck
> Sent: Friday, October 9, 2015 4:02 PM
> To: r-help at r-project.org
> Subject: [R] Reformatting dataframe for use with icc()
>
> Hello,
>
> I want to determine the inter-rater reliability of ratings made from a
> random selection of observers and observations. I plan to use the irr
> package to calculate the ICC, however, my dataframe is not organized in a
> way that the icc() function can handle. The icc() function works with
> dataframes in the following format:
>
>                      rater1 rater2 rater3...
> observation
> 1                           6       7      NA
> 2                           4    NA          6
> 3                         NA       2         4
> ...
>
> My dataframe is organized in the following format:
>
> rater.id               1  2  1  3  2  3 ...
> observation       1  1  2  2  3  3 ...
> rating                 6  7  4  6  2  4 ...
>
> I would like to reformat my dataframe as it is organized in the first
> example but I am not sure how to go about doing this. Any suggestions would
> be appreciated.
>
> Kind regards,
>
> Chad
>
> --
> Chad M. Danyluck, MA
> PhD Candidate, Psychology
> University of Toronto
>
>
>
> ?There is nothing either good or bad but thinking makes it so.? - William
> Shakespeare
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Oct 11 00:47:56 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 11 Oct 2015 00:47:56 +0200
Subject: [R] Data-frame selection
In-Reply-To: <CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
	<6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
	<CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>
Message-ID: <BDA1F67B-BB01-4302-B489-466DADC2D3DE@gmail.com>

These situations where the desired results depend on the order of observations in a dataset do tend to get a little tricky (this is one kind of problem that is easier to handle in a SAS DATA step with its sequential processing paradigm). I think this will do it:

keep <- function(d)
   with(d, {
     n <- length(Group)
     i <- c(TRUE,Group[-n] != Group[-1]) 
     unsplit(lapply(split(i,Group), cumsum), Group) == 1
   })
kp <- unsplit(lapply(split(teste, teste$ID), keep), teste$ID)
teste[kp,]

I.e. keep() is a function applied to each ID-subset of the data frame, returning a logical vector of the observations that you want to keep. 

i is an indicator that an observation is the first in a sequence. Splitting by group and cumsum'ing gives 1 for the first sequence, 2 for the next, etc. The observations to keep are the ones for which this value is 1.

-pd

> On 10 Oct 2015, at 22:27 , Cacique Samurai <caciquesamurai at gmail.com> wrote:
> 
> Hello Jeff!
> 
> Thanks very much for your prompt reply, but this is not exactly what I
> need. I need the first sequence of records. In example that I send, I
> need the first seven lines of group "T2" in ID "1" (lines 3 to 9) and
> others six lines of group "T3" in ID "1" (lines 10 to 15). I have to
> discard lines 16 to 20, that represent repeated sequential records of
> those groups in same ID.
> 
> Others ID (I sent just a small piece of my data) I have much more
> sequential lines of records of each group in each ID, and many
> sequential records that should be discarded. I some cases, I have just
> one record of a group in an ID.
> 
> As I told, I tried to use a labeling variable, that mark first seven
> lines 3 to 9 as 1 (first sequence of T2 in ID 1), lines 10 to 15 as 1
> (first sequence of T3 in ID 1), lines 16 and 17 as 2 (second sequence
> of T2 in ID 1) and lines 18 to 20 as 2 (second sequence of T3 in ID
> 1), and so on... Then will be easy take just the first record by each
> ID. But the code that I made was a long long loop sequence that at end
> did not work as I want to.
> 
> Once more, thanks in advanced for your atention and help,
> 
> Raoni
> 
> 2015-10-10 13:13 GMT-03:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>> ?aggregate
>> 
>> in base R. Make a short function that returns the first element of a vector and give that to aggregate.
>> 
>> Or...
>> 
>> library(dplyr)
>> ( test %>% group_by( ID, Group ) %>% summarise( Var=first( Var ) ) %>% as.data.frame )
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On October 10, 2015 8:38:00 AM PDT, Cacique Samurai <caciquesamurai at gmail.com> wrote:
>>> Hello R-Helpers!
>>> 
>>> I have a data-frame as below (dput in the end of mail) and need to
>>> select just the first sequence of occurrence of each "Group" in each
>>> "ID".
>>> 
>>> For example, for ID "1" I have two sequential occurrences of T2 and
>>> two sequential occurrences of T3:
>>> 
>>>> test [test$ID == 1, ]
>>>  ID Group  Var
>>> 3   1    T2 2.94
>>> 4   1    T2 3.23
>>> 5   1    T2 1.40
>>> 6   1    T2 1.62
>>> 7   1    T2 2.43
>>> 8   1    T2 2.53
>>> 9   1    T2 2.25
>>> 10  1    T3 1.66
>>> 11  1    T3 2.86
>>> 12  1    T3 0.53
>>> 13  1    T3 1.66
>>> 14  1    T3 3.24
>>> 15  1    T3 1.34
>>> 16  1    T2 1.86
>>> 17  1    T2 3.03
>>> 18  1    T3 3.63
>>> 19  1    T3 2.78
>>> 20  1    T3 1.49
>>> 
>>> As output, I need just the first group of T2 and T3 for this ID, like:
>>> 
>>> ID Group  Var
>>> 3   1    T2 2.94
>>> 4   1    T2 3.23
>>> 5   1    T2 1.40
>>> 6   1    T2 1.62
>>> 7   1    T2 2.43
>>> 8   1    T2 2.53
>>> 9   1    T2 2.25
>>> 10  1    T3 1.66
>>> 11  1    T3 2.86
>>> 12  1    T3 0.53
>>> 13  1    T3 1.66
>>> 14  1    T3 3.24
>>> 15  1    T3 1.34
>>> 
>>> For others ID I have just one occurrence or sequence of occurrence of
>>> each Group.
>>> 
>>> I tried to use a labeling variable, but cannot figure out do this
>>> without many many loops..
>>> 
>>> Thanks in advanced,
>>> 
>>> Raoni
>>> 
>>> dput (teste)
>>> structure(list(ID = structure(c(3L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2",
>>> "3", "4"), class = "factor"), Group = structure(c(1L, 2L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L,
>>> 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L,
>>> 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), .Label =
>>> c("T2",
>>> "T3"), class = "factor"), Var = c(0.32, 1.59, 2.94, 3.23, 1.4,
>>> 1.62, 2.43, 2.53, 2.25, 1.66, 2.86, 0.53, 1.66, 3.24, 1.34, 1.86,
>>> 3.03, 3.63, 2.78, 1.49, 2, 2.39, 1.65, 2.05, 2.75, 2.23, 1.39,
>>> 2.66, 1.05, 2.52, 2.49, 2.97, 0.43, 1.36, 0.79, 1.71, 1.95, 2.73,
>>> 2.73, 2.39, 2.17, 2.34, 2.42, 1.75, 0.66, 1.64, 0.24, 2.11, 2.11,
>>> 1.18)), .Names = c("ID", "Group", "Var"), row.names = c(NA, 50L
>>> ), class = "data.frame")
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Raoni Rosa Rodrigues
> Research Associate of Fish Transposition Center CTPeixes
> Universidade Federal de Minas Gerais - UFMG
> Brasil
> rodrigues.raoni at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From paul.bivand at gmail.com  Sun Oct 11 01:46:47 2015
From: paul.bivand at gmail.com (Paul Bivand)
Date: Sun, 11 Oct 2015 00:46:47 +0100
Subject: [R] importing spss files without value labels
In-Reply-To: <5D38B93F-22FD-4F77-BF49-7753D62A327E@comcast.net>
References: <CAEazi5_hDktZ0B7FgWkdggJerUQZgS2h=Ufu8cibO=4qnJum6Q@mail.gmail.com>
	<5D38B93F-22FD-4F77-BF49-7753D62A327E@comcast.net>
Message-ID: <CAC=KSNjvYPNjb-yL5rfSsDJFm1X89rcrPqcFMYNhm8Ra37w_Ag@mail.gmail.com>

Most users of spss files need to have the value labels as they handle
categorical variables, with the numeric representation being
arbitrary. So the packages that handle importing them (foreign, Hmisc,
memisc, haven) make that easy.

For numeric variables, survey houses often categorise different sorts
of missing variables with a value label of -9 or -8 etc. You'll need
to be aware of this and handle these.

Memisc offers the advantage of only importing needed variables, but
the stripping of labels would most likely have to be done in R. Try
the maintainer of memisc. And, read the documentation - for importers,
data.set, measure.

Paul Bivand
Centre for Economic & Social Inclusion
London

On 9 October 2015 at 19:43, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 9, 2015, at 9:19 AM, Yongnam Kim wrote:
>
>> Hi all,
>>
>> I know how to import spss data file (.sav) to R using foreign pkg like
>> read.spss(file, use.value.labels = FALSE,...) but I like to use a different
>> pkg, in particular, memisc. Is there any corresponding way to drop the
>> value labels when importing?
>>
>> Many thanks,
>>
>>       [[alternative HTML version deleted]]
>
> This is the third day in a row that you have posted an identical message. You should be asking yourself why you have not gotten any answers. One possibility is that people do not have any copies of an spss file that they can use for testing. You might consider posting a link to one. You should also read the Posting Guide:
>
>   http://www.R-project.org/posting-guide.html
>
> And also read the linked classic article by Eric Raymond that discusses how to proerly ask a technical question on a technical forum.
>
>>
>
> And as always .... do post in plain text.
>
> --
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sun Oct 11 02:12:38 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 10 Oct 2015 17:12:38 -0700 (PDT)
Subject: [R] Data-frame selection
In-Reply-To: <BDA1F67B-BB01-4302-B489-466DADC2D3DE@gmail.com>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
	<6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
	<CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>
	<BDA1F67B-BB01-4302-B489-466DADC2D3DE@gmail.com>
Message-ID: <alpine.BSF.2.00.1510101651560.67112@pedal.dcn.davis.ca.us>

Sorry I missed the boat the first time, and while it looks like Peter is 
getting closer I suspect that is not quite there either due to the T2 
being considered separate from T3 requirement.

Here is another stab at it:

library(dplyr)
# first approach is broken apart to show the progression of the innards
resultStep1 <- ( teste
                %>% group_by( ID )
                %>% mutate( Group = as.character( Group )
                          , transitionT2 = diff( c( FALSE, "T2"== Group ) )
                          , transitionT3 = diff( c( FALSE, "T3"== Group ) )
                          , groupseqT2 = cumsum( abs( transitionT2 ) )
                          , groupseqT3 = cumsum( abs( transitionT3 ) )
                          , isT2 = 1 == groupseqT2
                          , isT3 = 1 == groupseqT3
                          )
                %>% as.data.frame
                )
resultStep1
# notice how the groupseq columns number the groups of consecutive similar
# values, and you are only interested in the groups numbered 1.

# more compactly
result <- (   teste
           %>% group_by( ID )
           %>% mutate( Group = as.character( Group )
                     , keep = ( 1 == cumsum( abs( diff(
 				c( FALSE, "T2"== Group ) ) ) )
                              | 1 == cumsum( abs( diff(
 				c( FALSE, "T3"== Group ) ) ) )
                              )
                     )
           %>% filter( keep )
           %>% select( -keep )
           %>% as.data.frame
)

#####
> resultStep1
    ID Group  Var transitionT2 transitionT3 groupseqT2 groupseqT3  isT2  isT3
1   3    T2 0.32            1            0          1          0  TRUE FALSE
2   4    T3 1.59            0            1          0          1 FALSE  TRUE
3   1    T2 2.94            1            0          1          0  TRUE FALSE
4   1    T2 3.23            0            0          1          0  TRUE FALSE
5   1    T2 1.40            0            0          1          0  TRUE FALSE
6   1    T2 1.62            0            0          1          0  TRUE FALSE
7   1    T2 2.43            0            0          1          0  TRUE FALSE
8   1    T2 2.53            0            0          1          0  TRUE FALSE
9   1    T2 2.25            0            0          1          0  TRUE FALSE
10  1    T3 1.66           -1            1          2          1 FALSE  TRUE
11  1    T3 2.86            0            0          2          1 FALSE  TRUE
12  1    T3 0.53            0            0          2          1 FALSE  TRUE
13  1    T3 1.66            0            0          2          1 FALSE  TRUE
14  1    T3 3.24            0            0          2          1 FALSE  TRUE
15  1    T3 1.34            0            0          2          1 FALSE  TRUE
16  1    T2 1.86            1           -1          3          2 FALSE FALSE
17  1    T2 3.03            0            0          3          2 FALSE FALSE
18  1    T3 3.63           -1            1          4          3 FALSE FALSE
19  1    T3 2.78            0            0          4          3 FALSE FALSE
20  1    T3 1.49            0            0          4          3 FALSE FALSE
21  2    T2 2.00            1            0          1          0  TRUE FALSE
22  2    T2 2.39            0            0          1          0  TRUE FALSE
23  2    T2 1.65            0            0          1          0  TRUE FALSE
24  2    T2 2.05            0            0          1          0  TRUE FALSE
25  2    T2 2.75            0            0          1          0  TRUE FALSE
26  2    T2 2.23            0            0          1          0  TRUE FALSE
27  2    T2 1.39            0            0          1          0  TRUE FALSE
28  2    T2 2.66            0            0          1          0  TRUE FALSE
29  2    T2 1.05            0            0          1          0  TRUE FALSE
30  2    T3 2.52           -1            1          2          1 FALSE  TRUE
31  2    T2 2.49            1           -1          3          2 FALSE FALSE
32  2    T2 2.97            0            0          3          2 FALSE FALSE
33  2    T2 0.43            0            0          3          2 FALSE FALSE
34  2    T2 1.36            0            0          3          2 FALSE FALSE
35  2    T3 0.79           -1            1          4          3 FALSE FALSE
36  2    T3 1.71            0            0          4          3 FALSE FALSE
37  2    T3 1.95            0            0          4          3 FALSE FALSE
38  2    T2 2.73            1           -1          5          4 FALSE FALSE
39  2    T2 2.73            0            0          5          4 FALSE FALSE
40  2    T2 2.39            0            0          5          4 FALSE FALSE
41  2    T2 2.17            0            0          5          4 FALSE FALSE
42  2    T2 2.34            0            0          5          4 FALSE FALSE
43  2    T3 2.42           -1            1          6          5 FALSE FALSE
44  2    T3 1.75            0            0          6          5 FALSE FALSE
45  2    T3 0.66            0            0          6          5 FALSE FALSE
46  2    T3 1.64            0            0          6          5 FALSE FALSE
47  2    T2 0.24            1           -1          7          6 FALSE FALSE
48  2    T3 2.11           -1            1          8          7 FALSE FALSE
49  2    T3 2.11            0            0          8          7 FALSE FALSE
50  2    T3 1.18            0            0          8          7 FALSE FALSE

On Sun, 11 Oct 2015, peter dalgaard wrote:

> These situations where the desired results depend on the order of observations in a dataset do tend to get a little tricky (this is one kind of problem that is easier to handle in a SAS DATA step with its sequential processing paradigm). I think this will do it:
>
> keep <- function(d)
>   with(d, {
>     n <- length(Group)
>     i <- c(TRUE,Group[-n] != Group[-1])
>     unsplit(lapply(split(i,Group), cumsum), Group) == 1
>   })
> kp <- unsplit(lapply(split(teste, teste$ID), keep), teste$ID)
> teste[kp,]
>
> I.e. keep() is a function applied to each ID-subset of the data frame, returning a logical vector of the observations that you want to keep.
>
> i is an indicator that an observation is the first in a sequence. Splitting by group and cumsum'ing gives 1 for the first sequence, 2 for the next, etc. The observations to keep are the ones for which this value is 1.
>
> -pd
>
>> On 10 Oct 2015, at 22:27 , Cacique Samurai <caciquesamurai at gmail.com> wrote:
>>
>> Hello Jeff!
>>
>> Thanks very much for your prompt reply, but this is not exactly what I
>> need. I need the first sequence of records. In example that I send, I
>> need the first seven lines of group "T2" in ID "1" (lines 3 to 9) and
>> others six lines of group "T3" in ID "1" (lines 10 to 15). I have to
>> discard lines 16 to 20, that represent repeated sequential records of
>> those groups in same ID.
>>
>> Others ID (I sent just a small piece of my data) I have much more
>> sequential lines of records of each group in each ID, and many
>> sequential records that should be discarded. I some cases, I have just
>> one record of a group in an ID.
>>
>> As I told, I tried to use a labeling variable, that mark first seven
>> lines 3 to 9 as 1 (first sequence of T2 in ID 1), lines 10 to 15 as 1
>> (first sequence of T3 in ID 1), lines 16 and 17 as 2 (second sequence
>> of T2 in ID 1) and lines 18 to 20 as 2 (second sequence of T3 in ID
>> 1), and so on... Then will be easy take just the first record by each
>> ID. But the code that I made was a long long loop sequence that at end
>> did not work as I want to.
>>
>> Once more, thanks in advanced for your atention and help,
>>
>> Raoni
>>
>> 2015-10-10 13:13 GMT-03:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:
>>> ?aggregate
>>>
>>> in base R. Make a short function that returns the first element of a vector and give that to aggregate.
>>>
>>> Or...
>>>
>>> library(dplyr)
>>> ( test %>% group_by( ID, Group ) %>% summarise( Var=first( Var ) ) %>% as.data.frame )
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                      Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On October 10, 2015 8:38:00 AM PDT, Cacique Samurai <caciquesamurai at gmail.com> wrote:
>>>> Hello R-Helpers!
>>>>
>>>> I have a data-frame as below (dput in the end of mail) and need to
>>>> select just the first sequence of occurrence of each "Group" in each
>>>> "ID".
>>>>
>>>> For example, for ID "1" I have two sequential occurrences of T2 and
>>>> two sequential occurrences of T3:
>>>>
>>>>> test [test$ID == 1, ]
>>>>  ID Group  Var
>>>> 3   1    T2 2.94
>>>> 4   1    T2 3.23
>>>> 5   1    T2 1.40
>>>> 6   1    T2 1.62
>>>> 7   1    T2 2.43
>>>> 8   1    T2 2.53
>>>> 9   1    T2 2.25
>>>> 10  1    T3 1.66
>>>> 11  1    T3 2.86
>>>> 12  1    T3 0.53
>>>> 13  1    T3 1.66
>>>> 14  1    T3 3.24
>>>> 15  1    T3 1.34
>>>> 16  1    T2 1.86
>>>> 17  1    T2 3.03
>>>> 18  1    T3 3.63
>>>> 19  1    T3 2.78
>>>> 20  1    T3 1.49
>>>>
>>>> As output, I need just the first group of T2 and T3 for this ID, like:
>>>>
>>>> ID Group  Var
>>>> 3   1    T2 2.94
>>>> 4   1    T2 3.23
>>>> 5   1    T2 1.40
>>>> 6   1    T2 1.62
>>>> 7   1    T2 2.43
>>>> 8   1    T2 2.53
>>>> 9   1    T2 2.25
>>>> 10  1    T3 1.66
>>>> 11  1    T3 2.86
>>>> 12  1    T3 0.53
>>>> 13  1    T3 1.66
>>>> 14  1    T3 3.24
>>>> 15  1    T3 1.34
>>>>
>>>> For others ID I have just one occurrence or sequence of occurrence of
>>>> each Group.
>>>>
>>>> I tried to use a labeling variable, but cannot figure out do this
>>>> without many many loops..
>>>>
>>>> Thanks in advanced,
>>>>
>>>> Raoni
>>>>
>>>> dput (teste)
>>>> structure(list(ID = structure(c(3L, 4L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), .Label = c("1", "2",
>>>> "3", "4"), class = "factor"), Group = structure(c(1L, 2L, 1L,
>>>> 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 2L, 2L,
>>>> 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L,
>>>> 2L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L), .Label =
>>>> c("T2",
>>>> "T3"), class = "factor"), Var = c(0.32, 1.59, 2.94, 3.23, 1.4,
>>>> 1.62, 2.43, 2.53, 2.25, 1.66, 2.86, 0.53, 1.66, 3.24, 1.34, 1.86,
>>>> 3.03, 3.63, 2.78, 1.49, 2, 2.39, 1.65, 2.05, 2.75, 2.23, 1.39,
>>>> 2.66, 1.05, 2.52, 2.49, 2.97, 0.43, 1.36, 0.79, 1.71, 1.95, 2.73,
>>>> 2.73, 2.39, 2.17, 2.34, 2.42, 1.75, 0.66, 1.64, 0.24, 2.11, 2.11,
>>>> 1.18)), .Names = c("ID", "Group", "Var"), row.names = c(NA, 50L
>>>> ), class = "data.frame")
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>> --
>> Raoni Rosa Rodrigues
>> Research Associate of Fish Transposition Center CTPeixes
>> Universidade Federal de Minas Gerais - UFMG
>> Brasil
>> rodrigues.raoni at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From pdalgd at gmail.com  Sun Oct 11 02:40:37 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 11 Oct 2015 02:40:37 +0200
Subject: [R] Data-frame selection
In-Reply-To: <alpine.BSF.2.00.1510101651560.67112@pedal.dcn.davis.ca.us>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
	<6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
	<CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>
	<BDA1F67B-BB01-4302-B489-466DADC2D3DE@gmail.com>
	<alpine.BSF.2.00.1510101651560.67112@pedal.dcn.davis.ca.us>
Message-ID: <BA5732EC-367C-4479-82F3-2091E3400B37@gmail.com>


> On 11 Oct 2015, at 02:12 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Sorry I missed the boat the first time, and while it looks like Peter is getting closer I suspect that is not quite there either due to the T2 being considered separate from T3 requirement.

Er, what do you mean by that? 

As far as I can tell, we're selecting the same observations:

> teste[kp,]
   ID Group  Var
1   3    T2 0.32
2   4    T3 1.59
3   1    T2 2.94
4   1    T2 3.23
5   1    T2 1.40
6   1    T2 1.62
7   1    T2 2.43
8   1    T2 2.53
9   1    T2 2.25
10  1    T3 1.66
11  1    T3 2.86
12  1    T3 0.53
13  1    T3 1.66
14  1    T3 3.24
15  1    T3 1.34
21  2    T2 2.00
22  2    T2 2.39
23  2    T2 1.65
24  2    T2 2.05
25  2    T2 2.75
26  2    T2 2.23
27  2    T2 1.39
28  2    T2 2.66
29  2    T2 1.05
30  2    T3 2.52


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From oma.gonzales at gmail.com  Sun Oct 11 07:07:52 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sun, 11 Oct 2015 00:07:52 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
	<CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
Message-ID: <CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>

Hi  Boris,

I've modified a little the for loop to catch the IDs (if there is any)
otherwise to put NAs. This is for another data set.



for (i in 1:nrow(linio.tv)) {

        v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
isolate tokens

        if(any(grep("[A-Z][0-9]", v))) {

                linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]

        }

        else {
                linio.tv$id[i] <- NA
        }
}


I get this warning messages, nevertheless the IDs column get the correct
values:

Warning messages:
1: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
  number of items to replace is not a multiple of replacement length
2: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
  number of items to replace is not a multiple of replacement length


The problem:

There are entries where the grep part is not specific enough.

Like this one: "UN50JU6500-NEGRO". It satifies the rule in:

linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  , but is not supposed to take
also: "UN50JU6500-NEGRO" entirely, only this part: "UN50JU6500".


I've noticed this rule: the IDs can have at maxium 1 letter after the "-".
If it contains more than 1, that part should not be considered.

"TC-L42AS610"

Also IDs can start with numbers: 1,2, or 3.

"KDL-40R354B"




May you clarify to me if it's something that can be done within R?  I'm
trying to figure this out, but with any good result.

I could cleaned with "sub()" (there is only one entry giving me troubles)
but the idea is not to have "technical debt" for the future.




This is the new data set, I'm talking about:






linio.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), marca = c("LG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
"SAMSUNG", "LG", "LG", "SAMSUNG", "LG", "LG", "LG", "LG", "SAMSUNG",
"LG", "LG", "LG", "SONY", "SAMSUNG", "LG", "LG", "SAMSUNG", "SONY",
"SAMSUNG", "LG", "LG", "LG", "IMACO", "SAMSUNG", "LG", "SAMSUNG",
"SAMSUNG", "LG", "HAIER", "LG", "SONY", "SAMSUNG", "LG", "LG",
"LG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "HISENSE", "LG",
"SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "CONTINENTAL",
"LG", "IMACO", "AOC", "AOC", "SAMSUNG", "LG", "SONY", "LG", "LG",
"SONY", "SAMSUNG", "SAMSUNG", "PANASONIC", "LG", "SAMSUNG", "NEX",
"IMACO", "LG", "LG", "CONTINENTAL", "SONY", "LG", "LG", "SAMSUNG",
"LG", "LG", "LG", "LG", "LG", "SAMSUNG", "LG", "LG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "AOC", "LG", "LG",
"AOC", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "LG", "LG",
"SAMSUNG", "SAMSUNG", "SONY", "LG", "SAMSUNG", "SAMSUNG", "LG",
"SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "PANASONIC", "PANASONIC",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY",
"LG", "LG", "PANASONIC", "AOC", "SAMSUNG", "LG", "SAMSUNG", "LG",
"SAMSUNG", "LG", "LG", "LG", "PANASONIC", "PANASONIC", "LG",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
"SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "SAMSUNG",
"LG", "LG", "SAMSUNG", "LG"), producto = c("COMBO SMART - LG TV LED 4K
ULTRA HD 43'' - 43UF6750 + GOO...",
"SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", "SAMSUNG TV LED 3D SMART
FULL HD 48'' - 48J6400",
"SAMSUNG TV LED 3D SMART FULL HD 55'' - 55J6400", "LG TV SMART LED HD 32\"
32LF585B - BLANCO",
"LG TV SLIM ULTRA HD 3D WEBOS 2.0 49'' 49UF8500 - PLATEADO",
"LG TV SMART WEBOS 2.0 FULL HD 43\" 43LF5900 -NEGRO", "LG TV LED HD 32\" -
32LF550B",
"LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "LG TV  LED SMART HD 32\"
- 32LF585B",
"LG GAME TV LED FULL HD 49\" - 49LF5410", "SAMSUNG TV LED  FULL HD 60'' -
UN60FH6003",
"LG TV SMART WEBOS 2.0 FULL HD 49\" - 49LF6350", "LG TV LED  FULL HD 43'' -
43LF5410",
"SAMSUNG TV SMART FULL HD CURVO 40'' TIZEN -  UN40J6500", "LG TV SMART
WEBOS 2.0 ULTRA HD  4K 43\" - 43UF6400",
"LG TV SLIM LED CINEMA 3D FULL HD 42'' 42LB6200 INCLUYE 02...",
"LG GAMETV  LED FULL HD 43\" - 43LF5400", "LG GAME TV LED FULL HD 49\" -
49LF5410",
"TELEVISOR SAMSUNG UN40J5500 SMART TV LED FULL HD 40''-PLA...",
"LG SMART  4K ULTRA HD 55\" - 55UB8200", "LG -TV LED SMART WEBOS 2.0 FULL
HD 55\" - 55LF6350",
"LG - GAME TV LED  FULL HD 43'' - 43LF5410", "SONY - TV LED SMART HD 32'' -
32R505C",
"SAMSUNG TV LED 3D SMART FULL HD 40'' - UN40H6400", "LG SMART TV 32\" HD
WEBOS 2.0  32LF595B",
"LG - TV LED WEBOS 3D SMART ULTRA HD CURVO  55'' 55UG8700 ...",
"SAMSUNG TV LED FULL HD 40\" UN40JH5005 - NEGRO", "SONY TV LED FULL HD 40''
- KDL-40R354B",
"SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
"LG TV LED FULL HD 42'' ULTRA SLIM 42LY340C - NEGRO", "LG TV SMART LED FULL
HD 43\" - 43LF6350",
"LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
"IMACO - TV LED HD 24?? - LED24HD", "TELEVISOR SAMSUNG UN32J4300 SMART TV
LED HD 32''-NEGRO",
"LG TV 3D SMART LED ULTRA HD 65\" - 65UF8500", "SAMSUNG - TV LED SMART 3D
65\" FULL HD SERIE 8 INTERACTIVO...",
"SAMSUNG - TV LED HD 32\"  32JH4005 - NEGRO", "LG TV 55\" SMART ULTRA HD 4K
CINEMA 3D  55UB8500",
"HAIER TV LED HD LIVE GREEN 24'' - 24B8000", "LG TV LED FULL HD 47'' -
47LB5610",
"SONY TV LED FULL HD 32'' - KDL-32R304B", "SAMSUNG TV LED SERIE 5 FULL HD
39? - 39FH5005",
"LG - TV SAMT SLIM ULTRA HD 4K WEBOS 2.0 55'' 55UF7700 - P...",
"LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
"LG TV MONITOR LED HD 23.6? - 24MT47A", "SAMSUNG - MONITOR LED 32\" MD32C -
NEGRO",
"TELEVISOR SAMSUNG UN40J6400 SMART TV LED 3D FULL HD 40''-...",
"SAMSUNG LED SMART FULL HD 48'' - UN48J6500", "SONY - TV LED SMART FULL HD
40'' - 40R555C",
"TELEVISOR HISENSE LED 40\" 40K221W SMART TV LED FULL HD", "LG TV MONITOR
LED HD 23.6? - 24MT47A",
"TELEVISOR SAMSUNG UN48J6400 SMART TV LED 3D FULL HD 48''-...",
"LG 49UB8500 LED 49\" SMART 3D 4K", "SAMSUNG TV LED 3D SMART FULL HD 40''
TIZEN UN40J6400 - NEGRO",
"LG TV LED FULL HD 42\" - 42LY340C", "SAMSUNG TV LED HD 32'' UN32J4000 -
NEGRO",
"TELEVISOR SAMSUNG UN48J5500 SMART TV LED FULL HD 48''-PLA...",
"CONTINENTAL - TV LED 15.6\" CELED95935, INCLUYE RACK", "LG TV LED 4K ULTRA
HD 43\" - 43UF6750",
"IMACO - TV LED HD 16?? - LED16HD", "AOC - TELEVISOR HD 32\" LE32W454F-
NEGRO",
"AOC TV LED HD 20\" - LE20A1140", "SAMSUNG TV LED HD 32'' - UN32J4000",
"LG - TV MONITOR 27.5? - 28MT47B", "SONY TV LED FULL HD 40'' -
KDL-40R354B",
"LG TV MONITOR LED HD 23.6? - 24MT47A", "LG GAME TV LED FULL HD 49\" -
49LF5410",
"SONY TV LED FULL HD 40'' - KDL-40R354B", "SAMSUNG - UN48J6400 LED FULL HD
48\"SMART TIZEN 3D 2015 - ...",
"SAMSUNG - MONITOR FULL HD 40\" MD40C - NEGRO", "PANASONIC LED SMART FULL
HD 50\" - TC-50AS600",
"LG - 43LF5410 LED 43\" FULL HD GAME  - SILVER", "SAMSUNG - TELEVISOR LED
HD 32\" UN32JH4005 - NEGRO",
"NEX TV LED SMART HD 32\" USB WIFI INCORPORADO - LED3208SMR",
"IMACO - TV LED HD 19?? - LED19HD", "LG -TV LED HG 32\" - 32LF550B",
"LG - TELEVISOR LED 32\" HD 32LF550B", "CONTINENTAL - TV LED 19\"
CELED99935,  INCLUYE RACK",
"SONY TV LED FULL HD 40'' - KDL-40R354B", "LG - TELEVISOR LED 32\" HD SMART
TV 32LF585B - BLANCO",
"MONITOR TV LG 24MT47A LED HD 23.6?-PLATEADO", "TELEVISOR SAMSUNG UN32J4300
SMART TV LED HD 32''-NEGRO",
"LG GAME TV LED FULL HD 49\" - 49LF5400", "LG - TELEVISOR LED 32\" HD SMART
TV 32LF585B ? BLANCO",
"LG - TELEVISOR LED 32\" HD 32LF550B", "LG TV LED HD 32'' - 32LF550B",
"LG TV LED SMART HD 32'' - 32LF585B", "SAMSUNG - TELEVISOR LED FULL HD 40\"
UN40JH5005 ? NEGRO",
"LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", "LG TV LED WEBOS 3D
SMART ULTRA HD 49'' - 49UF8500",
"SAMSUNG - TV LED SMART FULL HD 40? UN40H5500 - NEGRO", "SAMSUNG TV LED
SMART HD 32'' UN32J4300 - NEGRO",
"SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", "SAMSUNG -
TELEVISOR LED FULL HD 40\" UN40JH5005 - NEGRO",
"SAMSUNG TV LED SMART TIZEN 3D QUADCORE40\" - UN40J6400", "AOC TV LED HD
32\" - LE32W454F +RACK FIJO",
"LG TV LED FULL HD 43'' - 43LF5410", "LG - TV LED WEBOS 3D SMART FULL HD
55'' - 55LF6500",
"AOC 32\" LE32W454F  HD DIGITAL LED TV + HOME THEATRE F1200U",
"LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED ALTA
DEFINICI?N DTV USB 32\" - 32JH4005",
"LG - 42LF6400 LED FULL HD 42'' SMART WEBOS 3D - SILVER", "TELEVISOR
SAMSUNG UN48J5300 SMART TV LED FULL HD 48''-NEGRO",
"SAMSUNG UN40JH5005 LED FULL HD 40\"  - NEGRO GLOSS", "LG - 24MT47A +
MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...",
"LG TV LED SMART 4K ULTRA HD 55\" - 55UB8200", "SAMSUNG - 55J6400 LED 55\"
SMART TIZEN 3D - BLACK",
"SAMSUNG TV CURVED SMART ULTRA HD 48'' TIZEN UN48JU6700 - ...",
"TELEVISI?N SONY KDL-32R505C LED 32\"-NEGRO", "LG TV LED CINEMA 3D 4K SMART
ULTRA HD 49'' + 02 LENTES 3D...",
"SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", "SAMSUNG - 40J5500 LED
40\" SMART QUADCORE / BLUETOOTH* - S...",
"LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED SMART
FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
"LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 ? PLAT...",
"TELEVISI?N SAMSUNG UN48J5500 LED SMART TV 48\"-PLATEADO", "LG - TELEVISOR
LED 42\" FULL HD SMART TV 42LF5850 - PLATEADO",
"TELEVISOR SAMSUNG  UN55JU6700 LED UHD 4K SMART 55'' - PLA...",
"LG - TV LED WEBOS 3D SMART SUPER ULTRA HD 55'' - 55UF9500",
"TELEVISOR SAMSUNG UN50JU6500  UHD 4K SMART 50'' - PLATEADO",
"SAMSUNG - TELEVISOR LED HD 40\" SMART UN40J5500 - NEGRO", "TELEVISOR
SAMSUNG UN48J6500 CURVO  FULL HD SMART 48'' - P...",
"SAMSUNG - TELEVISOR LED HD 32\" SMART UN32J4300 - NEGRO", "LG TV LED
CINEMA 3D 4K SMART ULTRA HD 55'' 55UB8500 - NEGRO",
"TELEVISI?N PANASONIC TC-L40SV7L LED FULL-HD 40''-NEGRO", "PANASONIC TV LED
42?? FULL HD TC-L42E6L - NEGRO.",
"TELEVISOR SAMSUNG UN 40JH5005 LED FULL HD", "SAMSUNG - TV LED SMART CURVO
3D ULTRA HD 65? UN65HU9000...",
"SAMSUNG - UN48J5300 LED FULL HD SMART 2015 - BLACK", "SAMSUNG TV LED SMART
FULL HD 50'' TIZEN UN50J5500 - PLATEADO",
"SAMSUNG - TV SMART 3D FULL HD 60? UN60H7100 - NEGRO", "SONY - TELEVISOR
LED SMART TV FULL HD 40'' KDL-40R555C - ...",
"LG TV 47\" LED FULL HD - 47LY340C", "LG TV UHD 4K 65UB9800 SMART 3D LED TV
C/WEBOS 65' LENTES 3D",
"PANASONIC - TELEVISOR TC-L42AS610 LED SMART FULL HD 42?...",
"AOC - TELEVISOR LED 32\" - LE32W454F", "SAMSUNG TV LED 32? - UN32FH4005G",
"LG TV SMART LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED 3D SMART FULL HD
40'' TIZEN UN40J6400 - NEGRO",
"LG TV SMART  LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED HD 32''
UN32JH4005 - NEGRO",
"LG TV PLASMA 2014 60\" FULL HD 1080P - 60PB5600", "LG TV LED CINEMA 3D
SMART FULL HD 55'' 55LB7050 - PLATEADO",
"LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "PANASONIC PUERTO USB LED
40\" - TC-L40SV7L",
"PANASONIC LED SMART FULL HD 42\" - TC-L42AS610", "LG TV SMART  LED FULL HD
49\" - 49LF6350",
"SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500-NEGRO",
"SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500 - NEGRO",
"SAMSUNG TV SMART FULL HD CURVO 48'' TIZEN UN48J6500", "SAMSUNG TV  SMART
ULTRA HD 4K  65'' - UN65JU6500",
"SAMSUNG UN48J5500 LED 48\" - PLATEADO", "SAMSUNG LED 32\" CONEXI?N WIFI -
UN32J4300",
"SAMSUNG LED SMART 40'' CONEXI?N WI-FI DIRECT - UN40J5500", "SAMSUNG LED
SMART ULTRA HD 55\" - TVUN55JU6700",
"SAMSUNG TV CURVED 3D SMART ULTRA HD 65'' TIZEN UN65JU7500...",
"SAMSUNG TELEVISOR  HG32NB460GF, 32\" LED, HD, 1366 X 768", "LG -TV SMART
LED FULL HD 55\" - 55LF6350",
"SAMSUNG TV LED SMART 3D 48\" - UN48H6400", "LG LED ULTRAHD 4K 49\" SMART
3D - 49UB8300",
"LG - TV LED SMART HD 32'' 32LF585B - PLATEADO", "SAMSUNG - TV LED FULL HD
40\" UN40JH5005  - NEGRO GLOSS",
"LG - TV LED FULL HD 43'' 43LF5410 - PLATEADO"), precio.antes = c(2599L,
1299L, 2899L, 3999L, 1199L, 4499L, 1999L, 1099L, 2299L, 1299L,
2499L, 3999L, 2199L, 1899L, 2299L, 2299L, 1799L, 1499L, 2299L,
1999L, 3999L, 3499L, 1549L, 1299L, 2299L, 2299L, 6999L, 1499L,
1499L, 1899L, 1499L, 2099L, 6999L, 599L, 1299L, 9999L, 8999L,
999L, 5999L, 599L, 2299L, 1299L, 1499L, 4999L, 6999L, 899L, 2299L,
2499L, 3299L, 1799L, 1399L, 899L, 2499L, 4199L, 2299L, 1499L,
1099L, 2499L, 399L, 2499L, 399L, 999L, 599L, 999L, 899L, 1499L,
699L, 2299L, 1399L, 2499L, 2999L, 2499L, 1599L, 1149L, 999L,
499L, 1089L, 1099L, 499L, 1499L, 1399L, 799L, 1299L, 2499L, 1399L,
1259L, 1299L, 1299L, 1599L, 1999L, 3999L, 1999L, 1199L, 999L,
1599L, 2299L, 999L, 1499L, 3699L, 1199L, 3899L, 1099L, 2299L,
2499L, 1399L, 729L, 4199L, 3599L, 4999L, 1399L, 3999L, 4999L,
2199L, 4499L, 2299L, 1699L, 2779L, 1699L, 5799L, 8999L, 3699L,
2099L, 3299L, 1299L, 5900L, 1799L, 1799L, 1399L, 14999L, 2499L,
2799L, 6299L, 1799L, 2417L, 9500L, 1799L, 799L, 999L, 1999L,
2499L, 1899L, 999L, 2299L, 3699L, 2199L, 1699L, 1999L, 2499L,
3499L, 3899L, 2999L, 7999L, 2299L, 1299L, 2099L, 5799L, 9999L,
1110L, 3399L, 2799L, 3899L, 1299L, 1399L, 1499L), precio.nuevo = c(1799L,
999L, 2299L, 3299L, 999L, 3199L, 1499L, 849L, 1399L, 979L, 1795L,
2999L, 1899L, 1299L, 1699L, 1599L, 1499L, 1299L, 1699L, 1449L,
3699L, 2499L, 1199L, 999L, 1499L, 899L, 4999L, 1199L, 1199L,
1389L, 1299L, 1699L, 4899L, 549L, 999L, 7499L, 6700L, 849L, 4299L,
549L, 1499L, 899L, 1299L, 3599L, 5354L, 538L, 1959L, 1599L, 2999L,
1367L, 1099L, 589L, 2449L, 3199L, 1529L, 1229L, 839L, 1779L,
329L, 1799L, 389L, 719L, 489L, 849L, 799L, 1185L, 599L, 1609L,
1299L, 2179L, 2839L, 1999L, 1599L, 899L, 799L, 449L, 880L, 899L,
429L, 1275L, 1199L, 589L, 999L, 1749L, 1199L, 1099L, 899L, 989L,
1399L, 1999L, 2999L, 1599L, 999L, 819L, 1299L, 2299L, 789L, 1299L,
3199L, 977L, 3089L, 849L, 1719L, 1799L, 1399L, 569L, 3979L, 3299L,
3369L, 1093L, 3389L, 3289L, 1419L, 3429L, 1405L, 1499L, 1899L,
1499L, 5199L, 6999L, 3199L, 1599L, 2999L, 1099L, 5089L, 1459L,
1499L, 1289L, 12999L, 1739L, 2255L, 5879L, 1499L, 1929L, 8499L,
1649L, 799L, 899L, 1659L, 1749L, 1609L, 831L, 2089L, 3659L, 1769L,
1499L, 1599L, 2176L, 2749L, 2889L, 2899L, 5599L, 1899L, 1099L,
1899L, 5199L, 8589L, 990L, 3169L, 2199L, 3899L, 949L, 1099L,
1199L), dif.precios = c(800L, 300L, 600L, 700L, 200L, 1300L,
500L, 250L, 900L, 320L, 704L, 1000L, 300L, 600L, 600L, 700L,
300L, 200L, 600L, 550L, 300L, 1000L, 350L, 300L, 800L, 1400L,
2000L, 300L, 300L, 510L, 200L, 400L, 2100L, 50L, 300L, 2500L,
2299L, 150L, 1700L, 50L, 800L, 400L, 200L, 1400L, 1645L, 361L,
340L, 900L, 300L, 432L, 300L, 310L, 50L, 1000L, 770L, 270L, 260L,
720L, 70L, 700L, 10L, 280L, 110L, 150L, 100L, 314L, 100L, 690L,
100L, 320L, 160L, 500L, 0L, 250L, 200L, 50L, 209L, 200L, 70L,
224L, 200L, 210L, 300L, 750L, 200L, 160L, 400L, 310L, 200L, 0L,
1000L, 400L, 200L, 180L, 300L, 0L, 210L, 200L, 500L, 222L, 810L,
250L, 580L, 700L, 0L, 160L, 220L, 300L, 1630L, 306L, 610L, 1710L,
780L, 1070L, 894L, 200L, 880L, 200L, 600L, 2000L, 500L, 500L,
300L, 200L, 811L, 340L, 300L, 110L, 2000L, 760L, 544L, 420L,
300L, 488L, 1001L, 150L, 0L, 100L, 340L, 750L, 290L, 168L, 210L,
40L, 430L, 200L, 400L, 323L, 750L, 1010L, 100L, 2400L, 400L,
200L, 200L, 600L, 1410L, 120L, 230L, 600L, 0L, 350L, 300L, 300L
), dif.porcentual = c(30.78, 23.09, 20.7, 17.5, 16.68, 28.9,
25.01, 22.75, 39.15, 24.63, 28.17, 25.01, 13.64, 31.6, 26.1,
30.45, 16.68, 13.34, 26.1, 27.51, 7.5, 28.58, 22.6, 23.09, 34.8,
60.9, 28.58, 20.01, 20.01, 26.86, 13.34, 19.06, 30, 8.35, 23.09,
25, 25.55, 15.02, 28.34, 8.35, 34.8, 30.79, 13.34, 28.01, 23.5,
40.16, 14.79, 36.01, 9.09, 24.01, 21.44, 34.48, 2, 23.82, 33.49,
18.01, 23.66, 28.81, 17.54, 28.01, 2.51, 28.03, 18.36, 15.02,
11.12, 20.95, 14.31, 30.01, 7.15, 12.81, 5.34, 20.01, 0, 21.76,
20.02, 10.02, 19.19, 18.2, 14.03, 14.94, 14.3, 26.28, 23.09,
30.01, 14.3, 12.71, 30.79, 23.86, 12.51, 0, 25.01, 20.01, 16.68,
18.02, 18.76, 0, 21.02, 13.34, 13.52, 18.52, 20.77, 22.75, 25.23,
28.01, 0, 21.95, 5.24, 8.34, 32.61, 21.87, 15.25, 34.21, 35.47,
23.78, 38.89, 11.77, 31.67, 11.77, 10.35, 22.22, 13.52, 23.82,
9.09, 15.4, 13.75, 18.9, 16.68, 7.86, 13.33, 30.41, 19.44, 6.67,
16.68, 20.19, 10.54, 8.34, 0, 10.01, 17.01, 30.01, 15.27, 16.82,
9.13, 1.08, 19.55, 11.77, 20.01, 12.93, 21.43, 25.9, 3.33, 30,
17.4, 15.4, 9.53, 10.35, 14.1, 10.81, 6.77, 21.44, 0, 26.94,
21.44, 20.01), pulgadas = c("43", "32", "48", "55", "32", "49",
"43", "32", "43", "32", "49", "60", "49", "43", "40", "43", "42",
"43", "49", "40", "55", "55", "43", "32", "40", "32", "55", "40",
"40", "40", "42", "43", "55", "24", "32", "65", "65", "32", "55",
"24", "47", "32", "39", "55", "55", "6", "32", "40", "48", "40",
"40", "6", "48", "49", "40", "42", "32", "48", "6", "43", "16",
"32", "20", "32", "5", "40", "6", "49", "40", "48", "40", "50",
"43", "32", "32", "19", "32", "32", "19", "40", "32", "6", "32",
"49", "32", "32", "32", "32", "40", "42", "49", "40", "32", "32",
"40", "40", "32", "43", "55", "32", "49", "32", "42", "48", "40",
"24", "55", "55", "48", "32", "49", "55", "40", "49", "40", "42",
"48", "42", "55", "55", "50", "40", "48", "32", "55", "40", "42",
"NA", "65", "NA", "50", "60", "40", "47", "65", "42", "32", "32",
"42", "40", "42", "32", "60", "55", "43", "40", "42", "49", "50",
"50", "48", "65", "48", "32", "40", "55", "65", "32", "55", "48",
"49", "32", "40", "43"), rangos = c("S/.1500 - S/.2500", "S/.500 -
S/.1500",
"S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
"S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.3500 - S/.4500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "> S/.4,500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
S/.1500",
"S/.1500 - S/.2500", "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500",
"> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.3500 - S/.4500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
S/.1500",
"S/.3500 - S/.4500", "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.1500 - S/.2500", "< S/.500", "S/.1500 - S/.2500",
"< S/.500", "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
S/.2500",
"S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.2500 - S/.3500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500",
"< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
S/.1500",
"S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.1500 - S/.2500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
S/.2500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
"S/.500 - S/.1500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.3500 - S/.4500", "S/.2500 - S/.3500",
"S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
"S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.2500 - S/.3500",
"S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
"> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
"> S/.4,500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", "> S/.4,500",
"S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500", "S/.1500 - S/.2500",
"S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
"S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.1500 - S/.2500",
"S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
"S/.2500 - S/.3500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
"> S/.4,500", "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
"> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
"S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
"S/.500 - S/.1500", "S/.500 - S/.1500")), .Names = c("id", "marca",
"producto", "precio.antes", "precio.nuevo", "dif.precios",
"dif.porcentual",
"pulgadas", "rangos"), class = "data.frame", row.names = c(NA,
-164L))








2015-10-10 11:55 GMT-05:00 Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com>
:

> Thank you very much to both of you. This information is very enlightening
> to me.
>
> Cheers.
>
>
> 2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:
>
>> David answered most of this. Just a two short notes inline.
>>
>>
>>
>>
>> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <
>> oma.gonzales at gmail.com> wrote:
>>
>> > David, Boris, so thankfull for your help. Both approaches are very
>> good. I got this solve with David's help.
>> >
>> > I find very insteresting Bori's for loop. And I need a little help
>> understanding the regex part on it.
>> >
>> > - The strsplit function: strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")
>> >
>> > I understand for this: split every row by a sequence of any number or
>> letter or "-" that appears at leat once (+ operator).
>> >
>> > 1.- What does mena the "^" symbol? If you remove it, just appeare
>> blanks.
>> > 2.- Why is there the necessity of "+" after the closing "]"?
>> >
>> > 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>> >      Identifies also the IDs where "-" is present. Here the regex does
>> not have the "-" included.
>>
>> Yes. I am not matching the entire token here. Note there is no "+": The
>> two character-class expressions match exactly one uppercase character
>> adjacent to exactly one number. If this is found in a token, grep returns
>> TRUE. It doesn't matter what else the token contains - the first regex
>> already took care of removing everything that's not needed. The vector of
>> FALSEs and a single TRUE that grep() returns goes inside the square
>> brackets, and selects the token from v.
>>
>>
>>
>> > Also, I notice that David used the "-" at the begining of the matching:
>> [-A-Z0-9], without the "^" (stars with) at the beginning.
>>
>> This can be very confusing about regular expressions: the same character
>> can mean different things depending on where it is found. Between two
>> characters in a character class expresssion, the hyphen means "range".
>> Elsewhere it is a literal hyphen. David put his at the beginning, I had it
>> at the end (in the first regex). Another tricky character is "?" which can
>> mean 0,1 matches, or turn "greedy" matching off...
>>
>> Online regex testers are invaluable to develop a regex - one I frequently
>> use is regexpal.com
>>
>> Cheers,
>> B.
>>
>>
>> >
>> > I would appreciate a response from you, gentlemen.
>> >
>> > Thanks again.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>> >
>> > On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
>> >
>> > > I think you are going into the wrong direction here and this is a
>> classical example of what we mean by "technical debt" of code. Rather than
>> tell to your regular expression what you are looking for, you are handling
>> special cases with redundant code. This is ugly, brittle and impossible to
>> maintain.
>> > >
>> > > Respect to you that you have recognized this.
>> > >
>> > >
>> > > The solution is rather simple:
>> > >
>> > > A) Isolate tokens. Your IDs contain only a limited set of characters.
>> Split your strings along the characters that are not found in IDs to
>> isolate candidate tokens, place them into a vector.
>> > >
>> > > B) Evaluate your tokens: as far as I can see IDs all contain letters
>> AND numbers. This is a unique characteristic. Thus it is sufficient to grep
>> for a letter/number pair in a token to identify it as an ID.
>> > >
>> > > Should you ever find a need to accommodate differently formed IDs,
>> there are only two, well defined places with clearly delegated roles where
>> changes might be needed.
>> > >
>> > > Here is the code:
>> > >
>> > > for (i in 1:nrow(ripley.tv)) {
>> > >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) #
>> isolate tokens
>> > >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs
>> and store
>> > > }
>> >
>> > That logic actually simplifies the regex strategy as well:
>> >
>> >  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>> >  ripley.tv$producto,
>> >  ignore.case = T)
>> >
>> >
>> > Almost succeeds, with a few all-character words, but if you require one
>> number in the middle you get full results:
>> >
>> >  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>> >  ripley.tv$producto,
>> >  ignore.case = T)
>> >
>> >  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"
>>  "LE40K5000N"
>> >  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"
>> > [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"
>> > [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"
>> > [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"
>> > [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"
>> > [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"
>> > [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
>> > [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
>> > [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
>> > [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"
>> > [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"
>> > [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"
>> > [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C"
>> "XBR-75X945C"
>> > [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
>> > [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
>> > [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"
>> > [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"
>>  "XBR-79X905B"
>> > [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"
>>  "TC-42AS650L"
>> > [96] "LC70LE660"   "LE58D3140"
>> >
>> > >
>> > >
>> > >
>> > > Cheers,
>> > > Boris
>> > >
>> > >
>> > >
>> > > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
>> oma.gonzales at gmail.com> wrote:
>> > >
>> > >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA,
>> NA,
>> > >>> NA, NA,
>> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> > >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
>> > >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
>> > >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>> > >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>> > >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
>> > >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
>> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
>> "SAMSUNG",
>> > >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC",
>> "PANASONIC",
>> > >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
>> > >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
>> > >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG",
>> "PANASONIC",
>> > >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
>> > >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\"
>> 3D
>> > >>>>> 48J6400",
>> > >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40''
>> TC-40CS600L",
>> > >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
>> > >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED
>> FHD
>> > >>> 55\" -
>> > >>>>> LE55B8000",
>> > >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" -
>> NEGRO",
>> > >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
>> > >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48''
>> 48JU6500",
>> > >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55''
>> 3D
>> > >>>>> 55JS9000",
>> > >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55''
>> 55JU6700",
>> > >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV
>> ULTRA HD
>> > >>> 65''
>> > >>>>> 3D 65JS9000",
>> > >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65''
>> 65JU7500",
>> > >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
>> > >>> 40LF6350",
>> > >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA
>> 3D
>> > >>>>> 42LF6450",
>> > >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\"
>> FULL HD
>> > >>>>> 3D",
>> > >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
>> > >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\"
>> ULTRA HD
>> > >>> 4K",
>> > >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D
>> SMART
>> > >>> TV
>> > >>>>> 55UF7700",
>> > >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\"
>> ULTRA HD
>> > >>> 4K
>> > >>>>> 3D",
>> > >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA
>> HD 4K
>> > >>> SMART
>> > >>>>> TC-50CX640W",
>> > >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD
>> 4K
>> > >>> CINEMA
>> > >>>>> SMART UG8700",
>> > >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\"
>> FULL HD
>> > >>> 3D",
>> > >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
>> > >>> KDL-40R354B",
>> > >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
>> > >>> 50J5500",
>> > >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
>> > >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
>> > >>> 40J6400",
>> > >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
>> > >>> KDL-40R555C
>> > >>>>> - NEGRO",
>> > >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" -
>> NEGRO",
>> > >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" -
>> BLANCO",
>> > >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
>> > >>>>> KDL-65W855C",
>> > >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD
>> LE40F1551",
>> > >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
>> > >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
>> > >>>>> LE32W454F",
>> > >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART
>> 3D
>> > >>>>> KDL-55W805C",
>> > >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
>> > >>>>> XBR-55X855C",
>> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
>> > >>> ULTRA HD
>> > >>>>> 4K 3D XBR-75X945C",
>> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV
>> LED 60''
>> > >>>>> ULTRA HD 4K LC60UE30U",
>> > >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80''
>> ULTRA HD
>> > >>> 4K
>> > >>>>> LC80UE30U",
>> > >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
>> > >>> ULTRA HD
>> > >>>>> 4K 3D",
>> > >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\"
>> ULTRA
>> > >>> HD
>> > >>>>> 4K 3D",
>> > >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
>> > >>> 32J4300",
>> > >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV
>> 55UG8700
>> > >>> 55\"
>> > >>>>> ULTRA HD 4K 3D",
>> > >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\"
>> FULL
>> > >>> HD
>> > >>>>> 3D",
>> > >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED
>> FULL HD
>> > >>> 50''
>> > >>>>> TC-50AS600L",
>> > >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K
>> LC70SQ17U
>> > >>> 70''",
>> > >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
>> TC-40A400L",
>> > >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
>> > >>> 55HU8700",
>> > >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
>> TC-42AS650L",
>> > >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
>> > >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
>> > >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
>> > >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
>> > >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
>> > >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
>> > >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
>> > >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
>> > >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
>> > >>> c(2799L,
>> > >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
>> > >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
>> > >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
>> > >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
>> > >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
>> > >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
>> > >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
>> > >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
>> > >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
>> > >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
>> > >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
>> > >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
>> > >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
>> > >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
>> > >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
>> > >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
>> > >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
>> > >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
>> > >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
>> > >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
>> > >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
>> > >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
>> > >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
>> > >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
>> > >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
>> > >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
>> > >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
>> > >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
>> > >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
>> > >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
>> > >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
>> > >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
>> > >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
>> > >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
>> > >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
>> > >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
>> > >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
>> > >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
>> > >>> S/.2500",
>> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> "S/.500 -
>> > >>>>> S/.1500",
>> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> > >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
>> > >>> S/.2500",
>> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", ">
>> S/.4,500",
>> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
>> > >>> S/.1500",
>> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
>> > >>> S/.2500",
>> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 -
>> S/.4500",
>> > >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 -
>> S/.4500",
>> > >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
>> > >>> S/.1500",
>> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", ">
>> S/.4,500",
>> > >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", ">
>> S/.4,500",
>> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", ">
>> S/.4,500",
>> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>> > >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", ">
>> S/.4,500",
>> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
>> > >>> S/.2500",
>> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 -
>> S/.1500",
>> > >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
>> > >>> c("id",
>> > >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
>> > >>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
>> > >>> row.names
>> > >>>>> = c(NA,
>> > >>>>> -97L))
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> >
>>
>>
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Sun Oct 11 07:39:43 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Sun, 11 Oct 2015 06:39:43 +0100
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
	<CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
	<CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
Message-ID: <CALJKBv_isbZarbg5Tdi085XTbmTkTjm9j7szWAALo8_cEY1eiQ@mail.gmail.com>

Hi,
omit unlist and test. otherwise  you can use apply function.

draft:

df1 <- apply(linio.tv, 1, function(x) strsplit(x[,idproductio],
"[^A-Z0-9-]+"))

fct <- function(linio.tv){

        if(any(grep("[A-Z][0-9]", linio.tv[,idx_productio]))) {

                linio.tv[,idx(id)] <- linio.tv[,idx_productio]

        }

        else {
                linio.tv[,idx(id)]<- NA
        }
}

df2 <- apply(df1, 1, function(x) fct(x))

I can't test this draft because I have not linio.tv


Karim


for (i in 1:nrow(linio.tv)) {

        v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
isolate tokens

        if(any(grep("[A-Z][0-9]", v))) {

                linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]

        }

        else {
                linio.tv$id[i] <- NA
        }
}

On Sun, Oct 11, 2015 at 6:07 AM, Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> Hi  Boris,
>
> I've modified a little the for loop to catch the IDs (if there is any)
> otherwise to put NAs. This is for another data set.
>
>
>
> for (i in 1:nrow(linio.tv)) {
>
>         v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
> isolate tokens
>
>         if(any(grep("[A-Z][0-9]", v))) {
>
>                 linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>
>         }
>
>         else {
>                 linio.tv$id[i] <- NA
>         }
> }
>
>
> I get this warning messages, nevertheless the IDs column get the correct
> values:
>
> Warning messages:
> 1: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>   number of items to replace is not a multiple of replacement length
> 2: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>   number of items to replace is not a multiple of replacement length
>
>
> The problem:
>
> There are entries where the grep part is not specific enough.
>
> Like this one: "UN50JU6500-NEGRO". It satifies the rule in:
>
> linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  , but is not supposed to take
> also: "UN50JU6500-NEGRO" entirely, only this part: "UN50JU6500".
>
>
> I've noticed this rule: the IDs can have at maxium 1 letter after the "-".
> If it contains more than 1, that part should not be considered.
>
> "TC-L42AS610"
>
> Also IDs can start with numbers: 1,2, or 3.
>
> "KDL-40R354B"
>
>
>
>
> May you clarify to me if it's something that can be done within R?  I'm
> trying to figure this out, but with any good result.
>
> I could cleaned with "sub()" (there is only one entry giving me troubles)
> but the idea is not to have "technical debt" for the future.
>
>
>
>
> This is the new data set, I'm talking about:
>
>
>
>
>
>
> linio.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), marca = c("LG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> "SAMSUNG", "LG", "LG", "SAMSUNG", "LG", "LG", "LG", "LG", "SAMSUNG",
> "LG", "LG", "LG", "SONY", "SAMSUNG", "LG", "LG", "SAMSUNG", "SONY",
> "SAMSUNG", "LG", "LG", "LG", "IMACO", "SAMSUNG", "LG", "SAMSUNG",
> "SAMSUNG", "LG", "HAIER", "LG", "SONY", "SAMSUNG", "LG", "LG",
> "LG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "HISENSE", "LG",
> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "CONTINENTAL",
> "LG", "IMACO", "AOC", "AOC", "SAMSUNG", "LG", "SONY", "LG", "LG",
> "SONY", "SAMSUNG", "SAMSUNG", "PANASONIC", "LG", "SAMSUNG", "NEX",
> "IMACO", "LG", "LG", "CONTINENTAL", "SONY", "LG", "LG", "SAMSUNG",
> "LG", "LG", "LG", "LG", "LG", "SAMSUNG", "LG", "LG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "AOC", "LG", "LG",
> "AOC", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "LG", "LG",
> "SAMSUNG", "SAMSUNG", "SONY", "LG", "SAMSUNG", "SAMSUNG", "LG",
> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "PANASONIC", "PANASONIC",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY",
> "LG", "LG", "PANASONIC", "AOC", "SAMSUNG", "LG", "SAMSUNG", "LG",
> "SAMSUNG", "LG", "LG", "LG", "PANASONIC", "PANASONIC", "LG",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "SAMSUNG",
> "LG", "LG", "SAMSUNG", "LG"), producto = c("COMBO SMART - LG TV LED 4K
> ULTRA HD 43'' - 43UF6750 + GOO...",
> "SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", "SAMSUNG TV LED 3D SMART
> FULL HD 48'' - 48J6400",
> "SAMSUNG TV LED 3D SMART FULL HD 55'' - 55J6400", "LG TV SMART LED HD 32\"
> 32LF585B - BLANCO",
> "LG TV SLIM ULTRA HD 3D WEBOS 2.0 49'' 49UF8500 - PLATEADO",
> "LG TV SMART WEBOS 2.0 FULL HD 43\" 43LF5900 -NEGRO", "LG TV LED HD 32\" -
> 32LF550B",
> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "LG TV  LED SMART HD 32\"
> - 32LF585B",
> "LG GAME TV LED FULL HD 49\" - 49LF5410", "SAMSUNG TV LED  FULL HD 60'' -
> UN60FH6003",
> "LG TV SMART WEBOS 2.0 FULL HD 49\" - 49LF6350", "LG TV LED  FULL HD 43'' -
> 43LF5410",
> "SAMSUNG TV SMART FULL HD CURVO 40'' TIZEN -  UN40J6500", "LG TV SMART
> WEBOS 2.0 ULTRA HD  4K 43\" - 43UF6400",
> "LG TV SLIM LED CINEMA 3D FULL HD 42'' 42LB6200 INCLUYE 02...",
> "LG GAMETV  LED FULL HD 43\" - 43LF5400", "LG GAME TV LED FULL HD 49\" -
> 49LF5410",
> "TELEVISOR SAMSUNG UN40J5500 SMART TV LED FULL HD 40''-PLA...",
> "LG SMART  4K ULTRA HD 55\" - 55UB8200", "LG -TV LED SMART WEBOS 2.0 FULL
> HD 55\" - 55LF6350",
> "LG - GAME TV LED  FULL HD 43'' - 43LF5410", "SONY - TV LED SMART HD 32'' -
> 32R505C",
> "SAMSUNG TV LED 3D SMART FULL HD 40'' - UN40H6400", "LG SMART TV 32\" HD
> WEBOS 2.0  32LF595B",
> "LG - TV LED WEBOS 3D SMART ULTRA HD CURVO  55'' 55UG8700 ...",
> "SAMSUNG TV LED FULL HD 40\" UN40JH5005 - NEGRO", "SONY TV LED FULL HD 40''
> - KDL-40R354B",
> "SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
> "LG TV LED FULL HD 42'' ULTRA SLIM 42LY340C - NEGRO", "LG TV SMART LED FULL
> HD 43\" - 43LF6350",
> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
> "IMACO - TV LED HD 24?? - LED24HD", "TELEVISOR SAMSUNG UN32J4300 SMART TV
> LED HD 32''-NEGRO",
> "LG TV 3D SMART LED ULTRA HD 65\" - 65UF8500", "SAMSUNG - TV LED SMART 3D
> 65\" FULL HD SERIE 8 INTERACTIVO...",
> "SAMSUNG - TV LED HD 32\"  32JH4005 - NEGRO", "LG TV 55\" SMART ULTRA HD 4K
> CINEMA 3D  55UB8500",
> "HAIER TV LED HD LIVE GREEN 24'' - 24B8000", "LG TV LED FULL HD 47'' -
> 47LB5610",
> "SONY TV LED FULL HD 32'' - KDL-32R304B", "SAMSUNG TV LED SERIE 5 FULL HD
> 39? - 39FH5005",
> "LG - TV SAMT SLIM ULTRA HD 4K WEBOS 2.0 55'' 55UF7700 - P...",
> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
> "LG TV MONITOR LED HD 23.6? - 24MT47A", "SAMSUNG - MONITOR LED 32\" MD32C -
> NEGRO",
> "TELEVISOR SAMSUNG UN40J6400 SMART TV LED 3D FULL HD 40''-...",
> "SAMSUNG LED SMART FULL HD 48'' - UN48J6500", "SONY - TV LED SMART FULL HD
> 40'' - 40R555C",
> "TELEVISOR HISENSE LED 40\" 40K221W SMART TV LED FULL HD", "LG TV MONITOR
> LED HD 23.6? - 24MT47A",
> "TELEVISOR SAMSUNG UN48J6400 SMART TV LED 3D FULL HD 48''-...",
> "LG 49UB8500 LED 49\" SMART 3D 4K", "SAMSUNG TV LED 3D SMART FULL HD 40''
> TIZEN UN40J6400 - NEGRO",
> "LG TV LED FULL HD 42\" - 42LY340C", "SAMSUNG TV LED HD 32'' UN32J4000 -
> NEGRO",
> "TELEVISOR SAMSUNG UN48J5500 SMART TV LED FULL HD 48''-PLA...",
> "CONTINENTAL - TV LED 15.6\" CELED95935, INCLUYE RACK", "LG TV LED 4K ULTRA
> HD 43\" - 43UF6750",
> "IMACO - TV LED HD 16?? - LED16HD", "AOC - TELEVISOR HD 32\" LE32W454F-
> NEGRO",
> "AOC TV LED HD 20\" - LE20A1140", "SAMSUNG TV LED HD 32'' - UN32J4000",
> "LG - TV MONITOR 27.5? - 28MT47B", "SONY TV LED FULL HD 40'' -
> KDL-40R354B",
> "LG TV MONITOR LED HD 23.6? - 24MT47A", "LG GAME TV LED FULL HD 49\" -
> 49LF5410",
> "SONY TV LED FULL HD 40'' - KDL-40R354B", "SAMSUNG - UN48J6400 LED FULL HD
> 48\"SMART TIZEN 3D 2015 - ...",
> "SAMSUNG - MONITOR FULL HD 40\" MD40C - NEGRO", "PANASONIC LED SMART FULL
> HD 50\" - TC-50AS600",
> "LG - 43LF5410 LED 43\" FULL HD GAME  - SILVER", "SAMSUNG - TELEVISOR LED
> HD 32\" UN32JH4005 - NEGRO",
> "NEX TV LED SMART HD 32\" USB WIFI INCORPORADO - LED3208SMR",
> "IMACO - TV LED HD 19?? - LED19HD", "LG -TV LED HG 32\" - 32LF550B",
> "LG - TELEVISOR LED 32\" HD 32LF550B", "CONTINENTAL - TV LED 19\"
> CELED99935,  INCLUYE RACK",
> "SONY TV LED FULL HD 40'' - KDL-40R354B", "LG - TELEVISOR LED 32\" HD SMART
> TV 32LF585B - BLANCO",
> "MONITOR TV LG 24MT47A LED HD 23.6?-PLATEADO", "TELEVISOR SAMSUNG UN32J4300
> SMART TV LED HD 32''-NEGRO",
> "LG GAME TV LED FULL HD 49\" - 49LF5400", "LG - TELEVISOR LED 32\" HD SMART
> TV 32LF585B ? BLANCO",
> "LG - TELEVISOR LED 32\" HD 32LF550B", "LG TV LED HD 32'' - 32LF550B",
> "LG TV LED SMART HD 32'' - 32LF585B", "SAMSUNG - TELEVISOR LED FULL HD 40\"
> UN40JH5005 ? NEGRO",
> "LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", "LG TV LED WEBOS 3D
> SMART ULTRA HD 49'' - 49UF8500",
> "SAMSUNG - TV LED SMART FULL HD 40? UN40H5500 - NEGRO", "SAMSUNG TV LED
> SMART HD 32'' UN32J4300 - NEGRO",
> "SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", "SAMSUNG -
> TELEVISOR LED FULL HD 40\" UN40JH5005 - NEGRO",
> "SAMSUNG TV LED SMART TIZEN 3D QUADCORE40\" - UN40J6400", "AOC TV LED HD
> 32\" - LE32W454F +RACK FIJO",
> "LG TV LED FULL HD 43'' - 43LF5410", "LG - TV LED WEBOS 3D SMART FULL HD
> 55'' - 55LF6500",
> "AOC 32\" LE32W454F  HD DIGITAL LED TV + HOME THEATRE F1200U",
> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED ALTA
> DEFINICI?N DTV USB 32\" - 32JH4005",
> "LG - 42LF6400 LED FULL HD 42'' SMART WEBOS 3D - SILVER", "TELEVISOR
> SAMSUNG UN48J5300 SMART TV LED FULL HD 48''-NEGRO",
> "SAMSUNG UN40JH5005 LED FULL HD 40\"  - NEGRO GLOSS", "LG - 24MT47A +
> MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...",
> "LG TV LED SMART 4K ULTRA HD 55\" - 55UB8200", "SAMSUNG - 55J6400 LED 55\"
> SMART TIZEN 3D - BLACK",
> "SAMSUNG TV CURVED SMART ULTRA HD 48'' TIZEN UN48JU6700 - ...",
> "TELEVISI?N SONY KDL-32R505C LED 32\"-NEGRO", "LG TV LED CINEMA 3D 4K SMART
> ULTRA HD 49'' + 02 LENTES 3D...",
> "SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", "SAMSUNG - 40J5500 LED
> 40\" SMART QUADCORE / BLUETOOTH* - S...",
> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED SMART
> FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
> "LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 ? PLAT...",
> "TELEVISI?N SAMSUNG UN48J5500 LED SMART TV 48\"-PLATEADO", "LG - TELEVISOR
> LED 42\" FULL HD SMART TV 42LF5850 - PLATEADO",
> "TELEVISOR SAMSUNG  UN55JU6700 LED UHD 4K SMART 55'' - PLA...",
> "LG - TV LED WEBOS 3D SMART SUPER ULTRA HD 55'' - 55UF9500",
> "TELEVISOR SAMSUNG UN50JU6500  UHD 4K SMART 50'' - PLATEADO",
> "SAMSUNG - TELEVISOR LED HD 40\" SMART UN40J5500 - NEGRO", "TELEVISOR
> SAMSUNG UN48J6500 CURVO  FULL HD SMART 48'' - P...",
> "SAMSUNG - TELEVISOR LED HD 32\" SMART UN32J4300 - NEGRO", "LG TV LED
> CINEMA 3D 4K SMART ULTRA HD 55'' 55UB8500 - NEGRO",
> "TELEVISI?N PANASONIC TC-L40SV7L LED FULL-HD 40''-NEGRO", "PANASONIC TV LED
> 42?? FULL HD TC-L42E6L - NEGRO.",
> "TELEVISOR SAMSUNG UN 40JH5005 LED FULL HD", "SAMSUNG - TV LED SMART CURVO
> 3D ULTRA HD 65? UN65HU9000...",
> "SAMSUNG - UN48J5300 LED FULL HD SMART 2015 - BLACK", "SAMSUNG TV LED SMART
> FULL HD 50'' TIZEN UN50J5500 - PLATEADO",
> "SAMSUNG - TV SMART 3D FULL HD 60? UN60H7100 - NEGRO", "SONY - TELEVISOR
> LED SMART TV FULL HD 40'' KDL-40R555C - ...",
> "LG TV 47\" LED FULL HD - 47LY340C", "LG TV UHD 4K 65UB9800 SMART 3D LED TV
> C/WEBOS 65' LENTES 3D",
> "PANASONIC - TELEVISOR TC-L42AS610 LED SMART FULL HD 42?...",
> "AOC - TELEVISOR LED 32\" - LE32W454F", "SAMSUNG TV LED 32? - UN32FH4005G",
> "LG TV SMART LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED 3D SMART FULL HD
> 40'' TIZEN UN40J6400 - NEGRO",
> "LG TV SMART  LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED HD 32''
> UN32JH4005 - NEGRO",
> "LG TV PLASMA 2014 60\" FULL HD 1080P - 60PB5600", "LG TV LED CINEMA 3D
> SMART FULL HD 55'' 55LB7050 - PLATEADO",
> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "PANASONIC PUERTO USB LED
> 40\" - TC-L40SV7L",
> "PANASONIC LED SMART FULL HD 42\" - TC-L42AS610", "LG TV SMART  LED FULL HD
> 49\" - 49LF6350",
> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500-NEGRO",
> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500 - NEGRO",
> "SAMSUNG TV SMART FULL HD CURVO 48'' TIZEN UN48J6500", "SAMSUNG TV  SMART
> ULTRA HD 4K  65'' - UN65JU6500",
> "SAMSUNG UN48J5500 LED 48\" - PLATEADO", "SAMSUNG LED 32\" CONEXI?N WIFI -
> UN32J4300",
> "SAMSUNG LED SMART 40'' CONEXI?N WI-FI DIRECT - UN40J5500", "SAMSUNG LED
> SMART ULTRA HD 55\" - TVUN55JU6700",
> "SAMSUNG TV CURVED 3D SMART ULTRA HD 65'' TIZEN UN65JU7500...",
> "SAMSUNG TELEVISOR  HG32NB460GF, 32\" LED, HD, 1366 X 768", "LG -TV SMART
> LED FULL HD 55\" - 55LF6350",
> "SAMSUNG TV LED SMART 3D 48\" - UN48H6400", "LG LED ULTRAHD 4K 49\" SMART
> 3D - 49UB8300",
> "LG - TV LED SMART HD 32'' 32LF585B - PLATEADO", "SAMSUNG - TV LED FULL HD
> 40\" UN40JH5005  - NEGRO GLOSS",
> "LG - TV LED FULL HD 43'' 43LF5410 - PLATEADO"), precio.antes = c(2599L,
> 1299L, 2899L, 3999L, 1199L, 4499L, 1999L, 1099L, 2299L, 1299L,
> 2499L, 3999L, 2199L, 1899L, 2299L, 2299L, 1799L, 1499L, 2299L,
> 1999L, 3999L, 3499L, 1549L, 1299L, 2299L, 2299L, 6999L, 1499L,
> 1499L, 1899L, 1499L, 2099L, 6999L, 599L, 1299L, 9999L, 8999L,
> 999L, 5999L, 599L, 2299L, 1299L, 1499L, 4999L, 6999L, 899L, 2299L,
> 2499L, 3299L, 1799L, 1399L, 899L, 2499L, 4199L, 2299L, 1499L,
> 1099L, 2499L, 399L, 2499L, 399L, 999L, 599L, 999L, 899L, 1499L,
> 699L, 2299L, 1399L, 2499L, 2999L, 2499L, 1599L, 1149L, 999L,
> 499L, 1089L, 1099L, 499L, 1499L, 1399L, 799L, 1299L, 2499L, 1399L,
> 1259L, 1299L, 1299L, 1599L, 1999L, 3999L, 1999L, 1199L, 999L,
> 1599L, 2299L, 999L, 1499L, 3699L, 1199L, 3899L, 1099L, 2299L,
> 2499L, 1399L, 729L, 4199L, 3599L, 4999L, 1399L, 3999L, 4999L,
> 2199L, 4499L, 2299L, 1699L, 2779L, 1699L, 5799L, 8999L, 3699L,
> 2099L, 3299L, 1299L, 5900L, 1799L, 1799L, 1399L, 14999L, 2499L,
> 2799L, 6299L, 1799L, 2417L, 9500L, 1799L, 799L, 999L, 1999L,
> 2499L, 1899L, 999L, 2299L, 3699L, 2199L, 1699L, 1999L, 2499L,
> 3499L, 3899L, 2999L, 7999L, 2299L, 1299L, 2099L, 5799L, 9999L,
> 1110L, 3399L, 2799L, 3899L, 1299L, 1399L, 1499L), precio.nuevo = c(1799L,
> 999L, 2299L, 3299L, 999L, 3199L, 1499L, 849L, 1399L, 979L, 1795L,
> 2999L, 1899L, 1299L, 1699L, 1599L, 1499L, 1299L, 1699L, 1449L,
> 3699L, 2499L, 1199L, 999L, 1499L, 899L, 4999L, 1199L, 1199L,
> 1389L, 1299L, 1699L, 4899L, 549L, 999L, 7499L, 6700L, 849L, 4299L,
> 549L, 1499L, 899L, 1299L, 3599L, 5354L, 538L, 1959L, 1599L, 2999L,
> 1367L, 1099L, 589L, 2449L, 3199L, 1529L, 1229L, 839L, 1779L,
> 329L, 1799L, 389L, 719L, 489L, 849L, 799L, 1185L, 599L, 1609L,
> 1299L, 2179L, 2839L, 1999L, 1599L, 899L, 799L, 449L, 880L, 899L,
> 429L, 1275L, 1199L, 589L, 999L, 1749L, 1199L, 1099L, 899L, 989L,
> 1399L, 1999L, 2999L, 1599L, 999L, 819L, 1299L, 2299L, 789L, 1299L,
> 3199L, 977L, 3089L, 849L, 1719L, 1799L, 1399L, 569L, 3979L, 3299L,
> 3369L, 1093L, 3389L, 3289L, 1419L, 3429L, 1405L, 1499L, 1899L,
> 1499L, 5199L, 6999L, 3199L, 1599L, 2999L, 1099L, 5089L, 1459L,
> 1499L, 1289L, 12999L, 1739L, 2255L, 5879L, 1499L, 1929L, 8499L,
> 1649L, 799L, 899L, 1659L, 1749L, 1609L, 831L, 2089L, 3659L, 1769L,
> 1499L, 1599L, 2176L, 2749L, 2889L, 2899L, 5599L, 1899L, 1099L,
> 1899L, 5199L, 8589L, 990L, 3169L, 2199L, 3899L, 949L, 1099L,
> 1199L), dif.precios = c(800L, 300L, 600L, 700L, 200L, 1300L,
> 500L, 250L, 900L, 320L, 704L, 1000L, 300L, 600L, 600L, 700L,
> 300L, 200L, 600L, 550L, 300L, 1000L, 350L, 300L, 800L, 1400L,
> 2000L, 300L, 300L, 510L, 200L, 400L, 2100L, 50L, 300L, 2500L,
> 2299L, 150L, 1700L, 50L, 800L, 400L, 200L, 1400L, 1645L, 361L,
> 340L, 900L, 300L, 432L, 300L, 310L, 50L, 1000L, 770L, 270L, 260L,
> 720L, 70L, 700L, 10L, 280L, 110L, 150L, 100L, 314L, 100L, 690L,
> 100L, 320L, 160L, 500L, 0L, 250L, 200L, 50L, 209L, 200L, 70L,
> 224L, 200L, 210L, 300L, 750L, 200L, 160L, 400L, 310L, 200L, 0L,
> 1000L, 400L, 200L, 180L, 300L, 0L, 210L, 200L, 500L, 222L, 810L,
> 250L, 580L, 700L, 0L, 160L, 220L, 300L, 1630L, 306L, 610L, 1710L,
> 780L, 1070L, 894L, 200L, 880L, 200L, 600L, 2000L, 500L, 500L,
> 300L, 200L, 811L, 340L, 300L, 110L, 2000L, 760L, 544L, 420L,
> 300L, 488L, 1001L, 150L, 0L, 100L, 340L, 750L, 290L, 168L, 210L,
> 40L, 430L, 200L, 400L, 323L, 750L, 1010L, 100L, 2400L, 400L,
> 200L, 200L, 600L, 1410L, 120L, 230L, 600L, 0L, 350L, 300L, 300L
> ), dif.porcentual = c(30.78, 23.09, 20.7, 17.5, 16.68, 28.9,
> 25.01, 22.75, 39.15, 24.63, 28.17, 25.01, 13.64, 31.6, 26.1,
> 30.45, 16.68, 13.34, 26.1, 27.51, 7.5, 28.58, 22.6, 23.09, 34.8,
> 60.9, 28.58, 20.01, 20.01, 26.86, 13.34, 19.06, 30, 8.35, 23.09,
> 25, 25.55, 15.02, 28.34, 8.35, 34.8, 30.79, 13.34, 28.01, 23.5,
> 40.16, 14.79, 36.01, 9.09, 24.01, 21.44, 34.48, 2, 23.82, 33.49,
> 18.01, 23.66, 28.81, 17.54, 28.01, 2.51, 28.03, 18.36, 15.02,
> 11.12, 20.95, 14.31, 30.01, 7.15, 12.81, 5.34, 20.01, 0, 21.76,
> 20.02, 10.02, 19.19, 18.2, 14.03, 14.94, 14.3, 26.28, 23.09,
> 30.01, 14.3, 12.71, 30.79, 23.86, 12.51, 0, 25.01, 20.01, 16.68,
> 18.02, 18.76, 0, 21.02, 13.34, 13.52, 18.52, 20.77, 22.75, 25.23,
> 28.01, 0, 21.95, 5.24, 8.34, 32.61, 21.87, 15.25, 34.21, 35.47,
> 23.78, 38.89, 11.77, 31.67, 11.77, 10.35, 22.22, 13.52, 23.82,
> 9.09, 15.4, 13.75, 18.9, 16.68, 7.86, 13.33, 30.41, 19.44, 6.67,
> 16.68, 20.19, 10.54, 8.34, 0, 10.01, 17.01, 30.01, 15.27, 16.82,
> 9.13, 1.08, 19.55, 11.77, 20.01, 12.93, 21.43, 25.9, 3.33, 30,
> 17.4, 15.4, 9.53, 10.35, 14.1, 10.81, 6.77, 21.44, 0, 26.94,
> 21.44, 20.01), pulgadas = c("43", "32", "48", "55", "32", "49",
> "43", "32", "43", "32", "49", "60", "49", "43", "40", "43", "42",
> "43", "49", "40", "55", "55", "43", "32", "40", "32", "55", "40",
> "40", "40", "42", "43", "55", "24", "32", "65", "65", "32", "55",
> "24", "47", "32", "39", "55", "55", "6", "32", "40", "48", "40",
> "40", "6", "48", "49", "40", "42", "32", "48", "6", "43", "16",
> "32", "20", "32", "5", "40", "6", "49", "40", "48", "40", "50",
> "43", "32", "32", "19", "32", "32", "19", "40", "32", "6", "32",
> "49", "32", "32", "32", "32", "40", "42", "49", "40", "32", "32",
> "40", "40", "32", "43", "55", "32", "49", "32", "42", "48", "40",
> "24", "55", "55", "48", "32", "49", "55", "40", "49", "40", "42",
> "48", "42", "55", "55", "50", "40", "48", "32", "55", "40", "42",
> "NA", "65", "NA", "50", "60", "40", "47", "65", "42", "32", "32",
> "42", "40", "42", "32", "60", "55", "43", "40", "42", "49", "50",
> "50", "48", "65", "48", "32", "40", "55", "65", "32", "55", "48",
> "49", "32", "40", "43"), rangos = c("S/.1500 - S/.2500", "S/.500 -
> S/.1500",
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.3500 - S/.4500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "> S/.4,500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> S/.1500",
> "S/.1500 - S/.2500", "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.3500 - S/.4500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> S/.1500",
> "S/.3500 - S/.4500", "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "< S/.500", "S/.1500 - S/.2500",
> "< S/.500", "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
> S/.2500",
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.2500 - S/.3500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> S/.1500",
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.1500 - S/.2500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
> S/.2500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
> "S/.500 - S/.1500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.3500 - S/.4500", "S/.2500 - S/.3500",
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.2500 - S/.3500",
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> "> S/.4,500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", "> S/.4,500",
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500", "S/.1500 - S/.2500",
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.1500 - S/.2500",
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> "S/.2500 - S/.3500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> "> S/.4,500", "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
> "S/.500 - S/.1500", "S/.500 - S/.1500")), .Names = c("id", "marca",
> "producto", "precio.antes", "precio.nuevo", "dif.precios",
> "dif.porcentual",
> "pulgadas", "rangos"), class = "data.frame", row.names = c(NA,
> -164L))
>
>
>
>
>
>
>
>
> 2015-10-10 11:55 GMT-05:00 Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com>
> :
>
> > Thank you very much to both of you. This information is very enlightening
> > to me.
> >
> > Cheers.
> >
> >
> > 2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:
> >
> >> David answered most of this. Just a two short notes inline.
> >>
> >>
> >>
> >>
> >> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <
> >> oma.gonzales at gmail.com> wrote:
> >>
> >> > David, Boris, so thankfull for your help. Both approaches are very
> >> good. I got this solve with David's help.
> >> >
> >> > I find very insteresting Bori's for loop. And I need a little help
> >> understanding the regex part on it.
> >> >
> >> > - The strsplit function: strsplit(ripley.tv$producto[i],
> "[^A-Z0-9-]+")
> >> >
> >> > I understand for this: split every row by a sequence of any number or
> >> letter or "-" that appears at leat once (+ operator).
> >> >
> >> > 1.- What does mena the "^" symbol? If you remove it, just appeare
> >> blanks.
> >> > 2.- Why is there the necessity of "+" after the closing "]"?
> >> >
> >> > 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
> >> >      Identifies also the IDs where "-" is present. Here the regex does
> >> not have the "-" included.
> >>
> >> Yes. I am not matching the entire token here. Note there is no "+": The
> >> two character-class expressions match exactly one uppercase character
> >> adjacent to exactly one number. If this is found in a token, grep
> returns
> >> TRUE. It doesn't matter what else the token contains - the first regex
> >> already took care of removing everything that's not needed. The vector
> of
> >> FALSEs and a single TRUE that grep() returns goes inside the square
> >> brackets, and selects the token from v.
> >>
> >>
> >>
> >> > Also, I notice that David used the "-" at the begining of the
> matching:
> >> [-A-Z0-9], without the "^" (stars with) at the beginning.
> >>
> >> This can be very confusing about regular expressions: the same character
> >> can mean different things depending on where it is found. Between two
> >> characters in a character class expresssion, the hyphen means "range".
> >> Elsewhere it is a literal hyphen. David put his at the beginning, I had
> it
> >> at the end (in the first regex). Another tricky character is "?" which
> can
> >> mean 0,1 matches, or turn "greedy" matching off...
> >>
> >> Online regex testers are invaluable to develop a regex - one I
> frequently
> >> use is regexpal.com
> >>
> >> Cheers,
> >> B.
> >>
> >>
> >> >
> >> > I would appreciate a response from you, gentlemen.
> >> >
> >> > Thanks again.
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> >
> >> > 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> >> >
> >> > On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
> >> >
> >> > > I think you are going into the wrong direction here and this is a
> >> classical example of what we mean by "technical debt" of code. Rather
> than
> >> tell to your regular expression what you are looking for, you are
> handling
> >> special cases with redundant code. This is ugly, brittle and impossible
> to
> >> maintain.
> >> > >
> >> > > Respect to you that you have recognized this.
> >> > >
> >> > >
> >> > > The solution is rather simple:
> >> > >
> >> > > A) Isolate tokens. Your IDs contain only a limited set of
> characters.
> >> Split your strings along the characters that are not found in IDs to
> >> isolate candidate tokens, place them into a vector.
> >> > >
> >> > > B) Evaluate your tokens: as far as I can see IDs all contain letters
> >> AND numbers. This is a unique characteristic. Thus it is sufficient to
> grep
> >> for a letter/number pair in a token to identify it as an ID.
> >> > >
> >> > > Should you ever find a need to accommodate differently formed IDs,
> >> there are only two, well defined places with clearly delegated roles
> where
> >> changes might be needed.
> >> > >
> >> > > Here is the code:
> >> > >
> >> > > for (i in 1:nrow(ripley.tv)) {
> >> > >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) #
> >> isolate tokens
> >> > >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs
> >> and store
> >> > > }
> >> >
> >> > That logic actually simplifies the regex strategy as well:
> >> >
> >> >  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
> >> >  ripley.tv$producto,
> >> >  ignore.case = T)
> >> >
> >> >
> >> > Almost succeeds, with a few all-character words, but if you require
> one
> >> number in the middle you get full results:
> >> >
> >> >  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
> >> >  ripley.tv$producto,
> >> >  ignore.case = T)
> >> >
> >> >  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"
> >>  "LE40K5000N"
> >> >  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"
>  "LE24B8000"
> >> > [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"
> "50JU6500"
> >> > [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"
> "65JS9000"
> >> > [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"
> "42LF6400"
> >> > [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"
> "49UF6750"
> >> > [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"
> "65UF7700"
> >> > [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
> >> > [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
> >> > [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
> >> > [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"
> "43LF5410"
> >> > [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"
>  "LE40F1551"
> >> > [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"
>  "58UF8300"
> >> > [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C"
> >> "XBR-75X945C"
> >> > [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
> >> > [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
> >> > [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"
> "32LF550B"
> >> > [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"
> >>  "XBR-79X905B"
> >> > [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"
> >>  "TC-42AS650L"
> >> > [96] "LC70LE660"   "LE58D3140"
> >> >
> >> > >
> >> > >
> >> > >
> >> > > Cheers,
> >> > > Boris
> >> > >
> >> > >
> >> > >
> >> > > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
> >> oma.gonzales at gmail.com> wrote:
> >> > >
> >> > >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA,
> >> NA,
> >> > >>> NA, NA,
> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> >> > >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> >> > >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> "HAIER",
> >> > >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> >> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> "SAMSUNG",
> >> > >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> >> > >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> >> > >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> >> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
> >> "SAMSUNG",
> >> > >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC",
> >> "PANASONIC",
> >> > >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY",
> "SONY",
> >> > >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> >> > >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG",
> >> "PANASONIC",
> >> > >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> >> > >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD
> 48\"
> >> 3D
> >> > >>>>> 48J6400",
> >> > >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40''
> >> TC-40CS600L",
> >> > >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> >> > >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED
> >> FHD
> >> > >>> 55\" -
> >> > >>>>> LE55B8000",
> >> > >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" -
> >> NEGRO",
> >> > >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N
> 50\"",
> >> > >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48''
> >> 48JU6500",
> >> > >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD
> 55''
> >> 3D
> >> > >>>>> 55JS9000",
> >> > >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55''
> >> 55JU6700",
> >> > >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV
> >> ULTRA HD
> >> > >>> 65''
> >> > >>>>> 3D 65JS9000",
> >> > >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65''
> >> 65JU7500",
> >> > >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> >> > >>> 40LF6350",
> >> > >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA
> >> 3D
> >> > >>>>> 42LF6450",
> >> > >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\"
> >> FULL HD
> >> > >>>>> 3D",
> >> > >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> >> > >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\"
> >> ULTRA HD
> >> > >>> 4K",
> >> > >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D
> >> SMART
> >> > >>> TV
> >> > >>>>> 55UF7700",
> >> > >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\"
> >> ULTRA HD
> >> > >>> 4K
> >> > >>>>> 3D",
> >> > >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA
> >> HD 4K
> >> > >>> SMART
> >> > >>>>> TC-50CX640W",
> >> > >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA
> HD
> >> 4K
> >> > >>> CINEMA
> >> > >>>>> SMART UG8700",
> >> > >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\"
> >> FULL HD
> >> > >>> 3D",
> >> > >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> >> > >>> KDL-40R354B",
> >> > >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> >> > >>> 50J5500",
> >> > >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> >> > >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> >> > >>> 40J6400",
> >> > >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> >> > >>> KDL-40R555C
> >> > >>>>> - NEGRO",
> >> > >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" -
> >> NEGRO",
> >> > >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" -
> >> BLANCO",
> >> > >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> >> > >>>>> KDL-65W855C",
> >> > >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD
> >> LE40F1551",
> >> > >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD
> KDL-32R304B",
> >> > >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD
> 32''
> >> > >>>>> LE32W454F",
> >> > >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD
> SMART
> >> 3D
> >> > >>>>> KDL-55W805C",
> >> > >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> >> > >>>>> XBR-55X855C",
> >> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED
> 75\"
> >> > >>> ULTRA HD
> >> > >>>>> 4K 3D XBR-75X945C",
> >> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV
> >> LED 60''
> >> > >>>>> ULTRA HD 4K LC60UE30U",
> >> > >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80''
> >> ULTRA HD
> >> > >>> 4K
> >> > >>>>> LC80UE30U",
> >> > >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800
> 79\"
> >> > >>> ULTRA HD
> >> > >>>>> 4K 3D",
> >> > >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\"
> >> ULTRA
> >> > >>> HD
> >> > >>>>> 4K 3D",
> >> > >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> >> > >>> 32J4300",
> >> > >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV
> >> 55UG8700
> >> > >>> 55\"
> >> > >>>>> ULTRA HD 4K 3D",
> >> > >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\"
> >> FULL
> >> > >>> HD
> >> > >>>>> 3D",
> >> > >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED
> >> FULL HD
> >> > >>> 50''
> >> > >>>>> TC-50AS600L",
> >> > >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K
> >> LC70SQ17U
> >> > >>> 70''",
> >> > >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
> >> TC-40A400L",
> >> > >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> >> > >>> 55HU8700",
> >> > >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
> >> TC-42AS650L",
> >> > >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58''
> LE58D3140"
> >> > >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> >> > >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> >> > >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> >> > >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> >> > >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> >> > >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> >> > >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> >> > >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes
> =
> >> > >>> c(2799L,
> >> > >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> >> > >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> >> > >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> >> > >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> >> > >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> >> > >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> >> > >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> >> > >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L,
> 14999L,
> >> > >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> >> > >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> >> > >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> >> > >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> >> > >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> >> > >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992,
> 2299,
> >> > >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099,
> 3999,
> >> > >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> >> > >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> >> > >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> >> > >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> >> > >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> >> > >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> >> > >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> >> > >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> >> > >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> >> > >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> >> > >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> >> > >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> >> > >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> >> > >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> >> > >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> >> > >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> >> > >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12,
> 39.48,
> >> > >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> >> > >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> >> > >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0,
> 11.67,
> >> > >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> >> > >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> >> > >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500
> -
> >> > >>> S/.2500",
> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
> >> "S/.500 -
> >> > >>>>> S/.1500",
> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >> > >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> >> > >>> S/.2500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", ">
> >> S/.4,500",
> >> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500
> -
> >> > >>> S/.1500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500
> -
> >> > >>> S/.2500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> >> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 -
> >> S/.4500",
> >> > >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 -
> >> S/.4500",
> >> > >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> >> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> >> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> >> > >>> S/.1500",
> >> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", ">
> >> S/.4,500",
> >> > >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", ">
> >> S/.4,500",
> >> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", ">
> >> S/.4,500",
> >> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >> > >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", ">
> >> S/.4,500",
> >> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500
> -
> >> > >>> S/.2500",
> >> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> >> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 -
> >> S/.1500",
> >> > >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")),
> .Names =
> >> > >>> c("id",
> >> > >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> >> > >>>>> "dif.precios", "dif.porcentual", "rangos"), class =
> "data.frame",
> >> > >>> row.names
> >> > >>>>> = c(NA,
> >> > >>>>> -97L))
> >> > >
> >> > > ______________________________________________
> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > > PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> > > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> > David Winsemius
> >> > Alameda, CA, USA
> >> >
> >> >
> >>
> >>
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From oma.gonzales at gmail.com  Sun Oct 11 07:42:10 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sun, 11 Oct 2015 00:42:10 -0500
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CALJKBv_isbZarbg5Tdi085XTbmTkTjm9j7szWAALo8_cEY1eiQ@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
	<CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
	<CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
	<CALJKBv_isbZarbg5Tdi085XTbmTkTjm9j7szWAALo8_cEY1eiQ@mail.gmail.com>
Message-ID: <CAM-xyZgh2fkNoBGN+2qwVBWnFwcbYRYGNzx_UR912Y7XmmZ60Q@mail.gmail.com>

Thanks Karim. linio.tv is in the email. In the last part.
El oct 11, 2015 12:39 AM, "Karim Mezhoud" <kmezhoud at gmail.com> escribi?:

> Hi,
> omit unlist and test. otherwise  you can use apply function.
>
> draft:
>
> df1 <- apply(linio.tv, 1, function(x) strsplit(x[,idproductio],
> "[^A-Z0-9-]+"))
>
> fct <- function(linio.tv){
>
>         if(any(grep("[A-Z][0-9]", linio.tv[,idx_productio]))) {
>
>                 linio.tv[,idx(id)] <- linio.tv[,idx_productio]
>
>         }
>
>         else {
>                 linio.tv[,idx(id)]<- NA
>         }
> }
>
> df2 <- apply(df1, 1, function(x) fct(x))
>
> I can't test this draft because I have not linio.tv
>
>
> Karim
>
>
> for (i in 1:nrow(linio.tv)) {
>
>         v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
> isolate tokens
>
>         if(any(grep("[A-Z][0-9]", v))) {
>
>                 linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>
>         }
>
>         else {
>                 linio.tv$id[i] <- NA
>         }
> }
>
> On Sun, Oct 11, 2015 at 6:07 AM, Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com> wrote:
>
>> Hi  Boris,
>>
>> I've modified a little the for loop to catch the IDs (if there is any)
>> otherwise to put NAs. This is for another data set.
>>
>>
>>
>> for (i in 1:nrow(linio.tv)) {
>>
>>         v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
>> isolate tokens
>>
>>         if(any(grep("[A-Z][0-9]", v))) {
>>
>>                 linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>
>>         }
>>
>>         else {
>>                 linio.tv$id[i] <- NA
>>         }
>> }
>>
>>
>> I get this warning messages, nevertheless the IDs column get the correct
>> values:
>>
>> Warning messages:
>> 1: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>>   number of items to replace is not a multiple of replacement length
>> 2: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>>   number of items to replace is not a multiple of replacement length
>>
>>
>> The problem:
>>
>> There are entries where the grep part is not specific enough.
>>
>> Like this one: "UN50JU6500-NEGRO". It satifies the rule in:
>>
>> linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  , but is not supposed to take
>> also: "UN50JU6500-NEGRO" entirely, only this part: "UN50JU6500".
>>
>>
>> I've noticed this rule: the IDs can have at maxium 1 letter after the "-".
>> If it contains more than 1, that part should not be considered.
>>
>> "TC-L42AS610"
>>
>> Also IDs can start with numbers: 1,2, or 3.
>>
>> "KDL-40R354B"
>>
>>
>>
>>
>> May you clarify to me if it's something that can be done within R?  I'm
>> trying to figure this out, but with any good result.
>>
>> I could cleaned with "sub()" (there is only one entry giving me troubles)
>> but the idea is not to have "technical debt" for the future.
>>
>>
>>
>>
>> This is the new data set, I'm talking about:
>>
>>
>>
>>
>>
>>
>> linio.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), marca = c("LG", "SAMSUNG",
>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>> "SAMSUNG", "LG", "LG", "SAMSUNG", "LG", "LG", "LG", "LG", "SAMSUNG",
>> "LG", "LG", "LG", "SONY", "SAMSUNG", "LG", "LG", "SAMSUNG", "SONY",
>> "SAMSUNG", "LG", "LG", "LG", "IMACO", "SAMSUNG", "LG", "SAMSUNG",
>> "SAMSUNG", "LG", "HAIER", "LG", "SONY", "SAMSUNG", "LG", "LG",
>> "LG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "HISENSE", "LG",
>> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "CONTINENTAL",
>> "LG", "IMACO", "AOC", "AOC", "SAMSUNG", "LG", "SONY", "LG", "LG",
>> "SONY", "SAMSUNG", "SAMSUNG", "PANASONIC", "LG", "SAMSUNG", "NEX",
>> "IMACO", "LG", "LG", "CONTINENTAL", "SONY", "LG", "LG", "SAMSUNG",
>> "LG", "LG", "LG", "LG", "LG", "SAMSUNG", "LG", "LG", "SAMSUNG",
>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "AOC", "LG", "LG",
>> "AOC", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "LG", "LG",
>> "SAMSUNG", "SAMSUNG", "SONY", "LG", "SAMSUNG", "SAMSUNG", "LG",
>> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG",
>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "PANASONIC", "PANASONIC",
>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY",
>> "LG", "LG", "PANASONIC", "AOC", "SAMSUNG", "LG", "SAMSUNG", "LG",
>> "SAMSUNG", "LG", "LG", "LG", "PANASONIC", "PANASONIC", "LG",
>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "SAMSUNG",
>> "LG", "LG", "SAMSUNG", "LG"), producto = c("COMBO SMART - LG TV LED 4K
>> ULTRA HD 43'' - 43UF6750 + GOO...",
>> "SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", "SAMSUNG TV LED 3D SMART
>> FULL HD 48'' - 48J6400",
>> "SAMSUNG TV LED 3D SMART FULL HD 55'' - 55J6400", "LG TV SMART LED HD 32\"
>> 32LF585B - BLANCO",
>> "LG TV SLIM ULTRA HD 3D WEBOS 2.0 49'' 49UF8500 - PLATEADO",
>> "LG TV SMART WEBOS 2.0 FULL HD 43\" 43LF5900 -NEGRO", "LG TV LED HD 32\" -
>> 32LF550B",
>> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "LG TV  LED SMART HD 32\"
>> - 32LF585B",
>> "LG GAME TV LED FULL HD 49\" - 49LF5410", "SAMSUNG TV LED  FULL HD 60'' -
>> UN60FH6003",
>> "LG TV SMART WEBOS 2.0 FULL HD 49\" - 49LF6350", "LG TV LED  FULL HD 43''
>> -
>> 43LF5410",
>> "SAMSUNG TV SMART FULL HD CURVO 40'' TIZEN -  UN40J6500", "LG TV SMART
>> WEBOS 2.0 ULTRA HD  4K 43\" - 43UF6400",
>> "LG TV SLIM LED CINEMA 3D FULL HD 42'' 42LB6200 INCLUYE 02...",
>> "LG GAMETV  LED FULL HD 43\" - 43LF5400", "LG GAME TV LED FULL HD 49\" -
>> 49LF5410",
>> "TELEVISOR SAMSUNG UN40J5500 SMART TV LED FULL HD 40''-PLA...",
>> "LG SMART  4K ULTRA HD 55\" - 55UB8200", "LG -TV LED SMART WEBOS 2.0 FULL
>> HD 55\" - 55LF6350",
>> "LG - GAME TV LED  FULL HD 43'' - 43LF5410", "SONY - TV LED SMART HD 32''
>> -
>> 32R505C",
>> "SAMSUNG TV LED 3D SMART FULL HD 40'' - UN40H6400", "LG SMART TV 32\" HD
>> WEBOS 2.0  32LF595B",
>> "LG - TV LED WEBOS 3D SMART ULTRA HD CURVO  55'' 55UG8700 ...",
>> "SAMSUNG TV LED FULL HD 40\" UN40JH5005 - NEGRO", "SONY TV LED FULL HD
>> 40''
>> - KDL-40R354B",
>> "SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
>> "LG TV LED FULL HD 42'' ULTRA SLIM 42LY340C - NEGRO", "LG TV SMART LED
>> FULL
>> HD 43\" - 43LF6350",
>> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
>> "IMACO - TV LED HD 24?? - LED24HD", "TELEVISOR SAMSUNG UN32J4300 SMART TV
>> LED HD 32''-NEGRO",
>> "LG TV 3D SMART LED ULTRA HD 65\" - 65UF8500", "SAMSUNG - TV LED SMART 3D
>> 65\" FULL HD SERIE 8 INTERACTIVO...",
>> "SAMSUNG - TV LED HD 32\"  32JH4005 - NEGRO", "LG TV 55\" SMART ULTRA HD
>> 4K
>> CINEMA 3D  55UB8500",
>> "HAIER TV LED HD LIVE GREEN 24'' - 24B8000", "LG TV LED FULL HD 47'' -
>> 47LB5610",
>> "SONY TV LED FULL HD 32'' - KDL-32R304B", "SAMSUNG TV LED SERIE 5 FULL HD
>> 39? - 39FH5005",
>> "LG - TV SAMT SLIM ULTRA HD 4K WEBOS 2.0 55'' 55UF7700 - P...",
>> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
>> "LG TV MONITOR LED HD 23.6? - 24MT47A", "SAMSUNG - MONITOR LED 32\" MD32C
>> -
>> NEGRO",
>> "TELEVISOR SAMSUNG UN40J6400 SMART TV LED 3D FULL HD 40''-...",
>> "SAMSUNG LED SMART FULL HD 48'' - UN48J6500", "SONY - TV LED SMART FULL HD
>> 40'' - 40R555C",
>> "TELEVISOR HISENSE LED 40\" 40K221W SMART TV LED FULL HD", "LG TV MONITOR
>> LED HD 23.6? - 24MT47A",
>> "TELEVISOR SAMSUNG UN48J6400 SMART TV LED 3D FULL HD 48''-...",
>> "LG 49UB8500 LED 49\" SMART 3D 4K", "SAMSUNG TV LED 3D SMART FULL HD 40''
>> TIZEN UN40J6400 - NEGRO",
>> "LG TV LED FULL HD 42\" - 42LY340C", "SAMSUNG TV LED HD 32'' UN32J4000 -
>> NEGRO",
>> "TELEVISOR SAMSUNG UN48J5500 SMART TV LED FULL HD 48''-PLA...",
>> "CONTINENTAL - TV LED 15.6\" CELED95935, INCLUYE RACK", "LG TV LED 4K
>> ULTRA
>> HD 43\" - 43UF6750",
>> "IMACO - TV LED HD 16?? - LED16HD", "AOC - TELEVISOR HD 32\" LE32W454F-
>> NEGRO",
>> "AOC TV LED HD 20\" - LE20A1140", "SAMSUNG TV LED HD 32'' - UN32J4000",
>> "LG - TV MONITOR 27.5? - 28MT47B", "SONY TV LED FULL HD 40'' -
>> KDL-40R354B",
>> "LG TV MONITOR LED HD 23.6? - 24MT47A", "LG GAME TV LED FULL HD 49\" -
>> 49LF5410",
>> "SONY TV LED FULL HD 40'' - KDL-40R354B", "SAMSUNG - UN48J6400 LED FULL HD
>> 48\"SMART TIZEN 3D 2015 - ...",
>> "SAMSUNG - MONITOR FULL HD 40\" MD40C - NEGRO", "PANASONIC LED SMART FULL
>> HD 50\" - TC-50AS600",
>> "LG - 43LF5410 LED 43\" FULL HD GAME  - SILVER", "SAMSUNG - TELEVISOR LED
>> HD 32\" UN32JH4005 - NEGRO",
>> "NEX TV LED SMART HD 32\" USB WIFI INCORPORADO - LED3208SMR",
>> "IMACO - TV LED HD 19?? - LED19HD", "LG -TV LED HG 32\" - 32LF550B",
>> "LG - TELEVISOR LED 32\" HD 32LF550B", "CONTINENTAL - TV LED 19\"
>> CELED99935,  INCLUYE RACK",
>> "SONY TV LED FULL HD 40'' - KDL-40R354B", "LG - TELEVISOR LED 32\" HD
>> SMART
>> TV 32LF585B - BLANCO",
>> "MONITOR TV LG 24MT47A LED HD 23.6?-PLATEADO", "TELEVISOR SAMSUNG
>> UN32J4300
>> SMART TV LED HD 32''-NEGRO",
>> "LG GAME TV LED FULL HD 49\" - 49LF5400", "LG - TELEVISOR LED 32\" HD
>> SMART
>> TV 32LF585B ? BLANCO",
>> "LG - TELEVISOR LED 32\" HD 32LF550B", "LG TV LED HD 32'' - 32LF550B",
>> "LG TV LED SMART HD 32'' - 32LF585B", "SAMSUNG - TELEVISOR LED FULL HD
>> 40\"
>> UN40JH5005 ? NEGRO",
>> "LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", "LG TV LED WEBOS 3D
>> SMART ULTRA HD 49'' - 49UF8500",
>> "SAMSUNG - TV LED SMART FULL HD 40? UN40H5500 - NEGRO", "SAMSUNG TV LED
>> SMART HD 32'' UN32J4300 - NEGRO",
>> "SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", "SAMSUNG -
>> TELEVISOR LED FULL HD 40\" UN40JH5005 - NEGRO",
>> "SAMSUNG TV LED SMART TIZEN 3D QUADCORE40\" - UN40J6400", "AOC TV LED HD
>> 32\" - LE32W454F +RACK FIJO",
>> "LG TV LED FULL HD 43'' - 43LF5410", "LG - TV LED WEBOS 3D SMART FULL HD
>> 55'' - 55LF6500",
>> "AOC 32\" LE32W454F  HD DIGITAL LED TV + HOME THEATRE F1200U",
>> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED ALTA
>> DEFINICI?N DTV USB 32\" - 32JH4005",
>> "LG - 42LF6400 LED FULL HD 42'' SMART WEBOS 3D - SILVER", "TELEVISOR
>> SAMSUNG UN48J5300 SMART TV LED FULL HD 48''-NEGRO",
>> "SAMSUNG UN40JH5005 LED FULL HD 40\"  - NEGRO GLOSS", "LG - 24MT47A +
>> MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...",
>> "LG TV LED SMART 4K ULTRA HD 55\" - 55UB8200", "SAMSUNG - 55J6400 LED 55\"
>> SMART TIZEN 3D - BLACK",
>> "SAMSUNG TV CURVED SMART ULTRA HD 48'' TIZEN UN48JU6700 - ...",
>> "TELEVISI?N SONY KDL-32R505C LED 32\"-NEGRO", "LG TV LED CINEMA 3D 4K
>> SMART
>> ULTRA HD 49'' + 02 LENTES 3D...",
>> "SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", "SAMSUNG - 40J5500
>> LED
>> 40\" SMART QUADCORE / BLUETOOTH* - S...",
>> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED SMART
>> FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
>> "LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 ? PLAT...",
>> "TELEVISI?N SAMSUNG UN48J5500 LED SMART TV 48\"-PLATEADO", "LG - TELEVISOR
>> LED 42\" FULL HD SMART TV 42LF5850 - PLATEADO",
>> "TELEVISOR SAMSUNG  UN55JU6700 LED UHD 4K SMART 55'' - PLA...",
>> "LG - TV LED WEBOS 3D SMART SUPER ULTRA HD 55'' - 55UF9500",
>> "TELEVISOR SAMSUNG UN50JU6500  UHD 4K SMART 50'' - PLATEADO",
>> "SAMSUNG - TELEVISOR LED HD 40\" SMART UN40J5500 - NEGRO", "TELEVISOR
>> SAMSUNG UN48J6500 CURVO  FULL HD SMART 48'' - P...",
>> "SAMSUNG - TELEVISOR LED HD 32\" SMART UN32J4300 - NEGRO", "LG TV LED
>> CINEMA 3D 4K SMART ULTRA HD 55'' 55UB8500 - NEGRO",
>> "TELEVISI?N PANASONIC TC-L40SV7L LED FULL-HD 40''-NEGRO", "PANASONIC TV
>> LED
>> 42?? FULL HD TC-L42E6L - NEGRO.",
>> "TELEVISOR SAMSUNG UN 40JH5005 LED FULL HD", "SAMSUNG - TV LED SMART CURVO
>> 3D ULTRA HD 65? UN65HU9000...",
>> "SAMSUNG - UN48J5300 LED FULL HD SMART 2015 - BLACK", "SAMSUNG TV LED
>> SMART
>> FULL HD 50'' TIZEN UN50J5500 - PLATEADO",
>> "SAMSUNG - TV SMART 3D FULL HD 60? UN60H7100 - NEGRO", "SONY - TELEVISOR
>> LED SMART TV FULL HD 40'' KDL-40R555C - ...",
>> "LG TV 47\" LED FULL HD - 47LY340C", "LG TV UHD 4K 65UB9800 SMART 3D LED
>> TV
>> C/WEBOS 65' LENTES 3D",
>> "PANASONIC - TELEVISOR TC-L42AS610 LED SMART FULL HD 42?...",
>> "AOC - TELEVISOR LED 32\" - LE32W454F", "SAMSUNG TV LED 32? -
>> UN32FH4005G",
>> "LG TV SMART LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED 3D SMART FULL
>> HD
>> 40'' TIZEN UN40J6400 - NEGRO",
>> "LG TV SMART  LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED HD 32''
>> UN32JH4005 - NEGRO",
>> "LG TV PLASMA 2014 60\" FULL HD 1080P - 60PB5600", "LG TV LED CINEMA 3D
>> SMART FULL HD 55'' 55LB7050 - PLATEADO",
>> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "PANASONIC PUERTO USB LED
>> 40\" - TC-L40SV7L",
>> "PANASONIC LED SMART FULL HD 42\" - TC-L42AS610", "LG TV SMART  LED FULL
>> HD
>> 49\" - 49LF6350",
>> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500-NEGRO",
>> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500 - NEGRO",
>> "SAMSUNG TV SMART FULL HD CURVO 48'' TIZEN UN48J6500", "SAMSUNG TV  SMART
>> ULTRA HD 4K  65'' - UN65JU6500",
>> "SAMSUNG UN48J5500 LED 48\" - PLATEADO", "SAMSUNG LED 32\" CONEXI?N WIFI -
>> UN32J4300",
>> "SAMSUNG LED SMART 40'' CONEXI?N WI-FI DIRECT - UN40J5500", "SAMSUNG LED
>> SMART ULTRA HD 55\" - TVUN55JU6700",
>> "SAMSUNG TV CURVED 3D SMART ULTRA HD 65'' TIZEN UN65JU7500...",
>> "SAMSUNG TELEVISOR  HG32NB460GF, 32\" LED, HD, 1366 X 768", "LG -TV SMART
>> LED FULL HD 55\" - 55LF6350",
>> "SAMSUNG TV LED SMART 3D 48\" - UN48H6400", "LG LED ULTRAHD 4K 49\" SMART
>> 3D - 49UB8300",
>> "LG - TV LED SMART HD 32'' 32LF585B - PLATEADO", "SAMSUNG - TV LED FULL HD
>> 40\" UN40JH5005  - NEGRO GLOSS",
>> "LG - TV LED FULL HD 43'' 43LF5410 - PLATEADO"), precio.antes = c(2599L,
>> 1299L, 2899L, 3999L, 1199L, 4499L, 1999L, 1099L, 2299L, 1299L,
>> 2499L, 3999L, 2199L, 1899L, 2299L, 2299L, 1799L, 1499L, 2299L,
>> 1999L, 3999L, 3499L, 1549L, 1299L, 2299L, 2299L, 6999L, 1499L,
>> 1499L, 1899L, 1499L, 2099L, 6999L, 599L, 1299L, 9999L, 8999L,
>> 999L, 5999L, 599L, 2299L, 1299L, 1499L, 4999L, 6999L, 899L, 2299L,
>> 2499L, 3299L, 1799L, 1399L, 899L, 2499L, 4199L, 2299L, 1499L,
>> 1099L, 2499L, 399L, 2499L, 399L, 999L, 599L, 999L, 899L, 1499L,
>> 699L, 2299L, 1399L, 2499L, 2999L, 2499L, 1599L, 1149L, 999L,
>> 499L, 1089L, 1099L, 499L, 1499L, 1399L, 799L, 1299L, 2499L, 1399L,
>> 1259L, 1299L, 1299L, 1599L, 1999L, 3999L, 1999L, 1199L, 999L,
>> 1599L, 2299L, 999L, 1499L, 3699L, 1199L, 3899L, 1099L, 2299L,
>> 2499L, 1399L, 729L, 4199L, 3599L, 4999L, 1399L, 3999L, 4999L,
>> 2199L, 4499L, 2299L, 1699L, 2779L, 1699L, 5799L, 8999L, 3699L,
>> 2099L, 3299L, 1299L, 5900L, 1799L, 1799L, 1399L, 14999L, 2499L,
>> 2799L, 6299L, 1799L, 2417L, 9500L, 1799L, 799L, 999L, 1999L,
>> 2499L, 1899L, 999L, 2299L, 3699L, 2199L, 1699L, 1999L, 2499L,
>> 3499L, 3899L, 2999L, 7999L, 2299L, 1299L, 2099L, 5799L, 9999L,
>> 1110L, 3399L, 2799L, 3899L, 1299L, 1399L, 1499L), precio.nuevo = c(1799L,
>> 999L, 2299L, 3299L, 999L, 3199L, 1499L, 849L, 1399L, 979L, 1795L,
>> 2999L, 1899L, 1299L, 1699L, 1599L, 1499L, 1299L, 1699L, 1449L,
>> 3699L, 2499L, 1199L, 999L, 1499L, 899L, 4999L, 1199L, 1199L,
>> 1389L, 1299L, 1699L, 4899L, 549L, 999L, 7499L, 6700L, 849L, 4299L,
>> 549L, 1499L, 899L, 1299L, 3599L, 5354L, 538L, 1959L, 1599L, 2999L,
>> 1367L, 1099L, 589L, 2449L, 3199L, 1529L, 1229L, 839L, 1779L,
>> 329L, 1799L, 389L, 719L, 489L, 849L, 799L, 1185L, 599L, 1609L,
>> 1299L, 2179L, 2839L, 1999L, 1599L, 899L, 799L, 449L, 880L, 899L,
>> 429L, 1275L, 1199L, 589L, 999L, 1749L, 1199L, 1099L, 899L, 989L,
>> 1399L, 1999L, 2999L, 1599L, 999L, 819L, 1299L, 2299L, 789L, 1299L,
>> 3199L, 977L, 3089L, 849L, 1719L, 1799L, 1399L, 569L, 3979L, 3299L,
>> 3369L, 1093L, 3389L, 3289L, 1419L, 3429L, 1405L, 1499L, 1899L,
>> 1499L, 5199L, 6999L, 3199L, 1599L, 2999L, 1099L, 5089L, 1459L,
>> 1499L, 1289L, 12999L, 1739L, 2255L, 5879L, 1499L, 1929L, 8499L,
>> 1649L, 799L, 899L, 1659L, 1749L, 1609L, 831L, 2089L, 3659L, 1769L,
>> 1499L, 1599L, 2176L, 2749L, 2889L, 2899L, 5599L, 1899L, 1099L,
>> 1899L, 5199L, 8589L, 990L, 3169L, 2199L, 3899L, 949L, 1099L,
>> 1199L), dif.precios = c(800L, 300L, 600L, 700L, 200L, 1300L,
>> 500L, 250L, 900L, 320L, 704L, 1000L, 300L, 600L, 600L, 700L,
>> 300L, 200L, 600L, 550L, 300L, 1000L, 350L, 300L, 800L, 1400L,
>> 2000L, 300L, 300L, 510L, 200L, 400L, 2100L, 50L, 300L, 2500L,
>> 2299L, 150L, 1700L, 50L, 800L, 400L, 200L, 1400L, 1645L, 361L,
>> 340L, 900L, 300L, 432L, 300L, 310L, 50L, 1000L, 770L, 270L, 260L,
>> 720L, 70L, 700L, 10L, 280L, 110L, 150L, 100L, 314L, 100L, 690L,
>> 100L, 320L, 160L, 500L, 0L, 250L, 200L, 50L, 209L, 200L, 70L,
>> 224L, 200L, 210L, 300L, 750L, 200L, 160L, 400L, 310L, 200L, 0L,
>> 1000L, 400L, 200L, 180L, 300L, 0L, 210L, 200L, 500L, 222L, 810L,
>> 250L, 580L, 700L, 0L, 160L, 220L, 300L, 1630L, 306L, 610L, 1710L,
>> 780L, 1070L, 894L, 200L, 880L, 200L, 600L, 2000L, 500L, 500L,
>> 300L, 200L, 811L, 340L, 300L, 110L, 2000L, 760L, 544L, 420L,
>> 300L, 488L, 1001L, 150L, 0L, 100L, 340L, 750L, 290L, 168L, 210L,
>> 40L, 430L, 200L, 400L, 323L, 750L, 1010L, 100L, 2400L, 400L,
>> 200L, 200L, 600L, 1410L, 120L, 230L, 600L, 0L, 350L, 300L, 300L
>> ), dif.porcentual = c(30.78, 23.09, 20.7, 17.5, 16.68, 28.9,
>> 25.01, 22.75, 39.15, 24.63, 28.17, 25.01, 13.64, 31.6, 26.1,
>> 30.45, 16.68, 13.34, 26.1, 27.51, 7.5, 28.58, 22.6, 23.09, 34.8,
>> 60.9, 28.58, 20.01, 20.01, 26.86, 13.34, 19.06, 30, 8.35, 23.09,
>> 25, 25.55, 15.02, 28.34, 8.35, 34.8, 30.79, 13.34, 28.01, 23.5,
>> 40.16, 14.79, 36.01, 9.09, 24.01, 21.44, 34.48, 2, 23.82, 33.49,
>> 18.01, 23.66, 28.81, 17.54, 28.01, 2.51, 28.03, 18.36, 15.02,
>> 11.12, 20.95, 14.31, 30.01, 7.15, 12.81, 5.34, 20.01, 0, 21.76,
>> 20.02, 10.02, 19.19, 18.2, 14.03, 14.94, 14.3, 26.28, 23.09,
>> 30.01, 14.3, 12.71, 30.79, 23.86, 12.51, 0, 25.01, 20.01, 16.68,
>> 18.02, 18.76, 0, 21.02, 13.34, 13.52, 18.52, 20.77, 22.75, 25.23,
>> 28.01, 0, 21.95, 5.24, 8.34, 32.61, 21.87, 15.25, 34.21, 35.47,
>> 23.78, 38.89, 11.77, 31.67, 11.77, 10.35, 22.22, 13.52, 23.82,
>> 9.09, 15.4, 13.75, 18.9, 16.68, 7.86, 13.33, 30.41, 19.44, 6.67,
>> 16.68, 20.19, 10.54, 8.34, 0, 10.01, 17.01, 30.01, 15.27, 16.82,
>> 9.13, 1.08, 19.55, 11.77, 20.01, 12.93, 21.43, 25.9, 3.33, 30,
>> 17.4, 15.4, 9.53, 10.35, 14.1, 10.81, 6.77, 21.44, 0, 26.94,
>> 21.44, 20.01), pulgadas = c("43", "32", "48", "55", "32", "49",
>> "43", "32", "43", "32", "49", "60", "49", "43", "40", "43", "42",
>> "43", "49", "40", "55", "55", "43", "32", "40", "32", "55", "40",
>> "40", "40", "42", "43", "55", "24", "32", "65", "65", "32", "55",
>> "24", "47", "32", "39", "55", "55", "6", "32", "40", "48", "40",
>> "40", "6", "48", "49", "40", "42", "32", "48", "6", "43", "16",
>> "32", "20", "32", "5", "40", "6", "49", "40", "48", "40", "50",
>> "43", "32", "32", "19", "32", "32", "19", "40", "32", "6", "32",
>> "49", "32", "32", "32", "32", "40", "42", "49", "40", "32", "32",
>> "40", "40", "32", "43", "55", "32", "49", "32", "42", "48", "40",
>> "24", "55", "55", "48", "32", "49", "55", "40", "49", "40", "42",
>> "48", "42", "55", "55", "50", "40", "48", "32", "55", "40", "42",
>> "NA", "65", "NA", "50", "60", "40", "47", "65", "42", "32", "32",
>> "42", "40", "42", "32", "60", "55", "43", "40", "42", "49", "50",
>> "50", "48", "65", "48", "32", "40", "55", "65", "32", "55", "48",
>> "49", "32", "40", "43"), rangos = c("S/.1500 - S/.2500", "S/.500 -
>> S/.1500",
>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.3500 - S/.4500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "> S/.4,500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>> S/.1500",
>> "S/.1500 - S/.2500", "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.3500 - S/.4500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>> S/.1500",
>> "S/.3500 - S/.4500", "> S/.4,500", "S/.500 - S/.1500", "S/.1500 -
>> S/.2500",
>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "< S/.500", "S/.1500 - S/.2500",
>> "< S/.500", "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
>> S/.2500",
>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.2500 - S/.3500",
>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>> S/.1500",
>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.1500 - S/.2500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
>> S/.2500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>> "S/.500 - S/.1500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.3500 - S/.4500", "S/.2500 - S/.3500",
>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.2500 - S/.3500",
>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>> "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> "> S/.4,500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", "> S/.4,500",
>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500", "S/.1500 -
>> S/.2500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.1500 - S/.2500",
>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>> "S/.2500 - S/.3500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>> "> S/.4,500", "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 -
>> S/.2500",
>> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
>> "S/.500 - S/.1500", "S/.500 - S/.1500")), .Names = c("id", "marca",
>> "producto", "precio.antes", "precio.nuevo", "dif.precios",
>> "dif.porcentual",
>> "pulgadas", "rangos"), class = "data.frame", row.names = c(NA,
>> -164L))
>>
>>
>>
>>
>>
>>
>>
>>
>> 2015-10-10 11:55 GMT-05:00 Omar Andr? Gonz?les D?az <
>> oma.gonzales at gmail.com>
>> :
>>
>> > Thank you very much to both of you. This information is very
>> enlightening
>> > to me.
>> >
>> > Cheers.
>> >
>> >
>> > 2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:
>> >
>> >> David answered most of this. Just a two short notes inline.
>> >>
>> >>
>> >>
>> >>
>> >> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <
>> >> oma.gonzales at gmail.com> wrote:
>> >>
>> >> > David, Boris, so thankfull for your help. Both approaches are very
>> >> good. I got this solve with David's help.
>> >> >
>> >> > I find very insteresting Bori's for loop. And I need a little help
>> >> understanding the regex part on it.
>> >> >
>> >> > - The strsplit function: strsplit(ripley.tv$producto[i],
>> "[^A-Z0-9-]+")
>> >> >
>> >> > I understand for this: split every row by a sequence of any number or
>> >> letter or "-" that appears at leat once (+ operator).
>> >> >
>> >> > 1.- What does mena the "^" symbol? If you remove it, just appeare
>> >> blanks.
>> >> > 2.- Why is there the necessity of "+" after the closing "]"?
>> >> >
>> >> > 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>> >> >      Identifies also the IDs where "-" is present. Here the regex
>> does
>> >> not have the "-" included.
>> >>
>> >> Yes. I am not matching the entire token here. Note there is no "+": The
>> >> two character-class expressions match exactly one uppercase character
>> >> adjacent to exactly one number. If this is found in a token, grep
>> returns
>> >> TRUE. It doesn't matter what else the token contains - the first regex
>> >> already took care of removing everything that's not needed. The vector
>> of
>> >> FALSEs and a single TRUE that grep() returns goes inside the square
>> >> brackets, and selects the token from v.
>> >>
>> >>
>> >>
>> >> > Also, I notice that David used the "-" at the begining of the
>> matching:
>> >> [-A-Z0-9], without the "^" (stars with) at the beginning.
>> >>
>> >> This can be very confusing about regular expressions: the same
>> character
>> >> can mean different things depending on where it is found. Between two
>> >> characters in a character class expresssion, the hyphen means "range".
>> >> Elsewhere it is a literal hyphen. David put his at the beginning, I
>> had it
>> >> at the end (in the first regex). Another tricky character is "?" which
>> can
>> >> mean 0,1 matches, or turn "greedy" matching off...
>> >>
>> >> Online regex testers are invaluable to develop a regex - one I
>> frequently
>> >> use is regexpal.com
>> >>
>> >> Cheers,
>> >> B.
>> >>
>> >>
>> >> >
>> >> > I would appreciate a response from you, gentlemen.
>> >> >
>> >> > Thanks again.
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> >
>> >> > 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
>> >> >
>> >> > On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
>> >> >
>> >> > > I think you are going into the wrong direction here and this is a
>> >> classical example of what we mean by "technical debt" of code. Rather
>> than
>> >> tell to your regular expression what you are looking for, you are
>> handling
>> >> special cases with redundant code. This is ugly, brittle and
>> impossible to
>> >> maintain.
>> >> > >
>> >> > > Respect to you that you have recognized this.
>> >> > >
>> >> > >
>> >> > > The solution is rather simple:
>> >> > >
>> >> > > A) Isolate tokens. Your IDs contain only a limited set of
>> characters.
>> >> Split your strings along the characters that are not found in IDs to
>> >> isolate candidate tokens, place them into a vector.
>> >> > >
>> >> > > B) Evaluate your tokens: as far as I can see IDs all contain
>> letters
>> >> AND numbers. This is a unique characteristic. Thus it is sufficient to
>> grep
>> >> for a letter/number pair in a token to identify it as an ID.
>> >> > >
>> >> > > Should you ever find a need to accommodate differently formed IDs,
>> >> there are only two, well defined places with clearly delegated roles
>> where
>> >> changes might be needed.
>> >> > >
>> >> > > Here is the code:
>> >> > >
>> >> > > for (i in 1:nrow(ripley.tv)) {
>> >> > >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+"))
>> #
>> >> isolate tokens
>> >> > >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs
>> >> and store
>> >> > > }
>> >> >
>> >> > That logic actually simplifies the regex strategy as well:
>> >> >
>> >> >  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>> >> >  ripley.tv$producto,
>> >> >  ignore.case = T)
>> >> >
>> >> >
>> >> > Almost succeeds, with a few all-character words, but if you require
>> one
>> >> number in the middle you get full results:
>> >> >
>> >> >  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>> >> >  ripley.tv$producto,
>> >> >  ignore.case = T)
>> >> >
>> >> >  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"
>> >>  "LE40K5000N"
>> >> >  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"
>>  "LE24B8000"
>> >> > [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"
>> "50JU6500"
>> >> > [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"
>> "65JS9000"
>> >> > [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"
>> "42LF6400"
>> >> > [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"
>> "49UF6750"
>> >> > [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"
>> "65UF7700"
>> >> > [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
>> >> > [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B"
>> "40J5500"
>> >> > [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"
>>  "40J6400"
>> >> > [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"
>> "43LF5410"
>> >> > [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"
>>  "LE40F1551"
>> >> > [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"
>>  "58UF8300"
>> >> > [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C"
>> >> "XBR-75X945C"
>> >> > [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"
>>  "48J5500"
>> >> > [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"
>> "32J4300"
>> >> > [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"
>> "32LF550B"
>> >> > [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"
>> >>  "XBR-79X905B"
>> >> > [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"
>> >>  "TC-42AS650L"
>> >> > [96] "LC70LE660"   "LE58D3140"
>> >> >
>> >> > >
>> >> > >
>> >> > >
>> >> > > Cheers,
>> >> > > Boris
>> >> > >
>> >> > >
>> >> > >
>> >> > > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
>> >> oma.gonzales at gmail.com> wrote:
>> >> > >
>> >> > >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA,
>> >> NA,
>> >> > >>> NA, NA,
>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
>> >> > >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
>> "HAIER",
>> >> > >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>> >> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>> "SAMSUNG",
>> >> > >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>> >> > >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
>> >> > >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
>> >> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
>> >> "SAMSUNG",
>> >> > >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC",
>> >> "PANASONIC",
>> >> > >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY",
>> "SONY",
>> >> > >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
>> >> > >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG",
>> >> "PANASONIC",
>> >> > >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
>> >> > >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD
>> 48\"
>> >> 3D
>> >> > >>>>> 48J6400",
>> >> > >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40''
>> >> TC-40CS600L",
>> >> > >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
>> >> > >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV
>> LED
>> >> FHD
>> >> > >>> 55\" -
>> >> > >>>>> LE55B8000",
>> >> > >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" -
>> >> NEGRO",
>> >> > >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N
>> 50\"",
>> >> > >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48''
>> >> 48JU6500",
>> >> > >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD
>> 55''
>> >> 3D
>> >> > >>>>> 55JS9000",
>> >> > >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55''
>> >> 55JU6700",
>> >> > >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV
>> >> ULTRA HD
>> >> > >>> 65''
>> >> > >>>>> 3D 65JS9000",
>> >> > >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65''
>> >> 65JU7500",
>> >> > >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
>> >> > >>> 40LF6350",
>> >> > >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD
>> CINEMA
>> >> 3D
>> >> > >>>>> 42LF6450",
>> >> > >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\"
>> >> FULL HD
>> >> > >>>>> 3D",
>> >> > >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
>> >> > >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\"
>> >> ULTRA HD
>> >> > >>> 4K",
>> >> > >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D
>> >> SMART
>> >> > >>> TV
>> >> > >>>>> 55UF7700",
>> >> > >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\"
>> >> ULTRA HD
>> >> > >>> 4K
>> >> > >>>>> 3D",
>> >> > >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA
>> >> HD 4K
>> >> > >>> SMART
>> >> > >>>>> TC-50CX640W",
>> >> > >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA
>> HD
>> >> 4K
>> >> > >>> CINEMA
>> >> > >>>>> SMART UG8700",
>> >> > >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\"
>> >> FULL HD
>> >> > >>> 3D",
>> >> > >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
>> >> > >>> KDL-40R354B",
>> >> > >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
>> >> > >>> 50J5500",
>> >> > >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
>> >> > >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
>> >> > >>> 40J6400",
>> >> > >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
>> >> > >>> KDL-40R555C
>> >> > >>>>> - NEGRO",
>> >> > >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" -
>> >> NEGRO",
>> >> > >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" -
>> >> BLANCO",
>> >> > >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
>> >> > >>>>> KDL-65W855C",
>> >> > >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD
>> >> LE40F1551",
>> >> > >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD
>> KDL-32R304B",
>> >> > >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD
>> 32''
>> >> > >>>>> LE32W454F",
>> >> > >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD
>> SMART
>> >> 3D
>> >> > >>>>> KDL-55W805C",
>> >> > >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
>> >> > >>>>> XBR-55X855C",
>> >> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED
>> 75\"
>> >> > >>> ULTRA HD
>> >> > >>>>> 4K 3D XBR-75X945C",
>> >> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV
>> >> LED 60''
>> >> > >>>>> ULTRA HD 4K LC60UE30U",
>> >> > >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80''
>> >> ULTRA HD
>> >> > >>> 4K
>> >> > >>>>> LC80UE30U",
>> >> > >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800
>> 79\"
>> >> > >>> ULTRA HD
>> >> > >>>>> 4K 3D",
>> >> > >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500
>> 65\"
>> >> ULTRA
>> >> > >>> HD
>> >> > >>>>> 4K 3D",
>> >> > >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
>> >> > >>> 32J4300",
>> >> > >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV
>> >> 55UG8700
>> >> > >>> 55\"
>> >> > >>>>> ULTRA HD 4K 3D",
>> >> > >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500
>> 55\"
>> >> FULL
>> >> > >>> HD
>> >> > >>>>> 3D",
>> >> > >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED
>> >> FULL HD
>> >> > >>> 50''
>> >> > >>>>> TC-50AS600L",
>> >> > >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K
>> >> LC70SQ17U
>> >> > >>> 70''",
>> >> > >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
>> >> TC-40A400L",
>> >> > >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D
>> CURVO
>> >> > >>> 55HU8700",
>> >> > >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
>> >> TC-42AS650L",
>> >> > >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58''
>> LE58D3140"
>> >> > >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
>> >> > >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L,
>> 65L,
>> >> > >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L,
>> 65L,
>> >> > >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L,
>> 50L,
>> >> > >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L,
>> 32L,
>> >> > >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L,
>> 80L,
>> >> > >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L,
>> 50L,
>> >> > >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L),
>> precio.antes =
>> >> > >>> c(2799L,
>> >> > >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L,
>> 1899L,
>> >> > >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L,
>> 14999L,
>> >> > >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
>> >> > >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
>> >> > >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
>> >> > >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
>> >> > >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
>> >> > >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L,
>> 14999L,
>> >> > >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L,
>> 7999L,
>> >> > >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
>> >> > >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
>> >> > >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
>> >> > >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3,
>> 5109.3,
>> >> > >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992,
>> 2299,
>> >> > >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099,
>> 3999,
>> >> > >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599,
>> 2999,
>> >> > >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
>> >> > >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
>> >> > >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
>> >> > >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999,
>> 2599,
>> >> > >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
>> >> > >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
>> >> > >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
>> >> > >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
>> >> > >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300,
>> 100,
>> >> > >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0,
>> 700,
>> >> > >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
>> >> > >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
>> >> > >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
>> >> > >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
>> >> > >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30,
>> 43.22,
>> >> > >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12,
>> 39.48,
>> >> > >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
>> >> > >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
>> >> > >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0,
>> 11.67,
>> >> > >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
>> >> > >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
>> >> > >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos =
>> c("S/.1500 -
>> >> > >>> S/.2500",
>> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>> >> "S/.500 -
>> >> > >>>>> S/.1500",
>> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> >> > >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
>> >> > >>> S/.2500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>> >> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", ">
>> >> S/.4,500",
>> >> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>> "S/.500 -
>> >> > >>> S/.1500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500",
>> "S/.1500 -
>> >> > >>> S/.2500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>> >> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 -
>> >> S/.4500",
>> >> > >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 -
>> >> S/.4500",
>> >> > >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>> >> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>> >> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500
>> -
>> >> > >>> S/.1500",
>> >> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", ">
>> >> S/.4,500",
>> >> > >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", ">
>> >> S/.4,500",
>> >> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", ">
>> >> S/.4,500",
>> >> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>> >> > >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", ">
>> >> S/.4,500",
>> >> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
>> "S/.1500 -
>> >> > >>> S/.2500",
>> >> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>> >> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 -
>> >> S/.1500",
>> >> > >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")),
>> .Names =
>> >> > >>> c("id",
>> >> > >>>>> "marca", "producto", "pulgadas", "precio.antes",
>> "precio.nuevo",
>> >> > >>>>> "dif.precios", "dif.porcentual", "rangos"), class =
>> "data.frame",
>> >> > >>> row.names
>> >> > >>>>> = c(NA,
>> >> > >>>>> -97L))
>> >> > >
>> >> > > ______________________________________________
>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > > and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> > David Winsemius
>> >> > Alameda, CA, USA
>> >> >
>> >> >
>> >>
>> >>
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Sun Oct 11 07:57:05 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Sun, 11 Oct 2015 06:57:05 +0100
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZgh2fkNoBGN+2qwVBWnFwcbYRYGNzx_UR912Y7XmmZ60Q@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
	<CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
	<CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
	<CALJKBv_isbZarbg5Tdi085XTbmTkTjm9j7szWAALo8_cEY1eiQ@mail.gmail.com>
	<CAM-xyZgh2fkNoBGN+2qwVBWnFwcbYRYGNzx_UR912Y7XmmZ60Q@mail.gmail.com>
Message-ID: <CALJKBv_BYcKXiu8qQdPpkB-9HmBvkLaRpXvg9ww1S_DOVbV51w@mail.gmail.com>

My code is not correct.
The idea is to use apply instead of a loop. more efficiency.
Karim

On Sun, Oct 11, 2015 at 6:42 AM, Omar Andr? Gonz?les D?az <
oma.gonzales at gmail.com> wrote:

> Thanks Karim. linio.tv is in the email. In the last part.
> El oct 11, 2015 12:39 AM, "Karim Mezhoud" <kmezhoud at gmail.com> escribi?:
>
>> Hi,
>> omit unlist and test. otherwise  you can use apply function.
>>
>> draft:
>>
>> df1 <- apply(linio.tv, 1, function(x) strsplit(x[,idproductio],
>> "[^A-Z0-9-]+"))
>>
>> fct <- function(linio.tv){
>>
>>         if(any(grep("[A-Z][0-9]", linio.tv[,idx_productio]))) {
>>
>>                 linio.tv[,idx(id)] <- linio.tv[,idx_productio]
>>
>>         }
>>
>>         else {
>>                 linio.tv[,idx(id)]<- NA
>>         }
>> }
>>
>> df2 <- apply(df1, 1, function(x) fct(x))
>>
>> I can't test this draft because I have not linio.tv
>>
>>
>> Karim
>>
>>
>> for (i in 1:nrow(linio.tv)) {
>>
>>         v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
>> isolate tokens
>>
>>         if(any(grep("[A-Z][0-9]", v))) {
>>
>>                 linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>
>>         }
>>
>>         else {
>>                 linio.tv$id[i] <- NA
>>         }
>> }
>>
>> On Sun, Oct 11, 2015 at 6:07 AM, Omar Andr? Gonz?les D?az <
>> oma.gonzales at gmail.com> wrote:
>>
>>> Hi  Boris,
>>>
>>> I've modified a little the for loop to catch the IDs (if there is any)
>>> otherwise to put NAs. This is for another data set.
>>>
>>>
>>>
>>> for (i in 1:nrow(linio.tv)) {
>>>
>>>         v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
>>> isolate tokens
>>>
>>>         if(any(grep("[A-Z][0-9]", v))) {
>>>
>>>                 linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>>
>>>         }
>>>
>>>         else {
>>>                 linio.tv$id[i] <- NA
>>>         }
>>> }
>>>
>>>
>>> I get this warning messages, nevertheless the IDs column get the correct
>>> values:
>>>
>>> Warning messages:
>>> 1: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>>>   number of items to replace is not a multiple of replacement length
>>> 2: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>>>   number of items to replace is not a multiple of replacement length
>>>
>>>
>>> The problem:
>>>
>>> There are entries where the grep part is not specific enough.
>>>
>>> Like this one: "UN50JU6500-NEGRO". It satifies the rule in:
>>>
>>> linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  , but is not supposed to
>>> take
>>> also: "UN50JU6500-NEGRO" entirely, only this part: "UN50JU6500".
>>>
>>>
>>> I've noticed this rule: the IDs can have at maxium 1 letter after the
>>> "-".
>>> If it contains more than 1, that part should not be considered.
>>>
>>> "TC-L42AS610"
>>>
>>> Also IDs can start with numbers: 1,2, or 3.
>>>
>>> "KDL-40R354B"
>>>
>>>
>>>
>>>
>>> May you clarify to me if it's something that can be done within R?  I'm
>>> trying to figure this out, but with any good result.
>>>
>>> I could cleaned with "sub()" (there is only one entry giving me troubles)
>>> but the idea is not to have "technical debt" for the future.
>>>
>>>
>>>
>>>
>>> This is the new data set, I'm talking about:
>>>
>>>
>>>
>>>
>>>
>>>
>>> linio.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), marca = c("LG", "SAMSUNG",
>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>>> "SAMSUNG", "LG", "LG", "SAMSUNG", "LG", "LG", "LG", "LG", "SAMSUNG",
>>> "LG", "LG", "LG", "SONY", "SAMSUNG", "LG", "LG", "SAMSUNG", "SONY",
>>> "SAMSUNG", "LG", "LG", "LG", "IMACO", "SAMSUNG", "LG", "SAMSUNG",
>>> "SAMSUNG", "LG", "HAIER", "LG", "SONY", "SAMSUNG", "LG", "LG",
>>> "LG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "HISENSE", "LG",
>>> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "CONTINENTAL",
>>> "LG", "IMACO", "AOC", "AOC", "SAMSUNG", "LG", "SONY", "LG", "LG",
>>> "SONY", "SAMSUNG", "SAMSUNG", "PANASONIC", "LG", "SAMSUNG", "NEX",
>>> "IMACO", "LG", "LG", "CONTINENTAL", "SONY", "LG", "LG", "SAMSUNG",
>>> "LG", "LG", "LG", "LG", "LG", "SAMSUNG", "LG", "LG", "SAMSUNG",
>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "AOC", "LG", "LG",
>>> "AOC", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "LG", "LG",
>>> "SAMSUNG", "SAMSUNG", "SONY", "LG", "SAMSUNG", "SAMSUNG", "LG",
>>> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG",
>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "PANASONIC", "PANASONIC",
>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY",
>>> "LG", "LG", "PANASONIC", "AOC", "SAMSUNG", "LG", "SAMSUNG", "LG",
>>> "SAMSUNG", "LG", "LG", "LG", "PANASONIC", "PANASONIC", "LG",
>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "SAMSUNG",
>>> "LG", "LG", "SAMSUNG", "LG"), producto = c("COMBO SMART - LG TV LED 4K
>>> ULTRA HD 43'' - 43UF6750 + GOO...",
>>> "SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", "SAMSUNG TV LED 3D
>>> SMART
>>> FULL HD 48'' - 48J6400",
>>> "SAMSUNG TV LED 3D SMART FULL HD 55'' - 55J6400", "LG TV SMART LED HD
>>> 32\"
>>> 32LF585B - BLANCO",
>>> "LG TV SLIM ULTRA HD 3D WEBOS 2.0 49'' 49UF8500 - PLATEADO",
>>> "LG TV SMART WEBOS 2.0 FULL HD 43\" 43LF5900 -NEGRO", "LG TV LED HD 32\"
>>> -
>>> 32LF550B",
>>> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "LG TV  LED SMART HD
>>> 32\"
>>> - 32LF585B",
>>> "LG GAME TV LED FULL HD 49\" - 49LF5410", "SAMSUNG TV LED  FULL HD 60'' -
>>> UN60FH6003",
>>> "LG TV SMART WEBOS 2.0 FULL HD 49\" - 49LF6350", "LG TV LED  FULL HD
>>> 43'' -
>>> 43LF5410",
>>> "SAMSUNG TV SMART FULL HD CURVO 40'' TIZEN -  UN40J6500", "LG TV SMART
>>> WEBOS 2.0 ULTRA HD  4K 43\" - 43UF6400",
>>> "LG TV SLIM LED CINEMA 3D FULL HD 42'' 42LB6200 INCLUYE 02...",
>>> "LG GAMETV  LED FULL HD 43\" - 43LF5400", "LG GAME TV LED FULL HD 49\" -
>>> 49LF5410",
>>> "TELEVISOR SAMSUNG UN40J5500 SMART TV LED FULL HD 40''-PLA...",
>>> "LG SMART  4K ULTRA HD 55\" - 55UB8200", "LG -TV LED SMART WEBOS 2.0 FULL
>>> HD 55\" - 55LF6350",
>>> "LG - GAME TV LED  FULL HD 43'' - 43LF5410", "SONY - TV LED SMART HD
>>> 32'' -
>>> 32R505C",
>>> "SAMSUNG TV LED 3D SMART FULL HD 40'' - UN40H6400", "LG SMART TV 32\" HD
>>> WEBOS 2.0  32LF595B",
>>> "LG - TV LED WEBOS 3D SMART ULTRA HD CURVO  55'' 55UG8700 ...",
>>> "SAMSUNG TV LED FULL HD 40\" UN40JH5005 - NEGRO", "SONY TV LED FULL HD
>>> 40''
>>> - KDL-40R354B",
>>> "SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
>>> "LG TV LED FULL HD 42'' ULTRA SLIM 42LY340C - NEGRO", "LG TV SMART LED
>>> FULL
>>> HD 43\" - 43LF6350",
>>> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
>>> "IMACO - TV LED HD 24?? - LED24HD", "TELEVISOR SAMSUNG UN32J4300 SMART TV
>>> LED HD 32''-NEGRO",
>>> "LG TV 3D SMART LED ULTRA HD 65\" - 65UF8500", "SAMSUNG - TV LED SMART 3D
>>> 65\" FULL HD SERIE 8 INTERACTIVO...",
>>> "SAMSUNG - TV LED HD 32\"  32JH4005 - NEGRO", "LG TV 55\" SMART ULTRA HD
>>> 4K
>>> CINEMA 3D  55UB8500",
>>> "HAIER TV LED HD LIVE GREEN 24'' - 24B8000", "LG TV LED FULL HD 47'' -
>>> 47LB5610",
>>> "SONY TV LED FULL HD 32'' - KDL-32R304B", "SAMSUNG TV LED SERIE 5 FULL HD
>>> 39? - 39FH5005",
>>> "LG - TV SAMT SLIM ULTRA HD 4K WEBOS 2.0 55'' 55UF7700 - P...",
>>> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
>>> "LG TV MONITOR LED HD 23.6? - 24MT47A", "SAMSUNG - MONITOR LED 32\"
>>> MD32C -
>>> NEGRO",
>>> "TELEVISOR SAMSUNG UN40J6400 SMART TV LED 3D FULL HD 40''-...",
>>> "SAMSUNG LED SMART FULL HD 48'' - UN48J6500", "SONY - TV LED SMART FULL
>>> HD
>>> 40'' - 40R555C",
>>> "TELEVISOR HISENSE LED 40\" 40K221W SMART TV LED FULL HD", "LG TV MONITOR
>>> LED HD 23.6? - 24MT47A",
>>> "TELEVISOR SAMSUNG UN48J6400 SMART TV LED 3D FULL HD 48''-...",
>>> "LG 49UB8500 LED 49\" SMART 3D 4K", "SAMSUNG TV LED 3D SMART FULL HD 40''
>>> TIZEN UN40J6400 - NEGRO",
>>> "LG TV LED FULL HD 42\" - 42LY340C", "SAMSUNG TV LED HD 32'' UN32J4000 -
>>> NEGRO",
>>> "TELEVISOR SAMSUNG UN48J5500 SMART TV LED FULL HD 48''-PLA...",
>>> "CONTINENTAL - TV LED 15.6\" CELED95935, INCLUYE RACK", "LG TV LED 4K
>>> ULTRA
>>> HD 43\" - 43UF6750",
>>> "IMACO - TV LED HD 16?? - LED16HD", "AOC - TELEVISOR HD 32\" LE32W454F-
>>> NEGRO",
>>> "AOC TV LED HD 20\" - LE20A1140", "SAMSUNG TV LED HD 32'' - UN32J4000",
>>> "LG - TV MONITOR 27.5? - 28MT47B", "SONY TV LED FULL HD 40'' -
>>> KDL-40R354B",
>>> "LG TV MONITOR LED HD 23.6? - 24MT47A", "LG GAME TV LED FULL HD 49\" -
>>> 49LF5410",
>>> "SONY TV LED FULL HD 40'' - KDL-40R354B", "SAMSUNG - UN48J6400 LED FULL
>>> HD
>>> 48\"SMART TIZEN 3D 2015 - ...",
>>> "SAMSUNG - MONITOR FULL HD 40\" MD40C - NEGRO", "PANASONIC LED SMART FULL
>>> HD 50\" - TC-50AS600",
>>> "LG - 43LF5410 LED 43\" FULL HD GAME  - SILVER", "SAMSUNG - TELEVISOR LED
>>> HD 32\" UN32JH4005 - NEGRO",
>>> "NEX TV LED SMART HD 32\" USB WIFI INCORPORADO - LED3208SMR",
>>> "IMACO - TV LED HD 19?? - LED19HD", "LG -TV LED HG 32\" - 32LF550B",
>>> "LG - TELEVISOR LED 32\" HD 32LF550B", "CONTINENTAL - TV LED 19\"
>>> CELED99935,  INCLUYE RACK",
>>> "SONY TV LED FULL HD 40'' - KDL-40R354B", "LG - TELEVISOR LED 32\" HD
>>> SMART
>>> TV 32LF585B - BLANCO",
>>> "MONITOR TV LG 24MT47A LED HD 23.6?-PLATEADO", "TELEVISOR SAMSUNG
>>> UN32J4300
>>> SMART TV LED HD 32''-NEGRO",
>>> "LG GAME TV LED FULL HD 49\" - 49LF5400", "LG - TELEVISOR LED 32\" HD
>>> SMART
>>> TV 32LF585B ? BLANCO",
>>> "LG - TELEVISOR LED 32\" HD 32LF550B", "LG TV LED HD 32'' - 32LF550B",
>>> "LG TV LED SMART HD 32'' - 32LF585B", "SAMSUNG - TELEVISOR LED FULL HD
>>> 40\"
>>> UN40JH5005 ? NEGRO",
>>> "LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", "LG TV LED WEBOS 3D
>>> SMART ULTRA HD 49'' - 49UF8500",
>>> "SAMSUNG - TV LED SMART FULL HD 40? UN40H5500 - NEGRO", "SAMSUNG TV LED
>>> SMART HD 32'' UN32J4300 - NEGRO",
>>> "SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", "SAMSUNG -
>>> TELEVISOR LED FULL HD 40\" UN40JH5005 - NEGRO",
>>> "SAMSUNG TV LED SMART TIZEN 3D QUADCORE40\" - UN40J6400", "AOC TV LED HD
>>> 32\" - LE32W454F +RACK FIJO",
>>> "LG TV LED FULL HD 43'' - 43LF5410", "LG - TV LED WEBOS 3D SMART FULL HD
>>> 55'' - 55LF6500",
>>> "AOC 32\" LE32W454F  HD DIGITAL LED TV + HOME THEATRE F1200U",
>>> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED ALTA
>>> DEFINICI?N DTV USB 32\" - 32JH4005",
>>> "LG - 42LF6400 LED FULL HD 42'' SMART WEBOS 3D - SILVER", "TELEVISOR
>>> SAMSUNG UN48J5300 SMART TV LED FULL HD 48''-NEGRO",
>>> "SAMSUNG UN40JH5005 LED FULL HD 40\"  - NEGRO GLOSS", "LG - 24MT47A +
>>> MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...",
>>> "LG TV LED SMART 4K ULTRA HD 55\" - 55UB8200", "SAMSUNG - 55J6400 LED
>>> 55\"
>>> SMART TIZEN 3D - BLACK",
>>> "SAMSUNG TV CURVED SMART ULTRA HD 48'' TIZEN UN48JU6700 - ...",
>>> "TELEVISI?N SONY KDL-32R505C LED 32\"-NEGRO", "LG TV LED CINEMA 3D 4K
>>> SMART
>>> ULTRA HD 49'' + 02 LENTES 3D...",
>>> "SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", "SAMSUNG - 40J5500
>>> LED
>>> 40\" SMART QUADCORE / BLUETOOTH* - S...",
>>> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED
>>> SMART
>>> FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
>>> "LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 ? PLAT...",
>>> "TELEVISI?N SAMSUNG UN48J5500 LED SMART TV 48\"-PLATEADO", "LG -
>>> TELEVISOR
>>> LED 42\" FULL HD SMART TV 42LF5850 - PLATEADO",
>>> "TELEVISOR SAMSUNG  UN55JU6700 LED UHD 4K SMART 55'' - PLA...",
>>> "LG - TV LED WEBOS 3D SMART SUPER ULTRA HD 55'' - 55UF9500",
>>> "TELEVISOR SAMSUNG UN50JU6500  UHD 4K SMART 50'' - PLATEADO",
>>> "SAMSUNG - TELEVISOR LED HD 40\" SMART UN40J5500 - NEGRO", "TELEVISOR
>>> SAMSUNG UN48J6500 CURVO  FULL HD SMART 48'' - P...",
>>> "SAMSUNG - TELEVISOR LED HD 32\" SMART UN32J4300 - NEGRO", "LG TV LED
>>> CINEMA 3D 4K SMART ULTRA HD 55'' 55UB8500 - NEGRO",
>>> "TELEVISI?N PANASONIC TC-L40SV7L LED FULL-HD 40''-NEGRO", "PANASONIC TV
>>> LED
>>> 42?? FULL HD TC-L42E6L - NEGRO.",
>>> "TELEVISOR SAMSUNG UN 40JH5005 LED FULL HD", "SAMSUNG - TV LED SMART
>>> CURVO
>>> 3D ULTRA HD 65? UN65HU9000...",
>>> "SAMSUNG - UN48J5300 LED FULL HD SMART 2015 - BLACK", "SAMSUNG TV LED
>>> SMART
>>> FULL HD 50'' TIZEN UN50J5500 - PLATEADO",
>>> "SAMSUNG - TV SMART 3D FULL HD 60? UN60H7100 - NEGRO", "SONY - TELEVISOR
>>> LED SMART TV FULL HD 40'' KDL-40R555C - ...",
>>> "LG TV 47\" LED FULL HD - 47LY340C", "LG TV UHD 4K 65UB9800 SMART 3D LED
>>> TV
>>> C/WEBOS 65' LENTES 3D",
>>> "PANASONIC - TELEVISOR TC-L42AS610 LED SMART FULL HD 42?...",
>>> "AOC - TELEVISOR LED 32\" - LE32W454F", "SAMSUNG TV LED 32? -
>>> UN32FH4005G",
>>> "LG TV SMART LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED 3D SMART FULL
>>> HD
>>> 40'' TIZEN UN40J6400 - NEGRO",
>>> "LG TV SMART  LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED HD 32''
>>> UN32JH4005 - NEGRO",
>>> "LG TV PLASMA 2014 60\" FULL HD 1080P - 60PB5600", "LG TV LED CINEMA 3D
>>> SMART FULL HD 55'' 55LB7050 - PLATEADO",
>>> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "PANASONIC PUERTO USB
>>> LED
>>> 40\" - TC-L40SV7L",
>>> "PANASONIC LED SMART FULL HD 42\" - TC-L42AS610", "LG TV SMART  LED FULL
>>> HD
>>> 49\" - 49LF6350",
>>> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500-NEGRO",
>>> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500 - NEGRO",
>>> "SAMSUNG TV SMART FULL HD CURVO 48'' TIZEN UN48J6500", "SAMSUNG TV  SMART
>>> ULTRA HD 4K  65'' - UN65JU6500",
>>> "SAMSUNG UN48J5500 LED 48\" - PLATEADO", "SAMSUNG LED 32\" CONEXI?N WIFI
>>> -
>>> UN32J4300",
>>> "SAMSUNG LED SMART 40'' CONEXI?N WI-FI DIRECT - UN40J5500", "SAMSUNG LED
>>> SMART ULTRA HD 55\" - TVUN55JU6700",
>>> "SAMSUNG TV CURVED 3D SMART ULTRA HD 65'' TIZEN UN65JU7500...",
>>> "SAMSUNG TELEVISOR  HG32NB460GF, 32\" LED, HD, 1366 X 768", "LG -TV SMART
>>> LED FULL HD 55\" - 55LF6350",
>>> "SAMSUNG TV LED SMART 3D 48\" - UN48H6400", "LG LED ULTRAHD 4K 49\" SMART
>>> 3D - 49UB8300",
>>> "LG - TV LED SMART HD 32'' 32LF585B - PLATEADO", "SAMSUNG - TV LED FULL
>>> HD
>>> 40\" UN40JH5005  - NEGRO GLOSS",
>>> "LG - TV LED FULL HD 43'' 43LF5410 - PLATEADO"), precio.antes = c(2599L,
>>> 1299L, 2899L, 3999L, 1199L, 4499L, 1999L, 1099L, 2299L, 1299L,
>>> 2499L, 3999L, 2199L, 1899L, 2299L, 2299L, 1799L, 1499L, 2299L,
>>> 1999L, 3999L, 3499L, 1549L, 1299L, 2299L, 2299L, 6999L, 1499L,
>>> 1499L, 1899L, 1499L, 2099L, 6999L, 599L, 1299L, 9999L, 8999L,
>>> 999L, 5999L, 599L, 2299L, 1299L, 1499L, 4999L, 6999L, 899L, 2299L,
>>> 2499L, 3299L, 1799L, 1399L, 899L, 2499L, 4199L, 2299L, 1499L,
>>> 1099L, 2499L, 399L, 2499L, 399L, 999L, 599L, 999L, 899L, 1499L,
>>> 699L, 2299L, 1399L, 2499L, 2999L, 2499L, 1599L, 1149L, 999L,
>>> 499L, 1089L, 1099L, 499L, 1499L, 1399L, 799L, 1299L, 2499L, 1399L,
>>> 1259L, 1299L, 1299L, 1599L, 1999L, 3999L, 1999L, 1199L, 999L,
>>> 1599L, 2299L, 999L, 1499L, 3699L, 1199L, 3899L, 1099L, 2299L,
>>> 2499L, 1399L, 729L, 4199L, 3599L, 4999L, 1399L, 3999L, 4999L,
>>> 2199L, 4499L, 2299L, 1699L, 2779L, 1699L, 5799L, 8999L, 3699L,
>>> 2099L, 3299L, 1299L, 5900L, 1799L, 1799L, 1399L, 14999L, 2499L,
>>> 2799L, 6299L, 1799L, 2417L, 9500L, 1799L, 799L, 999L, 1999L,
>>> 2499L, 1899L, 999L, 2299L, 3699L, 2199L, 1699L, 1999L, 2499L,
>>> 3499L, 3899L, 2999L, 7999L, 2299L, 1299L, 2099L, 5799L, 9999L,
>>> 1110L, 3399L, 2799L, 3899L, 1299L, 1399L, 1499L), precio.nuevo = c(1799L,
>>> 999L, 2299L, 3299L, 999L, 3199L, 1499L, 849L, 1399L, 979L, 1795L,
>>> 2999L, 1899L, 1299L, 1699L, 1599L, 1499L, 1299L, 1699L, 1449L,
>>> 3699L, 2499L, 1199L, 999L, 1499L, 899L, 4999L, 1199L, 1199L,
>>> 1389L, 1299L, 1699L, 4899L, 549L, 999L, 7499L, 6700L, 849L, 4299L,
>>> 549L, 1499L, 899L, 1299L, 3599L, 5354L, 538L, 1959L, 1599L, 2999L,
>>> 1367L, 1099L, 589L, 2449L, 3199L, 1529L, 1229L, 839L, 1779L,
>>> 329L, 1799L, 389L, 719L, 489L, 849L, 799L, 1185L, 599L, 1609L,
>>> 1299L, 2179L, 2839L, 1999L, 1599L, 899L, 799L, 449L, 880L, 899L,
>>> 429L, 1275L, 1199L, 589L, 999L, 1749L, 1199L, 1099L, 899L, 989L,
>>> 1399L, 1999L, 2999L, 1599L, 999L, 819L, 1299L, 2299L, 789L, 1299L,
>>> 3199L, 977L, 3089L, 849L, 1719L, 1799L, 1399L, 569L, 3979L, 3299L,
>>> 3369L, 1093L, 3389L, 3289L, 1419L, 3429L, 1405L, 1499L, 1899L,
>>> 1499L, 5199L, 6999L, 3199L, 1599L, 2999L, 1099L, 5089L, 1459L,
>>> 1499L, 1289L, 12999L, 1739L, 2255L, 5879L, 1499L, 1929L, 8499L,
>>> 1649L, 799L, 899L, 1659L, 1749L, 1609L, 831L, 2089L, 3659L, 1769L,
>>> 1499L, 1599L, 2176L, 2749L, 2889L, 2899L, 5599L, 1899L, 1099L,
>>> 1899L, 5199L, 8589L, 990L, 3169L, 2199L, 3899L, 949L, 1099L,
>>> 1199L), dif.precios = c(800L, 300L, 600L, 700L, 200L, 1300L,
>>> 500L, 250L, 900L, 320L, 704L, 1000L, 300L, 600L, 600L, 700L,
>>> 300L, 200L, 600L, 550L, 300L, 1000L, 350L, 300L, 800L, 1400L,
>>> 2000L, 300L, 300L, 510L, 200L, 400L, 2100L, 50L, 300L, 2500L,
>>> 2299L, 150L, 1700L, 50L, 800L, 400L, 200L, 1400L, 1645L, 361L,
>>> 340L, 900L, 300L, 432L, 300L, 310L, 50L, 1000L, 770L, 270L, 260L,
>>> 720L, 70L, 700L, 10L, 280L, 110L, 150L, 100L, 314L, 100L, 690L,
>>> 100L, 320L, 160L, 500L, 0L, 250L, 200L, 50L, 209L, 200L, 70L,
>>> 224L, 200L, 210L, 300L, 750L, 200L, 160L, 400L, 310L, 200L, 0L,
>>> 1000L, 400L, 200L, 180L, 300L, 0L, 210L, 200L, 500L, 222L, 810L,
>>> 250L, 580L, 700L, 0L, 160L, 220L, 300L, 1630L, 306L, 610L, 1710L,
>>> 780L, 1070L, 894L, 200L, 880L, 200L, 600L, 2000L, 500L, 500L,
>>> 300L, 200L, 811L, 340L, 300L, 110L, 2000L, 760L, 544L, 420L,
>>> 300L, 488L, 1001L, 150L, 0L, 100L, 340L, 750L, 290L, 168L, 210L,
>>> 40L, 430L, 200L, 400L, 323L, 750L, 1010L, 100L, 2400L, 400L,
>>> 200L, 200L, 600L, 1410L, 120L, 230L, 600L, 0L, 350L, 300L, 300L
>>> ), dif.porcentual = c(30.78, 23.09, 20.7, 17.5, 16.68, 28.9,
>>> 25.01, 22.75, 39.15, 24.63, 28.17, 25.01, 13.64, 31.6, 26.1,
>>> 30.45, 16.68, 13.34, 26.1, 27.51, 7.5, 28.58, 22.6, 23.09, 34.8,
>>> 60.9, 28.58, 20.01, 20.01, 26.86, 13.34, 19.06, 30, 8.35, 23.09,
>>> 25, 25.55, 15.02, 28.34, 8.35, 34.8, 30.79, 13.34, 28.01, 23.5,
>>> 40.16, 14.79, 36.01, 9.09, 24.01, 21.44, 34.48, 2, 23.82, 33.49,
>>> 18.01, 23.66, 28.81, 17.54, 28.01, 2.51, 28.03, 18.36, 15.02,
>>> 11.12, 20.95, 14.31, 30.01, 7.15, 12.81, 5.34, 20.01, 0, 21.76,
>>> 20.02, 10.02, 19.19, 18.2, 14.03, 14.94, 14.3, 26.28, 23.09,
>>> 30.01, 14.3, 12.71, 30.79, 23.86, 12.51, 0, 25.01, 20.01, 16.68,
>>> 18.02, 18.76, 0, 21.02, 13.34, 13.52, 18.52, 20.77, 22.75, 25.23,
>>> 28.01, 0, 21.95, 5.24, 8.34, 32.61, 21.87, 15.25, 34.21, 35.47,
>>> 23.78, 38.89, 11.77, 31.67, 11.77, 10.35, 22.22, 13.52, 23.82,
>>> 9.09, 15.4, 13.75, 18.9, 16.68, 7.86, 13.33, 30.41, 19.44, 6.67,
>>> 16.68, 20.19, 10.54, 8.34, 0, 10.01, 17.01, 30.01, 15.27, 16.82,
>>> 9.13, 1.08, 19.55, 11.77, 20.01, 12.93, 21.43, 25.9, 3.33, 30,
>>> 17.4, 15.4, 9.53, 10.35, 14.1, 10.81, 6.77, 21.44, 0, 26.94,
>>> 21.44, 20.01), pulgadas = c("43", "32", "48", "55", "32", "49",
>>> "43", "32", "43", "32", "49", "60", "49", "43", "40", "43", "42",
>>> "43", "49", "40", "55", "55", "43", "32", "40", "32", "55", "40",
>>> "40", "40", "42", "43", "55", "24", "32", "65", "65", "32", "55",
>>> "24", "47", "32", "39", "55", "55", "6", "32", "40", "48", "40",
>>> "40", "6", "48", "49", "40", "42", "32", "48", "6", "43", "16",
>>> "32", "20", "32", "5", "40", "6", "49", "40", "48", "40", "50",
>>> "43", "32", "32", "19", "32", "32", "19", "40", "32", "6", "32",
>>> "49", "32", "32", "32", "32", "40", "42", "49", "40", "32", "32",
>>> "40", "40", "32", "43", "55", "32", "49", "32", "42", "48", "40",
>>> "24", "55", "55", "48", "32", "49", "55", "40", "49", "40", "42",
>>> "48", "42", "55", "55", "50", "40", "48", "32", "55", "40", "42",
>>> "NA", "65", "NA", "50", "60", "40", "47", "65", "42", "32", "32",
>>> "42", "40", "42", "32", "60", "55", "43", "40", "42", "49", "50",
>>> "50", "48", "65", "48", "32", "40", "55", "65", "32", "55", "48",
>>> "49", "32", "40", "43"), rangos = c("S/.1500 - S/.2500", "S/.500 -
>>> S/.1500",
>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.3500 - S/.4500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "> S/.4,500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>> S/.1500",
>>> "S/.1500 - S/.2500", "> S/.4,500", "S/.500 - S/.1500", "S/.500 -
>>> S/.1500",
>>> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.3500 - S/.4500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>> S/.1500",
>>> "S/.3500 - S/.4500", "> S/.4,500", "S/.500 - S/.1500", "S/.1500 -
>>> S/.2500",
>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "< S/.500", "S/.1500 - S/.2500",
>>> "< S/.500", "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
>>> S/.2500",
>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.2500 - S/.3500",
>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>> "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>> S/.1500",
>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.1500 - S/.2500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
>>> S/.2500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>> "S/.500 - S/.1500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.3500 - S/.4500", "S/.2500 - S/.3500",
>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.2500 - S/.3500",
>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>> "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>> "> S/.4,500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", "> S/.4,500",
>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500", "S/.1500 -
>>> S/.2500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.1500 - S/.2500",
>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>> "S/.2500 - S/.3500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>>> "> S/.4,500", "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 -
>>> S/.2500",
>>> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
>>> "S/.500 - S/.1500", "S/.500 - S/.1500")), .Names = c("id", "marca",
>>> "producto", "precio.antes", "precio.nuevo", "dif.precios",
>>> "dif.porcentual",
>>> "pulgadas", "rangos"), class = "data.frame", row.names = c(NA,
>>> -164L))
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> 2015-10-10 11:55 GMT-05:00 Omar Andr? Gonz?les D?az <
>>> oma.gonzales at gmail.com>
>>> :
>>>
>>> > Thank you very much to both of you. This information is very
>>> enlightening
>>> > to me.
>>> >
>>> > Cheers.
>>> >
>>> >
>>> > 2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>> >
>>> >> David answered most of this. Just a two short notes inline.
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <
>>> >> oma.gonzales at gmail.com> wrote:
>>> >>
>>> >> > David, Boris, so thankfull for your help. Both approaches are very
>>> >> good. I got this solve with David's help.
>>> >> >
>>> >> > I find very insteresting Bori's for loop. And I need a little help
>>> >> understanding the regex part on it.
>>> >> >
>>> >> > - The strsplit function: strsplit(ripley.tv$producto[i],
>>> "[^A-Z0-9-]+")
>>> >> >
>>> >> > I understand for this: split every row by a sequence of any number
>>> or
>>> >> letter or "-" that appears at leat once (+ operator).
>>> >> >
>>> >> > 1.- What does mena the "^" symbol? If you remove it, just appeare
>>> >> blanks.
>>> >> > 2.- Why is there the necessity of "+" after the closing "]"?
>>> >> >
>>> >> > 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>> >> >      Identifies also the IDs where "-" is present. Here the regex
>>> does
>>> >> not have the "-" included.
>>> >>
>>> >> Yes. I am not matching the entire token here. Note there is no "+":
>>> The
>>> >> two character-class expressions match exactly one uppercase character
>>> >> adjacent to exactly one number. If this is found in a token, grep
>>> returns
>>> >> TRUE. It doesn't matter what else the token contains - the first regex
>>> >> already took care of removing everything that's not needed. The
>>> vector of
>>> >> FALSEs and a single TRUE that grep() returns goes inside the square
>>> >> brackets, and selects the token from v.
>>> >>
>>> >>
>>> >>
>>> >> > Also, I notice that David used the "-" at the begining of the
>>> matching:
>>> >> [-A-Z0-9], without the "^" (stars with) at the beginning.
>>> >>
>>> >> This can be very confusing about regular expressions: the same
>>> character
>>> >> can mean different things depending on where it is found. Between two
>>> >> characters in a character class expresssion, the hyphen means "range".
>>> >> Elsewhere it is a literal hyphen. David put his at the beginning, I
>>> had it
>>> >> at the end (in the first regex). Another tricky character is "?"
>>> which can
>>> >> mean 0,1 matches, or turn "greedy" matching off...
>>> >>
>>> >> Online regex testers are invaluable to develop a regex - one I
>>> frequently
>>> >> use is regexpal.com
>>> >>
>>> >> Cheers,
>>> >> B.
>>> >>
>>> >>
>>> >> >
>>> >> > I would appreciate a response from you, gentlemen.
>>> >> >
>>> >> > Thanks again.
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> >
>>> >> > 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net
>>> >:
>>> >> >
>>> >> > On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
>>> >> >
>>> >> > > I think you are going into the wrong direction here and this is a
>>> >> classical example of what we mean by "technical debt" of code. Rather
>>> than
>>> >> tell to your regular expression what you are looking for, you are
>>> handling
>>> >> special cases with redundant code. This is ugly, brittle and
>>> impossible to
>>> >> maintain.
>>> >> > >
>>> >> > > Respect to you that you have recognized this.
>>> >> > >
>>> >> > >
>>> >> > > The solution is rather simple:
>>> >> > >
>>> >> > > A) Isolate tokens. Your IDs contain only a limited set of
>>> characters.
>>> >> Split your strings along the characters that are not found in IDs to
>>> >> isolate candidate tokens, place them into a vector.
>>> >> > >
>>> >> > > B) Evaluate your tokens: as far as I can see IDs all contain
>>> letters
>>> >> AND numbers. This is a unique characteristic. Thus it is sufficient
>>> to grep
>>> >> for a letter/number pair in a token to identify it as an ID.
>>> >> > >
>>> >> > > Should you ever find a need to accommodate differently formed IDs,
>>> >> there are only two, well defined places with clearly delegated roles
>>> where
>>> >> changes might be needed.
>>> >> > >
>>> >> > > Here is the code:
>>> >> > >
>>> >> > > for (i in 1:nrow(ripley.tv)) {
>>> >> > >       v <- unlist(strsplit(ripley.tv$producto[i],
>>> "[^A-Z0-9-]+")) #
>>> >> isolate tokens
>>> >> > >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs
>>> >> and store
>>> >> > > }
>>> >> >
>>> >> > That logic actually simplifies the regex strategy as well:
>>> >> >
>>> >> >  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>>> >> >  ripley.tv$producto,
>>> >> >  ignore.case = T)
>>> >> >
>>> >> >
>>> >> > Almost succeeds, with a few all-character words, but if you require
>>> one
>>> >> number in the middle you get full results:
>>> >> >
>>> >> >  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>>> >> >  ripley.tv$producto,
>>> >> >  ignore.case = T)
>>> >> >
>>> >> >  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"
>>> >>  "LE40K5000N"
>>> >> >  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"
>>>  "LE24B8000"
>>> >> > [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"
>>> "50JU6500"
>>> >> > [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"
>>> "65JS9000"
>>> >> > [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"
>>> "42LF6400"
>>> >> > [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"
>>> "49UF6750"
>>> >> > [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"
>>> "65UF7700"
>>> >> > [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"
>>> "UG8700"
>>> >> > [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B"
>>> "40J5500"
>>> >> > [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"
>>>  "40J6400"
>>> >> > [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"
>>> "43LF5410"
>>> >> > [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"
>>>  "LE40F1551"
>>> >> > [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"
>>>  "58UF8300"
>>> >> > [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C"
>>> >> "XBR-75X945C"
>>> >> > [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"
>>>  "48J5500"
>>> >> > [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"
>>> "32J4300"
>>> >> > [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"
>>> "32LF550B"
>>> >> > [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"
>>> >>  "XBR-79X905B"
>>> >> > [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"
>>> >>  "TC-42AS650L"
>>> >> > [96] "LC70LE660"   "LE58D3140"
>>> >> >
>>> >> > >
>>> >> > >
>>> >> > >
>>> >> > > Cheers,
>>> >> > > Boris
>>> >> > >
>>> >> > >
>>> >> > >
>>> >> > > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
>>> >> oma.gonzales at gmail.com> wrote:
>>> >> > >
>>> >> > >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA,
>>> NA,
>>> >> NA,
>>> >> > >>> NA, NA,
>>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA,
>>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA,
>>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA,
>>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA,
>>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>> NA,
>>> >> > >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
>>> >> > >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
>>> "HAIER",
>>> >> > >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG",
>>> "SAMSUNG",
>>> >> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>> "SAMSUNG",
>>> >> > >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG",
>>> "LG",
>>> >> > >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
>>> >> > >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG",
>>> "SAMSUNG",
>>> >> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
>>> >> "SAMSUNG",
>>> >> > >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC",
>>> >> "PANASONIC",
>>> >> > >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY",
>>> "SONY",
>>> >> > >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG",
>>> "LG",
>>> >> > >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG",
>>> >> "PANASONIC",
>>> >> > >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG",
>>> "AOC",
>>> >> > >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD
>>> 48\"
>>> >> 3D
>>> >> > >>>>> 48J6400",
>>> >> > >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40''
>>> >> TC-40CS600L",
>>> >> > >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
>>> >> > >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV
>>> LED
>>> >> FHD
>>> >> > >>> 55\" -
>>> >> > >>>>> LE55B8000",
>>> >> > >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" -
>>> >> NEGRO",
>>> >> > >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N
>>> 50\"",
>>> >> > >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48''
>>> >> 48JU6500",
>>> >> > >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD
>>> 55''
>>> >> 3D
>>> >> > >>>>> 55JS9000",
>>> >> > >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55''
>>> >> 55JU6700",
>>> >> > >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV
>>> >> ULTRA HD
>>> >> > >>> 65''
>>> >> > >>>>> 3D 65JS9000",
>>> >> > >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65''
>>> >> 65JU7500",
>>> >> > >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL
>>> HD
>>> >> > >>> 40LF6350",
>>> >> > >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD
>>> CINEMA
>>> >> 3D
>>> >> > >>>>> 42LF6450",
>>> >> > >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400
>>> 49\"
>>> >> FULL HD
>>> >> > >>>>> 3D",
>>> >> > >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K
>>> 49UF6750",
>>> >> > >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\"
>>> >> ULTRA HD
>>> >> > >>> 4K",
>>> >> > >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA
>>> 3D
>>> >> SMART
>>> >> > >>> TV
>>> >> > >>>>> 55UF7700",
>>> >> > >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\"
>>> >> ULTRA HD
>>> >> > >>> 4K
>>> >> > >>>>> 3D",
>>> >> > >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\"
>>> ULTRA
>>> >> HD 4K
>>> >> > >>> SMART
>>> >> > >>>>> TC-50CX640W",
>>> >> > >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\"
>>> ULTRA HD
>>> >> 4K
>>> >> > >>> CINEMA
>>> >> > >>>>> SMART UG8700",
>>> >> > >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\"
>>> >> FULL HD
>>> >> > >>> 3D",
>>> >> > >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
>>> >> > >>> KDL-40R354B",
>>> >> > >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD
>>> 50''
>>> >> > >>> 50J5500",
>>> >> > >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\"
>>> 50J5300",
>>> >> > >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
>>> >> > >>> 40J6400",
>>> >> > >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
>>> >> > >>> KDL-40R555C
>>> >> > >>>>> - NEGRO",
>>> >> > >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\"
>>> -
>>> >> NEGRO",
>>> >> > >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" -
>>> >> BLANCO",
>>> >> > >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD
>>> 3D
>>> >> > >>>>> KDL-65W855C",
>>> >> > >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD
>>> >> LE40F1551",
>>> >> > >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD
>>> KDL-32R304B",
>>> >> > >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD
>>> 32''
>>> >> > >>>>> LE32W454F",
>>> >> > >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD
>>> SMART
>>> >> 3D
>>> >> > >>>>> KDL-55W805C",
>>> >> > >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD
>>> 4K
>>> >> > >>>>> XBR-55X855C",
>>> >> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED
>>> 75\"
>>> >> > >>> ULTRA HD
>>> >> > >>>>> 4K 3D XBR-75X945C",
>>> >> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV
>>> >> LED 60''
>>> >> > >>>>> ULTRA HD 4K LC60UE30U",
>>> >> > >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80''
>>> >> ULTRA HD
>>> >> > >>> 4K
>>> >> > >>>>> LC80UE30U",
>>> >> > >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800
>>> 79\"
>>> >> > >>> ULTRA HD
>>> >> > >>>>> 4K 3D",
>>> >> > >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500
>>> 65\"
>>> >> ULTRA
>>> >> > >>> HD
>>> >> > >>>>> 4K 3D",
>>> >> > >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
>>> >> > >>> 32J4300",
>>> >> > >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV
>>> >> 55UG8700
>>> >> > >>> 55\"
>>> >> > >>>>> ULTRA HD 4K 3D",
>>> >> > >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500
>>> 55\"
>>> >> FULL
>>> >> > >>> HD
>>> >> > >>>>> 3D",
>>> >> > >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED
>>> >> FULL HD
>>> >> > >>> 50''
>>> >> > >>>>> TC-50AS600L",
>>> >> > >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K
>>> >> LC70SQ17U
>>> >> > >>> 70''",
>>> >> > >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
>>> >> TC-40A400L",
>>> >> > >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D
>>> CURVO
>>> >> > >>> 55HU8700",
>>> >> > >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
>>> >> TC-42AS650L",
>>> >> > >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58''
>>> LE58D3140"
>>> >> > >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
>>> >> > >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L,
>>> 65L,
>>> >> > >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L,
>>> 65L,
>>> >> > >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L,
>>> 50L,
>>> >> > >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L,
>>> 32L,
>>> >> > >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L,
>>> 80L,
>>> >> > >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L,
>>> 50L,
>>> >> > >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L),
>>> precio.antes =
>>> >> > >>> c(2799L,
>>> >> > >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L,
>>> 1899L,
>>> >> > >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L,
>>> 14999L,
>>> >> > >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L,
>>> 2299L,
>>> >> > >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L,
>>> 3999L,
>>> >> > >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L,
>>> 999L,
>>> >> > >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
>>> >> > >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
>>> >> > >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L,
>>> 14999L,
>>> >> > >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L,
>>> 7999L,
>>> >> > >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L,
>>> 13999L,
>>> >> > >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299,
>>> 1399,
>>> >> > >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
>>> >> > >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3,
>>> 5109.3,
>>> >> > >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992,
>>> 2299,
>>> >> > >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099,
>>> 3999,
>>> >> > >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599,
>>> 2999,
>>> >> > >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
>>> >> > >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
>>> >> > >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
>>> >> > >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999,
>>> 2599,
>>> >> > >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
>>> >> > >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
>>> >> > >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
>>> >> > >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
>>> >> > >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300,
>>> 100,
>>> >> > >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0,
>>> 700,
>>> >> > >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
>>> >> > >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000,
>>> 2000,
>>> >> > >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
>>> >> > >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
>>> >> > >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30,
>>> 43.22,
>>> >> > >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12,
>>> 39.48,
>>> >> > >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
>>> >> > >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
>>> >> > >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0,
>>> 11.67,
>>> >> > >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
>>> >> > >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
>>> >> > >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos =
>>> c("S/.1500 -
>>> >> > >>> S/.2500",
>>> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>> >> "S/.500 -
>>> >> > >>>>> S/.1500",
>>> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> >> > >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
>>> >> > >>> S/.2500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>> >> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", ">
>>> >> S/.4,500",
>>> >> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>> "S/.500 -
>>> >> > >>> S/.1500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500",
>>> "S/.1500 -
>>> >> > >>> S/.2500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>>> >> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 -
>>> >> S/.4500",
>>> >> > >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 -
>>> >> S/.4500",
>>> >> > >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>> >> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>> >> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>> >> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>> "S/.500 -
>>> >> > >>> S/.1500",
>>> >> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", ">
>>> >> S/.4,500",
>>> >> > >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", ">
>>> >> S/.4,500",
>>> >> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", ">
>>> >> S/.4,500",
>>> >> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>> >> > >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", ">
>>> >> S/.4,500",
>>> >> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
>>> "S/.1500 -
>>> >> > >>> S/.2500",
>>> >> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>> >> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 -
>>> >> S/.1500",
>>> >> > >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")),
>>> .Names =
>>> >> > >>> c("id",
>>> >> > >>>>> "marca", "producto", "pulgadas", "precio.antes",
>>> "precio.nuevo",
>>> >> > >>>>> "dif.precios", "dif.porcentual", "rangos"), class =
>>> "data.frame",
>>> >> > >>> row.names
>>> >> > >>>>> = c(NA,
>>> >> > >>>>> -97L))
>>> >> > >
>>> >> > > ______________________________________________
>>> >> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > > PLEASE do read the posting guide
>>> >> http://www.R-project.org/posting-guide.html
>>> >> > > and provide commented, minimal, self-contained, reproducible code.
>>> >> >
>>> >> > David Winsemius
>>> >> > Alameda, CA, USA
>>> >> >
>>> >> >
>>> >>
>>> >>
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Sun Oct 11 13:52:42 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 11 Oct 2015 13:52:42 +0200
Subject: [R] error with seq() used in for loop
Message-ID: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>

Dear All,
I have a question concerning the seq() function arguments when used in a
for() loop.
I'll simplify this question to make it more clear. Suppose I have a
(5*3)matrix s (for ex.) and I need to write a function with  for() loop, in
each step of the loop I need to generate a sequence whose upper limit is
the ith element of the first row of s, then put the resulting sequences in
a list. I used the following simple code (I've only included the first part
of the function)


> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
> simpfun<- function (x,n,m,p,alpha,beta)
+ {
+ LD<-list()
+ for (i in 1:m-1)
+ {
+ LD[[i]]<-seq(0,x[i],1)
+ }
+ print(LD)
+ }
> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
Error in seq.default(0, x[i], 1) : 'to' must be of length 1

Although x is supposed to be the vector
1 0 1
and thus x[1]=1, x[2]=0,x[3]=1.
So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to' must
be of length 1" occurs in the first place.

Thanks for helping.

Maram

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Oct 11 14:07:43 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 11 Oct 2015 08:07:43 -0400
Subject: [R] error with seq() used in for loop
In-Reply-To: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
References: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
Message-ID: <561A510F.3040604@gmail.com>

On 11/10/2015 7:52 AM, Maram SAlem wrote:
> Dear All,
> I have a question concerning the seq() function arguments when used in a
> for() loop.
> I'll simplify this question to make it more clear. Suppose I have a
> (5*3)matrix s (for ex.) and I need to write a function with  for() loop, in
> each step of the loop I need to generate a sequence whose upper limit is
> the ith element of the first row of s, then put the resulting sequences in
> a list. I used the following simple code (I've only included the first part
> of the function)
> 
> 
>> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
>> simpfun<- function (x,n,m,p,alpha,beta)
> + {
> + LD<-list()
> + for (i in 1:m-1)
> + {
> + LD[[i]]<-seq(0,x[i],1)
> + }
> + print(LD)
> + }
>> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
> Error in seq.default(0, x[i], 1) : 'to' must be of length 1
> 
> Although x is supposed to be the vector
> 1 0 1
> and thus x[1]=1, x[2]=0,x[3]=1.
> So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to' must
> be of length 1" occurs in the first place.

The range of your loop is 1:m-1, where m is 4.  That is

> m <- 4
> 1:m-1
[1] 0 1 2 3

and x[0] is length 0.

I think you wanted 1:(m-1) (or even better, seq_len(m-1)) for your loop
values.

Duncan Murdoch

> 
> Thanks for helping.
> 
> Maram
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Sun Oct 11 14:10:34 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 11 Oct 2015 14:10:34 +0200
Subject: [R] error with seq() used in for loop
In-Reply-To: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
References: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
Message-ID: <1FBAA601-DE41-42BA-8821-E30C884EB2E9@xs4all.nl>


> On 11 Oct 2015, at 13:52, Maram SAlem <marammagdysalem at gmail.com> wrote:
> 
> Dear All,
> I have a question concerning the seq() function arguments when used in a
> for() loop.
> I'll simplify this question to make it more clear. Suppose I have a
> (5*3)matrix s (for ex.) and I need to write a function with  for() loop, in
> each step of the loop I need to generate a sequence whose upper limit is
> the ith element of the first row of s, then put the resulting sequences in
> a list. I used the following simple code (I've only included the first part
> of the function)
> 
> 
>> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
>> simpfun<- function (x,n,m,p,alpha,beta)
> + {
> + LD<-list()
> + for (i in 1:m-1)
> + {
> + LD[[i]]<-seq(0,x[i],1)
> + }
> + print(LD)
> + }
>> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
> Error in seq.default(0, x[i], 1) : 'to' must be of length 1
> 
> Although x is supposed to be the vector
> 1 0 1
> and thus x[1]=1, x[2]=0,x[3]=1.
> So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to' must
> be of length 1" occurs in the first place.


Use 

for (i in 1:(m-1))

in stead of what you put in the function.
Read the section ?Generating regular sequences? in the "An Introduction to R? manual.

Berend


From marammagdysalem at gmail.com  Sun Oct 11 14:12:55 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 11 Oct 2015 14:12:55 +0200
Subject: [R] error with seq() used in for loop
In-Reply-To: <561A510F.3040604@gmail.com>
References: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
	<561A510F.3040604@gmail.com>
Message-ID: <CAPLSCn2Y3FaG8HB-B_upowp0ABCcJ6S5ZaOR_UVTf5FGZtugAQ@mail.gmail.com>

Thanks a lot  for your help and patience Duncan.
It seems that my questions is really a trivial one but I never realized
that 1:4 means 0 1 2 3 4 , never knew it starts from 0.



On 11 October 2015 at 14:07, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 11/10/2015 7:52 AM, Maram SAlem wrote:
> > Dear All,
> > I have a question concerning the seq() function arguments when used in a
> > for() loop.
> > I'll simplify this question to make it more clear. Suppose I have a
> > (5*3)matrix s (for ex.) and I need to write a function with  for() loop,
> in
> > each step of the loop I need to generate a sequence whose upper limit is
> > the ith element of the first row of s, then put the resulting sequences
> in
> > a list. I used the following simple code (I've only included the first
> part
> > of the function)
> >
> >
> >> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
> >> simpfun<- function (x,n,m,p,alpha,beta)
> > + {
> > + LD<-list()
> > + for (i in 1:m-1)
> > + {
> > + LD[[i]]<-seq(0,x[i],1)
> > + }
> > + print(LD)
> > + }
> >> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
> > Error in seq.default(0, x[i], 1) : 'to' must be of length 1
> >
> > Although x is supposed to be the vector
> > 1 0 1
> > and thus x[1]=1, x[2]=0,x[3]=1.
> > So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to'
> must
> > be of length 1" occurs in the first place.
>
> The range of your loop is 1:m-1, where m is 4.  That is
>
> > m <- 4
> > 1:m-1
> [1] 0 1 2 3
>
> and x[0] is length 0.
>
> I think you wanted 1:(m-1) (or even better, seq_len(m-1)) for your loop
> values.
>
> Duncan Murdoch
>
> >
> > Thanks for helping.
> >
> > Maram
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Sun Oct 11 14:13:57 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 11 Oct 2015 14:13:57 +0200
Subject: [R] error with seq() used in for loop
In-Reply-To: <1FBAA601-DE41-42BA-8821-E30C884EB2E9@xs4all.nl>
References: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
	<1FBAA601-DE41-42BA-8821-E30C884EB2E9@xs4all.nl>
Message-ID: <CAPLSCn1kRi3E13RwfoOYVh1z0801agxR9306bWZH4CgYuqfzvQ@mail.gmail.com>

Thanks Berend

On 11 October 2015 at 14:10, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 11 Oct 2015, at 13:52, Maram SAlem <marammagdysalem at gmail.com> wrote:
> >
> > Dear All,
> > I have a question concerning the seq() function arguments when used in a
> > for() loop.
> > I'll simplify this question to make it more clear. Suppose I have a
> > (5*3)matrix s (for ex.) and I need to write a function with  for() loop,
> in
> > each step of the loop I need to generate a sequence whose upper limit is
> > the ith element of the first row of s, then put the resulting sequences
> in
> > a list. I used the following simple code (I've only included the first
> part
> > of the function)
> >
> >
> >> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
> >> simpfun<- function (x,n,m,p,alpha,beta)
> > + {
> > + LD<-list()
> > + for (i in 1:m-1)
> > + {
> > + LD[[i]]<-seq(0,x[i],1)
> > + }
> > + print(LD)
> > + }
> >> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
> > Error in seq.default(0, x[i], 1) : 'to' must be of length 1
> >
> > Although x is supposed to be the vector
> > 1 0 1
> > and thus x[1]=1, x[2]=0,x[3]=1.
> > So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to'
> must
> > be of length 1" occurs in the first place.
>
>
> Use
>
> for (i in 1:(m-1))
>
> in stead of what you put in the function.
> Read the section ?Generating regular sequences? in the "An Introduction to
> R? manual.
>
> Berend
>
>
>

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sun Oct 11 14:20:43 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 11 Oct 2015 14:20:43 +0200
Subject: [R] error with seq() used in for loop
In-Reply-To: <CAPLSCn2Y3FaG8HB-B_upowp0ABCcJ6S5ZaOR_UVTf5FGZtugAQ@mail.gmail.com>
References: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
	<561A510F.3040604@gmail.com>
	<CAPLSCn2Y3FaG8HB-B_upowp0ABCcJ6S5ZaOR_UVTf5FGZtugAQ@mail.gmail.com>
Message-ID: <2455E30C-F0F7-4E4F-99E5-3D63111ADF60@xs4all.nl>


> On 11 Oct 2015, at 14:12, Maram SAlem <marammagdysalem at gmail.com> wrote:
> 
> Thanks a lot  for your help and patience Duncan.
> It seems that my questions is really a trivial one but I never realized
> that 1:4 means 0 1 2 3 4 , never knew it starts from 0.
> 

It doesn?t mean what you mention.

1:4 is the sequence 1 2 3 4

1:4-1 is   (1 2 3 4) -1 ==> 0 1 2 3

The 1 is subtracted from all elements of the sequence.

Berend
> 
> 
> On 11 October 2015 at 14:07, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> 
>> On 11/10/2015 7:52 AM, Maram SAlem wrote:
>>> Dear All,
>>> I have a question concerning the seq() function arguments when used in a
>>> for() loop.
>>> I'll simplify this question to make it more clear. Suppose I have a
>>> (5*3)matrix s (for ex.) and I need to write a function with  for() loop,
>> in
>>> each step of the loop I need to generate a sequence whose upper limit is
>>> the ith element of the first row of s, then put the resulting sequences
>> in
>>> a list. I used the following simple code (I've only included the first
>> part
>>> of the function)
>>> 
>>> 
>>>> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
>>>> simpfun<- function (x,n,m,p,alpha,beta)
>>> + {
>>> + LD<-list()
>>> + for (i in 1:m-1)
>>> + {
>>> + LD[[i]]<-seq(0,x[i],1)
>>> + }
>>> + print(LD)
>>> + }
>>>> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
>>> Error in seq.default(0, x[i], 1) : 'to' must be of length 1
>>> 
>>> Although x is supposed to be the vector
>>> 1 0 1
>>> and thus x[1]=1, x[2]=0,x[3]=1.
>>> So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to'
>> must
>>> be of length 1" occurs in the first place.
>> 
>> The range of your loop is 1:m-1, where m is 4.  That is
>> 
>>> m <- 4
>>> 1:m-1
>> [1] 0 1 2 3
>> 
>> and x[0] is length 0.
>> 
>> I think you wanted 1:(m-1) (or even better, seq_len(m-1)) for your loop
>> values.
>> 
>> Duncan Murdoch
>> 
>>> 
>>> Thanks for helping.
>>> 
>>> Maram
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marammagdysalem at gmail.com  Sun Oct 11 14:44:28 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 11 Oct 2015 14:44:28 +0200
Subject: [R] error with seq() used in for loop
In-Reply-To: <2455E30C-F0F7-4E4F-99E5-3D63111ADF60@xs4all.nl>
References: <CAPLSCn2g8ju6R7qDsggFaZAy1Su3tf_djrgzw36Npmv2VEgf=A@mail.gmail.com>
	<561A510F.3040604@gmail.com>
	<CAPLSCn2Y3FaG8HB-B_upowp0ABCcJ6S5ZaOR_UVTf5FGZtugAQ@mail.gmail.com>
	<2455E30C-F0F7-4E4F-99E5-3D63111ADF60@xs4all.nl>
Message-ID: <CAPLSCn3D5keyK9JUetPonP9875Me5oebho6QwAJr8tL1AsenQQ@mail.gmail.com>

I got you Berend.
Thanks again

On 11 October 2015 at 14:20, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 11 Oct 2015, at 14:12, Maram SAlem <marammagdysalem at gmail.com> wrote:
> >
> > Thanks a lot  for your help and patience Duncan.
> > It seems that my questions is really a trivial one but I never realized
> > that 1:4 means 0 1 2 3 4 , never knew it starts from 0.
> >
>
> It doesn?t mean what you mention.
>
> 1:4 is the sequence 1 2 3 4
>
> 1:4-1 is   (1 2 3 4) -1 ==> 0 1 2 3
>
> The 1 is subtracted from all elements of the sequence.
>
> Berend
> >
> >
> > On 11 October 2015 at 14:07, Duncan Murdoch <murdoch.duncan at gmail.com>
> > wrote:
> >
> >> On 11/10/2015 7:52 AM, Maram SAlem wrote:
> >>> Dear All,
> >>> I have a question concerning the seq() function arguments when used in
> a
> >>> for() loop.
> >>> I'll simplify this question to make it more clear. Suppose I have a
> >>> (5*3)matrix s (for ex.) and I need to write a function with  for()
> loop,
> >> in
> >>> each step of the loop I need to generate a sequence whose upper limit
> is
> >>> the ith element of the first row of s, then put the resulting sequences
> >> in
> >>> a list. I used the following simple code (I've only included the first
> >> part
> >>> of the function)
> >>>
> >>>
> >>>> s<-matrix(c(1,0,1,0,1,1,0,0,1,0,0,0,0,0,1),nrow=5,byrow=TRUE)
> >>>> simpfun<- function (x,n,m,p,alpha,beta)
> >>> + {
> >>> + LD<-list()
> >>> + for (i in 1:m-1)
> >>> + {
> >>> + LD[[i]]<-seq(0,x[i],1)
> >>> + }
> >>> + print(LD)
> >>> + }
> >>>> mk<-simpfun(s[1,],n=6,m=4,p=0.3)
> >>> Error in seq.default(0, x[i], 1) : 'to' must be of length 1
> >>>
> >>> Although x is supposed to be the vector
> >>> 1 0 1
> >>> and thus x[1]=1, x[2]=0,x[3]=1.
> >>> So I don't get why the error "Error in seq.default(0, x[i], 1) : 'to'
> >> must
> >>> be of length 1" occurs in the first place.
> >>
> >> The range of your loop is 1:m-1, where m is 4.  That is
> >>
> >>> m <- 4
> >>> 1:m-1
> >> [1] 0 1 2 3
> >>
> >> and x[0] is length 0.
> >>
> >> I think you wanted 1:(m-1) (or even better, seq_len(m-1)) for your loop
> >> values.
> >>
> >> Duncan Murdoch
> >>
> >>>
> >>> Thanks for helping.
> >>>
> >>> Maram
> >>>
> >>>      [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Oct 11 15:23:26 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 11 Oct 2015 09:23:26 -0400
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
	<CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
	<CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
Message-ID: <0040B355-20C8-4835-B07F-0154DC512624@utoronto.ca>

You are the domain expert, but it would seem to me that "-NEGRO" is a part of the ID because it uniquely specifies the product.

From the perspective of expressing your business logic in code, dropping this part of the string should have a separate line in the code, and a comment. Dropping the "-NEGRO" part from the token is not part of identifying the tokens. And it's not part of recognizing which token is the ID. 

The regex to identify the unwanted part is "-[A-Z]{2,}$": a literal hyphen, followed by 2 or more uppercase letters, up to the end of the token. 

I think it's great that you are introducing code that handles the case that no ID is found. Whenever you have no complete control over your input data, it's important to anticipate variations. But I would also consider the case that two tokens match the description of an ID (perhaps an "O" is mistyped as a zero). Finally, your code is correct, but you are repeating the regular expression. That is a potential source of error when anyone ever updates the regex - it violates the DRY principle: Don't Repaet Yourself. For this you have three options: either change the logic of your code to use grep only once, or assign the regex to a variable e.g. IDregEx <- "[A-Z][0-9]", or assign the result of grep() to an intermediate value. Since we want to add checks, I'll go with the latter version.

# minimal working example with test cases
mwe <- structure(list(id = c(NA, NA, NA, NA, NA, NA), marca = c("LG", 
"LG", "PANASONIC", "SONY", "LG", "LG"), producto = c("LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", 
"LG - 24MT47A + MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...", 
"TELEVISI?N PANASONIC TC-L40SV7L-NEGRO LED FULL-HD 40''", "SONY - TELEVISOR LED SMART TV FULL HD 40'' KDL-40R555C - ...", 
"LG -TV LED HG 32\" ", "LG TV LED SMART HD 32'' - 32LF585B (LIKE 32LF550B)"
)), .Names = c("id", "marca", "producto"), row.names = c(90L, 
106L, 126L, 133L, 77L, 88L), class = "data.frame")

new <- mwe
for (i in 1:nrow(mwe)) {
    v <- unlist(strsplit(mwe$producto[i], "[^A-Z0-9-]+")) # isolate tokens
    g <- grep("[A-Z][0-9]", v)
    if (length(g) == 0) {  # no token looks like an ID
    	    ID <- NA
    	    warning(paste("No ID in row ", 
    	                   i,
    	                   ": >>",
    	                   mwe$producto[i]),
    	                   "<<",
    	                   sep="") 
    }
    else if (length(g) > 1) { # more than one token looks like an ID
        ID <- NA
    	    warning(paste("More than one ID in row ", 
    	                   i,
    	                   ": >>",
    	                   mwe$producto[i]),
    	                   "<<",
    	                   sep="") 
    }
    else {
         ID <- sub("-[A-Z]{2,}$", "", v[g]) # drop trailing qualifier, if any
    }
    new$id[i] <- ID
}
new


Cheers,
Boris






On Oct 11, 2015, at 1:07 AM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:

> Hi  Boris,
> 
> I've modified a little the for loop to catch the IDs (if there is any) otherwise to put NAs. This is for another data set.
> 
> 
> 
> for (i in 1:nrow(linio.tv)) {
>         
>         v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) # isolate tokens
>         
>         if(any(grep("[A-Z][0-9]", v))) {
>                 
>                 linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  
>                 
>         }  
>         
>         else {
>                 linio.tv$id[i] <- NA
>         }
> }
> 
> 
> I get this warning messages, nevertheless the IDs column get the correct values:
> 
> Warning messages:
> 1: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>   number of items to replace is not a multiple of replacement length
> 2: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>   number of items to replace is not a multiple of replacement length
> 
> 
> The problem:
> 
> There are entries where the grep part is not specific enough. 
> 
> Like this one: "UN50JU6500-NEGRO". It satifies the rule in:
> 
> linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  , but is not supposed to take also: "UN50JU6500-NEGRO" entirely, only this part: "UN50JU6500".
> 
> 
> I've noticed this rule: the IDs can have at maxium 1 letter after the "-". If it contains more than 1, that part should not be considered.
> 
> "TC-L42AS610"
> 
> Also IDs can start with numbers: 1,2, or 3.
> 
> "KDL-40R354B"
> 
> 
> 
> 
> May you clarify to me if it's something that can be done within R?  I'm trying to figure this out, but with any good result. 
> 
> I could cleaned with "sub()" (there is only one entry giving me troubles) but the idea is not to have "technical debt" for the future.
> 
> 
> 
> 
> This is the new data set, I'm talking about:
> 
> 
> 
> 
> 
> 
> linio.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 
> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), marca = c("LG", "SAMSUNG", 
> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG", 
> "SAMSUNG", "LG", "LG", "SAMSUNG", "LG", "LG", "LG", "LG", "SAMSUNG", 
> "LG", "LG", "LG", "SONY", "SAMSUNG", "LG", "LG", "SAMSUNG", "SONY", 
> "SAMSUNG", "LG", "LG", "LG", "IMACO", "SAMSUNG", "LG", "SAMSUNG", 
> "SAMSUNG", "LG", "HAIER", "LG", "SONY", "SAMSUNG", "LG", "LG", 
> "LG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "HISENSE", "LG", 
> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "CONTINENTAL", 
> "LG", "IMACO", "AOC", "AOC", "SAMSUNG", "LG", "SONY", "LG", "LG", 
> "SONY", "SAMSUNG", "SAMSUNG", "PANASONIC", "LG", "SAMSUNG", "NEX", 
> "IMACO", "LG", "LG", "CONTINENTAL", "SONY", "LG", "LG", "SAMSUNG", 
> "LG", "LG", "LG", "LG", "LG", "SAMSUNG", "LG", "LG", "SAMSUNG", 
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "AOC", "LG", "LG", 
> "AOC", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "LG", "LG", 
> "SAMSUNG", "SAMSUNG", "SONY", "LG", "SAMSUNG", "SAMSUNG", "LG", 
> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", 
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "PANASONIC", "PANASONIC", 
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", 
> "LG", "LG", "PANASONIC", "AOC", "SAMSUNG", "LG", "SAMSUNG", "LG", 
> "SAMSUNG", "LG", "LG", "LG", "PANASONIC", "PANASONIC", "LG", 
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", 
> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "SAMSUNG", 
> "LG", "LG", "SAMSUNG", "LG"), producto = c("COMBO SMART - LG TV LED 4K ULTRA HD 43'' - 43UF6750 + GOO...", 
> "SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", "SAMSUNG TV LED 3D SMART FULL HD 48'' - 48J6400", 
> "SAMSUNG TV LED 3D SMART FULL HD 55'' - 55J6400", "LG TV SMART LED HD 32\" 32LF585B - BLANCO", 
> "LG TV SLIM ULTRA HD 3D WEBOS 2.0 49'' 49UF8500 - PLATEADO", 
> "LG TV SMART WEBOS 2.0 FULL HD 43\" 43LF5900 -NEGRO", "LG TV LED HD 32\" - 32LF550B", 
> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "LG TV  LED SMART HD 32\" - 32LF585B", 
> "LG GAME TV LED FULL HD 49\" - 49LF5410", "SAMSUNG TV LED  FULL HD 60'' - UN60FH6003", 
> "LG TV SMART WEBOS 2.0 FULL HD 49\" - 49LF6350", "LG TV LED  FULL HD 43'' - 43LF5410", 
> "SAMSUNG TV SMART FULL HD CURVO 40'' TIZEN -  UN40J6500", "LG TV SMART WEBOS 2.0 ULTRA HD  4K 43\" - 43UF6400", 
> "LG TV SLIM LED CINEMA 3D FULL HD 42'' 42LB6200 INCLUYE 02...", 
> "LG GAMETV  LED FULL HD 43\" - 43LF5400", "LG GAME TV LED FULL HD 49\" - 49LF5410", 
> "TELEVISOR SAMSUNG UN40J5500 SMART TV LED FULL HD 40''-PLA...", 
> "LG SMART  4K ULTRA HD 55\" - 55UB8200", "LG -TV LED SMART WEBOS 2.0 FULL HD 55\" - 55LF6350", 
> "LG - GAME TV LED  FULL HD 43'' - 43LF5410", "SONY - TV LED SMART HD 32'' - 32R505C", 
> "SAMSUNG TV LED 3D SMART FULL HD 40'' - UN40H6400", "LG SMART TV 32\" HD WEBOS 2.0  32LF595B", 
> "LG - TV LED WEBOS 3D SMART ULTRA HD CURVO  55'' 55UG8700 ...", 
> "SAMSUNG TV LED FULL HD 40\" UN40JH5005 - NEGRO", "SONY TV LED FULL HD 40'' - KDL-40R354B", 
> "SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO", 
> "LG TV LED FULL HD 42'' ULTRA SLIM 42LY340C - NEGRO", "LG TV SMART LED FULL HD 43\" - 43LF6350", 
> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700", 
> "IMACO - TV LED HD 24?? - LED24HD", "TELEVISOR SAMSUNG UN32J4300 SMART TV LED HD 32''-NEGRO", 
> "LG TV 3D SMART LED ULTRA HD 65\" - 65UF8500", "SAMSUNG - TV LED SMART 3D 65\" FULL HD SERIE 8 INTERACTIVO...", 
> "SAMSUNG - TV LED HD 32\"  32JH4005 - NEGRO", "LG TV 55\" SMART ULTRA HD 4K CINEMA 3D  55UB8500", 
> "HAIER TV LED HD LIVE GREEN 24'' - 24B8000", "LG TV LED FULL HD 47'' - 47LB5610", 
> "SONY TV LED FULL HD 32'' - KDL-32R304B", "SAMSUNG TV LED SERIE 5 FULL HD 39? - 39FH5005", 
> "LG - TV SAMT SLIM ULTRA HD 4K WEBOS 2.0 55'' 55UF7700 - P...", 
> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700", 
> "LG TV MONITOR LED HD 23.6? - 24MT47A", "SAMSUNG - MONITOR LED 32\" MD32C - NEGRO", 
> "TELEVISOR SAMSUNG UN40J6400 SMART TV LED 3D FULL HD 40''-...", 
> "SAMSUNG LED SMART FULL HD 48'' - UN48J6500", "SONY - TV LED SMART FULL HD 40'' - 40R555C", 
> "TELEVISOR HISENSE LED 40\" 40K221W SMART TV LED FULL HD", "LG TV MONITOR LED HD 23.6? - 24MT47A", 
> "TELEVISOR SAMSUNG UN48J6400 SMART TV LED 3D FULL HD 48''-...", 
> "LG 49UB8500 LED 49\" SMART 3D 4K", "SAMSUNG TV LED 3D SMART FULL HD 40'' TIZEN UN40J6400 - NEGRO", 
> "LG TV LED FULL HD 42\" - 42LY340C", "SAMSUNG TV LED HD 32'' UN32J4000 - NEGRO", 
> "TELEVISOR SAMSUNG UN48J5500 SMART TV LED FULL HD 48''-PLA...", 
> "CONTINENTAL - TV LED 15.6\" CELED95935, INCLUYE RACK", "LG TV LED 4K ULTRA HD 43\" - 43UF6750", 
> "IMACO - TV LED HD 16?? - LED16HD", "AOC - TELEVISOR HD 32\" LE32W454F- NEGRO", 
> "AOC TV LED HD 20\" - LE20A1140", "SAMSUNG TV LED HD 32'' - UN32J4000", 
> "LG - TV MONITOR 27.5? - 28MT47B", "SONY TV LED FULL HD 40'' - KDL-40R354B", 
> "LG TV MONITOR LED HD 23.6? - 24MT47A", "LG GAME TV LED FULL HD 49\" - 49LF5410", 
> "SONY TV LED FULL HD 40'' - KDL-40R354B", "SAMSUNG - UN48J6400 LED FULL HD 48\"SMART TIZEN 3D 2015 - ...", 
> "SAMSUNG - MONITOR FULL HD 40\" MD40C - NEGRO", "PANASONIC LED SMART FULL HD 50\" - TC-50AS600", 
> "LG - 43LF5410 LED 43\" FULL HD GAME  - SILVER", "SAMSUNG - TELEVISOR LED HD 32\" UN32JH4005 - NEGRO", 
> "NEX TV LED SMART HD 32\" USB WIFI INCORPORADO - LED3208SMR", 
> "IMACO - TV LED HD 19?? - LED19HD", "LG -TV LED HG 32\" - 32LF550B", 
> "LG - TELEVISOR LED 32\" HD 32LF550B", "CONTINENTAL - TV LED 19\" CELED99935,  INCLUYE RACK", 
> "SONY TV LED FULL HD 40'' - KDL-40R354B", "LG - TELEVISOR LED 32\" HD SMART TV 32LF585B - BLANCO", 
> "MONITOR TV LG 24MT47A LED HD 23.6?-PLATEADO", "TELEVISOR SAMSUNG UN32J4300 SMART TV LED HD 32''-NEGRO", 
> "LG GAME TV LED FULL HD 49\" - 49LF5400", "LG - TELEVISOR LED 32\" HD SMART TV 32LF585B ? BLANCO", 
> "LG - TELEVISOR LED 32\" HD 32LF550B", "LG TV LED HD 32'' - 32LF550B", 
> "LG TV LED SMART HD 32'' - 32LF585B", "SAMSUNG - TELEVISOR LED FULL HD 40\" UN40JH5005 ? NEGRO", 
> "LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", 
> "SAMSUNG - TV LED SMART FULL HD 40? UN40H5500 - NEGRO", "SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", 
> "SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", "SAMSUNG - TELEVISOR LED FULL HD 40\" UN40JH5005 - NEGRO", 
> "SAMSUNG TV LED SMART TIZEN 3D QUADCORE40\" - UN40J6400", "AOC TV LED HD 32\" - LE32W454F +RACK FIJO", 
> "LG TV LED FULL HD 43'' - 43LF5410", "LG - TV LED WEBOS 3D SMART FULL HD 55'' - 55LF6500", 
> "AOC 32\" LE32W454F  HD DIGITAL LED TV + HOME THEATRE F1200U", 
> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", 
> "LG - 42LF6400 LED FULL HD 42'' SMART WEBOS 3D - SILVER", "TELEVISOR SAMSUNG UN48J5300 SMART TV LED FULL HD 48''-NEGRO", 
> "SAMSUNG UN40JH5005 LED FULL HD 40\"  - NEGRO GLOSS", "LG - 24MT47A + MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...", 
> "LG TV LED SMART 4K ULTRA HD 55\" - 55UB8200", "SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", 
> "SAMSUNG TV CURVED SMART ULTRA HD 48'' TIZEN UN48JU6700 - ...", 
> "TELEVISI?N SONY KDL-32R505C LED 32\"-NEGRO", "LG TV LED CINEMA 3D 4K SMART ULTRA HD 49'' + 02 LENTES 3D...", 
> "SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", "SAMSUNG - 40J5500 LED 40\" SMART QUADCORE / BLUETOOTH* - S...", 
> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO", 
> "LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 ? PLAT...", 
> "TELEVISI?N SAMSUNG UN48J5500 LED SMART TV 48\"-PLATEADO", "LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 - PLATEADO", 
> "TELEVISOR SAMSUNG  UN55JU6700 LED UHD 4K SMART 55'' - PLA...", 
> "LG - TV LED WEBOS 3D SMART SUPER ULTRA HD 55'' - 55UF9500", 
> "TELEVISOR SAMSUNG UN50JU6500  UHD 4K SMART 50'' - PLATEADO", 
> "SAMSUNG - TELEVISOR LED HD 40\" SMART UN40J5500 - NEGRO", "TELEVISOR SAMSUNG UN48J6500 CURVO  FULL HD SMART 48'' - P...", 
> "SAMSUNG - TELEVISOR LED HD 32\" SMART UN32J4300 - NEGRO", "LG TV LED CINEMA 3D 4K SMART ULTRA HD 55'' 55UB8500 - NEGRO", 
> "TELEVISI?N PANASONIC TC-L40SV7L LED FULL-HD 40''-NEGRO", "PANASONIC TV LED 42?? FULL HD TC-L42E6L - NEGRO.", 
> "TELEVISOR SAMSUNG UN 40JH5005 LED FULL HD", "SAMSUNG - TV LED SMART CURVO 3D ULTRA HD 65? UN65HU9000...", 
> "SAMSUNG - UN48J5300 LED FULL HD SMART 2015 - BLACK", "SAMSUNG TV LED SMART FULL HD 50'' TIZEN UN50J5500 - PLATEADO", 
> "SAMSUNG - TV SMART 3D FULL HD 60? UN60H7100 - NEGRO", "SONY - TELEVISOR LED SMART TV FULL HD 40'' KDL-40R555C - ...", 
> "LG TV 47\" LED FULL HD - 47LY340C", "LG TV UHD 4K 65UB9800 SMART 3D LED TV C/WEBOS 65' LENTES 3D", 
> "PANASONIC - TELEVISOR TC-L42AS610 LED SMART FULL HD 42?...", 
> "AOC - TELEVISOR LED 32\" - LE32W454F", "SAMSUNG TV LED 32? - UN32FH4005G", 
> "LG TV SMART LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED 3D SMART FULL HD 40'' TIZEN UN40J6400 - NEGRO", 
> "LG TV SMART  LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED HD 32'' UN32JH4005 - NEGRO", 
> "LG TV PLASMA 2014 60\" FULL HD 1080P - 60PB5600", "LG TV LED CINEMA 3D SMART FULL HD 55'' 55LB7050 - PLATEADO", 
> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "PANASONIC PUERTO USB LED 40\" - TC-L40SV7L", 
> "PANASONIC LED SMART FULL HD 42\" - TC-L42AS610", "LG TV SMART  LED FULL HD 49\" - 49LF6350", 
> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500-NEGRO", 
> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500 - NEGRO", 
> "SAMSUNG TV SMART FULL HD CURVO 48'' TIZEN UN48J6500", "SAMSUNG TV  SMART ULTRA HD 4K  65'' - UN65JU6500", 
> "SAMSUNG UN48J5500 LED 48\" - PLATEADO", "SAMSUNG LED 32\" CONEXI?N WIFI - UN32J4300", 
> "SAMSUNG LED SMART 40'' CONEXI?N WI-FI DIRECT - UN40J5500", "SAMSUNG LED SMART ULTRA HD 55\" - TVUN55JU6700", 
> "SAMSUNG TV CURVED 3D SMART ULTRA HD 65'' TIZEN UN65JU7500...", 
> "SAMSUNG TELEVISOR  HG32NB460GF, 32\" LED, HD, 1366 X 768", "LG -TV SMART LED FULL HD 55\" - 55LF6350", 
> "SAMSUNG TV LED SMART 3D 48\" - UN48H6400", "LG LED ULTRAHD 4K 49\" SMART 3D - 49UB8300", 
> "LG - TV LED SMART HD 32'' 32LF585B - PLATEADO", "SAMSUNG - TV LED FULL HD 40\" UN40JH5005  - NEGRO GLOSS", 
> "LG - TV LED FULL HD 43'' 43LF5410 - PLATEADO"), precio.antes = c(2599L, 
> 1299L, 2899L, 3999L, 1199L, 4499L, 1999L, 1099L, 2299L, 1299L, 
> 2499L, 3999L, 2199L, 1899L, 2299L, 2299L, 1799L, 1499L, 2299L, 
> 1999L, 3999L, 3499L, 1549L, 1299L, 2299L, 2299L, 6999L, 1499L, 
> 1499L, 1899L, 1499L, 2099L, 6999L, 599L, 1299L, 9999L, 8999L, 
> 999L, 5999L, 599L, 2299L, 1299L, 1499L, 4999L, 6999L, 899L, 2299L, 
> 2499L, 3299L, 1799L, 1399L, 899L, 2499L, 4199L, 2299L, 1499L, 
> 1099L, 2499L, 399L, 2499L, 399L, 999L, 599L, 999L, 899L, 1499L, 
> 699L, 2299L, 1399L, 2499L, 2999L, 2499L, 1599L, 1149L, 999L, 
> 499L, 1089L, 1099L, 499L, 1499L, 1399L, 799L, 1299L, 2499L, 1399L, 
> 1259L, 1299L, 1299L, 1599L, 1999L, 3999L, 1999L, 1199L, 999L, 
> 1599L, 2299L, 999L, 1499L, 3699L, 1199L, 3899L, 1099L, 2299L, 
> 2499L, 1399L, 729L, 4199L, 3599L, 4999L, 1399L, 3999L, 4999L, 
> 2199L, 4499L, 2299L, 1699L, 2779L, 1699L, 5799L, 8999L, 3699L, 
> 2099L, 3299L, 1299L, 5900L, 1799L, 1799L, 1399L, 14999L, 2499L, 
> 2799L, 6299L, 1799L, 2417L, 9500L, 1799L, 799L, 999L, 1999L, 
> 2499L, 1899L, 999L, 2299L, 3699L, 2199L, 1699L, 1999L, 2499L, 
> 3499L, 3899L, 2999L, 7999L, 2299L, 1299L, 2099L, 5799L, 9999L, 
> 1110L, 3399L, 2799L, 3899L, 1299L, 1399L, 1499L), precio.nuevo = c(1799L, 
> 999L, 2299L, 3299L, 999L, 3199L, 1499L, 849L, 1399L, 979L, 1795L, 
> 2999L, 1899L, 1299L, 1699L, 1599L, 1499L, 1299L, 1699L, 1449L, 
> 3699L, 2499L, 1199L, 999L, 1499L, 899L, 4999L, 1199L, 1199L, 
> 1389L, 1299L, 1699L, 4899L, 549L, 999L, 7499L, 6700L, 849L, 4299L, 
> 549L, 1499L, 899L, 1299L, 3599L, 5354L, 538L, 1959L, 1599L, 2999L, 
> 1367L, 1099L, 589L, 2449L, 3199L, 1529L, 1229L, 839L, 1779L, 
> 329L, 1799L, 389L, 719L, 489L, 849L, 799L, 1185L, 599L, 1609L, 
> 1299L, 2179L, 2839L, 1999L, 1599L, 899L, 799L, 449L, 880L, 899L, 
> 429L, 1275L, 1199L, 589L, 999L, 1749L, 1199L, 1099L, 899L, 989L, 
> 1399L, 1999L, 2999L, 1599L, 999L, 819L, 1299L, 2299L, 789L, 1299L, 
> 3199L, 977L, 3089L, 849L, 1719L, 1799L, 1399L, 569L, 3979L, 3299L, 
> 3369L, 1093L, 3389L, 3289L, 1419L, 3429L, 1405L, 1499L, 1899L, 
> 1499L, 5199L, 6999L, 3199L, 1599L, 2999L, 1099L, 5089L, 1459L, 
> 1499L, 1289L, 12999L, 1739L, 2255L, 5879L, 1499L, 1929L, 8499L, 
> 1649L, 799L, 899L, 1659L, 1749L, 1609L, 831L, 2089L, 3659L, 1769L, 
> 1499L, 1599L, 2176L, 2749L, 2889L, 2899L, 5599L, 1899L, 1099L, 
> 1899L, 5199L, 8589L, 990L, 3169L, 2199L, 3899L, 949L, 1099L, 
> 1199L), dif.precios = c(800L, 300L, 600L, 700L, 200L, 1300L, 
> 500L, 250L, 900L, 320L, 704L, 1000L, 300L, 600L, 600L, 700L, 
> 300L, 200L, 600L, 550L, 300L, 1000L, 350L, 300L, 800L, 1400L, 
> 2000L, 300L, 300L, 510L, 200L, 400L, 2100L, 50L, 300L, 2500L, 
> 2299L, 150L, 1700L, 50L, 800L, 400L, 200L, 1400L, 1645L, 361L, 
> 340L, 900L, 300L, 432L, 300L, 310L, 50L, 1000L, 770L, 270L, 260L, 
> 720L, 70L, 700L, 10L, 280L, 110L, 150L, 100L, 314L, 100L, 690L, 
> 100L, 320L, 160L, 500L, 0L, 250L, 200L, 50L, 209L, 200L, 70L, 
> 224L, 200L, 210L, 300L, 750L, 200L, 160L, 400L, 310L, 200L, 0L, 
> 1000L, 400L, 200L, 180L, 300L, 0L, 210L, 200L, 500L, 222L, 810L, 
> 250L, 580L, 700L, 0L, 160L, 220L, 300L, 1630L, 306L, 610L, 1710L, 
> 780L, 1070L, 894L, 200L, 880L, 200L, 600L, 2000L, 500L, 500L, 
> 300L, 200L, 811L, 340L, 300L, 110L, 2000L, 760L, 544L, 420L, 
> 300L, 488L, 1001L, 150L, 0L, 100L, 340L, 750L, 290L, 168L, 210L, 
> 40L, 430L, 200L, 400L, 323L, 750L, 1010L, 100L, 2400L, 400L, 
> 200L, 200L, 600L, 1410L, 120L, 230L, 600L, 0L, 350L, 300L, 300L
> ), dif.porcentual = c(30.78, 23.09, 20.7, 17.5, 16.68, 28.9, 
> 25.01, 22.75, 39.15, 24.63, 28.17, 25.01, 13.64, 31.6, 26.1, 
> 30.45, 16.68, 13.34, 26.1, 27.51, 7.5, 28.58, 22.6, 23.09, 34.8, 
> 60.9, 28.58, 20.01, 20.01, 26.86, 13.34, 19.06, 30, 8.35, 23.09, 
> 25, 25.55, 15.02, 28.34, 8.35, 34.8, 30.79, 13.34, 28.01, 23.5, 
> 40.16, 14.79, 36.01, 9.09, 24.01, 21.44, 34.48, 2, 23.82, 33.49, 
> 18.01, 23.66, 28.81, 17.54, 28.01, 2.51, 28.03, 18.36, 15.02, 
> 11.12, 20.95, 14.31, 30.01, 7.15, 12.81, 5.34, 20.01, 0, 21.76, 
> 20.02, 10.02, 19.19, 18.2, 14.03, 14.94, 14.3, 26.28, 23.09, 
> 30.01, 14.3, 12.71, 30.79, 23.86, 12.51, 0, 25.01, 20.01, 16.68, 
> 18.02, 18.76, 0, 21.02, 13.34, 13.52, 18.52, 20.77, 22.75, 25.23, 
> 28.01, 0, 21.95, 5.24, 8.34, 32.61, 21.87, 15.25, 34.21, 35.47, 
> 23.78, 38.89, 11.77, 31.67, 11.77, 10.35, 22.22, 13.52, 23.82, 
> 9.09, 15.4, 13.75, 18.9, 16.68, 7.86, 13.33, 30.41, 19.44, 6.67, 
> 16.68, 20.19, 10.54, 8.34, 0, 10.01, 17.01, 30.01, 15.27, 16.82, 
> 9.13, 1.08, 19.55, 11.77, 20.01, 12.93, 21.43, 25.9, 3.33, 30, 
> 17.4, 15.4, 9.53, 10.35, 14.1, 10.81, 6.77, 21.44, 0, 26.94, 
> 21.44, 20.01), pulgadas = c("43", "32", "48", "55", "32", "49", 
> "43", "32", "43", "32", "49", "60", "49", "43", "40", "43", "42", 
> "43", "49", "40", "55", "55", "43", "32", "40", "32", "55", "40", 
> "40", "40", "42", "43", "55", "24", "32", "65", "65", "32", "55", 
> "24", "47", "32", "39", "55", "55", "6", "32", "40", "48", "40", 
> "40", "6", "48", "49", "40", "42", "32", "48", "6", "43", "16", 
> "32", "20", "32", "5", "40", "6", "49", "40", "48", "40", "50", 
> "43", "32", "32", "19", "32", "32", "19", "40", "32", "6", "32", 
> "49", "32", "32", "32", "32", "40", "42", "49", "40", "32", "32", 
> "40", "40", "32", "43", "55", "32", "49", "32", "42", "48", "40", 
> "24", "55", "55", "48", "32", "49", "55", "40", "49", "40", "42", 
> "48", "42", "55", "55", "50", "40", "48", "32", "55", "40", "42", 
> "NA", "65", "NA", "50", "60", "40", "47", "65", "42", "32", "32", 
> "42", "40", "42", "32", "60", "55", "43", "40", "42", "49", "50", 
> "50", "48", "65", "48", "32", "40", "55", "65", "32", "55", "48", 
> "49", "32", "40", "43"), rangos = c("S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500", 
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.3500 - S/.4500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "> S/.4,500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "S/.1500 - S/.2500", "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.3500 - S/.4500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "S/.3500 - S/.4500", "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "< S/.500", "S/.1500 - S/.2500", 
> "< S/.500", "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.2500 - S/.3500", 
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.1500 - S/.2500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.2500 - S/.3500", 
> "S/.500 - S/.1500", "S/.2500 - S/.3500", "S/.500 - S/.1500", 
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.3500 - S/.4500", "S/.2500 - S/.3500", 
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500", 
> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.2500 - S/.3500", 
> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500", 
> "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", 
> "> S/.4,500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", "> S/.4,500", 
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500", "S/.1500 - S/.2500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500", 
> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.1500 - S/.2500", 
> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", 
> "S/.2500 - S/.3500", "S/.2500 - S/.3500", "S/.2500 - S/.3500", 
> "> S/.4,500", "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500", 
> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.2500 - S/.3500", 
> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.500 - S/.1500", 
> "S/.500 - S/.1500", "S/.500 - S/.1500")), .Names = c("id", "marca", 
> "producto", "precio.antes", "precio.nuevo", "dif.precios", "dif.porcentual", 
> "pulgadas", "rangos"), class = "data.frame", row.names = c(NA, 
> -164L))
> 
> 
> 
> 
> 
> 
> 
> 
> 2015-10-10 11:55 GMT-05:00 Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com>:
> Thank you very much to both of you. This information is very enlightening to me.
> 
> Cheers.
> 
> 
> 2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:
> David answered most of this. Just a two short notes inline.
> 
> 
> 
> 
> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:
> 
> > David, Boris, so thankfull for your help. Both approaches are very good. I got this solve with David's help.
> >
> > I find very insteresting Bori's for loop. And I need a little help understanding the regex part on it.
> >
> > - The strsplit function: strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")
> >
> > I understand for this: split every row by a sequence of any number or letter or "-" that appears at leat once (+ operator).
> >
> > 1.- What does mena the "^" symbol? If you remove it, just appeare blanks.
> > 2.- Why is there the necessity of "+" after the closing "]"?
> >
> > 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
> >      Identifies also the IDs where "-" is present. Here the regex does not have the "-" included.
> 
> Yes. I am not matching the entire token here. Note there is no "+": The two character-class expressions match exactly one uppercase character adjacent to exactly one number. If this is found in a token, grep returns TRUE. It doesn't matter what else the token contains - the first regex already took care of removing everything that's not needed. The vector of FALSEs and a single TRUE that grep() returns goes inside the square brackets, and selects the token from v.
> 
> 
> 
> > Also, I notice that David used the "-" at the begining of the matching: [-A-Z0-9], without the "^" (stars with) at the beginning.
> 
> This can be very confusing about regular expressions: the same character can mean different things depending on where it is found. Between two characters in a character class expresssion, the hyphen means "range". Elsewhere it is a literal hyphen. David put his at the beginning, I had it at the end (in the first regex). Another tricky character is "?" which can mean 0,1 matches, or turn "greedy" matching off...
> 
> Online regex testers are invaluable to develop a regex - one I frequently use is regexpal.com
> 
> Cheers,
> B.
> 
> 
> >
> > I would appreciate a response from you, gentlemen.
> >
> > Thanks again.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net>:
> >
> > On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
> >
> > > I think you are going into the wrong direction here and this is a classical example of what we mean by "technical debt" of code. Rather than tell to your regular expression what you are looking for, you are handling special cases with redundant code. This is ugly, brittle and impossible to maintain.
> > >
> > > Respect to you that you have recognized this.
> > >
> > >
> > > The solution is rather simple:
> > >
> > > A) Isolate tokens. Your IDs contain only a limited set of characters. Split your strings along the characters that are not found in IDs to isolate candidate tokens, place them into a vector.
> > >
> > > B) Evaluate your tokens: as far as I can see IDs all contain letters AND numbers. This is a unique characteristic. Thus it is sufficient to grep for a letter/number pair in a token to identify it as an ID.
> > >
> > > Should you ever find a need to accommodate differently formed IDs, there are only two, well defined places with clearly delegated roles where changes might be needed.
> > >
> > > Here is the code:
> > >
> > > for (i in 1:nrow(ripley.tv)) {
> > >       v <- unlist(strsplit(ripley.tv$producto[i], "[^A-Z0-9-]+")) # isolate tokens
> > >       ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs and store
> > > }
> >
> > That logic actually simplifies the regex strategy as well:
> >
> >  sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T)
> >
> >
> > Almost succeeds, with a few all-character words, but if you require one number in the middle you get full results:
> >
> >  sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
> >  ripley.tv$producto,
> >  ignore.case = T)
> >
> >  [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"   "LE40K5000N"
> >  [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"   "LE24B8000"
> > [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"    "50JU6500"
> > [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"    "65JS9000"
> > [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"    "42LF6400"
> > [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"    "49UF6750"
> > [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"    "65UF7700"
> > [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"    "UG8700"
> > [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B" "40J5500"
> > [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"     "40J6400"
> > [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"    "43LF5410"
> > [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"   "LE40F1551"
> > [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"   "58UF8300"
> > [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C" "XBR-75X945C"
> > [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"   "48J5500"
> > [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"    "32J4300"
> > [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"    "32LF550B"
> > [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"   "XBR-79X905B"
> > [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"   "TC-42AS650L"
> > [96] "LC70LE660"   "LE58D3140"
> >
> > >
> > >
> > >
> > > Cheers,
> > > Boris
> > >
> > >
> > >
> > > On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <oma.gonzales at gmail.com> wrote:
> > >
> > >>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA,
> > >>> NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
> > >>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
> > >>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
> > >>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
> > >>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
> > >>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
> > >>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG", "SAMSUNG",
> > >>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY", "SAMSUNG",
> > >>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC", "PANASONIC",
> > >>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY", "SONY",
> > >>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG", "LG",
> > >>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG", "PANASONIC",
> > >>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG", "AOC",
> > >>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD 48\" 3D
> > >>>>> 48J6400",
> > >>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40'' TC-40CS600L",
> > >>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
> > >>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV LED FHD
> > >>> 55\" -
> > >>>>> LE55B8000",
> > >>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" - NEGRO",
> > >>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N 50\"",
> > >>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48'' 48JU6500",
> > >>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD 55'' 3D
> > >>>>> 55JS9000",
> > >>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55'' 55JU6700",
> > >>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV ULTRA HD
> > >>> 65''
> > >>>>> 3D 65JS9000",
> > >>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65'' 65JU7500",
> > >>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL HD
> > >>> 40LF6350",
> > >>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD CINEMA 3D
> > >>>>> 42LF6450",
> > >>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400 49\" FULL HD
> > >>>>> 3D",
> > >>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K 49UF6750",
> > >>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\" ULTRA HD
> > >>> 4K",
> > >>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA 3D SMART
> > >>> TV
> > >>>>> 55UF7700",
> > >>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\" ULTRA HD
> > >>> 4K
> > >>>>> 3D",
> > >>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\" ULTRA HD 4K
> > >>> SMART
> > >>>>> TC-50CX640W",
> > >>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\" ULTRA HD 4K
> > >>> CINEMA
> > >>>>> SMART UG8700",
> > >>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\" FULL HD
> > >>> 3D",
> > >>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
> > >>> KDL-40R354B",
> > >>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD 50''
> > >>> 50J5500",
> > >>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\" 50J5300",
> > >>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
> > >>> 40J6400",
> > >>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
> > >>> KDL-40R555C
> > >>>>> - NEGRO",
> > >>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\" - NEGRO",
> > >>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" - BLANCO",
> > >>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD 3D
> > >>>>> KDL-65W855C",
> > >>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD LE40F1551",
> > >>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD KDL-32R304B",
> > >>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD 32''
> > >>>>> LE32W454F",
> > >>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD SMART 3D
> > >>>>> KDL-55W805C",
> > >>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD 4K
> > >>>>> XBR-55X855C",
> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED 75\"
> > >>> ULTRA HD
> > >>>>> 4K 3D XBR-75X945C",
> > >>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV LED 60''
> > >>>>> ULTRA HD 4K LC60UE30U",
> > >>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80'' ULTRA HD
> > >>> 4K
> > >>>>> LC80UE30U",
> > >>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800 79\"
> > >>> ULTRA HD
> > >>>>> 4K 3D",
> > >>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500 65\" ULTRA
> > >>> HD
> > >>>>> 4K 3D",
> > >>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
> > >>> 32J4300",
> > >>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV 55UG8700
> > >>> 55\"
> > >>>>> ULTRA HD 4K 3D",
> > >>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500 55\" FULL
> > >>> HD
> > >>>>> 3D",
> > >>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED FULL HD
> > >>> 50''
> > >>>>> TC-50AS600L",
> > >>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K LC70SQ17U
> > >>> 70''",
> > >>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40'' TC-40A400L",
> > >>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D CURVO
> > >>> 55HU8700",
> > >>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\" TC-42AS650L",
> > >>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58'' LE58D3140"
> > >>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
> > >>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L, 65L,
> > >>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L, 65L,
> > >>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L, 50L,
> > >>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L, 32L,
> > >>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L, 80L,
> > >>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L, 50L,
> > >>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L), precio.antes =
> > >>> c(2799L,
> > >>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L, 1899L,
> > >>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L, 14999L,
> > >>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L, 2299L,
> > >>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L, 3999L,
> > >>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L, 999L,
> > >>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
> > >>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
> > >>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L, 14999L,
> > >>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L, 7999L,
> > >>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L, 13999L,
> > >>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299, 1399,
> > >>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
> > >>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3, 5109.3,
> > >>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992, 2299,
> > >>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099, 3999,
> > >>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599, 2999,
> > >>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
> > >>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
> > >>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
> > >>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999, 2599,
> > >>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
> > >>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
> > >>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
> > >>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
> > >>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300, 100,
> > >>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0, 700,
> > >>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
> > >>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000, 2000,
> > >>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
> > >>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
> > >>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30, 43.22,
> > >>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12, 39.48,
> > >>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
> > >>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
> > >>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0, 11.67,
> > >>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
> > >>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
> > >>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos = c("S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
> > >>>>> S/.1500",
> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", "> S/.4,500",
> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "S/.500 -
> > >>> S/.1500",
> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500", "S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 - S/.4500",
> > >>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 - S/.4500",
> > >>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
> > >>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
> > >>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
> > >>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 -
> > >>> S/.1500",
> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", "> S/.4,500",
> > >>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", "> S/.4,500",
> > >>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > >>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500",
> > >>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500", "S/.1500 -
> > >>> S/.2500",
> > >>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
> > >>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500",
> > >>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")), .Names =
> > >>> c("id",
> > >>>>> "marca", "producto", "pulgadas", "precio.antes", "precio.nuevo",
> > >>>>> "dif.precios", "dif.porcentual", "rangos"), class = "data.frame",
> > >>> row.names
> > >>>>> = c(NA,
> > >>>>> -97L))
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> >
> 
> 
> 


From caciquesamurai at gmail.com  Sun Oct 11 17:10:50 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Sun, 11 Oct 2015 12:10:50 -0300
Subject: [R] Data-frame selection
In-Reply-To: <BA5732EC-367C-4479-82F3-2091E3400B37@gmail.com>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
	<6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
	<CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>
	<BDA1F67B-BB01-4302-B489-466DADC2D3DE@gmail.com>
	<alpine.BSF.2.00.1510101651560.67112@pedal.dcn.davis.ca.us>
	<BA5732EC-367C-4479-82F3-2091E3400B37@gmail.com>
Message-ID: <CAGtwFe2zj3y5ds6XueiCcr7Thd0wSqu9HLcNbUL+bzWeo7NExQ@mail.gmail.com>

Hi Peter and Jeff!

Thanks very much for your code! Both worked perfectly in my data set!!

All best,

Raoni

2015-10-10 21:40 GMT-03:00 peter dalgaard <pdalgd at gmail.com>:
>
>> On 11 Oct 2015, at 02:12 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> Sorry I missed the boat the first time, and while it looks like Peter is getting closer I suspect that is not quite there either due to the T2 being considered separate from T3 requirement.
>
> Er, what do you mean by that?
>
> As far as I can tell, we're selecting the same observations:
>
>> teste[kp,]
>    ID Group  Var
> 1   3    T2 0.32
> 2   4    T3 1.59
> 3   1    T2 2.94
> 4   1    T2 3.23
> 5   1    T2 1.40
> 6   1    T2 1.62
> 7   1    T2 2.43
> 8   1    T2 2.53
> 9   1    T2 2.25
> 10  1    T3 1.66
> 11  1    T3 2.86
> 12  1    T3 0.53
> 13  1    T3 1.66
> 14  1    T3 3.24
> 15  1    T3 1.34
> 21  2    T2 2.00
> 22  2    T2 2.39
> 23  2    T2 1.65
> 24  2    T2 2.05
> 25  2    T2 2.75
> 26  2    T2 2.23
> 27  2    T2 1.39
> 28  2    T2 2.66
> 29  2    T2 1.05
> 30  2    T3 2.52
>
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>



-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From marammagdysalem at gmail.com  Sun Oct 11 18:52:05 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 11 Oct 2015 18:52:05 +0200
Subject: [R] using the apply() family to evaluate nested functions with
	common arguments
Message-ID: <CAPLSCn1wJctk+fx7ar-idcaGK7M=++RPHdv1hMzUpcLq4UTkMg@mail.gmail.com>

Dear All,

I'm trying to use the apply family to evaluate 2 nested functions whose
arguments are somewhat overlapping. I'm doing this in order to evaluate
nested multiple summations in a certain equation. First, I created the s
matrix whose rows satisfy some logical condition.

n=8

m=4

D<-matrix(0,nrow=n-m+1,ncol=m-1)

for (i in 1:m-1)

 {

D[,i]<-seq(0,n-m,1)

 }

ED <- do.call(`expand.grid`,as.data.frame(D))

ED<-as.matrix(ED)

lk<-which(rowSums(ED)<=(n-m))

s<-ED[lk,]


Then, I'm trying to evaluate a function called simpfun for each row of s,
which could be easily done using the apply () function. The problem is that
within the simpfun I need to evaluate another function, incomb(). This
function has to be first evaluated for each row of the matrix LED, whose
elements are sequences having the corresponding elements of each row of s
as their upper limits.


simpfun<- function (x,n,m,p,alpha,beta)

  {

  a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))

  b<- vector(mode = "numeric", length = m-1)

  for ( i in 1:m-1)

   {

   b[i]<- (m-i)

   }

  c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))-sum(b%*%x)))

  d <-vector(mode = "numeric", length = m-1)

   for (i in 1:m-1)

   {

   d[i]<- n- (sum(x[(1):(i)])) - i

   }

  e<- n*(prod(d))*c

  LD<-list()

   for (i in 1:(m-1))

   {

   LD[[i]]<-seq(0,x[i],1)

   }

   LD[[m]]<-seq(0,(n-m-sum(x)),1)

   LED<-expand.grid (LD)

   LED<-as.matrix(LED)

     incomb<-function(x,alpha,beta) {


g<-((-1)^(sum(LED[1,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))

             fd<-
choose(x[1],LED[1,1])*choose(x[2],LED[1,2])*choose(x[3],LED[1,3])

          return (g)

      }



}



where my x in the simpfun() refers to one of the rows of the s matrix, so
that I'll be able to use something like


va<-apply(s,1,simpfun,n=,m=,p=,alpha=,beta=)



to apply it to each row of s.



The problem now is that for each row of s (which is supposed to be my x in
the simpfun()) ,I need to first apply the incomb() function for all the
rows of LED.Thus, I need to modify what I wrote above in the body of the
incomb() function in terms of something like y instead of LED[1,], so that
I can again use the apply() function on all its rows first for one row of s
,say x, and then repeat this for all the other rows of s. I can't figure
out how to do this while still having the rows of s, say x, as one of the
arguments of the incomb() function for which I'm going to use the apply()
function once more.


I'm sorry if what I'm asking for is not that clear, but I'm trying to
simplfy things as much as possible so that we don't go into tedious detalis.


Thanks a lot in advance.


Maram Salem

	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Sun Oct 11 21:10:14 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sun, 11 Oct 2015 21:10:14 +0200
Subject: [R] Parsing XML File
Message-ID: <20151011191014.GA8883@localhost.localdomain>

Dear All,
I am struggling with the parsing of the xml file you can find at

https://www.dropbox.com/s/i4ld5qa26hwrhj7/account.xml?dl=0

Essentially, I would like to be able to convert it to a data.frame to
manipulate it in R and detect all the attributes of an account for
which  unrealizedPNL goes above a threshold.
I stored that file as account.xml and looking here and there on the
web I put together the following script


#####################################################################
library(XML)

xmlfile=xmlParse("account.xml")

class(xmlfile) #"XMLInternalDocument" "XMLAbstractDocument"
xmltop = xmlRoot(xmlfile) #gives content of root
class(xmltop)#"XMLInternalElementNode" "XMLInternalNode"
"XMLAbstractNode"
xmlName(xmltop) #give name of node, PubmedArticleSet
xmlSize(xmltop) #how many children in node, 19
xmlName(xmltop[[1]]) #name of root's children

# have a look at the content of the first child entry
xmltop[[1]]
# have a look at the content of the 2nd child entry
xmltop[[2]]
#Root Node's children
number <- xmlSize(xmltop[[1]]) #number of nodes in each child
name <- xmlSApply(xmltop[[1]], xmlName) #name(s)
attribute <- xmlSApply(xmltop[[1]], xmlAttrs) #attribute(s)
size <- xmlSApply(xmltop[[1]], xmlSize) #size


values <- xmlSApply(xmltop, function(x) xmlSApply(x, xmlValue))
#####################################################################

which is leading me nowhere.
Any suggestion is appreciated.
Cheers

Lorenzo


From jdnewmil at dcn.davis.CA.us  Sun Oct 11 21:53:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 11 Oct 2015 12:53:37 -0700
Subject: [R] Data-frame selection
In-Reply-To: <BA5732EC-367C-4479-82F3-2091E3400B37@gmail.com>
References: <CAGtwFe1Yxpben-Zz5OXiff=VLJH_hUVAZ2uAFfm8bsodMJi2zg@mail.gmail.com>
	<6305619A-8678-4E98-B002-F0E4052AF8C3@dcn.davis.CA.us>
	<CAGtwFe3RiMGvPZN4w4-a4JNBXN+2vOB-qwX2DPqXCXEqcKm-DA@mail.gmail.com>
	<BDA1F67B-BB01-4302-B489-466DADC2D3DE@gmail.com>
	<alpine.BSF.2.00.1510101651560.67112@pedal.dcn.davis.ca.us>
	<BA5732EC-367C-4479-82F3-2091E3400B37@gmail.com>
Message-ID: <EC426731-19E1-4347-BF90-BA739F7F2BAC@dcn.davis.CA.us>

Sorry, looked like there were a different number of rows in the results because the rownames were different. I also see that the OP was interested in any Groups, not just the two in the example, so your solution probably meets the requirements better than mine 

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 10, 2015 5:40:37 PM PDT, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 11 Oct 2015, at 02:12 , Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>> 
>> Sorry I missed the boat the first time, and while it looks like Peter
>is getting closer I suspect that is not quite there either due to the
>T2 being considered separate from T3 requirement.
>
>Er, what do you mean by that? 
>
>As far as I can tell, we're selecting the same observations:
>
>> teste[kp,]
>   ID Group  Var
>1   3    T2 0.32
>2   4    T3 1.59
>3   1    T2 2.94
>4   1    T2 3.23
>5   1    T2 1.40
>6   1    T2 1.62
>7   1    T2 2.43
>8   1    T2 2.53
>9   1    T2 2.25
>10  1    T3 1.66
>11  1    T3 2.86
>12  1    T3 0.53
>13  1    T3 1.66
>14  1    T3 3.24
>15  1    T3 1.34
>21  2    T2 2.00
>22  2    T2 2.39
>23  2    T2 1.65
>24  2    T2 2.05
>25  2    T2 2.75
>26  2    T2 2.23
>27  2    T2 1.39
>28  2    T2 2.66
>29  2    T2 1.05
>30  2    T3 2.52


From jholtman at gmail.com  Sun Oct 11 21:54:10 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 11 Oct 2015 15:54:10 -0400
Subject: [R] Parsing XML File
In-Reply-To: <20151011191014.GA8883@localhost.localdomain>
References: <20151011191014.GA8883@localhost.localdomain>
Message-ID: <CAAxdm-7iGOYTGG0TSUZNn+JyjaJfQ_rB3AoqpxG3RTBV_yGbbw@mail.gmail.com>

Not sure exactly what you want since you did not show an expected output,
but this will extract the attributes from AccVal in the structure:

> #####################################################################
>  library(XML)
>
>  xmlfile=xmlParse("/temp/account.xml")
>
>  class(xmlfile) #"XMLInternalDocument" "XMLAbstractDocument"
[1] "XMLInternalDocument" "XMLAbstractDocument"
>  xmltop = xmlRoot(xmlfile) #gives content of root
>
>  #####  try this  ##############
>
>  accts <- sapply(getNodeSet(xmltop, "//AccVal"), xmlAttrs)
>
>  # create data.frame
>  accts_df <- as.data.frame(t(accts), stringsAsFactors = FALSE)
>  str(accts_df)
'data.frame':   364 obs. of  4 variables:
 $ key        : chr  "AccountCode" "AccountReady" "AccountType"
"AccruedCash" ...
 $ val        : chr  "DU108063" "true" "CORPORATION" "0" ...
 $ currency   : chr  "" "" "" "AUD" ...
 $ accountName: chr  "DU108063" "DU108063" "DU108063" "DU108063" ...
>  head(accts_df)
           key         val currency accountName
1  AccountCode    DU108063             DU108063
2 AccountReady        true             DU108063
3  AccountType CORPORATION             DU108063
4  AccruedCash           0      AUD    DU108063
5  AccruedCash           0     BASE    DU108063
6  AccruedCash           0      CAD    DU108063
>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Oct 11, 2015 at 3:10 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> I am struggling with the parsing of the xml file you can find at
>
> https://www.dropbox.com/s/i4ld5qa26hwrhj7/account.xml?dl=0
>
> Essentially, I would like to be able to convert it to a data.frame to
> manipulate it in R and detect all the attributes of an account for
> which  unrealizedPNL goes above a threshold.
> I stored that file as account.xml and looking here and there on the
> web I put together the following script
>
>
> #####################################################################
> library(XML)
>
> xmlfile=xmlParse("account.xml")
>
> class(xmlfile) #"XMLInternalDocument" "XMLAbstractDocument"
> xmltop = xmlRoot(xmlfile) #gives content of root
> class(xmltop)#"XMLInternalElementNode" "XMLInternalNode"
> "XMLAbstractNode"
> xmlName(xmltop) #give name of node, PubmedArticleSet
> xmlSize(xmltop) #how many children in node, 19
> xmlName(xmltop[[1]]) #name of root's children
>
> # have a look at the content of the first child entry
> xmltop[[1]]
> # have a look at the content of the 2nd child entry
> xmltop[[2]]
> #Root Node's children
> number <- xmlSize(xmltop[[1]]) #number of nodes in each child
> name <- xmlSApply(xmltop[[1]], xmlName) #name(s)
> attribute <- xmlSApply(xmltop[[1]], xmlAttrs) #attribute(s)
> size <- xmlSApply(xmltop[[1]], xmlSize) #size
>
>
> values <- xmlSApply(xmltop, function(x) xmlSApply(x, xmlValue))
> #####################################################################
>
> which is leading me nowhere.
> Any suggestion is appreciated.
> Cheers
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Oct 12 00:29:30 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 11 Oct 2015 15:29:30 -0700
Subject: [R] Regex: Combining sub/grepl with ifelse
In-Reply-To: <CALJKBv_BYcKXiu8qQdPpkB-9HmBvkLaRpXvg9ww1S_DOVbV51w@mail.gmail.com>
References: <CAM-xyZhi2NkDT50Q5K5F0yUNcAE5vmS9C9U53TX+JkKzKtfwjw@mail.gmail.com>
	<326DA280-EC09-45C3-8BF0-FFE3A75380EB@comcast.net>
	<CAM-xyZigE4qJZvwLqF20h2wkyk0yg+WfOZWQAyXFU-KeH9_kKA@mail.gmail.com>
	<F0542B08-EF04-4FC8-977C-ECEB50D0E963@comcast.net>
	<CAM-xyZim81KTQ8dGhJovTrzEGEhjPZ=n09rZj53sREVNDBdmrA@mail.gmail.com>
	<FADCE4DB-699E-4699-929C-E548B7DF308D@utoronto.ca>
	<D40BCD29-4730-4522-B1F0-6BDC549C286F@comcast.net>
	<CAM-xyZhjNau3DrVyq1MXAGQd1p60B9HwewR0TMM9RjdOccSUww@mail.gmail.com>
	<217E3480-D879-44C3-BFCB-4919B09E6033@utoronto.ca>
	<CAM-xyZgZ=mPwhhJuKR5MBV_QKifvAr8C5RBPWdGnfzTJXbFFCw@mail.gmail.com>
	<CAM-xyZgPLAvejNW1uW8Ct4GjcY2+-u-LSQ4kXPeRm_QWPUHo7g@mail.gmail.com>
	<CALJKBv_isbZarbg5Tdi085XTbmTkTjm9j7szWAALo8_cEY1eiQ@mail.gmail.com>
	<CAM-xyZgh2fkNoBGN+2qwVBWnFwcbYRYGNzx_UR912Y7XmmZ60Q@mail.gmail.com>
	<CALJKBv_BYcKXiu8qQdPpkB-9HmBvkLaRpXvg9ww1S_DOVbV51w@mail.gmail.com>
Message-ID: <39C8E240-9436-4D4F-86C9-C50028524F9B@comcast.net>


On Oct 10, 2015, at 10:57 PM, Karim Mezhoud wrote:

> My code is not correct.
> The idea is to use apply instead of a loop. more efficiency.

There is no increased efficiency in using apply. Both `apply` and a `for` loop will perform with equal efficiency. The only advantage is the mental clarity that might result.

-- 
David.


> Karim
> 
> On Sun, Oct 11, 2015 at 6:42 AM, Omar Andr? Gonz?les D?az <
> oma.gonzales at gmail.com> wrote:
> 
>> Thanks Karim. linio.tv is in the email. In the last part.
>> El oct 11, 2015 12:39 AM, "Karim Mezhoud" <kmezhoud at gmail.com> escribi?:
>> 
>>> Hi,
>>> omit unlist and test. otherwise  you can use apply function.
>>> 
>>> draft:
>>> 
>>> df1 <- apply(linio.tv, 1, function(x) strsplit(x[,idproductio],
>>> "[^A-Z0-9-]+"))
>>> 
>>> fct <- function(linio.tv){
>>> 
>>>        if(any(grep("[A-Z][0-9]", linio.tv[,idx_productio]))) {
>>> 
>>>                linio.tv[,idx(id)] <- linio.tv[,idx_productio]
>>> 
>>>        }
>>> 
>>>        else {
>>>                linio.tv[,idx(id)]<- NA
>>>        }
>>> }
>>> 
>>> df2 <- apply(df1, 1, function(x) fct(x))
>>> 
>>> I can't test this draft because I have not linio.tv
>>> 
>>> 
>>> Karim
>>> 
>>> 
>>> for (i in 1:nrow(linio.tv)) {
>>> 
>>>        v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
>>> isolate tokens
>>> 
>>>        if(any(grep("[A-Z][0-9]", v))) {
>>> 
>>>                linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>> 
>>>        }
>>> 
>>>        else {
>>>                linio.tv$id[i] <- NA
>>>        }
>>> }
>>> 
>>> On Sun, Oct 11, 2015 at 6:07 AM, Omar Andr? Gonz?les D?az <
>>> oma.gonzales at gmail.com> wrote:
>>> 
>>>> Hi  Boris,
>>>> 
>>>> I've modified a little the for loop to catch the IDs (if there is any)
>>>> otherwise to put NAs. This is for another data set.
>>>> 
>>>> 
>>>> 
>>>> for (i in 1:nrow(linio.tv)) {
>>>> 
>>>>        v <- unlist(strsplit(linio.tv$producto[i], "[^A-Z0-9-]+")) #
>>>> isolate tokens
>>>> 
>>>>        if(any(grep("[A-Z][0-9]", v))) {
>>>> 
>>>>                linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>>> 
>>>>        }
>>>> 
>>>>        else {
>>>>                linio.tv$id[i] <- NA
>>>>        }
>>>> }
>>>> 
>>>> 
>>>> I get this warning messages, nevertheless the IDs column get the correct
>>>> values:
>>>> 
>>>> Warning messages:
>>>> 1: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>>>>  number of items to replace is not a multiple of replacement length
>>>> 2: In linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)] :
>>>>  number of items to replace is not a multiple of replacement length
>>>> 
>>>> 
>>>> The problem:
>>>> 
>>>> There are entries where the grep part is not specific enough.
>>>> 
>>>> Like this one: "UN50JU6500-NEGRO". It satifies the rule in:
>>>> 
>>>> linio.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  , but is not supposed to
>>>> take
>>>> also: "UN50JU6500-NEGRO" entirely, only this part: "UN50JU6500".
>>>> 
>>>> 
>>>> I've noticed this rule: the IDs can have at maxium 1 letter after the
>>>> "-".
>>>> If it contains more than 1, that part should not be considered.
>>>> 
>>>> "TC-L42AS610"
>>>> 
>>>> Also IDs can start with numbers: 1,2, or 3.
>>>> 
>>>> "KDL-40R354B"
>>>> 
>>>> 
>>>> 
>>>> 
>>>> May you clarify to me if it's something that can be done within R?  I'm
>>>> trying to figure this out, but with any good result.
>>>> 
>>>> I could cleaned with "sub()" (there is only one entry giving me troubles)
>>>> but the idea is not to have "technical debt" for the future.
>>>> 
>>>> 
>>>> 
>>>> 
>>>> This is the new data set, I'm talking about:
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> linio.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA), marca = c("LG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG", "LG",
>>>> "SAMSUNG", "LG", "LG", "SAMSUNG", "LG", "LG", "LG", "LG", "SAMSUNG",
>>>> "LG", "LG", "LG", "SONY", "SAMSUNG", "LG", "LG", "SAMSUNG", "SONY",
>>>> "SAMSUNG", "LG", "LG", "LG", "IMACO", "SAMSUNG", "LG", "SAMSUNG",
>>>> "SAMSUNG", "LG", "HAIER", "LG", "SONY", "SAMSUNG", "LG", "LG",
>>>> "LG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "HISENSE", "LG",
>>>> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "CONTINENTAL",
>>>> "LG", "IMACO", "AOC", "AOC", "SAMSUNG", "LG", "SONY", "LG", "LG",
>>>> "SONY", "SAMSUNG", "SAMSUNG", "PANASONIC", "LG", "SAMSUNG", "NEX",
>>>> "IMACO", "LG", "LG", "CONTINENTAL", "SONY", "LG", "LG", "SAMSUNG",
>>>> "LG", "LG", "LG", "LG", "LG", "SAMSUNG", "LG", "LG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "AOC", "LG", "LG",
>>>> "AOC", "LG", "SAMSUNG", "LG", "SAMSUNG", "SAMSUNG", "LG", "LG",
>>>> "SAMSUNG", "SAMSUNG", "SONY", "LG", "SAMSUNG", "SAMSUNG", "LG",
>>>> "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG", "LG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "PANASONIC", "PANASONIC",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY",
>>>> "LG", "LG", "PANASONIC", "AOC", "SAMSUNG", "LG", "SAMSUNG", "LG",
>>>> "SAMSUNG", "LG", "LG", "LG", "PANASONIC", "PANASONIC", "LG",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "LG", "SAMSUNG",
>>>> "LG", "LG", "SAMSUNG", "LG"), producto = c("COMBO SMART - LG TV LED 4K
>>>> ULTRA HD 43'' - 43UF6750 + GOO...",
>>>> "SAMSUNG TV LED SMART HD 32'' UN32J4300 - NEGRO", "SAMSUNG TV LED 3D
>>>> SMART
>>>> FULL HD 48'' - 48J6400",
>>>> "SAMSUNG TV LED 3D SMART FULL HD 55'' - 55J6400", "LG TV SMART LED HD
>>>> 32\"
>>>> 32LF585B - BLANCO",
>>>> "LG TV SLIM ULTRA HD 3D WEBOS 2.0 49'' 49UF8500 - PLATEADO",
>>>> "LG TV SMART WEBOS 2.0 FULL HD 43\" 43LF5900 -NEGRO", "LG TV LED HD 32\"
>>>> -
>>>> 32LF550B",
>>>> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "LG TV  LED SMART HD
>>>> 32\"
>>>> - 32LF585B",
>>>> "LG GAME TV LED FULL HD 49\" - 49LF5410", "SAMSUNG TV LED  FULL HD 60'' -
>>>> UN60FH6003",
>>>> "LG TV SMART WEBOS 2.0 FULL HD 49\" - 49LF6350", "LG TV LED  FULL HD
>>>> 43'' -
>>>> 43LF5410",
>>>> "SAMSUNG TV SMART FULL HD CURVO 40'' TIZEN -  UN40J6500", "LG TV SMART
>>>> WEBOS 2.0 ULTRA HD  4K 43\" - 43UF6400",
>>>> "LG TV SLIM LED CINEMA 3D FULL HD 42'' 42LB6200 INCLUYE 02...",
>>>> "LG GAMETV  LED FULL HD 43\" - 43LF5400", "LG GAME TV LED FULL HD 49\" -
>>>> 49LF5410",
>>>> "TELEVISOR SAMSUNG UN40J5500 SMART TV LED FULL HD 40''-PLA...",
>>>> "LG SMART  4K ULTRA HD 55\" - 55UB8200", "LG -TV LED SMART WEBOS 2.0 FULL
>>>> HD 55\" - 55LF6350",
>>>> "LG - GAME TV LED  FULL HD 43'' - 43LF5410", "SONY - TV LED SMART HD
>>>> 32'' -
>>>> 32R505C",
>>>> "SAMSUNG TV LED 3D SMART FULL HD 40'' - UN40H6400", "LG SMART TV 32\" HD
>>>> WEBOS 2.0  32LF595B",
>>>> "LG - TV LED WEBOS 3D SMART ULTRA HD CURVO  55'' 55UG8700 ...",
>>>> "SAMSUNG TV LED FULL HD 40\" UN40JH5005 - NEGRO", "SONY TV LED FULL HD
>>>> 40''
>>>> - KDL-40R354B",
>>>> "SAMSUNG TV LED SMART FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
>>>> "LG TV LED FULL HD 42'' ULTRA SLIM 42LY340C - NEGRO", "LG TV SMART LED
>>>> FULL
>>>> HD 43\" - 43LF6350",
>>>> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
>>>> "IMACO - TV LED HD 24?? - LED24HD", "TELEVISOR SAMSUNG UN32J4300 SMART TV
>>>> LED HD 32''-NEGRO",
>>>> "LG TV 3D SMART LED ULTRA HD 65\" - 65UF8500", "SAMSUNG - TV LED SMART 3D
>>>> 65\" FULL HD SERIE 8 INTERACTIVO...",
>>>> "SAMSUNG - TV LED HD 32\"  32JH4005 - NEGRO", "LG TV 55\" SMART ULTRA HD
>>>> 4K
>>>> CINEMA 3D  55UB8500",
>>>> "HAIER TV LED HD LIVE GREEN 24'' - 24B8000", "LG TV LED FULL HD 47'' -
>>>> 47LB5610",
>>>> "SONY TV LED FULL HD 32'' - KDL-32R304B", "SAMSUNG TV LED SERIE 5 FULL HD
>>>> 39? - 39FH5005",
>>>> "LG - TV SAMT SLIM ULTRA HD 4K WEBOS 2.0 55'' 55UF7700 - P...",
>>>> "LG TV LED CURVO 55\" SMART ULTRA HD 4K CINEMA 3D - 55UC9700",
>>>> "LG TV MONITOR LED HD 23.6? - 24MT47A", "SAMSUNG - MONITOR LED 32\"
>>>> MD32C -
>>>> NEGRO",
>>>> "TELEVISOR SAMSUNG UN40J6400 SMART TV LED 3D FULL HD 40''-...",
>>>> "SAMSUNG LED SMART FULL HD 48'' - UN48J6500", "SONY - TV LED SMART FULL
>>>> HD
>>>> 40'' - 40R555C",
>>>> "TELEVISOR HISENSE LED 40\" 40K221W SMART TV LED FULL HD", "LG TV MONITOR
>>>> LED HD 23.6? - 24MT47A",
>>>> "TELEVISOR SAMSUNG UN48J6400 SMART TV LED 3D FULL HD 48''-...",
>>>> "LG 49UB8500 LED 49\" SMART 3D 4K", "SAMSUNG TV LED 3D SMART FULL HD 40''
>>>> TIZEN UN40J6400 - NEGRO",
>>>> "LG TV LED FULL HD 42\" - 42LY340C", "SAMSUNG TV LED HD 32'' UN32J4000 -
>>>> NEGRO",
>>>> "TELEVISOR SAMSUNG UN48J5500 SMART TV LED FULL HD 48''-PLA...",
>>>> "CONTINENTAL - TV LED 15.6\" CELED95935, INCLUYE RACK", "LG TV LED 4K
>>>> ULTRA
>>>> HD 43\" - 43UF6750",
>>>> "IMACO - TV LED HD 16?? - LED16HD", "AOC - TELEVISOR HD 32\" LE32W454F-
>>>> NEGRO",
>>>> "AOC TV LED HD 20\" - LE20A1140", "SAMSUNG TV LED HD 32'' - UN32J4000",
>>>> "LG - TV MONITOR 27.5? - 28MT47B", "SONY TV LED FULL HD 40'' -
>>>> KDL-40R354B",
>>>> "LG TV MONITOR LED HD 23.6? - 24MT47A", "LG GAME TV LED FULL HD 49\" -
>>>> 49LF5410",
>>>> "SONY TV LED FULL HD 40'' - KDL-40R354B", "SAMSUNG - UN48J6400 LED FULL
>>>> HD
>>>> 48\"SMART TIZEN 3D 2015 - ...",
>>>> "SAMSUNG - MONITOR FULL HD 40\" MD40C - NEGRO", "PANASONIC LED SMART FULL
>>>> HD 50\" - TC-50AS600",
>>>> "LG - 43LF5410 LED 43\" FULL HD GAME  - SILVER", "SAMSUNG - TELEVISOR LED
>>>> HD 32\" UN32JH4005 - NEGRO",
>>>> "NEX TV LED SMART HD 32\" USB WIFI INCORPORADO - LED3208SMR",
>>>> "IMACO - TV LED HD 19?? - LED19HD", "LG -TV LED HG 32\" - 32LF550B",
>>>> "LG - TELEVISOR LED 32\" HD 32LF550B", "CONTINENTAL - TV LED 19\"
>>>> CELED99935,  INCLUYE RACK",
>>>> "SONY TV LED FULL HD 40'' - KDL-40R354B", "LG - TELEVISOR LED 32\" HD
>>>> SMART
>>>> TV 32LF585B - BLANCO",
>>>> "MONITOR TV LG 24MT47A LED HD 23.6?-PLATEADO", "TELEVISOR SAMSUNG
>>>> UN32J4300
>>>> SMART TV LED HD 32''-NEGRO",
>>>> "LG GAME TV LED FULL HD 49\" - 49LF5400", "LG - TELEVISOR LED 32\" HD
>>>> SMART
>>>> TV 32LF585B ? BLANCO",
>>>> "LG - TELEVISOR LED 32\" HD 32LF550B", "LG TV LED HD 32'' - 32LF550B",
>>>> "LG TV LED SMART HD 32'' - 32LF585B", "SAMSUNG - TELEVISOR LED FULL HD
>>>> 40\"
>>>> UN40JH5005 ? NEGRO",
>>>> "LG LED FULL HD SMART TV 42''42LF5850 - PLATEADO", "LG TV LED WEBOS 3D
>>>> SMART ULTRA HD 49'' - 49UF8500",
>>>> "SAMSUNG - TV LED SMART FULL HD 40? UN40H5500 - NEGRO", "SAMSUNG TV LED
>>>> SMART HD 32'' UN32J4300 - NEGRO",
>>>> "SAMSUNG TV LED ALTA DEFINICI?N DTV USB 32\" - 32JH4005", "SAMSUNG -
>>>> TELEVISOR LED FULL HD 40\" UN40JH5005 - NEGRO",
>>>> "SAMSUNG TV LED SMART TIZEN 3D QUADCORE40\" - UN40J6400", "AOC TV LED HD
>>>> 32\" - LE32W454F +RACK FIJO",
>>>> "LG TV LED FULL HD 43'' - 43LF5410", "LG - TV LED WEBOS 3D SMART FULL HD
>>>> 55'' - 55LF6500",
>>>> "AOC 32\" LE32W454F  HD DIGITAL LED TV + HOME THEATRE F1200U",
>>>> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED ALTA
>>>> DEFINICI?N DTV USB 32\" - 32JH4005",
>>>> "LG - 42LF6400 LED FULL HD 42'' SMART WEBOS 3D - SILVER", "TELEVISOR
>>>> SAMSUNG UN48J5300 SMART TV LED FULL HD 48''-NEGRO",
>>>> "SAMSUNG UN40JH5005 LED FULL HD 40\"  - NEGRO GLOSS", "LG - 24MT47A +
>>>> MONITOR TV 24\" PUERTOS HDMI, USB, AV - NEG...",
>>>> "LG TV LED SMART 4K ULTRA HD 55\" - 55UB8200", "SAMSUNG - 55J6400 LED
>>>> 55\"
>>>> SMART TIZEN 3D - BLACK",
>>>> "SAMSUNG TV CURVED SMART ULTRA HD 48'' TIZEN UN48JU6700 - ...",
>>>> "TELEVISI?N SONY KDL-32R505C LED 32\"-NEGRO", "LG TV LED CINEMA 3D 4K
>>>> SMART
>>>> ULTRA HD 49'' + 02 LENTES 3D...",
>>>> "SAMSUNG - 55J6400 LED 55\" SMART TIZEN 3D - BLACK", "SAMSUNG - 40J5500
>>>> LED
>>>> 40\" SMART QUADCORE / BLUETOOTH* - S...",
>>>> "LG TV LED WEBOS 3D SMART ULTRA HD 49'' - 49UF8500", "SAMSUNG TV LED
>>>> SMART
>>>> FULL HD 40'' TIZEN UN40J5500 - PLATEADO",
>>>> "LG - TELEVISOR LED 42\" FULL HD SMART TV 42LF5850 ? PLAT...",
>>>> "TELEVISI?N SAMSUNG UN48J5500 LED SMART TV 48\"-PLATEADO", "LG -
>>>> TELEVISOR
>>>> LED 42\" FULL HD SMART TV 42LF5850 - PLATEADO",
>>>> "TELEVISOR SAMSUNG  UN55JU6700 LED UHD 4K SMART 55'' - PLA...",
>>>> "LG - TV LED WEBOS 3D SMART SUPER ULTRA HD 55'' - 55UF9500",
>>>> "TELEVISOR SAMSUNG UN50JU6500  UHD 4K SMART 50'' - PLATEADO",
>>>> "SAMSUNG - TELEVISOR LED HD 40\" SMART UN40J5500 - NEGRO", "TELEVISOR
>>>> SAMSUNG UN48J6500 CURVO  FULL HD SMART 48'' - P...",
>>>> "SAMSUNG - TELEVISOR LED HD 32\" SMART UN32J4300 - NEGRO", "LG TV LED
>>>> CINEMA 3D 4K SMART ULTRA HD 55'' 55UB8500 - NEGRO",
>>>> "TELEVISI?N PANASONIC TC-L40SV7L LED FULL-HD 40''-NEGRO", "PANASONIC TV
>>>> LED
>>>> 42?? FULL HD TC-L42E6L - NEGRO.",
>>>> "TELEVISOR SAMSUNG UN 40JH5005 LED FULL HD", "SAMSUNG - TV LED SMART
>>>> CURVO
>>>> 3D ULTRA HD 65? UN65HU9000...",
>>>> "SAMSUNG - UN48J5300 LED FULL HD SMART 2015 - BLACK", "SAMSUNG TV LED
>>>> SMART
>>>> FULL HD 50'' TIZEN UN50J5500 - PLATEADO",
>>>> "SAMSUNG - TV SMART 3D FULL HD 60? UN60H7100 - NEGRO", "SONY - TELEVISOR
>>>> LED SMART TV FULL HD 40'' KDL-40R555C - ...",
>>>> "LG TV 47\" LED FULL HD - 47LY340C", "LG TV UHD 4K 65UB9800 SMART 3D LED
>>>> TV
>>>> C/WEBOS 65' LENTES 3D",
>>>> "PANASONIC - TELEVISOR TC-L42AS610 LED SMART FULL HD 42?...",
>>>> "AOC - TELEVISOR LED 32\" - LE32W454F", "SAMSUNG TV LED 32? -
>>>> UN32FH4005G",
>>>> "LG TV SMART LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED 3D SMART FULL
>>>> HD
>>>> 40'' TIZEN UN40J6400 - NEGRO",
>>>> "LG TV SMART  LED FULL HD 42\" - 42LF5850", "SAMSUNG TV LED HD 32''
>>>> UN32JH4005 - NEGRO",
>>>> "LG TV PLASMA 2014 60\" FULL HD 1080P - 60PB5600", "LG TV LED CINEMA 3D
>>>> SMART FULL HD 55'' 55LB7050 - PLATEADO",
>>>> "LG TV LED SMART FULL HD 43'' 43LF6350 - NEGRO", "PANASONIC PUERTO USB
>>>> LED
>>>> 40\" - TC-L40SV7L",
>>>> "PANASONIC LED SMART FULL HD 42\" - TC-L42AS610", "LG TV SMART  LED FULL
>>>> HD
>>>> 49\" - 49LF6350",
>>>> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500-NEGRO",
>>>> "SAMSUNG TV LED SMART ULTRA HD 50'' TIZEN UN50JU6500 - NEGRO",
>>>> "SAMSUNG TV SMART FULL HD CURVO 48'' TIZEN UN48J6500", "SAMSUNG TV  SMART
>>>> ULTRA HD 4K  65'' - UN65JU6500",
>>>> "SAMSUNG UN48J5500 LED 48\" - PLATEADO", "SAMSUNG LED 32\" CONEXI?N WIFI
>>>> -
>>>> UN32J4300",
>>>> "SAMSUNG LED SMART 40'' CONEXI?N WI-FI DIRECT - UN40J5500", "SAMSUNG LED
>>>> SMART ULTRA HD 55\" - TVUN55JU6700",
>>>> "SAMSUNG TV CURVED 3D SMART ULTRA HD 65'' TIZEN UN65JU7500...",
>>>> "SAMSUNG TELEVISOR  HG32NB460GF, 32\" LED, HD, 1366 X 768", "LG -TV SMART
>>>> LED FULL HD 55\" - 55LF6350",
>>>> "SAMSUNG TV LED SMART 3D 48\" - UN48H6400", "LG LED ULTRAHD 4K 49\" SMART
>>>> 3D - 49UB8300",
>>>> "LG - TV LED SMART HD 32'' 32LF585B - PLATEADO", "SAMSUNG - TV LED FULL
>>>> HD
>>>> 40\" UN40JH5005  - NEGRO GLOSS",
>>>> "LG - TV LED FULL HD 43'' 43LF5410 - PLATEADO"), precio.antes = c(2599L,
>>>> 1299L, 2899L, 3999L, 1199L, 4499L, 1999L, 1099L, 2299L, 1299L,
>>>> 2499L, 3999L, 2199L, 1899L, 2299L, 2299L, 1799L, 1499L, 2299L,
>>>> 1999L, 3999L, 3499L, 1549L, 1299L, 2299L, 2299L, 6999L, 1499L,
>>>> 1499L, 1899L, 1499L, 2099L, 6999L, 599L, 1299L, 9999L, 8999L,
>>>> 999L, 5999L, 599L, 2299L, 1299L, 1499L, 4999L, 6999L, 899L, 2299L,
>>>> 2499L, 3299L, 1799L, 1399L, 899L, 2499L, 4199L, 2299L, 1499L,
>>>> 1099L, 2499L, 399L, 2499L, 399L, 999L, 599L, 999L, 899L, 1499L,
>>>> 699L, 2299L, 1399L, 2499L, 2999L, 2499L, 1599L, 1149L, 999L,
>>>> 499L, 1089L, 1099L, 499L, 1499L, 1399L, 799L, 1299L, 2499L, 1399L,
>>>> 1259L, 1299L, 1299L, 1599L, 1999L, 3999L, 1999L, 1199L, 999L,
>>>> 1599L, 2299L, 999L, 1499L, 3699L, 1199L, 3899L, 1099L, 2299L,
>>>> 2499L, 1399L, 729L, 4199L, 3599L, 4999L, 1399L, 3999L, 4999L,
>>>> 2199L, 4499L, 2299L, 1699L, 2779L, 1699L, 5799L, 8999L, 3699L,
>>>> 2099L, 3299L, 1299L, 5900L, 1799L, 1799L, 1399L, 14999L, 2499L,
>>>> 2799L, 6299L, 1799L, 2417L, 9500L, 1799L, 799L, 999L, 1999L,
>>>> 2499L, 1899L, 999L, 2299L, 3699L, 2199L, 1699L, 1999L, 2499L,
>>>> 3499L, 3899L, 2999L, 7999L, 2299L, 1299L, 2099L, 5799L, 9999L,
>>>> 1110L, 3399L, 2799L, 3899L, 1299L, 1399L, 1499L), precio.nuevo = c(1799L,
>>>> 999L, 2299L, 3299L, 999L, 3199L, 1499L, 849L, 1399L, 979L, 1795L,
>>>> 2999L, 1899L, 1299L, 1699L, 1599L, 1499L, 1299L, 1699L, 1449L,
>>>> 3699L, 2499L, 1199L, 999L, 1499L, 899L, 4999L, 1199L, 1199L,
>>>> 1389L, 1299L, 1699L, 4899L, 549L, 999L, 7499L, 6700L, 849L, 4299L,
>>>> 549L, 1499L, 899L, 1299L, 3599L, 5354L, 538L, 1959L, 1599L, 2999L,
>>>> 1367L, 1099L, 589L, 2449L, 3199L, 1529L, 1229L, 839L, 1779L,
>>>> 329L, 1799L, 389L, 719L, 489L, 849L, 799L, 1185L, 599L, 1609L,
>>>> 1299L, 2179L, 2839L, 1999L, 1599L, 899L, 799L, 449L, 880L, 899L,
>>>> 429L, 1275L, 1199L, 589L, 999L, 1749L, 1199L, 1099L, 899L, 989L,
>>>> 1399L, 1999L, 2999L, 1599L, 999L, 819L, 1299L, 2299L, 789L, 1299L,
>>>> 3199L, 977L, 3089L, 849L, 1719L, 1799L, 1399L, 569L, 3979L, 3299L,
>>>> 3369L, 1093L, 3389L, 3289L, 1419L, 3429L, 1405L, 1499L, 1899L,
>>>> 1499L, 5199L, 6999L, 3199L, 1599L, 2999L, 1099L, 5089L, 1459L,
>>>> 1499L, 1289L, 12999L, 1739L, 2255L, 5879L, 1499L, 1929L, 8499L,
>>>> 1649L, 799L, 899L, 1659L, 1749L, 1609L, 831L, 2089L, 3659L, 1769L,
>>>> 1499L, 1599L, 2176L, 2749L, 2889L, 2899L, 5599L, 1899L, 1099L,
>>>> 1899L, 5199L, 8589L, 990L, 3169L, 2199L, 3899L, 949L, 1099L,
>>>> 1199L), dif.precios = c(800L, 300L, 600L, 700L, 200L, 1300L,
>>>> 500L, 250L, 900L, 320L, 704L, 1000L, 300L, 600L, 600L, 700L,
>>>> 300L, 200L, 600L, 550L, 300L, 1000L, 350L, 300L, 800L, 1400L,
>>>> 2000L, 300L, 300L, 510L, 200L, 400L, 2100L, 50L, 300L, 2500L,
>>>> 2299L, 150L, 1700L, 50L, 800L, 400L, 200L, 1400L, 1645L, 361L,
>>>> 340L, 900L, 300L, 432L, 300L, 310L, 50L, 1000L, 770L, 270L, 260L,
>>>> 720L, 70L, 700L, 10L, 280L, 110L, 150L, 100L, 314L, 100L, 690L,
>>>> 100L, 320L, 160L, 500L, 0L, 250L, 200L, 50L, 209L, 200L, 70L,
>>>> 224L, 200L, 210L, 300L, 750L, 200L, 160L, 400L, 310L, 200L, 0L,
>>>> 1000L, 400L, 200L, 180L, 300L, 0L, 210L, 200L, 500L, 222L, 810L,
>>>> 250L, 580L, 700L, 0L, 160L, 220L, 300L, 1630L, 306L, 610L, 1710L,
>>>> 780L, 1070L, 894L, 200L, 880L, 200L, 600L, 2000L, 500L, 500L,
>>>> 300L, 200L, 811L, 340L, 300L, 110L, 2000L, 760L, 544L, 420L,
>>>> 300L, 488L, 1001L, 150L, 0L, 100L, 340L, 750L, 290L, 168L, 210L,
>>>> 40L, 430L, 200L, 400L, 323L, 750L, 1010L, 100L, 2400L, 400L,
>>>> 200L, 200L, 600L, 1410L, 120L, 230L, 600L, 0L, 350L, 300L, 300L
>>>> ), dif.porcentual = c(30.78, 23.09, 20.7, 17.5, 16.68, 28.9,
>>>> 25.01, 22.75, 39.15, 24.63, 28.17, 25.01, 13.64, 31.6, 26.1,
>>>> 30.45, 16.68, 13.34, 26.1, 27.51, 7.5, 28.58, 22.6, 23.09, 34.8,
>>>> 60.9, 28.58, 20.01, 20.01, 26.86, 13.34, 19.06, 30, 8.35, 23.09,
>>>> 25, 25.55, 15.02, 28.34, 8.35, 34.8, 30.79, 13.34, 28.01, 23.5,
>>>> 40.16, 14.79, 36.01, 9.09, 24.01, 21.44, 34.48, 2, 23.82, 33.49,
>>>> 18.01, 23.66, 28.81, 17.54, 28.01, 2.51, 28.03, 18.36, 15.02,
>>>> 11.12, 20.95, 14.31, 30.01, 7.15, 12.81, 5.34, 20.01, 0, 21.76,
>>>> 20.02, 10.02, 19.19, 18.2, 14.03, 14.94, 14.3, 26.28, 23.09,
>>>> 30.01, 14.3, 12.71, 30.79, 23.86, 12.51, 0, 25.01, 20.01, 16.68,
>>>> 18.02, 18.76, 0, 21.02, 13.34, 13.52, 18.52, 20.77, 22.75, 25.23,
>>>> 28.01, 0, 21.95, 5.24, 8.34, 32.61, 21.87, 15.25, 34.21, 35.47,
>>>> 23.78, 38.89, 11.77, 31.67, 11.77, 10.35, 22.22, 13.52, 23.82,
>>>> 9.09, 15.4, 13.75, 18.9, 16.68, 7.86, 13.33, 30.41, 19.44, 6.67,
>>>> 16.68, 20.19, 10.54, 8.34, 0, 10.01, 17.01, 30.01, 15.27, 16.82,
>>>> 9.13, 1.08, 19.55, 11.77, 20.01, 12.93, 21.43, 25.9, 3.33, 30,
>>>> 17.4, 15.4, 9.53, 10.35, 14.1, 10.81, 6.77, 21.44, 0, 26.94,
>>>> 21.44, 20.01), pulgadas = c("43", "32", "48", "55", "32", "49",
>>>> "43", "32", "43", "32", "49", "60", "49", "43", "40", "43", "42",
>>>> "43", "49", "40", "55", "55", "43", "32", "40", "32", "55", "40",
>>>> "40", "40", "42", "43", "55", "24", "32", "65", "65", "32", "55",
>>>> "24", "47", "32", "39", "55", "55", "6", "32", "40", "48", "40",
>>>> "40", "6", "48", "49", "40", "42", "32", "48", "6", "43", "16",
>>>> "32", "20", "32", "5", "40", "6", "49", "40", "48", "40", "50",
>>>> "43", "32", "32", "19", "32", "32", "19", "40", "32", "6", "32",
>>>> "49", "32", "32", "32", "32", "40", "42", "49", "40", "32", "32",
>>>> "40", "40", "32", "43", "55", "32", "49", "32", "42", "48", "40",
>>>> "24", "55", "55", "48", "32", "49", "55", "40", "49", "40", "42",
>>>> "48", "42", "55", "55", "50", "40", "48", "32", "55", "40", "42",
>>>> "NA", "65", "NA", "50", "60", "40", "47", "65", "42", "32", "32",
>>>> "42", "40", "42", "32", "60", "55", "43", "40", "42", "49", "50",
>>>> "50", "48", "65", "48", "32", "40", "55", "65", "32", "55", "48",
>>>> "49", "32", "40", "43"), rangos = c("S/.1500 - S/.2500", "S/.500 -
>>>> S/.1500",
>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.3500 - S/.4500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "> S/.4,500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>>> S/.1500",
>>>> "S/.1500 - S/.2500", "> S/.4,500", "S/.500 - S/.1500", "S/.500 -
>>>> S/.1500",
>>>> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.3500 - S/.4500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>>> S/.1500",
>>>> "S/.3500 - S/.4500", "> S/.4,500", "S/.500 - S/.1500", "S/.1500 -
>>>> S/.2500",
>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.2500 - S/.3500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "< S/.500", "S/.1500 - S/.2500",
>>>> "< S/.500", "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
>>>> S/.2500",
>>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.2500 - S/.3500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>>> "< S/.500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 -
>>>> S/.1500",
>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.1500 - S/.2500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 -
>>>> S/.2500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>>> "S/.500 - S/.1500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.3500 - S/.4500", "S/.2500 - S/.3500",
>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.2500 - S/.3500",
>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>>> "> S/.4,500", "S/.1500 - S/.2500", "S/.1500 - S/.2500", "> S/.4,500",
>>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "> S/.4,500", "S/.1500 -
>>>> S/.2500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.1500 - S/.2500",
>>>> "S/.500 - S/.1500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>> "S/.2500 - S/.3500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>>>> "> S/.4,500", "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 -
>>>> S/.2500",
>>>> "> S/.4,500", "> S/.4,500", "S/.500 - S/.1500", "S/.2500 - S/.3500",
>>>> "S/.1500 - S/.2500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
>>>> "S/.500 - S/.1500", "S/.500 - S/.1500")), .Names = c("id", "marca",
>>>> "producto", "precio.antes", "precio.nuevo", "dif.precios",
>>>> "dif.porcentual",
>>>> "pulgadas", "rangos"), class = "data.frame", row.names = c(NA,
>>>> -164L))
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 2015-10-10 11:55 GMT-05:00 Omar Andr? Gonz?les D?az <
>>>> oma.gonzales at gmail.com>
>>>> :
>>>> 
>>>>> Thank you very much to both of you. This information is very
>>>> enlightening
>>>>> to me.
>>>>> 
>>>>> Cheers.
>>>>> 
>>>>> 
>>>>> 2015-10-10 1:11 GMT-05:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>>>> 
>>>>>> David answered most of this. Just a two short notes inline.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> On Oct 10, 2015, at 12:38 AM, Omar Andr? Gonz?les D?az <
>>>>>> oma.gonzales at gmail.com> wrote:
>>>>>> 
>>>>>>> David, Boris, so thankfull for your help. Both approaches are very
>>>>>> good. I got this solve with David's help.
>>>>>>> 
>>>>>>> I find very insteresting Bori's for loop. And I need a little help
>>>>>> understanding the regex part on it.
>>>>>>> 
>>>>>>> - The strsplit function: strsplit(ripley.tv$producto[i],
>>>> "[^A-Z0-9-]+")
>>>>>>> 
>>>>>>> I understand for this: split every row by a sequence of any number
>>>> or
>>>>>> letter or "-" that appears at leat once (+ operator).
>>>>>>> 
>>>>>>> 1.- What does mena the "^" symbol? If you remove it, just appeare
>>>>>> blanks.
>>>>>>> 2.- Why is there the necessity of "+" after the closing "]"?
>>>>>>> 
>>>>>>> 3.- How this:  ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]
>>>>>>>     Identifies also the IDs where "-" is present. Here the regex
>>>> does
>>>>>> not have the "-" included.
>>>>>> 
>>>>>> Yes. I am not matching the entire token here. Note there is no "+":
>>>> The
>>>>>> two character-class expressions match exactly one uppercase character
>>>>>> adjacent to exactly one number. If this is found in a token, grep
>>>> returns
>>>>>> TRUE. It doesn't matter what else the token contains - the first regex
>>>>>> already took care of removing everything that's not needed. The
>>>> vector of
>>>>>> FALSEs and a single TRUE that grep() returns goes inside the square
>>>>>> brackets, and selects the token from v.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>>> Also, I notice that David used the "-" at the begining of the
>>>> matching:
>>>>>> [-A-Z0-9], without the "^" (stars with) at the beginning.
>>>>>> 
>>>>>> This can be very confusing about regular expressions: the same
>>>> character
>>>>>> can mean different things depending on where it is found. Between two
>>>>>> characters in a character class expresssion, the hyphen means "range".
>>>>>> Elsewhere it is a literal hyphen. David put his at the beginning, I
>>>> had it
>>>>>> at the end (in the first regex). Another tricky character is "?"
>>>> which can
>>>>>> mean 0,1 matches, or turn "greedy" matching off...
>>>>>> 
>>>>>> Online regex testers are invaluable to develop a regex - one I
>>>> frequently
>>>>>> use is regexpal.com
>>>>>> 
>>>>>> Cheers,
>>>>>> B.
>>>>>> 
>>>>>> 
>>>>>>> 
>>>>>>> I would appreciate a response from you, gentlemen.
>>>>>>> 
>>>>>>> Thanks again.
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 
>>>>>>> 2015-10-09 18:32 GMT-05:00 David Winsemius <dwinsemius at comcast.net
>>>>> :
>>>>>>> 
>>>>>>> On Oct 9, 2015, at 4:21 PM, Boris Steipe wrote:
>>>>>>> 
>>>>>>>> I think you are going into the wrong direction here and this is a
>>>>>> classical example of what we mean by "technical debt" of code. Rather
>>>> than
>>>>>> tell to your regular expression what you are looking for, you are
>>>> handling
>>>>>> special cases with redundant code. This is ugly, brittle and
>>>> impossible to
>>>>>> maintain.
>>>>>>>> 
>>>>>>>> Respect to you that you have recognized this.
>>>>>>>> 
>>>>>>>> 
>>>>>>>> The solution is rather simple:
>>>>>>>> 
>>>>>>>> A) Isolate tokens. Your IDs contain only a limited set of
>>>> characters.
>>>>>> Split your strings along the characters that are not found in IDs to
>>>>>> isolate candidate tokens, place them into a vector.
>>>>>>>> 
>>>>>>>> B) Evaluate your tokens: as far as I can see IDs all contain
>>>> letters
>>>>>> AND numbers. This is a unique characteristic. Thus it is sufficient
>>>> to grep
>>>>>> for a letter/number pair in a token to identify it as an ID.
>>>>>>>> 
>>>>>>>> Should you ever find a need to accommodate differently formed IDs,
>>>>>> there are only two, well defined places with clearly delegated roles
>>>> where
>>>>>> changes might be needed.
>>>>>>>> 
>>>>>>>> Here is the code:
>>>>>>>> 
>>>>>>>> for (i in 1:nrow(ripley.tv)) {
>>>>>>>>      v <- unlist(strsplit(ripley.tv$producto[i],
>>>> "[^A-Z0-9-]+")) #
>>>>>> isolate tokens
>>>>>>>>      ripley.tv$id[i] <- v[grep("[A-Z][0-9]", v)]  # identify IDs
>>>>>> and store
>>>>>>>> }
>>>>>>> 
>>>>>>> That logic actually simplifies the regex strategy as well:
>>>>>>> 
>>>>>>> sub("(.*[ \n])([-A-Z0-9]{6,12})(.*)", "\\2",
>>>>>>> ripley.tv$producto,
>>>>>>> ignore.case = T)
>>>>>>> 
>>>>>>> 
>>>>>>> Almost succeeds, with a few all-character words, but if you require
>>>> one
>>>>>> number in the middle you get full results:
>>>>>>> 
>>>>>>> sub("(.*[ \n])([-A-Z0-9]{3,6}[0-9][-A-Z0-9]{2,6})(.*)", "\\2",
>>>>>>> ripley.tv$producto,
>>>>>>> ignore.case = T)
>>>>>>> 
>>>>>>> [1] "48J6400"     "40J5300"     "TC-40CS600L" "LE28F6600"
>>>>>> "LE40K5000N"
>>>>>>> [6] "LE32B7000"   "LE32K5000N"  "LE55B8000"   "LE40B8000"
>>>> "LE24B8000"
>>>>>>> [11] "TC-42AS610"  "LE50K5000N"  "40JU6500"    "48JU6500"
>>>> "50JU6500"
>>>>>>> [16] "55JS9000"    "55JU6500"    "55JU6700"    "55JU7500"
>>>> "65JS9000"
>>>>>>> [21] "65JU6500"    "65JU7500"    "75JU6500"    "40LF6350"
>>>> "42LF6400"
>>>>>>> [26] "42LF6450"    "49LF6450"    "LF6400"      "43UF6750"
>>>> "49UF6750"
>>>>>>> [31] "UF6900"      "49UF7700"    "49UF8500"    "55UF7700"
>>>> "65UF7700"
>>>>>>> [36] "55UF8500"    "TC-55CX640W" "TC-50CX640W" "70UF7700"
>>>> "UG8700"
>>>>>>> [41] "LF6350"      "KDL-50FA95C" "KDL50W805C"  "KDL-40R354B"
>>>> "40J5500"
>>>>>>> [46] "50J5500"     "32JH4005"    "50J5300"     "48J5300"
>>>> "40J6400"
>>>>>>> [51] "KDL-32R505C" "KDL-40R555C" "55J6400"     "40JH5005"
>>>> "43LF5410"
>>>>>>> [56] "32LF585B"    "49LF5900"    "KDL-65W855C" "UN48J6500"
>>>> "LE40F1551"
>>>>>>> [61] "TC-32AS600L" "KDL-32R304B" "55EC9300"    "LE32W454F"
>>>> "58UF8300"
>>>>>>> [66] "KDL-55W805C" "XBR-49X835C" "XBR-55X855C" "XBR-65X905C"
>>>>>> "XBR-75X945C"
>>>>>>> [71] "XBR-55X905C" "LC60UE30U"   "LC70UE30U"   "LC80UE30U"
>>>> "48J5500"
>>>>>>> [76] "79UG8800"    "65UF9500"    "65UF8500"    "55UF9500"
>>>> "32J4300"
>>>>>>> [81] "KDL-48R555C" "55UG8700"    "60UF8500"    "55LF6500"
>>>> "32LF550B"
>>>>>>> [86] "47LB5610"    "TC-50AS600L" "XBR-55X855B" "LC70SQ17U"
>>>>>> "XBR-79X905B"
>>>>>>> [91] "TC-40A400L"  "XBR-70X855B" "55HU8700"    "LE40D3142"
>>>>>> "TC-42AS650L"
>>>>>>> [96] "LC70LE660"   "LE58D3140"
>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> Cheers,
>>>>>>>> Boris
>>>>>>>> 
>>>>>>>> 
>>>>>>>> 
>>>>>>>> On Oct 9, 2015, at 5:48 PM, Omar Andr? Gonz?les D?az <
>>>>>> oma.gonzales at gmail.com> wrote:
>>>>>>>> 
>>>>>>>>>>>> ripley.tv <- structure(list(id = c(NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>>>> NA,
>>>>>>>>>> NA, NA,
>>>>>>>>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>>>>>>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>>>>>>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>>>>>>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>>>>>>>>>> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
>>>> NA,
>>>>>>>>>>>> NA, NA, NA, NA, NA, NA, NA), marca = c("SAMSUNG", "SAMSUNG",
>>>>>>>>>>>> "PANASONIC", "HAIER", "HAIER", "HAIER", "HAIER", "HAIER",
>>>> "HAIER",
>>>>>>>>>>>> "HAIER", "PANASONIC", "HAIER", "SAMSUNG", "SAMSUNG",
>>>> "SAMSUNG",
>>>>>>>>>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG",
>>>> "SAMSUNG",
>>>>>>>>>>>> "SAMSUNG", "SAMSUNG", "LG", "LG", "LG", "LG", "LG", "LG",
>>>> "LG",
>>>>>>>>>>>> "LG", "LG", "LG", "LG", "LG", "LG", "PANASONIC", "PANASONIC",
>>>>>>>>>>>> "LG", "LG", "LG", "SONY", "SONY", "SONY", "SAMSUNG",
>>>> "SAMSUNG",
>>>>>>>>>>>> "SAMSUNG", "SAMSUNG", "SAMSUNG", "SAMSUNG", "SONY", "SONY",
>>>>>> "SAMSUNG",
>>>>>>>>>>>> "SAMSUNG", "LG", "LG", "LG", "SONY", "SAMSUNG", "AOC",
>>>>>> "PANASONIC",
>>>>>>>>>>>> "SONY", "LG", "AOC", "LG", "SONY", "SONY", "SONY", "SONY",
>>>> "SONY",
>>>>>>>>>>>> "SONY", "SHARP", "SHARP", "SHARP", "SAMSUNG", "LG", "LG",
>>>> "LG",
>>>>>>>>>>>> "LG", "SAMSUNG", "SONY", "LG", "LG", "LG", "LG", "LG",
>>>>>> "PANASONIC",
>>>>>>>>>>>> "SONY", "SHARP", "SONY", "PANASONIC", "SONY", "SAMSUNG",
>>>> "AOC",
>>>>>>>>>>>> "PANASONIC", "SHARP", "AOC"), producto = c("SMART TV LED FHD
>>>> 48\"
>>>>>> 3D
>>>>>>>>>>>> 48J6400",
>>>>>>>>>>>> "SMART TV LED FHD 40\" 40J5300", "TV LED FULL HD 40''
>>>>>> TC-40CS600L",
>>>>>>>>>>>> "TELEVISOR LED LE28F6600 28\"", "SMART TV 40\" HD LE40K5000N",
>>>>>>>>>>>> "TV LED HD 32'' LE32B7000", "SMART TV  32'' LE32K5000N", "TV
>>>> LED
>>>>>> FHD
>>>>>>>>>> 55\" -
>>>>>>>>>>>> LE55B8000",
>>>>>>>>>>>> "TV LED LE40B8000 FULL HD 40\"", "TV LE24B8000 LED HD 24\" -
>>>>>> NEGRO",
>>>>>>>>>>>> "TV LED FULL HD 42'' TC-42AS610", "TELEVISOR LED LE50K5000N
>>>> 50\"",
>>>>>>>>>>>> "SMART TV LED UHD 40\" 40JU6500", "SMART TV ULTRA HD 48''
>>>>>> 48JU6500",
>>>>>>>>>>>> "SMART TV 50JU6500 LED UHD 50\" - NEGRO", "SMART TV ULTRA HD
>>>> 55''
>>>>>> 3D
>>>>>>>>>>>> 55JS9000",
>>>>>>>>>>>> "SMART TV LED UHD 55\" 55JU6500", "SMART TV ULTRA HD 55''
>>>>>> 55JU6700",
>>>>>>>>>>>> "SMART TV CURVO 55JU7500 LED UHD 55\" 3D - NEGRO", "SMART TV
>>>>>> ULTRA HD
>>>>>>>>>> 65''
>>>>>>>>>>>> 3D 65JS9000",
>>>>>>>>>>>> "SMART TV 65JU6500 LED UHD 65\"", "SMART TV ULTRA HD 65''
>>>>>> 65JU7500",
>>>>>>>>>>>> "SMART TV LED UHD 75\" 75JU6500", "SMART TV WEB OS 40\" FULL
>>>> HD
>>>>>>>>>> 40LF6350",
>>>>>>>>>>>> "SMART TV 3D 42\" FULL HD 42LF6400", "TV LED 42\" FULL HD
>>>> CINEMA
>>>>>> 3D
>>>>>>>>>>>> 42LF6450",
>>>>>>>>>>>> "TV LED 49\" FULL HD CINEMA 3D 49LF6450", "SMART TV LF6400
>>>> 49\"
>>>>>> FULL HD
>>>>>>>>>>>> 3D",
>>>>>>>>>>>> "TV 43UF6750 43\" ULTRA HD 4K", "TV 49\" ULTRA HD 4K
>>>> 49UF6750",
>>>>>>>>>>>> "TV LED 49\" ULTRA HD SMART UF6900", "SMART TV 49UF7700 49\"
>>>>>> ULTRA HD
>>>>>>>>>> 4K",
>>>>>>>>>>>> "SMART TV 49UF8500 49\" ULTRA HD 4K 3D", "TV LED 55\" CINEMA
>>>> 3D
>>>>>> SMART
>>>>>>>>>> TV
>>>>>>>>>>>> 55UF7700",
>>>>>>>>>>>> "SMART TV 65UF7700 65\" ULTRA HD 4K", "SMART TV 55UF8500 55\"
>>>>>> ULTRA HD
>>>>>>>>>> 4K
>>>>>>>>>>>> 3D",
>>>>>>>>>>>> "TV LED 55\" ULTRA HD 4K SMART TC-55CX640W", "TV LED 50\"
>>>> ULTRA
>>>>>> HD 4K
>>>>>>>>>> SMART
>>>>>>>>>>>> TC-50CX640W",
>>>>>>>>>>>> "SMART TV 70UF7700 3D ULTRA HD 70\"", "TV LED CURVO 65\"
>>>> ULTRA HD
>>>>>> 4K
>>>>>>>>>> CINEMA
>>>>>>>>>>>> SMART UG8700",
>>>>>>>>>>>> "TV LED 60\" FULL HD SMART LF6350", "SMART TV KDL-50FA95C 50\"
>>>>>> FULL HD
>>>>>>>>>> 3D",
>>>>>>>>>>>> "SMART TV KDL50W805C 50\" FULL HD 3D", "TV LED 40\" FULL HD
>>>>>>>>>> KDL-40R354B",
>>>>>>>>>>>> "SMART TV LED FULL HD 40'' 40J5500", "SMART TV LED FULL HD
>>>> 50''
>>>>>>>>>> 50J5500",
>>>>>>>>>>>> "TV LED HD 32'' 32JH4005", "SMART TV LED FULL HD 50\"
>>>> 50J5300",
>>>>>>>>>>>> "SMART TV LED 48\" FULL HD 48J5300", "SMART TV FULL HD 40'' 3D
>>>>>>>>>> 40J6400",
>>>>>>>>>>>> "TV LED 32\" HD SMART KDL-32R505C", "TV LED 40\" SMART FULL HD
>>>>>>>>>> KDL-40R555C
>>>>>>>>>>>> - NEGRO",
>>>>>>>>>>>> "SMART TV LED FHD 55\" 3D 55J6400", "TV 40JH5005 LED FHD 40\"
>>>> -
>>>>>> NEGRO",
>>>>>>>>>>>> "TV 43\" FULL HD 43LF5410", "SMART TV 32LF585B LED HD 32\" -
>>>>>> BLANCO",
>>>>>>>>>>>> "TV LED 49\" FULL HD SMART 49LF5900", "SMART TV 65\" FULL HD
>>>> 3D
>>>>>>>>>>>> KDL-65W855C",
>>>>>>>>>>>> "SMART TV LED FHD 48\" UN48J6500", "TV LED 40\" FULL HD
>>>>>> LE40F1551",
>>>>>>>>>>>> "TV LED 32'' SMART HD TC-32AS600L", "TV LED 32'' HD
>>>> KDL-32R304B",
>>>>>>>>>>>> "TV OLED 55\" SMART 3D FULL HD 55EC9300 PLATEADO", "TV LED HD
>>>> 32''
>>>>>>>>>>>> LE32W454F",
>>>>>>>>>>>> "TV LED 58\" ULTRA HD SMART 58UF8300", "TV LED 55\" FULL HD
>>>> SMART
>>>>>> 3D
>>>>>>>>>>>> KDL-55W805C",
>>>>>>>>>>>> "TV LED 49\" ULTRA HD 4K XBR-49X835C", "TV LED 55\" ULTRA HD
>>>> 4K
>>>>>>>>>>>> XBR-55X855C",
>>>>>>>>>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-65X905C", "TV LED
>>>> 75\"
>>>>>>>>>> ULTRA HD
>>>>>>>>>>>> 4K 3D XBR-75X945C",
>>>>>>>>>>>> "TV LED ULTRA DELGADO 55\" ULTRA HD 4K XBR-55X905C", "SMART TV
>>>>>> LED 60''
>>>>>>>>>>>> ULTRA HD 4K LC60UE30U",
>>>>>>>>>>>> "SMART TV LED 70'' ULTRA HD 4K LC70UE30U", "SMART TV LED 80''
>>>>>> ULTRA HD
>>>>>>>>>> 4K
>>>>>>>>>>>> LC80UE30U",
>>>>>>>>>>>> "SMART TV LED FULL HD 48'' 48J5500", "SMART TV CURVO 79UG8800
>>>> 79\"
>>>>>>>>>> ULTRA HD
>>>>>>>>>>>> 4K 3D",
>>>>>>>>>>>> "SMART TV 65UF9500 65\" ULTRA HD 4K 3D", "SMART TV 65UF8500
>>>> 65\"
>>>>>> ULTRA
>>>>>>>>>> HD
>>>>>>>>>>>> 4K 3D",
>>>>>>>>>>>> "SMART TV 55UF9500 55\" ULTRA HD 4K 3D", "SMART TV LED HD 32\"
>>>>>>>>>> 32J4300",
>>>>>>>>>>>> "TV LED 48\" SMART FULL HD KDL-48R555C - NEGRO", "SMART TV
>>>>>> 55UG8700
>>>>>>>>>> 55\"
>>>>>>>>>>>> ULTRA HD 4K 3D",
>>>>>>>>>>>> "SMART TV 60UF8500 60\" ULTRA HD 4K 3D", "SMART TV 55LF6500
>>>> 55\"
>>>>>> FULL
>>>>>>>>>> HD
>>>>>>>>>>>> 3D",
>>>>>>>>>>>> "TV 32LF550B 32\" HD", "TV LED 47\" FULL HD 47LB5610", "TV LED
>>>>>> FULL HD
>>>>>>>>>> 50''
>>>>>>>>>>>> TC-50AS600L",
>>>>>>>>>>>> "TV SMART LED 55\" UHD 3D XBR-55X855B", "TV LED FULL HD 4K
>>>>>> LC70SQ17U
>>>>>>>>>> 70''",
>>>>>>>>>>>> "TV LED SMART UHD 79\" XBR-79X905B", "TV LED FULL HD 40''
>>>>>> TC-40A400L",
>>>>>>>>>>>> "TV LED SMART UHD 70\" XBR-70X855B", "SMART TV UHD 55'' 3D
>>>> CURVO
>>>>>>>>>> 55HU8700",
>>>>>>>>>>>> "TV FULL HD LE40D3142 40\" - NEGRO", "TELEVISOR LED 42\"
>>>>>> TC-42AS650L",
>>>>>>>>>>>> "SMART TV LCD FHD 70\" LC70LE660", "TV LED FULL HD 58''
>>>> LE58D3140"
>>>>>>>>>>>> ), pulgadas = c(48L, 40L, 40L, 28L, 40L, 32L, 32L, 55L, 40L,
>>>>>>>>>>>> 24L, 42L, 50L, 40L, 48L, 50L, 55L, 55L, 55L, 55L, 65L, 65L,
>>>> 65L,
>>>>>>>>>>>> 75L, 40L, 42L, 42L, 49L, 49L, 43L, 49L, 49L, 49L, 49L, 55L,
>>>> 65L,
>>>>>>>>>>>> 55L, 55L, 50L, 70L, 65L, 60L, 50L, 50L, 40L, 40L, 50L, 32L,
>>>> 50L,
>>>>>>>>>>>> 48L, 40L, 32L, 40L, 55L, 40L, 43L, 32L, 49L, 65L, 48L, 40L,
>>>> 32L,
>>>>>>>>>>>> 32L, 55L, 32L, 58L, 55L, 49L, 55L, 55L, 75L, 55L, 60L, 70L,
>>>> 80L,
>>>>>>>>>>>> 48L, 79L, 65L, 65L, 55L, 32L, 48L, 55L, 60L, 55L, 32L, 47L,
>>>> 50L,
>>>>>>>>>>>> 55L, 70L, 79L, 40L, 70L, 55L, 40L, 42L, 70L, 58L),
>>>> precio.antes =
>>>>>>>>>> c(2799L,
>>>>>>>>>>>> 1799L, 1699L, 599L, 1299L, 699L, 999L, 1999L, 999L, 499L,
>>>> 1899L,
>>>>>>>>>>>> 1799L, 2499L, 3999L, 3699L, 10999L, 4299L, 5499L, 6999L,
>>>> 14999L,
>>>>>>>>>>>> 8999L, 9999L, 14599L, 1999L, 2299L, 2299L, 2899L, 2999L,
>>>> 2299L,
>>>>>>>>>>>> 23992L, 3599L, 3799L, 4799L, 4999L, 8499L, 5999L, 4999L,
>>>> 3999L,
>>>>>>>>>>>> 11999L, 10999L, 4399L, 4499L, 3799L, 1399L, 2299L, 2799L,
>>>> 999L,
>>>>>>>>>>>> 2199L, 2299L, 2299L, 1299L, 1699L, 3499L, 1399L, 1549L, 1299L,
>>>>>>>>>>>> 2399L, 6499L, 2999L, 999L, 1249L, 999L, 14999L, 799L, 5999L,
>>>>>>>>>>>> 4499L, 4999L, 6499L, 12999L, 24999L, 8999L, 5999L, 7599L,
>>>> 14999L,
>>>>>>>>>>>> 2499L, 29999L, 13999L, 9999L, 9699L, 1299L, 2399L, 6999L,
>>>> 7999L,
>>>>>>>>>>>> 3699L, 999L, 1899L, 2999L, 7999L, 8499L, 24999L, 1399L,
>>>> 13999L,
>>>>>>>>>>>> 8499L, 999L, 2599L, 5799L, 2399L), precio.nuevo = c(2299,
>>>> 1399,
>>>>>>>>>>>> 1299, 549, 1099, 629, 799, 1699, 849, 439, 1499, 1549, 1759.2,
>>>>>>>>>>>> 2099.3, 2309.3, 7699.3, 2799.3, 3639.3, 4899.3, 10499.3,
>>>> 5109.3,
>>>>>>>>>>>> 6999.3, 10219.3, 1399, 1599, 1599, 2199, 2199, 1299, 23992,
>>>> 2299,
>>>>>>>>>>>> 2299, 2899, 2999, 5999, 3899, 4999, 3999, 8999, 6999, 4099,
>>>> 3999,
>>>>>>>>>>>> 3499, 1299, 1799, 2399, 799, 2199, 1799, 1999, 1199, 1599,
>>>> 2999,
>>>>>>>>>>>> 1199, 1399, 1099, 1999, 5999, 2799, 999, 1199, 949, 7999, 799,
>>>>>>>>>>>> 5299, 4299, 3999, 5999, 11999, 23999, 7999, 5699, 7599, 14499,
>>>>>>>>>>>> 2399, 29999, 11999, 8999, 7499, 1099, 2199, 6599, 7099, 3599,
>>>>>>>>>>>> 899, 1599, 2199, 4999, 6499, 19999, 1399, 9999, 5999, 999,
>>>> 2599,
>>>>>>>>>>>> 5699, 2399), dif.precios = c(500, 400, 400, 50, 200, 70, 200,
>>>>>>>>>>>> 300, 150, 60, 400, 250, 739.8, 1899.7, 1389.7, 3299.7, 1499.7,
>>>>>>>>>>>> 1859.7, 2099.7, 4499.7, 3889.7, 2999.7, 4379.7, 600, 700, 700,
>>>>>>>>>>>> 700, 800, 1000, 0, 1300, 1500, 1900, 2000, 2500, 2100, 0, 0,
>>>>>>>>>>>> 3000, 4000, 300, 500, 300, 100, 500, 400, 200, 0, 500, 300,
>>>> 100,
>>>>>>>>>>>> 100, 500, 200, 150, 200, 400, 500, 200, 0, 50, 50, 7000, 0,
>>>> 700,
>>>>>>>>>>>> 200, 1000, 500, 1000, 1000, 1000, 300, 0, 500, 100, 0, 2000,
>>>>>>>>>>>> 1000, 2200, 200, 200, 400, 900, 100, 100, 300, 800, 3000,
>>>> 2000,
>>>>>>>>>>>> 5000, 0, 4000, 2500, 0, 0, 100, 0), dif.porcentual = c(17.86,
>>>>>>>>>>>> 22.23, 23.54, 8.35, 15.4, 10.01, 20.02, 15.01, 15.02, 12.02,
>>>>>>>>>>>> 21.06, 13.9, 29.6, 47.5, 37.57, 30, 34.88, 33.82, 30, 30,
>>>> 43.22,
>>>>>>>>>>>> 30, 30, 30.02, 30.45, 30.45, 24.15, 26.68, 43.5, 0, 36.12,
>>>> 39.48,
>>>>>>>>>>>> 39.59, 40.01, 29.42, 35.01, 0, 0, 25, 36.37, 6.82, 11.11, 7.9,
>>>>>>>>>>>> 7.15, 21.75, 14.29, 20.02, 0, 21.75, 13.05, 7.7, 5.89, 14.29,
>>>>>>>>>>>> 14.3, 9.68, 15.4, 16.67, 7.69, 6.67, 0, 4, 5.01, 46.67, 0,
>>>> 11.67,
>>>>>>>>>>>> 4.45, 20, 7.69, 7.69, 4, 11.11, 5, 0, 3.33, 4, 0, 14.29, 10,
>>>>>>>>>>>> 22.68, 15.4, 8.34, 5.72, 11.25, 2.7, 10.01, 15.8, 26.68, 37.5,
>>>>>>>>>>>> 23.53, 20, 0, 28.57, 29.42, 0, 0, 1.72, 0), rangos =
>>>> c("S/.1500 -
>>>>>>>>>> S/.2500",
>>>>>>>>>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.500 - S/.1500",
>>>>>> "S/.500 -
>>>>>>>>>>>> S/.1500",
>>>>>>>>>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>>>>>>>>> "S/.500 - S/.1500", "< S/.500", "S/.500 - S/.1500", "S/.1500 -
>>>>>>>>>> S/.2500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>>>>>>>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.3500 - S/.4500", ">
>>>>>> S/.4,500",
>>>>>>>>>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>> "S/.500 -
>>>>>>>>>> S/.1500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.1500 - S/.2500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "> S/.4,500",
>>>> "S/.1500 -
>>>>>>>>>> S/.2500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.2500 - S/.3500",
>>>>>>>>>>>> "> S/.4,500", "S/.3500 - S/.4500", "> S/.4,500", "S/.3500 -
>>>>>> S/.4500",
>>>>>>>>>>>> "> S/.4,500", "> S/.4,500", "S/.3500 - S/.4500", "S/.3500 -
>>>>>> S/.4500",
>>>>>>>>>>>> "S/.2500 - S/.3500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.1500 - S/.2500", "S/.500 - S/.1500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>>>>>>>>>> "S/.500 - S/.1500", "S/.500 - S/.1500", "S/.1500 - S/.2500",
>>>>>>>>>>>> "> S/.4,500", "S/.2500 - S/.3500", "S/.500 - S/.1500",
>>>> "S/.500 -
>>>>>>>>>> S/.1500",
>>>>>>>>>>>> "S/.500 - S/.1500", "> S/.4,500", "S/.500 - S/.1500", ">
>>>>>> S/.4,500",
>>>>>>>>>>>> "S/.3500 - S/.4500", "S/.3500 - S/.4500", "> S/.4,500", ">
>>>>>> S/.4,500",
>>>>>>>>>>>> "> S/.4,500", "> S/.4,500", "> S/.4,500", "> S/.4,500", ">
>>>>>> S/.4,500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>>>>>>>>>> "> S/.4,500", "S/.500 - S/.1500", "S/.1500 - S/.2500", ">
>>>>>> S/.4,500",
>>>>>>>>>>>> "> S/.4,500", "S/.3500 - S/.4500", "S/.500 - S/.1500",
>>>> "S/.1500 -
>>>>>>>>>> S/.2500",
>>>>>>>>>>>> "S/.1500 - S/.2500", "> S/.4,500", "> S/.4,500", "> S/.4,500",
>>>>>>>>>>>> "S/.500 - S/.1500", "> S/.4,500", "> S/.4,500", "S/.500 -
>>>>>> S/.1500",
>>>>>>>>>>>> "S/.2500 - S/.3500", "> S/.4,500", "S/.1500 - S/.2500")),
>>>> .Names =
>>>>>>>>>> c("id",
>>>>>>>>>>>> "marca", "producto", "pulgadas", "precio.antes",
>>>> "precio.nuevo",
>>>>>>>>>>>> "dif.precios", "dif.porcentual", "rangos"), class =
>>>> "data.frame",
>>>>>>>>>> row.names
>>>>>>>>>>>> = c(NA,
>>>>>>>>>>>> -97L))
>>>>>>>> 
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>> 
>>>>>>> David Winsemius
>>>>>>> Alameda, CA, USA
>>>>>>> 
>>>>>>> 
>>>>>> 
>>>>>> 
>>>>> 
>>>> 
>>>>        [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From kristi.glover at hotmail.com  Mon Oct 12 10:41:13 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Mon, 12 Oct 2015 08:41:13 +0000
Subject: [R] 3D matrix columns messed up
Message-ID: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi R Users,
I was trying to make a matrix with three variables (x,y, z), but y variable (columns) names did not stay in its sequential order, t1,t2,t3,---t21; rather the matrix columns automatically appeared as a?t1,t10, t2,t20 etc. Besides these, z value (sites) did not come in the right place (meaning in right columns name).?I am wondering how I can make the matrix with the sequential order with right z value (site). I tried it several ways but did not work. One of the examples?I used?is given here. Would you mind to give me a mints??

x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L,?
1L), .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),?
? ? site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L), .Label = c("A",?
? ? "B", "D"), class = "factor"), time = structure(c(1L, 3L,?
? ? 5L, 1L, 5L, 1L, 6L, 2L, 4L), .Label = c("t1", "t10", "t2",?
? ? "t21", "t3", "t4"), class = "factor")), .Names = c("vs",?
"site", "time"), class = "data.frame", row.names = c(NA, -9L))


x$time<-factor(x$time)
tmp <- split(x, x$vs)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(x$time)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(x$site))
}))


tmp1


## I want the z (site) in respective columns.?


From tal.galili at gmail.com  Mon Oct 12 11:17:31 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 12 Oct 2015 12:17:31 +0300
Subject: [R] Using MASS::boxcox for a single variable gives different
 results than the original paper
Message-ID: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>

Hello all,

Given a set of observations, I would like to find lambda for a boxcox
transformation so to get a symmetric/normal result as possible.

I try to use MASS::boxcox, but get different results than when using the
formula from the original box-cox paper (link
<http://www.jstor.org/stable/2984418?seq=1#page_scan_tab_contents>).

I probably have made an error somewhere, but I can't figure out where.

Here is an example in which the lambda by MASS::boxcox is 0.42424, while by
the formula from the paper I get 0.40782.








# Toy data
################
set.seed(13241089)
x <- rnorm(1000, 10)
x2 <- x**2 # we want to transform x2 to something more normal
plot(density(x2))

# using MASS::boxcox
################

zpoints <- function(y) {
n <- length(y)
qnorm(ppoints(n))[order(order(y))]
}
mle <- function(BC) {
with(BC, x[which.max(y)])
}

a <- MASS::boxcox(x2 ~ zpoints(x2))
mle(a)
# lambda:
# 0.42424



# using formula from the paper
################

loglik_lambda <- function(l, y) {
GM <- exp(mean(log(y)))
if(l==0) x <- log(y)*GM else x <- (y^l-1)/ (l * GM^(l-1) )
#  if(l==0) x <- log(y) else x <- (y^l-1)/ (l )
sd(x)
}
fo <- function(l) loglik_lambda(l, y = x2)
V_fo <- Vectorize(fo)
V_fo(2)
curve(V_fo, -.5,1.5)
optimize(V_fo, c(-3,3))
# lambda:
# 0.40782

	[[alternative HTML version deleted]]


From Guillaume.Tahon at UGent.be  Mon Oct 12 11:08:52 2015
From: Guillaume.Tahon at UGent.be (gktahon)
Date: Mon, 12 Oct 2015 02:08:52 -0700 (PDT)
Subject: [R] Percentage sign in Vegan output
Message-ID: <1444640932952-4713496.post@n4.nabble.com>

Hi All,

I'm using the Vegan package in R to calculate some variables for my data set
and to make rarefaction curves.
However, I would like to give clear names to my samples and I do not succeed
in this.

For the package, I first read my OTU table (this is a text file with my
samples listed per column. The column header is the sample name as it should
appear in the legend.). After that, I transpose the table for the analysis
and I run the script.
I do get a nice output, meaning my figure looks good and everything. The
only problem is the sample names in the legend. What I have noticed is that
everything after a 'space' is automatically cut off/deleted and that special
characters are not taken into account. For example, when I want to show 95%,
it gives 95. as an output. Characters like %, /, # are changed into a .
symbol. I was wondering how I can solve this issue, because I would like to
insert spaces and special characters in my sample names.

For example, if I want my sample name to be DNA 95%, how do I have to do
this?

Many thanks in advance!



--
View this message in context: http://r.789695.n4.nabble.com/Percentage-sign-in-Vegan-output-tp4713496.html
Sent from the R help mailing list archive at Nabble.com.


From drjimlemon at gmail.com  Mon Oct 12 12:22:59 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 12 Oct 2015 21:22:59 +1100
Subject: [R] 3D matrix columns messed up
In-Reply-To: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fW7hSatHookgxk2vv4PzD-3rBUbmrHkU68Yh4zO1gLb-g@mail.gmail.com>

Hi Kristi,
The first part is relatively easy:

# change first line to
x$time<-factor(x$time,levels=c("t1","t2","t3","t4","t10","t21"))

As you have specified "site" as the second element in "x", not the third,
perhaps you just want:

x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L, 1L),
 .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
 time = structure(c(1L, 3L, 5L, 1L, 5L, 1L, 6L, 2L, 4L),
 .Label = c("t1", "t10", "t2", "t21", "t3", "t4"), class = "factor")),
 site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L),
 .Label = c("A", "B", "D"), class = "factor"),
 .Names = c("vs", "time", "site"), class = "data.frame",
 row.names = c(NA, -9L))

Jim

On Mon, Oct 12, 2015 at 7:41 PM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Hi R Users,
> I was trying to make a matrix with three variables (x,y, z), but y
> variable (columns) names did not stay in its sequential order,
> t1,t2,t3,---t21; rather the matrix columns automatically appeared as
> a t1,t10, t2,t20 etc. Besides these, z value (sites) did not come in the
> right place (meaning in right columns name). I am wondering how I can make
> the matrix with the sequential order with right z value (site). I tried it
> several ways but did not work. One of the examples I used is given here.
> Would you mind to give me a mints?
>
> x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L,
> 1L), .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
>     site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L), .Label =
> c("A",
>     "B", "D"), class = "factor"), time = structure(c(1L, 3L,
>     5L, 1L, 5L, 1L, 6L, 2L, 4L), .Label = c("t1", "t10", "t2",
>     "t21", "t3", "t4"), class = "factor")), .Names = c("vs",
> "site", "time"), class = "data.frame", row.names = c(NA, -9L))
>
>
> x$time<-factor(x$time)
> tmp <- split(x, x$vs)
> tmp1 <- do.call(rbind, lapply(tmp, function(x){
> tb <- table(x$time)
> idx <- which(tb>0)
> tb1 <- replace(tb, idx, as.character(x$site))
> }))
>
>
> tmp1
>
>
> ## I want the z (site) in respective columns.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tal.galili at gmail.com  Mon Oct 12 15:32:12 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 12 Oct 2015 16:32:12 +0300
Subject: [R] Using MASS::boxcox for a single variable gives different
 results than the original paper
In-Reply-To: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>
References: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>
Message-ID: <CANdJ3dUA_7x2XUsXbG9A2-Z5Ear5ToaMywbc6UNCVxpb6pO6hg@mail.gmail.com>

After trying this with the function "estimateTransform" from {car}, it
returns values similar to my solution rather than the one from MASS::boxcox:


# Toy data
################
set.seed(13241089)
x <- rnorm(1000, 10)
x2 <- x**2 # we want to transform x2 to something more normal



# using MASS::boxcox
################

mle <- function(BC) {
with(BC, x[which.max(y)])
}

ONES <- rep(1, length(x2))
a <- MASS::boxcox(lm(x2 ~ ONES))
mle(a)
# lambda:
# 0.42424



# using estimateTransform from car
################

# Same result as the paper: !
library(car)
ONES <- rep(1, length(x2))
estimateTransform(X=data.frame(x = ONES), Y = x2)
# lambda:
# 0.40782

(just as with my own function in the previous email)



What am I missing?









----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Mon, Oct 12, 2015 at 12:17 PM, Tal Galili <tal.galili at gmail.com> wrote:

> Hello all,
>
> Given a set of observations, I would like to find lambda for a boxcox
> transformation so to get a symmetric/normal result as possible.
>
> I try to use MASS::boxcox, but get different results than when using the
> formula from the original box-cox paper (link
> <http://www.jstor.org/stable/2984418?seq=1#page_scan_tab_contents>).
>
> I probably have made an error somewhere, but I can't figure out where.
>
> Here is an example in which the lambda by MASS::boxcox is 0.42424, while
> by the formula from the paper I get 0.40782.
>
>
>
>
>
>
>
>
> # Toy data
> ################
> set.seed(13241089)
> x <- rnorm(1000, 10)
> x2 <- x**2 # we want to transform x2 to something more normal
> plot(density(x2))
>
> # using MASS::boxcox
> ################
>
> zpoints <- function(y) {
> n <- length(y)
> qnorm(ppoints(n))[order(order(y))]
> }
> mle <- function(BC) {
> with(BC, x[which.max(y)])
> }
>
> a <- MASS::boxcox(x2 ~ zpoints(x2))
> mle(a)
> # lambda:
> # 0.42424
>
>
>
> # using formula from the paper
> ################
>
> loglik_lambda <- function(l, y) {
> GM <- exp(mean(log(y)))
> if(l==0) x <- log(y)*GM else x <- (y^l-1)/ (l * GM^(l-1) )
> #  if(l==0) x <- log(y) else x <- (y^l-1)/ (l )
> sd(x)
> }
> fo <- function(l) loglik_lambda(l, y = x2)
> V_fo <- Vectorize(fo)
> V_fo(2)
> curve(V_fo, -.5,1.5)
> optimize(V_fo, c(-3,3))
> # lambda:
> # 0.40782
>
>
>
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From nicholas.wray at ntlworld.com  Mon Oct 12 15:33:59 2015
From: nicholas.wray at ntlworld.com (nicholas.wray at ntlworld.com)
Date: Mon, 12 Oct 2015 14:33:59 +0100 (BST)
Subject: [R] Command to input a variable value in real time
Message-ID: <1152103984.439361.1444656839033.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>

Hi  I am sure that there is a command in R which tells the prog to wait until
you have input a value for a variable, but for the life of me I can't find it.
 Searches on the net only seem to talk about inputting datasets etc, not about
real time single inputs. I'd be most grateful if anyone could point me in the
right direction

Thanks, Nick Wray
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Oct 12 15:43:19 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 12 Oct 2015 15:43:19 +0200
Subject: [R] Using MASS::boxcox for a single variable gives different
	results than the original paper
In-Reply-To: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>
References: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>
Message-ID: <37250244-8FB5-4F74-9836-F86C1F971B06@gmail.com>

Two things:

A) x2 ~ zpoints(x2) is not right
B) granularity:
> a <- MASS::boxcox(x2 ~ 1,lambda=seq(-2,2,1e-5))
> mle(a)
[1] 0.40783

-pd

On 12 Oct 2015, at 11:17 , Tal Galili <tal.galili at gmail.com> wrote:

> Hello all,
> 
> Given a set of observations, I would like to find lambda for a boxcox
> transformation so to get a symmetric/normal result as possible.
> 
> I try to use MASS::boxcox, but get different results than when using the
> formula from the original box-cox paper (link
> <http://www.jstor.org/stable/2984418?seq=1#page_scan_tab_contents>).
> 
> I probably have made an error somewhere, but I can't figure out where.
> 
> Here is an example in which the lambda by MASS::boxcox is 0.42424, while by
> the formula from the paper I get 0.40782.
> 
> 
> 
> 
> 
> 
> 
> 
> # Toy data
> ################
> set.seed(13241089)
> x <- rnorm(1000, 10)
> x2 <- x**2 # we want to transform x2 to something more normal
> plot(density(x2))
> 
> # using MASS::boxcox
> ################
> 
> zpoints <- function(y) {
> n <- length(y)
> qnorm(ppoints(n))[order(order(y))]
> }
> mle <- function(BC) {
> with(BC, x[which.max(y)])
> }
> 
> a <- MASS::boxcox(x2 ~ zpoints(x2))
> mle(a)
> # lambda:
> # 0.42424
> 
> 
> 
> # using formula from the paper
> ################
> 
> loglik_lambda <- function(l, y) {
> GM <- exp(mean(log(y)))
> if(l==0) x <- log(y)*GM else x <- (y^l-1)/ (l * GM^(l-1) )
> #  if(l==0) x <- log(y) else x <- (y^l-1)/ (l )
> sd(x)
> }
> fo <- function(l) loglik_lambda(l, y = x2)
> V_fo <- Vectorize(fo)
> V_fo(2)
> curve(V_fo, -.5,1.5)
> optimize(V_fo, c(-3,3))
> # lambda:
> # 0.40782
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From bretschr at xs4all.nl  Mon Oct 12 15:44:27 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Mon, 12 Oct 2015 15:44:27 +0200
Subject: [R] Command to input a variable value in real time
In-Reply-To: <1152103984.439361.1444656839033.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
References: <1152103984.439361.1444656839033.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
Message-ID: <388F0D72-7C90-49E8-87F6-63F632164BD9@xs4all.nl>

Dear nicholas.wray,


Re:

> Hi  I am sure that there is a command in R which tells the prog to wait until
> you have input a value for a variable, but for the life of me I can't find it.
> Searches on the net only seem to talk about inputting datasets etc, not about
> real time single inputs. I'd be most grateful if anyone could point me in the
> right direction
> 
> Thanks, Nick Wray
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Maybe you need "readline()" in base-R:

> 
> readline {base}	R Documentation
> Read a Line from the Terminal
> 
> Description
> 
> readline reads a line from the terminal (in interactive use).
> 
> Usage
> 
> readline(prompt = "")
> 
> Arguments
> 
> prompt	
> the string printed when prompting the user for input. Should usually end with a space " ".
> 

Best wishes,

Frank
---





Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From jfox at mcmaster.ca  Mon Oct 12 15:45:05 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 12 Oct 2015 13:45:05 +0000
Subject: [R] Using MASS::boxcox for a single variable gives different
 results than the original paper
In-Reply-To: <CANdJ3dUA_7x2XUsXbG9A2-Z5Ear5ToaMywbc6UNCVxpb6pO6hg@mail.gmail.com>
References: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>
	<CANdJ3dUA_7x2XUsXbG9A2-Z5Ear5ToaMywbc6UNCVxpb6pO6hg@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F2EB2E@FHSDB2D11-2.csu.mcmaster.ca>

Dear Tal,

MASS:boxcox() evaluates the pseudo-log-likelihood at a pre-specified vector of values of the transformation parameter lambda. In your example,

> head(a$x)
[1] -2.000000 -1.959596 -1.919192 -1.878788 -1.838384 -1.797980

Which accounts, I think, for the small difference in the answer.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tal Galili
> Sent: October 12, 2015 9:32 AM
> To: r-help at r-project.org
> Subject: Re: [R] Using MASS::boxcox for a single variable gives different results
> than the original paper
> 
> After trying this with the function "estimateTransform" from {car}, it returns
> values similar to my solution rather than the one from MASS::boxcox:
> 
> 
> # Toy data
> ################
> set.seed(13241089)
> x <- rnorm(1000, 10)
> x2 <- x**2 # we want to transform x2 to something more normal
> 
> 
> 
> # using MASS::boxcox
> ################
> 
> mle <- function(BC) {
> with(BC, x[which.max(y)])
> }
> 
> ONES <- rep(1, length(x2))
> a <- MASS::boxcox(lm(x2 ~ ONES))
> mle(a)
> # lambda:
> # 0.42424
> 
> 
> 
> # using estimateTransform from car
> ################
> 
> # Same result as the paper: !
> library(car)
> ONES <- rep(1, length(x2))
> estimateTransform(X=data.frame(x = ONES), Y = x2) # lambda:
> # 0.40782
> 
> (just as with my own function in the previous email)
> 
> 
> 
> What am I missing?
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
> ----------------------------------------------------------------------------------------------
> 
> 
> On Mon, Oct 12, 2015 at 12:17 PM, Tal Galili <tal.galili at gmail.com> wrote:
> 
> > Hello all,
> >
> > Given a set of observations, I would like to find lambda for a boxcox
> > transformation so to get a symmetric/normal result as possible.
> >
> > I try to use MASS::boxcox, but get different results than when using
> > the formula from the original box-cox paper (link
> > <http://www.jstor.org/stable/2984418?seq=1#page_scan_tab_contents>).
> >
> > I probably have made an error somewhere, but I can't figure out where.
> >
> > Here is an example in which the lambda by MASS::boxcox is 0.42424,
> > while by the formula from the paper I get 0.40782.
> >
> >
> >
> >
> >
> >
> >
> >
> > # Toy data
> > ################
> > set.seed(13241089)
> > x <- rnorm(1000, 10)
> > x2 <- x**2 # we want to transform x2 to something more normal
> > plot(density(x2))
> >
> > # using MASS::boxcox
> > ################
> >
> > zpoints <- function(y) {
> > n <- length(y)
> > qnorm(ppoints(n))[order(order(y))]
> > }
> > mle <- function(BC) {
> > with(BC, x[which.max(y)])
> > }
> >
> > a <- MASS::boxcox(x2 ~ zpoints(x2))
> > mle(a)
> > # lambda:
> > # 0.42424
> >
> >
> >
> > # using formula from the paper
> > ################
> >
> > loglik_lambda <- function(l, y) {
> > GM <- exp(mean(log(y)))
> > if(l==0) x <- log(y)*GM else x <- (y^l-1)/ (l * GM^(l-1) ) #  if(l==0)
> > x <- log(y) else x <- (y^l-1)/ (l )
> > sd(x)
> > }
> > fo <- function(l) loglik_lambda(l, y = x2) V_fo <- Vectorize(fo)
> > V_fo(2)
> > curve(V_fo, -.5,1.5)
> > optimize(V_fo, c(-3,3))
> > # lambda:
> > # 0.40782
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ivan.calandra at univ-reims.fr  Mon Oct 12 15:57:27 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 12 Oct 2015 15:57:27 +0200
Subject: [R] Command to input a variable value in real time
In-Reply-To: <1152103984.439361.1444656839033.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
References: <1152103984.439361.1444656839033.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
Message-ID: <561BBC47.9050408@univ-reims.fr>

Dear Nick,

You might find the function varEntryDialog() useful:
http://www.r-bloggers.com/user-input-using-tcltk-2/

HTH,
Ivan

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 12/10/15 15:33, nicholas.wray at ntlworld.com a ?crit :
> Hi  I am sure that there is a command in R which tells the prog to wait until
> you have input a value for a variable, but for the life of me I can't find it.
>   Searches on the net only seem to talk about inputting datasets etc, not about
> real time single inputs. I'd be most grateful if anyone could point me in the
> right direction
>
> Thanks, Nick Wray
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ivan.calandra at univ-reims.fr  Mon Oct 12 16:06:00 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Mon, 12 Oct 2015 16:06:00 +0200
Subject: [R] Command to input a variable value in real time
In-Reply-To: <561BBC47.9050408@univ-reims.fr>
References: <1152103984.439361.1444656839033.JavaMail.open-xchange@oxbe25.tb.ukmail.iss.as9143.net>
	<561BBC47.9050408@univ-reims.fr>
Message-ID: <561BBE48.5040105@univ-reims.fr>

See this link for the function varEntryDialog() itself:
http://www.r-bloggers.com/user-input-using-tcltk/

Ivan


Le 12/10/15 15:57, Ivan Calandra a ?crit :
> Dear Nick,
>
> You might find the function varEntryDialog() useful:
> http://www.r-bloggers.com/user-input-using-tcltk-2/
>
> HTH,
> Ivan
>
> -- 
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> https://www.researchgate.net/profile/Ivan_Calandra
>
> Le 12/10/15 15:33, nicholas.wray at ntlworld.com a ?crit :
>> Hi  I am sure that there is a command in R which tells the prog to 
>> wait until
>> you have input a value for a variable, but for the life of me I can't 
>> find it.
>>   Searches on the net only seem to talk about inputting datasets etc, 
>> not about
>> real time single inputs. I'd be most grateful if anyone could point 
>> me in the
>> right direction
>>
>> Thanks, Nick Wray
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From tal.galili at gmail.com  Mon Oct 12 16:30:42 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 12 Oct 2015 17:30:42 +0300
Subject: [R] Using MASS::boxcox for a single variable gives different
 results than the original paper
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F2EB2E@FHSDB2D11-2.csu.mcmaster.ca>
References: <CANdJ3dWbif3qUgE2iC=iCiteZDmT6+RE97V4ue30RweJQkyf0A@mail.gmail.com>
	<CANdJ3dUA_7x2XUsXbG9A2-Z5Ear5ToaMywbc6UNCVxpb6pO6hg@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F2EB2E@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CANdJ3dWPd-+qXE4weNowESD1NLAJK+-SFTNwmU=oxk+8bVEvxQ@mail.gmail.com>

Peter and John - thank you both for the answers.


Tal




----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Mon, Oct 12, 2015 at 4:45 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Tal,
>
> MASS:boxcox() evaluates the pseudo-log-likelihood at a pre-specified
> vector of values of the transformation parameter lambda. In your example,
>
> > head(a$x)
> [1] -2.000000 -1.959596 -1.919192 -1.878788 -1.838384 -1.797980
>
> Which accounts, I think, for the small difference in the answer.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Tal
> Galili
> > Sent: October 12, 2015 9:32 AM
> > To: r-help at r-project.org
> > Subject: Re: [R] Using MASS::boxcox for a single variable gives
> different results
> > than the original paper
> >
> > After trying this with the function "estimateTransform" from {car}, it
> returns
> > values similar to my solution rather than the one from MASS::boxcox:
> >
> >
> > # Toy data
> > ################
> > set.seed(13241089)
> > x <- rnorm(1000, 10)
> > x2 <- x**2 # we want to transform x2 to something more normal
> >
> >
> >
> > # using MASS::boxcox
> > ################
> >
> > mle <- function(BC) {
> > with(BC, x[which.max(y)])
> > }
> >
> > ONES <- rep(1, length(x2))
> > a <- MASS::boxcox(lm(x2 ~ ONES))
> > mle(a)
> > # lambda:
> > # 0.42424
> >
> >
> >
> > # using estimateTransform from car
> > ################
> >
> > # Same result as the paper: !
> > library(car)
> > ONES <- rep(1, length(x2))
> > estimateTransform(X=data.frame(x = ONES), Y = x2) # lambda:
> > # 0.40782
> >
> > (just as with my own function in the previous email)
> >
> >
> >
> > What am I missing?
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > ----------------Contact
> > Details:-------------------------------------------------------
> > Contact me: Tal.Galili at gmail.com |
> > Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> > www.r-statistics.com (English)
> >
> ----------------------------------------------------------------------------------------------
> >
> >
> > On Mon, Oct 12, 2015 at 12:17 PM, Tal Galili <tal.galili at gmail.com>
> wrote:
> >
> > > Hello all,
> > >
> > > Given a set of observations, I would like to find lambda for a boxcox
> > > transformation so to get a symmetric/normal result as possible.
> > >
> > > I try to use MASS::boxcox, but get different results than when using
> > > the formula from the original box-cox paper (link
> > > <http://www.jstor.org/stable/2984418?seq=1#page_scan_tab_contents>).
> > >
> > > I probably have made an error somewhere, but I can't figure out where.
> > >
> > > Here is an example in which the lambda by MASS::boxcox is 0.42424,
> > > while by the formula from the paper I get 0.40782.
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > > # Toy data
> > > ################
> > > set.seed(13241089)
> > > x <- rnorm(1000, 10)
> > > x2 <- x**2 # we want to transform x2 to something more normal
> > > plot(density(x2))
> > >
> > > # using MASS::boxcox
> > > ################
> > >
> > > zpoints <- function(y) {
> > > n <- length(y)
> > > qnorm(ppoints(n))[order(order(y))]
> > > }
> > > mle <- function(BC) {
> > > with(BC, x[which.max(y)])
> > > }
> > >
> > > a <- MASS::boxcox(x2 ~ zpoints(x2))
> > > mle(a)
> > > # lambda:
> > > # 0.42424
> > >
> > >
> > >
> > > # using formula from the paper
> > > ################
> > >
> > > loglik_lambda <- function(l, y) {
> > > GM <- exp(mean(log(y)))
> > > if(l==0) x <- log(y)*GM else x <- (y^l-1)/ (l * GM^(l-1) ) #  if(l==0)
> > > x <- log(y) else x <- (y^l-1)/ (l )
> > > sd(x)
> > > }
> > > fo <- function(l) loglik_lambda(l, y = x2) V_fo <- Vectorize(fo)
> > > V_fo(2)
> > > curve(V_fo, -.5,1.5)
> > > optimize(V_fo, c(-3,3))
> > > # lambda:
> > > # 0.40782
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From aurora.gonzalez2 at um.es  Mon Oct 12 18:39:57 2015
From: aurora.gonzalez2 at um.es (AURORA GONZALEZ VIDAL)
Date: Mon, 12 Oct 2015 18:39:57 +0200
Subject: [R] predictions several categories
Message-ID: <20151012183957.Horde.jadnOuuF7lqdHs7QvXqB9g9@webmail.um.es>

Hello everybody.

I am using the caret package in order to predict something from some data.
I have "hours" , "days" and "temperature" where "hours" are given in
decimal form, "days" are the days of the week where each observation was
colected and "temperature" is the temperature that a user of air
conditioning inputed in the device.

I have simplified the problem but the thing is I want to predict the
temperature that is going to be choose having the time (hour and day of the
week).

I try to do something like this:

hour <-
c(12,12.5,12.75,13,14,14.5,16,10,11,14,15.71,13,9,10,12,13,18,20,12.2,13)
day <-
c("m","m","t","t","w","w","th","th","f","f","st","st","sn","sn","m","t","w","th","f","st")
temperature <-
c(19,20,21,22,20,23,26,27,26,26,25,23,23,20,24,25,25,22,28,26)
df <- data.frame(hour,day,temperature)

inTrain <- createDataPartition(y=df$temperature, p=0.6,list=F)
training <- df[inTrain,]
testing <- df[-inTrain,]

modelFit <- train(temperature ~ hour+day,data=training, method="glm")
modelFit
predictions <- predict(modelFit, newdata=testing)

but the predictions have decimals, so I don't know how to treate the
temperature variable (because it is only going to be a natural value).
Which model should I use to predict those data? Do you have any advice or
manual that I could check??

Also, I would like to know the correct way of testing the model (usually if
I had just two categories I would use a confusionMatrix but here i dont
have any clue).

Thank you very very much!!


------
Aurora Gonz?lez Vidal

@. aurora.gonzalez2 at um.es
T. 868 88 7866
www.um.es/ae

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Mon Oct 12 19:06:08 2015
From: valkremk at gmail.com (Val)
Date: Mon, 12 Oct 2015 12:06:08 -0500
Subject: [R] by group
Message-ID: <CAJOiR6Y=1tOd9HCS904tDTwQX8-Knb+B2FEGMCjcQYYJzTHifA@mail.gmail.com>

Hi all,


Assume that I have the following data set :

 cntry  state city Gender (1=F and 2=M)

 1 1 1   1
 1 1 1   2
 1 1 1   1
 1 1 2   2
 1 2 2   2
 1 2 3   2
 1 2 3   1

I want to calculate the number of Females and Males,
total (F+M) and  percentage (F/M) by country, state and city.

Here is the  sample of the output file  that I would like to have in a file.

cntry state City Gender
Cntry_F Cntry_M    Cntry_total 100 (Cntry_F/Cntry_M)
St_F    st_M    St_total  100*(   St_F/   St_M)
City_F     City_M     City_total  100*( City_F/ City_M)

 1  1  1  1   3  4  7  75    2  2  4  50   1 1 3  33
 1  1  1  2   3  4  7  75    2  2  4  50   1 1 3  33
 1  1  1  1   3  4  7  75    2  2  4  50   1 1 3  33
 1  1  2  2   3  4  7  75    2  2  4  50   2 0 2 100
 1  2  2  2   3  4  7  75    2  1  3  67   2 0 2 100
 1  2  3  2   3  4  7  75    2  1  3  67   1 1 2  50
 1  2  3  1   3  4  7  75    2  1  3  67   1 1 2  50

Your help is highly appreciated in advance

	[[alternative HTML version deleted]]


From andre_mikulec at hotmail.com  Mon Oct 12 14:53:53 2015
From: andre_mikulec at hotmail.com (Andre Mikulec)
Date: Mon, 12 Oct 2015 08:53:53 -0400
Subject: [R] =?windows-1256?q?library=28nlme=29_groupedData_question=FE?=
Message-ID: <BLU174-W159B0F83960C025B4D52389C310@phx.gbl>


SUMMARY
-------

Using package nlme, I am getting the following warning
when I try to create a grouped data object using?groupedData().

I believe that my logic is faulty.

Warning message:
In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else paste0(labels, ?:
? duplicated levels in factors are deprecated

What am I doing wrong? ?How do I adjust?

Thanks,
Andre Mikulec?
Andre_Mikulec at Hotmail.com


DETAILS ( ?the following R code can be copied and pasted to the R console and ran )
-------

library(nlme)

d.x <- read.table(header=TRUE, text="
o g h i ? ? d
A C E G ? ? 1.0
A C E H ? ? 2
A C F G ? ? 4
A C F H ? ? 8

A D E G ? ? 16
A D E H ? ? 32
A D F G ? ? 64
A D F H ? ? 128

B C E G ? ? 256
B C E H ? ? 1024
B C F G ? ? 2048
B C F H ? ? 4096

B D E G ? ? 8192
B D E H ? ? 16384
B D F G ? ? 32768
B D F H ? ? 65536
", stringsAsFactors = FALSE)

str(d.x, vec.len = 16)
# 'data.frame': ? 16 obs. of ?5 variables:
# $ o: chr ?"A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B" "B" "B" "B"
# $ g: chr ?"C" "C" "C" "C" "D" "D" "D" "D" "C" "C" "C" "C" "D" "D" "D" "D"
# $ h: chr ?"E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F"
# $ i: chr ?"G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H"
# $ d: num ?1 2 4 8 16 32 64 128 256 1024 2048 4096 8192 16384 32768 65536

gd <- groupedData(formula = d ~ h | g?
? ? ? ? ? ? ? ? ? , data ?= d.x?
? ? ? ? ? ? ? ? ? , outer = ~ o?
? ? ? ? ? ? ? ? ? , inner = ~ i
)

# Warning message:
# In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else paste0(labels, ?:
# ? duplicated levels in factors are deprecated
? ?

str(gd, vec.len = 16)
# Classes 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame': ? ? ?16 obs. of ?5 variables:
# ? $ o: chr ?"A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B" "B" "B" "B"
# $ g: Ord.factor w/ 4 levels "C"<"D"<"C"<"D": 1 1 1 1 2 2 2 2 1 1 1 1 2 2 2 2
# $ h: chr ?"E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F"
# $ i: chr ?"G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H"
# $ d: num ?1 2 4 8 16 32 64 128 256 1024 2048 4096 8192 16384 32768 65536
# - attr(*, "formula")=Class 'formula' length 3 d ~ h | g
# .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
# ? - attr(*, "outer")=Class 'formula' length 2 ~o
# .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
# ? - attr(*, "inner")=Class 'formula' length 2 ~i
# .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
# ? - attr(*, "FUN")=function (x)
# ? ? - attr(*, "order.groups")= logi TRUE


SOFTWARE INFORMATION
----------------

> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats ? ? graphics ?grDevices utils ? ? datasets ?methods ? base

other attached packages:
[1] nlme_3.1-121

loaded via a namespace (and not attached):
[1] grid_3.2.2 ? ? ?lattice_0.20-33



Thanks,

Andre Mikulec?
Andre_Mikulec at Hotmail.com? 		 	   		  

From dwinsemius at comcast.net  Mon Oct 12 20:32:33 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Oct 2015 11:32:33 -0700
Subject: [R] Percentage sign in Vegan output
In-Reply-To: <1444640932952-4713496.post@n4.nabble.com>
References: <1444640932952-4713496.post@n4.nabble.com>
Message-ID: <6ADA2FCD-6C60-470E-8940-03952C9E0EF7@comcast.net>


On Oct 12, 2015, at 2:08 AM, gktahon wrote:

> Hi All,
> 
> I'm using the Vegan package in R to calculate some variables for my data set
> and to make rarefaction curves.
> However, I would like to give clear names to my samples and I do not succeed
> in this.
> 
> For the package, I first read my OTU table (this is a text file with my
> samples listed per column. The column header is the sample name as it should
> appear in the legend.). After that, I transpose the table for the analysis
> and I run the script.
> I do get a nice output, meaning my figure looks good and everything. The
> only problem is the sample names in the legend. What I have noticed is that
> everything after a 'space' is automatically cut off/deleted and that special
> characters are not taken into account. For example, when I want to show 95%,
> it gives 95. as an output. Characters like %, /, # are changed into a .
> symbol. I was wondering how I can solve this issue, because I would like to
> insert spaces and special characters in my sample names.
> 

You can turn off the automatic coercion of header text to valid R symbol names, but then you will then need to always quote them. Read the help page for `?read.table`

You could use readLines to pull in a single text line for use in annotation.


> For example, if I want my sample name to be DNA 95%, how do I have to do
> this?

Giving a specific response is hampered by the lack of any example code or data.

> 
> Many thanks in advance!
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Percentage-sign-in-Vegan-output-tp4713496.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jsorkin at grecc.umaryland.edu  Tue Oct 13 00:11:43 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Mon, 12 Oct 2015 18:11:43 -0400
Subject: [R] writing a function that will refer to the elements of a
 dataframe much as is done by lm
Message-ID: <561BF7DF020000CB0013C051@smtp.medicine.umaryland.edu>

I am trying to learn how  to write R functions (really to program in R). I want to write a function that will allow me to refer to the elements of a data frame by column name, much as is done in lm. I can't seem to get the syntax correct. I want the function to print the elements of data2[,"Mo6MONO"]
 
data2 <- data.frame(POSTHHMONO=c(1,2,3,4),Mo6MON=c(10,11,12,13))
data2
doit<- function(pre,post,data) {
  element <- deparse(substitute(pre))
  print(element)
  frame <- deparse(substitute(data))
  print(frame)
  print(frame$element)
}
doit(Mo6MONO,POSTHHMONO,data2)
 
results of running function:
Browse[1]> doit(Mo6MONO,POSTHHMONO,data2)
[1] "Mo6MONO"
[1] "data2"
Error during wrapup: $ operator is invalid for atomic vectors

 
 
I have looked at lm, but don't understand the syntax, and have tried to run lm so as to learn the syntax by just don't understand . . . .
 
HELP
 
Thanks 
John
John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From drjimlemon at gmail.com  Tue Oct 13 00:35:22 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 13 Oct 2015 09:35:22 +1100
Subject: [R] writing a function that will refer to the elements of a
 dataframe much as is done by lm
In-Reply-To: <561BF7DF020000CB0013C051@smtp.medicine.umaryland.edu>
References: <561BF7DF020000CB0013C051@smtp.medicine.umaryland.edu>
Message-ID: <CA+8X3fXVGwy-mZd1RF_T1LJTiW2t50HsTWO3WwTAO+_iS1jXug@mail.gmail.com>

Hi John,
Here are a couple of ways to do this. Note that they produce slightly
different results.

data2<-data.frame(POSTHHMONO=c(1,2,3,4),Mo6MON=c(10,11,12,13))
doit<- function(pre,post,data) {
  element <- deparse(substitute(pre))
  print(element)
  print(data[element])
  frame<-deparse(substitute(post))
  print(frame)
  print(data[frame])
}
doit(Mo6MON,POSTHHMONO,data2)

# this produces the same as the $ extractor
doit<- function(pre,post,data) {
  element <- deparse(substitute(pre))
  print(element)
  print(data[,element])
  frame<-deparse(substitute(post))
  print(frame)
  print(data[,frame])
}
doit(Mo6MON,POSTHHMONO,data2)

Jim



On Tue, Oct 13, 2015 at 9:11 AM, John Sorkin <jsorkin at grecc.umaryland.edu>
wrote:

> I am trying to learn how  to write R functions (really to program in R). I
> want to write a function that will allow me to refer to the elements of a
> data frame by column name, much as is done in lm. I can't seem to get the
> syntax correct. I want the function to print the elements of
> data2[,"Mo6MONO"]
>
> data2 <- data.frame(POSTHHMONO=c(1,2,3,4),Mo6MON=c(10,11,12,13))
> data2
> doit<- function(pre,post,data) {
>   element <- deparse(substitute(pre))
>   print(element)
>   frame <- deparse(substitute(data))
>   print(frame)
>   print(frame$element)
> }
> doit(Mo6MONO,POSTHHMONO,data2)
>
> results of running function:
> Browse[1]> doit(Mo6MONO,POSTHHMONO,data2)
> [1] "Mo6MONO"
> [1] "data2"
> Error during wrapup: $ operator is invalid for atomic vectors
>
>
>
> I have looked at lm, but don't understand the syntax, and have tried to
> run lm so as to learn the syntax by just don't understand . . . .
>
> HELP
>
> Thanks
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:16}}


From dwinsemius at comcast.net  Tue Oct 13 02:25:31 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 12 Oct 2015 17:25:31 -0700
Subject: [R] writing a function that will refer to the elements of a
	dataframe much as is done by lm
In-Reply-To: <561BF7DF020000CB0013C051@smtp.medicine.umaryland.edu>
References: <561BF7DF020000CB0013C051@smtp.medicine.umaryland.edu>
Message-ID: <A60CE440-040C-4736-8EED-1D6B69095598@comcast.net>


On Oct 12, 2015, at 3:11 PM, John Sorkin wrote:

> I am trying to learn how  to write R functions (really to program in R). I want to write a function that will allow me to refer to the elements of a data frame by column name, much as is done in lm. I can't seem to get the syntax correct. I want the function to print the elements of data2[,"Mo6MONO"]
> 
> data2 <- data.frame(POSTHHMONO=c(1,2,3,4),Mo6MON=c(10,11,12,13))
> data2
> doit<- function(pre,post,data) {
>  element <- deparse(substitute(pre))
>  print(element)
>  frame <- deparse(substitute(data))
>  print(frame)
>  print(frame$element)
> }
> doit(Mo6MONO,POSTHHMONO,data2)
> 
> results of running function:
> Browse[1]> doit(Mo6MONO,POSTHHMONO,data2)
> [1] "Mo6MONO"
> [1] "data2"
> Error during wrapup: $ operator is invalid for atomic vectors
> 
> 
> 
> I have looked at lm, but don't understand the syntax, and have tried to run lm so as to learn the syntax by just don't understand . . . .
> 

Jim has already given an answer to the specific case of of your example, but lm doesn't actually have formals that are passed such values. It accepts formula objects which have a different syntax and evaluation rules. So it was not clear to me that your preamble matched your example.

When I have done what you did I just passed character vectors and used them inside "[[" since that is the equivalent of using "$". You are advised in the help pages not to use $ inside functions. Notice that deparse(substitute(.)) delivers a character vector.

-- 
David.
> HELP
> 
> Thanks 
> John
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing) 
> 
> Confidentiality Statement:
> This email message, including any attachments, is for ...{{dropped:15}}


From kristi.glover at hotmail.com  Tue Oct 13 02:44:28 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Tue, 13 Oct 2015 00:44:28 +0000
Subject: [R] 3D matrix columns messed up _ looking for your help
In-Reply-To: <CA+8X3fW7hSatHookgxk2vv4PzD-3rBUbmrHkU68Yh4zO1gLb-g@mail.gmail.com>
References: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>,
	<CA+8X3fW7hSatHookgxk2vv4PzD-3rBUbmrHkU68Yh4zO1gLb-g@mail.gmail.com>
Message-ID: <BY2PR13MB0454762043FFC5C4118DD62FFA300@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi Jim,

Thank you very much for your suggestions. It seems very easy but it is frustrating as it did not work me. with creating factors and rearranging the columns, still z value (site) did change.

for example

Tag site  DATE
a1 2C7  t1
a1 ENL  t3
a1 ENM t2

ENL is supposed to be assigned for the period t3. ENM should be assigned in t2, but using the code, the table gave wrong information as the z value (site) did not move to the corresponding column. ENL is in t2, ENM is inn t3 coumns, which is wrong.

> tmp1
   t1    t2    t3
a1 "2C7" "ENL" "ENM"

I have included the code if any one help me to solve the problem. This is a just example, I have a very big data set so that  I could not check it manually therefore, I just checked few rows  but it did not work. Your help is highly appreciated.


Here is the example

A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class = "factor"),
    site = structure(1:3, .Label = c("2C7", "ENL", "ENM"), class = "factor"),
    DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
    ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label = c("t1",
    "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
"DATE", "date"), row.names = c(NA, -3L), class = "data.frame")

A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
tmp <- split(A, A$Tag)
head(tmp)
tail(tmp)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(A$date)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(A$site))
}))

tmp1





________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: October 12, 2015 4:22 AM
To: Kristi Glover
Cc: R-help
Subject: Re: [R] 3D matrix columns messed up

Hi Kristi,
The first part is relatively easy:

# change first line to
x$time<-factor(x$time,levels=c("t1","t2","t3","t4","t10","t21"))

As you have specified "site" as the second element in "x", not the third, perhaps you just want:

x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L, 1L),
 .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
 time = structure(c(1L, 3L, 5L, 1L, 5L, 1L, 6L, 2L, 4L),
 .Label = c("t1", "t10", "t2", "t21", "t3", "t4"), class = "factor")),
 site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L),
 .Label = c("A", "B", "D"), class = "factor"),
 .Names = c("vs", "time", "site"), class = "data.frame",
 row.names = c(NA, -9L))

Jim

On Mon, Oct 12, 2015 at 7:41 PM, Kristi Glover <kristi.glover at hotmail.com<mailto:kristi.glover at hotmail.com>> wrote:
Hi R Users,
I was trying to make a matrix with three variables (x,y, z), but y variable (columns) names did not stay in its sequential order, t1,t2,t3,---t21; rather the matrix columns automatically appeared as a t1,t10, t2,t20 etc. Besides these, z value (sites) did not come in the right place (meaning in right columns name). I am wondering how I can make the matrix with the sequential order with right z value (site). I tried it several ways but did not work. One of the examples I used is given here. Would you mind to give me a mints?

x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L,
1L), .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
    site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L), .Label = c("A",
    "B", "D"), class = "factor"), time = structure(c(1L, 3L,
    5L, 1L, 5L, 1L, 6L, 2L, 4L), .Label = c("t1", "t10", "t2",
    "t21", "t3", "t4"), class = "factor")), .Names = c("vs",
"site", "time"), class = "data.frame", row.names = c(NA, -9L))


x$time<-factor(x$time)
tmp <- split(x, x$vs)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(x$time)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(x$site))
}))


tmp1


## I want the z (site) in respective columns.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From asengupta94404 at yahoo.com  Tue Oct 13 01:51:34 2015
From: asengupta94404 at yahoo.com (Amit Sengupta)
Date: Mon, 12 Oct 2015 23:51:34 +0000 (UTC)
Subject: [R] readaff() problem
References: <1110239268.2655284.1444693894730.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1110239268.2655284.1444693894730.JavaMail.yahoo@mail.yahoo.com>

 Hi,I am having a problem with the ReadAffy() in the university R programming environment. I install affyPLM and invoke library(affyPLM) in the following way. I have the cel files in the craig subdirectory. Please let me know how to resolve the problem.Amit
source("http://bioconductor.org/biocLite.R")  biocLite("affyPLM") biocLite("gcrma") library(affyPLM)> setwd("c:/Users/amit.sengupta/Desktop/myRfolder/craig")
> craig.data=ReadAffy()
Error in AllButCelsForReadAffy(..., filenames = filenames, widget = widget,? : 
? No cel filennames specified and no cel files in specified directory:c:/Users/amit.sengupta/Desktop/myRfolder/craig
Included are the outputs of installations.     
   -   ? Home 
   -  ??Amit 
   -   ? Help  
 
Press ? for keyboard shortcuts.
     Close Ad       
   - Mail
   - Contacts
   - Calendar
   - Notepad
   - Messenger
   -   News Feed 1  
                            
  
                        
| 
| 
|  |
|   |
|  |
|   |


| 
|  |


| 
|   |
|  |
|   |
|  |

 |

 |


|   |
|  |
|   |
| 
|  |  |

 |
|   |


|   |
|  |
|   |


|  | 
|  |
|   |
|  |
|   |
|  |  |
|   |
|  |
|   |
|  |  |
|  |
|   |

 |  |


|   |
|   |
|  |
|   |
| 
|    |

 |
|   |
| 
|  |  |

 |
|   |


|   |


|  | 
|  |
|   |
|  |  |
|   |

 |  |


|  |


|   |
|  |
|   |
|  |
|   |
|  |
|   |
|  |
|   |

 |

 |

      
|        |
|     |
|       |
|    |

                  
|    |

       
  
                                  
   - 
   - 
   - 
      
   -  
   -  
      
|        |
|     |
|       |
|    |

                  
|    |

       
  
                                                                                    
|        |
|     |
|       |
|    |

                  
|    |

       
  
                                                                        
|        |
|     |
|       |
|    |

                  
|    |

       
  
                         
   


                                                              


       
|        |
|     |
|       |
|    |

                  
|    |

   
|   |

   
   - 
  
|   |
|     
   



 
      |
|    |

                    
|    |

     
 preproc (5) 
   People         Amit Sengupta  Hi David, After installing bioclite, I invoke library(affyplm) and run into this problem. > library(affyPLM) Loading required package: affy Error: package ?Biobase? required by ?affy? could no         Sep 29 at 12:43 PM         Wheeler, David Linnard  Hello Sir, I had similar problems. For me I had to essentially resource bicolite everytime as below. Also, try to put quotations around your package names after the bioclite command, see it that works         Sep 29 at 3:08 PM   Hi David,This is the problem now with ReadAffy(). I have all files in myRfolder. Let me know what you think.Amit-------------------------------------------------------------
> source("http://bioconductor.org/biocLite.R")
Bioconductor version 3.1 (BiocInstaller 1.18.4), ?biocLite for help
> biocLite("affyPLM")
BioC_mirror: http://bioconductor.org
Using Bioconductor version 3.1 (BiocInstaller 1.18.4), R version 3.2.0.
Installing package(s) ?affyPLM?
trying URL 'http://bioconductor.org/packages/3.1/bioc/bin/windows/contrib/3.2/affyPLM_1.44.0.zip'
Content type 'application/zip' length 5289800 bytes (5.0 MB)
downloaded 5.0 MB

package ?affyPLM? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
??????? C:\Users\amit.sengupta\AppData\Local\Temp\RtmpITiCKT\downloaded_packages
> biocLite("gcrma")
BioC_mirror: http://bioconductor.org
Using Bioconductor version 3.1 (BiocInstaller 1.18.4), R version 3.2.0.
Installing package(s) ?gcrma?
trying URL 'http://bioconductor.org/packages/3.1/bioc/bin/windows/contrib/3.2/gcrma_2.40.0.zip'
Content type 'application/zip' length 490279 bytes (478 KB)
downloaded 478 KB

package ?gcrma? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
??????? C:\Users\amit.sengupta\AppData\Local\Temp\RtmpITiCKT\downloaded_packages
> library(affyPLM)
Loading required package: BiocGenerics
Loading required package: parallel

Attaching package: ?BiocGenerics?

The following objects are masked from ?package:parallel?:

??? clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,
??? clusterExport, clusterMap, parApply, parCapply, parLapply,
??? parLapplyLB, parRapply, parSapply, parSapplyLB

The following object is masked from ?package:stats?:

??? xtabs

The following objects are masked from ?package:base?:

??? anyDuplicated, append, as.data.frame, as.vector, cbind, colnames,
??? do.call, duplicated, eval, evalq, Filter, Find, get, intersect,
??? is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax,
??? pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rep.int,
??? rownames, sapply, setdiff, sort, table, tapply, union, unique,
??? unlist, unsplit

Loading required package: affy
Loading required package: Biobase
Welcome to Bioconductor

??? Vignettes contain introductory material; view with
??? 'browseVignettes()'. To cite Bioconductor, see
??? 'citation("Biobase")', and for packages 'citation("pkgname")'.

Loading required package: gcrma
Creating a generic function for ?nchar? from package ?base? in package ?S4Vectors?
Loading required package: preprocessCore
Warning message:
package ?affy? was built under R version 3.2.1  
	[[alternative HTML version deleted]]


From r.otojanov at qmul.ac.uk  Mon Oct 12 20:23:33 2015
From: r.otojanov at qmul.ac.uk (mrrox)
Date: Mon, 12 Oct 2015 11:23:33 -0700 (PDT)
Subject: [R] Testing Restrictions on Beta (long-run coefficients),
 reproducible example
Message-ID: <1444674213782-4713512.post@n4.nabble.com>

The code given below estimates a VEC model with 4 cointegrating vectors. It
is a reproducible code, so just copy and paste into your R console (or
script editor).

nobs = 200
e = rmvnorm(n=nobs,sigma=diag(c(.5,.5,.5,.5,.5)))
e1.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,1])
e2.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,2])
e3.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,3])
e4.ar1 = arima.sim(model=list(ar=.75),nobs,innov=e[,4])
y5 = cumsum(e[,5])
y1 = y5 + e1.ar1
y2 = y5 + e2.ar1
y3 = y5 + e3.ar1
y4 = y5 + e4.ar1
data = cbind(y1,y2,y3,y4,y5)

jcointt = ca.jo(data,ecdet="const",type="trace",K=2,spec="transitory")
summary(jcointt)
# estimate VECM with 4 cointegrating vectors
vecm <- cajorls(jcointt,r=4)
summary(vecm$rlm)
print(vecm)


I want to re-estimate the model with the following restrictions put on the
coinegrating vectors:
            
                   ect1   ect2  ect3   ect4
y1.l1               1      0      0     0
y2.l1            b1.1     1      0     0
y3.l1            b2.1     0      1     0
y4.l1            b3.1     0      0     1
y5.l1            b4.1    b4.2   b4.3   b4.4
constant        c1      c2     c3    c4      


here, b1.1 through to b4.1 are the coefficients (?1,?2,?3,?4) of the first
cointegrating vector. Similarly, b4.4 and c4 are coefficients of the fourth
cointegrating equation. Then, in order to test the restrictions on
Coinegrating Vectors, I run the following code:

test <- blrtest(jcointt,H=H1,r=4)


However, I do not know how I should specify the H1 matrix in this instance.
I was wondering if someone could demonstrate how I should go ahead with
testing the restrictions on long run equations and then re-estimate the
model using the above restrictions:

vecm2 <- cajorls(test,r=4)
summary(vecm2$rlm)
print(vecm2)


How should I specify the H1 matrix above in order to re-estimate the
re-parameterised cointegrating equations? I want to use the coefficients of
the first cointegrating equation (ect1) for inference.



--
View this message in context: http://r.789695.n4.nabble.com/Testing-Restrictions-on-Beta-long-run-coefficients-reproducible-example-tp4713512.html
Sent from the R help mailing list archive at Nabble.com.


From rmcgu at doh.health.nsw.gov.au  Tue Oct 13 00:27:20 2015
From: rmcgu at doh.health.nsw.gov.au (MCGUIRE, Rhydwyn)
Date: Mon, 12 Oct 2015 22:27:20 +0000
Subject: [R] by group
In-Reply-To: <CAJOiR6Y=1tOd9HCS904tDTwQX8-Knb+B2FEGMCjcQYYJzTHifA@mail.gmail.com>
References: <CAJOiR6Y=1tOd9HCS904tDTwQX8-Knb+B2FEGMCjcQYYJzTHifA@mail.gmail.com>
Message-ID: <AF36C32BE015CB48883C4A9F73CC8C3201748822D7@DOHNSMXDB03.doh.health.nsw.gov.au>

ddply() is what you are looking for. Here is an example http://www.inside-r.org/packages/cran/plyr/docs/ddply

Cheers,
Rhydwyn 


Rhydwyn McGuire
Senior Biostatistician | Health Statistics NSW
Level 7, 73 Miller St, North Sydney 2060
Tel 02 9391 9781 | rmcgu at doh.health.nsw.gov.au
www.health.nsw.gov.au



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
Sent: Tuesday, 13 October 2015 4:06 AM
To: r-help at r-project.org
Subject: [R] by group

Hi all,


Assume that I have the following data set :

 cntry  state city Gender (1=F and 2=M)

 1 1 1   1
 1 1 1   2
 1 1 1   1
 1 1 2   2
 1 2 2   2
 1 2 3   2
 1 2 3   1

I want to calculate the number of Females and Males, total (F+M) and  percentage (F/M) by country, state and city.

Here is the  sample of the output file  that I would like to have in a file.

cntry state City Gender
Cntry_F Cntry_M    Cntry_total 100 (Cntry_F/Cntry_M)
St_F    st_M    St_total  100*(   St_F/   St_M)
City_F     City_M     City_total  100*( City_F/ City_M)

 1  1  1  1   3  4  7  75    2  2  4  50   1 1 3  33
 1  1  1  2   3  4  7  75    2  2  4  50   1 1 3  33
 1  1  1  1   3  4  7  75    2  2  4  50   1 1 3  33
 1  1  2  2   3  4  7  75    2  2  4  50   2 0 2 100
 1  2  2  2   3  4  7  75    2  1  3  67   2 0 2 100
 1  2  3  2   3  4  7  75    2  1  3  67   1 1 2  50
 1  2  3  1   3  4  7  75    2  1  3  67   1 1 2  50

Your help is highly appreciated in advance

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
__________________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of health's Electronic Messaging Policy.
__________________________________________________________________________________________________________
_______________________________________________________________________________________________________
Disclaimer: This message is intended for the addressee named and may contain confidential information.
If you are not the intended recipient, please delete it and notify the sender.
Views expressed in this message are those of the individual sender, and are not necessarily the views of the NSW Ministry of Health.
_______________________________________________________________________________________________________
This email has been scanned for the NSW Ministry of Health by the Websense Hosted Email Security System.
Emails and attachments are monitored to ensure compliance with the NSW Ministry of Health's Electronic Messaging Policy.


From ahawk14 at yahoo.com  Tue Oct 13 02:55:42 2015
From: ahawk14 at yahoo.com (Annie Hawk)
Date: Tue, 13 Oct 2015 00:55:42 +0000 (UTC)
Subject: [R] how to do away for loop using functionals?
References: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>

HI R-experts, 


I am trying to speed up my calculation of the A results below and replace the for loop withsome functionals like lapply.? After manyreadings, trial and error, I still have no success.? Would anyone please give me some hints onthat?? 

Thank you in advance.

Anne?


The program is this, I have a complicated function and itneeds to operate on some subsets of a dataset many times, depending on thevalues of group.? I simplify the functionand dataset for this example run.? 

getResult <- function(d) {

? ? ??#examplefunction

?????weighted.mean(x=d[,1], w=d[,2]) 

}


?
#example data setup

n=20; 

set.seed(1)

g=rep(1:5,each=4)

df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1, 0.4) , g )); df

getResult(df)

i0=c(1,2,4,5,5)

ng= length(unique(g))


?
#initiation of result matrix

A=matrix(Inf, ng,?ng); A

for(i in 1:ng) 

{????????????? cat("i:",i,"")

??????????????? for(jin i0[i]:ng) {

??????????????????????????????? ok= !is.na(match(g,i:j)); cat("j:",j,"\n"); 

??????????????? ?? ???????????? A[i,j]=getResult(d=df[ok,])

??????????????? } #endfor (j)

} #end for (i)

Is there an elegant way to remove the for loop here?? I try to make it flat for faster run but Icannot figure out how to subset the observations faster without error to apply the functiongetResult.? Any hint is appreciated.


?

?
on another note, is there a more elegant way to initiate the list as follows?

mylist=list(); w=rep(4,5)

for (i in 1:5) mylist[[i]]=w[i:5]


?

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Tue Oct 13 11:28:18 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 13 Oct 2015 11:28:18 +0200
Subject: [R] using the apply() family to evaluate nested functions with
	common arguments
In-Reply-To: <CAPLSCn1wJctk+fx7ar-idcaGK7M=++RPHdv1hMzUpcLq4UTkMg@mail.gmail.com>
References: <CAPLSCn1wJctk+fx7ar-idcaGK7M=++RPHdv1hMzUpcLq4UTkMg@mail.gmail.com>
Message-ID: <CAPLSCn3Rb=NwX=e-5O9PozfF+afjw3aVW90YQ3pwWdUaq8dsug@mail.gmail.com>

I'm sorry, I forgot to mention that in the last step I have to use the
choose() function for all the elements of x not only x[1],x[2], and x[3].

Any suggestions or recommendation for some reference or a package that can
help me sort that out.

Thanks.

Maram Salem

On 11 October 2015 at 18:52, Maram SAlem <marammagdysalem at gmail.com> wrote:

> Dear All,
>
> I'm trying to use the apply family to evaluate 2 nested functions whose
> arguments are somewhat overlapping. I'm doing this in order to evaluate
> nested multiple summations in a certain equation. First, I created the s
> matrix whose rows satisfy some logical condition.
>
> n=8
>
> m=4
>
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
>
> for (i in 1:m-1)
>
>  {
>
> D[,i]<-seq(0,n-m,1)
>
>  }
>
> ED <- do.call(`expand.grid`,as.data.frame(D))
>
> ED<-as.matrix(ED)
>
> lk<-which(rowSums(ED)<=(n-m))
>
> s<-ED[lk,]
>
>
> Then, I'm trying to evaluate a function called simpfun for each row of s,
> which could be easily done using the apply () function. The problem is that
> within the simpfun I need to evaluate another function, incomb(). This
> function has to be first evaluated for each row of the matrix LED, whose
> elements are sequences having the corresponding elements of each row of s
> as their upper limits.
>
>
> simpfun<- function (x,n,m,p,alpha,beta)
>
>   {
>
>   a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))
>
>   b<- vector(mode = "numeric", length = m-1)
>
>   for ( i in 1:m-1)
>
>    {
>
>    b[i]<- (m-i)
>
>    }
>
>   c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))-sum(b%*%x)))
>
>   d <-vector(mode = "numeric", length = m-1)
>
>    for (i in 1:m-1)
>
>    {
>
>    d[i]<- n- (sum(x[(1):(i)])) - i
>
>    }
>
>   e<- n*(prod(d))*c
>
>   LD<-list()
>
>    for (i in 1:(m-1))
>
>    {
>
>    LD[[i]]<-seq(0,x[i],1)
>
>    }
>
>    LD[[m]]<-seq(0,(n-m-sum(x)),1)
>
>    LED<-expand.grid (LD)
>
>    LED<-as.matrix(LED)
>
>      incomb<-function(x,alpha,beta) {
>
>
> g<-((-1)^(sum(LED[1,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))
>
>              fd<-
> choose(x[1],LED[1,1])*choose(x[2],LED[1,2])*choose(x[3],LED[1,3])
>
>           return (g)
>
>       }
>
>
>
> }
>
>
>
> where my x in the simpfun() refers to one of the rows of the s matrix, so
> that I'll be able to use something like
>
>
> va<-apply(s,1,simpfun,n=,m=,p=,alpha=,beta=)
>
>
>
> to apply it to each row of s.
>
>
>
> The problem now is that for each row of s (which is supposed to be my x in
> the simpfun()) ,I need to first apply the incomb() function for all the
> rows of LED.Thus, I need to modify what I wrote above in the body of the
> incomb() function in terms of something like y instead of LED[1,], so that
> I can again use the apply() function on all its rows first for one row of s
> ,say x, and then repeat this for all the other rows of s. I can't figure
> out how to do this while still having the rows of s, say x, as one of the
> arguments of the incomb() function for which I'm going to use the apply()
> function once more.
>
>
> I'm sorry if what I'm asking for is not that clear, but I'm trying to
> simplfy things as much as possible so that we don't go into tedious detalis.
>
>
> Thanks a lot in advance.
>
>
> Maram Salem
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Tue Oct 13 12:24:16 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 13 Oct 2015 21:24:16 +1100
Subject: [R] 3D matrix columns messed up _ looking for your help
In-Reply-To: <BY2PR13MB0454762043FFC5C4118DD62FFA300@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>
	<CA+8X3fW7hSatHookgxk2vv4PzD-3rBUbmrHkU68Yh4zO1gLb-g@mail.gmail.com>
	<BY2PR13MB0454762043FFC5C4118DD62FFA300@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fUgNXLFLTsBRe=EJnhydnrqMKVpHicAd4djmB0xurvZNA@mail.gmail.com>

Hi Kristi,
This is a bit hard to follow, but I'll try. As you are replacing the
numeric values of the intermediate table with the character values of the
factor A$date, it looks to me as though the answer is as it should be. 2 ->
ENL, 3 -> ENM. I suspect that the solution is not difficult, but I can't
quite make out what you are trying to accomplish.

Jim


On Tue, Oct 13, 2015 at 11:44 AM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Hi Jim,
>
> Thank you very much for your suggestions. It seems very easy but it is
> frustrating as it did not work me. with creating factors and rearranging
> the columns, still z value (site) did change.
>
> for example
>
> Tag site  DATE
> a1 2C7  t1
> a1 ENL  t3
> a1 ENM t2
>
> ENL is supposed to be assigned for the period t3. ENM should be assigned
> in t2, but using the code, the table gave wrong information as the z value
> (site) did not move to the corresponding column. ENL is in t2, ENM is inn
> t3 coumns, which is wrong.
>
> > tmp1
>    t1    t2    t3
> a1 "2C7" "ENL" "ENM"
>
> I have included the code if any one help me to solve the problem. This is
> a just example, I have a very big data set so that  I could not check
> it manually therefore, I just checked few rows  but it did not work. Your
> help is highly appreciated.
>
>
> Here is the example
>
> A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class =
> "factor"),
>     site = structure(1:3, .Label = c("2C7", "ENL", "ENM"), class =
> "factor"),
>     DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
>     ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label = c("t1",
>     "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
> "DATE", "date"), row.names = c(NA, -3L), class = "data.frame")
>
> A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
> tmp <- split(A, A$Tag)
> head(tmp)
> tail(tmp)
> tmp1 <- do.call(rbind, lapply(tmp, function(x){
> tb <- table(A$date)
> idx <- which(tb>0)
> tb1 <- replace(tb, idx, as.character(A$site))
> }))
>
> tmp1
>
>
>
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* October 12, 2015 4:22 AM
> *To:* Kristi Glover
> *Cc:* R-help
> *Subject:* Re: [R] 3D matrix columns messed up
>
> Hi Kristi,
> The first part is relatively easy:
>
> # change first line to
> x$time<-factor(x$time,levels=c("t1","t2","t3","t4","t10","t21"))
>
> As you have specified "site" as the second element in "x", not the third,
> perhaps you just want:
>
> x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L, 1L),
>  .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
>  time = structure(c(1L, 3L, 5L, 1L, 5L, 1L, 6L, 2L, 4L),
>  .Label = c("t1", "t10", "t2", "t21", "t3", "t4"), class = "factor")),
>  site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L),
>  .Label = c("A", "B", "D"), class = "factor"),
>  .Names = c("vs", "time", "site"), class = "data.frame",
>  row.names = c(NA, -9L))
>
> Jim
>
> On Mon, Oct 12, 2015 at 7:41 PM, Kristi Glover <kristi.glover at hotmail.com>
> wrote:
>
>> Hi R Users,
>> I was trying to make a matrix with three variables (x,y, z), but y
>> variable (columns) names did not stay in its sequential order,
>> t1,t2,t3,---t21; rather the matrix columns automatically appeared as
>> a t1,t10, t2,t20 etc. Besides these, z value (sites) did not come in the
>> right place (meaning in right columns name). I am wondering how I can make
>> the matrix with the sequential order with right z value (site). I tried it
>> several ways but did not work. One of the examples I used is given here.
>> Would you mind to give me a mints?
>>
>> x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L,
>> 1L), .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
>>     site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L), .Label =
>> c("A",
>>     "B", "D"), class = "factor"), time = structure(c(1L, 3L,
>>     5L, 1L, 5L, 1L, 6L, 2L, 4L), .Label = c("t1", "t10", "t2",
>>     "t21", "t3", "t4"), class = "factor")), .Names = c("vs",
>> "site", "time"), class = "data.frame", row.names = c(NA, -9L))
>>
>>
>> x$time<-factor(x$time)
>> tmp <- split(x, x$vs)
>> tmp1 <- do.call(rbind, lapply(tmp, function(x){
>> tb <- table(x$time)
>> idx <- which(tb>0)
>> tb1 <- replace(tb, idx, as.character(x$site))
>> }))
>>
>>
>> tmp1
>>
>>
>> ## I want the z (site) in respective columns.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From neverstop at hotmail.it  Tue Oct 13 10:59:44 2015
From: neverstop at hotmail.it (Neverstop)
Date: Tue, 13 Oct 2015 01:59:44 -0700 (PDT)
Subject: [R] k-nearest neighbour classification
Message-ID: <1444726784734-4713523.post@n4.nabble.com>

Hi, I'm trying to perform a cross validation to choose the optimal k in the
k-nearest-neighbors algorithm for classification. I'm using the  knn
<http://stat.ethz.ch/R-manual/R-devel/library/class/html/knn.html>  
function of the package class. Reading the R documentation, I've found out
that there's already a function to perform cross validation:  knn.cv
<http://stat.ethz.ch/R-manual/R-devel/library/class/html/knn.cv.html>  . The
problem is that I don't understand how I should use it.

data(iris)
head(iris)
predictors.training=iris[c(1:25,51:75,101:125),c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")]
predictors.test=iris[c(26:50,76:100,126:150),c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")]
classes.training=iris[c(1:25,51:75,101:125),"Species"]
library(class)
knn.cv(train=predictors.training, cl=classes.training, k=c(1,3,5,7),
prob=TRUE)

Warning messages:
1: In if (ntr - 1 < k) { :
  the condition has length > 1 and only the first element will be used
2: In if (k < 1) stop(gettextf("k = %d must be at least 1", k), domain = NA)
:
  the condition has length > 1 and only the first element will be used

Thank you.





--
View this message in context: http://r.789695.n4.nabble.com/k-nearest-neighbour-classification-tp4713523.html
Sent from the R help mailing list archive at Nabble.com.


From maw90 at aber.ac.uk  Tue Oct 13 11:35:16 2015
From: maw90 at aber.ac.uk (mnw)
Date: Tue, 13 Oct 2015 02:35:16 -0700 (PDT)
Subject: [R] for loop not working
In-Reply-To: <1444403336163-4713392.post@n4.nabble.com>
References: <1444403336163-4713392.post@n4.nabble.com>
Message-ID: <1444728916107-4713525.post@n4.nabble.com>

Thank you for your comments. I guess what I need is to store movements and
then loop through that matrix. Here is a snippet of the 'movement' code. I
am trying to fill the matrix below with data from this loop. Is there
something else my matrix (bottom) requires? Or its positioning?

Many thanks,







# determine whether movement is occurring and if so what type
  # if there are insufficient history items then just record movement types
discretely
  
   if (i < historyLength) movement <- movementType(relAngle, angleThreshold)
  
  else if (i > historyLength-1) {
    # Array to store speeds
    speedHistory <- array(historyLength)
    n = historyLength-1
    # get the speeds from the previous n (hisoryLength) "Movements" 
    for (j in seq(1, length(historyLength))){
      speedHistory [n] = R[i-j, 6]
      n-1
      }
    
      if (!bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
"non-moving" 
      else if(bayesFilter(speedHistory, minSpeed, GPS_accy)) movement <-
movementType(relAngle, angleThreshold)
  
  
    
    holder <- matrix(data = movement, nrow = nrow(R), ncol = 1)
   
    
  }
  



--
View this message in context: http://r.789695.n4.nabble.com/for-loop-not-working-tp4713392p4713525.html
Sent from the R help mailing list archive at Nabble.com.


From dessen at igr.fr  Tue Oct 13 10:06:51 2015
From: dessen at igr.fr (Philippe DESSEN)
Date: Tue, 13 Oct 2015 10:06:51 +0200
Subject: [R] Windows release  R 3.2.2 : internet.dll module
Message-ID: <25782DE5-B5D5-4493-8425-D42190B5C541@igr.fr>

Hi

With the Windows release R-3.2.2,  I have a problem of internet.dll module
which prevents the use of automatic package loading in applications  and other access to internet (ex: BrB Array Tools )
There was no problem with the previous release  3.2.0 on the same DELL Windows 7 machine.
Is someboby have an explanation ?
There is some information on the FAQ , but without solution !
> 	https://cran.r-project.org/bin/windows/base/rw-FAQ.html
> 
> 	2.19 The Internet download functions fail.
> 

Best  regards

Philippe Dessen
IGR, Villejuif, France


R version 3.2.2 (2015-08-14) -- "Fire Safety"
Copyright (C) 2015 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)
?.
Type 'q()' to quit R.

> update.packages()
--- Please select a CRAN mirror for use in this session ---
Error in download.file(url, destfile = f, quiet = TRUE) : 
  internet routines cannot be loaded
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
  unable to load shared object 'C:/PROGRA~1/R/R-32~1.2/modules/x64/internet.dll':
  LoadLibrary failure:  The specified procedure could not be found.
Error in contrib.url(repos, type) : 
  trying to use CRAN without setting a mirror
> 



> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows XP Professional x64 (build 3790) Service Pack 2

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     
>


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Oct 13 13:37:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 13 Oct 2015 07:37:33 -0400
Subject: [R] Windows release R 3.2.2 : internet.dll module
In-Reply-To: <25782DE5-B5D5-4493-8425-D42190B5C541@igr.fr>
References: <25782DE5-B5D5-4493-8425-D42190B5C541@igr.fr>
Message-ID: <561CECFD.7010405@gmail.com>

On 13/10/2015 4:06 AM, Philippe DESSEN wrote:
> Hi
> 
> With the Windows release R-3.2.2,  I have a problem of internet.dll module
> which prevents the use of automatic package loading in applications  and other access to internet (ex: BrB Array Tools )
> There was no problem with the previous release  3.2.0 on the same DELL Windows 7 machine.
> Is someboby have an explanation ?
> There is some information on the FAQ , but without solution !

The important error message is the one that says R was unable to load
internet.dll.  Possible reasons for this are:

 - it is not there, or has been damaged.  A re-install of R might fix this.

 - something on your system is interfering with it, e.g. a virus checker
may have marked it as dangerous.  I haven't heard this from anyone else,
so it may be a false positive from your virus checker, or it may be that
the location you downloaded from has a damaged copy.

Duncan Murdoch

>> 	https://cran.r-project.org/bin/windows/base/rw-FAQ.html
>>
>> 	2.19 The Internet download functions fail.
>>
> 
> Best  regards
> 
> Philippe Dessen
> IGR, Villejuif, France
> 
> 
> R version 3.2.2 (2015-08-14) -- "Fire Safety"
> Copyright (C) 2015 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> ?.
> Type 'q()' to quit R.
> 
>> update.packages()
> --- Please select a CRAN mirror for use in this session ---
> Error in download.file(url, destfile = f, quiet = TRUE) : 
>   internet routines cannot be loaded
> In addition: Warning message:
> In download.file(url, destfile = f, quiet = TRUE) :
>   unable to load shared object 'C:/PROGRA~1/R/R-32~1.2/modules/x64/internet.dll':
>   LoadLibrary failure:  The specified procedure could not be found.
> Error in contrib.url(repos, type) : 
>   trying to use CRAN without setting a mirror
>>
> 
> 
> 
>> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows XP Professional x64 (build 3790) Service Pack 2
> 
> locale:
> [1] LC_COLLATE=English_United States.1252 
> [2] LC_CTYPE=English_United States.1252   
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                          
> [5] LC_TIME=English_United States.1252    
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base     
>>
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jvadams at usgs.gov  Tue Oct 13 14:54:27 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 13 Oct 2015 07:54:27 -0500
Subject: [R] k-nearest neighbour classification
In-Reply-To: <1444726784734-4713523.post@n4.nabble.com>
References: <1444726784734-4713523.post@n4.nabble.com>
Message-ID: <CAN5YmCFEM0nqZS+KbHd9Qx0pUNzAWEa2RnHUibxJujqoON=W9Q@mail.gmail.com>

The argument k should be a scalar, not a vector.  So, for example, this
works:

knn.cv(train=predictors.training, cl=classes.training, k=3, prob=TRUE)

Jean


On Tue, Oct 13, 2015 at 3:59 AM, Neverstop <neverstop at hotmail.it> wrote:

> Hi, I'm trying to perform a cross validation to choose the optimal k in the
> k-nearest-neighbors algorithm for classification. I'm using the  knn
> <http://stat.ethz.ch/R-manual/R-devel/library/class/html/knn.html>
> function of the package class. Reading the R documentation, I've found out
> that there's already a function to perform cross validation:  knn.cv
> <http://stat.ethz.ch/R-manual/R-devel/library/class/html/knn.cv.html>  .
> The
> problem is that I don't understand how I should use it.
>
> data(iris)
> head(iris)
>
> predictors.training=iris[c(1:25,51:75,101:125),c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")]
>
> predictors.test=iris[c(26:50,76:100,126:150),c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width")]
> classes.training=iris[c(1:25,51:75,101:125),"Species"]
> library(class)
> knn.cv(train=predictors.training, cl=classes.training, k=c(1,3,5,7),
> prob=TRUE)
>
> Warning messages:
> 1: In if (ntr - 1 < k) { :
>   the condition has length > 1 and only the first element will be used
> 2: In if (k < 1) stop(gettextf("k = %d must be at least 1", k), domain =
> NA)
> :
>   the condition has length > 1 and only the first element will be used
>
> Thank you.
>
>
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/k-nearest-neighbour-classification-tp4713523.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lauren.spirko at temple.edu  Tue Oct 13 16:36:39 2015
From: lauren.spirko at temple.edu (lspirk)
Date: Tue, 13 Oct 2015 07:36:39 -0700 (PDT)
Subject: [R] var.gamma in the prop.odds funtion (timereg package)
Message-ID: <1444746999629-4713532.post@n4.nabble.com>

Hi R users!

I am trying to calculate the variance of the parameter
under the null (Ho) using the "prop.odds" function in the timereg package.
I know var.gamma will give the variance of the parameter, but how do I find
this under Ho?

For the Cox PH model, I used iter = 0 and the "vcov" function:

        cox <- coxph(Surv(time, censor) ~ x, iter = 0, init = 0, data = dat)
        sig2 <- vcov(cox)

Is there something similar to use for a prop.odds model?

Thanks for the help!



--
View this message in context: http://r.789695.n4.nabble.com/var-gamma-in-the-prop-odds-funtion-timereg-package-tp4713532.html
Sent from the R help mailing list archive at Nabble.com.


From kristi.glover at hotmail.com  Tue Oct 13 18:17:30 2015
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Tue, 13 Oct 2015 16:17:30 +0000
Subject: [R] 3D matrix columns messed up _ looking for your help
In-Reply-To: <CA+8X3fUgNXLFLTsBRe=EJnhydnrqMKVpHicAd4djmB0xurvZNA@mail.gmail.com>
References: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>
	<CA+8X3fW7hSatHookgxk2vv4PzD-3rBUbmrHkU68Yh4zO1gLb-g@mail.gmail.com>
	<BY2PR13MB0454762043FFC5C4118DD62FFA300@BY2PR13MB0454.namprd13.prod.outlook.com>,
	<CA+8X3fUgNXLFLTsBRe=EJnhydnrqMKVpHicAd4djmB0xurvZNA@mail.gmail.com>
Message-ID: <BY2PR13MB04542B5898BB1A436DFEBB0CFA300@BY2PR13MB0454.namprd13.prod.outlook.com>

Hi Jim,

Thank you very much for the message. Sorry for the email that was not clear. Yes, you are right, in A$date, should be t2> ENM, t3> ENL. but using the code it gave t2>ENL, t3>ENM. I am struggling to fix it. If the data set was small, I could do it manually.


would you mind to try this example?


Here is the example

A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class = "factor"),
    site = structure(1:3, .Label = c("2C7", "ENL", "ENM"), class = "factor"),
    DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
    ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label = c("t1",
    "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
"DATE", "date"), row.names = c(NA, -3L), class = "data.frame")

A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
tmp <- split(A, A$Tag)
head(tmp)
tail(tmp)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(A$date)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(A$site))
}))

tmp1
=========


________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: October 13, 2015 4:24 AM
To: Kristi Glover
Cc: R-help
Subject: Re: [R] 3D matrix columns messed up _ looking for your help

Hi Kristi,
This is a bit hard to follow, but I'll try. As you are replacing the numeric values of the intermediate table with the character values of the factor A$date, it looks to me as though the answer is as it should be. 2 -> ENL, 3 -> ENM. I suspect that the solution is not difficult, but I can't quite make out what you are trying to accomplish.

Jim


On Tue, Oct 13, 2015 at 11:44 AM, Kristi Glover <kristi.glover at hotmail.com<mailto:kristi.glover at hotmail.com>> wrote:

Hi Jim,

Thank you very much for your suggestions. It seems very easy but it is frustrating as it did not work me. with creating factors and rearranging the columns, still z value (site) did change.

for example

Tag site  DATE
a1 2C7  t1
a1 ENL  t3
a1 ENM t2

ENL is supposed to be assigned for the period t3. ENM should be assigned in t2, but using the code, the table gave wrong information as the z value (site) did not move to the corresponding column. ENL is in t2, ENM is inn t3 coumns, which is wrong.

> tmp1
   t1    t2    t3
a1 "2C7" "ENL" "ENM"

I have included the code if any one help me to solve the problem. This is a just example, I have a very big data set so that  I could not check it manually therefore, I just checked few rows  but it did not work. Your help is highly appreciated.


Here is the example

A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class = "factor"),
    site = structure(1:3, .Label = c("2C7", "ENL", "ENM"), class = "factor"),
    DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
    ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label = c("t1",
    "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
"DATE", "date"), row.names = c(NA, -3L), class = "data.frame")

A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
tmp <- split(A, A$Tag)
head(tmp)
tail(tmp)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(A$date)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(A$site))
}))

tmp1





________________________________
From: Jim Lemon <drjimlemon at gmail.com<mailto:drjimlemon at gmail.com>>
Sent: October 12, 2015 4:22 AM
To: Kristi Glover
Cc: R-help
Subject: Re: [R] 3D matrix columns messed up

Hi Kristi,
The first part is relatively easy:

# change first line to
x$time<-factor(x$time,levels=c("t1","t2","t3","t4","t10","t21"))

As you have specified "site" as the second element in "x", not the third, perhaps you just want:

x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L, 1L),
 .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
 time = structure(c(1L, 3L, 5L, 1L, 5L, 1L, 6L, 2L, 4L),
 .Label = c("t1", "t10", "t2", "t21", "t3", "t4"), class = "factor")),
 site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L),
 .Label = c("A", "B", "D"), class = "factor"),
 .Names = c("vs", "time", "site"), class = "data.frame",
 row.names = c(NA, -9L))

Jim

On Mon, Oct 12, 2015 at 7:41 PM, Kristi Glover <kristi.glover at hotmail.com<mailto:kristi.glover at hotmail.com>> wrote:
Hi R Users,
I was trying to make a matrix with three variables (x,y, z), but y variable (columns) names did not stay in its sequential order, t1,t2,t3,---t21; rather the matrix columns automatically appeared as a t1,t10, t2,t20 etc. Besides these, z value (sites) did not come in the right place (meaning in right columns name). I am wondering how I can make the matrix with the sequential order with right z value (site). I tried it several ways but did not work. One of the examples I used is given here. Would you mind to give me a mints?

x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L,
1L), .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
    site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L), .Label = c("A",
    "B", "D"), class = "factor"), time = structure(c(1L, 3L,
    5L, 1L, 5L, 1L, 6L, 2L, 4L), .Label = c("t1", "t10", "t2",
    "t21", "t3", "t4"), class = "factor")), .Names = c("vs",
"site", "time"), class = "data.frame", row.names = c(NA, -9L))


x$time<-factor(x$time)
tmp <- split(x, x$vs)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(x$time)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(x$site))
}))


tmp1


## I want the z (site) in respective columns.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From c.danyluck at gmail.com  Tue Oct 13 20:05:53 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Tue, 13 Oct 2015 14:05:53 -0400
Subject: [R] Reformatting dataframe for use with icc()
In-Reply-To: <CAFFQM6YYH1vxXCsLenQHxKj2dNSN5PYMrQeU3Dv4B4VJAHvCEg@mail.gmail.com>
References: <CA+_f+RGz6T3i5HA=Dp=_YBwvtT_JD7GDD+a=BPB=bsVk0A_ugw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6CE1FA@mb02.ads.tamu.edu>
	<CAFFQM6YYH1vxXCsLenQHxKj2dNSN5PYMrQeU3Dv4B4VJAHvCEg@mail.gmail.com>
Message-ID: <CA+_f+RGDPC_ujdmoy5khLhMu70JAP7+JzdkRL441kxdibzmxFw@mail.gmail.com>

Indeed, I've worked with the solutions provided by others and the reshape
package has been very fluid to use. Thanks for the suggestion.

Chad

On Sat, Oct 10, 2015 at 4:56 PM, Frans Marcelissen <
fransiepansiekevertje at gmail.com> wrote:

> I think this is what reshape is made for...
> Frans
> --------------------------------------
>
> rater.id <- c(1, 2, 1, 3, 2, 3)
> observation <- c(1, 1, 2, 2, 3, 3)
> rating <- c(6, 7, 4, 6, 2, 4)
> dat=data.frame(rater.id,observation,rating)
>
> library(reshape)
> dat2<-melt(dat, id.vars = c('rater.id','observation'))
> cast(dat2,observation~rater.id)
> observation  1  2  3
>                1  6  7 NA
>                2  4 NA  6
>                3 NA  2  4
>
> 2015-10-10 20:15 GMT+02:00 David L Carlson <dcarlson at tamu.edu>:
>
>> Don't post in html, the list scrambles your tables. Assuming your data
>> looks like this
>>
>> > rater.id <- c(1, 2, 1, 3, 2, 3)
>> > observation <- c(1, 1, 2, 2, 3, 3)
>> > rating <- c(6, 7, 4, 6, 2, 4)
>> > dat <- data.frame(rbind(rater.id, observation, rating))
>> > dat
>>             X1 X2 X3 X4 X5 X6
>> rater.id     1  2  1  3  2  3
>> observation  1  1  2  2  3  3
>> rating       6  7  4  6  2  4
>>
>> We need to transpose the data and then use xtabs(). This will work as
>> long as there is not more than one rating on an observation by the same
>> rater:
>>
>> > t(dat)
>>    rater.id observation rating
>> X1        1           1      6
>> X2        2           1      7
>> X3        1           2      4
>> X4        3           2      6
>> X5        2           3      2
>> X6        3           3      4
>>
>> > tbl <- xtabs(rating~observation+rater.id, t(dat))
>> > tbl
>>            rater.id
>> observation 1 2 3
>>           1 6 7 0
>>           2 4 0 6
>>           3 0 2 4
>>
>> If the 0's are a problem:
>>
>> > tbl[tbl==0] <- NA
>> > print(tbl, na.print=NA)
>>            rater.id
>> observation    1    2    3
>>           1    6    7 <NA>
>>           2    4 <NA>    6
>>           3 <NA>    2    4
>>
>>
>> David L. Carlson
>> Department of Anthropology
>> Texas A&M University
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Chad
>> Danyluck
>> Sent: Friday, October 9, 2015 4:02 PM
>> To: r-help at r-project.org
>> Subject: [R] Reformatting dataframe for use with icc()
>>
>> Hello,
>>
>> I want to determine the inter-rater reliability of ratings made from a
>> random selection of observers and observations. I plan to use the irr
>> package to calculate the ICC, however, my dataframe is not organized in a
>> way that the icc() function can handle. The icc() function works with
>> dataframes in the following format:
>>
>>                      rater1 rater2 rater3...
>> observation
>> 1                           6       7      NA
>> 2                           4    NA          6
>> 3                         NA       2         4
>> ...
>>
>> My dataframe is organized in the following format:
>>
>> rater.id               1  2  1  3  2  3 ...
>> observation       1  1  2  2  3  3 ...
>> rating                 6  7  4  6  2  4 ...
>>
>> I would like to reformat my dataframe as it is organized in the first
>> example but I am not sure how to go about doing this. Any suggestions
>> would
>> be appreciated.
>>
>> Kind regards,
>>
>> Chad
>>
>> --
>> Chad M. Danyluck, MA
>> PhD Candidate, Psychology
>> University of Toronto
>>
>>
>>
>> ?There is nothing either good or bad but thinking makes it so.? - William
>> Shakespeare
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Tue Oct 13 20:16:36 2015
From: jfhenson1 at gmail.com (James Henson)
Date: Tue, 13 Oct 2015 13:16:36 -0500
Subject: [R] contrasts among simple effects
Message-ID: <CABPq8JPO3svc3m4ga_qi_v03MgvJLHmH6n9XMKn=RKYj7QP6_A@mail.gmail.com>

Greetings R Community

My goal is to make orthogonal contrasts among simple effects in analysis of
repeated measures data.  The SAS publication, on page 1224, shows how to
make this type of contrasts in SAS.  But, my search of books about repeated
measures analysis using R, and on-line has not yielded a methodology.
Hopefully, someone can direct me to a book or publication that will show me
a methodology.

Statistical Analysis of Repeated Measures Data Using SAS Procedures

http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf



Attached is a csv data file (file name = heartRate.csv).  My code for the
repeated measures analysis is below.


library("nlme")

# with AR1 variance/covariance structure, with ordered statement

heartRate$time <- factor(heartRate$time)

model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
=corAR1(, form=~1|person), data = heartRate)

summary(model2a)

anova(model2a)


Making a new variable ?simple? that merges the variables drug and time will
enable me to make orthogonal contrasts among the simple effects.  But, when
using the variable ?simple? as the independent variable, the data will no
longer be fitted to the AR1 variance/co-variance structure.

Thanks.

Best regards,

James F.Henson

From c.danyluck at gmail.com  Tue Oct 13 20:44:22 2015
From: c.danyluck at gmail.com (Chad Danyluck)
Date: Tue, 13 Oct 2015 14:44:22 -0400
Subject: [R] NaNs produced running icc()
Message-ID: <CA+_f+RFWyEG9bJ5RFV9i-1JmpZMDub9nEczEF2-jM1-s+8S45Q@mail.gmail.com>

Hello,

I want to determine the inter-rater reliability of ratings made from a
random selection of 11 raters and 71 subjects using the irr package. Each
rater was randomly assigned to rater only a handful of subjects. So there
will be some cells with NAs for raters who did not rate a particular person.

I have formatted my dataset in accordance with the example for calculating
the ICC in the irr package. When I run the icc() function, the output
indicates that I have zero subjects:

Single Score Intraclass Correlation

   Model: twoway
   Type : consistency

   Subjects = 0
     Raters = 11
   ICC(C,1) = NA

 F-Test, H0: r0 = 0 ; H1: r0 > 0
  F(-1,-10) = NA , p = NA

 95%-Confidence Interval for ICC Population Values:
  NA < ICC < NA
Warning messages:
1: In qf(1 - alpha/2, ns - 1, (ns - 1) * (nr - 1)) : NaNs produced
2: In qf(1 - alpha/2, (ns - 1) * (nr - 1), ns - 1) : NaNs produced

I am unsure what I am doing wrong. Below is reproducible code that can be
copied directly into R and should result in the same problem and warning
above. Any help would be appreciated.

Kind regards,

Chad

library(irr)
irr.smile.data <- structure(list(rater.1 = c(NA, NA, NA, NA, NA, NA, NA,
NA, NA,
                                             NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA,
                                             NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA,
                                             NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA,
                                             NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, 4L, 6L, 5L, 4L), rater.2 = c(NA,

                                      NA, NA, NA, NA, NA, NA, NA, NA, NA,
3L, NA, NA, NA, NA, NA, NA,

                                      NA, NA, 6L, 3L, 6L, NA, NA, NA, 2L,
3L, NA, 6L, NA, 6L, NA, 3L,

                                      NA, NA, NA, NA, NA, NA, 2L, NA, 2L,
NA, NA, NA, NA, 6L, 3L, 1L,

                                      2L, NA, 1L, NA, NA, NA, NA, NA, 2L,
2L, NA, 2L, NA, NA, NA, 2L,

                                      NA, NA, NA, NA, NA, NA), rater.3 =
c(NA, NA, NA, NA, NA, NA,


 NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,


 NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,


 NA, NA, NA, NA, NA, NA, NA, 5, NA, NA, NA, NA, 5.5, 5, NA, NA,


 NA, NA, 6, 5, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,


 7), rater.4 = c(7, 6, 6, NA, 7, 4, 4, 2, 5.5, 6.5, 4, 5, NA,


               NA, 6, 5, 6.5, 5, NA, NA, 6, 7, NA, 7, 6, 4, 2, 6, 3, 5, NA,


               2, 3, 6, 5, 6, 6, NA, 6, 5, NA, 2, NA, NA, NA, 6, 5, 6, 2,
NA,


               6, NA, 3, 6, NA, NA, NA, NA, NA, NA, 3, 2, NA, NA, NA, NA,
NA,


               NA, NA, 7, NA), rater.5 = c(NA, NA, NA, NA, NA, NA, 5, NA,
NA,


                                           NA, NA, 5, NA, NA, NA, 4, NA,
NA, NA, NA, NA, NA, 4, NA, NA,


                                           NA, NA, NA, NA, NA, NA, 2, NA,
NA, NA, NA, NA, NA, NA, NA, 4,


                                           2, 4.5, 4, 5, NA, NA, NA, NA,
NA, NA, 3, 4, NA, 5, 6, NA, NA,


                                           NA, NA, NA, NA, 3, NA, 3, 5, 6,
5, NA, NA, NA), rater.6 = c(NA,



                           NA, NA, 4, 6, 5.5, 4, NA, NA, NA, NA, NA, 5, 6,
NA, NA, NA, NA,



                           NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA,



                           NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA,



                           NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA,



                           NA, NA, NA, NA, NA), rater.7 = c(NA, NA, NA, NA,
NA, NA, NA,



                                                            NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,



                                                            NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,



                                                            NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, 5L, NA, NA, NA, NA, NA,



                                                            NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA



                           ), rater.8 = c(NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA,



                                          NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA,



                                          NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA,



                                          NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA, NA, 6L, NA, NA, NA,



                                          NA, NA, NA, NA, NA, NA, NA, NA,
NA, NA, NA), rater.9 = c(5, 6,




                       6, 2, 3, 2, 3, 1, 5, 5, 5, 5, 6, 7, 6, 5, 3, 2, 7,
5, 4, 5, 2,




                       6, 5, 5, 5, 7, 4, 6, 6, 2, 4, 6, 6, 5, 6, 6, 5, 5,
5, 3.5, 6,




                       2, 5, 7, 7, 5, 2, 2, 3, 3, 1, 7, 6, 5, 7, 5, 2, 5,
1.5, 3, 3,




                       5, 5, 5, 3, 6, 7, 5, 5), rater.10 = c(NA, NA, NA,
NA, NA, NA,




                                                             NA, NA, NA,
NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,




                                                             NA, NA, NA,
6L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 7L,




                                                             6L, NA, NA,
NA, NA, NA, NA, NA, NA, NA, 5L, 6L, NA, NA, NA, NA,




                                                             NA, NA, NA,
NA, 6L, 6L, NA, NA, NA, 6L, 5L, NA, NA, NA, NA, NA,




                                                             NA), rater.11
= c(NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,





   NA, NA, NA, NA, NA, NA, NA, 6L, 5L, NA, NA, NA, NA, NA, NA, NA,





   NA, NA, 2L, 5L, 2L, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,





   NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,





   NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)), .Names = c("rater.1",





                                                                "rater.2",
"rater.3", "rater.4", "rater.5", "rater.6", "rater.7",





                                                                "rater.8",
"rater.9", "rater.10", "rater.11"), class = "data.frame", row.names = c(NA,







 -71L))

icc(irr.smile.data, model="twoway")



--
Chad M. Danyluck, MA
PhD Candidate, Psychology
University of Toronto



?There is nothing either good or bad but thinking makes it so.? - William
Shakespeare

	[[alternative HTML version deleted]]


From claytonsamples at gmail.com  Tue Oct 13 20:24:34 2015
From: claytonsamples at gmail.com (Clayton Samples)
Date: Tue, 13 Oct 2015 14:24:34 -0400
Subject: [R] R help
Message-ID: <CA+BV9buDseUJh_OxYadAwPF2MXbeO=wFjMA03EbC9vLZ2+Wc4w@mail.gmail.com>

Hello R community,

I need a bit of direction. I am new to R, so please forgive any mistakes or
confusion.


Here is an example of the columns and data contained in my data frame.
Number: Factor w 345196 levels "1.001", "1.002", "1.003", "2.001", "2.002",
"2.003"
Name: factor w 2 levels ("X", "Y")
Variable: factor w 21 levels "unknown", "known"
Amount: num(1, 2, 3, 4, 5, 6)

My objective is to filter based on numbers ending in .002 within column
Number

I have used the melt function to organize the data and then tried

filter(df, PO.Number %in% c(.002))

However, this didn't work.

Thanks for the help.

	[[alternative HTML version deleted]]


From neverstop at hotmail.it  Tue Oct 13 16:13:44 2015
From: neverstop at hotmail.it (Neverstop)
Date: Tue, 13 Oct 2015 07:13:44 -0700 (PDT)
Subject: [R] k-nearest neighbour classification
In-Reply-To: <CAN5YmCFEM0nqZS+KbHd9Qx0pUNzAWEa2RnHUibxJujqoON=W9Q@mail.gmail.com>
References: <1444726784734-4713523.post@n4.nabble.com>
	<CAN5YmCFEM0nqZS+KbHd9Qx0pUNzAWEa2RnHUibxJujqoON=W9Q@mail.gmail.com>
Message-ID: <1444745624733-4713531.post@n4.nabble.com>

I know that knn.cv(train=predictors.training, cl=classes.training, k=3,
prob=TRUE) works but by doing so I fix the tuning paramer k to be 3. Isn't
cross validation a technique to choose the optimal tuning parameter trying a
range of different values for the tuning parameter? 



--
View this message in context: http://r.789695.n4.nabble.com/k-nearest-neighbour-classification-tp4713523p4713531.html
Sent from the R help mailing list archive at Nabble.com.


From ramendra.sarma at gmail.com  Tue Oct 13 18:28:56 2015
From: ramendra.sarma at gmail.com (Ramendra Sarma)
Date: Tue, 13 Oct 2015 21:58:56 +0530
Subject: [R] heritability parameter
Message-ID: <CAP3xa20esQjFX0_HxJGmo4cYWxHSVs8ibVp34zgadLF-xQTnZw@mail.gmail.com>

Is there in any library in R to calculate gcv, pcv and heritability
parameters in R?

-- 
----------------------------------------------------------------------------------------------------------------------------------------






*Dr R N SarmaProfessorDepartment of Plant Breeding and GeneticsAssam
Agricultural UniversityJorhat-785013Assam, Indiaweb: www.aau.ac.in;
<http://www.aaau.ac.in> Phone: +91-376-2310526; +91-376231133(R);
9435350529(M)*
--------------------------------------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From simon.wood at bath.edu  Tue Oct 13 15:17:10 2015
From: simon.wood at bath.edu (Simon Wood)
Date: Tue, 13 Oct 2015 14:17:10 +0100
Subject: [R] Problem with binomial gam{mgcv}
In-Reply-To: <1bcef75cb8964dbd974f1da09a124d05@exch07.campus.bath.ac.uk>
References: <CAMsrtkjc48tz4bcQ3e7tpKufWp1Kc4Gq9tY+-9GpU2LRC5AWRQ@mail.gmail.com>
	<1bcef75cb8964dbd974f1da09a124d05@exch07.campus.bath.ac.uk>
Message-ID: <561D0456.1040508@bath.edu>

Following up on Duncan's answer...

You can see that the model doesn't fit with a little bit of residual 
checking. For example

gam.check(Model)

shows that the binomial assumption is just wrong here: there is massive 
overdispersion, for example. Even the crudest response to this, of using 
quasibinomial, then gives a non-significant  s(x1) in the examples I've 
tried.

best,
Simon




On 10/10/15 12:40, Duncan Murdoch wrote:
> On 09/10/2015 8:00 PM, Erin Conlisk wrote:
>> Hello,
>>
>> I am having trouble testing for the significance using a binomial model in
>> gam{mgcv}.  Have I stumbled on a bug?  I doubt I would be so lucky, so
>> could someone tell me what I am doing wrong?
>>
>> Please see the following code:
>> ________________________________
>>
>> # PROBLEM USING cbind
>>
>> x1 <- runif(500, 0, 100)  # Create 500 random variables to use as my
>> explanatory variable
>>
>> y1 <- floor(runif(500, 0, 100)) # Create 500 random counts to serve as
>> binomial "successes"
>>
>> y2 <- 100-y1 # Create 500 binomial "failures", assuming a total of 100
>> trials and the successes recorded in y1
>>
>> Model <- gam(cbind(y1, y2) ? 1 + s(x1), family=binomial)
>> summary(Model)
>> ________________________________
>>
>> The result is that my random variable, x1, is highly significant.  This
>> can't be right...
> The problem is that statistical significance of a test doesn't mean that
> the alternative you have in mind is right, it just means that the null
> is wrong (or you were unlucky, but let's ignore that).
>
> The null hypothesis here is that all of the y1 values are independent
> binomial values with a common n=100 and common unspecifed probability of
> success.
>
> Since in fact y1 comes from a discrete uniform distribution, that's
> false, and the p-value is not anywhere near being a random Unif(0,1) value.
>
> If you wanted the null hypothesis to be true, you'd need to choose a
> success probability p somehow, then set y1 <- rbinom(500, size=100, prob
> = p).  The random uniform has a far larger variance, and that leads to a
> larger deviance in gam, hence significance.
>
> Duncan Murdoch
>
>> So what happens when I change the observations from a "batch" of 100 trials
>> to individual successes and failures?
>> ________________________________
>>
>> # NOW MAKE ALL THESE DATA 0 and 1
>>
>> r01<-rep(0,500)
>> data01<-cbind(x1, y1, y2, r01)
>> rownames(data01)<-seq(1,500, 1)
>> colnames(data01)<-c('x1', 'y1', 'y2', 'r01')
>> data01<-data.frame(data01)
>>
>> expanded0 <- data01[rep(row.names(data01), data01$y1), 1:4]  # Creates a
>> replicate of the      #  explanatory variables for each individual "success"
>>
>> r01<-rep(1,500)
>> data01<-cbind(x1, y1, y2, r01)
>> rownames(data01)<-seq(1,500, 1)
>> colnames(data01)<-c('x1', 'y1', 'y2', 'r01')
>> data01<-data.frame(data01)
>>
>> expanded1 <- data01[rep(row.names(data01), data01$y2), 1:4]  # Creates a
>> replicate of the      #  explanatory variables for each individual "failure"
>>
>> data01<-rbind(expanded0,expanded1)
>>
>> Model2 <- gam(r01 ? 1 + s(x1), family=binomial)
>> summary(Model2)
>> ___________________________________
>>
>> The result is what I expect.  Now my random variable, x1, is NOT
>> significant.
>>
>> What is going on here?
>>
>> I should say that I didn't just make this up.  My question arose playing
>> with my real data, where I was getting high significance, but a terrible
>> proportion of deviance explained.
>>
>> My apologies if this is explained elsewhere, but I have spent hours
>> searching for an answer online.
>>
>> Thank you kindly,
>> Erin Conlisk
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From treetexan2 at gmail.com  Tue Oct 13 17:39:12 2015
From: treetexan2 at gmail.com (Matt Fagan)
Date: Tue, 13 Oct 2015 11:39:12 -0400
Subject: [R] class-specific Gini metrics for Random Forest?
Message-ID: <CANyx+2_n4h-Kn4xhcxqVHGHpd0ipydO+=iZfU=fVAZf-YaNgJQ@mail.gmail.com>

library(randomForest)
data(iris)
fit <- randomForest(Species ~ ., data=iris, importance=TRUE);
fit.imp<-importance(fit)
fit.imp

columns 1-3 of fit.imp show the class-specific variable importance for the
Mean Decrease Acuracy measure (MDA). Is there a way to calculate
class-specific Gini metrics rather than the default class-specific MDA?
Simply setting "importance(fit, type=2)" doesn't do it.

I really want to do calculate these metrics. I was about to start trying to
code a way to do it, but thought I would ask here first.  Many thanks for
any help or pointers--I hope I missed something simple.

	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Tue Oct 13 21:09:48 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Tue, 13 Oct 2015 21:09:48 +0200
Subject: [R] Parsing XML File
In-Reply-To: <CAAxdm-7iGOYTGG0TSUZNn+JyjaJfQ_rB3AoqpxG3RTBV_yGbbw@mail.gmail.com>
References: <20151011191014.GA8883@localhost.localdomain>
	<CAAxdm-7iGOYTGG0TSUZNn+JyjaJfQ_rB3AoqpxG3RTBV_yGbbw@mail.gmail.com>
Message-ID: <20151013190948.GA1735@localhost.localdomain>

Dear Jim,
Thanks for your reply.
What you did is 100% what I need -- I now have a data frame with the
relevant data and I can take up from there.
Regards

Lorenzo

On Sun, Oct 11, 2015 at 03:54:10PM -0400, jim holtman wrote:
>Not sure exactly what you want since you did not show an expected output,
>but this will extract the attributes from AccVal in the structure:
>
>> #####################################################################
>>  library(XML)
>>
>>  xmlfile=xmlParse("/temp/account.xml")
>>
>>  class(xmlfile) #"XMLInternalDocument" "XMLAbstractDocument"
>[1] "XMLInternalDocument" "XMLAbstractDocument"
>>  xmltop = xmlRoot(xmlfile) #gives content of root
>>
>>  #####  try this  ##############
>>
>>  accts <- sapply(getNodeSet(xmltop, "//AccVal"), xmlAttrs)
>>
>>  # create data.frame
>>  accts_df <- as.data.frame(t(accts), stringsAsFactors = FALSE)
>>  str(accts_df)
>'data.frame':   364 obs. of  4 variables:
> $ key        : chr  "AccountCode" "AccountReady" "AccountType"
>"AccruedCash" ...
> $ val        : chr  "DU108063" "true" "CORPORATION" "0" ...
> $ currency   : chr  "" "" "" "AUD" ...
> $ accountName: chr  "DU108063" "DU108063" "DU108063" "DU108063" ...
>>  head(accts_df)
>           key         val currency accountName
>1  AccountCode    DU108063             DU108063
>2 AccountReady        true             DU108063
>3  AccountType CORPORATION             DU108063
>4  AccruedCash           0      AUD    DU108063
>5  AccruedCash           0     BASE    DU108063
>6  AccruedCash           0      CAD    DU108063
>>
>
>
>Jim Holtman
>Data Munger Guru
>
>What is the problem that you are trying to solve?
>Tell me what you want to do, not how you want to do it.
>
>On Sun, Oct 11, 2015 at 3:10 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
>wrote:
>
>> Dear All,
>> I am struggling with the parsing of the xml file you can find at
>>
>> https://www.dropbox.com/s/i4ld5qa26hwrhj7/account.xml?dl=0
>>
>> Essentially, I would like to be able to convert it to a data.frame to
>> manipulate it in R and detect all the attributes of an account for
>> which  unrealizedPNL goes above a threshold.
>> I stored that file as account.xml and looking here and there on the
>> web I put together the following script
>>
>>
>> #####################################################################
>> library(XML)
>>
>> xmlfile=xmlParse("account.xml")
>>
>> class(xmlfile) #"XMLInternalDocument" "XMLAbstractDocument"
>> xmltop = xmlRoot(xmlfile) #gives content of root
>> class(xmltop)#"XMLInternalElementNode" "XMLInternalNode"
>> "XMLAbstractNode"
>> xmlName(xmltop) #give name of node, PubmedArticleSet
>> xmlSize(xmltop) #how many children in node, 19
>> xmlName(xmltop[[1]]) #name of root's children
>>
>> # have a look at the content of the first child entry
>> xmltop[[1]]
>> # have a look at the content of the 2nd child entry
>> xmltop[[2]]
>> #Root Node's children
>> number <- xmlSize(xmltop[[1]]) #number of nodes in each child
>> name <- xmlSApply(xmltop[[1]], xmlName) #name(s)
>> attribute <- xmlSApply(xmltop[[1]], xmlAttrs) #attribute(s)
>> size <- xmlSApply(xmltop[[1]], xmlSize) #size
>>
>>
>> values <- xmlSApply(xmltop, function(x) xmlSApply(x, xmlValue))
>> #####################################################################
>>
>> which is leading me nowhere.
>> Any suggestion is appreciated.
>> Cheers
>>
>> Lorenzo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From dwinsemius at comcast.net  Tue Oct 13 21:26:11 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Oct 2015 12:26:11 -0700
Subject: [R] contrasts among simple effects
In-Reply-To: <CABPq8JPO3svc3m4ga_qi_v03MgvJLHmH6n9XMKn=RKYj7QP6_A@mail.gmail.com>
References: <CABPq8JPO3svc3m4ga_qi_v03MgvJLHmH6n9XMKn=RKYj7QP6_A@mail.gmail.com>
Message-ID: <F8E64940-67E4-45DF-A300-069E8166293A@comcast.net>


On Oct 13, 2015, at 11:16 AM, James Henson wrote:

> Greetings R Community
> 
> My goal is to make orthogonal contrasts among simple effects in analysis of
> repeated measures data.  The SAS publication, on page 1224, shows how to
> make this type of contrasts in SAS.  But, my search of books about repeated
> measures analysis using R, and on-line has not yielded a methodology.
> Hopefully, someone can direct me to a book or publication that will show me
> a methodology.
> 
> Statistical Analysis of Repeated Measures Data Using SAS Procedures
> 
> http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf
> 
> 
> 
> Attached is a csv data file (file name = heartRate.csv).


The .csv file type is not accepted by the mail server, ever. You would probably get it to be passed through to the list audience if you changed its name to:  heartRate.txt


>  My code for the
> repeated measures analysis is below.
> 
> 
> library("nlme")
> 
> # with AR1 variance/covariance structure, with ordered statement
> 
> heartRate$time <- factor(heartRate$time)
> 
> model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
> =corAR1(, form=~1|person), data = heartRate)
> 

I would have expected `time` to be in that formula. I do think that the correct mailing list would have been r-sig-mixed-models at r-project.org


> summary(model2a)
> 
> anova(model2a)
> 
> 
> Making a new variable ?simple? that merges the variables drug and time will
> enable me to make orthogonal contrasts among the simple effects.  But, when
> using the variable ?simple? as the independent variable, the data will no
> longer be fitted to the AR1 variance/co-variance structure.
> 
> Thanks.
> 
> Best regards,
> 
> James F.Henson
> ______________________________________________

David Winsemius
Alameda, CA, USA


From sarah.goslee at gmail.com  Tue Oct 13 21:42:26 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 13 Oct 2015 15:42:26 -0400
Subject: [R] R help
In-Reply-To: <CA+BV9buDseUJh_OxYadAwPF2MXbeO=wFjMA03EbC9vLZ2+Wc4w@mail.gmail.com>
References: <CA+BV9buDseUJh_OxYadAwPF2MXbeO=wFjMA03EbC9vLZ2+Wc4w@mail.gmail.com>
Message-ID: <CAM_vju=MiDf45AcTwWPu4bcP1FgH3J4esmGzrfkABXs6Po4LQQ@mail.gmail.com>

Hi,

First of all, you almost certainly want to get your data into R with
stringsAsFactors=FALSE rather than creating a factor with 345196
levels.

mydata <- read.table("whateverfile", stringsAsFactors=FALSE)

I'm just guessing, but you probably also don't really want filter(),
but subset() instead.

# fake data - you can use dput(head(mydata)) to provide some real data
mydata <- data.frame(Number=c("1.001", "1.002", "1.003", "2.001", "2.002",
"2.003"), Name=c("x", "y"), Amount=1:6, stringsAsFactors=FALSE)

subset(mydata, grepl("\\.002$", mydata$Number))


  Number Name Amount
2  1.002    y      2
5  2.002    x      5

If that's what you're after, you should probably take a look at
?filter to see what you were doing, and ?subset and ?grepl to see one
way to approach the question.

Sarah


On Tue, Oct 13, 2015 at 2:24 PM, Clayton Samples
<claytonsamples at gmail.com> wrote:
> Hello R community,
>
> I need a bit of direction. I am new to R, so please forgive any mistakes or
> confusion.
>
>
> Here is an example of the columns and data contained in my data frame.
> Number: Factor w 345196 levels "1.001", "1.002", "1.003", "2.001", "2.002",
> "2.003"
> Name: factor w 2 levels ("X", "Y")
> Variable: factor w 21 levels "unknown", "known"
> Amount: num(1, 2, 3, 4, 5, 6)
>
> My objective is to filter based on numbers ending in .002 within column
> Number
>
> I have used the melt function to organize the data and then tried
>
> filter(df, PO.Number %in% c(.002))
>
> However, this didn't work.
>
> Thanks for the help.
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From tr206 at kent.ac.uk  Tue Oct 13 21:55:39 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 13 Oct 2015 19:55:39 +0000
Subject: [R] quantile regression: warning message
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A1201005487AE@EX10-LIVE-MBN1.ad.kent.ac.uk>

Greetings R Community,
I am trying to run a quantile regression using the quantreg package. My code looks as follows:
RegressionUtilitiesUK<-rq(ReturnUtilities~yield.spread.change+ReturnFTSE, tau=0.01,data=State_variables_UK_calm)

Unfortunately, the summary() function returns the results but also following warning message:
Warning message:
In rq.fit.br(x, y, tau = tau, ...) : Solution may be nonunique

My question now is if I should worry about the results. Are my results correct and how can I avoid this message? I do not understand the message.

Thanks a lot for your feedback.

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Tue Oct 13 21:59:08 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Tue, 13 Oct 2015 14:59:08 -0500
Subject: [R] quantile regression: warning message
In-Reply-To: <332cf649e7a44806878db6508018be96@CITESHT4.ad.uillinois.edu>
References: <332cf649e7a44806878db6508018be96@CITESHT4.ad.uillinois.edu>
Message-ID: <CD921BD8-1891-48CF-AB3D-DFD5439061ED@illinois.edu>

see the output from the quantreg FAQ:

	FAQ()

especially point 2.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Oct 13, 2015, at 2:55 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Greetings R Community,
> I am trying to run a quantile regression using the quantreg package. My code looks as follows:
> RegressionUtilitiesUK<-rq(ReturnUtilities~yield.spread.change+ReturnFTSE, tau=0.01,data=State_variables_UK_calm)
> 
> Unfortunately, the summary() function returns the results but also following warning message:
> Warning message:
> In rq.fit.br(x, y, tau = tau, ...) : Solution may be nonunique
> 
> My question now is if I should worry about the results. Are my results correct and how can I avoid this message? I do not understand the message.
> 
> Thanks a lot for your feedback.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Tue Oct 13 22:24:47 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 13 Oct 2015 13:24:47 -0700
Subject: [R] R help
In-Reply-To: <CA+BV9buDseUJh_OxYadAwPF2MXbeO=wFjMA03EbC9vLZ2+Wc4w@mail.gmail.com>
References: <CA+BV9buDseUJh_OxYadAwPF2MXbeO=wFjMA03EbC9vLZ2+Wc4w@mail.gmail.com>
Message-ID: <C7033AC7-B1BC-4800-A0E3-C7A0B9827D79@dcn.davis.CA.us>

In general you should read the Posting Guide mentioned at the bottom of every email, which points out that you should post in plain text. Figuring out how to send plain text email in your email client will help you make sure that we see what you see. 

You should also try to insert reproducible code in your email rather than isolated snippets. Read the discussion at [1] to learn more.

filter(df, grepl( "\\.002", as.character( Number ) ) )

If you import the data with the stringsAsFactors=TRUE option you could get rid of the as.character conversion.  You should also look at the help for %in% because it compares the whole string, not sub strings.

?"%in%"

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 13, 2015 11:24:34 AM PDT, Clayton Samples <claytonsamples at gmail.com> wrote:
>Hello R community,
>
>I need a bit of direction. I am new to R, so please forgive any
>mistakes or
>confusion.
>
>
>Here is an example of the columns and data contained in my data frame.
>Number: Factor w 345196 levels "1.001", "1.002", "1.003", "2.001",
>"2.002",
>"2.003"
>Name: factor w 2 levels ("X", "Y")
>Variable: factor w 21 levels "unknown", "known"
>Amount: num(1, 2, 3, 4, 5, 6)
>
>My objective is to filter based on numbers ending in .002 within column
>Number
>
>I have used the melt function to organize the data and then tried
>
>filter(df, PO.Number %in% c(.002))
>
>However, this didn't work.
>
>Thanks for the help.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tr206 at kent.ac.uk  Tue Oct 13 22:38:12 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Tue, 13 Oct 2015 20:38:12 +0000
Subject: [R] quantile regression: warning message
In-Reply-To: <CD921BD8-1891-48CF-AB3D-DFD5439061ED@illinois.edu>
References: <332cf649e7a44806878db6508018be96@CITESHT4.ad.uillinois.edu>
	<CD921BD8-1891-48CF-AB3D-DFD5439061ED@illinois.edu>
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A1201005497DA@EX10-LIVE-MBN1.ad.kent.ac.uk>

Thank you very much.
So, the results are correct and the differences between the solutions are pretty small. Thus, I do not need to worry about the warning message? Yes?



-----Original Message-----
From: Roger Koenker [mailto:rkoenker at illinois.edu] 
Sent: 13 October 2015 21:59
To: T.Riedle
Cc: R-help at r-project.org
Subject: Re: [R] quantile regression: warning message

see the output from the quantreg FAQ:

	FAQ()

especially point 2.


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Oct 13, 2015, at 2:55 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Greetings R Community,
> I am trying to run a quantile regression using the quantreg package. My code looks as follows:
> RegressionUtilitiesUK<-rq(ReturnUtilities~yield.spread.change+ReturnFT
> SE, tau=0.01,data=State_variables_UK_calm)
> 
> Unfortunately, the summary() function returns the results but also following warning message:
> Warning message:
> In rq.fit.br(x, y, tau = tau, ...) : Solution may be nonunique
> 
> My question now is if I should worry about the results. Are my results correct and how can I avoid this message? I do not understand the message.
> 
> Thanks a lot for your feedback.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jmhannon.ucdavis at gmail.com  Tue Oct 13 23:16:20 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Tue, 13 Oct 2015 14:16:20 -0700
Subject: [R] how to do away for loop using functionals?
In-Reply-To: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
References: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
	<746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACdH2ZZioivXxZCVrp1dNrqc4vpF22LCW_5yhcKqrpmSHJ5r0A@mail.gmail.com>

The answer to "another note" is:

mapply(rep, w, 5:1)

I'll try to look at the first part in more detail later today.

-- Mike


On Mon, Oct 12, 2015 at 5:55 PM, Annie Hawk via R-help
<r-help at r-project.org> wrote:
> HI R-experts,
>
>
> I am trying to speed up my calculation of the A results below and replace the for loop withsome functionals like lapply.  After manyreadings, trial and error, I still have no success.  Would anyone please give me some hints onthat?
>
> Thank you in advance.
>
> Anne
>
>
> The program is this, I have a complicated function and itneeds to operate on some subsets of a dataset many times, depending on thevalues of group.  I simplify the functionand dataset for this example run.
>
> getResult <- function(d) {
>
>       #examplefunction
>
>      weighted.mean(x=d[,1], w=d[,2])
>
> }
>
>
>
> #example data setup
>
> n=20;
>
> set.seed(1)
>
> g=rep(1:5,each=4)
>
> df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1, 0.4) , g )); df
>
> getResult(df)
>
> i0=c(1,2,4,5,5)
>
> ng= length(unique(g))
>
>
>
> #initiation of result matrix
>
> A=matrix(Inf, ng, ng); A
>
> for(i in 1:ng)
>
> {              cat("i:",i,"")
>
>                 for(jin i0[i]:ng) {
>
>                                 ok= !is.na(match(g,i:j)); cat("j:",j,"\n");
>
>                                 A[i,j]=getResult(d=df[ok,])
>
>                 } #endfor (j)
>
> } #end for (i)
>
> Is there an elegant way to remove the for loop here?  I try to make it flat for faster run but Icannot figure out how to subset the observations faster without error to apply the functiongetResult.  Any hint is appreciated.
>
>
>
>
>
> on another note, is there a more elegant way to initiate the list as follows?
>
> mylist=list(); w=rep(4,5)
>
> for (i in 1:5) mylist[[i]]=w[i:5]
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Tue Oct 13 23:26:31 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 13 Oct 2015 16:26:31 -0500
Subject: [R] k-nearest neighbour classification
In-Reply-To: <1444745624733-4713531.post@n4.nabble.com>
References: <1444726784734-4713523.post@n4.nabble.com>
	<CAN5YmCFEM0nqZS+KbHd9Qx0pUNzAWEa2RnHUibxJujqoON=W9Q@mail.gmail.com>
	<1444745624733-4713531.post@n4.nabble.com>
Message-ID: <CAN5YmCHxD_awAwME9hMmNhaJgy+KPZPPbiSnq44uq=u9WgtD2A@mail.gmail.com>

Ah, I see what you're after.  I don't know of a built in function to search
for the best number of nearest neighbors.  You may have to run the code for
each k separately, then compare the resulting errors.

Jean

On Tue, Oct 13, 2015 at 9:13 AM, Neverstop <neverstop at hotmail.it> wrote:

> I know that knn.cv(train=predictors.training, cl=classes.training, k=3,
> prob=TRUE) works but by doing so I fix the tuning paramer k to be 3. Isn't
> cross validation a technique to choose the optimal tuning parameter trying
> a
> range of different values for the tuning parameter?
>
>
>
> --
> View this message in context:
> http://r.789695.n4.nabble.com/k-nearest-neighbour-classification-tp4713523p4713531.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jfhenson1 at gmail.com  Tue Oct 13 23:58:00 2015
From: jfhenson1 at gmail.com (James Henson)
Date: Tue, 13 Oct 2015 16:58:00 -0500
Subject: [R] contrasts among simple effects - 2
Message-ID: <CABPq8JOaOgV747Wo==j5UTQ-PpYX_+3h=GOQA1zStgHzbWO82A@mail.gmail.com>

Greetings R Community

Apologize for previously sending a csv file.

My goal is to make orthogonal contrasts among simple effects in analysis of
repeated measures data.  The SAS publication, on page 1224, shows how to
make this type of contrasts in SAS.  But, my search of books about repeated
measures analysis using R, and on-line has not yielded a methodology.
Hopefully, someone can direct me to a book or publication that will show me
a methodology.

Statistical Analysis of Repeated Measures Data Using SAS Procedures

http://cslras.pbworks.com/f/littell_j_anim_sci_76_4_analysis_of_repeated_measures_using_sas.pdf



Attached is a txt data file (file name = heart_rate.txt).  My code for the
repeated measures analysis is below.

library("nlme")

# with AR1 variance/covariance structure, with ordered statement

heartRate$time <- factor(heartRate$time)

model2a <- lme(HR ~ drug*ordered(time), random =~1|person, correlation
=corAR1(, form=~1|person), data = heartRate)

summary(model2a)

anova(model2a)


Making a new variable ?simple? that merges the variables drug and time will
enable me to make orthogonal contrasts among the simple effects.  But, when
using the variable ?simple? as the independent variable, the data will no
longer be fitted to the AR1 variance/covariance structure.

Thanks.

Best regards,

James F.Henson
-------------- next part --------------
drug	person	time	HR
a	1	1	72
a	4	1	78
a	7	1	71
a	10	1	72
a	13	1	66
a	16	1	74
a	19	1	62
a	22	1	69
b	2	1	85
b	5	1	82
b	8	1	71
b	11	1	83
b	14	1	86
b	17	1	85
b	20	1	79
b	23	1	83
c	3	1	69
c	6	1	66
c	9	1	84
c	12	1	80
c	15	1	72
c	18	1	65
c	21	1	75
c	24	1	71
a	1	2	86
a	4	2	83
a	7	2	82
a	10	2	83
a	13	2	79
a	16	2	83
a	19	2	73
a	22	2	75
b	2	2	86
b	5	2	86
b	8	2	78
b	11	2	88
b	14	2	85
b	17	2	82
b	20	2	83
b	23	2	84
c	3	2	73
c	6	2	62
c	9	2	90
c	12	2	81
c	15	2	72
c	18	2	62
c	21	2	69
c	24	2	70
a	1	3	81
a	4	3	88
a	7	3	81
a	10	3	83
a	13	3	77
a	16	3	84
a	19	3	78
a	22	3	76
b	2	3	83
b	5	3	80
b	8	3	70
b	11	3	79
b	14	3	76
b	17	3	83
b	20	3	80
b	23	3	78
c	3	3	72
c	6	3	67
c	9	3	88
c	12	3	77
c	15	3	69
c	18	3	65
c	21	3	69
c	24	3	65
a	1	4	77
a	4	4	81
a	7	4	75
a	10	4	69
a	13	4	66
a	16	4	77
a	19	4	70
a	22	4	70
b	2	4	80
b	5	4	84
b	8	4	75
b	11	4	81
b	14	4	76
b	17	4	80
b	20	4	81
b	23	4	81
c	3	4	74
c	6	4	73
c	9	4	87
c	12	4	72
c	15	4	70
c	18	4	61
c	21	4	68
c	24	4	63

From aditya.bhatia52 at gmail.com  Tue Oct 13 23:42:25 2015
From: aditya.bhatia52 at gmail.com (Aditya Bhatia)
Date: Wed, 14 Oct 2015 03:12:25 +0530
Subject: [R] Fitting a curve to weibull distribution in R using nls
Message-ID: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>

I am trying to fit this data to a weibull distribution:

My y variable is:1  1  1  4  7 20  7 14 19 15 18  3  4  1  3  1  1  1
1  1  1  1  1  1

and x variable is:1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
19 20 21 22 23 24

The plot looks like this:http://i.stack.imgur.com/FrIKo.png and I want
to fit a weibull curve to it. I am using the nls function in R like
this: nls(y ~ ((a/b) * ((x/b)^(a-1)) * exp(- (x/b)^a)))

This function always throws up an error saying: Error in
numericDeriv(form[[3L]], names(ind), env) :
 Missing value or an infinity produced when evaluating the model
In addition: Warning message:
In nls(y ~ ((a/b) * ((x/b)^(a - 1)) * exp(-(x/b)^a))) :
  No starting values specified for some parameters.
Initializing ?a?, ?b? to '1.'.
Consider specifying 'start' or using a selfStart model

So first I tried different starting values without any success. I
cannot understand how to make a "good" guess at the starting values.
Then I went with the SSweibull(x, Asym, Drop, lrc, pwr) function which
is a selfStart function. Now the SSWeibull function expects values for
Asym,Drop,lrc and pwr and I don't have any clue as to what those
values might be.

I would appreciate if someone could help me figure out how to proceed.

Background of the data: I have taken some data from bugzilla and my
"y" variable is number of bugs reported in a particular month and "x"
variable is the month number after release.


From Peter.Alspach at plantandfood.co.nz  Wed Oct 14 05:21:17 2015
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 14 Oct 2015 16:21:17 +1300
Subject: [R] heritability parameter
In-Reply-To: <CAP3xa20esQjFX0_HxJGmo4cYWxHSVs8ibVp34zgadLF-xQTnZw@mail.gmail.com>
References: <CAP3xa20esQjFX0_HxJGmo4cYWxHSVs8ibVp34zgadLF-xQTnZw@mail.gmail.com>
Message-ID: <E41B375B7520DE4A8C60781AC60B75450676B54C52@AKLEXM01.PFR.CO.NZ>

Tena koe Ramendra

There are various packages (not libraries) to fit mixed models, and hence the individual animal (or plant) model - perhaps the best known being lme4.  There's also MCMCglmm which takes a Baseyian approach, and asreml which is licence managed.  This is nothing like an exclusive list (e.g., nadiv and hglm), but it's a start.

I don't find your question clear, and thus apologise if the above does not address your request.

Peter Alspach

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ramendra Sarma
Sent: Wednesday, 14 October 2015 5:29 a.m.
To: r-help at r-project.org
Subject: [R] heritability parameter

Is there in any library in R to calculate gcv, pcv and heritability parameters in R?

--
----------------------------------------------------------------------------------------------------------------------------------------






*Dr R N SarmaProfessorDepartment of Plant Breeding and GeneticsAssam
Agricultural UniversityJorhat-785013Assam, Indiaweb: www.aau.ac.in;
<http://www.aaau.ac.in> Phone: +91-376-2310526; +91-376231133(R);
9435350529(M)*
--------------------------------------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From dorotabuczek81 at gmail.com  Wed Oct 14 05:04:58 2015
From: dorotabuczek81 at gmail.com (Dorota Buczek)
Date: Wed, 14 Oct 2015 13:04:58 +1000
Subject: [R] unsuscribe
Message-ID: <10EC8D46-9E56-44E4-B686-D58797F54053@gmail.com>

Please unsuscribe me from the mailing list.

Thank you 
Dorota


From dwinsemius at comcast.net  Wed Oct 14 06:14:10 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Oct 2015 21:14:10 -0700
Subject: [R] Fitting a curve to weibull distribution in R using nls
In-Reply-To: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>
References: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>
Message-ID: <B8B19879-2978-4633-9C6C-BA5AC2F08FB1@comcast.net>


On Oct 13, 2015, at 2:42 PM, Aditya Bhatia wrote:

> I am trying to fit this data to a weibull distribution:
> 
> My y variable is:1  1  1  4  7 20  7 14 19 15 18  3  4  1  3  1  1  1
> 1  1  1  1  1  1
> 
> and x variable is:1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> 19 20 21 22 23 24
> 
> The plot looks like this:http://i.stack.imgur.com/FrIKo.png and I want
> to fit a weibull curve to it. I am using the nls function in R like
> this: nls(y ~ ((a/b) * ((x/b)^(a-1)) * exp(- (x/b)^a)))

So despite the fact that the Weibull function has a continuous domain, you want to fit a set of integers to something like the Weibull with these values as case weights with the "x-values" being the position of these integers in a sequence?


-- 
David.
> 
> This function always throws up an error saying: Error in
> numericDeriv(form[[3L]], names(ind), env) :
> Missing value or an infinity produced when evaluating the model
> In addition: Warning message:
> In nls(y ~ ((a/b) * ((x/b)^(a - 1)) * exp(-(x/b)^a))) :
>  No starting values specified for some parameters.
> Initializing ?a?, ?b? to '1.'.
> Consider specifying 'start' or using a selfStart model
> 
> So first I tried different starting values without any success. I
> cannot understand how to make a "good" guess at the starting values.
> Then I went with the SSweibull(x, Asym, Drop, lrc, pwr) function which
> is a selfStart function. Now the SSWeibull function expects values for
> Asym,Drop,lrc and pwr and I don't have any clue as to what those
> values might be.
> 
> I would appreciate if someone could help me figure out how to proceed.
> 
> Background of the data: I have taken some data from bugzilla and my
> "y" variable is number of bugs reported in a particular month and "x"
> variable is the month number after release.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Wed Oct 14 06:15:38 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 13 Oct 2015 21:15:38 -0700
Subject: [R] unsuscribe
In-Reply-To: <10EC8D46-9E56-44E4-B686-D58797F54053@gmail.com>
References: <10EC8D46-9E56-44E4-B686-D58797F54053@gmail.com>
Message-ID: <0EE30D1E-4F00-4890-A750-F8B1F0A272DD@dcn.davis.CA.us>

We cannot do that. Please read the footer of any email on the list, such as quoted here.

>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 13, 2015 8:04:58 PM PDT, Dorota Buczek <dorotabuczek81 at gmail.com> wrote:
>Please unsuscribe me from the mailing list.
>
>Thank you 
>Dorota
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From aditya.bhatia52 at gmail.com  Wed Oct 14 06:28:10 2015
From: aditya.bhatia52 at gmail.com (Aditya Bhatia)
Date: Wed, 14 Oct 2015 04:28:10 +0000
Subject: [R] Fitting a curve to weibull distribution in R using nls
In-Reply-To: <B8B19879-2978-4633-9C6C-BA5AC2F08FB1@comcast.net>
References: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>
	<B8B19879-2978-4633-9C6C-BA5AC2F08FB1@comcast.net>
Message-ID: <CAOuxJ+7Mg6VqTtOZuee4fVH2q7BzCq3DsO8zoStEF5vi2-DCtw@mail.gmail.com>

Yes. I do.I'm trying to repeat the methodology of a paper. They have fitted
their data to a weibull curve and so I want to do the same too, but I'm
unable to figure out how..

On Wed, Oct 14, 2015, 9:44 AM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Oct 13, 2015, at 2:42 PM, Aditya Bhatia wrote:
>
> > I am trying to fit this data to a weibull distribution:
> >
> > My y variable is:1  1  1  4  7 20  7 14 19 15 18  3  4  1  3  1  1  1
> > 1  1  1  1  1  1
> >
> > and x variable is:1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> > 19 20 21 22 23 24
> >
> > The plot looks like this:http://i.stack.imgur.com/FrIKo.png and I want
> > to fit a weibull curve to it. I am using the nls function in R like
> > this: nls(y ~ ((a/b) * ((x/b)^(a-1)) * exp(- (x/b)^a)))
>
> So despite the fact that the Weibull function has a continuous domain, you
> want to fit a set of integers to something like the Weibull with these
> values as case weights with the "x-values" being the position of these
> integers in a sequence?
>
>
> --
> David.
> >
> > This function always throws up an error saying: Error in
> > numericDeriv(form[[3L]], names(ind), env) :
> > Missing value or an infinity produced when evaluating the model
> > In addition: Warning message:
> > In nls(y ~ ((a/b) * ((x/b)^(a - 1)) * exp(-(x/b)^a))) :
> >  No starting values specified for some parameters.
> > Initializing ?a?, ?b? to '1.'.
> > Consider specifying 'start' or using a selfStart model
> >
> > So first I tried different starting values without any success. I
> > cannot understand how to make a "good" guess at the starting values.
> > Then I went with the SSweibull(x, Asym, Drop, lrc, pwr) function which
> > is a selfStart function. Now the SSWeibull function expects values for
> > Asym,Drop,lrc and pwr and I don't have any clue as to what those
> > values might be.
> >
> > I would appreciate if someone could help me figure out how to proceed.
> >
> > Background of the data: I have taken some data from bugzilla and my
> > "y" variable is number of bugs reported in a particular month and "x"
> > variable is the month number after release.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Wed Oct 14 11:02:25 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Wed, 14 Oct 2015 02:02:25 -0700
Subject: [R] how to do away for loop using functionals?
In-Reply-To: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
References: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
	<746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CACdH2Zabfo-O1KkLWZHZ+mb+RNu4QNbwkgGnOAsyAgqFneKQYQ@mail.gmail.com>

I've done a simple-minded transliteration of your code into code using nested
lapply's.  I doubt that it buys you much in terms of performance (or even
clarity, which is really one of the main advantages of the `apply` family).


> A
        [,1]      [,2]     [,3]     [,4]     [,5]
[1,] 3.06097  6.507521 10.99610 12.05556 15.10388
[2,]     Inf 11.818495 15.85044 16.69465 19.70425
[3,]     Inf       Inf      Inf 19.14779 22.30343
[4,]     Inf       Inf      Inf      Inf 26.11170
[5,]     Inf       Inf      Inf      Inf 28.29882

> B
        [,1]      [,2]     [,3]     [,4]     [,5]
[1,] 3.06097  6.507521 10.99610 12.05556 15.10388
[2,]     Inf 11.818495 15.85044 16.69465 19.70425
[3,]     Inf       Inf      Inf 19.14779 22.30343
[4,]     Inf       Inf      Inf      Inf 26.11170
[5,]     Inf       Inf      Inf      Inf 28.29882
> all.equal(A, B)
[1] TRUE

If I happen to think of a more-elegant approach, I'll let you know.

-- Mike

Appendix: code
==============

###### Anne's code

getResult <- function(d) {

      #examplefunction

     weighted.mean(x=d[,1], w=d[,2])

}

#example data setup

n=20;

set.seed(1)

g=rep(1:5,each=4)

df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1,
0.4) , g )); df

getResult(df)

i0=c(1,2,4,5,5)

ng= length(unique(g))



#initiation of result matrix

A=matrix(Inf, ng, ng); A

for(i in 1:ng)

{              cat("i:",i,"")

                for(j in i0[i]:ng) {

                                ok= !is.na(match(g,i:j)); cat("j:",j,"\n");

                                A[i,j]=getResult(d=df[ok,])

                } #endfor (j)

} #end for (i)
A

###### Mike's code

n <- 20;
set.seed(1)
g <- rep(1:5,each=4)
df <- as.data.frame(cbind(sort(rnorm(mean=15,sd=10, n)),
                          runif(n),
                          rbinom(n, 1, 0.4),
                          g )); df
getResult(df)
i0 <- c(1,2,4,5,5)
ng <- length(unique(g))

B <- matrix(Inf, ng, ng);

invisible(lapply(1:ng, function(i) {
                     lapply(i0[i]:ng, function(j) {
                                ok <- !is.na(match(g, i:j))
                                B[i, j] <<- getResult(df[ok, ])
                            })
                 }))

B
all.equal(A, B)


On Mon, Oct 12, 2015 at 5:55 PM, Annie Hawk via R-help
<r-help at r-project.org> wrote:
> HI R-experts,
>
>
> I am trying to speed up my calculation of the A results below and replace the for loop withsome functionals like lapply.  After manyreadings, trial and error, I still have no success.  Would anyone please give me some hints onthat?
>
> Thank you in advance.
>
> Anne
>
>
> The program is this, I have a complicated function and itneeds to operate on some subsets of a dataset many times, depending on thevalues of group.  I simplify the functionand dataset for this example run.
>
> getResult <- function(d) {
>
>       #examplefunction
>
>      weighted.mean(x=d[,1], w=d[,2])
>
> }
>
>
>
> #example data setup
>
> n=20;
>
> set.seed(1)
>
> g=rep(1:5,each=4)
>
> df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1, 0.4) , g )); df
>
> getResult(df)
>
> i0=c(1,2,4,5,5)
>
> ng= length(unique(g))
>
>
>
> #initiation of result matrix
>
> A=matrix(Inf, ng, ng); A
>
> for(i in 1:ng)
>
> {              cat("i:",i,"")
>
>                 for(jin i0[i]:ng) {
>
>                                 ok= !is.na(match(g,i:j)); cat("j:",j,"\n");
>
>                                 A[i,j]=getResult(d=df[ok,])
>
>                 } #endfor (j)
>
> } #end for (i)
>
> Is there an elegant way to remove the for loop here?  I try to make it flat for faster run but Icannot figure out how to subset the observations faster without error to apply the functiongetResult.  Any hint is appreciated.
>
>
>
>
>
> on another note, is there a more elegant way to initiate the list as follows?
>
> mylist=list(); w=rep(4,5)
>
> for (i in 1:5) mylist[[i]]=w[i:5]
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Wed Oct 14 11:08:07 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 14 Oct 2015 20:08:07 +1100
Subject: [R] 3D matrix columns messed up _ looking for your help
In-Reply-To: <BY2PR13MB04542B5898BB1A436DFEBB0CFA300@BY2PR13MB0454.namprd13.prod.outlook.com>
References: <BY2PR13MB0454057F80E642298F18DCC5FA310@BY2PR13MB0454.namprd13.prod.outlook.com>
	<CA+8X3fW7hSatHookgxk2vv4PzD-3rBUbmrHkU68Yh4zO1gLb-g@mail.gmail.com>
	<BY2PR13MB0454762043FFC5C4118DD62FFA300@BY2PR13MB0454.namprd13.prod.outlook.com>
	<CA+8X3fUgNXLFLTsBRe=EJnhydnrqMKVpHicAd4djmB0xurvZNA@mail.gmail.com>
	<BY2PR13MB04542B5898BB1A436DFEBB0CFA300@BY2PR13MB0454.namprd13.prod.outlook.com>
Message-ID: <CA+8X3fXxWQgYP9g4_0YU12fLPGzYkafMoVwwGqPZockKJG1tnA@mail.gmail.com>

Hi Kristi,
I'm only guessing here, but if I change the order of the levels of "site",
it comes out the way you want. I don't think that this is a solution, but
let me know if it helps.

A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class =
"factor"),
    site = structure(1:3, .Label = c("2C7", "ENM", "ENL"), class =
"factor"),
    DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
    ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label = c("t1",
    "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
"DATE", "date"), row.names = c(NA, -3L), class = "data.frame")

A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
tmp <- split(A, A$Tag)
head(tmp)
tail(tmp)
tmp1 <- do.call(rbind, lapply(tmp, function(x){
tb <- table(A$date)
idx <- which(tb>0)
tb1 <- replace(tb, idx, as.character(A$site))
}))

tmp1

Jim


On Wed, Oct 14, 2015 at 3:17 AM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Hi Jim,
>
> Thank you very much for the message. Sorry for the email that was not
> clear. Yes, you are right, in A$date, should be t2> ENM, t3> ENL. but using
> the code it gave t2>ENL, t3>ENM. I am struggling to fix it. If the data set
> was small, I could do it manually.
>
>
> would you mind to try this example?
>
>
> Here is the example
>
> A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class =
> "factor"),
>     site = structure(1:3, .Label = c("2C7", "ENL", "ENM"), class =
> "factor"),
>     DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
>     ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label = c("t1",
>     "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
> "DATE", "date"), row.names = c(NA, -3L), class = "data.frame")
>
> A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
> tmp <- split(A, A$Tag)
> head(tmp)
> tail(tmp)
> tmp1 <- do.call(rbind, lapply(tmp, function(x){
> tb <- table(A$date)
> idx <- which(tb>0)
> tb1 <- replace(tb, idx, as.character(A$site))
> }))
>
> tmp1
> =========
>
>
>
> ------------------------------
> *From:* Jim Lemon <drjimlemon at gmail.com>
> *Sent:* October 13, 2015 4:24 AM
> *To:* Kristi Glover
> *Cc:* R-help
> *Subject:* Re: [R] 3D matrix columns messed up _ looking for your help
>
> Hi Kristi,
> This is a bit hard to follow, but I'll try. As you are replacing the
> numeric values of the intermediate table with the character values of the
> factor A$date, it looks to me as though the answer is as it should be. 2 ->
> ENL, 3 -> ENM. I suspect that the solution is not difficult, but I can't
> quite make out what you are trying to accomplish.
>
> Jim
>
>
> On Tue, Oct 13, 2015 at 11:44 AM, Kristi Glover <kristi.glover at hotmail.com
> > wrote:
>
>> Hi Jim,
>>
>> Thank you very much for your suggestions. It seems very easy but it is
>> frustrating as it did not work me. with creating factors and rearranging
>> the columns, still z value (site) did change.
>>
>> for example
>>
>> Tag site  DATE
>> a1 2C7  t1
>> a1 ENL  t3
>> a1 ENM t2
>>
>> ENL is supposed to be assigned for the period t3. ENM should be assigned
>> in t2, but using the code, the table gave wrong information as the z value
>> (site) did not move to the corresponding column. ENL is in t2, ENM is inn
>> t3 coumns, which is wrong.
>>
>> > tmp1
>>    t1    t2    t3
>> a1 "2C7" "ENL" "ENM"
>>
>> I have included the code if any one help me to solve the problem. This is
>> a just example, I have a very big data set so that  I could not check
>> it manually therefore, I just checked few rows  but it did not work. Your
>> help is highly appreciated.
>>
>>
>> Here is the example
>>
>> A<-structure(list(Tag = structure(c(1L, 1L, 1L), .Label = "a1", class =
>> "factor"),
>>     site = structure(1:3, .Label = c("2C7", "ENL", "ENM"), class =
>> "factor"),
>>     DATE = structure(c(1L, 3L, 2L), .Label = c("t1", "t2", "t3"
>>     ), class = "factor"), date = structure(c(1L, 3L, 2L), .Label =
>> c("t1",
>>     "t2", "t3"), class = "factor")), .Names = c("Tag", "site",
>> "DATE", "date"), row.names = c(NA, -3L), class = "data.frame")
>>
>> A$date<-factor(A$DATE, levels=c("t1","t2","t3"))
>> tmp <- split(A, A$Tag)
>> head(tmp)
>> tail(tmp)
>> tmp1 <- do.call(rbind, lapply(tmp, function(x){
>> tb <- table(A$date)
>> idx <- which(tb>0)
>> tb1 <- replace(tb, idx, as.character(A$site))
>> }))
>>
>> tmp1
>>
>>
>>
>>
>>
>> ------------------------------
>> *From:* Jim Lemon <drjimlemon at gmail.com>
>> *Sent:* October 12, 2015 4:22 AM
>> *To:* Kristi Glover
>> *Cc:* R-help
>> *Subject:* Re: [R] 3D matrix columns messed up
>>
>> Hi Kristi,
>> The first part is relatively easy:
>>
>> # change first line to
>> x$time<-factor(x$time,levels=c("t1","t2","t3","t4","t10","t21"))
>>
>> As you have specified "site" as the second element in "x", not the third,
>> perhaps you just want:
>>
>> x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L, 1L),
>>  .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
>>  time = structure(c(1L, 3L, 5L, 1L, 5L, 1L, 6L, 2L, 4L),
>>  .Label = c("t1", "t10", "t2", "t21", "t3", "t4"), class = "factor")),
>>  site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L),
>>  .Label = c("A", "B", "D"), class = "factor"),
>>  .Names = c("vs", "time", "site"), class = "data.frame",
>>  row.names = c(NA, -9L))
>>
>> Jim
>>
>> On Mon, Oct 12, 2015 at 7:41 PM, Kristi Glover <kristi.glover at hotmail.com
>> > wrote:
>>
>>> Hi R Users,
>>> I was trying to make a matrix with three variables (x,y, z), but y
>>> variable (columns) names did not stay in its sequential order,
>>> t1,t2,t3,---t21; rather the matrix columns automatically appeared as
>>> a t1,t10, t2,t20 etc. Besides these, z value (sites) did not come in the
>>> right place (meaning in right columns name). I am wondering how I can make
>>> the matrix with the sequential order with right z value (site). I tried it
>>> several ways but did not work. One of the examples I used is given here.
>>> Would you mind to give me a mints?
>>>
>>> x<-structure(list(vs = structure(c(1L, 1L, 2L, 3L, 4L, 2L, 3L, 1L,
>>> 1L), .Label = c("vs1", "vs2", "vs3", "vs4"), class = "factor"),
>>>     site = structure(c(1L, 2L, 3L, 1L, 3L, 1L, 3L, 1L, 2L), .Label =
>>> c("A",
>>>     "B", "D"), class = "factor"), time = structure(c(1L, 3L,
>>>     5L, 1L, 5L, 1L, 6L, 2L, 4L), .Label = c("t1", "t10", "t2",
>>>     "t21", "t3", "t4"), class = "factor")), .Names = c("vs",
>>> "site", "time"), class = "data.frame", row.names = c(NA, -9L))
>>>
>>>
>>> x$time<-factor(x$time)
>>> tmp <- split(x, x$vs)
>>> tmp1 <- do.call(rbind, lapply(tmp, function(x){
>>> tb <- table(x$time)
>>> idx <- which(tb>0)
>>> tb1 <- replace(tb, idx, as.character(x$site))
>>> }))
>>>
>>>
>>> tmp1
>>>
>>>
>>> ## I want the z (site) in respective columns.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Wed Oct 14 12:38:31 2015
From: marammagdysalem at gmail.com (marammagdysalem at gmail.com)
Date: Wed, 14 Oct 2015 12:38:31 +0200
Subject: [R] Last msg not sent to the list
Message-ID: <78C019CC-3A90-440B-81CC-B502FB235188@gmail.com>

Dear All,

My last mail entitled: "using the apply() family to evaluate nested functions with common arguments" to the r-help list didn't reach me though I've sent it 2 days ago. I've included my suggested code and asked about some details to make it work. In addition, I haven't received any feedback from the r-help that may be that mail had something wrong or needs some approval or ... , as the ones I used to receive when I first applied to the list. 
Any idea why is that?!
 
Thanks. 
Maram Salem

Sent from my iPhone

From ivan.calandra at univ-reims.fr  Wed Oct 14 12:54:19 2015
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Wed, 14 Oct 2015 12:54:19 +0200
Subject: [R] Last msg not sent to the list
In-Reply-To: <78C019CC-3A90-440B-81CC-B502FB235188@gmail.com>
References: <78C019CC-3A90-440B-81CC-B502FB235188@gmail.com>
Message-ID: <561E345B.1070408@univ-reims.fr>

Maram,

I have received both of your e-mails on this topic, so they made it to 
the list.
There is the option " Receive your own posts to the list?" on the 
membership configuration website 
(https://stat.ethz.ch/mailman/options/r-help/). If it is checked to 
"no", that would explain why you didn't receive your own posts.

As to why nobody answered, no idea. Try again?

HTH,
Ivan*
*

--
Ivan Calandra, PhD
University of Reims Champagne-Ardenne
GEGENAA - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 14/10/15 12:38, marammagdysalem at gmail.com a ?crit :
> Dear All,
>
> My last mail entitled: "using the apply() family to evaluate nested functions with common arguments" to the r-help list didn't reach me though I've sent it 2 days ago. I've included my suggested code and asked about some details to make it work. In addition, I haven't received any feedback from the r-help that may be that mail had something wrong or needs some approval or ... , as the ones I used to receive when I first applied to the list.
> Any idea why is that?!
>   
> Thanks.
> Maram Salem
>
> Sent from my iPhone
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Wed Oct 14 13:36:43 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 14 Oct 2015 13:36:43 +0200
Subject: [R] Fitting a curve to weibull distribution in R using nls
In-Reply-To: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>
References: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>
Message-ID: <EF15C7EE-2936-4236-811D-A6004984B06C@gmail.com>

There's a number of issues with this:

(a) your data appear to be binned counts, not measurements along a curve.
(b) The function you are trying to fit is the Weibull _density_ This has integral 1, by definition, whereas any curve anywhere near your y's would have integral near sum(y)=127
(c) SSweibull is for growth curves which are proportional to the cumulative Weibull distribution.
(d) SelfStart functions do *not* need starting values, that is the whole point

So you need to study things a bit more...

The expedient way would be this:

> MASS::fitdistr(rep(x,y), "Weibull")
     shape        scale   
   2.4207659   10.5078293 
 ( 0.1530137) ( 0.4079979)
Warning message:
In densfun(x, parm[1], parm[2], ...) : NaNs produced

> plot(y~x, ylim=c(0,20), xlim=c(0,24))
> curve(127*dweibull(x,2.42,10.5), add=TRUE)

It doesn't actually fit very well, but there are quite a few observations out in what was supposed to be the tail of the distribution.


If you want to play with SSweibull, you might do something like

> yy <- cumsum(y)
> nls(yy~SSweibull(x, Asym, Drop, lrc, pwr))
Nonlinear regression model
  model: yy ~ SSweibull(x, Asym, Drop, lrc, pwr)
   data: parent.frame()
   Asym    Drop     lrc     pwr 
122.417 122.471  -6.944   3.129 
 residual sum-of-squares: 187

This gives a nonlinear least squares fit to the cumulative distribution (I am _not_ advocating this, but you said that you were trying to figure out what others had been up to...). If you plot it, you get 

> plot(yy~x)
> curve(SSweibull(x, 122.42, 122.47, -6.94, 3.13), add=TRUE)

which _looks_ nicer, but beware! Everything looks nicer when cumulated and the fit strongly underemphasizes that the data curve is clearly growing past x=15.

Notice also that there is a parametrization difference. SSweibull has Asym and Drop which are F(inf) and F(inf)-F(0) respectively; in this case one could fix both at 127. pwr is  equal to a in the Weibull density, whereas lrc (log rate constant) comes from writing exp(-(x/b)^a)  as exp(-exp(lrc)*x^a), so
b = exp(-lrc)^(1/a) -- i.e.  exp(6.94)^(1/3.13) = 9.18 which is in the same range as the estimate from fitdistr().

You could also fit the weibull density directly using least squares

> nls(y~127*dweibull(x,shape,scale), start=c(shape=3,scale=10))
Nonlinear regression model
  model: y ~ 127 * dweibull(x, shape, scale)
   data: parent.frame()
shape scale 
3.419 9.574 
 residual sum-of-squares: 230.6

Number of iterations to convergence: 6 
Achieved convergence tolerance: 6.037e-06

> plot(y~x, ylim=c(0,20), xlim=c(0,24))
> curve(127*dweibull(x,2.42,10.5), add=TRUE)
> curve(127*dweibull(x,3.419,9.574), add=TRUE)

This fits the peak quite a bit better than the fitdistr() version, but notice again that there are also more observations in regions where there shouldn't really be any according to the fitted curve. This is a generic difference between maximum likelihood and the curve fitting approaches. 

-pd


On 13 Oct 2015, at 23:42 , Aditya Bhatia <aditya.bhatia52 at gmail.com> wrote:

> I am trying to fit this data to a weibull distribution:
> 
> My y variable is:1  1  1  4  7 20  7 14 19 15 18  3  4  1  3  1  1  1
> 1  1  1  1  1  1
> 
> and x variable is:1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> 19 20 21 22 23 24
> 
> The plot looks like this:http://i.stack.imgur.com/FrIKo.png and I want
> to fit a weibull curve to it. I am using the nls function in R like
> this: nls(y ~ ((a/b) * ((x/b)^(a-1)) * exp(- (x/b)^a)))
> 
> This function always throws up an error saying: Error in
> numericDeriv(form[[3L]], names(ind), env) :
> Missing value or an infinity produced when evaluating the model
> In addition: Warning message:
> In nls(y ~ ((a/b) * ((x/b)^(a - 1)) * exp(-(x/b)^a))) :
>  No starting values specified for some parameters.
> Initializing ?a?, ?b? to '1.'.
> Consider specifying 'start' or using a selfStart model
> 
> So first I tried different starting values without any success. I
> cannot understand how to make a "good" guess at the starting values.
> Then I went with the SSweibull(x, Asym, Drop, lrc, pwr) function which
> is a selfStart function. Now the SSWeibull function expects values for
> Asym,Drop,lrc and pwr and I don't have any clue as to what those
> values might be.
> 
> I would appreciate if someone could help me figure out how to proceed.
> 
> Background of the data: I have taken some data from bugzilla and my
> "y" variable is number of bugs reported in a particular month and "x"
> variable is the month number after release.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Wed Oct 14 14:49:59 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 14 Oct 2015 07:49:59 -0500
Subject: [R] Fitting a curve to weibull distribution in R using nls
In-Reply-To: <mailman.7.1444816802.8592.r-help@r-project.org>
References: <mailman.7.1444816802.8592.r-help@r-project.org>
Message-ID: <c10f8b$1ktjqr@ironport10.mayo.edu>



On 10/14/2015 05:00 AM, r-help-request at r-project.org wrote:
> I am trying to fit this data to a weibull distribution:
>
> My y variable is:1  1  1  4  7 20  7 14 19 15 18  3  4  1  3  1  1  1
> 1  1  1  1  1  1
>
> and x variable is:1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
> 19 20 21 22 23 24
>

One could always use existing R functions that fit a Weibull regression, instead of 
reinventing the wheel.

library(survival)
y <- scan()
1  1  1  4  7 20  7 14 19 15 18  3
4  1  3  1  1  1
1  1  1  1  1  1

wfit <- survreg(Surv(1:24) ~ 1, weights=y, dist="weibull")
wfit

Call:
survreg(formula = Surv(1:24) ~ 1, weights = y, dist = "weibull")

Coefficients:
(Intercept)
    2.352121

Scale= 0.4130924

Loglik(model)= -351.4   Loglik(intercept only)= -351.4
n= 24


zz <- seq(0, 25, length=100)
plot(zz, dsurvreg(zz, 2.352121, 0.4130924), col=2, type='l', ylim=c(0, .15),
	xlab="Value", ylab="Density")
points(1:24, y/sum(y))

-----
There are a half dozen ways to parameterize a Weibull distribution; the location-scale 
form used by survreg is one of the less common.  See help(survreg) for more information -- 
look at the example near the bottom of the page.

Terry Therneau


From henrik.bengtsson at ucsf.edu  Wed Oct 14 15:30:03 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 14 Oct 2015 06:30:03 -0700
Subject: [R] Last msg not sent to the list
In-Reply-To: <561E345B.1070408@univ-reims.fr>
References: <78C019CC-3A90-440B-81CC-B502FB235188@gmail.com>
	<561E345B.1070408@univ-reims.fr>
Message-ID: <CAFDcVCR4Efrk9MsMuo-QXkydfR=EokWrj1GPbeN+YVos0VsTkA@mail.gmail.com>

In addition,

if you go to https://stat.ethz.ch/mailman/listinfo/r-help (which is in
the footer of every R-help message), you'll find a link to 'R-help
Archives' (https://stat.ethz.ch/pipermail/r-help/).  On that latter
page, you'll see all messages that have been sent out to the list.
That will allow you to make sure your message went out.

/Henrik

On Wed, Oct 14, 2015 at 3:54 AM, Ivan Calandra
<ivan.calandra at univ-reims.fr> wrote:
> Maram,
>
> I have received both of your e-mails on this topic, so they made it to the
> list.
> There is the option " Receive your own posts to the list?" on the membership
> configuration website (https://stat.ethz.ch/mailman/options/r-help/). If it
> is checked to "no", that would explain why you didn't receive your own
> posts.
>
> As to why nobody answered, no idea. Try again?
>
> HTH,
> Ivan*
> *
>
> --
> Ivan Calandra, PhD
> University of Reims Champagne-Ardenne
> GEGENAA - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> https://www.researchgate.net/profile/Ivan_Calandra
>
> Le 14/10/15 12:38, marammagdysalem at gmail.com a ?crit :
>
>> Dear All,
>>
>> My last mail entitled: "using the apply() family to evaluate nested
>> functions with common arguments" to the r-help list didn't reach me though
>> I've sent it 2 days ago. I've included my suggested code and asked about
>> some details to make it work. In addition, I haven't received any feedback
>> from the r-help that may be that mail had something wrong or needs some
>> approval or ... , as the ones I used to receive when I first applied to the
>> list.
>> Any idea why is that?!
>>   Thanks.
>> Maram Salem
>>
>> Sent from my iPhone
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Wed Oct 14 15:52:48 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 14 Oct 2015 09:52:48 -0400
Subject: [R] Column width in R terminal ?
Message-ID: <20151014095248.31416@web004.roc2.bluetie.com>


Dear all,

I use regular R in xterm terminal in KDE Gui . Even though I have a big terminal  and LINES and COLUMNS parameters are set, R shows data frames and lists only 80 characters per line, then the rest on the next line.  How I can set it to real terminal size so it shows all in one line?

thanks 
CE


From sarah.goslee at gmail.com  Wed Oct 14 16:04:29 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 14 Oct 2015 10:04:29 -0400
Subject: [R] Column width in R terminal ?
In-Reply-To: <20151014095248.31416@web004.roc2.bluetie.com>
References: <20151014095248.31416@web004.roc2.bluetie.com>
Message-ID: <CAM_vjumK27QRVhnX4yq1CPbc7XMo=Ai2NyD_0msVV2L=rwy8iw@mail.gmail.com>

See ?options in particular the width option.

Sarah

On Wed, Oct 14, 2015 at 9:52 AM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I use regular R in xterm terminal in KDE Gui . Even though I have a big terminal  and LINES and COLUMNS parameters are set, R shows data frames and lists only 80 characters per line, then the rest on the next line.  How I can set it to real terminal size so it shows all in one line?
>
> thanks
> CE
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From zadig_1 at excite.com  Wed Oct 14 16:27:47 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 14 Oct 2015 10:27:47 -0400
Subject: [R] Column width in R terminal ?
Message-ID: <20151014102747.20882@web008.roc2.bluetie.com>


Thanks it works but I resize my terminals often. So I put in .Rprofile the line:

options(width=system("echo $COLUMNS",intern =TRUE))
 
but I get error :
Error in options(width = system("echo $COLUMNS", intern = TRUE)) :
  invalid 'width' parameter, allowed 10...10000

command works fine in  R but not in .Rprofile ?


-----Original Message-----
From: "Sarah Goslee" [sarah.goslee at gmail.com]
Date: 10/14/2015 10:04 AM
To: "ce" <zadig_1 at excite.com>
CC: "r-help" <r-help at r-project.org>
Subject: Re: [R] Column width in R terminal ?

See ?options in particular the width option.

Sarah

On Wed, Oct 14, 2015 at 9:52 AM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I use regular R in xterm terminal in KDE Gui . Even though I have a big terminal  and LINES and COLUMNS parameters are set, R shows data frames and lists only 80 characters per line, then the rest on the next line.  How I can set it to real terminal size so it shows all in one line?
>
> thanks
> CE
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Wed Oct 14 16:29:43 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 14 Oct 2015 10:29:43 -0400
Subject: [R] Column width in R terminal ?
In-Reply-To: <20151014102747.20882@web008.roc2.bluetie.com>
References: <20151014102747.20882@web008.roc2.bluetie.com>
Message-ID: <CAM_vjukThi63-3O5_k+PehoNU-jkSyrymkt8_EC6T90=hy211A@mail.gmail.com>

You should probably start by investigating what
system("echo $COLUMNS", intern = TRUE)
returns on your system.

That works for me on linux.

Sarah


On Wed, Oct 14, 2015 at 10:27 AM, ce <zadig_1 at excite.com> wrote:
>
> Thanks it works but I resize my terminals often. So I put in .Rprofile the line:
>
> options(width=system("echo $COLUMNS",intern =TRUE))
>
> but I get error :
> Error in options(width = system("echo $COLUMNS", intern = TRUE)) :
>   invalid 'width' parameter, allowed 10...10000
>
> command works fine in  R but not in .Rprofile ?
>
>
> -----Original Message-----
> From: "Sarah Goslee" [sarah.goslee at gmail.com]
> Date: 10/14/2015 10:04 AM
> To: "ce" <zadig_1 at excite.com>
> CC: "r-help" <r-help at r-project.org>
> Subject: Re: [R] Column width in R terminal ?
>
> See ?options in particular the width option.
>
> Sarah
>
> On Wed, Oct 14, 2015 at 9:52 AM, ce <zadig_1 at excite.com> wrote:
>>
>> Dear all,
>>
>> I use regular R in xterm terminal in KDE Gui . Even though I have a big terminal  and LINES and COLUMNS parameters are set, R shows data frames and lists only 80 characters per line, then the rest on the next line.  How I can set it to real terminal size so it shows all in one line?
>>
>> thanks
>> CE
>>


From zadig_1 at excite.com  Wed Oct 14 17:12:22 2015
From: zadig_1 at excite.com (ce)
Date: Wed, 14 Oct 2015 11:12:22 -0400
Subject: [R] Column width in R terminal ?
Message-ID: <20151014111222.18914@web004.roc2.bluetie.com>


This is perfect, automatically sets width  even if I resize when in R .
thanks a lot. 

-----Original Message-----
From: "Joss Wright" [joss at pseudonymity.net]
Date: 10/14/2015 10:32 AM
To: "ce" <zadig_1 at excite.com>
CC: r-help at r-project.org
Subject: Re: [R] Column width in R terminal ?

On Wed, Oct 14, 2015 at 09:52:48AM -0400, ce wrote:
> I use regular R in xterm terminal in KDE Gui . Even though I have a
> big terminal  and LINES and COLUMNS parameters are set, R shows data
> frames and lists only 80 characters per line, then the rest on the
> next line.  How I can set it to real terminal size so it shows all in
> one line?

As you're in Linux/xterm you might want to look at the setwidth package:

https://cran.r-project.org/web/packages/setwidth/index.html

Joss
-- 
Joss Wright | @JossWright
http://www.pseudonymity.net


From wdunlap at tibco.com  Wed Oct 14 17:34:50 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 14 Oct 2015 08:34:50 -0700
Subject: [R] how to do away for loop using functionals?
In-Reply-To: <CACdH2Zabfo-O1KkLWZHZ+mb+RNu4QNbwkgGnOAsyAgqFneKQYQ@mail.gmail.com>
References: <746008139.2755016.1444697742116.JavaMail.yahoo@mail.yahoo.com>
	<CACdH2Zabfo-O1KkLWZHZ+mb+RNu4QNbwkgGnOAsyAgqFneKQYQ@mail.gmail.com>
Message-ID: <CAF8bMcbFR+qiT+yVQmCtMz2nT4bNxEn5H-Z=F7jNf2sWFDjSGw@mail.gmail.com>

> df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n,
1, 0.4) , g ))

This is a lousy way to make a data.frame - the cbind forces all columns to
be the same
type and forces them into one vector then as.data.frame splits them up into
separate columns
again.  You also get weird names for your columns.  If you want to make a
data.frame, use
   df <- data.frame(ColA = sort(rnorm(mean=15,sd=10, n)), ColB = runif(n),
ColC = rbinom(n, 1, 0.4) , g = g)

However, since the columns you are passing to getResult are both numeric a
matrix (made
with cbind) would work just as well and selecting rows from it will
probably be faster. You
will have to have a large number of groups before you notice the difference.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Oct 14, 2015 at 2:02 AM, Michael Hannon <jmhannon.ucdavis at gmail.com>
wrote:

> I've done a simple-minded transliteration of your code into code using
> nested
> lapply's.  I doubt that it buys you much in terms of performance (or even
> clarity, which is really one of the main advantages of the `apply` family).
>
>
> > A
>         [,1]      [,2]     [,3]     [,4]     [,5]
> [1,] 3.06097  6.507521 10.99610 12.05556 15.10388
> [2,]     Inf 11.818495 15.85044 16.69465 19.70425
> [3,]     Inf       Inf      Inf 19.14779 22.30343
> [4,]     Inf       Inf      Inf      Inf 26.11170
> [5,]     Inf       Inf      Inf      Inf 28.29882
>
> > B
>         [,1]      [,2]     [,3]     [,4]     [,5]
> [1,] 3.06097  6.507521 10.99610 12.05556 15.10388
> [2,]     Inf 11.818495 15.85044 16.69465 19.70425
> [3,]     Inf       Inf      Inf 19.14779 22.30343
> [4,]     Inf       Inf      Inf      Inf 26.11170
> [5,]     Inf       Inf      Inf      Inf 28.29882
> > all.equal(A, B)
> [1] TRUE
>
> If I happen to think of a more-elegant approach, I'll let you know.
>
> -- Mike
>
> Appendix: code
> ==============
>
> ###### Anne's code
>
> getResult <- function(d) {
>
>       #examplefunction
>
>      weighted.mean(x=d[,1], w=d[,2])
>
> }
>
> #example data setup
>
> n=20;
>
> set.seed(1)
>
> g=rep(1:5,each=4)
>
> df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n,
> 1,
> 0.4) , g )); df
>
> getResult(df)
>
> i0=c(1,2,4,5,5)
>
> ng= length(unique(g))
>
>
>
> #initiation of result matrix
>
> A=matrix(Inf, ng, ng); A
>
> for(i in 1:ng)
>
> {              cat("i:",i,"")
>
>                 for(j in i0[i]:ng) {
>
>                                 ok= !is.na(match(g,i:j));
> cat("j:",j,"\n");
>
>                                 A[i,j]=getResult(d=df[ok,])
>
>                 } #endfor (j)
>
> } #end for (i)
> A
>
> ###### Mike's code
>
> n <- 20;
> set.seed(1)
> g <- rep(1:5,each=4)
> df <- as.data.frame(cbind(sort(rnorm(mean=15,sd=10, n)),
>                           runif(n),
>                           rbinom(n, 1, 0.4),
>                           g )); df
> getResult(df)
> i0 <- c(1,2,4,5,5)
> ng <- length(unique(g))
>
> B <- matrix(Inf, ng, ng);
>
> invisible(lapply(1:ng, function(i) {
>                      lapply(i0[i]:ng, function(j) {
>                                 ok <- !is.na(match(g, i:j))
>                                 B[i, j] <<- getResult(df[ok, ])
>                             })
>                  }))
>
> B
> all.equal(A, B)
>
>
> On Mon, Oct 12, 2015 at 5:55 PM, Annie Hawk via R-help
> <r-help at r-project.org> wrote:
> > HI R-experts,
> >
> >
> > I am trying to speed up my calculation of the A results below and
> replace the for loop withsome functionals like lapply.  After manyreadings,
> trial and error, I still have no success.  Would anyone please give me some
> hints onthat?
> >
> > Thank you in advance.
> >
> > Anne
> >
> >
> > The program is this, I have a complicated function and itneeds to
> operate on some subsets of a dataset many times, depending on thevalues of
> group.  I simplify the functionand dataset for this example run.
> >
> > getResult <- function(d) {
> >
> >       #examplefunction
> >
> >      weighted.mean(x=d[,1], w=d[,2])
> >
> > }
> >
> >
> >
> > #example data setup
> >
> > n=20;
> >
> > set.seed(1)
> >
> > g=rep(1:5,each=4)
> >
> > df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n),
> rbinom(n, 1, 0.4) , g )); df
> >
> > getResult(df)
> >
> > i0=c(1,2,4,5,5)
> >
> > ng= length(unique(g))
> >
> >
> >
> > #initiation of result matrix
> >
> > A=matrix(Inf, ng, ng); A
> >
> > for(i in 1:ng)
> >
> > {              cat("i:",i,"")
> >
> >                 for(jin i0[i]:ng) {
> >
> >                                 ok= !is.na(match(g,i:j));
> cat("j:",j,"\n");
> >
> >                                 A[i,j]=getResult(d=df[ok,])
> >
> >                 } #endfor (j)
> >
> > } #end for (i)
> >
> > Is there an elegant way to remove the for loop here?  I try to make it
> flat for faster run but Icannot figure out how to subset the observations
> faster without error to apply the functiongetResult.  Any hint is
> appreciated.
> >
> >
> >
> >
> >
> > on another note, is there a more elegant way to initiate the list as
> follows?
> >
> > mylist=list(); w=rep(4,5)
> >
> > for (i in 1:5) mylist[[i]]=w[i:5]
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Wed Oct 14 15:36:44 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 14 Oct 2015 09:36:44 -0400
Subject: [R] 'strange' R graphics problem | Linux...
Message-ID: <561E5A6C.1070503@gmail.com>

So, am running 3.2.2 on a Centos 6.xx box. Code executes fine, but I'm 
having a heck of a time with graphics. I don't think this is related to 
R in the broad sense, but how it is interacting with graphics on the 
system. here is a description of the problem.

1\ something simple:  test <- rnorm(100)

2\ try to generate a simple histogram  using hist(test)

3\ what happens is that a terminal window pops up (as I would expect for 
the graphic), but rather than showing the histogram, its essentially a 
screen-capture of the original terminal window in which I ran the 
script. Said second terminal window is not responsive, at all -- can't 
even close it short of opening another shell, and killing the process 
from the CLI.

4\ I get the exact same problem even if I try  a simple plot.new() -- 
generate a new terminal window, but with the same problem 'attributes' 
as described above.

For what it works, when I fire up gnuplot, terminal type set to X11 -- 
and basic gnuplot graphics (e.g., plot sin(x)) work perfectly. Other 
graphics seem to work fine too. Just nothing I try to plot using R.

Anyone have any ideas as to what to look for/try? Here is the output of 
sessionInfo() -- nothing obvious that I can see.

R version 3.2.2 (2015-08-14)
Platform: x86_64-redhat-linux-gnu (64-bit)
Running under: CentOS release 6.7 (Final)

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base


From joss at pseudonymity.net  Wed Oct 14 16:31:25 2015
From: joss at pseudonymity.net (Joss Wright)
Date: Wed, 14 Oct 2015 15:31:25 +0100
Subject: [R] Column width in R terminal ?
In-Reply-To: <20151014095248.31416@web004.roc2.bluetie.com>
References: <20151014095248.31416@web004.roc2.bluetie.com>
Message-ID: <20151014143125.GA1331@kafka.pseudonymity.local>

On Wed, Oct 14, 2015 at 09:52:48AM -0400, ce wrote:
> I use regular R in xterm terminal in KDE Gui . Even though I have a
> big terminal  and LINES and COLUMNS parameters are set, R shows data
> frames and lists only 80 characters per line, then the rest on the
> next line.  How I can set it to real terminal size so it shows all in
> one line?

As you're in Linux/xterm you might want to look at the setwidth package:

https://cran.r-project.org/web/packages/setwidth/index.html

Joss
-- 
Joss Wright | @JossWright
http://www.pseudonymity.net


From manishsindagi5 at gmail.com  Wed Oct 14 17:19:06 2015
From: manishsindagi5 at gmail.com (Manish Sindagi)
Date: Wed, 14 Oct 2015 11:19:06 -0400
Subject: [R] Subscription request
Message-ID: <CA+t6kQJHyhg0Teu5z2R+PpVieknCnXvuT1-PYyjFmCeA8r4ioA@mail.gmail.com>

Hi,

I have a few R programming related questions that i wanted to ask.

Can you please accept my subscription request.

Regards,

Manish.

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Wed Oct 14 20:23:13 2015
From: jholtman at gmail.com (jim holtman)
Date: Wed, 14 Oct 2015 14:23:13 -0400
Subject: [R] SQL Server "float" is not handled by RODBC -- Is there a
	workaround?
Message-ID: <CAAxdm-6AqCejJEDo=gfxLiekNPoKYNLTh=67AjBx_hMH-+_ogA@mail.gmail.com>

Here is the system I am using:
=====================================
> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252
LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lubridate_1.3.3 RODBC_1.3-12
loaded via a namespace (and not attached):
[1] magrittr_1.5  plyr_1.8.3    tools_3.2.2   memoise_0.2.1 Rcpp_0.12.1
stringi_0.5-5 digest_0.6.8
[8] stringr_1.0.0
========================================

I have data on a SQL Server that I am connecting to where some of the
fields are defined as "float" so that the data is stored in the database as
an IEEE 754 value.  Now when I read this is using RODBC, the data comes
across the interface in the floating point format; I used Wireshark to
examine the packets that were being sent.  Some of the data is also defined
as "int" and comes across in binary.

When the data is read in with

df <- sqlQuery(db, "select * from mydb", as.is = TRUE)

The resulting dataframe has the floating point values as 'chr' and the
integer fields as 'int'; I would have expected the floating point fields to
be 'num'.  Now in the "ODBC Connectivity" Vignette by Ripley there was the
comment that "double" data values come back as type 8, but on some systems
they may be type 6; well on SQL Server, "float" is type 6.

So what appears to happen, is this data is not recognized as a floating
point value and is therefore converted to a character.  When the data is
made available to the R script, I then have to convert this back to
floating point.  If I use "stringsAsFactors = FALSE" on the query, this
conversion back to floating point will be done within the RODBC package.
This becomes a problem when I have dataframes with several million rows and
multiple columns of numerics is that the conversion to/from characters is
adding time to the processing.

So I was wondering is there a workaround to this problem?  Is it possible
to add the capability to RODBC when processing SQL Server to avoid this
conversion?  Or is there some other way around this problem?

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

	[[alternative HTML version deleted]]


From Ted.Harding at wlandres.net  Wed Oct 14 20:35:01 2015
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Wed, 14 Oct 2015 19:35:01 +0100 (BST)
Subject: [R] Subscription request
In-Reply-To: <CA+t6kQJHyhg0Teu5z2R+PpVieknCnXvuT1-PYyjFmCeA8r4ioA@mail.gmail.com>
Message-ID: <XFMail.20151014193501.Ted.Harding@wlandres.net>

On 14-Oct-2015 15:19:06 Manish Sindagi wrote:
> Hi,
> 
> I have a few R programming related questions that i wanted to ask.
> Can you please accept my subscription request.
> 
> Regards,
> Manish.

Visit the R-help info web page:

  https://stat.ethz.ch/mailman/listinfo/r-help

Towards the bottom of this page is a section "Subscribing to R-help".
Follow the instructions in this section, and it should work!

Best wishes,
Ted.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 14-Oct-2015  Time: 19:34:55
This message was sent by XFMail


From tea3rd at gmail.com  Wed Oct 14 21:35:14 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 14 Oct 2015 14:35:14 -0500
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <561E5A6C.1070503@gmail.com>
References: <561E5A6C.1070503@gmail.com>
Message-ID: <CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>

Evan,

Not that this helps you, but I am using a very similar platform and I am
having the identical problem. My test simply comes from the first
help(plot) example. I tried doing some things to 'correct' the problem and
ended up mucking-up my Gnome environment. In the process, I was able to get
the example to display correctly, but as I said, I now have an unusable
system. I'm not sure this is an R specific problem, but some
incompatibility with the Centos Gnome environment.

Tom

On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch <evan.cooch at gmail.com> wrote:

> So, am running 3.2.2 on a Centos 6.xx box. Code executes fine, but I'm
> having a heck of a time with graphics. I don't think this is related to R
> in the broad sense, but how it is interacting with graphics on the system.
> here is a description of the problem.
>
> 1\ something simple:  test <- rnorm(100)
>
> 2\ try to generate a simple histogram  using hist(test)
>
> 3\ what happens is that a terminal window pops up (as I would expect for
> the graphic), but rather than showing the histogram, its essentially a
> screen-capture of the original terminal window in which I ran the script.
> Said second terminal window is not responsive, at all -- can't even close
> it short of opening another shell, and killing the process from the CLI.
>
> 4\ I get the exact same problem even if I try  a simple plot.new() --
> generate a new terminal window, but with the same problem 'attributes' as
> described above.
>
> For what it works, when I fire up gnuplot, terminal type set to X11 -- and
> basic gnuplot graphics (e.g., plot sin(x)) work perfectly. Other graphics
> seem to work fine too. Just nothing I try to plot using R.
>
> Anyone have any ideas as to what to look for/try? Here is the output of
> sessionInfo() -- nothing obvious that I can see.
>
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> Running under: CentOS release 6.7 (Final)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From tea3rd at gmail.com  Wed Oct 14 21:51:05 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 14 Oct 2015 14:51:05 -0500
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <561EB137.9080304@gmail.com>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
	<561EB137.9080304@gmail.com>
Message-ID: <CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>

Evan,

I have Ubuntu 14.04 and 15.10 at home and have not had problems, but I
don't think I've been using R 3.2.2 ? I'll try this evening.

Tom

On Wed, Oct 14, 2015 at 2:47 PM, Evan Cooch <evan.cooch at gmail.com> wrote:

> Tom --
>
> On 10/14/2015 3:35 PM, Thomas Adams wrote:
>
> Evan,
>
> Not that this helps you, but I am using a very similar platform and I am
> having the identical problem. My test simply comes from the first
> help(plot) example. I tried doing some things to 'correct' the problem and
> ended up mucking-up my Gnome environment. In the process, I was able to get
> the example to display correctly, but as I said, I now have an unusable
> system. I'm not sure this is an R specific problem, but some
> incompatibility with the Centos Gnome environment.
>
>
> Thanks very much. I have a couple of Linux Mint 17.x systems as well --
> I'll see if they throw the same problem at me/us.
>
> Tom
>
> On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
>
>> So, am running 3.2.2 on a Centos 6.xx box. Code executes fine, but I'm
>> having a heck of a time with graphics. I don't think this is related to R
>> in the broad sense, but how it is interacting with graphics on the system.
>> here is a description of the problem.
>>
>> 1\ something simple:  test <- rnorm(100)
>>
>> 2\ try to generate a simple histogram  using hist(test)
>>
>> 3\ what happens is that a terminal window pops up (as I would expect for
>> the graphic), but rather than showing the histogram, its essentially a
>> screen-capture of the original terminal window in which I ran the script.
>> Said second terminal window is not responsive, at all -- can't even close
>> it short of opening another shell, and killing the process from the CLI.
>>
>> 4\ I get the exact same problem even if I try  a simple plot.new() --
>> generate a new terminal window, but with the same problem 'attributes' as
>> described above.
>>
>> For what it works, when I fire up gnuplot, terminal type set to X11 --
>> and basic gnuplot graphics (e.g., plot sin(x)) work perfectly. Other
>> graphics seem to work fine too. Just nothing I try to plot using R.
>>
>> Anyone have any ideas as to what to look for/try? Here is the output of
>> sessionInfo() -- nothing obvious that I can see.
>>
>> R version 3.2.2 (2015-08-14)
>> Platform: x86_64-redhat-linux-gnu (64-bit)
>> Running under: CentOS release 6.7 (Final)
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> <http://www.R-project.org/posting-guide.html>
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From tr206 at kent.ac.uk  Wed Oct 14 21:56:22 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 14 Oct 2015 19:56:22 +0000
Subject: [R] algorithmic method quantile regression
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A120100549908@EX10-LIVE-MBN1.ad.kent.ac.uk>

Greetings R Community,
I am trying to run a quantile regression using the quantreg package. My regression includes 7 independent variables with approx. 800 daily observations each. Thus, I think that the Barrodale and Roberts algorithm should do the trick. However, the Frisch-Newton after preprocessing returns different results and more significant coefficients than the br method. Which algorithmic method should I use now? Do the results mean that the Frisch-Newton after preprocessing dominates the br method?

	[[alternative HTML version deleted]]


From rkoenker at illinois.edu  Wed Oct 14 22:32:48 2015
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 14 Oct 2015 15:32:48 -0500
Subject: [R] algorithmic method quantile regression
In-Reply-To: <493824fd8e11445682b67a1bf5eb1cc8@CITESHT2.ad.uillinois.edu>
References: <493824fd8e11445682b67a1bf5eb1cc8@CITESHT2.ad.uillinois.edu>
Message-ID: <28372756-6544-4956-AA45-61F62FCACAA4@illinois.edu>

Did you read item 1 in the quantreg FAQ()?  


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Oct 14, 2015, at 2:56 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Greetings R Community,
> I am trying to run a quantile regression using the quantreg package. My regression includes 7 independent variables with approx. 800 daily observations each. Thus, I think that the Barrodale and Roberts algorithm should do the trick. However, the Frisch-Newton after preprocessing returns different results and more significant coefficients than the br method. Which algorithmic method should I use now? Do the results mean that the Frisch-Newton after preprocessing dominates the br method?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marammagdysalem at gmail.com  Wed Oct 14 22:40:47 2015
From: marammagdysalem at gmail.com (marammagdysalem at gmail.com)
Date: Wed, 14 Oct 2015 22:40:47 +0200
Subject: [R] Last msg not sent to the list
In-Reply-To: <CAFDcVCR4Efrk9MsMuo-QXkydfR=EokWrj1GPbeN+YVos0VsTkA@mail.gmail.com>
References: <78C019CC-3A90-440B-81CC-B502FB235188@gmail.com>
	<561E345B.1070408@univ-reims.fr>
	<CAFDcVCR4Efrk9MsMuo-QXkydfR=EokWrj1GPbeN+YVos0VsTkA@mail.gmail.com>
Message-ID: <10B523D1-A047-49EC-B096-4CA13B6A891D@gmail.com>

Thanks a lot Ivan and Henrik.
 
Maram

Sent from my iPhone

> On Oct 14, 2015, at 3:30 PM, Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:
> 
> In addition,
> 
> if you go to https://stat.ethz.ch/mailman/listinfo/r-help (which is in
> the footer of every R-help message), you'll find a link to 'R-help
> Archives' (https://stat.ethz.ch/pipermail/r-help/).  On that latter
> page, you'll see all messages that have been sent out to the list.
> That will allow you to make sure your message went out.
> 
> /Henrik
> 
> On Wed, Oct 14, 2015 at 3:54 AM, Ivan Calandra
> <ivan.calandra at univ-reims.fr> wrote:
>> Maram,
>> 
>> I have received both of your e-mails on this topic, so they made it to the
>> list.
>> There is the option " Receive your own posts to the list?" on the membership
>> configuration website (https://stat.ethz.ch/mailman/options/r-help/). If it
>> is checked to "no", that would explain why you didn't receive your own
>> posts.
>> 
>> As to why nobody answered, no idea. Try again?
>> 
>> HTH,
>> Ivan*
>> *
>> 
>> --
>> Ivan Calandra, PhD
>> University of Reims Champagne-Ardenne
>> GEGENAA - EA 3795
>> CREA - 2 esplanade Roland Garros
>> 51100 Reims, France
>> +33(0)3 26 77 36 89
>> ivan.calandra at univ-reims.fr
>> https://www.researchgate.net/profile/Ivan_Calandra
>> 
>> Le 14/10/15 12:38, marammagdysalem at gmail.com a ?crit :
>> 
>>> Dear All,
>>> 
>>> My last mail entitled: "using the apply() family to evaluate nested
>>> functions with common arguments" to the r-help list didn't reach me though
>>> I've sent it 2 days ago. I've included my suggested code and asked about
>>> some details to make it work. In addition, I haven't received any feedback
>>> from the r-help that may be that mail had something wrong or needs some
>>> approval or ... , as the ones I used to receive when I first applied to the
>>> list.
>>> Any idea why is that?!
>>>  Thanks.
>>> Maram Salem
>>> 
>>> Sent from my iPhone
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tr206 at kent.ac.uk  Wed Oct 14 23:03:44 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 14 Oct 2015 21:03:44 +0000
Subject: [R] algorithmic method quantile regression
In-Reply-To: <28372756-6544-4956-AA45-61F62FCACAA4@illinois.edu>
References: <493824fd8e11445682b67a1bf5eb1cc8@CITESHT2.ad.uillinois.edu>
	<28372756-6544-4956-AA45-61F62FCACAA4@illinois.edu>
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A120100549C56@EX10-LIVE-MBN1.ad.kent.ac.uk>

The fn and br methods return the same results but the results provided by pfn differ. I do not find an explanation for this observation in the papers on quantile regression. Therefore my question.

-----Original Message-----
From: Roger Koenker [mailto:rkoenker at illinois.edu] 
Sent: 14 October 2015 22:33
To: T.Riedle
Cc: r-help at r-project.org
Subject: Re: [R] algorithmic method quantile regression

Did you read item 1 in the quantreg FAQ()?  


url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801

> On Oct 14, 2015, at 2:56 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> 
> Greetings R Community,
> I am trying to run a quantile regression using the quantreg package. My regression includes 7 independent variables with approx. 800 daily observations each. Thus, I think that the Barrodale and Roberts algorithm should do the trick. However, the Frisch-Newton after preprocessing returns different results and more significant coefficients than the br method. Which algorithmic method should I use now? Do the results mean that the Frisch-Newton after preprocessing dominates the br method?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aditya.bhatia52 at gmail.com  Thu Oct 15 02:18:58 2015
From: aditya.bhatia52 at gmail.com (Aditya Bhatia)
Date: Thu, 15 Oct 2015 05:48:58 +0530
Subject: [R] Fitting a curve to weibull distribution in R using nls
In-Reply-To: <EF15C7EE-2936-4236-811D-A6004984B06C@gmail.com>
References: <CAOuxJ+4zpBF4MbDVY8-SG8ipd8WbC+1VTOf=EeHnDwr5WQNiTA@mail.gmail.com>
	<EF15C7EE-2936-4236-811D-A6004984B06C@gmail.com>
Message-ID: <CAOuxJ+4TrSTAV6gbYnxDCYysRSjhkZ4NbRcDt9f4GRKx72y0pQ@mail.gmail.com>

Thank you for the amazing response. You are right;I definitely have to
study a bit more. I am just trying to copy the procedure in a paper so
I didn't give it much thought.

for point (a) : yes the data is binned counts; and my aim is to find
out which curve best approximates these counts.

I am going to try and see if I can fit something like :
nls(y~d*dweibull(x,shape,scale), start=c(shape=3,scale=10,d=127))
instead of just putting it to be the sum of the observations.
Hopefully I will get a better result. And the tail of distribution is
not very important to me so I don't mind that the result may not fit
the tail of the curve correctly.

Thanks again for your help. I can make some progress now.

-Aditya Bhatia
On Wed, Oct 14, 2015 at 5:06 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> There's a number of issues with this:
>
> (a) your data appear to be binned counts, not measurements along a curve.
> (b) The function you are trying to fit is the Weibull _density_ This has integral 1, by definition, whereas any curve anywhere near your y's would have integral near sum(y)=127
> (c) SSweibull is for growth curves which are proportional to the cumulative Weibull distribution.
> (d) SelfStart functions do *not* need starting values, that is the whole point
>
> So you need to study things a bit more...
>
> The expedient way would be this:
>
>> MASS::fitdistr(rep(x,y), "Weibull")
>      shape        scale
>    2.4207659   10.5078293
>  ( 0.1530137) ( 0.4079979)
> Warning message:
> In densfun(x, parm[1], parm[2], ...) : NaNs produced
>
>> plot(y~x, ylim=c(0,20), xlim=c(0,24))
>> curve(127*dweibull(x,2.42,10.5), add=TRUE)
>
> It doesn't actually fit very well, but there are quite a few observations out in what was supposed to be the tail of the distribution.
>
>
> If you want to play with SSweibull, you might do something like
>
>> yy <- cumsum(y)
>> nls(yy~SSweibull(x, Asym, Drop, lrc, pwr))
> Nonlinear regression model
>   model: yy ~ SSweibull(x, Asym, Drop, lrc, pwr)
>    data: parent.frame()
>    Asym    Drop     lrc     pwr
> 122.417 122.471  -6.944   3.129
>  residual sum-of-squares: 187
>
> This gives a nonlinear least squares fit to the cumulative distribution (I am _not_ advocating this, but you said that you were trying to figure out what others had been up to...). If you plot it, you get
>
>> plot(yy~x)
>> curve(SSweibull(x, 122.42, 122.47, -6.94, 3.13), add=TRUE)
>
> which _looks_ nicer, but beware! Everything looks nicer when cumulated and the fit strongly underemphasizes that the data curve is clearly growing past x=15.
>
> Notice also that there is a parametrization difference. SSweibull has Asym and Drop which are F(inf) and F(inf)-F(0) respectively; in this case one could fix both at 127. pwr is  equal to a in the Weibull density, whereas lrc (log rate constant) comes from writing exp(-(x/b)^a)  as exp(-exp(lrc)*x^a), so
> b = exp(-lrc)^(1/a) -- i.e.  exp(6.94)^(1/3.13) = 9.18 which is in the same range as the estimate from fitdistr().
>
> You could also fit the weibull density directly using least squares
>
>> nls(y~127*dweibull(x,shape,scale), start=c(shape=3,scale=10))
> Nonlinear regression model
>   model: y ~ 127 * dweibull(x, shape, scale)
>    data: parent.frame()
> shape scale
> 3.419 9.574
>  residual sum-of-squares: 230.6
>
> Number of iterations to convergence: 6
> Achieved convergence tolerance: 6.037e-06
>
>> plot(y~x, ylim=c(0,20), xlim=c(0,24))
>> curve(127*dweibull(x,2.42,10.5), add=TRUE)
>> curve(127*dweibull(x,3.419,9.574), add=TRUE)
>
> This fits the peak quite a bit better than the fitdistr() version, but notice again that there are also more observations in regions where there shouldn't really be any according to the fitted curve. This is a generic difference between maximum likelihood and the curve fitting approaches.
>
> -pd
>
>
> On 13 Oct 2015, at 23:42 , Aditya Bhatia <aditya.bhatia52 at gmail.com> wrote:
>
>> I am trying to fit this data to a weibull distribution:
>>
>> My y variable is:1  1  1  4  7 20  7 14 19 15 18  3  4  1  3  1  1  1
>> 1  1  1  1  1  1
>>
>> and x variable is:1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18
>> 19 20 21 22 23 24
>>
>> The plot looks like this:http://i.stack.imgur.com/FrIKo.png and I want
>> to fit a weibull curve to it. I am using the nls function in R like
>> this: nls(y ~ ((a/b) * ((x/b)^(a-1)) * exp(- (x/b)^a)))
>>
>> This function always throws up an error saying: Error in
>> numericDeriv(form[[3L]], names(ind), env) :
>> Missing value or an infinity produced when evaluating the model
>> In addition: Warning message:
>> In nls(y ~ ((a/b) * ((x/b)^(a - 1)) * exp(-(x/b)^a))) :
>>  No starting values specified for some parameters.
>> Initializing ?a?, ?b? to '1.'.
>> Consider specifying 'start' or using a selfStart model
>>
>> So first I tried different starting values without any success. I
>> cannot understand how to make a "good" guess at the starting values.
>> Then I went with the SSweibull(x, Asym, Drop, lrc, pwr) function which
>> is a selfStart function. Now the SSWeibull function expects values for
>> Asym,Drop,lrc and pwr and I don't have any clue as to what those
>> values might be.
>>
>> I would appreciate if someone could help me figure out how to proceed.
>>
>> Background of the data: I have taken some data from bugzilla and my
>> "y" variable is number of bugs reported in a particular month and "x"
>> variable is the month number after release.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


From tea3rd at gmail.com  Thu Oct 15 03:39:35 2015
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 14 Oct 2015 20:39:35 -0500
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <561EE6BC.9080907@cornell.edu>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
	<561EB137.9080304@gmail.com>
	<CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>
	<561EB44F.8060309@gmail.com> <561EE6BC.9080907@cornell.edu>
Message-ID: <CAGxgkWi08fy97EMFhE4+t5BCz=DtGSTLU21DJNUSiKK+XcCjiA@mail.gmail.com>

Evan,

I have R 3.2.2 installed on my Ubuntu 15.04 machine -- no problems with the
graphics display. I have R 3.1.1 installed on my Ubuntu 14.04 machine,
that, as expected I have not had any problems with... I tried to install
3.2.2 and 3.2.1 from source and got a very strange compile error, which I
need to sort out -- recompiling 3.1.1 failed as well...

Best,
Tom

On Wed, Oct 14, 2015 at 6:35 PM, Evan Cooch <evan.cooch at cornell.edu> wrote:

> A clue --
>
> Working from home, I created an ssh tunnel into my CentOS box, and brought
> up the desktop remotely using VNC. Fire up R in a terminal, and *voila*,
> graphics work fine.
>
> So, if I'm sitting at the CentOS machine, R graphics choke and die. If I
> use a remote desktop approach, graphics fine.
>
> Very strange...
>
> Forgot to add before, here are the 'capabilities' from my R install -- X11
> and cairo both 'there', so not sure what the problem is.
>
>        jpeg         png        tiff       tcltk         X11        aqua
>        TRUE        TRUE        TRUE        TRUE        TRUE       FALSE
>    http/ftp     sockets      libxml        fifo      cledit       iconv
>        TRUE        TRUE        TRUE        TRUE        TRUE        TRUE
>         NLS     profmem       cairo         ICU long.double     libcurl
>        TRUE       FALSE        TRUE        TRUE        TRUE       FALSE
>
> On 10/14/2015 4:00 PM, Evan Cooch wrote:
>
>
>
> On 10/14/2015 3:51 PM, Thomas Adams wrote:
>
> Evan,
>
> I have Ubuntu 14.04 and 15.10 at home and have not had problems, but I
> don't think I've been using R 3.2.2 ? I'll try this evening.
>
>
> Indeed - it could be an R-version issue, and not so much the distro. I
> might, for chuckles, roll back to 3.2.1, and see what happens.
>
>
> Tom
>
> On Wed, Oct 14, 2015 at 2:47 PM, Evan Cooch <evan.cooch at gmail.com> wrote:
>
>> Tom --
>>
>> On 10/14/2015 3:35 PM, Thomas Adams wrote:
>>
>> Evan,
>>
>> Not that this helps you, but I am using a very similar platform and I am
>> having the identical problem. My test simply comes from the first
>> help(plot) example. I tried doing some things to 'correct' the problem and
>> ended up mucking-up my Gnome environment. In the process, I was able to get
>> the example to display correctly, but as I said, I now have an unusable
>> system. I'm not sure this is an R specific problem, but some
>> incompatibility with the Centos Gnome environment.
>>
>>
>> Thanks very much. I have a couple of Linux Mint 17.x systems as well --
>> I'll see if they throw the same problem at me/us.
>>
>> Tom
>>
>> On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch <evan.cooch at gmail.com> wrote:
>>
>>> So, am running 3.2.2 on a Centos 6.xx box. Code executes fine, but I'm
>>> having a heck of a time with graphics. I don't think this is related to R
>>> in the broad sense, but how it is interacting with graphics on the system.
>>> here is a description of the problem.
>>>
>>> 1\ something simple:  test <- rnorm(100)
>>>
>>> 2\ try to generate a simple histogram  using hist(test)
>>>
>>> 3\ what happens is that a terminal window pops up (as I would expect for
>>> the graphic), but rather than showing the histogram, its essentially a
>>> screen-capture of the original terminal window in which I ran the script.
>>> Said second terminal window is not responsive, at all -- can't even close
>>> it short of opening another shell, and killing the process from the CLI.
>>>
>>> 4\ I get the exact same problem even if I try  a simple plot.new() --
>>> generate a new terminal window, but with the same problem 'attributes' as
>>> described above.
>>>
>>> For what it works, when I fire up gnuplot, terminal type set to X11 --
>>> and basic gnuplot graphics (e.g., plot sin(x)) work perfectly. Other
>>> graphics seem to work fine too. Just nothing I try to plot using R.
>>>
>>> Anyone have any ideas as to what to look for/try? Here is the output of
>>> sessionInfo() -- nothing obvious that I can see.
>>>
>>> R version 3.2.2 (2015-08-14)
>>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>> Running under: CentOS release 6.7 (Final)
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> <http://www.R-project.org/posting-guide.html>
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>>
>>
>>
>>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From ahawk14 at yahoo.com  Wed Oct 14 23:11:58 2015
From: ahawk14 at yahoo.com (Annie Hawk)
Date: Wed, 14 Oct 2015 21:11:58 +0000 (UTC)
Subject: [R] how to do away for loop using functionals?
In-Reply-To: <CAF8bMcbFR+qiT+yVQmCtMz2nT4bNxEn5H-Z=F7jNf2sWFDjSGw@mail.gmail.com>
References: <CAF8bMcbFR+qiT+yVQmCtMz2nT4bNxEn5H-Z=F7jNf2sWFDjSGw@mail.gmail.com>
Message-ID: <635092396.437369.1444857118477.JavaMail.yahoo@mail.yahoo.com>

Thank you Mike for looking into the problem and your helpful advice, really appreciate that. ?Also, thank you Bill for pointing out the bad data.frame code.I modified the codes per your suggestions and run some time tests on n=2000 (increase # obs and groups as I actually have a much bigger dataset and more complicated getResult function with 100 lines of code)
original code:> proc.time() - ptm? ?user ?system elapsed?? 72.37 ? ?0.06 ? 72.51?
modified code:> proc.time() - ptm? ?user ?system elapsed?? 73.21 ? ?0.20 ? 81.26?
Surprisingly the lapply doesn't appear to save time, perhaps I should use dplyr function to extract groups but I tried that before and it didn't save time either. ?I read that data.table is faster (if applicable) and perhaps I should go to that direction? Any thought of speeding the ops is much appreciated.Thank you,Anne


--------------------------------------------- CODE below?#sample data setupn=2000;?set.seed(1)g=rep(1:500,each=4)df=data.frame(s=sort(rnorm(mean=15,sd=10, n)), w=runif(n), h=rbinom(n, 1, 0.4) , g ); df ? ? ?getResult(df)#i0=c(1,2,4,5,5)i0=rep(c(1,2,4,5,5),100)
ng= length(unique(g))
#initiation of result matrixA=B=matrix(Inf, ng, ?ng); A## my code (Anne)ptm = proc.time()for(i in 1:ng)?{ #cat("i:",i," ") for(j in i0[i]:ng) { ok = !is.na(match(g,i:j)); #cat("j:",j,"\n");?  ?  A[i,j]=getResult(d=df[ok,]) } #end for (j)} #end for (i)proc.time() - ptm
## Mike's codeptm = proc.time()invisible(lapply(1:ng, function(i) {? ? ? ? ? ? ? ? ? ? ? lapply(i0[i]:ng, function(j) {? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?ok <- !is.na(match(g, i:j))? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?B[i, j] <<- getResult(df[ok, ])? ? ? ? ? ? ? ? ? ? ? ? ? ? ?})? ? ? ? ? ? ? ? ?}))proc.time() - ptm

 


     On Wednesday, October 14, 2015 11:35 AM, William Dunlap <wdunlap at tibco.com> wrote:
   

 > df=as.data.frame(cbind(?sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1,?0.4) , g?))

This is a lousy way to make a data.frame - the cbind forces all columns to be the sametype and forces them into one vector then as.data.frame splits them up into separate columnsagain.? You also get weird names for your columns.? If you want to make a data.frame, use? ?df <- data.frame(ColA = sort(rnorm(mean=15,sd=10, n)), ColB = runif(n), ColC = rbinom(n, 1,?0.4) , g = g)
However, since the columns you are passing to getResult are both numeric a matrix (madewith cbind) would work just as well and selecting rows from it will probably be faster. Youwill have to have a large number of groups before you notice the difference.

Bill Dunlap
TIBCO Software
wdunlap tibco.com
On Wed, Oct 14, 2015 at 2:02 AM, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:

I've done a simple-minded transliteration of your code into code using nested
lapply's.? I doubt that it buys you much in terms of performance (or even
clarity, which is really one of the main advantages of the `apply` family).


> A
? ? ? ? [,1]? ? ? [,2]? ? ?[,3]? ? ?[,4]? ? ?[,5]
[1,] 3.06097? 6.507521 10.99610 12.05556 15.10388
[2,]? ? ?Inf 11.818495 15.85044 16.69465 19.70425
[3,]? ? ?Inf? ? ? ?Inf? ? ? Inf 19.14779 22.30343
[4,]? ? ?Inf? ? ? ?Inf? ? ? Inf? ? ? Inf 26.11170
[5,]? ? ?Inf? ? ? ?Inf? ? ? Inf? ? ? Inf 28.29882

> B
? ? ? ? [,1]? ? ? [,2]? ? ?[,3]? ? ?[,4]? ? ?[,5]
[1,] 3.06097? 6.507521 10.99610 12.05556 15.10388
[2,]? ? ?Inf 11.818495 15.85044 16.69465 19.70425
[3,]? ? ?Inf? ? ? ?Inf? ? ? Inf 19.14779 22.30343
[4,]? ? ?Inf? ? ? ?Inf? ? ? Inf? ? ? Inf 26.11170
[5,]? ? ?Inf? ? ? ?Inf? ? ? Inf? ? ? Inf 28.29882
> all.equal(A, B)
[1] TRUE

If I happen to think of a more-elegant approach, I'll let you know.

-- Mike

Appendix: code
==============

###### Anne's code

getResult <- function(d) {

? ? ? #examplefunction

? ? ?weighted.mean(x=d[,1], w=d[,2])

}

#example data setup

n=20;

set.seed(1)

g=rep(1:5,each=4)

df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1,
0.4) , g )); df

getResult(df)

i0=c(1,2,4,5,5)

ng= length(unique(g))



#initiation of result matrix

A=matrix(Inf, ng, ng); A

for(i in 1:ng)

{? ? ? ? ? ? ? cat("i:",i,"")

? ? ? ? ? ? ? ? for(j in i0[i]:ng) {

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ok= !is.na(match(g,i:j)); cat("j:",j,"\n");

? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? A[i,j]=getResult(d=df[ok,])

? ? ? ? ? ? ? ? } #endfor (j)

} #end for (i)
A

###### Mike's code

n <- 20;
set.seed(1)
g <- rep(1:5,each=4)
df <- as.data.frame(cbind(sort(rnorm(mean=15,sd=10, n)),
? ? ? ? ? ? ? ? ? ? ? ? ? runif(n),
? ? ? ? ? ? ? ? ? ? ? ? ? rbinom(n, 1, 0.4),
? ? ? ? ? ? ? ? ? ? ? ? ? g )); df
getResult(df)
i0 <- c(1,2,4,5,5)
ng <- length(unique(g))

B <- matrix(Inf, ng, ng);

invisible(lapply(1:ng, function(i) {
? ? ? ? ? ? ? ? ? ? ?lapply(i0[i]:ng, function(j) {
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ok <- !is.na(match(g, i:j))
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? B[i, j] <<- getResult(df[ok, ])
? ? ? ? ? ? ? ? ? ? ? ? ? ? })
? ? ? ? ? ? ? ? ?}))

B
all.equal(A, B)


On Mon, Oct 12, 2015 at 5:55 PM, Annie Hawk via R-help
<r-help at r-project.org> wrote:
> HI R-experts,
>
>
> I am trying to speed up my calculation of the A results below and replace the for loop withsome functionals like lapply.? After manyreadings, trial and error, I still have no success.? Would anyone please give me some hints onthat?
>
> Thank you in advance.
>
> Anne
>
>
> The program is this, I have a complicated function and itneeds to operate on some subsets of a dataset many times, depending on thevalues of group.? I simplify the functionand dataset for this example run.
>
> getResult <- function(d) {
>
>? ? ? ?#examplefunction
>
>? ? ? weighted.mean(x=d[,1], w=d[,2])
>
> }
>
>
>
> #example data setup
>
> n=20;
>
> set.seed(1)
>
> g=rep(1:5,each=4)
>
> df=as.data.frame(cbind( sort(rnorm(mean=15,sd=10, n)),runif(n), rbinom(n, 1, 0.4) , g )); df
>
> getResult(df)
>
> i0=c(1,2,4,5,5)
>
> ng= length(unique(g))
>
>
>
> #initiation of result matrix
>
> A=matrix(Inf, ng, ng); A
>
> for(i in 1:ng)
>
> {? ? ? ? ? ? ? cat("i:",i,"")
>
>? ? ? ? ? ? ? ? ?for(jin i0[i]:ng) {
>
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?ok= !is.na(match(g,i:j)); cat("j:",j,"\n");
>
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?A[i,j]=getResult(d=df[ok,])
>
>? ? ? ? ? ? ? ? ?} #endfor (j)
>
> } #end for (i)
>
> Is there an elegant way to remove the for loop here?? I try to make it flat for faster run but Icannot figure out how to subset the observations faster without error to apply the functiongetResult.? Any hint is appreciated.
>
>
>
>
>
> on another note, is there a more elegant way to initiate the list as follows?
>
> mylist=list(); w=rep(4,5)
>
> for (i in 1:5) mylist[[i]]=w[i:5]
>
>
>
>
>? ? ? ? ?[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
	[[alternative HTML version deleted]]


From cristiucana at gmail.com  Wed Oct 14 20:49:30 2015
From: cristiucana at gmail.com (Ana Cristiuc)
Date: Wed, 14 Oct 2015 20:49:30 +0200
Subject: [R] Code translation from R to MATLAB
Message-ID: <CABAjVAJ8V28Zj5EAQi-+HDpdk-cAaRGnh-EmU0-Xsr0w-=vO-A@mail.gmail.com>

Dear Ted,



I have found on Internet your very good comments on R vs MATLAB languages.



I am a beginner in both languages, but unfortunately I have got a task to
translate a huge code from R to MATLAB.



Could you please recommend me some references or advices how to handle the
problems appearing from the differences between languages.



I was trying today to translate the below lines of code from R to MATLAB,
but very unsuccessfully.



Could you please help me by saying, at least, if I have any chances to
translate this R function to a function in  MATLAB or  it will be simpler
to avoid a function body for the initialization.



This is the first function from the attached script. It is the hardest part
of the code:





init <- function(N=3) {

    ## initialize model settings and load data

    ## Globals, side effects:

    ##  sets n.per, N, W, Y, dates, mats



    n.per <<- 12 # monthly data

    N <<- N      # three risk factors



    ## load yield data



    ## cat("loading GSW yield data...\n")

    ## if ('data' %in% dir()) {

    ##     load("data/gsw_data_monthly.RData")  # Y, dates, mats

    ## } else {

    ##     load("../data/gsw_data_monthly.RData")  # Y, dates, mats

    ## }

    ## ##mat.sel <- c(1:12)

    ## ##mat.sel <- c(3:12)  ## one through ten years

    ## mat.sel <- 2+c(1,2,3,4,5,7,10)

    ## Y <- Y[,mat.sel]/100/n.per

    ## mats <- mats[mat.sel]*n.per



    cat("loading Anh Le's yield data...\n")

    if ('data' %in% dir()) {

        load("data/le_data_monthly.RData")  # Y, dates

    } else {

        load("../data/le_data_monthly.RData")  # Y, dates

    }

    ## mats <- c(3,6,12,24,36,48,60,72,84,96,108,120)

    ##mats <- c(12,24,36,48,60,72,84,96,108,120)

    mats <- c(12,24,36,48,60,84,120)

    Y <- Y[,mats]/n.per



    if (dim(Y)[2]!=length(mats)) stop("wrong number of columns in yield
matrix");



    start.sample <- 19900101

    start.date <<- c(1990,1)

    ##start.sample <- 19850101

    ##start.date <<- c(1985,1)

    end.sample <- 20071231



    sel.sample <- dates>=start.sample & dates<=end.sample

    Y <- Y[sel.sample,]  ## change local variable

    dates <- dates[sel.sample]

    cat("sample from", as.character(min(dates)), "to",
as.character(max(dates)), "\n")



    ## first N principal components => pricing factors

    W <<- getW(Y, N)



    ## make local variables global   -- alt:  assign("Y", Y, env=.GlobalEnv)

    Y <<- Y; dates <<- dates; mats <<- mats

}



My understanding is that I can specify this initialization outside of a
function, but I am not sure.



I hope you will have some  free minutes to help me.



Many thanks in advance for your help!



Best regards,



Ana Cristiuc,

From evan.cooch at cornell.edu  Thu Oct 15 01:35:24 2015
From: evan.cooch at cornell.edu (Evan Cooch)
Date: Wed, 14 Oct 2015 19:35:24 -0400
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <561EB44F.8060309@gmail.com>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
	<561EB137.9080304@gmail.com>
	<CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>
	<561EB44F.8060309@gmail.com>
Message-ID: <561EE6BC.9080907@cornell.edu>

A clue --

Working from home, I created an ssh tunnel into my CentOS box, and 
brought up the desktop remotely using VNC. Fire up R in a terminal, and 
*voila*, graphics work fine.

So, if I'm sitting at the CentOS machine, R graphics choke and die. If I 
use a remote desktop approach, graphics fine.

Very strange...

Forgot to add before, here are the 'capabilities' from my R install -- 
X11 and cairo both 'there', so not sure what the problem is.

        jpeg         png        tiff       tcltk         X11 aqua
        TRUE        TRUE        TRUE        TRUE        TRUE FALSE
    http/ftp     sockets      libxml        fifo      cledit iconv
        TRUE        TRUE        TRUE        TRUE        TRUE TRUE
         NLS     profmem       cairo         ICU long.double libcurl
        TRUE       FALSE        TRUE        TRUE        TRUE FALSE

On 10/14/2015 4:00 PM, Evan Cooch wrote:
>
>
> On 10/14/2015 3:51 PM, Thomas Adams wrote:
>> Evan,
>>
>> I have Ubuntu 14.04 and 15.10 at home and have not had problems, but 
>> I don't think I've been using R 3.2.2 ? I'll try this evening.
>
> Indeed - it could be an R-version issue, and not so much the distro. I 
> might, for chuckles, roll back to 3.2.1, and see what happens.
>
>>
>> Tom
>>
>> On Wed, Oct 14, 2015 at 2:47 PM, Evan Cooch <evan.cooch at gmail.com 
>> <mailto:evan.cooch at gmail.com>> wrote:
>>
>>     Tom --
>>
>>     On 10/14/2015 3:35 PM, Thomas Adams wrote:
>>>     Evan,
>>>
>>>     Not that this helps you, but I am using a very similar platform
>>>     and I am having the identical problem. My test simply comes from
>>>     the first help(plot) example. I tried doing some things to
>>>     'correct' the problem and ended up mucking-up my Gnome
>>>     environment. In the process, I was able to get the example to
>>>     display correctly, but as I said, I now have an unusable system.
>>>     I'm not sure this is an R specific problem, but some
>>>     incompatibility with the Centos Gnome environment.
>>>
>>
>>     Thanks very much. I have a couple of Linux Mint 17.x systems as
>>     well -- I'll see if they throw the same problem at me/us.
>>
>>>     Tom
>>>
>>>     On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch
>>>     <evan.cooch at gmail.com> wrote:
>>>
>>>         So, am running 3.2.2 on a Centos 6.xx box. Code executes
>>>         fine, but I'm having a heck of a time with graphics. I don't
>>>         think this is related to R in the broad sense, but how it is
>>>         interacting with graphics on the system. here is a
>>>         description of the problem.
>>>
>>>         1\ something simple:  test <- rnorm(100)
>>>
>>>         2\ try to generate a simple histogram using hist(test)
>>>
>>>         3\ what happens is that a terminal window pops up (as I
>>>         would expect for the graphic), but rather than showing the
>>>         histogram, its essentially a screen-capture of the original
>>>         terminal window in which I ran the script. Said second
>>>         terminal window is not responsive, at all -- can't even
>>>         close it short of opening another shell, and killing the
>>>         process from the CLI.
>>>
>>>         4\ I get the exact same problem even if I try  a simple
>>>         plot.new() -- generate a new terminal window, but with the
>>>         same problem 'attributes' as described above.
>>>
>>>         For what it works, when I fire up gnuplot, terminal type set
>>>         to X11 -- and basic gnuplot graphics (e.g., plot sin(x))
>>>         work perfectly. Other graphics seem to work fine too. Just
>>>         nothing I try to plot using R.
>>>
>>>         Anyone have any ideas as to what to look for/try? Here is
>>>         the output of sessionInfo() -- nothing obvious that I can see.
>>>
>>>         R version 3.2.2 (2015-08-14)
>>>         Platform: x86_64-redhat-linux-gnu (64-bit)
>>>         Running under: CentOS release 6.7 (Final)
>>>
>>>         locale:
>>>          [1] LC_CTYPE=en_US.UTF-8  LC_NUMERIC=C
>>>          [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>>          [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>>>          [7] LC_PAPER=en_US.UTF-8  LC_NAME=C
>>>          [9] LC_ADDRESS=C  LC_TELEPHONE=C
>>>         [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>>         attached base packages:
>>>         [1] stats     graphics  grDevices utils    datasets  methods
>>>         base
>>>
>>>         ______________________________________________
>>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>>         list -- To UNSUBSCRIBE and more, see
>>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>>         PLEASE do read the posting guide
>>>         http://www.R-project.org/posting-guide.html
>>>         and provide commented, minimal, self-contained, reproducible
>>>         code.
>>>
>>>
>>>
>>>
>>>
>>>
>>
>>
>>
>>
>>
>


	[[alternative HTML version deleted]]


From elset_93 at yahoo.com  Wed Oct 14 22:29:56 2015
From: elset_93 at yahoo.com (Sherouk Moawad)
Date: Wed, 14 Oct 2015 20:29:56 +0000 (UTC)
Subject: [R] double summation
References: <1162929840.447951.1444854596176.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1162929840.447951.1444854596176.JavaMail.yahoo@mail.yahoo.com>

?i=02 ?j=01(exp(xi+xj)), i>j if (i>0 and j>0)?  I want to write this summation which has a condition on numerator(j<i)i>0 and j>0I tried on this code
sum(sapply(0:2, function(i){sum(sapply(0:1, function(j){if (i>0&j>0){i>j}{exp(x[i]+x[j])}))}))But it didn't work?Any help please
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Oct 15 06:05:21 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 14 Oct 2015 21:05:21 -0700
Subject: [R] double summation
In-Reply-To: <1162929840.447951.1444854596176.JavaMail.yahoo@mail.yahoo.com>
References: <1162929840.447951.1444854596176.JavaMail.yahoo@mail.yahoo.com>
	<1162929840.447951.1444854596176.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <FC4FDAF6-1BAB-4BF9-8097-2F9C2AF1D4D5@comcast.net>


On Oct 14, 2015, at 1:29 PM, Sherouk Moawad via R-help wrote:

> ?i=02 ?j=01(exp(xi+xj)), i>j if (i>0 and j>0)   I want to write this summation which has a condition on numerator(j<i)i>0 and j>0I tried on this code

That comes across as only barely comprehensible.


> sum(sapply(0:2, function(i){sum(sapply(0:1, function(j){if (i>0&j>0){i>j}{exp(x[i]+x[j])}))}))But it didn't work Any help please
> 	[[alternative HTML version deleted]]

You should learn to post in plain text. This IS a plain text mailing list.

It is generally effective to include Boolean logic in the summand. Try this untested modification:

sum(
    sapply(0:2, function(i){ sum( 
                sapply(0:1, function(j){ (i>0)*(j>0)(i>j)*(exp(x[i]+x[j]) ))))
      )

-- 
David Winsemius
Alameda, CA, USA


From evan.cooch at gmail.com  Wed Oct 14 21:47:03 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 14 Oct 2015 15:47:03 -0400
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
Message-ID: <561EB137.9080304@gmail.com>

Tom --

On 10/14/2015 3:35 PM, Thomas Adams wrote:
> Evan,
>
> Not that this helps you, but I am using a very similar platform and I 
> am having the identical problem. My test simply comes from the first 
> help(plot) example. I tried doing some things to 'correct' the problem 
> and ended up mucking-up my Gnome environment. In the process, I was 
> able to get the example to display correctly, but as I said, I now 
> have an unusable system. I'm not sure this is an R specific problem, 
> but some incompatibility with the Centos Gnome environment.
>

Thanks very much. I have a couple of Linux Mint 17.x systems as well -- 
I'll see if they throw the same problem at me/us.

> Tom
>
> On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch <evan.cooch at gmail.com 
> <mailto:evan.cooch at gmail.com>> wrote:
>
>     So, am running 3.2.2 on a Centos 6.xx box. Code executes fine, but
>     I'm having a heck of a time with graphics. I don't think this is
>     related to R in the broad sense, but how it is interacting with
>     graphics on the system. here is a description of the problem.
>
>     1\ something simple:  test <- rnorm(100)
>
>     2\ try to generate a simple histogram  using hist(test)
>
>     3\ what happens is that a terminal window pops up (as I would
>     expect for the graphic), but rather than showing the histogram,
>     its essentially a screen-capture of the original terminal window
>     in which I ran the script. Said second terminal window is not
>     responsive, at all -- can't even close it short of opening another
>     shell, and killing the process from the CLI.
>
>     4\ I get the exact same problem even if I try  a simple plot.new()
>     -- generate a new terminal window, but with the same problem
>     'attributes' as described above.
>
>     For what it works, when I fire up gnuplot, terminal type set to
>     X11 -- and basic gnuplot graphics (e.g., plot sin(x)) work
>     perfectly. Other graphics seem to work fine too. Just nothing I
>     try to plot using R.
>
>     Anyone have any ideas as to what to look for/try? Here is the
>     output of sessionInfo() -- nothing obvious that I can see.
>
>     R version 3.2.2 (2015-08-14)
>     Platform: x86_64-redhat-linux-gnu (64-bit)
>     Running under: CentOS release 6.7 (Final)
>
>     locale:
>      [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>      [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>      [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>      [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>      [9] LC_ADDRESS=C               LC_TELEPHONE=C
>     [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
>     attached base packages:
>     [1] stats     graphics  grDevices utils     datasets methods base
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>


	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Wed Oct 14 22:00:15 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 14 Oct 2015 16:00:15 -0400
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
	<561EB137.9080304@gmail.com>
	<CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>
Message-ID: <561EB44F.8060309@gmail.com>



On 10/14/2015 3:51 PM, Thomas Adams wrote:
> Evan,
>
> I have Ubuntu 14.04 and 15.10 at home and have not had problems, but I 
> don't think I've been using R 3.2.2 ? I'll try this evening.

Indeed - it could be an R-version issue, and not so much the distro. I 
might, for chuckles, roll back to 3.2.1, and see what happens.

>
> Tom
>
> On Wed, Oct 14, 2015 at 2:47 PM, Evan Cooch <evan.cooch at gmail.com 
> <mailto:evan.cooch at gmail.com>> wrote:
>
>     Tom --
>
>     On 10/14/2015 3:35 PM, Thomas Adams wrote:
>>     Evan,
>>
>>     Not that this helps you, but I am using a very similar platform
>>     and I am having the identical problem. My test simply comes from
>>     the first help(plot) example. I tried doing some things to
>>     'correct' the problem and ended up mucking-up my Gnome
>>     environment. In the process, I was able to get the example to
>>     display correctly, but as I said, I now have an unusable system.
>>     I'm not sure this is an R specific problem, but some
>>     incompatibility with the Centos Gnome environment.
>>
>
>     Thanks very much. I have a couple of Linux Mint 17.x systems as
>     well -- I'll see if they throw the same problem at me/us.
>
>>     Tom
>>
>>     On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch <evan.cooch at gmail.com
>>     <mailto:evan.cooch at gmail.com>> wrote:
>>
>>         So, am running 3.2.2 on a Centos 6.xx box. Code executes
>>         fine, but I'm having a heck of a time with graphics. I don't
>>         think this is related to R in the broad sense, but how it is
>>         interacting with graphics on the system. here is a
>>         description of the problem.
>>
>>         1\ something simple:  test <- rnorm(100)
>>
>>         2\ try to generate a simple histogram using hist(test)
>>
>>         3\ what happens is that a terminal window pops up (as I would
>>         expect for the graphic), but rather than showing the
>>         histogram, its essentially a screen-capture of the original
>>         terminal window in which I ran the script. Said second
>>         terminal window is not responsive, at all -- can't even close
>>         it short of opening another shell, and killing the process
>>         from the CLI.
>>
>>         4\ I get the exact same problem even if I try  a simple
>>         plot.new() -- generate a new terminal window, but with the
>>         same problem 'attributes' as described above.
>>
>>         For what it works, when I fire up gnuplot, terminal type set
>>         to X11 -- and basic gnuplot graphics (e.g., plot sin(x)) work
>>         perfectly. Other graphics seem to work fine too. Just nothing
>>         I try to plot using R.
>>
>>         Anyone have any ideas as to what to look for/try? Here is the
>>         output of sessionInfo() -- nothing obvious that I can see.
>>
>>         R version 3.2.2 (2015-08-14)
>>         Platform: x86_64-redhat-linux-gnu (64-bit)
>>         Running under: CentOS release 6.7 (Final)
>>
>>         locale:
>>          [1] LC_CTYPE=en_US.UTF-8  LC_NUMERIC=C
>>          [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8
>>          [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>>          [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>          [9] LC_ADDRESS=C  LC_TELEPHONE=C
>>         [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>>         attached base packages:
>>         [1] stats     graphics  grDevices utils  datasets  methods base
>>
>>         ______________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing
>>         list -- To UNSUBSCRIBE and more, see
>>         https://stat.ethz.ch/mailman/listinfo/r-help
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/posting-guide.html
>>         and provide commented, minimal, self-contained, reproducible
>>         code.
>>
>>
>>
>>
>>
>>
>
>
>
>
>


	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Oct 15 00:50:19 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 14 Oct 2015 18:50:19 -0400
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <561EB44F.8060309@gmail.com>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
	<561EB137.9080304@gmail.com>
	<CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>
	<561EB44F.8060309@gmail.com>
Message-ID: <561EDC2B.6080402@gmail.com>



On 10/14/2015 4:00 PM, Evan Cooch wrote:
>
>
> On 10/14/2015 3:51 PM, Thomas Adams wrote:
>> Evan,
>>
>> I have Ubuntu 14.04 and 15.10 at home and have not had problems, but 
>> I don't think I've been using R 3.2.2 ? I'll try this evening.
>
> Indeed - it could be an R-version issue, and not so much the distro. I 
> might, for chuckles, roll back to 3.2.1, and see what happens.
>
>>
>> Tom
>>


Tested on a Linux Mint 17.2 system, Cinnamon desktop -- R 3.2.2. 
Graphics work *perfectly*.

Will try rolling back to earlier version of R tomorrow on the CentOS 
6.xx box, to see if something has changed with R that is no longer 
playing nice with X11 as implemented on CentOS -- this wouldn't surprise 
me entirely, since CentOS goes for 'stability', whereas Mint is closer 
to 'bleeding edge'. If R is expecting a more 'current' implementation of 
X11 and associated libs than CentOS has, that would explain the problem.

	[[alternative HTML version deleted]]


From j.para.fernandez at hotmail.com  Thu Oct 15 09:52:56 2015
From: j.para.fernandez at hotmail.com (jpara3)
Date: Thu, 15 Oct 2015 00:52:56 -0700 (PDT)
Subject: [R] Creating a package with specail caracters
Message-ID: <1444895576135-4713615.post@n4.nabble.com>

Hi, 

I want to create my own package with a very simple GUI. The problem is that
I need to use special latin characters, as ?,?,?...

The function i have made is:

funcion<-function(){
tt<-tktoplevel()
tktitle(tt)<-"?GUI de estad?stica"
}


The problem is that when i run this function, instead estad?stica, appears
some strange simbols. How can I convert this to latin1??

Thanks!!!:





-----

Guided Tours Basque Country 

Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.

Travel planners for groups and design of tourist routes across the Basque Country.
--
View this message in context: http://r.789695.n4.nabble.com/Creating-a-package-with-specail-caracters-tp4713615.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Thu Oct 15 11:55:11 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 15 Oct 2015 11:55:11 +0200
Subject: [R] Creating a package with specail caracters
In-Reply-To: <1444895576135-4713615.post@n4.nabble.com>
References: <1444895576135-4713615.post@n4.nabble.com>
Message-ID: <1A967444-F373-474D-AB15-7B8C80FAE56B@gmail.com>


> On 15 Oct 2015, at 09:52 , jpara3 <j.para.fernandez at hotmail.com> wrote:
> 
> Hi, 
> 
> I want to create my own package with a very simple GUI. The problem is that
> I need to use special latin characters, as ?,?,?...
> 
> The function i have made is:
> 
> funcion<-function(){
> tt<-tktoplevel()
> tktitle(tt)<-"?GUI de estad?stica"
> }
> 
> 
> The problem is that when i run this function, instead estad?stica, appears
> some strange simbols. How can I convert this to latin1??
> 
> Thanks!!!:
> 
> 

I think it is the other way around: Tcl/Tk speaks UTF-8, so if you run R in a Latin-1 locale, you need to translate the strings to UTF-8. iconv() is your friend.

I'm a bit puzzled, though. The underlying C function RTcl_ObjFromCharVector tries to be smart about encodings, and the only way I can reproduce anything looking like your issue is if I do sneaky things like 

> x <- iconv("?GUI de estad?stica", to="latin1")
> Encoding(x) <- "UTF8"
> tktitle(tt)<-x
> x
[1] "\xa1GUI de estad\xedstica"

-pd

BTW: Notice that the Nabble interface is closing down. You need to use the mailing list directly.

> View this message in context: http://r.789695.n4.nabble.com/Creating-a-package-with-specail-caracters-tp4713615.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j.para.fernandez at hotmail.com  Thu Oct 15 11:59:04 2015
From: j.para.fernandez at hotmail.com (jpara3)
Date: Thu, 15 Oct 2015 02:59:04 -0700 (PDT)
Subject: [R] Creating a package with specail caracters
In-Reply-To: <1A967444-F373-474D-AB15-7B8C80FAE56B@gmail.com>
References: <1444895576135-4713615.post@n4.nabble.com>
	<1A967444-F373-474D-AB15-7B8C80FAE56B@gmail.com>
Message-ID: <1444903144678-4713618.post@n4.nabble.com>

Hi Peter, 

Thanks for your help, but the problem is still happening. 

I have done this:

funcion<-function(){

  tt<-tktoplevel(bg="white")
  x<-iconv("?GUI estad?stica",to="latin1")
  Encoding(x) <- "UTF8"
  tktitle(tt)<-x

}





-----

Guided Tours Basque Country 

Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.

Travel planners for groups and design of tourist routes across the Basque Country.
--
View this message in context: http://r.789695.n4.nabble.com/Creating-a-package-with-specail-caracters-tp4713615p4713618.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Thu Oct 15 13:13:31 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 15 Oct 2015 13:13:31 +0200
Subject: [R] Creating a package with specail caracters
In-Reply-To: <1444903144678-4713618.post@n4.nabble.com>
References: <1444895576135-4713615.post@n4.nabble.com>
	<1A967444-F373-474D-AB15-7B8C80FAE56B@gmail.com>
	<1444903144678-4713618.post@n4.nabble.com>
Message-ID: <C2C1E5D5-3E84-461B-A02F-836F446007FB@gmail.com>

Read more carefully! That is what I did to _reproduce_ your problem.

Try 

tktitle(tt) <-  iconv("?GUI estad?stica", to="UTF8", from="latin1")

or maybe from="", or from=<something else>, depending on how confused your system is about the current encoding, 


> On 15 Oct 2015, at 11:59 , jpara3 <j.para.fernandez at hotmail.com> wrote:
> 
> Hi Peter, 
> 
> Thanks for your help, but the problem is still happening. 
> 
> I have done this:
> 
> funcion<-function(){
> 
>  tt<-tktoplevel(bg="white")
>  x<-iconv("?GUI estad?stica",to="latin1")
>  Encoding(x) <- "UTF8"
>  tktitle(tt)<-x
> 
> }
> 
> 
> 
> 
> 
> -----
> 
> Guided Tours Basque Country 
> 
> Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.
> 
> Travel planners for groups and design of tourist routes across the Basque Country.
> --
> View this message in context: http://r.789695.n4.nabble.com/Creating-a-package-with-specail-caracters-tp4713615p4713618.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j.para.fernandez at hotmail.com  Thu Oct 15 13:45:44 2015
From: j.para.fernandez at hotmail.com (jpara3)
Date: Thu, 15 Oct 2015 04:45:44 -0700 (PDT)
Subject: [R] Creating a package with specail caracters
In-Reply-To: <C2C1E5D5-3E84-461B-A02F-836F446007FB@gmail.com>
References: <1444895576135-4713615.post@n4.nabble.com>
	<1A967444-F373-474D-AB15-7B8C80FAE56B@gmail.com>
	<1444903144678-4713618.post@n4.nabble.com>
	<C2C1E5D5-3E84-461B-A02F-836F446007FB@gmail.com>
Message-ID: <1444909544149-4713620.post@n4.nabble.com>

I have tried:

tktitle(tt) <- iconv("?GUI estad?stica", from="latin1",to="UTF8")
tktitle(tt) <- iconv("?GUI estad?stica", from="",to="UTF8")
tktitle(tt) <- iconv("?GUI estad?stica", to="UTF8")


But there are no good results. 

Can maybe exist a code to insert after the special characters, as \?i for ??

Thanks 




-----

Guided Tours Basque Country 

Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.

Travel planners for groups and design of tourist routes across the Basque Country.
--
View this message in context: http://r.789695.n4.nabble.com/Creating-a-package-with-specail-caracters-tp4713615p4713620.html
Sent from the R help mailing list archive at Nabble.com.


From b.h.mevik at usit.uio.no  Thu Oct 15 14:13:07 2015
From: b.h.mevik at usit.uio.no (=?utf-8?Q?Bj=C3=B8rn-Helge_Mevik?=)
Date: Thu, 15 Oct 2015 14:13:07 +0200
Subject: [R] Installing R 3.2.2 on machine with old libcurl
Message-ID: <s3s4mhsfhyk.fsf@slagelg.uio.no>

We have to install R 3.2.2 on machines with too old libcurl to be able
to use https when installing packages, etc.

When a user tries to use install.packages() (with the default value of
the "repos" option), she is presented with a list of https-repos, which
is not very useful.  She also gets an error message

Error in download.file(url, destfile = f, quiet = TRUE) : 
  unsupported URL scheme

We have put

local({
    options(useHTTPS = FALSE)
})

into the Rprofile.site file, and after that, the user gets a list of
http repos, so she will be able to install packages.  But the error
message is still displayed, which can be confusing.  Is there a way
around this problem?

Also, perhaps the useHTTPS option should default to FALSE if the libcurl
capability is FALSE?


-- 
Regards,
Bj?rn-Helge Mevik


From Rainer at krugs.de  Thu Oct 15 14:48:03 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 15 Oct 2015 14:48:03 +0200
Subject: [R] Latin Hyper cube with condition col1+ col2 < x
Message-ID: <m28u74fgcc.fsf@krugs.de>

Hi

I need a Latin Hypercube with the following conditions:

0 < x[,"a"] < 1
0 < x[,"b"] < 1
0 < x[,"c"] < 1

but also

x[,"a"] + x[,"b"] < h

The first three are easy:

--8<---------------cut here---------------start------------->8---
n <- 1000

lhc <- lhs::randomLHS(n=n, k=3
colnames(lhc) <- c("a", "b", "c")

x <- lhc
--8<---------------cut here---------------end--------------->8---

Now the last condition:

I tried

--8<---------------cut here---------------start------------->8---
h <- 28
x[,"a"] <- x[,"a"] / 2
x[,"b"] <- x[,"b"] / 2
--8<---------------cut here---------------end--------------->8---

But this obviously reduces the individual ranges.

Using the rowSum as in 
https://stat.ethz.ch/pipermail/r-help/2013-October/361263.html

makes the sum of the variables also to 2.

So how can I create a Latin Hypercube which fulfills the conditions?

Rainer

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151015/01121830/attachment.bin>

From boris.steipe at utoronto.ca  Thu Oct 15 15:19:42 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 15 Oct 2015 09:19:42 -0400
Subject: [R] Latin Hyper cube with condition col1+ col2 < x
In-Reply-To: <m28u74fgcc.fsf@krugs.de>
References: <m28u74fgcc.fsf@krugs.de>
Message-ID: <42E74D21-3197-4EC7-BF44-A8764A049E71@utoronto.ca>

I don't think the problem is well defined. Otherwise you could just pick very small numbers from a range that is guaranteed to keep the sum < h. 


B.

On Oct 15, 2015, at 8:48 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> Hi
> 
> I need a Latin Hypercube with the following conditions:
> 
> 0 < x[,"a"] < 1
> 0 < x[,"b"] < 1
> 0 < x[,"c"] < 1
> 
> but also
> 
> x[,"a"] + x[,"b"] < h
> 
> The first three are easy:
> 
> --8<---------------cut here---------------start------------->8---
> n <- 1000
> 
> lhc <- lhs::randomLHS(n=n, k=3
> colnames(lhc) <- c("a", "b", "c")
> 
> x <- lhc
> --8<---------------cut here---------------end--------------->8---
> 
> Now the last condition:
> 
> I tried
> 
> --8<---------------cut here---------------start------------->8---
> h <- 28
> x[,"a"] <- x[,"a"] / 2
> x[,"b"] <- x[,"b"] / 2
> --8<---------------cut here---------------end--------------->8---
> 
> But this obviously reduces the individual ranges.
> 
> Using the rowSum as in 
> https://stat.ethz.ch/pipermail/r-help/2013-October/361263.html
> 
> makes the sum of the variables also to 2.
> 
> So how can I create a Latin Hypercube which fulfills the conditions?
> 
> Rainer
> 
> -- 
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
> 
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
> 
> Fax (D):    +49 - (0)3 21 21 25 22 44
> 
> email:      Rainer at krugs.de
> 
> Skype:      RMkrug
> 
> PGP: 0x0F52F982
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Rainer at krugs.de  Thu Oct 15 15:27:03 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 15 Oct 2015 15:27:03 +0200
Subject: [R] Latin Hyper cube with condition col1+ col2 < x
In-Reply-To: <42E74D21-3197-4EC7-BF44-A8764A049E71@utoronto.ca> (Boris
	Steipe's message of "Thu, 15 Oct 2015 09:19:42 -0400")
References: <m28u74fgcc.fsf@krugs.de>
	<42E74D21-3197-4EC7-BF44-A8764A049E71@utoronto.ca>
Message-ID: <m24mhsfejc.fsf@krugs.de>

Boris Steipe <boris.steipe at utoronto.ca> writes:

> I don't think the problem is well defined. Otherwise you could just
> pick very small numbers from a range that is guaranteed to keep the
> sum < h.

What further information is missing? That the variables should be
covering the whole range from 0 to 1?

OK - forgotten to state that h <- 1.

This is for a sensitivity analysis which I want to conduct on a complex
function.

Rainer


>
>
> B.
>
> On Oct 15, 2015, at 8:48 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>
>> Hi
>> 
>> I need a Latin Hypercube with the following conditions:
>> 
>> 0 < x[,"a"] < 1
>> 0 < x[,"b"] < 1
>> 0 < x[,"c"] < 1
>> 
>> but also
>> 
>> x[,"a"] + x[,"b"] < h
>> 
>> The first three are easy:
>> 
>> --8<---------------cut here---------------start------------->8---
>> n <- 1000
>> 
>> lhc <- lhs::randomLHS(n=n, k=3
>> colnames(lhc) <- c("a", "b", "c")
>> 
>> x <- lhc
>> --8<---------------cut here---------------end--------------->8---
>> 
>> Now the last condition:
>> 
>> I tried
>> 
>> --8<---------------cut here---------------start------------->8---
>> h <- 28
>> x[,"a"] <- x[,"a"] / 2
>> x[,"b"] <- x[,"b"] / 2
>> --8<---------------cut here---------------end--------------->8---
>> 
>> But this obviously reduces the individual ranges.
>> 
>> Using the rowSum as in 
>> https://stat.ethz.ch/pipermail/r-help/2013-October/361263.html
>> 
>> makes the sum of the variables also to 2.
>> 
>> So how can I create a Latin Hypercube which fulfills the conditions?
>> 
>> Rainer
>> 
>> -- 
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>> 
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>> 
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>> 
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>> 
>> email:      Rainer at krugs.de
>> 
>> Skype:      RMkrug
>> 
>> PGP: 0x0F52F982
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151015/ed24b94b/attachment.bin>

From boris.steipe at utoronto.ca  Thu Oct 15 15:52:20 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 15 Oct 2015 09:52:20 -0400
Subject: [R] Latin Hyper cube with condition col1+ col2 < x
In-Reply-To: <m24mhsfejc.fsf@krugs.de>
References: <m28u74fgcc.fsf@krugs.de>
	<42E74D21-3197-4EC7-BF44-A8764A049E71@utoronto.ca>
	<m24mhsfejc.fsf@krugs.de>
Message-ID: <9CC25768-7B19-4AF2-9F6D-5EC76DF6E145@utoronto.ca>

If you need h equal to 1, then replace any non-zero initial value of x[,b] with 1-x[,a].
But if you really need "less than", you'll need to specify what your desired distribution of h - x[,"a"] + x[,"b"] should look like.

No?


B.



On Oct 15, 2015, at 9:27 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> Boris Steipe <boris.steipe at utoronto.ca> writes:
> 
>> I don't think the problem is well defined. Otherwise you could just
>> pick very small numbers from a range that is guaranteed to keep the
>> sum < h.
> 
> What further information is missing? That the variables should be
> covering the whole range from 0 to 1?
> 
> OK - forgotten to state that h <- 1.
> 
> This is for a sensitivity analysis which I want to conduct on a complex
> function.
> 
> Rainer
> 
> 
>> 
>> 
>> B.
>> 
>> On Oct 15, 2015, at 8:48 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> 
>>> Hi
>>> 
>>> I need a Latin Hypercube with the following conditions:
>>> 
>>> 0 < x[,"a"] < 1
>>> 0 < x[,"b"] < 1
>>> 0 < x[,"c"] < 1
>>> 
>>> but also
>>> 
>>> x[,"a"] + x[,"b"] < h
>>> 
>>> The first three are easy:
>>> 
>>> --8<---------------cut here---------------start------------->8---
>>> n <- 1000
>>> 
>>> lhc <- lhs::randomLHS(n=n, k=3
>>> colnames(lhc) <- c("a", "b", "c")
>>> 
>>> x <- lhc
>>> --8<---------------cut here---------------end--------------->8---
>>> 
>>> Now the last condition:
>>> 
>>> I tried
>>> 
>>> --8<---------------cut here---------------start------------->8---
>>> h <- 28
>>> x[,"a"] <- x[,"a"] / 2
>>> x[,"b"] <- x[,"b"] / 2
>>> --8<---------------cut here---------------end--------------->8---
>>> 
>>> But this obviously reduces the individual ranges.
>>> 
>>> Using the rowSum as in 
>>> https://stat.ethz.ch/pipermail/r-help/2013-October/361263.html
>>> 
>>> makes the sum of the variables also to 2.
>>> 
>>> So how can I create a Latin Hypercube which fulfills the conditions?
>>> 
>>> Rainer
>>> 
>>> -- 
>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>> 
>>> Centre of Excellence for Invasion Biology
>>> Stellenbosch University
>>> South Africa
>>> 
>>> Tel :       +33 - (0)9 53 10 27 44
>>> Cell:       +33 - (0)6 85 62 59 98
>>> Fax :       +33 - (0)9 58 10 27 44
>>> 
>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>> 
>>> email:      Rainer at krugs.de
>>> 
>>> Skype:      RMkrug
>>> 
>>> PGP: 0x0F52F982
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
> 
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
> 
> Fax (D):    +49 - (0)3 21 21 25 22 44
> 
> email:      Rainer at krugs.de
> 
> Skype:      RMkrug
> 
> PGP: 0x0F52F982


From boris.steipe at utoronto.ca  Thu Oct 15 16:38:24 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 15 Oct 2015 10:38:24 -0400
Subject: [R] Latin Hyper cube with condition col1+ col2 < x
In-Reply-To: <9CC25768-7B19-4AF2-9F6D-5EC76DF6E145@utoronto.ca>
References: <m28u74fgcc.fsf@krugs.de>
	<42E74D21-3197-4EC7-BF44-A8764A049E71@utoronto.ca>
	<m24mhsfejc.fsf@krugs.de>
	<9CC25768-7B19-4AF2-9F6D-5EC76DF6E145@utoronto.ca>
Message-ID: <D68EB179-EE87-438D-9F81-FCCA6D0F9ECD@utoronto.ca>

Sorry - two typos coorected:

If you need x[,"a"] + x[,"b"] equal to 1, then replace any non-zero initial value of x[,b] with 1-x[,a].
But if you really need "less than" h, you'll need to specify what your desired distribution of h - (x[,"a"] + x[,"b"]) should look like.


On Oct 15, 2015, at 9:52 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> If you need h equal to 1, then replace any non-zero initial value of x[,b] with 1-x[,a].
> But if you really need "less than", you'll need to specify what your desired distribution of h - x[,"a"] + x[,"b"] should look like.
> 
> No?
> 
> 
> B.
> 
> 
> 
> On Oct 15, 2015, at 9:27 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> 
>> Boris Steipe <boris.steipe at utoronto.ca> writes:
>> 
>>> I don't think the problem is well defined. Otherwise you could just
>>> pick very small numbers from a range that is guaranteed to keep the
>>> sum < h.
>> 
>> What further information is missing? That the variables should be
>> covering the whole range from 0 to 1?
>> 
>> OK - forgotten to state that h <- 1.
>> 
>> This is for a sensitivity analysis which I want to conduct on a complex
>> function.
>> 
>> Rainer
>> 
>> 
>>> 
>>> 
>>> B.
>>> 
>>> On Oct 15, 2015, at 8:48 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>> 
>>>> Hi
>>>> 
>>>> I need a Latin Hypercube with the following conditions:
>>>> 
>>>> 0 < x[,"a"] < 1
>>>> 0 < x[,"b"] < 1
>>>> 0 < x[,"c"] < 1
>>>> 
>>>> but also
>>>> 
>>>> x[,"a"] + x[,"b"] < h
>>>> 
>>>> The first three are easy:
>>>> 
>>>> --8<---------------cut here---------------start------------->8---
>>>> n <- 1000
>>>> 
>>>> lhc <- lhs::randomLHS(n=n, k=3
>>>> colnames(lhc) <- c("a", "b", "c")
>>>> 
>>>> x <- lhc
>>>> --8<---------------cut here---------------end--------------->8---
>>>> 
>>>> Now the last condition:
>>>> 
>>>> I tried
>>>> 
>>>> --8<---------------cut here---------------start------------->8---
>>>> h <- 28
>>>> x[,"a"] <- x[,"a"] / 2
>>>> x[,"b"] <- x[,"b"] / 2
>>>> --8<---------------cut here---------------end--------------->8---
>>>> 
>>>> But this obviously reduces the individual ranges.
>>>> 
>>>> Using the rowSum as in 
>>>> https://stat.ethz.ch/pipermail/r-help/2013-October/361263.html
>>>> 
>>>> makes the sum of the variables also to 2.
>>>> 
>>>> So how can I create a Latin Hypercube which fulfills the conditions?
>>>> 
>>>> Rainer
>>>> 
>>>> -- 
>>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>>> 
>>>> Centre of Excellence for Invasion Biology
>>>> Stellenbosch University
>>>> South Africa
>>>> 
>>>> Tel :       +33 - (0)9 53 10 27 44
>>>> Cell:       +33 - (0)6 85 62 59 98
>>>> Fax :       +33 - (0)9 58 10 27 44
>>>> 
>>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>>> 
>>>> email:      Rainer at krugs.de
>>>> 
>>>> Skype:      RMkrug
>>>> 
>>>> PGP: 0x0F52F982
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> -- 
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>> 
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>> 
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>> 
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>> 
>> email:      Rainer at krugs.de
>> 
>> Skype:      RMkrug
>> 
>> PGP: 0x0F52F982
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marammagdysalem at gmail.com  Thu Oct 15 16:45:29 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Thu, 15 Oct 2015 16:45:29 +0200
Subject: [R] Error in rep.int() invalid 'times' value
Message-ID: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>

Dear All,

I'm trying to do a simple task (which is in fact a tiny part of a larger
code).

I want to create a matrix, D, each of its columns is a sequence from 0 to
(n-m), by 1. Then, using D, I want to create another matrix ED, whose rows
represent all the possible combinations of the elements of the columns of
D. Then from ED, I'll select only the rows whose sum is less than or equal
to (n-m), which will be called the matrix s. I used the following code:

> n=5
> m=3
> D<-matrix(0,nrow=n-m+1,ncol=m-1)
> for (i in 1:m-1)
+  {
+ D[,i]<-seq(0,n-m,1)
+  }
> ED <- do.call(`expand.grid`,as.data.frame(D))
> ED<-as.matrix(ED)

> lk<-which(rowSums(ED)<=(n-m))

> s<-ED[lk,]


This works perfectly well. But for rather larger values of n and m (which
are not so large actually), the number of all possible combinations of the
columns of D gets extremely large giving me this error (for n=25, m=15):

> ED <- do.call(`expand.grid`,as.data.frame(D))
Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
  invalid 'times' value
In addition: Warning message:
In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
  NAs introduced by coercion to integer range


Any help or suggestions will be greatly appreciated.

Thanks,

Maram Salem

	[[alternative HTML version deleted]]


From wiebke.ullmann at uni-potsdam.de  Thu Oct 15 13:07:01 2015
From: wiebke.ullmann at uni-potsdam.de (Wiebke Ullmann)
Date: Thu, 15 Oct 2015 11:07:01 +0000
Subject: [R] create zoo object within a for loop
Message-ID: <COL130-W4D27788ED362B922D2627BA3E0@phx.gbl>

Dear everyone.

I have a data frame with relocation data of several animals

>head(data)



 
  
                            timestamp
  
  
  individual
  
  
  easting
  
  
  northing
  
 
 
  
  25.03.2014
  07:00
  
  
  animal1
  
  
  410712.5
  
  
  5913542
  
 
 
  
  25.03.2014
  08:00
  
  
  animal1
  
  
  410716.8
  
  
  5913536
  
 
 
  
  25.03.2014
  12:00
  
  
  animal1
  
  
  410717.9
  
  
  5913538
  
 
 
  
  25.03.2014
  17:00
  
  
  animal1
  
  
  410814.2
  
  
  5913827
  
 
 
  
  25.03.2014
  18:00
  
  
  animal1
  
  
  410577.2
  
  
  5912917
  
 
 
  
  25.03.2014
  19:00
  
  
  animal1
  
  
  410188.2
  
  
  5913556
  
 
 
  
  25.03.2014
  20:00
  
  
  animal1
  
  
  410413.8
  
  
  5913581
  
 
 
  
  25.03.2014
  21:00
  
  
  animal1
  
  
  409929.5
  
  
  5913376
  
 
 
  
  25.03.2014
  22:00
  
  
  animal1
  
  
  410007.5
  
  
  5913425
  
 
 
  
  25.03.2014
  07:00
  
  
  animal2
  
  
  410712.5
  
  
  5913542
  
 
 
  
  25.03.2014
  08:00
  
  
  animal2
  
  
  410716.8
  
  
  5913536
  
 
 
  
  25.03.2014
  12:00
  
  
  animal2
  
  
  410717.9
  
  
  5913538
  
 
 
  
  25.03.2014
  17:00
  
  
  animal2
  
  
  410814.2
  
  
  5913827
  
 
 
  
  25.03.2014
  18:00
  
  
  animal2
  
  
  410577.2
  
  
  5912917
  
 
 
  
  25.03.2014
  19:00
  
  
  animal2
  
  
  410188.2
  
  
  5913556
  
 
 
  
  25.03.2014
  20:00
  
  
  animal2
  
  
  410413.8
  
  
  5913581
  
 
 
  
  25.03.2014
  21:00
  
  
  animal2
  
  
  409929.5
  
  
  5913376
  
 
 
  
  25.03.2014
  22:00
  
  
  animal2
  
  
  410007.5
  
  
  5913425
  
 
 
  
  26.03.2014
  08:00
  
  
  animal3
  
  
  410546.3
  
  
  5913590
  
 
 
  
  26.03.2014
  09:00
  
  
  animal3
  
  
  410668.3
  
  
  5913467
  
 
 
  
  26.03.2014
  10:00
  
  
  animal3
  
  
  410665.3
  
  
  5913556
  
 
 
  
  26.03.2014
  11:00
  
  
  animal3
  
  
  410652.9
  
  
  5913450
  
 
 
  
  26.03.2014
  12:00
  
  
  animal3
  
  
  410649.4
  
  
  5913464
  
 



Some  hours in the timestamp are missing. I would like to fill the timestamp with the missing hours and the other variables with the last occuring information. It should look like this:




 
  
  timestamp
  
  
  individual
  
  
  easting
  
  
  northing
  
 
 
  
  25.03.2014
  07:00
  
  
  animal1
  
  
  410712.5
  
  
  5913542
  
 
 
  
  25.03.2014
  08:00
  
  
  animal1
  
  
  410716.8
  
  
  5913536
  
 
 
  
  25.03.2014
  09:00
  
  
  animal1
  
  
  410716.8
  
  
  5913536
  
 
 
  
  25.03.2014
  10:00
  
  
  animal1
  
  
  410716.8
  
  
  5913536
  
 
 
  
  25.03.2014
  11:00
  
  
  animal1
  
  
  410716.8
  
  
  5913536
  
 
 
  
  25.03.2014
  12:00
  
  
  animal1
  
  
  410717.9
  
  
  5913538
  
 


 ...


I know how to do this with a data frame that only includes the information of one animal. I used an index in zoo:

>animal1$time <- strptime(animal1$timestamp, format="%Y-%m-%d %H:%M:%S")
>animal1$time <- as.POSIXct(format(round(animal1$time, units="hours"), 
                                         format="%Y-%m-%d %H:%M"))
>animal1.zoo  <- zoo(animal1[,-5],animal1[,5]) #set Index
>animal1m     <- merge(animal1.zoo,
                       zoo(,seq(animal1[1,5],animal1[length(animal1$timestamp),5],by="hour")), 
                           all=TRUE)

And filled the other variables with na.locf.

But I do not know how to do this in one go for all the animals. I would like to use a for loop or lappy for lists.
I would be very glad if you could help me out. Thank you very much in advance.

Cheers,
Vivi
 		 	   		  
	[[alternative HTML version deleted]]


From bhawanasahu742 at gmail.com  Thu Oct 15 13:51:10 2015
From: bhawanasahu742 at gmail.com (Bhawana Sahu)
Date: Thu, 15 Oct 2015 17:21:10 +0530
Subject: [R] Problem in SVM model generation
Message-ID: <CACVT7p9QSYk1y9e+5JGntTH_2aNkwKNtLg9H9LW0Jq+xTqU4fg@mail.gmail.com>

 I am using R in my project for analysis of data, and I have generated SVM
model using kernlab package with the dataset (3000 rows and 281 columns).
Now I want to generate this model for dataset containing 8000 rows and 281
column, but here I am getting an error saying that "cannot allocate vector
of size 2.4 gb"

Earlier I was running this model on system with 4GB RAM, now I tried this
on the system having RAM size of 64 gb, I tried all possible way to
increase memory limit of R, and virtual memory, but problem persist.

Please suggest me what can be the issue with this, why am I getting this
error, Is there any limitation of this package.

Thank you

	[[alternative HTML version deleted]]


From from.d.putto at gmail.com  Thu Oct 15 17:22:29 2015
From: from.d.putto at gmail.com (Sheila the angel)
Date: Thu, 15 Oct 2015 17:22:29 +0200
Subject: [R] processing time line by line
Message-ID: <CAFinXcQRKBhJ4You_5h6YjN6iv6sRgsVOCuDkD0jNgP+hFW4kw@mail.gmail.com>

Hello All,
I am looking for any package/function which can give processing time for
each line of a given function. I came through the package "profr" but don't
know how to find line number.
Any help will be appreciated.
Thanks

--
Sheila

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Thu Oct 15 17:35:15 2015
From: cadeb at usgs.gov (Cade, Brian)
Date: Thu, 15 Oct 2015 09:35:15 -0600
Subject: [R] algorithmic method quantile regression
In-Reply-To: <AEB16B1613D44C4793A7E6B6986B7A120100549C56@EX10-LIVE-MBN1.ad.kent.ac.uk>
References: <493824fd8e11445682b67a1bf5eb1cc8@CITESHT2.ad.uillinois.edu>
	<28372756-6544-4956-AA45-61F62FCACAA4@illinois.edu>
	<AEB16B1613D44C4793A7E6B6986B7A120100549C56@EX10-LIVE-MBN1.ad.kent.ac.uk>
Message-ID: <CAM5M9BTXHMNjJKXsZYwcYK27JQ=bpzrFmu1dexEo_pKPPP+ySA@mail.gmail.com>

>From ?rq.fit.pfn I see:

Details:

     Preprocessing algorithm to reduce the effective sample size for QR
     problems with (plausibly) iid samples.  The preprocessing relies
     on subsampling of the original data, so situations in which the
     observations are not plausibly iid, are likely to cause problems.
     The tolerance eps may be relaxed somewhat.

And from 1 in the Quantreg FAQ that Roger indicated there is:

>From ?rq.fit.fn:

   eps: tolerance parameter for convergence.  In cases of multiple
          optimal solutions there may be some discrepancy between
          solutions produced by method '"fn"' and method '"br"'.  This
          is due to the fact that '"fn"' tends to converge to a point
          near the centroid of the solution set, while '"br"' stops at
          a vertex of the set.



So it sounds like the pfn version of quantile regression estimates might
differ because it is intended for independent identically distributed data
(think homogeneous), it involves subsampling of the data set, and
convergence criteria are slightly different for fn and pfn than for the br
(standard Barrodale and Roberts simplex linear program) algorithm.  All
conditions that could lead to different estimates.  My recommendation for
the sample sizes you are considering is to stick with the Barrodale and
Roberts algorithm as it is the best understood, most reliable procedure.

Brian


Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Wed, Oct 14, 2015 at 3:03 PM, T.Riedle <tr206 at kent.ac.uk> wrote:

> The fn and br methods return the same results but the results provided by
> pfn differ. I do not find an explanation for this observation in the papers
> on quantile regression. Therefore my question.
>
> -----Original Message-----
> From: Roger Koenker [mailto:rkoenker at illinois.edu]
> Sent: 14 October 2015 22:33
> To: T.Riedle
> Cc: r-help at r-project.org
> Subject: Re: [R] algorithmic method quantile regression
>
> Did you read item 1 in the quantreg FAQ()?
>
>
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
>
> > On Oct 14, 2015, at 2:56 PM, T.Riedle <tr206 at kent.ac.uk> wrote:
> >
> > Greetings R Community,
> > I am trying to run a quantile regression using the quantreg package. My
> regression includes 7 independent variables with approx. 800 daily
> observations each. Thus, I think that the Barrodale and Roberts algorithm
> should do the trick. However, the Frisch-Newton after preprocessing returns
> different results and more significant coefficients than the br method.
> Which algorithmic method should I use now? Do the results mean that the
> Frisch-Newton after preprocessing dominates the br method?
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Thu Oct 15 17:38:17 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 15 Oct 2015 17:38:17 +0200
Subject: [R] Latin Hyper cube with condition col1+ col2 < x
In-Reply-To: <D68EB179-EE87-438D-9F81-FCCA6D0F9ECD@utoronto.ca> (Boris
	Steipe's message of "Thu, 15 Oct 2015 10:38:24 -0400")
References: <m28u74fgcc.fsf@krugs.de>
	<42E74D21-3197-4EC7-BF44-A8764A049E71@utoronto.ca>
	<m24mhsfejc.fsf@krugs.de>
	<9CC25768-7B19-4AF2-9F6D-5EC76DF6E145@utoronto.ca>
	<D68EB179-EE87-438D-9F81-FCCA6D0F9ECD@utoronto.ca>
Message-ID: <m2zizkdtw6.fsf@krugs.de>

Boris Steipe <boris.steipe at utoronto.ca> writes:

> Sorry - two typos coorected:
>
> If you need x[,"a"] + x[,"b"] equal to 1, then replace any non-zero initial value of x[,b] with 1-x[,a].
> But if you really need "less than" h, you'll need to specify what your
> desired distribution of h - (x[,"a"] + x[,"b"]) should look like.

I think I get your point. I am thinking of adding an additional variable
to the x Latin Hypercube which I will than use as x[,"a] + x[,"b"] and I
will use that one as the distribution.

I think that will work.

Thanks,

Rainer

>
>
> On Oct 15, 2015, at 9:52 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>
>> If you need h equal to 1, then replace any non-zero initial value of x[,b] with 1-x[,a].
>> But if you really need "less than", you'll need to specify what your
>> desired distribution of h - x[,"a"] + x[,"b"] should look like.
>> 
>> No?
>> 
>> 
>> B.
>> 
>> 
>> 
>> On Oct 15, 2015, at 9:27 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>> 
>>> Boris Steipe <boris.steipe at utoronto.ca> writes:
>>> 
>>>> I don't think the problem is well defined. Otherwise you could just
>>>> pick very small numbers from a range that is guaranteed to keep the
>>>> sum < h.
>>> 
>>> What further information is missing? That the variables should be
>>> covering the whole range from 0 to 1?
>>> 
>>> OK - forgotten to state that h <- 1.
>>> 
>>> This is for a sensitivity analysis which I want to conduct on a complex
>>> function.
>>> 
>>> Rainer
>>> 
>>> 
>>>> 
>>>> 
>>>> B.
>>>> 
>>>> On Oct 15, 2015, at 8:48 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>>> 
>>>>> Hi
>>>>> 
>>>>> I need a Latin Hypercube with the following conditions:
>>>>> 
>>>>> 0 < x[,"a"] < 1
>>>>> 0 < x[,"b"] < 1
>>>>> 0 < x[,"c"] < 1
>>>>> 
>>>>> but also
>>>>> 
>>>>> x[,"a"] + x[,"b"] < h
>>>>> 
>>>>> The first three are easy:
>>>>> 
>>>>> --8<---------------cut here---------------start------------->8---
>>>>> n <- 1000
>>>>> 
>>>>> lhc <- lhs::randomLHS(n=n, k=3
>>>>> colnames(lhc) <- c("a", "b", "c")
>>>>> 
>>>>> x <- lhc
>>>>> --8<---------------cut here---------------end--------------->8---
>>>>> 
>>>>> Now the last condition:
>>>>> 
>>>>> I tried
>>>>> 
>>>>> --8<---------------cut here---------------start------------->8---
>>>>> h <- 28
>>>>> x[,"a"] <- x[,"a"] / 2
>>>>> x[,"b"] <- x[,"b"] / 2
>>>>> --8<---------------cut here---------------end--------------->8---
>>>>> 
>>>>> But this obviously reduces the individual ranges.
>>>>> 
>>>>> Using the rowSum as in 
>>>>> https://stat.ethz.ch/pipermail/r-help/2013-October/361263.html
>>>>> 
>>>>> makes the sum of the variables also to 2.
>>>>> 
>>>>> So how can I create a Latin Hypercube which fulfills the conditions?
>>>>> 
>>>>> Rainer
>>>>> 
>>>>> -- 
>>>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>>>> 
>>>>> Centre of Excellence for Invasion Biology
>>>>> Stellenbosch University
>>>>> South Africa
>>>>> 
>>>>> Tel :       +33 - (0)9 53 10 27 44
>>>>> Cell:       +33 - (0)6 85 62 59 98
>>>>> Fax :       +33 - (0)9 58 10 27 44
>>>>> 
>>>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>>>> 
>>>>> email:      Rainer at krugs.de
>>>>> 
>>>>> Skype:      RMkrug
>>>>> 
>>>>> PGP: 0x0F52F982
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> -- 
>>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>>> 
>>> Centre of Excellence for Invasion Biology
>>> Stellenbosch University
>>> South Africa
>>> 
>>> Tel :       +33 - (0)9 53 10 27 44
>>> Cell:       +33 - (0)6 85 62 59 98
>>> Fax :       +33 - (0)9 58 10 27 44
>>> 
>>> Fax (D):    +49 - (0)3 21 21 25 22 44
>>> 
>>> email:      Rainer at krugs.de
>>> 
>>> Skype:      RMkrug
>>> 
>>> PGP: 0x0F52F982
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 454 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151015/431caec4/attachment.bin>

From wdunlap at tibco.com  Thu Oct 15 17:52:48 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Oct 2015 08:52:48 -0700
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
Message-ID: <CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>

Doing enumerative combinatorics with rejection methods rarely
works well. Try mapping your problem to the problem of choosing
m-1 items from n-1.  E.g., your code was

f0 <- function(n, m) {
   stopifnot(n > m)
   D<-matrix(0,nrow=n-m+1,ncol=m-1)
   for (i in 1:m-1){
      D[,i]<-seq(0,n-m,1)
   }
   ED <- do.call(`expand.grid`,as.data.frame(D))
   ED<-unname(as.matrix(ED))
   lk<-which(rowSums(ED)<=(n-m))
   ED[lk,]
}

and I think the following does the same thing in much less space by
transforming the output of combn().

f1 <- function(n, m) {
   stopifnot(n > m)
   r0 <- t(diff(combn(n-1, m-1)) - 1L)
   r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1, len=n-m+1),
m-2))
   cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
}

The code for adding the last column is a bit clumsy and could probably be
improved.  Both f0 and f1 could also be cleaned up to work for m<=2.

See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more on
this sort of thing.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem <marammagdysalem at gmail.com>
wrote:

> Dear All,
>
> I'm trying to do a simple task (which is in fact a tiny part of a larger
> code).
>
> I want to create a matrix, D, each of its columns is a sequence from 0 to
> (n-m), by 1. Then, using D, I want to create another matrix ED, whose rows
> represent all the possible combinations of the elements of the columns of
> D. Then from ED, I'll select only the rows whose sum is less than or equal
> to (n-m), which will be called the matrix s. I used the following code:
>
> > n=5
> > m=3
> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
> > for (i in 1:m-1)
> +  {
> + D[,i]<-seq(0,n-m,1)
> +  }
> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > ED<-as.matrix(ED)
>
> > lk<-which(rowSums(ED)<=(n-m))
>
> > s<-ED[lk,]
>
>
> This works perfectly well. But for rather larger values of n and m (which
> are not so large actually), the number of all possible combinations of the
> columns of D gets extremely large giving me this error (for n=25, m=15):
>
> > ED <- do.call(`expand.grid`,as.data.frame(D))
> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>   invalid 'times' value
> In addition: Warning message:
> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>   NAs introduced by coercion to integer range
>
>
> Any help or suggestions will be greatly appreciated.
>
> Thanks,
>
> Maram Salem
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From axel.urbiz at gmail.com  Thu Oct 15 18:42:42 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 15 Oct 2015 12:42:42 -0400
Subject: [R] Variable names conflict
Message-ID: <CAAyVsXLMA-TjkG3z3qg+9XpHJTDGJ1P5xxdLgv3_zdkj7H4M0A@mail.gmail.com>

Hello,

I have a variable named 'x' defined inside a function, which   may conflict
with a variable name supplied in the argument to the function. What is the
best practice to avoid this conflict?

foo <- function(df) {
  x <- df[, 1, drop = FALSE]
  dfOut <- data.frame(df, x)
  dfOut

}
Data <- data.frame(x = c(1, 2), y = c(3, 4))
foo(Data)

  x y x.1
1 1 3   1
2 2 4   2

The following solution doesn't look nice to me?

foo <- function(df) {
  if (any(names(df) == 'x'))
    stop("x cannot be a variable name in the data frame")
  x <- df[, 1, drop = FALSE]
  dfOut <- data.frame(df, x)
  dfOut

}

Thanks!
Axel.

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Oct 15 19:49:55 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 15 Oct 2015 12:49:55 -0500
Subject: [R] Variable names conflict
In-Reply-To: <CAAyVsXLMA-TjkG3z3qg+9XpHJTDGJ1P5xxdLgv3_zdkj7H4M0A@mail.gmail.com>
References: <CAAyVsXLMA-TjkG3z3qg+9XpHJTDGJ1P5xxdLgv3_zdkj7H4M0A@mail.gmail.com>
Message-ID: <CAN5YmCGTS0Yf3FQa6VDS7d0UUorX1G_7wB_7H_NLOXYf1efoDg@mail.gmail.com>

Axel,

The solution you propose looks fine to me, if an error is the outcome that
you want in such a situation.  Were you hoping for a different outcome?
Would you, for example, prefer that the "x" in the data frame be given a
different name, rather than the "x" in the function?

Jean

On Thu, Oct 15, 2015 at 11:42 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> Hello,
>
> I have a variable named 'x' defined inside a function, which   may conflict
> with a variable name supplied in the argument to the function. What is the
> best practice to avoid this conflict?
>
> foo <- function(df) {
>   x <- df[, 1, drop = FALSE]
>   dfOut <- data.frame(df, x)
>   dfOut
>
> }
> Data <- data.frame(x = c(1, 2), y = c(3, 4))
> foo(Data)
>
>   x y x.1
> 1 1 3   1
> 2 2 4   2
>
> The following solution doesn't look nice to me?
>
> foo <- function(df) {
>   if (any(names(df) == 'x'))
>     stop("x cannot be a variable name in the data frame")
>   x <- df[, 1, drop = FALSE]
>   dfOut <- data.frame(df, x)
>   dfOut
>
> }
>
> Thanks!
> Axel.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Thu Oct 15 19:52:29 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Thu, 15 Oct 2015 17:52:29 +0000
Subject: [R] Variable names conflict
Message-ID: <248E6FA047A8C746BA491485764190F5220AD80C@ESESSMB207.ericsson.se>

May this be fine ?

foo <- function(df) {
  x <- df[, 1, drop = FALSE]
  available <- rev(letters[(letters %in% colnames(df)) == FALSE])
  colnames(x) <- available[1]
  dfOut <- data.frame(df, x)
  dfOut
}

Data <- data.frame(x = c(1, 2), y = c(3, 4))
foo(Data)

  x y z
1 1 3 1
2 2 4 2

--
GG



	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Oct 15 18:30:20 2015
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 15 Oct 2015 12:30:20 -0400
Subject: [R] 'strange' R graphics problem | Linux...
In-Reply-To: <CAGxgkWi08fy97EMFhE4+t5BCz=DtGSTLU21DJNUSiKK+XcCjiA@mail.gmail.com>
References: <561E5A6C.1070503@gmail.com>
	<CAGxgkWgzJQaT1Azfub543H0Hdsj+3bQZS+HMEygFXTMW+R0C+A@mail.gmail.com>
	<561EB137.9080304@gmail.com>
	<CAGxgkWif=20cafiQDOVASkQW6hjdB6zbwyPr-zGeX43f=zceFg@mail.gmail.com>
	<561EB44F.8060309@gmail.com> <561EE6BC.9080907@cornell.edu>
	<CAGxgkWi08fy97EMFhE4+t5BCz=DtGSTLU21DJNUSiKK+XcCjiA@mail.gmail.com>
Message-ID: <561FD49C.3050302@gmail.com>

Tried compiling all previous version of R 3.x.x. Compilations went fine. 
Code works, but every version throws the 'graphics problem' (basically, 
spawns the X1 window, which more or less becomes a static screen capture 
of the desktop under the spawned window.

What I think is related (cause?) is the code I had which generated lots 
of graphics worked fine in early summer, no longer works properly. While 
R has been updated since then, I don't think that's the problem (based 
on replicating the problem back through several iterations). What I 
suspect is driving things are the numerous package updates to CentOS 
which occurred in the later summer,many of which touched things related 
to X11. Short of re-installing a earlier version of the distro (which I 
could do in a VM, but that takes more time than I have), I will 
tentatively suggest the problem arises because of the CentOS changes.

One bit of information I want to flesh out is that I only get the 
'graphics error' if I am working at the console of the CentOS box. If I 
create an SSH tunnel, and do a remote desktop (with, say TightVNC), 
graphics work *perfectly*. VNC and related approaches often use very 
different graphical subsystems (mostly designed to minimize bandwidth 
overhead), but in so doing, R graphics  'work'.



On 10/14/2015 9:39 PM, Thomas Adams wrote:
> Evan,
>
> I have R 3.2.2 installed on my Ubuntu 15.04 machine -- no problems 
> with the graphics display. I have R 3.1.1 installed on my Ubuntu 14.04 
> machine, that, as expected I have not had any problems with... I tried 
> to install 3.2.2 and 3.2.1 from source and got a very strange compile 
> error, which I need to sort out -- recompiling 3.1.1 failed as well...
>
> Best,
> Tom
>
> On Wed, Oct 14, 2015 at 6:35 PM, Evan Cooch <evan.cooch at cornell.edu 
> <mailto:evan.cooch at cornell.edu>> wrote:
>
>     A clue --
>
>     Working from home, I created an ssh tunnel into my CentOS box, and
>     brought up the desktop remotely using VNC. Fire up R in a
>     terminal, and *voila*, graphics work fine.
>
>     So, if I'm sitting at the CentOS machine, R graphics choke and
>     die. If I use a remote desktop approach, graphics fine.
>
>     Very strange...
>
>     Forgot to add before, here are the 'capabilities' from my R
>     install -- X11 and cairo both 'there', so not sure what the
>     problem is.
>
>            jpeg         png        tiff tcltk         X11        aqua
>            TRUE        TRUE        TRUE        TRUE TRUE       FALSE
>        http/ftp     sockets      libxml        fifo cledit       iconv
>            TRUE        TRUE        TRUE        TRUE TRUE        TRUE
>             NLS     profmem       cairo         ICU long.double    
>     libcurl
>            TRUE       FALSE        TRUE        TRUE TRUE       FALSE
>
>     On 10/14/2015 4:00 PM, Evan Cooch wrote:
>>
>>
>>     On 10/14/2015 3:51 PM, Thomas Adams wrote:
>>>     Evan,
>>>
>>>     I have Ubuntu 14.04 and 15.10 at home and have not had problems,
>>>     but I don't think I've been using R 3.2.2 ? I'll try this evening.
>>
>>     Indeed - it could be an R-version issue, and not so much the
>>     distro. I might, for chuckles, roll back to 3.2.1, and see what
>>     happens.
>>
>>>
>>>     Tom
>>>
>>>     On Wed, Oct 14, 2015 at 2:47 PM, Evan Cooch
>>>     <evan.cooch at gmail.com <mailto:evan.cooch at gmail.com>> wrote:
>>>
>>>         Tom --
>>>
>>>         On 10/14/2015 3:35 PM, Thomas Adams wrote:
>>>>         Evan,
>>>>
>>>>         Not that this helps you, but I am using a very similar
>>>>         platform and I am having the identical problem. My test
>>>>         simply comes from the first help(plot) example. I tried
>>>>         doing some things to 'correct' the problem and ended up
>>>>         mucking-up my Gnome environment. In the process, I was able
>>>>         to get the example to display correctly, but as I said, I
>>>>         now have an unusable system. I'm not sure this is an R
>>>>         specific problem, but some incompatibility with the Centos
>>>>         Gnome environment.
>>>>
>>>
>>>         Thanks very much. I have a couple of Linux Mint 17.x systems
>>>         as well -- I'll see if they throw the same problem at me/us.
>>>
>>>>         Tom
>>>>
>>>>         On Wed, Oct 14, 2015 at 8:36 AM, Evan Cooch
>>>>         <evan.cooch at gmail.com <mailto:evan.cooch at gmail.com>> wrote:
>>>>
>>>>             So, am running 3.2.2 on a Centos 6.xx box. Code
>>>>             executes fine, but I'm having a heck of a time with
>>>>             graphics. I don't think this is related to R in the
>>>>             broad sense, but how it is interacting with graphics on
>>>>             the system. here is a description of the problem.
>>>>
>>>>             1\ something simple: test <- rnorm(100)
>>>>
>>>>             2\ try to generate a simple histogram  using hist(test)
>>>>
>>>>             3\ what happens is that a terminal window pops up (as I
>>>>             would expect for the graphic), but rather than showing
>>>>             the histogram, its essentially a screen-capture of the
>>>>             original terminal window in which I ran the script.
>>>>             Said second terminal window is not responsive, at all
>>>>             -- can't even close it short of opening another shell,
>>>>             and killing the process from the CLI.
>>>>
>>>>             4\ I get the exact same problem even if I try  a simple
>>>>             plot.new() -- generate a new terminal window, but with
>>>>             the same problem 'attributes' as described above.
>>>>
>>>>             For what it works, when I fire up gnuplot, terminal
>>>>             type set to X11 -- and basic gnuplot graphics (e.g.,
>>>>             plot sin(x)) work perfectly. Other graphics seem to
>>>>             work fine too. Just nothing I try to plot using R.
>>>>
>>>>             Anyone have any ideas as to what to look for/try? Here
>>>>             is the output of sessionInfo() -- nothing obvious that
>>>>             I can see.
>>>>
>>>>             R version 3.2.2 (2015-08-14)
>>>>             Platform: x86_64-redhat-linux-gnu (64-bit)
>>>>             Running under: CentOS release 6.7 (Final)
>>>>
>>>>             locale:
>>>>              [1] LC_CTYPE=en_US.UTF-8    LC_NUMERIC=C
>>>>              [3] LC_TIME=en_US.UTF-8   LC_COLLATE=en_US.UTF-8
>>>>              [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8
>>>>              [7] LC_PAPER=en_US.UTF-8    LC_NAME=C
>>>>              [9] LC_ADDRESS=C        LC_TELEPHONE=C
>>>>             [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>>             attached base packages:
>>>>             [1] stats     graphics grDevices utils  datasets 
>>>>             methods base
>>>>
>>>>             ______________________________________________
>>>>             R-help at r-project.org <mailto:R-help at r-project.org>
>>>>             mailing list -- To UNSUBSCRIBE and more, see
>>>>             https://stat.ethz.ch/mailman/listinfo/r-help
>>>>             PLEASE do read the posting guide
>>>>             http://www.R-project.org/posting-guide.html
>>>>             and provide commented, minimal, self-contained,
>>>>             reproducible code.
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>>
>>>
>>
>
>
>
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Oct 15 20:44:26 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Oct 2015 11:44:26 -0700
Subject: [R] create zoo object within a for loop
In-Reply-To: <COL130-W4D27788ED362B922D2627BA3E0@phx.gbl>
References: <COL130-W4D27788ED362B922D2627BA3E0@phx.gbl>
Message-ID: <FADAE3B2-155B-4D46-BBFF-EFAF039AA109@comcast.net>


On Oct 15, 2015, at 4:07 AM, Wiebke Ullmann wrote:

> Dear everyone.
> 
> I have a data frame with relocation data of several animals
> 
>> head(data)

It would be better to post output of dput(head(data))

> 
>                            timestamp
> 
> 
>  individual
> 
> 
>  easting
> 
> 
>  northing
> 
snipped larg amount of useless output

> 
> I know how to do this with a data frame that only includes the information of one animal. I used an index in zoo:
> 
>> animal1$time <- strptime(animal1$timestamp, format="%Y-%m-%d %H:%M:%S")
>> animal1$time <- as.POSIXct(format(round(animal1$time, units="hours"), 
>                                         format="%Y-%m-%d %H:%M"))
>> animal1.zoo  <- zoo(animal1[,-5],animal1[,5]) #set Index
>> animal1m     <- merge(animal1.zoo,
>                       zoo(,seq(animal1[1,5],animal1[length(animal1$timestamp),5],by="hour")), 
>                           all=TRUE)
> 
> And filled the other variables with na.locf.
> 
> But I do not know how to do this in one go for all the animals. I would like to use a for loop or lappy for lists.
> I would be very glad if you could help me out. Thank you very much in advance.
> 
> Cheers,
> Vivi
> 		 	   		  
> 	[[alternative HTML version deleted]]

You need to change settings in your mail client so you are adhering to the plain-text requirements of the mail-server offered by ETHZ. And please read the posting guide.


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Thu Oct 15 21:21:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 15 Oct 2015 12:21:04 -0700
Subject: [R] Variable names conflict
In-Reply-To: <CAAyVsXLMA-TjkG3z3qg+9XpHJTDGJ1P5xxdLgv3_zdkj7H4M0A@mail.gmail.com>
References: <CAAyVsXLMA-TjkG3z3qg+9XpHJTDGJ1P5xxdLgv3_zdkj7H4M0A@mail.gmail.com>
Message-ID: <3F630EBC-F8EA-4272-AB06-9E4AE9DDB2F2@dcn.davis.CA.us>

My strategy is to be specific about the names of columns at the top level. As I see it, letting functions internally come up with their own column names makes fragile code.

foo <- function(df, newColName ) {
 x <- setNames( df[, 1, drop = FALSE], newColName )
 dfOut <- data.frame(df, x)
 dfOut
}
Data <- data.frame(x = c(1, 2), y = c(3, 4))
foo(Data, "z") #at this point you know what names would collide and can choose wisely

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 15, 2015 9:42:42 AM PDT, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>Hello,
>
>I have a variable named 'x' defined inside a function, which   may
>conflict
>with a variable name supplied in the argument to the function. What is
>the
>best practice to avoid this conflict?
>
>foo <- function(df) {
>  x <- df[, 1, drop = FALSE]
>  dfOut <- data.frame(df, x)
>  dfOut
>
>}
>Data <- data.frame(x = c(1, 2), y = c(3, 4))
>foo(Data)
>
>  x y x.1
>1 1 3   1
>2 2 4   2
>
>The following solution doesn't look nice to me?
>
>foo <- function(df) {
>  if (any(names(df) == 'x'))
>    stop("x cannot be a variable name in the data frame")
>  x <- df[, 1, drop = FALSE]
>  dfOut <- data.frame(df, x)
>  dfOut
>
>}
>
>Thanks!
>Axel.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Oct 15 22:16:58 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Oct 2015 13:16:58 -0700
Subject: [R] Can scan() detect end-of-file?
Message-ID: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>

I would like to read a connection line by line with scan but
don't know how to tell when to quit trying.  Is there any
way that you can ask the connection object if it is at the end?

E.g.,

t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
tfile <- tempfile()
cat(t, file=tfile)
tcon <- file(tfile, "r") # or tcon <- textConnection(t)
scan(tcon, what="", nlines=1)
#Read 2 items
#[1] "A"               "Two line\nentry"
> scan(tcon, what="", nlines=1)  # empty line
#Read 0 items
#character(0)
scan(tcon, what="", nlines=1)
#Read 3 items
#[1] "Three\nline\nentry" "D"                  "E"
scan(tcon, what="", nlines=1) # end of file
#Read 0 items
#character(0)
scan(tcon, what="", nlines=1) # end of file
#Read 0 items
#character(0)

I am reading virtual line by virtual line because the lines
may have different numbers of fields.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


From mdalphin at gmail.com  Thu Oct 15 22:18:07 2015
From: mdalphin at gmail.com (Mark Dalphin)
Date: Fri, 16 Oct 2015 09:18:07 +1300
Subject: [R] SQL Server "float" is not handled by RODBC -- Is there a
 workaround?
In-Reply-To: <CAAxdm-6AqCejJEDo=gfxLiekNPoKYNLTh=67AjBx_hMH-+_ogA@mail.gmail.com>
References: <CAAxdm-6AqCejJEDo=gfxLiekNPoKYNLTh=67AjBx_hMH-+_ogA@mail.gmail.com>
Message-ID: <562009FF.2010503@peblnz.com>

Hi Jim,

No answers over the course of 24 hours so I'll give it a shot.

First, I always work under Linux, so my answers may well be worthless
for your Windows scenario.

Second, I don't know if my workaround works as I don't actually have a
SQL Server DB using float.

Now the workaround:

I have had many problems in the past using ODBC to connect to databases.
Nothing I could nail down to a fault in that system, but just no end of
problems. Some of that, of course, is due to me generally working under
Linux.

My general workaround that has been clean is to use JDBC instead. There
have been hassles at times to set up the RJava, but recent versions of
that have installed very easily. Once RJava is in place (and under
Windows, you'll have fun setting up Java cleanly), then installation of
a JDBC jar (I use jtds from SourceForge for SQL Server) and finally
RJDBC. The generic nature of the JDBC interface is a joy to work with,
interacting with most database types very well and in a uniform manner.

So, lots of work getting JDBC up and going to see if an alternative path
into your DB gets you your data in a better format. Now you see why I
waited 24 hours to say anything at all ...

Also, it might be worth while posting on the DB specific maillist:
    https://stat.ethz.ch/mailman/listinfo/r-sig-db

Hope this helps,
Mark Dalphin


On 15/10/15 07:23, jim holtman wrote:
> Here is the system I am using:
> =====================================
>> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252
> [3] LC_MONETARY=English_United States.1252
> LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lubridate_1.3.3 RODBC_1.3-12
> loaded via a namespace (and not attached):
> [1] magrittr_1.5  plyr_1.8.3    tools_3.2.2   memoise_0.2.1 Rcpp_0.12.1
> stringi_0.5-5 digest_0.6.8
> [8] stringr_1.0.0
> ========================================
>
> I have data on a SQL Server that I am connecting to where some of the
> fields are defined as "float" so that the data is stored in the database as
> an IEEE 754 value.  Now when I read this is using RODBC, the data comes
> across the interface in the floating point format; I used Wireshark to
> examine the packets that were being sent.  Some of the data is also defined
> as "int" and comes across in binary.
>
> When the data is read in with
>
> df <- sqlQuery(db, "select * from mydb", as.is = TRUE)
>
> The resulting dataframe has the floating point values as 'chr' and the
> integer fields as 'int'; I would have expected the floating point fields to
> be 'num'.  Now in the "ODBC Connectivity" Vignette by Ripley there was the
> comment that "double" data values come back as type 8, but on some systems
> they may be type 6; well on SQL Server, "float" is type 6.
>
> So what appears to happen, is this data is not recognized as a floating
> point value and is therefore converted to a character.  When the data is
> made available to the R script, I then have to convert this back to
> floating point.  If I use "stringsAsFactors = FALSE" on the query, this
> conversion back to floating point will be done within the RODBC package.
> This becomes a problem when I have dataframes with several million rows and
> multiple columns of numerics is that the conversion to/from characters is
> adding time to the processing.
>
> So I was wondering is there a workaround to this problem?  Is it possible
> to add the capability to RODBC when processing SQL Server to avoid this
> conversion?  Or is there some other way around this problem?
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Thu Oct 15 22:33:38 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 15 Oct 2015 22:33:38 +0200
Subject: [R] Creating a package with specail caracters
In-Reply-To: <1444909544149-4713620.post@n4.nabble.com>
References: <1444895576135-4713615.post@n4.nabble.com>
	<1A967444-F373-474D-AB15-7B8C80FAE56B@gmail.com>
	<1444903144678-4713618.post@n4.nabble.com>
	<C2C1E5D5-3E84-461B-A02F-836F446007FB@gmail.com>
	<1444909544149-4713620.post@n4.nabble.com>
Message-ID: <87113DB4-A4D9-4B9A-A6B3-82A6B784A4E1@gmail.com>


> On 15 Oct 2015, at 13:45 , jpara3 <j.para.fernandez at hotmail.com> wrote:
> 
> I have tried:
> 
> tktitle(tt) <- iconv("?GUI estad?stica", from="latin1",to="UTF8")
> tktitle(tt) <- iconv("?GUI estad?stica", from="",to="UTF8")
> tktitle(tt) <- iconv("?GUI estad?stica", to="UTF8")
> 
> 
> But there are no good results. 
> 

Hmm, I am out of ideas. But you never told us your system details, versions, locale settings etc. Try posting them and see if it rings a bell with someone.

Also, what happens if you try Encoding("?GUI estad?stica") on your system.

-pd


> Can maybe exist a code to insert after the special characters, as \?i for ??
> 


> Thanks 
> 
> 
> 
> 
> -----
> 
> Guided Tours Basque Country 
> 
> Guided tours in the three capitals of the Basque Country: Bilbao, Vitoria-Gasteiz and San Sebastian, as well as in their provinces. Available languages.
> 
> Travel planners for groups and design of tourist routes across the Basque Country.
> --
> View this message in context: http://r.789695.n4.nabble.com/Creating-a-package-with-specail-caracters-tp4713615p4713620.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sarah.goslee at gmail.com  Thu Oct 15 22:44:45 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 15 Oct 2015 16:44:45 -0400
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
Message-ID: <CAM_vjukw3KNkUVDHH_wvniThDiBBdBaQAaHN_rsvaPoN-KCwjQ@mail.gmail.com>

I've always used system("wc -l myfile") to get the number of lines in
advance. But here are two other R-only options, both using readLines
instead of scan. There's probably something more efficient, too.

Your setup:
t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
tfile <- tempfile()
cat(t, file=tfile)
tcon <- file(tfile, "r") # or tcon <- textConnection(t)

readLines() produces character(0) for nonexistent lines and "" for empty lines.

> readLines(tcon, n=1)
[1] "A \"Two line"
> readLines(tcon, n=1)
[1] "entry\""
> readLines(tcon, n=1)
[1] ""
> readLines(tcon, n=1)
[1] "\"Three"
> readLines(tcon, n=1)
[1] "line"
> readLines(tcon, n=1)
[1] "entry\" D E"
> readLines(tcon, n=1)
character(0)
> readLines(tcon, n=1)
character(0)

Or if the file isn't too large for memory, you can read the whole
thing in then process it line by line:

tcon <- file(tfile, "r") # or tcon <- textConnection(t)
allfile <- readLines(tcon, n=10000)

> length(allfile)
[1] 6

On Thu, Oct 15, 2015 at 4:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I would like to read a connection line by line with scan but
> don't know how to tell when to quit trying.  Is there any
> way that you can ask the connection object if it is at the end?
>
> E.g.,
>
> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
> tfile <- tempfile()
> cat(t, file=tfile)
> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
> scan(tcon, what="", nlines=1)
> #Read 2 items
> #[1] "A"               "Two line\nentry"
>> scan(tcon, what="", nlines=1)  # empty line
> #Read 0 items
> #character(0)
> scan(tcon, what="", nlines=1)
> #Read 3 items
> #[1] "Three\nline\nentry" "D"                  "E"
> scan(tcon, what="", nlines=1) # end of file
> #Read 0 items
> #character(0)
> scan(tcon, what="", nlines=1) # end of file
> #Read 0 items
> #character(0)
>
> I am reading virtual line by virtual line because the lines
> may have different numbers of fields.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
-- 
Sarah Goslee
http://www.functionaldiversity.org


From wdunlap at tibco.com  Thu Oct 15 22:56:37 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Oct 2015 13:56:37 -0700
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAM_vjukw3KNkUVDHH_wvniThDiBBdBaQAaHN_rsvaPoN-KCwjQ@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
	<CAM_vjukw3KNkUVDHH_wvniThDiBBdBaQAaHN_rsvaPoN-KCwjQ@mail.gmail.com>
Message-ID: <CAF8bMcZD1Smmd_N1Wu7Q5bGdTo4mOEwxHu4pPVV4LX6mGQ7yqQ@mail.gmail.com>

readLines() does not work for me since it breaks up
multiline fields that are enclosed in quotes.  E.g., the
text file line
  A "Two line\nentry"
should be imported as 2 strings, the second being
"Two line\nfield", not "\"Two line" with the next call to
readLines bringing in "fentry\"".

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 15, 2015 at 1:44 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> I've always used system("wc -l myfile") to get the number of lines in
> advance. But here are two other R-only options, both using readLines
> instead of scan. There's probably something more efficient, too.
>
> Your setup:
> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
> tfile <- tempfile()
> cat(t, file=tfile)
> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>
> readLines() produces character(0) for nonexistent lines and "" for empty lines.
>
>> readLines(tcon, n=1)
> [1] "A \"Two line"
>> readLines(tcon, n=1)
> [1] "entry\""
>> readLines(tcon, n=1)
> [1] ""
>> readLines(tcon, n=1)
> [1] "\"Three"
>> readLines(tcon, n=1)
> [1] "line"
>> readLines(tcon, n=1)
> [1] "entry\" D E"
>> readLines(tcon, n=1)
> character(0)
>> readLines(tcon, n=1)
> character(0)
>
> Or if the file isn't too large for memory, you can read the whole
> thing in then process it line by line:
>
> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
> allfile <- readLines(tcon, n=10000)
>
>> length(allfile)
> [1] 6
>
> On Thu, Oct 15, 2015 at 4:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> I would like to read a connection line by line with scan but
>> don't know how to tell when to quit trying.  Is there any
>> way that you can ask the connection object if it is at the end?
>>
>> E.g.,
>>
>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>> tfile <- tempfile()
>> cat(t, file=tfile)
>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>> scan(tcon, what="", nlines=1)
>> #Read 2 items
>> #[1] "A"               "Two line\nentry"
>>> scan(tcon, what="", nlines=1)  # empty line
>> #Read 0 items
>> #character(0)
>> scan(tcon, what="", nlines=1)
>> #Read 3 items
>> #[1] "Three\nline\nentry" "D"                  "E"
>> scan(tcon, what="", nlines=1) # end of file
>> #Read 0 items
>> #character(0)
>> scan(tcon, what="", nlines=1) # end of file
>> #Read 0 items
>> #character(0)
>>
>> I am reading virtual line by virtual line because the lines
>> may have different numbers of fields.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
> --
> Sarah Goslee
> http://www.functionaldiversity.org


From jholtman at gmail.com  Thu Oct 15 23:01:13 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 15 Oct 2015 17:01:13 -0400
Subject: [R] SQL Server "float" is not handled by RODBC -- Is there a
	workaround?
In-Reply-To: <562009FF.2010503@peblnz.com>
References: <CAAxdm-6AqCejJEDo=gfxLiekNPoKYNLTh=67AjBx_hMH-+_ogA@mail.gmail.com>
	<562009FF.2010503@peblnz.com>
Message-ID: <CAAxdm-75c0QDVYmfUMqhPkiBrP-K-g1pt4j83EZ5bivtyJBf_Q@mail.gmail.com>

Mark,

Thanks for the suggestion.  I will have to look into that option.  I assume
that if I am running on a 64-bit system, I also have to use the 64-bit
version of Java.  We have had some problems in the past because the company
standard is a 32-bit version of Java and we had to also load in the 64-bit
version to work with the XLConnect package.

I was reading the RJDBC package documention and they seem to list a lot of
methods (e.g., 'dbReadTable'), but don't say what the parameters are, or
what it returns.  Where do you find this information?  Also I notice that I
probably have to get the JDBC driver for SQL Server from Microsoft and
install that - is that correct?

I hate to start mixing approaches since we have a large number of scripts
that currently use the RODBC package, but I will try to see if the approach
you proposed do help overcome this problem.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Oct 15, 2015 at 4:18 PM, Mark Dalphin <mdalphin at gmail.com> wrote:

> Hi Jim,
>
> No answers over the course of 24 hours so I'll give it a shot.
>
> First, I always work under Linux, so my answers may well be worthless
> for your Windows scenario.
>
> Second, I don't know if my workaround works as I don't actually have a
> SQL Server DB using float.
>
> Now the workaround:
>
> I have had many problems in the past using ODBC to connect to databases.
> Nothing I could nail down to a fault in that system, but just no end of
> problems. Some of that, of course, is due to me generally working under
> Linux.
>
> My general workaround that has been clean is to use JDBC instead. There
> have been hassles at times to set up the RJava, but recent versions of
> that have installed very easily. Once RJava is in place (and under
> Windows, you'll have fun setting up Java cleanly), then installation of
> a JDBC jar (I use jtds from SourceForge for SQL Server) and finally
> RJDBC. The generic nature of the JDBC interface is a joy to work with,
> interacting with most database types very well and in a uniform manner.
>
> So, lots of work getting JDBC up and going to see if an alternative path
> into your DB gets you your data in a better format. Now you see why I
> waited 24 hours to say anything at all ...
>
> Also, it might be worth while posting on the DB specific maillist:
>     https://stat.ethz.ch/mailman/listinfo/r-sig-db
>
> Hope this helps,
> Mark Dalphin
>
>
> On 15/10/15 07:23, jim holtman wrote:
> > Here is the system I am using:
> > =====================================
> >> sessionInfo()
> > R version 3.2.2 (2015-08-14)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> >
> > locale:
> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> > States.1252
> > [3] LC_MONETARY=English_United States.1252
> > LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] lubridate_1.3.3 RODBC_1.3-12
> > loaded via a namespace (and not attached):
> > [1] magrittr_1.5  plyr_1.8.3    tools_3.2.2   memoise_0.2.1 Rcpp_0.12.1
> > stringi_0.5-5 digest_0.6.8
> > [8] stringr_1.0.0
> > ========================================
> >
> > I have data on a SQL Server that I am connecting to where some of the
> > fields are defined as "float" so that the data is stored in the database
> as
> > an IEEE 754 value.  Now when I read this is using RODBC, the data comes
> > across the interface in the floating point format; I used Wireshark to
> > examine the packets that were being sent.  Some of the data is also
> defined
> > as "int" and comes across in binary.
> >
> > When the data is read in with
> >
> > df <- sqlQuery(db, "select * from mydb", as.is = TRUE)
> >
> > The resulting dataframe has the floating point values as 'chr' and the
> > integer fields as 'int'; I would have expected the floating point fields
> to
> > be 'num'.  Now in the "ODBC Connectivity" Vignette by Ripley there was
> the
> > comment that "double" data values come back as type 8, but on some
> systems
> > they may be type 6; well on SQL Server, "float" is type 6.
> >
> > So what appears to happen, is this data is not recognized as a floating
> > point value and is therefore converted to a character.  When the data is
> > made available to the R script, I then have to convert this back to
> > floating point.  If I use "stringsAsFactors = FALSE" on the query, this
> > conversion back to floating point will be done within the RODBC package.
> > This becomes a problem when I have dataframes with several million rows
> and
> > multiple columns of numerics is that the conversion to/from characters is
> > adding time to the processing.
> >
> > So I was wondering is there a workaround to this problem?  Is it possible
> > to add the capability to RODBC when processing SQL Server to avoid this
> > conversion?  Or is there some other way around this problem?
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Oct 15 23:06:17 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 15 Oct 2015 17:06:17 -0400
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAF8bMcZD1Smmd_N1Wu7Q5bGdTo4mOEwxHu4pPVV4LX6mGQ7yqQ@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
	<CAM_vjukw3KNkUVDHH_wvniThDiBBdBaQAaHN_rsvaPoN-KCwjQ@mail.gmail.com>
	<CAF8bMcZD1Smmd_N1Wu7Q5bGdTo4mOEwxHu4pPVV4LX6mGQ7yqQ@mail.gmail.com>
Message-ID: <CAM_vjunEMQujKk+stWaVD6mSoo-6CgoPPXhJimz1tedUznj6Dw@mail.gmail.com>

Thus the post-processing, which I assume you'd have to do with scan() as well.

> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
> allfile <- readLines(tcon, n=10000)

> strsplit(paste(allfile, collapse="\n"), "\"")
[[1]]
[1] "A "                 "Two line\nentry"    "\n\n"
"Three\nline\nentry"
[5] " D E"

Or similar, depending on exactly what you want the result to look like.

On Thu, Oct 15, 2015 at 4:56 PM, William Dunlap <wdunlap at tibco.com> wrote:
> readLines() does not work for me since it breaks up
> multiline fields that are enclosed in quotes.  E.g., the
> text file line
>   A "Two line\nentry"
> should be imported as 2 strings, the second being
> "Two line\nfield", not "\"Two line" with the next call to
> readLines bringing in "fentry\"".
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Oct 15, 2015 at 1:44 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>> I've always used system("wc -l myfile") to get the number of lines in
>> advance. But here are two other R-only options, both using readLines
>> instead of scan. There's probably something more efficient, too.
>>
>> Your setup:
>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>> tfile <- tempfile()
>> cat(t, file=tfile)
>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>
>> readLines() produces character(0) for nonexistent lines and "" for empty lines.
>>
>>> readLines(tcon, n=1)
>> [1] "A \"Two line"
>>> readLines(tcon, n=1)
>> [1] "entry\""
>>> readLines(tcon, n=1)
>> [1] ""
>>> readLines(tcon, n=1)
>> [1] "\"Three"
>>> readLines(tcon, n=1)
>> [1] "line"
>>> readLines(tcon, n=1)
>> [1] "entry\" D E"
>>> readLines(tcon, n=1)
>> character(0)
>>> readLines(tcon, n=1)
>> character(0)
>>
>> Or if the file isn't too large for memory, you can read the whole
>> thing in then process it line by line:
>>
>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>> allfile <- readLines(tcon, n=10000)
>>
>>> length(allfile)
>> [1] 6
>>
>> On Thu, Oct 15, 2015 at 4:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>> I would like to read a connection line by line with scan but
>>> don't know how to tell when to quit trying.  Is there any
>>> way that you can ask the connection object if it is at the end?
>>>
>>> E.g.,
>>>
>>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>>> tfile <- tempfile()
>>> cat(t, file=tfile)
>>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>> scan(tcon, what="", nlines=1)
>>> #Read 2 items
>>> #[1] "A"               "Two line\nentry"
>>>> scan(tcon, what="", nlines=1)  # empty line
>>> #Read 0 items
>>> #character(0)
>>> scan(tcon, what="", nlines=1)
>>> #Read 3 items
>>> #[1] "Three\nline\nentry" "D"                  "E"
>>> scan(tcon, what="", nlines=1) # end of file
>>> #Read 0 items
>>> #character(0)
>>> scan(tcon, what="", nlines=1) # end of file
>>> #Read 0 items
>>> #character(0)
>>>
>>> I am reading virtual line by virtual line because the lines
>>> may have different numbers of fields.
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org


From amish.azeem1212 at outlook.com  Thu Oct 15 20:05:38 2015
From: amish.azeem1212 at outlook.com (amish azeem)
Date: Thu, 15 Oct 2015 18:05:38 +0000
Subject: [R] varying color in scatter3D plot
Message-ID: <BLU180-W71EF228449D2ABA3F846A8FA3E0@phx.gbl>

Dear R family,
I am trying to develop a 3D Scatterplot for the following data
> dput(fer)
structure(c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 54.682478566783, 73.7179265155391, 56.0442812544372, 123.944575771864, 81.6715941711683, 51.7551364274066, 64.017245155324, 73.3252689749492, 100.096914338008, 94.5597376188789), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("x", "y", "")))

You can notice that I have three columns and 10 rows. I was able to plot 3D scatterplot
library(plot3D)
x<-fer[,1]
y<-fer[,2]
z<-fer[,3]
scatter3D(x, y, z, bty = "g", pch = 18,           col.var = as.integer(fer[,2]),           col = c("black", "blue", "green","orange","red"),          pch = 18, ticktype = "detailed",          colkey = list(at = c(1,2, 3, 4,5), side = 2,           addlines = TRUE, length = 0.5, width = 0.5,          labels = c("M 1", "M 2", "M 3","M 4","M 5")),xlab="Model",ylab="station",zlab="Error" )

You could see that the color of plotted points are varying with respect to values on third column. I want them to vary W.r.t the 2nd column, while keeping fer[,1] on x-axis, fer[,2] on y-axis and fer[,3] on z-axis.I tried to change the input in  "col.var = as.integer(fer[,2])" but to no use.
Kindly help me out.
Thankyou very much in advance,

Amish
 		 	   		  
	[[alternative HTML version deleted]]


From amish.azeem1212 at outlook.com  Thu Oct 15 20:13:49 2015
From: amish.azeem1212 at outlook.com (amish azeem)
Date: Thu, 15 Oct 2015 18:13:49 +0000
Subject: [R] varying color in scatter3D plot
Message-ID: <BLU180-W390E5AAD6E338BBAF0D2F8FA3E0@phx.gbl>

Dear R family,I am trying to develop a 3D Scatterplot for the following data> dput(fer)structure(c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 54.682478566783, 73.7179265155391, 56.0442812544372, 123.944575771864, 81.6715941711683, 51.7551364274066, 64.017245155324, 73.3252689749492, 100.096914338008, 94.5597376188789), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("x", "y", "")))You can notice that I have three columns and 10 rows. I was able to plot 3D scatterplotlibrary(plot3D)x<-fer[,1]y<-fer[,2]z<-fer[,3]scatter3D(x, y, z, bty = "g", pch = 18,           col.var = as.integer(fer[,2]),           col = c("black", "blue", "green","orange","red"),          pch = 18, ticktype = "detailed",          colkey = list(at = c(1,2, 3, 4,5), side = 2,           addlines = TRUE, length = 0.5, width = 0.5,          labels = c("M 1", "M 2", "M 3","M 4","M 5")),xlab="Model",ylab="station",zlab="Error" )You could see that the color of plotted points are varying with respect to values on third column. I want them to vary W.r.t the 2nd column, while keeping fer[,1] on x-axis, fer[,2] on y-axis and fer[,3] on z-axis.I tried to change the input in  "col.var = as.integer(fer[,2])" but to no use.Kindly help me out.Thankyou very much in advance,Amish 		 	   		  
	[[alternative HTML version deleted]]


From jacksonan1945 at gmail.com  Thu Oct 15 20:17:49 2015
From: jacksonan1945 at gmail.com (Andre Jackson)
Date: Thu, 15 Oct 2015 14:17:49 -0400
Subject: [R] DeSolve package
Message-ID: <045401d10775$ccbb73a0$66325ae0$@gmail.com>

I have the following differential equations and return list:

dCgd.dt = -kad*y[1]-kgd*y[1]     # PK model equation gut d

  dCld.dt= kad*y[1]-rhyd-rmetd       #pk model equation liver d

  dCgl.dt = -kal*y2[1]-kgl*y2[1]     # PK model equation gut l

  dCll.dt= kal*y2[1]-rhyl-rmetl       #pk model equation liver l

  

            # PK model equation

  return(list(c(dCgd.dt,dCld.dt,dCgl.dt,dCll.dt),c(massbalance=sum())))

}

 

For the DDE solve I have :

out = dede(y=y0,times=times,func=model.LIDR,parms=parms)

 

This gives me the following error:

Error in func(time, state, parms, ...) : object 'p' not found

 

Can someone explain this error and its remedy?

Andre Jackson

Jacksonan1945 at gmail.com

"You must be the change you wish the world to be"

 


	[[alternative HTML version deleted]]


From james at jtoll.com  Thu Oct 15 23:05:32 2015
From: james at jtoll.com (James Toll)
Date: Thu, 15 Oct 2015 16:05:32 -0500
Subject: [R] rvest and the not css selector
Message-ID: <C62FE165-E7BC-43E4-81F4-9BFFB986B848@jtoll.com>

Hi,

I'm trying to use rvest to scrape a page and I am having difficulty excluding child element superscripts via a CSS selector.  For example, here I've read the html and selected nodes.


p <- read_html(targetUrl)
p %>% html_nodes("td.xyz")


The result looks something like this:

{xml_nodeset (20)}
 [1] <td class="xyz" width="50%">Foo<font size="-1"><sup>9</sup></font>:</td>
 [2] <td class="xyz" width="50%">Bar<font size="-1"><sup>3</sup></font>:</td>
[...]


I would like to extract the words "Foo" and "Bar" without the superscripts by passing along to html_text().  I thought something like this would work, but it returns just the superscripts. 

p %>% 
html_nodes("td.xyz") %>%
html_nodes(":not(sup)") %>% 
html_text()


Perhaps I?m using the not selector improperly.  Any suggestions on how to get this to work properly?  Thanks.


James


From wdunlap at tibco.com  Thu Oct 15 23:34:44 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Oct 2015 14:34:44 -0700
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAM_vjunEMQujKk+stWaVD6mSoo-6CgoPPXhJimz1tedUznj6Dw@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
	<CAM_vjukw3KNkUVDHH_wvniThDiBBdBaQAaHN_rsvaPoN-KCwjQ@mail.gmail.com>
	<CAF8bMcZD1Smmd_N1Wu7Q5bGdTo4mOEwxHu4pPVV4LX6mGQ7yqQ@mail.gmail.com>
	<CAM_vjunEMQujKk+stWaVD6mSoo-6CgoPPXhJimz1tedUznj6Dw@mail.gmail.com>
Message-ID: <CAF8bMcZCCE8ptTiBraonDLMY_Jr6xFscF1KdCbr5Fpa0L+366w@mail.gmail.com>

scan(nlines=) does this post-processing, which is why I'm using it
instead of readLines.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 15, 2015 at 2:06 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> Thus the post-processing, which I assume you'd have to do with scan() as well.
>
>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>> allfile <- readLines(tcon, n=10000)
>
>> strsplit(paste(allfile, collapse="\n"), "\"")
> [[1]]
> [1] "A "                 "Two line\nentry"    "\n\n"
> "Three\nline\nentry"
> [5] " D E"
>
> Or similar, depending on exactly what you want the result to look like.
>
> On Thu, Oct 15, 2015 at 4:56 PM, William Dunlap <wdunlap at tibco.com> wrote:
>> readLines() does not work for me since it breaks up
>> multiline fields that are enclosed in quotes.  E.g., the
>> text file line
>>   A "Two line\nentry"
>> should be imported as 2 strings, the second being
>> "Two line\nfield", not "\"Two line" with the next call to
>> readLines bringing in "fentry\"".
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Thu, Oct 15, 2015 at 1:44 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>> I've always used system("wc -l myfile") to get the number of lines in
>>> advance. But here are two other R-only options, both using readLines
>>> instead of scan. There's probably something more efficient, too.
>>>
>>> Your setup:
>>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>>> tfile <- tempfile()
>>> cat(t, file=tfile)
>>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>>
>>> readLines() produces character(0) for nonexistent lines and "" for empty lines.
>>>
>>>> readLines(tcon, n=1)
>>> [1] "A \"Two line"
>>>> readLines(tcon, n=1)
>>> [1] "entry\""
>>>> readLines(tcon, n=1)
>>> [1] ""
>>>> readLines(tcon, n=1)
>>> [1] "\"Three"
>>>> readLines(tcon, n=1)
>>> [1] "line"
>>>> readLines(tcon, n=1)
>>> [1] "entry\" D E"
>>>> readLines(tcon, n=1)
>>> character(0)
>>>> readLines(tcon, n=1)
>>> character(0)
>>>
>>> Or if the file isn't too large for memory, you can read the whole
>>> thing in then process it line by line:
>>>
>>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>> allfile <- readLines(tcon, n=10000)
>>>
>>>> length(allfile)
>>> [1] 6
>>>
>>> On Thu, Oct 15, 2015 at 4:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
>>>> I would like to read a connection line by line with scan but
>>>> don't know how to tell when to quit trying.  Is there any
>>>> way that you can ask the connection object if it is at the end?
>>>>
>>>> E.g.,
>>>>
>>>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>>>> tfile <- tempfile()
>>>> cat(t, file=tfile)
>>>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>>> scan(tcon, what="", nlines=1)
>>>> #Read 2 items
>>>> #[1] "A"               "Two line\nentry"
>>>>> scan(tcon, what="", nlines=1)  # empty line
>>>> #Read 0 items
>>>> #character(0)
>>>> scan(tcon, what="", nlines=1)
>>>> #Read 3 items
>>>> #[1] "Three\nline\nentry" "D"                  "E"
>>>> scan(tcon, what="", nlines=1) # end of file
>>>> #Read 0 items
>>>> #character(0)
>>>> scan(tcon, what="", nlines=1) # end of file
>>>> #Read 0 items
>>>> #character(0)
>>>>
>>>> I am reading virtual line by virtual line because the lines
>>>> may have different numbers of fields.
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org


From jdnewmil at dcn.davis.CA.us  Thu Oct 15 23:57:00 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 15 Oct 2015 14:57:00 -0700
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
Message-ID: <0B7A3678-F1E7-4D59-AED0-8390276D6B1F@dcn.davis.CA.us>

This is a problem in C as well... and the solution is to read the lines yourself and then give those lines to scan. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 15, 2015 1:16:58 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>I would like to read a connection line by line with scan but
>don't know how to tell when to quit trying.  Is there any
>way that you can ask the connection object if it is at the end?
>
>E.g.,
>
>t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>tfile <- tempfile()
>cat(t, file=tfile)
>tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>scan(tcon, what="", nlines=1)
>#Read 2 items
>#[1] "A"               "Two line\nentry"
>> scan(tcon, what="", nlines=1)  # empty line
>#Read 0 items
>#character(0)
>scan(tcon, what="", nlines=1)
>#Read 3 items
>#[1] "Three\nline\nentry" "D"                  "E"
>scan(tcon, what="", nlines=1) # end of file
>#Read 0 items
>#character(0)
>scan(tcon, what="", nlines=1) # end of file
>#Read 0 items
>#character(0)
>
>I am reading virtual line by virtual line because the lines
>may have different numbers of fields.
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mdalphin at gmail.com  Fri Oct 16 00:02:24 2015
From: mdalphin at gmail.com (Mark Dalphin)
Date: Fri, 16 Oct 2015 11:02:24 +1300
Subject: [R] SQL Server "float" is not handled by RODBC -- Is there a
 workaround?
In-Reply-To: <CAAxdm-75c0QDVYmfUMqhPkiBrP-K-g1pt4j83EZ5bivtyJBf_Q@mail.gmail.com>
References: <CAAxdm-6AqCejJEDo=gfxLiekNPoKYNLTh=67AjBx_hMH-+_ogA@mail.gmail.com>
	<562009FF.2010503@peblnz.com>
	<CAAxdm-75c0QDVYmfUMqhPkiBrP-K-g1pt4j83EZ5bivtyJBf_Q@mail.gmail.com>
Message-ID: <56202270.8010607@peblnz.com>

Hi Jim,

Yes, your Java versions need to match bit width.

As for drivers, I do not use the Microsoft one; it used to be hard to
obtain for Linux users; I don't know if it still is. I currently use
"jtds" from Sourceforge:
    http://jtds.sourceforge.net/

From their site:
> jTDS is an open source 100% pure Java (type 4) JDBC 3.0 driver for
> Microsoft SQL Server (6.5, 7, 2000, 2005, 2008 and 2012) and Sybase
> Adaptive Server Enterprise (10, 11, 12 and 15).

I always found reading the DBI + DBI-specific driver (eg RPostgreSQL or
RJDBC) documentation challenging. I think it is oriented towards the
programmer who wrote it rather than the end user. It probably needs a
long, wordy vignette like Tim Bunce once wrote for the Perl DBI, but I
am not stepping up to write it (so you don't hear me complaining)! Over
the years, I've gleaned enough and experimented enough that I have
certain methods well worked out. And I have ignored much of the
functionality that has been added over the years; I am sure that the DBI
implementors have put some real gems in there as I stumble upon new ones
all the time.

The help for DBI, "help(package='DBI')", lists many methods. RJDBC is
just an intermediary and it happens to implement most of them. In fact,
I usually read the DBI drivers packages (RPosgreSQL, RJDBC) with an eye
towards find "what is not implemented or what is broken" more than
anything else.

DBIConnection-class                    DBIConnection class.
DBIDriver-class                        DBIDriver class.
DBIObject-class                        DBIObject class.
DBIResult-class                        DBIResult class.
SQL                                    SQL quoting.
dbClearResult                          Clear a result set.
dbColumnInfo                           Information about result types.
dbConnect                              Create a connection to a DBMS.
dbDataType                             Determine the SQL data type of an
object.
dbDisconnect                           Disconnect (close) a connection
dbDriver                               Load and unload database drivers.
dbExistsTable                          Does a table exist?
dbFetch                                Fetch records from a previously
executed query.
dbGetException                         Get DBMS exceptions.
dbGetInfo                              Get DBMS metadata.
dbGetQuery                             Send query, retrieve results and
then clear result set.
dbGetRowCount                          The number of rows fetched so far.
dbGetRowsAffected                      The number of rows affected by
data modifying query.
dbGetStatement                         Get the statement associated with
a result set
dbHasCompleted                         Has the operation completed?
dbIsValid                              Is this DBMS object still valid?
dbListConnections                      List currently open connections.
dbListFields                           List field names of a remote table.
dbListResults                          A list of all pending results.
dbListTables                           List remote tables.
dbReadTable                            Copy data frames to and from
database tables.
dbRemoveTable                          Remove a table from the database.
dbSendQuery                            Execute a statement on a given
database connection.
dbiCheckCompliance                     Check a driver for compliance
with DBI.
make.db.names                          Make R identifiers into legal SQL
identifiers.
transactions                           Begin/commit/rollback SQL
transactions

In short, I usually only use a small subset of what is available:
    dbConnect, dbDisconnect, dbGetQuery, dbSendQuery, dbFetch and
'transactions'

Some of the apparent richness is from things like two methods to get
table information, one detailed and one simple. And since I know my
schemas already, I seldom use either. In addition, there is ample
support for complex DB interaction, including full support for
transactions, allowing multi-table updates with security.

My usual operation is something like this:

library(RJDBC)

jdbcStr <- 'jdbc:jtds:sqlserver://myHost.myLan:myPort/myDbName'

drv <- JDBC("net.sourceforge.jtds.jdbc.Driver",
            "/my/long/path/to/my/JDBC_Drivers/jtds/jtds-1.3.0.jar")

conn <- dbConnect(drv, jdbcStr, user='mark', password='*****')

## See what tables are present (DB exploration; not used in production)
tab <- dbGetTables(conn)

## A typical query if I am to iterate through
rs <- dbSendQuery(conn, 'SELECT TOP 10 * FROM Orders;')
## followed by dbFetch calls

## A more typical query if I can grab the whole thing at once
rs <- dbGetQuery(conn, 'SELECT * FROM Orders;')
print(rs)

dbDisconnect(conn)

Hope this helps; I might be able to help with specific examples for some
of the DBI methods, if you need it. I suspect that what I have written
above will cover most "query SQL", though not the "Insert/Update/Delete"
stuff.

Regards,
Mark Dalphin


On 16/10/15 10:01, jim holtman wrote:
> Mark,
>
> Thanks for the suggestion.  I will have to look into that option.  I
> assume that if I am running on a 64-bit system, I also have to use the
> 64-bit version of Java.  We have had some problems in the past because
> the company standard is a 32-bit version of Java and we had to also
> load in the 64-bit version to work with the XLConnect package.
>
> I was reading the RJDBC package documention and they seem to list a
> lot of methods (e.g., 'dbReadTable'), but don't say what the
> parameters are, or what it returns.  Where do you find this
> information?  Also I notice that I probably have to get the JDBC
> driver for SQL Server from Microsoft and install that - is that correct?
>
> I hate to start mixing approaches since we have a large number of
> scripts that currently use the RODBC package, but I will try to see if
> the approach you proposed do help overcome this problem.
>
>
> Jim Holtman
> Data Munger Guru
>  
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Thu, Oct 15, 2015 at 4:18 PM, Mark Dalphin <mdalphin at gmail.com
> <mailto:mdalphin at gmail.com>> wrote:
>
>     Hi Jim,
>
>     No answers over the course of 24 hours so I'll give it a shot.
>
>     First, I always work under Linux, so my answers may well be worthless
>     for your Windows scenario.
>
>     Second, I don't know if my workaround works as I don't actually have a
>     SQL Server DB using float.
>
>     Now the workaround:
>
>     I have had many problems in the past using ODBC to connect to
>     databases.
>     Nothing I could nail down to a fault in that system, but just no
>     end of
>     problems. Some of that, of course, is due to me generally working
>     under
>     Linux.
>
>     My general workaround that has been clean is to use JDBC instead.
>     There
>     have been hassles at times to set up the RJava, but recent versions of
>     that have installed very easily. Once RJava is in place (and under
>     Windows, you'll have fun setting up Java cleanly), then
>     installation of
>     a JDBC jar (I use jtds from SourceForge for SQL Server) and finally
>     RJDBC. The generic nature of the JDBC interface is a joy to work with,
>     interacting with most database types very well and in a uniform
>     manner.
>
>     So, lots of work getting JDBC up and going to see if an
>     alternative path
>     into your DB gets you your data in a better format. Now you see why I
>     waited 24 hours to say anything at all ...
>
>     Also, it might be worth while posting on the DB specific maillist:
>         https://stat.ethz.ch/mailman/listinfo/r-sig-db
>
>     Hope this helps,
>     Mark Dalphin
>
>
>     On 15/10/15 07:23, jim holtman wrote:
>     > Here is the system I am using:
>     > =====================================
>     >> sessionInfo()
>     > R version 3.2.2 (2015-08-14)
>     > Platform: x86_64-w64-mingw32/x64 (64-bit)
>     > Running under: Windows 7 x64 (build 7601) Service Pack 1
>     >
>     > locale:
>     > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>     > States.1252
>     > [3] LC_MONETARY=English_United States.1252
>     > LC_NUMERIC=C
>     > [5] LC_TIME=English_United States.1252
>     >
>     > attached base packages:
>     > [1] stats     graphics  grDevices utils     datasets  methods   base
>     >
>     > other attached packages:
>     > [1] lubridate_1.3.3 RODBC_1.3-12
>     > loaded via a namespace (and not attached):
>     > [1] magrittr_1.5  plyr_1.8.3    tools_3.2.2   memoise_0.2.1
>     Rcpp_0.12.1
>     > stringi_0.5-5 digest_0.6.8
>     > [8] stringr_1.0.0
>     > ========================================
>     >
>     > I have data on a SQL Server that I am connecting to where some
>     of the
>     > fields are defined as "float" so that the data is stored in the
>     database as
>     > an IEEE 754 value.  Now when I read this is using RODBC, the
>     data comes
>     > across the interface in the floating point format; I used
>     Wireshark to
>     > examine the packets that were being sent.  Some of the data is
>     also defined
>     > as "int" and comes across in binary.
>     >
>     > When the data is read in with
>     >
>     > df <- sqlQuery(db, "select * from mydb", as.is <http://as.is> =
>     TRUE)
>     >
>     > The resulting dataframe has the floating point values as 'chr'
>     and the
>     > integer fields as 'int'; I would have expected the floating
>     point fields to
>     > be 'num'.  Now in the "ODBC Connectivity" Vignette by Ripley
>     there was the
>     > comment that "double" data values come back as type 8, but on
>     some systems
>     > they may be type 6; well on SQL Server, "float" is type 6.
>     >
>     > So what appears to happen, is this data is not recognized as a
>     floating
>     > point value and is therefore converted to a character.  When the
>     data is
>     > made available to the R script, I then have to convert this back to
>     > floating point.  If I use "stringsAsFactors = FALSE" on the
>     query, this
>     > conversion back to floating point will be done within the RODBC
>     package.
>     > This becomes a problem when I have dataframes with several
>     million rows and
>     > multiple columns of numerics is that the conversion to/from
>     characters is
>     > adding time to the processing.
>     >
>     > So I was wondering is there a workaround to this problem?  Is it
>     possible
>     > to add the capability to RODBC when processing SQL Server to
>     avoid this
>     > conversion?  Or is there some other way around this problem?
>     >
>     > Jim Holtman
>     > Data Munger Guru
>     >
>     > What is the problem that you are trying to solve?
>     > Tell me what you want to do, not how you want to do it.
>     >
>     >       [[alternative HTML version deleted]]
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.
>     >
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 16 00:10:31 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 15 Oct 2015 15:10:31 -0700
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <0B7A3678-F1E7-4D59-AED0-8390276D6B1F@dcn.davis.CA.us>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
	<0B7A3678-F1E7-4D59-AED0-8390276D6B1F@dcn.davis.CA.us>
Message-ID: <CAF8bMcbDpnZsXs-1bB1snijyESPD+ZW8xG2e4_CxREp1aCc9dQ@mail.gmail.com>

C can tell when it hits the end of input.  Reading the lines with
readLines and passing them to scan() does not help - it is the
same as having scan read the original file.

My problem is that the file (or other connection) has a variable number
of fields on each "line", and perhaps no fields on some lines.  Fields
enclosed in quotes may include newline character.  I want to read this
file into a list of character vectors, the n'th element of the list being
the fields on the n'th "line" of the file.

repeating scan(connection, nlines=1, what="") does everything right
except for telling me when it has read everything the connection
has to offer.  scan(connection, what="") manages to figure out where
the end of the file is, but does not tell me the line number associated
each character string.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 15, 2015 at 2:57 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> This is a problem in C as well... and the solution is to read the lines yourself and then give those lines to scan.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 15, 2015 1:16:58 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>>I would like to read a connection line by line with scan but
>>don't know how to tell when to quit trying.  Is there any
>>way that you can ask the connection object if it is at the end?
>>
>>E.g.,
>>
>>t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>>tfile <- tempfile()
>>cat(t, file=tfile)
>>tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>scan(tcon, what="", nlines=1)
>>#Read 2 items
>>#[1] "A"               "Two line\nentry"
>>> scan(tcon, what="", nlines=1)  # empty line
>>#Read 0 items
>>#character(0)
>>scan(tcon, what="", nlines=1)
>>#Read 3 items
>>#[1] "Three\nline\nentry" "D"                  "E"
>>scan(tcon, what="", nlines=1) # end of file
>>#Read 0 items
>>#character(0)
>>scan(tcon, what="", nlines=1) # end of file
>>#Read 0 items
>>#character(0)
>>
>>I am reading virtual line by virtual line because the lines
>>may have different numbers of fields.
>>
>>Bill Dunlap
>>TIBCO Software
>>wdunlap tibco.com
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Fri Oct 16 00:56:55 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 15 Oct 2015 15:56:55 -0700 (PDT)
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAF8bMcbDpnZsXs-1bB1snijyESPD+ZW8xG2e4_CxREp1aCc9dQ@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
	<0B7A3678-F1E7-4D59-AED0-8390276D6B1F@dcn.davis.CA.us>
	<CAF8bMcbDpnZsXs-1bB1snijyESPD+ZW8xG2e4_CxREp1aCc9dQ@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1510151547100.40458@pedal.dcn.davis.ca.us>

I don't know what OS-independent function you use in C that performs the
way you describe. I would write the below function in C myself in order to get 
this functionality in that language.

readListOfVectors <- function( input ) {
  lines <- readLines( input )
  if ( "" == lines[ length( lines ) ] ) {
   lines <- lines[ -length( lines ) ]
  }
  result <- lapply( lines
                  , function( lin ) {
                     lc <- textConnection( lin )
                     res <- scan( lc, quiet=TRUE )
                     close( lc )
  		    res
 		   }
                  )
  result
}

# test
txt <- (
"1 2 3 4
1 4 5
2 4 6 8 9
")

tc <- textConnection(txt)
# can give it a filename or a connection object
readListOfVectors( tc )
close(tc)

On Thu, 15 Oct 2015, William Dunlap wrote:

> C can tell when it hits the end of input.  Reading the lines with
> readLines and passing them to scan() does not help - it is the
> same as having scan read the original file.
>
> My problem is that the file (or other connection) has a variable number
> of fields on each "line", and perhaps no fields on some lines.  Fields
> enclosed in quotes may include newline character.  I want to read this
> file into a list of character vectors, the n'th element of the list being
> the fields on the n'th "line" of the file.
>
> repeating scan(connection, nlines=1, what="") does everything right
> except for telling me when it has read everything the connection
> has to offer.  scan(connection, what="") manages to figure out where
> the end of the file is, but does not tell me the line number associated
> each character string.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Oct 15, 2015 at 2:57 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> This is a problem in C as well... and the solution is to read the lines yourself and then give those lines to scan.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 15, 2015 1:16:58 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>>> I would like to read a connection line by line with scan but
>>> don't know how to tell when to quit trying.  Is there any
>>> way that you can ask the connection object if it is at the end?
>>>
>>> E.g.,
>>>
>>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>>> tfile <- tempfile()
>>> cat(t, file=tfile)
>>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>> scan(tcon, what="", nlines=1)
>>> #Read 2 items
>>> #[1] "A"               "Two line\nentry"
>>>> scan(tcon, what="", nlines=1)  # empty line
>>> #Read 0 items
>>> #character(0)
>>> scan(tcon, what="", nlines=1)
>>> #Read 3 items
>>> #[1] "Three\nline\nentry" "D"                  "E"
>>> scan(tcon, what="", nlines=1) # end of file
>>> #Read 0 items
>>> #character(0)
>>> scan(tcon, what="", nlines=1) # end of file
>>> #Read 0 items
>>> #character(0)
>>>
>>> I am reading virtual line by virtual line because the lines
>>> may have different numbers of fields.
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dwinsemius at comcast.net  Fri Oct 16 01:42:44 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 15 Oct 2015 16:42:44 -0700
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAF8bMcbDpnZsXs-1bB1snijyESPD+ZW8xG2e4_CxREp1aCc9dQ@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
	<0B7A3678-F1E7-4D59-AED0-8390276D6B1F@dcn.davis.CA.us>
	<CAF8bMcbDpnZsXs-1bB1snijyESPD+ZW8xG2e4_CxREp1aCc9dQ@mail.gmail.com>
Message-ID: <0D966591-E24E-4B19-8D28-B963C3FF3D07@comcast.net>


On Oct 15, 2015, at 3:10 PM, William Dunlap wrote:

> C can tell when it hits the end of input.  Reading the lines with
> readLines and passing them to scan() does not help - it is the
> same as having scan read the original file.
> 
> My problem is that the file (or other connection) has a variable number
> of fields on each "line", and perhaps no fields on some lines.  Fields
> enclosed in quotes may include newline character.  I want to read this
> file into a list of character vectors, the n'th element of the list being
> the fields on the n'th "line" of the file.
> 
> repeating scan(connection, nlines=1, what="") does everything right
> except for telling me when it has read everything the connection
> has to offer.  scan(connection, what="") manages to figure out where
> the end of the file is, but does not tell me the line number associated

> each character string.
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Thu, Oct 15, 2015 at 2:57 PM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> This is a problem in C as well... and the solution is to read the lines yourself and then give those lines to scan.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                      Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>> 
>> On October 15, 2015 1:16:58 PM PDT, William Dunlap <wdunlap at tibco.com> wrote:
>>> I would like to read a connection line by line with scan but
>>> don't know how to tell when to quit trying.  Is there any
>>> way that you can ask the connection object if it is at the end?
>>> 
>>> E.g.,
>>> 
>>> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
>>> tfile <- tempfile()
>>> cat(t, file=tfile)
>>> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
>>> scan(tcon, what="", nlines=1)
>>> #Read 2 items
>>> #[1] "A"               "Two line\nentry"
>>>> scan(tcon, what="", nlines=1)  # empty line
>>> #Read 0 items
>>> #character(0)
>>> scan(tcon, what="", nlines=1)
>>> #Read 3 items
>>> #[1] "Three\nline\nentry" "D"                  "E"
>>> scan(tcon, what="", nlines=1) # end of file
>>> #Read 0 items
>>> #character(0)
>>> scan(tcon, what="", nlines=1) # end of file
>>> #Read 0 items
>>> #character(0)

If you run seek() after you scan() calls and test whether  the the result is the same twice in a scan-read, that could be your end of file signal.

[1] "Three\nline\nentry" "D"                  "E"                 
[1] 43
> scan(tcon, what="", nlines=1);seek(tcon)
Read 0 items
character(0)
[1] 43



-- 
David.
>>> 
>>> I am reading virtual line by virtual line because the lines
>>> may have different numbers of fields.
>>> 
>>> Bill Dunlap
>>> TIBCO Software

-- 

David Winsemius
Alameda, CA, USA


From marammagdysalem at gmail.com  Fri Oct 16 11:17:16 2015
From: marammagdysalem at gmail.com (marammagdysalem at gmail.com)
Date: Fri, 16 Oct 2015 11:17:16 +0200
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
Message-ID: <524BEA72-F5F3-433D-A5F7-7C2E7C5B99C7@gmail.com>

Thanks a lot for helping William. Will check the reference as well.

Sent from my iPhone

> On Oct 15, 2015, at 5:52 PM, William Dunlap <wdunlap at tibco.com> wrote:
> 
> Doing enumerative combinatorics with rejection methods rarely
> works well. Try mapping your problem to the problem of choosing
> m-1 items from n-1.  E.g., your code was
> f0 <- function(n, m) {
>    stopifnot(n > m)
>    D<-matrix(0,nrow=n-m+1,ncol=m-1)
>    for (i in 1:m-1){
>       D[,i]<-seq(0,n-m,1)
>    }
>    ED <- do.call(`expand.grid`,as.data.frame(D))
>    ED<-unname(as.matrix(ED))
>    lk<-which(rowSums(ED)<=(n-m))
>    ED[lk,]
> }
> and I think the following does the same thing in much less space by transforming the output of combn().
> f1 <- function(n, m) {
>    stopifnot(n > m)
>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1, len=n-m+1), m-2))
>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
> }
> The code for adding the last column is a bit clumsy and could probably be improved.  Both f0 and f1 could also be cleaned up to work for m<=2.
> 
> See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more on this sort of thing.
> 
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
>> On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
>> Dear All,
>> 
>> I'm trying to do a simple task (which is in fact a tiny part of a larger
>> code).
>> 
>> I want to create a matrix, D, each of its columns is a sequence from 0 to
>> (n-m), by 1. Then, using D, I want to create another matrix ED, whose rows
>> represent all the possible combinations of the elements of the columns of
>> D. Then from ED, I'll select only the rows whose sum is less than or equal
>> to (n-m), which will be called the matrix s. I used the following code:
>> 
>> > n=5
>> > m=3
>> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>> > for (i in 1:m-1)
>> +  {
>> + D[,i]<-seq(0,n-m,1)
>> +  }
>> > ED <- do.call(`expand.grid`,as.data.frame(D))
>> > ED<-as.matrix(ED)
>> 
>> > lk<-which(rowSums(ED)<=(n-m))
>> 
>> > s<-ED[lk,]
>> 
>> 
>> This works perfectly well. But for rather larger values of n and m (which
>> are not so large actually), the number of all possible combinations of the
>> columns of D gets extremely large giving me this error (for n=25, m=15):
>> 
>> > ED <- do.call(`expand.grid`,as.data.frame(D))
>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>   invalid 'times' value
>> In addition: Warning message:
>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>   NAs introduced by coercion to integer range
>> 
>> 
>> Any help or suggestions will be greatly appreciated.
>> 
>> Thanks,
>> 
>> Maram Salem
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Fri Oct 16 11:26:23 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 16 Oct 2015 09:26:23 +0000
Subject: [R] DeSolve package
Message-ID: <248E6FA047A8C746BA491485764190F5220ADB7A@ESESSMB207.ericsson.se>

It is likely the "p" variable is not defined in your R environment.



Inside your function model.LIDR, the variable "p" is used before being initialized

in any of the environments reachable by the search path, included the model.LIDR

function environment.



The remedy is to define and initialize "p" before it is being referenced (used).



It is not about any deSolve package specific error.



--

GG



	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Oct 16 12:24:40 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 16 Oct 2015 06:24:40 -0400
Subject: [R] varying color in scatter3D plot
In-Reply-To: <BLU180-W71EF228449D2ABA3F846A8FA3E0@phx.gbl>
References: <BLU180-W71EF228449D2ABA3F846A8FA3E0@phx.gbl>
Message-ID: <5620D068.2070701@gmail.com>

On 15/10/2015 2:05 PM, amish azeem wrote:
> Dear R family,
> I am trying to develop a 3D Scatterplot for the following data
>> dput(fer)
> structure(c(1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 54.682478566783, 73.7179265155391, 56.0442812544372, 123.944575771864, 81.6715941711683, 51.7551364274066, 64.017245155324, 73.3252689749492, 100.096914338008, 94.5597376188789), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("x", "y", "")))
> 
> You can notice that I have three columns and 10 rows. I was able to plot 3D scatterplot
> library(plot3D)
> x<-fer[,1]
> y<-fer[,2]
> z<-fer[,3]
> scatter3D(x, y, z, bty = "g", pch = 18,           col.var = as.integer(fer[,2]),           col = c("black", "blue", "green","orange","red"),          pch = 18, ticktype = "detailed",          colkey = list(at = c(1,2, 3, 4,5), side = 2,           addlines = TRUE, length = 0.5, width = 0.5,          labels = c("M 1", "M 2", "M 3","M 4","M 5")),xlab="Model",ylab="station",zlab="Error" )
> 
> You could see that the color of plotted points are varying with respect to values on third column. I want them to vary W.r.t the 2nd column, while keeping fer[,1] on x-axis, fer[,2] on y-axis and fer[,3] on z-axis.I tried to change the input in  "col.var = as.integer(fer[,2])" but to no use.
> Kindly help me out.
> Thankyou very much in advance,

The argument name is colvar, not col.var.

Duncan Murdoch


From giorgio.garziano at ericsson.com  Fri Oct 16 13:12:09 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 16 Oct 2015 11:12:09 +0000
Subject: [R] processing time line by line
Message-ID: <248E6FA047A8C746BA491485764190F5220ADC19@ESESSMB207.ericsson.se>

I may suggest this tutorial:


http://www.stat.berkeley.edu/~nolan/stat133/Fall05/lectures/profilingEx.html


and this discussion:


http://stackoverflow.com/questions/3650862/how-to-efficiently-use-rprof-in-r


which inspired this example:


Rprof("profile1.out", line.profiling=TRUE)
for(i in 1:10000) {
  rnorm(100,1,1);
  rbinom(1000,1,1)
  rbinom(10000,1,1)
}
Rprof(NULL)
summaryRprof("profile1.out", lines = "show")

$by.self
   self.time self.pct total.time total.pct
#4      4.44    86.72       4.44     86.72
#3      0.38     7.42       0.38      7.42
#2      0.30     5.86       0.30      5.86

$by.total
   total.time total.pct self.time self.pct
#4       4.44     86.72      4.44    86.72
#3       0.38      7.42      0.38     7.42
#2       0.30      5.86      0.30     5.86

$by.line
   self.time self.pct total.time total.pct
#2      0.30     5.86       0.30      5.86
#3      0.38     7.42       0.38      7.42
#4      4.44    86.72       4.44     86.72

$sample.interval
[1] 0.02

$sampling.time
[1] 5.12


--
GG

	[[alternative HTML version deleted]]


From giorgio.garziano at ericsson.com  Fri Oct 16 14:28:36 2015
From: giorgio.garziano at ericsson.com (Giorgio Garziano)
Date: Fri, 16 Oct 2015 12:28:36 +0000
Subject: [R] Problem in SVM model generation
Message-ID: <248E6FA047A8C746BA491485764190F5220ADD2A@ESESSMB207.ericsson.se>

>From R prompt, input:

memory.limit()

which returns the amount of memory available to R.

Then, before allocating that vector, run:

library(pryr)
mem_used()

To see current memory in use.

Should be: memory.limit() - mem_used() >= 2.4GBytes

--
GG


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct 16 19:37:01 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 16 Oct 2015 10:37:01 -0700
Subject: [R] Problem in SVM model generation
In-Reply-To: <CACVT7p9QSYk1y9e+5JGntTH_2aNkwKNtLg9H9LW0Jq+xTqU4fg@mail.gmail.com>
References: <CACVT7p9QSYk1y9e+5JGntTH_2aNkwKNtLg9H9LW0Jq+xTqU4fg@mail.gmail.com>
Message-ID: <7B666900-AB17-4D52-B8FE-AAD502475BB9@comcast.net>


On Oct 15, 2015, at 4:51 AM, Bhawana Sahu wrote:

> I am using R in my project for analysis of data, and I have generated SVM
> model using kernlab package with the dataset (3000 rows and 281 columns).
> Now I want to generate this model for dataset containing 8000 rows and 281
> column, but here I am getting an error saying that "cannot allocate vector
> of size 2.4 gb"
> 
> Earlier I was running this model on system with 4GB RAM, now I tried this
> on the system having RAM size of 64 gb, I tried all possible way to
> increase memory limit of R, and virtual memory, but problem persist.

The size of _contiguous_ memory is what's important and that will depend on the efficiency of your memory management (with Windows being accused of inferiority in the past) as well as how many other programs you have loaded and the degree of memory fragmentation. I'm not sure that you can resize memory when you already deep in a session. I thought it needed to be done early in the startup process but I'm not currently using Windows so am only reporting what I read in Rhelp

?'Memory-limits'
?Startup 

Delete any (possibly invisible) .RData file. Restart with a clean session of both your OS and R. You can get the size of objects currently in the R workspace with this function that I think I copied from one of Dirk Eddelbeuttel's or Bill Dunlap's posts:


getsizes <- 
function (num=10)  # change the num to different values to see more objects
{
    z <- sapply(ls(envir = globalenv()), function(x) object.size(get(x)))
    (tmp <- as.matrix(rev(sort(z))[1:num]))
}


getsizes()

> 
> Please suggest me what can be the issue with this, why am I getting this
> error, Is there any limitation of this package.
> 

Packages are not usually the culprit. It's usually program bloat by the user. I am usually guilty of having too many images and webpages open at the same time.


> Thank you
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hvillalo at ipn.mx  Fri Oct 16 22:36:20 2015
From: hvillalo at ipn.mx (Hector Villalobos)
Date: Fri, 16 Oct 2015 20:36:20 +0000
Subject: [R] optimization problem
Message-ID: <CABikkoVu_WrUUkcphd5QxxzSTtPkPstz_bggTGG3WNmtXg8ckw@mail.gmail.com>

Dear R users,

I'im trying to find the parameters of a dynamic biomass model using maximum
likelihood estimation. I used two approaches, one by hand, with optim()
function and the other using mle2() function from package bbmle. My problem
is that the results change a lot depending on the initial values... I can't
see what I am doing wrong...

Thank you for any help!


# Data
x <- 1995:2010
B <- c(3500, 3200, 3000, 2800, 2600, 3000, 3200, 3800, 4200, 4300, 4400,
4400, 4500, 4600, 5000, 4300)
Ct <- c(912, 767, 642, 482, 353, 331, 332, 309, 366, 402, 392, 478, 408,
434, 407, 637)
a <- c(0.539, 0.603, -0.948, 0.166, 1.895, 0.786, 0.901, 0.844, 0.337,
0.429, 0.304, 0.230, 1.001, 0.750, 0.507, 1.502)
Ag <- 0.55

# Function with quantity to minimize
modl <- function(par) {
  ro <- par[1]
  ko <- par[2]
  n <- length(B)
  Be <- rep(NA, n)
  Be[1] <- ko * Ag
  for ( k in 2:n)
    Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
  err <- (log(B) - log(Be))^2
  ee <- sqrt( sum(err)/(n-2) )
  LL <- (1/(sqrt(2*pi)*ee)) * exp( -(err/(2*ee^2) ) )
  -crossprod(LL)
}

# Using function optim()
par.optim <- optim(par = list(ro=0.4, ko=8000), modl, method = "BFGS")
ro <- par.optim$par[1]
ko <- par.optim$par[2]

# estimated values of "B"
n <- length(B)
Be <- rep(NA, n)
Be[1] <- ko * Ag
for ( k in 2:n)
  Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]

# Plot, estimation of "B" seems reasonable....
plot(x, B, ylim=c(1000, 7000))
lines(x, Be, col="blue", lwd=2)


# ... but it is very sensible to initial values...
par.optim2 <- optim(par = list(ro=0.4, ko=10000), modl, method = "BFGS")
ro2 <- par.optim2$par[1]
ko2 <- par.optim2$par[2]

Be2 <- rep(NA, n)
Be2[1] <- ko2 * Ag
for ( k in 2:n)
  Be2[k] <- Be2[k-1] + ro2 * a[k-1] * Be2[k-1] * (1 - Be2[k-1]/ko2) -
Ct[k-1]

lines(x, Be2, col="blue", lwd=2, lty=3)



# Uing mle2 function
library(bbmle)
LL <- function(ro, ko, mu, sigma) {
  n <- length(B)
  Be <- rep(NA, n)
  Be[1] <- ko * Ag
  for ( k in 2:n)
    Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
  err <- log(B) - log(Be)
  R <- (dnorm(err, mu, sigma, log=TRUE))
  -sum(R)
}

Bc.mle <- mle2(LL, start = list(ro=0.4, ko=8000, mu=0, sigma=1))
summary(Bc.mle)

ro3 <- coef(Bc.mle)[1]
ko3 <- coef(Bc.mle)[2]

Be3 <- rep(NA, n)
Be3[1] <- ko3 * Ag
for ( k in 2:n)
  Be3[k] <- Be3[k-1] + ro3 * a[k-1] * Be3[k-1] * (1 - Be3[k-1]/ko3) -
Ct[k-1]

lines(x, Be3, col="red", lwd=2)


-- 

H?ctor Villalobos <Hector.Villalobos.O at gmail.com>

Depto. de Pesquer?as y Biolog?a Marina

Centro Interdisciplinario de Ciencias Marinas-Instituto Polit?cnico Nacional

CICIMAR-I.P.N.

A.P. 592. Colonia Centro

La Paz, Baja California Sur, M?XICO. 23000

Tels.: (+52 612) 122 53 44; 123 46 58; 123 47 34 ext.: 81602

Fax: (+52 612) 122 53 22

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Oct 17 03:01:22 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 16 Oct 2015 18:01:22 -0700
Subject: [R] optimization problem
In-Reply-To: <CABikkoVu_WrUUkcphd5QxxzSTtPkPstz_bggTGG3WNmtXg8ckw@mail.gmail.com>
References: <CABikkoVu_WrUUkcphd5QxxzSTtPkPstz_bggTGG3WNmtXg8ckw@mail.gmail.com>
Message-ID: <CAGxFJbQM4+iucKRCFptitm3+Lwr0mda15B6-4-7cfVTj3QVAAA@mail.gmail.com>

I made no attempt to examine your details for problems, but in general,

 My problem
> is that the results change a lot depending on the initial values... I can't
> see what I am doing wrong...
>
> This is a symptom of an overparameterized model: The parameter estimates
> are unstable even though the predictions may not change much. In other
> words, your model may be too complex for your data.


Whether that is true here, you or others will have to determine. Try
simplifying your model as a start.

-- Bert



>
>
> # Data
> x <- 1995:2010
> B <- c(3500, 3200, 3000, 2800, 2600, 3000, 3200, 3800, 4200, 4300, 4400,
> 4400, 4500, 4600, 5000, 4300)
> Ct <- c(912, 767, 642, 482, 353, 331, 332, 309, 366, 402, 392, 478, 408,
> 434, 407, 637)
> a <- c(0.539, 0.603, -0.948, 0.166, 1.895, 0.786, 0.901, 0.844, 0.337,
> 0.429, 0.304, 0.230, 1.001, 0.750, 0.507, 1.502)
> Ag <- 0.55
>
> # Function with quantity to minimize
> modl <- function(par) {
>   ro <- par[1]
>   ko <- par[2]
>   n <- length(B)
>   Be <- rep(NA, n)
>   Be[1] <- ko * Ag
>   for ( k in 2:n)
>     Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
>   err <- (log(B) - log(Be))^2
>   ee <- sqrt( sum(err)/(n-2) )
>   LL <- (1/(sqrt(2*pi)*ee)) * exp( -(err/(2*ee^2) ) )
>   -crossprod(LL)
> }
>
> # Using function optim()
> par.optim <- optim(par = list(ro=0.4, ko=8000), modl, method = "BFGS")
> ro <- par.optim$par[1]
> ko <- par.optim$par[2]
>
> # estimated values of "B"
> n <- length(B)
> Be <- rep(NA, n)
> Be[1] <- ko * Ag
> for ( k in 2:n)
>   Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
>
> # Plot, estimation of "B" seems reasonable....
> plot(x, B, ylim=c(1000, 7000))
> lines(x, Be, col="blue", lwd=2)
>
>
> # ... but it is very sensible to initial values...
> par.optim2 <- optim(par = list(ro=0.4, ko=10000), modl, method = "BFGS")
> ro2 <- par.optim2$par[1]
> ko2 <- par.optim2$par[2]
>
> Be2 <- rep(NA, n)
> Be2[1] <- ko2 * Ag
> for ( k in 2:n)
>   Be2[k] <- Be2[k-1] + ro2 * a[k-1] * Be2[k-1] * (1 - Be2[k-1]/ko2) -
> Ct[k-1]
>
> lines(x, Be2, col="blue", lwd=2, lty=3)
>
>
>
> # Uing mle2 function
> library(bbmle)
> LL <- function(ro, ko, mu, sigma) {
>   n <- length(B)
>   Be <- rep(NA, n)
>   Be[1] <- ko * Ag
>   for ( k in 2:n)
>     Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
>   err <- log(B) - log(Be)
>   R <- (dnorm(err, mu, sigma, log=TRUE))
>   -sum(R)
> }
>
> Bc.mle <- mle2(LL, start = list(ro=0.4, ko=8000, mu=0, sigma=1))
> summary(Bc.mle)
>
> ro3 <- coef(Bc.mle)[1]
> ko3 <- coef(Bc.mle)[2]
>
> Be3 <- rep(NA, n)
> Be3[1] <- ko3 * Ag
> for ( k in 2:n)
>   Be3[k] <- Be3[k-1] + ro3 * a[k-1] * Be3[k-1] * (1 - Be3[k-1]/ko3) -
> Ct[k-1]
>
> lines(x, Be3, col="red", lwd=2)
>
>
> --
>
> H?ctor Villalobos <Hector.Villalobos.O at gmail.com <javascript:;>>
>
> Depto. de Pesquer?as y Biolog?a Marina
>
> Centro Interdisciplinario de Ciencias Marinas-Instituto Polit?cnico
> Nacional
>
> CICIMAR-I.P.N.
>
> A.P. 592. Colonia Centro
>
> La Paz, Baja California Sur, M?XICO. 23000
>
> Tels.: (+52 612) 122 53 44; 123 46 58; 123 47 34 ext.: 81602
>
> Fax: (+52 612) 122 53 22
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Sat Oct 17 09:05:24 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 17 Oct 2015 09:05:24 +0200
Subject: [R] optimization problem
In-Reply-To: <CAGxFJbQM4+iucKRCFptitm3+Lwr0mda15B6-4-7cfVTj3QVAAA@mail.gmail.com>
References: <CABikkoVu_WrUUkcphd5QxxzSTtPkPstz_bggTGG3WNmtXg8ckw@mail.gmail.com>
	<CAGxFJbQM4+iucKRCFptitm3+Lwr0mda15B6-4-7cfVTj3QVAAA@mail.gmail.com>
Message-ID: <51B70C2B-FB0C-4613-A09A-960C8C9372C6@xs4all.nl>


Your model is producing -Inf entries in the vector Be (in function modl and LL) at some stage during the optimization process.
You should first do something about that before anything else.

Berend


> On 17 Oct 2015, at 03:01, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I made no attempt to examine your details for problems, but in general,
> 
> My problem
>> is that the results change a lot depending on the initial values... I can't
>> see what I am doing wrong...
>> 
>> This is a symptom of an overparameterized model: The parameter estimates
>> are unstable even though the predictions may not change much. In other
>> words, your model may be too complex for your data.
> 
> 
> Whether that is true here, you or others will have to determine. Try
> simplifying your model as a start.
> 
> -- Bert
> 
> 
> 
>> 
>> 
>> # Data
>> x <- 1995:2010
>> B <- c(3500, 3200, 3000, 2800, 2600, 3000, 3200, 3800, 4200, 4300, 4400,
>> 4400, 4500, 4600, 5000, 4300)
>> Ct <- c(912, 767, 642, 482, 353, 331, 332, 309, 366, 402, 392, 478, 408,
>> 434, 407, 637)
>> a <- c(0.539, 0.603, -0.948, 0.166, 1.895, 0.786, 0.901, 0.844, 0.337,
>> 0.429, 0.304, 0.230, 1.001, 0.750, 0.507, 1.502)
>> Ag <- 0.55
>> 
>> # Function with quantity to minimize
>> modl <- function(par) {
>>  ro <- par[1]
>>  ko <- par[2]
>>  n <- length(B)
>>  Be <- rep(NA, n)
>>  Be[1] <- ko * Ag
>>  for ( k in 2:n)
>>    Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
>>  err <- (log(B) - log(Be))^2
>>  ee <- sqrt( sum(err)/(n-2) )
>>  LL <- (1/(sqrt(2*pi)*ee)) * exp( -(err/(2*ee^2) ) )
>>  -crossprod(LL)
>> }
>> 
>> # Using function optim()
>> par.optim <- optim(par = list(ro=0.4, ko=8000), modl, method = "BFGS")
>> ro <- par.optim$par[1]
>> ko <- par.optim$par[2]
>> 
>> # estimated values of "B"
>> n <- length(B)
>> Be <- rep(NA, n)
>> Be[1] <- ko * Ag
>> for ( k in 2:n)
>>  Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
>> 
>> # Plot, estimation of "B" seems reasonable....
>> plot(x, B, ylim=c(1000, 7000))
>> lines(x, Be, col="blue", lwd=2)
>> 
>> 
>> # ... but it is very sensible to initial values...
>> par.optim2 <- optim(par = list(ro=0.4, ko=10000), modl, method = "BFGS")
>> ro2 <- par.optim2$par[1]
>> ko2 <- par.optim2$par[2]
>> 
>> Be2 <- rep(NA, n)
>> Be2[1] <- ko2 * Ag
>> for ( k in 2:n)
>>  Be2[k] <- Be2[k-1] + ro2 * a[k-1] * Be2[k-1] * (1 - Be2[k-1]/ko2) -
>> Ct[k-1]
>> 
>> lines(x, Be2, col="blue", lwd=2, lty=3)
>> 
>> 
>> 
>> # Uing mle2 function
>> library(bbmle)
>> LL <- function(ro, ko, mu, sigma) {
>>  n <- length(B)
>>  Be <- rep(NA, n)
>>  Be[1] <- ko * Ag
>>  for ( k in 2:n)
>>    Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
>>  err <- log(B) - log(Be)
>>  R <- (dnorm(err, mu, sigma, log=TRUE))
>>  -sum(R)
>> }
>> 
>> Bc.mle <- mle2(LL, start = list(ro=0.4, ko=8000, mu=0, sigma=1))
>> summary(Bc.mle)
>> 
>> ro3 <- coef(Bc.mle)[1]
>> ko3 <- coef(Bc.mle)[2]
>> 
>> Be3 <- rep(NA, n)
>> Be3[1] <- ko3 * Ag
>> for ( k in 2:n)
>>  Be3[k] <- Be3[k-1] + ro3 * a[k-1] * Be3[k-1] * (1 - Be3[k-1]/ko3) -
>> Ct[k-1]
>> 
>> lines(x, Be3, col="red", lwd=2)
>> 
>> 
>> --
>> 
>> H?ctor Villalobos <Hector.Villalobos.O at gmail.com <javascript:;>>
>> 
>> Depto. de Pesquer?as y Biolog?a Marina
>> 
>> Centro Interdisciplinario de Ciencias Marinas-Instituto Polit?cnico
>> Nacional
>> 
>> CICIMAR-I.P.N.
>> 
>> A.P. 592. Colonia Centro
>> 
>> La Paz, Baja California Sur, M?XICO. 23000
>> 
>> Tels.: (+52 612) 122 53 44; 123 46 58; 123 47 34 ext.: 81602
>> 
>> Fax: (+52 612) 122 53 22
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
>> more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge is
> certainly not wisdom."
>   -- Clifford Stoll
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From haenlein at escpeurope.eu  Sat Oct 17 14:07:05 2015
From: haenlein at escpeurope.eu (Michael Haenlein)
Date: Sat, 17 Oct 2015 14:07:05 +0200
Subject: [R] igraph -- Selecting closest neighbors
Message-ID: <CAOyz9G7PEpgTKXRvu2FN70XLqZ5=w612CYNRTRjmgEHaEs09kw@mail.gmail.com>

Dear all,

I am looking for a function to select the N closest neighbors (in terms of
distance) of a vertex in igraph.

Assume for example N=7. If the vertex has 3 direct neighbors, I would like
that the function selects those 3 plus a random 4 among the second degree
neighbors.

Is there some way to do this in an efficient way? I have been trying to
program something using ego () with varying levels of distance but I have
not managed to get a conclusive solution.

Thanks for your help,

Michael


Michael Haenlein
Professor of Marketing
ESCP Europe

	[[alternative HTML version deleted]]


From chrishold at psyctc.org  Sat Oct 17 18:18:25 2015
From: chrishold at psyctc.org (Chris Evans)
Date: Sat, 17 Oct 2015 17:18:25 +0100 (BST)
Subject: [R] No speed up using the parallel package and ncpus > 1 with
 boot() on linux machines
Message-ID: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>

I think I am failing to understand how boot() uses the parallel package on linux machines, using R 3.2.2 on three different machines with 2, 4 and 8 cores all results in a slow down if I use "multicore" and "ncpus".  Here's the code that creates a very simple reproducible example:

bootReps <- 500
seed <- 12345
set.seed(seed)
require(boot)
dat <- rnorm(500)
bootMean <- function(dat,ind) {
  mean(dat[ind])
}
start.time <- proc.time()
bootDat <- boot(dat,bootMean,bootReps)
boot.ci(bootDat,type="norm")
stop.time <- proc.time()
elapsed.time1 <- stop.time - start.time
require(parallel)
set.seed(seed)
start.time <- proc.time()
bootDat <- boot(dat,bootMean,bootReps,
                parallel="multicore",
                ncpus=2)
boot.ci(bootDat,type="norm")
stop.time <- proc.time()
elapsed.time2 <- stop.time - start.time
elapsed.time1
elapsed.time2

Running that on my old Dell Latitude E6500 running Debian Squeeze and using 32 bit R 3.2.2 gives me:

> bootReps <- 500
> seed <- 12345
> set.seed(seed)
> require(boot)
> dat <- rnorm(500)
> bootMean <- function(dat,ind) {
+   mean(dat[ind])
+ }
> start.time <- proc.time()
> bootDat <- boot(dat,bootMean,bootReps)
> boot.ci(bootDat,type="norm")
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 500 bootstrap replicates

CALL : 
boot.ci(boot.out = bootDat, type = "norm")

Intervals : 
Level      Normal        
95%   (-0.0034,  0.1677 )  
Calculations and Intervals on Original Scale
> stop.time <- proc.time()
> elapsed.time1 <- stop.time - start.time
> require(parallel)
> set.seed(seed)
> start.time <- proc.time()
> bootDat <- boot(dat,bootMean,bootReps,
+                 parallel="multicore",
+                 ncpus=2)
> boot.ci(bootDat,type="norm")
BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
Based on 500 bootstrap replicates

CALL : 
boot.ci(boot.out = bootDat, type = "norm")

Intervals : 
Level      Normal        
95%   (-0.0030,  0.1675 )  
Calculations and Intervals on Original Scale
> stop.time <- proc.time()
> elapsed.time2 <- stop.time - start.time
> elapsed.time1
   user  system elapsed 
  0.028   0.000   0.174 
> elapsed.time2
   user  system elapsed 
  4.336   2.572   0.166 

A very slightly different 95% CI reflecting the way that invoking parallel="multicore" changes the seed setting and a huge deterioration in execution speed rather than any improvement.

On a more recent four core Toshiba and using ncpus=4 again on Debian Squeeze, 32bit R, I get exactly the same CIs and this timing:

> elapsed.time1
user system elapsed 
0.032 0.000 0.100 
> elapsed.time2
user system elapsed 
0.032 0.020 0.049 
>

and on a Mac Mini with eight cores on Squeeze but with 64bit R I get the same CIs and this timing:

> elapsed.time1
   user  system elapsed 
  0.012   0.004   0.017 
> elapsed.time2
   user  system elapsed 
  0.032   0.012   0.024 

I am clearly missing something, or perhaps something else is choking the work, not the CPU power, RAM?  I've tried searching for similar reports on the web and was surprised to find nothing using what seemed plausible search strategies.

Anyone able to help me?  I'd desperately like to get a marked speed up for some simulation work I'm doing on the Mac mini as it's taking days to run at the moment.  The computational intensive bits in the models is a bit more complicated than this here (!) but most of the workload will be in the bootstrapping and the function I'm bootstrapping for real, although it's a bit more complex than a simple mean, isn't that complex though it does involve a stratified bootstrap rather than a simple one.  I see very similar marginal speed _losses_ invoking more than one core for that work just as with this very simple example.

TIA,

Chris


From nalimilan at club.fr  Sat Oct 17 19:13:40 2015
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 17 Oct 2015 19:13:40 +0200
Subject: [R] No speed up using the parallel package and ncpus > 1 with
 boot() on linux machines
In-Reply-To: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
References: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
Message-ID: <1445102020.16289.75.camel@club.fr>

Le samedi 17 octobre 2015 ? 17:18 +0100, Chris Evans a ?crit :
> I think I am failing to understand how boot() uses the parallel
> package on linux machines, using R 3.2.2 on three different machines
> with 2, 4 and 8 cores all results in a slow down if I use "multicore"
> and "ncpus".  Here's the code that creates a very simple reproducible
> example:
> 
> bootReps <- 500
> seed <- 12345
> set.seed(seed)
> require(boot)
> dat <- rnorm(500)
> bootMean <- function(dat,ind) {
>   mean(dat[ind])
> }
> start.time <- proc.time()
> bootDat <- boot(dat,bootMean,bootReps)
> boot.ci(bootDat,type="norm")
> stop.time <- proc.time()
> elapsed.time1 <- stop.time - start.time
> require(parallel)
> set.seed(seed)
> start.time <- proc.time()
> bootDat <- boot(dat,bootMean,bootReps,
>                 parallel="multicore",
>                 ncpus=2)
> boot.ci(bootDat,type="norm")
> stop.time <- proc.time()
> elapsed.time2 <- stop.time - start.time
> elapsed.time1
> elapsed.time2
> 
> Running that on my old Dell Latitude E6500 running Debian Squeeze and
> using 32 bit R 3.2.2 gives me:
> 
> > bootReps <- 500
> > seed <- 12345
> > set.seed(seed)
> > require(boot)
> > dat <- rnorm(500)
> > bootMean <- function(dat,ind) {
> +   mean(dat[ind])
> + }
> > start.time <- proc.time()
> > bootDat <- boot(dat,bootMean,bootReps)
> > boot.ci(bootDat,type="norm")
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 500 bootstrap replicates
> 
> CALL : 
> boot.ci(boot.out = bootDat, type = "norm")
> 
> Intervals : 
> Level      Normal        
> 95%   (-0.0034,  0.1677 )  
> Calculations and Intervals on Original Scale
> > stop.time <- proc.time()
> > elapsed.time1 <- stop.time - start.time
> > require(parallel)
> > set.seed(seed)
> > start.time <- proc.time()
> > bootDat <- boot(dat,bootMean,bootReps,
> +                 parallel="multicore",
> +                 ncpus=2)
> > boot.ci(bootDat,type="norm")
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 500 bootstrap replicates
> 
> CALL : 
> boot.ci(boot.out = bootDat, type = "norm")
> 
> Intervals : 
> Level      Normal        
> 95%   (-0.0030,  0.1675 )  
> Calculations and Intervals on Original Scale
> > stop.time <- proc.time()
> > elapsed.time2 <- stop.time - start.time
> > elapsed.time1
>    user  system elapsed 
>   0.028   0.000   0.174 
> > elapsed.time2
>    user  system elapsed 
>   4.336   2.572   0.166 
> 
> A very slightly different 95% CI reflecting the way that invoking
> parallel="multicore" changes the seed setting and a huge
> deterioration in execution speed rather than any improvement.
> 
> On a more recent four core Toshiba and using ncpus=4 again on Debian
> Squeeze, 32bit R, I get exactly the same CIs and this timing:
> 
> > elapsed.time1
> user system elapsed 
> 0.032 0.000 0.100 
> > elapsed.time2
> user system elapsed 
> 0.032 0.020 0.049 
> > 
> 
> and on a Mac Mini with eight cores on Squeeze but with 64bit R I get
> the same CIs and this timing:
> 
> > elapsed.time1
>    user  system elapsed 
>   0.012   0.004   0.017 
> > elapsed.time2
>    user  system elapsed 
>   0.032   0.012   0.024 
> 
> I am clearly missing something, or perhaps something else is choking
> the work, not the CPU power, RAM?  I've tried searching for similar
> reports on the web and was surprised to find nothing using what
> seemed plausible search strategies.
> 
> Anyone able to help me?  I'd desperately like to get a marked speed
> up for some simulation work I'm doing on the Mac mini as it's taking
> days to run at the moment.  The computational intensive bits in the
> models is a bit more complicated than this here (!) but most of the
> workload will be in the bootstrapping and the function I'm
> bootstrapping for real, although it's a bit more complex than a
> simple mean, isn't that complex though it does involve a stratified
> bootstrap rather than a simple one.  I see very similar marginal
> speed _losses_ invoking more than one core for that work just as with
> this very simple example.
Parallel execution is useful only when the operation you want to run
takes enough time. Here, starting the workers takes more time than
computing the means. You should try with a larger number of replicates,
or a slower computation.


Regards

> TIA,
> 
> Chris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Sat Oct 17 19:28:12 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Oct 2015 10:28:12 -0700 (PDT)
Subject: [R] No speed up using the parallel package and ncpus > 1 with
 boot() on linux machines
In-Reply-To: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
References: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
Message-ID: <alpine.BSF.2.00.1510170945230.67112@pedal.dcn.davis.ca.us>

None of this is surprising. If the calculations you divide your work up 
into are small, then the overhead of communicating between parallel 
processes will be a relatively large penalty to pay.  You have to break 
your problem up into larger chunks and depend on vector processing within 
processes to keep the cpu busy doing useful work.

Also, I am not aware of any model of Mac Mini that has 8 physical cores... 
4 is the max. Virtual cores gain a logical simplification of 
multiprocessing but do not offer actual improved performance because 
there are only as many physical data paths and registers as there are 
cores.

Note that your problems are with long-running simulations... your examples 
are too small to demonstrate the actual balance of processing vs. 
communication overhead. Before you draw conclusions, try upping bootReps 
by a few orders of magnitude, and run your test code a couple 
of times to stabilize the memory conditions and obtain some consistency 
in timings.

I have never used the parallel option in the boot package before... I have 
always rolled my own to allow me to decide how much work to do within the 
worker processes before returning from them. (This is particularly severe 
when using snow, but not necessarily something you can neglect with 
multicore.)

On Sat, 17 Oct 2015, Chris Evans wrote:

> I think I am failing to understand how boot() uses the parallel package on linux machines, using R 3.2.2 on three different machines with 2, 4 and 8 cores all results in a slow down if I use "multicore" and "ncpus".  Here's the code that creates a very simple reproducible example:
>
> bootReps <- 500
> seed <- 12345
> set.seed(seed)
> require(boot)
> dat <- rnorm(500)
> bootMean <- function(dat,ind) {
>  mean(dat[ind])
> }
> start.time <- proc.time()
> bootDat <- boot(dat,bootMean,bootReps)
> boot.ci(bootDat,type="norm")
> stop.time <- proc.time()
> elapsed.time1 <- stop.time - start.time
> require(parallel)
> set.seed(seed)
> start.time <- proc.time()
> bootDat <- boot(dat,bootMean,bootReps,
>                parallel="multicore",
>                ncpus=2)
> boot.ci(bootDat,type="norm")
> stop.time <- proc.time()
> elapsed.time2 <- stop.time - start.time
> elapsed.time1
> elapsed.time2
>

> Running that on my old Dell Latitude E6500 running Debian Squeeze and 
> using 32 bit R 3.2.2 gives me:
>
>> bootReps <- 500
>> seed <- 12345
>> set.seed(seed)
>> require(boot)
>> dat <- rnorm(500)
>> bootMean <- function(dat,ind) {
> +   mean(dat[ind])
> + }
>> start.time <- proc.time()
>> bootDat <- boot(dat,bootMean,bootReps)
>> boot.ci(bootDat,type="norm")
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 500 bootstrap replicates
>
> CALL :
> boot.ci(boot.out = bootDat, type = "norm")
>
> Intervals :
> Level      Normal
> 95%   (-0.0034,  0.1677 )
> Calculations and Intervals on Original Scale
>> stop.time <- proc.time()
>> elapsed.time1 <- stop.time - start.time
>> require(parallel)
>> set.seed(seed)
>> start.time <- proc.time()
>> bootDat <- boot(dat,bootMean,bootReps,
> +                 parallel="multicore",
> +                 ncpus=2)
>> boot.ci(bootDat,type="norm")
> BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
> Based on 500 bootstrap replicates
>
> CALL :
> boot.ci(boot.out = bootDat, type = "norm")
>
> Intervals :
> Level      Normal
> 95%   (-0.0030,  0.1675 )
> Calculations and Intervals on Original Scale
>> stop.time <- proc.time()
>> elapsed.time2 <- stop.time - start.time
>> elapsed.time1
>   user  system elapsed
>  0.028   0.000   0.174
>> elapsed.time2
>   user  system elapsed
>  4.336   2.572   0.166
>
> A very slightly different 95% CI reflecting the way that invoking 
> parallel="multicore" changes the seed setting and a huge deterioration 
> in execution speed rather than any improvement.
>

> On a more recent four core Toshiba and using ncpus=4 again on Debian 
> Squeeze, 32bit R, I get exactly the same CIs and this timing:
>
>> elapsed.time1
> user system elapsed
> 0.032 0.000 0.100
>> elapsed.time2
> user system elapsed
> 0.032 0.020 0.049
>>
>
> and on a Mac Mini with eight cores on Squeeze but with 64bit R I get the 
> same CIs and this timing:
>
>> elapsed.time1
>   user  system elapsed
>  0.012   0.004   0.017
>> elapsed.time2
>   user  system elapsed
>  0.032   0.012   0.024
>
> I am clearly missing something, or perhaps something else is choking the work, not the CPU power, RAM?  I've tried searching for similar reports on the web and was surprised to find nothing using what seemed plausible search strategies.
>
> Anyone able to help me?  I'd desperately like to get a marked speed up for some simulation work I'm doing on the Mac mini as it's taking days to run at the moment.  The computational intensive bits in the models is a bit more complicated than this here (!) but most of the workload will be in the bootstrapping and the function I'm bootstrapping for real, although it's a bit more complex than a simple mean, isn't that complex though it does involve a stratified bootstrap rather than a simple one.  I see very similar marginal speed _losses_ invoking more than one core for that work just as with this very simple example.
>
> TIA,
>
> Chris
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From thpe at simecol.de  Sat Oct 17 22:19:22 2015
From: thpe at simecol.de (Thomas Petzoldt)
Date: Sat, 17 Oct 2015 22:19:22 +0200
Subject: [R] deSolve package
In-Reply-To: <045401d10775$ccbb73a0$66325ae0$@gmail.com>
References: <045401d10775$ccbb73a0$66325ae0$@gmail.com>
Message-ID: <5622AD4A.3060203@simecol.de>

Dear Andre,

some people would be happy to assist you, but your code fragment is 
incomplete, so diagnosing your problem was impossible. Please read the 
posting guide and provide a minimum reproducible example.

Furthermore I wonder why you use dede and not ode, and why sum() with 
empty parenthesis (that returns always zero).

Thomas Petzoldt

Am 10/15/2015 um 8:17 PM schrieb Andre Jackson:
> I have the following differential equations and return list:
>
> dCgd.dt = -kad*y[1]-kgd*y[1]     # PK model equation gut d
>
>    dCld.dt= kad*y[1]-rhyd-rmetd       #pk model equation liver d
>
>    dCgl.dt = -kal*y2[1]-kgl*y2[1]     # PK model equation gut l
>
>    dCll.dt= kal*y2[1]-rhyl-rmetl       #pk model equation liver l
>
>
>
>              # PK model equation
>
>    return(list(c(dCgd.dt,dCld.dt,dCgl.dt,dCll.dt),c(massbalance=sum())))
>
> }
>
>
>
> For the DDE solve I have :
>
> out = dede(y=y0,times=times,func=model.LIDR,parms=parms)
>
>
>
> This gives me the following error:
>
> Error in func(time, state, parms, ...) : object 'p' not found
>
>
>
> Can someone explain this error and its remedy?
>
> Andre Jackson
>
> Jacksonan1945 at gmail.com
>
> "You must be the change you wish the world to be"
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From chrishold at psyctc.org  Sun Oct 18 11:23:42 2015
From: chrishold at psyctc.org (Chris Evans)
Date: Sun, 18 Oct 2015 10:23:42 +0100 (BST)
Subject: [R] No speed up using the parallel package and ncpus > 1 with
 boot() on linux machines
In-Reply-To: <1445102020.16289.75.camel@club.fr>
References: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
	<1445102020.16289.75.camel@club.fr>
Message-ID: <1438031469.39825351.1445160222159.JavaMail.zimbra@psyctc.org>



----- Original Message -----
> From: "Milan Bouchet-Valat" <nalimilan at club.fr>
> To: "Chris Evans" <chrishold at psyctc.org>, r-help at r-project.org
> Sent: Saturday, 17 October, 2015 18:13:40
> Subject: Re: [R] No speed up using the parallel package and ncpus > 1 with boot() on linux machines

> Le samedi 17 octobre 2015 ? 17:18 +0100, Chris Evans a ?crit :
>> I think I am failing to understand how boot() uses the parallel
>> package on linux machines, using R 3.2.2 on three different machines
>> with 2, 4 and 8 cores all results in a slow down if I use "multicore"
>> and "ncpus".  Here's the code that creates a very simple reproducible
>> example:
... rest of my post deleted to save space ...

> Parallel execution is useful only when the operation you want to run
> takes enough time. Here, starting the workers takes more time than
> computing the means. You should try with a larger number of replicates,
> or a slower computation.
> 

Aha.  Makes perfect sense of course and explains what I'm seeing both for this and the real work which also involves bootstrapping a pretty simple function.

Merci Milan,

Chris


From chrishold at psyctc.org  Sun Oct 18 11:31:13 2015
From: chrishold at psyctc.org (Chris Evans)
Date: Sun, 18 Oct 2015 10:31:13 +0100 (BST)
Subject: [R] No speed up using the parallel package and ncpus > 1 with
 boot() on linux machines
In-Reply-To: <alpine.BSF.2.00.1510170945230.67112@pedal.dcn.davis.ca.us>
References: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
	<alpine.BSF.2.00.1510170945230.67112@pedal.dcn.davis.ca.us>
Message-ID: <1848341414.39825980.1445160673861.JavaMail.zimbra@psyctc.org>

As with Milan's answer: perfect explanation and hugely appreciated.  A few follow up questions/comments below.

----- Original Message -----
> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
> To: "Chris Evans" <chrishold at psyctc.org>
> Cc: r-help at r-project.org
> Sent: Saturday, 17 October, 2015 18:28:12
> Subject: Re: [R] No speed up using the parallel package and ncpus > 1 with boot() on linux machines

> None of this is surprising. If the calculations you divide your work up
> into are small, then the overhead of communicating between parallel
> processes will be a relatively large penalty to pay.  You have to break
> your problem up into larger chunks and depend on vector processing within
> processes to keep the cpu busy doing useful work.

Aha.  Got it!
 
> Also, I am not aware of any model of Mac Mini that has 8 physical cores...
> 4 is the max. Virtual cores gain a logical simplification of
> multiprocessing but do not offer actual improved performance because
> there are only as many physical data paths and registers as there are
> cores.

Ah.  Hadn't thought of that.  It's a machine I rent, I thought it was a mac mini.  detectCores() reports 8 but perhaps they are virtual cores. /proc/cpuinfo says the processor is an Intel(R) Core(TM) i7-3615QM CPU @ 2.30GHz and shows 8 cores but again ... perhaps they are virtual.  What's the best way to get a true core count?
 
> Note that your problems are with long-running simulations... your examples
> are too small to demonstrate the actual balance of processing vs.
> communication overhead. Before you draw conclusions, try upping bootReps
> by a few orders of magnitude, and run your test code a couple
> of times to stabilize the memory conditions and obtain some consistency
> in timings.

OK.  Good advice again but what you are saying, and the findings I had there, are pretty consistent with what I was seeing with long running things with bootReps up at 10k and I think you've told me what I really want to know.  I think the simplest way to parallelise may actually be fine for me: I'll run four (or maybe eight) separate R jobs (having a look at swapping to make sure I'm not pushing beyond physical RAM, don't think these simulations will.

> I have never used the parallel option in the boot package before... I have
> always rolled my own to allow me to decide how much work to do within the
> worker processes before returning from them. (This is particularly severe
> when using snow, but not necessarily something you can neglect with
> multicore.)

That sounds like an impressive and obviously pertinent approach.  I think, as I say, I may be able to get away with a very simple approach that runs parallel simulations and then aggregates the data from each and analyses that.

Many thanks Jeff.  Brilliant help.

Chris

 
> On Sat, 17 Oct 2015, Chris Evans wrote:
> 
>> I think I am failing to understand how boot() uses the parallel package on linux

... rest of my original post deleted to save space ...

 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From jacksonmrodrigues at gmail.com  Sun Oct 18 16:15:20 2015
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Sun, 18 Oct 2015 16:15:20 +0200
Subject: [R] How to plot shades between curves?
Message-ID: <CAPL76w9F0gecxfJVTv_pzTZo2Z+Lcd63mYigfONrZDSsVVdDMg@mail.gmail.com>

Dear all,

I have to compare several curves that range through different scales (x
axis) along the same time, so to make them comparable I brought all of them
to the same scale (x axis) and obviously kept the age axis (y axis) for all
of them.
As result, some variations (wiggles) simply disappeared (Figure on link
below, line Capa.diss) making impossible any interpretation. To deal with
such of problem, I plot the curve as it has to be in large scale (line
Capa.diss) and added a the same curve again on a secondary axis, but
exaggerating its values by a subjective factor of 0.7 (Capa.diss2).
Further, I want to fill the gap between both curves with some color.

Figure available on:
https://www.dropbox.com/s/dtcgk167mh9xykj/12120156_533366843482278_6929357065463452649_o.jpg?dl=0

My idea in doing it is: I have a plot in which the wiggles are "invisible",
to highlight these wiggles I projected a shadded curve of exaggerated data.

My question is: How to plot shades between curves?


Thank you all

Jackson Rodrigues

My codes are:

plot(Capa.diss,Capa.diss.age,ylim =
rev((range)(Capa.diss.age=c(min(Capa.diss.age),
10500))),xlim=(c(0,30)),type="l")
Capa.diss2<-Capa.diss*0.7
par(new=TRUE)
plot(Capa.diss2, Capa.diss.age, col='black',type="l",ylim =
rev((range)(Capa.diss.age=c(min(Capa.diss.age), 10500))),
xlim=(c(0,1)),xaxt="n",yaxt="n",xlab="",ylab="")

The following lline is the one I trying to use to fill the gap, but it is
not working.
polygon(c(Capa.diss.age,rev(Capa.diss.age)),c(Capa.diss2,rev(Capa.diss)),col="grey")


Date used:

Capa.diss<-c(0.7261102, 0.6655960, 0.5638357,0.8585834,0.6964527,0.8434504,
0.7106749,0.5981460,0.5747585,0.7347864,0.8012803,0.6826862,0.4949845,
0.5466870,0.5417343
,0.4774860,0.4814479,0.5254794,0.6236299,0.6575862,0.7047694,0.5550153,0.4499349,0.5939971,0.4138955,0.3659061,0.3126497,0.2476329,0.2503446,0.2686042,0.3036808,0.2747602,0.4221727,0.3935815,0.3942621,0.5821026,0.2251284,0.2670861,0.3580937,0.4239509,0.4010682,0.4104427,0.3666264,0.2555372,0.2995469,0.3985690,0.4304724,0.4136308,0.3525836,0.3898816,0.3517483,0.2924678,0.4807643,0.4471870,0.3694882,0.3970183,0.4827425,0.4766994,0.3391238,0.4153885,0.5502231,0.5330776,0.5867776,0.5195776,0.4882179,0.5298611,0.4626142)

Capa.diss.age<-c(2,152,302,452,602,752,902,1052,1202,1352,1502,1652,1802,1952,2102,2252,2402,2552,2702,2852,3002,3152,3302,3452,3602,3752,3902,4052,4202,4352,4502,4652,4802,4952,5102,5252,5402,5552,5702,5852,6002,6152,6302,6452,6602,6752,6902,7052,7202,7352,7502,7652,7802,7952,8102,8252,8402,8552,8702,8852,9002,9152,9302,9452,9602,9752,9902)

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Sun Oct 18 16:44:50 2015
From: btupper at bigelow.org (Ben Tupper)
Date: Sun, 18 Oct 2015 10:44:50 -0400
Subject: [R] How to plot shades between curves?
In-Reply-To: <CAPL76w9F0gecxfJVTv_pzTZo2Z+Lcd63mYigfONrZDSsVVdDMg@mail.gmail.com>
References: <CAPL76w9F0gecxfJVTv_pzTZo2Z+Lcd63mYigfONrZDSsVVdDMg@mail.gmail.com>
Message-ID: <96414EC7-D366-45C0-AFEF-346E2B0AB40B@bigelow.org>

Hi,

Thanks for the reproducible example!  (Don't forget to make your email client send text-only messages, not html, when sending to this list).

Would log scale work for you?


Capa.diss<-c(0.7261102, 0.6655960, 0.5638357,0.8585834,0.6964527,0.8434504, 0.7106749,0.5981460,0.5747585,0.7347864,0.8012803,0.6826862,0.4949845, 0.5466870,0.5417343,0.4774860,0.4814479,0.5254794,0.6236299,0.6575862,0.7047694,0.5550153,0.4499349,0.5939971,0.4138955,0.3659061,0.3126497,0.2476329,0.2503446,0.2686042,0.3036808,0.2747602,0.4221727,0.3935815,0.3942621,0.5821026,0.2251284,0.2670861,0.3580937,0.4239509,0.4010682,0.4104427,0.3666264,0.2555372,0.2995469,0.3985690,0.4304724,0.4136308,0.3525836,0.3898816,0.3517483,0.2924678,0.4807643,0.4471870,0.3694882,0.3970183,0.4827425,0.4766994,0.3391238,0.4153885,0.5502231,0.5330776,0.5867776,0.5195776,0.4882179,0.5298611,0.4626142)

Capa.diss.age<-c(2,152,302,452,602,752,902,1052,1202,1352,1502,1652,1802,1952,2102,2252,2402,2552,2702,2852,3002,3152,3302,3452,3602,3752,3902,4052,4202,4352,4502,4652,4802,4952,5102,5252,5402,5552,5702,5852,6002,6152,6302,6452,6602,6752,6902,7052,7202,7352,7502,7652,7802,7952,8102,8252,8402,8552,8702,8852,9002,9152,9302,9452,9602,9752,9902)

plot(Capa.diss,Capa.diss.age,
    ylim = c(0,10500),
    xlim = pmax(range(Capa.diss), c(0.1, 30)),
    type="l",
    log = 'x')

Note that pmax() is selecting the maximum of each element in the two input vectors - you might want something different


Cheers,
Ben


On Oct 18, 2015, at 10:15 AM, Jackson Rodrigues <jacksonmrodrigues at gmail.com> wrote:

> Dear all,
> 
> I have to compare several curves that range through different scales (x
> axis) along the same time, so to make them comparable I brought all of them
> to the same scale (x axis) and obviously kept the age axis (y axis) for all
> of them.
> As result, some variations (wiggles) simply disappeared (Figure on link
> below, line Capa.diss) making impossible any interpretation. To deal with
> such of problem, I plot the curve as it has to be in large scale (line
> Capa.diss) and added a the same curve again on a secondary axis, but
> exaggerating its values by a subjective factor of 0.7 (Capa.diss2).
> Further, I want to fill the gap between both curves with some color.
> 
> Figure available on:
> https://www.dropbox.com/s/dtcgk167mh9xykj/12120156_533366843482278_6929357065463452649_o.jpg?dl=0
> 
> My idea in doing it is: I have a plot in which the wiggles are "invisible",
> to highlight these wiggles I projected a shadded curve of exaggerated data.
> 
> My question is: How to plot shades between curves?
> 
> 
> Thank you all
> 
> Jackson Rodrigues
> 
> My codes are:
> 
> plot(Capa.diss,Capa.diss.age,ylim =
> rev((range)(Capa.diss.age=c(min(Capa.diss.age),
> 10500))),xlim=(c(0,30)),type="l")
> Capa.diss2<-Capa.diss*0.7
> par(new=TRUE)
> plot(Capa.diss2, Capa.diss.age, col='black',type="l",ylim =
> rev((range)(Capa.diss.age=c(min(Capa.diss.age), 10500))),
> xlim=(c(0,1)),xaxt="n",yaxt="n",xlab="",ylab="")
> 
> The following lline is the one I trying to use to fill the gap, but it is
> not working.
> polygon(c(Capa.diss.age,rev(Capa.diss.age)),c(Capa.diss2,rev(Capa.diss)),col="grey")
> 
> 
> Date used:
> 
> Capa.diss<-c(0.7261102, 0.6655960, 0.5638357,0.8585834,0.6964527,0.8434504,
> 0.7106749,0.5981460,0.5747585,0.7347864,0.8012803,0.6826862,0.4949845,
> 0.5466870,0.5417343
> ,0.4774860,0.4814479,0.5254794,0.6236299,0.6575862,0.7047694,0.5550153,0.4499349,0.5939971,0.4138955,0.3659061,0.3126497,0.2476329,0.2503446,0.2686042,0.3036808,0.2747602,0.4221727,0.3935815,0.3942621,0.5821026,0.2251284,0.2670861,0.3580937,0.4239509,0.4010682,0.4104427,0.3666264,0.2555372,0.2995469,0.3985690,0.4304724,0.4136308,0.3525836,0.3898816,0.3517483,0.2924678,0.4807643,0.4471870,0.3694882,0.3970183,0.4827425,0.4766994,0.3391238,0.4153885,0.5502231,0.5330776,0.5867776,0.5195776,0.4882179,0.5298611,0.4626142)
> 
> Capa.diss.age<-c(2,152,302,452,602,752,902,1052,1202,1352,1502,1652,1802,1952,2102,2252,2402,2552,2702,2852,3002,3152,3302,3452,3602,3752,3902,4052,4202,4352,4502,4652,4802,4952,5102,5252,5402,5552,5702,5852,6002,6152,6302,6452,6602,6752,6902,7052,7202,7352,7502,7652,7802,7952,8102,8252,8402,8552,8702,8852,9002,9152,9302,9452,9602,9752,9902)
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From jonathanreardon at outlook.com  Sun Oct 18 19:48:14 2015
From: jonathanreardon at outlook.com (Jonathan Reardon)
Date: Sun, 18 Oct 2015 18:48:14 +0100
Subject: [R] Replace NaN with value from the same row
Message-ID: <DUB125-W26E5BED19C0BF76F015F5FA43B0@phx.gbl>

Hi everyone,
A simple question, but i cannot figure this out.

I have a data-frame with 4 columns (onset, offset, outcome, mean):
 onset offset outcome   mean8   72071  72503       1  7244615 142598 143030       1    NaN30 293729 294161       1 294080
For each 'NaN' in the mean column, i want to replace that NaN with the 'offset' value in the same row.
Intended outcome: 
 onset offset outcome   mean8   72071  72503       1  7244615 142598 143030       1    14303030 293729 294161       1 294080
I have tried:
 df$mean <- replace(df$mean, is.na(df$mean), df$offset)
but i get the error message: 'number of items to replace is not a multiple of replacement length'. I'm assuming because this is trying to insert the whole 'offset' column into my one NaN cell. Is this a correct interpretation of the error message?
Can anyone tell me how to replace any mean row NaN's  with the offset value from that very same row?
I don't want to use any pasting etc as this needs to be used as part of a function working over a large dataset than the one shown here.
Cheers
Jonathan 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Oct 18 20:06:44 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 18 Oct 2015 11:06:44 -0700
Subject: [R] Replace NaN with value from the same row
In-Reply-To: <DUB125-W26E5BED19C0BF76F015F5FA43B0@phx.gbl>
References: <DUB125-W26E5BED19C0BF76F015F5FA43B0@phx.gbl>
Message-ID: <FD446749-509C-4C34-ACBF-8BA15EC07871@dcn.davis.CA.us>

Next time send your email using plain text format rather than HTML so we see what you saw.

Try 

idx <- is.na( df$mean )
df[ idx, "mean" ] <- df[ idx, "offset" ]

BTW there is a commonly-used function called df, so you might improve clarity by using DF for your temporary data frame name.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 18, 2015 10:48:14 AM PDT, Jonathan Reardon <jonathanreardon at outlook.com> wrote:
>Hi everyone,
>A simple question, but i cannot figure this out.
>
>I have a data-frame with 4 columns (onset, offset, outcome, mean):
>onset offset outcome   mean8   72071  72503       1  7244615 142598
>143030       1    NaN30 293729 294161       1 294080
>For each 'NaN' in the mean column, i want to replace that NaN with the
>'offset' value in the same row.
>Intended outcome: 
>onset offset outcome   mean8   72071  72503       1  7244615 142598
>143030       1    14303030 293729 294161       1 294080
>I have tried:
> df$mean <- replace(df$mean, is.na(df$mean), df$offset)
>but i get the error message: 'number of items to replace is not a
>multiple of replacement length'. I'm assuming because this is trying to
>insert the whole 'offset' column into my one NaN cell. Is this a
>correct interpretation of the error message?
>Can anyone tell me how to replace any mean row NaN's  with the offset
>value from that very same row?
>I don't want to use any pasting etc as this needs to be used as part of
>a function working over a large dataset than the one shown here.
>Cheers
>Jonathan 		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jonathanreardon at outlook.com  Sun Oct 18 20:11:32 2015
From: jonathanreardon at outlook.com (Jonathan Reardon)
Date: Sun, 18 Oct 2015 19:11:32 +0100
Subject: [R] Replace NaN from 1 column with a value from the same row
Message-ID: <DUB125-W281596F61D0AA41B073BF3A43B0@phx.gbl>

Hi everyone,
Ignore my previous post, i realised that the rows and columns i typed into the email were unreadable, sincere apologies for this.
A simple question, but i cannot figure this out.
I have a data-frame with 4 columns (onset, offset, outcome, mean):
df<-data.frame(onset=c(72071,142598,293729), offset=c(72503,143030,294161), outcome=c(1,1,1), mean=c(7244615,NaN,294080))
For each 'NaN' in the mean column, i want to replace that NaN with the 'offset' value in the same row. I tried:
df$mean <- replace(df$mean, is.na(df$mean), df$offset)
but i get the error message: 'number of items to replace is not a multiple of replacement length'. I'm assuming because this is trying to insert the whole 'offset' column into my one NaN cell. Is this a correct interpretation of the error message?
Can anyone tell me how to replace any mean row NaN's with the offset value from that very same row?I don't want to use any pasting etc as this needs to be used as part of a function working over a larger data set than the one shown here.
CheersJonathan  		 	   		  
	[[alternative HTML version deleted]]


From antoviral at gmail.com  Sun Oct 18 21:07:30 2015
From: antoviral at gmail.com (Antonello Preti)
Date: Sun, 18 Oct 2015 21:07:30 +0200
Subject: [R] Problem with custom.model.names in plotreg (texreg)
Message-ID: <CAPmpGDscr8RECh8rGLQL_eUq3Y1ZuspKOr8RSNnXjNwoYeeKTA@mail.gmail.com>

Hi, I need some advice.

I'm using the package 'texreg' to extract effects in a multinomial model.

While using the 'plotreg' command I've got a problem with the subcommand
'custom.model.names'.
I'm able to have this subcommand working with the 'screenreg' command.
However, when I use the subcommand 'custom.model.names' with the 'plotreg'
command, an error is what I get.

Is there any way to have the proper name of the models?
I do not like the, rather ugly, default naming ('Model 1', Model 2' and so
on).


Thank you in advance,
Antonello Preti


Here some code for exemplification. It is a very elementary model with the
'iris' dataset.

### the data

data(iris)
dim(iris)
str(iris)


### Polytomous (multinomial) logit model

library(nnet)
mod.mn <- multinom(Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width , data = iris)

summary(mod.mn, cor=FALSE)


### coefficients

print(t(summary(mod.mn)$coefficients))

### standard errors

print(t(summary(mod.mn)$standard.errors))



#################################
#### summary of results
#################################

library(texreg)

### custom.model.names OK

screenreg(mod.mn, custom.model.names = c("versicolor", "virginica"))


### custom.model.names giving error

plotreg(mod.mn, custom.model.names = c("versicolor", "virginica"))

### Error in plotreg(mod.mn, custom.model.names = c("versicolor",
"virginica")) :
###  The 'custom.model.names' argument must have the same length as the 'l'
argument.



## sessionInfo()
## R version 3.0.2 (2013-09-25)
## Platform: x86_64-w64-mingw32/x64 (64-bit)

## locale:
## [1] LC_COLLATE=Italian_Italy.1252  LC_CTYPE=Italian_Italy.1252
## [3] LC_MONETARY=Italian_Italy.1252 LC_NUMERIC=C
## [5] LC_TIME=Italian_Italy.1252

## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base

## other attached packages:
## [1] texreg_1.34 nnet_7.3-7

## loaded via a namespace (and not attached):
## [1] tools_3.0.2

	[[alternative HTML version deleted]]


From puetz at psych.mpg.de  Sun Oct 18 16:29:39 2015
From: puetz at psych.mpg.de (=?utf-8?Q?Benno_P=C3=BCtz?=)
Date: Sun, 18 Oct 2015 16:29:39 +0200
Subject: [R] How to plot shades between curves?
In-Reply-To: <CAPL76w9F0gecxfJVTv_pzTZo2Z+Lcd63mYigfONrZDSsVVdDMg@mail.gmail.com>
References: <CAPL76w9F0gecxfJVTv_pzTZo2Z+Lcd63mYigfONrZDSsVVdDMg@mail.gmail.com>
Message-ID: <BAE62FD2-7226-4566-AC25-278974AC886D@psych.mpg.de>


> 
> plot(Capa.diss,Capa.diss.age,ylim =
> rev((range)(Capa.diss.age=c(min(Capa.diss.age),
> 10500))),xlim=(c(0,30)),type="l")
> Capa.diss2<-Capa.diss*0.7
> par(new=TRUE)
> plot(Capa.diss2, Capa.diss.age, col='black',type="l",ylim =
> rev((range)(Capa.diss.age=c(min(Capa.diss.age), 10500))),
> xlim=(c(0,1)),xaxt="n",yaxt="n",xlab="",ylab="")
> 
> The following lline is the one I trying to use to fill the gap, but it is
> not working.
> polygon(c(Capa.diss.age,rev(Capa.diss.age)),c(Capa.diss2,rev(Capa.diss)),col="grey")
> 
Comparing this line with the code above I get the impression that you have the wrong order in your coordinates (x and y switched) - you plot way outside your [xy]lims and thus won?t see anything. 
Otherwise your approach seems OK

Benno

From christian at echoffmann.ch  Sun Oct 18 17:51:13 2015
From: christian at echoffmann.ch (Christian Hoffmann)
Date: Sun, 18 Oct 2015 17:51:13 +0200
Subject: [R] value of variable in ls()
Message-ID: <5623BFF1.3040702@echoffmann.ch>

This may seem trivial:

ls() gives me names of variables as a character vector. How can I print 
the values 'behind' those character values:

ls()
 > "a"
 > a
[1] 5

How can I do e.g. print("unknown"(ls())) and get the variable values in 
my current environment?

-- 
Christian W. Hoffmann
CH - 8915 Hausen am Albis, Schweiz
Rigiblickstrasse 15 b, Tel.+41-44-7640853
mailto: christian at echoffmann.ch
home: www.echoffmann.ch


From babak.shojaeirani at wur.nl  Sun Oct 18 16:08:10 2015
From: babak.shojaeirani at wur.nl (Shojaei Arani, Mohammad)
Date: Sun, 18 Oct 2015 14:08:10 +0000
Subject: [R] A question about SDE package
Message-ID: <fec57f1049c94ffa8c4bc9353a694da4@scomp5294.wurnet.nl>


Hello Friends,


I am trying to use the functions ksdrift and ksdiff both in SDE package. Unfortunately. It does not work for my data (attached). The following code shows how I tried to use it:




setwd("D:/Mohammad/Different/New folder")
mydata <- read.csv("Best.csv", header=FALSE)
myts<-ts(mydata,start=c(0, 1), end=c(523, 1), frequency=1)

X<-myts
set.seed(123)
theta <- c(-2026651,-146668.995,-3531.84,-28.3,-46740,-2238,-26.57)
b <- function(x)
theta[1]+theta[2]*x+theta[3]*x^2+theta[4]*x^3
sigma <- function(x)
theta[5]+theta[6]*x+theta[7]*x^2
minX <- min(X)
maxX <- max(X)
par(mfrow=c(2,1))
curve(b,minX, maxX)
lines(ksdrift(X))
curve(sigma,minX, maxX)
lines(ksdiff(X))

Although I do not get any error message I do not get any solution to my problem.

I would be very grateful if any of you can help me on this.

Kind regards,

Babak,

Wageningen University

From islahna at gmail.com  Sun Oct 18 13:56:02 2015
From: islahna at gmail.com (islah na)
Date: Sun, 18 Oct 2015 19:56:02 +0800
Subject: [R] R package related to solving calibration transfer problem
Message-ID: <CAO9sQAg-j6fzWgNb5ej5DHDZfqpPsmHDCsq1feiOPugigG3Zdg@mail.gmail.com>

Hi,
I'm new to R (and also chemometrics). I have problem using same
calibration model on spectrums obtained from two spectrometers of same
brand. There's little different in the wavelength, less than 1 nm
though and also different in their intensity level. What i understand, this
problem is a calibration transfer problem. I would like to know if there
exist any R package I can use for solving this kind of problem. Appreciate
any help.

thanks,
--islahna

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Oct 18 21:16:38 2015
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Sun, 18 Oct 2015 20:16:38 +0100
Subject: [R] value of variable in ls()
In-Reply-To: <5623BFF1.3040702@echoffmann.ch>
Message-ID: <20151018201638.Horde.XppJW-INmKMxjXV4MmCubkw@mail.sapo.pt>

Hello,

I'm not sure I understand, but something like this?

a <- 5
get("a")

See ?get
Hope this helps,

Rui Barradas
?

Citando Christian Hoffmann <christian at echoffmann.ch>:

> This may seem trivial:
>
> ls() gives me names of variables as a character vector. How can I print
> the values 'behind' those character values:
>
> ls()
>> "a"
>> a
>
> [1] 5
>
> How can I do e.g. print("unknown"(ls())) and get the variable values in
> my current environment?
>
> --
> Christian W. Hoffmann
> CH - 8915 Hausen am Albis, Schweiz
> Rigiblickstrasse 15 b, Tel.+41-44-7640853
> mailto: christian at echoffmann.ch
> home: www.echoffmann.ch[1]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.htmland provide commented,
> minimal, self-contained, reproducible code.

?

Liga??es:
---------
[1] http://www.echoffmann.ch

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sun Oct 18 21:26:08 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 18 Oct 2015 12:26:08 -0700
Subject: [R] Replace NaN with value from the same row
In-Reply-To: <DUB125-W18232E2E95E548BE1E901AA43B0@phx.gbl>
References: <DUB125-W26E5BED19C0BF76F015F5FA43B0@phx.gbl>,
	<FD446749-509C-4C34-ACBF-8BA15EC07871@dcn.davis.CA.us>
	<DUB125-W18232E2E95E548BE1E901AA43B0@phx.gbl>
Message-ID: <37EEB0CA-5017-4112-B323-E66568163EF6@dcn.davis.CA.us>

Please reply to all so the answers are seen on the mailing list, where my mistakes can be corrected and others can learn from any valid answers I manage to provide.

I warned you that df is the name of a common function. I used the name of the variable that you referred to in your question, which had hidden the common function called df. I would guess that you have not re-created the variables in R as you had them defined before.

To keep your mind clear on what R is thinking, learn to use the ls and str functions. Read about them using the help system:

?ls
?str

I think that

str(df)

tells you that df is a function, rather than a data.frame. If you create a variable called df like so:

df <- data.frame( test=5 )

or using any other function that gives you a data frame such as read.csv, then the df function in the base stats package will be hidden and

str(df)

will give you a different result.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 18, 2015 11:29:51 AM PDT, Jonathan Reardon <jonathanreardon at outlook.com> wrote:
>How do i send an email in plain text format and not HTML?
>I tried:
>idx <- is.na( df$mean )
>df[ idx, "mean" ] <- df[ idx, "offset" ]
>I got the error message:
>In is.na(df$mean) : is.na() applied to non-(list or vector) of type
>'NULL'
>Jon
>
>> Subject: Re: [R] Replace NaN with value from the same row
>> From: jdnewmil at dcn.davis.CA.us
>> Date: Sun, 18 Oct 2015 11:06:44 -0700
>> To: jonathanreardon at outlook.com; r-help at r-project.org
>> 
>> Next time send your email using plain text format rather than HTML so
>we see what you saw.
>> 
>> Try 
>> 
>> idx <- is.na( df$mean )
>> df[ idx, "mean" ] <- df[ idx, "offset" ]
>> 
>> BTW there is a commonly-used function called df, so you might improve
>clarity by using DF for your temporary data frame name.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> On October 18, 2015 10:48:14 AM PDT, Jonathan Reardon
><jonathanreardon at outlook.com> wrote:
>> >Hi everyone,
>> >A simple question, but i cannot figure this out.
>> >
>> >I have a data-frame with 4 columns (onset, offset, outcome, mean):
>> >onset offset outcome   mean8   72071  72503       1  7244615 142598
>> >143030       1    NaN30 293729 294161       1 294080
>> >For each 'NaN' in the mean column, i want to replace that NaN with
>the
>> >'offset' value in the same row.
>> >Intended outcome: 
>> >onset offset outcome   mean8   72071  72503       1  7244615 142598
>> >143030       1    14303030 293729 294161       1 294080
>> >I have tried:
>> > df$mean <- replace(df$mean, is.na(df$mean), df$offset)
>> >but i get the error message: 'number of items to replace is not a
>> >multiple of replacement length'. I'm assuming because this is trying
>to
>> >insert the whole 'offset' column into my one NaN cell. Is this a
>> >correct interpretation of the error message?
>> >Can anyone tell me how to replace any mean row NaN's  with the
>offset
>> >value from that very same row?
>> >I don't want to use any pasting etc as this needs to be used as part
>of
>> >a function working over a large dataset than the one shown here.
>> >Cheers
>> >Jonathan 		 	   		  
>> >	[[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>> 
>


From jdnewmil at dcn.davis.CA.us  Sun Oct 18 21:55:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 18 Oct 2015 12:55:14 -0700
Subject: [R] Replace NaN with value from the same row
In-Reply-To: <DUB125-W692B1068C8ECB4A4930A9CA43B0@phx.gbl>
References: <DUB125-W26E5BED19C0BF76F015F5FA43B0@phx.gbl>,
	<FD446749-509C-4C34-ACBF-8BA15EC07871@dcn.davis.CA.us>
	<DUB125-W18232E2E95E548BE1E901AA43B0@phx.gbl>,
	<D52E5E4D-35BF-4641-8135-E79722B84247@dcn.davis.CA.us>
	<DUB125-W692B1068C8ECB4A4930A9CA43B0@phx.gbl>
Message-ID: <08444A19-A378-4812-A0B4-0E25FA148777@dcn.davis.CA.us>

You should (re-)read the intro document that comes with R, "An Introduction to R". Pay particular attention to sections 2., 2.7, and 5.2.

The "idx" variable that I defined is a vector in the current environment (in your case apparently a local function environment). It is not a column in your data frame. You should look at it using the str function. (You might need to print the result of str, or use the debug capability of R to single-step through your function and then use str. Read the help at ?debug.)

The df[ idx, "offset" ] notation uses the logical indexing and string indexing concepts in section 2.7 to select a subset of the rows and one column of the data frame.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 18, 2015 12:24:42 PM PDT, Jonathan Reardon <jonathanreardon at outlook.com> wrote:
>Hi, Sorry to be a pain. Would you be kind enough to briefly explain
>what the lines are doing?
>From what i can gather, 'idx <- is.na( df$mean )' is making a new
>column called 'idx', finds the NaN values and inserts the boolean TRUE
>in the respective cell.
>df[ idx, "mean" ] <- df[ idx, "offset" ]      << i am unsure what this
>is doing exactly.
>Jon
>
>
>> Subject: RE: [R] Replace NaN with value from the same row
>> From: jdnewmil at dcn.davis.CA.us
>> Date: Sun, 18 Oct 2015 12:09:02 -0700
>> To: jonathanreardon at outlook.com
>> 
>> The Posting Guide mentioned at the bottom of every email in the list
>tells you that such an option is in your email software, which I know
>nothing about. Most software lets you choose the format as part of
>composing each email, but some software will let you set a default
>format to use for each email address (so all your emails to e.g.
>r-help at r-project.org will be plain text).
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> On October 18, 2015 11:29:51 AM PDT, Jonathan Reardon
><jonathanreardon at outlook.com> wrote:
>> >How do i send an email in plain text format and not HTML?
>> >I tried:
>> >idx <- is.na( df$mean )
>> >df[ idx, "mean" ] <- df[ idx, "offset" ]
>> >I got the error message:
>> >In is.na(df$mean) : is.na() applied to non-(list or vector) of type
>> >'NULL'
>> >Jon
>> >
>> >> Subject: Re: [R] Replace NaN with value from the same row
>> >> From: jdnewmil at dcn.davis.CA.us
>> >> Date: Sun, 18 Oct 2015 11:06:44 -0700
>> >> To: jonathanreardon at outlook.com; r-help at r-project.org
>> >> 
>> >> Next time send your email using plain text format rather than HTML
>so
>> >we see what you saw.
>> >> 
>> >> Try 
>> >> 
>> >> idx <- is.na( df$mean )
>> >> df[ idx, "mean" ] <- df[ idx, "offset" ]
>> >> 
>> >> BTW there is a commonly-used function called df, so you might
>improve
>> >clarity by using DF for your temporary data frame name.
>> >>
>>
>>---------------------------------------------------------------------------
>> >> Jeff Newmiller                        The     .....       ..... 
>Go
>> >Live...
>> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>> >Go...
>> >>                                       Live:   OO#.. Dead: OO#.. 
>> >Playing
>> >> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>> >> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> >rocks...1k
>> >>
>>
>>---------------------------------------------------------------------------
>> >
>> >> Sent from my phone. Please excuse my brevity.
>> >> 
>> >> On October 18, 2015 10:48:14 AM PDT, Jonathan Reardon
>> ><jonathanreardon at outlook.com> wrote:
>> >> >Hi everyone,
>> >> >A simple question, but i cannot figure this out.
>> >> >
>> >> >I have a data-frame with 4 columns (onset, offset, outcome,
>mean):
>> >> >onset offset outcome   mean8   72071  72503       1  7244615
>142598
>> >> >143030       1    NaN30 293729 294161       1 294080
>> >> >For each 'NaN' in the mean column, i want to replace that NaN
>with
>> >the
>> >> >'offset' value in the same row.
>> >> >Intended outcome: 
>> >> >onset offset outcome   mean8   72071  72503       1  7244615
>142598
>> >> >143030       1    14303030 293729 294161       1 294080
>> >> >I have tried:
>> >> > df$mean <- replace(df$mean, is.na(df$mean), df$offset)
>> >> >but i get the error message: 'number of items to replace is not a
>> >> >multiple of replacement length'. I'm assuming because this is
>trying
>> >to
>> >> >insert the whole 'offset' column into my one NaN cell. Is this a
>> >> >correct interpretation of the error message?
>> >> >Can anyone tell me how to replace any mean row NaN's  with the
>> >offset
>> >> >value from that very same row?
>> >> >I don't want to use any pasting etc as this needs to be used as
>part
>> >of
>> >> >a function working over a large dataset than the one shown here.
>> >> >Cheers
>> >> >Jonathan 		 	   		  
>> >> >	[[alternative HTML version deleted]]
>> >> >
>> >> >______________________________________________
>> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >PLEASE do read the posting guide
>> >> >http://www.R-project.org/posting-guide.html
>> >> >and provide commented, minimal, self-contained, reproducible
>code.
>> >> 
>> > 		 	   		  
>> 
>


From jonathanreardon at outlook.com  Sun Oct 18 21:59:45 2015
From: jonathanreardon at outlook.com (Jonathan Reardon)
Date: Sun, 18 Oct 2015 20:59:45 +0100
Subject: [R] Replace NaN with value from the same row
In-Reply-To: <08444A19-A378-4812-A0B4-0E25FA148777@dcn.davis.CA.us>
References: <DUB125-W26E5BED19C0BF76F015F5FA43B0@phx.gbl>,
	<FD446749-509C-4C34-ACBF-8BA15EC07871@dcn.davis.CA.us>
	<DUB125-W18232E2E95E548BE1E901AA43B0@phx.gbl>,
	<D52E5E4D-35BF-4641-8135-E79722B84247@dcn.davis.CA.us>
	<DUB125-W692B1068C8ECB4A4930A9CA43B0@phx.gbl>,
	<08444A19-A378-4812-A0B4-0E25FA148777@dcn.davis.CA.us>
Message-ID: <DUB125-W935920730816547EF40994A43B0@phx.gbl>

Ok, i will do, thanks for your help.
J

> Subject: RE: [R] Replace NaN with value from the same row
> From: jdnewmil at dcn.davis.CA.us
> Date: Sun, 18 Oct 2015 12:55:14 -0700
> To: jonathanreardon at outlook.com
> CC: r-help at r-project.org
> 
> You should (re-)read the intro document that comes with R, "An Introduction to R". Pay particular attention to sections 2., 2.7, and 5.2.
> 
> The "idx" variable that I defined is a vector in the current environment (in your case apparently a local function environment). It is not a column in your data frame. You should look at it using the str function. (You might need to print the result of str, or use the debug capability of R to single-step through your function and then use str. Read the help at ?debug.)
> 
> The df[ idx, "offset" ] notation uses the logical indexing and string indexing concepts in section 2.7 to select a subset of the rows and one column of the data frame.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 18, 2015 12:24:42 PM PDT, Jonathan Reardon <jonathanreardon at outlook.com> wrote:
> >Hi, Sorry to be a pain. Would you be kind enough to briefly explain
> >what the lines are doing?
> >From what i can gather, 'idx <- is.na( df$mean )' is making a new
> >column called 'idx', finds the NaN values and inserts the boolean TRUE
> >in the respective cell.
> >df[ idx, "mean" ] <- df[ idx, "offset" ]      << i am unsure what this
> >is doing exactly.
> >Jon
> >
> >
> >> Subject: RE: [R] Replace NaN with value from the same row
> >> From: jdnewmil at dcn.davis.CA.us
> >> Date: Sun, 18 Oct 2015 12:09:02 -0700
> >> To: jonathanreardon at outlook.com
> >> 
> >> The Posting Guide mentioned at the bottom of every email in the list
> >tells you that such an option is in your email software, which I know
> >nothing about. Most software lets you choose the format as part of
> >composing each email, but some software will let you set a default
> >format to use for each email address (so all your emails to e.g.
> >r-help at r-project.org will be plain text).
> >>
> >---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go
> >Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >Go...
> >>                                       Live:   OO#.. Dead: OO#.. 
> >Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#. 
> >rocks...1k
> >>
> >---------------------------------------------------------------------------
> >
> >> Sent from my phone. Please excuse my brevity.
> >> 
> >> On October 18, 2015 11:29:51 AM PDT, Jonathan Reardon
> ><jonathanreardon at outlook.com> wrote:
> >> >How do i send an email in plain text format and not HTML?
> >> >I tried:
> >> >idx <- is.na( df$mean )
> >> >df[ idx, "mean" ] <- df[ idx, "offset" ]
> >> >I got the error message:
> >> >In is.na(df$mean) : is.na() applied to non-(list or vector) of type
> >> >'NULL'
> >> >Jon
> >> >
> >> >> Subject: Re: [R] Replace NaN with value from the same row
> >> >> From: jdnewmil at dcn.davis.CA.us
> >> >> Date: Sun, 18 Oct 2015 11:06:44 -0700
> >> >> To: jonathanreardon at outlook.com; r-help at r-project.org
> >> >> 
> >> >> Next time send your email using plain text format rather than HTML
> >so
> >> >we see what you saw.
> >> >> 
> >> >> Try 
> >> >> 
> >> >> idx <- is.na( df$mean )
> >> >> df[ idx, "mean" ] <- df[ idx, "offset" ]
> >> >> 
> >> >> BTW there is a commonly-used function called df, so you might
> >improve
> >> >clarity by using DF for your temporary data frame name.
> >> >>
> >>
> >>---------------------------------------------------------------------------
> >> >> Jeff Newmiller                        The     .....       ..... 
> >Go
> >> >Live...
> >> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
> >Live
> >> >Go...
> >> >>                                       Live:   OO#.. Dead: OO#.. 
> >> >Playing
> >> >> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
> >with
> >> >> /Software/Embedded Controllers)               .OO#.       .OO#. 
> >> >rocks...1k
> >> >>
> >>
> >>---------------------------------------------------------------------------
> >> >
> >> >> Sent from my phone. Please excuse my brevity.
> >> >> 
> >> >> On October 18, 2015 10:48:14 AM PDT, Jonathan Reardon
> >> ><jonathanreardon at outlook.com> wrote:
> >> >> >Hi everyone,
> >> >> >A simple question, but i cannot figure this out.
> >> >> >
> >> >> >I have a data-frame with 4 columns (onset, offset, outcome,
> >mean):
> >> >> >onset offset outcome   mean8   72071  72503       1  7244615
> >142598
> >> >> >143030       1    NaN30 293729 294161       1 294080
> >> >> >For each 'NaN' in the mean column, i want to replace that NaN
> >with
> >> >the
> >> >> >'offset' value in the same row.
> >> >> >Intended outcome: 
> >> >> >onset offset outcome   mean8   72071  72503       1  7244615
> >142598
> >> >> >143030       1    14303030 293729 294161       1 294080
> >> >> >I have tried:
> >> >> > df$mean <- replace(df$mean, is.na(df$mean), df$offset)
> >> >> >but i get the error message: 'number of items to replace is not a
> >> >> >multiple of replacement length'. I'm assuming because this is
> >trying
> >> >to
> >> >> >insert the whole 'offset' column into my one NaN cell. Is this a
> >> >> >correct interpretation of the error message?
> >> >> >Can anyone tell me how to replace any mean row NaN's  with the
> >> >offset
> >> >> >value from that very same row?
> >> >> >I don't want to use any pasting etc as this needs to be used as
> >part
> >> >of
> >> >> >a function working over a large dataset than the one shown here.
> >> >> >Cheers
> >> >> >Jonathan 		 	   		  
> >> >> >	[[alternative HTML version deleted]]
> >> >> >
> >> >> >______________________________________________
> >> >> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> >https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >PLEASE do read the posting guide
> >> >> >http://www.R-project.org/posting-guide.html
> >> >> >and provide commented, minimal, self-contained, reproducible
> >code.
> >> >> 
> >> > 		 	   		  
> >> 
> > 		 	   		  
> 
 		 	   		  
	[[alternative HTML version deleted]]


From jholtman at gmail.com  Sun Oct 18 22:01:33 2015
From: jholtman at gmail.com (jim holtman)
Date: Sun, 18 Oct 2015 16:01:33 -0400
Subject: [R] value of variable in ls()
In-Reply-To: <20151018201638.Horde.XppJW-INmKMxjXV4MmCubkw@mail.sapo.pt>
References: <5623BFF1.3040702@echoffmann.ch>
	<20151018201638.Horde.XppJW-INmKMxjXV4MmCubkw@mail.sapo.pt>
Message-ID: <CAAxdm-6BDKUkcFXKrT9hgqxcBXEoputJ+AcnK5CeeyF107KF5g@mail.gmail.com>

Is this what you want::

> a <- 1
> b <- 2
> # get current objects
> x <- ls()
> # create list of values
> my_list <- lapply(x, get)
> # now add the names
> names(my_list) <- x
> my_list  # print values
$a
[1] 1
$b
[1] 2



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Sun, Oct 18, 2015 at 3:16 PM, <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> I'm not sure I understand, but something like this?
>
> a <- 5
> get("a")
>
> See ?get
> Hope this helps,
>
> Rui Barradas
>
>
> Citando Christian Hoffmann <christian at echoffmann.ch>:
>
> > This may seem trivial:
> >
> > ls() gives me names of variables as a character vector. How can I print
> > the values 'behind' those character values:
> >
> > ls()
> >> "a"
> >> a
> >
> > [1] 5
> >
> > How can I do e.g. print("unknown"(ls())) and get the variable values in
> > my current environment?
> >
> > --
> > Christian W. Hoffmann
> > CH - 8915 Hausen am Albis, Schweiz
> > Rigiblickstrasse 15 b, Tel.+41-44-7640853
> > mailto: christian at echoffmann.ch
> > home: www.echoffmann.ch[1]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.htmland provide commented,
> > minimal, self-contained, reproducible code.
>
>
>
> Liga??es:
> ---------
> [1] http://www.echoffmann.ch
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sheroukmoawad at yahoo.com  Sun Oct 18 23:03:34 2015
From: sheroukmoawad at yahoo.com (Sherouk Moawad)
Date: Sun, 18 Oct 2015 21:03:34 +0000 (UTC)
Subject: [R] condition in triple summation
References: <1481656241.2321025.1445202214853.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1481656241.2321025.1445202214853.JavaMail.yahoo@mail.yahoo.com>

Dear R-Expertsx=c(0,0.3, 0.5,0.6)sum(sapply(1:4, function(i) {sum(sapply(1:3, function(j){sum(sapply(1:2, function(k) {(i>j)*(j>k)*exp(x[i]+x[j]+x[k])}))}))}))
I want to restrict the condition (i>j>k) to only those cases where i>1&j>1&k>1In other words'if i=1 then i>=jif j=1 then j>=kother wise i>j>kcan this be done using coding or notThank you 
	[[alternative HTML version deleted]]


From jecogeo at gmail.com  Mon Oct 19 00:16:15 2015
From: jecogeo at gmail.com (Jefferson Ferreira-Ferreira)
Date: Sun, 18 Oct 2015 18:16:15 -0400
Subject: [R] =?utf-8?q?package_or_namespace_load_failed_for_=E2=80=98dismo?=
	=?utf-8?b?4oCZ?=
Message-ID: <CAFFT+Y7ab2+Ok7vUf7PR5eutFcULaTEvYucVp7KsFvZ_pgKYNg@mail.gmail.com>

Hello everyone.

I installed dismo package, but I've been receiving the following loading
error:

*Loading required package: raster*
*Loading required package: sp*
*Error : .onLoad failed in loadNamespace() for 'dismo', details:*
*  call: NULL*
*  error: 'tmpDir' It is not an exported object 'namespace:raster'*
*Error: package or namespace load failed for ?dismo?*

When I type traceback() I get:

*2: stop(gettextf("package or namespace load failed for %s",
sQuote(package)), *
*       call. = FALSE, domain = NA)*
*1: library("dismo")*


Session info:

*> sessionInfo()*
*R version 3.0.3 (2014-03-06)*
*Platform: x86_64-w64-mingw32/x64 (64-bit)*

*locale:*
*[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252   *
*[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C                      *
*[5] LC_TIME=Portuguese_Brazil.1252    *

*attached base packages:*
*[1] stats     graphics  grDevices utils     datasets  methods   base     *

*other attached packages:*
*[1] raster_2.2-31    sp_1.0-14        Revobase_7.2.0   RevoMods_7.2.0
RevoScaleR_7.2.0*
*[6] lattice_0.20-29  rpart_4.1-5     *

*loaded via a namespace (and not attached):*
*[1] codetools_0.2-8 foreach_1.4.2   grid_3.0.3      iterators_1.0.7
tools_3.0.3 *


Any advice or tip do deal with it will be appreciated?
Thanks in advance.

-- 

*Jefferson Ferreira-Ferreira*

Ge?grafo ? GEOPROCESSAMENTO IDSM | Coordenadoria de TI


Jefferson.ferreira at mamiraua.org.br

*Instituto de Desenvolvimento Sustent?vel Mamirau?*

Minist?rio da Ci?ncia, Tecnologia e Inova??o

Telefone: +55 97 3343-9710

*Google Maps* - Mapas deste e-mail:

Exibir mapa ampliado
<https://maps.google.com.br/maps?q=-3.355557,-64.731151&ll=-3.355471,-64.731145&spn=0.004632,0.006968&num=1&t=h&z=18>


*Contatos particulares:*
*(55) 9615-0100*

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 19 01:24:37 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 18 Oct 2015 16:24:37 -0700
Subject: [R] condition in triple summation
In-Reply-To: <1481656241.2321025.1445202214853.JavaMail.yahoo@mail.yahoo.com>
References: <1481656241.2321025.1445202214853.JavaMail.yahoo@mail.yahoo.com>
	<1481656241.2321025.1445202214853.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <D8B4184E-D43A-4687-A423-6C0EE987BDCD@dcn.davis.CA.us>

Learn to post using plain text format. We are seeing garbage on the screen.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 18, 2015 2:03:34 PM PDT, Sherouk Moawad via R-help <r-help at r-project.org> wrote:
>Dear R-Expertsx=c(0,0.3, 0.5,0.6)sum(sapply(1:4, function(i)
>{sum(sapply(1:3, function(j){sum(sapply(1:2, function(k)
>{(i>j)*(j>k)*exp(x[i]+x[j]+x[k])}))}))}))
>I want to restrict the condition (i>j>k) to only those cases where
>i>1&j>1&k>1In other words'if i=1 then i>=jif j=1 then j>=kother wise
>i>j>kcan this be done using coding or notThank you 
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Oct 19 01:36:45 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 18 Oct 2015 16:36:45 -0700
Subject: [R]
	=?utf-8?q?package_or_namespace_load_failed_for_=E2=80=98dismo?=
	=?utf-8?b?4oCZ?=
In-Reply-To: <CAFFT+Y7ab2+Ok7vUf7PR5eutFcULaTEvYucVp7KsFvZ_pgKYNg@mail.gmail.com>
References: <CAFFT+Y7ab2+Ok7vUf7PR5eutFcULaTEvYucVp7KsFvZ_pgKYNg@mail.gmail.com>
Message-ID: <4B19E060-6AE3-4813-8B56-B6A01CB0FCBE@dcn.davis.CA.us>

I don't know why this is happening for you, but if you want help here the Posting Guide asks you to update your R to the latest version first, since new packages sometimes won't work in old versions of R.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 18, 2015 3:16:15 PM PDT, Jefferson Ferreira-Ferreira <jecogeo at gmail.com> wrote:
>Hello everyone.
>
>I installed dismo package, but I've been receiving the following
>loading
>error:
>
>*Loading required package: raster*
>*Loading required package: sp*
>*Error : .onLoad failed in loadNamespace() for 'dismo', details:*
>*  call: NULL*
>*  error: 'tmpDir' It is not an exported object 'namespace:raster'*
>*Error: package or namespace load failed for ?dismo?*
>
>When I type traceback() I get:
>
>*2: stop(gettextf("package or namespace load failed for %s",
>sQuote(package)), *
>*       call. = FALSE, domain = NA)*
>*1: library("dismo")*
>
>
>Session info:
>
>*> sessionInfo()*
>*R version 3.0.3 (2014-03-06)*
>*Platform: x86_64-w64-mingw32/x64 (64-bit)*
>
>*locale:*
>*[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>  *
>*[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C                   
>  *
>*[5] LC_TIME=Portuguese_Brazil.1252    *
>
>*attached base packages:*
>*[1] stats     graphics  grDevices utils     datasets  methods   base  
>  *
>
>*other attached packages:*
>*[1] raster_2.2-31    sp_1.0-14        Revobase_7.2.0   RevoMods_7.2.0
>RevoScaleR_7.2.0*
>*[6] lattice_0.20-29  rpart_4.1-5     *
>
>*loaded via a namespace (and not attached):*
>*[1] codetools_0.2-8 foreach_1.4.2   grid_3.0.3      iterators_1.0.7
>tools_3.0.3 *
>
>
>Any advice or tip do deal with it will be appreciated?
>Thanks in advance.
>
>-- 
>
>*Jefferson Ferreira-Ferreira*
>
>Ge?grafo ? GEOPROCESSAMENTO IDSM | Coordenadoria de TI
>
>
>Jefferson.ferreira at mamiraua.org.br
>
>*Instituto de Desenvolvimento Sustent?vel Mamirau?*
>
>Minist?rio da Ci?ncia, Tecnologia e Inova??o
>
>Telefone: +55 97 3343-9710
>
>*Google Maps* - Mapas deste e-mail:
>
>Exibir mapa ampliado
><https://maps.google.com.br/maps?q=-3.355557,-64.731151&ll=-3.355471,-64.731145&spn=0.004632,0.006968&num=1&t=h&z=18>
>
>
>*Contatos particulares:*
>*(55) 9615-0100*
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Oct 19 00:31:35 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 19 Oct 2015 09:31:35 +1100
Subject: [R] How to plot shades between curves?
In-Reply-To: <BAE62FD2-7226-4566-AC25-278974AC886D@psych.mpg.de>
References: <CAPL76w9F0gecxfJVTv_pzTZo2Z+Lcd63mYigfONrZDSsVVdDMg@mail.gmail.com>
	<BAE62FD2-7226-4566-AC25-278974AC886D@psych.mpg.de>
Message-ID: <CA+8X3fX9-kc8iA1UBenGtJyE3d_V11nnXWh6x4j-DuRFRJkz=Q@mail.gmail.com>

Hi Jackson,
>From your description, I think you are trying to illustrate the deviation
of Capa.diss, so I will offer an entirely different method. If you do want
the primary line on the left of the plot with a big space on the right,
presumably to add more stuff there, try this:

plot(Capa.diss.mean + 10 * (Capa.diss-Capa.diss.mean),Capa.diss.age,
 type="l",col="gray",xlim=c(-1,30),xlab="Capa.diss")
lines(Capa.diss,Capa.diss.age)

This exaggerates the deviation of Capa.diss from its mean by a factor of 10
in the first gray line, then plots the "real" deviations over it as a black
line. Another possibility is that you want to decompose Capa.diss into low
and high frequency deviations (i.e. long term trend and transient
variation). That would involve a similar plotting technique.

Jim


On Mon, Oct 19, 2015 at 1:29 AM, Benno P?tz <puetz at psych.mpg.de> wrote:

>
> >
> > plot(Capa.diss,Capa.diss.age,ylim =
> > rev((range)(Capa.diss.age=c(min(Capa.diss.age),
> > 10500))),xlim=(c(0,30)),type="l")
> > Capa.diss2<-Capa.diss*0.7
> > par(new=TRUE)
> > plot(Capa.diss2, Capa.diss.age, col='black',type="l",ylim =
> > rev((range)(Capa.diss.age=c(min(Capa.diss.age), 10500))),
> > xlim=(c(0,1)),xaxt="n",yaxt="n",xlab="",ylab="")
> >
> > The following lline is the one I trying to use to fill the gap, but it is
> > not working.
> >
> polygon(c(Capa.diss.age,rev(Capa.diss.age)),c(Capa.diss2,rev(Capa.diss)),col="grey")
> >
> Comparing this line with the code above I get the impression that you have
> the wrong order in your coordinates (x and y switched) - you plot way
> outside your [xy]lims and thus won?t see anything.
> Otherwise your approach seems OK
>
> Benno
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bhawanasahu742 at gmail.com  Mon Oct 19 09:03:34 2015
From: bhawanasahu742 at gmail.com (Bhawana Sahu)
Date: Mon, 19 Oct 2015 12:33:34 +0530
Subject: [R] Problem in generating any model with my dataset in R
Message-ID: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>

Dear all,

I am using kernlab function for analysis of dataset containing 8000 rows
and 171 column, but getting an error saying cannot allocate the memory, It
is running properly with the dataset having 3000 rows and 251 column,

Also when I tried this with dataset having 7000 rows and 171 column getting
error saying that "Error in terms.formula(formula, data = data) : '.' in
formula and no 'data' argument"

What can be done with this dataset, how can I use this for analysis. Is
there any limitation ? please suggest me some solution.

Thanks for your help,

regards
Bhawana Sahu

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 19 09:23:14 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 19 Oct 2015 00:23:14 -0700
Subject: [R] No speed up using the parallel package and ncpus > 1 with
	boot() on linux machines
In-Reply-To: <1848341414.39825980.1445160673861.JavaMail.zimbra@psyctc.org>
References: <1931073813.39679332.1445098705240.JavaMail.zimbra@psyctc.org>
	<alpine.BSF.2.00.1510170945230.67112@pedal.dcn.davis.ca.us>
	<1848341414.39825980.1445160673861.JavaMail.zimbra@psyctc.org>
Message-ID: <1659E4EF-8A1E-4AC1-ABC5-8E5D7DC29240@dcn.davis.CA.us>

Regarding cores... The only reliable way I have found so far is to look up the processor specs. In your case I found [1] which says 4 cores.

[1] http://ark.intel.com/m/products/64900/Intel-Core-i7-3615QM-Processor-6M-Cache-up-to-3_30-GHz#@product/specifications
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 18, 2015 2:31:13 AM PDT, Chris Evans <chrishold at psyctc.org> wrote:
>As with Milan's answer: perfect explanation and hugely appreciated.  A
>few follow up questions/comments below.
>
>----- Original Message -----
>> From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
>> To: "Chris Evans" <chrishold at psyctc.org>
>> Cc: r-help at r-project.org
>> Sent: Saturday, 17 October, 2015 18:28:12
>> Subject: Re: [R] No speed up using the parallel package and ncpus > 1
>with boot() on linux machines
>
>> None of this is surprising. If the calculations you divide your work
>up
>> into are small, then the overhead of communicating between parallel
>> processes will be a relatively large penalty to pay.  You have to
>break
>> your problem up into larger chunks and depend on vector processing
>within
>> processes to keep the cpu busy doing useful work.
>
>Aha.  Got it!
> 
>> Also, I am not aware of any model of Mac Mini that has 8 physical
>cores...
>> 4 is the max. Virtual cores gain a logical simplification of
>> multiprocessing but do not offer actual improved performance because
>> there are only as many physical data paths and registers as there are
>> cores.
>
>Ah.  Hadn't thought of that.  It's a machine I rent, I thought it was a
>mac mini.  detectCores() reports 8 but perhaps they are virtual cores.
>/proc/cpuinfo says the processor is an Intel(R) Core(TM) i7-3615QM CPU
>@ 2.30GHz and shows 8 cores but again ... perhaps they are virtual. 
>What's the best way to get a true core count?
> 
>> Note that your problems are with long-running simulations... your
>examples
>> are too small to demonstrate the actual balance of processing vs.
>> communication overhead. Before you draw conclusions, try upping
>bootReps
>> by a few orders of magnitude, and run your test code a couple
>> of times to stabilize the memory conditions and obtain some
>consistency
>> in timings.
>
>OK.  Good advice again but what you are saying, and the findings I had
>there, are pretty consistent with what I was seeing with long running
>things with bootReps up at 10k and I think you've told me what I really
>want to know.  I think the simplest way to parallelise may actually be
>fine for me: I'll run four (or maybe eight) separate R jobs (having a
>look at swapping to make sure I'm not pushing beyond physical RAM,
>don't think these simulations will.
>
>> I have never used the parallel option in the boot package before... I
>have
>> always rolled my own to allow me to decide how much work to do within
>the
>> worker processes before returning from them. (This is particularly
>severe
>> when using snow, but not necessarily something you can neglect with
>> multicore.)
>
>That sounds like an impressive and obviously pertinent approach.  I
>think, as I say, I may be able to get away with a very simple approach
>that runs parallel simulations and then aggregates the data from each
>and analyses that.
>
>Many thanks Jeff.  Brilliant help.
>
>Chris
>
> 
>> On Sat, 17 Oct 2015, Chris Evans wrote:
>> 
>>> I think I am failing to understand how boot() uses the parallel
>package on linux
>
>... rest of my original post deleted to save space ...
>
> 
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Oct 19 11:56:00 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 19 Oct 2015 09:56:00 +0000
Subject: [R] Problem in generating any model with my dataset in R
In-Reply-To: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>
References: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF79F6@SRVEXCHMBX.precheza.cz>

Hi

Your objects are not so big, therefore I assume that something is wrong with their stucture, especially when one object gives you results.

I wonder if you get more precise answer without providing some basic facts (structure of data, code, OS, R version).

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bhawana
> Sahu
> Sent: Monday, October 19, 2015 9:04 AM
> To: r-help at r-project.org
> Subject: [R] Problem in generating any model with my dataset in R
>
> Dear all,
>
> I am using kernlab function for analysis of dataset containing 8000
> rows and 171 column, but getting an error saying cannot allocate the
> memory, It is running properly with the dataset having 3000 rows and
> 251 column,
>
> Also when I tried this with dataset having 7000 rows and 171 column
> getting error saying that "Error in terms.formula(formula, data = data)
> : '.' in formula and no 'data' argument"
>
> What can be done with this dataset, how can I use this for analysis. Is
> there any limitation ? please suggest me some solution.
>
> Thanks for your help,
>
> regards
> Bhawana Sahu
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From johnwasige at gmail.com  Mon Oct 19 12:19:43 2015
From: johnwasige at gmail.com (John Wasige)
Date: Mon, 19 Oct 2015 12:19:43 +0200
Subject: [R] sub-sample my data in R from two different tables
Message-ID: <CAJgdCD66VBzva2ZVHoYxYUX_ewRAPkFjwR=fFhpEtW_DXHqntw@mail.gmail.com>

?Hi, I need help on how to sub-sample my data in R. I have two tables, one
table with global dataset and another with a list of codes for sub sample
the global dataset.

?
Download link
?

https://www.wetransfer.com/downloads/a53aa3f722b2d2887b60b09239f7c4e620151018152100/ad852e

?

?All these tables have a column called: alloc_key. I want to use the list
of codes in reg6id_subsample_key.csv to extract all raws from
reg6idGlobal.csv for matching/ similar codes in column alloc_key of
reg6idGlobal.csv file.


?Somebody with an idea on how I can go about doing this?

Thanks for your help

John?




?

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Oct 19 12:39:55 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 19 Oct 2015 11:39:55 +0100
Subject: [R] sub-sample my data in R from two different tables
In-Reply-To: <CAJgdCD66VBzva2ZVHoYxYUX_ewRAPkFjwR=fFhpEtW_DXHqntw@mail.gmail.com>
References: <CAJgdCD66VBzva2ZVHoYxYUX_ewRAPkFjwR=fFhpEtW_DXHqntw@mail.gmail.com>
Message-ID: <5624C87B.3050005@dewey.myzen.co.uk>

Dear John

I suspect
?merge
will help here.

You would need to tidy up afterwards (or before) if you do not want the 
other columns in your dataframe of keys to be included in the result.

On 19/10/2015 11:19, John Wasige wrote:
> ?Hi, I need help on how to sub-sample my data in R. I have two tables, one
> table with global dataset and another with a list of codes for sub sample
> the global dataset.
>
> ?
> Download link
> ?
>
> https://www.wetransfer.com/downloads/a53aa3f722b2d2887b60b09239f7c4e620151018152100/ad852e
>
> ?
>
> ?All these tables have a column called: alloc_key. I want to use the list
> of codes in reg6id_subsample_key.csv to extract all raws from
> reg6idGlobal.csv for matching/ similar codes in column alloc_key of
> reg6idGlobal.csv file.
>
>
> ?Somebody with an idea on how I can go about doing this?
>
> Thanks for your help
>
> John?
>
>
>
>
> ?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From petr.pikal at precheza.cz  Mon Oct 19 13:39:29 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 19 Oct 2015 11:39:29 +0000
Subject: [R] Problem in generating any model with my dataset in R
In-Reply-To: <CACVT7p_-Lz5ebrqgjCkJh-9TeETkBWBYw=G9AGqOkfkDHsQ=fA@mail.gmail.com>
References: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF79F6@SRVEXCHMBX.precheza.cz>
	<CACVT7p_-Lz5ebrqgjCkJh-9TeETkBWBYw=G9AGqOkfkDHsQ=fA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7AC4@SRVEXCHMBX.precheza.cz>

Hi

Why do you replace NA with meaningless ?-?? NA for R means Not Available and R can handle it properly. ?-? means ?-? for R and is treated as character together with rest of the column. If somebody aviced it to you, do not trust him any more.

Anyway, you still do not provide info about data. If you have so many rows maybe the best way would be

dput(head(yourdata[1:50,])

or something like that.

Cheers
Petr



From: Bhawana Sahu [mailto:bhawanasahu742 at gmail.com]
Sent: Monday, October 19, 2015 12:14 PM
To: PIKAL Petr
Subject: Re: [R] Problem in generating any model with my dataset in R

Thank you very much for your suggestion,
I am running this on windows using R 3.2.2 and also I tried on linux as well.

In my data, some of the rows having "NA" and before using my dataset I am replacing this NA with "-", can this create a problem?

On Mon, Oct 19, 2015 at 3:26 PM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

Your objects are not so big, therefore I assume that something is wrong with their stucture, especially when one object gives you results.

I wonder if you get more precise answer without providing some basic facts (structure of data, code, OS, R version).

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Bhawana
> Sahu
> Sent: Monday, October 19, 2015 9:04 AM
> To: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: [R] Problem in generating any model with my dataset in R
>
> Dear all,
>
> I am using kernlab function for analysis of dataset containing 8000
> rows and 171 column, but getting an error saying cannot allocate the
> memory, It is running properly with the dataset having 3000 rows and
> 251 column,
>
> Also when I tried this with dataset having 7000 rows and 171 column
> getting error saying that "Error in terms.formula(formula, data = data)
> : '.' in formula and no 'data' argument"
>
> What can be done with this dataset, how can I use this for analysis. Is
> there any limitation ? please suggest me some solution.
>
> Thanks for your help,
>
> regards
> Bhawana Sahu
>
>       [[alternative HTML version deleted]]
>



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Mon Oct 19 13:43:28 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Mon, 19 Oct 2015 11:43:28 +0000
Subject: [R] Problem in generating any model with my dataset in R
In-Reply-To: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>
References: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F30ED7@FHSDB2D11-2.csu.mcmaster.ca>

Dear Bhawana Sahu,

You don't show any of the commands that you used to produce this error, so one can only guess at its source, but the error message you quote seems reasonably clear -- apparently, you failed to specify the data argument to the function(s) you called.

For example, with a data frame named D containing a variable y among others, lm(y ~ .) will fail but lm(y ~ ., data=D) will work.

If you *did* specify the data argument, then you'll have to provide more information about what you did, ideally including a small reproducible example.

I hope this helps,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bhawana
> Sahu
> Sent: October 19, 2015 3:04 AM
> To: r-help at r-project.org
> Subject: [R] Problem in generating any model with my dataset in R
> 
> Dear all,
> 
> I am using kernlab function for analysis of dataset containing 8000 rows and
> 171 column, but getting an error saying cannot allocate the memory, It is
> running properly with the dataset having 3000 rows and 251 column,
> 
> Also when I tried this with dataset having 7000 rows and 171 column getting
> error saying that "Error in terms.formula(formula, data = data) : '.' in formula
> and no 'data' argument"
> 
> What can be done with this dataset, how can I use this for analysis. Is there
> any limitation ? please suggest me some solution.
> 
> Thanks for your help,
> 
> regards
> Bhawana Sahu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhawanasahu742 at gmail.com  Mon Oct 19 14:04:38 2015
From: bhawanasahu742 at gmail.com (Bhawana Sahu)
Date: Mon, 19 Oct 2015 17:34:38 +0530
Subject: [R] Problem in generating any model with my dataset in R
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F30ED7@FHSDB2D11-2.csu.mcmaster.ca>
References: <CACVT7p8ZO4dqaY6W97x0rgrYgNcpba5DBPHabjckQJ0j-=3E=Q@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F30ED7@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CACVT7p9R3KeDukQcSYaKn42sy01hQ8v0TzNnCSL2xg32EzAtuw@mail.gmail.com>

I got the solution,

Problem was due to replacement of NA

Thank you so much

On Mon, Oct 19, 2015 at 5:13 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Bhawana Sahu,
>
> You don't show any of the commands that you used to produce this error, so
> one can only guess at its source, but the error message you quote seems
> reasonably clear -- apparently, you failed to specify the data argument to
> the function(s) you called.
>
> For example, with a data frame named D containing a variable y among
> others, lm(y ~ .) will fail but lm(y ~ ., data=D) will work.
>
> If you *did* specify the data argument, then you'll have to provide more
> information about what you did, ideally including a small reproducible
> example.
>
> I hope this helps,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bhawana
> > Sahu
> > Sent: October 19, 2015 3:04 AM
> > To: r-help at r-project.org
> > Subject: [R] Problem in generating any model with my dataset in R
> >
> > Dear all,
> >
> > I am using kernlab function for analysis of dataset containing 8000 rows
> and
> > 171 column, but getting an error saying cannot allocate the memory, It is
> > running properly with the dataset having 3000 rows and 251 column,
> >
> > Also when I tried this with dataset having 7000 rows and 171 column
> getting
> > error saying that "Error in terms.formula(formula, data = data) : '.' in
> formula
> > and no 'data' argument"
> >
> > What can be done with this dataset, how can I use this for analysis. Is
> there
> > any limitation ? please suggest me some solution.
> >
> > Thanks for your help,
> >
> > regards
> > Bhawana Sahu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From charles.santana at gmail.com  Mon Oct 19 14:41:33 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Mon, 19 Oct 2015 14:41:33 +0200
Subject: [R] Plotting EEG signals as a "head" using R
Message-ID: <CAH-FEngi55ga=p51MtG1BOf1n41JQE_ZBRfoD99eOanF8-C4Bg@mail.gmail.com>

Dear all,

I have .csv file with the evoked potential of different electrodes of a
human subject and I would like to plot a head figure representing the
evoked potentials. My csv file has 1000 lines (from 1ms to 1000 ms) and 12
columns (each column for an electrode I am studying).

Do you know a way to use this csv files to plot a head representing the
evoked potential at specific points (like P300, N100, etc) using R? (I know
a way to plot it in Matlab using ERPLAB and EEGLAB, but Matlab is not an
option in our Lab).

The idea is to have a head figure similar to the one in the following
picture:
http://d2avczb82rh8fa.cloudfront.net/content/jn/113/3/740/F3.large.jpg

Thanks for any help, sorry for not having a reproducible example.

Best,

Charles


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From toth.denes at ttk.mta.hu  Mon Oct 19 15:10:40 2015
From: toth.denes at ttk.mta.hu (=?UTF-8?B?RMOpbmVzIFTDs3Ro?=)
Date: Mon, 19 Oct 2015 15:10:40 +0200
Subject: [R] Plotting EEG signals as a "head" using R
In-Reply-To: <CAH-FEngi55ga=p51MtG1BOf1n41JQE_ZBRfoD99eOanF8-C4Bg@mail.gmail.com>
References: <CAH-FEngi55ga=p51MtG1BOf1n41JQE_ZBRfoD99eOanF8-C4Bg@mail.gmail.com>
Message-ID: <5624EBD0.3040807@ttk.mta.hu>

Hi,

the eegkit package 
(https://cran.r-project.org/web/packages/eegkit/index.html) might help 
you if you happen to work with a standard electrode cap.

Best,
   Denes



On 10/19/2015 02:41 PM, Charles Novaes de Santana wrote:
> Dear all,
>
> I have .csv file with the evoked potential of different electrodes of a
> human subject and I would like to plot a head figure representing the
> evoked potentials. My csv file has 1000 lines (from 1ms to 1000 ms) and 12
> columns (each column for an electrode I am studying).
>
> Do you know a way to use this csv files to plot a head representing the
> evoked potential at specific points (like P300, N100, etc) using R? (I know
> a way to plot it in Matlab using ERPLAB and EEGLAB, but Matlab is not an
> option in our Lab).
>
> The idea is to have a head figure similar to the one in the following
> picture:
> http://d2avczb82rh8fa.cloudfront.net/content/jn/113/3/740/F3.large.jpg
>
> Thanks for any help, sorry for not having a reproducible example.
>
> Best,
>
> Charles
>
>


From l.sutherland at tecnico.ulisboa.pt  Mon Oct 19 14:02:06 2015
From: l.sutherland at tecnico.ulisboa.pt (Dr. Leigh S. Sutherland)
Date: Mon, 19 Oct 2015 13:02:06 +0100
Subject: [R] leveneTest between 2-levels of 3-level factor in R?
Message-ID: <CAEfCOO5ioPuku23hkPh2Va9OAnVd_pR5EJj11fZZpASMTTboSw@mail.gmail.com>

Still feeling my way around using R...

What I have done so far:

I have a data.frame 'results' with response 'Fail', and three factors
'PREP', 'CLEAN' & 'ADHES'. ADHES has 3 levels: Crest Cryst Poly

I calculated the variances:

sigma..k=tapply(Fail,ADHES,var)
print(sqrt(sigma..k)):

Crest    Cryst     Poly 17.56668 41.64679 39.42669

then used leveneTest to test for constance of variance:

print(leveneTest(Fail~ADHES))

Levene's Test for Homogeneity of Variance (center = median)
      Df F value  Pr(>F)
group  2   3.929 0.02588 *
      51

The Question:
Now I want to use Levene's to test for constance of variance between only
the Cryst & Poly levels of the factor ADHES, but I cant work out the syntax
to do this in R.

Could anyone help, please?
?

	[[alternative HTML version deleted]]


From sheroukmoawad at yahoo.com  Mon Oct 19 09:53:45 2015
From: sheroukmoawad at yahoo.com (Sherouk Moawad)
Date: Mon, 19 Oct 2015 00:53:45 -0700
Subject: [R] condition in triple summation
In-Reply-To: <D8B4184E-D43A-4687-A423-6C0EE987BDCD@dcn.davis.CA.us>
Message-ID: <1445241225.41646.YahooMailAndroidMobile@web121103.mail.ne1.yahoo.com>

If I'm summing over (i,j,k) each from 1 to 3

And I have ?condition that (i>j>k)

But I want to restrict this condition to only cases where i,j,k>1

Sent from Yahoo Mail on Android

From:"Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
Date:Mon, Oct 19, 2015 at 1:24 AM
Subject:Re: [R] condition in triple summation

Learn to post using plain text format. We are seeing garbage on the screen.

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.


On October 18, 2015 2:03:34 PM PDT, Sherouk Moawad via R-help <r-help at r-project.org> wrote:
>Dear R-Expertsx=c(0,0.3, 0.5,0.6)sum(sapply(1:4, function(i)
>{sum(sapply(1:3, function(j){sum(sapply(1:2, function(k)
>{(i>j)*(j>k)*exp(x[i]+x[j]+x[k])}))}))}))
>I want to restrict the condition (i>j>k) to only those cases where
>i>1&j>1&k>1In other words'if i=1 then i>=jif j=1 then j>=kother wise
>i>j>kcan this be done using coding or notThank you 
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From andre_mikulec at hotmail.com  Mon Oct 19 14:31:04 2015
From: andre_mikulec at hotmail.com (Andre Mikulec)
Date: Mon, 19 Oct 2015 08:31:04 -0400
Subject: [R] =?windows-1256?q?library=28nlme=29_groupedData_question=FE?=
In-Reply-To: <BLU174-W159B0F83960C025B4D52389C310@phx.gbl>
References: <BLU174-W159B0F83960C025B4D52389C310@phx.gbl>
Message-ID: <BLU174-W17334E0930CE8E5B8C31409C3A0@phx.gbl>



All,

Some trial and error follows ( for anyone who cares ).


The case seems that groupedData does not like 
to have both "a grouping" and "an outher" defined at the same time.


library(nlme)


d.x <- read.table(header=TRUE, text="
o g h i     d
A C E G     1.0
A C E H     2
A C F G     4
A C F H     8

A D E G     16
A D E H     32
A D F G     64
A D F H     128

B C E G     256
B C E H     1024
B C F G     2048
B C F H     4096

B D E G     8192
B D E H     16384
B D F G     32768
B D F H     65536
", stringsAsFactors = FALSE)


# desirable 'outer' ommitted ( but I want 'outer' )


gd <- groupedData(formula = d ~ h | g  
                  , data  = d.x 
                  , inner = ~ i
)


# best (available) solution


gd <- groupedData(formula = d ~ h | o/g
                  , data  = d.x 
                  , inner = ~ i
)


> str(gd, vec.len = 16)
Classes 'nmGroupedData', 'groupedData' and 'data.frame':        16 obs. of  5 variables:
 $ o: chr  "A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B" "B" "B" "B"
 $ g: chr  "C" "C" "C" "C" "D" "D" "D" "D" "C" "C" "C" "C" "D" "D" "D" "D"
 $ h: chr  "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F"
 $ i: chr  "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H"
 $ d: num  1 2 4 8 16 32 64 128 256 1024 2048 4096 8192 16384 32768 65536
 - attr(*, "formula")=Class 'formula' length 3 d ~ h | o/g
  .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
 - attr(*, "formulaList")=List of 2
  ..$ o:Class 'formula' length 2 ~o
  .. .. ..- attr(*, ".Environment")=<environment: 0x00000000062a2a78>
  ..$ g:Class 'formula' length 2 ~g
  .. .. ..- attr(*, ".Environment")=<environment: 0x00000000062a3fa8>
 - attr(*, "inner")=List of 1
  ..$ g:Class 'formula' length 2 ~i
  .. .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
 - attr(*, "order.groups")=List of 2
  ..$ o: logi TRUE
  ..$ g: logi TRUE
 - attr(*, "FUN")=function (x)




Andre Mikulec
Andre_Mikulec at Hotmail.com


----------------------------------------
> From: andre_mikulec at hotmail.com
> To: r-help at r-project.org
> Subject: library(nlme) groupedData question?
> Date: Mon, 12 Oct 2015 08:53:53 -0400
>
>
> SUMMARY
> -------
>
> Using package nlme, I am getting the following warning
> when I try to create a grouped data object using groupedData().
>
> I believe that my logic is faulty.
>
> Warning message:
> In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else paste0(labels, :
> duplicated levels in factors are deprecated
>
> What am I doing wrong? How do I adjust?
>
> Thanks,
> Andre Mikulec
> Andre_Mikulec at Hotmail.com
>
>
> DETAILS ( the following R code can be copied and pasted to the R console and ran )
> -------
>
> library(nlme)
>
> d.x <- read.table(header=TRUE, text="
> o g h i d
> A C E G 1.0
> A C E H 2
> A C F G 4
> A C F H 8
>
> A D E G 16
> A D E H 32
> A D F G 64
> A D F H 128
>
> B C E G 256
> B C E H 1024
> B C F G 2048
> B C F H 4096
>
> B D E G 8192
> B D E H 16384
> B D F G 32768
> B D F H 65536
> ", stringsAsFactors = FALSE)
>
> str(d.x, vec.len = 16)
> # 'data.frame': 16 obs. of 5 variables:
> # $ o: chr "A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B" "B" "B" "B"
> # $ g: chr "C" "C" "C" "C" "D" "D" "D" "D" "C" "C" "C" "C" "D" "D" "D" "D"
> # $ h: chr "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F"
> # $ i: chr "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H"
> # $ d: num 1 2 4 8 16 32 64 128 256 1024 2048 4096 8192 16384 32768 65536
>
> gd <- groupedData(formula = d ~ h | g
> , data = d.x
> , outer = ~ o
> , inner = ~ i
> )
>
> # Warning message:
> # In `levels<-`(`*tmp*`, value = if (nl == nL) as.character(labels) else paste0(labels, :
> # duplicated levels in factors are deprecated
>
>
> str(gd, vec.len = 16)
> # Classes 'nffGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame': 16 obs. of 5 variables:
> # $ o: chr "A" "A" "A" "A" "A" "A" "A" "A" "B" "B" "B" "B" "B" "B" "B" "B"
> # $ g: Ord.factor w/ 4 levels "C"<"D"<"C"<"D": 1 1 1 1 2 2 2 2 1 1 1 1 2 2 2 2
> # $ h: chr "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F" "E" "E" "F" "F"
> # $ i: chr "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H" "G" "H"
> # $ d: num 1 2 4 8 16 32 64 128 256 1024 2048 4096 8192 16384 32768 65536
> # - attr(*, "formula")=Class 'formula' length 3 d ~ h | g
> # .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
> # - attr(*, "outer")=Class 'formula' length 2 ~o
> # .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
> # - attr(*, "inner")=Class 'formula' length 2 ~i
> # .. ..- attr(*, ".Environment")=<environment: R_GlobalEnv>
> # - attr(*, "FUN")=function (x)
> # - attr(*, "order.groups")= logi TRUE
>
>
> SOFTWARE INFORMATION
> ----------------
>
>> sessionInfo()
> R version 3.2.2 (2015-08-14)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats graphics grDevices utils datasets methods base
>
> other attached packages:
> [1] nlme_3.1-121
>
> loaded via a namespace (and not attached):
> [1] grid_3.2.2 lattice_0.20-33
>
>
>
> Thanks,
>
> Andre Mikulec
> Andre_Mikulec at Hotmail.com 		 	   		  

From jholtman at gmail.com  Mon Oct 19 16:00:48 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 19 Oct 2015 10:00:48 -0400
Subject: [R] condition in triple summation
In-Reply-To: <1445241225.41646.YahooMailAndroidMobile@web121103.mail.ne1.yahoo.com>
References: <D8B4184E-D43A-4687-A423-6C0EE987BDCD@dcn.davis.CA.us>
	<1445241225.41646.YahooMailAndroidMobile@web121103.mail.ne1.yahoo.com>
Message-ID: <CAAxdm-4tFQ6Q+VCjiDBgtLRnvwbt8jrY+oXFMDkVaPGSNPHUQQ@mail.gmail.com>

Not sure I understand what your condition 'i > j > k' means in the context
of where each of the values is 1:3.  The only value that meets that
condition is i =3, j=2 & k=1, but you said exclude any cases where the
values were equal to 1.

Can you clarify with an example what you mean.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Oct 19, 2015 at 3:53 AM, Sherouk Moawad via R-help <
r-help at r-project.org> wrote:

> If I'm summing over (i,j,k) each from 1 to 3
>
> And I have  condition that (i>j>k)
>
> But I want to restrict this condition to only cases where i,j,k>1
>
> Sent from Yahoo Mail on Android
>
> From:"Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
> Date:Mon, Oct 19, 2015 at 1:24 AM
> Subject:Re: [R] condition in triple summation
>
> Learn to post using plain text format. We are seeing garbage on the screen.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The    .....      .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.      ##.#.  Live Go...
>                                       Live:  OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.      #.O#.  with
> /Software/Embedded Controllers)              .OO#.      .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
>
> On October 18, 2015 2:03:34 PM PDT, Sherouk Moawad via R-help <
> r-help at r-project.org> wrote:
> >Dear R-Expertsx=c(0,0.3, 0.5,0.6)sum(sapply(1:4, function(i)
> >{sum(sapply(1:3, function(j){sum(sapply(1:2, function(k)
> >{(i>j)*(j>k)*exp(x[i]+x[j]+x[k])}))}))}))
> >I want to restrict the condition (i>j>k) to only those cases where
> >i>1&j>1&k>1In other words'if i=1 then i>=jif j=1 then j>=kother wise
> >i>j>kcan this be done using coding or notThank you
> >    [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Oct 19 16:04:46 2015
From: jholtman at gmail.com (jim holtman)
Date: Mon, 19 Oct 2015 10:04:46 -0400
Subject: [R] sub-sample my data in R from two different tables
In-Reply-To: <CAJgdCD66VBzva2ZVHoYxYUX_ewRAPkFjwR=fFhpEtW_DXHqntw@mail.gmail.com>
References: <CAJgdCD66VBzva2ZVHoYxYUX_ewRAPkFjwR=fFhpEtW_DXHqntw@mail.gmail.com>
Message-ID: <CAAxdm-6+_gOPJtWvUMeGKU2juZnzMJBZmCZ7jygsw_7deSeQhA@mail.gmail.com>

I all  you are doing is matching a single column and then extracting rows
that match, then the '%in%' operator should work:

indx <- reg6idGlobal$alloc_key %in% req6id_subsample_key$alloc_key
my_subset <- reg6idGlobal[indx, ]


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Mon, Oct 19, 2015 at 6:19 AM, John Wasige <johnwasige at gmail.com> wrote:

> ?Hi, I need help on how to sub-sample my data in R. I have two tables, one
> table with global dataset and another with a list of codes for sub sample
> the global dataset.
>
> ?
> Download link
> ?
>
>
> https://www.wetransfer.com/downloads/a53aa3f722b2d2887b60b09239f7c4e620151018152100/ad852e
>
> ?
>
> ?All these tables have a column called: alloc_key. I want to use the list
> of codes in reg6id_subsample_key.csv to extract all raws from
> reg6idGlobal.csv for matching/ similar codes in column alloc_key of
> reg6idGlobal.csv file.
>
>
> ?Somebody with an idea on how I can go about doing this?
>
> Thanks for your help
>
> John?
>
>
>
>
> ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From james at jtoll.com  Mon Oct 19 16:16:34 2015
From: james at jtoll.com (James Toll)
Date: Mon, 19 Oct 2015 09:16:34 -0500
Subject: [R] value of variable in ls()
In-Reply-To: <5623BFF1.3040702@echoffmann.ch>
References: <5623BFF1.3040702@echoffmann.ch>
Message-ID: <1E720C9F-2CF4-45F7-8585-A6D78BD5F19A@jtoll.com>


> On Oct 18, 2015, at 10:51 AM, Christian Hoffmann <christian at echoffmann.ch> wrote:
> 
> How can I do e.g. print("unknown"(ls())) and get the variable values in my current environment?

From your example, it sounds like what you want is simply this:

sapply(ls(), get)


James


From pdalgd at gmail.com  Mon Oct 19 17:12:49 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 19 Oct 2015 17:12:49 +0200
Subject: [R] value of variable in ls()
In-Reply-To: <1E720C9F-2CF4-45F7-8585-A6D78BD5F19A@jtoll.com>
References: <5623BFF1.3040702@echoffmann.ch>
	<1E720C9F-2CF4-45F7-8585-A6D78BD5F19A@jtoll.com>
Message-ID: <8D532032-AF9D-4791-9123-6D3967845076@gmail.com>


On 19 Oct 2015, at 16:16 , James Toll <james at jtoll.com> wrote:

> 
>> On Oct 18, 2015, at 10:51 AM, Christian Hoffmann <christian at echoffmann.ch> wrote:
>> 
>> How can I do e.g. print("unknown"(ls())) and get the variable values in my current environment?
> 
> From your example, it sounds like what you want is simply this:
> 
> sapply(ls(), get)
> 

Perhaps lapply rather than sapply; I don't think the simplification step of the latter is desirable. Incidentally, both variations are effectively crossing the creek to fetch as.list(GlobalEnv).

If your environment contains large objects, you will get what you asked for, but that might well be more than you expected.

> 
> James
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From hvillalo at ipn.mx  Mon Oct 19 17:41:27 2015
From: hvillalo at ipn.mx (Hector Villalobos)
Date: Mon, 19 Oct 2015 15:41:27 +0000
Subject: [R] optimization problem
In-Reply-To: <51B70C2B-FB0C-4613-A09A-960C8C9372C6@xs4all.nl>
References: <CABikkoVu_WrUUkcphd5QxxzSTtPkPstz_bggTGG3WNmtXg8ckw@mail.gmail.com>
	<CAGxFJbQM4+iucKRCFptitm3+Lwr0mda15B6-4-7cfVTj3QVAAA@mail.gmail.com>
	<51B70C2B-FB0C-4613-A09A-960C8C9372C6@xs4all.nl>
Message-ID: <CABikkoXhQ8s5A_k-WQnLi9uzHtfWqksgJqt8jvS_3ZDH7S9OUA@mail.gmail.com>

Thanks to all who responded,

I've found a very useful code here:

http://courses.washington.edu/fish507/notes.html

In particular the Lecture 3...

H?ctor


2015-10-17 7:05 GMT+00:00 Berend Hasselman <bhh at xs4all.nl>:

>
> Your model is producing -Inf entries in the vector Be (in function modl
> and LL) at some stage during the optimization process.
> You should first do something about that before anything else.
>
> Berend
>
>
> > On 17 Oct 2015, at 03:01, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > I made no attempt to examine your details for problems, but in general,
> >
> > My problem
> >> is that the results change a lot depending on the initial values... I
> can't
> >> see what I am doing wrong...
> >>
> >> This is a symptom of an overparameterized model: The parameter estimates
> >> are unstable even though the predictions may not change much. In other
> >> words, your model may be too complex for your data.
> >
> >
> > Whether that is true here, you or others will have to determine. Try
> > simplifying your model as a start.
> >
> > -- Bert
> >
> >
> >
> >>
> >>
> >> # Data
> >> x <- 1995:2010
> >> B <- c(3500, 3200, 3000, 2800, 2600, 3000, 3200, 3800, 4200, 4300, 4400,
> >> 4400, 4500, 4600, 5000, 4300)
> >> Ct <- c(912, 767, 642, 482, 353, 331, 332, 309, 366, 402, 392, 478, 408,
> >> 434, 407, 637)
> >> a <- c(0.539, 0.603, -0.948, 0.166, 1.895, 0.786, 0.901, 0.844, 0.337,
> >> 0.429, 0.304, 0.230, 1.001, 0.750, 0.507, 1.502)
> >> Ag <- 0.55
> >>
> >> # Function with quantity to minimize
> >> modl <- function(par) {
> >>  ro <- par[1]
> >>  ko <- par[2]
> >>  n <- length(B)
> >>  Be <- rep(NA, n)
> >>  Be[1] <- ko * Ag
> >>  for ( k in 2:n)
> >>    Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
> >>  err <- (log(B) - log(Be))^2
> >>  ee <- sqrt( sum(err)/(n-2) )
> >>  LL <- (1/(sqrt(2*pi)*ee)) * exp( -(err/(2*ee^2) ) )
> >>  -crossprod(LL)
> >> }
> >>
> >> # Using function optim()
> >> par.optim <- optim(par = list(ro=0.4, ko=8000), modl, method = "BFGS")
> >> ro <- par.optim$par[1]
> >> ko <- par.optim$par[2]
> >>
> >> # estimated values of "B"
> >> n <- length(B)
> >> Be <- rep(NA, n)
> >> Be[1] <- ko * Ag
> >> for ( k in 2:n)
> >>  Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
> >>
> >> # Plot, estimation of "B" seems reasonable....
> >> plot(x, B, ylim=c(1000, 7000))
> >> lines(x, Be, col="blue", lwd=2)
> >>
> >>
> >> # ... but it is very sensible to initial values...
> >> par.optim2 <- optim(par = list(ro=0.4, ko=10000), modl, method = "BFGS")
> >> ro2 <- par.optim2$par[1]
> >> ko2 <- par.optim2$par[2]
> >>
> >> Be2 <- rep(NA, n)
> >> Be2[1] <- ko2 * Ag
> >> for ( k in 2:n)
> >>  Be2[k] <- Be2[k-1] + ro2 * a[k-1] * Be2[k-1] * (1 - Be2[k-1]/ko2) -
> >> Ct[k-1]
> >>
> >> lines(x, Be2, col="blue", lwd=2, lty=3)
> >>
> >>
> >>
> >> # Uing mle2 function
> >> library(bbmle)
> >> LL <- function(ro, ko, mu, sigma) {
> >>  n <- length(B)
> >>  Be <- rep(NA, n)
> >>  Be[1] <- ko * Ag
> >>  for ( k in 2:n)
> >>    Be[k] <- Be[k-1] + ro * a[k-1] * Be[k-1] * (1 - Be[k-1]/ko) - Ct[k-1]
> >>  err <- log(B) - log(Be)
> >>  R <- (dnorm(err, mu, sigma, log=TRUE))
> >>  -sum(R)
> >> }
> >>
> >> Bc.mle <- mle2(LL, start = list(ro=0.4, ko=8000, mu=0, sigma=1))
> >> summary(Bc.mle)
> >>
> >> ro3 <- coef(Bc.mle)[1]
> >> ko3 <- coef(Bc.mle)[2]
> >>
> >> Be3 <- rep(NA, n)
> >> Be3[1] <- ko3 * Ag
> >> for ( k in 2:n)
> >>  Be3[k] <- Be3[k-1] + ro3 * a[k-1] * Be3[k-1] * (1 - Be3[k-1]/ko3) -
> >> Ct[k-1]
> >>
> >> lines(x, Be3, col="red", lwd=2)
> >>
> >>
> >> --
> >>
> >> H?ctor Villalobos <Hector.Villalobos.O at gmail.com <javascript:;>>
> >>
> >> Depto. de Pesquer?as y Biolog?a Marina
> >>
> >> Centro Interdisciplinario de Ciencias Marinas-Instituto Polit?cnico
> >> Nacional
> >>
> >> CICIMAR-I.P.N.
> >>
> >> A.P. 592. Colonia Centro
> >>
> >> La Paz, Baja California Sur, M?XICO. 23000
> >>
> >> Tels.: (+52 612) 122 53 44; 123 46 58; 123 47 34 ext.: 81602
> >>
> >> Fax: (+52 612) 122 53 22
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> >> more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Bert Gunter
> >
> > "Data is not information. Information is not knowledge. And knowledge is
> > certainly not wisdom."
> >   -- Clifford Stoll
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 

Dr. H?ctor Villalobos <Hector.Villalobos.O at gmail.com>

Depto. de Pesquer?as y Biolog?a Marina

Centro Interdisciplinario de Ciencias Marinas-Instituto Polit?cnico Nacional

CICIMAR-I.P.N.

A.P. 592. Colonia Centro

La Paz, Baja California Sur, M?XICO. 23000

Tels.: (+52 612) 122 53 44; 123 46 58; 123 47 34 ext.: 81602

Fax: (+52 612) 122 53 22

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Mon Oct 19 19:29:54 2015
From: wht_crl at yahoo.com (carol white)
Date: Mon, 19 Oct 2015 17:29:54 +0000 (UTC)
Subject: [R] warning on generic function when building R package
References: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>

Hi,I have invoked plot in a function (plot.func) as follows but when I check the built package, I get a warning:
plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab", ylab="ylab", main = "title", col = col,type = "l")?
R CMD check my.package
checking S3 generic/method consistency ... WARNING
plot:
? function(x, ...)
plot.func:
? function(x.pt, y.pt, arg3, arg4, "title", col, arg5)

See section ?Generic functions and methods? in the ?Writing R
Extensions? manual.
Which plot argument is illegitimate or missing and how to eliminate the warning?
Thanks
Carol

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Oct 19 19:37:41 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Oct 2015 10:37:41 -0700
Subject: [R] warning on generic function when building R package
In-Reply-To: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
References: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
	<635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbROgG8X_uD194ad7O_LxWxrX61C9r4vxX-qtDp4AmtkyQ@mail.gmail.com>

Have you read the manual as requested?
It will answer your question.

Bert
On Oct 19, 2015 6:31 PM, "carol white via R-help" <r-help at r-project.org>
wrote:

> Hi,I have invoked plot in a function (plot.func) as follows but when I
> check the built package, I get a warning:
> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab", ylab="ylab",
> main = "title", col = col,type = "l")
> R CMD check my.package
> checking S3 generic/method consistency ... WARNING
> plot:
>   function(x, ...)
> plot.func:
>   function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>
> See section ?Generic functions and methods? in the ?Writing R
> Extensions? manual.
> Which plot argument is illegitimate or missing and how to eliminate the
> warning?
> Thanks
> Carol
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 19 19:39:53 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 19 Oct 2015 10:39:53 -0700
Subject: [R] warning on generic function when building R package
In-Reply-To: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
References: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
	<635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <3F943C15-7420-4A43-9945-299E514FB094@dcn.davis.CA.us>

I would guess that x.pt does not have class "func", whatever that is. You really ought to read the manual section indicated in the error.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 19, 2015 10:29:54 AM PDT, carol white via R-help <r-help at r-project.org> wrote:
>Hi,I have invoked plot in a function (plot.func) as follows but when I
>check the built package, I get a warning:
>plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
>ylab="ylab", main = "title", col = col,type = "l")?
>R CMD check my.package
>checking S3 generic/method consistency ... WARNING
>plot:
>? function(x, ...)
>plot.func:
>? function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>
>See section ?Generic functions and methods? in the ?Writing R
>Extensions? manual.
>Which plot argument is illegitimate or missing and how to eliminate the
>warning?
>Thanks
>Carol
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Oct 19 19:45:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Oct 2015 13:45:45 -0400
Subject: [R] warning on generic function when building R package
In-Reply-To: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
References: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
	<635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56252C49.5070607@gmail.com>

On 19/10/2015 1:29 PM, carol white via R-help wrote:
> Hi,I have invoked plot in a function (plot.func) as follows but when I check the built package, I get a warning:
> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab", ylab="ylab", main = "title", col = col,type = "l") 
> R CMD check my.package
> checking S3 generic/method consistency ... WARNING
> plot:
>   function(x, ...)
> plot.func:
>   function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
> 
> See section ?Generic functions and methods? in the ?Writing R
> Extensions? manual.
> Which plot argument is illegitimate or missing and how to eliminate the warning?

The first argument to plot.func needs to be called "x" if you want to
use it as a method.  Method signatures need to be consistent with the
generic signature.

Duncan Murdoch


From bgunter.4567 at gmail.com  Mon Oct 19 20:14:13 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Oct 2015 11:14:13 -0700
Subject: [R] warning on generic function when building R package
In-Reply-To: <56252C49.5070607@gmail.com>
References: <635027287.902041.1445275794638.JavaMail.yahoo@mail.yahoo.com>
	<56252C49.5070607@gmail.com>
Message-ID: <CAGxFJbQXZstZGMkCD73LDY1Zy7z9tGQB0AZ1z_2M+y1xqUTu6g@mail.gmail.com>

... (Following up on Duncan)
and see also ?plot and ?plot.default for argument details.

Bert

On Monday, October 19, 2015, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 19/10/2015 1:29 PM, carol white via R-help wrote:
> > Hi,I have invoked plot in a function (plot.func) as follows but when I
> check the built package, I get a warning:
> > plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
> > R CMD check my.package
> > checking S3 generic/method consistency ... WARNING
> > plot:
> >   function(x, ...)
> > plot.func:
> >   function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
> >
> > See section ?Generic functions and methods? in the ?Writing R
> > Extensions? manual.
> > Which plot argument is illegitimate or missing and how to eliminate the
> warning?
>
> The first argument to plot.func needs to be called "x" if you want to
> use it as a method.  Method signatures need to be consistent with the
> generic signature.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From sheroukmoawad at yahoo.com  Mon Oct 19 20:39:13 2015
From: sheroukmoawad at yahoo.com (Sherouk Moawad)
Date: Mon, 19 Oct 2015 18:39:13 +0000 (UTC)
Subject: [R] condition in triple summation
In-Reply-To: <CAAxdm-4tFQ6Q+VCjiDBgtLRnvwbt8jrY+oXFMDkVaPGSNPHUQQ@mail.gmail.com>
References: <CAAxdm-4tFQ6Q+VCjiDBgtLRnvwbt8jrY+oXFMDkVaPGSNPHUQQ@mail.gmail.com>
Message-ID: <2121918027.2887861.1445279953482.JavaMail.yahoo@mail.yahoo.com>


| If for example I have a double sammation on (xj+xi)The first summation from 1 to 3 And second summation is from 1 to 2If I put the condition of (i>j ) then the term (x1+x1) will not be included?I need to cut the condition into tow parts?If i&j>1 then i>jWhile if i=1 then i>=jSo that the term (x1+x1) is includedCan this be done or it's an imaginary casePlease help |

 


     On Monday, October 19, 2015 4:00 PM, jim holtman <jholtman at gmail.com> wrote:
   

 Not sure I understand what your condition 'i > j > k' means in the context of where each of the values is 1:3.? The only value that meets that condition is i =3, j=2 & k=1, but you said exclude any cases where the values were equal to 1.
Can you clarify with an example what you mean.

Jim Holtman
Data Munger Guru
?
What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.
On Mon, Oct 19, 2015 at 3:53 AM, Sherouk Moawad via R-help <r-help at r-project.org> wrote:

If I'm summing over (i,j,k) each from 1 to 3

And I have ?condition that (i>j>k)

But I want to restrict this condition to only cases where i,j,k>1

Sent from Yahoo Mail on Android

From:"Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
Date:Mon, Oct 19, 2015 at 1:24 AM
Subject:Re: [R] condition in triple summation

Learn to post using plain text format. We are seeing garbage on the screen.

---------------------------------------------------------------------------
Jeff Newmiller? ? ? ? ? ? ? ? ? ? ? ? The? ? .....? ? ? .....? Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>? ? ? ? Basics: ##.#.? ? ? ##.#.? Live Go...
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Live:? OO#.. Dead: OO#..? Playing
Research Engineer (Solar/Batteries? ? ? ? ? ? O.O#.? ? ? #.O#.? with
/Software/Embedded Controllers)? ? ? ? ? ? ? .OO#.? ? ? .OO#.? rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.


On October 18, 2015 2:03:34 PM PDT, Sherouk Moawad via R-help <r-help at r-project.org> wrote:
>Dear R-Expertsx=c(0,0.3, 0.5,0.6)sum(sapply(1:4, function(i)
>{sum(sapply(1:3, function(j){sum(sapply(1:2, function(k)
>{(i>j)*(j>k)*exp(x[i]+x[j]+x[k])}))}))}))
>I want to restrict the condition (i>j>k) to only those cases where
>i>1&j>1&k>1In other words'if i=1 then i>=jif j=1 then j>=kother wise
>i>j>kcan this be done using coding or notThank you
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


? ? ? ? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




  
	[[alternative HTML version deleted]]


From fernando.mansito at gmail.com  Mon Oct 19 18:44:19 2015
From: fernando.mansito at gmail.com (FERNANDO MANSITO CABALLERO)
Date: Mon, 19 Oct 2015 18:44:19 +0200
Subject: [R] (no subject)
In-Reply-To: <CABOXfwM72j_7BLATLXFC00jyjv2f_46cg2MP=0Rn2n0wdVMCPA@mail.gmail.com>
References: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
	<BDCF159C-6A73-4C98-89D1-2D108E08A69B@comcast.net>
	<CABOXfwM72j_7BLATLXFC00jyjv2f_46cg2MP=0Rn2n0wdVMCPA@mail.gmail.com>
Message-ID: <CABOXfwM8C_OxDUJXXni1zbLNK6dC-GBnzpgQAEjEQZmxOHnfRQ@mail.gmail.com>

Hi,

I am very grateful to you all, because (as you well know) if you make the
database flat,

> Empl1 <- list(employee="Anna",spouse="Fred",children=3,
+ child.ages=c(4,7,9),employee="John",spouse="Mary",children=2,
+ child.ages=c(14,17))

adding a record with the same status as the first ones is feasible:

> Empl1 <- c(Empl1,employee="Liz",spouse="Paul",children=1,child.ages=8)

and once, thanks to you all, one learns how to obtain a first sample,

> unlist(Empl1[c(2,6,10)])
  spouse spouse spouse
  "Fred" "Mary" "Paul"

it would seem that one has broken the bad spell:

>  unlist(Empl1[c(2,6,10)][Empl1[c(1,5,9)]==c("Anna","John","Pete")])
   spouse spouse
   "Fred" "Mary"

However, one gets more correct matches but not everywhere (Anna Liz, John
Liz give incorrect
results, Fred and named character(0) respectively). I have read ?"[" but I
have not found where
my mistake is (1).

(1)In particular, the help says "Recursive (list-like) objects: indexing by
[ is similar to
atomic vectors and selects a list of the specified element(s)." More
generally, "] can select
more than one element" (as opposed to [[, $). I have tested with no added
packages and with all
my normally loaded packages and get the same problems in R3.2.2 Windows.

Fernando

On Mon, Oct 5, 2015 at 5:58 PM, FERNANDO MANSITO CABALLERO <
fernando.mansito at gmail.com> wrote:

> Hi
>
> Thanks a lot to all of you for your solutions and explanations.
>
> On Sun, Oct 4, 2015 at 10:34 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>>
>> On Oct 4, 2015, at 11:31 AM, FERNANDO MANSITO CABALLERO wrote:
>>
>> > Dear Madam/Sir,
>> >
>> > I  am   trying to understand  R and I have come to a stumbling block. i
>> > have written:
>> >
>> >> Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
>> >
>> +child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
>> > +child.ages=c(14,17)))
>> >> $family$spouse
>> > [1] "Fred"
>> >> #instead of [1] "Fred" "Mary"
>> >
>> > Where am I wrong?
>>
>> The $ function is short-hand for "[[" (with an unevaluated argument). The
>> "[[" function is not able to deliver multiple values. You might think you
>> needed to use:
>>
>> sapply( Empl[c(2,4)], function(x){ x$family$spouse )
>>
>>
>> And you cannot use that construction or its equivalent, because sapply
>> and lapply do not pass the names of their arguments:
>>
>> > sapply( Empl[c(2,4)], function(x){ x[['family']]['spouse']} )
>> $family
>> NULL
>>
>> $family
>> NULL
>>
>> #-----------
>>
>>
>> This succeeds:
>>
>> > sapply( Empl[grepl('family', names(Empl)) ], function(x){x$spouse})
>> family family
>> "Fred" "Mary"
>>
>>
>> --
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Oct 19 21:01:05 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 19 Oct 2015 12:01:05 -0700
Subject: [R] (no subject)
In-Reply-To: <CABOXfwM8C_OxDUJXXni1zbLNK6dC-GBnzpgQAEjEQZmxOHnfRQ@mail.gmail.com>
References: <CABOXfwP0n87vy=KwhprkH7T99Op+=DZ7VaCRq45nWu6DS3i8RA@mail.gmail.com>
	<BDCF159C-6A73-4C98-89D1-2D108E08A69B@comcast.net>
	<CABOXfwM72j_7BLATLXFC00jyjv2f_46cg2MP=0Rn2n0wdVMCPA@mail.gmail.com>
	<CABOXfwM8C_OxDUJXXni1zbLNK6dC-GBnzpgQAEjEQZmxOHnfRQ@mail.gmail.com>
Message-ID: <CAF8bMcYupcU1COgn8t67uQjdsk=H=E=7ytEe0YYk5F6a4eEWDw@mail.gmail.com>

You are making a long list with multiple components with the same name.
You probably want to make list of lists, with each component list
representing one employee.    E.g.,
  > Empl1 <- list(employee="Anna",spouse="Fred",children=3,
  + child.ages=c(4,7,9),employee="John",spouse="Mary",children=2,
  + child.ages=c(14,17))
  > Empl2 <- list(employee="Liz",spouse="Paul",children=1,child.ages=8)
  > Employees <- list(Empl1, Empl2)
  > vapply(Employees, function(x)x[["spouse"]], "")
  [1] "Fred" "Paul"
  > sapply(Employees, function(x)x[["children"]])
  [1] 3 1
  > lapply(Employees, function(x)x[["child.ages"]])
  [[1]]
  [1] 4 7 9

  [[2]]
  [1] 8

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Oct 19, 2015 at 9:44 AM, FERNANDO MANSITO CABALLERO
<fernando.mansito at gmail.com> wrote:
> Hi,
>
> I am very grateful to you all, because (as you well know) if you make the
> database flat,
>
>> Empl1 <- list(employee="Anna",spouse="Fred",children=3,
> + child.ages=c(4,7,9),employee="John",spouse="Mary",children=2,
> + child.ages=c(14,17))
>
> adding a record with the same status as the first ones is feasible:
>
>> Empl1 <- c(Empl1,employee="Liz",spouse="Paul",children=1,child.ages=8)
>
> and once, thanks to you all, one learns how to obtain a first sample,
>
>> unlist(Empl1[c(2,6,10)])
>   spouse spouse spouse
>   "Fred" "Mary" "Paul"
>
> it would seem that one has broken the bad spell:
>
>>  unlist(Empl1[c(2,6,10)][Empl1[c(1,5,9)]==c("Anna","John","Pete")])
>    spouse spouse
>    "Fred" "Mary"
>
> However, one gets more correct matches but not everywhere (Anna Liz, John
> Liz give incorrect
> results, Fred and named character(0) respectively). I have read ?"[" but I
> have not found where
> my mistake is (1).
>
> (1)In particular, the help says "Recursive (list-like) objects: indexing by
> [ is similar to
> atomic vectors and selects a list of the specified element(s)." More
> generally, "] can select
> more than one element" (as opposed to [[, $). I have tested with no added
> packages and with all
> my normally loaded packages and get the same problems in R3.2.2 Windows.
>
> Fernando
>
> On Mon, Oct 5, 2015 at 5:58 PM, FERNANDO MANSITO CABALLERO <
> fernando.mansito at gmail.com> wrote:
>
>> Hi
>>
>> Thanks a lot to all of you for your solutions and explanations.
>>
>> On Sun, Oct 4, 2015 at 10:34 PM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>>
>>>
>>> On Oct 4, 2015, at 11:31 AM, FERNANDO MANSITO CABALLERO wrote:
>>>
>>> > Dear Madam/Sir,
>>> >
>>> > I  am   trying to understand  R and I have come to a stumbling block. i
>>> > have written:
>>> >
>>> >> Empl <- list(employee="Anna",family=list(spouse="Fred",children=3,
>>> >
>>> +child.ages=c(4,7,9)),employee="John",family=list(spouse="Mary",children=2,
>>> > +child.ages=c(14,17)))
>>> >> $family$spouse
>>> > [1] "Fred"
>>> >> #instead of [1] "Fred" "Mary"
>>> >
>>> > Where am I wrong?
>>>
>>> The $ function is short-hand for "[[" (with an unevaluated argument). The
>>> "[[" function is not able to deliver multiple values. You might think you
>>> needed to use:
>>>
>>> sapply( Empl[c(2,4)], function(x){ x$family$spouse )
>>>
>>>
>>> And you cannot use that construction or its equivalent, because sapply
>>> and lapply do not pass the names of their arguments:
>>>
>>> > sapply( Empl[c(2,4)], function(x){ x[['family']]['spouse']} )
>>> $family
>>> NULL
>>>
>>> $family
>>> NULL
>>>
>>> #-----------
>>>
>>>
>>> This succeeds:
>>>
>>> > sapply( Empl[grepl('family', names(Empl)) ], function(x){x$spouse})
>>> family family
>>> "Fred" "Mary"
>>>
>>>
>>> --
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wht_crl at yahoo.com  Mon Oct 19 21:50:56 2015
From: wht_crl at yahoo.com (carol white)
Date: Mon, 19 Oct 2015 19:50:56 +0000 (UTC)
Subject: [R] warning on generic function when building R package
In-Reply-To: <56252C49.5070607@gmail.com>
References: <56252C49.5070607@gmail.com>
Message-ID: <487390316.42476.1445284256556.JavaMail.yahoo@mail.yahoo.com>

Thanks Murdoch.
defining
plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
and if plot doesn't take the exact parameters of plot.func but modified of these parametersplot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab", ylab="ylab", main = "title", col = col,type = "l")  
then, how to define and invoke to be consisent?
Regards,

     On Monday, October 19, 2015 7:45 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 19/10/2015 1:29 PM, carol white via R-help wrote:
> Hi,I have invoked plot in a function (plot.func) as follows but when I check the built package, I get a warning:
> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab", ylab="ylab", main = "title", col = col,type = "l") 
> R CMD check my.package
> checking S3 generic/method consistency ... WARNING
> plot:
>? function(x, ...)
> plot.func:
>? function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
> 
> See section ?Generic functions and methods? in the ?Writing R
> Extensions? manual.
> Which plot argument is illegitimate or missing and how to eliminate the warning?

The first argument to plot.func needs to be called "x" if you want to
use it as a method.? Method signatures need to be consistent with the
generic signature.

Duncan Murdoch



  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Oct 19 21:59:37 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 19 Oct 2015 15:59:37 -0400
Subject: [R] warning on generic function when building R package
In-Reply-To: <487390316.42476.1445284256556.JavaMail.yahoo@mail.yahoo.com>
References: <56252C49.5070607@gmail.com>
	<487390316.42476.1445284256556.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <56254BA9.4050202@gmail.com>

On 19/10/2015 3:50 PM, carol white wrote:
> Thanks Murdoch.
> 
> defining
> plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
> 
> and if plot doesn't take the exact parameters of plot.func but modified
> of these parameters
> plot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
> 
> then, how to define and invoke to be consisent?

I don't really understand your question, but this is all about the
function header for plot.func, not the call you make to plot().  You
need to name the first argument as "x", you need to include "..." as an
open argument, and you need a legal header.  So this would be okay:


plot.func<- function(x=x.init, y=y.init, arg3, arg4,
                     main = "title", # can't skip the arg name
                     col, arg5,
                     ...)  {          # can't skip the dots

Duncan Murdoch

> 
> Regards,
> 
> On Monday, October 19, 2015 7:45 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 19/10/2015 1:29 PM, carol white via R-help wrote:
> 
>> Hi,I have invoked plot in a function (plot.func) as follows but when I
> check the built package, I get a warning:
>> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
>> R CMD check my.package
>> checking S3 generic/method consistency ... WARNING
>> plot:
>>  function(x, ...)
>> plot.func:
>>  function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>>
>> See section ?Generic functions and methods? in the ?Writing R
>> Extensions? manual.
>> Which plot argument is illegitimate or missing and how to eliminate
> the warning?
> 
> 
> The first argument to plot.func needs to be called "x" if you want to
> use it as a method.  Method signatures need to be consistent with the
> generic signature.
> 
> Duncan Murdoch
> 
> 
> 
>


From charles.santana at gmail.com  Mon Oct 19 22:27:51 2015
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Mon, 19 Oct 2015 22:27:51 +0200
Subject: [R] Plotting EEG signals as a "head" using R
In-Reply-To: <5624EBD0.3040807@ttk.mta.hu>
References: <CAH-FEngi55ga=p51MtG1BOf1n41JQE_ZBRfoD99eOanF8-C4Bg@mail.gmail.com>
	<5624EBD0.3040807@ttk.mta.hu>
Message-ID: <CAH-FEngOnJYGRbXSJyX9K0OGjDquTm4nPXa1vBj3hRwjESQ0-w@mail.gmail.com>

Thanks a lot, D?nes!!

This library is very good! I can plot the head even in 3D using the command
"eegspace(space,voltage)", in which "space" defines the position of the
electrodes and voltage is the voltage of my EEG signal :)

Simple and elegant! :)

Thanks!

Best,

Charles



On 19 October 2015 at 15:10, D?nes T?th <toth.denes at ttk.mta.hu> wrote:

> Hi,
>
> the eegkit package (
> https://cran.r-project.org/web/packages/eegkit/index.html) might help you
> if you happen to work with a standard electrode cap.
>
> Best,
>   Denes
>
>
>
> On 10/19/2015 02:41 PM, Charles Novaes de Santana wrote:
>
>> Dear all,
>>
>> I have .csv file with the evoked potential of different electrodes of a
>> human subject and I would like to plot a head figure representing the
>> evoked potentials. My csv file has 1000 lines (from 1ms to 1000 ms) and 12
>> columns (each column for an electrode I am studying).
>>
>> Do you know a way to use this csv files to plot a head representing the
>> evoked potential at specific points (like P300, N100, etc) using R? (I
>> know
>> a way to plot it in Matlab using ERPLAB and EEGLAB, but Matlab is not an
>> option in our Lab).
>>
>> The idea is to have a head figure similar to the one in the following
>> picture:
>> http://d2avczb82rh8fa.cloudfront.net/content/jn/113/3/740/F3.large.jpg
>>
>> Thanks for any help, sorry for not having a reproducible example.
>>
>> Best,
>>
>> Charles
>>
>>
>>


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From wht_crl at yahoo.com  Mon Oct 19 22:32:23 2015
From: wht_crl at yahoo.com (carol white)
Date: Mon, 19 Oct 2015 20:32:23 +0000 (UTC)
Subject: [R] warning on generic function when building R package
In-Reply-To: <56254BA9.4050202@gmail.com>
References: <56254BA9.4050202@gmail.com>
Message-ID: <33155336.40213.1445286743035.JavaMail.yahoo@mail.yahoo.com>

In effect, this works
but whether I use x or x.init, y or y.init in plot.func, I get
 
no visible binding for global variable ?x.init?no visible binding for global variable ?y.init?
Regards,

     On Monday, October 19, 2015 9:59 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
   

 On 19/10/2015 3:50 PM, carol white wrote:
> Thanks Murdoch.
> 
> defining
> plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
> 
> and if plot doesn't take the exact parameters of plot.func but modified
> of these parameters
> plot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
> 
> then, how to define and invoke to be consisent?

I don't really understand your question, but this is all about the
function header for plot.func, not the call you make to plot().? You
need to name the first argument as "x", you need to include "..." as an
open argument, and you need a legal header.? So this would be okay:


plot.func<- function(x=x.init, y=y.init, arg3, arg4,
? ? ? ? ? ? ? ? ? ? main = "title", # can't skip the arg name
? ? ? ? ? ? ? ? ? ? col, arg5,
? ? ? ? ? ? ? ? ? ? ...)? {? ? ? ? ? # can't skip the dots

Duncan Murdoch

> 
> Regards,
> 
> On Monday, October 19, 2015 7:45 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
> 
> 
> On 19/10/2015 1:29 PM, carol white via R-help wrote:
> 
>> Hi,I have invoked plot in a function (plot.func) as follows but when I
> check the built package, I get a warning:
>> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
>> R CMD check my.package
>> checking S3 generic/method consistency ... WARNING
>> plot:
>>? function(x, ...)
>> plot.func:
>>? function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>>
>> See section ?Generic functions and methods? in the ?Writing R
>> Extensions? manual.
>> Which plot argument is illegitimate or missing and how to eliminate
> the warning?
> 
> 
> The first argument to plot.func needs to be called "x" if you want to
> use it as a method.? Method signatures need to be consistent with the
> generic signature.
> 
> Duncan Murdoch
> 
> 
> 
> 



  
	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Mon Oct 19 23:13:20 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 20 Oct 2015 10:13:20 +1300
Subject: [R] leveneTest between 2-levels of 3-level factor in R?
In-Reply-To: <CAEfCOO5ioPuku23hkPh2Va9OAnVd_pR5EJj11fZZpASMTTboSw@mail.gmail.com>
References: <CAEfCOO5ioPuku23hkPh2Va9OAnVd_pR5EJj11fZZpASMTTboSw@mail.gmail.com>
Message-ID: <56255CF0.9030200@auckland.ac.nz>

On 20/10/15 01:02, Dr. Leigh S. Sutherland wrote:
> Still feeling my way around using R...
>
> What I have done so far:
>
> I have a data.frame 'results' with response 'Fail', and three factors
> 'PREP', 'CLEAN' & 'ADHES'. ADHES has 3 levels: Crest Cryst Poly
>
> I calculated the variances:
>
> sigma..k=tapply(Fail,ADHES,var)
> print(sqrt(sigma..k)):
>
> Crest    Cryst     Poly 17.56668 41.64679 39.42669
>
> then used leveneTest to test for constance of variance:
>
> print(leveneTest(Fail~ADHES))

How does leveneTest() find the variables "Fail" and "ADHES" given that 
you do not provide it with a "data" argument?

> Levene's Test for Homogeneity of Variance (center = median)
>        Df F value  Pr(>F)
> group  2   3.929 0.02588 *
>        51
>
> The Question:
> Now I want to use Levene's to test for constance of variance between only
> the Cryst & Poly levels of the factor ADHES, but I cant work out the syntax
> to do this in R.
>
> Could anyone help, please?

I am not at all sure that I understand your somewhat incoherently 
expressed question, but I *think* that what you want to do might be done 
by setting

    ok <- with(results,ADHES%in%c("Cryst","Poly"))
    leveneTest(Fail ~ ADHES, data=results[ok,])

It's hard to say, since you do not provide a reproducible example.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From bgnumis at gmail.com  Mon Oct 19 23:04:48 2015
From: bgnumis at gmail.com (bgnumis bgnum)
Date: Mon, 19 Oct 2015 23:04:48 +0200
Subject: [R] Bollinger Band quantmod
Message-ID: <CAN25tHSDSPvyXYs8Q+TSuqE0BROfSFh2TDhwtxz9Tt3TkbZRBg@mail.gmail.com>

Hi all,

When I plot Bollinger bands  with

chartSeries(
IBEX,theme="white",
  TA = c(addBBands(50,2))

)

There is a "no" shadow area that it is used to obtain the levels. How can I
plot with charSeries so that the plot start on the shadow area? I mean,
?How can I say to de axis start plotting f.i. 50 steps forward on the chart
Series?

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Oct 19 23:53:51 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 20 Oct 2015 08:53:51 +1100
Subject: [R] warning on generic function when building R package
In-Reply-To: <33155336.40213.1445286743035.JavaMail.yahoo@mail.yahoo.com>
References: <56254BA9.4050202@gmail.com>
	<33155336.40213.1445286743035.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CA+8X3fWjxLo5bWOqDupP9Q8K95qJWAhEY=2E3Dh=ekp9dU1UkA@mail.gmail.com>

I think what you may have done is simply changed x.init= to x=x.init.
x.init may or may not be there when the function is called, and that is
what the warning is saying. While you have satisfied the restriction that
the first argument must be "x", but then set the default value to something
that R is unable to resolve to a value. What you may want to do is
something like this:

plot.func<-function(x,y,...) {
 if(missing(x)) stop("Must have an x value")
 if(missing(y)) stop("Must have a y value")
 ...
}

Jim


On Tue, Oct 20, 2015 at 7:32 AM, carol white via R-help <
r-help at r-project.org> wrote:

> In effect, this works
> but whether I use x or x.init, y or y.init in plot.func, I get
>
> no visible binding for global variable ?x.init?no visible binding for
> global variable ?y.init?
> Regards,
>
>      On Monday, October 19, 2015 9:59 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com> wrote:
>
>
>  On 19/10/2015 3:50 PM, carol white wrote:
> > Thanks Murdoch.
> >
> > defining
> > plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
> >
> > and if plot doesn't take the exact parameters of plot.func but modified
> > of these parameters
> > plot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> > ylab="ylab", main = "title", col = col,type = "l")
> >
> > then, how to define and invoke to be consisent?
>
> I don't really understand your question, but this is all about the
> function header for plot.func, not the call you make to plot().  You
> need to name the first argument as "x", you need to include "..." as an
> open argument, and you need a legal header.  So this would be okay:
>
>
> plot.func<- function(x=x.init, y=y.init, arg3, arg4,
>                     main = "title", # can't skip the arg name
>                     col, arg5,
>                     ...)  {          # can't skip the dots
>
> Duncan Murdoch
>
> >
> > Regards,
> >
> > On Monday, October 19, 2015 7:45 PM, Duncan Murdoch
> > <murdoch.duncan at gmail.com> wrote:
> >
> >
> > On 19/10/2015 1:29 PM, carol white via R-help wrote:
> >
> >> Hi,I have invoked plot in a function (plot.func) as follows but when I
> > check the built package, I get a warning:
> >> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> > ylab="ylab", main = "title", col = col,type = "l")
> >> R CMD check my.package
> >> checking S3 generic/method consistency ... WARNING
> >> plot:
> >>  function(x, ...)
> >> plot.func:
> >>  function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
> >>
> >> See section ?Generic functions and methods? in the ?Writing R
> >> Extensions? manual.
> >> Which plot argument is illegitimate or missing and how to eliminate
> > the warning?
> >
> >
> > The first argument to plot.func needs to be called "x" if you want to
> > use it as a method.  Method signatures need to be consistent with the
> > generic signature.
> >
> > Duncan Murdoch
> >
> >
> >
> >
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Oct 20 01:03:02 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Oct 2015 16:03:02 -0700
Subject: [R] warning on generic function when building R package
In-Reply-To: <487390316.42476.1445284256556.JavaMail.yahoo@mail.yahoo.com>
References: <56252C49.5070607@gmail.com>
	<487390316.42476.1445284256556.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <CAGxFJbRrSQwm3YEXEbChgg-iGpeUmmNzqJmzYA6n50kZeJuOLg@mail.gmail.com>

What is the class attribute of your (misnamed) x.pt argument? If it does
not inherit from class "func" then your plot.func method will not be used
when you call plot(). You would need to explicitly call plot.func()
instead.  If this question/comment makes no sense to you, then you have
some serious homework to do before you post further. Otherwise, follow the
advice you have been given.

Bert

On Monday, October 19, 2015, carol white via R-help <r-help at r-project.org>
wrote:

> Thanks Murdoch.
> defining
> plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
> and if plot doesn't take the exact parameters of plot.func but modified of
> these parametersplot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab=
> "xlab", ylab="ylab", main = "title", col = col,type = "l")
> then, how to define and invoke to be consisent?
> Regards,
>
>      On Monday, October 19, 2015 7:45 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com <javascript:;>> wrote:
>
>
>  On 19/10/2015 1:29 PM, carol white via R-help wrote:
> > Hi,I have invoked plot in a function (plot.func) as follows but when I
> check the built package, I get a warning:
> > plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
> > R CMD check my.package
> > checking S3 generic/method consistency ... WARNING
> > plot:
> >  function(x, ...)
> > plot.func:
> >  function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
> >
> > See section ?Generic functions and methods? in the ?Writing R
> > Extensions? manual.
> > Which plot argument is illegitimate or missing and how to eliminate the
> warning?
>
> The first argument to plot.func needs to be called "x" if you want to
> use it as a method.  Method signatures need to be consistent with the
> generic signature.
>
> Duncan Murdoch
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org <javascript:;> mailing list -- To UNSUBSCRIBE and
> more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is
certainly not wisdom."
   -- Clifford Stoll

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct 20 01:27:01 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 19 Oct 2015 16:27:01 -0700
Subject: [R] Can scan() detect end-of-file?
In-Reply-To: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
References: <CAF8bMcZz=rRWeDw4iGnCKNhe2GpW8D+6PpO2gEvfQnFYr+4K6g@mail.gmail.com>
Message-ID: <CAF8bMcbjWTg_PyJC8GF31MzxXi-TxSqAuTDyX14v5PQT+JVhoQ@mail.gmail.com>

> I would like to read a connection line by line with scan but
> don't know how to tell when to quit trying.  Is there any
> way that you can ask the connection object if it is at the end?

I found that adding the argument blank.lines.skip=FALSE to the
scan command will do the trick when nlines=1.  If the line is
empty it returns a vector of one empty character string;
at end-of-file it returns a zero-long character vector.  E.g.,
> cat(t <- "OneA OneB\n\n\"Third\nLine A\" \"Line3B\" Line3C\n", file= tf <- tempfile())
> str({tcon <- file(tf, "r"); lapply(1:5, function(i)scan(tcon, nlines=1, what=list(""), blank.lines.skip=FALSE, quiet=TRUE))})
List of 5
 $ :List of 1
  ..$ : chr [1:2] "OneA" "OneB"
 $ :List of 1
  ..$ : chr ""
 $ :List of 1
  ..$ : chr [1:3] "Third\nLine A" "Line3B" "Line3C"
 $ :List of 1
  ..$ : chr(0)
 $ :List of 1
  ..$ : chr(0)
> str({tcon <- file(tf, "r"); lapply(1:5, function(i)scan(tcon, nlines=1, what=list(""), blank.lines.skip=TRUE, quiet=TRUE))})
List of 5
 $ :List of 1
  ..$ : chr [1:2] "OneA" "OneB"
 $ :List of 1
  ..$ : chr(0)
 $ :List of 1
  ..$ : chr [1:3] "Third\nLine A" "Line3B" "Line3C"
 $ :List of 1
  ..$ : chr(0)
 $ :List of 1
  ..$ : chr(0)
> str({tcon <- file(tf, "r"); lapply(1:5, function(i)scan(tcon, nlines=1, what="", blank.lines.skip=FALSE, quiet=TRUE))})
List of 5
 $ : chr [1:2] "OneA" "OneB"
 $ : chr ""
 $ : chr [1:3] "Third\nLine A" "Line3B" "Line3C"
 $ : chr(0)
 $ : chr(0)
> str({tcon <- file(tf, "r"); lapply(1:5, function(i)scan(tcon, nlines=1, what="", blank.lines.skip=TRUE, quiet=TRUE))})
List of 5
 $ : chr [1:2] "OneA" "OneB"
 $ : chr(0)
 $ : chr [1:3] "Third\nLine A" "Line3B" "Line3C"
 $ : chr(0)
 $ : chr(0)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 15, 2015 at 1:16 PM, William Dunlap <wdunlap at tibco.com> wrote:
> I would like to read a connection line by line with scan but
> don't know how to tell when to quit trying.  Is there any
> way that you can ask the connection object if it is at the end?
>
> E.g.,
>
> t <- 'A "Two line\nentry"\n\n"Three\nline\nentry" D E\n'
> tfile <- tempfile()
> cat(t, file=tfile)
> tcon <- file(tfile, "r") # or tcon <- textConnection(t)
> scan(tcon, what="", nlines=1)
> #Read 2 items
> #[1] "A"               "Two line\nentry"
>> scan(tcon, what="", nlines=1)  # empty line
> #Read 0 items
> #character(0)
> scan(tcon, what="", nlines=1)
> #Read 3 items
> #[1] "Three\nline\nentry" "D"                  "E"
> scan(tcon, what="", nlines=1) # end of file
> #Read 0 items
> #character(0)
> scan(tcon, what="", nlines=1) # end of file
> #Read 0 items
> #character(0)
>
> I am reading virtual line by virtual line because the lines
> may have different numbers of fields.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com


From l.sutherland at tecnico.ulisboa.pt  Tue Oct 20 10:28:41 2015
From: l.sutherland at tecnico.ulisboa.pt (Dr. Leigh S. Sutherland)
Date: Tue, 20 Oct 2015 09:28:41 +0100
Subject: [R] leveneTest between 2-levels of 3-level factor in R?
In-Reply-To: <56255CF0.9030200@auckland.ac.nz>
References: <CAEfCOO5ioPuku23hkPh2Va9OAnVd_pR5EJj11fZZpASMTTboSw@mail.gmail.com>
	<56255CF0.9030200@auckland.ac.nz>
Message-ID: <CAEfCOO7arLhXep+DZOUYztTKagH7QmFi4fSsjnFLT6En-A=umg@mail.gmail.com>

Thanks Rolf,

Sorry, I was trying to be coherent, but obviously failed abysmally!
I am new to this list, I will give a reproducible example next time, and
more of the relevant script.

I managed to do what I wanted to with subset:

leveneTest(subset(results,ADHES == 'Poly'|ADHES == 'Cryst')[,5],
                 subset(results,ADHES == 'Poly'|ADHES == 'Cryst')[,3])

which gives the same results as your suggestion, which I can now look into
how it works

many thanks.

Leigh

On 19 October 2015 at 22:13, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 20/10/15 01:02, Dr. Leigh S. Sutherland wrote:
>
>> Still feeling my way around using R...
>>
>> What I have done so far:
>>
>> I have a data.frame 'results' with response 'Fail', and three factors
>> 'PREP', 'CLEAN' & 'ADHES'. ADHES has 3 levels: Crest Cryst Poly
>>
>> I calculated the variances:
>>
>> sigma..k=tapply(Fail,ADHES,var)
>> print(sqrt(sigma..k)):
>>
>> Crest    Cryst     Poly 17.56668 41.64679 39.42669
>>
>> then used leveneTest to test for constance of variance:
>>
>> print(leveneTest(Fail~ADHES))
>>
>
> How does leveneTest() find the variables "Fail" and "ADHES" given that you
> do not provide it with a "data" argument?
>
> Levene's Test for Homogeneity of Variance (center = median)
>>        Df F value  Pr(>F)
>> group  2   3.929 0.02588 *
>>        51
>>
>> The Question:
>> Now I want to use Levene's to test for constance of variance between only
>> the Cryst & Poly levels of the factor ADHES, but I cant work out the
>> syntax
>> to do this in R.
>>
>> Could anyone help, please?
>>
>
> I am not at all sure that I understand your somewhat incoherently
> expressed question, but I *think* that what you want to do might be done by
> setting
>
>    ok <- with(results,ADHES%in%c("Cryst","Poly"))
>    leveneTest(Fail ~ ADHES, data=results[ok,])
>
> It's hard to say, since you do not provide a reproducible example.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>



-- 
Leigh Sutherland

Centre for Marine Technology and Ocean Engineering (CENTEC)
Instituto Superior T?cnico
Av. Rovisco Pais
1049-001 LISBOA
PORTUGAL

Tel: +351 218 417 947

	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Tue Oct 20 11:05:30 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 20 Oct 2015 11:05:30 +0200
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
Message-ID: <CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>

Thanks William. I've tried the first code, ( with f0() ), but still for
n=25, m=15 , I got this:

> s<-f0(25,15)
Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
  invalid 'times' value
In addition: Warning message:
In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
  NAs introduced by coercion to integer range


I don't know if this is related to the memory limits of my laptop, or it
doesn't have to do with the memory.

Any help on how to fix this error will be greatly appreciated.

Thanks All.

Maram Salem

On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com> wrote:

> Doing enumerative combinatorics with rejection methods rarely
> works well. Try mapping your problem to the problem of choosing
> m-1 items from n-1.  E.g., your code was
>
> f0 <- function(n, m) {
>    stopifnot(n > m)
>    D<-matrix(0,nrow=n-m+1,ncol=m-1)
>    for (i in 1:m-1){
>       D[,i]<-seq(0,n-m,1)
>    }
>    ED <- do.call(`expand.grid`,as.data.frame(D))
>    ED<-unname(as.matrix(ED))
>    lk<-which(rowSums(ED)<=(n-m))
>    ED[lk,]
> }
>
> and I think the following does the same thing in much less space by
> transforming the output of combn().
>
> f1 <- function(n, m) {
>    stopifnot(n > m)
>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> len=n-m+1), m-2))
>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
> }
>
> The code for adding the last column is a bit clumsy and could probably be
> improved.  Both f0 and f1 could also be cleaned up to work for m<=2.
>
> See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more on
> this sort of thing.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
>> Dear All,
>>
>> I'm trying to do a simple task (which is in fact a tiny part of a larger
>> code).
>>
>> I want to create a matrix, D, each of its columns is a sequence from 0 to
>> (n-m), by 1. Then, using D, I want to create another matrix ED, whose rows
>> represent all the possible combinations of the elements of the columns of
>> D. Then from ED, I'll select only the rows whose sum is less than or equal
>> to (n-m), which will be called the matrix s. I used the following code:
>>
>> > n=5
>> > m=3
>> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>> > for (i in 1:m-1)
>> +  {
>> + D[,i]<-seq(0,n-m,1)
>> +  }
>> > ED <- do.call(`expand.grid`,as.data.frame(D))
>> > ED<-as.matrix(ED)
>>
>> > lk<-which(rowSums(ED)<=(n-m))
>>
>> > s<-ED[lk,]
>>
>>
>> This works perfectly well. But for rather larger values of n and m (which
>> are not so large actually), the number of all possible combinations of the
>> columns of D gets extremely large giving me this error (for n=25, m=15):
>>
>> > ED <- do.call(`expand.grid`,as.data.frame(D))
>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>   invalid 'times' value
>> In addition: Warning message:
>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>   NAs introduced by coercion to integer range
>>
>>
>> Any help or suggestions will be greatly appreciated.
>>
>> Thanks,
>>
>> Maram Salem
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Oct 20 11:29:43 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Oct 2015 09:29:43 +0000
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7D50@SRVEXCHMBX.precheza.cz>

Hi

What about using the second function f1 which William suggested?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maram
> SAlem
> Sent: Tuesday, October 20, 2015 11:06 AM
> To: William Dunlap; r-help at r-project.org
> Subject: Re: [R] Error in rep.int() invalid 'times' value
>
> Thanks William. I've tried the first code, ( with f0() ), but still for
> n=25, m=15 , I got this:
>
> > s<-f0(25,15)
> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>   invalid 'times' value
> In addition: Warning message:
> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>   NAs introduced by coercion to integer range
>
>
> I don't know if this is related to the memory limits of my laptop, or
> it doesn't have to do with the memory.
>
> Any help on how to fix this error will be greatly appreciated.
>
> Thanks All.
>
> Maram Salem
>
> On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com> wrote:
>
> > Doing enumerative combinatorics with rejection methods rarely works
> > well. Try mapping your problem to the problem of choosing
> > m-1 items from n-1.  E.g., your code was
> >
> > f0 <- function(n, m) {
> >    stopifnot(n > m)
> >    D<-matrix(0,nrow=n-m+1,ncol=m-1)
> >    for (i in 1:m-1){
> >       D[,i]<-seq(0,n-m,1)
> >    }
> >    ED <- do.call(`expand.grid`,as.data.frame(D))
> >    ED<-unname(as.matrix(ED))
> >    lk<-which(rowSums(ED)<=(n-m))
> >    ED[lk,]
> > }
> >
> > and I think the following does the same thing in much less space by
> > transforming the output of combn().
> >
> > f1 <- function(n, m) {
> >    stopifnot(n > m)
> >    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> >    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> > len=n-m+1), m-2))
> >    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0) }
> >
> > The code for adding the last column is a bit clumsy and could
> probably
> > be improved.  Both f0 and f1 could also be cleaned up to work for
> m<=2.
> >
> > See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more
> > on this sort of thing.
> >
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> > On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem
> > <marammagdysalem at gmail.com>
> > wrote:
> >
> >> Dear All,
> >>
> >> I'm trying to do a simple task (which is in fact a tiny part of a
> >> larger code).
> >>
> >> I want to create a matrix, D, each of its columns is a sequence from
> >> 0 to (n-m), by 1. Then, using D, I want to create another matrix ED,
> >> whose rows represent all the possible combinations of the elements
> of
> >> the columns of D. Then from ED, I'll select only the rows whose sum
> >> is less than or equal to (n-m), which will be called the matrix s. I
> used the following code:
> >>
> >> > n=5
> >> > m=3
> >> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
> >> > for (i in 1:m-1)
> >> +  {
> >> + D[,i]<-seq(0,n-m,1)
> >> +  }
> >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> >> > ED<-as.matrix(ED)
> >>
> >> > lk<-which(rowSums(ED)<=(n-m))
> >>
> >> > s<-ED[lk,]
> >>
> >>
> >> This works perfectly well. But for rather larger values of n and m
> >> (which are not so large actually), the number of all possible
> >> combinations of the columns of D gets extremely large giving me this
> error (for n=25, m=15):
> >>
> >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> >> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >>   invalid 'times' value
> >> In addition: Warning message:
> >> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >>   NAs introduced by coercion to integer range
> >>
> >>
> >> Any help or suggestions will be greatly appreciated.
> >>
> >> Thanks,
> >>
> >> Maram Salem
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Ramgad82 at gmx.net  Tue Oct 20 12:36:47 2015
From: Ramgad82 at gmx.net (Dagmar)
Date: Tue, 20 Oct 2015 12:36:47 +0200
Subject: [R] seq POSIXct and fill in data by Tagmarie
Message-ID: <5626193F.1030101@gmx.net>

Hello,
This must be a bloody R-beginner question but I just can't find an 
answer in my beginner books:
I have a dataframe like this:

myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012 
10:00:00", "24.09.2012 11:00:00"), Event=c("0.1","0.5","1.2") )
myframe$Timestamp <- as.POSIXct(strptime(myframe$Timestamp, 
format="%d.%m.%Y %H:%M:%S"))
expand<-data.frame(Timestamp=seq(myframe[1,1], myframe[3,1], by="1 mins"))
head(expand)
new <- merge(expand, myframe, all=T)
head(new)

I do not only want to expand the Dates but also I want to fill in the 
"Events" (i.e. 0,1 untill the date were 0.5 starts).
How do I do this?
Thanks in advance!


From wht_crl at yahoo.com  Tue Oct 20 13:44:08 2015
From: wht_crl at yahoo.com (carol white)
Date: Tue, 20 Oct 2015 11:44:08 +0000 (UTC)
Subject: [R] warning on generic function when building R package
In-Reply-To: <CA+8X3fWjxLo5bWOqDupP9Q8K95qJWAhEY=2E3Dh=ekp9dU1UkA@mail.gmail.com>
References: <CA+8X3fWjxLo5bWOqDupP9Q8K95qJWAhEY=2E3Dh=ekp9dU1UkA@mail.gmail.com>
Message-ID: <829538625.30262.1445341448852.JavaMail.yahoo@mail.yahoo.com>

Jim's solution works.
Thank you

Carol 


     On Monday, October 19, 2015 11:53 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
   

 I think what you may have done is simply changed x.init= to x=x.init. x.init may or may not be there when the function is called, and that is what the warning is saying. While you have satisfied the restriction that the first argument must be "x", but then set the default value to something that R is unable to resolve to a value. What you may want to do is something like this:
plot.func<-function(x,y,...) {?if(missing(x)) stop("Must have an x value")?if(missing(y)) stop("Must have a y value")?...}
Jim

On Tue, Oct 20, 2015 at 7:32 AM, carol white via R-help <r-help at r-project.org> wrote:

In effect, this works
but whether I use x or x.init, y or y.init in plot.func, I get

no visible binding for global variable ?x.init?no visible binding for global variable ?y.init?
Regards,

? ? ?On Monday, October 19, 2015 9:59 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:


?On 19/10/2015 3:50 PM, carol white wrote:
> Thanks Murdoch.
>
> defining
> plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
>
> and if plot doesn't take the exact parameters of plot.func but modified
> of these parameters
> plot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
>
> then, how to define and invoke to be consisent?

I don't really understand your question, but this is all about the
function header for plot.func, not the call you make to plot().? You
need to name the first argument as "x", you need to include "..." as an
open argument, and you need a legal header.? So this would be okay:


plot.func<- function(x=x.init, y=y.init, arg3, arg4,
? ? ? ? ? ? ? ? ? ? main = "title", # can't skip the arg name
? ? ? ? ? ? ? ? ? ? col, arg5,
? ? ? ? ? ? ? ? ? ? ...)? {? ? ? ? ? # can't skip the dots

Duncan Murdoch

>
> Regards,
>
> On Monday, October 19, 2015 7:45 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>
>
> On 19/10/2015 1:29 PM, carol white via R-help wrote:
>
>> Hi,I have invoked plot in a function (plot.func) as follows but when I
> check the built package, I get a warning:
>> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
> ylab="ylab", main = "title", col = col,type = "l")
>> R CMD check my.package
>> checking S3 generic/method consistency ... WARNING
>> plot:
>>? function(x, ...)
>> plot.func:
>>? function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>>
>> See section ?Generic functions and methods? in the ?Writing R
>> Extensions? manual.
>> Which plot argument is illegitimate or missing and how to eliminate
> the warning?
>
>
> The first argument to plot.func needs to be called "x" if you want to
> use it as a method.? Method signatures need to be consistent with the
> generic signature.
>
> Duncan Murdoch
>
>
>
>




? ? ? ? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



  
	[[alternative HTML version deleted]]


From marammagdysalem at gmail.com  Tue Oct 20 13:49:42 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 20 Oct 2015 13:49:42 +0200
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7D50@SRVEXCHMBX.precheza.cz>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7D50@SRVEXCHMBX.precheza.cz>
Message-ID: <CAPLSCn0hENxPdgwJQXEBJQCY2Mg+dXJpFHwSDetYsxHAX-Nvjg@mail.gmail.com>

Thanks for the hint Petr.

I'm just a little bit confused with the function f1(). could you please
help me and insert comments within f1() to be able to relate it with f0()?

Thanks a lot.

Maram Salem

On 20 October 2015 at 11:29, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> What about using the second function f1 which William suggested?
>
> Cheers
> Petr
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maram
> > SAlem
> > Sent: Tuesday, October 20, 2015 11:06 AM
> > To: William Dunlap; r-help at r-project.org
> > Subject: Re: [R] Error in rep.int() invalid 'times' value
> >
> > Thanks William. I've tried the first code, ( with f0() ), but still for
> > n=25, m=15 , I got this:
> >
> > > s<-f0(25,15)
> > Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >   invalid 'times' value
> > In addition: Warning message:
> > In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >   NAs introduced by coercion to integer range
> >
> >
> > I don't know if this is related to the memory limits of my laptop, or
> > it doesn't have to do with the memory.
> >
> > Any help on how to fix this error will be greatly appreciated.
> >
> > Thanks All.
> >
> > Maram Salem
> >
> > On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com> wrote:
> >
> > > Doing enumerative combinatorics with rejection methods rarely works
> > > well. Try mapping your problem to the problem of choosing
> > > m-1 items from n-1.  E.g., your code was
> > >
> > > f0 <- function(n, m) {
> > >    stopifnot(n > m)
> > >    D<-matrix(0,nrow=n-m+1,ncol=m-1)
> > >    for (i in 1:m-1){
> > >       D[,i]<-seq(0,n-m,1)
> > >    }
> > >    ED <- do.call(`expand.grid`,as.data.frame(D))
> > >    ED<-unname(as.matrix(ED))
> > >    lk<-which(rowSums(ED)<=(n-m))
> > >    ED[lk,]
> > > }
> > >
> > > and I think the following does the same thing in much less space by
> > > transforming the output of combn().
> > >
> > > f1 <- function(n, m) {
> > >    stopifnot(n > m)
> > >    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> > >    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> > > len=n-m+1), m-2))
> > >    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0) }
> > >
> > > The code for adding the last column is a bit clumsy and could
> > probably
> > > be improved.  Both f0 and f1 could also be cleaned up to work for
> > m<=2.
> > >
> > > See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more
> > > on this sort of thing.
> > >
> > >
> > >
> > > Bill Dunlap
> > > TIBCO Software
> > > wdunlap tibco.com
> > >
> > > On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem
> > > <marammagdysalem at gmail.com>
> > > wrote:
> > >
> > >> Dear All,
> > >>
> > >> I'm trying to do a simple task (which is in fact a tiny part of a
> > >> larger code).
> > >>
> > >> I want to create a matrix, D, each of its columns is a sequence from
> > >> 0 to (n-m), by 1. Then, using D, I want to create another matrix ED,
> > >> whose rows represent all the possible combinations of the elements
> > of
> > >> the columns of D. Then from ED, I'll select only the rows whose sum
> > >> is less than or equal to (n-m), which will be called the matrix s. I
> > used the following code:
> > >>
> > >> > n=5
> > >> > m=3
> > >> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
> > >> > for (i in 1:m-1)
> > >> +  {
> > >> + D[,i]<-seq(0,n-m,1)
> > >> +  }
> > >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > >> > ED<-as.matrix(ED)
> > >>
> > >> > lk<-which(rowSums(ED)<=(n-m))
> > >>
> > >> > s<-ED[lk,]
> > >>
> > >>
> > >> This works perfectly well. But for rather larger values of n and m
> > >> (which are not so large actually), the number of all possible
> > >> combinations of the columns of D gets extremely large giving me this
> > error (for n=25, m=15):
> > >>
> > >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > >> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> > >>   invalid 'times' value
> > >> In addition: Warning message:
> > >> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> > >>   NAs introduced by coercion to integer range
> > >>
> > >>
> > >> Any help or suggestions will be greatly appreciated.
> > >>
> > >> Thanks,
> > >>
> > >> Maram Salem
> > >>
> > >>         [[alternative HTML version deleted]]
> > >>
> > >> ______________________________________________
> > >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> PLEASE do read the posting guide
> > >> http://www.R-project.org/posting-guide.html
> > >> and provide commented, minimal, self-contained, reproducible code.
> > >>
> > >
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From yuan007 at gmail.com  Tue Oct 20 12:58:54 2015
From: yuan007 at gmail.com (Andy Yuan)
Date: Tue, 20 Oct 2015 11:58:54 +0100
Subject: [R] Most appropriate function for the following optimisation issue?
Message-ID: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>

Hello
 
Please could you help me to select the most appropriate/fastest function to use for the following constraint optimisation issue?
 
Objective function:
 
Min: Sum( (X[i] - S[i] )^2) 
 
Subject to constraint :
 
Sum (B[i] x X[i]) =0
 
where i=1??n and S[i] and B[i] are real numbers
 
Need to solve for X
 
Example:
 
Assume n=3
 
S <- c(-0.5, 7.8, 2.3)
B <- c(0.42, 1.12, 0.78)
 
Many thanks
AY



	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Oct 20 15:27:52 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Oct 2015 13:27:52 +0000
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAPLSCn0hENxPdgwJQXEBJQCY2Mg+dXJpFHwSDetYsxHAX-Nvjg@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7D50@SRVEXCHMBX.precheza.cz>
	<CAPLSCn0hENxPdgwJQXEBJQCY2Mg+dXJpFHwSDetYsxHAX-Nvjg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7E3D@SRVEXCHMBX.precheza.cz>

Hi

Why are you confused?

> f0(5,3)
     [,1] [,2]
[1,]    0    0
[2,]    1    0
[3,]    2    0
[4,]    0    1
[5,]    1    1
[6,]    0    2
> f1(5,3)
     [,1] [,2]
[1,]    0    0
[2,]    1    0
[3,]    2    0
[4,]    0    1
[5,]    1    1
[6,]    0    2
>

seems to give the same result.

> res0<-f0(25,15)
Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
  invalid 'times' value
In addition: Warning message:
In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
  NAs introduced by coercion to integer range

> res1<-f1(25,15)

So f1 works for required m,n.

William just used different approach to get the same result, which is indeed quite common in R.

Cheers
Petr

From: Maram SAlem [mailto:marammagdysalem at gmail.com]
Sent: Tuesday, October 20, 2015 1:50 PM
To: PIKAL Petr
Cc: r-help at r-project.org
Subject: Re: [R] Error in rep.int() invalid 'times' value

Thanks for the hint Petr.

I'm just a little bit confused with the function f1(). could you please help me and insert comments within f1() to be able to relate it with f0()?

Thanks a lot.

Maram Salem

On 20 October 2015 at 11:29, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

What about using the second function f1 which William suggested?

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] On Behalf Of Maram
> SAlem
> Sent: Tuesday, October 20, 2015 11:06 AM
> To: William Dunlap; r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] Error in rep.int<http://rep.int>() invalid 'times' value
>
> Thanks William. I've tried the first code, ( with f0() ), but still for
> n=25, m=15 , I got this:
>
> > s<-f0(25,15)
> Error in rep.int<http://rep.int>(rep.int<http://rep.int>(seq_len(nx), rep.int<http://rep.int>(rep.fac, nx)), orep) :
>   invalid 'times' value
> In addition: Warning message:
> In rep.int<http://rep.int>(rep.int<http://rep.int>(seq_len(nx), rep.int<http://rep.int>(rep.fac, nx)), orep) :
>   NAs introduced by coercion to integer range
>
>
> I don't know if this is related to the memory limits of my laptop, or
> it doesn't have to do with the memory.
>
> Any help on how to fix this error will be greatly appreciated.
>
> Thanks All.
>
> Maram Salem
>
> On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com<mailto:wdunlap at tibco.com>> wrote:
>
> > Doing enumerative combinatorics with rejection methods rarely works
> > well. Try mapping your problem to the problem of choosing
> > m-1 items from n-1.  E.g., your code was
> >
> > f0 <- function(n, m) {
> >    stopifnot(n > m)
> >    D<-matrix(0,nrow=n-m+1,ncol=m-1)
> >    for (i in 1:m-1){
> >       D[,i]<-seq(0,n-m,1)
> >    }
> >    ED <- do.call(`expand.grid`,as.data.frame(D))
> >    ED<-unname(as.matrix(ED))
> >    lk<-which(rowSums(ED)<=(n-m))
> >    ED[lk,]
> > }
> >
> > and I think the following does the same thing in much less space by
> > transforming the output of combn().
> >
> > f1 <- function(n, m) {
> >    stopifnot(n > m)
> >    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> >    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> > len=n-m+1), m-2))
> >    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0) }
> >
> > The code for adding the last column is a bit clumsy and could
> probably
> > be improved.  Both f0 and f1 could also be cleaned up to work for
> m<=2.
> >
> > See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more
> > on this sort of thing.
> >
> >
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com<http://tibco.com>
> >
> > On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem
> > <marammagdysalem at gmail.com<mailto:marammagdysalem at gmail.com>>
> > wrote:
> >
> >> Dear All,
> >>
> >> I'm trying to do a simple task (which is in fact a tiny part of a
> >> larger code).
> >>
> >> I want to create a matrix, D, each of its columns is a sequence from
> >> 0 to (n-m), by 1. Then, using D, I want to create another matrix ED,
> >> whose rows represent all the possible combinations of the elements
> of
> >> the columns of D. Then from ED, I'll select only the rows whose sum
> >> is less than or equal to (n-m), which will be called the matrix s. I
> used the following code:
> >>
> >> > n=5
> >> > m=3
> >> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
> >> > for (i in 1:m-1)
> >> +  {
> >> + D[,i]<-seq(0,n-m,1)
> >> +  }
> >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> >> > ED<-as.matrix(ED)
> >>
> >> > lk<-which(rowSums(ED)<=(n-m))
> >>
> >> > s<-ED[lk,]
> >>
> >>
> >> This works perfectly well. But for rather larger values of n and m
> >> (which are not so large actually), the number of all possible
> >> combinations of the columns of D gets extremely large giving me this
> error (for n=25, m=15):
> >>
> >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> >> Error in rep.int<http://rep.int>(rep.int<http://rep.int>(seq_len(nx), rep.int<http://rep.int>(rep.fac, nx)), orep) :
> >>   invalid 'times' value
> >> In addition: Warning message:
> >> In rep.int<http://rep.int>(rep.int<http://rep.int>(seq_len(nx), rep.int<http://rep.int>(rep.fac, nx)), orep) :
> >>   NAs introduced by coercion to integer range
> >>
> >>
> >> Any help or suggestions will be greatly appreciated.
> >>
> >> Thanks,
> >>
> >> Maram Salem
> >>



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Oct 20 15:32:13 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 20 Oct 2015 13:32:13 +0000
Subject: [R] seq POSIXct and fill in data by Tagmarie
In-Reply-To: <5626193F.1030101@gmx.net>
References: <5626193F.1030101@gmx.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7E4E@SRVEXCHMBX.precheza.cz>

Hi

Thanks for the data.

There is function na.locf in zoo package.

> library(zoo)

Attaching package: ?zoo?

The following objects are masked from ?package:base?:

    as.Date, as.Date.numeric

new$Event <- na.locf(new$Event)
  [1] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
 [19] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
 [37] 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
 [55] 0.1 0.1 0.1 0.1 0.1 0.1 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
 [73] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
 [91] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5
[109] 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 1.2
Levels: 0.1 0.5 1.2

Beware that Event is factor variable.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Dagmar
> Sent: Tuesday, October 20, 2015 12:37 PM
> To: r-help at r-project.org
> Subject: [R] seq POSIXct and fill in data by Tagmarie
>
> Hello,
> This must be a bloody R-beginner question but I just can't find an
> answer in my beginner books:
> I have a dataframe like this:
>
> myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
> 10:00:00", "24.09.2012 11:00:00"), Event=c("0.1","0.5","1.2") )
> myframe$Timestamp <- as.POSIXct(strptime(myframe$Timestamp,
> format="%d.%m.%Y %H:%M:%S"))
> expand<-data.frame(Timestamp=seq(myframe[1,1], myframe[3,1], by="1
> mins"))
> head(expand)
> new <- merge(expand, myframe, all=T)
> head(new)
>
> I do not only want to expand the Dates but also I want to fill in the
> "Events" (i.e. 0,1 untill the date were 0.5 starts).
> How do I do this?
> Thanks in advance!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From murdoch.duncan at gmail.com  Tue Oct 20 15:35:17 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 20 Oct 2015 09:35:17 -0400
Subject: [R] Most appropriate function for the following optimisation
 issue?
In-Reply-To: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
References: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
Message-ID: <56264315.6040008@gmail.com>

On 20/10/2015 6:58 AM, Andy Yuan wrote:
> Hello
>  
> Please could you help me to select the most appropriate/fastest function to use for the following constraint optimisation issue?

Just project S into the space orthogonal to B, i.e. compute the
residuals when you regress S on B (with no intercept).  For example,

X <- lsfit(B, S, intercept=FALSE)$residuals

>  
> Objective function:
>  
> Min: Sum( (X[i] - S[i] )^2) 
>  
> Subject to constraint :
>  
> Sum (B[i] x X[i]) =0
>  
> where i=1??n and S[i] and B[i] are real numbers
>  
> Need to solve for X
>  
> Example:
>  
> Assume n=3
>  
> S <- c(-0.5, 7.8, 2.3)
> B <- c(0.42, 1.12, 0.78)
>  
> Many thanks
> AY
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Tue Oct 20 16:20:53 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 20 Oct 2015 16:20:53 +0200
Subject: [R] Most appropriate function for the following optimisation
	issue?
In-Reply-To: <56264315.6040008@gmail.com>
References: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
	<56264315.6040008@gmail.com>
Message-ID: <49F01181-3646-466F-90EA-E7B389F2F3C0@xs4all.nl>


> On 20 Oct 2015, at 15:35, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 20/10/2015 6:58 AM, Andy Yuan wrote:
>> Hello
>> 
>> Please could you help me to select the most appropriate/fastest function to use for the following constraint optimisation issue?
> 
> Just project S into the space orthogonal to B, i.e. compute the
> residuals when you regress S on B (with no intercept).  For example,
> 
> X <- lsfit(B, S, intercept=FALSE)$residuals
> 

And  you can use an alternative like this with package nloptr using functions

library(nloptr)

f1 <- function(x) sum(crossprod(x-S))

heq <- function(x) sum(B * x)

# Check lsfit solution
f1(X)
heq(X)

slsqp(c(0,0,0),fn=f1,heq=heq)


Berend


From marammagdysalem at gmail.com  Tue Oct 20 17:15:58 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 20 Oct 2015 17:15:58 +0200
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7E3D@SRVEXCHMBX.precheza.cz>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7D50@SRVEXCHMBX.precheza.cz>
	<CAPLSCn0hENxPdgwJQXEBJQCY2Mg+dXJpFHwSDetYsxHAX-Nvjg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7E3D@SRVEXCHMBX.precheza.cz>
Message-ID: <CAPLSCn1PrNuaoAaFrMgTyKj_P8xArMFstYoMNsDSSSjvaGpcGw@mail.gmail.com>

Thanks a lot Petr.

I did exactly what you did and found that f1() works for n=25 and m=15. But
I just wanted to figure out how f1() works, as I used its output for this
larger code and It has been running for almost 5 hours now.

s<-f1(25,15)

simpfun<- function (x,n,m,p,alpha,beta)

  {

  a<-factorial(n-m)/(prod((factorial(x)))*(factorial((n-m)- sum(x))))

  b<- vector(mode = "numeric", length = m-1)

  for ( i in 1:m-1)

   {

   b[i]<- (m-i)

   }

  c<- a*((p)^(sum(x)))*((1-p)^(((m-1)*(n-m))-sum(b%*%x)))

  d <-vector(mode = "numeric", length = m-1)

   for (i in 1:m-1)

   {

   d[i]<- n- (sum(x[(1):(i)])) - i

   }

  e<- n*(prod(d))*c

LD<-list()

   for (i in 1:(m-1))

   {

   LD[[i]]<-seq(0,x[i],1)

   }

   LD[[m]]<-seq(0,(n-m-sum(x)),1)

   LED<-expand.grid (LD)

   LED<-as.matrix(LED)

   store1<-vector(mode= "numeric",length=nrow(LED))

    h<- vector(mode= "numeric", length= (m-1))

    lm<- vector(mode= "numeric", length= (m-1))

     for (j in 1:length(store1) )

         {

            incomb<-function(x,alpha,beta) {


 g<-((-1)^(sum(LED[j,])))*(gamma((1/beta)+1))*((alpha)^(-(1/beta)))

                  for (i in 1:(m-1))

                      {

                       h[i]<- choose(x[i],LED[j,i])

                       }

                 ik<-prod(h)*choose((n-m-sum(x)),LED[j,m])

                for (i in 1:(m-1))

                     {

                       lm[i]<-(sum(LED[j,1:i])) + i

                     }

                plm<-prod(lm)

               gil<-g*ik/(plm)

               hlm<-vector(mode= "numeric",length=(sum(LED[j,])+(m-1)))

             dsa<-length(hlm)

              for (i in 1:dsa)

                {

                 ppp<- sum(LED[j,])+(m-1)

                  hlm[i]<-
 (choose(ppp,i))*((-1)^(i))*((i+1)^((-1)*((1/beta)+1)))

                 }

          shl<-gil*(sum(hlm)+1)

          return (shl)

          }

       store1[j]<-incomb(x,alpha=0.2,beta=2)

      }


 val1<- sum(store1)*e

return(val1)

}

va<-apply(s,1,simpfun,n=25,m=15,p=0.3,alpha=0.2,beta=2)

EXP<-sum(va)



 I don't know if something is wrong or this is normal, but I've used R
before with looping codes but it never took too long.

Any suggestions please?
Thanks in advance.

Maram Salem

On 20 October 2015 at 15:27, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
>
>
> Why are you confused?
>
>
>
> > f0(5,3)
>
>      [,1] [,2]
>
> [1,]    0    0
>
> [2,]    1    0
>
> [3,]    2    0
>
> [4,]    0    1
>
> [5,]    1    1
>
> [6,]    0    2
>
> > f1(5,3)
>
>      [,1] [,2]
>
> [1,]    0    0
>
> [2,]    1    0
>
> [3,]    2    0
>
> [4,]    0    1
>
> [5,]    1    1
>
> [6,]    0    2
>
> >
>
>
>
> seems to give the same result.
>
>
>
> > res0<-f0(25,15)
>
> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>
>   invalid 'times' value
>
> In addition: Warning message:
>
> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>
>   NAs introduced by coercion to integer range
>
>
>
> > res1<-f1(25,15)
>
>
>
> So f1 works for required m,n.
>
>
>
> William just used different approach to get the same result, which is
> indeed quite common in R.
>
>
>
> Cheers
>
> Petr
>
>
>
> *From:* Maram SAlem [mailto:marammagdysalem at gmail.com]
> *Sent:* Tuesday, October 20, 2015 1:50 PM
> *To:* PIKAL Petr
> *Cc:* r-help at r-project.org
>
> *Subject:* Re: [R] Error in rep.int() invalid 'times' value
>
>
>
> Thanks for the hint Petr.
>
>
>
> I'm just a little bit confused with the function f1(). could you please
> help me and insert comments within f1() to be able to relate it with f0()?
>
>
>
> Thanks a lot.
>
>
>
> Maram Salem
>
>
>
> On 20 October 2015 at 11:29, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>
> Hi
>
> What about using the second function f1 which William suggested?
>
> Cheers
> Petr
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maram
> > SAlem
> > Sent: Tuesday, October 20, 2015 11:06 AM
> > To: William Dunlap; r-help at r-project.org
> > Subject: Re: [R] Error in rep.int() invalid 'times' value
> >
> > Thanks William. I've tried the first code, ( with f0() ), but still for
> > n=25, m=15 , I got this:
> >
> > > s<-f0(25,15)
> > Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >   invalid 'times' value
> > In addition: Warning message:
> > In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >   NAs introduced by coercion to integer range
> >
> >
> > I don't know if this is related to the memory limits of my laptop, or
> > it doesn't have to do with the memory.
> >
> > Any help on how to fix this error will be greatly appreciated.
> >
> > Thanks All.
> >
> > Maram Salem
> >
> > On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com> wrote:
> >
> > > Doing enumerative combinatorics with rejection methods rarely works
> > > well. Try mapping your problem to the problem of choosing
> > > m-1 items from n-1.  E.g., your code was
> > >
> > > f0 <- function(n, m) {
> > >    stopifnot(n > m)
> > >    D<-matrix(0,nrow=n-m+1,ncol=m-1)
> > >    for (i in 1:m-1){
> > >       D[,i]<-seq(0,n-m,1)
> > >    }
> > >    ED <- do.call(`expand.grid`,as.data.frame(D))
> > >    ED<-unname(as.matrix(ED))
> > >    lk<-which(rowSums(ED)<=(n-m))
> > >    ED[lk,]
> > > }
> > >
> > > and I think the following does the same thing in much less space by
> > > transforming the output of combn().
> > >
> > > f1 <- function(n, m) {
> > >    stopifnot(n > m)
> > >    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> > >    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> > > len=n-m+1), m-2))
> > >    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0) }
> > >
> > > The code for adding the last column is a bit clumsy and could
> > probably
> > > be improved.  Both f0 and f1 could also be cleaned up to work for
> > m<=2.
> > >
> > > See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more
> > > on this sort of thing.
> > >
> > >
> > >
> > > Bill Dunlap
> > > TIBCO Software
> > > wdunlap tibco.com
> > >
> > > On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem
> > > <marammagdysalem at gmail.com>
> > > wrote:
> > >
> > >> Dear All,
> > >>
> > >> I'm trying to do a simple task (which is in fact a tiny part of a
> > >> larger code).
> > >>
> > >> I want to create a matrix, D, each of its columns is a sequence from
> > >> 0 to (n-m), by 1. Then, using D, I want to create another matrix ED,
> > >> whose rows represent all the possible combinations of the elements
> > of
> > >> the columns of D. Then from ED, I'll select only the rows whose sum
> > >> is less than or equal to (n-m), which will be called the matrix s. I
> > used the following code:
> > >>
> > >> > n=5
> > >> > m=3
> > >> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
> > >> > for (i in 1:m-1)
> > >> +  {
> > >> + D[,i]<-seq(0,n-m,1)
> > >> +  }
> > >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > >> > ED<-as.matrix(ED)
> > >>
> > >> > lk<-which(rowSums(ED)<=(n-m))
> > >>
> > >> > s<-ED[lk,]
> > >>
> > >>
> > >> This works perfectly well. But for rather larger values of n and m
> > >> (which are not so large actually), the number of all possible
> > >> combinations of the columns of D gets extremely large giving me this
> > error (for n=25, m=15):
> > >>
> > >> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > >> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> > >>   invalid 'times' value
> > >> In addition: Warning message:
> > >> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> > >>   NAs introduced by coercion to integer range
> > >>
> > >>
> > >> Any help or suggestions will be greatly appreciated.
> > >>
> > >> Thanks,
> > >>
> > >> Maram Salem
> > >>
>
>
>
> ------------------------------
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From glennmschultz at me.com  Tue Oct 20 16:35:39 2015
From: glennmschultz at me.com (Glenn Schultz)
Date: Tue, 20 Oct 2015 14:35:39 +0000 (GMT)
Subject: [R] Creating S4 class with a slot as an array
Message-ID: <75c64a92-0ba2-4c3f-a618-131fe3d5778b@me.com>

Hello All,

I am trying to create an S4 class with a slot that is an array. ?Below is the code I tried but I have missed something. ?Any suggestions are appreciated.

setClass("CashFlow",
representation(
CashFlowArray = "array"))

setMethod("initialize",
signature = "CashFlow",
function(.Object,
CashFlowArray = "array"
){
.Object at CashFlowArray
return(.Object)
callNextMethod(.Object,...)
})
CashFlow <-function(CashFlowArray = array()){
new("CashFlow",
CashFlowArray = CashFlowArray)
}

CFTest <- array(data = 2, c(360,8))

Test <- CashFlow(CashFlowArray = CFTest)

Thanks,
Glenn

From wdunlap at tibco.com  Tue Oct 20 18:11:46 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 20 Oct 2015 09:11:46 -0700
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
Message-ID: <CAF8bMcYMHG5wSWtXY=qogEGRkN9Sf_AacFY8quRirZ35ww1HXA@mail.gmail.com>

f0 is essentially your original code put into a function, so
expect it to fail in the same way your original code did.
f1 should give the same answer as f0, but it should use
less memory and time.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Oct 20, 2015 at 2:05 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
> Thanks William. I've tried the first code, ( with f0() ), but still for
> n=25, m=15 , I got this:
>
>> s<-f0(25,15)
> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>   invalid 'times' value
> In addition: Warning message:
> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>   NAs introduced by coercion to integer range
>
>
> I don't know if this is related to the memory limits of my laptop, or it
> doesn't have to do with the memory.
>
> Any help on how to fix this error will be greatly appreciated.
>
> Thanks All.
>
> Maram Salem
>
> On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com> wrote:
>>
>> Doing enumerative combinatorics with rejection methods rarely
>> works well. Try mapping your problem to the problem of choosing
>> m-1 items from n-1.  E.g., your code was
>>
>> f0 <- function(n, m) {
>>    stopifnot(n > m)
>>    D<-matrix(0,nrow=n-m+1,ncol=m-1)
>>    for (i in 1:m-1){
>>       D[,i]<-seq(0,n-m,1)
>>    }
>>    ED <- do.call(`expand.grid`,as.data.frame(D))
>>    ED<-unname(as.matrix(ED))
>>    lk<-which(rowSums(ED)<=(n-m))
>>    ED[lk,]
>> }
>>
>> and I think the following does the same thing in much less space by
>> transforming the output of combn().
>>
>> f1 <- function(n, m) {
>>    stopifnot(n > m)
>>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
>>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
>> len=n-m+1), m-2))
>>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
>> }
>>
>> The code for adding the last column is a bit clumsy and could probably be
>> improved.  Both f0 and f1 could also be cleaned up to work for m<=2.
>>
>> See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more on
>> this sort of thing.
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem <marammagdysalem at gmail.com>
>> wrote:
>>>
>>> Dear All,
>>>
>>> I'm trying to do a simple task (which is in fact a tiny part of a larger
>>> code).
>>>
>>> I want to create a matrix, D, each of its columns is a sequence from 0 to
>>> (n-m), by 1. Then, using D, I want to create another matrix ED, whose
>>> rows
>>> represent all the possible combinations of the elements of the columns of
>>> D. Then from ED, I'll select only the rows whose sum is less than or
>>> equal
>>> to (n-m), which will be called the matrix s. I used the following code:
>>>
>>> > n=5
>>> > m=3
>>> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
>>> > for (i in 1:m-1)
>>> +  {
>>> + D[,i]<-seq(0,n-m,1)
>>> +  }
>>> > ED <- do.call(`expand.grid`,as.data.frame(D))
>>> > ED<-as.matrix(ED)
>>>
>>> > lk<-which(rowSums(ED)<=(n-m))
>>>
>>> > s<-ED[lk,]
>>>
>>>
>>> This works perfectly well. But for rather larger values of n and m (which
>>> are not so large actually), the number of all possible combinations of
>>> the
>>> columns of D gets extremely large giving me this error (for n=25, m=15):
>>>
>>> > ED <- do.call(`expand.grid`,as.data.frame(D))
>>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>>   invalid 'times' value
>>> In addition: Warning message:
>>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>>   NAs introduced by coercion to integer range
>>>
>>>
>>> Any help or suggestions will be greatly appreciated.
>>>
>>> Thanks,
>>>
>>> Maram Salem
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From wewolski at gmail.com  Tue Oct 20 18:18:04 2015
From: wewolski at gmail.com (Witold E Wolski)
Date: Tue, 20 Oct 2015 18:18:04 +0200
Subject: [R] r-markdown - keeping figures
Message-ID: <CAAjnpdjGnXg9Ui3TXLT0wcK5s7ZEVuMk3W0eD0W0L1nbsnVBxw@mail.gmail.com>

I am running r-markdown from r-studio and can't work out how to keep
the figures.
I mean I have a few figures in the document and would like to have
them as separate pdf's too as I have been used to have them when using
Sweave.



best regards
Witold


-- 
Witold Eryk Wolski


From bgnumis at gmail.com  Tue Oct 20 18:27:38 2015
From: bgnumis at gmail.com (bgnumis bgnum)
Date: Tue, 20 Oct 2015 18:27:38 +0200
Subject: [R] Scope of Axes
Message-ID: <CAN25tHSCHiZrUSwX2omCfNwc_EPH4C6pPvUaNynQhnp+O_ZfYg@mail.gmail.com>

Hi all,

I want to plot two graphs and I use this :

par(mar=c(10,6,6,6))
matplot(Simulation,type="l")

abline(h = 0, lwd = 2, col = "black")

fhist<-hist(Simulation,plot=FALSE)
par(mar=c(6,0,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")


The question is, that the legth of the hist plot is not equilibrated with
the main plot so the fhist is not achiving the goal I?m looking so that it
happens what I attach in png, it seems that the right plot is central value
is below the value of the simulation. How can I ensure that de max min in
the left is the same that in the right (second) plot?
-------------- next part --------------
A non-text attachment was scrubbed...
Name: adjust.png
Type: image/png
Size: 39511 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151020/91b29ae2/attachment.png>

From marammagdysalem at gmail.com  Tue Oct 20 18:32:33 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 20 Oct 2015 18:32:33 +0200
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAF8bMcYMHG5wSWtXY=qogEGRkN9Sf_AacFY8quRirZ35ww1HXA@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
	<CAF8bMcYMHG5wSWtXY=qogEGRkN9Sf_AacFY8quRirZ35ww1HXA@mail.gmail.com>
Message-ID: <CAPLSCn0Qg5osOh91ixXMaBVighD9Y5xLSyD5wGJ-M+B3sx9Rsg@mail.gmail.com>

Yes Indeed William. f1() works perfectly well and took only 30 secs to
execute f1(25,15), but I wonder if there is anyway to speed up the
execution of the rest of my code (almost seven hours now) ?

Thanks for helping.

Maram Salem

On 20 October 2015 at 18:11, William Dunlap <wdunlap at tibco.com> wrote:

> f0 is essentially your original code put into a function, so
> expect it to fail in the same way your original code did.
> f1 should give the same answer as f0, but it should use
> less memory and time.
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Oct 20, 2015 at 2:05 AM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
> > Thanks William. I've tried the first code, ( with f0() ), but still for
> > n=25, m=15 , I got this:
> >
> >> s<-f0(25,15)
> > Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >   invalid 'times' value
> > In addition: Warning message:
> > In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >   NAs introduced by coercion to integer range
> >
> >
> > I don't know if this is related to the memory limits of my laptop, or it
> > doesn't have to do with the memory.
> >
> > Any help on how to fix this error will be greatly appreciated.
> >
> > Thanks All.
> >
> > Maram Salem
> >
> > On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com> wrote:
> >>
> >> Doing enumerative combinatorics with rejection methods rarely
> >> works well. Try mapping your problem to the problem of choosing
> >> m-1 items from n-1.  E.g., your code was
> >>
> >> f0 <- function(n, m) {
> >>    stopifnot(n > m)
> >>    D<-matrix(0,nrow=n-m+1,ncol=m-1)
> >>    for (i in 1:m-1){
> >>       D[,i]<-seq(0,n-m,1)
> >>    }
> >>    ED <- do.call(`expand.grid`,as.data.frame(D))
> >>    ED<-unname(as.matrix(ED))
> >>    lk<-which(rowSums(ED)<=(n-m))
> >>    ED[lk,]
> >> }
> >>
> >> and I think the following does the same thing in much less space by
> >> transforming the output of combn().
> >>
> >> f1 <- function(n, m) {
> >>    stopifnot(n > m)
> >>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> >>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> >> len=n-m+1), m-2))
> >>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0)
> >> }
> >>
> >> The code for adding the last column is a bit clumsy and could probably
> be
> >> improved.  Both f0 and f1 could also be cleaned up to work for m<=2.
> >>
> >> See Feller vol. 1 or Benjamin's "Proofs that (really) count" for more on
> >> this sort of thing.
> >>
> >>
> >>
> >> Bill Dunlap
> >> TIBCO Software
> >> wdunlap tibco.com
> >>
> >> On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem <marammagdysalem at gmail.com
> >
> >> wrote:
> >>>
> >>> Dear All,
> >>>
> >>> I'm trying to do a simple task (which is in fact a tiny part of a
> larger
> >>> code).
> >>>
> >>> I want to create a matrix, D, each of its columns is a sequence from 0
> to
> >>> (n-m), by 1. Then, using D, I want to create another matrix ED, whose
> >>> rows
> >>> represent all the possible combinations of the elements of the columns
> of
> >>> D. Then from ED, I'll select only the rows whose sum is less than or
> >>> equal
> >>> to (n-m), which will be called the matrix s. I used the following code:
> >>>
> >>> > n=5
> >>> > m=3
> >>> > D<-matrix(0,nrow=n-m+1,ncol=m-1)
> >>> > for (i in 1:m-1)
> >>> +  {
> >>> + D[,i]<-seq(0,n-m,1)
> >>> +  }
> >>> > ED <- do.call(`expand.grid`,as.data.frame(D))
> >>> > ED<-as.matrix(ED)
> >>>
> >>> > lk<-which(rowSums(ED)<=(n-m))
> >>>
> >>> > s<-ED[lk,]
> >>>
> >>>
> >>> This works perfectly well. But for rather larger values of n and m
> (which
> >>> are not so large actually), the number of all possible combinations of
> >>> the
> >>> columns of D gets extremely large giving me this error (for n=25,
> m=15):
> >>>
> >>> > ED <- do.call(`expand.grid`,as.data.frame(D))
> >>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >>>   invalid 'times' value
> >>> In addition: Warning message:
> >>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> >>>   NAs introduced by coercion to integer range
> >>>
> >>>
> >>> Any help or suggestions will be greatly appreciated.
> >>>
> >>> Thanks,
> >>>
> >>> Maram Salem
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >>
> >
>

	[[alternative HTML version deleted]]


From phhs80 at gmail.com  Tue Oct 20 19:00:37 2015
From: phhs80 at gmail.com (Paul Smith)
Date: Tue, 20 Oct 2015 18:00:37 +0100
Subject: [R] Most appropriate function for the following optimisation
	issue?
In-Reply-To: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
References: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
Message-ID: <CALS=5mqjAM1=7zFKzpJLKf+GragMmOhP59XdNTHt+gros3CB4Q@mail.gmail.com>

On Tue, Oct 20, 2015 at 11:58 AM, Andy Yuan <yuan007 at gmail.com> wrote:
>
> Please could you help me to select the most appropriate/fastest function to use for the following constraint optimisation issue?
>
> Objective function:
>
> Min: Sum( (X[i] - S[i] )^2)
>
> Subject to constraint :
>
> Sum (B[i] x X[i]) =0
>
> where i=1?n and S[i] and B[i] are real numbers
>
> Need to solve for X
>
> Example:
>
> Assume n=3
>
> S <- c(-0.5, 7.8, 2.3)
> B <- c(0.42, 1.12, 0.78)
>
> Many thanks

I believe you can solve *analytically* your optimization problem, with
the Lagrange multipliers method, Andy. By doing so, you can derive
clean and closed-form expression for the optimal solution.

Paul


From ggrothendieck at gmail.com  Tue Oct 20 19:11:55 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Oct 2015 13:11:55 -0400
Subject: [R] Most appropriate function for the following optimisation
	issue?
In-Reply-To: <CALS=5mqjAM1=7zFKzpJLKf+GragMmOhP59XdNTHt+gros3CB4Q@mail.gmail.com>
References: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
	<CALS=5mqjAM1=7zFKzpJLKf+GragMmOhP59XdNTHt+gros3CB4Q@mail.gmail.com>
Message-ID: <CAP01uRngD0CsqXh=O-pM0SETCmJQ-96+-coet6JCQ3aJVhkCiA@mail.gmail.com>

Yes, it's the projection of S onto the subspace orthogonal to B which is:

X <- S - B%*%B / sum(B*B)

and is also implied by Duncan's solution since that is what the residuals
of linear regression are.

On Tue, Oct 20, 2015 at 1:00 PM, Paul Smith <phhs80 at gmail.com> wrote:

> On Tue, Oct 20, 2015 at 11:58 AM, Andy Yuan <yuan007 at gmail.com> wrote:
> >
> > Please could you help me to select the most appropriate/fastest function
> to use for the following constraint optimisation issue?
> >
> > Objective function:
> >
> > Min: Sum( (X[i] - S[i] )^2)
> >
> > Subject to constraint :
> >
> > Sum (B[i] x X[i]) =0
> >
> > where i=1?n and S[i] and B[i] are real numbers
> >
> > Need to solve for X
> >
> > Example:
> >
> > Assume n=3
> >
> > S <- c(-0.5, 7.8, 2.3)
> > B <- c(0.42, 1.12, 0.78)
> >
> > Many thanks
>
> I believe you can solve *analytically* your optimization problem, with
> the Lagrange multipliers method, Andy. By doing so, you can derive
> clean and closed-form expression for the optimal solution.
>
> Paul
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Tue Oct 20 19:13:10 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 20 Oct 2015 13:13:10 -0400
Subject: [R] Most appropriate function for the following optimisation
	issue?
In-Reply-To: <CAP01uRngD0CsqXh=O-pM0SETCmJQ-96+-coet6JCQ3aJVhkCiA@mail.gmail.com>
References: <0AA111C4-E5A3-4B0F-A0C6-F16C6D605050@gmail.com>
	<CALS=5mqjAM1=7zFKzpJLKf+GragMmOhP59XdNTHt+gros3CB4Q@mail.gmail.com>
	<CAP01uRngD0CsqXh=O-pM0SETCmJQ-96+-coet6JCQ3aJVhkCiA@mail.gmail.com>
Message-ID: <CAP01uRn_ux81QaTtF+NqcOp_s13YC-=Yu8e4+qZVjtcj7X494g@mail.gmail.com>

Correction.

Yes, it's the projection of S onto the subspace orthogonal to B which is:

X <- S - (B%o%B) %*% S/ sum(B*B)

and is also implied by Duncan's solution since that is what the residuals
of linear regression are.

On Tue, Oct 20, 2015 at 1:11 PM, Gabor Grothendieck <ggrothendieck at gmail.com
> wrote:

> Yes, it's the projection of S onto the subspace orthogonal to B which is:
>
> X <- S - B%*%B / sum(B*B)
>
> and is also implied by Duncan's solution since that is what the residuals
> of linear regression are.
>
> On Tue, Oct 20, 2015 at 1:00 PM, Paul Smith <phhs80 at gmail.com> wrote:
>
>> On Tue, Oct 20, 2015 at 11:58 AM, Andy Yuan <yuan007 at gmail.com> wrote:
>> >
>> > Please could you help me to select the most appropriate/fastest
>> function to use for the following constraint optimisation issue?
>> >
>> > Objective function:
>> >
>> > Min: Sum( (X[i] - S[i] )^2)
>> >
>> > Subject to constraint :
>> >
>> > Sum (B[i] x X[i]) =0
>> >
>> > where i=1?n and S[i] and B[i] are real numbers
>> >
>> > Need to solve for X
>> >
>> > Example:
>> >
>> > Assume n=3
>> >
>> > S <- c(-0.5, 7.8, 2.3)
>> > B <- c(0.42, 1.12, 0.78)
>> >
>> > Many thanks
>>
>> I believe you can solve *analytically* your optimization problem, with
>> the Lagrange multipliers method, Andy. By doing so, you can derive
>> clean and closed-form expression for the optimal solution.
>>
>> Paul
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

	[[alternative HTML version deleted]]


From dongchunyu2004 at 163.com  Tue Oct 20 18:39:37 2015
From: dongchunyu2004 at 163.com (Chunyu Dong)
Date: Wed, 21 Oct 2015 00:39:37 +0800 (CST)
Subject: [R] Transfer a 3-dimensional array to a matrix in R
Message-ID: <698d9545.eaa4.150861ecef2.Coremail.dongchunyu2004@163.com>

Hello!


Recently I am trying to transfer a large 3-dimensional array to a matrix. For example, a array like:
, , 1
     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6
, , 2
     [,1] [,2]
[1,]    7   10
[2,]    8   11
[3,]    9   12
, , 3
     [,1] [,2]
[1,]   13   16
[2,]   14   17
[3,]   15   18


I would like to transfer it to a matrix like:
1        7          13
4        10        16
2        8          14
5        11        17
3        9          15
6        12        18


Could you tell me how to do it in R ? Thank you very much!


Best regards,
Chunyu





	[[alternative HTML version deleted]]


From john.laing at gmail.com  Tue Oct 20 20:31:21 2015
From: john.laing at gmail.com (John Laing)
Date: Tue, 20 Oct 2015 14:31:21 -0400
Subject: [R] Transfer a 3-dimensional array to a matrix in R
In-Reply-To: <698d9545.eaa4.150861ecef2.Coremail.dongchunyu2004@163.com>
References: <698d9545.eaa4.150861ecef2.Coremail.dongchunyu2004@163.com>
Message-ID: <CAA3Wa=sJy7y2cdgpB6rZ2H1fewRSzePspMg+ujiySuuy9oDUQA@mail.gmail.com>

> x <- array(1:18, dim=c(3, 2, 3))
> x
, , 1

     [,1] [,2]
[1,]    1    4
[2,]    2    5
[3,]    3    6

, , 2

     [,1] [,2]
[1,]    7   10
[2,]    8   11
[3,]    9   12

, , 3

     [,1] [,2]
[1,]   13   16
[2,]   14   17
[3,]   15   18

> apply(x, 3, t)
     [,1] [,2] [,3]
[1,]    1    7   13
[2,]    4   10   16
[3,]    2    8   14
[4,]    5   11   17
[5,]    3    9   15
[6,]    6   12   18


On Tue, Oct 20, 2015 at 12:39 PM, Chunyu Dong <dongchunyu2004 at 163.com>
wrote:

> Hello!
>
>
> Recently I am trying to transfer a large 3-dimensional array to a matrix.
> For example, a array like:
> , , 1
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
> , , 2
>      [,1] [,2]
> [1,]    7   10
> [2,]    8   11
> [3,]    9   12
> , , 3
>      [,1] [,2]
> [1,]   13   16
> [2,]   14   17
> [3,]   15   18
>
>
> I would like to transfer it to a matrix like:
> 1        7          13
> 4        10        16
> 2        8          14
> 5        11        17
> 3        9          15
> 6        12        18
>
>
> Could you tell me how to do it in R ? Thank you very much!
>
>
> Best regards,
> Chunyu
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Martin.Morgan at roswellpark.org  Tue Oct 20 20:44:04 2015
From: Martin.Morgan at roswellpark.org (Morgan, Martin)
Date: Tue, 20 Oct 2015 18:44:04 +0000
Subject: [R] Creating S4 class with a slot as an array
In-Reply-To: <75c64a92-0ba2-4c3f-a618-131fe3d5778b@me.com>
References: <75c64a92-0ba2-4c3f-a618-131fe3d5778b@me.com>
Message-ID: <DF23DAC5A53912408040FF04D8B780AAE1DC8D@EXMB3RSC.roswellpark.org>



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Glenn
> Schultz
> Sent: Tuesday, October 20, 2015 10:36 AM
> To: R Help R
> Subject: [R] Creating S4 class with a slot as an array
> 
> Hello All,
> 
> I am trying to create an S4 class with a slot that is an array. ?Below is the code I
> tried but I have missed something. ?Any suggestions are appreciated.
> 
> setClass("CashFlow",
> representation(
> CashFlowArray = "array"))

probably here you would also like to provide a prototype

 setClass("CashFlow",
      representation(CashFlowArray="array"),
      prototype=prototype(CashFlowArray=array(numeric(), c(0, 0, 0))))

> 
> setMethod("initialize",
> signature = "CashFlow",
> function(.Object,
> CashFlowArray = "array"
> ){

.Object is the prototype, so the next line...

> .Object at CashFlowArray

references the prototypes' default value for the slot, without modifying it, and then...

> return(.Object)

returns the unmodified object, never getting to the following line...

> callNextMethod(.Object,...)

which would have passed the prototype and all arguments that are _not_ CashFlowArray on to the default 'initialize' method.

Maybe you meant

setMethod("initialize", "CashFlow", function(.Object, ..., CashFlowArray=array()) {
    callNextMethod(.Object, ..., CashFlowArray=CashFlowArray)
})

or, since the initialize method is now not doing anything, simply not defining it in the first place.

Martin Morgan

> })
> CashFlow <-function(CashFlowArray = array()){ new("CashFlow",
> CashFlowArray = CashFlowArray) }
> 
> CFTest <- array(data = 2, c(360,8))
> 
> Test <- CashFlow(CashFlowArray = CFTest)
> 
> Thanks,
> Glenn
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

From wdunlap at tibco.com  Tue Oct 20 20:48:18 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 20 Oct 2015 11:48:18 -0700
Subject: [R] Transfer a 3-dimensional array to a matrix in R
In-Reply-To: <CAA3Wa=sJy7y2cdgpB6rZ2H1fewRSzePspMg+ujiySuuy9oDUQA@mail.gmail.com>
References: <698d9545.eaa4.150861ecef2.Coremail.dongchunyu2004@163.com>
	<CAA3Wa=sJy7y2cdgpB6rZ2H1fewRSzePspMg+ujiySuuy9oDUQA@mail.gmail.com>
Message-ID: <CAF8bMcb4Y=7ik4nR8Pf8w7yMC=pdeKK7ygQthk3ATwNofsbGMA@mail.gmail.com>

Or use aperm() (array index permuation):
  > array(aperm(x, c(2,1,3)), c(6,3))
       [,1] [,2] [,3]
  [1,]    1    7   13
  [2,]    4   10   16
  [3,]    2    8   14
  [4,]    5   11   17
  [5,]    3    9   15
  [6,]    6   12   18

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Oct 20, 2015 at 11:31 AM, John Laing <john.laing at gmail.com> wrote:
>> x <- array(1:18, dim=c(3, 2, 3))
>> x
> , , 1
>
>      [,1] [,2]
> [1,]    1    4
> [2,]    2    5
> [3,]    3    6
>
> , , 2
>
>      [,1] [,2]
> [1,]    7   10
> [2,]    8   11
> [3,]    9   12
>
> , , 3
>
>      [,1] [,2]
> [1,]   13   16
> [2,]   14   17
> [3,]   15   18
>
>> apply(x, 3, t)
>      [,1] [,2] [,3]
> [1,]    1    7   13
> [2,]    4   10   16
> [3,]    2    8   14
> [4,]    5   11   17
> [5,]    3    9   15
> [6,]    6   12   18
>
>
> On Tue, Oct 20, 2015 at 12:39 PM, Chunyu Dong <dongchunyu2004 at 163.com>
> wrote:
>
>> Hello!
>>
>>
>> Recently I am trying to transfer a large 3-dimensional array to a matrix.
>> For example, a array like:
>> , , 1
>>      [,1] [,2]
>> [1,]    1    4
>> [2,]    2    5
>> [3,]    3    6
>> , , 2
>>      [,1] [,2]
>> [1,]    7   10
>> [2,]    8   11
>> [3,]    9   12
>> , , 3
>>      [,1] [,2]
>> [1,]   13   16
>> [2,]   14   17
>> [3,]   15   18
>>
>>
>> I would like to transfer it to a matrix like:
>> 1        7          13
>> 4        10        16
>> 2        8          14
>> 5        11        17
>> 3        9          15
>> 6        12        18
>>
>>
>> Could you tell me how to do it in R ? Thank you very much!
>>
>>
>> Best regards,
>> Chunyu
>>
>>
>>
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From toth.denes at ttk.mta.hu  Tue Oct 20 21:03:20 2015
From: toth.denes at ttk.mta.hu (=?ISO-8859-1?Q?D=E9nes_T=F3th?=)
Date: Tue, 20 Oct 2015 21:03:20 +0200
Subject: [R] Transfer a 3-dimensional array to a matrix in R
In-Reply-To: <CAF8bMcb4Y=7ik4nR8Pf8w7yMC=pdeKK7ygQthk3ATwNofsbGMA@mail.gmail.com>
References: <698d9545.eaa4.150861ecef2.Coremail.dongchunyu2004@163.com>	<CAA3Wa=sJy7y2cdgpB6rZ2H1fewRSzePspMg+ujiySuuy9oDUQA@mail.gmail.com>
	<CAF8bMcb4Y=7ik4nR8Pf8w7yMC=pdeKK7ygQthk3ATwNofsbGMA@mail.gmail.com>
Message-ID: <56268FF8.6020907@ttk.mta.hu>

Hi,

Bill was faster than me in suggesting aperm() instead of apply(), 
however, his solution is still suboptimal. Try to avoid array(), and
set the dimensions directly if possible.

----

fn1 <- function(x) {
     apply(x, 3, t)
}


fn2 <- function(x) {
     array(aperm(x, c(2, 1, 3)), c(prod(dim(x)[1:2]), dim(x)[3]))
}

fn3 <- function(x) {
     x <- aperm(x, c(2, 1, 3))
     dim(x) <- c(prod(dim(x)[1:2]), dim(x)[3])
     x
}

# check that the functions return the same
x <- array(1:18, dim=c(3, 2, 3))
stopifnot(identical(fn1(x), fn2(x)))
stopifnot(identical(fn1(x), fn3(x)))

# create two larger arrays, play with the size of the 3rd dimension
x <- array(1:18e4, dim=c(3, 2e1, 3e3))
y <- array(1:18e4, dim=c(3e3, 2e1, 3))

# and the timing:
library(microbenchmark)
microbenchmark(fn1(x), fn2(x), fn3(x), fn1(y), fn2(y), fn3(y), times = 100L)

---

Conclusion:
fn3() is about 3x as fast as fn2(), and fn1() can be extremely 
inefficient if dim(x)[3] is large.


HTH,
   Denes




On 10/20/2015 08:48 PM, William Dunlap wrote:
> Or use aperm() (array index permuation):
>    > array(aperm(x, c(2,1,3)), c(6,3))
>         [,1] [,2] [,3]
>    [1,]    1    7   13
>    [2,]    4   10   16
>    [3,]    2    8   14
>    [4,]    5   11   17
>    [5,]    3    9   15
>    [6,]    6   12   18
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Oct 20, 2015 at 11:31 AM, John Laing <john.laing at gmail.com> wrote:
>>> x <- array(1:18, dim=c(3, 2, 3))
>>> x
>> , , 1
>>
>>       [,1] [,2]
>> [1,]    1    4
>> [2,]    2    5
>> [3,]    3    6
>>
>> , , 2
>>
>>       [,1] [,2]
>> [1,]    7   10
>> [2,]    8   11
>> [3,]    9   12
>>
>> , , 3
>>
>>       [,1] [,2]
>> [1,]   13   16
>> [2,]   14   17
>> [3,]   15   18
>>
>>> apply(x, 3, t)
>>       [,1] [,2] [,3]
>> [1,]    1    7   13
>> [2,]    4   10   16
>> [3,]    2    8   14
>> [4,]    5   11   17
>> [5,]    3    9   15
>> [6,]    6   12   18
>>
>>
>> On Tue, Oct 20, 2015 at 12:39 PM, Chunyu Dong <dongchunyu2004 at 163.com>
>> wrote:
>>
>>> Hello!
>>>
>>>
>>> Recently I am trying to transfer a large 3-dimensional array to a matrix.
>>> For example, a array like:
>>> , , 1
>>>       [,1] [,2]
>>> [1,]    1    4
>>> [2,]    2    5
>>> [3,]    3    6
>>> , , 2
>>>       [,1] [,2]
>>> [1,]    7   10
>>> [2,]    8   11
>>> [3,]    9   12
>>> , , 3
>>>       [,1] [,2]
>>> [1,]   13   16
>>> [2,]   14   17
>>> [3,]   15   18
>>>
>>>
>>> I would like to transfer it to a matrix like:
>>> 1        7          13
>>> 4        10        16
>>> 2        8          14
>>> 5        11        17
>>> 3        9          15
>>> 6        12        18
>>>
>>>
>>> Could you tell me how to do it in R ? Thank you very much!
>>>
>>>
>>> Best regards,
>>> Chunyu
>>>
>>>
>>>
>>>
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From drjimlemon at gmail.com  Tue Oct 20 23:56:45 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 21 Oct 2015 08:56:45 +1100
Subject: [R] Scope of Axes
In-Reply-To: <CAN25tHSCHiZrUSwX2omCfNwc_EPH4C6pPvUaNynQhnp+O_ZfYg@mail.gmail.com>
References: <CAN25tHSCHiZrUSwX2omCfNwc_EPH4C6pPvUaNynQhnp+O_ZfYg@mail.gmail.com>
Message-ID: <CA+8X3fVshH2wgRAyiXAKyw2KT6JN83OrXerPwHOKMcEW4nO3=g@mail.gmail.com>

Hi bgnumis,
I'm too lazy to try to work out what "Simulation" contains, but try this:

Simulation<-sin(seq(0,6*pi,length.out=144))*5000+
 2000*runif(144)+seq(8000,5000,length.out=144)
png("bb.png",width=800,height=400)
par(mfrow=c(1,2))
plot(Simulation,type="l",ylim=c(0,20000))
abline(h = 0, lwd = 2, col = "black")
fhist<-hist(Simulation,breaks=seq(0,20000,by=2000),plot=FALSE)
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
dev.off()

Jim


On Wed, Oct 21, 2015 at 3:27 AM, bgnumis bgnum <bgnumis at gmail.com> wrote:

> Hi all,
>
> I want to plot two graphs and I use this :
>
> par(mar=c(10,6,6,6))
> matplot(Simulation,type="l")
>
> abline(h = 0, lwd = 2, col = "black")
>
> fhist<-hist(Simulation,plot=FALSE)
> par(mar=c(6,0,6,6))
> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
>
>
> The question is, that the legth of the hist plot is not equilibrated with
> the main plot so the fhist is not achiving the goal I?m looking so that it
> happens what I attach in png, it seems that the right plot is central value
> is below the value of the simulation. How can I ensure that de max min in
> the left is the same that in the right (second) plot?
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From valkremk at gmail.com  Wed Oct 21 00:49:24 2015
From: valkremk at gmail.com (Val)
Date: Tue, 20 Oct 2015 17:49:24 -0500
Subject: [R] by group
In-Reply-To: <AF36C32BE015CB48883C4A9F73CC8C3201748822D7@DOHNSMXDB03.doh.health.nsw.gov.au>
References: <CAJOiR6Y=1tOd9HCS904tDTwQX8-Knb+B2FEGMCjcQYYJzTHifA@mail.gmail.com>
	<AF36C32BE015CB48883C4A9F73CC8C3201748822D7@DOHNSMXDB03.doh.health.nsw.gov.au>
Message-ID: <CAJOiR6brDcLx7tebJV7hvwEpr8XhFUVhCYaKd+HEBnW=mtknZA@mail.gmail.com>

Hi All,

Thank you very  much for your suggestion to use ddply function for my data
set. I used the function like the following

mydata <- read.table(header=TRUE, text='
                             cntry  state city gender
                               1 1 1   1
                               1 1 1   2
                               1 1 1   1
                               1 1 2   2
                               1 2 2   2
                               1 2 3   2
                               1 2 3   1
                            ')

 cndata <- ddply(mydata, c("cntry","gender"), summarise,
                N    = length(gender)
  )
 cndata

cntry gender N
   1      1  3
   1      2  4

My question now is,  i want mdata to  be as follows
cntry  sex1(F) sex2 (M)
 1          3         4

Then I want And I want merge cndata with  the original data,  mydata. How
do I do that?

Thank you oin advance.






On Mon, Oct 12, 2015 at 5:27 PM, MCGUIRE, Rhydwyn <
rmcgu at doh.health.nsw.gov.au> wrote:

> ddply() is what you are looking for. Here is an example
> http://www.inside-r.org/packages/cran/plyr/docs/ddply
>
> Cheers,
> Rhydwyn
>
>
> Rhydwyn McGuire
> Senior Biostatistician | Health Statistics NSW
> Level 7, 73 Miller St, North Sydney 2060
> Tel 02 9391 9781 | rmcgu at doh.health.nsw.gov.au
> www.health.nsw.gov.au
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
> Sent: Tuesday, 13 October 2015 4:06 AM
> To: r-help at r-project.org
> Subject: [R] by group
>
> Hi all,
>
>
> Assume that I have the following data set :
>
>  cntry  state city Gender (1=F and 2=M)
>
>  1 1 1   1
>  1 1 1   2
>  1 1 1   1
>  1 1 2   2
>  1 2 2   2
>  1 2 3   2
>  1 2 3   1
>
> I want to calculate the number of Females and Males, total (F+M) and
> percentage (F/M) by country, state and city.
>
> Here is the  sample of the output file  that I would like to have in a
> file.
>
> cntry state City Gender
> Cntry_F Cntry_M    Cntry_total 100 (Cntry_F/Cntry_M)
> St_F    st_M    St_total  100*(   St_F/   St_M)
> City_F     City_M     City_total  100*( City_F/ City_M)
>
>  1  1  1  1   3  4  7  75    2  2  4  50   1 1 3  33
>  1  1  1  2   3  4  7  75    2  2  4  50   1 1 3  33
>  1  1  1  1   3  4  7  75    2  2  4  50   1 1 3  33
>  1  1  2  2   3  4  7  75    2  2  4  50   2 0 2 100
>  1  2  2  2   3  4  7  75    2  1  3  67   2 0 2 100
>  1  2  3  2   3  4  7  75    2  1  3  67   1 1 2  50
>  1  2  3  1   3  4  7  75    2  1  3  67   1 1 2  50
>
> Your help is highly appreciated in advance
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> __________________________________________________________________________________________________________
> This email has been scanned for the NSW Ministry of Health by the Websense
> Hosted Email Security System.
> Emails and attachments are monitored to ensure compliance with the NSW
> Ministry of health's Electronic Messaging Policy.
>
> __________________________________________________________________________________________________________
>
> _______________________________________________________________________________________________________
> Disclaimer: This message is intended for the addressee named and may
> contain confidential information.
> If you are not the intended recipient, please delete it and notify the
> sender.
> Views expressed in this message are those of the individual sender, and
> are not necessarily the views of the NSW Ministry of Health.
>
> _______________________________________________________________________________________________________
> This email has been scanned for the NSW Ministry of Health by the Websense
> Hosted Email Security System.
> Emails and attachments are monitored to ensure compliance with the NSW
> Ministry of Health's Electronic Messaging Policy.
>
> _______________________________________________________________________________________________________
>

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Oct 21 09:28:47 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 21 Oct 2015 07:28:47 +0000
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <CAPLSCn0Qg5osOh91ixXMaBVighD9Y5xLSyD5wGJ-M+B3sx9Rsg@mail.gmail.com>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
	<CAF8bMcYMHG5wSWtXY=qogEGRkN9Sf_AacFY8quRirZ35ww1HXA@mail.gmail.com>
	<CAPLSCn0Qg5osOh91ixXMaBVighD9Y5xLSyD5wGJ-M+B3sx9Rsg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7FA6@SRVEXCHMBX.precheza.cz>

Hi

Several options

Coding in C+ or other similar language (you seem to be more familiar with them)

Using debug and find out how your function behaves in steps

Using function with smaller m, n with Rprof to see where the time is spent.

I believe that coding in R like it was C+ is the way to hell. There is nothing wrong with cycles however if you compute something which can be computed easily by vectorised approach you loose efficiency.

e.g.

you compute this
m<-5
> for ( i in 1:m-1)
+    {
+    b[i]<- (m-i)
+    }
> b
[1] 4 3 2 1

but you can achieve it by

b <-  ((m-1):1)

Time comparison:

> m<-1e5
> system.time(for ( i in 1:m-1) {b[i]<- (m-i)})
   user  system elapsed
  11.61    0.00   12.11
> system.time(bb <- ((m-1):1))
   user  system elapsed
      0       0       0
> all.equal(b,bb)
[1] TRUE

So the time gain is huge only in this small computation.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maram
> SAlem
> Sent: Tuesday, October 20, 2015 6:33 PM
> To: William Dunlap
> Cc: r-help at r-project.org
> Subject: Re: [R] Error in rep.int() invalid 'times' value
>
> Yes Indeed William. f1() works perfectly well and took only 30 secs to
> execute f1(25,15), but I wonder if there is anyway to speed up the
> execution of the rest of my code (almost seven hours now) ?
>
> Thanks for helping.
>
> Maram Salem
>
> On 20 October 2015 at 18:11, William Dunlap <wdunlap at tibco.com> wrote:
>
> > f0 is essentially your original code put into a function, so expect
> it
> > to fail in the same way your original code did.
> > f1 should give the same answer as f0, but it should use less memory
> > and time.
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com
> >
> >
> > On Tue, Oct 20, 2015 at 2:05 AM, Maram SAlem
> > <marammagdysalem at gmail.com>
> > wrote:
> > > Thanks William. I've tried the first code, ( with f0() ), but still
> > > for n=25, m=15 , I got this:
> > >
> > >> s<-f0(25,15)
> > > Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep)
> :
> > >   invalid 'times' value
> > > In addition: Warning message:
> > > In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> > >   NAs introduced by coercion to integer range
> > >
> > >
> > > I don't know if this is related to the memory limits of my laptop,
> > > or it doesn't have to do with the memory.
> > >
> > > Any help on how to fix this error will be greatly appreciated.
> > >
> > > Thanks All.
> > >
> > > Maram Salem
> > >
> > > On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com>
> wrote:
> > >>
> > >> Doing enumerative combinatorics with rejection methods rarely
> works
> > >> well. Try mapping your problem to the problem of choosing
> > >> m-1 items from n-1.  E.g., your code was
> > >>
> > >> f0 <- function(n, m) {
> > >>    stopifnot(n > m)
> > >>    D<-matrix(0,nrow=n-m+1,ncol=m-1)
> > >>    for (i in 1:m-1){
> > >>       D[,i]<-seq(0,n-m,1)
> > >>    }
> > >>    ED <- do.call(`expand.grid`,as.data.frame(D))
> > >>    ED<-unname(as.matrix(ED))
> > >>    lk<-which(rowSums(ED)<=(n-m))
> > >>    ED[lk,]
> > >> }
> > >>
> > >> and I think the following does the same thing in much less space
> by
> > >> transforming the output of combn().
> > >>
> > >> f1 <- function(n, m) {
> > >>    stopifnot(n > m)
> > >>    r0 <- t(diff(combn(n-1, m-1)) - 1L)
> > >>    r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
> > >> len=n-m+1), m-2))
> > >>    cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0) }
> > >>
> > >> The code for adding the last column is a bit clumsy and could
> > >> probably
> > be
> > >> improved.  Both f0 and f1 could also be cleaned up to work for
> m<=2.
> > >>
> > >> See Feller vol. 1 or Benjamin's "Proofs that (really) count" for
> > >> more on this sort of thing.
> > >>
> > >>
> > >>
> > >> Bill Dunlap
> > >> TIBCO Software
> > >> wdunlap tibco.com
> > >>
> > >> On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem
> > >> <marammagdysalem at gmail.com
> > >
> > >> wrote:
> > >>>
> > >>> Dear All,
> > >>>
> > >>> I'm trying to do a simple task (which is in fact a tiny part of a
> > larger
> > >>> code).
> > >>>
> > >>> I want to create a matrix, D, each of its columns is a sequence
> > >>> from 0
> > to
> > >>> (n-m), by 1. Then, using D, I want to create another matrix ED,
> > >>> whose rows represent all the possible combinations of the
> elements
> > >>> of the columns
> > of
> > >>> D. Then from ED, I'll select only the rows whose sum is less than
> > >>> or equal to (n-m), which will be called the matrix s. I used the
> > >>> following code:
> > >>>
> > >>> > n=5
> > >>> > m=3
> > >>> > D<-matrix(0,nrow=n-m+1,ncol=m-1) for (i in 1:m-1)
> > >>> +  {
> > >>> + D[,i]<-seq(0,n-m,1)
> > >>> +  }
> > >>> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > >>> > ED<-as.matrix(ED)
> > >>>
> > >>> > lk<-which(rowSums(ED)<=(n-m))
> > >>>
> > >>> > s<-ED[lk,]
> > >>>
> > >>>
> > >>> This works perfectly well. But for rather larger values of n and
> m
> > (which
> > >>> are not so large actually), the number of all possible
> > >>> combinations of the columns of D gets extremely large giving me
> > >>> this error (for n=25,
> > m=15):
> > >>>
> > >>> > ED <- do.call(`expand.grid`,as.data.frame(D))
> > >>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)),
> orep) :
> > >>>   invalid 'times' value
> > >>> In addition: Warning message:
> > >>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
> > >>>   NAs introduced by coercion to integer range
> > >>>
> > >>>
> > >>> Any help or suggestions will be greatly appreciated.
> > >>>
> > >>> Thanks,
> > >>>
> > >>> Maram Salem
> > >>>
> > >>>         [[alternative HTML version deleted]]
> > >>>
> > >>> ______________________________________________
> > >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>> PLEASE do read the posting guide
> > >>> http://www.R-project.org/posting-guide.html
> > >>> and provide commented, minimal, self-contained, reproducible
> code.
> > >>
> > >>
> > >
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From marammagdysalem at gmail.com  Wed Oct 21 09:47:47 2015
From: marammagdysalem at gmail.com (marammagdysalem at gmail.com)
Date: Wed, 21 Oct 2015 09:47:47 +0200
Subject: [R] Error in rep.int() invalid 'times' value
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7FA6@SRVEXCHMBX.precheza.cz>
References: <CAPLSCn0yddAeMtV=B3BtUG-zhRRwUgh4JAJ1n2se4dzNEOUSVg@mail.gmail.com>
	<CAF8bMcZGu5L1EgeU-BuhxEDq4p7s+xm=je0=_Ljc19E4=PDZvA@mail.gmail.com>
	<CAPLSCn0V33eWgYwfeeu3M3FxMhJtpSuOPXGMVFHo890jr05u_A@mail.gmail.com>
	<CAF8bMcYMHG5wSWtXY=qogEGRkN9Sf_AacFY8quRirZ35ww1HXA@mail.gmail.com>
	<CAPLSCn0Qg5osOh91ixXMaBVighD9Y5xLSyD5wGJ-M+B3sx9Rsg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF7FA6@SRVEXCHMBX.precheza.cz>
Message-ID: <7F135557-6BE7-41A5-B538-CA8447BE2337@gmail.com>

Thanks a lot Petr for ur reply and advice. Hope I 'd be able to minmize time as much as possible.

Regards,
Maram Salem

Sent from my iPhone

> On Oct 21, 2015, at 9:28 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
> Several options
> 
> Coding in C+ or other similar language (you seem to be more familiar with them)
> 
> Using debug and find out how your function behaves in steps
> 
> Using function with smaller m, n with Rprof to see where the time is spent.
> 
> I believe that coding in R like it was C+ is the way to hell. There is nothing wrong with cycles however if you compute something which can be computed easily by vectorised approach you loose efficiency.
> 
> e.g.
> 
> you compute this
> m<-5
>> for ( i in 1:m-1)
> +    {
> +    b[i]<- (m-i)
> +    }
>> b
> [1] 4 3 2 1
> 
> but you can achieve it by
> 
> b <-  ((m-1):1)
> 
> Time comparison:
> 
>> m<-1e5
>> system.time(for ( i in 1:m-1) {b[i]<- (m-i)})
>   user  system elapsed
>  11.61    0.00   12.11
>> system.time(bb <- ((m-1):1))
>   user  system elapsed
>      0       0       0
>> all.equal(b,bb)
> [1] TRUE
> 
> So the time gain is huge only in this small computation.
> 
> Cheers
> Petr
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Maram
>> SAlem
>> Sent: Tuesday, October 20, 2015 6:33 PM
>> To: William Dunlap
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Error in rep.int() invalid 'times' value
>> 
>> Yes Indeed William. f1() works perfectly well and took only 30 secs to
>> execute f1(25,15), but I wonder if there is anyway to speed up the
>> execution of the rest of my code (almost seven hours now) ?
>> 
>> Thanks for helping.
>> 
>> Maram Salem
>> 
>>> On 20 October 2015 at 18:11, William Dunlap <wdunlap at tibco.com> wrote:
>>> 
>>> f0 is essentially your original code put into a function, so expect
>> it
>>> to fail in the same way your original code did.
>>> f1 should give the same answer as f0, but it should use less memory
>>> and time.
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>> 
>>> 
>>> On Tue, Oct 20, 2015 at 2:05 AM, Maram SAlem
>>> <marammagdysalem at gmail.com>
>>> wrote:
>>>> Thanks William. I've tried the first code, ( with f0() ), but still
>>>> for n=25, m=15 , I got this:
>>>> 
>>>>> s<-f0(25,15)
>>>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep)
>> :
>>>>  invalid 'times' value
>>>> In addition: Warning message:
>>>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>>>  NAs introduced by coercion to integer range
>>>> 
>>>> 
>>>> I don't know if this is related to the memory limits of my laptop,
>>>> or it doesn't have to do with the memory.
>>>> 
>>>> Any help on how to fix this error will be greatly appreciated.
>>>> 
>>>> Thanks All.
>>>> 
>>>> Maram Salem
>>>> 
>>>> On 15 October 2015 at 17:52, William Dunlap <wdunlap at tibco.com>
>> wrote:
>>>>> 
>>>>> Doing enumerative combinatorics with rejection methods rarely
>> works
>>>>> well. Try mapping your problem to the problem of choosing
>>>>> m-1 items from n-1.  E.g., your code was
>>>>> 
>>>>> f0 <- function(n, m) {
>>>>>   stopifnot(n > m)
>>>>>   D<-matrix(0,nrow=n-m+1,ncol=m-1)
>>>>>   for (i in 1:m-1){
>>>>>      D[,i]<-seq(0,n-m,1)
>>>>>   }
>>>>>   ED <- do.call(`expand.grid`,as.data.frame(D))
>>>>>   ED<-unname(as.matrix(ED))
>>>>>   lk<-which(rowSums(ED)<=(n-m))
>>>>>   ED[lk,]
>>>>> }
>>>>> 
>>>>> and I think the following does the same thing in much less space
>> by
>>>>> transforming the output of combn().
>>>>> 
>>>>> f1 <- function(n, m) {
>>>>>   stopifnot(n > m)
>>>>>   r0 <- t(diff(combn(n-1, m-1)) - 1L)
>>>>>   r1 <- rep(seq(from=0, len=n-m+1), choose( seq(to=m-2, by=-1,
>>>>> len=n-m+1), m-2))
>>>>>   cbind(r0[, ncol(r0):1, drop=FALSE], r1, deparse.level=0) }
>>>>> 
>>>>> The code for adding the last column is a bit clumsy and could
>>>>> probably
>>> be
>>>>> improved.  Both f0 and f1 could also be cleaned up to work for
>> m<=2.
>>>>> 
>>>>> See Feller vol. 1 or Benjamin's "Proofs that (really) count" for
>>>>> more on this sort of thing.
>>>>> 
>>>>> 
>>>>> 
>>>>> Bill Dunlap
>>>>> TIBCO Software
>>>>> wdunlap tibco.com
>>>>> 
>>>>> On Thu, Oct 15, 2015 at 7:45 AM, Maram SAlem
>>>>> <marammagdysalem at gmail.com
>>>> 
>>>>> wrote:
>>>>>> 
>>>>>> Dear All,
>>>>>> 
>>>>>> I'm trying to do a simple task (which is in fact a tiny part of a
>>> larger
>>>>>> code).
>>>>>> 
>>>>>> I want to create a matrix, D, each of its columns is a sequence
>>>>>> from 0
>>> to
>>>>>> (n-m), by 1. Then, using D, I want to create another matrix ED,
>>>>>> whose rows represent all the possible combinations of the
>> elements
>>>>>> of the columns
>>> of
>>>>>> D. Then from ED, I'll select only the rows whose sum is less than
>>>>>> or equal to (n-m), which will be called the matrix s. I used the
>>>>>> following code:
>>>>>> 
>>>>>>> n=5
>>>>>>> m=3
>>>>>>> D<-matrix(0,nrow=n-m+1,ncol=m-1) for (i in 1:m-1)
>>>>>> +  {
>>>>>> + D[,i]<-seq(0,n-m,1)
>>>>>> +  }
>>>>>>> ED <- do.call(`expand.grid`,as.data.frame(D))
>>>>>>> ED<-as.matrix(ED)
>>>>>> 
>>>>>>> lk<-which(rowSums(ED)<=(n-m))
>>>>>> 
>>>>>>> s<-ED[lk,]
>>>>>> 
>>>>>> 
>>>>>> This works perfectly well. But for rather larger values of n and
>> m
>>> (which
>>>>>> are not so large actually), the number of all possible
>>>>>> combinations of the columns of D gets extremely large giving me
>>>>>> this error (for n=25,
>>> m=15):
>>>>>> 
>>>>>>> ED <- do.call(`expand.grid`,as.data.frame(D))
>>>>>> Error in rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)),
>> orep) :
>>>>>>  invalid 'times' value
>>>>>> In addition: Warning message:
>>>>>> In rep.int(rep.int(seq_len(nx), rep.int(rep.fac, nx)), orep) :
>>>>>>  NAs introduced by coercion to integer range
>>>>>> 
>>>>>> 
>>>>>> Any help or suggestions will be greatly appreciated.
>>>>>> 
>>>>>> Thanks,
>>>>>> 
>>>>>> Maram Salem
>>>>>> 
>>>>>>        [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible
>> code.
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


From dongchunyu2004 at 163.com  Wed Oct 21 11:17:11 2015
From: dongchunyu2004 at 163.com (Chunyu Dong)
Date: Wed, 21 Oct 2015 17:17:11 +0800 (CST)
Subject: [R] Transfer a 3-dimensional array to a matrix in R
In-Reply-To: <CAF8bMcb4Y=7ik4nR8Pf8w7yMC=pdeKK7ygQthk3ATwNofsbGMA@mail.gmail.com>
References: <698d9545.eaa4.150861ecef2.Coremail.dongchunyu2004@163.com>
	<CAA3Wa=sJy7y2cdgpB6rZ2H1fewRSzePspMg+ujiySuuy9oDUQA@mail.gmail.com>
	<CAF8bMcb4Y=7ik4nR8Pf8w7yMC=pdeKK7ygQthk3ATwNofsbGMA@mail.gmail.com>
Message-ID: <59bc8ec1.c3d2.15089b01c6f.Coremail.dongchunyu2004@163.com>

thank you very much! Both the two methods work well for my data.


Best wishes,


Chunyu








At 2015-10-20 19:48:18, "William Dunlap" <wdunlap at tibco.com> wrote:
>Or use aperm() (array index permuation):
>  > array(aperm(x, c(2,1,3)), c(6,3))
>       [,1] [,2] [,3]
>  [1,]    1    7   13
>  [2,]    4   10   16
>  [3,]    2    8   14
>  [4,]    5   11   17
>  [5,]    3    9   15
>  [6,]    6   12   18
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>
>On Tue, Oct 20, 2015 at 11:31 AM, John Laing <john.laing at gmail.com> wrote:
>>> x <- array(1:18, dim=c(3, 2, 3))
>>> x
>> , , 1
>>
>>      [,1] [,2]
>> [1,]    1    4
>> [2,]    2    5
>> [3,]    3    6
>>
>> , , 2
>>
>>      [,1] [,2]
>> [1,]    7   10
>> [2,]    8   11
>> [3,]    9   12
>>
>> , , 3
>>
>>      [,1] [,2]
>> [1,]   13   16
>> [2,]   14   17
>> [3,]   15   18
>>
>>> apply(x, 3, t)
>>      [,1] [,2] [,3]
>> [1,]    1    7   13
>> [2,]    4   10   16
>> [3,]    2    8   14
>> [4,]    5   11   17
>> [5,]    3    9   15
>> [6,]    6   12   18
>>
>>
>> On Tue, Oct 20, 2015 at 12:39 PM, Chunyu Dong <dongchunyu2004 at 163.com>
>> wrote:
>>
>>> Hello!
>>>
>>>
>>> Recently I am trying to transfer a large 3-dimensional array to a matrix.
>>> For example, a array like:
>>> , , 1
>>>      [,1] [,2]
>>> [1,]    1    4
>>> [2,]    2    5
>>> [3,]    3    6
>>> , , 2
>>>      [,1] [,2]
>>> [1,]    7   10
>>> [2,]    8   11
>>> [3,]    9   12
>>> , , 3
>>>      [,1] [,2]
>>> [1,]   13   16
>>> [2,]   14   17
>>> [3,]   15   18
>>>
>>>
>>> I would like to transfer it to a matrix like:
>>> 1        7          13
>>> 4        10        16
>>> 2        8          14
>>> 5        11        17
>>> 3        9          15
>>> 6        12        18
>>>
>>>
>>> Could you tell me how to do it in R ? Thank you very much!
>>>
>>>
>>> Best regards,
>>> Chunyu
>>>
>>>
>>>
>>>
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Wed Oct 21 11:20:27 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Wed, 21 Oct 2015 05:20:27 -0400
Subject: [R] ggplot2: discontinuous ribbon
Message-ID: <562758DB.7020508@cognigencorp.com>

Hi

I would like to use ggplot2 to create a 2d plot showing a series of 
shaded areas that are not continuous with respect to the x-axis 
variable. The expected result is illustrated below using lattice/grid 
functions.

-------------
pdata <- data.frame(
   x=c(1,2,2,1,NA,3,4,4,3,NA,5,6,6,5),
   y=c(3,3,2,2,NA,2,2,1,1,NA,2.5,3,2,2))

lattice::xyplot((1:6)~(1:6),panel=function(pdata=pdata){
   grid::grid.polygon(pdata$x,pdata$y,
                default.units='native',
                gp=grid::gpar(fill=1,col=NULL,lty=0))
},pdata=pdata)
-------------

Here is my attempt to reproduce this plot in ggplot.

-------------
library(ggplot2)
data <- data.frame(
   x=c(1,2,NA,3,4,NA,5,6),
   ymin=c(2,2,NA,1,1,NA,2,2),
   ymax=c(3,3,NA,2,2,NA,2.5,3)
)

ggplot(data,aes(x=x))+geom_ribbon(aes(ymin=ymin,ymax=ymax))
-------------

Obviously, either geom_ribbon expects continuity in the data or I need 
to setup my data and/or call differently...

Thanks for your help

Sebastien


From thierry.onkelinx at inbo.be  Wed Oct 21 11:25:14 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 21 Oct 2015 11:25:14 +0200
Subject: [R] ggplot2: discontinuous ribbon
In-Reply-To: <562758DB.7020508@cognigencorp.com>
References: <562758DB.7020508@cognigencorp.com>
Message-ID: <CAJuCY5z-n-HD7PC-zqAjeyJ4WKoxGzGrWn64diQ2BgWfhmJ-CQ@mail.gmail.com>

Dear Sebastien,

You are looking for geom_polygon().

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-10-21 11:20 GMT+02:00 sbihorel <Sebastien.Bihorel at cognigencorp.com>:

> Hi
>
> I would like to use ggplot2 to create a 2d plot showing a series of shaded
> areas that are not continuous with respect to the x-axis variable. The
> expected result is illustrated below using lattice/grid functions.
>
> -------------
> pdata <- data.frame(
>   x=c(1,2,2,1,NA,3,4,4,3,NA,5,6,6,5),
>   y=c(3,3,2,2,NA,2,2,1,1,NA,2.5,3,2,2))
>
> lattice::xyplot((1:6)~(1:6),panel=function(pdata=pdata){
>   grid::grid.polygon(pdata$x,pdata$y,
>                default.units='native',
>                gp=grid::gpar(fill=1,col=NULL,lty=0))
> },pdata=pdata)
> -------------
>
> Here is my attempt to reproduce this plot in ggplot.
>
> -------------
> library(ggplot2)
> data <- data.frame(
>   x=c(1,2,NA,3,4,NA,5,6),
>   ymin=c(2,2,NA,1,1,NA,2,2),
>   ymax=c(3,3,NA,2,2,NA,2.5,3)
> )
>
> ggplot(data,aes(x=x))+geom_ribbon(aes(ymin=ymin,ymax=ymax))
> -------------
>
> Obviously, either geom_ribbon expects continuity in the data or I need to
> setup my data and/or call differently...
>
> Thanks for your help
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Wed Oct 21 11:31:10 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Wed, 21 Oct 2015 05:31:10 -0400
Subject: [R] ggplot2: discontinuous ribbon
In-Reply-To: <CAJuCY5z-n-HD7PC-zqAjeyJ4WKoxGzGrWn64diQ2BgWfhmJ-CQ@mail.gmail.com>
References: <562758DB.7020508@cognigencorp.com>
	<CAJuCY5z-n-HD7PC-zqAjeyJ4WKoxGzGrWn64diQ2BgWfhmJ-CQ@mail.gmail.com>
Message-ID: <56275B5E.7050506@cognigencorp.com>

Thanks!

On 10/21/2015 5:25 AM, Thierry Onkelinx wrote:
> Dear Sebastien,
>
> You are looking for geom_polygon().
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature 
> and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no 
> more than asking him to perform a post-mortem examination: he may be 
> able to say what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does 
> not ensure that a reasonable answer can be extracted from a given body 
> of data. ~ John Tukey
>
> 2015-10-21 11:20 GMT+02:00 sbihorel 
> <Sebastien.Bihorel at cognigencorp.com 
> <mailto:Sebastien.Bihorel at cognigencorp.com>>:
>
>     Hi
>
>     I would like to use ggplot2 to create a 2d plot showing a series
>     of shaded areas that are not continuous with respect to the x-axis
>     variable. The expected result is illustrated below using
>     lattice/grid functions.
>
>     -------------
>     pdata <- data.frame(
>       x=c(1,2,2,1,NA,3,4,4,3,NA,5,6,6,5),
>       y=c(3,3,2,2,NA,2,2,1,1,NA,2.5,3,2,2))
>
>     lattice::xyplot((1:6)~(1:6),panel=function(pdata=pdata){
>       grid::grid.polygon(pdata$x,pdata$y,
>                    default.units='native',
>                    gp=grid::gpar(fill=1,col=NULL,lty=0))
>     },pdata=pdata)
>     -------------
>
>     Here is my attempt to reproduce this plot in ggplot.
>
>     -------------
>     library(ggplot2)
>     data <- data.frame(
>       x=c(1,2,NA,3,4,NA,5,6),
>       ymin=c(2,2,NA,1,1,NA,2,2),
>       ymax=c(3,3,NA,2,2,NA,2.5,3)
>     )
>
>     ggplot(data,aes(x=x))+geom_ribbon(aes(ymin=ymin,ymax=ymax))
>     -------------
>
>     Obviously, either geom_ribbon expects continuity in the data or I
>     need to setup my data and/or call differently...
>
>     Thanks for your help
>
>     Sebastien
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


From tr206 at kent.ac.uk  Wed Oct 21 12:48:23 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Wed, 21 Oct 2015 10:48:23 +0000
Subject: [R] quantreg package: residuals
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12010054A30A@EX10-LIVE-MBN1.ad.kent.ac.uk>


Greetings R Community,

I am running quantile regressions using quantreg in R. I also plot the residuals in a QQplot which indicate fat tails. I would like to try using Student distribution, but I do not know if the R software allows it for my task in hand.

In my opinion it is very likely that there is a structural break and if that is not taken into consideration by the rq() function leading to QQ plots which display nonlinearity. Hence, the model is slightly misspecified.
I was also wondering if I can cope with the nonlinearity by using a sandwich estimate in the summary.rq() function such as "ker".

How can I modify the model to improve the model specification and the standard errors specifications? Can I modify the regression model or do I have to change the method used to compute the error terms in summary.rq()?

Thanks for your feedback.


	[[alternative HTML version deleted]]


From jrkrideau at inbox.com  Wed Oct 21 13:16:56 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 21 Oct 2015 03:16:56 -0800
Subject: [R] r-markdown - keeping figures
In-Reply-To: <CAAjnpdjGnXg9Ui3TXLT0wcK5s7ZEVuMk3W0eD0W0L1nbsnVBxw@mail.gmail.com>
Message-ID: <9C6139FCBAB.0000001Djrkrideau@inbox.com>

It may not be elegant but you can just embed a png() command in the knitr code.  Code from RStudio example with png() command added.


```{r, echo=FALSE}
plot(cars)
png("~/Rjunk/pnd.png")
plot(cars)
dev.off()
```

John Kane
Kingston ON Canada


> -----Original Message-----
> From: wewolski at gmail.com
> Sent: Tue, 20 Oct 2015 18:18:04 +0200
> To: r-help at r-project.org
> Subject: [R] r-markdown - keeping figures
> 
> I am running r-markdown from r-studio and can't work out how to keep
> the figures.
> I mean I have a few figures in the document and would like to have
> them as separate pdf's too as I have been used to have them when using
> Sweave.
> 
> 
> 
> best regards
> Witold
> 
> 
> --
> Witold Eryk Wolski
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From ashenkin at ufl.edu  Wed Oct 21 13:30:46 2015
From: ashenkin at ufl.edu (Alexander Shenkin)
Date: Wed, 21 Oct 2015 12:30:46 +0100
Subject: [R] apply function across dataframe columns for non-exclusive groups
Message-ID: <56277766.2030007@ufl.edu>

Hello all,

I've been banging my head over what must be a simple solution.  I would 
like to apply a function across columns of a dataframe for rows grouped 
across different columns.  These groups are not exclusive.  See below 
for an example.  Happy to use dplyr, data.table, or whatever.  Any 
guidance appreciated!

Thanks,
Allie


desired algorithm: calculate a/(a+b) for each TRUE and FALSE grouping of 
columns grp1 and grp2.

this_df = data.frame(a = c(1,2,3,4,5), b = c(7,8,9,10,11), grp1 = 
c(T,T,F,F,F), grp2 = c(F,T,F,T,F))

desired output (doesn't have to be exactly this format, but something 
along these lines):

grp1 T 0.166
grp1 F 0.286
grp2 T 0.25
grp2 F 0.25


From rni.boh at gmail.com  Wed Oct 21 13:47:33 2015
From: rni.boh at gmail.com (Bob O'Hara)
Date: Wed, 21 Oct 2015 13:47:33 +0200
Subject: [R] r-markdown - keeping figures
In-Reply-To: <CAAjnpdjGnXg9Ui3TXLT0wcK5s7ZEVuMk3W0eD0W0L1nbsnVBxw@mail.gmail.com>
References: <CAAjnpdjGnXg9Ui3TXLT0wcK5s7ZEVuMk3W0eD0W0L1nbsnVBxw@mail.gmail.com>
Message-ID: <CAN-Z0xX6gxJ4X6BvcFj9+s-NUCVNebLOPe2F0CSRS0Hb7P9m2A@mail.gmail.com>

The figures should be saved somewhere. e.g. if you have x.Rmd, you
should have a X_files/ folder with subfolders for the figures (e.g.
X-html or X-latex). At least that's what I have.

Bob

On 20 October 2015 at 18:18, Witold E Wolski <wewolski at gmail.com> wrote:
> I am running r-markdown from r-studio and can't work out how to keep
> the figures.
> I mean I have a few figures in the document and would like to have
> them as separate pdf's too as I have been used to have them when using
> Sweave.
>
>
>
> best regards
> Witold
>
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org


From jdnewmil at dcn.davis.CA.us  Wed Oct 21 14:11:03 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 21 Oct 2015 14:11:03 +0200
Subject: [R] apply function across dataframe columns for non-exclusive
	groups
In-Reply-To: <56277766.2030007@ufl.edu>
References: <56277766.2030007@ufl.edu>
Message-ID: <BB17F584-0D39-4EB7-AAC2-24CB0D19B53B@dcn.davis.CA.us>

The calculation appears to be sum(a)/(sum(a)+sum(b)).

library(dplyr)
library(tidyr)
result <- (   this_df
          %>% gather( group, truth, -c(a,b) )
          %>% group_by( group, truth )
          %>% summarise( calc = sum(a)/(sum(a)+sum(b)) )
          %>% as.data.frame
          )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 21, 2015 1:30:46 PM GMT+02:00, Alexander Shenkin <ashenkin at ufl.edu> wrote:
>Hello all,
>
>I've been banging my head over what must be a simple solution.  I would
>
>like to apply a function across columns of a dataframe for rows grouped
>
>across different columns.  These groups are not exclusive.  See below 
>for an example.  Happy to use dplyr, data.table, or whatever.  Any 
>guidance appreciated!
>
>Thanks,
>Allie
>
>
>desired algorithm: calculate a/(a+b) for each TRUE and FALSE grouping
>of 
>columns grp1 and grp2.
>
>this_df = data.frame(a = c(1,2,3,4,5), b = c(7,8,9,10,11), grp1 = 
>c(T,T,F,F,F), grp2 = c(F,T,F,T,F))
>
>desired output (doesn't have to be exactly this format, but something 
>along these lines):
>
>grp1 T 0.166
>grp1 F 0.286
>grp2 T 0.25
>grp2 F 0.25
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Oct 21 14:21:59 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 21 Oct 2015 14:21:59 +0200
Subject: [R] r-markdown - keeping figures
In-Reply-To: <CAN-Z0xX6gxJ4X6BvcFj9+s-NUCVNebLOPe2F0CSRS0Hb7P9m2A@mail.gmail.com>
References: <CAAjnpdjGnXg9Ui3TXLT0wcK5s7ZEVuMk3W0eD0W0L1nbsnVBxw@mail.gmail.com>
	<CAN-Z0xX6gxJ4X6BvcFj9+s-NUCVNebLOPe2F0CSRS0Hb7P9m2A@mail.gmail.com>
Message-ID: <D8934EF1-9E6E-4E3C-A026-AAEB30D658DD@dcn.davis.CA.us>

I think the default now is to not save them unless you set the fig.path chunk option.

http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 21, 2015 1:47:33 PM GMT+02:00, Bob O'Hara <rni.boh at gmail.com> wrote:
>The figures should be saved somewhere. e.g. if you have x.Rmd, you
>should have a X_files/ folder with subfolders for the figures (e.g.
>X-html or X-latex). At least that's what I have.
>
>Bob
>
>On 20 October 2015 at 18:18, Witold E Wolski <wewolski at gmail.com>
>wrote:
>> I am running r-markdown from r-studio and can't work out how to keep
>> the figures.
>> I mean I have a few figures in the document and would like to have
>> them as separate pdf's too as I have been used to have them when
>using
>> Sweave.
>>
>>
>>
>> best regards
>> Witold
>>
>>
>> --
>> Witold Eryk Wolski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From alaios at yahoo.com  Wed Oct 21 15:34:48 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 21 Oct 2015 13:34:48 +0000 (UTC)
Subject: [R] threshold and replace values in a matrix
References: <917393453.879777.1445434488717.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <917393453.879777.1445434488717.JavaMail.yahoo@mail.yahoo.com>

Dear all I have a table as that.
test<-matrix(data=rnorm(100),ncol=10)
and I want to find the values that are below my thresholdthreshold<- -0.5and replace them with a -1 instead.

I can of course write a double nested for loop to check one by one elementif (test[i,j]<= threshold)?? test[i,j]<- -1
but that would be rather inneficient sice I have very large tables.
Does R offer any "automation" for matrix data types?
I would like to thank you in advance for your replyRegardsAlex

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Oct 21 15:43:43 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 21 Oct 2015 13:43:43 +0000
Subject: [R] threshold and replace values in a matrix
In-Reply-To: <917393453.879777.1445434488717.JavaMail.yahoo@mail.yahoo.com>
References: <917393453.879777.1445434488717.JavaMail.yahoo@mail.yahoo.com>
	<917393453.879777.1445434488717.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF81EC@SRVEXCHMBX.precheza.cz>

Hi

I wonder why you are asking that after quite a long use of R.

test[test < (-.5)] <- (-1)

Double loops seems to me the last resort in R if any other approach fails.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alaios
> via R-help
> Sent: Wednesday, October 21, 2015 3:35 PM
> To: R-help Mailing List
> Subject: [R] threshold and replace values in a matrix
>
> Dear all I have a table as that.
> test<-matrix(data=rnorm(100),ncol=10)
> and I want to find the values that are below my thresholdthreshold<- -
> 0.5and replace them with a -1 instead.
>
> I can of course write a double nested for loop to check one by one
> elementif (test[i,j]<= threshold)   test[i,j]<- -1 but that would be
> rather inneficient sice I have very large tables.
> Does R offer any "automation" for matrix data types?
> I would like to thank you in advance for your replyRegardsAlex
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From alaios at yahoo.com  Wed Oct 21 16:02:49 2015
From: alaios at yahoo.com (Alaios)
Date: Wed, 21 Oct 2015 14:02:49 +0000 (UTC)
Subject: [R] threshold and replace values in a matrix
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF81EC@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FF81EC@SRVEXCHMBX.precheza.cz>
Message-ID: <549087646.878781.1445436169833.JavaMail.yahoo@mail.yahoo.com>

Thanks. replace also looks to work okay. 


     On Wednesday, October 21, 2015 3:43 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
   

 Hi

I wonder why you are asking that after quite a long use of R.

test[test < (-.5)] <- (-1)

Double loops seems to me the last resort in R if any other approach fails.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Alaios
> via R-help
> Sent: Wednesday, October 21, 2015 3:35 PM
> To: R-help Mailing List
> Subject: [R] threshold and replace values in a matrix
>
> Dear all I have a table as that.
> test<-matrix(data=rnorm(100),ncol=10)
> and I want to find the values that are below my thresholdthreshold<- -
> 0.5and replace them with a -1 instead.
>
> I can of course write a double nested for loop to check one by one
> elementif (test[i,j]<= threshold)? test[i,j]<- -1 but that would be
> rather inneficient sice I have very large tables.
> Does R offer any "automation" for matrix data types?
> I would like to thank you in advance for your replyRegardsAlex
>
>? ? ? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.


  
	[[alternative HTML version deleted]]


From xie at yihui.name  Wed Oct 21 16:55:18 2015
From: xie at yihui.name (Yihui Xie)
Date: Wed, 21 Oct 2015 09:55:18 -0500
Subject: [R] r-markdown - keeping figures
In-Reply-To: <D8934EF1-9E6E-4E3C-A026-AAEB30D658DD@dcn.davis.CA.us>
References: <CAAjnpdjGnXg9Ui3TXLT0wcK5s7ZEVuMk3W0eD0W0L1nbsnVBxw@mail.gmail.com>
	<CAN-Z0xX6gxJ4X6BvcFj9+s-NUCVNebLOPe2F0CSRS0Hb7P9m2A@mail.gmail.com>
	<D8934EF1-9E6E-4E3C-A026-AAEB30D658DD@dcn.davis.CA.us>
Message-ID: <CANROs4dALg8mhjnJ_Gd2Qft7ZqDF5sGmxqeTONz70v3AAepfGg@mail.gmail.com>

Yes, setting the fig.path option will prevent rmarkdown from deleting
the figure files, and the more natural way to preserve these
intermediate files is to set the rmarkdown option keep_tex or keep_md
(depending on your output format) to yes, e.g.

---
output:
  pdf_document:
    keep_tex: yes
  html_document:
    keep_md: yes
---

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Wed, Oct 21, 2015 at 7:21 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I think the default now is to not save them unless you set the fig.path chunk option.
>
> http://kbroman.org/knitr_knutshell/pages/Rmarkdown.html
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 21, 2015 1:47:33 PM GMT+02:00, Bob O'Hara <rni.boh at gmail.com> wrote:
>>The figures should be saved somewhere. e.g. if you have x.Rmd, you
>>should have a X_files/ folder with subfolders for the figures (e.g.
>>X-html or X-latex). At least that's what I have.
>>
>>Bob
>>
>>On 20 October 2015 at 18:18, Witold E Wolski <wewolski at gmail.com>
>>wrote:
>>> I am running r-markdown from r-studio and can't work out how to keep
>>> the figures.
>>> I mean I have a few figures in the document and would like to have
>>> them as separate pdf's too as I have been used to have them when
>>using
>>> Sweave.
>>>
>>>
>>>
>>> best regards
>>> Witold
>>>
>>>
>>> --
>>> Witold Eryk Wolski
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amagicalfishy at gmail.com  Wed Oct 21 13:30:37 2015
From: amagicalfishy at gmail.com (SirDoctorGentleman .)
Date: Wed, 21 Oct 2015 07:30:37 -0400
Subject: [R] Can't Get Contents and Centers of gg2plot stat_hexbin Histograms
Message-ID: <CANXUdNbEMKS4VSQH=ja39j5YZNdQBMe+uikJBoYUXX_v0WQq+Q@mail.gmail.com>

To find the bin centers, I've tried gg2plot_build(), but the
center-coordinates it provides are not what's plotted. In the below example
there are several misplaced "o" symbols and some bins w/o a symbol on them.

library(ggplot2)
dat <- data.frame(x = rnorm(100000, 6, 2), y = rnorm(100000, 6, 2))
hexHist = ggplot(dat, aes(x, y)) + stat_binhex(bins=15);
hexDat = ggplot_build(hexHist)$data[[1]]
hexHistFinal = hexHist + annotate("text", hexDat$x, hexDat$y, label="o")
hexHistFinal

I've also given hexbin::hcell2xy(hexbin(dat$x, dat$y, 15)) a shot, but
that's even further away from what's plotted.

I'm not sure how to go about figuring out what data is in what bin. (My
ultimate goal is to take the data in a given bin, take the averages of a
third and forth column in said data, and use *annotate* to superimpose said
average on a hexagonal density histogram). I've been working on this since
yesterday morning with no results. :(

Any ideas?

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Wed Oct 21 16:53:07 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 21 Oct 2015 14:53:07 +0000
Subject: [R] Linear regression with a rounded response variable
Message-ID: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>

Hi,
I am dealing with a regression problem where the response variable, time (second) to walk 15 ft, is rounded to the nearest integer.  I do not care for the regression coefficients per se, but my main interest is in getting the prediction equation for walking speed, given the predictors (age, height, sex, etc.), where the predictions will be real numbers, and not integers.  The hope is that these predictions should provide unbiased estimates of the "unrounded" walking speed. These sounds like a measurement error problem, where the measurement error is due to rounding and hence would be uniformly distributed (-0.5, 0.5).

Are there any canonical approaches for handling this type of a problem? What is wrong with just doing the standard linear regression?

I googled and saw that this question was asked by someone else in a stackexchange post, but it was unanswered.  Any suggestions?

Thank you,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From ccberry at ucsd.edu  Wed Oct 21 19:57:14 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Wed, 21 Oct 2015 10:57:14 -0700
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <alpine.OSX.2.20.1510211033030.490@charles-berrys-macbook.local>

On Wed, 21 Oct 2015, Ravi Varadhan wrote:

> Hi, I am dealing with a regression problem where the response variable, 
> time (second) to walk 15 ft, is rounded to the nearest integer.  I do 
> not care for the regression coefficients per se, but my main interest is 
> in getting the prediction equation for walking speed, given the 
> predictors (age, height, sex, etc.), where the predictions will be real 
> numbers, and not integers.  The hope is that these predictions should 
> provide unbiased estimates of the "unrounded" walking speed. These 
> sounds like a measurement error problem, where the measurement error is 
> due to rounding and hence would be uniformly distributed (-0.5, 0.5).
>

Not the usual "measurement error model" problem, though, where the errors 
are in X and not independent of XB.

Look back at the proof of the unbiasedness of least squares under the 
Gauss-Markov setup. The errors in Y need to have expectation zero.

>From your description (but see caveat below) this is true of walking 
*time*, but not not exactly true of walking *speed* (modulo the usual 
assumptions if they apply to time). In fact if E(epsilon) = 0 were true of 
unrounded time, it would not be true of unrounded speed (and vice versa).


> Are there any canonical approaches for handling this type of a problem?

Work out the bias analytically? Parametric bootstrap? Data augmentation 
and friends?

> What is wrong with just doing the standard linear regression?
>

Well, what do the actual values look like?

If half the subjects have a value of 5 seconds and the rest are split 
between 4 and 6, your assertion that rounding induces an error of 
dunif(epsilon,-0.5,0.5) is surely wrong (more positive errors in the 6 
second group and more negative errors in the 4 second group under any 
plausible model).


HTH,

Chuck


From marlinkcox at gmail.com  Wed Oct 21 20:31:34 2015
From: marlinkcox at gmail.com (Marlin Keith Cox)
Date: Wed, 21 Oct 2015 10:31:34 -0800
Subject: [R] Reordering of numerical vector
Message-ID: <CAHskWAX1KKQ0H54fxLjuH4-neALtiW3WLpn2J3iY_316qRrGnw@mail.gmail.com>

I do not have a dataset to share as I do not believe it needs it and I am
not sure I could reproduce easily.
I have a column of numerical data (Days) and another of a a measurement
(Resistance).  After subsetting, I do a linear regression of the two, and
it reorders the day (x axis) into some other order.

I am a fairly experienced R user and I cannot find the answer anywhere.

I am certain it is simple as these things usually are for me.

Thank you ahead of time.  Keith



M. Keith Cox, Ph.D.
Principal
MKConsulting
17105 Glacier Hwy
Juneau, AK 99801
U.S. 907.957.4606

	[[alternative HTML version deleted]]


From tianxu03 at gmail.com  Wed Oct 21 18:21:31 2015
From: tianxu03 at gmail.com (Victor Tian)
Date: Wed, 21 Oct 2015 12:21:31 -0400
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <CAHJErNAs18SgnLc5zwApqk_PRAUZiD6P1O=8ZJnRrwN=Xsosmw@mail.gmail.com>

Hi Ravi,

Thanks for this interesting question. My thoughts are given below.

If you believe the rounding is indeed uniformly distributed, then the
problem is equivalent with adding a uniform random error between (-0.5,
0.5) for every observation in addition to the standard normal error, which
will make the new error term have a mixture distribution.

Intuitively, the impact of this newly added term depends on the relative
scale of the original normal and the new uniform error terms. To see the
exact impact, you can simulate sets of new response variables by adding
uniform errors from (-0.5, 0.5) to the original response variables and see
the results.

I wish I could have more theoretical answers and hope this helps as well.

Best,
Xu

Xu Tian, Ph.D.
Senior Statistician
Validus Research
New York, NY 10005

On Wed, Oct 21, 2015 at 10:53 AM, Ravi Varadhan <ravi.varadhan at jhu.edu>
wrote:

> Hi,
> I am dealing with a regression problem where the response variable, time
> (second) to walk 15 ft, is rounded to the nearest integer.  I do not care
> for the regression coefficients per se, but my main interest is in getting
> the prediction equation for walking speed, given the predictors (age,
> height, sex, etc.), where the predictions will be real numbers, and not
> integers.  The hope is that these predictions should provide unbiased
> estimates of the "unrounded" walking speed. These sounds like a measurement
> error problem, where the measurement error is due to rounding and hence
> would be uniformly distributed (-0.5, 0.5).
>
> Are there any canonical approaches for handling this type of a problem?
> What is wrong with just doing the standard linear regression?
>
> I googled and saw that this question was asked by someone else in a
> stackexchange post, but it was unanswered.  Any suggestions?
>
> Thank you,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor,  Department of Oncology
> Division of Biostatistics & Bionformatics
> Sidney Kimmel Comprehensive Cancer Center
> Johns Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
*Xu Tian*

	[[alternative HTML version deleted]]


From marlinkcox at gmail.com  Wed Oct 21 21:00:43 2015
From: marlinkcox at gmail.com (Marlin Keith Cox)
Date: Wed, 21 Oct 2015 11:00:43 -0800
Subject: [R] Reordering of numerical vector
In-Reply-To: <CAHskWAX1KKQ0H54fxLjuH4-neALtiW3WLpn2J3iY_316qRrGnw@mail.gmail.com>
References: <CAHskWAX1KKQ0H54fxLjuH4-neALtiW3WLpn2J3iY_316qRrGnw@mail.gmail.com>
Message-ID: <CAHskWAWPJP8iEwTSdks2owwEGixSPNrcPxXP6zrajXRrUfDMzA@mail.gmail.com>

Got it.  During a read.csv I used stringsAsFactors=FALSE

M. Keith Cox, Ph.D.
Principal
MKConsulting
17105 Glacier Hwy
Juneau, AK 99801
U.S. 907.957.4606

On Wed, Oct 21, 2015 at 10:31 AM, Marlin Keith Cox <marlinkcox at gmail.com>
wrote:

> I do not have a dataset to share as I do not believe it needs it and I am
> not sure I could reproduce easily.
> I have a column of numerical data (Days) and another of a a measurement
> (Resistance).  After subsetting, I do a linear regression of the two, and
> it reorders the day (x axis) into some other order.
>
> I am a fairly experienced R user and I cannot find the answer anywhere.
>
> I am certain it is simple as these things usually are for me.
>
> Thank you ahead of time.  Keith
>
>
>
> M. Keith Cox, Ph.D.
> Principal
> MKConsulting
> 17105 Glacier Hwy
> Juneau, AK 99801
> U.S. 907.957.4606
>

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Wed Oct 21 22:07:17 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Wed, 21 Oct 2015 15:07:17 -0500
Subject: [R] Update dataframe based on some conditions
Message-ID: <CAKL8G3FycnGdyqXW8=B-bPXfBpj9ig_ZsZvLJR8GTkO65eyfdA@mail.gmail.com>

Dear R-help,

I am working on what it seems to be a simple problem, but after several
hours trying to come up with a solution, unfortunately I have not been able
to.

I would like to go from "datain" to "dataout", that is, create the NEWREF
variable according with some restrictions, and update the values for the
remaining variables in the original data set (which is way more bigger than
this example). The problem can be described as having products (coded as
REF) in stock. Here, the total nomber of units in stock are named TOENDREF
and those required for the customer are given by TIMEREF. The idea is to
use as many units of the previous REF as possible before using a new REF.

## input
datain <- structure(list(REF = c("999", "999", "999", "1099", "731", "731",
"731", "731", "1442", "1442", "1442", "1442"), TIMEREF = c(120,
240, 360, 30, 30, 60, 90, 120, 30, 60, 90, 120), TOENDREF = c(390,
270, 150, 480, 480, 450, 420, 390, 480, 450, 420, 390)), .Names = c("REF",
"TIMEREF", "TOENDREF"), row.names = c(NA, 12L), class = "data.frame")
datain

## output
dataout <- structure(list(REF = c(999L, 999L, 999L, 1099L, 731L, 731L,
731L,
731L, 1442L, 1442L, 1442L, 1442L), TIMEREF = c(120L, 240L, 360L,
30L, 30L, 60L, 90L, 120L, 30L, 60L, 90L, 120L), TOENDREF = c(390L,
270L, 150L, 120L, 90L, 30L, 420L, 300L, 270L, 210L, 120L, 0L),
    NEWREF = c(999L, 999L, 999L, 999L, 999L, 999L, 731L, 731L,
    731L, 731L, 731L, 731L)), .Names = c("REF", "TIMEREF", "TOENDREF",
"NEWREF"), row.names = c(NA, 12L), class = "data.frame")
dataout


I what follows I will try to explain what I want to accomplish:

* Example 1
Take rows 3 and 4 of "datain"

#REF TIMEREF TOENDREF
#3   999     360      150
#4  1099      30      480

As 150 units of REF 999 are available, we could substitute the 30 units of
REF 1099 with them. Hence, the 4th row of the _updated_ "datain" becomes

#REF TIMEREF TOENDREF NEWREF
#3   999     360      150      999
#4  1099      30      120      999

* Example 2
Now, let's take rows 3 to 8 of the _updated_ "datain":

#REF TIMEREF TOENDREF
#3   999     360      150
#4   999      30      120
#5   731      30      480
#6   731      60      450
#7   731      90      420
#8   731     120      390

In row 4, there 120 units available to be used. The number of units
required of REF 731 is 30, which can be easily covered by the remaining 120
units of REF 999. By doing so, the remaining units of REF 999 would then be
90.  Hence, the newly _updated_ "datain" becomes

#REF TIMEREF TOENDREF
#3   999     360      150
#4   999      30      120
#5   999      30       90
#6   999      60       30
#7   731      90      420
#8   731     120      300

Finally, the updated "datain" file after processing the remaining REF would
be

#REF TIMEREF TOENDREF
#9  731      30      270
#10 731      60      210
#11 731      90      120
#12 731     120        0

Hopefully I have explained well what I would like to end up with.  If this
is not the case, I will be more than happy to provide more information.

Any help would be very much appreciated.  Thanks in advance.

Best regards,
Jorge Velez.-

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Wed Oct 21 22:11:57 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 21 Oct 2015 16:11:57 -0400
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <CAP01uRnA9+6T1XNudvVEBYG+7qhzrk5Cf7jv_3QDcbC43VTxug@mail.gmail.com>

This could be modeled directly using Bayesian techniques. Consider the
Bayesian version of the following model where we only observe y and X.  y0
is not observed.

   y0 <- X b + error
   y <- round(y0)

The following code is based on modifying the code in the README of the CRAN
rcppbugs R package.


library(rcppbugs)
set.seed(123)

# set up the test data - y and X are observed but not y0
NR <- 1e2L
NC <- 2L
X <- cbind(1, rnorm(10))
y0 <- X %*% 1:2
y <- round(y0)

# for comparison run a normal linear model w/ lm.fit using X and y
lm.res <- lm.fit(X,y)
print(coef(lm.res))
##        x1        x2
## 0.9569366 1.9170808

# RCppBugs Model
b <- mcmc.normal(rnorm(NC),mu=0,tau=0.0001)
tau.y <- mcmc.gamma(sd(as.vector(y)),alpha=0.1,beta=0.1)
y.hat <- deterministic(function(X,b) { round(X %*% b) }, X, b)
y.lik <- mcmc.normal(y,mu=y.hat,tau=tau.y,observed=TRUE)
m <- create.model(b, tau.y, y.hat, y.lik)

# run the Bayesian model based on y and X
cat("running model...\n")
runtime <- system.time(ans <- run.model(m, iterations=1e5L, burn=1e4L,
adapt=1e3L, thin=10L))
print(apply(ans[["b"]],2,mean))
## [1] 0.9882485 2.0009989


On Wed, Oct 21, 2015 at 10:53 AM, Ravi Varadhan <ravi.varadhan at jhu.edu>
wrote:

> Hi,
> I am dealing with a regression problem where the response variable, time
> (second) to walk 15 ft, is rounded to the nearest integer.  I do not care
> for the regression coefficients per se, but my main interest is in getting
> the prediction equation for walking speed, given the predictors (age,
> height, sex, etc.), where the predictions will be real numbers, and not
> integers.  The hope is that these predictions should provide unbiased
> estimates of the "unrounded" walking speed. These sounds like a measurement
> error problem, where the measurement error is due to rounding and hence
> would be uniformly distributed (-0.5, 0.5).
>
> Are there any canonical approaches for handling this type of a problem?
> What is wrong with just doing the standard linear regression?
>
> I googled and saw that this question was asked by someone else in a
> stackexchange post, but it was unanswered.  Any suggestions?
>
> Thank you,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor,  Department of Oncology
> Division of Biostatistics & Bionformatics
> Sidney Kimmel Comprehensive Cancer Center
> Johns Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com

	[[alternative HTML version deleted]]


From peter.salzmanuser at gmail.com  Wed Oct 21 22:15:53 2015
From: peter.salzmanuser at gmail.com (peter salzman)
Date: Wed, 21 Oct 2015 16:15:53 -0400
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <CAHdoti=mquhZeSOhN8m-cza5CcgThnZ8uWk88t8mEEw4x-3H-Q@mail.gmail.com>

here is one thought:

if you plug in your numbers into any kind of regression you will get
prediction that are real numbers and not necessarily integers, it may be
that you predictions are good enough with this approximate value of Y. you
could test this by randomly shuffling your data by +- 0.5 and compare the
results with the original result.

let me add another idea:

if data is not fully observed this falls under the umbrella of censored
data, in this case you have interval censoring. if you see 5 then the
observations is in interval [4.5, 5.5]
i'm not familiar with the field but i'd search for 'regression with
interval censoring'


peter


On Wed, Oct 21, 2015 at 10:53 AM, Ravi Varadhan <ravi.varadhan at jhu.edu>
wrote:

> Hi,
> I am dealing with a regression problem where the response variable, time
> (second) to walk 15 ft, is rounded to the nearest integer.  I do not care
> for the regression coefficients per se, but my main interest is in getting
> the prediction equation for walking speed, given the predictors (age,
> height, sex, etc.), where the predictions will be real numbers, and not
> integers.  The hope is that these predictions should provide unbiased
> estimates of the "unrounded" walking speed. These sounds like a measurement
> error problem, where the measurement error is due to rounding and hence
> would be uniformly distributed (-0.5, 0.5).
>
> Are there any canonical approaches for handling this type of a problem?
> What is wrong with just doing the standard linear regression?
>
> I googled and saw that this question was asked by someone else in a
> stackexchange post, but it was unanswered.  Any suggestions?
>
> Thank you,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor,  Department of Oncology
> Division of Biostatistics & Bionformatics
> Sidney Kimmel Comprehensive Cancer Center
> Johns Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Peter Salzman, PhD
Department of Biostatistics and Computational Biology
University of Rochester

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Oct 22 02:11:22 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 22 Oct 2015 02:11:22 +0200
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <alpine.OSX.2.20.1510211033030.490@charles-berrys-macbook.local>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
	<alpine.OSX.2.20.1510211033030.490@charles-berrys-macbook.local>
Message-ID: <EC1F3221-76D9-490C-8A63-FB1A489E958A@gmail.com>


> On 21 Oct 2015, at 19:57 , Charles C. Berry <ccberry at ucsd.edu> wrote:
> 
> On Wed, 21 Oct 2015, Ravi Varadhan wrote:
> 
>> [snippage]
> 
> If half the subjects have a value of 5 seconds and the rest are split between 4 and 6, your assertion that rounding induces an error of dunif(epsilon,-0.5,0.5) is surely wrong (more positive errors in the 6 second group and more negative errors in the 4 second group under any plausible model).

Yes, and I think that the suggestion in another post to look at censored regression is more in the right direction. 

In general, I'd expect the bias caused by rounding the response to quite small, except at very high granularity. I did a few small experiments with the simplest possible linear model: estimating a mean based on highly rounded data,

> y <- round(rnorm(1e2,pi,.5))
> mean(y)
[1] 3.12
> table(y)
y
 2  3  4  5 
13 63 23  1 

Or, using a bigger sample:

> mean(round(rnorm(1e8,pi,.5)))
[1] 3.139843

in which there is a visible bias, but quite a small one: 

> pi - 3.139843
[1] 0.001749654

At lower granularity (sd=1 instead of .5), the bias has almost disappeared.

> mean(round(rnorm(1e8,pi,1)))
[1] 3.141577

If the granularity is increased sufficiently, you _will_ see a sizeable bias (because almost all observations will be round(pi)==3):

> mean(round(rnorm(1e8,pi,.1)))
[1] 3.00017


A full ML fit (with known sigma=1) is pretty easily done:

> library(stats4)
> mll <- function(mu)-sum(log(pnorm(y+.5,mu, .5)-pnorm(y-.5, mu, .5)))
> mle(mll,start=list(mu=3))

Call:
mle(minuslogl = mll, start = list(mu = 3))

Coefficients:
      mu 
3.122069 
> mean(y)
[1] 3.12

As you see, the difference is only 0.002. 

A small simulation (1000 repl.) gave (r[1,]==MLE ; r{2,]==mean)

> summary(r[1,]-r[2,])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
-0.004155  0.000702  0.001495  0.001671  0.002554  0.006860 

so the corrections relative to the crude mean stay within one unit in the 2nd place. Notice  that the corrections are pretty darn close to cancelling out the bias.

-pd

> 
> 
> HTH,
> 
> Chuck
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j.para.fernandez at hotmail.com  Thu Oct 22 10:49:40 2015
From: j.para.fernandez at hotmail.com (=?iso-8859-1?B?SmVz+nMgUGFyYSBGZXJu4W5kZXo=?=)
Date: Thu, 22 Oct 2015 10:49:40 +0200
Subject: [R] Get the output of a function in R GUI
Message-ID: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>

Hi,

I want to create my own RGUI, so I?m using tcltk for that. 

In a very simple example, I want to get the response of a function into a tktext, so I have done this:
data<-c(2,3,5,2)
tt<-tktoplevel
text<-tktext(tt)
tkpack(text)
sum(data)

How can I get the output of sum(data) in my tktext??

Thanks!
Jes?s 
 		 	   		  
	[[alternative HTML version deleted]]


From kmezhoud at gmail.com  Thu Oct 22 11:06:20 2015
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Thu, 22 Oct 2015 10:06:20 +0100
Subject: [R] Get the output of a function in R GUI
In-Reply-To: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>
References: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>
Message-ID: <CALJKBv-pOy=kmCXHe+b-cWGwYxehv2=aTfXJ+Jv1eUVhZq5=wA@mail.gmail.com>

Hi,

require(tcltk)
data<-c(2,3,5,2)
PressedOK <- function()
{
  tkmessageBox(message=sum(data))
}

tt <- tktoplevel()
OK.but <- tkbutton(tt,text="OK",command=PressedOK)
tkgrid(OK.but)
tkfocus(tt)

Please take a look in examples:
http://mcu.edu.tw/~chenmh/teaching/project/r/reference/RTclTkExamples/
Karim

On Thu, Oct 22, 2015 at 9:49 AM, Jes?s Para Fern?ndez <
j.para.fernandez at hotmail.com> wrote:

> Hi,
>
> I want to create my own RGUI, so I?m using tcltk for that.
>
> In a very simple example, I want to get the response of a function into a
> tktext, so I have done this:
> data<-c(2,3,5,2)
> tt<-tktoplevel
> text<-tktext(tt)
> tkpack(text)
> sum(data)
>
> How can I get the output of sum(data) in my tktext??
>
> Thanks!
> Jes?s
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From j.para.fernandez at hotmail.com  Thu Oct 22 11:16:51 2015
From: j.para.fernandez at hotmail.com (=?iso-8859-1?B?SmVz+nMgUGFyYSBGZXJu4W5kZXo=?=)
Date: Thu, 22 Oct 2015 11:16:51 +0200
Subject: [R] Get the output of a function in R GUI
In-Reply-To: <CALJKBv-pOy=kmCXHe+b-cWGwYxehv2=aTfXJ+Jv1eUVhZq5=wA@mail.gmail.com>
References: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>,
	<CALJKBv-pOy=kmCXHe+b-cWGwYxehv2=aTfXJ+Jv1eUVhZq5=wA@mail.gmail.com>
Message-ID: <DUB131-W7056E163E18AF3717D65A4CC270@phx.gbl>

Thanks, but it does?nt do what I want.

What I wnat is to insert it into a tktext. 

Jes?s

Date: Thu, 22 Oct 2015 10:06:20 +0100
Subject: Re: [R] Get the output of a function in R GUI
From: kmezhoud at gmail.com
To: j.para.fernandez at hotmail.com
CC: r-help at r-project.org

Hi, 

require(tcltk)
data<-c(2,3,5,2)
PressedOK <- function()
{
  tkmessageBox(message=sum(data))
}

tt <- tktoplevel()
OK.but <- tkbutton(tt,text="OK",command=PressedOK)
tkgrid(OK.but)
tkfocus(tt)

Please take a look in examples: http://mcu.edu.tw/~chenmh/teaching/project/r/reference/RTclTkExamples/
Karim

On Thu, Oct 22, 2015 at 9:49 AM, Jes?s Para Fern?ndez <j.para.fernandez at hotmail.com> wrote:
Hi,



I want to create my own RGUI, so I?m using tcltk for that.



In a very simple example, I want to get the response of a function into a tktext, so I have done this:

data<-c(2,3,5,2)

tt<-tktoplevel

text<-tktext(tt)

tkpack(text)

sum(data)



How can I get the output of sum(data) in my tktext??



Thanks!

Jes?s



        [[alternative HTML version deleted]]




______________________________________________

R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.

 		 	   		  
	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Thu Oct 22 11:17:34 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 22 Oct 2015 11:17:34 +0200
Subject: [R] Get the output of a function in R GUI
In-Reply-To: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>
References: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>
Message-ID: <B3AA7F56-A988-4E4B-988B-D1C360B3B995@gmail.com>


On 22 Oct 2015, at 10:49 , Jes?s Para Fern?ndez <j.para.fernandez at hotmail.com> wrote:

> Hi,
> 
> I want to create my own RGUI, so I?m using tcltk for that. 
> 
> In a very simple example, I want to get the response of a function into a tktext, so I have done this:
> data<-c(2,3,5,2)
> tt<-tktoplevel
> text<-tktext(tt)
> tkpack(text)
> sum(data)
> 
> How can I get the output of sum(data) in my tktext??


For instance with

tkinsert(text, "end", sum(data))

However, you need to reach out for a Tcl/Tk reference manual to sort out the mysteries of the index argument and of the widget subcommands in general.

-pd

> 
> Thanks!
> Jes?s 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From j.para.fernandez at hotmail.com  Thu Oct 22 11:24:07 2015
From: j.para.fernandez at hotmail.com (=?utf-8?B?SmVzw7pzIFBhcmEgRmVybsOhbmRleg==?=)
Date: Thu, 22 Oct 2015 11:24:07 +0200
Subject: [R] Get the output of a function in R GUI
In-Reply-To: <B3AA7F56-A988-4E4B-988B-D1C360B3B995@gmail.com>
References: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>,
	<B3AA7F56-A988-4E4B-988B-D1C360B3B995@gmail.com>
Message-ID: <DUB131-W259004CDD2F1F3CD1C813CC270@phx.gbl>

Thanks, but just one more question

How can I catch the response and put it on a tktext?

Imagien there is a function that the response is an error, how can i catch this error and manage it?

Thanks!

> From: pdalgd at gmail.com
> Subject: Re: [R] Get the output of a function in R GUI
> Date: Thu, 22 Oct 2015 11:17:34 +0200
> CC: r-help at r-project.org
> To: j.para.fernandez at hotmail.com
> 
> 
> On 22 Oct 2015, at 10:49 , Jes?s Para Fern?ndez <j.para.fernandez at hotmail.com> wrote:
> 
> > Hi,
> > 
> > I want to create my own RGUI, so I?m using tcltk for that. 
> > 
> > In a very simple example, I want to get the response of a function into a tktext, so I have done this:
> > data<-c(2,3,5,2)
> > tt<-tktoplevel
> > text<-tktext(tt)
> > tkpack(text)
> > sum(data)
> > 
> > How can I get the output of sum(data) in my tktext??
> 
> 
> For instance with
> 
> tkinsert(text, "end", sum(data))
> 
> However, you need to reach out for a Tcl/Tk reference manual to sort out the mysteries of the index argument and of the widget subcommands in general.
> 
> -pd
> 
> > 
> > Thanks!
> > Jes?s 
> > 		 	   		  
> > 	[[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 
 		 	   		  
	[[alternative HTML version deleted]]


From tcpietro at yahoo.it  Thu Oct 22 14:03:21 2015
From: tcpietro at yahoo.it (pietro chen)
Date: Thu, 22 Oct 2015 14:03:21 +0200
Subject: [R] SARIMA in rpy2
Message-ID: <CAAPSY0Q2_hEFrSHrHU=mi4cJwOeYU3wg39HMNQAE1v1sdweBMw@mail.gmail.com>

Hello,

Am trying to estimate a seasonal Arima by calling the R forecast package in
Rpy2:

fit = forecast.Arima(x = h02, order = order, seasonal = seasonal)

Strangely I get the estimates of the non-seasonal part, only, even if the
model is specified as (3,0,1)x(0,1,2). Can anyone tell me where the issue
is?

Regards,

P.

	[[alternative HTML version deleted]]


From office at djura.simpleuploader.com  Thu Oct 22 01:00:05 2015
From: office at djura.simpleuploader.com (Ana)
Date: Wed, 21 Oct 2015 19:00:05 -0400
Subject: [R] Anina magija (r help)
Message-ID: <beac6ade8f452803fccf208ab0b85864@djura.simpleuploader.com>

"Anina magija" je ?aj za mr?avljenje.



Napravljen je od bilja koje svakodnevno koristimo u ishrani i le?enju, po
recepturi koju su generacije travarki prenosile sa kolena na koleno i koju
je svaka naredna generacija obogatila novim dodatkom i boljim efektom. 



http://djura.simpleuploader.com/int/link.php?M=2797433&N=432&L=37&F=T



Za razliku od mnogih proizvoda, ?ajeva, tableta, pra?kova i napitaka,
"Anina magija" zaista radi svoj posao. Topi masne naslage bez obzira na to
?ta i koliko jedete.



Uputstvo za upotrebu je veoma jednostavno - pije se 1 ?olja ujutru posle
doru?ka i 1 uve?e posle ve?ere. Jedete ?ta god po?elite! Nema dijete!
i mr?avite lako...



Vi?e informacija mo?ete na?i na na?oj stranici.





To stop receiving these
emails:http://djura.simpleuploader.com/int/unsubscribe.php?M=2797433&C=e30553db539f628f5010553023e12258&L=48&N=432

	[[alternative HTML version deleted]]


From lindeh at uw.edu  Wed Oct 21 21:37:43 2015
From: lindeh at uw.edu (Hannah L. Linder)
Date: Wed, 21 Oct 2015 12:37:43 -0700
Subject: [R] GARCH convergence error in for-loop
Message-ID: <CAF0=RbaWK5Nj7ogjM-Eo_WfaQUVcO2J=OLK_pmP1y7UGirHpJg@mail.gmail.com>

Hello,

I am using the rugarch package to fit to simulated data. I am fitting the
same garch model to 1000 simulated data sets (all very similar with
slightly different error). Within each data set I am using 10-fold CV, so I
am fitting the model to 10 training sets. When I run the code (shown below)
I occasionally receive the error:

Solver Message: Error in is.nloptr(ret) : at least one element in x0 < lb

When I re-run the exact same code starting from the iteration that caused
and error, the error goes away. Does anyone know if this may be an error
with R or if I am missing a problem in the model?

Thank-you very much for your time! I could not generate reproducible code
for this question, but am happy to supply a sample of my data if someone is
interested in helping.

Hannah Linder
M.S.c School of Aquatic and Fishery Sciences, UW

Code:


library(rugarch)

fit.spec1=array(list(),c(1000,10))
fit1=array(list(),c(1000,10))


for (j in 1:1000){
  for (i in 1:10){
    fit.spec1[[j,i]]=ugarchspec(variance.model = list(model = "sGARCH",
                                       garchOrder = c(1,
1),external.regressors=as.matrix(train.all[[j]][[i]][,c(5,6)])),
                                mean.model= list(armaOrder = c(1,1),
                                                 include.mean = T,

 external.regressors=as.matrix(train.all[[j]][[i]][,c(2,4,5,6)])),
                                distribution.model = "sstd")
    fit1[[j,i]] <- ugarchfit(data=train.all[[j]][[i]][,c(1)],spec =
fit.spec1[[j,i]],solver="hybrid")
 }}

I am actually using the model on biological data, rather than finance. The
regressors in the model are  Julian day count (2), tidal range (4), and a
sin and cos (5,6) transform for time-of-day (24-hr period).

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Wed Oct 21 22:25:36 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Thu, 22 Oct 2015 07:25:36 +1100
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <CAHdoti=mquhZeSOhN8m-cza5CcgThnZ8uWk88t8mEEw4x-3H-Q@mail.gmail.com>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
	<CAHdoti=mquhZeSOhN8m-cza5CcgThnZ8uWk88t8mEEw4x-3H-Q@mail.gmail.com>
Message-ID: <CA+8X3fVJx1H=V6X6NtevSrWW+augAPYpnDvAUQUYYJ-MTCR78w@mail.gmail.com>

Hi Ravi,
And remember that the vanilla rounding procedure is biased upward. That is,
an observation of 5 actually may have ranged from 4.5 to 5.4.

Jim

On Thu, Oct 22, 2015 at 7:15 AM, peter salzman <peter.salzmanuser at gmail.com>
wrote:

> here is one thought:
>
> if you plug in your numbers into any kind of regression you will get
> prediction that are real numbers and not necessarily integers, it may be
> that you predictions are good enough with this approximate value of Y. you
> could test this by randomly shuffling your data by +- 0.5 and compare the
> results with the original result.
>
> let me add another idea:
>
> if data is not fully observed this falls under the umbrella of censored
> data, in this case you have interval censoring. if you see 5 then the
> observations is in interval [4.5, 5.5]
> i'm not familiar with the field but i'd search for 'regression with
> interval censoring'
>
>
> peter
>
>
> On Wed, Oct 21, 2015 at 10:53 AM, Ravi Varadhan <ravi.varadhan at jhu.edu>
> wrote:
>
> > Hi,
> > I am dealing with a regression problem where the response variable, time
> > (second) to walk 15 ft, is rounded to the nearest integer.  I do not care
> > for the regression coefficients per se, but my main interest is in
> getting
> > the prediction equation for walking speed, given the predictors (age,
> > height, sex, etc.), where the predictions will be real numbers, and not
> > integers.  The hope is that these predictions should provide unbiased
> > estimates of the "unrounded" walking speed. These sounds like a
> measurement
> > error problem, where the measurement error is due to rounding and hence
> > would be uniformly distributed (-0.5, 0.5).
> >
> > Are there any canonical approaches for handling this type of a problem?
> > What is wrong with just doing the standard linear regression?
> >
> > I googled and saw that this question was asked by someone else in a
> > stackexchange post, but it was unanswered.  Any suggestions?
> >
> > Thank you,
> > Ravi
> >
> > Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> > Associate Professor,  Department of Oncology
> > Division of Biostatistics & Bionformatics
> > Sidney Kimmel Comprehensive Cancer Center
> > Johns Hopkins University
> > 550 N. Broadway, Suite 1111-E
> > Baltimore, MD 21205
> > 410-502-2619
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> Peter Salzman, PhD
> Department of Biostatistics and Computational Biology
> University of Rochester
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Thu Oct 22 04:00:10 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Thu, 22 Oct 2015 02:00:10 +0000
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <EC1F3221-76D9-490C-8A63-FB1A489E958A@gmail.com>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
	<alpine.OSX.2.20.1510211033030.490@charles-berrys-macbook.local>,
	<EC1F3221-76D9-490C-8A63-FB1A489E958A@gmail.com>
Message-ID: <1445479196173.81149@jhu.edu>

Dear Peter, Charles, Gabor, Jim, Mark, Victor, Peter, and Harold,
You have given me plenty of ammunition.  Thank you very much for the useful answers. 
Gratefully,
Ravi
________________________________________
From: peter dalgaard <pdalgd at gmail.com>
Sent: Wednesday, October 21, 2015 8:11 PM
To: Charles C. Berry
Cc: Ravi Varadhan; r-help at r-project.org
Subject: Re: [R] Linear regression with a rounded response variable

> On 21 Oct 2015, at 19:57 , Charles C. Berry <ccberry at ucsd.edu> wrote:
>
> On Wed, 21 Oct 2015, Ravi Varadhan wrote:
>
>> [snippage]
>
> If half the subjects have a value of 5 seconds and the rest are split between 4 and 6, your assertion that rounding induces an error of dunif(epsilon,-0.5,0.5) is surely wrong (more positive errors in the 6 second group and more negative errors in the 4 second group under any plausible model).

Yes, and I think that the suggestion in another post to look at censored regression is more in the right direction.

In general, I'd expect the bias caused by rounding the response to quite small, except at very high granularity. I did a few small experiments with the simplest possible linear model: estimating a mean based on highly rounded data,

> y <- round(rnorm(1e2,pi,.5))
> mean(y)
[1] 3.12
> table(y)
y
 2  3  4  5
13 63 23  1

Or, using a bigger sample:

> mean(round(rnorm(1e8,pi,.5)))
[1] 3.139843

in which there is a visible bias, but quite a small one:

> pi - 3.139843
[1] 0.001749654

At lower granularity (sd=1 instead of .5), the bias has almost disappeared.

> mean(round(rnorm(1e8,pi,1)))
[1] 3.141577

If the granularity is increased sufficiently, you _will_ see a sizeable bias (because almost all observations will be round(pi)==3):

> mean(round(rnorm(1e8,pi,.1)))
[1] 3.00017


A full ML fit (with known sigma=1) is pretty easily done:

> library(stats4)
> mll <- function(mu)-sum(log(pnorm(y+.5,mu, .5)-pnorm(y-.5, mu, .5)))
> mle(mll,start=list(mu=3))

Call:
mle(minuslogl = mll, start = list(mu = 3))

Coefficients:
      mu
3.122069
> mean(y)
[1] 3.12

As you see, the difference is only 0.002.

A small simulation (1000 repl.) gave (r[1,]==MLE ; r{2,]==mean)

> summary(r[1,]-r[2,])
     Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
-0.004155  0.000702  0.001495  0.001671  0.002554  0.006860

so the corrections relative to the crude mean stay within one unit in the 2nd place. Notice  that the corrections are pretty darn close to cancelling out the bias.

-pd

>
>
> HTH,
>
> Chuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com










From mehdiabdulla2 at gmail.com  Thu Oct 22 07:45:16 2015
From: mehdiabdulla2 at gmail.com (mehdiabdulla2)
Date: Thu, 22 Oct 2015 00:45:16 -0500
Subject: [R] Need help in completing this R assignment
Message-ID: <hkxhnjcr3ihupcqsuwygtta4.1445492524633@email.android.com>




Sent from my T-Mobile 4G LTE Device

From j.para.fernandez at hotmail.com  Thu Oct 22 10:52:17 2015
From: j.para.fernandez at hotmail.com (=?iso-8859-1?B?SmVz+nMgUGFyYSBGZXJu4W5kZXo=?=)
Date: Thu, 22 Oct 2015 10:52:17 +0200
Subject: [R] Announcement - The Use Of Nabble For Posting To R-Help Will
In-Reply-To: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>
References: <DUB131-W73C963FAF7A60600072D1DCC270@phx.gbl>
Message-ID: <DUB131-W79257D46AA8D591843D0DACC270@phx.gbl>

Nice

 		 	   		  
	[[alternative HTML version deleted]]


From xibiao.ye at gmail.com  Wed Oct 21 21:14:50 2015
From: xibiao.ye at gmail.com (Xibiao YE)
Date: Wed, 21 Oct 2015 14:14:50 -0500
Subject: [R] (no subject)
Message-ID: <CANCELzZz3D96bPHEfh81ZqqakFfvpASo0erVY+shXais+AQkZw@mail.gmail.com>

Hi, I am new to R and am trying to run some spatial analysis using
SpatialEpi package. Here is part of my code:

geo<-latlong2grid(cbind(MBPolygon at data$X,MBPolygon at data$Y))
population<-tapply(mydata$population,mydata$PHRAS4,sum)
cases<-tapply(mydata$case, mydata$PHRAS4,sum)
expected.cases<-mydata$expected

and then I run:
output<-bayes_cluster(expected.cases, cases, population, geo, MBPolygon,
max.prop, k, shape, rate, J, pi0, n.sim.imp, n.sim.prior, n.sim.post)
which is a function for MCMC.

I got this message:

"  Error message as.vector(data): no method for coercing this S4 class to a
vector"

I ran the author's code and got the same message. I'm guessing there maybe
some issue with my R environment. Many people online mentioned namespace,
but no idea how to fix it.  Please help.

xibiao

	[[alternative HTML version deleted]]


From HDoran at air.org  Thu Oct 22 14:48:48 2015
From: HDoran at air.org (Doran, Harold)
Date: Thu, 22 Oct 2015 12:48:48 +0000
Subject: [R] Linear regression with a rounded response variable
In-Reply-To: <EC1F3221-76D9-490C-8A63-FB1A489E958A@gmail.com>
References: <2343d72827d54a2ab5f09531459059e7@ESGEBEX10.win.ad.jhu.edu>
	<alpine.OSX.2.20.1510211033030.490@charles-berrys-macbook.local>
	<EC1F3221-76D9-490C-8A63-FB1A489E958A@gmail.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD68601153E25DC@DC1VEX10MB001.air.org>


> Yes, and I think that the suggestion in another post to look at censored regression is more in the right direction.

I think this is right and perhaps the best (or at least better) pathway to pursue than considering this within the framework of measurement error (ME). Of course there *is* ME in the observed walking time since the observed value is only one draw from the distribution of potential times that could have been observed for each individual.

But, the typical econometric correction for ME requires that we have an observed value and then an estimate of its variance. Theoretically, I would imagine this variance to be heteroscedastic and to vary by individual.  In Ravi's regression with the observed value on the LHS, there is no bias in the regression coefficients because the ME is not correlated with the error term, but the standard errors of the coefficients would be too large. If such this conditional variance did exist, you could treat the reciprocal of the variance as a weight in WLS, such that values with less ME have greater weight in the estimation and there would also exists a closed form way to correct the standard errors.

This however, is not the problem as I understand it from Ravi. Instead, he observes x which lies within a known interval, x_l < x < x_u where x_l and x_u denote upper and lower limits for the observed values.

At first this threw me for a loop because censoring in my work is typically done at the extremes with left/right censored data. But, there is also a package in R for interval censoring (called interval), though I have not used it before. Some googling on this topic drew me to some good worked examples that I think fit within the framework Ravi is working within.

So, perhaps Ravi's question really has two issues, one of which might be solvable: there is ME in the outcome value, y. But, perhaps that is ignorable. The censoring is perhaps not ignorable, and even better yet solvable?


From josh.m.ulrich at gmail.com  Thu Oct 22 15:51:20 2015
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Thu, 22 Oct 2015 08:51:20 -0500
Subject: [R] Bollinger Band quantmod
In-Reply-To: <CAN25tHSDSPvyXYs8Q+TSuqE0BROfSFh2TDhwtxz9Tt3TkbZRBg@mail.gmail.com>
References: <CAN25tHSDSPvyXYs8Q+TSuqE0BROfSFh2TDhwtxz9Tt3TkbZRBg@mail.gmail.com>
Message-ID: <CAPPM_gTWDtnLd203AVFpeNM_N9HjteCkh=KjkQnf0H1+9Osh=A@mail.gmail.com>

On Mon, Oct 19, 2015 at 4:04 PM, bgnumis bgnum <bgnumis at gmail.com> wrote:
> Hi all,
>
> When I plot Bollinger bands  with
>
> chartSeries(
> IBEX,theme="white",
>   TA = c(addBBands(50,2))
>
> )
>
> There is a "no" shadow area that it is used to obtain the levels. How can I
> plot with charSeries so that the plot start on the shadow area? I mean,
> ?How can I say to de axis start plotting f.i. 50 steps forward on the chart
> Series?
>
This is very unclear. What's a "shadow area"?  What levels are you referring to?

>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From david.kaethner at gmail.com  Thu Oct 22 16:20:32 2015
From: david.kaethner at gmail.com (david.kaethner at gmail.com)
Date: Thu, 22 Oct 2015 16:20:32 +0200
Subject: [R] expression evaluation during recursion
Message-ID: <2160DEA3-36A0-4EB9-B642-BB8F0F9F2332@gmail.com>

Hello,

I?m trying to solve an exercise, where I want to walk through the search path recursively (http://adv-r.had.co.nz/Environments.html <http://adv-r.had.co.nz/Environments.html>). 

I?m puzzled by a certain behavior and hope somebody can give me an explanation.

This code works:

listenv <- function(env = parent.frame()) {
  if (identical(env, emptyenv())) {
    #stop("reached emptyenv", call. = FALSE)
    return(env)
  } else {
    print(env)
    listenv(parent.env(env))
  }
}

Here, the calling environment is determined with a default parameter in the function?s formals. 

However, if I want to assign the calling environment within the function?s body, I get the error message ?infinite recursion?. Also, I never get actual environments (with attributes, that is), only memory addresses like this: <environment: 0x10da46630>. 

listenv <- function(env) {
  env <- parent.frame()
  if (identical(env, emptyenv())) {
    #stop("reached emptyenv", call. = FALSE)
    return(env)
  } else {
    print(env)
    listenv(parent.env(env))
  }
}

Any explanation of what?s going on here would be greatly appreciated. I suspect it has to do with when exactly the parent.frame()-expression is evaluated, but that?s not an actual explanation.
	[[alternative HTML version deleted]]


From david.kaethner at gmail.com  Thu Oct 22 17:00:40 2015
From: david.kaethner at gmail.com (david.kaethner at gmail.com)
Date: Thu, 22 Oct 2015 17:00:40 +0200
Subject: [R] Update dataframe based on some conditions
In-Reply-To: <CAKL8G3FycnGdyqXW8=B-bPXfBpj9ig_ZsZvLJR8GTkO65eyfdA@mail.gmail.com>
References: <CAKL8G3FycnGdyqXW8=B-bPXfBpj9ig_ZsZvLJR8GTkO65eyfdA@mail.gmail.com>
Message-ID: <861D66B4-433B-4282-A461-851BE45E1552@gmail.com>

Hi,

what I find a little confusing about your example: If there are several positions with a REF of, say, 999, why do you not just add them up to a single position? Because if you have the same position in several rows, than REF is not a unique identifier for that position. You would need the row number as well. Without a unique ID per position, I don?t think you can solve your problem.

Further: If I fill up a position from a previous row, won?t I just do the same thing again for the next row, thereby carrying items just down the list? 

Also, it would help if you used as for the example more useful variable names (such as ?product_ID? or ?number_in_stock?). And it would help if you try to make your example as simple as possible, meaning that you use the smallest amount of data possible without changing the problem.


> Am 21.10.2015 um 22:07 schrieb Jorge I Velez <jorgeivanvelez at gmail.com>:
> 
> Dear R-help,
> 
> I am working on what it seems to be a simple problem, but after several
> hours trying to come up with a solution, unfortunately I have not been able
> to.
> 
> I would like to go from "datain" to "dataout", that is, create the NEWREF
> variable according with some restrictions, and update the values for the
> remaining variables in the original data set (which is way more bigger than
> this example). The problem can be described as having products (coded as
> REF) in stock. Here, the total nomber of units in stock are named TOENDREF
> and those required for the customer are given by TIMEREF. The idea is to
> use as many units of the previous REF as possible before using a new REF.
> 
> ## input
> datain <- structure(list(REF = c("999", "999", "999", "1099", "731", "731",
> "731", "731", "1442", "1442", "1442", "1442"), TIMEREF = c(120,
> 240, 360, 30, 30, 60, 90, 120, 30, 60, 90, 120), TOENDREF = c(390,
> 270, 150, 480, 480, 450, 420, 390, 480, 450, 420, 390)), .Names = c("REF",
> "TIMEREF", "TOENDREF"), row.names = c(NA, 12L), class = "data.frame")
> datain
> 
> ## output
> dataout <- structure(list(REF = c(999L, 999L, 999L, 1099L, 731L, 731L,
> 731L,
> 731L, 1442L, 1442L, 1442L, 1442L), TIMEREF = c(120L, 240L, 360L,
> 30L, 30L, 60L, 90L, 120L, 30L, 60L, 90L, 120L), TOENDREF = c(390L,
> 270L, 150L, 120L, 90L, 30L, 420L, 300L, 270L, 210L, 120L, 0L),
>    NEWREF = c(999L, 999L, 999L, 999L, 999L, 999L, 731L, 731L,
>    731L, 731L, 731L, 731L)), .Names = c("REF", "TIMEREF", "TOENDREF",
> "NEWREF"), row.names = c(NA, 12L), class = "data.frame")
> dataout
> 
> 
> I what follows I will try to explain what I want to accomplish:
> 
> * Example 1
> Take rows 3 and 4 of "datain"
> 
> #REF TIMEREF TOENDREF
> #3   999     360      150
> #4  1099      30      480
> 
> As 150 units of REF 999 are available, we could substitute the 30 units of
> REF 1099 with them. Hence, the 4th row of the _updated_ "datain" becomes
> 
> #REF TIMEREF TOENDREF NEWREF
> #3   999     360      150      999
> #4  1099      30      120      999
> 
> * Example 2
> Now, let's take rows 3 to 8 of the _updated_ "datain":
> 
> #REF TIMEREF TOENDREF
> #3   999     360      150
> #4   999      30      120
> #5   731      30      480
> #6   731      60      450
> #7   731      90      420
> #8   731     120      390
> 
> In row 4, there 120 units available to be used. The number of units
> required of REF 731 is 30, which can be easily covered by the remaining 120
> units of REF 999. By doing so, the remaining units of REF 999 would then be
> 90.  Hence, the newly _updated_ "datain" becomes
> 
> #REF TIMEREF TOENDREF
> #3   999     360      150
> #4   999      30      120
> #5   999      30       90
> #6   999      60       30
> #7   731      90      420
> #8   731     120      300
> 
> Finally, the updated "datain" file after processing the remaining REF would
> be
> 
> #REF TIMEREF TOENDREF
> #9  731      30      270
> #10 731      60      210
> #11 731      90      120
> #12 731     120        0
> 
> Hopefully I have explained well what I would like to end up with.  If this
> is not the case, I will be more than happy to provide more information.
> 
> Any help would be very much appreciated.  Thanks in advance.
> 
> Best regards,
> Jorge Velez.-
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From martyn.plummer at r-project.org  Thu Oct 22 15:06:34 2015
From: martyn.plummer at r-project.org (Martyn Plummer)
Date: Thu, 22 Oct 2015 15:06:34 +0200
Subject: [R] Codes of Conduct at R Conferences
Message-ID: <1445519194.6634.174.camel@r-project.org>

The useR! conferences in 2014 and 2015 both had codes of conduct in
order to ensure an experience free from harassment for all participants.
After a request from some members of the R community, the R Foundation
has decided to endorse this practice. Future conferences supported by
the R Foundation must have a code of conduct.  We encourage other R
meetings not affiliated with the R Foundation to adopt the same policy.

A code of conduct serves two important purposes. Firstly, it sends a
clear message to those outside the community that an R conference is a
professional and comfortable working environment for all participants.
Secondly, it provides a mechanism for reporting and monitoring any
incidents of harassment that may occur.

We have decided not to require a particular formulation for the code of
conduct, but suggest that conference organizers use the model of the
useR! 2015 meeting ( http://user2015.math.aau.dk/behaviouR ). This will
allow the code to be adapted to local circumstances and to evolve in the
future. Conference organizers should ensure that any sanctions laid out
in the code of conduct are legally and practically enforceable. 

Vigorous debate and lively exchange are important features of R
conferences. We expect this to continue within the boundaries set by the
code of conduct.

For the R Foundation
Martyn Plummer, Co-President

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From S.Ellison at LGCGroup.com  Thu Oct 22 18:54:41 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 22 Oct 2015 17:54:41 +0100
Subject: [R] Scope of Axes
In-Reply-To: <CAN25tHSCHiZrUSwX2omCfNwc_EPH4C6pPvUaNynQhnp+O_ZfYg@mail.gmail.com>
References: <CAN25tHSCHiZrUSwX2omCfNwc_EPH4C6pPvUaNynQhnp+O_ZfYg@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403C7AA249F@GBTEDVPEXCMB04.corp.lgc-group.com>

> fhist<-hist(Simulation,plot=FALSE)
> par(mar=c(6,0,6,6))
> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")

i) Unlike hist(), barplot() does not plot at histogram bin boundaries - you'll have noticed that you did not specify locations for the bars and in fact can not do so . There is no simple way of aligning a barplot with particular axis length and locations. But there is a useful example of usig rect() to do the job in ?pairs; look for the USJudgeRatings example and see the panel.hist function there. It should be straightforward to adapt that for horizontal use.

ii) axes= has nothing to do with the plot limits. xlim and ylim control plot limits.  You should set ylim and the top and bottom margins to the same values for both plots.

iii) Your png file includes a barplot with gridlines, so that cannot be the result of the exact command you used above. If you used a different plotting system for the bar plot the alignment would be very hard to guarantee, so stay with base graphics for both.



S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From sdeepak at iitk.ac.in  Thu Oct 22 16:18:57 2015
From: sdeepak at iitk.ac.in (sdeepak at iitk.ac.in)
Date: Thu, 22 Oct 2015 19:48:57 +0530
Subject: [R] Error in Opening Project on R Studio
Message-ID: <02af057dd4e8b9ff9b1f9fcf6a4bb7cd.squirrel@webmail1.iitk.ac.in>

Good Evening everyone,
                     I am Deepak Singh, Student I.I.T. Kanpur, INDIA, was
working on a project on R Studio and now when I am
trying to open my project it is showing the attached
error. Can it be fixed? if 'Yes' then how can I do
fix it ? Please help.

Thank You!
Deepak Singh
Student I.I.T. Kanpur, INDIA

From murdoch.duncan at gmail.com  Thu Oct 22 19:05:49 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Oct 2015 13:05:49 -0400
Subject: [R] expression evaluation during recursion
In-Reply-To: <2160DEA3-36A0-4EB9-B642-BB8F0F9F2332@gmail.com>
References: <2160DEA3-36A0-4EB9-B642-BB8F0F9F2332@gmail.com>
Message-ID: <5629176D.3020800@gmail.com>

On 22/10/2015 10:20 AM, david.kaethner at gmail.com wrote:
> Hello,
> 
> I?m trying to solve an exercise, where I want to walk through the search path recursively (http://adv-r.had.co.nz/Environments.html <http://adv-r.had.co.nz/Environments.html>). 
> 
> I?m puzzled by a certain behavior and hope somebody can give me an explanation.
> 
> This code works:
> 
> listenv <- function(env = parent.frame()) {
>   if (identical(env, emptyenv())) {
>     #stop("reached emptyenv", call. = FALSE)
>     return(env)
>   } else {
>     print(env)
>     listenv(parent.env(env))
>   }
> }
> 
> Here, the calling environment is determined with a default parameter in the function?s formals. 
> 
> However, if I want to assign the calling environment within the function?s body, I get the error message ?infinite recursion?. Also, I never get actual environments (with attributes, that is), only memory addresses like this: <environment: 0x10da46630>.

I'm not sure what you were looking for, but "<environment: 0x10da46630>"
is the normal way to print an environment, unless it happens to be one
of the special named ones (like .GlobalEnv).

> 
> listenv <- function(env) {
>   env <- parent.frame()
>   if (identical(env, emptyenv())) {
>     #stop("reached emptyenv", call. = FALSE)
>     return(env)
>   } else {
>     print(env)
>     listenv(parent.env(env))
>   }
> }
> 
> Any explanation of what?s going on here would be greatly appreciated. I suspect it has to do with when exactly the parent.frame()-expression is evaluated, but that?s not an actual explanation.


Your function completely ignores the "env" argument.  It never recurses.
 In the first case, "parent.frame()" is only a default value, so
recursion happens properly.  If you change the first line in the body to
these two lines

  if (missing(env))
    env <- parent.frame()

it would be equivalent.

Duncan Murdoch


From nilesh.dighe at monsanto.com  Thu Oct 22 19:10:29 2015
From: nilesh.dighe at monsanto.com (DIGHE, NILESH [AG/2362])
Date: Thu, 22 Oct 2015 17:10:29 +0000
Subject: [R] spatial adjustment using checks
Message-ID: <24156952D190E841BF8E66CB59FAB94A48652276@STLWEXMBXPRD14.na.ds.monsanto.com>

Hi,
I have yield data for several varieties and a randomly placed check (1 in every 8 column or "cols") in a field test arranged in a rows*cols grid format (see image attached).  Both "rows" & "cols" are variables in the data set.  I like to adjust "yield" variable for each row listed as "variety" in variable "linecode" by dividing its yield with the average yield of four nearest "check" (on the rows*cols field grid) in variable "linecode".  I like to have two checks on the same row where one check is on the left and the other is on the right side of a given variety.  The other two checks should come from the two neighboring columns ("cols").  If a check is missing on one or more sides of a given variety, then I like to proceed with the calculation with only the available checks around that given variety.  If two checks on the neighboring column are equidistance from a given variety then use position of the variety to choose which one to use (If variety is in cols 1-8 then use check from those cols; if variety is in cols 9-16 then use check from cols 9-16).

Below is the function I wrote which adjust yield values for each "variety" (variable "linecode") by dividing its yield with the average yield of all checks in the field.  Instead of using average check across the whole field, I like to use the four neighboring checks to make this adjustment.  I am struggling with specifying the four nearest checks in this loop.  I played around using "dist" function but without any success.  I tried searching for any packages that can do these nearest check adjustments without any success.  Any help will be appreciated.

-------------------function------------------------------------------
function (dataset, trait, control) {
    m <- c()
    x <- length(trait)
    chkmean <- tapply(trait, control, mean, na.rm = T)
    for (i in 1:x) {
        m[i] <- ifelse(control[i] == "variety", trait[i]/chkmean[1],
            trait[i]/trait[i])
    }
    head(as.data.frame(m))
}

---------------------data----------------------------------------------------------------------

dput(dat)

structure(list(rows = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,

1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,

3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L,

4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1", "2", "3",

"4"), class = "factor"), cols = structure(c(1L, 2L, 3L, 4L, 5L,

6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 16L, 15L,

14L, 13L, 12L, 11L, 10L, 9L, 8L, 7L, 6L, 5L, 4L, 3L, 2L, 1L,

1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,

15L, 16L, 16L, 15L, 14L, 13L, 12L, 11L, 10L, 9L, 8L, 7L, 6L,

5L, 4L, 3L, 2L, 1L), .Label = c("1", "2", "3", "4", "5", "6",

"7", "8", "9", "10", "11", "12", "13", "14", "15", "16"), class = "factor"),

    plotid = c(289L, 290L, 291L, 292L, 293L, 294L, 295L, 296L,

    297L, 298L, 299L, 300L, 301L, 302L, 303L, 304L, 369L, 370L,

    371L, 372L, 373L, 374L, 375L, 376L, 377L, 378L, 379L, 380L,

    381L, 382L, 383L, 384L, 385L, 386L, 387L, 388L, 389L, 390L,

    391L, 392L, 393L, 394L, 395L, 396L, 397L, 398L, 399L, 400L,

    465L, 466L, 467L, 468L, 469L, 470L, 471L, 472L, 473L, 474L,

    475L, 476L, 477L, 478L, 479L, 480L), yield = c(5.1, 5.5,

    5, 5.5, 6.2, 5.1, 5.5, 5.2, 5, 5, 3.9, 4.6, 5, 4.4, 5.1,

    4.3, 4.4, 4.2, 3.9, 4.6, 4.8, 5.4, 4.7, 5.5, 5.3, 4.8, 5.8,

    4.6, 5.8, 5.5, 5.3, 5.6, 5.6, 5, 4.8, 4.9, 5.2, 5.3, 4.6,

    4.8, 5.3, 4.2, 4.6, 4.2, 4.2, 4, 3.9, 4.5, 5.4, 4.8, 4.6,

    5.2, 4.9, 5.1, 4.5, 5.8, 5.2, 4.7, 4.8, 5.3, 5.8, 4.9, 5.9,

    4.5), line = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L,

    9L, 1L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L,

    20L, 1L, 21L, 22L, 1L, 23L, 24L, 25L, 26L, 27L, 28L, 29L,

    30L, 31L, 32L, 33L, 1L, 34L, 35L, 36L, 37L, 38L, 39L, 40L,

    41L, 42L, 1L, 43L, 44L, 45L, 46L, 47L, 48L, 49L, 50L, 1L,

    51L, 52L, 53L, 54L, 1L, 55L, 56L, 57L), .Label = c("CHK",

    "V002", "V003", "V004", "V005", "V006", "V007", "V008", "V009",

    "V010", "V011", "V012", "V013", "V014", "V015", "V016", "V017",

    "V018", "V019", "V020", "V021", "V022", "V023", "V024", "V025",

    "V026", "V027", "V028", "V029", "V030", "V031", "V032", "V033",

    "V034", "V035", "V036", "V037", "V038", "V039", "V040", "V041",

    "V042", "V043", "V044", "V045", "V046", "V047", "V048", "V049",

    "V050", "V051", "V052", "V053", "V054", "V055", "V056", "V057"

    ), class = "factor"), linecode = structure(c(1L, 2L, 2L,

    2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

    2L, 2L, 2L, 1L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,

    2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L,

    2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L,

    2L), .Label = c("check", "variety"), class = "factor")), .Names = c("rows",

"cols", "plotid", "yield", "line", "linecode"), row.names = c(NA,

-64L), class = "data.frame")

-------------------------------------------------------------------------------------------------
My expected output is in column "adj_yield" below:
    rows cols plotid yield line linecode  adj_yield
1     1    1    289   5.1  CHK    check     check
2     1    2    290   5.5 V002  variety     1.071
3     1    3    291   5.0 V003  variety     0.974
4     1    4    292   5.5 V004  variety     1.071
5     1    5    293   6.2 V005  variety     1.208
6     1    6    294   5.1 V006  variety     0.994
7     1    7    295   5.5 V007  variety     1.071
8     1    8    296   5.2 V008  variety     1.013
9     1    9    297   5.0 V009  variety     0.974
10    1   10    298   5.0  CHK    check     check
11    1   11    299   3.9 V010  variety     0.750
12    1   12    300   4.6 V011  variety     0.885
13    1   13    301   5.0 V012  variety     0.962
14    1   14    302   4.4 V013  variety     0.846
15    1   15    303   5.1 V014  variety     0.981
16    1   16    304   4.3 V015  variety     0.827
17    2   16    369   4.4 V016  variety     check
18    2   15    370   4.2 V017  variety     0.881
19    2   14    371   3.9 V018  variety     0.818
20    2   13    372   4.6 V019  variety     0.965
21    2   12    373   4.8 V020  variety     1.007
22    2   11    374   5.4  CHK    check     check
23    2   10    375   4.7 V021  variety     0.959
24    2    9    376   5.5 V022  variety     1.053
25    2    8    377   5.3  CHK    check     check
26    2    7    378   4.8 V023  variety     0.923
27    2    6    379   5.8 V024  variety     1.115
28    2    5    380   4.6 V025  variety     0.885
29    2    4    381   5.8 V026  variety     1.115
30    2    3    382   5.5 V027  variety     1.058
31    2    2    383   5.3 V028  variety     1.019
32    2    1    384   5.6 V029  variety     1.077


-----------------session info------------------------------------------------------------------------

R version 3.2.1 (2015-06-18)

Platform: i386-w64-mingw32/i386 (32-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1



locale:

[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252

[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252



attached base packages:

[1] stats     graphics  grDevices utils     datasets  methods   base



other attached packages:

[1] rlist_0.4.5.1 mapplots_1.5  agridat_1.12



loaded via a namespace (and not attached):

 [1] magrittr_1.5     plyr_1.8.3       tools_3.2.1      reshape2_1.4.1   Rcpp_0.12.0      stringi_0.5-5

 [7] grid_3.2.1       data.table_1.9.4 stringr_1.0.0    chron_2.3-47     lattice_0.20-31



Nilesh Dighe
(806)-252-7492 (Cell)
(806)-741-2019 (Office)


This e-mail message may contain privileged and/or confidential information, and is intended to be received only by persons entitled
to receive such information. If you have received this e-mail in error, please notify the sender immediately. Please delete it and
all attachments from any servers, hard drives or any other media. Other use of this e-mail by you is strictly prohibited.

All e-mails and attachments sent and received are subject to monitoring, reading and archival by Monsanto, including its
subsidiaries. The recipient of this e-mail is solely responsible for checking for the presence of "Viruses" or other "Malware".
Monsanto, along with its subsidiaries, accepts no liability for any damage caused by any such code transmitted by or accompanying
this e-mail or any attachment.


The information contained in this email may be subject to the export control laws and regulations of the United States, potentially
including but not limited to the Export Administration Regulations (EAR) and sanctions regulations issued by the U.S. Department of
Treasury, Office of Foreign Asset Controls (OFAC).  As a recipient of this information you are obligated to comply with all
applicable U.S. export laws and regulations.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: fieldlayout.png
Type: image/png
Size: 11941 bytes
Desc: fieldlayout.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151022/400b8ab1/attachment.png>

From murdoch.duncan at gmail.com  Thu Oct 22 19:11:42 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Oct 2015 13:11:42 -0400
Subject: [R] Error in Opening Project on R Studio
In-Reply-To: <02af057dd4e8b9ff9b1f9fcf6a4bb7cd.squirrel@webmail1.iitk.ac.in>
References: <02af057dd4e8b9ff9b1f9fcf6a4bb7cd.squirrel@webmail1.iitk.ac.in>
Message-ID: <562918CE.40002@gmail.com>

On 22/10/2015 10:18 AM, sdeepak at iitk.ac.in wrote:
> Good Evening everyone,
>                      I am Deepak Singh, Student I.I.T. Kanpur, INDIA, was
> working on a project on R Studio and now when I am
> trying to open my project it is showing the attached
> error. Can it be fixed? if 'Yes' then how can I do
> fix it ? Please help.

You've written to the wrong place.  You need to write to one of the
RStudio support forums at support.rstudio.com.

Duncan Murdoch


From tr206 at kent.ac.uk  Thu Oct 22 20:23:26 2015
From: tr206 at kent.ac.uk (T.Riedle)
Date: Thu, 22 Oct 2015 18:23:26 +0000
Subject: [R] quantile regression: error terms
Message-ID: <AEB16B1613D44C4793A7E6B6986B7A12010054A69E@EX10-LIVE-MBN1.ad.kent.ac.uk>

Greetings R Community,

I am running quantile regressions using quantreg in R. I also plot the residuals in a QQplot which indicate fat tails. I would like to try using Student distribution, but I do not know if the R software allows it for my task in hand.

In my opinion it is very likely that there is a structural break and if that is not taken into consideration by the rq() function leading to QQ plots which display nonlinearity. Hence, the model is slightly misspecified.
I was also wondering if I can cope with the nonlinearity by using a sandwich estimate in the summary.rq() function such as "ker".

How can I modify the model to improve the model specification and the standard errors specifications? Can I modify the regression model or do I have to change the method used to compute the error terms in summary.rq()?

Thanks for your feedback.

	[[alternative HTML version deleted]]


From david.kaethner at gmail.com  Thu Oct 22 20:44:08 2015
From: david.kaethner at gmail.com (david.kaethner at gmail.com)
Date: Thu, 22 Oct 2015 20:44:08 +0200
Subject: [R] expression evaluation during recursion
In-Reply-To: <5629176D.3020800@gmail.com>
References: <2160DEA3-36A0-4EB9-B642-BB8F0F9F2332@gmail.com>
	<5629176D.3020800@gmail.com>
Message-ID: <5A9809BC-2590-4E08-835F-B12FB0730EFA@gmail.com>

Hi,

I?m sure there?s a ton I don?t understand about environments, but I?m afraid your answer doesn?t make sense to me. 

If it?s on the search path, the ?print(env)? should yield something like:

<environment: package:pryr>
attr(,"name")
[1] "package:pryr"
attr(,"path")
[1] "/Library/Frameworks/R.framework/Versions/3.2/Resources/library/pryr?

I agree that there would only be an address if it was an unnamed environment such as the ones constructed during function execution. But I?m walking the search path here, so these should all contain information on packages. 

My question wasn?t so much about how to retrieve information on environments, there are plenty functions concerning that. I just don?t understand why it makes that much of a difference if I put the parent.frame() in the arguments list, or in the function body.


> Am 22.10.2015 um 19:05 schrieb Duncan Murdoch <murdoch.duncan at gmail.com>:
> 
> On 22/10/2015 10:20 AM, david.kaethner at gmail.com <mailto:david.kaethner at gmail.com> wrote:
>> Hello,
>> 
>> I?m trying to solve an exercise, where I want to walk through the search path recursively (http://adv-r.had.co.nz/Environments.html <http://adv-r.had.co.nz/Environments.html> <http://adv-r.had.co.nz/Environments.html <http://adv-r.had.co.nz/Environments.html>>). 
>> 
>> I?m puzzled by a certain behavior and hope somebody can give me an explanation.
>> 
>> This code works:
>> 
>> listenv <- function(env = parent.frame()) {
>>  if (identical(env, emptyenv())) {
>>    #stop("reached emptyenv", call. = FALSE)
>>    return(env)
>>  } else {
>>    print(env)
>>    listenv(parent.env(env))
>>  }
>> }
>> 
>> Here, the calling environment is determined with a default parameter in the function?s formals. 
>> 
>> However, if I want to assign the calling environment within the function?s body, I get the error message ?infinite recursion?. Also, I never get actual environments (with attributes, that is), only memory addresses like this: <environment: 0x10da46630>.
> 
> I'm not sure what you were looking for, but "<environment: 0x10da46630>"
> is the normal way to print an environment, unless it happens to be one
> of the special named ones (like .GlobalEnv).
> 
>> 
>> listenv <- function(env) {
>>  env <- parent.frame()
>>  if (identical(env, emptyenv())) {
>>    #stop("reached emptyenv", call. = FALSE)
>>    return(env)
>>  } else {
>>    print(env)
>>    listenv(parent.env(env))
>>  }
>> }
>> 
>> Any explanation of what?s going on here would be greatly appreciated. I suspect it has to do with when exactly the parent.frame()-expression is evaluated, but that?s not an actual explanation.
> 
> 
> Your function completely ignores the "env" argument.  It never recurses.
> In the first case, "parent.frame()" is only a default value, so
> recursion happens properly.  If you change the first line in the body to
> these two lines
> 
>  if (missing(env))
>    env <- parent.frame()
> 
> it would be equivalent.
> 
> Duncan Murdoch


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Oct 22 20:52:48 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Oct 2015 14:52:48 -0400
Subject: [R] expression evaluation during recursion
In-Reply-To: <5A9809BC-2590-4E08-835F-B12FB0730EFA@gmail.com>
References: <2160DEA3-36A0-4EB9-B642-BB8F0F9F2332@gmail.com>
	<5629176D.3020800@gmail.com>
	<5A9809BC-2590-4E08-835F-B12FB0730EFA@gmail.com>
Message-ID: <56293080.7080207@gmail.com>

On 22/10/2015 2:44 PM, david.kaethner at gmail.com wrote:
> Hi,
>
> I?m sure there?s a ton I don?t understand about environments, but I?m 
> afraid your answer doesn?t make sense to me.
>
> If it?s on the search path, the ?print(env)? should yield something like:

You never get to the search list.
>
> <environment: package:pryr>
> attr(,"name")
> [1] "package:pryr"
> attr(,"path")
> [1] "/Library/Frameworks/R.framework/Versions/3.2/Resources/library/pryr?
>
> I agree that there would only be an address if it was an unnamed 
> environment such as the ones constructed during function execution. 
> But I?m walking the search path here, so these should all contain 
> information on packages.
>
> My question wasn?t so much about how to retrieve information on 
> environments, there are plenty functions concerning that. I just don?t 
> understand why it makes that much of a difference if I put the 
> parent.frame() in the arguments list, or in the function body.

You seem to have ignored my explanation.

Duncan Murdoch

>
>
>> Am 22.10.2015 um 19:05 schrieb Duncan Murdoch 
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>:
>>
>> On 22/10/2015 10:20 AM,david.kaethner at gmail.com 
>> <mailto:david.kaethner at gmail.com>wrote:
>>> Hello,
>>>
>>> I?m trying to solve an exercise, where I want to walk through the 
>>> search path recursively 
>>> (http://adv-r.had.co.nz/Environments.html<http://adv-r.had.co.nz/Environments.html>).
>>>
>>> I?m puzzled by a certain behavior and hope somebody can give me an 
>>> explanation.
>>>
>>> This code works:
>>>
>>> listenv <- function(env = parent.frame()) {
>>>  if (identical(env, emptyenv())) {
>>>    #stop("reached emptyenv", call. = FALSE)
>>>    return(env)
>>>  } else {
>>>    print(env)
>>>    listenv(parent.env(env))
>>>  }
>>> }
>>>
>>> Here, the calling environment is determined with a default parameter 
>>> in the function?s formals.
>>>
>>> However, if I want to assign the calling environment within the 
>>> function?s body, I get the error message ?infinite recursion?. Also, 
>>> I never get actual environments (with attributes, that is), only 
>>> memory addresses like this: <environment: 0x10da46630>.
>>
>> I'm not sure what you were looking for, but "<environment: 0x10da46630>"
>> is the normal way to print an environment, unless it happens to be one
>> of the special named ones (like .GlobalEnv).
>>
>>>
>>> listenv <- function(env) {
>>>  env <- parent.frame()
>>>  if (identical(env, emptyenv())) {
>>>    #stop("reached emptyenv", call. = FALSE)
>>>    return(env)
>>>  } else {
>>>    print(env)
>>>    listenv(parent.env(env))
>>>  }
>>> }
>>>
>>> Any explanation of what?s going on here would be greatly 
>>> appreciated. I suspect it has to do with when exactly the 
>>> parent.frame()-expression is evaluated, but that?s not an actual 
>>> explanation.
>>
>>
>> Your function completely ignores the "env" argument.  It never recurses.
>> In the first case, "parent.frame()" is only a default value, so
>> recursion happens properly.  If you change the first line in the body to
>> these two lines
>>
>>  if (missing(env))
>>    env <- parent.frame()
>>
>> it would be equivalent.
>>
>> Duncan Murdoch
>


From david.kaethner at gmail.com  Thu Oct 22 21:10:22 2015
From: david.kaethner at gmail.com (david.kaethner at gmail.com)
Date: Thu, 22 Oct 2015 21:10:22 +0200
Subject: [R] expression evaluation during recursion
In-Reply-To: <56293080.7080207@gmail.com>
References: <2160DEA3-36A0-4EB9-B642-BB8F0F9F2332@gmail.com>
	<5629176D.3020800@gmail.com>
	<5A9809BC-2590-4E08-835F-B12FB0730EFA@gmail.com>
	<56293080.7080207@gmail.com>
Message-ID: <FD525327-58C0-4CE4-A1B5-ED9BF1489892@gmail.com>


> You seem to have ignored my explanation.

True, sorry. Thanks for sticking with me. Making sense now.


> 
> Duncan Murdoch
> 
>> 
>> 
>>> Am 22.10.2015 um 19:05 schrieb Duncan Murdoch <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>:
>>> 
>>> On 22/10/2015 10:20 AM,david.kaethner at gmail.com <mailto:david.kaethner at gmail.com>wrote:
>>>> Hello,
>>>> 
>>>> I?m trying to solve an exercise, where I want to walk through the search path recursively (http://adv-r.had.co.nz/Environments.html<http://adv-r.had.co.nz/Environments.html>).
>>>> 
>>>> I?m puzzled by a certain behavior and hope somebody can give me an explanation.
>>>> 
>>>> This code works:
>>>> 
>>>> listenv <- function(env = parent.frame()) {
>>>> if (identical(env, emptyenv())) {
>>>>   #stop("reached emptyenv", call. = FALSE)
>>>>   return(env)
>>>> } else {
>>>>   print(env)
>>>>   listenv(parent.env(env))
>>>> }
>>>> }
>>>> 
>>>> Here, the calling environment is determined with a default parameter in the function?s formals.
>>>> 
>>>> However, if I want to assign the calling environment within the function?s body, I get the error message ?infinite recursion?. Also, I never get actual environments (with attributes, that is), only memory addresses like this: <environment: 0x10da46630>.
>>> 
>>> I'm not sure what you were looking for, but "<environment: 0x10da46630>"
>>> is the normal way to print an environment, unless it happens to be one
>>> of the special named ones (like .GlobalEnv).
>>> 
>>>> 
>>>> listenv <- function(env) {
>>>> env <- parent.frame()
>>>> if (identical(env, emptyenv())) {
>>>>   #stop("reached emptyenv", call. = FALSE)
>>>>   return(env)
>>>> } else {
>>>>   print(env)
>>>>   listenv(parent.env(env))
>>>> }
>>>> }
>>>> 
>>>> Any explanation of what?s going on here would be greatly appreciated. I suspect it has to do with when exactly the parent.frame()-expression is evaluated, but that?s not an actual explanation.
>>> 
>>> 
>>> Your function completely ignores the "env" argument.  It never recurses.
>>> In the first case, "parent.frame()" is only a default value, so
>>> recursion happens properly.  If you change the first line in the body to
>>> these two lines
>>> 
>>> if (missing(env))
>>>   env <- parent.frame()
>>> 
>>> it would be equivalent.
>>> 
>>> Duncan Murdoch
>> 
> 


From Sebastien.Bihorel at cognigencorp.com  Fri Oct 23 03:46:02 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 22 Oct 2015 21:46:02 -0400
Subject: [R] Control of x-axis variable ordering in ggplot
Message-ID: <5629915A.2090604@cognigencorp.com>

Hi,

Given a certain data.frame, the lattice xyplot function will plot the 
data as.is and join the data point in the order of the data frame. It is 
my (probably flawed) understanding that, using the same data frame, 
ggplot orders the data by increasing order of the x-axis variable. Can 
one control this behavior?

Thanks

Sebastien

Code example

library(lattice)
library(ggplot2)


data <- data.frame(x=rep(1:4,each=25),
                    y=rep(1:25,times=4),
                    g=rep(1:4,each=25))
data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1

col <- 3:7

xyplot(y~x,data=data,groups=g,type='l',col=col)

ggplot(data, aes(x,y,group=g)) + geom_point(colour=col[data$g]) +
   geom_line(colour=col[data$g])


From jdnewmil at dcn.davis.CA.us  Fri Oct 23 07:13:55 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 23 Oct 2015 07:13:55 +0200
Subject: [R] Control of x-axis variable ordering in ggplot
In-Reply-To: <5629915A.2090604@cognigencorp.com>
References: <5629915A.2090604@cognigencorp.com>
Message-ID: <A594C3A9-7F47-48AB-B6B3-C3B407B33D06@dcn.davis.CA.us>

The ggplot function has no display behaviour. You have to couple it with a geom function to define how the data will be displayed. Read ?geom_line and ?geom_poly.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2015 3:46:02 AM GMT+02:00, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Hi,
>
>Given a certain data.frame, the lattice xyplot function will plot the 
>data as.is and join the data point in the order of the data frame. It
>is 
>my (probably flawed) understanding that, using the same data frame, 
>ggplot orders the data by increasing order of the x-axis variable. Can 
>one control this behavior?
>
>Thanks
>
>Sebastien
>
>Code example
>
>library(lattice)
>library(ggplot2)
>
>
>data <- data.frame(x=rep(1:4,each=25),
>                    y=rep(1:25,times=4),
>                    g=rep(1:4,each=25))
>data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>
>col <- 3:7
>
>xyplot(y~x,data=data,groups=g,type='l',col=col)
>
>ggplot(data, aes(x,y,group=g)) + geom_point(colour=col[data$g]) +
>   geom_line(colour=col[data$g])
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From bijoy.joseph at thl.fi  Fri Oct 23 09:38:43 2015
From: bijoy.joseph at thl.fi (Bijoy Joseph)
Date: Fri, 23 Oct 2015 10:38:43 +0300
Subject: [R] virus/trojan in contributed package: 'svs'
Message-ID: <5629E403.5030105@thl.fi>

Hello,

I came across the following when I was installing the 'svs' package:

$ clamscan svs_1.0.3.zip
svs_1.0.3.zip: BAT.CMDFlood FOUND

----------- SCAN SUMMARY -----------
Known viruses: 4035827
Engine version: 0.98.7
Scanned directories: 0
Scanned files: 1
Infected files: 1


clamscan finds this trojan in the source tarball as well. Does the 
r-project does a virus scan of contributed packages? I had come across a 
virus a few years earlier, but an email to the maintainer fixed that 
issue. I have heard nothing (yet) from the maintainer in this case.

Bijoy


From erinm.hodgess at gmail.com  Fri Oct 23 10:51:37 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 23 Oct 2015 03:51:37 -0500
Subject: [R] creating a list based on various mean values
Message-ID: <CACxE24nbCH4EEPK+_=nEurL9-=qn_KqMnp8q6v-eBhk1EeK-Tw@mail.gmail.com>

Hello!

I would like to create a list of random values, based on various means.
Here are the potential mean values:

> k1
 [1]  0.005  0.200  0.300  0.400  0.500  0.600  0.700  0.800  0.900  1.000
 1.100  1.200  1.300  1.400
[15]  1.500  1.600  1.700  1.800  1.900  2.000  5.000 10.000

There are 22 of them.

My original thought was to use "do.call" to produce a list of 22 items of
size 20.

> xr <- do.call("rnorm",args=list(n=20,mean=k1))
> xr
 [1] -1.46443269  0.83384389  0.39176720 -0.17954959  0.28245948
-0.44148055  1.98009926  1.73881739
 [9]  1.37312454  1.40509257 -0.03762214  0.43636354  1.82175069
 1.96439065  2.71731752  1.02388062
[17]  1.20732047  3.08650964  0.87910868  0.13018727
>

However, I am just getting back one set of size 20.  What am I doing wrong,
please? Or do I need to do a loop, please?  I thought that there must be a
more elegant solution.

This is on a Macbook Air, R version 3.2.2

Thanks so much,
Sincerely

-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Fri Oct 23 11:06:21 2015
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Fri, 23 Oct 2015 02:06:21 -0700
Subject: [R] creating a list based on various mean values
In-Reply-To: <CACxE24nbCH4EEPK+_=nEurL9-=qn_KqMnp8q6v-eBhk1EeK-Tw@mail.gmail.com>
References: <CACxE24nbCH4EEPK+_=nEurL9-=qn_KqMnp8q6v-eBhk1EeK-Tw@mail.gmail.com>
Message-ID: <CACdH2ZbRPPZ3HK3rOr6COro_Oyq1rFufNprhVwgmQJPtAXT4dQ@mail.gmail.com>

Does the following not do what you want?

k1 <- c(0.005, 0.200, 0.300, 0.400, 0.500, 0.600, 0.700, 0.800, 0.900,
        1.000, 1.100, 1.200, 1.300, 1.400, 1.500, 1.600, 1.700, 1.800,
        1.900, 2.000, 5.000, 10.000)
k1

xr <- lapply(k1, rnorm, n=20)
xr


On Fri, Oct 23, 2015 at 1:51 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> I would like to create a list of random values, based on various means.
> Here are the potential mean values:
>
>> k1
>  [1]  0.005  0.200  0.300  0.400  0.500  0.600  0.700  0.800  0.900  1.000
>  1.100  1.200  1.300  1.400
> [15]  1.500  1.600  1.700  1.800  1.900  2.000  5.000 10.000
>
> There are 22 of them.
>
> My original thought was to use "do.call" to produce a list of 22 items of
> size 20.
>
>> xr <- do.call("rnorm",args=list(n=20,mean=k1))
>> xr
>  [1] -1.46443269  0.83384389  0.39176720 -0.17954959  0.28245948
> -0.44148055  1.98009926  1.73881739
>  [9]  1.37312454  1.40509257 -0.03762214  0.43636354  1.82175069
>  1.96439065  2.71731752  1.02388062
> [17]  1.20732047  3.08650964  0.87910868  0.13018727
>>
>
> However, I am just getting back one set of size 20.  What am I doing wrong,
> please? Or do I need to do a loop, please?  I thought that there must be a
> more elegant solution.
>
> This is on a Macbook Air, R version 3.2.2
>
> Thanks so much,
> Sincerely
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Fri Oct 23 11:23:37 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 23 Oct 2015 11:23:37 +0200
Subject: [R] virus/trojan in contributed package: 'svs'
In-Reply-To: <5629E403.5030105@thl.fi>
References: <5629E403.5030105@thl.fi>
Message-ID: <845FD7E1-D45C-44E3-9DE7-2A696743F73E@gmail.com>

Virus scanners generate a fair amount of false positives. Does it persist if you unpack the zip file or the source tarball? If so, what file has the issue?

-pd

On 23 Oct 2015, at 09:38 , Bijoy Joseph <bijoy.joseph at thl.fi> wrote:

> Hello,
> 
> I came across the following when I was installing the 'svs' package:
> 
> $ clamscan svs_1.0.3.zip
> svs_1.0.3.zip: BAT.CMDFlood FOUND
> 
> ----------- SCAN SUMMARY -----------
> Known viruses: 4035827
> Engine version: 0.98.7
> Scanned directories: 0
> Scanned files: 1
> Infected files: 1
> 
> 
> clamscan finds this trojan in the source tarball as well. Does the r-project does a virus scan of contributed packages? I had come across a virus a few years earlier, but an email to the maintainer fixed that issue. I have heard nothing (yet) from the maintainer in this case.
> 
> Bijoy
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jrkrideau at inbox.com  Fri Oct 23 13:14:47 2015
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 23 Oct 2015 03:14:47 -0800
Subject: [R] Error in Opening Project on R Studio
In-Reply-To: <02af057dd4e8b9ff9b1f9fcf6a4bb7cd.squirrel@webmail1.iitk.ac.in>
Message-ID: <B581B2F6B47.00000924jrkrideau@inbox.com>

There was no attachment so we cannot tell if your problem is an R problem that is appropriate for the R-help list or if it is a RStudio issue that should go to their help forum.

The R-help list is very fussy about what kinds of attachments that it well accept.  It usually is best to just copy and paste any error messages into the main text of the e-mail.  If that does not seem appropriate you might try a pdf, png or plain text (.txt) attacment.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sdeepak at iitk.ac.in
> Sent: Thu, 22 Oct 2015 19:48:57 +0530
> To: r-help at r-project.org
> Subject: [R] Error in Opening Project on R Studio
> 
> Good Evening everyone,
>                      I am Deepak Singh, Student I.I.T. Kanpur, INDIA, was
> working on a project on R Studio and now when I am
> trying to open my project it is showing the attached
> error. Can it be fixed? if 'Yes' then how can I do
> fix it ? Please help.
> 
> Thank You!
> Deepak Singh
> Student I.I.T. Kanpur, INDIA
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From h.wickham at gmail.com  Fri Oct 23 13:15:08 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 23 Oct 2015 06:15:08 -0500
Subject: [R] Control of x-axis variable ordering in ggplot
In-Reply-To: <5629915A.2090604@cognigencorp.com>
References: <5629915A.2090604@cognigencorp.com>
Message-ID: <CABdHhvEUd9jWC8CUn4ruzM6jpc7ZTf2CR_q7d74j1ARnS9pFAw@mail.gmail.com>

You have two problems:

* geom_line() always draws from right-to-left
* you're defining colour outside of the plot in a very non-ggplot2 way.

Here's how I'd do it:

library(ggplot2)
data <- data.frame(
  x = rep(1:4, each = 25),
  y = rep(1:25, times = 4),
  g = rep(1:4, each = 25)
)
data$x <- data$x + 0.005 * data$y ^ 2 - 0.1 * data$y + 1

ggplot(data, aes(x, y, colour = factor(g))) +
  geom_point() +
  geom_path()


Alsonotethatcodeismucheasiertoreadifyouusespaces;)

Hadley

On Thu, Oct 22, 2015 at 8:46 PM, sbihorel
<Sebastien.Bihorel at cognigencorp.com> wrote:
> Hi,
>
> Given a certain data.frame, the lattice xyplot function will plot the data
> as.is and join the data point in the order of the data frame. It is my
> (probably flawed) understanding that, using the same data frame, ggplot
> orders the data by increasing order of the x-axis variable. Can one control
> this behavior?
>
> Thanks
>
> Sebastien
>
> Code example
>
> library(lattice)
> library(ggplot2)
>
>
> data <- data.frame(x=rep(1:4,each=25),
>                    y=rep(1:25,times=4),
>                    g=rep(1:4,each=25))
> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>
> col <- 3:7
>
> xyplot(y~x,data=data,groups=g,type='l',col=col)
>
> ggplot(data, aes(x,y,group=g)) + geom_point(colour=col[data$g]) +
>   geom_line(colour=col[data$g])
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From Sebastien.Bihorel at cognigencorp.com  Fri Oct 23 15:12:41 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Fri, 23 Oct 2015 09:12:41 -0400
Subject: [R] ggplot: combining geom's in function
Message-ID: <562A3249.9000503@cognigencorp.com>

Hi,

Next adventure into my journey from lattice to ggplot: I would like to 
create a custom generic function that combines multiple existing geom's  
in order to reproduce what the lattice panel.xyplot function does based 
on the type argument (ie, plotting points only for type='p', plotting 
lines for type 'l', etc).

My current naive attempt is:

library(lattice)
library(ggplot2)

geom_xyplot <- function (mapping = NULL, data = NULL, stat = "identity",
                          position = "identity", na.rm = FALSE, type = 
'p', ...) {

   if (any(type=='p')){
     geom_point(mapping = mapping, data = data, stat = stat,
                position = position, na.rm = na.rm, ...)
   }
   if (any(type=='l')){
     geom_path(mapping = mapping, data = data, stat = stat,
               position = position, na.rm = na.rm, ...)
   }
   if (any(type%in%c('b','o'))){
     geom_point(mapping = mapping, data = data, stat = stat,
                position = position, na.rm = na.rm, ...) +
       geom_path(mapping = mapping, data = data, stat = stat,
                 position = position, na.rm = na.rm, ...)
   }
}

data <- data.frame(x = rep(1:4, each = 25),
                    y = rep(1:25, times = 4),
                    g = rep(1:4, each = 25))
data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1

ggplot(data2, aes(x, y, group = g, colour = factor(g))) + 
geom_xyplot(type = 'l')

I get:
 > Error: No layers in plot


From albmont at centroin.com.br  Fri Oct 23 17:08:24 2015
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Fri, 23 Oct 2015 11:08:24 -0400
Subject: [R] Environment question
Message-ID: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>

>From the code below:

y <- 1

f1 <- function() { 
  cat("y =", y, "\n") 
}

f2 <- function() { 
  y <- 2
  f1()
}

f3 <- function() {
  y <- 3
  f <- f1
  f()
}

f4 <- function() {
  y <- 4
  f <- function() { cat("y =", y, "\n") }
  f()
}

f1()
f2()
f3()
f4()

Clearly, f1(), f2() and f4() will display "y = 1", "y = 1" and "y = 4",
but, not as much clearly but predictably, f3() also displays "y = 1".

Is there any way to rewrite the code of f3 in such a way that it
displays "y = 3"?

An obvious but cumbersome way would be something like:

f3 <- function() {
  y <- 3
  # write the code of f1 to a temporary file
  dump("f1", "temp.R")
  # read the code of f1
  str <- readLines("temp.R")
  # replace the code that defines function f1 for a code that defines function f
  str <- gsub("f1 <-", "f <-", str)
  # write the new code to the temporary file
  writeLines(str, "temp.R")
  # read the source but use local to get things from f3's environment
  # (with the default local = FALSE, "y" would get the value from globalenv())
  source("temp.R", local = TRUE)
  # ...?
  f()
  # PROFIT!
}
  
Is there a more elegant way to do this?

Alberto Monteiro


From murdoch.duncan at gmail.com  Fri Oct 23 17:21:04 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Oct 2015 11:21:04 -0400
Subject: [R] Environment question
In-Reply-To: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
References: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
Message-ID: <562A5060.5080005@gmail.com>

On 23/10/2015 11:08 AM, ALBERTO VIEIRA FERREIRA MONTEIRO wrote:
> From the code below:
> 
> y <- 1
> 
> f1 <- function() { 
>   cat("y =", y, "\n") 
> }
> 
> f2 <- function() { 
>   y <- 2
>   f1()
> }
> 
> f3 <- function() {
>   y <- 3
>   f <- f1
>   f()
> }
> 
> f4 <- function() {
>   y <- 4
>   f <- function() { cat("y =", y, "\n") }
>   f()
> }
> 
> f1()
> f2()
> f3()
> f4()
> 
> Clearly, f1(), f2() and f4() will display "y = 1", "y = 1" and "y = 4",
> but, not as much clearly but predictably, f3() also displays "y = 1".
> 
> Is there any way to rewrite the code of f3 in such a way that it
> displays "y = 3"?

After f <- f1, you can say

environment(f) <- environment()

That says that f should resolve non-local symbols by looking in the
environment that is current in that line, i.e. the local evaluation
frame of this invocation of f3.

One warning:  if in the real use case, the user is supplying f1, then
the user might be giving you something where the environment really
matters, and this substitution would cause the function to return
nonsense.  Or if the user's f1 makes use of other global variables that
happen to have the same name as other locals in f3, nonsense again.

Duncan Murdoch

> 
> An obvious but cumbersome way would be something like:
> 
> f3 <- function() {
>   y <- 3
>   # write the code of f1 to a temporary file
>   dump("f1", "temp.R")
>   # read the code of f1
>   str <- readLines("temp.R")
>   # replace the code that defines function f1 for a code that defines function f
>   str <- gsub("f1 <-", "f <-", str)
>   # write the new code to the temporary file
>   writeLines(str, "temp.R")
>   # read the source but use local to get things from f3's environment
>   # (with the default local = FALSE, "y" would get the value from globalenv())
>   source("temp.R", local = TRUE)
>   # ...?
>   f()
>   # PROFIT!
> }
>   
> Is there a more elegant way to do this?
> 
> Alberto Monteiro
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bgunter.4567 at gmail.com  Fri Oct 23 18:19:20 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 23 Oct 2015 09:19:20 -0700
Subject: [R] Environment question
In-Reply-To: <562A5060.5080005@gmail.com>
References: <534450511.750063.1445612904662.JavaMail.zimbra@centroin.com.br>
	<562A5060.5080005@gmail.com>
Message-ID: <CAGxFJbQ23bUe54aJSgpm4wk2m-efB8w9+1+JWgYf2rqgr=D7_Q@mail.gmail.com>

I do not understand exactly what you're looking for: "Any way to
rewrite the code.." is pretty vague. Here is _an_ answer, which may
completely miss what you mean,  followed by some comments.

y <- 1

f1 <- function(x=y) {
  cat("y =", x, "\n")
}

f2 <- function() {
  y <- 2
  f1()
}

f3 <- function() {
  y <- 3
  f1(y)
}

f4 <- function() {
  y <- 4
  f <- function() { cat("y =", y, "\n") }
  f()
}

> f1()
y = 1
> f2()
y = 1
> f3()
y = 3
> f4()
y = 4


Following up on Duncan's comments:

1) Looking up free variables in the enclosing environment is always
potentially risky imo, although it can certainly be useful. Explicitly
passing arguments with defaults seems safer.

2) Explicitly changing the enclosing environment is even riskier, as
Duncan made clear. The "environment<-" Help file explicitly adds:

"The replacement function parent.env<- is extremely dangerous as it
can be used to destructively change environments in ways that violate
assumptions made by the internal C code. It may be removed in the near
future"

If neither Duncan's nor my suggestions are helpful, you might try
re-posting with more context about the specific use case you are
concerned with.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Fri, Oct 23, 2015 at 8:21 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 23/10/2015 11:08 AM, ALBERTO VIEIRA FERREIRA MONTEIRO wrote:
>> From the code below:
>>
>> y <- 1
>>
>> f1 <- function() {
>>   cat("y =", y, "\n")
>> }
>>
>> f2 <- function() {
>>   y <- 2
>>   f1()
>> }
>>
>> f3 <- function() {
>>   y <- 3
>>   f <- f1
>>   f()
>> }
>>
>> f4 <- function() {
>>   y <- 4
>>   f <- function() { cat("y =", y, "\n") }
>>   f()
>> }
>>
>> f1()
>> f2()
>> f3()
>> f4()
>>
>> Clearly, f1(), f2() and f4() will display "y = 1", "y = 1" and "y = 4",
>> but, not as much clearly but predictably, f3() also displays "y = 1".
>>
>> Is there any way to rewrite the code of f3 in such a way that it
>> displays "y = 3"?
>
> After f <- f1, you can say
>
> environment(f) <- environment()
>
> That says that f should resolve non-local symbols by looking in the
> environment that is current in that line, i.e. the local evaluation
> frame of this invocation of f3.
>
> One warning:  if in the real use case, the user is supplying f1, then
> the user might be giving you something where the environment really
> matters, and this substitution would cause the function to return
> nonsense.  Or if the user's f1 makes use of other global variables that
> happen to have the same name as other locals in f3, nonsense again.
>
> Duncan Murdoch
>
>>
>> An obvious but cumbersome way would be something like:
>>
>> f3 <- function() {
>>   y <- 3
>>   # write the code of f1 to a temporary file
>>   dump("f1", "temp.R")
>>   # read the code of f1
>>   str <- readLines("temp.R")
>>   # replace the code that defines function f1 for a code that defines function f
>>   str <- gsub("f1 <-", "f <-", str)
>>   # write the new code to the temporary file
>>   writeLines(str, "temp.R")
>>   # read the source but use local to get things from f3's environment
>>   # (with the default local = FALSE, "y" would get the value from globalenv())
>>   source("temp.R", local = TRUE)
>>   # ...?
>>   f()
>>   # PROFIT!
>> }
>>
>> Is there a more elegant way to do this?
>>
>> Alberto Monteiro
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Oct 23 18:27:20 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 23 Oct 2015 18:27:20 +0200
Subject: [R] ggplot: combining geom's in function
In-Reply-To: <562A3249.9000503@cognigencorp.com>
References: <562A3249.9000503@cognigencorp.com>
Message-ID: <77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>

Have you looked at the qplot function in the ggplot2 package?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2015 3:12:41 PM GMT+02:00, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Hi,
>
>Next adventure into my journey from lattice to ggplot: I would like to 
>create a custom generic function that combines multiple existing geom's
> 
>in order to reproduce what the lattice panel.xyplot function does based
>
>on the type argument (ie, plotting points only for type='p', plotting 
>lines for type 'l', etc).
>
>My current naive attempt is:
>
>library(lattice)
>library(ggplot2)
>
>geom_xyplot <- function (mapping = NULL, data = NULL, stat =
>"identity",
>                          position = "identity", na.rm = FALSE, type = 
>'p', ...) {
>
>   if (any(type=='p')){
>     geom_point(mapping = mapping, data = data, stat = stat,
>                position = position, na.rm = na.rm, ...)
>   }
>   if (any(type=='l')){
>     geom_path(mapping = mapping, data = data, stat = stat,
>               position = position, na.rm = na.rm, ...)
>   }
>   if (any(type%in%c('b','o'))){
>     geom_point(mapping = mapping, data = data, stat = stat,
>                position = position, na.rm = na.rm, ...) +
>       geom_path(mapping = mapping, data = data, stat = stat,
>                 position = position, na.rm = na.rm, ...)
>   }
>}
>
>data <- data.frame(x = rep(1:4, each = 25),
>                    y = rep(1:25, times = 4),
>                    g = rep(1:4, each = 25))
>data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>
>ggplot(data2, aes(x, y, group = g, colour = factor(g))) + 
>geom_xyplot(type = 'l')
>
>I get:
> > Error: No layers in plot
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From erich.neuwirth at univie.ac.at  Fri Oct 23 18:44:07 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Fri, 23 Oct 2015 18:44:07 +0200
Subject: [R] ggplot: combining geom's in function
In-Reply-To: <77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
References: <562A3249.9000503@cognigencorp.com>
	<77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
Message-ID: <C8F34D52-A825-4441-9639-CFA0DD6DD0B8@univie.ac.at>

I often look for examples in
http://www.cookbook-r.com/Graphs/ <http://www.cookbook-r.com/Graphs/>

> On 23 Oct 2015, at 18:27, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> Have you looked at the qplot function in the ggplot2 package?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
> 
> On October 23, 2015 3:12:41 PM GMT+02:00, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hi,
>> 
>> Next adventure into my journey from lattice to ggplot: I would like to
>> create a custom generic function that combines multiple existing geom's
>> 
>> in order to reproduce what the lattice panel.xyplot function does based
>> 
>> on the type argument (ie, plotting points only for type='p', plotting
>> lines for type 'l', etc).
>> 
>> My current naive attempt is:
>> 
>> library(lattice)
>> library(ggplot2)
>> 
>> geom_xyplot <- function (mapping = NULL, data = NULL, stat =
>> "identity",
>>                         position = "identity", na.rm = FALSE, type =
>> 'p', ...) {
>> 
>>  if (any(type=='p')){
>>    geom_point(mapping = mapping, data = data, stat = stat,
>>               position = position, na.rm = na.rm, ...)
>>  }
>>  if (any(type=='l')){
>>    geom_path(mapping = mapping, data = data, stat = stat,
>>              position = position, na.rm = na.rm, ...)
>>  }
>>  if (any(type%in%c('b','o'))){
>>    geom_point(mapping = mapping, data = data, stat = stat,
>>               position = position, na.rm = na.rm, ...) +
>>      geom_path(mapping = mapping, data = data, stat = stat,
>>                position = position, na.rm = na.rm, ...)
>>  }
>> }
>> 
>> data <- data.frame(x = rep(1:4, each = 25),
>>                   y = rep(1:25, times = 4),
>>                   g = rep(1:4, each = 25))
>> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>> 
>> ggplot(data2, aes(x, y, group = g, colour = factor(g))) +
>> geom_xyplot(type = 'l')
>> 
>> I get:
>>> Error: No layers in plot
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151023/438b3e8d/attachment.bin>

From c06n.rm at gmail.com  Fri Oct 23 10:01:51 2015
From: c06n.rm at gmail.com (c06n)
Date: Fri, 23 Oct 2015 10:01:51 +0200
Subject: [R] Control of x-axis variable ordering in ggplot
In-Reply-To: <5629915A.2090604@cognigencorp.com>
References: <5629915A.2090604@cognigencorp.com>
Message-ID: <061D971D-4C17-4FAF-AC8E-326DB5519DC3@gmail.com>

Hi,

are you trying to do the same thing with ggplot as with lattice? 

In this case, your solution looks probably like this: 

ggplot(data, aes(x, y, group = g)) + 
  geom_path(aes(colour = g))

If you haven?t done so yet, I strongly recommend reading through the ggplot2 documentation: http://docs.ggplot2.org/current/index.html <http://docs.ggplot2.org/current/index.html>

It?s a bit of a read, but you?ll need this knowledge to successfully operate ggplot.

> Am 23.10.2015 um 03:46 schrieb sbihorel <Sebastien.Bihorel at cognigencorp.com>:
> 
> Hi,
> 
> Given a certain data.frame, the lattice xyplot function will plot the data as.is and join the data point in the order of the data frame. It is my (probably flawed) understanding that, using the same data frame, ggplot orders the data by increasing order of the x-axis variable. Can one control this behavior?
> 
> Thanks
> 
> Sebastien
> 
> Code example
> 
> library(lattice)
> library(ggplot2)
> 
> 
> data <- data.frame(x=rep(1:4,each=25),
>                   y=rep(1:25,times=4),
>                   g=rep(1:4,each=25))
> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
> 
> col <- 3:7
> 
> xyplot(y~x,data=data,groups=g,type='l',col=col)
> 
> ggplot(data, aes(x,y,group=g)) + geom_point(colour=col[data$g]) +
>  geom_line(colour=col[data$g])
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From bijoy.joseph at thl.fi  Fri Oct 23 12:56:13 2015
From: bijoy.joseph at thl.fi (Bijoy Joseph)
Date: Fri, 23 Oct 2015 13:56:13 +0300
Subject: [R] virus/trojan in contributed package: 'svs'
In-Reply-To: <845FD7E1-D45C-44E3-9DE7-2A696743F73E@gmail.com>
References: <5629E403.5030105@thl.fi>
	<845FD7E1-D45C-44E3-9DE7-2A696743F73E@gmail.com>
Message-ID: <562A124D.6010305@thl.fi>

See output below:

$ clamscan -ri svs/
./svs/extdata/InvT_Eng.txt: BAT.CMDFlood FOUND

In the tarball, the file is "./inst/extdata/InvT_Eng.txt", and clamscan 
gives the same output.

$ file svs/extdata/InvT_Eng.txt
./svs/extdata/InvT_Eng.txt: ASCII text, with CRLF line terminators

I managed to find a Windows machine to scan the file (using MS System 
center Endpoint), and it detected no threat! False positive, as you 
suggested.

Thanks,
Bijoy Joseph


On 2015-10-23 12:23, peter dalgaard wrote:
> Virus scanners generate a fair amount of false positives. Does it persist if you unpack the zip file or the source tarball? If so, what file has the issue?
>
> -pd
>
> On 23 Oct 2015, at 09:38 , Bijoy Joseph <bijoy.joseph at thl.fi> wrote:
>
>> Hello,
>>
>> I came across the following when I was installing the 'svs' package:
>>
>> $ clamscan svs_1.0.3.zip
>> svs_1.0.3.zip: BAT.CMDFlood FOUND
>>
>> ----------- SCAN SUMMARY -----------
>> Known viruses: 4035827
>> Engine version: 0.98.7
>> Scanned directories: 0
>> Scanned files: 1
>> Infected files: 1
>>
>>
>> clamscan finds this trojan in the source tarball as well. Does the r-project does a virus scan of contributed packages? I had come across a virus a few years earlier, but an email to the maintainer fixed that issue. I have heard nothing (yet) from the maintainer in this case.
>>
>> Bijoy
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From Sebastien.Bihorel at cognigencorp.com  Fri Oct 23 13:22:10 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Fri, 23 Oct 2015 07:22:10 -0400
Subject: [R] Control of x-axis variable ordering in ggplot
In-Reply-To: <CABdHhvEUd9jWC8CUn4ruzM6jpc7ZTf2CR_q7d74j1ARnS9pFAw@mail.gmail.com>
References: <5629915A.2090604@cognigencorp.com>
	<CABdHhvEUd9jWC8CUn4ruzM6jpc7ZTf2CR_q7d74j1ARnS9pFAw@mail.gmail.com>
Message-ID: <562A1862.6040100@cognigencorp.com>

Hi,

I want to thank Jeff, Dennis, c06n, and Hadley for their replies and 
explanations. As you probably guessed, I am fairly new to ggplot am 
trying to loose my lattice reflex while transitioning to ggplot.

Thank for the link to the ggplot external documentation.

Sebastien

On 10/23/2015 7:15 AM, Hadley Wickham wrote:
> You have two problems:
>
> * geom_line() always draws from right-to-left
> * you're defining colour outside of the plot in a very non-ggplot2 way.
>
> Here's how I'd do it:
>
> library(ggplot2)
> data <- data.frame(
>    x = rep(1:4, each = 25),
>    y = rep(1:25, times = 4),
>    g = rep(1:4, each = 25)
> )
> data$x <- data$x + 0.005 * data$y ^ 2 - 0.1 * data$y + 1
>
> ggplot(data, aes(x, y, colour = factor(g))) +
>    geom_point() +
>    geom_path()
>
>
> Alsonotethatcodeismucheasiertoreadifyouusespaces;)
>
> Hadley
>
> On Thu, Oct 22, 2015 at 8:46 PM, sbihorel
> <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hi,
>>
>> Given a certain data.frame, the lattice xyplot function will plot the data
>> as.is and join the data point in the order of the data frame. It is my
>> (probably flawed) understanding that, using the same data frame, ggplot
>> orders the data by increasing order of the x-axis variable. Can one control
>> this behavior?
>>
>> Thanks
>>
>> Sebastien
>>
>> Code example
>>
>> library(lattice)
>> library(ggplot2)
>>
>>
>> data <- data.frame(x=rep(1:4,each=25),
>>                     y=rep(1:25,times=4),
>>                     g=rep(1:4,each=25))
>> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>>
>> col <- 3:7
>>
>> xyplot(y~x,data=data,groups=g,type='l',col=col)
>>
>> ggplot(data, aes(x,y,group=g)) + geom_point(colour=col[data$g]) +
>>    geom_line(colour=col[data$g])
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Sebastien Bihorel
Cognigen Corporation
(t) +1 716 633 3463 ext 323
Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.

From efisio.solazzo at jrc.ec.europa.eu  Fri Oct 23 14:25:21 2015
From: efisio.solazzo at jrc.ec.europa.eu (efisio solazzo)
Date: Fri, 23 Oct 2015 14:25:21 +0200
Subject: [R] annotating faceted ggplot
Message-ID: <562A2731.4030505@jrc.ec.europa.eu>

Dear, I have been reading several posts but still cannot work out how to 
annotate a faceted boxplot created from existing statistics using ggplot.

the dataframe is smthing like:

>dep_stat
   specie.sp. models min     max   q25    q50      q75
1        NO2   mod1   0   225.0   0.1   0.40    1.300
2        NO2   mod2   0   219.5   0.6   2.40    8.100
3         O3   mod1   0  2834.4  93.8 334.80  793.525
4         O3   mod2   0  1238.6   5.0 214.70  376.400
5       PM25   mod1   0 49948.0 123.5 438.10 1146.100
6       PM25   mod2   0  2466.1   9.2  24.55  184.300


from which I create the plot in the figure, where the bars go from min 
to the 75th percentile.

ggplot(dep_stat, aes(x=models, ymin=min, ymax=q75, lower=q25, 
middle=q50, upper=q75)) +
geom_boxplot(stat='identity', width=0.5) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1.5)) +
theme(axis.title.x = element_blank())+theme(axis.title.y = 
element_blank()) +
facet_wrap(~specie.sp., nrow=1, scales="free")

I'm trying to add (as text) at the top of each bar the maximum value, 
but the annotate command doesn't do the job right:

annotate('text', x=rep(seq(1:length(models)),3), y=q75+0.5, 
label=as.character(max), color="red", angle = 90, cex=5).

In this way three values text get added to each column...I have also 
tried with geom_text and grobTree, without success.

thanks for your help.




From eugen_pircalabelu at yahoo.com  Fri Oct 23 19:31:08 2015
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Fri, 23 Oct 2015 17:31:08 +0000 (UTC)
Subject: [R] elementwise matrix multiplication with a special structure
References: <1439044795.2191750.1445621468807.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1439044795.2191750.1445621468807.JavaMail.yahoo@mail.yahoo.com>

Hello R users,
I have the following annoying matrix multiplication and I do not know how to avoid the nested loops, so maybe someone can help me with some ideas. I have searched the forum for past posts but nothing came up.Here it is:
?aa=matrix(1:9,3,3)?bb=matrix(seq(10,90,by=10),3,3)?cc=matrix(seq(100,900, by=100),3,3)?dd=NULL 
for(r in 1:3){????for(c in 1:3){????????for(j in 1:3){????????????for(k in 1:3){dd=c(dd,aa[j,k]*bb[r,j]*cc[k,c])}}}}dd?[1] ? 1000 ? 8000 ?21000 ? 8000 ?40000 ?96000 ?21000 ?84000 189000 ? 4000[11] ?20000 ?42000 ?32000 100000 192000 ?84000 210000 378000 ? 7000 ?32000[21] ?63000 ?56000 160000 288000 147000 336000 567000 ? 2000 ?16000 ?42000[31] ?10000 ?50000 120000 ?24000 ?96000 216000 ? 8000 ?40000 ?84000 ?40000[41] 125000 240000 ?96000 240000 432000 ?14000 ?64000 126000 ?70000 200000[51] 360000 168000 384000 648000 ? 3000 ?24000 ?63000 ?12000 ?60000 144000[61] ?27000 108000 243000 ?12000 ?60000 126000 ?48000 150000 288000 108000[71] 270000 486000 ?21000 ?96000 189000 ?84000 240000 432000 189000 432000[81] 729000
What I want to obtain is the content of the vector dd in an efficient (fast) and clever way.Thank you very much and have a great day ahead!Eugen

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Fri Oct 23 21:06:08 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Fri, 23 Oct 2015 15:06:08 -0400
Subject: [R] ggplot: combining geom's in function
In-Reply-To: <77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
References: <562A3249.9000503@cognigencorp.com>
	<77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
Message-ID: <562A8520.8060400@cognigencorp.com>

Hi

Thanks for the suggestion. Unfortunately, the qplot function would work 
nicely if only I did not need to combine its output with other geom 
called before...

A simple example using the data previously described:

ggplot(data, aes(x,y,group=g)) + geom_blank() + 
qplot(x=x,y=y,data=data,group=g,colour=factor(g),geom = c('point','line'))
 > Error in p + o : non-numeric argument to binary operator
In addition: Warning message:
Incompatible methods ("+.gg", "Ops.data.frame") for "+"

I know I could combine the geom's by adapting the order of the calls to 
my data and needs for this one example. But this is not my goal. I am 
trying to build a generic function, not an ad-hoc script.

Sebastien

On 10/23/2015 12:27 PM, Jeff Newmiller wrote:
> Have you looked at the qplot function in the ggplot2 package?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 23, 2015 3:12:41 PM GMT+02:00, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hi,
>>
>> Next adventure into my journey from lattice to ggplot: I would like to
>> create a custom generic function that combines multiple existing geom's
>>
>> in order to reproduce what the lattice panel.xyplot function does based
>>
>> on the type argument (ie, plotting points only for type='p', plotting
>> lines for type 'l', etc).
>>
>> My current naive attempt is:
>>
>> library(lattice)
>> library(ggplot2)
>>
>> geom_xyplot <- function (mapping = NULL, data = NULL, stat =
>> "identity",
>>                           position = "identity", na.rm = FALSE, type =
>> 'p', ...) {
>>
>>    if (any(type=='p')){
>>      geom_point(mapping = mapping, data = data, stat = stat,
>>                 position = position, na.rm = na.rm, ...)
>>    }
>>    if (any(type=='l')){
>>      geom_path(mapping = mapping, data = data, stat = stat,
>>                position = position, na.rm = na.rm, ...)
>>    }
>>    if (any(type%in%c('b','o'))){
>>      geom_point(mapping = mapping, data = data, stat = stat,
>>                 position = position, na.rm = na.rm, ...) +
>>        geom_path(mapping = mapping, data = data, stat = stat,
>>                  position = position, na.rm = na.rm, ...)
>>    }
>> }
>>
>> data <- data.frame(x = rep(1:4, each = 25),
>>                     y = rep(1:25, times = 4),
>>                     g = rep(1:4, each = 25))
>> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>>
>> ggplot(data2, aes(x, y, group = g, colour = factor(g))) +
>> geom_xyplot(type = 'l')
>>
>> I get:
>>> Error: No layers in plot
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Fri Oct 23 21:17:08 2015
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 23 Oct 2015 15:17:08 -0400
Subject: [R] string split problem
Message-ID: <CAMCXXmq8gCaDaPcJAOJJsUt2X1vnEaA9GK9Y4cQz3xVLUE=HhQ@mail.gmail.com>

Dear list,

Say I have a vector that has two different types of string

test <- c('aaa.bb.cc','aaa.dd')

I want to extract the first part of the string (aaa) as a name and save the
rest of the string as another name.

I was thinking something like

sub('(.*)\\.(.*)','\\1',test) but doesn't give me what I want.


Appreciate any comments. Thanks.

Jun

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Oct 23 21:25:26 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 23 Oct 2015 19:25:26 +0000
Subject: [R] elementwise matrix multiplication with a special structure
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D3835@mb02.ads.tamu.edu>

Don't use html formatted emails. The r-help server strips the html formatting leaving us the the mess you see below. 

You don't need any loops:

> aa <- matrix(1:9, 3, 3)
> bb <- aa * 10
> cc <- bb * 10
> x <- as.matrix(expand.grid(k=1:3, j=1:3, c=1:3, r=1:3))
> str(x)
 int [1:81, 1:4] 1 2 3 1 2 3 1 2 3 1 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:4] "k" "j" "c" "r"
> dd <- aa[x[, c("j", "k")]] * bb[x[, c("r", "j")]] * cc[x[, c("k", "c")]]
> dd
 [1]   1000   8000  21000   8000  40000  96000  21000  84000 189000
[10]   4000  20000  42000  32000 100000 192000  84000 210000 378000
[19]   7000  32000  63000  56000 160000 288000 147000 336000 567000
[28]   2000  16000  42000  10000  50000 120000  24000  96000 216000
[37]   8000  40000  84000  40000 125000 240000  96000 240000 432000
[46]  14000  64000 126000  70000 200000 360000 168000 384000 648000
[55]   3000  24000  63000  12000  60000 144000  27000 108000 243000
[64]  12000  60000 126000  48000 150000 288000 108000 270000 486000
[73]  21000  96000 189000  84000 240000 432000 189000 432000 729000

# Or a bit more compactly
> dd <- aa[x[, c(2, 1)]] * bb[x[, c(4, 2)]] * cc[x[, c(1, 3)]]

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of eugen pircalabelu via R-help
Sent: Friday, October 23, 2015 12:31 PM
To: r-help at r-project.org
Subject: [R] elementwise matrix multiplication with a special structure

Hello R users,
I have the following annoying matrix multiplication and I do not know how to avoid the nested loops, so maybe someone can help me with some ideas. I have searched the forum for past posts but nothing came up.Here it is:
?aa=matrix(1:9,3,3)?bb=matrix(seq(10,90,by=10),3,3)?cc=matrix(seq(100,900, by=100),3,3)?dd=NULL 
for(r in 1:3){????for(c in 1:3){????????for(j in 1:3){????????????for(k in 1:3){dd=c(dd,aa[j,k]*bb[r,j]*cc[k,c])}}}}dd?[1] ? 1000 ? 8000 ?21000 ? 8000 ?40000 ?96000 ?21000 ?84000 189000 ? 4000[11] ?20000 ?42000 ?32000 100000 192000 ?84000 210000 378000 ? 7000 ?32000[21] ?63000 ?56000 160000 288000 147000 336000 567000 ? 2000 ?16000 ?42000[31] ?10000 ?50000 120000 ?24000 ?96000 216000 ? 8000 ?40000 ?84000 ?40000[41] 125000 240000 ?96000 240000 432000 ?14000 ?64000 126000 ?70000 200000[51] 360000 168000 384000 648000 ? 3000 ?24000 ?63000 ?12000 ?60000 144000[61] ?27000 108000 243000 ?12000 ?60000 126000 ?48000 150000 288000 108000[71] 270000 486000 ?21000 ?96000 189000 ?84000 240000 432000 189000 432000[81] 729000
What I want to obtain is the content of the vector dd in an efficient (fast) and clever way.Thank you very much and have a great day ahead!Eugen

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From marc_schwartz at me.com  Fri Oct 23 21:39:50 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 23 Oct 2015 14:39:50 -0500
Subject: [R] string split problem
In-Reply-To: <CAMCXXmq8gCaDaPcJAOJJsUt2X1vnEaA9GK9Y4cQz3xVLUE=HhQ@mail.gmail.com>
References: <CAMCXXmq8gCaDaPcJAOJJsUt2X1vnEaA9GK9Y4cQz3xVLUE=HhQ@mail.gmail.com>
Message-ID: <49F34118-785E-46DE-85FD-65C7CB54D556@me.com>


> On Oct 23, 2015, at 2:17 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> 
> Dear list,
> 
> Say I have a vector that has two different types of string
> 
> test <- c('aaa.bb.cc','aaa.dd')
> 
> I want to extract the first part of the string (aaa) as a name and save the
> rest of the string as another name.
> 
> I was thinking something like
> 
> sub('(.*)\\.(.*)','\\1',test) but doesn't give me what I want.
> 
> 
> Appreciate any comments. Thanks.
> 
> Jun


How about something like this, which presumes that the characters (besides the periods) are only letters:

> gsub("^([[:alpha:]]+)\\.(.*)$", "\\1|\\2", test) 
[1] "aaa|bb.cc" "aaa|dd"   

or

> sub("^([[:alpha:]]+)\\.(.*)$", "\\1|\\2", test) 
[1] "aaa|bb.cc" "aaa|dd"   


The above takes the two components, before and after the first '.', adds the "|" as a character in between, to then be used in strsplit():


> strsplit(gsub("^([[:alpha:]]+)\\.(.*)$", "\\1|\\2", test), split = "\\|") 
[[1]]
[1] "aaa"   "bb.cc"

[[2]]
[1] "aaa" "dd" 


See ?regex

Regards,

Marc Schwartz


From maillists at nic.fi  Fri Oct 23 21:44:03 2015
From: maillists at nic.fi (K. Elo)
Date: Fri, 23 Oct 2015 22:44:03 +0300
Subject: [R] JSONlite import problem
Message-ID: <562A8E03.8040304@nic.fi>

Hi!

I have collected 500.000+ tweets with a Python script using 'tweepy', 
which stored the data in JSON format. I would like to use R for data 
analysis, but have encountered problems when trying to import the data 
file with 'jsonlite'.

Here what I have tried:

 > data.df<-fromJSON("example.json")
Error in feed_push_parser(readBin(con, raw(), n), reset = TRUE) :
   parse error: trailing garbage
           stamp_ms":"1436705823768"}   {"created_at":"Sun Jul 12 12:57
                      (right here) ------^

The import fails already on the first line :( A sample file causing this 
error is attached.

I have tried several solutions, e.g. this:
http://stackoverflow.com/questions/26519455/error-parsing-json-file-with-the-jsonlite-package

but it does not work and results in the same error.

Could anyone help me to understand what is causing the error and how to 
solve the issue? Thanks in advance.

Kind regards,
Kimmo Elo

--
University of Turku, Finland
Dep. of political science and contemporary history

From Sebastien.Bihorel at cognigencorp.com  Fri Oct 23 21:46:49 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Fri, 23 Oct 2015 15:46:49 -0400
Subject: [R] ggplot: combining geom's in function
In-Reply-To: <77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
References: <562A3249.9000503@cognigencorp.com>
	<77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
Message-ID: <562A8EA9.9040401@cognigencorp.com>

Following up on my previous reply, this following would work but would 
not behave like a geom function:

geom_xyplot <- function (gplot, mapping = NULL, data = NULL, stat = 
"identity",
                          position = "identity", na.rm = FALSE, type = 
'p', ...) {

   if (any(type=='p')){
     gplot + geom_point(mapping = mapping, data = data, stat = stat,
                        position = position, na.rm = na.rm, ...)
   }
   if (any(type=='l')){
     gplot + geom_path(mapping = mapping, data = data, stat = stat,
                       position = position, na.rm = na.rm, ...)
   }
   if (any(type%in%c('b','o'))){
     gplot + geom_point(mapping = mapping, data = data, stat = stat,
                        position = position, na.rm = na.rm, ...) +
       geom_path(mapping = mapping, data = data, stat = stat,
                 position = position, na.rm = na.rm, ...)
   }
}

Sebastien

On 10/23/2015 12:27 PM, Jeff Newmiller wrote:
> Have you looked at the qplot function in the ggplot2 package?
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 23, 2015 3:12:41 PM GMT+02:00, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hi,
>>
>> Next adventure into my journey from lattice to ggplot: I would like to
>> create a custom generic function that combines multiple existing geom's
>>
>> in order to reproduce what the lattice panel.xyplot function does based
>>
>> on the type argument (ie, plotting points only for type='p', plotting
>> lines for type 'l', etc).
>>
>> My current naive attempt is:
>>
>> library(lattice)
>> library(ggplot2)
>>
>> geom_xyplot <- function (mapping = NULL, data = NULL, stat =
>> "identity",
>>                           position = "identity", na.rm = FALSE, type =
>> 'p', ...) {
>>
>>    if (any(type=='p')){
>>      geom_point(mapping = mapping, data = data, stat = stat,
>>                 position = position, na.rm = na.rm, ...)
>>    }
>>    if (any(type=='l')){
>>      geom_path(mapping = mapping, data = data, stat = stat,
>>                position = position, na.rm = na.rm, ...)
>>    }
>>    if (any(type%in%c('b','o'))){
>>      geom_point(mapping = mapping, data = data, stat = stat,
>>                 position = position, na.rm = na.rm, ...) +
>>        geom_path(mapping = mapping, data = data, stat = stat,
>>                  position = position, na.rm = na.rm, ...)
>>    }
>> }
>>
>> data <- data.frame(x = rep(1:4, each = 25),
>>                     y = rep(1:25, times = 4),
>>                     g = rep(1:4, each = 25))
>> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>>
>> ggplot(data2, aes(x, y, group = g, colour = factor(g))) +
>> geom_xyplot(type = 'l')
>>
>> I get:
>>> Error: No layers in plot
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Fri Oct 23 21:52:17 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 23 Oct 2015 15:52:17 -0400
Subject: [R] JSONlite import problem
In-Reply-To: <562A8E03.8040304@nic.fi>
References: <562A8E03.8040304@nic.fi>
Message-ID: <562A8FF1.1050806@gmail.com>

On 23/10/2015 3:44 PM, K. Elo wrote:
> Hi!
>
> I have collected 500.000+ tweets with a Python script using 'tweepy',
> which stored the data in JSON format. I would like to use R for data
> analysis, but have encountered problems when trying to import the data
> file with 'jsonlite'.
>
> Here what I have tried:
>
>   > data.df<-fromJSON("example.json")
> Error in feed_push_parser(readBin(con, raw(), n), reset = TRUE) :
>     parse error: trailing garbage
>             stamp_ms":"1436705823768"}   {"created_at":"Sun Jul 12 12:57
>                        (right here) ------^
>
> The import fails already on the first line :( A sample file causing this
> error is attached.
>
> I have tried several solutions, e.g. this:
> http://stackoverflow.com/questions/26519455/error-parsing-json-file-with-the-jsonlite-package
>
> but it does not work and results in the same error.
>
> Could anyone help me to understand what is causing the error and how to
> solve the issue? Thanks in advance.

It looks like it's the same sort of problem as in that stackoverflow 
posting:  what's in your file is not valid Javascript, so it's not valid 
JSON.  It's probably multiple JSON objects without proper separators; 
you need to do the separating yourself.

BTW, your attachment failed; only some file types are allowed.  You 
should probably put the file online somewhere and post the URL.

Duncan Murdoch


From wdunlap at tibco.com  Fri Oct 23 21:53:14 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 23 Oct 2015 12:53:14 -0700
Subject: [R] string split problem
In-Reply-To: <CAMCXXmq8gCaDaPcJAOJJsUt2X1vnEaA9GK9Y4cQz3xVLUE=HhQ@mail.gmail.com>
References: <CAMCXXmq8gCaDaPcJAOJJsUt2X1vnEaA9GK9Y4cQz3xVLUE=HhQ@mail.gmail.com>
Message-ID: <CAF8bMcYUjK8+JtaCYenQK9vmRMsqhi-2-zXSbxwBcjhHx2UD5w@mail.gmail.com>

> test <- c('aaa.bb.cc','aaa.dd', 'aaa', 'aaa.', '.eee', '')
> sub("([^.]*)(.*)", "\\1", test)
[1] "aaa" "aaa" "aaa" "aaa" ""    ""
> sub("([^.]*)(.*)", "\\2", test)
[1] ".bb.cc" ".dd"    ""       "."      ".eee"   ""
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 23, 2015 at 12:17 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> Dear list,
>
> Say I have a vector that has two different types of string
>
> test <- c('aaa.bb.cc','aaa.dd')
>
> I want to extract the first part of the string (aaa) as a name and save the
> rest of the string as another name.
>
> I was thinking something like
>
> sub('(.*)\\.(.*)','\\1',test) but doesn't give me what I want.
>
>
> Appreciate any comments. Thanks.
>
> Jun
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jun.shen.ut at gmail.com  Fri Oct 23 22:18:49 2015
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Fri, 23 Oct 2015 16:18:49 -0400
Subject: [R] string split problem
In-Reply-To: <CAF8bMcYUjK8+JtaCYenQK9vmRMsqhi-2-zXSbxwBcjhHx2UD5w@mail.gmail.com>
References: <CAMCXXmq8gCaDaPcJAOJJsUt2X1vnEaA9GK9Y4cQz3xVLUE=HhQ@mail.gmail.com>
	<CAF8bMcYUjK8+JtaCYenQK9vmRMsqhi-2-zXSbxwBcjhHx2UD5w@mail.gmail.com>
Message-ID: <CAMCXXmreGVrya-+8-oAu83yTv5cyZG-vi+GFfAvkD6WjKnqO3A@mail.gmail.com>

Hi Marc/Bill
Thanks for reply. That's exactly what I am looking for.
Jun

On Fri, Oct 23, 2015 at 3:53 PM, William Dunlap <wdunlap at tibco.com> wrote:

> > test <- c('aaa.bb.cc','aaa.dd', 'aaa', 'aaa.', '.eee', '')
> > sub("([^.]*)(.*)", "\\1", test)
> [1] "aaa" "aaa" "aaa" "aaa" ""    ""
> > sub("([^.]*)(.*)", "\\2", test)
> [1] ".bb.cc" ".dd"    ""       "."      ".eee"   ""
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Fri, Oct 23, 2015 at 12:17 PM, Jun Shen <jun.shen.ut at gmail.com> wrote:
> > Dear list,
> >
> > Say I have a vector that has two different types of string
> >
> > test <- c('aaa.bb.cc','aaa.dd')
> >
> > I want to extract the first part of the string (aaa) as a name and save
> the
> > rest of the string as another name.
> >
> > I was thinking something like
> >
> > sub('(.*)\\.(.*)','\\1',test) but doesn't give me what I want.
> >
> >
> > Appreciate any comments. Thanks.
> >
> > Jun
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From mkbartl at gmail.com  Sat Oct 24 02:11:44 2015
From: mkbartl at gmail.com (Megan Bartlett)
Date: Fri, 23 Oct 2015 17:11:44 -0700
Subject: [R] Applying ME in spdep to phylogenetic autocorrelation
Message-ID: <CAB2zMEErJd0p0T2THMFyn7u+FzcCWRym=m1zncyVkH++QF51fA@mail.gmail.com>

Hi all,

I want to fit a model with the form:

trait 1 ~ trait 2 + environmental variable

while controlling for the phylogenetic relatedness in my study species. I
would use phylogenetic least squares regression, but I want to apply an
independent effects analysis to partition the effects of trait 2 and
environment on trait 1. (Partial correlation doesn't work here since all 3
variables are correlated).

It looks like the ME function in the spdep package does exactly what I
would like to do for phylogenetic autocorrelation, but for spatial
autocorrelation. Is there a way to apply ME to phylogenetically structured
instead of spatially structured data? I can use the mat2listw function to
convert the phylogenetic distance matrix to a listw object, but I'm not
sure I'm representing the neighbor relationships correctly. Should each
taxa be connected to every other taxa by a weight that reflects the
phylogenetic distance, or should only the most closely related tips be
counted as neighbors? Should the phylogenetic distance matrix itself go
into the mat2listw function, or should the values be converted to
1/distance, to be analogous to spatial weights? How can I use the S0, S1,
and S2 values from the summary() of the listw object to figure out whether
I've represented the neighbors correctly?

Thanks very much for your help!

Best,

Megan Bartlett

	[[alternative HTML version deleted]]


From maillists at nic.fi  Sat Oct 24 06:11:43 2015
From: maillists at nic.fi (K. Elo)
Date: Sat, 24 Oct 2015 07:11:43 +0300
Subject: [R] JSONlite import problem
In-Reply-To: <562A8FF1.1050806@gmail.com>
References: <562A8E03.8040304@nic.fi> <562A8FF1.1050806@gmail.com>
Message-ID: <562B04FF.6010907@nic.fi>

Hi!

You can download the example file with this link:
https://www.dropbox.com/s/tlf1gkym6d83log/example.json?dl=0

BTW, I have used a JSON validator and the problem seems to related to 
wrong/missing EOF.

--- snip ---
Error: Parse error on line 1:
...:"1436705823768"} {"created_at":"Sun J
---------------------^
Expecting 'EOF', '}', ',', ']', got '{'
--- snip ---

However, editing the file with a text editor to create "proper" EOF 
doesn't help.

-Kimmo-

23.10.2015, 22:52, Duncan Murdoch wrote:
> It looks like it's the same sort of problem as in that stackoverflow
> posting:  what's in your file is not valid Javascript, so it's not valid
> JSON.  It's probably multiple JSON objects without proper separators;
> you need to do the separating yourself.
>
> BTW, your attachment failed; only some file types are allowed.  You
> should probably put the file online somewhere and post the URL.
>
> Duncan Murdoch


From minglho at gmail.com  Sat Oct 24 02:59:20 2015
From: minglho at gmail.com (Ming-Lun Ho)
Date: Fri, 23 Oct 2015 17:59:20 -0700
Subject: [R] How to correct documentation?
Message-ID: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>

Hi,
    I used "?mtcars" to read the documentation for the dataset. I found a
mistake in how unit is listed, namely, that for the variable "wt," the unit
should be listed as "1000 lb," not "lb/1000." However, I don't know whom to
contact exactly for the correction. Please point me to the right place.
    Thanks.
          --Ming

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sat Oct 24 10:10:45 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 24 Oct 2015 19:10:45 +1100
Subject: [R] How to correct documentation?
In-Reply-To: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
Message-ID: <CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>

Hi Ming,
In fact, the notation lb/1000 is correct, as the values represent the
weight of the cars in pounds (lb) divided by 1000. I am not sure why this
particular transformation of the measured values was used, but I'm sure it
has caused confusion previously.

Jim


On Sat, Oct 24, 2015 at 11:59 AM, Ming-Lun Ho <minglho at gmail.com> wrote:

> Hi,
>     I used "?mtcars" to read the documentation for the dataset. I found a
> mistake in how unit is listed, namely, that for the variable "wt," the unit
> should be listed as "1000 lb," not "lb/1000." However, I don't know whom to
> contact exactly for the correction. Please point me to the right place.
>     Thanks.
>           --Ming
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Oct 24 10:50:28 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 24 Oct 2015 10:50:28 +0200
Subject: [R] ggplot: combining geom's in function
In-Reply-To: <562A8EA9.9040401@cognigencorp.com>
References: <562A3249.9000503@cognigencorp.com>
	<77847DEC-E881-472E-89CF-64A43DECBB64@dcn.davis.CA.us>
	<562A8EA9.9040401@cognigencorp.com>
Message-ID: <2BAC6EE5-D2D7-4745-8D7E-555CD0ECB470@dcn.davis.CA.us>

If you want to use the lattice way of doing things, why are you using ggplot?

`+` is defined for the output of ggplot (class "waiver") on the left, and the output of a layer function ("proto") on the right. The design of ggplot assumes left-to-right evaluation, which your first attempt failed to maintain. Your second approach is how I usually add multiple layers to a plot.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2015 9:46:49 PM GMT+02:00, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Following up on my previous reply, this following would work but would 
>not behave like a geom function:
>
>geom_xyplot <- function (gplot, mapping = NULL, data = NULL, stat = 
>"identity",
>                          position = "identity", na.rm = FALSE, type = 
>'p', ...) {
>
>   if (any(type=='p')){
>     gplot + geom_point(mapping = mapping, data = data, stat = stat,
>                        position = position, na.rm = na.rm, ...)
>   }
>   if (any(type=='l')){
>     gplot + geom_path(mapping = mapping, data = data, stat = stat,
>                       position = position, na.rm = na.rm, ...)
>   }
>   if (any(type%in%c('b','o'))){
>     gplot + geom_point(mapping = mapping, data = data, stat = stat,
>                        position = position, na.rm = na.rm, ...) +
>       geom_path(mapping = mapping, data = data, stat = stat,
>                 position = position, na.rm = na.rm, ...)
>   }
>}
>
>Sebastien
>
>On 10/23/2015 12:27 PM, Jeff Newmiller wrote:
>> Have you looked at the qplot function in the ggplot2 package?
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                        Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 23, 2015 3:12:41 PM GMT+02:00, sbihorel
><Sebastien.Bihorel at cognigencorp.com> wrote:
>>> Hi,
>>>
>>> Next adventure into my journey from lattice to ggplot: I would like
>to
>>> create a custom generic function that combines multiple existing
>geom's
>>>
>>> in order to reproduce what the lattice panel.xyplot function does
>based
>>>
>>> on the type argument (ie, plotting points only for type='p',
>plotting
>>> lines for type 'l', etc).
>>>
>>> My current naive attempt is:
>>>
>>> library(lattice)
>>> library(ggplot2)
>>>
>>> geom_xyplot <- function (mapping = NULL, data = NULL, stat =
>>> "identity",
>>>                           position = "identity", na.rm = FALSE, type
>=
>>> 'p', ...) {
>>>
>>>    if (any(type=='p')){
>>>      geom_point(mapping = mapping, data = data, stat = stat,
>>>                 position = position, na.rm = na.rm, ...)
>>>    }
>>>    if (any(type=='l')){
>>>      geom_path(mapping = mapping, data = data, stat = stat,
>>>                position = position, na.rm = na.rm, ...)
>>>    }
>>>    if (any(type%in%c('b','o'))){
>>>      geom_point(mapping = mapping, data = data, stat = stat,
>>>                 position = position, na.rm = na.rm, ...) +
>>>        geom_path(mapping = mapping, data = data, stat = stat,
>>>                  position = position, na.rm = na.rm, ...)
>>>    }
>>> }
>>>
>>> data <- data.frame(x = rep(1:4, each = 25),
>>>                     y = rep(1:25, times = 4),
>>>                     g = rep(1:4, each = 25))
>>> data$x <- data$x + 0.005*(data$y)^2-0.1*data$y+1
>>>
>>> ggplot(data2, aes(x, y, group = g, colour = factor(g))) +
>>> geom_xyplot(type = 'l')
>>>
>>> I get:
>>>> Error: No layers in plot
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Oct 24 13:35:51 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 24 Oct 2015 07:35:51 -0400
Subject: [R] JSONlite import problem
In-Reply-To: <562B04FF.6010907@nic.fi>
References: <562A8E03.8040304@nic.fi> <562A8FF1.1050806@gmail.com>
	<562B04FF.6010907@nic.fi>
Message-ID: <562B6D17.4010906@gmail.com>

On 24/10/2015 12:11 AM, K. Elo wrote:
> Hi!
> 
> You can download the example file with this link:
> https://www.dropbox.com/s/tlf1gkym6d83log/example.json?dl=0
> 
> BTW, I have used a JSON validator and the problem seems to related to 
> wrong/missing EOF.
> 
> --- snip ---
> Error: Parse error on line 1:
> ...:"1436705823768"} {"created_at":"Sun J
> ---------------------^
> Expecting 'EOF', '}', ',', ']', got '{'
> --- snip ---
> 
> However, editing the file with a text editor to create "proper" EOF 
> doesn't help.

The problem is that you have valid-looking JSON objects on each odd
numbered line, separated by single blank lines.  The parser expects an
EOF at the end of the first object, but instead it found a blank line
and another object.

So just use readLines to read all the lines, and individually convert
the ones that are not blank.

Duncan Murdoch

> 
> -Kimmo-
> 
> 23.10.2015, 22:52, Duncan Murdoch wrote:
>> It looks like it's the same sort of problem as in that stackoverflow
>> posting:  what's in your file is not valid Javascript, so it's not valid
>> JSON.  It's probably multiple JSON objects without proper separators;
>> you need to do the separating yourself.
>>
>> BTW, your attachment failed; only some file types are allowed.  You
>> should probably put the file online somewhere and post the URL.
>>
>> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From oma.gonzales at gmail.com  Sat Oct 24 23:26:22 2015
From: oma.gonzales at gmail.com (=?UTF-8?B?T21hciBBbmRyw6kgR29uesOhbGVzIETDrWF6?=)
Date: Sat, 24 Oct 2015 16:26:22 -0500
Subject: [R] regex not working for some entries in for loop
Message-ID: <CAM-xyZhnaDRLDp7S=Ln-9dNs=4jdZjRdUh2aKkHkpJLqwhrK0g@mail.gmail.com>

I'm using some regex in a for loop to check for some values in column
"source", and put a result in column "fuente".


I need some advice on this topics:

-Making the regex parts work, I've tasted them in regexpal.com and they
work, but not in R.
-Making the code (for loop) more efficient, more clear to read.

Cases:      - "buy-cheap-online.info", regex: ".*buy.*".
                - "guardlink.org", regex:  ".*guardlink.*". It is not
detected neither.
                - "googleads.g.doubleclick.net", regex:
"googleads[.]g[.]doubleclick[.]net".


The data is a txt attached in this email.


R Code:

for (i in 1:nrow(sesionesxfuente)) {

        organic <- grepl("start.iminent.com|websearch.com|
                         crawler.com|allmyweb.com",sesionesxfuente$source[i],
ignore.case = T)
        adwords <- grepl("cpc|ccp",sesionesxfuente$source[i], ignore.case =
T)
        referral <- grepl(".*google\\.com\\.pe.*|.*google\\.co\\.ve\\.*|
                          .*google\\.com\\.br.*|.*google\\.com\\.bo\\.*|
                          .*google\\.com\\.ar.*|.*google\\.com.*",
sesionesxfuente$source[i],
                          ignore.case = T)
        spam <- grepl("site.*|.*event.*|.*free.*|.*theguardlan.*|
                      .*guardlink.*|.*torture.*|.*forum.*|
                      .*buy.*|.*share.*|.*buttons.*|
                      .*pyme\\.lavoztx\\.com\\.*|.*amezon.*|
                      computrabajo.com.pe|.*porn.*|quality",
                      sesionesxfuente$source[i],
                      ignore.case = T)

        adsense <- grepl("tpc.googlesyndication.com|

 googleads[.]g[.]doubleclick[.]net",sesionesxfuente$source[i], ignore.case
= T)


        redes.sociales <- grepl("facebook.com|
                         twitter.com",sesionesxfuente$source[i],
ignore.case = T)



        if (sesionesxfuente$source[i] == "(direct)") {
                sesionesxfuente$fuente[i] <- "directo"
        }

        else if (sesionesxfuente$medium[i] == "organic" |
                 organic) {
                sesionesxfuente$fuente[i] <- "organico"
        }

        else if (sesionesxfuente$source[i] == "google"
                 & adwords) {

                sesionesxfuente$fuente[i] <- "adwords"
        }

        else if (referral) {

                sesionesxfuente$fuente[i] <- "referencias"
        }

        else if (adsense) {

                sesionesxfuente$fuente[i] <- "adsense"
        }

        else if (redes.sociales) {

                sesionesxfuente$fuente[i] <- "redes sociales"
        }


        else if (spam) {

                sesionesxfuente$fuente[i] <- "spam"
        }



        else {
                sesionesxfuente$fuente[i] <- sesionesxfuente$fuente[i]
        }
}

Thanks.
-------------- next part --------------
structure(list(date = structure(c(1404450000, 1404536400, 1404709200, 
1404795600, 1404882000, 1404882000, 1405054800, 1405141200, 1405227600, 
1405659600, 1405659600, 1405832400, 1406091600, 1406178000, 1406264400, 
1406350800, 1406696400, 1407301200, 1408251600, 1408424400, 1409029200, 
1409029200, 1409115600, 1409202000, 1410152400, 1410757200, 1411016400, 
1411275600, 1411362000, 1411448400, 1411621200, 1411621200, 1411794000, 
1411880400, 1411966800, 1411966800, 1411966800, 1412053200, 1412053200, 
1412053200, 1412139600, 1412312400, 1412398800, 1412398800, 1412485200, 
1412571600, 1412571600, 1412658000, 1412658000, 1412744400, 1412830800, 
1412830800, 1413003600, 1413176400, 1413262800, 1413262800, 1413349200, 
1413349200, 1413435600, 1413522000, 1413522000, 1413608400, 1413867600, 
1414040400, 1414126800, 1414213200, 1414213200, 1414386000, 1414472400, 
1414472400, 1414645200, 1414645200, 1414731600, 1414818000, 1414818000, 
1414990800, 1415163600, 1415250000, 1415941200, 1416286800, 1416373200, 
1416718800, 1417237200, 1417496400, 1417582800, 1417669200, 1418101200, 
1418101200, 1418187600, 1418360400, 1418360400, 1418360400, 1418533200, 
1418619600, 1418706000, 1418792400, 1418965200, 1419138000, 1419310800, 
1419397200, 1419483600, 1419570000, 1419656400, 1419742800, 1419829200, 
1419829200, 1419829200, 1419915600, 1420002000, 1420002000, 1420088400, 
1420088400, 1420088400, 1420174800, 1420174800, 1420261200, 1420347600, 
1420434000, 1420434000, 1420520400, 1420606800, 1420693200, 1420779600, 
1420866000, 1420866000, 1421038800, 1421125200, 1421211600, 1421298000, 
1421298000, 1421384400, 1421557200, 1421643600, 1421730000, 1421816400, 
1421902800, 1421902800, 1422248400, 1422248400, 1422248400, 1422334800, 
1422334800, 1422507600, 1422507600, 1422853200, 1422939600, 1422939600, 
1423285200, 1423717200, 1423803600, 1423890000, 1424062800, 1424062800, 
1424149200, 1424408400, 1424667600, 1424754000, 1424754000, 1424926800, 
1425099600, 1425272400, 1425358800, 1425445200, 1425618000, 1425618000, 
1425704400, 1425790800, 1425877200, 1425963600, 1426050000, 1426136400, 
1426222800, 1426309200, 1426395600, 1426395600, 1426395600, 1426482000, 
1426568400, 1426568400, 1426654800, 1426741200, 1426741200, 1426914000, 
1427173200, 1427173200, 1427173200, 1427173200, 1427346000, 1427346000, 
1427432400, 1427691600, 1427691600, 1427778000, 1427778000, 1427864400, 
1427864400, 1427950800, 1427950800, 1427950800, 1428123600, 1428296400, 
1428296400, 1428382800, 1428382800, 1428382800, 1428469200, 1428555600, 
1428642000, 1428728400, 1428728400, 1428728400, 1428987600, 1429074000, 
1429074000, 1429160400, 1429160400, 1429160400, 1429246800, 1429246800, 
1429246800, 1429246800, 1429333200, 1429333200, 1429419600, 1429506000, 
1429506000, 1429592400, 1429592400, 1429592400, 1429592400, 1429592400, 
1429765200, 1429765200, 1429851600, 1429938000, 1429938000, 1430024400, 
1430024400, 1430110800, 1430197200, 1430197200, 1430197200, 1430197200, 
1430197200, 1430283600, 1430283600, 1430370000, 1430370000, 1430456400, 
1430456400, 1430456400, 1430456400, 1430542800, 1430629200, 1430715600, 
1430715600, 1430715600, 1430715600, 1430802000, 1430802000, 1430802000, 
1430802000, 1430888400, 1430888400, 1430888400, 1430974800, 1430974800, 
1430974800, 1430974800, 1431061200, 1431061200, 1431061200, 1431061200, 
1431147600, 1431147600, 1431147600, 1431234000, 1431234000, 1431234000, 
1431234000, 1431320400, 1431320400, 1431320400, 1431320400, 1431406800, 
1431406800, 1431406800, 1431406800, 1431406800, 1431493200, 1431493200, 
1431493200, 1431579600, 1431579600, 1431579600, 1431579600, 1431579600, 
1431666000, 1431666000, 1431752400, 1431752400, 1431752400, 1431752400, 
1431838800, 1431838800, 1431838800, 1431838800, 1431838800, 1431925200, 
1431925200, 1432011600, 1432011600, 1432011600, 1432098000, 1432098000, 
1432098000, 1432184400, 1432184400, 1432184400, 1432270800, 1432530000, 
1432616400, 1432616400, 1432616400, 1432702800, 1432702800, 1432789200, 
1432875600, 1432875600, 1432962000, 1433134800, 1433221200, 1433307600, 
1433307600, 1433394000, 1433480400, 1433566800, 1433653200, 1433739600, 
1433826000, 1433912400, 1433912400, 1433998800, 1433998800, 1433998800, 
1434085200, 1434085200, 1434085200, 1434171600, 1434171600, 1434171600, 
1434258000, 1434258000, 1434344400, 1434430800, 1434430800, 1434517200, 
1434517200, 1434603600, 1434603600, 1434690000, 1434690000, 1434690000, 
1434776400, 1434776400, 1434776400, 1434776400, 1434862800, 1434949200, 
1435035600, 1435035600, 1435035600, 1435122000, 1435122000, 1435122000, 
1435122000, 1435208400, 1435208400, 1435294800, 1435381200, 1435381200, 
1435467600, 1435554000, 1435554000, 1435554000, 1435640400, 1435640400, 
1435726800, 1435726800, 1435726800, 1435813200, 1435813200, 1435899600, 
1435986000, 1435986000, 1436072400, 1436072400, 1436072400, 1436158800, 
1436158800, 1436158800, 1436245200, 1436245200, 1436245200, 1436245200, 
1436331600, 1436331600, 1436331600, 1436331600, 1436331600, 1436418000, 
1436418000, 1436504400, 1436590800, 1436590800, 1436677200, 1436677200, 
1436677200, 1436763600, 1436763600, 1436763600, 1436850000, 1436850000, 
1436850000, 1436936400, 1437022800, 1437022800, 1437022800, 1437022800, 
1437109200, 1437109200, 1437109200, 1437195600, 1437195600, 1437282000, 
1437282000, 1437282000, 1437368400, 1437368400, 1437454800, 1437454800, 
1437541200, 1437541200, 1437541200, 1437627600, 1437627600, 1437627600, 
1437714000, 1437714000, 1437714000, 1437714000, 1437800400, 1437800400, 
1437800400, 1437800400, 1437800400, 1437886800, 1437973200, 1437973200, 
1438059600, 1438059600, 1438059600, 1438059600, 1438232400, 1438318800, 
1438405200, 1438405200, 1438491600, 1438578000, 1438578000, 1438664400, 
1438664400, 1438664400, 1438750800, 1438750800, 1438750800, 1438750800, 
1438837200, 1438923600, 1438923600, 1439010000, 1439096400, 1439096400, 
1439182800, 1439182800, 1439269200, 1439269200, 1439355600, 1439355600, 
1439355600, 1439442000, 1439442000, 1439442000, 1439528400, 1439528400, 
1439614800, 1439614800, 1439701200, 1439787600, 1439787600, 1439787600, 
1439874000, 1439960400, 1439960400, 1440046800, 1440046800, 1440133200, 
1440133200, 1440219600, 1440306000, 1440392400, 1440478800, 1440565200, 
1440565200, 1440651600, 1440651600, 1440651600, 1440738000, 1440824400, 
1440910800, 1440910800, 1440997200, 1441083600, 1441083600, 1441083600, 
1441170000, 1441170000, 1441256400, 1441256400, 1441256400, 1441342800, 
1441342800, 1441429200, 1441429200, 1441429200, 1441429200, 1441515600, 
1441515600, 1441515600, 1441602000, 1441688400, 1441688400, 1441688400, 
1441774800, 1441774800, 1441861200, 1441861200, 1441947600, 1441947600, 
1442034000, 1442120400, 1442206800, 1442293200, 1442379600, 1442379600, 
1442466000, 1442466000, 1442552400, 1442552400, 1442638800, 1442725200, 
1442811600, 1442811600, 1442898000, 1442898000, 1442898000, 1442984400, 
1443070800, 1443070800, 1443157200, 1443157200, 1443243600, 1443243600, 
1443330000, 1443330000, 1443330000, 1443416400, 1443502800, 1443502800, 
1443502800, 1443502800, 1443589200, 1443589200, 1443675600, 1443762000, 
1443848400, 1443848400, 1443934800, 1443934800, 1444021200, 1444021200, 
1444107600, 1444194000, 1444280400, 1444280400, 1444366800, 1444453200, 
1444539600, 1444539600, 1444626000, 1444712400, 1444712400, 1444798800, 
1444798800, 1444885200, 1444971600, 1445058000, 1445144400, 1445230800, 
1445317200, 1445317200, 1445403600, 1445490000, 1445490000, 1445576400, 
1445662800, 1445662800), class = c("POSIXct", "POSIXt"), tzone = "America/Lima"), 
    source = c("(direct)", "(direct)", "(direct)", "(direct)", 
    "(direct)", "google", "(direct)", "(direct)", "(direct)", 
    "(direct)", "google", "bing", "(direct)", "(direct)", "(direct)", 
    "(direct)", "(direct)", "(direct)", "(direct)", "(direct)", 
    "(direct)", "google.com.pe", "google", "google.com.ar", "(direct)", 
    "(direct)", "(direct)", "(direct)", "(direct)", "(direct)", 
    "(direct)", "google", "google", "yahoo", "(direct)", "google", 
    "start.iminent.com", "(direct)", "computrabajo.com.pe", "google", 
    "(direct)", "(direct)", "(direct)", "google", "(direct)", 
    "(direct)", "google", "(direct)", "google", "(direct)", "(direct)", 
    "google", "(direct)", "(direct)", "(direct)", "google", "(direct)", 
    "google", "google", "(direct)", "google", "(direct)", "google.com.pe", 
    "(direct)", "(direct)", "(direct)", "google", "google", "(direct)", 
    "google", "(direct)", "google", "google", "(direct)", "google", 
    "google", "google", "google", "google", "google", "google", 
    "(direct)", "google", "(direct)", "google", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "google", "google", "(direct)", 
    "forum.topic52266738.darodar.com", "google", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "google", "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "(direct)", "forum.topic52266738.darodar.com", "google", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "google", "(direct)", "forum.topic52266738.darodar.com", 
    "google", "forum.topic52266738.darodar.com", "google", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "(direct)", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "forum.topic52266738.darodar.com", "forum.topic52266738.darodar.com", 
    "(direct)", "forum.topic52266738.darodar.com", "google", 
    "google", "google", "forum.topic52266738.darodar.com", "google", 
    "forum.topic52266738.darodar.com", "(direct)", "google", 
    "google", "(direct)", "(direct)", "google", "(direct)", "google", 
    "yahoo", "forum.topic52266738.darodar.com", "google", "(direct)", 
    "google", "google", "google", "google.com.pe", "google", 
    "google", "google", "(direct)", "google", "localhost:8080", 
    "(direct)", "google", "google", "(direct)", "google", "(direct)", 
    "google", "google", "google", "google", "(direct)", "google", 
    "google.com.ar", "google", "google", "google", "google", 
    "google", "google", "google", "forum.topic52266738.darodar.com", 
    "google", "simple-share-buttons.com", "(direct)", "(direct)", 
    "google", "site38.simple-share-buttons.com", "google", "site40.simple-share-buttons.com", 
    "(direct)", "(direct)", "google", "simple-share-buttons.com", 
    "site17.simple-share-buttons.com", "editors.choice52266738.hulfingtonpost.com", 
    "site12.simple-share-buttons.com", "google", "google", "simple-share-buttons.com", 
    "(direct)", "site20.simple-share-buttons.com", "google", 
    "site33.simple-share-buttons.com", "google", "simple-share-buttons.com", 
    "site30.simple-share-buttons.com", "google", "(direct)", 
    "google", "(direct)", "google", "yahoo", "google", "google", 
    "google", "(direct)", "google", "googlsucks.com", "www.Get-Free-Traffic-Now.com", 
    "buy-cheap-online.info", "google", "(direct)", "depositfiles-porn.ga", 
    "google", "(direct)", "google", "torture.ml", "www.Get-Free-Traffic-Now.com", 
    "buy-cheap-online.info", "torture.ml", "torture.ml", "free-share-buttons.com", 
    "torture.ml", "(direct)", "free-share-buttons.com", "google", 
    "theguardlan.com", "www.Get-Free-Traffic-Now.com", "google", 
    "www.Get-Free-Traffic-Now.com", "free-share-buttons.com", 
    "free-share-buttons.com", "www.Get-Free-Traffic-Now.com", 
    "free-share-buttons.com", "www.Get-Free-Traffic-Now.com", 
    "buy-cheap-online.info", "(direct)", "buy-cheap-online.info", 
    "free-share-buttons.com", "torture.ml", "www.Get-Free-Traffic-Now.com", 
    "google", "www.Get-Free-Traffic-Now.com", "(direct)", "site3.free-share-buttons.com", 
    "(direct)", "google.com.br", "site4.free-share-buttons.com", 
    "www.Get-Free-Traffic-Now.com", "torture.ml", "www.Get-Free-Traffic-Now.com", 
    "(direct)", "google", "site3.free-share-buttons.com", "site4.free-share-buttons.com", 
    "(direct)", "google", "site4.free-share-buttons.com", "www.event-tracking.com", 
    "(direct)", "site3.free-share-buttons.com", "www.event-tracking.com", 
    "(direct)", "google", "site4.free-share-buttons.com", "www.Get-Free-Traffic-Now.com", 
    "(direct)", "guardlink.org", "site3.free-share-buttons.com", 
    "www.event-tracking.com", "(direct)", "google", "www.event-tracking.com", 
    "(direct)", "site4.free-share-buttons.com", "site6.free-share-buttons.com", 
    "www.event-tracking.com", "(direct)", "google", "site6.free-share-buttons.com", 
    "www.event-tracking.com", "(direct)", "google", "site5.free-share-buttons.com", 
    "site6.free-share-buttons.com", "www.event-tracking.com", 
    "(direct)", "free-social-buttons.com", "google", "(direct)", 
    "free-social-buttons.com", "google", "www.Get-Free-Traffic-Now.com", 
    "www.event-tracking.com", "(direct)", "www.event-tracking.com", 
    "(direct)", "free-social-buttons.com", "google", "www.Get-Free-Traffic-Now.com", 
    "(direct)", "free-social-buttons.com", "google", "guardlink.org", 
    "www.event-tracking.com", "www.Get-Free-Traffic-Now.com", 
    "www.event-tracking.com", "(direct)", "free-social-buttons.com", 
    "www.Get-Free-Traffic-Now.com", "(direct)", "free-social-buttons.com", 
    "www.event-tracking.com", "(direct)", "free-social-buttons.com", 
    "google", "www.event-tracking.com", "google", "(direct)", 
    "google", "www.event-tracking.com", "google", "www.event-tracking.com", 
    "google", "(direct)", "www.event-tracking.com", "google", 
    "www.event-tracking.com", "guardlink.org", "google", "www.event-tracking.com", 
    "www.event-tracking.com", "google", "google", "google", "google", 
    "google", "(direct)", "google", "google", "lima-lima.olx.com.pe", 
    "www.event-tracking.com", "google", "lima.quebarato.com.pe", 
    "www.event-tracking.com", "google", "google.com.ar", "www.event-tracking.com", 
    "google", "yahoo", "google", "(direct)", "google", "google", 
    "www.event-tracking.com", "(direct)", "google", "(direct)", 
    "google", "www.event-tracking.com", "(direct)", "google", 
    "google.com", "www.event-tracking.com", "google", "google", 
    "(direct)", "google", "google.com", "google", "google.co.ve", 
    "google.com", "www.event-tracking.com", "google", "www.event-tracking.com", 
    "google", "google", "www.event-tracking.com", "(direct)", 
    "google", "googleads.g.doubleclick.net", "www.event-tracking.com", 
    "(direct)", "google", "gg.net.ru", "google", "www.event-tracking.com", 
    "google", "www.event-tracking.com", "(direct)", "google", 
    "www.event-tracking.com", "(direct)", "google", "www.event-tracking.com", 
    "(direct)", "google", "www.event-tracking.com", "(direct)", 
    "google", "google.com", "www.event-tracking.com", "google", 
    "google.co.ve", "google.com", "google.com.bo", "www.event-tracking.com", 
    "(direct)", "google", "google", "google", "www.event-tracking.com", 
    "google", "tpc.googlesyndication.com", "www.event-tracking.com", 
    "google", "google.com", "www.event-tracking.com", "(direct)", 
    "google", "google.com", "google", "google", "openurls.com.cn", 
    "tradesou.com", "www.event-tracking.com", "(direct)", "google", 
    "google.com", "(direct)", "google", "(direct)", "google", 
    "www.event-tracking.com", "google", "www.event-tracking.com", 
    "(direct)", "google", "(direct)", "google", "www.event-tracking.com", 
    "(direct)", "google", "www.event-tracking.com", "(direct)", 
    "google", "google.com", "www.event-tracking.com", "(direct)", 
    "erot.co", "google", "quirktools.com", "www.event-tracking.com", 
    "google", "google", "www.event-tracking.com", "(direct)", 
    "google", "pyme.lavoztx.com", "www.event-tracking.com", "google", 
    "google", "(direct)", "google", "google", "(direct)", "google", 
    "(direct)", "chinese-amezon.com", "google", "(direct)", "google", 
    "google.com", "googleads.g.doubleclick.net", "google", "(direct)", 
    "google", "google", "(direct)", "google", "(direct)", "google", 
    "(direct)", "google", "(direct)", "google", "google.com", 
    "(direct)", "google", "hongfanji.com", "(direct)", "google", 
    "(direct)", "google", "google", "(direct)", "ehowenespanol.com", 
    "google", "google", "(direct)", "google", "(direct)", "google", 
    "(direct)", "google", "google", "google", "google", "google", 
    "google", "google.com.mx", "(direct)", "google", "googleads.g.doubleclick.net", 
    "google", "google", "(direct)", "google", "google", "(direct)", 
    "google", "qualitymarketzone.com", "google", "qualitymarketzone.com", 
    "(direct)", "google", "qualitymarketzone.com", "google", 
    "qualitymarketzone.com", "(direct)", "google", "google.com", 
    "qualitymarketzone.com", "google", "googleads.g.doubleclick.net", 
    "qualitymarketzone.com", "google", "(direct)", "google", 
    "qualitymarketzone.com", "bing", "google", "(direct)", "google", 
    "(direct)", "google", "google", "google", "google", "google", 
    "google", "googleads.g.doubleclick.net", "(direct)", "google", 
    "(direct)", "google", "google", "google", "(direct)", "google", 
    "(direct)", "google", "google.com", "google", "google", "rednise.com", 
    "(direct)", "google", "(direct)", "google", "(direct)", "google", 
    "google.com", "google", "(direct)", "facebook.com", "google", 
    "google.com", "(direct)", "google", "google", "google", "(direct)", 
    "google", "(direct)", "google", "(direct)", "google", "google", 
    "google", "(direct)", "google", "google", "google", "(direct)", 
    "google", "google", "(direct)", "google", "google", "yahoo", 
    "google", "google", "google", "google", "google", "(direct)", 
    "google", "google", "(direct)", "google", "google", "facebook.com", 
    "google"), medium = c("(none)", "(none)", "(none)", "(none)", 
    "(none)", "organic", "(none)", "(none)", "(none)", "(none)", 
    "organic", "organic", "(none)", "(none)", "(none)", "(none)", 
    "(none)", "(none)", "(none)", "(none)", "(none)", "referral", 
    "organic", "referral", "(none)", "(none)", "(none)", "(none)", 
    "(none)", "(none)", "(none)", "organic", "organic", "organic", 
    "(none)", "organic", "referral", "(none)", "referral", "organic", 
    "(none)", "(none)", "(none)", "organic", "(none)", "(none)", 
    "organic", "(none)", "organic", "(none)", "(none)", "organic", 
    "(none)", "(none)", "(none)", "organic", "(none)", "organic", 
    "organic", "(none)", "organic", "(none)", "referral", "(none)", 
    "(none)", "(none)", "organic", "organic", "(none)", "organic", 
    "(none)", "organic", "organic", "(none)", "organic", "organic", 
    "organic", "organic", "organic", "organic", "organic", "(none)", 
    "organic", "(none)", "organic", "referral", "referral", "organic", 
    "organic", "(none)", "referral", "organic", "referral", "referral", 
    "referral", "organic", "referral", "referral", "referral", 
    "referral", "referral", "referral", "referral", "referral", 
    "(none)", "referral", "organic", "referral", "referral", 
    "organic", "(none)", "referral", "organic", "referral", "organic", 
    "referral", "referral", "(none)", "referral", "referral", 
    "referral", "referral", "referral", "(none)", "referral", 
    "organic", "organic", "organic", "referral", "organic", "referral", 
    "(none)", "organic", "organic", "(none)", "(none)", "organic", 
    "(none)", "organic", "organic", "referral", "organic", "(none)", 
    "organic", "organic", "organic", "referral", "organic", "organic", 
    "organic", "(none)", "organic", "referral", "(none)", "organic", 
    "organic", "(none)", "organic", "(none)", "organic", "organic", 
    "organic", "organic", "(none)", "organic", "referral", "organic", 
    "organic", "organic", "organic", "organic", "organic", "organic", 
    "referral", "organic", "referral", "(none)", "(none)", "organic", 
    "referral", "organic", "referral", "(none)", "(none)", "organic", 
    "referral", "referral", "referral", "referral", "organic", 
    "organic", "referral", "(none)", "referral", "organic", "referral", 
    "organic", "referral", "referral", "organic", "(none)", "organic", 
    "(none)", "organic", "organic", "organic", "organic", "organic", 
    "(none)", "organic", "referral", "referral", "referral", 
    "organic", "(none)", "referral", "organic", "(none)", "organic", 
    "referral", "referral", "referral", "referral", "referral", 
    "referral", "referral", "(none)", "referral", "organic", 
    "referral", "referral", "organic", "referral", "referral", 
    "referral", "referral", "referral", "referral", "referral", 
    "(none)", "referral", "referral", "referral", "referral", 
    "organic", "referral", "(none)", "referral", "(none)", "referral", 
    "referral", "referral", "referral", "referral", "(none)", 
    "organic", "referral", "referral", "(none)", "organic", "referral", 
    "referral", "(none)", "referral", "referral", "(none)", "organic", 
    "referral", "referral", "(none)", "referral", "referral", 
    "referral", "(none)", "organic", "referral", "(none)", "referral", 
    "referral", "referral", "(none)", "organic", "referral", 
    "referral", "(none)", "organic", "referral", "referral", 
    "referral", "(none)", "referral", "organic", "(none)", "referral", 
    "organic", "referral", "referral", "(none)", "referral", 
    "(none)", "referral", "organic", "referral", "(none)", "referral", 
    "organic", "referral", "referral", "referral", "referral", 
    "(none)", "referral", "referral", "(none)", "referral", "referral", 
    "(none)", "referral", "organic", "referral", "organic", "(none)", 
    "organic", "referral", "organic", "referral", "organic", 
    "(none)", "referral", "organic", "referral", "referral", 
    "organic", "referral", "referral", "organic", "organic", 
    "organic", "organic", "organic", "(none)", "organic", "organic", 
    "referral", "referral", "organic", "referral", "referral", 
    "organic", "referral", "referral", "organic", "organic", 
    "organic", "(none)", "organic", "organic", "referral", "(none)", 
    "organic", "(none)", "organic", "referral", "(none)", "organic", 
    "referral", "referral", "organic", "organic", "(none)", "organic", 
    "referral", "organic", "referral", "referral", "referral", 
    "organic", "referral", "organic", "organic", "referral", 
    "(none)", "organic", "referral", "referral", "(none)", "organic", 
    "referral", "organic", "referral", "organic", "referral", 
    "(none)", "organic", "referral", "(none)", "organic", "referral", 
    "(none)", "organic", "referral", "(none)", "organic", "referral", 
    "referral", "organic", "referral", "referral", "referral", 
    "referral", "(none)", "organic", "organic", "organic", "referral", 
    "organic", "referral", "referral", "organic", "referral", 
    "referral", "(none)", "organic", "referral", "organic", "organic", 
    "referral", "referral", "referral", "(none)", "organic", 
    "referral", "(none)", "organic", "(none)", "organic", "referral", 
    "organic", "referral", "(none)", "organic", "(none)", "organic", 
    "referral", "(none)", "organic", "referral", "(none)", "organic", 
    "referral", "referral", "(none)", "referral", "organic", 
    "referral", "referral", "organic", "organic", "referral", 
    "(none)", "organic", "referral", "referral", "organic", "organic", 
    "(none)", "organic", "organic", "(none)", "organic", "(none)", 
    "referral", "organic", "(none)", "organic", "referral", "referral", 
    "organic", "(none)", "organic", "organic", "(none)", "organic", 
    "(none)", "organic", "(none)", "organic", "(none)", "organic", 
    "referral", "(none)", "organic", "referral", "(none)", "organic", 
    "(none)", "organic", "organic", "(none)", "referral", "organic", 
    "organic", "(none)", "organic", "(none)", "organic", "(none)", 
    "organic", "organic", "organic", "organic", "organic", "organic", 
    "referral", "(none)", "organic", "referral", "organic", "organic", 
    "(none)", "organic", "organic", "(none)", "organic", "referral", 
    "organic", "referral", "(none)", "organic", "referral", "organic", 
    "referral", "(none)", "organic", "referral", "referral", 
    "organic", "referral", "referral", "organic", "(none)", "organic", 
    "referral", "organic", "organic", "(none)", "organic", "(none)", 
    "organic", "organic", "organic", "organic", "organic", "organic", 
    "referral", "(none)", "organic", "(none)", "organic", "organic", 
    "organic", "(none)", "organic", "(none)", "organic", "referral", 
    "organic", "organic", "referral", "(none)", "organic", "(none)", 
    "organic", "(none)", "organic", "referral", "organic", "(none)", 
    "referral", "organic", "referral", "(none)", "organic", "organic", 
    "organic", "(none)", "organic", "(none)", "organic", "(none)", 
    "organic", "organic", "organic", "(none)", "organic", "organic", 
    "organic", "(none)", "organic", "organic", "(none)", "organic", 
    "organic", "organic", "organic", "organic", "organic", "organic", 
    "organic", "(none)", "organic", "organic", "(none)", "organic", 
    "organic", "referral", "organic"), users = c(3L, 1L, 1L, 
    2L, 4L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 14L, 1L, 1L, 7L, 1L, 2L, 6L, 2L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 5L, 2L, 2L, 2L, 1L, 1L, 
    1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 
    1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 1L, 3L, 1L, 1L, 3L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 
    2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 43L, 1L, 1L, 2L, 38L, 2L, 
    40L, 1L, 2L, 1L, 16L, 17L, 1L, 12L, 2L, 1L, 35L, 1L, 20L, 
    1L, 33L, 1L, 27L, 30L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 
    1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 4L, 
    2L, 20L, 1L, 2L, 18L, 2L, 1L, 1L, 1L, 1L, 6L, 74L, 1L, 7L, 
    1L, 1L, 21L, 5L, 19L, 1L, 1L, 2L, 1L, 4L, 8L, 8L, 1L, 3L, 
    1L, 1L, 2L, 23L, 2L, 9L, 9L, 9L, 1L, 16L, 1L, 8L, 6L, 2L, 
    14L, 2L, 12L, 1L, 16L, 3L, 14L, 2L, 1L, 2L, 1L, 18L, 12L, 
    1L, 1L, 17L, 2L, 3L, 1L, 41L, 2L, 3L, 2L, 2L, 24L, 2L, 1L, 
    42L, 6L, 2L, 1L, 1L, 2L, 1L, 25L, 3L, 1L, 1L, 24L, 4L, 1L, 
    140L, 1L, 2L, 2L, 24L, 3L, 1L, 62L, 7L, 1L, 8L, 2L, 2L, 1L, 
    1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 14L, 1L, 1L, 
    1L, 1L, 1L, 2L, 2L, 1L, 2L, 4L, 7L, 1L, 1L, 2L, 1L, 1L, 1L, 
    1L, 1L, 3L, 1L, 3L, 3L, 4L, 4L, 2L, 1L, 5L, 1L, 3L, 1L, 2L, 
    2L, 1L, 2L, 1L, 6L, 1L, 4L, 1L, 4L, 1L, 1L, 1L, 4L, 1L, 5L, 
    4L, 3L, 1L, 2L, 1L, 1L, 1L, 3L, 1L, 5L, 1L, 5L, 3L, 1L, 3L, 
    1L, 1L, 2L, 1L, 4L, 5L, 1L, 1L, 3L, 2L, 2L, 7L, 1L, 1L, 1L, 
    2L, 1L, 2L, 3L, 3L, 1L, 2L, 1L, 2L, 4L, 1L, 1L, 1L, 2L, 1L, 
    5L, 5L, 1L, 1L, 3L, 1L, 3L, 1L, 1L, 3L, 1L, 4L, 1L, 1L, 1L, 
    1L, 4L, 1L, 7L, 1L, 1L, 2L, 1L, 2L, 4L, 1L, 3L, 2L, 1L, 2L, 
    1L, 3L, 3L, 5L, 1L, 1L, 3L, 1L, 1L, 3L, 3L, 1L, 1L, 2L, 1L, 
    2L, 1L, 1L, 4L, 3L, 1L, 1L, 1L, 7L, 1L, 4L, 4L, 2L, 3L, 1L, 
    4L, 2L, 6L, 1L, 3L, 1L, 1L, 2L, 1L, 1L, 4L, 3L, 2L, 5L, 1L, 
    1L, 3L, 6L, 2L, 5L, 2L, 2L, 1L, 4L, 4L, 3L, 4L, 7L, 7L, 1L, 
    1L, 2L, 1L, 7L, 3L, 1L, 2L, 6L, 1L, 2L, 4L, 6L, 5L, 1L, 8L, 
    3L, 5L, 3L, 2L, 2L, 1L, 5L, 5L, 1L, 3L, 5L, 1L, 3L, 4L, 1L, 
    2L, 2L, 4L, 2L, 4L, 3L, 3L, 2L, 4L, 3L, 1L, 2L, 4L, 1L, 6L, 
    1L, 5L, 1L, 2L, 2L, 4L, 1L, 4L, 3L, 1L, 1L, 4L, 2L, 2L, 1L, 
    4L, 1L, 6L, 2L, 1L, 6L, 1L, 1L, 4L, 4L, 6L, 1L, 2L, 1L, 7L, 
    2L, 7L, 5L, 3L, 1L, 3L, 4L, 5L, 2L, 2L, 6L, 1L, 6L, 3L, 1L, 
    8L, 7L, 4L, 3L, 5L, 1L, 5L, 4L, 1L, 7L, 5L, 1L, 1L), sessions = c(9L, 
    2L, 1L, 2L, 4L, 4L, 13L, 8L, 2L, 1L, 2L, 1L, 1L, 1L, 5L, 
    2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 1L, 14L, 1L, 1L, 7L, 1L, 2L, 6L, 2L, 1L, 1L, 
    1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 3L, 2L, 6L, 2L, 2L, 
    2L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
    1L, 1L, 3L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 1L, 2L, 3L, 4L, 4L, 3L, 
    1L, 3L, 3L, 4L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 2L, 
    1L, 1L, 3L, 1L, 1L, 2L, 1L, 2L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 3L, 1L, 1L, 3L, 2L, 1L, 1L, 2L, 
    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 3L, 2L, 1L, 1L, 
    1L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 43L, 1L, 1L, 
    2L, 38L, 2L, 40L, 1L, 2L, 1L, 16L, 17L, 1L, 12L, 2L, 1L, 
    35L, 1L, 20L, 1L, 33L, 1L, 27L, 30L, 1L, 1L, 2L, 1L, 2L, 
    1L, 1L, 1L, 1L, 1L, 3L, 1L, 1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 
    2L, 1L, 1L, 4L, 2L, 20L, 1L, 2L, 18L, 2L, 1L, 1L, 1L, 1L, 
    6L, 74L, 1L, 7L, 1L, 1L, 21L, 5L, 19L, 1L, 1L, 2L, 1L, 4L, 
    8L, 8L, 1L, 3L, 1L, 1L, 2L, 23L, 2L, 9L, 9L, 9L, 1L, 16L, 
    1L, 8L, 6L, 2L, 14L, 2L, 12L, 1L, 16L, 3L, 14L, 2L, 1L, 2L, 
    1L, 18L, 12L, 1L, 1L, 21L, 4L, 3L, 1L, 41L, 2L, 3L, 2L, 2L, 
    24L, 2L, 1L, 42L, 6L, 2L, 1L, 1L, 2L, 1L, 25L, 3L, 1L, 1L, 
    24L, 4L, 1L, 140L, 1L, 2L, 2L, 24L, 3L, 1L, 62L, 7L, 1L, 
    8L, 2L, 3L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 1L, 
    14L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 1L, 2L, 4L, 7L, 1L, 1L, 
    2L, 1L, 1L, 1L, 1L, 1L, 3L, 1L, 3L, 4L, 4L, 4L, 2L, 1L, 5L, 
    1L, 4L, 1L, 2L, 3L, 1L, 2L, 2L, 6L, 1L, 4L, 1L, 5L, 1L, 2L, 
    1L, 4L, 1L, 5L, 4L, 3L, 1L, 2L, 1L, 1L, 1L, 3L, 1L, 5L, 1L, 
    6L, 3L, 1L, 3L, 1L, 2L, 4L, 1L, 4L, 5L, 1L, 1L, 3L, 2L, 2L, 
    7L, 1L, 1L, 1L, 2L, 1L, 2L, 3L, 3L, 1L, 2L, 1L, 2L, 4L, 1L, 
    1L, 1L, 2L, 1L, 5L, 5L, 2L, 1L, 3L, 1L, 3L, 2L, 1L, 3L, 1L, 
    4L, 1L, 1L, 1L, 1L, 4L, 1L, 7L, 1L, 1L, 2L, 1L, 2L, 5L, 1L, 
    3L, 2L, 1L, 2L, 1L, 3L, 3L, 5L, 1L, 1L, 4L, 1L, 1L, 3L, 3L, 
    1L, 1L, 2L, 1L, 2L, 1L, 1L, 4L, 3L, 1L, 1L, 1L, 7L, 1L, 5L, 
    4L, 3L, 3L, 1L, 5L, 2L, 6L, 1L, 4L, 1L, 1L, 2L, 1L, 1L, 4L, 
    3L, 2L, 5L, 1L, 1L, 4L, 6L, 2L, 5L, 2L, 2L, 1L, 4L, 4L, 3L, 
    4L, 8L, 8L, 1L, 1L, 2L, 1L, 7L, 3L, 1L, 2L, 6L, 1L, 2L, 4L, 
    6L, 5L, 1L, 9L, 3L, 5L, 3L, 2L, 2L, 1L, 5L, 5L, 1L, 3L, 5L, 
    1L, 4L, 4L, 1L, 2L, 2L, 4L, 2L, 5L, 3L, 4L, 3L, 4L, 3L, 1L, 
    2L, 4L, 1L, 6L, 1L, 7L, 1L, 3L, 2L, 4L, 1L, 4L, 3L, 1L, 1L, 
    6L, 2L, 3L, 1L, 4L, 1L, 6L, 3L, 1L, 6L, 1L, 1L, 5L, 5L, 6L, 
    1L, 2L, 1L, 8L, 2L, 10L, 5L, 3L, 1L, 4L, 4L, 5L, 2L, 2L, 
    8L, 1L, 7L, 3L, 1L, 8L, 8L, 4L, 4L, 5L, 1L, 8L, 4L, 1L, 8L, 
    5L, 1L, 1L), fuente = c("directo", "directo", "directo", 
    "directo", "directo", "organico", "directo", "directo", "directo", 
    "directo", "organico", "organico", "directo", "directo", 
    "directo", "directo", "directo", "directo", "directo", "directo", 
    "directo", "referencias", "organico", "referencias", "directo", 
    "directo", "directo", "directo", "directo", "directo", "directo", 
    "organico", "organico", "organico", "directo", "organico", 
    "organico", "directo", "spam", "organico", "directo", "directo", 
    "directo", "organico", "directo", "directo", "organico", 
    "directo", "organico", "directo", "directo", "organico", 
    "directo", "directo", "directo", "organico", "directo", "organico", 
    "organico", "directo", "organico", "directo", "referencias", 
    "directo", "directo", "directo", "organico", "organico", 
    "directo", "organico", "directo", "organico", "organico", 
    "directo", "organico", "organico", "organico", "organico", 
    "organico", "organico", "organico", "directo", "organico", 
    "directo", "organico", "spam", "spam", "organico", "organico", 
    "directo", "spam", "organico", "spam", "spam", "spam", "organico", 
    "spam", "spam", "spam", "spam", "spam", "spam", "spam", "spam", 
    "directo", "spam", "organico", "spam", "spam", "organico", 
    "directo", "spam", "organico", "spam", "organico", "spam", 
    "spam", "directo", "spam", "spam", "spam", "spam", "spam", 
    "directo", "spam", "organico", "organico", "organico", "spam", 
    "organico", "spam", "directo", "organico", "organico", "directo", 
    "directo", "organico", "directo", "organico", "organico", 
    "spam", "organico", "directo", "organico", "organico", "organico", 
    "referencias", "organico", "organico", "organico", "directo", 
    "organico", NA, "directo", "organico", "organico", "directo", 
    "organico", "directo", "organico", "organico", "organico", 
    "organico", "directo", "organico", "referencias", "organico", 
    "organico", "organico", "organico", "organico", "organico", 
    "organico", "spam", "organico", "spam", "directo", "directo", 
    "organico", "spam", "organico", "spam", "directo", "directo", 
    "organico", "spam", "spam", NA, "spam", "organico", "organico", 
    "spam", "directo", "spam", "organico", "spam", "organico", 
    "spam", "spam", "organico", "directo", "organico", "directo", 
    "organico", "organico", "organico", "organico", "organico", 
    "directo", "organico", NA, "spam", NA, "organico", "directo", 
    "spam", "organico", "directo", "organico", "spam", "spam", 
    NA, "spam", "spam", "spam", "spam", "directo", "spam", "organico", 
    "spam", "spam", "organico", "spam", "spam", "spam", "spam", 
    "spam", "spam", NA, "directo", NA, "spam", "spam", "spam", 
    "organico", "spam", "directo", "spam", "directo", "referencias", 
    "spam", "spam", "spam", "spam", "directo", "organico", "spam", 
    "spam", "directo", "organico", "spam", "spam", "directo", 
    "spam", "spam", "directo", "organico", "spam", "spam", "directo", 
    NA, "spam", "spam", "directo", "organico", "spam", "directo", 
    "spam", "spam", "spam", "directo", "organico", "spam", "spam", 
    "directo", "organico", "spam", "spam", "spam", "directo", 
    "spam", "organico", "directo", "spam", "organico", "spam", 
    "spam", "directo", "spam", "directo", "spam", "organico", 
    "spam", "directo", "spam", "organico", NA, "spam", "spam", 
    "spam", "directo", "spam", "spam", "directo", "spam", "spam", 
    "directo", "spam", "organico", "spam", "organico", "directo", 
    "organico", "spam", "organico", "spam", "organico", "directo", 
    "spam", "organico", "spam", NA, "organico", "spam", "spam", 
    "organico", "organico", "organico", "organico", "organico", 
    "directo", "organico", "organico", NA, "spam", "organico", 
    NA, "spam", "organico", "referencias", "spam", "organico", 
    "organico", "organico", "directo", "organico", "organico", 
    "spam", "directo", "organico", "directo", "organico", "spam", 
    "directo", "organico", "referencias", "spam", "organico", 
    "organico", "directo", "organico", "referencias", "organico", 
    "referencias", "referencias", "spam", "organico", "spam", 
    "organico", "organico", "spam", "directo", "organico", NA, 
    "spam", "directo", "organico", NA, "organico", "spam", "organico", 
    "spam", "directo", "organico", "spam", "directo", "organico", 
    "spam", "directo", "organico", "spam", "directo", "organico", 
    "referencias", "spam", "organico", "referencias", "referencias", 
    "referencias", "spam", "directo", "organico", "organico", 
    "organico", "spam", "organico", "adsense", "spam", "organico", 
    "referencias", "spam", "directo", "organico", "referencias", 
    "organico", "organico", NA, NA, "spam", "directo", "organico", 
    "referencias", "directo", "organico", "directo", "organico", 
    "spam", "organico", "spam", "directo", "organico", "directo", 
    "organico", "spam", "directo", "organico", "spam", "directo", 
    "organico", "referencias", "spam", "directo", NA, "organico", 
    NA, "spam", "organico", "organico", "spam", "directo", "organico", 
    NA, "spam", "organico", "organico", "directo", "organico", 
    "organico", "directo", "organico", "directo", "spam", "organico", 
    "directo", "organico", "referencias", NA, "organico", "directo", 
    "organico", "organico", "directo", "organico", "directo", 
    "organico", "directo", "organico", "directo", "organico", 
    "referencias", "directo", "organico", NA, "directo", "organico", 
    "directo", "organico", "organico", "directo", NA, "organico", 
    "organico", "directo", "organico", "directo", "organico", 
    "directo", "organico", "organico", "organico", "organico", 
    "organico", "organico", "referencias", "directo", "organico", 
    NA, "organico", "organico", "directo", "organico", "organico", 
    "directo", "organico", "spam", "organico", "spam", "directo", 
    "organico", "spam", "organico", "spam", "directo", "organico", 
    "referencias", "spam", "organico", NA, "spam", "organico", 
    "directo", "organico", "spam", "organico", "organico", "directo", 
    "organico", "directo", "organico", "organico", "organico", 
    "organico", "organico", "organico", NA, "directo", "organico", 
    "directo", "organico", "organico", "organico", "directo", 
    "organico", "directo", "organico", "referencias", "organico", 
    "organico", NA, "directo", "organico", "directo", "organico", 
    "directo", "organico", "referencias", "organico", "directo", 
    "redes sociales", "organico", "referencias", "directo", "organico", 
    "organico", "organico", "directo", "organico", "directo", 
    "organico", "directo", "organico", "organico", "organico", 
    "directo", "organico", "organico", "organico", "directo", 
    "organico", "organico", "directo", "organico", "organico", 
    "organico", "organico", "organico", "organico", "organico", 
    "organico", "directo", "organico", "organico", "directo", 
    "organico", "organico", "redes sociales", "organico")), .Names = c("date", 
"source", "medium", "users", "sessions", "fuente"), row.names = c(NA, 
-617L), profile.info = structure(list(profile.id = "88090999", 
    account.id = "52266738", webproperty.id = "UA-52266738-1", 
    internal.webproperty.id = "84690154", profile.name = "Chayan Web Official", 
    table.id = "ga:88090999"), .Names = c("profile.id", "account.id", 
"webproperty.id", "internal.webproperty.id", "profile.name", 
"table.id")), query = structure(list(start.date = "2014-07-04", 
    end.date = "today", profile.id = "ga:88090999", dimensions = "ga:date,ga:source,ga:medium", 
    metrics = "ga:users,ga:sessions", start.index = 1L, max.results = 10000L), .Names = c("start.date", 
"end.date", "profile.id", "dimensions", "metrics", "start.index", 
"max.results")), class = "data.frame")

From r.turner at auckland.ac.nz  Sun Oct 25 00:07:46 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Oct 2015 11:07:46 +1300
Subject: [R] [FORGED] Re:  How to correct documentation?
In-Reply-To: <CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
Message-ID: <562C0132.8010802@auckland.ac.nz>

On 24/10/15 21:10, Jim Lemon wrote:
> Hi Ming,
> In fact, the notation lb/1000 is correct, as the values represent the
> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
> particular transformation of the measured values was used, but I'm sure it
> has caused confusion previously.

I disagree --- and agree with Ming.  The notation is incorrect.  Surely
"lb/1000" means thousandths of pounds.  E.g. 12345 lb/1000 is equal to
12.345 lb.

I'm sure that others will come up with all sorts of convoluted lawyerish 
arguments that the case is otherwise, but as far as I am concerned, any 
*sane* person would interpret "lb/1000" to mean thousandths of pounds.

If in the unlikely event that the documentation for some data set said 
"Weight (gm/1000)", I'm pretty sure that this would be interpreted to 
mean milligrams and *not* kilograms!

Since the description of the data was presumably taken from that given 
in the original source ("Motor Trend" magazine) it would probably be 
inappropriate to "correct" it.  However a note/warning should be added 
to the mtcars help file indicating that Motor Trend got things upside-down.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

> On Sat, Oct 24, 2015 at 11:59 AM, Ming-Lun Ho <minglho at gmail.com> wrote:
>
>> Hi,
>>      I used "?mtcars" to read the documentation for the dataset. I found a
>> mistake in how unit is listed, namely, that for the variable "wt," the unit
>> should be listed as "1000 lb," not "lb/1000." However, I don't know whom to
>> contact exactly for the correction. Please point me to the right place.
>>      Thanks.
>>            --Ming


From aolinto.lst at gmail.com  Sun Oct 25 00:19:17 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sat, 24 Oct 2015 20:19:17 -0200
Subject: [R] circular regression question
Message-ID: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>

Dear R users

I'm trying to reproduce the results from Lowry et al. 2007 Lunar landings -
Relationship between lunar phase and catch rates for an Australian
gamefish-tournament fisheryFisheries Research 88: 15?23

Basically we have two columns: Lunar  days and CPUE (catch per unit effort).
The aim is to test whether CPUE varies with the lunar cycle

Here is what I did:

library(circular)
# Black marlin CPUE
U<-c(0.02,0.024,0.017,0.02,0.018,0.034,0.042,0.026,0.017,0.019,0.006,0.008,0.011,0.014,0.007,0.018,0.008,0.004,0.008,0.013,0.011,0.008,0.006,0.004,0.008,0.005,0.016,0.011,0.022,0.048)
# Lunar day
LD <- seq(1:30)
# Lunar Day in radians
LDrad <- (360*LD)/29.58
# Plots
plot(U~LD)
plot(U~LDrad)
# Transform
LDcir <- circular(U,LDrad,type=c("angles"),units=c("radians"))
# circular model
circ.lm<-lm.circular(y=U,x=LDcir,init=1,type="c-l",verbose=TRUE)

but it runs with
circ.lm<-lm.circular(x=U,y=LDcir,init=1,type="c-l",verbose=TRUE)

Nevertheless U must be the dependent variable, not the independent one.

I also tried

Uy <- cbind(U,rep(1,length(U)))
circ.lm<-lm.circular(y=Uy,x=LDcir,init=2,type="c-l",verbose=TRUE)

Well I really appreciate any help, thanks in advance,

Antonio Olinto

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Sun Oct 25 00:27:44 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sun, 25 Oct 2015 00:27:44 +0200
Subject: [R] JSONlite import problem
In-Reply-To: <562B6D17.4010906@gmail.com>
References: <562A8E03.8040304@nic.fi> <562A8FF1.1050806@gmail.com>
	<562B04FF.6010907@nic.fi> <562B6D17.4010906@gmail.com>
Message-ID: <CABFfbXtcgX1mFr5a1cOP3gkn7_djxRp39WOVE=aQ8PUJwEhVsQ@mail.gmail.com>

On Sat, Oct 24, 2015 at 1:35 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> > However, editing the file with a text editor to create "proper" EOF
> > doesn't help.
>
> The problem is that you have valid-looking JSON objects on each odd
> numbered line, separated by single blank lines.  The parser expects an
> EOF at the end of the first object, but instead it found a blank line
> and another object.


Actually this is a common json streaming format called ndjson a.k.a.
jsonlines. Usually you can stream-import the data directly in jsonlite
using the stream_in function. See ?stream_in for examples.

However in this case there are white lines in between the json lines
which makes it a bit more tricky. I will add a feature to skip over
those lines.


From JSorkin at grecc.umaryland.edu  Sun Oct 25 00:28:34 2015
From: JSorkin at grecc.umaryland.edu (John Sorkin)
Date: Sat, 24 Oct 2015 18:28:34 -0400
Subject: [R] Add sequence numbers to lines with the same ID: How can this be
 accomplished?
In-Reply-To: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
Message-ID: <562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>

I have a file that has (1) Line numbers, (2) IDs. A given ID number can appear in more than one row. For each row with a repeated ID, I want to add a number that gives the sequence number of the repeated ID number. The R code below demonstrates what I want to have, without any attempt to produce the result, as I have no idea how to accomplish my goal.


line <- c(1,2,3,4,5,6,7,8,9,10)
ID<-    c(1,1,2,3,4,5,6,7,8,8)
cat("Note lines 1 and 2 both contain ID 1; lines 9 and 10 both contain ID 8")
cbind(line,ID)
Seq <-  c(1,2,1,1,1,1,1,1,1,2)
cat("Sequence numbers within ID added to the data")
cbind(line,ID,Seq)



John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 


Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From r.turner at auckland.ac.nz  Sun Oct 25 01:02:48 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Oct 2015 12:02:48 +1300
Subject: [R] Add sequence numbers to lines with the same ID: How can
 this be accomplished?
In-Reply-To: <562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
	<562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>
Message-ID: <562C0E18.5060008@auckland.ac.nz>

On 25/10/15 11:28, John Sorkin wrote:
> I have a file that has (1) Line numbers, (2) IDs. A given ID number can appear in more than one row. For each row with a repeated ID, I want to add a number that gives the sequence number of the repeated ID number. The R code below demonstrates what I want to have, without any attempt to produce the result, as I have no idea how to accomplish my goal.
>
>
> line <- c(1,2,3,4,5,6,7,8,9,10)
> ID<-    c(1,1,2,3,4,5,6,7,8,8)
> cat("Note lines 1 and 2 both contain ID 1; lines 9 and 10 both contain ID 8")
> cbind(line,ID)
> Seq <-  c(1,2,1,1,1,1,1,1,1,2)
> cat("Sequence numbers within ID added to the data")
> cbind(line,ID,Seq)

I *think* that

   unlist(lapply(rle(ID)$lengths,seq_len))

gives what you want.  At least it does for the given example.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch.duncan at gmail.com  Sun Oct 25 01:26:32 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 24 Oct 2015 19:26:32 -0400
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <562C0132.8010802@auckland.ac.nz>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz>
Message-ID: <562C13A8.60602@gmail.com>

On 24/10/2015 6:07 PM, Rolf Turner wrote:
> On 24/10/15 21:10, Jim Lemon wrote:
>> Hi Ming,
>> In fact, the notation lb/1000 is correct, as the values represent the
>> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
>> particular transformation of the measured values was used, but I'm sure it
>> has caused confusion previously.
> 
> I disagree --- and agree with Ming.  The notation is incorrect.  Surely
> "lb/1000" means thousandths of pounds.  E.g. 12345 lb/1000 is equal to
> 12.345 lb.
> 
> I'm sure that others will come up with all sorts of convoluted lawyerish 
> arguments that the case is otherwise, but as far as I am concerned, any 
> *sane* person would interpret "lb/1000" to mean thousandths of pounds.

And we insane ones would read "lb/1000" literally as "pounds divided by
one thousand".

The problem is that English is ambiguous.  In many, many ways.  We
should rewrite all the help files in Loglan.

Duncan Murdoch

> If in the unlikely event that the documentation for some data set said 
> "Weight (gm/1000)", I'm pretty sure that this would be interpreted to 
> mean milligrams and *not* kilograms!
> 
> Since the description of the data was presumably taken from that given 
> in the original source ("Motor Trend" magazine) it would probably be 
> inappropriate to "correct" it.  However a note/warning should be added 
> to the mtcars help file indicating that Motor Trend got things upside-down.


From bgunter.4567 at gmail.com  Sun Oct 25 01:33:17 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 24 Oct 2015 16:33:17 -0700
Subject: [R] Add sequence numbers to lines with the same ID: How can
 this be accomplished?
In-Reply-To: <562C0E18.5060008@auckland.ac.nz>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
	<562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>
	<562C0E18.5060008@auckland.ac.nz>
Message-ID: <CAGxFJbTzj25nQSLRaFCRd0o+64-gMcrcwzQ12tcnYbvircR=Jg@mail.gmail.com>

Rolf's solution works for the situation where all duplicated values
are contiguous, which may be what you need. However, I wondered how it
could be done if this were not the case. Below is an answer. It is not
as efficient or elegant as Rolf's solution for the contiguous case I
think; maybe someone will come up with something better. But I think
it works. Here's an example with code:

> w <- c(1:5,3,1,2,7,8,5,5,5,2,3)
> w
 [1] 1 2 3 4 5 3 1 2 7 8 5 5 5 2 3
> d <- 0+duplicated(w)
> for(x in unique(w)){
+   i <- w==x
+   d[i]<-1+ cumsum(d[i])
+
+ }
> d
 [1] 1 1 1 1 1 2 2 2 1 1 2 3 4 3 3

As always, corrections and/or improvements welcome.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Oct 24, 2015 at 4:02 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 25/10/15 11:28, John Sorkin wrote:
>>
>> I have a file that has (1) Line numbers, (2) IDs. A given ID number can
>> appear in more than one row. For each row with a repeated ID, I want to add
>> a number that gives the sequence number of the repeated ID number. The R
>> code below demonstrates what I want to have, without any attempt to produce
>> the result, as I have no idea how to accomplish my goal.
>>
>>
>> line <- c(1,2,3,4,5,6,7,8,9,10)
>> ID<-    c(1,1,2,3,4,5,6,7,8,8)
>> cat("Note lines 1 and 2 both contain ID 1; lines 9 and 10 both contain ID
>> 8")
>> cbind(line,ID)
>> Seq <-  c(1,2,1,1,1,1,1,1,1,2)
>> cat("Sequence numbers within ID added to the data")
>> cbind(line,ID,Seq)
>
>
> I *think* that
>
>   unlist(lapply(rle(ID)$lengths,seq_len))
>
> gives what you want.  At least it does for the given example.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aolinto.lst at gmail.com  Sun Oct 25 01:40:46 2015
From: aolinto.lst at gmail.com (Antonio Silva)
Date: Sat, 24 Oct 2015 21:40:46 -0200
Subject: [R] circular regression question
In-Reply-To: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
Message-ID: <CAE8g1gO6+6TXJ4OaLy+i0-q3x14Cfe17ct-ifb_=eULBNVJ0fA@mail.gmail.com>

Reading the help page with attention I saw that this function fits a
regression model for "circular dependent and linear independent".

So my question now is, is there a way to fit a model been with the circular
as the dependent variable?

Thanks

Antonio



2015-10-24 20:19 GMT-02:00 Antonio Silva <aolinto.lst at gmail.com>:

> Dear R users
>
> I'm trying to reproduce the results from Lowry et al. 2007 Lunar landings
> - Relationship between lunar phase and catch rates for an Australian
> gamefish-tournament fisheryFisheries Research 88: 15?23
>
> Basically we have two columns: Lunar  days and CPUE (catch per unit
> effort). The aim is to test whether CPUE varies with the lunar cycle
>
> Here is what I did:
>
> library(circular)
> # Black marlin CPUE
>
> U<-c(0.02,0.024,0.017,0.02,0.018,0.034,0.042,0.026,0.017,0.019,0.006,0.008,0.011,0.014,0.007,0.018,0.008,0.004,0.008,0.013,0.011,0.008,0.006,0.004,0.008,0.005,0.016,0.011,0.022,0.048)
> # Lunar day
> LD <- seq(1:30)
> # Lunar Day in radians
> LDrad <- (360*LD)/29.58
> # Plots
> plot(U~LD)
> plot(U~LDrad)
> # Transform
> LDcir <- circular(U,LDrad,type=c("angles"),units=c("radians"))
> # circular model
> circ.lm<-lm.circular(y=U,x=LDcir,init=1,type="c-l",verbose=TRUE)
>
> but it runs with
> circ.lm<-lm.circular(x=U,y=LDcir,init=1,type="c-l",verbose=TRUE)
>
> Nevertheless U must be the dependent variable, not the independent one.
>
> I also tried
>
> Uy <- cbind(U,rep(1,length(U)))
> circ.lm<-lm.circular(y=Uy,x=LDcir,init=2,type="c-l",verbose=TRUE)
>
> Well I really appreciate any help, thanks in advance,
>
> Antonio Olinto
>



-- 
Ant?nio Olinto ?vila da Silva
Bi?logo / Ocean?grafo
Instituto de Pesca (Fisheries Institute)
S?o Paulo, Brasil

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Oct 25 01:40:59 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 24 Oct 2015 16:40:59 -0700
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <562C13A8.60602@gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
Message-ID: <CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>

I sanction this discussion.

(Google on "auto-antonyms")

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Oct 24, 2015 at 4:26 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 24/10/2015 6:07 PM, Rolf Turner wrote:
>> On 24/10/15 21:10, Jim Lemon wrote:
>>> Hi Ming,
>>> In fact, the notation lb/1000 is correct, as the values represent the
>>> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
>>> particular transformation of the measured values was used, but I'm sure it
>>> has caused confusion previously.
>>
>> I disagree --- and agree with Ming.  The notation is incorrect.  Surely
>> "lb/1000" means thousandths of pounds.  E.g. 12345 lb/1000 is equal to
>> 12.345 lb.
>>
>> I'm sure that others will come up with all sorts of convoluted lawyerish
>> arguments that the case is otherwise, but as far as I am concerned, any
>> *sane* person would interpret "lb/1000" to mean thousandths of pounds.
>
> And we insane ones would read "lb/1000" literally as "pounds divided by
> one thousand".
>
> The problem is that English is ambiguous.  In many, many ways.  We
> should rewrite all the help files in Loglan.
>
> Duncan Murdoch
>
>> If in the unlikely event that the documentation for some data set said
>> "Weight (gm/1000)", I'm pretty sure that this would be interpreted to
>> mean milligrams and *not* kilograms!
>>
>> Since the description of the data was presumably taken from that given
>> in the original source ("Motor Trend" magazine) it would probably be
>> inappropriate to "correct" it.  However a note/warning should be added
>> to the mtcars help file indicating that Motor Trend got things upside-down.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From archboldways at hotmail.com  Sat Oct 24 12:23:48 2015
From: archboldways at hotmail.com (archboldways at hotmail.com)
Date: Sat, 24 Oct 2015 12:23:48 +0200
Subject: [R] Using R for credit risk modelling
Message-ID: <BLU436-SMTP2600EC86862C85FE279BDA3CE250@phx.gbl>

Good day,

I am looking for assistance in applying R to credit risk work mainly:
1. Credit scoring where a client can get any one credit risk rating from more than two possible ratings e.g Very Good, Good, Fair, Bad, Very Bad.
2.Economic capital calculations and RAROC models.

Would be grateful for any assistance...even resources to study.

Archie

Sent from my Huawei Mobile

From minglho at gmail.com  Sat Oct 24 10:22:39 2015
From: minglho at gmail.com (Ming-Lun Ho)
Date: Sat, 24 Oct 2015 08:22:39 +0000
Subject: [R] How to correct documentation?
In-Reply-To: <CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
Message-ID: <CAADh8bC66=BDYucTxtdX7_x90OURGoV--rmOvHO3YQcatKbCcw@mail.gmail.com>

Hi Jim,
   Conventionally, the units listed in a data description should represent
how to interpret the values of a variable. You would label the wt-axis in a
graph with the unit "1000 lb," so that should be the unit in the data
description. At least that is how data dictionaries in the statistics texts
I've taught from are set up.
      --Ming

On Sat, Oct 24, 2015, 01:10 Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ming,
> In fact, the notation lb/1000 is correct, as the values represent the
> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
> particular transformation of the measured values was used, but I'm sure it
> has caused confusion previously.
>
> Jim
>
>
> On Sat, Oct 24, 2015 at 11:59 AM, Ming-Lun Ho <minglho at gmail.com> wrote:
>
>> Hi,
>>     I used "?mtcars" to read the documentation for the dataset. I found a
>> mistake in how unit is listed, namely, that for the variable "wt," the
>> unit
>> should be listed as "1000 lb," not "lb/1000." However, I don't know whom
>> to
>> contact exactly for the correction. Please point me to the right place.
>>     Thanks.
>>           --Ming
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From mar.sapina at gmail.com  Sun Oct 25 00:53:45 2015
From: mar.sapina at gmail.com (Marijan Sapina)
Date: Sun, 25 Oct 2015 00:53:45 +0200
Subject: [R] Neuralnet package in R gives wrong output
Message-ID: <CAPHg8dthnLtNe+uLqS_t1Z-2La4Ein4bd6s_kwhw078kmUp5HA@mail.gmail.com>

I'm trying to generate prediction of the column "dubina" using this
algorithm made in R's "neuralnet" package. But I keep getting non-reliable
neural-net output. I have tried changing the number of hidden layers,
normalizing and denormalizing data. Is there a mistake in the algorithm,
maybe because of the activation function being logistic, not sigmoid?

The algorithm and the dataset are added as attachments.

I'll be very grateful if you'd help me.

Marijan

From ccberry at ucsd.edu  Sun Oct 25 05:05:33 2015
From: ccberry at ucsd.edu (Charles C. Berry)
Date: Sat, 24 Oct 2015 21:05:33 -0700
Subject: [R] Add sequence numbers to lines with the same ID: How can
 this be accomplished?
In-Reply-To: <CAGxFJbTzj25nQSLRaFCRd0o+64-gMcrcwzQ12tcnYbvircR=Jg@mail.gmail.com>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
	<562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>
	<562C0E18.5060008@auckland.ac.nz>
	<CAGxFJbTzj25nQSLRaFCRd0o+64-gMcrcwzQ12tcnYbvircR=Jg@mail.gmail.com>
Message-ID: <alpine.OSX.2.20.1510242055260.5901@charles-berrys-macbook.local>

On Sat, 24 Oct 2015, Bert Gunter wrote:

> Rolf's solution works for the situation where all duplicated values
> are contiguous, which may be what you need. However, I wondered how it
> could be done if this were not the case. Below is an answer. It is not
> as efficient or elegant as Rolf's solution for the contiguous case I
> think; maybe someone will come up with something better.

The often underappreciated `ave' comes to mind. viz.,

 	ave(w,w,FUN=seq_along)
and
 	ave(ID,ID,FUN=seq_along)

agree with the results below.

Of course, ave(...) is just split/unsplit in guise, further our discussion 
of a month or two back.

Best,

Chuck

> But I think
> it works. Here's an example with code:
>
>> w <- c(1:5,3,1,2,7,8,5,5,5,2,3)
>> w
> [1] 1 2 3 4 5 3 1 2 7 8 5 5 5 2 3
>> d <- 0+duplicated(w)
>> for(x in unique(w)){
> +   i <- w==x
> +   d[i]<-1+ cumsum(d[i])
> +
> + }
>> d
> [1] 1 1 1 1 1 2 2 2 1 1 2 3 4 3 3
>
> As always, corrections and/or improvements welcome.
>
> Cheers,
> Bert
> Bert Gunter
>
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
>
>
> On Sat, Oct 24, 2015 at 4:02 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 25/10/15 11:28, John Sorkin wrote:
>>>
>>> I have a file that has (1) Line numbers, (2) IDs. A given ID number can
>>> appear in more than one row. For each row with a repeated ID, I want to add
>>> a number that gives the sequence number of the repeated ID number. The R
>>> code below demonstrates what I want to have, without any attempt to produce
>>> the result, as I have no idea how to accomplish my goal.
>>>
>>>
>>> line <- c(1,2,3,4,5,6,7,8,9,10)
>>> ID<-    c(1,1,2,3,4,5,6,7,8,8)
>>> cat("Note lines 1 and 2 both contain ID 1; lines 9 and 10 both contain ID
>>> 8")
>>> cbind(line,ID)
>>> Seq <-  c(1,2,1,1,1,1,1,1,1,2)
>>> cat("Sequence numbers within ID added to the data")
>>> cbind(line,ID,Seq)
>>
>>
>> I *think* that
>>
>>   unlist(lapply(rle(ID)$lengths,seq_len))
>>
>> gives what you want.  At least it does for the given example.
>>
>> cheers,
>>
>> Rolf Turner
>>
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

Charles C. Berry                 Dept of Family Medicine & Public Health
cberry at ucsd edu               UC San Diego / La Jolla, CA 92093-0901
http://famprevmed.ucsd.edu/faculty/cberry/


From r.turner at auckland.ac.nz  Sun Oct 25 05:05:47 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Oct 2015 17:05:47 +1300
Subject: [R] Add sequence numbers to lines with the same ID: How can
 this be accomplished?
In-Reply-To: <CAGxFJbTzj25nQSLRaFCRd0o+64-gMcrcwzQ12tcnYbvircR=Jg@mail.gmail.com>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
	<562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>
	<562C0E18.5060008@auckland.ac.nz>
	<CAGxFJbTzj25nQSLRaFCRd0o+64-gMcrcwzQ12tcnYbvircR=Jg@mail.gmail.com>
Message-ID: <562C551B.6090802@auckland.ac.nz>


On 25/10/15 12:33, Bert Gunter wrote:

> Rolf's solution works for the situation where all duplicated values
> are contiguous, which may be what you need. However, I wondered how it
> could be done if this were not the case. Below is an answer. It is not
> as efficient or elegant as Rolf's solution for the contiguous case I
> think; maybe someone will come up with something better. But I think
> it works. Here's an example with code:
>
>> w <- c(1:5,3,1,2,7,8,5,5,5,2,3)
>> w
>   [1] 1 2 3 4 5 3 1 2 7 8 5 5 5 2 3
>> d <- 0+duplicated(w)
>> for(x in unique(w)){
> +   i <- w==x
> +   d[i]<-1+ cumsum(d[i])
> +
> + }
>> d
>   [1] 1 1 1 1 1 2 2 2 1 1 2 3 4 3 3
>
> As always, corrections and/or improvements welcome.

How about:

o <- order(w)
d <- unlist(lapply(rle(w[o])$lengths,seq_len))[order(o)]

Works for the given example. :-)

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


> On Sat, Oct 24, 2015 at 4:02 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 25/10/15 11:28, John Sorkin wrote:
>>>
>>> I have a file that has (1) Line numbers, (2) IDs. A given ID number can
>>> appear in more than one row. For each row with a repeated ID, I want to add
>>> a number that gives the sequence number of the repeated ID number. The R
>>> code below demonstrates what I want to have, without any attempt to produce
>>> the result, as I have no idea how to accomplish my goal.
>>>
>>>
>>> line <- c(1,2,3,4,5,6,7,8,9,10)
>>> ID<-    c(1,1,2,3,4,5,6,7,8,8)
>>> cat("Note lines 1 and 2 both contain ID 1; lines 9 and 10 both contain ID
>>> 8")
>>> cbind(line,ID)
>>> Seq <-  c(1,2,1,1,1,1,1,1,1,2)
>>> cat("Sequence numbers within ID added to the data")
>>> cbind(line,ID,Seq)
>>
>>
>> I *think* that
>>
>>    unlist(lapply(rle(ID)$lengths,seq_len))
>>
>> gives what you want.  At least it does for the given example.


From jsorkin at grecc.umaryland.edu  Sun Oct 25 05:14:13 2015
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Sun, 25 Oct 2015 00:14:13 -0400
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
	<CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
Message-ID: <562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>

Bert
Talking about Loglan and problems with the imprecise nature of English, which sense of sanction do you mean

to authorize, approve, or allow: an expression now sanctioned by educated usage.
to ratify or confirm: to sanction a law.
to impose a sanction on; penalize, especially by way of discipline

> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)


> On Oct 24, 2015, at 7:43 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> I sanction this discussion.
> 
> (Google on "auto-antonyms")
> 
> Cheers,
> Bert
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
> 
> 
> On Sat, Oct 24, 2015 at 4:26 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 24/10/2015 6:07 PM, Rolf Turner wrote:
>>>> On 24/10/15 21:10, Jim Lemon wrote:
>>>> Hi Ming,
>>>> In fact, the notation lb/1000 is correct, as the values represent the
>>>> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
>>>> particular transformation of the measured values was used, but I'm sure it
>>>> has caused confusion previously.
>>> 
>>> I disagree --- and agree with Ming.  The notation is incorrect.  Surely
>>> "lb/1000" means thousandths of pounds.  E.g. 12345 lb/1000 is equal to
>>> 12.345 lb.
>>> 
>>> I'm sure that others will come up with all sorts of convoluted lawyerish
>>> arguments that the case is otherwise, but as far as I am concerned, any
>>> *sane* person would interpret "lb/1000" to mean thousandths of pounds.
>> 
>> And we insane ones would read "lb/1000" literally as "pounds divided by
>> one thousand".
>> 
>> The problem is that English is ambiguous.  In many, many ways.  We
>> should rewrite all the help files in Loglan.
>> 
>> Duncan Murdoch
>> 
>>> If in the unlikely event that the documentation for some data set said
>>> "Weight (gm/1000)", I'm pretty sure that this would be interpreted to
>>> mean milligrams and *not* kilograms!
>>> 
>>> Since the description of the data was presumably taken from that given
>>> in the original source ("Motor Trend" magazine) it would probably be
>>> inappropriate to "correct" it.  However a note/warning should be added
>>> to the mtcars help file indicating that Motor Trend got things upside-down.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information. Any unauthorized use, disclosure or distribution is prohibited. If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From r.turner at auckland.ac.nz  Sun Oct 25 05:57:38 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 25 Oct 2015 17:57:38 +1300
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
	<CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
	<562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>
Message-ID: <562C6142.5080306@auckland.ac.nz>

On 25/10/15 17:14, John Sorkin wrote:
> Bert Talking about Loglan and problems with the imprecise nature of
> English, which sense of sanction do you mean
>
> to authorize, approve, or allow: an expression now sanctioned by
> educated usage. to ratify or confirm: to sanction a law. to impose a
> sanction on; penalize, especially by way of discipline.


Uh, that was Bert's point I believe.  I.e. he was deliberately striving 
for ambiguity.

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From marammagdysalem at gmail.com  Sun Oct 25 11:42:23 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 25 Oct 2015 12:42:23 +0200
Subject: [R] Avoiding for loops
Message-ID: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>

Hi All,

I wonder if I can avoid the for() loop in any of the following loops.These
loops are a part of a larger code which I'm trying to accelerate.

n=6
m=4
x<-c(0,1,1)

1st loop

for (i in 1:m-1)
   {
   d[i]<- n- (sum(x[(1):(i)])) - i
   }
  e<- n*(prod(d))


  2nd loop

LD<-list()
   for (i in 1:(m-1))
   {
   LD[[i]]<-seq(0,x[i],1)
   }

   LD[[m]]<-seq(0,(n-m-sum(x)),1)
   LED<-expand.grid (LD)
   LED<-as.matrix(LED)


3rd loop

for (i in 1:(m-1))

   {

    h[i]<- choose(x[i],LED[j,i])

     }



4th loop


 for (i in 1:(m-1))

  {

    lm[i]<-(sum(LED[j,1:i])) + i

      }


I appreciate if anyone has any suggestions or references.


Thanks in advance.


Maram Salem

	[[alternative HTML version deleted]]


From ujjwalsinha00 at gmail.com  Sun Oct 25 12:04:36 2015
From: ujjwalsinha00 at gmail.com (Ujjwal Kumar)
Date: Sun, 25 Oct 2015 16:34:36 +0530
Subject: [R] How to plott bar graphics
Message-ID: <CAGV0xWmkuW-UmeubZGch9tXSGw5NETJy6jRhSt7c1Ok-u1+xuQ@mail.gmail.com>

HI friends
I am struggling in plotting bar graph with this data sets in R. although I
can plot it in Microsoft excel( attached graphics). I need help in coding
it for R.(SE=standar error)
> >data
> habitat
> proportion_use
> proportion_use_SE
> selectivity_index
> selectivity_index_SE
> grassland
> 0.56
> 0.22
> 0.72
> 0.29
> sal_forest
> 0.11
> 0.04
> -0.43
> 0.13
> bamboo-mix
> 0.22
> 0.07
> 0.05
> 0.02
> miscellaneous
> 0.11
> 0.03
> -0.59
> 0.18
> >excel-graphics
>
>
> regards:
> Ujjwal

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Oct 25 13:14:33 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 25 Oct 2015 08:14:33 -0400
Subject: [R] Avoiding for loops
In-Reply-To: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>
References: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>
Message-ID: <17A29381-7283-469B-8467-692DC1CF4E3B@utoronto.ca>

If this code is slow it is not because you are using loops, but because you are dynamically building your vectors and lists and their size needs to change with each iteration causing significant unnecessary computational overhead. If you simply do something like

d <- numeric(m-1)
for (i in 1:m-1) {
 d[i] <- n - sum(x[1:i]) - i
}

for all of your loops, you will see already see very significant speedup. (If you look at my code formatting, and compare it with your own you may also benefit.) The bottom line: the point is not to avoid for-loops, but to speed up your code.

Nb. if you want to avoid loops for some aesthetic reason, read about apply() and its siblings,  and experiment with it. Of course, internally an apply() statement uses loops...

NNb: Do you know how to profile your code? How do you know which part of your code is actually slowing it down?



B.




On Oct 25, 2015, at 6:42 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:

> Hi All,
> 
> I wonder if I can avoid the for() loop in any of the following loops.These
> loops are a part of a larger code which I'm trying to accelerate.
> 
> n=6
> m=4
> x<-c(0,1,1)
> 
> 1st loop
> 
> for (i in 1:m-1)
>  {
>  d[i]<- n- (sum(x[(1):(i)])) - i
>  }
> e<- n*(prod(d))
> 
> 
> 2nd loop
> 
> LD<-list()
>  for (i in 1:(m-1))
>  {
>  LD[[i]]<-seq(0,x[i],1)
>  }
> 
>  LD[[m]]<-seq(0,(n-m-sum(x)),1)
>  LED<-expand.grid (LD)
>  LED<-as.matrix(LED)
> 
> 
> 3rd loop
> 
> for (i in 1:(m-1))
> 
>  {
> 
>   h[i]<- choose(x[i],LED[j,i])
> 
>    }
> 
> 
> 
> 4th loop
> 
> 
> for (i in 1:(m-1))
> 
> {
> 
>   lm[i]<-(sum(LED[j,1:i])) + i
> 
>     }
> 
> 
> I appreciate if anyone has any suggestions or references.
> 
> 
> Thanks in advance.
> 
> 
> Maram Salem
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sun Oct 25 13:21:44 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 25 Oct 2015 08:21:44 -0400
Subject: [R] Avoiding for loops
In-Reply-To: <F9282D5D-741B-4D97-8925-F865407BDB5A@utoronto.ca>
References: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>
	<F9282D5D-741B-4D97-8925-F865407BDB5A@utoronto.ca>
Message-ID: <5A92C722-288D-42AE-916F-C82CD0D8A6DA@utoronto.ca>

Sorry - I just noticed you actually have an error in your code: you had parentheses everywhere they were not needed and I overlooked you had not put them where they actually are needed. It has to be for (i in 1:(m-1)) ..., not as you wrote. I'm sure you'll understand the difference.

d <- numeric(m-1)
for (i in 1:(m-1)) {
    d[i] <- n - sum(x[1:i]) - i
}

B.

On Oct 25, 2015, at 8:13 AM, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> If this code is slow it is not because you are using loops, but because you are dynamically building your vectors and lists and their size needs to change with each iteration causing significant unnecessary computational overhead. If you simply do something like
> 
> d <- numeric(m-1)
> for (i in 1:m-1) {
>  d[i] <- n - sum(x[1:i]) - i
> }
> 
> for all of your loops, you will see already see very significant speedup. (If you look at my code formatting, and compare it with your own you may also benefit.) The bottom line: the point is not to avoid for-loops, but to speed up your code.
> 
> Nb. if you want to avoid loops for some aesthetic reason, read about apply() and its siblings,  and experiment with it. Of course, internally an apply() statement uses loops...
> 
> NNb: Do you know how to profile your code? How do you know which part of your code is actually slowing it down?
> 
> 
> 
> B.
> 
> 
> 
> 
> On Oct 25, 2015, at 6:42 AM, Maram SAlem <marammagdysalem at gmail.com> wrote:
> 
>> Hi All,
>> 
>> I wonder if I can avoid the for() loop in any of the following loops.These
>> loops are a part of a larger code which I'm trying to accelerate.
>> 
>> n=6
>> m=4
>> x<-c(0,1,1)
>> 
>> 1st loop
>> 
>> for (i in 1:m-1)
>>  {
>>  d[i]<- n- (sum(x[(1):(i)])) - i
>>  }
>> e<- n*(prod(d))
>> 
>> 
>> 2nd loop
>> 
>> LD<-list()
>>  for (i in 1:(m-1))
>>  {
>>  LD[[i]]<-seq(0,x[i],1)
>>  }
>> 
>>  LD[[m]]<-seq(0,(n-m-sum(x)),1)
>>  LED<-expand.grid (LD)
>>  LED<-as.matrix(LED)
>> 
>> 
>> 3rd loop
>> 
>> for (i in 1:(m-1))
>> 
>>  {
>> 
>>   h[i]<- choose(x[i],LED[j,i])
>> 
>>    }
>> 
>> 
>> 
>> 4th loop
>> 
>> 
>> for (i in 1:(m-1))
>> 
>> {
>> 
>>   lm[i]<-(sum(LED[j,1:i])) + i
>> 
>>     }
>> 
>> 
>> I appreciate if anyone has any suggestions or references.
>> 
>> 
>> Thanks in advance.
>> 
>> 
>> Maram Salem
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From lists at dewey.myzen.co.uk  Sun Oct 25 13:22:49 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Sun, 25 Oct 2015 12:22:49 +0000
Subject: [R] How to plott bar graphics
In-Reply-To: <CAGV0xWmkuW-UmeubZGch9tXSGw5NETJy6jRhSt7c1Ok-u1+xuQ@mail.gmail.com>
References: <CAGV0xWmkuW-UmeubZGch9tXSGw5NETJy6jRhSt7c1Ok-u1+xuQ@mail.gmail.com>
Message-ID: <562CC999.5000208@dewey.myzen.co.uk>

Dear Ujjwal

Two problems
1 - you posted in HTML so your post is unreadable
2 - your attached graphic was not in one of the formats which R-help 
accepts and so was stripped

On 25/10/2015 11:04, Ujjwal Kumar wrote:
> HI friends
> I am struggling in plotting bar graph with this data sets in R. although I
> can plot it in Microsoft excel( attached graphics). I need help in coding
> it for R.(SE=standar error)
>>> data
>> habitat
>> proportion_use
>> proportion_use_SE
>> selectivity_index
>> selectivity_index_SE
>> grassland
>> 0.56
>> 0.22
>> 0.72
>> 0.29
>> sal_forest
>> 0.11
>> 0.04
>> -0.43
>> 0.13
>> bamboo-mix
>> 0.22
>> 0.07
>> 0.05
>> 0.02
>> miscellaneous
>> 0.11
>> 0.03
>> -0.59
>> 0.18
>>> excel-graphics
>>
>>
>> regards:
>> Ujjwal
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From bhh at xs4all.nl  Sun Oct 25 13:26:00 2015
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 25 Oct 2015 13:26:00 +0100
Subject: [R] Avoiding for loops
In-Reply-To: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>
References: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>
Message-ID: <DD4F4C85-D193-4EF9-9CEA-C9FEFAD9728F@xs4all.nl>


> On 25 Oct 2015, at 11:42, Maram SAlem <marammagdysalem at gmail.com> wrote:
> 
> Hi All,
> 
> I wonder if I can avoid the for() loop in any of the following loops.These
> loops are a part of a larger code which I'm trying to accelerate.
> 
> n=6
> m=4
> x<-c(0,1,1)
> 
> 1st loop
> 
> for (i in 1:m-1)
>   {
>   d[i]<- n- (sum(x[(1):(i)])) - i
>   }
>  e<- n*(prod(d))
> 
> 
On the basis of the other loops I presume you mean

for( in in 1:(m-1))

in stead of what you wrote.

You get the same result with 

d <- n - cumsum(x) - (1:(m-1))


Berend


>  2nd loop
> 
> LD<-list()
>   for (i in 1:(m-1))
>   {
>   LD[[i]]<-seq(0,x[i],1)
>   }
> 
>   LD[[m]]<-seq(0,(n-m-sum(x)),1)
>   LED<-expand.grid (LD)
>   LED<-as.matrix(LED)
> 
> 
> 3rd loop
> 
> for (i in 1:(m-1))
> 
>   {
> 
>    h[i]<- choose(x[i],LED[j,i])
> 
>     }
> 
> 
> 
> 4th loop
> 
> 
> for (i in 1:(m-1))
> 
>  {
> 
>    lm[i]<-(sum(LED[j,1:i])) + i
> 
>      }
> 
> 
> I appreciate if anyone has any suggestions or references.
> 
> 
> Thanks in advance.
> 
> 
> Maram Salem
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Sun Oct 25 14:37:58 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Oct 2015 06:37:58 -0700
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <562C6142.5080306@auckland.ac.nz>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
	<CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
	<562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>
	<562C6142.5080306@auckland.ac.nz>
Message-ID: <CAGxFJbSPHwsjR09SaU0PaQ-u4GjUgPyK01c6AAOPe2t=ZGmNTQ@mail.gmail.com>

Yes. Too cute, maybe?

-- Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Oct 24, 2015 at 9:57 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> On 25/10/15 17:14, John Sorkin wrote:
>>
>> Bert Talking about Loglan and problems with the imprecise nature of
>> English, which sense of sanction do you mean
>>
>> to authorize, approve, or allow: an expression now sanctioned by
>> educated usage. to ratify or confirm: to sanction a law. to impose a
>> sanction on; penalize, especially by way of discipline.
>
>
>
> Uh, that was Bert's point I believe.  I.e. he was deliberately striving for
> ambiguity.
>
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276


From bgunter.4567 at gmail.com  Sun Oct 25 14:42:05 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Oct 2015 06:42:05 -0700
Subject: [R] Add sequence numbers to lines with the same ID: How can
	this be accomplished?
In-Reply-To: <alpine.OSX.2.20.1510242055260.5901@charles-berrys-macbook.local>
References: <CAE8g1gOkUjxT6csVEdJWurX9K--jd9YvKFxX30ABgdp1AJNbmA@mail.gmail.com>
	<562BCDD2020000CB0013D898@smtp.medicine.umaryland.edu>
	<562C0E18.5060008@auckland.ac.nz>
	<CAGxFJbTzj25nQSLRaFCRd0o+64-gMcrcwzQ12tcnYbvircR=Jg@mail.gmail.com>
	<alpine.OSX.2.20.1510242055260.5901@charles-berrys-macbook.local>
Message-ID: <CAGxFJbRO+m=EvHCfoES3zdhXOG8TNaavUtMgOg=95Y5QJ=Goyg@mail.gmail.com>

Yay Chuck!  Boo Bert.

-- Bert


Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Sat, Oct 24, 2015 at 9:05 PM, Charles C. Berry <ccberry at ucsd.edu> wrote:
> On Sat, 24 Oct 2015, Bert Gunter wrote:
>
>> Rolf's solution works for the situation where all duplicated values
>> are contiguous, which may be what you need. However, I wondered how it
>> could be done if this were not the case. Below is an answer. It is not
>> as efficient or elegant as Rolf's solution for the contiguous case I
>> think; maybe someone will come up with something better.
>
>
> The often underappreciated `ave' comes to mind. viz.,
>
>         ave(w,w,FUN=seq_along)
> and
>         ave(ID,ID,FUN=seq_along)
>
> agree with the results below.
>
> Of course, ave(...) is just split/unsplit in guise, further our discussion
> of a month or two back.
>
> Best,
>
> Chuck
>
>
>> But I think
>> it works. Here's an example with code:
>>
>>> w <- c(1:5,3,1,2,7,8,5,5,5,2,3)
>>> w
>>
>> [1] 1 2 3 4 5 3 1 2 7 8 5 5 5 2 3
>>>
>>> d <- 0+duplicated(w)
>>> for(x in unique(w)){
>>
>> +   i <- w==x
>> +   d[i]<-1+ cumsum(d[i])
>> +
>> + }
>>>
>>> d
>>
>> [1] 1 1 1 1 1 2 2 2 1 1 2 3 4 3 3
>>
>> As always, corrections and/or improvements welcome.
>>
>> Cheers,
>> Bert
>> Bert Gunter
>>
>> "Data is not information. Information is not knowledge. And knowledge
>> is certainly not wisdom."
>>   -- Clifford Stoll
>>
>>
>> On Sat, Oct 24, 2015 at 4:02 PM, Rolf Turner <r.turner at auckland.ac.nz>
>> wrote:
>>>
>>> On 25/10/15 11:28, John Sorkin wrote:
>>>>
>>>>
>>>> I have a file that has (1) Line numbers, (2) IDs. A given ID number can
>>>> appear in more than one row. For each row with a repeated ID, I want to
>>>> add
>>>> a number that gives the sequence number of the repeated ID number. The R
>>>> code below demonstrates what I want to have, without any attempt to
>>>> produce
>>>> the result, as I have no idea how to accomplish my goal.
>>>>
>>>>
>>>> line <- c(1,2,3,4,5,6,7,8,9,10)
>>>> ID<-    c(1,1,2,3,4,5,6,7,8,8)
>>>> cat("Note lines 1 and 2 both contain ID 1; lines 9 and 10 both contain
>>>> ID
>>>> 8")
>>>> cbind(line,ID)
>>>> Seq <-  c(1,2,1,1,1,1,1,1,1,2)
>>>> cat("Sequence numbers within ID added to the data")
>>>> cbind(line,ID,Seq)
>>>
>>>
>>>
>>> I *think* that
>>>
>>>   unlist(lapply(rle(ID)$lengths,seq_len))
>>>
>>> gives what you want.  At least it does for the given example.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>> --
>>> Technical Editor ANZJS
>>> Department of Statistics
>>> University of Auckland
>>> Phone: +64-9-373-7599 ext. 88276
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> Charles C. Berry                 Dept of Family Medicine & Public Health
> cberry at ucsd edu               UC San Diego / La Jolla, CA 92093-0901
> http://famprevmed.ucsd.edu/faculty/cberry/


From marammagdysalem at gmail.com  Sun Oct 25 14:48:09 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 25 Oct 2015 15:48:09 +0200
Subject: [R] Avoiding for loops
In-Reply-To: <DD4F4C85-D193-4EF9-9CEA-C9FEFAD9728F@xs4all.nl>
References: <CAPLSCn3-_iP2zR3TtWB_o=+jNJ2hYBf4mmvY-YDCzi-Kmp61og@mail.gmail.com>
	<DD4F4C85-D193-4EF9-9CEA-C9FEFAD9728F@xs4all.nl>
Message-ID: <CAPLSCn2a+VzEXzk3msjtuwdWF+5fF2SuzR0gQysrwE8pz1Q=9g@mail.gmail.com>

Thanks a lot Boris and Berend.

I'll consider the brackets ((m-1) in every loop). In addition, I'll read
more on profiling my code. In fact,I'm using the apply () in another part
of my code.

Thanks again for helping.

Maram Salem

On 25 October 2015 at 14:26, Berend Hasselman <bhh at xs4all.nl> wrote:

>
> > On 25 Oct 2015, at 11:42, Maram SAlem <marammagdysalem at gmail.com> wrote:
> >
> > Hi All,
> >
> > I wonder if I can avoid the for() loop in any of the following
> loops.These
> > loops are a part of a larger code which I'm trying to accelerate.
> >
> > n=6
> > m=4
> > x<-c(0,1,1)
> >
> > 1st loop
> >
> > for (i in 1:m-1)
> >   {
> >   d[i]<- n- (sum(x[(1):(i)])) - i
> >   }
> >  e<- n*(prod(d))
> >
> >
> On the basis of the other loops I presume you mean
>
> for( in in 1:(m-1))
>
> in stead of what you wrote.
>
> You get the same result with
>
> d <- n - cumsum(x) - (1:(m-1))
>
>
> Berend
>
>
> >  2nd loop
> >
> > LD<-list()
> >   for (i in 1:(m-1))
> >   {
> >   LD[[i]]<-seq(0,x[i],1)
> >   }
> >
> >   LD[[m]]<-seq(0,(n-m-sum(x)),1)
> >   LED<-expand.grid (LD)
> >   LED<-as.matrix(LED)
> >
> >
> > 3rd loop
> >
> > for (i in 1:(m-1))
> >
> >   {
> >
> >    h[i]<- choose(x[i],LED[j,i])
> >
> >     }
> >
> >
> >
> > 4th loop
> >
> >
> > for (i in 1:(m-1))
> >
> >  {
> >
> >    lm[i]<-(sum(LED[j,1:i])) + i
> >
> >      }
> >
> >
> > I appreciate if anyone has any suggestions or references.
> >
> >
> > Thanks in advance.
> >
> >
> > Maram Salem
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Sun Oct 25 15:50:07 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Sun, 25 Oct 2015 10:50:07 -0400
Subject: [R] Having trouble updating and installing R 3.2.1 and 3.2.2
Message-ID: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>

I get the following error:

Warning message:
In normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="C:\Users\Administrator\My Documents/R/win-library/3.2": Access is denied

This may be the first time that I have tried to upgrade R since I upgraded my Windows installation (on Parallels on my Mac no less) to Windows 10.

Needless to say when I try to install packages outside of core CRAN I have issues.

Any help is greatly appreciated.

Thanks much,
KW


From pdalgd at gmail.com  Sun Oct 25 16:11:35 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 25 Oct 2015 16:11:35 +0100
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <CAGxFJbSPHwsjR09SaU0PaQ-u4GjUgPyK01c6AAOPe2t=ZGmNTQ@mail.gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
	<CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
	<562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>
	<562C6142.5080306@auckland.ac.nz>
	<CAGxFJbSPHwsjR09SaU0PaQ-u4GjUgPyK01c6AAOPe2t=ZGmNTQ@mail.gmail.com>
Message-ID: <8C9AEBFC-1CA2-46B3-87FB-06BF4031E824@gmail.com>


> On 25 Oct 2015, at 14:37 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Yes. Too cute, maybe?
> 

...as in "charming" or...





Oh.

;-)
pd

> -- Bert
> Bert Gunter
> 
> "Data is not information. Information is not knowledge. And knowledge
> is certainly not wisdom."
>   -- Clifford Stoll
> 
> 
> On Sat, Oct 24, 2015 at 9:57 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>> On 25/10/15 17:14, John Sorkin wrote:
>>> 
>>> Bert Talking about Loglan and problems with the imprecise nature of
>>> English, which sense of sanction do you mean
>>> 
>>> to authorize, approve, or allow: an expression now sanctioned by
>>> educated usage. to ratify or confirm: to sanction a law. to impose a
>>> sanction on; penalize, especially by way of discipline.
>> 
>> 
>> 
>> Uh, that was Bert's point I believe.  I.e. he was deliberately striving for
>> ambiguity.
>> 
>> 
>> cheers,
>> 
>> Rolf
>> 
>> --
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maillists at nic.fi  Sun Oct 25 17:05:30 2015
From: maillists at nic.fi (K. Elo)
Date: Sun, 25 Oct 2015 18:05:30 +0200
Subject: [R] JSONlite import problem
In-Reply-To: <CABFfbXtcgX1mFr5a1cOP3gkn7_djxRp39WOVE=aQ8PUJwEhVsQ@mail.gmail.com>
References: <562A8E03.8040304@nic.fi> <562A8FF1.1050806@gmail.com>
	<562B04FF.6010907@nic.fi> <562B6D17.4010906@gmail.com>
	<CABFfbXtcgX1mFr5a1cOP3gkn7_djxRp39WOVE=aQ8PUJwEhVsQ@mail.gmail.com>
Message-ID: <562CFDCA.4060502@nic.fi>

Hi,

thanks to Duncan and Jeroen to quick replies. I was actually my thinking 
error :) I suppoed 'fromJSON' to cope with a multi-line file or a list, 
but this seems not to be the case. So I first read the file with 
'readLines' into a list and processed all items with 'fromJSON' within a 
for-loop. This worked.

Best,
Kimmo

25.10.2015, 01:27, Jeroen Ooms wrote:
> On Sat, Oct 24, 2015 at 1:35 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>>> However, editing the file with a text editor to create "proper" EOF
>>> doesn't help.
>>
>> The problem is that you have valid-looking JSON objects on each odd
>> numbered line, separated by single blank lines.  The parser expects an
>> EOF at the end of the first object, but instead it found a blank line
>> and another object.
>
>
> Actually this is a common json streaming format called ndjson a.k.a.
> jsonlines. Usually you can stream-import the data directly in jsonlite
> using the stream_in function. See ?stream_in for examples.
>
> However in this case there are white lines in between the json lines
> which makes it a bit more tricky. I will add a feature to skip over
> those lines.
>


From oscar.kjell at psy.lu.se  Sun Oct 25 10:14:35 2015
From: oscar.kjell at psy.lu.se (Oscar Kjell)
Date: Sun, 25 Oct 2015 09:14:35 +0000
Subject: [R]  Krippendorff's alpha bootstrapping implementation
Message-ID: <5EC65CB783EA48409DD18BFE64AB5D3ABC1832A5@uwmbx06.uw.lu.se>

Hi Polina and Jim,
Have you been able to implement the correct bootstrapping of Krippendorff's alpha?

Kind Regards,
Oscar



	[[alternative HTML version deleted]]


From martin.canon at gmail.com  Sun Oct 25 13:02:49 2015
From: martin.canon at gmail.com (Martin Canon)
Date: Sun, 25 Oct 2015 07:02:49 -0500
Subject: [R] y2z question (AGD)
Message-ID: <CAD3qanComneme+Axw39gAW_kE2pCTqF8XE5A4dun3mAn+96j_g@mail.gmail.com>

Hi to all.

I've been trying to calculate weight-for-age z-scores with the y2z
command (AGD package).

However, I keep getting strange results.

My hypothesis is that missings are the problem.

My dataframe looks like this:

data <- structure(list(sex = structure(c(3L, 3L, 3L, 2L, 3L), .Label = c("",
"F", "M"), class = "factor"), weight = c(8.5, 8.2, 9, NA, 5.8),
    age = c(8, 9, 12, 9, 1)), .Names = c("sex", "weight", "age"
), class = "data.frame", row.names = c(NA, 5L))

Weight is in kg and age in months.
I will use WHO curves for children younger than 2 years of age.

z-score calculation:

library(AGD)
data$zeta <- y2z(y = data$weight, x = data$age/12, sex = data$sex,
                ref = get("who.wgt"))

I get:

Warning message:
In `split<-.default`(`*tmp*`, f, drop = drop, value = value) :
  number of items to replace is not a multiple of replacement length

data$zeta
[1]     NA     NA     NA -0.124     NA

However a for loop seems to work.

for (i in 1:5) {

  data$zeta[i] <- y2z(y = data$weight[i],
                 x = data$age[i]/12,
                 sex = data$sex[i],
                ref = get("who.wgt"))
}

data$zeta
[1] -0.124 -0.751 -0.635     NA  2.002

Is there a workaround so that I don't have to use a for loop?
na.action doesn't work either.

Thanks.


Martin


From anna.lawsonmclean at gmail.com  Sun Oct 25 15:17:38 2015
From: anna.lawsonmclean at gmail.com (Anna Cecilia Lawson McLean)
Date: Sun, 25 Oct 2015 15:17:38 +0100
Subject: [R] Modifying graphs in 'survrec' package
Message-ID: <CAJBWR05qzrJ=69mL-NduTJtuRMc-+j+geeACRNOd9KY=0_K16Q@mail.gmail.com>

Dear all,

I am new to R and I am using the package 'survrec'. I would like to modify
the colors and lines in graphs with multiple groups. The package includes
this example:

data(colon)
fit<-survfitr(Survr(hc,time,event)~as.factor(dukes),data=colon,type="pena")

Using the arguments "col" or "lty" has not worked:

plot(fit,ylim=c(0,1),xlim=c(0,2000), col=c("red", "blue", "orange"), lty=3)


I would be very grateful for any help! Thank you very much in advance!

Kind regards,

Anna McLean

	[[alternative HTML version deleted]]


From bob at rudis.net  Sun Oct 25 18:32:18 2015
From: bob at rudis.net (boB Rudis)
Date: Sun, 25 Oct 2015 13:32:18 -0400
Subject: [R] Modifying graphs in 'survrec' package
In-Reply-To: <CAJBWR05qzrJ=69mL-NduTJtuRMc-+j+geeACRNOd9KY=0_K16Q@mail.gmail.com>
References: <CAJBWR05qzrJ=69mL-NduTJtuRMc-+j+geeACRNOd9KY=0_K16Q@mail.gmail.com>
Message-ID: <CAJ4QxaOdM4oC8wP_inXSfjz+Ds9Disz_94G1pbAQyT4D0Mn+eg@mail.gmail.com>

As answered here: http://stackoverflow.com/a/33331444/1457051

    palette(c("red", "blue", "orange"))
    par(lty=3)
    plot(fit,ylim=c(0,1),xlim=c(0,2000))

though, as indicated in that post, you'll need to customize the
survrec:::plot.survfitr function to do more detailed customization.

On Sun, Oct 25, 2015 at 10:17 AM, Anna Cecilia Lawson McLean
<anna.lawsonmclean at gmail.com> wrote:
> Dear all,
>
> I am new to R and I am using the package 'survrec'. I would like to modify
> the colors and lines in graphs with multiple groups. The package includes
> this example:
>
> data(colon)
> fit<-survfitr(Survr(hc,time,event)~as.factor(dukes),data=colon,type="pena")
>
> Using the arguments "col" or "lty" has not worked:
>
> plot(fit,ylim=c(0,1),xlim=c(0,2000), col=c("red", "blue", "orange"), lty=3)
>
>
> I would be very grateful for any help! Thank you very much in advance!
>
> Kind regards,
>
> Anna McLean
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Oct 25 18:53:21 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 25 Oct 2015 17:53:21 +0000
Subject: [R] y2z question (AGD)
In-Reply-To: <CAD3qanComneme+Axw39gAW_kE2pCTqF8XE5A4dun3mAn+96j_g@mail.gmail.com>
References: <CAD3qanComneme+Axw39gAW_kE2pCTqF8XE5A4dun3mAn+96j_g@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D407B@mb02.ads.tamu.edu>

It looks like the y2z() function strips NA's so that the vector lengths do not match any longer. The simplest workaround is to remove the NA's. You could do that by using data2 <- na.omit(data) to strip the observations with NA if they will not be used in the rest of the analysis. 

If you want to preserve the NAs in the data frame, this seems to work:

> nomiss <- complete.cases(data)
> data$zeta[nomiss] <- with(data[nomiss, ], y2z(weight, age/12, sex, ref=who.wgt))
> data
  sex weight age   zeta
1   M    8.5   8 -0.124
2   M    8.2   9 -0.751
3   M    9.0  12 -0.635
4   F     NA   9     NA
5   M    5.8   1  2.002


David L. Carlson
Department of Anthropology
Texas A&M University



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin Canon
Sent: Sunday, October 25, 2015 7:03 AM
To: R help <r-help at r-project.org>
Subject: [R] y2z question (AGD)

Hi to all.

I've been trying to calculate weight-for-age z-scores with the y2z
command (AGD package).

However, I keep getting strange results.

My hypothesis is that missings are the problem.

My dataframe looks like this:

data <- structure(list(sex = structure(c(3L, 3L, 3L, 2L, 3L), .Label = c("",
"F", "M"), class = "factor"), weight = c(8.5, 8.2, 9, NA, 5.8),
    age = c(8, 9, 12, 9, 1)), .Names = c("sex", "weight", "age"
), class = "data.frame", row.names = c(NA, 5L))

Weight is in kg and age in months.
I will use WHO curves for children younger than 2 years of age.

z-score calculation:

library(AGD)
data$zeta <- y2z(y = data$weight, x = data$age/12, sex = data$sex,
                ref = get("who.wgt"))

I get:

Warning message:
In `split<-.default`(`*tmp*`, f, drop = drop, value = value) :
  number of items to replace is not a multiple of replacement length

data$zeta
[1]     NA     NA     NA -0.124     NA

However a for loop seems to work.

for (i in 1:5) {

  data$zeta[i] <- y2z(y = data$weight[i],
                 x = data$age[i]/12,
                 sex = data$sex[i],
                ref = get("who.wgt"))
}

data$zeta
[1] -0.124 -0.751 -0.635     NA  2.002

Is there a workaround so that I don't have to use a for loop?
na.action doesn't work either.

Thanks.


Martin

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From marammagdysalem at gmail.com  Sun Oct 25 22:05:03 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Sun, 25 Oct 2015 23:05:03 +0200
Subject: [R] Time it takes to run a code
Message-ID: <CAPLSCn1_vDU7kpY9nf7XqP_H07Rc+CZMHYdq-rE8c+Uf0scVbw@mail.gmail.com>

Hi All,

I'm using a function, say func, and I want to apply it to all the rows of a
certain matrix. The problem is that my code kept on running for more than
two days without giving any output. I've made some modifications.But is
there a way to know the time needed to execute my code and reach an ouput
but before running the code and not after it is run? I've tried Sys.time()
and system.time(), but still the console freezed for so long and I didn't
reach anything.

Any suggestions are much appreciated.
Thanks in advance.

Maram Salem

	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Sun Oct 25 22:30:23 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 25 Oct 2015 17:30:23 -0400
Subject: [R] Time it takes to run a code
In-Reply-To: <CAPLSCn1_vDU7kpY9nf7XqP_H07Rc+CZMHYdq-rE8c+Uf0scVbw@mail.gmail.com>
References: <CAPLSCn1_vDU7kpY9nf7XqP_H07Rc+CZMHYdq-rE8c+Uf0scVbw@mail.gmail.com>
Message-ID: <A2A011F7-4FBF-40B5-A58E-D290F05702CE@utoronto.ca>

It may be useful for you to estimate the time complexity of your function: try it with smaller input that takes short and noticeable time, see whether the time increases linearly, quadratically, or exponentially with the number of elements you process, then  extrapolate to your full data set.


To see what your function is doing, you could 
- add a print statement that tells you the progress every 1000 or 10,000 items or so...
- add a progress bar
     https://stat.ethz.ch/R-manual/R-patched/library/utils/html/txtProgressBar.html
- install and use the pbapply package
    https://cran.r-project.org/web/packages/pbapply/pbapply.pdf


You are right to make sure you are getting some feedback, it is easy to make a mistake in function logic that will cause a function to fail to terminate.


B.



On Oct 25, 2015, at 5:05 PM, Maram SAlem <marammagdysalem at gmail.com> wrote:

> Hi All,
> 
> I'm using a function, say func, and I want to apply it to all the rows of a
> certain matrix. The problem is that my code kept on running for more than
> two days without giving any output. I've made some modifications.But is
> there a way to know the time needed to execute my code and reach an ouput
> but before running the code and not after it is run? I've tried Sys.time()
> and system.time(), but still the console freezed for so long and I didn't
> reach anything.
> 
> Any suggestions are much appreciated.
> Thanks in advance.
> 
> Maram Salem
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bretschr at xs4all.nl  Sun Oct 25 23:04:02 2015
From: bretschr at xs4all.nl (Franklin Bretschneider)
Date: Sun, 25 Oct 2015 23:04:02 +0100
Subject: [R] [FORGED] Re:  How to correct documentation?
In-Reply-To: <562C0132.8010802@auckland.ac.nz>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz>
Message-ID: <45EF016C-A3EC-42B4-83B9-424D28A2E358@xs4all.nl>

Dear all,


As to stating units in graphs: IMHO it should be as follows:

If an axis reads 0  ... 10  ... 20 ... etc and the unit is pounds (lb), the legend should read "weight/lb" (pronounced "weight in pound").
The logic is: 10 lb/lb = 10. In orther words, dividing a dimensioned number by the dimension leaves the bare number, which is what the axis shows.
So in the case of the OP the legend should read: "weight/1000lb".
Thus, 20000 lb/1000lb = 20, which is what the axis shows.

Best,


Frank
----




Franklin Bretschneider
Dept of Biology
Utrecht University
bretschr at xs4all.nl


From jdnewmil at dcn.davis.CA.us  Mon Oct 26 00:15:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 25 Oct 2015 16:15:54 -0700
Subject: [R] Having trouble updating and installing R 3.2.1 and 3.2.2
In-Reply-To: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>
References: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>
Message-ID: <A529BB44-6905-4AD0-B33C-0332A8181206@dcn.davis.CA.us>

I would guess that you ran R as administrator at some point and now you have a permissions problem on your user library. I can't say I know how to fix it, though using administrator mode to fix the permissions is probably hard while using administrator mode to delete the R directory and reinstalling your packages might be easier.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 25, 2015 7:50:07 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>I get the following error:
>
>Warning message:
>In normalizePath(path.expand(path), winslash, mustWork) :
>path[1]="C:\Users\Administrator\My Documents/R/win-library/3.2": Access
>is denied
>
>This may be the first time that I have tried to upgrade R since I
>upgraded my Windows installation (on Parallels on my Mac no less) to
>Windows 10.
>
>Needless to say when I try to install packages outside of core CRAN I
>have issues.
>
>Any help is greatly appreciated.
>
>Thanks much,
>KW
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Mon Oct 26 00:44:35 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sun, 25 Oct 2015 19:44:35 -0400
Subject: [R] [FORGED] Re:  How to correct documentation?
In-Reply-To: <562C0132.8010802@auckland.ac.nz>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz>
Message-ID: <80147FF5-44BC-4008-8815-98DA25B75399@utoronto.ca>

Ming is right. I can't imagine other discipline's standards are substantially different from ours, but e.g. the ACS style manual is very explicit to require ...

   "Label each axis with the parameter or variable being measured and the units of measure in parentheses."

The _units_ are not lb/1000. 1/1000 is a _transformation_ of the value, the unit is lb, or in that case (1000 lb). Writing lb/1000 is just as nonsensical as writing g/k instead of (kg). 1000 is simply a numerical prefix to the unit, like kilo.

It gets worse: According to the UK metric association:
   "The symbol for "per" (meaning "divided by") is ?/? (slash)."

Accordingly, "lb/1000" is to be read "pounds per 1000" which is actually wrong by six orders of magnitude. 

I don't think there is ambiguity here nor occasion for sophistry: as written, the label is wrong. It would be more than appropriate for a community that is passionate about data to correct this.


:-)
Boris

(Good Lord! https://xkcd.com/386/)

On Oct 24, 2015, at 6:07 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:

> On 24/10/15 21:10, Jim Lemon wrote:
>> Hi Ming,
>> In fact, the notation lb/1000 is correct, as the values represent the
>> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
>> particular transformation of the measured values was used, but I'm sure it
>> has caused confusion previously.
> 
> I disagree --- and agree with Ming.  The notation is incorrect.  Surely
> "lb/1000" means thousandths of pounds.  E.g. 12345 lb/1000 is equal to
> 12.345 lb.
> 
> I'm sure that others will come up with all sorts of convoluted lawyerish arguments that the case is otherwise, but as far as I am concerned, any *sane* person would interpret "lb/1000" to mean thousandths of pounds.
> 
> If in the unlikely event that the documentation for some data set said "Weight (gm/1000)", I'm pretty sure that this would be interpreted to mean milligrams and *not* kilograms!
> 
> Since the description of the data was presumably taken from that given in the original source ("Motor Trend" magazine) it would probably be inappropriate to "correct" it.  However a note/warning should be added to the mtcars help file indicating that Motor Trend got things upside-down.
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
>> On Sat, Oct 24, 2015 at 11:59 AM, Ming-Lun Ho <minglho at gmail.com> wrote:
>> 
>>> Hi,
>>>     I used "?mtcars" to read the documentation for the dataset. I found a
>>> mistake in how unit is listed, namely, that for the variable "wt," the unit
>>> should be listed as "1000 lb," not "lb/1000." However, I don't know whom to
>>> contact exactly for the correction. Please point me to the right place.
>>>     Thanks.
>>>           --Ming
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Mon Oct 26 01:45:57 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Oct 2015 11:45:57 +1100
Subject: [R] Krippendorff's alpha bootstrapping implementation
In-Reply-To: <5EC65CB783EA48409DD18BFE64AB5D3ABC1832A5@uwmbx06.uw.lu.se>
References: <5EC65CB783EA48409DD18BFE64AB5D3ABC1832A5@uwmbx06.uw.lu.se>
Message-ID: <CA+8X3fU-n6xnsF5QDeU=e4py1EMdY3vkemZBnJAj+FhC42CK=A@mail.gmail.com>

Hi Oscar,
I would be overjoyed if someone has translated the SPSS or SAS code
provided by Andrew Hayes:

http://www.afhayes.com/spss-sas-and-mplus-macros-and-code.html

scroll down to KALPHA and go for it. If you succeed, let:

Matthias Gamer <m.gamer at uke.uni-hamburg.de>

the maintainer of the irr package know, and I am sure he will also be
overjoyed.

Jim

On Sun, Oct 25, 2015 at 8:14 PM, Oscar Kjell <oscar.kjell at psy.lu.se> wrote:

> Hi Polina and Jim,
> Have you been able to implement the correct bootstrapping of
> Krippendorff's alpha?
>
> Kind Regards,
> Oscar
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Oct 26 08:58:37 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Oct 2015 18:58:37 +1100
Subject: [R] How to plott bar graphics
In-Reply-To: <CAGV0xWkdaEkqAVbeboxfzhUKnZnBRKHLLS54+vTDcDpsWMutQw@mail.gmail.com>
References: <CAGV0xWmkuW-UmeubZGch9tXSGw5NETJy6jRhSt7c1Ok-u1+xuQ@mail.gmail.com>
	<562CC999.5000208@dewey.myzen.co.uk>
	<CA+8X3fWXkaiw9V45FfvnKBVEg0uR_zmTEs43iPOduTKDA=z6jA@mail.gmail.com>
	<CAGV0xWkdaEkqAVbeboxfzhUKnZnBRKHLLS54+vTDcDpsWMutQw@mail.gmail.com>
Message-ID: <CA+8X3fVKjZd8Z=z64xz-c1M7ZytKLGKPMm6bw2k9mdo7jt1FRw@mail.gmail.com>

No worries. Just use:

abline(h=0)

Jim

On Mon, Oct 26, 2015 at 6:32 PM, Ujjwal Kumar <ujjwalsinha00 at gmail.com>
wrote:

> Thank you Jim for your Kind help
> The second code suits my need.
> Just another query If I need to put another line (horizontal, same as x-
> axis that passes through zero (0.0), and actually divide negative value of
> less than 0 and positve value more than zero, How to do this??
>
> Once again Thank you very much for guiding me.
>
> On Mon, Oct 26, 2015 at 6:02 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>
>> Hi Ujjwal,
>> Given that you have asked about a barplot and included standard errors,
>> you probably want something like the following:
>>
>> uk.df<-read.table(text=
>>
>>  "habitat,proportion_use,proportion_use_SE,selectivity_index,selectivity_index_SE
>>  grassland,0.56,0.22,0.72,0.29
>>  sal_forest,0.11,0.04,-0.43,0.13
>>  bamboo-mix,0.22,0.07,0.05,0.02
>>  miscellaneous,0.11,0.03,-0.59,0.18",sep=",",header=TRUE)
>> library(plotrix)
>> barpos<-barp(uk.df[c("proportion_use","selectivity_index")],
>>  names.arg=c("proportion_use","selectivity_index"),
>>  main="Habitat Use Plot",ylab="Proportion of use",
>>  col=2:5,ylim=c(-1,1.1))
>> dispersion(barpos$x,barpos$y,
>>  ulim=as.matrix(uk.df[c("proportion_use_SE","selectivity_index_SE")]))
>> legend(0.7,-0.3,uk.df$habitat,fill=2:4)
>>
>> You will almost certainly be told that you shouldn't do this, so maybe
>> you should consider:
>>
>> matplot(matrix(c(0.9,1.1,1.9,2.1,2.9,3.1,3.9,4.1),nrow=4,byrow=TRUE),
>>  uk.df[c("proportion_use","selectivity_index")],
>>  ylab="Proportion and selectivity of use",
>>  ylim=c(-1,1.1),pch=18:19,col=2:3,xaxt="n",xlab="Habitat",
>>  main="Habitat Use Plot")
>> axis(1,at=1:4,labels=uk.df$habitat)
>> dispersion(matrix(c(0.9,1.1,1.9,2.1,2.9,3.1,3.9,4.1),nrow=4,byrow=TRUE),
>>  as.matrix(uk.df[c("proportion_use","selectivity_index")]),
>>  ulim=as.matrix(uk.df[c("proportion_use_SE","selectivity_index_SE")]))
>> legend(2.5,1,c("Proportion of use","Selectivity of use"),
>>  pch=18:19,col=2:3)
>>
>> Jim
>>
>>
>> On Sun, Oct 25, 2015 at 11:22 PM, Michael Dewey <lists at dewey.myzen.co.uk>
>> wrote:
>>
>>> Dear Ujjwal
>>>
>>> Two problems
>>> 1 - you posted in HTML so your post is unreadable
>>> 2 - your attached graphic was not in one of the formats which R-help
>>> accepts and so was stripped
>>>
>>>
>>> On 25/10/2015 11:04, Ujjwal Kumar wrote:
>>>
>>>> HI friends
>>>> I am struggling in plotting bar graph with this data sets in R.
>>>> although I
>>>> can plot it in Microsoft excel( attached graphics). I need help in
>>>> coding
>>>> it for R.(SE=standar error)
>>>>
>>>>> data
>>>>>>
>>>>> habitat
>>>>> proportion_use
>>>>> proportion_use_SE
>>>>> selectivity_index
>>>>> selectivity_index_SE
>>>>> grassland
>>>>> 0.56
>>>>> 0.22
>>>>> 0.72
>>>>> 0.29
>>>>> sal_forest
>>>>> 0.11
>>>>> 0.04
>>>>> -0.43
>>>>> 0.13
>>>>> bamboo-mix
>>>>> 0.22
>>>>> 0.07
>>>>> 0.05
>>>>> 0.02
>>>>> miscellaneous
>>>>> 0.11
>>>>> 0.03
>>>>> -0.59
>>>>> 0.18
>>>>>
>>>>>> excel-graphics
>>>>>>
>>>>>
>>>>>
>>>>> regards:
>>>>> Ujjwal
>>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>> --
>>> Michael
>>> http://www.dewey.myzen.co.uk/home.html
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>
> --
> with regards
> Ujjwal Kumar
> *Research Fellow*
> Project: "Monitoring Source Population of Tigers in Kanha Tiger Reserve"
> Wildlife Institute of India
> mobile: +91 9808712591(Dehradun)
>                 +919407344453  (Kanha)
>
>    P.O. Box 18 Chandrabani
>   Dehradun (Uttarakhand) 248001
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Oct 26 01:32:35 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Oct 2015 11:32:35 +1100
Subject: [R] How to plott bar graphics
In-Reply-To: <562CC999.5000208@dewey.myzen.co.uk>
References: <CAGV0xWmkuW-UmeubZGch9tXSGw5NETJy6jRhSt7c1Ok-u1+xuQ@mail.gmail.com>
	<562CC999.5000208@dewey.myzen.co.uk>
Message-ID: <CA+8X3fWXkaiw9V45FfvnKBVEg0uR_zmTEs43iPOduTKDA=z6jA@mail.gmail.com>

Hi Ujjwal,
Given that you have asked about a barplot and included standard errors, you
probably want something like the following:

uk.df<-read.table(text=
 "habitat,proportion_use,proportion_use_SE,selectivity_index,selectivity_index_SE
 grassland,0.56,0.22,0.72,0.29
 sal_forest,0.11,0.04,-0.43,0.13
 bamboo-mix,0.22,0.07,0.05,0.02
 miscellaneous,0.11,0.03,-0.59,0.18",sep=",",header=TRUE)
library(plotrix)
barpos<-barp(uk.df[c("proportion_use","selectivity_index")],
 names.arg=c("proportion_use","selectivity_index"),
 main="Habitat Use Plot",ylab="Proportion of use",
 col=2:5,ylim=c(-1,1.1))
dispersion(barpos$x,barpos$y,
 ulim=as.matrix(uk.df[c("proportion_use_SE","selectivity_index_SE")]))
legend(0.7,-0.3,uk.df$habitat,fill=2:4)

You will almost certainly be told that you shouldn't do this, so maybe you
should consider:

matplot(matrix(c(0.9,1.1,1.9,2.1,2.9,3.1,3.9,4.1),nrow=4,byrow=TRUE),
 uk.df[c("proportion_use","selectivity_index")],
 ylab="Proportion and selectivity of use",
 ylim=c(-1,1.1),pch=18:19,col=2:3,xaxt="n",xlab="Habitat",
 main="Habitat Use Plot")
axis(1,at=1:4,labels=uk.df$habitat)
dispersion(matrix(c(0.9,1.1,1.9,2.1,2.9,3.1,3.9,4.1),nrow=4,byrow=TRUE),
 as.matrix(uk.df[c("proportion_use","selectivity_index")]),
 ulim=as.matrix(uk.df[c("proportion_use_SE","selectivity_index_SE")]))
legend(2.5,1,c("Proportion of use","Selectivity of use"),
 pch=18:19,col=2:3)

Jim


On Sun, Oct 25, 2015 at 11:22 PM, Michael Dewey <lists at dewey.myzen.co.uk>
wrote:

> Dear Ujjwal
>
> Two problems
> 1 - you posted in HTML so your post is unreadable
> 2 - your attached graphic was not in one of the formats which R-help
> accepts and so was stripped
>
>
> On 25/10/2015 11:04, Ujjwal Kumar wrote:
>
>> HI friends
>> I am struggling in plotting bar graph with this data sets in R. although I
>> can plot it in Microsoft excel( attached graphics). I need help in coding
>> it for R.(SE=standar error)
>>
>>> data
>>>>
>>> habitat
>>> proportion_use
>>> proportion_use_SE
>>> selectivity_index
>>> selectivity_index_SE
>>> grassland
>>> 0.56
>>> 0.22
>>> 0.72
>>> 0.29
>>> sal_forest
>>> 0.11
>>> 0.04
>>> -0.43
>>> 0.13
>>> bamboo-mix
>>> 0.22
>>> 0.07
>>> 0.05
>>> 0.02
>>> miscellaneous
>>> 0.11
>>> 0.03
>>> -0.59
>>> 0.18
>>>
>>>> excel-graphics
>>>>
>>>
>>>
>>> regards:
>>> Ujjwal
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> --
> Michael
> http://www.dewey.myzen.co.uk/home.html
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Oct 26 03:01:22 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 26 Oct 2015 13:01:22 +1100
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <80147FF5-44BC-4008-8815-98DA25B75399@utoronto.ca>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz>
	<80147FF5-44BC-4008-8815-98DA25B75399@utoronto.ca>
Message-ID: <CA+8X3fUfmPwbOkdff4T35uydZnz4VkNWNAueWb7WK_4sHLm1Dg@mail.gmail.com>

On Mon, Oct 26, 2015 at 10:44 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> Ming is right.

...

Having started all this trouble, I suppose I should offer a modest
explanation.

The OP was indeed "right" in the sense that the column heading did not
indicate the correct _units_ for the values. I suppose that "kilopounds"
would be the correct units if such a unit was acceptable to the relevant
standards committee. As Boris noted, lb/1000 is (sort of) the
transformation used to get the values. Given the burning interest in this
distinction between units (as used to explicitly back transform the values)
and and explanatory labels (how did these values come to be?) I should
state that the objection I refrained from adding to my original answer was,
'Why didn't they just leave the values in the initial units?"

I was reminded of a long past physics lecturer's favorite units of velocity
- furlongs per fortnight.

Jim

	[[alternative HTML version deleted]]


From alexander.thomas.1 at louisville.edu  Mon Oct 26 03:20:26 2015
From: alexander.thomas.1 at louisville.edu (alexander.thomas.1 at louisville.edu)
Date: Mon, 26 Oct 2015 02:20:26 +0000
Subject: [R] Function help
Message-ID: <1487D73C-B4C6-403F-9BEE-8BBCFC84744D@cardmail.louisville.edu>

Hello,

I'm following an example in the book, analyzing baseball data with R, but it's not working for me. The example is:

compute.hr <- function(pid){d <- subset(Batting.60, playerID==pid)
sum(d$HR)}

Every time I try this, it says there's an unexpected symbol. Any idea on what the unexpected symbol is or how to fix it? Thanks.


From amelia_marsh08 at yahoo.com  Mon Oct 26 08:44:38 2015
From: amelia_marsh08 at yahoo.com (Amelia Marsh)
Date: Mon, 26 Oct 2015 07:44:38 +0000 (UTC)
Subject: [R] Monte Carlo Simulation Convergence test
References: <360819009.2485138.1445845478970.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <360819009.2485138.1445845478970.JavaMail.yahoo@mail.yahoo.com>

Dear Forum, 

I have series of say 100 (say equity) instrument prices. From these prices, for each of these 100 instruments, I generate returns using ln(current price / previous price). 

Assuming originally I had 251 prices available for each of these 100 instruments over last one year period, I have matrix of 250X100 returns.

I assume that these returns follow Multivariate Normal Distribution. Using the returns, I generate a mean Vector of returns 'M' and also generate the Variance - covariance matrix of returns 'S'.

Then using MASS library, I simulate say 10000 returns for each of the 100 instruments as :

sim_rates = mvrnorm(10000, M, S) 

This gives me 10000 simulated returns for each of the 100 instruments and using these simulated returns carry out further analysis.

My query is how do I carry out convergence test in R to arrive at sufficint number of simulations? 


With reagrds

Amelia


From jlorenz at uni-goettingen.de  Mon Oct 26 11:24:16 2015
From: jlorenz at uni-goettingen.de (Lorenz, Jennifer)
Date: Mon, 26 Oct 2015 10:24:16 +0000
Subject: [R] Creating new variables in R
Message-ID: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>

Hi,

I  have a question regarding the creation of new variables on the basis of existing ones in R.

I have two variables containing information on parents' educational degree (e.g. 1 'high school degree', 2 'college degree', etc.). I would like to create a new variable for 'parents' highest educational degree', i.e. if variable1 (father's degree) is higher than variable2 (mother's degree) than the new variable (variable3) should take on the value of variable1, if not, than variable3 should take on the value of variable2.

I usually use SPSS for data manipulation, there I would code variable3 as follows:
COMPUTE variable3= 0.
IF variable1 > variable2 variable3= variable1.
IF variable1 <= variable2 variable3= variable2.

The closest I came to that in R was with this code:
data$variable3 <- 0
data$variable3[data$variable1 > data$variable2]<-data$variable1
data$variable3[data$variable1 <= data$variable2]<-data$variable2

I also tried:
data$variable3 <- ifelse(data$variable1 > data$variable2), data$variable1, data$variable2)

Both didn't work.

I am not sure if my post is at all understandable (this is my first time posting on R-help), but I am really hoping for some advice!
Thanks!
Jen



---
Jennifer Lorenz, M.A.
Georg-August-Universit?t G?ttingen
Sozialwissenschaftliche Fakult?t
Institut f?r Erziehungswissenschaft
Lehrstuhl Schulp?dagogik / Empirische Schulforschung

e-mail: jlorenz at uni-goettingen.de
phone: 0551-39-21411
adress: Waldweg 26, 37073 G?ttingen
room: 8.106

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Oct 26 11:58:28 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Oct 2015 06:58:28 -0400
Subject: [R] Creating new variables in R
In-Reply-To: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>
References: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>
Message-ID: <562E0754.4020300@gmail.com>

On 26/10/2015 6:24 AM, Lorenz, Jennifer wrote:
> Hi,
> 
> I  have a question regarding the creation of new variables on the basis of existing ones in R.
> 
> I have two variables containing information on parents' educational degree (e.g. 1 'high school degree', 2 'college degree', etc.). I would like to create a new variable for 'parents' highest educational degree', i.e. if variable1 (father's degree) is higher than variable2 (mother's degree) than the new variable (variable3) should take on the value of variable1, if not, than variable3 should take on the value of variable2.
> 
> I usually use SPSS for data manipulation, there I would code variable3 as follows:
> COMPUTE variable3= 0.
> IF variable1 > variable2 variable3= variable1.
> IF variable1 <= variable2 variable3= variable2.
> 
> The closest I came to that in R was with this code:
> data$variable3 <- 0
> data$variable3[data$variable1 > data$variable2]<-data$variable1
> data$variable3[data$variable1 <= data$variable2]<-data$variable2
> 
> I also tried:
> data$variable3 <- ifelse(data$variable1 > data$variable2), data$variable1, data$variable2)
> 
> Both didn't work.
> 
> I am not sure if my post is at all understandable (this is my first time posting on R-help), but I am really hoping for some advice!

This is a good place to use the ifelse() function:

data$variable3 <- ifelse(data$variable1 > data$variable2,
                         data$variable1, data$variable2)

Duncan Murdoch


From murdoch.duncan at gmail.com  Mon Oct 26 12:00:24 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Oct 2015 07:00:24 -0400
Subject: [R] Function help
In-Reply-To: <1487D73C-B4C6-403F-9BEE-8BBCFC84744D@cardmail.louisville.edu>
References: <1487D73C-B4C6-403F-9BEE-8BBCFC84744D@cardmail.louisville.edu>
Message-ID: <562E07C8.70806@gmail.com>

On 25/10/2015 10:20 PM, alexander.thomas.1 at louisville.edu wrote:
> Hello,
> 
> I'm following an example in the book, analyzing baseball data with R, but it's not working for me. The example is:

We don't know what "the book" is.  If this is the textbook for your
class, you should ask your instructor for help.
> 
> compute.hr <- function(pid){d <- subset(Batting.60, playerID==pid)
> sum(d$HR)}

That works for me.

Duncan Murdoch

> 
> Every time I try this, it says there's an unexpected symbol. Any idea on what the unexpected symbol is or how to fix it? Thanks.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Oct 26 12:21:32 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Oct 2015 07:21:32 -0400
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <80147FF5-44BC-4008-8815-98DA25B75399@utoronto.ca>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz>
	<80147FF5-44BC-4008-8815-98DA25B75399@utoronto.ca>
Message-ID: <562E0CBC.4050208@gmail.com>

On 25/10/2015 7:44 PM, Boris Steipe wrote:
> Ming is right. I can't imagine other discipline's standards are substantially different from ours, but e.g. the ACS style manual is very explicit to require ...
> 
>    "Label each axis with the parameter or variable being measured and the units of measure in parentheses."
> 
> The _units_ are not lb/1000. 1/1000 is a _transformation_ of the value, the unit is lb, or in that case (1000 lb). Writing lb/1000 is just as nonsensical as writing g/k instead of (kg). 1000 is simply a numerical prefix to the unit, like kilo.
> 
> It gets worse: According to the UK metric association:
>    "The symbol for "per" (meaning "divided by") is ?/? (slash)."

How is that relevant?  We aren't trying to represent "per" here, we are
trying to represent "divided by".

The only valid argument I've heard so far is that we should use what the
cited paper used.  That was "1000 lbs", so I'll change it.

Duncan Murdoch

> 
> Accordingly, "lb/1000" is to be read "pounds per 1000" which is actually wrong by six orders of magnitude. 
> 
> I don't think there is ambiguity here nor occasion for sophistry: as written, the label is wrong. It would be more than appropriate for a community that is passionate about data to correct this.
> 
> 
> :-)
> Boris
> 
> (Good Lord! https://xkcd.com/386/)
> 
> On Oct 24, 2015, at 6:07 PM, Rolf Turner <r.turner at auckland.ac.nz> wrote:
> 
>> On 24/10/15 21:10, Jim Lemon wrote:
>>> Hi Ming,
>>> In fact, the notation lb/1000 is correct, as the values represent the
>>> weight of the cars in pounds (lb) divided by 1000. I am not sure why this
>>> particular transformation of the measured values was used, but I'm sure it
>>> has caused confusion previously.
>>
>> I disagree --- and agree with Ming.  The notation is incorrect.  Surely
>> "lb/1000" means thousandths of pounds.  E.g. 12345 lb/1000 is equal to
>> 12.345 lb.
>>
>> I'm sure that others will come up with all sorts of convoluted lawyerish arguments that the case is otherwise, but as far as I am concerned, any *sane* person would interpret "lb/1000" to mean thousandths of pounds.
>>
>> If in the unlikely event that the documentation for some data set said "Weight (gm/1000)", I'm pretty sure that this would be interpreted to mean milligrams and *not* kilograms!
>>
>> Since the description of the data was presumably taken from that given in the original source ("Motor Trend" magazine) it would probably be inappropriate to "correct" it.  However a note/warning should be added to the mtcars help file indicating that Motor Trend got things upside-down.
>>
>> cheers,
>>
>> Rolf
>>
>> -- 
>> Technical Editor ANZJS
>> Department of Statistics
>> University of Auckland
>> Phone: +64-9-373-7599 ext. 88276
>>
>>> On Sat, Oct 24, 2015 at 11:59 AM, Ming-Lun Ho <minglho at gmail.com> wrote:
>>>
>>>> Hi,
>>>>     I used "?mtcars" to read the documentation for the dataset. I found a
>>>> mistake in how unit is listed, namely, that for the variable "wt," the unit
>>>> should be listed as "1000 lb," not "lb/1000." However, I don't know whom to
>>>> contact exactly for the correction. Please point me to the right place.
>>>>     Thanks.
>>>>           --Ming
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Mon Oct 26 12:53:02 2015
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 26 Oct 2015 11:53:02 +0000
Subject: [R] Creating new variables in R
In-Reply-To: <562E0754.4020300@gmail.com>
References: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>
	<562E0754.4020300@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFC76B@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan
> Murdoch
> Sent: Monday, October 26, 2015 11:58 AM
> To: Lorenz, Jennifer; r-help at r-project.org
> Subject: Re: [R] Creating new variables in R
>
> On 26/10/2015 6:24 AM, Lorenz, Jennifer wrote:
> > Hi,
> >
> > I  have a question regarding the creation of new variables on the
> basis of existing ones in R.
> >
> > I have two variables containing information on parents' educational
> degree (e.g. 1 'high school degree', 2 'college degree', etc.). I would
> like to create a new variable for 'parents' highest educational
> degree', i.e. if variable1 (father's degree) is higher than variable2
> (mother's degree) than the new variable (variable3) should take on the
> value of variable1, if not, than variable3 should take on the value of
> variable2.
> >
> > I usually use SPSS for data manipulation, there I would code
> variable3 as follows:
> > COMPUTE variable3= 0.
> > IF variable1 > variable2 variable3= variable1.
> > IF variable1 <= variable2 variable3= variable2.
> >
> > The closest I came to that in R was with this code:
> > data$variable3 <- 0
> > data$variable3[data$variable1 > data$variable2]<-data$variable1
> > data$variable3[data$variable1 <= data$variable2]<-data$variable2
> >
> > I also tried:
> > data$variable3 <- ifelse(data$variable1 > data$variable2),
> > data$variable1, data$variable2)
> >
> > Both didn't work.

The ifelse version should work. Are you sure that variable 1 and 2 are numeric?.

What is a result of str(data)?

Cheers
Petr

> >
> > I am not sure if my post is at all understandable (this is my first
> time posting on R-help), but I am really hoping for some advice!
>
> This is a good place to use the ifelse() function:
>
> data$variable3 <- ifelse(data$variable1 > data$variable2,
>                          data$variable1, data$variable2)
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From erich.neuwirth at univie.ac.at  Mon Oct 26 13:02:44 2015
From: erich.neuwirth at univie.ac.at (Erich Neuwirth)
Date: Mon, 26 Oct 2015 13:02:44 +0100
Subject: [R] Creating new variables in R
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFC76B@SRVEXCHMBX.precheza.cz>
References: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>
	<562E0754.4020300@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFC76B@SRVEXCHMBX.precheza.cz>
Message-ID: <1531B7E1-C8ED-4220-B1A4-161153099D55@univie.ac.at>

data <- within(data,variable3=pmax(variable1,variable2))
also should work if your variables are numeric.

using dplyr and magrittr (which I recommend to all my students)
it could be

library(dplyr)
library(magrittr)
data %<>% mutate(variable3=pmax(variable1,variable2))



> On 26 Oct 2015, at 12:53, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> 
> Hi
> 
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org>] On Behalf Of Duncan
>> Murdoch
>> Sent: Monday, October 26, 2015 11:58 AM
>> To: Lorenz, Jennifer; r-help at r-project.org <mailto:r-help at r-project.org>
>> Subject: Re: [R] Creating new variables in R
>> 
>> On 26/10/2015 6:24 AM, Lorenz, Jennifer wrote:
>>> Hi,
>>> 
>>> I  have a question regarding the creation of new variables on the
>> basis of existing ones in R.
>>> 
>>> I have two variables containing information on parents' educational
>> degree (e.g. 1 'high school degree', 2 'college degree', etc.). I would
>> like to create a new variable for 'parents' highest educational
>> degree', i.e. if variable1 (father's degree) is higher than variable2
>> (mother's degree) than the new variable (variable3) should take on the
>> value of variable1, if not, than variable3 should take on the value of
>> variable2.
>>> 
>>> I usually use SPSS for data manipulation, there I would code
>> variable3 as follows:
>>> COMPUTE variable3= 0.
>>> IF variable1 > variable2 variable3= variable1.
>>> IF variable1 <= variable2 variable3= variable2.
>>> 
>>> The closest I came to that in R was with this code:
>>> data$variable3 <- 0
>>> data$variable3[data$variable1 > data$variable2]<-data$variable1
>>> data$variable3[data$variable1 <= data$variable2]<-data$variable2
>>> 
>>> I also tried:
>>> data$variable3 <- ifelse(data$variable1 > data$variable2),
>>> data$variable1, data$variable2)
>>> 
>>> Both didn't work.
> 
> The ifelse version should work. Are you sure that variable 1 and 2 are numeric?.
> 
> What is a result of str(data)?
> 
> Cheers
> Petr
> 
>>> 
>>> I am not sure if my post is at all understandable (this is my first
>> time posting on R-help), but I am really hoping for some advice!
>> 
>> This is a good place to use the ifelse() function:
>> 
>> data$variable3 <- ifelse(data$variable1 > data$variable2,
>>                         data$variable1, data$variable2)
>> 
>> Duncan Murdoch
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> 
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> 
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> 
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 670 bytes
Desc: Message signed with OpenPGP using GPGMail
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151026/68b9e735/attachment.bin>

From jrkrideau at inbox.com  Mon Oct 26 13:28:06 2015
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 26 Oct 2015 04:28:06 -0800
Subject: [R] How to plott bar graphics
In-Reply-To: <CA+8X3fWXkaiw9V45FfvnKBVEg0uR_zmTEs43iPOduTKDA=z6jA@mail.gmail.com>
References: <cagv0xwmkuw-umeubzgch9txsgw5netjy6jrhst7c1ok-u1+xuq@mail.gmail.com>
	<562cc999.5000208@dewey.myzen.co.uk>
Message-ID: <DBDD8BF11E1.0000019Djrkrideau@inbox.com>

Hhi Ujjwal

As Jim says a lot of people don't like the barplot with error bars approach see http://biostat.mc.vanderbilt.edu/wiki/Main/DynamitePlots and links for some of the reasons  why.

Besides, in Tufte's terms most of a barplot is 'chart junk'.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: drjimlemon at gmail.com
> Sent: Mon, 26 Oct 2015 11:32:35 +1100
> To:
> Subject: Re: [R] How to plott bar graphics
> 
> Hi Ujjwal,
> Given that you have asked about a barplot and included standard errors,
> you
> probably want something like the following:
> 
> uk.df<-read.table(text=
>  "habitat,proportion_use,proportion_use_SE,selectivity_index,selectivity_index_SE
>  grassland,0.56,0.22,0.72,0.29
>  sal_forest,0.11,0.04,-0.43,0.13
>  bamboo-mix,0.22,0.07,0.05,0.02
>  miscellaneous,0.11,0.03,-0.59,0.18",sep=",",header=TRUE)
> library(plotrix)
> barpos<-barp(uk.df[c("proportion_use","selectivity_index")],
>  names.arg=c("proportion_use","selectivity_index"),
>  main="Habitat Use Plot",ylab="Proportion of use",
>  col=2:5,ylim=c(-1,1.1))
> dispersion(barpos$x,barpos$y,
>  ulim=as.matrix(uk.df[c("proportion_use_SE","selectivity_index_SE")]))
> legend(0.7,-0.3,uk.df$habitat,fill=2:4)
> 
> You will almost certainly be told that you shouldn't do this, so maybe
> you
> should consider:
> 
> matplot(matrix(c(0.9,1.1,1.9,2.1,2.9,3.1,3.9,4.1),nrow=4,byrow=TRUE),
>  uk.df[c("proportion_use","selectivity_index")],
>  ylab="Proportion and selectivity of use",
>  ylim=c(-1,1.1),pch=18:19,col=2:3,xaxt="n",xlab="Habitat",
>  main="Habitat Use Plot")
> axis(1,at=1:4,labels=uk.df$habitat)
> dispersion(matrix(c(0.9,1.1,1.9,2.1,2.9,3.1,3.9,4.1),nrow=4,byrow=TRUE),
>  as.matrix(uk.df[c("proportion_use","selectivity_index")]),
>  ulim=as.matrix(uk.df[c("proportion_use_SE","selectivity_index_SE")]))
> legend(2.5,1,c("Proportion of use","Selectivity of use"),
>  pch=18:19,col=2:3)
> 
> Jim
> 
> 
> On Sun, Oct 25, 2015 at 11:22 PM, Michael Dewey <lists at dewey.myzen.co.uk>
> wrote:
> 
>> Dear Ujjwal
>> 
>> Two problems
>> 1 - you posted in HTML so your post is unreadable
>> 2 - your attached graphic was not in one of the formats which R-help
>> accepts and so was stripped
>> 
>> 
>> On 25/10/2015 11:04, Ujjwal Kumar wrote:
>> 
>>> HI friends
>>> I am struggling in plotting bar graph with this data sets in R.
>>> although I
>>> can plot it in Microsoft excel( attached graphics). I need help in
>>> coding
>>> it for R.(SE=standar error)
>>> 
>>>> data
>>>>> 
>>>> habitat
>>>> proportion_use
>>>> proportion_use_SE
>>>> selectivity_index
>>>> selectivity_index_SE
>>>> grassland
>>>> 0.56
>>>> 0.22
>>>> 0.72
>>>> 0.29
>>>> sal_forest
>>>> 0.11
>>>> 0.04
>>>> -0.43
>>>> 0.13
>>>> bamboo-mix
>>>> 0.22
>>>> 0.07
>>>> 0.05
>>>> 0.02
>>>> miscellaneous
>>>> 0.11
>>>> 0.03
>>>> -0.59
>>>> 0.18
>>>> 
>>>>> excel-graphics
>>>>> 
>>>> 
>>>> 
>>>> regards:
>>>> Ujjwal
>>>> 
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> --
>> Michael
>> http://www.dewey.myzen.co.uk/home.html
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From S.Ellison at LGCGroup.com  Mon Oct 26 13:29:56 2015
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 26 Oct 2015 12:29:56 +0000
Subject: [R] regex not working for some entries in for loop
In-Reply-To: <CAM-xyZhnaDRLDp7S=Ln-9dNs=4jdZjRdUh2aKkHkpJLqwhrK0g@mail.gmail.com>
References: <CAM-xyZhnaDRLDp7S=Ln-9dNs=4jdZjRdUh2aKkHkpJLqwhrK0g@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E2672403C79B452B@GBTEDVPEXCMB04.corp.lgc-group.com>



> From: Omar Andr? Gonz?les D?az
> Subject: [R] regex not working for some entries in for loop
> 
> I'm using some regex in a for loop to check for some values in column "source",
> and put a result in column "fuente".

Your regexes are on multiple lines and include whitespace and linefeeds. For example you are not testing for 
" .*forum.*|.*buy.*"; you are testing for 
" .*forum.*|
                      .*buy.*"
(which among other things includes a \n)
Don?t do that. Keep it to one line with no white space.
if you must have line breaks in the code, form the pattern using paste, as in
pat1 <- paste(c("site.*", ".*event.*", ".*free.*", ".*theguardlan.*", 
	".*guardlink.*", ".*torture.*", ".*forum.*", ".*buy.*", 
	".*share.*", ".*buttons.*", ".*pyme\\.lavoztx\\.com\\.*", 
	".*amezon.*", "computrabajo.com.pe", ".*porn.*", "quality"),
	collapse="|")

spam <- grepl(pat1, sf$source,ignore.case = T)

Also, it's not immediately clear why you?re looping. grepl returns a vector of logicals; you have a vector of character strings. Consider replacing 'if' constructs with 'ifelse' - albeit a complicated ifelse() - and doing the whole thing without a loop.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From kw1958 at gmail.com  Mon Oct 26 14:16:47 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Mon, 26 Oct 2015 09:16:47 -0400
Subject: [R] Having trouble updating and installing R 3.2.1 and 3.2.2
In-Reply-To: <A529BB44-6905-4AD0-B33C-0332A8181206@dcn.davis.CA.us>
References: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>
	<A529BB44-6905-4AD0-B33C-0332A8181206@dcn.davis.CA.us>
Message-ID: <FE1D3C18-95AA-4D73-8105-27349CB3CD27@gmail.com>

I uninstalled all versions of R on my computer and killed all R directories (I think).

I am wondering that since I ?upgraded? to Windows 10 is it possible that I should create a user separate from the administrator account? My previous version of Windows was 7 Home I think. 

Here is a longer version of the error messages that I get.

> install.packages("sm")
Installing package into ?C:/Users/Administrator/My Documents/R/win-library/3.2?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
Warning: unable to access index for repository https://cran.cnr.Berkeley.edu/src/contrib
Warning: unable to access index for repository https://cran.cnr.Berkeley.edu/bin/windows/contrib/3.2
Warning messages:
1: In normalizePath(path.expand(path), winslash, mustWork) :
  path[1]="C:/Users/Administrator/My Documents/R/win-library/3.2": Access is denied
2: package ?sm? is not available (for R version 3.2.2) 


Thanks for your help,
KW


> On Oct 25, 2015, at 7:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
> 
> I would guess that you ran R as administrator at some point and now you have a permissions problem on your user library. I can't say I know how to fix it, though using administrator mode to fix the permissions is probably hard while using administrator mode to delete the R directory and reinstalling your packages might be easier.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 25, 2015 7:50:07 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> I get the following error:
>> 
>> Warning message:
>> In normalizePath(path.expand(path), winslash, mustWork) :
>> path[1]="C:\Users\Administrator\My Documents/R/win-library/3.2": Access
>> is denied
>> 
>> This may be the first time that I have tried to upgrade R since I
>> upgraded my Windows installation (on Parallels on my Mac no less) to
>> Windows 10.
>> 
>> Needless to say when I try to install packages outside of core CRAN I
>> have issues.
>> 
>> Any help is greatly appreciated.
>> 
>> Thanks much,
>> KW
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From jdnewmil at dcn.davis.CA.us  Mon Oct 26 14:49:42 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 26 Oct 2015 06:49:42 -0700
Subject: [R] Having trouble updating and installing R 3.2.1 and 3.2.2
In-Reply-To: <FE1D3C18-95AA-4D73-8105-27349CB3CD27@gmail.com>
References: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>
	<A529BB44-6905-4AD0-B33C-0332A8181206@dcn.davis.CA.us>
	<FE1D3C18-95AA-4D73-8105-27349CB3CD27@gmail.com>
Message-ID: <571C6FFB-98F1-4268-A1DB-60F83C7EF53E@dcn.davis.CA.us>

I have not used W10, but for quite awhile the *administrator" account (not the hidden one named "Administrator") has merely had the right to "Run As Administrator"... but doing so explicitly is not recommended unless you definitely know what you are doing (in which case you should not be asking for help here). As long as you let the UAC (User Account Control) prompt you at the necessary moments you should not have permissions trouble. If you have followed this advice already then there might be a bug in the installer, but I would have thought I would have seen more complaints by now if it was a bug.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 26, 2015 6:16:47 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>I uninstalled all versions of R on my computer and killed all R
>directories (I think).
>
>I am wondering that since I ?upgraded? to Windows 10 is it possible
>that I should create a user separate from the administrator account? My
>previous version of Windows was 7 Home I think. 
>
>Here is a longer version of the error messages that I get.
>
>> install.packages("sm")
>Installing package into ?C:/Users/Administrator/My
>Documents/R/win-library/3.2?
>(as ?lib? is unspecified)
>--- Please select a CRAN mirror for use in this session ---
>Warning: unable to access index for repository
>https://cran.cnr.Berkeley.edu/src/contrib
>Warning: unable to access index for repository
>https://cran.cnr.Berkeley.edu/bin/windows/contrib/3.2
>Warning messages:
>1: In normalizePath(path.expand(path), winslash, mustWork) :
>path[1]="C:/Users/Administrator/My Documents/R/win-library/3.2": Access
>is denied
>2: package ?sm? is not available (for R version 3.2.2) 
>
>
>Thanks for your help,
>KW
>
>
>> On Oct 25, 2015, at 7:15 PM, Jeff Newmiller
><jdnewmil at dcn.davis.CA.us> wrote:
>> 
>> I would guess that you ran R as administrator at some point and now
>you have a permissions problem on your user library. I can't say I know
>how to fix it, though using administrator mode to fix the permissions
>is probably hard while using administrator mode to delete the R
>directory and reinstalling your packages might be easier.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>
>> Sent from my phone. Please excuse my brevity.
>> 
>> On October 25, 2015 7:50:07 AM PDT, Keith S Weintraub
><kw1958 at gmail.com> wrote:
>>> I get the following error:
>>> 
>>> Warning message:
>>> In normalizePath(path.expand(path), winslash, mustWork) :
>>> path[1]="C:\Users\Administrator\My Documents/R/win-library/3.2":
>Access
>>> is denied
>>> 
>>> This may be the first time that I have tried to upgrade R since I
>>> upgraded my Windows installation (on Parallels on my Mac no less) to
>>> Windows 10.
>>> 
>>> Needless to say when I try to install packages outside of core CRAN
>I
>>> have issues.
>>> 
>>> Any help is greatly appreciated.
>>> 
>>> Thanks much,
>>> KW
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From caciquesamurai at gmail.com  Mon Oct 26 16:35:58 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Mon, 26 Oct 2015 13:35:58 -0200
Subject: [R] Formating time in R
Message-ID: <CAGtwFe2fXE72uJ-ZijV8aS=s5oaACObsMZms69SpnX-yZ8-NfQ@mail.gmail.com>

Hello R-Helpers!

I have a vector of times of events that time is fraction of 1, because it
was calculated in excel. Are there some way to format a period greater than
24h in a format like excel [h]:mm:ss?

Exemple:

test = c(1.424708, 0.028674)

> chron (times. = test [2], format = "h:m:S")
[1] 00:41:17

> chron (times. = test, format = "h:m:S")
Time in days:
[1] 1.424708 0.028674

I need an output like:

*34:11:35* 0:41:17

Thanks in advanced,

Raoni
-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com

	[[alternative HTML version deleted]]


From eugen_pircalabelu at yahoo.com  Mon Oct 26 13:39:10 2015
From: eugen_pircalabelu at yahoo.com (eugen pircalabelu)
Date: Mon, 26 Oct 2015 12:39:10 +0000 (UTC)
Subject: [R] elementwise matrix multiplication with a special structure
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D3805@mb02.ads.tamu.edu>
References: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D3805@mb02.ads.tamu.edu>
Message-ID: <918237533.3132857.1445863150105.JavaMail.yahoo@mail.yahoo.com>

Hello again,
Thanks for your reply and sorry for my own late reply! ?I am writing from a normal yahoo account so i don't know why it behaves like this. I was looking to avoid the expand.grid command because my matrices are of size 800x800 (i have some filters that exclude out some elements, so i don't need to pass by everything, but still) which is quickly too heavy for R but still doable in C.?
Thanks a lot and have ?a great day ahead!Eugen



 

     From: David L Carlson <dcarlson at tamu.edu>
 To: eugen pircalabelu <eugen_pircalabelu at yahoo.com> 
 Sent: Friday, October 23, 2015 9:21 PM
 Subject: RE: [R] elementwise matrix multiplication with a special structure
   
Don't use html formatted emails. The r-help server strips the html formatting leaving us the the mess you see below. 

You don't need any loops:

> aa <- matrix(1:9, 3, 3)
> bb <- aa * 10
> cc <- bb * 10
> x <- as.matrix(expand.grid(k=1:3, j=1:3, c=1:3, r=1:3))
> str(x)
 int [1:81, 1:4] 1 2 3 1 2 3 1 2 3 1 ...
 - attr(*, "dimnames")=List of 2
? ..$ : NULL
? ..$ : chr [1:4] "k" "j" "c" "r"
> dd <- aa[x[, c("j", "k")]] * bb[x[, c("r", "j")]] * cc[x[, c("k", "c")]]
> dd
 [1]? 1000? 8000? 21000? 8000? 40000? 96000? 21000? 84000 189000
[10]? 4000? 20000? 42000? 32000 100000 192000? 84000 210000 378000
[19]? 7000? 32000? 63000? 56000 160000 288000 147000 336000 567000
[28]? 2000? 16000? 42000? 10000? 50000 120000? 24000? 96000 216000
[37]? 8000? 40000? 84000? 40000 125000 240000? 96000 240000 432000
[46]? 14000? 64000 126000? 70000 200000 360000 168000 384000 648000
[55]? 3000? 24000? 63000? 12000? 60000 144000? 27000 108000 243000
[64]? 12000? 60000 126000? 48000 150000 288000 108000 270000 486000
[73]? 21000? 96000 189000? 84000 240000 432000 189000 432000 729000

# Or a bit more compactly
> dd <- aa[x[, c(2, 1)]] * bb[x[, c(4, 2)]] * cc[x[, c(1, 3)]]

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352





-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of eugen pircalabelu via R-help
Sent: Friday, October 23, 2015 12:31 PM
To: r-help at r-project.org
Subject: [R] elementwise matrix multiplication with a special structure

Hello R users,
I have the following annoying matrix multiplication and I do not know how to avoid the nested loops, so maybe someone can help me with some ideas. I have searched the forum for past posts but nothing came up.Here it is:
?aa=matrix(1:9,3,3)?bb=matrix(seq(10,90,by=10),3,3)?cc=matrix(seq(100,900, by=100),3,3)?dd=NULL 
for(r in 1:3){????for(c in 1:3){????????for(j in 1:3){????????????for(k in 1:3){dd=c(dd,aa[j,k]*bb[r,j]*cc[k,c])}}}}dd?[1] ? 1000 ? 8000 ?21000 ? 8000 ?40000 ?96000 ?21000 ?84000 189000 ? 4000[11] ?20000 ?42000 ?32000 100000 192000 ?84000 210000 378000 ? 7000 ?32000[21] ?63000 ?56000 160000 288000 147000 336000 567000 ? 2000 ?16000 ?42000[31] ?10000 ?50000 120000 ?24000 ?96000 216000 ? 8000 ?40000 ?84000 ?40000[41] 125000 240000 ?96000 240000 432000 ?14000 ?64000 126000 ?70000 200000[51] 360000 168000 384000 648000 ? 3000 ?24000 ?63000 ?12000 ?60000 144000[61] ?27000 108000 243000 ?12000 ?60000 126000 ?48000 150000 288000 108000[71] 270000 486000 ?21000 ?96000 189000 ?84000 240000 432000 189000 432000[81] 729000
What I want to obtain is the content of the vector dd in an efficient (fast) and clever way.Thank you very much and have a great day ahead!Eugen

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


  
	[[alternative HTML version deleted]]


From martin.canon at gmail.com  Mon Oct 26 12:52:31 2015
From: martin.canon at gmail.com (Martin Canon)
Date: Mon, 26 Oct 2015 06:52:31 -0500
Subject: [R] y2z question (AGD)
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D407B@mb02.ads.tamu.edu>
References: <CAD3qanComneme+Axw39gAW_kE2pCTqF8XE5A4dun3mAn+96j_g@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D407B@mb02.ads.tamu.edu>
Message-ID: <CAD3qanBL3W6rdV9POtQJ-_Z5YhxwxkvSa=bp0eg0nJp2SqmMMw@mail.gmail.com>

Thank you, David.

This solves the problem.

Regards,

Martin

On Sun, Oct 25, 2015 at 12:53 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> It looks like the y2z() function strips NA's so that the vector lengths do
> not match any longer. The simplest workaround is to remove the NA's. You
> could do that by using data2 <- na.omit(data) to strip the observations
> with NA if they will not be used in the rest of the analysis.
>
> If you want to preserve the NAs in the data frame, this seems to work:
>
> > nomiss <- complete.cases(data)
> > data$zeta[nomiss] <- with(data[nomiss, ], y2z(weight, age/12, sex,
> ref=who.wgt))
> > data
>   sex weight age   zeta
> 1   M    8.5   8 -0.124
> 2   M    8.2   9 -0.751
> 3   M    9.0  12 -0.635
> 4   F     NA   9     NA
> 5   M    5.8   1  2.002
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin
> Canon
> Sent: Sunday, October 25, 2015 7:03 AM
> To: R help <r-help at r-project.org>
> Subject: [R] y2z question (AGD)
>
> Hi to all.
>
> I've been trying to calculate weight-for-age z-scores with the y2z
> command (AGD package).
>
> However, I keep getting strange results.
>
> My hypothesis is that missings are the problem.
>
> My dataframe looks like this:
>
> data <- structure(list(sex = structure(c(3L, 3L, 3L, 2L, 3L), .Label =
> c("",
> "F", "M"), class = "factor"), weight = c(8.5, 8.2, 9, NA, 5.8),
>     age = c(8, 9, 12, 9, 1)), .Names = c("sex", "weight", "age"
> ), class = "data.frame", row.names = c(NA, 5L))
>
> Weight is in kg and age in months.
> I will use WHO curves for children younger than 2 years of age.
>
> z-score calculation:
>
> library(AGD)
> data$zeta <- y2z(y = data$weight, x = data$age/12, sex = data$sex,
>                 ref = get("who.wgt"))
>
> I get:
>
> Warning message:
> In `split<-.default`(`*tmp*`, f, drop = drop, value = value) :
>   number of items to replace is not a multiple of replacement length
>
> data$zeta
> [1]     NA     NA     NA -0.124     NA
>
> However a for loop seems to work.
>
> for (i in 1:5) {
>
>   data$zeta[i] <- y2z(y = data$weight[i],
>                  x = data$age[i]/12,
>                  sex = data$sex[i],
>                 ref = get("who.wgt"))
> }
>
> data$zeta
> [1] -0.124 -0.751 -0.635     NA  2.002
>
> Is there a workaround so that I don't have to use a for loop?
> na.action doesn't work either.
>
> Thanks.
>
>
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From minglho at gmail.com  Mon Oct 26 16:43:54 2015
From: minglho at gmail.com (Ming-Lun Ho)
Date: Mon, 26 Oct 2015 15:43:54 +0000
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <8C9AEBFC-1CA2-46B3-87FB-06BF4031E824@gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
	<CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
	<562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>
	<562C6142.5080306@auckland.ac.nz>
	<CAGxFJbSPHwsjR09SaU0PaQ-u4GjUgPyK01c6AAOPe2t=ZGmNTQ@mail.gmail.com>
	<8C9AEBFC-1CA2-46B3-87FB-06BF4031E824@gmail.com>
Message-ID: <CAADh8bCv6T64FLS=3G0OHw_w_z__62DR2vX8TrTZ8FdEu7pDfA@mail.gmail.com>

Hi All,
    So, coming back to the original point, how do I get the info to change
the documentation to someone who has the capability to do so? For all I
know, that could be one of you who responded, but I wouldn't know.
    Thanks.
        --Ming

On Sun, Oct 25, 2015, 08:11 peter dalgaard <pdalgd at gmail.com> wrote:

>
> > On 25 Oct 2015, at 14:37 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > Yes. Too cute, maybe?
> >
>
> ...as in "charming" or...
>
>
>
>
>
> Oh.
>
> ;-)
> pd
>
> > -- Bert
> > Bert Gunter
> >
> > "Data is not information. Information is not knowledge. And knowledge
> > is certainly not wisdom."
> >   -- Clifford Stoll
> >
> >
> > On Sat, Oct 24, 2015 at 9:57 PM, Rolf Turner <r.turner at auckland.ac.nz>
> wrote:
> >> On 25/10/15 17:14, John Sorkin wrote:
> >>>
> >>> Bert Talking about Loglan and problems with the imprecise nature of
> >>> English, which sense of sanction do you mean
> >>>
> >>> to authorize, approve, or allow: an expression now sanctioned by
> >>> educated usage. to ratify or confirm: to sanction a law. to impose a
> >>> sanction on; penalize, especially by way of discipline.
> >>
> >>
> >>
> >> Uh, that was Bert's point I believe.  I.e. he was deliberately striving
> for
> >> ambiguity.
> >>
> >>
> >> cheers,
> >>
> >> Rolf
> >>
> >> --
> >> Technical Editor ANZJS
> >> Department of Statistics
> >> University of Auckland
> >> Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Oct 26 17:38:12 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 26 Oct 2015 17:38:12 +0100
Subject: [R] Creating new variables in R
In-Reply-To: <1531B7E1-C8ED-4220-B1A4-161153099D55@univie.ac.at>
References: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>
	<562E0754.4020300@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFC76B@SRVEXCHMBX.precheza.cz>
	<1531B7E1-C8ED-4220-B1A4-161153099D55@univie.ac.at>
Message-ID: <E8321AF4-D33B-4AD8-A8BD-B458D2E6D051@gmail.com>

pmax() should work even without the fancy stuff. However, as Petr pointed out, so should the ifelse construct, unless there is more to the issue than we have been told. So I think Jennifer needs to elaborate on the "didn't work" aspect...

-pd

On 26 Oct 2015, at 13:02 , Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:

> data <- within(data,variable3=pmax(variable1,variable2))
> also should work if your variables are numeric.
> 
> using dplyr and magrittr (which I recommend to all my students)
> it could be
> 
> library(dplyr)
> library(magrittr)
> data %<>% mutate(variable3=pmax(variable1,variable2))
> 
> 
> 
>> On 26 Oct 2015, at 12:53, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> 
>> Hi
>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org>] On Behalf Of Duncan
>>> Murdoch
>>> Sent: Monday, October 26, 2015 11:58 AM
>>> To: Lorenz, Jennifer; r-help at r-project.org <mailto:r-help at r-project.org>
>>> Subject: Re: [R] Creating new variables in R
>>> 
>>> On 26/10/2015 6:24 AM, Lorenz, Jennifer wrote:
>>>> Hi,
>>>> 
>>>> I  have a question regarding the creation of new variables on the
>>> basis of existing ones in R.
>>>> 
>>>> I have two variables containing information on parents' educational
>>> degree (e.g. 1 'high school degree', 2 'college degree', etc.). I would
>>> like to create a new variable for 'parents' highest educational
>>> degree', i.e. if variable1 (father's degree) is higher than variable2
>>> (mother's degree) than the new variable (variable3) should take on the
>>> value of variable1, if not, than variable3 should take on the value of
>>> variable2.
>>>> 
>>>> I usually use SPSS for data manipulation, there I would code
>>> variable3 as follows:
>>>> COMPUTE variable3= 0.
>>>> IF variable1 > variable2 variable3= variable1.
>>>> IF variable1 <= variable2 variable3= variable2.
>>>> 
>>>> The closest I came to that in R was with this code:
>>>> data$variable3 <- 0
>>>> data$variable3[data$variable1 > data$variable2]<-data$variable1
>>>> data$variable3[data$variable1 <= data$variable2]<-data$variable2
>>>> 
>>>> I also tried:
>>>> data$variable3 <- ifelse(data$variable1 > data$variable2),
>>>> data$variable1, data$variable2)
>>>> 
>>>> Both didn't work.
>> 
>> The ifelse version should work. Are you sure that variable 1 and 2 are numeric?.
>> 
>> What is a result of str(data)?
>> 
>> Cheers
>> Petr
>> 
>>>> 
>>>> I am not sure if my post is at all understandable (this is my first
>>> time posting on R-help), but I am really hoping for some advice!
>>> 
>>> This is a good place to use the ifelse() function:
>>> 
>>> data$variable3 <- ifelse(data$variable1 > data$variable2,
>>>                        data$variable1, data$variable2)
>>> 
>>> Duncan Murdoch
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-
>>> guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ________________________________
>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
>> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
>> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>> 
>> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
>> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>> 
>> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
>> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
>> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
>> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>> 
>> In case that this e-mail forms part of business dealings:
>> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
>> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
>> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
>> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Mon Oct 26 17:55:32 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Oct 2015 12:55:32 -0400
Subject: [R] [FORGED] Re: How to correct documentation?
In-Reply-To: <CAADh8bCv6T64FLS=3G0OHw_w_z__62DR2vX8TrTZ8FdEu7pDfA@mail.gmail.com>
References: <CAADh8bA-7Sa_B6CXbD=7=WXVxCejJwQ7hJhmPFYq8z+28_2dKA@mail.gmail.com>
	<CA+8X3fXhgoeTp49xGf93EGeR8F9ks9SB7+41Ztk88nhXFV1JTQ@mail.gmail.com>
	<562C0132.8010802@auckland.ac.nz> <562C13A8.60602@gmail.com>
	<CAGxFJbS59memawDARZ6ykrVNOnYyVkRJm+Xow1Dd2VmDoTc6FQ@mail.gmail.com>
	<562C1EE1020000CB0013D8C1@smtp.medicine.umaryland.edu>
	<562C6142.5080306@auckland.ac.nz>
	<CAGxFJbSPHwsjR09SaU0PaQ-u4GjUgPyK01c6AAOPe2t=ZGmNTQ@mail.gmail.com>
	<8C9AEBFC-1CA2-46B3-87FB-06BF4031E824@gmail.com>
	<CAADh8bCv6T64FLS=3G0OHw_w_z__62DR2vX8TrTZ8FdEu7pDfA@mail.gmail.com>
Message-ID: <562E5B04.2010904@gmail.com>

On 26/10/2015 11:43 AM, Ming-Lun Ho wrote:
> Hi All,
>      So, coming back to the original point, how do I get the info to change
> the documentation to someone who has the capability to do so? For all I
> know, that could be one of you who responded, but I wouldn't know.

Posting the suggestion here is easiest; it's not 100% reliable (because 
people who can make the change might miss it), but it usually works.

If it doesn't (i.e. you post and get no response), you can post it as a 
bug report on bugs.r-project.org, but that's more work to handle, so it 
shouldn't be your first place to go.

If you post here and get an argument about whether your suggestion is 
correct (as in this case), then you shouldn't post it as a bug report.  
This is the place for arguments, the bug list is *not*.

Duncan Murdoch


>      Thanks.
>          --Ming
>
> On Sun, Oct 25, 2015, 08:11 peter dalgaard <pdalgd at gmail.com> wrote:
>
> >
> > > On 25 Oct 2015, at 14:37 , Bert Gunter <bgunter.4567 at gmail.com> wrote:
> > >
> > > Yes. Too cute, maybe?
> > >
> >
> > ...as in "charming" or...
> >
> >
> >
> >
> >
> > Oh.
> >
> > ;-)
> > pd
> >
> > > -- Bert
> > > Bert Gunter
> > >
> > > "Data is not information. Information is not knowledge. And knowledge
> > > is certainly not wisdom."
> > >   -- Clifford Stoll
> > >
> > >
> > > On Sat, Oct 24, 2015 at 9:57 PM, Rolf Turner <r.turner at auckland.ac.nz>
> > wrote:
> > >> On 25/10/15 17:14, John Sorkin wrote:
> > >>>
> > >>> Bert Talking about Loglan and problems with the imprecise nature of
> > >>> English, which sense of sanction do you mean
> > >>>
> > >>> to authorize, approve, or allow: an expression now sanctioned by
> > >>> educated usage. to ratify or confirm: to sanction a law. to impose a
> > >>> sanction on; penalize, especially by way of discipline.
> > >>
> > >>
> > >>
> > >> Uh, that was Bert's point I believe.  I.e. he was deliberately striving
> > for
> > >> ambiguity.
> > >>
> > >>
> > >> cheers,
> > >>
> > >> Rolf
> > >>
> > >> --
> > >> Technical Editor ANZJS
> > >> Department of Statistics
> > >> University of Auckland
> > >> Phone: +64-9-373-7599 ext. 88276
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Oct 26 17:56:23 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Oct 2015 12:56:23 -0400
Subject: [R] Creating new variables in R
In-Reply-To: <E8321AF4-D33B-4AD8-A8BD-B458D2E6D051@gmail.com>
References: <51661F79C9BE0341B082F375A44402FA5735DB52@UM-EXCDAG-A03.um.gwdg.de>
	<562E0754.4020300@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF88C4FFC76B@SRVEXCHMBX.precheza.cz>
	<1531B7E1-C8ED-4220-B1A4-161153099D55@univie.ac.at>
	<E8321AF4-D33B-4AD8-A8BD-B458D2E6D051@gmail.com>
Message-ID: <562E5B37.3040804@gmail.com>

On 26/10/2015 12:38 PM, peter dalgaard wrote:
> pmax() should work even without the fancy stuff. However, as Petr pointed out, so should the ifelse construct, unless there is more to the issue than we have been told. So I think Jennifer needs to elaborate on the "didn't work" aspect...

Her syntax was incorrect in the original posting, that's all.

Duncan Murdoch
>
> -pd
>
> On 26 Oct 2015, at 13:02 , Erich Neuwirth <erich.neuwirth at univie.ac.at> wrote:
>
> > data <- within(data,variable3=pmax(variable1,variable2))
> > also should work if your variables are numeric.
> >
> > using dplyr and magrittr (which I recommend to all my students)
> > it could be
> >
> > library(dplyr)
> > library(magrittr)
> > data %<>% mutate(variable3=pmax(variable1,variable2))
> >
> >
> >
> >> On 26 Oct 2015, at 12:53, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> >>
> >> Hi
> >>
> >>> -----Original Message-----
> >>> From: R-help [mailto:r-help-bounces at r-project.org <mailto:r-help-bounces at r-project.org>] On Behalf Of Duncan
> >>> Murdoch
> >>> Sent: Monday, October 26, 2015 11:58 AM
> >>> To: Lorenz, Jennifer; r-help at r-project.org <mailto:r-help at r-project.org>
> >>> Subject: Re: [R] Creating new variables in R
> >>>
> >>> On 26/10/2015 6:24 AM, Lorenz, Jennifer wrote:
> >>>> Hi,
> >>>>
> >>>> I  have a question regarding the creation of new variables on the
> >>> basis of existing ones in R.
> >>>>
> >>>> I have two variables containing information on parents' educational
> >>> degree (e.g. 1 'high school degree', 2 'college degree', etc.). I would
> >>> like to create a new variable for 'parents' highest educational
> >>> degree', i.e. if variable1 (father's degree) is higher than variable2
> >>> (mother's degree) than the new variable (variable3) should take on the
> >>> value of variable1, if not, than variable3 should take on the value of
> >>> variable2.
> >>>>
> >>>> I usually use SPSS for data manipulation, there I would code
> >>> variable3 as follows:
> >>>> COMPUTE variable3= 0.
> >>>> IF variable1 > variable2 variable3= variable1.
> >>>> IF variable1 <= variable2 variable3= variable2.
> >>>>
> >>>> The closest I came to that in R was with this code:
> >>>> data$variable3 <- 0
> >>>> data$variable3[data$variable1 > data$variable2]<-data$variable1
> >>>> data$variable3[data$variable1 <= data$variable2]<-data$variable2
> >>>>
> >>>> I also tried:
> >>>> data$variable3 <- ifelse(data$variable1 > data$variable2),
> >>>> data$variable1, data$variable2)
> >>>>
> >>>> Both didn't work.
> >>
> >> The ifelse version should work. Are you sure that variable 1 and 2 are numeric?.
> >>
> >> What is a result of str(data)?
> >>
> >> Cheers
> >> Petr
> >>
> >>>>
> >>>> I am not sure if my post is at all understandable (this is my first
> >>> time posting on R-help), but I am really hoping for some advice!
> >>>
> >>> This is a good place to use the ifelse() function:
> >>>
> >>> data$variable3 <- ifelse(data$variable1 > data$variable2,
> >>>                        data$variable1, data$variable2)
> >>>
> >>> Duncan Murdoch
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-
> >>> guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ________________________________
> >> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> >> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> >> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >>
> >> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> >> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
> >>
> >> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> >> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> >> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> >> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
> >>
> >> In case that this e-mail forms part of business dealings:
> >> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> >> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> >> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> >> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> >> ______________________________________________
> >> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Mon Oct 26 19:45:36 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 26 Oct 2015 11:45:36 -0700
Subject: [R] y2z question (AGD)
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D407B@mb02.ads.tamu.edu>
References: <CAD3qanComneme+Axw39gAW_kE2pCTqF8XE5A4dun3mAn+96j_g@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D407B@mb02.ads.tamu.edu>
Message-ID: <CAF8bMcbqgD7gsLtW26Vd6kP7YMxajqgfEhuHvjPpaM49o-3G2A@mail.gmail.com>

You can also use the na.exclude function, which is like na.omit but attaches
an attribute, "na.action", telling which rows were removed.  Then use the
naresid function to insert NA's into the right places in the output of
the function
that only works properly on NA-less data.  E.g.,

cleanData <- na.exclude(data)
data$zeta <- naresid(attr(cleanData, "na.action"), with(cleanData,
y2z(weight, age/12, sex, ref=who.wgt)))
data
#  sex weight age   zeta
#1   M    8.5   8 -0.124
#2   M    8.2   9 -0.751
#3   M    9.0  12 -0.635
#4   F     NA   9     NA
#5   M    5.8   1  2.002

It is a little wordy, but it does handle both vector and matrix data.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Oct 25, 2015 at 10:53 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> It looks like the y2z() function strips NA's so that the vector lengths do not match any longer. The simplest workaround is to remove the NA's. You could do that by using data2 <- na.omit(data) to strip the observations with NA if they will not be used in the rest of the analysis.
>
> If you want to preserve the NAs in the data frame, this seems to work:
>
>> nomiss <- complete.cases(data)
>> data$zeta[nomiss] <- with(data[nomiss, ], y2z(weight, age/12, sex, ref=who.wgt))
>> data
>   sex weight age   zeta
> 1   M    8.5   8 -0.124
> 2   M    8.2   9 -0.751
> 3   M    9.0  12 -0.635
> 4   F     NA   9     NA
> 5   M    5.8   1  2.002
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin Canon
> Sent: Sunday, October 25, 2015 7:03 AM
> To: R help <r-help at r-project.org>
> Subject: [R] y2z question (AGD)
>
> Hi to all.
>
> I've been trying to calculate weight-for-age z-scores with the y2z
> command (AGD package).
>
> However, I keep getting strange results.
>
> My hypothesis is that missings are the problem.
>
> My dataframe looks like this:
>
> data <- structure(list(sex = structure(c(3L, 3L, 3L, 2L, 3L), .Label = c("",
> "F", "M"), class = "factor"), weight = c(8.5, 8.2, 9, NA, 5.8),
>     age = c(8, 9, 12, 9, 1)), .Names = c("sex", "weight", "age"
> ), class = "data.frame", row.names = c(NA, 5L))
>
> Weight is in kg and age in months.
> I will use WHO curves for children younger than 2 years of age.
>
> z-score calculation:
>
> library(AGD)
> data$zeta <- y2z(y = data$weight, x = data$age/12, sex = data$sex,
>                 ref = get("who.wgt"))
>
> I get:
>
> Warning message:
> In `split<-.default`(`*tmp*`, f, drop = drop, value = value) :
>   number of items to replace is not a multiple of replacement length
>
> data$zeta
> [1]     NA     NA     NA -0.124     NA
>
> However a for loop seems to work.
>
> for (i in 1:5) {
>
>   data$zeta[i] <- y2z(y = data$weight[i],
>                  x = data$age[i]/12,
>                  sex = data$sex[i],
>                 ref = get("who.wgt"))
> }
>
> data$zeta
> [1] -0.124 -0.751 -0.635     NA  2.002
>
> Is there a workaround so that I don't have to use a for loop?
> na.action doesn't work either.
>
> Thanks.
>
>
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From caciquesamurai at gmail.com  Mon Oct 26 19:48:53 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Mon, 26 Oct 2015 16:48:53 -0200
Subject: [R] Formating time in R
Message-ID: <CAGtwFe3pK8ekvFu+_JDAj-3YtOLDHCDLzkNZjcF1WZN1p+hJ6Q@mail.gmail.com>

Hello R-Helpers!

I have a vector of times of events that time is fraction of 1, because
it was calculated in excel. Are there some way to format a period
greater than 24h in a format like excel [h]:mm:ss?

Exemple:

test = c(1.424708, 0.028674)

> chron (times. = test [2], format = "h:m:S")
[1] 00:41:17

> chron (times. = test, format = "h:m:S")
Time in days:
[1] 1.424708 0.028674

I need an output like:

34:11:35 0:41:17

Thanks in advanced,

Raoni

-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From jvadams at usgs.gov  Mon Oct 26 20:02:04 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Mon, 26 Oct 2015 14:02:04 -0500
Subject: [R] Formating time in R
In-Reply-To: <CAGtwFe3pK8ekvFu+_JDAj-3YtOLDHCDLzkNZjcF1WZN1p+hJ6Q@mail.gmail.com>
References: <CAGtwFe3pK8ekvFu+_JDAj-3YtOLDHCDLzkNZjcF1WZN1p+hJ6Q@mail.gmail.com>
Message-ID: <CAN5YmCE4c812s1fUKoLepPVs63-EakP9UVQG+WbaY8092TAhmg@mail.gmail.com>

Raoni,

You could write your own function to do this.  For example, using the
period class from the R package lubridate, you could do something like this:

days2 <- function(x) {
  h1 <- 24*x
  h <- floor(h1)
  m1 <- 60*(h1 - h)
  m <- floor(m1)
  s <- round(60*(m1 - m))
  new_period(second=s, minute=m, hour=h)
}

library(lubridate)
test <- c(1.424708, 0.028674)
days2(test)

[1] "34H 11M 35S" "41M 17S"

Jean

On Mon, Oct 26, 2015 at 1:48 PM, Cacique Samurai <caciquesamurai at gmail.com>
wrote:

> Hello R-Helpers!
>
> I have a vector of times of events that time is fraction of 1, because
> it was calculated in excel. Are there some way to format a period
> greater than 24h in a format like excel [h]:mm:ss?
>
> Exemple:
>
> test = c(1.424708, 0.028674)
>
> > chron (times. = test [2], format = "h:m:S")
> [1] 00:41:17
>
> > chron (times. = test, format = "h:m:S")
> Time in days:
> [1] 1.424708 0.028674
>
> I need an output like:
>
> 34:11:35 0:41:17
>
> Thanks in advanced,
>
> Raoni
>
> --
> Raoni Rosa Rodrigues
> Research Associate of Fish Transposition Center CTPeixes
> Universidade Federal de Minas Gerais - UFMG
> Brasil
> rodrigues.raoni at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From judsonblake at msn.com  Mon Oct 26 17:43:18 2015
From: judsonblake at msn.com (Judson)
Date: Mon, 26 Oct 2015 12:43:18 -0400
Subject: [R] Number of digits to display?
Message-ID: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>

How do I control the number of digits to display, 
say, in a matrix, without rounding or losing accuracy
in subsequent calculations?     
round() of course reduces accuracy.   

Also, if all my results
are really fractions, is there a way to display 
them as fractions of integers rather than 
decimal expressions?   

................... judson blake
 		 	   		  
	[[alternative HTML version deleted]]


From javajimburke at gmail.com  Mon Oct 26 17:08:03 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Mon, 26 Oct 2015 11:08:03 -0500
Subject: [R] My simple ORDER is broken
Message-ID: <CALkjiFS0moM_1hR0snGkhYVWWUBu6deZ6O_kRvKnE5F9V8PBCw@mail.gmail.com>

tmp_df[order(tmp_df$Democratic),]
   Precinct Last.Name Democratic Republican.Total Registered.Voters
2      2904 Open Seat          1                0                15
NA     2903 Open Seat        227              245              2035
3      2905 Open Seat         71              202               497


tmp_df[order(tmp_df[3]),]
   Precinct Last.Name Democratic Republican.Total Registered.Voters
2      2904 Open Seat          1                0                15
NA     2903 Open Seat        227              245              2035
3      2905 Open Seat         71              202               497

> tmp_df$Democratic[order(tmp_df$Democratic)]
[1] "1"   "227" "71"

What am I doing wrong? I would like the order below. I suspect the problem
lies with that NA to the left that R inserted somewhere along the line. So
how to reorder dataframe rows? Or get rid of that NA?
2      2904 Open Seat          1                0                15
3      2905 Open Seat         71              202               497
NA     2903 Open Seat        227              245              2035

Thanks,
Jim Burke

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Mon Oct 26 20:27:08 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Mon, 26 Oct 2015 14:27:08 -0500
Subject: [R] Number of digits to display?
In-Reply-To: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
References: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
Message-ID: <CAKL8G3HHQ0jd_D26KJ5Zk=+BR_gbnD8O5SboNaJe+RbhuvKzCg@mail.gmail.com>

Dear Judson,

Perhaps the following example would give you some ideas:

R> options(digits = 4)
R> rnorm(5)
#[1] -0.57089 -0.14759  0.05717 -0.04935  2.22123
R> options(digits = 3)
R> rnorm(5)
#[1]  0.789  0.616  0.156 -1.315 -1.090
R> options(digits = 2)
R> rnorm(5)
#[1] -1.04 -0.58 -0.50  0.30  0.60

?Best regards,
Jorge.-


On Mon, Oct 26, 2015 at 11:43 AM, Judson <judsonblake at msn.com> wrote:

> How do I control the number of digits to display,
> say, in a matrix, without rounding or losing accuracy
> in subsequent calculations?
> round() of course reduces accuracy.
>
> Also, if all my results
> are really fractions, is there a way to display
> them as fractions of integers rather than
> decimal expressions?
>
> ................... judson blake
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Oct 26 20:29:13 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 26 Oct 2015 12:29:13 -0700
Subject: [R] My simple ORDER is broken
In-Reply-To: <CALkjiFS0moM_1hR0snGkhYVWWUBu6deZ6O_kRvKnE5F9V8PBCw@mail.gmail.com>
References: <CALkjiFS0moM_1hR0snGkhYVWWUBu6deZ6O_kRvKnE5F9V8PBCw@mail.gmail.com>
Message-ID: <CAF8bMcZ0Ab+yWk1jV0KDbAPs1LCpvsKZE6fwj_vHSdT9=JXRKg@mail.gmail.com>

Show us the output of
   str(tmp_df)
Your problem could be caused by the Democratic column being
a character or factor column instead of a numeric column:
"71" > "227" but 71 < 227.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Oct 26, 2015 at 9:08 AM, Jim Burke <javajimburke at gmail.com> wrote:
> tmp_df[order(tmp_df$Democratic),]
>    Precinct Last.Name Democratic Republican.Total Registered.Voters
> 2      2904 Open Seat          1                0                15
> NA     2903 Open Seat        227              245              2035
> 3      2905 Open Seat         71              202               497
>
>
> tmp_df[order(tmp_df[3]),]
>    Precinct Last.Name Democratic Republican.Total Registered.Voters
> 2      2904 Open Seat          1                0                15
> NA     2903 Open Seat        227              245              2035
> 3      2905 Open Seat         71              202               497
>
>> tmp_df$Democratic[order(tmp_df$Democratic)]
> [1] "1"   "227" "71"
>
> What am I doing wrong? I would like the order below. I suspect the problem
> lies with that NA to the left that R inserted somewhere along the line. So
> how to reorder dataframe rows? Or get rid of that NA?
> 2      2904 Open Seat          1                0                15
> 3      2905 Open Seat         71              202               497
> NA     2903 Open Seat        227              245              2035
>
> Thanks,
> Jim Burke
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Oct 26 20:37:10 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 26 Oct 2015 12:37:10 -0700
Subject: [R] Number of digits to display?
In-Reply-To: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
References: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
Message-ID: <CAF8bMcY1h5uVbNnvuY3m7dtKxqW8CedfXWzKNw2=kxdT1bz5oQ@mail.gmail.com>

> myMatrix <- outer(c(1,24,30,75,96), 20:25, "/")
> print(myMatrix, digits=3)
     [,1]   [,2]   [,3]   [,4]   [,5] [,6]
[1,] 0.05 0.0476 0.0455 0.0435 0.0417 0.04
[2,] 1.20 1.1429 1.0909 1.0435 1.0000 0.96
[3,] 1.50 1.4286 1.3636 1.3043 1.2500 1.20
[4,] 3.75 3.5714 3.4091 3.2609 3.1250 3.00
[5,] 4.80 4.5714 4.3636 4.1739 4.0000 3.84
> MASS::fractions(myMatrix)
     [,1]  [,2]  [,3]  [,4]  [,5]  [,6]
[1,]  1/20  1/21  1/22  1/23  1/24  1/25
[2,]   6/5   8/7 12/11 24/23     1 24/25
[3,]   3/2  10/7 15/11 30/23   5/4   6/5
[4,]  15/4  25/7 75/22 75/23  25/8     3
[5,]  24/5  32/7 48/11 96/23     4 96/25

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Oct 26, 2015 at 9:43 AM, Judson <judsonblake at msn.com> wrote:
> How do I control the number of digits to display,
> say, in a matrix, without rounding or losing accuracy
> in subsequent calculations?
> round() of course reduces accuracy.
>
> Also, if all my results
> are really fractions, is there a way to display
> them as fractions of integers rather than
> decimal expressions?
>
> ................... judson blake
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Mon Oct 26 20:39:59 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Mon, 26 Oct 2015 14:39:59 -0500
Subject: [R] Number of digits to display?
In-Reply-To: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
References: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
Message-ID: <8C21BCB8-182B-48C5-B3B3-B0E6F8732FCD@me.com>


> On Oct 26, 2015, at 11:43 AM, Judson <judsonblake at msn.com> wrote:
> 
> How do I control the number of digits to display, 
> say, in a matrix, without rounding or losing accuracy
> in subsequent calculations?     
> round() of course reduces accuracy.   
> 
> Also, if all my results
> are really fractions, is there a way to display 
> them as fractions of integers rather than 
> decimal expressions?   
> 
> ................... judson blake


Hi,

You need to differentiate between the way in which R *stores* numeric values and the way in which it *displays* numeric values.

If you want to affect the display of values in routine output, see ?options and note 'digits' and 'scipen'.

Also see ?print.default.

Those approaches do not affect the precision of calculations on the *stored* values.

For fractions, see:

  require(MASS)
  ?fractions

Regards,

Marc Schwartz


From murdoch.duncan at gmail.com  Mon Oct 26 20:40:20 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 26 Oct 2015 15:40:20 -0400
Subject: [R] Number of digits to display?
In-Reply-To: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
References: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
Message-ID: <562E81A4.2060707@gmail.com>

On 26/10/2015 12:43 PM, Judson wrote:
> How do I control the number of digits to display, 
> say, in a matrix, without rounding or losing accuracy
> in subsequent calculations?     
> round() of course reduces accuracy.   
> 
> Also, if all my results
> are really fractions, is there a way to display 
> them as fractions of integers rather than 
> decimal expressions?   

See the fractions() function in the MASS package.

Duncan Murdoch


From dcarlson at tamu.edu  Mon Oct 26 21:20:04 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 26 Oct 2015 20:20:04 +0000
Subject: [R] y2z question (AGD)
In-Reply-To: <CAF8bMcbqgD7gsLtW26Vd6kP7YMxajqgfEhuHvjPpaM49o-3G2A@mail.gmail.com>
References: <CAD3qanComneme+Axw39gAW_kE2pCTqF8XE5A4dun3mAn+96j_g@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D407B@mb02.ads.tamu.edu>
	<CAF8bMcbqgD7gsLtW26Vd6kP7YMxajqgfEhuHvjPpaM49o-3G2A@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4651@mb02.ads.tamu.edu>

Thanks for this. I knew that na.exclude() existed, but never understood how to combine it with naresid().

David C

-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com] 
Sent: Monday, October 26, 2015 1:46 PM
To: David L Carlson
Cc: Martin Canon; R help
Subject: Re: [R] y2z question (AGD)

You can also use the na.exclude function, which is like na.omit but attaches
an attribute, "na.action", telling which rows were removed.  Then use the
naresid function to insert NA's into the right places in the output of
the function
that only works properly on NA-less data.  E.g.,

cleanData <- na.exclude(data)
data$zeta <- naresid(attr(cleanData, "na.action"), with(cleanData,
y2z(weight, age/12, sex, ref=who.wgt)))
data
#  sex weight age   zeta
#1   M    8.5   8 -0.124
#2   M    8.2   9 -0.751
#3   M    9.0  12 -0.635
#4   F     NA   9     NA
#5   M    5.8   1  2.002

It is a little wordy, but it does handle both vector and matrix data.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Oct 25, 2015 at 10:53 AM, David L Carlson <dcarlson at tamu.edu> wrote:
> It looks like the y2z() function strips NA's so that the vector lengths do not match any longer. The simplest workaround is to remove the NA's. You could do that by using data2 <- na.omit(data) to strip the observations with NA if they will not be used in the rest of the analysis.
>
> If you want to preserve the NAs in the data frame, this seems to work:
>
>> nomiss <- complete.cases(data)
>> data$zeta[nomiss] <- with(data[nomiss, ], y2z(weight, age/12, sex, ref=who.wgt))
>> data
>   sex weight age   zeta
> 1   M    8.5   8 -0.124
> 2   M    8.2   9 -0.751
> 3   M    9.0  12 -0.635
> 4   F     NA   9     NA
> 5   M    5.8   1  2.002
>
>
> David L. Carlson
> Department of Anthropology
> Texas A&M University
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Martin Canon
> Sent: Sunday, October 25, 2015 7:03 AM
> To: R help <r-help at r-project.org>
> Subject: [R] y2z question (AGD)
>
> Hi to all.
>
> I've been trying to calculate weight-for-age z-scores with the y2z
> command (AGD package).
>
> However, I keep getting strange results.
>
> My hypothesis is that missings are the problem.
>
> My dataframe looks like this:
>
> data <- structure(list(sex = structure(c(3L, 3L, 3L, 2L, 3L), .Label = c("",
> "F", "M"), class = "factor"), weight = c(8.5, 8.2, 9, NA, 5.8),
>     age = c(8, 9, 12, 9, 1)), .Names = c("sex", "weight", "age"
> ), class = "data.frame", row.names = c(NA, 5L))
>
> Weight is in kg and age in months.
> I will use WHO curves for children younger than 2 years of age.
>
> z-score calculation:
>
> library(AGD)
> data$zeta <- y2z(y = data$weight, x = data$age/12, sex = data$sex,
>                 ref = get("who.wgt"))
>
> I get:
>
> Warning message:
> In `split<-.default`(`*tmp*`, f, drop = drop, value = value) :
>   number of items to replace is not a multiple of replacement length
>
> data$zeta
> [1]     NA     NA     NA -0.124     NA
>
> However a for loop seems to work.
>
> for (i in 1:5) {
>
>   data$zeta[i] <- y2z(y = data$weight[i],
>                  x = data$age[i]/12,
>                  sex = data$sex[i],
>                 ref = get("who.wgt"))
> }
>
> data$zeta
> [1] -0.124 -0.751 -0.635     NA  2.002
>
> Is there a workaround so that I don't have to use a for loop?
> na.action doesn't work either.
>
> Thanks.
>
>
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From drjimlemon at gmail.com  Mon Oct 26 21:24:37 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 27 Oct 2015 07:24:37 +1100
Subject: [R] Function help
In-Reply-To: <1487D73C-B4C6-403F-9BEE-8BBCFC84744D@cardmail.louisville.edu>
References: <1487D73C-B4C6-403F-9BEE-8BBCFC84744D@cardmail.louisville.edu>
Message-ID: <CA+8X3fUkX6tyz4jOWuX3v+D+naw64zPN91GvKXX+p4bdRCwN7Q@mail.gmail.com>

Hi Alexander,
I suspect that when you write "try" you mean that you try to run the
function with some value for "pid". The "unexpected symbol" error message
usually includes the offending symbol and that will probably identify the
problem.

Jim

On Mon, Oct 26, 2015 at 1:20 PM, <alexander.thomas.1 at louisville.edu> wrote:

> Hello,
>
> I'm following an example in the book, analyzing baseball data with R, but
> it's not working for me. The example is:
>
> compute.hr <- function(pid){d <- subset(Batting.60, playerID==pid)
> sum(d$HR)}
>
> Every time I try this, it says there's an unexpected symbol. Any idea on
> what the unexpected symbol is or how to fix it? Thanks.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Mon Oct 26 23:40:16 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 26 Oct 2015 22:40:16 +0000
Subject: [R] Number of digits to display?
In-Reply-To: <8C21BCB8-182B-48C5-B3B3-B0E6F8732FCD@me.com>
References: <COL130-W12EE0DBA9D4682F90D957BAD230@phx.gbl>
	<8C21BCB8-182B-48C5-B3B3-B0E6F8732FCD@me.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D48AD@mb02.ads.tamu.edu>

Just to elaborate on Marc's comment:

> set.seed(42)
> x <- runif(1)
> dput(x)             # What R is storing as x
0.914806043496355
> print(x)            # Ways to display an approximation of x
[1] 0.914806
> print(x, digits=3)
[1] 0.915
> round(x, 2)
[1] 0.91
> signif(x, 4)
[1] 0.9148
> library(MASS)
> fractions(x)
[1] 7334/8017
> dput(x)             # But x is still the same
0.914806043496355


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Marc Schwartz
Sent: Monday, October 26, 2015 2:40 PM
To: Judson <judsonblake at msn.com>
Cc: R-help <r-help at r-project.org>
Subject: Re: [R] Number of digits to display?


> On Oct 26, 2015, at 11:43 AM, Judson <judsonblake at msn.com> wrote:
> 
> How do I control the number of digits to display, 
> say, in a matrix, without rounding or losing accuracy
> in subsequent calculations?     
> round() of course reduces accuracy.   
> 
> Also, if all my results
> are really fractions, is there a way to display 
> them as fractions of integers rather than 
> decimal expressions?   
> 
> ................... judson blake


Hi,

You need to differentiate between the way in which R *stores* numeric values and the way in which it *displays* numeric values.

If you want to affect the display of values in routine output, see ?options and note 'digits' and 'scipen'.

Also see ?print.default.

Those approaches do not affect the precision of calculations on the *stored* values.

For fractions, see:

  require(MASS)
  ?fractions

Regards,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From caciquesamurai at gmail.com  Tue Oct 27 01:50:31 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Mon, 26 Oct 2015 22:50:31 -0200
Subject: [R] Formating time in R
In-Reply-To: <CAN5YmCE4c812s1fUKoLepPVs63-EakP9UVQG+WbaY8092TAhmg@mail.gmail.com>
References: <CAGtwFe3pK8ekvFu+_JDAj-3YtOLDHCDLzkNZjcF1WZN1p+hJ6Q@mail.gmail.com>
	<CAN5YmCE4c812s1fUKoLepPVs63-EakP9UVQG+WbaY8092TAhmg@mail.gmail.com>
Message-ID: <CAGtwFe0F9AM8QGWkLsAhVwoBknGXNjtgoRU8cin6WsioxgPS9A@mail.gmail.com>

Hello Jean!

Thanks very much for your help and assistence! Works very fine!

All best,

Raoni

2015-10-26 17:02 GMT-02:00 Adams, Jean <jvadams at usgs.gov>:
> Raoni,
>
> You could write your own function to do this.  For example, using the period
> class from the R package lubridate, you could do something like this:
>
> days2 <- function(x) {
>   h1 <- 24*x
>   h <- floor(h1)
>   m1 <- 60*(h1 - h)
>   m <- floor(m1)
>   s <- round(60*(m1 - m))
>   new_period(second=s, minute=m, hour=h)
> }
>
> library(lubridate)
> test <- c(1.424708, 0.028674)
> days2(test)
>
> [1] "34H 11M 35S" "41M 17S"
>
> Jean
>
> On Mon, Oct 26, 2015 at 1:48 PM, Cacique Samurai <caciquesamurai at gmail.com>
> wrote:
>>
>> Hello R-Helpers!
>>
>> I have a vector of times of events that time is fraction of 1, because
>> it was calculated in excel. Are there some way to format a period
>> greater than 24h in a format like excel [h]:mm:ss?
>>
>> Exemple:
>>
>> test = c(1.424708, 0.028674)
>>
>> > chron (times. = test [2], format = "h:m:S")
>> [1] 00:41:17
>>
>> > chron (times. = test, format = "h:m:S")
>> Time in days:
>> [1] 1.424708 0.028674
>>
>> I need an output like:
>>
>> 34:11:35 0:41:17
>>
>> Thanks in advanced,
>>
>> Raoni
>>
>> --
>> Raoni Rosa Rodrigues
>> Research Associate of Fish Transposition Center CTPeixes
>> Universidade Federal de Minas Gerais - UFMG
>> Brasil
>> rodrigues.raoni at gmail.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From erinm.hodgess at gmail.com  Tue Oct 27 02:31:49 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 26 Oct 2015 20:31:49 -0500
Subject: [R] Looking for a more elegant solution than a loop
Message-ID: <CACxE24m2k80iBUkk97WtFz9kTt+AEBRQ_X-DNGeuRcTYLbvrRQ@mail.gmail.com>

Hello!

The following (which is a toy example) works fine, but I wonder if there is
a better or more elegant way than to do the loop:

 xz <- vector("list",length=4)
 x <- 6:9
 for(i in 1:4)xz[[i]] <- x[i]
 xz
[[1]]
[1] 6

[[2]]
[1] 7

[[3]]
[1] 8

[[4]]
[1] 9

This does exactly what I want, but the "for" loop seems out of place.
Maybe not.

Thanks,
Sincerely
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Oct 27 02:47:10 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Tue, 27 Oct 2015 01:47:10 +0000
Subject: [R] Looking for a more elegant solution than a loop
In-Reply-To: <CACxE24m2k80iBUkk97WtFz9kTt+AEBRQ_X-DNGeuRcTYLbvrRQ@mail.gmail.com>
References: <CACxE24m2k80iBUkk97WtFz9kTt+AEBRQ_X-DNGeuRcTYLbvrRQ@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F33AAE@FHSDB2D11-2.csu.mcmaster.ca>

Dear Erin,

How about

> x <- 6:9
> as.list(x)
[[1]]
[1] 6

[[2]]
[1] 7

[[3]]
[1] 8

[[4]]
[1] 9

Best,
 John

-----------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario
Canada L8S 4M4
Web: socserv.mcmaster.ca/jfox



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erin
> Hodgess
> Sent: October 26, 2015 9:32 PM
> To: R help <r-help at stat.math.ethz.ch>
> Subject: [R] Looking for a more elegant solution than a loop
> 
> Hello!
> 
> The following (which is a toy example) works fine, but I wonder if there is a
> better or more elegant way than to do the loop:
> 
>  xz <- vector("list",length=4)
>  x <- 6:9
>  for(i in 1:4)xz[[i]] <- x[i]
>  xz
> [[1]]
> [1] 6
> 
> [[2]]
> [1] 7
> 
> [[3]]
> [1] 8
> 
> [[4]]
> [1] 9
> 
> This does exactly what I want, but the "for" loop seems out of place.
> Maybe not.
> 
> Thanks,
> Sincerely
> Erin
> 
> 
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics University of Houston -
> Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Tue Oct 27 02:48:28 2015
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 26 Oct 2015 20:48:28 -0500
Subject: [R] Looking for a more elegant solution than a loop
In-Reply-To: <ACD1644AA6C67E4FBD0C350625508EC810F33AAE@FHSDB2D11-2.csu.mcmaster.ca>
References: <CACxE24m2k80iBUkk97WtFz9kTt+AEBRQ_X-DNGeuRcTYLbvrRQ@mail.gmail.com>
	<ACD1644AA6C67E4FBD0C350625508EC810F33AAE@FHSDB2D11-2.csu.mcmaster.ca>
Message-ID: <CACxE24k3M6bW7L6Ba9epz+GpqxuXnL7g1uWcZTCggSv7C+ZH3w@mail.gmail.com>

Beautiful....

Thanks so much!
Erin


On Mon, Oct 26, 2015 at 8:47 PM, Fox, John <jfox at mcmaster.ca> wrote:

> Dear Erin,
>
> How about
>
> > x <- 6:9
> > as.list(x)
> [[1]]
> [1] 6
>
> [[2]]
> [1] 7
>
> [[3]]
> [1] 8
>
> [[4]]
> [1] 9
>
> Best,
>  John
>
> -----------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario
> Canada L8S 4M4
> Web: socserv.mcmaster.ca/jfox
>
>
>
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Erin
> > Hodgess
> > Sent: October 26, 2015 9:32 PM
> > To: R help <r-help at stat.math.ethz.ch>
> > Subject: [R] Looking for a more elegant solution than a loop
> >
> > Hello!
> >
> > The following (which is a toy example) works fine, but I wonder if there
> is a
> > better or more elegant way than to do the loop:
> >
> >  xz <- vector("list",length=4)
> >  x <- 6:9
> >  for(i in 1:4)xz[[i]] <- x[i]
> >  xz
> > [[1]]
> > [1] 6
> >
> > [[2]]
> > [1] 7
> >
> > [[3]]
> > [1] 8
> >
> > [[4]]
> > [1] 9
> >
> > This does exactly what I want, but the "for" loop seems out of place.
> > Maybe not.
> >
> > Thanks,
> > Sincerely
> > Erin
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics University of Houston -
> > Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Oct 27 03:13:06 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 26 Oct 2015 19:13:06 -0700
Subject: [R] Looking for a more elegant solution than a loop
In-Reply-To: <CACxE24m2k80iBUkk97WtFz9kTt+AEBRQ_X-DNGeuRcTYLbvrRQ@mail.gmail.com>
References: <CACxE24m2k80iBUkk97WtFz9kTt+AEBRQ_X-DNGeuRcTYLbvrRQ@mail.gmail.com>
Message-ID: <CAF8bMcaqTy+KkoAs6ONo8DHAHW9b1e16VfZzKcNZbH1BjBxwbQ@mail.gmail.com>

> identical(as.list(x), xz)
[1] TRUE
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Oct 26, 2015 at 6:31 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Hello!
>
> The following (which is a toy example) works fine, but I wonder if there is
> a better or more elegant way than to do the loop:
>
>  xz <- vector("list",length=4)
>  x <- 6:9
>  for(i in 1:4)xz[[i]] <- x[i]
>  xz
> [[1]]
> [1] 6
>
> [[2]]
> [1] 7
>
> [[3]]
> [1] 8
>
> [[4]]
> [1] 9
>
> This does exactly what I want, but the "for" loop seems out of place.
> Maybe not.
>
> Thanks,
> Sincerely
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sporter at ori.org.za  Tue Oct 27 09:56:33 2015
From: sporter at ori.org.za (Sean Porter)
Date: Tue, 27 Oct 2015 10:56:33 +0200
Subject: [R] monte carlo simulations in permanova in vegan package
Message-ID: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>

Dear colleagues,

 

I am trying to run a PERMANOVA in the vegan package with an appropriate
number of permutations (see example below), ideally 9999. Obviously that
number of permutations does not exists so I would like to use Monte Carlo
permutation tests to derive the probability value, as is done in the
commercial package PERMANOVA+ for PRIMER. How can I adapt my code so that
adonis will do so ? Many thanks, Sean

 

> permanova <- adonis(species ~ time, data = time, permutations=99,
method="bray")

> permanova

 

Call:

adonis(formula = species ~ time, data = time, permutations = 99,      method
= "bray") 

 

Permutation: free

Number of permutations: 99

 

Terms added sequentially (first to last)

 

          Df SumsOfSqs  MeanSqs F.Model      R2 Pr(>F)   

time       1  0.070504 0.070504  123.65 0.96866   0.01 **

Residuals  4  0.002281 0.000570         0.03134          

Total      5  0.072785                  1.00000          

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

 

 

> permanova <- adonis(species ~ time, data = time, permutations=999,
method="bray")

'nperm' > set of all permutations; Resetting 'nperm'.

 

 

 

 


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Tue Oct 27 13:23:11 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 27 Oct 2015 05:23:11 -0700
Subject: [R] Having trouble updating and installing R 3.2.1 and 3.2.2
In-Reply-To: <571C6FFB-98F1-4268-A1DB-60F83C7EF53E@dcn.davis.CA.us>
References: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>
	<A529BB44-6905-4AD0-B33C-0332A8181206@dcn.davis.CA.us>
	<FE1D3C18-95AA-4D73-8105-27349CB3CD27@gmail.com>
	<571C6FFB-98F1-4268-A1DB-60F83C7EF53E@dcn.davis.CA.us>
Message-ID: <6F036F74-18F5-4476-AD4A-46DB628106E5@dcn.davis.CA.us>

You might also want to try a different mirror.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 26, 2015 6:49:42 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>I have not used W10, but for quite awhile the *administrator" account
>(not the hidden one named "Administrator") has merely had the right to
>"Run As Administrator"... but doing so explicitly is not recommended
>unless you definitely know what you are doing (in which case you should
>not be asking for help here). As long as you let the UAC (User Account
>Control) prompt you at the necessary moments you should not have
>permissions trouble. If you have followed this advice already then
>there might be a bug in the installer, but I would have thought I would
>have seen more complaints by now if it was a bug.
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On October 26, 2015 6:16:47 AM PDT, Keith S Weintraub
><kw1958 at gmail.com> wrote:
>>I uninstalled all versions of R on my computer and killed all R
>>directories (I think).
>>
>>I am wondering that since I ?upgraded? to Windows 10 is it possible
>>that I should create a user separate from the administrator account?
>My
>>previous version of Windows was 7 Home I think. 
>>
>>Here is a longer version of the error messages that I get.
>>
>>> install.packages("sm")
>>Installing package into ?C:/Users/Administrator/My
>>Documents/R/win-library/3.2?
>>(as ?lib? is unspecified)
>>--- Please select a CRAN mirror for use in this session ---
>>Warning: unable to access index for repository
>>https://cran.cnr.Berkeley.edu/src/contrib
>>Warning: unable to access index for repository
>>https://cran.cnr.Berkeley.edu/bin/windows/contrib/3.2
>>Warning messages:
>>1: In normalizePath(path.expand(path), winslash, mustWork) :
>>path[1]="C:/Users/Administrator/My Documents/R/win-library/3.2":
>Access
>>is denied
>>2: package ?sm? is not available (for R version 3.2.2) 
>>
>>
>>Thanks for your help,
>>KW
>>
>>
>>> On Oct 25, 2015, at 7:15 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.CA.us> wrote:
>>> 
>>> I would guess that you ran R as administrator at some point and now
>>you have a permissions problem on your user library. I can't say I
>know
>>how to fix it, though using administrator mode to fix the permissions
>>is probably hard while using administrator mode to delete the R
>>directory and reinstalling your packages might be easier.
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>Go...
>>>                                      Live:   OO#.. Dead: OO#.. 
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On October 25, 2015 7:50:07 AM PDT, Keith S Weintraub
>><kw1958 at gmail.com> wrote:
>>>> I get the following error:
>>>> 
>>>> Warning message:
>>>> In normalizePath(path.expand(path), winslash, mustWork) :
>>>> path[1]="C:\Users\Administrator\My Documents/R/win-library/3.2":
>>Access
>>>> is denied
>>>> 
>>>> This may be the first time that I have tried to upgrade R since I
>>>> upgraded my Windows installation (on Parallels on my Mac no less)
>to
>>>> Windows 10.
>>>> 
>>>> Needless to say when I try to install packages outside of core CRAN
>>I
>>>> have issues.
>>>> 
>>>> Any help is greatly appreciated.
>>>> 
>>>> Thanks much,
>>>> KW
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Tue Oct 27 13:44:47 2015
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 27 Oct 2015 08:44:47 -0400
Subject: [R] Having trouble updating and installing R 3.2.1 and 3.2.2
In-Reply-To: <571C6FFB-98F1-4268-A1DB-60F83C7EF53E@dcn.davis.CA.us>
References: <5770BA84-87CB-4836-A9EE-DAA401D9F17E@gmail.com>
	<A529BB44-6905-4AD0-B33C-0332A8181206@dcn.davis.CA.us>
	<FE1D3C18-95AA-4D73-8105-27349CB3CD27@gmail.com>
	<571C6FFB-98F1-4268-A1DB-60F83C7EF53E@dcn.davis.CA.us>
Message-ID: <55A79D27-50A9-4AF5-8833-D64EC79B8501@gmail.com>

Jeff et. al (although there are no others so far on this thread).

I finally gave up and decided to use 4.2 below from the "R for Windows FAQ?

_________________________________________________________
4.2 I don?t have permission to write to the R-3.2.2\library directory.

You can install packages anywhere and use the environment variable R_LIBS (see How do I set environment variables?) to point to the library location(s). 

Suppose your packages are installed in p:\myRlib. Then you can EITHER 

set the environment variable R_LIBS to p:/myRlib before starting R


OR use a package by, e.g. 

library(mypkg, lib.loc="p:/myRlib")


You can also have a personal library, which defaults to the directory R\win-library\x.y of your home directory for versions x.y.z of R. This location can be changed by setting the environment variable R_LIBS_USER, and can be found from inside R by running Sys.getenv("R_LIBS_USER"). This will only be used if it exists so you may need to create it: you can use 

dir.create(Sys.getenv("R_LIBS_USER"), recursive = TRUE)


to do so. If you use install.packages and do not have permission to write to the main or site library, it should offer to create a personal library for you and install the packages there. This will also happen if update.packages offers to update packages for you in a library where you do not have write permission. 

There can be additional security issues under Windows Vista and later: See Does R run under Windows Vista?. In particular, the detection that a standard user has suitable permissions appears to be unreliable under Vista, so we recommend that you do create a personal directory yourself. 

_________________________________________________________________________



---
KW



> On Oct 26, 2015, at 9:49 AM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:
> 
> I have not used W10, but for quite awhile the *administrator" account (not the hidden one named "Administrator") has merely had the right to "Run As Administrator"... but doing so explicitly is not recommended unless you definitely know what you are doing (in which case you should not be asking for help here). As long as you let the UAC (User Account Control) prompt you at the necessary moments you should not have permissions trouble. If you have followed this advice already then there might be a bug in the installer, but I would have thought I would have seen more complaints by now if it was a bug.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 26, 2015 6:16:47 AM PDT, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> I uninstalled all versions of R on my computer and killed all R
>> directories (I think).
>> 
>> I am wondering that since I ?upgraded? to Windows 10 is it possible
>> that I should create a user separate from the administrator account? My
>> previous version of Windows was 7 Home I think. 
>> 
>> Here is a longer version of the error messages that I get.
>> 
>>> install.packages("sm")
>> Installing package into ?C:/Users/Administrator/My
>> Documents/R/win-library/3.2?
>> (as ?lib? is unspecified)
>> --- Please select a CRAN mirror for use in this session ---
>> Warning: unable to access index for repository
>> https://cran.cnr.Berkeley.edu/src/contrib
>> Warning: unable to access index for repository
>> https://cran.cnr.Berkeley.edu/bin/windows/contrib/3.2
>> Warning messages:
>> 1: In normalizePath(path.expand(path), winslash, mustWork) :
>> path[1]="C:/Users/Administrator/My Documents/R/win-library/3.2": Access
>> is denied
>> 2: package ?sm? is not available (for R version 3.2.2) 
>> 
>> 
>> Thanks for your help,
>> KW
>> 
>> 
>>> On Oct 25, 2015, at 7:15 PM, Jeff Newmiller
>> <jdnewmil at dcn.davis.CA.us> wrote:
>>> 
>>> I would guess that you ran R as administrator at some point and now
>> you have a permissions problem on your user library. I can't say I know
>> how to fix it, though using administrator mode to fix the permissions
>> is probably hard while using administrator mode to delete the R
>> directory and reinstalling your packages might be easier.
>>> 
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>                                     Live:   OO#.. Dead: OO#.. 
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>> rocks...1k
>>> 
>> ---------------------------------------------------------------------------
>> 
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On October 25, 2015 7:50:07 AM PDT, Keith S Weintraub
>> <kw1958 at gmail.com> wrote:
>>>> I get the following error:
>>>> 
>>>> Warning message:
>>>> In normalizePath(path.expand(path), winslash, mustWork) :
>>>> path[1]="C:\Users\Administrator\My Documents/R/win-library/3.2":
>> Access
>>>> is denied
>>>> 
>>>> This may be the first time that I have tried to upgrade R since I
>>>> upgraded my Windows installation (on Parallels on my Mac no less) to
>>>> Windows 10.
>>>> 
>>>> Needless to say when I try to install packages outside of core CRAN
>> I
>>>> have issues.
>>>> 
>>>> Any help is greatly appreciated.
>>>> 
>>>> Thanks much,
>>>> KW
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 


From ssefick at gmail.com  Tue Oct 27 14:10:44 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 27 Oct 2015 08:10:44 -0500
Subject: [R] monte carlo simulations in permanova in vegan package
In-Reply-To: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
Message-ID: <CADKEMqgUmdcjxKNb-08-5W+EUseUYksXKBZSeKNOpTiEeM4b3g@mail.gmail.com>

The example code works, and reports 9999 permutations. Can you provide more
information?

data(dune)
data(dune.env)
adonis(dune ~ Management*A1, data=dune.env, permutations=9999)



On Tue, Oct 27, 2015 at 3:56 AM, Sean Porter <sporter at ori.org.za> wrote:

> Dear colleagues,
>
>
>
> I am trying to run a PERMANOVA in the vegan package with an appropriate
> number of permutations (see example below), ideally 9999. Obviously that
> number of permutations does not exists so I would like to use Monte Carlo
> permutation tests to derive the probability value, as is done in the
> commercial package PERMANOVA+ for PRIMER. How can I adapt my code so that
> adonis will do so ? Many thanks, Sean
>
>
>
> > permanova <- adonis(species ~ time, data = time, permutations=99,
> method="bray")
>
> > permanova
>
>
>
> Call:
>
> adonis(formula = species ~ time, data = time, permutations = 99,
> method
> = "bray")
>
>
>
> Permutation: free
>
> Number of permutations: 99
>
>
>
> Terms added sequentially (first to last)
>
>
>
>           Df SumsOfSqs  MeanSqs F.Model      R2 Pr(>F)
>
> time       1  0.070504 0.070504  123.65 0.96866   0.01 **
>
> Residuals  4  0.002281 0.000570         0.03134
>
> Total      5  0.072785                  1.00000
>
> ---
>
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
>
>
>
> > permanova <- adonis(species ~ time, data = time, permutations=999,
> method="bray")
>
> 'nperm' > set of all permutations; Resetting 'nperm'.
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Stephen Sefick
**************************************************
Auburn University
Biological Sciences
331 Funchess Hall
Auburn, Alabama
36849
**************************************************
sas0025 at auburn.edu
http://www.auburn.edu/~sas0025
**************************************************

Let's not spend our time and resources thinking about things that are so
little or so large that all they really do for us is puff us up and make us
feel like gods.  We are mammals, and have not exhausted the annoying little
problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal
science."

                              -Robert Gentleman

	[[alternative HTML version deleted]]


From wush978 at gmail.com  Tue Oct 27 14:24:09 2015
From: wush978 at gmail.com (Wush Wu)
Date: Tue, 27 Oct 2015 21:24:09 +0800
Subject: [R] Failed to read UTF-16LE file on Windows
Message-ID: <CABjzuv4jf1D1TDeTdk=2td2z-dDgBE5dRruW8=WCTmAbueqD5A@mail.gmail.com>

Dear all,

I tried to run the following code on 3 different OS:

```
download.file("
https://raw.githubusercontent.com/wush978/DataScienceAndR/course/RBasic-07-Loading-Dataset/orglist-100.CSV",
destfile = "orglist-100.CSV")
con <- file("orglist-100.CSV", encoding = "UTF-16LE")
src <- readLines(con)
length(src) # should be 100
```

On ubuntu and OS X, R correctly read 100 lines from the file. However, the
windows will only read the first line with the following warning message:

```
Warning message:
In readLines(file("orglist-100.CSV", encoding = "UTF-16LE")) :
  incomplete final line found on 'orglist-100.CSV'
```

Is there any recommended way to read a local UTF-16LE file on windows?

Thanks,
Wush

	[[alternative HTML version deleted]]


From marwa.syam at feps.edu.eg  Mon Oct 26 21:53:50 2015
From: marwa.syam at feps.edu.eg (Marwah Sabry Siam)
Date: Mon, 26 Oct 2015 22:53:50 +0200
Subject: [R] HPbayes
Message-ID: <CAOGgF38u+ZXbSVt2E5QfGnZnNW7OGiPiMa2MpD+oqPeFes5NuQ@mail.gmail.com>

Dear R-team,

I am using HPbayes package, specificaly hp.bm.imis function in it.
When I run the function it sometimes gives this error
Error in eigen(m, only.values = TRUE, symmetric = TRUE) :
  infinite or missing values in 'x'
even though in my data there isn't any missing values or infinte values.

The weird thing though is that when I run the function again sometimes
it changes the error to be
Error in like.resamp(K = K, log.like.0 = log.like.0, opt.cov.d = opt.cov.d,  :
  argument "K" is missing, with no default
even though I defined the K in advance.

I don't know what is the problem and why it gives different error at
each run. Also, when I expanded the function it gave another error in
MVN!!!

Thank you for your time and patience.


Regards,
Marwah Sabry Siam,
Teaching Assistant at Faculty of Economics and Political Science,
Statistics Department,
01225875205


From faridehbagherzadeh at yahoo.com  Tue Oct 27 06:33:52 2015
From: faridehbagherzadeh at yahoo.com (Farideh Bagherzadeh)
Date: Mon, 26 Oct 2015 22:33:52 -0700
Subject: [R] An R data set with both numerical and categorical variables and
	a two-class response (at least 15 variables)
Message-ID: <1445924032.88159.YahooMailBasic@web164905.mail.bf1.yahoo.com>

Hi 

I need a data set containing both numerical and categorical variables and a two-class outcome to be used in examples of my R package (for variable selection). Do you know any well-known one? I prefer it to be related to healthcare and to have at least about 15 variables.
?
Regards
Farideh Bagherzadeh Khiabani


From jlorenz at uni-goettingen.de  Tue Oct 27 13:20:32 2015
From: jlorenz at uni-goettingen.de (Lorenz, Jennifer)
Date: Tue, 27 Oct 2015 12:20:32 +0000
Subject: [R] Memory problems with mice
Message-ID: <51661F79C9BE0341B082F375A44402FA57360D0B@UM-EXCDAG-A03.um.gwdg.de>

Hi everyone,

I am trying to perform a multiple imputation with mice on a dataset of about 13000 observations and 178 variables. I can start an "empty" imputation ("imp_start <- mice(data, maxit=0)"), but after a few minutes R stops with the following error message:
Error: cannot allocate vector of size 2.0 Gb
In addition: Warning messages:
1: In col(value) :
  Reached total allocation of 8078Mb: see help(memory.size)
2: In col(value) :
  Reached total allocation of 8078Mb: see help(memory.size)
3: In unique.default(x) :
  Reached total allocation of 8078Mb: see help(memory.size)
4: In unique.default(x) :
  Reached total allocation of 8078Mb: see help(memory.size)
5: In unique.default(x) :
  Reached total allocation of 8078Mb: see help(memory.size)
6: In unique.default(x) :
  Reached total allocation of 8078Mb: see help(memory.size)

I am using R (with R Studio) on Windows 7, my computer has a total of 8 GB RAM.
Following advice I found on the internet, I installed the newest R-version (64-bit) and tried the following commands:
memory.size(max = F)
memory.limit(size=NA)

But I still get the same error. Now I am wondering, if my dataset is really to large for mice or R? Or is there any other setting I could use to increase memory size for R? I would really appreciate if anyone who is familiar with this problem would share their insights...

Thanks,
Jen


---
Jennifer Lorenz, M.A.
Georg-August-Universit?t G?ttingen
Sozialwissenschaftliche Fakult?t
Institut f?r Erziehungswissenschaft
Lehrstuhl Schulp?dagogik / Empirische Schulforschung

e-mail: jlorenz at uni-goettingen.de<mailto:jlorenz at uni-goettingen.de>
phone: 0551-39-21411
adress: Waldweg 26, 37073 G?ttingen
room: 8.106


	[[alternative HTML version deleted]]


From sporter at ori.org.za  Tue Oct 27 14:42:23 2015
From: sporter at ori.org.za (Sean Porter)
Date: Tue, 27 Oct 2015 15:42:23 +0200
Subject: [R] monte carlo simulations in permanova in vegan package
In-Reply-To: <CADKEMqgUmdcjxKNb-08-5W+EUseUYksXKBZSeKNOpTiEeM4b3g@mail.gmail.com>
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
	<CADKEMqgUmdcjxKNb-08-5W+EUseUYksXKBZSeKNOpTiEeM4b3g@mail.gmail.com>
Message-ID: <003701d110bd$522e1470$f68a3d50$@ori.org.za>

Hi Stephen and others,

 

I am trying to run a one-way permanova where I have only 2 levels in the factor ?time?, and each level contains only 3 replicates. So because I have such few observations (6 in total) and levels (2) there are not enough possible permutations to get a reasonable test (i.e. (2*3)!/ [2!(3!)^2].   That is why for example if I run the analysis with only 99 permutations it completes the task. However, if I set the number of permutations to anything larger it returns the message ?'nperm' > set of all permutations; Resetting 'nperm'.? as the number of possible permutations exceeds the number set by the argument ?permutations=?. In PERMANOVA + for PRIMER there is a way of dealing with this issue ? by using Monte Carlo simulations to generate the p value with a reasonable number of permutations. Hopefully this clarifies my situation and aim?

 

I was therefore hoping there was a way of coding for the Monte-Carlo permutation procedure into adonis?  

 

Thanks for your help!

 

From: stephen sefick [mailto:ssefick at gmail.com] 
Sent: 27 October 2015 03:11 PM
To: Sean Porter
Cc: r-help at r-project.org
Subject: Re: [R] monte carlo simulations in permanova in vegan package

 

The example code works, and reports 9999 permutations. Can you provide more information? 

 

data(dune)
data(dune.env)
adonis(dune ~ Management*A1, data=dune.env, permutations=9999)

 

 

On Tue, Oct 27, 2015 at 3:56 AM, Sean Porter <sporter at ori.org.za> wrote:

Dear colleagues,



I am trying to run a PERMANOVA in the vegan package with an appropriate
number of permutations (see example below), ideally 9999. Obviously that
number of permutations does not exists so I would like to use Monte Carlo
permutation tests to derive the probability value, as is done in the
commercial package PERMANOVA+ for PRIMER. How can I adapt my code so that
adonis will do so ? Many thanks, Sean



> permanova <- adonis(species ~ time, data = time, permutations=99,
method="bray")

> permanova



Call:

adonis(formula = species ~ time, data = time, permutations = 99,      method
= "bray")



Permutation: free

Number of permutations: 99



Terms added sequentially (first to last)



          Df SumsOfSqs  MeanSqs F.Model      R2 Pr(>F)

time       1  0.070504 0.070504  123.65 0.96866   0.01 **

Residuals  4  0.002281 0.000570         0.03134

Total      5  0.072785                  1.00000

---

Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1





> permanova <- adonis(species ~ time, data = time, permutations=999,
method="bray")

'nperm' > set of all permutations; Resetting 'nperm'.










        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.







-- 

Stephen Sefick
**************************************************
Auburn University                                         
Biological Sciences                                      
331 Funchess Hall                                       
Auburn, Alabama                                        
36849                                                           
**************************************************
sas0025 at auburn.edu                                  
http://www.auburn.edu/~sas0025                 
**************************************************

Let's not spend our time and resources thinking about things that are so little or so large that all they really do for us is puff us up and make us feel like gods.  We are mammals, and have not exhausted the annoying little problems of being mammals.

                                -K. Mullis

"A big computer, a complex algorithm and a long time does not equal science."

                              -Robert Gentleman


	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Tue Oct 27 15:50:29 2015
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Tue, 27 Oct 2015 14:50:29 +0000
Subject: [R] Memory problems with mice
In-Reply-To: <51661F79C9BE0341B082F375A44402FA57360D0B@UM-EXCDAG-A03.um.gwdg.de>
References: <51661F79C9BE0341B082F375A44402FA57360D0B@UM-EXCDAG-A03.um.gwdg.de>
Message-ID: <562F8F35.7020202@dewey.myzen.co.uk>

Dear Jennifer

See inline below

On 27/10/2015 12:20, Lorenz, Jennifer wrote:
> Hi everyone,
>
> I am trying to perform a multiple imputation with mice on a dataset of about 13000 observations and 178 variables. I can start an "empty" imputation ("imp_start <- mice(data, maxit=0)"), but after a few minutes R stops with the following error message:
> Error: cannot allocate vector of size 2.0 Gb
> In addition: Warning messages:
> 1: In col(value) :
>    Reached total allocation of 8078Mb: see help(memory.size)
> 2: In col(value) :
>    Reached total allocation of 8078Mb: see help(memory.size)
> 3: In unique.default(x) :
>    Reached total allocation of 8078Mb: see help(memory.size)
> 4: In unique.default(x) :
>    Reached total allocation of 8078Mb: see help(memory.size)
> 5: In unique.default(x) :
>    Reached total allocation of 8078Mb: see help(memory.size)
> 6: In unique.default(x) :
>    Reached total allocation of 8078Mb: see help(memory.size)
>
> I am using R (with R Studio) on Windows 7, my computer has a total of 8 GB RAM.
> Following advice I found on the internet, I installed the newest R-version (64-bit) and tried the following commands:

Well the internet is wonderful, but ...

> memory.size(max = F)
> memory.limit(size=NA)
>

... R documentation is even more wonderful.
?memory.limit
says that (size = NA) reports the limit but does not set it.

> But I still get the same error. Now I am wondering, if my dataset is really to large for mice or R? Or is there any other setting I could use to increase memory size for R? I would really appreciate if anyone who is familiar with this problem would share their insights...
>
> Thanks,
> Jen
>
>
> ---
> Jennifer Lorenz, M.A.
> Georg-August-Universit?t G?ttingen
> Sozialwissenschaftliche Fakult?t
> Institut f?r Erziehungswissenschaft
> Lehrstuhl Schulp?dagogik / Empirische Schulforschung
>
> e-mail: jlorenz at uni-goettingen.de<mailto:jlorenz at uni-goettingen.de>
> phone: 0551-39-21411
> adress: Waldweg 26, 37073 G?ttingen
> room: 8.106
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From tmrsg11 at gmail.com  Tue Oct 27 16:14:16 2015
From: tmrsg11 at gmail.com (C W)
Date: Tue, 27 Oct 2015 11:14:16 -0400
Subject: [R] How to use curve() with two parameters in the function
Message-ID: <CAE2FW2nJ3OeWHiG4AtCuGGr0uGvjTTjVPvEHSHh0qMz2vfHW1w@mail.gmail.com>

Dear R list,

I am trying to plot the curve of a function.

Here's the R code:

library(mvtnorm)

p <- function(x, mu){
   mu <- c(mu, 0)
   dmvnorm(c(x, 1), mu, diag(2))
}

> curve(p(x, 2), from = 0, to =1)
Error in dmvnorm(c(x, 1), mu, diag(2)) :
  mean and sigma have non-conforming size

I think my matrix probably have different size inside curve(), maybe I need
to use apply()?  I am not sure.

Thanks so much!

	[[alternative HTML version deleted]]


From cadeb at usgs.gov  Tue Oct 27 16:53:00 2015
From: cadeb at usgs.gov (Cade, Brian)
Date: Tue, 27 Oct 2015 09:53:00 -0600
Subject: [R] monte carlo simulations in permanova in vegan package
In-Reply-To: <003701d110bd$522e1470$f68a3d50$@ori.org.za>
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
	<CADKEMqgUmdcjxKNb-08-5W+EUseUYksXKBZSeKNOpTiEeM4b3g@mail.gmail.com>
	<003701d110bd$522e1470$f68a3d50$@ori.org.za>
Message-ID: <CAM5M9BTRMP_4AN2ApUGev+_o4VS2wW+GEWKU6HRnBXSyBK_Tkg@mail.gmail.com>

Sean:  There are only 20 possible combinations, 6!/(3! x 3!), so you just
need to enumerate them completely (no Monte Carlo approximation required).
I don't know if permanova() can do this but you can do it with the mrpp()
functions and argument (,exact=TRUE) in Blossom package for R.

Brian

Brian S. Cade, PhD

U. S. Geological Survey
Fort Collins Science Center
2150 Centre Ave., Bldg. C
Fort Collins, CO  80526-8818

email:  cadeb at usgs.gov <brian_cade at usgs.gov>
tel:  970 226-9326


On Tue, Oct 27, 2015 at 7:42 AM, Sean Porter <sporter at ori.org.za> wrote:

> Hi Stephen and others,
>
>
>
> I am trying to run a one-way permanova where I have only 2 levels in the
> factor ?time?, and each level contains only 3 replicates. So because I have
> such few observations (6 in total) and levels (2) there are not enough
> possible permutations to get a reasonable test (i.e. (2*3)!/ [2!(3!)^2].
>  That is why for example if I run the analysis with only 99 permutations it
> completes the task. However, if I set the number of permutations to
> anything larger it returns the message ?'nperm' > set of all permutations;
> Resetting 'nperm'.? as the number of possible permutations exceeds the
> number set by the argument ?permutations=?. In PERMANOVA + for PRIMER there
> is a way of dealing with this issue ? by using Monte Carlo simulations to
> generate the p value with a reasonable number of permutations. Hopefully
> this clarifies my situation and aim?
>
>
>
> I was therefore hoping there was a way of coding for the Monte-Carlo
> permutation procedure into adonis?
>
>
>
> Thanks for your help!
>
>
>
> From: stephen sefick [mailto:ssefick at gmail.com]
> Sent: 27 October 2015 03:11 PM
> To: Sean Porter
> Cc: r-help at r-project.org
> Subject: Re: [R] monte carlo simulations in permanova in vegan package
>
>
>
> The example code works, and reports 9999 permutations. Can you provide
> more information?
>
>
>
> data(dune)
> data(dune.env)
> adonis(dune ~ Management*A1, data=dune.env, permutations=9999)
>
>
>
>
>
> On Tue, Oct 27, 2015 at 3:56 AM, Sean Porter <sporter at ori.org.za> wrote:
>
> Dear colleagues,
>
>
>
> I am trying to run a PERMANOVA in the vegan package with an appropriate
> number of permutations (see example below), ideally 9999. Obviously that
> number of permutations does not exists so I would like to use Monte Carlo
> permutation tests to derive the probability value, as is done in the
> commercial package PERMANOVA+ for PRIMER. How can I adapt my code so that
> adonis will do so ? Many thanks, Sean
>
>
>
> > permanova <- adonis(species ~ time, data = time, permutations=99,
> method="bray")
>
> > permanova
>
>
>
> Call:
>
> adonis(formula = species ~ time, data = time, permutations = 99,
> method
> = "bray")
>
>
>
> Permutation: free
>
> Number of permutations: 99
>
>
>
> Terms added sequentially (first to last)
>
>
>
>           Df SumsOfSqs  MeanSqs F.Model      R2 Pr(>F)
>
> time       1  0.070504 0.070504  123.65 0.96866   0.01 **
>
> Residuals  4  0.002281 0.000570         0.03134
>
> Total      5  0.072785                  1.00000
>
> ---
>
> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
>
>
>
>
> > permanova <- adonis(species ~ time, data = time, permutations=999,
> method="bray")
>
> 'nperm' > set of all permutations; Resetting 'nperm'.
>
>
>
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
>
>
>
> --
>
> Stephen Sefick
> **************************************************
> Auburn University
> Biological Sciences
> 331 Funchess Hall
> Auburn, Alabama
> 36849
> **************************************************
> sas0025 at auburn.edu
> http://www.auburn.edu/~sas0025
> **************************************************
>
> Let's not spend our time and resources thinking about things that are so
> little or so large that all they really do for us is puff us up and make us
> feel like gods.  We are mammals, and have not exhausted the annoying little
> problems of being mammals.
>
>                                 -K. Mullis
>
> "A big computer, a complex algorithm and a long time does not equal
> science."
>
>                               -Robert Gentleman
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From ravi.varadhan at jhu.edu  Tue Oct 27 16:19:51 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 27 Oct 2015 15:19:51 +0000
Subject: [R] How to get variable name while doing series of regressions in
 an automated manner?
Message-ID: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>

Hi,

I am running through a series of regression in a loop as follows:

results <- vector("list", length(mydata$varnames))

for (i in 1:length(mydata$varnames)) {
results[[i]] <- summary(lm(log(eval(parse(text=varnames[i]))) ~ age + sex + CMV.status, data=mydata))
}

Now, when I look at the results[i]] objects, I won't be able to see the original variable names.  Obviously, I will only see the following:

Call:
lm(formula = log(eval(parse(text = varnames[i]))) ~ age + sex + CMV.status,
    data = mydata)


Is there a way to display the original variable names on the LHS?  In addition, is there a better paradigm for doing these type of series of regressions in an automatic fashion?

Thank you very much,
Ravi

Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
Associate Professor,  Department of Oncology
Division of Biostatistics & Bionformatics
Sidney Kimmel Comprehensive Cancer Center
Johns Hopkins University
550 N. Broadway, Suite 1111-E
Baltimore, MD 21205
410-502-2619


	[[alternative HTML version deleted]]


From ssefick at gmail.com  Tue Oct 27 17:09:50 2015
From: ssefick at gmail.com (stephen sefick)
Date: Tue, 27 Oct 2015 11:09:50 -0500
Subject: [R] monte carlo simulations in permanova in vegan package
In-Reply-To: <CAM5M9BTRMP_4AN2ApUGev+_o4VS2wW+GEWKU6HRnBXSyBK_Tkg@mail.gmail.com>
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
	<CADKEMqgUmdcjxKNb-08-5W+EUseUYksXKBZSeKNOpTiEeM4b3g@mail.gmail.com>
	<003701d110bd$522e1470$f68a3d50$@ori.org.za>
	<CAM5M9BTRMP_4AN2ApUGev+_o4VS2wW+GEWKU6HRnBXSyBK_Tkg@mail.gmail.com>
Message-ID: <CADKEMqhhK1MF8fi2AxfAesLCc3SooZoEGKJ2j8ESc2xFDXUBEQ@mail.gmail.com>

Look at the permute package. I believe this functionality is there.

Please excuse my brevity; this message was sent from my telephone.
On Oct 27, 2015 10:55 AM, "Cade, Brian" <cadeb at usgs.gov> wrote:

> Sean:  There are only 20 possible combinations, 6!/(3! x 3!), so you just
> need to enumerate them completely (no Monte Carlo approximation required).
> I don't know if permanova() can do this but you can do it with the mrpp()
> functions and argument (,exact=TRUE) in Blossom package for R.
>
> Brian
>
> Brian S. Cade, PhD
>
> U. S. Geological Survey
> Fort Collins Science Center
> 2150 Centre Ave., Bldg. C
> Fort Collins, CO  80526-8818
>
> email:  cadeb at usgs.gov <brian_cade at usgs.gov>
> tel:  970 226-9326
>
>
> On Tue, Oct 27, 2015 at 7:42 AM, Sean Porter <sporter at ori.org.za> wrote:
>
> > Hi Stephen and others,
> >
> >
> >
> > I am trying to run a one-way permanova where I have only 2 levels in the
> > factor ?time?, and each level contains only 3 replicates. So because I
> have
> > such few observations (6 in total) and levels (2) there are not enough
> > possible permutations to get a reasonable test (i.e. (2*3)!/ [2!(3!)^2].
> >  That is why for example if I run the analysis with only 99 permutations
> it
> > completes the task. However, if I set the number of permutations to
> > anything larger it returns the message ?'nperm' > set of all
> permutations;
> > Resetting 'nperm'.? as the number of possible permutations exceeds the
> > number set by the argument ?permutations=?. In PERMANOVA + for PRIMER
> there
> > is a way of dealing with this issue ? by using Monte Carlo simulations to
> > generate the p value with a reasonable number of permutations. Hopefully
> > this clarifies my situation and aim?
> >
> >
> >
> > I was therefore hoping there was a way of coding for the Monte-Carlo
> > permutation procedure into adonis?
> >
> >
> >
> > Thanks for your help!
> >
> >
> >
> > From: stephen sefick [mailto:ssefick at gmail.com]
> > Sent: 27 October 2015 03:11 PM
> > To: Sean Porter
> > Cc: r-help at r-project.org
> > Subject: Re: [R] monte carlo simulations in permanova in vegan package
> >
> >
> >
> > The example code works, and reports 9999 permutations. Can you provide
> > more information?
> >
> >
> >
> > data(dune)
> > data(dune.env)
> > adonis(dune ~ Management*A1, data=dune.env, permutations=9999)
> >
> >
> >
> >
> >
> > On Tue, Oct 27, 2015 at 3:56 AM, Sean Porter <sporter at ori.org.za> wrote:
> >
> > Dear colleagues,
> >
> >
> >
> > I am trying to run a PERMANOVA in the vegan package with an appropriate
> > number of permutations (see example below), ideally 9999. Obviously that
> > number of permutations does not exists so I would like to use Monte Carlo
> > permutation tests to derive the probability value, as is done in the
> > commercial package PERMANOVA+ for PRIMER. How can I adapt my code so that
> > adonis will do so ? Many thanks, Sean
> >
> >
> >
> > > permanova <- adonis(species ~ time, data = time, permutations=99,
> > method="bray")
> >
> > > permanova
> >
> >
> >
> > Call:
> >
> > adonis(formula = species ~ time, data = time, permutations = 99,
> > method
> > = "bray")
> >
> >
> >
> > Permutation: free
> >
> > Number of permutations: 99
> >
> >
> >
> > Terms added sequentially (first to last)
> >
> >
> >
> >           Df SumsOfSqs  MeanSqs F.Model      R2 Pr(>F)
> >
> > time       1  0.070504 0.070504  123.65 0.96866   0.01 **
> >
> > Residuals  4  0.002281 0.000570         0.03134
> >
> > Total      5  0.072785                  1.00000
> >
> > ---
> >
> > Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> >
> >
> >
> >
> > > permanova <- adonis(species ~ time, data = time, permutations=999,
> > method="bray")
> >
> > 'nperm' > set of all permutations; Resetting 'nperm'.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> >
> > --
> >
> > Stephen Sefick
> > **************************************************
> > Auburn University
> > Biological Sciences
> > 331 Funchess Hall
> > Auburn, Alabama
> > 36849
> > **************************************************
> > sas0025 at auburn.edu
> > http://www.auburn.edu/~sas0025
> > **************************************************
> >
> > Let's not spend our time and resources thinking about things that are so
> > little or so large that all they really do for us is puff us up and make
> us
> > feel like gods.  We are mammals, and have not exhausted the annoying
> little
> > problems of being mammals.
> >
> >                                 -K. Mullis
> >
> > "A big computer, a complex algorithm and a long time does not equal
> > science."
> >
> >                               -Robert Gentleman
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Tue Oct 27 18:07:33 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 27 Oct 2015 12:07:33 -0500
Subject: [R] How to get variable name while doing series of regressions
 in an automated manner?
In-Reply-To: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>
References: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <436EC54E-77B6-4535-A1F8-2A65CD836E9B@me.com>


> On Oct 27, 2015, at 10:19 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> 
> Hi,
> 
> I am running through a series of regression in a loop as follows:
> 
> results <- vector("list", length(mydata$varnames))
> 
> for (i in 1:length(mydata$varnames)) {
> results[[i]] <- summary(lm(log(eval(parse(text=varnames[i]))) ~ age + sex + CMV.status, data=mydata))
> }
> 
> Now, when I look at the results[i]] objects, I won't be able to see the original variable names.  Obviously, I will only see the following:
> 
> Call:
> lm(formula = log(eval(parse(text = varnames[i]))) ~ age + sex + CMV.status,
>    data = mydata)
> 
> 
> Is there a way to display the original variable names on the LHS?  In addition, is there a better paradigm for doing these type of series of regressions in an automatic fashion?
> 
> Thank you very much,
> Ravi


Ravi,

Something like this, using the 'iris' dataset might be helpful as an example:

# Define the response variables
VarNames <- c("Sepal.Length", "Sepal.Width", "Petal.Length")

# Create the formulae
> paste0("log(", VarNames, ") ~ Petal.Width + Species")
[1] "log(Sepal.Length) ~ Petal.Width + Species"
[2] "log(Sepal.Width) ~ Petal.Width + Species" 
[3] "log(Petal.Length) ~ Petal.Width + Species"


# Create a list of model summary objects
# The result of paste0() will be coerced to a formula by lm()
# if a valid formula, so no need to call as.formula()
MODS <- lapply(paste0("log(", VarNames, ") ~ Petal.Width + Species"), 
               function(x) summary(lm(x, data = iris)))


You can either use the original 'VarNames' vector for the source response variables, or consider:

> as.character(formula(MODS[[1]]))
[1] "~"                     "log(Sepal.Length)"    
[3] "Petal.Width + Species"


> sapply(MODS, function(x) formula(x)[[2]])
[[1]]
log(Sepal.Length)

[[2]]
log(Sepal.Width)

[[3]]
log(Petal.Length)


Regards,

Marc Schwartz


From tmrsg11 at gmail.com  Tue Oct 27 18:14:22 2015
From: tmrsg11 at gmail.com (C W)
Date: Tue, 27 Oct 2015 13:14:22 -0400
Subject: [R] How to use curve() with two parameters in the function
In-Reply-To: <CAE2FW2nJ3OeWHiG4AtCuGGr0uGvjTTjVPvEHSHh0qMz2vfHW1w@mail.gmail.com>
References: <CAE2FW2nJ3OeWHiG4AtCuGGr0uGvjTTjVPvEHSHh0qMz2vfHW1w@mail.gmail.com>
Message-ID: <CAE2FW2=P6awkAR=UOUrSAhoZ9WcQZTw3LsoxctPvvSSzZUov_w@mail.gmail.com>

Never mind, I figured it out.

You need to use sapply(), for instance, curve(sapply(x, p), from = 0, to
=10)

Thanks all!

On Tue, Oct 27, 2015 at 11:14 AM, C W <tmrsg11 at gmail.com> wrote:

> Dear R list,
>
> I am trying to plot the curve of a function.
>
> Here's the R code:
>
> library(mvtnorm)
>
> p <- function(x, mu){
>    mu <- c(mu, 0)
>    dmvnorm(c(x, 1), mu, diag(2))
> }
>
> > curve(p(x, 2), from = 0, to =1)
> Error in dmvnorm(c(x, 1), mu, diag(2)) :
>   mean and sigma have non-conforming size
>
> I think my matrix probably have different size inside curve(), maybe I
> need to use apply()?  I am not sure.
>
> Thanks so much!
>

	[[alternative HTML version deleted]]


From sg.ccnr at gmail.com  Tue Oct 27 18:38:46 2015
From: sg.ccnr at gmail.com (santiago gil)
Date: Tue, 27 Oct 2015 13:38:46 -0400
Subject: [R] rgl plot rotation with device other than mouse
Message-ID: <CADc7pFx37CWQHprmEgV17Vam7cKkN9gSjLYLCetsj4Y4bve+aQ@mail.gmail.com>

Hello R,

I'm trying to figure out if it would be possible use a device (maybe simply
a trackball) separate from the mouse that would have the ability to rotate
a 3D plot made with rgl without any buttons. This is to build an
interactive "demo"-like piece for which a mouse or trackpad is an
unsatisfactory manipulation tool. The worse solution would be to make the
trackpad button "sticky" so that it works as a rotation on/off toggle.
Anything that is less intrusive with the computer's operability is even
better. I couldn't find the right way in par3d or anything of the sort. Any
tips anybody? Or any other libraries to would use to do something like this?

Thanks!

Santiago
-- 
-------------------------------------------------------------------------------
http://barabasilab.neu.edu/people/gil/

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Oct 27 18:50:20 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 27 Oct 2015 10:50:20 -0700
Subject: [R] How to get variable name while doing series of regressions
 in an automated manner?
In-Reply-To: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>
References: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>
Message-ID: <CAGxFJbRHsVfPTSyVHn19Ai=dbOC4C15TDOw4AwRX6n_SX382Rg@mail.gmail.com>

Marc,Ravi:

I may misunderstand, but I think Marc's solution labels the list
components but not necessarily the summary() outputs. This might be
sufficient, as in:

> z <- list(y1=rnorm(10,5),y2 = rnorm(10,8),x=1:10)
>
> ##1
> results1<-lapply(z[-3],function(y)lm(log(y)~x,data=z))
> lapply(results1,summary)
$y1

Call:
lm(formula = log(y) ~ x, data = z)

Residuals:
    Min      1Q  Median      3Q     Max
-0.2185 -0.1259 -0.0643  0.1340  0.3988

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  1.69319    0.14375  11.779 2.47e-06 ***
x           -0.01495    0.02317  -0.645    0.537
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.2104 on 8 degrees of freedom
Multiple R-squared:  0.04945,    Adjusted R-squared:  -0.06937
F-statistic: 0.4161 on 1 and 8 DF,  p-value: 0.5369


$y2

Call:
lm(formula = log(y) ~ x, data = z)

Residuals:
      Min        1Q    Median        3Q       Max
-0.229072 -0.094579 -0.006498  0.134303  0.188158

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.084846   0.104108  20.026 4.03e-08 ***
x           -0.006226   0.016778  -0.371     0.72
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.1524 on 8 degrees of freedom
Multiple R-squared:  0.01692,    Adjusted R-squared:  -0.106
F-statistic: 0.1377 on 1 and 8 DF,  p-value: 0.7202


## 2

Alternatively, if you want output with the correct variable names,
bquote() can be used, as in:

> results2 <-lapply(names(z)[1:2],
+        function(nm){
+          fo <-formula(paste0("log(",nm,")~x"))
+           eval(bquote(lm(.(u),data=z),list(u=fo)))
+        })
> lapply(results2,summary)
[[1]]

Call:
lm(formula = log(y1) ~ x, data = z)

Residuals:
    Min      1Q  Median      3Q     Max
-0.2185 -0.1259 -0.0643  0.1340  0.3988

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  1.69319    0.14375  11.779 2.47e-06 ***
x           -0.01495    0.02317  -0.645    0.537
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.2104 on 8 degrees of freedom
Multiple R-squared:  0.04945,    Adjusted R-squared:  -0.06937
F-statistic: 0.4161 on 1 and 8 DF,  p-value: 0.5369


[[2]]

Call:
lm(formula = log(y2) ~ x, data = z)

Residuals:
      Min        1Q    Median        3Q       Max
-0.229072 -0.094579 -0.006498  0.134303  0.188158

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.084846   0.104108  20.026 4.03e-08 ***
x           -0.006226   0.016778  -0.371     0.72
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.1524 on 8 degrees of freedom
Multiple R-squared:  0.01692,    Adjusted R-squared:  -0.106
F-statistic: 0.1377 on 1 and 8 DF,  p-value: 0.7202


HTH or apologies if I've missed the point and broadcasted noise.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Tue, Oct 27, 2015 at 8:19 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> Hi,
>
> I am running through a series of regression in a loop as follows:
>
> results <- vector("list", length(mydata$varnames))
>
> for (i in 1:length(mydata$varnames)) {
> results[[i]] <- summary(lm(log(eval(parse(text=varnames[i]))) ~ age + sex + CMV.status, data=mydata))
> }
>
> Now, when I look at the results[i]] objects, I won't be able to see the original variable names.  Obviously, I will only see the following:
>
> Call:
> lm(formula = log(eval(parse(text = varnames[i]))) ~ age + sex + CMV.status,
>     data = mydata)
>
>
> Is there a way to display the original variable names on the LHS?  In addition, is there a better paradigm for doing these type of series of regressions in an automatic fashion?
>
> Thank you very much,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg)
> Associate Professor,  Department of Oncology
> Division of Biostatistics & Bionformatics
> Sidney Kimmel Comprehensive Cancer Center
> Johns Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Oct 27 19:17:38 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 27 Oct 2015 14:17:38 -0400
Subject: [R] rgl plot rotation with device other than mouse
In-Reply-To: <CADc7pFx37CWQHprmEgV17Vam7cKkN9gSjLYLCetsj4Y4bve+aQ@mail.gmail.com>
References: <CADc7pFx37CWQHprmEgV17Vam7cKkN9gSjLYLCetsj4Y4bve+aQ@mail.gmail.com>
Message-ID: <562FBFC2.3090303@gmail.com>

On 27/10/2015 1:38 PM, santiago gil wrote:
> Hello R,
>
> I'm trying to figure out if it would be possible use a device (maybe simply
> a trackball) separate from the mouse that would have the ability to rotate
> a 3D plot made with rgl without any buttons. This is to build an
> interactive "demo"-like piece for which a mouse or trackpad is an
> unsatisfactory manipulation tool. The worse solution would be to make the
> trackpad button "sticky" so that it works as a rotation on/off toggle.
> Anything that is less intrusive with the computer's operability is even
> better. I couldn't find the right way in par3d or anything of the sort. Any
> tips anybody? Or any other libraries to would use to do something like this?

Do you know how to get input from that device?  If so, you can 
explicitly set par3d("userMatrix") to a rotation
matrix based on the input.

rgl itself has no support for getting input from anything other than the 
mouse and keyboard.

Duncan Murdoch


From sg.ccnr at gmail.com  Tue Oct 27 19:35:42 2015
From: sg.ccnr at gmail.com (santiago gil)
Date: Tue, 27 Oct 2015 14:35:42 -0400
Subject: [R] rgl plot rotation with device other than mouse
In-Reply-To: <562FBFC2.3090303@gmail.com>
References: <CADc7pFx37CWQHprmEgV17Vam7cKkN9gSjLYLCetsj4Y4bve+aQ@mail.gmail.com>
	<562FBFC2.3090303@gmail.com>
Message-ID: <CADc7pFwx=iKcPObDvP2iTiQM5tig5kCJWeuw2J_Xy4-a3pF+bQ@mail.gmail.com>

Well, I haven't built the device yet, I'm trying to figure out what my
options will be. In the case of plugging in a simple USB trackball, I
suppose it can work with the HID Manager in Mac to customize the signal
from it.

In general, would it be possible to manipulate the plot, say for example,
with a standard joystick? Is there something "deeper" in the code that I
could look towards to make this possible? Or any other library that might
support something like this?

2015-10-27 14:17 GMT-04:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 27/10/2015 1:38 PM, santiago gil wrote:
>
>> Hello R,
>>
>> I'm trying to figure out if it would be possible use a device (maybe
>> simply
>> a trackball) separate from the mouse that would have the ability to rotate
>> a 3D plot made with rgl without any buttons. This is to build an
>> interactive "demo"-like piece for which a mouse or trackpad is an
>> unsatisfactory manipulation tool. The worse solution would be to make the
>> trackpad button "sticky" so that it works as a rotation on/off toggle.
>> Anything that is less intrusive with the computer's operability is even
>> better. I couldn't find the right way in par3d or anything of the sort.
>> Any
>> tips anybody? Or any other libraries to would use to do something like
>> this?
>>
>
> Do you know how to get input from that device?  If so, you can explicitly
> set par3d("userMatrix") to a rotation
> matrix based on the input.
>
> rgl itself has no support for getting input from anything other than the
> mouse and keyboard.
>
> Duncan Murdoch
>



-- 
-------------------------------------------------------------------------------
http://barabasilab.neu.edu/people/gil/

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Tue Oct 27 19:43:26 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 27 Oct 2015 13:43:26 -0500
Subject: [R] Extract entries from matrix
Message-ID: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>

Dear R-help,

I am working with a matrix "m" from which I would like to extract some
elements.  An toy example is as follows:

## input matrix
m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
5L), .Dim = c(22L, 5L))

R> m
#         [,1]  [,2] [,3] [,4] [,5]
#  [1,]    0    0    0    0    0
#  [2,]    0    0    0    0    0
#  [3,]    0    0    0    0    0
#  [4,]    1    2    3    0    0
#  [5,]    1    2    3    0    0
#  [6,]    1    2    3    0    0
#  [7,]    1    2    3    0    0
#  [8,]    1    2    3    0    0
#  [9,]    1    2    3    4    0
# [10,]   1    2    3    4    0
# [11,]   1    2    3    4    5
# [12,]   1    2    3    4    5

>From "m", I would like to extract the entries

4, 1
5, 2
6, 3
7, 1
8, 2
9, 3
10, 1
11, 2
12, 3

so at the end of applying a function "f" to "m" I get

1, 2, 3, 1, 2, 3, 4, 1, 2, 3


Basically the idea is to extract the diagonal elements until a zero is
found.

In the real problem the dimensions of "m" are much bigger, but this smaller
version of "m" illustrate what needs to be done.

I would greatly appreciate any ideas on how to do this.

Thanks in advance,
Jorge Velez.-

	[[alternative HTML version deleted]]


From mar.sapina at gmail.com  Tue Oct 27 18:34:12 2015
From: mar.sapina at gmail.com (Marijan Sapina)
Date: Tue, 27 Oct 2015 18:34:12 +0100
Subject: [R] Neuralnet package in R gives wrong output
Message-ID: <CAPHg8dtUOXNx=wg0TG0xyOx3EvhBFFoY+JvYSUGAC9rQ_o=x1A@mail.gmail.com>

I'm trying to generate prediction of the column "dubina" using this
algorithm made in R's "neuralnet" package. But I keep getting non-reliable
neural-net output. I have tried changing the number of hidden layers,
normalizing and denormalizing data. Is there a mistake in the algorithm,
maybe because of the activation function being logistic, not sigmoid?

The algorithm and the dataset are added as attachments but are added as
attachments.

I'd be very grateful if you'd help me.

From ravi.varadhan at jhu.edu  Tue Oct 27 19:27:10 2015
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 27 Oct 2015 18:27:10 +0000
Subject: [R] How to get variable name while doing series of regressions
 in an automated manner?
In-Reply-To: <CAGxFJbRHsVfPTSyVHn19Ai=dbOC4C15TDOw4AwRX6n_SX382Rg@mail.gmail.com>
References: <375e4397a75f4b578aa3168941e75861@ESGEBEX10.win.ad.jhu.edu>
	<CAGxFJbRHsVfPTSyVHn19Ai=dbOC4C15TDOw4AwRX6n_SX382Rg@mail.gmail.com>
Message-ID: <9dd6a6869c624484a1b9a237a4ff8a6c@ESGEBEX10.win.ad.jhu.edu>

Thank you very much, Marc & Bert.

Bert - I think you're correct.  With Marc's solution, I am not able to get the response variable name in the call to lm().  But, your solution works well.

Best regards,
Ravi

-----Original Message-----
From: Bert Gunter [mailto:bgunter.4567 at gmail.com] 
Sent: Tuesday, October 27, 2015 1:50 PM
To: Ravi Varadhan <ravi.varadhan at jhu.edu>
Cc: r-help at r-project.org
Subject: Re: [R] How to get variable name while doing series of regressions in an automated manner?

Marc,Ravi:

I may misunderstand, but I think Marc's solution labels the list components but not necessarily the summary() outputs. This might be sufficient, as in:

> z <- list(y1=rnorm(10,5),y2 = rnorm(10,8),x=1:10)
>
> ##1
> results1<-lapply(z[-3],function(y)lm(log(y)~x,data=z))
> lapply(results1,summary)
$y1

Call:
lm(formula = log(y) ~ x, data = z)

Residuals:
    Min      1Q  Median      3Q     Max
-0.2185 -0.1259 -0.0643  0.1340  0.3988

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  1.69319    0.14375  11.779 2.47e-06 ***
x           -0.01495    0.02317  -0.645    0.537
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.2104 on 8 degrees of freedom
Multiple R-squared:  0.04945,    Adjusted R-squared:  -0.06937
F-statistic: 0.4161 on 1 and 8 DF,  p-value: 0.5369


$y2

Call:
lm(formula = log(y) ~ x, data = z)

Residuals:
      Min        1Q    Median        3Q       Max
-0.229072 -0.094579 -0.006498  0.134303  0.188158

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.084846   0.104108  20.026 4.03e-08 ***
x           -0.006226   0.016778  -0.371     0.72
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.1524 on 8 degrees of freedom
Multiple R-squared:  0.01692,    Adjusted R-squared:  -0.106
F-statistic: 0.1377 on 1 and 8 DF,  p-value: 0.7202


## 2

Alternatively, if you want output with the correct variable names,
bquote() can be used, as in:

> results2 <-lapply(names(z)[1:2],
+        function(nm){
+          fo <-formula(paste0("log(",nm,")~x"))
+           eval(bquote(lm(.(u),data=z),list(u=fo)))
+        })
> lapply(results2,summary)
[[1]]

Call:
lm(formula = log(y1) ~ x, data = z)

Residuals:
    Min      1Q  Median      3Q     Max
-0.2185 -0.1259 -0.0643  0.1340  0.3988

Coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  1.69319    0.14375  11.779 2.47e-06 ***
x           -0.01495    0.02317  -0.645    0.537
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.2104 on 8 degrees of freedom
Multiple R-squared:  0.04945,    Adjusted R-squared:  -0.06937
F-statistic: 0.4161 on 1 and 8 DF,  p-value: 0.5369


[[2]]

Call:
lm(formula = log(y2) ~ x, data = z)

Residuals:
      Min        1Q    Median        3Q       Max
-0.229072 -0.094579 -0.006498  0.134303  0.188158

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)  2.084846   0.104108  20.026 4.03e-08 ***
x           -0.006226   0.016778  -0.371     0.72
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.1524 on 8 degrees of freedom
Multiple R-squared:  0.01692,    Adjusted R-squared:  -0.106
F-statistic: 0.1377 on 1 and 8 DF,  p-value: 0.7202


HTH or apologies if I've missed the point and broadcasted noise.

Cheers,
Bert
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
   -- Clifford Stoll


On Tue, Oct 27, 2015 at 8:19 AM, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> Hi,
>
> I am running through a series of regression in a loop as follows:
>
> results <- vector("list", length(mydata$varnames))
>
> for (i in 1:length(mydata$varnames)) { results[[i]] <- 
> summary(lm(log(eval(parse(text=varnames[i]))) ~ age + sex + 
> CMV.status, data=mydata)) }
>
> Now, when I look at the results[i]] objects, I won't be able to see the original variable names.  Obviously, I will only see the following:
>
> Call:
> lm(formula = log(eval(parse(text = varnames[i]))) ~ age + sex + CMV.status,
>     data = mydata)
>
>
> Is there a way to display the original variable names on the LHS?  In addition, is there a better paradigm for doing these type of series of regressions in an automatic fashion?
>
> Thank you very much,
> Ravi
>
> Ravi Varadhan, Ph.D. (Biostatistics), Ph.D. (Environmental Engg) 
> Associate Professor,  Department of Oncology Division of Biostatistics 
> & Bionformatics Sidney Kimmel Comprehensive Cancer Center Johns 
> Hopkins University
> 550 N. Broadway, Suite 1111-E
> Baltimore, MD 21205
> 410-502-2619
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From marammagdysalem at gmail.com  Tue Oct 27 20:31:20 2015
From: marammagdysalem at gmail.com (Maram SAlem)
Date: Tue, 27 Oct 2015 21:31:20 +0200
Subject: [R] Time it takes to run a code
In-Reply-To: <A2A011F7-4FBF-40B5-A58E-D290F05702CE@utoronto.ca>
References: <CAPLSCn1_vDU7kpY9nf7XqP_H07Rc+CZMHYdq-rE8c+Uf0scVbw@mail.gmail.com>
	<A2A011F7-4FBF-40B5-A58E-D290F05702CE@utoronto.ca>
Message-ID: <CAPLSCn3Vgq+bJQ++MXJ4ocZFonct0RNjEzB5U-YnktBaKQ2cFA@mail.gmail.com>

Thanks for helping Boris.

 Regards,
 Maram Salem

On 25 October 2015 at 23:30, Boris Steipe <boris.steipe at utoronto.ca> wrote:

> It may be useful for you to estimate the time complexity of your function:
> try it with smaller input that takes short and noticeable time, see whether
> the time increases linearly, quadratically, or exponentially with the
> number of elements you process, then  extrapolate to your full data set.
>
>
> To see what your function is doing, you could
> - add a print statement that tells you the progress every 1000 or 10,000
> items or so...
> - add a progress bar
>
> https://stat.ethz.ch/R-manual/R-patched/library/utils/html/txtProgressBar.html
> - install and use the pbapply package
>     https://cran.r-project.org/web/packages/pbapply/pbapply.pdf
>
>
> You are right to make sure you are getting some feedback, it is easy to
> make a mistake in function logic that will cause a function to fail to
> terminate.
>
>
> B.
>
>
>
> On Oct 25, 2015, at 5:05 PM, Maram SAlem <marammagdysalem at gmail.com>
> wrote:
>
> > Hi All,
> >
> > I'm using a function, say func, and I want to apply it to all the rows
> of a
> > certain matrix. The problem is that my code kept on running for more than
> > two days without giving any output. I've made some modifications.But is
> > there a way to know the time needed to execute my code and reach an ouput
> > but before running the code and not after it is run? I've tried
> Sys.time()
> > and system.time(), but still the console freezed for so long and I didn't
> > reach anything.
> >
> > Any suggestions are much appreciated.
> > Thanks in advance.
> >
> > Maram Salem
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Tue Oct 27 20:31:42 2015
From: jholtman at gmail.com (jim holtman)
Date: Tue, 27 Oct 2015 15:31:42 -0400
Subject: [R] Extract entries from matrix
In-Reply-To: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
Message-ID: <CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>

If you want to use the numbers you gave a the index into the matrix, then
you can create a matrix with the values and then index into 'm'.  I don't
see a '4' in the output example you gave using your index values:

> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
+  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
+  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
+  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
+  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
+  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
+  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
+  5L), .Dim = c(22L, 5L))
> # create index matrix
> indx <- matrix(c(4, 1,
+  5, 2,
+  6, 3,
+  7, 1,
+  8, 2,
+  9, 3,
+  10, 1,
+  11, 2,
+  12, 3), ncol = 2, byrow = TRUE)
>
>
> m
      [,1] [,2] [,3] [,4] [,5]
 [1,]    0    0    0    0    0
 [2,]    0    0    0    0    0
 [3,]    0    0    0    0    0
 [4,]    1    2    3    0    0
 [5,]    1    2    3    0    0
 [6,]    1    2    3    0    0
 [7,]    1    2    3    0    0
 [8,]    1    2    3    0    0
 [9,]    1    2    3    4    0
[10,]    1    2    3    4    0
[11,]    1    2    3    4    5
[12,]    1    2    3    4    5
[13,]    1    2    3    4    5
[14,]    1    2    3    4    5
[15,]    1    2    3    4    5
[16,]    1    2    3    4    5
[17,]    1    2    3    4    5
[18,]    1    2    3    4    5
[19,]    1    2    3    4    5
[20,]    1    2    3    4    5
[21,]    1    2    3    4    5
[22,]    1    2    3    4    5
> indx
      [,1] [,2]
 [1,]    4    1
 [2,]    5    2
 [3,]    6    3
 [4,]    7    1
 [5,]    8    2
 [6,]    9    3
 [7,]   10    1
 [8,]   11    2
 [9,]   12    3
> m[indx]
[1] 1 2 3 1 2 3 1 2 3


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
wrote:

> Dear R-help,
>
> I am working with a matrix "m" from which I would like to extract some
> elements.  An toy example is as follows:
>
> ## input matrix
> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> 5L), .Dim = c(22L, 5L))
>
> R> m
> #         [,1]  [,2] [,3] [,4] [,5]
> #  [1,]    0    0    0    0    0
> #  [2,]    0    0    0    0    0
> #  [3,]    0    0    0    0    0
> #  [4,]    1    2    3    0    0
> #  [5,]    1    2    3    0    0
> #  [6,]    1    2    3    0    0
> #  [7,]    1    2    3    0    0
> #  [8,]    1    2    3    0    0
> #  [9,]    1    2    3    4    0
> # [10,]   1    2    3    4    0
> # [11,]   1    2    3    4    5
> # [12,]   1    2    3    4    5
>
> >From "m", I would like to extract the entries
>
> 4, 1
> 5, 2
> 6, 3
> 7, 1
> 8, 2
> 9, 3
> 10, 1
> 11, 2
> 12, 3
>
> so at the end of applying a function "f" to "m" I get
>
> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
>
>
> Basically the idea is to extract the diagonal elements until a zero is
> found.
>
> In the real problem the dimensions of "m" are much bigger, but this smaller
> version of "m" illustrate what needs to be done.
>
> I would greatly appreciate any ideas on how to do this.
>
> Thanks in advance,
> Jorge Velez.-
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jorgeivanvelez at gmail.com  Tue Oct 27 20:43:56 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 27 Oct 2015 14:43:56 -0500
Subject: [R] Extract entries from matrix
In-Reply-To: <CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
Message-ID: <CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>

Dear Jim,

Thank you very much for your quick reply.

I am sorry for the confusion it may have caused, but I messed up the
indexes in my example.  I would like, from the following matrix "m"

## input
m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim = c(12L,
5L))

to obtain

 1 2 3 1 2 3 4 5 1

Sure using m[idx] will give the desired result.  The problem is that idx is
not known and needs to be determined from "m".  I would like to use
something like

extractDiagonals(m)
## [1]  1 2 3 1 2 3 4 5 1

I look forward to your reply.  Thanks in advance.

Best regards,
Jorge Velez.-



On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com> wrote:

> If you want to use the numbers you gave a the index into the matrix, then
> you can create a matrix with the values and then index into 'm'.  I don't
> see a '4' in the output example you gave using your index values:
>
> > m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> +  5L), .Dim = c(22L, 5L))
> > # create index matrix
> > indx <- matrix(c(4, 1,
> +  5, 2,
> +  6, 3,
> +  7, 1,
> +  8, 2,
> +  9, 3,
> +  10, 1,
> +  11, 2,
> +  12, 3), ncol = 2, byrow = TRUE)
> >
> >
> > m
>       [,1] [,2] [,3] [,4] [,5]
>  [1,]    0    0    0    0    0
>  [2,]    0    0    0    0    0
>  [3,]    0    0    0    0    0
>  [4,]    1    2    3    0    0
>  [5,]    1    2    3    0    0
>  [6,]    1    2    3    0    0
>  [7,]    1    2    3    0    0
>  [8,]    1    2    3    0    0
>  [9,]    1    2    3    4    0
> [10,]    1    2    3    4    0
> [11,]    1    2    3    4    5
> [12,]    1    2    3    4    5
> [13,]    1    2    3    4    5
> [14,]    1    2    3    4    5
> [15,]    1    2    3    4    5
> [16,]    1    2    3    4    5
> [17,]    1    2    3    4    5
> [18,]    1    2    3    4    5
> [19,]    1    2    3    4    5
> [20,]    1    2    3    4    5
> [21,]    1    2    3    4    5
> [22,]    1    2    3    4    5
> > indx
>       [,1] [,2]
>  [1,]    4    1
>  [2,]    5    2
>  [3,]    6    3
>  [4,]    7    1
>  [5,]    8    2
>  [6,]    9    3
>  [7,]   10    1
>  [8,]   11    2
>  [9,]   12    3
> > m[indx]
> [1] 1 2 3 1 2 3 1 2 3
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
>
>> Dear R-help,
>>
>> I am working with a matrix "m" from which I would like to extract some
>> elements.  An toy example is as follows:
>>
>> ## input matrix
>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 5L), .Dim = c(22L, 5L))
>>
>> R> m
>> #         [,1]  [,2] [,3] [,4] [,5]
>> #  [1,]    0    0    0    0    0
>> #  [2,]    0    0    0    0    0
>> #  [3,]    0    0    0    0    0
>> #  [4,]    1    2    3    0    0
>> #  [5,]    1    2    3    0    0
>> #  [6,]    1    2    3    0    0
>> #  [7,]    1    2    3    0    0
>> #  [8,]    1    2    3    0    0
>> #  [9,]    1    2    3    4    0
>> # [10,]   1    2    3    4    0
>> # [11,]   1    2    3    4    5
>> # [12,]   1    2    3    4    5
>>
>> >From "m", I would like to extract the entries
>>
>> 4, 1
>> 5, 2
>> 6, 3
>> 7, 1
>> 8, 2
>> 9, 3
>> 10, 1
>> 11, 2
>> 12, 3
>>
>> so at the end of applying a function "f" to "m" I get
>>
>> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
>>
>>
>> Basically the idea is to extract the diagonal elements until a zero is
>> found.
>>
>> In the real problem the dimensions of "m" are much bigger, but this
>> smaller
>> version of "m" illustrate what needs to be done.
>>
>> I would greatly appreciate any ideas on how to do this.
>>
>> Thanks in advance,
>> Jorge Velez.-
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From david.stevens at usu.edu  Tue Oct 27 20:52:42 2015
From: david.stevens at usu.edu (David Stevens)
Date: Tue, 27 Oct 2015 13:52:42 -0600
Subject: [R] warning on generic function when building R package
In-Reply-To: <33155336.40213.1445286743035.JavaMail.yahoo@mail.yahoo.com>
References: <56254BA9.4050202@gmail.com>
	<33155336.40213.1445286743035.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <562FD60A.4090009@usu.edu>

Sorry to be a late comer to this problem but I'm having a similar 
issue.  My function is called by ode from deSolve

ADM1_C <- function(t,state,parameters,...){

with(as.list(c(state,parameters)), {
   # do some stuff here and return a list containing a vector of 
derivatives to ode
...
})
}
in which 't' is a time and 'state' and 'parameters' are numeric vectors 
with each element named. When I invoke the solver,

times <- d.df$time
out <- as.data.frame(ode(y = state,times = times,func = ADM1_C,parms = 
parameters))

I get ~three Note:s for each value in 'state'  (sometimes more). The 
calculation is successful but the issue is a little puzzling.
Here's 'state'
state
      Ssu      Saa      Sfa      Sva      Sbu     Spro Sac      Sh2     
Sch4      Sic
0.300000 0.001000 0.300000 0.300000 0.300000 0.300000 0.300000 0.000001 
0.000010 0.040000
      Sin       Si       Xc      Xch      Xpr      Xli Xsu      Xaa      
Xfa      Xc4
0.010000 0.020000 0.300000 0.026000 0.300000 0.030000 0.400000 1.100000 
0.200000 0.410000
     Xpro      Xac      Xh2       Xi  Scation   Sanion Sva_m    Sbu_m   
Spro_m    Sac_m
0.137000 0.700000 0.010000 5.000000 0.040000 0.020000 0.090000 0.090000 
0.074000 0.169000
  Shco3_m     Snh3  Sgas_h2 Sgas_ch4 Sgas_co2
0.009700 0.016000 0.020000 0.020000 0.037600

The messages are something like this ...
Note: no visible binding for global variable 'Sin'
Note: no visible binding for global variable 'Snh3'
Note: no visible binding for global variable 'Scation'
Note: no visible binding for global variable 'Shco3_m'
.... (~130 rows of these messages)

Neither Duncan's nor Jim's solution solved the problem.  I can't change 
(at least I don't think so) how ode(...) calls the function except via 
the documentation. Any ideas? Does it matter? Could it be ode strips out 
the names, but only sometimes?

signed Grasping at Straws (David)

David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


On 10/19/2015 2:32 PM, carol white via R-help wrote:
> In effect, this works
> but whether I use x or x.init, y or y.init in plot.func, I get
>   
> no visible binding for global variable ?x.init?no visible binding for global variable ?y.init?
> Regards,
>
>       On Monday, October 19, 2015 9:59 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>     
>
>   On 19/10/2015 3:50 PM, carol white wrote:
>> Thanks Murdoch.
>>
>> defining
>> plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
>>
>> and if plot doesn't take the exact parameters of plot.func but modified
>> of these parameters
>> plot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
>> ylab="ylab", main = "title", col = col,type = "l")
>>
>> then, how to define and invoke to be consisent?
> I don't really understand your question, but this is all about the
> function header for plot.func, not the call you make to plot().  You
> need to name the first argument as "x", you need to include "..." as an
> open argument, and you need a legal header.  So this would be okay:
>
>
> plot.func<- function(x=x.init, y=y.init, arg3, arg4,
>                      main = "title", # can't skip the arg name
>                      col, arg5,
>                      ...)  {          # can't skip the dots
>
> Duncan Murdoch
>
>> Regards,
>>
>> On Monday, October 19, 2015 7:45 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>
>>
>> On 19/10/2015 1:29 PM, carol white via R-help wrote:
>>
>>> Hi,I have invoked plot in a function (plot.func) as follows but when I
>> check the built package, I get a warning:
>>> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
>> ylab="ylab", main = "title", col = col,type = "l")
>>> R CMD check my.package
>>> checking S3 generic/method consistency ... WARNING
>>> plot:
>>>    function(x, ...)
>>> plot.func:
>>>    function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>>>
>>> See section ?Generic functions and methods? in the ?Writing R
>>> Extensions? manual.
>>> Which plot argument is illegitimate or missing and how to eliminate
>> the warning?
>>
>>
>> The first argument to plot.func needs to be called "x" if you want to
>> use it as a method.  Method signatures need to be consistent with the
>> generic signature.
>>
>> Duncan Murdoch
>>
>>
>>
>>
>
>
>    
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Tue Oct 27 20:59:28 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 27 Oct 2015 15:59:28 -0400
Subject: [R] rgl plot rotation with device other than mouse
In-Reply-To: <CADc7pFwx=iKcPObDvP2iTiQM5tig5kCJWeuw2J_Xy4-a3pF+bQ@mail.gmail.com>
References: <CADc7pFx37CWQHprmEgV17Vam7cKkN9gSjLYLCetsj4Y4bve+aQ@mail.gmail.com>
	<562FBFC2.3090303@gmail.com>
	<CADc7pFwx=iKcPObDvP2iTiQM5tig5kCJWeuw2J_Xy4-a3pF+bQ@mail.gmail.com>
Message-ID: <562FD7A0.2040108@gmail.com>

On 27/10/2015 2:35 PM, santiago gil wrote:
> Well, I haven't built the device yet, I'm trying to figure out what my
> options will be. In the case of plugging in a simple USB trackball, I
> suppose it can work with the HID Manager in Mac to customize the signal
> from it.
> 
> In general, would it be possible to manipulate the plot, say for
> example, with a standard joystick? Is there something "deeper" in the
> code that I could look towards to make this possible? Or any other
> library that might support something like this?

I've already answered this below.

Duncan Murdoch

> 
> 2015-10-27 14:17 GMT-04:00 Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>>:
> 
>     On 27/10/2015 1:38 PM, santiago gil wrote:
> 
>         Hello R,
> 
>         I'm trying to figure out if it would be possible use a device
>         (maybe simply
>         a trackball) separate from the mouse that would have the ability
>         to rotate
>         a 3D plot made with rgl without any buttons. This is to build an
>         interactive "demo"-like piece for which a mouse or trackpad is an
>         unsatisfactory manipulation tool. The worse solution would be to
>         make the
>         trackpad button "sticky" so that it works as a rotation on/off
>         toggle.
>         Anything that is less intrusive with the computer's operability
>         is even
>         better. I couldn't find the right way in par3d or anything of
>         the sort. Any
>         tips anybody? Or any other libraries to would use to do
>         something like this?
> 
> 
>     Do you know how to get input from that device?  If so, you can
>     explicitly set par3d("userMatrix") to a rotation
>     matrix based on the input.
> 
>     rgl itself has no support for getting input from anything other than
>     the mouse and keyboard.
> 
>     Duncan Murdoch
> 
> 
> 
> 
> -- 
> -------------------------------------------------------------------------------
> http://barabasilab.neu.edu/people/gil/


From murdoch.duncan at gmail.com  Tue Oct 27 21:05:46 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 27 Oct 2015 16:05:46 -0400
Subject: [R] warning on generic function when building R package
In-Reply-To: <562FD60A.4090009@usu.edu>
References: <56254BA9.4050202@gmail.com>
	<33155336.40213.1445286743035.JavaMail.yahoo@mail.yahoo.com>
	<562FD60A.4090009@usu.edu>
Message-ID: <562FD91A.9060305@gmail.com>

On 27/10/2015 3:52 PM, David Stevens wrote:
> Sorry to be a late comer to this problem but I'm having a similar 
> issue.  My function is called by ode from deSolve
> 
> ADM1_C <- function(t,state,parameters,...){
> 
> with(as.list(c(state,parameters)), {
>    # do some stuff here and return a list containing a vector of 
> derivatives to ode
> ...
> })
> }
> in which 't' is a time and 'state' and 'parameters' are numeric vectors 
> with each element named. When I invoke the solver,
> 
> times <- d.df$time
> out <- as.data.frame(ode(y = state,times = times,func = ADM1_C,parms = 
> parameters))
> 
> I get ~three Note:s for each value in 'state'  (sometimes more). The 
> calculation is successful but the issue is a little puzzling.
> Here's 'state'
> state
>       Ssu      Saa      Sfa      Sva      Sbu     Spro Sac      Sh2     
> Sch4      Sic
> 0.300000 0.001000 0.300000 0.300000 0.300000 0.300000 0.300000 0.000001 
> 0.000010 0.040000
>       Sin       Si       Xc      Xch      Xpr      Xli Xsu      Xaa      
> Xfa      Xc4
> 0.010000 0.020000 0.300000 0.026000 0.300000 0.030000 0.400000 1.100000 
> 0.200000 0.410000
>      Xpro      Xac      Xh2       Xi  Scation   Sanion Sva_m    Sbu_m   
> Spro_m    Sac_m
> 0.137000 0.700000 0.010000 5.000000 0.040000 0.020000 0.090000 0.090000 
> 0.074000 0.169000
>   Shco3_m     Snh3  Sgas_h2 Sgas_ch4 Sgas_co2
> 0.009700 0.016000 0.020000 0.020000 0.037600
> 
> The messages are something like this ...
> Note: no visible binding for global variable 'Sin'
> Note: no visible binding for global variable 'Snh3'
> Note: no visible binding for global variable 'Scation'
> Note: no visible binding for global variable 'Shco3_m'
> .... (~130 rows of these messages)

I don't see how this has anything to do with the previous problem.
> 
> Neither Duncan's nor Jim's solution solved the problem.  I can't change 
> (at least I don't think so) how ode(...) calls the function except via 
> the documentation. Any ideas? Does it matter? Could it be ode strips out 
> the names, but only sometimes?

You will need to post something that we can reproduce if you want help
with it.  (Please do this on a new thread, since you really have nothing
to do with generic functions as far as I can see.)

Or you can add cat() and print() statements to your function (or set
breakpoints in a debugger) and you'll be able to see what it's getting.

Duncan Murdoch

> 
> signed Grasping at Straws (David)
> 
> David K Stevens, P.E., Ph.D.
> Professor and Head, Environmental Engineering
> Civil and Environmental Engineering
> Utah Water Research Laboratory
> 8200 Old Main Hill
> Logan, UT  84322-8200
> 435 797 3229 - voice
> 435 797 1363 - fax
> david.stevens at usu.edu
> 
> 
> On 10/19/2015 2:32 PM, carol white via R-help wrote:
>> In effect, this works
>> but whether I use x or x.init, y or y.init in plot.func, I get
>>   
>> no visible binding for global variable ?x.init?no visible binding for global variable ?y.init?
>> Regards,
>>
>>       On Monday, October 19, 2015 9:59 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>     
>>
>>   On 19/10/2015 3:50 PM, carol white wrote:
>>> Thanks Murdoch.
>>>
>>> defining
>>> plot.func<- function(x=x.init, y=y.init, arg3, arg4, "title", col, arg5)
>>>
>>> and if plot doesn't take the exact parameters of plot.func but modified
>>> of these parameters
>>> plot(x=x.pt,y=y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
>>> ylab="ylab", main = "title", col = col,type = "l")
>>>
>>> then, how to define and invoke to be consisent?
>> I don't really understand your question, but this is all about the
>> function header for plot.func, not the call you make to plot().  You
>> need to name the first argument as "x", you need to include "..." as an
>> open argument, and you need a legal header.  So this would be okay:
>>
>>
>> plot.func<- function(x=x.init, y=y.init, arg3, arg4,
>>                      main = "title", # can't skip the arg name
>>                      col, arg5,
>>                      ...)  {          # can't skip the dots
>>
>> Duncan Murdoch
>>
>>> Regards,
>>>
>>> On Monday, October 19, 2015 7:45 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>
>>>
>>> On 19/10/2015 1:29 PM, carol white via R-help wrote:
>>>
>>>> Hi,I have invoked plot in a function (plot.func) as follows but when I
>>> check the built package, I get a warning:
>>>> plot(x.pt,y.pt,xlim = c(0, 10), ylim = c(0,1), xlab= "xlab",
>>> ylab="ylab", main = "title", col = col,type = "l")
>>>> R CMD check my.package
>>>> checking S3 generic/method consistency ... WARNING
>>>> plot:
>>>>    function(x, ...)
>>>> plot.func:
>>>>    function(x.pt, y.pt, arg3, arg4, "title", col, arg5)
>>>>
>>>> See section ?Generic functions and methods? in the ?Writing R
>>>> Extensions? manual.
>>>> Which plot argument is illegitimate or missing and how to eliminate
>>> the warning?
>>>
>>>
>>> The first argument to plot.func needs to be called "x" if you want to
>>> use it as a method.  Method signatures need to be consistent with the
>>> generic signature.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>
>>>
>>
>>
>>    
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Tue Oct 27 22:06:40 2015
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 27 Oct 2015 21:06:40 +0000
Subject: [R] Extract entries from matrix
In-Reply-To: <CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
	<CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4FE9@mb02.ads.tamu.edu>

I don't see how you are getting the result you provide.

> m
      [,1] [,2] [,3] [,4] [,5]
 [1,]    0    0    0    0    0
 [2,]    0    0    0    0    0
 [3,]    0    0    0    0    0
 [4,]    1    2    3    0    0
 [5,]    1    2    3    0    0
 [6,]    1    2    3    0    0
 [7,]    1    2    3    0    0
 [8,]    1    2    3    0    0
 [9,]    1    2    3    4    0
[10,]    1    2    3    4    0
[11,]    1    2    3    4    5
[12,]    1    2    3    4    5
> t(sapply(1:8, function(x) diag(m[x:12, ])))
     [,1] [,2] [,3] [,4] [,5]
[1,]    0    0    0    0    0
[2,]    0    0    3    0    0
[3,]    0    2    3    0    0
[4,]    1    2    3    0    0
[5,]    1    2    3    0    0
[6,]    1    2    3    4    0
[7,]    1    2    3    4    5
[8,]    1    2    3    4    5

These are all of the diagonals from the 1st through 8th rows. The first 3 begin with 0 so we leave them out, but then we have 4th: 1, 2, 3; 5th: 1, 2, 3; 6th: 1, 2, 3, 4, etc so you must have some additional rule in mind to get your answer.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge I Velez
Sent: Tuesday, October 27, 2015 2:44 PM
To: jim holtman
Cc: R-help
Subject: Re: [R] Extract entries from matrix

Dear Jim,

Thank you very much for your quick reply.

I am sorry for the confusion it may have caused, but I messed up the
indexes in my example.  I would like, from the following matrix "m"

## input
m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim = c(12L,
5L))

to obtain

 1 2 3 1 2 3 4 5 1

Sure using m[idx] will give the desired result.  The problem is that idx is
not known and needs to be determined from "m".  I would like to use
something like

extractDiagonals(m)
## [1]  1 2 3 1 2 3 4 5 1

I look forward to your reply.  Thanks in advance.

Best regards,
Jorge Velez.-



On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com> wrote:

> If you want to use the numbers you gave a the index into the matrix, then
> you can create a matrix with the values and then index into 'm'.  I don't
> see a '4' in the output example you gave using your index values:
>
> > m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> +  5L), .Dim = c(22L, 5L))
> > # create index matrix
> > indx <- matrix(c(4, 1,
> +  5, 2,
> +  6, 3,
> +  7, 1,
> +  8, 2,
> +  9, 3,
> +  10, 1,
> +  11, 2,
> +  12, 3), ncol = 2, byrow = TRUE)
> >
> >
> > m
>       [,1] [,2] [,3] [,4] [,5]
>  [1,]    0    0    0    0    0
>  [2,]    0    0    0    0    0
>  [3,]    0    0    0    0    0
>  [4,]    1    2    3    0    0
>  [5,]    1    2    3    0    0
>  [6,]    1    2    3    0    0
>  [7,]    1    2    3    0    0
>  [8,]    1    2    3    0    0
>  [9,]    1    2    3    4    0
> [10,]    1    2    3    4    0
> [11,]    1    2    3    4    5
> [12,]    1    2    3    4    5
> [13,]    1    2    3    4    5
> [14,]    1    2    3    4    5
> [15,]    1    2    3    4    5
> [16,]    1    2    3    4    5
> [17,]    1    2    3    4    5
> [18,]    1    2    3    4    5
> [19,]    1    2    3    4    5
> [20,]    1    2    3    4    5
> [21,]    1    2    3    4    5
> [22,]    1    2    3    4    5
> > indx
>       [,1] [,2]
>  [1,]    4    1
>  [2,]    5    2
>  [3,]    6    3
>  [4,]    7    1
>  [5,]    8    2
>  [6,]    9    3
>  [7,]   10    1
>  [8,]   11    2
>  [9,]   12    3
> > m[indx]
> [1] 1 2 3 1 2 3 1 2 3
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
>
>> Dear R-help,
>>
>> I am working with a matrix "m" from which I would like to extract some
>> elements.  An toy example is as follows:
>>
>> ## input matrix
>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> 5L), .Dim = c(22L, 5L))
>>
>> R> m
>> #         [,1]  [,2] [,3] [,4] [,5]
>> #  [1,]    0    0    0    0    0
>> #  [2,]    0    0    0    0    0
>> #  [3,]    0    0    0    0    0
>> #  [4,]    1    2    3    0    0
>> #  [5,]    1    2    3    0    0
>> #  [6,]    1    2    3    0    0
>> #  [7,]    1    2    3    0    0
>> #  [8,]    1    2    3    0    0
>> #  [9,]    1    2    3    4    0
>> # [10,]   1    2    3    4    0
>> # [11,]   1    2    3    4    5
>> # [12,]   1    2    3    4    5
>>
>> >From "m", I would like to extract the entries
>>
>> 4, 1
>> 5, 2
>> 6, 3
>> 7, 1
>> 8, 2
>> 9, 3
>> 10, 1
>> 11, 2
>> 12, 3
>>
>> so at the end of applying a function "f" to "m" I get
>>
>> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
>>
>>
>> Basically the idea is to extract the diagonal elements until a zero is
>> found.
>>
>> In the real problem the dimensions of "m" are much bigger, but this
>> smaller
>> version of "m" illustrate what needs to be done.
>>
>> I would greatly appreciate any ideas on how to do this.
>>
>> Thanks in advance,
>> Jorge Velez.-
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Tue Oct 27 22:07:25 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 28 Oct 2015 10:07:25 +1300
Subject: [R] [FORGED] Re:  Extract entries from matrix
In-Reply-To: <CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
	<CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
Message-ID: <562FE78D.6090202@auckland.ac.nz>



Maybe it's just me --- I'm notoriously slow --- but I haven't a clue 
what you are trying to do.  You said:

   "... the idea is to extract the diagonal elements until a
    zero is found."

I don't see anything that resembles a "diagonal element" (*entry*, 
actually; sets have elements, arrays have entries) in your desired 
output.  What do you mean by the diagonal of a non-square matrix anyway?

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

8/10/15 08:43, Jorge I Velez wrote:
> Dear Jim,
>
> Thank you very much for your quick reply.
>
> I am sorry for the confusion it may have caused, but I messed up the
> indexes in my example.  I would like, from the following matrix "m"
>
> ## input
> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
> 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
> 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim = c(12L,
> 5L))
>
> to obtain
>
>   1 2 3 1 2 3 4 5 1
>
> Sure using m[idx] will give the desired result.  The problem is that idx is
> not known and needs to be determined from "m".  I would like to use
> something like
>
> extractDiagonals(m)
> ## [1]  1 2 3 1 2 3 4 5 1
>
> I look forward to your reply.  Thanks in advance.
>
> Best regards,
> Jorge Velez.-
>
>
>
> On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com> wrote:
>
>> If you want to use the numbers you gave a the index into the matrix, then
>> you can create a matrix with the values and then index into 'm'.  I don't
>> see a '4' in the output example you gave using your index values:
>>
>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>> +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>> +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>> +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>> +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> +  5L), .Dim = c(22L, 5L))
>>> # create index matrix
>>> indx <- matrix(c(4, 1,
>> +  5, 2,
>> +  6, 3,
>> +  7, 1,
>> +  8, 2,
>> +  9, 3,
>> +  10, 1,
>> +  11, 2,
>> +  12, 3), ncol = 2, byrow = TRUE)
>>>
>>>
>>> m
>>        [,1] [,2] [,3] [,4] [,5]
>>   [1,]    0    0    0    0    0
>>   [2,]    0    0    0    0    0
>>   [3,]    0    0    0    0    0
>>   [4,]    1    2    3    0    0
>>   [5,]    1    2    3    0    0
>>   [6,]    1    2    3    0    0
>>   [7,]    1    2    3    0    0
>>   [8,]    1    2    3    0    0
>>   [9,]    1    2    3    4    0
>> [10,]    1    2    3    4    0
>> [11,]    1    2    3    4    5
>> [12,]    1    2    3    4    5
>> [13,]    1    2    3    4    5
>> [14,]    1    2    3    4    5
>> [15,]    1    2    3    4    5
>> [16,]    1    2    3    4    5
>> [17,]    1    2    3    4    5
>> [18,]    1    2    3    4    5
>> [19,]    1    2    3    4    5
>> [20,]    1    2    3    4    5
>> [21,]    1    2    3    4    5
>> [22,]    1    2    3    4    5
>>> indx
>>        [,1] [,2]
>>   [1,]    4    1
>>   [2,]    5    2
>>   [3,]    6    3
>>   [4,]    7    1
>>   [5,]    8    2
>>   [6,]    9    3
>>   [7,]   10    1
>>   [8,]   11    2
>>   [9,]   12    3
>>> m[indx]
>> [1] 1 2 3 1 2 3 1 2 3
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
>> wrote:
>>
>>> Dear R-help,
>>>
>>> I am working with a matrix "m" from which I would like to extract some
>>> elements.  An toy example is as follows:
>>>
>>> ## input matrix
>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>>> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>>> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>>> 5L), .Dim = c(22L, 5L))
>>>
>>> R> m
>>> #         [,1]  [,2] [,3] [,4] [,5]
>>> #  [1,]    0    0    0    0    0
>>> #  [2,]    0    0    0    0    0
>>> #  [3,]    0    0    0    0    0
>>> #  [4,]    1    2    3    0    0
>>> #  [5,]    1    2    3    0    0
>>> #  [6,]    1    2    3    0    0
>>> #  [7,]    1    2    3    0    0
>>> #  [8,]    1    2    3    0    0
>>> #  [9,]    1    2    3    4    0
>>> # [10,]   1    2    3    4    0
>>> # [11,]   1    2    3    4    5
>>> # [12,]   1    2    3    4    5
>>>
>>> >From "m", I would like to extract the entries
>>>
>>> 4, 1
>>> 5, 2
>>> 6, 3
>>> 7, 1
>>> 8, 2
>>> 9, 3
>>> 10, 1
>>> 11, 2
>>> 12, 3
>>>
>>> so at the end of applying a function "f" to "m" I get
>>>
>>> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
>>>
>>>
>>> Basically the idea is to extract the diagonal elements until a zero is
>>> found.
>>>
>>> In the real problem the dimensions of "m" are much bigger, but this
>>> smaller
>>> version of "m" illustrate what needs to be done.
>>>
>>> I would greatly appreciate any ideas on how to do this.
>>>
>>> Thanks in advance.


From jorgeivanvelez at gmail.com  Tue Oct 27 22:38:44 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 27 Oct 2015 16:38:44 -0500
Subject: [R] Extract entries from matrix
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4FE9@mb02.ads.tamu.edu>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
	<CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4FE9@mb02.ads.tamu.edu>
Message-ID: <CAKL8G3F1rfcYXfq8n2YkYjDW=67My9z9uu2LpC07WK4vbtYdCg@mail.gmail.com>

Thank you all for your solutions and comments.

As Dr. Carlson mentioned, we leave rows 1 to 3 out as they are all zeroes.
Then, the entries I need to select from m are

----------------
entry     value
----------------
4,1  ---> 1
5,2  ---> 2
6,3  ---> 3
7,1  ---> 1
8,2  ---> 2
9,3  ---> 3
10,4  ---> 4
11,5  ---> 5
12,1  ---> 1

Note that the entry [7,4] is zero, so we start from the first column in the
7th row and then select entry [7,1] instead.  That's what I meant by  "...
the idea is to extract the diagonal elements until a zero is found."  I
should have said *entries* instead of  _diagonal elements_. I am sorry Dr.
Turner for the confusion.

Starting with m

R> m
#       [,1] [,2] [,3] [,4] [,5]
# [1,]    0    0    0    0    0
# [2,]    0    0    0    0    0
# [3,]    0    0    0    0    0
# [4,]    1    2    3    0    0
# [5,]    1    2    3    0    0
# [6,]    1    2    3    0    0
# [7,]    1    2    3    0    0
# [8,]    1    2    3    0    0
# [9,]    1    2    3    4    0
#[10,]    1    2    3    4    0
#[11,]    1    2    3    4    5
#[12,]    1    2    3    4    5

the first submatrix to work with is

# [4,]    1    2    3    0    0
# [5,]    1    2    3    0    0
# [6,]    1    2    3    0    0

from which the elements of interest are 1, 2, 3.  Note that the 7th row of
m is not included here because m[7, 5] = 0.

Further, the second submatrix is

# [7,]    1    2    3    0    0
# [8,]    1    2    3    0    0
# [9,]    1    2    3    4    0
#[10,]    1    2    3    4    0
#[11,]    1    2    3    4    5

and the corresponding elements are 1, 2, 3, 4, 5.

And the last matrix is

#[12,]    1    2    3    4    5

from which the position [12,1] is selected.

So, the resulting entries from this process are 1, 2, 3, 1, 2, 3, 4, 5, 1.

Thank you in advance for any additional insight you may provide.

Regards,
Jorge Velez.-



On Tue, Oct 27, 2015 at 4:06 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> I don't see how you are getting the result you provide.
>
> > m
>       [,1] [,2] [,3] [,4] [,5]
>  [1,]    0    0    0    0    0
>  [2,]    0    0    0    0    0
>  [3,]    0    0    0    0    0
>  [4,]    1    2    3    0    0
>  [5,]    1    2    3    0    0
>  [6,]    1    2    3    0    0
>  [7,]    1    2    3    0    0
>  [8,]    1    2    3    0    0
>  [9,]    1    2    3    4    0
> [10,]    1    2    3    4    0
> [11,]    1    2    3    4    5
> [12,]    1    2    3    4    5
> > t(sapply(1:8, function(x) diag(m[x:12, ])))
>      [,1] [,2] [,3] [,4] [,5]
> [1,]    0    0    0    0    0
> [2,]    0    0    3    0    0
> [3,]    0    2    3    0    0
> [4,]    1    2    3    0    0
> [5,]    1    2    3    0    0
> [6,]    1    2    3    4    0
> [7,]    1    2    3    4    5
> [8,]    1    2    3    4    5
>
> These are all of the diagonals from the 1st through 8th rows. The first 3
> begin with 0 so we leave them out, but then we have 4th: 1, 2, 3; 5th: 1,
> 2, 3; 6th: 1, 2, 3, 4, etc so you must have some additional rule in mind to
> get your answer.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge I
> Velez
> Sent: Tuesday, October 27, 2015 2:44 PM
> To: jim holtman
> Cc: R-help
> Subject: Re: [R] Extract entries from matrix
>
> Dear Jim,
>
> Thank you very much for your quick reply.
>
> I am sorry for the confusion it may have caused, but I messed up the
> indexes in my example.  I would like, from the following matrix "m"
>
> ## input
> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
> 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
> 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim = c(12L,
> 5L))
>
> to obtain
>
>  1 2 3 1 2 3 4 5 1
>
> Sure using m[idx] will give the desired result.  The problem is that idx is
> not known and needs to be determined from "m".  I would like to use
> something like
>
> extractDiagonals(m)
> ## [1]  1 2 3 1 2 3 4 5 1
>
> I look forward to your reply.  Thanks in advance.
>
> Best regards,
> Jorge Velez.-
>
>
>
> On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com> wrote:
>
> > If you want to use the numbers you gave a the index into the matrix, then
> > you can create a matrix with the values and then index into 'm'.  I don't
> > see a '4' in the output example you gave using your index values:
> >
> > > m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> > +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> > +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> > +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> > +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> > +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> > +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> > +  5L), .Dim = c(22L, 5L))
> > > # create index matrix
> > > indx <- matrix(c(4, 1,
> > +  5, 2,
> > +  6, 3,
> > +  7, 1,
> > +  8, 2,
> > +  9, 3,
> > +  10, 1,
> > +  11, 2,
> > +  12, 3), ncol = 2, byrow = TRUE)
> > >
> > >
> > > m
> >       [,1] [,2] [,3] [,4] [,5]
> >  [1,]    0    0    0    0    0
> >  [2,]    0    0    0    0    0
> >  [3,]    0    0    0    0    0
> >  [4,]    1    2    3    0    0
> >  [5,]    1    2    3    0    0
> >  [6,]    1    2    3    0    0
> >  [7,]    1    2    3    0    0
> >  [8,]    1    2    3    0    0
> >  [9,]    1    2    3    4    0
> > [10,]    1    2    3    4    0
> > [11,]    1    2    3    4    5
> > [12,]    1    2    3    4    5
> > [13,]    1    2    3    4    5
> > [14,]    1    2    3    4    5
> > [15,]    1    2    3    4    5
> > [16,]    1    2    3    4    5
> > [17,]    1    2    3    4    5
> > [18,]    1    2    3    4    5
> > [19,]    1    2    3    4    5
> > [20,]    1    2    3    4    5
> > [21,]    1    2    3    4    5
> > [22,]    1    2    3    4    5
> > > indx
> >       [,1] [,2]
> >  [1,]    4    1
> >  [2,]    5    2
> >  [3,]    6    3
> >  [4,]    7    1
> >  [5,]    8    2
> >  [6,]    9    3
> >  [7,]   10    1
> >  [8,]   11    2
> >  [9,]   12    3
> > > m[indx]
> > [1] 1 2 3 1 2 3 1 2 3
> >
> >
> > Jim Holtman
> > Data Munger Guru
> >
> > What is the problem that you are trying to solve?
> > Tell me what you want to do, not how you want to do it.
> >
> > On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <jorgeivanvelez at gmail.com
> >
> > wrote:
> >
> >> Dear R-help,
> >>
> >> I am working with a matrix "m" from which I would like to extract some
> >> elements.  An toy example is as follows:
> >>
> >> ## input matrix
> >> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
> >> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> >> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
> >> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
> >> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
> >> 5L), .Dim = c(22L, 5L))
> >>
> >> R> m
> >> #         [,1]  [,2] [,3] [,4] [,5]
> >> #  [1,]    0    0    0    0    0
> >> #  [2,]    0    0    0    0    0
> >> #  [3,]    0    0    0    0    0
> >> #  [4,]    1    2    3    0    0
> >> #  [5,]    1    2    3    0    0
> >> #  [6,]    1    2    3    0    0
> >> #  [7,]    1    2    3    0    0
> >> #  [8,]    1    2    3    0    0
> >> #  [9,]    1    2    3    4    0
> >> # [10,]   1    2    3    4    0
> >> # [11,]   1    2    3    4    5
> >> # [12,]   1    2    3    4    5
> >>
> >> >From "m", I would like to extract the entries
> >>
> >> 4, 1
> >> 5, 2
> >> 6, 3
> >> 7, 1
> >> 8, 2
> >> 9, 3
> >> 10, 1
> >> 11, 2
> >> 12, 3
> >>
> >> so at the end of applying a function "f" to "m" I get
> >>
> >> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
> >>
> >>
> >> Basically the idea is to extract the diagonal elements until a zero is
> >> found.
> >>
> >> In the real problem the dimensions of "m" are much bigger, but this
> >> smaller
> >> version of "m" illustrate what needs to be done.
> >>
> >> I would greatly appreciate any ideas on how to do this.
> >>
> >> Thanks in advance,
> >> Jorge Velez.-
> >>
> >>         [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From markseeto at gmail.com  Wed Oct 28 01:57:42 2015
From: markseeto at gmail.com (Mark Seeto)
Date: Wed, 28 Oct 2015 11:57:42 +1100
Subject: [R] rms package: residual df for penalised ols
Message-ID: <CAK2mLtP9dMNwugViqnXktbPuvDuLfyQSzVb74RuCDR_TCh0WWA@mail.gmail.com>

Dear R-help,

In the rms package, when using the ols function with a penalty, the
df.residual appears to always be n-1 (with n being the sample size).
That seems strange to me, but I don't have much knowledge in this
area.

Here's an example:

library(rms)

set.seed(1)

n <- 50

d <- data.frame(x1 = rnorm(n),
                x2 = rnorm(n, 0, 5),
                x3 = rnorm(n))
d$y <- with(d, 1 + 0.8*x1 + 0.5*x2 - 0.5*x3) + rnorm(n)

ols1 <- ols(y ~ x1 + x2 + x3, data=d)
ols2 <- ols(y ~ x1 + x2 + x3, data=d, penalty=10)

ols1$stats["d.f."]  # 3
ols2$stats["d.f."]  # 5.2

ols1$df.residual    # 46 = n - 3 - 1
ols2$df.residual    # 49


I would be grateful if someone could give a brief explanation of why
df.residual is n-1. The reason I'm interested in this is that
confidence intervals for predicted values use the df.residual value.

Thanks,
Mark


From caciquesamurai at gmail.com  Wed Oct 28 05:33:49 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Wed, 28 Oct 2015 02:33:49 -0200
Subject: [R] coxme adequacy check
Message-ID: <CAGtwFe2t=R5fFkBYagW+mWRi+i1kzaYAxqj0SfxhZVp8FTA2ww@mail.gmail.com>

Hello all!

I?m fitting a mixed effects cox model with coxme function of coxme package.
I want to konw what is the best way to check the model adequacy, once that
function cox.zph that does not work for coxme objects.

Thanks in advanced,

Raoni

-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com

	[[alternative HTML version deleted]]


From bgnumis at gmail.com  Tue Oct 27 21:17:20 2015
From: bgnumis at gmail.com (bgnumis bgnum)
Date: Tue, 27 Oct 2015 21:17:20 +0100
Subject: [R] Distribution hist
Message-ID: <CAN25tHQeX7nxMD5gWoM8w=hR5cPozE5B3XnpCGrU4ozVZkL6Ww@mail.gmail.com>

Hi all,

I have this data on "sim" variable

 10403.000        NA        NA        NA        NA
 11178.000        NA        NA        NA        NA
 11521.000        NA        NA        NA        NA
 11385.000        NA        NA        NA        NA
10102.000        NA        NA        NA        NA
 10544.013 10339.925  9912.695  9928.198  9932.112
  9008.050  9437.174 10406.784 10832.123 11095.868
 10955.094 10804.075  9002.848 11276.038 10503.487
 11899.525 10085.509  9109.918  8953.339 10135.833
 11047.832 14353.462  8804.653 11942.829  7722.255
  9732.114  8413.027 10213.796 10091.471 12317.169

I want to use matplot on a left plot and a "distribution line" on a right
plot.

My idea is the same size from the ylim (max and min) on the left plot will
be the same on the right plot (but I cannot get the same size so thar the
right plot show the distribution of the matplot on the left.

I tried this but canot (some suggest me using rect() for the boundaries of
the second plot but I cannot achive what I want.

I dont care if is it a hist or line plot but something similar a
distribution shape (or like a bell)


Can anyone try to help me?

par(mar=c(10,6,6,6))
matplot(Simulation,type="l",ylim=c(0,20000))


title(" Dim Mo Simulation 2 years",font=4)
fhist<-hist(Simulation,plot=FALSE)

par(mar=c(6,0,6,6))
barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")

	[[alternative HTML version deleted]]


From caciquesamurai at gmail.com  Wed Oct 28 10:56:00 2015
From: caciquesamurai at gmail.com (Cacique Samurai)
Date: Wed, 28 Oct 2015 07:56:00 -0200
Subject: [R] coxme adequacy check
Message-ID: <CAGtwFe3Yrr3Zo7KfSmY9j=g4OBqn7UXcDiiczQ5X==eP1HuROg@mail.gmail.com>

Hello all!

I?m fitting a mixed effects cox model with coxme function of coxme
package. I want to konw what is the best way to check the model
adequacy, once that function cox.zph does not work for coxme objects.

Thanks in advanced,

Raoni

-- 
Raoni Rosa Rodrigues
Research Associate of Fish Transposition Center CTPeixes
Universidade Federal de Minas Gerais - UFMG
Brasil
rodrigues.raoni at gmail.com


From jrkrideau at inbox.com  Wed Oct 28 13:25:00 2015
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 28 Oct 2015 04:25:00 -0800
Subject: [R] Neuralnet package in R gives wrong output
In-Reply-To: <CAPHg8dtUOXNx=wg0TG0xyOx3EvhBFFoY+JvYSUGAC9rQ_o=x1A@mail.gmail.com>
Message-ID: <F4FBE7F2460.00000CE3jrkrideau@inbox.com>

No attachements. R-help is very picky about attachements.

 I'd suggest supplying the data using dput() . See ?dput for more information

It is probably best to just copy and paste the code into your email. If this is no practical try sending a plain text file with a .txt extension

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mar.sapina at gmail.com
> Sent: Tue, 27 Oct 2015 18:34:12 +0100
> To: r-help at r-project.org
> Subject: [R] Neuralnet package in R gives wrong output
> 
> I'm trying to generate prediction of the column "dubina" using this
> algorithm made in R's "neuralnet" package. But I keep getting
> non-reliable
> neural-net output. I have tried changing the number of hidden layers,
> normalizing and denormalizing data. Is there a mistake in the algorithm,
> maybe because of the activation function being logistic, not sigmoid?
> 
> The algorithm and the dataset are added as attachments but are added as
> attachments.
> 
> I'd be very grateful if you'd help me.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Can't remember your password? Do you need a strong and secure password?
Use Password manager! It stores your passwords & protects your account.


From wush978 at gmail.com  Wed Oct 28 14:02:58 2015
From: wush978 at gmail.com (Wush Wu)
Date: Wed, 28 Oct 2015 21:02:58 +0800
Subject: [R] Failed to read UTF-16LE file on Windows
In-Reply-To: <CABjzuv4jf1D1TDeTdk=2td2z-dDgBE5dRruW8=WCTmAbueqD5A@mail.gmail.com>
References: <CABjzuv4jf1D1TDeTdk=2td2z-dDgBE5dRruW8=WCTmAbueqD5A@mail.gmail.com>
Message-ID: <CABjzuv7kbmsU2=mc15trniVOMsHJrJPYR4d13Aij0L5KVtTkuQ@mail.gmail.com>

Dear all,

Here is an answer I found.

```
library(stringi)
src <- readBin("orglist-100.CSV", "raw", file.info("orglist-100.CSV")$size)
src2 <- stri_encode(src, "UTF-16LE", "UTF-8")
con <- textConnection(src2)
answer <- read.table(con, header = TRUE, sep = ",")
```

Hope it will help someone in the future.

Wush


2015-10-27 21:24 GMT+08:00 Wush Wu <wush978 at gmail.com>:

> Dear all,
>
> I tried to run the following code on 3 different OS:
>
> ```
> download.file("
> https://raw.githubusercontent.com/wush978/DataScienceAndR/course/RBasic-07-Loading-Dataset/orglist-100.CSV",
> destfile = "orglist-100.CSV")
> con <- file("orglist-100.CSV", encoding = "UTF-16LE")
> src <- readLines(con)
> length(src) # should be 100
> ```
>
> On ubuntu and OS X, R correctly read 100 lines from the file. However, the
> windows will only read the first line with the following warning message:
>
> ```
> Warning message:
> In readLines(file("orglist-100.CSV", encoding = "UTF-16LE")) :
>   incomplete final line found on 'orglist-100.CSV'
> ```
>
> Is there any recommended way to read a local UTF-16LE file on windows?
>
> Thanks,
> Wush
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Oct 28 14:12:42 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 28 Oct 2015 08:12:42 -0500
Subject: [R] coxme adequacy check
In-Reply-To: <mailman.7.1446030002.30460.r-help@r-project.org>
References: <mailman.7.1446030002.30460.r-help@r-project.org>
Message-ID: <c10f8b$1nvgr2@ironport10.mayo.edu>



On 10/28/2015 06:00 AM, r-help-request at r-project.org wrote:
> Hello all!
>
> I?m fitting a mixed effects cox model with coxme function of coxme package.
> I want to konw what is the best way to check the model adequacy, once that
> function cox.zph that does not work for coxme objects.
>
> Thanks in advanced,
>
> Raoni

No one has done the theory work to see if the method used by coxme extends to random 
effects models.  I suspect that it does, but that is a long way from a proof.  So at this 
point I don't have a good suggestion, even though I have been thinking about the problem.

Terry Therneau


From jorgeivanvelez at gmail.com  Wed Oct 28 18:17:54 2015
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Wed, 28 Oct 2015 12:17:54 -0500
Subject: [R] Extract entries from matrix
In-Reply-To: <CAKL8G3F1rfcYXfq8n2YkYjDW=67My9z9uu2LpC07WK4vbtYdCg@mail.gmail.com>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
	<CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4FE9@mb02.ads.tamu.edu>
	<CAKL8G3F1rfcYXfq8n2YkYjDW=67My9z9uu2LpC07WK4vbtYdCg@mail.gmail.com>
Message-ID: <CAKL8G3Gde6OyMP+oC=snwWcZES7qn=4zJz_SGKGry8mUqUMHGQ@mail.gmail.com>

Dear all,

I thought I would better send an image illustrating that the problem is
(hope the file gets through).  In the picture, the matrix "m" is given by

## input
m <- structure(c(0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2,
2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,
0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5,
5), .Dim = c(12L, 5L))

We start from the entry [1,1] and select all values in the diagonal until
we find the first zero. That is, we select the values in purple.  Because
the first zero is found in [4,4], the next matrix begins in the 4th row.
The values of interest would be 1, 2, 3, 4, 5 (light blue).  The last value
in this resulting vector is entry m[8,5], which is located at the maximum
number of columns of m. Hence, the next matrix to work with starts at row 9
and the values of interest are 1, 2 (in orange).

The output vector would then be of the same length as the number of rows in
"m", and would contain the elements previously selected.

Any ideas on how to proceed?

Thank you very much in advance.

Best regards,
Jorge Velez.-



On Tue, Oct 27, 2015 at 4:38 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
wrote:

> Thank you all for your solutions and comments.
>
> As Dr. Carlson mentioned, we leave rows 1 to 3 out as they are all zeroes.
> Then, the entries I need to select from m are
>
> ----------------
> entry     value
> ----------------
> 4,1  ---> 1
> 5,2  ---> 2
> 6,3  ---> 3
> 7,1  ---> 1
> 8,2  ---> 2
> 9,3  ---> 3
> 10,4  ---> 4
> 11,5  ---> 5
> 12,1  ---> 1
>
> Note that the entry [7,4] is zero, so we start from the first column in
> the 7th row and then select entry [7,1] instead.  That's what I meant by  "...
> the idea is to extract the diagonal elements until a zero is found."  I
> should have said *entries* instead of  _diagonal elements_. I am sorry Dr.
> Turner for the confusion.
>
> Starting with m
>
> R> m
> #       [,1] [,2] [,3] [,4] [,5]
> # [1,]    0    0    0    0    0
> # [2,]    0    0    0    0    0
> # [3,]    0    0    0    0    0
> # [4,]    1    2    3    0    0
> # [5,]    1    2    3    0    0
> # [6,]    1    2    3    0    0
> # [7,]    1    2    3    0    0
> # [8,]    1    2    3    0    0
> # [9,]    1    2    3    4    0
> #[10,]    1    2    3    4    0
> #[11,]    1    2    3    4    5
> #[12,]    1    2    3    4    5
>
> the first submatrix to work with is
>
> # [4,]    1    2    3    0    0
> # [5,]    1    2    3    0    0
> # [6,]    1    2    3    0    0
>
> from which the elements of interest are 1, 2, 3.  Note that the 7th row of
> m is not included here because m[7, 5] = 0.
>
> Further, the second submatrix is
>
> # [7,]    1    2    3    0    0
> # [8,]    1    2    3    0    0
> # [9,]    1    2    3    4    0
> #[10,]    1    2    3    4    0
> #[11,]    1    2    3    4    5
>
> and the corresponding elements are 1, 2, 3, 4, 5.
>
> And the last matrix is
>
> #[12,]    1    2    3    4    5
>
> from which the position [12,1] is selected.
>
> So, the resulting entries from this process are 1, 2, 3, 1, 2, 3, 4, 5, 1.
>
> Thank you in advance for any additional insight you may provide.
>
> Regards,
> Jorge Velez.-
>
>
>
> On Tue, Oct 27, 2015 at 4:06 PM, David L Carlson <dcarlson at tamu.edu>
> wrote:
>
>> I don't see how you are getting the result you provide.
>>
>> > m
>>       [,1] [,2] [,3] [,4] [,5]
>>  [1,]    0    0    0    0    0
>>  [2,]    0    0    0    0    0
>>  [3,]    0    0    0    0    0
>>  [4,]    1    2    3    0    0
>>  [5,]    1    2    3    0    0
>>  [6,]    1    2    3    0    0
>>  [7,]    1    2    3    0    0
>>  [8,]    1    2    3    0    0
>>  [9,]    1    2    3    4    0
>> [10,]    1    2    3    4    0
>> [11,]    1    2    3    4    5
>> [12,]    1    2    3    4    5
>> > t(sapply(1:8, function(x) diag(m[x:12, ])))
>>      [,1] [,2] [,3] [,4] [,5]
>> [1,]    0    0    0    0    0
>> [2,]    0    0    3    0    0
>> [3,]    0    2    3    0    0
>> [4,]    1    2    3    0    0
>> [5,]    1    2    3    0    0
>> [6,]    1    2    3    4    0
>> [7,]    1    2    3    4    5
>> [8,]    1    2    3    4    5
>>
>> These are all of the diagonals from the 1st through 8th rows. The first 3
>> begin with 0 so we leave them out, but then we have 4th: 1, 2, 3; 5th: 1,
>> 2, 3; 6th: 1, 2, 3, 4, etc so you must have some additional rule in mind to
>> get your answer.
>>
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>>
>>
>>
>> -----Original Message-----
>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge I
>> Velez
>> Sent: Tuesday, October 27, 2015 2:44 PM
>> To: jim holtman
>> Cc: R-help
>> Subject: Re: [R] Extract entries from matrix
>>
>> Dear Jim,
>>
>> Thank you very much for your quick reply.
>>
>> I am sorry for the confusion it may have caused, but I messed up the
>> indexes in my example.  I would like, from the following matrix "m"
>>
>> ## input
>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
>> 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
>> 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim = c(12L,
>> 5L))
>>
>> to obtain
>>
>>  1 2 3 1 2 3 4 5 1
>>
>> Sure using m[idx] will give the desired result.  The problem is that idx
>> is
>> not known and needs to be determined from "m".  I would like to use
>> something like
>>
>> extractDiagonals(m)
>> ## [1]  1 2 3 1 2 3 4 5 1
>>
>> I look forward to your reply.  Thanks in advance.
>>
>> Best regards,
>> Jorge Velez.-
>>
>>
>>
>> On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com> wrote:
>>
>> > If you want to use the numbers you gave a the index into the matrix,
>> then
>> > you can create a matrix with the values and then index into 'm'.  I
>> don't
>> > see a '4' in the output example you gave using your index values:
>> >
>> > > m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> > +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>> > +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>> > +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> > +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>> > +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>> > +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> > +  5L), .Dim = c(22L, 5L))
>> > > # create index matrix
>> > > indx <- matrix(c(4, 1,
>> > +  5, 2,
>> > +  6, 3,
>> > +  7, 1,
>> > +  8, 2,
>> > +  9, 3,
>> > +  10, 1,
>> > +  11, 2,
>> > +  12, 3), ncol = 2, byrow = TRUE)
>> > >
>> > >
>> > > m
>> >       [,1] [,2] [,3] [,4] [,5]
>> >  [1,]    0    0    0    0    0
>> >  [2,]    0    0    0    0    0
>> >  [3,]    0    0    0    0    0
>> >  [4,]    1    2    3    0    0
>> >  [5,]    1    2    3    0    0
>> >  [6,]    1    2    3    0    0
>> >  [7,]    1    2    3    0    0
>> >  [8,]    1    2    3    0    0
>> >  [9,]    1    2    3    4    0
>> > [10,]    1    2    3    4    0
>> > [11,]    1    2    3    4    5
>> > [12,]    1    2    3    4    5
>> > [13,]    1    2    3    4    5
>> > [14,]    1    2    3    4    5
>> > [15,]    1    2    3    4    5
>> > [16,]    1    2    3    4    5
>> > [17,]    1    2    3    4    5
>> > [18,]    1    2    3    4    5
>> > [19,]    1    2    3    4    5
>> > [20,]    1    2    3    4    5
>> > [21,]    1    2    3    4    5
>> > [22,]    1    2    3    4    5
>> > > indx
>> >       [,1] [,2]
>> >  [1,]    4    1
>> >  [2,]    5    2
>> >  [3,]    6    3
>> >  [4,]    7    1
>> >  [5,]    8    2
>> >  [6,]    9    3
>> >  [7,]   10    1
>> >  [8,]   11    2
>> >  [9,]   12    3
>> > > m[indx]
>> > [1] 1 2 3 1 2 3 1 2 3
>> >
>> >
>> > Jim Holtman
>> > Data Munger Guru
>> >
>> > What is the problem that you are trying to solve?
>> > Tell me what you want to do, not how you want to do it.
>> >
>> > On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <
>> jorgeivanvelez at gmail.com>
>> > wrote:
>> >
>> >> Dear R-help,
>> >>
>> >> I am working with a matrix "m" from which I would like to extract some
>> >> elements.  An toy example is as follows:
>> >>
>> >> ## input matrix
>> >> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>> >> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>> >> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>> >> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>> >> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>> >> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>> >> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>> >> 5L), .Dim = c(22L, 5L))
>> >>
>> >> R> m
>> >> #         [,1]  [,2] [,3] [,4] [,5]
>> >> #  [1,]    0    0    0    0    0
>> >> #  [2,]    0    0    0    0    0
>> >> #  [3,]    0    0    0    0    0
>> >> #  [4,]    1    2    3    0    0
>> >> #  [5,]    1    2    3    0    0
>> >> #  [6,]    1    2    3    0    0
>> >> #  [7,]    1    2    3    0    0
>> >> #  [8,]    1    2    3    0    0
>> >> #  [9,]    1    2    3    4    0
>> >> # [10,]   1    2    3    4    0
>> >> # [11,]   1    2    3    4    5
>> >> # [12,]   1    2    3    4    5
>> >>
>> >> >From "m", I would like to extract the entries
>> >>
>> >> 4, 1
>> >> 5, 2
>> >> 6, 3
>> >> 7, 1
>> >> 8, 2
>> >> 9, 3
>> >> 10, 1
>> >> 11, 2
>> >> 12, 3
>> >>
>> >> so at the end of applying a function "f" to "m" I get
>> >>
>> >> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
>> >>
>> >>
>> >> Basically the idea is to extract the diagonal elements until a zero is
>> >> found.
>> >>
>> >> In the real problem the dimensions of "m" are much bigger, but this
>> >> smaller
>> >> version of "m" illustrate what needs to be done.
>> >>
>> >> I would greatly appreciate any ideas on how to do this.
>> >>
>> >> Thanks in advance,
>> >> Jorge Velez.-
>> >>
>> >>         [[alternative HTML version deleted]]
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: example.png
Type: image/png
Size: 35497 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20151028/4d4d0860/attachment.png>

From boris.steipe at utoronto.ca  Wed Oct 28 19:18:55 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 28 Oct 2015 14:18:55 -0400
Subject: [R] Extract entries from matrix
In-Reply-To: <CAKL8G3Gde6OyMP+oC=snwWcZES7qn=4zJz_SGKGry8mUqUMHGQ@mail.gmail.com>
References: <CAKL8G3EbGYXyONOQRNidABenVwmw3s0_8g3YXvzn4Ppukudwnw@mail.gmail.com>
	<CAAxdm-7x5R2yurFxxV=qoZLMZavD-yh3MyNjWcMdsdpK=JZP4Q@mail.gmail.com>
	<CAKL8G3HsziTML=v=ok39k-a8ir1-AFQ+6k04bmUXzwqnfRvyjw@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA7262D6D4FE9@mb02.ads.tamu.edu>
	<CAKL8G3F1rfcYXfq8n2YkYjDW=67My9z9uu2LpC07WK4vbtYdCg@mail.gmail.com>
	<CAKL8G3Gde6OyMP+oC=snwWcZES7qn=4zJz_SGKGry8mUqUMHGQ@mail.gmail.com>
Message-ID: <2AEAE5DE-666D-41E9-AE29-411455C87213@utoronto.ca>

Your code does not produce the matrix in your image.
The first three rows contain all-zeros and the last row is missing.
The following line fixes that:

m <- rbind(m[-(1:3), ], 1:5)

Given that matrix, the following code produces the output
you have illustrated. It's so trivial however that I suspect
something must be missing in your problem description.



v <- numeric(nrow(m))
j <- 1
for (i in 1:nrow(m)) {
    if (j > ncol(m) || m[i,j] == 0) {
        j <- 1
    }
    v[i] <- m[i,j]
    j <- j+1
}

v

Note that this puts 0 in the output if
there is a zero in your first column and
the "diagonal". Your example didn't have that.



B.


On Oct 28, 2015, at 1:17 PM, Jorge I Velez <jorgeivanvelez at gmail.com> wrote:

> Dear all,
> 
> I thought I would better send an image illustrating that the problem is
> (hope the file gets through).  In the picture, the matrix "m" is given by
> 
> ## input
> m <- structure(c(0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2,
> 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,
> 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5,
> 5), .Dim = c(12L, 5L))
> 
> We start from the entry [1,1] and select all values in the diagonal until
> we find the first zero. That is, we select the values in purple.  Because
> the first zero is found in [4,4], the next matrix begins in the 4th row.
> The values of interest would be 1, 2, 3, 4, 5 (light blue).  The last value
> in this resulting vector is entry m[8,5], which is located at the maximum
> number of columns of m. Hence, the next matrix to work with starts at row 9
> and the values of interest are 1, 2 (in orange).
> 
> The output vector would then be of the same length as the number of rows in
> "m", and would contain the elements previously selected.
> 
> Any ideas on how to proceed?
> 
> Thank you very much in advance.
> 
> Best regards,
> Jorge Velez.-
> 
> 
> 
> On Tue, Oct 27, 2015 at 4:38 PM, Jorge I Velez <jorgeivanvelez at gmail.com>
> wrote:
> 
>> Thank you all for your solutions and comments.
>> 
>> As Dr. Carlson mentioned, we leave rows 1 to 3 out as they are all zeroes.
>> Then, the entries I need to select from m are
>> 
>> ----------------
>> entry     value
>> ----------------
>> 4,1  ---> 1
>> 5,2  ---> 2
>> 6,3  ---> 3
>> 7,1  ---> 1
>> 8,2  ---> 2
>> 9,3  ---> 3
>> 10,4  ---> 4
>> 11,5  ---> 5
>> 12,1  ---> 1
>> 
>> Note that the entry [7,4] is zero, so we start from the first column in
>> the 7th row and then select entry [7,1] instead.  That's what I meant by  "...
>> the idea is to extract the diagonal elements until a zero is found."  I
>> should have said *entries* instead of  _diagonal elements_. I am sorry Dr.
>> Turner for the confusion.
>> 
>> Starting with m
>> 
>> R> m
>> #       [,1] [,2] [,3] [,4] [,5]
>> # [1,]    0    0    0    0    0
>> # [2,]    0    0    0    0    0
>> # [3,]    0    0    0    0    0
>> # [4,]    1    2    3    0    0
>> # [5,]    1    2    3    0    0
>> # [6,]    1    2    3    0    0
>> # [7,]    1    2    3    0    0
>> # [8,]    1    2    3    0    0
>> # [9,]    1    2    3    4    0
>> #[10,]    1    2    3    4    0
>> #[11,]    1    2    3    4    5
>> #[12,]    1    2    3    4    5
>> 
>> the first submatrix to work with is
>> 
>> # [4,]    1    2    3    0    0
>> # [5,]    1    2    3    0    0
>> # [6,]    1    2    3    0    0
>> 
>> from which the elements of interest are 1, 2, 3.  Note that the 7th row of
>> m is not included here because m[7, 5] = 0.
>> 
>> Further, the second submatrix is
>> 
>> # [7,]    1    2    3    0    0
>> # [8,]    1    2    3    0    0
>> # [9,]    1    2    3    4    0
>> #[10,]    1    2    3    4    0
>> #[11,]    1    2    3    4    5
>> 
>> and the corresponding elements are 1, 2, 3, 4, 5.
>> 
>> And the last matrix is
>> 
>> #[12,]    1    2    3    4    5
>> 
>> from which the position [12,1] is selected.
>> 
>> So, the resulting entries from this process are 1, 2, 3, 1, 2, 3, 4, 5, 1.
>> 
>> Thank you in advance for any additional insight you may provide.
>> 
>> Regards,
>> Jorge Velez.-
>> 
>> 
>> 
>> On Tue, Oct 27, 2015 at 4:06 PM, David L Carlson <dcarlson at tamu.edu>
>> wrote:
>> 
>>> I don't see how you are getting the result you provide.
>>> 
>>>> m
>>>      [,1] [,2] [,3] [,4] [,5]
>>> [1,]    0    0    0    0    0
>>> [2,]    0    0    0    0    0
>>> [3,]    0    0    0    0    0
>>> [4,]    1    2    3    0    0
>>> [5,]    1    2    3    0    0
>>> [6,]    1    2    3    0    0
>>> [7,]    1    2    3    0    0
>>> [8,]    1    2    3    0    0
>>> [9,]    1    2    3    4    0
>>> [10,]    1    2    3    4    0
>>> [11,]    1    2    3    4    5
>>> [12,]    1    2    3    4    5
>>>> t(sapply(1:8, function(x) diag(m[x:12, ])))
>>>     [,1] [,2] [,3] [,4] [,5]
>>> [1,]    0    0    0    0    0
>>> [2,]    0    0    3    0    0
>>> [3,]    0    2    3    0    0
>>> [4,]    1    2    3    0    0
>>> [5,]    1    2    3    0    0
>>> [6,]    1    2    3    4    0
>>> [7,]    1    2    3    4    5
>>> [8,]    1    2    3    4    5
>>> 
>>> These are all of the diagonals from the 1st through 8th rows. The first 3
>>> begin with 0 so we leave them out, but then we have 4th: 1, 2, 3; 5th: 1,
>>> 2, 3; 6th: 1, 2, 3, 4, etc so you must have some additional rule in mind to
>>> get your answer.
>>> 
>>> -------------------------------------
>>> David L Carlson
>>> Department of Anthropology
>>> Texas A&M University
>>> College Station, TX 77840-4352
>>> 
>>> 
>>> 
>>> -----Original Message-----
>>> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jorge I
>>> Velez
>>> Sent: Tuesday, October 27, 2015 2:44 PM
>>> To: jim holtman
>>> Cc: R-help
>>> Subject: Re: [R] Extract entries from matrix
>>> 
>>> Dear Jim,
>>> 
>>> Thank you very much for your quick reply.
>>> 
>>> I am sorry for the confusion it may have caused, but I messed up the
>>> indexes in my example.  I would like, from the following matrix "m"
>>> 
>>> ## input
>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L,
>>> 0L, 0L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L, 0L, 0L, 3L, 3L,
>>> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L,
>>> 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 5L, 5L), .Dim = c(12L,
>>> 5L))
>>> 
>>> to obtain
>>> 
>>> 1 2 3 1 2 3 4 5 1
>>> 
>>> Sure using m[idx] will give the desired result.  The problem is that idx
>>> is
>>> not known and needs to be determined from "m".  I would like to use
>>> something like
>>> 
>>> extractDiagonals(m)
>>> ## [1]  1 2 3 1 2 3 4 5 1
>>> 
>>> I look forward to your reply.  Thanks in advance.
>>> 
>>> Best regards,
>>> Jorge Velez.-
>>> 
>>> 
>>> 
>>> On Tue, Oct 27, 2015 at 2:31 PM, jim holtman <jholtman at gmail.com> wrote:
>>> 
>>>> If you want to use the numbers you gave a the index into the matrix,
>>> then
>>>> you can create a matrix with the values and then index into 'm'.  I
>>> don't
>>>> see a '4' in the output example you gave using your index values:
>>>> 
>>>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>> +  1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>>>> +  2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>>>> +  0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>>> +  3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>>>> +  4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>>>> +  0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>>>> +  5L), .Dim = c(22L, 5L))
>>>>> # create index matrix
>>>>> indx <- matrix(c(4, 1,
>>>> +  5, 2,
>>>> +  6, 3,
>>>> +  7, 1,
>>>> +  8, 2,
>>>> +  9, 3,
>>>> +  10, 1,
>>>> +  11, 2,
>>>> +  12, 3), ncol = 2, byrow = TRUE)
>>>>> 
>>>>> 
>>>>> m
>>>>      [,1] [,2] [,3] [,4] [,5]
>>>> [1,]    0    0    0    0    0
>>>> [2,]    0    0    0    0    0
>>>> [3,]    0    0    0    0    0
>>>> [4,]    1    2    3    0    0
>>>> [5,]    1    2    3    0    0
>>>> [6,]    1    2    3    0    0
>>>> [7,]    1    2    3    0    0
>>>> [8,]    1    2    3    0    0
>>>> [9,]    1    2    3    4    0
>>>> [10,]    1    2    3    4    0
>>>> [11,]    1    2    3    4    5
>>>> [12,]    1    2    3    4    5
>>>> [13,]    1    2    3    4    5
>>>> [14,]    1    2    3    4    5
>>>> [15,]    1    2    3    4    5
>>>> [16,]    1    2    3    4    5
>>>> [17,]    1    2    3    4    5
>>>> [18,]    1    2    3    4    5
>>>> [19,]    1    2    3    4    5
>>>> [20,]    1    2    3    4    5
>>>> [21,]    1    2    3    4    5
>>>> [22,]    1    2    3    4    5
>>>>> indx
>>>>      [,1] [,2]
>>>> [1,]    4    1
>>>> [2,]    5    2
>>>> [3,]    6    3
>>>> [4,]    7    1
>>>> [5,]    8    2
>>>> [6,]    9    3
>>>> [7,]   10    1
>>>> [8,]   11    2
>>>> [9,]   12    3
>>>>> m[indx]
>>>> [1] 1 2 3 1 2 3 1 2 3
>>>> 
>>>> 
>>>> Jim Holtman
>>>> Data Munger Guru
>>>> 
>>>> What is the problem that you are trying to solve?
>>>> Tell me what you want to do, not how you want to do it.
>>>> 
>>>> On Tue, Oct 27, 2015 at 2:43 PM, Jorge I Velez <
>>> jorgeivanvelez at gmail.com>
>>>> wrote:
>>>> 
>>>>> Dear R-help,
>>>>> 
>>>>> I am working with a matrix "m" from which I would like to extract some
>>>>> elements.  An toy example is as follows:
>>>>> 
>>>>> ## input matrix
>>>>> m <- structure(c(0L, 0L, 0L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
>>>>> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 0L, 0L, 0L, 2L, 2L, 2L, 2L,
>>>>> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 0L,
>>>>> 0L, 0L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
>>>>> 3L, 3L, 3L, 3L, 3L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 4L, 4L, 4L,
>>>>> 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 0L, 0L, 0L, 0L, 0L,
>>>>> 0L, 0L, 0L, 0L, 0L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L,
>>>>> 5L), .Dim = c(22L, 5L))
>>>>> 
>>>>> R> m
>>>>> #         [,1]  [,2] [,3] [,4] [,5]
>>>>> #  [1,]    0    0    0    0    0
>>>>> #  [2,]    0    0    0    0    0
>>>>> #  [3,]    0    0    0    0    0
>>>>> #  [4,]    1    2    3    0    0
>>>>> #  [5,]    1    2    3    0    0
>>>>> #  [6,]    1    2    3    0    0
>>>>> #  [7,]    1    2    3    0    0
>>>>> #  [8,]    1    2    3    0    0
>>>>> #  [9,]    1    2    3    4    0
>>>>> # [10,]   1    2    3    4    0
>>>>> # [11,]   1    2    3    4    5
>>>>> # [12,]   1    2    3    4    5
>>>>> 
>>>>>> From "m", I would like to extract the entries
>>>>> 
>>>>> 4, 1
>>>>> 5, 2
>>>>> 6, 3
>>>>> 7, 1
>>>>> 8, 2
>>>>> 9, 3
>>>>> 10, 1
>>>>> 11, 2
>>>>> 12, 3
>>>>> 
>>>>> so at the end of applying a function "f" to "m" I get
>>>>> 
>>>>> 1, 2, 3, 1, 2, 3, 4, 1, 2, 3
>>>>> 
>>>>> 
>>>>> Basically the idea is to extract the diagonal elements until a zero is
>>>>> found.
>>>>> 
>>>>> In the real problem the dimensions of "m" are much bigger, but this
>>>>> smaller
>>>>> version of "m" illustrate what needs to be done.
>>>>> 
>>>>> I would greatly appreciate any ideas on how to do this.
>>>>> 
>>>>> Thanks in advance,
>>>>> Jorge Velez.-
>>>>> 
>>>>>        [[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> 
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
> <example.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dagmar.cimiotti at gmx.de  Wed Oct 28 13:20:28 2015
From: dagmar.cimiotti at gmx.de (Dagmar Cimiotti)
Date: Wed, 28 Oct 2015 13:20:28 +0100
Subject: [R] rbind - names in dataframe. Beginner Question
Message-ID: <5630BD8C.3020300@gmx.de>

Hello,
It must be very easy.

I have data like this:
myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert", 
"Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
myframe
bighunger <- subset (myframe, myframe$Hunger>=2 &myframe$Hunger <3 )
bighunger
verybighunger <- subset(myframe,myframe$Hunger>=3)
verybighunger
hungry <- rbind (bighunger=bighunger,very=verybighunger)
hungry

BUT I want a result like this:
myframesresult <- data.frame(Hunger=c("bighunger","bighunger","very"), 
ID=c("Bert", "Bert", "duck"), Hunger=c(2,2,3))
myframesresult

Where is my mistake?
Very many thanks in advance!!
Dagmar


From komp at ittc.ku.edu  Wed Oct 28 15:25:49 2015
From: komp at ittc.ku.edu (Ed Komp)
Date: Wed, 28 Oct 2015 09:25:49 -0500
Subject: [R] problem with formula argument to randomForest
Message-ID: <94C351AF-9BA8-4876-B290-81132E7864A2@ittc.ku.edu>



The randomForest function generates an error whenever
I supply it with a formula using the function, I() to inhibit interpretation.
When I do so, I always get an error like this one:
     Error in unique(c("AsIs", oldClass(x))) : object 'Age' not found

Is this because of:
1.  a restriction for the randomForest function that I have not seen documented;
2.  a deficiency / error in randomForest; or
3.  an error in my calling sequence?

I am including a very simple example to demonstrate the problem.
Simply using   I(<colname>)  generates the error.
This is not a meaningful use of I(), but is very simple.
My Interest is for  I( <col1> / <col2>) .

I also demonstrate that the usage of I() in a formula works just fine
for another discrimination function, lda.

The sample code is included after my signature, along with line-by-line output.

Thanks in advance !

Ed Komp
ITTC Lab, University of Kansas

                                        ===============
> library(rpart)
> library(MASS)
> library(randomForest)
randomForest 4.6-12
Type rfNews() to see new features/changes/bug fixes.
> formula <- as.formula('Kyphosis ~ Age + Number + Start')
> formula
Kyphosis ~ Age + Number + Start
> formulaWithI <- as.formula('Kyphosis ~ I(Age) + Number + Start')
> formulaWithI
Kyphosis ~ I(Age) + Number + Start
> fit <- randomForest(formula,   data=kyphosis)
> fitWithI <- randomForest(formulaWithI,   data=kyphosis)
Error in unique(c("AsIs", oldClass(x))) : object 'Age' not found
>
> fit <- lda(formula, data = kyphosis)
> fitWithI <- lda(formula, data = kyphosis)
> fitWithI
Call:
lda(formula, data = kyphosis)

Prior probabilities of groups:
   absent   present
0.7901235 0.2098765

Group means:
             Age   Number     Start
absent  79.89062 3.750000 12.609375
present 97.82353 5.176471  7.294118

Coefficients of linear discriminants:
                LD1
Age     0.005910971
Number  0.291501797
Start  -0.170496626
>
> sessionInfo()
R version 3.2.2 (2015-08-14)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: OS X 10.11 (El Capitan)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] randomForest_4.6-12 MASS_7.3-44         rpart_4.1-10


From sarah.goslee at gmail.com  Wed Oct 28 20:54:44 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 28 Oct 2015 15:54:44 -0400
Subject: [R] rbind - names in dataframe. Beginner Question
In-Reply-To: <5630BD8C.3020300@gmx.de>
References: <5630BD8C.3020300@gmx.de>
Message-ID: <CAM_vjumz2wUXO4K1EdCN53dcqTuqu1zr1nhKO+fAnOVPZY=Tcg@mail.gmail.com>

If I'm reading this correctly, you want to add a column to your
dataframe with a name corresponding to the value in the Hunger column.

myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
"Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )

myframe$Hungertype <- c("none", "bighunger", "verybighunger")[myframe$Hunger]

     ID Hunger    Hungertype
1 Ernie      1          none
2 Ernie      1          none
3 Ernie      1          none
4  Bert      2     bighunger
5  Bert      2     bighunger
6  Bert      1          none
7  Duck      3 verybighunger

Then you can subset it to remove low values, sort it, etc.

On Wed, Oct 28, 2015 at 8:20 AM, Dagmar Cimiotti <dagmar.cimiotti at gmx.de> wrote:
> Hello,
> It must be very easy.
>
> I have data like this:
> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
> myframe
> bighunger <- subset (myframe, myframe$Hunger>=2 &myframe$Hunger <3 )
> bighunger
> verybighunger <- subset(myframe,myframe$Hunger>=3)
> verybighunger
> hungry <- rbind (bighunger=bighunger,very=verybighunger)
> hungry
>
> BUT I want a result like this:
> myframesresult <- data.frame(Hunger=c("bighunger","bighunger","very"),
> ID=c("Bert", "Bert", "duck"), Hunger=c(2,2,3))
> myframesresult
>
> Where is my mistake?
> Very many thanks in advance!!
> Dagmar


From jvadams at usgs.gov  Wed Oct 28 21:35:11 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 28 Oct 2015 15:35:11 -0500
Subject: [R] Distribution hist
In-Reply-To: <CAN25tHQeX7nxMD5gWoM8w=hR5cPozE5B3XnpCGrU4ozVZkL6Ww@mail.gmail.com>
References: <CAN25tHQeX7nxMD5gWoM8w=hR5cPozE5B3XnpCGrU4ozVZkL6Ww@mail.gmail.com>
Message-ID: <CAN5YmCH3cfLRtm_UPmvuhXO-bzrVQJZj3p6Yx=vx_NGoHKH-aA@mail.gmail.com>

Something like this might help you get started.

Simulation <-
  c(10403, NA, NA, NA, NA, 11178, NA, NA, NA, NA, 11521, NA, NA,
  NA, NA, 11385, NA, NA, NA, NA, 10102, NA, NA, NA, NA, 10544.013,
  10339.925, 9912.695, 9928.198, 9932.112, 9008.05, 9437.174, 10406.784,
  10832.123, 11095.868, 10955.094, 10804.075, 9002.848, 11276.038,
  10503.487, 11899.525, 10085.509, 9109.918, 8953.339, 10135.833,
  11047.832, 14353.462, 8804.653, 11942.829, 7722.255, 9732.114,
  8413.027, 10213.796, 10091.471, 12317.169)

yl <- c(0, 20000)
par(mfrow=c(1, 2), oma=c(0, 0, 2, 0))
matplot(Simulation, type="l", ylim=yl)
fhist <- hist(Simulation, plot=FALSE)
with(fhist, plot(counts, mids, ylim=yl, type="o"))
mtext("Dim Mo Simulation 2 years", outer=TRUE, side=3)


Jean

On Tue, Oct 27, 2015 at 3:17 PM, bgnumis bgnum <bgnumis at gmail.com> wrote:

> Hi all,
>
> I have this data on "sim" variable
>
>  10403.000        NA        NA        NA        NA
>  11178.000        NA        NA        NA        NA
>  11521.000        NA        NA        NA        NA
>  11385.000        NA        NA        NA        NA
> 10102.000        NA        NA        NA        NA
>  10544.013 10339.925  9912.695  9928.198  9932.112
>   9008.050  9437.174 10406.784 10832.123 11095.868
>  10955.094 10804.075  9002.848 11276.038 10503.487
>  11899.525 10085.509  9109.918  8953.339 10135.833
>  11047.832 14353.462  8804.653 11942.829  7722.255
>   9732.114  8413.027 10213.796 10091.471 12317.169
>
> I want to use matplot on a left plot and a "distribution line" on a right
> plot.
>
> My idea is the same size from the ylim (max and min) on the left plot will
> be the same on the right plot (but I cannot get the same size so thar the
> right plot show the distribution of the matplot on the left.
>
> I tried this but canot (some suggest me using rect() for the boundaries of
> the second plot but I cannot achive what I want.
>
> I dont care if is it a hist or line plot but something similar a
> distribution shape (or like a bell)
>
>
> Can anyone try to help me?
>
> par(mar=c(10,6,6,6))
> matplot(Simulation,type="l",ylim=c(0,20000))
>
>
> title(" Dim Mo Simulation 2 years",font=4)
> fhist<-hist(Simulation,plot=FALSE)
>
> par(mar=c(6,0,6,6))
> barplot(fhist$counts,axes=FALSE, space=0,horiz=TRUE,col="lightgray")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From luckbuttered at gmail.com  Thu Oct 29 05:00:39 2015
From: luckbuttered at gmail.com (Luck Buttered)
Date: Wed, 28 Oct 2015 23:00:39 -0500
Subject: [R] =?utf-8?q?Lattice_Package_in_R=3A_Is_it_possible_to_develop_a?=
	=?utf-8?q?n_interactive_=E2=80=9Cscatterplot/network=E2=80=9D=3F?=
Message-ID: <CAGRPoRT+c9qsxYtuGgKsCmhNjZ1_Py6UkhUJzcdKgZ-NhgYLeA@mail.gmail.com>

I am developing an interactive scatterplot so that when the user rolls over
a data point, a label is displayed. However, I would also like to add edges
between certain data points.

I am successful at developing the interactive scatterplot using several
libraries, including grid, gridSVG, lattice, and adegraphics. Below is a
MWE:

##########################################

library(grid)
library(gridSVG)
library(lattice)
library(adegraphics)

x = rnorm(10)
y = rnorm(10)
dat = data.frame(label = letters[1:10], x, y)

customPanel2 <- function(x, y, ...) {
  for (j in 1:nrow(dat)) {
    grid.circle(x[j], y[j], r = unit(.5, "mm"),
                default.unit = "native",
                name = paste("point", j, sep = "."))
  }}

xyplot(y ~ x, panel = customPanel2, xlab = "x variable", ylab=NULL,
scales=list(tck = c(1,0), y=list(at=NULL)))
for (i in 1:nrow(dat)) {
  grid.text(as.character(dat$label)[i], x = 0.1, y = 0.01, just =
c("left", "bottom"), name = paste("label", i, sep = "."), gp =
gpar(fontface = "bold.italic"))}
for (i in 1:nrow(dat)) {
  grid.garnish(paste("point", i, sep = "."), onmouseover =
paste('highlight("', i, '.1.1")', sep = ""), onmouseout =
paste('dim("', i, '.1.1")', sep = ""))
  grid.garnish(paste("label", i, sep = "."), visibility = "hidden")}

grid.script(filename = "aqm.js", inline = TRUE)
grid.export("interactiveScat.svg")

######################################

The resulting .svg file accomplishes everything I am aiming for - except
that I also wish to add certain non-interactive edges. I tried to do this
by incorporating the adeg.panel.edges method from the adegraphics library
after defining the edges and the coordinates to be mapped. So, basically my
MWE stays the exact same, except the xplot(...) function from before is
replaced with:

edges = matrix(c(1, 2, 3, 2, 4, 1, 3, 4), byrow = TRUE, ncol = 2)
coords <- matrix(c(x[1], y[1], x[2], y[2], x[3], y[3], x[4], y[4]),
byrow = TRUE, ncol = 2)

xyplot(y ~ x, panel = function(customPanel2){adeg.panel.edges(edges,
coords, lty = 1:4, cex = 5)}, xlab = "x variable", ylab=NULL,
scales=list(tck = c(1,0), y=list(at=NULL)))

It seems that this simply erases the interactive scatterplot made from the
original xyplot, and simply outputs the static edge and coordinate image.

I tried to follow the example as seen in (
http://finzi.psych.upenn.edu/library/adegraphics/html/adeg.panel.nb.html):

edges <- matrix(c(1, 2, 3, 2, 4, 1, 3, 4), byrow = TRUE, ncol = 2)
coords <- matrix(c(0, 1, 1, 0, 0, -1, -1, 0), byrow = TRUE, ncol = 2)
xyplot(coords[,2] ~ coords[,1],
  panel = function(...){adeg.panel.edges(edges, coords, lty = 1:4, cex = 5)})


I am a bit at a loss as to how to troubleshoot this problem. I suspect it
is a misuse of the ellipses function(...) in xyplot.

I read the xyplot help manual, and note that they state:

"It is useful to know in this context that all arguments passed to a
high-level Lattice function (such as xyplot) that are not recognized by it
are passed through to the panel function. It is thus generally good
practice when defining panel functions to allow a ... argument."

I feel I did define my panel function customPanel(...) using ellipses in my
MWE:

customPanel2 <- function(x, y, ...)

Any suggestions are greatly appreciated!

	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Thu Oct 29 08:18:14 2015
From: Ramgad82 at gmx.net (Dagmar)
Date: Thu, 29 Oct 2015 08:18:14 +0100
Subject: [R] rbind - names in dataframe. Beginner Question
In-Reply-To: <CAM_vjumz2wUXO4K1EdCN53dcqTuqu1zr1nhKO+fAnOVPZY=Tcg@mail.gmail.com>
References: <5630BD8C.3020300@gmx.de>
	<CAM_vjumz2wUXO4K1EdCN53dcqTuqu1zr1nhKO+fAnOVPZY=Tcg@mail.gmail.com>
Message-ID: <5631C836.9080704@gmx.net>

Dear Sarah, (dear All),
Thank you for trying to help! You are right, that I want to add a column 
to my dataframe with a corresponding value to the Hunger column.
Your solution is basically correct in the result but my data are a 
little more complicated. Maybe that example describes it better:

myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
"Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3) )
  myframe

  # Now I want to add a column which says "hunger" for values between 
1.0 - 2;
  #"big Hunger" for >2 $ <=3, "very big Hunger" for >3
  # so that the result looks somewhat like that:
myframeresult <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
"Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3),Hungertype 
=c("Hunger", "Hunger", "Hunger", "bigHunger", "bigHunger", 
"Hunger","verybigHunger" ) )
  myframeresult

Does anyone know the solution?
Thanks in advance for trying,
Dagmar


Am 28.10.2015 um 20:54 schrieb Sarah Goslee:
> If I'm reading this correctly, you want to add a column to your
> dataframe with a name corresponding to the value in the Hunger column.
>
> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>
> myframe$Hungertype <- c("none", "bighunger", "verybighunger")[myframe$Hunger]
>
>       ID Hunger    Hungertype
> 1 Ernie      1          none
> 2 Ernie      1          none
> 3 Ernie      1          none
> 4  Bert      2     bighunger
> 5  Bert      2     bighunger
> 6  Bert      1          none
> 7  Duck      3 verybighunger
>
> Then you can subset it to remove low values, sort it, etc.
>
> On Wed, Oct 28, 2015 at 8:20 AM, Dagmar Cimiotti <dagmar.cimiotti at gmx.de> wrote:
>> Hello,
>> It must be very easy.
>>
>> I have data like this:
>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>> myframe
>> bighunger <- subset (myframe, myframe$Hunger>=2 &myframe$Hunger <3 )
>> bighunger
>> verybighunger <- subset(myframe,myframe$Hunger>=3)
>> verybighunger
>> hungry <- rbind (bighunger=bighunger,very=verybighunger)
>> hungry
>>
>> BUT I want a result like this:
>> myframesresult <- data.frame(Hunger=c("bighunger","bighunger","very"),
>> ID=c("Bert", "Bert", "duck"), Hunger=c(2,2,3))
>> myframesresult
>>
>> Where is my mistake?
>> Very many thanks in advance!!
>> Dagmar


From ruipbarradas at sapo.pt  Thu Oct 29 08:38:31 2015
From: ruipbarradas at sapo.pt (ruipbarradas at sapo.pt)
Date: Thu, 29 Oct 2015 07:38:31 +0000
Subject: [R] rbind - names in dataframe. Beginner Question
In-Reply-To: <5631C836.9080704@gmx.net>
References: <5630BD8C.3020300@gmx.de>
	<CAM_vjumz2wUXO4K1EdCN53dcqTuqu1zr1nhKO+fAnOVPZY=Tcg@mail.gmail.com>
	<5631C836.9080704@gmx.net>
Message-ID: <20151029073831.Horde.XZNJnu3D71_3gbE9tmMl6M1@mail.sapo.pt>

Hello,

Try the following.

newframe <- myframe
newframe$Hungertype <- with(myframe, ifelse(Hunger <= 1, NA,
?? ??? ??? ??? ??? ??? ??? ?ifelse(1 < Hunger & Hunger
<= 2, "Hunger",
?? ??? ??? ??? ??? ??? ??? ?ifelse(Hunger < 3,
"bigHUnger", "verybigHunger") )))

Note that the new column is of type character but that in your example
myframeresult it is of type factor.

Hope this helps,

Rui Barradas
?

Citando Dagmar <Ramgad82 at gmx.net>:

> Dear Sarah, (dear All),
> Thank you for trying to help! You are right, that I want to add a column
> to my dataframe with a corresponding value to the Hunger column.
> Your solution is basically correct in the result but my data are a
> little more complicated. Maybe that example describes it better:
>
> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
> "Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3) )
> myframe
>
> # Now I want to add a column which says "hunger" for values between 1.0
> - 2;
> #"big Hunger" for >2 $ <=3, "very big Hunger" for >3
> # so that the result looks somewhat like that:
> myframeresult <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
> "Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3),Hungertype
> =c("Hunger", "Hunger", "Hunger", "bigHunger", "bigHunger",
> "Hunger","verybigHunger" ) )
> myframeresult
>
> Does anyone know the solution?
> Thanks in advance for trying,
> Dagmar
>
> Am 28.10.2015 um 20:54 schrieb Sarah Goslee:
>> If I'm reading this correctly, you want to add a column to your
>> dataframe with a name corresponding to the value in the Hunger column.
>>
>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>>
>> myframe$Hungertype <- c("none", "bighunger",
>> "verybighunger")[myframe$Hunger]
>>
>> ? ? ?ID Hunger? ? Hungertype
>> 1 Ernie? ? ? 1? ? ? ? ? none
>> 2 Ernie? ? ? 1? ? ? ? ? none
>> 3 Ernie? ? ? 1? ? ? ? ? none
>> 4? Bert? ? ? 2? ? ?bighunger
>> 5? Bert? ? ? 2? ? ?bighunger
>> 6? Bert? ? ? 1? ? ? ? ? none
>> 7? Duck? ? ? 3 verybighunger
>>
>> Then you can subset it to remove low values, sort it, etc.
>>
>> On Wed, Oct 28, 2015 at 8:20 AM, Dagmar Cimiotti
>> <dagmar.cimiotti at gmx.de> wrote:
>>> Hello,
>>> It must be very easy.
>>>
>>> I have data like this:
>>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>>> myframe
>>> bighunger <- subset (myframe, myframe$Hunger>=2 &myframe$Hunger <3 )
>>> bighunger
>>> verybighunger <- subset(myframe,myframe$Hunger>=3)
>>> verybighunger
>>> hungry <- rbind (bighunger=bighunger,very=verybighunger)
>>> hungry
>>>
>>> BUT I want a result like this:
>>> myframesresult <- data.frame(Hunger=c("bighunger","bighunger","very"),
>>> ID=c("Bert", "Bert", "duck"), Hunger=c(2,2,3))
>>> myframesresult
>>>
>>> Where is my mistake?
>>> Very many thanks in advance!!
>>> Dagmar
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.htmland provide commented,
> minimal, self-contained, reproducible code.

?

	[[alternative HTML version deleted]]


From Gerrit.Eichner at math.uni-giessen.de  Thu Oct 29 09:10:40 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 29 Oct 2015 09:10:40 +0100 (MET)
Subject: [R] rbind - names in dataframe. Beginner Question
In-Reply-To: <5631C836.9080704@gmx.net>
References: <5630BD8C.3020300@gmx.de>
	<CAM_vjumz2wUXO4K1EdCN53dcqTuqu1zr1nhKO+fAnOVPZY=Tcg@mail.gmail.com>
	<5631C836.9080704@gmx.net>
Message-ID: <Pine.SOC.4.64.1510290909220.10472@solcom.hrz.uni-giessen.de>

Hello, Sarah,

take a look at the online help page of the function cut() (and apply the 
function to the Hunger-column).

  Hth  --  Gerrit

On Thu, 29 Oct 2015, Dagmar wrote:

> Dear Sarah, (dear All),
> Thank you for trying to help! You are right, that I want to add a column to 
> my dataframe with a corresponding value to the Hunger column.
> Your solution is basically correct in the result but my data are a little 
> more complicated. Maybe that example describes it better:
>
> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
> "Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3) )
> myframe
>
> # Now I want to add a column which says "hunger" for values between 1.0 - 2;
> #"big Hunger" for >2 $ <=3, "very big Hunger" for >3
> # so that the result looks somewhat like that:
> myframeresult <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
> "Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3),Hungertype 
> =c("Hunger", "Hunger", "Hunger", "bigHunger", "bigHunger", 
> "Hunger","verybigHunger" ) )
> myframeresult
>
> Does anyone know the solution?
> Thanks in advance for trying,
> Dagmar
>
>
> Am 28.10.2015 um 20:54 schrieb Sarah Goslee:
>> If I'm reading this correctly, you want to add a column to your
>> dataframe with a name corresponding to the value in the Hunger column.
>> 
>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>> 
>> myframe$Hungertype <- c("none", "bighunger", 
>> "verybighunger")[myframe$Hunger]
>>
>>       ID Hunger    Hungertype
>> 1 Ernie      1          none
>> 2 Ernie      1          none
>> 3 Ernie      1          none
>> 4  Bert      2     bighunger
>> 5  Bert      2     bighunger
>> 6  Bert      1          none
>> 7  Duck      3 verybighunger
>> 
>> Then you can subset it to remove low values, sort it, etc.
>> 
>> On Wed, Oct 28, 2015 at 8:20 AM, Dagmar Cimiotti <dagmar.cimiotti at gmx.de> 
>> wrote:
>>> Hello,
>>> It must be very easy.
>>> 
>>> I have data like this:
>>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>>> myframe
>>> bighunger <- subset (myframe, myframe$Hunger>=2 &myframe$Hunger <3 )
>>> bighunger
>>> verybighunger <- subset(myframe,myframe$Hunger>=3)
>>> verybighunger
>>> hungry <- rbind (bighunger=bighunger,very=verybighunger)
>>> hungry
>>> 
>>> BUT I want a result like this:
>>> myframesresult <- data.frame(Hunger=c("bighunger","bighunger","very"),
>>> ID=c("Bert", "Bert", "duck"), Hunger=c(2,2,3))
>>> myframesresult
>>> 
>>> Where is my mistake?
>>> Very many thanks in advance!!
>>> Dagmar
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pphil at uoregon.edu  Thu Oct 29 05:28:24 2015
From: pphil at uoregon.edu (Patrick Phillips)
Date: Wed, 28 Oct 2015 21:28:24 -0700
Subject: [R] Specifying interactions in coxme
Message-ID: <149041F6-9578-4B7A-8F76-1397B0B6813F@uoregon.edu>

I am trying to estimate variance components from a complex random effects survival model using coxme (Package version 2.2-5). I am having problems specifying interaction effects in the random terms. I wonder if this is simply not implemented in coxme yet.

For instance, using the model

coxme(Surv(DeathAge,Dead) ~  treatment + (1 | block/tank))

Works fine (tank nested within block), but 

coxme(Surv(DeathAge,Dead) ~  treatment + (1 | block) + (1 | block:tank))

fails with "Error in getgroups(f2$group, m) : Invalid grouping factor block:tank?.

By my understanding of model specification in R, these should be equivalent statements (assuming that that the tank effects have been coded appropriately as unique within blocks). Any interaction specified using ?:? appears to fail.

I am actually interested in much more complex models but can?t seem to be able to specify any interactions effects. For instance a factorial model like,

coxme(Surv(DeathAge,Dead) ~  treatment + (1 | room*block))

fails with "Error in getgroups(f2$group, m) : Invalid grouping factor room * block?.

Since I can?t directly specify the interaction effects and the factorial operator ?*? does not seem to work, I appear to be SOL. It seems that only nested effects specified by the ?/? operator are allowed. Multiple nesting is also OK, which is great for a single hierarchical nesting design, but not sufficient for more complex random effects models.

Any thoughts would be most welcome.

Thanks, Patrick



 


From Ramgad82 at gmx.net  Thu Oct 29 10:46:20 2015
From: Ramgad82 at gmx.net (Dagmar)
Date: Thu, 29 Oct 2015 10:46:20 +0100
Subject: [R] rbind - names in dataframe. Beginner Question
In-Reply-To: <20151029073831.Horde.XZNJnu3D71_3gbE9tmMl6M1@mail.sapo.pt>
References: <5630BD8C.3020300@gmx.de>
	<CAM_vjumz2wUXO4K1EdCN53dcqTuqu1zr1nhKO+fAnOVPZY=Tcg@mail.gmail.com>
	<5631C836.9080704@gmx.net>
	<20151029073831.Horde.XZNJnu3D71_3gbE9tmMl6M1@mail.sapo.pt>
Message-ID: <5631EAEC.4090307@gmx.net>

Hello Rui and Gerrit and Sarah,

Thank you very much for your help. I finally got it to work!

Have a great day!
Dagmar

Am 29.10.2015 um 08:38 schrieb ruipbarradas at sapo.pt:
>
> Hello,
>
> Try the following.
>
>
> newframe <- myframe
> newframe$Hungertype <- with(myframe, ifelse(Hunger <= 1, NA,
>                             ifelse(1 < Hunger & Hunger <= 2, "Hunger",
>                             ifelse(Hunger < 3, "bigHUnger", 
> "verybigHunger") )))
>
>
> Note that the new column is of type character but that in your example 
> myframeresult it is of type factor.
>
> Hope this helps,
>
> Rui Barradas
>
> Citando Dagmar <Ramgad82 at gmx.net <mailto:Ramgad82 at gmx.net>>:
>
>> Dear Sarah, (dear All),
>> Thank you for trying to help! You are right, that I want to add a 
>> column to my dataframe with a corresponding value to the Hunger column.
>> Your solution is basically correct in the result but my data are a 
>> little more complicated. Maybe that example describes it better:
>>
>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>> "Bert","Bert", "Duck"), Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3) )
>> myframe
>>
>> # Now I want to add a column which says "hunger" for values between 
>> 1.0 - 2;
>> #"big Hunger" for >2 $ <=3, "very big Hunger" for >3
>> # so that the result looks somewhat like that:
>> myframeresult <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>> "Bert","Bert", "Duck"), 
>> Hunger=c(1.2,1.3,1.1,2.1,2.2,1.4,3.3),Hungertype =c("Hunger", 
>> "Hunger", "Hunger", "bigHunger", "bigHunger", 
>> "Hunger","verybigHunger" ) )
>> myframeresult
>>
>> Does anyone know the solution?
>> Thanks in advance for trying,
>> Dagmar
>>
>>
>> Am 28.10.2015 um 20:54 schrieb Sarah Goslee:
>>
>>> If I'm reading this correctly, you want to add a column to your
>>> dataframe with a name corresponding to the value in the Hunger column.
>>>
>>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>>>
>>> myframe$Hungertype <- c("none", "bighunger", 
>>> "verybighunger")[myframe$Hunger]
>>>
>>>      ID Hunger    Hungertype
>>> 1 Ernie      1          none
>>> 2 Ernie      1          none
>>> 3 Ernie      1          none
>>> 4  Bert      2     bighunger
>>> 5  Bert      2     bighunger
>>> 6  Bert      1          none
>>> 7  Duck      3 verybighunger
>>>
>>> Then you can subset it to remove low values, sort it, etc.
>>>
>>> On Wed, Oct 28, 2015 at 8:20 AM, Dagmar Cimiotti 
>>> <dagmar.cimiotti at gmx.de <mailto:dagmar.cimiotti at gmx.de>> wrote:
>>>
>>>> Hello,
>>>> It must be very easy.
>>>>
>>>> I have data like this:
>>>> myframe <- data.frame (ID=c("Ernie", "Ernie", "Ernie", "Bert",
>>>> "Bert","Bert", "Duck"), Hunger=c(1,1,1,2,2,1,3) )
>>>> myframe
>>>> bighunger <- subset (myframe, myframe$Hunger>=2 &myframe$Hunger <3 )
>>>> bighunger
>>>> verybighunger <- subset(myframe,myframe$Hunger>=3)
>>>> verybighunger
>>>> hungry <- rbind (bighunger=bighunger,very=verybighunger)
>>>> hungry
>>>>
>>>> BUT I want a result like this:
>>>> myframesresult <- data.frame(Hunger=c("bighunger","bighunger","very"),
>>>> ID=c("Bert", "Bert", "duck"), Hunger=c(2,2,3))
>>>> myframesresult
>>>>
>>>> Where is my mistake?
>>>> Very many thanks in advance!!
>>>> Dagmar
>>>>
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
>> UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.htmland provide commented, 
>> minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From devazresearch at gmail.com  Thu Oct 29 11:32:01 2015
From: devazresearch at gmail.com (deva d)
Date: Thu, 29 Oct 2015 16:02:01 +0530
Subject: [R] problem in running a plspm ...
Message-ID: <CAKuYVCUEiE1+1=d810KiRT-pW2mUctU5G2ky7yFJjKkpuJtnkA@mail.gmail.com>

i am getting this error when i give the command for running a plspm ...

requesting someone to pl help ...


> MARCAP_PLS=plspm(Partialmodelfields,MARCAP_Path,MARCAP_Blocks,modes=
MARCAP_Modes)
Error in if (w_dif < specs$tol || iter == specs$maxiter) break :
  missing value where TRUE/FALSE needed


*....*




...............

	[[alternative HTML version deleted]]


From jari.oksanen at oulu.fi  Thu Oct 29 14:23:12 2015
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 29 Oct 2015 13:23:12 +0000
Subject: [R] monte carlo simulations in permanova in vegan package
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
Message-ID: <loom.20151029T141655-51@post.gmane.org>

Sean Porter <sporter <at> ori.org.za> writes:

> I am trying to run a PERMANOVA in the vegan package with an appropriate
> number of permutations (see example below), ideally 9999. Obviously that
> number of permutations does not exists so I would like to use Monte Carlo
> permutation tests to derive the probability value, as is done in the
> commercial package PERMANOVA+ for PRIMER. How can I adapt my code so that
> adonis will do so ? Many thanks, Sean
[...clip...]
> 
> > permanova <- adonis(species ~ time, data = time, permutations=999,
> method="bray")
> 
> 'nperm' > set of all permutations; Resetting 'nperm'.
> 
I assume we are talking about the latest version of vegan and permute
packages. In that case you really should switch to complete enumeration
if you request exceeds the number of distinct permutations. As people
have told you, you should be satisfied with that because there are no
more distinct permutations. Alternatively, you need more data.

If you mean by Monte Carlo that the same that you have a sampling with
return instead of permutation, or that the same observation can appear
several times and therefore some other unit is missing, then there are two
pieces of advice:

1. You should not do so.
2. If you want to do so, you can generate your resampling matrices
by hand and use that matrix as the argument of permutations=. See
the documentations (?adonis) which tells how to do so.

Cheers, Jari Oksanen


From bgunter.4567 at gmail.com  Thu Oct 29 15:11:50 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 29 Oct 2015 07:11:50 -0700
Subject: [R]
	=?utf-8?q?Lattice_Package_in_R=3A_Is_it_possible_to_develop_a?=
	=?utf-8?q?n_interactive_=E2=80=9Cscatterplot/network=E2=80=9D=3F?=
In-Reply-To: <CAGRPoRT+c9qsxYtuGgKsCmhNjZ1_Py6UkhUJzcdKgZ-NhgYLeA@mail.gmail.com>
References: <CAGRPoRT+c9qsxYtuGgKsCmhNjZ1_Py6UkhUJzcdKgZ-NhgYLeA@mail.gmail.com>
Message-ID: <CAGxFJbQ87DJd1t7HUZCyaQ8FyCXYzKxthPF_HbjQcKkxniJLzA@mail.gmail.com>

You need to go back and read an R tutorial (e.g. the Intro to R one
that ships with R) about how functions pass ... arguments. Your
customPanel2 function does not use the ... argument passed to it, so
what you are trying to do by including it?

Beyond that, I do not have the patience to go through all the special
packages and functions you used. Maybe someone else will, and maybe
therein lies the problem. But the above suggests it might rather be a
failure of basic understanding.

Cheers,
Bert

Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Wed, Oct 28, 2015 at 9:00 PM, Luck Buttered <luckbuttered at gmail.com> wrote:
> I am developing an interactive scatterplot so that when the user rolls over
> a data point, a label is displayed. However, I would also like to add edges
> between certain data points.
>
> I am successful at developing the interactive scatterplot using several
> libraries, including grid, gridSVG, lattice, and adegraphics. Below is a
> MWE:
>
> ##########################################
>
> library(grid)
> library(gridSVG)
> library(lattice)
> library(adegraphics)
>
> x = rnorm(10)
> y = rnorm(10)
> dat = data.frame(label = letters[1:10], x, y)
>
> customPanel2 <- function(x, y, ...) {
>   for (j in 1:nrow(dat)) {
>     grid.circle(x[j], y[j], r = unit(.5, "mm"),
>                 default.unit = "native",
>                 name = paste("point", j, sep = "."))
>   }}
>
> xyplot(y ~ x, panel = customPanel2, xlab = "x variable", ylab=NULL,
> scales=list(tck = c(1,0), y=list(at=NULL)))
> for (i in 1:nrow(dat)) {
>   grid.text(as.character(dat$label)[i], x = 0.1, y = 0.01, just =
> c("left", "bottom"), name = paste("label", i, sep = "."), gp =
> gpar(fontface = "bold.italic"))}
> for (i in 1:nrow(dat)) {
>   grid.garnish(paste("point", i, sep = "."), onmouseover =
> paste('highlight("', i, '.1.1")', sep = ""), onmouseout =
> paste('dim("', i, '.1.1")', sep = ""))
>   grid.garnish(paste("label", i, sep = "."), visibility = "hidden")}
>
> grid.script(filename = "aqm.js", inline = TRUE)
> grid.export("interactiveScat.svg")
>
> ######################################
>
> The resulting .svg file accomplishes everything I am aiming for - except
> that I also wish to add certain non-interactive edges. I tried to do this
> by incorporating the adeg.panel.edges method from the adegraphics library
> after defining the edges and the coordinates to be mapped. So, basically my
> MWE stays the exact same, except the xplot(...) function from before is
> replaced with:
>
> edges = matrix(c(1, 2, 3, 2, 4, 1, 3, 4), byrow = TRUE, ncol = 2)
> coords <- matrix(c(x[1], y[1], x[2], y[2], x[3], y[3], x[4], y[4]),
> byrow = TRUE, ncol = 2)
>
> xyplot(y ~ x, panel = function(customPanel2){adeg.panel.edges(edges,
> coords, lty = 1:4, cex = 5)}, xlab = "x variable", ylab=NULL,
> scales=list(tck = c(1,0), y=list(at=NULL)))
>
> It seems that this simply erases the interactive scatterplot made from the
> original xyplot, and simply outputs the static edge and coordinate image.
>
> I tried to follow the example as seen in (
> http://finzi.psych.upenn.edu/library/adegraphics/html/adeg.panel.nb.html):
>
> edges <- matrix(c(1, 2, 3, 2, 4, 1, 3, 4), byrow = TRUE, ncol = 2)
> coords <- matrix(c(0, 1, 1, 0, 0, -1, -1, 0), byrow = TRUE, ncol = 2)
> xyplot(coords[,2] ~ coords[,1],
>   panel = function(...){adeg.panel.edges(edges, coords, lty = 1:4, cex = 5)})
>
>
> I am a bit at a loss as to how to troubleshoot this problem. I suspect it
> is a misuse of the ellipses function(...) in xyplot.
>
> I read the xyplot help manual, and note that they state:
>
> "It is useful to know in this context that all arguments passed to a
> high-level Lattice function (such as xyplot) that are not recognized by it
> are passed through to the panel function. It is thus generally good
> practice when defining panel functions to allow a ... argument."
>
> I feel I did define my panel function customPanel(...) using ellipses in my
> MWE:
>
> customPanel2 <- function(x, y, ...)
>
> Any suggestions are greatly appreciated!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pmaclean2011 at yahoo.com  Thu Oct 29 16:21:25 2015
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Thu, 29 Oct 2015 15:21:25 +0000 (UTC)
Subject: [R] Recover value from boot and quantile function
References: <991554080.4241868.1446132085017.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <991554080.4241868.1446132085017.JavaMail.yahoo@mail.yahoo.com>

#This may be trivia for some but I am running several bootstraps and 
#I would like to create a table/data frame with original mean, std.error from the
#x.boot object and confidence intervals from x.quant object. The boot and quantifile function  do not show how.


library(boot)
x <- rgamma(100,2,1)
x.boot <- boot(x, function(y,i) mean(y[i]), R=1000)
x.boot
hist(x.boot$t)
str(x.boot)
x.quant <- quantile(x.boot$t, p=c(0.025, 0.975))
x.quant
x.quant[1:2]
str(x.quant) Peter Maclean Department of Economics UDSM

#Create table/data frame


From tianxu03 at gmail.com  Thu Oct 29 16:16:17 2015
From: tianxu03 at gmail.com (Victor Tian)
Date: Thu, 29 Oct 2015 11:16:17 -0400
Subject: [R] Pasting a large chunk of R code in terminals
Message-ID: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>

Hi there,

Often times, I would run R in the terminal when the task is computationally
intensive and a nice-looking UI is less desired.

However, pasting a large chunk of code into the terminal often times ends
up being messed up. In Python, the same problem would happen, however,
iPython provides a small functionality called magic word such as %paste
that can help paste the code neatly into the terminal.

I'm wondering if there's a similar functionality in R.

Thanks,

-- 
*Xu Tian*

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Oct 29 16:43:45 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 29 Oct 2015 10:43:45 -0500
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
Message-ID: <BEE6A76A-5633-4528-B021-977DAF40CC45@me.com>


> On Oct 29, 2015, at 10:16 AM, Victor Tian <tianxu03 at gmail.com> wrote:
> 
> Hi there,
> 
> Often times, I would run R in the terminal when the task is computationally
> intensive and a nice-looking UI is less desired.
> 
> However, pasting a large chunk of code into the terminal often times ends
> up being messed up. In Python, the same problem would happen, however,
> iPython provides a small functionality called magic word such as %paste
> that can help paste the code neatly into the terminal.
> 
> I'm wondering if there's a similar functionality in R.
> 
> Thanks,
> 
> -- 
> *Xu Tian*


Rather than pasting a large amount of code into the terminal, put the code into a text file (e.g. MyCode.R) and use ?source i your terminal session, to read in the file to then be parsed and run.

Regards,

Marc Schwartz


From lorenzo.isella at gmail.com  Thu Oct 29 16:46:45 2015
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 29 Oct 2015 16:46:45 +0100
Subject: [R] Caret and Summary
Message-ID: <20151029154645.GC6809@localhost.localdomain>

Dear All,
I trained a model, let's call it mm, using caret+Cubist.
When I type summary(mm), the output is rather long.
This is because a Cubist model is a long set of rules, partially
reminiscent of a classification tree.
How can I save summary(mm) in a printer/article friendly way when this is long?
Specifically to Cubist, is there some way to plot the structure of the
rules?
Cheers

Lorenzo


From marc_schwartz at me.com  Thu Oct 29 16:51:35 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 29 Oct 2015 10:51:35 -0500
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <BEE6A76A-5633-4528-B021-977DAF40CC45@me.com>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
	<BEE6A76A-5633-4528-B021-977DAF40CC45@me.com>
Message-ID: <4006B058-2C25-4059-A78F-A8A6FA7455E2@me.com>


> On Oct 29, 2015, at 10:43 AM, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
> 
>> On Oct 29, 2015, at 10:16 AM, Victor Tian <tianxu03 at gmail.com> wrote:
>> 
>> Hi there,
>> 
>> Often times, I would run R in the terminal when the task is computationally
>> intensive and a nice-looking UI is less desired.
>> 
>> However, pasting a large chunk of code into the terminal often times ends
>> up being messed up. In Python, the same problem would happen, however,
>> iPython provides a small functionality called magic word such as %paste
>> that can help paste the code neatly into the terminal.
>> 
>> I'm wondering if there's a similar functionality in R.
>> 
>> Thanks,
>> 
>> -- 
>> *Xu Tian*
> 
> 
> Rather than pasting a large amount of code into the terminal, put the code into a text file (e.g. MyCode.R) and use ?source i your terminal session, to read in the file to then be parsed and run.
> 


BTW, another alternative is to run 'R CMD BATCH MyCode.R' from the CLI (Linux and OS X).

If you are on Windows, I believe that would be:

  R.exe CMD BATCH MyCode.R

possibly having to specify the $PATH to R.exe.

See ?BATCH for additional information and Appendix B in An Introduction to R:

  https://cran.r-project.org/doc/manuals/r-release/R-intro.html#Invoking-R

Regards,

Marc


From jdnewmil at dcn.davis.CA.us  Thu Oct 29 16:51:18 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 29 Oct 2015 08:51:18 -0700
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
Message-ID: <0116E35B-ABB8-4B62-9579-04D336571F60@dcn.davis.CA.us>

I highly recommend ?source.

You can use source("clipboard") on windows, but creating complete files that define functions and feeding those complete files to source is a significant step in developing reproducible analyses. Whenever you find yourself pasting more than a couple of lines (one or two function calls) you should be making another function. However, even if you resist making functions you should be making a habit of sourcing complete files from disk rather than passing large chunks of code.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2015 8:16:17 AM MST, Victor Tian <tianxu03 at gmail.com> wrote:
>Hi there,
>
>Often times, I would run R in the terminal when the task is
>computationally
>intensive and a nice-looking UI is less desired.
>
>However, pasting a large chunk of code into the terminal often times
>ends
>up being messed up. In Python, the same problem would happen, however,
>iPython provides a small functionality called magic word such as %paste
>that can help paste the code neatly into the terminal.
>
>I'm wondering if there's a similar functionality in R.
>
>Thanks,


From Sebastien.Bihorel at cognigencorp.com  Thu Oct 29 17:26:16 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 29 Oct 2015 12:26:16 -0400
Subject: [R] Achieve independent fine user control of ggplot geom settings
 when using groups in multiple geom's
Message-ID: <563248A8.4080809@cognigencorp.com>

Hello,

Before I get to my question, I want to make clear that the topic of my 
present post is similar to posts I recently submitted to the list. 
Although I appreciate the replies I got, I believe that I did not 
correctly frame these previous posts to get to the bottom of things.
I also want to make clear that the code example that I have inserted in 
this post is meant to illustrate my points/questions and does not 
reflect a particular interest in the data or the sequence of ggplot 
geom's used (except otherwise mentioned). Actually, I purposefully used 
junk meaningless data, geom's sequence, and settings, so that we agree 
the plot is ugly and that we, hopefully, don't get hang on specifics and 
start discussing about the merit of one approach vs another.

So here are my questions:

1- Can a user independently control the settings of each geom's used in 
a ggplot call sequence when grouping is required?

By control, I mean: user defines the graphical settings (groups, symbol 
shapes, colors, fill colors, line types, size scales, and alpha) and 
does not let ggplot choose these settings from some theme default.
By independently, I mean: the set of graphical settings can be totally 
different from one group to the next and from one geom to the next.

If this fine control can be achieved, how would you go about it (please, 
be assured that I already spent hours miserably failing to get to 
anything remotely productive, so your help would be really appreciated)?

library(dplyr)
library(tidyr)
library(ggplot2)
set.seed(1234)
dummy <- data.frame(dummy = numeric())
data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd = 0.1),
                    g1 = rep(1:4, each = 1000))
data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd = 0.25))
data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace = TRUE),
                     y3 = runif(20, min=-8, max=4),
                     g3 = rep(1:4, each = 5)) %>% group_by(g3) %>% 
arrange(x3)

gplot <- ggplot(dummy) ### I know this line is not necessary in this 
particular example, please assume this is relevantin the actual 
framework I am trying to build
gplot <- gplot +
   geom_smooth(data = data2,
               aes(x2, y2, group = g2, color = factor(g2), linetype = 
factor(g2), size = 0.5*g2),
               method = 'loess') +
   geom_path(data = data3,
             aes(x3, y3, group = g3, color = factor(g3), linetype = 
factor(g3), shape = factor(g3), size = 0.5*g3)) +
   geom_point(data = data,
              aes(x1, y1, group = g1, color = factor(g1), fill = 
factor(g1), shape = factor(g1), size = g1))
gplot

2- Is the situation easier or more complex (ie, does ggplot make some 
decisions/assumptions for the user?) if the same x, y, and group 
variables are used in different geom's but the user still wants to 
provide independently graphical settings for each geom?

Thank you

Sebastien


From thanoon.younis80 at gmail.com  Thu Oct 29 18:07:30 2015
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Thu, 29 Oct 2015 20:07:30 +0300
Subject: [R] vector of constant values
Message-ID: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>

Dear Members,

I want to simulate a vector of constants values with dimention = 200x2 and
all values of this vector are 1.

Any help please.


Regards

-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Thu Oct 29 18:18:05 2015
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 29 Oct 2015 13:18:05 -0400
Subject: [R] vector of constant values
In-Reply-To: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>
References: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>
Message-ID: <CAM_vjukkTZqyqE5jw7gu7QHjaxhVD=O9mwb_he4FrCcPERqQjQ@mail.gmail.com>

If you mean you need a matrix of that size,

matrix(1, nrow=200, ncol=2)

On Thu, Oct 29, 2015 at 1:07 PM, thanoon younis
<thanoon.younis80 at gmail.com> wrote:
> Dear Members,
>
> I want to simulate a vector of constants values with dimention = 200x2 and
> all values of this vector are 1.
>
> Any help please.
>
>
> Regards
>


From Gerrit.Eichner at math.uni-giessen.de  Thu Oct 29 18:21:07 2015
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Thu, 29 Oct 2015 18:21:07 +0100 (MET)
Subject: [R] vector of constant values
In-Reply-To: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>
References: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>
Message-ID: <Pine.SOC.4.64.1510291819060.10472@solcom.hrz.uni-giessen.de>

Hi, Thanoon!

> I want to simulate a vector of constants values with dimention = 200x2 and
> all values of this vector are 1.

You mean "I want to _construct_ a _matrix_ of dimension 200 x 2 with all 
entries equal to 1", don't you?

Homework? Take a look at

> ?matrix

  Hth  --  Gerrit

> Any help please.
>
>
> Regards
>
> -- 
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Oct 29 18:22:07 2015
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 29 Oct 2015 10:22:07 -0700
Subject: [R] vector of constant values
In-Reply-To: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>
References: <CABLo8nFFB+2_rj2Bh6SnO6LY2E3jb50Cfjfiet1TaZhhuJh-ww@mail.gmail.com>
Message-ID: <CAGxFJbTkDRQesXAy1KywJRA_QJZ8wAK-fjZw-bSPvp_61yL-uA@mail.gmail.com>

Have you read any R tutorials?? This is about as basic as it gets.

?rep

-- Bert

P.S. Due to vectorized operations, there is probably no need to do this anyway!
Bert Gunter

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
   -- Clifford Stoll


On Thu, Oct 29, 2015 at 10:07 AM, thanoon younis
<thanoon.younis80 at gmail.com> wrote:
> Dear Members,
>
> I want to simulate a vector of constants values with dimention = 200x2 and
> all values of this vector are 1.
>
> Any help please.
>
>
> Regards
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Oct 29 18:34:36 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 29 Oct 2015 13:34:36 -0400
Subject: [R] Achieve independent fine user control of ggplot geom
 settings when using groups in multiple geom's
In-Reply-To: <563248A8.4080809@cognigencorp.com>
References: <563248A8.4080809@cognigencorp.com>
Message-ID: <CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>

I would say in a word, 'no'. What you seem to be implying is that you
want multiple color scales, multiple shape scales, etc. As far as I
know there is no support for that in ggplot2.

Perhaps if you show us what you're actually trying to accomplish
someone can suggest a solution or at least a work-around.

Best,
Ista

On Thu, Oct 29, 2015 at 12:26 PM, sbihorel
<Sebastien.Bihorel at cognigencorp.com> wrote:
> Hello,
>
> Before I get to my question, I want to make clear that the topic of my
> present post is similar to posts I recently submitted to the list. Although
> I appreciate the replies I got, I believe that I did not correctly frame
> these previous posts to get to the bottom of things.
> I also want to make clear that the code example that I have inserted in this
> post is meant to illustrate my points/questions and does not reflect a
> particular interest in the data or the sequence of ggplot geom's used
> (except otherwise mentioned). Actually, I purposefully used junk meaningless
> data, geom's sequence, and settings, so that we agree the plot is ugly and
> that we, hopefully, don't get hang on specifics and start discussing about
> the merit of one approach vs another.
>
> So here are my questions:
>
> 1- Can a user independently control the settings of each geom's used in a
> ggplot call sequence when grouping is required?
>
> By control, I mean: user defines the graphical settings (groups, symbol
> shapes, colors, fill colors, line types, size scales, and alpha) and does
> not let ggplot choose these settings from some theme default.
> By independently, I mean: the set of graphical settings can be totally
> different from one group to the next and from one geom to the next.
>
> If this fine control can be achieved, how would you go about it (please, be
> assured that I already spent hours miserably failing to get to anything
> remotely productive, so your help would be really appreciated)?
>
> library(dplyr)
> library(tidyr)
> library(ggplot2)
> set.seed(1234)
> dummy <- data.frame(dummy = numeric())
> data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd = 0.1),
>                    g1 = rep(1:4, each = 1000))
> data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd = 0.25))
> data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
> data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace = TRUE),
>                     y3 = runif(20, min=-8, max=4),
>                     g3 = rep(1:4, each = 5)) %>% group_by(g3) %>%
> arrange(x3)
>
> gplot <- ggplot(dummy) ### I know this line is not necessary in this
> particular example, please assume this is relevantin the actual framework I
> am trying to build
> gplot <- gplot +
>   geom_smooth(data = data2,
>               aes(x2, y2, group = g2, color = factor(g2), linetype =
> factor(g2), size = 0.5*g2),
>               method = 'loess') +
>   geom_path(data = data3,
>             aes(x3, y3, group = g3, color = factor(g3), linetype =
> factor(g3), shape = factor(g3), size = 0.5*g3)) +
>   geom_point(data = data,
>              aes(x1, y1, group = g1, color = factor(g1), fill = factor(g1),
> shape = factor(g1), size = g1))
> gplot
>
> 2- Is the situation easier or more complex (ie, does ggplot make some
> decisions/assumptions for the user?) if the same x, y, and group variables
> are used in different geom's but the user still wants to provide
> independently graphical settings for each geom?
>
> Thank you
>
> Sebastien
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bibtri at gmail.com  Thu Oct 29 18:21:33 2015
From: bibtri at gmail.com (Jorge Rabinovich)
Date: Thu, 29 Oct 2015 14:21:33 -0300
Subject: [R] =?utf-8?q?=232_=28Thanks=29_=E2=86=92_Consultation_about_read?=
 =?utf-8?q?ing_hdf_files_from_nsidc?=
In-Reply-To: <CAP0RBGYkzR=Dcj+SGdvX=Yi1WwRChjWM131VJq=QoriJGELPyQ@mail.gmail.com>
References: <5631780F.9000808@gmail.com>
	<CAP0RBGYkzR=Dcj+SGdvX=Yi1WwRChjWM131VJq=QoriJGELPyQ@mail.gmail.com>
Message-ID: <5632559D.4040508@gmail.com>

City Bell, Thursday, October 29, 2015, 14:10

Hi there:
On 10/29/2015 10:12 AM, HDF-EOS Tools and Information Center Help wrote:
> Hi, Jorge!   The AMSR-E file you're trying to read with R is HDF"4", 
> not HDF"5" file format. Unfortunately, R does not support HDF4 
> directly. You can either convert it to HDF5 using h4toh5tool [1] or to 
> netCDF using h4tonccf [2]. Then, you can use HDF5 or netCDF R routines 
> to access the file.
> [1] https://www.hdfgroup.org/h4toh5/
> [2] http://www.hdfeos.org/software/h4cflib.php
Thanks a million.

I downloaded the h4h5tools-2.2.2-win64.zip file and obtained the 
H4TOH5-2.2.2-win64.exe after decompressing.

I executed that file and installed the H4TOH5-2.2.2-win64 without any 
problem. I also downloaded the H4TOH5 Users Guide and Reference Manual.

However I am not able to make the conversion. I went to the "command" 
option of Windows, and I pasted the following:

C:\Program Files\HDF_Group\H4TOH5\2.2.2\bin\h4toh5convert.exe 
D:\Guanacos_3\Consultoria Santa Cruz\Datos SC\Clima\MODIS 
Snow\AMSR_E_L3_5DaySnow_V09_20050126.hdf

and I got the following message: "C:\Program" is not recognized a an 
internal or external command.

What do you think I am doing wrong?

Thanks again,

Jorge

-- 
Dr.  Jorge Rabinovich
Centro de Estudios Parasitol?gicos y de Vectores (CEPAVE)
Universidad Nacional de La Plata
Boulevard 120 s/n (e/ 61 y 62), B1902CHX La Plata
Prov. de Buenos Aires, Argentina
Tel/fax directo: 0221-472-4694
E-mail: Jorge.Rabinovich at gmail.com (preferido)
E-mail: jrabinovich at cepave.edu.ar (alternativo)
Sitio Web Personal: http://www.ecopaedia.com.ar/cv/
Sitio Web Institucional: http://www.cepave.edu.ar


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From Max.Kuhn at pfizer.com  Thu Oct 29 18:17:24 2015
From: Max.Kuhn at pfizer.com (Kuhn, Max)
Date: Thu, 29 Oct 2015 17:17:24 +0000
Subject: [R] Caret and Summary
In-Reply-To: <20151029154645.GC6809@localhost.localdomain>
References: <20151029154645.GC6809@localhost.localdomain>
Message-ID: <D257CBF7.406E3%max.kuhn@pfizer.com>



On 10/29/15, 11:46 AM, "Lorenzo Isella" <lorenzo.isella at gmail.com> wrote:

>Dear All,
>I trained a model, let's call it mm, using caret+Cubist.
>When I type summary(mm), the output is rather long.
>This is because a Cubist model is a long set of rules, partially
>reminiscent of a classification tree.
>How can I save summary(mm) in a printer/article friendly way when this is
>long?

Other that using `capture.output`, I do not think so.

>Specifically to Cubist, is there some way to plot the structure of the
>rules?

There is a `dotplot` function that works with cubist objects. Besides
this, I do not know of any.

Thanks,

Max


From tianxu03 at gmail.com  Thu Oct 29 19:13:00 2015
From: tianxu03 at gmail.com (Victor Tian)
Date: Thu, 29 Oct 2015 14:13:00 -0400
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <0116E35B-ABB8-4B62-9579-04D336571F60@dcn.davis.CA.us>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
	<0116E35B-ABB8-4B62-9579-04D336571F60@dcn.davis.CA.us>
Message-ID: <CAHJErND=KX0azjLHFYPZ75gBmObMVF=3knRpz3JLYes=9yO-sw@mail.gmail.com>

Thanks, Marc and Jeff, for the advice of running a file of R code rather
than a chunk of R code.

Just thought it would be nice to have a feature like this so that there's
still a sense of interaction in running R code.

It was a random idea and I think using "source" would achieve the same goal.

Thanks,
Xu

On Thu, Oct 29, 2015 at 11:51 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> I highly recommend ?source.
>
> You can use source("clipboard") on windows, but creating complete files
> that define functions and feeding those complete files to source is a
> significant step in developing reproducible analyses. Whenever you find
> yourself pasting more than a couple of lines (one or two function calls)
> you should be making another function. However, even if you resist making
> functions you should be making a habit of sourcing complete files from disk
> rather than passing large chunks of code.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 29, 2015 8:16:17 AM MST, Victor Tian <tianxu03 at gmail.com>
> wrote:
> >Hi there,
> >
> >Often times, I would run R in the terminal when the task is
> >computationally
> >intensive and a nice-looking UI is less desired.
> >
> >However, pasting a large chunk of code into the terminal often times
> >ends
> >up being messed up. In Python, the same problem would happen, however,
> >iPython provides a small functionality called magic word such as %paste
> >that can help paste the code neatly into the terminal.
> >
> >I'm wondering if there's a similar functionality in R.
> >
> >Thanks,
>
>


-- 
*Xu Tian*

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Thu Oct 29 19:27:55 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 29 Oct 2015 14:27:55 -0400
Subject: [R] Achieve independent fine user control of ggplot geom
 settings when using groups in multiple geom's
In-Reply-To: <CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>
References: <563248A8.4080809@cognigencorp.com>
	<CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>
Message-ID: <5632652B.80605@cognigencorp.com>

Thank you for your reply.

I do not have anything specific data/geom/grouping in mind, rather a 
framework in which users would just pile of each other layer after layer 
of geom each defined with specific settings. A minimum realistic 
scenario would a geom_point followed by a geom_smooth or a geom_path 
using different colors...

Sebastien

On 10/29/2015 1:34 PM, Ista Zahn wrote:
> I would say in a word, 'no'. What you seem to be implying is that you
> want multiple color scales, multiple shape scales, etc. As far as I
> know there is no support for that in ggplot2.
>
> Perhaps if you show us what you're actually trying to accomplish
> someone can suggest a solution or at least a work-around.
>
> Best,
> Ista
>
> On Thu, Oct 29, 2015 at 12:26 PM, sbihorel
> <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Hello,
>>
>> Before I get to my question, I want to make clear that the topic of my
>> present post is similar to posts I recently submitted to the list. Although
>> I appreciate the replies I got, I believe that I did not correctly frame
>> these previous posts to get to the bottom of things.
>> I also want to make clear that the code example that I have inserted in this
>> post is meant to illustrate my points/questions and does not reflect a
>> particular interest in the data or the sequence of ggplot geom's used
>> (except otherwise mentioned). Actually, I purposefully used junk meaningless
>> data, geom's sequence, and settings, so that we agree the plot is ugly and
>> that we, hopefully, don't get hang on specifics and start discussing about
>> the merit of one approach vs another.
>>
>> So here are my questions:
>>
>> 1- Can a user independently control the settings of each geom's used in a
>> ggplot call sequence when grouping is required?
>>
>> By control, I mean: user defines the graphical settings (groups, symbol
>> shapes, colors, fill colors, line types, size scales, and alpha) and does
>> not let ggplot choose these settings from some theme default.
>> By independently, I mean: the set of graphical settings can be totally
>> different from one group to the next and from one geom to the next.
>>
>> If this fine control can be achieved, how would you go about it (please, be
>> assured that I already spent hours miserably failing to get to anything
>> remotely productive, so your help would be really appreciated)?
>>
>> library(dplyr)
>> library(tidyr)
>> library(ggplot2)
>> set.seed(1234)
>> dummy <- data.frame(dummy = numeric())
>> data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd = 0.1),
>>                     g1 = rep(1:4, each = 1000))
>> data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd = 0.25))
>> data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
>> data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace = TRUE),
>>                      y3 = runif(20, min=-8, max=4),
>>                      g3 = rep(1:4, each = 5)) %>% group_by(g3) %>%
>> arrange(x3)
>>
>> gplot <- ggplot(dummy) ### I know this line is not necessary in this
>> particular example, please assume this is relevantin the actual framework I
>> am trying to build
>> gplot <- gplot +
>>    geom_smooth(data = data2,
>>                aes(x2, y2, group = g2, color = factor(g2), linetype =
>> factor(g2), size = 0.5*g2),
>>                method = 'loess') +
>>    geom_path(data = data3,
>>              aes(x3, y3, group = g3, color = factor(g3), linetype =
>> factor(g3), shape = factor(g3), size = 0.5*g3)) +
>>    geom_point(data = data,
>>               aes(x1, y1, group = g1, color = factor(g1), fill = factor(g1),
>> shape = factor(g1), size = g1))
>> gplot
>>
>> 2- Is the situation easier or more complex (ie, does ggplot make some
>> decisions/assumptions for the user?) if the same x, y, and group variables
>> are used in different geom's but the user still wants to provide
>> independently graphical settings for each geom?
>>
>> Thank you
>>
>> Sebastien
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Thu Oct 29 19:46:19 2015
From: jholtman at gmail.com (jim holtman)
Date: Thu, 29 Oct 2015 14:46:19 -0400
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <CAHJErND=KX0azjLHFYPZ75gBmObMVF=3knRpz3JLYes=9yO-sw@mail.gmail.com>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
	<0116E35B-ABB8-4B62-9579-04D336571F60@dcn.davis.CA.us>
	<CAHJErND=KX0azjLHFYPZ75gBmObMVF=3knRpz3JLYes=9yO-sw@mail.gmail.com>
Message-ID: <CAAxdm-6r_atLwnp-ozowsbQz_vu8JcwSyQurDG-rJOysCZKX0A@mail.gmail.com>

Another good reason for using "source" instead of copy/paste is that if an
error occurs, the 'sourced' script will stop at the error, while the
copy/paste will keep on chugging away, knowing who does what in the rest of
the script.  Most of the editors I have used on Windows (notepad++, tinn-r)
support highlighting code and then automatically creating a temporary file
that is 'sourced' in.


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Thu, Oct 29, 2015 at 2:13 PM, Victor Tian <tianxu03 at gmail.com> wrote:

> Thanks, Marc and Jeff, for the advice of running a file of R code rather
> than a chunk of R code.
>
> Just thought it would be nice to have a feature like this so that there's
> still a sense of interaction in running R code.
>
> It was a random idea and I think using "source" would achieve the same
> goal.
>
> Thanks,
> Xu
>
> On Thu, Oct 29, 2015 at 11:51 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
> >
> wrote:
>
> > I highly recommend ?source.
> >
> > You can use source("clipboard") on windows, but creating complete files
> > that define functions and feeding those complete files to source is a
> > significant step in developing reproducible analyses. Whenever you find
> > yourself pasting more than a couple of lines (one or two function calls)
> > you should be making another function. However, even if you resist making
> > functions you should be making a habit of sourcing complete files from
> disk
> > rather than passing large chunks of code.
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On October 29, 2015 8:16:17 AM MST, Victor Tian <tianxu03 at gmail.com>
> > wrote:
> > >Hi there,
> > >
> > >Often times, I would run R in the terminal when the task is
> > >computationally
> > >intensive and a nice-looking UI is less desired.
> > >
> > >However, pasting a large chunk of code into the terminal often times
> > >ends
> > >up being messed up. In Python, the same problem would happen, however,
> > >iPython provides a small functionality called magic word such as %paste
> > >that can help paste the code neatly into the terminal.
> > >
> > >I'm wondering if there's a similar functionality in R.
> > >
> > >Thanks,
> >
> >
>
>
> --
> *Xu Tian*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Oct 29 19:50:41 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 29 Oct 2015 11:50:41 -0700
Subject: [R]
 =?utf-8?q?=232_=28Thanks=29_=E2=86=92_Consultation_about_read?=
 =?utf-8?q?ing_hdf_files_from_nsidc?=
In-Reply-To: <5632559D.4040508@gmail.com>
References: <5631780F.9000808@gmail.com>
	<CAP0RBGYkzR=Dcj+SGdvX=Yi1WwRChjWM131VJq=QoriJGELPyQ@mail.gmail.com>
	<5632559D.4040508@gmail.com>
Message-ID: <13BB0650-3184-4DDA-8982-ECA115802C5C@comcast.net>


> On Oct 29, 2015, at 10:21 AM, Jorge Rabinovich <bibtri at gmail.com> wrote:
> 
> City Bell, Thursday, October 29, 2015, 14:10
> 
> Hi there:
> On 10/29/2015 10:12 AM, HDF-EOS Tools and Information Center Help wrote:
>> Hi, Jorge!   The AMSR-E file you're trying to read with R is HDF"4", not HDF"5" file format. Unfortunately, R does not support HDF4 directly. You can either convert it to HDF5 using h4toh5tool [1] or to netCDF using h4tonccf [2]. Then, you can use HDF5 or netCDF R routines to access the file.
>> [1] https://www.hdfgroup.org/h4toh5/
>> [2] http://www.hdfeos.org/software/h4cflib.php
> Thanks a million.
> 
> I downloaded the h4h5tools-2.2.2-win64.zip file and obtained the H4TOH5-2.2.2-win64.exe after decompressing.
> 
> I executed that file and installed the H4TOH5-2.2.2-win64 without any problem. I also downloaded the H4TOH5 Users Guide and Reference Manual.
> 
> However I am not able to make the conversion. I went to the "command" option of Windows, and I pasted the following:
> 
> C:\Program Files\HDF_Group\H4TOH5\2.2.2\bin\h4toh5convert.exe D:\Guanacos_3\Consultoria Santa Cruz\Datos SC\Clima\MODIS Snow\AMSR_E_L3_5DaySnow_V09_20050126.hdf
> 
> and I got the following message: "C:\Program" is not recognized a an internal or external command.

It appears that you do not know how to tell Windows how to deal with a space in your command. That not really an on topic question for R-help. You need to learn how to use the operating system you have chosen. It might be a simple as not using full path to your program if it is registered, or you might need to navigate to the ?Program Files? directory, or <something else>.


> 
> What do you think I am doing wrong?
> 
> Thanks again,
> 
> Jorge
> 
> -- 
> Dr.  Jorge Rabinovich
> Centro de Estudios Parasitol?gicos y de Vectores (CEPAVE)
> Universidad Nacional de La Plata
> Boulevard 120 s/n (e/ 61 y 62), B1902CHX La Plata
> Prov. de Buenos Aires, Argentina
> Tel/fax directo: 0221-472-4694
> E-mail: Jorge.Rabinovich at gmail.com (preferido)
> E-mail: jrabinovich at cepave.edu.ar (alternativo)
> Sitio Web Personal: http://www.ecopaedia.com.ar/cv/
> Sitio Web Institucional: http://www.cepave.edu.ar
> 
> 
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From NordlDJ at dshs.wa.gov  Thu Oct 29 20:13:58 2015
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Thu, 29 Oct 2015 19:13:58 +0000
Subject: [R]
 =?utf-8?q?=232_=28Thanks=29_=E2=86=92_Consultation_about_read?=
 =?utf-8?q?ing_hdf_files_from_nsidc?=
In-Reply-To: <13BB0650-3184-4DDA-8982-ECA115802C5C@comcast.net>
References: <5631780F.9000808@gmail.com>
	<CAP0RBGYkzR=Dcj+SGdvX=Yi1WwRChjWM131VJq=QoriJGELPyQ@mail.gmail.com>
	<5632559D.4040508@gmail.com>
	<13BB0650-3184-4DDA-8982-ECA115802C5C@comcast.net>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27662EDADC87@WAXMXOLYMB025.WAX.wa.lcl>

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of David Winsemius
Sent: Thursday, October 29, 2015 11:51 AM
To: jorge.rabinovich at gmail.com
Cc: r-help at r-project.org; HDF-EOS Tools and Information Center Help
Subject: Re: [R] #2 (Thanks) ? Consultation about reading hdf files from nsidc


> On Oct 29, 2015, at 10:21 AM, Jorge Rabinovich <bibtri at gmail.com> wrote:
> 
> City Bell, Thursday, October 29, 2015, 14:10
> 
> Hi there:
> On 10/29/2015 10:12 AM, HDF-EOS Tools and Information Center Help wrote:
>> Hi, Jorge!   The AMSR-E file you're trying to read with R is HDF"4", not HDF"5" file format. Unfortunately, R does not support HDF4 directly. You can either convert it to HDF5 using h4toh5tool [1] or to netCDF using h4tonccf [2]. Then, you can use HDF5 or netCDF R routines to access the file.
>> [1] https://www.hdfgroup.org/h4toh5/
>> [2] http://www.hdfeos.org/software/h4cflib.php
> Thanks a million.
> 
> I downloaded the h4h5tools-2.2.2-win64.zip file and obtained the H4TOH5-2.2.2-win64.exe after decompressing.
> 
> I executed that file and installed the H4TOH5-2.2.2-win64 without any problem. I also downloaded the H4TOH5 Users Guide and Reference Manual.
> 
> However I am not able to make the conversion. I went to the "command" option of Windows, and I pasted the following:
> 
> C:\Program Files\HDF_Group\H4TOH5\2.2.2\bin\h4toh5convert.exe 
> D:\Guanacos_3\Consultoria Santa Cruz\Datos SC\Clima\MODIS 
> Snow\AMSR_E_L3_5DaySnow_V09_20050126.hdf
> 
> and I got the following message: "C:\Program" is not recognized a an internal or external command.

It appears that you do not know how to tell Windows how to deal with a space in your command. That not really an on topic question for R-help. You need to learn how to use the operating system you have chosen. It might be a simple as not using full path to your program if it is registered, or you might need to navigate to the ?Program Files? directory, or <something else>.


> 
> What do you think I am doing wrong?
> 
> Thanks again,
> 
> Jorge


You need to wrap paths that contain spaces with double quotes.  Given the way the lines are broken in the email I can only guess you might want something like this

"C:\Program Files\HDF_Group\H4TOH5\2.2.2\bin\h4toh5convert.exe "   "D:\Guanacos_3\Consultoria Santa Cruz\Datos SC\Clima\MODIS Snow\AMSR_E_L3_5DaySnow_V09_20050126.hdf"


Dan

Daniel Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From tianxu03 at gmail.com  Thu Oct 29 20:26:56 2015
From: tianxu03 at gmail.com (Victor Tian)
Date: Thu, 29 Oct 2015 15:26:56 -0400
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <CAAxdm-6r_atLwnp-ozowsbQz_vu8JcwSyQurDG-rJOysCZKX0A@mail.gmail.com>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
	<0116E35B-ABB8-4B62-9579-04D336571F60@dcn.davis.CA.us>
	<CAHJErND=KX0azjLHFYPZ75gBmObMVF=3knRpz3JLYes=9yO-sw@mail.gmail.com>
	<CAAxdm-6r_atLwnp-ozowsbQz_vu8JcwSyQurDG-rJOysCZKX0A@mail.gmail.com>
Message-ID: <CAHJErNAH2dg4XvcykV+vkxS_S+urzv=MEdKnMKMaytkPkUy6vA@mail.gmail.com>

Not a specific problem. Just an issue encountered pasting R codes in
terminals from time to time.

Cheers,

Xu

On Thu, Oct 29, 2015 at 2:46 PM, jim holtman <jholtman at gmail.com> wrote:

> Another good reason for using "source" instead of copy/paste is that if an
> error occurs, the 'sourced' script will stop at the error, while the
> copy/paste will keep on chugging away, knowing who does what in the rest of
> the script.  Most of the editors I have used on Windows (notepad++, tinn-r)
> support highlighting code and then automatically creating a temporary file
> that is 'sourced' in.
>
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
> On Thu, Oct 29, 2015 at 2:13 PM, Victor Tian <tianxu03 at gmail.com> wrote:
>
>> Thanks, Marc and Jeff, for the advice of running a file of R code rather
>> than a chunk of R code.
>>
>> Just thought it would be nice to have a feature like this so that there's
>> still a sense of interaction in running R code.
>>
>> It was a random idea and I think using "source" would achieve the same
>> goal.
>>
>> Thanks,
>> Xu
>>
>> On Thu, Oct 29, 2015 at 11:51 AM, Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us>
>> wrote:
>>
>> > I highly recommend ?source.
>> >
>> > You can use source("clipboard") on windows, but creating complete files
>> > that define functions and feeding those complete files to source is a
>> > significant step in developing reproducible analyses. Whenever you find
>> > yourself pasting more than a couple of lines (one or two function calls)
>> > you should be making another function. However, even if you resist
>> making
>> > functions you should be making a habit of sourcing complete files from
>> disk
>> > rather than passing large chunks of code.
>> >
>> ---------------------------------------------------------------------------
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> > Go...
>> >                                       Live:   OO#.. Dead: OO#..  Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> >
>> ---------------------------------------------------------------------------
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On October 29, 2015 8:16:17 AM MST, Victor Tian <tianxu03 at gmail.com>
>> > wrote:
>> > >Hi there,
>> > >
>> > >Often times, I would run R in the terminal when the task is
>> > >computationally
>> > >intensive and a nice-looking UI is less desired.
>> > >
>> > >However, pasting a large chunk of code into the terminal often times
>> > >ends
>> > >up being messed up. In Python, the same problem would happen, however,
>> > >iPython provides a small functionality called magic word such as %paste
>> > >that can help paste the code neatly into the terminal.
>> > >
>> > >I'm wondering if there's a similar functionality in R.
>> > >
>> > >Thanks,
>> >
>> >
>>
>>
>> --
>> *Xu Tian*
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


-- 
*Xu Tian*

	[[alternative HTML version deleted]]


From deeepersound at googlemail.com  Thu Oct 29 20:34:56 2015
From: deeepersound at googlemail.com (Maxim)
Date: Thu, 29 Oct 2015 20:34:56 +0100
Subject: [R] mapping between list and vector
Message-ID: <CAGsHYraTFhLfpYUosyXZhvcysMjOPBK6aGRDaUa3hTKya6JqEw@mail.gmail.com>

Hi,

for some reason I have to map elements of a list "myList" (of vectors of
different length) to a vector "myVec" as such:

myList <- list(a="key1", b=c("key2","key3"), c="key4")
myVec <- c("val1","val2","val3","val4")


result <- list()
lapply(myList,length) -> lngL

j <- 1
for (i in 1:(length(lngL))) {
result[[i]] <- paste(myVec[j:(j-1+lngL[[i]])],collapse="//")
j <- j+lngL[[i]]
}

that the result looks like this:

> result

[[1]]
[1] "val1"

[[2]]
[1] "val2//val3"

[[3]]
[1] "val3"

Above code is the fastest version I was able to come up with (the list
contains about 1 million elements). I guess the for loop can be substituted
by a lapply command making it less complicated and probably faster, but I
can't figure out how to do this in a more elegant and especially faster
fashion.

Best
Maxim

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Oct 29 20:58:12 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 29 Oct 2015 12:58:12 -0700
Subject: [R] Pasting a large chunk of R code in terminals
In-Reply-To: <CAHJErNAH2dg4XvcykV+vkxS_S+urzv=MEdKnMKMaytkPkUy6vA@mail.gmail.com>
References: <CAHJErNCaLsb-PAxzHX6qeBCvj8bLQJuyvEbFp8io1iJfiMfF0A@mail.gmail.com>
	<0116E35B-ABB8-4B62-9579-04D336571F60@dcn.davis.CA.us>
	<CAHJErND=KX0azjLHFYPZ75gBmObMVF=3knRpz3JLYes=9yO-sw@mail.gmail.com>
	<CAAxdm-6r_atLwnp-ozowsbQz_vu8JcwSyQurDG-rJOysCZKX0A@mail.gmail.com>
	<CAHJErNAH2dg4XvcykV+vkxS_S+urzv=MEdKnMKMaytkPkUy6vA@mail.gmail.com>
Message-ID: <F4AFE75E-5197-42FA-B01A-93007E6EF439@dcn.davis.CA.us>

I don't get the impression that you understood the part of my response where I said the feature does exist.

You might find reading ?file helpful, in particular the section titled "Clipboard".
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2015 12:26:56 PM MST, Victor Tian <tianxu03 at gmail.com> wrote:
>Not a specific problem. Just an issue encountered pasting R codes in
>terminals from time to time.
>
>Cheers,
>
>Xu
>
>On Thu, Oct 29, 2015 at 2:46 PM, jim holtman <jholtman at gmail.com>
>wrote:
>
>> Another good reason for using "source" instead of copy/paste is that
>if an
>> error occurs, the 'sourced' script will stop at the error, while the
>> copy/paste will keep on chugging away, knowing who does what in the
>rest of
>> the script.  Most of the editors I have used on Windows (notepad++,
>tinn-r)
>> support highlighting code and then automatically creating a temporary
>file
>> that is 'sourced' in.
>>
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>> On Thu, Oct 29, 2015 at 2:13 PM, Victor Tian <tianxu03 at gmail.com>
>wrote:
>>
>>> Thanks, Marc and Jeff, for the advice of running a file of R code
>rather
>>> than a chunk of R code.
>>>
>>> Just thought it would be nice to have a feature like this so that
>there's
>>> still a sense of interaction in running R code.
>>>
>>> It was a random idea and I think using "source" would achieve the
>same
>>> goal.
>>>
>>> Thanks,
>>> Xu
>>>
>>> On Thu, Oct 29, 2015 at 11:51 AM, Jeff Newmiller <
>>> jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>> > I highly recommend ?source.
>>> >
>>> > You can use source("clipboard") on windows, but creating complete
>files
>>> > that define functions and feeding those complete files to source
>is a
>>> > significant step in developing reproducible analyses. Whenever you
>find
>>> > yourself pasting more than a couple of lines (one or two function
>calls)
>>> > you should be making another function. However, even if you resist
>>> making
>>> > functions you should be making a habit of sourcing complete files
>from
>>> disk
>>> > rather than passing large chunks of code.
>>> >
>>>
>---------------------------------------------------------------------------
>>> > Jeff Newmiller                        The     .....       ..... 
>Go
>>> Live...
>>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live
>>> > Go...
>>> >                                       Live:   OO#.. Dead: OO#.. 
>Playing
>>> > Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>> >
>>>
>---------------------------------------------------------------------------
>>> > Sent from my phone. Please excuse my brevity.
>>> >
>>> > On October 29, 2015 8:16:17 AM MST, Victor Tian
><tianxu03 at gmail.com>
>>> > wrote:
>>> > >Hi there,
>>> > >
>>> > >Often times, I would run R in the terminal when the task is
>>> > >computationally
>>> > >intensive and a nice-looking UI is less desired.
>>> > >
>>> > >However, pasting a large chunk of code into the terminal often
>times
>>> > >ends
>>> > >up being messed up. In Python, the same problem would happen,
>however,
>>> > >iPython provides a small functionality called magic word such as
>%paste
>>> > >that can help paste the code neatly into the terminal.
>>> > >
>>> > >I'm wondering if there's a similar functionality in R.
>>> > >
>>> > >Thanks,
>>> >
>>> >
>>>
>>>
>>> --
>>> *Xu Tian*
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>


From jvadams at usgs.gov  Thu Oct 29 21:42:29 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 29 Oct 2015 15:42:29 -0500
Subject: [R] mapping between list and vector
In-Reply-To: <CAGsHYraTFhLfpYUosyXZhvcysMjOPBK6aGRDaUa3hTKya6JqEw@mail.gmail.com>
References: <CAGsHYraTFhLfpYUosyXZhvcysMjOPBK6aGRDaUa3hTKya6JqEw@mail.gmail.com>
Message-ID: <CAN5YmCGgbe68+7JkywtQwxy4rfSzmk=dixa5T13VDijLo9CY5g@mail.gmail.com>

Maxim,

I'm not sure how much faster this would be ... but you could test it out
and see.  I defined lngL and result as vectors instead of lists.  And I
calculated j outside of the "loop".

myList <- list(a="key1", b=c("key2","key3"), c="key4")
myVec <- c("val1","val2","val3","val4")

lngL <- sapply(myList, length)
L <- length(lngL)
j <- cumsum(c(1, lngL))[1:L]
result <- sapply(1:L, function(i) paste(myVec[j[i]:(j[i] - 1 + lngL[i])],
collapse="//"))

Jean

On Thu, Oct 29, 2015 at 2:34 PM, Maxim via R-help <r-help at r-project.org>
wrote:

> Hi,
>
> for some reason I have to map elements of a list "myList" (of vectors of
> different length) to a vector "myVec" as such:
>
> myList <- list(a="key1", b=c("key2","key3"), c="key4")
> myVec <- c("val1","val2","val3","val4")
>
>
> result <- list()
> lapply(myList,length) -> lngL
>
> j <- 1
> for (i in 1:(length(lngL))) {
> result[[i]] <- paste(myVec[j:(j-1+lngL[[i]])],collapse="//")
> j <- j+lngL[[i]]
> }
>
> that the result looks like this:
>
> > result
>
> [[1]]
> [1] "val1"
>
> [[2]]
> [1] "val2//val3"
>
> [[3]]
> [1] "val3"
>
> Above code is the fastest version I was able to come up with (the list
> contains about 1 million elements). I guess the for loop can be substituted
> by a lapply command making it less complicated and probably faster, but I
> can't figure out how to do this in a more elegant and especially faster
> fashion.
>
> Best
> Maxim
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Oct 29 21:49:46 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 29 Oct 2015 13:49:46 -0700
Subject: [R] Achieve independent fine user control of ggplot geom
	settings when using groups in multiple geom's
In-Reply-To: <5632652B.80605@cognigencorp.com>
References: <563248A8.4080809@cognigencorp.com>
	<CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>
	<5632652B.80605@cognigencorp.com>
Message-ID: <089CB06E-32E6-4997-9625-25B5C200083E@dcn.davis.CA.us>

I think a fundamental design principle of ggplot is that mapping of values to visual representation are consistent within a single plot, so reassigning color mapping for different elements would not be supported.

That being said, it is possible to explicitly control specific attributes within a single geom outside of the mapping, though this usually does break mappings in the legend.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2015 11:27:55 AM MST, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>Thank you for your reply.
>
>I do not have anything specific data/geom/grouping in mind, rather a 
>framework in which users would just pile of each other layer after
>layer 
>of geom each defined with specific settings. A minimum realistic 
>scenario would a geom_point followed by a geom_smooth or a geom_path 
>using different colors...
>
>Sebastien
>
>On 10/29/2015 1:34 PM, Ista Zahn wrote:
>> I would say in a word, 'no'. What you seem to be implying is that you
>> want multiple color scales, multiple shape scales, etc. As far as I
>> know there is no support for that in ggplot2.
>>
>> Perhaps if you show us what you're actually trying to accomplish
>> someone can suggest a solution or at least a work-around.
>>
>> Best,
>> Ista
>>
>> On Thu, Oct 29, 2015 at 12:26 PM, sbihorel
>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>> Hello,
>>>
>>> Before I get to my question, I want to make clear that the topic of
>my
>>> present post is similar to posts I recently submitted to the list.
>Although
>>> I appreciate the replies I got, I believe that I did not correctly
>frame
>>> these previous posts to get to the bottom of things.
>>> I also want to make clear that the code example that I have inserted
>in this
>>> post is meant to illustrate my points/questions and does not reflect
>a
>>> particular interest in the data or the sequence of ggplot geom's
>used
>>> (except otherwise mentioned). Actually, I purposefully used junk
>meaningless
>>> data, geom's sequence, and settings, so that we agree the plot is
>ugly and
>>> that we, hopefully, don't get hang on specifics and start discussing
>about
>>> the merit of one approach vs another.
>>>
>>> So here are my questions:
>>>
>>> 1- Can a user independently control the settings of each geom's used
>in a
>>> ggplot call sequence when grouping is required?
>>>
>>> By control, I mean: user defines the graphical settings (groups,
>symbol
>>> shapes, colors, fill colors, line types, size scales, and alpha) and
>does
>>> not let ggplot choose these settings from some theme default.
>>> By independently, I mean: the set of graphical settings can be
>totally
>>> different from one group to the next and from one geom to the next.
>>>
>>> If this fine control can be achieved, how would you go about it
>(please, be
>>> assured that I already spent hours miserably failing to get to
>anything
>>> remotely productive, so your help would be really appreciated)?
>>>
>>> library(dplyr)
>>> library(tidyr)
>>> library(ggplot2)
>>> set.seed(1234)
>>> dummy <- data.frame(dummy = numeric())
>>> data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd =
>0.1),
>>>                     g1 = rep(1:4, each = 1000))
>>> data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd
>= 0.25))
>>> data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
>>> data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace =
>TRUE),
>>>                      y3 = runif(20, min=-8, max=4),
>>>                      g3 = rep(1:4, each = 5)) %>% group_by(g3) %>%
>>> arrange(x3)
>>>
>>> gplot <- ggplot(dummy) ### I know this line is not necessary in this
>>> particular example, please assume this is relevantin the actual
>framework I
>>> am trying to build
>>> gplot <- gplot +
>>>    geom_smooth(data = data2,
>>>                aes(x2, y2, group = g2, color = factor(g2), linetype
>=
>>> factor(g2), size = 0.5*g2),
>>>                method = 'loess') +
>>>    geom_path(data = data3,
>>>              aes(x3, y3, group = g3, color = factor(g3), linetype =
>>> factor(g3), shape = factor(g3), size = 0.5*g3)) +
>>>    geom_point(data = data,
>>>               aes(x1, y1, group = g1, color = factor(g1), fill =
>factor(g1),
>>> shape = factor(g1), size = g1))
>>> gplot
>>>
>>> 2- Is the situation easier or more complex (ie, does ggplot make
>some
>>> decisions/assumptions for the user?) if the same x, y, and group
>variables
>>> are used in different geom's but the user still wants to provide
>>> independently graphical settings for each geom?
>>>
>>> Thank you
>>>
>>> Sebastien
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From fanjianling at gmail.com  Thu Oct 29 22:19:58 2015
From: fanjianling at gmail.com (Jianling Fan)
Date: Thu, 29 Oct 2015 15:19:58 -0600
Subject: [R] find max. value for a equation by optimize
Message-ID: <CAJ7mryJMQD8EHzGAmBNupz-Se3CC1EabKcp=aSNmtsGdrGPvmw@mail.gmail.com>

Hello, everyone,

I have a specific equation, When I draw it out, I found there is a
max. value for it at about x=5. but I couldn't point it out by
optimize(). Does anyone know why? Thanks!

my code is:

d50<-18.04
c<-  -1.276
dm<-147

sm <- function (x) {
  1/(1+(x/d50)^c)+(1-1/(1+(dm/d50)^c))*x/dm-(1/(1+((x-1)/d50)^c)+(1-1/(1+(dm/d50)^c))*(x-1)/dm)
}
curve(sm, 0,50)
optimize(sm,c(0,50))

The optimize() only give min. value but not max.


From jvadams at usgs.gov  Thu Oct 29 22:45:48 2015
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 29 Oct 2015 16:45:48 -0500
Subject: [R] find max. value for a equation by optimize
In-Reply-To: <CAJ7mryJMQD8EHzGAmBNupz-Se3CC1EabKcp=aSNmtsGdrGPvmw@mail.gmail.com>
References: <CAJ7mryJMQD8EHzGAmBNupz-Se3CC1EabKcp=aSNmtsGdrGPvmw@mail.gmail.com>
Message-ID: <CAN5YmCF=WY4XO3N8T35WZk5C97MPtj=OumDT4dYpXSD88MTBAg@mail.gmail.com>

If you read the help file for optimize, you will see that you need to set
the argument maximum to TRUE.

?optimize

optimize(sm, c(0, 50), maximum=TRUE)

Jean

On Thu, Oct 29, 2015 at 4:19 PM, Jianling Fan <fanjianling at gmail.com> wrote:

> Hello, everyone,
>
> I have a specific equation, When I draw it out, I found there is a
> max. value for it at about x=5. but I couldn't point it out by
> optimize(). Does anyone know why? Thanks!
>
> my code is:
>
> d50<-18.04
> c<-  -1.276
> dm<-147
>
> sm <- function (x) {
>
> 1/(1+(x/d50)^c)+(1-1/(1+(dm/d50)^c))*x/dm-(1/(1+((x-1)/d50)^c)+(1-1/(1+(dm/d50)^c))*(x-1)/dm)
> }
> curve(sm, 0,50)
> optimize(sm,c(0,50))
>
> The optimize() only give min. value but not max.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From fanjianling at gmail.com  Thu Oct 29 23:20:25 2015
From: fanjianling at gmail.com (Jianling Fan)
Date: Thu, 29 Oct 2015 16:20:25 -0600
Subject: [R] find max. value for a equation by optimize
In-Reply-To: <CAN5YmCF=WY4XO3N8T35WZk5C97MPtj=OumDT4dYpXSD88MTBAg@mail.gmail.com>
References: <CAJ7mryJMQD8EHzGAmBNupz-Se3CC1EabKcp=aSNmtsGdrGPvmw@mail.gmail.com>
	<CAN5YmCF=WY4XO3N8T35WZk5C97MPtj=OumDT4dYpXSD88MTBAg@mail.gmail.com>
Message-ID: <CAJ7mryKj_X_Rb7ZNC6QBC5gBj_X59vV-jU1_B37m-1zCAwE26Q@mail.gmail.com>

 Oops!

Thanks a lot! Jean

On 29 October 2015 at 15:45, Adams, Jean <jvadams at usgs.gov> wrote:
> If you read the help file for optimize, you will see that you need to set
> the argument maximum to TRUE.
>
> ?optimize
>
> optimize(sm, c(0, 50), maximum=TRUE)
>
> Jean
>
> On Thu, Oct 29, 2015 at 4:19 PM, Jianling Fan <fanjianling at gmail.com> wrote:
>>
>> Hello, everyone,
>>
>> I have a specific equation, When I draw it out, I found there is a
>> max. value for it at about x=5. but I couldn't point it out by
>> optimize(). Does anyone know why? Thanks!
>>
>> my code is:
>>
>> d50<-18.04
>> c<-  -1.276
>> dm<-147
>>
>> sm <- function (x) {
>>
>> 1/(1+(x/d50)^c)+(1-1/(1+(dm/d50)^c))*x/dm-(1/(1+((x-1)/d50)^c)+(1-1/(1+(dm/d50)^c))*(x-1)/dm)
>> }
>> curve(sm, 0,50)
>> optimize(sm,c(0,50))
>>
>> The optimize() only give min. value but not max.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Jianling Fan
???


From marcoigarapava at gmail.com  Thu Oct 29 23:38:38 2015
From: marcoigarapava at gmail.com (Marco Inacio)
Date: Thu, 29 Oct 2015 20:38:38 -0200
Subject: [R] find all unit vectors which are orthogonal to a given vector
Message-ID: <56329FEE.2030001@gmail.com>

Is there a function in R to get the set of all unit vectors which are 
orthogonal to a given vector?


From murdoch.duncan at gmail.com  Fri Oct 30 00:03:08 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Oct 2015 19:03:08 -0400
Subject: [R] find all unit vectors which are orthogonal to a given vector
In-Reply-To: <56329FEE.2030001@gmail.com>
References: <56329FEE.2030001@gmail.com>
Message-ID: <5632A5AC.7030503@gmail.com>

On 29/10/2015 6:38 PM, Marco Inacio wrote:
> Is there a function in R to get the set of all unit vectors which are 
> orthogonal to a given vector?

No.

Duncan Murdoch


From marcoigarapava at gmail.com  Fri Oct 30 00:11:06 2015
From: marcoigarapava at gmail.com (Marco Inacio)
Date: Thu, 29 Oct 2015 21:11:06 -0200
Subject: [R] find all unit vectors which are orthogonal to a given vector
In-Reply-To: <5632A5AC.7030503@gmail.com>
References: <56329FEE.2030001@gmail.com> <5632A5AC.7030503@gmail.com>
Message-ID: <5632A78A.9030701@gmail.com>

Ok, thanks!

On 2015-10-29 09:03 PM, Duncan Murdoch wrote:
> On 29/10/2015 6:38 PM, Marco Inacio wrote:
>> Is there a function in R to get the set of all unit vectors which are
>> orthogonal to a given vector?
> No.
>
> Duncan Murdoch
>


From axel.urbiz at gmail.com  Fri Oct 30 00:48:12 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 29 Oct 2015 19:48:12 -0400
Subject: [R] User-defined functions in dplyr
Message-ID: <CAAyVsXKoZwPHL1X1jZq216cSCqa=hrMDbxKWEGLOU9KF5dRbvw@mail.gmail.com>

Hello,

I?m using the plyr package to add a variable named "bin" to my original
data frame "df" with a user-defined function "create_bins". I'd like to get
similar results using dplyr instead, but failing to do so. set.seed(4)df <-
data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels = c("model1",
"model2")))
### Using plyr (works fine)create_bins <- function(x, nBins){  Breaks <-
unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))  dfB <-
 data.frame(pred = x$pred,                     bin = cut(x$pred, breaks =
Breaks, include.lowest = TRUE))  dfB} nBins = 10res_plyr <- plyr::ddply(df,
plyr::.(models), create_bins, nBins)head(res_plyr) ### Using dplyr
(fails) by_group <- dplyr::group_by(df, models)res_dplyr <-
dplyr::summarize(by_group, create_bins, nBins)Error: not a vector  Any help
would be much appreciated. Best,Axel.

	[[alternative HTML version deleted]]


From Sebastien.Bihorel at cognigencorp.com  Fri Oct 30 00:31:53 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Thu, 29 Oct 2015 19:31:53 -0400
Subject: [R] Achieve independent fine user control of ggplot geom
 settings when using groups in multiple geom's
In-Reply-To: <089CB06E-32E6-4997-9625-25B5C200083E@dcn.davis.CA.us>
References: <563248A8.4080809@cognigencorp.com>
	<CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>
	<5632652B.80605@cognigencorp.com>
	<089CB06E-32E6-4997-9625-25B5C200083E@dcn.davis.CA.us>
Message-ID: <5632AC69.8000001@cognigencorp.com>

Thank for your reply,

I may accept your point about the mapping consistency when the different 
geom's use the same data source. However, as pointed out in my example 
code, this does not have to be the case. Hence my question about the 
geom-specific control of group-dependent graphical settings.

Sebastien

On 10/29/2015 4:49 PM, Jeff Newmiller wrote:
> I think a fundamental design principle of ggplot is that mapping of values to visual representation are consistent within a single plot, so reassigning color mapping for different elements would not be supported.
>
> That being said, it is possible to explicitly control specific attributes within a single geom outside of the mapping, though this usually does break mappings in the legend.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 29, 2015 11:27:55 AM MST, sbihorel <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Thank you for your reply.
>>
>> I do not have anything specific data/geom/grouping in mind, rather a
>> framework in which users would just pile of each other layer after
>> layer
>> of geom each defined with specific settings. A minimum realistic
>> scenario would a geom_point followed by a geom_smooth or a geom_path
>> using different colors...
>>
>> Sebastien
>>
>> On 10/29/2015 1:34 PM, Ista Zahn wrote:
>>> I would say in a word, 'no'. What you seem to be implying is that you
>>> want multiple color scales, multiple shape scales, etc. As far as I
>>> know there is no support for that in ggplot2.
>>>
>>> Perhaps if you show us what you're actually trying to accomplish
>>> someone can suggest a solution or at least a work-around.
>>>
>>> Best,
>>> Ista
>>>
>>> On Thu, Oct 29, 2015 at 12:26 PM, sbihorel
>>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>>> Hello,
>>>>
>>>> Before I get to my question, I want to make clear that the topic of
>> my
>>>> present post is similar to posts I recently submitted to the list.
>> Although
>>>> I appreciate the replies I got, I believe that I did not correctly
>> frame
>>>> these previous posts to get to the bottom of things.
>>>> I also want to make clear that the code example that I have inserted
>> in this
>>>> post is meant to illustrate my points/questions and does not reflect
>> a
>>>> particular interest in the data or the sequence of ggplot geom's
>> used
>>>> (except otherwise mentioned). Actually, I purposefully used junk
>> meaningless
>>>> data, geom's sequence, and settings, so that we agree the plot is
>> ugly and
>>>> that we, hopefully, don't get hang on specifics and start discussing
>> about
>>>> the merit of one approach vs another.
>>>>
>>>> So here are my questions:
>>>>
>>>> 1- Can a user independently control the settings of each geom's used
>> in a
>>>> ggplot call sequence when grouping is required?
>>>>
>>>> By control, I mean: user defines the graphical settings (groups,
>> symbol
>>>> shapes, colors, fill colors, line types, size scales, and alpha) and
>> does
>>>> not let ggplot choose these settings from some theme default.
>>>> By independently, I mean: the set of graphical settings can be
>> totally
>>>> different from one group to the next and from one geom to the next.
>>>>
>>>> If this fine control can be achieved, how would you go about it
>> (please, be
>>>> assured that I already spent hours miserably failing to get to
>> anything
>>>> remotely productive, so your help would be really appreciated)?
>>>>
>>>> library(dplyr)
>>>> library(tidyr)
>>>> library(ggplot2)
>>>> set.seed(1234)
>>>> dummy <- data.frame(dummy = numeric())
>>>> data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd =
>> 0.1),
>>>>                      g1 = rep(1:4, each = 1000))
>>>> data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd
>> = 0.25))
>>>> data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
>>>> data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace =
>> TRUE),
>>>>                       y3 = runif(20, min=-8, max=4),
>>>>                       g3 = rep(1:4, each = 5)) %>% group_by(g3) %>%
>>>> arrange(x3)
>>>>
>>>> gplot <- ggplot(dummy) ### I know this line is not necessary in this
>>>> particular example, please assume this is relevantin the actual
>> framework I
>>>> am trying to build
>>>> gplot <- gplot +
>>>>     geom_smooth(data = data2,
>>>>                 aes(x2, y2, group = g2, color = factor(g2), linetype
>> =
>>>> factor(g2), size = 0.5*g2),
>>>>                 method = 'loess') +
>>>>     geom_path(data = data3,
>>>>               aes(x3, y3, group = g3, color = factor(g3), linetype =
>>>> factor(g3), shape = factor(g3), size = 0.5*g3)) +
>>>>     geom_point(data = data,
>>>>                aes(x1, y1, group = g1, color = factor(g1), fill =
>> factor(g1),
>>>> shape = factor(g1), size = g1))
>>>> gplot
>>>>
>>>> 2- Is the situation easier or more complex (ie, does ggplot make
>> some
>>>> decisions/assumptions for the user?) if the same x, y, and group
>> variables
>>>> are used in different geom's but the user still wants to provide
>>>> independently graphical settings for each geom?
>>>>
>>>> Thank you
>>>>
>>>> Sebastien
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Sebastien Bihorel
Cognigen Corporation
(t) +1 716 633 3463 ext 323
Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.

From axel.urbiz at gmail.com  Fri Oct 30 00:55:19 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Thu, 29 Oct 2015 19:55:19 -0400
Subject: [R] User-defined functions in dplyr
Message-ID: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>

Hello,

Sorry, resending this question as the prior was not sent properly.

I?m using the plyr package below to add a variable named "bin" to my
original data frame "df" with the user-defined function "create_bins". I'd
like to get similar results using dplyr instead, but failing to do so.

set.seed(4)
df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
c("model1", "model2")))


### Using plyr (works fine)
create_bins <- function(x, nBins)
{
  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
  dfB <-  data.frame(pred = x$pred,
                     bin = cut(x$pred, breaks = Breaks, include.lowest =
TRUE))
  dfB
}

nBins = 10
res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
head(res_plyr)

### Using dplyr (fails)

by_group <- dplyr::group_by(df, models)
res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
Error: not a vector


Any help would be much appreciated.

Best,
Axel.

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct 30 00:55:53 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 30 Oct 2015 00:55:53 +0100
Subject: [R] find all unit vectors which are orthogonal to a given vector
In-Reply-To: <5632A5AC.7030503@gmail.com>
References: <56329FEE.2030001@gmail.com> <5632A5AC.7030503@gmail.com>
Message-ID: <91A6426C-9CC5-4B34-9700-F5493221CD1D@gmail.com>


> On 30 Oct 2015, at 00:03 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 29/10/2015 6:38 PM, Marco Inacio wrote:
>> Is there a function in R to get the set of all unit vectors which are 
>> orthogonal to a given vector?
> 
> No.

Building blocks should be there, though. The last n-1 columns of 

Q <- qr.Q(qr(cbind(v, diag(nrow=length(v))))) 

looks like a good start. 

The full set is an n-1 dimensional sphere in n-space, spanned by those column vectors. If you need more than that representation, some further assembly is required.

-pd

 

> 
> Duncan Murdoch
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Fri Oct 30 01:28:10 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 29 Oct 2015 17:28:10 -0700
Subject: [R] User-defined functions in dplyr
In-Reply-To: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
Message-ID: <6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>

You are jumping the gun (your other email did get through) and you are posting using HTML (which does not come through on the list). Some time (re)reading the Posting Guide mentioned at the bottom of all emails on this list seems to be in order.

The error is actually quite clear. You should return a vector from your function, not a data frame.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>Hello,
>
>Sorry, resending this question as the prior was not sent properly.
>
>I?m using the plyr package below to add a variable named "bin" to my
>original data frame "df" with the user-defined function "create_bins".
>I'd
>like to get similar results using dplyr instead, but failing to do so.
>
>set.seed(4)
>df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>c("model1", "model2")))
>
>
>### Using plyr (works fine)
>create_bins <- function(x, nBins)
>{
>  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>  dfB <-  data.frame(pred = x$pred,
>                    bin = cut(x$pred, breaks = Breaks, include.lowest =
>TRUE))
>  dfB
>}
>
>nBins = 10
>res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
>head(res_plyr)
>
>### Using dplyr (fails)
>
>by_group <- dplyr::group_by(df, models)
>res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>Error: not a vector
>
>
>Any help would be much appreciated.
>
>Best,
>Axel.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marcoigarapava at gmail.com  Fri Oct 30 01:59:20 2015
From: marcoigarapava at gmail.com (Marco Inacio)
Date: Thu, 29 Oct 2015 22:59:20 -0200
Subject: [R] find all unit vectors which are orthogonal to a given vector
In-Reply-To: <91A6426C-9CC5-4B34-9700-F5493221CD1D@gmail.com>
References: <56329FEE.2030001@gmail.com> <5632A5AC.7030503@gmail.com>
	<91A6426C-9CC5-4B34-9700-F5493221CD1D@gmail.com>
Message-ID: <5632C0E8.8030903@gmail.com>

I think that's just what I needed. Thanks!

On 2015-10-29 09:55 PM, peter dalgaard wrote:
>> On 30 Oct 2015, at 00:03 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 29/10/2015 6:38 PM, Marco Inacio wrote:
>>> Is there a function in R to get the set of all unit vectors which are
>>> orthogonal to a given vector?
>> No.
> Building blocks should be there, though. The last n-1 columns of
>
> Q <- qr.Q(qr(cbind(v, diag(nrow=length(v)))))
>
> looks like a good start.
>
> The full set is an n-1 dimensional sphere in n-space, spanned by those column vectors. If you need more than that representation, some further assembly is required.
>
> -pd
>
>   
>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Fri Oct 30 02:17:43 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 29 Oct 2015 21:17:43 -0400
Subject: [R] install.packages() can't find install.packages() ?
Message-ID: <98935BCF-4F47-41A1-9976-138C9A33FFF3@utoronto.ca>

We are seeing the following problem when trying to install magrittr on Ubuntu 14.04


install.packages("magrittr")


Installing package into ?/home/ehsueh/R/x86_64-pc-linux-gnu-library/3.0?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
trying URL 'http://lib.ugent.be/CRAN/src/contrib/magrittr_1.5.tar.gz'
Content type 'application/x-gzip' length 200504 bytes (195 Kb)
opened URL
==================================================
downloaded 195 Kb


R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Error in eval(expr, envir, enclos) : 
  could not find function "install.packages"
In addition: Warning message:
In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called ?magrittr?




I don't understand why install.packages() executes, then can't find install.packages().
I also don't understand why R gives us the startup message at that point.

Installation of other packages fails as well.
Installation of magrittr my Mac works without issues.

Version info below.

Thanks!
Boris




=============================================
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8    
 [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8   
 [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] plot3D_1.0-2

loaded via a namespace (and not attached):
[1] misc3d_0.8-4 tcltk_3.0.2  tools_3.0.2

From r.turner at auckland.ac.nz  Fri Oct 30 03:23:05 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 30 Oct 2015 15:23:05 +1300
Subject: [R] install.packages() can't find install.packages() ?
In-Reply-To: <98935BCF-4F47-41A1-9976-138C9A33FFF3@utoronto.ca>
References: <98935BCF-4F47-41A1-9976-138C9A33FFF3@utoronto.ca>
Message-ID: <5632D489.8040502@auckland.ac.nz>



Have you tried this after starting R in a "clean" workspace?
Or perhaps after starting R --vanilla?

It sounds to me like something is corrupted in your install.packages() 
function --- or possible somewhere else --- which could be induced by 
having some ghosts lurking about in .RData.

(After all, it is getting close to Hallowe'en. :-) )

cheers,

Rolf

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

On 30/10/15 14:17, Boris Steipe wrote:
> We are seeing the following problem when trying to install magrittr on Ubuntu 14.04
>
>
> install.packages("magrittr")
>
>
> Installing package into ?/home/ehsueh/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://lib.ugent.be/CRAN/src/contrib/magrittr_1.5.tar.gz'
> Content type 'application/x-gzip' length 200504 bytes (195 Kb)
> opened URL
> ==================================================
> downloaded 195 Kb
>
>
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
>    Natural language support but running in an English locale
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>
> Error in eval(expr, envir, enclos) :
>    could not find function "install.packages"
> In addition: Warning message:
> In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>    there is no package called ?magrittr?
>
>
>
>
> I don't understand why install.packages() executes, then can't find install.packages().
> I also don't understand why R gives us the startup message at that point.
>
> Installation of other packages fails as well.
> Installation of magrittr my Mac works without issues.
>
> Version info below.
>
> Thanks!
> Boris
>
>
>
>
> =============================================
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>   [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] plot3D_1.0-2
>
> loaded via a namespace (and not attached):
> [1] misc3d_0.8-4 tcltk_3.0.2  tools_3.0.2


From boris.steipe at utoronto.ca  Fri Oct 30 05:33:01 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Fri, 30 Oct 2015 00:33:01 -0400
Subject: [R] install.packages() can't find install.packages() ?
In-Reply-To: <CAFftC1BrD4U8w5na4U4kb8r6XigJL3RTBKt4jROJ4cpZxiy9sA@mail.gmail.com>
References: <98935BCF-4F47-41A1-9976-138C9A33FFF3@utoronto.ca>
	<5632D489.8040502@auckland.ac.nz>
	<CAFftC1BrD4U8w5na4U4kb8r6XigJL3RTBKt4jROJ4cpZxiy9sA@mail.gmail.com>
Message-ID: <C0994450-D5F6-43FB-A243-1B0E78D3AB32@utoronto.ca>

Emma - do installations still work after you switch the startup script back on that I suggested you comment out? I'm specifically asking about loading plot3D...

As far as I'm concerned "it worked" would mean: you can load plot3D and magrittr through the startup script and then R is just fine and you can install e.g. stringr from CRAN. Is that so?

Lets make sure the ghosts aren't coming back - it's not quite Halloween yet.
:-)



On Oct 30, 2015, at 12:19 AM, Emma Hsueh <ehsueh1993 at gmail.com> wrote:

> Hi Rolf,
> 
> Looks like it is indeed the Halloween ghosts!
> I did what you said and it worked. Thank you!
> Do you know how the .RData might have gotten corrupted? 
> 
> Thanks again,
> Emma
> 
> Rolf Turner <r.turner at auckland.ac.nz> ? 2015?10?29? ??????
> 
> 
> Have you tried this after starting R in a "clean" workspace?
> Or perhaps after starting R --vanilla?
> 
> It sounds to me like something is corrupted in your install.packages() function --- or possible somewhere else --- which could be induced by having some ghosts lurking about in .RData.
> 
> (After all, it is getting close to Hallowe'en. :-) )
> 
> cheers,
> 
> Rolf
> 
> -- 
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
> 
> On 30/10/15 14:17, Boris Steipe wrote:
> We are seeing the following problem when trying to install magrittr on Ubuntu 14.04
> 
> 
> install.packages("magrittr")
> 
> 
> Installing package into ?/home/ehsueh/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://lib.ugent.be/CRAN/src/contrib/magrittr_1.5.tar.gz'
> Content type 'application/x-gzip' length 200504 bytes (195 Kb)
> opened URL
> ==================================================
> downloaded 195 Kb
> 
> 
> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>    Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
> Error in eval(expr, envir, enclos) :
>    could not find function "install.packages"
> In addition: Warning message:
> In library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>    there is no package called ?magrittr?
> 
> 
> 
> 
> I don't understand why install.packages() executes, then can't find install.packages().
> I also don't understand why R gives us the startup message at that point.
> 
> Installation of other packages fails as well.
> Installation of magrittr my Mac works without issues.
> 
> Version info below.
> 
> Thanks!
> Boris
> 
> 
> 
> 
> =============================================
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> locale:
>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>   [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] plot3D_1.0-2
> 
> loaded via a namespace (and not attached):
> [1] misc3d_0.8-4 tcltk_3.0.2  tools_3.0.2
> 
> 


From ehsueh1993 at gmail.com  Fri Oct 30 05:19:25 2015
From: ehsueh1993 at gmail.com (Emma Hsueh)
Date: Fri, 30 Oct 2015 00:19:25 -0400
Subject: [R] install.packages() can't find install.packages() ?
In-Reply-To: <5632D489.8040502@auckland.ac.nz>
References: <98935BCF-4F47-41A1-9976-138C9A33FFF3@utoronto.ca>
	<5632D489.8040502@auckland.ac.nz>
Message-ID: <CAFftC1BrD4U8w5na4U4kb8r6XigJL3RTBKt4jROJ4cpZxiy9sA@mail.gmail.com>

Hi Rolf,

Looks like it is indeed the Halloween ghosts!
I did what you said and it worked. Thank you!
Do you know how the .RData might have gotten corrupted?

Thanks again,
Emma

Rolf Turner <r.turner at auckland.ac.nz> ? 2015?10?29? ??????

>
>
> Have you tried this after starting R in a "clean" workspace?
> Or perhaps after starting R --vanilla?
>
> It sounds to me like something is corrupted in your install.packages()
> function --- or possible somewhere else --- which could be induced by
> having some ghosts lurking about in .RData.
>
> (After all, it is getting close to Hallowe'en. :-) )
>
> cheers,
>
> Rolf
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> On 30/10/15 14:17, Boris Steipe wrote:
>
>> We are seeing the following problem when trying to install magrittr on
>> Ubuntu 14.04
>>
>>
>> install.packages("magrittr")
>>
>>
>> Installing package into ?/home/ehsueh/R/x86_64-pc-linux-gnu-library/3.0?
>> (as ?lib? is unspecified)
>> --- Please select a CRAN mirror for use in this session ---
>> trying URL 'http://lib.ugent.be/CRAN/src/contrib/magrittr_1.5.tar.gz'
>> Content type 'application/x-gzip' length 200504 bytes (195 Kb)
>> opened URL
>> ==================================================
>> downloaded 195 Kb
>>
>>
>> R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
>> Copyright (C) 2013 The R Foundation for Statistical Computing
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> R is free software and comes with ABSOLUTELY NO WARRANTY.
>> You are welcome to redistribute it under certain conditions.
>> Type 'license()' or 'licence()' for distribution details.
>>
>>    Natural language support but running in an English locale
>>
>> R is a collaborative project with many contributors.
>> Type 'contributors()' for more information and
>> 'citation()' on how to cite R or R packages in publications.
>>
>> Type 'demo()' for some demos, 'help()' for on-line help, or
>> 'help.start()' for an HTML browser interface to help.
>> Type 'q()' to quit R.
>>
>> Error in eval(expr, envir, enclos) :
>>    could not find function "install.packages"
>> In addition: Warning message:
>> In library(package, lib.loc = lib.loc, character.only = TRUE,
>> logical.return = TRUE,  :
>>    there is no package called ?magrittr?
>>
>>
>>
>>
>> I don't understand why install.packages() executes, then can't find
>> install.packages().
>> I also don't understand why R gives us the startup message at that point.
>>
>> Installation of other packages fails as well.
>> Installation of magrittr my Mac works without issues.
>>
>> Version info below.
>>
>> Thanks!
>> Boris
>>
>>
>>
>>
>> =============================================
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>>   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>>   [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>> [1] plot3D_1.0-2
>>
>> loaded via a namespace (and not attached):
>> [1] misc3d_0.8-4 tcltk_3.0.2  tools_3.0.2
>>
>
>
>

	[[alternative HTML version deleted]]


From ehsueh1993 at gmail.com  Fri Oct 30 05:49:11 2015
From: ehsueh1993 at gmail.com (Emma Hsueh)
Date: Fri, 30 Oct 2015 00:49:11 -0400
Subject: [R] install.packages() can't find install.packages() ?
In-Reply-To: <C0994450-D5F6-43FB-A243-1B0E78D3AB32@utoronto.ca>
References: <98935BCF-4F47-41A1-9976-138C9A33FFF3@utoronto.ca>
	<5632D489.8040502@auckland.ac.nz>
	<CAFftC1BrD4U8w5na4U4kb8r6XigJL3RTBKt4jROJ4cpZxiy9sA@mail.gmail.com>
	<C0994450-D5F6-43FB-A243-1B0E78D3AB32@utoronto.ca>
Message-ID: <CAFftC1BA_ePHxJtw=V_hbdJxn+xJoJQ6X=jqOy0NT5XmaasUGw@mail.gmail.com>

I turned the startup script back on and tried installing stringr. It went
smoothly. Seems like the ghosts are gone. No clue how the corruption
happened though.

Thanks to both of you! Happy Halloween :D

Best,
Emma

Boris Steipe <boris.steipe at utoronto.ca> ? 2015?10?30? ??????

> Emma - do installations still work after you switch the startup script
> back on that I suggested you comment out? I'm specifically asking about
> loading plot3D...
>
> As far as I'm concerned "it worked" would mean: you can load plot3D and
> magrittr through the startup script and then R is just fine and you can
> install e.g. stringr from CRAN. Is that so?
>
> Lets make sure the ghosts aren't coming back - it's not quite Halloween
> yet.
> :-)
>
>
>
> On Oct 30, 2015, at 12:19 AM, Emma Hsueh <ehsueh1993 at gmail.com
> <javascript:;>> wrote:
>
> > Hi Rolf,
> >
> > Looks like it is indeed the Halloween ghosts!
> > I did what you said and it worked. Thank you!
> > Do you know how the .RData might have gotten corrupted?
> >
> > Thanks again,
> > Emma
> >
> > Rolf Turner <r.turner at auckland.ac.nz <javascript:;>> ? 2015?10?29?
> ??????
> >
> >
> > Have you tried this after starting R in a "clean" workspace?
> > Or perhaps after starting R --vanilla?
> >
> > It sounds to me like something is corrupted in your install.packages()
> function --- or possible somewhere else --- which could be induced by
> having some ghosts lurking about in .RData.
> >
> > (After all, it is getting close to Hallowe'en. :-) )
> >
> > cheers,
> >
> > Rolf
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > On 30/10/15 14:17, Boris Steipe wrote:
> > We are seeing the following problem when trying to install magrittr on
> Ubuntu 14.04
> >
> >
> > install.packages("magrittr")
> >
> >
> > Installing package into ?/home/ehsueh/R/x86_64-pc-linux-gnu-library/3.0?
> > (as ?lib? is unspecified)
> > --- Please select a CRAN mirror for use in this session ---
> > trying URL 'http://lib.ugent.be/CRAN/src/contrib/magrittr_1.5.tar.gz'
> > Content type 'application/x-gzip' length 200504 bytes (195 Kb)
> > opened URL
> > ==================================================
> > downloaded 195 Kb
> >
> >
> > R version 3.0.2 (2013-09-25) -- "Frisbee Sailing"
> > Copyright (C) 2013 The R Foundation for Statistical Computing
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> > R is free software and comes with ABSOLUTELY NO WARRANTY.
> > You are welcome to redistribute it under certain conditions.
> > Type 'license()' or 'licence()' for distribution details.
> >
> >    Natural language support but running in an English locale
> >
> > R is a collaborative project with many contributors.
> > Type 'contributors()' for more information and
> > 'citation()' on how to cite R or R packages in publications.
> >
> > Type 'demo()' for some demos, 'help()' for on-line help, or
> > 'help.start()' for an HTML browser interface to help.
> > Type 'q()' to quit R.
> >
> > Error in eval(expr, envir, enclos) :
> >    could not find function "install.packages"
> > In addition: Warning message:
> > In library(package, lib.loc = lib.loc, character.only = TRUE,
> logical.return = TRUE,  :
> >    there is no package called ?magrittr?
> >
> >
> >
> >
> > I don't understand why install.packages() executes, then can't find
> install.packages().
> > I also don't understand why R gives us the startup message at that point.
> >
> > Installation of other packages fails as well.
> > Installation of magrittr my Mac works without issues.
> >
> > Version info below.
> >
> > Thanks!
> > Boris
> >
> >
> >
> >
> > =============================================
> > R version 3.0.2 (2013-09-25)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> > locale:
> >   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
> >   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
> >   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
> >   [7] LC_PAPER=en_CA.UTF-8       LC_NAME=C
> >   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > other attached packages:
> > [1] plot3D_1.0-2
> >
> > loaded via a namespace (and not attached):
> > [1] misc3d_0.8-4 tcltk_3.0.2  tools_3.0.2
> >
> >
>
>

	[[alternative HTML version deleted]]


From sporter at ori.org.za  Fri Oct 30 11:13:49 2015
From: sporter at ori.org.za (Sean Porter)
Date: Fri, 30 Oct 2015 12:13:49 +0200
Subject: [R] monte carlo simulations in permanova in vegan package
In-Reply-To: <loom.20151029T141655-51@post.gmane.org>
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
	<loom.20151029T141655-51@post.gmane.org>
Message-ID: <014a01d112fb$aeb27fc0$0c177f40$@ori.org.za>

Thank you Jari,

It seems now that my question is morphing more into a statistical one, and
perhaps not appropriate for R-help list, so apologies. Yes we are talking
about the latest versions of the vegan and permute packages. 

When there are an insufficient number of permutations available due to low
sample sizes apparently an alternative is to use the result given in
Anderson & Robinson (2003) regarding the asymptotic permutation of the
numerator (or denominator) of the test statistic under permutation. And I
quote from Anderson et al. 2008 "It is demonstrated that each of the sums of
squares has, under permutation, an asymptotic distribution that is a linear
form in chi-square variables, where the coefficients are actually the
eigenvalues from a PCO of the resemblance matrix. Thus, chi-square variables
can be drawn randomly and independently, using Monte Carlo sampling, and
these can be combined with the eigenvalues to construct the asymptotic
permutation distribution for each of the numerator and denominator and,
thus,  for the entire pseudo-F statistic, in the event that too few actual
unique permutations exist."

Anderson, Gorley & Clarke. 2008. PERMANOVA+ for PRIMER: Guide to software
and statistical models.
Anderson & Robinson 2003. Generalised discriminant analysis based on
distances. Australian and New Zealand Journal of Statistics. 45: 301-318

I am sure you already know this! The above is what I am trying to do in the
vegan package though.. 

Apologies if I am missing something and if what you have said still applies
(that is not appropriate to exceed the possible number of permutations), I
am not a statistician..so any help/clarity would be welcome.. 


Regards, sean

?????????


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jari Oksanen
Sent: 29 October 2015 03:23 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] monte carlo simulations in permanova in vegan package

Sean Porter <sporter <at> ori.org.za> writes:

> I am trying to run a PERMANOVA in the vegan package with an 
> appropriate number of permutations (see example below), ideally 9999. 
> Obviously that number of permutations does not exists so I would like 
> to use Monte Carlo permutation tests to derive the probability value, 
> as is done in the commercial package PERMANOVA+ for PRIMER. How can I 
> adapt my code so that adonis will do so ? Many thanks, Sean
[...clip...]
> 
> > permanova <- adonis(species ~ time, data = time, permutations=999,
> method="bray")
> 
> 'nperm' > set of all permutations; Resetting 'nperm'.
> 
I assume we are talking about the latest version of vegan and permute
packages. In that case you really should switch to complete enumeration if
you request exceeds the number of distinct permutations. As people have told
you, you should be satisfied with that because there are no more distinct
permutations. Alternatively, you need more data.

If you mean by Monte Carlo that the same that you have a sampling with
return instead of permutation, or that the same observation can appear
several times and therefore some other unit is missing, then there are two
pieces of advice:

1. You should not do so.
2. If you want to do so, you can generate your resampling matrices by hand
and use that matrix as the argument of permutations=. See the documentations
(?adonis) which tells how to do so.

Cheers, Jari Oksanen

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From axel.urbiz at gmail.com  Fri Oct 30 12:04:03 2015
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Fri, 30 Oct 2015 07:04:03 -0400
Subject: [R] User-defined functions in dplyr
In-Reply-To: <6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
	<6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
Message-ID: <CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>

So in this case, "create_bins" returns a vector and I still get the same
error.


create_bins <- function(x, nBins)
{
  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
  bin <- cut(x$pred, breaks = Breaks, include.lowest = TRUE)
  bin
}


### Using dplyr (fails)
nBins = 10
by_group <- dplyr::group_by(df, models)
res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
Error: not a vector

On Thu, Oct 29, 2015 at 8:28 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You are jumping the gun (your other email did get through) and you are
> posting using HTML (which does not come through on the list). Some time
> (re)reading the Posting Guide mentioned at the bottom of all emails on this
> list seems to be in order.
>
> The error is actually quite clear. You should return a vector from your
> function, not a data frame.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com>
> wrote:
> >Hello,
> >
> >Sorry, resending this question as the prior was not sent properly.
> >
> >I?m using the plyr package below to add a variable named "bin" to my
> >original data frame "df" with the user-defined function "create_bins".
> >I'd
> >like to get similar results using dplyr instead, but failing to do so.
> >
> >set.seed(4)
> >df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
> >c("model1", "model2")))
> >
> >
> >### Using plyr (works fine)
> >create_bins <- function(x, nBins)
> >{
> >  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
> >  dfB <-  data.frame(pred = x$pred,
> >                    bin = cut(x$pred, breaks = Breaks, include.lowest =
> >TRUE))
> >  dfB
> >}
> >
> >nBins = 10
> >res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
> >head(res_plyr)
> >
> >### Using dplyr (fails)
> >
> >by_group <- dplyr::group_by(df, models)
> >res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
> >Error: not a vector
> >
> >
> >Any help would be much appreciated.
> >
> >Best,
> >Axel.
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Fri Oct 30 12:34:44 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 30 Oct 2015 06:34:44 -0500
Subject: [R] Achieve independent fine user control of ggplot geom
 settings when using groups in multiple geom's
In-Reply-To: <5632AC69.8000001@cognigencorp.com>
References: <563248A8.4080809@cognigencorp.com>
	<CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>
	<5632652B.80605@cognigencorp.com>
	<089CB06E-32E6-4997-9625-25B5C200083E@dcn.davis.CA.us>
	<5632AC69.8000001@cognigencorp.com>
Message-ID: <CABdHhvETn_D7MFUty3AUs_qG7+OzAmNcGef3HW7jzji2mHJEVw@mail.gmail.com>

I'd recommend reading the ggplot2 book - learning more about how
scales work in ggplot2 will help you understand why this isn't
possible.
Hadley

On Thu, Oct 29, 2015 at 6:31 PM, sbihorel
<Sebastien.Bihorel at cognigencorp.com> wrote:
> Thank for your reply,
>
> I may accept your point about the mapping consistency when the different
> geom's use the same data source. However, as pointed out in my example code,
> this does not have to be the case. Hence my question about the geom-specific
> control of group-dependent graphical settings.
>
> Sebastien
>
>
> On 10/29/2015 4:49 PM, Jeff Newmiller wrote:
>>
>> I think a fundamental design principle of ggplot is that mapping of values
>> to visual representation are consistent within a single plot, so reassigning
>> color mapping for different elements would not be supported.
>>
>> That being said, it is possible to explicitly control specific attributes
>> within a single geom outside of the mapping, though this usually does break
>> mappings in the legend.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 29, 2015 11:27:55 AM MST, sbihorel
>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>>
>>> Thank you for your reply.
>>>
>>> I do not have anything specific data/geom/grouping in mind, rather a
>>> framework in which users would just pile of each other layer after
>>> layer
>>> of geom each defined with specific settings. A minimum realistic
>>> scenario would a geom_point followed by a geom_smooth or a geom_path
>>> using different colors...
>>>
>>> Sebastien
>>>
>>> On 10/29/2015 1:34 PM, Ista Zahn wrote:
>>>>
>>>> I would say in a word, 'no'. What you seem to be implying is that you
>>>> want multiple color scales, multiple shape scales, etc. As far as I
>>>> know there is no support for that in ggplot2.
>>>>
>>>> Perhaps if you show us what you're actually trying to accomplish
>>>> someone can suggest a solution or at least a work-around.
>>>>
>>>> Best,
>>>> Ista
>>>>
>>>> On Thu, Oct 29, 2015 at 12:26 PM, sbihorel
>>>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>>>>
>>>>> Hello,
>>>>>
>>>>> Before I get to my question, I want to make clear that the topic of
>>>
>>> my
>>>>>
>>>>> present post is similar to posts I recently submitted to the list.
>>>
>>> Although
>>>>>
>>>>> I appreciate the replies I got, I believe that I did not correctly
>>>
>>> frame
>>>>>
>>>>> these previous posts to get to the bottom of things.
>>>>> I also want to make clear that the code example that I have inserted
>>>
>>> in this
>>>>>
>>>>> post is meant to illustrate my points/questions and does not reflect
>>>
>>> a
>>>>>
>>>>> particular interest in the data or the sequence of ggplot geom's
>>>
>>> used
>>>>>
>>>>> (except otherwise mentioned). Actually, I purposefully used junk
>>>
>>> meaningless
>>>>>
>>>>> data, geom's sequence, and settings, so that we agree the plot is
>>>
>>> ugly and
>>>>>
>>>>> that we, hopefully, don't get hang on specifics and start discussing
>>>
>>> about
>>>>>
>>>>> the merit of one approach vs another.
>>>>>
>>>>> So here are my questions:
>>>>>
>>>>> 1- Can a user independently control the settings of each geom's used
>>>
>>> in a
>>>>>
>>>>> ggplot call sequence when grouping is required?
>>>>>
>>>>> By control, I mean: user defines the graphical settings (groups,
>>>
>>> symbol
>>>>>
>>>>> shapes, colors, fill colors, line types, size scales, and alpha) and
>>>
>>> does
>>>>>
>>>>> not let ggplot choose these settings from some theme default.
>>>>> By independently, I mean: the set of graphical settings can be
>>>
>>> totally
>>>>>
>>>>> different from one group to the next and from one geom to the next.
>>>>>
>>>>> If this fine control can be achieved, how would you go about it
>>>
>>> (please, be
>>>>>
>>>>> assured that I already spent hours miserably failing to get to
>>>
>>> anything
>>>>>
>>>>> remotely productive, so your help would be really appreciated)?
>>>>>
>>>>> library(dplyr)
>>>>> library(tidyr)
>>>>> library(ggplot2)
>>>>> set.seed(1234)
>>>>> dummy <- data.frame(dummy = numeric())
>>>>> data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd =
>>>
>>> 0.1),
>>>>>
>>>>>                      g1 = rep(1:4, each = 1000))
>>>>> data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd
>>>
>>> = 0.25))
>>>>>
>>>>> data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
>>>>> data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace =
>>>
>>> TRUE),
>>>>>
>>>>>                       y3 = runif(20, min=-8, max=4),
>>>>>                       g3 = rep(1:4, each = 5)) %>% group_by(g3) %>%
>>>>> arrange(x3)
>>>>>
>>>>> gplot <- ggplot(dummy) ### I know this line is not necessary in this
>>>>> particular example, please assume this is relevantin the actual
>>>
>>> framework I
>>>>>
>>>>> am trying to build
>>>>> gplot <- gplot +
>>>>>     geom_smooth(data = data2,
>>>>>                 aes(x2, y2, group = g2, color = factor(g2), linetype
>>>
>>> =
>>>>>
>>>>> factor(g2), size = 0.5*g2),
>>>>>                 method = 'loess') +
>>>>>     geom_path(data = data3,
>>>>>               aes(x3, y3, group = g3, color = factor(g3), linetype =
>>>>> factor(g3), shape = factor(g3), size = 0.5*g3)) +
>>>>>     geom_point(data = data,
>>>>>                aes(x1, y1, group = g1, color = factor(g1), fill =
>>>
>>> factor(g1),
>>>>>
>>>>> shape = factor(g1), size = g1))
>>>>> gplot
>>>>>
>>>>> 2- Is the situation easier or more complex (ie, does ggplot make
>>>
>>> some
>>>>>
>>>>> decisions/assumptions for the user?) if the same x, y, and group
>>>
>>> variables
>>>>>
>>>>> are used in different geom's but the user still wants to provide
>>>>> independently graphical settings for each geom?
>>>>>
>>>>> Thank you
>>>>>
>>>>> Sebastien
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>
>>> http://www.R-project.org/posting-guide.html
>>>>>
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>
>
> --
> Sebastien Bihorel
> Cognigen Corporation
> (t) +1 716 633 3463 ext 323
> Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From sporter at ori.org.za  Fri Oct 30 12:48:54 2015
From: sporter at ori.org.za (Sean Porter)
Date: Fri, 30 Oct 2015 13:48:54 +0200
Subject: [R] monte carlo simulations in permanova in vegan package
References: <001901d11095$644ceeb0$2ce6cc10$@ori.org.za>
	<loom.20151029T141655-51@post.gmane.org> 
Message-ID: <015b01d11308$f72554a0$e56ffde0$@ori.org.za>

Thank you Jari,

It seems now that my question is morphing more into a statistical one, and
perhaps not appropriate for R-help list, so apologies. Yes we are talking
about the latest versions of the vegan and permute packages. 

When there are an insufficient number of permutations available due to low
sample sizes apparently an alternative is to use the result given in
Anderson & Robinson (2003) regarding the asymptotic permutation of the
numerator (or denominator) of the test statistic under permutation. And I
quote from Anderson et al. 2008 "It is demonstrated that each of the sums of
squares has, under permutation, an asymptotic distribution that is a linear
form in chi-square variables, where the coefficients are actually the
eigenvalues from a PCO of the resemblance matrix. Thus, chi-square variables
can be drawn randomly and independently, using Monte Carlo sampling, and
these can be combined with the eigenvalues to construct the asymptotic
permutation distribution for each of the numerator and denominator and,
thus,  for the entire pseudo-F statistic, in the event that too few actual
unique permutations exist."

Anderson, Gorley & Clarke. 2008. PERMANOVA+ for PRIMER: Guide to software
and statistical models.
Anderson & Robinson 2003. Generalised discriminant analysis based on
distances. Australian and New Zealand Journal of Statistics. 45: 301-318

I am sure you already know this! The above is what I am trying to do in the
vegan package though.. 

Apologies if I am missing something and if what you have said still applies
(that is not appropriate to exceed the possible number of permutations), I
am not a statistician..so any help/clarity would be welcome.. 


Regards, sean

?????????


-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jari Oksanen
Sent: 29 October 2015 03:23 PM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] monte carlo simulations in permanova in vegan package

Sean Porter <sporter <at> ori.org.za> writes:

> I am trying to run a PERMANOVA in the vegan package with an 
> appropriate number of permutations (see example below), ideally 9999.
> Obviously that number of permutations does not exists so I would like 
> to use Monte Carlo permutation tests to derive the probability value, 
> as is done in the commercial package PERMANOVA+ for PRIMER. How can I 
> adapt my code so that adonis will do so ? Many thanks, Sean
[...clip...]
> 
> > permanova <- adonis(species ~ time, data = time, permutations=999,
> method="bray")
> 
> 'nperm' > set of all permutations; Resetting 'nperm'.
> 
I assume we are talking about the latest version of vegan and permute
packages. In that case you really should switch to complete enumeration if
you request exceeds the number of distinct permutations. As people have told
you, you should be satisfied with that because there are no more distinct
permutations. Alternatively, you need more data.

If you mean by Monte Carlo that the same that you have a sampling with
return instead of permutation, or that the same observation can appear
several times and therefore some other unit is missing, then there are two
pieces of advice:

1. You should not do so.
2. If you want to do so, you can generate your resampling matrices by hand
and use that matrix as the argument of permutations=. See the documentations
(?adonis) which tells how to do so.

Cheers, Jari Oksanen

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Sebastien.Bihorel at cognigencorp.com  Fri Oct 30 13:50:00 2015
From: Sebastien.Bihorel at cognigencorp.com (sbihorel)
Date: Fri, 30 Oct 2015 08:50:00 -0400
Subject: [R] Achieve independent fine user control of ggplot geom
 settings when using groups in multiple geom's
In-Reply-To: <CABdHhvETn_D7MFUty3AUs_qG7+OzAmNcGef3HW7jzji2mHJEVw@mail.gmail.com>
References: <563248A8.4080809@cognigencorp.com>
	<CA+vqiLE_1WcTjwvDrm_xF2K_S=0NgEBXbaUB0dUBqg_=cjy9Yw@mail.gmail.com>
	<5632652B.80605@cognigencorp.com>
	<089CB06E-32E6-4997-9625-25B5C200083E@dcn.davis.CA.us>
	<5632AC69.8000001@cognigencorp.com>
	<CABdHhvETn_D7MFUty3AUs_qG7+OzAmNcGef3HW7jzji2mHJEVw@mail.gmail.com>
Message-ID: <56336778.3070406@cognigencorp.com>

Thanks Hadley,

I will certainly read your book. Unfortunately, what you just confirmed 
as the developer of ggplot means that ggplot is non-starter for what I 
want to build. Too bad, I was starting to appreciate some of its 
advantages over lattice.

About your book, in case I do not find a proper box on which to build it 
from source, I was wondering when it would become available in hard copy.

Sebastien

On 10/30/2015 07:34, Hadley Wickham wrote:
> I'd recommend reading the ggplot2 book - learning more about how
> scales work in ggplot2 will help you understand why this isn't
> possible.
> Hadley
>
> On Thu, Oct 29, 2015 at 6:31 PM, sbihorel
> <Sebastien.Bihorel at cognigencorp.com> wrote:
>> Thank for your reply,
>>
>> I may accept your point about the mapping consistency when the different
>> geom's use the same data source. However, as pointed out in my example code,
>> this does not have to be the case. Hence my question about the geom-specific
>> control of group-dependent graphical settings.
>>
>> Sebastien
>>
>>
>> On 10/29/2015 4:49 PM, Jeff Newmiller wrote:
>>> I think a fundamental design principle of ggplot is that mapping of values
>>> to visual representation are consistent within a single plot, so reassigning
>>> color mapping for different elements would not be supported.
>>>
>>> That being said, it is possible to explicitly control specific attributes
>>> within a single geom outside of the mapping, though this usually does break
>>> mappings in the legend.
>>>
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                         Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>> rocks...1k
>>>
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On October 29, 2015 11:27:55 AM MST, sbihorel
>>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>>> Thank you for your reply.
>>>>
>>>> I do not have anything specific data/geom/grouping in mind, rather a
>>>> framework in which users would just pile of each other layer after
>>>> layer
>>>> of geom each defined with specific settings. A minimum realistic
>>>> scenario would a geom_point followed by a geom_smooth or a geom_path
>>>> using different colors...
>>>>
>>>> Sebastien
>>>>
>>>> On 10/29/2015 1:34 PM, Ista Zahn wrote:
>>>>> I would say in a word, 'no'. What you seem to be implying is that you
>>>>> want multiple color scales, multiple shape scales, etc. As far as I
>>>>> know there is no support for that in ggplot2.
>>>>>
>>>>> Perhaps if you show us what you're actually trying to accomplish
>>>>> someone can suggest a solution or at least a work-around.
>>>>>
>>>>> Best,
>>>>> Ista
>>>>>
>>>>> On Thu, Oct 29, 2015 at 12:26 PM, sbihorel
>>>>> <Sebastien.Bihorel at cognigencorp.com> wrote:
>>>>>> Hello,
>>>>>>
>>>>>> Before I get to my question, I want to make clear that the topic of
>>>> my
>>>>>> present post is similar to posts I recently submitted to the list.
>>>> Although
>>>>>> I appreciate the replies I got, I believe that I did not correctly
>>>> frame
>>>>>> these previous posts to get to the bottom of things.
>>>>>> I also want to make clear that the code example that I have inserted
>>>> in this
>>>>>> post is meant to illustrate my points/questions and does not reflect
>>>> a
>>>>>> particular interest in the data or the sequence of ggplot geom's
>>>> used
>>>>>> (except otherwise mentioned). Actually, I purposefully used junk
>>>> meaningless
>>>>>> data, geom's sequence, and settings, so that we agree the plot is
>>>> ugly and
>>>>>> that we, hopefully, don't get hang on specifics and start discussing
>>>> about
>>>>>> the merit of one approach vs another.
>>>>>>
>>>>>> So here are my questions:
>>>>>>
>>>>>> 1- Can a user independently control the settings of each geom's used
>>>> in a
>>>>>> ggplot call sequence when grouping is required?
>>>>>>
>>>>>> By control, I mean: user defines the graphical settings (groups,
>>>> symbol
>>>>>> shapes, colors, fill colors, line types, size scales, and alpha) and
>>>> does
>>>>>> not let ggplot choose these settings from some theme default.
>>>>>> By independently, I mean: the set of graphical settings can be
>>>> totally
>>>>>> different from one group to the next and from one geom to the next.
>>>>>>
>>>>>> If this fine control can be achieved, how would you go about it
>>>> (please, be
>>>>>> assured that I already spent hours miserably failing to get to
>>>> anything
>>>>>> remotely productive, so your help would be really appreciated)?
>>>>>>
>>>>>> library(dplyr)
>>>>>> library(tidyr)
>>>>>> library(ggplot2)
>>>>>> set.seed(1234)
>>>>>> dummy <- data.frame(dummy = numeric())
>>>>>> data <- data.frame(x1 = rep(-2:2, each = 80) + rnorm(4000, sd =
>>>> 0.1),
>>>>>>                       g1 = rep(1:4, each = 1000))
>>>>>> data <- data %>% mutate(y1 = -x1^2 + 2*x1 - 2 + g1 + rnorm(4000, sd
>>>> = 0.25))
>>>>>> data2 <- data %>% select(x2=x1, y2=y1, g2=g1) %>% mutate(x2=-x2)
>>>>>> data3 <- data.frame(x3 = sample(seq(-2, 2, by = 0.1), 20, replace =
>>>> TRUE),
>>>>>>                        y3 = runif(20, min=-8, max=4),
>>>>>>                        g3 = rep(1:4, each = 5)) %>% group_by(g3) %>%
>>>>>> arrange(x3)
>>>>>>
>>>>>> gplot <- ggplot(dummy) ### I know this line is not necessary in this
>>>>>> particular example, please assume this is relevantin the actual
>>>> framework I
>>>>>> am trying to build
>>>>>> gplot <- gplot +
>>>>>>      geom_smooth(data = data2,
>>>>>>                  aes(x2, y2, group = g2, color = factor(g2), linetype
>>>> =
>>>>>> factor(g2), size = 0.5*g2),
>>>>>>                  method = 'loess') +
>>>>>>      geom_path(data = data3,
>>>>>>                aes(x3, y3, group = g3, color = factor(g3), linetype =
>>>>>> factor(g3), shape = factor(g3), size = 0.5*g3)) +
>>>>>>      geom_point(data = data,
>>>>>>                 aes(x1, y1, group = g1, color = factor(g1), fill =
>>>> factor(g1),
>>>>>> shape = factor(g1), size = g1))
>>>>>> gplot
>>>>>>
>>>>>> 2- Is the situation easier or more complex (ie, does ggplot make
>>>> some
>>>>>> decisions/assumptions for the user?) if the same x, y, and group
>>>> variables
>>>>>> are used in different geom's but the user still wants to provide
>>>>>> independently graphical settings for each geom?
>>>>>>
>>>>>> Thank you
>>>>>>
>>>>>> Sebastien
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> --
>> Sebastien Bihorel
>> Cognigen Corporation
>> (t) +1 716 633 3463 ext 323
>> Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Sebastien Bihorel
Cognigen Corporation
(t) +1 716 633 3463 ext 323
Cognigen Corporation, a wholly owned subsidiary of Simulations Plus, Inc.


From bsmith030465 at gmail.com  Fri Oct 30 15:43:36 2015
From: bsmith030465 at gmail.com (Brian Smith)
Date: Fri, 30 Oct 2015 10:43:36 -0400
Subject: [R] ggplot2: Controlling width of line
Message-ID: <CAEQKoCE_Xqj74wfO+w9hDSwea5zjL3Z8DYYy-XKfspKsYwgY6g@mail.gmail.com>

Hi,

I was trying to increase the size of certain lines in my plot (samples 'B'
and 'D' in example below). However, when I try to modify the line size, I
seem to screw up the linetypes. Also, is there a way to reflect the line
size in the legend?

Here is some sample code for illustration:

library(reshape)
matx <- matrix(sample(1:1000),4,5)
colnames(matx) <-  LETTERS[1:5]
rownames(matx) <- 1:4

subset1 <- c('B','D')

ltyvect <- c("solid","longdash","longdash","solid","solid")
colvect <- c("red","black","orange","blue","lightblue")
lwdvect <- rep(1,ncol(matx))

## For subset of samples, increase line width size
fmakelwd <- function(set1,subset1,vals1,val2=2){
    idx <- set1 %in% subset1
    vals1[idx] <- val2
    return(vals1)
}

maty <- melt(matx)
set1 <- maty$X2
vals1 <- rep(1,length(set1))

mylwd <- fmakelwd(set1,subset1,vals1,val2=1.5)
matz <- data.frame(maty,mylwd)

##### code without trying to modify line size

p <- ggplot(data=matz,aes(x=X1, y = value,col=X2,lty=X2,shape=X2))
p <- p + geom_line(aes(group = X2)) + geom_point(aes(shape =
factor(X2)),size=3) +
    scale_linetype_manual(values = ltyvect) +
    scale_color_manual(values = colvect) +
    theme(legend.title = element_blank())
p


#####  modifying line size

p <- ggplot(data=matz,aes(x=X1, y =
value,col=X2,lty=X2,shape=X2,size=mylwd))
p <- p + geom_line(aes(group = X2,size=mylwd)) + geom_point(aes(shape =
factor(X2)),size=3) +
    scale_linetype_manual(values = ltyvect) +
    scale_color_manual(values = colvect) +
    scale_size(range=c(0.1, 2), guide=FALSE) +
    theme(legend.title = element_blank())
p


#################


thanks!!

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 30 17:06:16 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 30 Oct 2015 09:06:16 -0700
Subject: [R] User-defined functions in dplyr
In-Reply-To: <CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
	<6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
	<CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>
Message-ID: <CAF8bMcbqD3B-gcM6D3vA2_UTCLNVcDhNbrfcY+Wa1jjgqfK4RA@mail.gmail.com>

The error message is not very helpful and the stack trace is pretty
inscrutable as well
> dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
Error: not a vector
> traceback()
14: stop(list(message = "not a vector", call = NULL, cppstack = NULL))
13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
12: summarise_impl(.data, dots)
11: summarise_.tbl_df(.data, .dots = lazyeval::lazy_dots(...))
10: summarise_(.data, .dots = lazyeval::lazy_dots(...))
9: dplyr::summarize(., create_bins)
8: function_list[[k]](value)
7: withVisible(function_list[[k]](value))
6: freduce(value, `_function_list`)
5: `_fseq`(`_lhs`)
4: eval(expr, envir, enclos)
3: eval(quote(`_fseq`(`_lhs`)), env, env)
2: withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
1: dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)


It does not mean that your function, create_bins, does not return a vector
--
the sum function gives the same result. help(summarize,package="dplyr")
says:
     ...: Name-value pairs of summary functions like ?min()?, ?mean()?,
          ?max()? etc.
It apparently means calls to summary functions, not summary functions
themselves.  The examples in the help file show the proper usage.

Use a call to your function and you will see it works better
   > dplyr::group_by(df, models) %>%
dplyr::summarize(create_bins(pred,nBins))
   Error: $ operator is invalid for atomic vectors
The traceback again is not very useful, because the call information was
stripped by dplyr (by the call=NULL in the call to stop()):
  > traceback()
  14: stop(list(message = "$ operator is invalid for atomic vectors",
          call = NULL, cppstack = NULL))
  13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
However it is clear that the fault is in your function, which is expecting a
data.frame x with a column called pred but gets pred itself.  Change x to
xpred
in the argument list and x$pred to xpred in the body of the function.

You will run into more problems because your function returns a vector
the length of its input but summarize expects a summary function - one
that returns a scalar for any size vector input.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 30, 2015 at 4:04 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:

> So in this case, "create_bins" returns a vector and I still get the same
> error.
>
>
> create_bins <- function(x, nBins)
> {
>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>   bin <- cut(x$pred, breaks = Breaks, include.lowest = TRUE)
>   bin
> }
>
>
> ### Using dplyr (fails)
> nBins = 10
> by_group <- dplyr::group_by(df, models)
> res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
> Error: not a vector
>
> On Thu, Oct 29, 2015 at 8:28 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
>
> > You are jumping the gun (your other email did get through) and you are
> > posting using HTML (which does not come through on the list). Some time
> > (re)reading the Posting Guide mentioned at the bottom of all emails on
> this
> > list seems to be in order.
> >
> > The error is actually quite clear. You should return a vector from your
> > function, not a data frame.
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com>
> > wrote:
> > >Hello,
> > >
> > >Sorry, resending this question as the prior was not sent properly.
> > >
> > >I?m using the plyr package below to add a variable named "bin" to my
> > >original data frame "df" with the user-defined function "create_bins".
> > >I'd
> > >like to get similar results using dplyr instead, but failing to do so.
> > >
> > >set.seed(4)
> > >df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
> > >c("model1", "model2")))
> > >
> > >
> > >### Using plyr (works fine)
> > >create_bins <- function(x, nBins)
> > >{
> > >  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
> > >  dfB <-  data.frame(pred = x$pred,
> > >                    bin = cut(x$pred, breaks = Breaks, include.lowest =
> > >TRUE))
> > >  dfB
> > >}
> > >
> > >nBins = 10
> > >res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
> > >head(res_plyr)
> > >
> > >### Using dplyr (fails)
> > >
> > >by_group <- dplyr::group_by(df, models)
> > >res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
> > >Error: not a vector
> > >
> > >
> > >Any help would be much appreciated.
> > >
> > >Best,
> > >Axel.
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 30 17:19:37 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 30 Oct 2015 09:19:37 -0700
Subject: [R] User-defined functions in dplyr
In-Reply-To: <CAF8bMcbqD3B-gcM6D3vA2_UTCLNVcDhNbrfcY+Wa1jjgqfK4RA@mail.gmail.com>
References: <CAAyVsXL+kdUDoiAJPXhVpqFWMwXQWZ_308JbRkP7J6HeYW+fCw@mail.gmail.com>
	<6D1A9E95-9B4B-4238-B447-0DA87E1018C9@dcn.davis.CA.us>
	<CAAyVsXK7Mu=9AthwsOT4vdQm07RifoXJFVHjsLKgSAAsY0FarA@mail.gmail.com>
	<CAF8bMcbqD3B-gcM6D3vA2_UTCLNVcDhNbrfcY+Wa1jjgqfK4RA@mail.gmail.com>
Message-ID: <CAF8bMcY-wSUZt0bHnmpCxsttr6OZ2KFe5xtAP86YkB7LdYQmbQ@mail.gmail.com>

dplyr::mutate is probably what you want instead of dplyr::summarize:

create_bins3 <- function (xpred, nBins)
{
    Breaks <- unique(quantile(xpred, probs = seq(0, 1, 1/nBins)))
    bin <- cut(xpred, breaks = Breaks, include.lowest = TRUE)
    bin
}
dplyr::group_by(df, models) %>% dplyr::mutate(Bin=create_bins3(pred,nBins))
#Source: local data frame [100 x 3]
#Groups: models [2]
#
#         pred models               Bin
#        (dbl) (fctr)            (fctr)
#1   0.2167549 model1     (0.167,0.577]
#2  -0.5424926 model1   (-0.869,-0.481]
...


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 30, 2015 at 9:06 AM, William Dunlap <wdunlap at tibco.com> wrote:

> The error message is not very helpful and the stack trace is pretty
> inscrutable as well
> > dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
> Error: not a vector
> > traceback()
> 14: stop(list(message = "not a vector", call = NULL, cppstack = NULL))
> 13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
> 12: summarise_impl(.data, dots)
> 11: summarise_.tbl_df(.data, .dots = lazyeval::lazy_dots(...))
> 10: summarise_(.data, .dots = lazyeval::lazy_dots(...))
> 9: dplyr::summarize(., create_bins)
> 8: function_list[[k]](value)
> 7: withVisible(function_list[[k]](value))
> 6: freduce(value, `_function_list`)
> 5: `_fseq`(`_lhs`)
> 4: eval(expr, envir, enclos)
> 3: eval(quote(`_fseq`(`_lhs`)), env, env)
> 2: withVisible(eval(quote(`_fseq`(`_lhs`)), env, env))
> 1: dplyr::group_by(df, models) %>% dplyr::summarize(create_bins)
>
>
> It does not mean that your function, create_bins, does not return a vector
> --
> the sum function gives the same result. help(summarize,package="dplyr")
> says:
>      ...: Name-value pairs of summary functions like ?min()?, ?mean()?,
>           ?max()? etc.
> It apparently means calls to summary functions, not summary functions
> themselves.  The examples in the help file show the proper usage.
>
> Use a call to your function and you will see it works better
>    > dplyr::group_by(df, models) %>%
> dplyr::summarize(create_bins(pred,nBins))
>    Error: $ operator is invalid for atomic vectors
> The traceback again is not very useful, because the call information was
> stripped by dplyr (by the call=NULL in the call to stop()):
>   > traceback()
>   14: stop(list(message = "$ operator is invalid for atomic vectors",
>           call = NULL, cppstack = NULL))
>   13: .Call("dplyr_summarise_impl", PACKAGE = "dplyr", df, dots)
> However it is clear that the fault is in your function, which is expecting
> a
> data.frame x with a column called pred but gets pred itself.  Change x to
> xpred
> in the argument list and x$pred to xpred in the body of the function.
>
> You will run into more problems because your function returns a vector
> the length of its input but summarize expects a summary function - one
> that returns a scalar for any size vector input.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 30, 2015 at 4:04 AM, Axel Urbiz <axel.urbiz at gmail.com> wrote:
>
>> So in this case, "create_bins" returns a vector and I still get the same
>> error.
>>
>>
>> create_bins <- function(x, nBins)
>> {
>>   Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>>   bin <- cut(x$pred, breaks = Breaks, include.lowest = TRUE)
>>   bin
>> }
>>
>>
>> ### Using dplyr (fails)
>> nBins = 10
>> by_group <- dplyr::group_by(df, models)
>> res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>> Error: not a vector
>>
>> On Thu, Oct 29, 2015 at 8:28 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us
>> >
>> wrote:
>>
>> > You are jumping the gun (your other email did get through) and you are
>> > posting using HTML (which does not come through on the list). Some time
>> > (re)reading the Posting Guide mentioned at the bottom of all emails on
>> this
>> > list seems to be in order.
>> >
>> > The error is actually quite clear. You should return a vector from your
>> > function, not a data frame.
>> >
>> ---------------------------------------------------------------------------
>> > Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> > Go...
>> >                                       Live:   OO#.. Dead: OO#..  Playing
>> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> > /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> >
>> ---------------------------------------------------------------------------
>> > Sent from my phone. Please excuse my brevity.
>> >
>> > On October 29, 2015 4:55:19 PM MST, Axel Urbiz <axel.urbiz at gmail.com>
>> > wrote:
>> > >Hello,
>> > >
>> > >Sorry, resending this question as the prior was not sent properly.
>> > >
>> > >I?m using the plyr package below to add a variable named "bin" to my
>> > >original data frame "df" with the user-defined function "create_bins".
>> > >I'd
>> > >like to get similar results using dplyr instead, but failing to do so.
>> > >
>> > >set.seed(4)
>> > >df <- data.frame(pred = rnorm(100), models = gl(2, 50, 100, labels =
>> > >c("model1", "model2")))
>> > >
>> > >
>> > >### Using plyr (works fine)
>> > >create_bins <- function(x, nBins)
>> > >{
>> > >  Breaks <- unique(quantile(x$pred, probs = seq(0, 1, 1/nBins)))
>> > >  dfB <-  data.frame(pred = x$pred,
>> > >                    bin = cut(x$pred, breaks = Breaks, include.lowest =
>> > >TRUE))
>> > >  dfB
>> > >}
>> > >
>> > >nBins = 10
>> > >res_plyr <- plyr::ddply(df, plyr::.(models), create_bins, nBins)
>> > >head(res_plyr)
>> > >
>> > >### Using dplyr (fails)
>> > >
>> > >by_group <- dplyr::group_by(df, models)
>> > >res_dplyr <- dplyr::summarize(by_group, create_bins, nBins)
>> > >Error: not a vector
>> > >
>> > >
>> > >Any help would be much appreciated.
>> > >
>> > >Best,
>> > >Axel.
>> > >
>> > >       [[alternative HTML version deleted]]
>> > >
>> > >______________________________________________
>> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > >https://stat.ethz.ch/mailman/listinfo/r-help
>> > >PLEASE do read the posting guide
>> > >http://www.R-project.org/posting-guide.html
>> > >and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From wagenadl at ucmail.uc.edu  Fri Oct 30 15:32:22 2015
From: wagenadl at ucmail.uc.edu (Wagenaar, Daniel (wagenadl))
Date: Fri, 30 Oct 2015 14:32:22 +0000
Subject: [R] (no subject)
Message-ID: <08471B2D53C89E47A3391EE6C00B314C75EE6BC2@UCMAILA7.ad.uc.edu>

Dear R users:

All textbook references that I consult say that in a nested ANOVA (e.g., A/B), the F statistic for factor A should be calculated as F_A = MS_A / MS_(B within A). But when I run this simple example:

set.seed(1)
A = factor(rep(1:3, each=4))
B = factor(rep(1:2, 3, each=2))
Y = rnorm(12)
anova(lm(Y ~ A/B))

I get this result:

Analysis of Variance Table

Response: Y
          Df Sum Sq Mean Sq F value Pr(>F)
A          2 0.4735 0.23675  0.2845 0.7620
A:B        3 1.7635 0.58783  0.7064 0.5823
Residuals  6 4.9931 0.83218               

Evidently, R calculates the F value for A as MS_A / MS_Residuals. While it is straightforward enough to calculate what I think is the correct result from the table, I am surprised that R doesn't give me that answer directly. Does anybody know if R's behavior is intentional, and if so, why? And, perhaps most importantly, how to get the "textbook" result in the most straightforward way? (I'd like to be able to give me students a simple procedure...)

Thanks,

Daniel Wagenaar

-- 
Daniel A. Wagenaar, PhD
Assistant Professor
Department of Biological Sciences
McMicken College of Arts and Sciences
University of Cincinnati
Cincinnati, OH 45221
Phone: +1 (513) 556-9757
Email: daniel.wagenaar at uc.edu
Web: http://www.danielwagenaar.net

From mathewanalytics at gmail.com  Fri Oct 30 15:07:45 2015
From: mathewanalytics at gmail.com (Abraham Mathew)
Date: Fri, 30 Oct 2015 10:07:45 -0400
Subject: [R] Error: Invalid First Argument in DPlyr
Message-ID: <CABbYstdytt_HeeTs6Pwt=FNRW5xQ8-W668MCH7zE9swO_Yjf8w@mail.gmail.com>

I'm getting an "invalid first argument" error for the following. However,
con is an actual connection and is set up properly. So what does this error
actually refer to?

library(dplyr)
con <- RSQLServer::src_sqlserver("***", database = "***")

myData <- con %>%
  tbl("table") %>%
  group_by( work_dt, campaign, ad_group, matchtype, keyword ) %>%
  select( work_dt, campaign, ad_group, matchtype, keyword,
impressions, clicks, cost ) %>%
  filter(site_id %in% c(6932,6946,6948,6949,6951,6952,6953,6954,
                        6955,6964,6978,6979,7061,7260,7272,7329,
                        7791,7794,7850,7858,7983)) %>%
  filter(work_dt >= as.Date("2014-10-01 00:00:00") & work_dt <
as.Date("2014-10-02 00:00:00")) %>%
  summarise(
    sum_impressions = sum(impressions),
    sum_clicks = sum(clicks),
    sum_cost = sum(cost),
  ) %>%
  collect()

This code produces:

Error in exists(name, env) : invalid first argument



exists("con")
> exists(con)
Error in exists(con) : invalid first argument> exists("con")[1] TRUE





-- 


*Abraham MathewData Ninja and Statistical Modeler*



*Minneapolis, MN720-648-0108 at abmathewksAnalytics_Blog
<https://mathewanalytics.wordpress.com/>*

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 30 18:14:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 30 Oct 2015 10:14:54 -0700
Subject: [R] Error: Invalid First Argument in DPlyr
In-Reply-To: <CABbYstdytt_HeeTs6Pwt=FNRW5xQ8-W668MCH7zE9swO_Yjf8w@mail.gmail.com>
References: <CABbYstdytt_HeeTs6Pwt=FNRW5xQ8-W668MCH7zE9swO_Yjf8w@mail.gmail.com>
Message-ID: <27E02CA5-B0C4-41C8-A404-C44E8FF02C6C@dcn.davis.CA.us>

You need to divide and conquer... find out which step is breaking the pipe by terminating it early at various points and if the problem is still not clear one you know which step is broken then give us a reproducible example.

I am not familiar with RSQLServer specifically, but the version of dplyr that I have installed (0.4.3) does not have a variant of the tbl function that is adapted to it.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 30, 2015 7:07:45 AM PDT, Abraham Mathew <mathewanalytics at gmail.com> wrote:
>I'm getting an "invalid first argument" error for the following.
>However,
>con is an actual connection and is set up properly. So what does this
>error
>actually refer to?
>
>library(dplyr)
>con <- RSQLServer::src_sqlserver("***", database = "***")
>
>myData <- con %>%
>  tbl("table") %>%
>  group_by( work_dt, campaign, ad_group, matchtype, keyword ) %>%
>  select( work_dt, campaign, ad_group, matchtype, keyword,
>impressions, clicks, cost ) %>%
>  filter(site_id %in% c(6932,6946,6948,6949,6951,6952,6953,6954,
>                        6955,6964,6978,6979,7061,7260,7272,7329,
>                        7791,7794,7850,7858,7983)) %>%
>  filter(work_dt >= as.Date("2014-10-01 00:00:00") & work_dt <
>as.Date("2014-10-02 00:00:00")) %>%
>  summarise(
>    sum_impressions = sum(impressions),
>    sum_clicks = sum(clicks),
>    sum_cost = sum(cost),
>  ) %>%
>  collect()
>
>This code produces:
>
>Error in exists(name, env) : invalid first argument
>
>
>
>exists("con")
>> exists(con)
>Error in exists(con) : invalid first argument> exists("con")[1] TRUE


From djnordlund at frontier.com  Fri Oct 30 18:35:57 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 30 Oct 2015 10:35:57 -0700
Subject: [R] how to work with time of day (independent of date)
Message-ID: <5633AA7D.307@frontier.com>

I have a data frame with date/times represented as charaacter strings 
and and a value at that date/time.  I want to get the mean value for 
each time of day, across days, and then plot time of day on the x-axis 
and means on the y-axis.  R doesn't appear to have a built-in time of 
day time type (independent of a date), unless I have missed something. 
What is the best way to create a time variable so that I can aggregate 
and plot by time of day, with time labelled in HH:MM format.  My current 
approach is to convert all date/times to the same date.  I can then 
manage the rest of what I want with ggplot2.  But I am  wondering if 
there is an easier/better way to do deal with time of day.

Here is a sample data frame.

df <- structure(list(date = structure(1:8, .Label = c("2015-10-29 
00:50:00",
"2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
"2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
"2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"), row.names = 
c(NA,
-8L), class = "data.frame")


Any suggestions appreciated.

Dan

-- 
Daniel Nordlund
Bothell, WA  USA


From jholtman at gmail.com  Fri Oct 30 18:56:09 2015
From: jholtman at gmail.com (jim holtman)
Date: Fri, 30 Oct 2015 13:56:09 -0400
Subject: [R] how to work with time of day (independent of date)
In-Reply-To: <5633AA7D.307@frontier.com>
References: <5633AA7D.307@frontier.com>
Message-ID: <CAAxdm-5tv7zmYWr=kkT1fohSW7a5c0NCQf_axsGKfiQD2G-sPA@mail.gmail.com>

is this what you want:

> df <- structure(list(date = structure(1:8, .Label = c("2015-10-29
00:50:00",
+ "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
+ "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
+ "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
+ 80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"), row.names =
c(NA,
+ -8L), class = "data.frame")
>
> # extract just the time and summarize by it
> tapply(df$value, substring(df$date, 12, 16), mean)
00:50 09:30 10:30 21:10
 66.0  20.0  79.0  59.5



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Oct 30, 2015 at 1:35 PM, Daniel Nordlund <djnordlund at frontier.com>
wrote:

> I have a data frame with date/times represented as charaacter strings and
> and a value at that date/time.  I want to get the mean value for each time
> of day, across days, and then plot time of day on the x-axis and means on
> the y-axis.  R doesn't appear to have a built-in time of day time type
> (independent of a date), unless I have missed something. What is the best
> way to create a time variable so that I can aggregate and plot by time of
> day, with time labelled in HH:MM format.  My current approach is to convert
> all date/times to the same date.  I can then manage the rest of what I want
> with ggplot2.  But I am  wondering if there is an easier/better way to do
> deal with time of day.
>
> Here is a sample data frame.
>
> df <- structure(list(date = structure(1:8, .Label = c("2015-10-29
> 00:50:00",
> "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
> "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
> "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
> 80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"), row.names =
> c(NA,
> -8L), class = "data.frame")
>
>
> Any suggestions appreciated.
>
> Dan
>
> --
> Daniel Nordlund
> Bothell, WA  USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Oct 30 19:22:32 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 30 Oct 2015 11:22:32 -0700
Subject: [R] how to work with time of day (independent of date)
In-Reply-To: <5633AA7D.307@frontier.com>
References: <5633AA7D.307@frontier.com>
Message-ID: <CAF8bMcZ5Af7B1d98K90j49xMxPSMpEs1vfaxcCE-KsuuwkwWyQ@mail.gmail.com>

You can use difftime objects to get the amount of time since the start of
the current day.  E.g.,
  > dateTime <- as.POSIXlt( c("2015-10-29 00:50:00",
  + "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
  + "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
  + "2015-10-31 10:30:00"))
  > date <- trunc(dateTime, units="days")
  > sinceMidnight <- difftime(dateTime, date, units="mins")
  > sinceMidnight
  Time differences in mins
  [1]   50  570 1270   50  570 1270   50  630

I use difftime(x, y, units=) instead of the similar x-y because the latter
chooses
the units based on how far apart x and y are, while the former gives me
consistent
units:
  > dateTime[1] - date[1]
  Time difference of 50 mins
  > as.numeric(.Last.value)
  [1] 50
  > dateTime[5:6] - date[5:6]
  Time differences in hours
  [1]  9.50000 21.16667
  > as.numeric(.Last.value)
  [1]  9.50000 21.16667

Depending on what you are using this for, you might want to compute time
since 3am
of the current day so you don't get discontinuities for most times when the
time
changes in spring and fall.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 30, 2015 at 10:35 AM, Daniel Nordlund <djnordlund at frontier.com>
wrote:

> I have a data frame with date/times represented as charaacter strings and
> and a value at that date/time.  I want to get the mean value for each time
> of day, across days, and then plot time of day on the x-axis and means on
> the y-axis.  R doesn't appear to have a built-in time of day time type
> (independent of a date), unless I have missed something. What is the best
> way to create a time variable so that I can aggregate and plot by time of
> day, with time labelled in HH:MM format.  My current approach is to convert
> all date/times to the same date.  I can then manage the rest of what I want
> with ggplot2.  But I am  wondering if there is an easier/better way to do
> deal with time of day.
>
> Here is a sample data frame.
>
> df <- structure(list(date = structure(1:8, .Label = c("2015-10-29
> 00:50:00",
> "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
> "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
> "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
> 80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"), row.names =
> c(NA,
> -8L), class = "data.frame")
>
>
> Any suggestions appreciated.
>
> Dan
>
> --
> Daniel Nordlund
> Bothell, WA  USA
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kw.stat at gmail.com  Fri Oct 30 20:12:44 2015
From: kw.stat at gmail.com (Kevin Wright)
Date: Fri, 30 Oct 2015 14:12:44 -0500
Subject: [R] (no subject)
In-Reply-To: <08471B2D53C89E47A3391EE6C00B314C75EE6BC2@UCMAILA7.ad.uc.edu>
References: <08471B2D53C89E47A3391EE6C00B314C75EE6BC2@UCMAILA7.ad.uc.edu>
Message-ID: <CAKFxdiQTR4uopMRte+J1T6hd8_DhRD9vyZbWsvyZnF_4_K-3EQ@mail.gmail.com>

Maybe you want

summary(aov(Y ~ A + Error(A:B)))

Kevin


On Fri, Oct 30, 2015 at 9:32 AM, Wagenaar, Daniel (wagenadl) <
wagenadl at ucmail.uc.edu> wrote:

> Dear R users:
>
> All textbook references that I consult say that in a nested ANOVA (e.g.,
> A/B), the F statistic for factor A should be calculated as F_A = MS_A /
> MS_(B within A). But when I run this simple example:
>
> set.seed(1)
> A = factor(rep(1:3, each=4))
> B = factor(rep(1:2, 3, each=2))
> Y = rnorm(12)
> anova(lm(Y ~ A/B))
>
> I get this result:
>
> Analysis of Variance Table
>
> Response: Y
>           Df Sum Sq Mean Sq F value Pr(>F)
> A          2 0.4735 0.23675  0.2845 0.7620
> A:B        3 1.7635 0.58783  0.7064 0.5823
> Residuals  6 4.9931 0.83218
>
> Evidently, R calculates the F value for A as MS_A / MS_Residuals. While it
> is straightforward enough to calculate what I think is the correct result
> from the table, I am surprised that R doesn't give me that answer directly.
> Does anybody know if R's behavior is intentional, and if so, why? And,
> perhaps most importantly, how to get the "textbook" result in the most
> straightforward way? (I'd like to be able to give me students a simple
> procedure...)
>
> Thanks,
>
> Daniel Wagenaar
>
> --
> Daniel A. Wagenaar, PhD
> Assistant Professor
> Department of Biological Sciences
> McMicken College of Arts and Sciences
> University of Cincinnati
> Cincinnati, OH 45221
> Phone: +1 (513) 556-9757
> Email: daniel.wagenaar at uc.edu
> Web: http://www.danielwagenaar.net
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Kevin Wright

	[[alternative HTML version deleted]]


From djnordlund at frontier.com  Fri Oct 30 20:26:00 2015
From: djnordlund at frontier.com (Daniel Nordlund)
Date: Fri, 30 Oct 2015 12:26:00 -0700
Subject: [R] how to work with time of day (independent of date)
In-Reply-To: <CAHz+bWY6c3ebdK1WG+YiGzy3cVe6RnKV5+SGnH6MB9bBu-MzHg@mail.gmail.com>
References: <5633AA7D.307@frontier.com>
	<CAHz+bWaeXW6uNYy56vt4O=aRoQkTB6YUX_-4ejQMnP8M72NVbw@mail.gmail.com>
	<CAHz+bWbNOCAAJq=qHAaLzQckRqR6fCUT6pAzOREuBdi0raj7Rw@mail.gmail.com>
	<CAHz+bWY6c3ebdK1WG+YiGzy3cVe6RnKV5+SGnH6MB9bBu-MzHg@mail.gmail.com>
Message-ID: <5633C448.3000606@frontier.com>

On 10/30/2015 11:17 AM, Mark Leeds wrote:
> Daniel: Just to complete my solution, here's the code for doing the
> mean. Didn't expect this to take 3 emails !!! Have a good weekend.
>
> temp <- tapply(f$value, f$justtimes, mean)
> finalDF <- data.frame(chrontimes = times(rownames(temp)), values = temp)
> plot(values ~ chrontimes, data = finalDF)
>
>
>
>
>
> On Fri, Oct 30, 2015 at 2:09 PM, Mark Leeds <markleeds2 at gmail.com
> <mailto:markleeds2 at gmail.com>> wrote:
>
>     Hi Daniel: I forgot that you wanted the mean so my code doesn't do
>     exactly what you asked for but you can use jim's code for that part.
>     His substring approach is also good but maybe
>     the chron approach is more general ? Sorry for confusion.
>
>
>
>
>     On Fri, Oct 30, 2015 at 2:07 PM, Mark Leeds <markleeds2 at gmail.com
>     <mailto:markleeds2 at gmail.com>> wrote:
>
>         Hi Daniel:  Assuming that you don't have to deal with time
>         zones, then you can use a chron object which has a seperate
>         field for the time.  See below for how to convert to just times.
>         I sent privately in order to not keep others from sending since
>         there may  be other ways. But, if you're okay with just this,
>         then you can just send to list to close out thread. No credit
>         needed. All the best.
>
>
>         library(chron)
>
>         f <- structure(list(date = structure(1:8, .Label = c("2015-10-29
>         00:50:00",
>         "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
>         "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
>         "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
>         80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"),
>         row.names = c(NA,
>         -8L), class = "data.frame")
>
>         print(f)
>
>         f$dateandtimes <-
>         as.chron(as.POSIXct(as.character(f$date),format = "%Y-%m-%d
>         %H:%M:%S"))
>         print(f)
>
>         f$justtimes <- times(as.numeric(f$dateandtimes) %% 1)
>         print(f)
>
>         plot(value ~ justtimes, data = f)
>
>         On Fri, Oct 30, 2015 at 1:35 PM, Daniel Nordlund
>         <djnordlund at frontier.com <mailto:djnordlund at frontier.com>> wrote:
>
>             I have a data frame with date/times represented as
>             charaacter strings and and a value at that date/time.  I
>             want to get the mean value for each time of day, across
>             days, and then plot time of day on the x-axis and means on
>             the y-axis.  R doesn't appear to have a built-in time of day
>             time type (independent of a date), unless I have missed
>             something. What is the best way to create a time variable so
>             that I can aggregate and plot by time of day, with time
>             labelled in HH:MM format.  My current approach is to convert
>             all date/times to the same date.  I can then manage the rest
>             of what I want with ggplot2.  But I am  wondering if there
>             is an easier/better way to do deal with time of day.
>
>             Here is a sample data frame.
>
>             df <- structure(list(date = structure(1:8, .Label =
>             c("2015-10-29 00:50:00",
>             "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30
>             00:50:00",
>             "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31
>             00:50:00",
>             "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
>             80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"),
>             row.names = c(NA,
>             -8L), class = "data.frame")
>
>
>             Any suggestions appreciated.
>
>             Dan
>
>             --
>             Daniel Nordlund
>             Bothell, WA  USA
>
>             ______________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing
>             list -- To UNSUBSCRIBE and more, see
>             https://stat.ethz.ch/mailman/listinfo/r-help
>             PLEASE do read the posting guide
>             http://www.R-project.org/posting-guide.html
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>
>
>

Thanks to all who responded (both on and off list).  Several useful 
suggestions were presented.  It looks like using the chron package may 
get me what I want, but I will play with all the solutions to see what 
works best for me.


Dan

-- 
Daniel Nordlund
Bothell, WA  USA


From clint at ecy.wa.gov  Fri Oct 30 20:30:22 2015
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 30 Oct 2015 12:30:22 -0700 (PDT)
Subject: [R] how to work with time of day (independent of date)
In-Reply-To: <CAF8bMcZ5Af7B1d98K90j49xMxPSMpEs1vfaxcCE-KsuuwkwWyQ@mail.gmail.com>
References: <5633AA7D.307@frontier.com>
	<CAF8bMcZ5Af7B1d98K90j49xMxPSMpEs1vfaxcCE-KsuuwkwWyQ@mail.gmail.com>
Message-ID: <alpine.LRH.2.20.1510301224590.5420@aeolus.ecy.wa.gov>

Bill,

Your final words, "changes in spring and fall" reminds me of a problem 
I have yet to solve.  Most of my data is logged in standard time (no 
daylight times) but often I see the note "daylight time encountered 
switching to UTC" even when I've specified "tz="PST".

I hope I've been missing something simple--any suggestions?

TIA

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 30 Oct 2015, William Dunlap wrote:

> You can use difftime objects to get the amount of time since the start of
> the current day.  E.g.,
>  > dateTime <- as.POSIXlt( c("2015-10-29 00:50:00",
>  + "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
>  + "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
>  + "2015-10-31 10:30:00"))
>  > date <- trunc(dateTime, units="days")
>  > sinceMidnight <- difftime(dateTime, date, units="mins")
>  > sinceMidnight
>  Time differences in mins
>  [1]   50  570 1270   50  570 1270   50  630
>
> I use difftime(x, y, units=) instead of the similar x-y because the latter
> chooses
> the units based on how far apart x and y are, while the former gives me
> consistent
> units:
>  > dateTime[1] - date[1]
>  Time difference of 50 mins
>  > as.numeric(.Last.value)
>  [1] 50
>  > dateTime[5:6] - date[5:6]
>  Time differences in hours
>  [1]  9.50000 21.16667
>  > as.numeric(.Last.value)
>  [1]  9.50000 21.16667
>
> Depending on what you are using this for, you might want to compute time
> since 3am
> of the current day so you don't get discontinuities for most times when the
> time
> changes in spring and fall.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Fri, Oct 30, 2015 at 10:35 AM, Daniel Nordlund <djnordlund at frontier.com>
> wrote:
>
>> I have a data frame with date/times represented as charaacter strings and
>> and a value at that date/time.  I want to get the mean value for each time
>> of day, across days, and then plot time of day on the x-axis and means on
>> the y-axis.  R doesn't appear to have a built-in time of day time type
>> (independent of a date), unless I have missed something. What is the best
>> way to create a time variable so that I can aggregate and plot by time of
>> day, with time labelled in HH:MM format.  My current approach is to convert
>> all date/times to the same date.  I can then manage the rest of what I want
>> with ggplot2.  But I am  wondering if there is an easier/better way to do
>> deal with time of day.
>>
>> Here is a sample data frame.
>>
>> df <- structure(list(date = structure(1:8, .Label = c("2015-10-29
>> 00:50:00",
>> "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
>> "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
>> "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
>> 80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"), row.names =
>> c(NA,
>> -8L), class = "data.frame")
>>
>>
>> Any suggestions appreciated.
>>
>> Dan
>>
>> --
>> Daniel Nordlund
>> Bothell, WA  USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From wdunlap at tibco.com  Fri Oct 30 20:57:05 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 30 Oct 2015 12:57:05 -0700
Subject: [R] how to work with time of day (independent of date)
In-Reply-To: <alpine.LRH.2.20.1510301224590.5420@aeolus.ecy.wa.gov>
References: <5633AA7D.307@frontier.com>
	<CAF8bMcZ5Af7B1d98K90j49xMxPSMpEs1vfaxcCE-KsuuwkwWyQ@mail.gmail.com>
	<alpine.LRH.2.20.1510301224590.5420@aeolus.ecy.wa.gov>
Message-ID: <CAF8bMcZ0n7TbCyxUzig2A3518cwAbLOEnb_Vgg1inn1eXu0GXQ@mail.gmail.com>

I get confused by this also, but I believe your time zone is US/Pacific,
which
specifies both the offset from UTC and the dates on which we switch between
'standard' (winter) and 'daylight savings' (summer).  I think you would have
to create a new time zone entry that is always UTC+8 hours, or whatever,
if you want to use standard time at all times.

I usually lie and use tz="UTC" when using data in local standard time (e.g.,
tide tables in the US).


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Oct 30, 2015 at 12:30 PM, Clint Bowman <clint at ecy.wa.gov> wrote:

> Bill,
>
> Your final words, "changes in spring and fall" reminds me of a problem I
> have yet to solve.  Most of my data is logged in standard time (no daylight
> times) but often I see the note "daylight time encountered switching to
> UTC" even when I've specified "tz="PST".
>
> I hope I've been missing something simple--any suggestions?
>
> TIA
>
> Clint
>
> Clint Bowman                    INTERNET:       clint at ecy.wa.gov
> Air Quality Modeler             INTERNET:       clint at math.utah.edu
> Department of Ecology           VOICE:          (360) 407-6815
> PO Box 47600                    FAX:            (360) 407-7534
> Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
> On Fri, 30 Oct 2015, William Dunlap wrote:
>
> You can use difftime objects to get the amount of time since the start of
>> the current day.  E.g.,
>>  > dateTime <- as.POSIXlt( c("2015-10-29 00:50:00",
>>  + "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
>>  + "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
>>  + "2015-10-31 10:30:00"))
>>  > date <- trunc(dateTime, units="days")
>>  > sinceMidnight <- difftime(dateTime, date, units="mins")
>>  > sinceMidnight
>>  Time differences in mins
>>  [1]   50  570 1270   50  570 1270   50  630
>>
>> I use difftime(x, y, units=) instead of the similar x-y because the latter
>> chooses
>> the units based on how far apart x and y are, while the former gives me
>> consistent
>> units:
>>  > dateTime[1] - date[1]
>>  Time difference of 50 mins
>>  > as.numeric(.Last.value)
>>  [1] 50
>>  > dateTime[5:6] - date[5:6]
>>  Time differences in hours
>>  [1]  9.50000 21.16667
>>  > as.numeric(.Last.value)
>>  [1]  9.50000 21.16667
>>
>> Depending on what you are using this for, you might want to compute time
>> since 3am
>> of the current day so you don't get discontinuities for most times when
>> the
>> time
>> changes in spring and fall.
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Fri, Oct 30, 2015 at 10:35 AM, Daniel Nordlund <
>> djnordlund at frontier.com>
>> wrote:
>>
>> I have a data frame with date/times represented as charaacter strings and
>>> and a value at that date/time.  I want to get the mean value for each
>>> time
>>> of day, across days, and then plot time of day on the x-axis and means on
>>> the y-axis.  R doesn't appear to have a built-in time of day time type
>>> (independent of a date), unless I have missed something. What is the best
>>> way to create a time variable so that I can aggregate and plot by time of
>>> day, with time labelled in HH:MM format.  My current approach is to
>>> convert
>>> all date/times to the same date.  I can then manage the rest of what I
>>> want
>>> with ggplot2.  But I am  wondering if there is an easier/better way to do
>>> deal with time of day.
>>>
>>> Here is a sample data frame.
>>>
>>> df <- structure(list(date = structure(1:8, .Label = c("2015-10-29
>>> 00:50:00",
>>> "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
>>> "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
>>> "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
>>> 80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"), row.names =
>>> c(NA,
>>> -8L), class = "data.frame")
>>>
>>>
>>> Any suggestions appreciated.
>>>
>>> Dan
>>>
>>> --
>>> Daniel Nordlund
>>> Bothell, WA  USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 30 21:19:21 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 30 Oct 2015 13:19:21 -0700
Subject: [R] how to work with time of day (independent of date)
In-Reply-To: <alpine.LRH.2.20.1510301224590.5420@aeolus.ecy.wa.gov>
References: <5633AA7D.307@frontier.com>
	<CAF8bMcZ5Af7B1d98K90j49xMxPSMpEs1vfaxcCE-KsuuwkwWyQ@mail.gmail.com>
	<alpine.LRH.2.20.1510301224590.5420@aeolus.ecy.wa.gov>
Message-ID: <254DC72C-FEDE-4173-BAE7-6F1EB27B435A@dcn.davis.CA.us>

Sys.setenv( TZ="Etc/GMT+8" )

executed before converting to POSIXct works for me, though using that string with the tz parameter also works. You should read ?Sys.timezone. For windows, look at the files in C:\Program Files\R\R-3.2.2\share\zoneinfo and note that PST is not defined though PST8PDT is.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 30, 2015 12:30:22 PM PDT, Clint Bowman <clint at ecy.wa.gov> wrote:
>Bill,
>
>Your final words, "changes in spring and fall" reminds me of a problem 
>I have yet to solve.  Most of my data is logged in standard time (no 
>daylight times) but often I see the note "daylight time encountered 
>switching to UTC" even when I've specified "tz="PST".
>
>I hope I've been missing something simple--any suggestions?
>
>TIA
>
>Clint
>
>Clint Bowman			INTERNET:	clint at ecy.wa.gov
>Air Quality Modeler		INTERNET:	clint at math.utah.edu
>Department of Ecology		VOICE:		(360) 407-6815
>PO Box 47600			FAX:		(360) 407-7534
>Olympia, WA 98504-7600
>
>         USPS:           PO Box 47600, Olympia, WA 98504-7600
>         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274
>
>On Fri, 30 Oct 2015, William Dunlap wrote:
>
>> You can use difftime objects to get the amount of time since the
>start of
>> the current day.  E.g.,
>>  > dateTime <- as.POSIXlt( c("2015-10-29 00:50:00",
>>  + "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30
>00:50:00",
>>  + "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31
>00:50:00",
>>  + "2015-10-31 10:30:00"))
>>  > date <- trunc(dateTime, units="days")
>>  > sinceMidnight <- difftime(dateTime, date, units="mins")
>>  > sinceMidnight
>>  Time differences in mins
>>  [1]   50  570 1270   50  570 1270   50  630
>>
>> I use difftime(x, y, units=) instead of the similar x-y because the
>latter
>> chooses
>> the units based on how far apart x and y are, while the former gives
>me
>> consistent
>> units:
>>  > dateTime[1] - date[1]
>>  Time difference of 50 mins
>>  > as.numeric(.Last.value)
>>  [1] 50
>>  > dateTime[5:6] - date[5:6]
>>  Time differences in hours
>>  [1]  9.50000 21.16667
>>  > as.numeric(.Last.value)
>>  [1]  9.50000 21.16667
>>
>> Depending on what you are using this for, you might want to compute
>time
>> since 3am
>> of the current day so you don't get discontinuities for most times
>when the
>> time
>> changes in spring and fall.
>>
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Fri, Oct 30, 2015 at 10:35 AM, Daniel Nordlund
><djnordlund at frontier.com>
>> wrote:
>>
>>> I have a data frame with date/times represented as charaacter
>strings and
>>> and a value at that date/time.  I want to get the mean value for
>each time
>>> of day, across days, and then plot time of day on the x-axis and
>means on
>>> the y-axis.  R doesn't appear to have a built-in time of day time
>type
>>> (independent of a date), unless I have missed something. What is the
>best
>>> way to create a time variable so that I can aggregate and plot by
>time of
>>> day, with time labelled in HH:MM format.  My current approach is to
>convert
>>> all date/times to the same date.  I can then manage the rest of what
>I want
>>> with ggplot2.  But I am  wondering if there is an easier/better way
>to do
>>> deal with time of day.
>>>
>>> Here is a sample data frame.
>>>
>>> df <- structure(list(date = structure(1:8, .Label = c("2015-10-29
>>> 00:50:00",
>>> "2015-10-29 09:30:00", "2015-10-29 21:10:00", "2015-10-30 00:50:00",
>>> "2015-10-30 09:30:00", "2015-10-30 21:10:00", "2015-10-31 00:50:00",
>>> "2015-10-31 10:30:00"), class = "factor"), value = c(88L, 17L,
>>> 80L, 28L, 23L, 39L, 82L, 79L)), .Names = c("date", "value"),
>row.names =
>>> c(NA,
>>> -8L), class = "data.frame")
>>>
>>>
>>> Any suggestions appreciated.
>>>
>>> Dan
>>>
>>> --
>>> Daniel Nordlund
>>> Bothell, WA  USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Fri Oct 30 21:43:23 2015
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 30 Oct 2015 13:43:23 -0700 (PDT)
Subject: [R] ggplot2: Controlling width of line
In-Reply-To: <CAEQKoCE_Xqj74wfO+w9hDSwea5zjL3Z8DYYy-XKfspKsYwgY6g@mail.gmail.com>
References: <CAEQKoCE_Xqj74wfO+w9hDSwea5zjL3Z8DYYy-XKfspKsYwgY6g@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1510301341330.61002@pedal.dcn.davis.ca.us>

Not sure why you are making this so complicated. In what way is the 
following not meeting your expectations?

ggplot( data=matz
       , aes( x = X1
            , y = value
            , col=X2
            , lty=X2
            , shape=X2
            , size=mylwd
            )
       ) +
    geom_line() +
    geom_point( size = 3 ) +
    scale_linetype_manual( values = ltyvect ) +
    scale_color_manual( values = colvect ) +
    scale_size_continuous( range = c( 0.1, 2 ) ) +
    theme( legend.title = element_blank() )


On Fri, 30 Oct 2015, Brian Smith wrote:

> Hi,
>
> I was trying to increase the size of certain lines in my plot (samples 'B'
> and 'D' in example below). However, when I try to modify the line size, I
> seem to screw up the linetypes. Also, is there a way to reflect the line
> size in the legend?
>
> Here is some sample code for illustration:
>
> library(reshape)
> matx <- matrix(sample(1:1000),4,5)
> colnames(matx) <-  LETTERS[1:5]
> rownames(matx) <- 1:4
>
> subset1 <- c('B','D')
>
> ltyvect <- c("solid","longdash","longdash","solid","solid")
> colvect <- c("red","black","orange","blue","lightblue")
> lwdvect <- rep(1,ncol(matx))
>
> ## For subset of samples, increase line width size
> fmakelwd <- function(set1,subset1,vals1,val2=2){
>    idx <- set1 %in% subset1
>    vals1[idx] <- val2
>    return(vals1)
> }
>
> maty <- melt(matx)
> set1 <- maty$X2
> vals1 <- rep(1,length(set1))
>
> mylwd <- fmakelwd(set1,subset1,vals1,val2=1.5)
> matz <- data.frame(maty,mylwd)
>
> ##### code without trying to modify line size
>
> p <- ggplot(data=matz,aes(x=X1, y = value,col=X2,lty=X2,shape=X2))
> p <- p + geom_line(aes(group = X2)) + geom_point(aes(shape =
> factor(X2)),size=3) +
>    scale_linetype_manual(values = ltyvect) +
>    scale_color_manual(values = colvect) +
>    theme(legend.title = element_blank())
> p
>
>
> #####  modifying line size
>
> p <- ggplot(data=matz,aes(x=X1, y =
> value,col=X2,lty=X2,shape=X2,size=mylwd))
> p <- p + geom_line(aes(group = X2,size=mylwd)) + geom_point(aes(shape =
> factor(X2)),size=3) +
>    scale_linetype_manual(values = ltyvect) +
>    scale_color_manual(values = colvect) +
>    scale_size(range=c(0.1, 2), guide=FALSE) +
>    theme(legend.title = element_blank())
> p
>
>
> #################
>
>
> thanks!!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r.turner at auckland.ac.nz  Fri Oct 30 23:00:47 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 31 Oct 2015 11:00:47 +1300
Subject: [R] Nested effects (was: "no subject")
In-Reply-To: <08471B2D53C89E47A3391EE6C00B314C75EE6BC2@UCMAILA7.ad.uc.edu>
References: <08471B2D53C89E47A3391EE6C00B314C75EE6BC2@UCMAILA7.ad.uc.edu>
Message-ID: <5633E88F.1090502@auckland.ac.nz>

On 31/10/15 03:32, Wagenaar, Daniel (wagenadl) wrote:
> Dear R users:
>
> All textbook references that I consult say that in a nested ANOVA
> (e.g., A/B), the F statistic for factor A should be calculated as F_A =
> MS_A / MS_(B within A). But when I run this simple example:
>
> set.seed(1)
> A = factor(rep(1:3, each=4))
> B = factor(rep(1:2, 3, each=2))
> Y = rnorm(12)
> anova(lm(Y ~ A/B))
>
> I get this result:
>

> Analysis of Variance Table
>
> Response: Y Df Sum Sq Mean Sq F value Pr(>F) A 2 0.4735 0.23675
> 0.2845 0.7620 A:B 3 1.7635 0.58783 0.7064 0.5823 Residuals 6 4.9931
> 0.83218
>
> Evidently, R calculates the F value for A as MS_A / MS_Residuals.
> While it is straightforward enough to calculate what I think is the
> correct result from the table, I am surprised that R doesn't give me
> that answer directly. Does anybody know if R's behavior is intentional,
> and if so, why? And, perhaps most importantly, how to get the "textbook"
> result in the most straightforward way? (I'd like to be able to give me
> students a simple procedure...)

The formula that you specify is based upon factor "B" being a *random* 
effect.  The lm() function handles *fixed* effects only, and thus treats 
"B" as a fixed effect --- whether this makes any sense or not is another 
story.  (IMHO only random effects make sense as nested effects.)

Kevin Wright has already told you how to get what you want/need using 
aov() and the Error() function.  This works only for balanced designs, 
essentially.  For more complicated designs you will need to dive into 
the nlme and lme4 packages.  For which you will need *lots* of patience, 
determination, and luck! :-)

cheers,

Rolf Turner

P. S. Please provide a useful *subject line* in your posts to this list.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From valkremk at gmail.com  Sat Oct 31 02:15:11 2015
From: valkremk at gmail.com (Val)
Date: Fri, 30 Oct 2015 20:15:11 -0500
Subject: [R] If else
Message-ID: <CAJOiR6aZ_rV2An=qzhv32wzZGfJ2g8zms6Zxbz730xzKyrtt2A@mail.gmail.com>

Hi all,
Iam trying to change character  to numeric but have probelm

mydata <- read.table(header=TRUE, text=', sep=" "
     id  sex
      1  NA
      2  NA
      3  M
      4  F
      5  M
      6  F
      7  F
       ')

if sex is missing then sex=0;
if sex is"M" then sex=1;
if sex is"F" then sex=2;

Any help please ?

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Sat Oct 31 02:28:19 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 30 Oct 2015 21:28:19 -0400
Subject: [R] If else
In-Reply-To: <CAJOiR6aZ_rV2An=qzhv32wzZGfJ2g8zms6Zxbz730xzKyrtt2A@mail.gmail.com>
References: <CAJOiR6aZ_rV2An=qzhv32wzZGfJ2g8zms6Zxbz730xzKyrtt2A@mail.gmail.com>
Message-ID: <CA+vqiLH4r-M3cXkkrs3irshS_1KB+6JicY+oR0KkHGGdG9JK0g@mail.gmail.com>

Using numeric for missing sounds like asking for trouble. But if you
must, something like

mydata$confusingWillCauseProblemsLater <-
  ifelse(
    is.na(mydata$sex),
    0,
    as.numeric(factor(mydata$sex,
                      levels = c("M", "F"))))

should do it.

Best,
Ista

On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
> Hi all,
> Iam trying to change character  to numeric but have probelm
>
> mydata <- read.table(header=TRUE, text=', sep=" "
>      id  sex
>       1  NA
>       2  NA
>       3  M
>       4  F
>       5  M
>       6  F
>       7  F
>        ')
>
> if sex is missing then sex=0;
> if sex is"M" then sex=1;
> if sex is"F" then sex=2;
>
> Any help please ?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Sat Oct 31 02:40:03 2015
From: valkremk at gmail.com (Val)
Date: Fri, 30 Oct 2015 20:40:03 -0500
Subject: [R] If else
In-Reply-To: <CA+vqiLH4r-M3cXkkrs3irshS_1KB+6JicY+oR0KkHGGdG9JK0g@mail.gmail.com>
References: <CAJOiR6aZ_rV2An=qzhv32wzZGfJ2g8zms6Zxbz730xzKyrtt2A@mail.gmail.com>
	<CA+vqiLH4r-M3cXkkrs3irshS_1KB+6JicY+oR0KkHGGdG9JK0g@mail.gmail.com>
Message-ID: <CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>

I am trying to change the mydata$sex  from character to numeric
I want teh out put like
   id  sex
      1  NA   0
      2  NA   0
      3  M     1
      4  F     2
      5  M    1
      6  F     2
      7  F    2

mydata$sex1 <- 0
if(mydata$sex =="M " ){
  mydata$sex1<-1
} else {
  mydata$sex1<-2
}

mydata$sex1

Warning message:In if (mydata$sex == "M ") { :
  the condition has length > 1 and only the first element will be
used> mydata$sex1[1] 2 2 2 2 2 2 2 2

>


On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com> wrote:

> Using numeric for missing sounds like asking for trouble. But if you
> must, something like
>
> mydata$confusingWillCauseProblemsLater <-
>   ifelse(
>     is.na(mydata$sex),
>     0,
>     as.numeric(factor(mydata$sex,
>                       levels = c("M", "F"))))
>
> should do it.
>
> Best,
> Ista
>
> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
> > Hi all,
> > Iam trying to change character  to numeric but have probelm
> >
> > mydata <- read.table(header=TRUE, text=', sep=" "
> >      id  sex
> >       1  NA
> >       2  NA
> >       3  M
> >       4  F
> >       5  M
> >       6  F
> >       7  F
> >        ')
> >
> > if sex is missing then sex=0;
> > if sex is"M" then sex=1;
> > if sex is"F" then sex=2;
> >
> > Any help please ?
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sat Oct 31 03:40:55 2015
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sat, 31 Oct 2015 15:40:55 +1300
Subject: [R] [FORGED]  If else
In-Reply-To: <CAJOiR6aZ_rV2An=qzhv32wzZGfJ2g8zms6Zxbz730xzKyrtt2A@mail.gmail.com>
References: <CAJOiR6aZ_rV2An=qzhv32wzZGfJ2g8zms6Zxbz730xzKyrtt2A@mail.gmail.com>
Message-ID: <56342A37.2020501@auckland.ac.nz>

On 31/10/15 14:15, Val wrote:
> Hi all,
> Iam trying to change character  to numeric but have probelm
>
> mydata <- read.table(header=TRUE, text=', sep=" "
>       id  sex
>        1  NA
>        2  NA
>        3  M
>        4  F
>        5  M
>        6  F
>        7  F
>         ')
>
> if sex is missing then sex=0;
> if sex is"M" then sex=1;
> if sex is"F" then sex=2;
>
> Any help please ?

sex <- c(NA,NA,"M","F","M","F","F")

# 1.
match(sex,c(NA,"M","F"))-1

# 2.
as.numeric(factor(sex,exclude=NULL,levels=c(NA,"M","F")))-1

cheers,

Rolf Turner

P. S. As others have told you, converting character to numeric is highly 
ill-advised.

R. T.

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From wagenadl at uc.edu  Fri Oct 30 18:46:17 2015
From: wagenadl at uc.edu (Daniel Wagenaar)
Date: Fri, 30 Oct 2015 13:46:17 -0400
Subject: [R] Nested ANOVA yields surprising results
Message-ID: <5633ACE9.3060107@uc.edu>

Dear R users:

All textbook references that I consult say that in a nested ANOVA (e.g., 
A/B), the F statistic for factor A should be calculated as

F_A = MS_A / MS_(B within A).

But when I run this simple example:

set.seed(1)
A <- factor(rep(1:3, each=4))
B <- factor(rep(1:2, 3, each=2))
Y <- rnorm(12)
anova(lm(Y ~ A/B))

I get this result:

   Analysis of Variance Table

   Response: Y
             Df Sum Sq Mean Sq F value Pr(>F)
   A          2 0.4735 0.23675  0.2845 0.7620
   A:B        3 1.7635 0.58783  0.7064 0.5823
   Residuals  6 4.9931 0.83218

Evidently, R calculates the F value for A as MS_A / MS_Residuals.

While it is straightforward enough to calculate what I think is the 
correct result from the table, I am surprised that R doesn't give me 
that answer directly. Does anybody know if R's behavior is intentional, 
and if so, why? Equally importantly, is there a straightforward way to 
make R give the answer I expect, that is:

      Df Sum Sq Mean Sq F value Pr(>F)
   A   2 0.4735 0.23675  0.4028 0.6999

The students in my statistics class would be much happier if they didn't 
have to type things like

   a <- anova(...)
   F <- a$`Sum Sq`[1] / a$`Sum Sq`[2]
   P <- 1 - pf(F, a$Df[1], a$Df[2])

(They are not R programmers (yet).) And to be honest, I would find it 
easier to read those results directly from the table as well.

Thanks,

Daniel Wagenaar

-- 
Daniel A. Wagenaar, PhD
Assistant Professor
Department of Biological Sciences
McMicken College of Arts and Sciences
University of Cincinnati
Cincinnati, OH 45221
Phone: +1 (513) 556-9757
Email: daniel.wagenaar at uc.edu
Web: http://www.danielwagenaar.net


From javajimburke at gmail.com  Fri Oct 30 21:59:53 2015
From: javajimburke at gmail.com (Jim Burke)
Date: Fri, 30 Oct 2015 15:59:53 -0500
Subject: [R] A simple crop/clip of a png map
Message-ID: <CALkjiFTEe5U6s+y_L=TOZqjPTZKg_NscH0kLoM-uP+vmT9hd-g@mail.gmail.com>

I have a 5.76" x 5.75" png image which I would like to crop to some inch
size. To use as a report header (after placing some title text on it).

So how to use R to crop a nice rectangle from my image?

Thanks for your thoughts
Jim Burke

	[[alternative HTML version deleted]]


From tmrsg11 at gmail.com  Sat Oct 31 05:10:31 2015
From: tmrsg11 at gmail.com (C W)
Date: Sat, 31 Oct 2015 00:10:31 -0400
Subject: [R] How to add legend to 2 different data frame overplot?
Message-ID: <CAE2FW2mSP7US50fsRqw0p823m4wXDxip9c37D8GE8MpMDMv9hQ@mail.gmail.com>

Hi,

I am trying to do add a legend to an overplot, something like this:

ggplot() +
    geom_density(data = df1, aes(x = x), fill = "green", show_guide =
FALSE) +
    geom_area(data = df2, aes(x = x), fill = "yellow", show_guide = FALSE) +
    scale_color_manual(values = c("green", "yellow"), labels = c('df1',
'df2'))

But the legend doesn't actually show up when I plot it.  How should I fix
this?

	[[alternative HTML version deleted]]


From gregcoats at me.com  Sat Oct 31 04:07:25 2015
From: gregcoats at me.com (Gregory Coats)
Date: Fri, 30 Oct 2015 23:07:25 -0400
Subject: [R] How to direct R to read commands from a text file
Message-ID: <96CAD5E9-74DE-4085-95DC-CC4078B87545@me.com>

All of the R commands that I want to issue are in a text file that concludes with the R command quit (save = ?yes?), and is called R_commands.txt. I can start R, and then manually issue
source (?R_commands.txt?).
But I would prefer to issue, from the bash command line, a one line command, directing R to start, execute all of the R commands in R_commands.txt, and then quit. How do I do that?
Greg Coats

From boris.steipe at utoronto.ca  Sat Oct 31 05:46:45 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 31 Oct 2015 00:46:45 -0400
Subject: [R] How to direct R to read commands from a text file
In-Reply-To: <96CAD5E9-74DE-4085-95DC-CC4078B87545@me.com>
References: <96CAD5E9-74DE-4085-95DC-CC4078B87545@me.com>
Message-ID: <46CF803C-C25B-4AFC-8AE6-F46032620F0E@utoronto.ca>

I should think this thread contains all you need:
   http://stackoverflow.com/questions/18306362/run-r-script-from-command-line


B.


On Oct 30, 2015, at 11:07 PM, Gregory Coats <gregcoats at me.com> wrote:

> All of the R commands that I want to issue are in a text file that concludes with the R command quit (save = ?yes?), and is called R_commands.txt. I can start R, and then manually issue
> source (?R_commands.txt?).
> But I would prefer to issue, from the bash command line, a one line command, directing R to start, execute all of the R commands in R_commands.txt, and then quit. How do I do that?
> Greg Coats
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Sat Oct 31 08:07:33 2015
From: drjimlemon at gmail.com (Jim Lemon)
Date: Sat, 31 Oct 2015 18:07:33 +1100
Subject: [R] How to add legend to 2 different data frame overplot?
In-Reply-To: <CAE2FW2mSP7US50fsRqw0p823m4wXDxip9c37D8GE8MpMDMv9hQ@mail.gmail.com>
References: <CAE2FW2mSP7US50fsRqw0p823m4wXDxip9c37D8GE8MpMDMv9hQ@mail.gmail.com>
Message-ID: <CA+8X3fXooaqaq7DcMa0fas_dTbkMUct_FjAv6-v1D4wmJXwo+Q@mail.gmail.com>

Hi C W,
I would guess you are trying to use the base graphics "legend" function.
Have you tried one of the scale_* functions in ggplot?

Jim


On Sat, Oct 31, 2015 at 3:10 PM, C W <tmrsg11 at gmail.com> wrote:

> Hi,
>
> I am trying to do add a legend to an overplot, something like this:
>
> ggplot() +
>     geom_density(data = df1, aes(x = x), fill = "green", show_guide =
> FALSE) +
>     geom_area(data = df2, aes(x = x), fill = "yellow", show_guide = FALSE)
> +
>     scale_color_manual(values = c("green", "yellow"), labels = c('df1',
> 'df2'))
>
> But the legend doesn't actually show up when I plot it.  How should I fix
> this?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Oct 31 08:19:42 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 31 Oct 2015 00:19:42 -0700
Subject: [R] How to add legend to 2 different data frame overplot?
In-Reply-To: <CAE2FW2mSP7US50fsRqw0p823m4wXDxip9c37D8GE8MpMDMv9hQ@mail.gmail.com>
References: <CAE2FW2mSP7US50fsRqw0p823m4wXDxip9c37D8GE8MpMDMv9hQ@mail.gmail.com>
Message-ID: <9C3EB16F-412D-4C7A-A760-4D8029616CE6@dcn.davis.CA.us>

Remove show_guide = FALSE?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 30, 2015 9:10:31 PM PDT, C W <tmrsg11 at gmail.com> wrote:
>Hi,
>
>I am trying to do add a legend to an overplot, something like this:
>
>ggplot() +
>    geom_density(data = df1, aes(x = x), fill = "green", show_guide =
>FALSE) +
>geom_area(data = df2, aes(x = x), fill = "yellow", show_guide = FALSE)
>+
>    scale_color_manual(values = c("green", "yellow"), labels = c('df1',
>'df2'))
>
>But the legend doesn't actually show up when I plot it.  How should I
>fix
>this?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Oct 31 11:59:40 2015
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 31 Oct 2015 02:59:40 -0800
Subject: [R] If else
In-Reply-To: <CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
Message-ID: <19F51FAADFD.00000132jrkrideau@inbox.com>

In line.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: valkremk at gmail.com
> Sent: Fri, 30 Oct 2015 20:40:03 -0500
> To: istazahn at gmail.com
> Subject: Re: [R] If else
> 
> I am trying to change the mydata$sex  from character to numeric

Why? 
 As Ista (mydata$confusingWillCauseProblemsLater) has pointed out this is a very unusual thing to do in R. 

Is there a very specific reason for doing this in your analysis.  Otherwise it may better to leave the coding as NA. Some of the data mungers here may be able to suggest which is the best strategy in R. 

R is 'weird' compared to more mundane stats packages such as SAS or SPSS and common techniques that one would use with them often are not appropriate in R.




> I want teh out put like
>    id  sex
>       1  NA   0
>       2  NA   0
>       3  M     1
>       4  F     2
>       5  M    1
>       6  F     2
>       7  F    2
> 
> mydata$sex1 <- 0
> if(mydata$sex =="M " ){
>   mydata$sex1<-1
> } else {
>   mydata$sex1<-2
> }
> 
> mydata$sex1
> 
> Warning message:In if (mydata$sex == "M ") { :
>   the condition has length > 1 and only the first element will be
> used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> 
>> 
> 
> 
> On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com> wrote:
> 
>> Using numeric for missing sounds like asking for trouble. But if you
>> must, something like
>> 
>> mydata$confusingWillCauseProblemsLater <-
>>   ifelse(
>>     is.na(mydata$sex),
>>     0,
>>     as.numeric(factor(mydata$sex,
>>                       levels = c("M", "F"))))
>> 
>> should do it.
>> 
>> Best,
>> Ista
>> 
>> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
>>> Hi all,
>>> Iam trying to change character  to numeric but have probelm
>>> 
>>> mydata <- read.table(header=TRUE, text=', sep=" "
>>>      id  sex
>>>       1  NA
>>>       2  NA
>>>       3  M
>>>       4  F
>>>       5  M
>>>       6  F
>>>       7  F
>>>        ')
>>> 
>>> if sex is missing then sex=0;
>>> if sex is"M" then sex=1;
>>> if sex is"F" then sex=2;
>>> 
>>> Any help please ?
>>> 
>>>         [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From pdalgd at gmail.com  Sat Oct 31 14:11:15 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 31 Oct 2015 14:11:15 +0100
Subject: [R] Nested ANOVA yields surprising results
In-Reply-To: <5633ACE9.3060107@uc.edu>
References: <5633ACE9.3060107@uc.edu>
Message-ID: <9C9C7DCB-F868-4177-AA2C-B5A11D5BAB04@gmail.com>


> On 30 Oct 2015, at 18:46 , Daniel Wagenaar <wagenadl at uc.edu> wrote:
> 
> Dear R users:
> 
> All textbook references that I consult say that in a nested ANOVA (e.g., A/B), the F statistic for factor A should be calculated as
> 
> F_A = MS_A / MS_(B within A).
> 

That would depend on which hypothesis you test in which model. If a reference tells you that you "should" do something without specifying the model, then you "should" look at a different reference.

In general, having anything other than the residual MS in the denominator indicates that you think it represents an additional source of random variation. I don't think that is invariably the case in nested designs (and, by the way, notice that "nested" is used differently by different books and software).

If you don't say otherwise, R assumes that there is only one source of random variation the model - a single error term if you like - and that all other terms represent systematic variations. In this mode of thinking, an A:B term represents an effect of B within A (additive and interaction effects combined), and you can test for its presence by comparing MS_A:B to MS_res. In its absence, you might choose to reduce the model and next look for an effect of A; purists would do this by comparing MS_A to the new MS_res obtained by pooling MS_A:B and MS_res, but lazy statisticians/programmers have found it more convenient to stick with the original MS_res denominator throughout (to get the pooling done, just fit the reduced model). 

If you want A:B to be a random term, then you need to say so, e.g. using

> summary(aov(Y~A+Error(A:B-1)))

Error: A:B
            Df Sum Sq Mean Sq F value Pr(>F)
A            2 0.4735  0.2367   0.403    0.7
Residuals    3 1.7635  0.5878               

Error: Within
          Df Sum Sq Mean Sq F value Pr(>F)
Residuals  6  4.993  0.8322               

(the -1 in the Error() term prevents an error message, which as far as I can tell is spurious).

Notice that you need aov() for this; lm() doesn't do Error() terms. This _only_ works in balanced designs.

-pd

> But when I run this simple example:
> 
> set.seed(1)
> A <- factor(rep(1:3, each=4))
> B <- factor(rep(1:2, 3, each=2))
> Y <- rnorm(12)
> anova(lm(Y ~ A/B))
> 
> I get this result:
> 
>  Analysis of Variance Table
> 
>  Response: Y
>            Df Sum Sq Mean Sq F value Pr(>F)
>  A          2 0.4735 0.23675  0.2845 0.7620
>  A:B        3 1.7635 0.58783  0.7064 0.5823
>  Residuals  6 4.9931 0.83218
> 
> Evidently, R calculates the F value for A as MS_A / MS_Residuals.
> 
> While it is straightforward enough to calculate what I think is the correct result from the table, I am surprised that R doesn't give me that answer directly. Does anybody know if R's behavior is intentional, and if so, why? Equally importantly, is there a straightforward way to make R give the answer I expect, that is:
> 
>     Df Sum Sq Mean Sq F value Pr(>F)
>  A   2 0.4735 0.23675  0.4028 0.6999
> 
> The students in my statistics class would be much happier if they didn't have to type things like
> 
>  a <- anova(...)
>  F <- a$`Sum Sq`[1] / a$`Sum Sq`[2]
>  P <- 1 - pf(F, a$Df[1], a$Df[2])
> 
> (They are not R programmers (yet).) And to be honest, I would find it easier to read those results directly from the table as well.
> 
> Thanks,
> 
> Daniel Wagenaar
> 
> -- 
> Daniel A. Wagenaar, PhD
> Assistant Professor
> Department of Biological Sciences
> McMicken College of Arts and Sciences
> University of Cincinnati
> Cincinnati, OH 45221
> Phone: +1 (513) 556-9757
> Email: daniel.wagenaar at uc.edu
> Web: http://www.danielwagenaar.net
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From valkremk at gmail.com  Sat Oct 31 16:23:05 2015
From: valkremk at gmail.com (Val)
Date: Sat, 31 Oct 2015 10:23:05 -0500
Subject: [R] If else
In-Reply-To: <19F51FAADFD.00000132jrkrideau@inbox.com>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
Message-ID: <CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>

Hi All,


Yes I need  to change to numeric  because I am preparing a data set  for
further  analysis. The variable to be changed  from character to numeric
(in this case, sex) will be a response variable.  Some records have missing
observation on sex and it is blank.
     id  sex
      1
      2
      3  M
      4  F
      5  M
      6  F
      7  F

I am reading the data like this

mydata <- read.csv(header=TRUE, text=', sep=", ")
     id  sex
      1   NA
      2  NA
      3  M
      4  F
      5  M
      6  F
      7  F

The  data set is huge   (>250,000)


I want the output like this

     id  sex    sex1
      1   NA    0
      2  NA     0
      3  M       1
      4  F       2
      5  M      1
      6  F       2
      7  F       2

Thank you in advance


On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com> wrote:

> In line.
>
> John Kane
> Kingston ON Canada
>
>
> > -----Original Message-----
> > From: valkremk at gmail.com
> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
> > To: istazahn at gmail.com
> > Subject: Re: [R] If else
> >
> > I am trying to change the mydata$sex  from character to numeric
>
> Why?
>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out this is
> a very unusual thing to do in R.
>
> Is there a very specific reason for doing this in your analysis.
> Otherwise it may better to leave the coding as NA. Some of the data mungers
> here may be able to suggest which is the best strategy in R.
>
> R is 'weird' compared to more mundane stats packages such as SAS or SPSS
> and common techniques that one would use with them often are not
> appropriate in R.
>
>
>
>
> > I want teh out put like
> >    id  sex
> >       1  NA   0
> >       2  NA   0
> >       3  M     1
> >       4  F     2
> >       5  M    1
> >       6  F     2
> >       7  F    2
> >
> > mydata$sex1 <- 0
> > if(mydata$sex =="M " ){
> >   mydata$sex1<-1
> > } else {
> >   mydata$sex1<-2
> > }
> >
> > mydata$sex1
> >
> > Warning message:In if (mydata$sex == "M ") { :
> >   the condition has length > 1 and only the first element will be
> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> >
> >>
> >
> >
> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com> wrote:
> >
> >> Using numeric for missing sounds like asking for trouble. But if you
> >> must, something like
> >>
> >> mydata$confusingWillCauseProblemsLater <-
> >>   ifelse(
> >>     is.na(mydata$sex),
> >>     0,
> >>     as.numeric(factor(mydata$sex,
> >>                       levels = c("M", "F"))))
> >>
> >> should do it.
> >>
> >> Best,
> >> Ista
> >>
> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
> >>> Hi all,
> >>> Iam trying to change character  to numeric but have probelm
> >>>
> >>> mydata <- read.table(header=TRUE, text=', sep=" "
> >>>      id  sex
> >>>       1  NA
> >>>       2  NA
> >>>       3  M
> >>>       4  F
> >>>       5  M
> >>>       6  F
> >>>       7  F
> >>>        ')
> >>>
> >>> if sex is missing then sex=0;
> >>> if sex is"M" then sex=1;
> >>> if sex is"F" then sex=2;
> >>>
> >>> Any help please ?
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on
> your desktop!
> Check it out at http://www.inbox.com/marineaquarium
>
>
>

	[[alternative HTML version deleted]]


From jacksonmrodrigues at gmail.com  Sat Oct 31 17:18:38 2015
From: jacksonmrodrigues at gmail.com (Jackson Rodrigues)
Date: Sat, 31 Oct 2015 17:18:38 +0100
Subject: [R] How to calculate the shared area of 2 plots?
Message-ID: <CAPL76w8aDCYUXr=5hBih3RoMxZiUJLYfDBfSj7+OU3baG3wWeA@mail.gmail.com>

Dear all,

I have 2 data sets (A and B) with normal distributions. When I plot them
together, they overlay/share one part of plot.
I want to extract from each A and B that shared area.
Actually I want to sum A+B and then to compare the result with the
individual shared area of A and B to know how much (in %) each one
represents. (Am I clear?)

The folowing codes do not represent exactly my data, however the final
result (plot) is very similar to what I get in the end with my data.
I can provide my original data if necessary.

A<-seq(-4,4,.01)
B<-seq(-4,4,.01)

densities<-dnorm(A, 0,1)
densities2<-dnorm(B, 0,1)

plot(A,densities, type="l", col="red")
lines(B+2,densities2, type="l")

I am very grateful for any support, help, advise  and etc ... :)


best wishes

Jackson
-- 

Jackson M. Rodrigues
Department of Palynology and Climate Dynamics
Albrecht-von-Haller-Institute for Plant Sciences
Georg-August-University G?ttingen
Untere Karspuele 2
37073 G?ttingen/Germany
Tel.:   0049 (0) 176 8186 4994

*"In order to succeed, we must first believe that we can."*
*Nikos Kazantzakis*

	[[alternative HTML version deleted]]


From rharris2727 at hotmail.co.uk  Sat Oct 31 10:59:06 2015
From: rharris2727 at hotmail.co.uk (Richard Harris)
Date: Sat, 31 Oct 2015 09:59:06 +0000
Subject: [R] =?utf-8?q?ASR_tree_with_highlighted_state-changes?=
Message-ID: <DUB407-EAS193E99593616FED244C41D5F32E0@phx.gbl>








Sent from Windows Mail

Hi,




I am looking for possible code (if any code exists) for creating a tree/ graphical representation of ancestral state reconstruction that clearly highlights state-changes or where state changes are estimated? I am using binary for my trait distinctions.




I am very new to r so please be gentle!


Thanks.
	[[alternative HTML version deleted]]


From judsonblake at msn.com  Sat Oct 31 16:52:51 2015
From: judsonblake at msn.com (Judson)
Date: Sat, 31 Oct 2015 11:52:51 -0400
Subject: [R] Vector of symbols?
Message-ID: <COL130-W945E79611B9A6A7AD9CA7EAD2E0@phx.gbl>



Is
there a way to multiply a matrix 

times
a vector of symbols?  

For
instance, could I do this: 

1       
0       0                          a

0        1      
0      times           b

-1       2      
1                          c                

 

which
should result in :  

                                                      a

                                                      b

                                                      c  ?a 
-2*b 
where a, b, and c 

are
as yet not assigned numeric values?  

........................... judson blake


 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Oct 31 17:39:54 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 31 Oct 2015 09:39:54 -0700
Subject: [R] If else
In-Reply-To: <CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
	<CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
Message-ID: <F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>

You haven't actually answered John's question as to the type of analysis you plan to do. It still looks from here like you should be using factor data rather than numeric, but since you are not being clear we cannot give specifics as to how to proceed.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
>Hi All,
>
>
>Yes I need  to change to numeric  because I am preparing a data set 
>for
>further  analysis. The variable to be changed  from character to
>numeric
>(in this case, sex) will be a response variable.  Some records have
>missing
>observation on sex and it is blank.
>     id  sex
>      1
>      2
>      3  M
>      4  F
>      5  M
>      6  F
>      7  F
>
>I am reading the data like this
>
>mydata <- read.csv(header=TRUE, text=', sep=", ")
>     id  sex
>      1   NA
>      2  NA
>      3  M
>      4  F
>      5  M
>      6  F
>      7  F
>
>The  data set is huge   (>250,000)
>
>
>I want the output like this
>
>     id  sex    sex1
>      1   NA    0
>      2  NA     0
>      3  M       1
>      4  F       2
>      5  M      1
>      6  F       2
>      7  F       2
>
>Thank you in advance
>
>
>On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com> wrote:
>
>> In line.
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>> > -----Original Message-----
>> > From: valkremk at gmail.com
>> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
>> > To: istazahn at gmail.com
>> > Subject: Re: [R] If else
>> >
>> > I am trying to change the mydata$sex  from character to numeric
>>
>> Why?
>>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
>this is
>> a very unusual thing to do in R.
>>
>> Is there a very specific reason for doing this in your analysis.
>> Otherwise it may better to leave the coding as NA. Some of the data
>mungers
>> here may be able to suggest which is the best strategy in R.
>>
>> R is 'weird' compared to more mundane stats packages such as SAS or
>SPSS
>> and common techniques that one would use with them often are not
>> appropriate in R.
>>
>>
>>
>>
>> > I want teh out put like
>> >    id  sex
>> >       1  NA   0
>> >       2  NA   0
>> >       3  M     1
>> >       4  F     2
>> >       5  M    1
>> >       6  F     2
>> >       7  F    2
>> >
>> > mydata$sex1 <- 0
>> > if(mydata$sex =="M " ){
>> >   mydata$sex1<-1
>> > } else {
>> >   mydata$sex1<-2
>> > }
>> >
>> > mydata$sex1
>> >
>> > Warning message:In if (mydata$sex == "M ") { :
>> >   the condition has length > 1 and only the first element will be
>> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
>> >
>> >>
>> >
>> >
>> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
>wrote:
>> >
>> >> Using numeric for missing sounds like asking for trouble. But if
>you
>> >> must, something like
>> >>
>> >> mydata$confusingWillCauseProblemsLater <-
>> >>   ifelse(
>> >>     is.na(mydata$sex),
>> >>     0,
>> >>     as.numeric(factor(mydata$sex,
>> >>                       levels = c("M", "F"))))
>> >>
>> >> should do it.
>> >>
>> >> Best,
>> >> Ista
>> >>
>> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
>> >>> Hi all,
>> >>> Iam trying to change character  to numeric but have probelm
>> >>>
>> >>> mydata <- read.table(header=TRUE, text=', sep=" "
>> >>>      id  sex
>> >>>       1  NA
>> >>>       2  NA
>> >>>       3  M
>> >>>       4  F
>> >>>       5  M
>> >>>       6  F
>> >>>       7  F
>> >>>        ')
>> >>>
>> >>> if sex is missing then sex=0;
>> >>> if sex is"M" then sex=1;
>> >>> if sex is"F" then sex=2;
>> >>>
>> >>> Any help please ?
>> >>>
>> >>>         [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ____________________________________________________________
>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
>on
>> your desktop!
>> Check it out at http://www.inbox.com/marineaquarium
>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From valkremk at gmail.com  Sat Oct 31 18:15:33 2015
From: valkremk at gmail.com (Val)
Date: Sat, 31 Oct 2015 12:15:33 -0500
Subject: [R] If else
In-Reply-To: <F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
	<CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
	<F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>
Message-ID: <CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>

Hi Jeff,

I thought I answered. Yes I was not clear about it.  The further analysis
will no  be done by R.  It is another software that will not accept a
character response variable.

Why R is so complicated to do that.  If it is SAS then I can do it on one
statement. .


On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You haven't actually answered John's question as to the type of analysis
> you plan to do. It still looks from here like you should be using factor
> data rather than numeric, but since you are not being clear we cannot give
> specifics as to how to proceed.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
> >Hi All,
> >
> >
> >Yes I need  to change to numeric  because I am preparing a data set
> >for
> >further  analysis. The variable to be changed  from character to
> >numeric
> >(in this case, sex) will be a response variable.  Some records have
> >missing
> >observation on sex and it is blank.
> >     id  sex
> >      1
> >      2
> >      3  M
> >      4  F
> >      5  M
> >      6  F
> >      7  F
> >
> >I am reading the data like this
> >
> >mydata <- read.csv(header=TRUE, text=', sep=", ")
> >     id  sex
> >      1   NA
> >      2  NA
> >      3  M
> >      4  F
> >      5  M
> >      6  F
> >      7  F
> >
> >The  data set is huge   (>250,000)
> >
> >
> >I want the output like this
> >
> >     id  sex    sex1
> >      1   NA    0
> >      2  NA     0
> >      3  M       1
> >      4  F       2
> >      5  M      1
> >      6  F       2
> >      7  F       2
> >
> >Thank you in advance
> >
> >
> >On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com> wrote:
> >
> >> In line.
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >>
> >> > -----Original Message-----
> >> > From: valkremk at gmail.com
> >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
> >> > To: istazahn at gmail.com
> >> > Subject: Re: [R] If else
> >> >
> >> > I am trying to change the mydata$sex  from character to numeric
> >>
> >> Why?
> >>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
> >this is
> >> a very unusual thing to do in R.
> >>
> >> Is there a very specific reason for doing this in your analysis.
> >> Otherwise it may better to leave the coding as NA. Some of the data
> >mungers
> >> here may be able to suggest which is the best strategy in R.
> >>
> >> R is 'weird' compared to more mundane stats packages such as SAS or
> >SPSS
> >> and common techniques that one would use with them often are not
> >> appropriate in R.
> >>
> >>
> >>
> >>
> >> > I want teh out put like
> >> >    id  sex
> >> >       1  NA   0
> >> >       2  NA   0
> >> >       3  M     1
> >> >       4  F     2
> >> >       5  M    1
> >> >       6  F     2
> >> >       7  F    2
> >> >
> >> > mydata$sex1 <- 0
> >> > if(mydata$sex =="M " ){
> >> >   mydata$sex1<-1
> >> > } else {
> >> >   mydata$sex1<-2
> >> > }
> >> >
> >> > mydata$sex1
> >> >
> >> > Warning message:In if (mydata$sex == "M ") { :
> >> >   the condition has length > 1 and only the first element will be
> >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> >> >
> >> >>
> >> >
> >> >
> >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
> >wrote:
> >> >
> >> >> Using numeric for missing sounds like asking for trouble. But if
> >you
> >> >> must, something like
> >> >>
> >> >> mydata$confusingWillCauseProblemsLater <-
> >> >>   ifelse(
> >> >>     is.na(mydata$sex),
> >> >>     0,
> >> >>     as.numeric(factor(mydata$sex,
> >> >>                       levels = c("M", "F"))))
> >> >>
> >> >> should do it.
> >> >>
> >> >> Best,
> >> >> Ista
> >> >>
> >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
> >> >>> Hi all,
> >> >>> Iam trying to change character  to numeric but have probelm
> >> >>>
> >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
> >> >>>      id  sex
> >> >>>       1  NA
> >> >>>       2  NA
> >> >>>       3  M
> >> >>>       4  F
> >> >>>       5  M
> >> >>>       6  F
> >> >>>       7  F
> >> >>>        ')
> >> >>>
> >> >>> if sex is missing then sex=0;
> >> >>> if sex is"M" then sex=1;
> >> >>> if sex is"F" then sex=2;
> >> >>>
> >> >>> Any help please ?
> >> >>>
> >> >>>         [[alternative HTML version deleted]]
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >>> and provide commented, minimal, self-contained, reproducible
> >code.
> >> >>
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ____________________________________________________________
> >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas
> >on
> >> your desktop!
> >> Check it out at http://www.inbox.com/marineaquarium
> >>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Sat Oct 31 18:29:10 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Sat, 31 Oct 2015 18:29:10 +0100
Subject: [R] How to calculate the shared area of 2 plots?
In-Reply-To: <CAPL76w8aDCYUXr=5hBih3RoMxZiUJLYfDBfSj7+OU3baG3wWeA@mail.gmail.com>
References: <CAPL76w8aDCYUXr=5hBih3RoMxZiUJLYfDBfSj7+OU3baG3wWeA@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F2109C9CC@UM-MAIL4112.unimaas.nl>

Something like this?

http://stats.stackexchange.com/questions/12209/percentage-of-overlapping-regions-of-two-normal-distributions

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician | Department of Psychiatry and
Neuropsychology | Maastricht University | P.O. Box 616 (VIJV1) | 6200 MD
Maastricht, The Netherlands | +31 (43) 388-4170 | http://www.wvbauer.com
________________________________________
From: R-help [r-help-bounces at r-project.org] On Behalf Of Jackson Rodrigues [jacksonmrodrigues at gmail.com]
Sent: Saturday, October 31, 2015 5:18 PM
To: r-help at r-project.org
Subject: [R] How to calculate the shared area of 2 plots?

Dear all,

I have 2 data sets (A and B) with normal distributions. When I plot them
together, they overlay/share one part of plot.
I want to extract from each A and B that shared area.
Actually I want to sum A+B and then to compare the result with the
individual shared area of A and B to know how much (in %) each one
represents. (Am I clear?)

The folowing codes do not represent exactly my data, however the final
result (plot) is very similar to what I get in the end with my data.
I can provide my original data if necessary.

A<-seq(-4,4,.01)
B<-seq(-4,4,.01)

densities<-dnorm(A, 0,1)
densities2<-dnorm(B, 0,1)

plot(A,densities, type="l", col="red")
lines(B+2,densities2, type="l")

I am very grateful for any support, help, advise  and etc ... :)


best wishes

Jackson
--

Jackson M. Rodrigues
Department of Palynology and Climate Dynamics
Albrecht-von-Haller-Institute for Plant Sciences
Georg-August-University G?ttingen
Untere Karspuele 2
37073 G?ttingen/Germany
Tel.:   0049 (0) 176 8186 4994

*"In order to succeed, we must first believe that we can."*
*Nikos Kazantzakis*

        [[alternative HTML version deleted]]
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.CA.us  Sat Oct 31 18:41:02 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 31 Oct 2015 10:41:02 -0700
Subject: [R] If else
In-Reply-To: <CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
	<CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
	<F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>
	<CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>
Message-ID: <99ACF179-A71C-461D-AA2D-E2C11A6616C6@dcn.davis.CA.us>

Rolf gave you two ways. There are others. They all misrepresent the data (there are only two sexes but you are effectively acting as if there are three); hence the inquisition in hopes of diverting you to a more correct method of analysis. However, this is not the support forum for whatever other software you plan to proceed with so never mind.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2015 10:15:33 AM PDT, Val <valkremk at gmail.com> wrote:
>Hi Jeff,
>
>I thought I answered. Yes I was not clear about it.  The further
>analysis
>will no  be done by R.  It is another software that will not accept a
>character response variable.
>
>Why R is so complicated to do that.  If it is SAS then I can do it on
>one
>statement. .
>
>
>On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> You haven't actually answered John's question as to the type of
>analysis
>> you plan to do. It still looks from here like you should be using
>factor
>> data rather than numeric, but since you are not being clear we cannot
>give
>> specifics as to how to proceed.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
>> >Hi All,
>> >
>> >
>> >Yes I need  to change to numeric  because I am preparing a data set
>> >for
>> >further  analysis. The variable to be changed  from character to
>> >numeric
>> >(in this case, sex) will be a response variable.  Some records have
>> >missing
>> >observation on sex and it is blank.
>> >     id  sex
>> >      1
>> >      2
>> >      3  M
>> >      4  F
>> >      5  M
>> >      6  F
>> >      7  F
>> >
>> >I am reading the data like this
>> >
>> >mydata <- read.csv(header=TRUE, text=', sep=", ")
>> >     id  sex
>> >      1   NA
>> >      2  NA
>> >      3  M
>> >      4  F
>> >      5  M
>> >      6  F
>> >      7  F
>> >
>> >The  data set is huge   (>250,000)
>> >
>> >
>> >I want the output like this
>> >
>> >     id  sex    sex1
>> >      1   NA    0
>> >      2  NA     0
>> >      3  M       1
>> >      4  F       2
>> >      5  M      1
>> >      6  F       2
>> >      7  F       2
>> >
>> >Thank you in advance
>> >
>> >
>> >On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com>
>wrote:
>> >
>> >> In line.
>> >>
>> >> John Kane
>> >> Kingston ON Canada
>> >>
>> >>
>> >> > -----Original Message-----
>> >> > From: valkremk at gmail.com
>> >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
>> >> > To: istazahn at gmail.com
>> >> > Subject: Re: [R] If else
>> >> >
>> >> > I am trying to change the mydata$sex  from character to numeric
>> >>
>> >> Why?
>> >>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
>> >this is
>> >> a very unusual thing to do in R.
>> >>
>> >> Is there a very specific reason for doing this in your analysis.
>> >> Otherwise it may better to leave the coding as NA. Some of the
>data
>> >mungers
>> >> here may be able to suggest which is the best strategy in R.
>> >>
>> >> R is 'weird' compared to more mundane stats packages such as SAS
>or
>> >SPSS
>> >> and common techniques that one would use with them often are not
>> >> appropriate in R.
>> >>
>> >>
>> >>
>> >>
>> >> > I want teh out put like
>> >> >    id  sex
>> >> >       1  NA   0
>> >> >       2  NA   0
>> >> >       3  M     1
>> >> >       4  F     2
>> >> >       5  M    1
>> >> >       6  F     2
>> >> >       7  F    2
>> >> >
>> >> > mydata$sex1 <- 0
>> >> > if(mydata$sex =="M " ){
>> >> >   mydata$sex1<-1
>> >> > } else {
>> >> >   mydata$sex1<-2
>> >> > }
>> >> >
>> >> > mydata$sex1
>> >> >
>> >> > Warning message:In if (mydata$sex == "M ") { :
>> >> >   the condition has length > 1 and only the first element will
>be
>> >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
>> >> >
>> >> >>
>> >> >
>> >> >
>> >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
>> >wrote:
>> >> >
>> >> >> Using numeric for missing sounds like asking for trouble. But
>if
>> >you
>> >> >> must, something like
>> >> >>
>> >> >> mydata$confusingWillCauseProblemsLater <-
>> >> >>   ifelse(
>> >> >>     is.na(mydata$sex),
>> >> >>     0,
>> >> >>     as.numeric(factor(mydata$sex,
>> >> >>                       levels = c("M", "F"))))
>> >> >>
>> >> >> should do it.
>> >> >>
>> >> >> Best,
>> >> >> Ista
>> >> >>
>> >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com>
>wrote:
>> >> >>> Hi all,
>> >> >>> Iam trying to change character  to numeric but have probelm
>> >> >>>
>> >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
>> >> >>>      id  sex
>> >> >>>       1  NA
>> >> >>>       2  NA
>> >> >>>       3  M
>> >> >>>       4  F
>> >> >>>       5  M
>> >> >>>       6  F
>> >> >>>       7  F
>> >> >>>        ')
>> >> >>>
>> >> >>> if sex is missing then sex=0;
>> >> >>> if sex is"M" then sex=1;
>> >> >>> if sex is"F" then sex=2;
>> >> >>>
>> >> >>> Any help please ?
>> >> >>>
>> >> >>>         [[alternative HTML version deleted]]
>> >> >>>
>> >> >>> ______________________________________________
>> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >>> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >>> and provide commented, minimal, self-contained, reproducible
>> >code.
>> >> >>
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >> ____________________________________________________________
>> >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks &
>orcas
>> >on
>> >> your desktop!
>> >> Check it out at http://www.inbox.com/marineaquarium
>> >>
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From jdnewmil at dcn.davis.CA.us  Sat Oct 31 19:36:00 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 31 Oct 2015 11:36:00 -0700
Subject: [R] Vector of symbols?
In-Reply-To: <COL130-W945E79611B9A6A7AD9CA7EAD2E0@phx.gbl>
References: <COL130-W945E79611B9A6A7AD9CA7EAD2E0@phx.gbl>
Message-ID: <03D4CFDF-A3D0-428D-A262-B27AED194921@dcn.davis.CA.us>

I believe it is possible, but R is not really a full-fledged symbolic algebra system so it wouldn't be an intuitive tool to use and what would you do with it once you had it? It is much more useful in R to do something like

f1 <- function( M, A, B, C ) {
    M %*% c( A, B, C )
}

m <- matrix( c( 1,0,-1,0,1,2,0,0,1 ), ncol=3 )
f1( m, 3, 4, 5 )
#      [,1]
# [1,]    3
# [2,]    4
# [3,]   10

which manipulates numeric values according to your definition.

For future reference... Please post on this list using plain text format... your email was a pain to decipher.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2015 8:52:51 AM PDT, Judson <judsonblake at msn.com> wrote:
>
>
>Is
>there a way to multiply a matrix 
>
>times
>a vector of symbols?  
>
>For
>instance, could I do this: 
>
>1       
>0       0                          a
>
>0        1      
>0      times           b
>
>-1       2      
>1                          c                
>
> 
>
>which
>should result in :  
>
>                                                      a
>
>                                                      b
>
>                                                      c  ?a 
>-2*b 
>where a, b, and c 
>
>are
>as yet not assigned numeric values?  
>
>........................... judson blake
>
>
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Sat Oct 31 19:36:52 2015
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Sat, 31 Oct 2015 14:36:52 -0400
Subject: [R] Vector of symbols?
In-Reply-To: <COL130-W945E79611B9A6A7AD9CA7EAD2E0@phx.gbl>
References: <COL130-W945E79611B9A6A7AD9CA7EAD2E0@phx.gbl>
Message-ID: <B048DBBC-E148-44F0-AB7A-AA98FD4136D0@utoronto.ca>

You are describing an awkward way of doing this (and your example is unreadable because you are not following posting instructions for the list) ... but the following contains the essence of what I think is needed: parse() and eval().

v <- character()

v[1] <- sprintf("%d ^ %s", 2, "duck")
v[2] <- sprintf("%d * %s", 4, "crow")
# [1] "2 ^ duck" "4 * crow"

duck <- -2
crow <- pi

eval(parse(text=v[1]))
# [1] 0.25

eval(parse(text=v[2]))
# 12.56637


However, myself, I would  not use symbols, but a named vector of values - unless it's important to you that these are _actually_ symbols. You probably avoid some conversions from and to symbols.

v1 <- c(2, 4)
v2 <- c(duck = -2, crow = pi)

v1[1] * v2["duck"]
v1[2] * v2["crow"]

You can of course freely interconvert and cast your symbol names to character:
duck <- 100
v2[as.character(quote(duck))] <- duck
v1[1] * v2["duck"]
#[1] 200



B.




On Oct 31, 2015, at 11:52 AM, Judson <judsonblake at msn.com> wrote:

> 
> 
> Is
> there a way to multiply a matrix 
> 
> times
> a vector of symbols?  
> 
> For
> instance, could I do this: 
> 
> 1       
> 0       0                          a
> 
> 0        1      
> 0      times           b
> 
> -1       2      
> 1                          c                
> 
> 
> 
> which
> should result in :  
> 
>                                                      a
> 
>                                                      b
> 
>                                                      c  ?a 
> -2*b 
> where a, b, and c 
> 
> are
> as yet not assigned numeric values?  
> 
> ........................... judson blake
> 
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Sat Oct 31 19:44:06 2015
From: jfox at mcmaster.ca (Fox, John)
Date: Sat, 31 Oct 2015 18:44:06 +0000
Subject: [R] If else
In-Reply-To: <CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>
References: <cajoir6az_rv2an=qzhv32wzzgfj2g8zms6zxbz730xzkyrtt2a@mail.gmail.com>
	<ca+vqilh4r-m3cxkkrs3irshs_1kb+6jicy+or0kkhggdg9jk0g@mail.gmail.com>
	<CAJOiR6aopHUfnb98Ug_Yapf8SRg+xPQYzwyS1cQrPk1Z3pPz1Q@mail.gmail.com>
	<19F51FAADFD.00000132jrkrideau@inbox.com>
	<CAJOiR6ZSNwdgzAx5Pc-7RKnjypgUzppnF09=6w=vvs399weKRA@mail.gmail.com>
	<F73F0BFB-DF37-436F-8FCE-181CF5B50543@dcn.davis.CA.us>
	<CAJOiR6YCTOsVV3Qn8HbXcUdDO5O0ym79tD5XVpm2wcHPwFmQyw@mail.gmail.com>
Message-ID: <ACD1644AA6C67E4FBD0C350625508EC810F350A0@FHSDB2D11-2.csu.mcmaster.ca>

Dear Val,

I haven't been following this thread, but there are several ways to do what you want, for example,

> within(mydata, sex1 <- ifelse(is.na(sex), 0, ifelse(sex == "M", 1, 2)))
  id  sex sex1
1  1 <NA>    0
2  2 <NA>    0
3  3    M    1
4  4    F    2
5  5    M    1
6  6    F    2
7  7    F    2

My apologies if someone has already suggested that.

Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Val
> Sent: Saturday, October 31, 2015 1:16 PM
> To: Jeff Newmiller
> Cc: r-help at R-project.org (r-help at r-project.org)
> Subject: Re: [R] If else
> 
> Hi Jeff,
> 
> I thought I answered. Yes I was not clear about it.  The further
> analysis
> will no  be done by R.  It is another software that will not accept a
> character response variable.
> 
> Why R is so complicated to do that.  If it is SAS then I can do it on
> one
> statement. .
> 
> 
> On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us>
> wrote:
> 
> > You haven't actually answered John's question as to the type of
> analysis
> > you plan to do. It still looks from here like you should be using
> factor
> > data rather than numeric, but since you are not being clear we cannot
> give
> > specifics as to how to proceed.
> > ----------------------------------------------------------------------
> -----
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> > Go...
> >                                       Live:   OO#.. Dead: OO#..
> Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> > ----------------------------------------------------------------------
> -----
> > Sent from my phone. Please excuse my brevity.
> >
> > On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
> > >Hi All,
> > >
> > >
> > >Yes I need  to change to numeric  because I am preparing a data set
> > >for
> > >further  analysis. The variable to be changed  from character to
> > >numeric
> > >(in this case, sex) will be a response variable.  Some records have
> > >missing
> > >observation on sex and it is blank.
> > >     id  sex
> > >      1
> > >      2
> > >      3  M
> > >      4  F
> > >      5  M
> > >      6  F
> > >      7  F
> > >
> > >I am reading the data like this
> > >
> > >mydata <- read.csv(header=TRUE, text=', sep=", ")
> > >     id  sex
> > >      1   NA
> > >      2  NA
> > >      3  M
> > >      4  F
> > >      5  M
> > >      6  F
> > >      7  F
> > >
> > >The  data set is huge   (>250,000)
> > >
> > >
> > >I want the output like this
> > >
> > >     id  sex    sex1
> > >      1   NA    0
> > >      2  NA     0
> > >      3  M       1
> > >      4  F       2
> > >      5  M      1
> > >      6  F       2
> > >      7  F       2
> > >
> > >Thank you in advance
> > >
> > >
> > >On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com>
> wrote:
> > >
> > >> In line.
> > >>
> > >> John Kane
> > >> Kingston ON Canada
> > >>
> > >>
> > >> > -----Original Message-----
> > >> > From: valkremk at gmail.com
> > >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
> > >> > To: istazahn at gmail.com
> > >> > Subject: Re: [R] If else
> > >> >
> > >> > I am trying to change the mydata$sex  from character to numeric
> > >>
> > >> Why?
> > >>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
> > >this is
> > >> a very unusual thing to do in R.
> > >>
> > >> Is there a very specific reason for doing this in your analysis.
> > >> Otherwise it may better to leave the coding as NA. Some of the data
> > >mungers
> > >> here may be able to suggest which is the best strategy in R.
> > >>
> > >> R is 'weird' compared to more mundane stats packages such as SAS or
> > >SPSS
> > >> and common techniques that one would use with them often are not
> > >> appropriate in R.
> > >>
> > >>
> > >>
> > >>
> > >> > I want teh out put like
> > >> >    id  sex
> > >> >       1  NA   0
> > >> >       2  NA   0
> > >> >       3  M     1
> > >> >       4  F     2
> > >> >       5  M    1
> > >> >       6  F     2
> > >> >       7  F    2
> > >> >
> > >> > mydata$sex1 <- 0
> > >> > if(mydata$sex =="M " ){
> > >> >   mydata$sex1<-1
> > >> > } else {
> > >> >   mydata$sex1<-2
> > >> > }
> > >> >
> > >> > mydata$sex1
> > >> >
> > >> > Warning message:In if (mydata$sex == "M ") { :
> > >> >   the condition has length > 1 and only the first element will be
> > >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> > >> >
> > >> >>
> > >> >
> > >> >
> > >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
> > >wrote:
> > >> >
> > >> >> Using numeric for missing sounds like asking for trouble. But if
> > >you
> > >> >> must, something like
> > >> >>
> > >> >> mydata$confusingWillCauseProblemsLater <-
> > >> >>   ifelse(
> > >> >>     is.na(mydata$sex),
> > >> >>     0,
> > >> >>     as.numeric(factor(mydata$sex,
> > >> >>                       levels = c("M", "F"))))
> > >> >>
> > >> >> should do it.
> > >> >>
> > >> >> Best,
> > >> >> Ista
> > >> >>
> > >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com> wrote:
> > >> >>> Hi all,
> > >> >>> Iam trying to change character  to numeric but have probelm
> > >> >>>
> > >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
> > >> >>>      id  sex
> > >> >>>       1  NA
> > >> >>>       2  NA
> > >> >>>       3  M
> > >> >>>       4  F
> > >> >>>       5  M
> > >> >>>       6  F
> > >> >>>       7  F
> > >> >>>        ')
> > >> >>>
> > >> >>> if sex is missing then sex=0;
> > >> >>> if sex is"M" then sex=1;
> > >> >>> if sex is"F" then sex=2;
> > >> >>>
> > >> >>> Any help please ?
> > >> >>>
> > >> >>>         [[alternative HTML version deleted]]
> > >> >>>
> > >> >>> ______________________________________________
> > >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> >>> PLEASE do read the posting guide
> > >> >> http://www.R-project.org/posting-guide.html
> > >> >>> and provide commented, minimal, self-contained, reproducible
> > >code.
> > >> >>
> > >> >
> > >> >       [[alternative HTML version deleted]]
> > >> >
> > >> > ______________________________________________
> > >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >> > https://stat.ethz.ch/mailman/listinfo/r-help
> > >> > PLEASE do read the posting guide
> > >> > http://www.R-project.org/posting-guide.html
> > >> > and provide commented, minimal, self-contained, reproducible
> code.
> > >>
> > >> ____________________________________________________________
> > >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks &
> orcas
> > >on
> > >> your desktop!
> > >> Check it out at http://www.inbox.com/marineaquarium
> > >>
> > >>
> > >>
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > >______________________________________________
> > >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > >https://stat.ethz.ch/mailman/listinfo/r-help
> > >PLEASE do read the posting guide
> > >http://www.R-project.org/posting-guide.html
> > >and provide commented, minimal, self-contained, reproducible code.
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Oct 31 20:04:04 2015
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 31 Oct 2015 12:04:04 -0700
Subject: [R] ASR tree with highlighted state-changes
In-Reply-To: <DUB407-EAS193E99593616FED244C41D5F32E0@phx.gbl>
References: <DUB407-EAS193E99593616FED244C41D5F32E0@phx.gbl>
Message-ID: <86163DDE-1AE2-44B7-A876-04AB0A287774@dcn.davis.CA.us>

Have you read [1]? Plotting usually comes after analysis, so if you haven't pulled your data into R yet then there may yet be a huge number of possible ways to proceed.

You should probably also read the Posting Guide mentioned at the bottom of every email on this list. In particular, sending your message using plain text (an option in your email client) will allow you to see what we will see when we read your email (the mails reach us without any formatting). Also, whenever possible give us a reproducible example that shows how far along you are in your analysis.

[1] https://cran.r-project.org/web/views/Phylogenetics.html
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2015 2:59:06 AM PDT, Richard Harris <rharris2727 at hotmail.co.uk> wrote:
>
>
>
>
>
>
>
>Sent from Windows Mail
>
>Hi,
>
>
>
>
>I am looking for possible code (if any code exists) for creating a
>tree/ graphical representation of ancestral state reconstruction that
>clearly highlights state-changes or where state changes are estimated?
>I am using binary for my trait distinctions.
>
>
>
>
>I am very new to r so please be gentle!
>
>
>Thanks.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Ted.Harding at wlandres.net  Sat Oct 31 20:47:07 2015
From: Ted.Harding at wlandres.net ( (Ted Harding))
Date: Sat, 31 Oct 2015 19:47:07 -0000 (GMT)
Subject: [R] If else
In-Reply-To: <99ACF179-A71C-461D-AA2D-E2C11A6616C6@dcn.davis.CA.us>
Message-ID: <XFMail.20151031193001.Ted.Harding@wlandres.net>

[Apologies if the message below should arrive twice. When first
sent there was apparently something wrong with the email address
to r-help, and it was held for moderation because "Message has
implicit destination" (whatever that means). I have made sure
that this time the email address is correct.]

John Fox has given a neat expression to achieve the desired result!

I would like to comment, however, on the somewhat insistent criticism
of Val's request from several people.

It can make sense to have three "sex"es. Suppose, for example,
that the data are records of street crime reported by victims.
The victim may be able to identify the sex of the preprator
as definitely "M", or definitely "F". One of the aims of the
analysis is to investgate whether there is an association
between the gender of the offender and the type of crime.

But in some cases the victim may not have been able to recognise
the offender's sex. Then it would have to go in the record as "NA"
(or equivalent). There can be two kinds of reason why the victim
was unable to recognise the sex. One kind is where the victim
simply did not see the offender (e.g. their purse was stolen
while they were concentrating on something else, and they only
found out later). Another kind is where the offender deliberately
disguises their gender, so that it cannot be determined from their
appearance. This second kind could be associated with a particular
category of crime (and I leave it to people's lurid imaginations
to think of possible examples ... ).

Then one indeed has three "sex"es: Male, Female, and Indeterminate,
for each of which there is a potential assoctiation with type of crime.
With most analyses, however, a category of "NA" would be ignored
(at least by R).

And then one has a variable which is a factor with 3 levels, all
of which can (as above) be meaningful), and "NA" would not be
ignored.

Hoping this helps to clarify! (And, Val, does the above somehow
correspond to your objectives).

Best wishes to all,
Ted.

On 31-Oct-2015 17:41:02 Jeff Newmiller wrote:
> Rolf gave you two ways. There are others. They all misrepresent the data
> (there are only two sexes but you are effectively acting as if there are
> three); hence the inquisition in hopes of diverting you to a more correct
> method of analysis. However, this is not the support forum for whatever other
> software you plan to proceed with so never mind.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 31, 2015 10:15:33 AM PDT, Val <valkremk at gmail.com> wrote:
>>Hi Jeff,
>>
>>I thought I answered. Yes I was not clear about it.  The further
>>analysis
>>will no  be done by R.  It is another software that will not accept a
>>character response variable.
>>
>>Why R is so complicated to do that.  If it is SAS then I can do it on
>>one
>>statement. .
>>
>>
>>On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us>
>>wrote:
>>
>>> You haven't actually answered John's question as to the type of
>>analysis
>>> you plan to do. It still looks from here like you should be using
>>factor
>>> data rather than numeric, but since you are not being clear we cannot
>>give
>>> specifics as to how to proceed.
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                       Live:   OO#.. Dead: OO#.. 
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
>>> >Hi All,
>>> >
>>> >
>>> >Yes I need  to change to numeric  because I am preparing a data set
>>> >for
>>> >further  analysis. The variable to be changed  from character to
>>> >numeric
>>> >(in this case, sex) will be a response variable.  Some records have
>>> >missing
>>> >observation on sex and it is blank.
>>> >     id  sex
>>> >      1
>>> >      2
>>> >      3  M
>>> >      4  F
>>> >      5  M
>>> >      6  F
>>> >      7  F
>>> >
>>> >I am reading the data like this
>>> >
>>> >mydata <- read.csv(header=TRUE, text=', sep=", ")
>>> >     id  sex
>>> >      1   NA
>>> >      2  NA
>>> >      3  M
>>> >      4  F
>>> >      5  M
>>> >      6  F
>>> >      7  F
>>> >
>>> >The  data set is huge   (>250,000)
>>> >
>>> >
>>> >I want the output like this
>>> >
>>> >     id  sex    sex1
>>> >      1   NA    0
>>> >      2  NA     0
>>> >      3  M       1
>>> >      4  F       2
>>> >      5  M      1
>>> >      6  F       2
>>> >      7  F       2
>>> >
>>> >Thank you in advance
>>> >
>>> >
>>> >On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com>
>>wrote:
>>> >
>>> >> In line.
>>> >>
>>> >> John Kane
>>> >> Kingston ON Canada
>>> >>
>>> >>
>>> >> > -----Original Message-----
>>> >> > From: valkremk at gmail.com
>>> >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
>>> >> > To: istazahn at gmail.com
>>> >> > Subject: Re: [R] If else
>>> >> >
>>> >> > I am trying to change the mydata$sex  from character to numeric
>>> >>
>>> >> Why?
>>> >>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
>>> >this is
>>> >> a very unusual thing to do in R.
>>> >>
>>> >> Is there a very specific reason for doing this in your analysis.
>>> >> Otherwise it may better to leave the coding as NA. Some of the
>>data
>>> >mungers
>>> >> here may be able to suggest which is the best strategy in R.
>>> >>
>>> >> R is 'weird' compared to more mundane stats packages such as SAS
>>or
>>> >SPSS
>>> >> and common techniques that one would use with them often are not
>>> >> appropriate in R.
>>> >>
>>> >>
>>> >>
>>> >>
>>> >> > I want teh out put like
>>> >> >    id  sex
>>> >> >       1  NA   0
>>> >> >       2  NA   0
>>> >> >       3  M     1
>>> >> >       4  F     2
>>> >> >       5  M    1
>>> >> >       6  F     2
>>> >> >       7  F    2
>>> >> >
>>> >> > mydata$sex1 <- 0
>>> >> > if(mydata$sex =="M " ){
>>> >> >   mydata$sex1<-1
>>> >> > } else {
>>> >> >   mydata$sex1<-2
>>> >> > }
>>> >> >
>>> >> > mydata$sex1
>>> >> >
>>> >> > Warning message:In if (mydata$sex == "M ") { :
>>> >> >   the condition has length > 1 and only the first element will
>>be
>>> >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
>>> >> >
>>> >> >>
>>> >> >
>>> >> >
>>> >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
>>> >wrote:
>>> >> >
>>> >> >> Using numeric for missing sounds like asking for trouble. But
>>if
>>> >you
>>> >> >> must, something like
>>> >> >>
>>> >> >> mydata$confusingWillCauseProblemsLater <-
>>> >> >>   ifelse(
>>> >> >>     is.na(mydata$sex),
>>> >> >>     0,
>>> >> >>     as.numeric(factor(mydata$sex,
>>> >> >>                       levels = c("M", "F"))))
>>> >> >>
>>> >> >> should do it.
>>> >> >>
>>> >> >> Best,
>>> >> >> Ista
>>> >> >>
>>> >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com>
>>wrote:
>>> >> >>> Hi all,
>>> >> >>> Iam trying to change character  to numeric but have probelm
>>> >> >>>
>>> >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
>>> >> >>>      id  sex
>>> >> >>>       1  NA
>>> >> >>>       2  NA
>>> >> >>>       3  M
>>> >> >>>       4  F
>>> >> >>>       5  M
>>> >> >>>       6  F
>>> >> >>>       7  F
>>> >> >>>        ')
>>> >> >>>
>>> >> >>> if sex is missing then sex=0;
>>> >> >>> if sex is"M" then sex=1;
>>> >> >>> if sex is"F" then sex=2;
>>> >> >>>
>>> >> >>> Any help please ?
>>> >> >>>
>>> >> >>>         [[alternative HTML version deleted]]
>>> >> >>>
>>> >> >>> ______________________________________________
>>> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> >>> PLEASE do read the posting guide
>>> >> >> http://www.R-project.org/posting-guide.html
>>> >> >>> and provide commented, minimal, self-contained, reproducible
>>> >code.
>>> >> >>
>>> >> >
>>> >> >       [[alternative HTML version deleted]]
>>> >> >
>>> >> > ______________________________________________
>>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>see
>>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> >> > PLEASE do read the posting guide
>>> >> > http://www.R-project.org/posting-guide.html
>>> >> > and provide commented, minimal, self-contained, reproducible
>>code.
>>> >>
>>> >> ____________________________________________________________
>>> >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks &
>>orcas
>>> >on
>>> >> your desktop!
>>> >> Check it out at http://www.inbox.com/marineaquarium
>>> >>
>>> >>
>>> >>
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-------------------------------------------------
E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
Date: 31-Oct-2015  Time: 19:29:50
This message was sent by XFMail


From valkremk at gmail.com  Sat Oct 31 21:27:55 2015
From: valkremk at gmail.com (Val)
Date: Sat, 31 Oct 2015 15:27:55 -0500
Subject: [R] If else
In-Reply-To: <XFMail.20151031193001.Ted.Harding@wlandres.net>
References: <99ACF179-A71C-461D-AA2D-E2C11A6616C6@dcn.davis.CA.us>
	<XFMail.20151031193001.Ted.Harding@wlandres.net>
Message-ID: <CAJOiR6YaRVMeDjxaiULp5jBpA7=0_9n5MM3FTjL28q-Utn8r5Q@mail.gmail.com>

Thank you very much Ted  for expressing my feeling!. I am working on field
data and the sex of an individual is not recorded  sometimes and hence and
I give it  a category of  NA.

Thank you all for the help.




On Sat, Oct 31, 2015 at 2:47 PM, Ted Harding <Ted.Harding at wlandres.net>
wrote:

> [Apologies if the message below should arrive twice. When first
> sent there was apparently something wrong with the email address
> to r-help, and it was held for moderation because "Message has
> implicit destination" (whatever that means). I have made sure
> that this time the email address is correct.]
>
> John Fox has given a neat expression to achieve the desired result!
>
> I would like to comment, however, on the somewhat insistent criticism
> of Val's request from several people.
>
> It can make sense to have three "sex"es. Suppose, for example,
> that the data are records of street crime reported by victims.
> The victim may be able to identify the sex of the preprator
> as definitely "M", or definitely "F". One of the aims of the
> analysis is to investgate whether there is an association
> between the gender of the offender and the type of crime.
>
> But in some cases the victim may not have been able to recognise
> the offender's sex. Then it would have to go in the record as "NA"
> (or equivalent). There can be two kinds of reason why the victim
> was unable to recognise the sex. One kind is where the victim
> simply did not see the offender (e.g. their purse was stolen
> while they were concentrating on something else, and they only
> found out later). Another kind is where the offender deliberately
> disguises their gender, so that it cannot be determined from their
> appearance. This second kind could be associated with a particular
> category of crime (and I leave it to people's lurid imaginations
> to think of possible examples ... ).
>
> Then one indeed has three "sex"es: Male, Female, and Indeterminate,
> for each of which there is a potential assoctiation with type of crime.
> With most analyses, however, a category of "NA" would be ignored
> (at least by R).
>
> And then one has a variable which is a factor with 3 levels, all
> of which can (as above) be meaningful), and "NA" would not be
> ignored.
>
> Hoping this helps to clarify! (And, Val, does the above somehow
> correspond to your objectives).
>
> Best wishes to all,
> Ted.
>
> On 31-Oct-2015 17:41:02 Jeff Newmiller wrote:
> > Rolf gave you two ways. There are others. They all misrepresent the data
> > (there are only two sexes but you are effectively acting as if there are
> > three); hence the inquisition in hopes of diverting you to a more correct
> > method of analysis. However, this is not the support forum for whatever
> other
> > software you plan to proceed with so never mind.
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                       Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On October 31, 2015 10:15:33 AM PDT, Val <valkremk at gmail.com> wrote:
> >>Hi Jeff,
> >>
> >>I thought I answered. Yes I was not clear about it.  The further
> >>analysis
> >>will no  be done by R.  It is another software that will not accept a
> >>character response variable.
> >>
> >>Why R is so complicated to do that.  If it is SAS then I can do it on
> >>one
> >>statement. .
> >>
> >>
> >>On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
> >><jdnewmil at dcn.davis.ca.us>
> >>wrote:
> >>
> >>> You haven't actually answered John's question as to the type of
> >>analysis
> >>> you plan to do. It still looks from here like you should be using
> >>factor
> >>> data rather than numeric, but since you are not being clear we cannot
> >>give
> >>> specifics as to how to proceed.
> >>>
>
> >>---------------------------------------------------------------------------
> >>> Jeff Newmiller                        The     .....       .....  Go
> >>Live...
> >>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> >>> Go...
> >>>                                       Live:   OO#.. Dead: OO#..
> >>Playing
> >>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >>> /Software/Embedded Controllers)               .OO#.       .OO#.
> >>rocks...1k
> >>>
>
> >>---------------------------------------------------------------------------
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>> On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
> >>> >Hi All,
> >>> >
> >>> >
> >>> >Yes I need  to change to numeric  because I am preparing a data set
> >>> >for
> >>> >further  analysis. The variable to be changed  from character to
> >>> >numeric
> >>> >(in this case, sex) will be a response variable.  Some records have
> >>> >missing
> >>> >observation on sex and it is blank.
> >>> >     id  sex
> >>> >      1
> >>> >      2
> >>> >      3  M
> >>> >      4  F
> >>> >      5  M
> >>> >      6  F
> >>> >      7  F
> >>> >
> >>> >I am reading the data like this
> >>> >
> >>> >mydata <- read.csv(header=TRUE, text=', sep=", ")
> >>> >     id  sex
> >>> >      1   NA
> >>> >      2  NA
> >>> >      3  M
> >>> >      4  F
> >>> >      5  M
> >>> >      6  F
> >>> >      7  F
> >>> >
> >>> >The  data set is huge   (>250,000)
> >>> >
> >>> >
> >>> >I want the output like this
> >>> >
> >>> >     id  sex    sex1
> >>> >      1   NA    0
> >>> >      2  NA     0
> >>> >      3  M       1
> >>> >      4  F       2
> >>> >      5  M      1
> >>> >      6  F       2
> >>> >      7  F       2
> >>> >
> >>> >Thank you in advance
> >>> >
> >>> >
> >>> >On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com>
> >>wrote:
> >>> >
> >>> >> In line.
> >>> >>
> >>> >> John Kane
> >>> >> Kingston ON Canada
> >>> >>
> >>> >>
> >>> >> > -----Original Message-----
> >>> >> > From: valkremk at gmail.com
> >>> >> > Sent: Fri, 30 Oct 2015 20:40:03 -0500
> >>> >> > To: istazahn at gmail.com
> >>> >> > Subject: Re: [R] If else
> >>> >> >
> >>> >> > I am trying to change the mydata$sex  from character to numeric
> >>> >>
> >>> >> Why?
> >>> >>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
> >>> >this is
> >>> >> a very unusual thing to do in R.
> >>> >>
> >>> >> Is there a very specific reason for doing this in your analysis.
> >>> >> Otherwise it may better to leave the coding as NA. Some of the
> >>data
> >>> >mungers
> >>> >> here may be able to suggest which is the best strategy in R.
> >>> >>
> >>> >> R is 'weird' compared to more mundane stats packages such as SAS
> >>or
> >>> >SPSS
> >>> >> and common techniques that one would use with them often are not
> >>> >> appropriate in R.
> >>> >>
> >>> >>
> >>> >>
> >>> >>
> >>> >> > I want teh out put like
> >>> >> >    id  sex
> >>> >> >       1  NA   0
> >>> >> >       2  NA   0
> >>> >> >       3  M     1
> >>> >> >       4  F     2
> >>> >> >       5  M    1
> >>> >> >       6  F     2
> >>> >> >       7  F    2
> >>> >> >
> >>> >> > mydata$sex1 <- 0
> >>> >> > if(mydata$sex =="M " ){
> >>> >> >   mydata$sex1<-1
> >>> >> > } else {
> >>> >> >   mydata$sex1<-2
> >>> >> > }
> >>> >> >
> >>> >> > mydata$sex1
> >>> >> >
> >>> >> > Warning message:In if (mydata$sex == "M ") { :
> >>> >> >   the condition has length > 1 and only the first element will
> >>be
> >>> >> > used> mydata$sex1[1] 2 2 2 2 2 2 2 2
> >>> >> >
> >>> >> >>
> >>> >> >
> >>> >> >
> >>> >> > On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
> >>> >wrote:
> >>> >> >
> >>> >> >> Using numeric for missing sounds like asking for trouble. But
> >>if
> >>> >you
> >>> >> >> must, something like
> >>> >> >>
> >>> >> >> mydata$confusingWillCauseProblemsLater <-
> >>> >> >>   ifelse(
> >>> >> >>     is.na(mydata$sex),
> >>> >> >>     0,
> >>> >> >>     as.numeric(factor(mydata$sex,
> >>> >> >>                       levels = c("M", "F"))))
> >>> >> >>
> >>> >> >> should do it.
> >>> >> >>
> >>> >> >> Best,
> >>> >> >> Ista
> >>> >> >>
> >>> >> >> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com>
> >>wrote:
> >>> >> >>> Hi all,
> >>> >> >>> Iam trying to change character  to numeric but have probelm
> >>> >> >>>
> >>> >> >>> mydata <- read.table(header=TRUE, text=', sep=" "
> >>> >> >>>      id  sex
> >>> >> >>>       1  NA
> >>> >> >>>       2  NA
> >>> >> >>>       3  M
> >>> >> >>>       4  F
> >>> >> >>>       5  M
> >>> >> >>>       6  F
> >>> >> >>>       7  F
> >>> >> >>>        ')
> >>> >> >>>
> >>> >> >>> if sex is missing then sex=0;
> >>> >> >>> if sex is"M" then sex=1;
> >>> >> >>> if sex is"F" then sex=2;
> >>> >> >>>
> >>> >> >>> Any help please ?
> >>> >> >>>
> >>> >> >>>         [[alternative HTML version deleted]]
> >>> >> >>>
> >>> >> >>> ______________________________________________
> >>> >> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>see
> >>> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> >>> PLEASE do read the posting guide
> >>> >> >> http://www.R-project.org/posting-guide.html
> >>> >> >>> and provide commented, minimal, self-contained, reproducible
> >>> >code.
> >>> >> >>
> >>> >> >
> >>> >> >       [[alternative HTML version deleted]]
> >>> >> >
> >>> >> > ______________________________________________
> >>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> >>see
> >>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >> > PLEASE do read the posting guide
> >>> >> > http://www.R-project.org/posting-guide.html
> >>> >> > and provide commented, minimal, self-contained, reproducible
> >>code.
> >>> >>
> >>> >> ____________________________________________________________
> >>> >> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks &
> >>orcas
> >>> >on
> >>> >> your desktop!
> >>> >> Check it out at http://www.inbox.com/marineaquarium
> >>> >>
> >>> >>
> >>> >>
> >>> >
> >>> >       [[alternative HTML version deleted]]
> >>> >
> >>> >______________________________________________
> >>> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >PLEASE do read the posting guide
> >>> >http://www.R-project.org/posting-guide.html
> >>> >and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 31-Oct-2015  Time: 19:29:50
> This message was sent by XFMail
> -------------------------------------------------
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Oct 31 23:02:47 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 31 Oct 2015 18:02:47 -0400
Subject: [R] If else
In-Reply-To: <XFMail.20151031193001.Ted.Harding@wlandres.net>
References: <XFMail.20151031193001.Ted.Harding@wlandres.net>
Message-ID: <56353A87.706@gmail.com>

On 31/10/2015 3:47 PM, (Ted Harding) wrote:
> [Apologies if the message below should arrive twice. When first
> sent there was apparently something wrong with the email address
> to r-help, and it was held for moderation because "Message has
> implicit destination" (whatever that means). I have made sure
> that this time the email address is correct.]
> 
> John Fox has given a neat expression to achieve the desired result!
> 
> I would like to comment, however, on the somewhat insistent criticism
> of Val's request from several people.
> 
> It can make sense to have three "sex"es. Suppose, for example,
> that the data are records of street crime reported by victims.
> The victim may be able to identify the sex of the preprator
> as definitely "M", or definitely "F". One of the aims of the
> analysis is to investgate whether there is an association
> between the gender of the offender and the type of crime.
> 
> But in some cases the victim may not have been able to recognise
> the offender's sex. Then it would have to go in the record as "NA"
> (or equivalent). There can be two kinds of reason why the victim
> was unable to recognise the sex. One kind is where the victim
> simply did not see the offender (e.g. their purse was stolen
> while they were concentrating on something else, and they only
> found out later). Another kind is where the offender deliberately
> disguises their gender, so that it cannot be determined from their
> appearance. This second kind could be associated with a particular
> category of crime (and I leave it to people's lurid imaginations
> to think of possible examples ... ).

I'm not convinced by your example.  I'm quite happy to say that the sex
is M or F or unobserved, but unobserved is not a third sex, under that
model it just means "M or F but I don't know which".  It is an
incomplete observation, it's not a third sex.

I can imagine 3 sexes in a case of multiple individuals:  "all M", "all
F", "mixed".

I can also imagine more complicated definitions of "sex" that include
more than 2 categories, but I think that's not what we're talking about
here.

> 
> Then one indeed has three "sex"es: Male, Female, and Indeterminate,
> for each of which there is a potential assoctiation with type of crime.
> With most analyses, however, a category of "NA" would be ignored
> (at least by R).

That claim is nonsense.  R never ignores *anything* unless the analyst
tells it to.  The analyst may choose to ignore something, but don't
blame R if the analyst makes a bad decision.

Duncan Murdoch


> And then one has a variable which is a factor with 3 levels, all
> of which can (as above) be meaningful), and "NA" would not be
> ignored.
> 
> Hoping this helps to clarify! (And, Val, does the above somehow
> correspond to your objectives).
> 
> Best wishes to all,
> Ted.
> 
> On 31-Oct-2015 17:41:02 Jeff Newmiller wrote:
>> Rolf gave you two ways. There are others. They all misrepresent the data
>> (there are only two sexes but you are effectively acting as if there are
>> three); hence the inquisition in hopes of diverting you to a more correct
>> method of analysis. However, this is not the support forum for whatever other
>> software you plan to proceed with so never mind.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> --------------------------------------------------------------------------- 
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 31, 2015 10:15:33 AM PDT, Val <valkremk at gmail.com> wrote:
>>> Hi Jeff,
>>>
>>> I thought I answered. Yes I was not clear about it.  The further
>>> analysis
>>> will no  be done by R.  It is another software that will not accept a
>>> character response variable.
>>>
>>> Why R is so complicated to do that.  If it is SAS then I can do it on
>>> one
>>> statement. .
>>>
>>>
>>> On Sat, Oct 31, 2015 at 11:39 AM, Jeff Newmiller
>>> <jdnewmil at dcn.davis.ca.us>
>>> wrote:
>>>
>>>> You haven't actually answered John's question as to the type of
>>> analysis
>>>> you plan to do. It still looks from here like you should be using
>>> factor
>>>> data rather than numeric, but since you are not being clear we cannot
>>> give
>>>> specifics as to how to proceed.
>>>>
>>> ---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>> Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                       Live:   OO#.. Dead: OO#.. 
>>> Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>>> rocks...1k
>>>>
>>> ---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On October 31, 2015 8:23:05 AM PDT, Val <valkremk at gmail.com> wrote:
>>>>> Hi All,
>>>>>
>>>>>
>>>>> Yes I need  to change to numeric  because I am preparing a data set
>>>>> for
>>>>> further  analysis. The variable to be changed  from character to
>>>>> numeric
>>>>> (in this case, sex) will be a response variable.  Some records have
>>>>> missing
>>>>> observation on sex and it is blank.
>>>>>     id  sex
>>>>>      1
>>>>>      2
>>>>>      3  M
>>>>>      4  F
>>>>>      5  M
>>>>>      6  F
>>>>>      7  F
>>>>>
>>>>> I am reading the data like this
>>>>>
>>>>> mydata <- read.csv(header=TRUE, text=', sep=", ")
>>>>>     id  sex
>>>>>      1   NA
>>>>>      2  NA
>>>>>      3  M
>>>>>      4  F
>>>>>      5  M
>>>>>      6  F
>>>>>      7  F
>>>>>
>>>>> The  data set is huge   (>250,000)
>>>>>
>>>>>
>>>>> I want the output like this
>>>>>
>>>>>     id  sex    sex1
>>>>>      1   NA    0
>>>>>      2  NA     0
>>>>>      3  M       1
>>>>>      4  F       2
>>>>>      5  M      1
>>>>>      6  F       2
>>>>>      7  F       2
>>>>>
>>>>> Thank you in advance
>>>>>
>>>>>
>>>>> On Sat, Oct 31, 2015 at 5:59 AM, John Kane <jrkrideau at inbox.com>
>>> wrote:
>>>>>
>>>>>> In line.
>>>>>>
>>>>>> John Kane
>>>>>> Kingston ON Canada
>>>>>>
>>>>>>
>>>>>>> -----Original Message-----
>>>>>>> From: valkremk at gmail.com
>>>>>>> Sent: Fri, 30 Oct 2015 20:40:03 -0500
>>>>>>> To: istazahn at gmail.com
>>>>>>> Subject: Re: [R] If else
>>>>>>>
>>>>>>> I am trying to change the mydata$sex  from character to numeric
>>>>>>
>>>>>> Why?
>>>>>>  As Ista (mydata$confusingWillCauseProblemsLater) has pointed out
>>>>> this is
>>>>>> a very unusual thing to do in R.
>>>>>>
>>>>>> Is there a very specific reason for doing this in your analysis.
>>>>>> Otherwise it may better to leave the coding as NA. Some of the
>>> data
>>>>> mungers
>>>>>> here may be able to suggest which is the best strategy in R.
>>>>>>
>>>>>> R is 'weird' compared to more mundane stats packages such as SAS
>>> or
>>>>> SPSS
>>>>>> and common techniques that one would use with them often are not
>>>>>> appropriate in R.
>>>>>>
>>>>>>
>>>>>>
>>>>>>
>>>>>>> I want teh out put like
>>>>>>>    id  sex
>>>>>>>       1  NA   0
>>>>>>>       2  NA   0
>>>>>>>       3  M     1
>>>>>>>       4  F     2
>>>>>>>       5  M    1
>>>>>>>       6  F     2
>>>>>>>       7  F    2
>>>>>>>
>>>>>>> mydata$sex1 <- 0
>>>>>>> if(mydata$sex =="M " ){
>>>>>>>   mydata$sex1<-1
>>>>>>> } else {
>>>>>>>   mydata$sex1<-2
>>>>>>> }
>>>>>>>
>>>>>>> mydata$sex1
>>>>>>>
>>>>>>> Warning message:In if (mydata$sex == "M ") { :
>>>>>>>   the condition has length > 1 and only the first element will
>>> be
>>>>>>> used> mydata$sex1[1] 2 2 2 2 2 2 2 2
>>>>>>>
>>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> On Fri, Oct 30, 2015 at 8:28 PM, Ista Zahn <istazahn at gmail.com>
>>>>> wrote:
>>>>>>>
>>>>>>>> Using numeric for missing sounds like asking for trouble. But
>>> if
>>>>> you
>>>>>>>> must, something like
>>>>>>>>
>>>>>>>> mydata$confusingWillCauseProblemsLater <-
>>>>>>>>   ifelse(
>>>>>>>>     is.na(mydata$sex),
>>>>>>>>     0,
>>>>>>>>     as.numeric(factor(mydata$sex,
>>>>>>>>                       levels = c("M", "F"))))
>>>>>>>>
>>>>>>>> should do it.
>>>>>>>>
>>>>>>>> Best,
>>>>>>>> Ista
>>>>>>>>
>>>>>>>> On Fri, Oct 30, 2015 at 9:15 PM, Val <valkremk at gmail.com>
>>> wrote:
>>>>>>>>> Hi all,
>>>>>>>>> Iam trying to change character  to numeric but have probelm
>>>>>>>>>
>>>>>>>>> mydata <- read.table(header=TRUE, text=', sep=" "
>>>>>>>>>      id  sex
>>>>>>>>>       1  NA
>>>>>>>>>       2  NA
>>>>>>>>>       3  M
>>>>>>>>>       4  F
>>>>>>>>>       5  M
>>>>>>>>>       6  F
>>>>>>>>>       7  F
>>>>>>>>>        ')
>>>>>>>>>
>>>>>>>>> if sex is missing then sex=0;
>>>>>>>>> if sex is"M" then sex=1;
>>>>>>>>> if sex is"F" then sex=2;
>>>>>>>>>
>>>>>>>>> Any help please ?
>>>>>>>>>
>>>>>>>>>         [[alternative HTML version deleted]]
>>>>>>>>>
>>>>>>>>> ______________________________________________
>>>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>>> and provide commented, minimal, self-contained, reproducible
>>>>> code.
>>>>>>>>
>>>>>>>
>>>>>>>       [[alternative HTML version deleted]]
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>>> see
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible
>>> code.
>>>>>>
>>>>>> ____________________________________________________________
>>>>>> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks &
>>> orcas
>>>>> on
>>>>>> your desktop!
>>>>>> Check it out at http://www.inbox.com/marineaquarium
>>>>>>
>>>>>>
>>>>>>
>>>>>
>>>>>       [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -------------------------------------------------
> E-Mail: (Ted Harding) <Ted.Harding at wlandres.net>
> Date: 31-Oct-2015  Time: 19:29:50
> This message was sent by XFMail
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From greenstone1114 at gmail.com  Sat Oct 31 21:28:35 2015
From: greenstone1114 at gmail.com (Green Stone)
Date: Sat, 31 Oct 2015 20:28:35 +0000
Subject: [R] Works on Mac,
 but not Windows: Using tempdir() to determine image location works
 with .tex file
Message-ID: <CAHjK6++KAKc7n-V1rrNGJ1Mr9kborG+=YNepjU8G7OidGGTe6g@mail.gmail.com>

I am writing an R package that generates a .pdf file for users that outputs
summarizations of data. I have a .Rnw script in the package (here, my MWE
of it is called test.Rnw). The user can do:

knit2pdf("test.Rnw", clean=T)

This makes the process easy for them, because it automatically creates the
.pdf file from the .tex file, and it erases unnecessary files for them
(.aux and .log, for example). It also stores any images into a temporary
directory (using tempdir()), which will then be erased routinely by the
system after they have been incorporated into the .tex and .pdf file. This
means they do not have to erase image files either.

Below is my test.Rnw MWE:

\documentclass[nohyper]{tufte-handout}
\usepackage{tabularx}
\usepackage{longtable}

\setcaptionfont{% changes caption font characteristics
  \normalfont\footnotesize
  \color{black}% <-- set color here}

\begin{document}
<<setup, echo=FALSE>>=
library(knitr)
library(xtable)
library(ggplot2)# Specify directory for figure output in a temporary directory
temppath <- tempdir()
opts_chunk$set(fig.path = temppath)@

  <<diamondData, echo=FALSE, fig.env = "marginfigure",
out.width="0.95\\linewidth", fig.cap = "The diamond dataset has
varibles depth and price.",fig.lp="mar:">>=
  print(qplot(depth,price,data=diamonds))@

  <<echo=FALSE,results='asis'>>=
  myDF <- data.frame(a = rnorm(1:10), b = letters[1:10])
print(xtable(myDF, caption= 'This data frame shows ten random
variables from the distribution and a corresponding letter',
label='tab:dataFrame'), floating = FALSE, tabular.environment =
"longtable", include.rownames=FALSE)@

  Figure \ref{mar:diamondData} shows the diamonds data set, with the
variables price and depth.Table \ref{tab:dataFrame} shows letters a through j
corresponding to a random variable from a normal distribution.

\end{document}

I should note that, in reality, there is another .Rnw file in my package
that calls the test.Rnw file via:

knit2pdf("/inst/Rnw/test.Rnw","/path/test.tex",clean=T)

In any case, I am trying to get this package ready to be submitted to CRAN
and have run across two problems:

1) The more perplexing question first: The MWE code above seems to work on
Mac Systems, but does not seem to work on Windows Systems! On Windows, the
.pdf file that is generated does not contain the images. After
troubleshooting, I think I have figured out the problem, but still cannot
find a solution.

Basically, on Windows, it seems that the tempdir() command will create a
pathway with double back-slashes, such as \this\is\myPath. Then, in the
.tex file, the pathway to the temporary directory (that contains the
images) are single back-slashes, such as \this\is\myPath. However, these
should be single forward-slashes, such as /this/is/myPath.

Indeed, if I manually the change the backslashes to forward slashes in the
.tex file in Windows, then I can successfully convert it to .pdf file that
successfully contains the images.

I am unsure how to solve this in my syntax, however. If I simply do
something like:

# Specify directory for figure output in a temporary directory
temppath <- tempdir()
gsub("\\\\", "/", temppath)

Then the images cannot be stored into the pathway on the Windows in the
first place, even if the .tex file will contain the correct single forward
slashes needed.

2) I am wondering if it would acceptable for me to, in my other .Rnw file,
add a second line to call:

knit2pdf("/inst/Rnw/test.Rnw","/path/test.tex",clean=T)
system(sprintf("%s", paste0("rm -r ", "/path/myFile.tex")))

So that the .tex file can also be automatically erased. I am trying to
confirm that such syntax would be acceptable by CRAN standards, as it does
involve erasing a file from the user's computer (which could seem like
dangerous/malware), although it points specifically at the .tex file it
just generated, and so it should not be deleting anything important for
them.

*Note: I am by default erasing all intermediary files so the user only
deals with the .pdf file. However, I am still allowing users the option to
go against this default, and keep these intermediary files, if needed.

I am grateful to hear any suggestions...

	[[alternative HTML version deleted]]


